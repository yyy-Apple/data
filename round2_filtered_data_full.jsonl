{"text": "Retrieved from http://math.stackexchange.com/questions/352352/integral-extension-implies-that-the-induced-map-on-prime-spectra-is-closed\nText:\nSign up \u00d7\n\nSay we have an integral extension $f:R \\hookrightarrow S$ of rings. I want to show that the induced map $f^*:Spec(S) \\twoheadrightarrow Spec(R)$ is closed. In other words, let $V(I) = \\{\\mathfrak{P} \\in Spec(S) | \\mathfrak{P} \\supset I\\}$, for some ideal $I \\in S$, be a closed subset in $Spec(S)$. I want to find an ideal $J \\in R$ such that $f^*(V(I)) = V(J)$.\n\nI thought about using $J = I^{c} = I \\cap R$ (contraction), but one direction is unclear to me. To be more precise, let $\\mathfrak{p}$ be a prime ideal of $R$ containing $I^c$. By the lying over property of the extension, we know that there exists a $\\mathfrak{P} \\in Spec(S)$ such that $\\mathfrak{p} = \\mathfrak{P}^c$. But is it even true then that $I$ is contained in $\\mathfrak{P}$?\n\nThanks for your time.\n\nshare|cite|improve this question\nYes, your candidate for $J$ is the right one. \u2013\u00a0 Georges Elencwajg Apr 5 '13 at 17:48\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nApply lying over to $R/I^c \\hookrightarrow S/I$.\n\nshare|cite|improve this answer\nAh, yes! Because passing to quotients preserves integrity (integrality?), and prime ideals $\\mathfrak{p}$ containing $I^c$ correspond to prime ideals $\\mathfrak{p}/I^c$in the quotient... Thus there exists a prime ideal $\\mathfrak{P}/I$ such that $(\\mathfrak{P}/I)^c = p/I^c$, and from there we can easily conclude that $\\mathfrak{P}^c = \\mathfrak{p}$. \u2013\u00a0 A.P. Apr 5 '13 at 20:34\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/1943/if-a-vehicle-is-rolling-down-a-hill-will-its-speed-depend-on-the-size-of-the-wh\nText:\nSign up \u00d7\n\nIf I am sitting on a skateboard and travel downhill, will the velocity depend at all on the size of the wheel?\n\nThe skateboard is only powered by gravity. There are a lot of variables to consider. Given the best conditions, where the surface of the road is smooth, and the tires are roughly equivalent.\n\nI've heard answers that larger wheels are faster because they offer more springiness, and smaller wheels are slower because they deform more and thus have higher rolling resistance. Larger wheels are faster because they roll over imperfections in the road better than smaller wheels.\n\nI am curious from a theoretical standpoint, does the size of the wheel matter? That is perhaps, ignoring things like rolling resistance. And also from a practical standpoint.\n\nshare|cite|improve this question\n\n3 Answers 3\n\nWell, you can't directly compare speeds, because the vehicle has different speeds at different times (or equivalently, at different positions). But you can compare the accelerations. It turns out that if you look at the theoretically simplest effect, moment of inertia, the acceleration does not depend on the wheel size, but it does depend on the shape of the wheels.\n\nSuppose a wheel has a moment of inertia $I$, which for a solid cylinder would be $\\frac{1}{2}mr^2$ ($m$ is the wheel's mass and $r$ is its radius). The kinetic energy of the wheel is\n\n$$K = \\frac{1}{2}mv^2 + \\frac{1}{2}I\\omega^2$$\n\nNow, suppose you have $N$ of these wheels mounted to a chassis of mass $M$. The kinetic energy of the entire ensemble is\n\n$$K = \\frac{1}{2}(M + Nm)v^2 + \\frac{1}{2}NI\\omega^2$$\n\nIf the wheels roll without slipping, then $v = r\\omega$ and that becomes\n\n$$K = \\frac{1}{2}\\left(M + Nm + \\frac{NI}{r^2}\\right)v^2$$\n\nAnd if this whole thing is rolling down a slope of inclination $\\theta$ (where $\\theta = 0$ corresponds to horizontal), the total energy is\n\n$$E = \\frac{1}{2}\\left(M + Nm + \\frac{NI}{r^2}\\right)v^2 - (M + Nm)gd\\sin\\theta = 0$$\n\nwhere $d$ is the distance traveled along the slope from the point at which the vehicle started rolling. If you take the time derivative of this and do a little algebra, you get\n\n$$a = \\frac{(M + Nm)g\\sin\\theta}{M + Nm + \\frac{NI}{r^2}}$$\n\nAt this point it's worth noting that moment of inertia for any kind of rotationally symmetric object (like a wheel) is given by a formula of the form\n\n$$I = bmr^2$$\n\nwhere $b$ is some number. For instance, $b = \\frac{1}{2}$ for the solid cylinder I mentioned above. For a hollow wheel (no hubcaps or anything) you'd have $b = 1$, for a sphere $b = \\frac{2}{5}$, and so on. So the above formula reduces to\n\n$$a = \\frac{(M + Nm)g\\sin\\theta}{M + Nm(1 + b)}$$\n\nNotice that it doesn't depend on the size of the wheel ($r$) anymore. But it does depend on that constant $b$, which is determined by the wheel's shape. A wheel with a larger value of $b$ will undergo less acceleration.\n\nshare|cite|improve this answer\n+1 Nice theoretical description. I'll point out that if you've read both David's my answers and are wondering if they say different things, no, they fundamentally agree. David shows that while $r$ doesn't matter, the mass of the wheels $m$ does matter. So if bigger wheels with bigger $r$ also have bigger $m$, they would be slower. \u2013\u00a0 Mark Eichenlaub Dec 15 '10 at 11:02\n\nFrom a purely theoretical standpoint, the radius of the wheel doesn't matter, but heavy wheels are slow.\n\nIn an idealized scenario, the skateboard conserves energy. This means that its total energy when it gets to the bottom of the hill is the same regardless of how it goes down.\n\nAs a wheel rolls down the hill, it picks up kinetic energy. Some of that goes into its translational motion, while some goes in its rotation. The energy in the rotation is essentially wasted from the point of view of going fast. A solid cylinder or disk, for example, will move $1/\\sqrt{1.5} = 0.81$ times as fast at the bottom of a hill it has rolled down as it would go if it slid down without rolling (and without friction).\n\nIf you have heavy wheels compared to the weight of the skateboard and rider, then you suffer most of this slowdown. If you have light wheels, the energy of the wheels hardly matters and you can approach the ideal sliding speed.\n\nNext we want to know if this matters. On Wikipedia I found that rolling resistances can be about $0.01$. When you roll down an incline of angle $\\theta$, you lose about $0.01 \\cot\\theta$ of the energy you pick up to friction. For now set rolling resistance equal to $c$ instead of the number $0.01$. For cylindrical wheels of total mass $m$ and total wheels and rider of mass $M$, a fraction $m/3M$ is used in rotational rather than translational kinetic energy. Thus, the rotational energy stored in the wheels becomes important when, roughly speaking,\n\n$$m/M > 3 c \\cot\\theta$$\n\nThe question we wanted to answer was not when rolling resistance becomes important, but what size wheels are faster. So imagine that $c$ is a function of $R$, the wheel radius, and that $m = \\lambda R^2$, saying that we'll consider wheels of the same density and thickness, but different radius.\n\nIf we differentiate both sides of the previous expression with respect to $R$, we get a condition for the extra rotational energy stored in the wheel size to start being a bad trade off for any improvement in rolling resistance.\n\n$$2\\lambda R/M > - 3 c'(R) \\cot\\theta$$\n\n\n$$ R > -\\frac{3 M c'(R) \\cot\\theta}{2\\lambda}$$\n\nWhen this inequality is satisfied, making the wheels large will slow you down. Otherwise larger wheels are better. Note that if $c'(R)$ is zero or positive, larger wheels are always worse.\n\nUnfortunately, I can't think of good ways to estimate $c'(R)$ without experimentation. One thing I can think of is this (it's highly speculative): A skateboard has pretty hard wheels that probably don't deform much under the weight of a rider, but skateboards are treated roughly and may get some grime in their bearings. So I would guess that friction in the bearing could be the most important factor in rolling resistance for a skateboard. I don't have much experience with them, but I think that if I take a skateboard wheel and spin it while holding it up in the air, it won't spin and spin for a minute or more like a bicycle wheel will. Larger wheels mean fewer rotations and less motion in the bearing, so this would give $c(R) = \\alpha/R$ for some constant $\\alpha$. This guess would give\n\n$$ R > \\frac{3 M \\alpha \\cot\\theta}{2\\lambda R^2}$$\n\n\n$$R > \\left(\\frac{3 M \\alpha \\cot\\theta}{2\\lambda}\\right)^{1/3}$$\n\nWhen I let the density of the wheels be $1g/cm^3$, the mass of the rider by $75 kg$, the slope $10 ^\\circ$, the width of the wheels $2 cm$, and the rolling resistance $0.01$ when the wheels are $5cm$ tall, I get that larger wheels slow you down when $R > 17 cm$. That would indicate that larger wheels are actually better in this case up to a pretty big size wheel (for a skateboard), but take it with a large grain of salt. There are lots of unjustified assumptions in there.\n\nshare|cite|improve this answer\n\nLet me try to make an explanation without formulas.\n\nSuppose you assume no rolling friction, and you start at the top of a hill at height h and you and your wheels weigh w. Then your initial potential energy is wh (uh-oh, a formula).\n\nThen you roll down the hill, and at the bottom your kinetic energy is wh, obviously.\n\nBut that consists of two parts, 1) you, traveling at a velocity v, plus 2) the wheels, which are spinning and have their own kinetic energy. Their rims are moving at velocity v with respect to their hubs.\n\nSo any energy in the spinning wheels will subtract from your bodily kinetic energy. In the extreme, if your wheels were connected to a big flywheel (like a \"friction motor\" in a toy) you would come down slowly and all the energy would be in the flywheel.\n\nSo to get down as fast as possible, you want to minimize the mass in the wheel rims. But if the wheel mass and distribution is held constant, the wheel radius should not matter. The reason the wheel radius does not matter is the energy in the wheels depends on v and the mass in the wheel rims, and nothing else.\n\nSo that would argue for smaller, lighter wheels. On the other hand, if you can't ignore rolling friction, I would suppose smaller wheels have more friction, depending on the type of surface (rough cement vs. something very smooth). If the surface were very smooth and firm, it would seem that tiny lightweight wheels (needle bearings?) would work best.\n\nshare|cite|improve this answer\nFriction is a complicated and not well understood thing, even more so rolling friction. Because rolling friction is not really a primary physical phenomenon like \"sliding friction\", I recommend not to mention it in one row. Rolling friction is humping and bumping of the wheel, and results from hysteresis of the deformations included. Eg, some skater rolls on a pavement, is that \"rolling friction\"? I'd prefer to dismiss rolling friction from pysics textbooks. \u2013\u00a0 Georg Nov 6 '11 at 10:15\n@Georg: I agree, but if someone is facing the practical engineering problem of choosing a wheel size, they can't ignore it, and the OP did want practical information. I'm just thinking of an extreme situation of a bicycle riding over rough terrain. If the wheels were small they would get stuck in every little bump. \u2013\u00a0 Mike Dunlavey Nov 6 '11 at 13:40\nYes of course! Thousands of years of wheel making show that bigger wheels are better the rougher the ground. \u2013\u00a0 Georg Nov 6 '11 at 13:47\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/200599/subspace-spanned-by-the-vectors\nText:\nSign up \u00d7\n\nI am having difficulty understanding this question:\n\nGraph the subspace spanned by the vectors $i = (3,-2,-1)^T$, $j = (-2,0,-1)^T$.\n\nYou don't have to graph it, but the answer for this problem is $z = (-3/5)x - (6/5)y$. I don't understand how to come up with that answer. I tried setting $i=-j$ but to no avail. Also, sorry for writing $i,j$ with $^T$, I do not know how to format it to make it look like a column vector.\n\nshare|cite|improve this question\nAre you sure that's the right answer? The points $(3,-2,-1)$ and $(-2,0,-1)$ don't seem to be on that plane. \u2013\u00a0 yunone Sep 22 '12 at 7:27\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nI think something is not quite right here.\n\nSince we are in $\\mathbb{R}^3$ we can find the normal to the plane spanned by $i, j$ by $i \\times j = (2,5,-4)^T$, hence the equation of the plane is $\\langle (x,y,z)^T, i \\times j \\rangle = 2x+5y-4z =0$, which gives $z = \\frac{1}{2} x + \\frac{5}{4} y$.\n\nHere is another approach that does not use the cross product:\n\nSuppose $(x,y,z) = a i + b j = (3a-2b, -2a, -(a+b))$. Then, from $y$ we have $a = -\\frac{y}{2}$, and from $x$ we have $b = -\\frac{3}{4} y -\\frac{1}{2} x$. Then $z = -(a+b) = \\frac{1}{2} x + \\frac{5}{4} y$.\n\nshare|cite|improve this answer\nHow did you get z=1/2x + 5/4y and (2,5,-4)^T ? We haven't been taught the cross product yet. \u2013\u00a0 diimension Sep 22 '12 at 21:53\nI added another approach. \u2013\u00a0 copper.hat Sep 22 '12 at 22:00\nI understand now because of your help, thank you very much copper!! \u2013\u00a0 diimension Sep 22 '12 at 23:15\nYou are very welcome, glad to be of help. \u2013\u00a0 copper.hat Sep 23 '12 at 0:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/261747/dimension-of-the-irreducible-components-of-an-affine-open-in-mathbbpn-k\nText:\nTake the 2-minute tour \u00d7\n\nI was doing some exercises in Liu's book on Algebraic Geometry. I am currently trying to solve a problem by showing the following:\n\nLet $U \\subset \\mathbb{P}^n_k$, k a field, be an affine open subset.\nShow that the irreducible components of $\\mathbb{P}^n_k-U$ all have dimension n-1.\n\nI would appreciate any help / hint here. I have some problems understanding $\\mathbb{P }^n_k$ at a deep (even semi-deep) level. I suspect that one could maybe show that the dimension of such an affine open should be of dimension n (or am I wrong here?), since we can compute the dimension of X on any open set. We should be able to write the complement as $V_+(I)$ for some homogenous ideal . However, I don't see how to get from this to that the irreducible components of the component has dimension n-1.\n\nThank you for looking at my question and please forgive me if it's a naive one.\n\nshare|improve this question\nI don't think it is naive. Here is something related: mathoverflow.net/questions/22040/\u2026 \u2013\u00a0 Andrew Dec 19 '12 at 0:07\nAs Andrew pointed out, this result holds in a fairly general situation (affine open subset in a noetherian separated scheme, this is also Exercise 4.1.15). But in the UDF case as in $\\mathbb P^n_k$, the proof is much easier: use the previous parts of Exericse 2.5.12. \u2013\u00a0 user18119 Dec 19 '12 at 7:06\nQiL: I'm afraid I don't see an obvious application of either of the previous ones. Should I use something like that on $D(x_i)$ it is principal? The wonders of technology, by the way, allowing one to talk directly to the author of the book. Thank you very much for your answers! \u2013\u00a0 Dedalus Dec 19 '12 at 10:12\n@Dedalus: it seems like the author didn't give enough details for this exercise :). Consider the intersection with the affine spaces in $\\mathbb P^n$ and use (b). If this is not enough I will post an answer. \u2013\u00a0 user18119 Dec 19 '12 at 13:22\n@QiL: I don't think the details are neccesarily left out (it might be that I'm simply dense here). If we let U be the open affine. if we go to the intersections of U with the principal affine opens $D(x_i)$, we get that in each such affine, $U \\cap D(x_i)$ is principal. The complement is $V(f)$, and it has irreduble components of dimension n-1 (right?) . So, can we from this conclude that each irreducible component of the complement of U in $\\mathbb{P}^n_k$ is irreducible of dimension n-1? \u2013\u00a0 Dedalus Dec 19 '12 at 13:55\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nFor the sake of an answer. Cover $\\mathbb P^n_k$ (with coordinates $x_0, \\dots, x_n$) by affines spaces $U_0, \\dots, U_n$ with $U_i=D_+(x_i)$. Then $$ \\mathbb P^n_k\\setminus U=\\cup_i (U_i\\setminus (U\\cap U_i))$$ and it is enough to show $U_i\\setminus (U\\cap U_i)$ is empty or pure of dimension $n-1$ for all $i\\le n$. By a previous part of the exercice, we know that $U_i\\setminus (U\\cap U_i)$ is a principal closed subset of $U_i$, hence it is empty or pure of dimension $n-1$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/130969/chain-rule-or-product-rule?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI have the following equation to calculate its derivative:\n\n$$f(x) = e^{3x}(\\sin(x)+\\cos(x))$$\n\nI used the product rule and I got this answer:\n\n\nBut the answer at the end of the book is:\n\n\nI am scratching my head to find where that $3$ came from. I think I have to use chaing rule here as well, but I am not sure to take which part of equation as $z$.\n\nshare|improve this question\nThe derivative of $e^{3x}$ is $3e^{3x}$. \u2013\u00a0 azarel Apr 12 '12 at 18:31\nYou could also simplify the answer further by factoring out $e^{3x}$ and combining like terms. \u2013\u00a0 Mike Apr 12 '12 at 20:06\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $g(x)=e^{3x}$ and $h(x)=\\sin(x)+\\cos(x)$.Then $f(x)=g(x)\\cdot h(x)$. The product rule states $f'(x)=g'(x)h(x)+g(x)h'(x)$.In our case $$(e^{3x})'(\\sin(x)+\\cos(x))+(e^{3x})(\\sin(x)+\\cos(x))'=3e^{3x}(\\sin(x)+\\cos(x))+e^{3x}(\\cos(x)-\\sin(x))$$\n\nWatch out that $ (e^{3x})'=3e^{3x}$. That's because $e^{3x}=e^{z}$ where $z=3x$. Therefore $\\frac{de^z}{dx}=\\frac{de^z}{dz}\\frac{dz}{dx}=e^z\\cdot z'(x)$. Substituting back, we got: $\\frac{de^{3x}}{dx}=e^{3x}\\cdot (3x)'=3e^{3x}$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162332/g-12-and-no-elements-of-order-2-in-zg\nText:\nTake the 2-minute tour \u00d7\n\nI am thinking on the following problem:\n\nIf $|G|=12$ and there is no element of order $2$ in its center then $3$-Sylow subgroup of $G$ cannot be normal in $G$.\n\nI was told that to assume the $3$-Sylow subgroup of $G$, say $P$, is normal in the group and go to reach a contradiction.\n\nMy attept: $|P|=3$ so it is cyclic, $P=\\langle x\\rangle=\\{1,x,x^2\\}$. As above hint, I would have for all $g\\in G$ two possibilities: $gxg^{-1}=x$ or $gxg^{-1}=x^2$. Cannot to go any further. I am in doubt if the hint leads me to a contradiction properly and if so, it does with a long proof. Any help or any other way are welcome to me. Thanks for your time.\n\nshare|improve this question\nThis is a followup to math.stackexchange.com/questions/158339/\u2026 \u2013\u00a0 Jack Schmidt Jun 24 '12 at 19:10\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nHint #1: Show that all Sylow 2-subgroups are abelian. So if an element of a Sylow 2-subgroup commutes with the elements of $P$, then it belongs to the center.\n\nHint #2: At this point the questions you should ask from yourself are: 1) What possibilities (up to isomorphism) are there for the Sylow 2-subgroup H? 2) Given that $P$ was assumed to be normal, what possibilities are there for the conjugation action for the non-trivial elements of $H$. Remember that conjugation action is a homomorphism from $H$ to $Aut(P)$.\n\nshare|improve this answer\n:About you first hint: That the Sylow 2-subgroups is abelian is obvious cause they are of order 4. So I should show that an element of one of these subgroups COMMUTE with $x$. Thanks. As you said me later, you put a loop in my mind finding the result. :-) \u2013\u00a0 Babak S. Jun 24 '12 at 10:14\nCorrect (re: the 1st hint). Be a bit careful in that the element of $H$ that commutes with $P$ should be of order two. It doesn't really matter much in this case, but for full credit... :-) \u2013\u00a0 Jyrki Lahtonen Jun 24 '12 at 10:29\nI am on the way you paved. Yes, with that element say $y$, I can see that $G$ is being generated by $x$ and $y$. Thanks. Thanks. \u2013\u00a0 Babak S. Jun 24 '12 at 10:38\n\nTo follow your attempt:\n\nFor every $g \\in G$, we have $gxg^{-1} = x$ or $gxg^{-1} = x^2$. Thus $x$ has $1$ or $2$ conjugates, in other words, $[G : C_G(x)] = 1$ or $[G : C_G(x)] = 2$. In both cases, $2$ divides the order of $C_G(x)$, and thus $C_G(x)$ contains an element $y$ of order $2$. This gives us the desired contradiction. Can you see why $y$ must belong to the center of $G$?\n\nshare|improve this answer\nThanks for your answer. It solves my problem in detail. :) \u2013\u00a0 Babak S. Jun 25 '12 at 5:39\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/433323/self-adjoint-operator-on-a-finite-dimensional-vector-space\nText:\nTake the 2-minute tour \u00d7\n\nLet $V$ be a finite-dimensional inner product space and let $x,y\\in V$ be nonzero vectors. If there is a self-adjoint operator $A:V\\rightarrow V$ such that $A(x)=y$ and $\\langle A(v),v\\rangle\\geq0$ for all $v\\in V$, then $\\langle x,y\\rangle>0$.\n\nI think we can conclude the following inequality $$\\langle x,y \\rangle=\\langle x,A(x) \\rangle=\\langle A^*(x),x \\rangle=\\langle A(x),x\\rangle\\geq 0$$\n\nbut I'm not able to show that strict inequality holds (or, in other words, that equality is not possible). Can someone give me a hint?\n\nshare|improve this question\nI added the operator theory tag since the result is true more generally (and can be proved the same way) on a Hilbert space, with $A$ a bounded self-adjoint positive operator. \u2013\u00a0 1015 Jul 1 '13 at 1:04\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nAssume for a contradiction that $(x,y)=0$. Then take an orthonormal basis $(e_j)$ of $V$ starting with $$ e_1=\\frac{x}{\\|x\\|}\\qquad e_2=\\frac{y}{\\|y\\|}. $$ The matrix $M$ of $A$ in this orthonormal basis must be symmetric semidefinite positive, and it looks like $$ M=\\pmatrix{0&t&0\\\\ t&*&*\\\\ 0&*&*}\\qquad t=\\frac{\\|y\\|}{\\|x\\|}>0 $$ by blocks, where the first and the second row are the actual first and second rows of $M$, the remaining blocks being of the ad hoc size.\n\nCan you see a contradiction?\n\nConsider the restriction of the quadratic form $(Ax,x)$ to the span of $\\{e_1,e_2\\}$, whose matrix is the upper-left $2\\times 2$ block of $M$. Since the restriction should be semidefinite positive as well, its eigenvalues, whence its determinant $-t^2<0$, must be nonnegative. Contradiction.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209498/matrix-of-positive-definite\nText:\nTake the 2-minute tour \u00d7\n\nProve that a $3\\times3$\n\n\nis positive definite if and only if $a > 0$, $ad - b^2 > 0 $ , $\\det K > 0$. Also prove that an $n\\times n$ matrix $K > 0$ is positive definite if and only if all the upper left square $k \\times k$ subdeterminants are positive for $k = 1, \\ldots, n$.\n\nFor the first part I know that in order it to be a positive definite then the quadratic function $q(x)$ can be transformed by completing the squares but I don't know how to prove $a > 0$, $ad - b^2 > 0 $ , $\\det K > 0$. For the second part I have no idea how to do.\n\nshare|improve this question\nSecond part implies the first \u2013\u00a0 Berci Oct 8 '12 at 21:53\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nHINT Note that if $A = \\begin{pmatrix}A_{11} & A_{12}\\\\ A_{21} & A_{22} \\end{pmatrix}$, where $A_{ij} \\in \\mathbb{R}^{n_i \\times n_j}$ is positive definite, then choosing $x = \\begin{pmatrix}x_1 \\\\ 0 \\end{pmatrix}$, where $x_1 \\in \\mathbb{R}^{n_1 \\times 1}$, we get $$x^TAx = x_1^T A_{11} x_1$$Hence, if $A$ is positive definite so is $A_{11}$ or for that matter any submatrix along the diagonal.\n\nHence, all you need to prove is that the determinant of a positive definite matrix is positive.\n\nTo prove the above fact, first prove that the eigenvalues of a positive definite matrix are positive (Why? Look at the definition of eigenvalue). Then prove that the determinant of a matrix is nothing but the product of all its eigenvalues (Why?).\n\nshare|improve this answer\nThank you marvis!! But we havent learned eigenvalues yet? What can I replace eigenvalues with to prove your hint? \u2013\u00a0 diimension Oct 8 '12 at 22:06\n@diimension: Since $A$ is symmetric positive definite, you can find $B$ such that $A = B \\,^t B$. So you get $\\det(A) = \\det(B) \\det(^t B) = (\\det(B))^2 \\ge 0$. \u2013\u00a0 Joel Cohen Oct 8 '12 at 22:15\nBeautiful thank you very much!! \u2013\u00a0 diimension Oct 8 '12 at 22:18\n@JoelCohen how will I be able to do the first part?Do I take the quadratic function into account here? \u2013\u00a0 diimension Oct 8 '12 at 22:20\n@diimension : The existence of $B$ is equivalent to saying the quadratic function can be written as a sum of squares : If $q(x) = (b_{1,1} x_1 + \\ldots + b_{1,n} x_n)^2 + (b_{2,1} x_1 + \\ldots + b_{2,n} x_n)^2 + \\ldots + (b_{n,1} x_1 + \\ldots + b_{n,n} x_n)^2$, then $A = \\,^t B B$ with $B = (b_{i,j})$. \u2013\u00a0 Joel Cohen Oct 8 '12 at 22:28\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/275434/1st-order-linear-ode-with-tridiagonal-matrix-efficient-solutions\nText:\nTake the 2-minute tour \u00d7\n\nI have a 1st-rder linear ODE system where the system is characterized by $A$. Given an initial state $x_0$, I want the state at some later time $t$, efficiently.\n\n$A$ happens to be a symmetric tridiagonal matrix where the coefficients are the same in each diagonal line.\n\n$$ A = \\begin{pmatrix} a & b & 0 & 0 & ... \\\\ b & a & b & 0 & ... \\\\ 0 & b & a & b & ... \\\\ 0 & 0 & b & a & ... \\\\ \\vdots &&\\ddots&\\ddots&\\ddots\\end{pmatrix} $$\n\nI need to solve this for many different $A$'s and also many different $x_0$'s. The general solution to that is of course\n\n$$x_t = e^{A t}x_0$$\n\nOne way to do this is to eigen-decompose $A$ into $A = F D F^\\top$. Then the solution becomes\n\n$$x_t = (F e^{D t} F^\\top) x_0$$\n\nWhich is a little better because now the multiplication with $x_0$ is $O(n^2)$, but the eigen-decomposition is $O(n^3)$ still. But this doesn't take advantage of the constant values of $a$ and $b$ or the symmetric tridiagonal nature of $A$. So it seems like I should be able to do better.\n\nshare|improve this question\nThere is a nice paper on numerical computation of matrix exponential: Nineteen Dubious Ways to Compute the Exponential of a Matrix by Moler & Van Loan (this is an update of the original paper, 25 years later). \u2013\u00a0 Jean-Claude Arbaut Apr 30 '14 at 22:17\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nI'm not aware of any special algorithms for computing matrix exponentials for matrices with tridiagonal structure, but you probably shouldn't be solving your ODE by directly computing the matrix exponential anyway. Computing matrix exponentials is a tricky business. There's a famous paper by Cleve Moler (inventor of MATLAB) and Charles van Loan that you should check out titled \"Nineteen Dubious Ways to Compute the Matrix Exponential\". It goes through a variety of schemes people have tried over the years and discusses the problems with each one. That's not to say it can't be done but that it's something that needs to be handled with care.\n\nThe good news is that there are plenty of ways to numerically solve your ODE without having to resort to the matrix exponential, and these are all almost certainly more efficient. As an example, consider Euler's method. You want the solution at time $t = t_f$ to $x'(t) = Ax(t)$ with initial condition $x(0) = x_0$. Pick $K + 1$ equally-spaced time-points $0 = t_0 < t_1 < \\cdots < t_K = t_f$, and let $h = (t_f - t_0)/K$ be the spacing between them. Let $x_k$ denote the approximation to the solution at time $t_k$. Euler's method is just the iteration $x_{k + 1} = x_k + hAx_k$.\n\nEach step requires one matrix-vector multiply and one addition of two vectors. Since your matrix is tridiagonal, the matrix-vector multiply will be $O(3n)$, and the vector addition will be $O(n)$. With $K + 1$ steps, you're looking at an overall computational complexity of $O(nK)$. As far as accuracy goes, Euler's method converges at a rate of $O(h) = O(K^{-1})$, so if you double the number of points you use, you cut the error in half.\n\nIf you want something with better convergence properties than Euler's method, there are many other possibilities. Some things to search for are \"Runge-Kutta methods\" and \"one-step methods.\" More sophisticated methods require more function-evaluations (matrix-vector multiplies, in this case) at each time step but can attain better accuracy with fewer time steps.\n\nAt any rate, there's no need to do an $O(n^3)$ eigenvalue computation if you don't want to!\n\nshare|improve this answer\nI didn't read your answer, it looks like we have read the same article ;-) \u2013\u00a0 Jean-Claude Arbaut Apr 30 '14 at 22:19\n\nYou are able to find a closed form expression, only depending on $a$ and $b$, for the the eigenvalues and respective eigenvectors of your matrix $A$. In fact, you can prove that, for $a \\neq 0$, the eigenvalues of $A$ are given by:\n\n$$\\lambda_j=b+2a \\cos(\\frac{j\\pi}{n+1}), \\, j=1,...,n$$ and the respective eigenvectors are known to be:\n\n$${{\\bf{v}}_j} = \\left[ {\\begin{array}{*{20}{c}}{\\sin \\left( {\\frac{{1j\\pi }}{{n + 1}}} \\right)}\\\\{\\sin \\left( {\\frac{{2j\\pi }}{{n + 1}}} \\right)}\\\\ \\vdots \\\\{\\sin \\left( {\\frac{{nj\\pi }}{{n + 1}}} \\right)}\\end{array}} \\right], \\, j=1,...,n$$\n\nThus you can very easily construct the matrices $F$ and $D$ in your decomposition. Also, since $D$ will always be diagonal, as the matrix $A$ is nonsingular, it's straightforward to compute $e^D$.\n\nTo get an idea how to get the expressions I mentioned see, for example:\n\nQuick way of finding the eigenvalues and eigenvectors of the matrix $A=\\operatorname{tridiag}_n(-1,\\alpha,-1)$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/114814/does-n2nk2n2k2-ldots-nmk2-have-a-general-equation\nText:\nTake the 2-minute tour \u00d7\n\nDoes $n^2+(n+k)^2+(n+2k)^2+\\ldots+(n+mk)^2$ have a general formula?\n\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 9 down vote accepted\n\nThe sum can we written as $\\sum_{j=0}^m(n+jk)^2=\\sum_{j=0}^mn^2+2jkn+j^2k^2$ and using the formulas $\\sum_{j=0}^mj=\\frac{m(m+1)}2$, $\\sum_{j=0}^mj^2=\\frac{m(m+1)(2m+1)}6$, we get \\begin{align*}\\sum_{j=0}^m(n+jk)^2&=(m+1)n^2+knm(m+1)+k^2\\frac{m(m+1)(2m+1)}6\\\\ &=(m+1)\\left(n^2+knm+\\frac{k^2m(2m+1)}6\\right). \\end{align*}\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/112026/characteristic-polynomial-of-hypercube-graph\nText:\nTake the 2-minute tour \u00d7\n\nThis is probably well-known, but... Define the $n$-dimensional hypercube graph $H_n$ as having for vertices the integers between 0 and $2^n-1$, and edges between integers differing by a power of 2. The characteristic polynomial of $H_n$ is then $\\prod_{k=0}^n(x-n+2k)^{\\frac {n!}{k!(n-k)!}}$, i.e. $(x-3)(x-1)^3(x+1)^3(x+3)$ for a cube, $(x-4)(x-2)^4x^6(x+2)^4(x+4)$ for a tesseract, etc. Is there a graph-theoretic proof of this result?\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 4 down vote accepted\n\nView the vertices as elements of $\\mathbb{Z}^n$. If $a\\in\\mathbb{Z}^n$, define a function $f_a$ on the vertices by $$ f_a(x) = (-1)^{a^Tx}. $$ This function is an eigenvectors and if $a$ has weight $w$, the eigenvalue is $n-2w$. I can make this look more combinatorial by viewing vertices (and $a$) as subsets of $\\{1,\\ldots,n\\}$ and noting that $f_a(x)$ is determined by the parity of $a \\cap x$ (abusing notation). Different choices of $a$ give linearly independent eigenvectors, so we get the multiplicities as well as the eigenvalues.\n\nThe actual difficulty with this question is in deciding what you mean by a \"graph theoretical proof\". From where I write, linear algebra is a standard and fundamental tool in graph theory.\n\nComment response: (too long for a comment box). OK. The $n$-cube is the Cartesian product of $n$ copies of $K_2$. The eigenvalues of the Cartesian product of two graphs $G$ and $H$ are the sums of the eigenvalues of $G$ with the eigenvalues of $H$. (The simplest way to see this is to note that the eigenvectors of the product are the Kronecker products of the eigenvectors of the factors.) Applying this $n$ times to $K_2$ gives the desired result.\n\nThere are formulas for the effect on the characteristic polynomial adding edges or vertices, but they are not all simple, and I cannot see how to use them to get the eigenvalues of the $n$-cube.\n\nshare|improve this answer\nWell, actually, I am looking for things like calculations of the characteristic polynomial by manipulations of the graph (addig edges or vertices, product of graphes, ans so on), and trying to get some intuition by using well-known families of graphs. But I may be completely on the wrong track \u2013\u00a0 Feldmann Denis Nov 10 '12 at 22:34\nMy comment to this was a bit too long, so I've added it to my answer. \u2013\u00a0 Chris Godsil Nov 10 '12 at 22:48\nA related remark: since $H_n$ is regular, an explicit formula for the number of trees follows from knowing the eigenvalues of the adjacency matrix. It was an open problem to find a combinatorial proof of this formula. Such a proof was recently given by Olivier Bernardi, front.math.ucdavis.edu/1207.0896. \u2013\u00a0 Richard Stanley Nov 11 '12 at 2:23\n\nThe hypercube graph is a Cayley graph. The Hamming graph $H(n,r)$ is the Cayley graph $Cay(\\Bbb Z_r^n,S)$ where $S$ is the set of all elements of $\\Bbb Z_r^n$ with exactly one nozero coordinate. In particular, the Hamming graph $H(n,2)$ is the familiar $n$-dimensional hypercube.\n\nSince $\\Bbb Z_r^n$ is abelian, $\\sum_{s\\in S}\\chi(s)$ where $\\chi$ is an irreducible representation of $\\Bbb Z_r^n$ is an eigenvalue of $H(n,r)$. The eigenvectors of the adjacency matrix $A$ of $H(n,r)$ are the vectors $\\{u_x\\}$, $x\\in\\Bbb Z_r^n$, where its $y$th coordinate is $\\omega_r^{-\\sum_{i=1}^nx_iy_i}$, $y\\in\\Bbb Z_r^n$ and $\\omega_r=e^{\\frac{2\\pi i}{r}}$. Let $\\lambda_x$ be the corresponding eigenvalue of $u_x$. If we dnote by $\\omega_H(x)$ the number of nonzero coordinates in $x$, we have $\\lambda_x=(r-1)n-r\\omega_H(x)$. Now it is enough to put $r=2$. For more details on the spectrum of Cayley graphs see \"Spectra of Cayley graphs, L. Babai, Journal of Combinatorial Theory, Series B 27, (1979) 180-189.\n\nshare|improve this answer\n\nIt is interesting, worthwhile, and not very difficult to understand the situation for the Cartesian product of two or more arbitrary graphs. However here is a simplified answer which applies to this case: Let $G$ be a graph with $n$ vertices and $H$ the $2n$ vertex graph made by taking two copies of $G$ and joining corresponding vertices with an edge. If the (possibly not distinct) eigenvelaues of $G$ are $\\theta_1,\\theta_2,\\cdots,\\theta_n$ then the $2n$ eigenvalues of $H$ are $\\theta_1\\pm 1,\\theta_2\\pm 1,\\cdots,\\theta_n\\pm 1.$ (Note that $H$ is just the Cartesian product $G \\times K_2$.) Here is why: Let $A$ be the adjacency matrix of $G$ and $\\mathbf{x}_1,\\cdots,\\mathbf{x}_n$ a basis of eigenvectors with $A\\mathbf{x}_i=\\theta_i\\mathbf{x}_i.$ Then the $2n \\times 2n$ adjacency matrix of $H$ is $\\left( \\begin{array}{cc} A & I \\\\\\ I & A \\\\\\ \\end{array}\\right)$ and it is easy to confirm that $\\left( \\begin{array}{c}\\mathbf{x}_i \\\\\\ \\mathbf{x}_i \\\\\\ \\end{array}\\right)$ and $\\left( \\begin{array}{c}\\mathbf{x}_i \\\\\\ -\\mathbf{x}_i \\\\\\ \\end{array}\\right)$ are eigenvectors for $\\theta_i+1$ and $\\theta_i-1.$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/278744/a-question-about-localization-of-integral-domains\nText:\nTake the 2-minute tour \u00d7\n\nLet $R$ be an integral domain and $P,Q$ be proper prime ideals of $R$. Let $R_P,R_Q$ be localizations of $R$ at $P,Q$. If $R_P\\subseteq R_Q$, is $Q\\subseteq P$?\n\nshare|improve this question\nPresumably, you mean $\\subseteq$ when considered as subsets of the field of fractions of $R$? \u2013\u00a0 Thomas Andrews Jan 14 '13 at 19:03\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nMore generally, if $R$ is a commutative ring, then $R$-algebra homomorphisms $R_P \\to R_Q$ exist and are unique - by the universal property of localizations - iff $R \\to R_Q$ maps $R \\setminus P$ to $(R_Q)^* = R_Q \\setminus Q R_Q$ iff (since $Q R_Q \\cap R = Q$) $R \\setminus P \\subseteq R \\setminus Q$ iff $Q \\subseteq P$.\n\nMore generally, if $X$ is a scheme with points $x,y$, then $x$ is a specialization of $y$ iff there is a morphism of $X$-schemes $\\mathrm{Spec}(\\mathcal{O}_{X,y}) \\to \\mathrm{Spec}(\\mathcal{O}_{X,x})$.\n\nshare|improve this answer\nthank you very much Martin \u2013\u00a0 Azadeh Jan 20 '13 at 9:49\nadd comment\n\nTake any element $q\\in Q$. If it was not it $P$, then it would be invertible in $R_P$, but not in $R_Q$, which would contradict the fact that $R_P\\subseteq R_Q$.\n\nshare|improve this answer\nThank you very much \u2013\u00a0 Azadeh Jan 14 '13 at 19:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/266144/banach-spaces-with-separable-continuous-duals-are-separable-a-clarification\nText:\nTake the 2-minute tour \u00d7\n\nI'm aware of this post, but I have not yet been granted permission to comment on these other posts, so I hope you'll excuse asking for a clarification here.\n\nFor clarity, I'll restate the question. If $X$ is a Banach space and $X^*$ (the space of continuous linear functionals) is separable, then $X$ is separable.\n\nIn this answer, the chosen answer provides the following argument: Choose a countable dense subset of $X^*$, say $\\{f_n\\}$. Choose $x_n\\in X$ so that $|f_n(x_n)|\\ge 1/2||f_n||_{op}$. If $Y$, the rational span of $\\{x_n\\}$, is not dense, then Hahn-Banach guarantees the existence of a nonzero continuous functional $f$ on $X$ so that $f$ vanishes on $\\overline{Y}$. Find an $n$ for which $||f-f_n||_{op}<1/4$, then since $f(x_n)=0$, we have that\n\n$1/4>||f-f_n||_{op}\\ge |f(x_n)-f_n(x_n)|=|f_n(x_n)|$\n\nEverything so far is elementary. Now, excuse me if I'm missing something simple, but he/she concludes that $|f_n(x_n)|>1/2$, and immediately reaches the contradiction. But we only know that $|f_n(x_n)|>1/2||f_n||_{op}$, no?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nYou can rescale $f$ so that it has unit norm. Then $\\|f-f_n\\|_{op}<1/4$ implies $\\|f_n\\|_{op}>3/4$. Now you can finish the chain of inequalities with $|f_n(x_n)|>(1/2)\\|f_n\\|_{op}>3/8$, which is still a contradiction.\n\nshare|improve this answer\nAh, of course! Thank you. \u2013\u00a0 user39992 Dec 27 '12 at 22:00\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/318660/orientation-of-closed-combinatorical-surfaces\nText:\nTake the 2-minute tour \u00d7\n\nI have some problems with the equivalence of definitions of orientation. I know two definitions of orientation, namely:\n\n  \u2022 A surface is orientable if it contains no 1-sided curves (a 1-sided curve in a combinatorical surface $F$ is a curve such if $p^{-1}(C)$ has just one component with $p:F'\\rightarrow F$ and $F'$ the surface we obtain by cutting $F$ along $C$)\n\nAlso there exists the following lemma: A one-sided curve is always non-seperating (non-seperating means that the number of components of $F'$ has the same as $F$). Can we use this fact? And why is that true? From my point of view one can prove this easy with contradiction,true?!\n\nNow the second definition:\n\n  \u2022 An orientation of a closed combinatorial surface F is an assignment of a clockwise or anticlockwise \\circulation\" to each face (really an ordering of its vertices, considered up to cyclic permutation), such that at any edge, the circulations coming from the two incident faces are in opposition.\n\nNow i want to show directly that a surface has an orientation if and only if it is orientable in the sense that it contains no 1-sided curves.\n\nCan someone help me with this question? Thank you!\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nAssume $F$ is oriented in the sense of the second definition. Let $C$ be a curve. Wlog.(!) the curve runs along edges. The map $p^{-1}(C)\\to\\{-1,+1\\}$ that maps a point to $+1$ if the \"current\" edge at that point is in forward direction of $C$ and to $-1$ if it is in reverse, is well defined (must be checked at vertices) and continuous. As each edge belongs to two faces and is differently oriented for these, ther exist both edges yielding $+1$ and edges yielding $-1$, hence $p^{-1}(C)$ has (at least) two connected components. Hence no one-sided curve exists.\n\nThe other direction is a bit more complicated if one wants to be formally exact, so the following is rather a sketch of an idea: Assume $F$ is oriented in the sense of the first definition. Select an arbitrary face and orient its edges. Extend this face by face to the whole surface by checking faces having at least one edge already oriented. If ever a conflict arises (i.e. the next step would orient an edge differently from an already given orientation by its other face), we find a onesided curve as follows: There is a sequence of faces between the conflicting faces that runs within alrady oriented faces. This also determines a sequence of edges (those that are shared by subsequent faces in this sequence). Join the midpoints of these edges to obtain a closed curve (i.e. starting and ending at the conflicting edge). Using the orientation given to the edges crossed along its way, we get a notion of \"left\" and \"right\" of the curve, which gets \"flipped\" by completely traversing the curve, thus showing that $p^{-1}(C)$ is connected.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/686/combinations-of-selecting-n-objects-with-k-different-types/690\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that I am buying cakes for a party. There are k different types and I intend to buy a total of n cakes. How many different combinations of cakes could I possibly bring to the party?\n\nshare|improve this question\nSeeded question \u2013\u00a0 Casebash Jul 25 '10 at 10:54\nPS. This problem has a really nice proof. I'm pretty hopeful that someone else has seen it posts it \u2013\u00a0 Casebash Jul 25 '10 at 11:23\nWhenever I do this sort of thing, the shop runs out of the cakes I want. \u2013\u00a0 walkytalky Jul 25 '10 at 15:20\nvoting to close--because I'd do so if I saw it as a real question--no indication the asker has thought about the problem first. \u2013\u00a0 Jamie Banks Jul 25 '10 at 19:24\n@Katie: Its a perfectly valid question and I haven't seen a hasn't thought about it close reason on any of the other SO websites (maybe mathoverflow is different though). If you want someone to think about a problem, the best solution is to just not give them the whole solution. For example, show them how you go about proving it and leave out the actual formula \u2013\u00a0 Casebash Jul 25 '10 at 20:54\nshow 3 more comments\n\n3 Answers\n\nup vote 12 down vote accepted\n\nUsing a method that's often called \"stars and bars\":\n\nWe draw $n$ stars in a row to represent the cakes, and $k-1$ bars to divide them up. All of the stars to the left of the first bar are cakes of the first type; stars between the first two bars are of the second type; .\u00a0. .\u00a0.\n\n\nHere's an example with $n=6$ and $k=5$. We're getting 2 of the first type, 3 of the second type, 0 of the third type, 1 of the fourth type, and 0 of the fifth type.\n\nIn order to solve the problem, we just need to reorder the stars and bars by choosing the $k-1$ spots for the bars out of the $n+k-1$ total spots, so our answer is:\n\n$$ \\binom{n+k-1}{k-1}. $$\n\nshare|improve this answer\nExactly what I was looking for \u2013\u00a0 Casebash Jul 25 '10 at 20:51\nNote that $\\binom {n+k-1}{k-1} = \\binom {n+k-1}{n}$ - here the description picks the $k-1$ spots for the bars - equivalently we could pick the $n$ spots for the cakes. \u2013\u00a0 Mark Bennet May 28 '13 at 17:20\nHere is a derivation of your formula using the Polya Enumeration Theorem. \u2013\u00a0 Marko Riedel Oct 28 '13 at 0:42\nadd comment\n\nLet g(n,k) = # combinations of cakes.\n\nNotice that:\n\n  \u2022 g(n,1) = 1. (all the cakes are the same)\n  \u2022 g(n,2) = n+1. (e.g. for 5 cakes, the # of cakes of type 1 can be 0, 1, 2, 3, 4, 5)\n  \u2022 g(1,k) = k.\n  \u2022 g(2,k) = k*(k-1)/2 + k (the first term is two different cakes; the second term is when both cakes are the same), as long as k > 1. (otherwise g(2,1) = 1)\n  \u2022 g(3,k) = k * (k-1) * (k-2)/6 + k*(k-1)/2 * 2 + k (the first term is 3 different cakes; the second term is 2 different cakes, with a *2 since there are two choices for which one to duplicate, the third term is when all 3 cakes are the same), as long as k > 2.\n\nIf we think of k as a radix rather than the # of cakes, then this problem is equivalent to expressing the # of distinct n-digit numbers in base k whose digits are in sorted order. (e.g. 1122399 is equivalent to 9921231)\n\nI think I can express it as a nonrecursive sum:\n\ng(n,k) = sum from j=1 to max(n,k) of { (k choose j) * h(n,j) }\n\nwhere h(n,j) is the # of ways to partition N cakes using j different types. (the term in the sum is when there are j distinct cakes actually chosen.)\n\nBut that's about as far as I can get... :/\n\nedit: looks like it's combinations with repetitions = ((k+n-1) choose n). (same as the wikipedia article with n and k swapped)\n\nshare|improve this answer\nnice solution Jason S............... \u2013\u00a0 juantheron Dec 13 '13 at 3:34\nadd comment\n\nLet's assume you have $n$ items and $k$ bins. You need $k-1$ separators to get the $n$ items into the $k$ bins. There are $(n + k - 1)!$ permutations of ordering $n$ items and $(k-1)$ separators. The permutations of the $n$ items don't matter, and the permutations of the $(k-1)$ separators don't matter, so you'll need to divide by $n!$ and $(k-1)!$\n\nThus you have $$\\frac{(n + k - 1)!}{n!(k-1)!} = \\binom{n+k-1}{k-1}$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/116802/number-of-elements-in-a-ring-with-identity-s-t-x2-1-r-for-all-0-r-neq-x\nText:\nTake the 2-minute tour \u00d7\n\nI'm not sure how to go about finding the solution to this question.\n\nLet R be a ring with identity such that $x^2 = 1_R$ for all $0_R \\neq x\\in R$. How many elements are in $R$?\n\nI've just been playing around with squaring elements, like $$(x+1_R)^2 = x^2+2.x+1_R =2.x+2.1_R = 1_R.$$\n\nBut I'm not sure where to go with this. Any help?\n\nshare|improve this question\nEither $1_R+1_R=0$ or $(1_R+1_R)^2=1_R$ so $3\\cdot 1_R=0$. \u2013\u00a0 Davide Giraudo Mar 5 '12 at 20:15\nadd comment\n\n2 Answers\n\nOne possibility, of course, is $R=\\{0\\}$. Assume $1_R\\neq 0$.\n\n$R$ has no zero divisors: if $xy=0$ and $x\\neq 0$, then $y = 1_Ry = xxy = x(0)=0$.\n\n$R$ is commutative: if $x$ and $y$ are nonzero, then so is $xy$ by the above; hence $(xy)^2 = x^2y^2$; canceling from $xyxy=xxyy$ we get $yx=xy$.\n\n(Of course, the ring satisfies $x^3=x$ for all $x$, so by a famous theorem of Jacobson, the ring is necessarily commutative; but we don't need to call in that heavy cannon to the fray).\n\nSince every nonzero element is invertible, $R$ is a field. Since $x^2-1_R$ has $|R-\\{0\\}|$ solutions, we have $|R-\\{0\\}|\\leq 2$, so $|R|\\leq 3$.\n\nIf $1_R+1_R=0$, then $R$ is of characteristic $2$, so $R\\cong \\mathbb{F}_2$ and $|R|=2$. And, indeed, in this case the hypothesis holds.\n\nIf $1_R+1_R\\neq 0$, then we get $4\\cdot 1_R = 1_R$, hence $3\\cdot 1_R=0$, so $R$ is of characteristic $3$, and therefore $R\\cong\\mathbb{F}_3$ and $|R|=3$. Again, the hypothesis holds for this ring.\n\nIn summary, $R$ has either $1$, $2$, or $3$ elements, and is either the trivial ring, $\\mathbb{F}_2$, or $\\mathbb{F}_3$.\n\nshare|improve this answer\nThanks, this is very helpful, but why does $x^3=x$ imply that $R$ is commutative? \u2013\u00a0 098765 Mar 5 '12 at 20:28\n@098765: It is a common exercise in Ring Theory, and also a consequence of a famous Theorem of Jacobson, which states that a ring for which there exists $n\\gt 0$ such that $x^n=x$ for all $x$ is always commutative. But I gave a simpler derivation that does not call upon such heavy artillery in an edit. \u2013\u00a0 Arturo Magidin Mar 5 '12 at 20:33\n@ArturoMagidin am pleased you revised your answer, because the proof that $x^3 = x$ implies R is commutative isn't trivial, and is probably beyond the stage at which the asker of this question is at. \u2013\u00a0 David Wheeler Mar 5 '12 at 20:53\nDoes your proof actually depend on commutativity? (mine does not). If not, then you can omit the proof of comutativity, since it's a trivial consequence of the final result. \u2013\u00a0 Bill Dubuque Mar 5 '12 at 22:42\n@Bill: I use commutativity only to conclude that I have a field rather than a simply division ring; I believe it is equivalent to your \"$x^{-1}=x\\Rightarrow R$ field\". \u2013\u00a0 Arturo Magidin Mar 6 '12 at 3:54\nadd comment\n\n$\\rm R=0\\:$ works. Else $\\rm\\ x\\ne 0$ $\\Rightarrow$ $\\rm x^2 =1$ $\\Rightarrow$ $\\rm x^{-1} = x $ $\\Rightarrow$ $\\rm R$ field, so $\\rm\\: x\\ne 0\\!\\iff\\!\\! (x-1)(x+1) = 0$ $\\iff$ $\\rm x=\\pm 1.\\:$ But $\\rm\\: R\\backslash0 = \\{\\pm1\\}$ $\\!\\iff\\!$ $\\rm R\\:\\! \\cong\\:\\! \\mathbb Z/2\\:$ or $\\:\\mathbb Z/3$.\n\nMore generally, the finite fields $\\:\\rm\\mathbb F_p,\\: \\mathbb F_q,\\ p,q\\:$ prime, are axiomatized by the ring axioms plus $$\\rm x^n =\\: x,\\quad n\\: =\\: 1 + lcm(p\\!-\\!1,q\\!-\\!1)$$ $$\\rm q\\:(x^p-x)\\: =\\: 0\\: =\\: p\\:(x^q-x)$$ $$\\rm pq\\: =\\: 0$$\n\nThus any identity true in both of these fields has a purely equational proof from the above axioms. This theorem extends similarly to any finite set of finite fields, for example see Stanley Burris and John Lawrence, Term rewrite rules for finite fields (1991). This result is very closely related to Jacobson's model-theoretic proof of commutativity of rings satisfying the identity $\\rm\\: x^{n_x} =\\: x$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/314978/row-and-column-algorithm\nText:\nTake the 2-minute tour \u00d7\n\nLooking for help in revising my algorithm. I need to find one that will give me the row and column of a cell on a grid.\n\nThe grid is $t \\times t$. For example, this is a grid for $t=5$. Now given $n$, find the row and column. $$\\begin{array}{|c|c|c|c|c|} 1& 2& 3& 4& 5\\\\ 6& 7& 8& 9& 10\\\\ 11& 12& 13& 14& 15\\\\ 16& 17& 18& 19& 20\\\\ 21& 22& 23& 24& 25 \\end{array}$$\n\nMy attempt:\n\nrow: $n / t + 1$ column: $n \\bmod t$\n\nSecond attempt:\n\n$\\operatorname{row}(x, t) = ((x-x \\bmod t)/t)+1$\n\n$\\operatorname{column}(x,t) = (x-1) \\bmod t+1$\n\nDoesn't work for $n = t^2$\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe row is :$$r = \\lfloor \\frac{n-1}{t} \\rfloor + 1$$\n\nThe column is:$$c = n - t(r-1)$$\n\nshare|improve this answer\nIf zero indexing were to be used ($0,1,2,\\ldots$ instead of $1,2,\\ldots$) then the answer would look cleaner. $c$ could also be (n-1)%t+1. \u2013\u00a0 adam W Feb 26 '13 at 16:23\nI understand, thank you! \u2013\u00a0 \u041c\u0438\u043a\u0440\u043e\u041f\u0438\u043d\u0433\u0432\u0438\u043d Feb 26 '13 at 16:26\nGlad to hear it, your welcome! \u2013\u00a0 adam W Feb 26 '13 at 16:35\nHi, I have another question. This was just borne out of curiosity. Is there an equation for reflections over diagonals? My attempt only works for the first column down when reflected over the topleft-bottomright diagonal. n - (row - 1)(t - 1) \u2013\u00a0 \u041c\u0438\u043a\u0440\u043e\u041f\u0438\u043d\u0433\u0432\u0438\u043d Feb 26 '13 at 23:14\nThis is a common operation using matrices called the transpose, it is simply the swap of the indices $r\\leftrightarrow c$. If by reflection over diagonals you mean other than the main (top left down to the bottom right), then maybe do some sort of shifting... though that sounds inexact, since any sort of \"reflecting\" would give indices out of bounds... \u2013\u00a0 adam W Feb 26 '13 at 23:36\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70610/hash-functions-and-inner-product?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nHi all,\n\nAs a part of a research I'm working on (involving derandomization of linear threshold functions), I'm trying to understand the following problem:\n\nIs there a small (polynomial rather than exponential) family of hash functions, from [k] to [n] (k much smaller than n, say n^{epsilon}), which guarantee a \"high inner product\" with constant probability for every vector in R^n?\n\n\"high inner product\" should be interpreted as following: The result of the hash function represents a vector in the binary hypercube, with 1 in every bucket which a coordinate of [k] is mapped into, and -1 elsewhere. Given a vector v in R^n, I would like at least a small constant factor of my hash functions to have an inner product which is above the expectation.\n\nIs this possible? Does someone here have an idea for some pointers?\n\nThanks, Guy\n\nshare|improve this question\n\n2 Answers 2\n\n(This should be a comment, but I don't have enough reputation to post a comment.) I have some clarifications regarding the question.\n\n  1. I guess I can think of each hash function as just a $\\lbrace \\pm 1 \\rbrace^n$ vector $u$ with at most $k = n^\\epsilon$ ones. Is this correct?\n  2. Also I don't understand the \"above the expectation\" condition. Why can't you just take two (arbitrary) vectors $u_1$ and $u_2$ with $k$ ones each, and at least one of them will have inner product at least equal to the expectation? Is it important that you strictly exceed the expectation? Do you want a constant fraction to be $\\delta$ more than the expectation for some small $\\delta > 0$?\n\n@Guy: please feel free to use the latex features of this site; it makes reading remarkably easier.\n\nshare|improve this answer\n\nThanks for the answer - this was my first question, and I apologize for not knowing about the latex here.\n\nAbout the comments in the previous post (Srivatsan):\n\n  1. This is correct - I'm trying to build an epsilon net for linear threshold functions, and this would be an important part of it. The \"hash function\" notation looks useful to me, since this reminds me of perfect hashing and similar concepts, where we are looking for some sort of \"independence\" or something similar between hash functions.\n\n  2. Since I'm trying to build a polynomial-size epsilon net, I need my family of vectors (\"hash functions\") to be very small in comparison with the family of all possible vectors, but still have a \"good\" inner product with $every$ other vector (at least for a constant factor of them). So I cannot take $u_1$ and $u_2$ as you ask and take their product, but I'm rather given an arbitrary vector $v\\in\\mathbb{R}^n$, and must find $u$ in my family which achieves a better inner product than the expectation (taken over the choice of any random vector with $k$ coordinates equal to 1).\n\nThanks, and hope this was a little clearer.\n\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/66866/maximum-angular-velocity-to-stop-in-one-rotation-with-a-known-torque\nText:\nTake the 2-minute tour \u00d7\n\nI have an object I can rotate with a given torque. I would like to stop applying torque once I've reached a defined maximum rotational speed. The maximum rotational speed should be defined so that applying maximum torque will stop the rotation of the object within one rotation. If I know my torque and moment of inertia, how can I find the maximum rotational velocity to allow me to stop the object in one rotation?\n\nTime is whatever is needed.\n\nI've tried finding the angular acceleration required to stop the object, but that leaves me with the time variable. Of the equations I've tried, I'm left with a time variable as well as the maximum angular velocity.\n\nshare|improve this question\nWhat approaches have you tried? Where are you hung up with this question? \u2013\u00a0 Jerry Schirmer Jun 2 '13 at 22:04\nI edited the question to give a little details about what I've tried. And it's not homework. More like hobby work. \u2013\u00a0 Byte56 Jun 2 '13 at 22:09\nFor people with similar homework questions: try the equivalent exercise in linear motion. E.g. the direct equivalent here is, given a stopping length L and a force F, what is the maximum velocity v ? You'll quickly spot that you need the second derivative a which you get from F=m*a. \u2013\u00a0 MSalters Jun 3 '13 at 0:00\n\n3 Answers 3\n\nup vote 2 down vote accepted\n\nTo stop the object you must do work. For a constant torque perpendicular to the moment arm, the work it does is equal to $\\tau\\cdot\\Delta\\theta$, and you want $\\Delta\\theta\\leq2\\pi$.\n\nIt should be obvious that the greatest angular velocity that a torque $\\tau$ can stop will take it the full $2\\pi$ radians to stop. In a rotating system, the rotational kinetic energy is given by $E_r=\\frac12I\\omega^2$ (a direct analogue of $E_K=\\frac12mv^2$ ). Now consider work-energy equivalence.\n\nshare|improve this answer\nGreat, I should have taken the energy approach. Been too long since physics. Thanks. \u2013\u00a0 Byte56 Jun 2 '13 at 22:29\nNo problem. J. Lowney has a full-detail solution above - you should check your algebra. A word of advice: on a problem like this, omit your direction signs and only consider magnitudes. Signs will only confuse you and freak you out when you end up with an imaginary angular velocity. \u2013\u00a0 Zen Jun 2 '13 at 22:31\n\nBuilding off of Zen's response, the energy will be $E_r = \\frac{1}{2}I\\omega^2$. The work done in one rotation is $\\tau\\Delta\\theta$. These two terms are equivalent in your case. I.e. you will have the following expression\n\n$$ E_r = \\frac{1}{2}I\\omega^2 = \\tau_\\text{max} \\Delta\\theta$$ $$ \\omega_\\text{max} = \\sqrt{\\frac{2\\tau_\\text{max}\\Delta\\theta}{I}}$$\n\nYou're treating your $\\Delta\\theta$ as $2\\pi$, for one full rotation, hence:\n\n$$\\omega_\\text{max} = \\sqrt{\\frac{4\\pi\\tau_\\text{max}}{I}}$$\n\nWhere $I$ is the moment of inertia of your object. $\\omega$ is the angular velocity. $\\tau$ is your torque.\n\nshare|improve this answer\nThanks for furthering the equation J. \u2013\u00a0 Byte56 Jun 2 '13 at 22:30\nHow would I go about expanding this to use multiple torque values at different positions around the object? \u2013\u00a0 Byte56 Jun 2 '13 at 22:43\nIf you have a function $\\tau(\\theta)$ that gives you torque at every position around the object then simply replace the naive expression for work $W=\\tau\\Delta\\theta$ by $$W=\\int_0^{2\\pi}\\tau(\\theta)d\\theta$$ \u2013\u00a0 Zen Jun 2 '13 at 22:56\n\nAlternative solution:\n\nI see you tried to do it by first finding angular acceleration $\\alpha=\\frac\\tau I$ (where tau is your applied torque). This also works! However I suspect you got stuck at $$\\alpha t=-\\omega_{max}$$ This is perfectly understandable because t is somewhere between 0 and a full period (under the original angular velocity $\\omega$ that is), but you don't know what t is.\n\nYou could try to set up some equations to solve simultaneously for $t$, but that's not necessary because you don't care about $t$, you only care about $\\omega_{max}$ There is another equation you can use, the so-called \"timeless equation\": $$\\omega_f^2=\\omega_o^2+2\\alpha\\Delta\\theta$$ where $\\omega_f$ is final angular velocity, $\\omega_o$ is initial angular velocity, $\\alpha$ is angular acceleration, and $\\Delta\\theta$ is angular displacement (this again is a direct analogue of the linear kinematic equation $v^2=v_0^2+2a\\Delta x$).\n\nLet $\\omega_f=0$ and $\\omega_0=\\omega_{max}$ (i.e., you start out at maximum velocity). By the same reasoning as above $\\Delta\\theta=2\\pi$ and if you know $\\tau$ and $I$ you can find $\\alpha$. Then you have: $$0=\\omega_{max}^2+2\\alpha\\cdot2\\pi$$ $$\\omega_{max}^2=2\\alpha\\cdot2\\pi$$ (again, ignore signs) $$\\omega_{max}=\\sqrt{4\\alpha\\pi}$$ which is the same as above, since $\\alpha=\\frac \\tau I$\n\nshare|improve this answer\nGreat, thanks Zen. \u2013\u00a0 Byte56 Jun 2 '13 at 23:39\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/11737/get-rid-of-tr-in-svm-kernel-trick/11740\nText:\nTake the 2-minute tour \u00d7\n\nI designed a kernel function (to be used within SVM) which has the expression $tr(AB)$ in it. For efficient implementation of this, I was wondering if I could write $tr(AB)$ as an inner product: $\\phi(A)^T \\phi(B)$? What is the function $\\phi()$?\n\nshare|improve this question\nI'm not sure I understand your question (it would help if you eliminated or explained your jargon), but the obvious optimization is that you don't explicitly need to compute AB: tr(AB) is the sum of A_{ij}*B_{ji} over all pairs i,j. You can do this with a single pass over your matrices. \u2013\u00a0 Darsh Ranjan Jan 14 '10 at 9:25\n@darsh you beat me by 3 minutes! I can explain some of the terminology. Imagine you have data in $\\mathbb{R}^d$ (here it seems to be in $\\mathbb{R}^{d\\times d}$??) but want to work with it in $\\mathbb{R}^D$, which you can accomplish by passing everything through a mapping $\\Phi$. If $D \\gg d$, this can be expensive. But in some cases your algorithm need only compute inner products $\\langle \\Phi(a), \\Phi(b)\\rangle$, in which case there may be a functin $k(\\cdot,\\cdot)$ which computes the same thing but with much less work than the explicit mapping. this is called the 'kernel trick'. \u2013\u00a0 Matus Telgarsky Jan 14 '10 at 9:34\nNote that you don't really need the explicit mapping $\\phi$. What you want is a kernel $k(A, B)$ which has the property that $k(A, B) = \\phi(A)^T \\phi(B)$. Generally, you compute the kernel directly, instead of calculating the mapping and computing the dot product -- that's why it's called kernel `trick'. In your case, it seems you want the kernel to be $k(A, B) = tr(AB)$. So it seems you want to know how to compute the trace efficiently, rather than what the mapping is. \u2013\u00a0 user3035 Jan 14 '10 at 10:02\nThe non-efficiency-related part of this question is basic linear algebra: tr(AB) is an inner product on the space of nxn matrices and so you can find isometric isomorphisms from M_{nxn} to R^{n^2}. Any of these will do for the map phi. I do not know whether or not any of these will improve the efficiency in calculating the trace, but I doubt it. \u2013\u00a0 Andrew Stacey Jan 14 '10 at 10:20\nSorry for being ambiguous. I know that I can implement $k(A,B)$ directly and avoid needing $\\phi()$. But it would be nice if I have $\\phi()$ because then, I can use a regular linear SVM on my $\\phi()$ mapped vectors. This is much simpler and faster compared to implementing $k(A,B)$ and plugging it into SVM. \u2013\u00a0 andinos Jan 14 '10 at 21:39\nadd comment\n\n2 Answers\n\nup vote 0 down vote accepted\n\nMatus is right. But if the matrices $A$, and $B$ have certain properties like being symmetric, or diagonal, then simply just vectorizing the matrices and taking their inner product would be equal to the $tr(AB)$.\n\nshare|improve this answer\nadd comment\n\nIf $A,B$ are arbitrary $n\\times n$ matrices, by definition of trace, $\\textrm{tr}(AB) = \\sum_{i,j} A_{ij}B_{ji}$. This is $O(n^2)$, but just reading the entries of $A$ is $\\Omega(n^2)$. Without any special structure on $A,B$, you probably can't do better.\n\nIf $A,B$ are (column) vectors, you probably mean the outer product $\\textrm{tr}(AB^T) = \\sum_i A_i B_i$.\n\nEdit: andinos clarified to say he wants to know about the implicit mapping of the kernel function. Well I have bad news: It does not exist!! The proof works by showing there exist matrices $A,B$ such that the corresponding kernel matrix is not positive semi-definite. To finish, apply Mercer's theorem.\n\nIn particular, set $A = \\left(\\begin{array}{cc}1 & 1 \\\\\\\\ -1 & 1\\end{array}\\right)$ and $B = A^T = \\left(\\begin{array}{cc}1 & -1 \\\\\\\\ 1 & 1\\end{array}\\right)$. Therefore $\\textrm{tr}(AB) = \\textrm{tr}(AA^T) = 4$, and $\\textrm{tr}(BA)$ is identical. On the other hand, $\\textrm{tr}(AA) = \\textrm{tr}(BB) = 0$. therefore, the kernel matrix $K$ is $\\left(\\begin{array}{cc}0 & 4 \\\\\\\\ 4 & 0\\end{array}\\right)$. Set $x = \\left(\\begin{array}{c} 1 \\\\\\\\ -1\\end{array}\\right)$, and observe that $x^T K x = -8 < 0$, and therefore $K$ is not PSD, so the kernel $k(A,B) = \\textrm{tr}(AB)$ is not PSD.\n\nOn the other hand! If you had instead defined your kernel to be $k'(A,B) = \\textrm{tr}(AB^T)$, notice that $k'(A,B) = \\sum_{i,j}A_{ij}B_{ij} = \\Phi(A)^T\\Phi(B)$ where $\\Phi$ simply takes its input matrix and outputs it as a column vector.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/52053/deforming-a-truncated-icosahedron-into-its-circumscribing-sphere\nText:\nTake the 2-minute tour \u00d7\n\nImagine that I have a truncated icosahedron consisted of 60 vertices, each of degree $deg(v) = 3$, and fixed edge length $L$. I'd like to assign some constant curvature or bending angle $\\theta$ to each edge s.t. I can deform the icosahedron into its circumscribing sphere.\n\nAs a function of the edge length $L$, what value of $\\theta$ allows me to properly perform this deformation?\n\nshare|improve this question\nI don't understand how you're using the \"bending angle\" to deform the icosahedron. Are you looking for the angle $\\theta$ that each edge makes with the circumscribing sphere? \u2013\u00a0 anon Jul 17 '11 at 23:49\n@anon, sorry for the confusion! No I'm looking for the bending angle that places each edge on the surface of the sphere. \u2013\u00a0 R.H. Jul 18 '11 at 3:04\nOh, you mean the angle formed by the arc which results from a radial projection of an edge onto the circumscribing sphere. \u2013\u00a0 anon Jul 19 '11 at 12:15\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nFix $L=1$. Then the radius of the circumscribed sphere is $r=\\frac{1}{4} \\sqrt{58+18 \\sqrt{5}} \\approx 2.478$. Now look at the isosceles triangle formed by the center of the sphere and one edge. It has sides of length $r$ and base length 1. So the angles at either end of the base are $\\cos^{-1} (1/(2r)) \\approx 78.3593^\\circ$. The angle between the tangent to the sphere at one endpoint and the edge is then about $11.6407^\\circ$.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Soccer Ball\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166360/vanishing-of-a-certain-improper-complex-integral\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $f,g \\in \\mathbb{C}[z]$ are polynomials with $\\text{deg } g - \\text{deg } f \\geq 2$. Is it true that $\\int_{-\\infty}^{\\infty} e^{iz}f(z)/g(z) dx = 0$, where $z = x + iy$ and $y > \\text{Im}(\\alpha)$ for any root $\\alpha$ of $g$? If so, how does one prove this? By the residue theorem and an easy estimate it follows that this integral does not depend on $y$ as long as it is above all the poles, so perhaps we could exploit this fact?\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nA better way of saying this: $\\displaystyle \\int_L e^{iz} \\dfrac{f(z)}{g(z)}\\ dz = 0$ where $L$ is the line $\\{x+Iy: x \\in {\\mathbb R}\\}$ and $\\text{Im}(\\alpha) < y$ for all roots $\\alpha$ of $g$ .\n\nIt is indeed true. Consider a closed contour $\\Gamma$ consisting of the segment $\\Gamma_1$ of $C$ from $x=-R$ to $x=R$ and the arc $\\Gamma_2$ of the circle of radius $\\sqrt{R^2 + y^2}$ above this segment. Since $|f(z)/g(z)| = O(|z|^{-2})$ as $|z| \\to \\infty$ while $|e^{iz}| = e^{-\\text{Im}(z)} \\le e^{-y}$ on $\\Gamma_2$, and $\\Gamma_2$ has length $O(R)$, the integral over $\\Gamma_2$ goes to $0$ as $R \\to \\infty$. Using Cauchy's Theorem, the integral over $\\Gamma_1$ also goes to $0$, which says $\\displaystyle \\int_L e^{iz} \\dfrac{f(z)}{g(z)}\\ dz = 0$.\n\nshare|improve this answer\nadd comment\n\nConsider closing the contour along a semicircle in the upper half-plane. By assumption there are no poles inside the contour, so the integral over the closed contour must vanish. But the integral over the semicircle vanishes, so the original integral must also vanish.\n\nAddendum: Shift the integral over the semicircle, let $\\zeta = z-iy$, so $\\zeta = R e^{i\\theta}$, where $\\theta\\in[0,\\pi]$. This introduces an unimportant factor of $e^{-y}$. We can now apply Jordan's lemma, which tells us that the absolute value of the integral over the semicircle is bounded by $$\\pi e^{-y} \\max_{\\theta\\in[0,\\pi]} \\left| \\frac{f(Re^{i\\theta}+iy)}{g(Re^{i\\theta}+iy)}\\right|.$$ By assumption, $|f/g| \\sim 1/R^2$ at worst. Therefore, the integral over the semicircle vanishes in the limit.\n\nshare|improve this answer\nWhy does the integral over the semicircle vanish? I don't think this is literally true, although it should tend to zero as the radius grows. \u2013\u00a0 Justin Campbell Jul 4 '12 at 1:39\n@JustinCampbell: Hi Justin, see my edit. In the limit $\\lim_{R\\to\\infty}$ it really does vanish! \u2013\u00a0 user26872 Jul 4 '12 at 2:57\nadd comment\nup vote 0 down vote accepted\n\nMy apologies to the people who have already answered, but I found a way which does not involve any difficult estimates: take a rectangular contour above the poles and let the vertical edges go off to infinity. By Cauchy's theorem the integral around this loop is $0$, and since $$\\bigg| e^{iz} \\frac{f(z)}{g(z)} \\bigg| \\leq \\frac{C}{x}$$ for large $|z|$ (here $C \\geq 0$ is a constant and $z = x+iy$) the integral along the vertical edges tends to zero as $|x| \\to \\infty$. Thus the integral along any two horizontal lines above the poles is equal. But as such a horizontal line $L_y = \\{ x + iy \\ | \\ x \\in \\mathbb{R} \\}$ moves upward (meaning $y \\to +\\infty$) the integral must tend to $0$, since $$\\bigg| e^{iz} \\frac{f(z)}{g(z)} \\bigg| \\leq e^{-y}\\frac{D}{x^2+1}$$ for large $|z|$ and $\\int_{-\\infty}^{\\infty} \\frac{1}{x^2+1} \\ \\mathrm{d}x$ is a constant independent of $y$. Thus $\\int_{L_y} e^{iz} \\frac{f(z)}{g(z)} \\ \\mathrm{d}z = 0$ for any $y$ above the poles.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/49080/to-prove-there-exist-two-relatively-prime-numbers-in-a-finite-set/49115\nText:\nTake the 2-minute tour \u00d7\n\nProve that in any set of $n+1$ positive numbers not exceeding $2n$ there must be two that are relatively prime.\n\nshare|improve this question\nThis is an old problem. Without giving too much away, have you thought about how you could definitely tell that two numbers are coprime? And maybe the bounds you are given may suggest using the pigeonhole principle? I think this is one you should work at before asking it. \u2013\u00a0 Mark Bennet Jul 2 '11 at 20:34\nadd comment\n\n4 Answers\n\nIn some circles at least this is as famous as the question of what is the sum of the first $n$ positive integers. It is often called the Posa Problem, because it was the problem that Erdos asked of the (then) 12 year-old Lajos Posa upon first meeting him. According to Erdos, Posa solved it in about $30$ seconds, all the while eating a bowl of soup. An account of this story is here; there must be a more primary source somewhere.\n\nP.S.: I have some colleagues who work in the branch of mathematics -- additive combinatorics -- for which this result is basically page 1. When I by chance mentioned this problem to one of them, she replied, \"Yes, and there is also one integer which divides another.\" Try that one too!\n\nshare|improve this answer\nadd comment\n\nTwo numbers must be consecutive.\n\nI read this years ago in a book about Erdos. Here's the page.\n\nshare|improve this answer\nYour answer appeared as I was finishing mine up. Indeed, I have read the book you cite (as well as another, similar Erdos biography that came out around the same time). It's interesting to note that the story as it is told in Schechter's book is isomorphic but not identical to the story as it is told in the link in my answer. \u2013\u00a0 Pete L. Clark Jul 2 '11 at 22:55\nadd comment\n\nThrow out the 1, since if it is on your list, then $gcd(a,1)=1$, and you are done. If not, you will necessarily have to choose two numbers in the list that are one unit appart, by the pigeonhole principle. Now show that if you have two consecutive numbers a,a+1, with a>1, your numbers must be relatively prime. (Hint: your linear combination is all-ready for you.)\n\n\nEDIT: It also follows that the sequence contains a pair $(a,b)$ such that $a|b$; we choose the terms to try to avoid a pair (a,b), by choosing $\\{ n,n+2,n+4,...,2n-2\\}$ as WOLG the even terms (i.e., we assume n is even), and $\\{n+1,n+3,...,2n-1\\}$ as the odd terms , so that the smallest multiple (i.e., by 2) of any of the chosen elements is strictly-larger than $2n$ (this shows that n+1 is the best-possible bound). But this only uses up n of the terms in the sequence. So we must choose some term 'b' strictly smaller than $n= \\frac {2n}{2}$. But , since $b<n$, there must be a multiple 'c' of b in the set $\\{n,n+1,....,2n-1\\}$. Then b|c.\n\nTrying to make the argument more precise: basically, given 2n, we argue that if n-k is the largest number in the collection $\\{a_1,..,a_n\\}$ of n+1 elements out of $\\{1,2.,...,2n\\}$, then we must remove some elements to avoid having a pair $(b,c)$ with $b|c$, but the crux is that we must remove \"too many\" elements to avoid having a pair $(b,c)$, after which we cannot have a total of $n-1$ elements in our sequence. Say, e.g., that $n-1$ is the smallest element of our set $\\{a_1,..,a_{n+1}\\}$. Then we have $(2n-(n-1)+1)=n+2$ numbers between $n-1$ and $2n$ to select our sequence of n+1 elements from. But if we select the number b=$n-1$ for our set, we cannot select its multiple c=$2(n-1)$. So we must throw out $2(n-1)$, and we are left with $n+1$. Then we must keep $n=(n-1)+1$ together with $ \\{n,n+1,...,2(n-1)-1,2(n-1)+1,2n\\}$ , to have a total of $n+1$ terms in our sequence. But that means that $n$ and $2n$ will both be in the sequence, and $n|2n$. The argument generalized for $n-k$ being the largest element chosen in $\\{a_1,..,a_n\\}$\n\nshare|improve this answer\nYeah, it becomes pretty easy if excluding 1. \u2013\u00a0 Robert Jul 2 '11 at 21:05\nadd comment\n\nThis follows from the pigeonhole principle. Consider the set of first $2n$ numbers. You can create $n$ subsets of co-primes as $\\{2k-1,2k\\}$ for $1\\leq k \\leq n$. It is easy to see that these will be coprime (their difference is 1, so their GCD is 1). Now you have $n$ pairs of coprimes, and amongst any $n+1$ numbers in this range, atleast two will be a coprime pair.\n\nNote: I have followed the definition to allow $(1,2)$ to be a coprime pair.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192928/optimize-function-lagrange-multipliers/193013\nText:\nTake the 2-minute tour \u00d7\n\nI have a function of 4 variables: (distance function)\n$d(x,x_1,y,y_1 )=(x-x_1 )^2+(y-y_1 )^2$\n\nsubject to 2 constraints:\n1. $g(x,x_1,y,y_1 )=ax^2+2hxy+2gx+by^2+2fy+c=0$\n2. $h(x,x_1,y,y_1 )= a_1 x_1^2+2h_1 x_1 y_1+2g_1 x_1+b_1 y_1^2+2f_1 y_1+c_1=0$\n\nUsing lagrange multipliers, and partial differentiation, what should be the values of $x,x_1,y,y_1$ in terms of $a,b,c,a_1,b_1,c_1,f,g,h,f_1,g_1,h_1$, with aforementioned constraints?\n\nshare|improve this question\nHave you tried writing down the gradients of all functions involved and coming up with an equation for the Lagrange multipliers? \u2013\u00a0 Alex R. Sep 9 '12 at 1:01\nYes I have tried and I have come up with equations. That was the easy part actually, the hard part is to find values of x,x1,y,y1, with which I'm struggling up to now. \u2013\u00a0 David Hoffman Sep 9 '12 at 20:49\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $\\nabla F= \\langle \\partial_x F, \\partial_{x_1} F, \\partial_y F, \\partial_{y_1} F \\rangle$. The method of Lagrange in this case requires the introduction of two multipliers. We should solve:\n\n$$ \\nabla d = \\lambda_1\\nabla g+ \\lambda_2\\nabla h $$\n\nsubject to constraints 1 and 2 as listed in your post.\n\nThe reason for this is as follows: if an extrema exists then curves $t \\mapsto \\alpha(t) $ which pass through the extremal point must make $\\eta=d \\circ \\alpha$ extreme at the corresponding point in the domain. Suppose $t=0$ gives $\\alpha(0)$ the extremal point (we can shift the parameter to make this happen, nothing is lost in this convenience).\n\nThe curve $\\alpha$ lies on the intersection of the level sets given by 1 and 2. We have\n\n$$ g (\\alpha(t)) =0 \\qquad h( \\alpha(t))=0 $$\n\nThe chain-rule yields\n\n$$ \\nabla g (\\alpha(t)) \\cdot \\alpha'(t)=0 \\qquad \\nabla h (\\alpha(t)) \\cdot \\alpha'(t)=0 $$\n\nLikewise, since $\\eta$ is extremal at $t=0$ the chain rule gives\n\n$$ \\nabla d (\\alpha(0)) \\cdot \\alpha'(0)=0 $$\n\nSummarizing, the tangent vector field $\\alpha'$ is orthogonal to the gradient fields of $g$ and $h$ where they can be compared and at $\\alpha(0)$ the tangent $\\alpha'(0)$ is orthogonal to $\\nabla d$. The point $\\alpha(0)$ is special in that we obtain orthogonality with respect to $\\nabla d, \\nabla g$ and $\\nabla h$.\n\nAt first glance this would not appear to connect $\\nabla d, \\nabla g$ and $\\nabla h$ in any particular way. However, there is not just one curve on the constraint surface. Provided the constraints 1. and 2. are nondegenerate the level set they define is two-dimensional and there will be a two-dimensional plane of tangent vectors which are found orthogonal to $\\nabla d, \\nabla g$ and $\\nabla h$. But, this means that $\\nabla d, \\nabla g$ and $\\nabla h$ are linearly dependent since $\\mathbb{R}^4$ should be the direct sum of the tangent and normal space. For these reasons we introduce multipliers to ascertain the location of the max/min solution.\n\nNotice the method is based on the existence of extreme solutions. For the continuous function $d$ these are known to exist if the constraint is a compact surface. Sometimes the method still \"works\" for non-compact constraints, but beware the limit of the method.\n\nshare|improve this answer\nI'm sorry but I can't really understand what you wrote, this math is too advanced for me. Would it be possible to explain this at a high-school level? If not, I will be absolutely ok with it. I just need to know whether a high school student is able to solve this. Thanks. \u2013\u00a0 David Hoffman Sep 9 '12 at 20:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/236495/the-mid-point-rule-as-a-function-in-matlab?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nHow would I go about creating a function in matlab which would calculate the following\n\n$$M_c(f)=h \\sum_{i=1}^N f(c_i)$$\n\n\n$h=\\frac{b-a}{N}, \\\\c_i=a+0.5(2i-1)h,\\\\ i=1,\\ldots,N$\n\nWhat I have tried so far is\n\nfunction(M(f))= composite_midpoint(f)\n\nfor i=1:1:N\n   M(f) = h*(sum + f)\n\nSorry about not inserting the matlab code directly, I'm not sure how to do it.\n\nshare|improve this question\nUpdated the formatting, you can use four spaces in front of each line to show code. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 16:41\nWhat types of 'functions' are you expecting to be able to input for f? Symbolic functions, or matlab functions? \u2013\u00a0 icurays1 Nov 13 '12 at 16:42\nIt would be a function which is smooth enough for Taylor's theorem and one which it's integral can be calculated exactly. \u2013\u00a0 Nicky Nov 13 '12 at 16:49\nYes, but with matlab functions are either .m files or \"symbolic\" functions. Its not going to work the way you have it written if you call it like \"composite_midpoint(x^2)\". It doesn't know what x^2 means. \u2013\u00a0 icurays1 Nov 13 '12 at 16:54\nIf I were to want the function to be x^2 how would I go about altering my code so that it worked for the midpoint rule? \u2013\u00a0 Nicky Nov 13 '12 at 16:59\nshow 1 more comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nFirst run this outside the function:\n\na = 6; \nb = 4.234;\nN = 10;\n\nThen save this function to a file called compositemidpoint.m (in your current directory)\n\nfunction M = compositemidpoint(a,b,N)\nh = (b-a)/N\ni = 1:N\nc_i = a+0.5*(2*i-1)*h\nf = log(c_i) + c_i.^2 % A sample function\nM = h*sum(f);\n\nThen call it by typing:\n\nshare|improve this answer\nIt does not really make sens yet, but this is how i debugged your attempted code to not-crash. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 16:52\nYour code only sums the vector $f$ and multiplies it by $h$. There is no midpoint rule occurring here - you have to create the vector $f$ by evaluating some function at the grid points $c_i$... \u2013\u00a0 icurays1 Nov 13 '12 at 16:56\nI have updated the answer to include an example function. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 17:01\nI tried running this but it wouldn't work. I've put in function out= compositemidpoint at the very begining of the function however it is still coming up with errors. \u2013\u00a0 Nicky Nov 13 '12 at 17:14\nI have included some instructions on how to call it. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 17:22\nadd comment\n\nHere's my solution, which is vectorized (for loops are bad in matlab).\n\nfunction Mf=midpoint_rule(a,b,N,f)\n\n%ci are your evaluation points\n%This evaluates the function f, which is another matlab function\n%you can just add up the vector y and multiply by h\n\n\nFor example, you can save another .m file Myfunction.m, that might look like:\n\nfunction y=Myfunction(x)\n\n%The dot means \"pointwise\"\n\n\nThen, in the main window, you would evaluate the integral by saying \"midpoint_rule(1,2,100,@Myfunction)\". The \"at\" symbol tells matlab you'll be using a matlab function called \"Myfunction\".\n\nshare|improve this answer\nIf you only need your midpoint rule function to run for a couple test functions, you can also hard-code them in by saying \"y=sin(x)\" etc instead of \"y=f(ci)\". But then you would have to change your code every time you have a new function to integrate! \u2013\u00a0 icurays1 Nov 13 '12 at 17:18\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/60426/generating-spaces-of-homogenous-polynomials-in-two-variables?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nConsider the $\\mathbb Z$-module that consists of the polynomials in $\\mathbb Z[x,y]$ that are homogeneous polynomials of degree $d$ in the indeterminates $x$ and $y$ (homogeneous meaning that all terms of the form $c_{ij} x^i y^j$ are such that $i+j = d$, where $d$ is the degree of the polynomial). One can see that there is a unique way of writing an homogeneous polynomial of degree $d$ in the form $$ \\sum_{j=0}^d c_k y^{d-k} \\prod_{i=0}^{k-1} (x-iy) $$ because there is precisely one term where $x$ is at the $k^{th}$ power for any $k$ in the range $[0,d]$, hence we can compute coefficients. Therefore, the polynomials $y^{d-k} \\prod (x-iy)$ form a basis of the $\\mathbb Z$-module.\n\n\nIs it possible to write any homogenous polynomial of degree $d$ in the form $$ \\sum_{k=0}^d c_k \\left( \\prod_{i=0}^{d-k-1} (y-ipx) \\right) \\left( \\prod_{i=0}^{k-1} (x-iy) \\right) $$ where $p$ is a prime number? (The larger context is a number theory context, thus the prime is the thing I need. The fact that $p$ is prime might not be needed to prove this though!) Note that the polynomials formed by the 2 products are actually homogenous polynomials of degree $d$ in $x$ and $y$, so this would be a basis of the $\\mathbb Z$-module of homogenous polynomials of degree $d$.\n\nThe reason for this question is because I am looking for a characterization for a certain class of polynomials that are always 0 with respect to a prime power modulus and the existence of this decomposition would help me very much. =)\n\nIf you have any suggestions please feel free to comment.\n\nshare|improve this question\nOne remark for those who might consider inverting some kind of matrices : the fact that it is easy to generate polynomials when there is no \"$ipx$\" term in the linear factors for $y$ is that you can rewrite this problem in the form of solving a linear equation of the form $AX = Y$, where $X$ and $Y$ are the coefficient vectors and $A$ is the coordinate switch matrix. The \"easiness\" comes from the fact that $A$ is either upper or lower triangular (depending on which way you place coefficients...), hence it is easy to see that $A$ needs to be invertible with integer non-zero determinant. \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 0:51\nRe: Your background question. You do know the classification of single variable polynomials with values (at integer points) vanishing modulo a prime power, don't you? That not-too-well-known result has been rediscovered periodically (Singmaster in '69, Niven & Warren in '57, Carlitz says that it was in Dickson's old book,...) \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 5:56\nYes, I know it, and it is quite simple to read (but took me weeks to prove...). Write $$ f(x) = \\sum_{k=0}^d c_k(x)_k. $$ It is always possible to do this in $\\mathbb Z[x]$. Now note that $f(\\ell) = \\sum_{k=0}^{\\ell} c_k k! \\begin{pmatrix} \\ell \\\\ k \\end{pmatrix}$, hence you can show by induction that $c_k k! \\equiv 0$ $\\mathrm{mod}$ $p^m$ by assuming that $f$ vanishes $\\mathrm{mod}$ $p^m$. Conversely, a polynomial with this property vanishes because $f(\\ell) = \\sum_{k=0}^{\\ell} c_k k! \\begin{pmatrix} \\ell \\\\ k \\end{pmatrix} \\equiv \\sum_{k=0}^{\\ell} 0 = 0.$ \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 7:32\nThe result I had in mind goes as follows. Write $p_k(x)=\\prod_{i=0}^{kp-1}(x-i)$. Then the values $p_k(n), n\\in\\mathbf{Z}$ are always divisible by $(kp)!$, so if you multiply these polynomials with the appropriate power of $p$ you get polynomials with values vanishing $\\pmod{p^\\ell}$. If you take such polynomials up to the first monic one, you have a generating set for the ideal of polynomials in $\\mathbf{Z}[x]$ that vanish module $p^\\ell$. \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 7:55\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nI don't think that you have a $\\mathbf{Z}$-basis. I claim that if $d>1$, then all the polynomials $q(x,y)$ in the $\\mathbf{Z}$-span of your generators have the property $p-1\\mid q(1,1)$. Thus, if $p>2$ the span cannot consist of all the homogeneous polynomials of degree $d$.\n\nProof: If you evaluate the polynomial $$p_k(x,y)=\\prod_{i=0}^{d-k-1}(y-ipx) \\prod_{i=0}^k(x-iy)$$ at $x=y=1$, the second product shows that $p_k(1,1)=0$ unless $k=0$ (if $k>0$, then the factor $x-y$ coming from $i=1$ makes this happen). But if $k=0$ and $d>1$, then the first product has a factor $y-px$ (again coming from $i=1$), and this forces $p_0(1,1)$ to be divisible by $y-px\\vert_{(x,y)=(1,1)}=1-p$. For all $k$ we have $p-1\\mid p_k(1,1)$, so the same holds for all the $\\mathbf{Z}$-linear combinations of the polynomials $p_k(x,y)$.\n\nshare|improve this answer\nGiven that $p-1$ is a unit in your eventual ring this may not ruin your approach, but it does seem to settle the question over $\\mathbf{Z}$. \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 6:10\nI am a little confused by your argument because there are many assumptions along the way... but maybe it's clear and I should read this tomorrow XD But in my ring, $p-1$ is indeed a unit, so I think that if you're right there is still work to do, and I would be really pissed to find out that it's not possible to do this... \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 7:36\nFor your curiosity : I have shown a few hours ago (heehee) that for $f(x,y)$ homogeneous of degree $d$ and $m \\le p$, vanishing mod $p^m$ is equivalent to be able to write it in the following form : $$ f(x,y) = \\sum_{j=0}^{m} \\left( \\left( p^{m-j} y^j \\prod_{i=0}^{jp-1} (x-iy) \\right) \\gamma_j (x,y) \\right) $$ where the $\\gamma_j(x,y)$'s are homogeneous polynomials of degree $d-j(p+1)$ that can be arbitrary. When working on these kind of vanishing question, understanding what happens up to $p^p$ and then moving to $p^{p+1}$ and $p^{p+2}$ in a clever manner is the key point. \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 7:38\n@Patrick: I made an attempt to make the structure of my argument clearer. \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 10:18\nOkay, so $p-1 | q(1,1)$. So since for instance $x^2$ (or $x^d$ for generality) is such that $p-1 \\nmid q(1,1) = 1$, we're done. =) Thank you! \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 14:38\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/45245/does-closing-curtains-make-your-home-warmer?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI mean, in the sense that the act of closing curtains would somehow reduce the amount of heat loss of the house to the outside, thus making it warmer for a given supply of heating.\n\nshare|improve this question\nWhy don't you experiment? In many cases (especially if the window is large and/or single glazed and the drapes are heavy and over-sized) just standing next to the window in a pair of shorts is enough to feel the difference on the skin of your legs. \u2013\u00a0 dmckee Nov 27 '12 at 22:28\nadd comment\n\n3 Answers\n\nup vote 6 down vote accepted\n\n1, you live somewhere that is colder outside than in\n2, the curtain has finite thermal resistance (ie some insulating value)\n3, the curtain is close enough to the window to reduce convection\n\nThen yes.\nTry measuring the air temperature on the window side of the curtain, it should be lower than the room.\n\nshare|improve this answer\nCurtains will also block infrared radiation ( which is heat) through the window, not only block convection. \u2013\u00a0 anna v Nov 28 '12 at 12:40\n@annav, just worked it out at 90W/m^2 for room temp to freezing (assuming perfect BB) not negligble ! \u2013\u00a0 Martin Beckett Nov 28 '12 at 16:42\nadd comment\n\nTo some extent, the answer is yes; however, considering the characteristics of a curtain, the amount of heat conservation is negligible.\n\nshare|improve this answer\nEr...good curtains constrain convection more than they provide conductive insulation and they work better then you seem to appreciate. As I said above, under the right circumstances the only instrument you need to detect the effect is your skin. \u2013\u00a0 dmckee Nov 27 '12 at 23:09\nThis was my brain-block too: I had forgotten convection. \u2013\u00a0 user12345 Nov 28 '12 at 12:04\nadd comment\n\nIf the inside surface of the window is colder than the air in your room then the room will lose heat to the window. If this is the case then curtains will reduce the heat loss in exactly the same way that putting on clothes reduces the heat loss from your body.\n\nDouble glazing reduces the heat loss from windows, but even so a quick measurement in my living room suggests the inside surface of my (double glazed) window is colder than the rest of the room so curtains will make a difference.\n\nBut don't draw the curtains during the day because if the Sun is shining you'll get greenhouse heating of your room. If you draw the curtains the sunshine will heat the curtains, but they'll tend to keep hot air near the window where the heat can conduct outwards.\n\nI did the experiment!\n\nIf anyone is still interested, I got up early this morning before the heating was on to measure the temperatures.\n\nMy living room has a window at each end, and I closed the curtains on one window and left the curtains open on the other window to act as a control. At 06:30 this morning the temperature in the room was 6\u00baC. When I placed the thermometer about a mm away from the uncurtained window the temperature was 5\u00baC, and 1 mm away from the curtained window (i.e. inside the curtains) the temperature was 2\u00baC. The temperature outside is about zero because there was a frost - I didn't go outside to measure it because it was too cold. Ask Francis Bacon about the dangers of such experiments :-)\n\nSo with the curtains closed the temperature at the window was 3 degrees lower showing that the curtains have a significant insulating effect. These are regular curtains, not especially heavy, so it's quite a big effect. I suspect it's not the thermal properties of the curtains that matters, but instead it's their ability to stop air currents from circulating cold air at the window into the rest of the room.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/297881/find-two-closest-points-on-two-functions\nText:\nTake the 2-minute tour \u00d7\n\nWe have two functions:\n\n$$\\begin{align*} y &= x^4-5x^3+2x^2-5 \\\\ y &= -11x-20 \\end{align*}$$\n\nMy task is to find two closest points that can be found on these two functions.\n\nCan somebody give any hints on how to solve these type of exercises?\n\nThank you!\n\nshare|improve this question\nDo you mean the closest points of the curves, or the minimum difference between the two functions? \u2013\u00a0 copper.hat Feb 8 '13 at 8:17\nThe minimum difference between the two functions. :) \u2013\u00a0 Trom Feb 8 '13 at 8:23\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nYou want to minimize $x^4-5 x^3+2 x^2+11 x+15$. Take the derivative, set that to $0$, and solve. Unfortunately this is an irreducible cubic, so the solutions are not very nice. There are three real roots: approximately $-.6828742578$, $1.275428188$, $3.157446070$. I'll leave it to you to find which of these gives the minimum.\n\nshare|improve this answer\nadd comment\n\nSince you want the minimum difference between $$\\begin{align*} y_1(x) &= x^4-5x^3+2x^2-5 \\text{ and }\\\\ y_2(x) &= -11x-20 \\end{align*}$$ you are looking for the minimum of $$ \\left| y_1(x) - y_2(x) \\right|$$ which will be a max / min of $$ z(x) = y_1(x) - y_2(x).$$ So write down the equation for $z$ as Robert Israel has done for you, differentiate $z$ and find its turning points.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/189224/defective-items-probability-question/189248\nText:\nTake the 2-minute tour \u00d7\n\nHi I'm working with probability as part of an engineering course, and I'm struggling with the following tutorial question: Components of a certain type are shipped to a supplier in batches of ten. Suppose that 50% of all such batches contain no defective components, 35% contain one defective component while 15% contain two defective components. If two components are randomly selected from the batch. What are the probabilities associated with 0, 1 and 2 defective components being in the batch under each of the following conditions? a) Neither selected component is defective. b) One of the two components is defective. c) Both components are defective.\n\nI've considered using hypergeometric probability distribution for events P(35%) and P(15%) while comparing to P(50%) but this yields no result.\n\nshare|improve this question\nHave you learned about the law of total probability? I would suggest that you try and solve the simpler problem of one item being selected at random from a randomly selected batch and finding the probability that it is defective, and then tackle the problem of two items. By the way, since this looks like homework, please add the homework tag. \u2013\u00a0 Dilip Sarwate Aug 31 '12 at 11:48\nadd comment\n\n2 Answers\n\nLet $B_0$ be the event that the batch has $0$ defectives, $B_1$ be the event the batch has $1$ defective, and $B_2$ be the event the batch has $2$ defectives.\n\nLet $D_0$ be the event that neither selected component is defective. Problem (a) asks us to find the conditional probabilities $\\Pr(B_0|D_0)$, $\\Pr(B_1|D_0)$, and $\\Pr(B_2|D_0)$. Now the hardest part, identifying precisely what we are after, has been done!\n\nFor the calculation, we use the general conditional probability formula $$\\Pr(X|Y)\\Pr(Y)=\\Pr(X\\cap Y).$$ Put $X=B_0$ and $Y=D_0$. We need $\\Pr(D_0)$ and $\\Pr(B_0\\cap D_0)$.\n\nThe event $D_0$ can happen in three different ways: (i) Our batch of $10$ is perfect, and we get no defectives in our sample of two; (ii) Our batch of $10$ has $1$ defective, but our sample of two misses them; (iii) Our batch has $2$ defective, but our sample misses them. If it helps, draw a tree that shows the three different paths through which we can end up with no defectives.\n\nFor (i), the probability is $(0.5)(1)$. For (ii), the probability that our batch has $1$ defective is $0.35$. Given that it has $1$ defective, the probability that our sample misses it is $\\binom{9}{2}/\\binom{10}{2}$, which is $8/10$. So the probability of (ii) is $(0.35)(8/10)$. For (iii), the probability our batch has $2$ defective is $0.15$. Given that it has $2$ defective, the probability that our sample misses both is $\\binom{8}{2}/\\binom{10}{2}$, which is $56/90$. So the probability of (iii) is $(0.15)(56/90)$. We have therefore found that $$\\Pr(D_0)=(0.5)(1)+(0.35)(8/10)+(0.15)(56/90).$$ The probability $\\Pr(B_0\\cap D_0)$ has been calculated during our calculation of $\\Pr(D_0)$. It is $(0.5)(1)$. We conclude that $$\\Pr(B_0|D_0)=\\frac{(0.5)(1)}{(0.5)(1)+(0.35)(8/10)+(0.15)(56/90)}.$$ The rest of the calculations for $D_0$ are easy, we have all the information needed. We get $$\\Pr(B_1|D_0)=\\frac{(0.35)(8/10)}{(0.5)(1)+(0.35)(8/10)+(0.15)(56/90)}$$ and $$\\Pr(B_2|D_0)=\\frac{(0.15)(56/90)}{(0.5)(1)+(0.35)(8/10)+(0.15)(56/90)}.$$\n\nAlternately, we could have used Bayes' Formula directly . I wanted to do it in the above more basic way so that the logic would be clear.\n\nNow unfortunately we have to deal with (b) and (c). But (c) is trivial! For (b), the calculation is as above, a little simpler, because if our sample of two has a defective, it cannot come from a perfect batch.\n\nshare|improve this answer\nAndr\u00e9, how is your calculation not a use of Bayes' formula, since you are simply replacing $P(D_i)$ in the expression $$P(B_j \\mid D_i) = \\frac{P(B_j \\cap D_i)}{P(D_i)}$$ by its value as obtained via the law of total probability? In over 35 years experience teaching probability to recalcitrant engineering undergraduate students, I have always tried to emphasize the formulation that you have used, pointing out that the numerator term is one that is computed as part of the denominator and thus need not be calculated again: cf. your \"The probability $P(B_0\\cap D_0)$ has been calculated during \" \u2013\u00a0 Dilip Sarwate Aug 31 '12 at 13:25\nIt is certainly absolutely the use of the Bayes' Formula idea. just going back one little step. (Before the divorce of Math and Stat, I used to teach the standard probability and statistics for engineers pretty often. One has to do a delicate balance between ideas and cookbook.) \u2013\u00a0 Andr\u00e9 Nicolas Aug 31 '12 at 13:37\nThanks a lot, this answer is making sense too now, this stuff isn't so bad if you really start understanding it. Thank you \u2013\u00a0 Tertius Aug 31 '12 at 14:01\nadd comment\n\nTry using Bayes' theorem: $$P(A|X) = P(X|A) \\dfrac{P(A)}{P(X)}$$\n\nFor instance, let event $A_m$ be \"there are $m$ defective components in the batch\" and let event $X_n$ be \"$n$ of the selected components are defective\". Then we have the given marginal probabilities for $A_m$:\n\n$$\\begin{aligned} P(A_0) &= 0.5 & P(A_1) &= 0.35 & P(A_2) &= 0.15 \\end{aligned}$$\n\nand the conditional probabilities for $X_n$ given $A_m$:\n\n$$\\begin{aligned} P(X_0|A_0) &= 1 & P(X_0|A_1) &= \\frac45 & P(X_0|A_2) &= \\frac{28}{45} \\\\ P(X_1|A_0) &= 0 & P(X_1|A_1) &= \\frac15 & P(X_1|A_2) &= \\frac{16}{45} \\\\ P(X_2|A_0) &= 0 & P(X_2|A_1) &= 0 & P(X_2|A_2) &= \\frac1{45} \\end{aligned}$$\n\n(Exercise: Why those probabilities? It's just a simple case of sampling without replacement.)\n\nFrom the conditional probabilities, we can also calculate the marginal probabilities for $X_n$ using the law of total probability:\n\n$$\\begin{eqnarray} P(X_0) &= 1\\cdot0.5 &+& \\frac45\\cdot0.35 &+& \\frac{28}{45}\\cdot0.15 =& \\frac{131}{150} =& 0.87333\\dots \\\\ P(X_1) &= 0\\cdot0.5 &+& \\frac15\\cdot0.35 &+& \\frac{16}{45}\\cdot0.15 =& \\frac{37}{300} =& 0.12333\\dots \\\\ P(X_2) &= 0\\cdot0.5 &+& 0\\cdot0.35 &+& \\frac{1}{45}\\cdot0.15 =& \\frac{1}{300} =& 0.00333\\dots \\\\ \\end{eqnarray}$$\n\nNow apply Bayes' theorem to get the conditional probabilities $P(A_m|X_n)$.\n\nshare|improve this answer\nThanks man, just went to see my lecturer about this problem. He confirmed everything you've said. Nice answer. \u2013\u00a0 Tertius Aug 31 '12 at 13:47\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mechanics.stackexchange.com/questions/2668/02-trailblazer-with-front-end-vibration-which-seems-to-increase-over-time?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nAbout a month ago my trailblazer developed this new features. When you get into the car and start driving, everything feels completely fine. Then after about 5 minutes you start noticing slight vibration (very slight, just feels like something isn't quite right). After about a 20 minute drive, the vibration is very noticeable. By that time, it almost sounds like low engine rumble, but its pitch and volume vary directly with car's speed, not engine speed. When it gets to that level, it is also easily felt in the steering wheel.\n\nThree weeks ago, I jacked the car up and noticed that there was a ton of grease spewed around passenger side CV boot. So I went through the motion, which took a while for various reasons, of replacing passenger CV shaft and while in there, also rebuilt 4WD disconnect with fresh bearings and seals. Yesterday I put the car back on the road and the vibration is still in there unchanged.\n\nI tugged on both wheels to check wheel hubs and at first glace the wheel bearings appear fine. I've had bad wheel bearings on this car before, left one is 5 years old. right one is 1 year old. Whenever wheel bearings were bad a) vibration would be constant through out the drive (i.e. you can feel it the second you start driving) and b) they would change in sound when turning left or right.\n\nThis current vibration is... 1) unaffected by turning left/right or going straight 2) does not change in sound if 4wd is engaged or disengaged 3) unaffected by putting the car in neutral and revving the engine\n\nI also checked the front differential fluid level (obviously destroying the fill plug in the process) and topped off the oil level. It was a little low, but no where near empty.\n\nAny ideas what would be causing it?\n\nUPDATE: Drove the car to work today. I have to take back (1) from above. If I turn the steering wheel right, vibration becomes stronger and if I turn left it gets weaker, which is actually consistent with driver's side wheel bearing being bad. The difference is that with my previous bad bearings, I only had to apply slight pressure to the steering wheel to hear sound difference, but this time, I have to push the steering wheel a bit further out (can still hear difference in a single lane going straight). Also the vibration this time seems to be distinctly lower pitch than the ones I've heard in the past with wheel bearings, but maybe they come in different shapes and sounds?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nI also have a AWD Trailblazer, and low diff oil can cause uneven gear wear (mine is perennially low because I have a leaking diff seal which the dealer can't get out). As the oil heats up, the vibration can become more prominent because the thick oil is no longer damping the vibration.\n\nYou may also want to check that your wheels are balanced. You might have chucked a wheel weight or worn a tire unevenly. But, the noise you describe (through the steering wheel) definitely sounds to me like a worn front diff.\n\nshare|improve this answer\nNick, although I appreciate a response, that is sooooo not what I wanted to hear :). Stupid TB. I did have the same suspicion, that' why I topped off the fluid, but I can't say it was that low. And btw, I did also notice that the differential pinion seal is leaking oil on my car as well. Stupid TB. \u2013\u00a0 DXM Jan 16 '12 at 20:44\nadd comment\n\nIt was driver-side wheel bearing.\n\nI've had 4 other bad wheel bearings (2 in this car, 1 in wife's BMW 330i and 1 in my old Integra) and they've always sounded the same. Smooth, mid- to high-pitch vibration which almost disappears when you turn the wheel one way or another.\n\nWhat confused me was this noise was much rougher (like I said in original question, almost low engine rumble) and at first it happened at any steering wheel angle. Past few days I did notice change in pitch/volume when moving the steering wheel but it wasn't like that at first.\n\nOne clue that told it it was probably a wheel bearing was after I came home few days ago, I felt the rims and driver side was significantly warmer than passenger side, which I would guess caused by extra friction in the bad hub.\n\nNow the car is back on the road and feels as smooth as butter.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247312/what-are-the-solutions-to-z41-0/247387\nText:\nSign up \u00d7\n\nI can't seem to find the solutions to $z^4+1=0 $. $z$ is in the complex plane.\n\nThe solutions show four roots; however, how do I find them once $z^4 = -1$?\n\nshare|cite|improve this question\nCan you find one? Do you know geometrically (in polar coordinates) what happens to a complex number $z$ when raised to power $n$? In the solution, basically you will draw a square in the unit circle. \u2013\u00a0 Berci Nov 29 '12 at 15:31\nDo you know the magic factorization $z^4+4=(z^2-2z+2)(z^2+2z+2)$? From this you can get what you\u2019re seeking. \u2013\u00a0 Lubin Nov 29 '12 at 17:10\nAfter answering, I realized I had already answered the same question, not too long ago. Duplicate of:\u2026 \u2013\u00a0 mrf Nov 29 '12 at 22:53\nNote: I think it is more appropriate to say \"find the solutions to $X$\" when $X$ is an equation; and \"find the roots of $X$\" when $X$ is a polynomial. \u2013\u00a0 Pedro Tamaroff Nov 29 '12 at 23:39\n\n5 Answers 5\n\nYou can write $z^4=-1$ as $(z^2)^2=-1$. The two square roots of $-1$ are $i$ and $-i$, so we get the two equations $z^2=\\pm i$.\n\nSince $i$ corresponds to $\\pi/2$ on the unit circle, its square root will have to correspond to $\\pi/4$ (or use De Moivre if you don't see this). So $$ z=\\pm\\frac{1+i}{\\sqrt 2},\\ \\ z=\\pm\\frac{1-i}{\\sqrt 2} $$ are the roots.\n\nshare|cite|improve this answer\n\nYou can write $-i$ in polar form: $$-i = e^{i \\cdot 3 \\pi /2} $$\n\nThen to find a fourth root...\n\nshare|cite|improve this answer\n\n$$z^4=-1=e^{\\pi i+2k\\pi i}=e^{\\pi i(1+2k)}\\Longrightarrow z=e^{\\frac{\\pi i}{4}(1+2k)}\\,\\,,\\,k=0,1,2,3$$\n\nshare|cite|improve this answer\n\nSince we have $i^2=-1$ $$z^4+1=(z^2)^2-(i)^2$$ $a^2-b^2=(a-b)(a+b)$, so we can factor to have $$z^4+1=(z^2)^2-(i)^2=(z^2-i)(z^2+i)$$ It's easy to solve from here on. $$z^4+1=0 \\implies \\left \\{ \\begin{align}&z^2-i=0\\implies z=\\pm\\sqrt i \\\\&z^2+i=0 \\implies z=\\pm\\sqrt{-i}\\end{align}\\right.$$\n\nUsing the properties\n\n  \u2022 $i=e^{i(\\pi/ 2)}$\n  \u2022 $-i=e^{i(3\\pi/ 2)}$\n  \u2022 $e^{i\\theta}=\\cos \\theta + i\\cdot \\sin \\theta$\n\nyou can express the result in much more interesting forms.\n\nshare|cite|improve this answer\n\n$$z^4+1 = (z^2+1)^2-2z^2 = (z^2+1-z\\sqrt2)(z^2+1+z\\sqrt2)$$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/30720/ned-velocity-to-redshift-conversion\nText:\nSign up \u00d7\n\nI've done some search with the Nasa Extragalactic Database (NED) and I have a very basic question about the velocity/redshift conversion. For example, for the first object of this page, we have $v=19791km/s$ and $z=0.066016$.\n\nIf we use the simple formula $z=v/c$, we find the result of the database : $19791/299792=0.0660157709345$. But now if we use the formula : $z = \\sqrt{\\frac{c+v}{c-v}}-1$ we find $0.0683461749892$\n\nWhich is the correct one and why ?\n\nThank you very much.\n\nshare|cite|improve this question\nI suspect that the velocity formula must incorporate the expansion of the Universe. I'm not sure though: I wouldn't expect it to be a ~3% effect at that redshift. \u2013\u00a0 Warrick Jun 25 '12 at 11:29\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe simple formula is just the first-order expansion of the more complicated one about $v = 0$, the latter being exact for the Doppler effect of motion purely along the line of sight. The $v$ here refers to the peculiar motion of the galaxy.\n\nBe aware that for all but the very nearest galaxies, the observed redshift comes almost entirely from the expansion of the universe, not from relative motion in the special-relativistic sense. Thus converting from redshift to velocity using either of the formulas mentioned, though a very common practice, can be misleading. For a thorough albeit technical discussion of subtleties related to this point, there is a paper by Davis and Lineweaver.\n\nEdit: Since I have lately been using NED a lot, I came across this page in their documentation. Point 1 in particular notes that \"no relativistic correction is applied\" and so you may see \"velocities in excess of the speed of light.\" (It also says $v = z/c$, but I hope that's just a typo.) There are two important points here. The first is that you can safely assume the values reported are redshift times the speed of light, possibly with a correction to a certain reference frame. The second is that even NASA is under the misconception that redshift of distant galaxies has something to do with Doppler shift, when this is just fundamentally false. The quantity $zc$ is really just a way of putting units to redshift, nothing more.\n\nshare|cite|improve this answer\nActually, now that you mention Davis & Lineweaver - there's another article (popular one) where Davis explains how Doppler and expansion redshifts are perfectly equivalent, it is really just a matter of one's choice of descriptive language. The real misconception is that superluminal speeds are not possible. Special Relativity only applies locally, and over the distances covered by a redshift of 1.4 (which, IIRC, is where expansion goes superluminal), this is no longer a good approximation. \u2013\u00a0 Thriveth Mar 24 '14 at 14:08\n\nThere are different formulas that give better approximations depending on the velocity distribution, and overall velocity magnitude. Suggest looking at :\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247855/strictly-convex-inequality-in-lp\nText:\nSign up \u00d7\n\nLet $1<p<\\infty$. Let $x,y\\in l^p$ such that $||x||_p=1$, $||y||_p=1$ and $x\\neq y$. Would you help me to show that for any $0<t<1$, $||tx+(1-t)y||_p<1$.\n\nMy answer : By using Minkowski inequality, we get $||tx+(1-t)y||_p\\leq t||x||_p+(1-t)||y||_p=t+(1-t)=1$. But I don't get the strict inequality.\n\nBut, For $p=2$: \\begin{eqnarray} ||tx+(1-t)y||_2^2&=&t^2||x||_2^2+(1-t)^2||y||_2^2+2t(1-t)\\Re(<x,y>)\\\\&=&1+2t(1-t)(\\Re(<x,y>)-1)) \\end{eqnarray}\n\nSince $x\\neq y$ and $||x||_2=||y||_2$, we conclude that $x\\neq ky$ for every scalar hence we get $\\Re(<x,y>)\\leq|<x,y>|<||x||_2||y||_2=1$. So, $||tx+(1-t)y||_2<1$.\n\nThanks everyone.\n\nshare|cite|improve this question\n\n1 Answer 1\n\nFor $1 < p < \\infty$, Minkowski's inequality is an equality if and only if one of the vectors is a multiple of the other by a nonnegative scalar.\n\nshare|cite|improve this answer\nIf the vectors is multiple of the other by scalar implies the equality is trivial. How about the converse? \u2013\u00a0 beginner Nov 30 '12 at 6:43\nYou can go back over the proof of Minkowski's inequality, and H\u00f6lder's which is usually used in that proof. At some point you may use something like the fact that the minimum of the function $f(x) = x^p/p - x$ for $x \\ge 0$ is at $x=1$. Now note that this is a unique minimum ($f$ is strictly convex)... \u2013\u00a0 Robert Israel Nov 30 '12 at 8:20\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/17801/approximation-property\nText:\nTake the 2-minute tour \u00d7\n\nIt seems to be a folk result that l_infinity has the approximation property, even the bounded approximation property, and also, I think, even the so-called propery pi (approximation property) of Lindenstrauss.\n\nThis is alluded to in a few texts, but I cannot seem to find the proof, which is presumably obvious.\n\nDoes anyone have a reference or an easy solution?\n\n\nR. Fry\n\nshare|improve this question\n\n1 Answer 1\n\nPartition the measure space into finitely many sets and consider the span of their indicator functions. This space is isometrically isomorphic to $\\ell_\\infty^n$ for appropriate $n$ and hence is the range of a norm one projection. Index the partitions by refinement to get a net of norm one finite rank projections that converge strongly to the identity.\n\nshare|improve this answer\nDear Prof Johnson, Thank you for the fast response. I am co-supervising a Masters student who needed an answer quickly so he could include it in his thesis which is to be handed in tomorrow! Cheers, \u2013\u00a0 Robb Fry Mar 11 '10 at 4:19\n\nYour Answer"}
{"text": "Retrieved from http://stackoverflow.com/questions/784533/reverse-that-math-function\nText:\nTake the 2-minute tour \u00d7\n\nI need to reverse a function with hard Math operations, I'm asking here to check if it's even possible, eventually for help.\n\n    public static UInt32 Func_4(UInt32 P, UInt32 X, UInt32 G)\n        UInt64 result = 1;\n        UInt64 mult = G;\n        if (X == 0)\n            return 1;\n        while (X != 0)\n            if ((X & 1) != 0)\n                result = (mult * result) % P;\n            X = X >> 1;\n            mult = (mult * mult) % P;\n        return (UInt32)result;\n\nBy \"Reversing\" I mean this: I know G, I know P, I know the result. I need X.\n\nI tried to translate it again this morning while my mind was clear, but I failed. Is it even possible?\n\nThank you in advance.\n\nshare|improve this question\nWhat are your expected inputs to the inverse? Which of P, X, and G are you looking to get back? \u2013\u00a0 Ben Alpert Apr 24 '09 at 4:34\nIt would help if you show the algorithm you hope to do. Also, if you know the result and don't know X, then why pass in X? Pass in the result as a parameter. \u2013\u00a0 James Black Apr 24 '09 at 4:38\nJames: I think he has r = f(p, x, g) and wants a function x = h(p, r, g). \u2013\u00a0 Ben Alpert Apr 24 '09 at 4:40\n@Ben,I need X. @James,X by default is random everytime you use the whole algoritm.I need to get that random number always.I know the other two,they are static.I also know the result.I have to reverse that function and then put the result and the other two parameters I know to get X. \u2013\u00a0 Ivan Prodanov Apr 24 '09 at 4:41\nWhat does the function compute? Let's start there. :) \u2013\u00a0 JP Alioto Apr 24 '09 at 4:45\n\n6 Answers 6\n\nup vote 20 down vote accepted\n\nIt looks like your Func_4() function calculates GX mod P. What you're asking for is a solution to the discrete logarithm problem, but no efficient algorithm is known.\n\nshare|improve this answer\nHowever, if the poster does solve this problem, I've got this RSA system I'm trying to break... \u2013\u00a0 Stefan Kendall Apr 24 '09 at 5:05\nthe \"mod\" is the problem. You won't break this ever. 5 mod 2 has the same result as 7 mod 2 and 9 mod 4 and so on. You can't determine the input based on the output. There is an infinity of input combinations that result in the desired output. Go to sleep. \u2013\u00a0 Andrei R\u00eenea Apr 24 '09 at 21:09\nExactly. You're not supposed to get X. You're supposed to check whether the client knew the correct x by sending it different G and P, and check if their results agree with yours. But at no point is x supposed to be transmitted. \u2013\u00a0 Tim Lin Apr 29 '09 at 15:20\n\n\nworking through this by hand for:\n\nP=5, X=0b0000 1110, G=7\n\nP=5, X=0b0001 1110, G=7\n\nP=5, X=0b0011 1110, G=7\n\nP=5, X=0b0111 1110, G=7\n\netc, i think you see the pattern\n\nall have the same return value for result (4)...\n\ntherefore any attempt to reverse this to get a value for X would have multiple possible values for X..\n\ndepending what you actually need out of this thing, this may not really matter...\n\nwhats the context of this thing?\n\nshare|improve this answer\n\nSince the modulo operator is in play, you can tell immediately that the function is not bijective: for a fixed P and G, different x's may return the same result.\n\nBut the function is bijective for a limited domain of x. Just like atan, asin, sqrt, .... produce a whole set of values, when you limit the domain, you can pick the correct one.\n\nAt first sight, what the function does, for a very large P, is,\n\nThe product of G(2i*x[i]), where x[i] is the i'th bit of x (starting with bit 0 as least significant).\n\nThis means that given a large P (larger than Prod(G2i), for x=0x1111...111), you can reverse the function. It also seems that the function was designed not to be reversible for smaller P's.\n\nshare|improve this answer\n\nIt looks like i = (g**x) mod p. That means there may be more than one x\n\nshare|improve this answer\nYeah,X = X << 1 ,everytime you step the loop. Does that mean its impossible? \u2013\u00a0 Ivan Prodanov Apr 24 '09 at 4:45\nNot impossible, just that there are multiple answers (and not due to the << but due to the %). Is this fast enough for you?... x=0; do { if (Func_4(P,x,G)==I) then return x; x++; } while (x!=0); \u2013\u00a0 Doug Currie Apr 24 '09 at 14:54\n\npseduo algorithm\n\nR = pow(G,X) mod P\n\nie) there exists one Q which is R + P * Q = pow (G,X)\n\nIn reverse, Check Y for all Q from 0 to UINT32((MAXUINT32-R)/P),\n\nY = log ( R + P * Q ) / log (G)\n\nand if the value Y does not have fractions, then they are the Set of multiple \"X\" answers to your problem.\n\nAssume X1 is the first X value which does not have fractions and X2 is the second X Value which does not have fractions. Then Set of all X can be given in the equation X(S) = X1 + (X2-X1) * S where S=0 to UINT32( (MAXUINT32-X1) / (X2-X1) ).\n\nThat is due to if 1= Pow(G,T) mod P and then Pow(G,X+T) mod P = Pow(G,X) mod P * Pow(G,T) mod P which is also Pow(G,X) mod P. Hence X, X+T, X+2T, X+3T... all will have same values..\n\nshare|improve this answer\n\nI seriously think you're abusing this algorithm. From your description, and from looking at the algorithm, it's pretty clear that this is designed to go forward only. Think of it as computing a checksum of X using keys P and G.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/134773/homocyclic-primary-module-over-pid\nText:\nTake the 2-minute tour \u00d7\n\nI posed the question here, but get no answers yet.\n\nLet $R$ be a PID, $M$ be an $R$-module. If $M$ is isomorphic to $r$ copies of cyclic primary module $R/\\langle p^s\\rangle$ where $p$ is a prime element of $R$, then does $M$ possess the following property?\n\nGiven any submodule $N$ of $M$ isomorphic to $R/\\langle p^{s_1}\\rangle\\oplus\\cdots\\oplus R/\\langle p^{s_r}\\rangle$, $M/N$ is isomorphic to $R/\\langle p^{s-s_1}\\rangle\\oplus\\cdots\\oplus R/\\langle p^{s-s_r}\\rangle$.\n\nshare|improve this question\nThis is better suited for MSE. You could start with $r=1$, with $M=R/p^sR$, $N=R/p^{s_1}R$. \u2013\u00a0 Dietrich Burde Jun 26 '13 at 8:23\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nChoose generators $n_1,\\dotsc,n_r$ for $N$ with $p^{s_i}n_i=0$. It is not hard to see that the annihilator of $p^{s_i}$ on $M$ is $p^{s-s_i}M$, so we can choose $m_i$ with $p^{s-s_i}m_i=n_i$. If we can prove that the elements $m_i$ form a basis for $M$ over the ring $R/p^s$, then everything else is clear.\n\nThe given assumptions on $N$ imply that the elements $p^{s-1}m_i=p^{s_i-1}n_i$ are linearly independent over $R/p$ in the space $M[p]=\\{m\\in M:pm=0\\}$, and by counting dimensions they must form a basis. Multiplication by $p^{s-1}$ gives an isomorphism $M/pM\\to M[p]$, so the elements $m_i$ form a basis for $M/pM$ over $R/p$.\n\nWe can certainly write $m_i=\\sum_ja_{ij}e_j$ for some matrix $A=(a_{ij})$ over $R$, where $e_1,\\dotsc,e_r$ is the standard basis for $M$. The above shows that $\\det(A)$ is invertible mod $p$. It follows easily that it is invertible mod $p^s$ as well, which proves the claim.\n\nMy argument refers to $p^{s_i-1}$ and so does not immediately work if $s_i=0$ for some $i$, but that can be cured with a few more steps.\n\nshare|improve this answer\nFollowing is the way I can think of to work for the case when some $s_i=0$. Get $m_i$'s in your argument for nonzero $s_i$'s, and prove that they are $R$-linearly independent by showing a correspinding minor of $A$ is invertible mod $p^s$. Then extend these $m_i$'s to an $R$-basis of $M$ as $M$ is homocyclic. Is there any simpler way? \u2013\u00a0 Binzhou Xia Jul 13 '13 at 13:17\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/122396/is-this-set-corresponding-to-a-bounded-linear-operator-necessarily-open\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\Lambda : X \\to X$ be a bounded linear operator on a Banach space $X$. My question is whether the set $$ \\{\\lambda \\in \\mathbb C: \\lambda I - \\Lambda \\quad\\text{is surjective} \\} $$ is necessarily open. The above set is similar to the resolvent set of $\\Lambda$, which is defined to be the set of all $\\lambda \\in \\mathbb C$ such that $\\lambda I - \\Lambda$ is invertible; I know that the resolvent set is always open. However, what about the set above?\n\nFor reference, it was a problem on a past qualifying exam (see problem 6) to prove that the set is in fact open. I'm not sure if they meant to indicate the resolvent set, or if the problem is correct as stated.\n\nshare|improve this question\nA related thread proving the stronger result that the space of surjective operators is open. \u2013\u00a0 t.b. Mar 20 '12 at 10:20\n@t.b. Thanks for pointing that out, the argument is very nice. \u2013\u00a0 Nick Strehlke Mar 20 '12 at 14:17\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nLet $\\lambda$ such that $T := \\lambda - \\Lambda$ is surjective. Then $\\bar T: X/\\ker T \\to X/\\ker T$, $\\bar T(x + \\ker T) = Tx + \\ker T$ is invertible, hence there is some $\\varepsilon > 0$ such that $\\bar T + \\mu$ is invertible for $|\\mu| < \\varepsilon$.\n\nLet $0 < |\\mu| < \\varepsilon$ and $y \\in X$. Then there is some $x \\in X$ such that $(\\bar T + \\mu)(x + \\ker T) = y + \\ker T$, which means that $Tx + \\mu x + \\ker T = y + \\ker T$. So there is some $z \\in X$ with $Tz = 0$ and $Tx + \\mu x + z = y$. Then \\begin{align*} (T + \\mu)\\left(x + \\frac 1\\mu z\\right) &= Tx + \\mu x + z\\\\ &= y. \\end{align*} As $y$ was arbitrary, $T + \\mu$ is surjective and the set in question is open.\n\n\nshare|improve this answer\nThanks martini, this is very helpful. \u2013\u00a0 Nick Strehlke Mar 20 '12 at 14:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/213275/injective-integral-domains-are-fields\nText:\nTake the 2-minute tour \u00d7\n\nProve that if an integral domain $R$ is an injective $R$-module then $R$ is a field.\n\n\nChoose a non-zero element $x$ of $R$ and consider the map $f: R \\rightarrow R$ given by $f(t)=tx$.\n\nThis yields an exact sequence $0 \\rightarrow R \\rightarrow R \\rightarrow R/\\langle x \\rangle \\rightarrow 0$ where the first map is $f$.\n\nBy assumption $R$ is injective and thus $R \\cong R \\oplus R/\\langle x \\rangle$.\n\nNow the claim is that $1 \\in \\langle x \\rangle$. Otherwise $(1,0 + \\langle x \\rangle)$, $(0,1+ \\langle x \\rangle)$ are zero divisors of $R \\oplus R/\\langle x \\rangle$ which is impossible since $R$ is an integral domain.\n\nThus $1 \\in \\langle x \\rangle$ so $x$ is invertible and we're done. Is this OK?\n\nshare|improve this question\nIn principle, the direct decomposition you found is of R as an R-module, and not as a ring. You should probably elaborate that point a bit. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Oct 13 '12 at 22:40\nCurious that we have two answers that are more interested in showing off their own proof than answering the question you actually asked. \u2013\u00a0 Hurkyl Oct 14 '12 at 0:26\nNote that you need to prove every non-zero $x$ is invertible, not just a chosen non-zero $x$. While I'm sure the former was your intent, the latter is what you actually wrote. You should probably explicitly write down what the product operation is on $R \\oplus R / \\langle x \\rangle$, so that you can verify the claimed zero divisors really are zero divisors (or find some other means of showing this). One last thing that gives me pause is the claim $R \\cong R \\oplus R / \\langle x \\rangle$ -- but that's probably just because I don't use injective modules much. \u2013\u00a0 Hurkyl Oct 14 '12 at 0:35\n@Hurkyl: Maybe it's curious, but I think it will be helpful to the OP to see how the various definitions of injectivity can be used to prove the statement in question. In my opinion, the direct sum decomposition property used by the OP isn't very elegant here. But, of course, that's a matter of taste ... \u2013\u00a0 Ralph Oct 14 '12 at 0:47\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nDefine $f$ as in your answer. By injectivity of $R$, there is an $R$-linear map $g: R \\to R$ such that $g \\circ f = id_R$ (draw a commutative triangle). Hence $1=g(f(1))=g(x)=g(x \\cdot 1)=x\\cdot g(1)$, i.e. $x$ has a multiplicative inverse.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166010/messenger-riddle?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nA column of troops one km long is moving along a straight road at a uniform pace. A messenger is sent from the head of the column, delivers a message at the rear of the column and returns. He also moves at a uniform pace and arrives back at the head of the column when it has just covered its own length. How far did the messenger travel?\n\nI can't get any ideas on how to start.\n\nThanks for any help.\n\nshare|improve this question\nHow far did the messenger travel means the distance traveled or the displacement? If its displacement then the answer should be 1km. \u2013\u00a0 Saurabh Jul 3 '12 at 6:10\nIt means distance. \u2013\u00a0 Matt Jul 3 '12 at 6:12\nYou just need to organise the information carefully and use distance = speed x time. Write down what you know about the movement of the column - say speed $u$ and the messenger say speed $v$ taking total time $t$. Split the movement of the messenger into two obvious parts. Then identify the total distance $d$ you want to find, and use the information you have to find an equation for $d$. \u2013\u00a0 Mark Bennet Jul 3 '12 at 6:19\nA trivial answer to the question would be $1$km, the length of the column. After all, the messenger starts out at the head of the column, and ends up again at the end of the column, at the point in time when it has covered its own length, and she then has advanced as much as the column has. This is probably not what the question intends, but it could be made clearer. \u2013\u00a0 Marc van Leeuwen Jul 3 '12 at 6:50\nadd comment\n\n3 Answers\n\nup vote 7 down vote accepted\n\nLet us assume that the speed of the column is $1$ km per unit of time. For convenience, call that unit an hour. The column took $1$ hour to cover its own length.\n\nLet $v$ be the speed of the messenger. When she is travelling to the back, the combined speed of approach of the messenger and the column rear is $v+1$, so the time it takes is $\\frac{1}{v+1}$. Going the other way, the speed at which the messenger gains on the head is $v-1$, so the time it takes to gain the whole $1$ km is $\\frac{1}{v-1}$. The whole task took $1$ hour, and therefore $$\\frac{1}{v+1}+\\frac{1}{v-1}=1.$$ This gives $v=1+\\sqrt{2}$. The time taken is an hour, so the distance travelled is $1+\\sqrt{2}$.\n\nshare|improve this answer\nadd comment\n\nLet the speed of troop is $u$ kmph and that of messenger is $v$ kmph.\nSo the relative speed when messenger is going backward is $v+u$ kmph.\nAnd relative speed while going forward is $v-u$ kmph $(v>u)$.\nSo the total time taken is $$t=\\frac{1}{v+u}+\\frac{1}{v-u}$$ but in this time troop had moved $1$km so the $t=\\frac{1}{u}$\n$$\\frac{1}{u}=\\frac{1}{v+u}+\\frac{1}{v-u}$$ $$v^2-2uv-u^2=0$$ which give us the following relation $$v=u(1+\\sqrt2)$$\n\nso the distance traveled is $$\\begin{align*} d= &\\underbrace{\\frac{v}{v+u}}_{backward}+\\underbrace{\\frac{v}{v-u}}_{forward}\\\\ &=\\frac{2v^2}{v^2-u^2}\\\\ &=\\frac{2v^2}{2uv}\\\\ &=\\frac{v}{u}=1+\\sqrt{2}\\text{ km}\\end{align*}$$\n\nshare|improve this answer\nMostly ok, but why did you give the answer using units of speed? Mind you, I've never seen it abbreviated \"kmph\". At least locally \"km/h\" is the only way to write it. This is different from, e.g. U.S.A., where \"mph\" is always used. I guess there are local variations :-) \u2013\u00a0 Jyrki Lahtonen Jul 3 '12 at 7:27\n@JyrkiLahtonen Oh that was a mistake .I have corrected it.Thanks \u2013\u00a0 Saurabh Jul 3 '12 at 7:32\nadd comment\n\nLet $x$ be the troops' speed and $y$ be the messenger's speed.\n\nTotal messenger travelling time is $1/x$ (as the troops moved 1km forward).\n\nIn the troops frame of reference, the messenger first moved backwards with the speed of $y+x$, and then moved forward with the speed of $y-x$ so that in the $1/x$ total time he returned to the initial position.\n\nLet $z$ be the time messenger spent to reach the rear of the column. Obviously, $z = 1/(y+x)$ (as messenger moves with the speed of $y+x$ relative to the column and has to travel $1$ km relative to the column to reach its rear).\n\nFrom the other side, we have $z \\times (y+x) + (1/x - z) \\times (y-x) = 0$, from which follows $2zx + y/x - 1 = 2/(y/x+1) + y/x - 1 = 0$.\n\nNote that the total messenger travelling distance is $d = y/x$. From the previous equation we get $2/(d+1) + d - 1 = 0$, $d^2-3 = 0$, and thus $d = \\sqrt{3}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/47302/is-there-an-example-of-gibbs-measure-that-is-not-a-weak-limit-of-finite-volume-g?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nConsider the first neighbors Ising model in $\\mathbb Z^2$, with the Hamiltonian in the finite volume $\\Lambda\\subset\\mathbb{Z}^2$ given by $$ H_{\\Lambda}(\\sigma|\\omega)=-J\\sum_{i,j\\in\\Lambda\\atop{\\|i-j\\|=1}}\\sigma_i\\sigma_j-J\\sum_{i\\in\\Lambda, j\\in\\Lambda^c\\atop{\\|i-j\\|=1}}\\sigma_i\\omega_j $$ where $\\omega\\in\\{-1,1\\}^{\\mathbb{Z}^2}$ is a boundary condition.\n\nBy the Aizenman-Higuchi Theorem for any $\\beta>0$, we have that closed convex hull of the weak limits of Gibbs measures in finite volume is the convex set $ [\\mu^{\\beta,+},\\mu^{\\beta,-}]. $\n\nQuestion: Is there any $\\beta>\\beta_c$ and $\\lambda\\in(0,1)$ such that $$ \\mu=\\lambda\\mu^{\\beta,+}+(1-\\lambda)\\mu^{\\beta,-} $$ and\n$$ \\mu\\notin \\left\\{w-\\lim_{\\Lambda\\uparrow\\mathbb{Z}^2}\\ \\ \\mu_{\\Lambda}^{\\beta,\\omega}:\\omega\\in\\{-1,1\\}^{\\mathbb{Z}^2} \\right\\} \\ \\ ? $$\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nI don't think so. Just consider Dobrushin boundary conditions (positive spins at vertices with nonnegative second coordinate, negative elsewhere), and a box of the form $$ \\Lambda_n=\\{-n,\\ldots,n\\}\\times\\{-n-[a\\sqrt{n}],\\ldots,n-[a\\sqrt{n}]\\}. $$ Then the mixture you'll get in the limit will have $\\lambda$ equal to the probability that the open contour passes below $0$, which should go continuously from $1$ to $0$ as $a$ goes from $-\\infty$ to $+\\infty$ (it is known that the interface converges weakly to a Brownian bridge under diffusive scaling).\n\nNote that this is very much a two-dimensional phenomenon. In 3d, at low enough temperature, I strongly doubt that you can find boundary conditions such that the limiting state is a nontrivial mixture of, say, Dobrushin states. (Of course, it is always true that you can reach extremal states in this way.)\n\nshare|improve this answer\nThank you very much for help me again. I liked the comment about high dimensional case it was very interesting. \u2013\u00a0 Leandro Dec 2 '10 at 5:30\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262615/a-logic-puzzle-from-tes-arena/262653\nText:\nTake the 2-minute tour \u00d7\n\nIts nice when games have riddles hidden in them. While playing TES:Arena, I came across an unusual logical puzzle: There are 3 cells.\n\nIf Cell 3 holds worthless brass, Cell 2 holds the gold key.\n\nIf Cell 1 holds the gold key, Cell 3 holds worthless brass.\n\nIf Cell 2 holds worthless brass, Cell 1 holds the gold key.\n\nKnowing this brave fool, and knowing that all that is said cannot be true, which cell contains the gold key?\n\nThe correct answer is Cell 2 as suggested by the game. I wanted to know how one could logically arrive at the result. Could anyone help me with this?\n\nWhat I tried: I negated all the above statements. The first implication became Cell 3 holds worthless brass AND Cell 2 does not have gold key. But if this is true, then cell 2 does not have the gold key and the result is incorrect. Hence I had this doubt.\n\nPS: Choosing the wrong door causes man eating spiders to be released.\n\nshare|improve this question\nDoes each cell necessarily contain either worthless brass or a gold key? \u2013\u00a0 Sp3000 Dec 20 '12 at 12:55\nAlthough not stated in game, there is only ONE cell with a gold key. The other cells may/may not have brass. \u2013\u00a0 Gautam Shenoy Dec 20 '12 at 12:57\nadd comment\n\n4 Answers\n\nIf you label the conditions a-c, and if the gold key exists and is unique, it is enough to show that not in 2 leads to a contradiction. But 'key not in 2' leads to 'key in 2' (so a contradiction), as follows:\n\nBy (c), not in 2 implies in 1. By (b) then, not in 3. By (a) then, key is in 2. Contradiction.\n\nTo be safe, you can check if the game makers messed up:\n\nAs 'key in 1' is a sub chain of the above, it also leads to 'key in 2'. Contradiction.\n\nSimilarly, 'key in 3' means by uniqueness that 2 holds brass, which, by (c), implies 1 holds the key. Contradiction.\n\nFinally note that if the key is in 2, it doesn't lead to any contradictions. So game is correct.\n\nshare|improve this answer\nadd comment\n\nCell 2 cannot hold worthless brass, and cell 1 cannot have the gold key.\n\nIf a cell can have neither brass nor key, then that is the limit of what you can conclude. For example, your conditions are consistent with cell 3 having the key and there being nothing in the other cells.\n\nBut if every cell contains either brass or key, then you know cell 2 has the key. You can prove that by assuming cell 2 did not have the key, and hence had worthless brass. That implies that cell 1 has the key, which implies cell 3 has worthless brass which implies that cell 2 has the key. Contradiction.\n\nHowever, if that additional condition were part of the problem, then your middle condition would be redundant.\n\nshare|improve this answer\nadd comment\n\nSorry to be contrary, but I believe you need 2 assumptions for there to be a unique solution. First, that all 3 statements are indeed true. If we allow that one or more of those statements doesn't hold, the whole thing falls apart.\n\nSecond, that each cell contains either brass or the key. No empty cells. If you disagree, try looking at these 2 solutions:\n\nCell 1 = Empty, Cell 2 = Key, Cell 3 = Empty\n\nCell 1 = Empty, Cell 2 = Empty, Cell 3 = Key\n\nNone of the 3 statements apply to either of these, so they're both possible valid solutions and you're left to guess and hope the spiders don't eat your face.\n\nNow, you can brute force your way through by listing all possible solutions and checking which are valid under the given statements. In this case there aren't many possible choices, so that approach is not too bad. However, I'm assuming you're looking for a bit deeper insight, so I'll walk through a technique that can sometimes provide a quicker route to the answer, especially in more complex puzzles.\n\nSince all the implications are one way (they are \"if\", not \"if and only if\"), one approach is to start by assuming a condition from the left side of a statement and trace the implications through all the statements to look for inconsistencies.\n\nJust going in order, let's assume first that Cell 3 holds brass. Then by statement 1, Cell 2 holds the key. Since we're assuming key or brass in each and only one key, then Cell 1 would have to be brass. Given that, neither of the last 2 statements apply, so this solution is possible with no contradictions. Let's continue and check the others to be sure we have the only possible valid solution.\n\nLooking at statement 2, let's assume now that Cell 1 holds the key. By statement 2, Cell 3 holds brass. By statement 1, Cell 2 holds the key. Since only 1 cell can hold the key, this is a contradiction. Therefore our original assumption is false, so Cell 1 does not hold the key.\n\nLastly, look at the third statement. If we assume Cell 2 holds brass, then Cell 1 holds the key. But we already know by our last reasoning that if Cell 1 holds the key we end up with a contradiction. So our assumption here is false, and Cell 2 does not hold brass.\n\nSince Cell 2 cannot hold brass, it must hold the key.\n\nshare|improve this answer\nadd comment\n\nIf you take \"not all that is said is true\" to mean that at least one statement is false, you can go through negating them and see where it leads. If the first statement is false, you have 3 holds brass and 2 does not hold the gold key. Given that there is a gold key, it must be behind door 1. Then the second and third statements would be true, but we still don't know whether cell 2 holds brass.\n\nIf the second statement is false, cell 1 has gold and 3 does not have brass (so is empty). The first and third sentences are then true and we again know nothing about cell 2.\n\nIf the third statement is false, 2 holds brass and 1 does not have gold, so it must be cell 3 that has gold. The other two are then true and we don't know what 1 holds.\n\nSince we didn't reach a contradiction from any of these, we can't choose between them. I would downvote the puzzle creator. However, if you ignore the \"not all that is said is true\" and believe them all, gnometorule has shown how to get there.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/270347/approximating-distances-in-the-hyperbolic-space\nText:\nTake the 2-minute tour \u00d7\n\nI am currently trying to understand the paper by Krioukov et. al. on hyperbolic networks, but since I do not have a background in hyperbolic geometry (or, in that sense, in geometry at all) I struggle to understand some points they are making.\n\nFor instance, they aim to compute the distance $x$ between two points $(r, \\theta)$ and $(r', \\theta')$ in the hyperbolic plane by using the hyperbolic law of cosines:\n\n\\begin{equation} \\mathsf{cosh}(kx) = \\mathsf{cosh}(kr) \\mathsf{cosh}(kr') - \\mathsf{sinh}(kr)\\mathsf{sinh}(kr')\\mathsf{cos}(\\Delta\\theta) \\end{equation}\n\nHere, $K=-k^2<0$ refers to the curvature, and $\\Delta \\theta = \\pi - |\\pi - |\\theta - \\theta'||$. I can intuitively follow this equation since it is similar to the regular law of cosines in the euclidean plane. However, in the next step they approximate it by assuming that $kr, kr'$ is large, and $\\Delta \\theta > 2 \\sqrt{e^{-2kr}+e^{-2kr'}}$ as follows: \\begin{equation} x = r + r' + \\frac{2}{k} \\ln \\sin \\frac{\\Delta\\theta}{2} \\approx r + r' + \\frac{2}{k} \\ln \\frac{\\Delta\\theta}{2}. \\end{equation}\n\nI am completely lost there, especially their assumption on $\\Delta \\theta$. Why does it make sense and how does it help simplify the fomula?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThe derivation is a little long, and I admit to being mystified by their assumption on $\\Delta \\theta$ - it merely needs to be that $\\Delta \\theta$ is small compared to something $O(1)$. But anyway...write\n\n$$\\cosh{k x} = \\cosh{k r} \\cosh{k r'} (1-\\tanh{k r} \\tanh{k r'} \\cos{\\Delta \\theta})$$\n\nand note that $\\lim_{t \\rightarrow \\infty} \\tanh{t} = 1$. We can then write\n\n$$\\cosh{k x} \\approx 2 \\cosh{k r} \\cosh{k r'} \\sin^2{\\left ( \\frac{\\Delta \\theta}{2} \\right )}$$\n\nUse the definition of cosh and that $k r$ and $k r'$ are both large to derive the following equation:\n\n$$\\exp{(2 k x)} - \\exp{(k (r + r'))} \\sin^2{\\left ( \\frac{\\Delta \\theta}{2} \\right )} \\exp{(k x)} + 1 \\approx 0 $$\n\nThis gives\n\n$$ \\exp{(k x)} \\approx \\exp{(k (r + r'))} \\sin^2{\\left ( \\frac{\\Delta \\theta}{2} \\right )} \\frac{1}{2} \\left [ 1 \\pm \\sqrt{1- 4 \\exp{(-k (r + r'))} \\csc^2{\\left ( \\frac{\\Delta \\theta}{2} \\right )}} \\right ] $$\n\nThe sqrt term on the right is very small. Assume the +ve solution, so the term in brackets is about 2. Take logs of both sides and get\n\n$$x \\approx r + r' + \\frac{2}{k} \\log{\\sin{\\left ( \\frac{\\Delta \\theta}{2} \\right )}} $$\n\nI hope this helps.\n\nshare|improve this answer\nIn fact, now that I look at it, I think the stated restriction on $\\Delta \\theta$ is there to keep that factor in the sqrt small. \u2013\u00a0 Ron Gordon Jan 4 '13 at 16:15\nIndeed it does. How on earth did you see that? Anyway, if I am not mistaken there are 2 minor mistakes that cancel each other out: First, in your 3rd equation, the 2 should disappear, since you have 2 cosh on the right side, which both multiply a factor 1/2 when converting to exponentials. Second, I think you forgot to square the right term under the squareroot. If one corrects those steps, the $\\log 2/k$ summand disappears as well. \u2013\u00a0 HdM Jan 4 '13 at 16:46\nI believe you are right! Thanks - what teamwork! \u2013\u00a0 Ron Gordon Jan 4 '13 at 16:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/297008/expected-value-of-largest-integer-in-a-draw/297074\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I pick $k$ integers without replacement from $\\{1, \\ldots, n\\}$. Let $I$ be the value of the highest integer. A calculation with binomials reveals $$E[I] = \\frac{k}{k+1}(n+1)$$ This is a very simple formula - does it have a simple calculation-free proof?\n\nshare|improve this question\nDo you know some instance of calculation-free proof for the expected value of some non-constant random variable? I would like to see it. \u2013\u00a0 Matem\u00e1ticos Chibchas Feb 7 '13 at 8:22\nIn many cases, you can use symmetry or some clever conditioning to avoid heavy calculations. \u2013\u00a0 pierre Feb 7 '13 at 8:33\nYou just said it: \"heavy\" calculations. This is OK, but no calculations at all? Besides, I agree that conditioning is clever, but it is based on the nontrivial subject of conditional expectation. \u2013\u00a0 Matem\u00e1ticos Chibchas Feb 7 '13 at 9:04\n@Matem\u00e1ticosChibchas - the answer by Henry below is what I would call calculation-free. \u2013\u00a0 pierre Feb 8 '13 at 23:42\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nPicking $k$ integers without replacement from $\\{1, \\ldots ,n\\}$ involves breaking the interval $[0,n+1]$ into $k+1$ pieces where the length of each piece has the same distribution.\n\nSo the expected length of each piece (including the piece from the highest sampled integer to $n+1$) is $\\dfrac{n+1}{k+1}$ and so the expected value of the highest sampled integer is $n+1 - \\dfrac{n+1}{k+1}$.\n\nSimple calculation will give your result.\n\nSo in general, the expected value of the $j$th sampled integer (counting from the bottom) is $j \\dfrac{n+1}{k+1} $.\n\nshare|improve this answer\nSorry by my ignorance, but I don't get it: what is the \"same distribution\" of each piece? (I don't understand the expected length stuff either, but hopefully this will be cleared when I get illuminated about the \"same distribution\" issue) Thanks. \u2013\u00a0 Matem\u00e1ticos Chibchas Feb 7 '13 at 20:08\nVery nice! But how do you show that are no \"edge effects,\" i.e., that the length of the first piece has the same as the length of the second? \u2013\u00a0 pierre Feb 7 '13 at 22:04\n@Matem\u00e1ticos Chibchas: Each length is a random variable with a distribution. Each of these distributions is the same and has the same mean. \u2013\u00a0 Henry Feb 8 '13 at 7:35\n@pierre: Imagine seating $k+1$ people round a table with $n+1$ seats: there are no edge effects in the gaps between people. Then cut the table where the first person sits and straighten it into a bench of length $n+1$. \u2013\u00a0 Henry Feb 8 '13 at 7:39\nLovely. Thank you for this fantastic answer. \u2013\u00a0 pierre Feb 8 '13 at 23:41\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/120326/on-weils-characters-of-type-a?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nIn Weil's paper\n\n\"On a certain type of characters of the idele-class group of an algebraic number field\",\n\nWeil introduces a class of characters on the Idele class group (of not necessarily finite order) which take algebraic values. He calls them, characters of type (A) (the (A) probably stands for algebraic, I guess). On the last 3 lines of p. 3, he says that Artin pointed out to him how to use Minkowski's theorem on units (in absolutely normal number fields) to show essentially that all such characters come from CM fields.\n\nBasically, this question boils down to understand the following: For which number fields $K$; collection of integers $f_{\\iota}$; and a suitable choice of an integer $m$, is it possible to have $$ \\prod_{\\iota\\in S_{\\infty} }\\left(\\frac{\\iota(\\epsilon)}{\\overline{\\iota(\\epsilon)}}\\right)^{mf_{\\iota}}=1 $$ for all $\\epsilon\\in \\mathcal{O}_K^{\\times}$? Here $S_{\\infty}$ denotes the set of infinite places of $K$.\n\nQ1: Is there a reference in the literature where I can find a proof (or a sketch of a proof) of this result?\n\nQ2: If no such reference exists, then how does one prove it from Minkowski's theorem?\n\nshare|improve this question\nSee Laurent Fargues's great article 'Motives and automorphic forms: the potentially abelian case', available here: www-irma.u-strasbg.fr/~fargues/Motifs_abeliens.pdf It's Proposition 1.12. \u2013\u00a0 Keerthi Madapusi Pera Jan 30 '13 at 14:49\nAlso, do you mean Dirichlet's theorem, rather than Minkowski's? \u2013\u00a0 Keerthi Madapusi Pera Jan 30 '13 at 14:49\nFargues' article is indeed great in many ways but I don't find his proof of Proposition 1.12 all that clear -- he leaves a lot of checking to the reader. \u2013\u00a0 David Loeffler Jan 30 '13 at 20:16\nsee Patrikis' 2012 thesis: math.ias.edu/~patrikis/variationsoct2012.pdf (in particular, 5.1.3). the first proof given is the standard one (see Keerthi's answer below), but it also indicates a second proof. \u2013\u00a0 fherzig Jan 31 '13 at 19:37\nadd comment\n\n2 Answers\n\nup vote 7 down vote accepted\n\nNow that I've had the chance to look at Fargues's proof carefully, it seems incomplete for what it claims to prove, but it might answer the question under consideration.\n\nSuppose that you have a collection of integers $f_{\\iota}$ indexed by embeddings $\\iota:K\\hookrightarrow\\mathbb{C}$ and satisfying for some integer $m$ (this is slightly different from the OP's identity):\n\n$$\\prod_{\\iota}\\iota(\\epsilon)^{mf_{\\iota}}=1,\\text{ for all $\\epsilon\\in\\mathcal{O}_K^\\times$}.$$\n\nThen I claim that there exists a CM sub-field $L\\subset K$ such that $f_{\\iota}$ only depends on $\\iota\\vert_L$ (for the purposes of this statement, totally real fields are CM).\n\nThe assertion that allows us to reduce this to Dirichlet's unit theorem is the following: It suffices to show that, for all $\\sigma\\in Aut(\\mathbb{C})$, $f_{\\sigma\\iota}+f_{\\sigma\\overline{\\iota}}$ is independent of $\\iota$ and $\\sigma$.\n\n(EDIT: It was incorrectly stated in the original version that it was enough to require independence from $\\iota$ alone).\n\nTo see this, we reinterpret this condition as follows: After fixing an embedding $\\bar{\\mathbb{Q}}\\hookrightarrow\\mathbb{C}$, we can view the collection $(f_{\\iota})$ as an element $f$ of the $G_{\\mathbb{Q}}$-module of maps $Hom(K,\\bar{\\mathbb{Q}})\\to\\mathbb{Z}$. The Galois action is given by $(\\sigma(f))_{\\iota}=f_{\\sigma^{-1}\\iota}$. From this point of view, our claim amounts to: For every complex conjugation $c$ of $\\bar{\\mathbb{Q}}$, $f_{\\iota}+f_{c(\\iota)}$ is independent of $c$ and $\\iota$. In particular, for all $\\sigma\\in G_{\\mathbb{Q}}$, and all complex conjugations $c$, we have:\n\n$$ f_{\\sigma^{-1}\\iota}+f_{c(\\sigma^{-1}\\iota)}=f_{\\iota}+f_{c\\iota}. $$\n\nAnother way to write this is, for all $\\iota$:\n\n$$ \\sigma(f)_{\\iota}+\\sigma(c(f))_{\\iota}=f_{\\iota}+c(f)_{\\iota}. $$\n\nSo $\\sigma$ stabilizes $f$ if and only if it stabilizes $c(f)$, for all complex conjugations $c$. Let $L$ be the fixed field of the stabilizer of $f$ in $G_{\\mathbb{Q}}$. We have shown that $L$ is stabilized by all complex conjugations. To show that $L$ is CM we need to now need to know that all complex conjugations have the same action on $L$. This amounts to showing that $f_{c(\\iota)}$ does not depend on the choice of $c$. But, since $f_{\\iota}+f_{c(\\iota)}$ does not depend on $c$ by hypothesis, this is clear.\n\nLet us return to the first identity above. Taking the logarithm of its absolute value gives us:\n\n$$ \\sum_{\\iota}f_{\\iota}\\vert \\iota(\\epsilon)\\vert=0. $$\n\nBut consider the map\n\n$$ \\ell:\\mathcal{O}_K^\\times\\otimes\\mathbb{R}\\rightarrow\\oplus_{v\\vert\\infty}\\mathbb{R}. $$ given by $\\ell(\\epsilon\\otimes 1)_v=\\log\\vert \\epsilon\\vert_v$ if $v$ is real and by $\\ell(\\epsilon\\otimes 1)_v=2\\log\\vert \\epsilon\\vert_v$ if $v$ is complex. The indexing set here is the set of inequivalent archimedean norms on $K$. Then Dirichlet's unit theorem says that $\\ell$ is an isomorphism onto the hyperplane $H$ where the sum of the co-ordinates is identically $0$.\n\nThis shows that, for all $(b_v)\\in H$,\n$$\\sum_{v}\\frac{f_{\\iota(v)}+f_{\\overline{\\iota}(v)}}{2}b_v=0.$$ Here, if $v$ is complex, $\\iota(v)$ and $\\overline{\\iota}(v)$ are the two complex embeddings inducing $v$. If $v$ is real, they're the same embedding. If one uses the usual basis of $H$ consisting of differences of the basis vectors for the ambient space, one finds that $f_{\\iota}+f_{\\overline{\\iota}}$ is independent of $\\iota$. Applying the same argument to the character $\\epsilon\\mapsto\\prod_{\\iota}\\sigma^{-1}(\\iota(\\epsilon))^{f_{\\iota}}=\\prod_\\iota\\iota(\\epsilon)^{f_{\\sigma\\iota}}$, one sees that $f_{\\sigma\\iota}+f_{\\sigma\\overline{\\iota}}$ is independent of $\\iota$ as well.\n\n(EDIT: The remainder of the proof has been changed to reflect the correction in the criterion above.)\n\nSet $w(\\sigma)=f_{\\sigma\\iota}+f_{\\sigma\\bar{\\iota}}$: this doesn't depend on $\\iota$. To finish the proof, we must show that it is independent of $\\sigma$ as well. First, let $L$ be as above. From what we have proven already, we find that $L$ is stable under all complex conjugations. Assume that $L$ is totally complex; this implies that $K$ is also totally complex. Then, if $n=[K:\\mathbb{Q}]$, we have:\n\n$$ 2nw(1)=\\sum_{\\iota}(f_{\\iota}+f_{\\bar{\\iota}})=\\sum_{\\iota}(f_{\\sigma\\iota}+f_{\\sigma\\bar{\\iota}})=2nw(\\sigma). $$\n\nSo, in this case, the independence is clear.\n\nTo finish, it is enough to show the following: If $L$ has one real place, then $L=\\mathbb{Q}$. But the hypothesis implies that there is a complex conjugation $c$ that acts trivially on $L$, and so $2f_{\\iota}=f_{\\iota}+f_{c(\\iota)}$ is independent of $\\iota$. In this case, the Hecke character must be the twist of a finite order character by a power of the norm character.\n\nshare|improve this answer\nHi Keerthi, I'm confused about one point. If $Stab(f)=H\\leq G_{\\mathbf{Q}}$, then you are showing that for all complex conjugation $c\\in G_{\\mathbf{Q}}$, $cHc^{-1}=H$. But this does not seem to imply that $L:=\\bar{\\mathbf{Q}}^{H}$ is a CM field. For example, if $L$ is Galois over $\\mathbf{Q}$ and not CM, then the condition $cHc^{-1}=H$ is trivially satisfied since $H$ is normal in $G_{\\mathbf{Q}}$. Am I right? \u2013\u00a0 Hugo Chapdelaine Jan 31 '13 at 17:10\nHi Hugo, you're right! I was confused about why I seemed to be getting post facto that $f_{\\sigma\\iota}+f_{\\bar{\\sigma}\\iota}$ was independent also of $\\sigma$. But of course I need to show this a priori! I'll see if I can fix the argument. \u2013\u00a0 Keerthi Madapusi Pera Jan 31 '13 at 20:25\nEdits made. I think the proof is now correct. \u2013\u00a0 Keerthi Madapusi Pera Jan 31 '13 at 21:13\nAlso, as Florian points out in the comments above, pretty much the same proof appears in Patrikis's thesis. \u2013\u00a0 Keerthi Madapusi Pera Jan 31 '13 at 21:23\nThanks a lot Keerthi! Your proof seems to be correct. \u2013\u00a0 Hugo Chapdelaine Jan 31 '13 at 23:05\nadd comment\n\nSchappacher, Periods of Hecke characters, Chapter Zero, involves some of this, though he quotes SGA 4.5 section 5 for some parts, which could also be useful. I can't track a specific results like what you want, but I think he covers it, in an essence.\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/9558/the-shortest-path-in-first-passage-percolation\nText:\nTake the 2-minute tour \u00d7\n\nConsider a square planar grid. (The vertices are pair of points in the plane with integer coordinates and two vertices are adjacent if they agree in one coordinate and differ by one in the other.)\n\nGive every edge a length one with probability a half and length two with probability a half.\n\nConsider a shortest path between the origin and the vertex $(n,0)$.\n\nShow that with probability that tends to one as $n$ tends to infinity the shortest path will not contain the \"middle edge\" on the x-axis inbetween the orgin and $(n,0)$. (Namely, the edge between the vertices $(\\lfloor\\frac{n}{2}\\rfloor,0)$ and $(\\lfloor\\frac{n}{2}\\rfloor+1,0)$.)\n\nThis question is in the category of \"a missing lemma\". It is not really a full fledged open problem but rather a statement which looks correct that was needed in some paper and resisted proof. Of course, some such \"lemmas\" turn out to be very difficult, but sometimes maybe a simple argument was simply missed. The relevant paper is with Itai Benjamini and Oded Schramm: First Passage Percolation Has Sublinear Distance Variance\n\nWhile MO have chosen to accept one answer, and there were some nice suggestions, the problem is still wide open.\n\nshare|improve this question\nThanks Alon, I myself cannot see the latex (it leaves the formulas uncompiled) so I prefer the plain text. \u2013\u00a0 Gil Kalai Dec 23 '09 at 10:34\nNitpicking: is it \"a shortest path\" or \"the shortest path\"? Do you want to show there is a shortest path avoiding the given edge, or that all shortest paths avoid the given edge. \u2013\u00a0 Boris Bukh Dec 23 '09 at 11:26\nThat's really a shame, Gil. Have you tried installing jsMath along with the fonts? It's not supposed to be necessary but perhaps it'll help. \u2013\u00a0 Alon Amit Dec 23 '09 at 18:00\nBoris, I suppose I just want to show that there is a shortest path avoiding this middle edge. Alon, jsMath? where \u2013\u00a0 Gil Kalai Dec 23 '09 at 18:50\nBoris: That's not nitpicky, it's actually an important point. If the distribution of passage times is continuous, then with probability one, there is a unique minimizing path between any two points. Here, since the distribution has atoms, with positive probability, there are multiple shortest paths. \u2013\u00a0 Tom LaGatta Dec 26 '09 at 2:02\nshow 1 more comment\n\n7 Answers\n\nGil: This is a type of problem that I know little about so here I am thinking out loud about problems that seem natural to ask about this situation. It is hard to believe that people have not already thought about these questions and perhaps answered them. Where would I look to find out more?\n\nYou write you are interested in a \"square planar grid.\" So I took this to mean that you were thinking about the points of a \"square grid graph\" with lx1 squares as the cells that goes from (0,0) to (n,n) and where weights were going to be assigned to the edges of size 1 or 2.\n\nThe paths that you are talking about need not be constrained to move up and to the right but it might be interesting to contrast the behavior of general shortest paths with those that move up and to the right. It would also seem to be of interest to see what happens if one selects half of the edges at random and makes them all length 1 edges and makes all the others of length 2. Since there are 4n edges this means 2n are 1's and 2n are 2's. Furthermore, If we insist that paths move up and to the right, such paths all have length 2n, so \"very shortest\" paths would consist only on 1's.\n\nIn both settings:\n\na. What is the probability there is a shortest path to (n,n) consisting of all 1's?\n\nb. What can be said about the expected value of the length of a shortest path to (n, n)? What can be said about the expected number of paths of this value?\n\nc. When one insists that each of the two lengths appear equally often how many different ways can this happen? (One can also ask how many of these are different up to symmetry of the \"colored\" graph, treating the lengths as two colors.) One could count in the general case too but the up and to the right case seems more interesting here.\n\nshare|improve this answer\nTo whomever gave this post a negative vote: Shame on you. This post does not answer the question Gil asked, but so what? It is exploratory and raises some interesting ideas; perhaps one of those could lead to a correct answer. Posts like this are exactly what MathOverflow needs. \u2013\u00a0 Tom LaGatta Dec 26 '09 at 1:57\nJoe, it is a very good idea to consider paths from (0,0) to (n,n) and to consider also the case where you only go north and east. This restricted model is called \"directed percolation\". As far as I know the lemma is not known for directed percolation. There is one version where the distribution of edge length is exponential and you want the path of MAXIMUM length where this model is understood very well and is strongly connected to maximum eigenvalues of random symmetric matrices, largest monotone subsequences etc. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:27\nIt may be possible that for this version (directed percolation; exponential lengths, maximum path), the detailed understanding of the model may lead to a proof of the lemma; but I am not sure even about it. (There are hopes, but no proofs for universality: that various models will behave in some sense the same way.) Strangely, I dont know the answer for a) off-hand. Nice question. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:34\n@Tom. I think you are wrong --- if someone read it and find it not helpful then it is right thing to vote down. (BTW, it was not me) \u2013\u00a0 Anton Petrunin Jan 27 '10 at 19:37\nadd comment\n\nGil, as you said, this is one of those typical FPP problems which seems obvious but is hard to prove. What have you tried already? It'd be helpful to know of some na\u00efve attempts which didn't work.\n\nHere are my thoughts:\n\nClaim: There exists non-random $\\lambda$ such that, with probability one, for large n, all shortest paths between $0$ and $(n,0)$ meet $\\lambda n + o(n)$ edges. (this is a LLN-type theorem so it shouldn't be hard to prove; e.g., via energy-entropy methods, since your passage time distributions are bounded)\n\nThus one can consider the probability space $\\Omega_n$ consisting of all paths between $0$ and $(n,0)$ which meet $\\lambda n + o(n)$ edges. A shortest path is a random variable $X_n$ on this space with a certain probability distribution.\n\nClaim: There exists $\\sigma$ such that $|\\Omega_n| \\approx \\sigma^n$. (should be easy: $\\log|\\Omega_n|$ is probably subadditive)\n\nLet $\\Omega_n'$ be the subspace of paths which meet the middle edge, so that $|\\Omega_n'| \\approx \\sigma^{n/2} + \\sigma^{n/2}$.\n\nSuppose that there exists $p > 0$ such that the shortest path between $0$ and $(n,0)$ meets the middle edge with probability at least $p$. (*)\n\nHere is the part which I'm struggling to quantify. Intuitively, the distribution of $X_n$ should be smeared smoothly over $\\Omega_n$. Certainly the mean is a horizontal line segment, but even paths which veer quite far away aren't unreasonable. However, if (*) holds, with probability at least $p$, $X_n$ concentrates on the much smaller subspace $\\Omega_n'$. This seems wrong.\n\nPerhaps all I've done is to translate one \"obvious\" statement into another. Hopefully this helps a bit. Good luck!\n\nshare|improve this answer\nTom, Interseting suggestion. I dont remember so much what we tried. At the end we managed to go around this lemma. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:38\nadd comment\n\nGil, thanks for bumping this post. I think I've got a new idea for you, but it's not a proof yet. Let $\\gamma_n$ be a minimizing geodesic between $(-n,0)$ and $(n,0)$, and let $\\gamma^{\\pm}_n$ be a minimizing geodesic betwen $(\\pm n, 0)$ and the origin.\n\nDenote by $d(\\gamma_n)$ the maximal Euclidean distance from the geodesic $\\gamma_n$ to the straight line path between $(-n,0)$ and $(n,0)$, and define $d(\\gamma^\\pm_n)$ similarly for $\\gamma^\\pm_n$. By the definition of the transversal fluctuation exponent $\\xi$, $d(\\gamma^\\pm_n)$ scales like $n^\\xi$ and $d(\\gamma_n)$ scales like $(2n)^\\xi$.\n\nSince $\\tfrac 1 2$ is less than the critical probability for oriented bond percolation in two dimensions $\\approx .633$, a theorem of Licea-Newman-Piza applies and there is a rigorous lower bound $$\\xi \\ge 1/3$$ for your model. (cf. Theorem 4.3 in Howard - Models of First-Passage Percolation)\n\nSuppose that $\\gamma_n = \\gamma^-_n \\cup \\gamma^+_n$ (i.e. the geodesic $\\gamma_n$ meets the origin), so that $$2^\\xi n^\\xi \\approx d(\\gamma_n) = \\max\\{d(\\gamma^-_n), d(\\gamma^+_n)\\} \\approx n^\\xi, $$ which suggests a contradiction since $2^\\xi > 1$ by the lower bound $\\xi \\ge 1/3$.\n\nHere's why it doesn't work. The exponent $\\xi$ is precisely defined as the minimal power of $n$ such that the following hold: $$\\lim_{n\\to\\infty} \\mathbb P\\left[d(\\gamma^\\pm_n) \\le n^\\xi \\right] = 1 \\qquad \\mathrm{and} \\qquad \\lim_{n\\to\\infty} \\mathbb P\\left[d(\\gamma_n) \\le (2n)^\\xi \\right] = 1.$$ Since the $\\approx$ signs above are really inequalities, there is no contradiction above.\n\nshare|improve this answer\nThat's very interesting. I did not know that there is a (provable) lower bound for xsi and this certainly looks very relevant. (In fact stronger than my question...) \u2013\u00a0 Gil Kalai Apr 28 '10 at 6:08\nadd comment\n\nHere is a sketch of a germ of an idea that might work. But don't take it too seriously.\n\nConsider the space $E_k$ of grid paths from $(0,0)$ to $(2k+1,0)$ with nonnegative $x_2$-coordinate and Euclidean length $2k+3$. Associate such paths with functions in the obvious way. Now there are $\\binom{2k+2}{2}$ such paths, $2\\binom{k+1}{2}$ (i.e., proportionally just less than one half) of which contain the middle edge. Now there exists an assignment of edge lengths and corresponding coefficients $\\{a_j\\}_{j=1}^k \\in \\{0,1\\}^k$ s.t. the sum $\\gamma = \\sum_{j=1}^k a_j \\gamma_j$ is a shortest path (provided we require a nonnegative $x_2$-coordinate).\n\nIf the $a_j$ and $\\gamma_j$ are selected uniformly at random, then the probability that the middle edge will be contained in $\\gamma$ is asymptotically $2^{-k/2}$.\n\nshare|improve this answer\nadd comment\n\nTalking about naive attempts, I thought maybe a simple solution along these lines could be found, but I couldn't:\n\nI denote by $p_k(n,2r)$ the probability that a shortest path from the origin to $(n,2r)$ contains the segment $(\\lfloor \\frac{n}{2}\\rfloor,k)$ to $(\\lfloor \\frac{n}{2}\\rfloor +1,k)$. A simple observation is that $p_k(n,2k)=p_k(n,0)$ (consider reflecting the path on the line $y=k$ in the region $x > \\lfloor \\frac{n}{2}\\rfloor$). The idea is to show that $p_k(n,2k)$ is close to $p_0(n,0)$ for small $k$. One can do this maybe by considering a new rectangular grid spanned by $(1,\\frac{2k}{n})$ and $(-\\frac{2k}{n},1)$ (with suitable edge weight distribution) and trying to find the new $p_0'(n,0)$ which should be a good approximation of $p_k(n,2k)$.\n\nNow if one can find a slowly decreasing function $f$ so that $p_k(n,2k)\\approx f(p_0(n,0))$ in the range, say $|k|\\le \\sqrt{n}$ then $$1=\\sum_{k=-\\infty}^{\\infty}p_k(n,0)=\\sum_{k=-\\infty}^{\\infty}p_k(n,2k)\\approx \\int_{-\\sqrt{n}}^{\\sqrt{n}}f(p)dp \\geq c\\sqrt{n}p_0(n,0)$$ for some constant $c$. If $\\lim_{n\\to \\infty}p_0(n,0)>0$ then the above inequality is obviously false for large enough $n$.\n\nETA: I realize this approach works if we were able to prove $$\\liminf_{n\\to \\infty} p_{0}(n,0)=\\liminf_{n\\to \\infty} p_k(n,0)$$ for any fixed $k$.\n\nshare|improve this answer\nadd comment\n\nUPDATE: Fixed typing error in 2nd paragraph (greater than -> less than or equal to)\n\nUPDATE2: Fixed typing errors pointed out by Gil Kalai\n\nUPDATE3: I put off the detailed version from my webpage\n\nUPDATE4: The solution is wrong, as pointed out to me by Nathana\u00ebl Berestycki. It is of course not enough to consider only the path that goes directly from the origin to (n,0). I didn't read the problem properly. Sorry.\n\nI don't know whether this problem is still open, but I think I have found an elementary proof for the original question. It is almost too simple to be true, but I don't see any mistake. Here's the sketch:\n\nAll numbers here are natural numbers between $0$ and $n$, and $n$ is sufficiently large. Fix a (large) $K$. Let $x_l$ be the smallest $x < n/3$, such that for all $1\\le j \\le K$, the length of the path $(x,0)\\rightarrow (x,j) \\rightarrow (x+K,j)$ is less than or equal to the length of the path $(x,0)\\rightarrow (x+K,0)$. The arrow indicates that we take the direct path. For definiteness, set $x_l = \\lfloor n/3 \\rfloor + 1$ if such a number does not exist, but note that it exists with probability going to one as $n\\rightarrow \\infty$. Note further that since we took the smallest $x$ with the above property, conditioned on $x_l$, the lengths of the edges to the right of the vertical line $x=x_l+K$ are still independent, of the same law as before, and independent of the configuration to the left of this vertical line.\n\nNow define $x_r$ by mirroring the above definition at the line $x=n/2$ (the largest $x>2n/3$, such that ....)\n\nThen, the paths $(x_l+K,j)\\rightarrow(x_r-K,j)$ are independent for $0\\le j\\le K$, hence, with probability going to $K/(K+1)$, there exists $1\\le j \\le K$, such that the path $(x_l+K,j)\\rightarrow(x_r-K,j)$ is shorter than $(x_l+K,0)\\rightarrow(x_r-K,0)$.\n\nCombining the above observations, with probability $K/(K+1) + o(1)$, there exist $x_l < n/3$, $x_r>2n/3$ and $1\\le j \\le K$ such that the path $(0,0) \\rightarrow (x_l,0)\\rightarrow (x_l,j)\\rightarrow (x_r,j) \\rightarrow (x_r,0) \\rightarrow (n,0)$ is shorter than the path $(0,0) \\rightarrow (n,0)$. Letting first $n\\rightarrow \\infty$, then $K\\rightarrow\\infty$ finishes the proof.\n\nshare|improve this answer\nDear Pascal, it is a bit too sketchy for me to follow but it looks promising! (Also I supppose the vertical line is x=x_l+K). \u2013\u00a0 Gil Kalai Sep 25 '11 at 13:26\n@Gil: Thanks for having a look at the proof and pointing out the typos. I'd be glad to write down a detailed version, if the problem still interests you. \u2013\u00a0 Pascal Maillard Sep 25 '11 at 17:22\nDear Pascal, yes definitely it is an interesting problem on its own, several people tried to prove it (including us) and it has some applications regarding geodesics in the random metric described by FPP. \u2013\u00a0 Gil Kalai Sep 25 '11 at 19:51\nDear Pascal, the conjecture is from 2002 by Benjamini, Schramm and myself in the paper cited in the question itself .front.math.ucdavis.edu/0203.5262 . It is mentioned at the bottom of page 2 and the top of page 5. Actually on page 5 a slightly stronger version that we needed is mentioned and maybe your method apply there too. \u2013\u00a0 Gil Kalai Sep 26 '11 at 12:10\nOK, I'll have a look at it and see if the method can be applied to the stronger statement. \u2013\u00a0 Pascal Maillard Sep 26 '11 at 12:59\nshow 1 more comment\n\nMidway Problem (a reformulation only)\n\nThis is not an Answer. Start with a 2n x2n grid graph. all edges length one, all even pairs linked.\n\nThe \"both even\" numbered vertices are \"the original graph\". Add (x odd, y even) vertices half the time. Add (x even, y odd) vertices the time. The (odd, odd) vertices are always out. Seems a decent starting point. Point Midway is now (n+1, 0), and in the graph half of the time.\n\nThe two questions may then be:\n\nStrongest question, as n grows: Show with probability approaching one that the set of all shortest paths between (0,0) and (2n,0) almost never contains Midway.\n\nWeaker question, as n grows: Show with probability approaching one that there is a shortest path\nbetween (0,0) and (2n,0) that does not contain Midway.\n\nThey may even have different answers, unless the shortest path has \"uniqueness\" properties. So again, this is not an answer.\n\nBut, the fractions are gone, and the edge lengths are all one!\n\nApologies for the initial typo. Is this variation more accessible?\nThe Far Corner variant of Midway, with an exclusion somewhere, may be easier for purists; but again, I do not know the answer (Nor even close). Propertys of shortest path sets from (0,0) to (2n,2n) may shed light on the axial case. Some small variety of forbidden minor, behaving as Midway, may be worthy of considering. I would try constant sized cycles.\n\nshare|improve this answer\nThat's an interesting variation of the problem that might be easier. When you say add (x odd y even) hald the time do you mean with probability 1/2? I suppose also the (x even y odd) vertices are also added half the time. that's interesting. \u2013\u00a0 Gil Kalai Jan 31 '10 at 16:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/20583/how-to-simplify-frac-sqrt4h-2h\nText:\nTake the tour \u00d7\n\nThe following expression:\n\n\nshould be simplified to:\n\n\n(even if I don't agree that this second is more simple than the first).\n\nThe problem is that I have no idea of the first step to simplify that.. any help?\n\nshare|improve this question\nThe magic words are \"multiply by the conjugate\". For what it is worth, I would actually prefer the former form to the latter. I find it is easier to keep radicals out of denominators, so I would call the former the simplification, not the latter. \u2013\u00a0 Arturo Magidin Feb 5 '11 at 21:25\nI prefer the latter because the removable singularity is removed. But I also am prone to say $\\sin\\frac{\\pi}{4}=\\frac{1}{\\sqrt 2}$ rather than $\\frac{\\sqrt 2}{2}$. @Tom: An important use of such \"simplification\" is that the latter expression indicates how the original expression can be continuously extended to $h=0$. This allows you to determine that the slope of the tangent line to the curve $y=\\sqrt x$ at the point $(4,2)$ is $\\frac{1}{4}$. If you haven't already learned derivatives, these ideas are explained in the following article: en.wikipedia.org/wiki/Derivative \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:59\nadd comment\n\n4 Answers\n\nup vote 13 down vote accepted\n\nIf you multiply both the top and the bottom by $\\sqrt{4+h}+2$, you get $\\frac{(\\sqrt{4+h}-2)(\\sqrt{4+h}+2)}{h(\\sqrt{4+h}+2)}$, which simplifies to $\\frac{h}{h(\\sqrt{4+h}+2)}$. Then, divide both by $h$ (assuming $h\\neq 0$), and you get $\\frac{1}{\\sqrt{4+h}+2}$.\n\nshare|improve this answer\nadd comment\n\nIt is really simple. Let us just do what is most intuitive, multiply numerator and denominator with what you want to have in denominator. You get: $$ \\frac{(\\sqrt{4+h} - 2)(\\sqrt{4+h} + 2)}{h(\\sqrt{4+h}+2)} $$ Then observe the numerator has a difference of squares. Multiply the numerator easily using that and then your left with $$\\frac{h}{h(\\sqrt{4+h}+2)}$$ Just assume $ h \\neq 0 $ and get \"rid\" of it.\n\nshare|improve this answer\nadd comment\n\nHINT $\\rm\\displaystyle\\quad\\quad g^2 = 4+h\\ \\ \\Rightarrow\\ \\ \\frac{g-2}h\\ =\\ \\frac{g-2}{g^2-4}\\ =\\ \\frac{1}{g+2}$\n\nUsually the \"simplification\" is the opposite inference - known as rationalizing the denominator.\n\nshare|improve this answer\nIs that step $\\frac{g-2}{g\u00b2-4}$ correct? If you multiply g+2 up and down, you get $\\frac{g\u00b2-4}{h(g+2)}$, and you can't go on from here.. \u2013\u00a0 Tom Brito Feb 20 '11 at 19:27\n@Tom: $\\rm\\ g^2 = 4 + h\\ \\Rightarrow\\ h = g^2-4\\:.\\:$ That step results from substituting this value for $\\rm\\:h\\:$ into the denominator. \u2013\u00a0 Bill Dubuque Feb 20 '11 at 19:42\nadd comment\n\nSo its not about simplification. You just want to show they are equal. What you do is put an equal sign between them, and cancel everything you can, if you get 1=1 or similar you are done.\n\nshare|improve this answer\nI have downvoted, because I think this answer is misleading. You have to be very careful when trying to prove an identity not to start with the equation you want to prove and arrive at another equation via potentially irreversible steps. It is best to work with just one side of the alleged identity at a time. \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:04\n@Jonas What is an irreversible step ? Do you not have to be equally careful when when working with one side? \u2013\u00a0 user5904 Feb 5 '11 at 21:07\nLet us prove that $-1$ can be simplified to $1$. So I'll put an equal sign between them, $-1=1$. Now if I square both sides, $1=1$. This is true, so $-1=1$. Don't get me wrong, I'm not saying that you are advocating such an illogical step, but starting by assuming (at least in appearance) what you are supposed to prove has the potential to lead to errors. \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:11\nYou have a good point about being careful with one side, but there the rule is that you never even change what the expression is. You can multiply by $1$, add $0$, factor, cancel, etc., but you typically don't do anything that actually changes the value. (Of course, this warning is only for beginners, not those who have enough experience to recognize that there are many valid ways to prove an identity.) \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:14\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/281206/partition-minimizing-maximum-of-eulers-totient-function-across-terms\nText:\nTake the tour \u00d7\n\nGiven natural numbers $M$ and $N$, I'd like to find a partition of $2^N$ with $M$ or fewer terms, $t_1 + t_2 + ... + t_M$, such that $\\max(\\phi(t_1), \\phi(t_2), ..., \\phi(t_M))$ is minimized, where $\\phi$ is Euler's totient function.\n\nWhat might a smart algorithm for this look like? I can approach this with raw CPU power and metaheuristic search, but maybe the partition can be found analytically? I am mostly interested in $N$ = 8, 16, 32, 64, 128 in case that somehow simplifies the problem.\n\nshare|improve this question\nHere's a suggestion, I don't know how good it is. Precompute a list of \"sparsely totient numbers,\" see oeis.org/A036913. Given $N$, find the largest sparsely totient number $x$ not exceeding $2^N$, let $t_M=x$, then apply recursively to $2^N-x$ to get $t_{M-1},\\dots,t_2$, then let $t_1$ be whatever's left over. Maybe instead of largest s.t.n not exceeding $2^N$, use largest s.t.n not exceeding $2^N/M$. \u2013\u00a0 Gerry Myerson Jan 18 at 4:46\nIt maybe a great idea. I read that the ith primorial multiplied by the ith prime is sparsely totient, and used that to quickly build a list (not all sparse totients, but for rough minimization may be OK). I tried building the partition for $2^{64}$ in the style of Euclid's algorithm for GCD -- I took the biggest number in the list < $2^{64}$ and took the remainder of dividing by it, then took the biggest sparse totient in the list under the remainder and took the remainder of dividing by it, etc. etc. Turns out a linear combination of those sparse totients exactly partitioned it. Coincidence? \u2013\u00a0 Joseph Garvin Jan 22 at 15:36\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/73142/estimating-lattice-sums-of-concave-functions/73154\nText:\nTake the tour \u00d7\n\nSuppose that $f$ is a twice-differentiable concave function from $R^2$ to $R$ that's negative outside of some bounded set (e.g. $f(x,y)=1-x^2-y^2$) and let $F=$max$(f,0)$. Let $S_n$ be the Riemann sum for the integral of $F$ over $R^2$ obtained by summing the values of $F$ at all points in the lattice $(Z/n)^2$ and dividing by $n^2$. What sort of bounds can be given for the difference between $S_n$ and the integral of $F$ over $R^2$? Is it $O(1/n)$ or $O(1/n^2)$ or what? This is a more focussed version of the question error estimates for multi-dimensional Riemann sums .\n\nshare|improve this question\nOy! Mr. Propp, are you going to accept or comment at mathoverflow.net/questions/71432/\u2026? (Also, I answered your comment at (mathoverflow.net/questions/71344/\u2026) \u2013\u00a0 Ricky Demer Aug 18 '11 at 19:04\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nIt looks like the error is in $O(1/n^2)$, with a precise and optimal bound $C/n^2$ if you have a fixed bound on (1) the second derivative of the function (2) the radius of the region where it is non-negative.\n\nAs the question is stated there are two sources for the error term:\n\n  \u2022 the error in each square, centered at a point of the lattice, on which the function is strictly positive. This terms is controled by the second derivative of the function (it clearly vanishes for a linear function) at it is bounded by $O(1/n^4)$, since the number of squares is $O(n^2)$ the estimate on this whole term is $O(1/n^2)$,\n\n  \u2022 the error term in the boundary squares, those on which the function takes both a $>0$ and a zero value. On those squares the error is $O(1/n^3)$ and the number or such boundary squares is $O(n)$ so we get again a bound $O(1/n^2)$.\n\n(Note that a complete argument has to be more precise because the function $f$ could have zero derivative at the points where it vanishes, then the number of boundary squares is $O(n^2)$ but I think the result does not change).\n\nTo check that this estimate is optimal you can think of a function which is invariant under a rotation of angle $\\pi/2$ and equal to say $N-x$ on $y>0, -y+u\\leq x\\leq y-u$ for some small $u>0$. Then the first error term can be made smaller than the second, while the second \"boundary\" error term is indeed of the order of $1/n^2$ (the boundary errors all sum up).\n\nshare|improve this answer\nThe errors in each cell tend to compensate. If instead of having a compactly supported function with limited regularity, we have a functin $F$ in the Schwartz class, then the total error is $O(n^{-k})$ for every $k>0$. This is a consequence of the Poisson summation formula and the fact that the Fourier transform of $F$ is of Schwartz class too. Therefore the question is really about the effect of the limited regularity of $F$, and whether the concavity helps. \u2013\u00a0 Denis Serre Aug 18 '11 at 16:14\nI agree but as stated the main error term comes from the boundary squares. In some cases at least no compensation occurs, as in the example I tried to described, where all centers of boundary squares are at points where $f=0$ so that all those boundary terms are positive. \u2013\u00a0 Jean-Marc Schlenker Aug 18 '11 at 17:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122818/nth-root-of-a-matrix-as-an-analytic-function\nText:\nTake the tour \u00d7\n\nLet $A$ be a $k \\times k$ invertible matrix over complex numbers.\n\nIf it possible to write its nth root as an analytic function (i.e. power series in $A$)?\n\nEDIT: Complex coefficients can be functions of $A$.\n\n\nIf a matrix $A$ has only one eigenvalue $\\lambda$, then it is simple. We take\n\n$$B = \\exp\\left[\\tfrac{1}{n} \\log (A ) \\right]$$\n\nwhere we have $B^n = A$. Using Jordan decomposition, we can simplify the logarithm to a polynomial in that matrix (as $(A - \\lambda \\mathbb{I})$ is nilpotent)\n\n$$\\log(A) = \\log(\\lambda) - \\sum_{i=1}^{k} \\frac{\\left(- \\tfrac{A}{\\lambda} + \\mathbb{I}_k \\right)^{i}}{i}.$$\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nIf I am reading this correctly, you are fine with a power series whose (scalar) coefficients depend on the matrix $A$. In this case, it suffices to take a polynomial $p$ that interpolates $\\sqrt[n]{x}$, such that for each eigenvalue $\\lambda$ with multiplicity $k_\\lambda$, the first $k_\\lambda-1$ derivatives of $p$ coincide with those of $\\sqrt[n]{x}$ (Hermite interpolant). A degree-$k$ polynomial will always do the job.\n\nshare|improve this answer\nYes, I'm fine with coefficients depending on the matrix. I don't know why I overlooked this solution. \u2013\u00a0 Piotr Migdal Feb 24 at 20:19\nHowever, it is not as simple - I cannot assume that the matrix is diagonalizable; so any function which just maps eigenvalues to their roots won't work. Take as a counterexample $A = [[1, 1], [0, 1]]$ and $f(z)=z$ (sure, another polynomial works for this $A$). \u2013\u00a0 Piotr Migdal Feb 24 at 20:30\nThe multiplicity of the eigenvalue $1$ is $2$, so you need a polynomial that matches $g(z)$ and $g'(z)$ in $z=1$, where $g(x)=\\sqrt[n]{x}$. For some more detail on this approach, you can check Higham's Functions of matrices, SIAM Press 2008. \u2013\u00a0 Federico Poloni Feb 24 at 21:08\nSorry - I meant to add Chapter 1, but I pressed \"enter\" too quickly. \u2013\u00a0 Federico Poloni Feb 24 at 21:11\n@Federico So, you have my thanks in arxiv.org/abs/1305.1506. \u2013\u00a0 Piotr Migdal May 8 at 8:54\nadd comment\n\nLet $A$ be a $k\\times k$ invertible matrix, i.e. in $Gl(k)$. Assume that the segment $[I,A]$ lies in $Gl(k)$. Let us define $$ \\text{Log}A=\\int_{[1,A]} \\frac{d\\xi}{\\xi}=\\int_0^1(I-tI+tA)^{-1}(A-I)dt. $$ It makes sense since $A$ commutes with the denominator inside the integral. The assumption is satisfied in particular whenever $A$ is symmetric invertible with a nonnegative real part. Analytic continuation arguments entail $$ \\exp(\\text{Log}A)=A\\quad \\bigl(\\exp(\\frac{1}{n}\\text{Log}A)\\bigr)^n=A. $$ Looking at the Jordan canonical form of $A$, it is not difficult to see that the only thing to be avoided for the above method to work is that eigenvalues should not be negative real numbers. Let $z=a+ib$ be an eigenvalue not in $\\mathbb R_-$ in a Jordan block $J_N$ of size $N$, with 1 above the diagonal. Considering the segment $[I_N,J_N]$, we find on the diagonal $$ (1-t)+tz\\notin \\mathbb R_-\\text{ since $z\\notin \\mathbb R_-$}, $$ and above the diagonal $ (1-t)0+t=t. $ The logarithm formula above works.\n\nshare|improve this answer\nadd comment\n\nIf all eigenvalues of $A$ are in the right half plane, there is $\\alpha > 0$ such that the circle $|z - \\alpha| < \\alpha$ contains all the eigenvalues, and the principal branch of $f(z) = z^{1/n}$ is analytic in that circle. We then have a convergent binomial series $$ A^{1/n} = \\alpha^{1/n} \\sum_{k=0}^\\infty {{1/n} \\choose k} (\\alpha^{-1} A - I)^k $$\n\nshare|improve this answer\nIt was my initial thought, but in my case I cannot make such an assumption. \u2013\u00a0 Piotr Migdal Feb 25 at 0:40\nadd comment\n\nIt easy to apply a series to a diagonalizable matrix, and diagonalizable matrices are dense. This should answer your question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/125870/counting-k-cliques-not-also-k1-on-random-graphs\nText:\nTake the tour \u00d7\n\nconsider the set of graphs with $n$ vertices and exactly half of all $\\binom n 2$ possible edges.\n\nlooking for a formula that counts the number of these graphs that have a $k$-clique but not a $(k+1)$-clique.\n\nlooked at some of the Erdos-Renyi random graph theory and related formulas but did not see this case covered so far. an estimate may be ok. also if this is used in a paper somewhere, that would be useful to know.\n\nedit as Erdos-Renyi theory & a comment points out the critical point for detection of a $k$-clique is at $k=\\log(n)$ where the probability goes from $P<0.5$ to $P>0.5$. it would be very interesting if there was a formula that could be derived independent of these regions (once called \"subcritical, critical, supercritical\"), but am seeking the answer for $k \\approx \\log(n)$ in particular.\n\nbackground/motivation: question inspired by similar constructions in theoretical computer science circuit theory proofs/theorems.\n\nshare|improve this question\nAsymptotically, for fixed $k\\ge 2$, almost all $K_{k+1}$-free graphs have $K_k$. But except for $k=2$, which is obvious, I'm not even sure that has been proved. \u2013\u00a0 Brendan McKay Mar 29 at 3:36\nParallel to Brendan's comment, if $k$ is larger than order $\\log(n)$, the probability of $\\omega(G)$ being $k+1$ is vanishingly small compared to the probability of $\\omega(G)$ being $k$. I recommend looking at Chapter 7 of Random Graphs by Janson, Luczak and Rucinski. Note that since you have half the edges, looking at the size of a maximum stable set is equivalent to looking at the size of a maximum clique. You should also look at Section 1.4 if you are unfamiliar with the asymptotic equivalence of $G(n,p)$ and $G(n,m)$. \u2013\u00a0 Andrew D. King Mar 29 at 16:31\n@andrew thanks. yes from Erdos-Renyi theory, $\\log(n)$ is the so-called \"critical point\" where existence of k-cliques switches from low (P<0.5) to high (P>0.5) probability, and am looking for the answer in exactly that region where P=0.5. should have mentioned that in the question. will edit \u2013\u00a0 vzn Mar 29 at 16:58\nDo you really expect someone can tell you a formula for the number? If you want asymptotics you should ask for asymptotics. \u2013\u00a0 Douglas Zare Mar 30 at 1:31\n@douglas are you saying a closed form formula is unlikely to exist, or hard to find, etc? \u2013\u00a0 vzn Apr 12 at 18:06\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53595.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nApplied Problems in Maxima and Minima\n\nDate: 08/30/97 at 23:40:40\nFrom: Anonymous\nSubject: Applied problems in maxima and minima\n\ntangent together with the coordinate axes determine a triangle of \nminimum area.\n\nAnswer: (2 (3)^(1/2) / 3, 8 / 3)\n\nPlease show me how to get the answer.\n\nDate: 08/31/97 at 12:38:45\nFrom: Doctor Anthony\nSubject: Re: Applied problems in maxima and minima\n\nWe can simplify the working a little by considering the curve y = x^2, \nand consider the triangle of minimum area formed by a tangent to the \ncurve, the y axis, and the line y = 4.  This allows us to use very \nsimple parametric coordinates (t,t^2) to represent the curve.\n\n  dy/dx = (dy/dt)/(dx/dt) = 2t/1  =  2t\n\nThe equation of the tangent is  \n\n                    y-t^2 = 2t(x-t)\n\nThis meets the y axis where x = 0, so \n\n                    y-t^2 = -2t^2\n\n                        y = -t^2\n\nas expected this is a distance t^2 below the x axis. The vertical side \nof the required triangle will therefore be of length 4+t^2.\n\nThe tangent meets y = 4 where  4-t^2 = 2tx-2t^2\n                             4 + t^2 = 2tx\n\n                                   x = (4+t^2)/2t\n\nArea of triangle  = (1/2)(4+t^2)(4+t^2)/2t\n\n                A = (1/4t)(16 + 8t^2 + t^4)\n\n                  = (1/4)(16/t + 8t + t^3)\n\n            dA/dt = (1/4)(-16/t^2 + 8 + 3t^2)  = 0 for max or min.\n\nSo       3t^2 + 8 = 16/t^2\n\n 3t^4 + 8t^2 - 16 = 0\n\n  (3t^2-4)(t^2+4) = 0    and so  t^2 = 4/3  \n\n                                   t = 2/sqrt(3)\n\nThus the x coordinate is 2/sqrt(3).  This is the same x value as \nfor the equation y = 4 - x^2, and therefore we can substitute \nx = 2/sqrt(3) in this equation to find the y coordinate.\n\n  y = 4 - 4/3 = 8/3\n\nCoordinates of required point   [2/sqrt(3), 8/3]\n-Doctor Anthony,  The Math Forum\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/78698/dissipative-hamiltonian-system-with-a-periodic-force?answertab=active\nText:\nTake the tour \u00d7\n\nLet $H:P \\to \\mathbb{R}$ be a Hamiltonian on a symplectic manifold $(\\omega,P)$ and let $X_H: P \\to TP$ be the Hamiltonian vector-field. Let $F:P \\to T^*P$ be a dissipative force field such that for $Y = \\omega^{\\sharp}(F)$ we have that $Y[H] < 0$ everywhere outside a point $x_0 \\in P$. This makes $x_0$ a stable point of the dissipative Hamiltonian system $(P,\\omega,H,F)$. Now let $f: \\mathbb{R} \\times P \\to T^*P$ be a time-periodic force. My question: Does there exists a periodic orbit (near $x_0$) for the periodically forced system $(P,\\omega,H, F + \\epsilon f)$ for sufficiently small $\\epsilon$ ? I'm sure the answer is yes, but how big can $\\epsilon$ be?\n\nshare|improve this question\nCan you provide a reference explaining what's a \"dissipative Hamiltonian system\"? \u2013\u00a0 Squark Oct 20 '11 at 23:18\nI'm not completely familiar with all your notation, but I assume $Y$ is the vector field corresponding to $F$ and $Y[H]$ the derivative of $H$ with respect to $Y$ that indicates dissipativeness. First of all, is there a reason that the fixed point $x_0$ is stable instead of unstable? Secondly, I would look at the linearized system around $x_0$. If the eigenvalues are strictly negative, then the fixed point must persist. This can be extended to time-periodic or generally time-dependent perturbations. To estimate the size of $\\epsilon$, you need to look at the proof of the stable manifold thm. \u2013\u00a0 Jaap Eldering Oct 21 '11 at 8:35\nThankyou Jaap. I will take a look. Your interpretation of the notation is correct. Secondly, I guess you are right. There is no reason to discriminate the unstable case. For dissipative systems I'd expect to find a stable periodic orbit from a stable point. Under time-reversal a stable equilibria would become an unstable one, and the corresponding stable limit cycle would become unstable as well. \u2013\u00a0 hoj201 Dec 8 '11 at 22:37\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38424/how-do-you-do-an-integral-involving-the-derivative-of-a-delta-function/38450\nText:\nTake the tour \u00d7\n\nI got an integral in solving Schrodinger equation with delta function potential. It looks like\n\n$$\\int \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x}$$\n\nI'm trying to solve this by splitting it into two integrals\n\n$$\\int_{-\\infty}^{x_0 - \\epsilon} \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x} + \\int_{x_0 + \\epsilon}^{\\infty} \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x}$$\n\nand then do the limit $\\epsilon\\to 0$. Could you tell me how to solve this integral please? I used Mathematica, it gave out a weird result.\n\nshare|improve this question\nAre you trying to evaluate $\\int \\left(\\frac{y(x)}{x}\\frac{d\\delta(x-x_{0})}{dx}\\right)dx$ for an arbitrary $y(x)$? I don't understand your statement about the limits, either, are you evaluating two separate integrals with limits $\\int_{-\\infty}^{x_{0}-\\epsilon}$ and $\\int_{x_{0}+\\epsilon}^{\\infty}$? \u2013\u00a0 Jerry Schirmer Sep 26 '12 at 23:16\nThanks Jerry. Yes it is. Basically it is a part of the radial part of my Schrodinger equation and y[x] is radial component and delta function is my potential function. There is a derivative of the potential function. I am trying to solve the equation for the delta function barrier about xo.Finally I can take the limit of e->0. \u2013\u00a0 nagendra Sep 26 '12 at 23:21\nI wonder if perhaps this would be better off at Mathematics? (I'll migrate it if that is the case) \u2013\u00a0 David Z Sep 26 '12 at 23:30\n@DavidZaslavsky: it is primarily a mathematics question, but of the type that physicists will care about more than mathematicians. I'll answer this soon. \u2013\u00a0 Jerry Schirmer Sep 26 '12 at 23:41\n@Jerry yes, but I still think those sorts of questions should be sent to math.SE. \u2013\u00a0 David Z Sep 27 '12 at 3:29\nadd comment\n\n4 Answers\n\nup vote 9 down vote accepted\n\nThe $\\delta$ function is not continuous, so it's a priori not differentiable. In fact, it's not even well-defined as an ordinary real-valued function, but can be made so in terms of distributions - linear maps on a space of test functions given by $f\\mapsto\\int\\delta f=f(a)$.\n\nIt's possible to sensibly define derivatives of distributions by looking at representations as limits of functions:\n\nIf $\\delta_i$ is a family of functions so that $\\lim_{i\\rightarrow\\infty}\\int\\delta_i(x) f(x)\\mathrm dx=f(a)$ for any test function $f$, then it can be considered a representation of the Dirac delta. Now, if we take the family of derivatives $\\frac{\\mathrm d}{\\mathrm dx}\\delta_i$ we arrive at $$ \\int\\left[\\frac{\\mathrm d}{\\mathrm dx}\\delta_i(x)\\right]f(x)\\mathrm dx=-\\int\\delta_i(x)\\left[\\frac{\\mathrm d}{\\mathrm dx}f(x)\\right]\\mathrm dx $$ through integration by parts and using the fact that $f$ has by definition compact support (which makes the boundary term vanish).\n\nAs the derivative is linear as well, this defines another linear map $f\\mapsto-\\int\\delta f'$ on the space of test functions, which we call the derivative of our distribution.\n\nSymbolically, $$ \\left[\\frac{\\mathrm d}{\\mathrm dx}\\delta(x-a)\\right]f(x)=-\\delta(x-a)f'(x) $$ which you can just plug in into your formula above without any need for actual computation as it holds true by definition.\n\nshare|improve this answer\nDear Christoph. Just to clarify that the derivatives is only for the DiracDelta function. What about in that case? \u2013\u00a0 nagendra Sep 27 '12 at 13:03\n@Nagendra: added some parens to clarify - I believe this is the case you're interested in \u2013\u00a0 Christoph Sep 27 '12 at 13:48\nadd comment\n\nSo, the properties of the derivative of the delta function can be shown relatively quickly though the following ansatz: Consider a function $\\delta(x)$ such that $\\delta(x) = \\frac{1}{a^{2}}(x+a)$ if $-a<x<0$ and $\\delta(x) = \\frac{1}{a^{2}}(a-x)$ if $0<x<a$, and $\\delta(x) = 0$ elsewhere. It is easy to see that $\\delta(x)$ has area 1 irrespective of the value of $a$, so we can consider $\\delta(x)$ to be the dirac delta function in the limit $a\\rightarrow0$.\n\nNow, consider the derivative of our putative delta function. It will be $\\frac{1}{a^{2}}$ for $-a<x<0$ and $-\\frac{1}{a^{2}}$ for $0<x<a$. Let's integrate a function $f(x)$ against $\\delta^{\\prime}(x)$:\n\n$\\begin{align} \\int \\delta^{\\prime}(x)f(x)dx &= \\int_{-a}^{0}\\frac{f(x)}{a^{2}}dx - \\int_{0}^{a}\\frac{f(x)}{a^{2}}dx\\\\ &=\\int_{0}^{a}\\frac{f(-x)}{a^{2}}dx-\\int_{0}^{a}\\frac{f(x)}{a^{2}}dx\\\\ \\end{align}$\n\nExtracting the $a^{2}$ out of the integral, and taking the limit $a\\rightarrow0$, we find, after applying L'Hopital's rule once, and then using the definition of the derivative:\n\n$\\int \\delta^{\\prime}(x)f(x) = -f'(0)$\n\nshare|improve this answer\nThanks Jerry. Hope it would work for the limiting point xo. Let me check it with my problem. \u2013\u00a0 nagendra Sep 27 '12 at 2:04\nadd comment\n\nThe Dirac delta function is often defined as the following distribution:\n\n$$\\int_a^b \\delta(x - x_0) F(x)\\mathrm{d}x = \\begin{cases}F(x_0), & a < x_0 < b \\\\ 0, & \\text{otherwise}\\end{cases}$$\n\nwhere $F$ is a suitable test function. Its derivative is then defined as\n\n$$\\int_a^b \\delta'(x - x_0) F(x)\\mathrm{d}x = -\\int_a^b \\delta(x - x_0) F'(x)\\mathrm{d}x$$\n\nwhich is also the result one would get from naively applying integration by parts. You can use this result directly to calculate your integral by setting $F(x) = \\frac{y(x)}{x}$ - no need to split the integral or take any limits.\n\nshare|improve this answer\nadd comment\n\nAs noted above, if $x_0$ a regular point of the integrand one calculates the value of the desired integral simply by substituting this point in the derivative with appropriate choice of sign. The interesting part is when the singularities of the integrand and the delta derivative coincide, i.e., where $x_0=0$. In order to compute the integral in this case we use the fact that $$\\delta_0'=\\lim_{\\epsilon \\to 0^+}\\frac{\\delta_\\epsilon-\\delta_{-\\epsilon}}{2 \\epsilon},$$ the limit being in the distributional sense. A back-of-an-envelope calculation suggests that this is only defined if $y(0)=0$ and that the integral is then $\\dfrac{y''(0)}2$. (Note that since the integrand is not a smooth function, the integral is not a priori defined).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/49963/su3-gauge-invariance-in-qcd/49972\nText:\nTake the tour \u00d7\n\nIn QCD, the gauge-invariant lagrangian under the trasformation\n\n$ \\psi \\to \\psi' = e^{ig T^a \\theta^a(x)} \\psi$\n\nis written as:\n\n$\\mathcal{L} = \\bar{\\psi}(i\\gamma^\\mu D_\\mu - m)\\psi - \\frac{1}{4}G^a_{\\mu\\nu}G_a^{\\mu\\nu}$\n\nwhere the covariant derivative is:\n\n$D_\\mu = \\partial_\\mu - ig T^a G^a_\\mu$\n\nand the field strength tensor is defined as:\n\n$ G^a_{\\mu\\nu} = \\partial_\\mu G^a_\\nu - \\partial_\\nu G^a_\\mu + g f_{abc} G^b_\\mu G^c_\\nu $\n\nIf I impose the gauge-invariance, I find that the gauge field transforms as:\n\n$ G^a_\\mu \\to G'^a_\\mu = G^a_\\mu + \\partial_\\mu \\theta^a $\n\nAm I correct? I think I am, but if I look at how the field strength transforms, I expect it to remain invariant, but instead I find an extra term:\n\n$ G^a_{\\mu\\nu} \\to G^a_{\\mu\\nu} + g_s f_{abc}(\\partial_\\mu \\theta^b \\partial_\\nu \\theta^c + \\partial_\\mu \\theta^b G^c_\\nu + \\partial_\\nu \\theta^c G^b_\\mu) $\n\nDoes this term vanish? Why? Or am I totally wrong on the transformation of the gauge field...?\n\nshare|improve this question\nFor nonabelian gauge fields the gauge field should transform as $A^a_\\mu \\rightarrow A^a_\\mu + (D_\\mu \\theta)^a$. \u2013\u00a0 DJBunk Jan 12 at 0:39\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe Gauge field transforms as $$ G_{\\mu}^{i}\\frac{\\lambda^{i}}{2} \\rightarrow G_{\\mu}' = uG_{\\mu}u^{-1}+\\frac{i}{g}u\\partial_{\\mu}u^{-1} $$ with $u \\in SU(3)$ such that $$ u^{-1}(x)=\\exp (-i\\alpha^i \\lambda^i /2) $$ this can be expanded in a series for infinitesimal transformations.\n\n\nexpanding $u^{-1}$ $$ u^{-1} \\approx 1 -i\\alpha^i \\lambda^i/2 + \\mathcal{O}(\\alpha^2) $$ you can preform this expansion for both $u$ and it's inverse to first order and make sure to keep everything to first order in $\\alpha$, it will include a commutator.\n\nshare|improve this answer\nCan you elaborate the expansion? Is the usual expression for the derivative of an exponential not valid for matrix exponentials? \u2013\u00a0 Ganondolf Jan 11 at 22:32\n@Ganondolf see the update. \u2013\u00a0 k\u03b7ives Jan 11 at 23:18\nUhm, I think I sorted out... Most probably I missed a commutator in the interaction term, which accounts for an extra term in the transformation of G. More important, as you suggested I should keep everything to first order, that should be the way to transform correctly the field strength tensor. I still don't know how exactly, but now I should be on the right way... Dropping the problem now for lack of time, but at least I saw the light at the end of the tunnel. Thank you. \u2013\u00a0 Ganondolf Jan 12 at 0:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/37877/finding-psix-t-for-a-free-particle-starting-from-a-gaussian-wave-profile?answertab=active\nText:\nTake the tour \u00d7\n\nConsider a free-particle with a Gaussian wavefunction,\n\n$$\\psi(x)~=~\\left(\\frac{a}{\\pi}\\right)^{1/4}e^{-\\frac12a x^2},$$ find $\\psi(x,t)$.\n\nThe wavefunction is already normalized, so the next thing to find is coefficient expansion function ($\\theta(k)$), where:\n\n$$\\theta(k)=\\int_{-\\infty}^{\\infty} \\psi(x)e^{-ikx} \\,dx.$$ But this equation seems to be impossible to solve without error function (as maple 16 tells me).\n\nIs there any trick to solve this?\n\nshare|improve this question\nI am a bit confused, why are you trying to find $\\psi (k)$ ? Or as you write it, $\\theta (k)$ ? \u2013\u00a0 DJBunk Sep 20 '12 at 23:06\nCan you put what you ran through maple 16? \u2013\u00a0 Magpie Apr 8 at 1:38\nadd comment\n\n1 Answer\n\nYour question seems rather confused,\n\n  \u2022 First you ask for the time evolution of the wavefunction. For this you will need to use the Schr\u00f6dinger equation $i \\partial \\psi/\\partial t= \\hat H \\psi $ and thus will need to know the Hamiltonian ($\\hat H$).\n  \u2022 Second you seem to want to work out the Fourier transform of the wavefunction. This will not give you the wavefunction as a function of time but will give you the wavefunction in momentum space. The integral you want to calculate is the Fourier transform of a Gaussian which is itself a Gaussian: $$\\int_{-\\infty}^{\\infty} e^{-ax^2/2}e^{-i k x} \\, dx \\\\ = \\int_{-\\infty}^{\\infty} e^{-ax^2/2}\\left(\\cos{kx} - i \\sin{kx} \\right) \\, dx .$$ The second term in the above integral is odd so will give zero. The first term is a known integral and gives $$=\\sqrt{\\frac{2\\pi}{a}} e^{-k^2/2 a} , $$ a Gaussian as promised with width inversey proportional to the original.\n\nI am pretty certain Maple should also be able to calculate the integral for you as it is written in my fist line (Mathematica can), so I imagine you are just not entering it correctly.\n\nEdit: Apologies for the first comment above. I had not seen that you had written this was for a free particle, so indeed you know the Hamiltonian, the potential is $V(x,t)=0$, and so from Schr\u00f6dinger's equation we know the time evolution of the energy Eigenstates is $\\psi(x,t)=e^{-i \\omega t}\\psi(x)$. For the free particle we have $\\omega=k^2/2m$ and so you know the time evolution of the Fourier transform.\n\nSo taking the Fourier transform given above, applying the time evolution, and transforming back to position space we have $$\\psi(x,t)=\\int_{-\\infty}^{\\infty} e^{-k^2/2 a}e^{-i\\omega t}e^{ikx} \\, dk \\\\ =\\int_{-\\infty}^{\\infty} e^{-\\frac{k^2}{2 a}(1+iat/m)}e^{ikx}\\, dk \\\\ \\sim e^{\\frac12 \\frac{x^2}{1/a+imt}}$$ as #Ron pointed out in his comment. This shows how the wavepacket spreads out with time.\n\nshare|improve this answer\nThe fourier trasnform evolves by simple phases, and a reverse fourier transform gives the time evolution, which is a spreading Gaussian, so that the a gets replaced everywhere by ${1\\over {(1/a)+it}}$ \u2013\u00a0 Ron Maimon Sep 21 '12 at 6:48\nOh yeah, hadn't seen the part saying this was for a free particle (doh!). Have added an edit to the answer to complete it. Thanks for pointing that out. \u2013\u00a0 Mistake Ink Sep 21 '12 at 13:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/68908/is-the-f-t-of-operatornamespan-mathscr-s-mathbb-r2-otimes-mathscr-dd/69105\nText:\nTake the tour \u00d7\n\nLet $K$ be the real vector space generated by elements $f$ in $\\mathscr S(\\mathbb R^2,\\mathbb R)\\otimes\\mathscr D(D, \\mathbb R)$, where $D$ is any bounded subset of $\\mathbb R^2$. Let $\\hat K$ be the vector space generated by the Fourier transform of each $f\\in K$, i.e. $\\hat K = \\{\\hat f\\ |\\ f\\in K\\}$. Is $\\hat K+i\\hat K$ dense in $L^2(\\mathbb R^4)$?\n\nshare|improve this question\nCould you please clarify the notation? One of the spaces is Schwartz space, I presume; what's the other one? \u2013\u00a0 Captain Oates Jun 27 '11 at 9:18\nI think the second factor is test functions with support in D. I am not sure if D is supposed to be fixed or arbitrary. Either way, this question has the flavor of homework. \u2013\u00a0 Michael Renardy Jun 27 '11 at 10:01\nI guess $\\mathscr D$ are smooth functions with compact support. If $L^2(\\RR^4)$ is the complex space i guess this is not true, because the Furiertransform of some real function has some symmetry, and otherwise the Fourier transform does not make sense to me. \u2013\u00a0 Marcel Bischoff Jun 27 '11 at 20:11\nProbably this question is not approriate for here. But if I know understand your notation correctly, if you take a function that has support outside of D then the Fourier transform is orthogonal to your space, or not? So it would not be dense. The situation is different if you restrict the fourier transform to something lying in some \"cone\". Then you end up to some situation similar to the Reeh-Schlieder Theorem in Quantum Field Theory. I recommened you to look into the books of Reed and Simon. \u2013\u00a0 Marcel Bischoff Jun 28 '11 at 10:56\n\"Probably this question is not appropriate for here\"... actually I don't see why. At most, one may ask the OP to provide some motivation and details, as explained in the section \"how to ask\". \u2013\u00a0 Pietro Majer Jul 27 '11 at 11:30\nshow 1 more comment\n\n1 Answer\n\nI'm sorry if this is not the appropriate place to ask such questions. I'll be more careful next time. By the way my question is strongly related to an actual problem in QFT (actually QFT on QST). I'm not sure about M. Bischoff conclusion on orthogonality pointed out in one of the comments to the question.\n\nThere is a result from Araki that state that the real Hilbert subspace of the one-particle Hilbert space $K(O)=\\{\\hat f\\big\\vert_{\\Omega_m^+}\\ |\\ f\\in\\mathscr D(O,\\mathbb R)\\}$, where $\\Omega_m^+$ is the hyperboloid of mass $m$ in the future light-cone and $O\\subset\\mathbb R^4$ is a non-empty simply connected bounded open subset of $\\mathbb R^4$, is standard, i.e. $\\overline{K(O)+iK(O)}$ is dense and $K\\cap iK=\\{0\\}$. The vector space $\\hat K$ I defined in the question ought to contain such a vector space $K(O)$ associated with a region $O\\subset\\mathbb R^2\\times D$, where $D$ satisfies some suitable regularity condition (e.g. regular boudary, simply connectedness,...) and therefore $K(O)\\subset \\hat K$, that would imply $\\hat K$ standard, according to the result from Araki.\n\nshare|improve this answer\nBut the important fact is the restriction to the mass shell, because then the \"two-point function\" (which is essentially the scalar product written is tempered distribution) is an analytic function in some tube region, because the Fourier transform has support in some cone. Then using the Edge of the Wedge theorem one can show that a vector orthogonal to your set is already the zero vector. This can be found eg. in Streater-Wightmann etc under Reeh-Schlieder theorem (the original article is german). If you do not restrict I think my argument says it will be not dense anymore. \u2013\u00a0 Marcel Bischoff Jul 4 '11 at 19:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/74055/the-cantor-function-is-surjective-and-continuous\nText:\nTake the tour \u00d7\n\nHow can I prove that the Cantor function is surjective and continuous?\n\nThe part, I think that the cantor function is monotonic and surjective, if I prove this, it is easy to prove that this implies continuity. The way to prove that is surjective, it's only via an algorithm, I don't know if this can be proved in a different way, more elegant. And the monotonicity I have no idea, I think that it's also via an algorithm.\n\n\nshare|improve this question\nSee Problems in real and complex analysis By Bernard R. Gelbaum, pages 17 and 155. \u2013\u00a0 Martin Sleziak Oct 19 '11 at 18:20\nComment (I don't have enough points to post a comment, sorry): A delta-epsilon proof is not too hard. \u2013\u00a0 gary Oct 19 '11 at 20:49\nadd comment\n\n1 Answer\n\nLet $f$ be the Cantor function. Let $y\\in[0,1]$. Let $0.d_1d_2d_3\\ldots$ be the binary expansion of $y$. Let $x$ be the number whose ternary expansion is $0.(2d_1)(2d_2)(2d_3)\\ldots\\ {}$. Then $f(x)=y$. For numbers with non-unique binary expansions, one gets two ternary expansions that do not represent the same number; call them $x_1 < x_2$. Then for all $x\\in [x_1,x_2]$, $f(x)=y$.\n\nAs for continuity, if a weakly monotone function has a discontinuity, it is a jump, so then the function cannot be surjective.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/143046/counting-number-of-linear-transformations\nText:\nTake the tour \u00d7\n\nLet $v_{1} = (1, 0)$, $v_{2} = (1, -1)$ and $v_{3} = (0, 1)$. How many linear transformations $T :\\mathbb {R^2}\\rightarrow \\mathbb {R^2} $ are there such that $T(v_{1} ) = v_{2}$, $T(v_{2} ) = v_{3}$, $T(v_{3} ) = v_{1}$. I am finding difficulty in tackling to this problem. I tried to identify corresponding linear transformation. But didn't come to any conclusion.It should be either 0, 1, 3 or $3!$\n\nshare|improve this question\nCan you find even one such transformation? \u2013\u00a0 Chris Eagle May 9 '12 at 12:46\nThat's what i am asking. i think answer should be zero. But how to show? \u2013\u00a0 srijan May 9 '12 at 12:48\nRemember that once you have defined a linear map on a basis, you can work out what its value has to be on any other vector. \u2013\u00a0 Matt Pressland May 9 '12 at 12:49\nIf you have some ideas about the problem (like that the answer is zero), then put them in your question. \u2013\u00a0 Chris Eagle May 9 '12 at 12:49\ni have added sir..it should be either 0 , 1 , 3 or 3! \u2013\u00a0 srijan May 9 '12 at 12:51\nshow 3 more comments\n\n1 Answer\n\nup vote 3 down vote accepted\n\n$v_2 = v_1-v_3$, so you'd need: $$ v_3 = T(v_2) = T(v_1-v_3)=T(v_1)-T(v_3) = v_2-v_1$$ which is not true.\n\nshare|improve this answer\nI think a hint would probably have been more helpful than a complete answer. (I'm just bothering to say this because I upvoted your answer, and then realised that I don't like the fact that complete answers to easy questions get disproportionately many upvotes, so upvoting it perhaps didn't make sense.) \u2013\u00a0 Tara B May 9 '12 at 13:12\n@Tara B: Unless the OP merely copies the above answer, there is work for the OP to do in order to see that the above does answer the question. \u2013\u00a0 Andr\u00e9 Nicolas May 9 '12 at 13:31\n@TaraB Actually, I agree with you, I probably should have just given a hint. Sometimes, my eagerness to answer overrides the filter that asks, \"What kind of answer is best for this user?\" I'll leave it as is, since I'll guess the OP has already read it, but will keep trying to improve my instincts for future answers. \u2013\u00a0 Thomas Andrews May 9 '12 at 13:39\n@Andr\u00e9Nicolas: That's true, but I think there's still more benefit to be gained from working out the rest from a hint than from figuring out why an answer works. \u2013\u00a0 Tara B May 9 '12 at 13:46\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/253958/how-to-show-that-the-complete-elliptic-integral-of-the-first-kind-increases-in-m?answertab=votes\nText:\nTake the tour \u00d7\n\nHow can you show that the complete elliptic integral of first kind $ \\displaystyle K(m)=\\int_0^\\frac{\\pi}{2}\\frac{\\mathrm du}{\\sqrt{1-m^2\\sin^2 u}}$ that is the same as a series $$K(m)=\\frac{\\pi}{2} \\left(1+\\left(\\frac{1}{2}\\right)^{2}m^2 +\\left(\\frac{1\\cdot 3}{2\\cdot 4}\\right)^{2}m^4 +...+ \\left(\\frac{(2n-1)!!}{2n!!} \\right )^2m^{2n} + ... \\right)$$\n\nincreases in m?\n\n\nshare|improve this question\nThe expansion of the integral you wrote has terms for every odd power of $m$ as well. \u2013\u00a0 Did Dec 8 '12 at 20:56\nIm sorry, can you explain again? something wrong on the expansion? \u2013\u00a0 JHughes Dec 8 '12 at 21:58\nYes, something was definitely wrong with the expansion... But it seems you saw the problem since you made the necessary correction. Note that this makes the accepted answer, which addresses (incorrectly) the original version of your question, a little odd. \u2013\u00a0 Did Dec 8 '12 at 23:42\nyeah yeah, thx, i already correct it. \u2013\u00a0 JHughes Dec 11 '12 at 1:24\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou can show that the derivative with respect to $m$ is always positive:\n\nNote that $$K'(m)=\\int_0^\\frac{\\pi}{2}\\frac{m \\sin^2 u\\, du}{(1-m^2\\sin^2 u)^{3/2}} \\geq 0$$ as the integrand is positive for all $0\\leq m \\leq 1$.\n\nshare|improve this answer\nThe numerator $m\\sin u$ should read $\\frac12\\sin^2u$. \u2013\u00a0 Did Dec 8 '12 at 23:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/504063/show-sum-limits-dn-phid-n\nText:\nTake the tour \u00d7\n\nThis question already has an answer here:\n\nShow $\\sum\\limits_{d|n}\\phi(d) = n$.\n\nExample : $\\sum\\limits_{d|4}\\phi(d) = \\phi(1) + \\phi(2) + \\phi(4) = 1 + 1 + 2 = 4$\n\nI was told this has a simple proof. Problem is, I can not think of a way to show this in a very simple and straightforward way.\n\nshare|improve this question\nShow it for prime powers (elementary), and then show that the sum is a multiplicative function, that means for $m,n$ coprime, you have $$\\sum_{d\\mid mn} \\phi(d) = \\left(\\sum_{e \\mid m} \\phi(e)\\right)\\left(\\sum_{g\\mid n}\\phi(g)\\right).$$ \u2013\u00a0 Daniel Fischer Sep 24 at 22:28\nAlternatively consider the set of cyclic subgroups of the multiplicative group and their corresponding orders. \u2013\u00a0 Alex R. Sep 24 at 22:32\nSince this came from an abstract algebra course your idea Alex is probably the right direction to head in. Would you be able to provide an example of what your talking about Alex? \u2013\u00a0 Steve Thomas Sep 24 at 22:43\nadd comment\n\nmarked as duplicate by lhf, Rick Decker, Daniel Rust, Danny Cheuk, Rebecca Sep 25 at 0:50\n\n\n5 Answers\n\nHint: You can show that $\\sum\\limits_{d|n}\\phi(d) = \\sum\\limits_{d|n}\\phi(\\frac{n}{d}) $ but $\\phi(\\frac{n}{d})$ is all numbers with GCD of $d$ with $n$. Therefore the last sum counts all numbers till $n$ and is equal to $n$.\n\nshare|improve this answer\nNice reindexing argument. (+1) \u2013\u00a0 robjohn Sep 24 at 22:49\n@robjohn, Thanks a lot! \u2013\u00a0 Arash Sep 25 at 13:36\nadd comment\n\nLet $G=\\langle x\\rangle$ be the cyclic group of order $n$ generated by $x$. Then, \\begin{align} n &= |G| \\\\ &= \\sum_{1\\leq d\\leq n} |\\{\\text{elements of order } d\\}| \\\\ &= \\sum_{d|n}|\\{\\text{elements of order } d\\}| \\end{align} by Lagrange's Theorem. But $G$ has a unique cyclic subgroup of order $d$ for each $d|n$, namely $\\langle x^{n/d}\\rangle$. Moreover, each such subgroup has $\\varphi(d)$ generators, so $$n = \\sum_{d|n}\\varphi(d)$$\n\nshare|improve this answer\nadd comment\n\nHere's one approach:\n\nConsider the polynomial $x^n-1$ as a polynomial over the complex numbers $\\mathbb{C}$. You can easily see, almost tautologically, that\n\n$$x^n-1=\\prod_{d\\mid n}\\Phi_d(x)\\qquad(\\ast)$$\n\nwhere $\\Phi_d(x)$ is the polynomial whose roots are the primitive $d^{\\text{th}}$ roots of unity (i.e. solutions to $x^d-1$ that do not satisfy $x^c-1$ for $0<c<d$).\n\nBut, rephrasing the definition, $\\Phi_d(x)$ is the polynomial with roots $e^{\\frac{2\\pi i r}{d}}$ where $e^{\\frac{2\\pi r s}{d}}\\ne 1$ for $0<s<d$. But, this is saying that $sr\\not\\equiv 0\\mod d$ for $0<s<d$, or that $d$ and $r$ have no common factors. Since we only need to care about $r$ which are less than or equal to $d$ we see that, in fact, the are $\\phi(d)$ such roots of $\\Phi_d(x)$.\n\nThis allows us to conclude that $\\deg \\Phi_d(x)=\\phi(d)$. Indeed, since $\\Phi_d(x)\\mid x^n-1$, and $x^n-1$ has no repeated roots in $\\mathbb{C}$ (it's coprime to its derivative) we see that $\\Phi_d(x)$ has no repeated roots. Thus, $\\deg\\Phi_d(x)$ is the number of roots of $\\Phi_d(x)$ which is $\\phi(d)$.\n\nSo, by comparing degrees in $(\\ast)$ we get:\n\n$$n=\\sum_{d\\mid n}\\deg\\Phi_d(x)=\\sum_{d\\mid n}\\phi(d)$$\n\nshare|improve this answer\nCool proof. +1'ed. \u2013\u00a0 Pedro Tamaroff Sep 24 at 23:27\nadd comment\n\nThe simplest proof I know is this:\n\nConsider all proper fractions of the form $a/n$. There are $n$ of those. When you consider their reduced forms you get fractions of the form $b/d$ with $d|n$ and $(b,d)=1$. By definition, there are $\\phi(d)$ of those. The result follows.\n\nshare|improve this answer\nadd comment\n\nConsider the set $[n]=\\{1,1,2,\\ldots,n\\}$ of size $n$. Define an equivalence relation as follows $$m\\sim m'\\iff (m,n)=(m',n)$$ That this is an equivalence relation should be clear. The equivalence classes are of the form $$\\widehat m=\\{0<m'\\leqslant n:(m',n)=d\\}$$ where $d=(m,n)\\mid n$. Now, what is the size of this class? It contains all positive elements $m'\\leqslant n$ such that $(m',n)=d$, or what is the same, all positive elements $$\\frac{m'}d\\leqslant \\frac nd$$ such that $$\\left(\\frac{m'}{d},\\frac nd \\right)=1$$\n\nThis amounts to $\\varphi\\left(\\dfrac nd\\right)$ elements. But there is one class for each positive divisor of $n$, thus we have paititioned our set getting $$n=\\sum_{d\\mid n}\\varphi\\left(\\dfrac nd\\right)$$\n\nBut as $d$ runs through all divisors of $n$; so does $\\dfrac nd$, so that $$n=\\sum_{d\\mid n}\\varphi(d)$$\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://mathoverflow.net/questions/124032/how-do-you-prove-that-every-curve-of-constant-width-is-convex/124044\nText:\nTell me more \u00d7\n\nCross-posted from math.stackexchange:\n\nLet C be a simple closed plane curve and let D be its interior. Recall that the width of C in a direction \u03b8 is the distance between two supporting lines for D which are perpendicular to \u03b8. A curve is said to have constant width if its width is the same in every direction; see the Reuleaux polygons for nontrivial examples.\n\nIt is often stated (for instance in \"The Enjoyment of Math\" by Rademacher and Toeplitz) that curves of constant width are necessarily convex. Does anyone know how to prove this? I can't find any references, and a proof eludes me.\n\nshare|improve this question\nHere is the question on \u2013\u00a0 Yoav Kallus Mar 8 at 23:58\nadd comment\n\n2 Answers\n\nFirst, observe that for a closed convex region $R$ of constant width $w$, there can be no interval $[a,b]\\subset \\partial R$. For take the support line $l$ to $R$ containing $[a,b]\\subset l$, and let $c$ be a point in the other parallel support line for $R$ realizing the width $w$. Then the height of the triangle $abc$ is $w = d(c,l)$. However, the distance $w<\\max\\{d(a,c),d(b,c)\\}$, and therefore the width of $R$ will be greater that the maximum of these two distances by choosing the support lines perpendicular to the longer side, contradicting constant width.\n\nNow, suppose $K$ is a constant width region, and let $R$ be the convex hull of $K$. If $K \\neq R$, then there exists an interval $[a,b]\\subset \\partial R-\\partial K$, a contradiction.\n\nshare|improve this answer\nThis is basically the answer given on, so I wonder what Paul found unsatisfying about the answer there. \u2013\u00a0 Yoav Kallus Mar 9 at 1:49\nOh, I didn't notice the stackexchange link until posting my answer. I guess there's the fact that the part of the boundary of the convex hull which doesn't lie on the boundary of $K$ is composed of open intervals, which is pretty standard. \u2013\u00a0 Ian Agol Mar 9 at 2:00\nI'm convinced, thanks! \u2013\u00a0 Paul Siegel Mar 9 at 14:48\nadd comment\n\nSay that the compact set $K \\subset \\mathbb{R}^2$ of constant width $d$ is not convex; then there is some support line that touches two points, say $A$ and $B$ on $\\partial K$. The parallel line that supports $K$ \"from the other side\" touches at least one point $C \\in \\partial K$. The distance between these two lines is the constant width $d$.\n\nBut either the distance $\\overline{AC}$ or $\\overline{BC}$ (or both) is strictly larger than $d$, so the width in the direction orthogonal to that line is larger than $d$ and $K$ has not constant width.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49799/a-graph-with-few-edges-everywhere\nText:\nTake the 2-minute tour \u00d7\n\nGiven a graph $G(V,E)$ whose edges are colored in two colors: red and blue. Suppose the following two conditions hold:\n\n  \u2022 for any $S\\subseteq V$, there are at most $O(|S|)$ red edges in $G[S]$\n  \u2022 for any $S\\subseteq V$, if $G[S]$ contains no red edges, then it contains $O(|S|)$ blue edges\n\nMy question is: can we conclude from this that the total number of blue edges is linear? I have no strong intuition for this, but it seems that it might be possible (some averaging/probabilistic argument?). To try to give an intuition, we can rephrase it as follows. The red graph is very sparse, even locally. The blue graph is also sparse in all regions that are free of red edges. Due to the sparseness of the red graph those 'regions' are numerous, so we hope this might imply that the blue graph is also sparse.\n\nOne can maybe consider first an easier version, if we assume that the red degree of every vertex is $O(1)$. In this case I also don't know the answer.\n\nNote that it's already too weak if we replace the first condition with just: the total number of red edges is linear. Look at the example: a blue $K_{\\sqrt n,n-\\sqrt n}$ with a red $\\sqrt n$-clique added in the corresponding part. This graph has $\\Omega(n^{3/2})$ blue edges (example by D. Palvolgyi). We can still ask in this version whether one can do better than $n^{3/2}$.\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 12 down vote accepted\n\nI think one can push through the probabilistic arguments of Tim Gowers and Fedor Petrov in the general case, as follows.\n\nLet $c$ be a constant such that the number of red edges in $G[S]$ is at most $c|S|$ for every $S \\subseteq V(G)$. One can order the vertices of $G$: $v_1, v_2, \\ldots, v_n$, so that every vertex has at most $2c$ neighbors with lower indices. (Define the ordering starting with the highest index. If $v_n, \\ldots,v_{i+1}$ are defined, set $v_i$ to be the vertex with the smallest degree in the subgraph induced by the vertices which are not yet indexed. This is a standard trick.)\n\nNow we define a random subset $S$ of $V(G)$ recursively: if $S \\cap$ {$v_1, \\ldots, v_i$} is chosen put $v_{i+1}$ in $S$ with probability $1/2$ if it is not joined by a red edge to any of the vertices already in $S$, otherwise don't put it in $S$. Then $S$ is red-free and, just as in Fedor's answer, we can see that the probability that a pair of vertices $u$ and $v$ joined by a blue edge both lie in $S$ is at least $2^{-4c-2}$. Therefore the number of blue edges is at most\n\n$2^{4c+2}c' \\mathbf{E}[|S|] \\leq 2^{4c+1}c'|V(G)|,$\n\nwhere $c'$ is the constant implicitly present in the condition on the density of the blue edges.\n\nshare|improve this answer\nI think you mean that the probability that both ends of a blue edge are chosen is at least $2^{-4c-2}$, and a complete write-up should also account for the additive constants allowed by big-O notation, but I'm convinced this will work. \u2013\u00a0 Tracy Hall Dec 18 '10 at 23:13\n@Tracy: Thank you, corrected $2c$ to $4c$. Additive constants in big-O could be absorbed into multiplicative ones. \u2013\u00a0 Sergey Norin Dec 18 '10 at 23:15\nvery nice proof! thank you all for combined efforts. \u2013\u00a0 filipm Dec 19 '10 at 9:58\n\nSuppose that the red edges can be written as a union of k matchings, $M_1,\\dots,M_k$. Now choose a random set of vertices as follows. For each edge in $M_1$ choose one of its end points randomly. Put in all other vertices with probability 1/2. Then do the same for $M_2,\\dots,M_k$. This gives us sets $A_1,\\dots,A_k$. Let $A$ be the intersection of these sets. Then each vertex has a probability $2^{-k}$ of belonging to $A$. Also, $A$ contains no red edges. More importantly, given a non-red edge, there is a probability $4^{-k}$ that both its end points belong to $A$. If we choose a random pair in $A$, the probability that it is a blue edge is at most $C/n$ for some $C$. I think (I haven't checked carefully enough to be sure) that this does the bounded-degree case, showing that we have at most $4^kCn$ blue edges. Maybe it even does the general case.\n\nshare|improve this answer\nThis certainly does bounded-degree case, since edges of a graph with maximal degree $d$ lie in a union of $d+1$ matchings (it is called Vizing's theorem, $2d-1$ matchings instead $d+1$ is almost obvious). General case may be done, if we replace matchings to trees and then change the probabilistic argument as Sergey suggests: enumerate vertices of each tree by ranges (starting from the root) and take each vertex with probability 1/2 if its (unique) already considered neighbor is not still taken. \u2013\u00a0 Fedor Petrov Dec 19 '10 at 20:52\n\nIt is not an answer, but bounded degree case only. If all red degrees do not exceed $d$. choose random (w.r.t. uniform distribution) red independent set $I$. I claim that for each edge $uv$ both $u$, $v$ belong to $I$ with probability bounded from below. Indeed, denote by $N$ the union of $u$, $v$ and their red neighbors. Then if we fix an intersection of $I$ and $V\\setminus N$, then conditional probability that $u,v$ both lie in $I$ is at least $1/2^{n}$, where $n=|N|\\leq 2d+2$.\n\nshare|improve this answer\n\nHere are just a couple of ideas (too long to fit a comment window). Let $R_i$ and $B_i$ be the red and the blue degrees of the $i$-th vertex. Take your graph and remove all vertices with $B_i\\le MR_i+M$. Take the remaining subgraph and remove all vertices with $B_i\\le MR_i+M$ (using the counts in the remaining subgraph, of course), and so on. No matter how many times we go, we remove at most $O(Mn)$ blue edges. If we stop, we have a graph in which each blue degree is at least $M$ times the corresponding red degree plus $M$.\n\nNow arrange the vertices in random order and select the red-independent set as the set of all vertices that preceede all their neighbors in the ordering. Each vertex $i$ will survive with probability $(R_i+1)^{-1}$. Moreover, if $(i,j)$ is not a red edge, then the probability that both $i,j$ survive is at least $\\frac12(R_i+1)^{-1}(R_j+1)^{-1}$. This puts the expected number of surviving blue edges at $$\\frac 12\\sum_{(i,j)\\in E_{\\text{blue}}}(R_i+1)^{-1}(R_j+1)^{-1}$$ and the expectation of the surviving number of vertices at $\\sum_{i}(R_i+1)^{-1}$.\n\nIf all degrees are bounded by $K$, then we, clearly, have what we want with much better bound than $4^K$. Unfortunately, if the degrees are unbounded, we still have a problem.\n\nshare|improve this answer\nhmm, why probability that a vertex survives is $(R_j+1)^{-1}$? Is not it $(R_j!)^{-1}$? \u2013\u00a0 Fedor Petrov Dec 19 '10 at 14:40\nIt just needs to be the first in the ordering, not to dictate the whole ordering. Anyway, this post is obsolete after Sergei's construction (only, of course, the vertex has to be chosen not with probability $1/2$ but with probability $1/c$ or so, so his survial chance for the pair is $(1-1/c)^{4c}c^{-2}\\approx c^{-2}$). \u2013\u00a0 fedja Dec 19 '10 at 23:09\noh, indeed (stupid me). I think, polynomial estimate is in general better then exponential, and it may be important in some other applications (say, if red degrees slowly grow). \u2013\u00a0 Fedor Petrov Dec 19 '10 at 23:21\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/116608/clifford-algebra-is-graded-separable\nText:\nTake the 2-minute tour \u00d7\n\nLet $D$ be an algebra of odd differential operators on a free module $V$, this algebra is isomorphic to the Clifford algebra $Cl(V^* \\oplus V)$. Let $m$ denote multiplication map $$m : D\\otimes D \\to D.$$ I need an explicit formula for a bimodule splitting of this map or equivalently an element $z \\in D\\otimes D$ s.t. $az=za$ for any $a \\in D$ and $m(z)=1$.\n\nIt is possible to use isomorphism of algebras $Cl(V^* \\oplus V) \\cong End(\\wedge V)$ and for $End(\\wedge V)$ such splitting is given (up to sign) by the same formula as for matrix algebra. So, I know that such splitting exists and I want a nice formula in term of differential operators (or standard generators of Clifford algebra).\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/144190/factoring-a-number-pa-qb-knowing-its-totient/144197\nText:\nTake the 2-minute tour \u00d7\n\nWe are given: $n=p^aq^b$ and $\\phi(n)$, where $p,q$ are prime numbers. I have to calculate the $a,b,p,q$, possibly using computer for some calculations, but the method is supposed to be symbolically valid and proper. I know that $\\phi(n)=p^{a-1}q^{b-1}(p-1)(q-1)$, but I dont know what can I deduct from this.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nWithout loss of generality we can assume that $p<q$. I would first compute the greatest common divisor of $n$ and $\\phi(n)$, $m=\\gcd(n,\\phi(n))$. There are two possibilities.\n\n1) $m=p^{a-1}q^{b-1}$. This happens, if $p$ is not a factor of $q-1$. In this case we can calculate $$ \\frac{n}{m}=pq,\\qquad\\text{and}\\qquad \\frac{\\phi(n)}{m}=(p-1)(q-1)=pq-(p+q)+1. $$ In this case we know $r=p+q$ and $s=pq$, and can solve the primes $p$ and $q$ as the roots of the quadratic equation $$ 0=(x-p)(x-q)=x^2-(p+q)x+pq=x^2-rx+s. $$\n\n2) $m=p^aq^{b-1}$. This happens, if $p$ is a factor of $q-1$. This time $$ \\frac{n}{m}=q,\\qquad\\text{and}\\qquad\\frac{\\phi(n)}{m}=\\frac{(p-1)(q-1)}p. $$\n\nI think that is possible to build a method from these bits alone. I would assume that we have the first case, and then check that it works in a separate verification step. The roots of the quadratic need to be integers, and we can keep on dividing $n$ with the roots to verify that the number $n$ is, indeed, of the form $p^aq^b$. If something goes wrong, then we must have case 2. This time we know $q$ directly, and can solve for $p$ from the equation $$ \\frac1{q-1}\\cdot\\frac{\\phi(n)}{m}=\\frac1{q-1}\\cdot\\frac{(p-1)(q-1)}p=\\frac{p-1}p=1-\\frac1p, $$ because the LHS is known.\n\nUndoubtedly there are alternative ways of exploiting these bits. The key is to compute $m$ first.\n\nshare|improve this answer\nThank you, I was hoping there's some way to avoid the initial case guesswork but I suppose this will have to do. \u2013\u00a0 poe123 May 12 '12 at 12:21\n@poe123, if you knew about this method, you could have said so. And waited for somebody to suggest a clever trick avoiding the verification step :-) No harm done, though! \u2013\u00a0 Jyrki Lahtonen May 12 '12 at 12:25\nOnce you have $t=n/m$ you can repeatedly divide it out of $n$ to get a power of $p$ or $q$ alone. Write $n=t^ku$, then if $u=1$ it's case 1) with $a=b$, otherwise in case 1) $\\gcd(t,u)$ is $p$ or $q$, in case 2) $\\gcd(t,u)$ is 1 and $t=q$. \u2013\u00a0 Zander May 14 '12 at 17:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/85418/expectation-of-log1x-if-x-is-a-gamma-random-variable\nText:\nTake the tour \u00d7\n\nI would like to know if there is a closed form expression for the expectation of log(1+x) when x is a gamma random variable.\n\nThank you.\n\nshare|improve this question\nYes, you may need Digamma function. See en.wikipedia.org/wiki/Polygamma_function \u2013\u00a0 Anand Jan 11 '12 at 15:58\nadd comment\n\n2 Answers\n\nIf $X$ has the gamma distribution with rate $\\lambda$ and shape parameter $n$, you're asking for $$ J(\\lambda, n) = \\frac{\\lambda^n}{\\Gamma(n)} \\int_0^\\infty t^{n-1} e^{-\\lambda t} \\log(1+t)\\ dt = \\frac{1}{\\Gamma(n)} \\int_0^\\infty s^{n-1} e^{-s} \\log(1+s/\\lambda) \\ ds$$\n\nUsing Maple, I get\n\n$$\\Psi \\left( n \\right) -\\ln \\left( \\lambda \\right) +{\\frac { {\\mbox{$_2$F$_2$}(1,1;\\,2,2-n;\\lambda)}\\lambda}{n-1}}+{\\frac { \\left( -1 \\right) ^{-n}\\pi }{\\sin \\left( \\pi n \\right) }}-{\\frac { \\left( -1 \\right) ^{-n}\\pi \\Gamma \\left( n,-\\lambda \\right) }{\\sin \\left( \\pi n \\right) \\Gamma \\left( n \\right) }} $$\n\nwhich seems to be correct when $n$ is a non-integer. For integer values of $n$, the result seems to be $\\frac{\\Gamma(n,-\\lambda)}{\\Gamma(n)} Ei(1,\\lambda)$ plus a polynomial in $\\lambda$ of degree $n-2$.\n\nshare|improve this answer\nadd comment\n\nI may be mistaken, but if you are making the change of variable $s = \\lambda t$, shouldn't there be an extra factor of $\\lambda$ outside the integral?\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49365/does-every-symmetric-group-s-n-have-a-single-element-of-maximal-word-norm\nText:\nTake the tour \u00d7\n\nGenerate $S_n$ by transpositions $s_i$ of (i) and (i+1). Both $S_3$ and $S_4$ have single elements of maximal word norm associated with this presentation. In fact, the Cayley graph of $S_3$ can be seen as a tiling of $S^1$, and the Cayley graph of $S_4$ a tiling of $S^2$. The element of maximal length is then antipodal to e.\n\nDoes every symmetric group $S_n$ have a single element of maximal word norm? If so, is there a formula for its length l(n)?\n\nshare|improve this question\nThanks for the answers. All are helpful - both the basic proof and bigger theory. \u2013\u00a0 ian Dec 14 '10 at 14:57\nadd comment\n\n5 Answers\n\nup vote 23 down vote accepted\n\nIt is amazing how a fact that I was taught in a middle school can be proved using big theories where I don't understand half of the words. Let me add a straightforward proof (for $S_n$ and only $S_n$).\n\nFor a permutation $\\sigma:\\{1,\\dots,n\\}\\to\\{1,\\dots,n\\}$, let $\\lambda(\\sigma)$ denote the number of inversions in $\\sigma$, that is the number of pairs $(i,j)$ such that $i<j$ and $\\sigma(i)>\\sigma(j)$. Then $\\lambda(\\sigma)$ equals the length of $\\sigma$ with respect to the generating set $\\{s_i\\}$.\n\nIndeed, left-multiplying $\\sigma$ by $s_i$ only interchanges $\\sigma(i)$ and $\\sigma(i+1)$, and hence changes $\\lambda(\\sigma)$ by at most 1. Therefore the length is bounded below by $\\lambda$. On the other hand, if $\\sigma$ is not the identity, there exists $i$ such that $\\sigma(i+1)<\\sigma(i)$, then left-multiplying by $s_i$ decreases $\\lambda(\\sigma)$ by 1. Repeating this procedure, one reaches the identity from $\\sigma$ by exactly $\\lambda(\\sigma)$ multiplications by generators.\n\nNow it is clear that the maximum length equals $n(n-1)/2$ and is attained only at the order reversing permutation (the one given by $\\sigma(i)=n+1-i$ for all $i$).\n\nshare|improve this answer\n+1 for the first sentence :) \u2013\u00a0 JBL Dec 14 '10 at 12:40\nTo combine with Qiaochu's answer: inversions $\\sigma(i)>\\sigma(j)$ correspond to flipped roots $e_i-e_j$. So the proof here extends easily to other root systems with their own notion of inversions, e.g. for the group of signed permutations. \u2013\u00a0 Allen Knutson Dec 14 '10 at 19:06\nadd comment\n\nYes; this is known as the longest element, and it exists and is unique for every finite Coxeter group (including the ones which do not arise as Weyl groups). The length of the longest element is the number of positive roots in the corresponding root system; here that number is ${n \\choose 2}$. A standard reference here is Humphreys' Reflection groups and Coxeter groups; Proposition 5.6b is relevant, and this is the content of Exercise 2 in that section.\n\nTo be more explicit (and to explain Tobias' answer), specialized to symmetric groups Proposition 5.6b says the following: let $S_n$ act on the orthogonal complement of the all-ones vector in $\\mathbb{R}^n$ in the obvious way. This complement is spanned by elements of the form $e_i - e_j, 1 \\le i \\neq j \\le n$; a choice of positive roots for the corresponding root system can be obtained by considering the elements with $i > j$, of which there are ${n \\choose 2}$. Then the length of $w \\in S_n$ is the number of positive roots $e_i - e_j$ sent to their negatives $e_j - e_i$ (which, one readily verifies, is the number of inversions in $w$). And there is a unique permutation that does this to every positive root: just send $k$ to $n + 1 - k$.\n\nOne way to interpret this result is that the length of an element $w \\in S_n$ (with its usual Coxeter system) is the least number of steps required to sort the word $w_1 w_2 ... w_n$ using bubblesort, and of course the word $n (n-1) (n-2) ... 3 2 1$ takes ${n \\choose 2}$ steps to sort and is maximal (since $n$ is moved $n-1$ times, $n-1$ is moved $n-2$ times, etc.)\n\nshare|improve this answer\nThe bit \"...their negatives $e_j - e_i$...\" is wrong above. It should just be \"negative roots,\" but this seems like too minor an edit to bump for. \u2013\u00a0 Qiaochu Yuan Nov 20 at 7:31\nadd comment\n\nThe Cayley graph of $S_n$ is the skeleton of the Permutahedron of order $n$. This polytope is the Minkowski sum of the $\\frac{n(n-1)}{2}$ segments connecting pairs of the standard basis vectors. You can now visualize that the element of maximal length is antipodal to the identity vertex and has length exactly $\\frac{n(n-1)}{2}$.\n\nshare|improve this answer\nNote that this is just a response to the observation that the Cayley graph of $S_n$ looks like $S^n$, the simplest proof is given by Sergei Ivanov in the other answer. \u2013\u00a0 Gjergji Zaimi Dec 14 '10 at 9:51\nadd comment\n\nYes, all $S_n$ have a unique longest element. One way to see this is that $S_n$ is the Weyl-group of the simple Lie algebra of type $A_{l-1}$, and here the length can be characterized by fixing a set of simple roots (and thus of positive roots). The length is then the number of positive roots that are sent to negative roots. The unique longest element is then the one that sends each simple root to its negative (the product of the simple reflections corresponding to each simple root)\n\nshare|improve this answer\nadd comment\n\nA more explicit version of Qiaochu's answer : $S_n$ can be viewed as a Coxeter group of type $A_{n-1}$. The maximal length is $\\frac{n(n-1)}{2}$, achieved by the element $$s_1(s_2s_1)(s_3s_2s_1) \\ldots (s_{n-1}s_{n-2} \\ldots s_2s_1)$$.\n\nThis is a classical result in Coxeter groups theory. Sketch of the proof : for each $i \\in [1,n-1]$ let $G_i$ be the so-called parabolic subgroup generated by $T_i=\\lbrace s_1,s_2, \\ldots ,s_n \\rbrace $. For any $w\\in G_k (1 \\leq k \\leq n-1)$ we can write $w=w_1w_2w_3 \\ldots w_r$ where each $w_i \\in T_k$ and $r$ is minimal. Among all those decompositions, we choose the one with as many generators in $T_{k-1}$ on the left as possible. This shows that $w$ can be written $w=w'x$, with $w'\\in G_{k-1}$, and $x\\in X_k$ where $X_k$ consists of the element $x\\in G_k$ all of whose minimal decompositions start with $s_k$.\n\nIt is not hard to show that the pair $(w',x)$ is unique (this is because $G_{k-1}$ and $X_k$ are disjoint) and trivially we have $l(w)=l(w')+l(x)$. By induction, any $w\\in S_n$ can be written uniquely $w=x_1x_2 \\ldots x_n$, where each $x_i$ is in $X_i$, and furthermore $l(w)=l(x_1)+l(x_2)+ \\ldots +l(x_n)$.\n\nNow, when the group is $S_n$ it is a straightforward exercise to show that $$X_k=\\lbrace s_{k},s_{k}s_{k-1}, \\ldots, s_{k}s_{k-1} \\ldots s_{2}s_{1} \\rbrace$$ for any $k$. Therefore $X_k$ has a unique element of maximal length, $\\xi_k=s_{k}s_{k-1} \\ldots s_{2}s_{1}$, and we deduce that $S_n$ has a unique element of maximal length which is the product $\\xi_1\\xi_2 \\ldots \\xi_{n-1}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/30891/explicit-formula-for-the-j-invariant-of-binary-quartic-form/30967\nText:\nTake the tour \u00d7\n\nA binary quartic form\n\n\ndecomposes as a product of linear factors $Y-t_jX$, $j=1,...,4$. I would like to have an explicit formula for symmetrization of the crossratio of $t_j$.\n\nshare|improve this question\nDo you mean the j-invariant of the elliptic curve $y^2=ax^4+bx^3+cx^2+dx+1$? \u2013\u00a0 Robin Chapman Jul 7 '10 at 13:54\nYes, that is exactly what I am looking for. \u2013\u00a0 David Mar\u00edn Jul 7 '10 at 14:00\nIf you have access to a computer algebra system, you can do the following. Let $\\xi$ denote a solution to $f(1,\\xi)=0$ where $f$ is your quartic. Then $f(X,Y+\\xi X)=b'X^3Y+\\cdots+Y^4$. The elliptic curve is now isomorphic to $y^2=b'x^3+c'x^2+d'x+1$. Transform it to the usual Weierstrass form and take the $j$-invariant. Note that $b'$ etc. will have $\\xi$s in them, but they should all cancel out via the equation $f(1,\\xi)=0$ in the final result. \u2013\u00a0 Robin Chapman Jul 7 '10 at 14:23\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nThe $j$ invariant is\n\n\n\n\n\n\nfor more details see my article J. Algebra 303 (2006) 771-788.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/48721/calculate-temperature-of-the-earth-through-blackbody-radiation/49739\nText:\nTake the tour \u00d7\n\nI don't understand the solutions to a problem about blackbody radiation and was wondering if anybody could help me out.\n\nHere is the question:\n\nThe sun can be considered as a blackbody radiation source at temperature T = 5778 K. Radiation from the sun which is incident on the earth is reflected by the atmosphere such that the intensity hitting the earth's surface is reduced by a factor R. Some of the radiation emitted from the earth's surface is reflected by the atmosphere such that only a fraction A leaves the atmosphere. If A = R = 0:1, what temperature would the earth be?\n\nThen in the solutions they state: This is obtained by first trying to find the power from the sun which passes through unit area at the earth's radial distance. This is given by:\n\n$\\frac{4 \\pi r_s^2}{4 \\pi d_e^2}\\sigma T_s^4$\n\nwhere $r_s$ is the radius of the sun, $d_e$ is the distance between the earth and sun and $T_s^4 = 5778K$ is the temperature of the sun.\n\nI know that $\\sigma T_s^4$ is from the Stefan-Boltzmann law, and that $4 \\pi r_s^2$ is the surface of the sun. What I don't understand is why the distance to the earth is important. Thanks in advance!\n\nshare|improve this question\nIf the Earth is farther from the sun it receives less radiation from the sun! Try sketching the geometry. (Hints: conservation of energy (flux); inverse square law) \u2013\u00a0 Michael Brown Jan 9 at 13:15\n@MichaelBrown So the $\\frac{1}{d_e^2}$ comes from the inverse square law? The thing that confuses me is that the earth's radius isn't needed anywhere. \u2013\u00a0 Longeyes Jan 9 at 13:35\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe standard procedure (or at least how I think about it) for getting the temperature of a planet from that of the star consists of alternating between power and power per unit area.\n\n  \u2022 You start with $\\sigma T^4$, the total power per unit area of the star.\n  \u2022 To get the total power, multiply by the area of the star.\n  \u2022 To get the power per unit area at the distance of the planet, you have to divide by the area of the sphere over which this energy is (by assumption evenly) distributed. This gets you to the quantity you have.\n  \u2022 Now you can find the total power absorbed by the planet, given the power per unit area it gets and an area1.\n  \u2022 Then you can divide by an area1 to get the power per unit area given off by the planet, which is a quantity you can set equal to $\\sigma T_\\text{planet}^4$ to find its temperature.\n\nSo there is a lot of multiplying and dividing by areas, and lots of factors of $\\pi$ will cancel when you string it all together. Note one can modify these steps to take additional complexities into account (the $R$ and $A$ of your problem, for example).\n\nFurther, note that I used the planet's radius - twice in fact. And if you go through the arithmetic, you should find that it cancels itself. Intuitively, you might expect that an object's temperature (an average thermal energy) only depends on the strength of the heat source and its distance, but not on the object's size. Both you and your pet hamster2 get to about the same temperature sitting at equal distances from the fireplace.\n\n1 Be careful about these two areas. You have to think about what area is appropriate where.\n\n2 I have no idea how I came up with this example.\n\nshare|improve this answer\nThanks! I think I understand how they got their results now :) By the first area...do you mean the \"receiving\" planet's surface? \u2013\u00a0 Longeyes Jan 11 at 10:40\n@Longeyes Yes, but there's a difference between the cross-sectional area $\\pi r^2$ and the total surface area $4 \\pi r^2$. \u2013\u00a0 Chris White Jan 11 at 15:57\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/109483/maximal-order-of-elements-in-gln-p?answertab=active\nText:\nTake the tour \u00d7\n\nI am looking for a formula for the maximal order of an element in GL(n,p), where p is prime.\n\nI recall seeing such a formula in a paper from the mid- or early 20th century, but could not find again this reference. I will be grateful for any hint.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nWell, by Hamilton--Cayley, each matrix $A\\in {\\rm GL}(n,p)$ generates an at most $n$-dimensional subalgebra ${\\mathbb F}_p[A]\\subseteq M(n,p)$ thus containing at most $p^n-1$ nonzero elements. Hence the order of $A$ cannot exceed $p^n-1$.\n\nOn the other hand, consider a degree $n$ monic polynomial $P_n$ whose root is a generator $\\xi$ of ${\\mathbb F}_{p^n}^*$. Then a matrix with $P_n$ as its characteristic polynomial has order at least $p^n-1$ since $\\xi$ is its eigenvalue.\n\nADDENDUM. if you wish the order to be the power of $p$, then the answer is $d=p^{\\lceil \\log_p n\\rceil}$. Since the order of $A$ is divisible by the multiplicative orders of its eigenvalues, all the eigenvalues should be $1$. Hence the characteristic polynomial is $(x-1)^n$, so $A^d-I=(A-I)^d=0$.\n\nOn the other hand, if $A=I+J$ is the Jordan cell of size $n$ (with eigenvalue 1), then $A^{d/p}=I^{d/p}+J^{d/p}\\neq I$, but $A^d=I+J^d=I$.\n\nNB. The subgroup of all (upper-)unitriangular matrices is a Sylow $p$-subgroup in ${\\rm GL}(n,p)$. So you may concentrate on it when looking at the elements of this kind.\n\nshare|improve this answer\nThank you very much for the elegant answer! A related question: what is the maximal p-power which is the order of an element of GL(n,p)? \u2013\u00a0 user27196 Oct 13 '12 at 6:41\nI've added an answer to this question, too. \u2013\u00a0 Ilya Bogdanov Oct 13 '12 at 7:20\nThank you very much again - this was very helpful. \u2013\u00a0 user27196 Oct 13 '12 at 8:31\nBeautiful trick to use Cayley-Hamilton here! \u2013\u00a0 Peter Mueller Oct 13 '12 at 9:35\nI have meanwhile found the paper: Ivan Niven, Fermat theorem for matrices, Duke Math. J. 15 (1948), 823-826, which gives an elementary and explicit description of the possible orders of elements in GL(n,q), where q is a prime power. Thanks again. \u2013\u00a0 user27196 Oct 14 '12 at 7:26\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/45253/almost-linear-ode-how-node-becomes-a-spiral?answertab=votes\nText:\nTake the tour \u00d7\n\nMost introductory ODE books contain a discussion of almost linear systems, and there are two cases when the behavior of an almost linear system near an equilbrium point can differ from the behaviour of a linearlized system. One of these two cases is when the linearlized system has a repeated nonzero real eigenvalue; then the equilibrium solution of the linearlized system is a node, while the original almost linear system could be a node or a spiral, and I wish to see an explicit example of when the spiral occurs.\n\nTo give you an idea of what I need, let's discuss the other case when the linearized system is a center, but the almost linear system could be a center or a spiral, and the example when the spiral occurs is $x^\\prime=y+x(x^2+y^2)$ and $y^\\prime=-x+y(x^2+y^2)$.\n\nUPDATE: I now feel much better about the question because it turned out not as silly as I initially feared. Apparently, given a $2\\times 2$ almost linear system $X^\\prime=F(X)$ if the solution $X=0$ of the linearized system $X^\\prime=AX$ is a node, then it is also a node for $X^\\prime=F(X)$, as long as $F$ is $C^2$. If $F$ is merely $C^1$ there is a counterexample indicated in the comments. In cartezian coordinates the counterexample is $x^\\prime=-x-\\frac{2y}{\\ln(x^2+y^2)}$ and $y^\\prime=-y+\\frac{2x}{\\ln(x^2+y^2)}$; the right hand side is not $C^2$.\n\nshare|improve this question\nMaybe I don't understand, but does $x'= -x + y^3$, $y'= -y - x^3$ qualify? However, the spiral and the node are always conjugated, so I don't see quite clearly what you mean by differ (when there are zero eigenvalues this is clear, since you can get, as in your example, really different behaviour). \u2013\u00a0 rpotrie Nov 8 '10 at 10:03\nIn a small neighborhood of the equilibrium point $p$, the spiral goes around $p$ infinitely many times, the node does not, so the behaviour is quite different. However, I found an example that does the job. In polar coordinates it looks like $r^\\prime=-r$ and $\\theta^\\prime=1/ln(r)$. \u2013\u00a0 Igor Belegradek Nov 8 '10 at 12:39\n@rpotrie, your example looks like a node in a small neigborhood of the origin. In a larger neigborhood it starts looking like a spiral but my question was about local begavior. Still it is a nice example, thanks! \u2013\u00a0 Igor Belegradek Nov 8 '10 at 18:26\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/393071/divide-by-a-number-without-dividing?answertab=active\nText:\nTake the tour \u00d7\n\nCan anyone come up with a way to divide any given x by any given y without actually dividing?\n\nFor example to add any given x to any given y without adding you would just do:\n\nAnd to subtract any given x from any given y (that is, y-x) you could do:\n*edit: well since (i) is ($\\sqrt{-1}$) and that is technically subtracting this one might not work perfectly but for the sake of the riddle and for the sake of example, I'm using that equation :)\n\nHow can you divide without dividing? Can anyone come up with equations that work for all $x$ and $y$ values? (For all intents and purposes we will leave out dividing by zero issues and what-not... don't worry about that...\n\nshare|improve this question\nI don't really see the point of this post. Divide without dividing? Sure you can do it for simple things, like solving: $2x = 6$. You could guess rational numbers until you get it right but that's pretty silly. What about something more complicated like $2x = \\pi$? How could you solve for $x$ without doing division? \u2013\u00a0 Cameron Williams May 16 at 2:20\n@CameronWilliams Exactly! How would you? That's what I want to know! I think it's a fun question! \u2013\u00a0 Albert Renshaw May 16 at 2:21\n$x/y=x\\times y^{-1}$ \u2013\u00a0 vadim123 May 16 at 2:22\n@CameronWilliams: Come now, Albert mentions $y+xe^{\\pi i}$ as a work-around for subtraction. You could not compute this without actually doing subtraction. The question is clearly about equivalent expressions with no immediate regard to practicality. We all have to learn these things at some point :) \u2013\u00a0 Eric Stucky May 16 at 2:27\nLet me just add that while the question may seem a little facetious, Paul Dirac spent some time trying to join special relativity and quantum mechanics before he discovered he could take a square root without taking a square root and revolutionise physics! (Slide 13) \u2013\u00a0 Nicolau Saker Neto May 16 at 3:32\nshow 9 more comments\n\n4 Answers\n\nup vote 7 down vote accepted\n\nLook at the equation $\\frac{1}{x}=a$. We use Newton's Method to approximate the solution.\n\nLet $f(x)=\\frac{1}{x}-a$. The standard Newton iteration gives $$x_{n+1}=x_n -\\frac{f(x_n)}{f'(x_n)}=x_n -\\frac{\\frac{1}{x_n}-a}{-\\frac{1}{x_n^2}}.$$ This simplifies to $$x_{n+1}=x_n(2-ax_n).$$\n\nRemark: Note that only subtraction and multiplication are used. If we start with $x_0$ close enough to $\\frac{1}{a}$, the method converges rapidly. It was once used to implement reciprocal in software.\n\nshare|improve this answer\n@AlbertRenshaw: You mentioned in the comments that your original idea was to try and \"guess high, guess low\" until you got to the right answer. This is a formally rigorous way of implementing a strategy similar to that one. The downside is that you'll never actually reach the number, but the upside is that for integer divisions you'll be able to see pretty quickly what you're \"headed towards,\" for example if your first guess is 0.8, this method tells you after four steps that $\\frac12\\approx 0.49999996$; it's not too much of a stretch to say, \"Oh, that's 0.5\". \u2013\u00a0 Eric Stucky May 16 at 2:49\nadd comment\n\nTake the logarithm that maps multiplication/division into addition/subtraction:\n\n$$\\frac{x}{y}=e^{\\log{x/y}}=e^{\\log x- \\log y}.$$\n\n$x,y >0$.\n\nAlso, see my answer for multiplying natural numbers here: Advocating base 12 number system\n\nshare|improve this answer\nadd comment\n\nFor $y \\neq 0$ $$\\large x\\div y = \\dfrac 1y\\times x = y^{-1}\\times x = \\large y^{\\left(e^{i\\pi}\\right)}\\times x = y^{\\left(i^2\\right)}\\times x$$\n\nshare|improve this answer\nVery nice!!! For now I will accept this, I am curious what others come up with!!! (I will accept it in 7 minutes when SE lets me) \u2013\u00a0 Albert Renshaw May 16 at 2:23\nMultiplying by the reciprocal could be thought of as the definition of division. This is analogous to saying that $x-y = x+(-y)$ is subtracting without subtracting, whereas an alternative would be to note that that is the definition of subtraction. \u2013\u00a0 Jonas Meyer May 16 at 2:30\n@JonasMeyer I'm eager to see if other's come up with solutions that don't use that... since the only way to \"really\" solve mathematically for (x^-y) is to use division. But this was more of a riddle question, in which case this is a valid answer :o) \u2013\u00a0 Albert Renshaw May 16 at 2:31\n@amWhy: I have seen all of the OP's comments. I'm not sure what part you want me to see. \u2013\u00a0 Jonas Meyer May 16 at 2:36\n@Jonas see below the answer...he simply wants to avoid using the symbol for division. \"I just meant without using the symbols in the actual equation! Haha :o) \" \u2013\u00a0 amWhy May 16 at 2:37\nshow 1 more comment\n\nLogs turn reciprocals into minus signs: $\\ln(1/y)=-\\ln(y)$. Thus, $$x/y=xe^{-\\ln y}.$$\n\n(This is assuming that $y$ is positive. If $y$ is negative, then $x/y=-xe^{-\\ln(-y)}$.)\n\nshare|improve this answer\nI like this one even better!!! :) \u2013\u00a0 Albert Renshaw May 16 at 2:33\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214234/tiling-a-minimal-perimeter-region-with-n-unit-squares?answertab=oldest\nText:\nTake the tour \u00d7\n\nSuppose I have $n$ identical unit squares and I want to use them all to tile a region with minimal perimeter $p(n)$. For instance I guess $p(n^2)=4n$, by arranging them im a $n\\times n$ square.\n\nIs there an explicit formula for $p(n)$? Or sharp bounds? How do one prove equalities or bounds for this type of quantities?\n\nI would be happy also with a recursive formula for $p(n)$, like $p(n\\cdot m) = f(p(m),p(n))$, but the factorization is not unique and I don't see how to get it easily.\n\nMy intuition is that given a certain number $n$, the minimal perimeter region is a rectangle with sides of integer lengths $l$ and $m$, where $l\\cdot m=n$ and $(l,m)$ is the pair of integer numbers \"closest\" (in some sense) to $(\\sqrt{n},\\sqrt{n})$, that's where number theory could play a role.\n\nI have no clue where to start proving something along these lines, so any hint, comment or reference is welcome!\n\nshare|improve this question\nI think it should be $p(n) \\sim 2\\sqrt{\\pi n}$ as $n\\to\\infty$ \u2013\u00a0 nikita2 Oct 15 '12 at 13:30\n@nikita2: That would be the asymptotic form for the minimal length of the convex hull; but if you measure the perimeter exactly following the sides of the squares a circular arrangement is actually worse than a square. \u2013\u00a0 joriki Oct 15 '12 at 15:03\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nFor every x in the range $n^2 \\le x < (n+1)^2$ you have $4n \\le p(x) \\le 4n+4$, so $p(x) = \\sqrt{x} + \\operatorname{O}(1)$. If you want a closed formula I would try with (putting $t=n^2-x$) $$ p(n^2+t) = \\begin{cases} 4n \\quad&\\text{if }t=0\\\\4n+2 &\\text{if }0 < t \\le n\\\\ 4n+4 &\\text{if }n < t \\le 2n\\end{cases}$$ which is the perimeter you obtain if you go from the square $n\\times n$ to the square $(n+1)\\times(n+1)$ tile by tile.\n\nEDIT (Proof sketch) We can assume that the shape with least perimeter is connected (if the shape has two pieces, connecting them by a suitable edge gives a shape with strictly less perimeter than the original).\n\nNow given $x = n^2+t$ with $0\\le t \\le 2n$ fix a shape that gives the least perimeter $p(x)$. Pick a rectangle with minimal dimensions $a\\times b$ containing the shape. The perimeter is at least $2a+2b$, (as it goes all the way from left to right and from top to bottom and back by the other side).\n\nOn the other hand $ab \\ge x$ because there are at least $x$ tiles inside the rectangle so $$ p(x) \\ge 2a + 2b \\ge 2a + 2x/a $$ the right hand side has a single minimum at $a = \\sqrt{x}$ but $a$ is an integer so we have $$ p(x) \\ge 2n + 2x/n = \\frac{ 4n^2 + 2t}{n} $$ (it is easy to see that $a=n+1$ gives a larger value). If $t = 0$ this gives $p(x) \\ge 4n$, if $t \\le n$ we have $p(x) > 4n$ but as $p(x)$ is even we have $p(x) \\ge 4n+2$ and if $t > n$ we have $p(x) > 4n+2$ so again $p(x) \\ge 4n+4$. As we have examples obtaining this bounds we are finished.\n\nshare|improve this answer\nthat was my guess as well, but does one prove it formally? \u2013\u00a0 Ale Zok Oct 15 '12 at 16:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/128525/expectation-of-the-trace-of-an-inverse-of-a-random-matrix\nText:\nTake the tour \u00d7\n\nGiven a $N \\times M$ matrix $X$ comprised of standard normal entries ($M > N$), I'm interested in approximating $E[trace((XX^T\\frac{\\gamma}{M} + I)^{-1}]$ in terms of $N, M$ and $\\gamma$. Unfortunately, I can't necessarily assume $\\gamma$ is small. I've had no luck in coming up with any kind of approximation. Thanks!\n\nFor context, this problem relates to the effective degrees of freedom for ridge regression.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nlet $\\lambda_{1},\\lambda_2,\\ldots\\lambda_N$ be the eigenvalues of $M^{-1}XX^{T}$; including for convenience a factor $1/N$, the quantity you seek is\n\n$$N^{-1}E[{\\rm Tr}(XX^{T}\\gamma/M)+I)^{-1}]=\\int d\\lambda \\rho(\\lambda)(\\lambda\\gamma+1)^{-1}$$\n\nwhere $\\rho(\\lambda)=E[N^{-1}\\sum_n\\delta(\\lambda-\\lambda_n)]$ is the eigenvalue density of Wishart matrices; this quantity is known in closed form for $N,M\\rightarrow\\infty$ at finite ratio $N/M=r\\in(0,1]$ (Marchenko-Pastur distribution). I find in this way the answer\n\n$$\\lim_{N,M\\rightarrow\\infty}N^{-1}E[{\\rm Tr}(XX^{T}\\gamma/M)+I)^{-1}]=(2r\\gamma)^{-1}\\left(-1-\\gamma\\sqrt{ab}+\\sqrt{(1+a\\gamma)(1+b\\gamma)}\\right)$$\n\nwith $a=(1+\\sqrt r)^2$ and $b=(1-\\sqrt r)^2$. As a check, you can take the limit $\\gamma\\rightarrow 0$ of this expression and obtain $1$, as it should.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/140310/a-limit-with-integral?answertab=active\nText:\nTake the tour \u00d7\n\nWe are given a continuous function $f \\colon [0,1] \\to \\mathbb{R}$. What is the value, if it exists, of the limit $$\\lim_{t \\to +\\infty} \\frac{1}{t} \\log \\int_0^1 \\cosh (t f(x))\\, \\mathrm{d}x \\ ?$$\n\nPS: this is not homework. It's a question contained in a Ph.D test, and I am unable to make progress toward the solution :-(\n\nshare|improve this question\nmay be try L'H\u00f4pital's rule \u2013\u00a0 Babgen May 3 '12 at 9:45\nMy first guess: consider $f(x)=mx+q$ and compute the limit in this particular case. Then remark that any continuous $f$ on $[0,1]$ can be uniformly approximated by affine functions. But also the affine case is not really easy... \u2013\u00a0 Siminore May 3 '12 at 9:55\nadd comment\n\n1 Answer\n\nup vote 9 down vote accepted\n\nWithout loss of generality, assume $f(x)\\geq 0$ (as $\\cosh$ is even). Let $m = \\max f(x)$ and let $\\delta$, $\\epsilon$ be such that $|x-x_0|<\\delta$ impies $m\\geq f(x)>m-\\epsilon$.\n\nFirst, $$ I_t = \\frac1t \\log\\int_0^1 \\cosh(tf(x))\\,dx \\leq \\frac1t \\log \\cosh(tm), $$ and since $\\log\\cosh(tm)\\sim \\log\\frac12 + tm$ ($t\\to\\infty$), this implies that $$ \\limsup_{t\\to\\infty} I_t \\leq m. $$\n\nSecond, $$I_t \\geq \\frac1t \\log \\int_{x_0-\\delta}^{x_0+\\delta} \\cosh(tf(x))\\,dx \\geq \\frac1t \\log \\big(2\\delta \\cosh(t(m-\\epsilon)),$$ which implies that $$ \\liminf_{t\\to\\infty} I_t \\geq m-\\epsilon. $$\n\nTaking the limit as $\\epsilon\\to0$, it follows that $\\lim_{t\\to\\infty}I_t$ exists and equals $\\max_x |f(x)|$.\n\nshare|improve this answer\nVery nice! Just a correction: $\\cosh (tm) \\sim \\frac{1}{2}\\mathrm{e}^{tm}$, so that $\\log \\cosh (tm) \\sim \\log \\frac{1}{2}+tm$ as $t \\to +\\infty$. \u2013\u00a0 Siminore May 3 '12 at 11:31\nThanks. Fixed that. \u2013\u00a0 Kirill May 3 '12 at 11:34\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/238791/galois-group-of-maximal-p-extension-of-mathbbq-l-zeta-p\nText:\nTake the tour \u00d7\n\nLet $F$ be the field obtained by adjoining to $\\mathbb{Q}_l$ a $p$-th root of unity, with $p \\not = l$. Denote by $F(p)$ the maximal $p$-extension of $F$, i.e. the maximal extension $L:F$ such that the degree is a power of $p$.\n\nQuestion: what is the structure of the Galois group $G(F(p):F)$?\n\nI found a reference in the literature stating that it is equal to the semidirect product of two copies of $\\mathbb{Z}_p$, but I don't know why, and have been unable to track down any references. Any help would be appreciated.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $K$ be the maximal unramified p-extension of $F=\\mathbb{Q}_l(\\zeta_p)$. Note that the valuation on $K$ is discrete (since $K/F$ is unramified), so many of the standard results on local fields apply to $K$. Let $k$ be the residue field of $K$, so $k$ is the maximal p-extension of $\\mathbb{F}_l(\\zeta_p)$. Then $k(\\sqrt[p]{u})/k$ is a p-extension for all $u\\in k$ (this uses the fact that $\\zeta_p\\in k$). Hence by maximality, $k$ contains $p$-th roots of all its elements. By Hensel's lemma, one can show that if $u\\in \\mathcal{O}_K^\\times$, then $\\sqrt[p]{u}\\in K$. One easy consequence is that $\\zeta_{p^n}\\in K$ for all natural numbers $n$.\n\nLet $L/K$ be a finite p-extension. Then we may split $L/K$ into an unramified extension $K_0/K$ and a totally ramified one $L/K_0$, both of which are p-extensions. By the definition of $K$, we must have $K_0=K$ so $L/K$ is totally ramified. $L/K$ is tamely ramified because it is a p-extension and $p\\neq l$. Let $p^n$ be its degree. I claim that $L=K(\\sqrt[p^n]{l})$. The classification of totally tamely ramified extensions gives $L=K(\\sqrt[p^n]{\\pi})$ for some generator $\\pi$ of $\\mathfrak{m}_K$. But $\\pi=ul$ for some $u\\in\\mathcal{O}_K^\\times$. Since $\\sqrt[p^n]{u}\\in K$, $K(\\sqrt[p^n]{\\pi})=K(\\sqrt[p^n]{l})$, proving the claim.\n\nSince $K/F$ is a p-extension, the maximal p-extension $F(p)$ of $F$ equals the maximal p-extension of $K$, which by the above is the extension $K(\\sqrt[p^\\infty]{l})$ obtained by adjoining all $p$-th power roots of $l$ to $K$. By the Galois theory of finite fields, we have $\\mathrm{Gal}(K/F)\\cong\\mathrm{Gal}(k/\\mathbb{F}_l(\\zeta_p))\\cong \\mathbb{Z}_p$. Since $K$ contains $p^n$-th roots of unity, $\\mathrm{Gal}(K(\\sqrt[p^k]{l})/K)\\cong\\mathbb{Z}/p^k\\mathbb{Z}$. By taking limits we have $\\mathrm{Gal}(F(p)/K)=\\mathrm{Gal}(K(\\sqrt[p^\\infty]{l})/K)\\cong \\mathbb{Z}_p$. In particular $\\mathrm{Gal}(F(p)/F)$ is an extension of $\\mathbb{Z}_p$ by $\\mathbb{Z}_p$.\n\nTo show it is a semidirect product, we need to construct a splitting of $\\mathrm{Gal}(F(p)/F)\\rightarrow \\mathrm{Gal}(K/F)\\cong \\mathbb{Z}_p$. I suspect such a splitting can be obtained by sending $1$ to the Frobenius automorphism of $F(p)/F$.\n\nshare|improve this answer\nThanks, I'm happy with this argument. \u2013\u00a0 KristianJS Nov 19 '12 at 14:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/252638/bounds-on-a-sum-involving-the-mobius-function\nText:\nTake the tour \u00d7\n\nIn Apostol's Analytic Number Theory, Apostol defines $$A(x):= \\sum_{n \\leq x} \\frac{\\mu(n)}{n}$$ and proves that $A(x)=o(1)$ implies the Prime Number Theorem, by showing that $$\\frac{M(x)}{x}=A(x)-\\frac{1}{x}\\int_1^x A(t)dt,$$ in which $M(x):=\\sum_{n \\leq x} \\mu(n)$ is the summatory function for the M\u00f6bius function (Theorem 4.16). What are some known error bounds for the function $A(x)$? In particular, do we have $A(x)= o(1/\\log x)$ as $x \\to \\infty$?\n\nshare|improve this question\nTerence Tao has a rather interesting paper about this : 'A remark on partial sums involving the Mobius function'. See too his blog. \u2013\u00a0 Raymond Manzoni Dec 7 '12 at 1:20\nSchoenfeld's paper, Marraki's one and Cohen's paper seem interesting too (summatory function is much more studied than the $\\zeta(1)$ formula). \u2013\u00a0 Raymond Manzoni Dec 7 '12 at 1:25\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nI'll answer my own question:\n\nThe Abel Summation formula gives\n\n$$A(x)=\\frac{M(x)}{x}+ \\int_1^x \\frac{M(u)}{u^2} du = \\frac{M(x)}{x}+\\int_1^\\infty \\frac{M(u)}{u^2} du-\\int_x^\\infty \\frac{M(u)}{u^2} du.$$ As $A(x)=o(1)$, the right-hand side of the above must tend to $0$. We have $M(x)/x \\to 0$, and the estimate $$\\left\\vert \\int_x^\\infty \\frac{M(u)}{u^2} du \\right\\vert \\leq \\int_x^\\infty \\frac{\\vert M(u)\\vert}{x^2} du =\\frac{1}{x^2}O(xM(x))=O(M(x)/x)$$ implies that the rightmost integral of our first line tends to $0$ as well. Thus $$\\int_1^\\infty \\frac{M(u)}{u^2} du=0,$$ and $A(x)=O(M(x)/x)$. In particular, we can answer our question by simply bounding the growth of Mertens' function $M(x)$. We have $$M(x)=O\\left(xe^{-c\\sqrt{\\log x}}\\right)$$ for some positive constant $c$. (I believe this follows from the classical bounds in the PNT but am unable to find a proper reference. Edit: I found a mention of the process here.) Then $A(x) =O(e^{-c \\sqrt{\\log x}})$, and since $$\\lim_{x \\to \\infty} \\frac{(\\log x)^n}{e^{c \\sqrt{\\log x}}}=0$$ for all $n$, we find $A(x)=o((\\log x)^{-n})$ for all $n >0$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/65555/how-do-you-come-up-with-a-povm/65574\nText:\nTake the tour \u00d7\n\nThis is a made-up example, just to understand a concept. If changing the probability values aids your explanation, that's fine by me.\n\nSay you have a physical quantity $E$ that can take values 1, 2, 3 with probabilities 0.4, 0.25, 0.35 respectively (working in a quantum framework). You have a positive operator valued measure, $E_1, E_2, E_3$, with $E_i$ corresponding to your measurement resulting in value $i$. If $\\rho$ is the density operator representing the current state, then you have:\n\nTr($\\rho E_1$) = 0.4, Tr($\\rho E_2$) = 0.25, Tr($\\rho E_3$) = 0.35\n\nGiven just these probability values, is it possible to construct $E_1, E_2, E_3$ \"backwards\"?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nYes. Not only is it possible, the solution is not unique and there exists a solution that is independent of $\\rho$.\n\nSo for $p_k$ being probabilities with $\\sum_k p_k = 1$, you can say $E_k = p_k \\mathbf{1}$, where $\\mathbf{1} = \\sum_j |j\\rangle \\langle j|$ (ie the identity matrix). Then $Tr[ E_k \\rho] = p_k Tr[\\rho] = p_k$. This works for all $\\rho$.\n\nThere are also nontrivial solutions. If say your state is a pure state $|\\psi\\rangle$ in some $d$ dimensional Hilbert space then you only need to find the basis $|k\\rangle$ for which $|\\psi\\rangle = \\sum_k \\sqrt{p_k} e^{i \\phi_k} |k\\rangle$.\n\nAlso notice something with the probability equations, in $Tr[\\rho E_1]$ if you don't assume that $\\rho$ is the state it could well be $E_1$ is the state and $\\rho$ is the measurement (although unlike $\\rho$, $E_k$ need not be normalized). So the question is the same as asking how to construct three states for which measurement of $\\rho$ gives the said probabilities.\n\nshare|improve this answer\nif the construction is not unique, for me it's impossible to know which operators has given the measurement, maybe it's only a matter of interpretation of the question. \u2013\u00a0 Ikiperu May 23 at 8:39\nThat's right. You need to do what's called measurement tomography, which is the same thing as state tomography but instead of engineering the right measurements you engineer the right states to measure. The basic idea is have a set of states that form a complete basis in the Hilbert-Schmidt space of operators, measure them repeatedly and use the resulting expectations to reconstruct the matrix elements. See for example nature.com/nphys/journal/v5/n1/abs/nphys1133.html \u2013\u00a0 SMeznaric May 23 at 10:22\nadd comment\n\nIf you count the number of variables that you want to find you get 18 (=9+9, 2 hermitian operators, the third is fixed by the others), but you impose only four conditions on these variables (=2x2, the trace may be complex, the third trace is already counted), therefore I think it's impossible.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/325141/probability-that-n-points-on-a-circle-are-in-one-semicircle\nText:\nTake the tour \u00d7\n\nChoose n points randomly from a circle, how to calculate the probability that all the points are in one semicircle? Any hint is appreciated.\n\nshare|improve this question\nHave I taken too much of a simplistic view on the problem by thinking the probability is $\\left\\(\\dfrac{1}{2}\\right\\)^n$? \u2013\u00a0 Noble. Mar 9 at 1:10\n@Noble: Yes, you have -- that's the probability that the points are all in one particular semicircle. \u2013\u00a0 joriki Mar 9 at 1:10\n@joriki I thought as much, it's a much more interesting problem then! \u2013\u00a0 Noble. Mar 9 at 1:11\nHint: Start with a point randomly on the circle and draw a diameter from that point. All you got to do now is ensure that rest of the $n-1$ points lie on the same side of the diameter (i.e., on a semi-circle). You can place the $n-1$ points using a coin toss. \u2013\u00a0 jay-sun Mar 9 at 1:12\n@jay-sun I dont think this is the correct way, three points could still be in one semicircle even if the last two are on two different sides of the diameter joining the first point and the center. \u2013\u00a0 Shu Xiao Li Mar 9 at 1:14\nadd comment\n\n4 Answers\n\nup vote 5 down vote accepted\n\nA variation on @joriki's answer (and edited with help from @joriki):\n\nSuppose that point $i$ has angle $0$ (angle is arbitrary in this problem) -- essentially this is the event that point $i$ is the \"first\" or \"leading\" point in the semicircle. Then we want the event that all of the points are in the same semicircle -- i.e., that the remaining points end up all in the upper halfplane.\n\nThat's a coin-flip for each remaining point, so you end up with $1/2^{n-1}$. There's $n$ points, and the event that any point $i$ is the \"leading\" point is disjoint from the event that any other point $j$ is, so the final probability is $n/2^{n-1}$ (i.e. we can just add them up).\n\nA sanity check for this answer is to notice that if you have either one or two points, then the probability must be 1, which is true in both cases.\n\nshare|improve this answer\nI don't understand this answer. (Strange, since you think it's a variation on mine. :-) I presume the \"if\" in \"if the remaining points end up all in the upper halfplane\" is intended to mean \"if and only if\"? If so, why is that? And why is the final probability simply the number of points times this one probability you calculated? \u2013\u00a0 joriki Mar 9 at 1:46\n@joriki Basically I'm breaking this down into conditional probabilities. The angle around the circle is just an arbitrary assignment, so conditionally pick $i$. All of these conditional probabilities are going to be identical, and there's $n$ of them, so whatever that probability is, multiply it by $n$. That's the easy part. (cont'd...) \u2013\u00a0 John Moeller Mar 9 at 1:48\n@joriki Since you've conditionally picked $i$, then you can arbitrarily choose the upper or lower halfplane as your \"in the same semicircle\" event. That's a coin-flip for each point, and they all have to be true, so it's $1/2^{n-1}$. (cont'd...) \u2013\u00a0 John Moeller Mar 9 at 1:51\nI think I see now -- I find it rather confusingly formulated, but if I understand correctly, you mean something like this: The probability of the remaining $n-1$ points being in the semicircle clockwise of a given point is $1/2^{n-1}$. These $n$ events (one for each given point) are disjoint, and exactly one of them has to occur for the points to lie in a semicircle; thus the desired probability is their sum. That's a nice argument :-) \u2013\u00a0 joriki Mar 9 at 2:02\nThere's a slight variation of this answer that uses the inherent symmetry: instead of picking $n$ points at random, pick $n$ random diameters of the circle and pick the $n$ points by randomly picking one of the 2 poles of each diameter. By essentially the same argument, you have the probability given by $(2n)/2^n=n/2^{n-1}$. \u2013\u00a0 sai Mar 9 at 2:16\nshow 4 more comments\n\nFind the largest angle gap, and number the points, say, clockwise such that that gap is between the last and first point. Then the probability density for the angle from the first to the last point to be $\\phi\\lt\\pi$ is\n\n$$ n\\frac1{2\\pi}\\left(\\frac\\phi{2\\pi}\\right)^{n-2}\\;, $$\n\nwhere the factor $n$ arises because we mapped $n$ numberings to one, $1/2\\pi$ is the density for the angle between the first and last point, and $(\\phi/2\\pi)^{n-2}$ is the probability that the remaining $n-2$ points are between them. The integral\n\n$$ \\int_0^\\pi n\\frac1{2\\pi}\\left(\\frac\\phi{2\\pi}\\right)^{n-2}=\\frac n{(2\\pi)^{n-1}}\\pi^{n-1}=\\frac n{2^{n-1}} $$\n\nis the desired probability.\n\nP.S.: Here's code that tests this result by simulations.\n\nshare|improve this answer\nadd comment\n\n\n\nfor the general problem (when the points have any distribution that is invariant w.r.t. rotation about the origin) and\n\n\nfor a nice application.\n\nAs a curiosity, this answer can be expressed as a product of sines:\n\n\nshare|improve this answer\nadd comment\n\nHere's another way to do this:\n\nDivide the circle into $2k$ equal sectors. There are $2k$ contiguous stretches of $k$ sectors each that form a semicircle, and $2k$ slightly shorter contiguous stretches of $k-1$ sectors that almost form a semicircle. The number of the semicircles containing all the points minus the number of slightly shorter stretches containing all the points is $1$ if the points are contained in at least one of the semicircles and $0$ otherwise; that is, it's the indicator variable for the points all being contained in at least one of the semicircles. The probability of an event is the expected value of its indicator variable, which in this case is\n\n$$k\\left(\\frac k{2k}\\right)^n-k\\left(\\frac{k-1}{2k}\\right)^n=k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)\\;.$$\n\nThe limit $k\\to\\infty$ yields the desired probability:\n\n$$ \\lim_{k\\to\\infty}k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)=\\lim_{k\\to\\infty}k2^{-n}\\left(\\frac{2n}k\\right)=\\frac n{2^{n-1}}\\;. $$\n\nshare|improve this answer\nWhy is $ \\lim_{k\\to\\infty}k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)=\\lim_{k\\to\\infty\u200c\u200b}k2^{-n}\\left(\\frac{2n}k\\right)$ true? \u2013\u00a0 sai Mar 9 at 5:09\n@sai: Apply the binomial theorem to the $n$-th power -- the first term cancels the $1$, the second term yields $2n/k$ and the remaining terms have more than one inverse power of $k$ and thus go to zero as $k\\to\\infty$. Note that $n$ is fixed; it's not a question of taking $n$ and $k$ to infinity simultaneously; we're just adding a finite number of terms, so the standard rules for adding convergent sequences apply. \u2013\u00a0 joriki Mar 9 at 8:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/90495/example-of-a-discontinuous-function\nText:\nTake the tour \u00d7\n\nIs there an example of a discontinuous function, $F$, defined on some complete subset $X\\subset R^n$ such that under some metric $d$, $\\sum\\limits_{n=1}^\\infty \\|F^n(x)-F^n(y)\\|<\\infty$ and\u00a0\n\nEither for multiple $x_i\\in X$ where $i\\in I$ and $I$ is any arbitrary indexing set, we have $F(x_i)=x_i$.\n\nOr For all $x\\in X, F(x)\\neq x$?\n\nshare|improve this question\nusually the notation $||.||$ is used for a norm, do you mean norm or metric? What do you assume about $x$ and $y$ in the inequality you stated? Is this supposed to hold for any $x, y$? \u2013\u00a0 user20266 Dec 11 '11 at 17:10\nThe parts \"multiple $x_i$\" and \"any arbitrary indexing set\" seem to contradict each other -- is $I$ really completely arbitrary, or does \"multiple $x_i$\" imply that $I$ has at least two elements? \u2013\u00a0 joriki Dec 11 '11 at 17:40\nAlso the sentence seems to be missing a verb -- do you mean \"Is there an example of a discontinuous function ...\"? \u2013\u00a0 joriki Dec 11 '11 at 17:58\n@Thomas: I meant a metric. Yes, for any x,y. Thanks. \u2013\u00a0 Will Dec 11 '11 at 19:18\n@joriki: Sorry for the ambiguities. I has to bhave at least 2 elements for the \"either\" option. Yes, I should probably use of instead. Edited. :) \u2013\u00a0 Will Dec 11 '11 at 19:20\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nYes. Take $X=[0,1]$ and\n\n$$F(x)=\\begin{cases}\\frac12&x=0\\;,\\\\\\frac x2&x\\ne0\\;.\\end{cases}$$\n\n$F$ is discontinuous at $0$. The sum is a geometric series and thus convergent. And $\\forall_{ x\\in X}F(x)\\ne x$.\n\nNote that the discontinuity at $0$ isn't required to make this work; we could introduce arbitrary discontinuities within the interval, as long as the iteration eventually moves beyond them towards $0$.\n\nClearly we can't have the other case, $F(x_i)=x_i$ for multiple $x_i\\in X$, since in that case the sum would diverge for $x=x_1$, $y=x_2$, being the sum over a non-zero constant.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/175448/cubic-polynomial-discriminant/175522\nText:\nTake the 2-minute tour \u00d7\n\nI am stuck on a cryptography problem that pertains to Elliptic Curves.\n\nThe problem is stated as follows:\n\nAssume the cubic polynomial $X^3+AX+B = (X-a)(X-b)(X-c)$\n\nIf $4A^3 + 27B^2 = 0$, then show two or all of $a,b,c$ are the same.\n\nSo far, I expanded the right side, so I get the following equations:\n\n$0 = a + b + c$\n\n$A = ab + ac + bc$\n\n$B = -abc$\n\nI can't seem to use the hypothesis in the correct way. I tried to compute $A^3$ but the expansion of it looks horrible. If any one has any tips how to approach this problem, that would be great.\n\nshare|improve this question\nDo you recognise that $4A^3+27B^2$ is the discriminant of the cubic? \u2013\u00a0 Andrew Jul 26 '12 at 13:44\nAlso, you might want to change the title and possibly the tags, as the question, though it will be related to elliptic curves and cryptography at some point, is really just about polynomials as stated. \u2013\u00a0 Tobias Kildetoft Jul 26 '12 at 13:54\n@Andrew: Yes I do now. But I guess I'm missing some key fact about that that allows me to conclude what I'm trying to show. \u2013\u00a0 MathNewbie Jul 26 '12 at 14:05\n@Tobias: Hopefully this will be much better of a tag. \u2013\u00a0 MathNewbie Jul 26 '12 at 14:07\nIn general, the discriminant of a polynomial is the product of the square of the differences of the roots. Hence, it is zero if and only if there is a multiple root. \u2013\u00a0 M Turgeon Jul 26 '12 at 14:09\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nThe case $A=0$ must be treated separately: In this case, $X^3+B$ has a double root if and only if $27B^2=0$, i.e. if and only if $B=0$. That is obvious, so let us assume $A\\ne 0$.\n\nLets set $f(X):=X^3+AX+B$ and consider $f'(X)=3X^2 + A$. A polynomial has a double root if and only if it shares this root with its derivative. Hence, let us check when that is the case. $f'(x)=0$ means $x^2 = -\\frac 13 A$ and $f(x)=0$ means $0=x^3+Ax+B=-\\frac{1}{3}Ax+Ax+B$, so $\\frac{2}{3}Ax = -B$, i.e. $x=\\frac{-3B}{2A}$. Plugging this back into $f'$, we get that $$0=f'(x)=3\\cdot\\frac{9B^2}{4A^2} + A,$$ which yields $27B^2 = -4A^3$. Hence, $f$ has a double root if and only if $27B^2+4A^3=0$.\n\nshare|improve this answer\nThanks, rattle. \u2013\u00a0 MathNewbie Jul 26 '12 at 17:50\n\nLet $X^3+Ax+B=(X-p)(X-q)^2$\n\nComparing the coefficients of the different powers of X,\n\n\n\n\nEliminating q, $4A^3+27B^2=0$ as $A^3=-27q^6$ and $B^2=4q^6$\n\nConversely, the parametric values of (A,B) can be written as $(-3s^2,2s^3)$\n\nThen, the equation becomes $X^3-3s^2X+2s^3=0$\n\nClearly, s is one of the solutions.\n\nOn the division by (X-s), we get $X^2+sX-2s^2=0 =>X=s,-2s$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59317/amenable-equivalence-relation-generated-by-an-action-of-a-non-amenable-group/59698\nText:\nTake the 2-minute tour \u00d7\n\nQuestion. Give a (possibly elementary) example of a probability measure preserving action $\\rho\\colon G \\curvearrowright X$ of a finitely-generated discrete group $G$ on a standard borel space $X$ with a probability measure, such that\n\n  1. the equivalence relation generated by $\\rho$ is ergodic and amenable,\n  2. the action $\\rho$ is faithful,\n  3. the group $G$ is non-amenable.\n\nA friend of mine asked me this question couple of days ago, which led us to another question, but perhaps there is an easier way to provide an example.\n\nshare|improve this question\nThis question is discussed in: Alexander S. Kechris \"Global Aspects of Ergodic Group Actions and Equivalence Relations\", pp. 31-34. It is available on line here: citeseerx.ist.psu.edu/viewdoc/summary?doi= \u2013\u00a0 Jesse Peterson Mar 27 '11 at 7:18\nYou can use the construction known as Mackey range: take a cocycle of an amenable equivalence relation with values in a non-amenable group G. Then G induces an amenable action on the space of skew product orbits. See Zimmer's paper for details. \u2013\u00a0 SIB Mar 27 '11 at 12:21\n@Jesse Peterson - Could you be a bit more specific? \u2013\u00a0 R W Mar 27 '11 at 12:31\nThe discussion is in Chapter 1, section 4, subsection (E). In the on line version I've linked to this actually begins on page 27 (page 37 of the pdf file). Thanks RW. \u2013\u00a0 Jesse Peterson Mar 27 '11 at 13:30\n@SIB - Yes, but the problem is still to find such a cocycle for which the resulting action is faithful - which is more or less equivalent to the original question. \u2013\u00a0 R W Mar 27 '11 at 13:40\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nThe answer is yes, such an action exists.\n\nWhat is needed for the construction is the following very nice example of an action of a non-amenable group on $\\mathbb Z$, which I just learned from Gabor Elek.\n\nConsider a graph with vertices given by $\\mathbb Z$ and unoriented edges between $n$ and $n+1$.\n\nPick a random labelling of the edges by the letters $a,b$ and $c$ with no $a$, $b$ or $c$ adjacent to the same letter. This defines an action of the group $G=\\mathbb Z/2 \\mathbb Z \\ast \\mathbb Z/2 \\mathbb Z \\ast \\mathbb Z/2 \\mathbb Z$. Indeed, just act according to existing labels or fix the element.\n\nThis action has the nice feature that it keeps invariant all counting measures on $\\mathbb Z$, i.e. all $\\mathbb Z$-Folner sequences sets are also Folner sequences for the $G$-action.\n\nNow, the space of labellings (as above) of the graph is itself a probability measure space (a Bernoulli space), which carries an ergodic p.m.p. $\\mathbb Z$-action by shifting. It is easy to see that $G$ acts on this space by measure preserving transformations (just by the method described above, done orbit by orbit) and induces an action as required. Indeed, the orbits are just the $\\mathbb Z$-orbits, so its ergodic and amenable. Faithfulness follows the fact that you considered all labellings, so that with positive probability (on the space of labellings), an element will act non-trivially. Note also that $G$ is not amenable.\n\nEDIT: As requested, more details on the action. The elements of the shift space are maps $f: \\mathbb Z \\to \\lbrace a,b,c \\rbrace$ with $f(n) \\neq f(n+1)$. A letter shifts $f$ to the right if $f(1)$ equals that letter, it shifts to the left, if $f(0)$ is equal to the letter; otherwise you fix $f$. It is obvious that the orbits are just the orbits of the shift-action of $\\mathbb Z$. Hence, the induced equivalence relation is just the one induced by the action of $\\mathbb Z$.\n\nshare|improve this answer\nI may miss something, but I don't see how it becomes an action. Take the sake of example the following labelling: $a$ on the edge $(0,1)$, and $b$ on all other edges $(n,n+1)$. Then, according to what you say, $a$ maps 0 to 1 and preserves all other vertices, whereas $a^{-1}$ maps 1 to 0 and preserves all other ones (I presume you meant that if you reverse orientation of an edge, then the label changes to its inverse). But then their composition is not the identity map. \u2013\u00a0 R W Mar 27 '11 at 13:37\nThanks, I corrected the construction. \u2013\u00a0 Andreas Thom Mar 27 '11 at 21:04\nI agree that now there is an action of the free product on $\\mathbb Z$. However, I still don't see how you define an action of this free product on your space of symbol sequences (your description \"just by the method described above, done orbit by orbit\" is not clear to me at all), and why this hypothetical action should be orbit equivalent to the shift. \u2013\u00a0 R W Mar 27 '11 at 22:27\nIt is really easy; I added more details above. \u2013\u00a0 Andreas Thom Mar 28 '11 at 0:15\nThat's nice - thank you. \u2013\u00a0 R W Mar 28 '11 at 3:48\n\nI believe in this paper there is an example of such group:\n\n  \u2022 Rostyslav Grigorchuk, Volodia Nekrashevych, \"Amenable actions of nonamenable groups\" (which can be downloaded from Volodia's webpage)\n\nalso, this is related (but not quite clear if one can built examples that you ask from it):\n\n  \u2022 Yair Glasner, Nicolas Monod, \"Amenable actions, free products and a fixed point property\"\nshare|improve this answer\nLet me also mention that by taking ``generic'' (think Baire category) generators one can show that the free groups have such an action. Also, by a result of Kirchberg (ams.org/mathscinet-getitem?mr=1282231), if $\\Gamma$ has property (T) and also has such an action then it must be residually finite. \u2013\u00a0 Jesse Peterson Mar 24 '11 at 12:53\n\nLet me join the discussion. Nicolas rightly says that amenability of an action is equivalent to amenability of the orbit equivalence relation and of a.e. stabilizer. It is also true that for a finite invariant measure amenability of the action is equivalent to amenability of the acting group. However, there is no contradiction here as (at least a priori) it might be possible that the orbit equivalence relation of an action of a non-amenable group is still amenable - due to the presence of huge stabilizers (which in this case must necessarily be non-amenable).\n\nI think that the paper by Grigorchuk and Nekrashevych quoted by Kate does provide a requested example. Indeed, they construct (Sections 3 and 4) a non-amenable group which has a faithful self-similar action on a homogeneous rooted tree. This action preserves the uniform measure on the boundary of the tree. Moreover, the orbit equivalence relation is a subrelation (mod 0) of the tail (or co-final in authors' terminology) equivalence relation. Since the latter one is hyperfinite ($\\equiv$ amenable), the orbit equivalence relation is also amenable.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/153564/is-it-true-that-for-matrices-where-all-entry-are-lower-than-1-determinant-is-lo\nText:\nTake the 2-minute tour \u00d7\n\nGeneric square matrix with positive 1 bounded entries\n\nConsidering a matrix $A=(a_{i.j})$ where $0 \\leq a_{i,j} < 1 \\forall i,j$. It is important to consider that all entries are strictly lower than 1 and positive.\n\nRows sum to a number lower than 1\n\nLet us consider that the sum of all entries of matrix $A$'s rows is lower than 1: $\\sum_{j=1}^{n}a_{i,j} < 1$. Sorry, maybe I did not specify it, only wrote in the formula, I talk about rows. Rows sum to a number lower than 1.\n\n\nLet us consider $\\det(A)$ (determinant).\n\nIs it true that $\\det(A)<1$???\n\nOr maybe $|\\det(A)| < 1$???\n\nshare|improve this question\nPerhaps you want to put absolute value signs around everything? Otherwise, consider $\\begin{bmatrix}-100 & 0 \\\\ 0 & -100\\end{bmatrix}$. \u2013\u00a0 Rahul Jun 4 '12 at 2:09\nYeah, all entries are positive. Please forgive me... \u2013\u00a0 Andry Jun 4 '12 at 2:13\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nEDIT: Taking into account the condition that the sum of the entries be less than one, the determinant is a sum of $n!$ terms, each of which is at most $n^{-n}$, so the determinant is bounded by $n!/n^n$, which is certainly less than 1 (for $n\\gt1$). Each term is les than $n^{-n}$ because it's a product of $n$ numbers that add up to less than 1, and you maximize the product by taking all the number to equal $1/n$.\n\n(Never mind --- I just saw the part about the sum of all the entries, or maybe it's the sum of all the entries in each row, being less than 1.)\n\nAre we only talking about $2\\times2$ matrices? If not, then $$\\pmatrix{a&b&0\\cr0&c&d\\cr e&0&f\\cr}$$ will have determinant $acf+bde$ which can certainly exceed 1 even if all the variables stand for numbers between zero and one.\n\nshare|improve this answer\nI am talking about sum of row entries... In your case, did you take into account this in your explaination? Sorry I am still reading, wanna be sure we are talking about the same. In my case I consider sum of row entries, not all elements in the matrix \u2013\u00a0 Andry Jun 4 '12 at 2:52\nI edited my questino because I specified the condition on rowas only in the frmula and not using words... It could be misleading. Very sorry for my carelessness \u2013\u00a0 Andry Jun 4 '12 at 2:54\nWhy don't you go away and think about your question for a couple of days and come back when you're able to put into writing the actual question you want to ask instead of something with lots of conditions missing or incorrectly stated? While you're at it, look up the Hadamard bound on determinants, it might answer your question, depending, of course, on what the heck your question might really be. \u2013\u00a0 Gerry Myerson Jun 4 '12 at 3:07\nI can understand that due to my carelessness you had to go through some troubles in understanding what I was looking for. Actually the question is the one here now, no more edits. I simply had in my mind the matrix structure but failed in explaining it and providing good details. I apologized. This being said, I do not think to deserve your bad words as there are many other members in this community behaving really bad towards those who answer their questions. You could simply say to pay more attention, it would have been \"more professional\". \u2013\u00a0 Andry Jun 4 '12 at 3:37\nEach term in the sum isn't necessarily bounded by $n^{-n}$, take a constant multiple of the identity matrix for example.. making all terms ${1 \\over n}$ actually minimizes things as the determinant becomes zero. \u2013\u00a0 Zarrax Jun 4 '12 at 4:59\nshow 1 more comment\n\nNote that $\\sum_j a_{ij}^2 < \\sum_j a_{ij} < 1$. So the magnitude of each row, viewed as a vector in ${\\mathbb R}^n$, is less than one. The absolute value of the determinant of $A$ is the volume of the parallelopiped spanned by the rows, which is at most the product of the magnitudes of the row vectors, and therefore is less than one in this case.\n\nIf you want to do it algebraically, you can prove it by induction on the dimension, the $1$ by $1$ case being trivial. Then you can do a cofactor expansion along any $i$th row, getting that $$det(A) = \\sum_j (-1)^{i + j} a_{ij} \\,det(A_{ij})$$ Note that each matrix $A_{ij}$ also satisfies the conditions of the problems, so each $|det(A_{ij})| < 1$ by induction hypothesis. You then get $$|det(A)| < \\sum_j |a_{ij}||det(A_{ij})|$$ $$< \\sum_j |a_{ij}|$$ $$< 1$$\n\nshare|improve this answer\nI think you'll find that what you are using in the first paragraph is what's commonly referred to as the Hadamard bound. \u2013\u00a0 Gerry Myerson Jun 4 '12 at 6:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/107694/constructing-numbers-from-basic-arithmetic-on-digits?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI was tooling around over on stackoverflow and happened upon this question. To summarise, given the set of digits $\\{1,2,3,4,5,6,7,8,9\\}$ and a set of basic arithmetic (binary) operators $\\{+,-,\\times,/\\}$, what is the least number of operations you need to construct a given integer? For example $239 = 8\\times6\\times5-1$, requires 3 operations.\n\nMy conjecture is that division doesn't help you. There is no number that can be constructed using division, that can't be constructed without division using the same number operations (or fewer). Can anyone prove or disprove this?\n\nshare|improve this question\nI have a feeling that you do need division sometimes. For instance, take numbers like 1+9+81+729+...+9^k. These are easy to make with division: (9*9*9*...*9-1)/8. But I'm not sure how to prove this works; that is, that at least some of these numbers are \"rough\" enough that there's no more efficient way to make them. \u2013\u00a0 Lopsy Feb 10 '12 at 2:48\nLopsy: You can calculate with a computer the smallest number of operations required with or without division. That wouldn't constitute a proof for general $n$, but will at least answer the OP's question. \u2013\u00a0 Yuval Filmus Feb 10 '12 at 5:46\nCould you be more precise of what to do if a division is not exact? Either you simply forbid this, or you consider the rational result as a valid intermediate value, or you take the quotient ignoring the remainder. I think your conjecture is false even if you simply forbid inexact divisions, but it helps to have carity about this first. \u2013\u00a0 Marc van Leeuwen Feb 10 '12 at 12:34\n@Marc: I used only exact division for my answer. \u2013\u00a0 joriki Feb 10 '12 at 13:02\nDo you allow parenthesis? eg. (1+9)*9 \u2013\u00a0 user1708 Feb 10 '12 at 13:19\nshow 1 more comment\n\n1 Answer\n\nup vote 12 down vote accepted\n\nDivision does help, but you have to use seven operations (eight operands) to find a case where it does. Here's a list of all expressions with seven operations with values that can't be obtained with seven operations without division:\n\n$$ \\begin{eqnarray} (5\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9-1)/2&=&89302\\\\ (5\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9+1)/2&=&89303\\\\ (7\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9-5)/2&=&125021\\\\ (7\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9+5)/2&=&125026\\\\ (7\\cdot7\\cdot9\\cdot9\\cdot9\\cdot9-3)/2&=&160743\\\\ (7\\cdot7\\cdot9\\cdot9\\cdot9\\cdot9+5)/2&=&160747\\\\ (7\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-1)/2&=&206671\\\\ (7\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9+3)/2&=&206673\\\\ (7\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9+5)/2&=&206674\\\\ (9\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-7)/2&=&265717\\\\ (9\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-5)/2&=&265718 \\end{eqnarray} $$\n\nHere's the code I used to find them.\n\nSo Lopsy's idea turns out to be a good one. In fact I found the penultimate example, $(9\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-7)/2=265717$ with a lot less computational effort than the others by factorizing the numbers of the form $(9^6\\pm d)/2$, where $d$ is a single-digit number, finding that $(9^6-7)/2=265717$ is a prime and thus can't be the result of a multiplication, noting that a number this large requires a product with at least six factors and could thus only be formed as $p_7\\pm p_1$, $p_6\\pm p_1\\pm p_1$ or $p_6\\pm p_2$ (where $p_k$ is a product of $k$ factors), and checking that no such expression yields $265717$.\n\nHere's an attempt at explaining that all the counterexamples involve division by $2$. The number should be large, in order to require most of the operations to be multiplications and to leave as little room as possible for additions, subtractions and small factors. The divisor cannot divide any of the other numbers, since then it would have to divide both terms and thus could be canceled. Thus, if the divisor were $3$, there could be no factors of $9$, which lowers the attainable maximum to $(8^6+8)/3=87384$, which is below the smallest counterexample. The higher the divisor $d$, the fewer potential candidates there are, since only every $d$-th number is divisible by $d$, and also the lower the attainable maximum. For $d=4$, the value of $(9^6+7)/4=132862$ is still within the lower range of the actual counterexamples, but with only half as many candidates for counterexamples, it may be just a coincidence that there aren't any. For $d=5$, the maximum $(9^6+9)/5=106290$ is already at the lower end of the range, and with only $2/5$ as many candidates, counterexamples aren't to be expected. Since $d=6$ is excluded for the same reason as $d=3$, the next possibility is $7$. For $d=7$, the maximum $(9^6+6)/7=75921$ is already below the smallest counterexample.\n\nHere's a table showing the number $a_n$ of values expressible with $n$ operations (excluding division) and, as requested in a comment, the least value $b_n$ not expressible with $n$ operations:\n\n$$ \\begin{array}{c|c} n&0&1&2&3&4&5&6&7\\\\ \\hline a_n&9&39&155&739&3667&16947&77860&379072\\\\ b_n&10&19&92&417&851&4237&14771&73237 \\end{array} $$\n\nThe growth rate appears to be well below $9$. That shows that it would be quite wrong to model the expressions as having random values uniformly distributed over the accessible interval $[1,9^{n+1}]$ (where $n$ is the number of operations). The generating function for the number of expressions with $n$ operations (excluding division) approximately satisfies\n\n\n(approximately because the symmetry factor $\\frac12$ shouldn't be applied when combining two identical expressions), and the solution is\n\n\nwith a singularity at $x=1/54$, so the growth rate of the number of expressions is $54$. If their values were uniformly distributed, the probability for a value not to be represented by an expression would be roughly of the order\n\n$$\\left(1-\\frac1{9^n}\\right)^{54^n}\\approx\\mathrm e^{-6^n}\\;,$$\n\nso we would expect almost complete coverage, i.e. a growth rate of $9$.\n\nshare|improve this answer\nWow really a nice answer, which reflects your hard-work sir. Fantastic answer. \u2013\u00a0 Iyengar Feb 10 '12 at 13:03\n@Iyengar: Thank you! \u2013\u00a0 joriki Feb 10 '12 at 13:06\n+1. Could you add a table with the smallest number not expressible in n operations? \u2013\u00a0 user1708 Feb 10 '12 at 13:19\n@Holowitz: Done. \u2013\u00a0 joriki Feb 10 '12 at 13:48\nExcellent stuff. If you're still keen you could see what happens for negative numbers. \u2013\u00a0 wxffles Feb 10 '12 at 19:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/223895/injectivity-of-homomorphism-in-localization\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\alpha:A\\to B$ be a ring homomorphism, $Q\\subset B$ a prime ideal, $P=\\alpha^{-1}Q\\subset A$ a prime ideal. Consider the natural map $\\alpha_Q:A_P\\to B_Q$ defined by $\\alpha_Q(a/b)=\\alpha(a)/\\alpha(b)$.\n\nSuppose that $\\alpha$ is injective. Then is $\\alpha_Q$ always injective? I think so, but I'm clearly being too dense to prove it! My argument goes as follows.\n\nLet $\\alpha(a)/\\alpha(b)=0$. Then $\\exists c \\in B\\setminus Q$ s.t. $c\\alpha(a)=0$. If $B$ is a domain we are done. If not we must exhibit some $d\\in A\\setminus P$ s.t. $da=0$. Obviously this is true if $c =\\alpha(d)$. But I don't see how I have any information to prove this!\n\nAm I wrong and this is actually false? If so could someone show me the trivial counterexample I must be missing?\n\nMany thanks!\n\nshare|improve this question\nI wish someone would provide us a counterexample. I tried to find it, but failed. \u2013\u00a0 Makoto Kato Oct 30 '12 at 0:29\nadd comment\n\n2 Answers\n\nup vote 8 down vote accepted\n\nTake $A=K[X]$, $B=K[X,Y]/(XY)$ and $\\alpha$ the following application $$A=K[X]\\subset K[X,Y]\\rightarrow K[X,Y]/(XY)=B.$$ Obviously $\\alpha$ is injective. Write $B=K[x,y]$ with $xy=0$. Let $Q=xB$. It is obvious that $Q$ is prime ($B/Q\\cong K[Y]$) and $P=\\alpha^{-1}(Q)=XA$. Now choose $\\frac{X}{1}\\in A_P$ and observe that $\\alpha(\\frac{X}{1})=\\frac{x}{1}$. But $\\frac{x}{1}=\\frac{0}{1}$ in $B_Q$ because $yx=0$ and $y\\in B-Q$.\n\nshare|improve this answer\n+1 Congratulations. \u2013\u00a0 Makoto Kato Oct 30 '12 at 6:52\nThat's a great counterexample - thanks! \u2013\u00a0 Edward Hughes Oct 30 '12 at 8:42\nadd comment\n\nSince algebraic geometry is one of the tags, let me give a geometric account of the problem: one is given Spec $B \\to $ Spec $A$ dominant, and one wants to show that this isn't necessarily dominant in a n.h. of some point $Q$ of Spec $B$. The basic way to achieve this is to arrange Spec $B$ to be the union of two components, one which maps dominantly to Spec $A$ and one which doesn't, and take $Q$ to be a point lying (only) on the component that doesn't map dominantly. This is what happens in YACP's answer: Spec $B$ is two lines crossing, Spec $A$ is a single line, and the map is the identity on the first line and constant on the second line. The point $Q$ is then taken to be the generic point of the second line.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/117194/fastest-way-to-try-all-passwords\nText:\nTake the 2-minute tour \u00d7\n\nSuppose you have a computer with a password of length $k$ in an alphabet of $n$ letters. You can write an arbitrarly long word and the computer will try all the subwords of $k$ consecutive letters. What is the smallest word that contains all combinations of $k$ letters as subword? (i.e. the fastest way to hack the computer :) )\n\nThe smallest word that contains $n^k$ subwords of size $k$ has length $k-1^+n^k$ and based on some easy cases, we would like to prove that it is in fact possible to find a word of such length that contains all possible passwords. The problem can be translated into a problem in graph theory, by taking as vertices all words of length $k$.\n\nWe tried $k=2$, where you can prove the conjecture by induction. For $n=2$ and small $k$ it also works.\n\nshare|improve this question\nSee De Bruijn sequence and De Bruijn graph \u2013\u00a0 TMM Mar 6 '12 at 19:35\n@TMM: Why not add that as an answer? \u2013\u00a0 Aryabhata Mar 6 '12 at 19:39\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nWhat you are looking for is the De Bruijn sequence and the associated graph, the De Bruijn graph.\n\nHamilton paths in the De Bruijn graph correspond to De Bruijn sequences. Hamilton paths in the De Bruijn graph of words of length $k$ also correspond to Euler tours in the De Bruijn graph of words of length $k - 1$, and since all De Bruijn graphs are regular, the existence of such sequences for each alphabet size $n$ and word length $k$ follows.\n\n(A few years ago I stumbled upon these graphs for my thesis, so I can provide more fascinating properties of these graphs if needed!)\n\nshare|improve this answer\nThat is exactly what I was looking for! Thanks \u2013\u00a0 Michalis Mar 6 '12 at 20:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/36376/why-magnetic-monopole-found-in-spin-ice-dont-modify-the-maxwells-equations\nText:\nTake the 2-minute tour \u00d7\n\nMagnetic monopole predicted by Dirac nearly a century ago was found in spin ice as quasi-particle(2). My question is Why magnetic monopole found in spin ice don't modify the Maxwell's Equations? (I know they are not elementary particles but quasi-particles.)\n\n(1) Dirac, P. A. M. Quantised singularities in the electromagnetic field. Proc. R. Soc. A 133, 60\u201372 (1931)\n\n(2) Castelnovo, C., Moessner, R. & Sondhi, S. Magnetic monopoles in spin ice. Nature 451, 42\u201345 (2008).\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nThese are \"fake monopoles\", in the sense that the north and south poles are not actually separated. They are the ends of thin tubes which behave like Dirac strings - like long thin twisted magnets. The tubes are formed due to geometrical frustration, which forces the magnetic field to be orientated either toward the outside or toward the inside of the tetrahedral cells. The tetrahedral cells end up by having two faces with \"spin in\" orientation and two faces with \"spin out\" orientation. Two tetrahedral cells couple one another like tiny magnets, so that tiny magnetic tubes form. The ends seem to be separated north and south magnetic poles, while in fact they are connected through the tube.\n\nHad they been genuine monopoles, they would have indeed modified Gauss's law for magnetism, and Faraday's law of induction, by adding terms corresponding to magnetic charge density and current.\n\nshare|improve this answer\nThank you very much for the answer! \u2013\u00a0 Jeremy Sep 17 '12 at 1:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/9352/what-effect-would-liquid-air-have-on-a-resonant-coil\nText:\nTake the 2-minute tour \u00d7\n\nThis description of Tesla's \"magnifying transmitter\", which supposedly used electrical resonance to transmit energy (similar to resonant inductive coupling?) states that the coils (or at least part of them) are submerged in liquid air, which \"causes an extraordinary magnification of oscillation in the resonating circuits\".\n\nWhat effect would submerging a coil in liquid air actually have? Does it just decrease resistance of the coils? I know with resonant inductive coupling, efficiency is improved with higher Q factor of the RLC circuit, and Q is improved by reducing the resistive component, so would this make some sense?\n\nDoes it have any other effects? Electrical conductivity, magnetic permeability, etc?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nIf that's an actual Tesla quote, it sounds like he's talking about the high output voltage during silent operation when no plasma streamers are present.\n\nIn that case the max voltage limit of a well-designed Tesla coil is determined by the maximum power limit on the power supply (volts and max current of wall outlet, breaker panel, etc.) Since radio wave losses are insignificant, all of the operating power goes into heating the spark gap, conductors, and the capacitor dielectric. When no spark streamers are present, the voltage rises high, and the entire TC becomes very hot!\n\nCopper resistivity drops by about 10X at LN2 temperature. If input power is adjusted to be constant, then a conductivity drop of 10X gives a resonator current increase of SQRT(10) ~= 3 times. For a simple linear RLC resonator the capacitor voltage is proportional to the inductor current, so liquid nitrogen cooling should increase the main TC output voltage by about 3X. (This is assuming that copper losses were dominant. If spark gap and capacitor dielectric loss was significant, then LN2 would give less than 3X voltage improvement.)\n\nAnd if spark streamers break out, this math doesn't work. If the majority of the available power was going into the plasma, then reducing the copper losses wouldn't increase the spark length by much.\n\n\nshare|improve this answer\nadd comment\n\nLiquid oxygen is paramagnetic. A Tesla coil is basically an air-core, high-frequency transformer. Immersing the coil in liquid air would be like putting a core in the transformer with a permeability higher than non-liquified air.\n\nshare|improve this answer\nThat description mentions a \"Magnetic Core\" already, so it's not an air core. Even if it were, the permeability of liquid air appears to be 1.00287, vs 1.00000037 for gaseous air. Not much of a difference compared to iron. \u2013\u00a0 endolith May 16 '11 at 21:40\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/149981/existence-of-lebesgue-integral/150002\nText:\nTake the 2-minute tour \u00d7\n\nHi, I have a question on my homework.\n\nFor each positive integer $n$, let $f_n:\\mathbb{R}\\to\\mathbb{R}$ be integrable, $ ~f_n\\geq 0$ and $f_n(x)\\to f$ pointwise. I need to show that if $\\int f_n$ converges to some finite $c\\geq 0$, then $\\int f$ exists and $0\\leq\\int f\\leq c$.\n\nI am thinking that for an arbitrary function $f$ , the Lebesgue integral exists iff $f$ is Lebesgue integrable or $\\int f$ is infinite (is this correct?). However, for a nonnegative function $f$, the Lebesgue integral always exists and $\\int f = \\sup\\{\\int g\uff1a0\\leq g\\leq f, ~~g$ bounded and supported on a set of finite measure$\\}$.\n\nIf what I am thinking is correct, then the question seems quite straigtforward. We have $f_n(x)$ converges to $f(x)$ for every $x$ and $f_n\\geq 0$ for every $n$. So $f$ is nonnegative everywhere and $\\int f$ exists since the Lebesgue integral exists for all nonnegative functions. That $0\\leq\\int f\\leq c$ just follows from the fact that $f \\leq 0$ and Fatou's Lemma.\n\nCan someone tell me under what condition the Lebesgue integral exists? Is my attempt correct?\n\nshare|improve this question\nI guess the downvotes come from poor formatting. Do you know how to put LaTeX? \u2013\u00a0 Davide Giraudo May 26 '12 at 9:28\ni havent learnt laytex... Can any one help me to edit it ? \u2013\u00a0 keji May 26 '12 at 9:38\n\"...Lebesgue integral exist iff $f$ is Lebesgue integrable...\" The definiiton of Lebesgue integrability is that the Lebesgue integral exists. \u2013\u00a0 Austin Mohr May 26 '12 at 9:47\nI edited it to make it look pretty in LaTeX (if the edit goes through). I'm also relatively new around here but the way I understand it it's considered a bit impolite to copy words like \"Show that\", since you're asking a question, not making a request. That might have played into the down vote as well. \u2013\u00a0 Eric Stucky May 26 '12 at 9:58\nLet $A \\subset [0,1]$ be a set that is not Lebesgue measurable and let $1_A$ be its characteristic function. Then formally, $\\int 1_A = \\lambda(A)$ so that its integral does not exist. But it is contained in $[0,1]$, so it it not because is measure is infinity. \u2013\u00a0 Juan Sim\u00f5es May 26 '12 at 10:05\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nDepending on your course, showing that \"the Lebesgue integral exists\" could include showing that the integral (which can be defined for any non-negative measurable function) is finite. But it doesn't matter here: for any non-negative measurable (you didn't mention this; see also Juan's comment) function $g$, $\\int g$ can be defined, and Fatou's lemma holds in that context, so that finiteness of the integral is established by afterwards by $$\\int f\\leq c.$$\n\nIn short: Your approach is correct.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/216311/fourier-transform-and-sampling-time\nText:\nTake the 2-minute tour \u00d7\n\nGiven a signal $x(t)$ and the $X(\\omega)$ obtained from $x(t)$ using a FFT with a sampling time $Ts$, I get a subset of $X(\\omega)$: $Y(\\omega)$ obtained from $X(\\omega)$ taking it between $\\omega_0$ and $\\omega_1$, the question is: if I make the IFFT of $Y(\\omega)$, does the new signal $y(t)$ have the same sampling time $Ts$? Thanks in advance\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nStarting from $x(t)$, you sample it with a sampling time $T_s$, then obtain a discrete time signal $x(n T_s)$ or $x(n)$, on which you apply FFT, to obtain the discrete spectrum $X(m)$ (the notation $X(\\omega)$ usually denotes the Discrete Time Fourier Transform, which is different from the Discrete Fourier Transform, a fast version of the latter is FFT). Now, if you truncate $X(m)$ by keeping its values from $m_0$ up to $m_1$ and discarding the rest, without zero padding, then you are changing the FFT resolution, which is proportional to $1/N$, where $N$ is the number of your samples. The FFT resolution is the frequency distance between adjacent FFT points and corresponds to time distance between adjacent signal points (in the time domain). So yes, you are changing the sampling rate of your original signal. My advice is to use zero padding to avoid that.\n\nshare|improve this answer\nwhen I get $Y(\\omega)$, I don't multiply with a window. In that case I would obtain a 'zero padding' of the whole signal $X(\\omega)$. In my case, I get $only$ the signal between $\\omega_0$ and $\\omega_1$ \u2013\u00a0 Riccardo.Alestra Oct 18 '12 at 14:01\nI see. I will modify my answer for that case. \u2013\u00a0 Manos Oct 18 '12 at 14:59\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/111161/nonhomeomorphic-cw-complexes-that-are-stably-homeomorphic?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nDo there exist CW-complexes $X$ and $Y$ that are not homeomorphic, but $X \\times I$ and $Y \\times I$ are homeomorphic? Here $I$ denotes the unit interval $[0, 1]$.\n\nshare|improve this question\nSee mathoverflow.net/questions/26385/\u2026 \u2013\u00a0 j.c. Nov 1 '12 at 15:26\n\n1 Answer 1\n\nYes. Take $X$ a punctured torus ($T^2\\setminus$open disk) and $Y$ a three-punctured $S^2$. Then $X\\times I=Y\\times I$ is a genus 2 handlebody.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/85115/euler-characteristic-of-weierstrass-divisor\nText:\nTake the 2-minute tour \u00d7\n\nI have a strong feeling that, for a compact connected Riemann surface $X$ of genus $g>0$, the Euler characteristic of the Weierstrass divisor $W$ equals $$\\chi(X,\\mathcal{O}_X(W)) = (g-1)^2.$$ Is this true?\n\n\nBy Riemann-Roch, the Euler characteristic is given by $$ \\chi(X,W) = g^3 -g + 1- g = g^3-2g+1.$$\n\nThis is not equal to $(g-1)^2$ for $g>1$.\n\nshare|improve this question\n\nclosed as too localized by Angelo, Qiaochu Yuan, Dan Petersen, Felipe Voloch, Mark Sapir Jan 7 '12 at 19:12\n\n\nJust apply Riemann-Roch: the divisor $W$ has degree $g^3 - g$. I voted to close as \"Too localized\". \u2013\u00a0 Angelo Jan 7 '12 at 7:19\nYou're right. I asked this question too quickly. \u2013\u00a0 Harized Jan 7 '12 at 7:20\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nI'm not sure I've heard the term Weierstrass divisor before, but I take it you mean the sum of the Weierstrass points, with multiplicities given by the weights. In this case, the sum of the weights, and hence the degree of the divisor, is given by\n\n$$\\sum_{p\\in X} w(p) = (g-1)g(g+1).$$\n\nBy Riemann-Roch, the Euler characteristic then equals $g^3-2g+1$, which is different from your formula.\n\nSee Arbarello-Cornalba-Griffiths-Harris, Geometry of Algebraic Curves, exercise batch I.E.\n\nshare|improve this answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/126477/resolvent-of-laplacian\nText:\nTake the 2-minute tour \u00d7\n\n\nLet $(M,g)$ be a Riemannian manifold and $-\\Delta$ the Laplacian on M (acting on smooth functions). Then the resolvent $R(\\xi)$ of $-\\Delta$ is a compact operator.\n\nIs it possible to find for every $\\epsilon>0$, a point in the resolvent set $\\xi$, s.t. $\\Vert R(\\xi) \\Vert\\leq \\epsilon$?\n\nMaybe it is very easy to prove, but I'm not so familiar with spectral theory. I hope you can help me.\n\n\nshare|improve this question\nThe resolvent of the Laplacian is compact if $(M,g)$ is compact. In general, the spectrum of the Laplacian will not be discrete. Consider the classical example $-y^2( \\partial^2_x + \\partial^2_y)$ on $SL_2(\\mathbb{Z}) \\backslash \\mathbb{H}$ for example. The spectrum has a continuous part. \u2013\u00a0 Marc Palm Apr 4 '13 at 7:01\nAssuming a self-adjoint realization of the Laplacian: Yes. The resolvent $R$ of a self-adjoint operator always satisfies the estimate $\\|R(z)\\|\\leq |\\mathrm{Im} z|^{-1}$ if $z$ is not real. \u2013\u00a0 S\u00f6nke Hansen Apr 4 '13 at 7:02\nJust to be sure that I am not confusing the OP. I was only saying that the resolvent will not always be compact. Nevertheless, you get your estimate as a chep consequence of functional calculus as Nik Weaver explains. @Soenke Hansen: I would believe that your estimate needs at least some constant, or not? \u2013\u00a0 Marc Palm Apr 4 '13 at 7:12\n@Marc: I think S\u00f6nke's estimate is right. As I mentioned, $\\|R(z)\\| = 1/{\\rm dist}(z, {\\rm spec}(-\\Delta))$. The distance from $z$ to ${\\rm spec}(-\\Delta)$ is always at least $|{\\rm Im}\\, z|$ since ${\\rm spec}(-\\Delta) \\subseteq {\\bf R}$. \u2013\u00a0 Nik Weaver Apr 4 '13 at 7:44\nHowever, I thought it was simpler to take $z < 0$ since actually ${\\rm spec}(-\\Delta) \\subseteq [0,\\infty)$. \u2013\u00a0 Nik Weaver Apr 4 '13 at 7:45\n\n2 Answers 2\n\nup vote 10 down vote accepted\n\nSure, since $-\\Delta$ is a positive operator, by the spectral theorem it can be realized as multiplication by a positive function $f(x)$ on some $L^2(X)$ space. Then $R(\\xi)$ is multiplication by $\\frac{1}{\\xi - f(x)}$ and its operator norm is the sup norm of this function. If $\\xi < 0$ then the function $\\frac{1}{\\xi - f(x)}$ is bounded by $\\frac{1}{|\\xi|}$ in absolute value, so as $\\xi \\to -\\infty$ we have $\\|R(\\xi)\\| \\to 0$.\n\nThe point is that $\\|R(\\xi)\\|$ equals one over the distance from $\\xi$ to ${\\rm spec}(-\\Delta)$.\n\nIf you restrict $\\xi$ to be positive the question is more interesting. On the unit circle ${\\bf T}^1$ the eigenvalues of $-\\Delta$ are the square integers, and for any $\\epsilon > 0$ we can find $\\xi > 0$ such that $|\\xi - n^2| > \\frac{1}{\\epsilon}$ for every $n \\in {\\bf Z}$, so we can still ensure that $\\|R(\\xi)\\| \\to 0$. In other words, the eigenvalues are spaced farther and farther apart so $\\xi > 0$ can be chosen arbitrarily far from the spectrum of $-\\Delta$. But on ${\\bf T}^4$ the eigenvalues of $-\\Delta$ are of the form $a^2 + b^2 + c^2 + d^2$ for $a, b, c, d \\in {\\bf Z}$, which means that every positive integer is an eigenvalue. Thus any $\\xi > 0$ is at most $\\frac{1}{2}$ units away from an eigenvalue, and therefore $\\|R(\\xi)\\| \\geq 2$ for every $\\xi > 0$.\n\nshare|improve this answer\nNik, I think you meant $T^4$ instead of $S^4$. \u2013\u00a0 Liviu Nicolaescu Apr 4 '13 at 9:17\n@Liviu: you're right, I'll correct it. \u2013\u00a0 Nik Weaver Apr 4 '13 at 16:52\n\nThis is mostly enhancing Nik Weaver's comments. Suppose that $M$ is compact of dimension $m$. If $m\\geq 2$, then for a generic metric $g$ on $M$ the eigenvalues $\\lambda_k$ of the Laplacian $\\Delta_g$ are simple. In general, for any $m$, Weyl's spectral estimates imply that\n\n$$\\lambda_k \\sim C_m \\left(\\frac{k}{{\\rm vol}_g(M)}\\right)^{\\frac{2}{m}}\\;\\;\\mbox{as $k\\to\\infty$}, $$\n\nwhere $C_m$ is an explicit universal constant that depends only on $m$. (Hat-tip to Marc Palm!) In particular this shows that for $m\\geq 2$ and a generic metric we have\n\n$$0<\\lambda_{k+1}-\\lambda_k =O(1). $$\n\nNow Nik Weaver's argument shows that there exists $r_0>0$ such for any $\\xi\\in [0,\\infty)\\setminus {\\rm spec}\\;(\\Delta)$ we have $\\Vert(R(\\xi)\\Vert\\geq r_0$.\n\nshare|improve this answer\n$C_m$ also depends on the volume of $M$? \u2013\u00a0 Marc Palm Apr 4 '13 at 9:51\n@Marc Palm: Yes, the constant is proportional to the volume. The basic principle of Weyl asymptotics is that the number of eigenvalues $<\\lambda$ behaves, asymptotically as $\\lambda\\to+\\infty$, as the symplectic volume of $\\{(x,\\xi)\\in T^*M; |\\xi|^2<\\lambda\\}$. \u2013\u00a0 S\u00f6nke Hansen Apr 4 '13 at 10:11\n@ Marc Palm I've edited my answer to incoporate the dependence on volume. \u2013\u00a0 Liviu Nicolaescu Apr 4 '13 at 11:52\nThe eigenvalues of the laplacian on the circle of radius $R$ are $\\lambda_k=(k/R)^2=(k/R)^{2/m}$, $m=\\dim S^1=1$. Note that the volume of this circle is $2\\pi R$. \u2013\u00a0 Liviu Nicolaescu Apr 4 '13 at 17:41\nYou missed the words \"generic metric\". As I mentioned in the first paragraph of my answer for a generic metric the eigenvalues are simple. This is an old result of Karen Uhlenbeck, Amer. J. Math. vol.98(1976), p. 1059-1078. \u2013\u00a0 Liviu Nicolaescu Apr 5 '13 at 12:04\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/92233/projection-onto-a-quadratic-cone\nText:\nTake the 2-minute tour \u00d7\n\nConsider a constraint of the form\n\n$$ f(x) := x^T A x = 0 $$\n\nwhere $A \\in \\mathbb{R}^n$ is symmetric but may be singular and indefinite. The constraint set $C$ is a (nonconvex) cone, since for any $x \\in C$ we also have $ux \\in C$ for all $u \\in \\mathbb{R}$.\n\nGiven a point $x_0$ not necessarily in $C$, I am seeking a cheap computational procedure for finding a nearby (in the Euclidean sense) point $x \\in C$. \"Nearby\" means something like the distance between $x$ and the closest point $x^* \\in C$ can be bounded in terms of the distance between $x_0$ and $C$. \"Cheap\" means something like $O(n \\log n)$ or some (very) small polynomial at worst.\n\nPerforming exact line search along the constraint gradient $-2Ax$ is one idea, yielding a single scalar quadratic equation for the shortest time t: $\\min_t f(x_0 - 2tAx_0)$. Unfortunately, the roots of this equation are not always real.\n\n\nshare|improve this question\nDo I correctly understand that the computational time shouldn't depend on point $x_0$ itself? \u2013\u00a0 Kirill Shmakov Mar 26 '12 at 18:42\nI suppose it could. \u2013\u00a0 TerronaBell Mar 27 '12 at 5:33\n\n1 Answer 1\n\nIf you write the problem of finding the closest point to $x_0$ on the cone with a Lagrange multiplier, the solution must have the form $x = (\\lambda A + I )^{-1}x_0$.\n\nIf you start by diagonalizing $A$, the inverse can be computed efficiently and you can search for $\\lambda$ by dichotomy. The algorithm will run in $O(n^2 \\log{1/\\epsilon})$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/47072/fermis-golden-rule-and-density-of-states/47075\nText:\nTake the tour \u00d7\n\nI know Fermi's Golden Rule in the form\n\n$$\\Gamma_{fi} ~=~ \\sum_{f}\\frac{2\\pi}{\\hbar}\\delta (E_f - E_i)|M_{fi}|^2$$\n\nwhere $\\Gamma_{fi}$ is the probability transition rate, $M_{fi}$ are the transition matrix elements.\n\nI'm struggling to do a derivation based on the density of states. I know that under certain circumstances it's a good approximation to replace $\\sum_f$ with $\\int_F \\rho(E_f) \\textrm{d}E_f$ to calculate the transition probability, for some energy range $F$.\n\nDoing this calculation I obtain\n\n$$\\Gamma_{fi} ~=~ \\int \\rho(E_f) \\frac{2\\pi}{\\hbar}\\delta (E_f - E_i) |M_{fi}|^2\\textrm{d}E_f.$$\n\nNow assuming that the $M_{fi}$ are constant in the energy range under the integral we get\n\n$$\\Gamma_{fi} ~=~ \\rho(E_i) \\frac{2\\pi}{\\hbar} |M_{fi}|^2.$$\n\nNow this is absolutely not what is written anywhere else. Other sources pull the $\\rho(E_f)$ out of the integral to obtain Fermi's Golden Rule of the form\n\n$$\\Gamma_{fi} ~=~ \\rho(E_f) \\frac{2\\pi}{\\hbar} |M_{fi}|^2$$\n\nfor any $f$ with $E_f$ in $F$ which makes much more physical sense. But why is what I've done wrong? If anything it should be more precise, because I have actually done the integral! Where have I missed something?\n\nshare|improve this question\nIt's the same thing because $E_i=E_f$ in this treatment, isn't it? \u2013\u00a0 Lubo\u0161 Motl Dec 17 '12 at 14:32\nadd comment\n\n1 Answer\n\nAs proposed by Lubos, the delta function you started with $\\delta(E_i-E_f)$ forces the final result to be invariant by $E_i \\leftrightarrow E_f$.\n\nshare|improve this answer\nI'm afraid I don't quite see this - could you expand on your argument perhaps? \u2013\u00a0 Edward Hughes Dec 17 '12 at 15:09\nWell, are you familiar with identity:$$\\delta(x-x_0)f(x) = \\delta(x-x_0)f(x_0)$$ true for distributions, it implies quite directly that you can change $\\rho(E_f)$ for $\\rho(E_i)$ in your second equation. \u2013\u00a0 Learning is a mess Dec 17 '12 at 15:15\nOh of course - apologies for missing that. But surely in general $\\rho(E_i)$ and $\\rho(E_f)$ are different even if $E_i = E_f$? For example the decay of one particle into two gives you an extra degree of freedom in $\\rho(E_f)$ that you didn't have in $\\rho(E_i)$. Or is this logic wrong? \u2013\u00a0 Edward Hughes Dec 17 '12 at 15:18\nDear Edward, you're summing or integrating over $f$ and the integrand depends on $M_{fi}$ and you decided you may eliminate the summation/integral completely. This implicitly means that for each energy $E_f$, the state must actually be unique. Otherwise you would have to keep the sum over the other quantum numbers that commute with the energy. \u2013\u00a0 Lubo\u0161 Motl Dec 17 '12 at 16:17\nI think the point of confusion here is that $\\rho(E)$ is the density of final states. Perhaps the notation would be more clear if $\\rho_f(E)$ were written instead. Now it should be clear that since energy is conserved $\\rho_f(E_f)=\\rho_f(E_i)$. Note that the density of initial states, which you might write as $\\rho_i(E)$ is not equal to $\\rho_f(E)$, as your comment, \"But surely...\" seems to suggest. \u2013\u00a0 MarkWayne Dec 17 '12 at 16:58\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://www.chegg.com/homework-help/questions-and-answers/wedge-shaped-block-mass-m-rests-smooth-horizontal-table-small-block-mass-m-placed-upper-su-q180605\nText:\nClassical Mechanics\n\n0 pts pending\nA wedge-shaped block of mass M rests on a smooth horizontal table.A small block of mass m is placed on its upper surface, which isalso smooth and inclined at an angle \u03b1 to the horizontal. Thesystem is released from rest. Write down the horizontal componentof momentum, and the kinetic energy of the system, in terms of thevelocity v of the wedge and the velocity u of the small blockrelative to it. Using conservation of momentum and the equation forthe rate of change of kinetic energy, find the accelerations of theblocks.\n\ndu/dt = (M + m)gsin\u03b1/(M + msin2x)\ndv/dt = mgsin\u03b1cos\u03b1/(M + msin2x)\n\nAnswers (0)"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/7568/can-reading-glasses-improve-ones-eyesight-of-objects-lying-in-the-long-range\nText:\nTake the tour \u00d7\n\nSomeone told me that reading glasses (a priori with a magnifying glass effect only) improve one's eyesight of objects lying in the long range distance. I am really sceptic about it since everything is blurry if I look at objects through those glasses! Is it possible (for this particular person at least)?\n\nshare|improve this question\nI'm not really sure what you are getting at here. I, for one, and near sighted, which means I cannot see things clearly in the distance. For me, this is at about 10 meters or so and I cant clearly read something as large as a scoreboard. So for me, glasses do vastly improve my eyesight for objects lying in the long range. Is the question can this be done in the general (normal 20/20) case? I know there is a limit to what you can clearly see based on the properties of light and the distance between your eyes, so that would be the limit, I'm willing to bet that is nearly reachable. \u2013\u00a0 CJB Mar 25 '11 at 18:31\n@CJB -- I think the key word here is reading glasses, which are converging lenses, unlike a nearsighted person's eyeglasses, which are diverging lenses. That's what wok means by the comment about \"magnifying glass effect.\" \u2013\u00a0 Ted Bunn Mar 25 '11 at 18:34\nAhhh, decent chance I read over that without even registering it. Then this question makes alot more sense, and is alot more clear \u2013\u00a0 CJB Mar 25 '11 at 18:49\n\"Reading glasses\" are those, when Granny says: My eyes are quite ok, but my arms are not long enough any more. \u2013\u00a0 Georg Mar 25 '11 at 19:24\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nI don't think this is possible. Suppose that your unaided eye can focus on objects over some range of distanced from $d_1$ (closest) to $d_2$ (furthest). Putting a converging lens in front of your eye reduces both $d_1$ and $d_2$. That is, it shifts the range of distances over which you can focus closer to you, not further.\n\nHere's the geometric-optics proof of this. Varying the distance at which you can focus is equivalent to varying the effective focal length of your eye. If $D$ is the diameter of your eye, and $d$ is the distance of the object you're focusing on, then the focal length is given by $$ {1\\over f}={1\\over d}+{1\\over D}. $$ When you put on your reading glasses, the effective $f$ is decreased, or to put it another way, the effective power of the lens, $1/f$, is increased. (To be specific, $1/f_{\\rm new}=1/f_{\\rm old}+1/f_{\\rm lens}$.) So the left side of the equation becomes larger. $D$ doesn't change, so $1/d$ must become larger. So $d$, the distance to which you focus, becomes less.\n\nshare|improve this answer\nThis makes sense: I have looked at the benefits of a converging lens on a random page about vision of Wikipedia, and reducing the focal distance makes objects more focused in some cases. However, does it still work if we consider $d=+\\infty$ for long range distance? \u2013\u00a0 Wok Mar 25 '11 at 18:56\nIf you can already focus to $d=\\infty$, then you may or may not still be able to focus to $d=\\infty$ after you put on reading glasses. That is, they may not hurt your ability to focus to long distances, but they can't help -- because your distance vision is already perfect. \u2013\u00a0 Ted Bunn Mar 25 '11 at 18:59\nTrue. Thanks! So it is a mystery, the mind is sometimes not rational! \u2013\u00a0 Wok Mar 25 '11 at 19:02\n@Ted Bunn, there might be one exeption, when ones eyes are extremely far-sighted, that much, that the shortest focus is farther away than infinity. In such a case, the convex lens would help to get the focus down to infinity or less. I don't know, whether such extreme far-sightedness really occurs. \u2013\u00a0 Georg Mar 25 '11 at 19:38\n@Georg -- Certainly true in principle. Such a person would be someone who couldn't see anything in focus, at any distance, with the unaided eye. I don't know if such people exist. If @wok's interlocutor was such a person, that'd be important information! \u2013\u00a0 Ted Bunn Mar 25 '11 at 20:02\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/202821/gambler-with-infinite-bankroll-reaching-his-target\nText:\nTake the 2-minute tour \u00d7\n\nSuppose a gambler with infinite bankroll has a target of winning 10 dollars. He wins/loses $\\$1$ with probabilities $0.48=p$ and $0.52=q$ respectively. What is the probability that he meets the target?\n\nThe answer using the usual methods is $(p/q)^n = (12/13)^{10}.$\n\nBy a rather devious process, I have arrived at a combinatorial formula, $$ \\sum_{k=n}^{\\infty}\\frac{n}{k}{2k-n-1\\choose k-n}p^kq^{(k-n)}, $$ I get the same results, but can it be proved that the results will be identical?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHere's a probabilistic argument. Let $T$ be the hitting time of the state $n$. Then a simple application of the hitting time theorem shows that, for $k\\geq n$, $$\\frac{n}{k}{2k-n-1\\choose k-n}p^kq^{(k-n)}=\\mathbb{P}(T=2k-n).\\tag1$$ Therefore $$\\sum_{k=n}^{\\infty}\\frac{n}{k}{2k-n-1\\choose k-n}p^kq^{(k-n)}=\\mathbb{P}(T<\\infty).\\tag2$$\n\nAs for an analytic argument, use a change of variables and simple properties of binomial coefficients to rewrite the sum on the left hand side of (2) as $$\\sum_{x=0}^{\\infty}\\frac{n}{2x+n}{2x+n\\choose x}p^{x+n}q^x.\\tag3$$ Using formula (5.70) on page 203 of Concrete Mathematics by Graham, Knuth, and Patashnik, the sum in (3) can be written as $$(p\\,{\\cal B}_2(pq))^n=\\left(1-\\sqrt{1-4pq}\\over 2q\\right)^n.$$ For $0\\leq p\\leq 1/2$ and $q=1-p$, this reduces to $(p/q)^n$.\n\nshare|improve this answer\nThanks a bunch ! \u2013\u00a0 true blue anil Sep 27 '12 at 4:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://everything2.com/title/The+mathematician%2527s+lightbulb+quandary\nText:\nHow many mathematicians does it take to change a lightbulb?\n\nTo consider the problem, we must first determine what mathematicians are. Loosely, they may be defined as a subset of the greater set of \"humans\" - which must now also be defined. To choose an arbitrary classification, people could be a Hilbert space. Unfortunately, the only appropriate choice for the \"inner product\" operation between two people is poor for two reasons. First, it is clearly not commutative - what A does to B is not the same as what B does to A, and therefore we lose useful mathematical properties. This could be forgiven - after all, many useful cases are non-commutative. However, the second impropriety in this theory is significantly more challenging. The inner product \u27e8a,b\u27e9 (pronounced a fuck b) certainly is not well-behaved (c.f. Kama Sutra), and can create an infinite amount of trouble (c.f. Oedipus), therefore making this description of humanity mathematically inconvenient. We must therefore assume that mathematicians do not fuck - or more accurately, if they do it does not directly influence the problem at hand.\n\nHaving ruled out Hilbert spaces, we may by analogy rule out all vector spaces. Instead, we should treat mathematicians and humans as a field - mathematicians are added all of the time, sometimes (in tragic circumstances involving battles with can-openers, mad scientists, and horrid jokes) they are subtracted. Division is possible, if only on the cellular level - which is good, for as we have assumed that mathematicians do not fuck, division would be necessary in order to multiply. Having loosely proved that mathematics is a field, we consider different fields by reductio ad absurdum.\n\nClearly, it is possible to have a non-integer number of mathematicians; the circumstances are unpleasant to contemplate, but supremely attainable by application of slicing implements (see references, paying special attention to the actions of Alferd Packer, Jeffrey Dahmer, and so on). However, this case may be safely neglected under the assumption that these postulated non-integer amounts of mathematicians would not survive long enough to change a lightbulb - and if such a one survives, he or she may be defined as a whole survivor, reducing the problem to integers.\n\nNow that we have moved from infinite function spaces through the real numbers, and reached the integers, it seems that our answer is nigh. To deal with zero: zero mathematicians can change no lightbulb, because the product of zero with anything is nothing - and thus no lightbulbs are changed. The next point is perhaps less obvious, and in fact depends on intensive algebraic computations, which have been omitted for the sake of space. Negative mathematicians cannot change light bulbs! This is true if for no other reason than depression, but has been formally proved by suicide (Boltzmann, 1906, Ehrenfest, 1933).\n\nWe are left with the positive integers, the counting numbers: we shall deal with them with the natural numbers' best friend, proof by induction. Clearly, one mathematician can change a light bulb - I have done it myself, though the great master Gauss no doubt could have done better. (Quibbling about historical eras proves nothing; time axes are arbitrary.) We therefore assume that some number, k, of mathematicians may change a lightbulb. If k mathematicians can change a lightbulb, can k+1? Naturally - there is nothing preventing the k+1th mathematician from merely observing, and so by induction, any positive integer number n of mathematicians may change a lightbulb. There only remains the problem of boundary conditions: we may not allow a countably infinite number of mathematicians, because they would, even in their natural emaciated state, require an infinite amount of mass, something impermissible in an assumed finite universe.\n\n\u2234 Any finite positive integer n of mathematicians may change a light bulb.\n\nPedantic corrections welcome, threats of violence because of mental pain not welcome, but not unusual either. This was written because the punchline needed a joke, and it got an arrogant attempt at a pastiche of proof instead."}
{"text": "Retrieved from http://mathoverflow.net/questions/75131/how-to-detect-frequency\nText:\nTake the 2-minute tour \u00d7\n\nLet $J$ be an arc in $\\mathbb{S}^{1}\\subset\\mathbb{C}$ (no matter open or closed) and $\\alpha\\in(0,2\\pi)$ be an angle such that $\\alpha/\\pi$ is irrational. Consider in $\\mathbb{S}^{1}$ the sequence $z_{n}=e^{in\\alpha}$. Then this sequence is dense in $\\mathbb{S}^{1}$ by Kronecker's Theorem or by ergodicity. Let's associate with the arc $J$ its \"indicator sequence\" $s(J)={s_{n}\\}$ of zeroes and ones defined as follows:\n\n$s_{n}=1$ if $z_{n}\\in J$ and $s_{n}=0$ if $z_{n}\\notin J$.\n\nSo, we get something like 0 0 1 1 1 0 0 0 1 1 0 0 1. . . Suppose that we are given such a sequence $s(J)$ for some $J$ and some $\\alpha$. By the Ergodic Theorem one gets the measure of arc $J$ as the limit\n\n$\\mathtt{meas}(J)=2\\pi\\underset{n\\rightarrow\\infty}{\\lim}\\frac{\\sigma_{n}}{n}$ where $\\sigma_{n}$ is the number of 1's in ${s_{1},s_{2},...,s_{n}}$.\n\nOK, but is it possible to detect the \"frequency\" $\\alpha$ only by the 0-1 data contained in the sequence $s_{n}$? More precisely, my question is:\n\nLet $\\{s_{n}\\}$ be a sequence of 0's and 1's and we know that it is an \"indicator sequence\" for some arc $J\\subset\\mathbb{S}^{1}$ and some angle $\\alpha$. Is it then possible to get $\\alpha$ by some formula similar to the above one for the measure of $J$? This would be something like a \"rotation number\" of sequence $\\{s_{n}\\}$.\n\nSimilar question may be posed for the torus $\\mathbb{T}^{n\\text{ }}$and an open set $J\\subset\\mathbb{T}^{n\\text{ }}$. Then we should detect not only the frequencies $\\alpha_{1},\\alpha_{2},...$ but also the \"dimension\" $n$ of the sequence. Here $\\alpha_{1},...,\\alpha_{n},\\pi$ have to be independent over $\\mathbb{Z}$.\n\n[I know that the \"indicator sequence\" is a standard construction in symbolic dynamics, but I am not very involved in the topic, so references are welcome.]\n\nP.S. Curly brackets {} are not displayed in math mode. How to fix the problem?\n\nshare|improve this question\nCurly brackets can be obtained via \\lbrace and \\rbrace. \u2013\u00a0 Andrew Sep 11 '11 at 10:20\n@Andrew @Symbo'leon Or via \\{ and \\}. \u2013\u00a0 Quinn Culver Sep 11 '11 at 15:27\n$S((0,\\alpha))$ forms what is called a Sturmian sequence, a special case of a subshift of finite type. If $J$ is a general interval, than one gets a more general subshift. I still believe, one always has uniqueness. \u2013\u00a0 Helge Sep 11 '11 at 17:23\n@Helge: Sturmian sequences - or, strictly speaking, their orbit closures - are subshifts of infinite type. Subshifts of finite type are those subshifts which can be obtained from the full shift by \"forbidding\" finitely many words, and have special properties not enjoyed by Sturmian shifts. (These days it is usually assumed that the forbidden words are all of length two, which can be achieved by re-coding the alphabet.) \u2013\u00a0 Ian Morris Sep 11 '11 at 21:00\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nIt seems likely to me that $\\alpha$ can be computed by calculating the frequencies of subwords of the coding sequence, but in a manner which depends on certain parameters. For example, if $\\alpha<\\min\\{|J|,2\\pi-|J|\\}$ then the interval $J \\setminus J +\\alpha$ has length precisely $\\alpha$, and it follows easily that $\\alpha$ equals the frequency of the subword 01. On the other hand if $|J|$ is very small and $\\alpha, 2\\pi-\\alpha$ are both larger than $|J|$, then the frequency of the subwords 01 and 10 are both $|J|$, while the subword 00 has frequency $1-2|J|$, and we cannot gain anything by considering words of length 1 or 2. So the frequencies of words of arbitrary length probably need to be considered.\n\nThe articles \"Coding rotations on intervals\" by Berstel and Vuillon, and \"Three-distance theorems and combinatorics on words\" by Alessandri and Berth\u00e9 appear to be relevant (especially Lemma 1 in the latter) but do not seem to yield a complete answer.\n\nshare|improve this answer\nadd comment\n\nUnless I am missing something you can just compute $\\lim_{N\\rightarrow \\infty} \\frac{1}{N}\\sum a_k \\exp(2 \\pi i k s)$ to find the Fourier transform of the characteristic function of the interval J, and then do an inverse transform to find J. This is more-or-less what you suggest about computing a rotation number.\n\nshare|improve this answer\nWhat I said above was not quite what you asked - let me try again. The above should give you the Fourier transform with argument $\\frac{s}{\\alpha}$. From this and knowledge of the Fourier transform of an interval you can recover $\\alpha$. \u2013\u00a0 Jared Bronski Sep 11 '11 at 23:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/543131/probability-of-a-result-from-3d6-lowest-to-highest\nText:\nTake the 2-minute tour \u00d7\n\nI have a fascination with tabletop sports games, and through that, I've developed an interest in probability. That said, it's not my strong suit, so I wanted to pose this question because I think involves a few different probability principles to solve it.\n\nHere's the premise...the game uses a roll of 3d6 to determine the result of a play. The dice are read from lowest to highest, as in:\n\na roll of 3, 6, 2 would be 2-3-6 a roll of 1, 4, 1 would be 1-1-4 etc.\n\nThat roll is then looked up on a chart to determine the result.\n\nI was curious about the probability of different results coming up so that if I wanted to make a house rule, I would know which result would be the best place to modify.\n\nSo, what I do know is that for probability, you multiply chances together, correct? So without the low to high rule I discussed above, any number would have a 1/6 * 1/6 * 1/6 chance of occurring, correct?\n\nHow would I apply this principle to any result? My guess is something like:\n\n1-1-4 = 1/6 * 1/6 * 5/6\n\nonly one chance for the first 2 die, and the last can be anything but 1, so 5 remaining numbers\n\n2-3-6 = 1/6 * 4/6 * 4/6\n\nfirst number can be 2 only = 1/6\n\nsecond number can be any number but 2 or 6 = 4/6\n\nsecond number can be any number but 2 or 3 = 4/6\n\nAm I understanding this correctly?\n\nshare|improve this question\nThis is the kind of thing that's really easy to get the computer to do. Complete results are here. \u2013\u00a0 MJD Oct 28 '13 at 18:32\nWouldn't $3,6,2$ be $2-3-6?$ \u2013\u00a0 Ross Millikan Oct 28 '13 at 18:37\nRoss, you're correct, I swear I had that typed correctly when I first posted it incorrectly on the main stack overflow page. I'll fix it... \u2013\u00a0 tjans Oct 29 '13 at 12:53\nadd comment\n\n1 Answer\n\nYour answer's not correct. For 1-1-4, you have multiplied by $\\frac56$, but it's not clear to me why. The correct calculation goes like this: there is a $\\frac16$ probability of getting a 1 on the first die, a $\\frac16$ probability of getting a 1 on the second die, and a $\\frac16$ (not $\\frac56$) probability of getting a 4 on the third die. This multiplies out to $\\frac1{216}$. But there are three different orders in which the rolls could occur to give a result of 1-1-4, since 1-4-1 or 4-1-1 give the same result. So you must multiply the $\\frac1{216}$ by 3, for a final result of $\\frac1{72}$.\n\nSimilarly, the result for 2-3-6 is again $\\frac1{216}$, but this time multiplied by 6 because there are 6 different orders in which the 2, 6, and 3 can appear; the final result is $6\\cdot\\frac1{216}=\\frac1{36}$.\n\nIn general, the answer is as follows: if the pattern you're looking up is XXX, with all three dice the same, the probability is $\\frac1{216}$. If the pattern is XXY or XYY, the probability is $\\frac1{72}$. And if the pattern is XYZ, the probability is $\\frac1{36}$.\n\nshare|improve this answer\nThe 5/6 was me overthinking things. I'll save me the embarrassment by not explaining why I thought it'd be 5/6 :) \u2013\u00a0 tjans Oct 29 '13 at 12:56\nfor 1-1-4, how are there 3 possibilities? Wouldn't there be 6 different ways for that as well, as each die is independent of the other? 1a-1b-4, 1a-4-1b, 1b-1a-4, 1b-4-1a, 4-1a-1b, 4-1b-1a \u2013\u00a0 tjans Oct 29 '13 at 13:03\nSuppose the three dice were red, blue, and green. The 4 can be on the red die, the blue die, or the green die; that's 3 ways. Saying that a green 4, a red 1 and a blue 1 is somehow different from a green 4, a blue 1 and a red 1 makes no sense at all. \u2013\u00a0 MJD Oct 29 '13 at 14:35\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59009/no-complexity-class-contains-all-recursive-languages\nText:\nTake the 2-minute tour \u00d7\n\nI want to prove that there does not exist some complexity class that contains all recursive languages.\n\nAny complexity class C is defined by a complexity measure $\\Phi$ (according to Blum axioms) and a total recursive function f:N $\\rightarrow$ N. So there does not exists C that contains all languages L for which there exists a Turing Machine M that decides L and for all x $\\Phi$(M,x)<=f(|x|).\n\nAny ideas?\n\nshare|improve this question\nI don't get it; doesn't the class R contains all the recursive languages? en.wikipedia.org/wiki/R_(complexity) \u2013\u00a0 Hsien-Chih Chang \u5f35\u986f\u4e4b Mar 21 '11 at 10:06\nThe author means a complexity class in the sense of Blum - en.wikipedia.org/wiki/Blum_axioms \u2013\u00a0 Fran\u00e7ois G. Dorais Mar 21 '11 at 10:38\nThank you Fran\u00e7ois! \u2013\u00a0 Hsien-Chih Chang \u5f35\u986f\u4e4b Mar 21 '11 at 11:02\nHave you looked at en.wikipedia.org/wiki/Blum%27s_speedup_theorem ? \u2013\u00a0 Andr\u00e1s Salamon Mar 21 '11 at 22:49\nThanks for your answer Andr\u00e1s but I really can't see how the speed up theorem implies that C can't exist. \u2013\u00a0 user13788 Mar 22 '11 at 15:34\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nLet $\\langle M_i\\rangle$ be an enumeration of all Turing Machines (TM) and $\\langle f_i\\rangle$ the corresponding ($f_i=f_{M_i}$) enumeration of the functions in $RE$. Suppose there is an $f\\in REC$ such that all the recursive languages are in the complexity class $\\mathcal{C}(f)=${$f_i\\in RE:\\forall x\\ \\Phi(i,x)\\leq f(x)$}.\n\nHere are two ways you can prove this is not possible:\n\n1) $\\Phi(i,x)=y$ is $REC$, thus let $N$ be the TM which computes it. We can use $N$ to construct a new TM $N'$ which takes as input $i$, then calculates $\\Phi(i,x)=y$ for every $x$ and all $y\\leq f(x)$ and it halts iff for some $x$, $\\Phi(i,x)=y$ is false for all $y\\leq f(x)$ or $rng(f_i(x))\\nsubseteq${$0,1$}.\n\nHaving a closer look on $N'$, we see that it recognizes exactly the language\n\n$TOT'=${$i\\in\\mathbb{N}:f_i\\mbox{ not total}\\vee f\\mbox{ is not a relation}$}.\n\nThus $TOT'\\in RE$ which can not be true because it is $\\Sigma_2$-complete. ($\\Sigma_2$ contains the relations which are $RE$ given a $co-RE$ oracle).\n\n2) We use the Recursive Relatedness Theorem, i.e.\n\nSuppose $\\Phi,\\Psi$ be complexity measures. Then there exists an $r(x,y)\\in REC$ s.t.:\n\n(i) $\\forall x,y\\ r(x,y)< r(x,y+1)$;\n\n(ii) $\\forall i\\ \\forall^* x\\ \\Phi(i,x)\\leq r(x,\\Psi(i,x))$; ($\\forall^*$ means for all but finitely many)\n\n(iii) $\\forall i\\ \\forall^* x\\ \\Psi(i,x)\\leq r(x,\\Phi(i,x))$.\n\n(This says roughly that the one measure is bounded by the other using a REC function.)\n\nLet $\\Phi$ be the measure under consideration and $T$ the usual masure of time complexity. By (iii), $T(i,x)\\leq r(x,\\Phi(i,x))$ and since $r$ is increasing for $y$ and $\\Phi(i,x)\\leq f(x)$, we get that $T(i,x)\\leq r(x,f(x))$ for all $i$ s.t. $f_i\\in \\mathcal{C}(f)$.\n\n$r(x,f(x))$ is recursive hence we can get a TM $M_{i_0}$ which given an input $x$ moves $r(x,f(x))+1$ times and halts with output $0$. $f_{i_0}$ realizes a recursive language so it is in $\\mathcal{C}(f)$, which means that $\\forall^* x\\ r(x,f(x))+1=T(i_0,x)\\leq r(x,f(x))$. But this is a contradiction.\n\nIf you want to see the proof that $TOT'$ is $\\Sigma_2$-complete (actually that $TOT=\\mathbb{N}\\setminus TOT'$ is $\\Pi_2$-complete. $TOT$ contains functions instead of relations but you can easily reduce the one to the other) you can check it in p.224 of Computability, complexity and languages of Martin Davis.\n\nInside the same book, you can find the proof of the recursive relatedness theorem in p.422. Actually the whole chapter (14) contains some useful results on abstract complexity.\n\nshare|improve this answer\nThank you Marios! \u2013\u00a0 user13788 Apr 1 '11 at 0:14\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/165625/restoring-a-point-after-transformation\nText:\nTake the 2-minute tour \u00d7\n\nI am given a point $ \\begin{bmatrix} u & v \\end{bmatrix}^T $ which I know is in form $\\begin{bmatrix} \\frac{x}{f(r)} & \\frac{y}{f(r)} \\end{bmatrix}^T$ where $f(r)$ is polynomial function, $f(r)=a_nr^n + \\cdots + a_1r + a_0$ and $r=\\sqrt{x^2+y^2}$.\n\nI want to restore $x$ and $y$ given $u$ and $v$. What I have done so far is below.\n\n$$ u = \\frac{x}{f(r)}\\\\ v = \\frac{y}{f(r)}\\\\ $$\n\nIf we square both equations and sum them we get:\n\n$$ \\tag{1} f(r) = \\frac1{\\sqrt{u^2+v^2}}r $$\n\nWhich is:\n\n$$ a_nr^n + \\cdots + \\left(a_1 - \\frac1{\\sqrt{u^2+v^2}}\\right) r + a_0 = 0 $$\n\nI can find the roots of a polynomial using roots() in MATLAB. Then using Equation 1 I can find the value of $f$ and then $u$ and $v$.\n\nWhen I try this with a numerical example with known polynomial coefficients I cannot restore $x$ and $y$ given $u$ and $v$, the results I am getting do not match. Am I missing something here?\n\nI can provide the coefficients and the numbers I am using if needed.\n\nUpdate: Here are my values which are not working. First polynomial coefficients $a_0, a_1, a_2$ are $-174.4486, 0, 0.0026$ respectively. Lets start with an original point $p = \\begin{bmatrix} \\frac{50}{-161.4486} & \\frac{50}{-161.4486}\\end{bmatrix}^T$. Observe that $p$ is in form described above where $f(r) = -161.4486$, you can calculate if you don't believe me :). Now my given point becomes $\\begin{bmatrix}-0.3097 & -0.3097\\end{bmatrix}^T$, using only this I want to find $x=50$ and $y=50$. Lets start. We calculate:\n\n$$\\frac1{\\sqrt{u^2+v^2}} = 2.2832$$\n\nWe put it into the polynomial and find the roots which are $r_1= 948.875$ and $r_2=-70.7107$. Since we know $r$ is non negative we choose $r_1$, plug it into the Equation 1 and we get $f(r)=2166.5$ put it into the equations we get $-671$ for $x$ and $y$. Before calculating those values we can understand something is wrong just looking at $r$, it is not the correct value which is $70.7107$.\n\nshare|improve this question\nAs Christian Blatter's answer shows, this procedure ought to work to get you the right solution. I think you should go ahead and provide the numbers you're working with; maybe then we can pinpoint the error. \u2013\u00a0 Rahul Jul 2 '12 at 21:24\n@RahulNarain I provided the actual values. \u2013\u00a0 nimcap Jul 3 '12 at 15:23\n@nimcap: The mistake is in your equation $(1)$. The correct version is equation $(4)$ in my edited answer. \u2013\u00a0 Christian Blatter Jul 3 '12 at 18:06\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\n\nThe values of $u$ and $v$, and therefore $u^2+v^2$, are given to you, and you want to find $x$, $y$ such that $$(u,v)=\\Bigl({x\\over f(r)}, {y\\over f(r)}\\Bigr)\\ ,\\qquad r:=\\sqrt{x^2+y^2}\\ .\\qquad(2)$$\n\nIt follows that we necessarily have $$x=f(r)u\\ , \\quad y=f(r)v\\qquad(3)$$ and therefore $$r^2=(u^2+v^2)f^2(r)\\ .\\qquad(4)$$\n\nThis equation only involves given data and the unknown $r$. Solving it produces a list of values $r_k>0$ (and maybe some other solutions), and to each of these $r_k$ by $(3)$ correspond values $$x_k= u f(r_k)\\ ,\\quad y_k=v f(r_k)\\ .\\qquad(5)$$ Now $(5)$ is just a necessary condition that solutions of the original equation $(2)$ would have to fulfill, and we have to prove that such pairs $(x_k,y_k)$ are in fact solutions of $(2)$, i.e., satisfy $$(u,v)=\\Bigl({x_k\\over f\\bigl(\\sqrt{x_k^2+y_k^2}\\bigr)},{y_k\\over f\\bigl(\\sqrt{x_k^2+y_k^2}\\bigr)}\\Bigr)\\ .$$ To this end we argue as follows: If $x_k$ and $y_k$ are given by $(5)$, where $r_k>0$ is a solution of $(4)$, then $$x_k^2+y_k^2=(u^2+v^2)f^2(r_k)=r_k^2\\ .$$ As $r_k>0$ it follows that $\\sqrt{x_k^2+y_k^2}=r_k$ and therefore $${x_k\\over f\\bigl(\\sqrt{x_k^2+y_k^2}\\bigr)}={x_k\\over f(r_k)}=u\\ ,$$ and similarly for $y$ resp. $v$.\n\nshare|improve this answer\nI believe that my problem has something to do with squaring and square rooting. I lose or introduce solutions that are not true by doing that, but I can't explain. \u2013\u00a0 nimcap Jul 2 '12 at 19:05\nthank you, it seems I had problem with extraneous solutions, which I forgot about the whole thing by not practicing algebra regularly. \u2013\u00a0 nimcap Jul 3 '12 at 20:28\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/82866/hodge-star-on-the-product-of-two-pseudo-riemannian-manifolds\nText:\nTake the 2-minute tour \u00d7\n\nLet S and N be two pseudo-Riemannian manifolds. Is it true that $$\\star_{S\\times N}(\\theta\\wedge\\omega)=\\star_{S}\\theta\\wedge\\star_{N}\\omega,$$ where $\\theta$ is a form on S and $\\omega$ is a form on N?\n\nshare|improve this question\nIn the Riemannian case, $*$ can be defined by $\\alpha\\wedge *\\alpha=volume$. So then your formula seems right, at least up to sign. \u2013\u00a0 Donu Arapura Dec 7 '11 at 13:46\nI guess first of all that your manifolds are oriented, right? Then, how do you define the Hodge * operator in the pseudo-riemannian case? Is it still an isometry? \u2013\u00a0 diverietti Dec 7 '11 at 15:57\nAs Donu says, the formula is correct up to signs. More precisely if $\\theta \\in \\Omega^p(S)$ and $\\omega \\in \\Omega^q(N)$ with $\\dim S = m$ and $\\dim N = n$, then $$ \\star_{S \\times N} (\\theta \\wedge \\omega) = (-1)^{q(m-p)} \\star_S \\theta \\wedge \\star_N \\omega $$ \u2013\u00a0 Jos\u00e9 Figueroa-O'Farrill Dec 8 '11 at 1:58\nThank you very much! But I obtain the following $$\\star_{S\\times N}(\\theta\\wedge\\omega)=\\frac{p!q!}{(p+q)!}(-1)^{q(m-p)}\\star_{S}\\theta\\wedge\\sta\u200c\u200br_{N}\\omega.$$ \u2013\u00a0 Natalia Dec 8 '11 at 13:17\nHere I suppose that $\\theta\\wedge\\omega=Alt(\\theta\\otimes\\omega),$ $Alt T=\\frac{1}{p!}\\Sigma_{\\sigma\\in S_{p}}(sgn \\sigma) T^{\\sigma},$ $$\\langle u_{1}\\otimes... \\otimes u_{p},\\tilde{u}_{1}\\otimes... \\otimes \\tilde{u}_{p}\\rangle=\\langle u_{1},\\tilde{u}_{1}\\rangle...\\langle u_{p},\\tilde{u}_{p}\\rangle,$$ where $u_{1},...u_{p},\\tilde{u}_{1},...,\\tilde{u}_{p}$ are 1-forms. Then I get $$\\langle\\theta_{1}\\wedge\\omega_{1},\\theta_{2}\\wedge\\omega_{2}\\rangle=\\frac{p!q!\u200c\u200b}{(p+q)!}\\langle\\theta_{1},\\theta_{2}\\rangle\\langle\\omega_{1},\\omega_{2}\\rangle$$ therefore the coefficient appear. Is it true? \u2013\u00a0 Natalia Dec 8 '11 at 13:20\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/85008/changing-divergent-series-to-convergent-by-re-ordering-denominators\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $a_n$ is strictly decreasing and positive and $\\sum_{n>1}a_n/n=\\infty$, let $g:\\mathbb N\\to\\mathbb N$ be a bijection between the positive integers, can we have $\\sum_{n>1}a_n/g(n)<\\infty$?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nIf $a_n$ goes to zero, choose a subsequence whose $n$th term is smaller than $1/n$.\n\nNow, for any index that is not a power of two, pair up $1/n$ with the term of the subsequence that is smaller than $1/n$.\n\nThe sum of these terms is smaller than $\\sum \\frac 1 {n^2}=\\pi^2/6$.\n\nPair up the remaining $a_n$ with the remaining $1/2^k$. This gives a series that is smaller than $\\sum a_1 \\frac 1 {2^n}=a_1$. (The $a_n$ are decreasing and bounded by $a_1$.)\n\nSince everything is positive, this implies that the series converges.\n\nshare|improve this answer\nThe idea is to form one subsequence that uses \"few\" $a_n$ and \"many\" $1/n$ so that $a_n$ is small and makes the product small, and another subsequence that uses \"many\" $a_n$ and \"few\" $1/n$ so that $1/n$ is small and makes the product small. This is the same idea as in David's answer, of course. \u2013\u00a0 Phira Nov 23 '11 at 19:10\n\nWe may assume, $a_n\\searrow 0$ (otherwise, you can't do it).\n\nChoose a subsequence $\\{a_{n_k}\\}$ with $a_{n_k}\\le {1\\over 2^k}$.\n\nWe write our new sequence: $a_1/2, a_2/4, \\ldots, a_{n_1-1}/2^{n_1-1}$\n\nThe next term is $a_{n_1}/1$.\n\nFor terms after $a_{n_1}$ and before $a_{n_2}$ we continue dividing by powers of 2.\n\nThe next term is $a_{n_2}/ 3$.\n\nIn general:\n\nTerms $a_i$ that are not a term of the subsequence are divided by $2^i$. The series formed by these terms will converge since the $a_i$ are decreasing and $\\sum{1\\over 2^n}$ converges\n\nA term $a_{n_k}$ is divided by the first integer that hasn't been used to that point. The series form by these terms clearly converges, since $a_{n_k}\\le 2^{-k}$ and we made the terms smaller.\n\nThus, the resulting series of nonnegative terms converges.\n\nI think this works. I'd try to formalize it; but I'm sure I would just make a mess of things...\n\nshare|improve this answer\nhum, but isn't the whole problem that the terms that are not terms of the subsequence may be very, very numerous ? it doesn't matter that you divide them by powers of 2 (say less than 2^n_k) if there are way more than 2^n_k of them... For this reason I actually think it is false (but definitely not trivial !) \u2013\u00a0 Glougloubarbaki Nov 23 '11 at 19:09\nThose terms are bounded, and the series formed by those terms would converge since $\\sum 2^{-n}$ converges. \u2013\u00a0 David Mitra Nov 23 '11 at 19:14\nit's hard to say it precisely, but if you take $a_n = 1/(\\ln(1+ \\ln(1+ \\ln(1+ n))))$ the number of terms before $a_n < 1/4$ is monstruous, and you'll end up with a sum of an enourmous number of terms of the size $1/4 /(\\ln(1+ \\ln(1+ \\ln(1+ n))))$ which is not so small, and so on at every stage, so that the sum will not converge. \u2013\u00a0 Glougloubarbaki Nov 23 '11 at 19:15\nI am also led to a similar conclusion. If it needs to formalize, one may do like this: Suppose $a_n \\downarrow 0$. Let $(x_{n})$ be an increasing sequence so that both $a_{x(k)} \\leq 2^{-k}$ and $x(k) \\geq 2^{k}$. Also let $(y_{n})$ be the enumeration of the set $\\mathbb{N} - \\{ x_n : n \\in \\mathbb{N} \\}$ in increasing order. Then define $$g(n) = \\begin{cases} x(k) & \\text{if} \\ n = y(k) \\\\ y(k) & \\text{if} \\ n = x(k) \\end{cases}.$$ Then $$\\sum_{n \\geq 1} \\frac{a_n}{g(n)} = \\sum_{k \\geq 1} \\frac{a_{x(k)}}{y(k)} + \\sum_{k \\geq 1} \\frac{a_{y(k)}}{x(k)},$$ which clearly converges. \u2013\u00a0 sos440 Nov 23 '11 at 19:18\nok, you're right \u2013\u00a0 Glougloubarbaki Nov 23 '11 at 19:25\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/56874/equation-for-the-family-of-lines-that-passes-through-3y-5x-10-0-and-3y-frac/56938\nText:\nTake the 2-minute tour \u00d7\n\nFind an equation for the family of lines that passes through the intersection of $3y-5x-10=0$ and $3y-\\frac{x}{3}-\\frac{5}{3}=0$\n\nshare|improve this question\n\n3 Answers 3\n\nI think it's $$\\displaystyle k \\left(3y-5x-10 \\right)+m \\left(3y-\\frac{x}{3}-\\frac{5}{3} \\right)=0$$ where $k$ and $m$ are not all zero.\n\nshare|improve this answer\n\nLet us denote by $L = L(a, b, c)$ the line $ax + by + c = 0$. $(a, b, c)$ can be considered a 3-dimensional vector $v$ and all lines can be represented by the 3-dimensinal vector space $R^3$. The bundle of lines $L(a, b, c)$ passing through the intersection $(i, j)$ of the given lines $L_1 = L(a_1, b_1, c_1)$ and $L_2 = L(a_2, b_2, c_2)$ satisfy\n\n$$a i + b j + c = 0$$\n\nSo, the vectors $v$ corresponding to this bundle lie in a 2-dimensional subspace $R^2$. $v_1 = (a_1, b_1, c_1)$ and $v_2 = (a_2, b_2, c_2)$ are also in this subspace because they satisfy the above restriction. Moreover, they are linearly independent (because the 2 lines cross) and hence they span this subspace. Therefore $v$ must be a linear combination of $v_1$ and $v_2$: $$v = \\lambda_1 v_1 + \\lambda_2 v_2$$. So, the bundle lines are given by $$L(\\lambda_1 a_1 + \\lambda_2 a_1, \\lambda_1 b_1 + \\lambda_2 a_2, \\lambda_1 c_1 + \\lambda_2 c_2)$$ $$ = \\lambda_1 L_1 + \\lambda_2 L_2$$ because $L$ is a linear form. The line equation of these lines is $$\\lambda_1 L_1 + \\lambda_2 L_2 = 0$$ (as used without proof in another answer). Now, we should divide by $\\lambda_1$ to get the family of bundle lines parametrized by one parameter $\\lambda$: $$L_1 + \\lambda L_2 = 0$$\n\nshare|improve this answer\n\nFind the intersection of $3x - 5y - 10 = 3x - \\frac{x}{3} - \\frac{5}{3}$, it should be a point in the plane $(a,b)$, then shift the origin to $(a,b)$.\n\nFor example, $x=y$ becomes $(x-a)=(y-b)$, to make it have an arbitrary slope $m$, just scale the left hand side of the equation to get $(x-a)m=(y-b)$, so the family of all lines that go through the point $(a,b)$ (except the vertical one) is given by $\\{(x,y) \\text{ } | \\text{ } (x-a)m=(y-b), m\\in\\mathbb{R} \\}$.\n\nIn your example, $(a,b) = \\left(\\frac{5}{14},-\\frac{25}{14}\\right)$, here are some of the lines in that family, sampled by selecting $m$ values from $[-5,5]$.\n\nLines passing through the point $\\left(\\frac{5}{14},-\\frac{25}{14}\\right)$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/23053/constructing-the-most-general-two-particle-spin-interaction-with-su2-symme\nText:\nTake the tour \u00d7\n\nSuppose I want to write down an interaction term for an action for spin 1/2 fermions that is $SU(2)$-symmetric.\n\nI start from the most naive general form of such an action: $$S_{int} ~=~ \\int_{4321} \\sum_{\\alpha \\beta \\gamma \\delta} \\bar \\psi(4)_\\alpha \\bar \\psi(3)_\\beta \\psi(2)_\\gamma \\psi(1)_\\delta V(4,3,2,1)_{\\alpha \\beta \\gamma \\delta}$$\n\nwhere the indices $1$ to $4$ stand for momenta and frequencies of my fermions.\n\nNow I want to find the form $V$ must have in order to be $SU(2)$ symmetric. By transforming the fermion fields and demanding that the action must stay invariant under that, I can show that $V$ must transform as $$V_{\\alpha' \\beta' \\gamma' \\delta'} ~=~ \\sum_{\\alpha\\beta\\gamma\\delta} R^\\dagger_{\\alpha \\alpha'} R^\\dagger_{\\beta \\beta'} R_{\\gamma \\gamma'} R_{\\delta \\delta} V_{\\alpha \\beta \\gamma \\delta}$$ where $R \\in SU(2)$.\n\nWell, and now I'm stuck continuing from here. Using some handwaving I think I could argue that $V$ must preserve total spin and also total spin in $z$-direction I could probably argue that $V$ can only scatter triplets to triplets, singlets to singlets, and also can't change the $z$-component of the triplet, but I would rather use a more rigorous approach.\n\nWhich will probably involve irreducible representations? I could probably get to the singlet/triplet statement above by noting that $SU(2)$ will transform multiplets into the same multiplet, so the singlet would be invariant under $SU(2)$ and the triplets would somehow mix. But why is it appropriate then to look at an \"ingoing\" singlet or \"ingoing\" triplet formed by indices $\\gamma$ and $\\delta$ as opposed to forming such states with, e.g., indices $\\alpha$ and $\\gamma$?\n\nADDENDUM: Well, I guess I can also start with the spins in a different basis: Assuming that I can put the two \"ingoing\" and the two \"outgoing\" spins into either a singlet or one of three triplets, I guess I can write the action as $$S \\sim \\int_{1234} \\sum_{jm j'm'} (\\bar \\psi(4) \\bar \\psi(3))_{jm} (\\psi(2) \\psi(1))_{j'm'} V(4,3,2,1)_{jm;j'm'}$$ Then I can first argue that due to conservation of total spin we require $j = j'$. And then for $V$ I can look at singlet-singlet scattering and triplet-triplet scattering separately: For $j = j' = 0$, $m$ must be $0$ and so $V$ is a scalar, invariant under $SU(2)$, But for $j = j' = 1$, the states with $m = 0, \\pm 1$ transform into each other in some way, and thus I must work a bit harder to get the symmetry right. I'll think about this, but in the meantime I'm open for more suggestions.\n\nshare|improve this question\nIs your action going to be renormalizable? In how many dimensions? It's worth noting that in 3+1D renormalizability limits you to no more than two fermion fields in a single term (because each has dimension 3/2, and you need to have dimension 4 total). \u2013\u00a0 David Z Mar 30 '12 at 21:31\nIt's for a condensed matter system so I don't worry about renormalizability; I'll always assume that there is a \"natural\" cut-off \u2013\u00a0 Lagerbaer Mar 30 '12 at 22:10\nOh, OK. Ignore me then :-) \u2013\u00a0 David Z Mar 30 '12 at 23:21\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThis is very much a quick and dirty answer, I havn't though too much about it. I might update my answer if I find time in the weekend, otherwise I hope others will give more precise answers.\n\n$V_{\\alpha\\beta\\gamma\\delta}$ transforms reducibly under $SU(2)$, as tensor products of four spin $\\frac 12$ representations. Using $\\bf\\frac 12\\otimes\\frac 12 = 0 \\oplus 1$ and $\\bf 1\\otimes 1 = 0 \\oplus 1 \\oplus 2$, we find that $V_{\\alpha\\beta\\gamma\\delta}$ decomposes into these irreducible representations $$\\mathbf{\\frac 12\\otimes\\frac 12\\otimes\\frac 12\\otimes\\frac 12} = (2\\times\\mathbf{0})\\oplus (3\\times \\mathbf{1}) \\oplus \\mathbf{2},$$ two singlets, three triplets and a spin 2 (5-dimensional representation). There is an action of the permutation group $S_4$ on the indices of $V_{\\alpha\\beta\\gamma\\delta}$, for $SU(N)$ it turns out that decomposing this tensor into irreducible representations of the permutation group also corresponds to irreducible representations of $SU(N)$. This can be done rather quickly using Young Tableau, you can find the details in most representation theory books for physicists (I don't have a relevant book here and don't remember the details. I might add the answer in the weekend). In the case of a tensor product $\\bf 1\\otimes 1 = 0\\oplus 1\\oplus 2$, we get the following decomposition\n\n$$ T_{ij} = \\delta_{ij}\\frac{tr(T)}3 + \\left(\\frac{T_{ij}-T_{ji}}2\\right) + \\left(\\frac{T_{ij}+T_{ji}}2 - \\delta_{ij}\\frac{tr(T)}3\\right).$$ These three terms transform irreducibly as spin $0$, spin $1$ and spin $2$ representations of $SU(2)$, respectively. In terms for the permutation group, these are the trivial, anti-symmetric and trace less symmetric representations, respectively.\n\nSomething similar can be done for $V_{\\alpha\\beta\\gamma\\delta}$, by using Young Tableau or just by playing around with it.\n\nshare|improve this answer\nHm, when you decompose $V$ into irreducible representations you combine all four spins into total spins of $0$, $1$ or $2$. But should I, given that two of the spins transform in one direction and the other two into the \"opposite\" direction, keep the spins whose operators have a \"bar\" on top separate from those without the bar, i.e. $(0 \\oplus 1) \\otimes (0 \\oplus 1)$? \u2013\u00a0 Lagerbaer Mar 30 '12 at 22:48\nMh, I think I'm just a bit confused. Maybe for clarification: When my general operator $V_{\\alpha\\beta\\gamma\\delta}$ is decomposed as you describe, are then the two singlets the only parts that are invariant under rotation as they transform like scalars? Or am I getting things completely wrong? \u2013\u00a0 Lagerbaer Mar 31 '12 at 5:01\nYou were right; the fact that I get two terms in the action that transform like singlets is related to the irreducible representations: One singlet is obtained by combining two singlets, the other is obtained by combining two triplets. \u2013\u00a0 Lagerbaer Apr 4 '12 at 18:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/43484/an-analytic-proof-of-the-de-franchis-theorem/43496\nText:\nTake the tour \u00d7\n\nThe De Franchis theorem in its simplest form states that given two compact Riemann surfaces $\\Sigma_{g_1},\\Sigma_{g_2}$ where $g_1,g_2 > 1$, there are only finitely many non-constant holomorphic mappings from $\\Sigma_{g_1}$ into $\\Sigma_{g_2}$.\n\nThe complete proof can be found in P.Samuel's book Lectures on Old and New Results on Algebraic Curves. This proof uses quite a bit of Algebraic Geometry, in which I have very little background. Does anyone know how to prove this result using purely complex analytic ideas?\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nLet me give a proof using the deformation theory of holomorphic maps developed by Horikawa [Journal Math. Soc. Japan 25]. This can be seen as a purely analytic proof in the spirit of Kodaira's \"deformations of complex structures\".\n\nSet $X:=\\Sigma_{g_1}$ and $Y:=\\Sigma_{g_2}$, and fix a non constant holomorphic mapping $f \\colon X \\to Y$.\n\nLet us denote by $\\textrm{Mor}(X, Y)$ the space of holomorphic maps from $X$ to $Y$. It is an analytic space, whose tangent space at the point $[f]$ coincides with the space of first-order deformations of $f$, namely $H^0(X, f^*T_Y)$.\n\nSince $Y$ is of genus $g \\geq 2$, we have $\\deg T_Y <0$, so $H^0(X, f^*T_Y)=0$.\n\nThis means that the morphism $f$ is rigid, in other words there are only finitely many first-order deformations of $f$ up to composition with automorphisms of $X$.\n\nBut it is well known that $|\\textrm{Aut}(X)| \\leq 84(g(X)-1)$, so there are only finitely many first - order deformations of $f$ at all.\n\nThis shows that every component of the space $\\textrm{Mor}(X, Y)$ is a point. In general, it can happen that $\\textrm{Mor}(X,Y)$ has countably many components; in this case, however, it has only finitely many of them, since the possible degrees of $f$ are bounded from above by the Riemann-Hurwitz formula. This implies that there are finitely many choices for $f$.\n\nIf you do not like deformation theory, there exists actually a purely analytic (and completely different) proof of a definitely strong result, the so called Kobayashi - Ochiai Theorem:\n\nTheorem. Let $X$ be a Moishezon space and $Y$ a compact complex spece of general type. Then the set of meromorphic maps from $X$ to $Y$ is finite.\n\nFrom the proof, that is a combination of techniques and uses in an essential way the Schwarz lemma, I refer you to the original Kobayashi-Ochiai paper [Meromorphic mappings onto compact complex spaces of general type, Inventiones Math. 31 (1975)]\n\nshare|improve this answer\n\" But Mor(X,Y) is a quasi-projective variety, so it has only finitely many components\": an analytic argument is given in my post below. \u2013\u00a0 Johannes Ebert Oct 25 '10 at 9:00\nRight. Actually I wrote this better; the fact that there are finitely many components follows easily since \\deg f must be bounded from above (Riemann-Hurwitz). \u2013\u00a0 Francesco Polizzi Oct 25 '10 at 9:09\nWell, \"easily\" if one accepts standard facts on deformation theory. I actually would like to see a proof using only the standard theory of Riemann surfaces. Your argument about compactness seems nice, but it does not prove that every component is actually a point. Or I am missing something? Probably one can work out a simplified version of Kobayashi-Ochiai's proof for Riemann surfaces... \u2013\u00a0 Francesco Polizzi Oct 25 '10 at 10:05\n@Francesco: this morning, I did not claim that my argument shows that the mapping space is dicrete. I found an argument on my wayhome from the department and updated my answer. \u2013\u00a0 Johannes Ebert Oct 25 '10 at 16:18\nadd comment\n\nHere is an argument. It is a generalization of the argument that shows the finiteness of automorphism groups. I have not thought through the details, so there might be a bug.\n\nFirst we show that the mapping space is compact. This is an analytic argument. You can pick, by uniformization, universal covers $E \\to \\Sigma_i$ ($E\\subset C$ is the unit disc). Then assume that $f_n: \\Sigma_1 \\to \\Sigma_2$ is a sequence of maps. The goal is to find a convergent subsequence. You can find lifts of these maps $g_n:E \\to E$, such that $g_n(0)$ remains in a bounded ball in the Poincare metric. By Montel's theorem, you find a convergent subsequence of $g_n$; the limit is a function $g:E \\to C$ (not yet to $E$). If $|g(z)|=1$ for some $z \\in E$, by the maximum principle, $g$ is constant. You can exclude this case, because $g_n (0)$ was to stay in a ball, but the circle as $\\infty$ away from $0$. So you can assume that $g_n$ converges to some map $g: E \\to E$. $g$ will be invariant under the Deck transformation group of $\\Sigma_1$ and so it descends to a map $f: \\Sigma_1 \\to \\Sigma_2$. This shows that the space of holomorphic maps is compact. In particular, only finitely many homotopy classes can be realized by holomorphic maps.\n\nNext we show that any homotopy class contains at most one holomorphic map (if it is not constant). I use basic facts from algebraic topology, but no algebraic geometry for that. Let $f: \\Sigma_1 \\to \\Sigma_2$ be a holomorphic map and let $\\Gamma \\subset \\Sigma_1 \\times \\Sigma_2$ be the graph; it is a complex submanifold. The normal bundle to $\\Gamma$ can be identified with $f^{\\ast} T\\Sigma_2$. This bundle has negative degree if $f$ is not constant, namely $deg (f) \\chi (\\Sigma_2)$. The algebraic self-intersection number of (the homology class of) $\\Gamma$ is thus negative.\n\nIf $g$ were another holomorphic map in the same homotopy class as $f$, then the graph $\\Delta$ of $g$ has the same homology class as $\\Gamma$. Thus the algebraic intersection number of the two graphs is, as argued above, negative. If $g$ and $f$ were different, then $\\Gamma$ and $\\Delta$ intersect in a finite number of point and the intersection index at each intersection point is positive (because $f$ and $g$ are both holomorphic), so the sum of the intersection indices is nonnegative. On the other hand, these intersection indices should add to the algebraic intersection number of $\\Gamma$ with itself, which is negative. Contradiction.\n\nshare|improve this answer\nI like this. In fact, your argument on the normal bundle nicely agrees with the one I used to show that $f$ is rigid. The crucial point in both approaches is really that $f^\u2217T\u03a3_2$ has negative degree. \u2013\u00a0 Francesco Polizzi Oct 25 '10 at 16:38\nYes, I think this is the crucial point in most arguments about Riemann surfaces of genus larger than one. \u2013\u00a0 Johannes Ebert Oct 26 '10 at 18:05\nadd comment\n\nWe break the proof up into two steps: 1. The set of holomorphic maps is compact in the compact open topology. This is an easy consequence of the hyperbolicity of the Riemann surfaces\n\n  1. The space of holomorphic maps is discrete. Suppose that there is a one parameter family (f_t) of maps between the Riemann surfaces. The derviative (\\frac{\\partial f}{\\partial t}\\0 is then a holomorphic section of the pull-back of the tangent bundle of the range over the domain. By hyperbolicity there are no non-zero sections.\n\nYou can find arguments of this type in\n\nM. Kalka, B. Shiffman and B. Wong, Finiteness and Rigidity Theorems for Holomorphic Mappings, Michigan Math. J. 28 (1981), 289-295.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/12899/charged-particle-close-to-a-charged-black-hole-what-happens\nText:\nTake the tour \u00d7\n\nLet's assume the Reissner\u2013Nordstr\u00f6m metric (charged black hole, non-rotating), for simplicity. The black hole is charged with a powerful electric charge. There's a particle nearby, of non-zero mass, let's say an electron, its charge being the same sign like the black hole's charge. The particle's initial speed, relative to the BH, is zero. The particle is close to the event horizon, but still outside of it.\n\nThe question is - what happens? Are there any combinations of parameters where the particle starts falling in, but stops before being swallowed? Or even repulsed outright? If so, any quantitative, intuitive examples?\n\nI'm asking because I know how easily intuition can get deceived by General Relativity, and doing the math involving the R-N metric is probably not feasible for me now. :)\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet's say the black hole has mass and charge $Q$ and $M$, and the electron has $m$ and $q$. An extremal black hole has $|Q|=2M$ (in the appropriate units). An electron has $|q| \\gg 2m$ in the same units. If the electron fell into a negatively charged extremal R-N black hole, then the black hole would have $|Q| > 2M$, which would make it more than extremal. This would cause it to be a naked singularity, which would be exciting, since it would be a counterexample to the cosmic censorship hypothesis; but I'm pretty sure there is no such trivial counterexample, since cosmic censorship is still alive and kicking, decades after being conjectured. Another way of seeing that it will be repelled is that extremal R-N black holes with like charges do not interact; their gravitational attraction exactly cancels their electrostatic repulsion. Since the electron has a greater $|q|/m$, it will definitely be repelled.\n\nOne thing to watch out for in this kind of situation is that different observers can disagree on the direction of the forces. For example, a light ray that falls radially into a black hole experiences a repulsion at certain points as measured in Schwarzschild coordinates. This is the famous \"Hilbert repulsion\" beloved of kooks like Angelo Loinger. The light ray nevertheless passes through the horizon, and local observers never see a repulsion -- McGruder, Gravitational repulsion in the Schwarzschild field, Phys. Rev. D 25, 3191\u20133194 (1982).\n\nshare|improve this answer\nIs it really the case that CCH is alive? I think I recall reading multiple times that there's no problem constructing non-pathological solutions that violate it. Moreover, there doesn't seem any reason to require it to be true (except in the wonderland where people assume GR is all there is to physics and singularity is in any sense physical). \u2013\u00a0 Marek Jul 28 '11 at 19:16\n@Marek: I don't know any more about its current status than what the WP article en.wikipedia.org/wiki/Cosmic_censorship_hypothesis says. There's a weak version and a strong version, and each can be true or false independent of the other. There are issues with how to define the hypothesis correctly. If it does hold, then it has to depend on some energy condition, but we know that basically all energy conditions fail under some circumstances. Re assuming \"GR is all there is to physics,\" I disagree philosophically. If we can prove existence or nonexistence of singularities,[...] \u2013\u00a0 Ben Crowell Jul 28 '11 at 19:27\n[...continued...] that really does mean something. For instance, the Hawking singularity theorem doesn't guarantee that the big bang singularity was a physical singularity, but it does suggest that the universe got to somewhere around the Planck density, which is a nontrivial inference. In any case, I strongly doubt that there is such a trivial counterexample as dropping an electron into an extremal R-N black hole. \u2013\u00a0 Ben Crowell Jul 28 '11 at 19:28\nI don't quite follow. To get at BB singularity all you need is right FLRW solutions (which follow from the parameters obtained from observations), no need to invoke Hawking. Moreover, BB is one and only special event in this universe completely unrelated to any other BH out there. By the way, I agree that showing existence of singularities is very important -- it shows the theory is breaking down which implies new exciting physics is lurking close by. But there's no need to prevent them from happening. FWIW, I agree with your last sentence though. \u2013\u00a0 Marek Jul 28 '11 at 19:39\nFRW assumes perfect homogeneity and isotropy. The Hawking singularity theorem applies when there is not perfect homogeneity and isotropy. \u2013\u00a0 Ben Crowell Jul 28 '11 at 23:02\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/6695/proving-that-if-mathrmntimen100-subseteq-mathrmdtimen1000-the\nText:\nTell me more \u00d7\n\nI'd really like your help with proving the following.\n\nIf $\\mathrm{NTime}(n^{100}) \\subseteq \\mathrm{DTime}(n^{1000})$ then $\\mathrm{P}=\\mathrm{NP}$.\n\nHere, $\\mathrm{NTime}(n^{100})$ is the class of all languages which can be decided by nondeterministic Turing machine in polynomial time of $O(n^{100})$ and $\\mathrm{DTime}(n^{1000})$ is the class of all languages which can be decided by a deterministic Turing machine in polynomial time of $O(n^{1000})$.\n\nAny help/suggestions?\n\nshare|improve this question\nHint: padding. \u2013\u00a0 sdcvvc Nov 16 '12 at 14:55\nwhere does this question originate from? \u2013\u00a0 vzn Nov 16 '12 at 21:55\nadd comment\n\n3 Answers\n\nup vote 3 down vote accepted\n\nHere is the solution using padding. Suppose $L \\in \\mathrm{NTime}(n^{1000})$. Define a new language $L' = \\{x0^{|x|^{10}-|x|} : x \\in L\\}$. Each $x \\in L$ corresponds to some $y \\in L'$ of length $|y| = |x| + (|x|^{10}-|x|) = |x|^{10}$. Therefore we can decide whether $y \\in L'$ in non-deterministic time $|x|^{1000} = |y|^{100}$, i.e. $L' \\in \\mathrm{NTime}(n^{100}) \\subseteq \\mathrm{DTime}(n^{1000})$. In order to decide whether $x \\in L$, form $y = x0^{x^{10}-|x|}$ and run the $|y|^{1000} = |x|^{10000}$-time deterministic algorithm for $L'$. We conclude that $L \\in \\mathrm{DTime}(n^{10000})$.\n\nshare|improve this answer\nadd comment\n\nBreak the problem into two parts:\n\n  1. There is a $\\mathsf{NP}$-complete language in $\\mathsf{NTime}(n^{1000})$.\n  2. If an $\\mathsf{NP}$-complete language is in $\\mathsf{DTime}(n^{1000}) \\subset \\mathsf{P}$ then $\\mathsf{P}=\\mathsf{NP}$.\nshare|improve this answer\nadd comment\n\nThis is a near trivial consequence of the definition of NP-completeness. If any language in NP is solvable in polynomial time (which is asserted by the premise), then they all are. Another way to look at this is to look at Cook's theorem for NP-completeness that reduces all NP-complete languages to the recognition of a language involving SAT and the conversion of the nondeterministic Turing machine into SAT.\n\nshare|improve this answer\nWhat you said is true, but of NP complete languages (not NP languages). We also need to show that there exists an NP complete language solvable in $NTime(n^{100})$-true, I think, but not obvious by definition. \u2013\u00a0 SamM Nov 16 '12 at 17:45\nagreed, good pt. think this follows from bounds in the Cook proof....? all NP machines can be converted/solved by SAT in NTime($n^c)$, $c<100$...? \u2013\u00a0 vzn Nov 16 '12 at 18:39\n@vzn: I don't think we can prove $c \\lt 100$. I believe you might be contradicting one of the hierarchy theorems... \u2013\u00a0 Aryabhata Nov 16 '12 at 21:33\nafter thinking about it a little more carefully, agree. (initial glance, thought this was a basic question...) cooks proof creates a new SAT that is polynomially bounded in size relative to the original machine but the initial machine is unbounded in the polynomial exponent (wrt that proof). if I derived a contradiction then $P \\neq NP$ =) ... anyway maybe we are saying this is actually an open question? ie not known to be either true or false wrt existing theory? \u2013\u00a0 vzn Nov 16 '12 at 21:51\n@vzn: The question can be solved using the technique of padding, alluded to by sdcvvc. \u2013\u00a0 Yuval Filmus Nov 16 '12 at 22:56\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/109420/is-this-a-known-solvable-problem-system-of-algebraic-equations?answertab=active\nText:\nTell me more \u00d7\n\nHi there,\n\nI am trying to find complex solutions with positive real part $\\{t_j \\;|\\;{\\rm Re}\\;t_j>0, j = 1, 2, 3, \\dots, n\\}$ of the system of equations $$0 = 1 + \\sum_j \\left(t_j^{2l+1} + {t_j^*}^{2l+1}\\right),\\; l = 1,2,3,\\dots m.$$ Where for a given $n$ I would like to make $m$ as large as possible. Since, this system is non-analytic and thus for $n=m$ most likely under-constrained, I had the idea to just fix the magnitude of all solutions to 1: $t_j = e^{i\\phi_j}$ with $-{\\pi\\over 2} < \\phi_1 \\le \\phi_2 \\le \\dots \\le \\phi_n <{\\pi\\over 2}$. In terms of these the system becomes: $$0 = 1 + 2\\sum_j \\cos{\\left[\\phi_j(2l+1)\\right]},\\; l = 1,2,3,\\dots n.$$ This definitely has solutions up to $n=m=2$, but already for $n=3$, my naive attempt at numerically solving this (Mathematica's NSolve) is taking quite long. Is there some better way to find or at least confirm the existence of such solutions?\n\nThanks, Nik\n\nshare|improve this question\nWhat is $t_j^*$? Is that the complex conjugate? \u2013\u00a0 Gerry Myerson Oct 11 '12 at 22:34\nSo letting $\\phi_0=1$ and $\\phi_{-i}=-\\phi_i$ you want that for $0 \\le \\ell \\le m$ the values $(e^{i\\phi_k})^{2\\ell+1}$ for $-n \\le k \\le n$ to have average real part $0$. If they were, in each case, equally distributed around the unit circle, that would suffice. \u2013\u00a0 Aaron Meyerowitz Oct 12 '12 at 0:42\nGerry, yes that is correct, I should have said that! \u2013\u00a0 nik Oct 12 '12 at 15:15\nAaron, yes, but is it possible to use those considerations to construct solutions with ${-\\pi\\over2} < \\phi_j < {\\pi\\over 2}$? I.e. they must lie in the positive half-plane. \u2013\u00a0 nik Oct 12 '12 at 15:22\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nI would try to get rid of the trigonometric functions, and rather rewrite the system as a polynomial system. If $x_j=\\cos(\\phi_j)$, then $\\cos(\\phi_j(2\\ell+1))=T_{2\\ell+1}(x_j)$, where $T_k$ is the $k$-th Chebychev polynomial of degree $k$. So your system of equations is \\begin{equation} 0=1+2\\sum_j T_{2\\ell+1}(x_j),\\;\\;l=1,2,\\dots,m, \\end{equation} with the requirement that $0<x_j\\le 1$. Such a system can be discussed via Groebner bases, see here how to do that with Sage. For $m=n\\le4$ there are only finitely many solutions. Among them pick those which fit your inequalities. For instance, for $m=n=4$, an approximation of a solution seems to be \\begin{align*} x_1 &= 0.963494595276259\\\\ x_2 &= 0.852773246361416\\\\ x_3 &= 0.600336170417163\\\\ x_4 &= 0.058262327046178 \\end{align*} Of course, you can use this technique also to handle the original case, where $t_j$ need not have length $1$. For instance, for $n=2$ one can show that $m\\le4$, and and approximate solution for $m=4$ is $t_1=0.466916296430820 + 0.717248344919154i$, $t_2=0.856453001234213 + 0.445264622297009i$.\n\nOne cannot expect simple expressions for the $t_j$. For instance, the absolute values of the $t_j$ are roots of an irreducible (over the rationals) polynomial of degree $60$.\n\nshare|improve this answer\nThanks! That is very helpful! \u2013\u00a0 nik Oct 12 '12 at 15:25\nSo what does the final solution for $m=n=4$ come out to be? \u2013\u00a0 Aaron Meyerowitz Oct 13 '12 at 4:57\n@Aaron: Not sure what you mean. We have $t_j=e^{i\\phi_j}=\\cos(\\phi_j)+i\\sin(\\phi_j)=x_j\\pm i\\sqrt{1-x_j^2}$. Since nik adds $t_j^{2\\ell+1}$ and its complex conjugate, it does not matter which sign you choose in $\\pm i\\sqrt{1-x_j^2}$ for each $j$. \u2013\u00a0 Peter Mueller Oct 13 '12 at 9:10\nadd comment\n\nConsider the case $m=n=4.$ If we take $t_j=\\cos(\\frac{2j\\pi}{9})+I\\sin(\\frac{2j\\pi}{9})$ then $\\sum_{j=0}^{8}t_j^q= 1 + \\sum_{j=1}^{4} \\left(t_j^{q} + {t_j^*}^{q}\\right)=0$ for $1 \\le q \\le 8.$ This is because the set of values $t_j^q$ is just the nine $9$th roots of unity (or in two cases, the third roots of unity taken three times). Admittedly, this is not exactly what you wanted.\n\nIf you take just the real parts for $j=1,2,3,4$ you get\n\n  \u2022 $t_1=t_1^*=.766044443118979$\n  \u2022 $t_2=t_2^*=.173648177666934$\n  \u2022 $t_3=t_3^*=-.500000000000$\n  \u2022 $t_4=t_4^*=-0.939692620785905$\n\nIt can be seen that this makes $1 + \\sum_{j=1}^4 \\left(t_j^{q} + {t_j^*}^{q}\\right)=0$ correct for $q=1,3,5,7.$\n\nshare|improve this answer\nHmm, maybe I am missing something, but please see my response to your comment above. \u2013\u00a0 nik Oct 12 '12 at 15:24\nadd comment\n\nYour problem may be understood as solving a system of equations and inequalities over $\\mathbb{R}$. It is solvable in the sense that there exists an algorithm to find solutions (e.g. to find a point in every connected component specified by the system just mentioned).\n\nSuch algorithms are desribed, e.g., in this book: \"Algorithms in Real Algebraic Geometry\" by Saugata Basu, Richard Pollack, Marie-Fran\u00e7oise Roy.\n\nHow practical they are at present, is another question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://michaelnielsen.org/polymath1/index.php?title=Finding_narrow_admissible_tuples&diff=7961&oldid=prev\nText:\nFinding narrow admissible tuples\n\nFrom Polymath1Wiki\n\n(Difference between revisions)\nJump to: navigation, search\nm (Benchmarks)\nm (added asymmetric HR entry for 5453 due to Sun)\nLine 182: Line 182:\n| [ 112,562]\n| [ 112,562]\n| [ 53,774]\n| [ 48,484]\n| [ 48,484]\n\nRevision as of 11:54, 19 June 2013\n\nFor any natural number k0, an admissible k0-tuple is a finite set {\\mathcal H} of integers of cardinality k0 which avoids at least one residue class modulo p for each prime p. (Note that one only needs to check those primes p of size at most k0, so this is a finitely checkable condition.) Let H(k0) denote the minimal diameter \\max {\\mathcal H} - \\min {\\mathcal H} of an admissible k0-tuple. As part of the Polymath8 project, we would like to find as good an upper bound on H(k0) as possible for given values of k0. To a lesser extent, we would also be interested in lower bounds on this quantity. There is some scattered numerical evidence that the optimal value of H is roughly of size k0logk0 + k0 for k0 in the range of interest.\n\n\nUpper bounds\n\nUpper bounds are primarily constructed through various \"sieves\" that delete one residue class modulo p from an interval for a lot of primes p. Examples of sieves, in roughly increasing order of efficiency, are listed below.\n\nZhang sieve\n\nThe Zhang sieve uses the tuple\n\n{\\mathcal H} = \\{p_{m+1}, \\ldots, p_{m+k_0}\\}\n\nwhere m is taken to optimize the diameter p_{m+k_0}-p_{m+1} while staying admissible (in practice, this basically means making m as small as possible). Certainly any m with pm + 1 > k0 works; in particular, one can just take {\\mathcal H} to be the first k0 primes past k0, but this is not optimal. Applying the prime number theorem then gives the upper bound H \\leq (1+o(1)) k_0\\log k_0.\n\nHensley-Richards sieve\n\nThe Hensley-Richards sieve [HR1973], [HR1973b], [R1974] uses the tuple\n\n{\\mathcal H} = \\{-p_{m+\\lfloor k_0/2\\rfloor - 1}, \\ldots, -p_{m+1}, -1, +1, p_{m+1},\\ldots, p_{m+\\lfloor k_0/2+1/2\\rfloor-1}\\}\n\nwhere m is again optimised to minimize the diameter while staying admissible.\n\nAsymmetric Hensley-Richards sieve\n\nThe asymmetric Hensley-Richard sieve uses the tuple\n\n{\\mathcal H} = \\{-p_{m+\\lfloor k_0/2\\rfloor - 1-i}, \\ldots, -p_{m+1}, -1, +1, p_{m+1},\\ldots, p_{m+\\lfloor k_0/2+1/2\\rfloor-1+i}\\}\n\nwhere i is an integer and i,m are optimised to minimize the diameter while staying admissible.\n\nSchinzel sieve\n\nGiven 0 < y < z < x, the Schinzel sieve (discussed in [S1961], [HR1973], [GR1998], [CJ2001]) sieves the interval [1,x] by 1mod p for primes p \\le y and by 0mod p for primes y < p \\le z. Provided that z is large enough (z = k0 clearly suffices), the first k0 survivors form an admissible k0-tuple (but not necessarily the narrowest one in the interval). The case y = 1 corresponds to a sieve of Eratosthenes; if one minimizes z and takes the first k0 survivors greater than 1, this yields the same admissible k0 tuple as Zhang, with the minimal possible value of m.\n\nShifted Schinzel sieve\n\nAs a generalization of the Schinzel sieve, one may instead sieve shifted intervals [s,s + x]. This is effectively equivalent to sieving the interval [0,x] of the residue classes -s\\ \\bmod\\ p for primes p\\le y and  1-s\\ \\bmod\\ p for primes y<p\\le z.\n\nGreedy sieve\n\nWithin a given interval, one sieves a single residue class amod p for increasing primes p=2,3,5,\\ldots, with a chosen to maximize the number of survivors. Ties can be broken in a number of ways: minimize a\\in[0,p-1], maximize a\\in [0,p-1], minimize |a-\\lfloor p/2\\rfloor|, or randomly. If not all residue classes modulo p are occupied by survivors, then a will be chosen so that no survivors are sieved. This necessarily occurs once p exceeds the number of survivors but typically happens much sooner. One then chooses the narrowest k0-tuple {\\mathcal H} among the survivors (if there are fewer than k0 survivors, retry with a wider interval).\n\nGreedy-greedy sieve\n\nHeuristically, the performance of the greedy sieve is significantly improved by starting with a shifted Schinzel sieve on [s,\\ s+x] using y = 2 and z = \\sqrt{x} and then continuing in a greedy fashion, as proposed by Sutherland. One first optimizes the shift value s over some larger interval (e.g. [-k_0\\log\\ k_0,\\ k_0\\log\\ k_0]) and then continues the sieving over primes p > z greedily choosing the best residue class for each prime according to a chosen tie-breaking rule (in Sutherland's original implementation, ties are broken downward in [0,\\ p-1]).\n\nSeeded greedy sieve\n\nGiven an initial sequence {\\mathcal S} that is known to contain an admissible k0-tuple, one can apply greedy sieving to the minimal interval containing {\\mathcal S} until an admissible sequence of survivors remains, and then choose the narrowest k0=tuple it contains. The sieving methods above can be viewed as the special case where {\\mathcal S} is the set of integers in some interval. The main difference is that the choice of {\\mathcal S} affects when ties occur and how they are broken with greedy sieving. One approach is to take {\\mathcal S} to be the union of two k0-tuples that lie in roughly the same interval (see Iterated merging) below.\n\nIterated merging\n\nGiven an admissible k0-tuple \\mathcal{H}_1, one can attempt to improve it using an iterated merging approach suggested by Castryck. One first uses a greedy (or greedy-Schinzel) sieve to construct an admissible k0-tuple \\mathcal{H}_2 in roughly the same interval as \\mathcal{H}_1, then performs a randomized greedy sieve using the seed set \\mathcal{S} = \\mathcal{H}_1 \\cup \\mathcal{H}_2 to obtain an admissible k0-tuple \\mathcal{H}_3. If \\mathcal{H}_3 is narrower than \\mathcal{H}_2, replace \\mathcal{H}_2 with \\mathcal{H}_3, otherwise try again with a new \\mathcal{H}_3. Eventually the diameter of \\mathcal{H}_2 will become less than or equal to that of \\mathcal{H}_1. As long as \\mathcal{H}_1\\ne \\mathcal{H}_2, one can continue to attempt to improve \\mathcal{H}_2, but in practice one stops after some number of retries.\n\nAs described by Sutherland, one can then replace \\mathcal{H}_1 with \\mathcal{H}_2 and begin the process anew, yielding a randomized algorithm that can be run indefinitely. Key parameters to this algorithm are the choice of the interval used when constructing \\mathcal{H}_2, which is typically made wider than the minimal interval containing \\mathcal{H}_1 by a small factor \u03b4 on each side (Sutherland suggests \u03b4 = 0.0025), and the number of failed attempts allowed while attempting to impove \\mathcal{H}_2.\n\nEventually this process will tend to converge to particular \\mathcal{H}_1 that it cannot improve (or more generally, a set of similar \\mathcal{H}_1's with the same diameter). Interleaving iterated merging with the local optimizations described below often allows the algorithm to make further progress.\n\nIterated merging can be viewed as a form of simulated annealing. The set \\mathcal{S} initially contains at least two admissible k0-tuples (typically many more), and as the algorithm proceeds the set \\mathcal{S} converges toward \\mathcal{H}_1 and the number of admissible k0-tuples it contains declines. One can regard the cardinality of the difference between \\mathcal{S} and \\mathcal{H}_1 as a measure of the \"temperature\" of a gradually cooling system, since the number of choices available to the algorithm declines as this cardinality is reduced (more precisely, one may consider the entropy of the possible sequence of tie-breaking choices available for a given \\mathcal{S}).\n\nLocal optimizations\n\nLet \\mathcal H = \\{h_1,\\ldots, h_{k_0}\\} be an admissible k0-tuple with endpoints h1 and h_{k_0}, and let \\mathcal I be the interval [h_1,h_{k_0}]. If there exists an integer h\\in\\mathcal I such that removing one of \\mathcal H's endpoints and inserting h yields an admissible k0-tuple \\mathcal H', then call \\mathcal H contractible, and if not, say that \\mathcal H non-contractible. Note that \\mathcal H' necessarily has smaller diameter than \\mathcal H. Any of the sieving methods described above may produce admissible k0-tuples that are contractible, so it is worth testing for contractibility as a post-processing step after sieving and replacing \\mathcal H by \\mathcal H' if this test succeeds.\n\nWe can also shift \\mathcal H to the left by removing its right end point h_{k_0} and replacing it with the greatest integer h0 < h1 that yields an admissible k0-tuple \\mathcal H', and we can similarly shift \\mathcal H to the right. The diameter of \\mathcal H' need not be less than \\mathcal H, but if it is, it provides a useful replacement. More generally, by shifting \\mathcal H repeatedly we can produce a sequence of admissible k0-tuples that lie successively further to the left or right. In general the diameter of these tuples may grow as we do so, but it will also occasionally decline, and we may be able to find a shifted \\mathcal H' with smaller diameter than \\mathcal H.\n\nA more sophisticated local optimization involves a process of ``adjustment\" proposed by Savitt. Let \\mathcal H be an admissible k0-tuple. For a prime p and an integer a, let [a;p] denote the residue class amod p, i.e. the set of integers {x:x = amod p}. Call [a;p] occupied if it contains an element of \\mathcal H .\n\nSuppose that [a;p] and [b;q] are occupied residue classes, for some distinct primes p and q, and that [a';p] and [b';q] are unoccupied. Let \\mathcal U be the intersection of \\mathcal H with [a;p] \\cup [b;q], and let \\mathcal V be a subset of the integers that lie in the intersection of the interval I containing H and the set [a';p] \\cup [b';q] such that the set \\mathcal H' formed by removing the elements of \\mathcal U from \\mathcal H and adding the elements of \\mathcal V is admissible. A necessary (and often sufficient) condition for and integer v to lie in \\mathcal V is that v must not lie in a residue class [c;r] that is the unique unoccupied residue class modulo r for any prime r other than p or q.\n\nThe admissible set \\mathcal H' lies in the interval \\mathcal I containing \\mathcal H, so its diameter is no greater than that of \\mathcal H, however its cardinality may differ. If it happens that \\mathcal H' contains more elements than \\mathcal H , then by eliminating points at either end of \\mathcal H' we obtain an admissible k0-tuple that is narrower than \\mathcal H and may ``adjust\" \\mathcal H by replacing it with \\mathcal H' . The process of adjustment can often be applied repeatedly, yielding a sequence of successively narrower admissible k0-tuples.\n\nFurther refinements\n\nLower bounds\n\nThere is a substantial amount of literature on bounding the quantity \u03c0(x + y) \u2212 \u03c0(x), the number of primes in a shifted interval [x + 1,x + y], where x,y are natural numbers. As a general rule, whenever a bound of the form\n\n \\pi(x+y) - \\pi(x) \\leq F(y) (*)\n\nis established for some function F(y) of y, the method of proof also gives a bound of the form\n\n k_0 \\leq F( H(k_0)+1 ). (**)\n\nIndeed, if one assumes the prime tuples conjecture, any admissible k0-tuple of diameter H can be translated into an interval of the form [x + 1,x + H + 1] for some x. In the opposite direction, all known bounds of the form (*) proceed by using the fact that for x > y, the set of primes between x + 1 and x + y is admissible, so the method of proof of (*) invariably also gives (**) as well.\n\nExamples of lower bounds are as follows;\n\nBrun-Titchmarsh inequality\n\nThe Brun-Titchmarsh theorem gives\n\n \\pi(x+y) - \\pi(x) \\leq (1 + o(1)) \\frac{2y}{\\log y}\n\nwhich then gives the lower bound\n\n H(k_0) \\geq (\\frac{1}{2}-o(1)) k_0 \\log k_0.\n\nMontgomery and Vaughan deleted the o(1) error from the Brun-Titchmarsh theorem [MV1973, Corollary 2], giving the more precise inequality\n\n k_0 \\leq 2 \\frac{H(k_0)+1}{\\log (H(k_0)+1)}.\n\nFirst Montgomery-Vaughan large sieve inequality\n\nThe first Montgomery-Vaughan large sieve inequality [MV1973, Theorem 1] gives\n\n k_0 (\\sum_{q \\leq Q} \\frac{\\mu^2(q)}{\\phi(q)}) \\leq H(k_0)+1 + Q^2\n\nfor any Q > 1, which is a parameter that one can optimise over (the optimal value is comparable to H(k0)1 / 2).\n\nSecond Montgomery-Vaughan large sieve inequality\n\nThe second Montgomery-Vaughan large sieve inequality [MV1973, Corollary 1] gives\n\n k_0 \\leq (\\sum_{q \\leq z} (H(k_0)+1+cqz)^{-1} \\mu(q)^2 \\prod_{p|q} \\frac{1}{p-1})^{-1}\n\nfor any z > 1, which is a parameter similar to Q in the previous inequality, and c is an absolute constant. In the original paper of Montgomery and Vaughan, c was taken to be 3 / 2; this was then reduced to \\sqrt{22}/\\pi [B1995, p.162] and then to 3.2 / \u03c0 [M1978]. It is conjectured that c can be taken to in fact be 1.\n\n\nEfforts to fill in the blank fields in this table are very welcome.\n\nk03,500,000 181,000 34,429 26,024 23,283 22,949 10,719 6,329 5,453 5,000\nUpper bounds\nFirst k0 primes past k0 59,874,594 2,530,338 420,878 310,134 275,082 270,698 117,714 65,924 55,892 50,840\nZhang sieve 59,093,364 2,486,370 411,932 303,558 268,536 264,414 114,806 64,176 54,488 49,578\nHensley-Richards sieve 57,554,086 2,422,558 402,790 297,454 262,794 258,780 112,868 63,708 48,634\nAsymmetric Hensley-Richards 2,418,054 401,700 296,154 262,286 258,302 112,562 53,774 48,484\nShifted Schinzel sieve 2,413,228 400,512 295,162 262,206 258,000 112,440 48,726\nGreedy-greedy sieve 2,326,476 388,076 286,308 253,968 249,992 108,694 46,968\nBest known tuple 57,554,086 2,326,476 386,382 285,210 252,804 248,898 108,450 60,726 51,526 46,810\nk0logk0 + k0 56,238,957 2,372,232 394,096 290,604 257,405 253,381 110,119 61,727 52,371 47,586\nLower bounds\nInclusion-exclusion 29,508,018 1,513,556 193,420 85,878 49,464 38,048\nPartitioning 156,614 73,094 43,130 34,068\nMV with c = 1 (conjectural) 32,503,908 1,395,694 234,872 173,420 153,691 151,298 66,314 37,274 28,781\nMV with c = 3.2 / \u03c0 32,469,985 1,393,869 234,529 173,140 153,447 151,056 66,211 37,207 28,737\nMV with c=\\sqrt{22}/\\pi 31,765,216 1,357,096 227,078 167,860 148,719 146,393 63,917 35,903 27,708\nSecond Montgomery-Vaughan 31,756,667 1,356,644 226,987 167,793 148,656 146,338 63,886 35,887 27,696\nBrun-Titchmarsh 30,137,225 1,272,083 211,046 155,555 137,756 135,599 58,863 32,916 25,351\nFirst Montgomery-Vaughan 28,080,007 1,184,954 196,729\n\n\n\n\n\n128,971 126,931 55,149\n\n\n30,982 24,012\n\n\nk0 4,000 3,405 3,000 2,000 1,000 672 342\nUpper bounds\nFirst k0 primes past k0 39,660 33,222 28,972 18,386 8,424 5,406 2,472\nZhang sieve 38,596 32,296 28,008 17,766 8,212 5,216 2,414\nHensley-Richards sieve 38,498 31,820 27,806 17,726 8,258 5,314\nAsymmetric Hensley-Richards 37,932 27,638 17,676 8,168 5,220\nShifted Schinzel sieve 38,168 27,632 17,616 8,160 5,196\nGreedy-greedy sieve 36,756 26,754 17,054 7,854 5,030\nBest known tuple 36,612 30,600 26,606 16,978 7,802 5,010* 2,328\nEngelsma data 36,622 30,606 26,622 16,978 7,802 4,998 2,328\nk0logk0 + k0 37,176 31,098 27,019 17,202 7,907 5,046 2,338\nLower bounds\nInclusion-exclusion 29,746 21,884 14,082\nPartitioning 27,248 20,434 13,620 6,802 4,574 342\nMV with c = 1 (conjectural) 22,564 18,898 16,456 10,500 4,858 3,124\nMV with c = 3.2 / \u03c0 22,523 18,866 16,428 10,480 4,847 3,118\nMV with c=\\sqrt{22}/\\pi 21,701 18,153 15,758 10,061 4,648 2,979\nSecond Montgomery-Vaughan 21,690 18,143 15,751 10,056 4,645 2,977\nBrun-Titchmarsh 19,785 16,536 14,358 9,118 4,167 2,648\nFirst Montgomery-Vaughan 18,768\n\n\n15,783 13,696 8,448\n\n\n3,959 2,558\n\nThe bold number indicates the best currently known result for a twin-prime-like theorem.\n\n* indicates that the widths listed are the best known tuples that have been found by the methods that gave the entries for larger values of k0, but are not as narrow as the literally best known tuples (due to Engelsma). For k0=342 and below the exact values of H(k0) have been determined by Engelsma (each is one less than the corresponding value of w listed in his tables).\n\nFor the Zhang tuples the optimal m < \u03c0(1010) that produced an admissible k0-tuple was used. This is not always the least m that produces an admissible k0-tuple; for k0 = 22,949, for example, the minimal m = 586 yields an admissible k0-tuple of diameter of 264,460, but m = 599 yields a narrower admissible k0-tuple with the listed diameter of 264,414. A list of table entries for which this occurs can be found here (and also for k0=6,329).\n\nThe shifted Schinzel tuples were generated with y = 2 using an optimally chosen interval contained in [ \u2212 k0logk0,k0logk0] (the interval is not in every case guaranteed to be optimal, particularly for larger values of k0, but it is believed to be so).\n\nThe greedy-greedy tuples were generated using Sutherland's original algorithm, breaking ties downward in every case (and the optimal interval in [ \u2212 k0logk0,k0logk0] was selected on this basis). As noted by Castryck, breaking ties upward may produce better results in some cases.\n\nThe lower bounds listed under in the inclusion-exclusion and partitioning rows due to Avishay and computed as described in this document (the case k0=342 corresponds to the trivial partition).\n\nPersonal tools"}
{"text": "Retrieved from http://math.stackexchange.com/questions/140583/compute-the-period-of-a-decimal-number-a-priori\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nUpper bound/exact length of decimal expansion of simple fraction\n\nI noticed that WolframAlpha given an operation like $\\frac{n}{m},\\;n,m \\in N$ that result in a periodic decimal number, computes really fast the length of the period.\n\nE.g. $\\frac{3923}{6173}$ has a period of 3086: here.\n\nI was wondering how this computation is done: is there some method to do this (except the trivial one of executing the division and looking for a sequence repetition) ?\n\nshare|improve this question\nNote: i'm not a mathematician, I apologize if I have done some mistake with names, tags, etc.. \u2013\u00a0 Aslan986 May 3 '12 at 20:54\nadd comment\n\nmarked as duplicate by Ross Millikan, sdcvvc, William, t.b., rschwieb Sep 14 '12 at 16:39\n\n\n3 Answers\n\nup vote 3 down vote accepted\n\nThe period is always a factor of the totient of the denominator. In your example, 6173 is prime, so its totient is 6172 and half of that is 3086. I suspect Alpha is just doing the long division. When the remainder at any step matches the remainder at a previous step you have found the repeat. You can also find the repeat by finding the $k$ such that $10^k \\equiv 1 \\pmod {denominator}$\n\nshare|improve this answer\nadd comment\n\nconsider for example $10/3=0.333333333333333 $ which has period 3,or 33 or as you like,it happens when one number can't be divided by another exactly and during this division,some sequence of numbers is repeating\n\nshare|improve this answer\nYes, sure :).The period length here is 1. In the example above the period length is 3086. I mean, 3086 is not the period, but it is its length. I Wonder how to compute this length a priori. \u2013\u00a0 Aslan986 May 3 '12 at 21:11\nadd comment\n\nSuppose that the fraction $\\rm\\:r\\in (0,1)$ has a decimal expansion purely periodic of length $\\rm\\:k.\\:$ Then $\\rm\\:10^k r - r\\:\\! =\\:\\! (10^k-1)\\:\\! r = n\\:$ is an integer, since $\\rm\\:10^k r\\:$ is simply $\\rm\\:r\\:$ left-shifted by $\\rm\\:k\\:$ places, so its digits after the decimal point are the same as those of $\\rm\\:r,\\:$ so they cancel out in the subtraction, leaving an integer. Conversely, if $\\rm\\: r = n/(10^k-1)$ then $\\rm\\:10^k\\:\\! r = n + r\\:$ so $\\rm\\:r\\:$ has period $\\rm\\:k\\:$ (or a divisor of $\\rm\\:k\\:$ if the cycle is not minimal).\n\nTherefore, to find the minimal period of $\\rm\\:r = n/m\\:$ we need to find the minimal $\\rm\\:k\\:$ such that $\\rm\\:(10^k-1) n/m\\:$ is an integer, i.e. such that $\\rm\\:m\\:|\\:n\\:\\!(10^k-1)\\:$ (here $\\rm\\:a\\:|\\:b\\:$ denotes $\\rm\\:a\\:$ divides $\\rm\\:b).\\:$ We may assume that $\\rm\\:n/m\\:$ is in lowest terms, i.e. $\\rm\\:gcd(m,n) = 1.\\:$ Hence, by Euclid's lemma, from $\\rm\\:m\\:|\\:n\\:\\!(10^k-1)\\:$ we deduce $\\rm\\:m\\:|\\:10^k-1.\\:$ Thus to find the least period we need to find the least $\\rm\\:k\\:$ such that $\\rm\\:10^k \\equiv 1\\pmod{m},\\:$ i.e. the order of $10,\\:$ modulo $\\rm\\:m.\\:$ There are various algorithms known for computing such orders, e.g. see the references in this post.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://mathoverflow.net/questions/37061/normal-varieties?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nLet X be a complex normal variety and U a subvariety that is open in the analytic topology. Then the map $\\pi_1(U) \\to \\pi_1(X)$ coming from the map $U \\subset V$ is surjective - why is this?\n\nedited to include complex\n\nshare|improve this question\nIf someone else doesn't give an answer, I'll try to write one later. In outline: reduce it to a local statement (normality enters because the links are connected) then use van Kampen. \u2013\u00a0 Donu Arapura Aug 29 '10 at 15:39\nI guess you are working over $\\mathbb{C}$? E.g., over $\\mathbb{R}$ the inclusion $\\mathbb{A}^1 \\subset \\mathbb{P}^1$ gives a counterexample. \u2013\u00a0 Pete L. Clark Aug 29 '10 at 15:47\nIs normality really needed? A subvariety that is open in the analytic topology is also open in the Zariski topology, and consequently has complement with \"topological\" codimension at least 2. But loops are 1-dimensional, so in $X$ they can be deformed to be entirely in $U$. That's a sketch of a proof, ignoring care needed to deal with singularities (in $X$ and $X-U$), so does a problem really arise when the singularities are worse than normal? \u2013\u00a0 BCnrd Aug 29 '10 at 15:49\nI'm assuming this is over $\\mathbb{C}$, but it should be stated. Also a more descriptive title would help. \u2013\u00a0 Donu Arapura Aug 29 '10 at 15:49\nBCnrd, if $X$ is a nodal rational curve, and $U$ is the smooth part, $\\pi_1(U)=\\mathbb{Z}$ maps to $0$, but $\\pi_1(X)=\\mathbb{Z}$. \u2013\u00a0 Donu Arapura Aug 29 '10 at 15:54\nshow 5 more comments\n\n2 Answers\n\nThis isn't strictly what you're looking for, but I don't have the rep to leave this as a comment. In the algebraic situation, this follows from Grothendieck's general yoga, which says that the map of (etale) fundamental groups induced by $U\\to X$ is surjective precisely when every connected (etale) cover of $X$ is still connected when pulled back to $U$. When $X$ is normal (or more generally, geometrically unibranch, if I'm not mistaken), then one checks easily that every connected etale cover of $X$ is still connected over the generic point of $X$ (I'm assuming $X$ itself is connected).\n\nI'm looking forward to Donu Arapura's geometric answer!\n\nshare|improve this answer\nIn fact, Keerthi Madapusi's idea works for the topological fundamental group. The point is that the statement holds for analytic spaces; by considering the universal cover, which is again an analytic space, it reduces to the statement that removing an analytic subspace of codimension 2 from a normal analytic space does not disconnect it, which follows easily from the Serre's characterization of normal local rings, by using local cohomology. \u2013\u00a0 Angelo Aug 29 '10 at 17:47\nGiven Keerti's answer + comments by Angelo & BCnrd, I think I'm off the hook :) \u2013\u00a0 Donu Arapura Aug 29 '10 at 18:02\nDear Angelo: can we really bypass invoking the Riemann Extension Theorem for bounded analytic functions on normal analytic spaces? It's only the bounded analytic functions that extend, not all of them, so how can local cohomology or other purely algebraic methods detect this? I am very interested to hear the idea behind how such an argument might go. (Note: I've never really looked into gap sheaves, if that is somehow relevant.) If there is an \"algebraic\" proof of the Extension Theorem, I'd be happy to see that too. \u2013\u00a0 BCnrd Aug 29 '10 at 21:15\nadd comment\n\nI would like to risk an answer that does not use the language of algebraic geometry. For a pair (complex analytic variety $X$; closed anlalitic subvariety $Y$), $U=X\\setminus Y$,\nthere exists a triangulation such that $Y$ is a subcomplex (see, for example Triangulations of algebraic sets - Hironaka 1974, can be found with google books). In other words $X$ is a simplicial complex, and $Y$ is a subcomplex. Now, if $X$ is normal its sinuglarities are in real codimension at least $4$. I.e. $X$ is a $PL$ manifold in codimension $4$.\n\nIn order to show that the fundamental group of $X\\setminus Y$ surjects onto the fundamental group of $X$, it is sufficient to show that every loop in $X$ can be homothoped into $X\\setminus Y$. Since $Y$ it is contained in the simplicial subcomplex of codimesnion $2$ it is enougth to show that any loop in $X$ can be homothoped so it does not touch any simplex of codim $2$, but this is true for every $PL$ space that is a manifold in codim $2$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/54163/lebesgue-outer-measure-of-0-1-cap-mathbbq\nText:\nTake the 2-minute tour \u00d7\n\nConsider the Lebesgue outer measure $$ \\bar{m}(X) = \\inf_{A \\supset X}\\bigg\\{\\sup_{P\\subset A}\\quad m(P)\\bigg\\} $$ where $X = [0,1]\\cap \\mathbb{Q}$ and $P = \\bigcup [a_i,b_i]$ is a suitable union of intervals. My question is: suppose that $\\bar{m}(X)=0$: can you exhibit one of those $A$'s? Thanks\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nSince $[0,1]$ is Borel and $\\mathbb Q$ is Borel, so is their intersection.\n\nTherefore these sets are in fact Lebesgue measurable, so the outer Lebesgue measure is equal to the Lebesgue measure.\n\nWe have, if so $\\overline m(X)=0$, therefore the intersection is of shrinking intervals.\n\nConsider $\\mathbb Q=\\{q_n\\mid n\\in\\mathbb N\\}$ an enumeration of the rationals in $X$ and $\\epsilon>0$, let $[a_i,b_i]$ be an interval around $q_i$ such that $b_i-a_i<\\frac{\\epsilon}{2^i}$, and let $A=\\bigcup [a_i,b_i]$.\n\nshare|improve this answer\nI am a bit confused about your answer. Your $A$ contains $[0,1]$, right? So its outer measure should be $\\geq 1$ ? \u2013\u00a0 user13823 Jul 28 '11 at 2:13\n@Sxy: No, why would it contain $[0,1]$? Note that the sum of the interval's length is only $\\epsilon$. So for a very very small $\\epsilon$ we have that $A$ contains almost nothing out of $[0,1]$. However if you take $\\epsilon$ to be $42$ then it might have some larger measure. \u2013\u00a0 Asaf Karagila Jul 28 '11 at 2:15\nSorry, you are right. My misunderstanding was related to a bad density argument I had in mind: the set of elements $\\{q_i\\}$ is dense in $X$, then each interval surrounding a single $q_i$ must contain some little part of $[0,1]$. So I jumped to the conclusion that those intervals had to cover $[0,1]$ completely. \u2013\u00a0 user13823 Jul 28 '11 at 7:01\n$X=\\mathbb{Q}\\cap[0,1]$ is measurable and countable, therefore, $m(X)=0$. But, take intervals $I_k$ that cover $X$. Then $1=m([0,1])=m^*(\\overline{X})\\leq m^*\\left(\\overline{\\bigcup I_k}\\right)\\leq m^*\\left(\\bigcup \\overline{I_k}\\right)\\leq \\sum m^*(\\overline{I_k})=\\sum m^*(I_k)$ \u2013\u00a0 leo Sep 30 '11 at 5:59\nWhere I've put the overline for closure. Then for any covering by intervals $I_k$, we have $\\sum m^*(I_k)\\geq 1$ and this implies that $m(X)\\geq 1$. What is the problem? What am I missing? Thank you. \u2013\u00a0 leo Sep 30 '11 at 6:04\n\nAny cover of the rationals would be a collection of open sets containing all rationals in [0,1]. A specific example would be: take any enumeration {$q_1,q_2,..,q_n,...$} of all rationals in $\\mathbb Q \\cap [0,1]$, and the use the open sets $O_n:=(q_n-\\frac{1}{2^n},q_n+\\frac {1}{2^n})$\n\nTo determine the outer measure, you may want to scale each interval by a fixed $\\epsilon>0$ and then add the widths of all the intervals (see what happens when you let $\\epsilon>0$ become small).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/dr.math/faq/faq.two.trains.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math: FAQ\n\n\u00a0\u00a0The Two Trains\u00a0\u00a0\n\n\n\n\nTo solve this problem, we'll use the distance formula:\n\n    Distance = Rate x Time\n\nSince an equation remains true as long as we perform the same operation on both sides, we can divide both sides by rate:\n\n      ----------\u00a0\u00a0=\u00a0 Time\nor by time:\n\n      ----------\u00a0\u00a0=\u00a0\u00a0Rate\n\n\nSpeed is another word that is used for rate. When a problem says that a train is moving at a speed of 40 mph, you can understand this to mean that the train's rate is 40 mph, which means it will travel 40 miles in one hour.\n\nHere are two different ways to approach this problem. Let's start by listing the information given:\n\n    Speed of Train A: 70 mph\n    Speed of Train B: 60 mph\n    Distance between Westford and Eastford: 260 miles\n\nMethod I: We'll use the notion of relative speed 1 (or relative rate) in order to express the rates of the two trains in one number that can then be used in the distance formula.\n\nImagine you're on Train A. You're going 70 mph, so your speed relative to the trees, houses, and other non-moving things outside the train is 70 mph. (All of those objects look as if they're going by at 70 mph.) Now imagine you're the engineer and you can see Train B coming toward you - not on the same track, of course! Since Train B is moving 60 mph, it will look as if it's approaching faster than if it were sitting still in the station - a lot faster than the trees and houses appear to be moving.\n\nThe relative speed of the two trains is the sum of the speeds they are traveling. (If you're on either of the trains, this is the speed you appear to be moving when you see the other train.) In our problem, the relative speed of the two trains is 70 mph + 60 mph = 130 mph. What if the trains were traveling in the same direction? Then we'd need to subtract the speed of the slower train from the speed of the faster train, and their relative speed would be 10 mph.\n\nAt this point we know two of the three unknowns: rate and distance, so we can solve the problem for time. Remember that time = distance/rate, the distance traveled is 260 miles, and the relative speed is 130 mph:\n\n    t = 260 miles/130 mph\n    t = 2 hrs.\n\nWe find that the trains meet two hours after leaving their respective cities.\n\nMethod II: Here we'll begin by noting that the distance between Westford and Eastford is 260 miles: this is the total distance the trains will travel. Using the distance formula (Distance = rate x time, or D = rt) we can express the distance traveled by each train:\n\n    Train A moving at 70 mph in t hours will cover 70t miles\n    Train B moving at 60 mph in t hours will cover 60t miles\n\n    Together the two trains will cover the distance 70t + 60t\n\nSince we know that this distance is 260 miles, we can write the following algebraic equation to represent this information.\n\n    70t + 60t = 260\n\nSolving this equation we find that:\n\n    130t = 260\n    \u00a0 \u00a0 t = 2\n\nwhich tells us that the trains will meet in 2 hours.\n\nNow, where do the trains meet? We again use the distance formula to find how far each train has traveled in two hours:\n\n    For Train A: 70 mph x 2 hrs = 140 miles\n    For Train B: 60 mph x 2 hrs = 120 miles\n\nThus the two trains meet at a point 140 miles from Westford and 120 miles from Eastford.\nTo check this, we can add 140 to 120: the answer is 260, which was the given distance between the two cities.\n\nLet's look at a variation on this problem.\n\nTrain A, traveling 40 mph, leaves Westford heading toward Eastford, 260 miles away. One hour after Train A leaves Westford, Train B, traveling 70 mph, leaves Eastford heading toward Westford. When do the two trains meet?\n\nNotice that in this problem, the two trains do not leave their respective cities at the same time.\n\nMethod I: Let's move the starting point for Train A so we can treat the problem as if the trains leave at the same time, which we already know how to do.\n\nWe know that Train A is moving 40 mph, and will therefore travel 40 miles in the hour before Train B leaves Eastford. This means that by the time Train B starts moving, the two trains are only 260 - 40 = 220 miles apart. Now we can use the relative speed of the trains, which is 40 + 70 = 110 mph. Using the distance formula for time (time = distance/rate), we write:\n\n    t = 220 miles/110 mph\n    t = 2 hrs.\n\nSince t represents the time traveled by each train after Train A has already traveled for one hour, Train B travels 2 hours before meeting Train A. Adding the extra hour that Train A travels before Train B starts moving, we see that Train A must travel 3 hours before meeting Train B.\n\nMethod II: Let t represent the time that Train A travels. Since Train B leaves one hour after Train A, let t -1 represent the time that Train B travels.\n\nAgain, the sum of the distances traveled by the two trains up until the time they meet is 260 miles: between the two of them, they cover all 260 miles of track. Using the distance formula:\n\n    distance traveled by Train A = 40t\n    distance traveled by Train B = 70(t -1)\n\n    40t + 70(t-1) = 260 miles\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0t = 3 hrs.\n\nSince t represents the time that Train A has been traveling, this means that Train A travels 3 hours before meeting Train B. But how long has Train B been traveling? Train B travels t -1 hours, which means that it travels 2 hours before meeting Train A.\n\nTo help us make sense of relative speed and how it relates to distance traveled, let's think of it in terms of the distance the two trains travel toward each other in one hour. We'll again use the distance formula:\n\n    Rate x Time = Distance\n\n    Train A's rate is 70 mph, so: 70 mph x 1 hr = 70 miles\n    Train B's rate is 60 mph, so: 60 mph x 1 hr = 60 miles\n\nIf we add these two numbers together, we get 130 miles, which means that 130 miles of track will be covered in one hour. This is the same as saying that the two trains are going 130 mph relative to each other, so:\n\n    130 mph x 1 hr = 130 miles\n\nEither way, the numbers tell you that 130 miles of track will be covered in an hour.\n\nFrom the Dr. Math Archives\n\n\u00a0\u00a0Trains, cars, bikes, boats, dolphins... using distance = rate x time:\n\nCycling around a Track\nDolphin Swimming\nHow Fast Does Bobo Run?\nHow Many Trains Meet?\nMan Crossing a Bridge\nMan and Train on a Bridge\nMan on a Railroad Bridge\nRowing Upstream and Down\nRunning in Opposite Directions\nSpeed of Two Trains\nTrain B Overtakes Train A\nTrain Overtaking Another Train\nTrain and Tunnel\nTrains and Fractions\nTraveling by Train, then Car\nTravelling Trains\nTurning Word Problems into Algebra Equations\nTwo Trains with a Twist\nWhere would the Two Trains Meet?\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. Math \u00ae\n\u00a9 1994-2014 Drexel University. All rights reserved."}
{"text": "Retrieved from http://cs.stackexchange.com/questions/21405/proving-iff-statement-with-reductions\nText:\nTake the 2-minute tour \u00d7\n\nI have a statement I am trying to prove, and I'm very close, but I think I'm missing a couple of key concepts about regular and context-free languages.\n\nQuestion: Let $ A = \\{ ww \\ | \\ w \\ \\epsilon \\ \\Sigma^{*} \\} $.\n\nShow that any language $L$ is Turing-decidable if and only if $L$ is many-one reducible to $A$.\n\nWhere I am so far:\n\n  1. Language $A$ is not context-free, but the complement of $A$ is context-free.\n\n  2. Both $A$ and the complement of $A$ are decidable.\n\nSo, that means I can prove one direction of the iff statement fairly easily:\n\nIf $L$ is many-one reducible to $A$ then since $A$ is decidable from statement (2) above, also $L$ is decidable.\n\nThe other direction is giving me problems. This is all I have gleaned so far:\n\nIf $L$ is Turing-decidable, then $L$ is a regular language.\n\nIs there some relation between regular and context-free languages with respect to reductions that I am missing? Or should I be making a different logic jump in this part of the proof?\n\nshare|improve this question\nA very minor nit. Instead of \\epsilon in your question, use \\in to indicate set membership. \u2013\u00a0 Rick Decker Feb 7 at 3:44\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThere is a more general theorem which says that if $A$ is a decidable language and $B$ is a decidable language that is not trivial (in the sense that $B\\ne\\Sigma^*$ and $B\\ne\\emptyset\\, $), then $A\\le_m B$. Roughly speaking, this says that all non-trivial decidable languages are many-to-one reducible to each other, meaning that $\\le_m$ is too coarse a metric to distinguish between decidable languges.\n\nIn your problem, suppose that $L\\subseteq \\Gamma^*$ and define a mapping $f:\\Gamma^*\\rightarrow\\Sigma^*$ defined by: $$ f(x) = \\begin{cases} \\mathtt{aa} & \\text{if $x\\in L$}\\\\ \\mathtt{a} & \\text{if $x\\notin L$} \\end{cases} $$ for some $\\mathtt{a}\\in\\Sigma^*$. This is a total computable function (since by definition, we can use the computable decider program to determine $x$'s membership in $L\\, $) and it's easy to verify that $x\\in L$ iff $f(x)\\in A$, which is all you need to show $L\\le_m A$. As Yuval noted, you don't need any results about regular or context-free languages to answer this question.\n\nshare|improve this answer\n\nFirst of all, not every decidable language is regular. For example, $A$ is decidable but not regular.\n\nHere is a hint: this question doesn't have anything to do with either regular languages or context-free languages. While we certainly need $A$ to be decidable, for the other direction we only need some really simple properties of $A$. Try to think for which $A$ it is not true that if $L$ is decidable then $L$ can be many-one reduced to $A$.\n\nshare|improve this answer\nI'm confused, in the direction \"if L is decidable...\", there isn't any connection from L to A. How can A have any affect on whether or not L is decidable? \u2013\u00a0 Alex Chumbley Feb 7 at 1:30\nWhy should it have any effect? My question was for which languages $A$ the following statement holds: If $L$ is decidable then it is many-one reducible to $A$. (If, not iff!) \u2013\u00a0 Yuval Filmus Feb 7 at 1:38\nWell, L must be \"easier\" than A since it's L <= A, so A could be decidable or undecidable, really \u2013\u00a0 Alex Chumbley Feb 7 at 1:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/183267/does-sum-lnn-n3-converge/183269\nText:\nTake the 2-minute tour \u00d7\n\nBy Direct Comparison Test:\n\n$$\\ln(n)/n^3 < n/n^3 = 1/n^2 $$\n\nConverges as that is a convergent a p-series\n\nBy n'th term Test:\n\n$$(\\ln(n))' = 1/n$$\n\n$$(n^3)' = 3n^2$$\n\n$$\\lim_{n\\to\\infty} (1/n) / 3n^2 = \\lim_{n\\to\\infty} (3n^2)/n =\\lim_{n\\to\\infty} 3n = \\infty$$\n\nso by $n$'th term it diverges.\n\nWhat am I doing wrong?\n\nshare|improve this question\n$\\frac{a}{b}\\neq a*b$. \u2013\u00a0 rschwieb Aug 16 '12 at 16:23\n\n4 Answers 4\n\nup vote 5 down vote accepted\n\nYou made an algebraic mistake. You have the quotient $$ 1/n\\over 3n^2.$$ If you wish to \"move the numerator $1/n$ downstairs\", you need to take its reciprocal, ${1\\over 1/n}=n$, first and do it: $$ {\\color{maroon}{1/n}\\over 3n^2}={1\\over \\color{maroon}n\\cdot 3n^2}. $$ You did this correctly.\n\nHowever, when you \"moved the denominator $3n^2$ upstairs\", you failed to use its reciprocal $1/3n^2$. Done correctly, you would have obtained $$ {1/n\\over\\color{maroon}{ 3n^2}}={(1/n)\\cdot(\\color{maroon}{1/3n^2})\\over1 }. $$\n\nNote both methods give $1\\over 3n^3$ as a result; there is no need to do both. Perhaps the simplest thing to do in order to simplify your expression is to write $$ {1/n\\over 3n^2}={1\\over n}\\cdot{1\\over 3n^2}={1\\over n\\cdot3n^2}={1\\over 3n^3}. $$\n\nshare|improve this answer\n\nYou have a \"typo\". The terms do go to zero: $\\displaystyle \\lim_{n\\to \\infty}\\frac{(1/n)}{3n^2}=\\lim_{n\\to\\infty}\\frac{1}{3n^3}=0$.\n\nshare|improve this answer\n\nYou got the division wrong. $$(1/n)/3n^2 = 1/3n^3 \\rightarrow 0$$\n\nshare|improve this answer\n\nYou're nth term test is wrong. The reason why you're getting a divergent limit is because you flipped your fractions around inccorectlly. Anyways, the nth term test dosen't involve taking derivitives. But, here is how you can do it:\n\n$\\frac{ln(n)}{n^3}>0$ for sufficently large n (i.e n>3). Now, we have that $0<\\frac{ln(n)}{n^3}<\\frac{1}{n^2}$. Clearly, $\\frac{1}{n^2}\\rightarrow 0$. Hence, by the squeeze theorem for limits, $\\frac{ln(n)}{n^3}$ $\\rightarrow 0$. Also, always remember that the nth term test is not sufficent to prove convergance, it's just a nessacary condition. i.e the harmonic series.\n\nshare|improve this answer\nHe's taking derivatives in line with L'Hopital's rule. \u2013\u00a0 process91 Aug 16 '12 at 16:50\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/87565/poincare-inequality-for-the-annulus\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $A=A(r,1)=\\{x: r<||x||<1\\} \\subset R^n$ is an annulus.\n\nWhether is known the constant of Poincare inequality for A or some its estimation (w.r.t. $L^2$): the constant $C$ in the inequality $||f||_ {L^2(A)}\\le C ||\\nabla f||_{L^2(A)},$ where $ f\\in W^{1,2}_0(A) $\n\nshare|improve this question\nA quick look on Wikipedia tells me that the Poincare constant depends on the domain and on the exponent $p$ (when one is looking at the $L^p$ norm of the gradient). Are you interested in estimates of the Poincare constant for certain $p$ in particular, or just any $p$? (My guess is that the $p=2$ case would be easier than the others.) \u2013\u00a0 Yemon Choi Feb 5 '12 at 8:33\nYes, I have had in mind the case p=2! \u2013\u00a0 Marijan Feb 5 '12 at 9:12\n\n2 Answers 2\n\nThe constant $C^{-2}$, that is, the infimum of the Raleigh quotient $$\\min _ { f \\in W^{1,2} _0(A) } \\frac {\\int_A|\\nabla f|^2 dx}{ \\int_A|f|^2 dx } $$ is the first eigenvalue of the Laplacian on $A$ with Dirichlet boundary conditions. As a general fact, a positive solution of $-\\Delta f=\\lambda f$ with Dirichlet boundary conditions is necessarily the first eigenfunction. Here, this allow to find it just by solving the corresponding ODE, where radial simmetry is assumed. The subject is of course classic. However, I do not have access to MatSciNet in this moment, but I'm pretty sure that a search on \"first eigenvalue of the Laplacian on an annulus\" should give you useful results; you may also like to write and solve the ODE by yourself, and to compute the corresponding Raleigh quotient.\n\nshare|improve this answer\nThis is almost certainly solved in many physics textbooks, either in electromagnetism or maybe thermodynamics (steady heat flow). \u2013\u00a0 Deane Yang Feb 5 '12 at 12:18\nIndeed ... \u2013\u00a0 Pietro Majer Feb 5 '12 at 12:45\nProbably has to do with zero of Bessel function... \u2013\u00a0 Marijan Feb 5 '12 at 13:27\n@Deane Yang, I would be grateful if you give a reference \u2013\u00a0 Marijan Feb 5 '12 at 13:50\nThe relevant topic is \"separation of variables\". Try googling \"separation of variables eigenvalues laplacian annulus\". \u2013\u00a0 Deane Yang Feb 5 '12 at 19:16\n\nIf you apply Poincare Inequality on the ball $B\\supset A$, thus\n\n$|\\vert f-\\frac{1}{|B|}\\int_A f|\\vert_{L^2(B)}\\le C |\\vert\\nabla f|\\vert_{L^{2}(B)}$\n\nand as we know $f=0$ outside $A$, thus\n\n$||\\frac{1}{|B|}\\int f||\\le\\frac{|A|}{|B|}||f||=\\alpha ||f||$\n\nBy triangular inequality,\n\n$|\\vert f-\\frac{1}{|B|}\\int f|\\vert_{L^2}\\ge (1-\\alpha)||f||_{L^2}$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/74173/how-do-we-describe-standard-matrix-multiplication-using-tensor-products?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $V$ be a finite dimensional vector space over a field $F$. Consider the bilinear map $End(V) \\times End(V) \\rightarrow End(V)$ given by $(u,v) \\rightarrow u \\circ v$ and the map associated linear map of tensor productsw $m : End(V) \\otimes End(V) \\rightarrow End(V)$.\n\nI am interested in how we can identify an element of the tensor product $End(V)^* \\otimes End(V)^* \\otimes End(V)$ with the map $m$ which apperently is just another way to describe standard multiplication of matrices. In any case the question can be formulated as follows:\n\nHow do we identify $m$ with an element $u^* \\otimes v^* \\otimes w \\in End(V)^* \\otimes End(V)^* \\otimes End(V)$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI believe it will be a sum of tensors, not a simple tensor. Choosing a basis of $V$, there is an element $u^* = a_{ij}$ that takes a matrix $A$ and gives you its $i,j$th entry. Set $b_{ij} = a_{ij}$ to be a nicer name for $v^*$, and $e_{ij}$ to be the matrix unit with a 1 in the $i,j$th spot, and 0 elsewhere. Then the matrix multiplication element is: $$ \\mu = \\sum_{i=1}^n \\sum_{j=1}^n \\sum_{k=1}^n a_{ij} \\otimes b_{jk} \\otimes e_{ik}$$ In other words, it is just the formula for matrix multiplication with some tensor products instead of multiplication signs.\n\nshare|improve this answer\nadd comment\n\nDepending on taste, one might also have the \"motion\" go in the opposite direction: with $v\\otimes \\lambda$ an endomorphism given by $(v\\otimes \\lambda)(w)=\\lambda(w)\\cdot v$, for $v,w\\in V$ and $\\lambda\\in V^*$, the multiplication/composition of endomorphisms is $$ (v\\otimes \\lambda)\\circ (w\\otimes \\mu) \\;=\\; \\lambda(w)\\cdot v\\otimes \\mu $$ for $v,w\\in V$ and $\\lambda,\\mu\\in V^*$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/414023/probability-of-winning-the-game-1-2-3\nText:\nTake the 2-minute tour \u00d7\n\nOk, game is as follow, with spanish cards (you can do it with poker cards using the As as a 1)\n\nYou shuffle, put the deck face bottom, and start turning the cards one by one, saying a number each time you turn a card around ---> 1, 2, 3; 1, 2, 3; etc. If when you say 1 a 1 comes out, you lose, same with 2 and 3. If you finish the deck without losing, you win.\n\nI know some basics of probabilities, but is there a way to calculate the probability of winning the game, given a random shuffled deck?\n\nshare|improve this question\nCan you name any number $1 \\to 13$ while turning the cards? I.e. whats the range of the numbers you may name? \u2013\u00a0 JohnWO Jun 7 '13 at 17:28\nIs the player allowed to say 1, 2, or 3 at random or does he/she always have to follow the sequence 1,2,3,1,2,3,...? \u2013\u00a0 iX3 Jun 7 '13 at 17:52\nIf one wants something more general; If one could name any numerical value of a card in the deck, i.e.: If there are 52 cards in the deck, divided over 4 suits, which range from $1 \\to 13$, counting $\\text{Ace's}$ as $1$, you would have $13$ different choices. So the chances of loss are approx.: $\\frac{d}{r^2\\;s}$, where $d$ denotes the number of cards left in the deck, and $r$ denotes the numberical range of the cards in the deck, and $s$ denotes the number of suits. \u2013\u00a0 JohnWO Jun 7 '13 at 17:54\nMonte Carlo method shows the probability of $\\approx 0.008$, so the approximation with $\\left(\\frac 2 3\\right)^{12}$ is for this deck size already good enough. \u2013\u00a0 Harold Jun 7 '13 at 18:32\nYes, i am sorry, you can't say any number, you have to say JUST 1, 2, 3, 1, 2, 3, 1, 2, 3, repeat. \u2013\u00a0 Pphax Jun 7 '13 at 22:17\nadd comment\n\n3 Answers\n\nup vote 3 down vote accepted\n\nFor $i,j\\in\\{1,2,3\\}$, let $a_{i,j}$ denote the number of $i$ cards being dealt with number $j$ spoken. We have $\\sum_j a_{i,j}=4$ and for a winning game $a_{i,i}=0$. The number of winning positions for a given $(a_{i,j})$ is $$\\frac{18!}{a_{2,1}!a_{3,1}!(18-a_{2,1}-a_{3,1})!}\\cdot\\frac{17!}{a_{1,2}!a_{3,2}!(17-a_{1,2}-a_{3,2})!}\\cdot\\frac{17!}{a_{1,3}!a_{2,3}!(17-a_{1,3}-a_{2,3})!}. $$ We need to sum this over all $(a_{i,j})$ and divide by the total count $$ \\frac{52!}{4!4!4!40!}.$$ (Actually, we need just let $a_{1,2}, a_{2,3}, a_{3,1}$ run from $0$ to $4$ and this determines $a_{1,3}=4-a_{1,2}$ etc.) The final result is $$p=\\frac{58388462678560}{7151046448045500}=\\frac{24532967512}{3004641364725}\\approx 0.008165 $$ (I just noted that Harold has performed a Monte Carlo simulation with matching result)\n\nshare|improve this answer\nI did calculate the precise probability too, also using combinatorics, but this formula looks so terrifying for me :) I like the approximation explained by Byron Schmuland more. But it would be intresting to find some simplier way for a common case, it should defenitely exist. \u2013\u00a0 Harold Jun 7 '13 at 19:16\nadd comment\n\nAnother update:\n\nAs explained in the paper below, you can use rook polynomials to solve such problems. Playing with a full deck of 52 cards we will call \"one\" 18 times, we will call \"two\" 17 times, and we will call \"three\" 17 times. The forbidden positions in the 52 by 52 board consist of three \"independent\" complete rectangles; one $18\\times 4$ and the other two $17\\times 4$.\n\nThe rook polynomial for a full $m\\times n$ rectangle with $m\\geq n$ is $$\\sum_{k=0}^n{m\\choose k}\\, {n!\\over (n-k)!}\\, x^k. $$\n\nMultiply the polynomials for these three rectangles to give us the rook polynomial for our problem\n\nThe number of winning deck orders is $$\\int_0^\\infty x^N R(-1/x) \\exp(-x)\\,dx $$ so the probability is this divided by $N!$, i.e. $$\\mathbb{P}(\\text{win})= 24532967512/3004641364725= 0.008165023553.$$\n\n\nUpdate: The solution below is for a simplified version of the problem where you work with a deck of size 12: four each of ace, deuce, and trey.\n\nThis is a problem in generalized derangements and joriki's answer here tells you what to do. In general, the number of deck orders that lead to a win is $$\\int_0^\\infty L_{n_1}(x)\\cdots L_{n_r}(x)\\,\\mathrm e^{-x}\\mathrm dx.$$\n\nIn this problem, we have $r=3$ and $n_1=n_2=n_3=4$. The fourth Laguerre polynomial is $L_4(x)=(x^4-16x^3+72x^2-96x+24)/24$. Raising this to the third power and integrating against $\\exp(-x)$ gives $346$. That is, there are $346$ ways to order the deck that give a win.\n\nDivide this by the total number of orders $12!/(4!)^3$, to give $$\\mathbb{P}(\\text{win})=173/17325=0.00998.$$\n\nshare|improve this answer\nWhy does your answer differ significantly from Harold's Monte Carlo result? \u2013\u00a0 Hagen von Eitzen Jun 7 '13 at 19:05\nI am playing with a deck of size 12: four each of ace, deuce, trey. \u2013\u00a0 Byron Schmuland Jun 7 '13 at 19:07\nNow I'm playing with a full deck! \u2013\u00a0 Byron Schmuland Jun 7 '13 at 20:04\nThank you Byron, i chose Hagen's answer because he answered first, but yours is very clear too. \u2013\u00a0 Pphax Jun 7 '13 at 22:44\nadd comment\n\nThis is a hard question, if the player is using optimal strategy rather than just cycling through numbers.\n\nFor example, once the deck is down to 2 cards the player is guaranteed a win, because those two cards are known and (even if they're different) the player can name the third number. If the deck is down to 3 cards the player is guaranteed a win unless those last three cards are all different, in which case the player can't do better than guessing at random (2/3 chance) of winning.\n\nFull analysis for a deck of size 6: 2 each of $1,2,3$.\nCard 1: random, 1/3 chance of loss\nCard 2: guess whatever card 1 was, 1/5 chance of loss (if top two cards are the same)\nCard 3: guess either of the first two cards, 1/4 chance of loss\nWe now have two situations. If the first three cards are all different, there is a further 1/3 chance of loss, based on the analysis in the paragraph above, otherwise a win is assured. Each case happens half the time; two each of the four cards lead to the two cases.\n\nAltogether, the probability of loss is: $$\\frac{1}{3}+\\frac{2}{3}\\frac{1}{5} + \\frac{2}{3}\\frac{4}{5}\\frac{1}{4} + \\frac{2}{3}\\frac{4}{5}\\frac{3}{4}\\frac{1}{2}\\frac{1}{3}=\\frac{2}{3}$$\n\nThis seems too good to be true, but there it is.\n\nshare|improve this answer\nI may be misunderstanding, but I thought the player is required to call $1,2,3,1,2,3,1,\\ldots$ in that order with no scope for strategy. \u2013\u00a0 MJD Jun 7 '13 at 19:02\n@iX3 asked this question but received no answer. \u2013\u00a0 vadim123 Jun 7 '13 at 19:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/225972/bounds-for-the-size-of-a-circle-with-a-fixed-number-of-integer-points\nText:\nTake the 2-minute tour \u00d7\n\nI know that there are infinitely many rational points on the (unit) circle. I am interested in the following question:\n\nHow large has the radius of a circle to be, such that there are at least $n$ integer (lattice) points on it?\n\nActually, I am not interested in the precise number, but in some reasonable good upper bound $f(n)$. Something like, there is a circle of radius $\\leq f(n)$ that has least $n$ integer points.\n\nshare|improve this question\nThe radius must be at least about $\\sqrt{\\frac{n}{\\pi}}$. Also see: en.wikipedia.org/wiki/Gauss_circle_problem \u2013\u00a0 Dan Brumleve Oct 31 '12 at 10:13\n@DanBrumleve: Sorry, but my question was ambiguous. I meant integer points on the circle and not inside the circle. I made the question more precise. \u2013\u00a0 A.Schulz Oct 31 '12 at 10:26\nHere is a lousy bound. There are $4(e+1)$ representations of $5^e$ as a sum of two squares of integers. \u2013\u00a0 Andr\u00e9 Nicolas Oct 31 '12 at 11:10\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nEdit: In the following I suppose that the center of the circle is $(0,0)$ and this extent easily to the case where the center is a lattice point.\n\nIf the radius of a circle is $r$ and we have $n$ lattice points on it (of cource $4|n$) then $r^2 \\in \\mathbb{N}$ and $r^2$ can be written as sum of two squares in $n$ different ways (assuming of course that $(a,b) \\neq (-a,b)$ and $(a,b) \\neq (b,a)$ for $a \\neq b$).\n\nSo if you are asking if there is a function $f$ s.t. if $k \\leq f(n)$ then $k$ can be written as sum of two squares in at least $n$ different ways then according to this paper the answer is no.\n\nIn theorem 4.3 is shown that for a prime $p$ there at most $8$ different ways to write $p$ as a sum of two squares.\n\nHowever, there is a function $g$ s.t. for all $n \\in \\mathbb{N}, \\ g(n)$ can be written as sum of two squares in $n$ different ways, so if this is what you are asking the answer is yes. This is a consequence of Theorem 4.4.\n\nTheorem 4.4. says that if the prime numbers of the form $1 \\pmod4$ in $m$ appear with exponents $a_1,a_2,\\ldots , a_s$ and the prime numbers of the form $3 \\pmod4$ in $m$ appear with even exponents then $m$ can be written as sum of two squares in $4(a_1+1)(a_2+1)\\ldots(a_s+1)$ different ways.\n\nLets say that you want to find a circle with $4k$ lattice points. Then you can take the radius to be $5^{\\frac{k-1}{2}}$.\n\ne.g to find $8$ lattice points take the radius to be $\\sqrt{5}$. The lattice points are $(1,2),(1,-2),(-1,2),(-1,-2),(2,1),(2,-1),(-2,1),(-2,-1)$.\n\nThe best bound (assuming the circle is centered at zero) is the following:\n\nDenote the primes of the form $1 \\pmod 4$ as $p_1<p_2<\\ldots$. Lets say that you want to find the smallest $m$ s.t. the circle with radius $m$ has $4n$ lattice points. Factor $n$ as $n=4a_1a_2\\ldots a_s$ where $a_i$ are primes with $a_1\\leq a_2\\leq a_3 \\leq \\ldots \\leq a_s$. Then the smallest $m$ is given by $m^2=p_1^{a_s-1}p_2^{a_{s-1}-1}p_3^{a_{s-2}-1}\\ldots p_s^{a_1-1}$. This can be deduced from Theorem 4.4, the fact that for $a<b, \\ r_1,r_2 \\in \\mathbb{N}, \\ \\text{ with } a^2>b \\text{ and } r_1\\geq 2 \\Rightarrow a^{r_1r_2-1}>a^{r_1-1}b^{r_2-1}$ and the fact that $p_{i+1}<p_i^2, \\ \\forall i \\in \\mathbb{N}.$\n\nFor example the smallest radius $m$ witch give $48$ lattice points is $m=5\\cdot \\sqrt{13 \\cdot 17}$.\n\nshare|improve this answer\nI think you'll find that last circle has radius $\\sqrt5$. But in fact you can get it down to $\\sqrt5/\\sqrt2$ with center $(1/2,1/2)$. No one said the center had to be a lattice point. \u2013\u00a0 Gerry Myerson Oct 31 '12 at 12:01\nCorrect, thanks. I will edit. \u2013\u00a0 P.. Oct 31 '12 at 12:06\n@Pambos: Interesting! This is the bound that was mentioned by Andr\u00e9 Nicolas at the question's comment. Thanks for your longer answer. I am curious if one can find a better bound or if this is the best you can get. \u2013\u00a0 A.Schulz Oct 31 '12 at 13:23\nIn the same direction of @Andr\u00e9 Nicolas's bound, we can take the radius as the square root of the product of the first $m$ primes $\\equiv 1\\pmod{4}$, in order to have $4\\cdot 2^m$ integer points on a circle having a radius that grows like $m^m$. \u2013\u00a0 Jack D'Aurizio Oct 31 '12 at 14:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/73817/a-test-for-randomness-of-direction-of-vector-data/73821\nText:\nTake the 2-minute tour \u00d7\n\nI want to test the hypothesis that a group of vectors in 3D space, say given by a long list of xyz coordinates from some experiment, have no preferred direction. Is it sufficient to pick some direction in space, say the x-axis, and calculate the cosine angle between each data vector and this direction, and look at the mean cosine angle? Thanks, -nuun\n\nshare|improve this question\nI cannot imagine that is the right way to do it, but it has been decades since I had a statistics class. For this kind of very specific question, I think you will have a better experience at stats.stackexchange.com/questions although, for the moment, their site is not coming up. \u2013\u00a0 Will Jagy Aug 27 '11 at 4:17\nadd comment\n\n4 Answers\n\nI presume that by \"having no preferred direction\" you mean that the distribution on the sphere is uniform - as it has just been pointed out by Gerry. Testing uniformity on the sphere is a classical statistical problem. There is A LOT about it: you may have a look at the book \"Directional Statistics\" by Mardia and Jupp (especially Chapters 9 and 10), or, for instance, at these more recent papers by Pycke and Bakshaev.\n\nshare|improve this answer\nadd comment\n\nThere is a notion of uniform distribution on spheres, and a notion of discrepancy on a sphere (which is a numerical measure of the distance from uniform distribution). That should give you some search terms. One paper on the topic (probably more theoretical than you want, but it should have or at least point to the relevant definitions) is Martin Blumlinger, Slice discrepancy and irregularities of distribution on spheres, Mathematika 38 (1991) 105-116.\n\nshare|improve this answer\nadd comment\n\nHere is one approach to consider.\n\nTreating the data as points on the surface of the unit sphere, consider the collection of convex subsets on this surface that contain all of your observations. Then, define $S$ to be minimum area among such sets. One way to interpret the idea of \"having no preferred direction\" is that this set $S$ should be almost as big as the entire surface; conversely a preferred direction would manifest as the data being tightly concentrated in a small area on the sphere.\n\nThis is just a rough idea -- figuring out how to operationalize \"almost as big as the entire surface\" would depend on your statistical needs. Hope I haven't missed the mark too badly.\n\nshare|improve this answer\nThat's a decent idea, I think. But what if there are several preferred directions? \u2013\u00a0 Nuun Aug 27 '11 at 6:09\nYeah, in that case you'd need to cluster the observations in some way first, so the relevant area would be over disjoint convex covering regions. But the basic idea of comparing the containing area to the total possible area still stands I would think. There are surely lots of (different) ways to do (basically) what you want -- it all boils down to operationally defining \"preferred direction\". Good luck. \u2013\u00a0 R Hahn Aug 27 '11 at 6:33\nA set of pretty uniformly distributed points, and the same set with one point appearing a billion times, will get the same measure. Your test is valid, but it's power will be very low. \u2013\u00a0 Brendan McKay Oct 27 '12 at 7:44\n@Brendan, I guess as an applied statistician I'm usually happy to rule out the kind of degeneracy you mention, but your point is well taken. On a separate note, several years ago I used your nauty program when doing my masters degree on a branch-and-bound algorithm for the maximum independent set problem. So thanks for that! \u2013\u00a0 R Hahn Oct 27 '12 at 15:37\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/51793.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nThe Erdos-Mordell Theorem\n\nDate: 10/13/2000 at 14:33:11\nFrom: Rayna Zacks \nSubject: Related to Fermat Point in Triangle\n\nLet P be a point in a triangle. Let D be the sum of the distances from \nP to the 3 vertices, and let E be the sum of the shortest distances \nfrom P to the edges (trilinear coordinates of P). Prove that D > 2*E.\n\nI have beaten this to death using analytic geometry and calculus to \nfind the point P which minimizes D-2*E and then prove that D-2*E at P \nis greater than 0. I have used a number of different parameterizations \nof the triangle using 3 numbers (xy coordinates of one vertex and the \nlength of the opposite side, two angles and length of one side, length \nof all three sides) and expressed D and E in these terms, calculated \nthe partial derivative of (D-2*E) with respect to the parameters, etc. \nI continually end up with intractable expressions.\n\nI have tried all geometrical approaches that I know to construct the \nFermat point - but it's clear that point P above is not related to the \nFermat point. (I have a number of proofs now of the Fermat point \n\nI have solved special cases (e.g. if <A + <B > 90 deg. and <A < 15 \ndeg. then D-2*E > 0), and also proved it for an isosceles triangles \nwhere P is on the altitude, and for right triangles, and have found \nmany cases where point P is the vertex opposite the shortest side.\nBut I have not found a simple general proof that D > 2*E.\n\nIn xy coordinates the problem reduces to something like the following:\n\nProve H > 0 where\n     H =  cos(b) - 2*sin(B) - (X*cos(w) - Y*sin(w))\n\nand we know that at point P the two partial derivatives require that\n\n     1)  cos(a) - cos(b) + cos(c) = 2*(sin(B) - sin(C))\n     2)  sin(a) + sin(b) - sin(c) = 2*(1 - cos(B) - cos(C))  \n\nwhere A, B and C are the 3 angles of the triangle; a, b and c are the \n3 angles of the triangle with P as a vertex, and (X,Y) are the \ncoordinates of one of the vertices of the triangle. The symmetries of \nthe above are obvious, but I cannot get the last step.\n\nI am working with my father to solve a recent problem from the AMM \nproblem section and the first step is to prove D > 2*E. This is my \njob. My father says that he has seen a proof of D > *2E in a problem \nbook but he cannot find it. Neither can he prove D > 2*E.\n\n\nRayna Zacks\n\nDate: 10/13/2000 at 17:08:15\nFrom: Doctor Floor\nSubject: Re: Related to Fermat Point in Triangle\n\nDear Rayna,\n\nThanks for writing. This theorem is known as the Erdos-Mordell \ntheorem, but it should read D >= 2*E.\n\nLet's consider the following:\n\n\nWe have that D, E and F are the feet of the perpendicular altitudes \nfrom P to AB, BC and CA respectively, while E' and F' are the feet of \nthe perpendicular altitudes from E and F to AB.\n\nCFPE is a cyclic quadrilateral because the opposite angles are \nsupplementary. PC is its diameter. We also know that the radius of the \ncircumcircle of EFC is EF/(2*sin(C)), and thus the diameter is \nEF/sin(C). This means that EF = PC*sin(C). Since EF >= E'F' this gives \n\n     PC*sin(C) >= E'F'   ........................................[1]\n\nAlso, we have \n\n     F'E' = F'D + DE' \n          = PF*cos(90-A) + PE*cos(90-B)\n          = PF*sin(A) + PE*sin(B)         .......................[2]\n\nThe combination of [1] and [2] shows that\n\n     PC * sin(C) >= PF*sin(A) + PE*sin(B)\n\n                        sin(A)       sin(B)\n              PC >= PF* ----- + PE * ----- \n                        sin(C)       sin(C)\n\nIn the same way you find similar results for PA and PB. These three \nexpressions combine to:\n     PA+PB+PC >=\n\n         sin(A)  sin(B)       sin(B)  sin(C)       sin(A)  sin(C)\n     PD*(----- + -----) + PE*(----- + -----) + PF*(----- + -----)\n         sin(B)  sin(A)       sin(C)  sin(B)       sin(C)  sin(A)\n\n              >= 2*(PD + PE + PF)\n\nbecause x + 1/x >= 2.\n\nAnd we have proven the Erdos-Mordell theorem (from 1935). Good luck in \nsolving the AMM problem. If you have more questions, just write back.\n\nBest regards,\n- Doctor Floor, The Math Forum\nAssociated Topics:\nCollege Triangles and Other Polygons\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/108593/how-to-prove-that-the-normalizer-of-diagonal-matrices-in-gl-n-is-the-subgroup\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to prove that de normalizer $N(T)$ of the subgroup $T\\subset GL_n$ of diagonal matrices is the subgroup $P\\in GL_n$ of generalized permutation matrices. I guess my biggest problem is that I don't really know how diagonal and permutation matrices (don't) commute. Because it is not true that $DM=MD$ when $D\\in T$ and $M\\in P$ since the permutation is either horizontal or vertical, but sometimes it seems like you can do something like it.\n\nSo far, I have proved that $P\\subset N(T)$, in the following way. Let $M_\\sigma\\in P$. Then $M_\\sigma=VS_\\sigma$, with $V\\in T$ and $S_\\sigma$ a permutation matrix. So $M_\\sigma DM^{-1}=VS_\\sigma D S_\\sigma^T V^{-1}$. Thus if we prove that $S_\\sigma D S_\\sigma^T$ is diagonal we are done. This is true since $S_\\sigma D S_\\sigma^T=(x_1 e_{\\sigma(1)} \\dots x_n e_{\\sigma(n)}) (e_{\\sigma^{-1}(1)} \\dots e_{\\sigma^{-1}(n)})=(x_{\\sigma^{-1}(1)}e_1 \\dots x_{\\sigma^{-1}(n)}e_n)$, where $e_i$ are the standard basis vectors. Even this is hopelessly written out. I'm trying to find a way to see what the product $S_\\sigma D S_\\sigma^T$ is without writing it in vectors.\n\nFor the other way around I don't really know what to do. I'm having a hard time rewriting matrix products in a useful way. Perhaps there is a way of proving this using something completely different? Maybe you can prove it using $N(T)/T\\simeq S_n$, but this actually what I want to use my question for. When I just write what I know about a matrix $M\\in N(T)$ I just get a big system of equations that isn't really handy.\n\nshare|improve this question\nTry taking a matrix in $N(T)$, testing it on the diagonal matrices with zeros in all but one diagonal entry, and forcing it to be a generalized permutation matrix. Recall that the group $GL_{n}$ lives inside a ring of matrices (i.e. use addition and distributivity). \u2013\u00a0 Isaac Solomon Feb 12 '12 at 19:33\n@IsaacSolomon Thanks, but I don't really understand it. When I take $D_1$ for instance (with zeroes everwhere but $D_{1,1}$), and I look at $MD_1=SM$ for some diagonal matrix $S$, I can see that it follows that the first column only has one non-zero entry. But now how do I put that together. I can write $M(x_1D_1 + \\dots + x_nD_n)=SM$, but then I get confused. \u2013\u00a0 dropfruitduo Feb 12 '12 at 20:09\nadd comment\n\n4 Answers\n\nup vote 2 down vote accepted\n\nLet $S\\in N(T)$. Then $SDS^{-1}$ is diagonal for each diagonal matrix $D$. Now, conjugation preserves the spectrum, which is exactly the diagonal in the case of diagonal matrices. So the diagonal of $SDS^{-1}$ has to be the same as the diagonal of $D$ up to a permutation. From this it's not hard to setup the equations to see that $S$ has to have a unique nonzero entry per row and column, i.e. $S$ is a generalized permutation matrix.\n\nConcretely, let us write $\\{E_{kj}\\}$ for the set of canonical matrix units (i.e. $E_{kj}$ is the matrix with a $1$ in the $k,j$ position and zeroes elsewhere). Let $D=E_{11}+2E_{22}+\\cdots+n E_{nn}$ (i.e. a diagonal matrix with all different entries). From the first paragraph, we know that $SDS^{-1}$ is $W=\\sigma(1)E_{11}+\\cdots+\\sigma(n)E_{nn}$ for some permutation $\\sigma$. Since $SD=WS$, we get that $$ S_{kj}(j-\\sigma(k))=0. $$ For each $j\\ne\\sigma(k)$, we have $S_{kj}=0$; so the only nonzero entry in the $k^{\\rm th}$ row of $S$ is $S_{k,\\sigma(k)}$. In other words, each row of $S$ contains a single nonzero entry, so $S$ is a generalized permutation matrix.\n\nshare|improve this answer\nRight that makes sense! It's mostly the writing down the equation part I'm having trouble with. So can I say: $SDS^{-1}=W$ for some diagonal $W$ with the same diagonal as $D$ up to a permutation for every $D$, so also for one with all unique diagonal entries. Then when I calculate $SD$ and $WS$ I get equations $(x_j-x_{\\sigma(i)})s_{i,j}=0$ for all $i,j$. Then since $x_1-x_{\\sigma(i)}$ is only zero for one $i$, the rest of the $s_{i,1}$ must be zero, and so for all j? Or am I making it too complicated? \u2013\u00a0 dropfruitduo Feb 12 '12 at 20:59\nMostly yes, you need to play a little with the choices of different diagonals. I'll add it to the solution in a few minutes. \u2013\u00a0 Martin Argerami Feb 12 '12 at 23:45\nHow about those diagonal matrices with some identical diagonal entries? \u2013\u00a0 Eric Apr 27 '12 at 14:47\nWhat about them? \u2013\u00a0 Martin Argerami Apr 28 '12 at 11:44\nadd comment\n\nIf $P$ is the permutation matrix corresponding to permutation $\\pi$, i.e. $P_{i,\\pi(i)} = 1$ for each $i$, and $D$ is a diagonal matrix, then $(PDP^{-1})_{ij} = \\sum_k \\sum_\\ell P_{ik} D_{k\\ell} P^{-1}_{\\ell j}$. For a term to be nonzero, you need $k = \\pi(i)$, $k=\\ell$ and $\\ell = \\pi(j)$, so $\\ldots$\n\nshare|improve this answer\nadd comment\n\nLet $S \\in N(T)$. Now, $\\forall D \\in T$ we have $SDS^{-1} \\in T$. As noted, conjugation preserves the spectrum, and so $D$ and $SDS^{-1}$ have the same diagonal entries up to permutation. This allows us to write $SDS^{-1} = \\prod_kP_kDP_k'$, where $P_k, P_k' \\in P_{S_n} \\leq GL(n)$, the group of permutation matrices. This shows that $N(T) \\leq \\langle T , P_{S_n}\\rangle$. Finally, a simple calculation shows that $\\langle T , P_{S_n}\\rangle \\leq N(T)$.\n\nshare|improve this answer\nadd comment\n\nThe set of eigenvectors common to all elements of $T$ is that of the nonzero multiples of the standard basis vectors. Any element of $N(T)$ must permute these common basis vectors among each other (if $P\\in N(T)$ and $v$ is a common eigenvector of $T$, then so is $P\\cdot v$). This means all columns of $P$ must have a single nonzero entry, and of course these entries have to be in distinct rows as well. Hence $N(T)$ is contained in the set of generalised permutation matrices. The reverse inclusion follows from a simple computation to show that permutation matrices normalise $T$ (as of course do elements of $T$ itself). Or show this using the fact that $t\\in T$ whenever all standard basis vectors are eigenvectors of $t$ (nearly the converse of the property used at the beginning).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70300/algorithm-to-determine-a-discrete-function\nText:\nTake the 2-minute tour \u00d7\n\n\nI'm not quite sure what title to give to this question or what tags to use, because this isn't really my area of expertise and I'm unfamiliar with the terminology. It is a problem that came up while trying to write a program to enumerate some graphs, however there is no graph theory left in this problem.\n\nLet me first start by giving definitions for the different components. I have a set $C$ and two functions: $s:C\\rightarrow \\mathbb{N}$ and $r:C\\rightarrow \\mathbb{N}$. The values for these functions are completely known. It is also true that $\\forall c \\in C: r(c)=s(c) \\vee r(c)=\\frac{s(c)}{2}$. I don't know whether this will make a difference for the solution of my problem, but it might be relevant information.\n\nI am now interested in finding all possible functions $m:C\\rightarrow \\mathbb{N}$ that satisfy the following conditions:\n\n  \u2022 $\\sum_{c\\in C}\\frac{s(c)}{m(c)}=\\sum_{c \\in C}\\frac{s(c)}{4}$\n  \u2022 $\\forall c \\in C: r(c) \\mid m(c)$\n\nI really need an algorithm to find all possible solution, but of course I'm also interested in any theoretical results that could help me find such an algorithm. As I said, I'm not really at home in this type of problems, so I have no idea what to look for and where to start. The first conditions makes it impossible to have an infinite number of solutions, but in some cases I have some better upper bounds and lower bounds available for the value of the function $m$ in certain points. It would be nice if this could be taken into account, but I think it would not be the bottle-neck if I just filtered the solutions to take these bounds into account.\n\nAny help is greatly appreciated. And of course I will try my best to clarify anything in my explanation that isn't clear.\n\nEdit: Let me first say that $C$ will always be finite.\n\nA small example might also be more clarifying. Suppose we have $C=\\{1,2\\}$, the function $s:C\\rightarrow\\mathbb{N};c\\mapsto 2$ and the function $r:C\\rightarrow\\mathbb{N};c\\mapsto 1$.\n\nWe then have three possible solutions for $m$:\n\n  \u2022 $m(1)=3$, $m(2)=6$\n  \u2022 $m(1)=4$, $m(2)=4$\n  \u2022 $m(1)=6$, $m(2)=3$\nshare|improve this question\nIs $C$ a finite set? I.e., can one loop over all elements of $C$ in an algorithm? \u2013\u00a0 Jesko H\u00fcttenhain Jul 14 '11 at 8:35\nYes, $C$ is most definitely finite and in most cases really small (at least size 2 but only in rare cases larger than 30). I'll have a look at your answer, Thanks already for answering. \u2013\u00a0 nvcleemp Jul 14 '11 at 9:25\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nI will assume that $C$ is finite for my answer.\n\nLet $n,d:C\\to\\mathbb{N}$ such that $n\\equiv\\left.m/r\\right.$ and $r\\equiv\\left.s/d\\right.$. In other words, $\\mathrm{im}(d)\\subseteq\\{1,2\\}$. Let $C_1:=d^{-1}(1)$ and $C_2:=C\\setminus C_1 = d^{-1}(2)$. Now, we want to find a function $n$ such that\n\n$R := \\displaystyle \\sum_{c\\in C} \\frac{d(c)}{n(c)} = \\sum_{c\\in C} \\frac{s(c)\\cdot d(c)}{s(c)\\cdot n(c)} = \\sum_{c\\in C} \\frac{s(c)}{r(c)\\cdot n(c)}= \\sum_{c\\in C} \\frac{s(c)}{m(c)} = \\sum_{c\\in C} \\frac{s(c)}{4} =: S$\n\nClaim. This problem has a solution if and only if $2\\le S\\le|C_1|+2|C_2|$.\nProof. We consider $S\\in\\mathbb{Q}$ and perform induction on $r$, where $C=\\{c_1,\\ldots,c_r\\}$. In the case $r=1$, the statement is clear. Assume now that $S>|C_1|+2|C_2|$. Then, no matter how we choose $n(c_r)$, by induction we can not find a valid solution for $S'=S-d(c_r)/n(c_r)$ on $C'=\\{c_1,\\ldots,c_{r-1}\\}$.\n\nIn the case where $S\\le|C_1|+2|C_2|$ however, a solution can be calculated by setting $n\\equiv 1$, so $R=|C_1|+2|C_2|$. We then have to decrease $R$ until it achieves the desired value.\n\nFor $d=1,2$ we can decrease $R$ by $dr-1$ in the following way: Pick $\\{c_1,\\ldots,c_r\\}\\subseteq C_d$ and set $n(c_i):=dr$ for all $i$. The following python code\n\ndef n(c):\n    D = 2*c[2] + c[1] - c[0]\n    for d in (1,2):\n        j,r = 0,c[d]\n        ctr = c[d]\n        while r > 0 and D != 0:\n            if d*r-1 <= D:\n                D -= d*r-1\n                n[d-1][j:j+r] = [d*r]*r\n                j += r\n                ctr -= r\n                r = ctr\n                r -= 1\n    print n[0]+n[1]\n\nexpects input of the form $(S,|C_1|,|C_2|)$ and returns the function $n$, with my notation. In your example above, $S=1$, $|C_1|=0$ and $|C_2|=2$, the output is\n\n>>> n((1,0,2))\n[4, 4]\n\nwhich is the second of your solutions. I think this should work.\n\nshare|improve this answer\nI might be missing something obvious, but what exactly do you mean by $|S|$? It is not the absolute value of the rational number $S$, right? \u2013\u00a0 nvcleemp Jul 14 '11 at 9:50\nErr, those are really not supposed to be there. It should be just $S$, I will edit it. \u2013\u00a0 Jesko H\u00fcttenhain Jul 14 '11 at 11:53\nThen there seems to be a problem with the condition that $|C|\\leq S$. As can be seen in the example I added in my original question this is not a necessary condition. But it doesn't seem like you really need this. \u2013\u00a0 nvcleemp Jul 14 '11 at 12:22\nIndeed, let me fix that up. \u2013\u00a0 Jesko H\u00fcttenhain Jul 14 '11 at 13:56\nI was working under the assumption that $S\\in\\mathbb{N}\\setminus\\{1\\}$. You allow $S\\in\\mathbb{N}\\cup\\left\\{\\frac{1}{2},\\frac{1}{4}\\right\\}$, but these additional three special cases can be easily handled by multiplying $n$ with $2$, $4$ or $8$. \u2013\u00a0 Jesko H\u00fcttenhain Jul 16 '11 at 22:19\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/282069/is-finding-a-hamiltonian-cycle-as-hard-as-determining-if-one-exists/282092\nText:\nTake the 2-minute tour \u00d7\n\nIs finding a hamiltonian cycle as hard as determining if one exists? Can a hamiltonian cycle be found in polynomial time given an oracle for detecting hamiltonian cycles?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nAssume you have a method to detect whether or not a graph $G$ with $v$ vertices and $e$ edges has a Hamiltonian cycle in time $p(v,e)$ for some polynomial $p$. The following method then actually finds such a cycle:\n\nFor each edge: Remove the edge; check if the graph is still Hamiltonian; if not, add the edge back, otherwise leave it deleted. Once we have treated all edges, a cycle remains.\n\nThis makes $e$ tests of time $\\le p(v,e)$ each, hence the time is $\\le e\\cdot p(v,e)$ and still polynomial.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38624/determining-the-center-of-mass-of-a-cone?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm having some trouble with a simple classical mechanics problem, where I need to calculate the center of mass of a cone whose base radius is $a$ and height $h$..!\n\nI know the required equation. But, I think that I may be making a mistake either with my integral bounds or that $r$ at the last..! $$z_{cm} = \\frac{1}{M}\\int_0^h \\int_0^{2\\pi} \\int_0^{a(1-z/h)} r \\cdot r \\:dr d\\phi dz$$\n\n'Cause, once I work this out, I obtain $a \\over 2$ instead of $h \\over 4$...!\n\nCould someone help me?\n\nshare|improve this question\nHello there Coolcrab and please keep an eye on our Homework policy before asking about homework questions, 'cause they're discouraged here..! Sorry :) \u2013\u00a0 Waffle's Crazy Peanut Sep 29 '12 at 10:16\nThey are not homework, and I did do the sum just making a mistake somewhere. And asking for help with that.. \u2013\u00a0 Coolcrab Sep 29 '12 at 10:55\nWhat!? $a/2 := h/4$!? I don't think so... Increasing $a$ has no effect on $h$, this assertation is plane false. \u2013\u00a0 Killercam Sep 29 '12 at 11:14\nOfc its not, and thats my problem. It's either my bounds or the r should be a z. I'm not sure. \u2013\u00a0 Coolcrab Sep 29 '12 at 11:16\n@Killercam: Hi guys, I understood it. But, I just assumed that the center of mass would be somewhere along the axis of the cone...! Isn't that right? \u2013\u00a0 Waffle's Crazy Peanut Sep 29 '12 at 11:36\nshow 2 more comments\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI am not sure about this formula. Lets start by taking the vertex of the solid cone to be $O(0, 0, 0)$ in cylindrical coordinates ($r$, $\\theta$, $z$). Then take the height of the cone to be $h$ and the base of the cone to have radius $a$. In this case the we know that\n\n$r = \\frac{a}{h} z$.\n\nThe formula for the center of mass of this cone can be written as\n\n$Mz_{M} = \\int^{h}_{0} z \\mathrm{d}m$,\n\nwhere $M$ is the total mass of the (solid) cone and $z_{M}$ is the location of the center of mass. We can write $\\mathrm{d}m$ as\n\n$\\mathrm{d}m = \\pi \\rho \\frac{a^{2}}{h^{2}}z^{2}\\mathrm{d}z$,\n\nwhere we have considered $\\mathrm{d}m$ to be the mass of a thin disk at height $z$ and of radius $r$, with thickenss $\\mathrm{d}z$. Now we can write the full equation for the center of mass as\n\n$Mz_{M} = \\pi\\rho\\int^{h}_{0}\\frac{a^{2}}{h^{2}}z^{3}\\mathrm{d}z$,\n\nthis becomes\n\n$Mz_{M} = \\rho Vz_{M} = \\frac{1}{4}\\pi\\rho a^{2}h^{2}$.\n\nWe know that the volume of a cone $V = \\frac{1}{3}\\pi a^{2} h$, so we find\n\n$z_{M} \\rho \\frac{1}{3}\\pi a^{2} h = \\frac{1}{4}\\pi\\rho a^{2}h^{2}$,\n\n\n$z_{M} = \\frac{3}{4} h$.\n\nWhich is the distance from the vertex of the cone.\n\nI hope this helps.\n\nshare|improve this answer\nadd comment\n\nI see the problem you have here, change the r*r drd\u03d5dz there to z*r drd\u03d5dz, then you should get the correct answer\n\nshare|improve this answer\nHi Mengyu, welcome to Physics.SE. Can you please use MathJax with dollar signs and markup to make your answer more readable? See meta.math.stackexchange.com/questions/5020/\u2026 \u2013\u00a0 Brandon Enright Feb 20 at 18:37\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/311043/determining-complex-differentiability-using-cauchy-riemann-equations\nText:\nTake the 2-minute tour \u00d7\n\nI need to find where $f(x+iy)=-6(\\cos x+i\\sin x)+(2-2i)y^3+15(y^2+2y)$ is complex differentiable.\n\nI first rearranged the function into its real and imaginary parts: $f(x+iy)=(-6\\cos x+2y^3+15y^2+30y)+i(-6\\sin x-6y^2)$\n\nThat means $u(x,y)=-6\\cos x+2y^3+15y^2+30y$ and $v(x,y)=-6\\sin x-6y^3$.\n\nThen, if we take the partial derivative of u and v in terms of x and y:\n\n$u_x=6\\sin x$\n\n\n$v_x=-6\\cos x$\n\n\nThen, by the Cauchy-Riemann equations, $u_x=v_y$ and $u_y=-v_x$.\n\nThis means that: $6\\sin x=-18y^2$ and $6y^2+30y+30=6\\cos x$.\n\nThis is where I am stuck. How do I solve for x and y? I was thinking that I could proceed in this way:\n\n$\\sin^2 x + \\cos^2 x=1 \\Rightarrow (-3y^2)^2+(y^2+5y+5)^2=1 \\Rightarrow 10y^4+10y^3+35y^2+50y+24=0$\n\nHowever, from here, how do I solve for y and then solve for x? I'd appreciate any tips. Thanks for your help in advance!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nYou can see from wolfram alpha that the solutions for the pair of equations never overlap.\n\nBut using your chain of logic: $10y^4+10y^3+35y^2+50y+24=0$ has no real solutions. Therefore the function is complex-differentiable nowhere.\n\nshare|improve this answer\nadd comment\n\nWe can simplify these equations into $$ \\sin{x} = -3 y^2, \\quad y^2 + 5y + 5 = \\cos{x} $$ Now, $x$ and $y$ are real, so the only way that the first equation can be satisfied is if $y \\in [-1/\\sqrt{3}, 1/\\sqrt{3}]$, since otherwise $-3y^2$ will not be in the range of sine.\n\nNow we turn to the second equation. The graph of $y^2 + 5y + 5$ achieves its minimum at $y = -5/2$; therefore it is monotone on the interval $[-1/\\sqrt{3}, 1/\\sqrt{3}]$. So we can simply check the endpoints to verify that $y^2 + 5y + 5 > 1$ when $y \\in [-1/\\sqrt{3}, 1/\\sqrt{3}]$, and hence it can never equal $\\cos{x}$ if the first equation is satisfied.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/134011/scalar-product-of-gaussian-process/134048\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $n(t)$ is a White Gaussian Noise (WGN) process with $E[n(t)]=0$, $E[n(t)^2]=\\sigma^2$ and $x(t)$ a deterministic function defined in $[0,T]$. How can I compute from first principles the variance of $g(T)$ defined as\n\n\nAny references to elementary textbooks on stochastic processes are also welcome.\n\nshare|improve this question\nis the e(t) in the definition of g(T) the n(t) you introduced before? \u2013\u00a0 tibL Apr 19 '12 at 17:20\nYou need the autocorrelation function of the process, not just the variance. \u2013\u00a0 Dilip Sarwate Apr 19 '12 at 17:25\nYes, the noise is white and e(t)=n(t). The text is now correct. \u2013\u00a0 Arrigo Benedetti Apr 19 '12 at 21:57\nIf the autocorrelation function is $$E[n(t)n(s)] = R_n(t-s)=\\begin{cases}\\sigma^2,&t=s,\\\\0,&t\\neq s,\\end{cases}$$ then the integral expression in Nate Eldredge's answer gives $\\operatorname{var}(g(T))=0$. If the autocorrelation function is $\\sigma^2\\delta(t-s)$ (note the difference) then see my comment on that answer as well as this question. \u2013\u00a0 Dilip Sarwate Apr 20 '12 at 11:06\nadd comment\n\n1 Answer\n\nAssuming that $e(t)$ is supposed to be $n(t)$ and that you know the covariances $E[n(s) n(t)]$, then note that $$g(T)^2 = \\int_0^T \\int_0^T x(s) x(t) n(s) n(t)\\,ds\\,dt$$ and so by Fubini's theorem $$E[g(T)^2] = \\int_0^T \\int_0^T x(s) x(t) E[n(s) n(t)]\\,ds\\,dt.$$\n\nshare|improve this answer\n@ArrigoBenedetti This calculation occurs in engineering applications very often where $n(t)$ is assumed to be a white Gaussian noise process with autocorrelation function $\\sigma^2\\delta(t-s)$ and so $E[g(T)] = 0$ while the variance becomes $$\\text{var}(g(T)=\\sigma^2\\int_0^T x^2(t) \\mathrm dt.$$ See for example Appendix A of this document. \u2013\u00a0 Dilip Sarwate Apr 19 '12 at 19:11\nThese heuristics are nice, but it may be important to mention that they're not too much more than this. In particular, the integrals, as shown, don't exist. \u2013\u00a0 cardinal Apr 20 '12 at 4:20\n@cardinal Would you please comment on or respond to this question of mine on this issue? Thanks. \u2013\u00a0 Dilip Sarwate Apr 20 '12 at 11:10\nThe application of Fubini's theorem is illegal here, as mentioned by @cardinal. \u2013\u00a0 Did Jan 15 '13 at 6:55\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/260182/solving-an-equation-with-an-integral/260190\nText:\nTake the 2-minute tour \u00d7\n\nI need to solve the following equation for $v(x)$: $$\\int_0^tv(x)(x+1)dx=f(t)$$ I am given the function $f(t)$. I've done this so far:\n\nIf we derive both sides by $t$, we get $v(t)(t+1)=f'(t)$ and $\\bar{v}(t)=\\frac{f'(t)}{t+1}$. The problem is that I am still off by a constant, i.e., the above only guarantees that : $\\int_0^t\\bar{v}(x)(x+1)dx+c=f(t)$ which is not enough for me.\n\nshare|improve this question\nHint: consider taking the Fourier or Laplace transform from both sides, solve algebraic equation and making the inverse transform. \u2013\u00a0 m0nhawk Dec 16 '12 at 19:38\n@monhawk: how should that help? \u2013\u00a0 Fabian Dec 16 '12 at 19:38\nIf your $f(0)=0$, then $c\\equiv0$ for any $\\nu(x)$. Isn't it? \u2013\u00a0 0x2207 Dec 16 '12 at 19:38\n@0x2207: yes, the constant is in fact $f(0)$. \u2013\u00a0 Fabian Dec 16 '12 at 19:39\n@Fabian, from definition $\\int_{0}^{0} g(x) dx \\equiv 0$ \u2013\u00a0 0x2207 Dec 16 '12 at 19:40\nshow 7 more comments\n\n2 Answers\n\nup vote 2 down vote accepted\n\nIt is easy to see that the constant $c$ in your post is in fact $f(0)$. Furthermore, a little thought shows that your equations cannot be solved unless $f(0)=0$ (just plug in $t=0$ in your equation and you find $0=f(0)$).\n\nshare|improve this answer\nadd comment\n\nI don't see what is the problem here. Obsviously $f(0)=0$ (for the equation to have a solution) and by deriving as you said, we get $$v(t)=\\frac{f^{\\prime}(t)}{t+1}$$ If we substitue this back in the orginal equation we have $$f(t)=\\int_{0}^{t}f^{\\prime}(x)dx=f(t)-f(0)=f(t)$$ which is true\n\nshare|improve this answer\nThe problem is the given $f(0)\\neq 0$. \u2013\u00a0 Hasanhasan Hasan Dec 16 '12 at 20:27\nThen the problem has no solutions \u2013\u00a0 Nameless Dec 16 '12 at 20:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/36609/what-is-the-nature-of-this-sequence?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\n$3, 4, 10, 33, 136$\n\nwhat will be next most appropriate value? I tried finding any relation in the sequence but i couldn't.\n\n$a.276 $\n\n$b.539 $\n\n$c.612 $\n\n\nshare|improve this question\nIs this just a puzzle or do you have some context you can provide? \u2013\u00a0 Aryabhata May 3 '11 at 6:15\nI have got options with me. $a.276$ $b.539$ $c.612$ $d.685$ \u2013\u00a0 amul28 May 3 '11 at 6:18\nOne option is $685$. $3, 3*1+1 = 4, 4*2 + 2 = 10, 10*3+3 = 33, 33*4+4 = 136, 136*5 + 5 = 685$... But such questions are nonsense as Qwirk's answer shows. I am voting to close a NARQ. \u2013\u00a0 Aryabhata May 3 '11 at 6:21\n@amul: I really don't know. There is no systematic method. Really, such questions are nonsense and solving this one likely won't help you solve other nonsense questions like this. It is unfortunate, but you have to guess what the idiot who wrote the question on the entrance test was thinking of... \u2013\u00a0 Aryabhata May 3 '11 at 6:41\nI agree that questions like this can be frustrating, especially when multiple answers might fit, but I don't agree that they're completely worthless. I think the ability to look at arbitrary data, see patterns, find possible relationships, and then identify the most likely relationship is a critical skill for a mathematician to have. The question isn't \"what was the exam writer thinking when he wrote this?\", it's \"what's the simplest relationship you can find between these numbers?\" \u2013\u00a0 Kevin May 3 '11 at 15:15\nshow 10 more comments\n\n2 Answers\n\nup vote 7 down vote accepted\n\nI agree with all the complaints about this sort of problem, but still.... There are some techniques which work from time to time.\n\nTry taking differences: $4-3=1$, $10-4=6$, $33-10=23$, $136-33=103$, so now we have to explain the sequence $1,6,23,103,\\dots$. Hmm, that doesn't seem very helpful.\n\nOK, subtraction didn't work, try division: $4\\div3=1r1$, $10\\div4=2r2$, $33\\div10=3r3$, $136\\div33=4r4$ - hey, that looks much better! (When I write $arb$, I mean quotient $a$, remainder $b$.)\n\nshare|improve this answer\nseems very clear for me. \u2013\u00a0 amul28 May 3 '11 at 7:09\nWow! I never knew division could be applied. I always used subtraction. +1 for arb notation. Its really helpful. \u2013\u00a0 Shiplu Dec 21 '11 at 7:44\nadd comment\n\nI must say, I have always disliked 'find the next term in the series question'. For any sequence, it is easy to produce any number next (e.g. for a sequence of $n$ terms, pick the $n+1$ number and then fit a polynomial to those $n+1$ terms).\n\nOEIS does not give anything useful for your sequence - how has it arisen?\n\nEdit: For this question, as Moron has shown, the likely answer is 685, based on the sequence $3,3\\times 1 + 1 = 4, 4 \\times 2 + 2 = 10, 10 \\times 3 + 3 = 33, 33 \\times 4 + 4 = 136,$$136 \\times 5 + 5 = 685$ . But in general knowing how to find the pattern in this sequence, will not help (much) in finding patterns in similar sequences.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/17440/on-the-continuation-of-a-polynomial\nText:\nTake the 2-minute tour \u00d7\n\nThis exrcise is from the first section of Marden:\n\nExercise 12. Let the interior of a piecewise regular curve $C$ contain the origin $\\cal O$ and be star-shaped with respect to $\\cal O$. If the complex numbers $a_1, a_2, \\ldots, a_m$ are given, then $n$ and $b_{m+1}, b_{m+2}, \\ldots, b_n$ may be determined so that all of the zeros of\n\n$F(z) = 1 + a_1 z + \\cdots + a_m z^m + b_{m+1} z^{m+1} + \\cdots + b_n z^n$\n\nlie on $C$.\n\nHint: Choose the zeros $\\zeta_j$ of $G(z) = z^n F(1/z)$ so that $z_j = 1/\\zeta_j$ are points of $C$ and so that the Newton-Girard formulas\n\n$s_k + s_{k-1} a_1 + \\cdots + k a_k = 0$\n\nare satisfied by the sums $s_r$ of the $r^{\\text{th}}$ powers of the $\\zeta_j$.\n\nI understand how the requirements of the hint will imply the result, but I do not know how to establish them. Indeed, if we can satisfy those requirements, then the remaining $b_j$ will be determined by the further Newton-Girard formulas.\n\nThis is a generalization of the previous problem in the book:\n\nExercise 11: If $F(z) = 1 + a_1 z + b_2 z^2 + \\cdots + b_n z^n$, the quantities $n, b_2, \\ldots, b_n$ may be so determined so that all the zeros of F lie on the unit circle.\n\nThe solution to this is simpler: we choose $n > -a_1$ and values $\\zeta_1, \\ldots, \\zeta_n$ on the unit circle with centroid $-a_1/n$. Vi\u00e8te's formulas tell us that these are the zeros of a polynomial $z^n + a_1 z^{n-1} + b_2 z^{n-2} + \\cdots + b_n = z^n F(1/z)$, so that $1/\\zeta_j$ are the zeros of $F(z)$ and lie on the unit circle.\n\nMy problem with Exercise 12 lies in ensuring the Newton-Girard formulas are satisfied; it is not as simple as choosing a centroid, and I can't see a way to do it even for the case when $C$ is the unit circle. How do I know that a solution exists here? Can I extend this to the general case, or is a separate argument needed?\n\nAlso, how do I center formulas?\n\nEdit: I forgot to mention that Marden gives some citations of this result:\n\nGavrilov, L., On the continuation of polynomials\nGavrilov, L., On the K-extension of polynomials\nCebotarev, N. G., \u00dcber die Fortsetzbarkeit von Polynomen auf geschlassene Kurven\nCebotarev, N. G., On Hurwitz's problem for transcendental functions\n\nUnfortunately I read neither Russian nor German and I can't seem to locate the last one, so these aren't of direct help to me.\n\nshare|improve this question\nI guess none of the coefficients can be zero then from Cauchy's Theorem. \u2013\u00a0 PEV Jan 14 '11 at 1:42\n@Trevor: I don't follow. Which theorem of Cauchy? \u2013\u00a0 Antonio Vargas Jan 14 '11 at 15:05\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/80400/deformation-of-line-bundles-over-dual-numbers/80410\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a scheme over a field $k$ and $L$ be an invertible sheaf on it. Let $D$ be the scheme over dual numbers over $k$ with parameter $t$, i.e. $Spec(k[t]/(t^2)$.\n\nLet $X':=X \\times_k D$ and $i:X \\rightarrow X\\times D$ the natural map.\n\nOne defines a first order deformation of $L$ over $D$ as a line bundle $L'$ on $X'$, such that $i^*L'$ is isomorphic to $L$.\n\nOne knows that the iso classes of deformations of $L$ correspond to $Ext^1_{\\mathcal O_X}(\\mathcal O_X, \\mathcal O_X)$.\n\nOne map is clear, I think: if you have a deformation $L'$, then consider the exact sequence on $D$:\n\n$0 \\rightarrow k \\rightarrow \\mathcal O_D \\rightarrow k \\rightarrow 0$, pull it back to $X'=X\\times_k D$, tensor with $L'$ and push down to $X$. Please correct me if this is not the right way.\n\nBut how do I get explicitly a deformation in the sense of the above definition out of an exact sequence on $X$\n\n$0\\rightarrow L \\rightarrow M \\rightarrow L \\rightarrow 0$?\n\nIn the books I read there are only hints I really don't understand, so I would be very glad about an answer which carefully constructs the deformation data out of this sequence.\n\nshare|improve this question\nA short exact sequence $0 \\to L \\to M \\to L \\to 0$ enables you to give $M$ the structure of a module over $X'$. You just need to be able to say how $\\epsilon$ acts on $M$. Composing the projection $M \\to L$ with the inclusion $L \\to M$ tells you how $\\epsilon$ acts. \u2013\u00a0 Mike Skirvin Nov 8 '11 at 16:28\nWell, exactly this is what appears in the books and what I don't fully understand, even not in terms of modules. Above all, why is $i^*L'$ isomorphic to $L$? \u2013\u00a0 Veen Nov 8 '11 at 17:12\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nOne important point is that $X$ and $X'$ have the same topological space, since $i:X'\\rightarrow X$ is a nilpotent immersion. In particular $M$ is already a sheaf on $|X|=|X'|$ (of $\\mathcal{O}_X$-modules). Since $\\mathcal{O}_{X'}=\\mathcal{O}_X\\oplus \\mathcal{O}_X[\\varepsilon]$, to give $M$ the structure of a sheaf of $\\mathcal{O}_{X'}$-modules you only need to define the action of $\\varepsilon$, as Mike Skirvin points out in his comment.\n\nSo you define multiplication by $\\varepsilon$ by the composition $M\\stackrel{g}{\\to} L\\stackrel{f}{\\to} M$ of the two maps given by the extension (notice that this is $\\mathcal{O}_X$-linear, and its square is zero). This makes $M$ a sheaf of $\\mathcal{O}_{X'}$-modules, and moreover using the local criterion of flatness you can check that it is flat over the base $D$.\n\nNow since $|X|=|X'|$ and $\\mathcal{O}_X=\\mathcal{O}_{X'}/(\\varepsilon\\cdot\\mathcal{O}_{X'})$, you have $i^*(M)=M\\otimes_{\\mathcal{O}_X'}\\mathcal{O}_X=M/(\\varepsilon \\cdot M)=M/f(L)=L$, since by definition of the action of $\\varepsilon$, $\\varepsilon \\cdot M=f(L)$.\n\nshare|improve this answer\n@Mattia: is this $M$ with the $\\mathcal O_{X'}$-structure you defined a line bundle on $X'$? It should be given the above definition of deformation. \u2013\u00a0 Veen Nov 8 '11 at 18:09\nI think so, if say $X$ is loc noetherian. Take an open affine $U=Spec A \\subseteq X$ (so the corresponding open of $X'$ is the spectrum of $A'=A[\\varepsilon]$) and apply the local criterion of flatness for the nilpotent ideal $(\\varepsilon)\\subseteq A[\\varepsilon]$ to the restriction of $M$ to $U$, call $N$ the corresponding $A'$-module. Namely, since $N/(\\varepsilon N)$ is flat over $A$ (loc free even) and $Tor_1^{A'}(N,A)=0$ (check that $\\cdot \\varepsilon: A\\to A'$ stays injective after tensoring with $N$), then $N$ is flat over $A'$, so it is locally free. (maybe there's an easier way..) \u2013\u00a0 Mattia Talpo Nov 8 '11 at 20:27\nWell, but one needs locally free of rank one as one wants it to be a line bundle on $X'$. But I think it really is, due to local splittings of the sequence $0\\rightarrow L \\rightarrow M \\rightarrow L \\rightarrow 0$ ($L$ is locally just the structure sheaf and so you get a retraction). Does this sound reasonable? \u2013\u00a0 Veen Nov 9 '11 at 12:35\nOnce you know that it is locally free, it must be of rank one, since its pullback to $X$ is.. \u2013\u00a0 Mattia Talpo Nov 9 '11 at 13:00\nYou helped me a lot, Mattia. Thanks. \u2013\u00a0 Veen Nov 10 '11 at 9:11\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/325208/the-boundary-of-a-region-for-complex-valued-functions\nText:\nTake the 2-minute tour \u00d7\n\nFrom Chapter $3$ of Stein and Shakarchi's complex analysis book, we have the following problem ($15$):\n\nShow that if $f$ is holomorphic in the unit disc (open), bounded, and converges uniformly to zero in the sector $\\theta<\\arg z<\\varphi$ as $|z|\\to1$, then $f=0$.\n\nWe're supposed to use either the Cauchy inequalities or maximum modulus principle (per the instructions at the beginning, since this is a $4$-part problem), but I don't quite see how to do it using either of those, though the structure of the problem seems to lend itself to the maximum modulus principle. The problem with this is that we know that in the interior of the sector, the function cannot attain a maximum modulus, however, we don't know anything about the boundary of the sector that is in the interior of the circle. This is one obstacle I couldn't quite overcome.\n\nMy approach was to extend the function past the boundary of the circle, which we can do since $f$ is bounded (I think, though even this part is a little bit 'hand-wavy'), and then, since it has a cluster of zeros, the function will be identically zero.\n\nHow should I approach the problem with the intention of using the maximum modulus principle or Cauchy inequalities? Any suggestions would be appreciated. Thanks!\n\nEDIT: I've been thinking about this problem, and I've come up with the following solution:\n\nLet $f$ be an analytic function on $\\mathbb{D}$ (take note that I'm not assuming $f$ is bounded), with the property that for $\\theta<\\arg z<\\varphi$, $|f(z)|$ converges to zero uniformly as $|z|\\to1$ in this sector. Then we can make a 'bump' on the disc in this sector so that it extends in this outside of $\\mathbb{D}$, call this set $\\Omega'$. Define $$g(z)=\\begin{cases}f(z)&:\\,z\\in\\Bbb D\\\\0 &:z\\notin\\Bbb D\\end{cases}.$$ Now, clearly in $\\Bbb D$ $g(z)$ is holomorphic and outside of $\\Bbb D$, it's holomorphic as it's constant, so the only questionable part would be on the boundary of the disc in this sector. At this point, we can take a small disc around each point entirely contained in $\\Omega'$, since it's open, and apply Morera's theorem to show that $g(z)$ is holomorphic here. Therefore, on all of $\\Omega'$, $g$ is holomorphic and has a cluster of zeros, hence is identically equal to zero, therefore $f(z)=0$.\n\nIs this proof correct? Or did I miss something and there is a counterexample when $f$ is not bounded? If it is correct, it's nice in that the proof didn't rely on the shape of the region at all, only on the fact that there was a nondegenerate connected subset of the boundary with the property. Therefore, we see the exercise as a very special case of the generalized problem.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nA particular case that should help you think of a solution is when the sector is of the form $0\\leq \\text{arg}z \\leq \\pi$. In this case consider $g(z)=f(z)f(-z)$. Since $f$ is bounded, $g$ admits a continuous extension to the boundary of the circle that is $0$ on said boundary. The maximum modulus principle gives the result.\n\nshare|improve this answer\nYour argument may be fixed, but note that it's not true that any bounded analytic function admits a continuous extension to the boundary. (The assumption on $f$ in the statement of the problem is important.) \u2013\u00a0 mrf Mar 9 '13 at 16:33\n@mrf: That's why I said that $g$, not $f$, admits a continous extension (the boundedness of $f$ is used to ensure that $g$ tends to zero at the boundary, not as automatic extension). \u2013\u00a0 Jose27 Mar 9 '13 at 18:33\n@Jose27: I've updated an argument of my own; would you take a look and let me know your thoughts? \u2013\u00a0 Clayton Mar 12 '13 at 2:01\n@mrf: I've added an argument of my own; would you take a look and let me know your thoughts? Thanks! \u2013\u00a0 Clayton Mar 12 '13 at 2:01\nHow do you generalize this to arbitrary $\\theta,\\varphi$? I don't quite see it. \u2013\u00a0 Clayton Mar 12 '13 at 12:15\n\nFirst of all, I think you should upvote (if you haven't already) and accept Jos\u00e9's answer, which seems like the canonical answer.\n\nTo address the follow up questions and remarks:\n\nI think your argument is correct, but it took me a little while to see why the integral of $g$ over a curve that crosses $\\partial\\mathbb{D}$ should be zero. You should provide some more details here.\n\nThe result is certainly true without assuming that $f$ is bounded. Here is another way to see this: Instead of bumping $\\partial\\mathbb{D}$ outward, we can create an inward bump. More precisely, let $U$ be an open subset of $\\mathbb{D}$ whose closure contains a (non-empty) arc on which $f$ extends to $0$. By shrinking $U$ a little, we can assume that $f$ is bounded on $U$, that $U$ is simply connected and that the boundary of $U$ is reasonably smooth. Map $U$ biholomorphically onto the unit disc (Carath\u00e9odory's theorem assures that the Riemann map extends continuously up to the boundary, so the arc maps onto another non-empty arc). This construction reduces the problem the the case where $f$ is bounded, and we can apply Jos\u00e9's solution and pull it back. Hence $f = 0$ on an open set, and by the identity theorem, $f = 0$ everywhere.\n\nshare|improve this answer\nI've upvoted Jose's answer. I understand about half of your answer, though. It sounds legitimate, but I'm unfamiliar with what it means to map something biholomorphically, conformal mappings for Caratheodory's theorem, Riemann maps, etcetera. When I get time, I'll read into these topics as much as I can and inform myself about your answer. \u2013\u00a0 Clayton Mar 12 '13 at 13:40\n@Clayton Ok, I thought you were aware of Riemann's mapping theorem. \u2013\u00a0 mrf Mar 12 '13 at 13:56\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/105573/method-of-false-position\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to use the Method of false position on the functions below to find solutions to within $10^{-5}$\n\n(1) $f(x) = \\ln (x-1) + \\cos(x-1) = 0$, for $1.3 \\leq x \\leq2$\n\n\n(2) $2x \\cos(2x) -(x-2)^2 = 0$, for $[2,3]$ and $[3,4]$\n\nI am trying to do this without using a computer program, and am stuck. Thanks\n\nshare|improve this question\nConcerning function 1, what are you asking here different from this question of yours? \u2013\u00a0 Am\u00e9rico Tavares Feb 4 '12 at 18:23\nThey are using different methods \u2013\u00a0 James R. Feb 6 '12 at 10:21\nThank you! I had wrongly thought it was the same method, just different names. \u2013\u00a0 Am\u00e9rico Tavares Feb 6 '12 at 12:48\n\n1 Answer 1\n\nup vote 1 down vote accepted\n  1. Evaluate $f(1.3)$ and $f(2)$. (You will want to use a calculator.)\n  2. Now, given just these two points, suppose $f$ is like a straight line through these two points. Where (i.e. for what $x$) would $f(x)=0$? (The $x$ you find this way, by pretending $f$ is a straight line inside the interval, is the false position.)\n  3. Evaluate $f(x)$ for this $x$ (using the correct $f$ again now).\n  4. You now have a smaller interval (either $[1.3,x]$ or $[x,2]$ -- whichever one contains a sign change for $f$) which you know contains the solution to $f(x)=0$.\n  5. Go back to step 1, but now use your smaller interval instead of $[1.3,2]$.\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/151885/zeroing-out-lower-order-terms-in-generating-function/151888\nText:\nTake the 2-minute tour \u00d7\n\nGiven a generating function $F(x)=a+bx+cx^2+dx^3+\\dotsb$, how do I truncate the $n$ lower order terms to get, for example if $n=2$: $cx^2+dx^3+\\dotsb$?\n\nFor example, if I wanted to find $0a+1b+2c+\\dotsb$, I would evaluate $$\\left.\\frac{dF(x)}{dx}\\right|_{x=1}$$\n\nThis procedure can be used to find the expected value of a probability distribution given its generating function.\n\nI want something similar for truncation of lower-order terms. This would give a cdf for a probability distribution. Since the cdf has a nice form for a binomial generating function, this suggests that there might be a nice way to arrive at it using generating function operators.\n\nI vaguely remember learning this once, but flipping through the book generatingfunctionology didn't yield it.\n\nshare|improve this question\nBy what available means? Obviously subtracting $a+bx$ from $F(x)$ works for your example, and is easily generalized... \u2013\u00a0 anon May 31 '12 at 4:09\n@anon: I've added to my question to make it more clear. \u2013\u00a0 Neil G May 31 '12 at 4:12\nIf differentiation and evaluation are all you have at hand, you can truncate by subtracting a partial Taylor expansion - however, without convergence (e.g. $\\sum n!x^n$) I'm unsure if truncation is obtainable with these two operations alone. \u2013\u00a0 anon May 31 '12 at 4:16\n@anon: There are other operations available, but I don't know what they are. \u2013\u00a0 Neil G May 31 '12 at 4:23\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nIf $f(x) = \\sum\\limits_{n=0}^\\infty a_n x^n$, then $f''(x) = \\sum\\limits_{n=2}^\\infty a_n n (n-1) x^{n-2}$, and $$ \\int_0^x (x-t) f''(t)\\ dt = \\sum_{n=2}^\\infty a_n x^n. $$ EDIT: More generally, $$ \\int_0^x \\dfrac{(x-t)^{k-1}}{(k-1)!} f^{(k)}(t)\\ dt = \\sum_{n=k}^\\infty a_n x^n. $$\n\nshare|improve this answer\nAwesome! Generating functions are the first time in my adult life that math felt like magic. \u2013\u00a0 Neil G May 31 '12 at 4:32\nWould you mind adding a line or two to make it clear why the antiderivative works here? \u2013\u00a0 Neil G May 31 '12 at 4:38\n$\\int_0^t f''(s)\\ ds = \\sum_{n=2}^\\infty a_n \\int_0^t n(n-1) s^{n-2}\\ ds = \\sum_{n=2}^\\infty a_n n t^{n-1}$, and so $\\int_0^x \\int_0^t f''(s)\\ ds\\ dt = \\sum_{n=2}^\\infty a_n x^n$. Now interchange the order of integration. \u2013\u00a0 Robert Israel May 31 '12 at 4:45\nPerfect, thank you very much. \u2013\u00a0 Neil G May 31 '12 at 5:29\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/148636/how-to-check-whether-a-positive-integer-can-be-written-as-linear-combination-of/148666\nText:\nTake the 2-minute tour \u00d7\n\nLet $n$, $k$ and $m_1, \\dots, m_k$ be positive integers. Which is the most efficient algorithm to find out whether there are positive integers $a_1, \\dots, a_k$ such that $n = \\sum_{i=1}^k a_i m_i$?\n\nTo make things nontrivial, think of $k$ being in the hundreds, and of $n$ and the $m_i$ having hundreds of decimal digits, each. -- Clearly if we would remove the requirement that the $a_i$ are positive, the Chinese Remainder Theorem would tell us the answer -- but we do require them to be positive.\n\nshare|improve this question\nMO is intended for topics at the graduate-school level and above. \u2013\u00a0 Andy Putman Nov 12 '13 at 4:10\nI don\u2019t see how this is not at the graduate-school level or above, nevertheless the problem seems to be equivalent to the unbounded subset-sum problem, whose NP-completeness is mentioned in mathoverflow.net/a/144983/12705 . \u2013\u00a0 Emil Je\u0159\u00e1bek Nov 12 '13 at 12:39\nThe question sounds perfectly legitimate to me (and Emil Je\u0159\u00e1bek provided an answer to it -- maybe he wants to post it as an actual answer as opposed to a comment, now that the question is reopened). \u2013\u00a0 Andr\u00e9 Henriques Nov 12 '13 at 12:47\nAndy, this is an important question related to the works of Sylvester and Frobenius where much was discovered in recent decades. \u2013\u00a0 Gil Kalai Nov 12 '13 at 13:58\nadd comment\n\n1 Answer\n\nThe problem can be thought of as a coin problem. There are $k$ coins with denominations $m_1,\\dots,m_k$ and you want to express an amount $n$ with these coins. As states, the problem is an integer programming question which is NP-complete when $k$ is part of the input. It is in P (with exponential dependence on $k$) when $k$ is fixed by an algorithm by Lenstra.\n\nThe problem is closely related the Frobenius/Sylvester coin problem - to find the minimum $n$ so that every larger integer has such a representation. See here and here. A polynomial algorithm when $k$ is bounded was achieved by Ravi Kannan. (The dependence on $k$ is double-exponential.)\n\nThese two problems (finding a representation for fixed $n$ and finding the value of $n$ above which a representation always exists) represent the first two levels in Presburger Hierarchy. An important open problem here is to find a P-algorithm for higher order problems in the Presburger Hierarchy.\n\nOf course, another important question is how to solve such questions in practice. I suppose other people can answer that better than me. One method that certainly comes to mind is to consider the linear programming relaxation (i.e. to allow rational $a_i$s) and then apply some rounding and \"local\" improvement.\n\nThe range proposed by the OP where $k$ - (the number of coins) is in the hunderds is interesting. I don't know if current algorithms can scratch this value.\n\nshare|improve this answer\nthe coin problem is to find the least integer which is not in the submonoid generated by some natural numbers (assuming the gcd is 1). The problem of the OP is the unbounded subset problem, as mentioned by Emil in his comment, and is NP complete. \u2013\u00a0 Benjamin Steinberg Nov 12 '13 at 14:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/123245/annihilator-ideals\nText:\nTell me more \u00d7\n\nFor an ideal $I$ of a ring $R$ with identity, let $r(I)=\\{r\\in R: Ir=0\\}$ and $l(I)=\\{r\\in R: rI=0\\}$.\n\nQuestion: If for any two ideals (two-sided ideal) $I, J$ of $R$, we have $l(I)+l(J)=l(I\\cap J)$, does $r(I)+r(J)=r(I\\cap J)$?\n\nshare|improve this question\nwell you shd clarify what you mean by the sum of two ideals. if the ring is noncommutative, then the usual definition of sum of two ideals namely all linear combinations of the form $a_1x_1+a_2x_2$ for $x_1\\in I$ and $x_2\\in J$ does not make any sense ... for all you know the two ideals might be right ideals. the only way to make sense of sum of two ideals would be to just take all the elements of the form $x_1+x_2$ ... suppose you mean it then it is clear that $r(I)+r(J)\\subset r(I\\cap J)$ .. similarly for the left ideal case. so your question reduces to if $l(I\\cap J) \\subset l(I) + l(J)$ th \u2013\u00a0 magguu Feb 28 at 18:54\nIn the noncommutative setting, if $I$ and $J$ are left/right/two-sided ideals, then $I+J = \\{x+y \\mid x\\in I, y\\in J\\}$ is a left/right/two-sided ideal. It is certainly a subgroup, and $r(x+y)\\in I+J$ if $I$ and $J$ are both left ideals, $(x+y)r\\in I+J$ if $I$ and $J$ are right ideals. So I'm not sure what you are going on about... \u2013\u00a0 Arturo Magidin Feb 28 at 19:13\nA ring $R$ is called a \"right Ikeda-Nakayama ring\" (or right IN-ring) if for any two right ideals $I$ and $J$, $l(I)+l(J)= = l(I\\cap J)$. Having a name to add to the property may be useful (though you seem to be asking a bit less than right IN if you require $I$ and $J$ to be two-sided ideals. \u2013\u00a0 Arturo Magidin Feb 28 at 21:14\nDear Professor Magidin, Yes any IN-ring has this property, but for $R=\\begin{pmatrix} F & F \\\\ 0 & F \\\\ \\end{pmatrix}$, we have $r(I)+r(J)=r(I\\cap J)$ for any two ideals $I, J$ and also $l(I)+l(J)=l(I\\cap J)$ but $R$ is not an IN-ring. \u2013\u00a0 Ali Mar 1 at 6:39\n@Ali Taherifar: I thought it might be strictly weaker; still, you may want to take a look at the literature on IN-rings. \u2013\u00a0 Arturo Magidin Mar 1 at 16:12\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/366309/integrating-with-the-substitution-u-n-v\nText:\nTell me more \u00d7\n\n\n$$\\frac{dN}{dt} = rN(1 - K^{-v}N^v)$$\n\nwhere $r,v,K$ are positive constants (and so I think $N$ is a function of $t$), using the substitution $u =N^{-v}$, given that $N$ has an initial value at $N_0 < K$. Determine the behaviour of the solution for large times.\n\nSo, in accordance with the answers, I have done everything correct and got to the point where I now have\n\n$$\\frac{du}{dt} = -vr(u - K^{-v}),$$\n\nbut now I'm a little stuck. For some reason, they have integrated\n\n$$\\int_{u_0}^u \\frac{du}{u - K^{-v}} = -vrt.$$\n\nWhy have they integrated between those two limits as opposed to ingetrating just $\\frac{du}{u - K^{-v}}$ and then solving for $u$ to get the initial condition like normal?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nBecause integrating with the lower limit $u=u_0$ is equivalent to applying the initial condition at $t=0$. To see this, write instead\n\n$$\\int_{u_0}^u \\frac{du'}{u'-K^{-v}} = -v r \\int_0^t dt'$$\n\nNote that I primed the integration variables; they are dummy variables and what we call them is of no importance to the out come of the problem. The limits, however, are important: the lower limits and upper limits of integration on each side of the equation must correspond. That is, $u(0)=u_0$ which is equivalent to $N(0)=N_0$.\n\nYou can also see this by integrating as you would expect, an indefinite integral:\n\n$$\\int \\frac{du}{u-K^{-v}} = -v r t + C$$\n\nwhere $C$ is an integration constant. This of course implies that\n\n$$\\log{(u-K^{-v})} = -v r t + C$$\n\nNow, at $t=0$, $u=u_0$, which means that\n\n$$C = \\log{(u_0-K^{-v})}$$\n\nso that\n\n$$\\log{(u-K^{-v})}-\\log{(u_0-K^{-v})} = -v r t$$\n\nwhich is equivalent to\n\n\nI hope this makes sense of where the lower integration limit comes from.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/62563/how-does-a-pierced-vacuum-move\nText:\nTell me more \u00d7\n\nIf a can of compressed air is pierced on the right, air pushes out, and the can moves to the left.\n\nIf a vacuum container is pierced on the right, which way does it move? Right? Left? Not at all? Oscillate about its original position?\n\nshare|improve this question\nThe last one oscillate about it's original position is a silly option. :D. But it must be doesn't move at all. \u2013\u00a0 Mr.\u00d8\u00d87 Apr 28 at 17:02\nadd comment\n\n1 Answer\n\nWhy does a pierced compressed air can move? One answer is: when it is not pierced at 'the target point', there is a pressure acting on the target point (I should say area, but nevermind) on the right from the inside, as well as on its mirror point on the left, and so for every pair of points, so that the total force is zero. When you pierce the can, there still is some pressure acting on the mirror point, but there is no pressure acting on the target point, so that the total force acting on the can is not zero, and is directed to the left. (One can check that the force is the same as if you use conservation of momentum for the whole can+air system). What is pressure? Pressure is transition of momentum from air to the walls. When you pierce the target point, the momentum goes not to the can, but to the environment, and gets absorbed somewhere there.\n\nWhat changes when you pierce a vacuum can? Now the pressure acts from the outside, and now, when you pierce the can, the force on the mirror point is again not compensated and is directed to the right. So one may conclude that the can should move. But one thing is different: the momentum that was to be transfered to the target point from the outside (but was not, because there is now no surface at the target point) is not absorbed \"somewhere\", it goes inside the can, and is finally absorbed by it exactly canceling the momentum received by the mirror point.\n\nSo, in this case there is a rather subtle cancelation. However, I believe that there are some further subtleties, which may cause a small difference in these momenta, and if you try to measure the force really hard, then you will see it.\n\nshare|improve this answer\n-1 Momentum must be conserved. The can will still move in a vacuum. This is how a thruster works ( \u2013\u00a0 Brandon Enright Apr 30 at 4:22\n@BrandonEnright, Please, read the question carefully. \u2013\u00a0 Peter Kravchuk Apr 30 at 4:39\nYep, my mistake. I read it as a can pierced in a vacuum container. I will take back the -1 if SE lets me. \u2013\u00a0 Brandon Enright Apr 30 at 4:44\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/34984/what-does-it-mean-to-increase-volume-by-x-decibels?answertab=active\nText:\nTell me more \u00d7\n\nI am trying to decipher what decibels are:\n\nIt seems to be a log ratio of audio amplitude multiplied by a constant. I am confused by what this means though.\n\nIf my original volume is X, what does say increasing the volume by Y decibels mean?\n\nDoes it mean New Volume = 10 log ( Y / X )?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nYou almost had it right but you applied the formula backwards. The power of the sound waves (at any given point) is formalized in Wikipedia as the following using the bel unit:\n\n$$P_1 = 10^{L_B} P_0$$\n\nA value in bel is 10 times the value in decibels\n\n$$ L_{dB} = L_B / 10$$\n\nYou are interested in the power at a power level $X+Y$ decibels versus the power at a previous power level, $X$ decibles. To get this ratio we will divide the power values.\n\n$$ \\frac{P_2}{P_1} = \\frac{10^{X/10+Y/10} P_0}{10^{X/10} P_0} = 10^{Y/10}$$\n\nThat is to say, increasing power by $10 Y$ decibels will multiply power by 10 to the $Y$. If you look at loudness charts, this sounds right. Truck traffic (90 dB) seems about 10 times as loud as a telephone dial tone (80 dB).\n\nshare|improve this answer\n$Y$ in the second equation is in bels, while in the third equation it is decibels. This is clear because $\\frac{P_2}{P_1}$ has two inconsistent expressions. \u2013\u00a0 Ross Millikan Aug 27 '12 at 2:39\n@RossMillikan I was using two different definitions of Y, this is confusing and unnecessary so I edited, put all variables in decibels now. Thanks. \u2013\u00a0 AlanSE Aug 27 '12 at 12:24\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58571.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nHow Many Pads of Paper?\n\nDate: 10/30/2001 at 02:23:05\nFrom: Jessica\nSubject: Number Theory\n\npads did he sell?\n\nI don't understand how to solve this without knowing at least one more \nvariable, like how much or what percent they were marked down to.\n\nDate: 10/30/2001 at 08:46:16\nFrom: Doctor Paul\nSubject: Re: Number Theory\n\nThe integer 60377 has only four factors: 1, 173, 349, 60377\n\nSo 60377 = 1 * 60377 or 173 * 349\n\nIt follows then that \n\n   603.77 =  .01 * 60377   or \n            1.73 * 349     or \n             173 * 3.49    or \n               1 * 603.77\n\nBut since we know the merchant charged less than $2.00, we can assume \nhe sold them for either $1.73 each or $.01 each.\n\nIn the former case he sold 349 pads, and in the latter case he sold \n60377 pads.\n\nNotice that 1.73 * 349 = 603.7699999999999999999999999...  and \n.01 * 60377 = 603.77\n\nI'm guessing that the correct answer here is probably 349 since the \nother case is obvious and wouldn't require you to do much work. But if \nthe problem is stated exactly as you have it written above, 60377 \nwould be a legitimate answer as well.\n\nFeel free to write back if you want to talk about this some more.\n\n- Doctor Paul, The Math Forum\nAssociated Topics:\nMiddle School Factoring Numbers\nMiddle School Word Problems\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/32798/partition-function-for-the-jaynes-cummings-hamiltonian?answertab=votes\nText:\nTell me more \u00d7\n\nI was wondering if anyone here has calculated before the partition function for the Jaynes-Cummings Hamiltonian: $H_{JC}=\\omega_0 (a^\\dagger a + \\sigma^+ \\sigma^-)+g (a \\sigma^+ +a^\\dagger \\sigma^-)$ (Here I have assumed resonance and $a,a^\\dagger$ are bosonic operators and $\\sigma^-,\\sigma^+$ are ladder operators for a spin one half particle) For the Hamiltonian above the energy of the ground state is zero and corresponds to 0 excitations in the harmonic oscillator and the spin being down. The excited eigenenergies come in pairs and are given by: $\\omega_{n\\pm}=n \\omega_0 \\pm \\sqrt{n}g$. I am interested in knowing the partition function: $\\mathcal{Z}=\\text{tr}( \\exp(-\\beta H_{JC} ))=1+2\\sum_{n=1}^\\infty\\exp(-\\beta \\omega_0 n )\\cosh(\\beta g \\sqrt{n}) $ I tried Mathematica to get an analytic expression for the above sum and it did not work. Any thoughts on whether the summation can be expressed in terms of some special function or how to calculate it numerically in an efficient and reliable way?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nit is not exact and is impossible to compute exactly i recommend to use the Euler method to approximate your series by an integral plus some extra corrections , this Euler-Maclaurin summation converges fast to the exact solution with only a few terms.\n\nshare|improve this answer\nThanks a lot Jose Javier, I will just use what you just wrote :) \u2013\u00a0 Nicol\u00e1s Quesada Jul 26 '12 at 1:53\nAlso do you know any reference related to this specific problem? \u2013\u00a0 Nicol\u00e1s Quesada Jul 26 '12 at 2:32\nno, unfortunately i know no reference to this problem :/ or how the partition funciton is obtained. \u2013\u00a0 Jose Javier Garcia Jul 26 '12 at 8:42\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58868.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nEstimating and Rounding\n\nDate: 03/04/2002 at 15:49:48\nFrom: Amy \nSubject: Division - one answer problems\n\nI am doing my math homework and we have to divide a two-digit number \ninto another number and get a one-digit quotient. For example, 192  \ndivided by 86 = . Can you please help me?\n\nDate: 03/04/2002 at 22:56:59\nFrom: Doctor Peterson\nSubject: Re: Division - one answer problems\n\nHi, Amy.\n\nYou can find some discussions of the tricks you need in our archives:\n\n   Division by Estimation\n\n   Long division, Egyptian Division, Guessing\n\n   Compatible Number Estimating\n\nThere are a couple of important things to remember: you have to \nestimate (because you don't have a multiplication table that goes up \nto the 86's), and when you estimate you expect not to be exact. \nTherefore, you will be learning not only to make the best guess you \ncan, but to correct the guess WHEN (not if) it turns out to be wrong. \nThat's just part of the process, and doesn't mean you've made a \n\nSo let's look at your example. The first thing I usually do is to \nround both numbers, generally so that there is one non-zero digit left \nin the divisor and two in the dividend (though that's not always true \n- you'll get used to how to make this decision with a little \npractice). In this case, 86 rounds up to 90, and 192 rounds down to \n190. It won't matter here, but I like to round both numbers in the \nsame direction, because that's more likely to give a good estimate. \nSo I'd round both numbers up here (giving preference to the divisor), \nmaking it\n    90 ) 200\n\nNow, we can divide both numbers by 10 and it won't change the \nquotient; so ignore the zeroes on the end:\n    9 ) 20\n\nNow we've got something we can do: the answer is 2, since 9 * 2 = 18.\n\nThat's our estimate; but is it the right answer for the real problem \nwe're doing? All we can do is check it by multiplying. We're hoping \n    86 ) 192\n\nTo check that (and also to find the remainder), we multiply the \ndivisor by the quotient: 2 * 86 = 172. This is good: it's less than \n192, but not so much less that we could fit another whole 86 into it. \nThat is, we can subtract to get a remainder, and the remainder is less \nthan the divisor:\n\n    86 } 192\n\nSo the remainder is 20.\n\nAt leat one of the links I gave you goes into how to correct an \nestimate if the check doesn't work out; briefly, you subtract one from \nthe quotient if it's too big (so that the product was too big to \nsubtract at all), and you add one if the quotient is too small (so \nthat the remainder is too big).\n\nLet me know if you need more help. You might want to send a sample \nproblem worked out, so I can see where you might be going wrong or \ngetting stuck.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Division\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/15853/disintegrations-are-measurable-measures-when-are-they-continuous?sort=oldest\nText:\nTell me more \u00d7\n\nThis is a sequel to another question I have asked.\n\nThe notion of disintegration is a refinement of conditional probability to spaces which have more structure than abstract probability spaces; sometimes this is called regular conditional probability. Let $Y$ and $X$ be two nice metric spaces, let $\\mathbb P$ be a probability measure on $Y$, and let $\\pi : Y \\to X$ be a measurable function. Let $\\mathbb P_X(B) = \\mathbb P(\\pi^{-1} B)$ denote the push-forward measure of $\\mathbb P$ on $X$. The disintegration theorem says that for $\\mathbb P_X$-almost every $x \\in X$, there exists a nice measure $\\mathbb P^x$ on $Y$ such that $\\mathbb P$ \"disintegrates\":$$\\int_Y f(y) ~d\\mathbb P(y) = \\int_X \\int_{\\pi^{-1}(x)} f(y) ~d\\mathbb P^x(y) d\\mathbb P_X(x)$$ for every measurable $f$ on $Y$.\n\nThis is a beautiful theorem, but it's not strong enough for my needs. Fix a Borel set $B \\subseteq X$, and let $p(x) = \\mathbb P^x(B)$. Part of the theorem is that $p$ is a measurable function of $x$. Suppose that the map $\\pi : Y \\to X$ is continuous instead of simply measurable. My question: What is a general sufficient condition for $p(x)$ to be continuous?\n\nTo me, this is an obvious question to ask, since if $x$ and $x'$ are two close realizations of a random $x \\in X$, then the measures $\\mathbb P^x$ and $\\mathbb P^{x'}$ should be close too, at least in many natural situations. However, in my combing through the literature, I haven't been able to find an answer to this question. My guess is that most people are content to integrate over $x$ when they use the theorem. For my purposes, I need some estimates which I get by continuity.\n\nAt this point, I've managed to prove and write down a pretty good sufficient condition for the case I care about (Banach spaces), using an abstract Wiener space-type construction. However, I am hoping that an expert can point me toward a good reference that does this in wider generality.\n\nshare|improve this question\nB must be a subset of Y? \u2013\u00a0 Andrey Gogolev Feb 20 '10 at 1:09\nAlso, sufficient condition on what, on B, on pi, both? \u2013\u00a0 Andrey Gogolev Feb 20 '10 at 1:24\nAndrey: B above is a Borel set in Y. The function pi need only be measurable for the general disintegration theorem to apply. However, in my case, pi is continuous function. \u2013\u00a0 Tom LaGatta Feb 20 '10 at 15:21\nadd comment\n\n3 Answers\n\nTue Tjur studied the existence of continuous disintegrations in a 1975 preprint \"A Constructive Definition of Conditional Distributions,\" Issue 13, Copenhagen Universitet. He gives necessary and sufficient conditions for their existence, at least in the setting of Radon measures.\n\nHe also discusses sufficient structure, and there considers a basic probability space that is an open subset of a finite-dimensional Euclidean space and the problem of conditioning on a random variable taking values in an open subsets of a Euclidean space $\\mathbb R^k$ such that, when the random variable is considered as a (measurable) function, it is surjective and continuously differentiable with differential of maximal rank. This particular special case may be too narrow for you, but perhaps the general case can give you some guidance.\n\nThe article is a bit hard to track down, so let me know if you need help finding it. The existence of continuous disintegrations arises also in the study of the computability of conditional probability, which is my interest.\n\nshare|improve this answer\nadd comment\n\nProbably is not general as you want, but if you don't think before about that can be a begining...\n\nProposition: If $\\pi:Y\\to X$ is bijective function such that $\\pi^{-1}$ is continuous then $\\mathbb{P}^{x_n}\\to\\mathbb{P}^{x}$ (weak topology) whenever $x_n\\to x$.\n\nProof: it follows from the Disintegration Theorem that for all $B\\in\\mathcal{B}(Y)$ we have\n\n$$ \\begin{array}{rcl} \\mathbb{P}(B)&=&\\displaystyle\\int_X\\int_{\\pi^{-1}(x)}\\chi_B(y)\\ d\\mathbb{P}^x(y)\\ d\\mathbb{P}_X(x) &=&\\displaystyle\\int_X \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) \\end{array} $$ For the other hand we have that $$ \\mathbb{P}(B)=\\displaystyle\\int_X \\chi_B(\\pi^{-1}(x))\\ d\\mathbb{P}_X(x) =\\displaystyle\\int_X \\chi_B(\\pi^{-1}(x))\\delta_{\\pi^{-1}(x)}(\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) $$ so $$ \\displaystyle\\int_X \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x)=\\mathbb{P}(B)=\\displaystyle\\int_X \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) $$\n\nSince $\\mathbb{P}^x$ is a probability measure and $B\\cap\\pi^{-1}(x)$ is a singleton or empty set, we have $$ \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x))\\geq \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) $$ and from previous integral equality almost surely we have $$ \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x))=\\mathbb{P}^x(B\\cap\\pi^{-1}(x)). $$ Fix $x$ and take $B=\\pi^{-1}(x)$, then from the above equality, follows that $\\mathbb{P}^x=\\delta_{\\pi^{-1}(x)}$.\n\nIf $x_n\\to x$ then $p(x_n)=\\mathbb{P}^{x_n}$ converge to $p(x)$ in the weak topology. In fact, by the continuity of $\\pi^{-1}$ we get that $\\int f\\ p(x_n) \\to\\int f\\ p(x)$ for all bounded uniformly continuous functions $f$.\n\nshare|improve this answer\nadd comment\n\nI think you need some hypothesis on the measure to be pushed, at least in the very common case where $\\pi$ is the projection to a factor in a product.\n\nTake any family $\\mathbb{P}^x$ of measures in a space $X'$, where $x$ runs over $X$, and let $Y=X'\\times X$, $\\pi$ be the projection on $X$, and $\\mathbb{P}=\\int_X \\mathbb{P}^x dx$ where $dx$ is any measure on $X$. Then $\\pi$ is very regular (smooth if $X'$ and $X$ are smooth manifolds for example) but yet, any kind of lack of regularity can appear in $\\mathbb{P}^x$ (which are by construction the disintegration measures, since they are unique up to a negligible set).\n\nI guess that in this setting, assuming $\\mathbb{P}$ to be absolutly continuous with continuous density would be sufficient.\n\nEdit: My guess seems wrong, as is shown by the restriction of Lebesgue measure to a L shaped polygon. You will probably need strong restrictions on $\\mathbb{P}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/2988/how-fast-can-we-find-all-four-square-combinations-that-sum-to-n\nText:\nTell me more \u00d7\n\nA question was asked at Stack Overflow (here):\n\nGiven an integer $N$, print out all possible combinations of integer values of $A,B,C$ and $D$ which solve the equation $A^2+B^2+C^2+D^2 = N$.\n\nThis question is of course related to Bachet's Conjecture in number theory (sometimes called Lagrange's Four Square Theorem because of his proof). There are some papers that discuss how to find a single solution, but I have been unable to find anything that talks about how fast we can find all solutions for a particular $N$ (that is, all combinations, not all permutations).\n\nI have been thinking about it quite a bit and it seems to me that it can be solved in $O(N)$ time and space, where $N$ is the desired sum. However, lacking any prior information on the subject, I am not sure if that is a significant claim on my part or just a trivial, obvious or already known result.\n\nSo, the question then is, how fast can we find all of the Four-Square Sums for a given $N$?\n\nOK, here's the (nearly) O(N) algorithm that I was thinking of. First two supporting functions, a nearest integer square root function:\n\n    // the nearest integer whose square is less than or equal to N\n    public int SquRt(int N)\n        return (int)Math.Sqrt((double)N);\n\nAnd a function to return all TwoSquare pairs summing from 0 to N:\n\n    // Returns a list of all sums of two squares less than or equal to N, in order.\n    public List<List<int[]>> TwoSquareSumsLessThan(int N)\n        //Make the index array\n        List<int[]>[] Sum2Sqs = new List<int[]>[N + 1];\n\n        //get the base square root, which is the maximum possible root value\n        int baseRt = SquRt(N);\n\n        for (int i = baseRt; i >= 0; i--)\n                int sum = (i * i) + (j * j);\n                if (sum > N)\n                    //make the new pair\n                    int[] sumPair = { i, j };\n                    //get the sumList entry\n                    List<int[]> sumLst;\n                    if (Sum2Sqs[sum] == null)\n                        // make it if we need to\n                        sumLst = new List<int[]>();\n                        Sum2Sqs[sum] = sumLst;\n                        sumLst = Sum2Sqs[sum];\n                    // add the pair to the correct list\n\n        //collapse the index array down to a sequential list\n        List<List<int[]>> result = new List<List<int[]>>();\n        for (int nn = 0; nn <= N; nn++)\n            if (Sum2Sqs[nn] != null) result.Add(Sum2Sqs[nn]);\n\n        return result;\n\nFinally, the algorithm itself:\n\n    // Return a list of all integer quads (a,b,c,d), where:\n    //      a^2 + b^2 + c^2 + d^2 = N,\n    // and  a >= b >= c >= d,\n    // and  a,b,c,d >= 0\n    public List<int[]> FindAllFourSquares(int N)\n        // get all two-square sums <= N, in descending order\n        List<List<int[]>> Sqr2s = TwoSquareSumsLessThan(N);\n\n        // Cross the descending list of two-square sums <= N with\n        // the same list in ascending order, using a Merge-Match\n        // algorithm to find all combinations of pairs of two-square\n        // sums that add up to N\n        List<int[]> hiList, loList;\n        int[] hp, lp;\n        int hiSum, loSum;\n        List<int[]> results = new List<int[]>();\n        int prevHi = -1;\n        int prevLo = -1;\n\n        //  Set the Merge sources to the highest and lowest entries in the list\n        int hi = Sqr2s.Count - 1;\n        int lo = 0;\n\n        //  Merge until done ..\n        while (hi >= lo)\n            // check to see if the points have moved\n            if (hi != prevHi)\n                hiList = Sqr2s[hi];\n                hp = hiList[0];     // these lists cannot be empty\n                hiSum = hp[0] * hp[0] + hp[1] * hp[1];\n                prevHi = hi;\n            if (lo != prevLo)\n                loList = Sqr2s[lo];\n                lp = loList[0];     // these lists cannot be empty\n                loSum = lp[0] * lp[0] + lp[1] * lp[1];\n                prevLo = lo;\n\n            // do the two entries' sums together add up to N?\n            if (hiSum + loSum == N)\n                // they add up, so cross the two sum-lists over each other\n                foreach (int[] hiPair in hiList)\n                    foreach (int[] loPair in loList)\n                        // make a new 4-tuple and fill it\n                        int[] quad = new int[4];\n                        quad[0] = hiPair[0];\n                        quad[1] = hiPair[1];\n                        quad[2] = loPair[0];\n                        quad[3] = loPair[1];\n\n                        // only keep those cases where the tuple is already sorted\n                        //(otherwise it's a duplicate entry)\n                        if (quad[1] >= quad[2]) //(only need to check this one case, the others are implicit)\n                        //(there's a special case where all values of the 4-tuple are equal\n                        // that should be handled to prevent duplicate entries, but I'm\n                        // skipping it for now)\n                // both the HI and LO points must be moved after a Match\n            else if (hiSum + loSum < N)\n                lo++;   // too low, so must increase the LO point\n            else    // must be > N\n                hi--;   // too high, so must decrease the HI point\n        return results;\n\nAs I said before, it should be pretty close to O(N), however, as Yuval Filmus points out, as the number of Four Square solutions to N can be of order (N ln ln N), then this algorithim could not be less than that.\n\nshare|improve this question\nI can think of a $O(N^2)$ time algorithm. If you want to, I can post the details. How can you do it in linear time? \u2013\u00a0 Juho Aug 1 '12 at 20:57\nYes, please post it. I'm still developing the linear algorithm details, but I'm pretty sure it's valid. \u2013\u00a0 RBarryYoung Aug 1 '12 at 21:04\nFor the record, it appears that sometimes there are as many as $\\Omega(N\\log\\log N)$ solutions, so we can't really have an $O(N)$ algorithm. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 14:37\nFrom here, it looks like the catch (and the extra non-linear factor) comes from the two foreach() loops within your main while loop; your total time is basically $\\displaystyle\\sum_{i=0}^{N/2} |hiList_{N-i}|*|loList_i|$, and the problem is that the sizes of hiList and loList aren't necessarily bounded by any constant. \u2013\u00a0 Steven Stadnicki Aug 2 '12 at 18:30\nYes, that's correct, however your formula's a little bit off because first i ranges from 0 to apprx. N*PI/8, and second only a fraction of the values of i satisfy hiList(N-i)+loList(i) = N, so they are not all added in. In any event, there's no way to fix this and I am pretty sure that this gives the minimum possible complexity of O(N*log(log(N))). \u2013\u00a0 RBarryYoung Aug 2 '12 at 21:11\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nJuho's algorithm can be improved to an $O(N)$ algorithm using meet-in-the-middle. Go over all pairs $A,B \\leq \\sqrt{N}$; for each pair such that $M=A^2+B^2 \\leq N$, store $(A,B)$ in some array $T$ of length $N$ (each position $M$ could contain several pairs, which might be stored in a linked list). Now go over pairs $M,N-M$ such that the corresponding cells in $T$ are non-empty.\n\nThis way we get an implicit representation of all quadruples. If we want to list all of them, then we can't do any better than $\\Omega(N\\log\\log N)$, since Jacobi's four square theorem shows that (for odd $N$) the number of representations is $8\\sigma(N)$, and there are infinitely many integers such that $\\sigma(N) \\geq (e^\\gamma - \\epsilon) N\\log\\log N$ (see Gr\u00f6nwall's theorem).\n\nIn order to get less trivial algorithms, one can try to factor $N$ over the appropriate quaternion ring, since we know that the representations as sums of two squares correspond (in some sense) to these factorizations, through Lagrange's four-square identity. We would still need to find all representations of any relevant prime.\n\nshare|improve this answer\nHmm, the meet-in-the-middle thing sounds very similar to what I am working on (almost done) which is an ascending/descending Merge-Match algorithm over the TwoSquare pairs. Does that sound the same? \u2013\u00a0 RBarryYoung Aug 2 '12 at 14:35\nIt's probably the same, meet-in-the-middle is such a common heuristic that it must have many different names. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 14:36\nUmm, I've been out of academia for thirty years, what's the $\\sigma(N)$ thing mean? (or can you point me to a reference?) thnx. \u2013\u00a0 RBarryYoung Aug 2 '12 at 14:40\nOr is that $\\sigma(N)$ really a $\\omicron(N)$? \u2013\u00a0 RBarryYoung Aug 2 '12 at 15:01\nSum of divisors function indeed. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 15:48\nshow 1 more comment\n\nI think a $o(N^2)$ time algorithm is not a trivial one and requires some insight if one exists. The obvious algorithm that runs in quadratic time enumerates all tuples $A,B,C,D \\leq \\sqrt[]{N}$. This can be done in four loops, so the total time complexity becomes $O(N^2)$. It also clearly enumerates all solutions.\n\nAs relating algorithms, Rabin and Shallit [1] present two randomized algorithms for decomposing integers as sum of squares. For two squares, they give a $O(\\log^2 n)$ expected time algorithm. For four squares, they give a $O(\\log^2 n \\log \\log n)$ expected time algorithm. Note that the algorithms don't give you all the solutions, but merely just one.\n\n[1] M. O. Rabin, J. O. Shallit, Randomized Algorithms in Number Theory, Communications on Pure and Applied Mathematics 39 (1986), no. S1, pp. S239\u2013S256.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/195700/find-a-bijection-between-the-cartesian-product-m-times-n-and-m-n\nText:\nTell me more \u00d7\n\nLet $[n]$ denote $\\{1,2,\\dots n\\}$.\n\nShow there is a bijection between $[m]\\times[n]$ and $[mn]$.\n\nI was thinking about doing something related to induction to prove that there is some value $b$ for every $f(a)$. Then probably settle for the definition of a product to say that in $\\{(a,b)\\mid a\\in A ; b\\in B\\}$ so there can only be values corresponding from $A$ and $B$ in $(a,b)$. If this seems correct, let me know.\n\nIf there's anyone with a more rigorous proof, I would be delighted.\n\nshare|improve this question\nThe first step would be a more rigorous statement of what you're actually trying to prove. e.g. what function from what domain to what codomain are you trying to prove is bijective? \u2013\u00a0 Hurkyl Sep 14 '12 at 12:27\nGuessing: are you finding a bijection between $[m]\\times[n]$ and $[mn]$? \u2013\u00a0 rschwieb Sep 14 '12 at 12:30\nApparently, this question is about showing $|A\\times B| = |A|\\cdot|B|$ in the finite case. \u2013\u00a0 Hagen von Eitzen Sep 14 '12 at 12:30\n@rschwieb Yes, I just seem to be inefficient in parsing it correctly. \u2013\u00a0 Casquibaldo Sep 14 '12 at 12:32\nI'm not exactly sure what you're allowing yourself to use. If you are defining the product of natural numbers as the cardinality of the cross product, then this pretty much follows by definition. I'll type up what I mean, and you can tell me if it's useful or not. \u2013\u00a0 rschwieb Sep 14 '12 at 12:35\nshow 3 more comments\n\n3 Answers\n\nup vote 2 down vote accepted\n\nIf you are defining the product of natural numbers this way, I'll supply a solution.\n\n$mn=|A\\times B|$ where $|A|=n$ and $|B|=m$\n\nIn particular you could use $A=[n]$ and $B=[m]$.\n\nBut now the statement that $mn=|[n]\\times[m]|$ says exactly that $[mn]$ is bijective to $[n]\\times[m]$, since $[mn]$ is a set of cardinality $mn$.\n\nTo find a concrete bijection between the two sets, imagine $[n]\\times[m]$ written out as a grid. Enumerate the entries of the grid from $1\\dots mn$ any way you like. That's a bijection from $[mn]$ to $[n]\\times[m]$.\n\nshare|improve this answer\nI think this is what I wanted to know. Thanks for clearing it up. \u2013\u00a0 Casquibaldo Sep 14 '12 at 12:46\nadd comment\n\nFor each two finite sets $A$ and $B$ with the same number of elements, you can find a bijection $A\\rightarrow B$. Simply enumerate the items: $A=\\{ a_1,\\dots,a_n \\}, B=\\{ b_1,\\dots,b_n \\}$ and define a mapping $\\phi:A\\rightarrow B$ by $a_j \\mapsto b_j$. This is one possible bijection.\n\nApply this for your case.\n\nshare|improve this answer\nadd comment\n\nFor any positive integer $k$, let $S_k$ be the set $\\{0,1, \\dots, k-1$. There is an obvious bijection between $S_k$ and $[k]$. So it is enough to show that there is a bijection between $S_m\\times S_n$ and $S_{mn}$. We describe a bijection that is natural from a number-theoretic point of view.\n\nRecall that for any positive integer $x$, and any positive integer $n$, there exist uniquely determined integers $q$ and $r$ such that $0\\le r\\le n-1$ and $$x=qn+r.\\tag{$1$}$$ This result is often called the Division Algorithm.\n\nIn Equation $(1)$, we have $0\\le q\\le m-1$ iff $0\\le x\\le mn-1$. So the mapping that takes the ordered pair $(q,r)$ to $x=qn+r$ is a bijection from $S_m\\times S_n$ to $S_{mn}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/2166/bertrands-postulate/2173\nText:\nTake the 2-minute tour \u00d7\n\nStatement For every $n > 1$ there is always at least one prime $p$ such that $n < p < 2n$.\n\nI am curious to know that if I replace that $2n$ by $2n-\\epsilon$, ($\\epsilon>0$) then what is the $\\inf (\\epsilon)$ so that the inequality still holds, meaning there is always a prime between $n$ and $2n-\\epsilon$\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 2 down vote accepted\n\nThree related points are worthy of mention, showing that epsilon can be close to n.\n\nThere is a result of Finsler that approximates how many primes lie between n and 2n, which is of order o(n/log(n)) as is to be expected by the Prime Number Theorem.\n\nLiterature on prime gaps will tell you the exponent delta such that there is (for sufficiently large n) at least one prime in the interval (n , n + n^delta). I think delta is less than 11/20.\n\nObserved data suggests that n^delta can be replaced by something much smaller: for n between something like 3 and 10^14 , some function like 2(log(n))^2 works.\n\nshare|improve this answer\n\nBertrand's postulate is\n\nif n > 3 is an integer, then there always exists at least one prime number p with n < p < 2n \u2212 2.\n\nThus \u03b5 < 2 for n > 3. What if n \u2264 3?\n\n  \u2022 For n = 3, 3 < 5 < 6 - \u03b5 \u21d2 \u03b5 < 1\n  \u2022 For n = 2, 2 < 3 < 4 - \u03b5 \u21d2 \u03b5 < 1\n\nHence we have 0 < \u03b5 < 1, if \u03b5 is a constant.\n\nshare|improve this answer\nnow the question may be more interesting. I actually wanted to find the least postive $\\epsilon$ such that the condition remains true. \u2013\u00a0 anonymous Aug 11 '10 at 16:21\n@Chandru1: Any \u03b5 between 0 and 1 will do, so the infimum of all possible positive \u03b5 is 0. This is not surprising. Did you want the supremum instead? (The supremum is 1 of you want it to hold for n=2 or 3, and infinity if you only want sufficiently large n.) \u2013\u00a0 ShreevatsaR Aug 11 '10 at 16:44\n@ShreevatsaR : Hi i got it. \u2013\u00a0 anonymous Aug 11 '10 at 16:50\n\nThe answer depends if you want an answer that is true \"for all n\" or an answer that is true \"for all sufficiently large n.\" For instance, there is not always a prime in an interval of the form (n, 3n/2). Take n=7, for instance. There is always a prime in such an interval \"for sufficiently large n,\" however.\n\nshare|improve this answer\n\nThis was there in the proof of Bertrand's theorem.\n\nif $n>60$, then $\\varepsilon=\\frac{2n}{3}$.\n\nshare|improve this answer\nHi! Welcome to math.SE. This solution would be more helpful if you cited readers to the proof you are referring to. Might you be able to add that? \u2013\u00a0 rschwieb Dec 28 '12 at 14:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/128508/gluing-gerbes-over-a-spectrum-of-a-field\nText:\nTake the 2-minute tour \u00d7\n\nA theorem of Giraud says that gerbes over a scheme $X$ bounded by a sheaf of Abelian groups $A$ are classified by elements of the etale cohomology group $H^2(X,A)$. Similar statements hold in other categories (differential, topological) as well.\n\nOne of the points of view on gerbes (emphasized, for example, by Hitchin in \"Lectures on special Lagrangian manifolds\") is that a gerbe can be glued from trivial gerbes just like a vector bundle can be glued from trivial vector bundles, but the gluing data is not transition functions but A-torsors. I am trying to see if this philosophy can be applied to gerbes over a spectrum of a (perfect) field $k$. Giraud's theorem tells in this case that isomorphism classes of gerbes are in bijective correspondence with elements of the Galois cohomology group $H^2(k, A)$.\n\nLet $k'/k$ be Galois with Galois group $G$ and let $A$ be an Abelian algebraic group defined over $k$ (we use $A$ to denote the corresponding Galois module). The Hochshild-Serre spectral sequence yields the following exact sequence: $$ \\ldots \\to H^2(G,A^{G_{k'}}) \\to \\mathrm{Ker}(H^2(k,A) \\to H^2(k',A)) \\to H^1(G,H^1(k',A)) \\to H^3(G,A^{G_{k'}})\\ldots $$ where $G_{k'}$ is the absolute Galois group of $k'$. Suppose we have a gerbe over $\\mathrm{Spec}\\ k$ that trivialises after base change to $\\mathrm{Spec}\\ k'$. An element of $H^1(G,H^1(k',A))$ is the gluing data that has been mentioned above (indeed, $H^1(k',A)$ classifies $A$-torsors defined over $k'$). If also the second and third cohomology of $G$ with coeffecients in $A^{G_{k'}}$ vanished then we would have an isomorphism between two middle terms of the sequence which means that any gerbe that trivialises over $\\mathrm{Spec}\\ k'$ can be described in terms of this gluing data.\n\nI have the following question: is it true that for any gerbe over $k$ one can always find a Galois extension $k'$ with Galois group $G$ such that the gerbe trivialises after base change to $k'$ and $H^2(G,A)$ and $H^3(G,A)$ vanish?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nI don't think so. I think a gerbe bound by $A$ over the spectrum of a field $k$ gives a cohomology class $\\eta\\in H^2(k,A)$, and the gerbe trivializes over an extension $k'/k$ if and only if this cohomology class trivializes. Now take $k=\\mathbb{R}$, $A=\\mathbf{G}_{m,\\mathbb{R}}$, then $H^2(k, A)={\\rm Br}(\\mathbb{R})=\\frac{1}{2}\\mathbb{Z}/\\mathbb{Z}$. Let $\\eta\\in{\\rm Br}(\\mathbb{R})$ be the nontrivial element (corresponding to Hamilton's quaternions). Then $\\eta$ trivializes over $\\mathbb{C}$, but not over $\\mathbb{R}$, so $k'=\\mathbb{C}$, $G={\\rm Gal}(\\mathbb{C}/\\mathbb{R})$, and $H^2(G,A)=H^2(\\mathbb{C}/\\mathbb{R},\\mathbf{G}_m)={\\rm Br}(\\mathbb{R})\\neq 0$, so $H^2(G,A)$ does not vanish.\n\nshare|improve this answer\nindeed, the statement I hoped for is false. Do you think it might still be true for some classes of fields? For example, fields finitely generated over an algebraically closed field? \u2013\u00a0 Dima Sustretov Apr 24 '13 at 7:43\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/95049/f-nx-p-converge-uniformly-to-nice-fx-p-do-zeros-of-f-n-p-converge-unifor?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nFix compact intervals $X, P \\subseteq \\mathbb{R}$.\n\nLet $f_n : X \\times P \\to \\mathbb{R}$ be a sequence of $C^2$ functions converging uniformly to a $C^2$ function $f$. The first and second derivatives of $f_n$ also converge uniformly to those of $f$.\n\nFor any $p \\in P$, the function $f(\\cdot,p) : X \\to \\mathbb{R}$ has a unique zero $x^*(p)$, and $f_1(x^*(p),p) \\neq 0$. Therefore there is a sequence $x_n^* (p) \\to x^*(p)$ such that $f_n(x_n^*(p),p)=0$ for large $n$.\n\nWhen can we also say that $x_n^*(p) \\to x(p)$ uniformly in $p$? Is there a standard reference for such results?\n\nshare|improve this question\nHow about $f_n(x,p)=(x-p)^2+1/n$? This converges to $f(x,p)=(x-p)^2$, but $f_n(x,p)\\neq 0$ for all $x,p$ and $n$. Therefore, your therefore does not seem right, unless I am misinterpreting something. \u2013\u00a0 Per Alexandersson Apr 24 '12 at 21:01\nI think \" $f_1(x,p)$ \" denotes the partial derivative wrto the first variable, x. In other words, he's in the hypotheses of the implicit function thm. \u2013\u00a0 Pietro Majer Apr 24 '12 at 22:04\n\n1 Answer 1\n\nIt's a quick proof by contradiction.\n\nAssume that $ x _ n ^ * $ does not converge uniformly to $x^*$. Then, there exists $\\epsilon > 0$ and, for all $n\\in \\mathbb{N}$, a point $p_n\\in P$ such that $|x_n ^ *(p _ n)-x ^ *(p _ n)|\\ge\\epsilon$.\n\nA subsequence $\\big( p_{n_k}\\, ,\\, x_ {n_k} ^ *(p _{n_k})\\big)$ converges to some $( p, y ^ * ) \\in P \\times X$, a zero of $f$ different from $(p,x^*(p))$, contradiction.\n\nshare|improve this answer\nNote that this requires nothing about the derivatives, just uniform convergence of $f_n$ to $f$ on $X \\times P$, continuity of $f$ on $X \\times P$, and the fact that $f(\\cdot,p)$ has a unique zero in $X$ for each $p \\in P$. \u2013\u00a0 Robert Israel Apr 26 '12 at 7:36\n(and compactness of $X$ and $P$) \u2013\u00a0 Robert Israel Apr 26 '12 at 7:37\nIndeed. We may say it's an instance of a kind of general situation: \"uniqueness plus compactness gives continuous dependence\". \u2013\u00a0 Pietro Majer Apr 26 '12 at 7:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/289375/bound-for-the-product-of-numbers/289771\nText:\nTake the 2-minute tour \u00d7\n\nLet $n \\in N$. Fix $m \\in [-n,n]$. I am curious, how to bound from above the following expression $$ (n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}}\\leq \\quad ? $$\n\nThank you.\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\n$$ (n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}} = n^{n+3/2}\\exp\\left(\\frac{n-m+2}{2}\\log(1+m/n)+\\frac{n+m+1}{2}\\log(1-m/n))\\right) \\leq n^{n+3/2}\\exp\\left(\\frac{m(n-m+2)}{2n}-\\frac{m(n+m+1)}{2n}\\right) = n^{n+3/2} \\exp\\left(\\frac{m-2m^2}{2n}\\right) \\leq n^{n+3/2} \\exp\\left(\\frac{1}{16n}\\right),$$\n\nand from the Taylor series of $\\log(1+x)$ and $\\log(1-x)$ in a neighbourhood of zero it is not difficult to derive lower bounds, too.\n\nshare|improve this answer\n\n$(n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}}\\leq (2n)^{n+1}(2n)^{n+1/2}=(2n)^{2n+3/2}$\n\nshare|improve this answer\nThank you, but I would like to get more accurate bound. I was trying to maximize this expression, but it turns out that there is no global maximum... Also, I've realized I did not mentioned that $m$ is fixed. Sorry. \u2013\u00a0 Alex Jan 29 '13 at 0:06\n\nI have had good luck tightening bounds by finding the form $(a-b)(a+b)$ which you already have. $$a^2 - b^2 \\le a^2 - b^2 \\le a^2$$ is a much better bound than the naive $$(a-b)^2 \\le (a-b)(a+b) \\le (a+b)^2$$ (with $b \\lt a$)\n\nSo for your problem, I would take as many factors of $n^2 - m^2$ as I can. Which exponent is larger switches at $m=\\frac12$ so treat each interval separately.\n\nFor $m \\ge \\frac 12$ we can break your expression as follows: $$ (n-m)^{\\frac{n-m+2}2} (n+m)^{\\frac{n-m+2}2} (n+m)^{m-\\frac12} $$ which is $$ (n^2-m^2)^{\\frac{n-m+2}2} (n+m)^{m-\\frac12} $$ To simplify the powers I will only eliminate $m$ from the quantities in parentheses. The previous expression is less than: $$ (n^2)^{\\frac{n-m+2}2} (2n)^{m-\\frac12} $$ which equals $$ n^{n-m+2} 2^{m-\\frac12} n^{m-\\frac12} $$ and $$ 2^{m-\\frac12} n^{n+\\frac32} $$\n\nYou can complete the same steps for $m \\le \\frac12$ to obtain a similar expression, then combine these for the overall upper bound.\n\nEdit: with the correction I just made it appears that both cases produce the same expression, so the result above should be the overall upper bound.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://brainmass.com/math/calculus-and-analysis/establish-non-existence-multivariable-limit-245416\nText:\nExplore BrainMass\n\nTo establish non-existence of multivariable limit\n\nWe examine the above function and consider its limit as (x,y)-> (0,0).We take two different paths in the x-y plane for approaching the point (0,0),and find that f(x,y) approaches two different values .This enables us to conclude that the given limit does not exist.For a detailed discussion see the solution given.\n\n\nSolution Preview\n\nFind limit of the function x^2y^2/[x^2y^2 + (x - y)^2] as (x,y) -> (0,0).\n\nTo explain the procedure, first let us consider the case of a single variable function by examining the limit of the function f(x) = |x|/x as x->0. If we are able to show that the left hand limit and right hand limits are unequal then the limit does not exist.\n\nWhen we consider the left hand limit then x->0 by taking values less than zero that is by taking negative values. When x < 0,then |x| = -x and accordingly |x|/x has value -1; this means that ...\n\nSolution Summary\n\nWe consider the limit of a given function f(x,y) of two variables x and y as the point (x,y) approaches a given point (a,b). By taking two different paths for approaching (a,b) ,we show that f(x,y) approaches two different values.This allows us to conclude that the limit in question does not exist."}
{"text": "Retrieved from https://www.physicsforums.com/threads/integration-by-substitution-its-been-a-while.289116/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntegration By Substitution It's Been A While\n\n  1. Feb 1, 2009 #1\n\n    It's been god knows how long since I've had to use integration by substitution. I've totally forgotten it. I am trying to integrate to solve for the value of an electric field at a given point. The integral I am trying to solve is:\n\n    (2kz/4(pi)(epsilon_0)*1/(z^2+x^2)^(3/2) dx.\n\n    I know the answer is (2kz/4(pi)(epsilon_0)*(x/[z^2(z^2+x^2)^(1/2)]\n\n    2. Relevant equations\n\n    I'm sure I have to set u=(z^2+x^2). This makes du = 2x.\n\n    3. The attempt at a solution\n\n    I'm confused as to what to do now. The equation I'm integrating doesn't have an x in it anywhere. I don't think I can say du/2x=dx because I will have x's and u's in the integral, which is no good. However, I can't just ignore it.\n\n    Also, how did that z^2 get in there on the bottom? z is a constant in this integration and since u = z^2+x^2, the z-term drops right out. I feel terribly lost.\n  2. jcsd\n  3. Feb 1, 2009 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    That's really confusing. Why don't you just post the actual problem you are working on and how you tried to solve it?\n  4. Feb 1, 2009 #3\n    Sure thing.\n\n    I'm trying to find the electric field at an arbitrary distance z above a straight line segment, where the arbitrary distance z is measured above one of the endpoints of the line segment.\n\n    Relevant Equations:\n\n    We are given that the electric field of a line charge is [tex]\\frac{1}{4 \\pi \\epsilon_0} \\int_P \\frac{\\lambda (R)}{r^2}dl[/tex].\n\n    Attempt At Solution.\n\n    A little element of the electric field is going to be pointed in two directions. One will be in the z-direction. The other will be in the direction parallel to the line. Using the geometry of the problem, I found that\n\n    [tex] dE=\\frac{1}{4 \\pi \\epsilon_0}\\frac{\\lambda dx}{r^2}(cos(\\theta) \\textbf{z}+sin(\\theta)\\textbf{x})=\\frac{\\lambda}{4 \\pi \\epsilon_0}\\frac{\\lamda dx}{r^3}(z\\textbf{z}+x\\textbf{x})[/tex], where the bold indicates unit vectors.\n\n    I split this up into two integrals. This is where I have to integrate by parts, and where I get stuck. I have for instance, one integral which is [tex]\\frac{1}{4 \\pi \\epsilon_0} \\int_0^L \\frac{2 \\lambda z}{(z^2+x^2)^{3/2}}}dx[/tex].\n\n    I set my u = (z^2+x^2) and my du is then 2xdx. I am confused because there is no x in my numerator, and I can't just say du/2x=dx because then I am going to have both x's and u's in my equation when I integrate it.\n  5. Feb 2, 2009 #4\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Well, if [itex]u = (z^2+x^2)[/itex], then [itex]2x=2\\sqrt{u-z^2}[/itex] right?....but I don't think that makes the integral any easier!\n\n    Try the substitution [tex]u=\\frac{x}{\\sqrt{x^2+z^2}}[/tex] instead :wink:\n  6. Feb 2, 2009 #5\n    Ah, I got it, I think.\n\n    If I use the u-substitution you suggest, I get [tex]du=\\frac{1}{\\sqrt{x^2+z^2}}-\\frac{x^2}{(x^2+z^2)^{3/2}}dx[/tex], which, getting a common denominator yields:\n\n\n    So [tex]\\frac{du}{z^2}=\\frac{dx}{(x^2+z^2}dx[/tex]\n\n    My integral is then just [tex]\\frac{\\lambda z}{4 \\pi \\epsilon_0}\\int_a^b \\frac{du}{z^2}[/tex] which, after re-substituting for u back into x's, and plugging in the bounds 0 and L, I get\n\n    [tex] \\frac{1}{4 \\pi \\epsilon_0} \\frac{\\lambda z L}{z^2(z^2+x^2)^{3/2}}[/tex].\n\n    Thanks, though I still wonder how I would have thought of that particular u-substitution on my own!\n\nHave something to add?\n\nSimilar Discussions: Integration By Substitution It's Been A While\n  1. Integral substitution? (Replies: 3)\n\n  2. Integral substituting (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/group-theory-question.198217/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nGroup theory question\n\n  1. Nov 14, 2007 #1\n\n    If p is a prime and G is group of order p^2, then show that G is abelian.\n\n    2. Relevant equations\n\n\n    3. The attempt at a solution\n\n    I first consider Z(G), the centre of G. Since it is a normal subgroup of G, then by Lagrange's Theorem, |Z(G)| divides |G|. Hence |Z(G)| = 1, p or p^2. We know that Z(G) not the trivial subgroup (proof already given) hence it must be of order p^2 or p.\n\n    If |Z(G)| = p^2, then Z(G) = G and hence by definition it is abelian.\n\n    If |Z(G)| = p, then .... well this is where I am stuck! :(\n\n    Please help!\n  2. jcsd\n  3. Nov 14, 2007 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Consider an element q that is not in Z(G). How big is the subgroup generated by q and Z(G)?\n  4. Nov 14, 2007 #3\n    In the case of your argument, if [itex] |Z(G)| = p [/itex] then we have that\n\n    [itex]\\frac{|G|}{|Z(G)|} = p[/itex] which we can't have.\n\n    So on the other hand, we know that if [itex] \\exists a \\in G[/itex] such that [itex] o(a) = p^2[/itex] where [itex] o(a) [/itex] is the order of a, then [itex] G = C_{p^2} [/itex]. Thus we can assume that every non-identity element has order p, since the order of the elements must divide the order of the group.\n\n    Thus consider a non-identity element of G, say a, and the subgroup it generates. Furthemore, consider another non-identity element, say b, that is not in [itex]<a>[/itex]. Such an element is guaranteed to exist since [itex]o(a) = p \\Rightarrow |<a>|\\neq|G| [/itex]. Consider the subgroup generated by [itex]b[/itex].\n\n    What can we say about the order of [itex] <a> [/itex] and the order of [itex] <b> [/itex] ?. What can we say about their intersection? What can we say about the order of their product?\n  5. Nov 14, 2007 #4\n    If we assume that every non-identity element has order p, then <a>, <b> would have order p also. Wouldn't their intersection be the empty set if b is defined as an element not in <a>? Sorry I'm not sure where I'm supposed to go with this.\n  6. Nov 14, 2007 #5\n    That's precisely correct. They're intersection is empty, and so\n\n    [tex] |<a> \\times <b>| = \\frac{|<a>||<b>|}{|<a>\\cap<b>|} = |<a>||<b>| = p^2 [/tex]\n\n    Thus, since [itex] a \\in G, \\; b\\in G, \\; \\text{ and } |<a> \\times <b>|=|G| [/itex] then\n\n    [tex] <a> \\times <b> = G [/tex]\n\n    Now the question is, what is [itex] <a> \\times <b> [/itex] isomorphic to?\n  7. Nov 14, 2007 #6\n    for any group G, if G/Z(G) has prime order, then G/Z(G) is cyclic, hence G is abelian\n  8. Nov 14, 2007 #7\n    Cyclic group of order p^2?\n  9. Nov 14, 2007 #8\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Assume G is non-abelian and go by contradiction.\n\n    And you'll need ircdan's statement.\n\n    It's a nice question.\n  10. Nov 14, 2007 #9\n    [tex] C_p \\times C_p [/tex]\n  11. Nov 14, 2007 #10\n    Via this method we've actually proved something stronger than the actual question. Namely that every group of order [tex] p^2 [/tex] is isomorphic to either [itex]C_{p^2} \\text{ or } C_p \\times C_p [/itex]\n  12. Nov 14, 2007 #11\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    This question pretty much does that.\n  13. Nov 14, 2007 #12\n    Is [tex]C_p \\times C_p[/tex] also cyclic? How do you know it is abelian?\n  14. Nov 14, 2007 #13\n    C_p x C_p is not cyclic but it is abelian since each factor is\n  15. Nov 14, 2007 #14\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    This question tells us that all groups of order p^2 are abelian.\n\n    What kind of abelian groups are there of order p^2?\n\n    Well, it can be cyclic if it has an element of order p^2 if not, then all the elements must be of order p (Lagrange's Theorem). And you work from there.\n  16. Nov 14, 2007 #15\n    Thanks for all the help! I've written the proof both ways and they seem to be pretty much equivalent.\n\n    I'm not sure if I should open a new thread for this but I would appreciate some help on another related question:\n\n    \"If G is a group of order 48 then show that it is not simple\"\n\n    Now |G| = 2^4 * 3. I'm thinking it would be a similiar argument to how you show groups of order (p^2 * q) are not simple, but in all honesty I don't even understand the proof for that very well.\n\n    I guess if you apply Sylow's theorem, then clearly there are Sylow p-subgroups of order 2^4. Are these p-subgroups normal? If so, how would you go about showing this?\n  17. Nov 14, 2007 #16\n    A theorem by Burnside states that the center of a finite p-group is non-trivial. So if |G|=p^2 and Z(G)!=G choose x in G so that x not in Z(G). We know by divisibility that Z(G) >= p (Burnside). But that means the centralizer C(x) must be G a contradiction. So Z(G)=G.\n  18. Nov 15, 2007 #17\n    you can produce a counting arguement\n  19. Nov 15, 2007 #18\n    Can you elaborate on that? (I assume you are talking about |G| = 48 not being simple)\n  20. Nov 15, 2007 #19\n    I imagine you should exploit the class equation\n  21. Nov 15, 2007 #20\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    How many of these can we have? Let n be the number of Sylow-2's. Then n=1(mod2) and n|3. This leaves us with n=1 or n=3. If n=1, we're done, because this implies the unique Sylow-2 is normal in G (why?). So suppose n=3. One possible way you can proceed from here is via group actions. Let G act on the set X of 3 Sylow-2's by conjugation. This induces a nontrivial homomorphism from G into Sym(X). What is its kernel? (Don't think too hard about what the kernel actually is; think about what kernels are, and how they could be relevant to proving the non-simplicity of G.)\n    Last edited: Nov 15, 2007\n\nHave something to add?\n\nSimilar Discussions: Group theory question\n  1. Group theory question (Replies: 5)\n\n  2. Group theory question (Replies: 3)"}
{"text": "Retrieved from http://mathoverflow.net/questions/82332/seeking-a-solution-algorithm-to-the-3-partition-problem\nText:\nTell me more \u00d7\n\nI need to divide 48 pieces of jewelry between 3 inheritors so as to give equal, or nearly equal value, to each. I have learned that this is called the 3-partition problem. I solved it for 9 pieces of jewely by exhaustive enumeration (some 19,000 possibilities) in a spreadsheet (LibreOffice Calc). No big deal. But all 48 pieces becomes a big deal.\n\nI don't actually need a perfect solution. A heuristic algorithm would suffice if it were acknowledged as an acceptable solution scheme by some set of professionals; programmers, estate settling lawyers, etc. In other words using a technique recognized as \"good enough\" will be good enough for my purpose.\n\nThis question is also posted on StackOverflow. They suggested I post here.\n\nThank you, David\n\nshare|improve this question\nThe problem is NP-complete to find an exact 3-partition; see the short Wikipedia description: So you have two choices: An exhaustive search of all possibilities, or approximation algorithms. \u2013\u00a0 Joseph O'Rourke Dec 1 '11 at 1:58\nTo: Joseph O'Rourke: it is the approximation algorithms that I seek. Where is one described? I've been on mathisfun and codingthewheel and don't find it there. \u2013\u00a0 Grabs At Strawberries Dec 1 '11 at 3:54\nThe first thing I'd do is to take a brief look at how the appraised values are distributed. You may find that it is obviously problematic (for example, if there are just a handful of exceptionally valuable pieces, which can't themselves be divided evenly into thirds, and the remaining pieces can't make up the difference). If you are lucky, there will be many pieces with roughly comparable values. In that case, simple randomized heuristics probably get you close enough for practical purposes (since, unless you actually have an offer on the table, the appraisals will have some error anyway). \u2013\u00a0 Henry Cohn Dec 1 '11 at 4:34\nOne difficulty in giving an abstract answer is that it's not clear how to model this. For example, one could try to bound the worst-case approximation ratio; this is an interesting theoretical question, but I'm not convinced it would shed much light on what you can do in practice. It really depends on the numbers. \u2013\u00a0 Henry Cohn Dec 1 '11 at 4:40\nI suggest you hire a mathematical consultant. Mathematicians have put in the hard yards to get to where they can solve this kind of problem; they deserve to be paid for their specialist skills. \u2013\u00a0 Gerry Myerson Dec 1 '11 at 5:03\nshow 5 more comments\n\n2 Answers\n\nThere exists a pseudo-polynomial time dynamic programming solution to this problem, for which running time and storage complexity depend on the sum of costs of the pieces of jewelry, denoted $S$. If the sum of costs, $S$, is small then the algorithm would be practical as its storage is $O(S^2)$ and its running time is $O(S^2N)$, $N$ being the number of pieces (48 here).\n\nTo get a sense of the algorithm take a look at the Subset sum problem Wikipedia page--dynamic programming solution. This concerns finding a subset of items which sums to a particular cost. Clearly you can solve the 2-partition problem by using the subset sum solutions, i.e., by enumerating over all the potential subset sums, and choosing the one that you prefer for any reason.\n\nNow generalizing to 3-partition is straightforward. You basically solve the double-subset sum problem. You store $Q(i,s, t)$ to be the value (true or false) of \"whether there are two disjoint subsets of $x_1, \\ldots, x_i$ which respectively sum to $s$ and $t$\". You can easily update $Q(i, s, t)$ by adding new items. Again one can enumerate over the potential $Q(N, s, t)$'s and choose the one that is considered best.\n\nObviously even if $S$ is large, the costs can be quantized using larger cost units, which results in a measurable upper bound on the error. This also can be used combined with the solution of Brendan McKay to guide a local search algorithm.\n\nshare|improve this answer\nAs a (perhaps useless) supplement to this description, Exercise 6.25 in the Dynamic Programming chapter of Vazirani's algorithms textbook (PDF: asks to devise \"a dynamic programming algorithm for 3- PARTITION that runs in time polynomial in $n$ and in\" $S$. [p.197] \u2013\u00a0 Joseph O'Rourke Dec 1 '11 at 20:50\nadd comment\n\nTo get a good approximation, I suggest a local refinement algorithm. Define some success measure (like the maximum value of a share minus the minimum value). Start with any distribution into three shares.\n\nNow move a small number of pieces into different shares if they improve the success measure. Keep doing that until no such improvement is possible. With 48 items, you should be able to find a partition where no movement of 4 or fewer items improves the success measure, and this will be a fairly good solution.\n\nStart with different random partitions to see if you get the same final result. If so, there is a fair chance (in practice, not in theory!) that you have the best solution. If you get multiple final results, you can at least choose the best one.\n\nA variation is to allow movement of a small number of pieces with low probability even if the success gets worse. Maybe the probability can depend on how much worse the success gets. This can get you out of local minima but you will never find the global minimum if you set the probabilities too high.\n\nMore sophisticated algorithms like simulated annealing, genetic search, and tabu search are out there and can be adapted to this problem.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/10854/subvalue-and-level/10868\nText:\nTell me more \u00d7\n\nI'm interested in the arguments of f in expressions like\n\n\nBy argument I mean what is here a, b and c. I would like to know the arguments and in what order they appear. For example, the order of the arguments in\n\n f[d]@(2 x f[b])@f[c]@f[q]\n\n\n {d, b, c, q}\n\nHow can I find this from the above expression? I tried to use Level[], but the Subvalue construction is hindering me.\n\nshare|improve this question\nWhat would be an appropriate title for this question? \u2013\u00a0 sjdh Sep 20 '12 at 12:01\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nHere is another way:\n\nCases[f[d]@(2 x f[b])@f[c]@f[q], f[x_] :> x, {-2}, Heads -> True]\nshare|improve this answer\nadd comment\n\nThis works:\n\nexpr = f[d]@(2 x f[b])@f[c]@f[q];\nExtract[expr, Position[expr, f[_]], First]\n   {d, b, c, q}\n\nNote that Extract[] and Position[] are able to handle expressions with any head, not just lists.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/42818/stable-orthogonalization-procedure?sort=newest\nText:\nTell me more \u00d7\n\nAt a high level, my question is the following: given a set of $k$ vectors in Euclidean space which are pairwise \"almost orthogonal\", can one find a set of $k$ orthogonal vectors which are pairwise close to the original ones? This could be seen as a stable version of Gram-Schmidt orthogonalization, in which, under the promise that the original set of vectors is not too far from being orthogonal, one has the guarantee that they do not need to be moved too much in order to become orthogonal.\n\nMore precisely, assume given vectors $v_i$, $i=1,\\ldots,k$ in a real (or complex) $k$-dimensional space, such that $\\sum_{i\\neq j} \\langle v_i,v_j\\rangle \\leq \\epsilon k$ ($\\epsilon$ should be understood as an arbitrarily small constant, or it could even be $o(k)$ if needed -- the weaker the assumption the better). Then, does there exist a set of orthogonal vectors $w_i$ such that $\\sum_i \\|w_i - v_i\\|^2 \\leq \\epsilon' k$? (The norm is the usual Euclidean norm.) The interesting question is whether one can get an $\\epsilon'$ which depends on $\\epsilon$ only, not on $k$.\n\nA related question (the one I am originally most interested in), is that of orthogonalizing $d$-dimensional projector matrices $P_1,\\ldots,P_k$: assume $\\frac{1}{d} \\sum_{i\\neq j} \\langle P_i,P_j \\rangle \\leq \\epsilon$ (where now the inner product is the trace inner product), can you find orthogonal projectors $Q_i$ such that $\\frac{1}{d}\\sum_i \\|P_i-Q_i\\|_F^2 \\leq \\epsilon'$? (Here the norm is the Frobenius norm, the sum of squares of the coefficients.) So far using various iterative procedures I can only get a bound where $\\epsilon' = poly(\\log k) \\epsilon$, but I would like to know if the dependence on $k$ can be removed.\n\nshare|improve this question\nSo in a way Graham-Schmidt may be seen as the greedy approach to this question: Pick the \"new\" n-th vector as the vector on the orthogonal complement of the span of the already picked n-1 vectors closest to the given n-th vector. \u2013\u00a0 HenrikR\u00fcping Oct 19 '10 at 19:22\nYes. Unfortunately it is not \"stable\", in the sense that as the first t vectors get orthogonalized, the overlap of the remaining vectors on the span of the t orthogonal vectors will grow with t, so that it \"costs\" more and more (in terms of distance moved) to make each subsequent vector orthogonal to the previous ones. In my calculations this typically leads to a linear or quadratic dependence of $\\epsilon'$ on k. \u2013\u00a0 Thomas Oct 19 '10 at 19:29\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nUse a Procrustes rotation of the standard basis vectors onto your vectors. This gives the set of orthogonal vectors with the smallest sum of squares of distances to your vectors.\n\n\"The orthogonal Procrustes problem is a matrix approximation problem in linear algebra. In its classical form, one is given two matrices A and B and asked to find an orthogonal matrix R which most closely maps A to B.\"\n\nIn your case you want to find the orthogonal matrix R which most closely maps the standard basis to your matrix. Something like the columns of R should then be the set of orthogonal vectors which are nearest to your vectors, where 'nearest' is in the sense of sum of squares.\n\nshare|improve this answer\nSorry, I should have mentioned all vectors are unit. I am not familiar with Procrustes rotations; is there a good reference to start learning about them (in relation to my original problem)? \u2013\u00a0 Thomas Oct 19 '10 at 19:45\nThat turned out to work pretty well also for the case of the projectors I was mentioning, thanks! \u2013\u00a0 Thomas Oct 21 '10 at 4:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/106828/define-lim-x-rightarrow-0-frac1x-int-0x-et2-dt-what-is-the/135274\nText:\nTake the 2-minute tour \u00d7\n\nThis question is in the section about definite integrals and the task is to calculate the limit. My first idea was division-by-zero but I am very unsure about this. What is the goal here? I then thought that should I investigate things by different limits?\n\nI have simplified this question but similar questions on the page 548 6* here.\n\nshare|improve this question\nThe goal is to see if you have understood the material covered till the fundamental theorem of calculus. \u2013\u00a0 Aryabhata Feb 7 '12 at 22:15\nWhich book did you get this from? \u2013\u00a0 Aryabhata Feb 7 '12 at 22:22\nSure you've seen this theorem if you've gotten that far? The limit is the derivative of $\\int_0^x \\exp t^2 dt$ at $x=0$. \u2013\u00a0 anon Feb 7 '12 at 22:29\n\n3 Answers 3\n\nup vote 8 down vote accepted\n\nYou may re-write what you have as\n\n$$ \\lim_{x\\to 0}\\frac{1}{x-0}\\int_0^x e^{t^2}\\,dt. $$\n\nIf you haven't seen it before,\n\n$$ \\frac{1}{x-0}\\int_0^x e^{t^2}\\,dt $$\n\nis the average value of the function $e^{t^2}$ over the interval $[0,x]$. Now, imagine that $F'(t)=e^{t^2}$. Then by the Fundamental Theorem of Calculus we have\n\n$$ \\int_0^x e^{t^2}\\,dt=F(x)-F(0). $$\n\nThus, your limit becomes\n\n$$ \\lim_{x\\to 0}\\frac{F(x)-F(0)}{x-0}. $$\n\nThis is just the definition of the derivative of $F$ evaluated at $x=0$. But, we know what the derivative of $F(x)$ is, namely $e^{x^2}$.\n\nshare|improve this answer\nWhat about if the other limit is of different form such as $x^{7}$, $ln(x)$ --? Then, it is not exactly the theorem (or the average -analogy). I think I need to do some adjusting or investigation of the limit then somehow? \u2013\u00a0 hhh Feb 7 '12 at 22:53\nFor example, this is not for the def. of derivative so do I need to somehow adjust it? $$\\lim_{x\\rightarrow 3} \\frac{x^{2}-F(9)}{x-3}$$ \u2013\u00a0 hhh Feb 7 '12 at 22:59\n@hhh: Do you mean that to be $F(x^2)$? In that instance, you've got some chain rule stuff going on. \u2013\u00a0 Joe Johnson 126 Feb 8 '12 at 14:17\n\nHINT: Let $$f(x)=\\int_0^x e^{t^2}dt\\;.$$\n\n  1. What is $\\lim\\limits_{x\\to 0}f(x)$?\n  2. What is $f\\,'(x)$?\n  3. L\u2019Hospital\u2019s rule.\nshare|improve this answer\nPerhaps the downvoter would care to explain? The suggested argument is in fact both correct and easy, and the answer has the virtue of not completely doing the homework problem for the OP. \u2013\u00a0 Brian M. Scott Feb 7 '12 at 22:59\nI don't see the point of #3 but I don't get the downvote either. This is basically what I would have said. \u2013\u00a0 anon Feb 7 '12 at 23:03\n@anon: The point of (3) is that you don\u2019t have to recognize this as the limit of a difference quotient: you can also see it simply as a $0/0$ indeterminate form. \u2013\u00a0 Brian M. Scott Feb 7 '12 at 23:07\nIn my opinion, that would defeat the point of the exercise. \u2013\u00a0 anon Feb 7 '12 at 23:10\n@anon: I take a different view of the point of the exercise: I think that the point is the fundamental theorem, as in my point (2). \u2013\u00a0 Brian M. Scott Feb 7 '12 at 23:13\n\ni think that our integral should be understood as the mean value of the exponential on the interval $ (0,x)$ since $ x \\rightarrow 0 $ the mean value on the interval $ (0,0) $ is just $ exp(0)=1$ to $1$ is the answer\n\nshare|improve this answer\nDid you ask the author of the question about his intended method of solution/interpretation? \u2013\u00a0 The Chaz 2.0 Apr 22 '12 at 13:33\n+1 good observation, indeed that is the straightforward interpretation. \u2013\u00a0 hhh Apr 22 '12 at 14:06\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/121561/pigeonhole-principle-question?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThere is a row of 35 chairs. Find the minimum number of chairs that must be occupied such that there are some consecutive set of 4 chairs or more occupied.\n\nI would like to have some hints as to approach this problem. This isn't for homework or anything, I'm just curious as to what would be the best strategy for this problem.\n\nshare|improve this question\nI'd say worst case is groups of $3$ occupied with $1$ open seat between them. So that's $9 \\times 3$ occupied seats and $8 \\times 1$ open seats, i.e. $27$ occupied seats. So I think you need $28$ occupied seats. \u2013\u00a0 TMM Mar 18 '12 at 1:55\nSounds like the answer. Please add it! \u2013\u00a0 user21436 Mar 18 '12 at 2:09\nUhm the best strategy is to try and use the pigeonhole principle? i.e. the title you gave the post. So are you asking how to use pigeonhole? \u2013\u00a0 john w. Mar 18 '12 at 2:50\nSomehow everybody understands that the second sentence contains a negation (the word \"not\"), but unless my eyesight is really betraying me, there is no such negation. For me the answer is obviously $4$. \u2013\u00a0 Marc van Leeuwen Mar 27 '13 at 14:17\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nFor every $4$ seats you need to keep at least $1$ open to not have $4$ consecutive chairs occupied. So divide the row in sets $S_k = \\{4k + 1, 4k + 2, 4k + 3, 4k + 4\\}$ for $k = 0, \\ldots, 7$ and $S_8 = \\{33, 34, 35\\}$. For each set $S_0, \\ldots, S_7$ you need to keep one seat open, so you need at least $8$ open seats to not have a sequence of $4$ occupied seats. This maximum can also be achieved, by leaving seats open at positions $4k$, for $k = 1, \\ldots, 8$.\n\nWith respect to applying the pigeonhole principle: If you do have more than $35 - 8 = 27$ seats filled, then you have at least $25$ seats filled for $S_0, \\ldots, S_7$. Since $25 / 8 > 3$, by the pigeonhole principle one of them must have at least $4$ seats occupied. But then you get a sequence of $4$ occupied seats. So if $28$ or more seats are occupied, you always have $4$ or more consecutive occupied seats.\n\nshare|improve this answer\nThere are 8 pigeonholes.We need to find the minimum pigeons so that at least one pigeon hole contains 4 pigeons.In generalized pigeon hole principle if there are n pigeons and k holes at least one pigeonhole should have $\\lceil n/k \\rceil$ pigeons.Therefore if we have $\\lceil 25/4 \\rceil$=4.So why isn't the answer=25 but 28? \u2013\u00a0 sam_rox Nov 18 '14 at 3:55\n:typo not $\\lceil 25/4 \\rceil$ but $\\lceil 25/8 \\rceil$ \u2013\u00a0 sam_rox Nov 18 '14 at 4:02\nHi Sam. The reason is that there are 35 = 4\u00d78+3 seats. You can apply the pigeonhole to the first 32 seats like you did, so you know that out of those 32 seats, it is possible to fill 24 seats. Add to that the other 3 seats, and you see it is possible to fill 27 seats. (But not 28.) \u2013\u00a0 TMM Nov 19 '14 at 17:26\n\nThis is not really an answer ........Fill the pigeonholes in blocks of 3 with 1 separator (shown as ~) 123~456~789~101112~131415~161718~192021~222324~252627 You can see that 27 is the max that can be occupied with 4 in a row. So if 28 or more seats are occupied, you always have 4 or more consecutive occupied seats. I just made many people's explanation into that...........What is The GENERALISING statement for this type of pigeonhole questions?\n\nshare|improve this answer\nAs you mention, this \"is not really an answer\". Perhaps you have the germ of an idea for asking a generalized version of the question, although it isn't quite polished yet. However the Answer box is only for answers. \u2013\u00a0 hardmath Mar 27 '13 at 13:38\nThis really is an answer, but needs a bit of spit and polish. Wellcome! But consider that this site looks for complete, closed (and we also wish for brilliant, no harm in wishing so near Easter ;) answers to questions. Please try for a more complete answer next time. \u2013\u00a0 vonbrand Mar 27 '13 at 13:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/77762/equivalence-of-a-vector-norm-being-absolute?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to show that a vector norm $\\|\\cdot\\|$ being absolute ($\\|x\\| = \\|\\;|x|\\;\\|)$ is equivalent to showing that $\\|x'\\| = \\|[\\alpha_1x_1\\ldots\\alpha_nx_n]^T\\| = \\|x\\|$ for all $x\\in\\mathbb{C}^n$ and $|\\alpha_i| = 1$ for all $\\alpha_i$. I've shown that if $\\|\\cdot\\|$ is absolute, then the given statement follows, but I'm having trouble showing the reverse.\n\nFrom my proof of the first part, I know that $|x'| = |x|$, so I can either show that $\\|x'\\| = \\|\\;|x'|\\;\\|$ or take the direct route of showing that $\\|x'\\| = \\|\\;|x|\\;\\|$. Either way, I don't see how to proceed. Intuition tells me that the crucial step will revolve around using the fact that $|\\alpha_i| = 1$, so that's where I've started, but no luck so for. I'll update if I find anything more out, but a nudge in the right direction would be much appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet $x\\in\\mathbb{C}$ be arbitrary and specialize (pick out) each $\\alpha_i$ individually such that $\\alpha_ix_i=|x_i|$ and the modulus is unity ($|\\alpha_i|=1$) for each $i$ - the given hypothesis then implies $\\|x'\\|=\\|[\\alpha_ix_i]^T\\|=\\||x|\\|.$\n\nshare|improve this answer\nDoesn't this violate the hypothesis that this must hold for all $\\alpha_i$? I read \"...for all $x$ and all $y$...\" to mean any combination of arbitrary $x$ and $y$ \u2013\u00a0 brc Nov 1 '11 at 6:39\n@brc: You get $\\|x'\\|=\\|x\\|$ by hypothesis. Also, since it holds for any $|\\alpha_i|=1$, you're free to make them whatever you want in order to continue investigating - it changes nothing. By choosing them so $\\alpha_ix_i=|x_i|$ (see how this is possible) you can check directly that $\\|x'\\|=\\||x|\\|$. Hence $\\|x\\|=\\||x|\\|$. \u2013\u00a0 anon Nov 1 '11 at 6:43\nThat makes sense. The explanation is/was clear, I was just worried about the assumptions made to derive it. Thanks. \u2013\u00a0 brc Nov 1 '11 at 6:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/199460/distribution-of-sum-of-absolute-value-of-random-variable\nText:\nTake the 2-minute tour \u00d7\n\nI'm wondering if there's a distribution $\\Gamma$ such that if we draw $x_i \\dots d_n$ iid from $\\Gamma$, then $\\sum_{i=1}^n |x_i|$ has a nice distribution. I thought maybe the normal distribution, since then the absolute value would be half-normal, but I'm not sure what the distribution of the sum of half-normal variables are.\n\nshare|improve this question\nIf you're willing to consider a distribution that's supported on the positive reals to begin with, there's a nice expression for the distribution of a sum of independent exponential random variables (en.wikipedia.org/wiki/Erlang_distribution) \u2013\u00a0 Julian Rosen Sep 20 '12 at 4:18\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nIf i.i.d. random variables $X_1, X_2, \\ldots, X_n$ have Laplacian density $$f(x) = \\frac{1}{2}\\exp\\left(-|x|\\right), -\\infty < x < \\infty,$$ then $|X_i|$ are i.i.d. exponential random variables with mean $1$, and $\\sum_{i=1}^n |X_i|$ is a Gamma random variable with mean $n$ and order parameter $n$. This is effectively the same result as the one in the comment by @PinkElephants but without the requirement of support on the positive reals only (which makes the distinction between $X_i$ and $|X_i|$ irrelevant.)\n\nshare|improve this answer\nI think the cases given thus far all satisfy the conditions for the central limit theorem. So for large n there is a normal distribution approximation that should be pretty good and can be normalized so that a standard normal approximation can be used. \u2013\u00a0 Michael Chernick Sep 20 '12 at 19:48\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/129195/problem-in-valuation-theory\nText:\nTake the 2-minute tour \u00d7\n\nFind $\\alpha\\in \\mathbb{Q}$, such that $v_2(\\alpha-1/3)\\ge 2$, $v_3(\\alpha-1/2)\\ge 3$ and $|\\alpha-1|_\\infty<1/2$, where $v_p$ is the $p$-adic exponential valuation and $|\\cdot|_\\infty$ is the usual absolute value.\n\nThanks in advance!\n\nshare|improve this question\nIs this homework? What have you tried? \u2013\u00a0 Alon Amit Apr 8 '12 at 6:45\n@Alon Amit, thanks for the comment. I have tried to do some 3-adic and 2-adic expansion for 1/2 and 1/3, respctively, then I may find \u03b1 by the Chinese Remainder Theorem. But I am confused with the expansions, since what I have got is quite different from what I need. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 7:38\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe first two conditions are equivalent to $v_2(3\\alpha-1)\\ge2$ and $v_3(2\\alpha-1)\\ge3$. That is,\n\n$$3\\alpha-1\\equiv 0 \\mod 2^2\\Bbb Z \\qquad and \\qquad 2\\alpha-1 \\equiv 0 \\mod 3^3\\Bbb Z.$$\n\nRewriting each side (note $2^{-1}\\equiv 14\\mod 27$), we obtain\n\n$$\\begin{cases} \\alpha\\equiv -1 \\mod 4 \\\\ \\alpha \\equiv 14 \\mod 27. \\end{cases}$$\n\nBy CRT we have $\\alpha=95 \\mod 108$. We need $|p/q-1|_\\infty <1/2$ while $pq^{-1} \\equiv 95 ~(108)$. The two nontrivial factors of $95$ are $5$ and $19$; we have $5^{-1}\\equiv 65$ and $19^{-1}\\equiv 91 \\mod 108$. The latter is close to $5+108=113$ in the $|\\cdot|_\\infty$ metric, so we check that $|113/91-1|_\\infty<1/2$ indeed holds.\n\nThis gives $\\alpha=113/91$ as one solution.\n\nshare|improve this answer\n@Qiang: If you want to do it by hand it'd be the extendend Euclidean algorithm. Otherwise cheat and consult google for an online applet. :) \u2013\u00a0 anon Apr 8 '12 at 16:22\nAnon, a thousand thanks for your answer! I want to know if there some tricks in solving the equation such as $19x\\equiv1 \\mod 108$? P.S. I thought about the weak approximation theorem later on today, feeling the problem would be solved by the constructive proof. But I didn't really do it after I read your answer. It's a really great answer! \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:25\nAnon, I got it. Thanks. It seems that your solution is actually $\\alpha=113/91$. I'm sorry I cannot @you on this computer. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:37\n@Qiang: Oops, typo. Fixed, thanks. Don't worry, comments on a person's answer always ping that person, so @anon would be redundant here. \u2013\u00a0 anon Apr 8 '12 at 16:50\n\nHint: If $\\alpha = \\frac{a}{b}$ then\n\n$\\alpha-\\frac{1}{2} = \\frac{2a-b}{2b}$\n\n$\\alpha-\\frac{1}{3} = \\frac{3a-b}{3b}$\n\nYou need to make the first fraction divisible by a high power of 3, and the second divisible by a high power of 2. It's easiest to make $b$ relatively prime to 6 so you don't have to worry about the denominators. Pick such a $b$. Can you find an $a$ such that $2a-b$ is divisible by 27? Can you find an $a$ that makes $3a-b$ divisible by 4? Can you find an $a$ that does both? Finally, can you make $a$ close enough to $b$ so that $\\frac{a}{b}$ is not too far from 1?\n\nshare|improve this answer\nAlon, thanks for your hint! I will try that. Later on today, I found that the weak approximation theorem will be useful here. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/198129/perfect-squares\nText:\nTake the 2-minute tour \u00d7\n\nWonder whether anybody here can provide me with a hint for this one.\n\nIs $c=1$ the only case in which the expression $(c^2+c-1)(c^2-3(c-1))$\n\nreturns a perfect square?\n\nshare|improve this question\n@Ben, so, what's the cutoff? and, why? \u2013\u00a0 Gerry Myerson Sep 18 '12 at 6:43\n@Ben, my experience with people at zero percent is that they are unaware of the accept mechanism and are grateful when it is pointed out to them. If they are aware of the mechanism and truly don't like any of the answers they've had on any of the questions they have asked, why would they keep asking questions here? \u2013\u00a0 Gerry Myerson Sep 18 '12 at 12:51\n@GerryMyerson: well, fair enough, but do you really think that Don Antonio's original comment was helpful in that regard? \u2013\u00a0 Ben Millwood Sep 18 '12 at 13:27\n@Ben, I'm not convinced that anything in this discussion has been helpful, especially as it really belongs elsewhere. Maybe you want to begin a thread on meta, or contribute to one of the already-existing meta threads on accepting answers. \u2013\u00a0 Gerry Myerson Sep 18 '12 at 23:10\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nYes, $c=0$ is the only such value. For the proof, it is useful to let $c=x+1$. Then our expression becomes $$(x^2+3x+1)(x^2-x+1).$$ Note that $x^2-x+1$ is always odd. Any common divisor of $x^2+3x+1$ and $x^2-x+1$ must divide the difference $4x$. But such a common divisor must be odd, so any common divisor must divide $x$. But then it must divide $1$.\n\nThus $x^2+3x+1$ and $x^2-x+1$ are relatively prime. Since $x^2-x+1$ is always positive, it follows that if their product is a perfect square, each must be a perfect square.\n\nBut that can only happen when $x=0$. To prove this, use the fact that for any integer $u$, there is no perfect square strictly between $u^2$ and $(u+1)^2$. Since you asked for a hint, I will, unless you request otherwise, leave out the rest of the argument. It is short.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/173636/putnam-problem-partitioning-integers-with-generating-functions/173675\nText:\nTake the 2-minute tour \u00d7\n\nWe were given the following A-1 problem from the 2003 Putnam Competition:\n\nLet $n$ be a fixed positive integer. How many ways are there to write $n$ as a sum of positive integers, $$ n= a_1+a_2+ \\cdots + a_k$$ With $k$ an arbitrary positive integer, and $a_1 \\le a_2 \\le \\cdots \\le a_k \\le a_1+1$. For example, with $n=4$ there are 4 ways: 2, 2+2, 1+1+2, 1+1+1+1.\n\nI managed to do this by induction, showing that there are always $n$ ways to partition an integer in such a way. In my combinatorics class however, we always solved integer partitioning problems with generating functions and I have been unable to construct one for this problem. I was wondering if the math.stackexchange community could help me out with this and at least give me a nudge in the right direction.\n\n\nshare|improve this question\nfixed, thank you \u2013\u00a0 Jeremy Jul 21 '12 at 15:58\nI assume that first way should be a 4. \u2013\u00a0 Mike Jul 21 '12 at 19:29\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nRecall exponential notation for partitions: $a^b$ signifies $b$ occurrences of $a$ in the partition. (Exponential notation can be useful for seeing the generating functions.) In exponential notation, every partition satisfying your constraints are of the form $m^k (m+1)^l$. In your $n = 4$ example, the partitions are $4^1 5^0$, $2^2 3^0$, $1^2 2^1$, and $1^4 2^0$. Notice that the smaller number, $a_1$, must have exponent at least $1$, while successor can have exponent $0$.\n\nFor a fixed $m$, the contributions from partitions of the form $m^k (m+1)^l$ are given by the following generating function:\n\n$$(x^m + x^{2m} + x^{3m} + \\cdots)(1 + x^{m+1} + x^{2(m+1)} + \\cdots)$$\n\nThis simplifies to:\n\n$$\\frac{x^m}{1-x^m} \\frac{1}{1-x^{m+1}}$$\n\nSuch contributions come from any $m \\geq 1$, and of course, the contributions are disjoint. Thus the full generating function is:\n\n$$\\sum_{m \\geq 1} \\frac{x^m}{1-x^m} \\frac{1}{1-x^{m+1}}$$\n\nThis might already be too great a nudge, but the point is that you now obtain something you can manipulate. After some obvious $1 - x$ factorings and some telescoping, I get $\\frac{x}{(1 - x)^2}$, a generating function for $n$, as desired. Let me know if you get similar results or not.\n\nshare|improve this answer\n\nThis does not really answer the question in the sense that it uses no generating functions. But think of the problem of partitioning any positive number $n$ into a given number $k$ of parts, with $1\\leq k\\leq n$, as equitably as possible, in the sense that no two parts differ by more than $1$ (for if they did, one could make it more equitable by moving a unit from the larger to the smaller part). One solution is to first make $k$ equal parts of size $\\lfloor n/k\\rfloor$, and then if $k$ does not evenly divide $n$ distribute the remaining $n\\bmod k$ units by assigning them randomly to distinct parts, making those $\\lceil n/k\\rceil$ (since the order of parts are not taken into account, it makes no difference which). Can you see why there are no other such equitable partitions of $n$ into $k$ parts? Once this is established, these are clearly the $n$ possible solutions of your problem, one for every $k$.\n\nPersonally, with such a complete description of the solution available, I'm mentally blocked to think how generating functions could be used to find an alternative solution. In fact, I think that the requirement that relates the sizes of different parts (limiting their difference to at most $1$) does not easily translate into the world of generating functions (as one can do for independent conditions on the size of parts, or on multiplicities of a given size).\n\nshare|improve this answer\nThis is a very pleasing solution, one that I prefer to a generating function based solution. As noted in the answer I gave, these partitions are uniquely realizable in exponential form as $m^k (m+1)^l$, where $k \\geq 1$ and $l \\geq 0$. So, there is a generating function approach, and as far as I can tell, the answer can be obtained solely using generating functions. \u2013\u00a0 Hugh Denoncourt Jul 22 '12 at 17:16\nYes I prefer this as well and is essentially the reasoning I used in my original solution, but I was looking for a different way, really to brush up on generating functions. \u2013\u00a0 Jeremy Jul 22 '12 at 20:14\n\nConsider the integer $n$. How are it's partitions related to the partitions of those of integers $k$ where $1 \\le k < n$? Can you find a recursive function that relates these?\n\n(FYI, Project Euler, Problem 76 is a variation of this question.)\n\nshare|improve this answer\nBut the Euler problem doesn't have the restriction that $a_k \\le a_1+1$ \u2013\u00a0 Ross Millikan Jul 22 '12 at 15:40\n@RossMillikan Thus I qualified my statment with the word \"variation.\" \u2013\u00a0 Code-Guru Jul 22 '12 at 17:37\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/69964/why-does-a-meromorphic-function-in-the-extended-complex-plane-have-finitely-ma?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nLet $f$ be meromorphic in $\\mathbb{C} \\cup \\{\\infty\\}$. Why must $f$ have only finitely many poles?\n\nEdit: Renamed question following the comments.\n\nshare|improve this question\nThe title of the post asks a different question than the body and the question in the title is inaccurate: a meromorphic function in the complex plane MAY have infinitely many poles. The space $\\mathbb C\\cup\\{\\infty\\}$ is usually called the extended complex plane or the Riemann sphere. \u2013\u00a0 Did Oct 5 '11 at 9:12\nAs an explicit counterexample to the title question, consider $\\frac{1}{2 - e^z}$. \u2013\u00a0 Qiaochu Yuan Oct 5 '11 at 15:22\n\n1 Answer 1\n\nup vote 27 down vote accepted\n\nBy definition a pole is an isolated singularity, and so each pole has a neighborhood containing no other poles besides itself. Thus the set of all poles is discrete.\n\nThe set of poles is also closed, since its complement, the set of points at which $f$ is holomorphic, is open. (Any point where $f$ is holomorphic has a neighborhood restricted to which $f$ is holomorphic.)\n\nSince $\\mathbb C \\cup \\{\\infty\\}$ is compact, any discrete and closed subset is discrete and compact, hence finite.\n\n(Note that the reasoning of the first two paragraphs applies to a meromorphic function on any open subset of the Riemann sphere. E.g. a meromorphic function on $\\mathbb C$ can have infinitely many poles, but they must form a closed and discrete subset of $\\mathbb C$, and hence there can only be finitely many in any given bounded subset, i.e. they must accumulate at $\\infty$. A typical example is given by $f(z) = 1/\\sin z$.)\n\nshare|improve this answer\nAs an exercise, extend this example and reasoning to show all nonconstant holomorphic maps between compact complex curves are finite (ie all fibers are finite sets). \u2013\u00a0 AnonymousCoward Oct 5 '11 at 4:27\nI guess this is if you are thinking of meromorphic functions as holomorphic maps to the Riemann sphere. \u2013\u00a0 AnonymousCoward Oct 5 '11 at 4:30\nhere there is a proof in the first paragraph: math.wisc.edu/~dummit/sets/110b-1s.pdf \u2013\u00a0 wqr Mar 29 '13 at 3:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/130902/counting-the-number-of-squares-on-an-n-times-n-board\nText:\nTake the 2-minute tour \u00d7\n\nYesterday I was asked by a friend how many squares are in a chess board of $8\\times 8$. I thought about 64 immediately, but of course this is not the solution, there are much more.\n\nSo the number of squares is: $$8\\times 8 + 7\\times 7 + 6\\times 6 + 5\\times 5 + 4\\times 4 + 3\\times 3 + 2\\times 2 + 1\\times 1=1^2 + 2^2 + 3^2 + 4^2...+ 8^2$$\n\nI came across this formula: $$\\frac{n(n + 1)(2n + 1)} 6$$\n\nIt produces the sum of squares in $n\\times n$ board.\n\nMy question is, how did he reached this formula? Did he just guessed patterns until he reached a match, or there is a mathematical process behind?\n\nIf there is a mathematical process, can you please explain line by line?\n\nThanks very much.\n\nBtw: Couldn't find matching tags for this question, says I can't create.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe first step is to recognize that there are $8^2$ squares of size $1$ by $1$, $7^2$ squares of size $2$ by $2$ and so on. That justifies the total number being, as you say, $1^2+2^2+3^2+\\ldots 8^2$. Sums of powers are calculated by Faulhaber's formula. There are several ways to derive them. One way is to know or suspect that $\\sum_{k=1}^n k^p$ should be of degree $p+1$. So for squares, we want $\\sum_{k=1}^n k^2=an^3+bn^2+cn+d$. Then if we evaluate it at $n+1$, we get $\\sum_{k=1}^{n+1} k^2=a(n+1)^3+b(n+1)^2+c(n+1)+d$. Subtracting, we get $(n+1)^2=a((n+1)^3-n^3)+b((n+1)^2-n^2)+c((n+1)^1-n^1)$ and equating the coefficients gets the desired formula. You can prove the formula rigorously by induction\n\nshare|improve this answer\nYou should say, \"So for squares, $p=2$, ...\" and then later you have $k^{n+1} = ...$ when you mean $k^2 = ...$ \u2013\u00a0 Thomas Andrews Apr 12 '12 at 15:30\n@ThomasAndrews: Thanks. Fixed. For the second it should have been $(n+1)^2$ as that is the term added to the sum. \u2013\u00a0 Ross Millikan Apr 12 '12 at 15:55\nOops my bad, had a mistake, ignore please. Thanks for the help Ross! \u2013\u00a0 Novak Apr 12 '12 at 21:09\nI accidently marked this as solved, even though I believe your answer is correct. I'm in the stage of the substracting. Can you please write the stages after? All of these techniques are new to me, as I'm only in the 10th grade. What am I supposed to do with the coefficients? Thanks \u2013\u00a0 Novak Apr 13 '12 at 16:11\n@GuyDavid: If you take the last equation and expand the powers of $n+1$ you get $n^2+2n+1=3an^2+3an+a+2bn+b+c$ We need this to be true for all $n$, so $1=3a, 2=3a+2b, 1=a+b+c$ by equating the coefficients of each power of $n$. Solving gives $a=1/3, b=1/2, c=1/6$ Then if you check you can find $d=0$ \u2013\u00a0 Ross Millikan Apr 13 '12 at 16:27\n\nformula to calculate the square in $m \\cdot n$ order: $[n(n+1)x(3m-n+1)]/6$\n\nshare|improve this answer\nWhat does \"mxn order\" mean? A board of size $m\\times n$ perhaps? A brief sentence fragment of this kind is almost never a good answer. \u2013\u00a0 hardmath Jan 12 '14 at 18:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/58666/is-there-any-matrix-2-times-2-such-that-a-neq-i-but-a3-i?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI want to ask you this question: Is there any matrix $2\\times 2$ such that $A\\neq I$ but $A^3=I$. In my opinion: No. Thank you very much\n\nshare|improve this question\nI don't think it is a matter of opinions... \u2013\u00a0 \u00c1lvaro Lozano-Robledo Aug 20 '11 at 15:42\n\n2 Answers 2\n\nup vote 25 down vote accepted\n\nRotation by $2\\pi/3$ in the plane. Find the $2 \\times 2$ matrix that gives you this linear transformation.\n\nshare|improve this answer\nHi! How did you get that? \u2013\u00a0 Jozef Aug 20 '11 at 15:08\nImagine something when applied 3 times is the identity. How do you think? \u2013\u00a0 GEdgar Aug 20 '11 at 15:12\nOk, I'll think. thanks \u2013\u00a0 Jozef Aug 20 '11 at 15:20\n\nSince you don't specify what field the entries of this matrix have to come from, I could just take a diagonal matrix whose entries are $1$ and $\\omega$ where $\\omega=e^{2\\pi i /3}$ is a primitive cube root of 1 in the complex numbers.\n\nI guess you want real or integer entries though. If $A^3=I$ then the eigenvalues of $A$, that is, the roots of the characteristic polynomial, have to be third roots of unity. A primitive third root of unity satisfies $x^2+x+1=0$, so you could look for a matrix over the integers with that as a characteristic polynomial....\n\nshare|improve this answer\n+1. Nice! Your argument shows that this holds for any (nonzero) commutative ring. \u2013\u00a0 Pierre-Yves Gaillard Aug 20 '11 at 16:17\nAnother way to get an integral matrix that does the job it to take the automorphism of order $3$ of the torus, then the induced map on homology. In fact, there's an automorphism of order $6$ coming from the symmetry of the hexagonal tiling. \u2013\u00a0 Ryan Budney Aug 20 '11 at 16:35\n@Ryan: over $\\mathbb Z$, you have reduced to the problem to the (equivalent, I'm pretty sure---given enough technology) one of finding an automorphism of order $3$ of the torus :) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Aug 20 '11 at 22:07\nYes, $2\\times 2$ matrices of the integers of finite order all come from symmetries of the torus. This is a special case of what's called the Nielsen Realization problem -- which is solved, by-the-way. en.wikipedia.org/wiki/Nielsen_realization_problem Among other things, this gives you a fairly intuitive way to enumerate all the finite-order elements of $GL_2 \\mathbb Z$ (up to conjugacy). \u2013\u00a0 Ryan Budney Aug 20 '11 at 22:20\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/109782/are-sines-of-primes-dense-in-1-1?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $P$ be the set of all prime numbers. Is $\\sin(P)$ dense is $[-1,1]?$ How could we approach such a problem?\n\nshare|improve this question\n+1 Cool question. What have you tried? \u2013\u00a0 draks ... Feb 15 '12 at 22:40\nOn distributional principles it sure seems true. Very cool question. \u2013\u00a0 Brian B Feb 15 '12 at 22:53\n@draks Well, I know the proof that $\\sin(\\mathbb N)$ is dense. Actually, I just remembered it from my first course in analysis and thought about this problem. The proof of the case with $\\mathbb N$ doesn't seem to generalize, and it would be strange if it did I think. But I have simply no idea how to find another approach. \u2013\u00a0 user23211 Feb 15 '12 at 22:57\nI don't know the $\\sin(\\mathbb{N})$ proof (can you provide a link?), but would it help to think of $\\mathbb{N}$ as sum of all primes, semi-primes, k-almost primes? \u2013\u00a0 draks ... Feb 15 '12 at 23:09\n@draks There's a question about it on this site. There's a link to a paper with a proof there but I can't access it from my house so I'm not sure what's in it. \u2013\u00a0 user23211 Feb 15 '12 at 23:12\n\n1 Answer 1\n\nup vote 14 down vote accepted\n\nAccording to the Wikipedia article about the discrepancy of a sequence:\n\nThe sequence of all multiples of an irrational $\\alpha$ by successive prime numbers, $2 \\alpha$, $3 \\alpha$, $5 \\alpha$, $7 \\alpha$, $11 \\alpha$, ... is equidistributed modulo 1. This is a famous theorem of analytic number theory, proved by I. M. Vinogradov in 1935.\n\nWith $\\alpha = \\frac{1}{2 \\pi}$, this implies that $P$ is equidistributed modulo $2 \\pi$. Using this, and the continuity of the sine function, I think it is straightforward to show that $\\sin(P)$ is dense in $[-1,1]$ (although not equidistributed).\n\nshare|improve this answer\nAlso, the distribution of $sin(P)$ can be derived from the fact of the equidistribution of $P$ modulo $2\\pi$. \u2013\u00a0 Michael Lugo Feb 16 '12 at 5:37\nDan, could you post a link or a reference to Vinogradov's proof? \u2013\u00a0 user23211 Feb 16 '12 at 8:11\n@ymar, I couldn't find one with a search, but here it is claimed to be \"a byproduct of [Vinogradov's work on] the odd Goldbach conjecture\". It is said to have been proven in 1935 so probably the document can be narrowed down on that basis. \u2013\u00a0 Dan Brumleve Feb 16 '12 at 8:34\nHow about $P^{it}$? Is this dense over the unit circle? \u2013\u00a0 draks ... Jul 16 '12 at 14:40\n@draks The phase of $P^{it}$ varies extremely slowly for any fixed $t$, so there's no question that it is dense on the unit circle. One only needs $\\frac{p_{n+1}}{p_n} \\to 1$, which is slightly stronger than Bertrand's postulate and weaker than the Prime Number Theorem. \u2013\u00a0 Erick Wong Jan 6 '13 at 7:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/83732/number-of-ways-to-divide-a-stick-of-integer-length-n/83751\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have a stick of integer length $N$. I'm looking for (preferably closed-form) formula that gives the numbers of ways in which we can divide the stick into 3 parts with distinct integral lengths.\n\nEDIT: Also, every part in any division has unique length which does not appear in any other division of $N$.\n\nEDIT2: Based on coffeemath's answer, just to clarify, I'm interested in maximal number of sums $F(n)$. Given some $N$, count the number of all possible ways to divide stick $N$ into 3 parts such that the length of any part in any valid division is unique number between $1$ an $N$.\n\nshare|improve this question\nUnless your three parts must have integral length the answer is obviously $\\infty$ ;) \u2013\u00a0 N. S. Nov 19 '11 at 20:23\nYes the three parts have integral length :) \u2013\u00a0 Mohammad Al-Turkistany Nov 19 '11 at 20:26\nis $0$ a valid length? \u2013\u00a0 robjohn Nov 19 '11 at 20:34\nNo, $0$ is invalid length. \u2013\u00a0 Mohammad Al-Turkistany Nov 19 '11 at 20:38\nOrder does not matter. Here you can not count both triples. \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 10:06\n\n5 Answers 5\n\nup vote 6 down vote accepted\n\nThe array $$\\matrix{1&30&16&4&24&31&7&18&13&15&28\\cr17&2&32&20&5&14&23&8&29&22&11\\cr33&19&3&27&22&6&21&25&9&10&12\\cr}$$ uses each integer $1,2,\\dots,33$ exactly once; each column sums to $51$ (so we have $11$ ways to divide a stick of length $51$ into three parts); and, as a bonus, each row sums to $187$. There's a calculator that finds such things.\n\nIt has been proved that an $m\\times n$ magic rectangle exists provided $m$ and $n$ have the same parity and exceed $1$, with the sole exception of $m=n=2$. Taking $m=3$, this gives a way of dividing a stick of length $(9n+3)/2$ into three parts in $n$ ways, where $n$ is an arbitrary odd number exceeding $1$. It's pretty clear that stick can't be divided into three parts in more than $n$ ways; if you can do it in $k$ ways, then the numbers used must add up to $k(9n+3)/2$, but they must also add up to at least $3k(3k+1)/2$, and this is easily seen to imply $k\\le n$.\n\nIn short, if $N$ is of the form $(9n+3)/2$, $n$ odd, then the number of ways is $(2N-3)/9$.\n\nThe magic rectangles theorem has been proven, and constructions given, in many papers. One, which gives references to others, is Thomas R Hagedorn, Magic rectangles revisited, Discrete Mathematics 207 (1999) 65-72. Of course, the construction is a bit of overkill for this problem, as we don't really need a magic rectangle, we just need the columns sums to be equal and don't care about the row sums. Here's a simple construction which just solves the original construction, without giving a magic rectangle: $$\\matrix{1&2&3&4&5&6&7&8&9&10&11\\cr17&18&19&20&21&22&12&13&14&15&16\\cr33&31&29&27&25&23&32&30&28&26&24\\cr}$$ The pattern should be clear.\n\nEDIT: Now, suppose $N$ is not of the form $(9n+3)/2$ with $n$ odd. Let's write $n'=n+1$ and $n''=n+2$, and $${9n+3\\over2}\\lt N\\lt{9n''+3\\over2}$$ for some odd $n$. First, we note that $F(N)\\ge n$; if $N-(1/2)(9n+3)=k$, then just add $k$ to each entry in the bottom row in the construction above. and you have $n$ ways to divide $N$ into three parts. Second, note that $F(N)\\le(2N-3)/9$, by the argument a few paragraphs up about the sum of the numbers involved. So we get\n\n  1. If $(1/2)(9n+3)\\lt N\\lt (1/2)(9n'+3)$, then $f(N)=n$;\n\n  2. If $(1/2)(9n'+3)\\le N\\lt(1/2)(9n''+3)$, then $f(N)$ is either $n$ or $n+1$.\n\nIn summary, for every $N$, we have a formula for $f(N)$ which is exact in some ranges, and off by at most $1$ in other ranges. I suspect that the $n+1$ is generally correct in the situation where we haven't pinned things down. For example, for $N=20$, we have $$((9)(4)+3)/2\\lt N\\lt((9)(5)+3)/2$$ with the left inequality barely holding, and we get $f(20)=4$ from $$\\matrix{1&2&3&4\\cr5&7&8&6\\cr14&11&9&10\\cr}$$\n\nshare|improve this answer\nThanks for your answer. May be I'm missing something but does it work for any $N$ since I'm looking for $F(N)$ for any $N$. \u2013\u00a0 Mohammad Al-Turkistany Feb 6 '13 at 0:35\nNow that you've answered it, I feel like I understand the problem for the first time!! \u2013\u00a0 hardmath Feb 6 '13 at 2:16\n\nThis is an example of achieving $a$ distinct sums for a stick of length $6a$. No specific integer occurs twice in any particular sum, or twice in two different sums, or more succinctly all the numbers involved in the sums are distinct. I think that is what the OP means in the statement of the \"EDIT\".\n\nThe triples are $T_k=[k,3a-2k+1,3a+k-1]$ for $1 \\le k \\le a.$ Each triple then has sum $6a$ as desired, and the numbers used are all distinct. The middle numbers are going down by 2 as $k$ runs through $\\{1,2,...,a\\}$ with the last one being $3a-2a-1=a+1$, just after the highest number $a$ of the first term in any triple, and the first middle number is the largest of the middle numbers namely $3a-2\\cdot 1+1=3a-1,$ which is just before the lowest of the third elements of the triples, i.e. $3a+1-1=3a$. After that the third elements of the triples increase by 1 each step until reaching the highest third element of a triple, namely $3a+a-1=4a-1$ (So the last triple $T_a$ is $[a,a+1,4a-1]$).\n\nI don't know if better can be done for a stick of length $6a$, but I haven't been able to prove that; it may be that some other sheme of getting different triples could give more than $a$ sums for the $6a$ long stick. What I tried to do was to have the middle numbers going down two each time, and make the block of them start right after the end of the first block going up one each time, and end just before the final block which again goes up one each time. I can't think of a denser way to pack the triples.\n\nBy the way in my opinion, given the restriction of no number used twice in any one triple or even anywhere on the list of triples obtained, the OP should specify whether his question is to find the maximal number of sums say $F(n)$ for a given stick length $n$, or on the other hand maybe the OP is interested in a formula of type $F(n,t)$ for the number of ways a stick of length $n$ can be cut into three parts in $t$ ways, no repeated numbers. The latter would be a lot harder, and even a provable formula for $F(n)$ would seem difficult, at least to me.\n\nEDIT In this construction the \"middle numbers\" are spaced 2 apart. And in most cases more triples can be found in the unused numbers of the middle range. For example in the case $a=4$ with stick length $6a=24$, the $a=4$ triples formed using the construction are\n\n$[1,11,12],\\ [2,9,13],\\ [3,7,14],\\ [4,5,15]$\n\nThe unused numbers of the middle range make up another triple $[6,8,10],$ so that for stick length 24 one can find 5 triples.\n\nFor the case $a=10$ (stick length 60) besides the ten automatically constructed triples, the unused middle numbers are the nine even numbers from 12 through 28, and these can be put into the three triples $[12,20,28],\\ [14,22,24],\\ [16,18,26].$ So for stick length 60 the max number of triples is at least 13.\n\nshare|improve this answer\nI'm interested in maximal number of sums $F(n)$ \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 1:18\nThanks for the comment. This narrows down what you're looking for. I'll try for some provably maximal cases. I guess each sum may as well be in say increasing order, as rearrangements of a single sum cannot appear on the list because of the uniqueness requirement... \u2013\u00a0 coffeemath Feb 5 '13 at 1:28\nThanks for helping. \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 1:47\n\nI assume that your lengths have to be integers. Let $a, b,c$ be the lengths.\n\nYou want $a+b+c=N$ and $a,b,c$ pairwise distinct.\n\nSince the equation is homogeneous in $a,b,c$ we can find the solutions for which $a<b<c$ and then by permuting we get all solutions (thus the no of solutions will be multiplied by 6).\n\nNow this is a simple counting problem.\n\n$N=a+b+c < 3c$, thus $c > \\frac{N}{3}$. Also $c=N-a-b <N-2$.\n\nFor each fixed $\\frac{N}{3} < c < N-2$ you need to count all the solutions to the equation $a+b =N-c$ with $a < b <c$. This is very easy, since any $b$ yields an unique $a$, the only thing you have to make sure is that $a < b <c$.\n\nAfter finding this number, add this by $c$ and you get your formula...\n\nshare|improve this answer\n\nI think you're asking about partitions of an integer into distinct parts. That is, you're interested in $$ q_k(N) := \\# \\{ (a_1, \\dots, a_s) \\; : \\; a_1 > \\dots > a_s > 0, \\; \\sum a_i = N \\} $$ (and $s$ is allowed to be anything). You can show that $q_k(N + \\binom{k}{2}) = p_k(N)$ where $p_k(N)$ is equal the number of partitions of $N$ into exactly $k$ parts. Then, if $N$ isn't too big you can compute $p_k(N)$ via the recurrence $p_k(N) = p_{k-1}(N-1) + p_k(N-k)$. (Base conditions are $p_k(k) = 1$ for all $k$, $p_{n-1}(n) = 1$, $p_1(n) = 1$, and $p_2(n) = \\lfloor n/2 \\rfloor$.)\n\nshare|improve this answer\n\nThese values (where the first term is the count for $N=6$ here) form sequence A001339 in the Online Encyclopedia of Integer Sequences.\n\nThe number of ways to partition $N$ into exactly three distinct positive integer parts equals the number of ways to partition $N-6$ into at most three (non-negative) integer parts. The following observation explains a one-to-one correspondence: If $N-6=a+b+c$ for non-negative integers $a \\le b \\le c$, then $N = (a+1) + (b+2) + (c+3)$ is a partition of $N$ into three distinct positive integer parts.\n\nNo closed form is provided in OEIS, so one may presume there is none.\n\n(The \"EDIT\" remark in the original question is unclear to me, so this may not be the right answer.)\n\nshare|improve this answer\n\"No closed form is provided in OEIS\"? Au contraire, several closed forms are provided in OEIS. Also, a simple, rational generating function is given, which guarantees the existence of a closed form. But, as you note, this doesn't seem to be the question OP wants answered. \u2013\u00a0 Gerry Myerson Feb 5 '13 at 11:20\nThanks, Gerry. I struck my wrong remark about closed form. \u2013\u00a0 Steve Kass Feb 5 '13 at 16:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/252298/how-to-find-sum-of-changing-binomnr-times-binomms-series\nText:\nTake the 2-minute tour \u00d7\n\nHow can we find the sum of the following series\n\n$$\\sum_{i=0}^p \\binom{m-q+1+i}{i} \\binom{n+q-1-i}{n-i}=\\sum_{i=0}^p\\frac{(m-q+1-i)!}{ i! (m-q+1)!}\\frac{ ( n + q-1-i)!}{ (q-1)! (n-i)!}$$ where $p < n,m$?\n\nshare|improve this question\nDo you denote by $!n$ the factorial? Usually it is denoted by $n!$. \u2013\u00a0 martini Dec 6 '12 at 14:21\n$!n$ is not the notation for factorial, but rather for derangements. \u2013\u00a0 Cameron Buie Dec 6 '12 at 14:30\n\n2 Answers 2\n\nHere is an answer computed by maple\n\n$${n+q-1\\choose n}{_2F_1(-n,m-q+2;\\,-n-q+1;\\,1)}-{m-q+2+p\\choose p+1}{n+q -2-p\\choose n-p-1}$$ $$\\times\\,{_3F_2(1,-n+1+p,m-q+3+p;\\,p+2,-n-q+2+p;\\,1)} $$\n\nwhere $_2F_1$ and $_3F_2$ are the hypergeometric function.\n\nThe same answer can be computed by Mathematica $9$.\n\nshare|improve this answer\n\nIf $p\\ge n$, then $$ \\begin{align} \\sum_{i=0}^p\\binom{m-q+1+i}{i}\\binom{n+q-1-i}{n-i} &=\\sum_{i=0}^p\\binom{m-q+1+i}{m-q+1}\\binom{n+q-1-i}{q-1}\\\\ &=\\binom{m+n+1}{m+1} \\end{align} $$ However, if $p\\lt n$ I don't think there is a closed form (that, in general, doesn't involve hypergeometric functions).\n\nTo confirm Mhenni Benghorbal, Mathematica 8 gives $$ \\binom{n+q-1}{n}\\,_2F_1(-n,m-q+2;-n-q+1;1) -\\binom{m+p-q+2}{p+1}\\binom{n-p+q-2}{n-p-1}\\\\ \\times\\,_3F_2(1,-n+p+1,m+p-q+3;p+2,-n+p-q+2;1) $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-to-find-antiderivative-of-product.140410/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHow to find antiderivative of product\n\n  1. Oct 29, 2006 #1\n    problem: find the anti derivative of x^5 + tan(2x)sec(2x)dx\n\n    how do you find the anti derivative of the second half of that problem tan(2x)sec(2x)\n  2. jcsd\n  3. Oct 29, 2006 #2\n    Does the function y=sec(u)tan(u) look familiar at all? Perhaps as the derivative of some common elementary function?\n  4. Oct 29, 2006 #3\n    yeah, you are going to have to use u-substitution twice. I don't know if I am correct or not, but I changed everything to sin and cos before anything and manipulated it that way. I then let u = cosx and du = -sinx. For the second u-substitution, I let v=u\u00b2-1 and (1/2)dv = udu. I hope that helps and does not confuse you and more.\n  5. Oct 29, 2006 #4\n    What are you doing? What is the derivative of secant?\n  6. Oct 29, 2006 #5\n    oh yeah... I see that the deriveitive of secx = secx tanx... Hmm... looks like I went a long.. long long long way around it.. haha. Sorry about that donjt81, I hope I didn't lead you too far the wrong way. I think it comes out to the same answer. Does it? Well, I guess we can both learn a lesson, or at least myself. And that is to really look at what's in front of you with the equation before just jumping into it. I just jumped right in and started to manipulate it, when I could have just taken a minute to think about what was really there and solved it much quicker and easier.\n\nHave something to add?\n\nSimilar Discussions: How to find antiderivative of product"}
{"text": "Retrieved from https://www.physicsforums.com/threads/magnetic-flux-equator-and-flying-bullets.272027/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMagnetic Flux, Equator and flying bullets!\n\n  1. Nov 15, 2008 #1\n\n\n    User Avatar\n\n\n    At the equator, the earth\u2019s magnetic field is approximately horizontal, is directed towards the north and has a value of [tex] 8 \u00d7 10^{-5} [/tex] T.\n\n\n    Estimate the EMF induced between the top and bottom of a bullet shot horizontally at a target on the equator if the bullet is shot east. Assume the bullet has length of 1 cm, a diameter of 0.4 cm and travels at a speed of 300 m/s (for simplicity, one can assume that the bullet has a square cross-section).\n\n    2. Relevant equations\n\n    [tex] \\epsilon = -\\frac{d\\Phi}{dt} [/tex]\n\n    [tex] \\Phi = \\int B da = BHx [/tex]\n\n    3. The attempt at a solution\n\n    I think I have done this question, but would like to check to see it I have done it correctly...\n\n    [tex] \\Phi = BHx [/tex]\n\n\n    [tex] \\epsilon = -\\frac{dBHx}{dt} [/tex]\n\n    B and H are constants:\n\n    [tex] \\epsilon = -BH\\frac{dx}{dt} [/tex]\n\n\n    [tex] \\frac{dx}{dt} = v [/tex]\n\n    [tex] \\epsilon = -BHv [/tex]\n\n    we know:\n\n    B = [tex] 8 \u00d7 10^{-5} [/tex]\n    H = 0.004\n    v = 300\n\n    thus inserting the values I get:\n\n    [tex] \\epsilon = -9.6 \\time 10^{-5} [/tex] Volts\n\n    Does this look correct?\n\n  2. jcsd\n  3. Nov 15, 2008 #2\n\n\n    User Avatar\n\n    Does this look like the right solution?\n\n  4. Nov 16, 2008 #3\n\n\n    User Avatar\n\n    Does it look like I have attempted the question in the correct way? Does it look right?\n\n\n  5. Nov 16, 2008 #4\n    Hi TFM,\n\n    Your answer looks good to me, although I wouldn't use H as a variable when considering B-fields since it could be confused with the auxillary field H. This question is familar to a hall effect question, although the circumstances are different you get the same final equation. I geuss when it comes down to it though you still have moving charges in a B-field, so in essence it's the same. Odd.\n  6. Nov 17, 2008 #5\n\n\n    User Avatar\n\n    Ok that's good. For the second part,\n\n\n    What is the EMF if the bullet was travelling South?\n\n    I am assuming that the same equation will be used, which should give the same value, since none of the variables appear to have changed. The only real difference is that the bullet is no longer travelling perpendicular, but it does have a perpendicular surface (to the current). Does this sound right?\n\n  7. Nov 17, 2008 #6\n    If the bullet is travelling south then all the charges inside it are also travelling south. The velocity of the charges will be parallel to the magnetic field. What is the force on a charge when moving parallel to a magnetic field?\n  8. Nov 17, 2008 #7\n\n\n    User Avatar\n\n    Well the formula is:\n\n    [tex] Q(v \\times B) [/tex]\n\n    which is a cross product, so the force will be 0?\n\n  9. Nov 18, 2008 #8\n\n\n    User Avatar\n\n    Does this look right? If so, how would this force connect to the EMF force, [tex] \\epsilon [/tex]?\n\n  10. Nov 18, 2008 #9\n    note: emf isn't a force.\n\n    The two methods (Faraday and Lorentz) should lead to the same answer. However I am now confused, since when the bullet moves south there is still a surface parallel to B (so B.da is non zero) which will sweep out an area and lead to an emf. However the Lorentz force law contradicts this, because it says that since all the charges are now moving parallel to B the force on them must be zero.\n\n    Please can someone explain this odd inconsistency? I think I have something obvious mixed up somewhere.\n  11. Nov 19, 2008 #10\n    I think that as the bullet is now travelling parallel to the B-field there will be no change in magnetic flux through any of it's surfaces or open surfaces, since there will be as much B-field going in as there is coming out and it's not cutting any field lines. Does that make sense?\n  12. Nov 20, 2008 #11\n\n\n    User Avatar\n\n    That does indeed make sense.\n\n\nHave something to add?\n\nSimilar Discussions: Magnetic Flux, Equator and flying bullets!\n  1. Metal Magnetic Flux (Replies: 19)\n\n  2. Magnetic Flux (Replies: 0)\n\n  3. Magnetic flux (Replies: 13)\n\n  4. Magnetic Flux (Replies: 5)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-scalars-from-vectors.43276/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestion: scalars from vectors\n\n  1. Sep 15, 2004 #1\n    I saw this question posted yesterday, and now got a similar question to work out.\n\n    A = (6i-8j) cm\n    B = (-8i+3j) cm\n    C = (26i+19j) cm\n\n\n    Determine the two scalars a and b.\n\n    Ideas anyone??\n\n\n    Last edited: Sep 15, 2004\n  2. jcsd\n  3. Sep 15, 2004 #2\n    C=0 ?? But you jsut said C=26i+19j . Is this a typo? or did you mean aA+bB-C=0\n\n    in which case aA+bB=C\n    seems pretty straightforward to me. Split it up into the vector components, and youll have 2 equations with 2 unknowns, easily solveable.\n  4. Sep 15, 2004 #3\n    Sorry. That was a tipo. I made a mistake.\n\n    aA+bB+C=0 not aA+bB=C=0 not\n  5. Sep 15, 2004 #4\n    Well, what have you done so far? How have you approached it?\n  6. Sep 15, 2004 #5\n    I used the equation a^2 + b^2 = c^2 and the coodinates (6,-8) and (-8,3) to determine that the magnitude of A is 0.5cm and that the magnitude of B is 0.7cm. But I don't know if that is what is meant by \"determine the two scalars a and b\". I'm asuming scalars in this question is the scalar quantity or \"magnitude\".\n    Last edited: Sep 15, 2004\n  7. Sep 15, 2004 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The \"equation a^2+ b^2= c^2\" doesn't even make sense here. You are given vectors A, B, C, not numbers a, b, c (and you certainly don't have any number c).\n\n    Do you know how to add vectors and multiply vectors by a number? That should have been ther first thing you learned!\n\n    If A= 6i+8j, then aA= (6a)i+ (8a)j.\n\n    If B= -8i+ 3j, then bB= (-8b)i+ (3b)j\n\n    aA+ bB = (6a- 8b)i+ (8a+ 3b)j and that must be equal to C= 26i+ 19j.\n\n    Okay, have you learned that two vectors are equal only if the respective components are equal?\n\n    To have aA+ bB= C, you must have (6a- 8b)i+ (8a+ 3b)j= 26i+ 19j and so\n    6a- 8b= 26 and -8a+ 3b= 19.\n\n    Can you solve those two equations for a and b?\n\nHave something to add?\n\nSimilar Discussions: Question: scalars from vectors\n  1. Vector and scalars (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/entropy-of-the-universe.249227/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEntropy of the universe\n\n  1. Aug 9, 2008 #1\n\n    A model universe comprises 100 atoms in system 1 and 1500 atoms in system 2. Compute the entropy for the universe when there are 3 atoms on in system 2 and 97 atoms on in system 1 (using sterlings approximation).\n\n    3. The attempt at a solution\n    I am able to find the entropy of systems 1 and 2 by initially finding the number of microstates and then the equation:\n\n    entropy = boltzmanns * ln(microstates)\n\n    Just wondering how I would get the entropy of the universe though.\n  2. jcsd\n  3. Aug 10, 2008 #2\n\n\n    User Avatar\n\n    Well, if you know how many microstates there are for systems 1 and 2, then how many microstates are possible for the combined system (1+2)?\n  4. Aug 10, 2008 #3\n    I was unsure of the terminology. So taking universe as systems 1 and 2:\n\n    I can find number of microstates using \u03a9 = C(N,n)\n    (i.e. the number of ways of moving n atoms from N sites)\n\n    Thus for system 1:\n    \u03a9 = C(1500,3)?\n    This is a massive number!\n\n    Am I on the right track?\n  5. Aug 10, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    Yup that's the correct way of doing the calculation. The calculation may be made easier by finding a formula for C(N,n) in terms of factorials, then applying Stirling's approximation.\n  6. Aug 11, 2008 #5\n    sterlings approximation only helps once I get a value of \u03a9 though correct?\n    I cannot even compute C(1500,3)=1500!/3!1497! due to overflow!\n  7. Aug 11, 2008 #6\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    Try to calculate ln(\u03a9) instead.\n  8. Aug 12, 2008 #7\n    Ok, so I managed to compute C(1500,3) and C (100,97).\n    I got 561375500 and 646800 respectively.\n\n    (I wish to keep in terms of boltzmanns)\n    Therefore for system 1:\n    entropy = K*ln(561375500) = 20.15K\n\n    and system 2:\n    entropy = K*ln(646800) = 13.38K\n\n    total = 33.53K?\n\n    Where does Sterling's Approximation come into this?\n  9. Aug 12, 2008 #8\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    ln(\u03a9) = ln(1500!/3!1497!) = ln(1500!) - ln(3!) - ln(1497!) = 1500ln(1500) - 1500 - ln(6) - 1497ln(1497) + 1497\n\n    Here's where sterling's approximation saves you from evaluating horrible factorials.\n  10. Aug 13, 2008 #9\n    yeah i completed it, thanks for help\n\nHave something to add?\n\nSimilar Discussions: Entropy of the universe\n  1. Quantum entropy and ? (Replies: 2)\n\n  2. Entropy expression (Replies: 1)\n\n  3. Finding Entropy (Replies: 3)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/finding-the-surface-flux-of-the-sun.185342/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nFinding the surface flux of the sun\n\n  1. Sep 17, 2007 #1\n\n    The flux from the Sun above the Earth's atmosphere is about 1370 watts/m^2. This quantity is called the solar constant S and equals pi*f(sun). Use the angular radius of the sun as seen from the Eart to find pi*F , the surface flux of the sun.\n\n    2. Relevant equations\n\n    possible equations that may be relevant: Flux=sigma*T^4, T being the temeperature dependence and sigma=5.669*10^-8/m^2 *K^4; Luminosity = flux*area, a\n\n    3. The attempt at a solution\n\n    I have to find the angular radius of the sun in order to find the surface flux of the sun. To find the angular radius of the sun, I would probably have to used the fact that theta=lambda/Diameter of the sun; theta=lambda/2*radius of the sun. L=4*pi*R^2 *sigma*T^4. There are still 3 unknown variables: lambda, and the Temperature. Perhaps I should approach a solution to this problem in a different fashion: I know the radius of the sun is 6.96*10^5 km and luminosity of the sun is 3.90*10^26 W and the flux from the sun over the earth's atmosphere is 1370 watts/m^2. L/A=flux => (3.90*10^26 W)/(4pi(6.96*10^8 m)^2) = 64067276.69 W/m^2. But that calculation gives me the total flux of the sun, it doesn't give me the surface flux of the sun. how do you find the surface flux of the sun?\n  2. jcsd\n  3. Sep 18, 2007 #2\n    I think you can just use the area of spheres, and the sun as a point source to calculate this.\n  4. Sep 18, 2007 #3\n\n\n    User Avatar\n    Homework Helper\n\n    I don't think you want to treat the Sun as a point source if your aim is to find its surface flux (the angular radius is not that tiny).\n  5. Sep 18, 2007 #4\n\n\n    User Avatar\n    Homework Helper\n\n    I believe you're supposed to proceed from the angular radius, *without* knowing the radius of the Sun or the distance to it from here. As BlackWyvern says, you want to use the surface areas of spheres. You want to consider that one square meter versus the entire sphere at Earth's distance, then consider how that relates to the area of the Sun's surface. Using the definition of angular radius (in the small-angle approximation), you'll notice that it can be identified in your proportional relations.\n\n    You shouldn't need to know anything about blackbody radiation or the Sun's surface temperature either.\n\n    I was puzzled by one other thing you said: what definition are they using in your course for \"surface flux\"? I've been checking around and that term generally means power or luminosity per surface area ( W/[m^2] ).\n    Last edited: Sep 18, 2007\n  6. Sep 18, 2007 #5\n    I just realized that wouldn't work because of the distance differences.\n\n    But you could do pretty much the same thing, just know that since it's a radiation, it's intensity will depreciate proportional to 1/d^2. Use this and the surface area of spheres (I think it's A = 4 (pi) r^2 ) to derive it.\n  7. Sep 18, 2007 #6\n\n\n    User Avatar\n    Homework Helper\n\n    Actually, these two statements are equivalent. This is because L = F x A, which is the key to the solution. Since intensity is power/area, it has a simple relation to flux; in fact, depending on which specialists' definition you're using, that can *be* the same thing. (That's why I asked what definition was intended in the problem.)\n  8. Sep 18, 2007 #7\n\n\n    User Avatar\n    Homework Helper\n\n    I found one source that might help with this. In Foukal's _Solar Astrophysics_ (pp.40-41), what we will find is the net flux through the Sun's surface. If we call *that* f, then f = pi*F, where F is known as the \"astrophysical flux\".\n  9. Sep 18, 2007 #8\n    I don't think the definition of angular radius is stated clearly in my textbook , but is it theta=lambda/2*radius. how do you find theta and lambda in order to find radius of the sun. Also should I assume that the luminosity of the sun is 3.90*10^26 Watts\n\n    well according to my book, theta = lambda/d , d being the size of the apeture. theta= 5e-7 rad. so the two unkwowns are lambda and d. I don't understand why d and lambda are relevant in helping me find the radius of the sun.\n\n    also, would r just be the distance from one point on earth to another point on the sun, which is just one astronomical unit ?\n\n    if so, then the surface area sun would be: SA=4*pi*r^2 = 4*pi*(1.496e11 m)^2 = 2.812e23 m^2\n\n    Since the flux of the earth is given in the problem, I can now find the luminosity of the sun, which is just L = SA *F = (2.81e21m^2)(1370 W/m^2) = 3.84e24 watts.\n\n    Now how would I find the surface flux of the Sun , now that I calculated its luminosity? Could I also used the fact that sin(theta)= R/AU. How would I find theta ?\n\n    I don't understand why my professor wants me to go through numerous calculations for finding the radius of the sun when it is given in the book. I mean whats the point of have the radius of the sun in the appendix of my textbook if I'm going to have to going to have rederived it through tedious calculations.\n    Last edited: Sep 18, 2007\n  10. Sep 18, 2007 #9\n\n\n    User Avatar\n    Homework Helper\n\n    I think they're giving you an apparent radius, based on the wavelength of observation. The theta = lambda/d is an approximate value for the angular size of the Airy disk for a point source.\n\n    In any case, that isn't what we need here. For the physical angular size of the Sun, we'd just want the angle subtended by the Sun's radius at the distance of Earth (1 AU, as you've said). Use the small-angle approximation, since this angle is much less than 0.1 radian.\n\n    I think you have the radius of Earth's orbit in there...\n\n    So you have the surface area of a sphere of 1 AU radius, but something's off because that value for the luminosity is a factor of 100 low...\n\n    You can drop the sine because the small-angle approximation will be valid (it gives entirely adequate precision).\n\n    You don't need to *find* theta, actually, as I'll explain below. Go back to the equation you gave, L = F x A. Consider that the same power leaving the Sun's surface also passes through that sphere with 1 AU radius. So you can equate F x A for each sphere and solve for F for the Sun's surface; theta will appear in your expression.\n\n    Are you in an astrophysics or experimental physics course? The point of the exercise is that you are calculating the nex flux of the Sun from two *directly measurable* quantities, the solar radiation flux at the \"top\" of Earth's atmosphere and the angular diameter of the Sun. Quantities calculated only from directly measurable ones are more reliable than those which are computed from inferred quantities, such as the solar radius or the astronomical unit (there is a whole historical literature you can look at about how these and similar quantities were found and how we got to the currently accepted values).\n\n    When you get past the introductory courses (1000-level in some systems) in the physical sciences, you start getting more into *how* various quantities and equations are derived, rather than just being told, \"Take our word for this and use it!\"\n\n    All those nicely-tabulated quantities listed in your textbook or handbooks of reference data are the result of uncounted person-years of effort and debate. It is always a good idea to know where the numbers you use came from and how reliable (precise, or even just accurate) they really are...\n\nHave something to add?"}
{"text": "Retrieved from https://www.physicsforums.com/threads/help-on-simple-linear-algebra-problem.119074/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHelp on simple linear algebra problem\n\n  1. Apr 28, 2006 #1\n    Let A and I be as follows.\n\n    A = [1 d]\n    [c b]\n    I=[1 0]\n    [0 1]\n\n    Prove that if b - cd != 0, then A is row equivalent to I\n\n    I'm CLUELESS as to WHERE TO START. Please help me\n\n    I tried simplifying to the matrix\n\n    [1 d]\n    [0 b - cd]\n\n    And have no clue what to do next.\n  2. jcsd\n  3. Apr 28, 2006 #2\n    What is the criteria for row equivalent matrices? How would you perform the allowable operations to get to I?\n  4. Apr 28, 2006 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    To get [itex]\\left(\\begin{array}{cc}1 & 0\\\\0 & 1\\end{array}\\right)[/itex]\n    you will need a 1 in place of that b-cd. What row operation will give you that?\n  5. May 18, 2006 #4\n    It has been a while since I took linear algebra so I forget the terms for these things, but I know what you're getting at. If A is row equivalent to I, that means that elementary row operations can reduce it to such. That can only be done if the determinant is not zero. (Then we say A is either singular or not singular, don\u2019t remember which) The determinant of A is b - cd. So in a sense, you're done, unless you actually need to prove what I just said.\n\n    In that case, argue by contradiction. Show that if b - cd = 0, The reduced row echelon form of A is not the identity matrix.\n\n    Hope that helps.\n\nHave something to add?\n\nSimilar Discussions: Help on simple linear algebra problem\n  1. Linear Algebra Help (Replies: 1)\n\n  2. Linear Algebra help (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/proving-a-polynomial-is-constant.198730/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProving a polynomial is constant\n\n  1. Nov 16, 2007 #1\n    Can someone give me a hint on problem 5:\n\n\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n  2. jcsd\n  3. Nov 16, 2007 #2\n    what have you tried?\n    Last edited: Nov 16, 2007\n  4. Nov 16, 2007 #3\n    It is a nice problem. First, you need to know that is a polynomial of degree n takes the same value (n+1) times then it must be be a constant polynomial. The problem says P(x) is a polynomial with integer coefficients so it means P(x) is an integer whenever x is an integer. We know that |P(x)|<n^2 whenever |x|<n so it means for x = -(n-1),...,-1,0,1,...,(n-1) we get P(x) = -(n^2-1),...,-1,0,1,...,(n^2-1). Let P(x) be the \"pigeons\" and x be the \"x\". By strong pigeonhole at least n+1 of the pigeons end up in the same hole. So it must be constant.\n  5. Nov 17, 2007 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    P(x) = x\n\n    n=1, and |P(x)|<1 whenever |x|<1^2. But P(x) is not constant.\n  6. Nov 17, 2007 #5\n    First of all it should be |P(x)|<n whenever |x|<n^2 and secondly I get that there are 2n^2-1 pigeons flying into n-1 pigeon-holes? I have never heard of the strong pigeonhole principle but I do not see why one of the pigeonholes needs to get n+1 pigeons?\n  7. Nov 17, 2007 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    If each pigeonhole has at most n pigeons, then at most how many pigeons are there?\n  8. Nov 17, 2007 #7\n    Less than or equal to n times the number of pigeon-holes.\n\n    In our case, there must be less than or equal to 2n^2 - n total pigeons, which is a contradiction when n is greater than 1. So that explains morphism's counterexample.\n\n    But what exactly is the strong pigeon-hole principle? How is it different than \"if kn+1 pigeon fly into n pigeonholes, than one of the pigeonholes gets at least k+1 pigeons\"?\n\n    Can you instead show that ceiling( (2n^2-1)/(2n-1)) is greater than or equal to n+1 somehow?\n    Last edited: Nov 17, 2007\n  9. Nov 17, 2007 #8\n    I did the problem backward, I am sorry. But the way it should be as Ehrenfest posted is correct if you apply my argument.\n\n    Okay, it is very simple. If you have 6 pigeonholes and 32 pigeons then there is a pigeonhole that has at least 6 pigeons. In general given h pigeonholes and p pigeons then the number is [n/p] where [ ] here is the ceiling function.\n  10. Nov 17, 2007 #9\n    That is what I would just call the normal pigeonhole principle. Is there a reason you called is \"strong\"?\n  11. Nov 17, 2007 #10\n    I call the \"basic\" pigeonhole to be the one that says that there exists at least one hole having two pigeons. The \"strong\" one is the generalized argument. I am not sure if that is how it is officially called but that is how I refer to it.\n\n    Here is a problem to try for you to solve:\n    \"Let S be the set {2,3,....,100} what is the largest subset that can be chosen of non-prime numbers so that all are pairwise co-prime?\"\n    (Here, 'largest' means the largest number of elements in a set).\n  12. Nov 17, 2007 #11\n    That's hard. So the pigeon-holes would have to be the number of primes less than 100. And the pigeons would have to be the elements of S. But the problem is pigeon's can fly into multiple holes!\n  13. Nov 18, 2007 #12\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Am I missing something, or isn't P(x)=x a counterexample to the original problem?\n  14. Nov 18, 2007 #13\n    It is a counterexample. See post #7.\n  15. Nov 21, 2007 #14\n    @ehrenfest. It really is not so hard. If n is a number in {2,3,...,100} it not a prime number then we can write n = p*m where p is a prime number. So for any n there exists a smallest possible prime divisor. Given any n the smallest prime divisor is 7 because it cannot be 11 because if it were its other prime divisor (which it must have because the number is not prime) must be at least 11 again but then 11*11=121 > 100 which is too large. So 7 is the smallest prime divisor of n. So the smallest prime divisors of n can be: 2,3,5,7. That means if you have 5 (non-prime) numbers by pigeonhole it means two of them share a prime factor so they are not co-prime. That means if you have at least 5 non-prime numbers then they all cannot be pairwise coprime. That means 4 is the largest possible subset, i.e. {4,9,25,49}\n\nHave something to add?"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limit-of-a-sequence.3335/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLimit of a sequence\n\n  1. Jun 26, 2003 #1\n    It isn't a homework problem but I think I better post it here instead of Mathematics forum, since it belongs to \"exam help\".\n\n    Prove that for any positive real numbers a and b,\n    lim [(an+b)1/n-1] = 0\n\n    I don't need to use things like |a-b|<epsilon. A simple way will do. I know it's an easy question but I don't know where to start. Could someone please help.\n  2. jcsd\n  3. Jun 26, 2003 #2\n\n    Tom Mattson\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    This one just screams \"L'Hopital!\"\n\n    First, rearrange it to:\n\n\n    Then take the natural log of both sides to get:\n\n    lim ln(an+b)/n=0\n\n    This goes to &infin;/&infin;, which is an indeterminate form and ripe for L'Hopital's rule.\n  4. Jun 26, 2003 #3\n    LOL, thanks Tom and L'hopital\n\n    lim ln(an+b)/n\n\n    = lim a/(an+b)\n  5. Jun 27, 2003 #4\n    Oh sorry, I forgot to mention\n    is a sequence, not a function. I think L'hopital's rule applies to differentiable functions only.\n\n    Perhaps I better rephase the question a bit.\n    A sequence {an} is defined by (an+b)1/n-1\n    Prove that\n    lim (an+b)1/n-1 = 0\n    (a and b are real numbers and n is a positive integer)\n  6. Jun 27, 2003 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    It is true that L'hopital's rule applies to functions rather than sequences.\n\n    However, IF we can convert a sequence an to a function f(x) (we can't if the sequence involves things like n! or \"floor\" or \"ceiling\" that can't be written simply as a continuous function), then f(x)-> L, an-> L. The other way doesn't necessarily work- the function might not have a limit, depending on how it is defined for non-integer values.\n  7. Jun 27, 2003 #6\n    So we can treat a sequence as a function if it is an \"elementary\" one like the one I posted, and can apply L'hopital's rule, is it correct?\n\nHave something to add?\n\nSimilar Discussions: Limit of a sequence\n  1. Limit of sequence (Replies: 13)\n\n  2. Limits of Sequences (Replies: 8)\n\n  3. Limit of a sequence (Replies: 3)\n\n  4. Limit of a sequence (Replies: 2)"}
{"text": "Retrieved from http://mathoverflow.net/questions/109106/upper-bound-on-expectation-value-of-the-product-of-two-random-variables/109110\nText:\nTake the 2-minute tour \u00d7\n\nHello, I am trying to find an upper bound on the expectation value of the product of two random variables.\n\nSo suppose x, y are two non-independent random variables, given that I know the distribution of x p(x) and the distribution of y q(y), how can I find an upper bound on E[|x * y |] that is a function of p and q?\n\nI know that Holder's inequality gives an upper bound to my problem in terms of moments of x and y, but this is a poor bound for the problem that I am considering.\n\nThank you! Best Michele\n\nshare|improve this question\n\nclosed as not a real question by Yemon Choi, Qiaochu Yuan, Andres Caicedo, Will Jagy, Bill Johnson Oct 8 '12 at 16:04\n\n\nCauchy-Schwarz? \u2013\u00a0 Yemon Choi Oct 8 '12 at 0:22\nWell if it gives you a poor bound for your problem, you need to specify more details. The Cauchy-Schwarz inequality is sharp \u2013\u00a0 Yemon Choi Oct 8 '12 at 1:42\nWhy the down-votes? I don't think that C-S is sharp for this situation. If you assume that they are non-negative valued, the sharp upper bound is obtained when the variables are monotonically coupled. I'll post a formula for this in a few minutes. \u2013\u00a0 Anthony Quas Oct 8 '12 at 3:04\nC-S is sharp if all that you know are the second moments. Here we've got far more information: the entire distribution of the random variables. \u2013\u00a0 Anthony Quas Oct 8 '12 at 3:07\nI still think, though, that the question should have included at least some examples of the kinds of distribution that the OP had in mind \u2013\u00a0 Yemon Choi Oct 8 '12 at 3:52\n\n2 Answers 2\n\nI'll assume that $X$ and $Y$ are non-negative random variables. Let $F_X$ be the cumulative distribution function of $X$ (that is $F_X(t)=\\mathbb P(X\\le t)$) and $F_Y$ be the cumulative distribution function of $Y$.\n\nIn your notation, probably $F_X(t)=\\int_0^t p(s)\\,ds$ and $F_Y(y)=\\int_0^t q(t)\\,dt$.\n\nNow define two functions on $[0,1]$: $g_X(x)=\\sup\\lbrace t\\colon \\mathbb P(X\\le t)\\le x\\rbrace $ and similarly $g_Y(x)=\\sup\\lbrace t\\colon \\mathbb P(Y\\le t)\\le x\\rbrace$. These functions are the increasing rearrangements of $X$ and $Y$. That is these are non-decreasing functions with the property that $m\\lbrace x\\colon g_X(x)\\le t\\rbrace =\\mathbb P(X\\le t)$ and $m\\lbrace x\\colon g_Y(x)\\le t\\rbrace = \\mathbb P(Y\\le t)$.\n\nNow the largest possible value of $\\mathbb E XY$ given the distributions is $\\int_0^1 g_X(t)g_Y(t)\\ dt$. Intuitively the reason for this is that the largest value for the expectation is obtained when the largest values of $X$ are multiplied by the largest values of $Y$. Slightly more precisely imagine you've arranged the $X$ values from largest to smallest. Think of these as \"weights\" for the $Y$ values. Obviously you get the biggest integral if you weight the big $Y$ values with the biggest weights.\n\nshare|improve this answer\nDear Anthony, Thank you very much for your answer! A few questions: - Is this bound better than Holder's inequality's bound \ud835\udd3c[XY] <= E[X^p]^(1/p)*E[Y^q]^(1/q) with q>1,p>1,1/p+1/q = 1? If it is, is there a way of proving or simply justifying this? - Where can I find a proof of the bound that you suggested? Thanks you Best Michele \u2013\u00a0 Michele Oct 9 '12 at 23:54\nThe justification is in my answer. For more, you could try Lindvall's book \"Lectures on the Coupling Method\". This is the best possible bound: If you let $\\omega$ be uniformly distributed in the unit interval, then $g_X(\\omega)$ has the same distribution as $X$ and $g_Y(\\omega)$ has the same distribution as $Y$ and the product of these random variables has the integral in my answer. \u2013\u00a0 Anthony Quas Oct 10 '12 at 5:19\nDear Anthony, Still, it is not clear to me how to prove the inequality that you suggested : E[X*Y] <= \\int_{0}^{1} dt g_{X}(t) * g_{Y}(t). Is the proof in the book \"Lectures on the Coupling Method\"? It it not clear either wether and why this bound is better than the Holder's inequality bound E[X^p]^(1/p)*E[Y^q]^(1/q). Can you prove this? Thanks! Michele \u2013\u00a0 Michele Oct 16 '12 at 1:05\nIf you know that $X$ is uniformly distributed on the unit interval and $Y$ are is the uniformly distributed random variable on [1,2], then the bound I'm suggesting comes from $g_X(t)=t$, $g_Y(t)=1+t$, so that $\\mathbb E XY\\le \\int (t+t^2)\\,dt=5/6$. If you use H\\\"older's inequality, you get $(1/(p+1))^{1/p}((2^{q+1}-1)/(q+1))^{1/q}$. This is greater than 5/6 for all $1/p+1/q=1$. My bound is attained if $X$ is uniform and $Y=1+X$. In general, my bound is always attained for some joint distribution on $X$ and $Y$. The Holder bound is not always attained. So mine is lower and is best poss. \u2013\u00a0 Anthony Quas Oct 16 '12 at 5:57\nApparently the inequality I'm quoting goes by the name \"Hardy-Littlewood inequality\". See math.toronto.edu/almut/rearrange.pdf \u2013\u00a0 Anthony Quas Oct 16 '12 at 6:55\n\nI would try yo apply Hoeffding's Lemma, who used his result to identify the bivariate cdfs with given marginal cdfs that minimize or maximize correlation. Let $(X,Y)$ be a random vector with bivariate cdf $H$, let $F$ and $G$ be their marginal cdfs, respectively. It is well known that a sharp upper bound for $H(x,y)$ is $\\min(F(x),G(y))$. By Hoeffding's Lemma we get that $$E(XY)\\leq E(X)E(Y)+\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\big[\\min(F(x),G(y))-F(x)G(y)\\big]dxdy$$\n\nshare|improve this answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56191.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nBalls in Boxes\n\nDate: 05/05/99 at 13:49:04\nFrom: Alp Bassa\nSubject: A combinatorial problem (putting balls in boxes)\n\n\nI tried to solve the following problem. I know the answer, but I \ndon't know how to find it. I hope you can help me:\n\nin 2 of the boxes should be more then the balls in the other box. How \nmany ways are there to do this?\n\nAnswer: t*(t+1)/2 (why?)\n\nI tried to solve it this way:\n\n\nIf there are B(n-2) ways to do this with n-2 balls, then we can to \nthis with n Balls in B(n) ways. Now we just have to find some relation \nbetween B(n) and B(n-2). So it seems like a recursion problem.\n\nThank you very much,\nAlp Bassa\n\nDate: 05/05/99 at 16:09:40\nFrom: Doctor Anthony\nSubject: Re: A combinatorial problem (putting balls in boxes)\n\nIf any box is empty one box will have more balls than the other two, \nso we know that every box has some balls. Also with 2t+1 balls no box \ncan have more than t balls or again it would not satisfy the condition \nof being outnumbered by the other two. So the generating function is\n\n(x + x^2 + x^3 + ..... + x^t)^3 and we require coefficient of x^(2t+1)\n\nWe can write the series as  \n\n                 x^3(1 - x^t)^3\n                    (1 - x)^3 \n\n       = x^3(1-x^t)^3(1-x)^(-3)\n\n  =  x^3[1 -3x^t + 3x^(2t) - x^(3t)][1 + C(3,1)x + C(4,2)x^2 + ....\n\n  = x^3 - 3x^(t+3) + 3x^(2t+3) - x^(3t+3)]SUM[C(r+2,2)x^r] \n\nWe can ignore the terms 3x^(2t+3) - x^(3t+3) as they are already \nbeyond the power of 2t+1 that we require.\n\n  We have x^3.C(2t,2t-2).x^(2t-2)  =  C(2t,2t-2).x^(2t+1)\n\n  also  -3x^(t+3).C(t,t-2).x^(t-2)  =  -3.C(t,t-2).x^(2t+1)\n\nSo required coefficient is\n\n    2t(2t-1)     3t(t-1)       4t^2 - 2t - 3t^2 + 3t\n      2!           2!                    2!\n\n                                t^2 + t        t(t+1)\n                                   2             2 \n\nand so the number of arrangements satisfying the condition is \n\n\n- Doctor Anthony, The Math Forum\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56218.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nLab Partner Pairings\n\nDate: 01/21/2001 at 22:45:08\nFrom: Don Maynard\nSubject: Finding lab partner pairs in a class of 22\n\nA friend who is a teacher would like to find all the possible pairings \nof his 22 students for science labs. Is there an algorithm for this? \n\nIt's a problem that is much more complicated than it appears at first \nsight. There should be 11 pairs and no student should be paired to the \nsame other student twice in the series. I wrote a program that could \nlist up to 14 pairings, but that was not satisfactory because we \nwanted to find all possible lists and be assured that they were all \nthere. Any ideas? \n\nThanks for your consideration.\n\nDon Maynard\nAmerican School in Japan\n\nDate: 01/29/2001 at 11:52:31\nFrom: Doctor Ian\nSubject: Re: Finding lab partner pairs in a class of 22\n\nHi Don,\n\nIf I understand your question correctly, you are using the word \n'pairing' in the following way. A class of four students has the \nfollowing pairings:\n\n   Pairing 1:  AB CD \n   Pairing 2:  AC BD\n   Pairing 3:  AD BC\n\nIf this is the correct interpretation, then you can generate all the\npossible pairings in the following way.  \n\nI'll use the following data structure to represent a single pairing.  \nIt's a list that contains two other lists. The first list is a list of \nstudent pairs. (Each pair is itself a list.) The second list is a list \nof unpaired students. \n  (((a b) (c d))            The pairing so far.\n   (e f g h))               Students yet to be paired.\n\nStart with list containing a single empty pairing:\n\n    (a b c d)))\n\nFrom this, generate the set of possible first pairs, and make a new \npairing that begins with each of those pairs:\n\n  ((((a b))\n    (c d))\n   (((a c))\n    (b d))\n   (((a d))\n    (b c))\n   (((b c))\n    (a d))\n   (((b d))\n    (a c))\n   (((c d))\n    (a b))\n\nNote what we did here - we took each possible pair from the list of\nunpaired students, and added that pair to the pairing. Then we removed\nthose students from the unpaired list. Each pair gives rise to a \ncompletely new pairing. \n\nNow do the same thing over again:\n\n  ((((a b) (c d))\n   (((a c) (b d))\n   (((a d) (b c))\n   (((b c) (a d))\n   (((b d) (a c))\n   (((c d) (a b))\n\nEach pairing is expanded until its unpaired list is empty, at which \npoint the pairing is complete. Note that in the general case (i.e., \nmore than two unpaired students), each pairing will give rise to \nseveral new pairings each time a new pair is selected, e.g.:\n\n  (((a f) (c e))\n   (b d g h))\n  (((a f) (c e) (b d))\n   (g h))\n  (((a f) (c e) (b g))\n   (d h))\n  (((a f) (c e) (b h))\n   (d g))\n  (((a f) (c e) (d g))\n   (b h))\n  (((a f) (c e) (d h))\n   (b g))\n  (((a f) (c e) (g h))\n   (b d))\nIn fact, a pairing with N unpaired students will give rise to \nN*(N-1)/2 new pairings.  \nNote that this algorithm will generate some duplicate pairings. But \nyou can sort all the pairings, which will force duplicates to appear \nnext to each other, making them easy to find and remove: \n\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a d) (b c))\n  ((b c) (a d))\n  ((b d) (a c))\n  ((c d) (a b))\n\n  == sort ==>\n\n  ((a b) (c d))\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a c) (b d))\n  ((a d) (b c))\n  ((a d) (b c))\n\n  == remove duplicates ==>\n\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a d) (b c))\n\nIn fact, since the number of possible pairings for 22 students is \ngoing to be VERY large, you might want to so this sort-and-remove step \nafter each round of selections, instead of waiting until the end.  \n\nI've used notation from the Lisp programming language, which is \nideally suited for this kind of thing; but you should be able to \nimplement the same algorithm in just about any programming language. \n\nI hope this helps.  Write back if you'd like to talk about this some \nmore, or if you have any other questions. \n\n- Doctor Ian, The Math Forum\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/110892/a-question-about-standard-inner-product-linear-algebra\nText:\nTake the 2-minute tour \u00d7\n\nIt's a question from a test I didn't knew how to solve:\n\nAn inner product space in $V=R^n$, such as $$\\left\\langle \\pmatrix{ x_1\\\\ \\vdots \\\\ x_n}\\pmatrix{ y_1\\\\ \\vdots\\\\ y_n} \\right\\rangle = x_1y_1 + x_2y_2 +\\ldots +x_ny_n $$ (standard)\n\n$ v , u $ are not linear dependent in $V$. And $W = \\operatorname{sp}d \\left \\{ (u+v),(u-v) \\right \\}$; now I am asked to prove that if exists a $w$ in $W^\\perp$, $w\\neq0$ then : $3 \\leq \\dim(V)$.\n\nI tried to check for dimensions $2$, $1$ and to prove that $w=0$ but with no luck...\n\n\nshare|improve this question\n\"sp\" stands for \"span\", right? So $W$ is in fact the vector space generated by $u$ and $v$. Then show that $\\{u,v,w\\}$ is linearly independent. \u2013\u00a0 Davide Giraudo Feb 19 '12 at 11:03\nyes it is :) I will try to solve it now. thank you! \u2013\u00a0 YNWA Feb 19 '12 at 11:10\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nSince $2u=(u+v)+(u-v)$ and $2v=(u+v)-(u-v)$, we have $\\operatorname{span}\\{u+v,u-v\\}=\\operatorname{span}(u,v)$. If we have $au+bv+cw=0$ where $a,b,c\\in\\mathbb R$ then $$0=\\langle au+bv+cw,w\\rangle=a\\langle u,w\\rangle+b\\langle v,w\\rangle+c\\langle w,w\\rangle=c\\langle w,w\\rangle.$$ Since $w\\neq 0$ we have $\\langle w,w\\rangle\\neq 0$ so $c=0$ and $au+bv=0$. Since $u$ and $v$ are linearly independent, we have $a=b=0$ so finally the set $\\{u,v,w\\}$ is linearly independent.\n\nNote that the fact that $\\langle\\cdot,\\cdot\\rangle$ was the usual inner product was not necessary; it would work for example if $\\langle x,y\\rangle=\\sum_{j=1}^na_jx_jy_j$ where $a_j$ are positive real numbers.\n\nshare|improve this answer\nthank you, simple and well written... :) \u2013\u00a0 YNWA Feb 19 '12 at 11:33\nYou're welcome. \u2013\u00a0 Davide Giraudo Feb 19 '12 at 11:33\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/116308/minimum-of-different-independent-poisson-random-variables?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nLet $X_1,\\ldots,X_N$ be independent Poisson distributed random variables with unequal parameters $\\lambda_1,\\ldots,\\lambda_N$.\n\nIs there any closed form expression or at least a good approximation for the distribution (I am most interested in the CCDF) of their minimum $Y = \\min\\limits_{1\\leqslant i\\leqslant N}(X_{i})$?\n\nshare|improve this question\n\n2 Answers 2\n\nThe CCDF of $Y$ is the product of the CCDF's of $X_1,\\ldots, X_N$. The CCDF of $X_j$ (at nonnegative integer $x$) is $1 - \\Gamma(1+x,\\lambda_j)/x!$ where $\\Gamma$ is the incomplete Gamma function. That's about as closed a form as you're going to get. As for approximations, which limit are you interested in?\n\nshare|improve this answer\nThanks, Robert! I had the gamma formula as well. What I need to do is integrate this on $\\lambda \\in (0,\\infty)$. Are there any good and integrable lower and/or upper bounds? \u2013\u00a0 miladydesummer Dec 13 '12 at 21:14\nIntegrate what exactly and over what domain? If you the $\\Lambda$'s a reasonably large then Poisson can be approximated by Normal distribution, so if you were interested in, say, the expectation of the minimum it will be bounded between $\\min_i(\\Lambda_i)$ and $\\min_i(\\lambda_i-\\sqrt{\\log(N)}\\sqrt{\\Lambda_i})$. \u2013\u00a0 Ori Gurel-Gurevich Dec 14 '12 at 5:39\nOops, I accidentally made some of the $\\lambda$'s $\\Lambda$. \u2013\u00a0 Ori Gurel-Gurevich Dec 14 '12 at 5:40\nSorry, my integration explanation was very vague. I want to integrate the CCDF of the minimum Y, over variable $t\\in(0,\\infty)$, with $\\lambda_j = \\p_j t$. Unfortunately, the $p_j$'s are very small, so I'm guessing the normal approximation would not be so great here... \u2013\u00a0 miladydesummer Dec 14 '12 at 11:56\nDo you really mean to integrate from $t=0$ to $\\infty$? The CCDF goes to $1$ as $t \\to \\infty$, so the result would be $\\infty$. \u2013\u00a0 Robert Israel Dec 14 '12 at 18:43\n\nFor large $N$ asymptotics, you want to look into extreme value theory. In particular, take a look at this book.\n\nshare|improve this answer\nIsn't extreme value theory only for min/max of IID variables? Mine are independent but not identical, since they have different parameters... \u2013\u00a0 miladydesummer Dec 15 '12 at 12:32\nThe most classical parts are but that's not the full extent of the theory, just like the most classical versions of the central limit theorem are for IID variables, but more general versions exist. \u2013\u00a0 Mark Meckes Dec 17 '12 at 16:33\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/131300/can-one-prove-int-f-0-for-f-0-without-lebesgue-integration\nText:\nTake the 2-minute tour \u00d7\n\nIn an exercise session of an analysis course (which covers Riemann integration and differentiation in one dimension rigorously) the following question came up:\n\nSuppose $f$ is strictly positive and integrable (on some compact interval $[a,b]$ on the real line). Can we show that $\\int_a^b f > 0$?\n\nThe proof by using measure theory and Lebesgue integration is easy, but also beyond the students at this point. So can one do without machinery such as sets of zero measure?\n\nTools in use: Mean value theorems, fundamental theorem of calculus, Riemann's condition for integrability (upper and lower integral within every epsilon of each other implies integrability), Riemann-Darboux integral, usual integration and differentiation techniques, as well as elementary real analysis in the epsilon-delta style.\n\nshare|improve this question\nHint: interval sequence theorem and upper Darboux sum \u2013\u00a0 89085731 Apr 13 '12 at 14:57\nThere's also a proof via the Baire category theorem. \u2013\u00a0 Chris Eagle Apr 13 '12 at 19:08\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nThis can be shown using the concept of oscillation.\n\nFor a bounded $f$, the oscillation of $f$ over set $A$ (which is not a single point) is given by\n\n$$w(A) = \\sup_{A} f - \\inf_{A} f$$\n\nFor a single point $x$, the oscillation is defined as\n\n$$ w(x) = \\inf_{J} w(J)$$\n\nwhere $J$ ranges over bounded intervals containing $x$.\n\nNote that if $x \\in I$, then $w(x) \\le w(I)$.\n\nNow if $f$ is Riemann integrable over $[a,b]$, then we can show that given any $n \\gt 0$, there is a sub-interval $I_{n}$ of $[a,b]$ such that $w(I_n) \\le \\frac{1}{n}$.\n\nThis is because, if every subinterval $I$ of $[a,b]$ had $w(I) \\gt \\frac{1}{n}$, then for every partition of $[a,b]$ the difference between the upper and lower sums would be at least $\\frac{b-a}{n}$ and as a consequence, $f$ would not be integrable.\n\nNow pick $I_{n+1} \\subset I_{n}$ such that $w(I_{n+1}) \\le \\frac{1}{n+1}$.\n\nBy completeness there is a point $c$ such that $c \\in I_n$.\n\nThus $w(c) \\le w(I_n) \\le \\frac{1}{n}$ for all $n$. Hence $w(c) = 0$.\n\nNow it can be show that $f$ is continuous at point $x$ if and only if $w(x) = 0$.\n\nNote: This is basically a simplification of one proof of the Riemann Lebesgue theorem of continuity almost everywhere.\n\nshare|improve this answer\nI think it may not be the Riemann Lebesgue theorem.The Riemann Lebesgue Theorem might be $\\lim_{n\\to \\infty}\\int_a^b f(x)g(nx)dx=\\frac{1}{T}\\int_a^b f(x)dx\\int_0^T g(x)dx$ \u2013\u00a0 89085731 Apr 14 '12 at 0:26\n@Gingerjin: There are multiple with \"Riemann Lebesgue\" name. For instance, there is the Riemann Lebesgue Lemma... \u2013\u00a0 Aryabhata Apr 14 '12 at 0:29\n\nIf f is integrable in [a,b], there is a point x0 in the interval where f is continuous, and positive. Then there is a neighborhood of the point where f is positive , contained in the interval.There we can take a closed inreval where it is positive and there f has minimum then the integral at this interval is bigger or equal than the integral of the minimum which is positive. We can then apply aditivity in the interval [a,b] and in the other closed intervals the integral is no negative since each riemann summ si no negative.\n\nshare|improve this answer\nI think you first need to prove there is a point that is continuous in[a,b] for him.Actually, this conclusion will lead to the conclusion that the continuous point is dense. \u2013\u00a0 89085731 Apr 13 '12 at 15:05\nYes.We can use that if f is Riemann integrable then the set of discontinuities has measure zero, but I will think how to prove without measure theory that there is a point of continuity. \u2013\u00a0 alpha.Debi Apr 13 '12 at 15:56\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/proof-by-induction.253129/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProof by induction\n\n  1. Sep 1, 2008 #1\n    Show, by induction, that for all whole number of Roubles greater than 7, the amount can be given without change by using only 3 rouble and 5 rouble notes.\n\n    2. Relevant equations\n    In other words for all [tex]n \\in N, n > 7[/tex], there exist [tex] a, b \\in N [/tex] such that [tex] n = 5a + 3b [/tex]\n\n    3. The attempt at a solution\n    This is true for n = 8\n\n    I'm wondering if I can't use strong induction. I've noticed that all of these n's appear to be writable with [tex]a \\in \\{0,1,2\\}[/tex] while letting b take on any value, and that when you express the integers greater than 7 in order the a's when thus constrained go 1, 0, 2, 1, 0, 2, etc and each time around the b increments by one for each repetition of a. So, I don't know if I can weasel something out of this like to go from n to n+1 means either going from 1 to 0, 0 to 2, or 2 to 1 in a with the associated incrementation, but I just get the feeling that this isn't the way to go. It seems I'm missing something easier.\n  2. jcsd\n  3. Sep 1, 2008 #2\n    Looks like you're on the right track, and since it's true for n=8, it's true for n=18, n=28, etc. And if it's true for n=9...\n  4. Sep 2, 2008 #3\n    I think the real trick on this was to use strong induction and notice that P(n+1) is implied by assuming P(1)...P(n) are true. Specifically, if P(n-2) is true, then P(n+1) is implied because it is three more than it, so if P(n-2) were written as 5a+3b, P(n+1) is 5a + 3(b+1)\n\nHave something to add?\n\nSimilar Discussions: Proof by induction\n  1. Proof by induction (Replies: 2)\n\n  2. Proof by induction (Replies: 9)\n\n  3. Proof by induction (Replies: 32)\n\n  4. Induction Proof (Replies: 14)\n\n  5. Proof by Induction (Replies: 6)"}
{"text": "Retrieved from https://brainmass.com/physics/electric-power/electric-field-in-a-spherical-cavity-in-a-dielectric-medium-170253\nText:\nExplore BrainMass\n\nElectric field in a spherical cavity in a dielectric medium\n\nShow that the field inside a spherical cavity cut in a uniform dielectric medium is uniform and of magnitude\n\nEcav = 3erEm/(2Er+1),\n\nwhere er is the relative permittivity of the medium and Em is the uniform field in the dielectric at a point distant from the cavity.\n\nSolution Preview\n\nAs usual we introduce the \"electric displacement field\" D:\n\nD = er E (1)\n\nwhere er is the relative permittivity .\n\nThen, as explained in your textbook,\n\ndiv D = rho_free/epsilon_0 (2)\n\nwhere rho_free is the charge density due to free charges, not the induced polarization charges. So, the polarization effects of the medium do not appear in D and D behaves like the electric field would if there were no medium.\n\nTo solve problems like this one where you have different regions with constant relative permittivities, you reason as follows. In each of the regions equation (1) is valid, albeit it with a different er for each region. If we introduce the electric potential V defined by E = -nabla V, then it follows from (1) that in each region:\n\nD = -er nabla V (3)\n\nInsert this in (2) to obtain:\n\nnabla^2 V = -rho_free/(er epsilon_0) (4)\n\nOr if there are no free charges, such as in this problem, we have:\n\nnabla^2 V = 0 (5)\n\nSo, we just need to solve the Laplace equation. To do that we need to know the boundary conditions. Let's consider the boundary of two dielectrics. It follows from the Maxwell equation nabla times E = 0 (which allows you to write E = nabla V in the first place), via Stokes' Theorem that:\n\nThe ...\n\nSolution Summary\n\nA detailed explanation is given."}
{"text": "Retrieved from http://mathforum.org/kb/thread.jspa?threadID=2455175&messageID=8911841\nText:\nThe Math Forum\n\nSearch All of the Math Forum:\n\n\nMath Forum \u00bb Discussions \u00bb sci.math.* \u00bb sci.math\n\nTopic: probability problem\nReplies: 2 \u00a0 Last Post: May 4, 2013 11:34 AM\n\nAdvanced Search\n\n\nPosts: 419\nRegistered: 10/7/06\nRe: probability problem\nPosted: May 4, 2013 11:34 AM\n\nOn May 4, 1:43\u00a0pm, wrote:\n> Hello,\n> I am stuck with a probability problem. Here is the problem. Any help would be great.\n> There are N samples each have probability of Pi (i=0......n-1)\n> I want to find out probability of at least K of them occurs. Each is sampled only once. If probability of N events to be same it would have simpler. now since probability is different , not sure how to calculate this. Please also mention logic behind the calculations.\n\n1. What's the result if K = 0? With that out of the way, assume K >=\n\n2. Let q (i, j) be the probability that exactly j of the first i\nsamples occur, for 0 <= i <= n, 0 <= j < K. Let r (i) be the\nprobability that K or more of the first samples occur.\n\nGiven that K > 0, what is q (0, 0), what is q (0, j) for 1 <= j < K,\nwhat is r (0)? Look at the definitions of q and r, and the result\nshould be obvious.\n\nFor 1 <= i <= n: Since you know q (i-1, j) for 0 <= j < K, r (i-1),\nand p (i-1) which is the probability that the i-th sample occurs, how\ndo you calculate q (i, 0), q (i, j) for 1 <= j < K, and r (i) ?\nThere's a simple formula for each.\n\nThe desired result is r (n). Why?\n\n3. For extra points: How do you reduce the number of calculations if K\n>= n / 2?\n\n\n[Privacy Policy] [Terms of Use]"}
{"text": "Retrieved from http://math.stackexchange.com/questions/673824/generalization-of-sum-of-cube-of-any-3-consecutive-integers-is-divisible-by-3\nText:\nTake the 2-minute tour \u00d7\n\nI have this question posted by professor in graduate Number Theory class. First he asked for proof that the sum of cube of 3 consecutive integers is divisible by 3, which is very easy to prove, but then he continued by asking to prove its generalization, ie., n | 1^n + 2^n + 3^n + ... + n^n.\n\nHere you can easily find a counterexample that if n is even, the generalization fails. But if n is odd, looks like it works. I tried using mathematical induction but did not go anywhere. Then I tried using Binomial Expansion, Pascal Triangle, and using representation of consecutive numbers as ... (a-3), (a-2), (a-1), a, (a+1), (a+2), (a+3), ... in order to cancel out, but still did not go anywhere.\n\nI would appreciate any help. Thank you for your time.\n\nshare|improve this question\nHint: Use modular arithmetic. If you have $1,2,3,4,\\dots, n$, in modulo $n$, you have $1,2,3,\\dots, -3,-2,-1,0$. If $n$ is odd, then $(-a)^n = -a^n$, so that would cancel with $a^n$. \u2013\u00a0 Braindead Feb 12 '14 at 14:29\nWhy doesn't $a-3,a-2,a-1,a,a+1,a+2,a+3$ work? Add those $7$ numbers together and you get $7a$, which is divisible by $7$. \u2013\u00a0 John Habert Feb 12 '14 at 15:16\nThanks for your response! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:29\n@Braindead: Do give me example. Suppose you have 5, 6, 7, 8, 9, 10, 11 (mod 7), how do you turn them into -3, -2, -1, 0, 1, 2, 3 (mod 7) such that they will be cancel out? Thanks. \u2013\u00a0 A.Magnus Feb 14 '14 at 15:27\n@LoveMath I edited my answer to include the example. \u2013\u00a0 Braindead Feb 14 '14 at 17:01\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nSince this is a graduate level number theory class, I think it's safe to assume that you are familiar with modulo arithmetic?\n\nGiven any list of $n$ consecutive integers, $a, a+1, a+2, \\dots, a+n-1$, modulo $n$ this list is equivalent to $0,1,2,3,\\dots,n-1$ modulo $n$. (Note that I am not saying $a \\equiv 0 \\pmod{n}$). This list can be rewritten as:\n\n$1 \\equiv 1 \\pmod{n}$\n\n$2 \\equiv 2 \\pmod{n}$\n\n$3 \\equiv 3 \\pmod{n}$\n\n\n$\\dfrac{(n-1)}{2} \\equiv \\dfrac{(n-1)}{2} \\pmod{n}$\n\n$n-1 \\equiv -1 \\pmod{n}$\n\n$n-2 \\equiv -2 \\pmod{n}$\n\n$n-3 \\equiv -3 \\pmod{n}$\n\n\n$\\dfrac{(n+1)}{2} \\equiv -\\dfrac{(n-1)}{2} \\pmod{n}$\n\nSince $n$ is odd, exponentiation preserves the sign. And so\n\n$$0^n + 1^n + 2^n + \\dots + \\left(\\dfrac{n-1}{2}\\right)^n + \\left(\\dfrac{n+1}{2}\\right)^n + \\dots + (n-2)^n + (n-1)^n + n^n$$\n\nis equivalent to\n\n$$1^n + 2^n + \\dots + \\left(\\dfrac{n-1}{2}\\right)^n - \\left(\\dfrac{n-1}{2}\\right)^n + \\dots - 2^n - 1^n$$\n\nmodulo $n$, and so the sum becomes $0$ modulo $n$. Note that the exponent could be replaced by any odd integer and the statement will still hold.\n\nEDIT: Here is the example you requested in the comments.\n\nLet's say we have the list 5, 6, 7, 8, 9, 10, 11, with $n=7$.\n\nOkay, so the first thing I will do is to find their representatives in $\\mod 7$ between $0$ and $6$ inclusive.\n\n\n5, 6, 7, 8, 9, 10, 11 becomes 5, 6, 0, 1, 2, 3, 4.\n\nNow, let's look at $(n-1)/2$. For $n=7$, this number is 3. That is the cut off for the positive terms. The rest of them I turn them into negatives:\n\n$5, 6, 7, 8, 9, 10, 11$ becomes\n\n$5, 6, 0, 1, 2, 3, 4,$ which is\n\n$7-2, 7-1, 0, 1, 2, 3, 7-3$, which becomes\n\n$-2, -1, 0, 1, 2, 3, -3$.\n\nNow, take any odd power of these numbers, sum, you get 0 in modulo 7.\n\nTechnically, I could've gone directly from the original list to $-2, -1, 0, 1, 2, 3, -3$, without going through the intermediate step, but I wanted to illustrate how the proof applies to this particular example.\n\nshare|improve this answer\nThanks for your elaborate response! I actually came up with my own, but mine is good only for prime, yours is more comprehensive. (I used binomial coefficient, when n is prime then all coefficients will be divisible by n, etc.) Thanks again! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:29\nSolid Answer, nicely done. \u2013\u00a0 Newb Feb 14 '14 at 17:02\n\nThe remainders modulo $2k+1$ can be (re)written as $0,\\pm1,\\pm2,\\ldots,\\pm k$. By rising them each to any positive odd power of our choosing, they will maintain their sign, while their absolute values will be pair-wise equal, so ultimately their sum will be divisible through $n=2k+1$.\n\nshare|improve this answer\nThank you for your response! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:26\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/180511/irreducible-polynomials-with-integer-coefficients-over-q\nText:\nTake the 2-minute tour \u00d7\n\nSuppose p(x) is an irreducible polynomial over Q of degree n, with integer coefficients. If p(x) has two roots r1 and r2 satisfying r1r2 = 5, prove that n is even.\n\nAttempt at solution:\n\n  \u2022 Because the base field is Q, the field extension is separable, hence no roots of multiplicity > 1.\n\n  \u2022 Because r1r2 = 5, I think we can show that if the degree of n is odd, then this will contradict the fact that p(x) has integer coefficients somehow, but I can't seem to do this.\n\nAny help would be appreciated very much, thank you.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nClaim. For every root $r$ of $p(x)$, $r' = 5/r$ is also a root of $p(x)$.\n\nProof: Let $g$ be an element of the Galois group that maps $r_1$ to $r$, i.e. $gr_1 = r$. Let $r' = gr_2$. Then $rr' = gr_1 \\cdot gr_2 = g(r_1r_2) =g(5) = 5$. QED\n\nTherefore, we can split all roots of $p(x)$ into pairs $(r, r')$ such that $rr' = 5$. Since $p(x)$ doesn't have multiple roots, $r\\neq r'$ in each pair. Thus the number of roots is even. Therefore, the polynomial has even degree.\n\nshare|improve this answer\nYury - thank you so much for the quick response & concise solution. Appreciate it. \u2013\u00a0 Conan Wong Aug 9 '12 at 5:21\nPresumably, 5 can be replaced with any rational number, and the same result obtains. \u2013\u00a0 Gerry Myerson Aug 9 '12 at 6:08\n\nHint $\\ $ Since $\\rm\\,p(x)\\,$ is irreducible the Galois group G acts transitively on its roots, so G contains the involution $\\rm\\:x\\to 5/x.\\:$ If the involution has no fixed points then it $\\rm\\color{#C00}{pairs}$ the roots so they are $\\rm\\color{#C00}{even}$ in number. Else, if $\\,\\alpha\\,$ is a fixed point then $\\rm\\,\\alpha\\, = 5/\\alpha\\,$ so $\\rm\\:\\,\\alpha^2 = 5\\,$ so $\\,\\ldots$\n\nshare|improve this answer\nThank you Bill - much appreciated. \u2013\u00a0 Conan Wong Aug 9 '12 at 14:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/5713/what-is-an-example-of-a-finite-model-in-first-order-logic-having-a-unique-undefi\nText:\nTake the 2-minute tour \u00d7\n\nThis is (a slight paraphrase) of question 1.3.14 in Chang and Keisler's Model Theory book.\n\n\"Show that for each natural number $n$, there is a language $L_n$ and finite model $M_n$ of $L$ such that $M_n$ has precisely $n$ undefinable elements.\"\n\nHere, an element $x\\in M$ is definable if there is a (first order) formula in $L$, called $\\phi$, such that $x$ is the unique element of $M$ satisfying $\\phi$. Of course, \"undefinable\" means \"not definable\".\n\nIt is starred, indicating that it is more difficult than a standard problem in that book.\n\nChang and Keisler remark that $n=1$ is the only difficult case. In that spirit, here is the proof for all $n\\neq 1$.\n\nLet $L_n$ have a single 2 place predicate symbol (I'm thinking of $L_n = \\{ < \\}$). Let $M_n$ be the partial order with minimum a and with elements $b_1,...,b_{n}$ with $a < b_i$ for all $i$ and the $b_i$ pairwise incomparable.\n\nFirst note that a is definable: it uniquely satisfies $\\phi(x) =$ for all y, $x\\leq y$.\n\nNow, if $n =0$, there are no $b_i$, and hence in this model, we have 0 undefinable elements.\n\nIf $n > 1$, then I claim that all the $b_i$ are undefinable. The short answer is that any permutation of the $b_i$ can be extended to a unique isomorphism of $M_n$. Hence, for any formula $\\phi$, we have $\\phi(b_i)$ iff $\\phi(b_j)$ for all $b_j$. Thus, no $\\phi$ can single out any particular $b_i$, so each $b_i$ is undefinable.\n\nThis proof fails completely for $n=1$, for then $b_1$ is the unique element that satisfies \"b_1 is not a\". Or more in the spirit of first order logic, $b_1$ is the unique element satisfying $\\phi(x) =$ there is a $y$ such that for all $z$, $y< z$ and $x$ is not equal to $y$.\" Incidentally, this proves that any such model that works for $n=1$ must have at least 3 elements.\n\nSo, my question is:\n\nWhat is an example of a language with finite model having precisely one undefinable element? Is the smallest cardinality of such a model known?\n\nThanks in advance!\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 12 down vote accepted\n\nIf your languages necessarily have the = relation, which is a common assumption, then the case n=1 is impossible in a finite model. The reason is that if a model $M$ has $k$ elements $x_1$, $x_2$, ... $x_k$ for finite $k\\gt 1$ and each $x_i$ is defined by $\\varphi_i(x)$ for $i\\lt k$, then the remaining element $x_k$ is defined by the formula $\\neg\\varphi_1(x)\\wedge\\cdots\\wedge \\neg\\varphi_{k-1}(x)$. If $M$ has only one element, then it is defined by the formula $x=x$.\n\nBut if we do not insist that $=$ is in the language, then let $L$ be the empty language, having no relations at all. In this case, there are no atomic formulas and hence no well-formed formulas to define elements, so a one-point model has exactly one undefinable element.\n\nIf we allow infinite models, then we can easily arrange to have exactly one undefinable element, even in a language with $=$. For example, consider the lanuage with infinitely many constant symbols, and have a model where all these constants are interpreted by different elements, and there is one extra un-named object. That extra object will be the only non-definable element, even when $=$ is in the language.\n\nshare|improve this answer\nThank you for your answer as well! \u2013\u00a0 Jason DeVito Sep 29 '10 at 17:07\n\nYou can't have equality as a relation in the language that is interpreted as equality in the model, otherwise you can define the undefinable element as that (one) which is not equal to any of the definable ones. Most languages in common use have equality so it is hard to think of a natural example that describes, e.g., algebraic structures or combinatorial objects.\n\nshare|improve this answer\nThank you for your answer! \u2013\u00a0 Jason DeVito Sep 29 '10 at 17:06\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/93466/minimum-height-trees-why-does-deleting-leaves-layer-by-layer-give-us-the-answer\nText:\nHere is the problem I tried to solve. Finally, I gave up and found a solution which was correct. Here is it.\n\nHere is the problem description:\n\nFor a undirected graph with tree characteristics, we can choose any node as the root. The result graph is then a rooted tree. Among all possible rooted trees, those with minimum height are called minimum height trees (MHTs). Given such a graph, write a function to find all the MHTs and return a list of their root labels.\n\nThe graph contains n nodes which are labeled from 0 to n - 1. You will be given the number n and a list of undirected edges (each edge is a pair of labels).\n\nYou can assume that no duplicate edges will appear in edges. Since all edges are undirected, [0, 1] is the same as [1, 0] and thus will not appear together in edges.\n\nExample 1 :\n\nInput: n = 4, edges = [[1, 0], [1, 2], [1, 3]]\n\n   / \\\n  2   3 \n\nOutput: 1\n\nExample 2 :\n\nInput: n = 6, edges = [[0, 3], [1, 3], [2, 3], [4, 3], [5, 4]]\n\n 0  1  2\n  \\ | /\n\nOutput: 3, 4\n\nHere is the solution I tried to understand:\n\nThe basic idea is \"keep deleting leaves layer-by-layer, until reach the root.\"\n\nSpecifically, first find all the leaves, then remove them. After removing, some nodes will become new leaves. So we can continue remove them. Eventually, there is only 1 or 2 nodes left. If there is only one node left, it is the root. If there are 2 nodes, either of them could be a possible root.\n\nI'm not sure I understand it so I could explain it to somebody. Why does deleting leaves layer-by-layer give us the answer?\n\n\nLet $T$ be a tree, and let $T'$ be the tree formed from $T$ by removing all leaves (vertices of degree 1). Assume that $T$ contains at least three vertices, so that $T'$ is not empty. This implies that every leaf $f \\in T$ has a (unique) neighbor $p(f) \\in T$ which is not a leaf.\n\nFor $v \\in T$, denote by $h_v(T)$ the height of $T$ when rooted at $v$. I claim that the following hold:\n\nFor every vertex $v \\in T'$, $$ h_v(T) = h_v(T') + 1. $$ For every leaf $f \\in T \\setminus T'$, $$ h_f(T) = h_{p(f)}(T) + 1. $$\n\nFor the first claim, consider $T$ rooted at a non-leaf $v$. The height of $T$ is the length of the maximal root-to-leaf path. Every such path gets shortened by one in $T'$, implying that $h_v(T) = h_v(T') + 1$.\n\nFor the second claim, let $x$ be a leaf farthest away from $p(f)$. We can assuming that $x \\neq f$ since $p(f)$ has at least two neighbors, and $f$ is at minimal distance from $p(f)$. Clearly $d(f,x) = d(p(f),x) + 1$, and so $h_f(T) \\geq h_{p(f)}(T) + 1$. The other direction follows from the triangle inequality, which implies that $d(f,y) \\leq d(p(f),y) + 1$ for all nodes $y$.\n\nThe algorithm. If $T$ contains one or two vertices, then clearly all vertices are centers (roots of minimum height trees). Otherwise, by the second claim, no leaf can be a center, and so by the first claim, the centers of $T$ are the same as the centers of $T'$. This suggests the following algorithm for computing the centers of $T$:\n\n  1. While $T$ contains at least three vertices, remove all leaves of $T$.\n  2. Once $T$ contains one or two vertices, return all vertices of $T$.\n\nThe correctness of the algorithm follows the reasoning stated above.\n\n  \u2022 $\\begingroup$ Beautiful explanation. $\\endgroup$ \u2013\u00a0Anant May 11 at 1:58\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/431164/distributing-distinguishable-particles-in-dinstinguishable-boxes-and-computing-c\nText:\nI have n distinguishable particles and m distinguishable boxes. If all particles are in the same box the system has an energy of -$\\epsilon$ in all the other cases the energy is 0.\n\nNow I want to compute the canonical partition function. The Helmhltoz energy and the entropy of the ground state.\n\nTo start with I would count the number of possibilities to put all particles in single boxes.\n\nThere are $n!$ ways to arrange n distinguishable particles. And I have m boxes. And last I have $m!$ ways to arrange the different boxes. Therefore I have $n!*m*m!$ possibilities. The next step is to compute all possibilities to distribute n distinguishable particles in m distinguishable boxes. To distribute n particles in m boxes I have $m^{n}$ possibilities for a single configuration. Then I can arrange each configuration in $n!$ ways and last I can arrange the boxes again in $m!$ different ways. Hence the number of remaining possibilities is\n\n$$ m^{n}*n!*m!-n!*m*m!. $$\n\nThis gives the partition function:\n\n$$ Z(m,n,T)=m^{n}*n!*m!-n!*m*m!+n!*m*m!*e^{\\beta*\\epsilon}=\\\\ m!*n!*m*(m^{n-1}-1+e^{\\beta\\epsilon}) $$\n\nSince constant factors in the partition function do not matter when computing averages since they cancel I can neglect the prefactor m!*n!*m The partition function is therefore $$ Z(m,n,T)=m^{n-1}-1+e^{\\beta\\epsilon} $$\n\nThe Hemholtz free energy is then: $$ F=-k_bT*log(m^{n-1}-1+e^{\\beta\\epsilon}) $$\n\nNow I am not sure if the counting I have done above is correct and the next thing is I am not completely sure how to compute the ground state entropy.\n\nThe entropy is defined as $S=-k_{b}\\sum_{i}p_{i}log(p_i)$ and for as single state it should be $S=-k_{b}*p*log(p)$. The probability for the ground state would then be:\n\n$$ p_{G}=\\frac{e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}} $$ and hence the entropy $$ S=-\\frac{k_b*e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}}*log\\left(\\frac{e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}}\\right) $$\n\nBut still I am not quite sure if this is correct especially with the counting I feel very insecure. Thanks for your help\n\n  \u2022 $\\begingroup$ I am not sure, but here is what I think could be the right way. I am not sure why you are bothered with arranging the boxes and particles after you have considered m^n possibilities. I think that this itself includes all possible arrangements of the particles and boxes. Rearranging the order in which you consider the boxes or particles should not create more microstates. Hence I think the partition function should be (m^(n) - m) + m * e^(beta * E) $\\endgroup$ \u2013\u00a0Hari Sep 28 '18 at 15:30\n  \u2022 $\\begingroup$ @Hari. Okay but what is the criterion for creating a new microstate I think this is the point I don't quite get. So what is the criterion to be a microstate? Because I thought since the particles are distinguishable and so are the boxes any arrangement of particles and boxes would create a new microstate. Is this wrong $\\endgroup$ \u2013\u00a0zodiac Sep 29 '18 at 10:09\n  \u2022 $\\begingroup$ Suppose there are 2 boxes (B1,B2) and 2 particles (P1, P2). The microstates will be : 1) B1 (P1,P2) B2 () ; 2) B1 () B2(P1,P2) ; 3) B1 (P1) B2(P2) ; 4) B1(P2) B2(P1). I think these are the only microstates, rearranging the order in which you write B1 and B2, in this case 5) B2(P1) B1(P2) or 6) B2(P2) B1(P1) are not microstates as they are physically the same as (4) and (3) respectively. $\\endgroup$ \u2013\u00a0Hari Sep 29 '18 at 18:33\n  \u2022 $\\begingroup$ Thank but I fear I still don't get it right I guess. I mean what you are saying sounds completely reasonable. But if 5) and 6) are the same as 4) and 3) does't this mean those states have a higher entropy since they have more realizations. $\\endgroup$ \u2013\u00a0zodiac Oct 1 '18 at 6:44\n  \u2022 $\\begingroup$ And also I can place the labeled particles in different orders to the boxes since they are distinguishable. Then for example your state 1) B1 (P1,P2) B2 () could also be written as 1')B1(P2,P1) , B2(). I mean for sure those states are physically indistinguishable but dont' they have a higher a priori probability since there are more possibilities to create those states. I am sorry for bothering you again. But this seems to be a very crucial point that I don't get. I think this is also shown on this wiki page. link: en.wikipedia.org/wiki/Microstate_(statistical_mechanics). $\\endgroup$ \u2013\u00a0zodiac Oct 1 '18 at 6:44\n\nBased on Harrys comments I would like to answer this question to close this thread. It does not matter in which order I put the labeled particles in to the boxes since there are no drawers in the boxes and hence in the end I am not able to differentiate between the order of the particles anymore. This means $B(1,2,3)$ is the same as B(2,1,3) because the balls are lose in this box and are able to roll around freely. The next thing is the boxes have labels this states that box one will always be box one no matter where it is put to on the shelf. Hence there is no need to take into account the permutations of the boxes. Therefore the canonical partition function is just\n\n$$ Z(n,m,T)=(m^{n}-m)+me^{\\beta\\epsilon} $$\n\nThe Helmholtz free energy $$ F(n,m,T)=-k_{B}T=log\\left( m^{n} - m + e^{\\beta\\epsilon} \\right) $$\n\nAnd the ground state probability and the entropy stay the same since one m factors out.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/23269/differential-equation-quite-weird-task\nText:\nI'm having some trouble while trying to understand one task.. The task is as follows:\n\n$$\\ddot{x}(t) + \\dot{x}(t) + 2x(t) = \\sin(\\omega t)$$ where $x(0) = 7, t\\geq 0$\n\nThe solution is in the following form:\n\n$$x(t) = f(t) + A\\sin(\\omega t + \\varphi)$$\n\nAnd the task is: find $\\omega$ so that $A$ is max.\n\nMy understanding of this is that $f(t)$ is the solution of the homogeneous differential equation and the rest is the special solution of the nonhomogeneous equation. Still that does not give me any clue about how to evaluate the relationship between $A$ and $\\omega$. Any clues?\n\n\nSince $f$ is the (generic) homogeneous solution, you can choose to set it equal to zero; then you just have the special solution $x(t) = A\\mathrm{sin}(\\omega t+\\phi)$. You should be able to find $\\ddot{x}(t)$ and $\\dot{x}(t)$, then plug them all into your core differential equation and see what it means for both sides to be equal - if you've done it right, this will give you the relation between $\\omega$ and $A$ that you're looking for.\n\n  \u2022 $\\begingroup$ Thank you. I'm certainly able to do that, but is it right to just \"choose the solution to be equal to 0\" ? What are the consequences? $\\endgroup$ \u2013\u00a0kubal5003 Feb 22 '11 at 20:36\n  \u2022 $\\begingroup$ kubal: if you plug in the generic form for $x(t)$ into the equation and then use the fact that $f(t)$ solves the homogeneous version of the equation, you'll find that it cancels right out and you're left with exactly the same terms that you would've had if you had chosen $f(t)$ to be $0$ to begin with. $\\endgroup$ \u2013\u00a0Steven Stadnicki Feb 22 '11 at 21:37\n  \u2022 $\\begingroup$ I guess I'll have to do that in order to prove that the solution is not just a special case. This might appear on tommorows exam (I hope not) $\\endgroup$ \u2013\u00a0kubal5003 Feb 22 '11 at 22:12\n\nThe correct value of $\\omega$ is not $\\frac{\\sqrt{7}}{2} \\approx 1.32$. It's $\\sqrt{\\frac{3}{2}} \\approx 1.22$. We are looking for a near resonance effect, but you can't actually have resonance when the harmonic oscillator is damped. This makes the analysis is a little different.\n\nA reference is the section on sinusoidal forcing in the Wikipedia page on the harmonic oscillator. From the formulas there you can see that the relationship between $A$ and $\\omega$ is given by\n\n$$A = \\frac{1}{\\sqrt{\\omega^2 + (2 - \\omega^2)^2}}.$$\n\nSolving $\\frac{dA}{d \\omega} = 0$ yields $\\omega = \\sqrt{\\frac{3}{2}}$.\n\nUpdate: Here's the derivation.\n\nThe trick is to generalize, and solve the differential equation $x'' + x' + 2x = e^{i \\omega t}$. The resulting solution will have a real part and an imaginary part. Since $e^{i \\omega t} = \\cos \\omega t + i \\sin \\omega t$, you actually want the imaginary part of the solution.\n\nAs the driving force is an exponential, we know that the particular solution must be of the form $x_p(t) = c e^{i \\omega t}$. Subbing that into the differential equation produces the auxiliary equation $-c \\omega^2 + i c\\omega + 2c = 1$. Solving that for $c$ yields $$c = \\frac{1}{a + i b} = \\frac{a - i b}{a^2 + b^2},$$ where $a = 2 - \\omega^2$ and $b = \\omega$. Thus the particular solution to the complex differential equation is $$x_p(t) = \\frac{a - i b}{a^2 + b^2} (\\cos \\omega t + i \\sin \\omega t),$$ of which the imaginary part is $$-\\frac{b}{a^2 + b^2} \\cos \\omega t + \\frac{a}{a^2+b^2} \\sin \\omega t.$$ Since $A$ is just the magnitude of this solution (you're doing a rotation to the vertical axis when converting to $A \\sin (\\omega t + \\phi)$), we get $$A = \\frac{1}{\\sqrt{a^2+b^2}} = \\frac{1}{\\sqrt{\\omega^2 + (2 - \\omega^2)^2}}.$$\n\n  \u2022 $\\begingroup$ You could also get this by assuming a solution of the form $c_1 \\cos \\omega t + c_2 \\sin \\omega t$. Once you find $c_1$ and $c_2$ in terms of $\\omega$, you'll have $A = \\sqrt{c_1^2 + c_2^2}$. I like the solution with the complex exponential, though; it seems more intuitive to me. $\\endgroup$ \u2013\u00a0Mike Spivey Feb 23 '11 at 3:37\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/42930/what-is-the-expected-value-of-the-number-of-die-rolls-necessary-to-get-a-specifi\nText:\nGiven a discrete random number generator, such as a six-sided die, what is the expected value of the number of rolls necessary to roll a specific number (e.g. a six)?\n\nI think the result should be given by E$\\langle$rolls$\\rangle$ = $\\frac{1}{6}\\sum_{n=0}^\\infty{(\\frac{5}{6})^n(n+1)}$, but I don't know how to calculate the convergence of that sum.\n\nAlso, how do I calculate the variance?\n\n\nA slightly simpler recursive derivation is this. We must roll the die at least once. On the first roll we get a 6 with probability $\\frac{1}{6}$. Otherwise we start again. Hence, $E = 1 + \\frac{5}{6}E$, which gives $E=6$.\n\nHere is a more general answer:\n\nRegard rolling the die as a Bernoulli process $X_1,X_2, \\ldots$, where $X_i = $ Success, with probability $p$, and $X_i = $ Failure, with probability $1-p$. The process stops after the first success.\n\nLet $N_s$ be the length of the sequence until the first Success. This is a random integer. Then we have $$ \\Pr (N_s=k) = \\Pr(\\underbrace{FF\\cdots F}_{k-1}\\ S) = \\underbrace{(1-p)(1-p)\\cdots(1-p)}_{k-1}\\ p=(1-p)^{k-1}p=pq^{k-1}, $$ where $q=1-p$ and $k\\ge1$. This is called a Geometric Distribution, which is the discrete equivalent of the Exponential Distribution. Random variables with these distributions are called memoryless. (See Ross, Introduction to Probability Models, 9th Edition, page 284.)\n\nThe expected value and variance of $N_s \\sim \\text{Geom}(p)$ are $$ \\text{E}{N_s(p)}=\\frac{1}{p}, \\text{ and } \\text{Var}{N_s(p)} = \\frac{1-p}{p^2}. $$Proof can be found in Ross, above. Note that $$\\text{E}{N_s(p)} = 1 +(1-p)\\text{E}{N_s(p)}, \\text{ whose solution is } \\frac{1}{p}.$$\n\nIn your case $p = \\frac{1}{6}\\,$ and so E(No. rolls) = 6, and Var(No. rolls) = 30 -- Geom$(\\frac{1}{6})$ has a long tail.\n\n\nOne \"trick\" that often lets you avoid issues of convergence when solving probability problems is to use a recursive argument.\n\nYou have a 1/6 probability of rolling a 6 right away, and a 5/6 chance of rolling something else and starting the process over (but with one additional roll under your belt).\n\nLet $E$ be the expected number of rolls before getting a 6; by the reasoning above, we have:\n\n$E = (1)(1/6) + (E + 1)(5/6)$\n\nSolving for $E$ yields $E = 6$.\n\nAn alternative approach is to use the generating function. The generating function $G(t)$ for a probability distribution that only takes on integer values is defined as:\n\n$G(t) = \\Sigma_{i = 0}^{\\infty} p_i t^i$\n\nThe reason the generating function comes in handy is that $G'(1)$ gives the expected value and $G''(1) + G'(1) - (G'(1))^2$ gives the variance; one can check this directly.\n\nIn our case, the generating function is:\n\n$G(t) = (1/6)t + (1/6)(5/6)t^2 + (1/6)(5/6)^2t^3 + \\ldots$\n\nWe can rewrite this as follows:\n\n$G(t) = (1/5)(5t/6 + (5t/6)^2 + (5t/6)^3 + \\ldots)$\n\nSumming the geometric series gives $G(t) = t/(6-5t)$; from here, we can calculate $G'(t)$ and $G''(t)$, plug in $t = 1$, and use the above expressions to extract both the expected value and the variance (6 and 30, respectively).\n\n\nElliott's answer is surely the nicest. To sum the series, we can use a method similar to the geometric series.\n\nLet $$S = 1 + 2 \\cdot \\left(\\frac{5}{6}\\right) + 3 \\cdot \\left(\\frac{5}{6}\\right)^2 + \\cdots $$\n\n\n$$\\frac{5}{6}S = \\frac{5}{6} + 2 \\cdot \\left(\\frac{5}{6}\\right)^2 + 3 \\cdot \\left(\\frac{5}{6}\\right)^3 + \\cdots $$\n\n$$S - \\frac{5}{6}S = 1+ \\left(\\frac{5}{6}\\right) +\\left(\\frac{5}{6}\\right)^2 + \\cdots $$\n\nThis is just a geometric series and hence we have that\n\n$$S = 36$$\n\nNow we have that $$\\frac{1}{6} \\sum_{n=0}^\\infty \\left(\\frac{5}{6}\\right)^n (n+1) = \\frac{1}{6} \\cdot S = 6,$$ as expected.\n\n(Convergence of the series can be seen by the ratio test)\n\n  \u2022 $\\begingroup$ Very nice. It's great to see so many different ways to find the convergence value for power series. $\\endgroup$ \u2013\u00a0jeremy radcliff Jan 25 '17 at 21:12\n\nHere's an intuitive argument. Roll the die $6000$ times. You'd expect there to be $1000$ 6's among them. Consider the gaps between successive 6's in the list (plus the initial gap to the first 6). These lengths are the values of independent draws from a geometric RV with $p=1/6$, so the average gap length is the expected value you want.\n\nThe sum of these (~1000) gap lengths is 6000, and so the average gap is $6000/1000=6$ (modulo a little fudge at the end which would go to $0$ by making the string longer).\n\n\nI'm late to the party, but here's a slightly different path to the same solution. Let $X$ be the number of die rolls until we roll a specific number. Let $p$ be the probability that we roll the specific number and $q = 1-p$ be the probability that we roll any of the other numbers. We know\n\n$$ \\mathbb{E}[X] \\triangleq 1p + 2qp + 3q^2 p + 4q^3p + \\dots $$\n\nNote that the geometric series $\\sum_{x=1}^{\\infty} q^x = \\frac{q}{1-q}$. Using this fact and a little algebra and calculus, we get,\n\n$$ \\begin{align} \\mathbb{E}[X] &= 1p + 2qp + 3q^2 p + 4q^3p + \\dots \\\\ &= \\sum_{x = 0}^{\\infty} (x + 1) q^x p \\\\ &= \\sum_{x = 1}^{\\infty} x q^{x-1} p \\\\ &= \\sum_{x = 1}^{\\infty} \\frac{\\partial}{\\partial q} q^x p \\\\ &= p \\frac{\\partial}{\\partial q} \\Big( \\sum_{x = 1}^{\\infty} q^x \\Big) \\\\ &= p \\frac{\\partial}{\\partial q} \\Big( \\frac{q}{1-q} \\Big) \\\\ &= p \\frac{1}{(1 - q)^2} \\\\ &= \\frac{\\frac{1}{6}}{\\big(1 - \\frac{5}{6}\\big)^2} \\\\ &= 6 \\end{align} $$\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/35308/running-a-command-in-term-from-eshell-with-arguments\nText:\nBasically I want to run watch from eshell.\n\nSimply running watch date (for example) doesn't work (only the first header line is displayed). Apparently I should run it with term or ansi-term but these two commands take only one argument -the command, which would be watch - and I don't know where to put the arguments (i.e. date in the example above).\n\nSo, I guess my question is: What is the proper way to run watch date (or any other watch such as watch \"make myprog && ./myprog\") from eshell?\n\n\nInteresting question. I found a non-trivial answer. Looking at functions term and ansi-term, I saw that though they themselves only take one program-related argument, under the hood they both invoke functions that allow passing additional arguments to programs (make-term and term-ansi-make-term respectively). This gave me an idea about how to accomplish what you want:\n\n  \u2022 for term: (switch-to-buffer (make-term \"test-term\" \"/bin/bash\" nil \"-c\" \"watch date\"))\n  \u2022 for ansi-term: (switch-to-buffer (term-ansi-make-term \"test-ansi\" \"/bin/bash\" nil \"-c\" \"watch date\"))\n\nIt's a bit unwieldy in that form, so you might want to write a function abstracting this:\n\n(defun eshell/watch-process (process)\n                   nil \"-c\" (format \"watch %s\" process))))\n\nAnd then you can run watch-process date directly in Eshell.\n\n\nThe Eshell documentation refers to commands that are not line-oriented but are designed to run in a terminal, such as watch, as \"visual commands\". To tell Eshell that a command is a visual command, add its name to the list in the eshell-visual-commands variable as follows:\n\n(push \"watch\" eshell-visual-commands)\n\nThenceforth Eshell will automatically run watch in a term buffer.\n\nSee Input/Output in the Eshell manual.\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/4887/dijkstra-to-favor-solution-with-smallest-number-of-edges-if-several-paths-have-s\nText:\nYou can modify any graph $G$ so that Dijkstra's finds the solution with the minimal number of edges thusly:\n\nMultiply every edge weight with a number $a$, then add $1$ to the weight to penalize each additional edge in the solution, i.e.\n\n\nThis does not work for all values of $a$; $a$ needs to be at least $x$ for this to work. If $a$ is not this minimum number, it might not choose the shortest path. How do I find this minimum value $x$?\n\nPs. This was done recreationally, I'm done with homework long ago.\n\n  \u2022 $\\begingroup$ If two paths have an equal weight, the one with the fewest edges should be chosen. Sorry. I see that I did not make that clear. $\\endgroup$ \u2013\u00a0The Unfun Cat Oct 5 '12 at 19:16\n  \u2022 $\\begingroup$ You could also do it by adding $\\epsilon$ to all edge weights, where $\\epsilon < m/e$, m = minimum edge weight, e = number of edges in shortest path (or even overall, if you don't know the shortest path length). $\\endgroup$ \u2013\u00a0BlueRaja - Danny Pflughoeft Oct 5 '12 at 20:04\n  \u2022 $\\begingroup$ Interesting tidbit, thanks. Will have to look at it. $\\endgroup$ \u2013\u00a0The Unfun Cat Oct 5 '12 at 20:05\n\nGiven a graph $G = (V,E,w)$, we define $G'=(V,E,w')$ with $w'(e) = aw(e) + 1$ where $a = |E| + \\varepsilon$ for some $\\varepsilon \\geq 0$ as proposed in the comments of the question.\n\nLet $P$ a path in $G$ with cost $C$, i.e. $w(P)=C$. Then, $P$ has cost $aC + |P|$ in $G'$, i.e. $w'(P) = aC + |P|$.\n\nThe lemma follows directly from the definition of $w'$.\n\nCall the result of Dijkstra on $G'$ $P$, which is a shortest path in $G'$. Assume $P$ was not a shortest path with fewest edges (among all shortest paths) in $G$. This can happen in one of two ways.\n\n  1. $P$ is not a shortest path in $G$.\n    Then, there is a path $P'$ with $w(P') < w(P)$. As $|P|,|P'| \\leq |E| \\leq a$, this implies that also $w'(P') < w'(P)$ with above lemma\u00b9. This contradicts that $P$ was chosen as shortest path in $G'$.\n  2. $P$ is a shortest path but there is a shortest path with fewer edges.\n    Then, there is another shortest path $P'$ -- i.e. $w(P) = w(P')$ -- with $|P'| < |P|$. This implies that $w'(P') < w'(P)$ by above lemma, which again contradicts that $P$ is a shortest path in $G'$.\n\nAs both cases have led to a contradiction, $P$ is indeed a shortest path with fewest edges in $G$.\n\nThat covers one half of the proposition. What about $a < |E|$, i.e. $a = |E| - \\varepsilon$ with $\\varepsilon \\in (0,|E|)$?\n\n  1. Actually, we also need that $a$ or all weights in $G$ are integers. Otherwise, $w(P') < w(P)$ does not cause the weights in $G'$ to be at least $|E|$ apart. This is not a restriction, though; we can always scale $w$ with a constant factor so that all weights are integer, assuming we start with rational weights.\n  \u2022 $\\begingroup$ I haven't yet been able to come up with a proof that $a = |E|$ is the smallest $a$ for which this works. I'll give it some more thought. $\\endgroup$ \u2013\u00a0Raphael Oct 7 '12 at 22:17\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/47636/prompt-with-pre-populated-minibuffer-input/47642\nText:\nI need to prompt user for input, but I also would like to prepend the user's minibuffer input with a string. e.g.:\n\n  \u2022 user runs my function\n  \u2022 after the prompt, the text awesome (hardcoded string) is automatically inserted in the minibuffer\n  \u2022 user can start typing and it simply appends what she types to awesome, which is already there\n  \u2022 user types bananas, presses RET, the value returned is awesome bananas\n\nUser should also be able to modify awesome part of the string. For example one may chose to send bad bananas instead.\n\nCan someone help me to achieve that? I've tried with completing-read, but can't get it right.\n\n\nI think what you need is (read-string \"input: \" \"awesome\").\n\n  \u2022 I don't have a read-input function, I think you meant read-string. \u2013\u00a0Omar Feb 6 at 2:13\n  \u2022 1\n    It looks like read-input is obsolete, and read-string is preferred. I updated the answer. Thanks for noting it! \u2013\u00a0John Kitchin Feb 6 at 2:52\n  \u2022 Exactly what I needed. Thanks John! \u2013\u00a0iLemming Feb 6 at 18:48\n\nI think you're asking how you can tell completing-read to insert some text in the minibuffer by default, so you can append some more text that you type, to have the returned value be the result of the append.\n\nThat is, I don't think you're asking about prepending awesome to the prompt, but rather appending it to the prompt. I think you're saying that you want it to be part of the returned value (by default, i.e., if the user doesn't erase it), not part of the prompt. (I've edited your question along those lines. If I guessed wrong then please reject the edit.)\n\n(completing-read \"My prompt: \" '(\"awesome blue\" \"awesome red\" \"some\" \"other\")\n                 nil nil \"awesome \" nil \"a default, if you want it\")\n\nThe initial input is the 5th arg. The 3rd arg is nil, so you can enter anything you like - it need not match any of the completion candidates. C-h f completing-read tells you:\n\ncompleting-read is a built-in function in C source code.\n\n\nRead a string in the minibuffer, with completion.\n\nPROMPT is a string to prompt with; normally it ends in a colon and a space.\n\nCOLLECTION can be a list of strings, an alist, an obarray or a hash table. COLLECTION can also be a function to do the completion itself.\n\nPREDICATE limits completion to a subset of COLLECTION.\n\nSee try-completion, all-completions, test-completion, and completion-boundaries, for more details on completion, COLLECTION, and PREDICATE. See also Info node (elisp)Basic Completion for the details about completion, and Info node (elisp)Programmed Completion for expectations from COLLECTION when it\u2019s a function.\n\nREQUIRE-MATCH can take the following values:\n\n  \u2022 t means that the user is not allowed to exit unless the input is (or completes to) an element of COLLECTION or is null.\n\n  \u2022 nil means that the user can exit with any input.\n\n  \u2022 confirm means that the user can exit with any input, but she needs to confirm her choice if the input is not an element of COLLECTION.\n\n  \u2022 confirm-after-completion means that the user can exit with any input, but she needs to confirm her choice if she called minibuffer-complete right before minibuffer-complete-and-exit and the input is not an element of COLLECTION.\n\n  \u2022 anything else behaves like t except that typing RET does not exit if it does non-null completion.\n\nIf the input is null, completing-read returns DEF, or the first element of the list of default values, or an empty string if DEF is nil, regardless of the value of REQUIRE-MATCH.\n\nIf INITIAL-INPUT is non-nil, insert it in the minibuffer initially, with point positioned at the end. If it is (STRING . POSITION), the initial input is STRING, but point is placed at zero-indexed position POSITION in STRING. (Note that this is different from read-from-minibuffer and related functions, which use one-indexing for POSITION.) This feature is deprecated--it is best to pass nil for INITIAL-INPUT and supply the default value DEF instead. The user can yank the default value into the minibuffer easily using M-n.\n\nHIST, if non-nil, specifies a history list and optionally the initial position in the list. It can be a symbol, which is the history list variable to use, or it can be a cons cell (HISTVAR . HISTPOS). In that case, HISTVAR is the history list variable to use, and HISTPOS is the initial position (the position in the list used by the minibuffer history commands). For consistency, you should also specify that element of the history as the value of INITIAL-INPUT. (This is the only case in which you should use INITIAL-INPUT instead of DEF.) Positions are counted starting from 1 at the beginning of the list. The variable history-length controls the maximum length of a history list.\n\nDEF, if non-nil, is the default value or the list of default values.\n\nIf INHERIT-INPUT-METHOD is non-nil, the minibuffer inherits the current input method and the setting of enable-multibyte-characters.\n\nCompletion ignores case if the ambient value of completion-ignore-case is non-nil.\n\nSee also completing-read-function.\n\nYou'll notice that it tells you that parameter INITIAL-INPUT is deprecated. That's nonsense, IMHO. That just reflects someone's preference for not using it, as a user-interface style. If you want input inserted initially, that's what it's for. Whoever deprecated it is really just telling you that you shouldn't want input inserted initially. If you want it then do it.\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/189703/symbolic-integral\nText:\nI am in trouble with the following integral:\n\n$$rtartaruga(r)=\\int \\frac{\\Sigma(r') }{\\Delta(r') \\sqrt{\\Delta th}} d r'$$ Where: $$\\Delta(r) =\\left(a^2+r^2\\right) \\left(\\frac{r^2}{l^2}+1\\right)-2 m r$$ $$\\Sigma(r) =\\sqrt{\\text{$\\Delta $th} \\left(a^2+r^2\\right)^2-a^2 \\Delta \\sin ^2(\\theta )}$$ And $\\Delta th$ is a constant in $r$: $\\text{$\\Delta $th}=1-\\frac{a^2 \\cos ^2(\\theta )}{l^2}$.\n\nIn the following region of parameters: $|a|<l$ and $m>m_c$ (where $m_c$ is a certain positive constant $\\Delta (r)$ has two positive roots and the integrand is divergent in these points.\n\nI would really like to have an analytical solution for the above integral so i try to evaluate it symbolically:\n\n\\[CapitalSigma] = \n  Sqrt[(r^2 + a^2)^2 \\[CapitalDelta]th - \n    a^2 \\[CapitalDelta] Sin[\\[Theta]]^2];\n\n\\[CapitalDelta] = (r^2 + a^2) (1 + r^2/l^2) - 2 m r;\n\n\\[CapitalDelta]th = 1 - a^2/l^2 Cos[\\[Theta]]^2;\n\n mc = l/(3 Sqrt[6]) (Sqrt[(1 + a^2/l^2) + 12/l^2 a^2] + 2 a^2/l^2 + 2)*\n   Sqrt[(Sqrt[(1 + a^2/l^2) + 12/l^2 a^2] - a^2/l^2 - 1)];\n\n\n rtartaruga[r_] = \n  r, Assumptions -> {{r, m, \\[Theta], a, l} \\[Element] Reals, \n    Abs[a] < l, m > mc, r > 0, l > 0, \\[Theta] >= 0, \\[Theta] <= Pi}, \n  PrincipalValue -> True]\n\nThe output is a very long one and includes special functions. When i try to evaluate it at some point:\n\na = 1/2;\nl = 2;\nm = 1;\n\\[Theta] = Pi/4;\nClear[a, l, m, \\[Theta]]  \n\nI get:\n\n-0.274199 - 0.47465 I\n\nBut the result has to be real as the integrand!\n\nI know that there are other similar questions on this issue, and i understand that the problem is about branch cuts on the complex plane, but practically i can't find a way to get out my problem (if it's possible).\n\nMay someone help me please?\n\nThanks in advance!\n\n  \u2022 $\\begingroup$ If I am reading this correctly, it is an antiderivative as opposed to a definite integral. So the result need not be real valued. Also the two options being given will be ignored (possibly the Assumptions will have a minor effect, I'm not absolutely certain about that one). $\\endgroup$ \u2013\u00a0Daniel Lichtblau Jan 17 at 19:02\n  \u2022 $\\begingroup$ Hi! First of all thank you for your reply.The indefinite integral of a real function could has a constant imaginary part, right? The problem is that this is not my case:ln[81]:= a = 1/2; l = 2; m = 1; [Theta] = Pi/4; N[rtartaruga[[0.4], 10] N[rtartaruga[[0.7], 10] N[rtartaruga[[5], 10] N[rtartaruga[[10], 10] N[rtartaruga[20], 10] Clear[a, l, m, [Theta]] Out[85]= -0.274199 - 0.47465 I Out[86]= -0.166399 - 0.492226 I Out[87]= 4.822826746 + 3.423249825 I Out[88]= -2.238523542 + 0.*10^-10 I Out[89]= -2.045605814 + 0.*10^-10 I $\\endgroup$ \u2013\u00a0SuperBaba Jan 18 at 10:25\n  \u2022 $\\begingroup$ Due to branch cuts it could be piecewise constant actually. $\\endgroup$ \u2013\u00a0Daniel Lichtblau Jan 18 at 16:50\n  \u2022 $\\begingroup$ Thank you very much, now it's all clear to me! $\\endgroup$ \u2013\u00a0SuperBaba Jan 26 at 13:57\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/98596/check-if-two-items-are-equal-after-replacing\nText:\nLet's say that an item is either a natural number or a list of items. Examples of items are:\n\n  \u2022 1\n  \u2022 [2]\n  \u2022 [4, [3, 1], 3, 4]\n\nA rule states that two items are equal. For example:\n\n  \u2022 1 = 2\n  \u2022 3 = [3, 1]\n  \u2022 [4, 3] = [1, 5]\n\nWhen using these example rules, we can transform [4, [3, 2]] into [4, [3, 1]] into [4, 3] into [1, 5] and we can say that [4, [3, 2]] equals [1, 5].\n\nI want to find an algorithm that, given items $a$ and $b$ and a finite set of rules, determines if $a = b$.\n\nI already thought of an algorithm that works in some cases. But I hope to find an efficient algorithm that works in all cases. It would also be nice if the algorithm can detect $a \\not= b$ instead of infinitely searching for ways to let $a = b$. Is this a known problem? Any help is appreciated.\n\nNote: We can simplify the problem by only allowing the number 1 instead of every natural number. This is equivalent, because we can transform 1 into [1], 2 into [1, 1], 3 into [1, 1, 1], etcetera.\n\n  \u2022 1\n    $\\begingroup$ This looks like the decision problem for the theory of equality with uninterpreted functions, from smt (arrays here being function calls). However, I don't know of any nice explanation of how to solve it quickly, beyond using Union Find. $\\endgroup$ \u2013\u00a0Curtis F Oct 15 '18 at 1:25\n  \u2022 1\n    $\\begingroup$ @CurtisF The underlying problem is about function calls. I thought this would be an easier way to display the problem. $\\endgroup$ \u2013\u00a0Paul Oct 15 '18 at 2:15\n  \u2022 $\\begingroup$ @Paul, if this question comes from a book or a paper, can you add a reference? If it comes back your personal thinking, any background or motivation? It would be great for you to add those information in the question, which should motivate and help people to tackle this question more and better. $\\endgroup$ \u2013\u00a0Apass.Jack Oct 23 '18 at 3:29\n\nI found a solution to my problem. Let's look at the simpler but equivalent problem in which an item is recursively defined as an empty list or a list of items. I'll summarize the algorithm.\n\n\n  \u2022 Int counter starting at 0\n  \u2022 Hash map: list of integers $\\to$ integer. The integers represent equivalence classes.\n\nFunction find(item) $\\to$ int:\n\nFinds the equivalence class of an item. Recursively call find on all the children of item. Now you have a list of ints. If this list of ints is contained in the hash map, return the corresponding value. If not, add the list to the hash map with the counter as value. Increase the counter and return the value.\n\nFunction merge(int a, int b):\n\nMerges two equivalence classes a and b. In the hash map, replace all occurences (both in keys and in values) of a by b. Now it can happen that one key is mapped to multiple values. If that happens, again merge those values. Repeat this until every key maps to a unique value.\n\n\nFor every rule c = d, call merge(find(c), find(d)). Then to see if a = b, check if find(a) = find(b).\n\n  \u2022 2\n    $\\begingroup$ \"Finds the equivalence class of an item\". There are infinitely many elements in an equivalence class. $3 =[3, 1] = [[3,1],1] = [[[3,1],1]]=\\cdots$. Have you handled them all? $\\endgroup$ \u2013\u00a0Apass.Jack Oct 23 '18 at 23:28\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/202755/independent-permutation-symmetry-of-a-tensor-using-tensorsymmetry-command\nText:\nSuppose I have this tensor $A_{ijkl} = \\epsilon_{ik} \\epsilon_{jl}+\\epsilon_{il} \\epsilon_{jk}$. Now I want to find all the independent permutation symmetries of the indices of this tensor. The answer is $(ij)$,$(kl)$,$(ik)(jl)$, where by $(ij)$ I mean the tensor is symmetric under the permutation of $i,j$. Similarly $(ik)(jl)$ represents the multiplication of two disjoint cycles.\n\nI am very new to computation and I want to implement this in Mathematica. Here's what I tried:\n\nss = TensorProduct[LeviCivitaTensor[2], LeviCivitaTensor[2]]; A = ss + TensorTranspose[ss, {Cycles[{{2, 4}}], 1}]; TensorSymmetry[A] \n\nThis yields the result:\n\n{{Cycles[{{2, 4}}], 1}, {Cycles[{{1, 2}, {3, 4}}], 1}, {Cycles[{{1, 2, 3, 4}}], 1}}\n\nWhich when translated back into my notation reads $(kl)$, $ (ik) (jl) $ and $(ikjl)$, but we can see that the results are not simplified. For example we can use $ (ik) (jl) $ to simplify $(ikjl)$ as follows:\n\n$ (ikjl) = (ikj) (jl) = (jik) (jl) = (ji) (ik) (jl)$\n\nSo $(ijkl)$ when used with $(ik)(jl)$ reduces to $(ij) \\equiv (ji)$ as wanted. I want to do this simplification using Mathematica, in other words I want Mathematica to use all the cycles in the list to reduce it to a simplified and independent one. Could someone please help me to implement this? Thanks in advance. On a side note I find manipulating symbolic tensors in Mathematica very difficult. Suggestion for packages that helps this kind of calculation is much appreciated. I know there exists packages like Ricci which are dedicated for GR related calculations, I want something more simple and accessible for tensor analysis.\n\n\nI don't think your TensorProduct expression agrees with your notation. If you correct the definition of A you get your desired symmetries:\n\nA = TensorTranspose[TensorProduct[LeviCivitaTensor[2],LeviCivitaTensor[2]],{1,3,2,4}] + \n\n\n{{Cycles[{{3, 4}}], 1}, {Cycles[{{1, 2}}], 1}, {Cycles[{{1, 3}, {2, 4}}], 1}}\n\n  \u2022 $\\begingroup$ Thank you for your answer, but if we take a more complicated example Mathematica does not simplify as pointed out, for example take 3 epsilon tensor direct product ordered as {1,2,3,4,5,6}. Mathematica gives you as one of the Tensor symmetries this: (135)(246), which using others could be simplified to (15)(26). $\\endgroup$ \u2013\u00a0Sudhakantha Girmohanta Jul 27 at 3:54\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/56323/baire-category-theorem-application\nText:\nIn Antoine Henrot Michel Pierre - Variation et optimisation de formes, Une analyse geometrique, a book I'm studying I found an interesting problem. The problem is listed below. The first 3 points of the problem are pretty easy, and I solved them. The 4-th seems a little harder. The only indication I get is to use point 3) and the Baire theorem for $(\\Sigma,\\delta)$.\n\nDenote by $\\Sigma$ the quotient space of the family of Lebesgue measurable sets of $\\Bbb{R}^N$ by the equivalence relation $E_1 \\sim E_2 \\Leftrightarrow\\chi_{E_1}=\\chi_{E_2} a.e.$. Denote by $|X|$ the Lebesgue measure of the measurable set $X$.\n\n1) Prove that $\\delta(E_1,E_2)=\\arctan( |E_1 \\Delta E_2|)$ is a distance on $\\Sigma$.\n\n2) Prove that given $(E_n)_{n \\geq 1}, E$ measurable sets in $\\Bbb{R}^N$ the following three properties are equivalent.\n\n  \u2022 $\\delta(E_n,E) \\to 0$;\n\n  \u2022 $\\chi_{E_n}-\\chi_E \\xrightarrow{\\sigma(L^1,L^\\infty)} 0$;\n\n  \u2022 $\\chi_{E_n}-\\chi_E \\xrightarrow{L^1} 0$.\n\n3) Prove that $(\\Sigma,\\delta)$ is a complete metric space.\n\n4) Given the sequence $ (f_n)$ of integrable real valued functions on $\\Bbb{R}^N$, such that for any measurable set $E$ of $\\Bbb{R}^N$ there exists $\\displaystyle \\lim_{n\\to \\infty}\\int_E f_n$, prove that if $|E| \\to 0$ then $\\displaystyle\\sup_n\\int_E |f_n| \\to 0$. (Hint: Use the Baire category theorem for $(\\Sigma,\\delta)$)\n\nThe question is: How can I apply Baire theorem to solve the 4-th point in the problem?\n\n\nChoose $\\varepsilon > 0$ and consider sets defined by $$\\Sigma_k = \\{E:\\ \\left|\\int\\limits_{E} (f_n-f_m) \\right| \\leqslant \\varepsilon, \\textrm{ if } n,m \\geqslant k \\}$$ Since for any measurable set a limit of integrals exists, we have $\\Sigma = \\bigcup\\limits_{k} \\Sigma_k$. Note, that given an integrable function $f$, the functional $f(E):= \\int\\limits_{E}f$ is continuous respect to $E$ in metric $\\delta$. Indeed, $f(E)-f(F) = \\int f \\cdot ( 1_E - 1_F )$, hence $|f(E)-f(F)| \\leqslant \\int |f| \\cdot | 1_E - 1_F | = \\int |f| \\cdot 1_{E \\Delta F} = \\int\\limits_{E\\Delta F} |f|$.\n\nThe last expression tends to $0$ if $|E\\Delta F|$ tends to $0$ because of integrability of $f$, equivalently if $d(E,F)\\to 0$. This remark shows that sets $\\Sigma_k$ are closed as an intersection of closed subsets of the space $(\\Sigma,d)$.\n\nFrom Baire theorem we obtain that one of sets $\\Sigma_k$ has an interior point. Therefore, there exists a measurable set $E_0$ and integer $k$ such that the inequality $ |f_n(E)-f_m(E) | \\leqslant \\varepsilon$ holds, whenever $|E\\Delta E_0| \\leqslant \\delta$ and $m,n\\geqslant k$. We will show, that this inequality holds in fact for any set $E$, provided that its measure is sufficiency small.\n\nBy identities $\\mathbf{1}_{E\\cup E_0} - \\mathbf{1}_{E_0} = \\mathbf{1}_{E\\cap E_0^{c}}$ and $\\mathbf{1}_{E_0}-\\mathbf{1}_{E_0\\setminus E} = \\mathbf{1}_{E\\cap E_0}$ we obtain for an arbitrary integrable $f$ $$f(E) = f(E \\cap E_0^{c}) + f(E\\cap E_0) = f(E\\cup E_0) - f(E_0) + f(E_0) - f(E_0\\setminus E)$$ If $|E| < \\delta$, then all of sets $E_0,E_0\\cup E, E_0\\setminus E$, belong to the ball $\\{E:\\ |E\\Delta E_0| < \\delta \\}$. Applying the last inequality to $f_n-f_m$ and $|E| < \\delta$ we get $$ |f_n(E)-f_m(E)| \\leqslant 2\\varepsilon \\quad \\textrm { if } |E|<\\delta, \\ n,m\\geqslant k$$\n\nFinally, observe that the finite family of integrable functions $f_1,\\ldots, f_k$ is obviously locally uniformly integrable, i.e. $\\sup\\limits_{i\\leqslant k} |f_i(E)| \\to 0$ if $|E|\\to 0$. Therefore, for sufficiency small $\\delta'$ we have $$|f_i(E)|\\leqslant \\varepsilon \\quad \\textrm{ if } |E| < \\delta', i\\leqslant k$$\n\nGluing together two estimates that have been derived, we see that for some positive $\\delta$\n\n$$ \\left|\\int\\limits_{E} f_n\\right| \\leqslant 3\\varepsilon, \\quad \\textrm{ if } |E| \\leqslant \\delta$$\n\nWe have estimated integrals for functions $f_n$, instead their modulus. It doesn't matter, however. Namely, applying the last estimate to the set $E\\cap \\{f_n > 0\\}$ and $E\\cap \\{f_n < 0\\}$ respectively (both contained in $E$ hence with a smaller measure), gives finally\n\n$$ \\int\\limits_{E} |f_n| \\leqslant 6\\varepsilon, \\quad \\textrm{ if } |E| \\leqslant \\delta$$\n\nWhat finished the proof.\n\n  \u2022 $\\begingroup$ Very nice! $\\mbox{}$ $\\endgroup$ \u2013\u00a0Nate Eldredge Mar 14 '11 at 15:58\n  \u2022 $\\begingroup$ An interesting exercise :-) However, my professor told me, when I showed him this proof, that it is possible to give a short proof without the Baire theorem, using Schur property of the sequences space $l^{1}$ $\\endgroup$ \u2013\u00a0Maciej S. Mar 14 '11 at 17:03\n  \u2022 $\\begingroup$ Very beautiful proof. $\\endgroup$ \u2013\u00a0Beni Bogosel Mar 15 '11 at 6:04\n\nBy the way, in a posted solution we used only following properties of functionals $f(E)=\\int\\limits_{E} f$:\n\n  1. Continuous respect to $|E|$ (Lebesgue measure)\n  2. Additive (on disjoint sets)\n  3. Finite\n\nTherefore, our problem can be reformulated in a following way:\n\nSuppose, that $\\mu_n$ is a sequence of finite measures, absolutely continuous w.r.t. the Lebesgue measure. Then $\\sup\\limits_{n} \\ |\\mu_n|(E) \\to 0$ if $|E|\\to 0$.\n\nSo we have proved Vitali-Hahn-Saks theorem :-)\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1189169/find-a-branch-of-log-2z-1-that-is-analytic-at-all-points-in-the-plane\nText:\nFind a branch of $\\log (2z - 1)$ that is analytic at all points in the plane except those on the following rays\n\na) {$x + iy : x \\leq \\frac{1}{2}, y = 0$}\n\nDefinition: $F(z)$ is said to be a branch of a multiple valued function $f(z)$ in a domain $D$ if $F(z)$ is single valued and continuous in D and has the property that, for each $ z$ in $D$, the value $F(z)$ is one of the values of $f(z)$\n\nCan someone please help me start this problem? I don't how to start, and there are no examples in the book. I would really appreciate it . Thanks\n\n\nThe best idea is probably to substitute variables, and investigate what happens to the given ray after the substitution:\n\nLet, for example, $w=u+i\\cdot v=2z-1=2(x+i\\cdot y)-1$. Then we get that $z\\in \\mathbb{C}\\setminus(-\\infty,1/2]\\Leftrightarrow w\\in \\mathbb{C}\\setminus(-\\infty,0]$.\n\nNow, by definition, $\\log(w)=\\ln|w|+i\\cdot \\arg(w)$. Thus you should only investigate the argument. Basically, what we want to avoid is to have an argument branch that is continuous when $\\Re(w)=u<0$.\n\nLet us therefore create a branch for $\\arg$, which we will call $\\tilde\\arg$. We define this branch by $\\tilde\\arg(w):=\\theta(w)$, where $\\theta$ is a continuosly varying argument for $w$ on one of the intervals $(-\\pi+2n\\pi,\\pi+2n\\pi)$, $n\\in \\mathbb{Z}$. This means that $\\tilde\\arg(w)$ is continuous for all $w\\notin (-\\infty,0]$.\n\nThus, we define the suitable branch of $\\log$ with $\\tilde\\log(w):=ln|w|+i\\cdot \\tilde\\arg(w)$. As the argument now varies continuously, this branch of the logarithm is now analytic on the desired set.\n\nAn example of a branch that works in this case is the principal branch of $\\log$, which has an argument varying continuosly between $(-\\pi,\\pi)$.\n\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/56324/negative-voltage-level-shifting-to-an-adc\nText:\nI am currently building a project that uses an AD595 analog devices chip to linearize the output of the Thermocouple sensor to 10mv/deg C. This output is to be connected to the ADC input of a Zigbee radio, with a max input of 1.2v. Given that the Zigbee input determines the range, this would achieve a 0-120 degree temperature range. I am now trying to adjust this design to also sense negative temperature.\n\nThe AD595 chip can run as dual-supply by connecting -5v and +5v, to give both positive and negative output, however The zigbee radio will not accept a negative voltage input. I believe i now need to place in the design a Non-Inverting Summing Amplifier to \"level shift\" the range so that \"-1.2v - 0v - 1.2v\" becomes \"0v - 0.6v - 1.2v\" and can be interperated by the ADC. I am fairly new to this and i'm not sure where to start, it being especially difficult using a negative voltage.\n\nSo far i have used a voltage divider on the output to produce a 5mv/deg C output thus increasing the temperature range to 0-240 deg C. I will have a regulated 5V (ad595), 3.3V (for zigbee) and -5V (for dual) supply.\n\nIf anyone could help or point me towards worthwhile resources i would appreciate it a lot.\n\n\n  \u2022 1\n    \\$\\begingroup\\$ try electronics.stackexchange.com/questions/55644/\u2026. Also, all the automatically generated \"related\" links. \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 12:12\n  \u2022 \\$\\begingroup\\$ Thanks... I have already viewed these responses and haven't found a solution - the link you posted differs from what i am asking - hence why i am asking this question. \\$\\endgroup\\$ \u2013\u00a0Nick G Jan 28 '13 at 12:45\n  \u2022 \\$\\begingroup\\$ How do any of those solutions differ other than by shifting by different amounts? Shifting, attenuating, or multiplying a voltage is a very common task. Where exactly are you stuck on understanding the existing solutions? \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 13:08\n  \u2022 \\$\\begingroup\\$ Please take a look at my question. I need to achieve 0V-1.2V from -1.2V to +1.2V. The solution you posted above shifts 0V-5V to a negative-positive 2.5V range. Level shifting may be a common task, however as i stated in the question \"I am fairly new to this...\" If you need me to clariy anything in the question i will gladly do so. \\$\\endgroup\\$ \u2013\u00a0Nick G Jan 28 '13 at 13:14\n  \u2022 \\$\\begingroup\\$ What temperature range do you need to measure, exactly? There are ways to measure negative temperatures with the AD595 without negative voltages, relative to ground. The main limitation is the range of temperatures that can be measured, given the difference between the supply rails. Although nominally starting at 0 degrees, this range can trivially be shifted up and down. \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 13:20\n\nHere's a single supply inverting opamp configuration that will do what you want. You will need an opamp capable of output drive to it's lower rail (You will probably want to include a small capacitor across R2 to limit bandwidth, since you don't need much for thermocouple readings)\nR3/R2 may need to be increased in order not to load thermocouple depending on type - EDIT, just noticed the output is coming from the AD595, so it's probably low impedance (not checked datasheet) and fine as is:\n\nLevel Shift\n\nR3/R2 simply divide the input voltage by 2. R1 and R5 present 400mV to the positive input. Since the opamp tries to keep the two inputs equal, it creates a level shift. For example, when there is -1.2V at the input, to keep the inverting input at 400mV, there needs to be 1.2V at the output. We can now see R3/R2 as a voltage divider with -1.2V at one end and +1.2V at the other, we get 2.4V across R3+R2, so the voltage across R3 is:\n\n2.4V * (R3 / (R2 + R3)) = 2.4V * (10k\u03a9 / 15k\u03a9) = 1.6V and so:\n\n-1.2V + 1.6V = 400mV\n\nYou can run the calculations for the other input voltages and see how it works across the range (remembering there is always 400mV at the inverting input, and effectively no current flows into the input)\n\nAnother way to look at it given the above is, say we have -0.6V at the input. We know there must be +0.4V at the other side of R3, so the current flowing through R3 is:\n\n(0.4V - -0.6V) / 10k\u03a9 = 0.1mA\n\nNow we know none of this current flows into the inverting input, so it must flow through R2:\n\n5k\u03a9 * 0.1mA = 0.5V\n\n0.4V + 0.5V = 0.9V at the output\n\n\nLevel Shift Simulation\n\nIf you need it non-inverting, you can easily do this in firmware or add a simple inverting buffer after this.\n\n\nJust had a look at the Zigbee datasheet and it seems the Vref is fixed at 1.2V (although there is Vref pin, I couldn't find any mention of how to use it in the analog IO section), so you have to work with this unless you use an external (possibly higher resolution) ADC and feed the data to the Zigbee. It's a 10-bit ADC, so 1.2V / 1024 = ~1.17mV LSB, which won't be so bad with with filtering (which use a low cutoff since you have a slowly changing signal from the thermocouple)\nBear in mind the ADC595 has an calibration error of around +-1\u00b0C (or +-3%deg;C depending on which variant you are using) so absolute accuracy will not be excellent, but you could go for a higher resolution as mention if you wanted to.\nSo read the ADC595 datasheet advice thoroughly, pay attention to the PCB layout (if possible a 4-layer with solid ground plane), keep any digital signals away from the analog as best you can and use plenty of decoupling and all should be well.\n\n  \u2022 \\$\\begingroup\\$ Many thanks for that! Could you please explain how you obtained the values for R1-R5? Out of interest - what is the simulation software you are using? Thank you again. \\$\\endgroup\\$ \u2013\u00a0Nick G Jan 28 '13 at 13:40\n  \u2022 \\$\\begingroup\\$ I added a description of how it works. Note that the values are not set in stone, it's the ratios that are important. The higher R2/R3, the higher the input impedance. The higher R1 and R5, the less power consumption (but too high and it's more susceptible to noise) \\$\\endgroup\\$ \u2013\u00a0Oli Glaser Jan 28 '13 at 13:58\n  \u2022 \\$\\begingroup\\$ Input impedance is just R3, since the inverting input is a virtual ground (it is always equal to the non-inverting input). description at wikipedia \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 14:43\n  \u2022 \\$\\begingroup\\$ @PhilFrost - Yes, I know, but the ratio stays the same in this case (e.g. if R2 is increased, R3 must be) so I just put it this way instead. Although note that in this case the inverting input is not at the same value as thermocouple ground. \\$\\endgroup\\$ \u2013\u00a0Oli Glaser Jan 28 '13 at 15:09\n  \u2022 \\$\\begingroup\\$ @PhilFrost - Note that DC input impedance changes with applied voltage for this reason (e.g. if the input voltage is at -1V, it sees an effective impedance of -1V / 140uA = 7.142k) \\$\\endgroup\\$ \u2013\u00a0Oli Glaser Jan 28 '13 at 15:36\n\nThe AD595 can measure negative temperatures without a negative power supply. What it actually needs is a voltage that's more negative than its COM terminal. When the datasheet says \"output is 0V at 0 degrees\", what it means is, \"output is 0V relative to COM at 0 degrees.\" There's no reason COM must be your circuit ground. For example, if you wanted 0 degrees to be the middle of your supply voltage, you could do this:\n\nvoltage divider\n\nFrom the perspective of the ADC595, COM is \"ground\" and it has supply voltages (known as \"ground\" and \\$V_{cc}\\$ elsewhere) of \\$\\pm \\frac{1}{2}V_{cc}\\$. That what the ADC595 conisders \"ground\" is actually half of \\$V_{cc}\\$ to the rest of the circuit doesn't affect its operation at all, except now you don't also need a -5V supply.\n\nThis is a simple resistive voltage divider. R2 exists to calibrate for any differences between R1 and R3. You could use just a pot, or just R1 and R3 also, depending on how carefully you need to calibrate this.\n\nThis potentially introduces two errors: the first is that Vcc may not be a stable voltage. If Vcc isn't regulated well enough to meet your accuracy requirements, then you can construct a more stable voltage source to use instead of Vcc. That's enough of a problem to merit another question. But also maybe your ADC is referenced to Vcc, in which case this is an advantage, not a problem.\n\nThe other is that the current going in or out of COM will change your voltage reference. The current should be small, so this should not be a big error. The smaller you make the resistors, the smaller this error will be, but also the more power you will waste in the voltage divider. To eliminate this error, you can buffer the output of the voltage divider before connecting it to COM.\n\nAlso check out the section in the datasheet, \"RECALIBRATION PRINCIPLES AND LIMITATIONS\". This discusses ways to change the gain and zero point of the internal amplifier.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3188325/in-how-many-ways-can-7-women-10-men-sit-at-table-such-that-no-woman-sits-beside\nText:\nWe have $7$ women and $10$ men; they sit at a table. I've been trying to solve how many ways can they sit excluding the case of women sitting next to each other.\n\nMy reasoning was the following: I will have to alternate woman and men to certain extent so that no woman will sit next to another woman. The possible alternations are the following cases:\n\n$a)$ One of $7$ woman takes the first sit; one of $10$ men take the second; one of $6$ remaining women take the third; one of $9$ remaining men take the fourth, etc. So I have $10*7*9*6*8*5*7*4*6*3*5*2*4*1=10!7!$ possibilties.\n\n$b)$One of $10$ men takes the first place; one of $7$ woman the second; etc. Again, $10!7!$ possibilities, but the order has changed.\n\nIn either case, I have $3$ men remaining. Let's call $A$ and $A'$ the selections of alternated men and woman that I described on points $a)$ and $b)$, and $S$ the selection of the three remaining men. The first man of $S$ is any of the three remaining; the second man of $S$ is any of the two remaining; the last one is the one that's neither of the previous two. So I have for $S$ $3*2*1=3!$ cases.\n\nSo my posibilities are that $A$ is the case or $A'$ is the case, and $P$. Which leaves me with $(10!7!+10!7!)*3!$ posibilities.\n\nIs my reasoning okay? With this type of problems it troubles me how hard it is to actually test or check if one's answer is right. (Excuse any error on my english, it's not my native language.)\n\n  \u2022 1\n    $\\begingroup$ Is the table round? $\\endgroup$ \u2013\u00a0Dbchatto67 Apr 15 '19 at 5:45\n  \u2022 $\\begingroup$ Yes, sorry I forgot to say this. $\\endgroup$ \u2013\u00a0lafinur Apr 15 '19 at 14:06\n\nYour result is correct. More generally, assume that there are $m$ men and $w$ women with $m\\geq w\\geq 1$. Number the $m+n$ chairs around the circular table from $1$ to $m+n$ and let the \"oldest\" woman sit down at the $1$-st chair. In our final arrangement, let $x_i$ be the number of men between the $i$-th woman and the next one. Then $$x_1+x_2+\\dots +x_w=m$$ where each $x_i$ is a positive integer. The number of solutions of this equation is $\\binom{m-1}{w-1}$ (see stars-and-bars). Each solution tells us which chair goes to a man or to a women. Now we have $(w-1)!$ ways to place the remaining $w-1$ women and $m!$ ways to place the $m$ men. Therefore the number of arrangements is $$\\binom{m-1}{w-1}(w-1)!m!=\\frac{(m-1)!m!}{(m-w)!}.$$ For $m=10$ and $w=7$ the above formula gives $$\\frac{9!\\cdot 10!}{3!}=219469824000$$ which coincides with your result $(10!7!+10!7!)3!$.\n\n  \u2022 1\n    $\\begingroup$ I really didn't expect my result to be correct, haha. Well, surprises come in life! Thank you very much, Robert, for your assistance! $\\endgroup$ \u2013\u00a0lafinur Apr 15 '19 at 14:10\n\nRobert Z has provided a nice solution. Here is another approach.\n\nSuppose Edward is one of the men. We will use him as a reference point. Seat Edward first. Once Edward has been seated, there are $9!$ ways to seat the remaining men as we proceed clockwise around the table. This creates ten spaces in which we can place the women, one to the left of each of the ten men. To ensure that the women are separated, we choose seven of these ten spaces in which to place a woman. The women can be arranged in those spaces in $7!$ ways. Hence, the number of admissible arrangements is $$9!\\binom{10}{7}7!$$ For $m$ men and $w$ women, a similar argument yields $$(m - 1)!\\binom{m}{w}w!$$ which is equal to zero when $w > m$, as we would expect.\n\n  \u2022 $\\begingroup$ +1. For OP, the number of ways to arrange $10$ men around the table is a circular permutation: $P_{10}=(10-1)!=9!$. $\\endgroup$ \u2013\u00a0farruhota Apr 15 '19 at 11:33\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1926519/dead-of-winter-probability-of-avoiding-death\nText:\nIn the board game Dead of Winter, certain actions a player can take result in rolling a 12-sided die. On one face of the die, there's a tooth, representing instant death by zombie. Two faces of the die result in a frostbite wound, and three faces of the die result in a regular wound. Half the time one rolls the die, there is no e ffect. Suppose the game calls for a player to roll the die three times in a row. Assume that if a tooth is rolled, death occurs and no further rolls are made. Assume also that if three wounds of any kind are rolled, death occurs. What is the probability that a player rolling the die three times escapes death?\n\nI tried (11/12)(11/12)(6/12), but I don't think that this accounts for the order of the die. For example, if I rolled a non-wound on the second roll, wouldn't that change my third probability?\n\n  \u2022 1\n    $\\begingroup$ frost bite = regular wound in this exercise ? $\\endgroup$ \u2013\u00a0marmouset Sep 14 '16 at 13:06\n\nFirst of all, you must avoid that tooth three times running. The probability of that is $\\left(\\frac {11}{12}\\right)^3$.\n\nNow, let's suppose that you have dodged the tooth. That means that each of your three rolls is one of the other eleven options. Five of these are wounds, though, and you mustn't get three of those. What is the (conditional) probability of getting three of those? Well, it's $\\left(\\frac {5}{11}\\right)^3$. Therefore the conditional probability that you don't get three wounds is $1-\\left(\\frac {5}{11}\\right)^3$.\n\nAs you need both things to occur the final answer is $$\\left(\\frac {11}{12}\\right)^3\\times\\left(1-\\left(\\frac {5}{11}\\right)^3\\right)=0.697916667$$\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/104514/computing-nash-equilibria-in-discrete-auctions\nText:\nI am trying to compute the (pure strategy) Nash equilibria of some discrete auctions.\n\nMore precisely, let us define the strategy of each player as a function mapping from every valuation that they might have to their bid (i.e. the 'bidding function'). Let us suppose that each player's valuation is drawn from some finite set and that their bid must belong to this same (finite) set. I am interested in finding the set of bidding functions, one for each player, such that each player's bidding function is optimal given the bidding functions of all the other players.\n\nIf it makes things easier, we can assume that valuations are symmetric (i.e. each player's valuation is generated by the same probability distribution) and that there are only two bidders. Ideally, however, we would proceed without these simplifications. I am interested in computing the equilibrium for the first price sealed bid and all pay auctions (in the latter, you pay your bid even if you lose; in the former, you don't.)\n\nI have considered writing down the discrete auction game in normal form and finding the equilibria using software like Gambit. However, this would seem tricky since the strategy space is so large. For example, if a player chooses bids from $ \\{1,...,10\\} $ and draws values from $ \\{1,...,10\\} $, then already they have $10^{10}$ pure strategies.\n\nDoes anyone have any ideas about how to proceed here?\n\n  \u2022 $\\begingroup$ The answer might depend on the parameters. How large is the finite set of possible valuations, in practice? Is it at most about 10? $\\endgroup$ \u2013\u00a0D.W. Feb 18 '19 at 20:20\n  \u2022 $\\begingroup$ No, usually more like 100 - 1000 (unfortunately!) However, we can reduce the dimensionality somewhat by ruling out strategies that require you to bid more than your valuation. $\\endgroup$ \u2013\u00a0afreelunch Feb 20 '19 at 15:04\n  \u2022 $\\begingroup$ OK. What determines whether a player's bidding function is optimal, given the other functions? I'm wondering how one would check that, and how \"simple\" a computation it is. (If it involves reasoning about all other possible choices for that player's bidding function, that sounds pretty complicated. But maybe there's some simpler characterization of when a proposed bidding function is optimal, when given all the other players' functions?) $\\endgroup$ \u2013\u00a0D.W. Feb 20 '19 at 19:33\n  \u2022 $\\begingroup$ Optimal = maximises expected payoff (i.e. assume risk neutrality) $\\endgroup$ \u2013\u00a0afreelunch Feb 23 '19 at 16:00\n  \u2022 $\\begingroup$ OK. How do we calculate expected payoff, given all the players bidding functions? Is it \"highest bidder wins the item, and their payoff for that item is what they bid minus their valuation of the item\"? And where is the randomness (why do you say expected payoff)? $\\endgroup$ \u2013\u00a0D.W. Feb 23 '19 at 19:44\n\nIf there are only two players, you could use integer linear programming.\n\nI'll introduce some zero-or-one integer variables to encode the (unknown) bidding functions (via a one-hot encoding). Let $x_{v,b}=1$ if player $0$'s bid is $b$ when their valuation is $v$, and $0$ otherwise; and $y_{w,c}=1$ if player $1$'s bid is $c$ when their valuation is $w$, and $0$ otherwise. In this way, if there are $n$ possible valuations, we obtain $2n^2$ zero-or-one integer variables. We will write down linear inequalities on these variables that characterize the optimality condition, then use an integer programming solver to find a solution that satisfies all of these inequalities.\n\nNote that if player $0$'s valuation is $v$ and player $1$'s valuation is $w$, then player $0$'s payoff (in a first-price auction) is\n\n$$\\sum_{b>c} x_{v,b} y_{w,c} (v-b).$$\n\nTherefore, if player $0$'s valuation is $v$, player $0$'s expected payoff is\n\n$$\\sum_w p_1(w) \\sum_{b>c} x_{v,b} y_{w,c} (v-b),$$\n\nwhere $p_1(w)$ represents the probability that player $1$ gets valuation $w$. Now, we need this to be at least what it would be if player $0$ used any other bid for valuation $v$, i.e., any other choice of $x_{v,\\cdot}$'s. If there are $n$ possible valuations, there are only $n$ possible bids, so we obtain $n$ inequalities\n\n$$\\sum_w p_1(w) \\sum_{b>c} x_{v,b} y_{w,c} (v-b) \\ge \\sum_w p_1(w) \\sum_{b'>c} y_{w,c} (v-b'),$$\n\nwhere we obtain one such inequality for each possible value of $b'$. (The sum on the left-hand-side is over $w,b,c$ that satisfy the condition $b>c$; the sum on the right-hand-side is over $w,c$ that satisfy the condition $c<b'$.)\n\nThis is a quadratic inequality. We'll turn it into a linear inequality using the techniques of Express boolean logic operations in zero-one integer linear programming (ILP). In particular, introduce new zero-or-one variables $t_{v,w,b,c}$, with the intention that $t_{v,w,b,c}=x_{v,b} y_{w,c}$. This can be enforced using the linear inequalities $t_{v,w,b,c} \\ge x_{v,b} + y_{w,c} - 1$, $t_{v,w,b,c} \\le x_{v,b}$, $t_{v,w,b,c} \\le y_{w,c}$, $0 \\le t_{v,w,b,c} \\le 1$. Now the optimality condition becomes\n\n$$\\sum_w p_1(w) \\sum_{b>c} t_{v,w,b,c} (v-b) \\ge \\sum_w p_1(w) \\sum{b'>c} y_{w,c} (v-b'),$$\n\nfor each $v,b'$. We obtain one such inequality for each $v$ and each $b'$. These $n^2$ inequalities ensure that player $0$'s strategy will be optimal (given player $1$'s strategy).\n\nThen, add similar inequalities to require player $1$'s strategy to be optimal (given player $0$'s strategy).\n\nAlso add the $n^2+n$ constraints that $0 \\le x_{v,b} \\le 1$ and $\\sum_b x_{v,b}=1$ to require the $x$'s to correspond to a bidding function, and similarly for the $y$'s.\n\nFinally, take all of these inequalities and feed them to an off-the-shelf integer linear programming solver. If it finds a solution, then you have found a Nash equilibrium for your game. ILP is NP-hard, so there is no guarantee that it will terminate in a reasonable amount of time, but in my experience often the solvers can handle surprisingly large systems of inequalities.\n\nThe same approach can handle all-pay auctions as well as first-price auctions.\n\nIn practice, you might be able to speed up the solver by adding some extra constraints to help it identify a solution faster. In particular, I have a hunch that without loss of generality the optimal bidding function can be assumed to be monotonic: if we increase my valuation, my bid should never decrease. We can add extra inequalities to the system to characterize this additional assumption, and this might narrow the search space and thus help the ILP solver find a solution more rapidly.\n\nOne big limitation is that this seems limited to two players (or a very small number of players). If there are multiple players, the number of variables and inequalities will explode, and this might not be an effective approach.\n\n\nYour Answer"}
{"text": "Retrieved from http://mathfactor.uark.edu/2009/12/morris-follow-up-trieltruelwhatever/\nText:\nMorris: Follow Up: Triel/Truel/Whatever\n\n\n\n\nJeff suggested that they might all choose not to shoot at each other and it would go on forever. \u00a0This made me think about the logic. \u00a0I\u2019m going to say that someone shoots at someone at some point and everyone knows this. \u00a0So everyone knows that if they shoot to miss then one of the others will shoot to hit at some point.\n\nIf anyone shoots to hit then they will shoot at the best shot. \u00a0If they hit they will be in two-man duel and would prefer to be against the worst shot possible.\u00a0\n\nSo\u00a0Fran\u00e7ois\u00a0knows that no-one will shoot at him. \u00a0Xavier knows that one of the others will shoot at him. \u00a0\n\n\nFran\u00e7ois\u00a0has two options, he can shoot at Xavier or he can shoot to miss.\n\nIf he hits Xavier he will be in a two man dual with JC shooting first, he only has a one in five chance of surviving the first shot so his chance of survival is less than 1/5.\n\nIf\u00a0Fran\u00e7ois\u00a0shoots to miss he knows that the other two will shoot at each other, if they choose to shoot to hit. \u00a0So at some point JC or Xavier will kill the other. \u00a0At this point\u00a0Fran\u00e7ois\u00a0will be in a two man duel with himself shooting first. \u00a0This gives him at least a fifity/fifty chance.\n\nSo\u00a0Fran\u00e7ois\u00a0shoots to miss.\n\n\nXavier and JC know this. \u00a0They know they are effectively in a two man duel with each other. \u00a0They therefore shoot at each other.\n\n\nThat sorts out the strategy, what about the probabilities?\n\n\nLet\u2019s consider JC first. \u00a0There is a fifty/fifty chance that Xavier or JC will shoot first. \u00a0JC\u2019s only chance is to shoot first and hit. \u00a0The chance is 1/2 x 4/5 = 2/5.\n\nSo 2/5 of the time JC will face\u00a0Fran\u00e7ois\u00a0with Francois shooting first. \u00a0\n\nLet\u2019s say that the chance that\u00a0Fran\u00e7ois\u00a0wins is f. \u00a0He has a 1/2 chance of killing JC with his first shot. \u00a0There is a 1/2 x 1/5 = 1/10 chance that both miss with their first shot, we are back to the starting position so the probability of\u00a0Fran\u00e7ois\u00a0surviving is now f again.\n\nThe chance of\u00a0Fran\u00e7ois\u00a0surviving is f = 1/2 + 1/10 f. \u00a0This gives 9/10 f = 1/2 and f = 5/9. \u00a0The chance of\u00a0Fran\u00e7ois\u00a0surviving is 5/9. \u00a0The chance of JC surviving is 4/9.\n\n\nThis gives JC a total survival chance of 2/5 x 4/9 = 8/45.\n\n\nNow consider Xavier. \u00a0He has a 3/5 chance of facing\u00a0Fran\u00e7ois\u00a0with\u00a0Fran\u00e7ois\u00a0shooting first.\n\nHis chance of surviving is 1/2, the chance that\u00a0Fran\u00e7ois\u00a0misses.\n\nHis total survival chance is 3/10.\n\n\nFinally Francois\u2019 chance of surviving is 2/5 x 5/9 + 3/5 x 1/2 = 2/9 + 3/10 = 47/90.\n\n\nSo the probabilities of being the last man standing are: \u00a0Fran\u00e7ois\u00a047/90; Xavier 3/10 and JC 8/45.\n\n\nAmazingly the worst shot has the best chance of survival!\n\n\nRSS feed for comments on this post \u00b7 TrackBack URL\n\nLeave a Comment\n\nYou must be logged in to post a comment.\n\nThe Math Factor Podcast Website\n\n\nA production of the University of Arkansas, Fayetteville, Ark USA\n\nDownload a great math factor poster to print and share!"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/26080/what-type-of-hmm-gmm-i-need/26094\nText:\nContext: I have 100 speech sentences that I asked my friend to speak. The vocabulary in the sentences are same but only the order of words are changed. My friend says that he spoke exactly what was asked for each sentence. But I don't know whether he spoke exactly that sentence or something else. What I have here is those 100 reference sentences against which I need to match his speech samples. As I want to do it by computer and not by listening manually therefore I am seeking your guidance.\n\nData: I have been able to segment the words in each speech sample of my friend. So I have 100 sentences each segmented into individual words with sequence of each word preserved for each sentence. I have extracted required features from each word (MFCC + Delta and Delta Delta).\n\nWhat I am looking for: I need your guidance and help in informing how can I recognize these words with over 95% accuracy. As I read many papers and articles, GMM + HMM is the reasonably good way to do this. But I have a confusion, when I have already segmented every sentence, why should I try to match the entire speech sentence by transitioning state to state using HMM? I can simply match each word and see if the sequence is same with respect to the reference sentence word sequence. Is GMM + HMM the way to go for this? Can I use DTW or Neural Network or SVM to classify (matching or not matching) each word and get high accuracy?\n\n\nNormally in speech-to-text we don't already have a perfect segmentation into words, which is why we often use the HMM to match the entire speech sentence. Also, this way the HMM can take into account probabilistic information on the distribution of word bigrams (and even trigrams). If you already have a segmentation and you are sure it is correct, then you can use the HMM to match just the word, if you like. But getting a reliably correct segmentation is tricky, given how people speak in practice, so you might want to check how accurate your segmentation is before relying upon it.\n\nEither GMM + HMM or DTW would be a reasonable approach.\n\nA very simple approach would be to download an existing speech-to-text tool and use it on those sentences, instead of trying to build something yourself.\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/37796/speed-up-org-map-entries-when-matching-by-property\nText:\nQuestion: Why is org-map-entries property matching so slow, and what can I do to speed it up?\n\nBackground: I have a relatively simple use for org-map-entries: grab the effort (in integer minutes) from all org agenda entries with tag goal and a given priority (e.g. B).\n\n(org-map-entries #'hw-org-get-effort-in-minutes \"goal+PRIORITY=\\\"B\\\"\" 'agenda)\n\nThis is terribly slow, taking over a minute for my ~12k line agenda file.\n\nHowever, if I remove the PRIORITY from the filter so any goals tagged item is selected, it completes almost instantly.\n\nI can also set filters like goal/DONE and they complete very quickly, but if I do something like goals+EFFORT>0 we are back to taking over a minute. It seems properties in general are very slow to match.\n\nI found a cheat workaround: I can match properties inside the the mapped function very quickly using org-entry-get. When I do this, execution is less than a second. This seems silly, hopefully there is a better way, but at least it works!\n\nAlready tried: Since (benchmark 1000 (hw-org-effort-to-minutes \"1:20\")) returns \"Elapsed time: 0.000019s\", I don't think my function contributes much.\n\nAccording to profiler, ~40% of CPU time is used by cond, with ~29% coming from element parsing (org-element--current-element). The next two largest contributions overall are 14% and 13%, so the 40% of cond seems to be the bulk of the problem. Not sure why element parsing would be done more often with property matchers, unless the difference comes from parsing only header (tags, TODO) vs. header + body (properties).\n\n\nOne way to improve speed is to parse the contents of your agenda files once in a temporary buffer collecting the effort of all the entries matching goal+PRIORITY=\"B\" (see Test 1). With ~10K lines, I get \"Elapsed time: 0.052280s\" compared to \"Elapsed time: 1.340006s\" using org-map-entries (Test 2) which I think is what you were trying to do. For better results using org-map-entries you can try Test 3, which is also pretty fast. Tested with Emacs version 26.2 and Org mode version 9.2.4.\n\nTest 1 (fastest)\n\n (apply '+ (let (efforts\n                 (regexp (concat org-effort-property \":\\s*\\\\(.+\\\\)\")))\n               (mapcar #'insert-file-contents org-agenda-files)\n               (goto-char (point-min))\n               (while (re-search-forward regexp nil t)\n                 (let ((effort (match-string 1)))\n                     (when (and (member \"goal\" (org-get-tags))\n                                (= (and (looking-at org-heading-regexp)\n                                        (org-get-priority (match-string 0)))\n                    (push (org-duration-to-minutes effort) efforts))))))\n\nTest 2 (slowest)\n\n (apply '+ (org-map-entries\n            (lambda ()\n               (org-entry-get nil org-effort-property)))\n\nTest 3 (pretty good)\n\n (apply '+ (org-map-entries\n            (lambda ()\n              (if (re-search-forward (concat org-effort-property \":\\s*\\\\(.+\\\\)\")\n                    (when (looking-at org-complex-heading-regexp)\n                      (let ((priority (match-string 3))\n                            (tags (match-string 5)))\n                        (if (and (string= priority \"[#B]\")\n                                 (string-match \":goal:\" tags))\n                            (org-duration-to-minutes effort)\n            nil 'agenda)))\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/76758/count-of-distinct-substrings-in-string-inside-range\nText:\nHaving string $S$ of length $n$, finding the count of distinct substrings can be done in linear time using LCP array. Instead of asking for unique substrings count in whole string $S$, query $q$ containing indexing $(i,j)$ where $0 \\le i \\le j < n$ is asking for count of distinct substring inside given query range for string $S[i..j]$.\n\nMy approach is just applying linear time construction of LCP array to each query. It gives complexity $O(|q|n)$. Number of queries could raise to order of $n$ so answering all queries makes it $O(n^2)$.\n\nCan it be done better, than linear time for every query?\n\nIn general, if one process substring of string for which we already have suffix array, suffix tree, lcp array, are those structures not relevant anymore, and must be build from scratch again?\n\n  \u2022 $\\begingroup$ The size of input and output seem to be natural lower bounds. $\\endgroup$ \u2013\u00a0Raphael Jun 14 '17 at 5:59\n  \u2022 1\n    $\\begingroup$ I don't have time to think about this, but it's quite standard to build segment trees out of these complex structures (in competitive programming), maybe it's the case for suffix arrays/trees/etc. You just have to be clever in defining a fast \"combine\" operation (which will be used for a father node with his children, or at the end to combine the results of all the leaves covering your interval). $\\endgroup$ \u2013\u00a0md5 Jun 14 '17 at 8:44\n  \u2022 $\\begingroup$ The number of queries is the number of ordered pairs $i, j$ which is $(n*(n+1))/2$, so the complexity should be $O(n^3)$ $\\endgroup$ \u2013\u00a0user11171 Jul 3 '18 at 22:45\n  \u2022 $\\begingroup$ @md5 I don't think a segment tree (or fenwick tree) based solution will work because the number of substrings lacks additive inverse. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 16:27\n\nThe question does not motivate the number of queries being $O(n)$, which seems an arbitrary worst case since the number of unique possible queries is the number of ordered pairs and thus $O(n^2)$.\n\nHere are two different solutions with better time complexity for the $O(n^2)$ case based on (implicit) suffix trees constructed incrementally with Ukkonen's algorithm. Both solutions are based on preprocessing and have complexity $O(n^2 + |Q|)$ where $Q$ is the set of queries. The second solution runs in $O(n + |Q|)$ if all queries have the same width.\n\nSolution 1 - Preprocess all unique queries\n\nIterate over the suffixes of $S$. For each suffix $S_i=S[i..n]$, build the suffix tree of $S_i$ with Ukkonen's algorithm. After update $j$ to the current suffix tree, store the tree size in a matrix at position $(i,i+j-1)$. A query for the range $[x,y]$ is answered by the matrix element at $(x,y)$.\n\nSuffix tree size can be stored along with the suffix tree and updated in constant time at each step by modifying the update procedure in Ukkonen's algorithm. For each update the size increases by the current number of leaves.\n\nSolution 2 - Preprocess unique query widths\n\nThis solution is harder to implement but requires less preprocessing work if there are few query widths. Preprocessing takes $O(n)$ time if there is only one query width.\n\nFor each query width $w$, use a sliding window of width $w$ and incrementally build a suffix tree. Remove the suffix starting one character to the left of the window by remove the longest suffix from the tree. At each step, the current number of substrings within the sliding window is the tree size.\n\nAll queries can then be answered in linear time by using the results of the precomputation.\n\nNote: removing the longest suffix can be done by removing the oldest leaf of the suffix tree. It is not easy to implement correctly.\n\n  \u2022 $\\begingroup$ This seems to be a bit off. The task is not to answer all possible $O(n^2)$ queries, but to answer some $q$ given queries. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 11:17\n  \u2022 $\\begingroup$ I answered the question for the general case, which was the point of the question. In the special case where the number of queries is low, the solution proposed by the question author would run faster in practice. The number of outputs of a valid solution is $q$, which is of size $O(n^2)$ (disregarding duplicate queries), so any possible solution must run in $O(n^2)$ or slower. My proposed solution takes time $O(n^2)$ for preprocessing and then each query can be answered in constant time. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 15:10\n  \u2022 $\\begingroup$ Again, $q$ is a parameter. The question is explicitly interested in the number of queries $q$ being $\\Theta(n)$, not $\\Theta(1)$ nor $\\Theta(n^2)$. The answer for $q$ queries is of size $\\Theta(q)$ which need not be $\\Theta(n^2)$. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 15:39\n  \u2022 $\\begingroup$ Why would the number of queries be of order $n$? It seems like an arbitrary condition, if not an oversight by the author. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 15:46\n  \u2022 $\\begingroup$ The whole problem statement is kind of the same degree of arbitrary. However, this is how a typical data structures problem in competitive programming looks like, so it is unlikely that $n^2$ queries are what the OP looks for. I'd bet $n$ and $q$ are independent parameters from $1$ to $100\\,000$ or so, and the time limit is a couple of seconds, so that an $O(nq)$ solution times out, but something better like $O(n \\sqrt q)$ doesn't. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 15:51\n\nThere is $O(n \\sqrt{n} + |Q| \\sqrt{n})$ offline solution.\n\n  1. Sort elements $(i,j)$ of $Q$ in ascending order of $j$.\n  2. Distribute them into $\\sqrt{n}$ buckets so, that $(i,j)$ goes into bucket number $\\lfloor \\frac{i}{\\sqrt{n}} \\rfloor$.\n  3. For each bucket starting at $b$ and each query $(i,j)$ in it, build a suffix tree for $S[b,j]$.\n  4. For each query in a bucket, remove redundant characters from the left and report the answer.\n\nStep 3 takes $O(n)$ for each bucket, because we use Ukkonen's algorithm and $j$ goes in ascending order.\n\nStep 4 takes $O(\\sqrt{n})$ for each query, because removing $\\sqrt{n}$ longest suffixes from the tree takes $O(\\sqrt{n})$. Note that you can use an indirection layer to avoid modifications to the original suffix tree.\n\n  \u2022 $\\begingroup$ The number of distinct substrings is the number of paths in the suffix tree that start at the root and end at a node with just a single leaf below it, correct? Do you store these path counts explicitly in the notes? If so, then how do you update things when removing the first character in O(1) time? There could be up to $\\sqrt n$ of them (in the case where the first character is unique within the block). If not, how do you compute them on the fly? $\\endgroup$ \u2013\u00a0j_random_hacker Jul 8 '18 at 7:49\n  \u2022 $\\begingroup$ @j_random_hacker Ukkonen's algorithm builds so called implicit suffix tree. Number of distinct substrings is just sum of lengths of its edges (i.e. size of corresponding trie). $\\endgroup$ \u2013\u00a0Dmitri Urbanowicz Jul 8 '18 at 14:14\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/319842/how-many-ways-to-fill-in-a-square-grid-with-certain-restrictions\nText:\nSuppose I have a 5x5 grid of squares. I would like to fill in 15 checkmarks in the squares such that (1) each of the 25 square cells contains at most one checkmark, (2) each row has exactly 3 checkmarks, and (3) each column has exactly 3 checkmarks. How many ways are there to fill in these 15 checkmarks?\n\nMore generally, suppose I have an $n \\times n $ square grid, and I would like to fill in $mn$ checkmarks such that (1) each of the $n^2$ square cells contains at most one checkmark, (2) each row has exactly m checkmarks, and (3) each column has exactly m checkmarks. How many ways are there to do so? If $m=1,$ I think the answer is $n!$. But I am not sure about the general case.\n\nAlso, if I have an additional restriction that no checkmarks on the diagonal, i.e., no checkmark in the (1,1), (2,2),... (n,n) cells. How many ways are there?\n\nThanks very much! Wish all very happy new year!\n\n  \u2022 $\\begingroup$ If you remove the only one checkmark per box requirement then you are looking at the Ehrhart polynomial of the Birkhoff polytope, and get into the Anand-Dumir-Gupta conjecture and related areas. $\\endgroup$ \u2013\u00a0Sam Hopkins Dec 31 '18 at 21:25\n\nWhat you are looking for is the number of matrices in the class $\\mathcal A(n,m)$ of $(0,1)$-matrices that are $n\\times n$ and have each row and column containing exactly $m$ entries equal to $1$. This is a pretty well-studied question, but an exact answer isn't known except in some small cases.\n\nYou are right that for $m=1$, the number is $n!$, as then you are counting the $n\\times n$ permutation matrices. A sort of generalization of this was obtained in\n\nWei, Wan-Di. \"The class $\\mathfrak A(R,S)$ of $(0,1)$-matrices.\" Discrete Mathematics 39, no. 3 (1982): 301\u2013305. Journal link\n\nwhere it is given that the number of such matrices is at least\n\n\nI say it is \u201csort of\u201d a generalization because it is only a lower bound. Again, there is no closed form known for the exact number. I think the most frequently-cited asymptotic results are those of McKay and others, for example see\n\nMcKay, Brendan D., Wang, Xiaoji. \"Asymptotic enumeration of 0-1 matrices with equal row sums and equal column sums.\" Linear Algebra and its Applications. 373 (2003): 273\u2013287. Journal link\n\nand anything that cites it.\n\nThere are other results \u2013 and other asymptotic results \u2013 out there. A good starting point for more details is the book Combinatorial Matrix Classes by Brualdi.\n\nFinally, note that this is the same as counting balanced regular bipartite graphs. For example, your question is the same as this one where the $d_v$ and $d_c$ of that question are taken to be equal. So you may wish to see the answer \u2013 provided by McKay! \u2013 appearing there.\n\n  \u2022 $\\begingroup$ Thanks so much for the very helpful information!! Happy New Year! $\\endgroup$ \u2013\u00a0KPU Jan 1 at 4:25\n\nThe problem amounts to counting binary or $0/1$-matrices with restrictions on row/column sums.\n\nIn general, let the row sums be $r(n)=(r_1,\\dots,r_n)$ and column sums $c(n)=(c_1,\\dots,c_n)$. Obviously, $0\\leq r_i, c_j\\leq n$ for all $i, j$. Further, let $\\mathbf{x}=(x_1,\\dots,x_n)$ and $\\mathbf{y}=(y_1,\\dots,y_n)$ with the multi-exponent notation $\\mathbf{x}^{u}=x_1^{u_1}\\cdots x_n^{u_n}$. Then, there is this generating function $$\\prod_{i,j=1}^n(1+x_iy_j)=\\sum_{r(n),c(n)} N(r(n),c(n))\\mathbf{x}^{r(n)}\\mathbf{y}^{c(n)} \\tag1$$ for the enumeration $N(r(n),c(n))$ of the number of binary matrices with row sums $r(n)$ and $c(n)$.\n\nTo get back to your question, extract the coefficient $N((k,\\dots,k),(k,\\dots,k))$ of $$\\mathbf{x}^{(k,\\dots,k)}\\mathbf{y}^{(k,\\dots,k)}$$ from the above product in (1).\n\n\nYour Answer"}
{"text": "Retrieved from https://blog.flyingcoloursmaths.co.uk/big-lead-can-football-team/\nText:\nA reader asks:\n\nWhat\u2019s the biggest lead a football team can have in the table after $n$ games?\n\nIn a typical football league, teams get three points for a win, one for a draw, and none for getting beat. After, for example, one game, if one team wins and all of the other games are draws, the winners will have three points, while everyone except the team they beat will have one point \u2014 the winners will be two points ahead.\n\nThere\u2019s not a whole lot more to it \u2014 after two games, the biggest possible lead is four points (one team wins both of its games to get six points, and all of the others are draws, leaving everyone else with at most two points). As long as the winning team hasn\u2019t played all of the teams, the biggest lead after $n$ games is $2n$ points.\n\nBut what if they\u2019ve played everyone?\n\nIn a four-team group, it\u2019s possible to have a seven-point lead after three games, rather than just six: if you beat all three of the other teams, you\u2019ll have nine points; if they all draw with each other, they each have two points. Assuming you always win and everyone else always draws, once you\u2019ve played everyone once, you\u2019ll have $3n$ points, and the best of the rest will have $n-1$ points - they\u2019ll have drawn every game except for the one they lost to you - giving you a margin of $3n - (n-1) = 2n+1$.\n\nIn general, if you\u2019ve played everyone at least $m$ times, your biggest possible margin is $2n + m$. So, when Dunfermline beat the other nine teams in Scottish League One four times, and they all draw with each other, they\u2019ll have a lead of $2 \\times 36 + 4 = 76$ points."}
{"text": "Retrieved from https://math.stackexchange.com/questions/1422637/what-is-k-in-fermats-little-theorem/1422647#1422647\nText:\nAccording to Fermat's Little Theorem, for all integer $a$, if $p$ is a prime, then $$a^p \\equiv a \\pmod p$$ In other words, there exists a non-zero integer $k$ such that $$a^p-a=pk$$ Is there a method to determine $k$? I have seen many proofs using the multinomial expansion and/or recurrent analysis but none explicitly mentioned what $k$ is? Any Hints?\n\nEXPLANATION:let me be clearer, let's say, for any 2 integers $a,b$, if $p$ is odd, then $$(a+b)^p\\equiv {a^p+b^p}\\pmod p$$ In other words, there exists $k \\in \\mathbb {Z} \\neq 0$ such that $$(a+b)^p=a^p+b^p+kp$$ In this case using the binomial expansion, it is easy to see that $$k=\\dfrac{\\sum_{k=1}^{p-1}{ n\\choose k}a^{p-k}b^k}{p}$$ I was wondering if there is a similar expression of $k$ in the Fermat's Little Theorem.\n\n  \u2022 4\n    $\\begingroup$ One way to calculate it is to raise $a$ to the power $p$, sutract $a$ from the result, then divide that by $p$. I.e., finding $k$ is not difficult. Fermat's theorem simply proves that it is always an integer. $\\endgroup$ Sep 5, 2015 at 2:49\n  \u2022 6\n    $\\begingroup$ It's $(a^p-a)/p$. What else is there to say? $\\endgroup$\n    \u2013\u00a0whacka\n    Sep 5, 2015 at 2:54\n\n1 Answer 1\n\n\nYou are stating an equivalence between those two statements, namely $$a^p\\,=\\,a\\;(mod\\,p) \\Longleftrightarrow\\,a^p\\,-\\,a\\,=p\\,k$$ This means, that second statement is the definition of $k$.\n\n1)Your example is not different as it is still giving $k$ in terms of the two sides and $p$. Thus it is not a method for calculating $k$ but it's merely re-expressing $k\\,=\\,\\frac{(a+b)^b\\,-\\,(a^p+b^p)}{p}$ differently.\n\nYou could as well write $k=\\frac{a\\,(a^{p-1}-1)}{p}$ for the first relation. Not knowing how $a$ (and $b$ as well in your example) depends on $p$ the best you can do is give a formal expression for $k$ -as you do in your example.\n\n2)If what you want is to still write it in terms of some power series you could argue as follows. Given that $\\sum^{p-1}_{n=0}a^n\\,=\\,\\frac{a^{p}-a}{a-1}$ for $a\\neq1$, then $$k\\,=\\,\\frac{(a-1)\\,\\sum^{p-1}_{n=0}a^n}{p}$$ But this doesn't provide you with a method for calculating $k$ different from directly using its definition.\n\n  \u2022 $\\begingroup$ Please see my edited post. $\\endgroup$\n    \u2013\u00a0user97615\n    Sep 5, 2015 at 14:50\n  \u2022 2\n    $\\begingroup$ Now I'm not sure what you are asking, I have to admit. Initially I thought you were missing something in the definition of congruence, but now I'm thinking you haven't clearly posed a question. If what you want is introduce a power series in the expression of k, I've shown you one way. However, then you should state it clearly in your question what you want and why, that's is, what motives your question. This helps people get your mindset better and provide you with better answers. $\\endgroup$\n    \u2013\u00a0MASL\n    Sep 5, 2015 at 16:26\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2111132/number-of-ways-to-choose-n-objects-from-groups-of-indistinguishable-objects\nText:\nSay I have 5 blue, 6 red, and 7 green balls. How many ways are there to choose 8 balls, without regard to order? My first thought was to just add up all the balls and choose 8 from the collection of 18, but I know that that'll overcount the possibilities, as I can get the same color combination of balls multiple ways by choosing different balls within the same color group. How would I correctly approach this problem?\n\n  \u2022 $\\begingroup$ So all the same color balls are the same? $\\endgroup$\n    \u2013\u00a0S.C.B.\n    Jan 24 '17 at 1:25\n  \u2022 $\\begingroup$ Yep. All balls in the same color group are the same. $\\endgroup$ Jan 24 '17 at 1:29\n\nAny selection can be described as a triple $(b,r,g)$ where $0\u2264b\u22645$, $0\u2264r\u22646$, $0\u2264g\u22647$ and $r+b+g=8$.\n\nAs the numbers involved are small, it's not difficult to work case by case. We'll go through the possible values of $b$.\n\nI. $b=0$. Then $r\u22651$ but any non-zero value of $r$ works so $\\fbox 6$ cases.\n\nII. $b=1$. Now $r$ can be any value from $0$ to $6$ so $\\fbox 7$ cases.\n\nIII. $b=2$ Again we can use any value of $r$ so $\\fbox 7$ cases.\n\nIV. $b=3$. Now $0\u2264r\u22645$ so $\\fbox 6$ cases.\n\nV. $b=4$ Now $0\u2264r\u22644$ so $\\fbox 5$ cases.\n\nVI. $b=5$ Now $0\u2264r\u22643$ so $\\fbox 4$ cases.\n\nFinally the answer is $$6+7+7+6+5+4=\\fbox {35}$$\n\nNote: while the logic is fairly simple, case by case enumeration can be a bit error prone so I suggest checking carefully. As an alternate method you could multiply out the generating functions $$(1+x+x^2+x^3+x^4+x^5)(1+x+\\cdots +x^6)(1+x+\\cdots +x^7)$$ seeking the coefficient of $x^8$.\n\n\nLet's say that we ignore the green balls for now. We have can have between 0 and 5 blue balls and 0 and 6 red balls. So the number of possible pairings of number blue and number red is: $$6 * 7 = 42$$ Now we have to eliminate combinations where we had more than 8 balls so we need to see how far above the target we can get by adding the number of blue (5) and red (6) balls and subtracting the total desired (8). Then we sum the integers from 1 to that answer. This gives us how many of our 42 scenarios are too high. $$5 + 6 - 8 = 3$$ $$\\sum_{n=1}^{3} n = 6$$ $$42 - 6 = 36$$ Then we need to subtract off the bottom where the greens can't get us to 8 which only occurs when we have zero blue and zero red so: $$36 - 1 = 35$$ And thus you have 35 combinations.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.flyingcoloursmaths.co.uk/common-problem-decimal-division/\nText:\nI\u2019m a big advocate of error logs: notebooks in which students analyse their mistakes. I recommend a three-column approach: in the first, write the question, in the second, what went wrong, and in the last, how to do it correctly. Oddly, that\u2019s the format for this post, too.\n\nThe question\n\nDecimal division: something like 14.4 \u00f7 1.2\n\nWhat went wrong\n\nGot 1.2 instead of 12.\n\nHow to do it right\n\nApproach 1: Estimation. 14 \u00f7 1 is 14, so an answer of 1.2 is way off - 12 seems more reasonable.\n\nApproach 2: Decimal fractions. (A little bit of commentary here: at this point, students normally groan and say \u201cI can\u2019t do fractions\u201d or similar. It would be rude to point out that they clearly can\u2019t yet do decimal division, either.)\n\n  \u2022 Treat the sum as $\\frac{14.4}{1.2}$\n  \u2022 Decide that the bottom is ugly.\n  \u2022 \u201cCancel up\u201d: multiply top and bottom by 10 ((5 works just as well))\n  \u2022 You now have $\\frac{144}{12}$, which is obviously 12.\n\nApproach 3: Fractional fractions. Even a naive approach to dividing fractions is simple here:\n\n$14.4 \\div 1.2 = \\frac{144}{10} \\div \\frac{12}{10}$\n\n$\\frac{144}{10} \\div \\frac{12}{10} = \\frac{1440}{120} = \\frac{144}{12} = 12$.\n\nThere are probably a dozen other ways to approach this. What are your favourites?\n\n* Edited 2017-05-16 to add a category."}
{"text": "Retrieved from http://math.stackexchange.com/questions/214398/the-most-general-meromorphic-function-such-that\nText:\nTake the 2-minute tour \u00d7\n\nSuppose f is meromorphic in a neighborhood of the closed unit disk , that it does not have zeroes nor poles in the open unit disk, and that $|f(z)|=1$ for $|z|=1$. Find the most general such function. Let's denote D = open unit disk\n\nWell, since f has no poles in D, it's holomorphic there, thus by the maximum modulus principle $ |f(z)| < 1$ for $|z|<1$. If f does not have a zero , then we can use the minimum modulus principle, so f attains it's minimum in $\\partial D $ thus $f(z)=1 \\forall z \\in D$ , by analytic continuation $f(z)=1 \\forall$ in where f is defined $ I'm not sure if my solution it's correct :S. I never used the fact that it's analytic in a neighborhood of the closure. I'm missing something?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nActually the conclusion from the minimum modulus principle is $|f(z)| = 1$, not $f(z) = 1$. And the And then you can use the Open Mapping Theorem to say that $f$ is constant.\n\nYou did use the fact that $f$ is continuous on the closed unit disk in applying the maximum and minimum modulus principles.\n\nshare|improve this answer\nYou are completely right, I use the hypothesis that my domain is open , to assert that $f(D)$ is open but contained in $S^1$ Thanks :D! \u2013\u00a0 Daniel Oct 15 '12 at 20:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/72959/metric-for-signal-to-noise-ratio-in-communication-systems?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI'm not quite sure about how to define a good measure of the quality of a communication channel with fading and interference. Let us assume the simplest case, where a node in a network receives the following quantity:\n$$ y = s + w $$\nwhere $s$ is the amplitude (positive real) of the signal and $w$ the noise (gaussian with zero mean and variance $\\sigma^2$). A simple measure of the channel quality is simply given by ${\\rm SNR} = s^2 / \\sigma^2$, i.e., the ratio of the power of the signal vs the power of the noise.\nNow, suppose the received signal is $$ y = h_s s + w$$\nwhere $h_s$ and $w$ are complex gaussian with zero mean and unitary variance. A measure of the SNR that makes sense could be derived by looking at the power of the received signal $$ |y|^2 = y y' = |h_s|^2 s^2 + 2{\\rm Re}(h_ss~w') + |w|^2$$\nnow, since for practical applications the noise process is much faster than the fading (represented by $h_s$) what people normally do is to average over $w$, obtaining\n$$ E[|y|^2]_w = |h_s|^2 s^2 + \\sigma^2 $$\nhence, a measure of the signal strength that makes sense would be $ {\\rm SNR} = |h_s|^2 s^2 / \\sigma^2$.\nWhat I am interested about is the case with interference. Suppose there is an extra term that takes into account for interfering signals\n$$ y = h_s s + h_{\\rm I} s_{\\rm I} + w $$\nwhere $h_I$ is complex with zero mean and unitary variance. How could I possibly define the SNR in this case? By taking $|y|^2$ there are cross terms, i.e., products of $h_s$ and $h_{\\rm I}$ that do not disappear even if I average over the noise $w$. So it seems not obvious to me how to decouple $|y|^2$ into two different pieces, one for the signal and the other for the noise. The final goal would be determining a good measure of the SNR in order to be able to compute probabilities like\n\n$$ P({\\rm SNR} \\geq \\gamma_0).$$\n\nshare|improve this question\nif one can assume that $h_I$ is uncorrelated with $w$ and $h_s$, then you could just average $\u2223y\u2223^2$ over both $h_I$ and $w$; cross terms would still vanish; this is not what you want? \u2013\u00a0 Carlo Beenakker Aug 16 '11 at 13:47\nyes I know, but typically, the $h$ terms vary more slowly than the noise $w$. So averaging over $h$ is not that practical. \u2013\u00a0 Bob Aug 16 '11 at 22:37\n\n1 Answer 1\n\nThe general case is not known. If you find the correct information theoretic metric for the interference channel, you can find the capacity of interference channels (an open problem since the 1960s).\n\nIn your case, it looks like a MAC channel. Decode the stronger signal first and then decode the weaker one. Assuming you have a powerful code underneath, Euclidean distance as metric suffices.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/101661/going-in-the-direction-of-the-gradient?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nFirst, a motivating example. Suppose $f(x)$ is convex, differentiable, with a single minimum $x^*$.\n\nThen the differential equation $$\\dot{x}(t) = -\\nabla f(x(t))$$ drives $x(t)$ to $x^*$.\n\nNow my question is about a generalization of this. Let $f(x), g(x)$ be two smooth convex functions and let ${\\cal G}$ be the set of minima of $g(x)$, which we assume to be nonempty. Consider the differential equation $$ \\dot{x}(t) = - \\frac{1}{t} \\nabla f(x(t)) - \\nabla g(x(t))$$ Is it true that this equation drives $x(t)$ to the minimum of $f(x)$ on ${\\cal G}$? If not, would it be true if we replaced $1/t$ by a different function, say one which perhaps decays slower? Or perhaps by adding some additional conditions on $f$, e.g., strong convexity?\n\nThis statement seems to be true in a few simple examples I tried. For example, taking $g(x)=(x_1+x_2-2)^2$ and $f(x)=x_1^2+x_2^2$ and solving the resulting equation numerically, I get that solutions seem to approach $(1,1)$.\n\nNote: I asked this on math.SE without receiving an answer\n\nshare|improve this question\nDo you mean instead that $x(t)$ is driven to the minimum of $g$ ? \u2013\u00a0 Denis Serre Jul 9 '12 at 9:02\nNo, $x(t)$ should be driven to the minimum of $f(x)$ on ${\\cal G}$, which is the set of minimizers of $g$ (at least, that is what I think should be true!) For example, in the example I gave in the final paragraph, the set of minimizers of $g$ is the set $x_1+x_2=2$ and the minimum of $f$ on it is $(1,1)$ - which is where indeed the solution appears to go numerically. \u2013\u00a0 user21162 Jul 9 '12 at 9:21\n\n1 Answer 1\n\nAssume $f$ is strongly convex (i.e., $f''>\\varepsilon$ for some fixed $\\varepsilon>0$). Then for any two solutions $x$ and $y$ we have $|x(t)-y(t)|\\le \\tfrac C t$. In particular if one solution converges then all of them converge to the same point.\n\nIf this point $x^* $ is not the minimum of $f$ on $\\mathcal G$ then you get an immediate contradiction. (There is a draught in one direction near $x^* $ for all $t$'s.)\n\nshare|improve this answer\nThank you for answering. Could I ask for more details? I tried to understand your answer but failed. 1. Why do solutions satisfy $|x(t)\u2212y(t)| < C/t$? 2. How do you know at least one solution converges? 3. Can you spell out the contradiction that converging to a non-minimum results in? Thanks! \u2013\u00a0 user21162 Jul 8 '12 at 14:56\nThe estimate follows along the same lines as Picard's existence theorem. For the second part of argument, look at a neighborhood of $x^* $ and try to estimate the behavior of solutions for big $t$, it will slide in a direction of a fixed vector tangent to $\\mathcal{G}$; that means this can not be a limit point. \u2013\u00a0 Anton Petrunin Jul 8 '12 at 20:31\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/16796/choosing-seats-for-guests\nText:\nTake the 2-minute tour \u00d7\n\nYou have a circular table with $N$ seats.$K$ bellicose guests are going visit your house of-course you don't want them to sit beside each other.As the host, you want to find out how many ways there are to choose $K$ seats such that none of them is adjacent to each other.\n\nI noticed that there is a solution other than $0$ if ($N \\ge 2K $) but I am not sure how to approach for the rest.\n\nEDIT: Only $K$ bellicose guests are visiting,no friendly guest are there the remaining $N-K$ seats will be vacant.\n\nA possible mathematical translation of this problem: Choosing $K$ candidate points from a circle of $N$ indistinguishable points such that there are more than one vacant point between adjacent candidate points.\n\nshare|improve this question\nUp to rotation or not? If not, try fixing K and seeing if you can write down a recurrence in terms of N. \u2013\u00a0 Qiaochu Yuan Jan 8 '11 at 13:46\n@ Qiaochu Yuan: Please rephrase, I don't understand what you meant by \"Up to rotation or not\". \u2013\u00a0 Quixotic Jan 8 '11 at 13:48\nQiaochu is asking (since the table is circular) whether your count of solutions should treat a rotation of a solution as another solution (or just count rotationally equivalent solutions as one). Also notice that you've misstated the inequality: should be $N \\ge 2K$ to get solutions. \u2013\u00a0 hardmath Jan 8 '11 at 14:38\n@hardmath: I am not sure whether the clock-wise or anticlockwise solution are treated different of not. \u2013\u00a0 Quixotic Jan 8 '11 at 14:45\nRight, I'd assume those (reflections) are counted differently, although of course \"who sits next to whom\" will be the same. A reflection is never a rotation except for the trivial case N=2, so there's not really a conflict in saying we want to identify rotationally equivalent solutions but distinguish reflections. \u2013\u00a0 hardmath Jan 8 '11 at 15:13\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nChoose a seat $S$, and a bellicose guest $B$. Sit $B$ in $S$, and tell them not to move, whether they like it or not. That done, there are $(K-1)!$ ways of ordering the remaining bellicose guests clockwise around the table, and $F!$ ways of ordering the friendly guests (here I am using leonbloy's notation $F = N - K$). For each such ordering, we have to choose a pattern of the form $f...b...f...b...f$. This pattern:\n1. starts and ends with $f$ (so that $B$ is isolated);\n2. contains $(K-1)$ $b$'s and $F$ $f$'s; and\n3. contains no two adjacent $b$'s.\n\nBut the number of such patterns is the same as the number of patterns that\n1. start with $f$; and\n2. contain $(K-1)$ $b$'s and $(F-K+1)$ $f$'s.\n\n(To see this, just replace each instance of $bf$ in the original pattern by $b$.) The number of such patterns is the binomial coefficient $\\binom{F-1}{K-1}$. So we end up with:\n\n$(K-1)!F!\\binom{F-1}{K-1} = \\frac{F!(F-1)!}{(F-K)!}$\n\nThis is the number of seating arrangements with guest $B$ in seat $S$. Multiply by $N$ to get the total number.\n\nEdit Reading the question more carefully, it asks for the number of (what I call here) patterns, not the number of seatings. For each pattern, there are $K!F!$ seatings, so the answer is\n\n$N\\frac{F!(F-1)!}{(F-K)!}/(K!F!) = \\frac{N(F-1)!}{(F-K)!K!}$\n\nshare|improve this answer\nSeems right to me. Just to clarify: \"This is the number of seating arrangements with guest B in seat S\" means: with \"a particular B guest (say b1) in seat S\", not \"with some belicose guest in seat S\". \u2013\u00a0 leonbloy Jan 9 '11 at 0:13\n@leonbloy: I suggest that my answer was perfectly clear on that point. I think you must have forgotten the first two sentences by the time you reached the last two. \u2013\u00a0 TonyK Jan 9 '11 at 0:22\nIn TonyK's counting the seats have name tags. If you only distinguish between white and black seats you have a different problem, see my former comment on this question. Maybe the proposer should clarify this point. \u2013\u00a0 Christian Blatter Jan 9 '11 at 11:59\nLet $N = 4$ and $K = 2$ we get $F = 2$ then your formula is giving $2 \\times N = 8$ but given answer is $2$. \u2013\u00a0 Quixotic Jan 9 '11 at 12:28\n@Christian Blatter: My first result is the number of seating arrangements with B in S, which is the same as the number of seating arrangements counting rotations (but not reflections) as identical. Now just multiply this by N to get the number of seating arrangements counting rorations as distinct. No special Polya theory is required. \u2013\u00a0 TonyK Jan 9 '11 at 12:29\n\nLet's call $F=N-K$ number of \"friendly\" guests. And let's call $S(F,K)$ the count of seating ways assuming that seats and guests are distinguible (rotations are distinct solutions).\n\nWe know that $F \\ge K$. For the limit case $F = K$ we have $S(F,K) = 2 K (K-1)! K! = 2 K!^2$.\n\nNow, the recursion: we count the number of ways when adding a friendly guest:\n\n$S(F+1,K) = (F+K+1) S(F,K)$\n\nFrom this (if it's correct!) you can get an explicit solution.\n\nUpdate: this is not correct. See TonyK's answer\n\nshare|improve this answer\nI don't think your recursion is right. Adding a friendly guest between two bellicose guests can transform an invalid seating into a valid one. Also it doesn't agree with the formula in my answer :-) \u2013\u00a0 TonyK Jan 8 '11 at 20:02\n@TonyK: you're right \u2013\u00a0 leonbloy Jan 9 '11 at 0:00\nNo friendly guests are there,please read my question. :-) \u2013\u00a0 Quixotic Jan 9 '11 at 15:04\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/59212/deriving-torque-from-euler-lagrange-equation\nText:\nTake the 2-minute tour \u00d7\n\nHow could you derive an equation for the torque on a rotating (but not translating) rigid body from the Euler-Lagrange equation? As far as I know from my first class in Classical Mechanics, there is no potential defined for a rotating body, so the only term I see in the Lagrangian is the $\\frac{1}{2}I\\omega^2$. Since there is no $\\theta$, I'm just getting that torque always equals $0$.\n\nshare|improve this question\nIt depends how the body is fixed in space. If it is floating, there's no torque and the angular momentum is conserved. But if the body is supported by a pedestal or something like that, the potential energy $mgh$ where $h$ is the height of the center of mass effectively does depend on the angle $\\phi$ and the derivative of this potential energy with respect to the angle gives you torque. \u2013\u00a0 Lubo\u0161 Motl Mar 27 '13 at 15:26\nComment to the question (v1): It is still possible to define the potential energy $V$ of a torsion spring, so that angular system has a Lagrangian formulation. \u2013\u00a0 Qmechanic Mar 27 '13 at 15:30\nHow does height depend on theta (The angle between the applied force and the radius)? Knowing torque should equal |F||R|sin(theta), the potential should then equal |F||R|cos(theta). If |F||R|cos(theta) = mgh = |F|*h, that would imply that the height is less than the radius. -- What am I missing here? \u2013\u00a0 JLA Mar 27 '13 at 16:16\nYou know you need to refine the rotation with generalized coordinates (like Euler angles) which will yield generalized forces (torques). \u2013\u00a0 ja72 Aug 20 '13 at 14:32\nadd comment\n\n1 Answer\n\nThe question isn't clear to me, the torque is zero if there's not an applied torque, and it's nonzero if it's not zero, but that's just a tautology. Do you mean that you just want to derive something/anything torque-esque given an applied force? If so, here's one way.\n\nThis isn't a job for a potential, it's the job for a generalized force. Consider the 2d case, with a particle at some position $s=(x,y)$, with mass $m$ and a force vector $F$ applied to it.\n\nThe first form of the Euler-Lagrange equations I learned was the form:\n\n$$\\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_i}-\\frac{\\partial T}{\\partial q_i}=Q_i$$ where $T$ is the kinetic energy (NOT the lagrangian), $q_i$ are the parameters describing the system, and $Q_i$ is defined as the generalized force $Q_i=\\sum_j F_j \\frac{\\partial s_j}{\\partial q_i}$. (Goldstein classical mechanics ch 1)\n\nThen, parameterizing in terms of polar coordinates, we can define $s=(q_1 \\cos(q_2),q_1 \\sin(q_2))$.\n\nGoing through the motions of finding the kinetic energy, generalized forces, and partial derivatives:\n\n$\\dot{s}=(\\dot{q_1}\\cos(q_2)-q_1\\sin(q_2) \\dot{q_2},\\dot{q_1}\\sin(q_2)+q_1\\cos(q_2) \\dot{q_2})$\n\n\n\n$Q_1=F\\cdot(\\cos(q_2),\\sin(q_2))\\equiv F_r$ (define $F_r$ this way)\n\n$Q_2=F\\cdot(-q_1\\sin(q_2),q_1\\cos(q_2))\\equiv \\tau$ (define $\\tau$ this way)\n\nEuler-Lagrange equation for $q_1$:\n\n$\\ddot{q_1}m-m\\dot{q_2}^2 q_1=F_r$\n\nfor $q_2$:\n\n$\\frac{d}{dt}(m q_1^2 \\dot{q_2})-0=\\tau =m q_1^2 \\ddot{q_2}+2 m q_1 \\dot{q_1} \\dot{q_2}$\n\nDenoting $q_1=r$, $q_2=\\theta$ for clarity's sake, we wind up with the equations: $$m\\ddot{r}-m r \\dot{\\theta}^2=F_r$$ $$m r^2 \\ddot{\\theta}+2 m r \\dot{r} \\dot{\\theta}=\\tau$$\n\nFrom which we can identify the torque and whatever we want. If $r$ is constant, we have $F_r=-m v^2/r$, and identifying $m r^2 \\dot{\\theta}=L$ with the angular momentum, we see $\\dot{L}=\\tau$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18319/can-a-continuous-nowhere-differentiable-function-have-specified-shape-at-ever\nText:\nTake the 2-minute tour \u00d7\n\nI'm a bit embarrassed to admit that:\n\na) This is a rather unmotivated question.\n\nb) I can't remember whether or not I've asked this before, but searching doesn't seem to turn anything up so ...\n\nConsider some \"shape\" function $\\phi: \\mathbf{R} \\to \\mathbf{R}$. Then given some function $f: \\mathbf{R} \\to \\mathbf{R}$, one can ask whether the \"difference quotient\",\n\n$\\lim_{y\\to x} \\frac{f(y)-f(x)}{\\phi(y-x)}$,\n\nexists at various points $x$. Letting $\\phi(x) = x$ corresponds to taking normal derivatives, and intuitively when the limit exists this means that near $x$, the function $f$ \"looks like\" $\\phi$ does near 0.\n\nHowever, if the ratio $\\phi(x)/x$ is not bounded above or away from 0 as $x\\to 0$ (I'm mostly thinking of the case when it is neither, so that $\\phi$ is \"wildly oscillating\" in some sense), then anywhere the above limit exists and is nonzero, the function $f$ is necessarily non-differentiable.\n\nMy question: If $\\phi$ is some wildly oscillating function as described above (pick your favorite), can there be an $f$ for which this limit exists everywhere?\n\n(Edit: I suppose I really want $\\phi$ and $f$ to be continuous functions.)\n\nshare|improve this question\nDo you want the limit to be nonzero almost everywhere? \u2013\u00a0 Douglas Zare Mar 15 '10 at 22:50\nHow about taking $\\phi$ to be a discontinuous additive function and $f=\\phi$? \u2013\u00a0 Jonas Meyer Mar 15 '10 at 22:51\n@Douglas Zare Not necessarily. Is there an easy (non-constant) example if it isn't required? @Jonas Meyer Good point. I guess I really want $\\phi$ to be continuous, and $f$ to be a continuous nowhere-differentiable function. I really should have put the adjective continuous in a lot of places. \u2013\u00a0 Mike Hall Mar 16 '10 at 0:32\n@Mike, Any $C^{0,\\alpha}$-function $f$ and $\\phi(x)=|x|^\\beta$ for $0<\\beta<\\alpha<1$ will do. \u2013\u00a0 Anton Petrunin Mar 16 '10 at 1:12\nBut Anton, I don't think that meets the \"wildly oscillating\" criterion. \u2013\u00a0 Jonas Meyer Mar 16 '10 at 1:18\nshow 2 more comments\n\n1 Answer\n\nup vote 5 down vote accepted\n\nAssume WLOG that $\\phi(x)>0$ when $x>0$. Since the limit described exists for all $x$ in the source of $f$. We get for any $x$ the bound:\n\n$f(x+\\delta)-f(x) \\leq C\\phi(\\delta)$\n\nfor $0 < \\delta < \\delta_0$ for some $C,\\delta_0>0$ which may depend on $x$.\n\ndiving by $\\delta$ we get by the assumptions on $\\phi$ that\n\n$\\underline{\\lim}_{\\delta \\to 0} ( \\frac{f(x+\\delta) - f(x)}{\\delta}) \\leq 0$\n\nThis is one the four derivatives of $f$, and proposition 2 chapter 5 in Real Analysis by H.L. Royden states that if $f$ is continuous then it is (non-strictly) decreasing. Similar for increasing. So $f$ is constant.\n\nshare|improve this answer\n\u201cAssume WLOG that $\\phi(x)>0$ when $x>0$.\u201d Why? M Hall specifically wants to consider the \u2018wildly oscillatory\u2019 case. (I am supposing that $x \\mapsto x\\sin(1/x)$ is wildly oscillatory, anyway.) \u2013\u00a0 L Spice May 9 '11 at 2:13\nWildly oscilating refers to $\\phi(x)/x$ being both close to zero and unbounded for very small $x$. The assumption WLOG refers to the fact that the limit would not exist if $\\phi$ were not strictly positive or negative in a small $(0,\\epsilon)$ (assuming continuity). \u2013\u00a0 Thomas Kragh May 27 '11 at 15:12\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mechanics.stackexchange.com/questions/2577/when-should-i-change-the-oil-as-the-tech-recommends-or-as-my-oil-change-light-i?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI have a Toyota Corolla 2008. It has an oil change light indicator. The tech at the one hour oil change place recommends to change it every 3,000 miles but the indicator light only goes off about every 5,000 miles.\n\nWhich one is correct? How often should I change my oil?\n\nDoes the light just monitor millage, or does it have sensors that test the dirtiness of the oil?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nUsually the more sophisticated oil change indicators measure the way you drive and adjust for that - ie, if you're doing a lot of freeway miles you're probably getting longer intervals as that's not as hard on the oil as lots of stop and go in town. They are however making the assumption that you are using an oil that meets all the manufacturer's specification regarding viscosity, API grade and other specs. Oh, and the part that's most likely to be overlooked - an OEM or OEM quality (or better) oil filter. If you don't have the latter, you probably have to change the oil more often because of the diminished filtration quality of the oil filter. There's no point in using good oil with a good additive package that keeps the contaminants in suspension if they'll just pass through the oil filter or the oil filter's bypass valve because the filter isn't doing its job.\n\nSo, for OEM quality or better filters and OEM quality or better oil, follow the oil change indicator light, or if you really want to geek out, get an oil analysis done to determine how often you need to change the oil.\n\nThat said, the one hour oil change tech isn't wrong by suggesting 3k intervals in the sense that you won't hurt the car if you use a good oil; the only pain you'll feel is going to be in your wallet. Asking them if you need to change the oil more often than the manufacturer's recommendations is a bit like asking at McD if you should add a second cheese burger to your order.\n\nThe 3k interval certainly made sense a couple of decades ago, but the quality of the oils and the filtration has improved massively since (again, for good quality oils), as have the manufacturing tolerances for engines. So basically now you have oils that don't break down as quickly as they used to and you've got engines that are machined to tighter tolerances and thus have less contaminants pass into the oil so you don't need to change the oil quite as often as you used to.\n\nHowever, if you use the cheapest oil available with the cheapest oil filter, then you should change your oil more often, or just buy better quality parts.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/nonempty-subset-proof.71048/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nNonempty subset proof\n\n  1. Apr 11, 2005 #1\n    No idea where to start with this one...to prove that it is not possible to have a set B of 5 distinct positive single-digit integers such that every possible nonempty subset of B has a different sum. How do I approach it/do it?\n  2. jcsd\n  3. Apr 11, 2005 #2\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Given 5 distinct numbers, there are 2^5 - 1 possible sums of subsets, excluding the sum of all 5 which is 31.\n\n    However, the biggest possible sum of 4 distinct single digit numbres is 9+8+7+6= 28, so apply the pigeon hole principle.\n  4. Apr 11, 2005 #3\n    I'll try that, thanks for the suggestion!\n\nHave something to add?\n\nSimilar Discussions: Nonempty subset proof\n  1. A proof. (Replies: 2)\n\n  2. Any subset (Replies: 2)\n\n  3. Subset product (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/galois-theory-morphisms.546932/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nGalois Theory: Morphisms\n\n  1. Nov 3, 2011 #1\n\n    Let K = Q(21/4)\n\n    Determine the automorphism group Aut(K/Q)\n\n    2. Relevant equations\n\n    An automorphism is an isomorphism from a Field to itself\n\n    Aut(K/Q) is the group of Automorphisms from k/Q to K/Q\n\n    Definition: A K-Homomorphism from L/K to L'/K is a homomorphism L---> L' that is the identity on K\n\n    3. The attempt at a solution\n\n    I am completely at a loss really. I have calculated there are four homomorphisms from K to C and think from there if I know how many are K-homomorphisms then that'll be the number of automorphisms, because a homomorphism from a field to itself is an automorphism (Please correct me if I'm wrong on this). Then that'll give me the set of Automorphisms.\n\n    My problem is that I don't know how to go from the number of homomorphisms to the actual homomorphisms. I think it has a relation to the roots of 2(1 /4) in C (which I have calculated to be 2(1 /4), - 2(1 /4), i*2(1 /4), -i2(1 /4) )\n\n    Please help, this lack of understanding is preventing me from moving forward with other questions and my notes from lectures completely gloss over how to do this.\n  2. jcsd\n  3. Nov 3, 2011 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    [itex](2^{1/4}^2= 2^{1/2}[/itex] and [itex](2^{1/4}^3=2^{3/4}[/itex] are irrational but [itex](2^{1/4})^4= 2[/itex] is rational so any number in [/itex]Q(2^{1/4})[/itex] is of the form [itex]a+ b2^{1/4}+ c2^{1/2}+ d2^{3/4}[/itex] for rational numbers a, b, c, d. For any automorphism, f, [itex]f(a+ b2^{1/4}+ c2^{1/2}+ d2^{3/4})= a + bf(2^{1/4})+ cf(2^{1/2})+ df(2^{3/4})[/itex] so the possible values of f depend entirely upon the possible values of [itex]f(2^{1/4})[/itex], [itex]f(2^{1/2})[/itex] and [itex]f(2^{3/4})[/itex].\n\n    Further, [itex](f(2^{1/4})^4= f(2)[/itex] is rational so [itex]f(2^{1/4}[/itex] must be a fourth root of 2. Also, [itex]f(2^{1/2})^2= f(2)[/itex] so [itex]f(2^{1/2}) must be [itex]2^{1/2} (or [itex]-2^{1/2}[/itex] which is just a rational number times [itex]2^{1/2}. Each f permutes the fourth roots of 1 while fixing [itex]2^{1/2}[/itex].\n  4. Nov 3, 2011 #3\n\n\n    User Avatar\n    Science Advisor\n\n    it is somewhat misleading to say the values of f depend on the values of f(21/4), f(21/2) and f(23/4).\n\n    f is a field automorphism, so (for example) f(23/4) = f((21/4)3)= (f(21/4)3,\n\n    so f ONLY depends on the value of f(21/4).\n\n    while it is true that f permutes the roots of x4-2, it is not true that any such permutation yields an \"f\". f takes conjugate pairs to conjugate pairs, as well (the square of a fourth root of 2 must be a square root of 2).\n\n    so if one regards the 4 roots of x4-2 as \u03b11234, where:\n\n    \u03b1j = \u03b1e(j-1)\u03c0i/4\n\n    then (\u03b12 \u03b14) yield a member of Aut(K/Q), but (\u03b12 \u03b13) does not.\n\nHave something to add?\n\nSimilar Discussions: Galois Theory: Morphisms\n  1. Galois theory (Replies: 4)\n\n  2. Galois Theory question (Replies: 0)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-final-velocity-of-the-cart-and-students.53214/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the final velocity of the cart and students\n\n  1. Nov 18, 2004 #1\n    Three Physics 111 AP students, each having a mass of 60kg, climb onto a large flatbed cart that has a mass of 120 kg. Standing at one end and taking turns they run to the opposite end and jump off, one immediately following the other, each with a velocity of 10 m/s with respect to the cart. Calculate the final velocity of the cart and students with respect to the earth.\n\n    I know I need to use [itex]m_1v_1 + m_2v_2 = m_1v_1 + m_2v_2[/itex], and I have done a bunch of simpler problems with no trouble. I'm pretty sure this has to be done in steps but I'm not sure how to incorporate the answer of each step into the next. I have something like this for the first step:\n\n    [tex]60 \\cdot 0 + 120 \\cdot 0 = 60 \\cdot 10 + 120(v + 10)[/tex]\n  2. jcsd\n  3. Nov 18, 2004 #2\n    Read integral's post.\n    Last edited: Nov 18, 2004\n  4. Nov 18, 2004 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    I believe that this problem is a bit more subtle, it is essentially a rocket problem. The mass of the \"cart\" does not remain constant. As each student jumps it becomes less massive, thus each successive student will cause a larger change in velocity.\n    after the first student jumps the carts velocity will change by:\n    [tex] v_c = \\frac {m_1 V_1} {m_2 + m_3 + m_c}[/tex]\n\n    Repeat for each student and sum the changes to get the total change.\n\nHave something to add?\n\nSimilar Discussions: Calculate the final velocity of the cart and students"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55629.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nMonty Hall Strikes Again\n\nSubject: Probability Question from OZ!\nDate: Wed, 2 Nov 1994 17:13:05 +1100 (EST)\nFrom: \"Sean Pryor\"\n\n\nBasically the problem goes like this.  There are three cups, one of which \nswap them?\n\nTo summarise:\n\nThree cups with a coin under one.\nYou pick one, I pick one that DOESN'T have the coin.\nYou then either stay with your choice, or swap it with the remaining cup.\nWhat is the probability of getting the coin, either way?\n\nBTW the answer I get is 50% either way - though it has been suggested \nthat you have a 2/3 chance if you swap cups....  I disagree with this, \nbut I don't think my maths is capable of giving a definitive answer \n(which is why you're reading this!)\n\n(This problem has placed a cool Australian $50 on the line here in a bet - \nso I need an answer proving me right! :-)  My mate would never let me \nforget it if he was right...)\n\n\nSean Pryor\n\nDate: Thu, 3 Nov 1994 08:20:34 -0500\nFrom: Phil Spector\n\n\nThis question is a famous brain teaser that is usually described in terms\nof the game show Let's Make a Deal.  Indeed, you do have a 2/3 chance \nof winning if you swap cups.  The answer is anti-intuitive, and my efforts \nat explaining it usually fall a little flatter than others' explanations, so\nI'm going to let other Dr. Math's try to provide an answer, and I'm going\nto work on a productive explanation.\n\nBasically, the solution is based as follows:\nLet's say it was under cup 1.\nOption 1: You originally choose cup 1.  Then, you get shown one of the\nempty cups (let's say cup 2 or 3) at which point if you CHANGE (to the\nremaining empty cup, either cup 2 or 3), you LOSE, but if you REMAIN \nwith cup one, you WIN.\n\nOption 2: You originally choose cup 2.  Then, you get shown the remaining\nempty cup (cup 3), at which point if you CHANGE (to cup 1), you WIN, \nbut if you REMAIN with cup 2, you LOSE\n\nOption 3: You originally choose cup 3.  Then, you get shown the remaining\nempty cup (cup 2), at which point if you CHANGE (to cup 1), you WIN, \nbut if you REMAIN with cup 3, you LOSE.\n\nEach of the three options has an equal chance of occuring, based upon your\noriginal random pick.  If you change 1/3 of the time, you lose (in the case\nof option 1, which has a 1/3 probability of occuring), while if you change\n2/3 of the time (with options 2 or 3, which have a 2/3 probability of\noccuring), you win.\n\nTherefore, the proper choice is always to change!  Sorry about that 50\ndollars. :(\n\nI think the place where things skew to the anti-intuitive is the fact that\nyou will -always- get shown an EMPTY cup by the game-show host/tricker, \nnot necessarily a random cup.\n\nHope this helped.\n\nPhil, a Dr. Math who knows only statistics revolving around game shows...\n\nSubject: Probability Question from OZ!\nFrom: \"Sean Pryor\"\n\nHey, it wasn't my $50!  It was a mate you was silly enough to bet on a\nmaths problem!! :-)\n\nI think I understand.  My query is that perhaps you have a 2/3 of getting\nthe coin when changing, taking into account the whole process.  If you\nisolate the last choice and say - now it's either in this cup or that and\nI can choose this or that, its 1/2.  Is that a reasonable method of\nexplaining the anti-intuitive bit?  Or have I missed the point here...\n\nX-Sender: pspecto1@cc.swarthmore.edu\nDate: Fri, 4 Nov 1994 18:46:18 -0500\n\nExactly.  Nope, you explained it better than I did...\n\n\n>What better place to start - my favourite was always the Wheel of Fortune\n>- spinning wheels, angular momentum, friction, force, acceleration, sectors,\n>degrees, probability - that show had it all! :-)\n\nTrue, but I always thought Pat Sajak was a dweeb. :)  Glad Dr. Math could\nhelp, and of course, write back with any other problems you have...\n\nAssociated Topics:\nHigh School Logic\nHigh School Probability\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from https://mathoverflow.net/questions/45149/can-regular-expressions-be-made-unambiguous/48243\nText:\nTake the 2-minute tour \u00d7\n\nWhen investigating regular languages, regular expressions are obviously a useful characterisation, not least because they are amenable to nice inductions. On the other hand ambiguity can get in the way of some proofs.\n\nEvery regular language is recognized by an unambiguous context-free grammar (take a deterministic automaton which recognises it, and make a production $R \\rightarrow tS$ for every edge $R \\stackrel{t}{\\rightarrow} S$ in the DFA, and $R \\rightarrow \\epsilon$ for every accepting state $R$).\n\nOn the other hand, the natural \"grammar\" for a regular language is its regular expression. Can these be made unambiguous?\n\nTo be precise, let's define a parse for a regular expression (this is I think a natural definition, but not one I've seen named before).\n\n  \u2022 $x$ is an $x$-parse of $x$, if $x$ is a symbol or $x=\\varepsilon$\n  \u2022 $(y, 0)$ is an $R\\cup R'$-parse of $x$, if $y$ is an $R$-parse of $x$\n  \u2022 Similarly, $(y,1)$ is an $R\\cup R'$-parse of $x$, if $y$ is an $R'$-parse of $x$\n  \u2022 $(y_1, y_2)$ is an $RR'$-parse for $x_1x_2$, if $y_i$ is an $R$-parse for $x_i$ for $i=1,2$\n  \u2022 $[]$ is an $R^*$-parse for $\\varepsilon$\n  \u2022 $[y_1, y_2, \\dots, y_n]$ is an $R^*$-parse of $x_1x_2\\cdots x_n$, if $y_i$ is an $R$-parse for $x_i$ for $1 \\le i \\le n$\n\nIn short, the parses of a string tell us how a regular expression matches a string if it does.\n\nA regular expression $R$ is unambiguous if, for every $x \\in L(R)$, there is only one $R$-parse of $x$.\n\nGiven a regular expression, is there an unambiguous regular expression which matches the same language?\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 7 down vote accepted\n\nThere's a standard construction of a regular expression from a DFA: define an expression R(i,j,k) for the language of strings that take state i to state j of the DFA while using intermediate states that belong only to the subset of states from state 1 to state k, as follows.\n\n  \u2022 R(i,j,0) is [xyz...] where x, y, z etc are the symbols that occur as labels of transitions from state i to state j (there can be no intermediate states). If there is no such transition then R(i,j,0)=0 (the expression for the empty language).\n  \u2022 Similarly, R(i,i,0) is e + [xyz...] where e is the expression that represents the empty string.\n  \u2022 For k > 0, R(i,j,k) is R(i,j,k-1) + R(i,k,k-1) R(k,k,k-1)* R(k,j,k-1). That is, any string that takes you from i to j using intermediate states up to k either goes from i to j without going through k, or can be parsed into a sequence of substrings that go from i to k, k back to itself zero or more times, and then k to j.\n  \u2022 The regular expression for the whole language is then the sum of the expressions R(1,i,n) where i is one of the accepting states.\n\nThe first two of these rules obviously give you unambiguous expressions, the third is unambiguous because there's only one way of parsing the string into substrings as described, and the fourth is unambiguous because any given string can only go to a single accepting state. Therefore, the final regular expression constructed in this way is unambiguous.\n\nshare|improve this answer\nI think this is essentially the same construction as I have seen before, but this presentation is simpler while at the same time making the unambiguity clear. Thank you! The next question this raises for me is whether it can be done without the exponential explosion of the RE -> DFA step. A nice problem for me to think about. \u2013\u00a0 Max Nov 7 '10 at 13:29\nadd comment\n\nRegarding your question about disambiguation without exponential increase: if you're willing to move to generalized regular expressions (regular expressions with the complement and intersection operators as primitives, rather than exponential-blowup-inducing derived operations), then yes: assuming longest-match-convention on the Kleene star the only source of ambiguity will be the alternation (vertical bar) construct, and you can disambiguate every instance of this by simply turning \"a|b\" into \"a|(b&~a)\" (\"a or b-and-not-a\").\n\nNote that adding intersection and complementation does not alter the class of languages which may be defined. The languages which can be defined are still exactly the regular languages.\n\nI think this suggests that you probably can't disambiguate in general without exponential blowup because disambiguation is \"pretty similar to\" (vague term, I know) intersection with the complement.\n\nHere's a nice paper which presents many of the results needed above.\n\nshare|improve this answer\nI did not intend to use the longest match rule. My intuition is that one can make alternation unambiguous with neither a complement operator nor exponential blowup by factoring out the common part of the alternatives. \u2013\u00a0 Max Dec 5 '10 at 1:09\nThanks for the nice reference though! \u2013\u00a0 Max Dec 5 '10 at 1:10\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214315/norm-of-integral-operator-in-l1\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the norm of the operator $$ T\\colon L^1[0,1] \\to L^1[0,1]: f\\mapsto \\left(t\\mapsto \\int_0^t f(s)ds\\right) $$ ?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nLet $f\\in L^1([0,1])$. Then\n\n$$\\|Tf\\|_1=\\int_0^1 \\left|\\int^t_0 f(s) ds\\right| dt \\le \\int_0^1 \\int_0^1 |f(s)| ds dt = \\|f\\|_1$$\n\nThis shows $\\|T\\|\\le 1$. Setting $f_n(x)=n\\chi_{[0,1/n]}(x)$, we see $||f_n||_1=1$. Note that\n\n$$\\int^t_0 n\\chi_{[0,1/n]}(s) ds=\\left\\{\\begin{array}\\,1 & \\text{if}\\;t\\ge1/n\\\\ nt & \\text{if}\\;t<1/n\\end{array}\\right.$$ It follows that $$||Tf_n||_1=\\int^1_0\\int_0^t n\\chi_{[0,1/n]}(s)ds dt=\\int_0^{1/n}nt\\,dt+\\int_{1/n}^1 1\\,dt =1-\\frac{1}{2n}\\rightarrow 1\\;\\text{as}\\;n\\rightarrow\\infty. $$ Hence $||T||=1$.\n\nshare|improve this answer\nFor $f \\equiv 1$, I found $||Tf||_1=1/2$ and not $1$. Otherwise, $f(x)=e^x$ works. \u2013\u00a0 Seirios Oct 15 '12 at 16:46\nThanks for the answers! But by the definition of the norm of T as $\\Vert T \\Vert = \\sup_ {f \\in L^1[0,1],\\Vert f\\Vert_1=1} \\Vert Tf \\Vert_1$, I can't really see how $f=2$ works, nor can I see that using $f=e^x$ will work, since $\\Vert f \\Vert _1 \\neq 1$ for both of these cases. Is the definition I'm using wrong? \u2013\u00a0 Maethor Oct 15 '12 at 20:17\nWhat makes you think that your simple-minded estimate is anywhere near sharp? If you do just one step in your computation, you get $$ \\int_{0}^{1}\\left\\lvert\\int_{0}^t f(x)\\,dt\\right\\rvert\\,dx \\leq \\int_{0}^1 \\int_{0}^t \\lvert f(x)\\rvert\\,dx\\,dt $$ which is an integral over a triangular region. If you brutally replace $t$ by $1$ here, you will get an integral over a square, so your estimate will overshoot badly. I would suggest to think about $F(t) = \\int_{0}^t f(x)\\,dx$ and think about what differential equation it solves. You should get $2/\\pi$ as a final solution, unless I'm mistaken. \u2013\u00a0 commenter Oct 16 '12 at 2:27\n@Norbert: geeez, you're right... I was led astray by considering $f(x) = \\frac{\\pi}{2} \\cos{\\frac{\\pi x}{2}}$ as in the $L^2$-case. .@IHaveAStupidQuestion: Try $f_n = n \\chi_{[0,1/n]}$. This sequence will minimize the effect of charging the upper right triangle in your estimate and a computation shows that $\\lVert Tf_n\\rVert_{1} \\nearrow 1$. \u2013\u00a0 commenter Oct 16 '12 at 11:40\n@MattN. The operator $T$ is the Volterra operator. The trick to compute its norm in $L^2$ is to consider $S = T^\\ast T$. Then $\\lVert T\\rVert^2 = \\lVert T^\\ast T\\rVert$. Use that $S$ is compact and self-adjoint, so its norm is equal to its maximal eigenvalue. An eigenfunction $\\lambda f = T^\\ast T f$ is a solution to $f'' = - \\lambda f$ and this yields an ansatz that lets you compute the eigenvalues and eigenvectors of $S$ and thus its norm. \u2013\u00a0 commenter Oct 16 '12 at 13:22\nshow 18 more comments\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/12717/charging-12v-150ah-battery/12718\nText:\nTake the 2-minute tour \u00d7\n\nI want to charge a 12V battery of 150Ah with a solar panel. The solar panel specs is 12V, 25 Watt.\n\nCan anyone please provide me how to calculate that how much time it will take to charge the battery? Please provide the calculations and formulas.\n\nshare|improve this question\nCan someone migrate this to electrical.stackexchange and make sure people don't have to see this question asked here? \u2013\u00a0 Larry Harson Jul 24 '11 at 21:35\n@user2146 - at the level of understand how Ah, V, watts go together and how to model the time - it's physics. If they were askign for a specific charge circuit then it would be eeng \u2013\u00a0 Martin Beckett Jul 24 '11 at 22:49\n@user2146: in addition to agreeing with what Martin said, I'll mention that the best way to signal that you think a question should be migrated is to flag it. Commenting really doesn't help. I'm not sure why you seem to hate this question so much, anyway. \u2013\u00a0 David Z Jul 24 '11 at 22:55\nok, david and martin are right. I'll delete my comments to save clutter and david and martin can do the same \u2013\u00a0 Larry Harson Jul 25 '11 at 2:33\n@user2146 - no need it's a useful discussion to decide the level of questions here. consider it 'case law' ;-) \u2013\u00a0 Martin Beckett Jul 25 '11 at 3:24\nadd comment\n\n5 Answers\n\nup vote 3 down vote accepted\n\nWatts (electrical power) = Volts $\\cdot$ Amps, so 25W = 12V $\\cdot$ 2.1A\n\n150Amp Hour is the total capacity so 150amp $\\cdot$ 1hour, 1amp $\\cdot$ 150hours, or 2.1amp for 72hours.\n\nThat's in an ideal world of course, there are heating losses as you charge the battery, the voltage of the solar panel varies with the load and if you entirely empty a 12V lead acid battery you are likely to damage it. But basically you are looking at 10days of full sunshine\n\nshare|improve this answer\n+1 for remembering that most solar panels do not work at night \u2013\u00a0 Henry Jul 24 '11 at 23:45\nIt depends on the year, of course. One hour on a sunny day in winter is going to be pretty useless compared to one hour in summer. \u2013\u00a0 Larry Harson Jul 25 '11 at 2:36\n@Henry - well I was making the unproven assumption the OP wasn't in orbit! \u2013\u00a0 Martin Beckett Jul 25 '11 at 3:22\nadd comment\n\nThe answers you've got so far from Vladimir and Martin give you a good first-order approximation: power = current x voltage. Energy = power x time. So your 12V battery of 150Ah needs 1800Wh of energy (12 x 150). So a 25W PV panel would need 72 hours at full output (1800Wh/25W).\n\nThe equation is: Peak-hours required = $\\frac{V_{batt} \\times capacity_{batt}}{Power_{PV}} $\n\nThat's an unusual combination of quite a small panel and a very big battery - is the battery designed to be a multi-week store for a low-power system, by any chance?\n\nFor a more accurate answer, you need a lot more information.\n\nThe output of the panel at any moment will depend on:\n\n(1) the voltage, (which will be determined by the battery, and will change as the battery charges)\n\n(2) the ambient temperature, and\n\n(3) the amount light hitting the panel. The amount of light hitting the panel will depend on panel tilt, orientation, overshading, weather, altitude, location, time of year, time of day.\n\nFor (1), you need the panel IV curve, typically presented on the manufacturer's datasheet. That datasheet will also tell you how output varies with panel temperature. You can then estimate the panel's temperature from the ambient temperature - it will (to the first order) be a fairly steady amount above ambient.\n\nHere are some example power curves for a 12V PV (and it looks like it's approx 125W peak) panel, from altestore.com :\n\nPV panel I-V curve\n\nYou also need to know about the battery's characteristics as it charges: the heat losses, and how its voltage changes with temperature and % charged. In a more complex system that involves a controller too, you'd need to know how the controller behaves, how it tracks the maximum power point, and what its internal losses are. A controller is very desirable, not only because it will track the PV panel's maximum power point, but also because it will prevent the battery over-charging.\n\nThere are various online PV calculators that will combine some of this information to give you estimates of output, such as the US NREL PVWATTS calculator. And there are free online GIS insolation resources to give you the raw source information to do detailed calculations yourself, such as the EU PVGIS database.\n\nshare|improve this answer\nI think it's the combination of biggest standard pickup/SUV battery and largest (cheap) battery top-up solar panel \u2013\u00a0 Martin Beckett Aug 3 '11 at 4:23\nadd comment\n\n150 Amper*hour is the battery charge capacity. With power of 25 Watt = 25 A*V at V = 12 V you will supply 25/12 Coulomb each second (Amper*s). So the charge time is equal to 150/(25/12) = 72 hours.\n\nshare|improve this answer\nadd comment\n\nIn the simplest case, and some unmentioned assumptions, the minimum charging time would be given by the formula already mentioned: $$ T = \\frac{V \\times Ah}{W}$$ this gives 12x150/25 = 72 hours.\n\nHowever, this case makes at least two major assumptions, the battery is fully discharged and there are no losses of any kind!\n\nIn the real world, the battery will not be fully discharged and there are energy losses \"everywhere.\" Just to drive the point home, if the battery is already charged, then the time would be zero.\n\nA typical 12V battery is considered \"discharged\" when its voltage is reduced to 9V. This means it has lost only 1/4 of its energy. Everything else remaining the same, it would only need 1/4 of the time (18 hrs) to charge up. If we assume 50% efficiency, this would bring the time up to 36 hours. Assuming 8 hrs per day of sunshine, it would take about 4 days.\n\nshare|improve this answer\nadd comment\n\nYou need to know the implication of using a 25W panel, for me that is pretty small. The idea is 150Ah at 12 V (DC) we need to apply the 10hr charging method, so 10% of 150Ah gives 15A.$$\\frac{150\\,\\text{Ah}}{10\\,\\text h}=15\\,\\text A$$\n\nSo power of needed solar panel is computed as follows, $12\\,\\text V\\cdot15\\,\\text A=180\\,\\text W$. So the power of your panel is 180 W.\n\nshare|improve this answer\nThe 10% of 150ah is 15ah. \u2013\u00a0 jinawee Feb 2 at 12:48\nadd comment\n\nprotected by Qmechanic Apr 11 at 14:32\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/119655/how-many-permutations/119665\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to calculate the number of possible non-repeated permutations of these serial key styles.\n\nI have no mathematical background and cannot read formulas, which is why I'm struggling with other online literature about this.\n\nIf someone could either let me know how many for each, or how I might calculate it, I'd be very grateful.\n\nThe character set is 24 uppercase letters, and 8 numbers. (removing I, O, 0, 1)\n\n1) 7FB-E48-W60\n\n\n\n4) H6EFA-N6H7O-08WW8-0S4SC-4K4S8\n\nThanks very much.\n\n\nshare|improve this question\nYou say \"removing I, O, 0, 1$, but I see 0,1, and O in your examples. Do you mean these are examples without the restrictions? \u2013\u00a0 Thomas Andrews Mar 13 '12 at 12:39\nHi, Thomas. Sorry, these examples don't have those excluded, they're to demonstrate the grouping and length. The finished product would have those excluded. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:02\nHi, dtldarek. I struggle with simple multiplication and division when it involves odd numbers. I don't know what any of that stuff means. I was hoping for pointers on what to type into a calculator, or just the answer for each. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:07\nTo be specific, what do you mean by \"non-repeated\" and what do you mean by \"permutations of styles\"? \u2013\u00a0 dtldarek Mar 13 '12 at 13:08\nHi, Sorry that part was unclear. I'm choosing to adopt one of these, numbered 1, to 4 styles of codes to use as voucher codes to be printed on coupon cards to be sold in stores. I want to know how many of these \"keys\" or \"serials\" I could generate uniquely with the character set of 24 upper case letters and 8 numbers, by \"non-repeated\" I mean unique entire keys, but each key can contain the same character more than once. I'd prefer to use style 1, but if that only gives me 2 million possible serial keys, then I'd have to go for 2, etc... \u2013\u00a0 i-CONICA Mar 13 '12 at 13:15\nadd comment\n\n4 Answers\n\nup vote 2 down vote accepted\n  1. The dashes don't make any difference.\n  2. Your alphabet has 24 + 8 = 32 characters.\n  3. There are 32^n = 32 * 32 * 32 * ... * 32 * 32 (n times) different strings of length n using this alphabet.\n  4. Using your schemes:\n    1. 32^9 = 35184372088832,\n    2. 32^12 = 1152921504606846976,\n    3. 32^16 = 1208925819614629174706176,\n    4. 32^25 = 42535295865117307932921825928971026432.\n\nHave fun ;-)\n\nshare|improve this answer\nadd comment\n\nsince without repetition: (32 because 8+24)\n\n1- 32*31*30*29*28*27*26*25*24 = $\\frac{32!}{(32-9)}!$\n\n2- $\\frac{32!}{(32-12)}!$ \n\n3- $\\frac{32!}{(32-16)}!$ \n\n4- $\\frac{32!}{(32-25)}!$\n\nBut your example above shows repetition and I,O,0, & 1. I hope that is what you want.\n\nshare|improve this answer\nHi, Zeina. Sorry, I written the question a little confusingly. By \"non-repeating\" I mean how many of these keys could I generate uniquely. Each key can contain the same character more than once. I've left some notes on the question. Thank you for your time. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:17\nadd comment\n\nIf, as you say in an earlier comment, characters can occur multiple times in a given serial number, then it's quite straightforward: the total number of serial numbers available for a key of length $k$ is $32^k$, where 32 is the size of your character set (24 letters and 8 digits).\n\nIn practice it's usually more complicated, though, since the serial key is generated in such a way that some information can be extracted from the key (most notably whether or not the key is valid, but also things like an identifier for the product and its version number).\n\nshare|improve this answer\nadd comment\n\nIn that case the probabilities become:\n\n1- $\\32^{9} = 35184372088832\n\n2- $\\32^{12}\n\n3- $\\32^{16}\n\n4- $\\32^{25}\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/66748/how-do-control-the-boundary-regularity-of-the-legendre-transformation-domain-fr?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet f(x) be a strongly convex smooth function (its Hessian matrix is positive definite) defined in a convex domain D, introduce the Legendre transformation $$x=(x_1,...,x_n)\\rightarrow (\\xi_1,...,\\xi_n),\\xi_i=\\frac{\\partial f}{\\partial x_i},$$ $$u(\\xi_1,...,\\xi_n)=x_i\\xi_i-f$$ The Legendre transformation domain W is defined by: $$W=((\\xi_1,...,\\xi_n)|\\xi_i=\\frac{\\partial f}{\\partial x_i}, x\\in D )$$ I want to know the regularity of the boundary of W, (can assume the domain W is bounded) what conditions to make the boundary $\\partial W$ smooth or $C^2$?\n\nshare|improve this question\nIf $f$ is strongly convex and defined in a nbd of $\\bar D$, it's gradient $\\nabla f$ is a (monotone) diffeomorphism, so $\\partial W$ is $C^2$ if $\\partial D$ is $C^2$ and $f$ is $C^3$ on a nbd of $\\bar D$. \u2013\u00a0 Pietro Majer Jun 2 '11 at 17:26\nIn my question, f(x) may be defined on the whole $\\mathbb{R}^n$ (this situation is my interest), for example, the following function (known as hyperbolic affine hypersphere): $$f(x_1,...,x_n)=\\frac{1}{x_1\\cdots x_n}, x_i>0, 1\\leq i\\leq n.$$ Choose suitable coordinates, this graph can be represented by another function $\\tilde{f}$ defined on the whole $\\mathbb{R}^n$, and the Legendre transformation domain of $\\tilde{f}$ is a simplex. \u2013\u00a0 fible Jun 5 '11 at 2:28\nadd comment\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/516612/probability-of-getting-n-heads-after-cn-tosses\nText:\nTake the 2-minute tour \u00d7\n\nIf $X_n$ is the number of coin tosses to get $n$ heads, then how can one show that there exists a constant $c>1$ such that $P(X_n \\geq cn) \\leq 1/n$? I am looking for a direct elementary proof.\n\nAssume the coin tosses are fair and independent.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nSince $X_n$ is the sum of $n$ i.i.d. geometric random variables with parameter $\\frac12$, $E[X_n]=2n$ and $\\mathrm{var}(X_n)=2n$. Bienaym\u00e9-Chebychev inequality implies that, for every nonnegative $x$, $$ P[X_n\\geqslant E[X_n]+x]\\leqslant\\mathrm{var}(X_n)/x^2. $$ If $x^2=2n^2$, the RHS is $1/n$ and $E[X_n]+x=(2+\\sqrt2)n$ hence $c=2+\\sqrt2$ answers the question. Or, $$ P[X_n\\gt 4n]\\leqslant1/(2n). $$\n\nshare|improve this answer\nThank you. This would be a great answer but I was hoping, perhaps in vain, that there might be a proof that was elementary and entirely self contained. \u2013\u00a0 felix Oct 6 '13 at 16:43\nI suppose I could just incorporate a direct proof of en.wikipedia.org/wiki/\u2026 . \u2013\u00a0 felix Oct 6 '13 at 17:36\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/138368/function-space-inner-product/138552\nText:\nTake the 2-minute tour \u00d7\n\nLet $u,v$ be arbitrary elements of a function space $X$ defined on $\\Omega \\subset \\mathbb{R}^n$. Define\n\n$$ (u,v)_2 = \\int_\\Omega \\partial_x u \\, \\partial_x v + \\partial_y u \\, \\partial_y v \\:dx $$\n\nNow, my question is what should $X$ be so that $(\\cdot,\\cdot)_2$ defines an inner product?\n\nIt is clear that $(\\cdot,\\cdot)_2$ is symmetric and linear but the problem seems to be positive-definitiveness.\n\nshare|improve this question\nIn particular, $(u,u)_2 = 0$ for every constant function $u=c$. \u2013\u00a0 chango Apr 29 '12 at 9:25\nHint: $(u,u)_2=\\int_\\Omega |\\nabla u|^2$. Hence the only constant function in $X$ must be $0$. Anyway, the most used choice is $X=W_0^{1,2}(\\Omega)$. But you can also think of a space of functions $u$ with $\\int_\\Omega u=0$. \u2013\u00a0 Siminore Apr 29 '12 at 9:43\nOk, so $X=W_0^{1,2}(\\Omega)$ is the space of functions in $H^1(\\Omega)$ which vanish on $\\partial \\Omega$. And I have that $(u,u)_2=0$ implies that $u$ is constant a.e. But how do I conclude from that that $c=0$? \u2013\u00a0 chango Apr 29 '12 at 10:50\nSince $u$ vanishes on $\\partial \\Omega$. Actually, by Poincar\u00e9's inequality, $\\int_\\Omega |\\nabla u|^2 =0$ implies $\\int_\\Omega |u|^2=0$. This is a more refined viewpoint. \u2013\u00a0 Siminore Apr 29 '12 at 11:26\nadd comment\n\n2 Answers\n\nThe norm involving the inner product of the first derivative shall be associate with the Sobolev norm for the space $W^{1,2}(\\Omega)$, in which the elements and their weak derivative are both $L^2$-integrable. And as you mentioned in the comment, the fact that having constant plugging in would make the inner product be zero makes the induced \"norm\" only a semi-norm, we denote it as $|\\cdot|_{W^{1,2}(\\Omega)}$\n\nSo Here what we wanna do is to find $X$ such that this semi-norm behaves the same as the full $W^{1,2}(\\Omega)$-norm on $X$, ie, we want to quotient the kernel of $\\nabla$ out to get an equivalence class $W^{1,2}(\\Omega)/ \\mathbb{R}$, there are normally two ways to do this:\n\n  \u2022 For every element $u\\in W^{1,2}(\\Omega)$, consider the new space for $\\displaystyle \\bar{u} = u - \\frac{1}{|\\Omega|}\\int_{\\Omega} u $, and we have $\\displaystyle \\int_{\\Omega} \\bar{u} = 0$, naming this equivalence class as space $\\mathring{H}^1(\\Omega) = X$, then by Poincar\u00e9 inequality, for any $w\\in \\mathring{H^1}(\\Omega)$: $$ \\|w \\|_{L^2(\\Omega)}\\leq C\\|\\nabla w \\|_{L^2(\\Omega)} $$ hence $$ |w |_{W^{1,2}(\\Omega)} \\leq \\|w \\|_{W^{1,2}(\\Omega)}\\leq(1+ C)|w |_{W^{1,2}(\\Omega)} $$ we have the norm equivalence, and this construction is normally associated with the Pure Neumann problem for the second order elliptic PDEs.\n\n  \u2022 Another construction is we set the boundary value to be zero like $H^1_0 = X$ like you said, and use Friedrichs' inequality(Poincar\u00e9 inequality's counterpart for zero-trace functions), we could get the same norm equivalence relation above whereas the geometry constant $C$ might be different. This space relates to the Dirichlet problem for Poisson equation.\n\n  \u2022 We also could have a mixed version of above two which associates to the following problem $$ \\left\\{ \\begin{aligned} -\\Delta u &= f &\\text{ in } \\Omega \\\\ u &= g &\\text{ on } \\Gamma_D\\subset \\partial \\Omega \\\\ \\nabla u\\cdot \\boldsymbol{n} &= g_N &\\text{ on } \\Gamma_N\\subset \\partial \\Omega \\end{aligned} \\right. $$ Define the space $X = H^1_{g}(\\Omega) = \\{u\\in H^1(\\Omega): u = g \\text{ on } \\Gamma_D\\}$, if the Dirichlet boundary is not empty, $|\\cdot|_{W^{1,2}(\\Omega)}$ is a norm too.\n\nshare|improve this answer\nadd comment\nup vote 0 down vote accepted\n\nOk, so from what I gather on the basis of Siminore's comments:\n\n$X=H_0^1$ and using Poincare's inequality we have that\n\n$$ \\|u\\|_{L^2}\\leq C \\| \\nabla u \\|_{L^2}. $$\n\nHence $(u,u)_2=\\| \\nabla u \\|_{L^2}=0$ implies $u=0$ a.e.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/239441/properties-of-the-unit-normal-to-a-partially-rotated-hyperplane?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be an $n-1 \\times n$ matrix. The span of the rows of $A$ define a hyperplane in $\\mathbb{R}^n$; let $u$ be the unit normal to this hyperplane.\n\nNow, let $x \\in \\mathbb{R}^{n-1}$, and replace each element $A_{i1}$ in the first column of $A$ with a variable term $A_{i1}cos(\\theta) - x_i sin(\\theta)$; let $u(\\theta)$ be the resulting unit normal (thus, $u(0) = u$).\n\nSuppose we slide $\\theta$ up from $0$ continuously, and stop if/when $u_k(0) - u_k(\\theta) = \\Delta$ for some index $k \\in \\{1, \\dots, n\\}$. In terms of $A$, $x$, $k$, and $\\Delta$, how far can we slide $\\theta$?\n\nEDIT: I've managed to reduce the problem to a possibly simpler one. If we delete column $k$ from the modified matrix, then can we find an analytic form for its determinant? In other words, what is $\\det(A_{*,\\sim k}, \\theta)$?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nLet $A_{\\star,\\tilde{k}}$ be your matrix of interest (the sub-matrix from removing column $k$). Let it have determinant of $d$. Also let $\\mathbf{u}^\\top$ be the first row of the inverse for the matrix. Call the first column of the matrix $\\mathbf{y}$. Then the determinant is $d\\mathbf{u}^\\top\\mathbf{y}$. If $\\mathbf{y}$ is altered while keeping the rest of the matrix, then the determinant still has the same form but with the new column in place of $\\mathbf{y}$: $$d_{new}=d\\mathbf{u}^\\top\\left(\\mathbf{y}\\cos\\theta-\\mathbf{x}\\sin\\theta\\right) = d\\left(\\cos\\theta-\\mathbf{u}^\\top\\mathbf{x}\\sin\\theta\\right)$$ since from the definition of inverse we have that $\\mathbf{u}^\\top\\mathbf{y} = 1$. Thus your variation on $\\theta$ (from $0$ to $\\pi$) gives a determinant ranging from $d$ to the quantity of $-d\\mathbf{u}^\\top\\mathbf{x}$ where $\\mathbf{x}$ is the vector of elements $x_i$.\n\nMy notation of $\\mathbf{u}$ here is different than your $u(\\theta)$. The point is that the determinant of your altered matrix will take the form of a dot product with $\\mathbf{u}$ and the altered column of the matrix. This is simply known to me and may be more difficult to show you in proof form, I hope this helps regardless.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/202630/product-of-3-integers-is-72-find-the-3-integers-that-give-the-smallest-sum\nText:\nTake the 2-minute tour \u00d7\n\nProduct of 3 integers a, b, c equals 72, where every factor is positive integer. Find the integers a, b, c with the smallest sum.\n\nIt's easy to get the factors of 72 manually and see that the 3 smallest factors that give the product as 72 will be the smallest sum.\n\nI checked the factorization like this:\n\n1-1-72: 74\n1-2-36: 39\n1-4-18: 25\n1-8-9:  18\n2-4-9:  15\n3-4-6:  13\n\nIt seems like the smallest possible factors will give the smallest sum.\n\nBut there must be some trick to it or some kind of algorithm to find the smallest integers for any arbitrary product without laborious factoring.\n\nThanks for your help.\n\nshare|improve this question\nThe factors must be close to each other. A heuristic: The AM-GM inequality gives us $(a+b+c)/3 \\geq \\sqrt[3]{abc}$ where equality holds when $a=b=c$ and the difference between the LHS and RHS increases when $a$, $b$ and $c$ are far apart from each other. \u2013\u00a0 user17762 Sep 26 '12 at 5:00\nYes @Marvis is right: And 3-4-6 are the closest number in this case. \u2013\u00a0 Sumit Bhowmick Sep 26 '12 at 6:15\nOne algorithm might be to find the factor of $72$ closest to $\\sqrt[3]{72}$, which is $4$. Then find the factor of $72/4=18$ closest to $\\sqrt[2]{18}$, which is $3$. That leaves $18/3=6$. I don't know if it is always optimal, but it should be close to optimal. \u2013\u00a0 Henry Sep 26 '12 at 7:40\n@Graphth: Lagrange multipliers don't work when you need integer solutions. \u2013\u00a0 TonyK Nov 19 '12 at 15:34\n\n1 Answer 1\n\nYou could try decomposing $72$ into its prime factors. This is:\n\n$$72 = 2^3\\times 3^2 = 2*2*2*3*3.$$\n\nThen pick the smallest combination of factor, which is $2\\times 2$, $2\\times 3$ and $3$, so that $4\\times 6\\times 3 = 72$, and $4 + 6 + 3 = 13$.\n\nHope it helps.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/258204/finding-a-pythagorean-triple-a2-b2-c2-with-abc-40\nText:\nTake the 2-minute tour \u00d7\n\nLet's say you're asked to find a Pythagorean triple $a^2 + b^2 = c^2$ such that $a + b + c = 40$. The catch is that the question is asked at a job interview, and you weren't expecting questions about Pythagorean triples.\n\nIt is trivial to look up the answer. It is also trivial to write a computer program that would find the answer. There is also plenty of material written about the properties of Pythagorean triples and methods for generating them. However, none of this would be of any help during a job interview.\n\nHow would you solve this in an interview situation?\n\nshare|improve this question\nI personally have memorized most of the small Pythagorean triples (this one, for example, is 8, 15, 17). \u2013\u00a0 Joe Z. Dec 13 '12 at 20:36\ntbh, I bet they were testing your ability to admit that you didn't have the tools to solve it right there in the limited amount of time. I highly doubt they wanted you to know the answer. \u2013\u00a0 picakhu Dec 13 '12 at 20:41\nIt certainly helps to know the formula for general relatively prime triples, since you can solve for any triple such that $a+b+c$ divides 40 and then multiply to get a triple with $a+b+c=40$. \u2013\u00a0 Thomas Andrews Dec 13 '12 at 20:41\n\n5 Answers 5\n\nup vote 8 down vote accepted\n\nAssuming you do have a pen and paper, you could substitute $c = 40 - a - b$ into the first equation to get\n\n$$a^2 + b^2 = (40 - a - b)^2 = a^2 + b^2 + 1600 - 80(a + b) + 2ab.$$\n\nRewriting this equation, you get\n\n$$a + b - 20 = \\frac{ab}{40}.$$\n\nFrom this it follows that $ab$ has to be a multiple of $40$, i.e., one of them is a multiple of $5$. That narrows it down to only a few options...\n\nIf that's still too much brute-force, you could also note that $a + b > 20$ from the above equation, and $a + b < 27$, since $c$ has to be the largest of the three. This leaves only the three pairs\n\n\nLooking at the earlier equation, you see the third pair is the right one.\n\nshare|improve this answer\nOr you can rewrite that as $ab=40a+40b-800$ or $(a-40)(b-40)=800$. Given that you know $0<a,b<40$, this shouldn't be too hard to work out. \u2013\u00a0 Thomas Andrews Dec 13 '12 at 20:46\n@thomas, you know better, you know 0<a,b<20 \u2013\u00a0 picakhu Dec 13 '12 at 20:48\n@Thomas: Yes, that should work too. Still, at some point you will have to guess $a$ and $b$ I think. \u2013\u00a0 TMM Dec 13 '12 at 20:55\nThis is exactly the sort of thing I was looking for. Thank you! \u2013\u00a0 NPE Dec 14 '12 at 7:09\n\nThe general pythagorean triple can be written (up to swapping $a$ and $b$) as $$a=2kuv$$ $$b=k(u^2-v^2)$$ $$ c=k(u^2+v^2)$$ where $k,u,v$ are positive integers, $u,v$ are relatively prime with different parity and $u\\geq v$. For $a+b+c=40$, then, you get the condition $2k(u^2+uv)=40$, so you need $u^2+uv=u(u+v)$ to be a factor of $20$. Since $u,v$ have different parity, and they are positive, you know $u+v>1$ is odd, so $u+v=5$.\n\nGiven that $u\\geq v$, that yields $u=4,v=1$ and $u=3,v=2$. But $u=3$ isn't possible, since $3$ is not a factor of $20$. So The only solution is $(u,v)=(4,1)$ and therefore the only solution is $k(15,8,17)$ which you can see must have $k=1$, and you are done - the only solution is $(15,8,17)$. And $(8,15,17)$, if you count that as different.\n\nFor the more general problem, $a+b+c=2n$ (the sum of a Pythagorean triple is always even) this amounts to factoring $n=kuw$ with the following conditions:\n\n  \u2022 $k,u,w$ are positive in\n  \u2022 $w$ is odd\n  \u2022 $u<w<2u$\n\nGiven such a solution, you get a triple (by setting $v=w-u$:) $$a=2ku(w-u)$$ $$b=kw(2u-w)$$ $$c=k(2u^2+w^2-2uw)$$\n\nAnd this gives all such triples (modulo swapping $a$ and $b$.)\n\nListing these amounts to first listing the set of possible values of $w$, which can be any odd factors of $n$ such that $1<w<\\sqrt{2n}$. Then find values of $u$ with $w/2<u<w$ and $uw|n$. Then set $k=n/uw$ and you have your triple $(k,u,w)$ from which you can compute an $(a,b,c)$.\n\n(If you want to allow $ab=0$, the change the above to $u\\leq w < 2u$. Then $u=v=1$ and $k=n$ is always a solution.)\n\nshare|improve this answer\n\nThis is a rect triangle with a length of 40. for example triangle (3,4,5) with a length of 12, you can get the solution: (120/12,160/12,200/12). the point is that you know some patterns in advanced. (5,12,13) etc...\n\nshare|improve this answer\nThe solution you give is not integer. \u2013\u00a0 Martin Argerami Dec 13 '12 at 22:56\nThe term \"Pythagorean triple\" is used only for integer solutions to $a^2+b^2=c^2$ \u2013\u00a0 Thomas Andrews Dec 14 '12 at 14:25\n\n$$a^2=(c-b)(c+b) \\Rightarrow b+c = \\frac{a^2}{c-b}$$\n\n\nFor simplicity let $c-b=\\alpha$.\n\n\n$$a^2+\\alpha a-40\\alpha =0$$ Since this equation has integral solutions,\n\n$$\\Delta=\\alpha^2+160 \\alpha$$\n\nis a perfect square.Thus\n\n$$\\alpha^2+160 \\alpha =\\beta^2$$\n\n\n$$(\\alpha+80)^2=\\beta^2+80^2 \\,.$$\n\nThis way we reduced the problem to finding all pytagorean triples of the type $(80, ??, ??)$. This can be easily done if you know the formula, or by setting\n\n$$80^2=(\\alpha+80-\\beta)(\\alpha+80+\\beta)$$ and solving.\n\nshare|improve this answer\n\nIn practical, I will first solve this problem by assuming a=b. This gives approximately (11.72,11.72,16.56), then I try all possible ways around this solution. I can first assume the largest side is 17, then try (12,11),(13,10),(14,9),(15,8).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/71040/marble-game-theory\nText:\nTake the 2-minute tour \u00d7\n\nIn a game, there exist three piles of marbles, each pile with ,a,b, and c marbles respectively, where a,b,c are natural numbers and all different. At each turn, you can double the number of marbles in one pile by transporting marbles from one other larger pile (relative to the pile that is going to be doubled, before the doubling). The game is won when any two of the piles have an equal number of marbles.\n\nEither show that the game can be won from any starting a,b,c, or prove that this is not the case. (In particular, prove that the game cannot be won from every starting a,b,c.)\n\nAn interesting one, but the solution come does not.\n\n\nshare|improve this question\n\n2 Answers 2\n\nA duplicate of this question, Emptying buckets by moving pebbles around, was asked (and, interestingly, received a lot more upvotes than this one). Before Brian pointed out that it was a duplicate, I came up with a solution different from the shortlist solution. (I treat the problem of emptying one of the piles, which, as discussed in Phira's answer and comments, is equivalent.)\n\nThe idea is to successively produce $0$s in the binary representations of two of the numbers, starting with the least significant bit. So assume that the last $k$ bits of $b$ and $c$ are already zero; then if neither $b$ nor $c$ is zero yet, our aim is to make the last $k+1$ bits of two of the numbers zero.\n\nSo consider the $(k+1)$-th bits of $b$ and $c$. If they're both $0$, we're done. If they're both $1$, we just need one transfer between $b$ and $c$ to make them both $0$. If one is $0$ and one is $1$, we can put the $1$ in the lesser of the two by transferring from the greater to the lesser until it becomes the lesser.\n\nWithout loss of generality, assume $b\\lt c$. Now there are two cases. If $a\\ge b$, we can get rid of the $1$ by a transfer from $a$ to $b$. Otherwise, $a\\lt b\\lt c$, and we transfer first from $b$ to $a$ and then from $c$ to $b$, thus going from $a,b,c$ to $2a,b-a,c$ to $2a,2(b-a),c+a-b$. Now the sum of the first two numbers is $2b$, which has $0$s in the last $k+1$ bits, so we can make the last $k+1$ bits of those two numbers $0$ by making transfers between them, each of which gets rid of their last $1$ bits.\n\nIf we initially assign $a$, $b$ and $c$ such that $a$ has the fewest final zeros, this strategy seems to be slightly more efficient than the shortlist strategy: Compared to the total of $103505$ transfers minimally required to solve all distinct instances with totals less than $100$, this strategy makes $172865$ transfers while the shortlist strategy makes $190994$.\n\nshare|improve this answer\nThe $2b$ trick is nice. ($2b$ or $\\lnot 2b\\dots$) \u2013\u00a0 Brian M. Scott Dec 8 '11 at 21:33\n:-) ${}{}{}{}{}$ \u2013\u00a0 joriki Dec 8 '11 at 21:39\n\nIf you start with 0,1,2 it does not work.\n\nFor strictly positive numbers this is essentially problem C3 of the IMO shortlist 1994 where we want to empty an account in the same situation. (Because you have to have two equal amounts before an amount can get zero.)\n\nThere are several websites that offer shortlist solutions, for example:\n\n\nI don't know if I am supposed to copy a solution here.\n\nshare|improve this answer\nPresumably, \"natural numbers\" here is meant to exclude 0 (pretty common usage). \u2013\u00a0 Alon Amit Oct 9 '11 at 8:54\nFor natural number read positive integer. It\u2019s a regrettably common usage. \u2013\u00a0 Brian M. Scott Oct 9 '11 at 9:02\nPositive is also not always advisable as there are languages/countries where 0 is positive and negative. \u2013\u00a0 Phira Oct 9 '11 at 9:09\n@Brian M.Scott Note that the IMO problem has two parts. The first part is about emptying just one of the three accounts which is exactly equivalent to making two accounts the same size. \u2013\u00a0 Phira Oct 10 '11 at 7:22\nYou\u2019re right. $\\quad$ \u2013\u00a0 Brian M. Scott Oct 10 '11 at 7:42\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/76472/inverted-factorial-and-trailing-zeros-problem\nText:\nTake the 2-minute tour \u00d7\n\nFirst than anything a big Hello for all math fans like me.\n\nI've found a problem that is pretty interesting and I can't find the answer. As all of you must know, to counting the trailing zeros of $n$ factorial goes by this formula:\n\n$$c = (n/5)+(n/25)+(n/125)+(n/5^q)$$\n\nNow the problem is the following:\n\nWhat happen if the problem is in the other side, you have $c$ number of trailing zeros and you want to know the first $n$ that its $n!$ has $q$ trailing zeros, how can it be done?, I've searched a lot and I can't reach a solution. Is there an approach that I'm missing or something?\n\nThanks in advance and sorry about my English and my lack of Latex, but I'm already learning :D\n\nshare|improve this question\nI guess that $q$ is the floor of $\\log_5 (n)$. So it amounts to inverting the above function. There might not be a nice closed form for this, but I'd guess that you can write program to do this quickly. \u2013\u00a0 Tony Huynh Sep 27 '11 at 6:11\nI guess that $(m)$ refers to the floor function $\\lfloor m\\rfloor$, and that some dots are missing between the $125$ term and the $5^q$ term. Use $\\backslash\\text{lfloor}$, $\\backslash\\text{rfloor}$ and $\\backslash\\text{cdots}$. \u2013\u00a0 Did Sep 27 '11 at 6:29\nI looked at this too quickly to check the following but it seems that $\\frac16n-\\log_5n\\le c\\le\\frac16n+\\log_5n$, hence $x\\le n\\le y$ where $x=6c-6\\log_5x$ and $y=6c+6\\log_5y$. \u2013\u00a0 Did Sep 27 '11 at 6:39\nPlease replace every $6$ by $4$ in my previous comment. Sorry. \u2013\u00a0 Did Sep 27 '11 at 7:28\nThe number of trailing zeros in $n!$ is at oeis.org/A027868 -- perhaps some of the facts about the sequence given there can be inverted to give what you want. \u2013\u00a0 Michael Lugo Sep 27 '11 at 16:05\n\n2 Answers 2\n\nConsider the mixed radix representation of a positive integer using the bases 1, 6, 31, 156, 781, ... defined recursively by $b_n = 5b_{n-1}+1$, or in closed form as the sequence $(5^n-1)/4$. For example, the mixed radix representation of 2011 is <22421>, since $2011 = 2\\cdot 781 + 2\\cdot156 + 4\\cdot 31+2\\cdot 6+1\\cdot 1$. All the digits in this representation are 0, 1, 2, 3, or 4, except that a number can have 5 as a digit if all digits after the 5 equal 0; for example, the mixed radix representation of 2028 is <22450>, the mixed radix representation of 2029 is <22500>, and the mixed radix representation of 2030 is <23000>.\n\nThe point of defining this mixed radix representation is as follows: if $n$ is written in base 5 as $n = [d_kd_{k-1}\\cdots d_1d_0]_5$, then the number of trailing zeros in $n!$ is equal to the integer whose mixed radix representation is <$d_kd_{k-1}\\cdots d_1$> (note the omission of $d_0$).\n\nTherefore we can invert the function - that is, given the number $c$, we can find the smallest integer $n$ such that $n!$ has $c$ trailing zeros - as follows. Write $c$ in mixed radix representation; then append a zero to that string of numbers; then convert the string of numbers to a base-5 integer.\n\nFor example, with $c=2011={}$<22421>, the first integer $n$ such that $n!$ has $c$ trailing zeros is $n = [224210]_5 = 8055$. (Of course, the set of such integers $n$ is then precisely {8055,8056,8057,8058,8059}.)\n\nOne must be a little careful if the mixed radix representation of $c$ contains the digit 5: that means that there is no integer $n$ such that $n!$ has exactly $c$ trailing zeros. But we can find the smallest integer $n$ such that $n!$ has at least $c$ trailing zeros by \"carrying\" the 5s to the left.\n\nFor example, with $c=2028={}$<22450>, we rewrite $[224500]_5 = [225000]_5 = [230000]_5$, and so $n=[230000]_5= 8125$ is the smallest integer such that $n!$ contains at least 2028 trailing zeros; in fact, thanks to the 2 carries, $n!$ actually contains <23000>${}={}$2030 trailing zeros.\n\nshare|improve this answer\n\nAn article in GanitCharcha (www.ganitcharcha.com) will help you and have discussed on your question. Look at Problem 2 here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/69490.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nManipulating a Formula Algebraically\n\nDate: 06/15/2006 at 23:45:03\nFrom: Debbie\nSubject: What is this formula used for?  \n\nI have the formula M = C(1 + r) in my algebra text, but it doesn't \ntell me what it is for.  It also asks me to solve for the r variable.  \n\nI know that the formula when solved for the r variable is:\n      M - C\n  r = -------\n\nbut I don't understand how to get all the way there.  This is as far\nas I know:  \n      M = C(1 + r)\n     -C  -C\n  M - C =  (1 + r)\n\nBeyond this I haven't got a clue.  Where did the 1 go?  Where does the\nextra C come from?  How do you get r alone?  Thanks for your help!\n\nDate: 06/16/2006 at 10:17:55\nFrom: Doctor Peterson\nSubject: Re: What is this formula used for?\n\nHi, Debbie.\n\nFirst, you don't need to even ask what a formula is for in this sort \nof problem.  One of the most important things about algebra (or math \nin general, really) is that it is abstract: that is, we can take all \nsorts of real-world problems and turn them into math problems (such \nas equations to solve), and once you've done that, it doesn't matter \nat all where they came from.  The methods you use in algebra ignore \nthe meaning of the problem, and just look at the equation itself.\n\nMany equations you'll work with in class don't come from anywhere at \nall; you are just practicing techniques that you can use on problems \nthat do have some real-world meaning.  It's sort of like a medical \nstudent practicing an operation on a dummy; he doesn't have to ask \nabout the patient's family or insurance!  But when he gets into real \nmedicine, all those things will matter.  In this case, the equation \nMIGHT relate to interest on a bank account, with r being the interest \nrate; but the same equation could come from other sorts of problems, \ntoo--or none at all.\n\nNow, to solve this equation for r, the important thing is to make \nsure that at each step you are making a new equation that is still \ntrue--that is, an equivalent equation.  We know that if we do the \nsame thing to each side, e.g. adding the same thing, the new equation \nwill be equivalent.  But often students don't pay close attention to \nwhat they are doing, and they don't really make an equivalent \n\nLook closely at what you did:\n\n      M = C(1 + r)\n     -C  -C\n  M - C =  (1 + r)\n\nWhat you say you are doing is subtracting C from both sides.  But \nthat's not really what you did.  When you do the subtraction (without \nsimplifying anything), you actually get\n\n  M - C = C(1 + r) - C\n\nNow you have to simplify, and you can't just cross off the C's!  If we \nexpand C(1 + r) using the distributive property, we get\n\n  M - C = C + Cr - C\n\nand then combining like terms gives\n\n  M - C = Cr\n\nThat's not what you got!  Why?  Because you didn't actually subtract C \nfrom the right side, but just crossed something off, thinking it was \nthe right thing to do.  This is a very common mistake!  You must \nalways think of the subtraction as making a change to the equation and \nthen simplifying, not just as canceling something.\n\nWe can continue, now--even though what you did is not the recommended\nmethod, which I will get to in a minute.  Look at the equation we have \n\n  M - C = Cr\n\nWhat is our goal?  To get r by itself.  We're almost there; all that's \n\"wrong\" with this is that r is multiplied by C, and we can get rid of\nthat by dividing by C.  So let's divide BOTH SIDES by C, again making \nsure that's really what we do:\n\n  M - C   Cr\n  ----- = --\n    C     C\n\nNow we can simplify the right side; multiplying r by C and then \ndividing by C undoes the multiplication and just leaves r:\n\n  M - C\n  ----- = r\n\nAnd that's our answer!\n\nNow, there are two other methods that make the first step easier than \nwhat we ended up doing.  One is to always simplify both sides of an \nequation before we start solving:\n\n  M = C(1 + r)\n\n  M = C + Cr\n\n(I distributed on the right side.)\n\nNow we want to get r alone; on the right side it is FIRST being \nmultiplied by C (remember the order of operations?) and THEN we're \nadding C to it.  To get it by itself, we have to undo both operations; \nand we do that in reverse order.  (For example, in the morning I put \non my socks first, then my shoes; to undo that at night, I take off \nmy shoes first, then my socks.)  So we'll first undo the addition of \nC, by subtracting C from both sides:\n\n    M   =   C + Cr\n  - C     - C\n  M - C =       Cr\n\nWhat this really means is that we are subtracting C from both sides \nlike this:\n\n  M - C = C + Cr - C = Cr\n\nwhere I simplified the right side by combining the like terms C and \n\nNow we're right where we were in the first method, and just have to \ndivide by C to finish.\n\nThere's another way we could have done this, without simplifying \nfirst; we'd look at the equation as given and see that in\n\n  M = C(1 + r)\n\nwe are FIRST adding 1 to r, and THEN multiplying by C.  We can undo \nthat by FIRST dividing both sides by C, and THEN subtracting 1 from \nboth sides.  The answer we get would look different, but would mean \nthe same thing.  If you wish, you may try doing that; but the method \nI've shown is what is usually taught.  I mention it because it is \nclose to what you tried to do: you wanted to get rid of the C first; \nbut because it is being MULTIPLIED rather than added, you have to \nDIVIDE by it rather than subtract, in order to eliminate it.  What you \nreally did was to subtract C from the left side and divide by C on \nthe right, which didn't give an equivalent equation.\n\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nMiddle School Equations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/84424/a-simpler-proof-of-jensens-inequality\nText:\nTake the 2-minute tour \u00d7\n\nJensen's inequality states that if $(X,\\mu)$ is a measure space with $\\mu(X) = 1$, $\\phi$ is convex, and $f:X \\rightarrow \\mathbb R$ is integrable, then\n\n$$\\phi\\left(\\int fd\\mu\\right) \\leq \\int \\phi \\circ fd\\mu.$$ I am trying to find an alternative proof which doesn't require the fact that convex functions are differentiable. I first prove the result for simple functions: if $f = \\sum_{i=1} ^n a_i \\chi_{A_i} $ and the $A_i$ to be disjoint with $X = \\bigsqcup_{i=1} ^n A_i$. Then $\\sum_{i=1} ^n \\mu(A_i) = 1$, so\n\n$$\\phi\\left(\\int_X \\sum_{i=1} ^n a_i \\chi_{A_i} d\\mu\\right) = \\phi\\left(\\sum_{i=1} ^n a_i \\mu(A_i ) \\right) \\leq \\sum_{i=1} ^n \\phi(a_i) \\mu(A_i ) = \\int_X \\phi \\circ f d\\mu .$$\n\nI want to extend this to the general case by approximating $f$ with a sequence of simple functions $(f_n)$. However, I run into a problem showing that the integrals of $\\phi \\circ f_n$ converge to the integral of $\\phi \\circ f$. Any suggestions?\n\nshare|improve this question\nI think the proof of Jensen's inequality in Rudin, Real and Complex Analysis, 3rd ed. (early in Chapter 3) doesn't use the differentiability of $\\phi$, at least not overtly. That could be what you want. \u2013\u00a0 Dimitrije Kostic Nov 22 '11 at 5:27\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nHere is a proof without differentiation.\n\nSince $\\phi$ is convex, $\\phi$ is the supremum of some affine functions $\\alpha$, in the sense that $\\phi(x)=\\sup_\\alpha \\alpha(x)$ for every $x$, where each $\\alpha$ is defined by $\\alpha:x\\mapsto a_\\alpha x+b_\\alpha$ for some $a_\\alpha$ and $b_\\alpha$.\n\nNow, the integral is linear hence, for every $\\alpha$, $\\displaystyle\\int\\alpha(f)\\mathrm d\\mu=\\int(a_\\alpha f+b_\\alpha)\\mathrm d\\mu=a_\\alpha I+b_\\alpha=\\alpha(I)$, with $I=\\displaystyle\\int f\\mathrm d\\mu$. Since $\\alpha(f)\\leqslant \\phi(f)$, $\\displaystyle\\int\\alpha(f)\\mathrm d\\mu\\leqslant\\int\\phi(f)\\mathrm d\\mu$ hence $\\alpha(I)\\leqslant\\displaystyle\\int\\phi(f)\\mathrm d\\mu$.\n\nThis holds for every $\\alpha$ hence $\\sup_\\alpha \\alpha(I)\\leqslant\\displaystyle\\int\\phi(f)\\mathrm d\\mu$. Since $\\phi(I)=\\sup_\\alpha \\alpha(I)$, the proof is complete.\n\nshare|improve this answer\nI really like this. Thanks. \u2013\u00a0 Potato Dec 25 '12 at 6:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/53898/can-a-single-sentence-be-used-to-distinguish-between-isomorphic-classes-of-finit/53901\nText:\nTake the 2-minute tour \u00d7\n\nThe answer seems to be yes, judging from the following exercise I found in the book Mathematical Logic by H.D. Ebbinghaus, J. Flum, and W. Thomas:\n\nLet $S$ be a finite symbol set and let $\\mathfrak{U}$ be a finite $S$-structure. Show that there is an $S$-sentence $\\varphi _{\\mathfrak{U}}$ the models of which are precisely the $S$-structures isomorphic to $\\mathfrak{U}$.\n\nI think I have an idea of how to solve this exercise, but I seem to be unable to materialize it. Thanks.\n\nshare|improve this question\nNote that a very similar thing can be done for countable structures using infinitary logic. The result is called the \"Scott sentence\". These slides are pretty accessible: stanford.edu/~halcrow/Scott's_Isomorphism_Theorem.pdf \u2013\u00a0 Carl Mummert Jul 31 '11 at 11:33\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThe point is that you can describe your entire structure within one sentence.\n\nConsider this example: $S=\\{<\\}$ and $\\mathfrak U$ is $\\{0,1,2\\}$ and $<^\\mathfrak U$ is the usual ordering of natural numbers.\n\nWe can write: $$\\begin{align}\\varphi:= \\exists x\\exists y\\exists z&\\Big(x\\neq y\\land x\\neq z\\land y\\neq z \\land\\\\ &\\forall a(a=x\\lor a=y\\lor a=z)\\land\\\\ & x<y\\land x<z\\land y<z\\land \\\\&z\\nless x\\land y\\nless x\\land z\\nless y\\land\\\\&\\forall a(a\\nless a)\\Big)\\end{align}$$\n\nThis tells us there are exactly three different elements, and how they are ordered. Every structure in which $\\varphi$ is true has three elements and they are ordered as such, we can simply write the isomorphism as $0\\mapsto x, 1\\mapsto y, 2\\mapsto z$.\n\nIn the general case, since $S$ has finitely many symbols, and $\\mathfrak U$ is finite, we can write an exact description including:\n\n  1. \"There are $n$ different elements in $U$\";\n  2. \"There are no other elements than those $n$;\n  3. For every function symbol $f$ we can write $f(x)=y$, describing the interpretation of $f$ in $U$;\n  4. For every relation symbol $R$ we can write exactly which $k$-tuples are in $R$ and which are not.\n\nAs in the example, it is very simple to write the isomorphism, and prove it is $S$-isomorphism as wanted.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limits-when-determining-area-between-two-graphs.78874/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nLimits When Determining Area between two Graphs\n\n  1. Jun 13, 2005 #1\n    Hi all having a little problem with finding the limits on the area between 2 graphs.\n\n    i can find the easy one such as:\n\n    Find the area between y=x^2 and y = 2x\n    which is:\n    x^2 = 2x\n    x^2 - 2x = 0\n    x(x-2) = 0\n\n    x = 0 & 2\n\n    but when i have a question like:\n    Find the area between y=2-x^2 & y =x\n\n    i cant work it out i got to x(1+x)= 2\n\n    but im sooo lost\n    any help appreciated\n  2. jcsd\n  3. Jun 13, 2005 #2\n    Nvermind, I understand what your saying. To find the points of intersection between those two graphs, set them equal to each other.\n\n    [tex] 2-x^2 = x [/tex]\n\n    [tex] x^2 + x = 2 [/tex]\n\n    An obvious one is x=1.\n\n    Try quadratic formula.\n    Last edited: Jun 13, 2005\n  4. Jun 13, 2005 #3\n    sorry whozum i dont think i explained the question well, i need to work out the points of intersection i have no problems working out the area.\n\n    yeh ive already got 1. so using the quadratic formula i should be able to find the points out?\n  5. Jun 13, 2005 #4\n    so the intersecting points are -2 & 1?\n  6. Jun 13, 2005 #5\n    There you go. Graph it to make sure.\n  7. Jun 13, 2005 #6\n    hello there\n\n    well first of all you need to find where both functions actually intersect this is done by making 2-x^2=x then using the quadratic formulae to find where they intersect, and so you will find that they will intersect at 1 and at -2 now if you want to find the area between these functions its best that you graph it and then split up the area which should correspond to the addition to a couple of integrals\n    [tex]\\int_0^1 2-x-x^2 dx+\\int_{-\\sqrt{2}}^0 2-x^2+x dx-\\int_{-2}^{-\\sqrt 2} x -2+x^2 dx[/tex]\n    by integrating you will be able to find the area between those two functions?\n    by the way y=2-x^2 has roots at +/-sqrt{2}\n    the area is 2.5 units hopefully with out any small errors\n    Last edited: Jun 13, 2005\n  8. Jun 13, 2005 #7\n    thanks guys!\n  9. Jun 13, 2005 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Why in the world should one do such a thing? For all x between -2 and 1, 2- x2 is larger than x so 2-x2- x is positive and is the \"height\" of a thin rectangle between the two. The area is\n    [tex]\\int_{-2}^1 2- x- x^2 dx= \\frac{9}{2}= 4.5[/tex].\n  10. Jun 13, 2005 #9\n    yeh thats tha answer i got 9/2\n\nHave something to add?\n\nSimilar Discussions: Limits When Determining Area between two Graphs"}
{"text": "Retrieved from https://www.physicsforums.com/threads/2nd-order-de-solution.142577/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\n2nd Order De Solution\n\n  1. Nov 6, 2006 #1\n    I am familiar with how to solve a second order, non-homogenous DE with constants, i.e.\n\n    [tex]\\frac {\\partial^2X(t)}{\\partial t^2} + \\frac{\\partial X(t)}{\\partial t} = C[/tex]\n\n    by first solving the homogenous eqn, then setting the equation equal to a constant, yielding a sol'n of\n\n    [tex]X(t)= Ae^{0}+ Be^{-t}+ C[/tex]\n\n    But how does one solve a 2nd order equation that also has another t variable in it, such as:\n\n    [tex]\\frac {\\partial^2X(t)}{\\partial t^2} + \\frac{1}{t} \\frac{\\partial X(t)}{\\partial t} = C[/tex]?\n  2. jcsd\n  3. Nov 6, 2006 #2\n    First of all, you only seem to have one independent variable, so it may suitable to express your equation as\n\n    [tex]\\frac{d^2 X(t)}{dt^2} + \\frac{1}{t} \\frac{d X(t)}{dt} = C[/tex]\n\n    (note total derivative, not partial). Also, since no X(t) appears outside a derivative, you effectively have a first order equation, namely\n\n    [tex]\\frac{dp}{dt} + \\frac{p}{t} = C [/tex]\n\n\n    [tex]p(t) = \\frac{dX(t)}{dt} [/tex]\n\n    Now, any first order equation of the form\n\n    [tex]\\frac{dy}{dx} + s(x) y + r(x) = 0 [/tex]\n\n    has the solution\n\n    [tex]y(x) = -e^{-\\int s(x) dx} \\int r(x) e^{\\int s(x) dx} dx [/tex]\n\n    (just differentiate this and you'll see it works) Hence you can solve for p(t), and then for X(t).\n    Last edited: Nov 6, 2006\n  4. Nov 6, 2006 #3\n    Ah, that's a very nice way of framing the equation, I hadn't thought of that. Thanks!\n\nHave something to add?\n\nSimilar Discussions: 2nd Order De Solution\n  1. Solving a 2nd order DE (Replies: 11)\n\n  2. 2nd order nonlinear DE (Replies: 0)\n\n  3. 2nd order Linear DE (Replies: 1)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/203491/expected-coverage-after-sampling-with-replacement-k-times\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nprobability distribution of coverage of a set after X independently, randomly selected members of the set\n\nIf I sample with replacement $k$ times from a jar of with a finite population of $N$ unique marbles. What is the probability distribution for the fraction of the unique marbles that I sample?\n\nshare|improve this question\nadd comment\n\nmarked as duplicate by Byron Schmuland, tomasz, Chris Eagle, Norbert, Noah Snyder Oct 7 '12 at 19:09\n\n\n1 Answer\n\nup vote 1 down vote accepted\n\nWe answer only the expectation question in the title, and not the more complicated distribution question asked in the body of the post. Questions like this one have been asked several times on MSE. There is also a large technical literature on related questions.\n\nFor $i=1$ to $N$, let random variable $X_i$ be $1$ if $i$ is chosen at least once, and let $X_i=0$ otherwise.\n\nThe probability that $X_i=1$ is $1$ minus the probability that the number is chosen no times. On any one trial, the probability of not choosing $i$ is $\\frac{N-1}{N}$. Hence $$\\Pr(X_i=1)=1-\\left(\\frac{N-1}{N}\\right)^k.$$ The number $Y$ of $i$ chosen is given by $$Y=\\sum_{i=1}^N X_i,$$ so by the linearity of expectation, $$E(Y)=\\sum_{i=1}^N X_i=N\\left( 1-\\left(\\frac{N-1}{N}\\right)^k \\right).$$ For the expected proportion, divide by $N$.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/65011/prove-this-formula-for-the-fibonacci-sequence\nText:\nTake the 2-minute tour \u00d7\n\nThis formula provides the $n$th term in the Fibonacci Sequence, and is defined using the recurrence formula: $u_n = u_{n \u2212 1} + u_{n \u2212 2}$, for $n > 1$, where $u_0 = 0$ and $u_1 = 1$.\n\nShow that\n\n$$u_n = \\frac{(1 + \\sqrt{5})^n - (1 - \\sqrt{5})^n}{2^n \\sqrt{5}}.$$\n\nPlease help me with its proof. Thank you.\n\nshare|improve this question\nQuite related. You can use the eigendecomposition of a matrix to derive the Binet formula. Alternatively, you solve the characteristic equation of your recurrence. \u2013\u00a0 \uff2a. \uff2d. Sep 16 '11 at 5:14\nThere's a straightforward induction proof. The base cases are $n=0$ and $n=1$. For the induction step, you assume that this formula holds for $k-1$ and $k$, and use the recurrence to prove that the formula holds for $k+1$ as well. \u2013\u00a0 Srivatsan Sep 16 '11 at 5:14\nBriefly: associated with your difference equation $u_{n+1}-u_n-u_{n-1}=0$ is the polynomial $x^2-x-1$. Find the roots of that polynomial, and an appropriate linear combination of powers of those two roots gives Binet. \u2013\u00a0 \uff2a. \uff2d. Sep 16 '11 at 5:16\nYet another method is to a uniqueness theorem. Since the solution must be unique, just show your proposed $u_n$ satisfies the recurrence relation and has the same initial conditions. \u2013\u00a0 Ragib Zaman Sep 16 '11 at 10:44\nDid you read en.wikipedia.org/wiki/Fibonacci_number#Closed-form_expression ? \u2013\u00a0 lhf Sep 16 '11 at 12:10\nadd comment\n\n3 Answers\n\nHINT $\\rm\\quad\\ u_n =\\: x^n\\ \\iff\\ 0\\ =\\ x^{n+2}\\:-\\:x^{n+1}\\:-\\:x^n\\ =\\ (x^2-x-1)\\ x^n\\ =:\\ f(x)\\ x^n\\:.\\:$\n\nTherefore, we infer that $\\rm\\ \\phi^{\\ n}\\:$ and $\\rm\\ \\bar\\phi^{\\ n}\\:$ are solutions, where $\\rm\\:\\phi,\\ \\bar\\phi\\:$ are the roots of $\\rm\\:f(x)\\:.$\n\nThus by linearity $\\rm\\ g_n =\\: c\\ \\phi^{\\:n} +d\\ \\bar\\phi^{\\:n}\\ $ is also a solution, for any constants $\\rm\\: c,\\:d\\:.$\n\nBy induction, solutions are uniquely determined by their initial conditions $\\rm\\:u_0,\\:u_1,\\:$ hence\n\n$\\begin{array}{rl} \\qquad\\qquad\\rm g_n =\\: f_n\\!\\! &\\iff\\quad\\begin{array}{}\\rm 0\\: =\\: f_0 =\\: g_0 =\\: c+d \\\\ \\rm 1\\: =\\: f_1 =\\: g_1 =\\: c\\ \\phi + d\\ \\bar\\phi\\end{array} \\\\ &\\iff\\quad\\rm d = {-}c,\\quad c\\: =\\: \\dfrac{1}{\\phi-\\bar\\phi} \\\\ &\\iff\\quad\\rm g_n =\\: \\dfrac{\\phi^{\\:n}-\\bar\\phi^{\\:n}}{\\phi\\ -\\ \\bar\\phi\\ \\ \\ } \\end{array}$\n\nThis is a prototypical example of the power of uniqueness theorems for proving equalities. Here the uniqueness theorem is that for linear difference equations (i.e. recurrences). While here the uniqueness theorem has a trivial one-line proof by induction, in other contexts such uniqueness theorems may be far less less trivial (e.g. for differential equations). As such, they may provide great power for proving equalities. For example, some of my prior posts.\n\nshare|improve this answer\nadd comment\n\nLet's catalog some those suggestions given in the comments. First, let me rewrite the Binet formula in a more convenient form:\n\n\nwhere $\\phi=\\frac12(1+\\sqrt5)$ is the golden ratio.\n\n1) Verifying the Binet formula satisfies the recursion relation. First, we verify that the Binet formula gives the correct answer for $n=0,1$. The only thing needed now is to substitute the formula into the difference equation $u_{n+1}-u_n-u_{n-1}=0$. You then obtain\n\n\nWe can do some factoring:\n\n\nand since we know that $\\phi^2-\\phi-1=0$, Binet's formula is verified.\n\n2) Solving the characteristic equation. One can associate with the linear difference equation $u_{n+1}-au_n-bu_{n-1}=0$ the characteristic equation $x^2-ax-b=0$. If the two roots of the characteristic equation are $x_1$ and $x_2$, the solutions of the difference equation take the form $u_n=px_1^n+qx_2^n$.\n\nFor the Fibonacci recurrence, $a=b=1$, and the roots of $x^2-x-1=0$ are $\\phi$ and $1-\\phi=-\\phi^{-1}$. Thus, $F_n$ is expressible as\n\n\nWe can solve for $p$ and $q$ by using the initial conditions $F_0=0,F_1=1$. This gives the two equations\n\n\nwith the solutions $p=-q=\\frac1{\\sqrt{5}}$. Substituting that into the preliminary expression for $F_n$ yields the Binet formula.\n\nshare|improve this answer\nadd comment\n\nUsing generating functions \u00e0 la Wilf's \"generatingfunctionology\". Define the ordinary generating function: $$ F(z) = \\sum_{n \\ge 0} F_n z^n $$ The Fibonacci recurrence is: $$ F_{n + 2} = F_{n + 1} + F_n \\qquad F_0 = 0, F_1 = 1 $$ Applying properties of the ordinary generating function: $$ \\frac{F(z) - F_0 - F_1 z}{z^2} = \\frac{F(z) - F_0}{z} + F(z) $$ The solution to this equation as partial fractions is: $$ F(z) = \\frac{z}{1 - z - z^2} = \\frac{1}{\\sqrt{5}}\\cdot \\left( \\frac{1}{1 - \\phi z} - \\frac{1}{1 - \\bar{\\phi} z} \\right) $$ Here $\\phi = \\frac{1}{2} (1 + \\sqrt{5})$ and $\\bar{\\phi} = \\frac{1}{2}(1 - \\sqrt{5})$ are the roots of $r^2 - r - 1$. This is just two geometric series: $$ F_n = \\frac{1}{\\sqrt{5}}(\\phi^n - \\bar{\\phi}^n) $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/4551/a-question-on-function-fields-extending-my-previous-question/4647\nText:\nTake the 2-minute tour \u00d7\n\nConsider the extension Q(a,b) of the field of rationals, where a,b are algebraically independent transcendentals. To Q(a,b) adjoin the roots of the polynomials x^5+a^5=1 and y^5+b^5=1. The resulting field Q(a,b)[x,y] is a radical extension of Q(a,b).\n\nIs it true that the only solutions to the equation X^5+Y^5=1 in the field Q(a,b)[x,y] are {0,1},{a,x}, {b,y}, {1/a,-x/a) and (1/b, -y/b)?\n\nComment: See FC's answer to my previous question.\n\nshare|improve this question\nCan I recommend that you rewrite your title so that it asks a question? \u2013\u00a0 Theo Johnson-Freyd Nov 8 '09 at 1:07\nWhy don't you mimic what FC told you about the 1-dimensional case and see how far it gets and then tell us? \u2013\u00a0 Kevin Buzzard Nov 8 '09 at 7:44\nto FC: i marked your answer as correct. do you think mimicking your answer (to the first question) might work to answer the second question? Let me know what you think...you can email me at bmk@math.cornell.edu, and I will tell you why I am interested in these questions and perhaps this might lead to an interesting work. \u2013\u00a0 Bakh Nov 9 '09 at 17:11\nadd comment\n\n4 Answers\n\nThe complete set of solutions consists of $$(1,0), (0,1),$$ $$(a,x), (x,a), (1/a,-x/a), (-x/a,1/a), (1/x,-a/x), (-a/x,1/x),$$ $$(b,y), (y,b), (1/b,-y/b), (-y/b,1/b), (1/y,-b/y), (-b/y,1/y).$$\n\nLet $C$ be the affine curve $X^5+Y^5=1$ over $\\mathbf{Q}$. Because your field $K:=\\mathbf{Q}(a,b)[x,y]$ is the function field of the $\\mathbf{Q}$-variety $C \\times C$, the set $C(K)$ is in bijection with the set of rational maps $C \\times C \\to C$. So the only fact needed beyond what was in FC's answer to your earlier question is the geometric fact that every non-constant rational map $C \\times C \\to C$ is a composition consisting of the first or second projection $C \\times C \\to C$ followed by a birational automorphism of $C$. More generally,\n\nIf $X,Y,Z$ are curves over a field $k$, and the genus of $Z$ is at least $2$, then every rational map $X \\times Y \\to Z$ factors through the first or second projection.\n\nProof: Extend the rational map to a rational map $X \\times Y \\to Z \\times Y$ by using the projection $X \\times Y \\to Y$ as the second coordinate map. Restrict this to the fibers above the generic point of $Y$ to get a rational map $X_L \\to Z_L$, where $L$ is the function field of $Y$. If this is constant, i.e., factors through the structure map to $\\operatorname{Spec L}$, then the original map factors through the projection to $Y$. On the other hand, the genus hypothesis implies that, up to powers of Frobenius in characteristic $p$, there are only finitely many non-constant rational maps from $X$ to $Z$ over any field, and hence finitely many of bounded degree in any characteristic, so there are no algebraic families of such maps, so the rational map $X_L \\to Z_L$ must be the base extension of a rational map $X \\to Z$, which means that the original rational map factors through the projection to $X$. $\\square$\n\n@Bakh: Both FC and I used the general observation that if $X$ and $Y$ are curves over a field $k$, and $K$ is the function field of $Y$, then $X(K)$ is in bijection with the set of rational maps from $Y$ to $X$. If you have not studied enough algebraic geometry yet to understand this, the following example may be helpful:\n\nConsider the case where $X$ is the plane curve $f(x,y)=0$ and $Y$ is the affine line $\\mathbf{A}^1$, so $K=k(t)$. To give a point in $X(K)$ is to give rational functions $r(t)$ and $s(t)$ such that $f(r(t),s(t))=0$ identically. If we substitute a particular element of $k$ for $t$, then $(r(t),s(t))$ specializes to a point on $X(k)$, and hence we get a map $\\mathbf{A}^1(k) \\to X(k)$ except that we must avoid the finitely many poles of $r(t)$ and $s(t)$. The same holds for points over any field extension of $k$, and in fact we get a rational map $\\mathbf{A}^1 \\to X$.\n\nMore scheme-theoretically, one can say that an element of $X(K)$ is a $k$-morphism from the generic point of $Y$ to $X$, and such a morphism spreads out to a morphism from some Zariski dense open subscheme of $Y$ to $X$, i.e., to a rational map from $Y$ to $X$.\n\nshare|improve this answer\nGiven that Bakh asked this question last Nov 7, and last logged in Nov 15, there's a chance he/she will never see this answer Bjorn. If one of your motivations for doing the exercise I suggested to Bakh was to make their life easier, then you might want to consider emailing them alerting them to the fact you've done it! \u2013\u00a0 Kevin Buzzard Mar 25 '10 at 8:48\nOK, thank you, Kevin; I'll do that. \u2013\u00a0 Bjorn Poonen Mar 25 '10 at 9:25\nadd comment\n\nYou will have more points than just the ones listed. To start, notice that $x$ and $y$ are both invertible. This is because $1 - a^5$ is invertible, and this equals $x^5$. This lets you write $1/x$ as $x^4/(1 - a^5)$. For this reason, you'll at least have extra solutions like $$(1/x, -a/x).$$\n\nAs to whether this amended list is complete, I do not know. I would believe that it is, but cannot say at the moment.\n\nshare|improve this answer\nadd comment\n\nNo. If you adjoin all the roots of $x^5=1-a^5$ to $\\mathbb{Q}(a, b)$, then you obtain a field that contains a primitive 5th root of unity. This will lead to more solutions of $X^5+Y^5=1$ then you have listed here.\n\nshare|improve this answer\nI think the intention was to adjoin exactly one root of each of the two polynomials. \u2013\u00a0 S. Carnahan Nov 8 '09 at 8:16\nadd comment\n\nHere are my comments to some of the suggestions and answers:\n\n(1) I dont quite know some of the facts (theorems, formulas, definitions) mentioned in FC's answer in order to mimic his answer in this case. Those facts might assume certain things not satisfied by the fields I am looking at.\n\n(2) i am adjoining exactly one root of each of the polynomials.\n\n(3) My guess is one might use the fact that a and b are algebraically independent (over Q) and that x and y are algebraic over a and b, respectively. Hence, there might be a reasoning that states that any polynomial equation p=0 that uses both something from {x,a} and something from {y,b} should be a trivial one. Therefore, the case might be reduced to the case of the first question (answered by FC). Cant make this work due to the lack of knowledge in the area at this stage.\n\nCheers, -Bakh.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://newton.dep.anl.gov/askasci/math99/math99144.htm\nText:\nNEWTON, Ask A Scientist!\nName: Norman\nStatus: student\t\nAge:  N/A\nLocation: N/A\nCountry: N/A\nDate: N/A \n\nIf the probability of being struck by lightning is 1 in 600,000, what is the probability of being struck twice?\n\n\nIn general, the probability of some occurrence with known probability happening twice to the same individual would be a product of the independent probabilities.\n\nIn your example, this would mean 1/600,000 times 1/600,000 or 1/360,000,000,000.\n\nJust a comment on this result...such a probability would represent the chance for a random occurrence assuming the original probability was calculated from random occurrences. This probability might be much higher for someone who tends to golf, mountain climb, fish, etc during lightning storms.\n\nIt also presumes that the individual could survive the first strike, which unfortunately might not be very likely.\n\nThanks for using NEWTON!\n\nRic Rupnik\n\n\nLightning does not know whether you have been struck previously. After you are struck, you have a 1 in 600,000 chance of being struck a second time. The probability of being struck twice can be worked out as follows. Consider 600,000 sets of events. In the first 599,999 you are never struck. In the last you are struck at least once. This is the 1 in 600,000 chance of being struck at least once. Make each of these sets 600,000 events. All of the first 599,999 sets of 600,000 events are \"never struck\"(359,999,400,000 events). In the last set of 600,000 events, the first 599,999 are \"only struck once\". The last is \"struck more then once\". This is a total of 360,000,000,000 events. The probabilities are:\n\nnever struck: (599,999 in 600,000),or (359,999,400,000 in 360,000,000,000)\n\nstruck exactly once: (599,999 in 360,000,000,000),or essentially (1 in 600,000)\n\nstruck more than once: 1 in 360,000,000,000 (1 in 360 billion)\n\nDr. Ken Mellendorf\nPhysics Instructor\nIllinois Central College\n\nClick here to return to the Mathematics Archives\n\n\n\nEducational Programs\nBuilding 360\n9700 S. Cass Ave.\nArgonne, Illinois\n60439-4845, USA\nUpdate: June 2012\nWeclome To Newton\n\nArgonne National Laboratory"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/134629/how-to-properly-drive-mosfet-in-mpp-tracking-duty-cycle-above-50-for-a-synchron\nText:\nI'm currently building a 10W high voltage (~50V-100V) Maximum Power Point Tracking (MPPT) buck regulator on the side for educational purposes. For the time being, the output is tied to a load. Things are working well, and the circuit properly tracks the maximum power point as expected. So far so good.\n\nI'm using the LTC4444-5 High Voltage Synchronous N-Channel MOSFET Driver to drive the top and bottom NMOS MOSFETs controlling the buck power stage (switching at 100kHz), which introduces an issue. On many occasions, my MPPT algorithm wants to set the duty cycle above 50%. This is problematic for a synchronous buck stage since it starts lowering the voltage on the bootstrap capacitor charged by the synchronous MOSFET driver, to the point where the top MOSFET barely turns on.\n\nIn order to have the top MOSFET turn on for duty cycles >50%, I have two options:\n\n  1. Find a high side MOSFET driver that uses a charge pump rather than a bootstrap cap. The best candidate I found was the MIC5011 from Micrel. Ignoring the fact that the maximum input voltage is too low, it's biggest drawback is that it turns on too slowly: 25us absolute best case (40kHz), more common case is 50us(20kHz).\n  2. Have an isolated MOSFET driver with an isolated power supply, but that's starting to get pricey.\n\nIs isolation the only way to properly drive these MOSFETs? Are there high-side MOSFET drivers that are high voltage (say >50V), switch quickly (easily support 100kHz) and can handle >50% duty cycle?\n\nBetter yet, am I going down the wrong path? Is there a simpler way to solve this issue?\n\n\n1 Answer 1\n\n\nIt's odd what you say about the bootstrap circuit not performing well above D=0.5. I'm using the same driver chip for a hefty 200 watt power supply where the duty range is quite wide and I've never seen this happening.\n\nI'm switching at 100 kHz - maybe you are using a switch frequency that is too low? Too low a frequency will cause bootstrap power to be a problem.\n\nAnother alternative is to use something like a little 2 watt Traco-Power or XP or Murata mini-power module to generate a floating 12 volt for your top FET.\n\n  \u2022 \\$\\begingroup\\$ What size capacitor do you have on your LTC444-5. I calculated 10uF, but maybe I need to go bigger? \\$\\endgroup\\$\n    \u2013\u00a0TRISAbits\n    Oct 16, 2014 at 22:21\n  \u2022 \\$\\begingroup\\$ I used the standard (no thinking) 220nF but maybe your input voltage is dropping quite low - realistically you can only produce twice Vcc maximum with a bootstrap cap so, what is F and what is your lowest voltage from the panels when it drops out causing problems? \\$\\endgroup\\$\n    \u2013\u00a0Andy aka\n    Oct 16, 2014 at 22:30\n\nYour Answer"}
{"text": "Retrieved from https://mathzsolution.com/is-there-an-injective-cubic-polynomial-z2%E2%86%92zmathbb-z2-rightarrow-mathbb-z/\nText:\nIs There An Injective Cubic Polynomial Z2\u2192Z\\mathbb Z^2 \\rightarrow \\mathbb Z?\n\nEarlier, I was curious about whether a polynomial mapping Z2Z could be injective, and if so, what the minimum degree of such a polynomial could be. I\u2019ve managed to construct such a quartic and rule out the existence of such a quadratic, but this leaves open the question of whether a cubic might exist. Equivalently my question is:\n\nCan a cubic polynomial of two variables with integer coefficients be injective?\n\nMy intuition is that there probably is such a function since there is a quadratic bijection N2N so if we allow ourselves an extra \u201cdegree\u201d to compensate for the transition from N to Z, it seems like it ought to be sufficient. However, I have yet to come up with an example that I suspect of being injective nor any general method I might use to try to prove injectivity.\n\nThe Part of This Post That Isn\u2019t A Question, But That Helps Motivate It Or Maybe Inspire Someone:\n\nSo far I have determined that there is an injective quartic and there is not an injective quadratic. To construct the quartic which is injective, note that the map f:N2N defined by f(x,y)=(x+y)2+y is injective and so is the map g:ZN defined by g(n)=2n2n. Then, one can set\nas an injective polynomial (of degree 4) in the two variables.\n\nNo quadratic polynomial may exist because any integer valued polynomial of degree two has a (non-zero) multiple expressible as:\nwhere P1 and P2 are polynomials with integer coefficients. Then, if we choose some y1 and a y2 such that y_1\\equiv y_2 \\pmod{4aP_1(y_1)}, we clearly have that P_1(y_1)\\equiv P_1(y_2)\\pmod a and that P_2(y_1)-P_2(y_2)=4aP_1(y_1)k for integer k. Then, we can choose two integers c_1 and c_2 such that c_1^2-c_2^2=P_2(y_2) \u2013 P_2(y_1)\nc_1\\equiv c_2 \\equiv P_1(y_1)\\equiv P_1(y_2) \\pmod a\nIn particular the values\nsatify the above. Then, choosing x_1=\\frac{c_1-P_1(y_1)}{a} x_2=\\frac{c_2-P_1(y_2)}{a} yields that P(x_1,y_1)=P(x_2,y_2), since their difference is (c_1^2-c_2^2) \u2013 (P_2(y_2)-P_2(y_1)) which we chose the c\u2018s to make 0.\n\nI have no idea how to approach the cubic case.\n\nA Moderately Surprising Computational Result\n\nUsing Mathematica, I determined that there is no polynomial of degree three with integer coefficients with absolute value 2 or less which is injective over the domain (\\mathbb Z \\cap [-2,2])^2. This surprises me, but it such a small set of polynomials that it might not mean anything other than that we might expect large-ish coefficients if a suitable polynomial does exist. (It could also be indicative of the fact that no such polynomial exists). I would have checked a larger range, but my computer crashed.\n\nI also thought the solving the one-dimensional case completely might help, and can see that x\\mapsto ax^3 + bx^2 + cx + d is injective if and only if it cannot be written as a(x-A)(x-B)\\left(x-\\frac{C}a\\right)+k for integer a,A,B,C,k \u2013 but this isn\u2019t super helpful, far as I can tell. However, the statement f(x,y) is injective is equivalent to asserting that t\\mapsto f(m_1t + b_1,m_2t+b_2) is injective for all m_1,b_1,m_2,b_2\\in\\mathbb Z with not both m equalling 0 \u2013 so this could be used to eliminate some cases, if nothing else.\n\n\nDisclaimer: This is merely a too lengthy comment to fit in the comment section.\n\nI still have no idea about the general degree 3 case, but here is another proof that no polynomial of degree 2 will work:\n\nWrite the polynomial P(x,y) of degree 2 as\n\nP(x,y)=\\sum_{i+j\\leq 2}c_{ij} x^i y^j,\\quad c_{ij}\\in\\mathbb Z\n\nConsider a point (a,b)\\in\\mathbb Z^2\\setminus\\{(0,0)\\} and the expression\n\n\nIf the coefficient (c_{10}a+c_{01}b) is zero, then t\\mapsto P(ta,tb) is an even function. Then\n\n\nfor all t\\in\\mathbb Z. If c_{10}=c_{01}=0 we can choose any (a,b)\\in\\mathbb Z^2\\setminus\\{(0,0)\\}. Otherwise (a,b)=(-c_{01},c_{10})\\neq(0,0) works. In any case, we have found an infinitude of pairs (ta,tb),(-ta,-tb) contradicting P being injective.\n\nSource : Link , Question Author : Milo Brandt , Answer Author : String\n\nLeave a Comment"}
{"text": "Retrieved from http://www.math.uni-magdeburg.de/institute/imo/teaching/wise19/cao/models/color.mod\nText:\nset V; # nodes param q default card(V); # number of colors to try # we definitely won't need more colors than there are vertices set C = 1..q; # set of potential colors set E within V cross V; # edges var x {V cross C} binary; # x[v,c] = 1 if vertex v is colored using color c, and x[v,c] = 0 otherwise var y {C}; # encodes whether color c is used (1 = used) # x binary => y binary, so we don't need to declare that here # objective function: minimize the number of colors used minimize NumOfUsedCols: sum {c in C} y[c]; # each vertex has exactly one color s.t. AssignColor {v in V}: sum {c in C} x[v,c] = 1; # adjacent vertices must not have the same color s.t. Conflict {(v,w) in E, c in C}: x[v,c] + x[w,c] <= 1; # if vertex v has color c, then color c is used s.t. SetIndicator {v in V, c in C}: x[v,c] <= y[c]; # we allow that y[c] = 1 although c is not used. # However, this will never occur in an optimal solution, so we # don't have to exclude it explicitly"}
{"text": "Retrieved from http://archives.math.utk.edu/visual.calculus/4/int_by_parts.7/index.html\nText:\nEvaluate the following integral:\n\n  1. Let\n    and let\n\n  2. Hence,\n    and let\n\n  3. Using the formula for integration by parts\n\n    we get\n\n  4. Now we can use integration by parts again to compute the following integral\n\n  5. Let\n    and let\n\n  6. Hence,\n    and let\n\n  7. Finally we get\n\n  8. We can now use the above result to finish solving the problem:\n\n  9. It is easy to see that the integral obtained ( marked in red ) is the same as the original integral. Let us combine both integrals on the left hand side:\n\n  10. Acknowledgment: The java applet which is used on this page to display the equations in the discussion above is HotEqn from the Virtual Control Lab.\n\n    This page and the javascript used on this page was written by Marek Szapiel."}
{"text": "Retrieved from https://bioinformatics.stackexchange.com/questions/13627/how-to-design-deseq2-lrt-model-with-individuals-nested-in-2-levels\nText:\nWe have a complicated experimental design that we would like to perform LRT analysis for. Our main goal is to discover significant genes for the \"Injection:Social\" interaction term across the entire dataset by removing it from the LRT reduced model, and as a bonus we are also interested in discovering significant genes for that interaction term for each respective brain region.\n\nSample  Injection   Social  Region  Individual  ind.n\nHY06    L   ISO HY  S06 S1\nNST6    L   ISO NS  S06 S1\nTN06    L   ISO TN  S06 S1\nHY08    L   ISO HY  S08 S2\nNST8    L   ISO NS  S08 S2\nTN08    L   ISO TN  S08 S2\nHY30    L   KF  HY  S30 S1\nNST30   L   KF  NS  S30 S1\nTN30    L   KF  TN  S30 S1\nHY32    L   KF  HY  S32 S2\nNST32   L   KF  NS  S32 S2\nTN32    L   KF  TN  S32 S2\nHY64    L   KFC HY  S64 S1\nNST64   L   KFC NS  S64 S1\nTN64    L   KFC TN  S64 S1\nHY65    L   KFC HY  S65 S2\nNST65   L   KFC NS  S65 S2\nTN65    L   KFC TN  S65 S2\nHY19    L   NF  HY  S19 S1\nNST19   L   NF  NS  S19 S1\nTN19    L   NF  TN  S19 S1\nHY24    L   NF  HY  S24 S2\nNST24   L   NF  NS  S24 S2\nTN24    L   NF  TN  S24 S2\nHY05    S   ISO HY  S05 S1\nNST5    S   ISO NS  S05 S1\nTN05    S   ISO TN  S05 S1\nHY12    S   ISO HY  S12 S2\nNST12   S   ISO NS  S12 S2\nTN12    S   ISO TN  S12 S2\nHY31    S   KF  HY  S31 S1\nNST31   S   KF  NS  S31 S1\nTN31    S   KF  TN  S31 S1\nHY34    S   KF  HY  S34 S2\nNST34   S   KF  NS  S34 S2\nTN34    S   KF  TN  S34 S2\nHY62    S   KFC HY  S62 S1\nNST62   S   KFC NS  S62 S1\nTN62    S   KFC TN  S62 S1\nHY63    S   KFC HY  S63 S2\nNST63   S   KFC NS  S63 S2\nTN63    S   KFC TN  S63 S2\nHY04    S   NF  HY  S04 S1\nNST4    S   NF  NS  S04 S1\nTN04    S   NF  TN  S04 S1\nHY20    S   NF  HY  S20 S2\nNST20   S   NF  NS  S20 S2\nTN20    S   NF  TN  S20 S2\n\nMy first attempt was building simple full (m1) and reduced (m2) models that gets directly at our question of interest but doesn't control for nested individuals.\n\nm1 <- model.matrix(~ Region + Social * Injection, colData_filt)\nm2 <- model.matrix(~ Region + Social + Injection, colData_filt)\n\nWe want to control for individual/batch effects, which is nested within both \"Injection\" and \"Social\" but not region, as we have three brain regions per individual. I followed the example in the DESeq2 manual for creating a term (ind.n) distiguishing individuals nested within groups, but now I'm not sure how to create the full and reduced model given that I have one more level than the example.\n\nI've tried a really elaborate full model (m1) with the interaction term of interest (Injection:Social) removed for the reduced model (m2), but I'm not sure this is correct based on our design.\n\nm1 <- model.matrix(~ Injection + Injection:ind.n + Injection:Social + Injection:Region + Social + Social:ind.n + Social:Region + Region, colData_filt)\nm2 <- model.matrix(~ Injection + Injection:ind.n + Injection:Region + Social + Social:ind.n + Social:Region + Region, colData_filt)\n\nI'm assuming this is wrong, but even if this was by some miracle the correct formulation, would there be a way to extract genes that explain the \"Injection:Social\" interaction term for separate brain regions?\n\nAs a work-around, I subsetted the data by region and ran three separate LRT analyses for each subset and compared the results. While this simplified the model to look like the first example above, I worry that we lose some power by ignoring the fact we have multiple brain region samples from single individuals across the dataset.\n\nAny guidance is much appreciated. Thanks in advance\n\n\nFrom what I can gather, you want to account for the effect of individual, nested within region. That is, you want to see after accounting for these, is there a consistent effect for Injection:Social across all conditions.\n\nSo you set up the model like this:\n\nm1 <- model.matrix(~ ind.n*Region + Injection + Social + Injection:Social,data=..)\n\nThe last term should be Injection:Region and you can just use the waldTest (default) in DESeq2 for this term.\n\nWhat does the terms do? ind.n*Region is the equivalent of ind.n + Region + ind.n:Region , and with this you effectively get an effect for every region in every individual.\n\nWhy don't we need the Injection:ind.n or Social:ind.n or Social:Region. These terms indicate the effect of Injection or Social can vary by individuals or regions. Most likely introducing too many parameters when you are interested in a common effect. Also you do not have the replicates or samples to distinguish this effect from region or other effects.\n\nSince you provided an example we can run DESeq2 and you can see how the results look like:\n\nmat = counts(makeExampleDESeqDataSet(n=1000,m=48))\ndds = DESeqDataSetFromMatrix(mat,df,~ ind.n*Region + Injection + Social + Injection:Social)\n\ndds = DESeq(dds)\n\n [1] \"Intercept\"            \"ind.n_S2_vs_S1\"       \"Region_NS_vs_HY\"     \n [4] \"Region_TN_vs_HY\"      \"Injection_S_vs_L\"     \"Social_KF_vs_ISO\"    \n [7] \"Social_KFC_vs_ISO\"    \"Social_NF_vs_ISO\"     \"ind.nS2.RegionNS\"    \n[10] \"ind.nS2.RegionTN\"     \"InjectionS.SocialKF\"  \"InjectionS.SocialKFC\"\n[13] \"InjectionS.SocialNF\" \n\nThe terms you need are \"InjectionS.SocialKF\",\"InjectionS.SocialKFC\", \"InjectionS.SocialNF\", and you can look at each of them:\n\nlog2 fold change (MLE): InjectionS.SocialNF \nWald test p-value: InjectionS.SocialNF \nDataFrame with 6 rows and 6 columns\n              baseMean     log2FoldChange             lfcSE               stat\n             <numeric>          <numeric>         <numeric>          <numeric>\ngene1  9.9811166787259   1.25304112986447 0.819806376919295   1.52845984752303\ngene2 30.3449455820337 0.0329442893152027 0.705199688255367 0.0467162562092241\ngene3 3.83223545055379    1.0281136369045  1.64095596190233  0.626533350543196\ngene4  11.232305747171  0.595738624408923   0.8243883031544  0.722643227868976\ngene5 6.70950627004097  0.756449993378065   1.0631622863378  0.711509430967263\ngene6 26.1431134888287 -0.854784518963918 0.625714541243558  -1.36609342219393\n                 pvalue              padj\n              <numeric>         <numeric>\ngene1 0.126398405431826 0.978671002658464\ngene2 0.962739373909937 0.999897888026606\ngene3 0.530965168963838 0.978671002658464\ngene4 0.469899103018657 0.978671002658464\ngene5 0.476768608734069 0.978671002658464\ngene6 0.171909642630577 0.978671002658464\n\nAs mentioned, you can do a LRT if you want to test all the Injection:Social term interactions terms at one go, that is, the null hypothesis is that all of them are zero:\n\ndds = nbinomLRT(dds,reduced=~ ind.n*Region + Injection + Social)\n\nUsually the individual terms are more intuitively than testing all of them are zero, but you might have a special need for this.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Thank you, I will try this soon. Just to clarify, an LRT would still be appropriate for the larger question of finding the effect of the \"Injection:Social\" term and you suggest Wald for determining the region-specific impacts? Would it also be valid include a term like \"Injection:Social:Region\" in the suggested Wald model formulation in an attempt to explore the interactive effects of \"Injection:Social\" by region, or would that require more 3-way interaction terms with \"ind.n\"? $\\endgroup$ \u2013\u00a0jfaberha Jun 23 at 17:30\n  \u2022 1\n    $\\begingroup$ @jfaberha, thanks for providing the data, i have updated my answer, hopefully its clearer now. You can include \"Injection:Social:Region\" only if you include Region:Social. My point is this, do you think there is such an effect? $\\endgroup$ \u2013\u00a0StupidWolf Jun 23 at 18:41\n  \u2022 1\n    $\\begingroup$ I would visualize this with a pca or correlation matrix to see where the effects are coming from before applying them onto the model. No need to have a super complicated model... $\\endgroup$ \u2013\u00a0StupidWolf Jun 23 at 18:42\n  \u2022 $\\begingroup$ To answer your question regarding the \"Injection:Social:Region\" term, I will do some more research to see if this has an appreciable effect in the dataset. One question posed by the PI of this study is - what are the genes responsive to the \"Injection:Social\" interaction term in each of the different brain regions and are they different? I was guessing that maybe a 3-way interaction term could address this in the binomial Wald analysis, but I agree that adds excessive complexity to the model. That's said, I'm not sure how to get region-specific interactions without running separate analyses. $\\endgroup$ \u2013\u00a0jfaberha Jun 23 at 19:49\n  \u2022 1\n    $\\begingroup$ The main question is regarding the Injection:Social term across the dataset, with the brain region-specific interactions being less important follow-up. That said, I will move forward with LRT for the primary question and separate analyses for the region-specific analyses. Thank you for all the help! $\\endgroup$ \u2013\u00a0jfaberha Jun 23 at 20:37\n\nYour Answer"}
{"text": "Retrieved from https://au.mathworks.com/help/pde/ug/deflection-of-a-piezoelectric-actuator.html\nText:\nDeflection of Piezoelectric Actuator\n\nThis example shows how to solve a coupled elasticity-electrostatics problem.\n\nPiezoelectric materials deform under an applied voltage. Conversely, deforming a piezoelectric material produces a voltage. Therefore, analysis of a piezoelectric part requires the solution of a set of coupled partial differential equations with deflections and electrical potential as dependent variables.\n\nIn this example, the model is a two-layer cantilever beam, with both layers made of the same polyvinylidene fluoride (PVDF) material. The polarization direction points down (negative y-direction) in the top layer and points up in the bottom layer. The typical length to thickness ratio is 100. When you apply a voltage between the lower and upper surfaces of the beam, the beam deflects in the y-direction because one layer shortens and the other layer lengthens.\n\nThe equilibrium equations describe the elastic behavior of the solid:\n\n\nHere, \u03c3 is the stress tensor, and f is the body force vector. Gauss's Law describes the electrostatic behavior of the solid:\n\n\nD is the electric displacement, and \u03c1 is the distributed free charge. Combine these two PDE systems into this single system:\n\n\nFor a 2-D analysis, \u03c3 has the components \u03c311,\u03c322, and \u03c312=\u03c321, and D has the components D1 and D2.\n\nThe constitutive equations for the material define the stress tensor and electric displacement vector in terms of the strain tensor and electric field. For a 2-D analysis of an orthotropic piezoelectric material under plane stress conditions, you can write these equations as\n\n\nCij are the elastic coefficients, Ei are the electrical permittivities, and eij are the piezoelectric stress coefficients. The piezoelectric stress coefficients in these equations conform to conventional notation in piezoelectric materials where the z-direction (the third direction) aligns with the \"poled\" direction of the material. For the 2-D analysis, align the \"poled\" direction with the y-axis. Write the strain vector in terms of the x-displacement u and y-displacement v:\n\n\nWrite the electric field in terms of the electrical potential \u03d5:\n\n\nYou can substitute the strain-displacement equations and electric field equations into the constitutive equations and get a system of equations for the stresses and electrical displacements in terms of displacement and electrical potential derivatives. Substituting the resulting equations into the PDE system equations yields a system of equations that involve the divergence of the displacement and electrical potential derivatives. As the next step, arrange these equations to match the form required by the toolbox.\n\nPartial Differential Equation Toolbox\u2122 requires a system of elliptic equations to be expressed in a vector form:\n\n\nor in a tensor form:\n\n\nwhere repeated indices imply summation. For the 2-D piezoelectric system in this example, the system vector u is\n\n\nThis is an N=3 system. The gradient of u is\n\n\nFor details on specifying the coefficients in the format required by the toolbox, see:\n\nThe c coefficient in this example is a tensor. You can represent it as a 3-by-3 matrix of 2-by-2 blocks:\n\n\nTo map terms of constitutive equations to the form required by the toolbox, write the c tensor and the solution gradient in this form:\n\n\nFrom this equation, you can map the traditional constitutive coefficients to the form required for the c matrix. The minus sign in the equations for the electric field is incorporated into the c matrix to match the toolbox's convention.\n\n\nBeam Geometry\n\nCreate a PDE model. The equations of linear elasticity have three components, so the model must have three equations.\n\nmodel = createpde(3);\n\nCreate the geometry and include it in the model.\n\nL = 100e-3; % Beam length in meters\nH = 1e-3; % Overall height of the beam\nH2 = H/2; % Height of each layer in meters\n\ntopLayer = [3 4 0 L L 0 0 0 H2 H2];\nbottomLayer = [3 4 0 L L 0 -H2 -H2 0 0];\ngdm = [topLayer;bottomLayer]';\ng = decsg(gdm,'R1+R2',['R1';'R2']');\n\n\nPlot the geometry with the face and edge labels.\n\nxlabel('X-coordinate, meters')\nylabel('Y-coordinate, meters')\naxis square\n\nMaterial Properties\n\nSpecify the material properties of the beam layers. The material in both layers is polyvinylidene fluoride (PVDF), a thermoplastic polymer with piezoelectric behavior.\n\nE = 2.0e9; % Elastic modulus, N/m^2\nNU = 0.29; % Poisson's ratio\nG = 0.775e9; % Shear modulus, N/m^2\nd31 = 2.2e-11; % Piezoelectric strain coefficients, C/N\nd33 = -3.0e-11;\n\nSpecify relative electrical permittivity of the material at constant stress.\n\nrelPermittivity = 12;\n\nSpecify the electrical permittivity of vacuum.\n\npermittivityFreeSpace = 8.854187817620e-12; % F/m\nC11 = E/(1 - NU^2); \nC12 = NU*C11;\nc2d = [C11 C12 0; C12 C11 0; 0 0 G];\npzeD = [0 d31; 0 d33; 0 0];\n\nSpecify the piezoelectric stress coefficients.\n\npzeE = c2d*pzeD;\nD_const_stress = [relPermittivity 0; 0 relPermittivity]*permittivityFreeSpace;\n\nConvert the dielectric matrix from constant stress to constant strain.\n\nD_const_strain = D_const_stress - pzeD'*pzeE;\n\nYou can view the 21 coefficients as a 3-by-3 matrix of 2-by-2 blocks. The cij matrices are the 2-by-2 blocks in the upper triangle of this matrix.\n\nc11 = [c2d(1,1) c2d(1,3) c2d(3,3)];\nc12 = [c2d(1,3) c2d(1,2); c2d(3,3) c2d(2,3)];\nc22 = [c2d(3,3) c2d(2,3) c2d(2,2)];\nc13 = [pzeE(1,1) pzeE(1,2); pzeE(3,1) pzeE(3,2)];\nc23 = [pzeE(3,1) pzeE(3,2); pzeE(2,1) pzeE(2,2)];\nc33 = [D_const_strain(1,1) D_const_strain(2,1) D_const_strain(2,2)];\nctop = [c11(:); c12(:); c22(:); -c13(:); -c23(:); -c33(:)];\ncbot = [c11(:); c12(:); c22(:);  c13(:);  c23(:); -c33(:)];\n\nf = [0 0 0]';\n\nBoundary Conditions\n\nSet the voltage (solution component 3) on the top of the beam (edge 1) to 100 volts.\n\nvoltTop = applyBoundaryCondition(model,'mixed','Edge',1,...\n\nSpecify that the bottom of the beam (edge 2) is grounded by setting the voltage to 0.\n\nvoltBot = applyBoundaryCondition(model,'mixed','Edge',2,...\n\nSpecify that the left side (edges 6 and 7) is clamped by setting the x- and y-displacements (solution components 1 and 2) to 0.\n\nclampLeft = applyBoundaryCondition(model,'mixed','Edge',6:7,...\n                                                 'u',[0 0],...\n\nThe stress and charge on the right side of the beam are zero. Accordingly, use the default boundary condition for edges 3 and 4.\n\nFinite Element and Analytical Solutions\n\nGenerate a mesh and solve the model.\n\nmsh = generateMesh(model,'Hmax',5e-4);\nresult = solvepde(model)\nresult = \n  StationaryResults with properties:\n\n    NodalSolution: [3605x3 double]\n       XGradients: [3605x3 double]\n       YGradients: [3605x3 double]\n       ZGradients: [0x3 double]\n             Mesh: [1x1 FEMesh]\n\nAccess the solution at the nodal locations.The first column contains the x-deflection. The second column contains the y-deflection. The third column contains the electrical potential.\n\nrs = result.NodalSolution;\n\nFind the minimum y-deflection.\n\nfeTipDeflection = min(rs(:,2));\nfprintf('Finite element tip deflection is: %12.4e\\n',feTipDeflection);\nFinite element tip deflection is:  -3.2900e-05\n\nCompare this result with the known analytical solution.\n\ntipDeflection = -3*d31*100*L^2/(8*H2^2);\nfprintf('Analytical tip deflection is: %12.4e\\n',tipDeflection);\nAnalytical tip deflection is:  -3.3000e-05\n\nPlot the deflecton components and the electrical potential.\n\nvarsToPlot = char('X-Deflection, meters', ...\n                  'Y-Deflection, meters', ...\n                  'Electrical Potential, Volts');\nfor i = 1:size(varsToPlot,1)\n  % scale the axes to make it easier to view the contours\n  axis([0, L, -4*H2, 4*H2])\n  xlabel('X-Coordinate, meters')\n  ylabel('Y-Coordinate, meters')\n  axis square\n\n\n  1. Hwang, Woo-Seok, and Hyun Chul Park. \"Finite Element Modeling of Piezoelectric Sensors and Actuators.\" AIAA Journal 31, no.5 (May 1993): 930-937.\n\n  2. Pieford, V. \"Finite Element Modeling of Piezoelectric Active Structures.\" PhD diss., Universite Libre De Bruxelles, 2001."}
{"text": "Retrieved from https://mathoverflow.net/questions/299434/congruences-ramanujan-style\nText:\nLet $t\\in\\Bbb{N}$ and consider the sequences $p_t(n)$ defined by $$\\sum_{n\\geq0}p_t(n)x^n=\\prod_{i\\geq1}\\frac1{(1-x^i)^t}=(x;x)_{\\infty}^{-t}.$$ The numbers $p_t(n)$ can be regarded as enumerating partitions of $n$ into parts that come with $t$ colors. Furthermore, $p_t(n)=\\sum_{\\lambda\\vdash n}\\prod_{j\\geq1}\\binom{k_j+t-1}{t-1}$ where $\\lambda=1^{k_1}2^{k_2}\\cdots$ and each $k_j\\geq0$. Note also that $p_1(n)=p(n)$ is the usual number of (unrestricted) integer partitions of $n$. Ramanujan's famous congruences state $$\\begin{cases} p(5n+4)\\equiv0\\mod 5, \\\\ p(7n+5)\\equiv0\\mod 7, \\\\ p(11n+6)\\equiv0\\mod 11. \\end{cases}$$\n\nIn the same spirit, the following appear to be true. Are they? $$\\begin{cases} p_t(5n+4)\\equiv0\\mod 5, \\qquad t\\equiv0,1,2,4\\mod 5 \\\\ \\,p_t(7n+5)\\equiv0\\mod 7, \\qquad \\,\\,t\\equiv0,1,4 \\,\\,\\,\\, \\mod 7\\\\ p_t(11n+6)\\equiv0\\mod 11, \\qquad t\\equiv0,1,10\\mod 11. \\end{cases}$$\n\n  \u2022 1\n    $\\begingroup$ Nice. You could add the \"generating-functions\" and the \"ramanujan\" tag. $\\endgroup$ \u2013\u00a0Wolfgang May 4 '18 at 19:00\n  \u2022 2\n    $\\begingroup$ The cases $t=0,1 \\mod p$ ($p=5,7,11$) follow from finite field arithmetic. Indeed, denoting the generating function of $p_1$ by f, we have: $f^{pn_1 + n_0} (x) = f(x^ {p})^{n_1} f(x)^{n_0} \\mod p$ for any prime p and $n_0<p$. By comparing coefficients, $p_{p n_1 + n_0}(p m_1 + m_0) = \\sum_{i=0}^{m_1} p_{n_1}(i)* p_{n_0}(p(m_1 -i)+ m_0) \\mod p$ for $m_0 < p$. In the case of $p=5$ for instance, we may take $n_0=1, m_0=4$ and use Ramamujan's congruences to obtain your result for t=1. For t=0 it is even easier, as it corresponds to $n_0 = 0$, and $p_{0}(j)$ is indicator of 0. $\\endgroup$ \u2013\u00a0Ofir Gorodetsky May 4 '18 at 20:47\n  \u2022 2\n    $\\begingroup$ See also: (Freeman) Dyson's crank. It's a great story. $\\endgroup$ \u2013\u00a0shreevatsa May 5 '18 at 4:49\n\nMore general versions of this have been established: see in particular Theorem 2 of Kiming and Olsson, and for other work see (for example) Locus and Wagner.\n\nTo answer the question fully, as Ofir Gorodetsky observed the problem is trivial when $t$ is $0$ or $1$ modulo the prime modulus. The other cases correspond to $t \\equiv \\ell-1$ or $t\\equiv \\ell-3$ modulo $\\ell$ (with $\\ell$ being $5$, $7$, or $11$). These cases are the \"non-exceptional congruences\" covered by Theorem 2 of the paper by Kiming and Olsson (and the argument there is essentially elementary following easily from Euler's pentagonal number theorem in the case of $\\ell-1$, and an identity of Jacobi in the case of $\\ell-3$). The real interest is in the situation of exceptional congruences, and Theorem 4 of Kiming and Olsson gives some examples of these. For instance, if $t\\equiv 3 \\mod 11$ then $$ p_{t}(11n+7) \\equiv 0 \\pmod{11}. $$\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ I appreciate the details $\\endgroup$ \u2013\u00a0T. Amdeberhan May 5 '18 at 13:47\n\nYour Answer"}
{"text": "Retrieved from https://gaurish4math.wordpress.com/tag/infinte-descent/\nText:\nTag Archives: infinte descent\n\nA Curious Investigation\n\n\nAs I always say:\n\nMathematicians are those weird beasts who enjoy being surrounded by problems.\n\nMy current field of interest is Diophantine Equations (DE). Those who ever studied Number theory know about the classic\u00a0Pythagorean Triplets,\u00a0 equivalent to finding possible integer solutions of x^2+y^2 = z^2.\n\nAlso, it is a standard exercise (involving Method of Infinite Descent)\u00a0in DE to prove \u00a0thatx^2+y^2 = 3 z^2 has no integer solutions. But in this blog post I intend \u00a0to discuss following sibling of such degree two DE:\n\nSolve x^2+y^2 = 2z^2 for integers.\n\nClearly, z\\neq 0, I can divide whole equation by z^2 and denote, X=x/z and Y=y/z to get:\n\nSolve\u00a0X^2+Y^2 = 2 for rational numbers.\n\nObserve that (1,1) is a solution of given equation, then any other\u00a0solution (a,b) will lie with (1,1) on a line with rational slope (or\u00a0infinite slope, a vertical line, trivial case).\u00a0Furthermore, every line through (1,1) with rational slope will intersect with the quadratic curve in exactly two points. Because every quadratic equation has either no solutions or two real solutions, and\u00a0we already know that (1,1) is one solution.\n\nTo find all solutions, we first look at the vertical line case by\u00a0substituting X=1 \u00a0and seeing what two solutions you get. \u00a0One will be Y=1,\u00a0and the other gives a solution (which is the same solution in this case). Next, we take a line with rational slope m through (1,1), so that (using slope-intercept form):\n\n\nNow solve this line \u00a0and given curve X^2+Y^2 = 2\u00a0(which is circle of radius\u00a0\\sqrt{2} ). We will get:\n\nX = \\frac{m^2-2m -1}{m^2+1}\n\n\nWhere, m \\in \\mathbb{Q}, thus like x^2+y^2=z^2, x^2+y^2 = 2z^2 has infinite integer solution.\n\nEnding note:\n\nx^2+y^2 = 2 has only 4 integer solutions."}
{"text": "Retrieved from https://blog.paulhankin.net/tags/mathematics/\nText:\nTag: Mathematics\n\n\n16 June 2019 / Paul Hankin / programming\n\nComputing large integer powers modulo some number is a somewhat common operation. For example, it's used in RSA encryption. Usually, this is done using exponentiation by squaring, but this go program correctly prints the results of \\(n^{2^{64}}\\ (\\mathrm{mod}\\ 115763)\\) for \\(n\\) from 1 to 20, seemingly naively:\n\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tfor n := 1; n <= 20; n++ {\n\t\tresult := 1\n\t\tfor i := 0; i < 2^64; i++ {\n\t\t\tresult = (result * n) % 115763\n\t\tfmt.Printf(\"pow(%d, pow(2, 64)) mod 115763 = %d\\n\", n, result)\n\nIt runs, unoptimized, in a few milliseconds on my desktop. You can run it yourself online using the go playground. Feel free to edit the code a little before running it to convince yourself it's not just fast because the playground is caching the results or something.\n\nHow can it be that fast? Is go's optimizing compiler that clever? It's not, and there's a trick in the code. Can you see it?\n\n14 June 2019 / Paul Hankin / programming\n21 May 2015 / Paul Hankin / game theory / computer science\n\nThis blog post looks at closed-hand Chinese Poker, and describes a near-optimal strategy for it which is readily implementable on a computer."}
{"text": "Retrieved from https://economics.stackexchange.com/questions/17208/slutsky-decomposition-of-given-labor-supply-model\nText:\nLet utility curve an individual given as $U(C,R) = C^aR^{1-a}$ where $(0\\lt a \\lt 1)$ and $C$ denotes consumption commodity and $R$ denotes its leisure, and price of $C$ is given as $P$, and the nominal wage for a unit of labor given as $W$. Total amount time available for the individual is $T$.\n\nNow I would like to derive the change of labor supply when nominal wage get increased with two different effect decomposed - income effect/substitution effect.\n\nWhat I have got is $L^s$ only, which is equal to $T-R$, following below process:\n\nfirst, $P\\cdot C = L^s\\cdot W $\n\nsecond, $T-R = L^s$\n\nby, first and second, $P\\cdot C= (T-R)\\cdot W$ (*)\n\nand the from the utility function we can derive the condition of maxmizing its utility, $MU_C = MU_R$, which is eqaul to $\\frac{a}{1-a}=\\frac{C}{R}$(**)\n\nNow, since the (*), (**) must hold at the same time, we can derive equation between $W$ and $R$ without $C$ as below:\n\n$P\\cdot \\frac{a}{1-a}\\cdot R = (T-R)\\cdot W$\n\nThen we get $R = \\frac{TW}{P(\\frac{a}{1-a})+W}$ and $L^s =T\\frac{P(\\frac{a}{1-a})}{P(\\frac{a}{1-a})+W}$\n\nbut my derivation of $L^s$ looks only decreasing while W is increasing.\n\nAny points did I do wrong? I want to did some decomposition of Slutsky, but lack of skills to deal with partial derivatives, it makes me hard to do also.\n\n\nIn this static model with no savings/intertemporal aspect, labor supply does not depend on the wage. Using the equality relations, we can maximize over $L^s$ without constraints\n\n$$\\max_{L^s} U = \\left(\\frac{L^s\\cdot W}{P}\\right)^a\\cdot (T-L^s)^{1-a}$$\n\n$$\\frac {\\partial U}{\\partial L^s} = \\frac a{L^s}\\cdot U - \\frac {1-a}{T-L^s}\\cdot U$$\n\nand setting this equal to zero we get the optimal $L^s$\n\n$$\\frac a{L^s}= \\frac {1-a}{T-L^s} \\implies L^s = aT$$\n\nOne can verify that, at the optimum, the second derivative of the Utility function is negative so we do have a maximum.\n\n| improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/443941/two-server-powersupplies-in-a-row-dangerous\nText:\nI have two server PSUs from HP which can output 12V with 1200W (HP DPS 1200.) My goal is to obtain 24V by chaining the outputs of the two units.\n\nI have modified one of the PSUs so that the negative output is no longer connected to earth by replacing one of the case screws with a nylon one, as recommended by threads in RC forums, where users use those supplies to power their battery chargers.\n\nThe metal case of both supplies is still grounded, so the only concern should be high voltages on the 24V output of the combined unit if something goes wrong inside the PSU.\n\nOne guy in these forums was concerned about the over voltage protection no longer working if this modification is done.\n\nI want to know if such a modification disables safety features in events where the transformer is defective and shorts mains voltage to the low voltage side and if the order in which the supplies get connected changes this behavior.\n\n(negative/earth side of the unmodified unit to 12v of the floating unit)\n\n  \u2022 \\$\\begingroup\\$ There is nothing called voltage. It is always voltage difference. If the PSU never sees a greater voltage difference on its output than it is rated for, you have nothing to worry. You may have to add a diode for reverse voltage though, in case the load shorts. \\$\\endgroup\\$ \u2013\u00a0Indraneel Jun 17 '19 at 2:49\n  \u2022 \\$\\begingroup\\$ Verify that 0V actually is disconnected from mains earth before connecting them in series. Put the multimeter in beep mode and poke the metal chassis right near the heatsinks and such to make sure there are no paths to earth remaining. \\$\\endgroup\\$ \u2013\u00a0Oskar Skog Jun 17 '19 at 3:18\n  \u2022 \\$\\begingroup\\$ @Oscar Skog, I have verified that the resistance between earth and the 0v output is now in the MOhms range... \\$\\endgroup\\$ \u2013\u00a0Beny Benz Jun 17 '19 at 9:02\n\nQuestion: Does this modification disable safety features?\n\nNO. Not if done exactly as stated.\n\nIt enables a status resistor loop to enable the supply and only removes the secondary earth bond and not the primary AC safety ground to enable series DC connection of 12+12=24V @ 75A (850W at 120Vac, 1200W out at 230Vac rating high efficiency) making the two supplies unique with an unmodified one = Earth gnd = V- = 0V and modified one 12Vout to V- to 24V=V+. with AWG 8 or heavier cable. You can choose an external fuse for the charger cables you select if undersized. ( e.g. or use welding cable)\n\nI understand all the safety requirements and fundamentals of this category of designs and none of the safety features are bypassed or disabled in the article link below. However, any modifications are not permitted for resale, but ok for personal use.\n\nI assume this is the one you have read, (because it is written by a professional and popular with hobbyists. )\n\nBut if you make any mistakes with your fingers touching charged HVDC contact points inside, this is your doing. -48V PSU's are normally designed with an earth ground jumper option for V+ or V- earthing. But for Server communication V- is always earth grounded for noise immunity. Short, #8 or bigger solid or stranded welding wire for interconnect cables are necessary to prevent short circuit wire fire. Your application load needs some kind of soft start switch to prevent overcurrent trips then a bypass series load for high current. How you regulate your battery charger with a BMS is outside the scope of this question.\n\nDO NOT attempt anything described herein without ensuring that you have taken all the necessary precautions to safeguard yourself and others from injury.\n\n|improve this answer|||||\n  \u2022 1\n    \\$\\begingroup\\$ Whoever downvoted , please show some courtesy to explain why \\$\\endgroup\\$ \u2013\u00a0Tony Stewart Sunnyskyguy EE75 Jun 17 '19 at 3:04\n\nYour Answer"}
{"text": "Retrieved from https://www.khanacademy.org/math/math-for-fun-and-glory/puzzles/brain-teasers/v/brain-teaser-blue-forehead-room\nText:\nMain content\nCurrent time:0:00Total duration:7:25\n\nBlue forehead room brain\u00a0teaser\n\nVideo transcript\n\nThere's a new reality television program, and it's called the Blue-- I should probably write it in blue-- but it's called the Blue Forehead Room. And what they do in this reality television program-- and you'll have to bear with me, because the show probably wouldn't be that interesting to watch-- but it's interesting to predict what happens. What they do is, they take a room. They'll call it the blue forehead room. And let's see, that's kind of a top view of the room. And let's say there's a door here. None of this is relevant to the actual problem. This is the door, right there. And what they do is they get 100 perfect logicians to sit in this room, in a circle. So they're all sitting in a circle in this room. Now, before the game even starts, before they even enter the room the first time, the logicians are told two things. They're told, One: that at least one of you has your forehead painted blue. At least one of you has your forehead-- And they all get their foreheads painted, so that obviously if you're the only guy who has your forehead painted. But you just don't know what color it is. So all of them have different color foreheads. Or, we don't know. But all they're told is, obviously I've painted your forehead. At least one of the people in the room that you will enter will have their forehead painted blue. And then they're also told that as soon as you deduce that your forehead is blue, you need to leave the room. And what's going to happen is-- and it's very important that I set this up properly. They're all outside of the room. No-one's inside the room. And let's say they're blindfolded. And while they're blindfolded, they essentially have the thing painted onto their forehead. So they can't see the paintbrush or anything. So they really don't know what's on their forehead. And then after that, they all enter the room. And they all sit in a circle like this, so that they can all look at each other. And let's say when they enter, the lights are off. So the lights are off, and then the protocol is that the lights will be turned on, and then they can all look around at each other. There's no reflective surfaces. They can't look into each other's eyes and try to see the reflection. No tricks like that. There are no mirrors in this room. Nothing like that. All they can do is look at each other. So, just as an example, let's say that this is me right here. As soon as the lights get turned on the first time, I'll be able to look at all the other people in the room. And I could see, it'll be pretty obvious to me if anyone has a blue forehead. Maybe that guy has one, that guy doesn't. I don't know, right? And I can see them. I can't see my own forehead. And what happens is, then they will turn off the lights, and the way they're going to do it is you have to leave the room after you have realized that you have a blue forehead. So for example, let's say I enter into the room, and because I'm a perfect logician I see things that allow me to perfectly deduce that I have a blue forehead. Then what they're going to do is they're going to turn off the lights again. And then, if I know that I have a blue forehead while the lights are turned off, I would leave the room. And then when they turn the lights back on, I'd be gone. So there would be no Sal here. So let's say there were 100 before, then there would be 99 guys sitting in the room. Right? As soon as I realize I have a blue forehead, when the lights get turned off, I leave. And just remember these are perfect logicians. So everyone in the room. And not only are they all perfect logicians, but they all know that everyone else is a perfect logician. So, everyone is also told, and this is true, everyone is a perfect logician. Which means they have infallible powers of logic. So my question to you-- Just remember, I have each of these perfect logicians. We set them up outside of the room, paint their foreheads. They're blindfolded. They have no clue. Then we have all of them walk into a dark room, sit in a circle like this. And then what we tell them is, as soon as you realize that you have a blue forehead, as soon as you have a blue forehead, you have to leave the room. Now my question to you is, let's say that we've actually painted everybody's forehead blue. What happens? So remember, this is what we've told each of the people. Right? As soon as you realize your forehead is blue, you leave the room. And now I've just asked you, the producers like to really play with these logicians. They've actually painted everybody's forehead blue. So when everyone goes in the room the first time, what's going to happen? Let's say I'm one of the logicians. This is me right here. As soon as I open my eyes, I'm going to see 99 other fellow logicians with blue foreheads. And then, maybe I can somehow deduce something about my own. I don't think you can. And the lights will go off. And then if I haven't deduced anything about my own blueness of my forehead, then they'll turn the lights back on. And then maybe some other guy will have left. I don't know. Or maybe not. And then I'll see the same 99 guys again. And that'll just keep occurring until something happens. And my question to you is what happens? When? And why? I'm thinking whether I should give you a hint right now. Well let me tell it to you this way. That's the problem. You should be able to solve it. And just so you know where this came from, if I remember correctly I think this was on a computer science exam I had at MIT. So just so you know, this isn't just for fun. I don't want to go into all of the applications that this type of problem can apply to, because that by itself would be a bit of a hint. So if you don't want a hint, turn off the video now or pause it. If you do want a hint, I'm about to give it to you. So my hint is-- and remember turn this off if you don't want to hint-- but the hint is what happens when there are less than 100 people. So I gave the situation where we have 100 logicians. But this problem is actually a lot easier if you try it with a smaller number. Anyway I'll see you in the solution video."}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/32070/auto-delete-parent-window-when-deleting-any-child/32107\nText:\nI understand that when a window is split, the original window and the new window become children under a new \"parent window\".\n\nI would like the option to somehow register these windows such that when either child window is deleted, the other child and the parent are also automatically deleted.\n\nHere's why I want this ...\n\nI'm using a complicated 3rd-party package that has a number of ways to create buffers and windows. Under certain isolated conditions (usually during a conditional operation within a hook function), I split certain windows.\n\nIf I use the standard facilities of this package to delete the original window (which is now one of the two children), the other, newly created child window remains.\n\nI know that I can write code to determine the parent of a window being deleted and to write more code to delete its parent and sibling windows. However, this involves manually modifying functions within this complicated 3rd-party package, and I'd like to avoid this.\n\nIdeally, I'd like to somehow register the children and the parent at the time that the window is initially split, so that whenever one of the three windows is deleted, the other two are also automatically deleted. This way, when the existing 3rd-party code deletes the original window as part of its normal processing, the parent and the other child will also automatically be deleted.\n\nI have not been able to find any such facility in emacs nor in any searches. Does such a thing exist, by any chance?\n\nOne idea which occurs to me is to write wrapper functions for delete-window and split-window and install them via emacs' advice mechanism. But is there perhaps another mechanism for my desired functionality which might already exist?\n\nThank you very much for any suggestions.\n\nNOTE: In digging through the emacs source code, I notice something called an \"atomic window\" or an \"atom window\". I can't find many docs for this, but it seems like it might give me what I want. For example, look at the final paragraph of the doc string for delete-window ...\n\n(delete-window &optional WINDOW)\n\nDelete WINDOW. WINDOW must be a valid window and defaults to the selected one. Return nil.\n\nIf the variable \u2018ignore-window-parameters\u2019 is non-nil or the \u2018delete-window\u2019 parameter of WINDOW equals t, do not process any parameters of WINDOW. Otherwise, if the \u2018delete-window\u2019 parameter of WINDOW specifies a function, call that function with WINDOW as its sole argument and return the value returned by that function.\n\nOtherwise, if WINDOW is part of an atomic window, call \u2018delete-window\u2019 with the root of the atomic window as its argument. Signal an error if WINDOW is either the only window on its frame, the last non-side window, or part of an atomic window that is its frame\u2019s root window.\n\n... and here's the doc string for a function I found called display-buffer-in-atom-window ...\n\n(display-buffer-in-atom-window BUFFER ALIST)\n\nDisplay BUFFER in an atomic window. This function displays BUFFER in a new window that will be combined with an existing window to form an atomic window. If the existing window is already part of an atomic window, add the new window to that atomic window. Operations like \u2018split-window\u2019 or \u2018delete-window\u2019, when applied to a constituent of an atomic window, are applied atomically to the root of that atomic window.\n\nALIST is an association list of symbols and values. The following symbols can be used.\n\n\u2018window\u2019 specifies the existing window the new window shall be\ncombined with. Use \u2018window-atom-root\u2019 to make the new window a\nsibling of an atomic window\u2019s root. If an internal window is\nspecified here, all children of that window become part of the\natomic window too. If no window is specified, the new window\nbecomes a sibling of the selected window. By default, the\n\u2018window-atom\u2019 parameter of the existing window is set to \u2018main\u2019\nprovided it is live and was not set before.\n\n\u2018side\u2019 denotes the side of the existing window where the new window shall be located. Valid values are \u2018below\u2019, \u2018right\u2019, \u2018above\u2019 and \u2018left\u2019. The default is \u2018below\u2019. By default, the \u2018window-atom\u2019 parameter of the new window is set to this value.\n\nThe return value is the new window, nil when creating that window failed.\n\nI'll be investigating this atom(ic) window thing, and I'll report back.\n\n  \u2022 Instead of fiddling with core functions that every library relies upon, I would recommend you run a test when closing the selected-window for other windows containing a particular buffer and then delete those windows using the optional argument in delete-window. For example, you can set up the letter q to call your custom quit window function in the selected-window to handle deleting any other windows matching your specified criteria. You could get fancy and record prior windows in a variable or a window-config -- buffers inside windows can change . . . . \u2013\u00a0lawlist Apr 11 '17 at 16:57\n  \u2022 Thank you. Yes, I can do that, but it would involve re-writing parts of the 3rd-party package that I'm using, and I'm trying to avoid that. I don't delete the window \"manually\"; rather, the 3rd-party software deletes it during its own processing. That's why I'm thinking that I might have to override some core functions. But perhaps there are as-yet-undiscovered hooks within the 3rd-party package that I could use for this purpose. I'm continuing to investigate. \u2013\u00a0HippoMan Apr 12 '17 at 10:59\n  \u2022 I just discovered something in emacs called an \"atom window\" or an \"atomic window\" which might give me what I want. I added text to my question, above, discussing this. \u2013\u00a0HippoMan Apr 12 '17 at 11:23\n  \u2022 ... and atom(-ic) windows indeed do the trick! See my Answer. \u2013\u00a0HippoMan Apr 12 '17 at 13:44\n\nIt turns out that atom(ic) windows are indeed exactly what I want. Consider this code ...\n\n;; Instead of split-window, do this ...\n(let ((subwin (display-buffer-in-atom-window\n               `((window . ,(get-buffer-window (current-buffer)))\n                 (side . below)))))\n  (with-selected-window subwin\n    ;; do whatever you want with subwin\n\nWhen the original window is deleted via a generic call to (delete-window), the subwindow also gets deleted.\n\n| improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from http://www.mathpages.com/home/kmath300.htm\nText:\nTwo In the Shop\n\nSuppose we have 10 units in service, each with an MTBF (Mean Time \nBetween Failure) of 2,000 hours.  Each operates for 2 months per \nyear.  When one fails it is returned to the maintenance shop for \nrepair, and spends 1 week there.  What is the probability that\ntwo units will be in the maintenance shop at the same time for \n\nAssuming the MTBF is quoted in operational hours, the failure\ndistribution is exponential, and the \"2 months per year\" operational\ntime is spread evenly through the year (e.g., 4 hours per day), it\nfollows that the mean calender time between failures of a specific\nunit is 12,000 hours.  Also, a unit spends 168 hours (=1 week) in \nthe shop each time it fails.  Therefore, each unit has a mean duty\ncycle of 12168 hours, of which 12000 are spent in the field and 168\nare spent in the shop.\n\nThe periods in the shop are random and uncorrelated for each of the \n10 units.  The probability of any particular unit being in the shop \nat a randomly chosen instant is just p = 168/12168.  The probability\nof two specific units being in the shop at a random instant is p^2.\nIn general, the probability of exactly k out of 10 units being in the\nshop at a given instant is \n              Pr{k}  =   ----------  p^k (1-p)^(10-k)\n                         (10-k)! k!\n\nso the probability of finding exactly 2 units in the shop is 0.007675,\nwhereas the probability of TWO OR MORE in the shop is 0.007970.\n\nOf course, the above analysis makes several tacit assumptions, and in\nreality the probability could be significantly higher or lower, for \nany of several reasons.  For example, we didn't specify that all the\noperational periods were independent and uniformly distributed over\nthe year, so it's possible that all the units are operational for the \nsame 2-month period each year, which would increase the probability of\nhaving two in the shop at some point during the \"busy season\".  On the \nother hand, the real probability could also be much smaller.  Strictly \nspeaking, within the stated conditions of the original problem, the \nprobability of two or more units in the shop simultaneously could be \nanything from 0 to about 0.3874.  For example, if each unit operates \nfor EXACTLY 2000 hours between failures, we could stagger their repair \ncycles so that one fails every 200 hours, which is greater than the \none week repair time of 168 hours.  Thus, the probability of two in \nthe shop would be 0.  (One could also manipulate the probability by \nassuming the units operate in more or less mutually exclusive 2-month \nperiods during the year.)\n\nOn the other hand, if the units are operated in synchronized pairs\n(hopefully not two engines of a twin-engine airplane), and each fails\nevery 2000 hours exactly, then each pair is in the shop for 168 hours\nout of every 2168 hours, giving a probability of 0.0774.  If the five\npairs of units are staggerred, then the fraction of [active] time with\ntwo units in the shop would be 0.3874.\n\nIt might be interesting to figue out the maximum probability that\nwould be strictly consistent with the stated conditions of the\nproblem.  In many casually-stated probability problems it turns out\nthe answer can be anything on the interval from 0 to 1 (inclusive).\n\nReturn to MathPages Main Menu"}
{"text": "Retrieved from http://mathoverflow.net/questions/34988/maximum-number-of-distinct-diagonals-generated-by-permutations\nText:\nTake the 2-minute tour \u00d7\n\nGiven an n by $n$ matrix with $0$'s and $1$'s only, consider the $n!$ different permutations generated by permuting the rows, what is the maximum number of different diagonals generated?\n\nshare|improve this question\nIs the question for a general upper bound or an upper bound if I know the matrix? \u2013\u00a0 Daniel Krenn Aug 9 '10 at 11:09\nAs in, you can choose any n by n 0-1 matrix you want to maximize this number. \u2013\u00a0 Kamil Aug 9 '10 at 12:12\n\n1 Answer 1\n\nIf I am allowed to choose the matrix, it seems that I can generate all $2^n$ different diagonals.\n\nEdit. Sorry, this approach only generates $2^n -n $ diagonals.\n\nLet $I$ be the $n \\times n$ identity matrix and let $D$ be a diagonal whose non-zero entries are indexed by $S$.\n\nFurther suppose that $D$ does not have exactly one zero entry.\n\nLet $\\pi$ be a perumation of the rows of $I$ whose fixed points are exactly $S$. Then the diagonal of $\\pi(I)$ is $D$, and there are $2^n-n$ such diagonals.\n\nUpdate. Here is a proof that $2^n-n$ is in fact the best one can do.\n\nAn $n \\times n$ bipartite graph is a bipartite graph with bipartition $([n]_r, [n]_c)$, where $[n]_r$ and $[n]_c$ are both copies of $[n]$. Let $G$ be an $n \\times n$ bipartite graph. Define $G'$ to be equivalent to $G$, if $G'$ can be obtained from $G$ by complementing the neighbourhoods of some vertices in $[n_r]$. Note that the equivalence class of $G$, denoted $[G]$, has size $2^n$.\n\nIt is easy to check that the following lemma proves the tightness of the bound.\n\nLemma. For any $n \\times n$ bipartite graph $G$, at most $2^n-n$ members of $[G]$ have a perfect matching.\n\nProof. For each $i \\in [n]_c$ there is a graph $G^i \\in [G]$ such that $i \\in [n_c]$ has degree 0 in $G^i$. Just pick the vertices in $[n]_r$ that are adjacent to $i$ in $G$ and complement their neighbourhoods. If all $G^i$ are distinct, then the lemma clearly follows. Otherwise, $G^i=G^j$ for some $i \\neq j$. Thus, both $i$ and $j$ have degree 0 in $G^i$. But now, the $n$ graphs obtained from $G^i$ by performing a single complementation each do not have a perfect matching.\n\nshare|improve this answer\nThis seems to have a slight problem with the case of the configurations with exactly one zero. \u2013\u00a0 damiano Aug 9 '10 at 12:20\nNot with $n=3$ you can't :-) \u2013\u00a0 Robin Chapman Aug 9 '10 at 12:23\nI suppose that I cannot generate diagonals that have exactly $n-1$ ones in this way, since if I fix $n-1$ rows, then I automatically fix the last one. But it seems that I can still get $2^n-n$ diagonals. \u2013\u00a0 Tony Huynh Aug 9 '10 at 12:24\nA clever argument! One minor comment: I do not think that the current proof of the lemma deals with the case where more than one vertex in [n]_c have exactly the same set of neighbors, but it can be fixed easily. \u2013\u00a0 Tsuyoshi Ito Aug 10 '10 at 1:03\njust a minor remark, the same without graphs: if two rows (say i-th and j-th) are equal to $r$, then each diagonal has at least two coincidences with $r$ (coincidence means coincidence of one of $n$ coordinate functionals). So, there are at least $n$ forbidden diagonals. If all rows are different, then all their complements are forbidden and we again have $n$ forbidden diagonals. \u2013\u00a0 Fedor Petrov Aug 10 '10 at 12:17\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/57266.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nBlending Seed\n\nDate: 09/27/98 at 00:26:11\nFrom: Anonymous\nSubject: Grass seed problem\n\nHi!  Here is a problem that my father and I have been working on for \nhalf an hour:  \n\nA lawn-and-garden dealer wants to make a new blend of grass seed by \nusing 200 pounds of $0.45 per pound seed and some $0.65 per pound \nseed. How much of the $0.65 seed does the dealer need to make a $0.55 \nper pound blend?\n\nThank you so very much for your help. Hope to hear from you soon.\n\nDate: 09/27/98 at 01:22:14\nFrom: Doctor Ken\nSubject: Re: Grass seed problem\n\n\nFirst I'll give you a sort of intuition-based solution, and then I'll \ngo back and be a little more formal, writing things out in algebraic \n\nThe first thing I noticed about this problem was that a pound of one \nkind of seed costs 45 cents, a pound of the other costs 65 cents, and \nwe want to make a mix that costs 55 cents. Well, 55 is halfway between \n45 and 65, so it seems like we should combine equal parts of the two \nkinds of seed. Since we need to use 200 pounds of the first kind, we \nshould use 200 pounds of the other kind, for a total of 400 pounds.  \n\nTo verify this solution, let's see how much the pieces would cost.  \n200 pounds of the first kind of seed would cost 200 * $0.45 = $90, and \n200 pounds of the second kind of seed would cost 200 * $0.65 = $130.  \nWe bought 400 pounds total and paid $220, so we paid on average \n$220/400 = $0.55. Seems to check out.\n\nNow, how can we use algebra to find this same solution? The first \nthing I usually try to do is to find a sentence (an English sentence, \nor whatever language you like best) that says something true and \nuseful about the problem. Then I translate that sentence into an \nalgebraic equation.  \n\nIn this problem, I think I'd make this sentence: \"The cost per pound \nof the combined seed mixture is 55 cents.\" Let's work on translating \nthat into an equation. First it becomes:\n\n   cost per pound = $0.55\n\nWhat is the cost per pound? It's the number you get when you divide \nthe total price by the number of pounds of seed:\n\n     total price\n    pounds of seed\n\nThe total price is the cost of the 45c part and the 65c part. The \nnumber of pounds of seed is the number of pounds of the first kind \nplus the number of pounds of the second kind. The only unknown thing \nhere is the number of pounds of the second kind, so let's call that x.\n\n    200*$0.45 + x*$0.65\n         200 + x\n\nNow we've done the translation. I'll leave it to you to work out the \nsolution from here, and verify that the answer really is 200.\n\n- Doctor Ken, The Math Forum\nAssociated Topics:\nElementary Word Problems\nMiddle School Algebra\nMiddle School Word Problems\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/104426/an-pure-intriguing-counting-problem-of-index-sets\nText:\nTake the 2-minute tour \u00d7\n\nHi Guys. The problem here seems like a homework, but I think that it is not that easy.It comes from a theorem I recently proved.The content of the theorem is not important, the issue is that I have no idea how to counting the number of the index sets that satisfy the constraint the theorem restricted.\n\nTheorem: Suppose a sequence of integers has distinct $n^2+1$ numbers and have exactly t one monotone subsequence of length $n+1$,(Note Erdos Szekeres Theorem guarantees the existence of the unique subsequence.),the index set $C$ of the unique monotone subsequence of length n+1 must satisfy following properties.\n\n(Constraint of index set)\n\nLet $C_i$ denotes the $i$th element of the index set $C$ where $2 \\leq i \\leq n$.Then\n\n(0) $ C_1 < C_2 < \\dots < C_i < C_{n+1}$\n\n(1) $j< C_1 <(j-1)n+1$\n\n(2) $ij < C_i<(j-1)n+i+(i-2)(n-j)$\n\n(3) $ nj+1 < C_{n+1} < (j-1)n + n + 1 + (n-1)(n-j) $\n\nwhere $j$ is any integer for $1$ to $n$ .\n\n(End of the Constraint)\n\nThe meaning of the $j$ is that if the elements of $C$ satisfies the group of constraints above for any $j$, we say that it satisfies the constraints.\n\nEND of the theorem.\n\n\nHow many index sets C satisfy the constraint above are there?\n\nOr could someone provide an approximation of the numbers of qualified index set $C$s. Even the ration of the qualified index sets to the trivial bound $ { n^2 +1 \\choose n+1 }$ would be very desirable.\n\nIF you are reading this, thank you for you patient for at least arriving here. I would also thank for anyone that might suggest some people might know a method to the problem.\n\nshare|improve this question\nYour last constraint expression might be easier to grok if written as n^2+1-(n-j). Also, there have been a few questions asked on related matters recently on specialized combnations, which is what your sets appear to be. You might check those out. (Link to be provided later.) Gerhard \"Search Engines Stole My Memory\" Paseman, 2012.08.10 \u2013\u00a0 Gerhard Paseman Aug 10 '12 at 22:04\nHere is the first in a chain of links that might be of interest. mathoverflow.net/questions/104028/string-possible-combinations/\u2026 . My answer has a comment from me which contains the next link. My guess is that parking functions and Gessel-Viennot (somewhere after the third link) will be relevant to your problem. Gerhard \"Ring Around The Web References\" Paseman, 2012.08.10 \u2013\u00a0 Gerhard Paseman Aug 11 '12 at 2:12\nHi Gerhard. Thanks very much about your links.It seems that I need time to dig it out. \u2013\u00a0 WangYao Aug 11 '12 at 6:31\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/20942/brownian-bridge-under-observational-error?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $Z_t$ follows a simple discrete random walk $Z_t=Z_{t-1}+e_t$ , where $e_t$ are a bunch of uncorrelated normal variables with arbitrary variance sigma^2, and that there are observations of the series at t=a and t=b, with both observations having normal uncorrelated observational error with variance $O_a$ and $O_b$.\n\nHow can I find distribution for intermediate values between a and b?\n\nshare|improve this question\n\n1 Answer 1\n\nif you consider a Gaussian vector $V=(X,Y) \\in \\mathbb{R}^{d=m+n}$, you know how to find the conditional distribution of $X$ knowing the value of $Y=y$, right ? This is exactly the same thing here.\n\nFor example, let us suppose that $a=0, b=N+1$:\n\n  \u2022 you have a noisy observation $Y=(y_1, y_2)=(O_a, O_b)$ with know covariance matrix $\\Sigma_Y$\n  \u2022 the data you are looking for, $X=(z_1, \\ldots, z_N) \\in \\mathbb{R}^N$, have a known covariance matrix $\\Sigma_X$\n  \u2022 the covariance matrix $E[X Y^t] = \\Sigma_{X,Y}$ is also known.\n\nA quick way to find the conditional distribution of $X$ knowing $Y$ is to write $$X = AU + BV$$ $$Y=CU$$ where $U,V$ are independent standard Gaussian random variable of size $2$ and $N$ respectively, while $A \\in M_{N,2}(\\mathbb{R})$ and $B \\in M_{N,N}(\\mathbb{R})$ and $C \\in M_{2,2}(\\mathbb{R})$. Because\n\n  \u2022 $CC^t = \\Sigma_Y$ gives you $C=\\Sigma_y^{\\frac{1}{2}}$,\n  \u2022 $AC^t = \\Sigma_{X,Y}$ then gives you $A=\\Sigma_{X,Y}\\Sigma_y^{-\\frac{1}{2}}$,\n  \u2022 $AA^t + BB^t = \\Sigma_{X}$ then gives you $B=(\\Sigma_{X}-\\Sigma_{X,Y}\\Sigma_y^{-1}\\Sigma_{X,Y})^{\\frac{1}{2}}$,\n\nthe $3$ matrices are easily computable, and $C$ is invertible in the case you are considering. This shows that if you know that $Y=y$, the conditional law of $X | Y=y$ is given by $$X = AC^{-1}y + BV,$$ which is a Gaussian vector with mean $AC^{-1}y = \\Sigma_{X,Y}\\Sigma_y^{-1}y$ and covariance $BB^t = \\Sigma_{X}-\\Sigma_{X,Y}\\Sigma_y^{-1}\\Sigma_{X,Y}$\n\nshare|improve this answer\nI'm having trouble working through the notation, specifically the covariance matrix of Y (The covariance matrix of the sampling error? Or of the observations?). Could you elaborate the calculation for N=2? \u2013\u00a0 David Shor Apr 11 '10 at 11:12\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/32944/how-to-decide-convergence-of-the-ensemble-average-in-a-monte-carlo-process\nText:\nTell me more \u00d7\n\nI am simulating electromagnetic scattering off a rough surface. The usual process is to do a Monte Carlo simulation, which is briefly described as follows.\n\n  \u2022 Generate a randomly rough surface, and compute the scattered far-field intensity in a particular direction of interest.\n  \u2022 Repeat this process for several different instances of rough surfaces, and get an ensemble average of the far-field intensity.\n\nThis ensemble average converges after sufficient instances have been taken. So, my question is that how does one determine in a rigourous manner if convergence has happened? In the electromagnetic scattering community, this question is not addressed, and heuristic estimates are used (e.g. \"we used 100 instances\") instead.\n\nThanks apriori.\n\nshare|improve this question\nIn case you are not aware, there is a scientific computation site now in beta which may have a higher density of experts. I'm sure they would be happy to have this question (and it might be a better fit there than here), but (1) I won't migrate it unless you ask and (2) I don't think it is in any danger of being closed here. Your choice. \u2013\u00a0 dmckee Jul 27 '12 at 0:14\nThanks for the tip @dmckee, I will keep that group in mind for future questions. I've got one good answer here already, and I don't mind if you migrate it to the other group. \u2013\u00a0 UdX Jul 27 '12 at 17:39\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nIn this problem, you have a real valued quantity which has an unknown distribution, and you want to estimate the error on the average from averaging N independent draws. This is an application of the central limit theorem.\n\nIf you choose $N$ independent picks from a distribution $\\rho(x)$ with zero mean and finite second moment, meaning that\n\n$$ \\int x^2 \\rho(x) = \\sigma^2$$\n\nThen add the picks together to get $X$, you get that the sum is distributed as the $N$-fold convolution of $\\rho$ with itself. This eventually converges to a Gaussian of second moment $N\\sigma^2$. This means that the error in taking an average over $N$ steps is the width of the distribution of $X/N$, which is\n\n$$ {\\sqrt{N\\sigma^2}\\over N} = {\\sigma\\over \\sqrt{N}}$$\n\nIn other words, the error is Gaussian distributed with a width that falls off as the square root of the number of trials. Your error is the $\\sigma$ of the distribution divided by the square root of the number of trials.\n\nIf your trials give you $x_1,x_2,...,x_N$ for x, you calculate the mean of these, and call it x:\n\n$$ x = {\\sum_i x_i \\over N}$$\n\nThen calculate the average square of $(x_i-x)$ to get a best-estimator for $\\sigma$\n\n$$ \\sigma^2 = {\\sum_i (x_i - x)^2 \\over N} $$\n\nThen your error is $\\sigma/\\sqrt{N}$. This is the best estimate to make in your circumstances.\n\nThe one thing you have to check is the convergence to a Gaussian. This means that you make sure that the roughness model gives a distribution of intensities where the $sigma$ is not dominated by rare events, so that the estimate from N trials of $\\sigma$ is reliable. In principle, you could have a contrived rough surface model which produces ridiculous things on very rare occasions--- for example, suppose the roughness occasionally conspires over long distances to be a nearly exactly periodic sinusoid. This makes the surface a diffraction grating, with extremely sharp peaks at certain directions. If you are looking at the direction where the diffraction peak occurs, you get a huge outlier in the scattered intensity for a diffraction grating configuration, and this might occur in too few trials, so that the peak might never show up in your limited number of trials.\n\nIn practice, you just make sure your roughness model is not conspiratorial (so as to make periodic gratings) and for this it is usually enough (aside from contrived nonlocal roughness conspiracy) to check that the distribution of intensities doesn't have a power-law tail. You cannot do anything rigorous without a description of the roughness model, so that you can show that diffraction grating conspiracies don't happen with any reasonable probability, so that the second-moment is well described by what you see.\n\nThis is usually true, absent obvious tail phenomenon (for example, you see 2 trials out of 200 that dominate the variance) so doing a central limit theorem error analysis is good enough.\n\nshare|improve this answer\nThanks for the useful answer, @Ron. I do know the statistics of the rough surface, and can therefore be confident that there are no pathological surfaces in my ensemble. Just to be precise, what you mean by error is the standard deviation. PS: A small typo in your answer: the second moment of the sum is N \\sigma^2, not N \\sigma. \u2013\u00a0 UdX Jul 27 '12 at 20:35\nadd comment\n\nDo you have access to the standard deviation? If so, the coefficient of variation is a good measure of convergence: A generalisation is the root mean square deviation. Those wikipedia pages also tell you how to handle, to some extent, situations where the mean is close to zero.\n\nshare|improve this answer\nWell, since I have access to the intensity for each instance of a rough surface, I can generate all statistics, including the standard deviation. will fail for a zero-mean process, though. \u2013\u00a0 UdX Jul 27 '12 at 17:41\n@UdX I just updated the answer with some links that may be useful. Hope that helps. \u2013\u00a0 Gabriel Landi Jul 27 '12 at 23:13\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/40473/effective-theta-characteristics?sort=votes\nText:\nTell me more \u00d7\n\nLet $C$ be a complex smooth projective curve of genus $g$ and let $N$ be the number of effective theta-characteristics of $C$, or equivalently, the number of points of order two on the theta divisor of $J(C)$.\n\nIt is known that, if $C$ is generic, $N$ is the number of the odd theta characteristics. Mumford proves that on a principally polarized abelian variety the theta divisor cannot contain all the points of order two. It follows that $N<2^{2g}$.\n\nGiven an arbitrary curve $C$, is it known a upper bound for $N$ depending on $g$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nWell, there's a lower bound as odd theta characteristics on a canonical curve are effective, so there are at least $2^{g-1}(2^g -1)$ of them. Even thetas are trickier.\n\nPlease consult Dolgachev's book:\n\nshare|improve this answer\nYes, I mean upper bound. Thank you. Now I've modified the question and it is more precise. I take a look to your link. \u2013\u00a0 V M Sep 29 '10 at 14:38\nProbably of especial interest to you would be the Scorza correspondence if you don't already know about it. \u2013\u00a0 stankewicz Sep 29 '10 at 14:41\nI didn't know about it. I'm not sure I understand your answer. Do you mean that Scorza correspondence gives an estimate on the maximal number of effective theta characteristics? \u2013\u00a0 V M Oct 2 '10 at 14:46\nWell, not directly but you need a non-effective theta characteristic to define such a correspondence and a correspondence on $C\\times C$ of the type detailed in Dolgachev's book gives a non-effective theta. So while I don't know of a non-trivial upper bound, there's at least a foothold you can start from if you wanted to prove something. \u2013\u00a0 stankewicz Oct 2 '10 at 15:35\nadd comment\n\nIn genus 4 it seems the maximum number of vanishing even theta nulls is 10, which in fact occurs on a unique 4 dimensional principally polarized abelian variety. A bound may be obtained by considering the effect on the degree of the Gauss map of the theta divisor.\n\nYou may consult the paper of Robert Varley:\n\noops these are perhaps the isolated singularities on theta. I have not checked but the non isolated case of hyperelliptic jacobians may be different. Lets see, a h.e jacobian of genus 4 occurs as a double cover of P^1 branched at 10 points, so there are I guess, gosh again it seems there are 10 of them, i.e. the hyperelliptic line bundle plus one of the 10 ramification points.\n\nThe ranks of the double points are all 3 in this case, and are all 4 in the previous isolated case.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/64231.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nWhere Do the Parentheses Go?\n\nDate: 09/12/2003 at 00:48:21\nFrom: Lynn\nSubject: order of operations and writing equations\n\nI'm trying to help my daughter with some problems she's been given. \nEach one has a string of numbers and operations on one side, and a\nresult on the other side.  What you're supposed to do is insert\nparentheses around the numbers and operations in order to get the\nresult.  For example:\n\n      2    2    2\n 2 + 7  - 3  / 3  - 1 * 5 = 35\n\nI know how PEMDAS works, but I don't see how to solve these problems\nwithout just doing a lot of guessing.  Argh!\n\nDate: 09/12/2003 at 08:53:18\nFrom: Doctor Peterson\nSubject: Re: order of operations and writing equations\n\nHi, Lynn.\n\nThis sort of problem is just a puzzle -- there is no standard, \nstraighforward way to solve it, you just have to try things out and \nmake intelligent guesses. It may help to read what we have to say \nabout the order of operations\n\n\nbut there is no specific technique we can give you. I'll just try to \nget you started, thinking through the problem until I see where to go.\n\nUsing our e-mail notation, your equation is\n\n\nLooking at this, I notice that 35 = 5*7, and that there is a 7 and a \n5 in the left side. So my first action is to add parentheses so that \nmultiplication by 5 will be the last operation performed; if we can \nmake the rest of the expression equal 7, we'll be in good shape. This \nis just a guess; it may turn out that we won't want to multiply by 5 \nat all. But we can try it:\n\n  (2 + 7^2 - 3^2 / 3^2 - 1) * 5 = 35\n\nNow, it's not obvious that we can get 7 out of that, or that the 7 \nthat is there will in any way show through in the final form (since \nwe can't undo the squaring, and we would have to divide by 7 to leave \nourselves with just one 7). But I do see, at least, that 7^2 is much\ntoo big, so we have to make it smaller, either by subtracting\nsomething big or by dividing. \n\nAs written, the division only affects 3^2; 3^2/3^2 is 1. So we'll want\nto have parentheses around at least part of \n\n  2 + 7^2 - 3^2\n\nand we can decide eventually how much of \n\n  3^2 - 1\n\nto divide by. If we used all of both, we'd have\n\n  (2 + 7^2 - 3^2) / (3^2 - 1) = 42/10\n\nwhich is in the right ballpark but not a whole number, much less \nexactly 7. It doesn't help if we divide 42 by 3^2 or by 3 rather than \n3^2 - 1.\n\nNow we can try either adding more parentheses inside (2 + 7^2 - 3^2) \nto change what we are dividing, or pull the 2 outside of the \n\nAt this point I've finally looked ahead enough to see the solution. \nI'll leave you with just a hint: you'll want to take the first choice \nI mentioned in the last paragraph, and you'll have to change what you \ndivide by as well. See what you can do.\n\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Puzzles\nMiddle School Puzzles\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/64159/algebraic-plane-curves-and-their-tangent-curves/64180\nText:\nTake the 2-minute tour \u00d7\n\nGiven an algebraic plane curve how can one construct a corresponding curve whose degree is one less and such that the points of intersection are also points of tangency?\n\nSpecifically, if a plane curve $F$ is given by the polynomial equation $f(x,y) \\equiv \\sum_{j=0}^{n}\\sum_{i=0}^j{a_{i,j}x^{j-i}y^i}=0$, where $x,y \\in \\mathbb{C}$, how can one construct a corresponding plane curve $\\widetilde{F}$, given by $\\widetilde{f}(x,y) \\equiv \\sum_{j=0}^{n-1}\\sum_{i=0}^j{\\widetilde{a}_{i,j}x^{j-i}y^i}=0$ such that for a pair $p,q$ satisfying\n\n\\begin{equation} f(p,q)=\\widetilde{f}(p,q)=0 \\end{equation}\n\nwe also have\n\n\\begin{equation} \\dfrac{\\partial_xf}{\\partial_x \\widetilde{f}} \\bigg|_{x=p,y=q}=\\dfrac{\\partial_yf}{\\partial_y \\widetilde{f}} \\bigg|_{x=p,y=q} \\end{equation}?\n\nshare|improve this question\nI probably do not understand what you mean: but why doesn't $\\tilde F(x,y)=1$ work? \u2013\u00a0 Mariano Su\u00e1rez-Alvarez May 6 '11 at 21:26\nBecause that polynomial has no roots, i.e. $\\widetilde{f}(x,y) \\equiv 1 \\neq 0$ and does not constitute an algebraic plane curve \u2013\u00a0 hailekofi May 6 '11 at 21:39\nadd comment\n\n2 Answers\n\nIf $n$ is odd, you can take an arbitrary $g$ of degree $(n-1)/2$ and $\\tilde f = g^2$. The solution is far from unique and there will be others. For $n=2$, $\\tilde f$ is the tangent line at some point of $F$. For $n=3$, if you have a smooth cubic with inflexion $O$, taken as origin of the group law, choose a point of order $2, P_0$. For arbitrary points $P,Q$ on the curve, let $R= -(P+Q)+P_0$. Then $2(P+Q+R)=0$ so there is a conic through $P,Q,R$ tangent to $F$ at these points. The case $P_0=O$ reduces to my first construction, but as you see there are three other families. Do you have any reason to believe there will be a nice formula?\n\nshare|improve this answer\nYou don't need n to be odd for the nonreduced trick: let g have degree one and take $\\tilde f=g^{d-1}$. I guess the interesting question is whether a nonreduced all-tangent curve exists. A quick parameter count makes me skeptical... \u2013\u00a0 quim May 7 '11 at 8:17\nadd comment\n\nThe answer is clearly yes for d=2,3,4 and 6. I am skeptical about larger degrees.\n\nThe family of plane curves of degree (at most) d-1 has dimension (d-1)(d+2)/2. Imposing d(d-1)/2 tangency points with the given curve determines a family of curves of degree d-1 tangent to C of dimension at least d-1. For large d, the family of nonreduced solutions will have dimension bigger than d-1, so this gives no information about existence of reduced solutions. However, for d=2,4 and 6 there must be reduced solutions because the nonreduced families of solutions have dimension 0, 2 and 4 respectively.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/312109/an-inequality-of-length-of-module\nText:\nTake the 2-minute tour \u00d7\n\nDo you know a proof for the following inequality?\n\nSuppose that $(R,m)$ is a Noetherian local ring, $q$ is an $m$-primary ideal and $M$ is a finitely generated $R$-module. Then $$ l(q^nM/q^{n+1}M) \\leq l(M/qM) \\cdot \\mu(q^n), $$ where $\\mu(q^n)$ denote the smallest number of generators of $q^n$.\n\n\nshare|improve this question\nFirst line in the proof of Prop 11.1.10 (pg. 217?). By the way, what happened to your previous comments? It didn't prove the original inequality but it's something worth to notice too. \u2013\u00a0 mr.bigproblem Feb 24 '13 at 2:06\nHere is a link to the textbook of Huneke and Swanson mentioned above (from Swanson's website): people.reed.edu/~iswanson/book/SwansonHunekeCUP06.pdf \u2013\u00a0 mbrown Feb 24 '13 at 17:16\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nLet $n \\ge 1$; for $n=0$, this is trivial. Say $x_1, \\dots, x_m$ are generators of $q^n$. $(x_1+q^{n+1})M/q^{n+1}M \\oplus \\dots \\oplus (x_m+q^{n+1})M/q^{n+1}M$ maps onto $q^nM/q^{n+1}M$ in an obvious way (just sum the components), and $M/qM^{\\oplus m}$ maps onto $(x_1+q^{n+1})M/q^{n+1}M \\oplus \\dots \\oplus (x_m+q^{n+1})M/q^{n+1}M$ in an evident way (multiply the $i$th component by $x_i$; one can check this is well-defined). Thus, $q^nM/q^{n+1}M$ is a quotient of $M/qM^{\\oplus m}$.\n\nshare|improve this answer\nVerified! Thanks for the answer! I'll edit the question, getting rid of the conditions $\\mu(q) = \\text{dim } R$ and $M$ is $R$-finite. \u2013\u00a0 mr.bigproblem Feb 24 '13 at 19:52\nWe should really require that $M$ is fg, so that everything has finite length; otherwise, one could end up with $\\infty \\cdot 0$ on the right side. \u2013\u00a0 mbrown Feb 26 '13 at 2:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/17575/determining-the-capacitance-of-a-system-with-a-non-homogenous-dielectric?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nIn an experiment we were given non-homogenous dielectric substances described by functions of coordinate. How can capacitance be determined from this?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nYou need to use the following equations coming from electrostatic:\n\n$$\\nabla\\cdot(\\epsilon({\\bf x}){\\bf E})=\\rho({\\bf x})$$\n\n$${\\bf E}=-\\nabla\\phi$$\n\nwith the proper boundary conditions. Then, with the definition of capacitance you will get the result. This is not often feasible analytically and will depend on the problem at hand.\n\nshare|improve this answer\nadd comment\n\nHere's a (flawed) method on doing it--which works for many cases Otherwise @Jon's method is the way to go.\n\nBreak it into infinitesimal thin rods so that you get $\\infty$ parallel capacitors of area $\\rm dA$. Usually one of the directions will be homogenous, so you can write $\\rm dA=z\\rm dy$. Otherwise, $\\rm dA=dy\\cdot dz$\n\nBreak each rod into infinitesimal chunks and get $\\infty$ series capacitors per slice of thickness $\\rm dx$.\n\nFor each rod, find the infinitesimal reciprocal of capacitance $\\rm d(\\frac1C_{chunk})$ (in terms of $(x,y,z)$ Integrate $\\int \\rm d(\\frac1C_{chunk})=\\frac1{dC_{rod}}$\n\nNow integrate $\\int \\rm dC_{rod}=C_{eq}$\n\nThe issue here is, when you break them into a set of series capacitors, you use the capacitors-in-series formula. This assumes that charge distribution on each capacitor in series is the same--which is wrong in this case. We can't apply charge conservation on a rod here, as charge can enter and leave from various spots.\n\nUsually, a sufficently symmetric case works.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/276279/how-to-define-a-function-which-takes-a-real-number-and-gives-as-a-result-the-clo/276283\nText:\nTell me more \u00d7\n\nHow can I define a function which takes as an only parameter a real number and gives as a result the closest smaller natural number? E.g. $f(3.554)=3, f(4.95485)=4, f(2.001)=2$.\n\nshare|improve this question\nThe function is called $floor$ and written as $\\lfloor x\\rfloor$ \u2013\u00a0 Shard Jan 12 at 11:56\nIf you're looking for a function that can be expressed in terms of elementary functions, you're out of luck. Floor and ceiling functions can be represented as infinite series that converge, but only in part of the domain. You can't use those representations in practice. \u2013\u00a0 Greg Ros Jan 12 at 12:12\nYes, exactly what I wanted to know. I asked my Mathematics teacher(I'm in High school) and he told me that I got the definiton of the function with my question. So I decided to search or ask how it could be defined in pure math notation, not in a specific language. \u2013\u00a0 user1113314 Jan 12 at 12:46\nadd comment\n\n2 Answers\n\nFirst, if your real number $k < 1$, then the function $f$ is not defined at $k$ since there is no natural number lesser than the value of $k$.\n\nThe function $f$ you are trying to define is just a subset of the floor function where $f:\\{x|x\\ge 1\\} \\mapsto \\mathbb{N}$. Thus we can define your function as $f(x) = \\max (y\\in \\mathbb{N}|y\\le x), x \\in [1,\\infty)$.\n\nshare|improve this answer\nPhew, I needed too many corrections on this one. \u2013\u00a0 \u03a0\u03b1\u03c1\u03b8 \u039a\u03bf\u03c7\u03bb\u03b9 Jan 12 at 12:09\nThank you, really comprehensive answer. \u2013\u00a0 user1113314 Jan 12 at 13:04\n@user1113314: No problem! \u2013\u00a0 \u03a0\u03b1\u03c1\u03b8 \u039a\u03bf\u03c7\u03bb\u03b9 Jan 12 at 13:34\nadd comment\n\nYou can define such a function directly by it's desired properties, i.e. for $x\\geq 1$, define $$ f(x) :=\\max \\left\\{ n\\in\\mathbb{N}:n\\leq x \\right\\}. $$ As has already been pointed out, $f(x)$ is commonly denoted by $\\lfloor x\\rfloor$. Clearly $f$ is discontinuous, so it cannot be expressed as a finite composition of continuous functions (which probably is what you've actually been looking for) or a power series.\n\nOne obvious representation of $f$ would be to write it as a limit of step functions: $$ f = \\lim_{n\\rightarrow \\infty}\\sum_{k=1}^n k \\cdot\\chi_{[k,k+1)}$$ where $\\chi_I$ is the characteristic function of the interval $I$, but this is really nothing more than toying with the definition.\n\nshare|improve this answer\nThank you for the answer. the representation is too complicated for me. I'll take a look at the floor(x) implementation in Wikipedia. \u2013\u00a0 user1113314 Jan 12 at 13:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/56315/approximate-analytic-solution-of-schroedinger-equation-with-arbitrary-power-pote?sort=votes\nText:\nTell me more \u00d7\n\nI'm solving the following Schroedinger equation in the domain $r>0$\n\n$\\psi''(r) + \\left(E-\\frac{a}{r^b}\\right)\\psi(r)=0 $,\n\nwhere $0 < b < 2$ and $a, E$ are positive constants. Primarily I'm interested in the asymptotical power behavior of the solution as $r\\to 0$. To be complete in the description of the problem, I fix my boundary conditions at $r\\to +\\infty$ as a plane wave ansatz.\n\nI did a lot of DSolve with Mathematica and found out that $\\psi(r)\\to const$ as $r\\to 0$. It gave me a hint for the power series solution, that one of the terms in the expansion\n\n$\\psi(r) = \\sum\\limits_i a_i r^{\\alpha_i}$\n\nfor some (noninteger) $\\alpha_i>0$ should cancel with $a/r^b$. However, even with this assumption there are a bunch of terms which do not cancel. Power expansion does not seem to work in this case as well as the WKB approximation (double checked numerically). What are the other known methods to find an approximate asymptotic behavior in this case? A good reference would be great too!\n\nshare|improve this question\nProbably a stupid and unhelpful comment, but have you tried letting $r=1/s$ with $s \\to \\infty$? \u2013\u00a0 Zen Harper Feb 23 '11 at 8:01\nWell, it's just changing $r^\\alpha \\to s^{-\\alpha}$, it does not affect power counting... \u2013\u00a0 Peter Feb 23 '11 at 18:44\nI am not an expert on differential equations, so ignore my comments if they sound stupid! Letting $s=1/r$ pushes the singularity out to infinity, but I'm not sure it's of much use. But also, if you let $\\psi = \\exp f$ then you change the second order linear equation into a first order nonlinear one. Maybe this is not simpler, but at least it's different! \u2013\u00a0 Zen Harper Feb 25 '11 at 1:58\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nAs $r$ approaches zero, the coefficient of $\\psi$ becomes dominated by the contribution of $-a/r^b$. This means that in the vicinity of zero your solution is dominated by solution of the following equation $$ \\psi''-\\frac{a}{r^b}\\psi=0. $$ This can be demonstrated more rigorously (and, also, refined to the higher accuracy) by scaling into the vicinity of $r=0$. This equation possesses an explicit solution in terms of the modified Bessel functions: $$ \\psi=C_1\\sqrt{r}K_{\\frac{1}{2-b}}\\left(\\frac{2\\sqrt{a}}{b-2}r^{1-b/2}\\right)+C_2\\sqrt{r}I_{\\frac{1}{2-b}}\\left(\\frac{2\\sqrt{a}}{b-2}r^{1-b/2}\\right). $$ The latest edition of NIST Handbook tells us that for $z\\to 0$ $$ I_{\\nu}(z)\\sim (\\frac{1}{2}z)^{\\nu}/\\Gamma(\\nu+1) \\quad\\mbox{and}\\quad K_{\\nu}(z)\\sim \\frac{1}{2}\\Gamma(\\nu)(\\frac{1}{2}z)^{-\\nu} $$ so the actual constant at $r\\to0$ depends only on $C_1$, unless $C_1$ vanishes. It seems pretty clear that there are no singularities here; typically you should expect that $$ \\psi\\sim \\frac{C_1}{\\Gamma(\\frac{3-b}{2-b})}\\left(\\frac{\\sqrt{a}}{b-2}\\right)^{\\frac{1}{2-b}} \\quad\\mbox{for}\\quad r\\to 0. $$ Specific values of $C_1$ and $C_2$ are less trivial to obtain, but they can be found by matching this limiting solution to another solution that is valid further away from $r=0$.\n\nThe method of matched asymptotic expansions is often used to solve this type of problems asymptotically, see e.g. Kevorkian & Cole (1996) \"Multiple Scale and Singular Perturbation Methods\", Springer. In this method you would need to construct two solutions: \"inner\" solution, valid as $r\\to 0$, (it is the solution derived above) and \"outer\" solution, valid as $r\\to\\infty$ (which you took to be a plane wave). Some ingenuity may be needed to ensure that the ranges of validity of these two solutions overlap, so that they can actually be matched.\n\nshare|improve this answer\nThanks! I was just working with Mathematica, apparently it didn't know about that solution. So yeah, it's a good point to check with thextbooks from time to time. \u2013\u00a0 Peter Mar 2 '11 at 19:08\nI knew this equation from Section 8.4 of Gradshteyn and Ryzhik's \"Table of Integrals, Series and Products\" (this is where they collected various properties of Bessel functions). Maple 7 was also albe to integrate it. However, more generally, you should treat yourself to a copy of Polyanin and Zaitsev's \"Handbook of Exact Solutions for Ordinary Differential Equations\" which, I suspect, still beats any current computer algebra system hands down. \u2013\u00a0 Aleksey Pichugin Mar 2 '11 at 19:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58160.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nGreatest Common Factor (GCF)\n\nDate: 04/13/99 at 10:38:25\nFrom: Eugene\nSubject: Mathematics 6th grade\n\nHere's the question: The GCF of my numerator and denominator is 5. The \nfraction is equivalent to 4/6. \n\nI tried listing all the multiples of 5 and none is divisible by 6 \nexcept 30. But if I divide this by 6 it will be 5 and 5 x 4 is 20. But \n20/30's GCF is not 5, it's 10. HELP!\n\nDate: 04/13/99 at 12:48:27\nFrom: Doctor Peterson\nSubject: Re: Mathematics 6th grade\n\nHi, Eugene.\n\nYes, this is a little tricky; I fell into almost the same trap you \ndid. You're thinking well so far, but now you have to back up and ask \nwhy it didn't work. To let you practice avoiding the trap, I'll work a \nslightly different problem: the GCF will be 7 rather than 5, and the \nfraction will be equivalent to 3/6 rather than 4/6.\n\nWhat you are doing is looking for some number N by which you can \nmultiply the numerator and denominator, so that\n\n    3xN    3\n    --- = ---\n    6xN    6\n\nand the GCD of 3xN and 6xN is 7. It makes sense to try N = 7, as you \ndid with 5; but the GCD of 21 and 42 is 21, not 7. What happened?\n\nLet's factor the numerator and denominator of our new fraction:\n\n    3xN    3xN\n    --- = -----\n    6xN   2x3xN\n\nDo you see that the GCD will not be N, but 3xN, because 3 and 6 \nalready have a common factor, 3? In order to make the GCD be 7, then, \nN must be 7/3. Then\n\n    3xN   7\n    --- = --\n    6xN   14\n\nwhich is equivalent to 3/6, and the GCD of 7 and 14 is 7.\n\nWere you surprised that N was not a whole number? You can multiply the \nnumerator and denominator of a fraction by any fraction and it will \nstill be equivalent; but the result will be two whole numbers only if, \nas in this case, there was a common factor (3).\n\nSo the reason our problem was tricky is that 3/6 is not in lowest \nterms, so equivalent fractions do not have to have whole-number \nmultiples of the numerator and denominator. We can get to the answer \nvery easily by first writing 3/6 in lowest terms as 1/2, then \nmultiplying numerator and denominator by 7.\n\nNow see what you can do with your problem. There are several ways to \nsolve it, once you see what's wrong.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Fractions\nMiddle School Fractions\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/15907/position-function-not-always-retuning-an-answer-even-with-no-apparent-problems?answertab=oldest\nText:\nTell me more \u00d7\n\nI'm having some problems with Position.\n\nSometimes it will give an empty list instead of the actual position of the element I am looking for when that element is specified through some other code but will return the correct position when the element is specified directly as a number as in the minimum working example below.\n\ndata = {{0.1, 0.0001683}, {0.2, 0.00035754}, {0.3, 0.00056711}, {0.4, \n   0.00078986}, {0.5, 0.0010333}, {0.6, 0.0010333}, {0.7, \n   0.0015758}, {0.8, 0.0018738}, {0.9, 0.0022054}, {1., \n   0.0025706}, {1.1, 0.0029788}, {1.2, 0.0034366}, {1.3, \n   0.0039831}, {1.4, 0.0046433}, {1.5, 0.0055203}, {1.6, \n   0.0068061}, {1.7, 0.010939}, {1.8, 0.031246}, {1.9, 0.054948}, {2.,\n    0.076556}, {2.1, 0.098521}, {2.2, 0.12551}, {2.3, 0.1585}, {2.4, \n   0.1921}, {2.5, 0.22544}, {2.6, 0.25798}, {2.7, 0.28992}, {2.8, \n   0.32051}, {2.9, 0.35095}, {3., 0.38104}}\n\ninterpol = Interpolation[data];\n\nq = FindRoot[interpol[x] == 0.159, {x, 2.9}][[1, 2]]\n\nxlow = Floor[q, 0.1]\n\nPosition[data[[All, 1]], xlow]\n\nPosition[data[[All, 1]], 2.3]\n\nWhen running v8 on xP this code gives {} for the first output and {{23}} for the second.\n\nThis type of error is referenced in the Possible Issues section of the documentation for Position in v8 and v9 but no advice is given.\n\nIn[1] := Position[Range[-1, 1, 0.05], 0.1]\nOut[1] = {}\n\nI've tried putting N everywhere I can to solve it as I thought it could just be a precision or representation issue ( i.e. 2.3 vs 23/10 ) but with no success. Does anyone have nifty work around or solution to this that I am missing please?\n\nshare|improve this question\nWould Position[data[[All, 1]], Nearest[data[[All, 1]], xlow][[1]]] be acceptable ? \u2013\u00a0 b.gatessucks Dec 7 '12 at 10:25\nIt works so it most certainly would be acceptable! Thanks for the fast reply. \u2013\u00a0 fizzics Dec 7 '12 at 10:40\nSince I believe the correct answer is to use Chop (see below), it's also worth pointing to this and this. \u2013\u00a0 Jens Dec 8 '12 at 18:26\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nPosition is looking for an exact match (pseudo-SameQ), rather than a numeric one.\nYou will get the result you want with:\n\nPosition[data[[All, 1]], _?(# == xlow &)]\n\n\nPosition[data[[All, 1]], x_ /; x == xlow]\n\nGenerally you should use Equal (short form ==) any time you are trying to mach Real numbers, to allow for small rounding errors.\n\nUsing the pattern 0 | 0. is not sufficient; See this for examples.\n\nFor an excellent treatment of the problems of matching inexact numbers see:\n\nInstability in DeleteDuplicates and Tally\n\nshare|improve this answer\nThanks for the fast reply. Both of those do the job perfectly but I'm a bit confused by the structure you use in the first one. Wouldn't the _? return a True value instead of a numeric? The second structure I don't fully understand either as I don't see how Position knows to loop over x and compared each term. There is obviously more functionality built in than I appreciate \u2013\u00a0 fizzics Dec 7 '12 at 10:37\n@fizzics Both _?(# == xlow &) and x_ /; x == xlow are patterns, which is what Position needs as a second argument. _?testfunction is a pattern for any single expression for which testfunction yields True when applied. x_ /; expr is a pattern for any single expression, which we locally name x, for which expr evaluates to True; if x appears in expr the local definition is used. Read the documentation for Pattern, PatternTest, and Condition, then see this question. Return with any further questions. \u2013\u00a0 Mr.Wizard Dec 7 '12 at 11:27\nadd comment\n\nOne alternative approach that is very powerful when dealing with approximate real numbers hasn't been mentioned yet: use Chop or Threshold.\n\nThese two functions are intended for just the type of situations you describe, so I would always try them first:\n\nIn your example, this simple command works:\n\nPosition[Chop[data[[All, 1]] - xlow], 0]\n\n\nInstead of finding xlow, I reformulated the problem so that you find 0 in the list of differences with xlow.\n\nshare|improve this answer\nExcellent recommendation. Numeric methods are almost always faster. \u2013\u00a0 Mr.Wizard Dec 8 '12 at 22:22\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/90927/shortest-absolute-value-of-path-in-graph?sort=oldest\nText:\nTell me more \u00d7\n\nSuppose we have a weighted, acyclic digraph, with positive and negative edge weights.\n\nIs there an algorithm that determines whether there is a path of weight zero between vertices A and B? The Bellman-Form algorithm finds the path of smallest weight - is there another algorithm that determines the path of smallest absolute value weight?\n\nThanks, Charles\n\nshare|improve this question\nWhat weights are allowable? Integers between -16 and 16? Arbitrary rational or real numbers? Something in between? (If there is a minimum gap between path weights, it might make the problem easier.) \u2013\u00a0 Charles Staats Mar 11 '12 at 20:18\nThe weights are integers in the interval [-c,c] for some integer constant c. \u2013\u00a0 Charles Bailey Mar 11 '12 at 20:23\nIf it's a finite graph, then of course there's an algorithm, exhaustive search. Perhaps your question is whether there is a more efficient algorithm? \u2013\u00a0 Gerry Myerson Mar 11 '12 at 23:03\nYes, it's a finite graph, so exhaustive search would work. I'm looking for something more efficient. Thanks, Charles \u2013\u00a0 Charles Bailey Mar 12 '12 at 2:55\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nIt is NP-complete if $c$ is not specified. For a set of numbers $m_1,\\ldots,m_t$ make a digraph with vertices $v_0,v_1,\\ldots,v_t$. From $v_{i+1}$ to $v_i$ put two edges, of length $m_i$ and $-m_i$, for each $i$. A path of zero length from $v_0$ to $v_t$ corresponds to a partition of $m_1,\\ldots,m_t$ into two sets of equal size, which is a well known NP-complete problem (called PARTITION).\n\nshare|improve this answer\nThat still leaves the question of whether any practical algorithms exist, at least to find \"small\" absolute values. There is the obvious convex relaxation, but it is not clear it works at all... \u2013\u00a0 Igor Rivin Mar 12 '12 at 4:35\nfor weights given in unary, one might suspect that there will be a dynamic programming algorithm... \u2013\u00a0 Dima Pasechnik Mar 13 '12 at 5:06\nIf the weights are integers of magnitude $O(c)$, then there is an $O(cnm)$ dynamic programming algorithm, where $m$ is the number of edges. For each vertex in topological order, determine which path lengths occur from the starting vertex to that vertex. It would be nice to know if faster is possible. \u2013\u00a0 Brendan McKay Mar 13 '12 at 6:58\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/159493/can-there-be-a-function-thats-even-and-odd-at-the-same-time?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI woke up this morning and had this question in mind. Just curious if such function can exist.\n\nshare|improve this question\nIn case anyone has forgotten what \u201ceven\u201d and \u201codd\u201d functions are, $f$ is even if $f(x) = f(-x)$ and odd if $-f(x) = f(-x)$. See also Wikipedia on even and odd functions. \u2013\u00a0 Rory O'Kane Jun 17 '12 at 18:54\nYou might find it interesting that I often used to ask this as an extra credit question on precalculus tests when even/odd function properties were covered, typically worth an extra 3 points on a 100 point scale (so a score of 103/100 was possible). I'd usually get about 2 to 5 students getting the extra points (out of a total of maybe 25-35 students) in a U.S. college precalculus class, and about half the class getting the extra points in U.S. honors level high school classes I used to teach. \u2013\u00a0 Dave L. Renfro Jun 18 '12 at 15:56\n\n6 Answers 6\n\nup vote 38 down vote accepted\n\nOthers have mentioned that $f(x)=0$ is an example. In fact, we can prove that it is the only example of a function from $\\mathbb{R}\\to \\mathbb{R}$ (i.e a function which takes in real values and outputs real values) that is both odd and even. Suppose $f(x)$ is any function which is both odd and even. Then $f(-x) = -f(x)$ by odd-ness, and $f(-x)=f(x)$ by even-ness. Thus $-f(x) = f(x)$, so $f(x)=0.$\n\nshare|improve this answer\nOf course, one could argue that restrictions of the constant $0$ function to different domains symmetric about the origin are different functions, set-theoretically speaking. \u2013\u00a0 Cameron Buie Jun 17 '12 at 15:30\n@CameronBuie That is true, I will make my answer more precise to indicate this. Thank you. \u2013\u00a0 Ragib Zaman Jun 17 '12 at 15:31\nFunny, I never thought of f(x) = 0 as a possibility. Thanks for the answers everyone! \u2013\u00a0 bodacydo Jun 17 '12 at 21:06\n\nIf $K$ is a field of characteristic 2, every function $K\\to K$ is both even and odd.\n\nshare|improve this answer\ni'm sorry, wouldn't that be \"unequal to 2\"? \u2013\u00a0 akkkk Jun 17 '12 at 15:31\n@Auke: No. I won't spoil the joke by spelling it out, sorry. \u2013\u00a0 Harald Hanche-Olsen Jun 17 '12 at 15:40\nActually, you don't even need a field, any ring of characteristic 2 will do. \u2013\u00a0 Ilmari Karonen Jun 17 '12 at 15:42\n@HaraldHanche-Olsen, oh, I am sorry, I misread your answer, you are completely right :) nice one \u2013\u00a0 akkkk Jun 17 '12 at 15:43\nThis is a wonderful answer! \u2013\u00a0 Edward Hughes Jun 17 '12 at 23:52\n\nYes. The constant function $f(x) = 0$ satisfies both conditions.\n\nEven: $$ f(-x) = 0 = f(x) $$\n\nOdd: $$ f(-x) = 0 = -f(x) $$\n\nFurthermore, it's the only real function that satisfies both conditions:\n\n$$ f(-x) = f(x) = -f(x) \\Rightarrow 2f(x) = 0 \\Rightarrow f(x) = 0 $$\n\nshare|improve this answer\n\nHint $\\rm\\ f\\:$ is even and odd $\\rm\\iff f(x) = f(-x) = -f(x)\\:\\Rightarrow\\: 2\\,f(x) = 0.\\:$ This is true if $\\rm\\:f = 0,\\:$ but may also have other solutions, e.g. $\\rm\\:f = n\\:$ in $\\rm\\:\\mathbb Z/2n =\\:$ integers mod $\\rm 2n,$ where $\\rm\\: -n \\equiv n.$\n\nshare|improve this answer\n+1, but note that your last $\\iff$ applies (in the backwards, i.e. 'if' direction) only to $f(x) = -f(x)$, and not to the part where $f(-x)$ equals both of them. \u2013\u00a0 ShreevatsaR Jun 17 '12 at 18:04\nYes, I meant to write $\\:\\Rightarrow\\: $ but it was lost in editing. Now fixed. Thanks. \u2013\u00a0 Bill Dubuque Jun 17 '12 at 18:19\n\nSuppose $f$ odd an even. Let $x \\in D$ ( D is set definition of $f$) then you have : $ f(x)=f(-x)=-f(x)$. What can you conclude about $f$ ?\n\nshare|improve this answer\n\nAs other people have mentioned already, the real function $f(x)$ which maps every real number to zero (i.e.$f(x) = 0 \\space \\forall x \\in \\mathbb{R}$) is both even and odd because $$f(x) - f(-x) = 0 \\space \\space , f(x)+f(-x) = 0\\space \\forall x \\in \\mathbb{R} .$$ Also it is the only function defined over $\\mathbb{R}$ to possess this property.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/11981/building-a-multi-variable-regression-model\nText:\nTake the 2-minute tour \u00d7\n\nI have a large set of data points which have 18 dimensions to them. I know that these data points must follow a strict polynomial formula with no possible variance. Given that I have enough data (I assure you I have), how do I go about building a regression model to find the general formula of the lowest polynomials for the equation which gives these data points?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nThe input dimension being 18 is a little problematic, so I have a few suggestions. I'm putting the statistical approach first due to your choice of tags and terminology..\n\nLinear regression can be made to fit polynomials by simply explicitly creating all the monomial terms; ie for an input with two dimensions $x= (x_1,x_2)$, for a quadratic you'd instead use $x' = (1,x_1,x_2,x_1x_2,x_1^2,x_2^2)$. Notice that this means, to add all $d$th order terms, you would create $O(18^d)$ dimensions! Notice furthermore that your regression model has equivalently many parameters! Therefore, it may be beneficial to try to simplify the model a little with some regularization, maybe use lasso (l1-regularization). Note that, as specified, the degree of the polynomial is not being minimized. The regularization I mentioned only minimizes the l1 length, and even putting a sparsity constraint on the weights alone (which is simpler than minimizing degree) is nonconvex. To find the degree, you could binary search; ie try degrees $1,2,4,8,\\ldots$ until you get zero error, and then binary search within the last interval to find the exact order.\n\nAnother approach is to directly use polynomial interpolation. Simply grow $d$, building an interpolating polynomial at each iteration, and stopping when the one built on the provided points fits all other points. For univariate data, the Lagrange Polynomial[1] is the way to go. I don't know your case offhand but just noticed wikipedia has a \"polynomial interpolation\" page which should be helpful.\n\nanything you try will be slow due to the dimension, your stipulation that you necessarily find the absolute smallest degree, and the vast number of parameters in any such polynomial.\n\n[1] lagrange interpolation\n\nshare|improve this answer\nadd comment\n\nIf there is no possible variation then this isn't really a regression question. It's straight up linear algebra. You have alot of equations of the form. y= ax_1+b x_2+..+q x_18 + aa x_1^2+ab x_1x_2... (all terms taken 2 at a time),+ (stuff taken 3 at a time)+..\n\nNow either you have an idea of where to end this and need to solve a giant matrix, or you aren't sure where to end this and don't really have enough data. By not enough data I mean that you can fit infintely many polynomials if you allow the degree to be unbounded. Just as you can fit infintely many polynomials to a finite set of points in R^2.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/7183/connection-between-bernoulli-polynomials-and-polygamma-function\nText:\nTake the 2-minute tour \u00d7\n\nThere is an intricate connection between Hurwitz Zeta and the (traditional) polygamma function:\n\n\nIf to use a generalization for Bernoulli numbers, this can be considered a formula, connecting polygamma and Bernoulli polynomials of negative order:\n\n$$\\psi_n(z)=(-1)^{n+1}n!\\frac{B_{-n}(x)}n$$ (1)\n\nAs much as this equality is impressing, it is limited as it only holds for natural n.\n\nAfter a couple of unsuccessful attempts to find a more general formula, I encountered a more natural, \"balanced\" generalization of polygamma function explained in this paper. It turned out that while the old formula still holds for natural n (since the old polygamma and balanced polygamma coincide in integer positive orders), a completely new formula connecting this balanced polygamma with Zeta and Bernoulli numbers can be derived which holds for any z:\n\n$$\\zeta(z,q)=\\frac{\\Gamma (1-z) \\left(2^{-z} \\left(\\psi \\left(z-1,\\frac{q}{2}+\\frac{1}{2}\\right)+\\psi \\left(z-1,\\frac{q}{2}\\right)\\right)-\\psi(z-1,q)\\right)}{\\ln(2)}$$\n\n$$B_z(q) = -\\frac{\\Gamma (z+1) \\left(2^{z-1} \\left(\\psi\\left(-z,\\frac{q}{2}+\\frac{1}{2}\\right)+\\psi\\left(-z,\\frac{q}{2}\\right)\\right)-\\psi(-z,q)\\right)}{\\ln (2)}$$\n\nBoth of them can be expressed completely in terms of balanced polygamma and elementary functions if to notice that $\\Gamma(x)=e^{\\psi(-1,x)+\\frac 12 \\ln(2\\pi)}$, which allows to get rid of the Gamma function.\n\nWhile the target was reached, these expressions still leave a bad impression. I cannot simplify it as no CAS system is capable of operations with the balanced polygamma.\n\nHence I am asking for help on how to simplify the expressions so they could be easier to manage and use. It is also not evident how the letter formulas become the former ones at positive real z.\n\nshare|improve this question\nThis appears to be a duplicate of mathoverflow.net/questions/42696 \u2013\u00a0 Robin Chapman Oct 19 '10 at 13:08\nUsually people ask first here and then promote it to MO if it is sufficiently advanced that it stands a better chance of getting answered there. So I'm not entirely sure why you posted here if you couldn't get answers there. \u2013\u00a0 \uff2a. \uff2d. Oct 19 '10 at 14:14\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55169.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPixels in a Triangle\n\nDate: 08/02/99 at 09:14:15\nFrom: Berkant Barla Cambazoglu\nSubject: Triangle pixel intersection\n\nI basically want to find the number of pixels inside a 2D triangle. \nThe triangle may have nodes with floating point coordinate values, but \nthe points returned as answer must have integer-valued coordinates.\n\nThere are some exact solutions: we may scan convert the triangle, or \nperform an inside-outside test over the triangle using the line \nequations of the edges forming the triangle. However, these methods \nare too slow, and they are unnecessary for this particular problem. \nI don't want the coordinates of the pixels; what I seek is just the \ntotal number of pixels inside the triangle.\n\nAn approximation to this problem would be to calculate the area of the \ntriangle and assume that it is the same with the number of pixels \ninside the triangle. However, in this method some triangles can get \nmuch higher values than the actual value. For example, even a triangle \nhas no pixels inside, it is always assigned a positive value instead \nof 0.\n\nI will be glad if you can offer me a smart solution. Thanks for your \n\nDate: 08/02/99 at 13:03:26\nFrom: Doctor Peterson\nSubject: Re: Triangle pixel intersection\n\nHi, Berkant.\n\nThis sounds like it might be a good place to apply Pick's Theorem, \nwhich you can read about here:\n\n\nThis says that the area of a triangle (or any polygon) whose vertices \nare lattice points (in your situation, this is the same as saying they \nare on pixels - integer coordinates) is I+B/2-1, where I is the \nnumber of lattice points (pixels) inside the polygon, and B is the \nnumber of lattice points on the boundary. You want to find I, so \nyou'll need to find the area and B. Of course, your vertices don't \nnecessarily have integer coordinates, but it will probably work if you \nround to find the corner pixel.\n\nSo what's B? The number of lattice points exactly on the line from \n(x1,y1) to (x2,y2), including one of its endpoints, will be the GCD of \n(x1-x2) and (y1-y2). Add these and you'll have B.\n\nSo my formula for I, given three vertices (x1,y1), (x2,y2), and \n(x3,y3) rounded to integers, would be\n\n   I = A + 1 - [gcd(x1-x2, y1-y2) + gcd(x2-x3, y2-y3)\n       + gcd(x3-x1, y3-y1)]/2\n\nIn case you're not familiar with it, you can get the area (again after \nrounding the coordinates) this way:\n\n  A = [(x1-x2)(y1+y2) + (x2-x3)(y2+y3) + (x3-x1)(y3+y1)]/2\n    = [x1 y2 - x2 y1 + x2 y3 - x3 y2 + x3 y1 - x1 y3]/2\n\nwhich is the same as using a determinant, as explained here:\n\n\nLet's test this with a triangle that will contain no pixels:\n\n    (0,0) (15,15) (15,16)\n\nThe area is\n\n    A = [0*15 - 15*0 + 15*16 - 15*15 + 15*0 - 0*16]/2 = 7.5\n\n    gcd(-15,-15) = 15\n    gcd(0,-1)    =  1\n    gcd(15,16)   =  1\n\n    I = 7.5 + 1 - (15+1+1)/2 = 8.5 - 8.5 = 0\n\nwhich is correct.\n\nI'm a little uncertain about how this will work out in practice, \nbecause if you're working with lines drawn on a computer, the \nalgorithm that draws the lines will count many pixels that are \nactually inside as being part of the edge, in order to be able to draw \nit without gaps. On the other hand, if you're looking for exactly the \npixels within the actual triangle defined by non-integer vertices, \nyou'll gain or lose points when you round the coordinates. Whether \nthis is acceptable depends on the details of your application.\n\nPlease let me know whether or not this helps.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nHigh School Geometry\nHigh School Practical Geometry\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/215999/how-many-0s-are-at-the-end-of-20\nText:\nTake the 2-minute tour \u00d7\n\nI'm not exactly sure how to answer this question, any help would be appreciated. After reading this I'm still not sure.\n\n\nshare|improve this question\nDoes this site answer it and walk through enough details? purplemath.com/modules/factzero.htm, using the number of fives method or Wolfram Alpha: wolframalpha.com/input/?i=number+of+trailing+zeros+in+20%21 \u2013\u00a0 Amzoti Oct 18 '12 at 1:09\nThat's funny, I literally just stumbled across this site. \u2013\u00a0 Unknown Oct 18 '12 at 1:10\nEvidently there is only one! (sorry, couldn't resist) \u2013\u00a0 treble Oct 18 '12 at 1:34\nI got asked this in a programming job interview once, but for $100!$ - I didn't get the job :( \u2013\u00a0 Ergwun Oct 18 '12 at 6:50\nadd comment\n\n3 Answers\n\nup vote 10 down vote accepted\n\nThere is a general formula that can be used. But it is good to get one's hands dirty and compute.\n\nIf $20!$ seems dauntingly large, calculate $10!$. You will note it ends with two zeros. Multiplying $10!$ by all the numbers from $11$ to $20$ except $15$ and $20$ will not add to the zeros. Multiplying by $15$ and $20$ will add one zero each.\n\nRemark: Suppose that we want to find the number of terminal zeros in something seriously large, like $2048!$. It is not hard to see that this number is $N$, where $5^N$ is the largest power of $5$ that divides $2048!$. This is because we need a $5$ and a $2$ for every terminal $0$, and the $5$s are the scarcer resource.\n\nTo find $N$, it is helpful to think in terms of money. Every number $n$ between $1$ and $2048$ has to pay a $1$ dollar tax for every $5$ \"in it.\" So $45$ has to pay $1$ dollar, but $75$ has to pay $2$ dollars, because $75=5^2\\cdot 3$. And a $5$-rich person like $1250$ has to pay $4$ dollars.\n\nLet us gather the tax in stages. First, everybody divisible by $5$ pays a dollar. These are $5$, $10$, $15$ and so on up to $2045$, that is, $5\\cdot 1, 5\\cdot 2,\\dots, 5\\cdot 409$. So there are $409$ of them. It is useful to bring in the \"floor\" or \"greatest integer $\\le x$ \" function, and call the number of dollars gathered in the first stage $\\lfloor 2048/5\\rfloor$.\n\nBut many numbers still owe some tax, namely $25,50,75,\\dots,2025$. Get them to pay $1$ dollar each. These are the multiples of $25$, and there are $\\lfloor 2048/25\\rfloor$ of them.\n\nBut $125$, $250$, and so on still owe money. Get them to pay $1$ dollar each. We will gather $\\lfloor 2048/125\\rfloor$ dollars.\n\nBut $625$, $1250$, and $1875$ still owe money. Gather $1$ dollar from each, and we will get $\\lfloor 2048/625\\rfloor$ dollars.\n\nNow everybody has paid up, and we have gathered a total of $$\\lfloor 2048/5\\rfloor + \\lfloor 2048/25\\rfloor +\\lfloor 2048/125\\rfloor +\\lfloor 2048/625\\rfloor$$ dollars. That's the number of terminal zeros in $2048!$.\n\nshare|improve this answer\nI don't always upvote answers that are in \"competition\" with my own...but when I do, it's because it's a damn good answer! (+1) \u2013\u00a0 Cameron Buie Oct 18 '12 at 3:59\nYours is a good answer, now with an additional upvote. I thought that this might be an opportunity to describe in very concrete terms the process that yields the usual formula. \u2013\u00a0 Andr\u00e9 Nicolas Oct 18 '12 at 4:13\nAgreed. You did it much more explicitly and intuitively than I (though, to be fair, I'd never even realized that there was an explicit formula before, and was operating off the cuff). Upvote appreciated. \u2013\u00a0 Cameron Buie Oct 18 '12 at 4:33\nadd comment\n\nCount up the number of factors of $5$ and the number of factors of $2$ in $20!$. Since we get a zero for every pair of factors $5\\cdot 2$, then the minimum of these will answer your question. More simply, $5$ happens less often as a factor (since it's bigger than $2$), so we need only count up the number of $5$'s. In particular, there's one each in $5,10,15,20$, so there are $4$ zeroes at the end.\n\nIf the problem had asked about $25!$, then there'd be $6$ zeroes--not $5$--because there are two factors of $5$ in $25$. Similar idea for other numbers.\n\nshare|improve this answer\nIt gets harder when you try it with bases other than 10. \u2013\u00a0 marty cohen Oct 18 '12 at 1:44\nThat's true, Marty, though not relevant to the context. \u2013\u00a0 Cameron Buie Oct 18 '12 at 1:52\nadd comment\n\nGeneral formula (for the interested) about the number of zeroes in n! in any base (b). First consider all prime factors of b, then consider the biggest one (p). Then use this formula.\n\n$\\lfloor n/p \\rfloor$ + $\\lfloor n/p^2 \\rfloor$ + $\\lfloor n/p^3 \\rfloor$ + ....\n\nThis and using the fact that, the floor becomes zero after some exponent, you can calculate the number of zeroes in any base.\n\n\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/84671/minimum-distance-between-two-data-sets\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have two sets of data, $X$ and $Y$, each of which contains $10$ positive numbers. Now let us order the data sets $X=\\left\\{ x_{1},\\cdots,x_{10}\\right\\}$, $x_{1}\\ge\\cdots\\ge x_{10}>0$ and $Y=\\left\\{ y_{1},\\cdots,y_{10}\\right\\}$, $y_{1}\\ge\\cdots\\ge y_{10}>0$ and define $d:=\\sum_{k=1}^{10}\\left|x_{i_{k}}-y_{j_{k}}\\right|$, that is the sum of the distances of the numbers in pairs from the two data sets. Does anyone know how to prove that $d$ achieves its minimum when $i_{k}=j_{k}=k$ for $1\\le k\\le10$, or is there any counter example if it is not true? Thanks.\n\nshare|improve this question\nsame question was posted and was answered here: math.stackexchange.com/questions/95546/\u2026 \u2013\u00a0 Paul Jan 1 '12 at 11:29\nadd comment\n\n1 Answer\n\nHere is a slightly more general proof.\n\nLet $x$ be any vector in $R^n$. Let $x^\\downarrow$ denote the vector obtained from $x$ by sorting its entries in decreasing order, so that $x_1^\\downarrow \\ge x_2^\\downarrow \\ge \\cdots \\ge x_n^\\downarrow$. Now, let $x, z \\in R^n$, and consider $x+z$. Clearly, if we apply the same permutation to $x$ and $z$ separately, the entire sum $x+z$ is also permuted the same way. Hence, we may assume wlog that $x=x^\\downarrow$. Now, let $x$ be as in your question above, and let $z=-y$.\n\nRecall now the concept of majorization. A quick calculation (also see Theorem II.4.2 of Matrix Analysis by R. Bhatia) shows that $$x^\\downarrow + z^\\uparrow \\prec x + z$$ (since we assumed wlog that $x=x^\\downarrow$); also since $y=-z$ we obtain\n\n$$x^\\downarrow - y^\\downarrow \\prec x - y.$$\n\nBut this majorization implies that for any symmetric gauge function $G$, we have $$G(x^\\downarrow-y^\\downarrow) \\le G(x-y).$$ This then implies the original minimization claim if we choose $G=\\|\\cdot\\|_1$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/36165/electric-scooter-acceleration\nText:\nTake the 2-minute tour \u00d7\n\nI tested two electric scooters with almost same power (1500 W), but very different performances: A \"Zem Star 45\" (1500 W, 60 Nm) can reach 50 km/h in \"a few seconds\" (not measured actually), An \"Ingaeta Ingo\" (1500 W, ??? Nm) took more than 10 seconds to reach 50 km/h.\n\nHow much does torque affect acceleration performance?\n\nGiven two identical scooters (same weight, same engine power, same wheels size), rgardless of wheels and air friction, how can I calculate acceleration given the torque on a flat street?\n\nshare|improve this question\nI add: Star 45 has a 60V motor, Ingo has a 48V one. How does this relate to speed and acceleration? \u2013\u00a0 jumpjack Sep 12 '12 at 19:00\nadd comment\n\n2 Answers\n\nA typical electric motor has its torque varying linearly with speed. You can translate this through the gearbox into traction $F$ and speed $v$ to arrive at the acceleration function ignoring air resistance\n\n$$ a(v) = \\frac{F_0}{m} \\left( 1- \\frac{v}{v_f} \\right) $$\n\nwhere $F_0$ is the initial (peak) traction (relating to the peak torque of motor), and $v_f$ the top speed of vehicle (relating to zero load speed).\n\nTo get the time to reach a speed $v$ you do\n\n$$ t(v) = \\int_0^v \\frac{m/F_0}{ \\left( 1- \\frac{v}{v_f} \\right) }\\;{\\rm d}v = \\frac{m\\,v}{F_0} \\left(1-\\frac{v}{2\\,v_f} \\right) $$\n\ninverting yields\n\n$$ v(t) = v_f \\left( 1-\\sqrt{1-\\frac{2 F_0}{m v_f} t} \\right) $$\n\nIn addition, to get the distance traveled you do\n\n$$ x(v) = \\int_0^v \\frac{m v/F_0}{ \\left( 1- \\frac{v}{v_f} \\right) }\\;{\\rm d}v = \\frac{m v^2 (3 v_f-2 v)}{6 F_0 v_f} $$\n\ninverting yields\n\n$$ v(x) = \\frac{v_f}{2} + v_f \\sin\\left( \\frac{1}{3} \\sin^{-1}\\left( \\frac{12 F_0}{m v_f^2} x -1 \\right) \\right) $$\n\nEdit 1\n\nThe power produced by the motor is $$ P = T(\\omega)\\, \\omega = m\\, v\\, a(v) = F_0 v \\left( 1- \\frac{v}{v_f} \\right) $$ peak power occurs at $v=v_f$ with value $P_{peak} = F_0 v_f / 4 $\n\nshare|improve this answer\nA typical electric motor has constant torque. \u2013\u00a0 jumpjack Sep 12 '12 at 18:56\nIf it had constant torque then it would produce infinite power (as the speed increases). It has limited power as derived by $P = T(\\omega) \\omega = F(v) v$ \u2013\u00a0 ja72 Sep 13 '12 at 11:54\nadd comment\n\nThe force between the driven wheel and the road is given by:\n\n$$ F = ma = \\frac{\\tau}{r} $$\n\nwhere $\\tau$ is the torque and $r$ is the driven wheel radius, so the acceleration is:\n\n$$ a = \\frac{\\tau}{m \\space r} $$\n\nNB this is the torque at the wheel, while the torque the manufacturer quotes is normally the torque at the engine crankshaft. The torque at the wheel will depend on how much the engine speed is geared up or down.\n\nAt any speed greater than zero you need to subtract the aerodynamic drag off the force, but the simple expression for the acceleration - torque relation will be valid at low speeds.\n\nshare|improve this answer\nWhat about hub motors? \u2013\u00a0 jumpjack Sep 12 '12 at 18:58\nIt doesn't matter what type of motor it is. All that matters is the torque it produces at the wheel. \u2013\u00a0 John Rennie Sep 13 '12 at 6:13\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathhelpforum.com/advanced-statistics/134307-deriving-event-probability-discrete-time-interval-probability-time-series.html\nText:\nThe probability that I am smiling at any given point during the day is given by a function f(t) [note this is not a pdf but simply the probability of the event at a given time; thus 0<=f(t)<=1 but int_0^24 f(s) ds does not necessarily equal 1].\nWhat is the probability P that I will smile during a specific time interval[t1,t2] during the day?\nI have noted that:\nint_t1^t2 f(s) ds has units time and is not bounded above by 1;\nbreaking the time interval into smaller timesteps and treating the probability in each of these as independent (and then multipliying) gives arbitary results since it is dependent on the choice of time step;\ntaking the mean or maximum etc. of f(t) in the interval would mean that watching me for one minute or twenty four hours could have the same probability of success;\nobviously if f(t)=1 for any t in[t1,t2] then P=1 while if f(t)=0 for all t in[t1,t2] then P=0."}
{"text": "Retrieved from http://math.stackexchange.com/questions/266171/irreducibility-of-polynomial-if-no-root-capelli\nText:\nTake the 2-minute tour \u00d7\n\nThis question already has an answer here:\n\nLet $F$ be a field of arbitrary characteristic, $a\\in F$, and $p$ a prime number. Show that $$f(X)=X^p-a$$ is irreducible in $F[X]$ if it has no root in $F$.\n\nThis answer to a related question mentions the result is due to Capelli.\n\nI can prove the result if $F$ has characteristic $p$ as follows. Suppose $f$ is reducible: $f(X)=g(X)h(X)$ with $g(X)$ an irreducible factor of degree $m$, $1\\le m<p$. Then if $\\alpha$ is a root of $g$ in some extension field $K$ of $F$, we have $$f(X)=X^p-\\alpha^p=(X-\\alpha)^p$$ so its divisor $g(X)$ must be of the form $(X-\\alpha)^m$. Since the coefficient of $X^{m-1}$ in $g$ is in $F$, we have $m\\alpha\\in F$. So $\\alpha\\in F$ because $m$ is invertible modulo $p$.\n\nHow would you show the result in other characteristics?\n\nshare|improve this question\nadd comment\n\nmarked as duplicate by leo, Daniel Robert-Nicoud, Sujaan Kunalan, Davide Giraudo, Old John Nov 27 '13 at 21:53\n\n\n3 Answers\n\nup vote 3 down vote accepted\n\nA proof of this result can be found on page 297 of Lang's Algebra and goes as follows.\n\nLet $F$ be a field of characteristic $q \\neq p$. If $f(x)$ has no root in $F$, then it must be the case that $a$ is not a $p$ - th power in $F$. Suppose that $f(x)$ is reducible. By passing the larger extension $K = F(\\alpha)$ , we see that $\\alpha$ must have degree $d$ where $d < p$. Then $\\alpha^p = a$ and by applying $N_{K/F}(-)$ gives that $N_{K/F}(\\alpha)^p = a^d$ by multiplicativity of the field norm. Since $(d,p) = 1$ this means that $a$ is a power of $p$ in $F$, a contradiction.\n\nshare|improve this answer\nI'm curious though because I don't see where the hypothesis that the characteristic is not equal to $p$ is used. \u2013\u00a0 fpqc Dec 28 '12 at 1:33\nWhat I think: If the field is of characteristic $p$ then for any $a\\in F$ there is $b\\in F$ s.t $b^p=a$ hence $F(b)=b^p-a=a-a=0$ hence the polynomial is reducible \u2013\u00a0 Belgi Dec 28 '12 at 1:39\n@Belgi The Frobenius automorphism is surjective IIRC iff the field is finite. \u2013\u00a0 fpqc Dec 28 '12 at 1:40\nhmm yes, but we are not given that $F$ is not finite \u2013\u00a0 Belgi Dec 28 '12 at 1:41\n@Belgi Nor are we given that $F$ is finite. The point now is that $F$ is an arbitrary field of arbitrary characteristic. \u2013\u00a0 fpqc Dec 28 '12 at 1:42\nshow 11 more comments\n\nSuppose the characteristic of $F$ is not $p$. Let $\\Omega$ be the algebraic closure of $F$. By the assumption on the characteristic of $F$, $\\Omega$ has a primitive $p$-th root of unity $\\zeta$. Let $\\alpha$ be a root of $x^p - a$ in $\\Omega$. Since $\\alpha$ is not contained in $F$, $\\alpha \\neq 0$. Hence $\\alpha, \\alpha\\zeta, \\cdots, \\alpha\\zeta^{p-1}$ are distinct roots of $x^p - a$. Suppose $x^p - a = g(x)h(x)$, where $g(x)$ and $h(x)$ are monic polynomials in $F[x]$ and $1 \\le$ deg $g(x) \\lt p$. Let $k =$ deg $g(x)$. Let $b$ be the constant term of $g(x)$. Then $b = (-1)^k \\alpha^k \\zeta^m$, where $m$ is an integer. Hence $b^p = (-1)^{kp} a^k$ If $(-1)^{kp} = 1$, then let $c = b$. Suppose $(-1)^{kp} = -1$. If $p$ is odd, then let $c = -b$. If $p = 2$, then let $c = b$. In either case, $c^p = a^k$.\n\nLet $\\Gamma$ be the multiplicative group of $F$. Let $\\Gamma^p = \\{x^p |\\ x \\in \\Gamma\\}$. $\\Gamma^p$ is a subgroup of $\\Gamma$. Let $\\pi$ be the canonical homomorophism $\\Gamma \\rightarrow \\Gamma/\\Gamma^p$. Let $\\beta = \\pi(a)$. Since $x^p - a$ does not have a root in $F$, $\\beta \\neq 1$. On the other hand, $\\beta^p = \\pi(a^p) = 1$. Hence the order of $\\beta$ is $p$. However, since $c^p = a^k$, $\\beta^k = 1$. This is a contradiction. Hence $x^p - a$ is irreducible in $F[x]$.\n\nshare|improve this answer\nadd comment\n\n1) I can give you the details of a paper by Chebotarev translated from russian to german in which appears the Capelli Lemma, yet\n\n2) There's also a paper in italian by Capelli, from 1904, which details I can give you, yet\n\n3) The book \"Algebra I\", by R\u00e9dei, has the same lemma with extensions. Alas, the book was written in hungarian, though it seems to be there's a translation to german with, perhaps, the help of Halm\u00f6s.\n\nGoogling around a little there are several references to that lemma but, as far as I could see, none of the first ones, at least, brings the version you want.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/265650/finding-a-harmonic-function\nText:\nTake the 2-minute tour \u00d7\n\nI need to find a harmonic function in the region ${ {z: |z|<1: Imz>0} }$ whose boundary values are in 1 on the interval $(-1,1)$ and $0$ on the half- circle.\n\nI have no clue, where to start!\n\nI do not think I can proceed like as I used to for finding conformal mapping.\n\nI do not mind getting details since this one of the qual question. Any help much appreciated.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nFirst, find a conformal map from the half-disk to the upper half plane, making sure that the half circle is sent to the positive real half-line, and the diameter of the half-disk is sent to the negative real half-line. (Hint: look at the map $z \\mapsto - \\frac{1}{2}(z + z^{-1})$). Let's call this map $\\Phi$.\n\nSecond, consider the Arg function (or, if you like, the imaginary part of the logarithm with a suitable branch cut making it analytic on the upper half plane). Define your Arg so as to assign the value zero to the positive half line and $\\pi$ to the negative half line.\n\nThird, having done all this, you've concocted a harmonic function $u$ on the upper half plane. Now form $u \\circ \\Phi$, which takes on the correct boundary values.\n\nshare|improve this answer\nWould you please prove more rigorously please. I kind of lost in the second and third part. \u2013\u00a0 Deepak Dec 27 '12 at 0:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209842/simple-way-for-solving-generic-work-and-time-problems\nText:\nTake the 2-minute tour \u00d7\n\nI was looking for a general way of formulating solutions for work and time problems.\n\nFor example,\n\n30 soldiers can dig 10 trenches of size 8*3*3 ft in half a day working 8 hours per day. How many hours will 20 soldiers take to dig 18 trenches of size 6*2*2 ft working 10 hours per day?\n\nNow i know that Work = Efficiency * Time, but i get confused sometimes in selecting which factor in the given problem will contribute directly to the work i.e. increase it and which factors will result in the work being done faster.\n\nI've seen the method in which one uses a table to write all the parameters given in the problem e.g. making columns titled work, number of soldiers, volume of trench, number of days required, number of hours per day, efficiency, wages etc and uses the direct and inverse proportionality to write the equation for solving a given unknown. However i face the same problem i.e. finding out which factors are directly related and which are in an inverse relation.\n\nIs there a simple way of solving these general problems?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\n$30$ soldiers can dig $10$ trenches of size $8\\cdot 3\\cdot 3$ cube fit in $4$ hours.\n\n$1$ soldier can dig $10$ trenches of size $8\\cdot 3\\cdot 3$ cube fit in $4\\cdot 30$ hours.\n\n$1$ soldier can dig $1$ trench of size $8\\cdot 3\\cdot 3$ cube fit in $\\frac{4\\cdot 30}{10}$ hours.\n\n$1$ soldier can dig $1$ trench of size $1\\cdot 1\\cdot 1$ cube fit in $\\frac{4\\cdot 30}{10\\cdot 8\\cdot 3\\cdot 3}$ hours.\n\n$20$ soldiers can dig $18$ trenches of size $6\\cdot 2\\cdot 2$ cube fit in $$\\frac{4\\cdot 30\\cdot 18\\cdot 6\\cdot 2\\cdot 2}{10\\cdot 8\\cdot 3\\cdot 3\\cdot 20}=\\frac{36}{10}=3.6$$ hours which is clearly $<10$ hours.\n\nThe number of trenches and the size of trenches are directly proportional to the time, but the number of soldiers is inversely roportional to the time, the more the number of soldiers, the lesser is the time.\n\nshare|improve this answer\n@BrianM.Scott, thanks for your observation. \u2013\u00a0 lab bhattacharjee Oct 10 '12 at 5:00\nadd comment\n\nIdentify the basic assumptions. In this problem it\u2019s clear that soldiers are considered interchangeable: they all work at the same rate. (Recall that in some problems we have different workers working at different rates and have to keep track of the work rate of each worker. And it\u2019s the work rates that are important, because they\u2019re additive: if $A$ and $B$ have work rates of $r$ and $s$ amount of work per unit of time, then $A$ and $B$ working together have a combined work rate of $r+s$.) It\u2019s also clear the amount of work is being measured in cubic feet dug, and that cubic feet are to be considered interchangeable: they\u2019re all equally hard to dig. Finally, the basic unit of time here is the hour, since we\u2019re dealing with working days of two different lengths in hours.\n\nNow convert the initial data to basic units. We have $30$ soldiers doing the work. They dig $10$ trenches of $8\\cdot3\\cdot3$ cubic feet each, for a total of $720$ cubic feet of earth dug, and they do it in half of an $8$-hour day, or $4$ hours.\n\nAt this point we can calculate their combined work rate: $720$ cubic feet in $4$ hours is $\\frac{720}4=180$ cubic feet per hour. But that\u2019s the combined work rate of $30$ interchangeable soldiers, so each soldier is digging only $\\frac1{30}$-th of that, or $\\frac{180}{30}=6$ cubic feet per hour.\n\nNow let\u2019s take a look at the question (which we should have had in the backs of our minds all along as a guide to what\u2019s relevant and what\u2019s likely to be useful). We have $20$ soldiers available. We want to dig $18$ trenches, each $6\\cdot2\\cdot2$ cubic feet in size, so we want to move $18\\cdot6\\cdot2\\cdot2=432$ cubic feet of earth. Finally, we want to know how long this will take. We know that one soldier digs $6$ cubic feet per hour, so $20$ soldiers dig $20\\cdot6=120$ cubic feet per hour. It will therefore take them $\\frac{432}{120}=3.6$ hours, considerably less than one $10$-hour working day.\n\nshare|improve this answer\nThanks for the explanation. \u2013\u00a0 Karan Oct 10 '12 at 14:59\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/442326/math-olympiad-problem\nText:\nTake the 2-minute tour \u00d7\n\nA year is peculiar if the sum of the first two digits and the last two digits is equal to the middle two digits. For example, 1978. When was the last peculiar year and is there an algorithm to find any peculiar year?\n\nHow would I go about solving this problem? I am completely lost. Any ideas would help.\n\nshare|improve this question\nfor i=0 to 2013; If ... then print ... \u2013\u00a0 Lord Soth Jul 12 '13 at 20:45\n@LordSoth are you suggesting to put leading zeros to those years with number of digits less than 4, since you've started from 0? \u2013\u00a0 Mathlovin Jul 12 '13 at 20:52\n@LordSoth: Starting in 1978 seems like a much better idea. Or just going backwards from 2013. \u2013\u00a0 Chris Eagle Jul 12 '13 at 20:52\n@MathApprentice I have written the code for you. $1978$ is the last one we saw. Unfortunately we need to wait for another $294$ years (note that we would be dead by then) to see the next one, $2307$. \u2013\u00a0 Lord Soth Jul 12 '13 at 20:56\nGuys, I think all of you are missing one important thing \u2013 this is/was a math problem, not a 5-th grade programming problem, so it needs to be solved somehow analytically and somewhat intuitively. As a starter, if $\\overline{abcd}$ your number, where $0 < a \\le 9,\\, 0 \\le a,b,c \\le 9$ and $a,b,c,d \\in \\mathbb N$, then the condition might be written as $$ 10a + b + 10c + d = 10b + c $$ So, one might try to solve it using divisibility or whatever. \u2013\u00a0 Mathlovin Jul 12 '13 at 21:04\nshow 1 more comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThere is no peculiar year in the 21st century, since the middle two digits form a 1 digit number.\n\nIn the 20th century, any year is of the form $19xy$. Then the year is peculiar if and only if\n\n$$19+xy=9x \\Leftrightarrow 19+10x+y=90+x \\Leftrightarrow 9x+y=71 \\,.$$\n\nThen since $0 \\leq y \\leq 9$ we get\n\n$$9x \\leq 71 \\leq 9x+9 \\Rightarrow 62 \\leq 9x \\leq 71 \\Rightarrow x=7 \\,.$$\n\nPlugging $x=7$ in $9x+y=71$ we get that $y=8$.\n\nThus, the only peculiar year in 20's century is 1978.\n\nIf the question asks for the peculiar year before 1978, it must be in the 19th century or before:\n\n\nIn the 19th century, any year is of the form $18xy$. Then the year is peculiar if and only if\n\n$$18+xy=8x \\Leftrightarrow 18+10x+y=80+x \\Leftrightarrow 9x+y=62 \\,.$$\n\n\n$$9x \\leq 62 \\leq 9x+9 \\Rightarrow 53 \\leq 9x \\leq 62 \\Rightarrow x=6 \\,.$$\n\nPlugging $x=6$ in $9x+y=62$ we get that $y=8$.\n\nThus in the 19th century the only peculiar year is $1868$.\n\nP.S. Any peculiar year of the form $1abc$ satisfies\n\n$$10+a+10b+c=10a+b \\Rightarrow 9a-9b-c=10$$\n\nThis implies that $c \\equiv -1 \\pmod{9}$ thus $c=8$ and then\n\n$$a-b=2 \\,.$$\n\nFrom here you get easily all the peculiar years between $1000$ and $1999$.\n\nP.P.S. If you are looking for all $4$ digits answers $abcd$ then you need to solve\n\n$$10a+b+10c+d=10b+c \\Rightarrow 10a+d= 9(b-c) \\,.$$\n\n\n$$a+d \\equiv 0 \\pmod 9 \\,,$$ and any pair $(a,d)$ which satisfies this relation uniquely determine $b-c$.\n\nSo fixing $a$ you get the value(s) of $d$ and from here $b-c$.\n\nshare|improve this answer\nThe answer is getting too long, so added this as a comment. The $a+d \\equiv 0 \\pmod 9$ is pretty obvious if you are familiar with $\\pmod 9$ arithmetic: $$a+b+c+d \\equiv ab+cd \\equiv bc \\equiv b+c \\pmod 9 $$ \u2013\u00a0 N. S. Jul 12 '13 at 21:29\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/41236/deriving-the-poynting-theorem/41240\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to derive the Poynting theorem. So far, I've only been able to narrow down which equations I think I'll need to do so. These are the equations:\n\nMaxwell's Equations: $$ \\nabla\\times{\\bf E} = - {{\\partial{\\bf B}}\\over{\\partial t}} $$ $$ \\nabla\\times{\\bf H} = {\\bf J} + {{\\partial{\\bf D}}\\over{\\partial t}} $$ Equations relating the flux densities and fields: $$ \\bf D = \\epsilon_0\\bf E + \\bf P $$ $$ \\bf B = \\mu_0\\bf H + \\mu_0\\bf M $$ The vector identity: $$ \\nabla\\cdot (\\bf E\\times\\bf H) = (\\nabla\\times\\bf E)\\cdot \\bf H - (\\nabla\\times\\bf H)\\cdot \\bf E $$ Using these equations, I need to obtain Poynting's theorem, which is given as: $$ \\nabla\\cdot\\bf S = -\\frac{\\partial}{\\partial t}(\\frac{1}{2}\\epsilon_0\\bf E^{2}+\\frac{1}{2}\\mu_0\\bf H^{2})+\\bf E\\cdot\\frac{\\partial\\bf P}{\\partial t}+\\mu_0\\bf H\\cdot\\frac{\\partial\\bf M}{\\partial t} $$ Could someone please help me out?\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 1 down vote accepted\n\nFirst of all, I think you're missing a $-\\textbf{J}.\\textbf{E}$ term in the RHS of your final expression. The rest of the expression looks fine.\n\nI present here some general guidelines on how to approach this derivation. As per the homework guidelines of stackexchange I will not provide all the steps. Others are welcome to correct me on this if I have not completely understood the guidelines. I understand that solving coupled equations using vector calculus can be overwhelming and error-prone. Therefore, I will provide \u201canchor points,\u201d which are nothing but validation steps that you are heading in the right direction. My TA used this technique. If you are getting some horrible terms, which I failed to mention, then it is \u201cprobably\u201d time to step back and recheck your calculations. The reason I say \u201cprobably\u201d is because it is possible that you come up with an alternate derivation. I think the one I worked out is the simplest one. Here it is:\n\nYou can observe that the identity is nothing but:\n\n$$\\nabla.\\textbf{S}=(\\nabla \\times \\textbf{E}).\\textbf{H}-(\\nabla \\times \\textbf{H}).\\textbf{E}$$\n\nThe two terms on the RHS of the above equation should give a hint as to which equations you should manipulate first. Where in the above list can you find $\\nabla \\times \\textbf{E}$ or $\\nabla \\times \\textbf{H}$? You\u2019ll need to bring those equations in that form first, i.e. the form $(\\nabla \\times \\textbf{E}).\\textbf{H}$ and $(\\nabla \\times \\textbf{H}).\\textbf{E}$ and then substitute their modified RHS in the identity. After all these manipulations, say you have obtained a form (*). You can observe that the RHS of (*) has time derivatives. You can now start seeing that (*) is closer to the form that you want. You will now need to use $\\textbf{D}= \\epsilon_0 \\textbf{E}+\\textbf{P}$ and $\\textbf{B}= \\mu_0 (\\textbf{H}+\\textbf{M})$ in (*) in the time derivatives. Yes, you are missing the latter in the above list. After a little bit of simplification, you will need to obtain a contracted form. I will show one (of the two):\n\n$$\\textbf{E}.\\frac{\\partial \\textbf{E}}{\\partial t} = \\frac{\\partial}{\\partial t}\\left(\\frac{1}{2}\\textbf{E}^2\\right)$$\n\nAfter performing a similar manipulation for the magnetic field term, you will obtain the desired expression (with the missing $-\\textbf{J}.\\textbf{E}$).\n\nshare|improve this answer\nadd comment\n\nPoynting's theorem is the statement of the conservation of energy and momentum for a system of charged particles and electromagnetic fields.\n\nYou're on the right track. A definition should help you get the theorem into standard from: $u = \\frac{1}{2}(\\mathbf{E}\\cdot\\mathbf{D} + \\mathbf{B}\\cdot\\mathbf{H})$. (Up to some constants like $\\mu_0$, $\\epsilon_0$ and $4\\pi$.)\n\nThe result you're looking for is: \\begin{align} \\frac{\\partial u}{\\partial t} + \\nabla\\cdot\\mathbf{S} = -\\mathbf{J}\\cdot\\mathbf{E}. \\end{align}\n\nBest of luck.\n\nshare|improve this answer\nadd comment\n\nWell, trying to get in the form of what Mark Wayne put down...you can start with the dfinition of the energy density \"u\" and find the partial wrt time. From there you can use Maxwell's Equations to make some substitutions. Finally in the end you will NEED a not so known/popular vector identity to give you the (ExB) term. Good luck...not a bad derivation at all :)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141999/series-solution-near-ordinary-points-for-second-order-differential-equations?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nGiven $(1+x^2)y''+2xy'-2y = 0$\n\nThe above equations obviously has analytic points everywhere except for $x=1$ and $-1$.\n\nFind two linearly independent solutions $y_1$ and $y_2$ to the differential equation valid near $x_0=0$. To make life a little easier, choose the linearly independent equations:\n\n$y_1$ $:$ $a_0$ = $y(x_0)$ = 1 and $a_1$ = $y'(x_0)$ = 0\n\n$y_2$ $:$ $a_0$ = $y(x_0)$ = 0 and $a_1$ = $y'(x_0)$ = 1\n\nAfter a mess of writing, I came up with the following:\n\n$a_{n+2}$ = $[{-(n-1)(n)a_n - 2a_n(n-1)}]/[{(n+1)(n+2)}]$\n\nI don't know if that monster is right, but that's where I need you help. Can somebody give this a sanity check, and then solve the rest?\n\nshare|improve this question\nSome more detail would be nice. What did you get after substituting your power series ansatz into your differential equation? \u2013\u00a0 \uff2a. \uff2d. May 7 '12 at 1:43\nI checked the series solution myself, your expression of $a_{n+2}$ looks correct to me. \u2013\u00a0 Shuhao Cao May 7 '12 at 2:14\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nIf we set up $y = \\displaystyle \\sum^{\\infty}_{n=1} a_n x^n$ like you did, plugging back to the original equation: $$ (-2a_0+2a_2) + 6a_3 x +\\sum^{\\infty}_{n=2}\\Big((n+2)(n+1)a_{n+2} - (n-1)(n+2)a_n\\Big)x^n = 0 $$ simplify the expression for $a_{n+2}$ when $n\\geq 2$: $$ a_{n+2} = -\\frac{n-1}{n+1} a_n \\qquad (*) $$ for the constant and $x$-term we have: $$ a_0 = a_2, \\text{ and } a_3 = 0 $$\n\n  \u2022 Now if the initial condition is $a_0 = 1, a_1 = 0$, then we have: $$ a_2 = 1, \\text{ and } a_{n+2} = (-1)^{n/2}\\frac{n-1}{n+1}\\cdot \\frac{n-3}{n-1}\\cdots\\frac{1}{3} = \\frac{(-1)^{n/2}}{n+1} $$ and $n$ can be even numbers, let $n = 2k$ we have the solution is: $$ y = 1+x^2 + \\sum^{\\infty}_{k=1}\\frac{(-1)^k x^{2k+2}}{2k+1} = 1 + x\\cdot \\sum^{\\infty}_{k=0}\\frac{(-1)^k x^{2k+1}}{2k+1} = 1+ x\\arctan x $$\n\n  \u2022 Now if the initial condition is $a_0 = 0, a_1 = 1$, $a_2 = a_0 = 0$ implies all even powered $x$ coefficients are zero after $n=2$ because of the relation $(*)$, also by $(*)$ and $a_3 = 0$ we know that all odd powered $x$ coefficients are zero too after $n=3$, therefore the solution is just: $$ y = x $$\n\nTo sum up, the two linearly independent solutions are: $$y = x \\;\\text{ or }\\; 1+ x\\arctan(x)$$\n\nshare|improve this answer\nThanks Jon. The only reason why I got stuck was because the simplification threw me off. It was late and I didn't even think to simplify (in fact I thought it was already simplified). Anyway, thanks again. \u2013\u00a0 Nico Bellic May 7 '12 at 14:16\n@NicoBellic Haha, no problem, btw I love GTA4 too! \u2013\u00a0 Shuhao Cao May 7 '12 at 17:01\nHaha, nice few people recognize the reference. \u2013\u00a0 Nico Bellic May 7 '12 at 18:16\nThe power series method works well provided I can solve the recursion relation. All the textbook examples usualy lead to a recursion that involves two coefficients only ( in this case $a_{n+2}$ and $a_n$). However, in most real world examples this is not the case, ie $a_{n+2}$ is usualy a function of $a_n$ and som other values of $a$ with lower indices. How do I solve the recursion relation then? Or in other words how would I go about solving an equation $(1 + x^2)y^{''} + 2 x y^{'} -2 x y =0$ using the power expansion method? \u2013\u00a0 Przemo Feb 12 at 16:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96649/smooth-quadric-over-p-adic-integers\nText:\nTake the 2-minute tour \u00d7\n\nLet $k$ be a $p$-adic field with ring of integers $\\mathcal{O}_K$ and residue field $\\mathbb{F}$. Say I have a (projective) quadric $Q$ which is smooth over $\\mathcal{O}_K$, such that the reduction $\\bar{Q}$ (smooth over $\\mathbb{F}$) contains a line $\\cong \\mathbb{P}^1$ defined over $\\mathbb{F}$. Does it follow that $Q$ contains a line $\\cong \\mathbb{P}^1$ defined over $\\mathcal{O}_K$?\n\nIf yes, I guess this would somehow follow from Hensel's lemma, but I'm not sure how exactly.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nYes, for the reason you give. The Hilbert scheme of lines in $Q$ is smooth over $\\mathcal O_K$ (the obstruction to smoothness lies in $H^1$ of a normal bundle $\\mathcal N$; the homogeneity of $Q$ shows that $\\mathcal N$ is generated by $H^0$, so has $H^1=0$ from the classification of bundles on $\\mathbb P^1$). Now apply Hensel's lemma to this Hilbert scheme.\n\nshare|improve this answer\nOk, great answer! \u2013\u00a0 Wanderer May 11 '12 at 10:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/32802/modular-equations-system?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI have the following task - I have to find all a for which the following system has a solution:\n\n$x \\equiv 1\\pmod 2$\n\n$x \\equiv 2\\pmod 3$\n\n$x \\equiv a\\pmod 5$\n\nI will be very grateful if someone show me the principle behind solving this. By the way, I have some guesses that maybe the LCM is involved.\n\nP.S If I knew the a, how would I solve the system?\n\nThanks in advance!\n\nshare|improve this question\nIt has a solution for any a. See en.wikipedia.org/wiki/Chinese_remainder_theorem \u2013\u00a0 Martin Sleziak Apr 13 '11 at 16:37\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nThe principle is essentially the Chinese Remainder Theorem. Because the moduli are pairwise coprime, there is a solution for any value of $a$.\n\nBut suppose you didn't know the value of $a$. One way to proceed is the following (which is often a faster way of solving such systems rather than the constructive proof of the Chinese Remainder Theorem):\n\nIf $x\\equiv 1\\pmod{2}$, then you must have $x = 1+2r$ for some integer $r$. Plugging that into the second congruence, you have $1+2r\\equiv 2\\pmod{3}$, or $2r\\equiv 1 \\pmod{3}$. Multiplying through by $2$ we get $r\\equiv 2 \\pmod{3}$, so $r$ must be of the $r=2+3s$. Plugging that into $x$, we get that $x$ must be of the form $x = 1+2r = 1+2(2+3s) = 1+4+6s = 5+6s$.\n\nFinally, we plug that into the final congruence. It gives $5+6s\\equiv a\\pmod{5}$, which is equivalent to $s\\equiv a\\pmod{5}$. This can always be solved, $s=a+5k$, so the system always has a solution. The solution(s) is $x=5+6s = 5+6(a+5k) = 5+6a + 30k$. that is, $x\\equiv 5+6a\\pmod{30}$.\n\nshare|improve this answer\nThanks for the help! \u2013\u00a0 Petar Minchev Apr 13 '11 at 18:01\nadd comment\n\nThis system of modular equations can be solved by inspection - without rote application of CRT. The first two equations are $\\rm\\ x \\equiv -1\\ (mod\\ 2,3)\\ $ therefore they are equivalent to $\\rm\\ x\\equiv -1\\ (mod\\ 6)\\:.\\:$ To solve this and the remaining equation is easy because the moduli $\\rm\\ m=5\\:,\\ n=6\\ $ are such that one has an obvious inverse modulo the other, viz. $\\rm\\:6\\equiv 1\\ (mod\\ 5)\\:$ hence $\\rm\\:6^{-1}\\equiv 1^{-1}\\ \\equiv 1\\ (mod\\ 5)\\:.\\:$ Therefore, applying EasyCRT below with $\\rm\\:b = -1\\:$ we conclude $$\\rm\\ x\\ \\equiv\\ b + n\\ \\bigg[\\frac{a-b}{n}\\ mod\\ m\\bigg]\\ \\equiv\\ -1 + 6\\ (a+1)\\ \\equiv\\ 5+6a\\ \\ (mod\\ 30)\\:.$$\n\nThese special cases of CRT, where the RHS is constant, and where one modulus has obvious inverse mod the other, are well worth knowing, since they arise frequently in practice, so they often go a long way towards shortening manual calculations. Below is the EasyCRT that I employ to easily compute the solution when one modulus $\\rm\\:n\\:$ has obvious inverse mod the other $\\rm\\:m\\:.$\n\nTHEOREM (EasyCRT) $\\rm\\ \\ $ If $\\rm\\ m,\\:n\\:$ are coprime integers then $\\rm\\ n^{-1}\\ $ exists $\\rm\\ (mod\\ m)\\ \\ $ and\n\n$\\rm\\displaystyle\\quad\\quad\\quad\\quad\\quad x\\equiv a\\ (mod\\ m),\\ \\ x\\equiv b\\ (mod\\ n)\\ \\ \\iff\\ \\ x\\ \\equiv\\ b + n\\ \\bigg[\\frac{a-b}{n}\\ mod\\ m\\:\\bigg]\\ \\ (mod\\ m\\:n)$\n\nProof $\\rm\\ (\\Leftarrow)\\ \\ \\ mod\\ n\\::\\ x\\equiv b + n\\ (\\cdots)\\equiv b\\:,\\ $ and $\\rm\\ mod\\ m\\::\\ x\\equiv b + (a-b)\\ n/n \\equiv a\\:.$\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/18268/consecutive-birthdays-probability\nText:\nTake the 2-minute tour \u00d7\n\nLet $n$ be a number of people. At least two of them may be born on the same day of the year with probability: $$1-\\prod_{i=0}^{n-1} \\frac{365-i}{365}$$\n\nBut what is the probability that at least two of them are born on two consecutive days of the year (considering December 31st and January 1st also consecutive)? It seems a good approximation is: $$1-\\prod_{i=0}^{n-1} \\frac{365-2 \\times i}{365}$$\n\nHowever, simulating pseudo-random integers with Python, the 99%-confidence intervals may be slightly different. So do you have any closed formula?\n\nResults of the simulation with Python. Here are 99%-confidence intervals below:\n\nNumber of people:  1    Lower bound: 0.0        Upper bound: 0.0\nNumber of people:  2    Lower bound: 0.00528    Upper bound: 0.00567\nNumber of people:  3    Lower bound: 0.01591    Upper bound: 0.01657\nNumber of people:  4    Lower bound: 0.03185    Upper bound: 0.03277\nNumber of people:  5    Lower bound: 0.0528     Upper bound: 0.05397\nNumber of people:  6    Lower bound: 0.07819    Upper bound: 0.07959\nNumber of people:  7    Lower bound: 0.10844    Upper bound: 0.11006\nNumber of people:  8    Lower bound: 0.14183    Upper bound: 0.14364\nNumber of people:  9    Lower bound: 0.17887    Upper bound: 0.18086\nNumber of people: 10    Lower bound: 0.21816    Upper bound: 0.2203\nNumber of people: 11    Lower bound: 0.25956    Upper bound: 0.26183\nNumber of people: 12    Lower bound: 0.30306    Upper bound: 0.30544\nNumber of people: 13    Lower bound: 0.34678    Upper bound: 0.34925\nNumber of people: 14    Lower bound: 0.39144    Upper bound: 0.39397\nNumber of people: 15    Lower bound: 0.43633    Upper bound: 0.4389\nNumber of people: 16    Lower bound: 0.48072    Upper bound: 0.48331\nNumber of people: 17    Lower bound: 0.52476    Upper bound: 0.52734\n\nI give here some results with a tweaked approximation formula, using Wolfram Alpha: $$\\left( 1 - \\frac{n-1}{2 \\times 365 + n-1} \\right) \\times \\left( 1-\\prod_{i=0}^{n-1} \\frac{365-2 \\times i}{365} \\right)$$\n\nHowever, this is just a tweak, ans is clearly wrong for $n=33$ since:\n\nNumber of people: 33    My guess: 0.91407\nNumber of people: 33    Lower bound: 0.94328    Upper bound: 0.94447\n\nThanks to Jacopo Notarstefano, leonbloy, and Moron, here is the (correct) formula: $$ 1-\\sum_{k=1}^{n}\\frac{1}{365^{n-k}k}\\left(\\prod_{i=1}^{k-1}\\frac{365-\\left(k+i\\right)}{365\\times i}\\right)\\sum_{j=0}^{k-1}\\left(-1\\right)^{j}C_{k}^{j}\\left(k-j\\right)^{n} $$\n\nAnd here are the results of the computations using this formula with Python:\n\nNumber of people:  1    Probability: 0.0\nNumber of people:  2    Probability: 0.005479452\nNumber of people:  3    Probability: 0.016348283\nNumber of people:  4    Probability: 0.032428609\nNumber of people:  5    Probability: 0.053459591\nNumber of people:  6    Probability: 0.079104502\nNumber of people:  7    Probability: 0.108959718\nNumber of people:  8    Probability: 0.14256532\nNumber of people:  9    Probability: 0.179416899\nNumber of people: 10    Probability: 0.218978144\nNumber of people: 11    Probability: 0.260693782\nNumber of people: 12    Probability: 0.304002428\nNumber of people: 13    Probability: 0.34834893\nNumber of people: 14    Probability: 0.393195856\nNumber of people: 15    Probability: 0.438033789\nNumber of people: 16    Probability: 0.482390182\nNumber of people: 17    Probability: 0.525836596\nNumber of people: 18    Probability: 0.567994209\nNumber of people: 19    Probability: 0.608537602\nNumber of people: 20    Probability: 0.647196551\nNumber of people: 21    Probability: 0.683756966\nNumber of people: 22    Probability: 0.718059191\nNumber of people: 23    Probability: 0.749995532\nNumber of people: 24    Probability: 0.779509664\nNumber of people: 25    Probability: 0.806569056\nNumber of people: 26    Probability: 0.831211564\nNumber of people: 27    Probability: 0.853561895\nNumber of people: 28    Probability: 0.873571839\nNumber of people: 29    Probability: 0.892014392\nNumber of people: 30    Probability: 0.906106867\nNumber of people: 31    Probability: 0.919063161\nNumber of people: 32    Probability: 0.928791992\nNumber of people: 33    Probability: 0.944659069\nshare|improve this question\nThe reason your first formula doesn't work is this: if two people have the same birthday, then they only exclude two days between them, not four. I can't see what your second formula is trying to do. \u2013\u00a0 TonyK Jan 20 '11 at 10:09\nThanks. For information, the second formula is just the result of playing with the simulation and the results. It seems okay for small n, but just an approximation of the expected result. \u2013\u00a0 Wok Jan 20 '11 at 10:11\nI wish people didn't ask questions like this. I have work to do! \u2013\u00a0 TonyK Jan 20 '11 at 10:16\nI'll tell my friend to stop asking me intractable problems: he does not know the answer and I am not sure there is a nice formula. Sorry. \u2013\u00a0 Wok Jan 20 '11 at 11:18\nThe second formula is wrong but is a nice try: it corresponds to count all the possible ways of placing the n birthdays, taking into count that each new birthday removes two possibilities. But this is incorrect because it may happen that a new birthday just removes one possibiliy (or none!) It must be a good approximation for small n. \u2013\u00a0 leonbloy Jan 20 '11 at 11:58\n\n3 Answers 3\n\nup vote 9 down vote accepted\n\nI believe we can give a formula, but I would not call it \"closed form\".\n\nWe have $\\displaystyle n$ people, and $\\displaystyle k$ possible birthdays to choose from (i.e. $\\displaystyle k$ days in a year). Let $\\displaystyle M$ be the minimum of the two.\n\nWe will try and count the number of birthday assignments in which no two people have consecutive birthdays.\n\nTo do this, we will try and count the assignments which use exactly $d$ distinct birthdays, for $\\displaystyle d=1, 2 \\dots, k$, and then add them up.\n\nNow suppose we had a set of $\\displaystyle d$ distinct birthdays (don't worry about the consecutive part, just yet). How many ways can we assign these $\\displaystyle d$ birthdays to $\\displaystyle n$ people, so that each birthday is used at least once?\n\nThis is basically the problem of finding the number of ways to partition a set of size $\\displaystyle n$ in exactly $\\displaystyle d$ non-empty parts and assign the $\\displaystyle d$ birthdays to each part in the partition, exactly one to each.\n\nThe number of ways to partition a set of size $\\displaystyle n$ into $\\displaystyle d$ non-empty parts is given by a Stirling Number of Second Kind, $S(n,d)$. The number of ways to assign $\\displaystyle d$ birthdays is $\\displaystyle d!$.\n\nThus the number we are looking for is $\\displaystyle S(n,d) \\times d!$.\n\nNow suppose we managed to count the number of subsets containing $\\displaystyle d$ elements (from the $\\displaystyle k$ birthdays) such that no two elements of the set are consecutive, then we could multiply that number by $\\displaystyle S(n,d) \\times d!$ to give the number of birthday assignments which use exactly $\\displaystyle d$ birthdays such that no two are consecutive.\n\nFor the moment, ignore the fact that Jan 1 and Dec 31 are consecutive.\n\nWe need to select $\\displaystyle d$ numbers from $\\displaystyle 1,2, \\dots, k$ such that no two are consecutive.\n\nNow if $\\displaystyle b_1 \\lt b_2 \\lt \\dots \\lt b_d$ were such numbers, then notice that\n\n$\\displaystyle 1 \\le b_1 \\lt b_2 - 1 \\lt b_3 - 2 \\dots \\lt b_d - (d-1) \\le k-(d-1)$ gives us a way to select numbers from $\\displaystyle 1, 2, \\dots, k-(d-1)$ without having to bother about the consecutive issue.\n\nThis can be done in $\\displaystyle {k-d+1 \\choose d}$ ways.\n\nNow since Jan 1 and Dec 31 are consecutive, we need to subtract from this, the number of sets which contain both $\\displaystyle 1$ and $\\displaystyle k$.\n\nThis number is same as the number of $\\displaystyle d-2$ non-consecutive subsets of $\\displaystyle \\{3, \\dots, k-2\\}$ which is $\\displaystyle {k-d-1 \\choose d-2}$.\n\nThus the number of ways of selecting $\\displaystyle d$ non-consecutive birthdays (assuming $\\displaystyle 1$ and $\\displaystyle k$ are consecutive) is $\\displaystyle {k-d+1 \\choose d} - {k-d-1 \\choose d-2}$, with the understanding that the term being subtracted is $\\displaystyle 0$ for $\\displaystyle d = 1$ and that $\\displaystyle {a \\choose b} = 0$ if $\\displaystyle a \\lt b$\n\nThus, for $\\displaystyle M = \\text{min}\\{n,k\\}$, the total number we are looking for is,\n\n$$ \\sum_{d=1}^{M} S(n,d)\\times d! \\times \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)$$\n\nNote that $\\displaystyle S(n,d) \\ d! = \\sum_{j=0}^{d} (-1)^j {d \\choose j} (d-j)^n$\n\nSo we could also write the formula as\n\n$$ \\sum_{d=1}^{M} \\left(\\sum_{j=0}^{d} (-1)^j {d \\choose j} (d-j)^n\\right) \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)$$\n\nwhich is a bit ugly.\n\nThus the probability you are looking for is\n\n$$1 - \\frac{ \\sum_{d=1}^{M} S(n,d)\\times d! \\times \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)}{k^n}$$\n\nshare|improve this answer\nWhat I don't get is \"We have n people, and k birthdays.\" In my \"experiment\", I have n (fixed) people, each with a random birthday. The set of distict birthdays (which also appeared in my deduction) is a random number, not an input. Perhaps I'm missing something. \u2013\u00a0 leonbloy Jan 20 '11 at 23:37\n@leon: $k = 365$ in our case. Have edited to make it clearer. \u2013\u00a0 Aryabhata Jan 20 '11 at 23:40\n@leon: I see where your confusion might be. We are using similarly named variables, but they mean different things in our answers. For instance, your $k$, is my $d$. Your $M$ is my $k$. btw, I have confirmed that your answer and my answer give the same answer. Also, in your answer, instead of $Q(n,k)$, you perhaps meant $Q(M,k)$. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:31\n+1 for thorough explanations. I believe all three answers are great! Yet yours would be the most pedagogical one. \u2013\u00a0 Wok Jan 21 '11 at 15:44\n@Moron: right, thanks for the correction, fixed. I prefered to expressed it in that way (Q individualized) to emphasize that it's a probability \u2013\u00a0 leonbloy Jan 21 '11 at 18:01\n\nNB: I worked earlier on this problem and came up with the following solution. The first answer that was posted made me think that I got something wrong, and I discarded my work. Since the new answer by Moron agrees (essentially) with my previous work here it is, a slightly different derivation of the same formula.\n\nLet $k$ be the number of days in a year. Let $m$ be the distinct number of birthdays among the $n$ friends. Let's assume that $k$ is big enough to have a non-trivial problem (say, $k > n/2$)\n\nWe're interested in binary strings with these three conditions:\n\n  1. Are of length $k$, with $m$ ones and $k-m$ zeros.\n  2. There's at least one zero between any two ones.\n  3. Condition 2 holds when \"wrapping around\" the string.\n\nLet's count them by constructing them with the following algorithm:\n\n  \u2022 Start with a string of $m$ ones: $11\\dots 1$\n  \u2022 There are now three distinct cases: there's a birthday on the first day of the year, there is a birthday on the last day of the year, there's a birthday on neither.\n  \u2022 In the first case we have to distribute $k-m$ zeros in $m$ non-empty buckets. Those are called compositions, and one can show that there are $\\binom{k-m-1}{m-1}$ such assignments.\n  \u2022 The second case is analogous, giving another $\\binom{k-m-1}{m-1}$ possible strings.\n  \u2022 The third case is similar, giving instead $\\binom{k-m-1}{m}$ strings.\n\nPutting this together we have: $$2\\cdot \\binom{k-m-1}{m-1}+\\binom{k-m-1}{m}$$\n\nSince $n$ friends share $m$ birthdays we have to account for that, giving this expression:\n\n$$p(n,k) =\\frac{\\sum_{m=1}^n{ m! \\cdot S(n,m)\\cdot \\Bigg (2\\cdot \\binom{k-m-1}{m-1}+\\binom{k-m-1}{m}}\\Bigg )}{k^n}$$\n\nwhere $S(n,m)$ is the Stirling number of the second kind.\n\n@Moron: Why do we need to multiply by $m!$ here? Oh right! Stirling numbers of the second kind count the number of coalitions, but we care about their order, too!\n\nshare|improve this answer\nDid you mean $S(n,m)$? We need to multiply by factorial as we also need to assign the birthdays. The Stirling number counts the number of unordered partitions. We could assign the birthdays to each partition in $m!$ ways. For instance for $m=2$ there are $2^{n-1} - 1$ partitions, but you can rearrange the parts of the partition to get different birthdays assigned. \u2013\u00a0 Aryabhata Jan 21 '11 at 4:12\n+1: Apart from the missing $m!$ term. We have that identity $2 \\binom{k-m-1}{m-1} + \\binom{k-m-1}{m} = \\binom{k-m+1}{m} - \\binom{k-m-1}{m-2}$, which matches my answer. So this confirms that this matches Leonbloy's answer too. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:39\nOh right! We do care about their order, too. Fixed the typo in $S(n,m)$. Thank you! \u2013\u00a0 Jacopo Notarstefano Jan 21 '11 at 8:54\n+1 for an explanation using binary strings and compositions. \u2013\u00a0 Wok Jan 21 '11 at 15:21\nUsing weak compositions makes the problem really simple to handle. Bravo! \u2013\u00a0 Wok Jan 21 '11 at 15:32\n\nUPDATE - THIS IS WRONG -- SEE BELOW CORRECT ANSWER --- Let's call N1 the number of configurations that have at least one day in between birthdays (this excludes not only consecutive birthdays, but also coincident birthdays).\n\nI get (counting weak compositions) :\n\n$ \\displaystyle N_1 = 365 \\frac{(365-n-1)!}{(365-2n)!}$\n\nIf you want to include coincident birthdays, we have\n\n$\\displaystyle N_0 = \\frac{365!}{(365-n)!}$\n\nSo the probability asked is\n\n$\\displaystyle P = \\frac{N_0 - N_1}{365^n}$\n\nUpdate: there might be is some error here, I think I'm failing to taking into account the configurations that have both coincident and consecutive birthdays, I'll revise this tonight. I suspect that N1 is correct, and that allows to compute the probability of having consecutive OR coincident birthdays. To count consecutive (exclusively) birthdays seems more difficult.\n\nUPDATE: Here's the correct (I hope) answer.\n\nThe probability of having at least a pair of consecutive birthday for M (=365) days and n persons is\n\n$\\displaystyle P(M,n) = 1 - \\sum_{k=1}^n Q(M,k) {M \\choose k} \\frac{S(n,k) k! }{M^n} = 1 - \\frac{1}{M^{n-1}} \\sum_{k=1}^n \\frac{(M-k-1)!}{(M-2k)!} S(n,k) $\n\nwhere $ \\displaystyle Q(M,k) = \\frac{{M -k - 1 \\choose k -1} }{{M -1 \\choose k -1} } $\n\nand $S(n,k)$ are the Stirling numbers of the second kind\n\nSome computed values follow\n\nM=365 n=1 p=0.00000000\nM=365 n=2 p=0.00547835\nM=365 n=3 p=0.01634745\nM=365 n=4 p=0.03242761\nM=365 n=5 p=0.05345896\nM=365 n=6 p=0.07910314\nM=365 n=7 p=0.10895871\nM=365 n=8 p=0.14256439\nM=365 n=9 p=0.17941667\nM=365 n=10 p=0.21897764\nM=365 n=11 p=0.26069278\nM=365 n=12 p=0.30400167\nM=365 n=13 p=0.34834843\nM=365 n=14 p=0.39319571\nM=365 n=15 p=0.43803357\nM=365 n=16 p=0.48239009\nM=365 n=17 p=0.52583640\n\nM=365 n=30 p=0.90729104\n\nM=365 n=42 p=0.99074145 \n\n\nLet $M$ (=365) number of days, and $n$ = number of persons and $k$ = number of distinct birthdays ($k$ is not fixed, it's a random variable in the range $1..n$). Let $P_{M,n}(S)$ be the probability of NOT having consecutive birthdays (S is the event: \"all birthdays are separated\")\n\nThen $P_{M,n}(S) = \\sum_k P_{M,n}(S \\; k) = \\sum_k P_{M,n}( S | k ) P_{M,n}(k )$\n\nThe following steps compute the two factors inside the summation:\n\n\n$P_{M,n}( S | k )$ is the probability of having the events separated, given that the number of distinct birthdays is $k$. If we think of birthdays as occupied boxes in a circular list, a little reflection shows that all configurations are equiprobable ($n$ does not matter now) and we can assume without altering the result that the first box of the list is occupied. Now, the total number of possible ocurrences are the number of selection of $k-1$ boxes among $M-1$ (combination).\n\nAnd the number of \"succesfull\" arrangements are those that result in non-consecutive occupied boxes. But this is equivalent of specifying a list of $k$ numbers greater than 1 that sum up to M; and this is the same as specifying a list of $k$ numbers greater than 0 than sum up to $M-k$; and this can be counted, by a reasoning similar to this one, as the combination of $k -1$ taken from $M -k - 1$. So,\n\n$\\displaystyle P_{M,n}( S | k ) = \\frac{{M -k - 1 \\choose k -1} }{{M -1 \\choose k -1} } = Q(M,k)$\n\n\n$P_{M,n}(k)$ : if we place $n$ balls at random in $M$ boxes, what is the probability that exactly $k$ boxes will be non-empty?\n\nThe total counting is given by $M^n$. To count the \"successful\" cases, we multiply:\n\n  \u2022 all the possible sets of occupied boxes (combinations of $k$ taken from $M$)\n\n  \u2022 the total numbers of ways of putting $n$ balls in $k$ boxes leaving no empty box: that is given by the Stirling numbers of the second kind.\n\n  \u2022 and we need to multiply by $k!$ (permutations of boxes) because the Stirling numbers consider nondistinct boxes.\n\n    $\\displaystyle P_{M,n}(k ) = {M \\choose k} \\frac{S(n,k) k! }{M^n}$\n\nAnd from there follows the formula above.\n\nshare|improve this answer\nI agree (now!) with all this. I hope you don't have anything else on tonight though :-) \u2013\u00a0 TonyK Jan 20 '11 at 15:39\nThanks for trying, but it does not fit the estimated probabilities with Python. :( \u2013\u00a0 Wok Jan 20 '11 at 19:07\nAlthough my symulations do not give the same probabilities for several n, I wonder whether there is a bias due to the *pseudo-*randomness of generated integers. \u2013\u00a0 Wok Jan 20 '11 at 22:08\nWeird. You made the edit while I was writing my answer. They seem to be a bit different though. \u2013\u00a0 Aryabhata Jan 20 '11 at 23:30\nI have confirmed that the updated formula is same as mine. +1. Basically I have confirmed that $Q(M,k) {M \\choose k} = {M-k+1 \\choose k} - {M-k-1 \\choose k-2}$. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:32\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/263429/four-digit-reversal-numbers\nText:\nTake the 2-minute tour \u00d7\n\nHow to prove without an exhaustive checking that there are only 2 (nontrivial) four digit reversal numbers?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThat depends how exhaustive you are willing to be. The multiplier can only be in the range $2-9$, which is only eight cases. To check $4$ we write $abcd \\times 4=dcba$ where concatenation indicates different digits. $a$ has to be even as the last digit of the product, and has to be $2$ or there would be a carry. Then $d$ has to be $8$ so that it can produce $a$. $b$ has to be $0,1,2$ to avoid a carry and is odd because of the carry from the ones place, so it is $1$. Then $c$ has to be $7$ and we are done-$2178 \\times 4 = 8712$. $5, 6$ and $8$ are out because $a$ would have to be $1$ to avoid a product over $10,000$ but that is odd and not $5$. $7$ is out because again $a$ would have to be $1$, but then $d$ can't be $3$. So we just have to check $2, 3,$ and $9$-not too much work.\n\nshare|improve this answer\n\nLet $A = \\{2,3,4,5,6,7,8,9\\}$.\n\nLet the $4$ digit reversal number be $abcd$ i.e. $1000a + 100b + 10 c + d$, where $a \\in \\{1\\} \\cup A$, $d \\in \\{1,2,3,\\ldots,a-1\\}$ and $b,c \\in \\{0,1\\} \\cup A$. Its reversed number is $$dcba = 1000d + 100c + 10b + a$$ We want $abcd = k \\times (dcba)$ where $k \\in A$. This gives us $$(1000-k)a + (100-10k)b + (10-100k)c + (1-1000k) d = 0$$\n\n$$\\color{red}{\\text{First note that $10 \\vert (ka-d)$. This also means that if $a$ is even, then $d$ also has to be even.}}$$\n\nLet us call the above necessary condition in red as $\\star$. As explained below, this necessary condition filters out almost all the solutions that are not possible.\n\n  \u2022 If $a=2$. Then $d=1$. Violates $\\star$.\n  \u2022 If $a=3$. Then $d=1$. Hence, $k=1$ or $2$. $ka - d = 1 or 5$. Violates $\\star$.\n  \u2022 If $a=4$. Then $d=2$. If $d=2$, then $k=2$, then $ka-d = 6$. Violates $\\star$.\n  \u2022 If $a=5$. Then $d=1$ or $2$. If $d=1$, $k = 3$ or $4$ or $5$. But $10$ doesn't divide $ka - d$ if $d=1$. Violates $\\star$. If $d=2$, $k=2$. Violates $\\star$.\n  \u2022 If $a=6$, then $d=2$. If $d=2$, then $k=3$. Violates $\\star$.\n  \u2022 If $a=7$, then $d=1,2,3$. If $d=1$, $k=4,5,6,7$. Violates $\\star$. If $d=2$, then $k=3$. Violates $\\star$.\n  \u2022 If $a=8$, then $d=2,4$. If $d=4$, $k=2$. Violates $\\star$. If $d=2$, $k=3,4$. $k=3$ violates $\\star$. However, $k=4$ satisfies $\\star$. Hence, $a=8$, $d=2$ and $k=4$ is a possible candidate. Let us return to this candidate later.\n  \u2022 If $a=9$, then $d=1,2,3,4$. If $d=1$, $k=5,6,7,8,9$. Except $k=9$, the rest violate $\\star$. We will return to the case $a=9$, $d = 1$ and $k=9$ later. If $d=2$, then $k=4$. Violates $\\star$. If $d=3$, $k=3$. Violates $\\star$. If $d=4$, $k=2$. Violates $\\star$.\n\nHence, after this elimination using the necessary condition $\\star$, we get only two possibilities.\n\n  1. $a = 8$, $d=2$ and $k=4$. This means $60b - 390c + 996 \\times 8 - 3999 \\times 2 = 0$. Hence, $2b - 13c = 1$. This gives $b=7$ and $c=1$.\n  2. $a = 9$, $d=1$ and $k=9$. This means $10b - 890c + 991 \\times 9 - 8999 \\times 1$. Hence, $b-89c = 8$. This gives us $b=8$ and $c=0$.\n\nHence, the only two numbers are $8712$ and $9801$.\n\nshare|improve this answer\nI like both answers thus far, though. Thank you. \u2013\u00a0 anon Dec 21 '12 at 22:38\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/280837/cdf-of-maxx-1-x-2-maxx-3-x-4-where-all-x-is-are-iid-from-ua-b?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am looking for the cumulative density function of the sum of two variables, which are themselves the result of a rank order process.\n\nThus, if $x_1, x_2, x_3$ and $x_4$ are all independent draws from a uniform distribution with support $[a,b]$, what is the CDF for $\\max(x_1,x_2)+\\max(x_3,x_4)$?\n\n\nshare|improve this question\n\n2 Answers 2\n\nLet $X=\\max\\{x_1,x_2\\}$. We find the density function of $X$. We have that $F_X(x)=\\mathbb{P}\\{X\\leq x\\}=\\mathbb{P}\\{\\max\\{x_1,x_2\\}\\leq x\\}=\\mathbb{P}\\{x_1\\leq x \\cap x_2\\leq x\\}=\\mathbb{P}\\{x_1\\leq x\\}\\mathbb{P}\\{x_2\\leq x\\}$. Because they are uniformly distributed, it follows that the above is just the product of the cdfs of your original uniform distribution. Therefore $F_X(x)=(\\frac{x-a}{b-a})^2$ whenever $x\\in[a.b)$. From this it follows that $f_X(x)=\\frac{2(x-a)}{(b-a)^2}$. Similarly, if $Y=\\max\\{x_3,x_4\\}$, you have that $f_Y(y)=\\frac{2(y-a)}{(b-a)^2}$. Now let $Z=X+Y$. You have that $Z\\leq 2b$ with probability one and $Z\\leq 2a$ with probability 0. For $z\\in[2a,2b)$ you have $F_Z(z)=\\mathbb{P}\\{Z\\leq z\\}=\\mathbb{P}\\{X+Y\\leq z\\}=\\int_A f_{X,Y}(x,y) dA$ Because of independence of $x_1,x_2,x_3$ and $x_4$ you have that $X$ and $Y$ are independent. This means that $f_{X,Y}(x,y)=f_X(x)f_Y(y)$. Therefore, $F_Z(z)=\\int_A f_X(x)f_Y(y) dA=\\int_{-\\infty}^\\infty\\int_{-\\infty}^{z-x}f_X(x)f_Y(y)dydx=\\int_{-\\infty}^\\infty f_X(x)\\int_{-\\infty}^{z-x}f_Y(y)dydx=\\int_a^b f_X(x)\\int_a^{z-x}f_Y(y)dydx=\\int_a^b f_X(x) (\\frac{a+x-z}{b-a})^2dx=\\frac{1}{(b-a)^4}\\int_a^b 2(x-a)(a+x-z)^2 dx=\\frac{1}{12(a-b)^2}(11a^2+10ab-16az +3b^2-8bz+6z^2)$. I hope this is correct.\n\nshare|improve this answer\nThanks. Been working on this and got to the point where I have the PDFs and CDFs of x and y correct as as yours. I follow most of the rest of your derivations, but your result produces a strictly convex to the origin CDFs and therefore negative probabilities over some range. I have tried to take it from the double integrals in Mathematica. I get something close but slightly different but still with implausible results. \u2013\u00a0 user58641 Jan 17 '13 at 21:02\nI could've made a typo, but notice also that you have $z\\in[2a,2b)$. So the cdf is zero for all $z<2a$, whatever that integral turns out to be for $z\\in[2a,2b)$ and 1 for $z\\geq 2b$. \u2013\u00a0 mathemagician Jan 17 '13 at 21:15\nGot that. I am only plotting from 2a to 2b but there appears to be something not quite right in the development of the integrals since trying to go back up and replicating your steps I get similar results. \u2013\u00a0 user58641 Jan 17 '13 at 21:19\nif somebody could point at the mistake that would be highly appreciated \u2013\u00a0 mathemagician Jan 17 '13 at 22:01\n\nSuppose $u,v$ are i.i.d. $U(0,1)$. Then for any $w\\in[0,1]$, $\\operatorname{Pr}(\\max(u,v)\\le w)=w^2$. Hence the density of $W=\\max(u,v)$ is given by $f(w)=2w$. Therefore, if $X=(\\max(x_1,x_2)-a)/(b-a)$ and $Y=(\\max(x_3,x_4)-a)/(b-a)$, the densities of $X$ and $Y$ on $[0,1]$ are $2x$ and $2y$ respectively.\n\nNow let $Z=X+Y=\\left[\\max(x_1,x_2)+\\max(x_1,x_2)-2a\\right]/(b-a)$. Then for any $m\\in[0,\\,2]$, we have $$ \\phantom{=}\\operatorname{Pr}\\left(Z\\le m\\right) =\\begin{cases} \\int_0^m \\int_0^{m-y} 4xy\\, dx dy=\\frac{m^4}{6} &\\text{ if } m\\le1,\\\\ 1-\\int_{m-1}^1 \\int_{m-y}^1 4xy\\, dx dy = 1-\\frac16m(m-2)^2(m+4) &\\text{ otherwise}. \\end{cases} $$\n\nshare|improve this answer\n@D. The density may exceed $1$. Why not? The standard normal density evaluated at $x=0$, for instance, approaches infinity when the standard deviation $\\sigma$ approaches zero. By the way, I've verified the formula using computer simulation. With a million simulation trials, the above formula agrees with the simulation value to three decimal places for $m=0.1,0.2,\\ldots,1.9$. \u2013\u00a0 user1551 Jan 17 '13 at 23:54\nThanks. If you got an email of my last comment, just disregard.. That was silly! Thanks a lot for your help. I think I got it now, although a good reference for these derivations would be useful! \u2013\u00a0 user58641 Jan 18 '13 at 0:25\n@D. I don't have any reference. For $m\\le1$, I just integrated the joint density function over the triangular domain bounded by the $x$-axis, the $y$-axis and the line $x+y=m$. For $m\\ge1$, I integrated the density over the triangular domain bounded by $x=1$, $y=1$ and $x+y=m$, and then subtract the result from $1$. \u2013\u00a0 user1551 Jan 18 '13 at 1:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/125671/ell-1-dense-in-c-0\nText:\nTake the 2-minute tour \u00d7\n\nThis may be a silly question, but here goes. To ensure clarity, $\\ell_1$ is the space of absolutely summable sequences, and $c_0$ the space of bounded sequences with limit 0. So we know that $\\ell_1\\subset c_0$ by basic principles. My question is: is $\\ell_1$ when equipped with the sup-norm dense in $c_0$?\n\nHere is my thought, and I would appreciate a comment on correctness or if something went wrong:\n\nLet $\\xi\\in c_0$ and write $\\xi=\\{\\xi_1,\\xi_2,\\xi_3,\\dots\\}$. Now define $P_n:\\ell_1\\to c_0$ by $$P_n(\\eta)=\\{\\eta_1,\\eta_2,\\dots,\\eta_n\\}$$ So if $\\xi\\in c_0$, we can say $$\\xi=\\underset{n\\to\\infty}{\\lim}P_n\\xi$$\n\nSo does this get us all of $c_0$?\n\nA typical example would be the harmonic sequence $\\{1, 1/2, \\dots, 1/n,\\dots\\}$. This is in $c_0$ but not $\\ell_1$, but taking finite pieces of this sequence at a time guarantees us to remain in $\\ell_1$, and we can approximate the sequence in $c_0$ as the limit of elements of $\\ell_1$.\n\nshare|improve this question\nYour proof for the harmonic sequence generalizes. \u2013\u00a0 dls Mar 28 '12 at 23:41\n$c_{00}$ is dense in $c_0$, so any set containing $c_{00}$ is dense in $c_0$. \u2013\u00a0 user16299 Mar 29 '12 at 2:50\n@Yemon Will the same reasoning always hold for sums of Banach spaces? It seems like the same arguments will work to show that the $\\ell_1$ sum of Banach spaces is dense in the $c_0$ sum of Banach space, and so on. Or is there an example out there where this would break down? \u2013\u00a0 Keaton Mar 29 '12 at 16:04\n@keaton I think it should work, just as you say \u2013\u00a0 user16299 Apr 1 '12 at 0:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nYes. Let $(x_n)\\in c_0$ and take $\\epsilon>0$. Since $x_n\\to 0$, we have some $N$ such that $n\\geq N\\implies |x_n|<\\epsilon$. Define the sequence $(y_n)$ by $y_n=x_n$ for $n<N$ and $y_n=0$ for $n\\geq N$. Clearly $(y_n)\\in \\ell^1$, and for any $n$, $|x_n-y_n|\\leq \\epsilon$, hence $\\sup\\limits_{n}|x_n-y_n|\\leq \\epsilon$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/152414/directional-derivates-and-unique-subgradients\nText:\nTake the 2-minute tour \u00d7\n\nI have a question about the fine structure of convex functions. Convex functions behave very regular in the interior of their domain of definition (e.g. they are locally Lipschitz continuous there) but otherwise some weird things can happen. My question concerns convex functions that possess at most one subgradient at each point. Let's fix notation:\n\nLet $X$ be a Banach space and $J:X\\to\\mathbb{R}\\cup\\{\\infty\\}$ be a convex, extended valued function. Denote by $\\newcommand{\\dom}{\\mathrm{dom}}\\dom J = \\{x\\ :\\ J(x)<\\infty\\}$ and assume that the subdifferential $\\partial J$ of $J$ is at most single valued and denote its unique element by $\\nabla J(x)$ (if it exists). Moreover, denote the G\u00e2teaux directional derivative at $x$ in direction $h$ by $DJ(x;h)$. My question is:\n\nDoes $x,y\\in \\dom J$ imply that $$\\langle \\nabla J(x),y-x\\rangle = DJ(x;y-x)\\ ?$$\n\nSome background: I would like to state that in the above framework for some non-strictly convex $J$ there exist $x,y\\in\\dom J$ such that $\\langle \\nabla J(x),y-x\\rangle = J(y)-J(x)$. It clear that one gets $x$ and $y$ such that for $\\lambda\\in]0,1]$ it holds that $$ \\frac{J(\\lambda y + (1-\\lambda)x) - J(x)}{\\lambda}=J(y) - J(x) $$ which implies $DJ(x,y-x) = J(y) - J(x)$.\n\nHowever, there exists a pathological convex function such that its subdifferential at some point is single values although it is not G\u00e2teaux differentiable there (Example 4.2.6 in Borwein and Vanderwerffs \"Convex Functions: Constructions, Characterizations and Counterexamples\", see here). However, I assume a wee bit more, namely that the subdifferential is at most single valued everywhere (but probably this already rules out some pathological things\u2026).\n\nshare|improve this question\nWhat about $f(x) = -1(1-|x|^2)^{1/2}$ on $|x| \\le 1$ and $f(x)=+\\infty$ elsewhere? This function is in fact differentiable at $x$ for all $|x| < 1$, but $\\partial f(x) = \\emptyset$ for all $|x| \\ge 1$---the badness comes from $1 \\in \\dom f$--- does this break your setup? \u2013\u00a0 Suvrit Dec 20 '13 at 17:26\nWell, I am interested in the case where $\\partial f(x)$ is a singleton for all $x$ in $\\mathrm{dom} f$. In your example, the subdifferential is empty precisely where the directional derivative does not exist. \u2013\u00a0 Dirk Dec 20 '13 at 18:02\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/84634/help-prove-a-maximal-inequality\nText:\nTake the 2-minute tour \u00d7\n\nLet $X_1,\u2026,X_n$ are exchangeable of random variables, and $n$ is an even number. $S_k=X_1+\\dots+X_k$. $M_k=X_{n/2}+\\dots+X_{n/2+k}$.\n\nI want to prove:\n\n$$\\Pr(\\max_{1 \\le k \\le n}{|S_k|>\\epsilon}) \\le \\\\Pr(\\max_{1 \\le k \\le n/2}{|S_k|>\\epsilon/2}) + \\Pr(\\max_{1 \\le k \\le n/2}{|M_k|>\\epsilon/2})$$\n\n[added by YC] for background context to this question, see this MSE question\n\nshare|improve this question\nIf $X_1,\\dots, X_n$ are exchangeable, then doesn't $(S_1,\\dots, S_{n/2})$ have the same distribution as $(M_1,\\dots, M_{n/2})$? \u2013\u00a0 Yemon Choi Dec 31 '11 at 9:04\nWell, it isn't true in general. Take $X_i=1/n$ for all $i$ and $\\epsilon=2/3$. \u2013\u00a0 Brendan McKay Dec 31 '11 at 14:19\n@BrendanMcKay, It is still right, the LHS is $\\Pr(1>2/3)=1$, the RHS is $\\Pr(1/2>1/3)+\\Pr(1/2>1/3)=2$ \u2013\u00a0 Fan Zhang Dec 31 '11 at 15:51\nI think the summation for $M_k$ should start at $n/2 + 1$ so that it is the sum of $k$ terms. With this modification, as Yemon Choi pointed out, $M_k$ has the same distribution as $S_k$ so both probabilities on the right hand side are equal. \u2013\u00a0 Pablo Lessa Dec 31 '11 at 18:00\nThe motivation: math.stackexchange.com/questions/94948/\u2026 \u2013\u00a0 Byron Schmuland Dec 31 '11 at 19:11\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nYou can prove it by using the fact that the following holds always:\n\n$\\max_{1 \\le k \\le n}|S_k| \\le \\max_{1 \\le k \\le n/2}|S_k| + \\max_{1 \\le k \\le n/2}|M_k|$\n\nIf the left hand side is larger than $\\epsilon$ then one of the right hand terms is larger than $\\epsilon/2$.\n\nThis also shows that the inequality is valid under absolutely no assumptions on the joint distribution of the variables $X_1,\\ldots,X_n$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/41933/uniqueness-for-solution-of-a-d-dbar-system-related-to-davey-stewartson-solitons\nText:\nTake the 2-minute tour \u00d7\n\nThis question concerns a system of equations that arise in the study of one-soliton solutions to the Davey-Stewartson equation.\n\nIn what follows, $f(z)$ denotes a function which depends smoothly (but not necessarily analytically!) on $z=x+iy$. Thus $f:\\mathbb{C} \\rightarrow \\mathbb{R}$ or equivalently $f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$. We denote by $\\overline{\\partial}$ and $\\partial$ the usual operators $$ \\overline{\\partial} = \\frac{1}{2} \\left( \\partial_x + i \\partial_y \\right) $$ and $$\\partial = \\frac{1}{2} \\left( \\partial_x - i \\partial_y \\right). $$\n\nThe system is:\n\n$$\\overline{\\partial} n_1(z) = (1+|z|^2)^{-1} n_2(z)$$ $$\\partial n_2(z) = -(1+|z|^2)^{-1} n_1(z)$$\n\nand the question is as follows. Suppose that\n\n$$\\lim_{|z|\\rightarrow \\infty} |z| n_1(z) = \\lim_{\\|z| \\rightarrow \\infty} |z| n_2(z) = 0$$\n\nCan one prove that $n_1(z)=n_2(z)=0$ if one assumes a priori that $n_1$ and $n_2$ belong to $L^p(R^2)$ for all $p>2$ (including $p=\\infty$)? For this purpose one can assume that the limits above exist.\n\nThanks in advance for any help.\n\nPeter Perry, University of Kentucky\n\nshare|improve this question\nDid you try with some Pohozaev-type inequality? e.g. like this: 1) apply $\\partial$ to the first equation so it becomes $\\Delta n_1+(1+|z|^2)^{-1}n_1=g$ where $g$ decays at infinity faster than $z^{-3}$ 2) multiply by $\\overline{z}n_1$ and integrate over an annulus. Typically you obtain quite good information on the behavior of the gradient with this method \u2013\u00a0 Piero D'Ancona Oct 13 '10 at 7:09\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/108276/linear-code-in-cryptography\nText:\nTake the 2-minute tour \u00d7\n\nIs it possible to construct a [6,2] linear code that is two-error correcting?\n\nI think I need to use this Theorem:\n\nSuppose that C is a t-error correcting code in (Z_2)^8. Then order(C)*((n choose 0)+(n choose 1) +...+(n choose t)) is less than or equal to 2^n\n\nshare|improve this question\nSurely coding-theory is a more appropriate tag for this question? \u2013\u00a0 Jyrki Lahtonen Feb 11 '12 at 22:06\nYes, you have the \"correct theorem\" to use in proving the result (except that you probably meant to type $\\mathbb Z_2^6$ instead of $\\mathbb Z_2^8$ and of course $n$ is $6$. \u2013\u00a0 Dilip Sarwate Feb 11 '12 at 22:26\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nNo. At least not, if you are talking about binary linear codes (which seems to be the case judging from everything else that you say). There are several ways of seeing that this is impossible. The result that you described is one of them. There are $$ {6\\choose 0}+{6\\choose 1}+{6\\choose 2}=22 $$ binary vectors at distance $\\le 2$ from a given codeword. So if you had 4 codewords in a double-error correcting binary code of length 6, then these 4 Hamming spheres sets of vectors should not intersect. Therefore between themselves they would cover a total of $4\\cdot 22=88$ vectors. But there are only $2^6=64$ in the entire space $F_2^6$! Therefore this is impossible.\n\nThis also follows from the so called Griesmer bound stating that if a binary code of dimension $k$ has minimum distance at least $d$, then its length $n$ satisfies the bound $$ n\\ge \\sum_{i=0}^{k-1}\\lceil\\frac{d}{2^i}\\rceil. $$ So if a 2-dimensional binary linear code can correct two errors, its minimum distance is at least $d5$, then its length must be at least $$ n\\ge \\lceil\\frac51\\rceil+\\lceil\\frac52\\rceil=5+3=8. $$ The double-error correcting code in your other question is an example of a shortest possible binary linear double error correcting code that has 4 codewords.\n\nContinue to read at your own peril:\n\nNote: It is possible to find 2-dimensional double error correcting codes of length six over a larger alphabet. For example using suitably chosen Reed-Solomon codes you can shorten it to form a code with the properties:\n\n  1. The codewords have six components, all of which are bytes (as opposed to bits like here).\n  2. Two out of the six bytes carry information, and the remaining four are check bytes.\n  3. The code can recover from any error, where at most two out of the six bytes are incorrectly received/read.\nshare|improve this answer\nTo add to Jyrki's excellent answer, the Hamming bound that the OP said he thought he needed to use (and Jyrki filled in the details) actually shows that no binary code (whether linear or nonlinear) with $4$ codewords of length $6$ can correct $2$ errors. \u2013\u00a0 Dilip Sarwate Feb 11 '12 at 22:27\nThis is all very interesting stuff, I appreciate the help with all of this. I'm guessing applications such as maple and matlab would be good for playing around with these types of codes. \u2013\u00a0 Jackson Hart Feb 11 '12 at 23:07\nWhy do you assume there are 4 codewords? What if it were 2 codewords? Then it might work, right? \u2013\u00a0 Jackson Hart Feb 11 '12 at 23:11\n>Why do you assume there are 4 codewords? Because the terminology $[n,k]$ linear binary code usually means a code with $2^k$ binary vectors of length $n$ that constitute a $k$-dimensional subspace of $\\mathbb Z_2^n$. Older books also used $(n,k)$ instead of $[n,k]$ but in more modern texts, a $[n,k]$ code is linear (or at least has $2^k$ or $q^k$ codewords) while a $(n,M)$ code means $M$ vectors (of length $n$) that do not necessarily constitute a linear code. \u2013\u00a0 Dilip Sarwate Feb 12 '12 at 1:45\n@Jackson: A 2-dimensional binary linear code (or any binary code with 4 words) is so small that you can play with them without any CAS. If we look at 2-dimensional codes of length 6, then the best code (in terms of minimum distance) is {000000,111100,110011,001111}. You see that its minimum distance is four, so it can correct one error and detect two. Notice two further things: the bits here are in groups of two so that the second bit always the same as the first, the fourth the same as the third, ditto the sixth and the fifth. \u2013\u00a0 Jyrki Lahtonen Feb 12 '12 at 7:20\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/208696/number-of-roots-of-an-equation/208719\nText:\nTake the 2-minute tour \u00d7\n\nPlotting the equation $x^3-x^2 \\sin(x)+\\cos(x)$ I see that $x^3-x^2 \\sin(x)+\\cos(x)=0$ has only one real solution, is there a simpler way to see that it cannot have 3 real solutions?\n\nshare|improve this question\nOne consideration is the sin and cos are less than $1$ in magnitude, so the function may be compared to $x^3-x^2+1$ which also is close to $x^3 - x^2 = x^2(x-1)$. \u2013\u00a0 adam W Oct 7 '12 at 13:11\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nWe have $f(x) = x^3-x^2\\sin(x) +\\cos(x)$, hence $f'(x)=(3-\\cos(x))x^2-(2x-1)\\sin(x)$, $f''(x)=(x^2-2)\\sin(x) + 6x-(4x-1)\\cos(x) $.\n\nFor $0\\le x$ we have $\\sin x\\le x$, hence $f(x)\\ge x^3-x^3+\\cos(x)\\ge \\cos x$, hence any positive root of $f$ must be $\\ge\\frac\\pi2$. But already for $x\\ge\\frac 3 2$, we have $f(x)\\ge x^3-x^2-1=(x-1)x^2-1\\ge(\\frac32-1)\\frac94-1=\\frac18>0$. Therefore $f$ has no nonnegative root.\n\nIf $-\\frac\\pi2\\le x\\le 0$ then $\\sin(x)\\le \\frac2\\pi x$ and $\\cos(x)\\ge1+\\frac2\\pi x$, hence $f(x)\\ge(1-\\frac2\\pi)x^3+1+\\frac2\\pi x$. The right hand side becomes $=0$ at $x=-1$ and has positive derivative. We conclude that $f(x)>0$ for $x> -1$.\n\nObserve that $A\\sin x+B \\cos x=\\sqrt{A^2+B^2}(\\cos u\\sin x+\\sin u \\cos x)=\\sqrt{A^2+B^2}\\sin(x+u)$ for some $u$, i.e. $$\\tag1 |A\\sin x + B\\cos x|\\le \\sqrt {A^2+B^2}.$$ Therefore we see that $f(x)=x^3-x^2\\sin x+\\cos x$ can be estimated as $$ f(x)\\le x^3+\\sqrt{x^2+1}<x^3+\\sqrt{x^2+1+\\frac1{4x^2}}=x^3+\\left|x+\\frac1{2x}\\right|,$$ i.e. for negative $x$ by $$ f(x)<x^3-x-\\frac1{2x}=\\frac{2x^2(x^2-1)-1}{2x} $$ The numerator is positive for $x^2>\\frac{1+\\sqrt 3}2$, i.e. for $x<-\\sqrt{\\frac{1+\\sqrt 3}2}$, even more so for $x\\le -\\frac65$.\n\nBy the results so far, $f$ can have roots only in $(-\\frac65,-1]$.\n\nBetween any two roots of $f$, there must be a root of $f'$. If $f$ has moe than one root, it must have at least three roots (counting multiplicity) because $f(x)\\to\\pm\\infty$ as $x\\to\\pm\\infty$, hence $f'$ must have two roots in $(-\\frac65,-1]$ (again, counting multipliciites) and finally $f''$ must have at least one root in $(-\\frac65,-1]$. Even a mild estimate for $\\sin$ and $\\cos $ in this interval should suffice to show $f''(x)<0$ here.\n\nshare|improve this answer\n\nLet $f(x) = x^3$ and $g(x) = x^2 \\sin(x) - \\cos(x)$. Clearly $$ |g(x)| \\le x^2 + 1, $$ and hence a necesary condition for $f(x) - g(x) = 0$ is that $$ -\\beta = \\frac{1}{3}\\big(-1 - \\alpha_1^{-1/3} - \\alpha_1^{1/3}\\big) \\le x \\le \\frac{1}{3}\\big(1+\\alpha_1^{1/3}+\\alpha_2^{1/3}\\big) = \\beta $$ where $\\alpha_1 = \\frac{29-3\\sqrt{93}}{2}$ and $\\alpha_2 = \\frac{29+3\\sqrt{93}}{2}$.\n\nNow, $$ g'(x) = x^2\\cos(x) + (2 x + 1)\\sin(x) $$ implies $g'(x) > 0$ from $0 < x \\le \\frac{\\pi}{2}$, meaning that $g(x)$ is strictly increasing in $0 < x \\le \\beta < \\frac{\\pi}{2}$, achieving its maximum at $x = \\beta$ and minimum at $x = 0$.\n\nGiven that $g(0) < f(0)$, $\\,f$ striclty increasing, and $$ g(\\beta) < \\beta^2 \\sin(\\beta) < \\beta^3 = f(\\beta), $$ there is no positive solution to $f(x) - g(x) = 0$ for $x \\in [0,\\infty)$.\n\nThe case $ x < 0$ is a bit more interesting. First, we see that $$ g'(x) = 0 \\quad \\Longleftrightarrow \\quad \\frac{x^2}{2 x +1} = -\\tan(x) $$ meaning that $g(x)$ has a (unique) critical point $x_c$ in $\\big(-\\beta,0\\big)$; moreover, $x_c \\in [-\\frac{1}{2},0)$ and it's a maximum (it's easy to see that $g'(-\\pi/4) > 0$ and $g'(-\\pi/12) < 0$).\n\nIn $x \\in [-\\frac{1}{2},0)$, $g(0) < f(0)$ and $$ g(x) < -\\cos(x) \\le -\\cos(-1/2) < -(1/2)^3 \\le x^3 = f(x) $$ implying that there is no solution for $f(x) - g(x) = 0$ for $x \\in [-\\frac{1}{2},\\infty)$.\n\nFinally, $g'(x) > 0 $ for $x \\in [-\\beta, -\\frac{1}{2}]$, and then there is one (and only one) solution in that interval.\n\nHope I didn't made any mistakes.\n\nshare|improve this answer\n\nIt might be helpful to notice that it has an uneven number of solutions, since $x^3 \\to \\pm\\infty$ for $x \\to \\pm\\infty$. We can furthermore see that the function is not strictly even or odd (as it is composed of both an even function $\\cos(x)$, and uneven functions $x^3, x^2\\cdot\\sin(x)$), this might hint at only one solution.\n\nHowever, since the total function is made up of both polynomials of finite order and sinus/cosinus parts, it could have many more solutions - just compare it to the plot of\n\n$$\\frac{1}{100} x^3 - x^2\\sin(x) + \\cos(x).$$\n\nSo, to answer your question, there is no general way of deciding how many solutions such a function could have.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/70410/compact-operator-maps-weakly-convergent-sequences-into-strongly-convergent-seque/70411\nText:\nTake the 2-minute tour \u00d7\n\nI found the following property of compact operators in a proof, and I can't prove it.\n\nProve that if $T \\in \\mathcal{L}(E,F)$ is compact, and if $u_n \\rightharpoonup u$ (the sequence converges weakly to $u$ in $\\sigma(E,E^*)$) then $Tu_n \\to Tu$ strongly in $F$.\n\nI was able to prove that $Tu_n$ has a convergent subsequence ($u_n \\rightharpoonup u$ implies that $(u_n)$ is bounded in $E$. Then, because $T$ is compact it must follow that $(Tu_n)$ must contain some strong convergent subsequence), but didn't manage to finalize the proof.\n\nAny reference or hints are welcome.\n\nshare|improve this question\n@all: please ignore my vote to close. I'm pretty sure this was discussed several times already, but I can't seem to find the thread at the moment. The thread I linked to is not a duplicate of this question. Beni, sorry about that. \u2013\u00a0 t.b. Oct 6 '11 at 18:19\n@t.b.: It's ok. I was wondering why it was voted to close. I also searched the site before posting, and didn't find it. \u2013\u00a0 Beni Bogosel Oct 6 '11 at 18:21\n\n2 Answers 2\n\nup vote 10 down vote accepted\n\nMake use of the following topological lemma.\n\nLemma Let $X$ be a topological space and $\\mathbf{x}=(x_n)_{n\\in \\mathbb{N}}$ be a sequence of elements of $X$. If every subsequence of $\\mathbf{x}$ contains a subsequence convergent to $x$ then $x_n \\to x$.\n\nshare|improve this answer\nThis surely is a very nice argument. Thank you. \u2013\u00a0 Beni Bogosel Oct 6 '11 at 18:22\nYou're welcome! This little lemma is simple yet useful to know, IMHO. \u2013\u00a0 Giuseppe Negro Oct 6 '11 at 21:29\n\nThis is also true by the following reason:\n\nSince you've already proved that there is a strongly convergent subsequence, let's say $ Tu_{n_k} \\to u^* $ for $ k \\to \\infty $. Then by the weak convergence of $ u_n \\rightharpoonup u $ you get immediately that $ Tu_n \\rightharpoonup Tu $. Now since strong convergence implies weak convergence and from the uniqueness of the limit of a weak convergent sequence it must be true that\n\n$ u^*= Tu $.\n\nTherefore $ Tu $ is a limit point of the sequence $ (Tu_n)_{n \\in \\mathbb{N}} $. Now there's just one thing left to prove your statement\n\nClaim: There's no other limit point, hence it must be the limit.\n\nProof: Suppose there's another limit point $ z $ of the sequence $ (Tu_n)_{n \\in \\mathbb{N}} $. Again there must be a subsequence $ (Tu_{n_m})_{m \\in \\mathbb{N}} $ converging to $ z $. Hence this subsequence $ u_{n_m} \\rightharpoonup u$. Last step, use the same argumentation as above to conclude that $ z = Tu = u^*$.\n\nTherefore $ Tu_n \\to Tu $ as $ n\\to \\infty $.\n\nTo be precisly, at this point you know,\n\n$ Tu_{n_k} \\to Tu $ and that the limit $ Tu $ is the only limit point of $ (Tu_n)_{n\\in \\mathbb{N}} $. Use now a contradiction argument to prove that $ Tu_n\\to Tu $.\n\nshare|improve this answer\nWhy is it \"immediate\" that you get $Tu_n \\rightharpoonup Tu$ from the weak convergence of the $u_n$? \u2013\u00a0 maximumtag Mar 11 at 21:56\n@maximumtag what is your definition of weak convergence? \u2013\u00a0 math Mar 25 at 10:23\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/328091/every-complete-countable-metric-space-has-a-discrete-dense-subset\nText:\nTake the 2-minute tour \u00d7\n\nGiven a complete, countable metric space, say $X$, I'd like to show it has a discrete, dense subset. This seems like an application of the Baire Category Theorem, but that doesn't seem to go anywhere. Any help would be appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 8 down vote accepted\n\nConsider the collection $I$ of all isolated points of $X$. (By the Baire Category Theorem $I$ is nonempty, but that is somewhat immaterial for the moment.) Note that $I$ is then a discrete subspace of $X$. If $I$ were not dense, then $U = X \\setminus \\overline{I}$ is a nonempty (open) set without isolated points. From here we can construct in the usual manner a Cantor set as a subset of $X$, contradicting that $X$ is countable! (The construction goes as in the linked answer, just ensuring that the $x_\\sigma$ are chosen from $U$.)\n\nshare|improve this answer\nAh, so I was heading in the right direction it seems. Thanks for your help. \u2013\u00a0 Alexander Sibelius Mar 12 '13 at 4:58\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/88109/order-of-growth-of-s-1-zetas\nText:\nTake the 2-minute tour \u00d7\n\nAgain, order of growth problems.\n\nShow that the function $(s-1)\\zeta(s)$ is an entire function of growth order $1$; or equivalently, $$|(s-1)\\zeta(s)| \\leq A_{\\epsilon} \\; \\exp \\left(a_{\\epsilon}|s|^{1+\\epsilon} \\right).$$\n\nOf course, $\\zeta (\\cdot)$ denotes the Riemann zeta function.\n\nMany thanks in advance.\n\nshare|improve this question\nIt's not quite true that those statements are equivalent. The first implies the second (assuming an implicit universal quantifier for $\\epsilon\\gt0$, existential quantifiers for $a_\\epsilon$ and $A_\\epsilon$, and a universal quantifier for $s$), but it further implies that there are no such $a_\\epsilon$ and $A_\\epsilon$ for $\\epsilon\\lt0$. \u2013\u00a0 joriki Dec 11 '11 at 9:56\n\n3 Answers 3\n\nup vote 2 down vote accepted\n\nAnother approach is through the Laurent series of the Riemann zeta function at $s=1$,\n\n\nwhere the $\\gamma_n$ are the Stieltjes constants. Multiplying by $s-1$ yields\n\n\nTheorem 2.2.2 of Entire Functions by Ralph Philip Boas expresses the order $\\mu$ of an entire function given by a power series\n\n\nin terms of the coefficients:\n\n$$\\mu=\\limsup_{n\\to\\infty}\\frac{n\\log n}{\\log (1/|a_n|)}\\;.$$\n\nTo evaluate the limit superior, we can use bounds found by Matsuoka: For all $n\\ge10$,\n\n$$|\\gamma_n|\\le\\frac{\\exp(n\\log\\log n)}{10000}\\;,$$\n\nand for infinitely many n\n\n$$|\\gamma_n|\\gt\\exp(n\\log\\log n-n\\epsilon)\\;.$$\n\nBy substituting Stirling's approximation for the factorial,\n\n$$\\log n!\\sim n\\log n -n\\;,$$\n\nwe can see that the limit superior is $1$: The upper bound on $\\gamma_n$ ensures that the quotient is eventually below $1+\\delta$, and the lower bound ensures that it is infinitely often above $1$.\n\nshare|improve this answer\n\nThis is an application of Phragmen-Lindelof, Laplace-Stirling asymptotics of Gamma (or less), and the functional equation. The completed zeta function $\\xi(s)=\\pi^{-s/2}\\Gamma(s/2)\\zeta(s)$ has the functional equation $\\xi(1-s)=\\xi(s)$, and simple poles at $s=1,0$. Thus, $s(s-1)\\xi(s)$ is entire.\n\nFrom the resulting $\\zeta(1-s)=\\pi^{s/2}\\Gamma(s/2)\\zeta(s)/\\pi^{-(1-s)/2}\\Gamma((1-s)/2))$, multiplying through by $s(s-1)$ to eliminate the poles, and from asymptotics of $\\Gamma$, we find that $\\zeta(s)$ is of vertical growth of the order ${1\\over 2}+|\\Re(s)|$ to the left of $0$, with as explicit (crude) constants as one wants. Applying Phragmen-Lindelof gives bounded order of growth in the critical strip. (The details of this latter concern Lindelof and RH, but are irrelevant for the present coarser statement.)\n\nThis sort of consideration (at very modest detail) is sufficient to invoke Hadamard-product business.\n\nThe Hadamard-product stuff is treated in detail in Ahlfors' \"Complex Analysis\", as are asymptotics for $\\Gamma$. The functional equation of $\\zeta$ is treated many places. The argument I sketched is also given many places, such as Lang's \"Algebraic Number Theory\". It should be viewed as \"standard\".\n\nshare|improve this answer\n\nI think this is done in any serious treatment of the zeta function, but is a bit long to write out here. Try Davenport's Multiplicative Number Theory.\n\nEDIT: or try these notes by my colleague, William Chen. He defines $$\\xi(s)=(1/2)s(s-1)\\pi^{-s/2}\\Gamma(s/2)\\zeta(s)$$ Theorem 6C gives a product formula for $\\xi$. Section 6.3 introduces functions of order 1. Theorem 6K relates functions of order 1 to products over zeros. All that goes into Section 6.4, where Chen proves $$\\xi(s)=O_{\\alpha}\\left(e^{|s|^{\\alpha}}\\right)$$\n\nMORE EDIT: Perhaps the discussion in Bateman and Diamond, Analytic Number Theory, would help. Theorem 8.1 gives the \"asymmetric functional equation,\" $$\\zeta(s)=2^s\\pi^{s-1}\\Gamma(1-s)\\zeta(1-s)$$ Then Section 8.2 gives various estimates for $\\zeta$. With $s=\\sigma+it$, they note $$\\zeta(s)=1+O(2^{-\\sigma})$$ as $\\sigma\\to\\infty$. By Theorem 8.1 and Stirling they get $$\\zeta(\\sigma+it)=O(|t|^{(1/2)-\\sigma})$$ for $-a\\le\\sigma\\le-b\\lt0$, $|t|\\ge1$. Then they get (Lemma 8.4) $$\\zeta(s)=O(\\log t)$$ for $\\sigma\\ge1$, $t\\ge2$, and $$\\zeta(s)=O_{\\delta}(t^{1-\\delta})$$ for $0\\lt\\delta\\lt1$, $\\sigma\\ge\\delta$, $t\\ge2$.\n\nshare|improve this answer\nDavenport is kind of vague. I guess the inequality is to be deduced from the functional equation $\\zeta(s)=\\pi^{s-1/2} \\frac{\\Gamma((1-s)/2)}{\\Gamma(s/2)} \\zeta(1-s)$, but I don't see it yet... \u2013\u00a0 Anna Dec 11 '11 at 20:12\nOk, I understand the proof that $\\xi$ has order at most $1$. But how does that imply that $(s-1)\\zeta$ has order $1$ (given the function eqn)? \u2013\u00a0 Anna Dec 11 '11 at 23:44\nI suppose you have to know something about the Gamma function. Perhaps Stirling's formula is enough. \u2013\u00a0 Gerry Myerson Dec 12 '11 at 0:38\n@Anna Where did you find the proof that $\\xi$ has order at most 1? Can you comment the book/weblink you used? I've been looking around for that proof, but I have not been able to find it. Also, it can be shown that the other functions in $\\zeta$'s functional equation have order of growth 1, hence (s-1)$\\zeta(s)$ has order of growth 1. \u2013\u00a0 nick Jul 9 at 7:15\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/84382/does-an-essential-resolution-of-2-dimensional-hypersurface-singularity-preserves\nText:\nTake the 2-minute tour \u00d7\n\nPut $V= \\mathbb{C}^3$. Let $D \\subset V$ be an isolated singularity and\n$\\mu: \\tilde{V} \\rightarrow V$ be a log resolution of the pair $(V,D)$ whose exceptional locus $E$ and the strict transform $\\tilde{D}$ satisfies that $\\tilde{D} \\cup E$ has a normal crossing support. We can define $c_j \\in \\mathbb{Z}$ such that $K_{\\tilde{V}} + \\tilde{D}\u3000= \\mu^* (K_V +D)+ \\sum c_j E_j $ where $E = \\bigcup E_j$ is the irreducible decomposition.\n\nQuestion Is there $\\mu$ such that $c_j \\le 0$ for all $j$?\n\nshare|improve this question\n\n1 Answer 1\n\nThe answer is surely no.\n\nIf $D$ itself does not have a minimal log smooth resolution, then certainly $(V,D)$ couldn't have such a log resolution you need. On the other hand, there are bunch of isolated surface singularities whose minimal resolution is not log smooth, e.g., the log canonical surface singularity whose minimal log resolution has its exceptional locus an nodal rational curve.\n\nshare|improve this answer\nThank you for the comment. I think that every normal surface singularity $D$ has a log resolution such that each discrepancy is non-positive. It is called an essential resolution, e.g. in Ishii's paper. Actually, if I blow up the node of the nodal curve in your example, the coefficient of the $-1$-curve is 0. \u2013\u00a0 tarosano Jan 14 '12 at 18:04\nI see. You are right. We also need to consider the curves of discrepancy 0 which doesn't necessarily appear in the minimal resolution of the surface itself. \u2013\u00a0 CYXU Jan 16 '12 at 0:58\nJust for safety, maybe the discrepancy of the $-1$-curve is $-1$. \u2013\u00a0 tarosano Mar 4 '13 at 11:24\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/142809/sampling-value-prediction-and-error-correction?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI am a programmer and I don't have much background in mathematics. I know this question might look much more clear to you if I could articulate it in mathematical terminologies. The problem is this is my first question here and I don't know how to ask it in maths languages! So bare with me...\n\nI am making a car-racing game where multiple players on the Internet can compete with each other. Each player drives a car whose position and rotation changes continuously over time. To let players over the network share the same game I have to quickly deliver each player's position and rotation to all other player. The problem is there is always going to be a network latency between data being sent and being received. In other words, by the time a piece of data reaches another player, it is already dated.\n\nI think the solution to my problem is to make a function that can predict the position and rotation of other cars based on the previous data collected. When newer data arrives, the function should have a feedback so that error could be corrected. Parameters used for prediction should also be modified, maybe.\n\nFor example, I am thinking about sampling the position as well as velocity of my car evenly over time, and sending them to other player one by one. Now before other players receive my new data, they can use their own \"predicted velocity\" to approximate my movement. Once the new data arrives, they can use the new position and velocity to do error correction and make new predictions.\n\nSome additional requirements about the function includes:\n\n  1. Efficiency: the prediction and error correction function must be efficient because it is going to be computed by computer every tens of milliseconds.\n  2. Robust: I will sample evenly but the other players won't receive data at an even speed, due to network uncertainties.\n  3. Error Bound: it would be great if there is a way to confine error within a certain range.\n\nI have been googling papers for such functions but I haven't found much useful information. Maybe it's because I don't have the correct keywords. So any answer/comment that\n\n  1. helps to identify & clarify the problem in the math realm\n  2. points to papers of solutions\n\nis highly appreciated!\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYou might want to consider a Kalman filter with a very low measurement error (since presumably, when a player receives an update about position and rotation through the network, that update is treated as gospel).\n\nIn a little more detail, if you have last known position $x$, velocity $v$, rotation $\\theta$ and angular velocity $\\omega$, then you can compute an updated position and velocity after time $\\delta t$:\n\n$$x \\leftarrow x + v \\delta t$$ $$v \\leftarrow v$$ $$\\theta \\leftarrow \\theta + \\omega\\delta t$$ $$\\omega \\leftarrow \\omega$$\n\nSince this involves two multiplications and two additions, it should be fast. You do this every $\\delta t$ seconds until you receive an update, at which point you set the position, velocity, rotation and angular velocity to their updated values, and continue as before.\n\nIf you additionally have the last known acceleration $a$ and angular acceleration $\\nu$ then your update equations become:\n\n$$x \\leftarrow x + v \\delta t + \\tfrac{1}{2} a \\delta t^2$$ $$v \\leftarrow v + a \\delta t$$ $$\\theta \\leftarrow \\theta + \\omega \\delta t + \\tfrac{1}{2} \\nu \\delta t^2$$ $$\\omega \\leftarrow \\omega + \\nu \\delta t$$\n\nwhich will be more accurate, as they take the time-varying velocity and angular velocity into account (whereas the previous equations assume they are constant).\n\nAs for bounding the error, it will depend somewhat on how the game works and how fast quickly the players can change their accelerations. For a naive estimate, you can say that the error in position from the first set of equations is $O(n v \\delta t^2)$ where $n$ is the number of time steps since you received an update, and in the second case it is $O(na\\delta t^3)$, but if the accelerations have changed significantly since you last received an update, these bounds can be violated.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/401530/how-does-one-show-that-two-functors-are-not-isomorphic\nText:\nTake the 2-minute tour \u00d7\n\nLet $C$ be the category of finite-dimensional vector spaces over some field. It is easy to construct pairs of endofunctors $F, G$ of $C$, of the same variance, such that $F(V)$ and $G(V)$ have the same dimension for every $V \\in C$, yet are not naturally isomorphic.\n\nFor example, we could take $G(V) := (V^*)^{\\otimes 2}$, and $F(V) := (V^{\\otimes 2})^*$, where $*$ denotes the dual. Or, I'm sure many of us have, at some time, tried showing that $(\\Lambda V)^* \\simeq \\Lambda(V^*)$ canonically, before realizing that it is false. A convincing reason why they are not canonically isomorphic is that there is no obvious reason, in terms of universal properties, why they should be. In other words: if you try proving that $(\\Lambda V)^* \\simeq \\Lambda(V^*)$ canonically, you're going to have a bad time.\n\nHowever, how does one explicitly show that $F$ and $G$ are not isomorphic? Is there a slick, systematic way of doing this?\n\nEdit: Well, my examples couldn't be worse, as Mariano points out. But the gist of my question still stands (perhaps just get rid of the finite-dimensionality assumption ;))\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere is one way to construct families of endofunctors $F, G$ of $\\text{FinVect}$ that can't be distinguished on the basis of dimension counts. First, consider the family of endofunctors $V \\mapsto S^n(V)$, and second, consider the family of endofunctors $V \\mapsto \\Lambda^n(V)$. The first sends vector spaces of dimension $d$ to vector spaces of dimension ${d+n-1 \\choose n}$ while the second sends vector spaces of dimension $d$ to vector spaces of dimension ${d \\choose n}$. Both of these form bases for the space of integer-valued polynomials in one variable ($d$), hence together there are many linear dependences between them. The smallest one is that\n\n$${d+1 \\choose 2} = {d \\choose 2} + d$$\n\nwhich implies that $F(V) = S^2(V)$ and $G(V) = \\Lambda^2(V) \\oplus V$ can't be distinguished by their dimension counts.\n\nNevertheless, they are not isomorphic. The reason is that for any endofunctor $F$, the vector space $F(V)$ naturally admits the structure of a $\\text{GL}(V)$-representation, and $S^2(V)$ and $\\Lambda^2(V) \\oplus V$ are not isomorphic as $\\text{GL}(V)$-representations. More simply, you can consider the action of a diagonal matrix on $S^2(V)$ and on $\\Lambda^2(V) \\oplus V$ and verify that the traces (which are symmetric functions) are different.\n\nIn fact I think every endofunctor (edit: defining a polynomial function between Hom spaces, see Steve's comment) of $\\text{FinVect}$ is equivalent to a direct sum of Schur functors, so they can all be distinguished in this way up to isomorphism. (I need some mild hypothesis on the base field; I think characteristic zero suffices.)\n\nshare|improve this answer\nNice example, +1. \"In fact I think every endofunctor of FinVect is equivalent to a direct sum of Schur functors...\" Probably you need to assume the functors are polynomial on Hom spaces (obviously direct sums of Schur functors are). \u2013\u00a0 S123 May 24 '13 at 23:11\nOh, hmm. I suppose there are endofunctors induced from endomorphisms of the base field and that these can be distinguished by applying the endofunctors to a one-dimensional vector space... \u2013\u00a0 Qiaochu Yuan May 24 '13 at 23:16\nGood point, char. 0 is also necessary. \u2013\u00a0 S123 May 24 '13 at 23:37\nYes, I think something funny happens in positive characteristic because of divided powers, e.g. I think $S^p(V)^{\\ast}$ and $S^p(V^{\\ast})$ fail to be isomorphic in characteristic $p$, but I'm not sure about the details. \u2013\u00a0 Qiaochu Yuan May 25 '13 at 4:35\nJust to be sure: By $S^n(V)$ you mean $\\mathrm{Sym}^n(V)$, the $n$th symmetric power, right? \u2013\u00a0 Martin Brandenburg May 25 '13 at 10:00\n\nThe functors $FV=(V^*)^{\\otimes 2}$ and $G(V)=(V^{\\otimes2})^*$ on the category of finite fimensional vector spaces are isomorphic. The map $\\phi:(V^*)^{\\otimes2}\\to(V^{\\otimes2})^*$ such that $\\phi(f\\otimes g)(v\\otimes w)=f(v)g(w)$ is a natural transformation (defined on the whole category of vector spaces) which in the category of f.d. vector spaces is an isomorphism of functors.\n\nSimilarly, $\\Lambda(V^*)$ and $(\\Lambda V)^*$ are canonically isomorphic on the category of f.d. vector spaces.\n\nshare|improve this answer\nOne thing that does happen is that it is impossible to write down the inverse function for my map in a natural way: one does need to pick a basis and its dual basis to do so. But the resulting map ends up being independent of the choice of the basis, so nothing breaks. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez May 24 '13 at 21:41\nAlso, $\\phi$ is not an isomorphism if $V$ is infinite dimensional. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez May 24 '13 at 21:42\n+1, You are absolutely right! I think that the origin of my misconception, regarding these two examples, is that there does not seem to be a way to appeal directly to the universal property in order to construct the isomorphism (or else it would hold regardless of dimension). It seems that it has to be constructed \"by hand\", and then, by counting dimensions, it happens to be an isomorphism... Anyways, thanks for clearing that up, I'll edit my question. Regards, \u2013\u00a0 Bruno Joyal May 24 '13 at 22:01\nEh. I think the claim that there is a canonical isomorphism between $\\Lambda(V^{\\ast})$ and $(\\Lambda V)^{\\ast}$ is a little strong. I can think of two such isomorphisms one might try to write down, and I have some suspicion I know which one is the \"right\" one, but I'm not entirely convinced. \u2013\u00a0 Qiaochu Yuan May 24 '13 at 22:42\n@QiaochuYuan, I am using the word canonical in the precise sense of natural. There can be several natural isomorphisms between functors. The word canonical has traditionally an added nuance that points to a some sort of preferrence, but that ony makes sense in a context; in other words, right is context-dependent here as everywhere. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez May 24 '13 at 23:37\n\nI would like to address the question posed in the title in its full generality, rather than discussing single cases.\n\nTwo parallel functors are simply objects in a functor category. Citing Awodey:\n\nOne way to prove that two objects are not isomorphic is to use \u201cinvariants\u201d: attributes that are preserved by isomorphisms. If two objects differ by an invariant they cannot be isomorphic. Generalized elements provide an easy way to define invariants....\n\nSo if you are convinced that 2 functors are not isomorphic, try to use that feeling to provide invariants or generalized elements in the functor category that back up your intuition.\n\nIf the functor category is locally small, the above procedure amounts to using the Yoneda embedding: 2 objects in a locally small category are isomorphic if and only if their Yoneda embeddings are isomorphic.\n\nThis is certainly a slick and systematic procedure, but it may not be that easy.\n\nshare|improve this answer\nThis doesn't address the question. \u2013\u00a0 Martin Brandenburg May 25 '13 at 9:58\nwhat is the question in your opinion @MartinBrandenburg ? \u2013\u00a0 magma May 25 '13 at 10:19\nApart from the observation that one can use invariants (which was in a comment which is now deleted, I dunno why), and which applies to anything, not only functors, the rest of what you wrote is basically saying that to show that two functors are not isomorphic you need to show they are not :-) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez May 25 '13 at 14:34\n@MarianoSu\u00e1rez-Alvarez I was not aware of a comment mentioning invariants. I looked at this question only a few hours ago and I did not see that comment. Please note that I plainly said that this procedure is applicable to anything, as long as you can see the * any things* as objects in a suitable category. The rest of my answer is not a tautology. It is a consequence of the Yoneda lemma. I simply emphasized that: to see whether 2 objects are isomorphic, you can check whether the respective Yoneda embeddings are isomorphic. Cont.... \u2013\u00a0 magma May 25 '13 at 15:17\n@MarianoSu\u00e1rez-Alvarez..... This may or may not be easier, but is certainly a different problem, thus not a tautology. Awodey gives an explicit example of this with posets.I realize that my answer is very general, but so appears to be (some of) the OP's questions (title and 3rd paragraph). You and others have covered the specific examples mentioned in the rest of the Op's post. By the way, I do appreciate your smiley, we are all here to help and learn from each other in a relaxed atmosphere :-) \u2013\u00a0 magma May 25 '13 at 15:20\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/163440/will-the-following-expression-be-irrational-rational-or-integer?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWill the following expression be irrational, rational or integer?\n\n$$\\sqrt[3]{\\sqrt a +b} - \\sqrt[3]{\\sqrt a -b}$$\n\nwhere $a$ = $52$ and $b$ = $5$ .\n\nBy intuition, I think this will be an integer.\n\nshare|improve this question\nIt certainly depends on $a,b$. For example, take $a=b=0$, then the expression is $0 \\in \\mathbb{Z}$. Take $a=b=1$ and the expression is $2^{1/3}$ which is irrational. \u2013\u00a0 nullUser Jun 26 '12 at 18:51\n@Bazinga I've added LaTeXed version of your formula. If this is what you meant, you can edit the post ant leave the LaTeX-ed version there. For more about writing math at this site see here or here. \u2013\u00a0 Martin Sleziak Jun 26 '12 at 18:51\nThanks @MartinSleziak \u2013\u00a0 Bazinga Jun 26 '12 at 18:53\nGiven any natural $a,b$, it will be an algebraic integer, therefore either integer or irrational. \u2013\u00a0 sdcvvc Jun 26 '12 at 18:57\nInstead of saying \"irrational, rational or integer\", it may be more useful to say \"irrational, non-integer rational, or integer\". \u2013\u00a0 Dave L. Renfro Jun 26 '12 at 19:02\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nLet's use the identity $(\\alpha + \\beta)^3 = \\alpha^3+\\beta^3+3\\alpha\\beta(\\alpha+\\beta)$\n\nSet $\\alpha =\\sqrt[3]{b+\\sqrt{a}} \\text{ and } \\beta= \\sqrt[3]{b - \\sqrt{a}} \\text { and } \\alpha+\\beta=x$\n\nWe know that $\\alpha\\beta = \\sqrt[3]{b+\\sqrt{a}} \\times \\sqrt[3]{b - \\sqrt{a}} = \\sqrt[3]{b^2-a} = \\sqrt[3]{25-52} = -3$\n\nSo $x^3= b+\\sqrt a + b-\\sqrt a - 9x = 2b-9x = 10-9x$\n\nYou know that you are looking for a real answer, because $a$ is positive and the two cube roots are therefore cube roots of real numbers. Arturo has factorised the cubic, but it is easy to see that 1 is a root (integer roots must be divisors of 10).\n\nshare|improve this answer\n\nThe expression quickly brings to my mind the Cardano formulas for a (depressed) cubic. Which suggested the following:\n\nWe can rewrite as $$\\sqrt[3]{b+\\sqrt{a}} + \\sqrt[3]{b - \\sqrt{a}}.$$ This is a root of the cubic $y^3 + 3py + q=0$, where $b = \\frac{-q}{2}$ and $a=\\frac{q^2+4p^3}{4}$.\n\nWith $b=5$, we have $q=-10$, so $$52 = a = \\frac{100+4p^3}{4}.$$ This gives $4p^3 = 208-100 = 108$, so $p^3 = 27$, or $p=3$.\n\nThus, the expression at hand is a root of the cubic $$y^3 + 9y -10 = 0.$$ This cubic has an obvious integer root $y=1$ (or you could use the rational root test to see if it has any rational roots if this is not obvious), which after factoring gives $$y^3 + 9y - 10 = (y-1)(y^2 + y+10).$$ The quadratic is irreducible over $\\mathbb{R}$, so its roots are complex.\n\nAssuming you mean the real cubic roots of the real numbers, since our number is real, it must equal $1$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/1347/hyperbolic-critters-studying-euclidean-geometry?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nYou've spent your whole life in the hyperbolic plane. It's second nature to you that the area of a triangle depends only on its angles, and it seems absurd to suggest that it could ever be otherwise.\n\nBut recently a good friend named Euclid has raised doubts about the fifth postulate of Poincar\u00e9's Elements. This postulate is the obvious statement that given a line $L$ and a point $p$ not on $L$ there are at least two lines through $p$ that do not meet $L$. Your friend wonders what it would be like if this assertion were replaced with the following: given a line $L$ and a point $p$ not on $L$, there is exactly one line through $p$ that does not meet $L$.\n\nYou begin investigating this Euclidean geometry, but you find it utterly impossible to visualize intrinsically. You decide your only hope is to find a model of this geometry within your familiar hyperbolic plane.\n\nWhat model do you build?\n\nI do not know if there's a satisfying answer to this question, but maybe it's entertaining to try to imagine. For clarity, we Euclidean creatures have built models like the upper-half plane model or the unit-disc model to visualize hyperbolic geometry within a Euclidean domain. I'm wondering what the reverse would be.\n\nshare|improve this question\nSince all Riemannian geometries are, locally, approximately flat, I imagine the intuition would be something like \"imagine everything from a bug's perspective.\" By analogy, we often think of the surface of the Earth as being like a plane, because locally, this is a fairly good approximation. (Minus hills, etc.) \u2013\u00a0 Charles Staats Aug 1 '10 at 20:28\nadd comment\n\n4 Answers\n\nup vote 60 down vote accepted\n\nHere's another version of Doug Chatham's answer, but with details.\n\nIf you lived in Hyperbolic space, then Euclidean geometry would be natural to you as well. The reason is that you can take what is called a horosphere (in the half-space model for us, this is just a hyperplane which is parallel to our limiting hyperplane) and this surface actually has a Euclidean geometry on it!\n\nSo unlike for us, where the hyperbolic plane cannot be embedded into Euclidean 3-space, the opposite is true: the Euclidean plane can be embedded into hyperbolic 3-space! So this is analogous to our understanding of spherical geometry. It's no surprise the spherical geometry is slightly different, however, it fits nicely into our Euclidean view of things, because spherical geometry is somewhat contained in three-dimensional geometry because of the embedding.\n\nshare|improve this answer\nFascinating! Suffice it to say I did not expect such a nice answer to this question. \u2013\u00a0 Zach Conn Aug 2 '10 at 20:42\nI only had a good answer because I was doing hyperbolic geometry in the previous lecture of the summer course I'm teaching. \u2013\u00a0 Charles Siegel Aug 5 '10 at 4:27\nThis is nice and intuitive, in that the \"lines\" of this strange Euclidean geometry are given by nice intuitive geodesics on the horosphere. (Similar to how spherical geometry is more intuitive than the Poincar\u00e9 disk.) \u2013\u00a0 Matt Apr 21 '11 at 1:12\nIn fact, a plane obviously yields standard n-1 dimensional hyperbolic geometry, and a plane with a little bit of curvature (i.e. a hypercycle) will work too if you're willing to use geodesics as your lines, but when the curvature gets to the critical point (so the surface becomes a horosphere, and the number of points at infinity suddenly drops to one), then you get Euclidean geometry, and with curvature past the critical point (so the surface becomes a sphere) you get spherical geometry. This makes it very intuitive that Euclidean is right at the boundary between hyperbolic and spherical. \u2013\u00a0 Matt Apr 21 '11 at 1:45\nadd comment\n\nLook up \"horosphere\" (for example, in page 90 of the Princeton Companion to Mathematics). Wikipedia describes it on its Horoball page.\n\nshare|improve this answer\nCare to explain why this answer is correct? \u2013\u00a0 Qiaochu Yuan Aug 2 '10 at 3:16\nCharles Siegel's answer explains it better than I would have. \u2013\u00a0 Doug Chatham Aug 2 '10 at 12:53\nWhile I am glad you pointed to this link, in the future if you are worried about not explaining well, and just want to provide a link, you should consider just leaving a comment. This seems to be the protocol for this. \u2013\u00a0 BBischof Aug 2 '10 at 14:30\nWell, now that I have enough rep points to make comments on questions I didn't ask or answer, I'll do that. \u2013\u00a0 Doug Chatham Aug 3 '10 at 14:16\nadd comment\n\nAn alternative to the horosphere model ...\n\nIn \"A Euclidean Model for Euclidean Geometry\", Adolf Madur discusses a Disk model of the Euclidean plane. (Madur says that David Gans has priority for discussing this model, so I'll call it the \"Gans Disk\".) The \"lines\" consist of diameters of the Disk, and half-ellipses that have a diameter as a major axis; the measure of the angle between two \"lines\" is defined as the traditional measure of the angle between their respective major axes. With an appropriate metric (which I have forgotten, and which is just missing in the document preview linked), we get all of the Euclidean plane crammed into the Disk.\n\nOverlaying the Gans Disk on the Poincare Disk (or a sub-disk thereof) provides another way for Hyperbolians to study Euclidean geometry. They just have to agree to treat these half-ellipse paths (which I don't think are ellipses to them) as \"lines\", and to alter their concept of angle measure and length accordingly.\n\nThis model might be considerably harder for Hyperbolians to wrap their minds around than the horosphere model, though.\n\nEdit. Since ellipses are projections of tilted circles, we can \"lift\" the Gans Disk to a \"Gans Hemisphere\". (This is actually a middle phase in the derivation of the Gans Disk model.) There, the \"lines\" are great semi-circles, with angles measured via their diameters in the equatorial plane. Not a major refinement of the Gans Disk, but at least the \"lines\" are naturally-occurring geometric objects, instead of the contrived ellipse-paths. Of course, the metric would need adjustment; off the top of my head, I don't know how much more (or less?) complicated that metric would be.\n\nshare|improve this answer\nadd comment\n\nIn a sense there is one model for Euclidean geometry. However, the geometry of the sphere can be studied on spheres with different radii and, thus, different curvature.\n\nFor critters who grew up on a hyperbolic plane there is also a parameter that measures the curvature of their world. Some nice visuals about this and technical details can be found here:\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234473/sum-of-random-variables-uniformly-distributed-0-1-and-0-2\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to get $P(0.9<Y<=1.8)$ for the sum of 2 random and uniform values x1,x2 (so that y=x1+x2) where $x1$~$u(0,1)$ and $x2$~$(0,2)$ and I'm trying to do the convolution for it. Seems like $\\int\\limits_a^b\\int_0^2 xf(x)\\,\\mathrm{d}x$ where a=0.9, b=1.8 and which seems like a logical way to start. I'm not comfortable with convolution but I'm trying to understand the step-by-step reason that this is the proper equation, and how the problem can be solved. I'd like to understand as much about this as possible so I'd like to also compare that problem to finding the $P(0.9<Y<=1.8)$ for just $x1$~$u(0,1)$ where the values summed are independent but still over the same (0,1) area, and also compare it to $P(0.9<Y<=1.8)$ for $exp(2)$ where lambda is 2, which I'm also not really understanding the summed distribution.\n\nshare|improve this question\nHow is $Y$ related to $x_1$ and $x_2$? It is not clear from your description. \u2013\u00a0 Daryl Nov 10 '12 at 22:37\nsum of two random variables is y. \u2013\u00a0 Seyhmus G\u00fcng\u00f6ren Nov 10 '12 at 22:42\nthat's correct, and also added to the above. y=x1+x2 \u2013\u00a0 stackuser Nov 10 '12 at 22:44\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe answer to your question is $\\frac{179}{400}$. First you need to make the convolution of two $p.d.f.$s. However note that this operation is valid only for the independent random variables $X_1$ and $X_2$. I assume they are independent and continue with the solution.\n\nThe result of the convolution will be on the positive $y$ axis, having non zero values between $0$ and $3$. The density of $Y$ is a linear increasing function from $0$ to $1/2$ for $y\\in [0,1]$, a constant function $p_Y(y)=1/2$ when $y\\in [1,2]$ and a linear decreasing function from $1/2$ to $0$ when $y\\in [2,3]$.\n\nWhat remains to do is to find the area under this $p.d.f.$. If you draw and calculate the area either with integrals or using some simple geometric relations, you will find that the area under the curve w.r.t. the square is $0.4$ and the area with respect to the left triange is $19/400$, which adds up to $\\frac{179}{400}$.\n\nshare|improve this answer\nthank you!! so it sounds like the graph is a triangle from 0 to 2 peaking at 1/2. not sure what the limits of integration are here, sounds like a single integral though. if this can be shown in latex, it would be great for visualizing. sorry it tells me i can't upvote until i get to 15 but i would if i could. \u2013\u00a0 stackuser Nov 11 '12 at 1:36\n@stackuser: There's a very elegant solution to that in this case. If this answer answers your question, you can accept it by checking the little checkmark next to it (see this faq and this one). That gives you $2$ reputation points, exactly what you're missing to be able to upvote :-) \u2013\u00a0 joriki Nov 11 '12 at 8:08\ndone and done. that works! there's so much for a newcomer to learn about the stack-exchange rules. \u2013\u00a0 stackuser Nov 11 '12 at 8:27\nadd comment\n\nHere is a blog post describing something similar to the problem you are attempting to solve. Convolution is the way to go.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/258648/cohomology-of-a-tensor-product?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $k$ be a field of characteristic $p$ and $V$ be a $k^p$ vector space. Denote by $k_s$ the separable closure of $k$ and set $G_k := Gal(k_s|k)$. Prove that\n\n$$ H^0(G_k, V \\otimes_{k^p} k_s^p) = V \\\\ H^n(G_k, V \\otimes_{k^p} k_s^p) = 0, \\: r > 0. $$\n\nThe case $n = 0$ is easy, since $(V \\otimes k_s^p)^{G_k} = V^{G_k} \\otimes (k_s^p)^{G_k} = V \\otimes k^p = V$.\n\nI am unsure, if my reasoning in the case $n > 0$ is correct:\n\nWe can view $V \\otimes k_s^p$ as a direct sum of copies of $k^p_s$. If $H^n(G_k, k^p_s) = 0, n>0$ and $H^n(.)$ commutes with the direct sum, the claim is proven.\n\nSo basically my proof assumes, that $H^n(G_k, k_s) = 0$ induces $H^n(G_k, k^p_s) = 0$. Is that correct?\n\nshare|improve this question\nWhat is your $r$? In addition, this seems to be exactly what this book says! \u2013\u00a0 awllower Dec 28 '12 at 14:57\nSorry, I have overlooked your comment. I fixed the typo and will look at the book. Thanks \u2013\u00a0 p.kelly Jan 13 '13 at 21:55\nI looked at the book and couldn't find anything except Lemma 4.3.11 which says: $H^n(G_k,k_s) = 0, n > 0$. I need $H^n(G_k, k_s^p) = 0$. Or did you mean something else? \u2013\u00a0 p.kelly Jan 14 '13 at 14:33\nI mean: at page 40, it is asserted that the tensor product is a direct sum of copies of K(Indeed the sum is different from what you wrote, but I was not remembering well...)And if $k^p$ is separable, then the theorem of Hilbert asserts your statement, right? Or are there some mistakes in the arguments? In any case, thanks for your attention. \u2013\u00a0 awllower Jan 14 '13 at 15:07\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/141792/how-do-you-prove-that-1-is-the-supremum-of-the-set-a-fracmn-m-n-in-m\nText:\nTake the 2-minute tour \u00d7\n\nit might be a simple question.\n\nI need to prove that $1$ is the supremum of the following set: $$A=\\left\\{\\frac{m}{n}\\mathrel{}\\middle|\\mathrel{} m<n\\wedge m,n\\in \\mathbb{N}\\right\\}$$ So, actually I need to prove 2 things:\n\n  1. $\\forall x\\in A .x\\le 1$\n  2. $\\forall \\varepsilon>0 \\ \\exists x\\in A .x>1-\\varepsilon$\n\nSo, the the first requirement is easy to prove, from the defeinition of $A$. but the second is not so simple for me. I've tried to show that this $x$ exists, but I can't show how it looks like.. I guess I should express it with $\\varepsilon$, but I have no success so far.\n\nIf there are other ways to prove it, it'll fine too, and I'll be happy to hear about them.\n\n\nshare|improve this question\nCan you find an integer $N$ with $N>\\frac 1 {\\epsilon}$? (The Axiom of Archimedes, if you have encountered it) \u2013\u00a0 Mark Bennet May 6 '12 at 15:24\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHint: ${n\\over n+1} =1-{1\\over n+1}$.\n\nshare|improve this answer\nI'm not sure how to use it. I guess I should look at $\\frac{1}{n+1}$ as $\\varepsilon$, but still I don't understand how to build $x$ from it :( \u2013\u00a0 RB14 May 6 '12 at 15:41\n@RB14 Given $\\epsilon>0$, select $n$ such that ${1\\over n+1}<\\epsilon$ (why can you do this?). Then show that $1-{1\\over{n+1}} >1-\\epsilon$. \u2013\u00a0 David Mitra May 6 '12 at 15:45\nyeah, apprently I'm a bit idiot :) \u2013\u00a0 RB14 May 6 '12 at 15:48\n@RB14 Not at all; this stuff is hard unless you've been doing it for 15+ years... \u2013\u00a0 David Mitra May 6 '12 at 15:49\nthere supposed to be a continuation to that comment, but I accidently pressed enter, and my chrome browser did not allow me to delete that comment. any way, I get it now, I should select $x$ to be $\\frac{n}{n+1}$ where $n > \\frac{1}{\\epsilon}$. that is possible from the reason Mark mentioned in his comment - the axiom of archimedes. thanks guys! \u2013\u00a0 RB14 May 6 '12 at 15:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/83450/two-questions-about-distributing-points-on-the-surface-of-an-infinite-dimensio?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet H be a separable and infinite-dimensional Hilbert space which we can consider to be a vector space with real scalars and one of its points h as origin (null vector). Let S be an infinite set of unit length vectors of H, all originating from h. Must S always contain pairs of distinct vectors which subtend an angle less than or equal to pi/2 at h? If the answer to this question is negative and S is a counterexample, must S nevertheless always contain pairs of distinct vectors that subtend obtuse angles at h which are arbitrarily close to pi/2?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nI'll use $(u,v)$ to denote the inner product. If $u_1, \\ldots, u_n$ are unit vectors, $0 \\le \\|u_1 + \\ldots + u_n\\|^2 = \\sum_{i,j=1}^n (u_i, u_j)$. There are $n$ terms $(u_i, u_i) = 1$ and $n^2-n$ with $i \\ne j$, so the average of the $(u_i, u_j)$ with $i \\ne j$ must be at least $-1/(n-1)$, and therefore at least one pair has $(u_i, u_j) \\ge -1/(n-1)$. In particular, for an infinite set of vectors the infimum of the angles must be at most $\\pi/2$.\n\nFor an example where all angles are obtuse, if $e_1,\\ e_2, \\ldots$ are orthonormal vectors consider the unit vectors $v_n =\\sqrt{3/4} \\left(e_n - \\sum_{i=n+1}^\\infty 2^{n-i} e_i\\right)$ and note that for $n < m$, $(v_n, v_m) = (3/4) 2^{n-m} \\left( 1 - \\sum_{i=1}^\\infty 2^{-2i} \\right) < 0$.\n\nshare|improve this answer\nBravo! This is a beautiful answer. \u2013\u00a0 Garabed Gulbenkian Dec 14 '11 at 20:57\nI assume that by \"supremum\" you mean \"Limit Superior\" and not \"Least Upper Bound\" \u2013\u00a0 Garabed Gulbenkian Dec 14 '11 at 21:22\nOops, I meant infimum. I'll edit \u2013\u00a0 Robert Israel Dec 14 '11 at 22:12\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/156705/solution-for-assigning-independent-tasks-to-independent-individuals\nText:\nTake the 2-minute tour \u00d7\n\nI have $n$ tasks that I wish to delegate to $m$ independent individuals, where $m$ is a factor or divisor of $n$. Each of the tasks $T_{1} ... T_{n}$ is independent. From the following two extremes, which or what in between, is the optimal solution?\n\n1) Highest quality, least efficient: assign $T_{1}$ to all $I_{j}$ (where $j = 1, 2, 3,..., m$) and choose the best result; move onto $T_{2}$ and do similarly; repeat for all $T_{i}$ (where $i = 1, 2, 3,..., n$).\n\n2) Most efficient, lowest quality: assign $T_{1}$ to $I_{1}$, $T_{2}$ to $I_{2}$, and so on for $T_{m}$ to $I_{m}$. Decide which results are of sufficient quality, then assign $T_{m+1}$ to $I_{1}$, $T_{m+2}$ to $I_{2}$ and so on until $T_{n}$ is assigned to $I_{n}$\n\nThe primary objective is to get as many $T$ finished and of satisfactory quality in a given time $t$.\n\nshare|improve this question\nThis is called a \"assignment problem\". It's a standard problem in Operations Research. You need to explain what the weight W, the efficiency E, and the effectiveness Q are. If $T_i$ is performed by $I_k$, how do these quantities come into play? \u2013\u00a0 Hans Engler Jun 11 '12 at 2:14\n@HansEngler perhaps W, E and Q can be ignored for the moment. \u2013\u00a0 Kaleb Jun 11 '12 at 21:43\nIt looks to me like this may be rather different from an assignment problem: in version 1 you end up assigning every task to every worker. Apparently there is some element of chance involved, in that you only find out the quality of the work after the task is completed. \u2013\u00a0 Robert Israel Jun 11 '12 at 21:58\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nI hope this reformulation of your problem is close to what you meant. You have $n$ tasks $T_1,\\ldots,T_n$ and $m$ workers $I_1,\\ldots,I_m$. Worker $I_i$ will perform task $T_j$ in time $t_{ij}$ (which is known in advance), but the result may or may not be of sufficient quality: the probability that it is of sufficient quality is $p_{ij}$, independent of the results of other workers on this task and this worker on other tasks (and of the assignments that are made). Let $X_{ij}$ be the decision variable, $1$ if worker $I_i$ is assigned task $T_j$, $0$ otherwise. Then the probability that at least one worker completes task $T_j$ with sufficient quality is $1 - \\prod_{i}(1 - p_{ij} X_{ij})$. The objective is to maximize the expected number of tasks completed with sufficient quality, which is $$ \\sum_{j} \\left(1 - \\prod_{i} (1 - p_{ij} X_{ij})\\right)$$ In order for everything to be completed by time $t$, you have the constraints $\\sum_j t_{ij} X_{ij} \\le t$ for every $i$.\n\nThis problem is a nonlinear integer programming problem. It may be quite difficult to find an optimal solution, but methods to get nearly-optimal solutions (e.g. simulated annealing or tabu search) may be useful.\n\nshare|improve this answer\nThanks. This formulation is what I wanted. I'm not too familiar with optimisation as a subject, so would it be possible to solve numerically (obtaining values for the probabilities, etc.) rather than generally? \u2013\u00a0 Kaleb Jun 23 '12 at 10:29\nAs I said: \"It may be quite difficult to find an optimal solution, but methods to get nearly-optimal solutions (e.g. simulated annealing or tabu search) may be useful.\" \u2013\u00a0 Robert Israel Jun 24 '12 at 6:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/53344/sections-of-grassmannian-bundles\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a smooth projective variety of dimension $n$. Take the bundle $TX \\oplus Sym^2(TX)$ over $X$ where $Sym^2(TX)$ is the second symmetric product of the tangent space. The Grassmannian bundle $Gr(n,TX \\oplus Sym^2(TX))$ has a canonical section, namely $TX$.\n\nMy question is: what is the Poincare dual of this section in the cohomology ring of the Grassmannian bundle?\n\nThe cohomology ring is\n\n$H^*(Gr(n,TX \\oplus Sym^2(TX)))=H(X)[c_1,\\ldots, c_n,d_1,\\ldots, d_{{n+1 \\choose 2}}]/$\n\n$(1+c_1+\\ldots +c_n)(1+d_1+\\ldots +d_{{n+1 \\choose 2}})=c(TX \\oplus Sym^2(TX))$\n\nThis is probably a trivial question I am a bit confused about it now.\n\nshare|improve this question\nHi Gergely! This should be not extremely difficult but for sure not completely trivial... I'll think about it later, if no one answers you meanwhile! All the best! \u2013\u00a0 diverietti Jan 26 '11 at 11:57\nMy guess: it is the top Chern class of $Hom(TX,Sym^2(TX))$, that is $\\prod(\\beta_i-\\alpha_j)$ where $\\beta_i$s and $\\alpha_j$s are the Chern roots of the $d$`s and $c$'s respectively, i.e $\\prod(1+\\beta_i)=1+d_1+\\ldots$ \u2013\u00a0 Gergely Berczi Jan 26 '11 at 12:18\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $U$ denote the tautological subbundle. I guess that $c_i = c_i(U^*)$ in your notation. Consider the composition map $$ U \\to p^*(TX + S^2TX) \\to p^*S^2TX, $$ where $p:Gr \\to X$ is the projection. Then your section is the zero locus of this map. In other words, it is the zero locus of a global section of the vector bundle $U^*\\otimes p^* S^2TX$. The section is regular, so the class of the zero locus equals the top Chern class of the bundle. Thus the answer is $$ c_{n^2(n+1)/2}(U^*\\otimes p^*S^2TX). $$ The rest is a straightforward computation.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/7907/how-to-find-all-integer-points-on-an-elliptic-curve/8119\nText:\nTake the 2-minute tour \u00d7\n\nHow can I determine the integer points of a given elliptic curve if I know its rank and its torsion group?\n\nI read same basic books on elliptic curves but as a non-professional I didn't understand everything. Is it true that if rank is 0 and torsion group is isomorphic to a group of order $n$ then the number of integer points is $n-1$? And what is a good reference to learn to determine the integer points if the rank is positive?\n\nI tried to read the book Rational Points on Elliptic Curves but I didn't found an explicit algorithm. I just heard something like take some point and use group law to find the rest. But how can I be sure that I have found every point?\n\nThe curve I had on my mind is $2x^3 + 385x^2 + 256x - 58195 = 3y^2$. I'm not even sure if this is an elliptic curve. I mean why it is projective and why it is isomorphic to a closed subvariety of $\\mathbb{P}_{\\mathbb{Q}}^2$? And why it contain the priviledged rational point $(0,1,0)$?\n\nshare|improve this question\nYour question about curves of rank 0 has positive answer, more or less by definition. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Dec 5 '09 at 22:12\nThanks! I have one curve which is of rank 4 and torsion subgroup isomorphic to trivial abelian group so I would like to know some method to prove the solutions I found are the only one. \u2013\u00a0 amateur algebraist Dec 5 '09 at 22:26\nIn general, you should indicate clearly what is the \"main\" part of your question. \u2013\u00a0 Andrew Critch Dec 6 '09 at 0:32\nIt is a non a trivial fact that the torsion points on an elliptic curve in Weierstrass form have integer coordinates. If the curve is not in the Weierstrass form, it can have rational torsion points that are not integral. I suggest reading Washington's \"Elliptic Curves: Number Theory and Cryptography\". It is very detailed and well written. \u2013\u00a0 Dror Speiser Dec 7 '09 at 17:43\nEssentially the same question was asked earlier on this site: mathoverflow.net/questions/6676/\u2026 \u2013\u00a0 Bjorn Poonen Jan 7 '10 at 17:06\nadd comment\n\n4 Answers\n\nup vote 7 down vote accepted\n\nFinding all the integral points on an elliptic curve is a non-trivial computational problem. You say you are a \"non-professional\" so here is a non-professional answer: get hold of some mathematical software that does it for you (e.g. MAGMA), and then let it run until it either finds the answer or runs out of memory. Alternatively, do what perhaps you should have done at the start if you just have one curve and want to know the answer: post the equation of the curve, and hope that someone else does it for you. Here's another example of an algorithm currently used in these sorts of software (a Thue one was mentioned above but here's a different approach): find generators for the group (already computationally a bit expensive at times, depending on your luck and/or the size of sha), invoke Baker-like theorems saying \"if the coordinates of the point are integral then it must be of the form sum_i n_i P_i with the n_i at most ten to the billion\", and then use clever congruence techniques to massively cut down the search space by giving strong congruences for all the n_i. Then just do a brute force search.\n\nWhether or not this will work for you, I cannot say, because it all depends on how big the coordinates of your curve are. The only clue you give so far is that the conductor is \"bigger than 130000\" [Edit: that was written before the OP edited the question to tell us which curve he was interested in] which of course does not preclude it being bigger than 10^10^10. Also, you need an expert to decide which of the algorithms is best for you. I'd rather do a massive amount of arithmetic in a field of tiny discriminant than a small amount of arithmetic in a field whose discriminant is so large that I can't even factor it, for example.\n\nSo in short the answer is that you're probably not going to be able to do it with pencil and paper, but there are programs around that will do it, if all you want to know is the answer.\n\nEDIT: you posted the equation of the curve. Magma V2.15-10 says the integral points are\n\n[ <-23, -196>, <19, 182>, <61, 784>, <-191, 28>, <103, -1442>, <-19, -144>, <-67, 592>, <23, 242>, <-49, -454>, <-157, -742>, <817, 21196>, <521, 11364>, <3857, 200404>, <10687, -910154>, <276251, -118593646> ]\n\nplus what you get if you change all the y's to -y's.\n\nshare|improve this answer\nOkay. But how can I prove those are the only one? Am I right that the priviledged rational point is not an integer point? \u2013\u00a0 amateur algebraist Dec 6 '09 at 15:32\nMy computer says it has proved those are the only ones. Whether or not you want to believe (a) my computer and (b) the program I used is up to you. If you want to try your own computer and another program (e.g. SAGE, which would also do the job) then feel free. If you want to prove it by hand then I would first buy a lot of pieces of paper, because what takes my computer 30 seconds will take a lot longer to do by hand. As for the \"priviledged rational point\", you can choose whether or not it's an integer point. That's not a maths question, it's a convention question. \u2013\u00a0 Kevin Buzzard Dec 6 '09 at 16:28\nadd comment\n\nThe following Sage code (which I ran with Sage 4.2.1) produces the solutions (and agrees with Magma!):\n\nE = EllipticCurve([0, 1155,0,4608,-6285060])  \nE1 = E.minimal_model()\npts1 = E1.S_integral_points([2,3])\niso = E1.isomorphism_to(E)\npts = [iso(P) for P in pts1]\nsolutions = [(x/6,y/18) for (x,y,z) in pts]\nsolutions = [(x,y) for (x,y) in solutions if x.is_integral() and y.is_integral()]\n\nBefore the first line I used pencil-and-paper to scale the equation to be in Weierstrass form (monic in both X and Y) which involves new variables 6X and 18Y; the solutions a rescaled at the end. In fact we found all S-integral solutions with S={2,3}, i.e. all solutions which are integral except at 2 and 3. (There are 32 of these, of which only 15 are really integral).\n\nJohn Cremona\n\nshare|improve this answer\nadd comment\n\nNo point reinventing the wheel. Use Cremona's table seven on\n\n\nshare|improve this answer\nUnfortunately the curve I had on my mind has larger conductor than 130000 \u2013\u00a0 amateur algebraist Dec 5 '09 at 23:57\nadd comment\n\nThis is handled (with explicit examples) in Nigel Smart's \"The algorithmic resolution of diophantine equations.\" Chapter VII.4, in particular, gives a method for producing finitely many Thue equations whose integer solutions contain the integer solutions to the given elliptic equation.\n\nComputationally, the bottleneck is finding a system of fundamental units for the splitting field.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?t=681376\nText:\nCauchy-Goursat's theorem and singularities\n\nby Verdict\nTags: cauchygoursat, singularities, theorem\nVerdict is offline\nMar27-13, 07:36 PM\nP: 113\nCalculate the closed path integral of [tex]\\frac{z+2 i}{z^3+4 z}[/tex] over a square with vertices (-1-i), (1,i)\nand so forth.\n\n2. Relevant equations\nThe closed line integral over an analytic function is 0\n\n3. The attempt at a solution\nAlright, so first I factored some stuff, leaving me with\n[tex]\\frac{1}{z (z-2 i)}[/tex]\n\nNow, this has a simple pole at 0 and at 2i. However, 2i isn't in the square, so I'm only concerned about the one at 0. Now, I don't know how to continue from here on, formally. I know (do I?) that the answer has to be i*2pi, as that always happens to be the case when doing a closed integral of a function that has 1 singularity (and it is enclosed by the path). But how do I 'calculate' this? I tried writing z = x+iy and the same for dz, and then working it all out and parameterizing the vertices, but that gives horrible expressions to integrate and just doesn't seem right.\n\nIs there something I'm missing?\n\nAlso, there is a follow up question, which concerns the same integral but now over the square with vertices (-1-3i), (1+3i) and so forth. So this encloses both singularities, but they aren't symmetric or anything, so then I can't really go any further. (Is it even true, that when the singularities are distributed symmetrically, that they sort of cancel each others effect and your integral evaluates as 0?)\n\nKind regards\nPhys.Org News Partner Science news on\nNASA data shed new light on changing Greenland ice\nMandelbroth is offline\nMar28-13, 02:36 PM\nMandelbroth's Avatar\nP: 583\nCauchy-Goursat only gets you so far. You have two options:\n\n1. Evaluate it using the typical method of line integrals.\n2. Use the more general theorem.\n\nNot all contour integrals around singularities yield ##2\\pi i##. They do, however, follow the relation $$\\oint_{\\beta}f(z) \\ dz = 2\\pi i \\sum \\mathfrak{R}_{z_i}(f(z))$$\nif ##\\beta## is a Jordan curve, where ##\\mathfrak{R}_{z_i}## denotes the residue of the function at a point ##z=z_i## interior to ##\\beta##.\n\nIf you are unfamiliar with residues, I would suggest using the typical line integral method.\n\nEdit: Didn't see the bottom of your post.\nI see where you would get the idea that they might \"cancel each other out.\" However, it is entirely wrong. Once you get a little further into complex analysis, you'll probably have a kind of epiphany moment where you'll start thinking \"Hey! None of this makes any logical real sense in terms of what I learned from basic calculus. Better start thinking about it differently!\" At that point, everything starts making sense because you'll notice that, in terms of complex numbers, it really doesn't matter what the contour is or where the poles are. As long as the contour contains the same poles and has the same winding number, you get the same answer.\nVerdict is offline\nMar28-13, 02:46 PM\nP: 113\nThank you for your answer!\nI've discussed my issue with the teacher today, and apparently he accidentally gave out exercises that were meant for later in the course. This was only one of them, and I've spent hours thinking about this one and the others, so that is a little frustrating.\n\nEither way, it is still very good to see that what I thought might have been the case is not true at all. I wasn't sure that it was, it just seemed to be so every single time. But its good to know that it is simply not the case. I look forward to getting further into the material though, I really enjoy how elegant everything is in the complex numbers.\n\nRegister to reply\n\nRelated Discussions\nThe Cauchy-Goursat Theorem Topology and Analysis 1\nKln theorem and initial-state singularities High Energy, Nuclear, Particle Physics 0\nContour integral with multiple singularities inside domain without residue theorem?? Calculus & Beyond Homework 14\ngreens theorem and cauchy theorem help Calculus & Beyond Homework 4\nCauchy horizon singularities General Astronomy 2"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/9914/finding-the-height-of-a-d-ary-heap\nText:\nTake the 2-minute tour \u00d7\n\nI would like to find the height of a d-ary heap. Assuming you have an Array that starts indexing at $1$ we have the following:\n\nThe parent of a node $i$ is given by: $\\left\\lfloor\\frac{i+1}{d}\\right\\rfloor$\n\nThe $d$ children of a parent at node $i$ are given by: $di-d+1, di-d+2,\\ldots di+1$\n\nThe height of a heap (which is slightly different than the height of a binary search tree) is a longest path from the root to a leaf. A longest path will always be from the last node in the heap to the root, but how do I calculate this longest path?\n\nMy first Idea is to setup a recurrence relation for the height of the tree:\n\n\\begin{equation} h(1) = 0\\\\ h(i) = h\\left(\\left\\lfloor\\frac{i+1}{d}\\right\\rfloor\\right)+1 \\end{equation}\n\nThis seems overly-complicated and I feel like the answer is much more simple. Is there a better way to find the height of a $d-$ary heap?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nA path from the last node to the leaf would always be a longest path. This is because the last node is always at the lowest level in the heap. Now, assume the root is at level $0$. Then the number of nodes at a completely filled level $i$ would be $d^i$.\n\nLet level $k$ be the last completely filled level in the heap. So the number of nodes upto (and including) level $k$ is: $$\\sum\\limits_{i = 0}^{k}d^i = \\frac{d^{k+1} - 1}{d - 1}$$\n\nNow, the last node - the $n^{th}$ node - can either be the last node at level $k$, or it can be in an incomplete level $k+1$. Taking care of these two cases, it can be seen that: $$\\frac{d^{k+1} - 1}{d - 1} \\le n < \\frac{d^{k+2} - 1}{d - 1}$$ $$\\Rightarrow k\\le \\log_d(n(d-1) + 1) - 1 < k+1$$\n\nNow, equality is only if the last node is the last leaf of level $k$, which also has distance $k$ from the root. If not, that is if there is a level $k+1$, then the $\\log$ term would not be an integer, and applying the ceiling operator would give the right height of $k+1$. Thus, if the last element of the array is at position $n$, the height of the heap is: $$h = \\lceil \\log_d(nd - n + 1) \\rceil - 1$$ You can change the base of the logarithm using the change of base formula. Note that this is the same method that Yuval gives in his answer.\n\nshare|improve this answer\nadd comment\n\nA different approach is to calculate the number of points $n_d(h)$ in a saturated (maximal) $d$-ary heap of height $h$. Given $n_d(h)$, the height of a $d$-ary heap of size $n$ is the minimal $h$ such that $n_d(h) \\geq n$. Given the formula for $n_d(h)$, you should be able to find $h$ explicitly.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?p=2003624\nText:\nFinding max/min given contraint\n\nby ultra100\nTags: constraint equation, lagrange, maximum, minimum, multivariable\nultra100 is offline\nDec15-08, 09:13 PM\nP: 9\n\nFind the product of the maximum and minimum values of the function f(x, y) = xy\non the ellipse (x^2)(1/9) + y^2 = 2\n\n3. The attempt at a solution\n\nI tried soving using lagrange multiplier and got:\n\nfx = y - (2/9)(x*lambda)\nfy = x - 2y*lambda\nflambda = (x^2)(1/9) + y^2 - 2\n\nthen I set these = 0, but my answer came out wrong.. any suggestions for figuring out the min/max?\n\n2. Relevant equations\n\n3. The attempt at a solution\nPhys.Org News Partner Science news on\nAt tech fest: 3D printers, bitcoin and 'Titanfall'\nLondon launches hi-tech trial for pedestrian safety\nLignin breakthroughs serve as GPS for plant research\nNoMoreExams is offline\nDec15-08, 09:23 PM\nP: 626\nFor y I'm getting, [tex] y = \\pm 1 [/tex]\n\nThe way I set this up was as follows:\n\n\n[tex] f(x,y) = xy; g(x,y) = \\frac{x^{2}}{9} + y^{2} = 2 \\Rightarrow h(x,y,\\lambda) = f(x,y) + \\lambda g(x,y) [/tex]\n\n(Note that the sign in front of [tex] \\lambda [/tex] does not matter)\n\nSo let's take our partials, we get:\n\n[tex] \\frac{dh}{dx} = y + \\frac{2 \\lambda}{9}x, \\frac{dh}{dy} = x + 2 \\lambda y, \\frac{dh}{d\\lambda} = \\frac{x^2}{9} +y^2 - 2 [/tex]\n\nWe know that each of those partials vanish i.e. we can set each to 0.\n\nThe first one gives us\n\n[tex] 9y = -2 \\lambda x [/tex]\n\nand the second one gives us\n\n[tex] \\frac{x}{y} = -2 \\lambda[/tex]\n\nAnd by simple substitution we get:\n\n[tex] 9y^{2} = x^{2} [/tex]\n\nSo let's substitute it into our 3rd equation to get:\n\n[tex] y^{2} + y^{2} = 2 [/tex]\n\nWhich yields our desired result of [tex] y = \\pm 1 [/tex]. Now we can plug this into our g(x,y) to get [tex] x = \\pm 3 [/tex]\n\nNote that it doesn't matter which value for y we pick therefore our solution set will be:\n\n[tex] (1,3), (1,-3), (-1,3), (-1,-3) [/tex]\n\nNow if you don't want to do this using Lagrange Multipliers, we can just realize that we can rewrite our g(x,y) as\n\n[tex] y = \\pm \\sqrt{2 - \\frac{x^2}{9}} [/tex]\n\nand now we can substitute this into our f(x,y) get an equation of one variable i.e.\n\n[tex] \\bar{f}(x) = \\pm x \\cdot \\sqrt{2 - \\frac{x^2}{9}} [/tex]\n\nNow we can proceed using the techniques you learned in Calculus 1 (I'm going to use Maple because I'm lazy)\n\n> a:=x*sqrt(2-x^2/9);\n\na := [tex] \\frac{1}{3} x \\sqrt{18 - x}[/tex]\n\n> solve(diff(a,x)=0,x);\n\n-3, 3\n\nNote that choosing the negative root produces the same results.\nultra100 is offline\nDec15-08, 09:31 PM\nP: 9\nwhat equations are you using to get y = to +/- 1?\n\nNoMoreExams is offline\nDec15-08, 09:50 PM\nP: 626\n\nFinding max/min given contraint\n\nQuote Quote by ultra100 View Post\nRefresh your page :)\nultra100 is offline\nDec15-08, 09:56 PM\nP: 9\nThanks!!! This helps a lot\n\nRegister to reply\n\nRelated Discussions\nFinding the Method of moments estimator? Having trouble finding E(Y^2) Calculus & Beyond Homework 1\nFinding the pH of TSP Biology, Chemistry & Other Homework 5\nFinding pH Biology, Chemistry & Other Homework 11\nfinding the inverse and finding a matrix * A = 0 matrix Introductory Physics Homework 6\nFinding Yourself General Discussion 34"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296742/prove-partial-derivatives-of-uniformly-convergent-harmonic-functions-converge-to\nText:\nTake the 2-minute tour \u00d7\n\nI think the title says it all.\n\nIf you have a sequence of harmonic functions from a bounded complex domain to the real numbers, show that on a subset at a positive distance from the boundary of the domain, e.g. a compact subset of the domain, the derivatives of the harmonic functions converge uniformly to the derivative of the limit of the sequence of the harmonic functions.\n\nThank you!\n\nMy attempt: I tried to apply the mean value property (like Gamelin does for analytic functions) to find a bound (unsuccessfully). I know the question has been asked before, but I did not understand the solution. I also tried to come up with something similar to Cauchy estimates for harmonic functions, but I wound up more confused than when I started.\n\nEDIT: Keep in mind by derivative I meant partial derivatives. My attempt was to find an analogue of the Cauchy integral formula (for derivatives) but I seem to get the same formula for both partial derivatives, which does not make sense to me because it seems like the partial derivatives can be different.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nYour approach is correct, I would use the mean value property to try to derive an analogue of the Cauchy estimates. Let $\\Omega$ be the domain, and let $u$ be harmonic. See if you can show that if $B(z,r) \\subset \\Omega$, then $$ |\\partial_i u(z)| \\le Cr^{-1} \\|u \\|_{L^{\\infty}(\\partial B(z,r))}$$ You will be using both the mean value property (since $\\partial_i u$ is itself harmonic) and the divergence theorem. If you have further questions I can elaborate more.\n\nElaboration: The $L^{\\infty}$, in the context of continuous functions (such as the harmonic functions in this problem), is just the norm corresponding to uniform convergence. So the sequence of harmonic functions $u_n$ converging uniformly on a compact set $K$ can be rewritten as $\\|u - u_n\\|_{L^{\\infty}(K)} \\rightarrow 0$ as $n \\rightarrow \\infty$.\n\nTo obtain the estimate in question, first use the mean value property to obtain: $$ \\partial_i u(z) = \\frac{1}{\\pi r^2} \\int_{B(z,r)} \\partial_i u(x,y) \\, dx \\, dy, $$ which follows from $\\partial_i u$ itself being harmonic. By the divergence theorem, then this is equal to $$ \\frac{1}{\\pi r^2} \\int_{\\partial B(z,r)} u \\nu^i \\, dS, $$ where $\\nu^i$ is the $i$-th component of the unit vector normal to the surface $\\partial B(z,r)$. Thus $$ |\\partial_i u(z)| \\le \\frac{1}{\\pi r^2} \\int_{\\partial B(z,r)} |u| \\, dS = \\frac{2}{r} \\|u\\|_{L^{\\infty}(\\partial B(z,r))}$$ This allows you to control the pointwise convergence of the partial derivatives of $u_n$ by the uniform convergence of $u_n$. However, this in turn allows you to control the uniform convergence of the derivatives on a compact set, since then you can just use larger balls.\n\nshare|improve this answer\nHello. I'm unfamiliar with L norms. I'm learning about harmonic functions in a one variable complex analysis course. I was wondering if you could elaborate on how you derived the given inequality. I'm still unsure of where divergence theorem comes in. I think I was able to derive the Cauchy integral formula for harmonic functions but the formula for derivative I'm getting seems to be the same for all the partial derivatives... \u2013\u00a0 MR1992 Feb 7 '13 at 0:35\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/193094/does-lvert-p-rvert-leq-lvert-q-rvert-imply-up-f-leq-uq-f\nText:\nTake the 2-minute tour \u00d7\n\nLet $P = \\{a=x_0,x_1, \\ldots, x_n=b\\}$ be a partition on the interval $[a,b]$. Then $\\lVert P\\rVert$ denotes the norm of partition $P$, defined to be the length of the greatest subinterval of the form $[x_{i-1},x_i]$.\n\nLet $f:[a,b] \\to \\mathbb{R}$ be a bounded function. Define $M_i = \\operatorname{sup} f([x_{i-1},x_i])$ for all $i = 1, \\ldots,n$ and the upper sum of $f$ corresponding to $P$ is $U(P,f)= \\sum_{i=1}^{n}{M_i\\Delta x_i}$ (where $\\Delta x_i = x_i - x_{i-1}$). Here is the real question:\n\nSuppose $P$, $Q$ are two partitions on $[a,b]$ such that $\\lVert P\\rVert \\leq \\lVert Q\\rVert$. Then is it true that $U(P,f) \\leq U(Q,f)$?\n\nThis seems to be true intuitively, but I can't find a solid argument to claim so. I tried to look for counter-examples too, but without any success. I would appreciate any help regarding this problem. Thanks and regards.\n\nshare|improve this question\nAs already pointed out in the answers, this is not always true. However if you additionally assume that every point of $Q$ is a point of $P$ (i.e. $P$ is a so called refinement of $Q$), then your claim will follow. See for example baby Rudin Theorem 6.4. \u2013\u00a0 user22705 Sep 9 '12 at 10:20\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nThis isn't necessarily true. Here is a counterexample: $$ f(x) = \\begin{cases} 0 & \\text{if } 0 \\le x \\le 2 \\\\ x & \\text{if } 2 \\lt x \\le 3 \\\\ \\end{cases} $$\n\nConsider two partitions: $P = [0, 1, 2, 3]$, $Q = [0, 2, 2.5, 3]$.\n\nClearly $\\|P\\| = 1$, $\\|Q\\| = 2$. Therefore $\\|P\\| \\le \\|Q\\|$.\n\nHowever $U(P, f) = 3$, $U(Q, f) = 2.75$. Therefore $U(P, f) > U(Q, f)$.\n\nshare|improve this answer\nadd comment\n\nAs an strengthening of Ayman's answer, suppose $P$ and $Q$ are partitions such that there is even a single point in $P$ that is not in $Q$. Then for any $m$, $M$ with $m\\le M$, there exists an $f$ such that $U(P,f) = M$, $U(Q,f)=m$, i.e. I can make $U(P,f)$ as large as I like while keeping $U(Q,f)$ small.\n\nThe technique is simple: find a point $x$ in $P\\setminus Q$, and pick $y_k$ in $Q$ such that $y_k<x<y_{k+1}$. Then give $f$ a huge spike on the interval $(y_k, y_{k+1})$, and $Q$ will not pick it up at all, but $U(P,f)$ can be made arbitrarily large.\n\nHence you really need $P\\subseteq Q$ to conclude anything about $U(P,f)$ relating to $U(Q,f)$.\n\nshare|improve this answer\nadd comment\n\nAyaman's counterexample works even if you restrict yourself to equidistant partitions. If $0<\\alpha<1$ and $$f(x) = \\begin{cases}1&0\\le x <\\alpha\\\\0&\\alpha\\le x\\le1\\end{cases}$$ and let $P_n$ be the equidistant partition $\\{x_0=0, x_1=\\frac1n,\\ldots, x_n=1$}, then $\\Vert P_n\\Vert=\\frac1n$ and $U(P_n,f)=\\frac1n(\\lfloor n \\alpha\\rfloor+1)$. For example, $\\alpha=\\frac12$ leads to the sequence $$1, 1, \\frac 23, \\frac34,\\frac35,\\frac23, \\frac47, \\frac58,\\ldots $$ that converges to $\\frac12$, but not monotonously.\n\nshare|improve this answer\nadd comment\n\nHere is a different counterexample. Let $f$ be the function $f(x)=0$ for $x \\in [0,2] $ except $f(.75)=f(1.25)=1$.\n\nThen for $P=\\{0,.75,1.25,2\\},\\;\\;Q=\\{0,.5,1.5,2\\}$ we have$||P||=.75<1=||Q||$ but $U(P,f)=2>1=U(Q,f)$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/130088/two-variable-recurrence-equation-with-varying-coefficients\nText:\nTake the 2-minute tour \u00d7\n\n\nI have the following two variable recurrence equation for integers $j,k$:\n\n$f(j,k) = (k/j)f(j-1,k-1) - (3 + k/j)f(j-1,k+2)$\n\nwhere $f(j,0) = (3^j - 1)/j + 3jf(j-1,2)$, $f(0,0) = 0$, $f(0,k) = a_k$.\n\nI would like to express $f(n,0)$ in terms of the different $a_k$ values.\n\nI tried a generating function approach, by considering the generating function $\\phi(x,y) = \\sum_j\\sum_k f(j,k)x^jy^k$, but it gives rise to a nasty differential equation.\n\nAny ideas on how to attack this recurrence equation? Maybe by just calculating it for a few $n$ values, observe a pattern and use induction? The latter is also quite tedious. Is there any neat approach to this?\n\nshare|improve this question\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/237280/smallest-imperfect-graph-whos-chromatic-number-equals-clique-number\nText:\nTake the 2-minute tour \u00d7\n\nSo I need to find the smallest imperfect graph, $G$ who's chromatic number equals it's clique number. ie:\n\n$$\\chi(G) = \\omega(G)$$\n\nFinding imperfect graphs isn't hard (since finding perfect graphs is). Even finding imperfect graphs with this property isn't too hard. But how do we find the smallest graph (I assume minimal # vertices). Even if I have an idea what this graph is, how can I prove it is the smallest? I.e if I think sum graph on $n$ vertices is the smallest graph satisfying this, it seems daunting to show every graph of order $<n$ fails to satisfy this (unless $n$ is relatively small).\n\nMethods to approach and tackle this problem?\n\nshare|improve this question\nWhat is the smallest $n$ you can easily find an example for? \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 16:19\n$C_5$ with an added internal vertex connected to 3 vertices of $C_5$, 2 of which neighbours, 1 of which is not a neighbour to either. so $n=6$ \u2013\u00a0 user45814 Nov 14 '12 at 16:53\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nConsider the cyclic graph with five vertices $a,b,c,d,e$ and add a sixth vertex $f$ with edges $af$, $bf$, $df$. Then $\\omega(G)=\\chi(G)=3$ and the graph is not perfect becaus the induced subgraph obtained by removing $f$ has $\\chi=3$ and $\\omega=2$.\n\nWhy is six minimal? For graphs up to four vertices, $\\chi=\\omega$ always holds, hence every graph with at most five vertices having $\\chi=\\omega$ is perfect.\n\nshare|improve this answer\nOh, I see you found that by yourself in a comment meanwhile. \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 17:05\nYes, but couldn't find a way to show it was minimal. Thanks! \u2013\u00a0 user45814 Nov 14 '12 at 17:13\nIs there an easy way to show for graphs up to four verticies that X=w? I can tell it's true, but not sure if I can just state that (Ill post this as a new question, since it seems it may take some thought) \u2013\u00a0 user45814 Nov 14 '12 at 17:44\nIf $\\omega=n$, then trivially $\\omega=\\chi$. If $\\omega=n-1$, then colour a maximal clique with $\\omega$ colours and the remaining vertex with the colour of one of its non-neighbours. If $\\omega\\le n-2$, then $G$ is either $C_4$ or a tree with $\\chi=2$ or disconnected with $\\chi=1$. \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 17:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/16059/can-a-super-extremal-charged-black-hole-be-made-out-of-electrons-only/16061\nText:\nTake the 2-minute tour \u00d7\n\nIn a previous Question it was argued that it would be impossible to add enough charge to a black hole to make it pass the extremal black hole limit since adding charge would increase the mass of the black hole due to the electrostatic field energy (and thus mass) that would be added as the charge is added.\n\nNote that an electron cannot be a black hole but if an electron were a black hole it would be a super-extremal black hole per this wikipedia article: Basically the Schwarzchild radius for the electron's mass is $r_s = 1.35 \\times 10^{-57} m$ whereas the charge radius of the electron is $r_q = 9.15 \\times 10^{-37} m$. So since $$\\frac{r_q}{r_s} \\approx 10^{21} \\gt 1$$ an electron, if it was a black hole, would be a super-extremal black hole by a large margin. In words, the electrons mass is completely negligible compared to its charge.\n\nAn uncharged black hole can be constructed out of matter at any given mass density by simply constructing a big enough sphere of that matter. This is true because a sphere of radius $R$ with a constant (low?) density will have a mass $M$ that is $\\propto R^3$ whereas the Schwartzchild radius is $\\propto M \\propto R^3$. So as $R$ increases the radius of the sphere will eventual be less than the Schwartzchild radius.\n\nSo, can we make a super-extremal charged black hole by using a very large sphere of radius $R$ that is made out of electrons uniformly distributed with (low) charge density $\\rho$?\n\nshare|improve this question\nI was hoping the answer was yes, but as I did the calculations I convinced myself it would not work, so I am documenting my calculations by asking and answering this question. I hope this might be interesting to other people and I hope you will check my calculations. If my answer is wrong, please correct me! \u2013\u00a0 FrankH Oct 23 '11 at 8:13\nIt should be added that there is no reason to suppose that the relation Q=M for extreme black holes is correct for black holes the size of electrons. Electrons are quantum black holes in string theory--- they are strings--- and the lightest black hole excitation in a charged string theory always is on the other side of the extremality bound. Whether you call it a black hole is a matter of convention, but you can't use classical GR to describe something that small. \u2013\u00a0 Ron Maimon Oct 23 '11 at 17:44\nYes, @ron, you are right. The electron cannot be a black hole for lots of reasons. The electrons Schwartzchild radius is many orders of magnitude smaller than the Planck length so classical GR will not apply. I will edit the question to clarify that. Thanks. Any opinion on my answer would be appreciated. \u2013\u00a0 FrankH Oct 23 '11 at 18:17\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe answer is no. As stated, the electrons mass will be ignored. If we assume the mass of the sphere is just due to the electrostatic field energy of the uniformly charged sphere, can we create a black hole and can the charge to mass ratio $\\frac{Q}{M}$ be super-extremal ($\\frac{Q}{M} \\gt 1$ in appropriate units).\n\nNow the charge of the sphere is $$Q \\propto \\rho R^3$$ the electric field strength $E(r)$ as a function of the radius $r$ is $E(r) \\propto \\rho r$ and the mass $M$ due to the electrostatic field energy is $$M \\propto \\int_0^R E^2(r) d^3r \\propto \\rho^2 R^5 $$ Therefore the ratio of charge to electrostatic field energy-mass is $$\\frac{Q}{M} \\propto \\rho^{-1} R^{-2}$$\n\nConsider the case of constant $\\rho$ with $R$ increasing: Since $M \\propto R^5$ increases rapidly, eventually a black hole will form. However the ratio $\\frac{Q}{M}$ will decrease as $R$ increases, so it will not be an extremal black hole.\n\nNow consider the case of constant $R$ with $\\rho$ increasing: Since $M \\propto \\rho^2$ a black hole will eventually form. but again the ratio $\\frac{Q}{M}$ will decrease as $\\rho$ increases, so it will not be an extremal black hole.\n\nTherefore it is impossible to create a super-extremal black hole from a uniform sphere with a constant charge density since the electrostatic energy-mass alone will create a black hole with a charge to mass ratio less than 1. Any additional neutral mass added into the sphere will result in an even lower charge to mass ratio so that will also not be super-extremal.\n\nshare|improve this answer\n+1: nice answer. \u2013\u00a0 Ron Maimon Oct 23 '11 at 18:35\nDue to the fact that no one has found any mistake in my calculations for the past 2 weeks, I am accepting my own answer so this will not stay as an open question forever... \u2013\u00a0 FrankH Nov 5 '11 at 4:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/54866/algorithm-for-graph-with-nodes-grouped-into-sets\nText:\nI have a weighted graph. The nodes of this graph are grouped into sets, and each node has only one corresponding set (no overlapping). Nodes in the same set do not have edges between them. An edge only connects nodes that are in different sets.\n\nI want to select one node from each set, such that the total weight of the edges between these nodes is minimized. Between two sets, I will only be traversing one edge.\n\nOnly some sets are adjacent to each other, they are not all interconnected. But some sets do have multiple neighbours. When one set is adjacent to another, the nodes in these two sets form a complete bipartite graph.\n\nAre there any algorithms to accomplish this? And is there a name for this type of graph?\n\n  \u2022 $\\begingroup$ When you say \"the toatal edge weight is minimized\", you mean the total weight of the edges between the selected vertices? This doesn't look at all like a minimum spanning tree, to me: the structure you're selecting is neither spanning (it doesn't touch every vertex) nor a tree. $\\endgroup$ \u2013\u00a0David Richerby Mar 24 '16 at 2:28\n  \u2022 $\\begingroup$ Yes, the total weight of the edges between the vertices. I said spanning tree because I want to touch all sets, selecting one node from each. It's not really a spanning tree, that may have been a poor analogy. $\\endgroup$ \u2013\u00a0Vermillion Mar 24 '16 at 2:33\n\nThe special case of zero-one weights is already NP-hard. In fact, even determining whether there is a choice such that the total weight is zero is NP-hard. See this question on cstheory.se. (You can arrange that all the weights are, say, $1$ or $2$, and then the condition that two connected parts are fully connected is satisfied.)\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/123951/find-two-contiguous-subarrays-with-the-greatest-difference\nText:\nHere's an interview question I've seen on a few sites. People claim that an O(n) solution is possible, but I've been racking my brain these last 2 days and I couldn't come up with a solution, nor find one anywhere on the web.\n\nGiven an array of integers, find two disjoint, contiguous subarrays such that the absolute difference between the sum of the items in each subarray is as big as possible.\n\nExample input: (2, -1, -2, 1, -4, 2, 8)\n\nExample output: ((1, 4), (5, 6))\n\nThe output above is the indices of these two subarrays: ((-1, -2, 1, -4,), (2, 8))\n\nI've been trying to reduce this problem to the Maximum subarray problem but with no success.\n\n  \u2022 $\\begingroup$ Hint, two contiguous subarrays means the last element of the first subarray is adjacent to the first element of the second subarray. Did you see a parameter here? $\\endgroup$ \u2013\u00a0John L. Apr 11 at 17:35\n  \u2022 $\\begingroup$ I believe OP did not mean that the two subarrays are adjacent. My guess is that they used the word 'contiguous' to just mean that the two disjoint subarrays are independently contiguous themselves, which I think is redundant given the definition of subarray. But it is still used in many places. eg. \"finding a contiguous subarray with the largest sum\" in en.wikipedia.org/wiki/Maximum_subarray_problem $\\endgroup$ \u2013\u00a0CodeChef Apr 11 at 17:45\n  \u2022 1\n    $\\begingroup$ @CodeChef Unfortunately, the example given in the question can be considered the supposed interpretation of \"contiguous subarray.\", although it does not rule out the possibility to treat is as \"redundant\" as well. Treating it as meaningful and not redundant shows, I believe, the most respect to the almost universal convention that \"subarray means contiguous elements\" and, hence, the the author of the original problem. $\\endgroup$ \u2013\u00a0John L. Apr 11 at 17:53\n  \u2022 1\n    $\\begingroup$ Yes, I agree. My guess was also based on having seen this problem (the variant I assumed it to mean) multiple times in relation to interview questions, but you are absolutely right. $\\endgroup$ \u2013\u00a0CodeChef Apr 11 at 17:57\n\nBecause the two subarrays are disjoint, there exists at least one index $m$ such that one entire subarray lies $\\leq m$ and the other subarray lies $\\gt m$.\n\nBut we do not know what this $m$ is, beforehand. So let us iterate over all the $n$ possibilities for $m$. Now if an $m$ is fixed, then the problem reduces to the Maximum subarray problem, and the Minimum subarray problem. This is because for the absolute difference to be the largest, one side of $m$ should have the maximum possible subarray, and the other side should have the minimum possible subarray. So we try both of these options and take the maximum absolute difference among the two.\n\nBut this is still $\\mathcal{O}(n^2)$, because there are $n$ different values of $m$, and for each of those values, we have to spend $\\mathcal{O}(n)$ time to compute the needed minimum and maximum subarrays.\n\nThe next observation is to note that a single $\\mathcal{O}(n)$ run of the Maximum subarray algorithm on the entire array can actually give us one of the needed values for all values of $m$:\n\nGiven: int A[n]\n\nMaxSubarrayTill[0] = A[0]\nMaxSubarrayEndingAt[0] = A[0]\n    MaxSubarrayEndingAt[i] = max{A[i], MaxSubarrayEndingAt[i - 1] + A[i]}\n    MaxSubarrayTill[i] = max{MaxSubarrayTill[i - 1], MaxSubarrayEndingAt[i]}\n\nHere, $\\text{MaxSubarrayTill}[i]$ denotes the maximum sum subarray which ends $\\le i$, and $\\text{MaxSubarrayEndingAt}[i]$ denotes the maximum sum subarray which ends at index $i$.\n\nSimilarly, we can compute the $\\text{MinSubarrayTill}[i]$ array in $\\mathcal{O}(n)$ time. And by repeating the same two algorithms in reverse (ie. from the end of the array to the beginning), we can get $\\text{MaxSubarrayFrom}[i]$ and $\\text{MinSubarrayFrom}[i]$.\n\nSo in $\\mathcal{O}(n)$ time we have precomputed all the values that we needed in the first algorithm, which we can now go back to. Interate over all the values of $m$, and find the largest absolute difference in $\\mathcal{O}(n)$ time.\n\nIf the problem also stipulates that the two subarrays should be adjacent, then we can leave out $\\text{MaxSubarrayTill}[i]$ and its analogous arrays, and instead only consider $\\text{MaxSubarrayEndingAt}[i]$ and its analogous three other arrays. The rest of the algorthm remains the same.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathlair.allfunandgames.ca/missingdollar.php\nText:\n[Math Lair] The Missing Dollar\n\nMath Lair Home > Puzzles & Problems > The Missing Dollar\n\nThree men decide to spend a night in a hotel room. They pay $30 for the room (assume that this took place a long time ago, when hotel rooms might have actually cost $30). They split the cost evenly amongst themselves, with each man paying $10. As they are about to leave, the manager of the hotel, realizing that the three men are frequent patrons of the hotel, decides to give the men $5 back. He gives $5 to the bellhop and asks him to give the money to the three men. The bellhop, not wanting to split $5 among the three men, decides to pocket $2 of the money and gives each of the three guests $1. Each of the guests has now paid $9 for the room, for a total of $27, and the bellhop has $2, for a total of $29. Where is the missing dollar?\n\nMany people find this problem rather frustrating. The key to it is to look at it in a different way. The three men each paid $30. Out of that, $25 is in the hotel's cash register, $2 is in the bellhop's pocket, and each of the three men have $1, for a total of $30. Looking at it this way, there is no missing dollar. So why is there a dollar missing in the analysis above?\n\nThe problem contains a trick. Each of the guests paid $9, for a total of $27. That $27 includes the $2 in the bellhop's pocket. You can't add that $2 to the $27 and expect to get a meaningful result, but that's what the problem does. The sum in the problem is a red herring that doesn't correspond to any real-life amount."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/58000/maximum-cost-path-in-integer-matrix\nText:\nIn preparation for my design and algorithms exam, I encountered the following problem.\n\nGiven a $2 \\times N$ integer matrix $(a[i][j] \\in [-1000, 1000])$ and an unsigned integer $k$, find the maximum cost path from the top left corner $(a[1][1])$ and the bottom right corner $a[2][N]$, given the following:\n\n$\\bullet$ The path may not go through the same element more than once\n\n$\\bullet$ You can move from one cell to the other vertically or horizontally\n\n$\\bullet$ The path may not contain more than $k$ consecutive elements from the same line\n\n$\\bullet$ The cost of the path is determined by the sum of all the values stored within the cells it passes through\n\nI've been thinking of a simple greedy approach that seems to work for the test cases I've tried, but I'm not sure if it's always optimal. Namely, while traversing the matrix, I select a the maximum cost cell on the vertical or horizontal and then go from there. I've got a counter I only increment if the current cell is on the same line with the previously examined one and reset it otherwise. If at some point the selected element happens to be one that makes the counter go over the given value of $k$, I simply go with the other option that's left.\n\nHowever, I feel that I'm missing out on something terribly important here, but I just can't see what. Is there some known algorithm or approach that may be used here?\n\nAlso, the problem asks for an optimal solution (regarding temporal complexity).\n\n\nThis problem was basically made for dynamic programming (DP). Just review it and follow a couple of examples and solving this problem is straight-forward.\n\nYour simple greedy approach does not always work. Consider:\n\n[ begin ] [  2 ]\n[ 3 ]     [ 10 ]\n[ 1 ]     [ -1000 ]\n[ 1 ]     [ end ]\n\nThe optimal solution would be to go right, down, left, down, down, right.\n\n  \u2022 $\\begingroup$ I meant $2$ lines and $N$ columns, but I guess it doesn't make a difference in this case. $\\endgroup$ \u2013\u00a0user43389 May 29 '16 at 23:28\n\nWe shall approach this using dynamic programming -- the greedy algorithm is 'myopic' in that it only considers immediate neighbors and not the path that follows those neighbors.\n\nLet $C(i, \\ j, \\ m)$ be the cost of the max-cost path starting from $a[i][j]$ going towards $a[2][n]$, where $i$ is either $1$ or $2$, $\\ j \\in [1, n]$ and $m \\in [0, k]$.\n\n  \u2022 $m$ here denotes that we have $m$ remaining consecutive steps that could be taken along row $i$.\n  \u2022 The additional constraint we enforce here is that when we are calculating $a[1][i]$, we have not yet visited $a[2][i]$, and similarly when we're calculating $a[2][i]$, we have not yet visited $a[1][i]$.\n\nWith this constraint in place, what recurrence can we come up with? Well,\n\n  1. $C(1, \\ j, \\ m) = a[1][j] + \\max \\{ M(1, j+1, m-1), \\ a[2][j] + M(2, j+1, k)\\} \\ $ and similarly,\n  2. $C(2, \\ j, \\ m) = a[2][j] + \\max \\{ M(2, j+1, m-1), \\ a[1][j] + M(1, j+1, k)\\} \\ $\n\nNow, what's the rationale here? If we started at $a[1][j]$, we have two choices:\n\n  \u2022 continue along row $1$ : we then go to $a[1][j+1]$ with $m-1$ remaining consecutive steps that we can take along row $1$. (note here that $a[2][j+1]$ is not yet visited, maintaining the invariant).\n\n  \u2022 switch to row $2$ : we go to $a[2][j]$, incurring a cost of $a[2][j]$, and then have only one choice from there - to go to $a[1][j+1]$. Because we have switched rows, we can now refresh our count and take $k$ consecutive steps along row $2$. (note again that we haven't visited $a[1][j+1]$ yet).\n\nNow if we calculate our subproblems starting from $j = n$ towards $j=1$ for every value of $m$, you shall have your answer in $C(1, \\ 1, \\ k)$.\n\nI shall leave the base cases and runtime analysis to you. Note that my solution calculates the cost of the path and not the path itself; can you extend my solution to calculate the path too?\n\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/254617/explicit-formula-of-base-change-for-gln\nText:\nLet $E/F$ be a quadratic extension of number fields and $v$ is a place of $F$.\n\nLet $\\chi_1,\\chi_2$ be the unramified characters of $F_v^{\\times}$.\n\nIf $B(\\chi_1,\\chi_2)$ is the unramified principal series representation of $GL_2(F_v)$, what is the $BC(\\pi)$, the base change of $\\pi$ to $GL_2(E_v)$?\n\nI suppose that $BC(\\pi)=B(\\chi_1 \\circ \\text{Norm}_{E_v/F_v},\\chi_2 \\circ \\text{Norm}_{E_v/F_v})$. Is this right?\n\n\nThe answer to your final question should be yes.\n\nLet me assume that $v$ is inert in $E$, so that $E_v / F_v$ is a honest quadratic extension. Assuming that $B(\\chi_1, \\chi_2)$ is irreducible, it corresponds via local Langlands (a theorem for $\\mathrm{GL}_2(K)$ and any $p$-adic field $K$) to the 2-dimensional representation of the Weil group of $F_v$ given by the sum of the characters $\\chi_1$ and $\\chi_2$.\n\nThe operation of base change on the $p$-adic side corresponds to restriction of Galois representations, thus the base change of $B(\\chi_1, \\chi_2)$ corresponds via local Langlands to the restriction of $\\chi_1 \\oplus \\chi_2$ to the Weil group of $E_v$.\n\nWhen we restrict $\\chi_1 \\oplus \\chi_2$ to the Weil group of $E_v$ and then make this homomorphism factor through the abelianization $E_v^*$, local class field theory tells us that this corresponds exactly to pre-composition of $\\chi_1$ and $\\chi_2$ with the Norm map. Now go back to the $p$-adic side and you have your statement.\n\n  \u2022 $\\begingroup$ Thanks for your comment. You said only the case where $v$ is inert in $E$. If $v$ splits in $E$, what is $BC(\\pi)$? In this case, since $GL_2(E_v)\\simeq GL_2(F_v)\\times GL_2(F_v)$, I suppose it should be $B(\\chi_1,\\chi_2) \\boxtimes B(\\chi_1,\\chi_2)$. Am I right? $\\endgroup$ \u2013\u00a0Monty Nov 14 '16 at 13:49\n  \u2022 1\n    $\\begingroup$ Yes, I think that is correct. $\\endgroup$ \u2013\u00a0user94041 Nov 14 '16 at 18:30\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/134451/deformation-of-curves-with-three-nodes\nText:\nLet $X$ be a stable curve consisting of two components meeting at three points. Let $M$ be its versal deformation space. The locus in $M$ parametrizing singular curves is a divisor with three components $D_1, D_2, D_3$, each corresponding to a node on $X$. The question is, which curve does a general point on $D_1\\cap D_2$ correspond to? More precisely, does it correspond to an irreducible nodal curve, or a curve with two components meeting at two points?\n\n\nA general point on $D_1 \\cap D_2$ is given by smoothing the third node, which produces an irreducible curve with two nodes.\n\n  \u2022 $\\begingroup$ Your other possibility would have the wrong arithmetic genus, unless two of the nodes collided, but I guess that's not in the versal deformation space at all. $\\endgroup$ \u2013\u00a0Allen Knutson Jun 22 '13 at 5:24\n  \u2022 $\\begingroup$ Thank you very much. May I ask for some more detail explanation of it? $\\endgroup$ \u2013\u00a0marker Jun 22 '13 at 15:10\n  \u2022 $\\begingroup$ Perhaps you just need to distinguish deformations from resolutions. I.e. a curve with two components meeting at two nodes is obtained by partially resolving the original curve by separating the branches at the third node, but this is a not a \"deformation\". Indeed the only way to deform a node non trivially is to smooth it. A deformation preserves the arithmetic genus, as Allen Knutson referred to, but a resolution reduces it. I always recall the maxim of Brieskorn, something like that analysis of singularities has three key aspects: resolution, deformation, and monodromy. $\\endgroup$ \u2013\u00a0roy smith Jun 23 '13 at 20:19\n\nYour Answer"}
{"text": "Retrieved from https://mechanics.stackexchange.com/questions/16383/clutchless-downshifts-using-throttle-blip-on-a-motorbike-sequential-gearbox/16385\nText:\nThis is with respect to non synchromesh, sequential transmission. Ducati along with several after market systems, implement clutchless downshifts by automatically applying a slight throttle to unload the gear.\n\nDucati Quick Shift up/down (DQS)\nFlatshifter Blip Clutchless Downshift Kit\n\nI understand how clutchless upshifts work.\nFor clutchless downshifts - while I understand the concept behind blipping the throttle while coasting, engine braking and hard braking helps unload the gear, I do not understand how how this could be achieved perfectly.\nI want to understand how this process is automated - timing, logical order of events etc. (Main question)\n\n  1. I believe a sensor on the gear shifter (strain guage) gives input to the controller of the riders intention to downshift.\n\n  2. The controller slighty blips the throttle to unload the gear and engage the lower gear. The blip also helps in revving the newly engaged gear and possibly helps reduce RPM mismatch resulting in smoother engine braking.\n    Am i correct in the above two statements? How is the amount of blip calculated (is it rev dependent or is it not so sensitive)? Is there any tendency to upset the bike (by working in opposition to braking)?\n\n  \u2022 What would be the process for clutchless downshifts when the throttle is being applied , ie no engine braking. E.g you're accelerating in a higher gear and want to shift down? \u2013\u00a0chilljeet Apr 22 '15 at 11:14\n\n\nThe Ducati transmission type is a constant mesh sequential.\n\nThere is a ride by wire system that controls the the throttle butterfly's.\n\nRide by wire is necessary in order for the ECU to regulate power based upon various maps the rider can select.\n\n\nThe clutchless downshift is similar to the clutchless upshift in that it is essentially doing the opposite of the latter.\n\n1. Foot depresses shift lever\n\n2. Grounding switch detects beginning of shift\n\n3. ECU sends signal to throttle body actuator\n\n4. Throttle body actuator momentarily opens butterfly in the throttle body\n\n  \u2022 Engine receives enough fuel to momentarily unload force on dog and slot gear relationship in transmission\n\n  \u2022 Dog and slot in the gear relationship has force being transmitted through them unloaded and are now able to be separated\n\n5. Riders continued depression of the shift lever forces the shift drum to begin to turn.\n\n6. Shift fork slides unloaded gear out of position/Other gear shift fork slides the next gear into position (these two events are occurring simultaneously).\n\n7. Butterfly closes in throttle body\n\n8. Force from rear wheel that's transferred through the chain and the secondary shaft loads gear with force.\n\n9. Deceleration continues with engine braking engaged and the transmission under load again.\n\n  \u2022 1\n    excellent. I'm interested in point no. 4 . How is the amount by which the throtlle has to be opened decided (what all other inputs are needed)? Can this technique be implemented manually by the rider as easily and safely as I believe clutchless upshifts are? \u2013\u00a0chilljeet Apr 15 '15 at 5:53\n  \u2022 1\n    I've come to the conclusion there isn't a need for perfect rev-matching as blipping the throttle reduces engine braking (apart from unloading the gear), significantly reducing shock load. \u2013\u00a0chilljeet Apr 22 '15 at 11:10\n\nYour Answer"}
{"text": "Retrieved from https://blog.flyingcoloursmaths.co.uk/digital-root-puzzle/\nText:\nEvery so often, a puzzle comes along and is just right for its time. Not so hard that you waste hours on it, but not so easy that it pops out straight away. I heard this from Simon at Big MathsJam last year and thought it\u2019d be a good one to share and analyse. I\u2019ve adopted (and slightly adapted) @colinthemathmo\u2019s wording of it:\n\nApart from exactly one exception, the digital root ((The digital root of a number is the result of summing its digits, and summing the digits of that sum, repeatedly, until you reach a single number. For example, the digital root of 981 is 9: 9+8+1 = 18 and 1+8=9.)) of the product of twin primes is always 8. Why?\n\nI\u2019d recommend convincing yourself that it\u2019s true, finding the exception, and having a go at a proof before reading on. Assuming you want to.\n\nMy proof is as follows: except for the pair 3 and 5, twin primes are always of the form $6n-1$ and $6n+1$, or else one of them would be divisible by 2, 3 or both.\n\nThe product $(6n-1)(6n+1) = 36n^2 - 1$ is one less than a multiple of 9. Taking the digital root of this gives the remainder modulo 9, which is 8.\n\nWith a tombstone.\n\nIn fact, it can be taken further: all of these twin prime products are congruent to 35 (modulo 36). It turns out that you can find a similar result in other bases than 10 - in fact, in any base that\u2019s one more than a factor of 36 (except for base 2).\n\nIn base 3, the iterated digit sum also turns out to be 1; this is the remainder modulo 2, which tells you the product of twin primes is odd. Again, not exactly impressive.\n\nBase 4 is where we start getting somewhere. The iterated digit sum here is two, meaning the product is one less than a multiple of 3.\n\nFor bases 3, 4, 5, 7, 10, 13, 19 and 37, the product of twin primes turns out to be two less than the base.\n\nIsn\u2019t that neat?\n\n* Edited 2017-13-03 to include a definition of digital root, at @colinthemathmo\u2019s suggestion. Thanks, Colin!"}
{"text": "Retrieved from https://www.physicsforums.com/threads/entropy-change-of-a-hot-falling-object.521552/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEntropy change of a hot, falling object\n\n  1. Aug 14, 2011 #1\n\n    A shipyard worker drops a hot steel rivet (mass 125g, temperature 350 degrees C)\n    into a river at temperature 5 degrees C, a distance 30m below. Stating any assumptions\n    you make, calculate the entropy change of the universe as a result of this event.\n    (specific heat capacity of steel ~0.4 J g-1 K-1).\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n\n\n\n\n    If anybody could tell me if I'm on the right lines at all or what the heck to do with the fact that the rivet's being dropped from 30m I'd greatly appreciate it. Thanks!\n    Last edited: Aug 14, 2011\n  2. jcsd\n  3. Aug 14, 2011 #2\n\n\n    User Avatar\n    Homework Helper\n\n    You have traced the change in entropy of the rivet, but I believe there are two more things you need to look at in the \"universe\" (essentially the rivet-Earth system). How much heat has been added to the river by the change in gravitational potential energy in the rivet-Earth system? Also, the river absorbs the heat of the rivet with virtually no temperature change (it's large enough to serve as a \"heat reservoir\"), so what is the change in the entropy of the river from that?\n\n    So there is the entropy change of the cooling rivet plus the entropy change from the change in mechanical energy plus the entropy change from the heat transfer from rivet to river.\n  4. Aug 14, 2011 #3\n    Thanks for the reply.\n\n    So, as I see it, so far I've worked out the decrease in the entropy of the rivet.\n\n    The heat flowing into the reservoir from the rivet cooling will be the same as the heat loss from the rivet:\n\n\n    That gives me 17250 J.\n\n    Then, if we assume the temperature of the reservoir doesn't change, then, using the temperature of the river in Kelvins for T:\n\n\n    That gives me an increase of entropy in the river as 62.1 JK-1\n\n    Finally, the change in gravitational potential energy is:\n\n\n    If we assume that this is all converted to heat in the river we can work out a second component for the increase in entropy. I get S = 0.13 JK-1.\n\n    Overall this gives me a net increase in the entropy of the universe as S = 21.93 JK-1.\n\n    Is this the right track or have I completely messed up?\n  5. Aug 14, 2011 #4\n\n\n    User Avatar\n    Homework Helper\n\n    I agree with those results to the first decimal place (since I rounded off only at the end), so we get a net increase in entropy for the \"universe\" of 21.9 J/K .\n\n    It is a reasonable safe assumption that just about all of the potential energy change is transferred into heating the river. The \"splash\" at impact displaces water and ejects some of it upward (briefly), as well as producing (a minute amount of) acoustical energy. But since practically all the water falls back into the river, that mechanical energy winds up heating the river after all. (We can extend \"the universe\" to include the air over the river, but the tiny amounts of water scattered as microdroplets and vapor and of sound energy probably contribute additions to entropy scarcely worth pursuing...)\n\nSimilar Discussions: Entropy change of a hot, falling object\n  1. Entropy change (Replies: 1)\n\n  2. Change of entropy (Replies: 0)\n\n  3. Change in entropy (Replies: 2)\n\n  4. Entropy changes (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-to-begin-oscillation-in-steady-state.42282/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHow to begin oscillation in steady state?\n\n  1. Sep 8, 2004 #1\n    I need to find the initial conditions such than an underdamped harmonic oscillator will immediately begin steady-state motion under the time dependent force F = m f cos\u03c9t.\n\n    For the underdamped case:\n    [tex]x(t) = ae^{-\\gamma t}cos(\\Omega t+\\alpha)+\\frac{f}{r}cos(\\omega t-\\theta)[/tex]\n\n    and if it matter, [tex]r^2 = (\\omega^2_0-\\omega^2)^2+4\\gamma^2\\omega^2[/tex]\n    and [tex]\\theta = Tan^{-1}\\frac{2\\gamma\\omega}{\\omega^2_0-\\omega^2}\n\n    I thought I would just have to find x0 and v0 such that the transient was 0, but that doesn't seem to be leading down the right track. What direction should my solution be heading?\n    Last edited: Sep 8, 2004\n  2. jcsd\n  3. Sep 8, 2004 #2\n    Why not just let x0=0 and v0=0? This should zero out the transient portion of the solution and leave the driving force intact.\n  4. Sep 8, 2004 #3\n    Makes sense to me, but the back of the book doesn't seem to agree. It has [tex]x_0=\\frac{f (\\omega^2_0-\\omega^2)}{r^2}[/tex] and [tex]v_0=\\frac{2\\gamma\\omega^2f}{r^2}[/tex].\n  5. Sep 8, 2004 #4\n    oh. take x(0) and x'(0) and let a = 0. If a = 0 then the transient solution is immediate null, but you'll see x0 and v0 are not. You'll have to subtitute for theta as well.\n  6. Sep 9, 2004 #5\n\n\n    User Avatar\n    Homework Helper\n\n    It was a good start. Let [tex]a=0[/tex]. Find x(0) and v(0). You have\n    [tex]x(0)=\\frac{f}{r}cos(\\theta ) \\mbox{ and }v(0)=\\frac{f\\omega}{r}\\sin(\\theta ) [/tex], use that\n    [tex] cos(\\theta ) = \\frac{1}{\\sqrt{1+tan^2(\\theta )}}\\mbox{, }sin(\\theta )=\\frac{tan(\\theta )}{\\sqrt{1+tan^2(\\theta )}} \\mbox{ and } tan(tan^{-1}(\\theta))=\\theta [/tex].\n\n\nSimilar Discussions: How to begin oscillation in steady state?\n  1. Steady-state current (Replies: 11)"}
{"text": "Retrieved from https://shitpost.plover.com/m/math.diophantine-equation.html\nText:\nContent-Type: text/shitpost\n\nSubject: A little algebraic thingy\nPath: you\u200b!your-host\u200b!wintermute\u200b!wikipedia\u200b!hardees\u200b!m5\u200b!plovergw\u200b!shitpost\u200b!mjd\nDate: 2018-01-23T19:53:46\nNewsgroup: rec.pets.math.diophantine-equation\nMessage-ID: <>\nContent-Type: text/shitpost\n\nA few days ago I was wondering if there are any (nontrivial) integer solutions of $$a^2 - ab + b^2 = 1\\tag{$\\spadesuit$}$$\n\nbut I couldn't do it in my head. I had the idea it would be pretty easy if I tried on paper, and yes, it was one of those ones where you don't even really have to think, you just push the symbols around.\n\nFrom !!(\\spadesuit)!!, adding or subtracting !!ab!!, we get both $$\\begin{align} a^2 + b^2 & = 1 + ab \\\\ (a-b)^2 & = 1 - ab \\end{align}$$\n\nand since in both cases the left sides are non-negative, we have both !!1+ab\\ge 0!! and !!1-ab \\ge 0!!, so !!-1\\le ab \\le 1!!, and we are done.\n\nI thought about it a little more and decided that perhaps a more elegant way to put it was: Multiplying !!(\\spadesuit)!! by 2, we get $$\\begin{align} 2a^2 - 2ab + 2b^2 &= 2 \\\\ a^2 + b^2 + (a-b)^2 &= 2 \\\\ \\end{align}$$\n\nand then since we have three squares that sum to 2, one must be zero and the rest must be 1.\n\nProbably there is a nice geometric proof also."}
{"text": "Retrieved from https://math.stackexchange.com/questions/812503/periodicity-of-a-triginometric-function\nText:\nI have a trigonometric function and I'm interested to know whether or not it has a period. At this stage I'm fairly certain that it is not periodic. However, I don't know how to prove it. Can anyone help?\n\nThis is the function:\n\n$$g(x) = \\sin(2 \\pi (x-a) \\times b \\times \\cos(2 \\pi (x - a) \\times c)) + d$$\n\n\n\nSubstitute $\\xi=2\\pi(x-a)$ and set $d=0$ w.l.o.g, then your period $T$ should satisfy\n\n$$\\sin[(\\xi+T)b\\cos((\\xi+t)c)]=\\sin[\\xi b \\cos(\\xi c)]$$ i.e. for $bc\\neq 0$ the arguments must differ by an integer multiple of $2\\pi$ for all $x$:\n\n$$(\\xi+T)b\\cos(\\xi x+Tc)=\\xi b \\cos(\\xi c) + 2\\pi k(x)$$\n\nwith some function $k(x)\\in\\mathbb{Z}$. As this function has to be smooth and is restricted to $\\mathbb{Z}$, it must be constant and you get\n\n$$\\xi \\cos(\\xi c + Tc)+T\\cos(\\xi c +Tc)=\\xi\\cos(\\xi c)+2\\pi k,\\qquad \\forall \\xi.$$\n\nThis is obviously not possible for $T\\neq 0$.\n\nEdit: Of course as mentioned, the specific case $bc=0$ has to be excluded.\n\n  \u2022 $\\begingroup$ :) ${}{}{}{}{}{}{}{}$ $\\endgroup$ \u2013\u00a0MPW May 28 '14 at 13:40\n  \u2022 $\\begingroup$ Thanks! My maths skills are questionable to say the least, but I have two questions: 1) is it not true that if the period is $T$, then $g(x) = g(x + T) \\forall x$? And, if so, I'm wondering if the substitution is correct? 2) should $\\forall \\xi$ be $\\forall k$? $\\endgroup$ \u2013\u00a0SnagaDuath May 28 '14 at 20:08\n  \u2022 $\\begingroup$ @SnagaDuath (improved comment) (1) This point I did a bit fast. If the function is invariant under replacing $x\\mapsto x+T_x$ with some period $T_x\\neq 0$ it is also invariant under replacing $\\xi\\mapsto \\xi+T_\\xi$ with some period $T_x\\neq 0$. You have $T_\\xi=2\\pi T_x$ In my answer i discussed $T_\\xi$. (2) No it is $\\forall \\xi$ meaning for all function arguments like the $\\forall x$ in your comment. $\\endgroup$ \u2013\u00a0flonk May 29 '14 at 18:02\n\nIn some cases the function is periodic. Specifically, if $c=0$ and $b\\neq 0$, the function has period $\\frac1b$.\n\n\nYour Answer"}
{"text": "Retrieved from https://mechanics.stackexchange.com/questions/22209/why-would-my-odometer-reset-to-the-same-mileage-whenever-i-turn-off-the-ignition\nText:\nI have a 2000 Nissan Altima and the odometer (not trip meter) reads 86186 miles when I first start the car. As it's driven, the odometer seems to work correctly, incrementing miles. But if I turn off the ignition the odometer resets to 86186 miles again.\n\nWhat could possibly cause this to occur?\n\nI searched the internet to see if there was possibly a computer bug - but so far have found nothing.\n\n  \u2022 Is the clock and trip meter also resetting too ? \u2013\u00a0Arka Patra Nov 1 '15 at 5:44\n  \u2022 1\n    Mileage is stored in several places within the vehicle computer system. The main one (whatever/where ever that may be) is telling the dash system the mileage is as described and resets it when power is turned off. I don't know which part actually stores the information, so leaving this as a comment. No clue how to get it right, either. This is a strange problem which I've not heard of before, but anything is possible! \u2013\u00a0P\u1d00\u1d1c\u029fs\u1d1b\u1d07\u02802 Nov 1 '15 at 10:58\n  \u2022 Is the 86186 the mileage you expect, or has a random number just appeared? \u2013\u00a0HandyHowie Nov 1 '15 at 16:48\n  \u2022 @Paulster2 The data is stored in the odometer unit itself. There is a c-mos battery it it , just like in a computer motherboard. It helps to keep the data saved. Probably that is causing the problem , given the car's age. How long the battery on the motherboard lasts ? \u2013\u00a0Arka Patra Nov 1 '15 at 18:13\n  \u2022 @ArkaPatra - Yes the mileage is stored in the odometer. In most vehicles its stored in several places in the computer system. Its designed that way to help alleviate tampering, but people have found ways around it. If someone resets it one place to indicate a lower mileage, the computer will take over at some point and reset it to the proper mileage. Car lots will reset the mileage and an undetermined amount of time later the dash display will reset it self to the proper mileage, which completely befuddles the unsuspecting vehicle buyer. \u2013\u00a0P\u1d00\u1d1c\u029fs\u1d1b\u1d07\u02802 Nov 1 '15 at 20:02\n\n\nYour car (like most cars) saves the milage in a small memory chip inside the instrument cluster. That chip is called an EEPROM. Like most memory units EEPROMs are subject to wear. If you rewrite the data often enough the chip will fail to save the new data or save corrupted data. This could be the case here.\n\nSo, why is the \"correct\" (i.e. new) value displayed? Because the value is saved somewhere else (in RAM) temporarily before it gets saved to the EEPROM for long-term storage. This temporary value does not survive your\n\nProcess of odometer display / save\n\n  \u2022 Start of car: Read last value from EEPROM\n\n  \u2022 Continuously: Calculate new value (by adding miles to last value). Show current value in display.\n\n  \u2022 Every x seconds or miles: Save new value to EEPROM\n\n\nYour can\n\n  \u2022 replace the EEPROM in your instrument cluster. This is a rather complicated procedure which requires some electronics and computer knowledge. You have to desolder the old chip, buy a new, copy data from old to new and solder the new chip in. If you haven't done this before chances are you are breaking your instrument cluster. Besides you probably have to the buy special tools to do it.\n\n  \u2022 replace your instrument cluster. This is a far more easy way of fixing the problem. Buy a used instrument cluster and swap it with your old. The new cluster's odometer will start from a wrong milage, but it will count correctly. If you plan to sell the car you should inform the buyer of the differing milage. In order to obtain the offset, maybe you can read the correct milage from the ECU using a OBD2 dongle or someone at a Nissan workshop can tell you using their diagnostic tool.\n\nBonus: EEPROM wear\n\nEEPROMs last many erase and write cycles. The number of life-time cycles are in the 100000s or millions. That sounds much but considering a 20 year usage of a car, it is not.\n\nIf you use your car for 250k km (~150k mi) and the car saves the new value every 0,25 km thats 100000 writes. If you drive with an average of 50 km/h (~30 mph), it takes you 5000 hours to drive 250k km. If your car is not updating the values by distance but by time and it does that once every 10 seconds, you have 1,8 million writes. I don't know which of the two intervals is used to update the storage, but I guess it's a combination of those two: Each x miles, but at least every y seconds.\n\nWhile most chips exceed their life expectancy, some don't. This can be a result of higher operating and storing temperatures or just a random fail.\n\n  \u2022 Thanks for a very informative and detailed answer. I still have the car but want to get rid of it now. But I'm in a bad situation as the DMV requires accurate reporting of the mileage. And I cannot in good conscience do what the last seller did to me. I posted on Craigs and disclosed the speedometer issue - now for two weeks. But looks like no one wants to touch it. Maybe time to consider donating it to Father Joe's. Thanks Nissan. \u2013\u00a0docscience Feb 11 '16 at 22:23\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1261179/number-of-solutions-of-equations-mod-pn\nText:\nUsing Hensel's lemma, it is easy to prove that if $p$ is a prime with $p\\equiv 1\\mod 3$ then the equation $x^2-x+1=0$ has at least two solutions $\\mod p^n$ for all $n\\geq 1$. Are there more than two solutions?. Of course, the anwer is not when $n=1$ but what happens if $n\\gt 1$?. I have many more equations to analyze so it would be interesting to find an answer for more general equations.\n\nThanks in advance.\n\n\nIt is convenient to note that $x$ is a solution of $x^2-x+1\\equiv 0\\pmod{p^n}$ if and only if $x\\equiv -t\\pmod{p^n}$, where $t$ is a solution of $t^2+t+1\\equiv 0\\pmod{p^n}$.\n\nSince $p$ is an odd prime, there is a primitive root $g$ modulo $p^n$. To show that there are exactly $2$ solutions of $t^2+t+1\\equiv 0\\pmod{p^n}$, it is enough to show that the congruence $t^3-1\\equiv 0\\pmod{p^n}$ has exactly $3$ solutions. We look for solutions of the shape $g^k$.\n\nWe have that $g^k$ is a solution of the congruence $t^3-1\\equiv 0\\pmod{p^n}$ if and only if $g^{3k}\\equiv 1\\pmod{p^n}$.\n\nNote that $\\varphi(p^n)=(p-1)p^{n-1}$. Let $p=1+3m$. If we put $k=mp^{n-1}$, then $g^{3k}\\equiv 1\\pmod{p^n}$. And in general, $g^{3k}\\equiv 1\\pmod{p^n}$ if and only if $\\varphi(p^n)$ divides $3k$. For $0\\le k\\lt \\varphi(p^n)$, this happens if and only if $k=0$, $m$, or $2m$.\n\n  \u2022 $\\begingroup$ @Diego: Thanks for the edit! $\\endgroup$ \u2013\u00a0Andr\u00e9 Nicolas May 1 '15 at 23:29\n  \u2022 $\\begingroup$ question: why did you prefer $t^3-1$ over $t^2+t+1=(t+\\frac{1}{2})^2+\\frac{3}{4}$ and the three solutions must be counted with multiplicity for $p=3$ the solution $t=1$ is a double root $\\endgroup$ \u2013\u00a0Elaqqad May 2 '15 at 1:19\n  \u2022 $\\begingroup$ The problem is about primes of the form $3k+1$. As to $t^3-1$, it looks nicer than $(t+1/2)^2+3/4$, and a basic chapter in elementary number theory has to do with order. Also, the same idea would work with longer sums. But it is true that $(2t+1)^2+3$ would work nicely, and then it comes down to $x^2\\equiv a\\pmod{p^n}$. $\\endgroup$ \u2013\u00a0Andr\u00e9 Nicolas May 2 '15 at 1:42\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/14107/theory-of-multi-label-classification\nText:\nMulti-label classification is a machine-learning problem where each sample can have zero or more labels from a closed set of possible labels. This task has applications in several fields. For example, in dialog systems, each sentence that the human says may have several intents, and the classifier should detect all of them. For example, the sentence \"I want a cake and a drink\" contains the two intents \"WANTCAKE\" and \"WANTDRINK\".\n\nTheoretically, I expect a classifier to classify multi-label samples, even if the training data contained only single-label samples. For example, consider the following training set (where each word is considered a feature):\n\n  \u2022 \"I want a cake\" -> WANTCAKE\n  \u2022 \"I want a drink\" -> WANTDRINK\n  \u2022 \"I want a solution\" -> WANTSOLUTION\n\nI would expect a classifier to realize, that the words \"I want a\" are not relevant for classification, and the words cake/drink/solution are indicative of the classes WANTCAKE/WANTDRINK/WANTSOLUTION respectively, and classify the sentence \"I want a cake and a drink\" correctly as {WANTCAKE,WANTDRINK}.\n\nThis seems trivial to humans. Therefore. I was very surprised to find out, that many state-of-the-art multi-label classifiers fail miserably on this simple task!\n\nFor example, consider a multi-label classifier in the \"Binary Relevance\" method. In this method, there is a single binary classifier for each label. For example, there is a binary classifier for the \"WANTCAKE\" label, trained with I want a cake\" as a positive sample, and the other two sentences as negative samples. When this classifier sees the sentence \"I want a cake and a drink and a solution\", it sees a single feature \"cake\" that is a positive signal of WANTCAKE, and two features, \"drink\" and \"solution\", that are negative signals of WANTCAKE, because they appeared in the training set with sentences that did not have the WANTCAKE label. Therefore, this classifier returns 'negative'. The same happens for the other two binary classifiers, and thus the multi-label classifier returns an empty set!\n\nI also tried other approaches to multi-label classification, such as RF-PCT (Random Forest Prediction Clustering Trees), with a slightly larger example (7 labels instead of 3) and got similar results.\n\nI sent this problem to machine learning experts, and they told me that I need more training data. They said that a classifier cannot tag multi-label instances, if the training data contains only single-label instances. In practice, they are right - adding more training data usually improves the accuracy of the classifier.\n\nBut I am still bothered with the theoretical issue - how can it be, that there is no state-of-the-art classifier that can solve this trivial, 3-instance problem?\n\nI am looking for a classifier that provably solves such problems. I.e., a classifier for which there is a proof, that if it is given correct single-label samples, it can correctly solve multi-label cases.\n\nIs there such a classifier?\n\n  \u2022 $\\begingroup$ The problem here is not one of machine learning alone, but of natural language processing and of semantics. There are plenty of machine-learning algorithms for multi-label learning. But the challenging part here is to deduce the semantics. When we say \"I want a cake and a drink\", we need to infer that the speaker meant \"I want a cake $\\land$ I want a drink\". If you say \"I want a cake but not a drink\", we need to infer that the speaker meant \"I want a cake $\\land$ $\\neg$(I want a drink)\". If the speaker says \"I could stand to bend my elbow, but nothing sweet, I'm on a diet\" -- good luck! $\\endgroup$ \u2013\u00a0D.W. Sep 4 '13 at 4:53\n  \u2022 $\\begingroup$ You are right that natural language understanding is more complicated than just multi-label classification. But here I am interested only in the multi-label-classification aspect of the problem (i.e. only in sentences whose semantics can be infered from their bag-of-words). This is only an example of a multi-label-classification problem. $\\endgroup$ \u2013\u00a0Erel Segal-Halevi Sep 7 '13 at 22:36\n\nYou subsequently clarified that you are looking for a way to do multi-label classification in general, and the example in the question about wanting a cake was just an example.\n\nOK, here is one standard way to do multi-label classification. For each candidate label, you build a boolean classifier that outputs true or false: true means that the label applies, false means it doesn't.\n\nIn your example, you'd have three classifiers: a \"cake classifier\" that outputs true if the sentence should be labelled \"wants-cake\" and false otherwise; a \"drink classifier\" that outputs true if the sentence should be labelled \"wants-drink\" and false otherwise; and a \"solution classifier\" that outputs true if the sentence should be labelled \"wants-drink\" and false otherwise. You now train each one separately. Given a sentence, you run all three classifiers on it and use that to select which labels should or should not be associated to the sentence. For instance, if the \"cake classifier\" outputs true, the \"drink classifier outputs false, and the \"solution classifier\" outputs true, then you label the sentence as \"wants-cake + wants-solution\".\n\nThis allows you to use any boolean classifier as your underlying building block. For instance, you can use SVMs, decision trees, random forests, and many other schemes.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1327543/does-the-euler-product-for-the-dirichlet-beta-function-converge-for-all-re?noredirect=1\nText:\nThe Dirichlet $\\beta$-function is defined for $\\Re(s)>0$ as:\n\n$$\\beta(s) = \\sum_{n=0}^\\infty\\frac{(-1)^n}{(2n+1)^s}$$\n\nIt has the following Euler product (I used that Dirichlet character $\\chi_{4}(p)=\\sin\\left(\\frac{p \\,\\pi}{2}\\right)$):\n\n$$\\prod_p \\bigg(\\frac {p^s}{p^s-\\sin\\left(\\frac{p \\,\\pi}{2}\\right)} \\bigg)$$\n\nNumerical evidence suggests that this Euler product also (slowly) converges for values $\\Re(s)>\\frac12$.\n\nDoes convergence in the domain $\\frac12 < \\Re(s) \\le 1$ indeed occur? If so, could this be proven (I guess a proof would also imply that all complex zeros of $\\beta(s)$ must reside on the critical line)?\n\n\nJust to share that by multiplying the Leibniz formula for $\\pi$ ($\\beta(1)=\\frac{\\pi}{4}$) and this formula (35), gives the very elegant relationship:\n\n$$\\prod_p \\bigg(\\frac{p-\\sin\\left(\\frac{p \\,\\pi}{2}\\right)}{{p+\\sin\\left(\\frac{p \\,\\pi}{2}\\right)}} \\bigg)=2$$\n\n  \u2022 $\\begingroup$ This is going to revolve around the convergence of the series $ \\sum_p \\chi_4(p) p^{-s} $ for $1/2<\\Re(s)\\leqslant 1$. I don't think we have enough information about the pattern of the primes modulo 4 to be able to say anything helpful. (Of course the nature of the beast is that such a relationship is equivalent to the function's Riemann hypothesis.) $\\endgroup$ \u2013\u00a0Chappers Jun 16 '15 at 15:36\n  \u2022 $\\begingroup$ Chappers, you are probably right, although this is one of the very few Euler products that I know of that converges for $s=1$ ($\\beta(1)$ is a well-known formula). Hence it could be an indication that further convergence exists. Numercal evidence does indeed suggest (very slow) convergence continues in the strip, however certainly not $\\le \\frac12$. $\\endgroup$ \u2013\u00a0Agno Jun 16 '15 at 20:37\n  \u2022 $\\begingroup$ $\\chi_4(2n+1) = (-1)^n$. Then $\\sum_p \\chi_4(p)p^{-s}$ and hence $\\prod_p \\frac{1}{1-\\chi_4(p)p^{-s}}$ converge for $\\Re(s) > \\sigma$ iff $L(s,\\chi_4)$ has no zeros for $\\Re(s) > \\sigma$ (the proof of $\\Longleftarrow$ is very similar to the prime number theorem) $\\endgroup$ \u2013\u00a0reuns Nov 29 '17 at 22:17\n  \u2022 $\\begingroup$ @reuns Thanks and clear. I have learned a lot since this question and wouldn't have asked it today. $\\endgroup$ \u2013\u00a0Agno Nov 30 '17 at 14:03\n  \u2022 $\\begingroup$ Sure. To me this equivalence between the zeros and the abscissa of convergence is really the fundamental theorem of the theory of $\\zeta(s), L(s,\\chi)$, more than the PNT. $\\endgroup$ \u2013\u00a0reuns Nov 30 '17 at 14:14\n\nSince the product (over primes) for Dirichlet L-series is valid only for $\\Re{(s)}>1$, as mentioned in all textbooks on this subject, the answer to Agno initial question is that not even the `easiest' case $s=1$ is proved for $\\prod_p \\bigg(\\frac {p^s}{p^s-\\sin\\left(\\frac{p \\,\\pi}{2}\\right)} \\bigg)$. I have investigated these products for $1/2 < \\Re{(s)} \\le 1$ for a while and also detected a slow numerical convergence, but this was just a conclusion on experimental computations, nothing such as a formal proof.\n\nP.S.: Could someone (maybe Agno, himself, or Reuns) provide a reference in literature (or internet) for the formal proof of \"the equivalence between the zeros and the abscissa of convergence\" mentioned by Reuns?\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1931497/copula-pde-hv-frac-partial-pu-v-partial-v-c-hu-frac-partial-pu\nText:\nI wish to solve the following PDE:\n\n\\begin{equation} H(v) \\frac{\\partial P(u,v)}{\\partial v} = c H(u) \\frac{\\partial P(u,v)}{\\partial u} \\end{equation}\n\nwhere $c$ is some constant in $(- \\infty, 0)$ and $P(u, v)$ is defined on $[0, 1]^2$, satisfying the boundary conditions:\n\n\\begin{align} P(0, v) &= 0 \\\\ P(u, 0) &= 0 \\\\ P(u, 1) &= u \\\\ P(1, v) &= v \\end{align}\n\nI have already ruled out the following solutions:\n\n  1. $P(u, v) = A(u) B(v)$. This admits a solution to the PDE but fails to satisfy the boundary constraints.\n\n  2. $P(u, v) = A(B(u, v))$ where $B$ is symmetric, i.e., $B(u, v) = B(v, u)$.\n\n\nIf $F$ is the cumulative distribution function of some random variable $X$ and $H$ is defined by\n\n\\begin{equation} H(x) = F^{-1}(x) f(F^{-1}(x)) \\end{equation}\n\nwhere $f$ is the density of $X$ (i.e. $\\frac{dF(x)}{dx}$ if it exists) and $F^{-1}$ is the inverse function of the cumulative distribution function $F$, then the provided PDE is satisfied by the copulas of bivariate random variables where both marginals are distributed according to $F$ and the correlation between the two is zero.\n\n  \u2022 $\\begingroup$ Use \\partial for the partial derivative notation $\\partial$. Also, is this not just a linear, first order PDE which can be solved using the method of characteristics? You may not be able to find the characteristics explicitly unless you know the form of $H$, but I think you can solve this. $\\endgroup$ \u2013\u00a0mattos Sep 18 '16 at 13:55\n  \u2022 $\\begingroup$ Thanks for the edit and pointing out characteristics. Can't believe I forgot about those; I'll give it a try and report back. $\\endgroup$ \u2013\u00a0R.G. Sep 18 '16 at 14:09\n  \u2022 $\\begingroup$ @Mattos It seems that for given functions $H$ characteristics seem to admit solutions (at least in very easy cases). Thanks again for the heads-up! $\\endgroup$ \u2013\u00a0R.G. Sep 19 '16 at 12:36\n  \u2022 $\\begingroup$ All good mate, hope it helps. $\\endgroup$ \u2013\u00a0mattos Sep 19 '16 at 14:04\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/11417/are-there-a-lambda-mu-expression-equivalent-to-the-yin-yang-puzzle/11421\nText:\nThe yin yang puzzle was written in Scheme. Since it uses call/cc, it is not possible to express it in a pure lambda expression, unless we do a CPS transform.\n\nHowever, given the fact that $\\lambda \\mu$-calculus have the power to model call/cc, is it possible to write an equivalent $\\lambda \\mu$-expression? I am still learning $\\lambda \\mu$-deductions, so this would be a good example to show how the deduction works.\n\nThere is no need to model the \"display\" command in a pure expression. Ideally only showing how the calculus keep looping and evaluates diffident terms again and again.\n\nUPDATE My translation in $\\lambda$-expression with CPS:\n\n(\u03bbcallcc.callcc (\u03bbyin.callcc (\u03bbyang.yin yang))(\u03bbcc.cc cc)\n\nIn CPS, (\u03bbcc.cc cc) is what \"call with current continuation\" means. So the expression takes it as a parameter. This will result in assign the sub-expression starts \u03bbyin assign its continuation into parameter yin. And then in the body, the second callcc assigns the yang of sub-expression starts \u03bbyang into itself. Finally, apply yin yang.\n\nNote the above translate is not full CPS, only the concept of call/cc has been translated. But it provides the same behavior and it is not hard to do a full CPS translate.\n\n\nYou can get an important hint to solution by thinking how to make the yin-yang puzzle work in a typed language, see this question. OCaml computes the type of yin and yang to be ('a -> 'a) as 'a, which is a recursive type equal to its own function space. Such a type is precisely what it takes to implement the untyped $\\lambda$-calculus in a typed language.\n\nWhat does this have to do with your question? In the untyped $\\lambda$-calculus (or typed calculus with general recursive types) we can define $\\mu$ and other fixed-point combinators. So, since yin and yang cannot be given types, we must use the untyped $\\lambda$-calculus, but then $\\mu$ is not needed as a primitive. In fact, the CPS transform of the puzzle will be just pure $\\lambda$-calculus.\n\nYou can compute the CPS transform in the privacy of your mind. Here is my version, written in Ocaml. To run it, you need to pass -rectypes to Ocaml:\n\nlet callcc f k = f k ;;\nlet yin c = callcc (fun x -> x x) (fun k -> print_char '@'; c k) ;;\nlet yang c = callcc (fun x -> x x) (fun k -> print_char '*'; c k) ;;\nlet _  = yin yang (fun x -> x) ;;\n\nClearly, the let statements are just a convenience. Without them, and with callcc expanded out, we get:\n\n(fun c -> (fun x -> x x) (fun k -> print_char '@'; c k))\n(fun x -> x)\n\nWe could remove the print_char statement and $\\eta$-reduce:\n\n  1. Start with:\n\n    (fun c -> (fun x -> x x) (fun k -> c k))\n    (fun x -> x)\n  2. Reduce fun k -> c k to c:\n\n    (fun c -> (fun x -> x x) c) (fun c -> (fun x -> x x) c) (fun x -> x)\n  3. Reduce fun c -> (fun x -> x x) c to fun x -> x x:\n\n    (fun x -> x x) (fun x -> x x) (fun x -> x)\n\nSo the essence of the yin-yang puzzle is just self-application of self-application. How appropriate! As a last step, we can put in the print_char statements again, to get a one-liner:\n\n(fun x -> x (fun k -> print_char '@'; x k)) (fun x -> x (fun k -> print_char '*'; x k)) (fun x -> x)\n  \u2022 1\n    $\\begingroup$ Is that you mean I don't need a \u03bb\u03bc-expression? Can you please explain how to define \u03bc since \u03bc is not a \"fixed-point combinator\", as what I know so far. $\\endgroup$ \u2013\u00a0Earth Engine Apr 20 '13 at 10:20\n  \u2022 1\n    $\\begingroup$ I may have answered the wrong question because I totally assumed $\\mu$ was a fixed point combinator. Are you referring to Parigot's $\\lambda\\mu$-calculus? In that case the answer ought to be similar, except we're not going to simulate continuations by explicit continuation passing, I suppose. The main point is that it's going to be untyped, no matter what you do. $\\endgroup$ \u2013\u00a0Andrej Bauer Apr 20 '13 at 18:01\n  \u2022 $\\begingroup$ I agreed that it is going to be untyped, and this is not what asking. But yes I am referring to Parigot's \u03bb\u03bc-calculus so \u03bc is not a fixed point combinator. I am learning it so I would like to see what the result looks like. $\\endgroup$ \u2013\u00a0Earth Engine Apr 21 '13 at 10:53\n  \u2022 $\\begingroup$ Well, you don't have to use $\\mu$ because you can do it just with $\\lambda$ (because we're untyped). Let me think what it would look like with $\\mu$. $\\endgroup$ \u2013\u00a0Andrej Bauer Apr 21 '13 at 21:31\n  \u2022 $\\begingroup$ I said I understand that we can do the same thind with \u03bb when using CPS. But CPS changes the semantic of the expression (your - an my - translated expression do not looks like or structured like the origin version any more), this is the reason why I am looking for a direct \u03bb\u03bc translation. $\\endgroup$ \u2013\u00a0Earth Engine Apr 22 '13 at 2:03\n\nYour Answer"}
{"text": "Retrieved from https://robotics.stackexchange.com/questions/19509/ik-3dof-iterative\nText:\nI want to solve for a 3dof planar arm using gradient descent to approximate end position. Now I am a little confused about the formula and was wondering if someone can help me out.\n\nThis is my thought process:\n\n  1. First start about using the forward kinematic solution mapping angles to euclidean space:\n\n    $x = l_1 * cos\\theta_1 + l_2 * \\cos(\\theta_1 + \\theta_2) + l_3 * \\cos(\\theta_1 + \\theta_2 + \\theta_3)$\n\n    $y = l_1 * sin\\theta_1 + l_2 * \\sin(\\theta_1 + \\theta_2) + l_3 * \\sin(\\theta_1 + \\theta_2 + \\theta_3)$\n\n    $\\phi = (\\theta_1 + \\theta_2 + \\theta_3)$\n\n  2. Now to I need to define a cost function ( that is where I get a little stuck), I know from a 2dof example, that I need to minimize the distance from the endpoint of my arm $x_{ep} $ to the target in euclidean space $x_{tg}$. defined as: $|| x_{ep} - x_{tg}||^2$ using gradient descent. Now, for a 3dof arm, obviously I would have an unlimited amount of solutions with this solution, so that I need to add one additional constraint, namely the angle $\\phi$ for my endeffector too. Here I am not quite sure on how to add the angle to the cost function as a parameter.\n\n  3. Then I would find the gradient function $\\nabla f_{cost} $ for each $\\theta$, in respect to my cost function, specified above using partial derivatives. $\\frac{\\partial f_{cost}}{\\partial \\theta_{1}}(|| \\begin{bmatrix} x_{ep} \\\\ y_{ep} \\\\ \\phi_{ep} \\end{bmatrix} - \\begin{bmatrix} x_{tg} \\\\ y_{tg} \\\\ \\phi_{tg} \\end{bmatrix}||^2)$, $\\frac{\\partial f_{cost}}{\\partial \\theta_{2}} ...$ , $\\frac{\\partial f_{cost}}{\\partial \\theta_{3}} ...$\n\nThen we simply try to iteratively minimize the cost function until we are below a tolerance $tol$.\n\nI know there is a missing piece, but I am not quite sure where, I believe it lies the cost function. Maybe I am wrong, thank you for your suggestions!\n\n\nIt can be demonstrated that the Gradient Descent (GD) policy corresponds to the use of the classical Jacobian transposed method for solving IK problems in robotics.\n\nThis strategy does not suffer from singularities but turns out to be slow and can get stuck in particular circumstances. More importantly, GD does not offer a principled way to deal with multiple prioritized objectives as you are looking for, instead.\n\nTo this end, you ought to make use of the Jacobian pseudoinverse $\\mathbf{J}^+$ that allows you to exploit kinematic redundancies to implement a hierarchy of tasks to be attained.\n\nIn particular, this policy can be represented by the following relation:\n\n$$ \\mathbf{\\dot{q}} = \\mathbf{J}^+ \\cdot \\left( \\mathbf{x}_\\text{tg} - \\mathbf{x}_\\text{ep} \\right) + \\left( \\mathbf{I} - \\mathbf{J}^+\\mathbf{J} \\right) \\cdot \\mathbf{\\dot{q}_0}, $$\n\n\n  \u2022 $\\mathbf{\\dot{q}}$ is the direction where to convergence iteratively (or, equivalently, the velocity that you would send to the joints).\n  \u2022 $\\left( \\mathbf{x}_{tg} - \\mathbf{x}_{ep} \\right)$ is the primary task that encodes the reaching in position.\n  \u2022 $\\mathbf{J}^+=\\mathbf{J}^T\\left(\\mathbf{J}\\mathbf{J}^T\\right)^{-1}$ is the pseudoinverse of the Jacobian of the primary task $\\mathbf{J}=\\frac{\\partial \\left( \\mathbf{x}_\\text{tg} - \\mathbf{x}_\\text{ep} \\right)}{\\partial \\mathbf{\\theta}}$ (as $\\mathbf{J}$ is not square).\n  \u2022 $\\mathbf{\\dot{q}_0}$ is the Jacobian of the secondary task \u2212 not yet specified \u2212 that encodes the reaching in orientation.\n  \u2022 $\\left( \\mathbf{I} - \\mathbf{J}^+\\mathbf{J} \\right)$ is the Null Space projection ensuring that the secondary task won't interfere with the primary task. In essence, the algorithm will provide directions that will drive the system toward both the objectives, if possible; otherwise, the primary task will take over the secondary task. Therefore, the primary task acts as a constraint in a typical optimization setting.\n\nIn our context, the simplest secondary objective $q_0$ could be:\n\n$$ q_0 = \\left( \\phi_\\text{tg} - \\phi \\right)^2. $$\n\nHence, it stems that:\n\n$$ \\mathbf{\\dot{q}_0} = \\frac{\\partial q_0}{\\partial \\mathbf{\\theta}}. $$\n\nRemarkably, $\\mathbf{J}^+$ is prone to singularities, thus it can be replaced by the Damped Least-Squares version $\\mathbf{J}_\\text{DLS}^+$ that makes the policy work very similarly to a Jacobian transposed in the neighborhood of singularities:\n\n$$ \\mathbf{J}_\\text{DLS}^+ = \\mathbf{J}^T\\left(\\mathbf{J}\\mathbf{J}^T + \\mu^2\\mathbf{I}\\right)^{-1}, $$\n\nwhere $\\mu$ is a damping factor that can be chosen as a function of the smallest singular value of $\\mathbf{J}$.\n\nInterestingly enough, we challenge students with the same exact problem during our school on robot programming \ud83d\ude09\n\n\n\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/308113/step-subcircuit-in-ltspice\nText:\nI try to simulate different MOSFET's for wich a spice model is provided by the manufacturer as a .lib file containing a subcircuit. In my schematic, the subcircuit is included with a .inc <fname> statement and used by changing the Prefix of a NMOS from M to X and setting to value to the name of the subcircuit.\n\nAll of this works, however, as I want to compare different MOSFETS, I want to step through a list of different models.\n\nI tried to use the same method as found here:\n\n  1. Define numerical models: .model 1 ako:<FET Type>\n  2. Step over the numerical models\n\nHowever, this does not work. A error \"Unknown subcircuit called\" is returned.\n\nIs there another way of stepping over different subcurcuits?\n\n\nIt's not officially supported, since LTspice flattens the schematics prior to simulation. That is, all subcircuits, hierarchies, are expanded and flattened to fit in the matrix solver, so if, for example, a second circuit that is stepped doesn't coincide element by element and node by node with the first one, then LTspice may have problems expanding the circuit \"mid-flight\".\n\nA minor proof is using any stepped subcircuit and looking at the extended netlist format, in the log, after the simulation. You'll see that the expanded subcircuit is the first one, repeated over all the steps.\n\nBut that doesn't mean it's not impossible, only that, if it fails, you shouldn't complain. First, ako only works with models, which are well-defined internally, while subcircuits can have any topology. For this, rename your subcircuits with numerals, 1, 2, 101, etc, so that they can be used with a .step variable. Then you're set, but, again, don't expect miracles. Here's a quick example:\n\n\nAlternatively, you can use switches and/or resistors that connect the subcircuits to the rest of the schematic, and step their values between 1m and 1g, for example, but that will make all the subcircuits count towards the matrix solver, even if they won't be used.\n\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/32785/finding-a-maximum-diameter-tree-in-an-undirected-unweighted-graph\nText:\nThe diameter of a graph is the largest of all shortest-path distances in it. How can we find a tree of maximum diameter within an undirected unweighted graph?\n\nNote that the tree does not have to be a spanning tree.\n\n  \u2022 $\\begingroup$ It makes no difference whether the tree is spanning or not. If there is a tree of diameter $d$, there is a spanning tree of diameter $d$ or greater so the question \"Is there a tree of diameter $d$?\" has the same complexity as \"Is there a spanning tree of diameter $d$?\" $\\endgroup$ \u2013\u00a0David Richerby Nov 6 '14 at 12:46\n\nThis (probably) can't be done efficiently since a maximum-diameter spanning tree could be a Hamiltonian path.\n\nMore specifically, an $n$-vertex graph has a tree of diameter $n-1$ as a subgraph if, and only if, it has a Hamiltonian path (the tree is the Hamiltonian path). Therefore, the problem of finding a maximum-diameter subtree is NP-hard, since you can reduce Hamiltonian path to it by finding the maximum-diameter subtree and checking whether or not it's a path of length $n-1$.\n\n  \u2022 $\\begingroup$ The problem includes the Hamiltonian path problem, and therefore is NP complete. $\\endgroup$ \u2013\u00a0Bangye Nov 6 '14 at 12:40\n  \u2022 2\n    $\\begingroup$ @Bangye Careful. $\\Sigma^*$ includes Hamiltonian path, too. $\\endgroup$ \u2013\u00a0Raphael Nov 6 '14 at 12:58\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/14239/functional-derivative-of-convolution\nText:\nTake the 2-minute tour \u00d7\n\nHow to carry out the following functional derivative?\n\n$$\\frac{\\delta F}{\\delta n(r)}$$ where $$F=\\int dr n(r) \\int C(|r-r'|) n(r') dr'$$\n\nis it simply: $$2 \\int dr' C(|r-r'|) n(r')$$?\n\nshare|improve this question\nThe answer to the question (v1) is Yes. \u2013\u00a0 Qmechanic Sep 1 '11 at 18:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nNotice that $F$ is essentially a quadratic form; i.e. if it were matrices then you would have (in summation notation): $$F = x_i C_{ij} x_j.$$ Then you would use the fact that $\\frac{\\partial x_i}{\\partial x_j} = \\delta_{ij}$ to get \\begin{align} \\frac{\\partial F}{\\partial x_k} &= \\delta_{ik} A_{ij} x_{j} + x_i A_{ij} \\delta_{jk} \\ &= 2 A_ik x_k \\end{align} if $A_{ij} = A_{ij}$ i.e. it is symmetric.\n\nHere, we use a similar fact: $$\\frac{\\delta n(x)}{\\delta n(y)} = \\delta(x-y)$$ where $\\delta$ this time is the Dirac distribution. Your \"matrix\" in the middle is obviously symmetric, so your proposed answer is correct.\n\nshare|improve this answer\nThanks, that makes sense. Cheers Biosftw \u2013\u00a0 Biosftw Sep 1 '11 at 18:37\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/171807/positive-primes-represented-by-indefinite-binary-quadratic-form?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nNeil Sloane asked me about commands in computer languages to find the (positive) primes represented by indefinite binary quadratic forms. So I wrote something in C++ that works. This is for the OEIS, these primes go into sequences... Note that, within a few hours, another guy had run the tables much higher with a one-line Maple command. Some days it does not pay to get up.\n\nI thought of one I really do not understand. Discriminant $205$ has four classes of forms, $$ \\langle 1, 13, -9 \\rangle, \\; \\langle -1, 13, 9 \\rangle, \\; \\langle 3, 13, -3 \\rangle, \\; \\langle -3, 13, 3 \\rangle. $$\n\nThe third and fourth are opposites so in the same genus, although distinct. The first two are in the principal genus, but they are not opposites, one is $-1$ times the other; in particular, they get diffeent positive primes, although both do residues $\\pmod 5$ and $\\pmod {41}.$ For $\\langle 1, 13, -9 \\rangle$ we get $$ 1,5,59,131,139,241,269,271,359,409, \\ldots, $$ while for $\\langle -1, 13, 9 \\rangle$ we get $$ 31,41,61,251,349,379,389,401,419,431, \\ldots. $$\n\nFor positive forms, low class number, there are polynomials, such as in Cox's book, such that primes represented by the principal form are those for which the polynomial factors a certain way. For a prime $p \\equiv 1 \\pmod 3,$ Gauss showed that $2$ is a cubic residue if an only if $p = u^2 + 27 v^2.$ Jacobi showed that $3$ is a cubic residue if an only if $p = u^2 + uv + 61 v^2.$ All I found in Henri Cohen's tables was the fact that $\\mathbb Q(\\sqrt {205})$ has class number $2$ and $L_K = \\mathbb Q(\\sqrt 5),$ appendix 12C on pages 533 and 534. See related information at IT'S A LINK.\n\nLet's see, $34$ is the smallest number where it is a surprise that there is no solution to $x^2 - 34 y^2 = -1.$ The smallest such odd number is $205,$ as there is no solution to $x^2 - 205 y^2 = -1.$ For prime $p \\equiv 1 \\pmod 4,$ there is always a solution to $x^2 - p y^2 = -1.$ Proof in Mordell's book. Anyway, this is why $\\langle 1, 13, -9 \\rangle, \\; \\langle -1, 13, 9 \\rangle$ are distinct classes.\n\nSo, that is the question, can I distinguish the represented (positive) primes by factoring some polynomial mod these primes?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 13 down vote accepted\n\nClass field theory promises such a polynomial (more properly, such a number field $H$, since a polynomial generating $H$ might have to err on the first few primes, though in our case it turns out there's a polynomial with no exceptional primes). The proof is effective, though the recipe is often hard to carry out. So I attempted an end run by asking this database for number fields of degree $8$ and discriminant $205^4$, and was rewarded with $$ x^8 + 15 x^6 + 48 x^4 + 15 x^2 + 1, $$ which generates an unramified normal extension $H \\, / \\, {\\bf Q}(\\sqrt{205})$ with the right Galois group. This polynomial matches your list exactly: the gp code\n\n   f = factormod(x^8+15*x^6+48*x^4+15*x^2+1, p)[,1];\n\nreturns your 5, 59, 131, 139, 241, 269, 271, 359, 409, and then continues 541, 569, 599, 661, 701, 761, 859, 881, 911, 941, still in exact agreement with the list of primes represented by $u^2 + 13uv - 9v^2$.\n\n[added later] That gp code checks whether all factors of $P_8(x) := x^8 + 15 x^6 + 48 x^4 + 15 x^2 + 1 \\bmod p$ have degree $1$. Since the polynomial is Galois, it would have been sufficient to check that one factor is linear:\n\n   if(poldegree(factormod(x^8+15*x^6+48*x^4+15*x^2+1, p)[1,1])==1, print(p))\n\n(I \"cheated\" a tad by excluding $p=2$, which is a factor of the discriminant of $P_8$ but not of the number field.) The Galois group of $P_8$ is dihedral, so one can find a quartic polynomial $P_4$ with the same Galois closure that factors completely mod $p$ iff $P_8$ does; such a polynomial was exhibited by NAME_IN_CAPS answering the follow-up Question 171846. Alternatively, we know already that $p$ is (either $5$ or) a quadratic residue of both $5$ and $41$, so by Quadratic Reciprocity $5$ and $41$ have square roots mod $p$, which means that $p$ factors completely in ${\\bf Q}(\\sqrt{5},\\sqrt{41})$. And indeed $x^2$ generates that field and equals (some conjugate of) $$ -\\frac14 (15 + 3 \\sqrt{5} + \\sqrt{41} + \\sqrt{205}); $$ so you can also test whether $p$ is represented by $u^2 + 13uv - 9v^2$ by computing $\\sqrt{5} \\bmod p$ and $\\sqrt{41} \\bmod p$ (if they don't exist then there's no representation), and then testing whether $-(15 + 3 \\sqrt{5} + \\sqrt{41} + \\sqrt{205})$ is a square mod $p$.\n\nshare|improve this answer\nFor the very similar discriminant 221 and $x^2 + 13 x y - 13 y^2, $ I was surprised to find that $$ f(x) = x^8 + x^6 - 4 x^5 - 38 x^4 - 2 x^3 + 123 x^2 -34 x + 17, $$ has a repeated root $\\pmod {101},$ although still linear factors, seven of them with one of them squared. Is that allowed? After that it is always 8 roots. This time the primes are $ 17,101,103,127,179,251,263,373,433,$ \u2013\u00a0 Will Jagy Jun 15 at 20:47\nFor 221, the quartic $$ x^4 + x^3 + x^2 + 2 x + 4 $$ behaves well \u2013\u00a0 Will Jagy Jun 15 at 20:57\nThe repeated root mod $101$ is an example of my warning that \"a polynomial generating [the Hilbert class field] $H$ might have to err on the first few primes\" if $H$ has no generator $x$ such that ${\\bf Z}[x]$ is the full ring of integers of $H$. A better choice for this purpose is $x^8 + 34 x^6 + 83 x^4 + 34 x^2 + 1$, which has spurious repeated roots only mod $2$ and $3$ (and as it happens no linear factors modulo either of these primes). Then $x+1/x$ generates a quartic isomorphic with the one you found with coefficients $1,1,1,2,4$. \u2013\u00a0 Noam D. Elkies Jun 15 at 22:14\nCool. Thanks, Noam. That does look much better. I found my degree eight on that website you mentioned, by putting in $221^4.$ Actually, the first time it thought i meant 2214 and complained. i decided it was better to multiply out the number. \u2013\u00a0 Will Jagy Jun 15 at 22:17\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/229201/the-quadratic-form-x2-ny2-via-prime-factors/229347\nText:\nTake the 2-minute tour \u00d7\n\nElementary algebra shows that the product of two numbers in the form $x^2 + ny^2$ again has the same form, since if $p = (a^2 + nb^2)$ and $q = (c^2 + nd^2)$, $$pq = (a^2 + nb^2)(c^2 + nd^2) = (ac \\pm nbd)^2 + n(ad \\mp bc)^2$$ My question is: Assuming that a number $z$ can be factored into primes of the form $x^2 + ny^2$, does every representation of $z$ in this form arise from repeated applications of this formula to the prime factors?\n\nshare|improve this question\ngive me a minute, Gerry pointed out that I had missed your actual intent. \u2013\u00a0 Will Jagy Nov 4 '12 at 22:47\nLet me know if my second answer is what you wanted, I've got a million of these. \u2013\u00a0 Will Jagy Nov 4 '12 at 23:18\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nAlright, the answer to the actual question asked is yes, as follows. I am taking a prime $p$ with $\\gcd(p,n) = 1.$ Then I am demanding $u^2 + n v^2 = p.$ Next, I am taking some number, composite or prime, call it $Q,$ and demand about $pQ$ rather than $Q$ itself, $$ pQ = r^2 + n s^2. $$ First, we get $$ \\left( \\frac{u}{v} \\right)^2 \\equiv \\left( \\frac{r}{s} \\right)^2 \\equiv -n \\pmod p. $$ Choose $\\pm s$ so that $$ \\left( \\frac{u}{v} \\right) \\equiv \\left( \\frac{r}{s} \\right) \\pmod p. $$ So we have $ u s \\equiv v r \\pmod p,$ or $$ -us + vr \\equiv 0 \\pmod p. $$ Next, $$ p^2 Q = (ur + n v s)^2 + n (-us + v r)^2, $$ and so $$ Q = \\left( \\frac{ur + n v s}{p} \\right)^2 + n \\left(\\frac{-us + v r}{p} \\right)^2 $$ in integers.\n\nCombine this once again with $p = u^2 + n v^2$ and you get back to $pQ = r^2 + n s^2$ as desired.\n\nshare|improve this answer\nadd comment\n\nWell, no. It is a fair question, though. Even with class number one, we can begin with $1 + 3 = 4,$ although $x^2 + 3 y^2$ does not represent $2.$ The way Dickson would have talked about this is the imprimitive form of the same discriminant, namely $2 x^2 + 2 x y + 2 y^2.$\n\nStaying with one class per genus, we have $1 + 5 = 6,$ although $x^2 + 5 y^2$ does not represent $2,3.$ This is a different phenomenon called Gauss composition. The trick for this one is that $2 x^2 + 3 y^2$ does represent $2,3,$ and there is a different identity that allows $(2 a^2 + 3 b^2)(2 c^2 + 3 d^2) = x^2 + 6 y^2. $ You should probably be able to find such an identity by hand.\n\nOne of the simplest ones where identifying the primes involved becomes a mess is $x^2 + 11 y^2.$ It is a bit of a problem (although solved) to say which primes can be expressed as $x^2 + 11 y^2$ and which by $3 x^2 + 2 x y + 4 y^2,$ among those primes $p$ for which the Jacobi symbol $(-11 | p) = 1.$ But, seeing as the latter form does represent $3,5$ integrally, we are not surprised to see $4 + 11 = 15.$ In this case, you ought to involve the \"opposite\" form in $(3 a^2 + 2 a b + 4 b^2)(3 c^2 - 2 c d + 4 d^2) = x^2 + 11 y^2.$ The presence of the opposite form is what makes the set (of three \"classes\") into a group.\n\nWell, that's a start.\n\nshare|improve this answer\nI'm not sure this speaks to the question which, as I understand it, goes: if $z=pq$, and $p=a^2+nb^2$, and $q=c^2+nd^2$, then must every representation $z=e^2+nf^2$ come from these representations of $p$ and $q$? E.g., $47=6^2+(11)1^2$, $103=2^2+(11)3^2$; if $(47)(103)=r^2+11s^2$, must $r,s$ come from the identity in the original post? \u2013\u00a0 Gerry Myerson Nov 4 '12 at 22:37\n@Gerry, I see what you mean. I believe the answer to that is yes, let me think about it. As long as $4n \\neq 0 \\pmod {pq}.$ \u2013\u00a0 Will Jagy Nov 4 '12 at 22:43\n@GerryMyerson, separate answer posted. There are always extra cases, I imagine $n=p$ works out as well but is not currently included. \u2013\u00a0 Will Jagy Nov 4 '12 at 23:22\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/20622/how-to-compute-drag-coefficient-given-initial-position-initial-velocity-and-fin\nText:\nTake the 2-minute tour \u00d7\n\nThe equations I'm using are:\n\nx = x + (DT * vx)\nvx = vx * C\n\nMy DT is always 0.01 and the coefficient C (related to a linear drag coefficient, as mentioned in the comments) is greater than 0 and less than 1. The above will keep happening until x naturally reaches its limit.\n\nWhat I want is an equation to find C given the other three inputs: initial x, initial velocity x and final resting x(this is where the object has come to a stop and vx = 0). Right now it's tedious because I have to plug in ix, ivx and C and run my simulation to see where the object stops. Then I have to do further tweaking to get exactly what I'm looking for.\n\nHere are some samples:\n\ninitial x = 3.5\nvelocity x = -12.0\nacceleration = 0.92\nfinal resting x = 2.0\n\ninitial x = 3.5\nvelocity x = -14.0\nacceleration = 0.92\nfinal resting x = 1.75\n\nFor example(from the first dataset), we start at 3.5 we want to end at 2.0 and our velocity is -12.0 .. what do we need to use for C?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nBasically what you're doing is calculating a discrete time series: you're finding an discrete series of positions $x_n$ (where $n\\in\\mathbb{Z}_+$) which are paired with times $t_n = t_0 + n\\Delta t$. But there are a couple of ways you could interpret this time series, and the formula you're looking for depends on which one you use.\n\nExact positions\n\nOne option is to say that $x_n$ represents the exact position of the particle at time $t_n$. In order to find the asymptotic position as $n\\to\\infty$ (that is, the position where the particle stops), you need to convert your iterative formulas,\n\n$$\\begin{align}x_n &= x_{n-1} + v_{n-1}\\Delta t \\\\ v_n &= Cv_{n-1}\\end{align}$$\n\ninto direct formulas. Hopefully you can see that, because the speed gets multiplied by $C$ at every step, the speed at the $n$'th step will be given by\n\n$$v_n = C^n v_0$$\n\nThen figuring out the formula for $x_n$ is probably most easily done by finding a pattern:\n\n$$\\begin{align}x_1 &= x_0 + v_0\\Delta t \\\\ x_2 &= x_1 + v_1\\Delta t \\\\ &= x_0 + v_0\\Delta t + Cv_0\\Delta t \\\\ x_3 &= x_2 + v_2\\Delta t \\\\ &= x_0 + v_0\\Delta t + Cv_0\\Delta t + C^2v_0\\Delta t\\end{align}$$\n\nYou wind up with\n\n$$x_n = x_0 + v_0\\Delta t \\sum_{k=0}^{n}C^k$$\n\nIn the limit as $n\\to\\infty$, this simplifies to\n\n$$x_\\infty = x_0 + \\frac{v_0\\Delta t}{1-C}$$\n\nwhich you can solve for $C$. This equation reproduces the sample results you listed.\n\nIt's important to note that the value of $C$ you get from this interpretation depends on your choice of $\\Delta t$. To simulate the same motion using a different time step, you'll need to change the value of $C$. Only the ratio $\\frac{\\Delta t}{1-C}$ is fixed.\n\nDiscrete approximation\n\nThe other way in which one could interpret your time series is as a discrete approximation to some continuous function $x(t)$ that describes the actual motion. If you find it strange that the result depends on the time step $\\Delta t$, this might be worth looking into.\n\nTo motivate this interpretation, you need to know something about finite difference approximations. In a nutshell, when you want to use a computer to numerically solve a differential equation, you can replace the derivative operator with a finite difference operator:\n\n$$\\frac{\\mathrm{d}f}{\\mathrm{d}t} \\to \\frac{f(t + \\Delta t) - f(t)}{\\Delta t}$$\n\nThe thing on the right here is merely the simplest example of a finite difference operator. (It also happens to be quite inaccurate.) This particular one looks a lot like the definition of the derivative, except that $\\Delta t$ is finite, not infinitesimal (hence the name).\n\nYour iteration equations can be written in the form\n\n$$\\begin{align}\\frac{x_n - x_{n-1}}{\\Delta t} &= v_{n-1} \\\\ \\frac{v_n - v_{n-1}}{\\Delta t} &= \\frac{C - 1}{\\Delta t}v_n\\end{align}$$\n\nYou can assume that this is the finite difference approximation to some exact differential equation, and work backwards to find the equation. For example, by replacing the finite difference operator in the position equation with a derivative, you get\n\n$$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = v(t)$$\n\nIf you try to do the same thing with the velocity, well, you can't, because the right side doesn't have a defined limit as $\\Delta t\\to 0$. But there are a couple of little hacks you can use, for example: choose some characteristic time scale $\\tau$ and set $\\Delta t = \\tau$ on the right, while still taking the limit on the left. You wind up with\n\n$$\\frac{\\mathrm{d}v}{\\mathrm{d}t} = \\frac{C - 1}{\\tau}v(t)$$\n\nSolving this differential equation gives you\n\n$$\\begin{align}v(t) &= v(0)e^{-t(1-C)/\\tau} \\\\ x(t) &= x(0) + \\frac{v(0)\\tau}{1-C} \\bigl(1 - e^{-t(1-C)/\\tau}\\bigr)\\end{align}$$\n\nand in the limit as $t\\to\\infty$,\n\n$$x(\\infty) = x(0) + \\frac{v(0)\\tau}{1-C}$$\n\nwhich, again, you can solve for $C$. It turns out to be the same thing as before, only with $\\tau$ instead of $\\Delta t$. This is only the case because this is an exceptionally simple equation, and because of the particular way in which I chose to define the time scale $\\tau$. In general, these two methods won't give identical results, in part because of the inaccuracies of the particular finite difference approximation I used.\n\nshare|improve this answer\nThank you. Is it possible to implement this type of motion without it being dependent on the DT? \u2013\u00a0 Ryan Feb 7 '12 at 6:49\nNo, there's no way to avoid introducing a time scale of some sort if the particle is going to come to rest. \u2013\u00a0 David Z Feb 7 '12 at 7:21\nadd comment\n\nIntegrate with respect to the time. One problem is that if you change DT, you will get a different result, since acceleration does not change with DT, although it should.\n\nYour formulas written as functions:\n\n$$ x(t) = x_0 + \\int_0^t v(t) \\cdot \\mathrm dt $$\n\n$$ v(t) = v_0 \\cdot a^t $$\n\nCombining those yields:\n\n$$ x(t) = x_0 + \\int_0^t v_0 \\cdot a^t \\cdot \\mathrm dt $$ $$ x(t) = x_0 + v_0 \\int_0^t e^{\\log(a)t} \\cdot \\mathrm dt $$ $$ x(t) = x_0 + v_0 \\left[ \\frac{1}{\\log(a)} e^{\\log(a)t} \\right]_0^t $$ $$ x(t) = x_0 + v_0 \\frac{1}{\\log(a)} (a^t - 1)$$\n\n$\\log(a)$ is negative, so for $t \\to \\infty$ you should get:\n\n$$ \\lim_{t \\to \\infty} x(t) = x_{\\mathrm{final}} = x_0 + v_0 \\frac{1}{\\log(a)} (0 - 1)$$ $$ x_{\\mathrm{final}} = x_0 - v_0 \\frac{1}{\\log(a)}$$\n\nThe greater your $a$ is, the less far the particle will have made it. Sounds reasonable.\n\nIf you have a $\\mathrm dt = 0.01$ seconds, you will have a factor of $a^{100}$ per second. So for your $a = 0.92$ I would instead use $a^{100} = 0.000239212$ as $a$.\n\nWhen I put this into my formula, I get:\n\n$$ x_{\\mathrm{final}} = 3.5 - (-12.0) \\frac{1}{\\log(0.000239212)} = 2.0608 $$\n\n$$ x_{\\mathrm{final}} = 3.5 - (-14.0) \\frac{1}{\\log(0.000239212)} = 1.82097 $$\n\nI am not sure whether the formula is wrong or whether your program just makes rounding errors (as usual with numeric calculations).\n\nshare|improve this answer\nThank you for the detailed derivation, but I realize I only need a coefficient of friction. See my comment to my original question up top. \u2013\u00a0 Ryan Feb 6 '12 at 23:54\nThere were some edits made to the question, in case you'd like to update your answer to reflect them. \u2013\u00a0 David Z Feb 7 '12 at 3:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214353/trouble-with-this-integral\nText:\nTake the 2-minute tour \u00d7\n\nCould anyone help me to do this integral ?\n\n$$\\int_{\\,0}^\\infty \\; \\frac{\\exp \\left( -\\frac{1}{x} -x\\right)}{\\sqrt{x}} \\, dx = \\sqrt{\\pi}e^{-2} $$\n\nI think you start with completing the square in the exponent, but what substitution do you make then ? $u=\\sqrt{x}$ didn't seem to get me far.\n\nshare|improve this question\nAre you familiar with Error Functions? \u2013\u00a0 Inquest Oct 15 '12 at 18:17\nDoes $\\displaystyle \\frac{1}{\\sqrt x}= \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{\\infty} e^{-xt^2} dt$ help? Anyway, (+1) for the question. \u2013\u00a0 Chris's sis Oct 15 '12 at 18:18\n@JoeKing: This is a special case of the integral dealt with here. This is the case $n = t = 1/\\sqrt{\\pi}$. \u2013\u00a0 user26872 Oct 15 '12 at 20:17\nadd comment\n\n1 Answer\n\nup vote 10 down vote accepted\n\nSubstitute first $x=u^2$ in order to have:\n\n$$ I = \\int_{0}^{+\\infty}\\frac{dx}{\\sqrt{x}\\exp\\left(x+\\frac{1}{x}\\right)}=2\\int_{0}^{+\\infty}e^{-\\left(x^2+\\frac{1}{x^2}\\right)}\\,dx$$\n\nUse now the substitution $x=\\frac{1}{y}$ to have:\n\n$$ I = 2\\int_{0}^{+\\infty}\\frac{1}{x^2}e^{-\\left(x^2+\\frac{1}{x^2}\\right)}\\,dx,$$\n\nfrom which follows:\n\n$$ I = \\int_{0}^{+\\infty}\\left(1+\\frac{1}{x^2}\\right)e^{-\\left(x^2+\\frac{1}{x^2}\\right)}\\,dx,$$\n\nand the key substitution is now $u = x-\\frac{1}{x}$, from which we have:\n\n$$ I = \\int_{-\\infty}^{+\\infty}e^{-u^2-2}\\,du = e^{-2}\\sqrt{\\pi}, $$\n\n\nshare|improve this answer\nNice and simple (+1). \u2013\u00a0 Chris's sis Oct 15 '12 at 18:30\nWow. I would never have worked that out. Was it obvious to you ? \u2013\u00a0 Joe King Oct 15 '12 at 18:45\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/1283/permutationsrange12-produces-an-error-instead-of-a-list/1362\nText:\nTake the 2-minute tour \u00d7\n\nThis input:\n\n\nResults in this (error) output:\n\n  The result of evaluating Permutations[{1,2,3,4,5,6,7,8,9,10,11,12}] \n  would be a packed array with 5748019200 elements, but the number of elements \n  in a packed array must be a machine integer. >>\n\nThat number (5748019200) is interesting, because it's exactly 12 times 12! (that's factorial, not exclamation point)\n\nPresumably, Mathematica is trying to store all 12! length 12 lists in a single monolithic array. I can imagine this failing.\n\nUsually, Mathematica shields me from these types of problems. For example, I had no trouble calculating 12*12!.\n\nMy intention is to Select some elements from this list, so I don't need to have every permutation in memory at once.\n\nQuestion: Is there a different way to generate the permutations that avoids this problem?\n\nshare|improve this question\nRun the same code on a 64-bit machine ;-) Seriously though, it is possible to iterate over permutations but I'm not sure if the algorithm is implemented directly in Mathematica. \u2013\u00a0 David Z Feb 4 '12 at 3:28\n@David It doesn't work on a 64-bit machine either. Harold: Apparently the maximum size of a packed array is 2^31-1. This is a huge array: a 2^31 - 1-element packed array of machine integers (i.e. assuming the most efficient storage possible) would take up 8 GB of contiguous memory. You need to have a lot of memory in your computer to be able to store such an array (definitely much more than 8 GB because of the contiguous memory block requirement) \u2013\u00a0 Szabolcs Feb 4 '12 at 20:13\nadd comment\n\n3 Answers\n\nup vote 7 down vote accepted\n\nCombinatorica` has the function NextPermutation which allows you to iterate over the permutations. There may be ways of generating a smaller subset if you have more information about what you are looking for.\n\nshare|improve this answer\nOn that note: the algorithms in Combinatorica are based on old FORTRAN routines discussed in this book; OP might want to take a look at the book and see what other strategies might be appropriate for his circumstances. \u2013\u00a0 \uff2a. \uff2d. Feb 4 '12 at 3:48\n@J.M., that book looks to be a tremendous resource. I'm glad I asked this question now. \u2013\u00a0 Harold Feb 4 '12 at 4:52\n@Harold note, the functionality in Combinatorica` is being slowly folded into the kernel functions. So, loading it will give a warning message to that effect, but NextPermutation doesn't (yet?) seem to have been moved over. \u2013\u00a0 rcollyer Feb 4 '12 at 4:55\n@J.M. Thanks a lot for the link to that book. Looks excellent \u2013\u00a0 TomD Feb 4 '12 at 9:34\nadd comment\n\nConsider than the permutations of {1, 2, 3, 4, 5} are each of the permutations of {1, 2, 3, 4} with 5 inserted at each possible place. One can therefore examine the permutations of {1, 2, 3, 4, 5} in blocks like this:\n\np4 = Permutations@Range@4;\n\n  ReplaceList[x, {h___, t___} :> {h, 5, t}],\n  {x, p4}\n\nFor example, making a certain selection:\n\n    # + #2 - #3*#4/#5 > 7 & @@ # &\n  {x, p4}\n\nThe same can be applied to the permutations of Range@12.\n\nshare|improve this answer\nadd comment\n\nWell from computational point of view, if you wanted the whole list or some part of it then the size of output would be the main problem.\n\nAssuming plaintext output is used ... by my rough estimation it would take over 225 GB (gigabytes) to store the whole list on a disk. Furthermore it would take about 4 days to compute them all on this laptop.\n\nYou need data like:\n\nfilename = \"f://out.txt\";\nseed = Range[12];\nsize = 10;\n\nRecursive method call like:\n\nseed = MPermutations[seed, size, filename]\n\nOther useful lines:\n\n\nThis is an example of what MPermutations could look like if flat file output is used. It computes next count number of permutations of list, prints them in filename and returns the last element.\n\nMPermutations[list_, count_Integer, filename_String] := Module[\n  {n = 1, current = list},\n   n < count, current = NextPermutation[current];\n   Write[filename, current]];\n\nReturn result is needed to make recursive method call possible. Recomputing that line will add next size amount of results to file (assuming that data is in a different cell).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/157251/can-we-decompose-a-polynomial-into-difference-of-convex-polynomials\nText:\nTake the 2-minute tour \u00d7\n\nGiven a multivariate polynomial $p(x_1, ..., x_n)$ on $\\mathbb{R}^n$, can we always decompose it into the difference of two convex polynomials? i.e., is there a pair of convex polynomials $f$ and $g$, such that: $\\forall (x_1, ..., x_n) \\in \\mathbb{R}^n$, $p(x_1, ..., x_n) = f(x_1, ..., x_n) - g(x_1, ..., x_n)$?\n\nIf given a bounded region $\\mathbb{N}$ which is a convex subset of $\\mathbb{R}^n$, can we then decompose polynomial $p(x_1, ..., x_n)$ such that in $\\forall (x_1, ..., x_n) \\in \\mathbb{N}$ , $p(x_1, ..., x_n) = f(x_1, ..., x_n) - g(x_1, ..., x_n)$ where $f$ and $g$ are convex polynomials.\n\nIf we can (no matter under the unbounded or bounded case), is there any constructive method to find such a pair of $f$ and $g$ for a given $p$?\n\nshare|improve this question\nThis sounds very familiar; I think my previous advisor B. Shapiro described this to me, or something very similar. In any case, in more than one variable, it feels like a strong condition to be representable in such a way; so my guess is this is either false, or unsolved. \u2013\u00a0 Per Alexandersson Feb 10 at 21:37\nadd comment\n\n2 Answers\n\nPolynomials of degree $n$ which are convex in the given domain form a cone (subset which is closed under \"+\" and multiplication on nonnegative numbers) in the finite-dimensional space of polynomials of degree $n$.\n\nLemma For a given cone $C$ in a vector space $V$ the following statements are equivalent\n\n(a) $C$ contains an inner point\n\n(b) $\\forall v \\in V \\exists s, t \\in C$ such that $s-t=v$\n\n(c) linear span of $C$ is $V$\n\n\n(b)<=>(c) obvious\n\n(a)=>(c) obvious\n\n(c)=>(a) pick a basis $(e_1, ..., e_n)$ in $C$ and take $e_1 + ... + e_n$, its inner\n\nFor the bounded region, theorem follows obviously, because slight deformation of strictly convex polynomial is convex in the bounded domain.\n\nFor the unbounded region it can be done as follows: solve it for the homogeneous polynomials (where you can restrict to the unit sphere and use that it is compact) and then take the homogeneous convex polynomial which is inner and add the standard quadratic form.\n\nshare|improve this answer\nThanks. Could you please specify how to construct the difference of two convex, given an arbitrary polynomial? \u2013\u00a0 slwang Feb 11 at 18:07\nOk. Let $Q$ be $(\\Sigma x_i^2)$, $S = Q^n + Q$, where $2n > deg$ of your polynomial. $Hess(S) > 0$ and $1/|1/Hess(S)|$ tends to infinity as $C * r^(4n-4)$. For any polynomial $Z$ of degree $\\leq 2n$ its true that $|Hess(Z)|$ tends to infinity not faster than $C' * r^(4n-4)$ there exist such $N > 0$ that $|Hess(Z)| < N 1/|1/Hess(S)|$, and, hence, $NS + Z$ is convex. So, for $P = NS + Z$, $Q = NS$ everything holds. \u2013\u00a0 Lev Soukhanov Feb 13 at 16:20\nWow. Great construction. Thanks very much. \u2013\u00a0 slwang Feb 14 at 7:37\nHi Lev. Could you please also simply explain why a=>c is obvious, or give me some references? Moreover, in your construction what is the definition of $|1/Hess(S)|$, the determinant of inverse Hessian? \u2013\u00a0 slwang Feb 18 at 21:27\n(a) => (c): Let us take a little ball around an inner point. It linearly spans the vector space. Also |1/Hess(S)| is a norm of the inverse matrix, sum of the squares of matrix elements. \u2013\u00a0 Lev Soukhanov Feb 19 at 21:15\nadd comment\n\nFor a bounded convex region as the domain, the answer is yes.\n\nLet $ Hess(p) $ be the hessian matrix of p (the matrix of the second derivatives by each pair of variables). This is an $ n\\times n $ symmetric matrix each of whose elements is a real polynomial. The elements of this matrix are bounded functions on N, say the absolute value of each element is at most m everywhere in N. Define\n\n$$ f(x_1, \\dots, x_n) := nm(x_1^2 + \\dots + x_n^2) $$\n\nThen f is convex, and $ Hess(f) = 2nmE $ where E is the identity matrix of size n. Now $ g := f - p $ is a polynomial, and $ Hess(g) = Hess(f) - Hess(p) $ at any point in N is a symmetric real matrix whose diagonal elements are at least $ 2nm - m $ but other elements have absolute value at most m so it is postive definite. This implies that g is convex in N.\n\nI don't know if a similar argument could work in the unbounded case.\n\nEdit: mentioned the matrix being symmetric, which I used implicitly.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/74212/is-it-decidable-whether-or-not-a-collection-of-integer-matrices-generates-a-free/74231\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have integer matrices $A_1,\\ldots,A_n\\in\\operatorname{GL}(n,\\mathbb Z)$. Define $\\varphi:F_n\\to\\operatorname{GL}(n,\\mathbb Z)$ by $x_i\\mapsto A_i$. Is there an algorithm to decide whether or not $\\varphi$ is injective?\n\nshare|improve this question\nThe corresponding problem for semigroups is undecidable for $n\\geq 3$. I don't know what is known for groups. It is probably open and undecidable. \u2013\u00a0 Benjamin Steinberg Sep 1 '11 at 0:50\nBenjamin - I'd be interested in a reference for the semi-group case, if you have one. \u2013\u00a0 HJRW Sep 1 '11 at 6:01\nThis was proved by Klarner, Birget and Satterfield in IJAC in 1991 for something like n=5 and improved to 3 and upper triangular in iml.univ-mrs.fr/~cassaign/publis/freeness.ps.gz \u2013\u00a0 Benjamin Steinberg Sep 1 '11 at 13:52\nThanks, Benjamin! \u2013\u00a0 HJRW Sep 1 '11 at 16:26\nadd comment\n\n2 Answers\n\nup vote 24 down vote accepted\n\nFor $n=1, 2$ the answer is \"yes\" since the group is virtually free, for $n\\ge 3$ the answer is not known (an open problem).\n\nEdit. In fact even for two $n\\times n$-matrices the problem is open. Moreover the solution of the following ``easier\" problem is not known: for which algebraic integers $\\lambda$ the matrices $\\left(\\begin{array}{ll} 1 & 2\\\\\\ 0 & 1 \\end{array}\\right)$ and $\\left(\\begin{array}{ll} 1 & 0\\\\\\ \\lambda & 1 \\end{array}\\right)$ generate a free group (see this paper, for example). The fact that this problem is easier follows from the trivial observation that the group generated by these two matrices is isomorphic to some effectively computable group of $n\\times n$-integer matrices for some $n\\ge 2$ (depending on the degree of the algebraic number $\\lambda$).\n\nshare|improve this answer\nIt's not clear for me that's it's easier. It might happen that for each n there's an algorithm in GL(n,Z) to detect free groups (as in the initial question) but that this algorithm does not depend recursively on n. \u2013\u00a0 Yves Cornulier Sep 3 '11 at 21:43\n@Yves: The size of the matrices is the degree of the $\\lambda$. There is currently no hope to resolve the problem even if the degree is 3. \u2013\u00a0 Mark Sapir Sep 4 '11 at 4:48\nadd comment\n\nHere are some general facts that may be relevant.\n\nGiven a finitely presented group $G$ and a representation $\\rho:G\\to GL_n(\\mathbb{Z})$, there is no algorithm which is uniform in $n$ that decides whether or not $\\rho$ is injective.\n\nHowever, this leaves open the possibility that there is such an algorithm for particular $n$. (It's easy for $n=2$, when the group is virtually free. I believe nothing is known for $n>2$.) Also, the examples we construct are not free groups, so it may be possible to say something in that case.\n\nIn another direction, given a finite presentation for a group $G$ and a solution to the word problem in $G$, one can algorithmically determine whether or not $G$ is a free group.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/248966/2-connected-planar-graph-and-vertex-degree\nText:\nTake the 2-minute tour \u00d7\n\nIf $G$ is a 2-connected loopless planar graph, and for each vertex $v$ we define: $f(v) = (1/2) - (1/deg(v))$, where $deg(v)$ is the degree of vertex $v$,\n\nShow that for some region $R: \\sum f(v) < 1 $, where the sum is over all vertices $v$ incident with $R$.\n\nI'm confused about how to go about this. Some properties that could be relevant are:\n\n  \u2022 for 2-connected planar graphs, every region is bounded by a cycle\n  \u2022 $12 \\leq \\sum [6 - deg(v)]$ so $\\sum deg(v) \\leq 6|V(G)| - 12$\n  \u2022 $\\sum deg(v) = 2 |E(G)| $\n  \u2022 every region is clearly bounded by at least 3 edges and thus has at least 3 vertices incident to it\n  \u2022 for 2-connected graphs, every vertex has $deg(v) \\geq 2$\n\n    Anyone have ideas?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nLet us denote the sum for a region as $$F(R) = \\sum_{v\\in R}f(v)$$ Consider the sum of $F$ over all regions of the graph. There are $\\deg v$ faces incident with each vertex so each $f(v)$ is counted precisely $\\deg v$ times. $$\\sum_{R\\in G}F(R) = \\sum_{v\\in G} f(v)\\deg v=\\sum_{v\\in G}\\left(\\frac{\\deg v}{2}-1\\right)$$ From the handshaking lemma, this is equal to $$\\sum_{R\\in G}F(R)=|E| - |V|$$ From Euler's formula $$|E|-|V| = |R|-2$$ where $|R|$ is the number of regions. Therefore the average of $F$ over the regions $$\\overline{F(R)} = \\frac{|R|-2}{|R|}<1$$ is less than $1$. Therefore there must exist at least one region for which $F(R)$ itself is less than $1$.\n\nshare|improve this answer\nthank you! the trick here was to see that there are deg(v) faces incident with each vertex. I'm assuming thats because the graph is 2-connected? \u2013\u00a0 DustinH Dec 2 '12 at 15:53\nYes, it's necessary for the graph to be 2-connected. You may want to prove that fact just to be complete. \u2013\u00a0 EuYu Dec 2 '12 at 18:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/4800/choosing-solutions-for-the-intersections-of-n-number-of-circles\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I have an number of distances from an unknown location to a known location. I can use these distances and the known locations to draw a number of circles. The point where all the circles intersect is my unknown location. This is easy to solve. However, if my distance measurements have some error, I will get a cluster of points around my unknown location. The question is, for each pair of intersection points, how can I tell which solution is closer to my unknown point?\n\nEvery solution I have come up with involves many special cases, such as when all the known locations are inside one circle, or all the known locations are co-linear, and so on, buy I am hoping to come up with a more elegant solution.\n\n\nLets make this more simple. I have 2 circles that have at most 2 intersection points. If they don't intersect, I can easily choose the point between them. If they do intersect at 2 points, how can I use a third circle to choose which one of these 2 intersections is the correct one?\n\nMy current plan is to do a comparison between the distance between the radius of the third circle and the intersection points and choose the smaller one. The problem with this is that I don't know how much error this approach can tolerate before you choose the wrong side. If I knew that, I could put a goal on my measurement method to try to reduce the error by X%\n\nshare|improve this question\nThe Wikipedia page for GPS suggests that such a system can be solved using a generalization of Newton's method. \u2013\u00a0 Isaac Sep 16 '10 at 18:27\nadd comment\n\n1 Answer\n\nOne handles error with a probability model. In this case, the typical error in a distance measurement is likely proportional to the distance itself. The errors themselves are often thought of as accumulated small nearly independent errors, allowing one to invoke the Central Limit Theorem and suppose, at least as a reasonable hypothesis, that the errors are normally distributed. We usually assume there's no systematic bias in the errors: they should average out to zero in principle. A simple model is obtained by supposing the errors are independent. (Other suppositions can be treated, depending on how the measurements were made, but it quickly gets complicated.)\n\nThis leaves us with just three unknowns to estimate: the true coordinates $(x,y)$ of your location and the precision of the relative errors, usually expressed as their (common) standard deviation $\\sigma$. Your data consist of $n$ measured distances to the known locations $(x_i, y_i)$, say $d_i, i = 1 \\ldots n$. Mathematically, these assumptions translate to the following. The probability of observing $d_i$ equals\n\n$$\\frac{1}{\\sqrt{2 \\pi} \\sigma \\delta_i} \\exp \\left( -\\frac{(d_i - \\delta_i)^2}{2 \\sigma^2 \\delta_i^2)} \\right)$$\n\nwhere $\\delta_i = \\delta_i(x,y) = \\sqrt{(x - x_i)^2 + (y - y_i)^2}$.\n\nThe probability of your data $(d_1, d_2, \\ldots, d_n)$ is the product of these probabilities. This is the likelihood.\n\nOne reasonably tractable estimator maximizes the likelihood (as a function of the unknown parameters $x$, $y$, and $\\sigma$). This is usually done by maximizing the negative logarithm of the likelihood, which will be a sum of terms, one for each data value. It's nonlinear and a little nasty, but we know geometrically that there will be at least one global optimum and, quite likely, exactly one. Many methods exist to solve this, available in statistical packages, numerical optimization routines, and general-purpose math software like Mathematica.\n\nOf course the optimal arguments $(x,y)$ tell you where your location likely is. The optimal value of $\\sigma$ estimates the typical relative error in the distance measurement: you can check that it's a reasonable value. There are ways to extract confidence intervals for all three parameters (from the Hessian of the log likelihood). A joint confidence interval for $(x,y)$ gives you an ellipse in which the true point is likely to be. Statistical packages will give you this information. If you are doing this by hand, you can analyze any other candidate solution $(x',y')$, such as the intersection of a few circles, by evaluating the likelihood there and comparing it to the optimum likelihood. If the logarithms differ by less than $2$, the candidate solution is consistent with the data.\n\nBTW, as you've seen, you're practically forced to take a statistical approach. With real data you find that some circles don't even intersect and that overall the set of data has little or no internal consistency. You have to model the error somehow.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/97965/solve-drag-equation-for-previous-timestep?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am working on a series of equations to calculate the trajectory of a projectile in reverse. For example, given the ground impact angle and velocity, calculate the flight of the projectile. Here is the equation to calculate the drag on a projectile in normal flight (not reversed yet):\n\n$$ x_2=x(1-k\\sqrt{x^2+y^2}) $$ $$ y_2=y(1-k\\sqrt{x^2+y^2}) $$\n\n$x$ and $y$ are the before-drag velocities, and $k$ is a constant that includes the fluid density, reference area, drag coefficient, and timestep. The result, $x_2$ and $y_2$, are the after-drag velocities. On my graphing calculator, including these functions in a program creates a nice-looking trajectory. However, to reverse the formula, I need to solve the above equations for $x$ and $y$. Given the resulting velocity, find the velocity at the previous timestep. I am at a loss on how to do this.\n\nPut simply, solve the above 2 equations for $x$ and $y$.\n\nAny help will be appreciated.\n\nshare|improve this question\nCould you please explain exactly what you're trying to do? Are the $x,y$'s infinitesmal quantities that are evaluated at each time step and then summed up (integrated) to calculate the trajectory? If so, what integration scheme are you using? \u2013\u00a0 yohBS Jan 10 '12 at 20:47\n@yohBS I don't understand exactly what you are saying (I'm in 10th grade). Every timestep, $x_2$ times the timestep is added to the x position of the projectile, and $y_2$ times the timestep is added to the y position. Then, $x$ and $y$ are set equal to $x_2$ and $y_2$ for the next timestep. Hope this helps. \u2013\u00a0 Joel Jan 10 '12 at 21:11\nYou just do what you would do as if time was running forwards, but change the sign of the drag $k$ (is the opposite of drag shove?) and the two \"after-drag velocities\", so the projectile goes up and backwards with extra shove. \u2013\u00a0 Henry Jan 10 '12 at 22:50\n@Henry Changing the sign of $k$ doesn't work. That is applying negative drag to $x_2$ and $y_2$. For the equations to work, the drag must be applied to $x$ and $y$. \u2013\u00a0 Joel Jan 11 '12 at 16:11\nadd comment\n\n1 Answer\n\nIt helps to write down the equation in vector form: $$\\mathbf v_2=(1-k|\\mathbf v|)\\mathbf v\\tag1$$ This shows that $\\mathbf v_2$ is a scalar multiple of $\\mathbf v$ (no surprise there). Take the magnitude on both sides of(1): $$|\\mathbf v_2|=(1-k|\\mathbf v|)|\\mathbf v|\\tag2$$ Here I assume that $1-k|\\mathbf v|\\ge 0$, that is the velocity does not change direction due to drag. This is physically reasonable. Equation (2) is quadratic for $|\\mathbf v|$, with the solution $$|\\mathbf v|=\\frac{1-\\sqrt{1-4k|\\mathbf v_2|}}{2k} \\tag3$$ Thus, to obtain $\\mathbf v$ from $\\mathbf v_2$, we should divide $\\mathbf v_2$ by its magnitude, and the multiply the result by the right side of (3): $$ \\mathbf v =\\frac{1-\\sqrt{1-4k|\\mathbf v_2|}}{2k |\\mathbf v_2|}\\mathbf v_2 $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/120848/differential-equation-with-absolute-value\nText:\nTake the 2-minute tour \u00d7\n\nAfter some algebraic simplification, I got the ODE: $$\\ddot x(t)+\\sqrt {(\\dot x(t)+x(t))^2}+k x(t)=0$$ I interpreted this equation as: $$\\ddot x(t)+|{(\\dot x(t)+x(t))}|+k x(t)=0$$ I have some problem to solve it. Could you give me some hint please? Thanks.\n\nshare|improve this question\nNormally when I have absolute values I split the problem into two cases. \u2013\u00a0 Godisemo Mar 16 '12 at 8:40\nYou may use Godisemo's hint and then it becomes a 2nd ordered linear ODE with constant coefficients. \u2013\u00a0 Tapu Mar 16 '12 at 9:01\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYour equation is equivalent to\n\n$$\\ddot x(t)\\pm\\dot x(t)\\pm x(t)+kx(t)=0$$\n\nso you have to solve the equations\n\n$$\\ddot x(t)+\\dot x(t)+(1+k)x(t)=0 \\qquad \\ddot x(t)-\\dot x(t)-(1-k)x(t)=0.$$\n\nThe solutions of these equations can be obtained by solving the characteristics equations\n\n$$\\lambda^2\\pm\\lambda+(\\pm 1+k)=0$$\n\n\n$$\\lambda_{1,2}=\\frac{\\mp 1\\pm\\sqrt{1-4(\\pm 1+k))}}{2}$$\n\nand depending on the value of $k$ you will get different sets of solutions.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166294/condition-to-have-unique-solution\nText:\nTake the 2-minute tour \u00d7\n\nConsider $\\Delta u =f(x) , x \\in \\Omega $ and $\\nabla u\\cdot n +\\alpha u = g(x) , x\\in \\partial\\Omega $, where $n$ is outward normal. Can anyone give me a hind how to find sufficient condition on $\\alpha$ so that the solution is unique. Thanks\n\nshare|improve this question\nwhat do you mean by $\\nabla\\cdot n$? Do you mean $\\nabla u\\cdot n$ instead? \u2013\u00a0 Paul Jul 3 '12 at 21:22\n@Paul : thanks for pointing out. \u2013\u00a0 Theorem Jul 3 '12 at 21:24\nFor future reference, you should write the operators as \\Delta and \\nabla instead of \\triangle and \\triangledown. \u2013\u00a0 Rahul Jul 3 '12 at 21:50\n@RahulNarain : thank you , i didn't know that . \u2013\u00a0 Theorem Jul 3 '12 at 21:51\nadd comment\n\n2 Answers\n\nI think the condition is $\\alpha \\geq 1,$ which you need for coercivity of the bilinear form, which in turn can be got by using the fact that$$\\lVert \\nabla u \\rVert_{L^2(\\Omega)}^2 + \\lVert u \\rVert^2_{L^2(\\partial\\Omega)} \\geq C\\lVert u \\rVert_{H^1(\\Omega)}^2$$ for every $u \\in H^1(\\Omega).$\n\nAdded: If you multiply by a test function $v \\in H^1(\\Omega)$ and IBP, you get $$\\int_\\Omega{\\nabla u \\nabla v} - \\int_{\\partial\\Omega}{v\\nabla u \\cdot \\nu} = \\int_\\Omega{-fv}$$ where $\\nu$ is the normal. Plugging in your boundary condition and moving the term involving $g$ on the other side: $$\\int_\\Omega{\\nabla u \\nabla v} + \\alpha\\int_{\\partial\\Omega}{uv} = \\int_{\\partial\\Omega}{gv} - \\int_\\Omega{fv}$$ So your bilinear form $b(u,v)$ (for Lax-Milgram) is the LHS. For coercivity, we need $$b(v,v) \\geq C_1\\lVert v \\rVert^2_{H^1(\\Omega)}$$ for some $C_1$. We have $$b(v,v) = \\lVert \\nabla v \\rVert^2_{L^2(\\Omega)} + \\alpha \\lVert v \\rVert^2_{L^2(\\partial\\Omega)},$$ which implies coercivity if $\\alpha \\geq 1$ because you can use the statement I gave at the top of this post.\n\nshare|improve this answer\nSir , can you tell me how can i get the condition on $\\alpha$ using the fact that u have given ? \u2013\u00a0 Theorem Jul 4 '12 at 3:19\n@Theorem I updated the answer. \u2013\u00a0 Court Jul 4 '12 at 7:16\n@Court I would like to add to Court's solution. A sharper condition is $\\alpha > 0$. Just note that $$ b(v,v) \\ge \\min \\{1, \\alpha \\} (\\| \\nabla v \\|_{L^2 (\\Omega)} + \\| v \\|_{L^2(\\partial \\Omega)} \\ge \\min \\{1, \\alpha \\} C \\| u \\|_{H^1(\\Omega)}$$ \u2013\u00a0 D... Jan 5 at 16:42\nadd comment\n\nI think that this paper can be very useful and essentially contains the answer.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.co.uk/help/optim/ug/minimization-with-gradient-and-hessian.html?nocookie=true\nText:\nDocumentation Center\n\n  \u2022 Trial Software\n  \u2022 Product Updates\n\nMinimization with Gradient and Hessian\n\nThis example involves solving a nonlinear minimization problem with a tridiagonal Hessian matrix H(x) first computed explicitly, and then by providing the Hessian's sparsity structure for the finite-differencing routine.\n\nThe problem is to find x to minimize\n\n\nwhere n = 1000.\n\n\n\ntype brownfgh\n\n\n\nn = 1000;\nxstart = -ones(n,1);\nxstart(2:2:n,1) = 1;\noptions = optimoptions(@fminunc,'GradObj','on','Hessian','on');\n[x,fval,exitflag,output] = fminunc(@brownfgh,xstart,options);\n\nThis 1000 variable problem is solved in about 7 iterations and 7 conjugate gradient iterations with a positive exitflag indicating convergence. The final function value and measure of optimality at the solution x are both close to zero. For fminunc, the first order optimality is the infinity norm of the gradient of the function, which is zero at a local minimum:\n\n\nfval =\n\nexitflag =\n\noutput = \n         iterations: 7\n          funcCount: 8\n       cgiterations: 7\n      firstorderopt: 4.7948e-10\n          algorithm: 'large-scale: trust-region Newton'\n            message: 'Local minimum found.\n\nOptimization completed because the size of the grad...'\n    constrviolation: []\nWas this topic helpful?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/187255/determining-the-value-of-h-that-makes-a-linear-system-consistent/187294\nText:\nTake the 2-minute tour \u00d7\n\nI'm just beginning linear algebra at university and have a teacher who moves very fast and has pre-done slides so i can't actually see the problem worked out, he just talks it out. On top of this, he's also from China and heavily accented, making him hard to understand.\n\nAnyway, i have an augmented matrix, and i want the values of $h$ that make it consistent:\n\n$$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 2 & -8 & 6 \\\\ \\end{array}\\right]$$\n\nand quite frankly, i'm not sure just how to start. I tried eliminating the 1 in the second row, but that made the second line $[0\\;\\;\\; h+4\\;\\; -8]$ and i'm not even sure if that's the right direction or even allowed.\n\nThanks in advance.\n\nshare|improve this question\nIs it clear to you what \"consistent\" means, or even what we mean by an \"augmented matrix\"? \u2013\u00a0 akkkk Aug 26 '12 at 22:13\nI don't see the relevance of the ethnicity of your professor. I would wager he spends time to create those slides so that you read them. \u2013\u00a0 James S. Cook Aug 26 '12 at 23:02\nI don't see the relevance of looking so much into it, I was just stating that I felt behind because he was from another country and heavily accented and I was having a hard time keeping up. The only difference was that I off-handedly mentioned where he was from. \u2013\u00a0 BMEdwards37 Sep 11 '12 at 16:17\nadd comment\n\n3 Answers\n\nA linear system is inconsistent is if it represents a contradiction, for instance the system\n\n$$\\left[\\begin{array}{cc|c} 0 & 0 & -10 \\\\ 3 & -2 & 1 \\\\ \\end{array}\\right]$$\n\nis inconsistent because the first line represents a linear equation $0x+0y=-10$, i.e. $0=-10$, which is a contradiction. Geometrically, when you solve a 2x2 linear system, you are finding the intersection between a pair of lines. If you reach a contradiction, like the system above, then your lines do not intersect, i.e. they must be parallel.\n\nIf you are being asked this question, you have probably already covered Gauss-Jordan ellimination. Inconsistencies in linear systems can be readily identified if the system is brought to reduced row echelon form (can you see why?), so I would start with that. The steps are simple:\n\n$$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 2 & -8 & 6 \\\\ \\end{array}\\right]$$ Multiply the second row by $1/2$: $$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ Subtract the second row from the first: $$\\left[\\begin{array}{cc|c} 0 & h+4 & -8 \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ Without even proceeding further, it is obvious that one way for the system to be inconsistent is if the first line is $0\\, 0\\, |\\, -8$, since this would be equivalent to saying $0x+0y=-8$, that is $0=-8$, a contradiction. The first row would have this form only if $h=-4$, so $h=-4$ makes the system inconsistent.\n\nNow it is pretty clear at this point that no other value of $h$ would make the system inconsistent, and after you are comfortable with Gauss-Jordan elimination this fact would be apparent to you as well, though you should really try to understand why first. So let's say $h\\ne-4$. Then we can multiply the first row by $\\frac 1 {h+4}$: $$\\left[\\begin{array}{cc|c} 0 & 1 & -\\frac 8 {h+4} \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ And now subtract 4 times the first row from the second: $$\\left[\\begin{array}{cc|c} 0 & 1 & -\\frac 8 {h+4} \\\\ 1 & 0 & 3+\\frac {32} {h+4} \\\\ \\end{array}\\right]$$ To really be precise, you can swap the two rows: $$\\left[\\begin{array}{cc|c} 1 & 0 & 3+\\frac {32} {h+4} \\\\ 0 & 1 & -\\frac 8 {h+4} \\\\ \\end{array}\\right]$$\n\nThus for any value of $h$ other than $-4$, we can solve the system - there is no way to make the system displayed above have a row which looks like $0\\,0\\,|\\,c$, for any non-zero number $c$.\n\nshare|improve this answer\nadd comment\n\nA simpler solution is based on a theorem that any system $Ax = b$ is consistent iff rank of $[A \\mid b]$ equal to rank of $A$.\n\nTo compute rank of $A$ perform elimination on $A$ to get: $ \\pmatrix{1 & 0 \\\\ 0 & -8-2h} $ Hence $\\text{rank}(A)=1$ if $h = -4$ and $\\text{rank}(A) = 2$ otherwise.\n\nTo compute rank of $[A \\mid b]$ perform elimination on $[A \\mid b]$ to get: $$ \\pmatrix{1 & 0 & \\frac{3h-20}{h+4} \\\\ 0 & 1 & \\frac{-8}{h+4}} $$ So for values other that $h=-4$ we have $\\text{rank}([A \\mid b]) = 2$.\n\nComparing two ranks, we have a consistent system other than $h=-4$.\n\nshare|improve this answer\nadd comment\n\nSo it is consistent whenever there is at least one solution. That means that the two lines you have cannot be parallel to each other. Multiply the first row by $2$, and you get $[2, 2h, -10]$. The lines will be parallel for the equations $m_1x+n_1y=a$ and $m_2x+n_2y=b$ if $m_1=m_2$ and $n_1=n_2$. In this case, $m_1=2, m_2=2, n_1=2h, n_2=-8$. Since $m_1 = m_2, n_1 \\neq n_2$, so $2h \\neq -8, h\\neq-4$.\n\nNote that there are an infinite number of solutions (aka consistent) if $m_1=m_2, n_1=n_2,$ and $a=b$. Otherwise, you do not have to worry about the $a$ and $b$ values.\n\nshare|improve this answer\nWow, I was going in the complete wrong direction. I'm probably going to have another question here soon, but let me look at it first now after seeing this and i'll see if it helps, these variables are really throwing me off. Thank you though, and keep an eye out for another question here in about 20 minutes :p \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:28\n@BMEdwards37 Sorry I messed up with the negatives, but i fixed my answer. You can think of an augmented matrix as a system of equations, where the each column represents a different dimension, and the last column represents a constant. I was wrong in using \"x\" and \"y\" as dimensions. Usually, people would use $X_1, X_2, X_3...X_n$ \u2013\u00a0 mathguy Aug 26 '12 at 22:30\n@BMEdwards37 Wait, I want to let you know that you are not going in the wrong direction. You ended up with [0 h+4 -8], which is good! The only way to make sure a system is consistent is that ALL of the values cannot equal 0 (nevermind the last column). In your example, since the first column is 0, then the second column CANNOT be 0, so $h+4\\neq0$. If all of the columns except the last equal 0, then there are no solutions. If all columns including the last equal 0, then there are infinite solutions =) \u2013\u00a0 mathguy Aug 26 '12 at 22:35\nI understood your meaning, didn't catch the negatives either. I'm going to post another question because i'm not even sure what it's asking, i appreciate the help. \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:37\nAhh i see, i wasn't so far off. Thanks. \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/110812/show-a-sigma-algebra-contains-the-borel-sets-with-a-infty-or-infty/110816\nText:\nTake the 2-minute tour \u00d7\n\nFor a certain $\\sigma$-algebra $A$ on the real line, I would like to show that it contains the Borel sets. I can show that $A$ contains the left and right half-line $(a,\\infty)$ and $(-\\infty,b)$ for any real numbers $a$ and $b$. My question is : can I infer that $A$ contains the Borel sets by only prooving that it contains the left half-line or is it mandatory to show that $A$ contains both half-line? I'm not clear on how the Borel sets are generated from half-line and open intervals.\n\nshare|improve this question\nMaybe I'm missing something, but for any $a\\leq b$, $(a,b)=(a,\\infty)\\cap(-\\infty,b)$. So the $\\sigma$-algebra contains the base of open intervals, and contains the $\\sigma$-algebra generated by them, hence the Borel sets. \u2013\u00a0 Vika Feb 19 '12 at 3:54\n@Vika yes, but I think Nicolas was asking if it is enough to start with only one of these -- either right OR left -- half-open intervals; i.e. suppose you have $(a, \\infty)$ in your $\\sigma$-algebra for all $a\\in \\mathbb R$. \u2013\u00a0 William DeMeo Feb 19 '12 at 4:03\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nWhat is the complement of one of these half-lines? Then consider intersections, unions, etc. In other words, yes, if you can show your $\\sigma$-algebra contains $(a, \\infty)$ for any $a$, that is enough... but it sounds like it would be a good exercise for you to prove this. Here are some hints:\n\n  1. What is the complement of $(a, \\infty)$?\n\n  2. For $a< b$, what is the intersection of $(a, \\infty)$ and $(-\\infty, b]$?\n\n  3. Show that a $\\sigma$-algebra containing all half-open intervals $(a, b]$ contains all Borel sets. In fact, this is sometimes taken as the definition -- i.e. the Borel $\\sigma$-algebra is the $\\sigma$-algebra generated by the half-open intervals. So, you are either done, or you need to show that this is equivalent to whatever definition you are using. (Hint: at this point you have all the intervals $(a, b-1/n]$, for $n\\in \\mathbb N$ in your $\\sigma$-algebra.)\n\nshare|improve this answer\nYour trivia is motivating. Here is my attempt. 1. The complement of $(a,\\infty)$ is $(-\\infty,a]$. 2. The intersection of $(a,\\infty)$ and $(-\\infty,b]$ is $(a,b]$. 3. Since $(a,b)=\\cup_{n=0}^{\\infty}(a,b-1/n]$ then the $\\sigma$-algebra $A$ contains all open intervals. Since any open set is the union of a countable collection of open intervals, then $A$ contains all the open sets. Since the Borel $\\sigma$-algebra is the intersection of all such $\\sigma$-algebra, then $A$ contains the Borel $\\sigma$-algebra and hence all Borel sets. Thank you. \u2013\u00a0 Nicolas Essis-Breton Feb 19 '12 at 21:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/92311/distributional-derivative-is-locally-integrable-then-the-distribution-as-well\nText:\nTake the 2-minute tour \u00d7\n\nGiven a distribution $T \\in D'(\\mathbb{R})$ such that the distributional derivative $\\partial T \\in L^1_{loc}(\\mathbb{R})$. Can one deduce that $T \\in L^1_{loc}(\\mathbb{R})$ as well? Or can anyone give me an example where $T \\notin L^1_{loc}(\\mathbb{R})$?\n\nshare|improve this question\nIt's not just in $L^1_{loc}$; it's actually continuous. You should be able to prove this yourself. \u2013\u00a0 Deane Yang Mar 26 '12 at 21:48\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nLet $T$ be your distribution. By hypothesis $$ T'(\\phi)=-T(\\phi')=\\int_\\mathbb R f\\phi'dx, $$ where $\\phi$ is a test function and $f\\in L^1_{\\text{loc}}$.\n\nFix $x_0\\in\\mathbb R$ and define $$ F(x):=\\int_{x_0}^x f(x)dx. $$ Then $F$ is a continuous function, which is almost everywhere differentiable; moreover, if $F'(x)$ is defined at some point $x$, then it equals $f(x)$, so that $F'$ and $f$ define the same element in $L^1_{\\text{loc}}$.\n\nThen, the distribution $T$ is given by integration against $F$ up to some additive constant. Indeed, by integration by parts one obtains $$ \\int_\\mathbb R F\\phi' dx=-\\int_\\mathbb R F'\\phi dx=-\\int_\\mathbb R f\\phi'dx=T(\\phi') $$ This shows that the distribution $T_F$ defined by $F$ equals $T$ on every test function which is the derivative of a test function (the point is that a priori a primitive of a test function is no longer a test function in general). To conclude you just need the following elementary lemma:\n\nLemma. Let $S$ be a distribution such that $S'=0$. Then, $S(\\bullet)=\\alpha\\int_\\mathbb R\\bullet dx$, for some $\\alpha\\in\\mathbb R$.\n\nProof. Let $\\alpha:=S(\\phi_0)$, where $\\phi_0$ is a test function such that $\\int_\\mathbb R\\phi_0 dx=1$. Let $\\phi$ be any test function and write it as $\\phi=(\\phi-c\\phi_0)+c\\phi_0$, where $c=\\int_\\mathbb R\\phi dx$. Then, $\\int_\\mathbb R(\\phi-c\\phi_0)dx=0$ so that $\\phi-c\\phi_0$ admits a primitive which is actually a test function, for instance $$ \\Phi_c:=\\int_{-\\infty}^x(\\phi(t)-c\\phi_0(t))dt. $$ Therefore, $S(\\phi-c\\phi_0)=S(\\Phi_c')=-S'(\\Phi_c)=0$. But then, $$ S(\\phi)=c S(\\phi_0)=\\alpha\\int_\\mathbb R\\phi dx.\\qquad\\qquad\\square $$ Thus, since $(T_F-T)'(\\phi)=T(\\phi')-T_F(\\phi')=0$ for every test function $\\phi$, you have that $T=T_F+\\alpha\\int_\\mathbb R\\bullet dx$, for some $\\alpha\\in\\mathbb R$.\n\nTherefore, $T=T_{F+\\alpha}$ and $T$ is the distribution associated to the continuous almost everywhere differentiable function $F+\\alpha$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/93247/irreducible-elements-in-a-ideal-of-rx-1-x-2\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbf R$ denote the real numbers, let's take a finite number of points in $\\mathbf R^2$ and let's take the ideal $I$ of all the polynomials that vanish on this points. Using the Hilbert basis theorem we know that $I$ is finitely generated. I want to know if there exists an element in this ideal that is an irreducible polynomial.\n\nClearly I can suppose that all the finite generators are not irreducible, otherwise it's done. Using this, how can I find such a polynomial?\n\nshare|improve this question\nTake $F=\\sum_{i+j\\le N} a_{ij}x_1^jx_2^j$. To pass through the points imposes a finite set of conditions on the coefficients $a_{ij}$. Taking $N$ sufficiently large you can find such an $F$ which is also irreducible. \u2013\u00a0 J.C. Ottem Apr 5 '12 at 20:05\nBut how can I prove that it\u00b4s irreducible? \u2013\u00a0 Daniel Apr 5 '12 at 20:09\nLet ${\\cal P}_N$ be the space of degree-$N$ polynomials. The reducible polynomials in ${\\cal P}_N$ form the union of subvarieties each of codimension at least $N-O(1)$ [see e.g. my answer to mathoverflow.net/questions/88895]. The polynomials vanishing on a finite set $S$ of points constitute a subspace of ${\\cal P}_N$ of codimension at most $\\#(S)$. Therefore, once $N > \\#(S) = O(1)$ most polynomials in that subspace are irreducible, QED. \u2013\u00a0 Noam D. Elkies Apr 5 '12 at 21:06\nI don\u00b4t understand your answer, and your link is deleted. \u2013\u00a0 Daniel Apr 5 '12 at 23:59\n@Daniel: Try mathoverflow.net/questions/88895 (I see that if you click on what I wrote the final \"]\" gets appended to the URL). What I wrote has a slight typo: should be $N > \\#(S) + O(1)$, not $\\#(S) = O(1)$. Basically, once $N$ is large enough (bigger than the size of the finite subset plus a bit), there aren't enough reducible polynomials of degree $N$ to fill the space of degree-$N$ polynomials vanishing on $S$. (If $N < \\#(S)$ the claim can fail, because all the points in $S$ might lie on one line $l$, and then a degree-$N$ polynomial vanishing on $N$ would vanish identically on $l$.) \u2013\u00a0 Noam D. Elkies Apr 6 '12 at 0:08\n\n1 Answer 1\n\nTo give an explicit answer, choose a system of coordinates $x,y$ such that no two points have the same $x$ coordinate. This is possible since the slopes of lines that pass through pairs of points in the set are only finitely many of all the slopes. Then use basic algebra or the Chinese remainder theorem to find a polynomial equation $y=f(x)$ that passes through all your points. $y-f(x)$ is irreducible so you're done.\n\n(Proof: its degree in $\\mathbb R[x][y]$ is one so it must be the product of a linear and a constant term, but no nontrivial constant terms divide it.)\n\nEdit: A secondary question might be: what is the worst-case scenario lowest-degree polynomial that accomplishes this goal? This method shows that, with $n$ points, there is always a degree $n-1$ irreducible polynomial. Sometimes, there is no degree $n-2$ polynomial: Take $n-1$ points on a line, and one off it. Then an irreducible polynomial vanishing at all $n$ points cannot vanish identically on the line, but vanishes at $n-1$ points on it, so has degree at least $n-1$.\n\nshare|improve this answer\nAh and I forgot something, not only must cancel on this points, and be irreducible, also has only that roots , and no more! \u2013\u00a0 Daniel Apr 6 '12 at 5:46\nI would never have thought there was such a beautifully elementary solution: congratulations, Will ! \u2013\u00a0 Georges Elencwajg Apr 6 '12 at 7:15\n@Will Sawin Your polynomials has other roots right? ( Not just the finite points, What can I do to find a polynomial that only has that finite points and it\u00b4s also irreducible)? \u2013\u00a0 Daniel Apr 6 '12 at 15:31\n@J.C. Ottem I have a question, how can I put in the coefficients the conditions of being irreducible? \u2013\u00a0 Daniel Apr 6 '12 at 15:32\n@Daniel: Let $y,f(x)$ be as before and $g(x)$ vanish at the $x$ coordinates of the set of points, then $(y-f(x))^2+g(x)^2$ is irreducible in $\\mathbb R[x,y]$, because it splits in $\\mathbb C[x,y]$ into $(y-f(x)+ig(x))(y-f(x)-ig(x))$, neither of which is in $\\mathbb R[x,y]$ \u2013\u00a0 Will Sawin Apr 7 '12 at 0:03\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/37360/complete-estimates-of-the-error-for-a-well-known-asymptotic-expression-of-partiti/37453\nText:\nTake the 2-minute tour \u00d7\n\nLet $p(n,m)$ be the number of partitions of an integer $n$ into integers $\\le m$, we have a well-known asymptotic expression:\n\nFor a fixed $m$ and $n\\to\\infty$, $$p(n,m)=\\frac{n^{m-1}}{m!(m-1)!} (1+O(1/n)) $$\n\nMy question is: why the error $O(1/n)$ is independent of $m$? Or how can it be extended for $m$ growing slowly with $n$? Please help me to find the answer or the references. Thanks.\n\nshare|improve this question\nI think there's a derivation of this in George Andrews' book Theory of Partitions. At the very least you might check there. (This is a comment instead of an answer because I don't actually have the book in front of me to check.) \u2013\u00a0 Michael Lugo Sep 1 '10 at 15:14\n\n3 Answers 3\n\nup vote 3 down vote accepted\n\nI'm not entirely sure of what you are asking, but note that Erdos and Lehner proved here that $$p(n,m)\\sim \\frac{n^{m-1}}{m!(m-1)!}$$ holds for $m=o(n^{1/3})$. In generality for any finite set $A$, with $|A|=m$ and $p(n,A)$ denoting the number of partitions of $n$ with parts from $A$, one has $$p(n,A)=\\frac{1}{\\prod_{a\\in A}a}\\frac{n^{m-1}}{(m-1)!}+O(n^{m-2}).$$\n\nSuch estimations can be deduced from the generating function of $p$ by using methods that are described in many books, for example \"Analytic Combinatorics\" by Flajolet and Sedgewick.\n\nshare|improve this answer\n\nThank Robin Chapman very much for editing.\n\nThere is a nice asymptotic expression for partition $q(n,M)$ that denotes the number of partitions of $n$ with $M$ parts all distinct: As $n\\to\\infty$,\n\n$$ q(n,M)\\approx \\frac{(n-1)!}{M!(M-1)!(n-M)!}\\left( 1+O\\left( \\frac{M^{3}}{n} \\right) \\right)$$\n\nIsn't there no similar asymptotic expression for partition $p(n,m)$?\n\nshare|improve this answer\n\nG. Szekeres, Quart. J. Math. (Oxford) 4(2) (1953), 96-111, obtains an asymptotic formula for $p(n,m)$ valid uniformly for all $n$ and $m$.\n\nshare|improve this answer\nHis formula only seems to be valid for n at most a constant times m<sup>2</sup>. It also involves the solution of a quite nasty looking implicit equation, so I'm not sure how useful it is. \u2013\u00a0 Richard Borcherds Sep 2 '10 at 4:23\nPlease be noted that in G. Szekeres' two papers in 1951 and 1953, the asymptotic formulae for $p(n,m)$ valid only under strong condition that $m$ is related to $n^2$. In physics, no asymptotic formula not useful unless $m \\alpha n$ ($\\alpha >0$ and as $m$ is large). \u2013\u00a0 QHLIU Sep 4 '10 at 8:20\nI am not an expert in this area, but see combinatorics.org/Volume_4/Abstracts/v4i2r06ab.html. Here Szekeres' asymptotic formula is given that is valid in the range $k\\geq n^{1/6}$, and is valid uniformly in the entire range $k\\geq 1$ by adding $1/k$ to the big-oh term. See also the article by Romik in Europ. J. Combinatorics 26 (2005), 1-17. As for whether the formula is useful, Szekeres uses it to prove that for $n$ sufficiently large, the sequence $p(n,1), p(n,2),\\dots, p(n,n)$ is unimodal, the only known proof of this result. \u2013\u00a0 Richard Stanley Sep 7 '10 at 15:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/178664/consider-x-2-sqrt36-x-xt-where-x-is-the-integer-part-of?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nconsider $x = (2+\\sqrt[]{3})^6$, $x=[x]+t$, where $[x]$ is the integer part of $x$, and $t$ is the 'non integer' part of $x$. find the value of $x(1-t)$\n\nshare|improve this question\nNOTE: $(2+\\sqrt3)=(2+\\sqrt[]{2^2-1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 4:36\nNOTE: $(2+\\sqrt[]{3})^6=((2+\\sqrt[]{3})^3)^2=(26+\\sqrt[]{26^2-1})^2=(1351+\\sqrt[]{1351\u200c\u200b^2-1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 5:43\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nNote that $(2+\\sqrt{3})^6+(2-\\sqrt{3})^6$ is an integer, indeed an even integer. For imagine expanding each term, using the Binomial Theorem. The terms involving odd powers of $\\sqrt{3}$ cancel.\n\nWe have $2-\\sqrt{3}=\\frac{1}{2+\\sqrt{3}}$. So $(2-\\sqrt{3})^6=\\frac{1}{x}$, and $$(2+\\sqrt{3})^6+(2-\\sqrt{3})^6=x+\\frac{1}{x}.$$\n\nSince $2-\\sqrt{3}$ is between $0$ and $0.3$, the number $(2-\\sqrt{3})^6$ is positive but close to $0$. So $x$ is close to but below the integer $x+\\frac{1}{x}$, and therefore $$\\lfloor x\\rfloor=x+\\frac{1}{x}-1.$$\n\nAlso, $t=x-(x+\\frac{1}{x}-1)=1-\\frac{1}{x}$, so $1-t=\\frac{1}{x}$. It follows that $x(1-t)=(x)(1/x)=1$.\n\nRemark: The result is obviously structural. In particular, the exponent $6$ is irrelevant. The same argument works with, for example, $(3+2\\sqrt{2})^{99}$, and in many analogous situations.\n\nA crucial role was played by the conjugate $2-\\sqrt{3}$ of the number $2+\\sqrt{3}$. This sort of thing happens very frequently.\n\nThe fact that medium sized powers of $2+\\sqrt{3}$ are almost integers (but just a little bit smaller than an integer) is at first a little startling. It may be enlightening to use the calculator to compute a few powers. For similar but not identical behaviour, compute some powers of $2+\\sqrt{5}$.\n\nshare|improve this answer\nAnd I was working all the numbers out by hand. I got as far as recognizing that the integer part of (2+sqrt(3))^6=1351+[75660/56] if I didn't make any mistakes anywhere... Checking in Python, I see I was off by one. I thought Newton's method gave under-approximations for square roots but I was wrong, it gives over-approximations \u2013\u00a0 dspyz Aug 4 '12 at 5:03\n$(2+\\sqrt[]{5})^2$=$(9+\\sqrt[]{9^2-1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 6:46\n$(2+\\sqrt[]{5})^3=(38+\\sqrt[]{38^2+1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 6:53\nNote that in this case we are alternately a bit below an integer and a bit above an integer. That's basically because $2-\\sqrt{5}$ is negative. \u2013\u00a0 Andr\u00e9 Nicolas Aug 4 '12 at 6:57\n$(2+\\sqrt[]{5})=\\frac{-1}{2-\\sqrt[]{5}}$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 6:59\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/70125/calculating-n-choose-k-mod-one-million?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI am working on a programming problem where I need to calculate 'n choose k'. I am using the relation formula $$ {n\\choose k} = {n\\choose k-1} \\frac{n-k+1}{k} $$ so I don't have to calculate huge factorials. Is there any way to use this formula and just keep track of the last 6 digits. Could you compute the next k, with only knowing the some of the last digits.\nI understand this is a lot to ask, so all I ask is a point in the right direction. Maths is by far not my strongest subject.\nThanks in advance.\n\nshare|improve this question\nCan you give us an idea of the scale of $n$ or $k$? \u2013\u00a0 Henry Oct 5 '11 at 18:40\n0 <= n, k <= 100. \u2013\u00a0 ricola86 Oct 5 '11 at 18:43\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n\nYou might also want to use $\\binom{n}{k}=\\binom{n}{n-k}$ to reduce the case where $k>n/2$.\n\nUsing $\\binom{n}{k} = \\binom{n}{k-1} \\frac{n-k+1}{k}$ mod one million has a problem when $(k,10)\\not=1$. Such $k$ are zero divisors mod one million, so you cannot divide by $k$ mod one million and get a meaningful result.\n\nHowever, you can count the number of factors of $p$ that are in $\\binom{n}{k}$ for prime $p$. Let $s_p(n)$ be the sum of the base $p$ digits of $n$. Then, the number of factors of $p$ in $\\binom{n}{k}$ is $(s_p(k)+s_p(n-k)-s_p(n))/(p-1)$. Thus, instead of multiplying by $n-k+1$ and dividing by $k$, multiply by $n-k+1$ with all factors of $2$ and $5$ removed and divide by $k$ with all factors of $2$ and $5$ removed. At the end, multiply by the number of factors of $2$ and $5$ computed above.\n\nFor example, let's compute $\\binom{97}{89}=\\binom{97}{8}$.\n\nHere are $97$, $8$, and $89$ in base $2$ and $5$ followed by their sum of digits: $$ 97=1100001_2(3)=342_5(9) $$ $$ 8=1000_2(1)=13_5(4) $$ $$ 89=1011001_2(4)=324_5(9) $$ Therefore, the number of factors of $2$ in $\\binom{97}{89}$ is $(1+4-3)/(2-1)=2$, and the number of factors of $5$ is $(4+9-9)/(5-1)=1$. Therefore, mod one million,\n\n$$ \\begin{align} \\binom{97}{8} &=\\frac{97}{1}\\frac{96/32}{2/2}\\frac{95/5}{3}\\frac{94/2}{4/4}\\frac{93}{5/5}\\frac{92/4}{6/2}\\frac{91}{7}\\frac{90/10}{8/8}\\times2^2\\times5^1\\\\ &=\\frac{97}{1}\\frac{3}{1}\\frac{19}{3}\\frac{47}{1}\\frac{93}{1}\\frac{23}{3}\\frac{91}{7}\\frac{9}{1}\\times4\\times5\\\\ &=010441\\times20\\\\ &=208820 \\end{align} $$ Everything is good above since we can divide by $3$ and $7$ mod one million.\n\nCaveat: Remember that modular division is quite different than standard division of integers, rationals, and reals. It requires solving a Diophantine equation which usually involves the Euclidean algorithm. For example, $1/7=3\\pmod{10}$ because $3\\times7=1\\pmod{10}$.\n\nshare|improve this answer\nI see after finally posting that most of what I say is covered in the links supplied by Sasha. I hope the example gives it some added value. \u2013\u00a0 robjohn Oct 5 '11 at 21:46\nthis is good stuff thanks. It's well explained and I've surprised myself in being able to understand it. +1. \u2013\u00a0 ricola86 Oct 7 '11 at 15:14\n@ricola86: as long as you remember that division $\\pmod{m}$ is quite different than normal division. It requires solving a diophantine equation and usually involves the Euclidean algorithm. E.g. $1/7=3\\pmod{10}$. \u2013\u00a0 robjohn Oct 7 '11 at 15:38\n+1,Nice explanation,you may also like to add the final comment in the actual answer as well. \u2013\u00a0 Quixotic Oct 7 '11 at 18:20\n@FoolForMath: Good idea. I have added a caveat to my answer. \u2013\u00a0 robjohn Oct 7 '11 at 19:40\nshow 1 more comment\n\nIn terms of factorials, probably not.\n\nUse the recurrence ${n \\choose k} = {n \\choose k-1} + {n-1 \\choose k-1}$ and just work mod $10^6$.\n\nAlternatively you can work mod $2^6$ and mod $5^6$ and combine the two results using the Chinese Remainder Theorem. There seem to be interesting patterns in the binomial coefficients mod prime powers but I don't know if there are actually formulas. This is probably more trouble than it's worth, though.\n\nshare|improve this answer\nadd comment\n\nI remember solving SPOJ MARBLES which is actually finding $\\binom{n}{k}$,constraints there are also similar to this problem in hand.\n\nLast January this same problem (with much more difficult constraints) features in Codechef's January cookfoff.You may like to check the editorial which explains the algorithm along with the implementation.\n\nshare|improve this answer\nThis is exactly what I was looking for, thanks alot. Funnily enough, it's a codechef problem I'm working on. \u2013\u00a0 ricola86 Oct 5 '11 at 19:11\n@ricola86:Aha,glad to help!:-)I didn't practise in codechef anymore,but I guess you are not asking help for any current problem-set?! ;-) \u2013\u00a0 Quixotic Oct 5 '11 at 19:16\nerrmm no, I wouldnt dream of it. \u2013\u00a0 ricola86 Oct 5 '11 at 19:24\n@ricola86:Alright! :) \u2013\u00a0 Quixotic Oct 5 '11 at 19:27\nadd comment\n\nYou may find the following page of interest.\n\nMuch of the math behind it is also discussed in this post at math.SE\n\nshare|improve this answer\nNice link thanks, It seems I can't upvote with a low reputation :(. \u2013\u00a0 ricola86 Oct 5 '11 at 19:10\n@ricola86: I upvoted for you. Oops, now I can't upvote for myself! :-) \u2013\u00a0 robjohn Oct 5 '11 at 22:22\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/429590/prove-that-there-not-real-roots-with-px-ax3bx2cxd\nText:\nTake the 2-minute tour \u00d7\n\nlet $P(x)=ax^3+bx^2+cx+d,a,b,c,d\\in R$, such that $$\\min{\\{d,b+d\\}}>\\max{\\{|c|,|a+c|\\}}$$\n\nshow that $P(x)=0$ have no real roots in $[-1,1]$\n\nshare|improve this question\nYou have left out two key pieces of information in the question: the context in which you encountered the question (what class, what book), and what you have tried already. Separately, questions that are phrased in the imperative (\"Show that\") are often considered impolite, because they can come across as orders rather than as questions. \u2013\u00a0 Carl Mummert Jun 26 '13 at 2:15\nWhat's the close votes for?? OP has numerous questions, and contributed answers to non-trivial questions. I think the phrasing has more to do with English not being OP's first language. \u2013\u00a0 Calvin Lin Jun 26 '13 at 4:01\n@Calvin Lin: the number of close votes matches the number of upvotes on my previous comment, if you count the author (me) as an upvote. This particular question could be substantially improved. \u2013\u00a0 Carl Mummert Jun 26 '13 at 11:05\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\n$P(-1)=-a+b-c+d$ and $P(1) = a+b+c+d$ so $P(-1)\\times P(1)= -a^2+b^2-c^2+d^2-2ac+2bd=-(a+c)^2+(b+d)^2$ Since $Min\\{d,b+d\\}>Max${|c|,|a+c|}, we have $P(-1)\\times P(1)>0$ and we have, granted by Bolzano's Theorem, that the number of roots of $P(x)=0$ in $[-1,1]$ is even, that means that $P(x)$ has $0$ or $2$ roots in $[-1,1]$.\n\nNow uses the Cardano's formula to show that it cant have 3 distinct real roots, wich means that 2 roots are complex number and only one is real and this one cant be in $[-1,1]$\n\nshare|improve this answer\nDoes this account for the possibility that it has a double root in $[-1,1]$? \u2013\u00a0 Antonio Vargas Jun 26 '13 at 16:46\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96239/determinant-of-an-updated-covariance-matrix/96240\nText:\nTake the 2-minute tour \u00d7\n\nI am faced with the following problem :\n\nOriginally (at time 0) I have a number of data samples $x^0_{1...n}$ (normalised : $E[x] = 0, Var[x] = 1$) from which I have calculated the covariance matrix $C^0 = X^T X$ (where $X$ is the matrix of data samples), and the corresponding determinant $|C^0|$ (I could also store all and any minors are necessary).\n\nGiven this information I would like to perform the following iterative process incurring the smallest computational cost possible :\n\nAt time $t+1$ I am presented with a new data sample $x^{t+1}_{new}$ (similarly normalised) which can replace any of my existing data samples. Thus if I discard example $x^t_k$ in favour of this new sample, I have a new covariance matrix $C^{t+1}_{k,new}$. I would like to calculate (given $C^0$, its minors and determinant) $\\forall t$ $argmax_k |C^{t+1}_{k,new}|$.\n\nNote that at each time step $t+1$, if I decide to discard $x^t_k$ in favour of $x^{t+1}_{new}$ then $x^{t+1}_k = x^{t+1}_{new}$ .\n\nMy question is, is there a method to calculate the determinants without incurring a cost of $n^3$ per determinant per time step?\n\nThanks for the help.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nFirst compute a Cholesky factorization of the covariance matrix. Now your tentative new covariance matrix is a rank-2 update of the old, $$ M_{new}=M_{old}+\\frac{1}{n}x_{new}x_{new}^T-\\frac{1}{n}x_{old}x_{old}^T. $$ You can use Sylvester's formula here to compute the determinant of the update; for this you'll only need to solve a linear system, which is $O(n^2)$ using your Cholesky factorization.\n\nThen when your \"replacement\" take place for real you just have to update the Cholesky factorization, and there are algorithms to do that (low-rank updates of Cholesky factorization) in $O(n^2)$ as well. Check Matlab's cholupdate for instance.\n\nSo you pay $O(n^3)$ at the first step and then $O(n^2)$ per step.\n\nEDIT: better and clearer algorithm\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70803/shortest-painting-of-the-sphere/70807\nText:\nTake the 2-minute tour \u00d7\n\nLet $S$ be the sphere in $\\mathbb{R}^3$ and $C:[0,1]\\to S$ a continuously differentiable curve on $S$. Let $T:[0,1]\\to\\mathbb{R}^3$ denote the tangent vector of $C$. Let $P(t)$ be the plane containing $C(t)$ and having normal vector $T(t)$.\n\nGiven a size $d$ of the \"paint brush\" we define the \"brush\" $b:[0,1]\\to \\mathcal{P}(S)$ by letting $b(t)$ be the points of $S$ that are at most a distance $d$ (metric on the sphere) from $C(t)$ that are contained in $P(t)$.\n\nWe can think of this as saying the \"brush\" $b(t)$ is an arc on the sphere that is \"orthogonal\" to the motion $C(t)$ of the \"paint brush\".\n\nGiven $d$ what is the arclength of the shortest curves such that $\\cup_{t\\in[0,1]} b(t) = S$. This says that the \"paint brush\" covered the sphere.\n\nshare|improve this question\nDuplicate? mathoverflow.net/questions/26212/\u2026 \u2013\u00a0 Gjergji Zaimi Jul 20 '11 at 9:19\n\n2 Answers 2\n\nThe model is that used by Henryk Gerlach and Heiko von der Mosel in their 2010 paper \"On sphere-filling ropes\" arXiv:1005.4609v1 (math.GT) may be relevant. Their question is different: What is the longest rope of a given thickness on a sphere? But their explicit solutions are packings, and it seems they could be converted to painting paths. Here is a piece of their Fig. 6:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Rope on sphere\n\nshare|improve this answer\nYes indeed -- by as brush width half the width of the rope. This seems to give an optimal painting for countably many widths. Very nice! \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:38\n\nThis question is somewhat related to this recent one. More precisely, the comment by Gjergji Zaimi in the earlier question gives a painting of length $2\\sqrt{2}\\pi$ for $d=\\pi/4$, which, as explained in another comment there, is optimal for a path at constant distance from the sphere. So for $d=\\pi/4$ the optimal length should be $2\\sqrt{2}\\pi$.\n\nshare|improve this answer\nOf course $d=\\pi/4$ is very special, since for this painting each point of the sphere is painted exactly once (except for a curve). It's not clear whether there is another value of $d$ for which this is possible. \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:02\nindeed your comment there was very good too. \u2013\u00a0 Pietro Majer Jul 20 '11 at 10:04\nThanks! But the answer by Joseph O'Rourke above is much more complete. \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:46\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/99959/generators-of-a-2d-lattice/99964\nText:\nTake the 2-minute tour \u00d7\n\nDear MO_World,\n\nI'm hoping someone can point me towards a reference for something. I have an invertible $2\\times 2$ matrix, $A$, with real entries such that for both of the rows, the entries are rationally independent (this ensures that $A\\mathbb Z^2$ only intersects the coordinate axes at the origin).\n\nWhat I want is a pair of generators of the lattice, $u$ and $v$, with $u$ belonging to the first quadrant and $v$ to the fourth quadrant.\n\nI have a proof that I'm not entirely happy with using continued fraction convergents, but as it's going in an already-long paper, I'd love to have a self-contained reference for this.\n\nDoes anyone have any suggestions?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nEDIT: why does a lattice have a shortest vector? To get to the other side? No. Because it is too far to walk around. Also your matrix $A$ is invertible, $A^{-1}$ has an operator norm with respect to the ordinary length, for any vector $w$ we have $|A^{-1} w| \\leq C |w|$ with a constant $C > 0$ that depends on the matrix. So $|A x| \\geq |x| / C. $ All nonzero lattice vectors have length at least 1, so all vectors in your lattice have length at least $1/C.$ Furthermore, the number of lattice vectors with length below any given bound is finite. So there is a shortest vector.\n\nEDITEDIT: For the why is the shortest vector part of a basis? Call it $u.$ It is expressed as $r x + s y,$ for $x,y$ the columns of your matrix. If $\\gcd(r,s) = g > 1,$ then $u/g$ is a strictly shorter vector in the lattice.\n\nORIGINAL: Take a shortest vector $u,$ and a fairly short vector $v,$ with $$ u \\cdot u = a, \\; \\; u \\cdot v = b, \\; \\; v \\cdot v = c. $$ Without loss of generality, $u$ is in the first quadrant. If $v$ is in the second or fourth quadrant we are done. If $v$ is in the third quadrant, replace by $-v.$ So now both are in the first quadrant, the angle $\\theta$ between them is below $\\pi/2$ and we get $$ 1 > \\cos \\theta = \\frac{b}{\\sqrt{ac}} > 0. $$ So $$ 0 \\leq b \\leq a \\leq c $$ and $$ b^2 < a c. $$\n\nSo, take the fairly short vector $v$ and subtract off multiples of $u$. We know that $u$ is shortest so for any integer $k$\n$$ | v - k u|^2 \\geq |u|^2 = a. $$\n\nNow, take the circle of radius $\\sqrt a$ around the origin. For real $t,$ we know that, if the line $v - t u$ passes through the circle at all, the length of the segment of intersection is no longer than $\\sqrt a,$ otherwise there would be an integral value of $t$ giving a lattice point inside the circle, which is forbidden. It follows that the point of closest approach to the origin is not closer than $\\frac{\\sqrt{3a}}{2}.$ In turn, pretending that the line passes through the fourth quadrant next, the length of the line segment between the intersections with the $x$ and $y$ axes is no shorter than $$ \\sqrt {3a} > \\sqrt a.$$ That is, there is an integral value $t = t_0$ for which $v - t_0 u$ lies in the fourth quadrant. The new basis for the lattice is $$u, v-t_0 u.$$\n\nshare|improve this answer\nThanks for this - a nice argument. \u2013\u00a0 Anthony Quas Jun 19 '12 at 4:52\n\nHere is an other proof.\n\nI will construct a hexagon with the vertices $u, v, w, -u, -v, -w$ from your lattice $L$ such that $$\\angle(u,v),\\ \\angle(v,w),\\ \\angle(w,-u)\\le \\tfrac\\pi2$$ and such that each pair $$(u,v),\\ (v,w),\\ (w,-u),\\ (-u,-v),\\ (-v,-w), (-w,u)$$ forms a basis of $L$. Clearly in this case one of these bases will satisfy your condition.\n\n\n  \u2022 Take $u$ in $L$ which minimize the norm.\n  \u2022 Take $v$ in $L\\backslash\\langle u\\rangle$ which minimize the norm.\n\nNote that $u$ and $v$ form a basis of $L$. WLOG we may assume that $\\angle(u,v)\\le\\tfrac\\pi2$. Note that for $w=v-u$ all the above conditions hold.\n\nshare|improve this answer\nAnother very nice creative argument - thank you! \u2013\u00a0 Anthony Quas Jun 19 '12 at 15:38\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/91528/probability-to-be-the-winner-in-a-tournament\nText:\nTake the 2-minute tour \u00d7\n\nIn a project in Game Theory we (Ayala Arad and Ariel Rubinstein) are stuck with the following \"simple\" question. We are sure of the conjecture but we failed to find a (hopefully simple) proof:\n\nLet A and B be two non-empty finite disjoint sets of players. Any two players in A are \"matched\" and $\\$2$ are transferred from one to the other. Any player in A is also matched with any player in B and $\\$1$ is transferred from one to the other. The two possible directions of each transfer are equally likely and independent. No transfers are carried out between players in B. The winner is the player with the highest net transfers. In the case of a tie, the winner is selected randomly from among the highest scoring players. (For example if |A|=1 and |B|=2 the probability of winning for the player in A is 1/4 and the probability for the player in B is 3/8. If |A|=|B|=2 the corresponding numbers are 21/64 and 11/64). Claim: If |AUB|>3 then the probability of winning for any player in A is strictly larger than that of any player in B.\n\nshare|improve this question\nDear Ariel, Welcome to MathOverflow! May the force be with you :) \u2013\u00a0 Gil Kalai Mar 18 '12 at 14:16\nWouldn't any two players in A have the same number of transfers, and the same for B? I guess I don't understand the game. \u2013\u00a0 Patrick Reardon Mar 18 '12 at 18:15\nTo Patrick: Note, that the direction of transfer between any two players is indepedent from the directions in other \"matches\". \u2013\u00a0 Ariel Rubinstein Mar 18 '12 at 22:00\nThanks, it's clearer now. So we could say that every pair of players in $A$ flip a fair coin and the winner gets $\\$2$. Every pair of players with one from $A$ and one from $B$ flip a fair coin and the winner gets $\\$1$. Interesting problem! \u2013\u00a0 Patrick Reardon Mar 19 '12 at 8:33\n\n3 Answers 3\n\nHere's a partial answer, I believe that the technique can be generalized to include more cases.\n\nSuppose that $|A|=|B|=n$ and $n$ is large enough. As $n\\to \\infty$, the distribution of what an $A$-player gets is roughly $N(0,3n-2)$ and what $B$=player gets is roughly $N(0,n)$. Hence, we can choose some threshold $t_n$ (about $\\sqrt{\\log n}$ or so) such that the expected number of $A$-players getting more than $t_n$ is large (tends to infinity) and the expected number of $B$-players getting more then $t_n$ is small (tends to zero). The probability that a $B$-player will get more then $t_n$ therefore also goes to 0.\n\nFurthermore, the amounts different players get are almost pairwise independent (they are independent up to the amount one of them pays the other). Thus, a second moment argument easily show that the probability of some $A$-player gets more then $t_n$ goes to 1. So the probability that an $A$-player will win goes to 1. Since the players are symmetric and there are equal number of $A$ and $B$ players, we get that the probability of an $A$-player to win is strictly larger then that of a $B$-player.\n\nThis can be extended to other regimes by analyzing what $t_n$ and the probabilities actually are and perhaps using the binomial distribution instead of Normal (actually, I now notice that the argument is not precise as it is since I use Normal approximation in a regime where it is not formally valid, but it's easy to correct). Perhaps all cases where either $|A|$ or $|B|$ are large enough can be covered that way and perhaps \"large enough\" turns out to be pretty small after all. Perhaps I'll try to give a more complete answer later.\n\nOne final remark: it seems that (at least asymptotically) it is not important that $2>1$, but only that $2>0$.\n\nshare|improve this answer\nThanks. We do need the result for small values as well (and not just for large numbers). Note that for general |A| and |B| (not for the case that |A|=|B|) we need the condition that $2>$1: Consider the case that the transfer between a member of A and a member of B (which is now $1) is very very high then if |A|>|B|, the probability of a member of B to win will be larger (the transfers inside B will be negligible). \u2013\u00a0 Ariel Rubinstein Mar 18 '12 at 21:58\n\nThis was intended to be a comment to Ori's post but it is too long, so I'm posting it as an answer. First of all, let us modify the game a bit by initially giving each player a random score between $0$ and $\\varepsilon$. That will break the ties just as needed but will allow us to talk about the winner.\n\nNow the case $|A|=|B|$ is trivial. Let's do all transactions between $A$ and $B$ first and look at the resulting configurations. They split into natural pairs (swapping $A$ and $B$). Now let $a$ be the top score in $A$ and $b$ be the top score in $B$. Arrange the pair so that $a>b$. Then we need to show that for every configuration the probability that the top score in $A$ will become less than $b$ after transactions in $A$ is less than that the probability that the top score in $B$ will become larger than $a$ if we do the transactions in $B$. Identify $A$ with $B$ in some way so that the top scorers are identified. Any way to do the transactions in $A$ that moves the winner to $B$ should bring the score $a$ of the top scorer in $A$ below $b$ at the very least and that may be insufficient in some configurations. On the other hand, if have one such way and do the inverse transactions in $B$ instead, they'll bring the top scorer in $B$ above $a$ and it is not necessary to move the winner to $B$. That's all one needs to say about the equal cardinalities case.\n\nNow, like Ori, I have to say that I'll try to give a more complete answer later.\n\nshare|improve this answer\n\nFor the little it might be worth, here are the results of some simulations:\n\nThe columns correspond to values of $|A|$ and the rows to values of $|B|$. The four-tuple in each cell is (Probability winner is in $A$, Probability winner is in $B$, Probability a given member of $A$ is the winner, Probability a given member of $B$ is the winner).\n\nI simulated each of these 10,000 times, rounded results to the nearest percent, and retyped them (which has a small chance of having introduced additional errors).\n\nI was struck by the non-monotonicity in the third entry as you go down the third column, so I repeated these trials and got the same result.\n\nshare|improve this answer\nThanks. We conducted here similar simulation for all |A|,|B|<11 In case you are interested: arielrubinstein.tau.ac.il/simulation.pdf \u2013\u00a0 Ariel Rubinstein Mar 19 '12 at 5:43\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/17837/linearmodelfit-with-millions-of-rows\nText:\nTake the 2-minute tour \u00d7\n\nI'd like to do a simple regression with millions of rows of (x,y) data. It seems to be too long for Mathematica. Is there a way to speed it up? It shouldn't be that hard to do, I am not sure what Mathematica is doing.\n\nFor example here's how the timing grows with the size of the input:\n\n    First@Timing[LinearModelFit[RandomReal[NormalDistribution[], {#, 2}], x, x];] & \n        /@ {10, 100, 1000, 10000, 100000}\n\ngenerating on my machine:\n\n    {0., 0.015600, 0.046800, 0.670804, 26.722971}\n\nIt doesn't seem like it should be taking so much longer for longer data, and yet it does.\n\nshare|improve this question\nWhy do you want to use all your (millions of) points? To get more precision? ask yourself what precision you do need, and how many points are needed to get that. I think that will be enough, but there are also several statistically interesting ways to work with subsets and then combine the results. \u2013\u00a0 belisarius Jan 15 '13 at 19:08\n\n1 Answer 1\n\nup vote 9 down vote accepted\n\nLinearModelFit does too much--it computes residuals, etc., etc. When working with large problems, just compute what you need when you need it. It all begins with the fit itself, which should be done with LeastSquares:\n\nLeastSquares[{ConstantArray[1, #], RandomReal[NormalDistribution[], #]}\\[Transpose], \n RandomReal[NormalDistribution[], #]]]] & /@ (10^Range[7])\n\n{0., 0., 0., 0., 0.047, 0.437, 4.508}\n\nMore than half that time is just the random number generation. In brief, computing the fit only takes about one second per four million points. The timing with more independent variables will be proportionately longer (it should scale linearly with the number of points and cubically with the number of variables).\n\nOnce datasets get this large, regression (with just a single independent variable) is usually pointless: you can do just fine by randomly subsampling the data, sometimes with as few as a hundred points or so, depending on the sizes of the residuals and how precise the estimates need to be.\n\nshare|improve this answer\nThanks. And if I need p-values or Rsquareds etc. should I just calculate them myself? Wish there was an option to LinearModelFit to delay computation of extraneous stuff until explicitly called for. \u2013\u00a0 Philip Maymin Jan 16 '13 at 4:01\nI have not found any option in LinearModelFit to delay those calculations. Fortunately, all the ancillary calculations are easy to carry out--it's just a bit of a pain. But any regression with millions of data points is going to take some work :-). (I suppose in MMA 9 you could link to R and use its lm, summary, predict, etc. functions.) \u2013\u00a0 whuber Jan 16 '13 at 14:55\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/95705/why-does-ice-form-on-bridges-even-if-the-temperature-is-above-freezing/95800\nText:\nTake the 2-minute tour \u00d7\n\nSo with this \"arctic blast\" continuing, I've noticed that for my area, the temperature drops below freezing just long enough to cause freezing rain, but then the sun comes out and the temperature rises immediately. However, on bridges, ice continues to form.\n\nHow can ice form even if the temperature is above freezing?\n\nshare|improve this question\n\n6 Answers 6\n\nup vote 17 down vote accepted\n\nAs a supplement to @tpg2114's answer, it also depends on the \"wetness\" of an object.\n\nAs most people should know the evaporation of water requires energy and this lowers the temperature.\n\nThe lowest temperature a wet object can reach is what is called the \"wet-bulb temperature.\" This can be several degrees lower than the \"dry-bulb temperature,\" the amount can vary depending on the humidity (specifically atmospheric pressure). If that wet-bulb temperature gets below 0\u00b0C, then freezing is possible.\n\nIn order for said wet object to get close to the wet-bulb temperature, some convection needs to occur in order to take that evaporated water away (i.e. wind).\n\nThis is one of the ways wind under a bridge can cause freezing under the right conditions. Another possible reason might be heat lost by radiation or the earth via conduction.\n\nshare|improve this answer\nHeat loss via conduction won't cause bridges to cool down faster than the surrounding land. I think the radiative effect is dominant. \u2013\u00a0 gerrit Jan 29 at 10:03\n@gerrit yes It would; a more obvious instance of this is the use of thermal wells in some HVAC systems. The further down you go, the less variation in temperature with outside conditions. When the surface is cool, the not-quite-as-cool dirt and rocks below it warm it up considerably. For the same reason, snowfall does not typically accumulate immediately upon starting, as the ground is not yet at the freezing point. Lower material is able to source enough heat to keep the surface above freezing unless it is particularly cold out, or particularly high wind. \u2013\u00a0 AJMansfield Jan 29 at 18:01\n@AJMansfield But that's not the bridge having a conductive heat sink, that's the bridge lacking a conductive heat source. In other words, the road is heated from below, but the bridge isn't. But the bridge does not lose heat through conduction (it is, to a first order, only in contact with air, and air is a bad heat conductor). \u2013\u00a0 gerrit Jan 29 at 20:06\n\nTypically freezing rain falls as water because the air is warm enough that it won't be ice, but then it freezes when it's on the surface of things because those surfaces are below freezing. This usually happens with roads and the ground when it's been a long time of very cold temperatures.\n\nBridges also tend to get colder, faster, than other roads because air can flow under them. They don't get the thermal insulation and thermal absorption of the ground. So regular roads may be warm enough or have warmed enough to prevent freezing while bridges have not warmed up enough yet to prevent ice from forming.\n\nshare|improve this answer\ndon't forget about the water evaporating \u2013\u00a0 ton.yeung Jan 28 at 21:34\n@ton.yeung That's a possible factor but if it's close to freezing and it's been precipitating, my guess is the relative humidity is quite high and so the evaporation rate would be pretty low. Obviously if it's super windy or something that would change, but it's probably not a significant factor otherwise. \u2013\u00a0 tpg2114 Jan 28 at 21:47\nits super windy \u2013\u00a0 ton.yeung Jan 28 at 21:53\nFreezing rain more typically falls as liquid, supercooled water. \u2013\u00a0 User58220 Jan 28 at 22:17\n\nShort answer is it can't form when the temperature of the water is above the freezing point. As @Krazer and @tpg2114 have pointed out the temperature of water on surfaces will frequently be lower than the air temperature.\n\nI'm answering just to clarify that the wet-bulb temperature is only indirectly relevant. The wet bulb temperature is not (definitionally) the lowest temperature an object can reach as a result of evaporation. It does provide a lower bound on the temperature that can be reached under outside conditions as experimentally at these pressures it turns out that the rate of convective heating of the water by the air tends to be faster than the rate of evaporative cooling of the water. Thus, the coldest evaporative cooling can reduce the water will be no lower than the coldest the water can make the air. This, of course, occurs when the air evaporates as much water as possible and the total amount of air is very large compared with the water left (so the water contains a negligible amount of thermal energy and is cooled to the air temperature) and at a temperature equal to the wet bulb temperature.\n\nWorking outside one also has to deal with radiative and convective transfers from a very very large volume of air and if still air is left around the water reservoir the rate of cooling by evaporation will drop as the air approaches saturation and the huge body of dry air will start to heat the reservoir faster than it is being cooled. Experimentally, it turns out that high wind speeds and shielded reservoirs give the largest cooling but can't actually reach the wet bulb temperature.\n\nHowever, as suggested here at lower air pressures convection does not ultimate dominate evaporative cooling. In this case one can reduce the water to a lower temperature than the surrounding air and the wet bulb temperature is no longer a minimum value for the temperature evaporation can reduce surface to. Essentially this works since you are letting the highest energy molecules in the water escape and thereby reducing the average kinetic energy of the remaining molecules and the air is so thin that this effect cools the water faster than the neighboring air can heat it back up.\n\nshare|improve this answer\n\nAnother item to think of is the temperature of the bridge itself. If the temperature had been previously below freezing, and the bridge structure itself is cold, it will continue to act as a heat sink until it warms up.\n\nshare|improve this answer\n\nI've pondered that as well. And here is my thoughts.\n\nRoadways have the benefit of being \"insulated\" by the earth under them. So in freezing conditions, the ground underneath is still liberating heat and the roadway may not be at 0C/32F quite yet.\n\nBridges, however, do not benefit from being insulated by the earth- they are exposed to the environment on all sides. And hence, they can approach environmental temperature much faster. In this case, freezing or below.\n\nSo, watch for ice on bridges!\n\nshare|improve this answer\n\nThe wind's \"chill factor\" is a surface area effect. In a bridge, the surface area exposed to the wind is at least twice as much as a comparable section of the road, so with the proper conditions, the bridge's surface will be colder than the freezing point while the road is above this point. For example, assume the still air temperature is 44F and the chill factor -10F. The temperature on the road would be 34F, while the temperature on the bridge would be around 24F.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/66716/equality-in-noncommutative-h%C3%B6lder-inequality\nText:\nTake the 2-minute tour \u00d7\n\nLet $1\\leq p,q,r\\leq \\infty$ such that $\\frac{1}{r}=\\frac{1}{p}+\\frac{1}{q}$. Let $S_p$ denote the Schatten space. For any $x\\in S_p$ and any $y\\in S_q$ we have $$ ||xy||_{S_r} \\leq ||x||_{S_p}||y||_{S_q} $$ (noncommutative H\u00f6lder's inequality).\n\nDoes it exists necessary and sufficient conditions on $x,y$ in order to have an equality in this inequality?\n\nMore generally, I ask the same question replacing $S_p$ by the noncommutative $L_p$-space $L_p(M)$ associated with a semifinite von Neumann algebra $M$ equipped with a normal semifinite faithful trace $\\tau$.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nThe necessary and sufficient condition is that $|x|^p$ and $|y^*|^q$ are proportional. This can be deduced from Dixmier's paper (although it is not clearly stated that way there; it is based on Proposition 8). It probably also appears in more modern treatments (Nelson, Terp, Haagerup, Hiai, Kosaki, etc.) but I don't have the sources here to check that.\n\nshare|improve this answer\nYou probably mean that $|x|^p$ and $|y^*|^p$ are proportional. \u2013\u00a0 Mikael de la Salle Jun 2 '11 at 19:52\nRight. Thanks, Mikael. I'll correct it right away. \u2013\u00a0 Martin Argerami Jun 2 '11 at 20:53\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/48298/how-to-calculate-the-effect-of-the-earths-magnetic-field-on-a-hze-particle?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to calculate the protection provided by the earth's magnetic field from HZE particles to astronauts in low earth orbit, such as those on the ISS.\n\nHZE particles are often quoted as a danger of travel in deep space. But given their high energies I am skeptical that the Earth's magnetic field provides significant protection to humans outside the atmosphere (the ISS orbits ~370km above the Earth).\n\nI have been able to find data on the energy of the particles expressed in MeV or GeV and the strength of the magnetic field expressed in microteslas.\n\nWhat formulas would be applicable in calculating whether 1) the particle is deflected, and 2) if it's not deflected the energy reduction by the time it reaches a given altitude?\n\nshare|improve this question\nAnd? What is the question here? Are you unsure of the meaning of the units; unsure of the physics or what? I mean, the radius of curvature goes by $p_{\\perp}/qB$ (you can look up the full derivation in any E&M text). \u2013\u00a0 dmckee Jan 3 '13 at 22:13\nI'm trying to calculate the protection provided by the earth's magnetic field from HZE particles to astronauts in LEO, eg: the ISS. \u2013\u00a0 Patrick Ritchie Jan 4 '13 at 0:00\n\n1 Answer 1\n\nThe basic physcs here is the Lorentz force on a moving charge, $q$, with velocity, $\\vec{v}$ due to a magnetic field $\\vec{B}$. $$ F = q \\left( \\vec{E} + \\vec{v} \\times \\vec{B} \\right) \\quad ,$$ where we ignore the electrical field so we get $$ \\vec{F}_B = q \\vec{v} \\times \\vec{B}\\quad .$$\n\nThe cross-product implies that the force acts perpendicularly to both field and velocity which means that the general path is (locally) helix with it's axis along the direction of the magnetic field.\n\nThe accelration is $\\vec{a}_B = \\frac{\\vec{F}_B}{m} = \\frac{q v_\\perp B}{m}$ which implies a radius of curvature of in the plane normal to the magnetic field. Noting that this is a centripital force we use $a = \\frac{v^2_{\\perp}}{r}$ to find the radius of curvature as $$r_\\perp = \\frac{v^2_{\\perp}}{a} = \\frac{m v_\\perp}{qB} = \\frac{p_\\perp}{qB} \\quad .$$\n\nDespite the classical derivation the final form involving momentum, charge and field is relativisitcally correct.\n\nMomentum parallel to the field is unaffected.\n\nNow, saying that the path is a helix is only correct for uniform fields which is not true over scales a significant fraction of the Earth's radius, but it is a good approximation of scales of a hundred kilometers or less, which suggests a reasonable step size for a low precision simulation.\n\nMoving beyond the physics you are asking about the the desired result, these particles never lose any energy due to the effects of magnetic fields and are just pointed in different direction. The result is to first order no change in the flux ariving at objects in orbit.\n\nThere are some places where that first order result is insuffient (the flux can actually get amplified near the magnetic poles where particles are revesed and could pass the target twice), but it is a place to start.\n\nNote that I put the charge in the wrong place in the comment I dashed off earlier and have used moderator superpower to fix it post facto.\n\nshare|improve this answer\nMaybe you should emphasize the conclusion that no protection is provided by the earth's magnetic field because the flux does not change locally. Probably the OP is confused by the deviations by the sun's magnetic field, which happen because of the much larger volume that magnetic field affects (c.f.cosmic rays and climate) \u2013\u00a0 anna v Jan 4 '13 at 5:30\nthat should be \"than the one the earth's magnetic field affects\" \u2013\u00a0 anna v Jan 4 '13 at 9:42\nThanks, i'll dig into these and see if I can get some results. \u2013\u00a0 Patrick Ritchie Jan 4 '13 at 15:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/146187/probability-of-picking-a-specific-card-from-a-deck\nText:\nTake the 2-minute tour \u00d7\n\nQuestion: Assume you have a deck with with $52$ cards ($4$ suites of $13$ cards: numbers $1\\ldots 9$, and faces J,Q,K). What is the probability you draw jack of hearts in a hand of $5$?\n\nMy way of thinking is the following:\n\n$$\\frac{\\left(\\dfrac{1\\cdot51\\cdot50\\cdot49\\cdot48}{4!}\\right)}{ \\left(\\dfrac{52\\cdot51\\cdot50\\cdot49\\cdot48}{5!}\\right)}$$\n\n$1$ is for the jack of hearts being drawn, and then $51\\ldots48$ for the rest of the $4$ cards\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 4 down vote accepted\n\nYour thinking is correct, though let me provide another way of looking at the problem that might make its structure clearer:\n\n  \u2022 There are ${51\\choose 4}$ ways to pick a hand that include the Jack of Hearts (because once we've picked the Jack, we can choose 4 other cards from the remaining 51)\n  \u2022 There are ${52\\choose 5}$ ways to pick a hand, with no restrictions.\n\nTherefore the probability of getting a hand with the Jack of Hearts is\n\n$$\\frac{51\\choose 4}{52\\choose 5} = \\frac{51!5!47!}{4!47!52!} = \\frac{5}{52}$$\n\nYou can check that the obvious generalization is, in fact, true: the probability of drawing a particular card in a hand of $m$ cards with a deck of size $n$ is $m/n$.\n\nshare|improve this answer\nadd comment\n\nThe probability you draw the jack of hearts is the same as the probability of drawing any other particular card. Since you draw 5 cards, the 52 individual probabilities have to add up to 5, so each probability is 5/52. In particular, the probability of drawing the jack of hearts is 5/52.\n\nshare|improve this answer\nadd comment\n\nAlternatively, there are $\\binom{51}{5}$ ways of picking a hand that does not have the Jack of Hearts. There are a total of $\\binom{52}{5}$ ways of picking $5$ cards, so the probability of choosing a hand with the Jack of Hearts is: $$1 - \\frac{\\binom{51}{5}}{\\binom{52}{5}} = 1-\\frac{47}{52} = \\frac{5}{52}$$\n\nshare|improve this answer\nAlthough a bit more complicated, this is valid (+1) \u2013\u00a0 robjohn Mar 5 at 23:42\nadd comment\n5/52 seems wrong to me.  \n\nI suggest the slightly higher probability of:\n                          n = (1/52 + 1/51 + 1/50 + 1/49 + 1/48)\n\nWhich approximates to:\n                          n = 5/50\n\nEach time a cards is picked the deck gets smaller, and the probability of \npicking the \"good\" card the next round increases.\n\n5/52 would be the probability ONLY if after each time you drew one card, \nyou replaced it into the deck before the next draw.\nshare|improve this answer\nWith replacement, the probability would be $1-\\left(\\frac{51}{52}\\right)^5$ \u2013\u00a0 robjohn Mar 5 at 23:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/184699/how-do-we-prove-that-the-pythagorean-theorem-holds-for-a-right-angled-isoceles-t/184703\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nWhat is the most elegant proof of the Pythagorean theorem?\n\nHow do we prove that the Pythagorean theorem holds for a right angled isoceles triangle with sides, $a,b,a$.\n\nFor a right angled triangle with sides $a,b,c$, where $\\angle C = 90^{\\circ}$, we have $a^2+b^2=c^2$\n\nshare|improve this question\n\nmarked as duplicate by William, M Turgeon, Fabian, Noah Snyder, tomasz Oct 5 '12 at 19:48\n\n\nI do not understand if you want to prove Pythagora's theorem or something else. \u2013\u00a0 Siminore Aug 20 '12 at 17:07\nWhat is it about the many standard methods of proof that you think don't work in the isoceles case? \u2013\u00a0 Robert Mastragostino Aug 20 '12 at 17:08\nIt follows immediately from the general Pythagorean theorem. Or are you asking whether there\u2019s a simpler proof for the special case of an isosceles right triangle? \u2013\u00a0 Brian M. Scott Aug 20 '12 at 17:08\n@RajeshKSingh You do see that $a\\neq b\\neq c$ does not prohibit $a=c$, right? It kind of sounds like you're treating $\\neq$ as a transitive relationship. \u2013\u00a0 rschwieb Aug 20 '12 at 17:15\nDownvoters and closers: I'm half-sure that you're all missing this person's mistake. I'm pretty sure he has just misread $a\\neq b \\neq c$ as meaning \"a, b and c are all unequal.\" He just thinks that the isosceles case is still unproven. \u2013\u00a0 rschwieb Aug 20 '12 at 17:24\nshow 6 more comments\n\n1 Answer\n\nup vote 5 down vote accepted\n\nMake a paper square with sides $b$. Divide it into $4$ triangles by drawing the two diagonals. Cut along the diagonals.\n\nWe get $4$ congruent isosceles right-angled triangles. Let the right-angled triangles we get have legs $a$. They each have hypotenuse $b$.\n\nWe can put these triangles together in pairs along their hypotenuses to form two $a\\times a$ squares. So we have cut a $b\\times b$ square into four pieces and reassembled the pieces to make two $a\\times a$ squares. Since area is conserved, it follows that $$a^2+a^2=b^2.$$\n\nRemark: This is a simple dissection proof of a very special case of the Pythagorean Theorem. There are several general dissection proof of the Theorem.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/138944/questions-on-symmetric-matrices\nText:\nTake the 2-minute tour \u00d7\n\nDescribe a basis for the vector space of symmetric n x n matrices. What is the dimension of this space?\n\nshare|improve this question\nIs this homework? If it is, it is customary to label it so, and to mention any attempts you have made. \u2013\u00a0 Martin Argerami Apr 30 '12 at 16:08\n@Jim_CS : My guess is that whoever down-voted this question did so because it's written as if you copied a question written by someone other than yourself. \u2013\u00a0 Michael Hardy Apr 30 '12 at 16:16\nIt was in an exam i had today and i never came across it during the course or pre exam study so i had no answer for it. well i said the dimension was n as that seemed obvious. \u2013\u00a0 Jim_CS Apr 30 '12 at 16:20\nReading the comments, I feel you could first try to answer the following questions: (i) Describe a basis for the vector space of all the $n\\times n$ matrices? (ii) What is its dimension? \u2013\u00a0 Did Apr 30 '12 at 18:13\nI dont know what all the downvotes are for...what else am I supposed to put in the post when I wasnt even able to make an attempt at this question in the exam? (apart from putting dim = n, which seems wrong in any case) \u2013\u00a0 Jim_CS Apr 30 '12 at 22:19\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nHINT: If you know all of the elements on and above the diagonal of a symmetric matrix, you know the whole matrix. How many elements are there on or above the diagonal of an $n\\times n$ matrix?\n\nAdded: I can see that you're having trouble getting a handle on the vector space in question; perhaps this will help. Let $S_n$ be the space of $n\\times n$ symmetric matrices. In the simplest case that isn't completely trivial, $n=2$, the elements of $S_2$ are matrices of the form $$\\pmatrix{a&b\\\\b&c}\\;.$$ Vector addition in $S_2$ is just ordinary matrix addition: $$\\pmatrix{a_1&b_1\\\\b_1&c_1}+\\pmatrix{a_2&b_2\\\\b_2&c_2}=\\pmatrix{a_1+a_2&b_1+b_2\\\\b_1+b_2&c_1+c_2}\\;.$$ Note that the result of this addition is still symmetric, so it really is in $S_2$. If it weren't, $S_2$ wouldn't be closed under addition and therefore wouldn't be a vector space after all.\n\nScalar multiplication in $S_2$ is ordinary multiplication of a matrix by a scalar: $$\\alpha\\pmatrix{a&b\\\\b&c}=\\pmatrix{\\alpha a&\\alpha b\\\\\\alpha b&\\alpha c}\\;,$$ and again all's well, since the result is still in $S_2$.\n\nHere's a simple exercise to help you get more accustomed to working with this vector space.\n\nLet $V=\\{\\langle a,b,c,d\\rangle\\in\\Bbb R^4:b=c\\}$.\n\n  1. Prove that $V$ is a subspace of $\\Bbb R^4$.\n  2. Prove that $V$ is isomorphic to $S_2$. That is, find a linear transformation $T:V\\to S_2$ that is one-to-one and maps $V$ onto $S_2$.\nshare|improve this answer\nWell there are n elements on the diagonal so the dimension is n, yes? \u2013\u00a0 Jim_CS Apr 30 '12 at 17:01\n@Jim_CS: There are $n$ elements on the diagonal, but specifying them isn't enough to specify the whole matrix, so the dimension of the space is more than $n$. You also have to specify the elements above the diagonal. How many of those are there? As for your other question, it means exactly what it says: the space of $n\\times n$ symmetric matrices, i.e., the space whose elements are these matrices. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 17:03\n@Jim_CS : it seems to me that you're making a confusion between the dimension of the space spanned by the column of a single matrix (i.e. its rank) and the dimension of the space of all (symmetric) matrices, which is a vector space itself (the \"vectors\" are the matrices) \u2013\u00a0 Andrea Mori Apr 30 '12 at 17:13\n@Jim_CS: The $3\\times 3$ identity matrix isn't a vector space, so it doesn't even have a dimension. Its rank is $3$. That aside, you're not thinking about what the question actually asks. You have a vector space $V$ whose elements $-$ the actual vectors in $V$ $-$ are $n\\times n$ symmetric matrices. Each matrix is one vector in $V$. You could write it out as a single row of $n^2$ numbers instead of as a square array, except that it would be much harder to tell that it was symmetric. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 17:15\n@Jim_CS: I'll expand my answer a bit to try to give you a better idea of what the space itself is like. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 22:24\nshow 4 more comments\n\nIf $A$ is a symmetric $n\\times n$ matrix, then $A$ has the form $$ \\begin{bmatrix} * \\ & a_1 & a_2 & \\cdots & a_k \\\\ a_1 & * \\ & a_3 \\\\ a_2 & a_3 & * \\ \\\\ \\vdots & & & \\ddots & \\\\ \\\\ a_k & & & & * \\ \\end{bmatrix} $$ where the $*$ entries are whatever you like them to be. You can see that we have $a_{ij}=a_{ji}$.\n\nFrom this form you can see that we need $n$ elements in the basis to span the diagonal entries. For the remaining $n(n-1)$ entries, we need exactly $\\frac{1}{2}n(n-1)$ elements in the basis to in order to span those entries (due to the fact that $a_{ij}=a_{ji}$). This gives a basis with $\\frac{1}{2}n(n+1)$ elements.\n\nDefine $T_{ij}$ to be the matrix with $(T_{ij})_{ij}=1$ and all other entries equal to $0$. Then define $$ M_{ij} = T_{ij}+T_{ij}^\\text t $$ where $i$ and $j$ range over $1,2,\\dots, n$. Then for a given $n\\times n$ symmetric matrix $A$, we can write it as $$ A = \\sum_{i=1}^n\\sum_{j=1}^n \\frac{1+\\delta_{ij}}{2}(A)_{ij}M_{ij} $$ where $(A)_{ij}$ denotes the $(i,j)^\\text{th}$ entry of the given matrix $A$. The $\\frac{1+\\delta_{ij}}{2}$ in the sum is to correct for the fact that $M_{ij}=M_{ji}$.\n\nThe collection of the distinct $M_{ij}$ will form a basis for the space of $n\\times n$ symmetric matrices. Of course, this is not proof, but provides a way that you might express the basis.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/20529/fast-method-for-nth-squarefree-number-using-mathematica/20541\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to compute Nth Squarefree numbers using Mathematica. What I am trying to utilize is the SquareFreeQ[i] function.\n\nHere is my solution :\n\nNSqFree[N_] := For[n = 1; i = 1, n <= N + 1, If[SquareFreeQ[i], If[n == N, Print[i] ] n++] i++]\n\nBut I am supposed to compute NSqFree[1000000000] but seems like my approach is taking for ever. Any faster method ?\n\n\n\nHere an exactly identical topcoder question and the corresponding editorial for the same.\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n\nYou have to us the Inclusion-Exclusion principle: suppose you want to find the number of square free numbers up to $N$, then from $N$ you have to substract the number of integers divisible by the square of a prime, but then you have to add any multiple of the square of the product of two discinct primes and so on, in formulas the number looked for is $$ N - \\sum_{p^2 \\le N} \\left\\lfloor\\frac{N}{p^2}\\right\\rfloor + \\sum_{p^2q^2 \\le N} \\left\\lfloor\\frac{N}{p^2q^2}\\right\\rfloor - \\sum_{p^2q^2r^2 \\le N} \\left\\lfloor\\frac{N}{p^2q^2r^2}\\right\\rfloor + \\cdots -\\cdots $$ using the moebius $\\mu$ function you can write this last formula as $$ \\sum_{n \\le \\sqrt{N}} \\mu(n) \\left\\lfloor\\frac{N}{n^2}\\right\\rfloor $$ I don't know how to write this in mathematica but it should take a negligible fraction of the time it takes your current method.\n\nshare|improve this answer\nBut my problem is to find the exact Nth Square free number not the number of square free numbers up to N,I have used your idea in here and here but I am not getting how to use the same formula to get the exactly Nth square free number. \u2013\u00a0 Quixotic Feb 5 '11 at 18:42\nOkay I guess I got my answer and here is the explanation. \u2013\u00a0 Quixotic Feb 5 '11 at 18:50\nI'm sorry, I had misunderstood the question. But you can use the same formula combined with a binary search. It will take only a few applications of the formula. \u2013\u00a0 Esteban Crespi Feb 5 '11 at 18:52\nadd comment\n\nYou won't do a billion (if I counted the zeros right) loops any time soon, so you need a better approach. Wikipedia has an approximation under the section Distribution of square-free numbers. So you could start with $10^9 \\pi^2/6$ and calculate how many below that are square-free, then correct from there. You will need to use inclusion/exclusion, but there are only about 40,000 to consider.\n\nshare|improve this answer\nadd comment\n\nI'm not an expert of number-theoretic algorithms, but it seems to me that you can employing the Chinese Remainder Theorem to obtain a decent first stab at a \"sieving\" algorithm.\n\n  \u2022 Use several registers r[p], each storing a residue modulo p2 for some prime p. Define such a register for various small primes p\u00a0\u2208\u00a0{2,\u20093,\u20095,\u2009...\u2009,\u2009P} for some suitably large prime P. You will use these to represent an integer R, such that R\u00a0\u2261\u00a0r[p] (mod p2). You shouldn't need too many such registers to faithfully represent even reasonably large non-negative numbers (the registers can uniquely determine any integer from 1 to 22\u00a0\u00d7\u00a032\u00a0\u00d7\u00a052\u00a0\u00d7\u00a0...\u00a0\u00d7\u00a0P2).\n\n  \u2022 Whenever you wish to increment R, increment each of the registers r[p] as well. If R is square-free, none of these registers will be zero modulo the square of the appropriate prime. For sufficiently small integers N, you can even characterize N as being square-free if none of these residues are zero. Put another way, the more registers r[p] you maintain, the larger the range of square-free numbers you can automatically detect using these registers.\n\nSuppose that you want to test for square-freeness up to some upper limit N. What do you need to test square-freeness using nothing but registers such as I've described? What you need is for any composite number less than N to have a prime factor from the list of registers that you maintain; that is, you need registers for each of the primes up to \u221aN.\n\nIf you're going to iterate through all integers anyway, you can discover the list of primes that you need to characterize square-freeness at the same time by the Sieve of Erasthotenes, and construct the list of residues modulo squares-of-primes as you go. Any time you find a new prime P, so long as P2\u00a0<\u00a0N, add P to the list of primes for which you maintain registers and initialize a register for residues modulo P2.\n\nAs Ross suggests in his answer, you can use results on the distribution of square-free numbers to obtain an upper bound for the Nth square-free number (it should grow more slowly than N\u00a0ln(N) or so, in any case). This gives you an upper bound on the number of registers that you have to maintain as you search for square-free integers.\n\nFrom this, you should actually be able to show a polynomial-time asymptotic upper bound on the runtime of your procedure.\n\nshare|improve this answer\nadd comment\n\nI think that your method can be improved by sieving: if $n$ is not squarefree you don't need to check any of its multiples. Start with a reasonable estimate (like the one Ross Millikan gave) and sieve like you would do in a prime sieve.\n\nIs this viable? I don't know! I can't program in Mathematica, but later today I'll try to implement this in Python.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/68966/mean-value-of-arithmetic-function?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we define a mean value of arithmetic function $G(f)$ as $$ G(f)=\\lim_{x \\rightarrow \\infty} \\frac{1}{x \\log{x}} \\sum_{n \\leq x} f(n) \\log{n},$$ and suppose now for an arithmetic function $f$, $G(f)$ exist and is equal to $A$, how to use this result to show that the ordinary mean value of arithmetic function $M(f)=\\lim_{x \\rightarrow \\infty} \\frac{1}{x} \\sum_{n \\leq x} f(n)$ also exists?\n\nshare|improve this question\nPunctution should go inside double dollar signs (ideally separated by \"\\;\"), otherwise it appears on the next line. \u2013\u00a0 joriki Oct 1 '11 at 8:46\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nVia Abel's summation formula: $$\\sum_{n\\le x} (f(n)\\log n)\\frac{1}{\\log n}=\\left(\\sum_{n\\le x}f(n)\\log n\\right)\\frac{1}{\\log x}+\\int_2^x \\left(\\sum_{m\\le u} f(m)\\log m\\right)\\frac{du}{u\\log^2 u}.$$ Divide by $x$ and subtract, obtain: $$M_x(f)-G_x(f)=\\frac{1}{x}\\int_2^xG_u(f)\\frac{du}{\\log u}=\\frac{\\mathrm{Li}(x)}{x}\\left(A+O(1)\\right)\\to0.$$\n\nshare|improve this answer\nadd comment\n\nYou'll want to use \"partial summation\", also called \"summation by parts\". Define $G(f;x) = \\sum_{n\\le x} f(n)\\log n$ and $M(f;x) = \\sum_{n\\le x} f(n)$. Then you can write $M(f;x)$ as a Riemann-Stieltjes integral $$ M(f;x) = \\int_1^x \\frac1{\\log t} \\, dG(f;t). $$ (Technically the lower endpoint should be $1-\\epsilon$.) Then integrating by parts gives $$ M(f;x) = \\frac{G(f;x)}{\\log x} + \\int_1^x \\frac{G(f;t)}{t(\\log t)^2} \\,dt. \\tag1 $$ (Even if you don't know Riemann-Stieltjes integrals, you can still verify this last identity by hand - just split the integral up into intervals of length 1, on which $G$ is constant.)\n\nWhen you divide both sides of equation (1) by $x$ and take the limit as $x\\to\\infty$, all that remains to show is that the term with the integral tends to $0$. (Note that $G(f;t)=0$ for $t<2$, so there's no problem with the integral at the lower endpoint.)\n\nshare|improve this answer\n(+1) I just realized my answer is essentially the same thing, I didn't see it at first because I'm not used to RS integration. The integrand in $\\mathrm{(1)}$ is $(A+o(1))/t$ so its integral divided by $x$ is $\\frac{\\log x}{x}(A+O(1))$ which is $o(1)$. Thus the arithmetic mean exists and equals $A$. \u2013\u00a0 anon Oct 1 '11 at 9:40\nTrue ... the integrand is in fact $(A+o(1))/\\log t$, but the integral still turns out to be $o(1)$. \u2013\u00a0 Greg Martin Oct 2 '11 at 3:29\nOh yes, you're correct. \u2013\u00a0 anon Oct 2 '11 at 3:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55633/diophantine-problem?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nI have reduced a knotty research problem to the following reasonable looking form:\n\nGiven any two integers $a$ and $b$, show that there are natural numbers $x_1,x_2,x_3$ and a (probaby negative) integer $n$, where $-3n < x_1+x_2+x_3$, satisfying:\n\n$x_1x_2x_3=-n^3-an-b,$ and\n\n\nI am not expecting a solution to this (although that would of course be the ideal outcome)! However, I don't really know where to start. How might one go about solving something like this? Are there any tried and tested methods I should know about?\n\nAnd finally, given the unsolvability of Hilbert's tenth problem, is it possible that there is no way to know whether or not this is true?\n\n(edit: equations corrected. Sorry for time-wasting!)\n\nshare|improve this question\nThanks! To everyone. Your observations have made me realise I've made a stupid mistake. I have corrected the equations in my question...they now look a lot more probable. \u2013\u00a0 Adam Feb 16 '11 at 22:54\nIf $a$ is positive you still get bounded $n,$ after your changes. \u2013\u00a0 Will Jagy Feb 16 '11 at 23:06\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nFollowing up Charles Matthews' idea, Maclaurin's inequality gives\n\n$$\\frac{x_1 + x_2 + x_3}{3} \\ge \\sqrt{ \\frac{3n^2 - 2n + a}{3} } \\ge \\sqrt[3]{ n^3 + an - b}.$$\n\nThe second inequality in particular expands out to an inequality of the form $-54n^5 + \\text{lower order terms} \\ge 0$, so does in fact provide an upper bound for $n$ in terms of $a$ and $b$. If you don't expect the statement to be true, from here it is possible to search for counterexamples.\n\nIf I'm not mistaken, the above inequality never holds when $a = b = 1$, so no such $n$ exists in this case. In general in order to get a reasonable number of possibilities for $n$, $a$ needs to be large compared to $b$. Are you sure you meant to ask the question about any possible $a, b$?\n\nshare|improve this answer\n\nMy guess is that it doesn't work. But I think elementary methods are your friend here. For example the two equations seem set up to apply the AM-GM inequality here, which apparently yields a comparison of two sextic polynomials in n. I think this comes out bounding n in terms of a and b. And unless the x-values are similar in size, there should be more. But most n don't factor like that, so I would expect this to fail.\n\nshare|improve this answer\n\nYou are asking whether the cubic polynomial\n\n$$ X^3 - c X^2 + (a + 3 n^2 -2n) X - (n^3 +a n - b) = 0$$ has positive integer solutions under the assumption that $c < 3 n.$ While I don't know the answer, this presumably reduces to standard arithmetic geometry, bypassing Hilbert's tenth problem.\n\nshare|improve this answer\nI think you mean c > 3n. \u2013\u00a0 Qiaochu Yuan Feb 16 '11 at 17:52\nwith the correction it should be possible with a=2 and b=1 to find the local maximum of the cubic and verify that it is below the x axis \u2013\u00a0 Aaron Meyerowitz Feb 16 '11 at 23:17\n\nHere is an alternative formulation (possibly your original one) where $x_m$ is replaced by $n +$ something which yields $0 < i+j+k$ with each of $i,j,k \\ge -n$ . Then (I've already fixed one mistake, so check my work)\n\n$2(i+j+k+1)n + (ij+jk +ki) = a$\n\n$(i+j+k)n^2 + (ij+jk+ki)n +ijk = an - b$\n\n$(i+j+k+2)n^2 - ijk = b$\n\nSince $(ij +jk +ki)$ can be negative, we don't have $a > n$ or even $b> 0$.\n\nHowever there are inequalities mentioned in other posts which apply to the terms $(s-1) = (i+j+k)$ and $t =(ij +jk +ki)$. Further, one has $an/2 - b = ijk $. So it might be useful to rewrite the system using $s$ and $t$ and solve it given $n$, and then see if $i,j,k$ can be found after that.\n\nGerhard \"Ask Me About System Design\" Paseman, 2011.02.16\n\nshare|improve this answer\nIn the new version (using s and t), we have s > 0, 2sn +t =a, and ijk -sn^2 = b. With n given, one can get s and t in terms of a and b nicely. (I'll let you do that.) The same general advice holds. Good Luck. Gerhard \"Ask Me About System Design\" Paseman, 2011.02.16 \u2013\u00a0 Gerhard Paseman Feb 16 '11 at 23:13\nOops: In the comment above, I mean s = (i+j+k) now, not s=(i+j+k+1). Perhaps you should do it yourself. Gerhard \"Ask Me About System Design\" Paseman, 2011.02.16 \u2013\u00a0 Gerhard Paseman Feb 16 '11 at 23:18\nInstead of keeping up with the changes, I'll just suggest the idea above: use n+i for x_1, n+j for x_2, n+k for x_3, or something similar, and see where that takes you. If you develop it and want more suggestions, you can respond here. Again, good luck. Gerhard \"Going To Play Elsewhere Now\" Paseman, 2016.02.16 \u2013\u00a0 Gerhard Paseman Feb 16 '11 at 23:23\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55065/maximizing-the-smallest-eigenvalue-of-a-diagonally-dominant-matrix/55072\nText:\nTake the 2-minute tour \u00d7\n\nAssume that we have a full-rank diagonally dominant matrix $A$, all the diagonal elements of which are positive, all the non-diagonal elements are negative, and the sum of the absolute values of the non-diagonal elements is equal to the diagonal element. More precisely: \\begin{equation} A=[a_{i,j}] \\qquad a_{i,i}>0 \\qquad a_{i,j} \\leq 0 \\textrm{ for $i \\neq j$} \\quad \\textrm{and } \\quad a_{i,i}=\\sum _{j\\neq i}|a_i,_j | \\end{equation}\n\nWe also have a positive diagonal matrix $D$ whose trace is constant and equal to $K$: \\begin{equation} d_{ij}=0 \\textrm{ for } i \\neq j \\qquad d_{ii} \\geq 0 \\quad \\textrm{and } \\quad K=\\sum_{i}d_{i,i} \\end{equation}\n\nWhat is the matrix $D$ such that the smallest eigenvalue of the matrix sum $T=A+D$ is as large as possible? In other words, how can we find the $d_{ii}$ 's such that we maximize the smallest eigenvalue of $T=A+D$? Thank you all in advance! :-)\n\nshare|improve this question\nThe existence of such matrix is easy to prove, do you want to find it's coefficients? \u2013\u00a0 Kate Juschenko Feb 10 '11 at 22:05\nWe need to find the elements of the diagonal matrix $D$, such that the real part of the eigenvalue with the smallest real part is as large as possible. If finding this matrix is easy, could you please give me some pointers on where to look? Thanks! :-) \u2013\u00a0 Maria Kinget Feb 10 '11 at 23:18\nBecause everything acts on a finite-dimensional Hilbert space such matrix always exists. I don't know how to find it's coefficients. \u2013\u00a0 Kate Juschenko Feb 10 '11 at 23:58\nThe smallest eigenvalue (or the real part of the eigenvalue with smallest real value) of a matrix is a nonconvex function of the matrix. Thus I would expect this to be a hard nonconvex optimization problem unless something special about the additional structure of your problem simplifies things. \u2013\u00a0 Brian Borchers Feb 11 '11 at 0:53\nYou say the matrix $A$ has full rank, but all the row sums are zero, so that the all-ones vector is an eigenvector with eigenvalue $0$. So $A$ can't be full rank. \u2013\u00a0 alex Feb 24 '11 at 21:55\n\n2 Answers 2\n\nIf the A matrix were symmetric (so the eigenvalues are real), then you could just solve a semidefinite programming problem (SDP) to find the matrix D (and 'lambda'). In particular, maximizing the smallest eigenvalue ('lambda') of the matrix A + D in your case would be equivalent to the SDP (over variables D and lambda):\n\nmax lambda such that: A + D >= lambda I Trace(D) = K D_{ii} >= 0\n\nwhere the first '>=' denotes 'greater-or-equal in the cone of positive semidefinite matrices', and I is the identity matrix.\n\nThere are several MATLAB-based packages in which you can formulate and solve problems like this (for instance, Yalmip and CVX). You'll probably also need a solver for SDPs (e.g., sedumi or sdpt3). Good luck, -Dan\n\nshare|improve this answer\n\nMaximize what? The smallest eigenvalue is complex... Do you want to maximize the absolute value of the smallest eigenvalue?\n\nshare|improve this answer\nThe question states that the entries of A and D are real (and even states what their signs should be). So, if A is symmetric, then the eigenvalues will be real. (The nonsymmetric case seems less natural, although you could study it as well.) \u2013\u00a0 David Speyer Feb 10 '11 at 20:35\nWrong on three counts: The smallest eigenvalue is real, by Perron-Frobenius. The convention chosen in the question has row sum zero, so actually the all-ones vector is a right eigenvector. Choosing equal diagonal entries is not always the best you can do, as you can see by the example $A = \\left[\\begin{array}{rr}1 & -1\\\\\\\\ 0 & 0 \\end{array}\\right]$ and $K=1$. \u2013\u00a0 Tracy Hall Feb 10 '11 at 20:36\n@Tracy: How does P-F tell you that the smallest eigenvalue is real? \u2013\u00a0 Igor Rivin Feb 10 '11 at 20:39\n@Igor: Apply it to $tI -A-D$ for large enough positive $t$, such as $t=\\mathrm{tr}(A)+K$. \u2013\u00a0 Tracy Hall Feb 10 '11 at 20:55\nWe need to maximize the real part of the eigenvalue with the smallest real part. Thanks for pointing this out! :-) \u2013\u00a0 Maria Kinget Feb 10 '11 at 21:28\n\nYour Answer"}
{"text": "Retrieved from https://mathhelpboards.com/threads/manipulating-quadratic-and-exponential-expressions.26380/\nText:\nWelcome to our community\n\nBe a part of something great, join today!\n\nmanipulating quadratic and exponential expressions\n\n\nNew member\nJul 19, 2019\nI am having so much trouble figuring this out, I would really appreciate some help.\n\nThe question is:\nThe following function, L, gives the approximate percent literacy rate in India t years after 1900.\n\nL(t)=5.3 x 1.025^t\n\nWhich of the following equivalent functions shows, as a constant or coefficient, the approximate number of years it took for the literacy rate to triple?\n\n(a) L(t)=5.3 x 3^t/44.5\n(b) L(t)=5.3 x 1.077^t/3\n(c) L(t)=5.3 x 1.008^3t\n(d) L(t)=3 x 1.025^t+23\n\nThanks so much. I know what the answer is, but I just have no idea why it is the answer. I just want to understand :(\n\n\nWell-known member\nMHB Math Helper\nMar 1, 2012\nNorth Texas\ninitial literacy percentage is $L(0) = 5.3 \\cdot (1.025)^0 = 5.3$\n\ntriple literacy percentage is $3 \\cdot 5.3$ ...\n\n$3 \\cdot 5.3 = 5.3 \\cdot (1.025)^t$\n\n$3 = 1.025^t$\n\n$\\log(3) = t\\log(1.025) \\implies t = \\dfrac{\\log(3)}{\\log(1.025)} \\approx 44.5 \\text{ years}$\n\n... now look at equation (a)"}
{"text": "Retrieved from https://math.stackexchange.com/questions/948098/determine-the-nth-string-among-those-of-a-given-length-in-alphabetical-order-s\nText:\nWhen building strings using a particular character set (the set can change), such as in a brute-force password cracking, how would I determine which string occurs in the $n$th position when the strings are ordered alphabetically for each length, starting at a given string? (Conversely, what is the position of a given string among those of the same length, starting at a given string of that length?)\n\nFor example, if the character set is $ABCDEFG$, then among the strings of length 2, starting at $AA$, string $AC$ is in position 3 and string $AE$ is in position 5:\n\n$$\\begin{matrix} \\text{position:}&1&2&3&4&5&6&7\\\\ \\text{string:}&AA&AB&AC&AD&AE&AF&AG \\end{matrix} $$\n\nI am programming in Delphi and want to use a function that returns the string: function CharArrayPosToStr(ca: TCharArray; len, pos: Integer): String;\n\nThe purpose is to break the job into working sets of given lengths, so I need to be able to quickly determine something like: Set 1 starts at $AAAA$ and ends at $AAQA$ and set 2 begins at $AAQB$, etc.\n\n\nThe shortlex ordered list of all words on the seven-letter alphabet $ABCDEFG$ is $$A,B, C, D, E, F, G, AA, AB, ..., GF, GG, AAA, ..., GGG, ...$$\n\nIf we replace the letters $A,B,C,D,E,F,G$ with the nonzero digits $1,2,3,4,5,6,7$, then\nthis becomes the list of positive integers written in bijective base-7 notation (in numerical order): $$1, 2, 3, 4, 5, 6, 7, 11, 12, ..., 76, 77, 111, ..., 777, ...$$\n\nMore generally, in the shortlex ordering of all the words on the digit-set $\\{1, 2, ..., k\\} (k \\ge 1)$, the $m$th word is $a_n a_{n\u22121} ... a_1 a_0$, where\n\n$$\\begin{align} a_0 & = m - q_0 k , & & q_0 = f\\left(\\frac m k \\right) \\\\ a_1 & = q_0 - q_1 k , & & q_1 = f\\left(\\frac {q_0} k \\right) \\\\ a_2 & = q_1 - q_2 k , & & q_2 = f\\left(\\frac {q_1} k \\right) \\\\ & \\vdots & & \\vdots \\\\ a_n & = q_{n-1} - 0 k , & & q_n = f\\left(\\frac {q_{n-1}} k \\right) = 0 \\end{align} $$\n\nand $$f(x) = \\lceil x \\rceil - 1.$$\n\nSo, to find the $m$th word in the shortlex ordering of words on an alphabet of $k$ letters, just use the preceding algorithm to find the bijective base-$k$ numeral for $m$ (and convert back to letters using the reverse substitution).\n\nAlso, note that the list-position $m$ of a given word is obtained simply by making the digit-substitution and then reading the result (say $a_n a_{n\u22121} ... a_1 a_0$) as a bijective base-$k$ numeral: $$ m = (a_n a_{n\u22121} ... a_1 a_0)_{\\text{bijective base-}k} = a_n\\ k^n + a_{n-1}\\ k^{n-1} + ... + a_1\\ k^1 + a_0\\ k^0.$$\n\nIf you're interested in the positions of certain words relative to that of others (i.e. in a particular list segment), just find the relative position by the appropriate subtractions.\n\n\nI realize this is an old thread, but the problem seemed familiar, and I recognized I've had a solution for years. In VBA, you can do it like this:\n\nFunction ShortlexPos(sInp As String, sSym As String) As Long\n  If Len(sInp) Then ShortlexPos = InStr(sSym, Right(sInp, 1)) _\n     + Len(sSym) * ShortlexPos(Left(sInp, Len(sInp) - 1), sSym)\nEnd Function\n\nFor example, columns in Excel are named\n\nA, B, ..., Y, Z, AA, AB, ..., AX, AY, AZ, BA, ... XFD\n\nThe position of the last column is given by\n\n\n... which (correctly) returns 16384.\n\nThe complementary function returns the sequence at a given position:\n\nFunction ShortLexStr(iNum As Long, sSym As String) As String\n  If iNum > 0 Then ShortlexStr = ShortlexStr((iNum - 1) \\ Len(sSym), sSym) & _\n   Mid(sSym, ((iNum - 1) Mod Len(sSym)) + 1, 1)\nEnd Function\n\nFor example,\n\n\nreturns XFD\n\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/40290/when-is-the-big-o-relation-preserved-under-exponentiation\nText:\nSuppose that $f, g$ are functions from the positive integers to the positive reals. Under what circumstances will $\\log f(n)=O(\\log g(n))$ imply $f(n)=O(g(n))$?\n\nIt's easy to see that this isn't always true: If $f(n)=3^n$ and $g(n)=2^n$ then we know that $3^n\\notin O(2^n)$, but taking logs gives $\\log3^n = n\\log 3$ and $\\log 2^n=n\\log 2$ and it's obvious that $n\\log 3=O(n\\log 2)$.\n\nThe reason is also clear: If there exists a $c>0$ such that $\\log f(n)\\le c\\,\\log g(n)$ then all we can say is that $f(n)\\le (g(n))^c$, which won't necessarily allow one to conclude $f(n)=O(g(n))$. When, though, can we correctly make the inference?\n\n  \u2022 $\\begingroup$ Just to make sure it's clear, the statement $f(n) = O(g(n))$ is equivalent to the statement $\\log f(n) = \\log g(n) + O(1)$ because $c_1\\cdot e^x = e^{x + \\log c_1} = e^{x + c_2}$ for some constant $c_2$. $\\endgroup$ \u2013\u00a0usul Mar 11 '15 at 3:46\n\nIt is at least sufficient to have $\\log f(n) \\in o(\\log g(n))$. This gives us that for sufficiently large $N$, we have $\\log f(n) \\leq \\log g(n)$ for all $n > N$.\n\nHence immediately we have that for $c=1, n > N$, $f(n) \\leq c\\cdot g(n)$ and ergo $f(n) \\in O(g(n))$.\n\nThis also suggests the condition that if we have that $\\log f(n) \\leq c\\cdot \\log (g(n))$ where $c \\leq 1$ for sufficiently large $n$, then we also get $f(n) \\in O(g(n))$.\n\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/208553/solve-an-integral-differential-equation-with-dsolve\nText:\nI do not understand why the following code does not solve the equation:\n\n\neqn = y[t] == \\!\\(\n\\*SubsuperscriptBox[\\(\\[Integral]\\), \\(0\\), \\(t\\)]\\(Exp[\n      a \\((t - s)\\)] y[s] \\[DifferentialD]s\\)\\);\nsol = DSolve[eqn, y[t], t, y[0] = 1]\n\nCan someone help me please? Thanks in advance.\n\nI tried to use yours idea on the real case, obtaining the following, which is still an integral-differential equation:\n\n\n  \u2022 $\\begingroup$ DSolve[]'s support for integral equations is still somewhat limited, so don't be surprised if some things don't work yet $\\endgroup$ \u2013\u00a0Mariusz Iwaniuk Oct 26 '19 at 15:09\n  \u2022 $\\begingroup$ Are there some other functions which could be useful? $\\endgroup$ \u2013\u00a0Umberto Tomasini Oct 26 '19 at 15:22\n  \u2022 $\\begingroup$ Use LaplaceTransform for equation. $\\endgroup$ \u2013\u00a0Mariusz Iwaniuk Oct 26 '19 at 15:28\n\nYou can sometimes remove the integral part by differentiating the expression with respect to $t$. For example,\n\nD[y[t] == Integrate[Exp[a*(t - s)]*y[s], {s, 0, t}], t]\n(*y'[t] == Integrate[a*E^(a*(-s + t))*y[s], {s, 0, t}] + y[t] *)\n\nWe see that the first term on the right hand side is simply $ay(t)$. So, now you can solve the differential equation\n\n\n\nDSolve[{y'[t] == (a + 1) y[t], y[0] == 1}, y[t], t]\n(* {{y[t] -> E^(t + a t)}} *)\n| improve this answer | |\n  \u2022 $\\begingroup$ I agree with you, the fact is that I was looking for solving a more difficult integral equation, which related differential equation still presents integrals which I cannot neglect. $\\endgroup$ \u2013\u00a0Umberto Tomasini Oct 26 '19 at 18:15\n  \u2022 $\\begingroup$ To clarify, I did not neglect the integral. If your kernel function is separable (i.e., $k(t,s)=f(t)g(s)$), then the following relation should hold upon differentiation y'[t] == y[t] (f[t] g[t] + f'[t]/f[t]). No integrals are necessary. If it is not separable, then, as Mariusz stated, your options are probably limited, but you would need to provide an example to be sure. $\\endgroup$ \u2013\u00a0Tim Laska Oct 27 '19 at 0:21\n  \u2022 $\\begingroup$ Yes, you are right, I get your idea. I tried to apply it on the real case, obtaining the differential-integral equation above $\\endgroup$ \u2013\u00a0Umberto Tomasini Oct 27 '19 at 14:42\n  \u2022 $\\begingroup$ You should provide the initial definition for $y(t)$ and $K(t-s)$. It will be easier for people to help if you also provide the Mathematica code. $\\endgroup$ \u2013\u00a0Tim Laska Oct 28 '19 at 1:43\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/78145/exponentially-different-running-times-random-access-machine-ram-vs-turing-mach?noredirect=1\nText:\nI propose a simple polynomial algorithm for the following problem. Given $m$ integers each one stored on $n$ bits, output the integer that appears the most often.\n\n  1. Reserve a memory area with $2^n$ slots/registers/locations/cells, each cell being long enough to store the number $m$. This requires constant time because we do not initialize/touch the cells. If you agree with this, skip to step 2. Otherwise, check the following four points.\n    \u2022 One could easily be tempted to read \"reserve a memory area\" as \"allocate a memory area\". Actually, the memory allocation operation is an invention/complication of real multi-tasking machines where programs can \"fight\" for memory. If I consider some (Random Access Machine) RAM machine that only knows running my algorithm, I can state that the algorithm can simply use the whole memory. Thus, it is enough to reserve (read \"put aside\" not \"allocate\") the first $2^n$ cells for a an array with $2^n$ elements. The next memory cells are simply used for other variables.\n    \u2022 To be more precise, I consider running my algorithm on a RAM-TM (Random Access Memory-Turing Machine) that is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to move the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics. The RAM-TM has no notion of memory allocation. This seems to be a simplification of the various (Transdichotomous or word) RAM machines out there.\n    \u2022 Even if I must confess I do not really know the exact technical details of all theoretical machines RAM (or RASP), it is possible to work with an exponentially-large memory area and yet use only a polynomially large number of cells and my algorithm is not the first doing this. This also happens in the binary search algorithm over a sorted array: $n$ cells but only $O(log(n))$ time complexity. This scientific paper introduced a data structure that uses a large memory area but has constant time access, see also the answer of zotachidil to this question. My algorithm could work with this data structure instead of explicitly reserving space.\n    \u2022 see Ps 1.\n  2. Go through the $m$ numbers in the input and for each one of them $x$ assign $[x]=0$, where $[x]$ is the memory slot/location number $x$ in the above reserved memory area.\n  3. Go through the $m$ numbers in the input and for each one of them $x$ assign $[x]=[x]+1$.\n  4. Take the first number $x$ in the input and assign $outVal=x$ and $maxFreq=[x]$.\n  5. Scan again the $m$ numbers and for each number $x$ perform: if $[x]>maxFreq$, set $outVal=x$ and $maxFreq=[x]$.\n  6. Output $outVal$.\n\nThe algorithm has time complexity $O(mn)$ assuming $n\\hskip 0.7mm \\not \\hskip -0.7mm \\ll m$ at least on the RAM-TM (see ps 2.), i.e., linear. It is certainly not the only algorithm to solve the problem, but I do not know any other linear algorithm using polynomial memory.\n\nHowever, the big problem is that the algorithm would require exponential time in a Turing machine, no? Does this contradict one of the Extended/Complexity-Theoretic Church\u2013Turing Theses? The section \"Variations\" of the Wikipedia article on the Church\u2013Turing thesis states that \"polynomial-time overhead and constant-space overhead could be simultaneously achieved for a simulation of a Random Access Machine on a Turing machine [55]\", where [55] is \"C. Slot, P. van Emde Boas, On tape versus core: an application of space efficient perfect hash functions to the invariance of space, STOC, December 1984\". Something seems inconsistent. Any help would be greatly appreciated.\n\nps 1. A real-machine argument for the fact one can allocate $O(2^n)$ bits in constant time. Notice I did not say the $2^n$ cells are initialized to some zero values. In a programming language like C this should be achieved by an instruction malloc instead of calloc. In my comment to D.W.'s answer, I provide a reference for a real-life memory allocator that \"performs the allocation/deallocation in constant time\". However, D.W. seem to reject this argument, claiming the above \"constant time\" is calculated by ignoring the fact that we can have $n\\to \\infty$ since in practice $n$ does no go to $\\infty$, if I understood the response. As for me, it is hard to believe this \"constant time\" is actually $O(2^n)$, constant time is really far from $O(2^n)$. I would be surprised to see such large approximations in a paper published by Real-Time Systems.\n\nps 2. Not really essential, but a technical edit: because of Step 5, the complexity of the algorithm should be $O(nm+m\\cdot log(m))$ on a RAM-TM and not $O(nm)$, which is relevant only if $n$ is very very small compared to $m$.\n\n  \u2022 $\\begingroup$ You claim that there is no polynomial time algorithm for a TM machine solving that problem, or you say there is no LINEAR time algorithm for that problem? Time complexity may change depending on what model you choose. But I think your problem is solvable in polynomial time on a deterministic TM. $\\endgroup$ \u2013\u00a0fade2black Jul 20 '17 at 21:28\n  \u2022 $\\begingroup$ Thanks for this reply. I do not really claim there is no Linear algorithm, not essential (by the way, I think the TM needs $O(n^2)$ to compare two numbers on n digits). I agree the deterministic TM can solve it in polynomial time. But the algorithm itself, is it really polynomial on a RAM machine? If yes, how could a TM simulate it with only a polynomial time overhead as stated by the citation from [55]? There are some extended Church-Turing theses claiming the TM can simulate any realistic computation model up to polynomial-time reductions (sec \"Variations\" in the Church-Turing wiki article). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 20 '17 at 21:42\n  \u2022 1\n    $\\begingroup$ You say that \"[...] Turing machine should be able to simulate my algorithm in polynomial time\" but at the same time you demand that you should be able to create a $2^k$ size \"array\" in the RAM model, whereas this must take $2^k$ time in a Turing Machine model. Well, then, of course the TM will be exponentially slower than the RAM machine, but only because you demand it. $\\endgroup$ \u2013\u00a0P\u00e5l GD Jul 21 '17 at 18:11\n  \u2022 $\\begingroup$ Two more things. You need to reserve $2^{n \\log m}$ cells to hold your information, second, in your question regarding binary search, you are given the \"array\" an an input to the algorithm, i.e., the array is already allocated and populated. Nobody claims you're able to construct and populate an array of $n$ elements in $\\log n$ time. $\\endgroup$ \u2013\u00a0P\u00e5l GD Jul 22 '17 at 8:06\n  \u2022 $\\begingroup$ @P\u00e5l GD, thanks for your replies, I agree. If you think I need to edit my question to take these remarks into account, please specify the information I need to update. I said we need $2^n$ cells, each one large enough to store $m$, which is perfectly equivalent to using $2^{n~\\text{log}(m)}$ bits as you said (incidentally, you actually said \"$2^{n~\\text{log}(m)}$ cells\", but I assume you thought about bits). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 11:24\n\nYour algorithm involves an array of length $2^n$. Allocating an array of length $2^n$ takes $\\Theta(2^n)$ time. Consequently, the running time will be $O(m+2^n)$.\n\nAlternatively, you can represent the array in a sparse way using a self-balancing binary tree data structure. Then each access to the array takes $O(\\log m)$ time, so the total running time of your algorithm is $O(m \\log m)$ (assuming we can treat $n$ as a constant).\n\nAlternatively, you could use a hash table to replace the array. Then the expected time per access is $O(1)$ if you use a suitable hash function, so your algorithm will have expected running time $O(m)$ (again, treating $n$ as a small constant). However, this is the expected running time, not the worst-case running time; the worst case could be as bad as $O(m^2)$.\n\nYou seem to have the idea that you can allocate and work with an array of exponential in constant time. I don't think that's correct. What is true is that you can simulate such an array, at the cost of a logarithmic increase in the running time (using the methods I described above). If you care only about whether the algorithm is polynomial-time or not, you can ignore the logarithmic increase, but if you care about the concrete running time, you can't ignore it.\n\nAnd if you really care about the precise running time, you should probably specify the model of computation (e.g., transdichotomous model, etc.). For instance, in the transdichotomous model, if $n$ is guaranteed to be at most the word size (i.e., all of your integers fit within a word), then yes, your algorithm works and runs in linear time -- you can allocate/reserve memory for $2^n$ cells without difficulties. However if $n$ is larger than the word size, you can't. So, giving a precise answer to your question requires specifying a particular model of computation.\n\nRelated: Saving on array initialization.\n\n  \u2022 $\\begingroup$ Could you please expand on why allocating $O(2^n)$ bits requires $O(2^n)$ time? I do not fully agree on this. You think this holds on which RAM machine(s)? Regarding the real-life machines, there is at least a memory allocator that \"performs the allocation/deallocation in constant time maintaining a very low memory fragmentation.\", citing page 150 of [M. Masmano, I. Ripoll, P. Balbastre, and A. Crespo. A constant-time dynamic storage allocator for real-time systems. Real-Time Systems, 40(2):149-179, 2008]. My algorithm should be polynomial when using with this allocator, no? $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:24\n  \u2022 $\\begingroup$ @DanielPorumbel, I haven't read that paper, but my guess would be that it is constant-time in a particular model. Ultimately, memory allocators tend to rely on virtual memory, which tend to rely on a page table datastructure, which are based on a tree data structure, and in the end, as $n \\to \\infty$, the cost of accessing a page you've never accessed before is $O(\\log n)$. (We treat it as $O(1)$ in real machines because in real life $n$ doesn't get very large, but if you want to do asymptotic analysis, arguably it really should be considered $O(\\log n)$ time.) $\\endgroup$ \u2013\u00a0D.W. Jul 21 '17 at 16:44\n  \u2022 $\\begingroup$ So if you're using virtual memory to support memory allocation of extremely large memory regions, of which you write to only a small amount of... you're basically using the \"simulate the array using a tree data structure\" without realizing it. The hardware is doing the tree for you, so it's not visible to you, but it's there. Anyway, if we want to make really precise statements about running time, we have to fix a specific model of computation, and that requires deeper analysis than what's in my answer. $\\endgroup$ \u2013\u00a0D.W. Jul 21 '17 at 16:45\n  \u2022 $\\begingroup$ @ D.W. If you don't trust the memory allocator is really constant-time as claimed (by the way, you seem to accept a complexity of $O(log n)$ which is not $O(2^n)$ and would keep my algo polynomial), please check my first argument below point 1 on the edited question. I can simply consider a RAM machine only for my algorithm. My algorithm would not need memory allocation on this machine, because it can have the whole available memory at its disposal. It can simply put aside the first $O(2^n)$ bits and access them in constant time using the formalization of the RAM machine. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 16:57\n  \u2022 $\\begingroup$ @DanielPorumbel, it's simple since changing $f(n)$ bits requires $\\Omega(f(n))$ time. Because changing a bit in $0$ time is impossible. We consider that machine memory is not essentially bounded by constant unlike computer. $\\endgroup$ \u2013\u00a0rus9384 Jul 21 '17 at 20:50\n\nI would argue that this is not an exponential algorithm on either Random Access Memory or a Turing Machine. On a Turing Machine you could compute as follows (assuming you have a symbol set and state set large enough to cover all of the integers. If not, you are going to have to do a more complex comparison, but that will only be a linear slowdown): Along the tape, alternate cells are the integers, and then counters next to them.\n\nFor each integer in the list:\n    Iterate along the tape, and compare each cell with the current integer\n    If it is the same, increment the relevant counter, otherwise move along the tape.\nOnce you have completed this for all of the integers, iterate along the tape again, and look for the highest counter. Output the integer next to the highest counter\n\nThis algorithm will take $4m$ steps per integer (two out and two back for each integer currently on the tape), multiplied by $m$ integers. It will then take $2m$ time to compare all of the counters, and $2m$ to return to the start to output the answer. This is a total of $4m^2+4m$, which is $O(n^2)$ By using RAM, either a hashtable or an exponential amount of memory can be used. For a hashtable, it is a worst case $O(n^2)$ algorithm, and best case $O(n)$, and with exponential memory it is $O(n)$.\n\nTherefore, in answer to your question, no, it does not have to take exponential time on a Deterministic Turing Machine. Your implementation does, but only because you opted to use an exponential amount of memory. By using RAM, the algorithm can be reduced to $O(n)$ given sufficient memory, or $O(n^2)$ with reasonable limits.\n\nEdited to answer both the comments and the edited question:\n\nWhile the algorithm you use allocates an exponential amount of memory, as you correctly point out it does not write to it. Because of this, the TM can simulate the algorithm without needing the same number of memory locations. Where I have above written the integer to the tape, that is effectively a pointer to your exponential amount of memory. In the interests of simplicity I did not have my array in order, however had I inserted into the middle of the array, rather than appending new values. (at a cost of $O(n)$), then my algorithm would exactly simulate yours.\n\nTo demonstrate this difference, consider the following algorithm:\n\nFor an input of length n:\n    write a 1 to the 2^nth cell\n\nBy your definition, this algorithm is exponential, because the TM would have to move out $2^n$ cells to write. When running this in RAM, it would take constant time. Crucially however, ONLY the $2^n$th cell has been written to, and the rest are undefined. For this reason, the TM could simulate it by writing a 1 to the first cell and ending. I would argue therefore, that this algorithm is constant time.\n\nBased on the above logic, although your algorithm reserves an exponential amount of memory, it only ever uses a linear amount of it (the total amount required to transcribe the input). For this reason, it is not required for the TM to allocate an exponential amount of memory, it can also use a linear amount. This will take either $O(n^2)$ or $O(n^3)$ depending on whether or not you want the array in order.\n\nIn answer to your second point, yes, I sidestepped the issue of the amount of time taken to compare integers. I did this by assuming that the symbol and state set was large enough to accomodate the integers. If you ignore this assumption, there is a further $n^2$ slowdown. (I would note however that it's $n^2$ on the length of a single integer, not on the length of the input as a whole.)\n\nIn conclusion, depending on precisely how you simulate the algorithm, and what you define to be part of the machine vs variable with the input, the TM algorithm can range from $O(n^2)$ to $O(n^5)$, but is definitely polynomial.\n\n  \u2022 $\\begingroup$ Thanks, I agree to what you said. But you actually only prove that the Turing machine solves the problem in polynomial time, using a different algorithm. But the extended Church-Turing theses mentioned at the end of my question seem to say that the Turing machine can simulate RAM machines with polynomial overhead. This would mean that the Turing machine should be able to simulate my algorithm in polynomial time. I don't know how this could happen? $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:30\n  \u2022 $\\begingroup$ A second comment, less important. In the complexity of you Turing Machine (TM) algorithm, do you think the TM can compare two integers on $n$ bits in less than $O(n^2)$? Did you take this into account in the TM complexity calculation? I think this is one of the reasons why multi-tape TMs are useful: they can recognize language $xx$ in linear time, while the TM needs $n^2$ moves, where $n$ is the binary size of $x$. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:40\n  \u2022 $\\begingroup$ @DanielPorumbel, \"simulate the algorithm\" doesn't mean it works exactly identically. The simulation might do all sorts of clever things... including replacing a giant array with a small sorted list, as this answer suggests. $\\endgroup$ \u2013\u00a0D.W. Jul 22 '17 at 1:40\n  \u2022 $\\begingroup$ @C Baish, thanks for the response. As far as I can see, you still use an additional assumption that the input comes alternating the integers and the counters. It is simple to avoid this by using a second tape for the counters. A TM with two tapes can be simulated in quadratic time by a TM with one tape. The second tape could well represent the contents of my utilized memory cells. Less importantly, your $m$ and $n$ notations are a bit confusing, because your $n$ is not my $n$ but it is the input size which is also $m$, assuming \"my $n$\" (size of each integer) is a bounded constant (?). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 10:42\n  \u2022 $\\begingroup$ @C Baish,@D.W. maybe you both found the key: simulate the huge memory with a polynomial size list. This list can work somehow as a virtual memory with polynomial access time. It is enough to use a lame list, no need for a faster red black tree. I will try to answer the question myself by adapting this ideas to bring the resulting Turing machine closer to what I understand by \"simulation\". As it stands the algorithm of C. Baish is not (yet) a simulation for my taste, because it requires a particular input structure. This can however be easily avoided with a second tape as in my above comment. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 10:52\n\nSo this is what I consider as the pitfalls of abstracting physical computation into a purely mathematical theory. First, to answer your question, by extended Church-Turing, when you implement your algorithm on a physical RAM machine, it will run in exponential time.\n\nThere are some subtle points here.\n\n  1. To access a uniformly random memory cell among all $2^n$ cells (of constant size, say, of bits), assuming general relativity and quantum mechanics, there is no way you can do this in $o(2^{n/3})$ time (proof left as exercise, hint: use concentration of volume).\n  2. There are no contradictions because when you reduce a RAM program with time $T$ and space $S$ into a Turing machine, the running time of the Turing machine will be ${\\sf poly}(S, T)$. So extended Church-Turing thesis is robust as long as you don't use superpolynomial space. See also: Strongly polynomial time v.s. weakly polynomial time, although this particular example is not a typical example of weakly polynomial time.\n\nTo conclude, extended Church-Turing thesis really considers reasonable computational models, and the seeming contradiction really stems from the fact that you are making an unreasonable assumption that RAM access only costs constant time.\n\nP.S. You can also consider similar \"speed-ups\" in the circuit model, in fact, you can prove that circuits can decide everything (including undecidable problems) in as much time as one needs to read the input.\n\n  \u2022 $\\begingroup$ Welcome to CS.SE! $\\endgroup$ \u2013\u00a0D.W. Apr 3 at 22:48\n\nThanking everybody for the responses, I come myself with a solution that satisfies me at 99.99%, using arguments from your replies. The main idea is that the Turing Machine (TM) can simulate my RAM machine in polynomial time, provided an initialization axiom.\n\nTo be very clear, I can run my algorithm in $O(nm+m\\log(m))$ time on a RAM-TM (Random Access Memory-Turing Machine). The RAM-TM is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to jump the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics, and an input tape. We consider an additional program tape that represent instructions. For instance, scan, $+1$ could mean ''scan the input tape and for each number increment the memory content pointed by the number''. Incidentally, my algorithm also runs in polynomial time on a Transdichotomous RAM machine with word size $w=n+1$. I think D.W. agrees on this (last paragraph of the response).\n\nA Turing Machine (TM) can simulate my RAM-TM in polynomial time, circumventing the fact that my RAM-TM has infinite memory, since the memory tape is infinite. Consider a whole execution of the RAM-TM consisting of running algorithms/programs $A_1$, $A_2$, $\\dots$, $A_p$, where $A_p$ is my algorithm. If the total time complexity of all these runs is polynomial in $p$ and in the total input size of $A_1$, $A_2$, $\\dots$, $A_p$, then the TM can simulate the whole execution in polynomial time.\n\nWe simulate the whole RAM-TM execution using a 2-tape TM, knowing that a 2-tape TM can be simulated in quadratic (hence polynomial) time by a TM. We use the second tape to store the accessed memory cells of the infinite RAM-TM memory. Since the RAM-TM execution is polynomial, the number of accessed cells is polynomial. We can simply use the second tape of the TM to store all accessed memory locations, each location together with its content. Whenever any of the algorithms accesses memory content $[x]$ on the RAM-TM, the 2-tape TM can scan the second tape in polynomial time and search for index $x$ and retrieve the associated content $[x]$.\n\nI said I am satisfied at 99.9%, because I think we still need an initialization axiom. It is not clear what the 2-tape TM should do when it finds no content associated to some index $x$, i.e., if the RAM-TM asks to retrieve an uninitialized memory cell. We use the following axiom: when the RAM-TM is first turned on, the memory tape contains only zeros. This does not mean that my algorithm $A_p$ can rely on the fact that all uninitialized cells are 0. From the viewpoint of $A_p$, uninitialized cells have an undetermined value, due to the previous programs $A_1$, $A_2$, $\\dots$, $A_{p-1}$.\n\nWithout this axiom, the RAM-TM can not be simulated as far as I can see. Imagine a RAM-TM that has the following memory state when first turned on: the infinitely many bits of the memory tape contain the binary digits of $\\pi$. It can solve the following problem: given an integer $n$ as input, return the $n^\\text{th}$ digit of $\\pi$. It can do this by simply returning $[n]$ in $O(\\log(n))$ time, where it needs $O(\\log(n))$ to write $n$ on the index tape. If we try to simulate this using some multi-tape TM with $\\pi$ on one of the tapes, it would need $O(n)$ time to go to the $n^\\text{th}$ location on that tape. $O(n)$ is exponential compared to the input size $log(n)$.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/water-pressure-in-conical-tank-question.9850/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nWater Pressure in Conical Tank Question\n\n  1. Nov 28, 2003 #1\n\n    Another God\n\n    User Avatar\n    Staff Emeritus\n    Gold Member\n\n    I was wondering if anyon could help me out.\n\n    You have a conical tank with a top diameter of 1m, going down to an outlet of 150mm diameter, height of the tank = 3m, and it's full of water. Assuming an air pressure of 15psi, what is the pressure at the 150mm opening? (the bottom)?\n\n    Does the air pressure make a difference due to the nozzle shape of the tank?\n\n  2. jcsd\n  3. Nov 28, 2003 #2\n\n    Are you trying to say something about a pipeline with a wider beginning and a narow end. The water is flowing from the wider end to the narrower end.\n\n    If this is the problem, then u can use bernoulli's theorem,\n    The total energies at both the ends are the same.\n\n    i.e the sum of pressure energy, kinetic energy and potential energy is constant throughout the flow.\n\n    in other words:\n\n    [tex](p^2)/w + gh + (v^2)/2g [/tex] is always a constant. Assuming that flow is downwards in the problem, the height of the 1m openong is 3 m and that of the 150mm end is 0. So using this find the total energy on each side and equate them. Since the same fluid is flowing w-the sp.density is the same. p is the pressure. At the opening the pressure = air pressure.\n    v is the velocity. To find the value of v at both the ends (or atleast cancel out the v term in the equation) u need to use the continuity equation A1*v1 = A2*v2. Using this find, v1/v2, substitute the other values and then find the value of the pressure at the other end.\n\n    Got it???\n\n  4. Nov 29, 2003 #3\n\n    Another God\n\n    User Avatar\n    Staff Emeritus\n    Gold Member\n\n    Yep, that exactly what we meant.\n\n    Thanks for the reply, we'll run some numbers, and get back to you with what conclusions we reach.\n\n    Thanks again.\n  5. Nov 29, 2003 #4\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Nope. Thats one of the trick questions in fluids. Remember - pressure is pressure. The pressure (static and velocity are the same for the various cases you could do here, conveniently) at the bottom is simply the weight density of water times the height. Technically, thats the static pressure, but if the water is flowing, the static pressure at the bottom of the tank is equal to the velocity pressure. So from that you can caluclate the velocity of the water and the flowrate."}
{"text": "Retrieved from https://www.physicsforums.com/threads/conservation-of-energy-inclined-plane-w-spring.539899/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nConservation of energy/inclined plane w/ spring\n\n  1. Oct 13, 2011 #1\n    Problem: A 2 kg mass is held at the top of a ramp 6m above a spring which has a spring constant of 40 N/m (the 6 m distance is measured along the ramp surface). The ramp is at 30 degrees relative to the horizon. Find the speed of the mass as it just strikes the spring 6 meters below the point it was released from. Find how much the spring is compressed. Ignore friction.\n\n    Formulae: PEspring=1/2kx2, KE=1/2mv2, GPE=mgh (we use 10 m/s2 for acceleration due to gravity), and conservation of energy\n\n    The professor said this problem was tricky, but the solution I found seems like it may be too easy. I calculated the gravitational potential energy to be 60J at the top of the incline. At the end of the ramp, where theoretically all of the GPE would be kinetic energy now because \u03bc=0, I calculated the velocity to be 7.75 m/s. Would this be the correct way to go, given that the incline is at an angle?\n  2. jcsd\n  3. Oct 13, 2011 #2\n    The dimensions of the incline are 6m on the hypotenuse, 3m on vertical leg, 5.2m on horizontal leg by trigonometry.\n  4. Oct 13, 2011 #3\n    And also, k=40N/m.\n  5. Oct 13, 2011 #4\n    The solution will become fairly easy if you apply the work energy theorem.\n\n    Initial configuration - ke is 0\n\n    Final configuration (when spring is completely compressed) - ke is again 0\n\n    So between these to configurations, the work done by all the forces should cancel out to be zero.\n\n    W(gravity) {for 6m + compression} + W(spring){For Cmpression ONLY} = 0\n  6. Oct 13, 2011 #5\n    Thanks for the help! I looked in the textbook (there was an example problem that was exactly the same but done backwards and with different values) and they all lined up with your explanation of using the work-energy theorem, and it basically seemed to be the way I worked it at first. I guess the tricky part that he was talking about was figuring out that you need to find the vertical leg of the inclined plane in order to use that value to plug in to find the potential energy.\n\n    Thanks again!"}
{"text": "Retrieved from https://www.physicsforums.com/threads/vector-differentiation-of-velocity-polar-coord.363484/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Vector differentiation of velocity (polar coord.)\n\n  1. Dec 15, 2009 #1\n    The velocity of a particle moving in a plane in polar coordinates is\n\n    [tex]{\\bf{v}} = v_r {\\bf{\\hat r}} + r\\omega \\hat \\theta[/tex]\n\n    where [tex]v_r = \\frac{{dr}}{{dt}}[/tex] and [tex]\\omega = \\frac{{d\\theta }}{{dt}}[/tex].\n\n    By differentiating w.r.t. time, show that the acceleration of the particle is\n\n    [tex]{\\bf{a}} = \\left( {\\frac{{dv_r }}{{dt}} - \\omega ^2 r} \\right){\\bf{\\hat r}} + \\left( {2\\omega v_r + r\\frac{{d\\omega }}{{dt}}} \\right)\\hat \\theta[/tex]\n\n    (The no-subscript v should be bold, as should the a and the r's with hats.)\n\n    Okay, I'm confident I can work this one out, except for one thing: how does that [tex]\\omega ^2 r[/tex] get into the derivative? I assume the [tex]\\bf{\\hat r}[/tex] is a unit vector, so the derivative of [tex]v_r[/tex] should just be [tex]{\\frac{{dv_r }}{{dt}}[/tex] right? Anyway, if anyone could just explain that detail to me, I'll be on my way.\n\n  2. jcsd\n  3. Dec 15, 2009 #2\n    I like writing in the dot notation because it helps me to remember the dependencies of each variable.\n\n\n    So r depends on time and theta depends on time, what are all the variables that now have r in them and theta in them? (Hint: unit vectors might count!)\n    Last edited: Dec 15, 2009"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-about-simple-harmonic-motion.93241/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Question about simple harmonic motion\n\n  1. Oct 9, 2005 #1\n    A square block, with a mass of 3.40 kg and edge lengths d = 6.00 cm, is mounted on an axle through its center. A spring of spring constant k = 1190 N/m connects the block's upper corner with a rigid wall. Initially the spring is at its rest length. If the block is rotated by 3\u00b0 and then released, what is the period of the resulting SHM?\n\n    What type of problem should this be treated as?\n  2. jcsd\n  3. Oct 9, 2005 #2\n\n\n    User Avatar\n    Homework Helper\n\n    It oscillates by rotation ... it's called a torsional oscillator.\n    You look at \"restoring torque\" which returns the object\n    (which responds slowly due to its rotational Inertia) to\n    the equilibrium orientation angle.\n\n    set torque = I alpha , get torque as function of theta.\n    Now it should operationally look like an oscillator eq'n.\n\n    Be careful to keep the omega_(orientation_change_rate)\n    distinct from the omega_(forward trig function argument)\n    omega_ocr has amplitude 3 degrees, while\n    omega_tfa is multiplied by time.\n\n    Enjoy it, this one is fun!\n  4. Oct 9, 2005 #3\n    there are two different omegas? I'm slightly confused. I know for a torsion oscillator, period is usually found using T = (2*pi)*(I/kappa)^(1/2)\n    Inertia can be calculated...but how should I go about getting kappa, setting the net torque = -k*theta?\n  5. Oct 10, 2005 #4\n\n\n    User Avatar\n    Homework Helper\n\n    Torque is force multiplied by perpendicular distance from axis of rotation.\n\n    Tau = -K(d/2)^2 @ sin@ =@ approx"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/415801/better-transistor-inverter-using-ground-signal\nText:\nI'm getting close to finishing my brand spanking new gate control design. I sincerely appreciate all the help I've received out here.\n\nMy latest challenge is to extinguish an LED when a circuit is grounded. To do so, I require a simple transistor inverter. However, I could not find anything that uses a ground signal. So I had to come up with one.\n\nThe parameters of the circuit are that the input signal has to be a ground, the circuit power has to be 12V, and I am trying to stick to transistors (I could probably use CMOS, but I'm trying to design the entire thing using transistor logic - it's been a great learning experience). This inverter is also powered by solar/battery, so current draw (particularly when active and LED is out) is important. The best I can do is 213.26 uA. Here is my design:\n\n\n(Simulation link)\n\nAll 3 transistors seem to go into saturation mode when they are forward biased, and go into cutoff mode when they are not. I'd like to reduce the current draw, but I don't think it's possible and still maintain exactly 10 mA on the LED when it is lit. Is there a simpler design that I am missing? Am I overlooking the obvious (yet again)?\n\nAs always, any help is sincerely appreciated. I can't wait to finish this design and start building it.\n\n  \u2022 \\$\\begingroup\\$ tinyurl.com/y9lkrcnh \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 2:25\n  \u2022 \\$\\begingroup\\$ There's probably a reason you didn't do this, but tinyurl.com/yc8tavfo ? \\$\\endgroup\\$ \u2013\u00a0user253751 Jan 8 '19 at 2:40\n  \u2022 \\$\\begingroup\\$ Pulling 11.75 mA in off state. \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 2:48\n  \u2022 \\$\\begingroup\\$ Although, thinking about it, seems like a lot of work to save the equivalent power consumed by a single LED. You have a point, and that's why I posted. \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 2:56\n\nI think there are two transistors too many. Most people will say that 70K is a bit high for the base resistor in this application, but we can leave that alone for now. Here is a more simple solution.\n\n\nsimulate this circuit \u2013 Schematic created using CircuitLab\n\nIs there a reason you are not using a saturated switch to drive the LED? Also, why is exactly 10 mA LED current important?\n\n  \u2022 \\$\\begingroup\\$ Sorry, I don't know what a saturated switch is. I'll have to look it up. But in the meantime, you once again came up with an elegant (and INFINITELY better) solution. This is precisely what I was looking for. I tend to over complicate things. Your circuit is perfect (and uses less current). \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 3:39\n  \u2022 \\$\\begingroup\\$ Oh sorry, forget to add.......I've seen circuits where the current used by different LED's is slightly different, and it drives me nuts because I notice it. I'm shooting for 10mA, and if I can just make sure I get close enough to not notice the difference, I will be happy. Right now I'm just simulating. -smiles- \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 3:41\n  \u2022 \\$\\begingroup\\$ @Rikki \"Saturated\" means the transistor is \"completely on\", so that adding more base current won't turn it on any more. \\$\\endgroup\\$ \u2013\u00a0user253751 Jan 8 '19 at 4:16\n  \u2022 \\$\\begingroup\\$ You mention \"saturation\" in your question. Same thing. When the intent of a transistor circuit is to go from full on to full off without operation in the linear active region between, the application is called a saturated switch. \\$\\endgroup\\$ \u2013\u00a0AnalogKid Jan 8 '19 at 14:23\n  \u2022 \\$\\begingroup\\$ Got it. The circuit I provided went from cutoff to 30% of the way into the saturation region of operation when forward biased. I was confused by the term \"saturation switch\" since this is what my circuit was doing (and yours too). This is fun and I sincerely appreciate all your help. \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 19:04\n\nYou are correct (and I was in error), your Q3 and my Q1 are operating in the saturation region, but barely. The rule of thumb (from the 1950's) is that the base current should be no less than 10% of the collector current for hard saturation. I think 5% (20:1) is a more reasonable number for today's parts. The problem with this is that your off-state circuit current is now higher.\n\nTo fix that, change Q1 to a small MOSFET such as the 2N7000 or 2N7002. Now the gate pullup resistor can be 100K or even 1 M, reducing the off-state current through the circuit. For the high resistor values I would add a small noise filter cap such as 100 nF or 1 uF from the gate to GND.\n\n  \u2022 \\$\\begingroup\\$ I see it as a different answer to the same question, albeit one that is very similar to the first answer. The FET can make for a significantly lower off-state current. \\$\\endgroup\\$ \u2013\u00a0AnalogKid Jan 9 '19 at 4:10\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/264156/prove-that-pqm-leq-pmqm\nText:\nIf $p,q$ are positive quantities and $0 \\leq m\\leq 1$ then Prove that $$(p+q)^m \\leq p^m+q^m$$\n\nTrial: For $m=0$, $(p+q)^0=1 < 2= p^0+q^0$\n\nand for $m=1$, $(p+q)^1=p+q =p^1+q^1$.\n\nSo, For $m=0,1$ the inequality is true.How I show that the inequality is also true for $0 < m < 1$.\n\nPlease help.\n\n\nLet $m=1-n$, where $n \\in [0,1]$. Then\n\n$(p+q)^m = (p+q)^{1-n} = p (p+q)^{-n} + q (p+q)^{-n} \\leq p p^{-n} + q q^{-n} = p^m + q^m$.\n\n  \u2022 $\\begingroup$ (Conversely, if $m \\geq 1$ then $(p+q)^m \\geq p^m + q^m$ with the same method.) $\\endgroup$ \u2013\u00a0sdcvvc Dec 23 '12 at 15:32\n  \u2022 2\n    $\\begingroup$ Does this theorem has a name? Is it a type of Jensen's Inequality? $\\endgroup$ \u2013\u00a0luchonacho Mar 9 '17 at 11:45\n  \u2022 $\\begingroup$ @luchonacho I don't know of a name, and it doesn't seem to be Jensen because it relies only on monotonicity not convexity. $\\endgroup$ \u2013\u00a0sdcvvc Mar 12 '17 at 15:06\n\nYour Answer"}
{"text": "Retrieved from https://flyingcoloursmaths.co.uk/ask-uncle-colin-elastic-speed-limit/\nText:\nDear Uncle Colin,\n\nI clumsily dropped a particle of mass $m$! Luckily, it\u2019s attached to a light elastic string with a modulus of elasticity of $3mg$ and natural length $a$. The other end of the string is attached to the point where I dropped the weight from.\n\nWhen I say \u2018dropped\u2019, I mean \u2018propelled downwards with a speed of $\\sqrt{3ga}$\u2019, of course. I\u2019m worried it\u2019s going to go too fast! What\u2019s the fastest it goes?\n\n-- Hands Off Our Kinetic Energy!\n\nHello HOOKE! There are a few ways to approach this. You hint at one of them in your name: you can work with the conservation of energy to find out when the velocity stops changing.\n\nThe total energy throughout the travel is made up of (potential) + (kinetic) + (elastic). I\u2019ll take the zero level for height as the point where the particle is dropped.\n\nInitially, then, the energy is $E_0 = (0) + \\left( \\frac 12 m v_0^2 \\right) + 0$, which comes to $E_0 = \\frac 32 mga$.\n\nOnce the elastic becomes taut, let\u2019s write \u2018height\u2019 as $(a+x)$, where $x$ is the extension of the string; the velocity is unknown.\n\n$E_t = -\\left( mg(x+a) \\right) + \\left( \\frac 12 mv^2 \\right) + \\left( \\frac 12 \\lambda \\frac{x^2 }{a} \\right)$. That needs some tidying up: $E_t = mgx + mga + \\frac 12 mv^2 + \\frac 32 mg \\frac{x^2}{a}$\n\nBy conservation of energy, we have $E_0 = E_t$, so $\\frac 32 mga = -mgx - mga + \\frac 12 mv^2 + \\frac 32 mg \\frac{x^2}{a}$.\n\nIt\u2019s still a mess. Everything has a factor of $m$ we can get rid of, and it\u2019s probably good to multiply by 2 as well: $3ga = - 2gx - 2ga + v^2 + 3g \\frac{x^2}{a}$\n\nNow rearrange to get $v^2$ on its own: $v^2 = g\\left( 5a + 2x - 3\\frac{x^2}{a} \\right)$\n\nDifferentiate with respect to $x$ and you get $v \\diff vx = g\\left( 2 - 6\\frac{x}{a} \\right)$, which has its extremum when $2 - 6\\frac xa = 0$, or when $x = \\frac 13 a$.\n\nPutting this back into the $v^2$ equation, we get: $v^2 = g\\left( 5a + \\frac 23 a - \\frac{a}{3} \\right)$, or $v^2 = \\frac {16}{3} ga$. The maximum speed is $\\frac 43 \\sqrt {3ga}$.\n\nAs I say, there are alternative approaches: you can find the maximum speed by looking for the point where the net force is zero; you can model the freefall part of the travel with SUVAT and then use either energy or a differential equation; I\u2019m sure there are other approaches that didn\u2019t spring to my mind.\n\nI hope your particle is all right after its trauma!\n\n-- Uncle Colin"}
{"text": "Retrieved from https://mathoverflow.net/questions/360632/bounds-on-operatornamesgnau-operatornamesgnav-when-u-v-1-leq/360722\nText:\n$\\DeclareMathOperator\\sgn{sgn}$Suppose A is a $N \\times N$ Hermitian and unitary matrix, i.e., $A^{\\dagger}=A$ and $A^{\\dagger}A=I =AA^{\\dagger}$. (Assume all entries are real.)\n\nAnd let $u \\in \\{-1,1\\}^N$, $v \\in \\{-1,1\\}^N$.\n\nSuppose $\\|u- v\\|_1 \\leq \\epsilon N$ (i.e., $u$ and $v$ differ on $\\frac{\\epsilon}{2} N$ coordinates) .\n\nand $\\sgn: \\mathbb{R} \\rightarrow \\{-1,0,1\\}$ be the sign function, i.e., maps all negative numbers to $-1$, and positive numbers to $1$, and $0$ to $0$.\n\nI want a non-trivial upper bound on $$\\|\\sgn(Au)-\\sgn(Av)\\|_1$$ in terms of $\\epsilon$. For example, is it upper bounded by $4\\epsilon N$?\n\n  \u2022 1\n    $\\begingroup$ Since each place where $u$ and $v$ differ contributes 2 to their $\\operatorname L^1$-distance, I guess you want $\\|u - v\\| \\le 2\\epsilon N$, or that $u$ and $v$ differ in at most $\\frac1 2\\epsilon N$ places? $\\endgroup$ \u2013\u00a0LSpice May 18 '20 at 23:12\n  \u2022 $\\begingroup$ @Omnomnomnom, thanks for fixing my bone-headed error of including \\sgn in the subject. $\\endgroup$ \u2013\u00a0LSpice May 19 '20 at 1:24\n  \u2022 1\n    $\\begingroup$ @LSpice No problem. Anyway, Mathjax doesn't behave in an intuitive way. For instance, despite the fact that your command is only defined in the question body, it used to be the case that the command \\sgn would work in any answer-posts below your definition. $\\endgroup$ \u2013\u00a0Ben Grossmann May 19 '20 at 1:26\n\nThere is a straightforward bound.\n\nConsider A to be the $\\log(N)$-fold tensor product of $H= \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$.\n\nA is Unitary and Hermitian. In fact A is just the Fourier transform.\n\nSet $u$ to be all one vector, i.e. $u=(1, 1, 1, \\ldots , 1)^T$.\n\nAnd $v$ is all one vector with the first coordinate set to $-1$, i.e. $v=(-1, 1, 1, \\ldots , 1)^T$\n\nSee $Au =(1, 0 , 0 , \\ldots 0)^T$\n\nand $Av$ has non zero entries in all coordinates.\n\nThus, $\\|\\operatorname{sgn}(Au)-\\operatorname{sgn}(Av)\\|_1 \\geq N-1$.\n\nConclusion. No non-trivial bound.\n\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/103468/a-problem-on-lagrange-interpolation-polynomials/103520\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nBased on a previous question, I had the following conjecture and was wondering if anyone knew how to prove it or find a counterexample.\n\nConsider the polynomial $$ p(t)=c\\frac{(t-x_0)(t-x_1)\\cdots(t-x_n)}{(x-x_0)(x-x_1)\\cdots(x-x_n)}$$\n\nwhere $x_0,x_1,\\ldots,x_n$, and $x$ are distinct and all lie in the interval $[a,b]$, and $c\\neq 0$. The polynomial $p(t)$ is the lagrange interpolation polynomial of degree $n+1$ satisfying $p(x_i) = 0$ for $i=0,\\ldots,n$ and $p(x)=c$. Its $(n+1)$-th derivative is the constant $$p^{(n+1)}(t)=\\frac{c(n+1)!}{(x-x_0)(x-x_1)\\cdots(x-x_n)}$$\n\nConjecture: suppose $f(t)\\in C^{(n+1)}[a,b]$ and satisfies $f(x_i) = 0$ for $i=0,\\ldots,n$ and $f^{(n+1)}(t)>p^{(n+1)}(t)$ for all $t\\in [a,b]$ or $f^{(n+1)}(t)<p^{(n+1)}(t)$ for all $t\\in [a,b]$. Prove that $f(x) \\neq p(x)=c$.\n\nOr find a counter example to the conjecture\n\nshare|cite|improve this question\nup vote 0 down vote accepted\n\nThis is true. If $f(x)=p(x)$, then $f-p$ has $n+2$ distinct zeros, between which lie $n+1$ distinct zeros of $(f-p)'$, between which lie $n$ distinct zeros of $(f-p)''$, and so on, leading to a zero of $(f-p)^{(n+1)}$, contradicting the fact that $f^{(n+1)}\\lessgtr p^{(n+1)}$.\n\nNote that the proof uses neither the fact that $p$ is a polynomial, nor the fact that the function values are zero; it proves the more general fact that if two $C^n$ functions coincide at $n+1$ distinct points, their $n$-th derivatives must coincide at some point in between.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/285270/show-blockmatrix-is-invertible\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $B \\in \\mathbb{R}^{n \\times n}, C \\in \\mathbb{R}^{m \\times n}, m \\leq n$ and $\\operatorname{rank} C = m$\n\nSuppose for every $v \\neq 0$ with $Cv=0$ it is $v^TBv > 0$.\n\nShow: then $A = \\begin{pmatrix}B & C^T \\\\ C & 0 \\end{pmatrix}$ is invertible.\n\nClearly the columns of $\\begin{pmatrix}C^T \\\\ 0 \\end{pmatrix}$ are linearly independent, since $\\operatorname{rank} C = \\operatorname{rank} C^T$. (or somethin like $dim Im(C) = dim Ker(C^T)$ ?)\n\nThen the columns of $\\begin{pmatrix}B \\\\ C \\end{pmatrix}$ are linearly independent, since for every $v \\neq 0$ with $Cv=0$ it is $v^TBv > 0$ which already requires $Bv \\neq 0$ and therefore the kernel is trivial.\n\nBut how to conclude now that these first n columns are idependent from the other m columns and therefore that $A$ is invertible?\n\nshare|cite|improve this question\nA nice way to solve the exercise is to think as if $B$ and $C$ were numbers. How would you find the inverse in this case? Apply \"the same formula\" here. \u2013\u00a0Quimey Jan 23 '13 at 19:49\nWell, but wouldn't i need $B$ to be invertible for the first block? \u2013\u00a0fritz Jan 23 '13 at 19:53\nDon't really get somewhere trying to think about it this way.. \u2013\u00a0fritz Jan 23 '13 at 20:27\n\n$A$ is a square matrix, so invertibility is equivalent to the kernel being trivial. So what you can do is suppose that $v \\in \\mathbb{R}^{n + m}$ is nonzero, and show that $Av$ is nonzero. You can do this by breaking down $v = (v_1, v_2) \\in \\mathbb{R}^n \\oplus \\mathbb{R}^m$, in other words you analyze the problem by matrix multiplying $$ \\begin{bmatrix} B & C^T \\\\ C & 0 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}$$ It is also useful to know that since $\\mathrm{rank}(C) = m$, then the linear map $x \\mapsto Cx$ is onto, so then the linear map $y \\mapsto C^T y$ is one-to-one.\n\nEdit: Here is a more fleshed out solution. Consider the matrix product given above. If $v$ is nonzero, we will show that $Av$ is nonzero. Multiplying out the matrix product, we obtain $$ Av = \\begin{bmatrix} Bv_1 + C^T v_2 \\\\ Cv_1 \\end{bmatrix} $$ If $Cv_1 \\neq 0$, then we are done, so assume that $Cv_1 = 0$. Now, suppose that $v_1 = 0$. Then $v_2 \\neq 0$, in which case $Av = \\begin{bmatrix} C^T v_2 \\\\ 0 \\end{bmatrix}$. Since $y \\mapsto C^T y$ is a 1-1 linear map, then $C^T v_2 \\neq 0$, so then $Av \\neq 0$. Now, alternatively suppose that $v_1 \\neq 0$, but still $Cv_1 = 0$. Then, by the hypothesis, it must be that $v_1^T B v_1 > 0$. Therefore\n\n$$ v_1^T (Bv_1 + C^T v_2) = v_1^T Bv_1 + v_1^T C^T v_2 > v_1^T C^T v_2 = (v_2^T Cv_1)^T = 0,$$ where the last expression is $0$ since $Cv_1 = 0$. Thus the first entry in the vector is nonzero, and hence $Av \\neq 0$ in this case as well. Thus we have shown that $A$ has a trivial kernel, and hence is an invertible matrix.\n\nshare|cite|improve this answer\nThanks for this approach. I considered the following cases: a) $v=(v_1,0)$: so it's either $Cv_1=0$ but then it follows that $Bv_1 \\neq 0$ (since $v_1^TBv_1 > 0$) or it is already $Cv_1 \\neq 0$, done. b) $v=(0,v_2)$: since $y \\mapsto C^Ty$ is one-to-one it is clear that $C^Tv_2 \\neq 0$, done. c) $v=(v_1,v_2)$: ??? \u2013\u00a0fritz Jan 23 '13 at 21:15\nThere doesn't need to be a third case. The two cases are (1) $v_1$ is nonzero, and (2) $v_2$ is nonzero. These cases are not mutually exclusive; all we require is that $v = (v_1, v_2)$ is not zero, so at least one case holds. \u2013\u00a0Christopher A. Wong Jan 23 '13 at 21:17\nOkay, I screwed it up at this point. I focused on $Bv_1 + C^T v_2 = 0$ which I thought might be possible for $v_1$ with $Cv_1 = 0$ and therefore $Bv_1 \\neq 0$ and then thought about why $v_2$ can't be choosen in a way so that $Bv_1 = - C^T v_2$. It would be nice to resolve this mistake, when starting thinking like this? \u2013\u00a0fritz Jan 23 '13 at 21:23\nYes, you need to deal with this case. Perhaps in a short while I will post a more detailed solution. \u2013\u00a0Christopher A. Wong Jan 23 '13 at 21:27\nThanks a lot. Minor note: Am I right, that you actually can't conclude that the first entry in the vector is greater than zero but just that it is different from zero? $v_1^T(Bv_1 + C^Tv_2) > 0 \\not{\\implies} (Bv_1 + C^Tv_2) > 0$? \u2013\u00a0fritz Jan 24 '13 at 6:27\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/61042/bijection-between-sets-p-groups-and-conjugacy-classes\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $G$ be a finite group. We let $T_{G}$ denote the set of conjugacy classes of subgroups of $G$ and let $T$ denote a set of representatives of $T_{G}$.\n\nHow to establish a bijection between the following sets:\n\n$\\{H \\in T: O^{p}(H)=H\\}$ and $\\{S \\in T: [N_{G}(S): S] \\textrm{is not divisible by p} \\}$.\n\nHere $N_{G}(S)$ means the normalizer of $S$ in $G$ and $O^{p}(H)$ the smallest normal subgroup of $H$ such that $H/O^{p}(H)$ is a $p$-group.\n\nshare|cite|improve this question\nWhat's $O^p(O^p(S))$ ? \u2013\u00a0user641 Aug 31 '11 at 23:35\nNotice that for the set on the right hand side, $N_G(O^p(S))$ contains $N_G(S)$; what does $S$ map to in $N_G(O^p(S))/O^p(S)$? \u2013\u00a0user641 Aug 31 '11 at 23:38\n@Steve D: I don't understand your last line. Can you please explain? \u2013\u00a0user6495 Sep 1 '11 at 0:16\nAbout what $S$ maps to? Have you thought about it? What do we know about $S/O^p(S)$? \u2013\u00a0user641 Sep 1 '11 at 0:34\nIf you'd prefer, I could also post a full answer - but where's the fun in that? \u2013\u00a0user641 Sep 1 '11 at 0:36\nup vote 1 down vote accepted\n\nLet $A=\\{H\\in T\\ |\\ O^p(H)=H\\}$ and $B=\\{S\\in T\\ |\\ p\\nmid [N_G(S):S]\\ \\}$. We need to define two maps $\\phi:A\\rightarrow B$ and $\\psi:B\\rightarrow A$, which are both well-defined up to conjugacy, and are inverses of one another.\n\nThe map from $B$ to $A$ is easier to describe: $\\psi(S)=O^p(S)$. Note that $O^p(O^p(S))=O^p(S)$, so $\\psi(S)\\in A$. Since $O^p(S)^g=O^p(S^g)$, this map is well-defined.\n\nTo define $\\phi(H)$, choose a subgroup $K$, with $H\\le K\\le N_G(H)$, such that $K/H$ is a Sylow p-subgroup of $N_G(H)/H$. Let $\\phi(H)=K$. Since $N_G(H)^g=N_G(H^g)$, and Sylows are conjugate, this map is well-defined. Moreover, since $K/H$ is a p-group, $O^p(K)\\subset H$, and thus $O^p(K)=H$ since $H\\in A$. Thus $N_G(K)\\subset N_G(H)$, and since $p\\nmid [N_G(H):K]$, certainly $p\\nmid [N_G(K):K]$. Thus $\\phi(H)\\in B$.\n\nFrom what was said above, we see that $O^p(\\phi(H))=H$, so that $\\psi\\phi(H)=H$.\n\nIn the other direction, since $O^p(S)$ is characteristic in $S$, we have $N_G(S)\\subset N_G(O^p(S))$. Now $S/O^p(S)$ is a p-subgroup of $N_G(O^p(S))/O^p(S)$, and since \"normalizers grow\" in p-groups, yet $S\\in B$, $S/O^p(S)$ must be a Sylow p-subgroup of $N_G(O^p(S))/O^p(S)$. Thus $\\phi(\\psi(S))=\\phi(O^p(S))=S$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64017/eigenvalues-of-laplacian-beltrami-operator/84983\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI am interested in the first non zero eigenvalue of the Laplace-Beltrami operator in a 2D compact manifold, and if there is a geometric characterization of its value.\n\nI am interested in the case when you fix the volume of the manifold to some value (say $Vol = 1$), and let the other modes of the metric fluctuate. The average curvature of the manifold is imposed by the Gauss-Bonet theorem, but can let the curvature to fluctuate from one point to another.\n\nMy intuition says that the first non zero eigenvalue should approach 0 in the limit when the \"fluctuations of the curvature\" grow, but I can not give a precise meaning to this statement.\n\nso the question is: Is there any characterization of the first eigenvalue(s) of the Laplace-Beltrami operator in a 2D compact riemann manifold as functions of the curvature or its powers (i.g. $\\int R^2 \\sqrt{g} d^2x$).\n\nSo let me be more specific. Imagine a manifold topologically equivalent to a Torus. The metric can be written as\n\n\nand the scalar curvature\n\n$R=\u22122\\Delta \\log(f)$\n\nFor the case $f=cte$ we have a flat torus. Now expanding f as a fourier series we will have some regions of the torus with poritive curvature and some regions with negative curvature (this invalid some known theorems, that need wither the curvature to be always positive or always negative). Gauss bonnet says that:\n\n$\\int R=0$\n\nSo the concrete question is: Is there a characterisation of the first eigenvalue of the Laplace operator in terms of $\\int R^2$?\n\nshare|cite|improve this question\nup vote 8 down vote accepted\n\nThe first eigenvalue of a compact surface can be made arbitrarily small (even for surfaces of fixed genus); see, for example, [1], [2], [3] (and references therefrom).\n\nHowever, as proved by Sarnak and Xue [4], there are arithmetic examples of (constant negative curvature) compact Riemann surfaces of arbitrarily high genus with the first eigenvalue bounded away from zero (see also [5] for a construction involving Selberg's $3/16$'' theorem).\n\n[1] B. Randol, Small eigenvalues of Laplace operator on compact Riemann surfaces, Bull. AMS 80, 1974 996-1008\n\n[2] R. Schoen, S. Wolpert, S. Yau, Geometric bounds on the low eigenvalues of a compact surface, Proc. Symp. Pure Math, vol. 36, AMS, 1980, 279-285.\n\n[3] P. Buser, On Cheeger\u2019s inequality $\u03bb_1 \u2265 \\frac{h^2}{4}$. Proc. Symp. Pure. Math. vol. 36, 29\u201377.\n\n[4] P. Sarnak and X. Xue, Bounds for multiplicites of automorphic representations, Duke Math J. 64, 1991, 207-227.\n\n[5] R. Brooks, E. Makover, Riemann surfaces with large first eigenvalue. J. Anal. Math. 83, 2001, 243\u2013258.\n\nshare|cite|improve this answer\n\nYes, This is a classical result due to Lichnerowicz. If the Ricci tensor of a compact Riemannian manifold, is such that $Ric \\geq kg$ for some k > 0, then $\\lambda_1 \\geq \\frac{nk}{n - 1}$. In Your case, you just replace the Ricci curvature by $Kg$. You will find a proof in the book of Aubin A Course in Differential Geometry as consequence of the Bochner Formula.\n\nshare|cite|improve this answer\nThis inequality is false: there are closed hyperbolic surfaces (constant curvature $=-1$) for which $\\lambda_1$ is arbitrarily small. \u2013\u00a0Ian Agol Jun 22 '11 at 1:51\nThe inequality only applies to manifolds of positive curvature. \u2013\u00a0Nate Eldredge Jan 6 '12 at 2:41\n\nYour intuition seems correct: assume that some part of your surface contains a long cylinder with a flat metric. Take a test-function on the surface, supported on that cylinder, equal to +1 roughly on one half of the cylinder and -1 on the other half, and of total integral 0. In this case, the $L^2$-norm of the gradient of your function will be very small compared to the $L^2$-norm of the function. By the variational characterization of the first eigenvalue of the Laplacian (= Rayleigh quotient), you can make the first eigenvalue very small.\n\nshare|cite|improve this answer\n\nThis is a challenging problem. The precise meaning of randomness of the metric ought to play a role. I cannot think of a natural one in a general case but I suggest you consider first the case of the two-torus $T^2$ equipped with a metric of the form\n\n$$ g = e^{2 u} d\\theta_1^2+ e^{2v} d\\theta_2^2 $$\n\nwhere $u,v: T^2\\to\\mathbb{R} $ are independent random functions. Here you need to specify the nature of the randomness of $u$ and $v$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/69813/residency-time-of-a-spherical-brownian-particle-in-a-cylindrical-container-with\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI place two spherical particles, $P_1$ and $P_2$ (with radii $r_1$ & $r_2$), into a cylindrical container of radius $r_c$ ($r_1$ & $r_2$ $\\leq \\frac{1}{2}r_c$) and height $h$. While $P_1$ is immobilized at the centerpoint of the cylindrical container, $P_2$ has a coefficient of diffusion $D$, and can freely diffuse throughout the container and across its walls (i.e. the boundaries of the cylindrical container are non-reflecting).\n\nWe randomly position $P_1$ and $P_2$ somewhere inside the cylindrical container. Can we derive an expression for the mean residency time of $P_2$ as a function of the relative sizes of the particles and the cylindrical container? Is it a fair approximation to simply estimate the residency time of $P_2$ in a cylindrical container resized to subtract the volume of $P_1$?\n\nUpdate - $P_1$ is now fixed at the centerpoint of the cylindrical container, and $r_1$ & $r_2$ are defined to be $\\leq \\frac{1}{2}r_c$, s.t. $P_1$ cannot block access, say, to half the cylindrical container.\n\nUpdate 2 - In practice, $r_1$, $r_2$, and $r_c$ will be within one or two orders of magnitude of one another, i.e. it is not the case that $r_1$ & $r_2$ $<< \\frac{1}{2}r_c$). Also, all collisions between particles, like the walls of the container, are fully reflecting.\n\nUpdate 3 - I'd be perfectly happy calling the cylindrical container a \"spherical container\" with the same radius, $r_c$. Similarly, I'd be happy to not pin $P_1$ at any particular point, and instead to simply make the walls of the sphere reflecting specifically for this particle.\n\nshare|cite|improve this question\nYou haven't said anything about the relative sizes of the particles and the cylindrical container. Clearly, in one extreme case (P1's radius is as large as the radius of the cylinder so it completely blocks access to part of the cylinder) P1 matters. Just as clearly, P1 doesn't matter in the other extreme case (e.g. the cylinder has a diameter measured in light years and P1 and P2 are the size of small molecules.) You need to tell us something more about what you're actually trying to model... \u2013\u00a0Brian Borchers Jul 8 '11 at 18:21\n@Brian, you're absolutely right. Hopefully the added clarifications will better address your concerns. \u2013\u00a0Rob Grey Jul 8 '11 at 19:56\nNot really. If r_1 and r_2 are far smaller than r_c, then the additional particle shouldn't have any significant effect on the escape time. The problem only becomes interesting if r_1 is big enough. You also haven't told us what happens if particle 1 and particle 2 interact with each other. Does particle 2 just bounce off particle 1? \u2013\u00a0Brian Borchers Jul 8 '11 at 23:28\nRob, there's an hour to go on this bounty, and one answer which is very reasonable. Is there a problem with the answer? \u2013\u00a0Nilima Nigam Jul 20 '11 at 1:23\nup vote 3 down vote accepted\n\nYou can use the Feynman-Kac formula to get the Moment Generating Function of the time it takes the particle to leave.\n\nI will consider the case where you fix $P_1$ and let $P_2$ move. Whatever the geometry of your problem, you can get an equivalent problem with a point particle diffusing in some region in space, where there is one wall that it reflects off (let's call it $\\Gamma_0$) and another where it is absorbed (let's call it $\\Gamma_1$.) Let $X(t)$ be the position of the particle at time $t$. Let $T$ be the time at which the process first hits $\\Gamma_1$. Let $f(x,\\lambda) =E [ e^{\\lambda T} | X(0)=x]$. Then Feynman-Kac gives you that $f$ satisfies $\\nabla^2 f/2 + \\lambda f =0$ with $\\frac{\\partial f}{\\partial n} = 0$ on $\\Gamma_0$ and $f=1$ on $\\Gamma_1$. This is the Helmholtz equation on your domain with mixed boundary conditions. $f(x,\\lambda)$ is the moment generating function of $T$ with $X(t)=x$, evaluated at $\\lambda$. So now you can compute the mean of $T$, etc.\n\nOne geometry for your problem for which you can get an exact solution for each $\\lambda$ is if you have one sphere fixed at the middle of the big sphere and you are tracking a point particle that diffuses, bounces off the small sphere and is absorbed by the big sphere. In that case the solutions to the PDE are spherical Bessel functions.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inertial-problem-is-the-helicopter-still-moving-with-the-speed-of-the-rotating-earth.50285/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nInertial problem:is the helicopter still moving with the speed of the rotating earth?\n\n  1. Oct 29, 2004 #1\n    a helicopter flies up straightly perpendicular to an \"X\" marked on a floor. then, the helicopter keep static in the air when it has reached 10m from the floor. after 5 hours, will the \"X\" still remain right on the floor below the helicopter?\n  2. jcsd\n  3. Oct 29, 2004 #2\n\n\n    User Avatar\n    Science Advisor\n\n    What could make it otherwise?\n    Reilly Atkinson\n  4. Oct 29, 2004 #3\n    actually, my point is that will the X \"moves\" away as the earth is rotating after 5 hours?\n    for example, the earth is rotating with the speed 1km/s(just an example coz i dunno what's the actual speed). will the helicopter remain the speed of 1km/s in the direction of the rotation of the earth while it's floating staticly on the sky. it's because newton's nertial law tells us that the objects inside the same reference frame will have the same speed with the reference frame if no other force is applied to the objects inside. in my question before, the earth is the reference frame and it's moving in the speed of 1km/s and the helicopter is the object inside the reference frame. so, is the helicopter still have the same speed with the earth, which is 1km/s, after 5 hours? if yes, the X will remain 90 degree below of the helicopter.\n  5. Oct 29, 2004 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    that's funny...\n\n    If Newton's law would not apply,it would be a great problem (actaully a fatal one) for those athletes in the high jump discipline.They would definitely be crushed by the stadium approaching them at 465 m/s (at the equator)... :rofl: That's the first example that crossed my mind.Other even more sadistic could be imagined.\n  6. Oct 29, 2004 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I think it was Isaac Asimov that wrote a short story about a scientist, who was very smart but very poor, that found a way to bring any object to a complete stop instantaneously. A rival scientist, less smart, but more famous and rich, publicly ridiculed the poor scientist's theory. The two scientists often challenged each other to billiards, so the poor scientist invited the famous scientist to a demonstration of the first operational 'anti-momentum machine'. The poor scientist demonstrated how his anti-momentum machine worked by shooting a pool ball into the anti-momentum field.\n\n    If you add the rotation of the Earth, the Earth's motion around the Sun, the Solar System's motion about the center of the Milky Way, the Milky Way's motion, etc., etc., it's amazing how fast all those velocities add up.\n\n    I liked that story almost as much his story about the poor soccer referee who made a bad game deciding call against the home team. 100,000 mirror weilding fans focusing their ire into one united effort can really make a referee's blood boil. I referee soccer and always use that story to comfort comrades who've just endured the fury of a critical blown call.\n  7. Oct 29, 2004 #6\n    Let's examine two cases :\n\n    1. As the helicopter gains in altitude, it keeps its inertia in the horizontal direction, as does the air which supports it, so if he is above the equator, would stay right a top the x. (Of course, the pilot has to have the x as a reference over which to fly, but what I mean is that he will not have to make corrections if he is near the equator. I believe \"near the equator\" includes most of the industrial world : up to 60 or 70 degrees in latitude.)\n\n    2. If he is flying above the north pole, he will have to yaw, because the earth and atmosphere will tend to spin under and around him.\n\n    So if he is \"near\" the north pole, then yes, the pilot will have to make corrections to stay over the x. The perceived force is exactly what is called the Coriolis effect and is entirely compatible with all that Newton has to say. The amount of corrections depends on the helicopter's horizontal speed and latitude (+ distance and time of travel), and it does have to be accounted for in self-guided systems or by visual pilots (perhaps unkowingly when flying visual). Even some advanced training simulators (for helicopters and planes) take it into account.\n    Last edited by a moderator: Oct 29, 2004\n  8. Oct 29, 2004 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The helicopter did not maintain a constant speed. It accelerated in order to raise it's height. Even if it is only pushing in a radial direction (directly away from the center of the Earth), the atmosphere is pushing in the direction of the Earth's rotation and giving the helicopter some tangential acceleration.\n\n    However, if the Earth were a vacuum, a push strictly in the radial direction with no tangential component would cause the object to fall behind the Earth's rotation. You add energy, you increase the size of an object's orbit, regardless of how you add the energy - in other words, if a geosysnchronous satellite is accelerated in the same direction of the Earth's rotation instead of radially, it will still increase the size of the orbit and its angular velocity will still fall behind the Earth's angular velocity.\n  9. Oct 29, 2004 #8\n    There is however an initial tangential component of speed, whether atmosphere or vacuum. It is the reason for 2D-directionnal symmetry in our daily lives (high jump, golf etc.).\n  10. Oct 30, 2004 #9\n    if the helicopter is not flying in the vacuum, the air or the wind will become the friction forces to the helicopter. then, the inertial tangential component of the helicopter would be effected by these frictions. with this reason, i suppose that the pilot would see the X \"moving\" away slowly from the below of his helicopter.\n\nHave something to add?\n\nSimilar Discussions: Inertial problem:is the helicopter still moving with the speed of the rotating earth?\n  1. Helicopter's rotation (Replies: 6)\n\n  2. Rotation of earth (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inverse-of-upper-triangular-matrix.206915/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nInverse of Upper Triangular Matrix\n\n  1. Jan 2, 2008 #1\n    Does anyone know a formula to find the inverse of an upper triangular matrix of dimension n (with a reference preferred)?\n  2. jcsd\n  3. Jan 2, 2008 #2\n    isn't row reduction how you find inverses? as in augment the matrix with the correspondent identity matrix and row reduce\n  4. Jan 2, 2008 #3\n    Yes, I understand. However, I am trying to find a general formula for upper triangular matrices. Something along the lines of the inverse formula for 2x2 matrices. I remember my linear algebra teacher telling us that formulas like that exist for higher dimension matrices.\n  5. Jan 2, 2008 #4\n    Do you remember the analytic formula for the inverse of a matrix from that linear algebra class? Note that the determinant of an upper triangular matrix is just the product of the diagonal components (which are the eigenvalues of the matrix). The cofactors are either 0 or signed determinants of smaller upper triangular matrices.\n  6. Jun 18, 2009 #5\n    For those of you, like me, that just want the answer... here it is (Slider142, please read the item at the bottom re: cofactors and why that doesn't work in this case, sorry):\n\n    My full problem was as follows:\n\n    Given a set of observations and a fixed start-point - in this case acoustic ranges, magnetic and true bearings and some angles, from a ship at sea to towed cables behind it - solve the position in x and y of all other nodes in a network down the length of those cables. For those familiar with surveying, it's a classic triangulation network, using the variation of co-ordinates method of least squares.\n\n    Underlying this is the fact that this network is VERY large, needs to be solved millions of times during a survey and at a minimum, once every few seconds as a boat moves forward acquiring data in real time. There are more than 10,000 observations and more than 1500 nodes to solve.\n\n    I firstly designed a Normal Matrix, A (for those interested 'A' is actually C'WC where C is a design matrix of observations).\n\n    Then, having obtained 'A' I formed 'b' - a simple vector (again, for those interested, 'b' is actually A'Wb where this 2nd 'b' is just the observed minus computed observations for the current estimate of node positions)\n\n    What I need is x, in Ax=b, where x is a vector of the corrections I need to make to positions of the nodes from their currently estimated position.\n\n    Having found x, I will then correct the node positions by this amount, go back to the beginning and re-iterate until such time as the node positions are not changing.\n\n    Now, and here's the rub - no observation is ever perfect, and eliminating 'bad' or unacceptaby bad observations requires a solution to the inverse of A to be found and used.\n\n\n    (again, for those interested, I need a solution of C.A^-1.C', to work out the normalised residuals, or w statistic, and eliminate the worst offender from the network and re-solve)\n\n    In summary:\n\n    I needed the least squares solution of a system Ax=b AND the inverse of the Sparse, positive Definite, symmetric Matrix, A, to enable data snooping using the w-test, which can only be done by multiplying items by the inverse of A. I then need to eliminate bad data and re-compute the network from the beginning. That's the problem. Within the solution I'll need to compute the inverse of a triangular matrix.\n\n    My solution\n    Start with an initial approximation of the node positions, and set x to zero.\n\n    1. Firstly, compute A - which is sparse, positive definite and symmetric - and store it. Computing and storing it is most efficiently achieved by using CSR (Compressed Sparse Row) format - essentially only storing non-zero values and indexes instead of the whole matrix.\n\n    2. Compute b - store this as a vector.\n\n    3. Apply a matrix row re-ordering algorithm to minimise the work required in the next step, Cholesky decomposition. I used Banker's algorithm for this - generally recognised as being better than Reverse Cuthill-McKee (RCM)\n\n    4. Decompose A, using Cholesky decomposition - but store the result as a simple vector of values of a triangular matrix, including zeros. This is because in computing the Cholesky decomposition the same structure as the original matrix is not preserved and so a large amount of manipulation and data 'insertion' (which is time consuming) can be avoided simply by storing it as a simple vector.\n\n    5. Take the matrix stored as a vector in 4 and put it into CSR format for the next step.\n\n    6. Use Forward and Backward Substitution to solve for x, using CSR format thoughout and storing the result, x, as a simple vector. It is important to use CSR format for this, otherwise it becomes very time consuming.\n\n    7. Having solved for x, apply the corrections to node positions and go back to the beginning, using these updated positions for all nodes as the new estimate of position and put x back to zero.\n\n    8. When no further useful changes in position are occurring - or the solution has converged - then the work starts... we now need to assess an estimate of the error from each observation. the w-statistic needs to be computed.\n\n    this is where The inverse is needed - we compute it using the latest value of the Cholesky factor, determined above - let's call it L - which is Triangular.\n\n    The inverse of A is the inverse of L (call it Li) multiplied by it's own transpose, Li.Li'\n\n    Here's where the inverse of a triangular matrix comes in, as L is triangular - but I simply don't have the time to do a naive solution - I need the fastest available because my L is over 1500 rows and may be up to 3000 rows long.\n\n    So, store L as CSR format and use the fact that ONE VECTOR (one column) of the inverse can be computed from FORWARD SUBSTITUTION as follows:\n\n    Let L.Li = I where I is one vector of the identity matrix...\n\n    (Any Matrix, times it's own inverse, is the identity matrix...)\n\n    For One vector of Li, use forward substitution to solve L x Li = [1,0,0,0,0...0] - Store the resulting vector as the 1st column of Li...\n\n    Then use the next vector, [0,1,0,0,0,0....0], and the next [0,0,1,0,0,0,0....0] and so on, building up a solution to Li column by column.\n\n    The use of CSR format in this is vital to keep the computation time to a minimum.\n\n    This works because forward substitution, when using CSR format on a sparse matrix, is very fast.\n\n    et voila, we have the Inverse of a triangular matrix using the minimum possible flops (or at least I believe it to be the minimum possible... ANYONE who knows a faster way, PLEASE, PLEASE, PLEASE let me know!!\n\n    The next problem, for me, is to compute Li.Li' - ie. a Triangular x it's own transpose in the minimum possible time, ie. the minimum number of flops.\n\n    This seemingly trivial, final operation, actually takes more time than the entire of the solution above when the matrix is large (which it always is.)\n\n    One final thing, for those interested - if you are wondering why I didn't use Conjugate Gradients for the least squares solution... it's because although that IS faster than cholesky decomposition, it is numerically unstable when computing the inverse as a sum of it's components - rounding error really kills it. Otherwise it would be beautiful, and quick. if anyone knows a way of stabilising CG, please let me know!\n\n    Well, that's it - I genuinely hope to have been of use to someone out there... it's taken me quite a while to hammer out the method above. Unlike many of you, I'm not a student or professor - just a guy trying to do a job in the real world. So please, if it is useful or if you see something I missed, or a way of improving it, please DO let me know.\n\n\n    Mike Li, from New Zealand.\n\n  7. Jun 18, 2009 #6\n    Sorry Slider142 - got carried away and forgot to say why cofactors don't work quite as simply as you suggest here...\n\n    When you form the cofactor by eliminating a row/column, some of the resulting matricies are not triangular any more - which means the determinant needs to be found of a full matrix, not a simple triangular one. For the others you're right, they're either 0 or the product of the diagonals.\n\n    That makes the solution a whole lot more complex... consequently it's quicker and easier to use forward substitution to find the inverse of a matrix, one vector at a time from L.Li = I where L is a triangular matrix and Li is 1 vector of it's inverse and I is one vector from the identity matrix.\n\n\n    Mike Li.\n\nHave something to add?\n\nSimilar Discussions: Inverse of Upper Triangular Matrix"}
{"text": "Retrieved from https://www.physicsforums.com/threads/multiple-percentages-probability.134225/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nMultiple Percentages Probability\n\n  1. Sep 30, 2006 #1\n    Hi, I seem to be having problems calculating this out. My friends were asking me how to caculate multiple precentages and I thought it would be easy but I got a little stuck. Here is the problem.\n\n    Lets say there is a program that spits out the words yes and no. 60% chance it says yes and 40% chance it says no. If I hit it once, there is a 60% chance it says yes and a 40% chance it says no. If I click it 7 times and it says yes 6 times, what are the odds? I put .6^6 to calculate it, but it seems that I don't include the fact that it says no once. Also, what would the odds be if it said yes all 7 times or no all 7 times? How would you calculate these percentages?\n\n    Thanks alot, seems like a great forum so far.\n  2. jcsd\n  3. Sep 30, 2006 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You're looking for what's called the binomial distribution.\n\n    The odds of exactly 6 out 7 \"yes\" is (7 choose 6) * 0.6^6 * 0.4 ^ 1. Let me explain. You are getting 6 \"yes\" and 1 \"no\"; the chances of getting those answers []in that order[/i] is 0.6^6 * 0.4 ^ 1. Since you don't care about the order, you need to multiply this by the number of ways to choose 6 elements out of 7. In general, (x choose y) is\n\n\n    For (7 choose 6), that's 7!/(6! * 1!) = 7, giving a total probability of [itex]7\\cdot0.6^6\\cdot0.4^1[/itex].\n  4. Sep 30, 2006 #3\n    Thanks so much\n    I cant believe someone actually solved this for me in such a clear manner.\n    This forum is great!\n  5. Sep 30, 2006 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'm glad to have helped. o:)\n\nHave something to add?\n\nSimilar Discussions: Multiple Percentages Probability\n  1. Percentage help (Replies: 7)\n\n  2. Multiple Percentages (Replies: 2)\n\n  3. Percentage reduction (Replies: 10)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-f-x-equation.158367/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple f(x) equation\n\n  1. Feb 27, 2007 #1\n    Given f(x) = x^2. Graph f(2x)\n\n    2. Relevant equations\n\n    I just need to draw the graph\n\n    3. The attempt at a solution\n\n    What I tried was putting the x value in the equation which would give me the y value by means of the x^2 part, and the x value would double to give me my new point. This wasn't what the answer key had. Any tips?\n  2. jcsd\n  3. Feb 27, 2007 #2\n    When you are asked to find f(2x), you need to substitute 2x as a whole for the original x. Will the value of f(x) really double?\n  4. Feb 27, 2007 #3\n    it becomes f(2x) = (2x)^2\n  5. Feb 27, 2007 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    There are two ways to do this. The simplest is to do what theperthvan (and, indirectly, Tedjn) suggests: replace x by 2x. What is (2x)2?\n\n    The other is to argue that any change before the \"main\" function, x2, is applied is a change in x and so changes the graph only horizontally. The value x= 1, after multiplying by 2, becomes the same as x= 2. But 1 is only 1/2 as far from the origin as 2: the whole graph of y= x2 is \"squeezed\" by 1/2 horizontally but not changed vertically.\n\nHave something to add?\n\nSimilar Discussions: Simple f(x) equation\n  1. F(x) and 1/f(x) (Replies: 11)"}
{"text": "Retrieved from http://mathinsight.org/penicillin_clearance_model\nText:\nMath Insight\n\nConstructing a mathematical model for penicillin clearance\n\nIn developing a model of bacteria growth, we detailed every step of building the model from the data. Since we assumed the change in the population size in one time step was a linear function of the population size, the model was so simple that we could even solve it. We ended up with a fairly simple expression showing the exponential growth of the population size.\n\nHere we'll examine a situation that seems completely different. We'll look at what happens when we give a patient a bolus injection (a one-time injection) of penicillin. In this case, of course, the penicillin won't start multiplying like bacteria in the patient. Instead, the body (i.e., the kidneys) will start removing the penicillin from the body. However, if we make a model where the amount of penicillin removed is a linear function of the amount penicillin in the blood, the model is starting to look a lot like the bacteria growth model. In fact, we'll get exponential decay of the amount of penicillin in the blood.\n\nThere's one more big difference between the bacteria growth example and this page. Here, we'll just get you started on the process, giving you background information about the drug clearance. We then let you go make the model on your own.\n\n\nWhen penicillin was first discovered, its usefulness was limited by the efficiency with which the kidney eliminates penicillin from the blood plasma (blood minus blood cells) passing through it. The modifications that have been made to penicillin (leading to amphicillin, moxicillin, mezlocillin, etc.) have enhanced its ability to cross membranes and reach targeted infections and reduced the rate at which the kidney clears the plasma of penicillin.\n\nEven with these improvements in penicillin, the kidneys can still remove penicillin fairly rapidly. In this project, you will build a mathematical model of penicillin clearance based on an assumption of how the kidneys operate. The secret to your success will be to build into the model a key parameter that captures the speed of the penicillin clearance. Then, you can estimate the model parameter by fitting predictions of the model to data. Lastly, you will compare your model predictions to the data to see how well the model matches the data.\n\nThe assumption behind the model is that the amount of penicillin removed by the kidneys in a five minute interval is proportional to the total amount of penicillin. We can formulate this assumption as a word model for the renal (i.e., kidney) clearance of penicillin.\n\nRenal clearance of penicillin\n\nIn each five minute interval following penicillin injection, the kidneys remove a fixed fraction of the penicillin that was in the plasma at the beginning of the five minute interval.\n\nYour goal is to translate this word model into a mathematical model that has a parameter that determines how much penicillin the kidneys remove in each interval. You can then use the below data to determine this parameter.\n\nThe following table and graph contain data for serum penicillin concentrations at 5 minute intervals for the 20 minutes following a bolus injection (a one-time injection) of 2 g into the serum of \u201cfive healthy young volunteers\u201d (read \u201cmedical students\u201d) taken from T. Bergans, Penicillins, in Antibiotics and Chemotherapy, Vol 25, H. Sch\u00f8onfeld, Ed., S. Karger, Basel, New York, 1978. We are interpreting serum in this case to be plasma.\n\nTime (min)Penicillin Concentration (\u03bcg/ml)\nPenicillin concentration versus time\n\nYour turn\n\nNow its your turn to develop a mathematical model of penicillin clearance. You can use a procedure similar to the one we used to developed the model of bacteria growth. Your model should be based on\n\n  \u2022 the above data, and\n  \u2022 the assumption that the drop in penicillin concentration each 5 minutes will depend linearly on the concentration.\n\nIf all goes well, you should be able to create a model that has an unknown parameter, fit the model to determine that parameter from the data, and then compare your model prediction to the data to see how well you did.\n\nWhen you are all finished, you can compare your results to some findings from the research literature. Analysis of some numbers from the research literature seems to indicate that the all of the blood plasma of a human passes through the kidneys every 5 minutes and that the kidneys remove about 20% of the penicillin in the blood that passes through them.1 You can determine if your analysis of the above data yields a result close to that rate of clearance.\n\nInstructions from writing up the penicillin project are here.\n\nFor more practice on building dynamical system models, try out the exercises."}
{"text": "Retrieved from http://math.stackexchange.com/questions/93808/what-is-the-smallest-convex-set-includes-all-smooth-unit-curves\nText:\nTake the 2-minute tour \u00d7\n\nI try to understand: is there a smallest in area convex set that every smooth curve with length 1 can be placed inside it by translation and rotation?\n\nI only have a upper bound $S \\leq \\frac14+\\frac{\\pi}{16}$ because of convex hull of two circles radius $\\frac14$ and simple lower bound $S\\geq\\frac1{4\\pi}$.\n\nDoes this set exist and what is its length?\n\nshare|improve this question\nIs your question the same as this one on MathOverflow? Smallest area shape that covers all unit length curve \u2013\u00a0 Rahul Dec 24 '11 at 3:19\nOh, I've searched here, not on the MathOverflow because this problem looks so pretty simple. Thx. \u2013\u00a0 sas Dec 24 '11 at 4:33\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nThis is entry D18, \"The worm problem,\" in the book Unsolved Problems in Geometry (Croft, Falconer, and Guy, 1991):\n\nLeo Moser asked what are the minimal comfortable living quarters for a \"unit worm\"?\n\nThey credit the smallest cover yet discovered to Gerriets & Poole (in 1973 or 1974), and describe it as a \"certain truncated rhombus of area less than $0.286$...\". Maybe someone will have a link or reference to the particular shape? For your bounds, I would only point out that the convex hull of a semicircle of arclength $1$, with radius $1/\\pi$ and area $1/(2\\pi)$, gives a better lower bound (of $0.159...$).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/190053/field-extension-question-basis-cannot-be-expressed-as-linear-combination\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I have a field extension K of F with basis $\\{1,\\beta\\}$, $\\beta\\in K^*/F^*$.\n\nHow do I show that $\\beta^2$ cannot be written as $c_1+c_2\\beta$, where $c_1,c_2\\in F, c_2\\ne 0$ unless $\\beta^2 \\in F^*$?\n\nFor example, if $K=\\mathbb{Q}(\\sqrt 2)$, $F=\\mathbb{Q}$, I would want to show that $2$ cannot be written as $c_1 +c_2 \\sqrt{2}$, where $c_i \\in \\mathbb{Q}, c_2\\ne 0$, unless 2 is in $\\mathbb{Q^*}$, which it is. This follows by arguing that $\\sqrt{2}$ is irrational, but how do I do it in the more general setting as in above?\n\nSincere thanks for help.\n\nshare|improve this question\nBut 2 is $2+0\\sqrt{2}$. Take $c_1=2,c_2=0$. \u2013\u00a0 Sigur Sep 2 '12 at 15:27\nIf $\\{1,\\beta\\}$ is a basis for $K$ over $F$ then every element of $K$ can be written as $c_1+c_2\\beta$ where $c_1,c_2 \\in F$ in particular $\\beta^n$. \u2013\u00a0 JSchlather Sep 2 '12 at 15:29\n@Sigur That was fast! I edited my question above. \u2013\u00a0 yoyostein Sep 2 '12 at 15:29\n@JacobSchlather Thanks (+1), but I just added a new condition that $c_2\\ne 0$. \u2013\u00a0 yoyostein Sep 2 '12 at 15:32\nThe intended question seems to be muddled. If $\\{1, \\beta\\}$ are an $F$-basis of $K$, then necessarily $\\beta^2$ can be written (uniquely) as $c_1+c_2\\beta$ with $c_1, c_2\\in F$. Then $X^2-c_2 X - c_1$ is the minimal poylnomial of $\\beta$. As it is irreducible, we conclude that is $c_1=0$ is impossible. However, $c_2=0$ is equivalent to $\\beta^2=c_1\\in F$. \u2013\u00a0 Hagen von Eitzen Sep 2 '12 at 17:14\n\n1 Answer 1\n\nThis is still false. Let $F=\\mathbb{Q}$, $K=F(\\sqrt{2})$ and $\\beta=1+\\sqrt2$. Then $$ \\beta^2=1+2\\sqrt2+2=3+2\\sqrt2=1+2\\beta. $$ Here $c_2=2\\neq0$ as requested, but $\\beta^2\\notin F$.\n\nIs this really what you wanted to ask?\n\nshare|improve this answer\nOk. This is what the OP really wanted to ask. \u2013\u00a0 Jyrki Lahtonen Sep 3 '12 at 5:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/9277/minimum-for-this-function?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI thought of writing this question Minimum for this function in a different way, if it helps.\n\nI want to minimize $$\\sum_{i=1}^n a_ix_i + \\nu \\sum_{i=1}^n b_i 2^{x_i} ,$$\nwhere $a_i \\in [0,1]$, $b_i \\in (0,\\infty)$, and $x_i \\in [x_{\\min},0)$, and\n$$ \\sum_{i=1}^n 2^{x_i} = 1 .$$\n\n$x_{\\min}$, $\\nu$, $a_i$ and $b_i$ are constants.\n\nI guess the tricky part is to minimize the function while ensuring all $2^{x_i}$ sum up to $1$ for these $n$ variables.\n\nThank you for your patience and help.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nFirst let $x = (x_1, \\dots, x_n)$ and write $f(x) = \\sum_i^n a_i x_i + \\nu\\sum_i^n b_i 2^{x_i}$ and $g(x) = \\sum_i^n 2^{x_i} - 1$. Now the method of Lagrange's multipliers tells you that you have a solution $x'$ iff it is an extremal point of the function $f(x) + \\lambda g(x)$ with $\\lambda$ a parameter to be determined. So you get equations $a_i + (\\nu b_i + \\lambda) 2^{x'_i} \\log{2} = 0$ for all $1 \\leq i \\leq n$. It's now easy to express $x'_i$ as a function of lambda and plugging this into the remaining constraint $g(x') = 0$ to find the lambda and complete the solution. Hope this helps.\n\nshare|improve this answer\nI agree but is this (math.stackexchange.com/questions/9105/\u2026) not going to happen here. I will get a polynomial equation for $\\lambda$, which will be not solvable if degree is greater than 5. \u2013\u00a0 SkypeMeSM Nov 7 '10 at 16:54\nIt will be solvable numerically. \u2013\u00a0 Yuval Filmus Nov 7 '10 at 16:54\nIt will not be solvable in radicals (in general). Is this a problem? Another thing is that x' need not be a minimum but only a stationary point, so you will need to further inspect the stationary points. The minimum can also be attained on the boundary of the domain D(f), g=0 which means that some x_k might be equal to x_{min} but that only reduces the problem to having less variables. \u2013\u00a0 Marek Nov 7 '10 at 17:26\nOk. I understand what you are saying. I guess I got my answer here. :) Thank you all. \u2013\u00a0 SkypeMeSM Nov 7 '10 at 17:29\n\nI don't think rewriting this way helps. In the first place, how would you show that if $y$ is the optimal solution of $\\min_y f(y)$, then $x = 2^y$ is the optimal solution to $\\min_x f(\\log x)$?\n\nshare|improve this answer\nThis is not a good answer. \u2013\u00a0 The Chaz 2.0 Dec 13 '11 at 5:23\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/101659/what-is-the-value-of-x-with-exponential-growth-but-decreases-as-it-reaches-its-m\nText:\nTake the 2-minute tour \u00d7\n\nI am building a financial model. I am looking for the value of Y:number of subscribers over X:month.\n\nThe model calls for the following.\n\n  \u2022 Competing of a market with 500,000 exclusive subscribers.\n  \u2022 Growth in year one will be exponential month over month with the total at the end of the year being 2500 subscribers.\n  \u2022 Growth in following years is expected to be 250% but will decrease as the product saturates the market.\n  \u2022 20,000 new subscribers will be introduced into the market each year with a total of 2,000 leaving the market each year.\nshare|improve this question\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nI can't give you an equation for $y(x)$ but I can give you a differential equation that it must satisfy...I'm not sure if an exact (closed form) equation exists.\n\nTo derive the equation, note that if the total-subscriber population was unlimited rather than 500,000, an exponential growth model would be: $$ y'(x) = ry(x),\\quad y(0) = y_0 $$ where $r>0$ is the growth factor and $y_0$ is the initial number of people subscribing to your service. The term $y'(x)$ is the change in $y$ with respect to $x$...the derivative from calculus. If you forgot your calculus, then think of it as how much $y$ changes when $x$ increases by one month (this is almost true). In this case the solution is $y(x) = y_0 e^{rx}$, which is exponential. Note that the growth is zero if you start with no one subscribing to your service! Let's assume therefore that you're able to get a small number of initial subscribers and call this number $y_0$. In fact, your assumption of 2500 year 1 subscribers and 250% growth means that $$ y_0 = 1000. $$\nYour assumption of 250% yearly growth means that $$ r = \\frac{\\ln 2.5}{12}. $$ This model is insufficient since it doesn't take saturation into account. To add that in (still ignoring the 20,000 new - 2,000 dropped yearly subscribers) we try the model $$ y'(x) = r y(x)(1 - \\frac{y}{250000}), \\quad y(0) = 1000 $$ Now, when $y(x) < 250,000$ growth will be positive, and when $y>250,000$ growth with be negative. Of course $y>250,000$ is impossible, but the effect will be saturation at 250,000 (the solution will never grow beyond 250,000 unless it starts there...). One can show that the solution to this is $$ y(x) = 250000 \\frac{1000 e^{rx}}{1 + 1000 e^{rx}}. $$ This is the logistic sigmoid, and this model is logistic growth, most often used in modeling populations.\n\nWe now have to take into account that the general subscriber population grows by 20,000 each year, but 2,000 people are lost. The general population growth can be modeled by replacing 250,000 with $$250,000 + 20,000\\frac{x}{12}$$ Now, to deal with the lost subscribers, we note that some of those 2,000 will be our subscribers, and some will not. This complicates things significantly. We can take the approximation that the total population gains 18,000 people per year. This is approximately true when you have much less than 250,000 subscribers. While it is possible to take this complicating factor into account, I'd argue, \"what's the point?\" There will always be some error with your model...also, there is no way your model will simultaneously work well at this stage in time (when you have a small market share), and further down the road when you are close to monopoly...so I think you should just attempt a model that works well when you have a small to medium market share...to do otherwise would be to confuse mathematical models with reality. If your investors require a model that \"works\" everywhere, then that can be done. In any case, our simplification means that we replace 250,000 with $$c(x) = 250,000 + 18,000\\frac{x}{12}.$$ $y(x)$ then satisfies the equation $$ y' = ry(1-\\frac{y}{c(x)}),\\quad y(0) = 1000. $$ You can solve for $y(x)$ using e.g. MATLAB or Python or whatever. It will look like a logistic sigmoid, but the right side will slowly grow without bound.\n\nIf I wanted to complicate the model I would add some uncertainty in the growth rates using some random variables.\n\nshare|improve this answer\n\nThis is a type of sigmoid function maybe more specifically a logistic function.\n\nUnless you are a transhumanist, in which case the growth will obviously never stop and will instead reach a singularity like 1/0.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/146232/norm-preserving-map-is-linear\nText:\nTake the 2-minute tour \u00d7\n\nHow can one show that a norm-preserving map $T: X \\rightarrow X'$ where $X,X'$ are vector spaces and $T(0) = 0$ is linear? Thanks in advance.\n\nshare|improve this question\nCould you clarify what you mean by norm-preserving? Note that if $T$ is not linear, then $|Tx| = |x|$ does not mean that $|Tx - Ty| = |x - y|$, which is what is usually meant (and as noted below, your claim is false if you only require $|Tx| = |x|$ and true in many cases if you actually meant distance-preserving). \u2013\u00a0 Ben Millwood May 17 '12 at 11:30\n\n2 Answers 2\n\nThe claim is false. For example, take $X=X'=\\mathbb{R}$, and $T(x)=|x|$ for all $x$.\n\nshare|improve this answer\nI think, for nonlinear maps, \"norm preserving\" has to mean $\\|T(x)-T(y)\\| = \\|x-y\\|$. \u2013\u00a0 GEdgar May 17 '12 at 12:46\n@GEdgar, the OP assumes also $T(0)=0$ and so $\\|T(x)-T(y)\\| = \\|x-y\\|$ implies $\\|T(x)\\| = \\|x\\|$. \u2013\u00a0 lhf May 17 '12 at 13:44\nBut not conversely. \u2013\u00a0 GEdgar May 17 '12 at 14:30\n\nThis claim is true if your map $T$ is surjective and an isometry. In this case simply apply Mazur-Ulam theorem.\n\nIf we require that map to be surjective, but only norm-preserving, then we can construct counterexample $$ T:\\mathbb{C}\\to\\mathbb{C}:z\\mapsto z e^{i |z|} $$ where $\\mathbb{C}$ is consideres as vector spaces over $\\mathbb{R}$.\n\nshare|improve this answer\nHold on, the link you gave refers to isometries, but there are functions that are norm-preserving but not isometries (e.g. the norm function itself). Are you sure the theorem applies? \u2013\u00a0 Ben Millwood May 17 '12 at 11:11\n@benmachine So what is yours definition of norm-preserving? \u2013\u00a0 Norbert May 17 '12 at 11:13\n$|f(x)| = |x|$ for all $x$. Since $f(x)-f(y)$ need not be $f(x-y)$, this need not mean that $|f(x) - f(y)| = |x - y|$. \u2013\u00a0 Ben Millwood May 17 '12 at 11:16\nOh, in this case you are right. Then even for surjective maps we can construct counterexamples. \u2013\u00a0 Norbert May 17 '12 at 11:17\nYeah, on second thoughts, norm-preserving as I phrased it is a pretty silly condition. I can't imagine the OP doesn't mean isometry. \u2013\u00a0 Ben Millwood May 17 '12 at 11:25\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/591784/if-two-sequences-converge-in-a-metric-space-the-sequence-of-the-distances-conve\nText:\nTake the 2-minute tour \u00d7\n\nLet $(p_n)$ and $(q_n)$ be sequences in the metric space $(X, d)$ and assume that $p_n \\rightarrow p \\in X$ and $q_n \\rightarrow q \\in X$. Prove that $d(p_n, q_n)$ converges to $d(p, q)$.\n\nOk, so using the triangle inequality (and assuming the sequences are Cauchy - but can I do that?), I can prove that the distance does converge, but how do I say it converges to $d(p,q)$ exactly?\n\nshare|improve this question\nWhy don't you look at the sequence d(p, $q_n$) -- what does that converge to? \u2013\u00a0 Betty Mock Dec 4 '13 at 0:48\nAssume it converges to $d'\\neq d(p,q)$, where $|d'-d(p,q)|=\\varepsilon > 0$. Go far enough in the sequences that $d(p_n,p)$, $d(q_n,q)$, and $|d'-d(p_n,q_n)|$ are all less than $\\varepsilon/3$. Show a contradiction. \u2013\u00a0 mjqxxxx Dec 4 '13 at 0:49\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe key is to use the reverse triangle inequality. Since $d$ is a distance, you have $d(x,y)\\leq d(x,z)+d(z,y)$ for any $x,y,z\\in X$. This you can write as $$ d(x,y)-d(z,y)\\leq d(x,z). $$ As the roles of $x$ and $z$ can be reversed, you get the reverse triangle inequality $$ |d(x,y)-d(z,y)|\\leq d(x,z). $$\n\nNow we get directly that $$ |d(p_n,q)-d(p,q)|\\leq d(p_n,p),\\ \\ \\ |d(p_n,q_n)-d(p_n,q)|\\leq d(q_n,q). $$ Now (using the triangle inequality) $$ |d(p_n,q_n)-d(p,q)|\\leq |d(p_n,q_n)-d(p_n,q)|+|d(p_n,q)-d(p,q)|\\leq d(q_n,q)+d(p_n,p). $$ So $\\lim_{n\\to\\infty}d(p_n,q_n)=d(p,q)$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://stackoverflow.com/questions/8580113/using-all-in-mapat-in-mathematica\nText:\nTake the 2-minute tour \u00d7\n\nI often have a list of pairs, as\n\ndata = {{0,0.0},{1,12.4},{2,14.6},{3,25.1}}\n\nand I want to do something, for instance Rescale, to all of the second elements without touching the first elements. The neatest way I know is:\n\nTranspose[MapAt[Rescale, Transpose[data], 2]]\n\nThere must be a way to do this without so much Transposeing. My wish is for something like this to work:\n\nMapAt[Rescale, data, {All, 2}]\n\nBut my understanding is that MapAt takes Position-style specifications instead of Part-style specifications. What's the proper solution?\n\nTo clarify,\n\nI'm seeking a solution where I don't have to repeat myself, so lacking double Transpose or double [[All,2]], because I consider repetition a signal I'm not doing something the easiest way. However, if eliminating the repetition requires the introduction of intermediate variables or a named function or other additional complexity, maybe the transpose/untranspose solution is already correct.\n\nshare|improve this question\nNote that [[All,2]] has the same number of characters as Transpose. So far the solutions are interesting, but I think none is shorter than the double-transpose one, especially if you permit the esc-tr-esc shortcut. Perhaps I should have posed the question as a code golf challenge? \u2013\u00a0 ArgentoSapiens Dec 20 '11 at 19:15\nif you want a shorter solution you probably should specifically ask for it. different people will consider different things to be the (proper OR most elegant OR easiest to understand) solution. \u2013\u00a0 acl Dec 20 '11 at 19:21\nWell if you simply don't want a double Transpose or double [[All,2]], both answers I gave seem suitable :) (I'd go for Mr.W's though, it's easier to read if not to write) \u2013\u00a0 acl Dec 20 '11 at 19:34\nWhy is you data that form on the first place, {{_Integer,_Real},..} performance wise {{__Integer},{__Real}} where better and then you would not have the problem to begin with. \u2013\u00a0 user1054186 Dec 20 '11 at 19:44\nThanks, all, for your answers. There is not always a super-compact way to do these things; these solutions have shown the variety that is possible when seeking a balance between compactness and versatility. \u2013\u00a0 ArgentoSapiens Dec 20 '11 at 21:35\n\n5 Answers 5\n\nup vote 10 down vote accepted\n\nUse Part:\n\ndata = {{0, 0.0}, {1, 12.4}, {2, 14.6}, {3, 25.1}}\n\ndata[[All, 2]] = Rescale @ data[[All, 2]];\n\n\nCreate a copy first if you need to. (data2 = data then data2[[All, 2]] etc.)\n\nAmending my answer to keep up with ruebenko's, this can be made into a function also:\n\npartReplace[dat_, func_, spec__] :=\n  Module[{a = dat},\n    a[[spec]] = func @ a[[spec]];\n\npartReplace[data, Rescale, All, 2]\n\nThis is quite general is design.\n\nshare|improve this answer\nPutting it in your own words, +1 for doing it exactly the way I'd do it (but see my answer below for a few minor differences) \u2013\u00a0 Leonid Shifrin Dec 20 '11 at 20:49\n\nI am coming late to the party, and what I will describe will differ very little with what @Mr. Wizard has, so it is best to consider this answer as a complementary to his solution. My partial excuses are that first, the function below packages things a bit differently and closer to the syntax of MapAt itself, second, it is a bit more general and has an option to use with Listable function, and third, I am reproducing my solution from the past Mathgroup thread for exactly this question, which is more than 2 years old, so I am not plagiarizing :)\n\nSo, here is the function:\n\nOptions[mapAt] = {MappedListable -> False}; \nmapAt[f_, expr_, {pseq : (All | _Integer) ..}, OptionsPattern[]] := \n  Module[{copy = expr}, \n    copy[[pseq]] = \n      If[TrueQ[OptionValue[MappedListable]] && Head[expr] === List, \n        f /@ copy[[pseq]] \nmapAt[f_, expr_, poslist_List] := MapAt[f, expr, poslist]; \n\nThis is the same idea as what @Mr. Wizard used, with these differences: 1. In case when the spec is not of the prescribed form, regular MapAt will be used automatically 2. Not all functions are Listable. The solution of @Mr.Wizard assumes that either a function is Listable or we want to apply it to the entire list. In the above code, you can specify this by the MappedListable option.\n\nI will also borrow a few examples from my answer in the above-mentioned thread:\n\nIn[18]:= mat=ConstantArray[1,{5,3}];\n\nIn[19]:= mapAt[#/10&,mat,{All,3}]\nOut[19]= {{1,1,1/10},{1,1,1/10},{1,1,1/10},{1,1,1/10},{1,1,1/10}}\n\nIn[20]:= mapAt[#/10&,mat,{3,All}]\nOut[20]= {{1,1,1},{1,1,1},{1/10,1/10,1/10},{1,1,1},{1,1,1}}\n\nTesting on large lists shows that using Listability improves the performance, although not so dramatically here:\n\nIn[28]:= largemat=ConstantArray[1,{150000,15}];\n\nIn[29]:= mapAt[#/10&,largemat,{All,3}];//Timing\nOut[29]= {0.203,Null}\n\nIn[30]:= mapAt[#/10&,largemat,{All,3},MappedListable->True];//Timing\nOut[30]= {0.094,Null}\n\nThis is likely because for the above function (#/10&), Map (which is used internally in mapAt for the MappedListable->False (default) setting, was able to auto-compile. In the example below, the difference is more substantial:\n\nf[x_] := 2 x - 1;\n\nIn[54]:= mapAt[f,largemat,{All,3}];//Timing\nOut[54]= {0.219,Null}\n\nIn[55]:= mapAt[f,largemat,{All,3},MappedListable->True];//Timing\nOut[55]= {0.031,Null}\n\nThe point is that, while f was not declared Listable, we know that its body is built out of Listable functions, and thus it can be applied to the entire list - but OTOH it can not be auto-compiled by Map. Note that adding Listable attribute to f would have been completely wrong here and would destroy the purpose, leading to mapAt being slow in both cases.\n\nshare|improve this answer\nHow can I not vote for this? You always bring a deeper analysis to the table. By the way, \"The solution of @Mr.Wizard assumes that either a function is Listable or we want to apply it to the entire list.\" I thought that was the point of this question based on the example. Yours in certainly an interesting take on it. Your last paragraph highlights something I have wondered about before: is there, or does it make sense to have, some way to assert that a function as \"inherently listable\"? This could help with misuse case 4 here.. \u2013\u00a0 Mr.Wizard Dec 21 '11 at 0:35\n@Mr.Wizard I think one can implement something like the type-inference for Listability, to address this problem. This does not even sound as a very hard problem. \u2013\u00a0 Leonid Shifrin Dec 21 '11 at 18:55\nWhat do you have in mind? It is a very loosely formed idea for me at this time. \u2013\u00a0 Mr.Wizard Dec 21 '11 at 19:07\n@Mr.Wizard The question can be formulated as follows: given a piece of code representing a function call, determine whether or not the result will be internally parallelized by appropriate Listable kernel functions which are called during the evaluation of this piece of code. But I start to see that this is not such a simple problem as I initially thought, so I withdraw my previous statement. \u2013\u00a0 Leonid Shifrin Dec 21 '11 at 19:13\n\nHow about\n\nTranspose[{#[[All, 1]], Rescale[#[[All, 2]]]} &@data]\n\nwhich returns what you want (ie, it does not alter data)\n\nIf no Transpose is allowed,\n\nThread[Join[{#[[All, 1]], Rescale[#[[All, 2]]]} &@data]]\n\n\nEDIT: As \"shortest\" is now the goal, best from me so far is:\n\ndata\\[LeftDoubleBracket]All, 2\\[RightDoubleBracket] = Rescale[data[[All, 2]]]\n\nat 80 characters, which is identical to Mr.Wizard's... So vote for his answer.\n\nshare|improve this answer\nIs that any cleaner than what he uses now? \u2013\u00a0 Mr.Wizard Dec 20 '11 at 18:37\n@Mr.W well, obviously I think it is (it uses indexing rather than MapAt, transposing and indexing to locate the elements to be acted upon, don't you think this is cleaner?), but of course different people think in different ways. \u2013\u00a0 acl Dec 20 '11 at 18:39\nPardon me, I didn't mean to be rude. I guess I fixated on the OP's request to \"do this without so much Transposeing.\" \u2013\u00a0 Mr.Wizard Dec 20 '11 at 18:43\n@Mr.W no rudeness perceived. I agree that yours looks cleaner; less @&# going on, which is bizarre :) \u2013\u00a0 acl Dec 20 '11 at 18:44\nLook, @Mr.W, no Transpose! \u2013\u00a0 acl Dec 20 '11 at 19:07\n\nHere is another approach:\n\nop[data_List, fun_] := \n Join[data[[All, {1}]], fun[data[[All, {2}]]], 2]\n\nop[data, Rescale]\n\nEdit 1:\n\nAn extension from Mr.Wizard, that does not copy it's data.\n\nSetAttributes[partReplace, HoldFirst]\npartReplace[dat_, func_, spec__] := dat[[spec]] = func[dat[[spec]]];\n\nused like this\n\npartReplace[data, Rescale, All, 2]\n\nEdit 2: Or like this\n\nReplacePart[data, {All, 2} -> Rescale[data[[All, 2]]]]\nshare|improve this answer\nReplacePart was the first thing I thought of, but I used {_, 2} and it failed. EDIT: Oh darn, it still doesn't work. :-(( Is this a v8 change? \u2013\u00a0 Mr.Wizard Dec 21 '11 at 0:37\nThis works in 801 and 804. I don't have V7 handy anymore. It could be that this was fixed, but I don't know. \u2013\u00a0 user1054186 Dec 21 '11 at 8:36\n\nThis worked for me and a friend\n\nIn[128]:= m = {{x, sss, x}, {y, sss, y}}\nOut[128]= {{2, sss, 2}, {y, sss, y}}\n\nIn[129]:= function[ins1_] := ToUpperCase[ins1];\nfatmap[ins2_] := MapAt[function, ins2, 2];\n\nIn[131]:= Map[fatmap, m]\nOut[131]= {{2, ToUpperCase[sss], 2}, {y, ToUpperCase[sss], y}}\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/221332/proof-that-language-is-not-context-free\nText:\nTake the 2-minute tour \u00d7\n\nIs this the appropriate way to show that this language is not context-free?\n\nGiven the language $L$ containing the words $1$, $101$, $101001$, $1010010001$, where each word $L_n$ is of the form $10^110^21...10^{n-1}10^n1$.\n\nAssume that $L$ is context-free, and as such that there is some $p$ which is the pumping length for $L$.\n\nConsider $s = L_{p-1}$. It is trivial to show that $|s| \\geq p$.\n\nBy the pumping lemma, we should be able write $s$ in the form $s = > wvxyz$ where $|vxy| \\leq p$ and $|vy| \\geq 1$ such that $wv^ixy^iz \\in > L$ for all $i$.\n\nAs $i = 0$, being a possible number of repeats, would give $wxz \\in > L$.\n\nTherefore, as $L$ only permits deletion from the tail of words we can derive that $x = \\lambda$ and $z = \\lambda$.\n\nAlso we can see that either $v$ or $y$ must equal $0^{p-1}1$. We can confirm that $|vxy| \\leq p$ holds for this.\n\nHowever, $i = 2$ is also a possible number of repeats, but would result in a word that ends $0^{p-1}10^{p-1}1$ and therefore that is not contained in $L$.\n\nTherefore we have a contradiction, and $L$ is not context-free.\n\nThankyou for your comments. Yes, this is homework.\n\nshare|improve this question\nSee also this question on cs.SE. \u2013\u00a0 Raphael Oct 26 '12 at 11:06\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nYou're on the right track (certainly avoiding the most common fallacies in using the pumping lemma) but the logic is incomplete. It's not quite true that $L$ only permits deletion from the tail of words. Deletion from near the tail is also possible, such as 101001000100001.\n\nThere will no doubt be more than one way to complete the argument. One simple option is to divide into two cases depending on whether $vy$ contains any 1, and make deductions about the distribution of spacings between pairs of 1s in either case.\n\nshare|improve this answer\nThanks, excellent point there. I beleive that there is a solution by using $0^i10^{p-1-i}$. \u2013\u00a0 thomasfedb Oct 26 '12 at 5:10\nYes, using $x = \\lambda$, $z = 0^i1$, with either $v$ or $y$ being $0^i10^{p-1-i}$ for some $0 \\leq i < p - 1$ I think I can cover all the possible deletions. \u2013\u00a0 thomasfedb Oct 26 '12 at 5:16\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/226718/a-group-g-in-which-every-subgroup-is-normal-includes-g-g-in-the-center?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a group such that all of its subgroups are normal, prove that $[G,G]\\subset Z_G$ where $[G,G]$ is the subgroup generated by the commutators $$[G,G]=\\langle [g,h]: g,h \\in G\\rangle \\;$$ where $[g,h]=ghg^{-1}h^{-1}$ and $Z_G$ is the center of $G$ $$Z_G=\\{g \\in G : (\\forall x \\in G)gx=xg\\}.$$\n\nI tried fixing $x\\in G$ and tried proving that all commutators commutate with $x$. Doing this will show that the set of all commutators is a subset of the center, and thus the group generated by the commutators is a subgroup of the center.\n\nLet us consider $\\langle x\\rangle$, if it is normal, then $yxy^{-1}=x^{\\gamma(y)}$; then the we have that $$\\gamma:y\\mapsto\\gamma(y)$$ is such that $$\\gamma(y_1y_2)=\\gamma(y_1)\\gamma(y_2)$$\n\nThen for any commutator $c=ghg^{-1}h^{-1}$ we have $$cxc^{-1}=ghg^{-1}h^{-1}xhgh^{-1}g^{-1}=x^{\\gamma(ghg^{-1}h^{-1})}=x^{\\gamma(g)\\gamma(h)\\gamma(g^{-1})\\gamma(h^{-1})}=x^{\\gamma(gg^{-1})\\gamma(hh^{-1})}=x^{\\gamma(e)\\gamma(e)}=x$$$$cxc^{-1}=x \\Longrightarrow cx=xc$$\n\nIs it correct? Are there any more elegant methods? In my proof the fact that $\\gamma:G\\rightarrow Z/nZ$ is not an homomorphism is giving me some trouble, although everything seems to work.\n\nshare|improve this question\nI improved some formatting, spelling and wording. For future posts, notice that $<$ and $\\langle$ (and $>$ and $\\rangle$) are different symbols. To obtain the latter, use the commands \\langle, \\rangle. Also, you may want to omit the definitions of most basic objects (the center, commutator subgroup), since they make your posts longer and more tedious to read. \u2013\u00a0 tomasz Nov 1 '12 at 11:40\nAlso, notice the difference between $\\to$ and $\\mapsto$ (\\to and \\mapsto): you write $f:{\\bf R}\\to {\\bf R}$ but $f:x\\mapsto x^2$. \u2013\u00a0 tomasz Nov 1 '12 at 11:43\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nWhy do you think $\\gamma$ isn't a homomorphism? It seems like a homomorphism into the multiplicative group $({\\bf Z}/n{\\bf Z})^*$ (or ${\\bf Z}^*=\\{-1,1\\}$ if $x$ is of infinite order); I believe it is enough to show what you have stated: that $\\gamma(yy')=\\gamma(y)\\gamma(y')$ which I presume you can do, then you can show that it is into the group by noticing that $\\gamma(e)=\\gamma(y)\\gamma(y^{-1})=1$, which you have used anyway; you may want to provide a short argument as to why it is well defined.\n\nThough you may want to show these things in more detail if it's a homework or something like that. Otherwise, it seems correct and actually quite elegant.\n\nshare|improve this answer\nHow can I be sure that $\\gamma$ doesn't output values outside of $(Z/nZ)^*$? \u2013\u00a0 Temitope.A Nov 1 '12 at 12:44\n@Temitope.A: by exhibiting the fact that each $\\gamma(y)$ is invertible, as I have written. \u2013\u00a0 tomasz Nov 1 '12 at 12:47\nOh yeah! Thanks for your help. \u2013\u00a0 Temitope.A Nov 1 '12 at 12:49\n\n\nEasy to see that it's enough to prove for $G=<a,b,c>$ that $[a,b]\\subset Z_G(c)$.\n\nLet $ac\\not= ca$, $c\\notin <a,b>$, then denote maximal group $M: M\\not= G, <a,b>\\subset M$, so $|G/M|=p$, $p$ is prime, so $G'\\subset M$, $c\\notin M$, so $c\\notin G'$, $aca^{-1}=c^l$, $l\\not= 0$, if $p|l$, then $[a,c]\\notin M$, but $[a,c]\\in G'\\subset M$, so $\\exists k\\in Z: p|kl-2$, so $[a^k,c]=c^{kl-1}=c^{kl-2}*c\\notin M$, but $[a^k,c]\\in G'\\subset M$, and if $ac=ca$, then $[a,b]c=a^ic=ca^i=c[a,b]$, if $c\\in <a,b>$, then $[a,b]\\in Z_G(<a,b>)\\subset Z_G(c)$. done\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/71917/proof-involving-a-convex-set?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nSo, the problem is actually from a microeconomics class. The problem is this:\n\nIf preferences are represented by a utility function $u(x,y)=xy$, show that these preferences are convex.\n\nNow in case you don't know, in economics, \"convex preferences\" means preferences such that the set of preferences that are at least as preferred to some bundle is convex. So basically what this means is I need to show this:\n\nLet $0\\le t\\le 1$\n\nif $u(x_1,y_1)=u(x_2,y_2)$, then $u(tx_1+(1-t)x_2,ty_1+(1-t)y_2)\\ge u(x_1,y_1)$.\n\nso $x_1y_1\\le (tx_1+(1-t)x_2)(ty_1+(1-t)y_2)$.\n\nNow, I have tried expanding this out and factoring all kinds of different ways, and I feel like I'm not getting anywhere. Am I going about this incorrectly by trying to expand this? Is there some simpler way? If anyone could give me some kind of hint that would be amazing.\n\n\nshare|improve this question\nAre you sure that the inequality is in that direction? A convex function is usually defined as $$f(tx+(1-t)y)\\le tf(x)+(1-t)f(y)$$ for $0\\le t\\le1$. \u2013\u00a0 robjohn Oct 12 '11 at 6:20\n@robjohn, Colin asks that the sets $\\{u\\geqslant h\\}$ are convex for every $h$ (that is, yes, that the function $u$ is concave). \u2013\u00a0 Did Oct 12 '11 at 6:27\n@Didier: Thanks, that makes sense. \u2013\u00a0 robjohn Oct 12 '11 at 6:50\nThe implication \"it has sets $\\Rightarrow$ [elementary-set-theory] or [set-theory] fits as tags\" is incorrect. I removed the unneeded tag. :-) \u2013\u00a0 Asaf Karagila Oct 12 '11 at 7:13\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nSince $x_1y_1=x_2y_2$, what you want to prove is equivalent to $$tx_1y_1+(1-t)x_2y_2\\leqslant(tx_1+(1-t)x_2)(ty_1+(1-t)y_2). $$ Expanding the RHS, one sees that the RHS minus the LHS is $$t(1-t)(x_1y_2+x_2y_1-x_1y_1-x_2y_2)=t(1-t)(x_1-x_2)(y_2-y_1). $$ Using $x_1y_1=x_2y_2$ once again, you know that $x_1>x_2$ implies $y_1<y_2$ and that $x_1<x_2$ implies $y_1>y_2$ hence the last product is always nonnegative. Done.\n\nshare|improve this answer\nHoly moly. I thought about trying to use the fact that $$x_1 y_1 = x_1 y_1$$ but it never occurred to me to do it the way that you did. How did you even think of that? Anyway, thank you very much for your help, I've got it. \u2013\u00a0 crf Oct 12 '11 at 7:32\nNot enough time to elaborate just now but the answer is: symmetry. \u2013\u00a0 Did Oct 12 '11 at 7:36\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/7383/ltl-show-negaub-leftrightarrow-neg-b-u-neg-a-land-neg-b-lor-g-neg\nText:\nTake the 2-minute tour \u00d7\n\nI got as far as \\begin{align} w \\vDash \\neg (a U b) &\\Leftrightarrow \\neg (w \\vDash a U b) \\Leftrightarrow \\neg (\\exists_{i\\geq0} : w^i \\vDash b \\land \\forall_{0\\leq k < i} : w^k \\vDash a) \\\\ &\\Leftrightarrow \\forall_{i\\geq0} : \\neg(w^i \\vDash b) \\lor \\exists_{0\\leq k < i} : \\neg(w^k \\vDash a) \\end{align}\n\nbut got stuck.\n\nIf you could offer some advice as on where to start I would very much appreciate it. Thanks in advance\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\n$aUb$ means that $a$ holds up to (and not necessarily including) the first point where $b$ holds, which must exist. There are two ways in which this can fail: $b$ never holds, or the first time that $a$ fails precedes the first time in which $b$ is true. The first case is handled by $G \\lnot b$. The second case is handled by $\\lnot b U (\\lnot a \\land \\lnot b)$ (why?).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/123355/maximum-number-of-edges-fn-k-in-a-graph-on-n-vertices-with-no-k-core\nText:\nTake the 2-minute tour \u00d7\n\nThe $k$-core of a finite graph is defined as follows. Delete all vertices of degree $< k$ and repeat until there are no such vertices left. If there is a nonempty subgraph remaining, necessarily of minimum degree $\\ge k$, we call this graph the $k$-core. If the deletion process results in removing all vertices, we say that the graph has no $k$-core.\n\nLet $f(n,k)$ denote the maximum number of edges in a simple graph on $n$ vertices with no $k$-core. For example, if $f(n,2)=n-1$ for every $n$, since $n$ edges are sufficient (and necessary) to guarantee the existence of a cycle.\n\nWhat about $k \\ge 3$? Maybe a formula is too much to hope for, so for fixed $k$ what are the asymptotics of $f(n,k)$ as $n \\to \\infty$?\n\nI suspect this kind of question has been studied, so any references would be appreciated. It is very similar in flavor to questions in \"classical\" extremal graph theory, where one tries to maximize the number of edges in a graph on $n$ vertices with no $H$-subgraph, where $H$ is a fixed graph. This question fits in a more general setting where $H$ ranges over an infinite family of possible subgraphs.\n\nshare|improve this question\nI think you want \"of minimum degree >= k\". Also, the literature on triangle free graphs may hint at an answer for f(n,3), even though it will only give an upper bound, and possibly a very weak bound. If you specialize to bipartite graphs, (I am guessing) you might also find some literature. Gerhard \"Ask Me About System Design\" Paseman, 2013.03.01 \u2013\u00a0 Gerhard Paseman Mar 1 '13 at 17:17\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\n$$f(n,k)= (n-k)(k-1)+\\frac{k(k-1)}{2}, \\; \\mathrm{for} \\; n \\geq k, $$ $$f(n,k) = \\frac{n(n-1)}{2}, \\; \\mathrm{for} \\; n \\leq k. $$\n\nProof: Every graph with no $k$-core on $n$ vertices contains a vertex of degree $\\leq k-1$ which one can delete, obtaining a graph with no $k$-core. Thus $$f(n,k) \\leq f(n-1,k) + k-1.$$\n\nThe formula now follows by induction. In the base case $n \\leq k$ the formula gives the number of edges in the complete graph.\n\nFor an example that the bound can be achieved, let $G$ be a graph with $V(G) = \\{1,2, \\ldots, n \\}$ and let the vertices $i$ and $j$ be adjacent if and only if $|i-j| < k$. It is easy to check that $G$ has no $k$-core and has the right number of edges.\n\nshare|improve this answer\n\nIf I'm not confused, I believe the graphs you are searching for (with a $k-1$ core but no $k$-core, and adding any edge creates a $k$-core) are also called \"maximal $(k-1)$-degenerate graphs,\" see e.g. the wikipedia article on degeneracy.\n\nThe paper \"k-degenerate graphs\" of Lick and White proves the following:\n\nCorollary 1: Let $G$ be a maximal $k$-degenerate graph with $p$ points, $p\\geq k$. Then $G$ has $kp-\\binom{k+1}{2}$ [edges].\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/32098/positivity-of-sequences-via-generating-series?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThere are different ways of showing that a given sequence $a_0,a_1,a_2,\\dots$ of integers, say, is nonnegative. For example, one can show that $a_n$ count something, or express $a_n$ as a (multiple) sum of obviously positive numbers. Another recipe is manipulating with the corresponding generating series $A(x)=\\sum_{n=0}^\\infty a_nx^n$ and showing that $A(x)\\ge0$ (this is the notation for a series which has all coefficients nonnegative, and this extends to formal power series in as many variables as needed).\n\nAn example of criterion in this direction is $$ (*) \\qquad A(xy)\\ge0 \\iff \\frac1{(1-x)(1-y)}A\\biggl(\\frac{xy}{(1-x)(1-y)}\\biggr)\\ge0 $$ (the multiple $1/(1-x)(1-y)$ is introduced for cosmetic purposes only and, of course, both $A(x)\\ge0$ and $A(xy)\\ge0$ are by definition equivalent to the nonnegativity of the sequence $a_n$). The latter can be verified by comparing the corresponding coefficients in the power series expansion $$ \\frac1{(1-x)(1-y)}A\\biggl(\\frac{xy}{(1-x)(1-y)}\\biggr) =\\sum_{n=0}^\\infty a_n\\sum_{k,m=0}^\\infty\\binom{n+k}n\\binom{n+m}nx^{n+k}y^{n+m}. $$\n\nOn the other hand, the one-dimensional version of $( * )$, $$ A(x)\\ge0 \\iff \\frac1{1-x}A\\biggl(\\frac{x}{1-x}\\biggr)\\ge0, $$ is simply false.\n\nMy question is whether it is possible to find two nontrivial rational functions $p(x)\\in\\mathbb Q[[x]]$ and $r(x)\\in x\\mathbb Q[[x]]$ in one variable $x$ such that $$ A(x)\\ge0 \\iff p(x)A\\bigl(r(x)\\bigr)\\ge0. $$ Although I am not supposed to put several problems in one question, I would also ask about a more direct proof of $( * )$ and about general ways of constructing such $p$ and $r$ in more than one variable.\n\nMotivation. Basically I am interested in proving nonnegativity of certain $q$-series sequences $a_0(q),a_1(q),a_2(q),\\dots$ by manipulating with the corresponding generating series $A_q(x)=\\sum_{n=0}^\\infty a_n(q)x^n$. Some of them can be \"guessed\" from non-$q$-versions, for example there is a neat $q$-analogue of the criterion $( * )$.\n\nshare|improve this question\nHi, Wadim. So you sometimes do \"positivity\" of series, same as the article I sent you. Let me be sure: (*) is true and really does follow from the expansion with the binomial coefficients? Then the next one with just $$ \\left( \\frac{x}{1-x} \\right) $$ is false, so I suggest you switch to (But it is not!) Do you have an example of falsity for this one? \u2013\u00a0 Will Jagy Jul 16 '10 at 1:16\nHi Will, yes I do (sometimes) positivity. :-) $( * )$ does follow by comparing the coefficients of $x^Ny^M$ when you fix successively $N=0,1,\\dots$ and choose the corresponding $M$ sufficiently large. As for a 1-variable counterexample, take $A(x)=1+x-x^2+x^3$; then $A(x/(1-x))/(1-x)\\ge0$. \u2013\u00a0 Wadim Zudilin Jul 16 '10 at 1:37\nI agree with Will that the sentence \"but it does not\" is confusing and should be changed to \"but it is not.\" \u2013\u00a0 Charles Staats Jul 16 '10 at 2:05\nDone! $ $ \u2013\u00a0 Wadim Zudilin Jul 16 '10 at 2:25\nI am having trouble seeing how (*) follows from the double iteration of the false statement. Could you elaborate? \u2013\u00a0 Qiaochu Yuan Jul 16 '10 at 17:37\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nIt is impossible, and not just for rational functions. To see this, let's consider the coefficients $b_n$ of $p(x) A(r(x))$ as functions of the $a_n$, the coefficients of $A(x)$. Since $r(0) = 0$ (as it must be) we see that:\n\n  \u2022 Each $b_n$ is a linear combination of $a_0, \\dots, a_n$; i.e. we have an upper-triangular infinite matrix $F$, not depending on $a_n$, such that (writing $\\vec{a} = (a_n), \\vec{b} = (b_n)$) $\\vec{b} = F \\vec{a}$. Suppose for now that $p(0), r'(0) \\neq 0$; then $F$ has a nonzero diagonal, and so is invertible.\n\n  \u2022 If $\\vec{b} \\geq 0$ for all $\\vec{a} \\geq 0$, then in particular this is true of the columns of $F$, taking $\\vec{a}$ to be infinite \"basis\" vectors. Conversely, we have equivalently that $\\vec{a} = F^{-1} \\vec{b}$, so if $\\vec{a} \\geq 0$ for all $\\vec{b} \\geq 0$ this must be true of the columns of $F^{-1}$. We conclude that both $F$ and $F^{-1}$ have nonnegative entries.\n\n  \u2022 Lemma in linear algebra: if $F$ is upper-triangular and both it and $F^{-1}$ have nonnegative real entries, then $F$ is diagonal. Proof by induction: true for $1 \\times 1$ matrices vacuously. In general, by induction we may assume that the upper-left and lower-right $(n - 1) \\times (n - 1)$ blocks of $F$ are diagonal, so only the $(1,n)$ entry of $F$ is nonzero off the diagonal. Then we have $(F^{-1})_{1n} = -F_{1n} F_{nn}/F_{11}$. Since $F_{11}$ and $F_{nn}$ are both positive, $F_{1n}, (F^{-1})_{1n} \\geq 0$ implies $F_{1n} = 0$.\n\n  \u2022 This is also true of infinite matrices, since we can compute the finite upper-left blocks independently of the rest of the matrix.\n\n  \u2022 However, if $F$ is diagonal then we see that $p(x)A(r(x)) = \\sum a_n p(x) r(x)^n = \\sum F_{nn} a_n x^n$ for all choices of $a_n$, so (for example, taking $a_n = t^n$ for a new variable $t$ and rewriting both sides as power series in $t$) we have $p(x) r(x)^n = F_{nn} x^n$ for all $n$ (and some $F_{nn} > 0$). That is, $(r(x)/x)^n = F_{nn} p(x)^{-1}$ for all $n$, so in fact $r(x)/x = F_{11}/F_{00}$ is constant, and finally, $p(x)$ is constant as well.\n\n  \u2022 Now we remove the assumptions that $p(0), r'(0) \\neq 0$. If $x^k$ divides $p(x)$, then replacing $p(x)$ by $p(x)/x^k$ does not change positivity of the coefficients. Now suppose the bottom exponent of $r(x)$ is $x^m$ with positive coefficient; then in $\\mathbb{R}[[x]]$ we can write $r(x) = s(x)^m$, and if we denote $A_m(x) = A(x^m)$, we have $A(r(x)) = A_m(s(x))$. Clearly, $A_m$ has nonnegative coefficients if and only if $A$ does, and $s'(0) \\neq 0$, so the previous proof applies and $s(x)$ is a multiple of $x$, i.e. $r(x)$ is a multiple of $x^m$, and $p(x)$ is a multiple of $x^k$.\n\nshare|improve this answer\nRyan, thank you very much for your computation (it will take time for me to follow it in details). I took $p_0=r_1=q(x)=1$, so that $p(x)=1+x$, $r(x)=x-x^2$, and computed $p(x)A(r(x))$ for $A=\\sum_{j=0}^4a_jx^j$. The coefficient of $x^8$ in the resulting polynomial is $-3a_4<0$. \u2013\u00a0 Wadim Zudilin Jul 22 '10 at 6:04\nHmmm. Looking back over the argument I realize that it is not possible for $F$ to be diagonal, since that would necessitate $p(x) r(x)^n \\in \\mathbb{Q}$ for all $n$, an impossibility. I will think on this and replace the above answer with something correct tomorrow, when I am more awake. \u2013\u00a0 Ryan Reich Jul 22 '10 at 6:38\nNo hurry, Ryan, and thanks again. I was thinking of the problem hard before posting it. The expectation is \"no\" which is probably harder than giving at least one (nontrivial) example. \u2013\u00a0 Wadim Zudilin Jul 22 '10 at 6:43\nIt is definitely \"no\". My mistake (which betrays the fact that I am NOT a combinatorialist) is that I forgot all the binomial coefficients :) \u2013\u00a0 Ryan Reich Jul 22 '10 at 13:08\nI haven't gone through your solution yet, but I'm wondering where do you lose answers like $p(x)=x^3$ and $r(x)=x^2$? \u2013\u00a0 Gjergji Zaimi Jul 22 '10 at 17:34\n\nJust a quick observation. It is not hard to see that this is impossible if there exists some $i$ such that for all $j \\ge i$, the coefficients of $p(x) r(x)^j$ are all positive after the first positive coefficient. (This occurs, for example, whenever $p, r$ themselves have this property.) This is because by induction one can take $A(x) = a_i x^i - x^{i+1} + a_{i+2} x^{i+2} + ...$ where $a_i, a_{i+2}, ... $ can be chosen to be large enough so that $p(x) A(r(x)) \\ge 0$. In general some weird things happen that you might be able to fix with the Skolem-Mahler-Lech theorem, and I suspect that when $r$ is a polynomial it should always be possible to find a counterexample.\n\nshare|improve this answer\nThanks a lot, Qiaochu! I didn't have your argument to exclude the \"eventually\" positive ($j\\ge i$) case of $p(x)r(x)^j$, but of course I suspect that only \"trivial\" pairs $p(x),r(x)$ do the job. I am just wondering whether the problem was studied... Can you provide some details on what do you mean by the SML theorem? \u2013\u00a0 Wadim Zudilin Jul 18 '10 at 2:44\nIf r is not a polynomial, the coefficients of p(x) r(x)^j will be nonzero infinitely often for sufficiently large j. Unfortunately, they can also be zero infinitely often, so changing the coefficients of A isn't necessarily enough to give you control over the coefficients of p(x) A(r(x)). The SML theorem tells you what kind of control you have and I think one could argue as above, but more carefully. \u2013\u00a0 Qiaochu Yuan Jul 18 '10 at 2:55\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/183259/collatz-ish-olympiad-problem\nText:\nTake the 2-minute tour \u00d7\n\nThe following is an Olympiad Competition question, so I expect it to have a pretty solution:\n\nFor a positive integer $d$, define the sequence: \\begin{align} a_0 &= 1\\\\ a_n &= \\begin{cases} \\frac{a_{n-1}}{2}&\\quad\\text{if }a_{n-1}\\text{ is even}, \\\\ a_{n-1}+d &\\quad\\text{if }a_{n-1}\\text{ is odd.} \\end{cases} \\end{align} Find all values of $d$ such that $a_n=1$ for some $n>0$.\n\nIt is obvious that $d$ must be odd, or else the sequence is monotone increasing. Also, I have numerically observed that all odd values of $d$ seem to work. Can anyone provide a hint as to how to even begin to prove this? Thank you!\n\nshare|improve this question\nDid you intend \"... if $a_n$ is even, .... if $n$ is odd.\" Should $n$, or $a_n$ be used in both predicates? \u2013\u00a0 Sasha Aug 16 '12 at 16:05\nThanks for pointing that out. I edited the question \u2013\u00a0 Raj Raina Aug 16 '12 at 16:25\nYes I have tried induction, but I see no way of relating previous values of $d$ with bigger values of $d$ (i.e. the induction step) \u2013\u00a0 Raj Raina Aug 16 '12 at 16:40\n@RajRaina There still seems be to a typo. Did you mean to say $a_{n+1} = \\frac{a_n}{2}$ if $a_n$ is even, and $a_{n+1} = a_n + d$ if $a_n$ is odd? \u2013\u00a0 Sasha Aug 16 '12 at 16:41\nAHH sorry for not proofreading more carefully! I edited :) \u2013\u00a0 Raj Raina Aug 16 '12 at 16:43\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere is an outline of an argument. Our guess was that the sequence goes back to $1$ for any $d = 2m-1$.\n\nFirst, it seems preferable to work with the sequence\n\n$$b_0 = 1, \\quad b_n = \\begin{cases} \\dfrac{b_{n-1}}2 & (b_{n-1}\\text{ even}) \\\\ \\frac{b_{n-1}+d}2 & (b_{n-1} \\text{ odd})\\end{cases}$$\n\ninstead of $a_n$ (the statement to be proven remains the same).\n\nHint: Show that it is enough to show $b_n\\equiv 1 \\pmod d$ for some $n$. What does the sequence $b_n$ look like mod $d$?\n\nI have included a more detailed outline below (but I fear it is giving away way too much!)\n\nClaim 1: We have $0<b_n<d$ for all $n$.\n\n\nThis allows us to work mod $d$ from now on, i.e. we have $b_n = 1$ if and only if $b_n\\equiv 1 \\pmod d$.\n\n\nClaim 2: $\\frac12 \\equiv m \\pmod d$, where $d=2m-1$ as above.\n\n\nNow notice that the sequence is really simple when considered $\\pmod d$! Use this to show\n\n\nClaim 3: $b_n \\equiv m^n \\pmod d$\n\n\nClaim 3 implies that $b_k \\equiv 1 \\pmod d$ for some $k$ (why?), so by Claim 1 it follows that $b_k=1$ for this $k$. $\\square$\n\nshare|improve this answer\nSince you tagged the question (homework) I assume you wanted a hint rather than a full solution. Please let me know whether you think the above format is helpful in this/how it could be improved... \u2013\u00a0 Sam Aug 16 '12 at 17:59\nA nice argument. You actually show what the return time is, not just that it does return as I do. \u2013\u00a0 Ross Millikan Aug 16 '12 at 18:09\n@RossMillikan: Thank you. Yes, at least for the $b_n$, the return time is given by $\\mathrm{ord}(m)$, where $m\\in \\mathbb Z_{2m-1}^\\times$ and $d = 2m-1$. But it doesn't seem easy to get a return time for the $a_n$ from this (although it does give an upper bound of $2\\varphi(d)$). \u2013\u00a0 Sam Aug 16 '12 at 18:20\n@SamL. I posed a related question before seeing your response. Your response answers the question completely though. You might want to respond to it, to claim the credit. Thanks! \u2013\u00a0 Sasha Aug 16 '12 at 18:59\nThank you Sam L. If I am understanding correctly, we can now say that $b_{n}\\equiv 2^{\u2212n}\\pmod d$ (Claim 3), and so we need $2^n \\equiv 1 \\pmod d$, which has the trivial solution $n = \\phi (d)-1$ since $2$ and $d$ are relatively prime, and so we will always have $b_{\\phi(d)-1} =1$. What a simple solution! But what was Claim 2 necessary for? \u2013\u00a0 Raj Raina Aug 16 '12 at 23:12\n\nIt is true that you return to $1$ for all odd $d$, and the power of $2$ that you get to for the return is the next power of $2$ above $d$.\n\nAll odd numbers in the series are less than $d$, which means it must cycle. If $a_n$ is odd and less than $d$, $a_{n+1}$ is less than $2d$ and even, so the next odd is again less than $d$.\n\nTo have a cycle that does not include $1$ you must have a number that can be reached from two different numbers-one to enter the cycle and one to continue it. But this is impossible-odd numbers have to be reached by division by $2$, even numbers greater than $d$ have to be reached by addition, and even numbers less than $d$ have to be reached by division.\n\nshare|improve this answer\nThank you for your help! \u2013\u00a0 Raj Raina Aug 16 '12 at 23:04\n\nThe question has already an \"accepted\" answer - but the following scheme may be useful for some later reader anyway.\nThe iterative dividing and adding can be expressed as a whole operation.\nWe formulate one transformation as $$ a_{k+1}={a_k+d \\over 2^A }$$ and work on odd $a_k$ only. The value for A is determined by the requirement, that it is the highest A such that the result of the transformation is an odd integer.\nThe second transformation is then $$ a_{k+2}={{a_k+d \\over 2^A }+d \\over 2^B} = {a_k \\over 2^{A+B} } + d \\cdot ({1 \\over 2^{A+B} } + {1 \\over 2^B} )$$ and so on.\n\nLet the h subsequent exponents of such transformations $a_0 \\to a_h = 1$ be denoted as $A,B,C,\\ldots,G,H$ and their sum as $S$. Then the full transformation can be written as\n$$ 1 (=a_h) = {a_0 \\over 2^S} + d \\cdot {(1+2^A + 2^{A+B} + \\ldots + 2^{A+B+\\ldots + G})\\over 2^S} $$ and we must have an integer solution for\n$$ 2^S = a_0 + d \\cdot (1+2^A + 2^{A+B} + \\ldots + 2^{A+B+\\ldots +G})= a_0 + d \\cdot x $$\nwhere S is to be found (if there is a solution in $A,B,C,\\ldots,H$ at all!).\n\nThus we solve for S such that $ 2^S = a_0 \\pmod d$ which must in general be done by searching (see \"discrete-logarithm-problem\").\nNow here seems to be the critical problem of the original question: we need to know such combinations of $d$ and $a_0$ that this equation has a solution at all. Possibly this is also meant to be the core problem in your homework-assignment, so I won't proceed here ( #1 see below)\n\nIf in fact there is a solution for some S then we compute\n$$ x = { 2^S - a_0 \\over d} $$. Then the bits in the binary representation of x correspond to the \"division by 2's\" of the original formulation of the problem.\n\nFor instance, with $a_0 = 605, d=13$ I found $2^S = a_0 + d \\cdot x $ with $ S=11, x=111$ and $2048 = 605 + 13 \\cdot 111 $\n\n(#1): Referring to another answer we might reformulate this as $ 2 = a_0^{1 \\over S} \\pmod d$ which hints to the concept of \"primitive roots (mod p)\".\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/305026/enumerating-rooted-labeled-trees-without-langrange-inversion-formula\nText:\nTake the 2-minute tour \u00d7\n\nI am wondering how to enumerate rooted labeled trees without the Langrange inversion formula. Because each tree is a collection of other trees, the recursive generating function becomes $$C(x) = x + xC(x) + xC(x)^2 ... = \\sum_n x[C(x)]^n/{n!} = xe^{C(x)}$$\n\nFrom my notes, I am told that we may be able to utilize the function $G(x)$ which counts the number of forests on n vertices => $xG(x) = C(x)$ I can been trying to fiddle around with these functions as well as taking derivatives/log of both, but I can't seem to isolate $C(x)$ to get a functional equation to extract coefficients. Any help would be appreciated!\n\nshare|improve this question\nThe solution to $C(x) = x \\exp(C(x))$ is a new transcendental function, you won't find a \"nice\" formula for it, it is related to Lambert's W function <en.wikipedia.org/wiki/Lambert_W_function>; \u2013\u00a0 vonbrand Feb 15 '13 at 20:21\nBTW, why restrict yourself from using one of the most useful tools to handle this type of equations? \u2013\u00a0 vonbrand Feb 15 '13 at 20:22\nWell based on the notes, we're not suppose to have covered the LIF so the problems should be doable without. I actually asked this problem to give me some intuition for other problems and the counting proofs are great! \u2013\u00a0 Azhuang Feb 17 '13 at 7:07\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere's another proof, I believe due to Jim Pitman.\n\nA rooted forest is a disjoint union of rooted trees, which we will think of as a digraph with edges always directed toward the roots. Given a rooted forest $F$ on $n$ vertices with $k$ components, we would like to add an edge while still having a forest. To do this, choose any vertex $x$ and any of the $k-1$ roots $y$ not in the same component as $x$ and add the edge $y \\rightarrow x$. There are thus $n(k-1)$ ways of doing this, and the resulting forest now has $k-1$ components. If we start from forest with $n$ isolated vertices, we see that we can add $n-1$ edges in\n\n$$n(n-1)\\cdot n(n-2) \\cdot \\ldots \\cdot n(1) = (n-1)! \\cdot n^{n-1}$$ ways. In this expression each tree has been counted $(n-1)!$ ways since the order in which we added edges does not matter, so dividing this out gives the desired formula.\n\nshare|improve this answer\n\nUsually, you would use the Lagrange inversion formula together with the functional equation $C(x)=x e^{C(x)}$ to extract the coefficients from $C(x)$. But if you don't want to do that, here is a combinatorial argument to count labeled rooted trees, from Joyal (1981), p. 16:\n\nCall a vertebrate an unrooted labeled tree with two (possibly coincident) distinguished points, a red one and a black one. By following a path from the red point to the black point, rooting each subtree you come to at that point, and removing all edges along the path, you can change the vertebrate into a nonempty sequence of rooted labeled trees. This is a bijective correspondence, so the number $V_n$ of vertebrates on $n$ vertices which are labeled $\\{1,\\ldots,n\\}$ is the same as the number of nonempty sequences of rooted trees on vertices labeled $\\{1,\\ldots,n\\}$.\n\nLet $n\\ge 1$. The number of ways of arranging the roots of $k$ rooted trees into a sequence is $k!$, which is the same as the number of ways of arranging the roots of $k$ rooted trees into a permutation. So, $V_n$ is also the number of sets of rooted trees on vertices labeled $\\{1,\\ldots,n\\}$ together with a permutation acting on their roots. But every self-map on $\\{1,\\ldots,n\\}$ gives such a structure (composed of trees of elements which coalesce under the action of the self-map and eventually fall into cycles), and conversely. This is a bijective correspondence, so $V_n$ equals the number of self-maps on $\\{1,\\ldots,n\\}$, which is $n^n$.\n\nEach rooted tree on labeled vertices $\\{1,\\ldots,n\\}$ gives $n$ different vertebrates, by coloring the root black and any of $\\{1,\\ldots,n\\}$ red. This is an $n$-to-$1$ correspondence, so, if $n\\ge 1$, the number of rooted trees on $n$ vertices is $n^n/n=n^{n-1}$.\n\nJoyal also uses similar reasoning to give a combinatorial proof of the Lagrange inversion formula (pp. 21-24.)\n\nshare|improve this answer\nThere is a detailed presentation of this argument in Mikl\u00f3s B\u00f3na, Introduction to Enumerative Combinatorics, McGraw-Hill, 2007, pp. 266-8. \u2013\u00a0 Brian M. Scott Feb 16 '13 at 0:27\n\nPitman gave a wonderful solution.\n\nTalking about \"Joyal point of view\" one could give up those vertebrates and talking only about functions and labeled trees. And in case we haven't rooted trees there'll be $n^2$ functions for each tree. Otherwise, if the problem concerns labeled rooted trees, then we'll have $n$ functions associated to every such tree.\n\n(So there are $n^{n-2}$ labeled trees and $n^{n-1}$ labeled rooted trees)\n\nTalking on the base set $[n]={1,2,...,n}$\n\nIt's not that obvious how you build the function(s) starting from a labeled tree (rooted or not). But it's similar. For example, in the case of \"unrooted\" labeled trees we'll have \"n X n\" = $n^2$ unique paths, from each vertex to each vertex (including from a vertex to itself). Such a path, with the vertices M = {$v_1, ..., v_k$} like this $v_1$ -> $v_2$ ->...-> $v_k$ will build partially a function $f(v_i)=v_{i+1}$, where $v_{k+1}$ is $v_1$. For the \"subtrees\" (having the ROOT in the paths' vertices it's simple).\n\nConversely, having a function, you must build a tree ... There is a unique (nonempty) set $M$ with maximum elements such as $f$ is bijective on $M$ ... If we write the elements of $M$ increasingly $M = \\{i_1, i_2,...,i_2\\}$ then $f(i_1)$ -> $f(i_2)$ -> ... -> $f(i_k)$ will be the path .. for the rest is much more simple... (and we'll have finally $n^2$ functions giving the same tree). The operations are inverse to one another...\n\nIn the case of rooted labeled trees we'll have $n$ unique paths joining the root with every other vertex (including the root itself). The rest is just the same.\n\nAnyway, here are only the main STEPS. A rigorous demonstration it's much more longer than this, because you must justify all, major or minor \"tricks\" or statements.\n\nWhat is interesting in my case (what I'm looking for) is the possibility to follow similar steps (in the \"Joyal style\", using functions) to prove the Moon theorem, I mean enumerating labeled trees having given (fixed) degrees, so $d(x_i)= d_i$ for $i \\in [n]$, of course with $\\sum d_i = 2(n-1)$...\n\n... and find the well known multinomial coefficient $\\binom{n-2}{d_1 -1 \\; d_2 -1 \\; ... \\; d_n -1}$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192981/proving-1-0-using-only-the-field-axioms-and-order-axioms?answertab=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nHow do I prove $1 > 0$ using only field axioms and order axioms? I have tried using the cancellation law, with the identities in a field and I cannot get anywhere. Does anybody have any suggestions?\n\nshare|cite|improve this question\nI think $1 = 1^2$ is helpful. \u2013\u00a0Dylan Moreland Sep 9 '12 at 2:02\n@GerryMyerson I assume the OP means \"ordered field axioms\". \u2013\u00a0Alex Becker Sep 9 '12 at 2:28\nYou need not only the axioms of fields and the axioms of linearly ordered sets, but also the axioms that say the linear order is compatible with the algebraic operations, i.e. if $a,b>0$ then $ab>0$, etc..... \u2013\u00a0Michael Hardy Sep 9 '12 at 2:53\nIn general assume the most minimal set of axioms. I think a lot of textbooks and people might have different terminology. \u2013\u00a0CodeKingPlusPlus Sep 10 '12 at 1:52\nup vote 6 down vote accepted\n\nSuppose $1 < 0$. Adding $(-1)$ to both sides we'd also have $0 < -1$ (addition axiom). But if $0 < a$ then it must also hold that $0 < a^2$ (multiplication axiom). For $a = -1$ this means $0 < (-1)^2 = 1$, a contradiction.\n\nshare|cite|improve this answer\nCan't you do the same with $0$ < $1$? Subtract 1 from each side then we have $-1$ < $0$. Now square both sides. We have $1$ < $0$ another contradiction. Thus, this method does not work. \u2013\u00a0CodeKingPlusPlus Sep 10 '12 at 1:51\n@CodeKingPlusPlus There is some missing detail that I believe Marek meant for you to fill in. Of course it is incorrect to say that if $a, b$ are elements of an ordered field then $a < b$ implies $a^2 < b^2$ \u2014 one remembers the graph of $ y = x^2$ over $\\mathbb R$. But what is true is that if $0 < a < b$ then $0 < a^2 < b^2$. \u2013\u00a0Dylan Moreland Sep 10 '12 at 3:34\n@CodeKingPlusPlus: I was not squaring. I was multiplying by (a > 0) -- a positive number by assumption (since 0 < -1). In your argument (-1 < 0) is a negative number, so the multiplication axiom cannot be applied. \u2013\u00a0Marek Sep 10 '12 at 6:29\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/40816/fibonacci-series-mod-a-number/40818\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm trying to write a program with an input of numbers $n$ and $k$ (where $n<10^{1000}$ and $k<10^9$), where I compute fib[n] % k. What is a good FAST way of computing this?\n\nI realize that the resulting series is periodic, just not sure how to find it efficiently.\n\nshare|cite|improve this question\nIf k has no large prime or large prime power factors, then brute force combined with the Chinese Remainder Theorem will get you somewhere quickly. Otherwise use recursions to do the Fibonacci series mod k, to compute e.g. F(2j) and F(2j+1) mod k from F(j) and f(j+1) mod k. If n and k satisfy the bounds you say, a reasonably coded laptop can give you the answer in seconds or less. Gerhard \"Ask Me About System Design\" Paseman, 2010.10.01 \u2013\u00a0Gerhard Paseman Oct 2 '10 at 6:11\nThe Fibonacci entry in wikipedia has this identity : $F_{lk+c} = \\sum_{i=0}^l {l\\choose i} F_{c-i} F_k^i F_{k+1}^{l-i}$. It definitely seems to be relevant in your case, where write $n=lk+c$ and then you have to know $F_j$ mod $k$ for $j=1,\\ldots,k+1$ as well as ${l\\choose i}$ mod $k$. I don't know if this is efficient enough. \u2013\u00a0Somnath Basu Oct 2 '10 at 6:19\nModulo a prime $>5$ the Fibonacci sequence has a period that is either a factor of $p-1$ or $2(p+1)$. This follows from Binet's formula. If $5$ is a quadratic residue modulo $p$, then $$x^2=x+1$$ has two roots in the field $F_p$, and thus both roots have multiplicative orders that are factors of $p-1$. OTOH if $5$ is a quadratic non-residue, then the roots $\\tau_1,\\tau_2$ of that polynomial are in the finite field $K=F_{p^2}$. But by known Galois theory of $K$ we then have $$\\tau_1^p=\\tau_2=-1\\frac1{\\tau_1},$$ so $\\tau_^{p+1}=\\tau_2^{p+1}=-1.$$ See \u2013\u00a0Jyrki Lahtonen May 26 '12 at 15:56\nup vote 12 down vote accepted\n\nThis is really just an expansion of Gerhard's comment. One has the matrix formula $$\\begin{pmatrix} 1&1\\\\\\ 1&0 \\end{pmatrix}^n= \\begin{pmatrix} F_{n+1}&F_n\\\\\\ F_n&F_{n-1} \\end{pmatrix} $$ so the problem reduces to computing $A^n$ modulo $k$ where $$A=\\begin{pmatrix} 1&1\\\\\\ 1&0 \\end{pmatrix}.$$ This can be done by the repeated squaring method often used in modular exponentiation. The idea is to compute $A^n$ recursively either as $(A^m)^2$ or $A(A^m)^2$ according to whether $n=2m$ or $n=2m+1$.\n\nshare|cite|improve this answer\nSorry for the late accept, I have been busy lately. Thank you all for the help! \u2013\u00a0user9734 Oct 4 '10 at 12:28\nAlso note that the order of $GL_2(\\Z_k)$ is much smaller than $n$, and the order of the matrix divides this order. If $l$ is the reminder of $n$ divided by this order, then $A^n=A^l \\mod p$. Last but not least it is enough to consider the subgroup of matrices of $det =\\pm1$. \u2013\u00a0Nick S Nov 7 '10 at 19:52\n\nPerhaps Elsenhans, Jahnel, \"The Fibonacci sequence modulo $p^2$ \u2013 An investigation by computer for $p < 10^{14}$\" will be interesting for you. There are sections about the algorithm.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/50770/open-parent-cell-groups-of-selected-cell\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI wrote a small script for a palette, which allows me to highlight a specific cell in a notebook by using SelectionMove[mycell, All, Cell]. The cell is selected as expected, but sometimes this cell is part of a cell group (section, subsection etc.) which is currently closed, so the cell itself is hidden, and SelectionMove does not reveal it. So far, I didn't find a way to open all parent groups of this cell programatically so that this cell will be shown... Is this possible?\n\nshare|improve this question\nYou can use pattern matching like there: 33416 \u2013\u00a0Kuba Jun 14 '14 at 9:11\nup vote 1 down vote accepted\n\nYou can select parent cell group of currently selected object in notebook nb with SelectionMove[nb, All, CellGroup] and then open it using FrontEndTokenExecute[nb, \"SelectionOpenAllGroups\"]. To open all groups containing currently selected cell you can use something like this:\n\n       SelectionMove[nb, All, CellGroup];\n       If[MatchQ[NotebookRead[nb], Cell[CellGroupData[_, Closed], ___]],\n           FrontEndTokenExecute[nb, \"OpenCloseGroup\"]\n\nIt will select parent group, open it (if it's closed), return selected cell expression and repeat until returned expression is unchanged (i.e. when there's no parent CellGroup).\n\n\nIt seems that NotebookLocate automatically opens all groups containing located cell.\n\nSo you could just add CellTags to selected cell and then locate it:\n\nSetOptions[NotebookSelection[nb], CellTags -> \"MyFavoriteCell\"]\nSetSelectedNotebook[nb]; NotebookLocate[\"MyFavoriteCell\"]\n\nIt should be much faster (and cleaner) than my previous, overcomplicated method.\n\nshare|improve this answer\nThanks - does what I want, but the use of NotebookRead makes this slightly slow when using this function in a large notebook. I didn't find a workaround, because this seems to be the only way to find out whether or not the cell group is open... \u2013\u00a0mjayvizzle Jun 15 '14 at 10:51\n@mjayvizzle Please look at edited version. \u2013\u00a0jkuczm Jun 15 '14 at 11:33\nThanks - that's much faster! Didn't think about the option to assign a cell tag... \u2013\u00a0mjayvizzle Jun 15 '14 at 14:58\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/100688/convexity-of-spectral-radius-of-markov-operators-random-walks-on-non-amenable-g\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $P_1,P_2$ denote stochastic transition matrices on a countable set $I$. Consider $P_1,P_2$ as operators on $\\ell^2(I)$ given by multiplication.\n\nQuestion Under which conditions can we show that for $t\\in (0,1)$, $$\\rho(tP_1+(1-t)P_2)\\le t\\rho(P_1)+(1-t)\\rho(P_2),$$ where $\\rho(\\cdot )$ denotes the spectral radius? (Of course, it would be nice to consider this problem also for more general classes of Markov operators acting on some function space.)\n\nMy hope is that the strong assumption that both matrices are stochastic, is enough to prove the inequality.\n\nExample My favorite example is the case where $I$ is the free group $G$ of rank $d\\ge2$ and $P_1,P_2$ are given by $P_i(g,g'):=\\mu_i( g^{-1}g' )$, where $\\mu_i$ is some measure on a set of generators of $G$. In this case, the spectral radius of $P_i$ is strictly less than one, since the group is non-amenable (H. Kesten 1959). I don't know if the above inequality holds in this setting. (Note that non-zero constant functions are not in $\\ell^2(G)$.)\n\nAn additional assumption I'm fine with the additional assumption that $P_1$ and $P_2$ have zeros at the same places. So, regarding the previous example, the measures $\\mu_i$ have the same support. A further simplification would be to assume that one of measures is equidistributed on its support.\n\nRelated results If $P_1,P_2$ commute, then the inequality holds. This is too restrictive.\n\nIf $P_1,P_2$ are selfadjoint, then the spectral radius can be replaced by the norm, and the inequality holds. I'm not interested in this case. I don't want to assume that $P_i$ is reversible with respect to some measure.\n\nFinite matrices with real eigenvalues In the following paper, Lax proved that the spectral radius on the set of $n\\times n$ matrices with real eigenvalues is convex.\n\nKingman proved that spectral radius is log-convex on the space of finite dimensional non-negative matrices.\n\nCohen proved that the spectral radius is a convex function of the diagonal elements on the space of finite dimensional non-negative matrices. There are generalisations for multiplication operators by Kato.\n\nOn amenability If the group is $G$ is amenable in the previous example, then for a large class of transition operators, the spectral radius is equal to one (e.g. uniform irreducibility and invariant measure bounded away from zero and infinity). Hence, under these conditions, all the spectral radii in the above inequality are equal to one. So, equality holds.\n\nExample As an example, let $G$=$\\mathbb{Z}$ and consider $P_1,P_2$ corresponding to the random walks, which go one step to the left resp. right with probabilities $p_i$ resp. $q_i$, $p_i+q_i=1$, $i=1,2$.\n\nReferences LAX, P. D. Differential equations, difference equations and matrix theory. Comm. Pure Appl. Math. 11 (1958), 175-194.\n\nKingman, J.F.C.: A convexity property of positive matrices. Quart. J. Math. Oxford (2) 12, 283-284 (1961)\n\nCohen, J.E.: Convexity of the dominant eigenvalue of an essentially nonnegative matrix. Proc. Amer. Math. Soc. 81, 657-658 (1981)\n\nKato: Superconvexity of the Spectral Radius, and Convexity of the Spectral Bound and the Type, Mathematische Zeitschrift, (1982)\n\nUsing commutativity There are several papers of M.Zima about related properties for positive operators on partially ordered Banach spaces (see below). In there, some commutativity is required to prove the inequality in question. I don't want to assume commutativity.\n\nM.Zima, A theorem on the spectral radius of the sum of two operators and its applications, Bull. Austral. Math. Soc. 48 (1993), 427{434. MR 94j:47006\n\nM.Zima, On the local spectral radius in partially ordered Banach spaces, Czechoslovak Math. J. 49 (1999), 835{841. MR 2001m:47011\n\nshare|cite|improve this question\n\nFor a lot of results of this sort (though probably not exactly what you are asking for), check out:\n\nConvexity and log convexity for the spectral radius Roger D. Nussbaum Linear Algebra and its Applications Volume 73, January 1986, Pages 59\u2013122\n\nshare|cite|improve this answer\nThanks for the reference. But, so far, I didn't find an answer to my question in it. It seems that the paper is more about eigenvalues. I don't see how to apply it to the l^2 setting. \u2013\u00a0Mika Jun 27 '12 at 3:42\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18268/discrete-stochastic-process-exponentially-correlated-bernoulli/23441\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nThere is a question that was asked on stackoverflow that at first sounds simple but I think it's a lot harder than it sounds.\n\nSuppose we have a stationary random process that generates a sequence of random variables x[i] where each individual random variable has a Bernoulli distribution with probability p, but the correlation between any two of the random variables x[m] and x[n] is \u03b1|m-n|.\n\nHow is it possible to generate such a process? The textbook examples of a Bernoulli process (right distribution, but independent variables) and a discrete-time IID Gaussian process passed through a low-pass filter (right correlation, but wrong distribution) are very simple by themselves, but cannot be combined in this way... can they? Or am I missing something obvious? If you take a Bernoulli process and pass it through a low-pass filter, you no longer have a discrete-valued process.\n\n(I can't create tags, so please retag as appropriate... stochastic-process?)\n\nshare|cite|improve this question\nyou could try to take a process $x(t)$ like an Ornstein-Uhlenbeck, that has a correlation structure that decreases exponentially, and then define $B_n = 1_{x(n) > \\alpha}$ where $\\alpha$ is a well-chosen threshold - I have not done the computations, but I have the feeling that the correlation between these Bernoulli random variables also decreases exponentially. Do you really need the correlation to be equal to $\\alpha^{|m-n|}$ ? Would an exponentially decreasing correlation be enough for your particular purpose ? \u2013\u00a0Alekk Mar 15 '10 at 14:59\nthx for the suggestion... I'm posting this on behalf of someone else (see the link in the 1st sentence) so I do not know the stringency of their requirements. The problem seemed simple enough to state that I felt I could translate into a \"proper\" problem statement for mathoverflow. \u2013\u00a0Jason S Mar 15 '10 at 15:20\n...and I had kind of the same hunch (make a continuous-value process, then use a threshold to produce a binary-value output) but don't quite know how to go about characterizing the output process w/r/t correlation, other than an empirical calculation on the computer. \u2013\u00a0Jason S Mar 15 '10 at 15:56\nBy the way, the SO problem is not $\\alpha^{|m-n|}$, but $c|m-n|^{-\\alpha}$. \u2013\u00a0Douglas Zare Mar 15 '10 at 18:09\nYes, that was pointed out to me... but I am suspicious + wondering if the OP meant alpha ^ |m-n|. Using the c |m-n| ^ (-alpha) formula, correlation is undefined for m=n. \u2013\u00a0Jason S Mar 15 '10 at 19:15\nup vote 6 down vote accepted\n\nHere is a construction.\n\n  \u2022 Let $\\{Y_i\\}$ be independent Bernouilli random variables with probability $p$.\n  \u2022 Let $N(t)$ be a Poisson process chosen so that $P(N(1)=0)=\\alpha$.\n  \u2022 Let $X_i = Y_{N(i)}$.\n\nIn words, we have some radioactive decay which tells us when to flip a new (biased) coin. $X_n$ is the last coin flipped at time $n$. The correlation between $X_m$ and $X_n$ comes from the possibility that there are no decays between time $m$ and time $n$, which happens with probability $\\alpha^{|m-n|}$.\n\nThe conditional correlation between $X_m$ and $x_n$ is $1$ if $N(m) = N(n)$, and $0$ if $N(m)\\ne N(n)$, so $\\text{Cor}(X_n,X_m) = P(N(m)=N(n)) = \\alpha^{|m-n|}.$\n\nYou can simplify this by saying that $N(i) = \\sum_{t=1}^i B_i$ where $\\{B_i\\}$ are independent Bernoulli random variables which are $0$ with probability $\\alpha$.\n\nshare|cite|improve this answer\nfascinating! I think I understand... thanks! \u2013\u00a0Jason S Mar 15 '10 at 19:13\nBrilliant answer \u2013\u00a0David Bar Moshe Mar 16 '10 at 9:44\nPhrasing it in terms of a Poisson process seems overly complicated; the properties of Poisson processes aren't actually used. Couldn't one just phrase it as follows? Let $$X_{i+1} = \\begin{cases} X_i & \\text{with probability }\\alpha; \\\\ \\text{a new Bernoulli trial independent of }X_i & \\text{with probability }1-\\alpha. \\end{cases} $$ \u2013\u00a0Michael Hardy Jun 2 '10 at 20:36\n\nIn other words:\n\nStart with a random variable $X_0$ Bernoulli with parameter $p$, random variables $Y_n$ Bernoulli with parameter $\\alpha$, random variables $Z_n$ Bernoulli with parameter $p$, and assume that all these are independent. Define recursively the sequence $(X_n)_{n\\ge0}$ by setting $X_{n+1}=Y_nX_n+(1-Y_n)Z_n$ for every $n\\ge0$.\n\nThen $X_n$ and $X_{n+k}$ are conditionally correlated if and only if $Y_i=1$ for every $i$ from $n$ to $n+k-1$. This happens with probability $\\alpha^k$, hence you are done.\n\nThis is Douglas Zare's idea, but with no Poisson process.\n\nshare|cite|improve this answer\nInteresting variation, thanks! \u2013\u00a0Jason S Mar 16 '10 at 14:06\nThe last line of my answer gave the same construction. My $B_i$ is your $1-Y_i$. \u2013\u00a0Douglas Zare Mar 16 '10 at 14:33\n\nI suggest also to look a the paper: Generating spike-trains with specified correlations. By Jakob Macke, Philipp Berens, et al. (Max Planck Institute for Biological Cybernetics.).\n\nGenerating spike-trains with specified correlations\n\nThey also offer a Matlab Package for 'Sampling from multivariate correlated binary and poisson random variables' ... also available at Matlab central:\n\nSampling from multivariate correlated binary and poisson random variables\n\nAlso look at the page link\n\nshare|cite|improve this answer\n\nThe above solution is very nice, but relies on the very special structure of the desired process. In a much more general framework, I think that one could use a perfect simulation algorithm as described in:\n\nProcesses with long memory: Regenerative construction and perfect simulation, Francis Comets, Roberto Fern\u00e1ndez, and Pablo A. Ferrari, Ann. Appl. Probab. 12, Number 3 (2002), 921-943.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/48009/inequality-on-probability-distributions?sort=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI would like to know if the following inequality is satisfied by all probability distributions (or at least some class of probability distributions) for all integer $n \\geq 2$.\n\n$\\int_0^{\\infty} F(z)^{n-1}(1-\\frac{F(z)}{n})\\left[zF(z)^{n-2} - \\int_0^z F(t)^{n-2}dt\\right]f(z)dz$ $\\leq \\int_0^{\\infty} F(z)^{n-1}\\left[zF(z)^{n-1} - \\int_0^z F(t)^{n-1}dt\\right]f(z)dz $\n\nSome comments follow:\n\n1) F(z) is the cumulative distribution function of any probability distribution over positive real numbers. The outer integral runs over the entire support of the distribution, thus, in general, from zero to infinity. f(z) is the probability density function.\n\n2) I will be happy even if this is proved for bounded support distributions, in which case, the outer integral runs from 0 to some upper limit H.\n\n3) Note that both the LHS and the RHS are always non-negative. This is because of the special form of what is inside the square brackets. For both the LHS and the RHS, the second term in the square bracket (i.e. the negative integral from 0 to z), when replaced by its value at the upper limit throughout the region of integration from 0 to z, gives precisely the first term in the square bracket. Thus the term in the square bracket is always non-negative, for both the LHS and the RHS.\n\n4) Also note the obvious similarity in the structure between the LHS and the RHS. The only differences are the difference in exponent for what is inside the square brackets, and the LHS having an extra factor of $1 - \\frac{F(z)}{n}$.\n\n5) Note that for $n=2$, this inequality is definitely true since the LHS evaluates to zero owing to the term in the square bracket in the LHS becoming zero, and the RHS is always non-negative, as mentioned in point 3 above.\n\n6) It is easy to work out that for all $n \\geq 2$, this inequality is true for uniform [0,1] distributions, i.e., the distribution with support [0,1] and $F(z) = z$.\n\n7) I tried evaluating this integral for small values of $n$ (till 50) using Maple for exponential distribution, and the positive half of the normal distribution and found it to be true. I am guessing that this inequality is true for at least some large class of probability distributions if not all distributions.\n\n8) For instance, would a monotone hazard rate condition help? Monotone hazard rate means that $\\frac{f(z)}{1-F(z)}$ is non-decreasing.\n\nshare|cite|improve this question\nCould you give some background of this inequality? \u2013\u00a0zhoraster Dec 2 '10 at 11:21\nThis inequality pops up in my research in algorithmic game theory. The actual context itself yields little intuition, except for the fact that if the above inequality held, the result we get would be a natural one. Briefly, the problem has to do with comparing two kinds of auctions with each other and analyzing bidding strategies in the two auctions. One auction rewards the highest bidder more than the other, so we would expect the expected highest bid to be larger in the first auction. That is what this inequality would imply. \u2013\u00a0Balu Dec 2 '10 at 18:21\nIs $n$ the number of bidders and this inequality derived from expected order statistics? \u2013\u00a0R Hahn Jan 1 '11 at 7:48\nHahn, the answer to both of your questions is yes. \u2013\u00a0Balu Jan 2 '11 at 11:37\nup vote 7 down vote accepted\n\nThe inequality holds for every $n\\ge2$ (integer or not) and every probability distribution. Here is a proof. We begin with two easy facts.\n\nFact 1: For every $z\\ge0$ and every $k\\ge1$, $$ zF(z)^k-\\int_0^zF(t)^k\\mathrm{d}t=k\\int_0^ztF(t)^{k-1}f(t)\\mathrm{d}t. $$ Fact 2: For every $t$ and every $k\\ge0$, $$ (k+1)\\int_t^{+\\infty}F(z)^kf(z)\\mathrm{d}z=1-F(t)^{k+1}. $$ (Fact 1 is an integration by parts. Fact 2 is trivial.)\n\nNow to the proof.\n\nReplace the brackets on the LHS and on the RHS by integrals over $t$ in $(0,z)$ thanks to Fact 1. This yields expressions of the LHS and of the RHS as double integrals. Interchange the order of integration. The inner integrals over $z$ in $(t,+\\infty)$ can both be evaluated thanks to Fact 2. One gets that the difference between the RHS and the LHS is $$ A_n=n^{-1}\\int_0^{+\\infty}tf(t)F(t)^{n-3}P_n(F(t))\\mathrm{d}t, $$ where $$ P_n(x)=(n-1)x(1-x^n)-(n-2)(1-x^n)+(n-2)(1-x^{n+1})/(n+1). $$ Hence $$ A_n=n^{-1}\\int_0^{+\\infty}Q_n(F(t))\\mathrm{d}t,\\qquad\\mbox{with}\\quad Q_n(x)=\\int_x^1u^{n-3}P_n(u)\\mathrm{d}u. $$ The proof that $A_n\\ge0$ for every probability distribution is complete if $Q_n\\ge0$ over $(0,1)$. Some easy calculus of variation will do the job.\n\nNamely, over $(0,1)$, the second derivative $P''_n$ is positive then negative, hence the first derivative $P'_n$ is increasing then decreasing. Since $P'_n(0)>0$ and $P'_n(1)<0$ (expressions omitted), $P'_n$ is positive then negative, hence $P_n$ is increasing then decreasing. Since $P_n(0)<0$ and $P_n(1)=0$, $P_n$ is negative then positive.\n\nThis shows that $Q_n$ is increasing then decreasing over $(0,1)$. Since $Q_n(1)=0$, it remains to prove that $Q_n(0)\\ge0$. This last fact follows from the explicit computation of the integral over $(0,1)$ defining $Q_n(0)$, which yields, unless I am mistaken, that $Q_n(0)=(n-2)/(2(n-1)(2n-1))$. Since this quantity is nonnegative for every $n\\ge2$, we are done.\n\nshare|cite|improve this answer\nThanks Didier! Perfect. \u2013\u00a0Balu Jan 2 '11 at 11:36\n\nYour Answer"}
{"text": "Retrieved from http://electronics.stackexchange.com/questions/105086/why-we-gradually-increase-size-of-inverters-in-buffer-design\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWhen trying to drive a high capacitive load why do we gradually increase size of inverters in buffer design. Why not give the output of a circuit to one large inverter?\n\nshare|improve this question\nAbout progressive sizing ? \u2013\u00a0BASIL VARGHESE Apr 2 '14 at 17:37\nThis question makes no sense without some context. \u2013\u00a0Olin Lathrop Apr 2 '14 at 17:40\nThis comes from VLSI design, where very small transistors are used in internal logic but they must ultimately drive very large transistors in the output buffers. \u2013\u00a0Joe Hass Apr 2 '14 at 18:21\n@OlinLathrop I suppose you could take it that way, but at that point it seems like you're deliberately going out of your way to be confused. The information he provided does not make sense in the contexts you suggested, but it is sufficiently clear (and makes sense) for IC design. \u2013\u00a0W5VO Apr 2 '14 at 19:48\n@W5VO: But IC design was never mentioned. Actually when I read the question, my first thought was inverters that make AC from DC, since I just had a recent questions about them on my mind. I'm not a IC designer, so the IC design context never occurred to me. If the OP had mentioned IC design, I would have no problem with this question and would have simply skipped it knowing it was not for me. \u2013\u00a0Olin Lathrop Apr 2 '14 at 20:01\nup vote 3 down vote accepted\n\nLet us assume that we have given the output to one large inverter. Now the signal that has to drive the o/p cap will now see a larger gate capacitance of the large inverter. This results in slow rise or fall times. A unit inverter can drive approximately an inverter that 4 times bigger in size. So we need to drive a cap of 64 unit inverter then we try to keep the sizing like say 1,4,16,64. So that each inverter sees a same ratio of o/p to i/p cap. This is the main reason behind going for progressive sizing......\n\nshare|improve this answer\n\nDriving a very large inverter from the output of a normal (tiny) logic gate means that a large capacitance will be charged and discharged with tiny transistors. This takes a very long time, causes slow rise/fall transitions on the output pin, and causes considerable power waste in the large inverter.\n\nDepending on the exact process parameters, it usually turns out that the lowest total propagation delay results from having a sequence of inverters. As the signal progresses from the internal logic signal to the output pin the transistors in the inverters get larger, increasing by a factor of 3X to 5X in each successive inverter.\n\nshare|improve this answer\n+1. You might also mention that the method of logical effort can be used to calculate how many intermediate stages will give the lowest total propagation delay; typically a fan-out of 4 (FO4). \u2013\u00a0davidcary Apr 3 '14 at 13:36\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/25312/number-of-spanning-trees-of-a-quotient-graph?sort=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $G$ be a finite connected graph on a $2m$-element vertex set $V$. For any graph with vertices $u,v$, let $\\mu(u,v)$ denote the number of edges between $u$ and $v$. Suppose that $G$ has an automorphism $f$ that is a fixed-point free involution on the vertices. We can define a quotient graph $G/f$ by letting the vertices of $G/f$ be the orbits $[u]=\\left\\lbrace u,f(u)\\right\\rbrace$ of $f$, and setting $$ \\mu([u],[v]) = \\mu(u,v) + \\mu(f(u),v). $$ Let $\\kappa(H)$ denote the number of spanning trees of a graph $H$. By the Matrix-Tree Theorem and some simple linear algebra, one can show that $2\\kappa(G)$ is divisible by $\\kappa(G/f)$. My question is whether the factor of 2 is necessary, i.e., is it always true that $\\kappa(G)$ is divisible by $\\kappa(G/f)$? Similar questions can be asked for more complicated automorphism groups of $G$.\n\nshare|cite|improve this question\nI think this works in the general case too if we define a quotient according to $\\mu([u],[v])=\\mu(u,v)+\\mu(u,f(v))+\\cdots+\\mu(u,f^{n-1}(v))$, where $f$ is an automorphism of degree $n$, but I havent checked the details. I wonder if there are any other graph related quantities that behave this way under taking quotients. \u2013\u00a0Gjergji Zaimi Jun 4 '10 at 14:40\n\nLet us group the vertices as $U=\\{u_1,u_2,\\dots,u_n\\}$ and $V=\\{v_1,v_2,\\dots, v_n\\}$ where $f(u_i)=v_i$. Let $L_0$ be the laplacian of the graph with vertex set $U$ and edges as restricted from $G$, let $L _1 = \\operatorname{diag}\\left( \\sum _{j=1}^n \\mu(u _i, v _j)\\right)$ and $L=L _0+L _1$, also let $A$ be the symmetric matrix whose $a _{ij}$ is $-\\mu(u _i,v _j)$. Clearly the Laplacian of $G$ is $M=\\left( \\begin {array} {cc} L & A \\\\\\ A & L \\end {array} \\right)$. Let $M^*$ stand for the matrix $M$ with deleted first row and column. We have $$\\kappa(G)=\\det \\left( \\begin {array} {cc} L & A \\\\\\ A & L \\end {array} \\right) ^ *=\\det \\left( \\begin {array} {cc} B & C \\\\\\ D & (L+A)^ * \\end {array} \\right)$$ for some block matrices $B,C,D$ of size $n\\times n,n\\times (n-1),$ and $(n-1)\\times n$ where this second matrix was obtained by adding the $i$th row of $M^{\\*}$ to it's $n+i$th row for $1\\le i\\le n-1$ and then adding the first (or last) $n-1$ columns to the $n$th column. So $D$ is the matrix $(L+A)*$ together with a last column of zeros, making $(L+A)^{\\*-1}D$ with integer entries. Next we factor it using one of these identities $$\\kappa(G)=\\det(L+A)^ * \\det(B-C(L+A)^{*-1}D)$$ and observe that $L+A$ is the Laplacian of $G/f$ so $\\det(L+A)^ *=\\kappa(G/f)$, and since the second factor is an integer we get the desired divisibility.\n\nshare|cite|improve this answer\nIt seems to me that the statement \"Clearly the Laplacian of G is M = [[L,A],[A,L]]\" is false. Can the proof be fixed? \u2013\u00a0Richard Stanley May 29 '10 at 21:33\nFortunately it was just a typo, I think it's fixed now. \u2013\u00a0Gjergji Zaimi May 31 '10 at 5:55\nThe proof looks o.k. now. Getting the last column of zeros was a key step. Thanks for your answer! \u2013\u00a0Richard Stanley Jun 21 '10 at 1:12\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/146424/what-is-the-number-of-functions-f-a-rightarrow-a-forall-x-ina-ffx-x/146432\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWhat is the number of functions $f : A\\rightarrow A, \\forall_{x\\in{A}} f(f(x))=x$, set $A$ have $n$ distinct elements.\n\nFor $A=\\{a,b,c,d\\}$ we could look on the right-upper triangle of matrix of all possible pairs (? better word needed here) - below. For $a$ we have four possibilities but if we choose $a->b$ for example, then we have to delete second column. Without deletation we would have $4!$ functions $f$ for $A=\\{a,b,c,d\\}$, but there is only 1+6+3 of them.\n\n$a->a,a->b,a->c,a->d \\\\ ........b->b,b->c,b->d \\\\ ................c->c,c->d \\\\ ........................d->d $\n\nI think that if $n=2k$ then we could choose first $k$ elements so we have $k$ sets with single element then for each elements with number $k+1 : 2k$ we assign $0$ or $1$. $0$ if $a_{i}->a_{i}$ and $1$ if $a_{i}->a_{1 : n}$, for $i\\in k+1:2k$, so we have $2^k$ possibilities. If $j$, $1's$ have been assigned then we have $\\binom{k}{j}$ possibilities for two element sets and ... I'm out of ideas.\n\nYou could edit my post this is welcome.\n\nshare|cite|improve this question\nIn other words, the number of permutations $\\sigma\\in S_n$ such that $\\sigma^2=e$. If you're familiar with the terms, consider the cycle decomposition of these $\\sigma$'s. (Apparently, the answer isn't terribly simple, though.) \u2013\u00a0anon May 17 '12 at 18:30\nyes, it's the essence of my question \u2013\u00a0Qbik May 17 '12 at 18:33\nI don't get the tagging. This is neither set theory nor category theory related. \u2013\u00a0Asaf Karagila May 17 '12 at 18:33\nup vote 4 down vote accepted\n\nLet $B$ denote a set of size $n+1$ with $B=A\\cup\\{o\\}$, $A$ of size $n$, and $o$ not in $A$. Let $f$ denote an involution of $B$. Then:\n\n  \u2022 Either $f(o)=o$, then $f$ is characterized by an involution of $A$.\n  \u2022 Or $f(o)\\ne o$, then there are $n$ possible choices of $f(o)=a$ with $a$ in $A$. Once $a$ is fixed, one knows that $f(a)=o$ hence $f$ is characterized by an involution of $A\\setminus\\{a\\}$.\n\nLet $i_n$ denote the number of involutions of a set of size $n$. One sees that $i_1=1$, $i_2=2$, and that the recursion $i_{n+1}=i_n+ni_{n-1}$ holds, for every $n\\geqslant2$. This characterizes the sequence $(i_n)_{n\\geqslant1}$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/16851/set-x-increases-by-1-set-y-increases-by-3-need-help-with-a-function-that-will\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nTwo sets\n\nx = 1,2,3,4,5...\ny = 1,4,7,10,13...\n\nI need to write a function\n\n$f(x_n) = y_n$\n\nI found that if I\n\n  1. take a number from x\n  2. double it\n  3. subtract 2\n  4. add the result to the original number\n  5. I get the corresponding number from y\n\nHere's what I have so far (it's in ruby code), it works but is there a better way of doing it.\n\ndef f(x)\n  if x > 1\n    return x + ((2 * x) - 2)\n    return 1\n\ny = f(x)\nshare|cite|improve this question\nNot sure what better way you are looking for. What you have seems fine, expect we can multiply by 3 instead of doubling and then adding itself. I guess Ruby does not have overflow issues. \u2013\u00a0Aryabhata Jan 9 '11 at 1:12\nup vote 3 down vote accepted\n\nYour values y form what is called an arithmetic progression, namely a sequence where each element is obtained from the previous one just by adding always the same constant. In your case the constant is 3, namely: 1, 4=1+3, 7=4+3, 10=7+3 and so on.\n\nSince the FIRST time you add 3 corresponds to x=2, the formula is just\n\n\nor (equivalently)\n\n\nshare|cite|improve this answer\nWow thanks, I can't believe I didn't think about 3x instead of 2x + x lol. \u2013\u00a0Seth Archer Brown Jan 9 '11 at 3:32\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-do-you-calculate-all-the-possible-combinations-on-a-rubiks-cube.759259/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHow do you calculate all the possible combinations on a Rubik's cube?\n\n  1. Jun 23, 2014 #1\n    I thought it would just be the number of faces multiplied by the nine cubes on each face? What am i doing wrong?\n  2. jcsd\n  3. Jun 23, 2014 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Not all combinations are possible mechanically. I would probably try to solve this with a program. Are you comfortable writing a C program (or using some other programming language) to solve this?\n  4. Jun 23, 2014 #3\n    I know very little programming, a tiny but if Python but that's about it\n  5. Jun 23, 2014 #4\n\n    D H\n\n    User Avatar\n\n    Staff: Mentor\n\n    You're not going to be able to count the permutations on a computer. The number is too big.\n\n    If you consider the problem of the number of permutations that can be made by pulling a Rubik's cube apart piece by piece and then reassembling it, this is a huge number. There are eight corner cubes which can be placed. That means 8! permutations just based on corner cube location. Each corner cube can be placed in one of three orientations. That's a factor of 38 permutations on top of the 8! location permutations. The twelve corner cubes lead to two more factors, 12! and 212. Altogether, there are ##8! \\, 3^8 \\, 12! \\, 2^{12}## permutations of the ripped apart and resembled cube. That is a *big* number.\n\n    Most of these permutations do not lead to the nice all colors on one face arrangement. There are constraints, but the final number is still huge.\n  6. Jun 24, 2014 #5\n\n\n    User Avatar\n    Homework Helper\n\n    See here\n    There are\n    $${8! \\times 3^7 \\times (12!/2) \\times 2^{11}} = 43,252,003,274,489,856,000 \\\\\n\n    the larger number is 12 times the smaller as there are 12 orbits\n    that is any position can reach 1/12 positions though legal moves separating possible moves into 12 orbits\n\nHave something to add?\nDraft saved Draft deleted\nSimilar Discussions: How do you calculate all the possible combinations on a Rubik's cube?\n  1. Rubik cube (Replies: 8)\n\n  2. Rubik's cube (Replies: 2)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/355934/hamming-code-error-correction\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm currently learning how Hamming codes work and so far I am understanding it!\n\nI have worked through several examples, and it seems to work well following the below table:Hamming Code Table\n\nWhere I get stuck however is when I have an example which its length means it ends on a parity bit. For example:\n\n\nIgnore the meaning of obviously random binary string above, but the fact that it is 16 bits long, when you are error checking it, you start with p1 and then do p2, p4, p8 and finally p16. What I don't understand however, is that as there are no digits after position 16, how am I meant to work out if p16 is correct or not. If the string was 20 bits long, I know you just count 16 and skip 16, starting at p16. However as there are no bits after p16 I am a bit stuck.\n\nIf anyone has any idea, that would be awesome!\n\n\nshare|cite|improve this question\nThis code has 15 bits of data, plus 5 of redundacy (parity), giving a total of 20 bits per encoded symbol. To decode each symbol you need 20 bits. I don't understand why you are given 16 bits to decode, and what are you supposed to do with that. \u2013\u00a0leonbloy Apr 9 '13 at 14:17\nThe table above shows how to error correct up to 20 bits, but the symbol doesn't have to be 20 bits. For example the code word 110110001010 without the parity bits would be 01001010. The original code word can be error corrected using p1, p2, p4 and p8. My problem is not knowing how to error correct a symbol of 16 bits. \u2013\u00a0Luke Presland Apr 9 '13 at 14:36\nNo. The table above is general, in the sense that it can be used to generate a coding scheme for different sizes. But you must fix that size (raw data size and encoded size) beforehand, and the decoder must know it. \u2013\u00a0leonbloy Apr 9 '13 at 14:41\nIndeed. The example I am stuck on is a fixed length of 16 bits. I'm not sure if I'm just not explaining this correctly, but I have worked through examples of 12 bits, which I understand. But 16 bits is just confusing. \u2013\u00a0Luke Presland Apr 9 '13 at 14:46\nup vote 3 down vote accepted\n\nIf the encoded size is 16, this means that the raw size was 11, and the last bit is a useless parity bit, with value zero, that only checks itself. If it's zero, then it's ok, if it's 1 its an error. Of course, to chose this Hamming code of length 16 would be a stupid thing to do, because we are sending a bit with no useful information or error detection capability.\n\nshare|cite|improve this answer\nThanks for your answer! When you say 1 means it is an error. Is this effecting the data stream or does it have no effect? \u2013\u00a0Luke Presland Apr 9 '13 at 15:05\nThe error affected only the parity bit, so \"the correction\" for the data is trivial: do nothing. \u2013\u00a0leonbloy Apr 9 '13 at 15:09\nAh thank you. I hope my question wasn't too trivial. \u2013\u00a0Luke Presland Apr 9 '13 at 15:14\nNot, it wasn't. \u2013\u00a0leonbloy Apr 9 '13 at 15:16\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/161707/is-there-an-efficient-algorithm-to-compute-a-minimal-polynomial-for-the-root-of\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nAn algebraic number is defined as a root of a polynomial with rational coefficients.\n\nIt is known that every algebraic number $\\alpha$ has a unique minimal polynomial, the monic polynomial with rational coefficients of smallest degree of which $\\alpha$ is a root.\n\nIt is also known that the algebraic numbers are algebraically closed, meaning that any polynomial with algebraic numbers as coefficients has algebraic roots.\n\nMy question is:\n\nGiven the root of a degree $d$ uni-variate polynomial with $n$ terms with algebraic coefficients, is there an efficient (i.e. polynomial time in $d$ and $n$) algorithm to generate its minimal polynomial?\n\nI have searched the literature, but found very little work on algebraic number theory concerned with computational complexity. The closest result I found is:\n\nTheorem 1.4.7 in Lovasz's book:\n\nbut I don't think this (quite) answers my question.\n\nshare|cite|improve this question\nIf there is no algorithm for computing the minimal polynomial, an efficient algorithm for finding any polynomial with rational coefficients for which this number is a root, will suffice. \u2013\u00a0dan8394 Jun 22 '12 at 16:32\nOne generally finds the minimal polynomial of an algebraic number, not of a polynomial. Could you please clarify your question? \u2013\u00a0Ragib Zaman Jun 22 '12 at 16:33\nI have done so. Thanks for your careful reading! \u2013\u00a0dan8394 Jun 22 '12 at 16:35\nThanks, and no problem. \u2013\u00a0Ragib Zaman Jun 22 '12 at 16:35\n\nSuppose you have a finite field extension $\\mathbb Q \\subset K$ and an irreducible polynomial $P \\in K[X]$.\n\nLet $L$ be the Galois closure of $K$, $G$ be the Galois group of $\\mathbb Q \\subset L$, and $H$ be the subgroup of $G$ fixing $K$. Then $G$ acts on $L[X]$ by $\\sigma(\\sum a_i X^i) = \\sum \\sigma(a_i)X^i$, and $H$ is still the subgroup of $G$ fixing $K[X]$.\n\nThen define $\\tilde{P} = \\prod_{\\sigma \\in G/H} \\sigma(P)$. For any $\\sigma$ in $G$, $\\sigma(\\tilde{P}) = \\tilde P$, thus $\\tilde P \\in \\mathbb Q[X]$, and I think it should be irreducible over $\\mathbb Q$ if $K$ is the extension generated by the coefficients of $P$. And so far, the computation is polynomial in the degree of the extension $\\mathbb Q \\subset L$ (which may be exponential in the degree of $K$) and in the degree of $P$.\n\nIf you don't know exactly what $L$ and $G$ are but you know the set of conjugates $C_i$ of each coefficient $a_i$ of $P$, define $$\\tilde P = \\prod_{(b_0, \\ldots, b_n) \\in C_0 \\times \\ldots \\times C_n} (b_0 + b_1 X + \\ldots b_n X^n)$$ This will produce a polynomial in $\\mathbb Q[X]$, but can be extremely larger than the minimal polynomial.\n\nHere you pick one conjugate for each coefficient, and you do the product for all possible simultaneous choices of those conjugates. If you have one coefficient with 2 conjugates and another one with 3, and all the other coefficients are rationals, then you have 6 polynomials to multiply.\n\nFinally, if you don't know the conjugates of the coefficients but you know some annihilating polynomial for each coefficient, let $C_i$ be a set of formal roots of those polynomials, and formally expand that product. You will get an expression involving the formal roots symmetrically so you can write it using the elementary symmetric polynomials of those roots, and then use the Viete relations and replace those with the corresponding coefficients of your annihilating polynomials.\n\nHowever, these two methods can be exponential in the degree of $P$, so you should avoid them if possible.\n\nIn the worst case scenario, the Galois group of $\\mathbb Q \\subset K$ will be $S_n$, meaning that we have to do calculations in a very big field extension.\n\nsuppose $K$ is of degree $n$ and $P$ is of degree $d$. We can estimate of the generic formula you need to use to transform $P$ into a polynomial with rational coefficients.\n\nPick $L = \\mathbb Q(Y_1, \\ldots, Y_n)$, let $Z_1, \\ldots, Z_n$ be the elementary symmetric polynomials in $Y_i$, pick $K_0 = L^{S_n} = \\mathbb Q(Z_1, \\ldots, Z_n)$, and $K = K_0(Y_1)$ So the extension $K_0 \\subset K$ is the \"generic\" extension of degree $n$ over $\\mathbb Q$. Then say $P = \\sum a_i X^i$, where $a_i \\in K = K_0[Y_1]$ and are of degree $ < n$. So you can write $P = \\sum b_{i,j} X^i Y_1^j$ where $b_{i,j} \\in K_0$, and $(i,j) \\in \\{0 \\ldots d \\} \\times \\{0 \\ldots n \\}$. Add indeterminates $B_{i,j}$, so that now $P$ is an element of $K[B_{i,j},X]$. We can compute the product $\\prod_{k=1}^n P(Y_k,B_{i,j},X)$ in $L[B_{i,j},X]$, then since it is symmetric, write it as an element of $K_0[B_{i,j},X]$. In fact since the coefficients of $P$ are polynomials in $Y_1$ with integer coefficients, this will be a polynomial in $\\mathbb Z[Z_i, B_{i,j},X]$ of degree $dn$ in $X$, homogeneous of degree $n$ in the $B_{i,j}$.\n\nFor any choice of $n$ indeterminates among the $B_{i,j}$, $B_{i(1),j(1)} \\ldots B_{i(n),j(n)}$ will appear accompanied with $X^{i(1)+\\ldots i(n)}$ and a polynomial in $Z_k$ of degree $j(1)+\\ldots j(n) \\le n^2$ in $Y_k$. So we obtain less than about $(n+d)!/n!d! * n^{2n}/n!$ terms in the final polynomial. Though there may be a better bound on the complexity of polynomials in $Z_k$ that are of a given degree less than $n^2$ than $n^{2n}/n!$ (in particular, not all of them should be able to appear).\n\nWell the good thing it that this is polynomial in $d$ when $n$ is fixed, and is probably exponential in $n$ when $d$ is fixed. And when both of them vary, it's exponential in $d$ and $n$.\n\nshare|cite|improve this answer\nThank you. These are some promising ideas. Can you clarify your notation in the equation? Is $\\times$ a Cartesian product? What fixes the order of conjugates in that expression? \u2013\u00a0dan8394 Jun 23 '12 at 8:04\nTo clarify, I am interested in worst case complexity. Your answer seems to imply that the best-known algorithms are exponential in run time. Is there a rigorous way to prove this? My investigations in Mathematica also support this conclusion. \u2013\u00a0dan8394 Jun 23 '12 at 8:58\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/15055/finding-distribution-parameters-of-a-gaussian-mixture-distribution\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nShort version: how to estimate the parameters of a mixture of multivariate normal distributions (i.e.: Gaussian mixture model)?\n\nLong version.\n\nI am trying to estimate the parameters of a mixture of multivariate Gaussian distribution.\n\nI know how to do it for a single multivariate normal distribution:\n\ndataSet = RandomVariate[dist, 300];\nestDist = EstimatedDistribution[dataSet, MultinormalDistribution[{m1, m2}, {s11, s12}, {s12, s22]}}]]\n\nPlot[{PDF[dist, {x, 0}], PDF[estDist, {x, 0}]}, {x, -4, 4}, Filling -> Axis]\nPlot3D[PDF[estDist, {x, y}], {x, -2, 2}, {y, -2, 2}]\n\nSimilarity of PDF at y=0, density of dataset and estimated density.\n\nAll fine and dandy. However, the same approach does not work for me with mixture distributions. In particular, I am interested in mixtures of Gaussian distribution (Gaussian Mixture Model).\n\nI generate a sample dataset:\n\ntargetDist = MixtureDistribution[{1/3, 2/3}, {MultinormalDistribution[{0, 0}, {{1, 0}, {0, 1}}], MultinormalDistribution[{3, 3}, {{1, 0}, {0, 1}}]}];\ndataSet = RandomVariate[targetDist, 500];\n\nMixture of Gaussians\n\nI try to find the estimated distribution with:\n\nestimatedDist = EstimatedDistribution[dataSet,\n    MixtureDistribution[{w1, w2}, {\n        MultinormalDistribution[{m11, m12}, {{s111, s112}, {s112, s122}}],\n        MultinormalDistribution[{m21, m22}, {{s211, s212}, {s212, s222}}]\n\nBut the evaluation always fails with:\n\nNMaximize::cvdiv: Failed to converge to a solution. The function may be unbounded. >>\n\nFor some reason, it works if, instead of using MultinormalDistribution I use BinormalDistribution with $\\rho$=0.\n\nI know how to estimate these parameters using the Expectation Maximization algorithm, but I was wondering if there is a Mathematica-friendly way to do it.\n\n\nGiving initial estimates of the parameters does not really improve much. Even when giving the exact parameters like this:\n\nestimatedDist = EstimatedDistribution[dataSet, \n        {w1, w2},\n        {MultinormalDistribution[{m11, m12}, {{s111, s112}, {s121, s122}}],\n         MultinormalDistribution[{m21, m22}, {{s211, s212}, {s221, s222}}]}],\n        {{w1, 1/3}, {w2, 2/3}, {m11, 0}, {m12, 0}, {s111, 1}, {s112, 0}, {s121, 0}, {s122, 1}, {m21, 3}, {m22, 3}, {s211, 1}, {s212, 0}, {s221, 0}, {s222, 1}}]\n\nEstimatedDistribution seems to take much more time than what it would be reasonable (and, since the estimates are exact, \"reasonable\" means 0.1 sec).\n\nAfter about 15 minutes of processing on a 3.3GHz Xeon, I got this error:\n\nFindMaximum::eit: The algorithm does not converge to the tolerance of\n4.806217383937354`*^-6 in 500 iterations. The best estimated solution,\nwith feasibility residual, KKT residual, or complementary residual of\n{2.1536*10^-12,0.00200273,5.6281*10^-13}, is returned. >>\n\nThen a popup message:\n\nClick here to find out if this problem is known, and to help improve\nMathematica by reporting it to Wolfram Research.\nshare|improve this question\nYou are aware that you can supply EstimatedDistribution[] with initial estimates of parameters? \u2013\u00a0J. M. Nov 22 '12 at 14:19\n@J.M. Please see my edit. Using the exact parameters as estimation seems just to avoid divergence, but EstimatedDistribution still fails to return a meaningful result. \u2013\u00a0Giuseppe Cardone Nov 22 '12 at 15:15\nup vote 9 down vote accepted\n\nYou need to make sure that the constraints on the parameters are satisfied. In this case, these are\n\n1) The mixture weights sum to one. 2) The covariance matrices of the two bivariate normals need to be positive definite.\n\nThe first constraint can be guaranteed by specifying the weights as follows:\n\nw1 = Exp[w]/(1 + Exp[w]);\n\nwhere w is unconstrained.\n\nThe second constraint can be enforced by using the Cholesky Decomposition of the covariance matrices as below.\n\nc1 = {{c111, 0}, {c112, c122}};\n\nwhere c1 is a lower triangular matrix of unrestricted elements. The resulting covariance matrix is given by s1 below.\n\ns1 = c1.Transpose[c1]\n\nOut[9]= {{c111^2, c111 c112}, {c111 c112, c112^2 + c122^2}}\n\nSimilarly, we have for the other covariance,\n\ns2 = c2.Transpose[c2];\n\nLet the two mean vectors be\n\nm1 = {m11, m12};\n\nm2 = {m21, m22};\n\nThe mixture pdf can be written as\n\nIn[15]:= mixPDF = MixtureDistribution[{w1, 1 - w1}, \n  {MultinormalDistribution[m1, s1], \n   MultinormalDistribution[m2, s2]\n\nOut[15]= MixtureDistribution[{E^w/(1 + E^w), \n  1 - E^w/(1 + E^w)}, {MultinormalDistribution[{m11, \n    m12}, {{c111^2, c111 c112}, {c111 c112, c112^2 + c122^2}}], \n    m22}, {{c211^2, c211 c212}, {c211 c212, c212^2 + c222^2}}]}]\n\nThen one may get what you are looking for, depending upon starting values.. The first try here does not give the correct answer.\n\nIn[16]:= est1 = EstimatedDistribution[dataSet, mixPDF]\n\nOut[16]= MixtureDistribution[{0.0172133, \n  0.982787}, {MultinormalDistribution[{1.37871, \n    0.821044}, {{4.88591, 1.35155}, {1.35155, 0.373881}}], \n    1.88312}, {{3.0206, 2.01692}, {2.01692, 3.08025}}]}]\n\nSpecifying starting values helps.\n\nIn[17]:= est2 = \n  mixPDF, {{m11, - 0.5}, {m12, 0.8}, {m21, 1.5}, {m22, 2.0}, {c111, \n    1.5}, {c112, 0.0}, {c122, 1.0}, {c211, 1.5}, {c212, 0.0}, {c222, \n    1.0}, {w, 0.2}}]\n\nOut[17]= MixtureDistribution[{0.39772, \n  0.60228}, {MultinormalDistribution[{0.110727, \n    0.110757}, {{1.05393, 0.060291}, {0.060291, 1.07923}}], \n    3.02315}, {{0.84418, -0.148054}, {-0.148054, 0.982491}}]}]\n\nAn alternative approach can use FindDistributionParameters as follows\n\nest3 = FindDistributionParameters[dataSet, \n  mixPDF, {{m11, 0.0}, {m12, 0.0}, {m21, 2.5}, {m22, 3.0}, {c111, \n    1.0}, {w, 0.5}}]\n\nOut[18]= {m11 -> 0.110727, m12 -> 0.110757, m21 -> 3.0927, \n m22 -> 3.02315, c111 -> 1.02661, c112 -> 0.0587281, c122 -> 1.0372, \n c211 -> 0.918792, c212 -> -0.16114, c222 -> 0.978021, w -> -0.414975}\n\nThe original parameters can be obtained as\n\nIn[19]:= {w1, 1 - w1, m1, s1, m2, s2} /. est3\n\nOut[19]= {0.39772, 0.60228, {0.110727, \n  0.110757}, {{1.05393, 0.060291}, {0.060291, 1.07923}}, {3.0927, \nshare|improve this answer\nThis is a great answer. I hadn't realized that EstimatedDistribution doesn't take sensible constraints on the parameters into account. So, I assume that we have to use similar tactics for other distributions, right? Like n>=0 for the binomial distribution and sigma >=0 for normal distribution. \u2013\u00a0Sjoerd C. de Vries Jul 3 '13 at 21:03\n\nYou may have more success creating your own custom mixture distribution.\n\nOleksandr Pavlyk created a presentation about creating distributions in Mathematica for the Wolfram Technology Conference 2011 workshop:\n\n'Create Your Own Distribution'.\n\nYou can download it here.\n\nThe downloads include the notebook,\n\n\nthat seems to lay out all the pieces required to create a distribution that one can use like the distributions that come with Mathematica.\n\nIt takes some time and thought to set up all of the pieces, but once done your custom distribution can work like a charm.\n\nshare|improve this answer\nI think that defining a new distribution would be much more difficult that implementing the EM algorithm, which is relatively simple. \u2013\u00a0Giuseppe Cardone Nov 23 '12 at 20:13\nI cant seem to find the .nb file? \u2013\u00a0Chen Stats Yu Dec 19 '14 at 1:04\n@ChenStatsYu -- Send me an email and I can send you the notebook. You can find my address in my profile. \u2013\u00a0Jagra Dec 19 '14 at 14:04\n@Jagra Sorry about the confusion. I finally got the notebook. I will give it a go. I am having some trouble optimizing a likelihood from a mixture distribution. I wonder define an implicit PDF will have a better way to find mle. \u2013\u00a0Chen Stats Yu Dec 19 '14 at 14:17\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-total-current.82840/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the total current\n\n  1. Jul 21, 2005 #1\n    A coil of self-inductance 0.7H is joined in parallel with a non-inductive resistance of 50 ohm. Calculate the total current, the current throught the wattless and power components when connected to a supply of 200V at a frequency of 50Hz.\n\n    Here is my steps:\n    Impedance Z= root [ 50^2 + (2pi*50*0.7)^2 ] = 225.5 ohm\n    Total current = 200/ Z = 0.9756A\n\n    Am I right? as for the other two questions, i really don't know how to solve them. :confused: Please help me with it. Thank you!\n\n  2. jcsd\n  3. Jul 21, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have treated the resistor and coil as a series combination. The problem says they are in parallel.\n\n\n    When you do the first part correctly, you will be able to find the total current. You can find the current in each branch, and therefore in each device using the individual impedences and the applied voltage.\n    Last edited: Jul 21, 2005\n  4. Jul 21, 2005 #3\n    the equation for total impedance Z you used above would apply to a series circuit with coil inductance 0.7H and resistor resistance 50 ohms.\n    however, in this case, these 2 components are in parallel, and you would first need to compute Ztotal using (complex impedances):\n\n    [tex] \\frac{1}{Z_{total}} \\ = \\ \\frac{1}{Z_{coil}} \\, + \\, \\frac{1}{Z_{resistor}} [/tex]\n\n    and then use:\n\n    [tex] Total \\ Current \\ Magnitude \\ = \\ \\frac{200 \\ Volts}{|Z_{total}|} [/tex]\n\n    an easier method for this parallel circuit is to sum the currents thru each branch of the parallel circuit:\n\n    [tex] \\mbox{Current Thru Coil} \\ = \\ \\frac{200}{2 \\pi (50)(0.7)\\mathbf{j}} [/tex]\n\n    [tex] \\left ( \\ \\ \\mbox{Current Magnitude Thru Coil} \\ = \\ \\left | \\, \\frac{200}{2 \\pi (50)(0.7)\\mathbf{j}} \\, \\right | \\ = \\ \\frac{200}{2 \\pi (50)(0.7)} \\ \\ \\right ) [/tex]\n\n    [tex] \\mbox{Current Thru Resistor} \\ = \\ \\frac{200}{(50)} [/tex]\n\n    [tex] \\mbox{Total Current Magnitude} \\ = \\ \\, \\left \\Large | \\, \\mbox{Current Thru Coil} \\ + \\ \\mbox{Current Thru Resistor} \\, \\right | [/tex]\n\n    this also answers the last 2 questions of your problem.\n    (*** Clarifications/corrections added from suggestions by OlderDan ***)\n    Last edited: Jul 21, 2005\n  5. Jul 21, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The currents are not in phase. You cannot simply add them. Your first equation is valid only if complex impedences are used. I fixed the link in my earlier post. Check it out.\n  6. Jul 21, 2005 #5\n    Hello olderdan and geosonel, thank you for your help. I realise I have treated the problem wrongly. However, when I follow your method, i get the total current to be 4.9095 ohm; and the answer given is 0.8865A. Yet, the other two answers are 0.8642A and 0.1964A respectively, which do not add up to 0.8865A...What do you think? :)\n  7. Jul 21, 2005 #6\n    OlderDan -- your comments are, of course, correct.\n    the entire Msg #3 was originally intended to incorporate COMPLEX impedances and use complex representations. clarifications/corrections have been added based on your suggestions.\n\n    Clari --\n    changes were made to Msg #3 to better indicate the COMPLEX representations of the various quatities. do you know how to use these complex representations? specifically, the total current would be equal to:\n    total current = (complex current thru coil) + (complex current thru resistor)\n    = (-0.9095j) + (4)\n\n    total current MAGNITUDE = | (-0.9095j) + (4) |\n\n    [tex] \\ = \\ \\sqrt{(0.9095)^{2} + (4)^{2}} \\ = \\ 4.102 \\ amps [/tex]\n\n    the individual current magnitudes must be combined like shown above because the current thru the coil and current thru the resistor are out of phase (which is why they are represented by complex quantities).\n\n    apparently the book is wrong about the answer. either that or you may have made a careless error in copying the problem. you might double check the problem.\n  8. Jul 21, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I think you have not treated the impedence as complex when calculating the equivalent impedence, and the unit of \"ohm\" in your result should be \"amp\". I see no way of getting the answers you have been given. A 50 ohm resistor by itself connected to a 200 volt supply would give a 4 amp current. A parallel path through the 0.7H inductor would give a current of 0.9095 amp at 50 hz that is 90 degrees out of phase with the resistor current. You cannot simply add these two (which is effectively what you did by not calculating the equivalent impedence correctly) because they are out of phase, but even when added correctly they still add up to about 4.10 amps, which is a lot more than the answers you are given.\n\n    EDIT: Late to the party again :smile: See geosonel's reply for more detail on the calculations\n\n    Please check the problem and make sure you are stating it correctly. The ratio of the currents given for the separate currents is about right. Is there something else in series with the parallel combination? Do you have the voltage right?\n    Last edited: Jul 21, 2005\n  9. Jul 23, 2005 #8\n    I think your answers are right, while those given by my teacher are wrong, so i believe i know how to sort it out now. ^^ Thank you very much!! :smile:\n\n    To geosonel, i haven't learned anything about the RLC circuit in parallel in fact, so i know nothing about complex representations. What is j in:\n    To olderdan, i have stated out the problems clearly, and there's certainly nothing in series with the parallel combination.\n  10. Jul 23, 2005 #9\n    Clari -\n    we didn't know your mathematical background when suggesting the \"complex representation\" method for AC circuits. unfortunately, it's difficult to provide a complete tutorial on AC circuit methods in this forum.\n\n    if you're interested in learning what the \"j\" signifies in the previous msgs and how the \"complex representation\" method works, try the tutorial given in the URL link below. (this tutorial takes 8 pages, including the introduction). this link also provides good info on many other electronic circuit topics.\n    Last edited: Jul 23, 2005\n  11. Jul 23, 2005 #10\n\n\n    User Avatar\n    Homework Helper\n\n    I have done the problem with very basic method by taking voltage V = v(max)sin(wt)\n    taking the total instantaneous current then finding the rms value of it using integration method and got the same answer 4.102 A as by geosonel\n    Last edited: Jul 23, 2005\n\nHave something to add?\n\nSimilar Discussions: Calculate the total current\n  1. Calculating current (Replies: 2)\n\n  2. Calculating current (Replies: 3)\n\n  3. Calculating Current (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/volume-of-a-solid.3590/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nVolume of a solid\n\n  1. Jul 4, 2003 #1\n    I need help on this problem which is giving me a few headaches...!!!!\n\n    here goes..\n\n    Show that the volume of the solid bounded by the coordinate planes and the plane tangent to the portion of the surface xyz = k, k>0, in the first octant does not depend on the point of tangency.\n\n    Your help will be much appreciated.\n  2. jcsd\n  3. Jul 4, 2003 #2\n    OK, i think i have the answer. i make it 9k/2. how much help do you want?\n\n    my first hint: the normal to that surface can be found by taking the gradient.\n  4. Jul 4, 2003 #3\n    Hi lethe,\n\n    I am totally lost on this question to be honest and I can't seem to work out what to do here to solve it. I would really appreciate it if you could explain step by step what you are doing so I can understand how you came to your conclusion and your answer.\n\n    eg. how you came to your answer of 9k/2.\n\n    and also your hint: the normal to that surface can be found by taking the gradient.\n\n    How would you go about solving this?\n\n    Your help will be greatly appreciated.\n  5. Jul 4, 2003 #4\n\n    step 1: the gradient of xyz - k gives you the normal vector to the surface.\n\n    the gradient is (yz,xz,xy)\n\n    step 2: the equation for a plane with normal vector n is n*(x-x0)=0\n\n    so the equation for the tangent plane at x0 is y0z0(x-x0)+x0z0(y-y0)+x0y0(z-z0)=0\n\n\n    x/x0 + y/y0 + z/z0 = 3\n\n    step 3: find the three coordinate intercepts of this plane by plugging in x=y=0 and get z=30, then x=z=0 and get y=3y0, and x=3x0\n\n    step 4: calculate the volume. it is a right pyramid, the base has legs 3x0 and 3y0, so the area of the base is 9x0y0/2. the area for a pyramid is 1/3*Base*height, so this is 9x0y0z0/2, but since x0 is on the surface, x0y0z0 = k, and we get 9k/2 for the volume\n  6. Jul 5, 2003 #5\n    Hey thanks for your help lethe!\n\n\nHave something to add?\n\nSimilar Discussions: Volume of a solid\n  1. Volume of a solid (Replies: 1)\n\n  2. Solid angle (Replies: 7)\n\n  3. Imaginary volume (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/intersection-of-two-functions.265279/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntersection of two functions\n\n  1. Oct 17, 2008 #1\n    (Problem from practice math subject GRE exam:) At how many points in the xy-plane do the graphs of [tex]y=x^{12}[/tex] and [tex]y=2^x[/tex] intersect?\n\n    The answer I got was 2, but the answer key says 3.\n\n    Intuitively, by the shape of their graphs, I would say two. I tried to calculate actual values for x:\n\n\n    [tex]x\\ln2=12\\ln x[/tex]\n\n    [tex]\\frac{\\ln2}{12}=\\frac{\\ln x}{x}[/tex]\n\n\n    I don't know what to do with that last equation.\n\n    I'm really confused though, because I can't even imagine how they would get a third intersection. Any help would be appreciated. :)\n  2. jcsd\n  3. Oct 18, 2008 #2\n    It's pointless to try to solve a transcendental equation analytically. Remember that x^12 is an even function, and note that 2^x approaches 0 as x approaches -infinity, but also remember that when x=0 that x^12 = 0, so you know that the two plots cross once for x < 0. You might guess they cross once for x>=0, but think about when x is > say 1000 and when x is say 2. Which function is larger in each case? Which is larger at x=0? Which is larger for x = -1000?\n  4. Oct 18, 2008 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Clearly the graph of y= 2x crosses the graph of y= x12 for x somewhere between -1 and 0: 2-1= 1/2 and (-1)12= 1 so the graph of x12 is higher for x= -1 while, at x= 0, 20= 1 and 012= 0 so the graph of 2x is higher for x= 0.\n\n    Also 212= 4096 while 22= 4: the graph of x12 is higher again so the graph must intersect again between x= 0 and x= 2.\n\n    The question, then, is whether the graphs intersect a third time for x> 2; whether 2x is larger than x12 for \"sufficiently large x\".\n\n    One way to answer that is to look at the limit of 2x/x12 as x goes to infinity. Since that fraction itself becomes \"infinity over infinity\" we can apply L'Hopital's rule. Repeatedly differentiating, the numerator just stays 2x (times a power of ln(2)) while the denominator has lower and lower powers eventually becoming a constant (after 12 differentiations, we get 12!) and then 0. What does that tell you about the limit? And what does that tell you about whether 2x or x12 is larger for very large x?\n  5. Oct 18, 2008 #4\n    Thanks! This makes sense. So...\n\n\n    Which means that for very large x, 2^x does eventually exceed x^12, which gives us the third intersection point.\n\n    So, one last question -\n\n    Is this a good general strategy for this type of problem (if I were to get a similar one on the actual exam): First sketch the graph and see what obvious/immediate intersection points I can find. Then use the limit idea for [tex]x\\rightarrow\\infty[/tex] and [tex]x\\rightarrow-\\infty[/tex].\n\n    Will this ensure that I find all of my intersection points?\n\n    Thanks so much! :)\n  6. Oct 18, 2008 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Not necessarily. For example, it there were 3 more intersections between x= 2 and infinity, the same changes in which is smaller and which is larger would be true. You might try looking at the derivative of f- g. If that is always positive, then that can't happen.\n\nHave something to add?"}
{"text": "Retrieved from http://maa.org/frank-morgans-math-chat-mathfest-99-primes-and-prizes\nText:\nYou are here\n\nFrank Morgan's Math Chat - MATHFEST '99: PRIMES AND PRIZES\n\nAugust 5, 1999\n\nLast weekend over 1100 gathered in Providence for the summer MathFest of the Mathematical Association of America. Hedrick lecturer Carl Pomerance, recently of the University of Georgia and now at Bell Labs, with his marvelous understated humor, gave fascinating accounts of prime numbers. The largest known prime, discovered by Nayan Hajratwala on June 1, is 26,972,593 - 1, a \"Mersenne\" number of the form 2p - 1 (with the exponent p itself prime). It is an open question whether infinitely many Mersenne numbers are prime, or even whether infinitely many Mersenne numbers are not prime! It is well known, however, that there are infinitely many primes. Indeed, the Prime Number theorem says that the number of primes less than x is on the order of x/log x. The Riemann Hypothesis, perhaps the most important outstanding conjecture in mathematics, gives a more accurate estimate.\n\nNew prize winners included Ravi Vakil of MIT, who won the Trevor Evans award for his article on \"The youngest tenured professor in Harvard's history\" in Math Horizons (September, 1998). The article describes Noam Elkies's triumphs as a high school student in the Math Olympiad, his work in number theory, and his achievements in chess and music. More on the Math Olympiad appears in Vakil's book, A Mathematical Mosaic: Patterns and Problem-Solving.\n\nThe MAA Board of Governors discussed plans for Special Interest Groups in the MAA (\"SIGMAAs\") and for a new popular magazine.\n\nUS CHIEF JUSTICE WILLIAM REHNQUIST won a Washington Post quiz, \"What auto is referred to in a license plate that reads 1 DIV 0?\" with his answer:\n\n\"I believe it refers to an Infiniti, since when you divide 0 into 1, the result is infinity.\"\n\nBut is it legal to divide by 0? (Reuters, as reported in The Christian Science Monitor of 14 July 1999.)\n\n\n\n\nANSWER. No, by symmetry, each has expected gain 0 from swapping. The flaw in Abel's reasoning is that it is impossible for X and 10X to be equally likely! For example, if $1, $10, $100, $1000, . . ., all had the same positive probability, the total probability would be infinite instead of just 100%.\n\nElliot Kearsley and Joseph DeVincentis argue that if the possible values were say $1, $10, . . ., $1,000,000 and Abel and Beta had to agree to swap, they would never swap. Of course Abel wouldn't swap if he had $1,000,000 (so that Beta had $100,000); nor would Beta. Now if Abel had $100,000, he would know that Beta had either $1,000,000 (and Beta wouldn't swap) or $10,000; so Abel wouldn't agree to swap with $100,000; nor would Beta. Similarly if Abel had $10,000, he would know that Beta either had $100,000 (and wouldn't swap), or $1000; so Abel wouldn't agree to swap, and so on. Of course if Abel had just $1, he could agree to swap, but Beta with $10 would not, by the conclusion of the reasoning above.\n\n(Actually the flaw in this argument is that Abel and Beta could have more complicated strategies of swapping with certain probabilities. Abel might decide to swap occasionally with $1,000,000 just to tempt Beta into swapping with $100,000 when Abel really had only $10,000.)\n\nThis challenge partly resembles \"The Wallet Paradox\" described by Merryfield, Viet, and Watson in The American Mathematical Monthly of August-September 1997, in which Abel and Beta have to decide whether to swap wallets.\n\nNEW CHALLENGE (via Charles Chace). Consider a statement of the form\n\n\nIs this a logical truth? What if\n\nP is \"ai is monotone\"\n\nQ is \"ai is bounded\"\n\nR is \"ai is convergent\"\n\n(where ai represents a sequence of real numbers).\n\n\nCopyright 1999, Frank Morgan."}
{"text": "Retrieved from http://math.stackexchange.com/questions/142347/denumerable-and-infinite-sets\nText:\nSign up \u00d7\n\nIf $A$ is an infinite set and $B$ is denumerable, $A$ is equipotent with the union $A\\cup B$.\n\nHow to prove this?\n\nshare|cite|improve this question\nWhat is your definition of \"infinite set\"? (Seriously; there are a couple of ways of defining it, and some lead to easy proofs of this, others less so). Also, are you working with the Axiom of Choice? \u2013\u00a0Arturo Magidin May 7 '12 at 19:46\nYes im working with the AC, and the book im studying defined infinite set as a set that is not equipotent with a natural number n \u2013\u00a0Katlus May 7 '12 at 19:48\nHave you proven that every infinite set has a denumerable subset? \u2013\u00a0Arturo Magidin May 7 '12 at 19:49\nYa i proved that \u2013\u00a0Katlus May 7 '12 at 19:50\nWith the axiom of choice, $|A|$ is some cardinal and $|B| = \\aleph_0$. $|A \\cup B| \\leq |A| + |B| = \\text{max}(|A|, |B|) = |A|$ since $|B| = \\aleph_0$ is the smallest infinite cardinal. \u2013\u00a0William May 7 '12 at 19:51\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $B'=B\\setminus A$. If $B'$ is finite, then biject $B$ with $A\\cap B$, and use that bijection to biject $A\\cup B = A\\amalg B'$ with $A$ (where $\\amalg$ denotes a disjoint union).\n\nIf $B'$ is infinite, let $D$ be a denumerable subset of $A$. Then biject $D\\amalg B'$ with $D$, and use that bijection to get a bijection of $A\\cup B = A\\amalg B'$ with $A$.\n\n(This requires you to prove that the union of two disjoint denumerable sets is denumerable; I trust you know how to do that)\n\nshare|cite|improve this answer\nI proved it.. But this problem precedes the problem 'union of two denumerable sets is denumerable'. Do you have any easier proof? \u2013\u00a0Katlus May 7 '12 at 20:56\n@Katlus: I suspect there are ways of doing it, but I can't think of any off the top of my head; you could break up the cases with $B'$ infinite according to whether $B\\cap A$ is finite or infinite, but I don't think it will be any simpler \u2013\u00a0Arturo Magidin May 8 '12 at 1:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/823601/divergent-complex-sequence-with-distinct-points-and-without-accumulation-point-t\nText:\nSign up \u00d7\n\nIs it true that any Divergent complex sequence with distinct points and without accumulation point tends to $\\infty$ ? (One can also replace distinctness condition by condition finitely repeating terms)\n\nI think it's true as my intuition, but tried to prove this as follows :\n\nBy contradiction, suppose $\\{z_i\\}$ are bounded, that is: $\\forall n\\,:\\,|z_n|\\in D_M$. Now as sequence doesn't have accumulation point and $D_M$ is open, all points of the sequence (which their cardinality is infinite) and for each $i$, there exists $r_i$ such that : $$\\forall i\\neq j\\,:\\,D_{r_i}(z_i)\\cap\\{z_j\\}=\\emptyset\\quad\\wedge\\quad \\bigcup_{i=1}^\\infty D_{r_i}(z_i)\\subset D_M$$ From distintness, we know that the set of all these neighborhoods are infinitely countable.\n\nAny help is appreciate for the rest.\n\n\nDivergence is necessary to be determined which I have not used it yet !\n\nshare|cite|improve this question\nYou need to prove more than the fact the $z_i$ are not bounded. Try to show that any disk with centre the origin has only finitely many points of the sequence. That will basically get you there. \u2013\u00a0Andr\u00e9 Nicolas Jun 7 '14 at 6:12\nYes you're right. Thanks \u2013\u00a0Fardad Pouran Jun 7 '14 at 6:24\nYou are welcome. You added a question about divergence. That is not needed, a convergent sequence will have an accumulation point. \u2013\u00a0Andr\u00e9 Nicolas Jun 7 '14 at 6:27\nOk I meant I had not considerd this fact and i wanted to emphasize on it. \u2013\u00a0Fardad Pouran Jun 7 '14 at 6:33\n@Andr\u00e9Nicolas, Could you please give another hint ? \u2013\u00a0Fardad Pouran Jun 7 '14 at 17:58\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nHint: Take a large number $B$. If the sequence $(z_n)$ has an infinite number of terms in the disk with radius $B$, then the sequence has an accumulation point (Bolzano-Weierstrass).\n\nIt follows that for any $B$, there are only finitely many $n$ such that $|z_n|\\le B$. Therefore there is an $N=N_B$ such that if $n\\gt N$ then $|z_n|\\gt B$. This is precisely what it means for $z_n$ to go to infinity.\n\nshare|cite|improve this answer\nIndeed it was suffices for my idea to discuss on $\\bar{D}_M$ instead of $D_M$, which compactness is perfect property for sequences :) \u2013\u00a0Fardad Pouran Jun 8 '14 at 5:19\nHappy to be of help. \u2013\u00a0Andr\u00e9 Nicolas Jun 8 '14 at 5:26\nthank you . My sight over problem was limited \u2013\u00a0Fardad Pouran Jun 8 '14 at 5:42\n\nYour Answer"}
{"text": "Retrieved from http://www.pedagonet.com/mathgenius/answer257.html\nText:\nAnswer :\n\nThe correct answer is 1,992 different ways.\u00a0\nEvery F is either a corner F or a side F\u2014standing next to a corner in its own square of F's.\u00a0\nNow, FIED may be read from a corner F in 16 ways; therefore DEIF may be read into a corner F also in 16 ways; hence DEIFIED may be read through a corner F in 16\u00a0\u00d7\u00a016\u00a0=\u00a0256 ways.\u00a0\nConsequently, the four corner F's give 4\u00a0\u00d7\u00a0256\u00a0=\u00a01,024 ways.\u00a0\nThen FIED may be read from a side F in 11 ways, and DEIFIED therefore in 121 ways.\u00a0\nBut there are eight side F's; consequently these give together 8\u00a0\u00d7\u00a0121\u00a0=\u00a0968 ways.\u00a0\nAdd 968 to 1,024 and we get the answer, 1,992.\n\nIn this form the solution will depend on whether the number of letters in the palindrome be odd or even.\u00a0\nFor example, if you apply the word NUN in precisely the same manner, you will get 64 different readings; but if you use the word NOON, you will only get 56, because you cannot use the same letter twice in immediate succession (since you must \"always pass from one letter to another\") or diagonal readings, and every reading must involve the use of the central N.\n\nThe reader may like to find for himself the general formula in this case, which is complex and difficult. I will merely add that for such a case as MADAM, dealt with in the same way as DEIFIED, the number of readings is 400.\n\nMath Genius"}
{"text": "Retrieved from http://math.stackexchange.com/questions/2356/is-it-possible-to-split-coin-flipping-3-ways/620526\nText:\nSign up \u00d7\n\nWhen flipping a coin to make important decisions in life you can flip once to choose between 2 possible outcomes. (Heads I eat cake, Tails I eat chocolate!)\n\nYou can also flip twice to choose between 4 outcomes. (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads)\n\nCan you use a coin to choose evenly between three possible choices? If so how?\n\n(Ignoring slight abnormalities in weight)\n\nshare|cite|improve this question\nSee also:\u2026 \u2013\u00a0Isaac Aug 13 '10 at 15:55\n@Isaac: Your link is an exact duplicate. Why wasn't this question closed? \u2013\u00a0Casebash Aug 13 '10 at 23:39\nMeta discussion here:\u2026 \u2013\u00a0Tom Boardman Aug 14 '10 at 0:08\nfind a coin with a large edge, so that the probability it falls on the edge is 1/3. now you only need one toss :) \u2013\u00a0user20963 Dec 10 '11 at 6:05\n@Nico: Or just flip a coin in a world where 2 = 3... not very useful answer. \u2013\u00a0The Chaz 2.0 Dec 10 '11 at 10:11\n\n8 Answers 8\n\nup vote 17 down vote accepted\n\nIf you throw your coin $n$ times you have $2^n$ outcomes, the probability of each of which is $\\frac{1}{2^n}$. The larger $n$ is, the better you can divide $2^n$ into three approximately equal parts:\n\nJust define $a_n=[2^n/3]$ and $b_n=[2\\cdot 2^n/3]$, where $[\\cdot]$ denotes rounding off (or on). Since $\\frac{a_n}{2^n}\\to\\frac{1}{3}$ and $\\frac{b_n}{2^n}\\to\\frac{2}{3}$ as $n\\to\\infty$, each of the three outcomes\n\n\"the number of Heads is between $0$ and $a_n$\",\n\n\"the number of Heads is between $a_n$ and $b_n$\", and\n\n\"the number of Heads is between $b_n$ and $2^n$\"\n\nhas approximately the probability $\\frac{1}{3}$.\n\nAlternatively, you could apply your procedure to get four outcomes with the same probability (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads) to your problem in the following way:\n\nAssociate the three outcomes Heads-Heads, Tails-Tails, Heads-Tails with your three possible choices. In the case that Tails-Heads occurs, just repeat the experiment.\n\nSooner or later you will find an outcome different from Tails-Heads.\n\nIndeed, by symmetry, the probability for first Heads-Heads, first Tails-Tails, or first Heads-Tails is $\\frac{1}{3}$, respectively.\n\n(Alternatively, you could of course throw a die and select your first choice if the outcome is 1 or 2, select your second choice if the outcome is 3 or 4, and select your third choice if the outcome is 5 or 6.)\n\nshare|cite|improve this answer\nCan't you count tails-heads as the same as heads-tails? \u2013\u00a0Tyler Hilton Aug 13 '10 at 15:26\n@Affan, it would not be fair as that possibility would occur with the same probability as the other two combined. \u2013\u00a0Joshua Shane Liberman Aug 13 '10 at 15:35\nOh I get ya, thanks! \u2013\u00a0Tyler Hilton Aug 13 '10 at 17:15\nI think what Rasmus meant (in the second part) is that you would always toss in pairs and take into account the order of the two tosses: only if the first toss (of a pair) is tails and the second toss is heads toss the coin another two times. \u2013\u00a0Andre Holzner Aug 19 '10 at 18:58\n\nA simple (practical, low-computation) approach to choosing among three options with equal probability exploits the fact that in a run of independent flips of an unbiased coin, the chance of encountering THT before TTH occurs is 1/3. So:\n\nFlip a coin repeatedly, keeping track of the last three outcomes. (Save time, if you like, by assuming the first flip was T and proceeding from there.)\n\nStop whenever the last three are THT or TTH.\n\nIf the last three were THT, select option 1. Otherwise flip the coin one more time, choosing option 2 upon seeing T and option 3 otherwise.\n\nshare|cite|improve this answer\n\nEDIT Oh dear, Rasmus has extended his answer and rendered this one obsolete! In fact, stop reading this right now and go see what he has done.\n\nI interpret what you are asking as trying to find a way to decide without introducing bias (as would be introduced by counting tails-heads as the same as heads-tails). Rasmus's suggestion of repeating the experiment for a certain configuration seems the best choice.\n\nI drew a little tree and tried to group outcomes into three \"equally-likely\" sets and then realized this is impossible because $3$ does not divide $2^n$ for any $n$. (The quantity $2^n$ being the number of unique outcomes after $n$ \"flips\".)\n\nshare|cite|improve this answer\n\nHere's another method: consider H to be 0 and T to be 1. Consider the results that you get from your coins as successive bits (after the binary point) in a binary number. Assign numbers in the interval [0, 1/3) to the first choice; [1/3, 2/3) to the second choice; [2/3, 1) to the third choice. Flip coins until you know, no matter what happens on the remaining flips, in which of these intervals the resulting real number in [0, 1) will lie.\n\nMore concretely, this means that if you flip two coins and observe HH, make the first choice; no matter what happens the result will be between .0000... = 0 and .001111... = 1/4. Similarly if you observe TT, make the third choice; the result will be between 3/4 and 1. If you observe HT, you can't commit to a choice yet; the result will be between 1/4 and 1/2, which overlaps two of the intervals. Something similar is true for TH.\n\nIn either case flip a third time. HTT corresponds to the interval [3/8, 1/2) which lies entirely in [1/3, 2/3), so HTT corresponds to the second choice; similarly for THH. If you see HTH you're still undecided between the first and second choices; THT is still undecided between the second and third.\n\nContinuing in this way, HTHH corresponds to the first choice, HTHT and THTH are still undecided, THTT corresponds to the third choice.\n\nIn general, for the cut-points 1/3 and 2/3, you flip coins until you get either two heads or two tails in a row. If you first get two heads in a row, this corresponds to the first choice if the initial flip was a head, the second if the initial flip was a tail. If you first get two tails in a row, this corresponds to the second choice if the initial flip was a head, the third choice if the initial flip was a tail.\n\nYou might wonder how many flips this takes, on average, to give a result. With probability 1/2 you get a result on the second flip; with probability 1/4, on the third flip; with probability 1/8, on the fourth flip, and in general with probability $1/2^{n-1}$ for $n \\ge 2$. The sum $\\sum_{n \\ge 2} n/2^{n-1}$ has value 3, so on average this method takes three flips.\n\nThis is a bit slower on average than the method Rasmus suggested, which takes on average 8/3 flips. However, the same method works even if the three choices are not equally likely! (It won't have such a clean way of being expressed as \"flip until you get two in a row\", though.)\n\nshare|cite|improve this answer\n\nIf you are at a crossroads in life requiring you to choose one of three options, then coin tossing is not the correct thing to do.\n\nRather, pick up a dice and roll it. Go for first option if the diece turns up 1 or 2. Go for second option if the dice turns up 3 or 4. Go for the third option if the dice turns up 5 or 6.\n\nEdit: Oops, I saw that Rasmus already gave this option. Anyway I strongly suggest that you prefer this one to the other two methods given by him.\n\nshare|cite|improve this answer\nWell, from the philosophically view-point, I think it's inadvisable to use random experiments for decision making anyway. \u2013\u00a0Rasmus Aug 13 '10 at 15:57\nTrue, true. But if at all someone does a random experiment for decision making, better do one that will get done in the shortest time! So your third method is more time-saving compared to the other two. \u2013\u00a0user1119 Aug 13 '10 at 16:02\n@Rasmus: From a game-theory viewpoint, it often is advisable to use a random method to make decisions. :) \u2013\u00a0Larry Wang Aug 13 '10 at 16:40\n@Kaestur Hakarl: Well... Touch\u00e9! :) \u2013\u00a0Rasmus Aug 13 '10 at 16:53\nOne of Piet Hein's grooks comes to mind: A PSYCHOLOGICAL TIP Whenever you're called on to make up your mind, and you're hampered by not having any, the best way to solve the dilemma, you'll find, is simply by spinning a penny. No -- not so that chance shall decide the affair while you're passively standing there moping; but the moment the penny is up in the air, you suddenly know what you're hoping. \u2013\u00a0Bob Durrant Sep 15 '10 at 20:49\n\nI think I have a pretty good idea where you don't have to redo at all.\n\nflip the coin to decide a side for the first two possibilities. if heads come up, its heads for option 1 and tails for option 2 or vice versa flip again to decide a side for option 3. hence, we have 3 outcomes of a coin for 3 possibilities, and all three are not the same. example: H for 1, T for 2 and T for 3, but not H or T for all 3 options.\n\nnow flip again. if the coin lands on heads, and heads is only on say, option 1, then option 1 wins. if H is on 2 options, select those 2, keep heads for 1 and tails for the other, flip again and decide. the same is applicable if it lands on tails.\n\nI hope you understand how it works and how each option has an equal chance of getting selected.\n\nyou don't have to redo your flips anywhere here. (there is a definite answer).\n\nshare|cite|improve this answer\nAn interesting idea, but I don't think it works. Option 3 is guaranteed to match one of the first two options. It will never be the lone-H or lone-T, and thus will never be selected by the first flip. Option 1 or Option 2 are thus more likely to be selected. \u2013\u00a0Nathan Kurz Mar 22 '14 at 17:46\n\nI prefer a method based on a simple unbalanced game: the first person to throw heads wins. In this game, the person who throws first has a $\\frac 23$ chance of winning, the other has a $\\frac 13$ chance of winning.\n\nTo decide fairly between three outcomes, simply put two outcomes on one team in this game, so they have a $\\frac 23$ chance of getting picked. If this team of outcomes wins, simply toss another coin to decide between them. If the other team wins, there is only one outcome on that team and so no further tosses are needed.\n\nThis method is equivalent to Rasmus's \"alternatively\" answer, and will take $2{\\frac 23}$ coin tosses on average. I don't think there exists a method with fewer average coin tosses, but I have no proof of this.\n\nshare|cite|improve this answer\n\nConsider a similar problem and answer first that happens for our gaming group: If you have a die and need a choice from 1-5, how do you do it? One way is to roll the die and re-roll if you get a six. The advantage of this method is that in a noisy group of drunken people you won't get an objection that one outcome is favored over another.\n\nIn the same vein, people are apt to readily acknowledge there are 4 possibilities for a coin flipped twice (or flip two different coins such as a sickle and a knut at once). In the case that both sickle and knut come up tails, flip both again until you have one of the other three outcomes.\n\nshare|cite|improve this answer\n\nprotected by Zev Chonoles Jul 14 at 0:46\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/22002/travelling-salesman-with-start-and-end-points-for-30-points/22015\nText:\nSign up \u00d7\n\nI am doing a route optimisation for delivery vehicles and failing dismally. Please see problem statement below. My current solution uses FindShortestTour, but this does not have defined start and end points.\n\nData is received from the calling application in the following format: {\"Unique Identifier used by server\", Original order, Task locked, Latitude, Longitude}\n\nThe first point will always have the unique identifier \"00000000-0000-0000-0000-000000000000\" and represents the depot. This point will always have an order of 1 and always be locked.\n\nA number of tasks may be locked in their given order at the beginning of the list. The Task locked is a boolean represented by 1 - locked, 0 - unlocked. These locked tasks are not included in the optimisation as they are fixed in their given order at the beginning of the scheduled.\n\nThe route is to be optimised finding the shortest path starting at the last locked point and ending back at the depot, traversing all other unlocked points. Depot is always locked and will be used if there are no other locked tasks.\n\nThe output is to be in the following format: {\"Unique Identifier used by server\", Original order, Distance to Next Task in km} and is to be arranged in the optimal order. The order will always start with the depot the traverse locked Tasks in their given order. This will be followed by unlocked tasks optimised from the last locked to the depot. This list will not contain the final depot point as the distance returned is the distance to next task. i.e. The last ordered task distance will be the distance from itself to the depot.\n\nThe calculation needs to be able to handle the optimisation of 30 points in under a minute as accurately as possible.\n\ninput = {{\"00000000-0000-0000-0000-000000000000\", 1., \n    1., -26.17132739, \n    28.21375807}, {\"817463b3-e330-4405-9008-e21821e6c121\", 2., \n    1., -26.2055333333333, \n    28.420565}, {\"36418378-a9ef-49d7-be5a-3a54264a8479\", 3., \n    0., -25.99202013, \n    27.53309061}, {\"49595197-11e5-463a-8f7b-6cd294c33f43\", 4., \n    0., -26.14895194, \n    27.92271447}, {\"83fd029b-0313-4519-a785-ff7b9843c85c\", 5., \n    0., -26.169355, \n    28.2079083333333}, {\"612bf08a-1679-4feb-8fee-d12deb49803a\", 6., \n    0., -25.6755766666667, \n    28.0820533333333}, {\"382f1997-5efe-42c1-99f5-bcb8da30e1c8\", 7., \n    0., -26.8742866666667, \n    28.25047}, {\"883d68f2-b50f-48ca-b065-febfc6ea9546\", 8., \n    0., -26.0938733333333, \n    28.1937966666667}, {\"1bf089bf-acae-4a41-8c4b-e120cef8a148\", 9., \n    0., -25.9877716666667, \n    28.0691433333333}, {\"6958e90b-d42a-4c13-b6ec-78bbdd301aba\", 10., \n    0., -25.7661166666667, \n    28.2811033333333}, {\"2f2c5d25-c1de-449e-b779-dd95699d83ed\", 11., \n    0., -26.0474216666667, \n    28.0060766666667}, {\"a11feb01-f067-49aa-b99d-50879229c423\", 12., \n    0., -25.7949916666667, \n    28.29928}, {\"729b8bfb-029a-483a-814a-1575a6fe47bc\", 13., \n    0., -26.0258616666667, \n    28.0692033333333}, {\"732771dd-55fd-4074-a097-2665686f67d8\", 14., \n    0., -26.772045, \n    28.49977}, {\"0690914d-ba34-4086-b5ae-feda7ed6d22b\", 15., \n    0., -26.044905, \n    28.0346666666667}, {\"5de23f0e-9a05-40af-8e1e-f887d5a06452\", 16., \n    0., -26.4070083333333, \n    28.138515}, {\"3e95a2ac-9985-4753-a4cc-5372ca44ed12\", 17., \n    0., -25.64392423, \n    28.13148167}, {\"d2e0bce2-8061-4b57-b983-aa409c1532fe\", 18., \n    0., -26.42138814, \n    28.1074221}, {\"0259d54a-0782-4ac8-a5f6-42af6e3edbc3\", 19., \n    0., -25.78637, 28.28066}, {\"f686b23a-de85-4004-ae70-8d2703336b5d\",\n     20., 0., -26.043795, \n    28.1197816666667}, {\"e8bca7d4-69ad-4477-8791-9daedbc563c9\", 21., \n    0., -26.2624883333333, 28.17859}};\n\n   27.24}, ..., {\"83fd029b-0313-4519-a785-ff7b9843c85c\", 5., 0.62}}\n\nCurrent poor solution here:\n\nEdit The requirement boils down to a traveling salesman path problem.\n\nI have a fixed start and end point with a list of intermediate points which need to be visited exactly once in an optimal order.\n\nI have a working solution here\n\nshare|improve this question\nHello, and welcome to Mathematica.SE! Please edit your question to contain a minimal example, say, with a small collection of cities for your problem. So we can most directly address the Mathematica question at hand, and not the logistics one. \u2013\u00a0VF1 Mar 24 '13 at 19:59\n@TheGwa: is this a typo in the headline? I'm only counting 20 or 21 points (depending on how you see this, it can be considered a 20 or 21 point problem). But where does the 30 in the title come from? \u2013\u00a0Andreas Lauschke Mar 25 '13 at 18:24\n@VF1 I am new to Mathematica and was hoping that giving the most possible information about my problem at hand would get me the most directed help. I have clarified the question and added my working solution to it too. Many thanks. \u2013\u00a0TheGwa Mar 25 '13 at 22:21\n@Andreas: Sorry I have edited the question. 30 points is what I need. \u2013\u00a0TheGwa Mar 25 '13 at 22:22\nTry with an intelligent goo:\u2026 \u2013\u00a0faysou Mar 26 '13 at 9:42\n\n3 Answers 3\n\nup vote 7 down vote accepted\n\nCould make the end point have distance zero from the depot. Say pt 2is your start point and pty 1 is the finish (depot). Then your example could have a route computed thusly.\n\npt2 = input[[All, 4 ;; -1]];\nlen = Length[pt2];\n\ndists = Table[Norm[pt2[[j]] - pt2[[k]]], {j, 1, len}, {k, 1, len}];\ndists[[1, 2]] = dists[[2, 1]] = 0.;\n\n DistanceFunction -> (dists[[#1, #2]] &)]\n\n(* Out[123]= {3.808066795204197, {1, 5, 8, 20, 13, 15, 11, 9, 12, 19, 10,\n   17, 6, 3, 4, 21, 16, 18, 7, 14, 2}} *)\n\nNow just reverse it to start at point 2 and end at the depot.\n\nshare|improve this answer\nBut that's exactly my point. It's cheating if you can pick and choose your start and end nodes. The optimal tour is {{-25.6756,28.0821},{-25.6439,28.1315},{-25.7661,28.2811},{-25.7864,28.2807},{-2\u200c\u200b5.795,28.2993},{-26.2055,28.4206},{-26.772,28.4998},{-26.8743,28.2505},{-26.4214,\u200c\u200b28.1074},{-26.407,28.1385},{-26.2625,28.1786},{-26.1713,28.2138},{-26.1694,28.207\u200c\u200b9},{-26.0939,28.1938},{-26.0438,28.1198},{-25.9878,28.0691},{-26.0259,28.0692},{-\u200c\u200b26.0449,28.0347},{-26.0474,28.0061},{-26.149,27.9227},{-25.992,27.5331}}, verified optimal, and the longest edge is between start and end, the length is 3.22458 \u2013\u00a0Andreas Lauschke Mar 25 '13 at 5:27\n@Andreas The query stated that it was necessary to fix a start and end (and gave a straightforward justification for that). I made no claim to the effect that the tour I found was optimal in the TSP sense, only that it seemed fine for the stated purpose of the original post. As for \"cheating\", I have no idea how meeting (or trying to meet) a stated requirement falls into that category. \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 17:10\nthe o/p does not mention a specific start point -- unless I'm missing something (in that case please correct me). You pick the start point purely arbitrary, which gives you room to make your solution almost arbitrarily \"good\". As for you having no idea how meeting a stated requirement falls into the cheating category, I can only concur, but you merely CLAIM you are meeting a stated requirement. As I said, you pick your start node arbitrarily, giving you the option to pick and choose, thus making your tour (almost) arbitrarily \"good\" (or bad). \u2013\u00a0Andreas Lauschke Mar 25 '13 at 17:17\n@Andreas The statement has the route beginning at the last locked point, and ending at the depot (which I assumed to be the initial point, also categorized as locked). I simply reversed this, found a tour starting at the depot and ending at the last locked point which, in this example, was the second point. Then said to simply reverse that. I now notice that another point, #14, is also locked, so the basic idea seems about right but not the actual result. On a separate note, I'm not sure how preselecting a starting point leads to a better (let alone arbitrarily good) solution for a TSP. \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 17:24\n@Andreas You are certainly correct. I confess I was oblivious to the possibility that our discussion had a point... \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 18:04\n\nNote that FindShortestTour will not allow for start and end points because it is a tour, and thus you can cycle your staring and ending point by simply removing an edge in your Hamiltonian circuit. To find the shortest path for a given start and end point, I would recommend searching for \"find shortest path\" in the Documentation Center, which would lead one to the function of interest, FindShortestPath.\n\nAs speed seems to be an issue, consider changing the Method used by the function or implementing your own approximate algorithm. However, I don't think it would be necessary to go this far as you stated your problem is for 30 points.\n\nEDIT: As requested, here is an approximate algorithm for the traveling salesman problem. If a significant speed/optimization is required, feel free to implement your own. In the method, start refers to the starting vertex, and adj refers to the adjacency matrix of the graph (you will have to create your own).\n\nHere is a nearest-neighbor algorithm:\n\nNearestNeighbor[start_Integer?Positive, adj_?MatrixQ]:=\n    With[{len = Length[adj]},\n        Module[{visited=ConstantArray[1, len], nearest, neighbors, mult, total = 0},\n                visited[[#]] = Infinity;\n                neighbors = adj[[#]];\n                mult=neighbors visited;\n                First@First[Position[mult, nearest]]\n\nYou can easily create an adjacency matrix by telling Mathematica to do so after you have created a Graph object from your coordinates. Look up WeightedAdjacencyMatrix and Graph in the documentation. If you have a set of points pts, then it is fairly easy to do:\n\npts = RandomReal[1, {20, 2}];\nwam[pts_, dist_: EuclideanDistance] := \n  Array[If[Equal[##], Infinity, \n     dist[pts[[#1]], pts[[#2]]]] &, {Length@pts, Length@pts}];\nshare|improve this answer\nThanks VF1. I have tried to implement the shortest path algorithm from here:\u2026 it is too slow for anything over 17 points however. I have tried the FindShortestPath function, but I can't work out how to create a graph from my list of coordinates. Could you please point me to an approximate algorithm for the shortest path problem. \u2013\u00a0TheGwa Mar 24 '13 at 21:50\nI have supplied the Nearest-Neighbor approximate algorithm. This takes in a weighted adjacency matrix. In order to convert a set of coordinates into a Mathematica Graph object, I recommend you take a look at the documentation for Graph, please read the rest of my answer. \u2013\u00a0VF1 Mar 24 '13 at 23:31\nThank you for your input. It has helped me significantly in understanding a number of key concepts in Mathematica. It was not the solution I used in the end, but it helped greatly. \u2013\u00a0TheGwa Mar 25 '13 at 22:25\n\nJVMTools has very powerful TSP functions, using initial and post-opt methods and exploiting concurrency by submitting competing algorithms in parallel, and chaining post-opt methods (also in parallel):\n\nTSP Intro and TSP Power Examples\n\nIf you want specific start and end points, you could use the option \"All\", which will return all tours for the subdivision of the list of nodes, and then pick the first one. That is guaranteed to use the start and end points the user has provided. However, note that with fixed start and end points you may not necessarily get the shortest tour through all nodes. The author of JVMTools has specifically implemented it in a manner so that node list subdivision is used in parallel with the start-end edge as a viable candidate, so that it's not possible to \"cheat\" to create particularly good or bad solutions by specifying fixed start and end points. But, you can discard n-1 solutions and take only the first, that will use your start and end nodes.\n\nFindShortestTour[] uses very simple algorithms. 20 points is small enough, but even with 20 points you are most likely not getting an optimal tour with any of the FST methods. They have a free trial version for JVMTools that is not feature-capped (only time-limited). Some of the algorithms available through JVMTools solve TSP problems with a few thousand nodes to optimality with amazing speed (like less than a minute).\n\nAddition Mar 25:\n\nDue to Lou's request, here is my code. I'm a bit hesitant to say/show too much about JVMTools, because it's my own commercial product, and I don't want to do \"cheap plugs\" in this venerable community, but due to Lou's request, here it comes. Geez, this is gonna get long, but I like the \"Leonid method\" :).\n\nThere's a few ways to do it. If all distances are Euclidean lengths and you want one of the best TSP algorithms in the world (MAOS, \"multi-agent optimization system\", similar to an ant-colony optimization system), you could simply submit\n\nJTravellingSalesmanMAOS[Round[1000 input[[All,{4,5}]]],200,200,100,1,\"EUC_2D\"]//AbsoluteTiming\n\n\nThis uses 200 agents, 200 as the size of the maximum learning cycle as termination condition, 100 as the number of cycles for the best cycle that no longer changes, 1 as the number of trials, and EUC_2D to specify the 2-dimensional Euclidean norm as distance function. Don't worry, if you understand a bit about multi-agent / ant colony optimization, these terms will not be intimidating. With JVMTools you can use that powerful algorithm without understanding too much about multi-agent optimization / ant colony optimization. MAOS is used by JVMTools with permission of the owners.\n\nThe tour is verified optimal, and the only reason it takes 1.4 seconds total time is because the data is encrypted with asymmetric 2048 cipher strength encryption on the client side and sent to the JVMTools server, where the MAOS algorithm runs (like a webservice) on a high-performance Fedora 18 system, and then the result is sent back. 1.4 seconds for 20 nodes is a prohibitively long run time, but the encryption takes constant time for long as well as short data lists, and JVMTools wasn't written for such toy problems. When choosing the MAOS algorithm in JVMTools there is some 1.4 second overhead for everything you send, due to the encryption. This is to ensure that the client data remains confidential when travelling over the public internet with proven unbreakable encryption (active attacks, passive attacks, eavesdropping attacks, chosen-plaintext attacks, chosen ciphertext attacks, man-in-the-middle attacks, padding attacks, ...), and for large problems this constant 1.4 second encryption overhead amortizes away.\n\nBut you can also model things in a more flexible way, by specifying the node pairs you want to consider (or drop) and explicitly setting the edge lengths. This may be more appropriate here, as the o/p has \"non-standard\" edge lengths.\n\n\n\nIt looks a bit more complicated than how you specify it when using the MAOS algorithm in JVMTools or FST in M, but in the end it gives you more flexibility, because a) you can specify the distances for each and every one of the n(n-1)/2=Binomial[n,2] theoretically feasible edges individually (assuming complete graph to start with), setting it to any (positive) number, including MaxDouble or 0, b) you can leave out index pairs, which means there is no edge (taken as infinity) -- which means it is no longer a complete graph. With FST you can only specify a distance function, not what I would call edge data. In addition, pairs then provides a \"data overview\" in a concise form of what you are about to submit as edge-by-edge data. You could literally edit that manually in a spreadsheet program and read in as a M symbol, if you want to model a complicated non-Eudlidean, highly non-convex structure. And although these lists can get long (generated or edited manually), there is no time delay when sending it over to the JVM, because both indices as well as costs are rectangular arrays of compatible type, thus internally they are packed arrays (auto-packed), and JLink/MathLink uses native array methods for primitives, giving you native speed.\n\nUnless I miss something, the o/p did not specify the start node, only the end node (the first), so I can't address that specific case. All TSP functions in JVMTools assume that you want an optimal solution for the FULL cycle, this is by design and not an omission. But you can leave out edges and set arbitrary positive edge lengths, giving you full control over how to model it very individually.\n\nThe option ConcurrentPostOpt shown above did the following in 41 milliseconds:\n\n  \u2022 in thread 1, FarthestInsert is used as initial method, then 6NodeSwap is applied as post-opt, this is candidate 1. Next CheapestInsert is used as initial method, then 6NodeSwap is applied as post-opt, this is candidate 2.\n  \u2022 in thread 2 NearestNeighbor is used as initial method, then 6NodeSwapSingle is applied as post-opt, this is candidate 3.\n  \u2022 in thread 3 NearestNeighbor is used as initial method, then 6NodeSwapDouble is applied as post-opt, this is candidate 4.\n\nThe output is the best solution of candidates 1 through 4. As 6NodeSwap is extremely fast (yet effective), I have put two initial/post-opt pairs in one thread, as even both strategies one after the other is faster than the other two, meaning I can get 4 candidates by using only 3 threads.\n\nThe tour is verified optimal.\n\nBut with 20 nodes you can't really show any meaningful comparison. 20 nodes is a toy problem, a \"micro-benchmark\", which is not a meaningful comparison. The TSP functions in JVMTools were written for a few thousand nodes (a practical runtime/memory limitation is probably around 20 thousand nodes), where M can do nothing but throw in the towel.\n\nshare|improve this answer\nWhy don't you post the anser by using your environment. It seems that we now have two different answers to one question :). Your website looks great. \u2013\u00a0Lou Mar 25 '13 at 10:31\n@Lou: done, see my addition above. \u2013\u00a0Andreas Lauschke Mar 25 '13 at 17:06\nLauske Thanks for the edit. I learned alot and it seems more and more that Java and Mathematica form a very great couple indeed. Impressive. \u2013\u00a0Lou Mar 25 '13 at 20:24\n@Lou: indeed, M and the JVM are a match made in heaven. The M/.Net combination (qua NETLink) is also quite powerful, it's very, very similar. I mull writing a blog post here about using JLink. I think JLink is totally under-appreciated. \u2013\u00a0Andreas Lauschke Mar 25 '13 at 20:33\n@Andreas: This looks like a really amazing technology. Unfortunately I cannot install Java on the server due to security concerns, but I appreciate the input. I am sure it will help others greatly. \u2013\u00a0TheGwa Mar 25 '13 at 22:27\n\nYour Answer"}
{"text": "Retrieved from http://www.mathgoespop.com/2011/01/test-taking-part-3.html\nText:\nTest Taking, Part 3\n\nIf you'll permit me this small indulgence, gentle reader, this week I'd like to return to a topic from last month.\u00a0 More precisely, I'd like to continue the series of posts that discussed how one best ought to prepare for an exam in which all N questions are given beforehand, and one knows that M questions will appear on the exam, of which the student must answer K.\u00a0 In my first post I discussed this problem in the context of preparing essays, while in my second I discussed it in the context of preparing for the US citizenship exam.\n\nApparently I'm not the only one who thought this a worthwhile problem.\u00a0 This problem has also made an appearance at the fun-filled blog Mind Your Decisions (it's an excellent discussion, so if this kind of thing suits you, check it out).\u00a0 In the comments section, discussion on this problem continues; in particular, one person proposed that the model should be modified to include the possibility of guessing.\u00a0 This is an entirely reasonable thing to want, and thankfully it can be incorporated into the model without too much added effort.\n\nLet me recall the notations I used when I discussed the problem earlier.\u00a0 I've already mentioned N, M, and K.\u00a0 Let's let n represent the number of questions you can answer, and of those n, let X represent the number that actually appear on the exam.\u00a0 As we've seen, X satisfies a hypergeometric distribution, and the probability that X is some value k is given by\n\nMoreover, since you will pass the exam only if X is at least K (in other words, only if the number of questions on the exam that you can answer is at least the minimum number of correct answers need to pass), the probability of passing is\n\nThis is all review from the earlier posts, and does not take into account the effect of guessing.\u00a0 Let us now imagine how we can include this refinement into the model.\n\nIntuitively, if we are allowed to guess, then the probability of our being able to pass should increase.\u00a0 To make things as simple as possible, let's assume that if you don't know the answer to a question, you have a probability p of guessing correctly - in other words, the probability of a correct answer is the same for each question.\u00a0 Let's also assume that the probability of guessing correctly is independent of the number of questions on the exam that you can answer without guessing (we'll use this assumption in a moment).\n\nIn this modified situation, you will win if you can answer enough questions, or if you can guess enough correct answers in the event that you can't answer the minimum number of questions with absolute certainty.\u00a0 So, if X is at least K, nothing changes - you'll simply answer the minimum number of questions and call it a day.\u00a0 What's new is the situation when X < K, in which case you'll need to guess in order to try and pass.\n\nRoughly speaking, then, the probability of passing is equal to P(X \u2265 K) + P(X < K and you guess correctly enough times).\u00a0 How many times is \"enough\"?\u00a0 Well, X plus the number of correct guesses must be at least K.\u00a0 Considering the cases X = 0, 1, ..., K - 1 separately, we can rewrite this as\n\nSince the value of X is independent of the number of correct guesses you'll make, this can be written as\n\nMoreover, since we want the number of correct guesses to be between K - i and M - i, we can write the above as\n\nNow, the probability occurring in the sum over j should hopefully look familiar to anyone with a basic background in probability.\u00a0 The number of successes out of a fixed number of trials given that the probability of success is some number p follows the Binomial distribution, one of the first probability distributions encountered in any course in probability or statistics.\u00a0 In particular, since we've said that the probability of a correct guess is p, knowledge of the binomial distribution tells us that\n\nIn summary, the probability of passing is\n\nIf we want a more explicit formula, we can also use our knowledge of the probability distribution for X.\u00a0 Also, notice that P(X = i) is 0 if n < i (the number of questions on the exam for which you know the answer can't exceed the number of questions in total for which you know the answer), so we can write the probability of success in two ways, depending on whether n < K or n K.\n\nIf n < K, then the probability of passing becomes\n\nIn the case that n \u2265 K, we have a contribution from the P(X \u2265 K) term, and so the total probability is\n\nThis is all well and good (and agrees with what commenter Scott derived in the comments of the Mind Your Decisions post), but what does it say about our example from last time (where N = 100, M = 10 and K = 6)?\u00a0 As before, here are some graphs of the probability of success as a function of how many questions you can answer.\u00a0 Note that any such graph depends on the probability p.\u00a0 So, let's illustrate two examples:\n\nCase 1: p is a fixed value.\u00a0 Here are the graphs corresponding to p = 0, p = .25, p = .375, p = .5, and p = .75 (i.e. the chances of you guessing correctly are either 25%, 37.5% 50%, or 75% - note that the case of p = 0 corresponds to the previous case where guessing isn't a factor).\n\nSome highlights \u2014 without guessing, you need to know the answers to 55 questions in order to have at least 50% chance of passing.\u00a0 With a 25% chance of guessing correctly, you only need to know the answers to 40 questions.\u00a0 At 37.5%, the number of questions decreases to 28, at 50% it drops to 10 questions, and if you have a 75% chance of answering correctly, you have over a 90% chance of passing without knowing any answers at all!\u00a0 If you want at least an 80% chance of passing, the number of answers becomes 67 (p = 0), 56 (p = .25), 48 (p = .375), and 35 (p = 0.5).\n\nCase 2: p increases with n.\u00a0 It seems reasonable to assume that the more answers you know, the better your chances of correctly guessing the answer to a question you don't know, since you will be more knowledgeable in general.\u00a0 In this particular example, I've taken p to equal n/N (in this case n/100).\u00a0 Note that with this choice, initially the probability of success will be 0, but as n grows the probability of success should grow relatively rapidly.\n\nThe above graph quantifies the above heuristics.\u00a0 Note that the red line grows very rapidly, so that the probability of success is greater than 50% after memorizing 33 questions, more than 80% after 43 questions, and over 95% after slightly over half of the questions (53).\n\nSo there you have it.\u00a0 If you are feeling lazy the next time you have to prepare for an exam, hopefully this will provide you some guidance as to the minimum amount of work you can do while still being reasonably confident that you won't fail.\n\nHope you all have a great weekend!\n\ncomments powered by Disqus"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164928/find-the-number-of-common-normals-to-both-these-curves\nText:\nSign up \u00d7\n\nFind the number of common normals to the curves $ x^2 + (y-1)^2 =1 $ and $y^2=4x$.\n\nMy take :\n\nI formed a cubic in $m$ i.e. slope, so there'll be 3 normals. Please help.\n\nshare|cite|improve this question\nPlease explain how you formed a cubic in slope $m$. \u2013\u00a0hardmath Jun 30 '12 at 15:13\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYour first curve is a circle of radius 1, centered at $(0,1)$. Its normals are the lines through its center, that is, the lines $$y=mx+1$$ for arbitrary $m$ (this leaves out the vertical normal, but that's obviously not normal to the other curve). So now you just have to work out the values of $m$ for which the graph of $y=mx+1$ is normal to the graph of $y^2=4x$. Can you do that?\n\nI guess not, so here goes.\n\nFrom $y^2=4x$ we get $2yy'=4$, so $y'=2/y$. If $(a,b)$ is a point on the graph of $y^2=4x$, then\n1. the slope of the normal to the curve at that point is $-b/2$, and\n2. $b^2=4a$.\nSo the equation of the normal is $$y-b=-(b/2)(x-a)$$ which we can write as $$y=-(b/2)x+(1/2)ab+b$$ But we want the normal to be $y=mx+1$, so $$(1/2)ab+b=1$$ Now combining that with $b^2=4a$, we get, after a little algebra, $$b^3+8b-8=0$$ and it's easy to show that equation has exactly one real zero, so there is exactly one common normal.\n\nshare|cite|improve this answer\nso, no real values of m. Thus no common normals. \u2013\u00a0Bazinga Jul 1 '12 at 7:46\nIf you sketch the two curves, I think it's clear that there is at least one common normal. \u2013\u00a0Gerry Myerson Jul 1 '12 at 9:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/34695/number-of-subsets-with-n-k-elements-containing-at-least-one-of-a-given-set-of\nText:\nSign up \u00d7\n\nI would like to prove the following statement:\n\nLet $E$ be a set with $n$ elements, and let $k$ be an integer such that $1\\leq k<n-k$. Let $r\\leq\\binom{n}{k}$ and $\\mathcal{A}$ be a set of $r$ subsets of $E$ with $k$ elements. Then the number of subsets of $E$ with $n-k$ elements which contain (as a subset) at least one element of $\\mathcal{A}$ is $\\geq r$.\n\nAt the moment, I have no idea. Straightforward induction doesn't seem to be the right way here. I'd be glad for any kind of help.\n\nshare|cite|improve this question\nThe subsets of $E$ do not contain elements of $\\mathcal{A}$ (which are sets in their own right), but may have them as subsets. \u2013\u00a0Ross Millikan Apr 23 '11 at 15:58\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nThere are exactly $w=\\binom{n-k}{n-2k}=\\binom{n-k}{k}$ ways to extend a $k$ set to a $n-k$-set. But there also exactly this number of $k$-sets contained in a $n-k$-set.\n\nTherefore, the sets in $A$ give rise to $r\\cdot w$ admissible $(n-k)$-sets where each set has been counted at most $w$ times, so there are at least $r$ of them.\n\n(Note that the $k$-sets and $(n-k)$-sets together with the inclusion property form a bipartite $w$-regular graph which is a standard exercice for the condition of the marriage theorem.)\n\nshare|cite|improve this answer\nThank you very much! \u2013\u00a0Stefan Walter Apr 23 '11 at 16:44\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/677481/a-union-of-two-subspaces-not-equal-to-the-vector-space\nText:\nSign up \u00d7\n\nThis question already has an answer here:\n\nLet $L,M$ two subspaces of the vector space, $V$ such that both $L,M \\ne V$.\nProve: $L\\cup M \\ne V$.\n\nI think this is a case of a proof by contradiction.\nLets assume $L \\cup M = V$.\n\n$$\\dim(V) = \\dim(L) + \\dim(M) - \\dim(L\\cap M)$$\n\nHow to proceed?\n\nshare|cite|improve this question\n\nmarked as duplicate by egreg, Lost1, T. Bongers, Your Ad Here, Zev Chonoles Feb 26 '14 at 8:45\n\n\nSee this \u2013\u00a0angryavian Feb 15 '14 at 15:58\n@angryavian: The idea is similar, but it's not the exact same question. \u2013\u00a0Najib Idrissi Feb 15 '14 at 15:59\nSo, is it suffice to show a contradiction example? @angryavian \u2013\u00a0AndrePoole Feb 15 '14 at 15:59\nThe simplest method to show what you're looking for is to consider $L\\oplus M \\subset V$, and show that $L\\cup M$ just won't cut it for the direct sum, let alone the whole vector space. \u2013\u00a0FireGarden Feb 15 '14 at 16:00\nThe dimensional argument is not going to work: You can take two one-dimensional subspaces of $\\Bbb R^2$ and union them together; the equation will work, but the union is not a vector space (as shown in the link) so won't equal $V$. \u2013\u00a0tabstop Feb 15 '14 at 16:01\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nLet's break down the proof in two cases:\n\n  \u2022 If $L \\subset M$ (resp. $M \\subset L$) then $L \\cup M = M \\neq V$ (resp. $L \\cup M = L \\neq V$);\n  \u2022 Otherwise choose $x \\in L \\setminus M$, $y \\in M \\setminus L$. Then $x + y$ is neither in $L$ (for then $y$ would be in $L$) nor in $M$ (same reason). Therefore $x + y \\not\\in L \\cup M$.\nshare|cite|improve this answer\nSo simple! Thanks. The main key was using the properties of a vector space. Cool. \u2013\u00a0AndrePoole Feb 15 '14 at 16:04\n\nSuppose $W \\not\\subset L $ and $L \\not\\subset W $, otherwise is trivial.\n\nLet $v \\in L-W $ and $u \\in W - L $, then if $ L \\cup W = V $ we have $v + u \\in L$ or $v + u \\in L$, and in both cases we obtain a contradiction.\n\nshare|cite|improve this answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/210543/is-this-inequality-proof-correct/210555\nText:\nSign up \u00d7\n\n$a$ and $b$ are fixed real numbers.\n\nClaim: $a < b$ implies $a < b - \\varepsilon$ for some $\\varepsilon > 0$.\n\nProof: Utilise the fact that $a \\implies b$ is equivalent to $b' \\implies a'$.\n\nSo this is equivalent to proving $a \\ge b - \\varepsilon\\,$ for all $\\varepsilon > 0 \\implies a \\ge b$.\n\nNow, as $a \\ge b - \\varepsilon$, take the infimum of both sides.\n\n$$\\inf (a) \\ge \\inf \\{b - \\varepsilon \\mid \\varepsilon > 0\\}$$\n\n$\\inf (a) = a$ and the right-hand side $= b$, hence:\n\n$$a \\ge b.$$\n\nThus, $a \\ge b - \\varepsilon$ for all $\\varepsilon > 0$ implies $a \\ge b$. Which then proves our original claim.\n\nshare|cite|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nSoo... looks good, but!:\n\n  1. Rather use different letters for propositions in your 3rd line, at least capitals ($A\\implies B$ equivalent to $\\lnot B\\implies \\lnot A$)\n  2. Instead of $\\inf$ you are considering $\\sup$\n  3. You are implicitly using $\\sup\\{b-\\varepsilon \\mid \\varepsilon >0\\} = b$, which is true, but... it is equivalent to the given problem. that's why it's not really working.\n\nAnd the solution is (straight ahead):\n\nIf $a<b$, then $b-a>0$, and let $\\varepsilon:=\\displaystyle\\frac{b-a}2$.\n\nshare|cite|improve this answer\nAbout point 3... Any two true statements are equivalent. \u2013\u00a0Arthur Oct 10 '12 at 16:41\nAh ok. Yes the infimum was a slip on my part. Ok so I see that epsilon works, thank you! \u2013\u00a0user64219 Oct 10 '12 at 16:46\nAny $\\varepsilon\\in (0,b-a)$ works. \u2013\u00a0Berci Oct 10 '12 at 20:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/58161/simulate-a-double-chance-bet-with-two-single-bets/58184\nText:\nSign up \u00d7\n\nIf you bet on the result of a soccer match, you usually have three possibilities. You bet\n\n  \u2022 1 - if you think the home team will win\n  \u2022 X - if you think the match ends in a draw\n  \u2022 2 - if you think the away team will win\n\nLets say we have the following soccer match with the following betting quotes:\n\nKansas City vs. Portland - 1 = 1.92, X = 3.57, 2 = 5.00\n\nThis means: If you think Portland (In the opinion of the bookie, the underdog) will win the match, you bet on 2\n\nExample (I bet \\$100): In case Portland wins I win \\$400 $$100*5.00-100 = 400$$ $$stake*quote-stake = net win$$ (When Portland loses the match, or it ends in a draw, I'll lose my stake)\n\nNow, some bookies offer a so-called double chance bet. This kind of bet takes one possibility out. That leaves you to following bets. You bet\n\n  \u2022 1/X - if you think the home team will win or the match ends in a draw\n  \u2022 X/2 - if you think the away team will win or the match ends in a draw\n\nThis variant is perfect if you think Portland will win the match, or at least it will end up in a draw. To calculate this quotes I use the following formula: (Q1 = 1st quote 1, Q2 = 2nd quote)\n\n$$ 1/(1/Q1+1/Q2) $$\n\nFor the 1/X bet $$ 1/(1/1.92+1/3.57) = 1.25 $$\n\nFor the X/2 bet $$ 1/(1/3.57+1/5) = 2.08 $$\n\nNow comes my math problem: When the bookie does not offer a double chance bet, I want to create it my self: With two single bets. For the Kansas City vs. Portland bet I'd like to place a X/2 bet. The quote for the bet is as I showed before 2.08. I want to place \\$100 on it. When I win the bet, I'll get \\$108 net win:\n\n$$100*2.08-100 = 108$$\n\nHow do I have to split the money on two (X and 2) single bets, to win \\$108, when Portland wins or the match ends in a draw?\n\nI got to the solution for this case by trying out. But with the result in my hand, I still don't get the formula to calculate it.\n\nI bet \\$58.35 on X and \\$41.65 on 2\n\n$$ 58.35*3.57-58.53-41.65 \u2248 108$$ and $$ 41.65*5.00-41.65-58.53 \u2248 108$$\n\nNotice the last subtraction. You have to subtract the stake of the other bet. Because when Portland wins, I win only the 2 bet and lose the stake for the X bet.\n\nshare|cite|improve this question\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nLet's examine the X/2 case. Denote by $Q_X=3.57$ the bookie's quote for X and $Q_2=5.00$ for 2. Denote by $Q=1/(1/Q_X+1/Q_2)=(Q_X Q_2)/(Q_X+Q_2)\\approx 2.0828$ the quote you have calculated for the X/2 bet. You want to split the total bet $B=\\$100$ into two bets $B_X$ (for X) and $B_2$ (for 2) so that $B_X Q_X=BQ=B_2 Q_2$. From the first equation you get $B_X=B(Q/Q_X)$. Similarly from the second equation you get $B_2=B(Q/Q_2)$, or alternatively $B_2=B-B_X$ (as the value of $B_1$ is already known). Let's substitute the values: $$B_X=100(2.0828/3.57)\\approx 58.34\\quad\\text{and}\\quad B_2=100-58.34=41.66.$$ In fact, you can do this more easily without calculating $Q$ at all, since $$B_X=B\\frac{Q}{Q_X}=B\\frac{Q_2}{Q_X+Q_2}.$$\n\nshare|cite|improve this answer\n\nThe defining feature of a double chance bet is that, if either of the events you bet on happens, you win the same amount regardless of which event it was.\n\nTo simulate a double chance bet with single bets, you need to divide the stake so that the same will happen.\n\nSo, let $Q_1$ and $Q_2$ be the quotes offered for the two events. We seek a value $0 \\le \\alpha \\le 1$ such that, if we bet a fraction $\\alpha$ of our total stake on event 1 and the rest on event 2, the payout in either case will be the same, i.e.\n\n$$\\alpha Q_1 = (1 - \\alpha) Q_2.$$\n\nTo solve this, expand the right hand side, collect the $\\alpha$ terms together on one side and divide to get\n\n$$\\alpha = \\frac{Q_2}{Q_1 + Q_2}.$$\n\nThen, to ensure equal payout in either case, you should bet $\\alpha$ times you total stake on event 1, and the rest on event 2.\n\nshare|cite|improve this answer\n\nPlanning on betting that either team wins?\n\n\n$S_1=S_2*\\frac{Q_2}{Q_1}, S_2=S_1*\\frac{Q_1}{Q_2}$\n\n$S_1+S_2=1$ (to find $S_1$ and $S_2$ as percentages)\n\n$S_1+S_1\\frac{Q_1}{Q_2}=1, S_2+S_2\\frac{Q_2}{Q_1}$\n\n$S_1=\\frac1{Q_2/Q_1+1}, S_2=\\frac1{Q_1/Q_2+1}$\n\nFor X/2, S_1 = 58.3% just as above.\n\nshare|cite|improve this answer\nIf you think it isn't a tie with these odds, put 72.2% on 1 and 27.7% on 2 for +38.7% on a win. Remember that you never win a double-chance if $\\frac1{1/Q_1+1/Q_2}<=1$. \u2013\u00a0user474632 Aug 17 '11 at 23:50\n\nYou bet $\\$100$ $Q2 / (Q1 + Q2)$ on X and $\\$100$ $Q1 / (Q1 + Q2)$ on 2. To the nearest cent, these work out at $\\$58.34$ and $\\$41.66$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/518186/eulerian-paths-in-non-traversable-graphs\nText:\nSign up \u00d7\n\nSuppose I have a weighted connected graph which is traversable (each vertex has even degree) and I wish to walk over all edges. Clearly any Eulerian path minimizes the total weight. What can be said about the case of non-traversable (weighted connected) graphs? Can a minimum-weight path still be found in polynomial time?\n\nshare|cite|improve this question\nYou want a path that traverses every edge at least once, I suppose? \u2013\u00a0Henning Makholm Oct 7 '13 at 22:57\n@HenningMakholm: Yes. Sorry, I had typed that but it must have been deleted as I edited the post before submitting. \u2013\u00a0Charles Oct 8 '13 at 3:46\nI would be surprised if it had an efficient solution. It is a variant of the travelling purchaser problem (on the line graph) but with some simplifications (like travel cost zero) and only one product. \u2013\u00a0Leen Droogendijk Oct 8 '13 at 5:58\nThis is the Route inspection problem a.k.a. Chinese Postman Problem. This has a polynomial time algorithm for undirected graphs and polynomial for directed graphs, but it is NP-complete for mixed graphs. \u2013\u00a0N. S. Oct 8 '13 at 17:10\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nYes, this can be done in polynomial time.\n\nWhat we need to is find a minimum-weight set of edges to traverse twice, such that the graph with some edges doubled is traversable. Once we have that, finding an actual Eulerian path is of course easy.\n\nThe edges we need to double will form a set of paths each connecting two odd-degree nodes, such that each odd-degree node is the endpoint of exactly one of the path.\n\nTo find out which odd-degree nodes to connect, temporarily disregard the even-degree nodes and instead consider a graph with one edge between each pair of odd-degree nodes, its weight being the length of the shortest path between those nodes in the original graph.\n\nWhat we need to find is then a minimal perfect matching in the reduced graph, which is known to have a polynomial-time algorithm.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/168329/how-to-show-this-property-for-the-diameter-of-a-set?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $(M, d)$ be a metric space and $A\\subset M$ such that $$\\mathrm{diam}(A)=\\sup_{a,b\\in A}d(a,b)=D<\\infty.$$ How can I prove that for any $\\varepsilon> 0$ there is $x\\in A$ such that $A\\subset\\{y\\in M: d(x,y)<(\\varepsilon +D)\\}$?\n\nshare|improve this question\nHint: by contradiction assume that the claim is false. So there exists an $\\epsilon>0$ such that A is NOT in the set of points within $\\epsilon+D$ of $x$. Notice that $x\\in A$ by assumption. You can break it down into two cases, one where $A$ has just a single point, and when $A$ has at least two points. \u2013\u00a0 Alex R. Jul 8 '12 at 19:34\nI don't see why it says \"there is\" -- isn't this rather trivially true for all $x\\in A$? \u2013\u00a0 joriki Jul 8 '12 at 19:36\n\n1 Answer 1\n\nSuppose that for some $\\epsilon>0$, it is the case that for any $x\\in A$, $A\\not\\subset\\{y\\in M:d(x,y)<(\\epsilon+D)\\}$. In other words, suppose that for any $x\\in A$, there is some $y\\in A$ such that $d(x,y)\\geq\\epsilon+D$. Then $$\\operatorname{diam}(A)=\\sup_{a,b\\in A}d(a,b)\\geq D+\\epsilon>D,$$ which is a contradiction. In fact, this is a contradiction if for even a single $x\\in A$, there is some $y\\in A$ with $d(x,y)\\geq \\epsilon+D$. Thus, our assumption that there exists such an $\\epsilon$ must be false.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/233384/exponential-diophantine-equation-and-its-solutions/233898\nText:\nTake the 2-minute tour \u00d7\n\nThe exponential Diophantine equation $x^2 + y^2 = 4x^n + 43$ has no integral solution $(x, y, z)$ for $n \\geqslant 3.$ I have seen the problem in the lecture series in math conference. I do not know, how one can inspect the solutions of the cited above equation? We can check few solutions by trial and error. Here the condition is $n > 3$ or $n = 3$ case is failed to find solutions. If there is any mathematical proof to justify the statement? discuss.\n\nshare|improve this question\nShouldn't have any solutions for any $n$ since $x^2+y^2-3$ is never divisible by $4$ \u2013\u00a0 Thomas Andrews Nov 9 '12 at 5:53\n@ThomasAndrews!I got it. discuss the above post mathematically by taking the cases. \u2013\u00a0 vmrfdu123456 Nov 9 '12 at 6:42\n\n1 Answer 1\n\nThe right hand side is $3\\mod 4$, but this can never be the sum of two squares since any square is either $0^2\\equiv 2^2 \\equiv 0\\mod 4$ or $1^2\\equiv 3^2\\equiv 1\\mod 4$.\n\nshare|improve this answer\n@pi367!fine. Thank U \u2013\u00a0 vmrfdu123456 Nov 10 '12 at 6:03\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/233666/linear-operator-on-a-vector-space-v-such-that-t2-t-i-0/233673\nText:\nTake the 2-minute tour \u00d7\n\nlet T be a linear operator on a vector space V such that $T^2 -T +I=0$.Then\n\n  1. T is oneone but not onto.\n  2. T is onto but not one one.\n  3. T is invertible.\n  4. no such T exists.\n\ncould any one give me just hint?\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 1 down vote accepted\n\nI was looking at a problem similar to this, and these answers are great but I needed a bit more to make it click. Here is a step by step with the rules used.\n\n$T^2 \u2212 T + I = 0$\n\n$TT = T - I$\n\n$TT = T - TT^{-1}$ , because $I = TT^{-1}$\n\n$TT = IT - TT^{-1}$ , because $IT = T$\n\n$TT = T(I-T^{-1})$ , factor out the T\n\n$T = I - T^{-1}$ , remove T from both sides\n\nIn my case we had to prove $T^{-1} = 2I - T$ given almost the same equation (that 2 being the difference). I know this break down is probably too basic for most, but this what helped me understand how to apply those rules.\n\nI was lead here by this duplicate.\n\nshare|improve this answer\n\n$$ T^2-T+I=0 \\iff T(I-T)=I=(I-T)T, $$ i.e. $T$ is invertible and $T^{-1}=I-T$. In particular $T$ is injective and surjective.\n\nshare|improve this answer\n\nLet $\\mathbb{x}$ be any vector in the nullspace. Then $T\\mathbb{x} = \\mathbb{0}$. Using your equation $T^2 - T + I = 0$, what can you conclude about $\\mathbb{x}$?\n\nAlternatively if you know about minimal polynomials: How does your polynomial split?\n\nshare|improve this answer\n$T^2(x)-T(x)=0$ and so $I(x)=0$ so $x=0$ so $T$ is injective. am I right? \u2013\u00a0 La Belle Noiseuse Nov 9 '12 at 16:38\nI know about minimal polynomial, it has distinct roots over the field $\\mathbb{C}$ \u2013\u00a0 La Belle Noiseuse Nov 9 '12 at 16:40\nYour mapping is injective. It is not necessarily surjective unless $V$ is finite-dimensional. \u2013\u00a0 EuYu Nov 9 '12 at 16:52\nIt is surjective: $T(-Tx + x) = x$ \u2013\u00a0 Robert Israel Nov 9 '12 at 16:54\nOh, well that's that. Thank you for catching my mistake @RobertIsrael \u2013\u00a0 EuYu Nov 9 '12 at 16:54\n\n$T(T-1)= -I$ then $\\det T\\cdot \\det (T-I) = (-1)^n$ which implies $\\det (T) \\neq0 \\,\\,.$ hence $T$ invertible\n\nshare|improve this answer\nIs it true for a vector space with not a finit dimension ? \u2013\u00a0 Ricky Bobby Nov 9 '12 at 16:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/275856/the-roots-in-a-finite-field?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbb F$ be a finite field of order $q=p^k$, where $p$ is an odd prime number. For an element $a\\in\\mathbb F$ how can we count the m-th roots of $a$? That is, the number of solutions of the equation $$x^m=a$$\n\nSuppose that $a\\neq 0$.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nThe multiplicative group of $\\mathbb F$ is cyclic of order $q-1$, and as already pointed out by DonAntonio, all solutions of $x^m=a$ can be obtained from any fixed solution by multiplying it by all $m$th roots of unity in $\\mathbb F$. This implies:\n\n  \u2022 If there is at least one solution, the total number of solutions is the number of $m$th roots of unity in $\\mathbb F$, which is $$\\gcd(m,q-1).$$\n  \u2022 In order to determine whether the equation has a solution, let $r$ be the multiplicative order of $a$ (i.e., the least $r$ such that $a^r=1$). Then $x^m=a$ is solvable iff $$\\gcd(m,q-1)\\mid\\frac{q-1}r.$$\nshare|improve this answer\nThe criterion for solvability can be written more consisely as $a^{(q-1)/\\gcd(m,q-1)}=1$. \u2013\u00a0 Emil Je\u0159\u00e1bek Jan 14 '13 at 16:40\n\nAs in any other field, if $\\,\\alpha\\,$ is a root, i.e. $\\,\\alpha^m=a\\,$ ,then all the roots are $\\,\\alpha\\, w^k\\,,\\,k=0,1,...,m-1\\,$ , where $\\,w\\,$ is a primitive $\\,m-$th root of unity: $\\,w^m=1\\,\\,\\,,\\,\\,w^t\\neq 1\\,\\,,\\,\\forall\\,0\\leq t<m\\,$ .\n\nI don't think something in general can be said: it'll depend on $\\,a\\,\\,,\\,\\operatorname{char}\\Bbb F$\\, and on $\\,m\\,$ , though it can be divided in cases.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/130481/on-permutation-similarity-and-block-diagonals\nText:\nTake the 2-minute tour \u00d7\n\nSimilar matrices share many invariants: determinant, trace, characteristic polynomial, rank, eigenvalues, etc., but the reverse implication is not true. Two matrices sharing any of these invariants does not prove that they are similar.\n\nUnder which necessary and/or sufficient conditions (like the value of some or more invariant quantities) can one ensure that a non-negative, integral square matrix is non-trivially permutation-similar to a block diagonal matrix of non-negative, integral square matrices, i.e., a (non-trivial) direct sum of such matrices? My question is one of reducibility. That is, given $A \\in \\mathbb{Z}_{\\geqslant 0}^{n \\times n}$, under which conditions does one have $A = P^{-1} (\\bigoplus_i A_i) Q$, where $P$ and $Q$ are $n \\times n$ permutation matrices, $A_i \\in \\mathbb{Z}_{\\geqslant 0}^{n_i \\times n_i}$ for $1 \\leqslant n_i < n$ for all indices $i$.\n\nIt seems like combinatorics plays a significant role here. For example, by simply counting the number of zero entries of $A$, one can rule out certain decompositions. For instance, if $A$ has no zero entries or an odd number of zero entries, then it certainly cannot decompose into any non-trivial block diagonal form.\n\nshare|improve this question\nI don't understand the question. A non-negative integral square matrix is already a block matrix of non-negative integral square matrices. I also don't understand what the first paragraph has to do with the rest of the question. \u2013\u00a0 Qiaochu Yuan Apr 11 '12 at 15:51\nCertainly permutation-similarity preserves the nonnegativity and integrality of entries, as well as the squareness of the matrix. It sounds like you want to determine the smallest blocks into which nonzero entries of a given matrix can be arranged. This can probably be attacked by graph closure ideas. Search for matrix bandwidth minimization algorithm for some related ideas. \u2013\u00a0 hardmath Apr 11 '12 at 16:33\nThanks for the comments, QY and Hardmath. I've clarified my question. \u2013\u00a0 user02138 Apr 11 '12 at 18:43\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nI still don't really understand the question (what kind of conditions do you care about? Theoretical? Algorithmic?) but here are some thoughts. $A$ is the adjacency matrix of a directed graph, and conjugating $A$ by a permutation just corresponds to relabeling the vertices. What you want is more or less to compute the connected components of the underlying undirected graph, or at least to determine whether there is one or more than one such component.\n\nProbably there are many algorithms to do this efficiently; here's two off the top of my head.\n\n  \u2022 Compute $B = (A + A^T)^{2^k}$ by repeated squaring, where $k$ is the smallest positive integer such that $2^k \\ge n$. Then check whether at least one entry in $B$ is equal to zero. (If the entries of the matrices get large enough to be annoying, at any step you can replace all positive entries by $1$.)\n\n  \u2022 Compute the Laplacian matrix $\\Delta$ of the underlying undirected graph. $\\dim \\ker \\Delta$ is equal to the number of connected components, and this can be efficiently computed by row reduction.\n\nshare|improve this answer\nThere's a discussion of computing the number of connected components of a graph at en.wikipedia.org/wiki/Connected_component_(graph_theory). It starts, It is straightforward to compute the connected components of a graph in linear time using either breadth-first search or depth-first search. In either case, a search that begins at some particular vertex v will find the entire connected component containing v (and no more) before returning. To find all the connected components of a graph, loop through its vertices, [continued next comment] \u2013\u00a0 Gerry Myerson Apr 12 '12 at 1:39\n[continued from previous comment] starting a new breadth first or depth first search whenever the loop reaches a vertex that has not already been included in a previously found connected component. Hopcroft and Tarjan (1973)[1] describe essentially this algorithm, and state that at that point it was \"well known\". \u2013\u00a0 Gerry Myerson Apr 12 '12 at 1:40\nThanks, Gerry. I'll look into this.... \u2013\u00a0 user02138 Apr 12 '12 at 13:04\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/43471/commutation-relation-with-hamiltonian\nText:\nTake the 2-minute tour \u00d7\n\nHow do we get $[\\beta , L] = 0$ , where $L$= orbital angular momentum and $\\beta$= matrix from Dirac equation?\n\nshare|improve this question\n\n1 Answer 1\n\nThe matrix $\\beta$ or $\\gamma_0$ is just a scalar so it doesn't change under spatial rotations. More algebraically, the angular momentum matrices in the Dirac spinor representation are given by $(\\gamma_i\\gamma_j-\\gamma_j \\gamma_i)/4$ which commutes with $\\gamma_0$ because there are two sign flips (each spatial $\\gamma_i$ anticommutes with $\\gamma_0$).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/242087/eigen-value-minimization-proof\nText:\nTake the 2-minute tour \u00d7\n\nThe two minimization problems below are equivalent:\n\n$\\min\\{\\mathrm{trace}(AX^TBX): XX^T=I_n\\}=\\min\\{\\mathrm{trace}(AQ^T\\tilde{B}Q): QQ^T=I_m\\}$, where $A,\\tilde{B}$ and $Q$ are square matrices of the same size, $A,B$ are also p.s.d and $X$ is a $m \\times n, (m >n) $ rectangular matrix.\n\nThe solution to this latter minimization problem is well known: the extrema of the trace are the extrema of $\\{\\sum_{i=1}^m\\lambda_i(A)\\lambda_{\\sigma(i)}(\\tilde{B}): \\sigma\\in S_m\\}$, where $\\lambda_i(M)$ denotes the $i$-th eigenvalue of a real symmetric matrix $M$ and $S_m$ is the symmetric group of order $m$.\n\nSuppose $A$ and $\\tilde{B}$ are orthogonally diagonalized as $A=U\\Lambda U^T$ and $\\tilde{B}=V\\Sigma V^T$, where $\\Lambda = \\mathrm{diag}(\\lambda_1(A), \\lambda_2(A), \\ldots, \\lambda_m(A))$ contains the eigenvalues of $A$ arranged in ascending order and $\\Sigma$ is analogously defined, but the eigenvalues are arranged in descending order. That is, if $\\lambda_1(B),\\ldots,\\lambda_n(B)$ are arranged in ascending order, and for $\\Sigma=\\mathrm{diag}\\left(\\lambda_n(B),\\ldots,\\lambda_1(B),0,\\ldots,0\\right)$\n\nThen am looking for a 'detailed proof' that the minima is reached at an $X^*$ given by:\n\n\\begin{align} X^* &= VU^T \\begin{bmatrix}I_n\\\\ 0_{(m-n)\\times n}\\end{bmatrix}. \\end{align}\n\nfor my better understanding.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nIt is a bit easy to show for the square case. For the rectangular case, it becomes cumbersome due to heavy notational stuff. You need to have the following inequality for the positive (semi) definite matrices\n\n\\begin{align}trace(AB)\\geq\\sum_{i=1}^{N}\\alpha_i \\beta_{N-i+1}\\end{align}\n\nwhere $\\alpha_ 1\\geq\\alpha_ 2...\\geq\\alpha_ N$ are the eigenvalues of $A$ and $\\beta_ 1\\geq\\beta_ 2...\\geq\\beta_ N$ are eigenvalues of $B$. The lower bound is achieved when $A$ and $B$ commute and the corresponding eigenvalues are in order (ie ascending for $A$ and descending for $B$).\n\nNow $X$ is orthogonal, Define $\\hat{B}=X^{H}BX$. Note that $B$ and $\\hat{B}$ will have same eigenvalues. This implies $trace(A\\hat{B})\\geq \\sum_{i=1}^{N}\\alpha_i \\beta_{N-i+1}$. Thus it is enough to design $X$ such that we can attain the (universal) lower bound for every $X$. This is possible only if $X=VU^{H}P$. Here $U$ and $V$ comes from eigen decomposition of $A$ and $B$. $P$ is a suitable permutation (which is orthogonal) matrix which rearranges the eigenvalues. Since you have already assumed the required order, it should be identity.\n\nshare|improve this answer\nalso- any views on if the objective function considered in this question is Convex-as in is this solution a point where a global minima is reached? \u2013\u00a0 qlinck Nov 21 '12 at 18:25\nNote that $trace(AX^{T}BX)=vec(X)^{T}(A\\otimes B)vec(X)$. Since $A$ and $B$ are positive (semi)definite, this implies the objective function is a convex quadratic. But note that this doesn't imply the optimization is itself convex as the orthogonality constraint is not convex. But in this case, due to the constraint, whatever $X$ you come up with (which obeys the constraint), the inequality always holds. For any other $X$ (which obeys the constraint), you can't reduce the objective value than the lower bound. Hence, it should be the solution \u2013\u00a0 dineshdileep Nov 22 '12 at 3:01\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/279826/proving-that-a-b-ne-emptyset-when-a-b\nText:\nTake the 2-minute tour \u00d7\n\nI am struggling to prove what seems like a trivial fact - subtracting a smaller set from a bigger set cannot produce the empty set - and it just seems like there must be a simple proof of this.\n\nIs there a way to prove that if $|A| > |B|$, then $A - B \\ne \\emptyset$?\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nIf $A\\setminus B = \\varnothing$, then $A \\subseteq B$ so inclusion provides an injection from $A$ into $B$ implying $\\lvert A \\rvert \\leq \\lvert B \\rvert$.\n\nshare|improve this answer\nThat's beautiful. Thanks so much! \u2013\u00a0 templatetypedef Jan 16 '13 at 4:44\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/69281/combinatorial-proof-help\nText:\nTake the 2-minute tour \u00d7\n\nI have to prove the identity using a combinatorial proof:\n\n$\\displaystyle\\sum\\limits_{k=0}^n 2^k \\binom{n}{k} = 3^n$\n\nI think this should be my combinatorial proof:\n\nWe want to form a committee of $k$ people from a total of $n$ people. There are two ways of counting this committee.\n\n1) Go through each member from the $n$ total people, and decide if they should be added to the committee or not, until we have reached $k$ people. This gives us the LHS.\n\n...For the RHS, however, I am not sure how to form it. I think it should be something like forming subsets of $3$ people and choosing from that, but I'm not sure how that will form the same committee as the LHS.\n\nEDIT: Okay, I also had the idea of forming a ternary string, and I could get the RHS this way. But I was not sure about the LHS. But the first answer gave me the right idea. Thanks a lot.\n\nshare|improve this question\nWhile calculating k people committee from n people committee you will get $\\binom{\\displaystyle n}{\\displaystyle k}$ but how would you account for $2^{k}$ on the LHS ?? \u2013\u00a0 Ramana Venkata Oct 2 '11 at 17:06\nIf this is a homework problem, it should carry the homework tag. If not, please ignore :-) \u2013\u00a0 robjohn Oct 2 '11 at 17:13\n@Ramana True, agreed. Yeh, I should use a ternary string idea. \u2013\u00a0 user952949 Oct 2 '11 at 17:13\n@robjohn: Ok, tagged :) \u2013\u00a0 user952949 Oct 2 '11 at 17:58\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nWe want to form $n$-letter words over the alphabet $\\{a,b,c\\}$. There are $3^n$ such words.\n\nTo count these words in another way, take a fixed $k$, where $0 \\le k \\le n$. To make an $n$-letter word with a total of $k$ $a$'s and/or $b$'s, choose the $k$ positions that will have $a$ and/or $b$. This can be done in $\\binom{n}{k}$ ways. For each such way, these $k$ positions can be filled with $a$'s and/or $b$'s in $2^k$ ways, for a total of $2^k \\binom{n}{k}$ ways. For each of these $2^k\\binom{n}{k}$ ways, there is only one way to put in the $c$'s. Finally, add up, $k=0$ to $n$.\n\nshare|improve this answer\nThanks. I was also thinking of using a ternary string idea at first. I could form the RHS, but was having trouble with the LHS. Thanks for the pointer, this helps. \u2013\u00a0 user952949 Oct 2 '11 at 17:18\nIf you are going to tell two stories, one for the right, one for the left, committees (\"choose\") seem unsuitable. You can easily generalize the above idea in various ways, to get other identities. \u2013\u00a0 Andr\u00e9 Nicolas Oct 2 '11 at 17:46\n\nThere is a nice double counting proof, from the geometric point of view. Consider all faces of a n-cube. These faces can be encoded by a sequence of \"0\", \"1\" and a \"*\", where the star signifies that the coordinate can be either 0 or 1 in the face. This immediately gives $3^n$ faces. On the other hand, the number of $k$-dimensional faces is equal to $\\binom{n}{k}$ way of choosing $k$ coordinates times $2^{n-k}$ ways of fixing the remaining coordinates, all summed over all $k=1..n$. Of course, this proof is actually equivalent to that by Andre above.\n\nP.S. This is actually Example 8.3 in my discrete geometry book (sorry for the shameless plug - much of the book is about something else).\n\nshare|improve this answer\nThanks for the reference :). \u2013\u00a0 Srivatsan Oct 6 '11 at 3:09\nWow, thanks for pointing me to a geometry proof. Very interesting :D \u2013\u00a0 user952949 Oct 6 '11 at 19:00\n\nHint: Remember that $3^n$ is the number of ways to put a set of $n$ distinct things into an array of $3$ containers. Likewise, $2^n$ is the number of ways to put a set of $n$ distinct things into an array of $2$ containers.\n\nshare|improve this answer\nYes, true. I was thinking about it in a stupid way, I should use a forming a string method, much more intuitive than the committee method. \u2013\u00a0 user952949 Oct 2 '11 at 17:19\n@user952949: Since it's been 4 days, there's probably no harm in mentioning that there are $\\binom{n}{k}$ ways to choose which $k$ things go into the first two containers and which $n-k$ things go into the third. \u2013\u00a0 robjohn Oct 6 '11 at 17:56\nThanks for your help :) I finished the proof a while ago, I forgot to close the question. \u2013\u00a0 user952949 Oct 6 '11 at 18:57\n\nWhile you are not looking for an algebraic proof, the algebraic proof using the binomial theory is tempting...\n\n$\\sum_{k=0}^{n} \\binom{n}{k} (1+1)^{k}.1^k=(2+1)^n$\n\nshare|improve this answer\nBut we have to prove it using double counting. But yes, an algebraic proof would look nice and neat. \u2013\u00a0 user952949 Oct 6 '11 at 18:58\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209441/prove-factoring-is-in-np\nText:\nTake the 2-minute tour \u00d7\n\nINPUT: an integer $n$ and a integer $d$\nQUESTION: does $n$ have a prime factor less than $d$?\n\nDoes a polynomial time algorithm exist that can tell whether or not $n$ has a prime factor $< d$?\n\nWould iterating through all possible primes $< d$ take too long?\n\nshare|improve this question\nYour title doesn't match your question. \u2013\u00a0 Chris Eagle Oct 8 '12 at 20:19\nAm I mistaken that in order to prove a problem is in NP the following must be true? \"Given some information C, you can create an algorithm V that will verify for every input whether X is in your domain or not. V must run in polynomial time.\" \u2013\u00a0 Takkun Oct 8 '12 at 20:22\nTakkun: you are mistaken. The most straightforward characterization of NP is as polynomially checkable problems, roughly: 'if we are given a purported solution for this problem, can we in fact verify that it is a solution in polynomial time?' Note that this then allows you to guess a potential solution (the 'N', Nondeterministic) and then check it in polynomial time (the 'P', Polynomial). \u2013\u00a0 Steven Stadnicki Oct 8 '12 at 20:24\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nIterating through all possible primes $\\lt d$ would in fact take too long; assuming that $n$ and $d$ are both given in binary and that $d$ is comparable to $n$, then it would take time exponential in the size of your input. But you don't have to iterate through all possible primes; instead, you can guess a number $k$ less than $d$ and then check whether or not $k$ is a factor of $n$. (Can you see why you don't need to check whether $k$ is prime or not?)\n\nshare|improve this answer\nIs it true that every non-prime number has a prime factor? (Addressing your question of why you don't have to check for primality of k) \u2013\u00a0 Takkun Oct 8 '12 at 20:54\n@Takkun Exactly; and moreso, that factor must be less than the number itself - so even if $k$ isn't prime, you've established that $n$ has some prime factor $p\\leq k\\lt d$. (Note that this means you don't necessarily know what the prime factor is - you're answering a yes-no question, not finding a value!) \u2013\u00a0 Steven Stadnicki Oct 8 '12 at 21:01\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/255885/constructing-idempotent-generator-of-idempotent-ideal/258657\nText:\nTake the 2-minute tour \u00d7\n\nExercise 2.1 in Matsumura's Commutative Ring Theory reads as follows: \"Let $A$ be a commutative ring and $I$ an ideal that is finitely generated and $I=I^2$. Then $I$ is generated by an idempotent.\"\n\nIn trying to solve it, i first followed a constructive approach, where e.g. for the case of two generators i tried to construct an idempotent generator. However, it seemed difficult. Then i realized that i could apply Nakayama's lemma to the $A$-module $I$ and the existence of the idempotent generator follows.\n\nMy question is: How could one go about finding this idempotent generator? Is there a systematic way?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nOne can reconstruct a method by considering the usual proof of Nakayama's lemma.\n\nSuppose you know that the ideal is generated by $n$ elements, $(x_1, ..., x_n)$. By assumption, we may write $x_i = \\sum a_{ij} x_j$, where the $a_{ij} \\in I$. The element we're looking for is $p(1) -1$, where $p$ is the characteristic polynomial of the matrix $(a_{ij})$.\n\nTo see this, consult the proof of NAK in, say, Matsumura or Atiyah-Macdonald.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/355720/probability-distribution-of-a-sum-of-random-variables\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have two independent random variables $X$ and $Y$. Their sum is $Z = X + Y$. How can I calculate the conditional distribution of $P(Z|X)$?\n\nshare|improve this question\nDo you mean the conditional distribution? or the conditional expectation? \u2013\u00a0 Sim\u00e9on Apr 9 '13 at 8:04\n@Ju'x: I mean the conditional distribution. Sorry for the confusion. \u2013\u00a0 prasopes Apr 9 '13 at 8:05\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nRecall that the conditional distribution of $Z$ conditioned by $X$ is defined as any family of probability measures $(\\mu_x)_x$ such that, for every bounded function $u$, one has $E[u(Z)\\mid X]=v(X)$, where the function $v$ is defined as $$ v(x)=\\int u(z)\\mathrm d\\mu_x(z). $$ Here, one can take for each $\\mu_x$ the distribution of $x+Y$. Thus, introducing the distribution $\\nu$ of $Y$, for every Borel subset $B$ and every $x$, one sets $$ \\mu_x(B)=P[x+Y\\in B]=\\nu(B-x). $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56476.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nEllipse Geometry\n\nDate: 08/09/98 at 03:03:00\nFrom: Simon Crosbie\nSubject: Ellipse geometry\n\nan ellipse and bisecting the perimeter of the ellipse at right angles \nto the tangent at that point. How do I determine the distance along \nthe long axis of an ellipse that this line must start from? \n\nI am a joiner who specializes in constructing special-shaped plantation \nshutters. A formula showing this relation would help me work out the \nprecise timbers required to construct an ellipse. I have already worked \nout a formula which I use to draw an ellipse of a given width and \nheight using two centers and a piece of string. The distance between \nthe two centers is found with the expression:\n\n   Center spacing = 2*Sqrt((Height/2)*(Height/2)*(Width/2))\n   Length of string = Height + Center spacing\n\nwhere Height is the length of the long axis of the ellipse and Width \nis the length of the short axis.\n\nDate: 08/09/98 at 09:16:33\nFrom: Doctor Jerry\nSubject: Re: Ellipse geometry\n\nHi Simon,\n\nLet's see if I understand your problem. You have an ellipse:\n\n\nThe numbers 2a and 2b are the lengths of the major and minor axes. The \nfoci of the ellipse are at (-c,0) and (c,0), where c = sqrt(a^2-b^2). \nThe length of the string is 2a.\n\nI think 2a is what you have called width and 2b is what you have called \nheight. I don't understand your formula for center spacing. I'd say \nthat the center spacing (the distance between centers) is: \n\n   2c = 2*sqrt(a^2-b^2)\n\nI'll use what I understand, as outlined in my first paragraph. You are \nseeking a point (X,0), where -a < X < a, on the major axis, from which \na line at a specified angle d (I'll assume 0 < d < 90) will intercept \nthe ellipse at right angles to the tangent.\n\nThere is a well-known formula for the equation of the tangent line to \nthe ellipse at any point (x0,y0) of the ellipse. It is:\n\n   a^2*y0*y + b^2*x*x0 = a^2*b^2\n\nAssuming (x0,y0) is in the first quadrant, the slope of this line is\n-b^2*x0/(a^2*y0). The slope of the line K perpendicular to this line is \nthe negative reciprocal of this, namely, a^2*y0/(b^2*x0). This is the \ntangent of the angle d.\n\nThe equation of K is y-y0 = a^2*y0/(b^2*x0)(x-x0). Its x-intercept, \nwhich you want, is (set y=0):\n\n   X = x0(1-b^2/a^2) = x0(a^2-b^2)/a^2 = x0*c^2/a^2\n\nSince tan(d) = a^2*y0/(b^2*x0) and x0^2/a^2+y0^2/b^2 = 1, we can \neliminate y0:\n\n   1/x0^2 = (b^2/a^4)tan^2(d) + 1/a^2  \n\nWe now know x0 in terms of d. Put this into the equation for X and \nyou're done.\n\nPlease check this out. Write back if I've made mistakes or been \n\n- Doctor Jerry, The Math Forum\nAssociated Topics:\nHigh School Conic Sections/Circles\nHigh School Coordinate Plane Geometry\nHigh School Geometry\nHigh School Practical Geometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/7779/how-can-i-easily-eliminate-the-dependency-of-a-stylesheet-on-a-non-built-in-styl?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nAs per discussion here:\n\nUser A has a notebook that uses custom definitions from styles.nb. Now user A passes the notebook to user B. The styles do not show up for B because B does not have styles.nb. This is because the private stylesheet for the notebook inherits from styles.nb (which inherits from Default.nb).\n\nHow can I easily copy the definitions from style.nb into the private styles for the notebook i.e. as if style.nb didn't exist and all custom definitions were in the private styles and base inherited from Default.nb\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 19 down vote accepted\n\nIn answering the question the underlying assumptions are that the parent stylesheet (myparent.nb) of private stylesheet for a notebook is not a built in stylesheet; and that the stylesheet has one or more custom styles that inherit from myparent.nb.\n\n\nstylesheetSetter[path_String] := \n Module[{child, childstyles, parent, nb, tmp, parentparent, \n\n(* find the parent stylesheet from the private stylesheet, a.k.a child *)\n  child = Options[EvaluationNotebook[], StyleDefinitions];\n  parent = \n     Cell[StyleData[StyleDefinitions -> x_]] :> x, \\[Infinity]];\n  childstyles = Cases[child, Cell[StyleData[_, ___], __], \\[Infinity]];\n\n(* get the parent *)\n  nb = NotebookOpen[path <> parent];\n  tmp = NotebookGet[nb];\n\n (* find the parent definition *)\n\n  parentparent = \n   Cases[tmp, Cell[StyleData[StyleDefinitions -> x_]], \\[Infinity]];\n\n (* scrape the styles *)\n\n  parentstyles = \n   Cases[tmp, Cell[StyleData[x_, y___], z__], \\[Infinity]];\n\n (* merge parents parent, child styles, parent styles *)\n\n   StyleDefinitions -> \n    Notebook[Join[parentparent, childstyles, parentstyles], \n     StyleDefinitions -> \"PrivateStylesheetFormatting.nb\"]];\n\n\n  1. I have a notebook.\n\n  2. I chose a user created notebook \"mystyles.nb\" as my stylesheet (Format > Stylsheet).\n\n  3. In the course of using this notebook I decided I wanted to change some styles. I then edited the private stylesheet to alter the styles for e.g. \"Input\", \"Text\" ...whatever. This can be done in a number of ways but most users will do this via Format > Edit Stylesheet...\n\n  4. Find out what the path to your user created stylesheets is. For me it is\n\n\npath = $UserBaseDirectory <> \"/SystemFiles/FrontEnd/StyleSheets/\";\n\nNow run the function:\n\n\nIf you now go to Format > Edit Stylesheet... you should now see that your private stylesheet has a built in stylesheet as its parent.\n\nNote that I haven't added checks and condition to see whether a private stylesheet is being used and if it meets the conditions. So this will only work under the conditions described. Another assumption is that a built in stylesheet can be found one parent back from the user created stylesheet.\n\nAn alternative is to mix and match styles programmatically. This function will take an existing stylesheet, a list of style data cells, and a new stylesheet name and return the stylesheet:\n\n\nstylesheetChanger[file_String, mynewstyles_List, \n  stylesheetname_String] := Module[{nb, tmp, parent, cells},\n\n  nb = NotebookOpen[file];\n  tmp = NotebookGet[nb];\n  (* find the parent definition *)\n\n  parent = Cases[tmp, Cell[StyleData[StyleDefinitions -> x_]], {1, 2}];\n  (* scrape the styles *)\n\n  cells = Cases[tmp, Cell[StyleData[x_, y___], z__], {1, 3}];\n  (* create a new style sheet that references a built in stylesheet \\\nand merges the old and new styles *)\n\n  nb = CreateDocument[\n    Notebook[Join[parent, mynewstyles, cells], \n     StyleDefinitions -> \"PrivateStylesheetFormatting.nb\"], \n    WindowSize -> All];\n  (* save the stylesheet *)\n  NotebookSave[nb, stylesheetname];\n\n\nmyColor = Black;\nbackground = GrayLevel[1];\n\nexistingstylesheet = $UserBaseDirectory <> \n\nmynewstyles = {Cell[StyleData[\"Input\"], FontColor -> myColor, \n   Background -> background, \n   AutoStyleOptions -> {\"CommentStyle\" -> {FontColor -> \n        RGBColor[0, 0, 1], FontSize -> 11, \n       FontFamily -> \"Comic Sans MS\", ShowAutoStyles -> False, \n       ShowSyntaxStyles -> False, AutoNumberFormatting -> False}}]}\n\nstylesheetChanger[existingstylesheet, mynewstyles, \"newstylesheet.nb\"]\nshare|improve this answer\nNice, but I nearly downvoted you for the use of Comic Sans. \u2013\u00a0 Verbeia Jul 2 '12 at 4:24\nThis is nice, thanks Mike \u2013\u00a0 rm -rf Jul 2 '12 at 4:27\n@Verbeia I find that fonts like Comic Sans are very good for comments. :) \u2013\u00a0 Mike Honeychurch Jul 2 '12 at 5:01\n@MikeHoneychurch very useful. Thank you! \u2013\u00a0 Black Milk Apr 28 '13 at 4:46\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56132.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPossible Combinations on a Push Lock\n\nDate: 4/17/96 at 15:53:5\nFrom: Anonymous\nSubject: lock problem\n\nThe digits available are 1 thru 5.  Furthermore, in each \ncombination a digit can occur only once.  You need at least two \npushes to open the lock. How many different combinations are \n\nThis is as far as I got......\n\n\t5! = 120 combinations\n\nThis seem to be the right answer but I feel that there is more to \nit. I am not sure I understand the problem fully.  Any help to the \nsolution of this problem would be most appreciated.\n\nDate: 4/18/96 at 20:2:40\nFrom: Doctor Ken\nSubject: Re: lock problem\n\nHey there -\n\nIf I understand this problem correctly, you can't use any number \ntwice in a combination, even if they are in different pushes.  So \nthe following would be okay:\n\n4, then \n5 and 2, \nthen 3 and 1.  \n\nBut this wouldn't:\n\n4, then\n5 and 4, then\n3 and 4, because you re-use 4.\n\nNotice that this limits us to at most 5 pushes, because after that \nyou're going to have to start repeating.  Anyway, let's get some \nnotation: if a push consists of 5 and 4, for example, let's write \nthat as (5,4).  And let's use the + sign to seperate consecutive \npushes, so that the first combination we had would be written as \n(4) + (5,2) + (3,1).\n\nAnyway, I think this is a harder problem than one that will be \nable to be solved with just one case: we're going to have to break \nit down.\n\nSo let's break it down according to how many digits we use in each \ncombination.  We know we need to use at least 2, because we need \nto have at least 2 pushes.  So how many different combinations can \nwe have that use exactly 2 digits?  Well, we'll have 5 choices for \nthe first one and 4 choices for the second (order does matter in \nthis case).  So that's 20 ways of choosing our digits.  Then how \nmany different combinations can we get with these 2 digits?  It \nseems pretty obvious, in this case, that all we can do is push one \nbutton, then the other (i.e. we can't push 2 at the same time).  \nSo we'll just get 20 different combinations that use 2 digits.\n\nNow let's look at 3 digits, which is a little more interesting.  \nHow many ways can we choose which 3 digits to use?  Well, again, \nit's 5*4*3 = 60.  \n\nBut now we have several choices for whether these buttons are \npushed one at a time, or together with others.  For instance, if \nwe chose the digits 1, 2, and 3, in that order, we could have \n(1) + (2) + (3), or we could have (1,2) + (3), or (1) + (2,3).  \nIt looks like these are the only possible combinations that use \nonly 1, 2, and 3 in that order.  So since every selection of 3 \ndigits will have these 3 different combination orders, there will \nbe a total of 60 * 3 = 180 combinations that use 3 digits.\n\nCan you do the cases where we use 4, and then 5 digits yourself?  \nThey get tougher the more digits you have, but try to get it \nyourself before you write back for more help.  This is a neat \nproblem, and it will be worth it if you solve it yourself.\n\n-Doctor Ken,  The Math Forum\n\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/143252/system-of-odes-and-lyapunov-function\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI've tried to solve a little problem that goes as follows:\n\nConsider a system of ODEs: $$x'=y-x^3\\text{ and } y'=-x^3-y^3$$ And the function $$L(x,y)=\\frac{1}{2}y^2+\\frac{1}{4}x^4.$$\n\nNow I shall show that $(0,0)$ is not linearly stable, and that $L$ is a Lyapunov function.\n\nI tried to investigate $\\frac{dL}{dy}$ and $\\frac{dL}{dx}$ and check if this is smaller or greater than $0$ at (0,0). However, these two terms are just $\\frac{dL}{dy}=y,\\frac{dL}{dx}=x^3$, so it seems we have to solve for $x,y$ explicitly? I'm confused because this looks like one of those exercise where brute-force can be avoided (And we did not deal with non-linear ODEs yet)?\n\nyours, Marie\n\nshare|cite|improve this question\nYou can investigate \"the derivative of L with respect to your system\", $\\nabla L \\cdot f(y)$, where $f(y)$ is your system. See the example here. The system is guaranteed to be stable if this derivative is negative definite. \u2013\u00a0tentaclenorm May 9 '12 at 22:37\nup vote 2 down vote accepted\n\nFor $L(x,y)$ to be a Lyapunov function, what you want to do is consider $$\\dfrac{dL}{dt} = y \\dfrac{dy}{dt} + x^3 \\dfrac{dx}{dt} = y (-x^3 - y^3) + x^3 (y - x^3)$$ Do you see why $\\dfrac{dL}{dt} \\le 0$, with equality only at $(0,0)$? And why $L(x,y) \\ge 0$, with equality only at $(0,0)$?\n\nshare|cite|improve this answer\nAwesome! So for the linear stability, we also have to differentiate w.r.t. $t$, not $x,y$ and hence the two exercises were connected! :) \u2013\u00a0Marie. P. May 9 '12 at 23:06\nWait - I see how $\\frac{dL}{dt}<0$ and $L(x,y)>0$ except equalities at $0$, but if the derivative is negative, then how can the function start at $0$ and then be always greater than zero? \u2013\u00a0Marie. P. May 9 '12 at 23:16\nIf you start at $(0,0)$, then obviously you stay there. If you start somewhere else, then as time goes on $L(x,y)$ decreases so you must approach $(0,0)$. \u2013\u00a0Robert Israel May 10 '12 at 0:34\n@Marie.P.: Also, that second equality there is the reason we say that the derivative ${dL\\over dt}$ is computed along a solution since we substitute back in the dynamics from the ODE there. \u2013\u00a0JohnD Dec 14 '12 at 3:22\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207208/cutting-a-n-dimensional-cubic-cake\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nGiven a cubic cake, defined as $\\{(x,y,z)|0\\leq x,y,z\\leq 1\\}$.\n\nWe cut it by the planes\n\n$p_1\\leftrightarrow x=y$\n\n$p_2\\leftrightarrow y=z$\n\n$p_3\\leftrightarrow x=z$.\n\nHow many pieces will we have after cutting?\n\nAnd the 4-dimensional case: $\\{(x,y,z,u)|0\\leq x,y,z,u\\leq 1\\}$\n\nHow many pieces will we have after having cut by the spaces\n\n$x=y$, $x=z$, $x=u$, $y=z$, $y=u$, $z=u$?\n\nAnd the $n$-dimensional case...\n\nshare|cite|improve this question\nHint: What are the conditions on the two subsets after cutting along $x=y$? That is, how do you determine if $(x,y,z)$ is in one subset or the other? \u2013\u00a0Thomas Andrews Oct 4 '12 at 15:30\nI have a solution, but i wanted to share this with others. Because i find it a beautiful problem. \u2013\u00a0barto Oct 4 '12 at 15:37\nThis is not a puzzle site, it is a site for answering questions so that later people with the same question can find the answer. So if you have an answer, then post it. @barto \u2013\u00a0Thomas Andrews Oct 4 '12 at 15:41\nup vote 1 down vote accepted\n\nWhen cutting by the space $x=y$, we divide the cake in two parts:\n\nOne part with $x>y$ and one part with $x<y$.\n\nThe same holds for spaces like $y=z$, $z=u$, ...\n\nThat means, that every ordering of the variables $x$, $y$, $z$, ... defines a part. And since there are $n!$ orderings, there are $n!$ pieces after cutting.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://tutorial.math.lamar.edu/Classes/DE/LaplacesEqn.aspx\nText:\nPaul's Online Math Notes\nDifferential Equations (Notes) / Partial Differential Equations (Notes) / Laplace's Equation\u00a0\u00a0 [Notes]\nDifferential Equations - Notes\n\n\u00a0Laplace\u2019s Equation\n\nThe next partial differential equation that we\u2019re going to solve is the 2-D Laplace\u2019s equation,\n\n\n\n\nA natural question to ask before we start learning how to solve this is does this equation come up naturally anywhere?\u00a0 The answer is a very resounding yes!\u00a0 If we consider the 2-D heat equation,\n\n\n\n\n\u00a0We can see that Laplace\u2019s equation would correspond to finding the equilibrium solution (i.e. time independent solution) if there were not sources.\u00a0 So, this is an equation that can arise from physical situations.\n\n\nHow we solve Laplace\u2019s equation will depend upon the geometry of the 2-D object we\u2019re solving it on.\u00a0 Let\u2019s start out by solving it on the rectangle given by , .\u00a0 For this geometry Laplace\u2019s equation along with the four boundary conditions will be,\n\n\n\n\nOne of the important things to note here is that unlike the heat equation we will not have any initial conditions here.\u00a0 Both variables are spatial variables and each variable occurs in a 2nd order derivative and so we\u2019ll need two boundary conditions for each variable.\n\n\nNext, let\u2019s notice that while the partial differential equation is both linear and homogeneous the boundary conditions are only linear and are not homogeneous.\u00a0 This creates a problem because separation of variables requires homogeneous boundary conditions.\n\n\nTo completely solve Laplace\u2019s equation we\u2019re in fact going to have to solve it four times.\u00a0 Each time we solve it only one of the four boundary conditions can be nonhomogeneous while the remaining three will be homogeneous.\u00a0\n\n\nThe four problems are probably best shown with a quick sketch so let\u2019s consider the following sketch.\n\n\n\n\nNow, once we solve all four of these problems the solution to our original system, (1), will be,\n\n\n\n\n\nBecause we know that Laplace\u2019s equation is linear and homogeneous and each of the pieces is a solution to Laplace\u2019s equation then the sum will also be a solution.\u00a0 Also, this will satisfy each of the four original boundary conditions.\u00a0 We\u2019ll verify the first one and leave the rest to you to verify.\n\n\n\n\nIn each of these cases the lone nonhomogeneous boundary condition will take the place of the initial condition in the heat equation problems that we solved a couple of sections ago.\u00a0 We will apply separation of variables to the each problem and find a product solution that will satisfy the differential equation and the three homogeneous boundary conditions.\u00a0 Using the Principle of Superposition we\u2019ll find a solution to the problem and then apply the final boundary condition to determine the value of the constant(s) that are left in the problem.\u00a0 The process is nearly identical in many ways to what we did when we were solving the heat equation.\n\n\nWe\u2019re going to do two of the cases here and we\u2019ll leave the remaining two for you to do.\n\n\nExample 1 \u00a0Find a solution to the following partial differential equation.\n\n\n\nWe\u2019ll start by assuming that our solution will be in the form,\n\n\nand then recall that we performed separation of variables on this problem (with a small change in notation) back in Example 5 of the Separation of Variables section.\u00a0 So from that problem we know that separation of variables yields the following two ordinary differential equations that we\u2019ll need to solve.\n\n\n\nNote that in this case, unlike the heat equation we must solve the boundary value problem first.\u00a0 Without knowing what \u00a0is there is no way that we can solve the first differential equation here with only one boundary condition since the sign of \u00a0will affect the solution.\u00a0\n\n\nLet\u2019s also notice that we solved the boundary value problem in Example 1 of Solving the Heat Equation and so there is no reason to resolve it here.\u00a0 Taking a change of letters into account the eigenvalues and eigenfunctions for the boundary value problem here are,\n\n\n\nNow that we know what the eigenvalues are let\u2019s write down the first differential equation with \u00a0plugged in.\n\n\nBecause the coefficient of \u00a0in the differential equation above is positive we know that a solution to this is,\n\n\n\nHowever, this is not really suited for dealing with the \u00a0boundary condition.\u00a0 So, let\u2019s also notice that the following is also a solution.\n\n\n\nYou should verify this by plugging this into the differential equation and checking that it is in fact a solution.\u00a0 Applying the lone boundary condition to this \u201cshifted\u201d solution gives,\n\n\n\nThe solution to the first differential equation is now,\n\n\nand this is all the farther we can go with this because we only had a single boundary condition.\u00a0 That is not really a problem however because we now have enough information to form the product solution for this partial differential equation.\n\n\nA product solution for this partial differential equation is,\n\n\n\nThe Principle of Superposition then tells us that a solution to the partial differential equation is,\n\n\nand this solution will satisfy the three homogeneous boundary conditions.\n\n\nTo determine the constants all we need to do is apply the final boundary condition.\n\n\n\nNow, in the previous problems we\u2019ve done this has clearly been a Fourier series of some kind and in fact it still is.\u00a0 The difference here is that the coefficients of the Fourier sine series are now,\n\n\ninstead of just .\u00a0 We might be a little more tempted to use the orthogonality of the sines to derive formulas for the , however we can still reuse the work that we\u2019ve done previously to get formulas for the coefficients here.\n\n\nRemember that a Fourier sine series is just a series of coefficients (depending on n) times a sine.\u00a0 We still have that here, except the \u201ccoefficients\u201d are a little messier this time that what we saw when we first dealt with Fourier series.\u00a0 So, the coefficients can be found using exactly the same formula from the Fourier sine series section of a function on \u00a0we just need to be careful with the coefficients.\u00a0\n\n\n\nThe formulas for the \u00a0are a little messy this time in comparison to the other problems we\u2019ve done but they aren\u2019t really all that messy.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\n\nOkay, let\u2019s do one of the other problems here so we can make a couple of points.\n\n\nExample 2 \u00a0Find a solution to the following partial differential equation.\n\n\n\nOkay, for the first time we\u2019ve hit a problem where we haven\u2019t previous done the separation of variables so let\u2019s go through that.\u00a0 We\u2019ll assume the solution is in the form,\n\n\n\nWe\u2019ll apply this to the homogeneous boundary conditions first since we\u2019ll need those once we get reach the point of choosing the separation constant.\u00a0 We\u2019ll let you verify that the boundary conditions become,\n\n\n\nNext, we\u2019ll plug the product solution into the differential equation.\n\n\n\nNow, at this point we need to choose a separation constant.\u00a0 We\u2019ve got two homogeneous boundary conditions on h so let\u2019s choose the constant so that the differential equation for h yields a familiar boundary value problem so we don\u2019t need to redo any of that work.\u00a0 In this case, unlike the \u00a0case, we\u2019ll need .\n\n\nThis is a good problem in that is clearly illustrates that sometimes you need \u00a0as a separation constant and at other times you need .\u00a0 Not only that but sometimes all it takes is a small change in the boundary conditions it force the change.\n\n\nSo, after adding in the separation constant we get,\n\n\nand two ordinary differential equations that we get from this case (along with their boundary conditions) are,\n\n\n\nNow, as we noted above when we were deciding which separation constant to work with we\u2019ve already solved the first boundary value problem.\u00a0 So, the eigenvalues and eigenfunctions for the first boundary value problem are,\n\n\n\nThe second differential equation is then,\n\n\n\nBecause the coefficient of the \u00a0is positive we know that a solution to this is,\n\n\n\nIn this case, unlike the previous example, we won\u2019t need to use a shifted version of the solution because this will work just fine with the boundary condition we\u2019ve got for this.\u00a0 So, applying the boundary condition to this gives,\n\n\nand this solution becomes,\n\n\n\nThe product solution for this case is then,\n\n\n\nThe solution to this partial differential equation is then,\n\n\n\nFinally, let\u2019s apply the nonhomogeneous boundary condition to get the coefficients for this solution.\n\n\n\nAs we\u2019ve come to expect this is again a Fourier sine (although it won\u2019t always be a sine) series and so using previously done work instead of using the orthogonality of the sines to we see that,\n\n\n\nOkay, we\u2019ve worked two of the four cases that would need to be solved in order to completely solve (1).\u00a0 As we\u2019ve seen each case was very similar and yet also had some differences.\u00a0 We saw the use of both separation constants and that sometimes we need to use a \u201cshifted\u201d solution in order to deal with one of the boundary conditions.\n\n\nBefore moving on let\u2019s note that we used prescribed temperature boundary conditions here, but we could just have easily used prescribed flux boundary conditions or a mix of the two.\u00a0 No matter what kind of boundary conditions we have they will work the same.\n\n\nAs a final example in this section let\u2019s take a look at solving Laplace\u2019s equation on a disk of radius a and a prescribed temperature on the boundary.\u00a0 Because we are now on a disk it makes sense that we should probably do this problem in polar coordinates and so the first thing we need to so do is write down Laplace\u2019s equation in terms of polar coordinates.\n\n\nLaplace\u2019s equation in terms of polar coordinates is,\n\n\n\n\n\nOkay, this is a lot more complicated than the Cartesian form of Laplace\u2019s equation and it will add in a few complexities to the solution process, but it isn\u2019t as bad as it looks.\u00a0 The main problem that we\u2019ve got here really is that fact that we\u2019ve got a single boundary condition.\u00a0 Namely,\n\n\n\n\nThis specifies the temperature on the boundary of the disk.\u00a0 We are clearly going to need three more conditions however since we\u2019ve got a 2nd derivative in both r and\n\n\nWhen we solved Laplace\u2019s equation on a rectangle we used conditions at the end points of the range of each variable and so it makes some sense here that we should probably need the same kind of conditions here as well.\u00a0 The range on our variables here are,\n\n\n\n\nNote that the limits on \u00a0are somewhat arbitrary here and are chosen for convenience here.\u00a0 Any set of limits that covers the complete disk will work, however as we\u2019ll see with these limits we will get another familiar boundary value problem arising.\u00a0 The best choice here is often not known until the separation of variables is done.\u00a0 At that point you can go back and make your choices.\n\n\nOkay, we now need conditions for \u00a0and .\u00a0 First, note that Laplace\u2019s equation in terms of polar coordinates is singular at \u00a0(i.e. we get division by zero).\u00a0 However, we know from physical considerations that the temperature must remain finite everywhere in the disk and so let\u2019s impose the condition that,\n\n\n\n\nThis may seem like an odd condition and it definitely doesn\u2019t conform to the other boundary conditions that we\u2019ve seen to this point, but it will work out for us as we\u2019ll see.\n\n\nNow, for boundary conditions for \u00a0we\u2019ll do something similar to what we did for the 1-D head equation on a thin ring.\u00a0 The two limits on \u00a0are really just different sides of a line in the disk and so let\u2019s use the periodic conditions there.\u00a0 In other words,\n\n\n\nWith all of this out of the way let\u2019s solve Laplace\u2019s equation on a disk of radius a.\n\n\nExample 3 \u00a0Find a solution to the following partial differential equation.\n\n\n\nIn this case we\u2019ll assume that the solution will be in the form,\n\n\n\nPlugging this into the periodic boundary conditions gives,\n\n\n\nNow let\u2019s plug the product solution into the partial differential equation.\n\n\n\nThis is definitely more of a mess that we\u2019ve seen to this point when it comes to separating variables.\u00a0 In this case simply dividing by the product solution, while still necessary, will not be sufficient to separate the variables.\u00a0 We are also going to have to multiply by \u00a0to completely separate variables.\u00a0 So, doing all that, moving each term to one side of the equal sign and introduction a separation constant gives,\n\n\n\nWe used \u00a0as the separation constant this time to get the differential equation for \u00a0to match up with one we\u2019ve already done.\n\n\nThe ordinary differential equations we get are then,\n\n\n\nNow, we solved the boundary value problem above in Example 3 of the Eigenvalues and Eigenfunctions section of the previous chapter and so there is no reason to redo it here.\u00a0 The eigenvalues and eigenfunctions for this problem are,\n\n\n\nPlugging this into the first ordinary differential equation and using the product rule on the derivative we get,\n\n\n\nThis is an Euler differential equation and so we know that solutions will be in the form \u00a0provided p is a root of,\n\n\n\nSo, because the \u00a0case will yield a double root, versus two real distinct roots if \u00a0we have two cases here.\u00a0 They are,\n\n\n\nNow we need to recall the condition that .\u00a0 Each of the solutions above will have \u00a0as \u00a0Therefore in order to meet this boundary condition we must have .\n\n\nTherefore, the solution reduces to,\n\n\nand notice that with the second term gone we can combine the two solutions into a single solution.\n\n\nSo, we have two product solutions for this problem.\u00a0 They are,\n\n\n\nOur solution is then the sum of all these solutions or,\n\n\n\nApplying our final boundary condition to this gives,\n\n\n\nThis is a full Fourier series for \u00a0on the interval , i.e. .\u00a0 Also note that once again the \u201ccoefficients\u201d of the Fourier series are a little messier than normal, but not quite as messy as when we were working on a rectangle above.\u00a0 We could once again use the orthogonality of the sines and cosines to derive formulas for the \u00a0and \u00a0or we could just use the formulas from the Fourier series section with \u00a0to get,\n\n\n\nUpon solving for the coefficients we get,\n\n\n\nPrior to this example most of the separation of variable problems tended to look very similar and it is easy to fall in to the trap of expecting everything to look like what we\u2019d seen earlier.\u00a0 With this example we can see that the problems can definitely be different on occasion so don\u2019t get too locked into expecting them to always work in exactly the same way.\n\n\nBefore we leave this section let\u2019s briefly talk about what you\u2019d need to do on a partial disk.\u00a0 The periodic boundary conditions above were only there because we had a whole disk.\u00a0 What if we only had a disk between say .\n\n\nWhen we\u2019ve got a partial disk we now have two new boundaries that we not present in the whole disk and the periodic boundary conditions will no longer make sense.\u00a0 The periodic boundary conditions are only used when we have the two \u201cboundaries\u201d in contact with each other and that clearly won\u2019t be the case with a partial disk.\n\n\nSo, if we stick with prescribed temperature boundary conditions we would then have the following conditions\n\n\n\n\nAlso note that in order to use separation of variables on these conditions we\u2019d need to have \u00a0to make sure they are homogeneous.\n\n\nAs a final note we could just have easily used flux boundary conditions for the last two if we\u2019d wanted to.\u00a0 The boundary value problem would be different, but outside of that the problem would work in the same manner.\n\n\nWe could also use a flux condition on the \u00a0boundary but we haven\u2019t really talked yet about how to apply that kind of condition to our solution.\u00a0 Recall that this is the condition that we apply to our solution to determine the coefficients.\u00a0 It\u2019s not difficult to use we just haven\u2019t talked about this kind of condition yet.\u00a0 We\u2019ll be doing that in the next section.\n\n\n\u00a9 2003 - 2016 Paul Dawkins"}
{"text": "Retrieved from http://mathoverflow.net/questions/158536/modifying-dehns-algorithm-to-allow-equal-length-replacements\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm an analyst trying to understand a certain class of finitely presented groups (one example is below) so it's quite likely this question is naive but I hope it is at least intelligible. Given a finitely presented group $G$ with generators $g_1, \\dots g_n$ and relations $R=\\{r_1,\\dots r_m\\}$ one would like to solve the word problem in $G$; of course it is not solvable in general, but is solvable for certain classes of $G$. In particular there is Dehn's algorithm, which (as I understand it) runs like this: given a word $w$ in the generators, with length $|w|$, if one finds a subword $v$ of $w$ such that $vu^{-1}\\in R$ and $|u|<|v|$ then replace $v$ by $u$ and continue. If no such word $v$ exists, stop. (The length-decreasing condition guarantees that the algorithm will halt.) Say Dehn's algorithm works if, whenever $w=e$ in $G$, then Dehn's algorithm successfully reduces $w$ to $e$. (One should probably have some symmetry conditions on the set of relators (that they be closed under cyclic permutations, etc.); for the purposes of this question assume whatever symmetry you need.)\n\nIt is known that Dehn's algorithm works for surface groups (this was Dehn's original result), and it has since been extended to groups satisfying some kinds of \"small cancellation\" conditions, word-hyperbolic groups, etc. My question is about the following modification of Dehn's algorithm and which, if any, groups for which it is known to work. The idea is simply to modify the original algorithm to allow substitutions $v\\to u$ if $vu^{-1}\\in R$ and $|u|\\leq |v|$, rather than only $|u|<|v|$. (Since everything is finite, it seems clear enough that one can specify some particular method of searching through the word so that the algorithm still halts. That is, at each step first look for length-reducing substitutions; if there are none, look for length-preserving substitutions, there are only finitely many possible so one may enumerate the possibilities and specify some rule for picking one. After each length-preserving substitution, check again for length-reducing substitutions. If there is one, continue, if none of the possible length-preserving substitutions allow for a subsequent length-reducing substitution, halt.)\n\nA motivating example is the following: consider the group $G$ on six generators $g_1, g_2, g_3, h_1, h_2, h_3$ and relations $$ R=\\{ g_jh_kh_j^{-1}g_k^{-1}:j,k =1,2,3 \\text{ distinct}\\}; $$ enlarge $R$ to be closed under inverses and cyclic permutations. It is not hard to see that Dehn's algorithm fails in $G$: in particular one may verify that the word $$ w=h_2 h_1^{-1} h_3 h_2^{-1} h_1 h_3^{-1} $$ has the form $$ w=g_1^{-1} rstg_1 $$ with $r,s,t\\in R$ so $w=e$ in $G$. But Dehn's algorithm does not reduce $w$ since all the relators have length 4, and no 3-letter subword of a relator appears in $w$ (a 3-letter subword of a relator must contain both $g$'s and $h$'s). However if we allow length-preserving substitutions such as $h_2h_3^{-1}\\to g_2^{-1}g_3$ then the algorithm gets \"unstuck\": $$ h_2 h_1^{-1} h_3 h_2^{-1} h_1 h_3^{-1} \\to h_2 h_1^{-1} g_2^{-1}g_3 h_1 h_3^{-1}\\to g_1^{-1}g_3 h_1 h_3^{-1} \\to e. $$ I suspect (but don't yet have a proof) that the modified Dehn's algorithm works for this group.\n\nQuestion: are there known classes of groups (beyond those for which Dehn's algorithm works) for which the modified Dehn's algorithm (with substitutions $|u|=|v|$ allowed) solves the word problem?\n\nshare|cite|improve this question\nI suspect there are no other such group clases known: I imagine one can well-(partial-)order the words and run a variant of Dehn's algorithm using the well-order. There may be issues of definability, and so one can't just use \"any\" well-order. In particular, I think one can define a group G' and a translation of rules so that length-preserving rules in G become length reducing rules in G', and get essentially the same results. Gerhard \"Is Just Guessing About This\" Paseman, 2014.02.24 \u2013\u00a0Gerhard Paseman Feb 24 '14 at 19:36\nRemark : A group $G$ has a presentation for which there is a classical Dehn algorithm if and only if $G$ is hyperbolic. You indicated that you know the \"if\" direction; for the \"only if\" direction, it is clear that if there is a presentation where the classical Dehn algorithm works, then the group has a linear Dehn function (which is known to be equivalent to hyperbolicity). \u2013\u00a0Andy Putman Feb 24 '14 at 20:17\n\nThere are some other types of groups for which this type of algorithm would work. The easiest examples are abelian groups. For example, with the free abelian group of rank $2$, $\\langle x,y, \\mid xy=yx \\rangle$, if you systematically make the substitutions $y^ax^b \\mapsto x^ay^b$ with $a,b = \\pm 1$, together with free reductions, then you can transform any word to the normal form $x^iy^j$ with $i,j \\in {\\mathbb Z}$.\n\nThis would work for all groups with a finite confluent rewriting system with respect to an ordering on words that respects length: the lenlex orderings are the most common. This includes surface groups, which you can do already, but this class of groups is closed under direct products, so you are getting some new examples.\n\nThis property is actually stronger than what you want - you don't require complete confluence, just confluence on the identity element. Unfortunately, unlike complete confluence, confluence on the identity is known to be undecidable for a general finite rewriting system.\n\nI tried running the Knuth-Bendix completion algorithm on your $6$-generator example, but without success, so I don't know whether there is a modified Dehn's algorithm for that group.\n\nBut I did verify that it is an automatic group, which means that you can construct finite state automata that can solve the word problem in quadratic time, by reducing word to a normal form.\n\nAdded later: I have now checked HJRW's calculation computationally, and calculated an explicit isomorphism to the group ${\\mathbb Z}^2 * F_2 = \\langle a,b,c,d \\mid ab=ba \\rangle$. This is\n\n$a \\mapsto g_1g_3^{-1}$, $b \\mapsto g_1 g_2^{-1}$, $c \\mapsto h_1$, $d \\mapsto g_1$\n\nwith inverse\n\n$g_1 \\mapsto d$, $g_2 \\mapsto b^{-1}d$, $g_3 \\mapsto a^{-1}d$, $h_1 \\mapsto c$, $h_2 \\mapsto d^{-1}b^{-1}dc$, $h_3 \\mapsto d^{-1}a^{-1}dc$.\n\nshare|cite|improve this answer\nThanks! As you can guess what I'd really like to do is solve the word problem here; I have come across automatic groups as a class in which the word problem is solvable--could you say more about how you verify it is automatic? Is there a theorem that applies here, or an algorithm that (sometimes) says a given group is automatic? \u2013\u00a0Mike Jury Feb 24 '14 at 23:05\nIn this case, I just ran the programs to construct the automata, and they worked. I don't know of any theoretical result that applies to these groups in particular. The programs are available either as a standalone package or from GAP or Magma. \u2013\u00a0Derek Holt Feb 24 '14 at 23:26\n\nIn fact, we can describe your group $G$ quite explicitly.\n\nThe presentation has the property that each generator appears in exactly two relators. Therefore, the corresponding presentation complex $X$ is locally a surface everywhere except at the unique vertex. In particular, $X$ is homeomorphic to a surface $S$ with some number of points identified.\n\nTo find out how many points are identified, we need to compute the link of the vertex. This is exactly the Whitehead graph of the relators $R$, and can be done quite explicitly. If I did it correctly, it consists of two triangles and one hexagon; in particular, it has three components. (I did this in a hurry and may have done it incorrectly, but in any case it's a good exercise to do for yourself, and the same principles apply.)\n\nTherefore, $S$ has a cell decomposition with three vertices, six edges and four three squares, giving $\\chi(S)=0$ and so $S$ is a torus or a Klein bottle. (More explicitly, I think we can see that it is in fact a torus.) Since identifying a pair of vertices corresponds to taking a free product with $\\mathbb{Z}$, we have\n\n$G\\cong \\pi_1S*F_2$ ,\n\nin which case G is in fact a hyperbolic group with torsion, and of course the word problem is easy to solve. Note that this does not contradict your observation that your presentation is not Dehn---as well as a Dehn presentation, hyperbolic groups have many non-Dehn presentations.\n\nIt's not too hard to see this explicitly by using two of the relators to eliminate two of the generators.\n\nshare|cite|improve this answer\nOf course, your class probably don't all have this form. But if the relators are all of length four (as is the case here) then there's a good chance that there's some sort of uniform geometric solution to the word problem. \u2013\u00a0HJRW Feb 25 '14 at 13:51\nThis is very helpful, I'm heartened at the prospect of being able to calculate explicitly. Indeed in the general case all of my relators have length four (though the number of relators will in general be quite a bit larger than the number of generators). Is there a reference you can point me to that describes these methods? \u2013\u00a0Mike Jury Feb 25 '14 at 14:13\nWell, the best-case scenario is that the Whitehead graph is triangle-free. In this case, the presentation complex is non-positively curved, which makes solving the word problem fairly straightforward. This doesn't seem to be the case here. The next-best case is that you can glue in higher-dimensional cubes to make the link of the vertex a flag complex - ie every 1-skeleton of an n-simplex (for n>1) in the Whitehead graph gets filled in. In this case, the resulting complex is again non-positively curved... \u2013\u00a0HJRW Feb 25 '14 at 21:24\n... I haven't had a chance to think about whether this is possible in the case of your example. The standard reference is Metric spaces of non-positive curvature by Bridson and Haefliger, specifically the section on Gromov's link condition. It would help to know the next-simplest example in your class. \u2013\u00a0HJRW Feb 25 '14 at 21:26\nThanks, both answers help a lot. The general case is $3n$ generators $a_1, a_2, a_3, b_1, b_2, b_3,\\dots$ and relations $a_jb_kb_j^{-1}a_k^{-1}, b_jc_kc_j^{-1}b_k^{-1},\\dots $ etc. Actually I think these groups can now be calculated using the explicit isomorphism found by Derek Holt; the $n^{th}$ group will be an amalgamated free product of the $(n-1)^{st}$ group with $\\mathbb Z^2\\ast F_2$. For example in the 9-generator case we get $(\\mathbb Z^2\\ast F_2)\\ast_B(\\mathbb Z^2\\ast F_2)$ where $B$ is the subgroup generated by the $b_j$, which I think is isomorphic to $\\mathbb Z^2\\ast \\mathbb Z$. \u2013\u00a0Mike Jury Feb 26 '14 at 13:09\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/320506/degree-bounds-and-coefficient-size-in-elimination-theory\nText:\nSuppose we have polynomials is of form $$h_1(x_1,\\dots,x_{dn})-c_1\\in\\mathbb Z[x_1,\\dots,x_{dn}]$$ $$\\vdots$$ $$h_{nd}(x_1,\\dots,x_{dn})-c_{nd}\\in\\mathbb Z[x_1,\\dots,x_{dn}]$$ where $h_1(x_1,\\dots,x_{dn}),\\dots,h_n(x_1,\\dots,x_{dn})\\in\\mathbb Z[x_1,\\dots,x_{nd}]$ are homogeneous polynoials of degree $d$ with each $x_i$ degree $1$ (that is only monomials of form $x_{i_1},\\dots,x_{i_d}$) on the conditions that\n\n  1. each coefficient except $c_1,\\dots,c_{nd}$ is random in $[-B,B]\\setminus\\{0\\}$\n\n  2. with $c_1,\\dots,c_{nd}$ being of absolute value at most $B^{1+\\frac1{2^d-1}}$\n\n  3. in each monomial $x_{i_1},\\dots,x_{i_d}$ we have $i_j\\in\\{(j-1)n+1,\\dots,jn\\}$.\n\nThen if you use elimination theory we can successively eliminate variables and reduce to an univariate polynomial.\n\nLet the absolute value of the maximum coefficient size $B'$ of final univariate polynomial in reduced form (no common gcd of coefficients) and the let the degree be $d'$.\n\nThen can $B'^{\\frac1{d'}+\\epsilon}>B^{\\frac1{d(2^d-1)}}$ hold with probability $1-o(1)$ at arbitrarily small $\\epsilon>0$ as $B$ increases and $d$ is fixed?\n\n  \u2022 $\\begingroup$ Editing a question with high frequency indicates that the questioner hasn't thought enough about his/her question before asking. (And my experience is to better stay away from questions that are not well-thought.) $\\endgroup$ \u2013\u00a0tj_ Jan 11 at 23:42\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/45123/dired-file-open-using-external-viewers-based-on-filetype-and-without-promptin\nText:\nWhen I hit RETURN on a filename in Dired, I'd like Emacs to automatically do one of several things, depending on the file's type:\n\n1 - If it's a text file, I'd like to open the file in a new buffer in Emacs.\n\n2 - If the filetype is listed in a user-configurable list of filetypes and external viewers, open the file in an external viewer associated with that filetype.\n\n3 - If the filetype is not text and not in the above list, return an error saying the file is of an unknown type.\n\nI've found some answers (1, 2) that advise using dired-read-shell-command and either ! or & to open files with external viewers.\n\nThe above answers are insufficient for my needs, because:\n\n1 - They require multiple keystrokes (at least ! or & and then RETURN at the prompt), while I want this done with just a single keystroke, without any prompting.\n\n2 - They won't open text files in Emacs, but will instead try to use external viewers for everything. I want text files opened in Emacs.\n\n3 - They dispatch based on filename extensions, while I want to dispatch based on filetype (ie. as a result of using either the \"file\" or \"mimetype\" command on linux)\n\n4 - They don't error-out if the filetype is not found in the list of known filetypes.\n\n\nThe following is a macOS specific solution as it needs file(1) and open(1). Feel free to adjust the code.\n\n(defun chunyang-file-mime-type (file)\n  \"Return mime-type of FILE.\"\n  ;; file(1) doesn't fail in such case\n  (unless (file-readable-p file)\n    (error \"%s: No such file or no read permission\" file))\n    (let ((exit (call-process \"file\" nil t nil \"--brief\" \"--mime-type\" file)))\n      ;; Remove the final newline if any\n      (when (eq (char-before) ?\\n)\n        (delete-char -1))\n      (if (zerop exit)\n        (error \"file: %s: %s\" file (buffer-string))))))\n\n(defun chunyang-open-file-with-app (file app)\n  \"Open FILE with APP.\"\n  ;; open(1) exists immediately and does not block Emacs\n  (call-process \"open\" nil nil nil \"-a\" app file))\n\n(defvar chunyang-mime-type-app-alist\n  '((\"video/mp4\" . \"VLC\")\n    (\"application/pdf\" . \"Firefox\")))\n\n(defun chunyang-open-file (file)\n  \"Open FILE base on its mime-type.\"\n  (interactive \"f\")\n  (setq file (expand-file-name file))\n  (let ((mime-type (chunyang-file-mime-type file)))\n    (if (string-prefix-p \"text/\" mime-type)\n        (find-file file)\n      (let ((app (cdr (assoc mime-type chunyang-mime-type-app-alist))))\n        (if app\n            (chunyang-open-file-with-app file app)\n          (user-error \"No app is associated with %s\" mime-type))))))\n\n(defun chunyang-dired-open-file ()\n  (chunyang-open-file (dired-get-file-for-visit)))\n\nYour Answer"}
{"text": "Retrieved from https://galwaymathsgrinds.wordpress.com/maths-topics/binomial-theorem/\nText:\nBinomial Theorem\n\nFormulae and Tables page 20\n\nI think that on first seeing the Binomial theorem many students think it very complicated and straight away tell themselves that this is too difficult to deal with. But like many other things in maths if we just identify a few patterns in how things are ordered it suddenly appears much simpler.\n\nIt is binomial because we are working with the sum or difference of two algebraic terms, (x+y). It tells us the result of raising this to any whole number power. Lets take a few examples that we know already or can easily work out by multiplying out the (x+y) the required number of times. Remember from the rules of indices that anything to the power of zero is 1.\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)0 = 1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1 term\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)1 = x+y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2 terms\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)2 = x2 +2xy + y2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0 3 terms\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)3 = x3 + 3x2y + 3xy2 + y3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\u00a0 4 terms\n\nIf we raise it to the power of n, then the number of terms in the expansion will be n + 1, and these are all added together.\n\nLook at the powers of x. They start at the same power as the binomial is being raised to and then decrease by 1 in each succeeding term until we reach x0. Remember x0 is 1. And since multiplying by 1 makes no difference we do not need to write it in.\n\nThe powers of y follow the reverse pattern starting at y0 in the first term. Again since this is 1 and it is multiplied by xn it is just ignored. They increase by 1 in each succeeding term until we reach yn.\n\nWe then have to find the coefficients of the different terms. These are given by calculating nCr where n is the power we are raising the binomial to, and r starts at 0 for the first term and increments by 1 in each succeeding term until it reaches n.\n\nThe booklet gives the definition of nCr in terms of factorials but it is much simpler to just use the nCr button on your calculator.\n\nIn general then a binomial expansion raised to the power of n will consist of the sum of n+1 terms of the form nCr . xn-r .yr where r starts at zero and increases by 1 in succeeding terms.\n\nThis results in\n\nGeneral term of binomial expansion\n\n= Tr+1 = nCr . xn-r .yr\n\nFind the term independent of x in (x2 \u2013 1/x)15\n\nThe term independent of x is the term with no x, in other words the index (power) on x is zero.\n\nTr+1 = 15Cr . (x2)15-r .(-1/x)r\n\n= 15Cr . (x)30-2r .(-1/x)r\n\n= 15Cr . x30-2r .(-x)-r\n\n= 15Cr . -x30-3r\n\n30-3r = 0 for independent term. r = 10\n\nTr+1 = 15Cr . (x2)15-r .(-1/x)r = 3003 . x10 . 1/(-x10) = 3003"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/116566/is-there-a-olog-n-time-algorithm-to-find-the-maximum-element-of-a-circular-shi\nText:\nConsider this problem: You are given an array $A$ (of distinct integers) of one out of the following four types:\n\n  \u2022 Ascending (e.g., 1,2,4,6);\n  \u2022 Descending (e.g., 6,4,2,1);\n  \u2022 Ascending rotated (a non-trivial circular shift of an ascending array, e.g., 4,6,1,2);\n  \u2022 Descending rotated (a non-trivial circular shift of an descending array, e.g., 4,2,1,6).\n\nThe task is to determine the type and the maximum element of $A$.\n\nSince $A$ is \"sorted\", is there a $O(\\log n)$-time approach or is the best possible time complexity $O(n)$, as suggested in the link?\n\n  \u2022 3\n    $\\begingroup$ Please include the question as part of your post. The link could rot in the future. $\\endgroup$ Nov 1 '19 at 16:45\n  \u2022 $\\begingroup$ The question has been put on hold seconds before I could post my answer. Am I allowed to edit the question even if I'm not the original poster? $\\endgroup$\n    \u2013\u00a0Steven\n    Nov 1 '19 at 18:31\n  \u2022 $\\begingroup$ @Steven yes, and edit was very good. $\\endgroup$\n    \u2013\u00a0Evil\n    Nov 2 '19 at 4:20\n  \u2022 1\n    $\\begingroup$ Let N>= 3 be the array size, n = N/3, m=2N/3, x=position of last element. Read a, b, c from index 0, n and m. a, b, c can be sorted in six different ways, and each corresponds to one of the six cases array sorted in ascending/descending order, and x<n, n<=x<m, and x>= m. The rest is binary search in a sub array of size N/3, so O(log N). $\\endgroup$\n    \u2013\u00a0gnasher729\n    Nov 2 '19 at 10:36\n  \u2022 $\\begingroup$ What did you try? Where did you get stuck? Can you recognize any of the four cases? We're happy to help you understand the concepts but just solving exercises for you is unlikely to achieve that. You might find this page helpful in improving your question. $\\endgroup$\n    \u2013\u00a0D.W.\n    Nov 3 '19 at 7:31\n\nLet $A = \\langle a_1, \\dots, a_n \\rangle$ be the input array. I will only consider the case $n \\ge 3$, otherwise the problem is trivial.\n\nThe key property is that the order relation between all but one pair of consecutive elements modulo $n$ in $A$ will be \"greater than\" if $A$ is some circular shift of an increasing array (possibly the trivial shift by $0$), and \"less than\" if $A$ is some circular shift of a decreasing array. Examining the first and last elements suffices to determine if the shift is trivial or not.\n\nIn practice you can determine the type of $A$ in constant time, as follows:\n\n  \u2022 Look the majority value $x$ among $\\textrm{sign}(a_1-a_n)$, $\\textrm{sign}(a_2-a_1)$, and $\\textrm{sign}(a_3-a_2)$.\n\n  \u2022 If $x = +1$ then $A$ is some circular shift of an increasing array. If $\\textrm{sign}(a_1-a_n)=-1$, $A$ is of type \"ascending\", otherwise it is of type \"ascending rotated\".\n\n  \u2022 If $x = -1$ then $A$ is some circular shift of a decreasing array. If $\\textrm{sign}(a_1-a_n)=1$, $A$ is of type \"descending\", otherwise it is of type \"descending rotated\".\n\nAs for returning the maximum, I will only discuss the case in which $A$ is a circular shift of an increasing array (the complementary case is handled similarly). Notice that, if the maximum element is in some position $a_j$, then all $a_1, \\dots, a_j$ are larger than or equal to $a_1$, while all ements $a_{j+1}, \\dots, a_n$ are smaller than $a_1$. This allows you to binary search for the last element that is larger than or equal to $a_1$, i.e., $a_j$.\n\n  \u2022 1\n    $\\begingroup$ No doubt this is a great answer as per me. But, I think we should consider $x$ as majority of $sign(a_1-a_n), sign(a_2-a_1)$ and $sign(a_3 - a_2)$. Because I'm getting wrong answer if I follow above approach with sequence $6,3,4,5$. $\\endgroup$ Nov 2 '19 at 11:07\n  \u2022 $\\begingroup$ Ughh. You are right! Thanks for spotting that. $\\endgroup$\n    \u2013\u00a0Steven\n    Nov 2 '19 at 11:13\n\nif we are given with first two cases i.e Ascending sorted array and descending sorted arrays we can simply find the difference b/w last element of array and first element of array i.e (last element of array - first element of arrays)if difference is positive then it is ascending order and maximum element is the element at last index of array (in ascending sorted arrays ) and vice versa. it takes just 0(1) in that case.\n\n  \u2022 1\n    $\\begingroup$ We don\u2019t know which of the four cases it is, finding which case is part of the problem. $\\endgroup$\n    \u2013\u00a0gnasher729\n    Nov 3 '19 at 13:35\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/499031/minimum-number-of-weighings-necessary\nText:\n8 boxes each having different weights are numbered from 1 to 8 (the lightest 1, the heaviest 8). The total weight of 4 boxes are equal to the other 4\u2019s total, and your task is to identify these two groups. You have a balance scale with two pans on which you can compare the weight of two groups each having exactly 4 boxes. What is the minimum number of weighings necessary to guarantee to accomplish this task?\n\n  \u2022 $\\begingroup$ As there are $\\frac 12 {8 \\choose 4}=35 \\gt 2^5$ (barely) ways to split the eight boxes into fours, one would guess $6$. $\\endgroup$ Sep 19 '13 at 22:05\n  \u2022 $\\begingroup$ Thank you very much. I was trying to solve it by choosing the most useful 4's every time. But it's hard to be sure that way=) thanks again. $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 19 '13 at 22:15\n  \u2022 $\\begingroup$ I didn't post that as an answer, as I am not convinced. But it gives an idea where to look. In puzzles like this, there may be a trick that gets you down to $5$. $\\endgroup$ Sep 19 '13 at 22:20\n  \u2022 $\\begingroup$ But you're saying it shouldn't be more than 6 right? Because I could guarantee it with 7 weighings, which should be wrong if that's what you mean. $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 19 '13 at 22:32\n  \u2022 1\n    $\\begingroup$ Some of the valid combinations are 1238, 1248,1258,1268, 1278. If you weigh 1258 first you can eliminate two of the others by noting which way the balance tilts. I believe this is the kind of thinking needed. $\\endgroup$ Sep 20 '13 at 18:46\n\nKnowing that the weights increase monotonically from box $1$ to box $8$ allows several options to be discarded out of hand. In particular, if the groups are $A=\\{a_1,a_2,a_3,a_4\\}$ and $B=\\{b_1,b_2,b_3,b_4\\}$, with $a_1<a_2<a_3<a_4$ and $b_1<b_2<b_3<b_4$ and $a_1<b_1$, then we already know the $A$'s are lighter if $a_i<b_i$ for each $i$. These ignorable configurations correspond to walks by $\\pm 1$ from $0$ to $0$ that are always non-negative: $$ 010101010 \\\\ 010101210 \\\\ 010121010 \\\\ 012101010 \\\\ 012121010 \\\\ 012101210 \\\\ 010121210 \\\\ 012321010 \\\\ 012121210 \\\\ 010123210 \\\\ 012123210 \\\\ 012321210 \\\\ 012323210 \\\\ 012343210 $$ (fourteen, or the Catalan number $C_4$) where the $A$'s are definitely lighter. (The last in this list corresponds to $A=\\{1,2,3,4\\}$ and $B=\\{5,6,7,8\\}$, for instance.) This leaves only $\\frac{1}{2}{{8}\\choose{4}}-14=21$ partitions to choose from. So it's quite possible that $5$ weightings are enough.\n\nIndeed, even $4$ may be enough, since a weighing may be balanced (that is, there are three possible outcomes, one of which consists of only one possibility). So ideally the first weighing would either balance or reduce us to $10$ possibilities; the second would either balance or reduce us to $5$ possibilities; the third would either balance or reduce us to $2$ possibilities; and the fourth would determine the answer.\n\n\nI would start with $1278$. If heavy, it allows you to knot that $7$ and $8$ are in different groups, if light, you know $1$ and $2$ are in different groups. Let us assume it is heavy, otherwise subtract all numbers below from $9$.\n\nThe remaining combinations that are possible are $$\\begin {array} \\\\1268&1368&1468&1568\\\\ 1258&1358&1458\\\\1248&1348\\\\1238\\\\ \\\\2368\\\\2358&2458\\\\2348\\\\ \\\\3458\\end{array}$$ where combinations above, north or east are known to be heavier. The line breaks represent layers in a 3D matrix. If we try $1358$ next, then either $1468$ or $2358$, we might need as many as four more. This gives $7$ weighings. I haven't proven that you can't do it in $6$.\n\n  \u2022 $\\begingroup$ There is something I dont understand. There are 6 combinations(considering 21 valid) which has 7 and 8 on the same side. There should be 15 left. How did you narrow it down to ten? What happened to 2368, 3458, 2458, 2358 and 2348 ? $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 21 '13 at 22:23\n  \u2022 $\\begingroup$ @Taner: oversight. Updated and it cost me one. Now I think one can do better. $\\endgroup$ Sep 21 '13 at 23:01\n  \u2022 $\\begingroup$ Maybe I'm asking too many questions, but I also couldnt entirely understand why did we assume 1278 would be heavier and not lighter? How does 1278 being lighter be an easier way to find the equality? $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 22 '13 at 2:46\n  \u2022 $\\begingroup$ @Taner: there is a symmetry in the problem that is broken when we get that result. Any strategy that applies if 1278 is heavy is mirrored by one where 1278 is light, with all the numbers subtracted from 9. So instead of trying 1358 next, we would try 1468, then 1358 or 1467. $\\endgroup$ Sep 22 '13 at 5:16\n\nYour Answer"}
{"text": "Retrieved from https://ww2.mathworks.cn/help/stats/improve-an-engine-cooling-fan-using-design-for-six-sigma-techniques.html\nText:\nMain Content\n\nImprove an Engine Cooling Fan Using Design for Six Sigma Techniques\n\nThis example shows how to improve the performance of an engine cooling fan through a Design for Six Sigma approach using Define, Measure, Analyze, Improve, and Control (DMAIC). The initial fan does not circulate enough air through the radiator to keep the engine cool during difficult conditions. First the example shows how to design an experiment to investigate the effect of three performance factors: fan distance from the radiator, blade-tip clearance, and blade pitch angle. It then shows how to estimate optimum values for each factor, resulting in a design that produces airflows beyond the goal of 875 ft3 per minute using test data. Finally it shows how to use simulations to verify that the new design produces airflow according to the specifications in more than 99.999% of the fans manufactured. This example uses MATLAB\u00ae, Statistics and Machine Learning Toolbox\u2122, and Optimization Toolbox\u2122.\n\nDefine the Problem\n\nThis example addresses an engine cooling fan design that is unable to pull enough air through the radiator to keep the engine cool during difficult conditions, such as stop-and-go traffic or hot weather). Suppose you estimate that you need airflow of at least 875 ft3/min to keep the engine cool during difficult conditions. You need to evaluate the current design and develop an alternative design that can achieve the target airflow.\n\nAssess Cooling Fan Performance\n\nLoad the sample data.\n\n\nThe data consists of 10,000 measurements (historical production data) of the existing cooling fan performance.\n\nPlot the data to analyze the current fan's performance.\n\nylabel('Max Airflow (ft^3/min)')\ntitle('Historical Production Data')\n\nThe data is centered around 842 ft3/min and most values fall within the range of about 8 ft3/min. The plot does not tell much about the underlying distribution of data, however. Plot the histogram and fit a normal distribution to the data.\n\nhistfit(originalfan) % Plot histogram with normal distribution fit\nformat shortg\nxlabel('Airflow (ft^3/min)')\nylabel('Frequency (counts)')\ntitle('Airflow Histogram')\n\npd = fitdist(originalfan,'normal') % Fit normal distribution to data\npd = \n\n\n  Normal distribution\n       mu = 841.652   [841.616, 841.689]\n    sigma =  1.8768   [1.85114, 1.90318]\n\nfitdist\u00a0fits a normal distribution to data and estimates the parameters from data. The estimate for the mean airflow speed is 841.652 ft3/min, and the 95% confidence interval for the mean airflow speed is (841.616, 841.689). This estimate makes it clear that the current fan is not close to the required 875 ft3/min. There is need to improve the fan design to achieve the target airflow.\n\nDetermine Factors That Affect Fan Performance\n\nEvaluate the factors that affect cooling fan performance using design of experiments (DOE). The response is the cooling fan airflow rate (ft3/min). Suppose that the factors that you can modify and control are:\n\n  \u2022 Distance from radiator\n\n  \u2022 Pitch angle\n\n  \u2022 Blade tip clearance\n\nIn general, fluid systems have nonlinear behavior. Therefore, use a response surface design to estimate any nonlinear interactions among the factors. Generate the experimental runs for a Box-Behnken design in coded (normalized) variables [-1, 0, +1].\n\nCodedValue = bbdesign(3)\nCodedValue =\n\n    -1    -1     0\n    -1     1     0\n     1    -1     0\n     1     1     0\n    -1     0    -1\n    -1     0     1\n     1     0    -1\n     1     0     1\n     0    -1    -1\n     0    -1     1\n     0     1    -1\n     0     1     1\n     0     0     0\n     0     0     0\n     0     0     0\n\nThe first column is for the distance from radiator, the second column is for the pitch angle, and the third column is for the blade tip clearance. Suppose you want to test the effects of the variables at the following minimum and maximum values.\n\nDistance from radiator: 1 to 1.5 inches\nPitch angle: 15 to 35 degrees\nBlade tip clearance: 1 to 2 inches\n\nRandomize the order of the runs, convert the coded design values to real-world units, and perform the experiment in the order specified.\n\nrunorder = randperm(15);     % Random permutation of the runs\nbounds = [1 1.5;15 35;1 2];  % Min and max values for each factor\n\nRealValue = zeros(size(CodedValue));\nfor i = 1:size(CodedValue,2) % Convert coded values to real-world units\n    zmax = max(CodedValue(:,i));\n    zmin = min(CodedValue(:,i));\n    RealValue(:,i) = interp1([zmin zmax],bounds(i,:),CodedValue(:,i));\n\nSuppose that at the end of the experiments, you collect the following response values in the variable TestResult.\n\nTestResult = [837 864 829 856 880 879 872 874 834 833 860 859 874 876 875]';\n\nDisplay the design values and the response.\n\ndisp({'Run Number','Distance','Pitch','Clearance','Airflow'})\ndisp(sortrows([runorder' RealValue TestResult]))\n'Run Number'    'Distance'    'Pitch'    'Clearance'    'Airflow'\n\n            1          1.5           35          1.5          856\n            2         1.25           25          1.5          876\n            3          1.5           25            1          872\n            4         1.25           25          1.5          875\n            5            1           35          1.5          864\n            6         1.25           25          1.5          874\n            7         1.25           15            2          833\n            8          1.5           15          1.5          829\n            9         1.25           15            1          834\n           10            1           15          1.5          837\n           11          1.5           25            2          874\n           12            1           25            1          880\n           13         1.25           35            1          860\n           14            1           25            2          879\n           15         1.25           35            2          859\n\nSave the design values and the response in a table.\n\nExpmt = table(runorder', CodedValue(:,1), CodedValue(:,2), CodedValue(:,3), ...\n\nD stands for Distance, P stands for Pitch, and C stands for Clearance. Based on the experimental test results, the airflow rate is sensitive to the changing factors values. Also, four experimental runs meet or exceed the target airflow rate of 875 ft3/min (runs 2, 4,12, and 14). However, it is not clear which, if any, of these runs is the optimal one. In addition, it is not obvious how robust the design is to variation in the factors. Create a model based on the current experimental data and use the model to estimate the optimal factor settings.\n\nImprove the Cooling Fan Performance\n\nThe Box-Behnken design enables you to test for nonlinear (quadratic) effects. The form of the quadratic model is:\n\nAF\u00a0=\u00a0\u03b20+\u03b21*Distance+\u03b22*Pitch+\u03b23*Clearance+\u03b24*Distance*Pitch+\u03b25*Distance*Clearance+\u03b26*Pitch*Clearance+\u03b27*Distance2+\u03b28*Pitch2+\u03b29*Clearance2,\n\nwhere AF is the airflow rate and Bi is the coefficient for the term i. Estimate the coefficients of this model using the fitlm function from Statistics and Machine Learning Toolbox.\n\nmdl = fitlm(Expmt,'Airflow~D*P*C-D:P:C+D^2+P^2+C^2');\n\nDisplay the magnitudes of the coefficients (for normalized values) in a bar chart.\n\nh = bar(mdl.Coefficients.Estimate(2:10));\nset(h,'facecolor',[0.8 0.8 0.9])\nset(gcf,'units','normalized','position',[0.05 0.4 0.35 0.4])\nylabel('Airflow (ft^3/min)')\nxlabel('Normalized Coefficient')\ntitle('Quadratic Model Coefficients')\n\nThe bar chart shows that Pitch and Pitch2 are dominant factors. You can look at the relationship between multiple input variables and one output variable by generating a response surface plot. Use plotSlice to generate response surface plots for the model mdl interactively.\n\n\nThe plot shows the nonlinear relationship of airflow with pitch. Move the blue dashed lines around and see the effect the different factors have on airflow. Although you can use\u00a0plotSlice\u00a0to determine the optimum factor settings, you can also use Optimization Toolbox to automate the task.\n\nFind the optimal factor settings using the constrained optimization function fmincon.\n\nWrite the objective function.\n\nf = @(x) -x2fx(x,'quadratic')*mdl.Coefficients.Estimate;\n\nThe objective function is a quadratic response surface fit to the data. Minimizing the negative airflow using\u00a0fmincon\u00a0is the same as maximizing the original objective function. The constraints are the upper and lower limits tested (in coded values). Set the initial starting point to be the center of the design of the experimental test matrix.\n\nlb = [-1 -1 -1]; % Lower bound\t\t\t\t\t\nub = [1 1 1];    % Upper bound                       \nx0 = [0 0 0];    % Starting point\n[optfactors,fval] = fmincon(f,x0,[],[],[],[],lb,ub,[]); % Invoke the solver\nLocal minimum found that satisfies the constraints.\n\nOptimization completed because the objective function is non-decreasing in \nfeasible directions, to within the default value of the function tolerance,\nand constraints are satisfied to within the default value of the constraint tolerance.\n\nConvert the results to a maximization problem and real-world units.\n\nmaxval = -fval;\nmaxloc = (optfactors + 1)';\nbounds = [1 1.5;15 35;1 2];\nmaxloc=bounds(:,1)+maxloc .* ((bounds(:,2) - bounds(:,1))/2);\ndisp('Optimal Values:')\ndisp([maxloc' maxval])\nOptimal Values:\n    'Distance'    'Pitch'    'Clearance'    'Airflow'\n\n            1       27.275            1       882.26\n\nThe optimization result suggests placing the new fan one inch from the radiator, with a one-inch clearance between the tips of the fan blades and the shroud.\n\nBecause pitch angle has such a significant effect on airflow, perform additional analysis to verify that a 27.3 degree pitch angle is optimal.\n\ntbl = table(pitch,airflow);\nmdl2 = fitlm(tbl,'airflow~pitch^2');\nans =\n\n\nThe results show that a quadratic model explains the effect of pitch on the airflow well.\n\nPlot the pitch angle against airflow and impose the fitted model.\n\nhold on\nylim([840 885])\ntitle('Fitted Model and Data')\nxlabel('Pitch angle (degrees)') \nlegend('Test data','Quadratic model','Location','se')\nhold off\n\nFind the pitch value that corresponds to the maximum airflow.\n\nans =\n\n\nThe additional analysis confirms that a 27.3 degree pitch angle is optimal.\n\nThe improved cooling fan design meets the airflow requirements. You also have a model that approximates the fan performance well based on the factors you can modify in the design. Ensure that the fan performance is robust to variability in manufacturing and installation by performing a sensitivity analysis.\n\nSensitivity Analysis\n\nSuppose that, based on historical experience, the manufacturing uncertainty is as follows.\n\nFactorReal ValuesCoded Values\nDistance from radiator1.00 +/- 0.05 inch1.00 +/- 0.20 inch\nBlade pitch angle27.3 +/- 0.25 degrees0.227 +/- 0.028 degrees\nBlade tip clearance1.00 +/- 0.125 inch-1.00 +/- 0.25 inch\n\nVerify that these variations in factors will enable to maintain a robust design around the target airflow. The philosophy of Six Sigma targets a defect rate of no more than 3.4 per 1,000,000 fans. That is, the fans must hit the 875 ft3/min target 99.999% of the time.\n\nYou can verify the design using Monte Carlo simulation. Generate 10,000 random numbers for three factors with the specified tolerance. First, set the state of the random number generators so results are consistent across different runs.\n\n\nPerform the Monte Carlo simulation. Include a noise variable that is proportional to the noise in the fitted model, mdl (that is, the RMS error of the model). Because the model coefficients are in coded variables, you must generate dist, pitch, and clearance using the coded definition.\n\ndist = random('normal',optfactors(1),0.20,[10000 1]);\npitch = random('normal',optfactors(2),0.028,[10000 1]);\nclearance = random('normal',optfactors(3),0.25,[10000 1]);\nnoise = random('normal',0,mdl2.RMSE,[10000 1]);\n\nCalculate airflow for 10,000 random factor combinations using the model.\n\nsimfactor = [dist pitch clearance];\nX = x2fx(simfactor,'quadratic');\n\nAdd noise to the model (the variation in the data that the model did not account for).\n\nsimflow = X*mdl.Coefficients.Estimate+noise;\n\nEvaluate the variation in the model's predicted airflow using a histogram. To estimate the mean and standard deviation, fit a normal distribution to data.\n\npd = fitdist(simflow,'normal');\nhold on\ntext(,300,['Mean: ' num2str(round(])\ntext(,280,['Standard deviation: ' num2str(round(pd.sigma))])\nhold off\ntitle('Monte Carlo Simulation Results')\n\nThe results look promising. The average airflow is 882 ft3/min and appears to be better than 875 ft3/min for most of the data.\n\nDetermine the probability that the airflow is at 875 ft3/min or below.\n\nformat long\npfail = cdf(pd,875)\npass = (1-pfail)*100\npfail =\n\n\npass =\n\n\nThe design appears to achieve at least 875 ft3/min of airflow 99.999% of the time.\n\nUse the simulation results to estimate the process capability.\n\nS = capability(simflow,[875.0 890])\npass = (1-S.Pl)*100\nS = \n\n       mu: 8.822982645666709e+02\n    sigma: 1.424806876923940\n        P: 0.999999816749816\n       Pl: 1.509289008603141e-07\n       Pu: 3.232128339675335e-08\n       Cp: 1.754623760237126\n      Cpl: 1.707427788957002\n      Cpu: 1.801819731517250\n      Cpk: 1.707427788957002\n\npass =\n\n\nThe Cp value is 1.75. A process is considered high quality when Cp is greater than or equal to 1.6. The Cpk is similar to the Cp value, which indicates that the process is centered. Now implement this design. Monitor it to verify the design process and to ensure that the cooling fan delivers high-quality performance.\n\nControl Manufacturing of the Improved Cooling Fan\n\nYou can monitor and evaluate the manufacturing and installation process of the new fan using control charts. Evaluate the first 30 days of production of the new cooling fan. Initially, five cooling fans per day were produced. First, load the sample data from the new process.\n\n\nPlot the X-bar and S charts.\n\ncontrolchart(spcflow,'chart',{'xbar','s'}) % Reshape the data into daily sets\n\nAccording to the results, the manufacturing process is in statistical control, as indicated by the absence of violations of control limits or nonrandom patterns in the data over time. You can also run a capability analysis on the data to evaluate the process.\n\n[row,col] = size(spcflow);\nS2 = capability(reshape(spcflow,row*col,1),[875.0 890])\npass = (1-S.Pl)*100\nS2 = \n\n       mu: 8.821061141685465e+02\n    sigma: 1.423887508874697\n        P: 0.999999684316149\n       Pl: 3.008932155898586e-07\n       Pu: 1.479063578225176e-08\n       Cp: 1.755756676295137\n      Cpl: 1.663547652525458\n      Cpu: 1.847965700064817\n      Cpk: 1.663547652525458\n\npass =\n\n\nThe Cp value of 1.755 is very similar to the estimated value of 1.73. The Cpk value of 1.66 is smaller than the Cp value. However, only a Cpk value less than 1.33, which indicates that the process shifted significantly toward one of the process limits, is a concern. The process is well within the limits and it achieves the target airflow (875 ft3/min) more than 99.999% of the time."}
{"text": "Retrieved from https://web2.0calc.com/questions/math-question_88\nText:\nwhat is 6^2/2(3)+4\n\nGuest\u00a0Aug 3, 2017\n\n4+0 Answers\n\n\nwhat is 6^2/2(3)+4\n\n\nPower calculation before point calculation before line calculation,\nthen from left to right.\n\n\n\\(\\frac{6^2}{2\\times 3}+4=\\frac{36}{6}+4=6+4\\color{blue}=10\\)\n\n\nWhoever wants can also shorten de Bruch by 6. \u00a0\u00a0 (\\(\\frac{36}{6}=\\frac{6}{1}\\) )\n\n\nlaugh\u00a0 !\n\nasinus \u00a0Aug 3, 2017\n\nThis is a rare example in mathematics where, I believe,\u00a0parentheses is necessary in order to evaluate the expression without ambiguity. I will demonstrate why.\n\n\nStrictly speaking, asinus's interpretation is incorrect. If you were to evaluate this with a calculator inputted like as is, the calculator would evaluate it as\u00a0\\(\\frac{6^2}{2}*3+4\\). This is because the 2(3) is really multiplication, so division takes precedence since it is\u00a0comes first in the expression. First it does 6^2, then it divides 6^2 by 2 because division is first from left to right, and then it multiplies that quantity by 3. Here is another example with a variable\u00a0\n\n\n\n\nUsing the same logic as above, this equation, in fraction form is strictly\u00a0\\(\\frac{8}{2}y\\)--not\u00a0\\(\\frac{8}{2y}\\). Some would argue, however, that 2y is a term, so it shouldn't be separated.\u00a0\u00a0\n\n\nHow do we eliminate this ambiguity if there is no fraction button to speak of? Use parentheses!\u00a0\n\n\nAsinus's interpretation of \\(\\frac{6^2}{2*3}+4\\)\u00a0will be unambiguous once you add 1 set of parentheses with\u00a0\\(6^2/(2(3))+4\\). Now, the only correct interpretation is\u00a0\\(\\frac{6^2}{2*3}+4\\)\u00a0because the parentheses indicate that we are dividing by the quantity of the product of 2 and 3.\n\n\nThe strict interpretation is\u00a0\\(\\frac{6^2}{2}*3+4\\)\u00a0should be written like\u00a0\\((6^2/2)(3)+4\\). In this case, the quantity of six squared divided by two is all multiplied by three. No more ambiguity.\n\n\nOkay, after all of this ranting, now I will evaluate what I believe to be, under the current rules of the order of operations, the way to evaluate the expression 6^2/2(3)+4 as\u00a0\\(\\frac{6^2}{2}*3+4\\):\n\n\n\\(\\frac{6^2}{2}*3+4\\) Evaluate the numerator.\u00a0\\(6^2=36\\)\n\\(\\frac{36}{2}*3+4\\) Simplify the fraction\u00a0by recognizing that the 36 is divisible by 2 because 36 is even.\n\\(18*3+4\\) Do multiplication before addition.\n\n\n\n\n\nTheXSquaredFactor \u00a0Aug 3, 2017\n\nHello\u00a0 \\(X^2\\)\n\nNeither of us is wrong.\nRight, who puts brackets to represent the meaning of his term.\ngreetings :)\n\nasinus \u00a0Aug 4, 2017\n\nGreetings to you, too :)\n\nTheXSquaredFactor \u00a0Aug 5, 2017\n\n23 Online Users"}
{"text": "Retrieved from https://www.physicsforums.com/threads/minimize-a-certain-function-involving-sine-and-cosine.662968/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMinimize a certain function involving sine and cosine\n\n  1. Jan 7, 2013 #1\n    It isn't a homework problem per se, but a curiosity a stumbled upon when trying to solve a physics problem (I was trying to calculate the angle I would need to do less work possible, while moving the box). The equation I found is:\n    [itex]f(\\theta)=\\cos(\\theta)+ 0.4sen(\\theta)[/itex]\n\n    2. Relevant equations\n\n    Just the one stated above, and trig identities, probably.\n\n    3. The attempt at a solution\n\n    I tried a few things (including deriving and finding the roots of the function without success, since I couldn't found the roots), I also tried to rewrite (Using cos\u00b2 + sin\u00b2 = 1) and got:\n    [itex]f(\\theta)=\\sqrt{1-\\sin^2(\\theta)}+ 0.4sin(\\theta)[/itex]\n    But I also don't know how to find the minimum in this equation.\n\n    How could I go about solving that?\n\n    Thanks in advance!\n    Last edited: Jan 7, 2013\n  2. jcsd\n  3. Jan 7, 2013 #2\n    What problems did you run into? Did you do anything with tangent?\n  4. Jan 7, 2013 #3\n\n\n    User Avatar\n    Science Advisor\n\n    Interesting that you use both \"sen\" and \"sin\"! Can't decide between French and English?\n\n    You have [itex]f(\\theta)= cos(\\theta)+ 0.4sin(\\theta)[/itex] (only English for me, I'm afraid.). I don't see any reason to introduce a square root just to have only sine. Taking the derivative, [itex]f'(\\theta)= -sin(\\theta)+ 0.4cos(\\theta)= 0[/itex] at a max or min. That is the same as [itex]sin(\\theta)= 0.4 cos(\\theta)[/itex] or, since sine and cosine are not 0 for the same [itex]\\theta[/itex], we must have [itex]sin(\\theta)/cos(\\theta)= tan(\\theta)= 0.4[/itex]. You can use a calculator to solve that.\n    Last edited by a moderator: Jan 7, 2013\n  5. Jan 7, 2013 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Reposting HallsofIvy's post to fix up the LaTex:\n  6. Jan 7, 2013 #5\n    Oh god, I can't believe I ignored sin(x)/cos(x) = tan(x). I'm terribly sorry, thanks a lot! That solves my problem.\n\n    About the whole sen and sin thing, it's because I'm actually Brazilian, and here we write \"Sen\", so I sometimes get both of them confused :P\n  7. Jan 7, 2013 #6\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You also need to worry about whether the point you find is a maximizer or a minimizer of f.\n  8. Jan 7, 2013 #7\n    Yes indeed, but that was easily done by deriving again and finding if the result in this particular point would be positive or negative, since I found a negative value I concluded that it was a maximum, the value I wanted(In OP I miswrote, I actually wanted a maximum initially).\n\n    [itex]tan(\\theta)= 0.4;\\theta = 21.8^o\\\\f''(21.8^o)= -1.077[/itex]\n\n    However, since you mentioned that, I just realized that I have no idea on how to find the minimum. Shouldn't [itex]tan(\\theta) = 0.4[\\itex] yield two values, one of which is a maximum and another which is a minimum?\n  9. Jan 7, 2013 #8\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n  10. Jan 7, 2013 #9\n    Hmm. I found by trial and error that the angles should be: 21.8\u00b0 and 201.8\u00b0, but how am I supposed to get the 201.8\u00b0? My calculator only gave me 21.8\u00b0.\n  11. Jan 7, 2013 #10\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    tan(x)=tan(x+180). The values of tan repeat every 180 degrees (pi in radians). It's periodic with period pi.\n  12. Jan 7, 2013 #11\n    Ohhh, I see, thanks!\n    I really need to get better in trigonometry. I have several wrong concepts :S\n  13. Jan 7, 2013 #12\n\n\n    User Avatar\n    Homework Helper\n\n    This is usually done with the identity\n\n    [tex]\\cos (x)+\\frac{2}{5} \\sin (x)=\\sqrt {1+\\left( \\frac{2}{5} \\right) ^2 } \\sin \\left( x+\\arctan \\left( \\frac{5}{2} \\right) \\right)[/tex]\n\n    Which is quite easy to optimize.\n\nSimilar Discussions: Minimize a certain function involving sine and cosine"}
{"text": "Retrieved from https://www.physicsforums.com/threads/questions-on-weinberg-cosmology-book.697215/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestions on Weinberg Cosmology Book\n\n  1. Jun 15, 2013 #1\n    I am following up Weinberg Cosmology book, but I have one question.\n\n    In chapter 3.1, we have Eq (3.1.3) and (3.1.4)\n\n    [itex] s(T) = \\frac{\\rho(T) + p(T)}{T} [/itex]\n    [itex] T\\frac{dp(T)}{dT} = \\rho(T) + p(T) [/itex]\n\n    In Eq (3.1.5), we have the Fermi-Dirac or Bose-Einstein distributions.\n\n    [itex] n(p, T) = \\frac{4 \\pi g p^2}{(2 \\pi \\hbar)^3} \\frac{1}{exp(\\sqrt{p^2 + m^2} / k_B T) \\pm 1} [/itex].\n\n    From using this number distribution, the author said we have the energy density and pressure of a particle mass m are given by Eq (3.1.6) and (3.1.7).\n\n    [itex] \\rho(T) = \\int n(p, T) dp \\sqrt{p^2 + m^2} [/itex]\n    [itex] p(T) = \\int n(p, T) dp \\frac{p^2}{3\\sqrt{p^2 + m^2}} [/itex]\n\n    Here, energy density is straightforward by the definition of number density.\n    But, for pressure, the author said it can be derived from Eq(3.1.4), the second equation on this post.\n\n    However, I cannot derive this pressure equation using Eq(3.1.4). Can somebody help me do this?\n\n    Thank you.\n  2. jcsd\n  3. Jun 22, 2013 #2\n\n\n    User Avatar\n    Science Advisor\n\n    My Weinberg seems a lot different from your Weinberg! But tracing through it, here's where the p(T) equation comes from. For a particle (using c = 1), the energy is E = \u03b3m and the momentum is p = \u03b3mv. Thus p/E = v (Eq.1)\n\n    For a system of particles, the energy-momentum tensor is T\u03bc\u03bd = \u2211n pn\u03bc dxn\u03bd/dt \u03b43(x-xn), or using Eq.1, T\u03bc\u03bd = \u2211n pn\u03bc pn\u03bd/En \u03b43(x-xn\n\n    For a perfect fluid, the spatial components of T\u03bc\u03bd are related to the pressure p by Tij = p \u03b4ij.\n\n    Thus p = (1/3) \u01a9j Tjj = (1/3) \u01a9n pn2/En \u03b43(x-xn).\n\n    This gets you the p2 in the numerator, the E in the denominator, and the 1/3 out front."}
{"text": "Retrieved from https://www.physicsforums.com/threads/factoring-3rd-degree-polynomial-for-eigenvalues.719119/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nFactoring 3rd degree polynomial for eigenvalues\n\n  1. Oct 27, 2013 #1\n    Was given a matrix\n    To find the eigenvalues I set up the characteristic equation\n    [-1-x | 7 | -5 ]\n    [-4 | 11-x | -6 ]\n    [-4 | 8 | -3-x]\n\n    With some dirty work I got this bad boy out, which I'm having trouble factoring\n\n    2. Relevant equations\n    Looking for method to factor it, without aid of calculator\n    Or if there's a better way to determine the equation which will give me the factors without setting up a polynomial\n\n    3. The attempt at a solution\n    I tried the grouping method but that doesn't work since all I end up with is\n  2. jcsd\n  3. Oct 27, 2013 #2\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Use the rational root theorem on the polynomial ##x^3 - 7x^2 + 15 x - 9##; that is, look for roots among the + or - integer factors of -9.\n  4. Oct 27, 2013 #3\n    Thanks I forgot about that theorem.\n    But how do I rule out the negative or positive integers?\n  5. Oct 27, 2013 #4\n\n\n    Staff: Mentor\n\n    You can rule out a potential root r by discovering that x - r is not a factor of your cubic polynomial. The rational root theorem says that the possible rational roots for your cubic are 1, -1, 3, -3, 9, and -9.\n\n    Use either long division or synthetic division to determine whether x - 1, x - (-1), x - 3, x - (-3), x - 9, or x - (-9) are factors. If one of these is a factor, the remainder will be zero. If it's not a factor, the remainder will be nonzero.\n  6. Oct 27, 2013 #5\n  7. Oct 27, 2013 #6\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    In this case you can put x = -y to find that the polynomial has the form p(x) = -q(y), where ##q(y) = y^3 + 7 y^2 + 15 y +9##. Obviously, q(y) does not have any positive roots (all its coefficients are > 0), so p(x) does not have any negative roots. This type of trick does not always work, but it happens to be OK in this example. Even if it did not work, you could just try out all the factors of -9 to see if one of them sets p(x) = 0. As soon as you find one that works you can stop checking and start again with the resulting quadratic remaining factor.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/what-is-this-constant-in-the-gravitational-acceleration-formula.542612/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nWhat is this constant in the gravitational acceleration formula?\n\n  1. Oct 21, 2011 #1\n\n    Hey all, I'm doing an assignment and I was given the formula below, but I'm unsure what one of the constants is.\n\n    2. Relevant equations\n\n    Acceleration = - \u03bcEr/r3\n\n    3. The attempt at a solution\n\n    Below the formula it says \"where \u03bcE is the gravitational constant for the Earth and r is the position vector of the vehicle\". But this is talking about a satellite orbiting Earth, so it can't be 9.8m/s/s, can it?\n\n    Am I meant to use \u03bcE = u*m1*m2/r2 to find it?\n\n    I've used the 'geocentric gravitational constant' elsewhere in the assignment, but it used a different symbol, this isn't it either is it?\n\n  2. jcsd\n  3. Oct 21, 2011 #2\n\n\n    User Avatar\n    Homework Helper\n\n  4. Oct 21, 2011 #3\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Last edited by a moderator: Apr 26, 2017\n  5. Oct 21, 2011 #4\n\n\n    User Avatar\n    Homework Helper\n\n    The correct formula you asked about is\n\n    [tex]\\vec a = -\\mu_e \\frac{\\vec r}{r^3}[/tex]\n\n    [itex]\\vec r [/itex] is the position vector of a satellite or any point-like mass with respect to the centre of Earth, and [itex]\\vec a [/itex] is its gravitational acceleration. The formula is a special case of the Universal Law of Gravity,\n\n    [tex]\\vec F = -G \\frac{m_1 m_2 \\vec r}{r^3}[/tex]\n\n    the force a point mass 1 exerts on an other point mass 2 at distance r. The force is parallel and opposite to the vector [itex]\\vec r[/itex] pointing to mass 2 from mass 1.\n    G is the gravitational constant G= 6.67259 \u02d910-11 Nm2kg-2.\n\n    If the first mass is the Earth, Gm1=GMearthe.\n\n  6. Oct 21, 2011 #5\n    Is that 'Gravitational Constant' the 'Universal Gravitational Constant (6.67*10-11' Nascent?\n  7. Oct 21, 2011 #6\n    Ignore my above post.\n\n    That makes sense ehild! Because F = ma, a = F/m. You remove the mass of the satellite from your second formula and exchange F for a. Leaving you with a = G*mE*r/r3.\n\n  8. Oct 21, 2011 #7\n\n\n    User Avatar\n    Homework Helper\n\n    All right, I see you got it."}
{"text": "Retrieved from https://brainmass.com/physics/velocity/finding-overall-speed-and-velocity-540821\nText:\nExplore BrainMass\n\nFinding Overall Speed and Velocity\n\nEach of parts (b), (c) and (d) requires you to use numerical answers found in earlier parts of the question.\n\nA dragonfly has a flight speed in still air of 4.5ms-1. It is pointed in the direction N - 29 degree - E, but flies in a wind of speed 7.5ms-1 from the direction S- 42 degree - E. Take i to be 1ms-1 due east and j to be 1ms-1 due north. Also, take\n\nvd to be the velocity of the dragonfly in still air,\nvw to be the velocity of the wind,\nv to be the resultant velocity of the dragonfly.\n\nExpress each of the vectors vd and vw in component form, giving the components correct to four decimal places.\n\nHence show that the resultant velocity v of the dragonfly is given in component form approximately by\nv = -2.8368 i + 9.5094 j\n\nBy putting v into geometric form, find the overall speed |v| of the dragonfly (in ms-1 correct to one decimal place) and its direction of travel, as a bearing (with the angle in degrees correct to one decimal place).\n\nUsing your answers to parts (b) and (c), find the time taken by the dragonfly to travel one kilometre (in seconds, correct to one decimal place), and the distance west that it travels in this time (correct to the nearest metre)\n\nSolution Preview\n\nvd = 4.5 m/s N 29 degree E == 4.5 m/s, at 29 degree towards East from North\n=> vd = 4.5(i sin(29) + j cos(29)) = 4.5*( 0.4848i+ 0.8746j)\n\n=> vd = 2.1816i + 3.9358j --Answer\n\nvw = 7.5 m/s from S 42 degree E ...\n\nSolution Summary\n\nHere we solve a problem related to motion of an object (here dragonfly) influenced by the medium (here wind velocity). We estimate wind velocity of dragonfly and displacement in a given time duration."}
{"text": "Retrieved from https://www.physicsforums.com/threads/air-resistance-and-drag-coefficien.260206/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Air Resistance and drag coefficien\n\n  1. Sep 29, 2008 #1\n\n    An object of mass 10kg is projected upwards (from ground level) with initial velocity 60m/s. It hits the ground 8.4 seconds later.\n\n    Find the drag coefficient, k.\n\n    2. Relevant equations\n\n    dv/dt + rv = -g, where r = k/m\n\n    3. The attempt at a solution\n\n    I have used the integrating factor of e^rt to give me the final equation:\n\n    v = -g/r + C/e^rt\n\n    I then plug in the initial values to get:\n\n    60 = -98/k + C\n\n    I am not sure what to do next. We are given an impact time of 8.4 seconds. Do I assume that at this instant the velocity is -60 m/s (i.e. the exact opposite of the initial)? Or can I assume that at time 4.2 seconds the velocity is equal to 0? In either case, I am not sure how to solve the equation so that I only have one variable (e.g. just k or just C).\n\n  2. jcsd\n  3. Sep 29, 2008 #2\n    I don't follow your logic, why would you do this? I would start by making a FBD of the object. Your drag force will obviously be a function of velocity but you should come up with a fairly simple integral based off of the golden kinematics equations.\n  4. Sep 29, 2008 #3\n    Solved it.\n\n    I had to use e^-rt, use the initial velocity to give me a value for C, substitute that back in and then integrate with respect to t to give me height. From there you know that at t=0 and t=8.4, the height is 0. You can then calculate r and because you know the mass, k.\n\n    Use that r value for the velocity and you can then solve the velocity at t=8.4. The maximum height will be when the velocity equation is equal to 0.\n\n\n    Took me 2 hours, but I worked it out."}
{"text": "Retrieved from https://www.physicsforums.com/threads/proof-of-divergence-for-the-harmonic-series.155418/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Proof of Divergence for the Harmonic Series.\n\n  1. Feb 9, 2007 #1\n    Prove the divergence of the harmonic series by contridiction\n\n    2. Relevant equations\n    Attached file\n\n    3. The attempt at a solution\n\n    I understand what they are doing in the first two lines, however, the lines after assuming the series converges with sum S, confuses me. They list the harmonic series and are adding terms in sets of three. I cant see where the next line comes from ( > 1 + 3/3 + 3/6 + 3/9).\n\n    Would somebody please be able to help me understand this proof?\n\n\n    Attached Files:\n\n  2. jcsd\n  3. Feb 9, 2007 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    Dearly Missed\n\n    Remember that 1/2+1/4>2/3?\n\n    So, 1/2+1/3+1/4=1/2+1/4+1/3>2/3+1/3=3/3\n  4. Feb 9, 2007 #3\n    Ohhhh...makes sense. Thanks a lot!"}
{"text": "Retrieved from https://www.physicsforums.com/threads/eccentricity-of-orbit.244403/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Eccentricity of Orbit\n\n  1. Jul 10, 2008 #1\n    A particle moves in an elliptical orbit in an inverse-square law central force \ufb01eld. If the\n    ratio of the maximum angular velocity to the minimum angular velocity of the particle\n    in its orbit is n, then show that the eccentricity of the orbit is\n\n    \\epsilon = \\frac{\\sqrt{n}-1}{\\sqrt{n}+1}[/tex]\n\n    Not sure where to go with this. I tried finding total energy and angular momentum in terms of max/min angular velocity and radius but can't get anywhere\n  2. jcsd\n  3. Jul 10, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n\n    At what points in the orbit are the maximal and minimum angular (or, for that matter, linear) velocities attained? At what distances from the \"massive body\" (what the particle is orbiting around -- assumed to be \"infinitely massive\" here) is the particle at those moments? (You don't need values here -- just identify those places on the orbit and label them appropriately.)\n\n    Now for the critical part. Angular momentum is conserved. What angle does the velocity makes to the radial vector from the massive body at those moments (and no others)? Express the angular momentum in terms of radial distance and velocities for those two moments and set them equal. What is the relationship between these two angular (or linear) velocities and the two distances from the massive body?\n\n    Having found how the ratio of angular velocities, called n here, relates to those distances, how do those distances fit into the expression for the eccentricity of an ellipse?\n\n    That would be the full derivation of the answer. If you already know how n relates to the ratio of distances, it's a short step to getting to the eccentricity expression...\n  4. Jul 10, 2008 #3\n    Thanks, got it. Silly of me for starting with eccentricity in terms of energy and angular momentum instead of geometry.\n  5. Jul 10, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    \u2026 geometry \u2026\n\n    Hi cscott! :smile:\n\n    Consider it geometrically \u2026\n\n    Hint: if F is a focus of the ellipse, and P and Q are the ends of the major axis, what is PF/QF as a function of e?\n\n    And then what is n as a function of PF/QF? :smile:"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54873.html\nText:\nThe Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nDistance Between 2 Lines: Vectors\n\nDate: 8/19/96 at 23:29:28\nFrom: Anonymous\nSubject: Shortest Distance...\n\nWhat is the shortest distance between 2 lines?\n\nDate: 8/20/96 at 8:16:26\nFrom: Doctor Anthony\nSubject: Re: Shortest Distance...\n\nI am not sure how much vector work you have done, but I will assume a \nknowledge of scalar products of vectors, and the vector equation of \nstraight lines.  \n\nIn 3D space the shortest distance between two skew lines is in the \ndirection of the common perpendicular. (There is one and only one such \ndirection, as can be seen if you move one line parallel to itself \nuntil it intersects the other line. These two lines would now define a \nplane, and the perpendicular to this plane is the direction of the \ncommon perpendicular).  \n\nYou now take any point on one line, and any point on the other line, \nand write down the vector joining these two points.  Finally you find \nthe component of this vector in the direction of the common \nperpendicular.  This is done by finding the scalar product of the \nvector with the UNIT vector in the direction of the common \nperpendicular.  The result of the scalar product is the shortest \ndistance you require.  \n\nI will illustrate the method by means of an example. \n\nFind the shortest distance between the lines:\n\nx/1 = (y-3)/1 = z/(-1)\n\n(x-5)/3 = (y-8)/7 = (z-2)/(-1)\n\nFirst we require the vector perpendicular to both (1,1,-1) and \n\nLet the common perpendicular be (p,q,r). The scalar product of this \nwith both (1,1.-1) and (3,7,-1) will be zero, so:\n\n   p+q-r = 0 and 3p+7q-r = 0\n\nNote that although there are apparently 3 unknowns and only two \nequations, these are homogeneous equations (having 0 on the right hand \nside), so we could find values of p/r and q/r and hence the ratios \np:q:r which is all that we require.  Using the determinant method for \nsolving, we have:\n\n    p       -q          r\n|1  -1|   |1  -1|     |1   1|\n|7  -1|   |3  -1|     |3   7|\n\n   p/6  =  -q/2    =   r/4\n\n   p/3  =  q/-1    =   r/2   and so  p:q:r = 3:-1:2\n\nSo the common perpendicular is the vector (3,-1,2)\n\nAs a UNIT vector this is (1/sqrt(14)){3,-1,2}\n\nNext we have point (0,3,0) on line (1) and (5,8,2) on line (2).  \nThe vector joining these points is (5,5,2)  and now scalar product \nthis with the unit vector of the common perpendicular.\n\nScalar product = (1/(sqrt(14)){5*3 + 5*(-1) + 2*2}\n               = (1/sqrt(14)){15 - 5 + 4}\n               = 14/sqrt(14)\n               = sqrt(14)    \n\n   and this is the shortest distance required.\n\n-Doctor Anthony,  The Math Forum\n Check out our web site!   \nAssociated Topics:\nHigh School Geometry\nHigh School Higher-Dimensional Geometry\nHigh School Linear Algebra\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM"}
{"text": "Retrieved from https://www.physicsforums.com/threads/probability-expected-value-of-z-where-z-x-1-y-2.530580/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Probability- expected value of Z, where z= X/(1+y)^2\n\n  1. Sep 15, 2011 #1\n\n    X & Y are independent r.v.s with uniform distribution between 0 and 1.\n\n    Z= X/(1+Y)^2\n\n    find E[Z].\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    Here is what I did.\n\n    E[Z]= E[X]*E[1/(1+Y)^2]\n    I think that once I know the distribution of (1+Y)^(-2), I'll be able to find the answer. Is it 1/(1+Y)^2~ U(1,2) ?\n  2. jcsd\n  3. Sep 15, 2011 #2\n    You can also use this theorem:\n\n\n    So, in your case, this comes down to\n\n  4. Sep 15, 2011 #3\n\n\n    thanks for the answer.\n\n    Is 1+y^2 a typo in your answer?\n    so adding a constant to a uniform r.v. doesn't change it's distribution?\n  5. Sep 15, 2011 #4\n\n    Obviously it does change the distribution. But I don't see how that is important here.\n  6. Sep 15, 2011 #5\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If W = 1/(1+Y)^2, then for any w > 0 we have P{W <= w} = P{1/(1+Y)^2 <= w} = P{-sqrt(w) <= 1/(1+Y) <= sqrt(w)}. The left-hand inequality -sqrt(w) <= 1/(1+Y) holds automatically because Y >= 0, so P{W <= w} = P{1/(1+Y) <= sqrt(w)} = P{Y >= -1 + 1/sqrt(w)}. Since Y ~ U(0,1), we can easily get P{W <= w} and hence can get the density function of W. Alternatively: just apply the standard formula for the density of a transformed random variable.\n\n  7. Sep 15, 2011 #6\n\n    Well I was thinking that now its uniformly distributed from 1 to 2... isn't it?\n\n    Oh right its still uniform from 0 to 1...\n    omg... I'm so rusty :\\\n\n    Last edited: Sep 15, 2011\n  8. Sep 15, 2011 #7\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have all the information you need to work out the answer for yourself."}
{"text": "Retrieved from https://www.physicsforums.com/threads/extended-power-derivative.763884/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Extended power derivative\n\n  1. Jul 29, 2014 #1\n    I am having difficulty calculating the following derivative [tex]{ \\frac{2x^2-1}{(3x^4+2)^2}}[/tex]\n\n    Could someone demonstrate the first step algebraically? Assuming c is the exponent on the variable expression, n is the numerator and d is the denominator, I tried:\n\n\n    Which gives me\n\n    Which simplifies to\n    [tex]\\frac{-48 x^7+72 x^5+8 x^3-16 x}{(3x^4+2)^3}[/tex]\n\n    However, the book lists the answer as being [tex]\\frac{-36x^5+24x^3+8x}{(3x^4+2)^2}[/tex]\n  2. jcsd\n  3. Jul 29, 2014 #2\n\n    Char. Limit\n\n    User Avatar\n    Gold Member\n\n    I'm not quite sure what rule you're trying to use, but if it's the quotient rule, then you've got it written down wrong. The correct way is:\n\n    [tex]\\frac{d}{dx} \\frac{n(x)}{d(x)} = \\frac{n'(x) d(x) - d'(x) n(x)}{d(x)^2}[/tex]\n\n    Since you've already worked the latter expression out, it should be easy to finish for you.\n  4. Jul 29, 2014 #3\n    Are you sure that : [tex]\\frac{d}{dx} (3x^4+2)^2=12x^3[/tex] ?\n  5. Jul 29, 2014 #4\n    My book lists a rule called the \"extended power rule,\" which goes as follows:\n\n    \"Suppose g(x) is a differentiable function of x. Then, for any real number k,\n\n    [tex]\\frac {d}{dx}[g(x)]^k=k[g(x)]^{k-1}*\\frac{d}{dx}[g(x)][/tex]\n\n    Here's a link to the text:\n\n\n    I could easily solve the problem by expanding the binomial expression (3x^4+2)^2 and then using the standard product rule, but I need to know how to use the extended product rule as one of the sample question is raised to the power of 7, and there is no way that I am going to expand that. If you can offer me an alternative method to dealing with the derivatives of high order expressions, I would accept that as well.\n  6. Jul 29, 2014 #5\n\n    Char. Limit\n\n    User Avatar\n    Gold Member\n\n    The extended power rule isn't exactly relevant here. And you got that particular part correct. The problem was that the quotient rule, for whatever reason, was done incorrectly. I'm not sure where you got a c or the first part of that product.\n  7. Jul 29, 2014 #6\n    The book says to use the extended power rule in addition to the quotient rule to solve this particular problem, so it has to be relevant >_>\n\n    According to the extended power rule, I take the exponent off the expression, k (i accidentally put c), and multiply it by g(x). The text has a step-by-step example of how to use the extended power rule in conjunction with another quotient problem, [tex]\\sqrt[4]{\\frac{x+3}{x-2}}[/tex] in which they use the setup [tex]k\\frac{n(x)}{d(x)}\\frac{n'(x)*d(x)-d'(x)*n(x)}{d(x)^2}[/tex], but that form doesn't appear to work here.\n  8. Jul 29, 2014 #7\n    You don't need to expend these high order derivatives, just use the chain rule. As a reminder [tex](3x^4+2)^2[/tex] can be seen as a function of this type : [tex]f(g(x))\\ \\mbox{where}\\ g(x)=3x^4+2\\ \\mbox{and}\\ f(x) = x^2\\\\ \\mbox {Now consider that the x in}\\ x^2\\ \\mbox{actually is your function g(x), that is, f(x) is applied to g(x), the x in brackets become g(x).}\\\\ \\mbox{You then have your function h(x) = f(g(x)), which is} (3x^4+2)^2\\\\ \\mbox{You can now differentiate h(x), and as you can see, it's simply the derivative of f(g(x)).}\\\\ \\mbox{Use the chain rule:} \\frac{d}{dx}f(g(x)) = f'(g(x)) * g'(x)\\ \\mbox{and you've got the derivative.}\\\\ \\mbox{You can now differentiate polynomials, for instance :} \\frac{d}{dx}(4x^5+3)^9 = 9*(4x^5+3)^8 * 20x^4\\\\ \\mbox{In general :}\\ \\frac{d}{dx}(P(x))^n = n(P(x))^{n-1} * P'(x)[/tex]\n\n    Hope this helps!\n  9. Jul 29, 2014 #8\n    thank you!\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/mis-using-bernoullis-equation.836002/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Mis-using Bernoulli's equation\n\n  1. Oct 4, 2015 #1\n\n    An incompressible heated gas of constant temperature and pressure flows along an infinitely long tube at an unspecified velocity v1; a pressure of P1; and a density of p1 into an unheated open area of infinite volume containing the same gas at a lower pressure of P2; a density of p2,; and an effective velocity v2 of 0 m/s. The pipe is horizontal. Find the velocity of the gas inside the tube, ignoring friction and head losses.\n\n    2. Relevant equations\n    Bernoulli's equation, maybe\n\n    3. The attempt at a solution\n    Since the pipe is horizontal, h1 and h2 are treated as 0, cancelling out the pgh terms on each side of the equation. Since v2 is also 0, the .5p2v22 is eliminated. That leaves us with:\n\n    P1 + .5p1v12 = P2\n\n    Since P1 > P2 in this situation, the answer is always going to be the square root of a negative number.\n\n    Common sense tells me that the gas will flow from a region of high pressure to a region of low pressure, so it should flow out of the tube; sadly, it seems that I am applying Bernoulli's equation incorrectly in attempting to form a basic model of that effect. That, or something else is terribly wrong with the way the scenario is laid out (this is my own thought experiment; it is not homework, and no teacher is to blame for this problem).\n\n    Just looking at the reduced equation, it's all wrong. There's no way the high pressure value plus PLUS the squared velocity is going to equal the low pressure value. But the flow velocity in the tube is going to be non-zero since gas will be constantly leaving the tube ad infinitum, while the velocity outside of the tube is going to be zero since it is effectively a section of tube with a cross-sectional area approaching infinity.\n  2. jcsd\n  3. Oct 5, 2015 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    2017 Award\n\n    Bernoulli equation is conservation of energy. At tube inlet you have pressure energy and kinetic energy. At tube outlet you have lower pressure energy, so if all else can be ignored, you should have higher kinetic energy. I.e. v2 > v1, in contradiction with your assumption that v2 = 0.\n    The change from v2 > v1, to v'2 = 0 must occur somewhere in or around the tube outlet area, apparently.\n\n    Look at Bernoulli examples for flow through a small orifice (most have \u0394p > 0 from tank to jet) and compare with your case (\u0394p > 0 from pipe to 'tank')\n  4. Oct 5, 2015 #3\n    Your answer makes sense. I have erred in assuming that the equation covers the quiescent gas in the open area rather than the gas ejected from the tube in the immediate vicinity of the tube's outlet.\n  5. Oct 6, 2015 #4\n    Followup question: Given that the above-mentioned gas in the tube assumes a velocity of v2 immediately after exiting the tube where v2 > v1, is it safe to assume that the pressure P2 and density p2 of said gas will be the same as that of the quiescent gas in the open area? Or will that only pertain once the velocity of the exiting gas settles out after some arbitrary amount of time and effectively equals 0?\n  6. Oct 6, 2015 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    2017 Award\n\n    Bernoulli to the rescue again: when the gas is slowing down, the pressure must necessarily increase ! So I would say no. There will be some contraction effects and a volume where p is even lower than P2. I think I saw them described in one of the orifice flow examples.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/44226/compile-function-which-calls-other-functions-to-c/44228\nText:\nTake the 2-minute tour \u00d7\n\nI have a function which calls other functions and I would like to compile it to C code. For example:\n\nfoo[p_] := 0.7 Exp[-p^2]\nf[a_, n_] := \n Module[{s, p, i}, s = 0; p = a; \n  For[i = 0, i < n, i++, s += foo[p]; p *= a;]; s]\n\nNow if I do\n\ncf = Compile[{{a, _Real}, {n, _Integer}}, f[a, n]]\n\nand print the C code with\n\n\nthe output is\n\nR1 = MainEvaluate[ Hold[f][ R0, I0]]\n\nwhich is obviously not desired.\n\nWhen I try Compile[{{a, _Real}, {n, _Integer}}, Evaluate@f[a, n]], it just gives a function which returns 0...\n\nshare|improve this question\nHave a look at my answer here mathematica.stackexchange.com/q/24595/66 , it does what you want with the function CompileExpand and if the names of the user functions called are defined with upper cases. \u2013\u00a0 faysou Mar 19 '14 at 7:42\n\n1 Answer 1\n\nup vote 12 down vote accepted\n\nYou need to inject the body of your function definition(s) into the Compile call without evaluating it. One possibility is (I had to change your Module a bit to correct a type error)\n\nf[a_, n_] := Module[{s = 0.0, p = a, i},\n\ncf = ReleaseHold[Hold[Compile[{{a, _Real}, {n, _Integer}}, f[a, n]]] \n       /. DownValues[f] /. DownValues[foo]]\n\nMore explanation\n\nFirst of all you need to understand that when you make a function definintion, Mathematica stores a replacement rule. There are different kinds of such rules and the most important ones are DownValues and OwnValues. OwnValues are used when you make assignments like x=1 or x:=1. DownValues are for function definitions. Let take a look at the rules of foo\n\n(* {HoldPattern[foo[p_]] :> 0.7 Exp[-p^2]} *)\n\nVery sloppy speaking, when you make any calculation in Mathematica then it looks at your code and checks what rules are connected with a symbol. Then it uses these rules and makes the replacement, if the pattern matches.\n\nIn your case, the problem with your Compile call is that\n\n  1. Compile has the attribute HoldAll which prevents that f[a,n] is replaced with its definition.\n  2. If you force the evaluation of the expression f[a,n] using Evaluate then it does too much, because it doesn't only insert the definition body of f (the Module part) but it evaluates it right away. This is not good because at this point, you don't have numeric values for a and n and therefore, the For loop doesn't do anything at all.\n\nAt this point, it is clear what you want: You have made a definition for f[a,n], how can you get the fully expanded function body? Two ingredients: First, you use the definition rules (DownValues) by yourself and second, you prevent the evaluation using Hold. There you go..\n\nHold[f[a, n]] /. DownValues[f]\n(* Hold[Module[{s$ = 0., p$ = a, i$}, \n         For[i$ = 0, i$ < n, i$++, s$ += foo[p$]; p$ *= a;]; s$]] \n\nAs you see we are not finished, because the definition of foo was not expanded, but this is not a problem, because we can do it the same way. All this combined with Compile gives the above solution.\n\nshare|improve this answer\nWould you care to explain a bit how this works? What is the purpose of DownValues? \u2013\u00a0 Danvil Mar 19 '14 at 9:15\n@Danvil I have added some information in my answer. \u2013\u00a0 halirutan Mar 19 '14 at 10:19\nThank you very much! So am I assuming correctly that Mathematica can not compile a recursive function to C? E.g. f[n_] := If[n == 0, 1, n f[n - 1]]. \u2013\u00a0 Danvil Mar 19 '14 at 13:52\n@Danvil Yes, I discussed this issue several times with e.g. @Oleksandr R. who has quite some knowledge about such stuff. When I remember correctly, then there is no general way to make a recursive compiled function. This goes along with Leonids answer here. \u2013\u00a0 halirutan Mar 19 '14 at 21:00\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122104/area-of-triangles-vs-comparison-triangles\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a complete, simply connected Riemannian manifold satisfying a quadratic (coarse) isoperimetric inequality. (I.e., there is a constant $C_{0}$ such that every loop of length $\\ell$ has a filling disk of area $\\leq C_{0}\\ell^{2}+C_{0}$.)\n\nFor points $a,b,c\\in X$, define $Area_{X}(a,b,c)$ to be the minimal area of any geodesic triangle in $X$ with vertices $a,b,c$. Define $Area_{comp}(a,b,c)$ to be the area of a Euclidean triangle with side lengths $d(a,b)$, $d(b,c)$ and $d(c,a)$.\n\nDoes there exist a constant $C$ such that for all $a,b,c\\in X$ we have:\n\n$Area_{X}(a,b,c)\\leq C Area_{comp}(a,b,c)+C$?\n\nIf the answer is no, then are there counterexamples when $X$ is homogeneous?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\n\nBlow a bubble of the same size at each integer point of $\\mathbb R^2$. Clearly coarse isoperimetric inequality will hold.\n\nOn the other hand, the global metric on the plane can be made arbitrary close to the Manhattan metric, in particular there will be triangles which bound arbitrary large area while its comparison area is near zero.\n\nshare|improve this answer\nP.S. If you look in \"Periodic metric\" by Burago you will see more than you want to. \u2013\u00a0 Anton Petrunin Feb 18 '13 at 0:17\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/rate-of-change-of-x-wrt-sin-x.747893/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nRate of change of x wrt sin(x)\n\n  1. Apr 9, 2014 #1\n    Is possible to compute the rate of change of x wrt sin(x)? ##\\frac{dx}{d \\sin(x)}##\n  2. jcsd\n  3. Apr 9, 2014 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Have you tried just plotting it in Excel? You will get some 1/0 inflection points that you will need to deal with...\n  4. Apr 9, 2014 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Compare with ##\\frac{dsin^{-1}(x)}{dx}##\n\n    Or, turn the graph of sin(x) on its side.\n  5. Apr 9, 2014 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Compare to reciprocal dsin(x)/dx. Sin-1(x) is not relevant.\n  6. Apr 9, 2014 #5\n    Why isn't it relevant?\n\n    If we have dx/d(sinx), why is it not reasonable for me to let sinx = y and therefore have that x = arcsin(y)?\n\n    Then I have d(arcsin(y))/y = 1 / sqrt(1-y\u00b2)\n\n    And thus dx/d(sinx) = 1/sqrt(1-sin\u00b2(x)) = 1/sqrt(cos\u00b2(x)) = 1/|cos(x)|\n\n    Just curious, so where does this break down? This is a very unique question so I'm sure there is an error in my logic. One may note that this comes out to be only slightly different than the reciprocal method (no absolute value). I suspect this is because in assigning these variables in the way I did, I restricted/changed domain?\n    Last edited: Apr 9, 2014\n  7. Apr 9, 2014 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n\n    Due to the inverse function theorem, it is very relevant.\n  8. Apr 10, 2014 #7\n    After a quick Google, it looks like I followed this theorem with f(a) = sin(x). So why does f'(b) evaluate to 1/|cos(x)| according to my work rather than 1/cos(x) as the inverse function theorem claims it should?\n\n    I mean, hopefully we can agree that the answer to the OP's question is actually 1/cos(x) and not 1/|cos(x)|.\n  9. Apr 10, 2014 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    There are two ways to \"differentiate x with respect to sin(x)\". The first is to use the fact that\n    [tex]\\frac{dx}{dy}= \\frac{1}{\\frac{dy}{dx}}[/tex].\n    Here y= sin(x) so dy/dx= cos(x). Then dx/dy= 1/cos(x) is a perfectly good answer.\n\n    The other way is to say that if y= sin(x) then [itex]x= sin^{-1}(y)[/itex] so that the derivative of \"x with respect to sin(x)\" is [itex]dx/dy= d(sin^{-1}(y))/dy= 1/\\sqrt{1- y^2}[/itex].\n\n    It's not at all difficult to prove that those are the same. If y= sin(x) then [itex]1- y^2= 1- sin^2(x)= cos^2(x)[/itex] so [itex]1/\\sqrt{1- y^2}= 1/cos(x)[/itex].\n  10. Apr 10, 2014 #9\n    So, I can differentiate any function f(x) wrt another any function g(x).\n\n    If df = f'(x) dx and dg = g'(x) dx, thus df/dg = f'/g' ...\n  11. Apr 10, 2014 #10\n    Our work is the same, but I don't understand how you conclude that sqrt(cos\u00b2(x)) = cos(x). This is |cos(x)|, don't you agree?\n  12. Apr 10, 2014 #11\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n\n    Well, the sine function is not invertible, since it's not injective and not surjective. This is of course no problem for the inverse function theorem, since it will take a \"local inverse\".\n    You worked with the arcsine, which is indeed a local inverse. But not all local inverses are like the arcsine. That is, if we restrict the sine to ##(-\\pi/2,\\pi/2)## then the arcsine is an inverse. But guess what? The cosine function is actually positive on that said, so the absolute values drop.\n\n    If you apply the inverse function theorem on some other domain, then you can't use the arcsine anymore in that form.\n\n    Does that make sense?\n  13. Apr 10, 2014 #12\n    Yes, thank you.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Rate of change of x wrt sin(x)\n  1. Integration of sin(x) (Replies: 14)\n\n  2. Sin x =cosh x (Replies: 12)\n\n  3. Inverse of sin(x)+x (Replies: 10)"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/51655.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nTangent Lines and Odd Degree Polynomials\n\nDate: 07/24/98 at 16:13:42\nFrom: Michelle Moulton\nSubject: modern algebra/geometery\n\nLet p(x) be a polynomial of odd degree. Determine whether every point \nin the plane lies on at least one line which is tangent to the curve  \ny = p(x).\n\nDate: 07/26/98 at 15:27:56\nFrom: Doctor Jaffee\nSubject: Re: modern algebra/geometery\n\nHi Michelle,\n\nThis was a tough one, but I think I've found a way to justify that \nevery point does, in fact, lie on at least one line that is tangent to \np(x), where p(x) is an odd polynomial. I assume that you understand the \nbasics of calculus. If not, this explanation probably won't make any \nsense to you. In that case, write back and I'll try to come up with a \nnon-calculus explanation.\n\nSince the function is differentiable everywhere, any point on the \ncurve is automatically on a line tangent to the curve. Let's consider \nthe point (a, b), which is not on the curve. In order for this point to \nbe on a line tangent to the curve, there must be a point (x, p(x)) \nwhich is the point of tangency. The slope of the line, then, is p'(x) \nand the equation of the line is p(x) - b = p'(x)(x - a), where a and b \nare constants and x is the variable we have to calculate to find the \npoint of tangency.\n\nIn other words we have to solve an equation whose degree is odd. But \nthe curve of every polynomial with an odd degree has to intercept the \nx-axis at least once, so this equation must have at least one solution, \nwhich proves that there does exist at least one point on the curve \nwhose tangent line goes through the point (a, b).\n\nI hope this explanation makes sense. If not, write back.\n\n- Doctor Jaffee, The Math Forum\nAssociated Topics:\nCollege Calculus\nCollege Euclidean Geometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from https://www.physicsforums.com/threads/y-x-2-y-2-xy-ode.86514/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\n\n  1. Aug 27, 2005 #1\n    for this O.D.E. :\n    y`= (x^2 + y^2)/xy\n    it's unseparable, so what other methods can there be taken?\n  2. jcsd\n  3. Aug 27, 2005 #2\n    It's a change of variables case (actually excercise #1 in my book on this topic), the way you do this is check to see whether f(x,y) = f(tx,ty), where f(x,y) = dy/dx.\n    So if you substitute tx and ty for x and y respectively, you'll see that equality holds. Then do following substitution: y = x V(x) into the DE and see what you get with applying dy/dx and some simplifications. It should reduce to separable equation.\n  4. Aug 27, 2005 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    This is just like the post about the other ODE. You can write it as:\n\n\n    Again, with the substitution z=y/x it becomes:\n\n    which is separable.\n  5. Aug 28, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    it's homogenous, separable, use v=y/x\n  6. Aug 30, 2005 #5\n    ok, thanks!\n  7. Sep 3, 2005 #6\n    here's my work:\n    y`=x/y +x/y\n    suppose y=vx\n    => y`=v+xv`\n    so v+xv`=1/v+v\n    => vdv=dx/x\n    => v^2=ln[absolute value(x)]+c`\n    => (y^2)/(x^2)=ln[absolute value(x)]+c\n    => y^2=2(x^2)ln[absolute value(x)]+cx^2\n    now if i take the square root on both sides, there should be a positive and negative sign on the right~\n    the correct answer should only have the positive sign, but how can you be sure that it should be positive?\n  8. Sep 3, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Whoopsie, you've forgot a factor 1/2 on the left side.\n\n    You can use either sign, both will be valid solutions to the ODE. This becomes clear when you plug y back into the ODE to check if it works out. Then, with the benefit of hindsight, you could foresee this, since if y is one solution, then the other is -y and it's derivative is -y'. If you write the ODE as xyy'=x^2+y^2 you can see that if y is a solution, then -y is too.\n\n    Ofcourse, if you're given a boundary value or initial value/condition then there will be only one solution. (otherwise the problem is ill-stated).\n  9. Sep 4, 2005 #8\n    thank you very much! :)\n\nHave something to add?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/597134/deformations-of-a-cuspidal-plane-cubic\nText:\nTake the 2-minute tour \u00d7\n\nTo practice with deformations, I am trying to compute the space of first order deformations of the cuspidal curve $X=\\textrm{Spec }B$, where $B=P/I$, $P=k[x,y]$ and $I=(f)=(y^2-x^3)$.\n\nThe conormal sequence $$I/I^2\\overset{d}{\\longrightarrow}\\Omega_{P/k}\\otimes_PB\\cong B\\,dx\\oplus B\\,dy\\longrightarrow \\Omega_{B/k}\\longrightarrow 0$$ induces a $B$-linear map (the \"dual\" of $d$) $$\\alpha:\\hom_B(\\Omega_{P/k}\\otimes_PB,B)\\to\\hom_B(I/I^2,B).$$ Just to be as clear as possible with those who read this question, I give a list of \"synonyms\" of the space of first order deformations of $X$ (hoping not to confuse anyone, nor to state something wrong!):\n\n  \u2022 $\\textrm{coker } \\alpha$,\n  \u2022 $T^1(B/k,B)$,\n  \u2022 $\\textrm{Ex}_k(B,B)$,\n  \u2022 $\\textrm{Ext}^1_B(\\Omega_{B/k},B)$.\n\nI attempted to determine $\\textrm{coker }\\alpha$, but now I'm stuck.\n\nWhat I did was just to translate the maps explicitly. So for instance $I/I^2$ is a principal module generated by $\\overline f=f+I^2$, so $$d:\\overline f\\mapsto 2y\\,dy-3x^2\\,dx.$$ This is useful to determine $\\alpha$. The source is generated by two vector fields $\\partial/\\partial x$ and $\\partial/\\partial y$, so: \\begin{align} \\alpha: &\\partial/\\partial x\\mapsto (\\overline f\\mapsto \\partial f/\\partial x=-3x^2),\\\\ \\alpha: &\\partial/\\partial y\\mapsto (\\overline f\\mapsto \\partial f/\\partial y=2y). \\end{align}\n\nNow, as $I/I^2$ is a principal module, we get an identification $(\\star)$ $$\\textrm{coker }\\alpha=\\hom_B(I/I^2,B)/\\textrm{Im }\\alpha\\overset{(\\star)}{\\cong} B/(-3x^2,2y)\\cong k[t^2,t^3]/(t^4,t^6).$$\n\nI cannot go further, and I remember having read on Moduli of Curves that this space should be $2$-dimensional. Can anyone help me to conclude?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe quotient $B/(-3x^2,2y) \\cong B/(x^2,y) = k\\langle 1, x \\rangle$.\n\nA mini-versal deformation is given by $x^3 + y^2 + ax + b$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/38853/order-of-stabilizer\nText:\nTake the 2-minute tour \u00d7\n\n$G$ is a group which acts transitively on a set $S$. $G_s$ is the stabilizer of $s$. How to see the map from $G/G_s$ to $S$ given by $g*G_s \\to g(s)$ is one to one?\n\nshare|improve this question\n\n2 Answers 2\n\nLet $g,h\\in G$. If $g(s)=h(s)$, then $$g^{-1}(g(s))=g^{-1}(h(s)),$$ which becomes $$(g^{-1}g)(s)=e(s)=s=(g^{-1}h)(s).$$ Thus $g^{-1}h\\in G_s$ because $g^{-1}h$ stabilizes $s$. Thus $g^{-1}hG_s=G_s$, and thus $hG_s=gG_s$.\n\nTherefore, given any $gG_s$ and $hG_s$, if $g(s)=h(s)$ then $gG_s=hG_s$. Thus the map is injective (which is one possible meaning of one-to-one).\n\nSome people instead use \"one-to-one\" to mean bijective. Under this meaning, the map $gG_s\\mapsto g(s)$ is still one-to-one. We have already shown the map is injective above; so all that is left is to prove it is surjective, and then we will have shown it is bijective.\n\nGiven any $t\\in S$, there is a $g\\in G$ such that $g(s)=t$ (this is the definition of transitive). Thus given any $t\\in S$, there is an element of $G/G_s$ that maps to $t$, namely $gG_s$ where $g$ is any element that sends $g(s)=t$ (and we know at least one must exist).\n\nshare|improve this answer\n\n$g(s)=h(s)\\iff h^{-1}g\\in G_s\\iff gG_s=hG_s$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/48221/spectral-sequence-for-cohomology-of-open-subset\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a smooth compact orientable manifold (or variety) and let $j: U \\subset X$ be the complement to a union $\\bigcup_{i \\in I} X_i$ of smooth compact orientable manifolds. Suppose that $A$ is a sheaf on $X$ - say, the locally constant sheaf $Z$ (although the question below can be asked for coherent sheaves too). Let $Z_U$ be $j_!j^* Z$, i.e. the locally constant sheaf on $U$ extended by zero to $X$. The usual set theoretic inclusion-exclusion formula leads to a long exact sequence of sheaves $0 \\to Z_U \\to Z \\to \\oplus Z_{X_i} \\to \\oplus Z_{X_i \\cap X_j} \\to \\ldots$ where for a closed subset $f: W \\subset X$ one sets $Z_W = f_* f^* Z$.\n\nThis leads to a spectral sequence with first page given by cohomology of finite intersections $X_{i_1} \\cap \\ldots \\cap X_{i_s}$, and the differential is induced by the combinatorial inclusion-exclusion formula.\n\nAre there any examples when the differential of $E_2$ is non zero and known explicitly (which means that we also know the E_2 terms)? Maybe something in terms of excess intersection bundles for intersections of $X_i$, some Gysin maps, etc/?\n\nshare|improve this question\nLike this? dpmms.cam.ac.uk/~bt219/config.pdf \u2013\u00a0 Ryan Budney Dec 3 '10 at 23:20\nThank you Ryan, you could see well beyond the question I stated :) \u2013\u00a0 Vladimir Baranovsky Dec 6 '10 at 0:30\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/65202/how-to-prove-log-n-n?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nSorry if this is a silly question but most books claim $\\log n < n$ for $n \\geq 1$ without providing any proof, saying it's too obvious. Could someone give me a rigorous proof? Is there some trick or method I forgot about?\n\nshare|improve this question\nIn fact, $\\log x \\leq x-1$ for any $x \\geq 0$. This is equivalent to the inequality $1+t \\leq e^t$ for all $t \\in \\mathbb R$. \u2013\u00a0 Srivatsan Sep 17 '11 at 3:06\nHint: $e^x = 1 + x + x^2/2 + x^3/6 ... > 1 + x$ when $x>0$. \u2013\u00a0 Thomas Andrews Sep 17 '11 at 4:19\nSee this question for proofs that for all $t\\gt 0$, $\\log t\\leq t-1$, which implies the question you have. So this looks like a duplicate. \u2013\u00a0 Arturo Magidin Sep 17 '11 at 4:57\n\n6 Answers 6\n\nup vote 14 down vote accepted\n\nIf we let $f(n) = \\log n$ and $g(n) = n$, then $f'(n) = \\frac{1}{n}$ and $g'(n)=1$. Since $f(1) < g(1)$ and $f'(n) \\leq g'(n)$ for $n \\geq 1$, we must have $f(n) < g(n)$ for all $n \\geq 1$.\n\nThe idea in the last sentence is sometimes called the racetrack principle: If $f(n)$ and $g(n)$ denote the positions of horses $f$ and $g$ at time $n$, horse $f$ starts behind horse $g$ (i.e, $f(1) < g(1)$), and at any given time horse $f$ is never faster than horse $g$ (i.e, $f'(n) \\leq g'(n)$) then horse $f$ will always be behind horse $g$ (i.e, $f(n) < g(n)$ for $n \\geq 1$).\n\nOP asks for a proof of the racetrack principle.\n\nThe racetrack principle: If $f(a) < g(a)$ and $f'(n) \\leq g'(n)$ for $n \\geq a$, then $f(n) < g(n)$ for $n \\geq a$.\n\nProof: Let $h(n) = f(n) - g(n)$. Then $h'(n) = f'(n) - g'(n) \\leq 0$. The mean value theorem tells us that there exists some point $x \\in [a,n]$ such that $$h'(x) = \\frac{h(n) - h(a)}{n-a}.$$ Since we know the claim is true for $n=a$, take $n > a$. We already know $h'(x) \\leq 0$, so we get $h(n) - h(a) \\leq 0$, which means $f(n) - g(n) \\leq f(a) - g(a) < 0$, and so $f(n) < g(n)$ for $n \\geq 1$.\n\nshare|improve this answer\nOops - cross-posted the same thing. Sorry! \u2013\u00a0 Billy Sep 17 '11 at 3:06\nHow do I prove this general theorem? Is it possible to do using the Big-O definition? \u2013\u00a0 Mark Sep 17 '11 at 3:08\n@Mark: I'll add a proof. \u2013\u00a0 Mike Spivey Sep 17 '11 at 3:12\nOn the account of your proof,I guess we can call it a variation of racetrack principle :-) \u2013\u00a0 VelvetThunder Sep 17 '11 at 3:35\n\nHow rigorous do you need? If it's rigorous enough in your context, prove that log(1) < 1 (shouldn't be hard!), and then show that the derivative of log(x) is less than or equal to the derivative of x for all $x \\geq 1$.\n\nshare|improve this answer\nCould you prove this using Big-O definition? \u2013\u00a0 Mark Sep 17 '11 at 3:16\n@Mark: No, this isn't what big O notation is about. Big O describes limiting behaviour (e.g. as two functions go to infinity), and says nothing about what they do elsewhere. \u2013\u00a0 Billy Sep 17 '11 at 3:18\nYou are right, but I wonder how one should prove this without using calculus. Are there more primitive tools? \u2013\u00a0 Mark Sep 17 '11 at 3:21\n@Mark: That depends on how you define the natural logarithm in the first place. The most direct definitions I am aware of, either as $\\log x = \\int_1^x dt/t$, or as the inverse of the exponential function defined as $d/dx \\exp x = \\exp x$ and $\\exp 0 = 1$, are definitions which themselves require calculus. \u2013\u00a0 Rahul Sep 17 '11 at 3:57\n\njust simply look at the function $f(t)=t-log(t)$. You can show that this function is always increasing and that $f(n)\\ge f(1)=1$ for every $n$.\n\nshare|improve this answer\n\nI will assume that by $\\log n$ we mean the natural logarithm of $n$.\n\nIf $b > 1$, then $\\log b$ is the area under the curve $y=1/x$, above the $x$-axis, from $x=1$ to $x=b$.\n\nThis area is clearly less than the area of the rectangle with base $b-1$ and height $1$, so $\\log b <b-1$.\n\nComment: It is not uncommon in calculus courses to define $\\log b$ as above, and then introduce the exponential function. If we want to make the argument rigorous, we would probably introduce the definite integral before introducing the derivative, and define $\\log b$ as $\\int_1^b \\frac{1}{t} dt$. The inequality we need is an easy consequence of the definition of Riemann integral.\n\nshare|improve this answer\n\nFor $n\\geq 1$, $\\log n < n$ iff $n < e^n = 1 + n + n^2/2! + n^3/3! + \\cdots$\n\nshare|improve this answer\n\nIn your comments you seem ask about this in the context of the big O notation -- e.g., the concept frequently used in computer science that when analyzing an algorithm for time (or resource consumption like RAM). In big O notation, the following order appears (with constant time as best, and exponential time being worst):\n\n  \u2022 $O(1)$ - constant time\n  \u2022 $O(\\log N)$ - logarithmic\n  \u2022 $O(N)$ - linear\n  \u2022 $O(N \\log N)$ - loglinear\n  \u2022 $O(N^2)$ - quadratic (followed by other polynomial times e.g., $O(N^3)$ - cubic, etc.)\n  \u2022 $O(2^N)$ - exponential time\n\nYou aren't going to come up with a mathematical proof for this ordering that shows for every $N$ that a $O(\\log N)$ function will be smaller than every $O(N)$ function, because it simply isn't true. To demonstrate with a counterexample, let $f(N) = 10^{100} \\log N$ (an $O(\\log N)$ algorithm; you ignore the constant multiplier), and let $g(N) = N$ ($O(N)$ algorithm). While $N \\lt 10^{98}$, $f$ the logarithmic function will be larger (and hence slower; less optimal) than $g$ the linear-time function, opposite to what you usually expect.\n\nThe point of big O notation is that the scaling what usually matters most is how the functional will scale for large N. Comparing any logarithmic and linear function, the logarithmic function will always be smaller than the linear function for all values of $N$ larger than some finite number. You would say that a $O(\\log N)$ function grows asymptotically slower than a $O(N)$ function.\n\nNote in many cases like comparing $f(N) = N$ and $g(N) = \\log N$ it will be true over the entire domain of $N$ (equivalent to $N \\gt 0$).\n\nThe power of big-O notation is that is if you know you have an $O(N)$ and an $O(\\log N)$ function and both take 2 seconds to do when $N = 100$, when you need to process $N = 100000$ cases, the O(N) function will worst-case take roughly 2000 seconds, but the $O(\\log N)$ function will take only about 5 seconds.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/131648/even-more-generalized-catalan-numbers/131656\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the number of ways to parenthesize $n$ elements using applications of operators of arbitrary arities larger than or equal to $2$? For example, for $n=3$, there are $3$ ways: $$ abc, a(bc),(ab)c $$ and for $n=4$ there are 11 ways: $$ abcd,\\ ab(cd),\\ a(bc)d,\\ (ab)cd ,\\ a(bcd), (abc)d,$$ $$ a(b(cd)),\\ a((bc)d),\\ (ab)(cd),\\ (a(bc))d,\\ ((ab)c)d $$ Note that, if we restrict the operators to have arity $2$ (i.e. binary operators), then the answer would be given by the Catalan number $C_{n-1}$. (More generally, if we restrict the operators to have arity $p$, the answer would be given by generalized Catalan numbers. So the point here is that the arity is arbitrary, corresponding to a situation where I can select between operators of arities 2,3,4,...\n\nAn aymptotic formula for $n\\to\\infty$ would also be highly appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nA little bit of programming and a look up in the OEIS tells me that this is the sequence A001003, the solution to Schroeder's second problem, see also Wikipedia.\n\nAccording to the page in OEIS, the asymptotic form is $$ \\frac{n^{-3/2}}{4}\\sqrt{\\frac{\\sqrt{18}-4}{\\pi}}(3+\\sqrt{8})^n. $$\n\nshare|improve this answer\nThe wikipedia is clickable in this notation: en.wikipedia.org/wiki/Schr%C3%B6der%E2%80%93Hipparchus_number \u2013\u00a0 Gottfried Helms May 24 '13 at 1:10\nJust was I was looking for. Thank you! \u2013\u00a0 Esben May 24 '13 at 7:03\nBy the way, if you take just the first four terms in the sequence (1,1,3,11) and put them into OEIS, the first suggestion (out of 191) that comes up is in fact the right answer. OEIS is incredibly useful for these types of questions. \u2013\u00a0 Kirill May 24 '13 at 17:50\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/58972/probability-of-preserving-connectivity-between-pair-of-vertices-in-weighted-grap\nText:\nTake the 2-minute tour \u00d7\n\nLet $G=(V,E)$ be an undirected graph and $p \\colon E \\mapsto (0,1]$ defines weights of its edges.\n\nLet's fix two connected vertices $v_1, v_2 \\in V$.\n\nRandom graph $G'=(V,E')$ is obtained from $G$ by removing each edge $e \\in E$ with probability $1-p(e)$.\n\nWhat is the probability that connectivity between $v_1$ and $v_2$ is preserved in $G'$?\n\nshare|improve this question\nThis looks hopeless to have a nice formula isn't it ? \u2013\u00a0 camomille Mar 20 '11 at 14:39\nYou definitely must tell more about the graph (and about the weight function) to get any answer at all. Compare the case of the line graph with $v_1$ and $v_2$ far apart to the case of the complete graph on $n$ vertices with $n$ large. \u2013\u00a0 Did Mar 20 '11 at 14:52\n@Didier well, you right, that's implied part of the question -- if there are no nice results for arbitrary graph, maybe there are any non-trivial classes of graphs, where this problem is trackable? In my context it would be randomly generated scale-free network with number of edges that makes the brute force method unfeasible. \u2013\u00a0 alyst Mar 20 '11 at 17:33\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet L be the set of all simple paths in G from $v_1$ to $v_2$. By inclusion-exclusion, the probability that $v_1$ and $v_2$ are connected is\n\n$\\sum_{A \\subseteq L} (-1)^{|A|-1} P(\\cup A \\subseteq E')$\n\nwhere for any set S of edges, $P(S \\subseteq E') = \\prod_{e \\in S} p(e)$.\n\nAlthough explicit computation won't be feasible for large graphs, under appropriate conditions this might be used to get asymptotics.\n\nshare|improve this answer\nThanks, Robert. That gives an idea for an alternative formula: if $M$ is a collection of all minimal sets of edges, which removal disrupts connectivity between $v_1$ and $v_2$, then $1 - \\sum_{B \\subseteq M} (-1)^{|B|-1} P(\\cup B \\not\\subseteq E')$ should also be the sought probability, where $P(S \\not\\subseteq E') = \\prod_{e \\in S} (1-p(e))$. \u2013\u00a0 alyst Mar 20 '11 at 21:28\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/sum-of-superadditive-functions.156650/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSum of superadditive functions\n\n  1. Feb 16, 2007 #1\n    Show that the sum of two superadditive (supermodular) functions is superadditive.\n\n    2. Relevant equations\n    Let X and Y be partially ordered sets and g(x,y) a real-valued function on XxY. g is supermodular (superadditive) if for x1>=x2 in X and y1>=y2 in Y,\n    g(x1,y1) + g(x2,y2) >= g(x1,y2) + g(x2,y1)\n\n    3. The attempt at a solution\n    Let g(x,y) and h(x,y) be supermodular functions on XxY. Then the following inequalities hold:\n    h(x1,y1) + h(x2,y2) >= h(x1,y2) + h(x2,y1)\n\n    Let f(x,y) = g(x,y) + h(x,y), then\n    [g(x1,y1) + h(x1,y1)] + [g(x2,y2) + h(x2,y2)] >= [g(x1,y2) + h(x1,y2)] + [g(x2,y1) + h(x2,y1)]\n    f(x1,y1) + f(x2,y2) >= f(x1,y2) + f(x2,y1)\n\n    Thus, the sum of two supermodular functions is supermodular.\n  2. jcsd\n  3. Feb 16, 2007 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    It's better to write it out with the f's:\n    [tex]f(x_1,y_1)+f(x_2,y_2)=\\left(g(x_1,y_1)+h(x_1,y_1)\\right)+\\left(g(x_2,y_2)+h(x_2,y_2)\\right) ... \\geq f(x_1,y_2)+f(x_2,y_1)[/tex]\n  4. Feb 16, 2007 #3\n    Thank you\n\n    Thank you so much.\n\nHave something to add?\n\nSimilar Discussions: Sum of superadditive functions"}
{"text": "Retrieved from https://www.physicsforums.com/threads/spot-the-error-in-my-code-in-c.163923/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nSpot the error in my code. (in C).\n\n  1. Apr 3, 2007 #1\n    i was asked to write down a code that calculates via the trapezoid method, the integral f(x)=10x^2-x^3 from x=-2.5 up to x=2, and compares it to the analytic solution. well here's my code, my problem is that it's stuck on numbers such as 20 (number of segments).\n    can anyone spot my error in my code, i appreciate:\n    Code (Text):\n\n    #include <stdio.h>\n    #include <math.h>\n    \u00a0 long double initial,area,Segments,dx;\n    \u00a0 printf(\"insert the number of sgements to subdivide the interval \\n\");\n    \u00a0 scanf(\"%f\", &Segments);\n    \u00a0 if(Segments!=0) dx=4.5/Segments;\n    \u00a0 else printf(\"error \\n\");\n    \u00a0 while(area<=84.515625 && initial<2)\n    \u00a0 \u00a0 \u00a0 \u00a0 printf(\"the numerical integration yields %f with accuracy of 0.001 from analytical result \\n\",area);\n  2. jcsd\n  3. Apr 3, 2007 #2\n\n    D H\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    This is a terrible loop condition:\n\n    while(area<=84.515625 && initial<2)\u200b\n\n    This condition does not involve the number of intervals (i.e., your variable \"Segments\") at all.\n  4. Apr 3, 2007 #3\n    You process long double values. You should use %lf instead of just %f in scanf and printf. If your system uses different sizes for these types then scanf will store your input using the format you indicate, which is not the format you are actually using. Your program behavior will be undefined.\n  5. Apr 4, 2007 #4\n    DH, why should my loop condition should have included the variable 'Segments' ?\n  6. Apr 4, 2007 #5\n    thanks out of whack, didnt know you should use %lf here.\n  7. Apr 4, 2007 #6\n\n    D H\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Both clauses are examples of \"bad programming\" techniques. The first clause, area<=84.515625, presumes an answer. Suppose you wanted to estimate the area under a curve to which you don't know the answer? The loop condition should be independent of the specific function to be integrated.\n\n    The second clause, initial<2, is a little better but still has some problems. A couple minor problems first: The comparand 2 should be 2.0, not 2. A variable would be even better. The big problem is that you might make an extra step because of the way real numbers are approximated on a computer. You can correct this by comparing initial to 2.0-epsilon, where epsilon is some small number.\n\n    An even better approach is to take advantage of the fact that you know exactly how many times the body of the loop should be executed: it is the number of Segments.\n\n    for (i=0; i<Segments; i++) { body; }\n\n    Additional comments:\n    \u2022 Segments should not be declared as a \"long double\". How would your program behave if the user specified 3.1415926536 Segments? The trapezoid method requires number of segments be a positive integer. What C data type comes closest to this?\n    \u2022 For that matter, why is anything declared as a \"long double\"? Doubles have about 15 decimal places of accuracy, which is far more than you need.\n    \u2022 Why are you changing the value of \"initial\"? (The variable name disagrees with its use.)\n    \u2022 You are generating the final report inside the loop. Bad style, again. This should be done outside the loop, and the report should be generated for all cases. (You do want to know that some choices are bad choices, don't you?)\n\n    Some pseudocode:\n\n    unsigned int n_segments, iseg;\n    double x_init, x_end, x, dx;\n\n    // Get integration limits (x_init, x_end) and number of steps (n_segments).\n\n    dx = (x_init-x_end)/n_segments;\n    area = 0.0;\n    for (iseg = 0; iseg < n_segments; iseg++) {\n    // Calculate start of the iseg interval.\n    // Estimate area contribution from this segment.\n    // Generate report.\n  8. Apr 4, 2007 #7\n\n    D H\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    For scanf, long doubles should be scanned using %Lf, not %lf.\n\n    The format \"%f\" for printf, is correct. %lf is non-standard (undefined behavior), although most systems interpret \"%lf\" as \"the stupid user meant %f\". Printf is a varargs funtion, so all arguments are converted according to ancient C function-call rules: arguments are passed as ints, doubles, or pointers. In particular, a long double (or a float) is converted to a double in the call to printf.\n  9. Apr 4, 2007 #8\n    My mistake: it is indeed %Lf for long double and not %lf. And %Lf is standard for printf as well, as specified in ISO/IEC 9899 (I've just double checked).\n  10. Apr 4, 2007 #9\n\n    D H\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    %Lf can be used but does not have to be used for long doubles passed to printf. Check your standards again, this time looking for how default argument promotions works with the arguments corresponding to the ellipsis in variable argument functions. A long double is converted to a double at the function call. The %Lf format will work whether you call printf with a float, double, or long double value because what is actually passed is a double.\n  11. Apr 4, 2007 #10\n    No need to check the standard again. :rolleyes: It really does say what I said: %Lf is also useable with printf. Its behavior is defined. The standard also says plenty of other things, you've mentioned some of them.\n\n    One benefit of supporting %Lf in both scanf and printf is to let the programmer use a single format string for both input and output, which is handy at times.\n  12. Apr 4, 2007 #11\n\n    D H\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, the standard says what you said: %Lf can be used with printf. Isn't that exactly what I said? Where I disagree with you is your prior post where you implied %Lf must be used when you pass a long double to printf. You are not really passing a long double to printf, you are passing a plain old vanilla double thanks to C's default argument promotion rules.\n  13. Apr 4, 2007 #12\n    Sorry, I thought you were replying to the post above yours, not the one you had previously replied to. Of course, I agree that even though %Lf is legal syntax in printf, it is not the only valid option. I find that the same data types call for the same specifiers for consistency and self documentation, but this is a personal preference. Your own preference may differ. I think we all got it straight now.\n\nHave something to add?\n\nSimilar Discussions: Spot the error in my code. (in C).\n  1. Critique my C++ code (Replies: 11)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/trigonometric-substitution.264934/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nTrigonometric substitution\n\n  1. Oct 16, 2008 #1\n    Hello, I have been wokring on this problem for some hours now, and I get the wrong answer, but I can't understand why, could you guys please look at it?\n  2. jcsd\n  3. Oct 16, 2008 #2\n    I should probably mention that the answer is supposed to be:\n\n    2*arctan(2x)+4x/(4x^2+1) +C\n  4. Oct 16, 2008 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    I didn't go through that in detail but it looks like a very strange way to attack the problem! You have a square of a square and you write it as a fourth power of a square root of a square so you can apply a trig substitution!\n    You don't need the square root to apply a trig substitution. Let 2x= tan t and 4x2+ 1= tan2 t+ 1= sec2. (4x2+ 1)2= sec4 t and 2dx= sec2 t dt. Your integral becomes\n    [tex]\\int\\frac{8dx}{(4x^2+ 1)^2}= \\int \\frac{4dt}{sec^2 t}= 4\\int cos^2 t dt[/itex]\n    That should be easy.\n\nHave something to add?\n\nSimilar Discussions: Trigonometric substitution"}
{"text": "Retrieved from http://math.stackexchange.com/questions/370862/find-a-best-fit-line-through-a-point-cloud-that-goes-through-a-specific-point\nText:\nTake the 2-minute tour \u00d7\n\nI'm not a mathematician so I hope I ask this question properly; I apologize for anyone who is annoyed with how I ask it (I will try my best to be precise).\n\nSay I have a point cloud in $\\Re^3$. I wish to fit a line through to this point cloud. However - and this is the kicker - I wish to force the line through a specified point in the point cloud; that is, I wish to find a vector through a point I specify which minimizes the distance squared from all the points in the cloud to the line spanned by the vector. Does this make sense?\n\nIf I were explaining this to a non-mathematician (like me), I would say I want to \"anchor\" a line on one of the points and then best fit the line from there.\n\nI understand the notion of ordinary least squares, but this particular spin on the problem doesn't make sense to me.\n\nThanks in advance, Ben\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nThis notion makes sense. You still have two degrees of freedom for the line, which can be two angles we will call elevation $(E)$ and azimuth $(A)$. It is easiest if you move the origin to the anchor point by subtracting the coordinates of the anchor points from each of the points in the cloud. Then your line has parameterization $t(\\sin E \\cos A, \\sin E \\sin A, \\cos E)$ if you measure $E$ up from the $xy$ plane and $A$ counterclockwise from the $X$ axis. Now you can find the distances from each other point in the cloud to the line using this formula where the vector I gave is $\\bf n$, square them, and add them up. Now use a 2D function minimizer on $A,E$. Depending on the points, there may be local minima to fool you.\n\nshare|improve this answer\nThanks! I will try this out and post the results here for the sake of posterity. \u2013\u00a0 user74039 Apr 23 '13 at 22:52\nLike ordinary least squares, there are no \"local\" minima distinct from the global minimum (though in degenerate cases the location of the global minimum may not be unique). Differentiating the sum of squares \"errors\" with respective to the unknown parameters gives a (homogeneous) linear system to solve. \u2013\u00a0 hardmath Apr 26 '13 at 0:27\nadd comment\n\nRoss Millikan's solution will work. To get the exact answer, probably faster, you can modify a solution for finding the 3D line of best fit (without an anchor point). The way that works is you compute the covariance matrix of the point cloud and the line of best fit is the line through the centroid in the direction of the eigenvector associated with the largest eigenvalue.\n\nTo modify this solution for the current problem, you can do the same thing, only when you're computing the covariance matrix, you subtract the anchor point from each point in the point cloud, rather than subtracting the centroid.\n\nshare|improve this answer\nadd comment\n\nThe least squares fit of a line/plane/etc. with an additional constraint of passing through a specified point is usually reduced to the case where that point is the origin (subtract the specified point from all data and fit a linear homogenous function). In this connection such model fitting is called \"regression through the origin\" (RTO) to quickly distinguish it from ordinary least squares (OLS).\n\nSome references and discussions are given in Answers to this previous Question.\n\nNote that the number of parameters for a line and a plane surface in 3D are equal, but there is a difference in what the nearest distance to the line or the plane is. Passing through the origin makes the fitted model a subspace, so the nearest distance is given by (subtracting) the orthogonal projection of each data point onto the subspace.\n\nLike ordinary least squares one gets a system of linear equations to solve for the unknown parameters, but the system is homogeneous. One is therefore solving for a nontrivial solution to a problem like $Au = 0$, and since there are only three unknowns speed of solution is not an issue.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/309879/showing-representation-numbers-are-at-most-on-the-order-of-polynomial-growth/311972\nText:\nTake the 2-minute tour \u00d7\n\nIf $Q$ is the sum of squares quadratic form $\\sum_1^n x_i^2$ over some lattice, then $r_Q(m)$, the number of representations of an integer $m$ by $Q$ (order/sign matter) is sometimes given in a nice formula, as in the case with Jacobi's formula in the case of $n=4$. Can we say something moderate about how $r_Q$ grows? It seems like it shouldn't grow faster than polynomially, but I am struggling to see why in a rigorous way. Since $\\sum_1^n x_i^2=m$ is the equation of a sphere (or I suppose an ellipsoid if we transform our lattice to $Z^n$ under a change of variable?), we should be able to bound such solutions by some function of the surface area since there should be some small upper bound for the proportion of lattice points over the surface area and the surface area is a polynomial function of the radius.\n\nI would like to make the argument a bit more rigorous, any advice?\n\nEdit: To be clear, I'm interested in how $r_Q(m)$ grows with $m$.\n\nshare|improve this question\nAre you interested in how $r_Q$ grows with $r$ or with $Q$? \u2013\u00a0 Ross Millikan Feb 21 '13 at 5:22\n$r_Q$ is a function. I'm interested in how it grows with $n$. \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:25\nOK, I was thinking of it as a function of $r$ or $Q$, but a function of $n$ is a fine question. It will top out at $n=Q$ unless you count different orders as different. Do you? \u2013\u00a0 Ross Millikan Feb 21 '13 at 5:31\nI should have written \"grows with $m$\", rather than $n$ (assume $n$ is fixed, fixed by $Q$ in fact).Different orders are the same, though signs matter. \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:34\nSorry, scratch that. Order DOES matter. The point is that we are looking at the distinct number of points on a lattice that map to $m$ under $r_Q$. \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:46\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nFor each solution to $\\sum_{i=1}^n x_i^2 = m$, you can place an open cube of side-length $1$ centered on that solution. Doing so, you obtain a family of disjoint open cubes covering the solutions, with each open cube having volume $1$. So your next move should be to bound the volume that you can possibly cover with those cubes, polynomially in $m$.\n\nSince every cube centered on $x$ is included in the open ball of radius $\\sqrt n/2$ centered on $x$ (using the euclidean metric), and $d(0,x) = \\sqrt m$ whenever $x$ is a representation of $m$, you obtain with the triangular inequality that all those cubes are included in $\\{y \\in \\Bbb R^n, \\sqrt m - \\sqrt n/2 < d(0,y) < \\sqrt m + \\sqrt n/2 \\} = B(0,\\sqrt m + \\sqrt n/2) - B(0,\\sqrt m - \\sqrt n/2)$\n\nSince the volume of a ball of radius $R$ is $k_nR^n$ for some constant $k_n$, you get that the volume of this domain is $k_n((\\sqrt m + \\sqrt n/2)^n - (\\sqrt m - \\sqrt n/2)^n) \\sim k_n(n^{3/2}m^{(n-1)/2}) $ (you can also argue intuitively that this should behave like $\\sqrt n$ times the area of the sphere of radius $\\sqrt m$, and again find a volume bounded by a $K_n m^{(n-1)/2}$).\n\nSince the number of representations of $m$ is bounded by the volume of this domain, and since this volume is a $O(m^{(n-1)/2})$, that number $r_n(m)$ grows polynomially at worst.\n\nYou can also use this reasoning with volumes to show that the degree $(m-1)/2$ is the smallest possible for this kind of result : if it wasn't, then putting cubes around every solution of $\\sum x_i < R^2$ would tell you that the volume of the sphere of radius $R$ would grow smaller than $R^n$, which is absurd.\n\nshare|improve this answer\nadd comment\n\nIf order and signs matter, I strongly suspect that for large $n$ it will be dominated by sums of $\\pm 1$ and $0$. We have to select $Q$ spots for a non-zero and $2^Q$ signs, so we have ${n \\choose Q}2^Q$ expressions. There will be a few more with summands greater than $1$, but for large $n$ they will be insignificant. This is exponential in $n$ and $Q$.\n\nshare|improve this answer\nSo you don't like my ellipsoid argument? \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:58\n@EricGregor: not if some of the $x_i$ can be zero. If not, when $n \\gt Q$there are no representations. That is a small growth rate. \u2013\u00a0 Ross Millikan Feb 21 '13 at 6:00\nRoss, I think the interest is in fixing $n$ and asking about large $m$. \u2013\u00a0 Gerry Myerson Feb 21 '13 at 6:03\n@GerryMyerson: for fixed $n$ and large $m$ the surface area argument is a good one. There can't be more than $O(m^2)$ lattice points on the ellipsoid. Most of them won't have a representation with exactly $n$ terms. A few will have more than one, like $25^2=7^2+24^2=15^2+20^2$ but it seems likely not enough to matter. \u2013\u00a0 Ross Millikan Feb 21 '13 at 6:11\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/54723/commutator-formulas-in-a-universal-enveloping-algebra\nText:\nTake the 2-minute tour \u00d7\n\nI am interested in finding formulas for commutators of symmetrized monomials in a universal enveloping algebra. Let $C(x_1,\\ldots, x_n)= (1/n!)\\sum x_{\\sigma(1)}\\cdots x_{\\sigma(n)}$ where the sum runs over all permutations, and $x_i \\in L$ for some LIe algebra $L$. This is an element of $UL$.\n\nNow, reasonable combinatorics shows that, in $UL$, we have,\n\n$ [C(x_1,\\ldots, x_n), l] = \\sum_{i=1}^n C(\\ldots,[x_i,l],\\ldots) $\n\nfor $l\\in L$.\n\nI am looking for formulas for $[C(x_1,\\ldots, x_n), C(y_1,\\ldots, y_m)]$ in terms of symmetrized monomials and brackets. Even for $n=m=2$ the number of terms gets fairly large. If anyone knows where I can find such things I would be very grateful.\n\nshare|improve this question\nWhat is exact formulas for the case $n=m=2$? \u2013\u00a0 Melania Feb 8 '11 at 6:54\nPresumably you are working over an arbitrary field of characteristic 0 here. As Melania comments, one should try to answer the question first for products of length 2. Anyway I can't visualize an illuminating general answer, since the symmetrization process already depends so heavily on the specific nature of the bracket in the Lie algebra. Maybe in very special cases a good formula could be written down? \u2013\u00a0 Jim Humphreys Feb 8 '11 at 14:09\nadd comment\n\n1 Answer\n\nThis is probably not yet a final answer but may shine some additional light on the problem: For simplicity, I assume that $L$ is finite-dimensional and defined over the reals (for some other field of char $0$, the following should still work).\n\nThe symmetrization map can be viewed as a linear map \\begin{equation} \\sigma\\colon \\mathrm{S}(L) \\longrightarrow \\mathrm{U}(L) \\end{equation} from the symmetric algebra over $L$ into the universal envelopping algebra. It is now possible (essentially via PBW) to show that this is a fitration compatible linear bijection. Thus it allows to pull-back the product of $\\mathrm{U}(L)$ to $\\mathrm{S}(L)$. The result is the star product of Gutt / Drinfel'd (both in 1983, I guess). A further canonical isomorphism yields that the symmetric algebra is nothing else than the poylnomials on the dual $L^*$ (suppose $L$ is finite-dimensional for convenience) Thus your question is equivalent to the following task:\n\nWhat is the Gutt star product commutator of two (homogeneous) polynomials on $L^*$?\n\nGutt has computed many properties of this star product and fan almost explicit formula. However, it essentially involved the full BCH series of $L$, so my guess is that a complete answer might be as complicated as computing BCH.\n\nThe Gutt star product can be characterized nicely as follows: take $x, y \\in L$ and view them as linear polynomials on $L^*$ as usual. Then form the formal exponential functions $e_{\\hbar x} (\\alpha) = \\exp(\\hbar \\alpha(x))$ and similarly for $e_{\\hbar y}$ where $\\hbar$ is your formal parameter. Then $\\star_{\\mathrm{Gutt}}$ is uniquely determined by \\begin{equation} e_{\\hbar x} \\star_{\\mathrm{Gutt}} e_{\\hbar y} = e_{\\mathrm{BHC}(\\hbar x, \\hbar y)} \\end{equation} I hope I got the signs right :) You can find this formulas also in Section 8 of q-alg/9707030 (published in Commun. Math. Phys.). There are many more papers on the Gutt star product, so a little MRsearch will probably give some addition info.\n\nThe solution of your problem is now obtained by differentiating the above equation with respect to $\\hbar$ sufficiently often and use polarization afterwarts. But as I sad, you need to know BCH quite well to efficiently do that. In the end you take commutators\\ldots\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/80905/pole-on-radius-of-convergence-no-absolute-convergence-on-that-circle?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI am confronted with the following problem:\n\nThe radius of convergence of a function $f(z)=\\sum c_n(z-z_0)^n$ is $R$, and the function has a pole at some $w_0$, with $|w_0-z_0|=R$. Why does, for any other $w$ on the circle with radius $R$, the series not converge absolutely?\n\nI tried to use the MVT, but that does not work out. Can anyone give me a sketch of the proof?\n\n\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nBy assumption $\\sum c_n(w_0-z_0)^n$ divergent. This implies that $\\sum |c_n||w_0-z_0|^n=\\sum |c_n|R^n$ is also divergent.\n\nChoose any other $w$ such that $|w-z_0|=R$. Then we have $\\sum|c_n||w-z_0|^n=\\sum |c_n|R^n$ which we already known diverge.\n\nshare|improve this answer\nCaution: it's not so obvious that $\\sum c_n (w_0 - z_0)^n$ diverges. You need Abel's theorem, I think \u2013\u00a0 Robert Israel Nov 11 '11 at 0:31\nadd comment\n\nIf the series converges absolutely, $|f(z)| \\le \\sum_{n=0}^\\infty |c_n| R^n$ on $\\{z: |z - z_0| < R\\}$. But if $w_0$ is a pole, $|f(z)| \\to \\infty$ as $z \\to w_0$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/14321/how-do-i-numerically-solve-a-custom-function?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWhenever I use functions like FindRoot or NDSolve, it sends x through the function and deals with the result. That would be fine if I was sending a simple math function through, but I have something more like a short program. Is there any way to make it solve it by putting specific values through the function and looking at the results?\n\nshare|improve this question\nYou can give a program as a function to FindRoot. Just be sure to restric the arguments to numerical values, e.g. programF[x_?NumberQ] := ...; FindRoot[programF[x]==0,{x,1}]. \u2013\u00a0 Daniel Lichtblau Nov 8 '12 at 22:41\nWhat do I do about passing arrays? \u2013\u00a0 DanielLC Nov 9 '12 at 0:56\nThat's a bit vague. Could you maybe talk about your actual problem, so we can be more helpful? \u2013\u00a0 \uff2a. \uff2d. Nov 9 '12 at 2:17\nTo pass array try programF[x_?(ArrayQ[#, _, NumericQ] &)] := ...; \u2013\u00a0 PlatoManiac Nov 9 '12 at 2:18\n@Plato, like x_ /; ArrayQ[x, _, MatchQ[#, 0 | 1] &] then? \u2013\u00a0 \uff2a. \uff2d. Nov 9 '12 at 8:33\nshow 4 more comments\n\n1 Answer\n\nup vote 2 down vote accepted\n\nI will give you a simple but realistic example. Imagine you are given two $d$-dimensional vectors $X$ and $B$. Now you are asked to find a matrix say $A$ such that $AX=B.$ How can we use Mathematica to solve this problem?\n\nPrepare the two vectors X and B\n\nd = 6;\nX = RandomInteger[{1, 100}, d];\nB = RandomReal[{200, 400}, d];\n\nNow is time to define a function that takes a numerical $d\\times d$-dimensional array $A$ as input and computes the norm $|A X-B|.$\n\nObj[A_?(ArrayQ[#, _, NumericQ] &)] := (A. X - B) // Norm;\n\nAt this point one would try to minimize the above function in order to get the matrix $A$ such that $AX=B$ holds approximately. We use the FindMinimum function with a derivative free method option.\n\nFindMinimum[Obj[A], {A, RandomReal[{1, 25}, {d, d}]},\nMethod -> \"PrincipalAxis\", AccuracyGoal -> 12, PrecisionGoal -> 60,\nMaxIterations -> 1000] // Short\n\n\nSimilar things can be done for functions like FindRoot or NDSolve. Hope this helps.\n\n\nshare|improve this answer\nThis works, but when I tried to modify it to use a real number (replacing (ArrayQ[#, _, NumericQ] &) with NumberQ) or even a one dimensional array (I just changed the program so it uses one dimensional arrays and set the initial point to one) it started sending variables through again. Also, taking out the ?(ArrayQ[#, _, NumericQ] &) part also resulted in that. Am I modifying it wrong? I need to run these sorts of functions with a real number and a one dimensional array. \u2013\u00a0 DanielLC Nov 12 '12 at 23:44\nNever mind. It seems to work fine now. \u2013\u00a0 DanielLC Nov 14 '12 at 23:17\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/1660/direct-proof-of-gelfand-zetlin-identity/2823\nText:\nTake the 2-minute tour \u00d7\n\nDenote by $D(a_1,\\dots,a_n)$ the product $\\prod_{j>i}(a_j-a_i)$. Assuming that $a_i$ are integers s.t. $a_1\\le a_2\\le\\dots\\le a_n$, proove that $D(a_1,...,a_n)/D(1,...,n)$ is the number of Gelfand-Zetlin triangles (that is, triangles consisting of $\\frac{n(n+1)}2$ integers, s.t. each number is greater it's lower-left neighbor but not greater than lower-right neighbor) with the base $a_i$.\n\nFor example, for n=3 one needs to prove that number of b1, b2, b' s.t. $a_1\\le b_1<a_2\\le b_2<a_3$, $b_1\\le b'<b_2$ is exactly $\\frac{(a_3-a_2)(a_3-a_1)(a_2-a_1)}{3}$.\n\nAs one can guess from the name \u201cGelfand-Zetlin\u201d, this fact is well-known in representation theory (namely, in LHS we count dimension of a $gl_n$-representation by Weyl formula, and in RHS we count elements in Gelfand-Zetlin basis of the same representation). But maybe someone can come with more or less direct proof? (Some kind of bijective proof, maybe.)\n\nInformal probabilistic argument\n\nFor simplicity, consider the case $n=3$: D(a_1,a_2,a_3) counts the number of triangles s.t. $a_1\\le b_1<a_2\\le b_2<a_3$, $a_1\\le b'<a_3$ \u2014 and we're interested only in G-Z triangles, i.e. in triangles s.t. $b_1\\le b'< b_2$. Now, mathematical expectation of the length of the interval $(b_1,b_2)$ is exactly one half of the length of the interval from which $b'$ is chosen. So one may expect that the probability that random triangle is G-Z is $1/2$ \u2014 and the answer is indeed $D(a_1,a_2,a_3)/D(1,2,3)$.\n\n(The main problem with this computation is that we're multiplying probabilities for events that are clearly not independent. And although for n=3 it's not hard to transform this heuristic argument into a formal proof, even for n=4 I failed to do such thing.)\n\nshare|improve this question\nThere is a beautiful identity I learned from Gjergji Zaimi (artofproblemsolving.com/Forum/viewtopic.php?f=590&t=290405) which is probably relevant here, but I haven't thought about how to complete the argument; I am guessing an inclusion-exclusion argument, possibly using the Lindstrom-Gessel-Viennot lemma. \u2013\u00a0 Qiaochu Yuan Aug 5 '10 at 22:06\nadd comment\n\n3 Answers\n\nup vote 3 down vote accepted\n\nAs Qiaochu points out the formula given by Gjergji Zaimi is certainly relevant. It realizes $D(a_1,\\ldots,a_n)/D(1,\\ldots,n)$ as the determinant of the $n$-by-$n$ matrix $M$ with $(i,j)$-entry $${a_i\\choose j-1}.$$ By row operations this equals the determinant of the $(n-1)$-by-$(n-1)$ matrix $N$ with $(i,j)$-entry $${a_{i+1}\\choose j}-{a_i\\choose j}.$$ The $i$-th row of $n$ is the sum of vectors $v_{a_i},v_{a_i+1},\\ldots,v_{a_{i+1}-1}$ where the $j$-th entry of $v_c$ is $${c\\choose j-1}.$$ By the multilinearity of the determinant as a function of its rows, $N$ is the sum the determinants with rows $v_{b_1},\\ldots,v_{b_{n-1}}$ where $a_1\\le b_i < a_2\\le b_2 < a_3\\le\\cdots$. These tuples $(b_1,\\ldots,b_{n-1})$ are precisely the admissible penultimate rows in GZ triangles with bottom row $(a_1,\\ldots,a_n)$. Hence both sides of the sought equality satisfy the same recurrence.\n\nshare|improve this answer\nCombinatorial interpretation (from a friend of mine): the determinant = the number of non-intersecting paths from points $0,1,\\dots,n-1$ on Y-axis to points $a_1,\\dots,a_n$ on X-axis = number of Gelfand-Zetlin triangles. \u2013\u00a0 Grigory M Aug 6 '10 at 15:06\nSee also: I. Gessel. Binomial determinants, paths, and hook length formulae in Adv. Math. (from non-intersecting paths to binomial determinant and computation of binomial determinant). \u2013\u00a0 Grigory M Aug 21 '12 at 17:42\nadd comment\n\nSchur polynomials proof\n\nObserve that $D(a_1,\\ldots,a_n)/D(1,\\ldots,n)=s_\\lambda(1,\\ldots,1)$ (for $a_i=\\lambda_i+i$). But by Giambelli (aka Jacobi-Trudi) formula $s_\\lambda=\\det h_{\\lambda_i+j-1}$, so $s_\\lambda(1,\\ldots,1)=\\det\\binom{a_i}{j-1}$. Now by Lindstrom-Gessel-Viennot lemma last determinant counts non-intersecting lattice paths from the set $0,1,\\ldots,n$ on Y-axis to the set $a_1,\\ldots,a_n$ on X-axis. Finally, observe that any such path is characterized by x-coordinates of \"steps down\" \u2014 which are subject to conditions from the definition of GZ triangle.\n\n/* Well, it's not that direct and it's more or less the proof from Robin Chapman's answer. Nevertheless, it explains something, I hope. */\n\nshare|improve this answer\nadd comment\n\nJust to make sure: you know that what you are asking for is actually Weyl's dimension formula for the highest weight representation in the case of SL(n,C) resp. SU(n)? I suppose there is no direct combinatorial proof that does not make use of this fact.\n\nshare|improve this answer\nWhy not? Many similar results about e.g. Young tableaux have purely combinatorial proofs. \u2013\u00a0 Qiaochu Yuan Aug 5 '10 at 22:31\nYes, LHS is the Weyl dimension formula for a representation of gl_n, and RHS is the number of elements in Gelfand-Zetlin basis in the same representation. \u2013\u00a0 Grigory M Aug 6 '10 at 7:47\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/26771/what-is-the-expected-number-of-steps-in-the-following-process\nText:\nTake the 2-minute tour \u00d7\n\nWe have $n$ boxes. And initially there are $x_1, x_2, x_3, \\ldots, x_n$ marbles in each box. We randomly (with equal probabilities) select one of the boxes. We take one marble from it and we put it into another (different from the origin) box chosen randomly (with equal probabilities). We continue this process until one of the boxes become empty. How many operations we do on average?\n\nIt is not a homework. I don't know whether a closed form solution exists. My current results are:\n\n\\begin{align}{} x_1 x_2 & \\text{ for } n=2\\\\ \\frac{3x_1 x_2 x_3}{x_1 + x_2 + x_3} & \\text{ for } n=3 \\end{align}\n\nI have crossposted in artofproblemsolving. This problem is related and maybe (or not) useful.\n\nUpdate2: As i learned: this problem has been studied before. As usual :) It seems very hard even for $n=4$. No explicit solution is known, only asymptotics for the case $f(x,x,x,x)$. Nevertheless the solution is much much more easier if we change slightly the problem. For example.\n\nBig thanks to Viktor for pointing the reference!\n\nshare|improve this question\nLooking at what you have for $n=2$ and $n=3$, my guess would be $\\frac{\\binom{n}{2}}{\\displaystyle \\sum_{i,j,i \\neq j}\\frac{1}{x_i x_j}}$ \u2013\u00a0 user17762 Mar 13 '11 at 20:33\nIt's beautiful but it seems that it does not pass the following test for $n=4$: $f(x,x,x,x)=f(x-1,x+1,x,x)+1$. \u2013\u00a0 Roah Mar 13 '11 at 21:21\n@Tomek The case $n=2$ is the usual one dimensional gambler's ruin problem. It is true, but not intuitively obvious, that for a symmetric random walk the expected number of steps needed to hit 0 is infinite, even starting at 1. Unless we hit 0 very soon, the random walk wanders far into the positives and then takes a long (but finite!) number of steps to reach 0. \u2013\u00a0 Byron Schmuland Mar 15 '11 at 0:22\nThat is N-player ruin problem. See: Y.Swan - A Matrix-Analytic Approach to the N-Player Ruin Problem \u2013\u00a0 Viktor Mar 15 '11 at 23:23\nThere is a paper arguing for why this is unlikely to have any closed form solution for N>3. projecteuclid.org/\u2026 \u2013\u00a0 user1708 Mar 18 '11 at 7:42\n\n1 Answer 1\n\nHere are some results for very small numbers, when there are $n$ variables: $$ \\begin{align*} f(1,1,1,\\ldots,1) &= 1, \\\\ f(2,1,1,\\ldots,1) &= \\frac{n}{n-1}, \\\\ f(3,1,1,\\ldots,1) &= \\frac{n^3-2n^2+3n}{n^3-3n^2+4n-2} = \\frac{n}{n-1} \\cdot \\frac{n^2-2n+3}{n^2-2n+2}, \\\\ f(2,2,1,\\ldots,1) &= \\frac{n^3-n^2+2n}{n^3-3n^2+4n-2} = \\frac{n}{n-1} \\cdot \\frac{n^2-n+2}{n^2-2n+2}. \\end{align*} $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/235297/countable-base-topology\nText:\nTake the 2-minute tour \u00d7\n\nCan you please help me to prove that if a space has a countable base, then it has countable dense subset?\n\nI know this happens in the real line, i.e.: it has a countable base as $\\{(a,b):a,b \\in\\Bbb Q\\}$ and $\\Bbb Q$ is dense in $\\Bbb R$.\n\nBut how can I generalize this result as mentioned in the problem?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nWe (commonly) say a topological space that has a countable base is second countable. And we also (commonly) say a topological space that has a countable dense subset to be separable.\n\nHere, we would like to show that a topological space $(X,\\tau)$ that is second countable implies it is separable.\n\nLet ${\\scr B}=\\{B_n\\}_{n\\in{\\bf N}} $ be a countable base for $X$. We need a candidate set that could possibly be a countable dense subset of $X$. Since we only have information about ${\\scr B}$ is countable, we use it to construct a set.\n\nSuppose without loss that every base set in the collection $\\scr B$ is not empty. Now, for each $B_n\\in {\\scr B}$, pick any element $x_n\\in B_n$. This is possible since each $B_n$ is not empty. (And this infinitary choice is possible by Axiom of Choice.)\n\nWrite $D=\\{x_n\\}_{n\\in{\\bf N}}$, the collection of $x_n$ we just constructed. This set $D$ is our candidate set that is (i) countable, and (ii) dense in $X$.\n\nWe know $D$ is countable because we picked an $x_n$ for each $B_n$ from $\\scr B$, that is, $D$ is bijective to our countable base $\\scr B$. Hence $D$ is (i) countable.\n\nNow we would like to show $D$ is dense in $X$. Recall the definition of a dense set $E$: We say $E$ is dense in $X$ if every nonempty open set $U$ of $X$ intersects $E$.\n\nNow, also recall a property of a base $\\scr B$: If $\\scr B$ is a base then for every open set $U$ of $X$, and each point $x\\in U$, there exists $B\\in{\\scr B}$ such that $x\\in B\\subset U$.\n\nTry to show (ii) by using the definition of denseness and definition of a base.\n\nHint: To show (ii), take any nonempty open set $U$ of $X$. We need to show $U$ intersects our set $D$. Note for any $x\\in U$, there exists a base $B_k$ such that $x\\in B_k\\subset U$. But $B_k$ contains $x_k\\in D$. We have claimed.\n\nshare|improve this answer\n\nPick one point from every member of the countable base.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/112116/normal-subgroup-of-prime-order-is-characteristic/112129\nText:\nTake the 2-minute tour \u00d7\n\nI'm stuck on this exercise from Herstein's topics in algebra:\n\nSuppose that $G$ is a group and $|G| = pm$, where $p \\not| ~ m$ and $p$ is a prime. If $H$ is a normal subgroup of order $p$ in $G$, prove that $H$ is characteristic.\n\nHow to prove that? What we know:\n\n  \u2022 $H$ and $\\varphi(H)$ have prime order $p$, so they must be cyclic and abelian\n  \u2022 They are both normal subgroups of $G$\n\nhow to show that, in fact, we have $H = \\varphi(H)$ for every automorphism $\\varphi$ ?\n\nshare|improve this question\nDo you know about Sylow subgroups yet? Subgroups of order $p$ are Sylow $p$-subgroups in $G$, so $\\varphi(H)$ must be conjugate to $H$. But $H$ is normal, so... \u2013\u00a0 Arturo Magidin Feb 22 '12 at 18:32\nHi, the question is quite early in the book and the few things I know are: Definitions and Examples of Groups \\ Subgroups \\ Lagrange's Theorem \\ Homomorphisms and Normal Subgroups. I understand that it might be difficult to prove that using only basic facts.. Herstein seems to love this kind of question \u2013\u00a0 Haile Feb 22 '12 at 18:40\nWell, $G/H$ is a group of order $m.$ Use this to prove that $H$ is the only subgroup of $G$ which has order $p.$ \u2013\u00a0 Geoff Robinson Feb 22 '12 at 18:52\n\n1 Answer 1\n\nup vote 10 down vote accepted\n\nDefine $K = \\varphi(H)$. Since $H$ is normal and $K$ is a subgroup, $HK$ is also a subgroup with order\n\n\\begin{align*}|HK| = \\frac{|H||K|}{|H \\cap K|}\\end{align*}\n\nBoth subgroups have prime order $p$, so their intersection $H \\cap K$ is trivial or of order $p$. If the intersection is trivial, then $HK$ is a subgroup of order $p^2$. This is not possible, since $p^2$ does not divide $|G|$. Thus $H \\cap K$ has order $p$ and therefore $H = H \\cap K =K$.\n\nshare|improve this answer\nClear! Thank you. \u2013\u00a0 Haile Feb 22 '12 at 19:36\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/18613/handling-error-in-database-connection-timeconstrained?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI have a lot of scripts that use a database connection, and I have realized that my code should be protected against errors in my connection. For example, when my database is out for some technical reason.\n\nI tried to use this in a fake broke connection:\n\nsqlConn:=OpenSQLConnection[JDBC[\"Microsoft SQL Server(jTDS)\",\"\"],\"Username\"->\"myUser\",\"Password\"->\"myPass\"];\n(conn = TimeConstrained[sqlConn, 1]) // AbsoluteTiming\n\nBut without success as you can see. The 1 second argument is not respected. I get this:\n\n\"JDBC::error: Network error IOException: Operation timed out >>\"\n{76.518145, $Aborted}\n\nWolfram technical support asked me to try changing $SQLTimeout, but that did not work either.\n\nI tried before the last code:\n\n\nand the time restriction is also not respected.\n\nThey then told me:\n\n\"Most of the timeout functions in Mathematica takes into account only the CPU time spent inside the main Mathematica kernel process; it does not include additional threads or processes. And the time OpenSQLConnection spend is mostly on it's own thread.\"\n\nSome clue on how to deal with this?\n\nshare|improve this question\nWhat about throwing in a mention of TimeConstrained in the question title? \u2013\u00a0 Yves Klett Jan 28 '13 at 13:11\nAFAIK the $SQLTimeout variable is there exactly for that purpose. Can you explain what you have tried and why you think it does not work? \u2013\u00a0 Albert Retey Jan 28 '13 at 13:46\n@AlbertRetey Hi. Tks, I have made some changes to make it clearer in this topic. \u2013\u00a0 Murta Jan 28 '13 at 14:31\n@YvesKlett tks. Done! \u2013\u00a0 Murta Jan 28 '13 at 14:33\ndocumentation of $SQLTimeout is vague, but could be understand as if $SQLTimeout doesn't work for initiating the connection but only for queries. Have you tried that? Maybe this question is also of interest. As mentioned there you might need to change some settings for the network connection on the client or for the connection settings on the sql server. Another possibility would be to build something with the v9 asynchronouse tasks, but I haven't tried that... \u2013\u00a0 Albert Retey Jan 28 '13 at 15:00\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nI was able to reproduce your behaviour on Mathematica V9 64-bit under Windows 7. Neither TimeConstrained nor $SQLTimeout would work. However, an explicit \"Timeout\" option worked for me:\n\n, \"Username\" -> \"myUser\"\n, \"Password\" -> \"myPass\"\n, \"Timeout\" -> 1\n\nThe evaluation stopped with the message JDBC::error: Login timed out. after one second. Interestingly, this expression apparently made a persistent change to the DatabaseLink state because thereafter any attempt to open the database would time out after one second -- even if I did not specify the \"Timeout\" option! If I subsequently tried a longer explicit timeout setting, that longer value would then \"stick\" and be applied to all future connection attempts. It would seem that we are looking at a bug here. I cannot say that I am surprised however. The handling of timeouts and early cancellation of SQL transactions is notoriously unreliable in many, if not most, SQL software stacks. In our context here, we are doubly removed from SQL Server by both JDBC and DatabaseLink.\n\nIncidentally, it also does not surprise me that TimeConstrained fails here. In practice, I find that TimeConstrained sometimes has difficulty interrupting a process that engages in a blocking I/O operation (and the front-end does too).\n\n\nFurther investigation reveals that DatabaseLink is using the Java class java.sql.DriverManager to allocate non-pooled SQL connections. Furthermore, it is setting the loginTimeout property of this class in a persistent fashion. Therefore, we can adjust that property ourselves without actually attempting to open a connection thus:\n\n\n\nWe can query the current setting like this:\n\n\nThe same investigation also revealed that OpenSQLConnection only uses the $SQLTimeout global variable if we pass an invalid value for the \"Timeout\" option:\n\nBlock[{$SQLTimeout = 1}\n, OpenSQLConnection[\n    , \"Username\" -> \"myUser\"\n    , \"Password\" -> \"myPass\"\n    , \"Timeout\" -> \"invalid\"\n\nWe are even informed that the default will be used:\n\nOpenSQLConnection::timeout: Illegal value for Timeout option: invalid (continuing with default value)\n\nAll this, and more, can be found if one studies the files found in:\n\nFileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"Links\", \"DatabaseLink\"}] //\nshare|improve this answer\nTks a lot, nice answer! You beat Wolfram Suport. +1. Do you know how can I set back this parameter without make a new call? What is the default value? This persistent state is really annoying. \u2013\u00a0 Murta Jan 28 '13 at 16:59\n@Murta Yes, we can reset the parameter without opening a new connection -- see my update. \u2013\u00a0 WReach Jan 28 '13 at 17:36\n@WReach Thank you for this quite descent investigative reverse engineering. Thank you! \u2013\u00a0 Stefan Jan 28 '13 at 17:53\n\nIn Mathematica V10, the jtds driver was updated to version 1.3.1.\n\nNow the command:\n\n    , \"Username\" -> \"myUser\"\n    , \"Password\" -> \"myPass\"\n    , \"Timeout\" -> 3\n\nWill respect the 3 seconds limit.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/25505/what-is-int-0-12-dx-dy-mathcalp-frac-logxx-y?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the value of $$\\int_{[0,1]^2} \\!\\!\\!dx\\,dy\\,\\mathcal{P} \\frac{\\log(x)}{x-y},$$ where $\\mathcal{P}$ denotes Cauchy's principal value. I solved this once for a homework, but I can neither remember the answer nor reproduce it right now... (bad memory)\n\nAny help or comment is highly welcome.\n\nshare|improve this question\nwhat do you mean by principal value? you have infinite values along $y=x$ and $\\{0\\}\\times[0,1]$. how are you approaching those? \u2013\u00a0 yoyo Mar 7 '11 at 17:16\nThe logarithmic singularity at ${0}\\times [0,1]$ seems to be integrable. So only the pole at $x=y$ poses problems. Cauchy's princial value (en.wikipedia.org/wiki/Cauchy_principal_value) denotes the limit when this singularity is approached symetrically... \u2013\u00a0 Fabian Mar 7 '11 at 17:32\nMathematica tells me that the result is $\\pi^2/6$ [looks like $\\zeta(2)$]. Any thoughts why (or if) this is correct? \u2013\u00a0 Fabian Mar 7 '11 at 17:34\nCan you not take the Hilbert transform of $1_{[0,1]}$ and then compute the (principal value) integral of $\\log(x)$ times the result of that? \u2013\u00a0 Jonas Teuwen Mar 7 '11 at 21:30\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $f(x,y)=\\frac{\\log x}{x-y}$. Since the principal value does not seem well-defined here, let's integrate $f(x,y)+f(y,x)= \\frac{\\log (x/y)}{x-y}$ (which is positive) on the triangle defined by $0<y<x<1$. Now $\\int_0^x \\frac{\\log (x/y)}{x-y} dy = -\\int_0^1 \\frac{\\log u}{1-u} du$ (change of variable $y=xu$), which does not depend on $x$, and so this is equal to the first integral (integrating for $x$ between $0$ and $1$).\n\nNow $-\\int_0^{1-\\epsilon} \\frac{\\log u}{1-u} du = \\int_0^{1-\\epsilon} \\sum_{ n \\geq 1} \\frac{u^{n-1}}{n} du = \\sum_{n \\geq 1} \\frac{(1-\\epsilon)^n}{n^2}$ and letting $\\epsilon$ go to $0$ gives $\\zeta(2)=\\frac{\\pi^2}{6}$.\n\nshare|improve this answer\nWhy you think the principal value is not well defined? \u2013\u00a0 Fabian Mar 9 '11 at 18:22\nThe examples at the end of the Wikipedia page illustrate this fact, for a given integral you can get different values if you choose your epsilons differently. But most of the time if you make \"reasonable\" choices the result is the same: for example in your case if we integrate on a closed symetric (with respect to the diagonal) domain not containing the diagonal and if this domain \"converges\" to the whole of $[0,1]^2$. If we integrate wrt $y$ first, excluding $[x-\\epsilon,x+\\epsilon]$ (then $\\epsilon \\rightarrow 0$) we still find $\\zeta(2)$. But other choices would give different values. \u2013\u00a0 Plop Mar 9 '11 at 19:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/16583/a-trigonometry-problem?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet x = pi/(2k+1), for k>0. Prove that\ncosxcos2xcos3x...coskx = (1/2)^k\n\nI've confirmed this numerically for n from 1 to 30. I'm finding it surprisingly difficult using standard trig formula manipulation. Even for the case k = 2, I needed to actually work out cosx by other methods to get the result.\n\nPlease let me know if you have a neat proof.\n\nshare|improve this question\nMaybe such puzzles are better posted in www.artofproblemsolving.com \u2013\u00a0 Gerald Edgar Feb 27 '10 at 11:53\n\n3 Answers 3\n\nup vote 13 down vote accepted\n\nLet $S(x)=\\prod_{j=1}^k \\text{sin}(jx)$ and $C(x)=\\prod_{j=1}^k \\text{cos}(jx)$. Let x = $\\frac{\\pi}{2k+1}$. Then $S(2x) = S(x)$ (from $\\text{sin}(\\pi-x)=\\text{sin}(x)$), and $S(2x)=2^kS(x)C(x)$ (from $\\text{sin}(2x)=2\\text{sin}(x)\\text{cos}(x)$), from which the result follows.\n\n\nshare|improve this answer\nThanks Steve. Very neat ! \u2013\u00a0 Cosmonut Feb 27 '10 at 12:03\n\nHint: multiply by sin(x)\n\nshare|improve this answer\n\nThe standard way of doing problems like these is to look at the coefficients of the Chebyshev polynomials. The polynomial $T_n$ of degree $n$ such that $T_n(2 \\cos \\theta) = 2 \\cos n \\theta$ has leading term $1$, and we want to compute something like the fourth root of the product of the roots of $T_{2k+1}(x)^2 = 4$. Vieta's formulas and some reflection identities should handle it from here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/93149/locally-lipschitz-implies-lipschitz-under-equivalent-metrics\nText:\nTake the 2-minute tour \u00d7\n\n\nFor $i=1,2$ let $X_i$ be a non-empty set and $d_i$ a metric $X_i^2 \\to \\mathbb{R}$. Suppose $f$ is a locally Lipschitz (*) function $(X_1, d_1) \\to (X_2, d_2)$.\n\nQuestion. Do there exist metrics $\\delta_1: X_1^2 \\to \\mathbb{R}$ and $\\delta_2: X_2^2 \\to \\mathbb{R}$ such that i) $\\delta_i$ is (topologically) equivalent to $d_i$ (for $i=1,2$) and ii) $f$ is a Lipschitz function $(X_1, \\delta_1) \\to (X_2, \\delta_2)$?\n\n(*) For each $x \\in X_1$, there exists a neighborhood $U_x$ of $x$ in $(X_1, d_1)$ such that the restriction of $f$ to $U_x$ is a Lipschitz function $(U_x, d_1) \\to (X_2, d_2)$.\n\nshare|improve this question\nThis question does not make sense to me. You can simply choose $\\delta_i = d_i$. Your heading seems to imply that you want to know whether $f$ will remain locally Lipschitz if the $d_i$ are replaced by arbitrary (topologically) equivalent metrics $\\delta_i$. While I don't know a counterexample, I doubt this is true, though, cause topological equivalence does not let you control the size of neighbourhoods in the metric sense. \u2013\u00a0 user20266 Dec 21 '11 at 11:11\n@Thomas: the OP wants to see if one can find a different metric generating the same topology such that the locally Lipschitz function is now globally Lipschitz. For example, let $f:\\mathbb{R} \\to \\mathbb{R}_{\\geq 0}$ be $x\\mapsto x^2$. This is locally but not globally Lipschitz. But if you take the diffeomorphism $\\mathbb{R}_{\\geq 0}\\mapsto\\mathbb{R}_{\\geq 0}$ given by $x\\mapsto \\sqrt{x}$, you pull back a Riemannian metric (and hence a distance function) w.r.t. which the map $f$ is now Lipschitz globally with Lipschitz constant 1. \u2013\u00a0 Willie Wong Dec 21 '11 at 11:32\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nYes \u2014 assuming that \u201c$d_1$ is topologically equivalent to $\\delta_1$\u201d means that $d_1$ and $\\delta_1$ induce the same topologies.\n\nIt is sufficient to require $f$ to be continuous, and only the metric on $X_1$ needs to be modified.\n\nPut $\\delta_1(x,y) = d_1(x,y) + d_2(f(x),f(y))$.\n\nThen $\\delta_1$ is a metric which is topologically equivalent to $d_1$: Indeed, since $d_1 \\leq \\delta_1$ we have that $x_n \\to x$ with respect to $\\delta_1$ implies $x_n \\to x$ with respect to $d_1$; conversely, continuity of $f$ ensures that $d_1$-convergence implies $\\delta_1$-convergence. Thus, both metrics describe the same closed sets on $X_1$, so they induce the same topologies.\n\nAs $d_2(f(x),f(y)) \\leq \\delta_1(x,y)$ we see that $f:(X_1,\\delta_1) \\to (X_2,d_2)$ is $1$-Lipschitz.\n\nshare|improve this answer\nIs the codomain $(X,\\delta_2)$ or $(X,d_2)$? \u2013\u00a0 Jesse Madnick Dec 21 '11 at 12:04\n@Jesse: the answer to your question is \"yes\". (t.b. set $d_2 = \\delta_2$.) \u2013\u00a0 Willie Wong Dec 21 '11 at 12:07\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-about-ellipse.62405/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestion about Ellipse\n\n  1. Feb 3, 2005 #1\n\n    Here is a problem in coordinate geometry, in particular about the ellipse.\n\n    A point moves such that the sum of the squares of its distances from two intersecting straight lines is constant. Prove that its locus is an ellipse and find the eccentricity in terms of the angle between the straight lines.\n\n    My solution:\n\n    Without loss of generality we may assume the two straight lines to be [itex]y = 0[/itex] and [itex]y = mx[/itex] where [itex]m = \\tan\\phi[/itex] ([itex]\\phi[/itex] is the angle between the lines). Their point of intersection is thus the origin O(0,0).\n\n    Let the point whose locus is to be found be [itex]P(\\alpha,\\beta)[/itex]. The constraint on P is then,\n\n    [tex]\\beta^2 + \\frac{(m\\alpha - \\beta)^2}{m^2+1} = k^2 [/tex]\n\n    where k is some constant ([itex]k\\epsilonR[/itex])\n\n    This after some rearranging and replacing [itex](\\alpha,\\beta)[/itex] with with general coordinates [itex](x,y)[/itex] yields\n    [itex]m^2x^2 - 2mxy + y^2(m^2+2) - k^2(1+m^2) = 0[/itex]\n    which when compared with the general second degree equation,\n    [itex]Ax^2 + 2Hxy + By^2 + 2gx + 2fy + c = 0 [/itex]\n    does turn out to be an ellipse.\n\n    However it is not in the standard form, so finding its eccentricity is not as easy. Now I understand that by rotating the coordinate axes we can bring the equation into such a form by a suitable choice of the rotation angle which causes the cross term (H) to disappear. However, I want to know if there is some other way out to find the eccentricity (or more generally to do this problem).\n\n    I would be grateful if someone could offer some ideas.\n\n    Thanks and cheers\n  2. jcsd\n  3. Feb 3, 2005 #2\n    After posting this, I realized this probably isn't the right place for this post. For the moderator(s): if you think, could you please shift it to the right place. Sorry for the inconvenience...\n  4. Feb 5, 2005 #3\n    Someone please help!!\n  5. Feb 5, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    Dearly Missed\n\n    What's wrong with writing it in standard form?? :confused:\n  6. Feb 5, 2005 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I don't see any other way to extract the excentricity,other than knowing the semiaxes...You can do that simply applying the theory of conics and the set of linear transformations which bring the conic to a known form,in this case an ellipse.\n\n  7. Feb 6, 2005 #6\n    Okay thanks for your replies. Suppose that I live in a very weird world and I'm supposed to show that I can do this \"smartly\" but not in a lengthy way. How would I do it? :biggrin:\n\n    I know I can rotate the axes and do what I've said I can in the first post to get it in the standard form. But I was wondering if there's some other way out. Anyway thanks...\n\n  8. Feb 7, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    How about if i told you that the equation:\n    [tex] m^{2}x^{2}-2mxy+y^{2}(m^{2}+2)-k^{2}(m^{2}+1) [/tex](1)\n\n    is the EQUATION OF A CIRCLE...\n\n    The equation (1) can be written:\n    [tex](mx-y)^{2}+[y\\sqrt{m^{2}+1}]^{2} =[k\\sqrt{m^{2}+1}]^{2} [/tex] (2)\n\n    and making the rotation & the notation:\n    [tex] x'=:mx-y [/tex] (3)\n    [tex] y'=y\\sqrt{m^{2}+1} [/tex] (4)\n    [tex] R=:k\\sqrt{m^{2}+1} [/tex] (5)\n\n    is exactly the equation of a circle:\n    [tex] x'^{2}+y'^{2}=R^{2} [/tex] (6)\n\n    If this outcome is not correct,then it's your fault for providing an incorrect quadratic form... :wink:\n\n  9. Feb 8, 2005 #8\n    I do not know what you are trying to imply. The question and my working are before you. Do you believe the question is wrong?\n    Last edited: Feb 8, 2005\n  10. Feb 8, 2005 #9\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I don't know that.I've just shown you that the equation u came up with when substituting alpha & beta wiht x & y is the equation of a circle,and not of an ellipse.\n\n  11. Feb 8, 2005 #10\n    You could try assuming [itex]y = mx[/itex] and [itex]y = -mx[/itex] where [itex]m = \\tan\\phi/2[/itex]\n\n    This is squashing the coordinates, and so will transform a circle into an ellipse\n  12. Feb 8, 2005 #11\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Ups,you made me realize that what i had was not a genuine rotation and indeed i squashed \"y\" and so the initial ellipse became a circle... :frown:\n\n    I would have to stick to the initial advice,namely applying the theory of conics...\n\n  13. Feb 10, 2005 #12\n    Yes but the problem is to extract the eccentricity from the equation without reducing it to a standard form via rotation. However, as the problem stands now, I do not think there is any other method than to do it the brute force way. Thanks for your help though.\n\n\nHave something to add?\n\nSimilar Discussions: Question about Ellipse"}
{"text": "Retrieved from https://www.physicsforums.com/threads/one-dimensional-motion-with-friction.102575/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nOne dimensional motion with friction\n\n  1. Dec 3, 2005 #1\n\n    I was wondering if someone could help me out with this one. Its been years since I've done physics and this problems is bugging the hell out of me.\n\n  2. jcsd\n  3. Dec 3, 2005 #2\n    You know the coefficient of friction, but you don't know the frictional force, nor do you know the normal force. You do have a common element to both the frictional force and the normal force though. Try eliminating it and then working from there.\n\n  4. Dec 3, 2005 #3\n    Could you elaborate more please? :confused:\n  5. Dec 3, 2005 #4\n\n\n    User Avatar\n    Gold Member\n\n    There are several different models for kinetic friction. In some cases it is assumed to increase as velocity increases, but I suspect that this is not the model you are intended to use as this would result in a differential equation, which seems to be more advanced than the level of the question. In that case, you are probably expected to assume that the force of friction is proportional to the normal force and directed against the velocity, but independant of its maginitude. This means that\n    [tex]F_{f}= \\mu N[/tex]\n    Where F_f is the friction force, mu is the coefficient of friction and N is the magnitude of the normal force. You know the normal force cancels out the force of gravity because the can is not accelerating in the vertical direction. So N=m(mass of can)*g(acceleration due to gravity). You don't know the mass, but work the problem out as if you did and you will see that it does not matter.\n\nHave something to add?\n\nSimilar Discussions: One dimensional motion with friction\n  1. One dimensional motion (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/exponential-function.272143/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nExponential function\n\n  1. Nov 15, 2008 #1\n    Its true that if you integrate an exponential function from some time t0 to infinity it will converge to a finite value.\n\n    However, is the same true if it is multiplied by say t, t^2, t^3,t^n.\n\n    i.e. t*exp(-t) for example.\n\n    the exp is decaying to zero faaster than t is, so it goes to zero in the limit. But there are functions that decay to zero but their integral is not finite because the rate of decay is not *fast enough*.\n\n    Would the integral of exp multiplied by any power of t ALWAYs converge to a finite number?\n  2. jcsd\n  3. Nov 15, 2008 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n\n    [tex]\\int_{t_0}^\\infty t^n e^{-t} dt[/tex]\n\n    is always finite. You can prove this by induction (hint: use integration by parts).\n\n    Here's an interesting factoid for you:\n\n    [tex]\\int_0^\\infty t^n e^{-t} dt = n!.[/tex]\n  4. Nov 15, 2008 #3\n    Yes, using an integration by parts to get an inductive argument. Integrating t*exp(-t) for example will get you\n\n    -te^{-t} + \\int_{t_0}^\\infty e^{-t} dt\n\n    The left summand will go to 0 and the right integral converges. That establishes that the indefinite integral of t*exp(-t) converges, then since the derivative t^2 is 2t you can establish it again with t^2 and so on (the left summand, t^n*exp(-t) will always go to 0 since t^n = o(e^t) for all n).\n\n    Edit: oops, morphism already answered.\n  5. Nov 15, 2008 #4\n    Also consider what happens when you integrate the power series.\n\n    t^n*exp(-t) is sufficiently nice that you should be able to interchange the sum and integral.\n\nHave something to add?\n\nSimilar Discussions: Exponential function\n  1. Exponential Functions (Replies: 6)\n\n  2. Exponential function (Replies: 4)\n\n  3. Exponential function (Replies: 7)\n\n  4. Exponential functions (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-harmonic-question.56760/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Harmonic Question\n\n  1. Dec 14, 2004 #1\n    A mass is attached on a spring .When it is stretched and is let free to move then it oscillates.show that this motion is simple harmomic>>>spring obeys Hook's law.\n    My workings:\n    As the mass pulls the spring down mg>-kx but when it as it goes further more down -kx is greater than mg and the apring goes up n hence oscillates.\n    when the mass goes downwards ,displacement is negative,on the extremevelocity is 0 which means acceleration is maxium.so acceleration is proportional to displacement but due to the negative sign of displacement they are in opposite direction\n    >>> i am a bit confused how acceleration is in opposite direction to the displacement...My working is a bit mixed up :rolleyes: ..can you give me some better way of answering this question.\n    Thanks a lot in advance. :smile:\n  2. jcsd\n  3. Dec 14, 2004 #2\n    The spring+mass system will reach an equilibrium where the retarding force of the spring will balance out the gravity. ie mg = kx. This new x will be the position of the new equilibrium. If you now stretch the spring any more, it will behave just like any other spring and obey hooke's law and begin oscillating.\n\nHave something to add?\n\nSimilar Discussions: Simple Harmonic Question"}
{"text": "Retrieved from http://math.stackexchange.com/questions/321738/does-sum-n-3-infty-frac-1-log-n-log-logn-converge\nText:\nTake the 2-minute tour \u00d7\n\nDoes the following series converge:\n\n$$\\sum_{n=3}^\\infty \\frac {1}{(\\log n)^{\\log(\\log(n)}}$$\n\nI've tried all test I know... Any ideas ?\n\nshare|improve this question\nHave you tried $\\lim_{n\\to\\infty}n\\cdot u_n$? \u2013\u00a0 Babak S. Mar 5 '13 at 19:32\ncan this be done using cauchy's condensation test? \u2013\u00a0 MSEoris Mar 5 '13 at 19:52\nAndr\u00e9 Nicolas has already answered this question, but if you're interested in seeing some motivation for a slighly different approach, see this post. \u2013\u00a0 Dave L. Renfro Mar 6 '13 at 16:24\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nNote that $(\\log n)^{-\\operatorname{loglog} n}=e^{-(\\operatorname{loglog} n)^2}$, since $\\log n=e^{\\operatorname{loglog} n}$.\n\nFor large $n$, we have $(\\operatorname{loglog} n)^2\\lt \\log n$, so for large $n$ the $n$-th term is greater than $\\frac{1}{n}$.\n\nThe fact that $(\\operatorname{loglog} n)^2$ is eventually dominated by $\\log n$ is just the familiar fact that $e^x\\gt x^2$ for large enough $x$.\n\nRemark: In dealing with convergence of series, it is often better to ask oneself first: How fast are the terms approaching $0$? Looking instead for a test to use tends to distance us from the concrete reality of the series.\n\nshare|improve this answer\nInteresting philosophy in the remark, are there any specific schools of thought using similar views? \u2013\u00a0 Arjang Mar 5 '13 at 20:17\nThe remark was not really of a philosophical nature, though it could be interpreted as a tilt towards Platonism as opposed to Formalism. However, what was meant is that in problem-solving, concrete confrontation of the problem can be more effective than searching through the toolchest for a suitable tool. \u2013\u00a0 Andr\u00e9 Nicolas Mar 5 '13 at 20:23\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/129879/filling-in-a-rational-orthogonal-matrix-given-one-row?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nQuick version: given natural $n$ and a row of $n$ integers such that the sum of the squares is another square, call it $m^2.$ For $n=5,6,7$ is it always possible to fill in the rest of an $n$ by $n$ matrix of integers, call it $M,$ so that $M M^T = m^2 I? $ If so, $M/m$ is rational orthogonal.\n\nNotes: this is true for $n=1,2,3,4,8.$ 1 is trivial 2 uses complex numbers, 4 uses quaternions, 8 uses octonions. 3 uses quaternion stuff applied to ternary quadratic forms, papers of Jones and Pall mostly, the main one 1939. The naive adaptation of the Jones-Pall formalism to our $n=7$ does not work very well, see Octonions and the dance of the seven veils\n\nThis is false for $n = 9,17,25,33,\\ldots.$ Indeed, take any odd $n = k^2,$ let the first row have all entries $1,$ no second row is possible that is orthogonal to the given first row, consists of integers, and has the same length. Problem mod 2, insofar as the dot product of the two rows is odd, therefore nonzero. Actually, for any $n >1, \\; \\; \\; n \\equiv 1 \\pmod 8,$ one may specify any $n-3$ odd numbers, then find the final three (also odd) by Gauss three square theorem to get an odd square sum, no luck.\n\nAnyway, I did some computer checks, entirely successful for small entries for $n=5,6,7,$ and instinct tells me that it only gets easier with larger entries.\n\nSo, that is the short version, does this work for any first row of integral length (sum of squares is another square) in dimension $n=5,6,7?$\n\nshare|improve this question\nThat's nice, if you do a large number of edits, but they are all in a few minutes, it clumps them together and counts only one edit. \u2013\u00a0 Will Jagy May 6 '13 at 19:42\nIndeed. However, note that after a certain number of edits (maybe 8) the question automatically becomes CW, so be careful despite the clumping. \u2013\u00a0 Tony Huynh May 6 '13 at 19:51\n@Tony, yes, I pay attention to that. If I click in the middle, where it currently says \"edited 13 mins ago\" it shows me the revision list and the official edit count. So that is how I know when to start an answer of my own, for example. \u2013\u00a0 Will Jagy May 6 '13 at 19:54\nYou might be interested in weighing matrices. (I think that's the term.) I know Robert Craigen and others in combinatorial matrix theory have studied matrices with MM^T = wI. Also Will Orrick might know some people who can help. Gerhard \"Ask Me About Indirect References\" Paseman, 2013.05.06 \u2013\u00a0 Gerhard Paseman May 6 '13 at 20:03\n@Gerhard, I used to have a very nice bathroom scale, based on strain gauge. Later I dripped a bunch of water on it and it died. en.wikipedia.org/wiki/Weighing_matrix Will Orrick is an MO regular, not sure about the other name. It appears the important case for most people has entries $0,1,-1.$ \u2013\u00a0 Will Jagy May 6 '13 at 20:37\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYes, it is possible to fill in. Your problem is a particular case of a completion problem and is treated in the following paper:\n\nHsia, J.S. Two theorems on integral matrices. Linear Multilinear Algebra 5, 257-264 (1978).\n\nshare|improve this answer\nThank you. I had that article at one point. \u2013\u00a0 Will Jagy May 8 '13 at 20:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/15162/hitting-times-for-an-n-dimensional-random-walk-on-a-lattice-with-strictly-posit?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nPlease consider a random walk on a finite N-dimensional lattice with vectors $(x_1, ..., x_N)$. We define the origin to be $(0, ..., 0)$ and the target to be at the point in the lattice furthest away from the origin - i.e. $(||x_1||, ..., ||x_N||)$ where $||x_k||$ is the integer length of the lattice in the $x_{k}$ dimension. Here, each step of the random walk is a uniformly distributed, strictly positive random integer in each of the N-dimensions with an upper-bound value defined by the requirement that one cannot exceed the dimensions of the lattice.\n\nIs there a nice method, aside from explicit path-counting, to derive the probability density for hitting times provided an arbitrary lattice as defined above?\n\nSome computational results: For the $N=1$ case I expected the target hitting time (defined as the number of steps to reach the target) to fit well with a logarithmic growth function of the form $A*ln(S)$ where A is a positive real number and $\"S\"$ is the number of integer steps one takes to reach the target from the origin. Running simulations (averaging 10,000 times) this yielded a decent fit with the value of $A$ ~ 1.146 for $||x|| = 100$, but $A$ decreases to ~1.095 for $||x|| = 1,000$ and decreased further ~1.069 for $||x||=10,000$.\n\nshare|improve this question\nThis sounds a lot like directed percolation. ;) \u2013\u00a0 Gjergji Zaimi Feb 13 '10 at 3:08\nHow are you choosing your random step sizes? \u2013\u00a0 Qiaochu Yuan Feb 13 '10 at 3:08\nLeonid, yes, that's exactly what I mean. One would generate a uniformly distributed random integer between '1' and the largest integer value that won't take you out of the lattice for each of the 'N' dimensions. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:24\nLeonid, I apologize, I misspoke. The overall step size must be non-zero, but movement in any subset of the dimensions may be zero for a step. I.e. one of the randomly generated integers must be at least one, but the remainder may be zero-valued. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:35\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAssuming you mean Leonid Kovalev's interpretation, the distribution of the hitting time in the $N = 1$ case is the same as the distribution of the number of cycles of a random permutation of $[n]$.\n\nTo be more specific, I'll change coordinates. Let $X_0 = (x_0^1, \\ldots, x_0^N) = (S, S, \\ldots, S)$. Let $X_1 = (x_1^1, \\ldots, x_1^N)$, where $x_1^j$ is chosen uniformly at random from $0, 1, \\ldots, x_0^j-1$. Define $X_2$ similarly in terms of $X_1$, and so on.\n\nThen the sequence $(x_0^1, x_1^1, x_2^1, x_3^1, \\ldots)$ are as follows:\n\n  \u2022 $x_0^1 = L$, of course.\n  \u2022 $x_1^1$ is uniformly distributed on $\\{ 0, \\ldots, S-1 \\}$.\n  \u2022 $x_2^1$ is uniformly distributed on $\\{ 0, \\ldots, x_1^1-1 \\}$.\n\nand so on... In particular the distribution of $x_1^1$ is the distribution of number of elements in a random permutation on $S$ elements which are {\\it not} in the cycle containing 1; In particular the distribution of $x_1^1$ is the distribution of number of elements in a random permutation on $S$ elements which are {\\it not} in any of the $k$ cycles with the smallest minima.\n\nSo the distribution of the smallest $k$ for which $x_k^1 = 0$ is exactly the distribution of the number of cycles of a random permutation of $\\{ 1, \\ldots, S \\}$; this is $1 + 1/2 + \\cdots + 1/S \\sim \\log S + \\gamma$, where $\\gamma = 0.577\\ldots$ is the Euler-Mascheroni constant.\n\nIn the higher-dimensional cases, the time to reach $(0, \\ldots, 0)$ is just the {\\it maximum} of the number of cycles of $N$ permutations chosen uniformly at random; this should still have expectation $\\log S$ plus a constant depending on $N$.\n\nshare|improve this answer\nThanks for your answer Michael. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:39\nYou're welcome! It just happens that I spend way too much time thinking about random permutations. That being said, the original problem was a little underspecified, and I happened to make the interpretations that led to me being able to solve it. In your second comment I see you actually had a different interpretation in mind. I suspect the overall behavior is the same -- still logarithmic -- but it would be harder to prove because the $N$ dimensions are no longer independent. \u2013\u00a0 Michael Lugo Feb 13 '10 at 3:50\n\nWhile I like Michael Lugo's answer better, I thought I might as well put up the solution I sketched out for myself for the one-dimensional case:\n\nThe probability that the walker visits a particular point on the one-dimensional lattice can be expressed as $\\frac{1}{||x_k||-p}$ where $p$ is the distance between the lattice point and the origin. Therefore, we can express the probability that, during a given step, the walker visits the target lattice point (i.e. the lattice point furthest from the origin) as - $P(target)$ = $\\frac{(\\frac{1}{||x_k||-(||x_k||-1)})}{\\sum_{i=0}^{\\||x_k||-1}\\frac{1}{||x_k||-i}}$. $\\frac{1}{P(target)}$ should therefore provide the average hitting time for the one-dimensional walkers under the imposed conditions. Computationally this value approximates Michael Lugo's answer of $ln(||x_k||)+\\gamma$ within ~0.1 by $||x_k||$ = 5.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/266604/uniqueness-of-for-integration-functional\nText:\nTake the 2-minute tour \u00d7\n\nLet $f\\in C([0,1])$ and assume that there exists a positive constant C such that $\\left| \\int_0^1p'(t)f(t) dt \\right| \\leq C\\|p\\|_2 $ for all polynomials $p$, where $\\|p\\|^2_2 = \\int_0^1 |p(t)|^2 dt$. Show that there exists a unique $g\\in L^2([0,1])$ such that \\begin{equation} f(x) = \\int_0^x g(t) dt, \\\\ \\int_0^1 g(t)dt =0 \\end{equation} My try: let $\\ell(p) = \\int_0^1 p'(t) f(t) ds$ then $$\\ell(p) = \\int_0^1 p'(t) \\left(\\int_0^tg(x) dx\\right) dt$$ Integrate by parts: $$\\ell(p) = - \\int_0^1 p(t)g(t) dt$$ and this unique by Riesz theorem. Im pretty sure I need some kind of extension here but I cannot see where, please correct me and fill in some blanks.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nTo define $\\ell(p) = \\int_0^1 p'(t) f(t)\\, ds$ was the right move. I don't understand what happens after that line, though: the second formula for $\\ell(p)$ does not seem to agree with the first.\n\nUniqueness of $g$ is not so hard: If both $g_1$ and $g_2$ serve the purpose, then $\\int_0^x (g_1-g_2)=f(x)-f(x)=0$ for all $x$, which implies [why?] that $g_1$ and $g_2$ are the same element of $L^2$.\n\nFor existence, we certainly need the Riesz representation theorem. But the first step should probably be to extend $\\ell$ to a bounded linear functional on all of $L^2$, by Hahn-Banach. Then the Riesz representation theorem gives us $g\\in L^2$ such that $\\ell(p)=\\langle p,g\\rangle $ for all $g$.\n\nYou are also correct in that we need integration by parts. On which side of\n$$\\int_0^1 p'(t)f(t)\\,dt = \\int_0^1 p(t)g(t)\\,dt$$ can we do it? Only on the right, because $f$ is not known to be differentiable. So, introduce $G(x)=\\int_0^x g(t)\\,dt$ and perform the magic: $$\\int_0^1 p(t)g(t)\\,dt = p(1)G(1) - \\int_0^1 p'(t)G(t)\\,dt$$ This is what we have so far: $$\\int_0^1 p'(t)f(t)\\,dt = p(1)G(1) - \\int_0^1 p'(t)G(t)\\,dt$$\n\nI leave it for you to finish the proof. To-do items:\n\n  \u2022 show that $G(1)=0$\n  \u2022 show that $f\\equiv -G$\nshare|improve this answer\nThanks alot I see I had a typo in my try. And shouldnt it be -$\\int_0^1p(t)G'(t)dt = \\int_0^1p(t)g(t) dt $ and $G(1) = 0$ is given from the beginning. \u2013\u00a0 Johan Dec 29 '12 at 8:34\n@Johan No, $G(1)=0$ is not given. This is something you are told to prove in the sentence that begins with \"Show that..\". (note that the formula $\\int_0^1 g=0$ is a part of that sentence). When you are asked \"show that there exists a unicorn with five legs\", it does not mean you can assume that unicorns have five legs. It means your duty is to not only to produce a unicorn, but one that has five legs. No four-legged unicorns will be accepted. \u2013\u00a0 user53153 Dec 29 '12 at 8:44\nSorry, I can not read what I'm typing, u are correct! \u2013\u00a0 Johan Dec 29 '12 at 8:54\nSo the last things following by putting $p(t) =1 $? \u2013\u00a0 Johan Dec 29 '12 at 9:49\n@Johan Yes, that's right. \u2013\u00a0 user53153 Dec 29 '12 at 15:55\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/152021/solutions-of-an-integral-equation\nText:\nTake the 2-minute tour \u00d7\n\nGiven the integral equation: $$\\sqrt{f(x)}\\int_{0}^{x}f(\\tau)d\\tau=g(x)$$ with g(x) known function, in what cases and how is it possible to solve it?\n\n\nshare|improve this question\nIf $g(x)=k_1x^\\beta$ then the solution has a simple form $f(x)=\\sqrt{(\\alpha+1)k_1} x^\\alpha$ being $\\alpha=\\frac{2}{3}(\\beta-1)$ with $\\beta\\ne 1$. \u2013\u00a0 Jon May 31 '12 at 14:08\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nSquare both sides of the equation : $$F^'(x) \\ (F(x))^2=(g(x))^2$$ with $F(x) = \\int_{0}^{x}f(\\tau)d\\tau $.\nNow by integration between 0 and t : $$\\frac{(F(t))^3}{3} = \\int_{0}^{t} (g(x))^2 dx$$ F(t) can now be expressed : $$F(t) =\\sqrt[3]{3} \\ \\left( \\int_{0}^{t} (g(x))^2 dx \\right)^{1/3}$$ since $F'(t)=f(t)$, by derivation we obtain : $$f(t) = \\sqrt[3]{3} \\ (g(t))^2 \\left(\\int_{0}^{t} (g(x))^2 dx \\right)^{-2/3}$$\n\nshare|improve this answer\n\nLet us assume that $g(x)$ is differentiable (in fact $g(x)$ should be also positive and monotonously increasing $f(x)$ has to be positive such that the square root is properly defined).\n\nTake a derivative of your equation and you obtain $$ f(x)^{3/2} + \\frac{g(x)\\, f'(x)}{2 f(x)} =g'(x). $$ Thus, you have reduced your equation to a differential equation with the initial condition $f(0) = g(0)$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/77749/minimizing-an-entropylike-expression-with-a-quadratic-constraint?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet '$\\{X_i\\}$' be a set of n positive integers, and fix k to be a positive integer. I am interested in finding the set of solutions to the pair of inequalities:\n\n'$\\displaystyle \\sum_{i=1}^n X_i \\displaystyle \\sum_{|i - m| \\leq k} X_m \\geq t^2$'\n\n\n'$\\displaystyle \\sum_{i=1}^n X_i [ \\log (X_i) +1] \\leq t [ \\log (t/(k+1)) +1]$'\n\nwhere $t$ grows polynomially faster than n (i.e. $t = n^{1 + \\epsilon}$ for some $\\epsilon > 0$) and we define $0 \\log 0 \\equiv 0$. The quadratic expression can also be written as the quadratic form x^T A x, where the $ x \\in \\mathbb{R}^n$ and $A$ is the matrix with 1's in the first k off diagonals.\n\nNow, '$X_i = t/(k+1)$' for exactly $k+1$ contiguous elements and zero otherwise is a solution. Having spent a lot of time with the problem, I am nearly certain that this is the only solution (asymptotically in n), but cannot come up with a proof.\n\nI tried reformulating the problem as minimizing the entropy-like term with the quadratic as a constraint. However, the interior of $\\mathbb{R}^{n}^+$ will only include maxima of the function, so there would be $n+1$ Lagrange multipliers, making the approach seem intractable.\n\nI have already shown that if the mass is bounded above by t, or if there exists a set whose size is uniformly bounded in n whose mass is bounded below by t, this is the only solution. The trouble arises when one considers the option of infinitely many o(t) terms adding up to something that is $\\Theta(t^2)$ - I cannot seem to find bounds sensitive enough to give me a contradiction here. Also notice that this is not technically a convex problem: the fully concentrated option '$X_i = t$' once and zero otherwise does not satisfy the entropy inequality whenever $k >0$.\n\nDoes the implication follow, or is there some pathological example that satisfies both equations without being concentrated on $k+1$ elements?\n\nThanks so much! (and apologies for the poor formatting...)\n\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56926.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSumming Triangle Numbers\n\nDate: 04/21/98 at 15:05:43\nFrom: Karen Hooton\nSubject: Sum of triangle numbers\n\nDear Dr. Math,\n\nI am trying to find the formula for the sum of triangle numbers, such \nas: 1 + 3 + 6 + 10 + 15. \n\nI've gone through my school library and checked out the Internet with \nno luck. Is it at all possible that you can help me out?\n\nYours sincerely,\nKaren Hooton\n\nDate: 04/22/98 at 10:51:30\nFrom: Doctor Nick\nSubject: Re: Sum of triangle numbers\n\nHi Karen -\n\nThis is a nice question and it has a nice answer.\n\nLet g(n) be the n-th triangular number. So:\n\n     g(1) = 1\n     g(2) = 3\n     g(3) = 6\n\nand so on. You probably know that:\n\n     g(n) = n(n+1)/2\n\nLet f(n) be the sum of the triangular numbers 1 through n.\n\n     f(n) = g(1) + g(2) + ... + g(n)\n\n     f(n) = n(n+1)(n+2)/6\n\nHow can we prove this? We can prove it by induction. That is, we'll \nprove two things:\n   1) It's true for some n (n=1, in this case).\n   2) If it's true for n, then it's true for n+1.\n\nThis will allow us to conclude that it's true for all n >= 1.\n\nNow 1) is easy. We know that f(1) = g(1) = 1. So it's true for n = 1.\n\nNow for 2). Suppose it's true for n. Consider f(n+1). We have:\n\n     f(n+1) = g(1) + g(2) + ... + g(n) + g(n+1) \n            = f(n) + g(n+1)\n\nUsing our assumption that f(n) = n(n+1)(n+2)/6 and that \ng(n+1) = (n+1)(n+2)/2, we have:\n\n     f(n+1) = n(n+1)(n+2)/6 + (n+1)(n+2)/2\n            = n(n+1)(n+2)/6 + 3(n+1)(n+2)/6\n            = (n+1)(n+2)(n+3)/6\n\nwhich is exactly what the formula says it should be. Thus we have \nshown that if it's true for n, it's true for n + 1. Since we showed it \nwas true for n = 1, we now know it's also true for n = 1 + 1 = 2, and \nthen for n = 2 + 1 = 3, and so on, for all n >= 1.\n\nBy the way, these numbers (1,4,10,20,35,56,...) are known as \ntetrahedral numbers. If you imagine piling triangles of dots on top of \none another first 1, then 3, then 6, then 10 you'll get a tetrahedron \nof dots at each stage with 1,4,10,20 dots total. Take a look at:\n\nfor some high level information about them and related fun things.\n\nHave fun,\n\n-Doctor Nick,  The Math Forum\nAssociated Topics:\nHigh School Sequences, Series\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/64590/distributivity-mod-an-integer?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $a,b,c,m \\in \\mathbb{Z}$, is it always the case that $$a((b+c) \\text{ mod } q) \\text{ mod } q = (ab \\text{ mod } q + ac \\text{ mod }\u00a0q) \\text{ mod } q$$\n\nshare|improve this question\nThanks, do you have any reference? \u2013\u00a0 Li-thi Sep 14 '11 at 22:04\nNo reference, sorry, but I've extended my comment to an answer that contains an argument in lieu of authority. \u2013\u00a0 Henning Makholm Sep 14 '11 at 22:06\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nYes. When doing modular arithmetic you can take the modulus as often or seldom as you want to before you reach the final result, as long as you only do addition, subtraction and multiplication, and always end with a modulus. So your equation is equivalent to $a(b+c)\\equiv ab+ac \\pmod q$.\n\nThe formal justification for this is that when you're doing computations in $\\mathbb Z/q\\mathbb Z$, you can use any representative for each residue class you want for each operation, and the \"mod $q$\" just exchanges one representative for another for the same class. Only the final \"mod $q$\" is important; it ensures that if you have the same residue class on both sides, you will get the same representatives.\n\nshare|improve this answer\n\nAll the normal distributive, commutative and associative laws of $\\mathbb{Z}$ are preserved modulo any $q$; this can be seen as how the factor ring $\\text{ }\\mathbb{Z}_q$ \"inherits\" the nice arithmetical properties of the base ring $\\mathbb{Z}$.\n\nshare|improve this answer\nIf you put \\text{ } (with a space) before glitchy ascended markup it will make it look normal (at least I think it works in general). \u2013\u00a0 anon Sep 15 '11 at 2:39\n\nHINT $\\quad \\rm\\begin{align} x\\ -\\ y\\ q\\ \\ mod\\ q\\ \\ &=\\ \\ \\rm x\\ \\ mod\\ q\\quad\\ \\ for\\ all\\ integers\\ x,\\:y \\\\ \\rm \\Rightarrow\\quad a\\ (b + c\\ -\\ n\\:q)\\: \\ mod\\ q\\ \\ &=\\rm\\ \\ (ab\\ -\\ j\\ q\\ +\\ ac\\ -\\ k\\:q)\\:\\ mod\\ q \\\\ \\rm \\Rightarrow\\quad a\\ (b + c\\ mod\\ q)\\: \\ mod\\ q\\ \\ &=\\rm\\ \\ (ab\\ mod\\ q\\ +\\ ac\\ mod\\ q)\\:\\ mod\\ q \\end{align}$\n\nsince both sides equal $\\rm\\:\\ ab+ac\\ \\ mod\\ q\\:\\ $ by the first identity. Notice that we have invoked above three times the basic identity $\\rm\\: m\\ mod\\ q\\ =\\ m - i\\ q\\ $ for some integer $\\rm\\:i\\:.\\:$\n\nIf you have knowledge of congruence arithmetic then you may find it of interest to reformulate the above using such. This will yield a much more conceptual view of the essence of the matter.\n\nshare|improve this answer\n\nNote that the result can be shown by brute force, so to speak, without any group theory.\n\nLet $n = a((b+c) \\text{ mod } q) \\text{ mod } q$; then $a((b+c) \\text{ mod } q) = n + dq$ for some integer $d$. Similarly, $b+c = (b+c) \\text{ mod } q + eq$ for some integer $e$, so $$\\begin{align*}a(b+c) &= a[(b+c)\\text{ mod }q+eq]\\\\ &=n+(d+ae)q. \\end{align*}$$\n\nNow let $m = (ab \\text{ mod } q + ac \\text{ mod } q) \\text{ mod } q$. Then $ab \\text{ mod } q + ac \\text{ mod } q = m + fq$ for some integer $f$. Similarly, $ab = ab \\text{ mod } q +gq$ and $ac = ac \\text{ mod } q +hq$ for some integers $g$ and $h$, so $$\\begin{align*}ab+ac &= (ab \\text{ mod }q+gq)+(ac \\text{ mod }q + hq)\\\\ &=(ab \\text{ mod }q + ac \\text{ mod }q) + (g+h)q\\\\ &=m+(f+g+h)q. \\end{align*}$$\n\nThen $$\\begin{align*}n-m &= [a(b+c)-(d+ae)q] - [ab+ac-(f+g+h)q]\\\\ &=[a(b+c)-(ab+ac)]-[(d+ae)q-(f+g+h)q]\\\\ &=(f+g+h-d-ae)q, \\end{align*}$$ so $q \\mid (n-m)$. But $0 \\le m,n < q$ by the definition of the mod function, so $\\vert n-m\\vert < q$, and we must have $n-m=0$, i.e., $n=m$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/97811/pencil-of-lines-and-degree-d-curve-in-mathbbcp2/97816\nText:\nTake the 2-minute tour \u00d7\n\nQuestion. Let $C$ be a generic smooth curve of degree $d$ in $\\mathbb{CP}^2$, and let $P$ be an arbitrary point away from this curve. How many lines are there through point $P$ that are tangent, or have tangency of order $k$ (for any $k$ between 3 and $d$) with $C$? Probably this can be done for small $d$ using the equation for $C$, but I would like to find out if there is a formula for general $d$.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nYou have some polynomial $f(x,y,z)$. A line through the point $(1:0:0)$ can be paramaterized by a map from $\\mathbb P^1: (u:v) \\to (u:av:bv)$ for some constant $a$ and $b$. $f$ restricts to a degree $d$ polynomial in $u$ and $v$. Since it has no roots where $v=0$, set $v=1$. You now have a univariate polynomial such that the $k$th coefficient is a degree $k$ polynomial in $a$ and $b$. The discriminant of this polynomial determines whether it has a double root, which is the same as if the line is tangent. The discriminant is a degree $d(d-1)$ polynomial in $a$ and $b$.\n\nThus, the generic number of roots is $d(d-1)$. This is similarly the generic number of tangent lines. The generic number of inflection points or higher is zero, as this would require a multiple root of the discriminant.\n\nTo check that there is not some extra constraint on the discriminant polynomial that forces a multiple root, we can just find an example that does not have a multiple root. If $f(x,y,z)=x^d+xy^{d-1}+z^d$, then $f(u)=u^d+ua^{d-1}+b^d$, whose discriminant, which is $a^{d^2-d}+b^{d^2-d}$ up to some constant factors, has no multiple roots.\n\nshare|improve this answer\n@Will thanks for your answer \u2013\u00a0 user23802 May 24 '12 at 6:13\nYou can also find the tangency points as intersections with the polar curve $\\partial f/\\partial x=0$. This is an alternative way to see that there are $d(d-1)$ such points. If the base point of the pencil is $[a:b:c]$, you need the polar to be $a \\partial f/\\partial x + b \\partial f/\\partial y +c \\partial f/\\partial z=0$. For non generic curves the amount by which $d(d-1)$ is bigger than the actual number can be controlled (depending on higher order tangencies and singularities). Look for \"Pl\u00fccker formulas\". \u2013\u00a0 quim May 24 '12 at 9:34\n\nLet $\\tilde\\pi:\\mathbb{PC}^2\\setminus\\{P\\}\\to\\mathbb{PC}$ be the projection from $P$, which restricts to a surjective morphism $\\pi:C\\to\\mathbb{PC}$ of degree $d$. You are asking for the number of points of ramification of this morphism with multiplicity, or more precisely the degree of the ramification divisor $R$. By Hurwitz' theorem, it can be computed as $$\\deg(R) = 2g(C)-2 - d(2g(\\mathbb{PC}) - 2)=2\\binom{d-1}{2} + 2(d-1) = d(d-1).$$\n\nshare|improve this answer\n@Jesko thanks for your answer. \u2013\u00a0 user23802 May 24 '12 at 6:15\nA technical note: There is of course no morphism from $\\mathbb {CP}^2$ to $\\mathbb {CP}$. You mean to say that $\\bar{\\pi}$ is a morphism from $\\mathbb {CP}^2-\\{P\\}$. \u2013\u00a0 Will Sawin May 24 '12 at 6:16\n@Will: Thanks, I corrected it. \u2013\u00a0 Jesko H\u00fcttenhain May 24 '12 at 6:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/283740/finding-the-first-odd-abundant-number-less-than-1000/291555\nText:\nTake the 2-minute tour \u00d7\n\nWe say about number $n $ abundant if the sum of the divisors except $n$ is bigger than the number $n$.For example : $12$ is abundant because the sum of divisors except $12$ is bigger than $12$ : $1+2+3+4+6=16>12$ .How to find the first odd abundant number less than $1000$\n\nshare|improve this question\n\"the first odd abundant number less than 1000\": that's a strange way of putting it! If the smallest abundant number is less than 1000, then that's your answer right there; and if it's not, then your question is like \"who is the present king of France?\" \u2013\u00a0 TonyK Jan 21 '13 at 20:54\n@TonyK The smallest abundant number. \u2013\u00a0 sen Jan 21 '13 at 20:57\n\n3 Answers 3\n\nWe will take the problem to be finding the smallest abundant number, then will confirm that it is less than $1000.$ For a prime power $p^e$, the sum of divisors is $\\sum_{i=1}^e p^i=\\frac{p^{e+1}-1}{p-1}$. The sum of divisors function is multiplicative, so if $n=\\prod_i p_i^{e_i}$, the sum of divisors of $n, \\sigma(n) = \\prod_i \\frac{p_i^{e_i+1}-1}{p_i-1}$. We need $\\frac {\\sigma(n)}n =\\prod_i \\frac{p_i^{e_i+1}-1}{p_i^{e_i}(p_i-1)}=\\prod_i 1+\\frac {p_i^{e_i}-1}{p_i^{e_i}(p_i-1)}\\gt 2$\n\nIf we make a table of $\\frac{p_i^{e_i+1}-1}{p_i^{e_i}(p_i-1)}$ we get\n\n$$\\begin {array}&&3&5&7&11\\\\0&1&1&1&1\\\\ 1&1.333333&1.2&1.142857&1.090909\\\\ 2&1.444444&1.24&1.163265&1.099174\\\\ 3&1.481481&1.248&1.166181&1.099925\\\\ 4&1.493827&1.2496&1.166597&1.099993\\\\ 5&1.497942&1.24992&1.166657&1.099999\\\\ 6&1.499314&1.249984&1.166665&1.1\\\\ \\end{array}$$\n\nwhere the column is the prime and the row is the exponent. We want to find the set of entries that multiply to more than $2$ with the smallest product of prime powers. This makes us think that what as we increase the power of each prime, what we get is the difference of the log of the next entry and the current entry and what we pay is the log of the prime. So we make a new table that way\n\n$$\\begin{array} &&3&5&7&11\\\\ 1&0.26186&0.113283&0.068622&0.036287\\\\ 2&0.072858&0.020373&0.009096&0.003147\\\\ 3&0.023045&0.003996&0.001286&0.000285\\\\ 4&0.007554&0.000796&0.000184&2.59E-05\\\\ 5&0.002504&0.000159&2.62E-05&2.35E-06\\\\ 6&0.000833&3.18E-05&3.74E-06&2.14E-07\\\\ \\end{array}$$\n\nUsing the greedy algorithm, the priority order of factors is $3,5,3,7,11,3,5\\ldots$ leading to a series of candidates $3,15,45,315,3465$, but we see we can sneak another factor of $3$ onto $315$ giving $945$. The way the candidates stack up:\n\n$$\\begin{array} n&\\sigma(n)&\\frac {\\sigma(n)}n\\\\ 3&4&1.333333\\\\ 15&24&1.6\\\\ 45&78&1.733333\\\\ 315&624&1.980952\\\\ 945&1920&2.031746\\\\ 3465&7488&2.161039 \\end {array}$$\n\nand $945$ is the first to exceed $2$. We get more \"bang for the buck\" with $3465$, but $945$ is good enough.\n\nshare|improve this answer\n\nThe oeis is a good source for sequences like these.\n\nFor example, your answer can be found here as linked from here.\n\nIn particular, the answer is $945$.\n\nIf you want to check this particular example, you could do it as so in Wolfram|Alpha.\n\nshare|improve this answer\n\nIf you're familiar with a bit of R-programming, then you could try this script:\n\nn <- 1000\no <- sapply(seq(3, n, by=2), function(x) {\n    t <- sapply(1:x-1, function(y) {\n        ifelse(x %% y == 0, y, 0)\n    t <- sum(t, na.rm = TRUE)\ndf <- data.frame(num = seq(3, n, by = 2), sum_div = o)\n> df[with(df, sum_div > num), ]\n\n#     num sum_div\n# 472 945     975\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/11818/probability-of-random-number-repeating\nText:\nTake the 2-minute tour \u00d7\n\nIn the situation of having a high entropy random number generator, that generates numbers in the range of 0 and 2,147,000,000.\n\nIf i have a list of 1,000,000 integer values, what are the chances that a random number will already be on my list?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nOne minus the probability that they are all different: $$1 - \\left( 1- \\frac{1}{n} \\right) \\left( 1- \\frac{2}{n} \\right) \\cdots \\left( 1- \\frac{k-1}{n} \\right),$$ where $n=2,147,000,001$ (since you include $0$) and $k=1,000,000.$\n\nSee the birthday problem for more information.\n\nshare|improve this answer\n\nIf the list is drawn with replacement, the chance that a given number (the new draw) is not in it is $$(1-\\frac{1}{2147000001})^{1000000}$$ The birthday problem only comes up if you ask for the chance of a collision anywhere in the 1000001 numbers.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/200807/boy-and-girl-paradox/200814\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to understand the boy and girl paradox. The paradox states that if a family has two children and one of them is a boy, then the probability of the other being a girl is 2/3. When you write out the set of possible outcomes { bb, bg, gb, gg } it makes a little more sense. My question is why does age/order matter? The two possible outcomes boy/girl and girl/ boy are the same right?\n\nshare|improve this question\n\nmarked as duplicate by M Turgeon, user127.0.0.1, TMM, T. Bongers, egreg Feb 2 '14 at 0:29\n\n\n@ChristianBlatter It's even more complicated than that, because it depends on how and why you were told this information. (To be more precise, it depends on what the probability that you would be told this information in various situations, even if you assume that you would not be told it if it were false.) \u2013\u00a0 Trevor Wilson Sep 22 '12 at 19:25\n\n7 Answers 7\n\nIt's not really the case that age or order matters. Suppose that the children were twins, and were somehow born in parallel rather than in series. Forgetting about the information that there is at least one boy, there are exactly three distinct possibilities, \"two boys\", \"two girls\", and \"one of each\". However, the mere fact that there are three possibilities does not imply that all three possibilities have the same probability of $1/3$.\n\nTo give another example of this, if I flip a coin it will either come up heads, come up tails, or land balanced on its edge. However, it would be a mistake to conclude that these events all have probability $1/3$.\n\nshare|improve this answer\n\nThe sample space is $\\Omega := \\{(B,B), (B,G), (G,B), (G,G)\\}$, where the 1st element of each pair denotes the gender of the first child, and the 2nd element denotes the gender of the second child. Let us assume that each pair is equally likely, which is a reasonable assumption.\n\nIf you tell me that one of the children is a boy, then the sample space is reduced to\n\n$$\\Omega' := \\{(B,B), (B,G), (G,B)\\}$$\n\nafter I incorporate the information you gave me (\"One of the children is a boy\"). Since it is reasonable to assume that all three pairs are equally likely, the probability that the other child is a girl is given by\n\n$$\\mathbb{P} \\left(\\{(B,G), (G,B)\\}\\right) = \\mathbb{P} \\left(\\{(B,G)\\}\\right) + \\mathbb{P} \\left(\\{(G,B)\\}\\right) = \\frac{1}{3} + \\frac{1}{3} = \\frac{2}{3}$$\n\nshare|improve this answer\nWhat if I've been shown the boy? This implicitely makes him child #1 and the other child is child #2. This makes the sample space ${(1:B, 2:B), (1:B, 2:G)}$. It seems to be a matter of definition and the real-world sitation allows for both interpretations? \u2013\u00a0 Gerenuk Sep 22 '12 at 20:22\n@Gerenuk: By \"first child\" and \"second child\" I meant \"1st child that was born\" and \"2nd child that was born\", i.e., I was referring to chronological order. The order in which you observe them does not change their dates of birth ;-) \u2013\u00a0 Rod Carvalho Sep 22 '12 at 20:27\nI wasn't actually refering to someone's notion of first and second :) I was merely suggesting that instead of tell \"one is a boy\" the situation could be that I'm shown a boy and told there is another child behind the door. In that case I'd conclude there is a 0.5 change. Why is that discrepancy? \u2013\u00a0 Gerenuk Sep 22 '12 at 22:20\n@Gerenuk: One picks the uniform probability mass function (pmf) because it maximizes entropy. Thus, if we have no information at all, we assume a uniform pmf over $\\Omega$. If you tell me that one of the children is a boy, then one of the points in the sample space is eliminated and the pmf is updated as we assume a uniform pmf over $\\Omega'$. This is a Bayesian interpretation of the problem. Would be interesting to think of a Frequentist interpretation. \u2013\u00a0 Rod Carvalho Sep 22 '12 at 22:28\nI think it's more important to prove alternatives wrong. You only repeated your argument. Can you explain what is wrong with my notation where it directly and naturally follows that the sample space is different to start with? I propose that the very start of proposing a BB,BG,GB,GG sample space might be incorrect (probably depending on the method the samples where determined!). \u2013\u00a0 Gerenuk Sep 23 '12 at 8:47\n\nMy question is why does age/order matter?\n\nThe order bg or gb matters, mathematically because when defining all events (outcomes) for a random variable, you must assure that the sum of probabilities for all outcomes must equal 1. And indeed, as you know the probability associated for every outcome is $\\frac{1}2*\\frac{1}2=\\frac{1}4$ and multiplied by $4$ outcomes you get 1.\n\nIntuitively this is the same as a coin toss (2 throws, where e.g. B means heads and G tails).\n\n\nNo, the two outcomes are not the same, but they have the same probability.\n\nshare|improve this answer\n\nWell given that the children are different entities, you could say that order matters in this problem, hence the fact that $bg$ is not the same as $gb$. Say you have a big sister, and your aunt has an elder boy and a baby girl. Both families have a boy and a girl but the configuration is different. That is why knowing that one of them is a boy, it leaves $3$ possibilities, $2$ of which have girl, while if you know that the elder is a boy, the you only have $2$ configurations left.\n\nshare|improve this answer\n\nTry it with coins: First, flip a nickel and a dime. There quite clearly are four possibilities: (N=H, D=H), (N=H, D=T), (N=T, D=H), and (N=T, D=T). Each, also quite clearly, has a probability of 1/4; so the probability of two heads is 1/4, the probability of two tails is 1/4, and the probability of one of each is 1/2.\n\nThen repeat the same experiment with two absolutely identical quarters. There now seem to be three combinations we can discern: (Both H), (Both T), and (one H and one T). But do you really think the odds change to 1/3 for each combination just because the coins are now identical? I certainly hope not. Even though you can't see the difference between the coins, they still are different coins, and the ways that the different combinations can occur still depend on that difference.\n\nWhen we count possibilities for two-child families, age-order matters only because we have to acknowledge that the two children are different from each other. Even if we aren't given any information that distinguishes them, that difference still matters.\n\nBut as for the probability paradox you mentioned, the answer depends on how you \"know\" that one is a boy. If it is because you asked if the family had any boys, then every BB, BG, or GB family would answer \"yes\" and the answer is 1/3. But if you learned that fact incidentally, then you could have learned a BG of GB family has a girl. You can only count half of them, and the answer is 1/2.\n\nshare|improve this answer\n\n@Andrew-kudwitt , @rod-carvalho , I have a point here! Evidently the gender of one child shouldnt affect the other..May i state that you are wrong in the very first step of choosing your sample space like @gerenuk said.. You \" may or may not consider the order\" .If you do it correctly, your answer should be same in both the cases.. For instance , if you donot consider order of birth, your sample space is (xB, xG) because you donot care about the observed child! so probability of the other being a boy is 1/2 ! If you do consider the order, ( take the observed boy to be denoted as B0 ) ,then your sample space is (B0 G, B0 B, G B0, B0 B) , SO still the probability of the other child beig a boy is 2/4=1/2...the order and gender of other child doesnt matter..it shouldnt matter.. because one child being a boy doesnot affect the other's gender (excluding the bio stuffs involved, ofcourse)!\n\nshare|improve this answer\ngerenuk is right! \u2013\u00a0 Aishwarya Krishnan Sep 11 '13 at 9:03\n\npython script proof for those of little faith/CS background:\n\nfrom random import randrange\n\nresults = {\n\"one_boy_born_tuesday\":{\"B\": 0, \"G\": 0}, \"one_boy\":{\"B\": 0, \"G\": 0}, \"first_is_boy\":{\"B\": 0, \"G\": 0}, \"first_is_boy_born_tuesday\":{\"B\": 0, \"G\": 0}\n\nfor i in xrange(1000000):\n    house = []\n    for j in range(2):\n        sex = \"B\" if randrange(2) == 0 else \"G\"\n        day = randrange(7)\n        house.append({\"sex\":sex, \"day\":day})\n\n    exp = \"one_boy_born_tuesday\"\n    if (house[0][\"sex\"] == \"B\" and house[0][\"day\"] == 3):\n        results[exp][house[1][\"sex\"]] += 1\n    elif (house[1][\"sex\"] == \"B\" and house[1][\"day\"] == 3):\n        results[exp][house[0][\"sex\"]] += 1   \n\n    exp = \"one_boy\"\n    if (house[0][\"sex\"] == \"B\"):\n\n    exp = \"first_is_boy\"\n\n    exp = \"first_is_boy_born_tuesday\"\n\nfor k, v in results.items():\n    print \"-\"*60\n    print k\n    print v\n    print 1.0*v[\"B\"]/(v[\"G\"]+v[\"B\"])\n\nand the results (tada):\n\n{'B': 250451, 'G': 500196}\n\n{'B': 35337, 'G': 35850}\n\n{'B': 250451, 'G': 249837}\n\n{'B': 66134, 'G': 71911}\nshare|improve this answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/31047/optimization-problem-with-two-step-discontinuous-function\nText:\nTake the 2-minute tour \u00d7\n\nimagine my function as a staircase with two steps. This function is to be fitted to some empirical data and I'm searching for an algorithm which minimizes the Root Mean Squared Error between this function and the data. The decision variables are L1 and L2 (for the level of the steps on the y-axis) and C (for the cut-off-point between the steps on the x-axis). The possible values for C on the x-axis are discreete and finite. Can you point me to algorithms or even possible solutions in Excel (VBA), Matlab or C++? The standard Excel solver is unable to solve this problem, because it requires a smooth function, but the (expensive) Premium solver seems able to do it.\n\nMy suggestion for an algorithm would be following 2-step method: Given the finite set of values for C, for each C, optimize L1 and L2. Then, optimum C* would the C with the lowest RMSE given L1* and L2*. Would that be correct? Or is there a more elegant way to it?\n\nAny helpful comments are appreciated. Steve\n\nshare|improve this question\nWhen you say \"imagine my function as a staircase with two steps\", I imagine a function with three different values and two steps between them, but then you only have two variables for the \"level of the steps\" and only once position on the $x$ axis. So it seems you actually mean just a function that changes from one value to another just once? This would usually be referred to as a \"step function\", not a \"two-step function\". \u2013\u00a0 joriki Apr 5 '11 at 7:07\nNote that your problem has a discrete aspect and a continuous aspect. The decision for $C$ is discrete, since it doesn't matter where between two consecutive data points you put it. The decision for $L_1$ and $L_2$ is continuous. The continuous part is easy: Once you know where the step is, $L_1$ and $L_2$ are just the averages of the data on each side of the step. So your problem is basically to find the best split point. \u2013\u00a0 joriki Apr 5 '11 at 7:16\nIt helps if you mark edits as edits in the text; then people who have already read the question know that they need to reread parts of it to be up to date. My comments above referred to the original question. \u2013\u00a0 joriki Apr 5 '11 at 7:27\nYour algorithm is correct. I was hoping one might be able to show that the RMSE is convex in $C$, which would have meant you don't have to try all values for $C$, but there are counterexamples for that, with several local minima for $C$, so I think you do have to try them all. When you say \"optimize $L_1$ and $L_2$\", note that in this case that just means \"take the average of the data on each side of $C$\". \u2013\u00a0 joriki Apr 5 '11 at 7:47\nwith respect to your 1st comment: You are right, only one change of value, sorry for the confusion. 2nd comment: correct. 3d comment: sorry again. 4th comment: I realize that for a given C, I can evaluate L1* and L2* independently from one another. That's what I meant. \u2013\u00a0 Steve06 Apr 5 '11 at 17:34\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe example $\\{(-1,-1),(-\\epsilon,-\\epsilon),(\\epsilon,\\epsilon),(1,1)\\}$ shows that there can be more than one local minimum with respect to $C$: Splitting 1 & 3 either way is better than splitting 2 & 2. So it seems you can't avoid trying out every position for the step.\n\nTo find the optimal $C$ efficiently, note that the optimal $L_1$ and $L_2$ given $C$ will be the average of the data on each side of $C$, so that what you're trying to minimize is\n\n$$ \\begin{eqnarray} && \\sum_{x_i<C}\\left(f_i-\\frac{\\sum_{x_i<C}f_i}{N_<}\\right)^2 + \\sum_{x_i\\ge C}\\left(f_i-\\frac{\\sum_{x_i\\ge C}f_i}{N_\\ge}\\right)^2 \\\\ &=& \\sum_{x_i<C}f_i^2 - \\frac{\\left(\\sum_{x_i<C}f_i\\right)^2}{N_<} + \\sum_{x_i\\ge C}f_i^2 - \\frac{\\left(\\sum_{x_i\\ge C}f_i\\right)^2}{N_\\ge} \\\\ &=& \\sum f_i^2 - \\left( \\frac{\\left(\\sum_{x_i<C}f_i\\right)^2}{N_<} + \\frac{\\left(\\sum_{x_i\\ge C}f_i\\right)^2}{N_\\ge} \\right)\\;, \\end{eqnarray} $$\n\nwhere $N_<$ and $N_\\ge$ are the numbers of points to the left and right of $C$, respectively. The first term is constant, so you can ignore it, so all you need to do is sweep through from left to right, in each step adding one function value to the left-hand sum and subtracting it from the right-hand sum and evaluating the expression in parentheses.\n\nshare|improve this answer\ni implemented an algorithm that checks every possible split point, but due to the no. of possibilities (around 1000) it's a bit slow. I consider starting with a large net of inspecting first every 100th possible split point, then, within the range of the 2 nearby solutions with the lowest average error, I would tighten the net to every 20th possible split point, and finally loop through every possibility of the best 20-point range. Would that make sense? \u2013\u00a0 Steve06 Apr 6 '11 at 14:58\n@Steve: I'm not sure how good your chances to get close to the optimal solution would be with such an approach. I think it would depend on the clustering of the values and might differ quite a bit from the optimal result in some cases. If you have 1000 split points, you should be able to try them in almost no time, so I suspect you might be doing it inefficiently -- did you use the approach in my answer to avoid having to sum function values for each possible split? \u2013\u00a0 joriki Apr 6 '11 at 15:57\nit takes long because (a) because L1, L2 are each fitted to the data iteratively, (b) I use Excel VBA which as a scripting language is of course a lot slower than some C code and (c) the whole procedure has to be repeated for 500 different companies in my sample. At the moment, one company takes about half an hour on average to be optimized. \u2013\u00a0 Steve06 Apr 6 '11 at 17:51\n@Steve: Your last comment makes we wonder whether you've understood my answer. This should be a matter of milliseconds, not hours. Most importantly, $L1$ and $L2$ should not be fitted to the data iteratively -- as I wrote in the answer, they are simply the averages of the function values to the left and to the right of the split point, respectively, and even these averages don't have to be recalculated for each potential split point. I recommend that you try to implement my answer; I'll be happy to help if you have questions about it. \u2013\u00a0 joriki Apr 6 '11 at 17:59\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96372/rate-of-change-of-mass-of-a-parameterized-region?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $R_t$ be a family of compact, simply connected regions in the plane defined by\n\n$R_t = \\{x\\in\\mathbb{R}^2 : h(x) \\leq t\\}$\n\nfor all $t$, where $h(x)$ is some nicely behaved smooth function. Suppose $f(x)$ is a probability density on $\\mathbb{R}^2$ and define\n\n$M(t) = \\iint_{R_t} f(x) dA$\n\nfor all $t$. Is it true that\n\n$\\frac{dM}{dt}|_{t=t_0} = \\int_{\\partial R_{t_0}} f(x) /\\|\\nabla h\\| ds$\n\nwhere $ds$ denotes integration with respect to arc length? If not, what is the right expression for $\\frac{dM}{dt}$? I assume this is some well-known first-year calculus-type problem but I can't find it stated in any context (it may very well be a common homework problem though I've not seen it).\n\nshare|improve this question\nThis is not a good question for MO. See en.wikipedia.org/wiki/Coarea_formula \u2013\u00a0 Anton Petrunin May 9 '12 at 0:51\nThis is a special case of the coarea formula. \u2013\u00a0 Liviu Nicolaescu May 9 '12 at 17:58\nThanks to both of you, I wasn't familiar with that result! That clears this question up for me nicely. \u2013\u00a0 Jennifer Gao May 11 '12 at 0:26\n\n1 Answer 1\n\nWith $H$ the Heaviside function (characteristic function of $\\mathbb R_+$), you have $$ M(t)=\\int_{\\mathbb R^n} f(x) H(t-h(x)) dx $$ and thus, at least formally, $$ \\dot M(t)=\\int_{\\mathbb R^n} f(x) \\delta_0(t-h(x)) dx= \\int_{\\mathbb R^n} f(x)\\Vert\\nabla h(x)\\Vert ^{-1} \\underbrace{\\delta_0(t-h(x))\\Vert\\nabla h(x)\\Vert dx}_{d\\sigma} , $$ where $d\\sigma$ is the Euclidean surface measure on {$x, h(x) =t$}. Here, it is important to assume that $h$ is say $C^1$ such that $dh\\not=0$ at $h=t$ for $t$ in neighborhood of some distinguished value $t_0$. As a result, $$ \\dot M(t)=\\int_{\\partial R(t)}f(x)\\Vert\\nabla h(x)\\Vert ^{-1} d\\sigma. $$ The previous computation can be justified by Green's formula: for $X$ a $C^1_c$ vector field on $\\Omega$ ( an open subset of $\\mathbb R^n$ with a $C^1$ boundary) $$ \\int_\\Omega \\text{div} X\\ dx=\\int_{\\partial \\Omega} X\\cdot \\nu\\ d\\sigma, $$ where $\\nu$ is the exterior unit normal to $\\partial \\Omega$, and $d\\sigma$ is the Euclidean surface measure on $\\partial \\Omega$. That formula can be proven by showing $$ d\\sigma=\\lim_{\\epsilon\\rightarrow 0} \\phi(\\frac{\\rho(x)}{\\epsilon})\\epsilon^{-1}\\Vert\\nabla \\rho(x)\\Vert\\quad\\text{(distribution sense),} $$ for $\\phi\\in C^\\infty_c(\\mathbb R),\\int \\phi(t) dt=1$, $\\Omega=${$x, \\rho(x)<0$}, $d\\rho\\not=0$ at $\\rho=0$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/321150/find-a-nonzero-3-times-3-matrix-with-all-0-eigenvalues-is-there-a-systematic/321154\nText:\nTake the 2-minute tour \u00d7\n\nAfter playing around for a bit I found one:\n\n\nbut I couldn't find a good systematic way.\n\nshare|improve this question\nIt is not hard to come up with non-zero nilpotent matrices. \u2013\u00a0 Andr\u00e9 Nicolas Mar 5 '13 at 6:12\nI get lots of junk mail about solving nilpotency problems... \u2013\u00a0 copper.hat Mar 5 '13 at 6:13\n@Andr\u00e9Nicolas thank you for telling me what I was looking for! That+Wikipedia was a great help. \u2013\u00a0 crf Mar 6 '13 at 4:31\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nAll strictly triangular matrices are nilpotent (see here) & hence can have $0$ as the only eigenvalue.\n\nshare|improve this answer\n\n\n$$A = \\begin{bmatrix} 0&a&c\\\\ 0&0&b\\\\ 0&0&0 \\end{bmatrix} $$\n\nwith $ab \\ne 0$ and $c$ arbitrary.\n\nSo the only eigenvalue is $\\lambda_{1,2,3} = 0$, with multiplicity three.\n\nUpdate: from CH's comment, the restriction on $a, b$ is not needed.\n\nshare|improve this answer\nWhy do you care about the values of $a,b$? \u2013\u00a0 copper.hat Mar 5 '13 at 6:15\n@copper.hat: You are correct, I don't need that restriction. Since $ab \\ne 0$, the \ufb01rst two rows are not proportional and their cross-product is $(ab, 0, 0)$, so the eigenspace, $E(0) = ker A$ is the line through $e_1 = (1, 0, 0)$. However, we don't need anything quite so rigid for this problem. I tried to do something to help match the example from the OP. \u2013\u00a0 Amzoti Mar 5 '13 at 6:21\nNice post, and update, too...I've done my fare share of edits/updates based on feedback! \u2013\u00a0 amWhy Apr 25 '13 at 0:25\n\nUsing the Schur decomposition, it is exactly the set of matrices $U T U^*$, where $U$ is unitary, and $T$ is strictly upper triangular.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/27234/elogz-t2-proof-of-convergence-with-law-of-large-numbers\nText:\nTake the 2-minute tour \u00d7\n\nHi all, question: Let $Z_t$ be an iid sequence with $$\\mathbb{E}\\log(Z_t^2)<0 $$ Show that $$\\sum_{j=0}^\\infty Z_t^2 Z_{t-1}^2 ... Z_{t-j}^2 < \\infty$$ almost surely\n\nI am supposed to use LLN to solve this... but i can't make ends meet (this is exam preparation sheet question)\n\nshare|improve this question\nThis is just a straightforward exercise. Don't think it is really the kind of question this site is intended for. To answer, take the log of the product, divide by n and use LLN to deduce that the product is less than one (almost surely) for all large n. \u2013\u00a0 George Lowther Jun 6 '10 at 17:13\nActually I misread it. The formula doesn't seem to make sense. Shouldn't the product be $Z_1\\cdots Z_j$, in which case the LLN shows that the terms are almost surely bounded by a geometric series with ratio less than 1, so absoluty convergent. \u2013\u00a0 George Lowther Jun 6 '10 at 17:22\n\n2 Answers 2\n\nIf the term $Z_i^2$ of the independent and identically distributed random sequence is less than 1, then you can find a $q$ with $Z_i^2 \\leq q < 1$ for almost all $i$ (acording to the law of large numbers). Then the $k$-fold product is less than $q^k$ such that the geometric series limits your sum by $\\frac{1}{1-q}$.\n\nI presume that you meant $Z_{t+j}^2$ instead of $Z_{t-j}^2$. Otherwise you'd get negative indices.\n\nshare|improve this answer\n\nFor every $t$, let $Y_t=\\log(Z_t^2)$. Fix some $t$. The sequence $(Y_{t-k})_{k\\geqslant0}$ is i.i.d. with $E[Y_t]\\lt0$ hence the usual law of large numbers yields $\\frac1j\\sum\\limits_{k=0}^{j-1}Y_{t-k}\\to E[Y_1]$. Fix some negative $m\\gt E[Y_1]$.\n\nThen $\\frac1j\\sum\\limits_{k=0}^{j-1}Y_{t-k}\\leqslant m$ for every $j$ large enough, that is, for every $j\\geqslant J$ where $J$ is random and almost surely finite. In particular, for every $j\\geqslant0$, $\\sum\\limits_{k=0}^{j}Y_{t-k}\\leqslant mj+X$, for some almost surely finite random $X$. This implies the pointwise convergence of the series since $$ \\sum_{j\\geqslant0}\\exp\\left(\\sum\\limits_{k=0}^{j}Y_{t-k}\\right)\\leqslant\\sum_{j\\geqslant0}\\mathrm e^X\\mathrm e^{mj}=\\mathrm e^X(1-\\mathrm e^m)^{-1}. $$ Note that the RHS above is almost surely finite since $m\\lt0$ but is not (a priori) uniformly bounded since $X$ may be unbounded.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/84473/on-an-eigenvalue-inequality?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\lambda_1 (\\cdot)$ be the larger absolute value eigenvalue of a $2\\times2$ matrix and $\\lambda_2 (\\cdot)$ the smaller absolute value eigenvalue of a $2\\times2$ matrix, i.e. $|\\lambda_1 (\\cdot)| \\ge |\\lambda_2 (\\cdot)|$. Is it true that $$ \\left|\\left|\\lambda_{1}\\left(A+B\\right)\\right|^{1/3}-\\left|\\lambda_{1}\\left(A\\right)\\right|^{1/3}\\right|+\\left|\\left|\\lambda_{2}\\left(A+B\\right)\\right|^{1/3}-\\left|\\lambda_{2}\\left(A\\right)\\right|^{1/3}\\right|\\leq\\left|\\lambda_{1}\\left(B\\right)\\right|^{1/3}+\\left|\\lambda_{2}\\left(B\\right)\\right|^{1/3} $$ for any $2\\times2$ symmetric real matrix $A$ (would suffice to prove or disprove for not positive-definite matrices $A$) and $2\\times2$ diagonal real matrix $B$? Thanks a lot for any helpful answers! By the way, a relevant question was answered by Suvrit here.\n\nshare|improve this question\nWhere do you get these statements from? Suvrit gave a counterexample to a previous claim, so unless there is a good reason to believe this is true, it is not clear that it is worthwhile thinking about these questions. \u2013\u00a0 Igor Rivin Dec 28 '11 at 20:52\nI think that this inequality does hold (even for $n \\times n$ matrices), but I know the proof only for positive definite matrices, which implies a restricted version of the inequality that you actually seem to be after. \u2013\u00a0 Suvrit Dec 28 '11 at 20:55\nFair enough..... \u2013\u00a0 Igor Rivin Dec 28 '11 at 22:01\nMETA: tea.mathoverflow.net/discussion/1187/\u2026 \u2013\u00a0 Will Jagy Dec 29 '11 at 6:19\n\n1 Answer 1\n\nBelow I highlight that a much more general claim holds for $n\\times n$ positive definite matrices, and that a slightly weaker version of your inequality holds for general symmetric matrices.\n\nRecall a classic theorem of Ando, (T.Ando, \"Comparison of norms $\\|f(A)-f(B)\\|$ and $\\|f(|A-B|)\\|$, Math. Z., 197, (1988)):\n\nTheorem (Ando). Let $A$ and $B$ be positive semidefinite matrices, and let $\\|\\cdot\\|$ be any unitarily invariant norm, and let $|X| = (X^TX)^{1/2}$ denote the matrix absolute value. For any nonnegative operator monotone function $f(t)$ on $[0,\\infty)$,\\begin{equation*} \\|f(A)-f(B)\\| \\le \\|f(|A-B|)\\|\\end{equation*}\n\nNow, in your case we can use $f(t) = t^r$ for $r \\in [0,1]$, to obtain $$\\|A^r-B^r\\| \\le \\|\\ |A-B|^r\\ \\|,$$ which when specialized to the trace-norm (sum of singular values) yields the inequality that you desire (but for positive matrices).\n\nThis inequality immediately implies the following weaker one for general symmetric matrices $$\\| f(|A|) - f(|B|) \\| \\le \\left\\|f\\bigl(\\bigl|\\ |A|-|B|\\ \\bigr|\\bigr)\\right\\|,$$ which is somewhat weaker than what you desire (but may suffice for your needs---which can be elaborated upon only if you follow Igor's suggestion and tell us where you are getting these questions from, and in what context!)\n\nshare|improve this answer\nIn that case, I'm curious to see your proof of the positive definite case! \u2013\u00a0 Suvrit Dec 29 '11 at 12:01\n@unknown: it actually does follow because of the following theorem: $\\|\\sigma^\\arrowdown(f(A)) - \\sigma^\\arrowdown(f(B))\\| \\le \\|f(A)-f(B)\\|$ \u2013\u00a0 Suvrit Jan 1 '12 at 11:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207303/throwing-coins-probability\nText:\nTake the 2-minute tour \u00d7\n\nX and Y are throwing coins. X throws $n$ times and Y throws $n+1$ times. What's the probability that Y got more heads than Y?\n\nI was trying to consider all the situations that X got $i$ heads and Y got $j>i$ heads but it didn't lead me to any sensible conclusion.\n\nshare|improve this question\n\n2 Answers 2\n\nLet $H_X, H_Y,T_X,T_Y$ denote the heads and tails counts of $X$ and $Y$. Assume that the heads of $X$'s coin is red, tails green, whereas the heads of $Y$'s coin is green, tails red. We ask for the probability of $$H_Y>H_X$$ $$\\iff T_X+H_Y=n-H_X+H_Y>n+H_X-H_Y=H_X+T_Y-1\\\\\\iff T_X+H_Y\\ge T_Y+H_X$$ But the latter expression is just that the number of grean outcomes is at least as large as the number of red ones. For this, the answer (by symmetry and since ties cannot occur) $\\frac12$.\n\nAlternatively, let $Y$ delay her last throw. With both players making $n$ throws, there is a certein probability $p$ that $X$ has more heads, the same probaility that $Y$ has more heads, and the probability $1-2p$ for a tie. With the last coin, $Y$ can only make a change in case of a tie and does so half the time for a win. That is: The probability of more heads for $Y$ is $p+\\frac{1-2p}2=\\frac12$.\n\nshare|improve this answer\n\nLet $X_n$ and $Y_n$ be the number of head in the first $n$ tosses. What is asked for is the probability of $$P(X_n < Y_{n+1}) = P(X_n < Y_n) + P(X_n = Y_n)P(\\text{last toss of }Y \\text{is a head})$$ Apparently, $P(X_n<Y_n)+P(X_n>Y_n)+P(X_n=Y_n)=1$ and because of symmetry, $P(X_n<Y_n)=P(X_n>Y_n)$ so that $P(X_n<Y_n)=\\frac{1-P(X_n=Y_n)}{2}$. Moreover, $P(\\text{last toss of }Y \\text{is a head})=1/2$. Plug them into the above equation, you will find out that $$P(X_n<Y_{n+1})=\\frac{1}{2}$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/186038/finding-the-function-of-a-graph?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nHow do I find the function of this graph? You can ignore the first two values before 20 cm.\n\nshare|improve this question\nIf you have a set of points and you want to find a function which approximates those points, you can use interpolation. If you don't know the actual point values, I would say the best you can do is to estimate them. Perhaps someone else has a clever solution where you can just input the graph and it estimates the points and the function for you. \u2013\u00a0 process91 Aug 23 '12 at 21:04\nNot sure what the physics are here, but it looks a bit like x*exp(-x**2) \u2013\u00a0 Johannes Ernst Aug 23 '12 at 21:13\nI would also say interpolation is your best bet. The function $ \\frac{66x}{x^2+144} $ does seem slightly similar to the points, though. \u2013\u00a0 Envious Page Aug 23 '12 at 21:14\nit seems to be decreasing in $\\frac {6.6}x$ for $x\\gg 1$. \u2013\u00a0 Raymond Manzoni Aug 23 '12 at 22:43\nadd comment\n\n3 Answers 3\n\nup vote 0 down vote accepted\n\nFirst an approximative table of values (in decimeters $\\to$ Volts) for gray paper :\n\n$\\small \\begin{array}{ccccccccccccccccccccc} 1&2&3&4&5&6&7&8&9&10&11&12&13&14&15\\\\ \\hline 2.3&2.75&1.98&1.52&1.24&1.04&0.89&0.81&0.71&0.66&0.6&0.56&0.51&0.48&0.46 \\end{array} $\n\nWhen we plot the inverse of the voltage we get a nearly linear behavior so let's try a quadratic regression on the inverse of the voltage starting at distance $40\\,\\mathrm{cm}$ ($40\\,\\mathrm{cm}\\to 1,\\ 50\\to 2,\\cdots$) (Alpha's complete result) :\n\nquad reg\n\n$$f(x)= -0.00137562x^2+0.157268x+0.500273$$ We need to replace $x$ in Wolfram Alpha's formula by $\\frac x{10}-3\\ $ to take the $\\mathrm{cm}\\to \\mathrm{dm}$ conversion and $1\\to 4$ shift into account.\n\nThe interpolated formula becomes (for $x\\ge 30$) : $$V(x)\\approx \\frac 1{0.01608842+ 0.016552172\\;x- 0.0000137562\\;x^2}$$ (of course the digits obtained shouldn't be considered too seriously...)\n\nComparison to the initial table : $\\small \\begin{array}{ccccccccccccccccccccc} 1&2&3&4&5&6&7&8&9&10&11&12&13&14&15\\\\ \\hline 2.3&2.75&1.98&1.52&1.24&1.04&0.89&0.81&0.71&0.66&0.6&0.56&0.51&0.48&0.46\\\\ \\color{#ff0000}{5.5}&\\color{#ff0000}{2.93}&2.0&1.52&1.24&1.04&0.9&0.8&0.72&0.65&0.6&0.55&0.52&0.48&0.46 \\end{array} $\n\nHoping it helped a little,\n\nshare|improve this answer\nIt helped a lot, thanks! How did you find out that the inverse voltage gave linear behavior? \u2013\u00a0 Sven Aug 25 '12 at 6:01\n@Sven: Glad it helped ! Well I plotted the inverse of my table. I observed too (on your graph) that $30\\times 2=40\\times 1.5=60\\times1=\\cdots$ (nearly...), \u2013\u00a0 Raymond Manzoni Aug 25 '12 at 6:57\nadd comment\n\nGiven the quantities displayed in your graph (distance from an object emitting radiation), it may be something of the form\n\n$$f\\left(x\\right) = \\frac{1}{ax^2}$$\n\nIn order to find a fitting value for the parameter $a$, you could use an error function (a function that for a parameter $a$ gives you the error from the data in your graph). You can then find the parameter $a$ that makes the error function minimal using either numerical methods or calculus.\n\nGiven that it's only one parameter, you may of course also try out a few values and see how close you can get.\n\nshare|improve this answer\nadd comment\n\nA good idea in such cases is to make a logarithmic or a double logarithmic plot of your data. If the decay is exponential, you will get points approximately on a straight line when you plot $\\log(y)$ against $x$. If the decay follows a power law, you will get approximately a straight line when you plot $\\log(y)$ against $\\log(x)$.\n\nHere the second alternative seems to work best, which suggests that you can use the model $$\\log(y)=a+b\\log(x)$$ This can solved for $y$ and rewritten as $$y={\\rm e}^ax^b$$ The parameters $a$ and $b$ can be estimated by performing linear regression of $v=\\log(y)$ against $u=\\log(x)$. I used the numbers given in Raymond's answer, with the modification that (after deleting the two first points) the first points are given by $$(x_1,y_1)=(1.5,2.75), \\qquad (x_2,y_2)=(2,2.52)$$ Then the method of least squares gave me the estimates $$\\hat a=1.50, \\qquad \\hat b=-0.83$$ Hence your function may be described by $$y={\\rm e}^{1.50}x^{-0.83}=4.48 x^{-0.83}$$\n\nWhen choosing which model you will use, you have to balance goodness of fit with your theoretic knowledge of the underlying process. There might for instance be physical reasons to prefer (or reject) a power law when modeling reflection properties, even if other models might give better (or worse) fit to the data.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209001/how-can-i-prove-that-for-every-real-number-a-there-exists-a-sequence-r-n-of/209017\nText:\nTake the 2-minute tour \u00d7\n\nHow to prove that for every real number $a$ there exists a sequence $r_n$ of rational numbers such that $r_n \\rightarrow a$.\n\nshare|improve this question\nThe answer depends greatly on how you define your real numbers. If it is the completion of the rationals then this is trivial. \u2013\u00a0 Ragib Zaman Oct 8 '12 at 0:59\nadd comment\n\n3 Answers 3\n\nup vote 4 down vote accepted\n\nWithout loss of generality we may assume the real number $a$ is $\\gt 0$. (If $a \\lt 0$, we can apply the argument below to $|a|$ and then switch signs.) We sketch a fairly formal proof, based on the fact that the reals are a complete ordered field. In one of the remarks at the end, we give an easy informal but incomplete \"proof.\"\n\nLet $n$ be a natural number. Let $m=m(n)$ be the largest positive integer such that $\\frac{m}{n}\\lt a$. Then $\\frac{m+1}{n}\\ge a$, and therefore $|a-m/n|\\lt 1/n$.\n\nLet $r_n=m/n$. It is easy to show from the definition of limit that the sequence $(r_n)$ has limit $a$.\n\nRemarks: $1.$ One really requires proof that there is a positive integer $m$ such that $\\frac{m}{n}\\ge a$. It is enough to show that there is a positive integer $k$ such that $k \\ge a$, for then we can take $m=kn$. The fact that there is always an integer $\\gt a$ is called the Archimedean property of the reals. We proceed to prove that the reals do have this property.\n\nSuppose to the contrary that all positive integers are $\\lt a$. Then the set $\\mathbb{N}$ of positive integers is bounded, so has a least upper bound $b$. That means that for any $\\epsilon \\gt 0$ there is an integer $k$ such that $0\\lt k\\lt b$ and $b-k\\lt \\epsilon$. Pick $\\epsilon=1/2$. Then $k+1\\gt b$, contradicting the assumption that $b$ is an upper bound for $\\mathbb{N}$.\n\n$2.$ One can also give a very quick but not fully persuasive \"proof\" of the approximation result. Assume as before that $a\\gt 0$. The numbers obtained by truncating the decimal expansion of $a$ at the $n$-th place are rational, and clearly have limit $a$. The problem is that we are then assuming that every real number has a decimal expansion.\n\nshare|improve this answer\nWhy is it problematic to assume that real numbers have decimal expansion? \u2013\u00a0 leo Oct 8 '12 at 2:04\n@leo: To prove that the real numbers have certain properties, we have to start with a formal definition of the reals. Then we can prove representability by an infinite series $a_0+\\frac{a_1}{10}+\\frac{a_2}{100}+\\cdots$ where $a_0$ is an integer and the rest of the $a_i$ are digits, that is, integers between $0$ and $9$. But before a course in \"analysis\" one takes these facts for granted, and then for example $3, 3.1,3.14,3.141,3.1415, 3.14159,\\dots$ is a sequence of rationals with limit $\\pi$. To answer your question, one has to know at what level the question is being asked. \u2013\u00a0 Andr\u00e9 Nicolas Oct 8 '12 at 2:13\nadd comment\n\nHint: The rational numbers are dense in the reals. If there is a real number $a$ for which there lacks such a sequence, what can we say about the neighborhood of $a$?\n\nshare|improve this answer\nThis statement is equivalent to the statement that the rationals are dense in the reals. \u2013\u00a0 Qiaochu Yuan Oct 8 '12 at 0:34\nThe point of the exercise is to see one such sequence. Isn't? \u2013\u00a0 leo Oct 8 '12 at 2:03\nadd comment\n\nI'm surprised that no one's talked about decimal notation yet, but here's an informal proof. (For familiarity, we'll use the base-10 system.)\n\nIf $x$ is rational, just use the sequence $\\left(r_n\\right)=\\left(x, x, x, x, \\dots\\right)\\to x$. If it's irrational, we'll have to do some work: Represent $x$ using decimal notation. It will be a non-repeating, non-terminating decimal. For example, let\n\n$$x = \\sqrt{2} = 1.414213562...$$\n\nThen just make every term of your sequence a terminating decimal, a more refined approximation of $\\sqrt{2}$.\n\n$$\\left(r_n\\right)=\\left(1, 1.4, 1.41, 1.414, 1.4142, 1.41421, 1.414213, \\dots\\right)$$\n\nObviously, since every term in the sequence is a terminating decimal, it's a rational number. By the Cauchy criterion, the rational sequence converges, and it converges to the real number $\\sqrt{2}$.\n\nIt's not a formal proof, but you can see how it works.\n\nshare|improve this answer\nCertainly not a formal proof -- it's borderline circular! That any real number can be approximated by a decimal requires proof. But you're absolutely right that one can find a rational number with a fixed power denominator (i.e., a number of the form p/q^n for some fixed q) to approximate any real number. PS -- according to the answer right above yours, people did talk about decimals in October. \u2013\u00a0 user54535 Jan 6 '13 at 4:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141377/ranking-probability-problem\nText:\nTake the 2-minute tour \u00d7\n\n$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$.\n\nWe know $P(A > B) = 0.7, P(B > C) = 0.6$, what is $P(A > C)$?\n\nIs this a well defined problem? Does it have a sensible answer?\n\nEDIT: Suppose we have two careless observers. An observer observes $A > B$ and there are 70% probability that she is right. Another observer observes $B > C$ and there are 60% probability that she is right. So what is the probability of $A > C$ in the underlying event?\n\nshare|improve this question\nWait, if they are all sampled from the same uniform distribution on $[0,1]$, how can we have $P(A > B) \\neq 0.5$? \u2013\u00a0 TMM May 5 '12 at 13:37\n@TMM I edited the question. Is it well defined now? \u2013\u00a0 lqhl May 5 '12 at 14:05\nThere is a potentially interesting Bayesian problem here, struggling to get out. \u2013\u00a0 Andr\u00e9 Nicolas May 5 '12 at 14:29\nadd comment\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nI wrote following MATLAB code. Simulation results show the probability is around 0.602. I hope someone could confirm this with an analytic answer.\n\nN = 1000000;\n\nA = rand(N, 1);\nB = rand(N, 1);\nC = rand(N, 1);\n\np1 = 0.7;\np2 = 0.6;\n\nc1 = rand(N, 1);\nc2 = rand(N, 1);\n\nob1 = ((A > B) & (c1 < p1)) | ((A < B) & (c1 > p1));\nob2 = ((B > C) & (c2 < p2)) | ((B < C) & (c2 > p2));\n\nob = ob1 & ob2;\n\npos = ob & (A > C);\n\nsum(pos) / sum(ob)\n\n\nI enumerate all the 6 possibilities of relative order of $A, B, C$. They all appear with probability 1/6.\n\nThe following lists shows with how much probability each case passes the two observers\n\n  \u2022 $A>B>C$, $0.7\\times 0.6$\n\n  \u2022 $A>C>B$, $0.7\\times 0.4$\n\n  \u2022 $B>A>C$, $0.3\\times 0.6$\n\n  \u2022 $B>C>A$, $0.3\\times 0.6$\n\n  \u2022 $C>A>B$, $0.7\\times 0.4$\n\n  \u2022 $C>B>A$, $0.3\\times 0.4$\n\nAmong them, $A>B>C$, $A>C>B$, $B>A>C$ are the valid cases. So\n\n$\\frac {0.7\\times 0.6+0.7\\times 0.4+0.3\\times 0.6} {0.7\\times 0.6+0.7\\times 0.4+0.3\\times 0.6+0.3\\times 0.6+0.7\\times 0.4+0.3\\times 0.4} = 0.6027$\n\nshare|improve this answer\nWhat does \"$A > C > B, 0.7 \\times 0.4$\" mean? Certainly it cannot mean $P(A > C > B) = 0.7 \\cdot 0.4$. \u2013\u00a0 TMM May 5 '12 at 15:35\n@TMM It means the probability that $A>C>B$ passes the two observers. Since $A>C$, it passes the first observer probability with $70\\%$ (she makes a correct observation) probability. Since $C>B$, it passes the second observer with $40\\%$ probability (she makes a mistake). And the two events are independent. Hope this solves your problem :) \u2013\u00a0 chtlp May 5 '12 at 15:41\nNope, it doesn't. The two observations are fixed, while the values of $A,B,C$ are not. So what does \"the probability that [it] passes the two observers\" mean? \u2013\u00a0 TMM May 5 '12 at 15:45\n@TMM Imagine we repeat sampling $\\langle A, B, C\\rangle$ many times, some of them fit the description $P(A>B)=0.7$, $P(B>C)>0.6$ (``pass the observers''). And we want to know in these events, how many of them have $A>C$. \u2013\u00a0 chtlp May 5 '12 at 16:16\n+1: Despite the downvoting, the simulated answer and the maths is absolutely correct, under the assumption that the values of A,B and C are independent of the observed probabilities. Nice job. \u2013\u00a0 Ronald May 5 '12 at 23:27\nadd comment\n\nAh. It depends strongly on the method for making those probabilistic observations.\n\nFor example: If we observe that A=0.7, then we should note P(A>B)=0.7.\n\nIf we observe that C=0.4, then we should note P(B>C)=0.6.\n\n(This is perhaps the most obvious, natural way of accessing those probabilities. An observation of B would affect both probabilities)\n\nAnd, if those were our observations, then it's absolutely guaranteed that A>C. P(A>C) = 1.\n\nshare|improve this answer\nYou are assuming $A$ is fixed in $P(A > B) = 0.7$, but it could also be that $B$ is fixed, e.g. $B = 0$ and $A = B + U(-0.3, 0.7)$ and $C = B + U(-0.4, 0.6)$ with $U(a,b)$ a uniformly distributed random variable on $[a,b]$. In that case $P(A > C) > 0.5$ but $P(A > C) \\neq 1$. \u2013\u00a0 TMM May 5 '12 at 17:24\nAs I said, it depends on the method of making the probabilistic observations. What I said is consistent with the observations, and I would argue is the most natural way for those observations to occur, but there are other possible cases. \u2013\u00a0 Ronald May 5 '12 at 23:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/490874/r-has-just-one-prime-ideal-iff-r-nr-is-a-field/490961\nText:\nTake the 2-minute tour \u00d7\n\nLet $R$ be a ring with nilradical $N(R)$. How can one show that $R$ has just one prime ideal if and only if $R/N(R)$ is a field ?\n\nshare|improve this question\nCan you prove one of the directions? \u2013\u00a0 Tobias Kildetoft Sep 11 '13 at 19:16\nThis question is extremely on-topic and interesting, the topic being algebraic geometry. I consider the statement that it is homework insulting, since no solid proof for that is given. I vote to reopen. \u2013\u00a0 Georges Elencwajg Sep 11 '13 at 20:43\n@GeorgesElencwajg It has clear precedent here to use the term homework for all questions that have been given to the one asking them for them to solve. Whether it has been given by a book, by a teacher or something/someone else is not important for the idea that the best answers for questions of this type are the ones that provide the minimal amount of hint in order for the OP to solve it themselves (since presumably the OP is trying to learn). I agree that the phrasing of the closure reason is poor given that this is not something one can expect the OP to know. \u2013\u00a0 Tobias Kildetoft Sep 12 '13 at 6:36\nDear @Cantlog: thanks for your edits. I hope fewer people will object to this question now. \u2013\u00a0 Georges Elencwajg Sep 12 '13 at 7:37\nPlease improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Questions that do not provide this information are often closed even if they possess mathematical content. \u2013\u00a0 Carl Mummert Sep 12 '13 at 12:17\nshow 2 more comments\n\n3 Answers 3\n\nup vote 13 down vote accepted\n\nSince you have tagged it \"commutative algebra\" I assume that your ring is commutative and has an identity element. First suppose $R$ has only one prime ideal. Then $R$ has only one maximal ideal and $N(R) = J(R)$ which mean that $R/N(R)$ is a field.\n\nConversely, suppose $R/N(R)$ is a field. This means that $N(R)$ is a maximal. On the other hand $N(R)$ is equal to intersection of prime ideal. SO it would be maximal only if it is the intersection of only one prime ideal which means that $R$ has only one prime ideal.\n\nshare|improve this answer\n@YACP I have edited the answer. How about know? \u2013\u00a0 kian Sep 11 '13 at 19:38\nadd comment\n\nLet us call a commutative ring $R$ a quasi-field if it satisfies the equivalent properties:\n\n$\\bullet$ $R$ has only one prime ideal.\n$\\bullet$ The nilradical $\\operatorname {Nil}(R)$ is maximal.\n$\\bullet$ $R$ is local of dimension zero.\n\nNoetherian quasi-fields are a dime a dozen and the ring $k[T_1,\\cdots,T_n,\\cdots]/(T_1^2,\\cdots,T_n^2,\\cdots)$ (where $k$ denotes a field) is a non-noetherian quasi-field.\n\nAn interesting appearance of quasi-fields is in the following result:\n\nA point $\\xi$ of a scheme $X$ is the generic point of an irreducible component of $X$ iff its local ring $\\mathcal O_{X,\\xi}$ is a quasi-field.\n\nNB: This is not an answer to the question (which has already been answered satisfactorily) but a remark on the interest of this notion and propaganda for the terminology.\n\nshare|improve this answer\nFantastic answer. Of the 15 users who went out of their way to prevent answers on this question, 10 did so after this answer was posted, in addition to the 5 who would have precluded it altogether. On MSE, it is more important to uphold a (far from unanimous) stylistic preference about how questions are posted, than to allow questions that lead to answers of significant long-term \"interest to the community\". \u2013\u00a0 zyx Sep 12 '13 at 22:17\nThank you, @zyx. \u2013\u00a0 Georges Elencwajg Sep 12 '13 at 22:26\nSomebody downvoted this, but not any of the other answers. No good deed goes unpunished... (anyway, thanks again for the illuminating answer). \u2013\u00a0 zyx Sep 12 '13 at 22:51\nDear @zyx, I really like your misanthropic but profound aphorism \"no good deed goes unpunished\". It reminds me of an exclamation I once read: \"Why does he hate me? I didn't even help him...\" \u2013\u00a0 Georges Elencwajg Sep 12 '13 at 23:16\nadd comment\n\nI assume your ring is commutative.\n\n$R/N(R)$ is a field $\\Leftrightarrow\\,N(R)$ is a maximal ideal. But $$N(R)=\\bigcap_{P\\subset R}P,$$ the intersection being over all prime ideals in $R$. Such an intersection is a maximal ideal if and only if we are intersecting a single ideal.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/246812/finding-maximal-chain-of-cardinality-aleph\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nA countale partially ordered set that has an uncountable number of maximal chains\n\nLet $(P,\\leq) $ partial ordered set. We say $I\\subseteq P $ is a chain if for all $a,b \\in I $, held $a\\leq b$ or $b\\leq a$.\n\n$I\\subseteq P $ is maximal chain if there is no $J\\subseteq P$ that contains $I$ totally.\n\n\nFind partial ordered set $(P,\\leq) $, such that $\\text{card P}=\\aleph_0$, but the set of maximal chain cardinality is $\\aleph$.\n\nCan somebody explain me what I need to do?\n\nThank you!\n\nshare|improve this question\n\nmarked as duplicate by Asaf Karagila, martini, Cameron Buie, tomasz, Henry T. Horton Nov 29 '12 at 2:21\n\n\nIs $\\aleph$ the same as $\\aleph_0$? If not, what is it? \u2013\u00a0 Brian M. Scott Nov 28 '12 at 21:06\n$\\text{card}\\mathbb{R}=\\aleph$ \u2013\u00a0 17SI.34SA Nov 28 '12 at 21:16\nThat\u2019s a most unusual notation; normally one writes $2^{\\aleph_0}$, $2^\\omega$, or $\\mathfrak c$ for $|\\Bbb R|$. \u2013\u00a0 Brian M. Scott Nov 28 '12 at 21:23\n@Brian: That was Cantor's original notation, actually. It is also not uncommon in Israel (for some reason) to use $\\aleph$. At least in introductory courses. \u2013\u00a0 Asaf Karagila Nov 28 '12 at 21:42\nadd comment\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nI expect that you know what a chain in the partial order $\\langle P,\\le\\rangle$ is: a subset of $P$ that is linearly ordered by $\\le$. A maximal chain is simply a chain that is not a proper subset of any other chain. For example, if you partially order the positive integers by divisibility (i.e., $m\\le n$ iff $m\\mid n$), then $C=\\{2^k:k\\in\\Bbb N\\}$ is a maximal chain: if you add to $C$ any positive integer that is not a power of $2$, you\u2019ll no longer have a chain. Thus, you\u2019re being asked to find a countable partial order that has $|\\Bbb R|$ distinct maximal chains.\n\nIt is perhaps a little surprising that it\u2019s possible to find such a small partial order with so many different chains, so it\u2019s not surprising that an example probably isn\u2019t immediately obvious. I\u2019ve given a couple of (very similar) examples below, leaving the verification that they work to you; if you want to try finding one on your own, you should stop reading here.\n\nLet $P$ be the set of finite sequences of $0$\u2019s and $1$\u2019s, setting $\\sigma\\le\\tau$ if and only if $\\sigma$ is an initial segment of $\\tau$. Show that there is a maximal chain for each infinite sequence of $0$\u2019s and $1$\u2019s.\n\nAlternatively, let $\\mathscr{F}$ be the family of finite subsets of $\\Bbb N$, and define the partial order $\\le$ as follows: for $F,G\\in\\mathscr{F}$, $F\\le G$ if and only if $F\\subseteq G$ and either $F=G$ or $\\max F<\\min(G\\setminus F)$. In other words, if $F$ and $G$ are distinct members of $\\mathscr{F}$, then $F<G$ if and only if $F\\subseteq G$ and every element of $G\\setminus F$ is larger than every element of $F$. Show that there is a maximal chain in $\\langle\\mathscr{F},\\le\\rangle$ for each infinite subset of $\\Bbb N$. (This partial order is isomorphic to the subset of the first one consisting of those finite sequences whose last terms are $1$.)\n\nshare|improve this answer\nBrian, read closely. The OP asked for an explanation what is the question asking, instead you wrote a solution to the question. :-) \u2013\u00a0 Asaf Karagila Nov 28 '12 at 21:46\n@Asaf: Damn. I knew that, and then I got distracted before writing my answer. \u2013\u00a0 Brian M. Scott Nov 28 '12 at 21:50\nadd comment\n\nYou need to find a countable partial order $(P,\\leq)$ such that the collection of $\\{C\\subseteq P\\mid C\\text{ is a maximal chain}\\}$ has cardinality $2^{\\aleph_0}$.\n\nOne example would be all finite binary strings ordered by end-extension. Show that any maximal chain would correspond to an infinite subset of $\\mathbb N$, and that different subsets correspond to different maximal chains.\n\n$C\\subseteq P$ is a maximal chain, I'll remind you, if $(C,\\leq\\upharpoonright C)$ is a linear order, and whenever $C\\subsetneqq D$ we have that there are $x,y\\in D$ such that $x\\nleq y$ and $y\\nleq x$. Namely $C$ is a chain and it cannot be extended to a strictly larger chain.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192090/what-is-wrong-with-this-idft-trick/192439\nText:\nTake the 2-minute tour \u00d7\n\nIn this section from Wikipedia about IDFT, three methods are given for expressing the Inverse Discrete Fourier Transform in terms of the direct transform.\n\nBeing curious, I implemented the three methods in Octave:\n\n% define TD signal\nN = 1024; n = [1:N]-1; f = [4 8];\nx0 = sin(2*pi*n'*f/N);\nx0 = sum(x0');\n\n% calculate FD spectrum\ny0 = fft(x0);\n\n% trick #1\ny1 = fliplr(y0);\nx1 = fft(y1) / N;\n\n% trick #2\ny2 = conj(y0);\nx2 = conj(fft(y2)) / N;\n\n% trick #3\ny3 = imag(y0) + i*real(y0);\nx3 = fft(y3) / N;\nx3 = imag(x3) + i*real(x3);\n\n% plot results\nplot(n,x0,'m-o', n,x1,'r-*', n,x2,'g-^', n,x3,'bxo');\naxis tight\n\nIf happens that tricks #2 and #3 work well, while trick #1 fails to generate the correct result.\n\nAm I missing something in the explanation, or is there an error in Wikipedia?\n\nUPDATE: It seems like the magnitude of the y1 result is actually OK, it is just that the angle is doing funny things. Replacing the plot line with:\n\nplot(n,abs(x0),'m-o', n,abs(x1),'r-*', n,abs(x2),'g-^', n,abs(x3),'bxo');\n\nshows the overlap.\n\nshare|improve this question\nIn your definition of $n$, you create a row vector. x0 would then be a row vector, except that you take the sin of n': n-transposed. So x0 would, I believe, be a column vector. Which means that y0 would be a column vector, and so fliplr would be operating on a column vector and hence do nothing (at least, this would be the case if Octave works as MATLAB does). Did you check that y0 is a row vector, as expected? \u2013\u00a0 Arkamis Sep 6 '12 at 21:12\n@EdGorcenski - x0 is being transposed in the sum() as well, so I end up with a row vector. Typing whos shows all vectors have a 1 in their 1st dimension. \u2013\u00a0 ysap Sep 6 '12 at 21:33\nAh, so it is; I missed that! \u2013\u00a0 Arkamis Sep 6 '12 at 21:49\n@EdGorcenski - I just posted an update to the question. \u2013\u00a0 ysap Sep 6 '12 at 21:49\nadd comment\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nI found my mistake. According to Wikipedia, using the 1st method, the indices of the reversed series are modulo N. So the correct code is:\n\n% trick #1\ny1 = [y0(1) fliplr(y0(2:N))];\nx1 = fft(y1) / N;\n\nand not as posted in the question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232576/questions-about-convergence-in-lp\nText:\nTake the 2-minute tour \u00d7\n\nIf $X_n$ converges to $X$ in $L^p$, do we have $X_n^p$ converges to $X^p$ in $L^1$?\n\nWe can prove that it is true when p=1,2 easily. I am curious whether this is true for all $p>0$.\n\nshare|improve this question\nYou should consider $|X|^p$ and so on, as $X^p$ does not make sense for all $X$ and all $p>0$. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Nov 8 '12 at 3:05\nThanks for your comment. When I consider Lp convergence, I will take modulus. I don't think we need to add modulus in the beginning. \u2013\u00a0 XXX11235 Nov 8 '12 at 23:53\nadd comment\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nNote that $$|x^p - y^p| = \\left|\\int_y^x p t^{p-1}\\ dt \\right| \\le p (|x|+|y|)^{p-1} |x - y|$$ Thus if $1/p + 1/q = 1$ (where $1 < p,q < \\infty$) $$\\eqalign{\\|X^p - Y^p\\|_1 &\\le \\int p (|X| + |Y|)^{p-1} |X - Y| \\cr &\\le p \\|(|X| + |Y|)^{p-1}\\|_q \\|X - Y\\|_p \\cr &= p \\left(\\int (|X| + |Y|)^p\\right)^{1/q} \\|X - Y\\|_p \\cr &= p \\||X|+|Y|\\|_p^{p/q} \\|X - Y\\|_p \\cr &\\le p (\\|X\\|_p + \\|Y\\|_p)^{p/q} \\|X - Y\\|_p\\cr}$$ If $X_n \\to X$ in $L^p$, $\\|X_n\\|_p$ is bounded, and so we get $\\|X_n^p - X^p\\|_1 \\to 0$.\n\nshare|improve this answer\nGet it. Thank you very much!! \u2013\u00a0 XXX11235 Nov 8 '12 at 23:48\n@Robert Israel: Dear Sir. I have an interesting question in the following math.stackexchange.com/questions/346937/\u2026 I would like to ask your comments? \u2013\u00a0 blindman Apr 12 '13 at 2:18\nadd comment\n\nIt's not correct for $0 < p < 1$. Take $X_n: [0,1] \\to \\mathbb{R}$ as $X_n(x) = n \\cdot I_{[0,1/n)}(x)$, where $I_A$ = indicator function of a set $A$. Then $\\|X_n\\|_p = n^{1-1/p}$ and therefore $X_n \\to 0$ in $L^p$ for $p < 1$, but $X_n$ does not converge in $L^1$.\n\nshare|improve this answer\nI don't understand you solution. But many thanks anyway. \u2013\u00a0 XXX11235 Nov 8 '12 at 23:53\nadd comment\n\nIt is solved by Robert Israel.\n\nshare|improve this answer\nIf you cite an author, give book, edition and page number. Be complete. \u2013\u00a0 ncmathsadist Nov 9 '12 at 2:38\nIt is actually the first answer of this page. I should have said \"It is answered by Robert\" \u2013\u00a0 XXX11235 Nov 10 '12 at 3:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/39088/how-do-i-do-error-calculus-right-using-gnuplot-as-an-example\nText:\nTake the 2-minute tour \u00d7\n\nGiven is a set of measurements with their respective errors for example an energy spectrum. In gnuplot one is to fit a function $ f(x;\\{p_i\\})$ depending on a variable $x$ and on fit parameters $p_i$. When the fit is done one gets values for the $p_i$ with errors and a correlation matrix with values $ c_{ij}$. Now one has to calculate a value $v(\\{\\text{some of the }p_i\\})$ that depends on some of the the $p_i$ and find its error $\\Delta p_i$.\n\nHow will a calculate the error $e$? Do I have to take correlations into account? Can I do it the way I attempted it in my solution attempt.\n\nSolution Attempt: $e^2=\\sum_{i}\\left(\\frac{\\partial v}{\\partial p_i}\\cdot \\Delta p_i\\right)^2+\\sum_{ij}\\frac{\\partial v}{\\partial p_i}\\frac{\\partial v}{\\partial p_j}c_{ij}\\Delta p_i \\Delta p_j$\n\nIf this is right what happens if one of the $c_{ij}$ is negative?\n\nshare|improve this question\nDoes this really have anything to do with gnuplot? It seems like you're just asking how to interpret the results of a regression with uncertainties given on the coefficients. \u2013\u00a0 David Z Oct 5 '12 at 0:46\n@David I agree this is more general than gnuplot, and people here (myself included) can probably give some feedback. But I'm wondering if there's a stackexchange more appropriate for error analysis. \u2013\u00a0 Chris White Oct 5 '12 at 7:26\nI think questions on error analysis in general are fine here, and in fact this is probably the best site on the network to put them on. If not here, I could see them perhaps going on Mathematics. However, questions about gnuplot usage would go on Super User or Computational Science. I suspect this question is basically fine, it just needs to be retitled/edited to show that it is asking about error analysis in general, not the usage of gnuplot to do error analysis, and I wanted to confirm that suspicion with the OP. \u2013\u00a0 David Z Oct 5 '12 at 8:00\nI changed the title. Is this title maybe more ok? Please is there anybody who can answer it? \u2013\u00a0 A badbad student Oct 5 '12 at 10:05\nQuestions about the meaning of sums of residuals in a regression would be fine on Stats.SE, as well. \u2013\u00a0 dmckee Oct 5 '12 at 14:50\nadd comment\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://www.physicsforums.com/threads/32n-3-0-mod-p-formula-for-n.125837/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\n32n + 3 = 0 mod p formula for n\n\n  1. Jul 12, 2006 #1\n    If p is prime > 2 then there is a easy way to solve 32n+3 = 0 mod p\n\n    if p = 1 mod 8 then m = (p-1)/4 and n = m(m+1)/2 mod p\n    if p = 3 mod 8 then m = (p-3)/4 and n = m(m+1)/2 mod p\n    if p = 5 mod 8 then m = (p-5)/8*2 + 1 and n = m(m+1)/2 mod p\n    if p = 7 mod 8 then m = (p-7)/8*2 + 1 and n = m(m+1)/2 mod p\n\n    Strange how triangular numbers relate to primes!\n\n    Can anyone give a proof for this relation?\n    Last edited: Jul 12, 2006\n  2. jcsd\n  3. Jul 12, 2006 #2\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If you just substitute in the expression for n in terms of p it drops out.\n\n    e.g if you take the p=1 mod 8 example\n\n    32(p-1)(p+3)/2*4*4 +3 = -3+3=0 mod p.\n\n    The others are the same.\n\n    It doesn't appear too hard to generate other relations like this. Of course had you not chosen 32 and 3 you would not have this explicit relation with triangular numbers. You have dropped into the trap of looking at your probabilities a posterii. Note that 32/4=8 and you're looking at p mod 8.\n    Last edited: Jul 12, 2006\n  4. Jul 12, 2006 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    p doesn't have to be prime either, those solutions still work.\n\n    edit- you can also combine the p=1 and 5 mod 8 cases, both have m=(p-1)/4. Likewise for the other two, i.e. just look at p mod 4.\n    Last edited: Jul 12, 2006\n  5. Jul 12, 2006 #4\n    Your right. The formula for n is much simpler if you look at it mod 4.\n\n    I stumbled on to this by chance. Looking at the problem to find n such that solves 32n + 3 = 0 mod p, the solution escapes any reasoned thought.\n    As you have shown, the proof of the solution to this problem is quite simple for odd p. Thanks\n    It is not the case for even p. For some even p there is no solution at all, and I havent found a relation that determines which even p have solutions or a formula for those cases.\n  6. Jul 13, 2006 #5\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    There are no solutions for any even p.\n\n    You're trying to find n and t so that 32n+3=pt. If p is even then the RHS is even and the LHS is always odd so there are no solutions.\n  7. Jul 15, 2006 #6\n    Could'nt we also do it this way?\n\n    Rewrite the equation as [itex] 32n+3 = kp [/itex]. Rewrite that as\n\n    (1) [tex] kp - 32n = 3[/tex]\n\n    Now this linear diophantine equation has solution (n,p) only when k is relatively prime to 32. The rrs mode 32 is {1,3,5,7,9,11,13,15,19,21,23,25,27,29,31}. Let one of these be denoted by r.\n\n    [tex] (32t+r)p - 32n = 3[/tex]\n\n    So for any prime P and reduced residue of 32, R we have\n\n    [tex] Pt - n = \\frac {3-RP}{32}[/tex]\n\n    Which can be shown either to exist or not as a diophantine equation depending on whether 32|(3-RP).\n\n    So although this is not your typical closed form solution you can check easily to see if a given residue and a given prime allow a solution. When 32|(3-RP) we know that there is at least one solution t=3-RP and [itex]n = P(3-RP)-\\frac {3-RP}{32}[/tex]\n\n    Then we can write all of them as\n\n    t = 3-RP + s\n    [tex]n = P(3-RP)-\\frac {3-RP}{32} - s[/tex]\n\n    s is an integer of our choosing.\n\n    This is intersting in that it shows us that while t and n are discrete linear in the residues, t discrete linear in the primes but n is discrete quadratic in the primes. That begs the follwing question, clearly\n\n    [tex] -RP^2+(3 -\\frac {R}{32})P-(\\frac {3}{32} +s+n)=0[/tex]\n\n    So since s can be any integer, for every s there is a correspondence established between the set of primes and some subset of the integers, represented by n. If one were searching for a prime in a given interval this last equation could be used with n as a search parameter. The question is will all integer P be prime or will there be pseudo-primes? For a given interval and value for s any primes found should be denoted s-primes. So then are there intervals for which no primes are found unless s is very very large? We would not want to use this equation to search for primes on intervals where the number of possible values for s or n became very large. Those questions would have to be addressed.\n\n    Another question I find interesting here is this. Is it true that\n    [itex]\\{z|z=\\frac {3-RP}{32}, r \\in rrs mod 32, P - prime\\}[/itex] is actually the set of integers? Is it further true that [itex]\\{z|z=\\frac {3-RP}{B}, r \\in rrs mod B, P - prime, gcd(B,P)=1\\}[/itex] is actually the set of integers.\n    Last edited: Jul 15, 2006\n  8. Jul 15, 2006 #7\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Your last (two) questions are trivially false. They are equivalent to the statements that for every integer z, 3-32z is p, a prime, times some number in the reduced residue system mod 32 and that is obviously false.\n\n    You can insert forced spaces in latex with \\ , a slash followed by a space. Things like rrs, mod and prime should be typeset in roman, not in italics. I think we can use \\text{foo} to do that here, or if not the {\\rm foo} might work.\n\n    [tex] \\left\\{ z\\ | z \\in \\mathbb{Z},\\ z=\\frac{3-rp}{32},\\ r \\in \\text{rrs mod} 32, \\ p\\ \\text{prime}\\right\\}[/tex]\n    Last edited: Jul 15, 2006\n  9. Jul 15, 2006 #8\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    This equation isn't hard to solve. There is a solution exactly when p is odd (prime is irrelevant), and in this case it is a unique residue class mod p.\n\n    It's not hard to find either, if p=4n+1 say, then ((p-1)/4)*4=-1 mod p, ((p+3)/4)*4=3 mod p, and one of (p-1)/4 or (p+3)/4 is even, so we know ((p-1)/4)*((p+3)/4)/2 is an integer, and when multiplied by 32 is -3 mod p, so this is our solution. (similar if p=4n+3). All others lie in the same residue class mod p.\n\n    And when it's not, you've got nothing. This is in fact usually the case, for any odd number p, there is only one choice of r out of the 16 that will work.\n\n    Of course you can actually find the only working r if you want, just find the inverse of p mod 32 and multiply by 3. You can find n this way, with the 16 cases for p mod 32. They'll reduce to the above mod 4 considerations, but not before much work.\n\n    You want that to be -p*s in your n, not -s. This is just getting all n in this residue class mod p.\n\n    So you're hoping to fix s and r, then try putting in values of n and hope the reulting p is a prime? Have you actually tried doing this to see what happens? Can you make these p's land in whatever interval you were looking for primes in? Are they often integers, let alone prime?\n  10. Jul 15, 2006 #9\n    No because we are just solving the satandard linear diophantine equation in t and n and the parameter s is multiplied by the gcd of the coefficients which in this case is 1.\n\n    Those last two statements were intended to evoke just the response you gave. What sets are they?\n\n    And if for any odd p one and only one of the residues works for a solution how are the residues ordered by consecutive odd p? Are we talking about all possible permutations that must pass or are we talking about one particular ordering of the residues that is repeated over and over for consecutive odd p.\n\n    I have to praise you though on noticing that it suffices to use p odd and not prime. It is an important point that sometimes by restricting or enlarging perspective we find proofs that may not exist on other sets.\n\n    Just for you and to help allay my blues over not finding a job yet, I am going to sit down and go over that Goldbach proof I was talking about. It will probably fizzle, but I am guessing I am going to end up with a question about the distribution of primes similar to Wilson's Theorem, between p and 2p there is at least one other prime. Only I think it will have ot be more restrictive. I will probably see if you have any insights on that. I'll try to post tomorrow night.\n  11. Jul 16, 2006 #10\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You were looking for solutions n and t of:\n\n\n    Then gave a solution in terms of P and R under the condition 32|(3-RP), these were fine. You then claim for any integer s, t+s and n-s will give a solution as well, but if you sub these in, the left hand side is:\n\n\n    That's not a solution to the equation you are after (unless s=0 of course).\n\n    You'll want to check that theorem on linear diophantine equations again. I think you are after something like:\n\n    if gcd(a,b)|c then ax+by=c has infinitely many solutions. fix any specific solution x_0, y_0 say, then all solutions are given by:\n\n    [tex]x=x_0+\\frac{b}{\\gcd (a,b)}t,\\ y=y_0-\\frac{a}{\\gcd (a,b)}t[/tex]\n\n    as t ranges over the integers. See the difference?\n\n    What response are you talking about?\n\n    Is this about the original equation or after you introduced the 'r'? I'm guessing you're asking about the necessary r's given p's and of course this is cyclic. r depends only on p mod 32 (remember how I said to find this r). You can work out the order easily enough, by hand or mathematica will do it in a second.\n\n    save your praise, it's just elementary facts about linear congurences.\n\n    That's not Wilson's theorem, it's Bertrand's Postulate.\n  12. Aug 5, 2006 #11\n    Thanks for your concise treatment. Let me re-phrase it.\n\n    Let [tex]p = a \\ \\mod \\ 4[/tex],\n\n    Then [tex]\\frac{(p-a)*(p-a+4)}{32}[/tex] is a triangular number, [tex]n[/tex],\n\n    Furthermore for odd p, as all odd numbers are either congruent to 1 or 3[tex]\\mod\\ 4[/tex] and since [tex]1 = -3\\ \\mod\\ 4[/tex], then [tex]32*n = -(3*1) \\ \\mod\\ 4[/tex].\n    Last edited: Aug 5, 2006\n  13. Aug 5, 2006 #12\n    Your right, I confused 2 separate issues.\n\n    Formerly, I was looking for \"a\" mod p such that 4a*(8a+1) = a mod p There is an unique solution for all odd p which reduces to the present problem . For some even p, not all, there are solutions to this former question also.\n\nHave something to add?\n\nSimilar Discussions: 32n + 3 = 0 mod p formula for n\n\n  2. N congruent 3 mod 4 (Replies: 7)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/113477/what-is-expected-number-of-turns-to-play-this-childrens-game/113483\nText:\nTake the 2-minute tour \u00d7\n\nI'm playing this game with children am I'm ready to stab my eyes with an ice pick. It seems like it never ends, but I know I expect it to end. What is my expected number of spins to remove all the fruit from the tree?\n\nGoal: To remove 14 cherries from tree by executing one of following seven directions at random per turn.\n\n 1. Remove 1 cherry.\n 2. Remove 2 cherries.\n 3. Remove 3 cherries.\n 4. Remove 4 cherries.\n 5. Return 1 cherry to tree.\n 6. Return 2 cherries to tree.\n 7. Return all your cherries to tree.\n\nOnce I realized I have a 1/7 chance each turn of playing this game in perpetuity, I started reaching for the kitchen drawer.\n\nshare|improve this question\nSuppose there are 2 cherries on the tree. Does the game end if you roll a 3 or a 4? (ie, if you're asked to remove more cherries than there are left.) \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:32\nYes, if there are two cherries, picking 2,3, or 4 cherries will end the game. \u2013\u00a0 zundarz Feb 26 '12 at 3:35\nAlso, if all 14 cherries are on the tree and you roll a 5, does the tree now have 15 cherries or does nothing happen? \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:36\nIn my solution below, I assume that nothing happens in this case. \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:46\nUm, if there are children threatening you with ice picks, then the statistical properties of some game probably shouldn't be on top of your priority list. \u2013\u00a0 Henning Makholm Feb 26 '12 at 3:48\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nI actually spent some time about a year ago doing some computations for a variant of this game, sold as Hi-Ho Cherry-O. It's identical to your game, except with 10 cherries instead of 14. (I learned about it from a colleague with a 4-year-old daughter.)\n\nThe computation is a nice example of some simple Markov chain techniques, which produce linear equations of the sort in Brett Frankel's answer. I considered the cases of 1 to 4 players, which are amenable to computer solution.\n\nAnother interesting feature is that since the players take turns, the first player has a slight advantage.\n\nHere are the results I got for 10 cherries. If you are really interested, I can try and reconstruct my code and run the 14 cherry case.\n\n1 player game:\n\nExpected length: 15.8019792994073 rounds\n\n2 player game:\n\nExpected number of rounds: 9.58554137805221\nP(player 1 wins) = 0.518720469382215\nP(player 2 wins) = 0.481279530617784\nExpected number of turns = 18.6523622867222\n\n3 player game:\n\nExpected number of rounds: 7.49668096168849\nP(player 1 wins) =  0.357756582790784\nP(player 2 wins) =  0.332728455615310\nP(player 3 wins) =  0.309514961593905\nExpected number of turns: 21.4418012638686\n\n4 player game:\n\nExpected number of rounds: 6.44149249272987\nP(player 1 wins) =  0.276928283784381\nP(player 2 wins) =  0.258099951775544\nP(player 3 wins) =  0.240610168544412\nP(player 4 wins) =  0.224361595895655\nExpected number of turns: 24.1783750474708\n\nEdit: I should also mention some previous work by Jeffrey Humpherys.\n\nshare|improve this answer\nI get $1179248/80915\\approx14.573910894148181$ for $10$ cherries, yet the same as DSM for $14$ cherries. Are you sure you used exactly the same rules (especially when there aren't enough cherries to remove or to return)? \u2013\u00a0 joriki Feb 26 '12 at 5:22\n@joriki: DSM's answer is now deleted, but I believe the rule I used is that when there aren't enough cherries, you add or remove as many as possible. E.g. if you have only one cherry in your bucket and spin a 6, you return that one cherry to your tree. Again, I unfortunately only saved pieces of my code, so I can't check it, but perhaps if I have some time in the near future I'll reconstruct it. \u2013\u00a0 Nate Eldredge Feb 26 '12 at 14:16\nNate E.: The game is Hi-Ho-Cherry-Oh. It seems like 14 cherries!! After I removed the ice-picks from my eyes, I recounted and there are just 10 cherries. \u2013\u00a0 zundarz Feb 26 '12 at 14:26\nI've resolved the discrepancy between our results; see my answer. \u2013\u00a0 joriki Feb 27 '12 at 12:35\n\nYou can solve via a series of 14 linear equations: Let $E_n$ be the expected number of turns remaining until the game is over when there are currently $n$ cherries on the tree. For example, $$E_1=\\frac{4}{7}1+\\frac{1}{7}(1+E_2)+\\frac{1}{7}(1+E_3)+\\frac{1}{7}(1+E_{14})$$\n\n\nBy the time you finish writing down all 14 equations and solving, the game may well be over. (Then again, I expect the answer will be quite large).\n\nshare|improve this answer\n\nI've found the reason for the discrepancy between Nate's answer and my results (which agree with DSM's). In the version of the game that Nate linked to, the dog and the bird both require you to return $2$ cherries to the tree, whereas in the present version 5. says one cherry and only 6. says two cherries. If I change my code to the linked version my result for the expected number of turns is in agreement with Nate's. For the present version, I get\n\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/12139/number-of-relations-that-are-both-symmetric-and-reflexive\nText:\nTake the 2-minute tour \u00d7\n\nConsider a non-empty set A containing n objects. How many relations on A are both symmetric and reflexive?\n\nThe answer to this is $2^p$ where $p=$ $n \\choose 2$. However, I dont understand why this is so. Can anyone explain this?\n\nshare|improve this question\nthis is not (number-theory); just because it numbers does not make it number theory. It's about counting, so it's combinatorics. \u2013\u00a0 Arturo Magidin Nov 27 '10 at 23:40\n\n5 Answers 5\n\nup vote 12 down vote accepted\n\nTo be reflexive, it must include all pairs $(a,a)$ with $a\\in A$. To be symmetric, whenever it includes a pair $(a,b)$, it must include the pair $(b,a)$. So it amounts to choosing which $2$-element subsets from $A$ will correspond to associated pairs. If you pick a subset $\\{a,b\\}$ with two elements, it corresponds to adding both $(a,b)$ and $(b,a)$ to your relation.\n\nHow many $2$-element subsets does $A$ have? Since $A$ has $n$ elements, it has exactly $\\binom{n}{2}$ subsets of size $2$.\n\nSo now you want to pick a collection of subsets of $2$-elements. There are $\\binom{n}{2}$ of them, and you can either pick or not pick each of them. So you have $2^{\\binom{n}{2}}$ ways of picking the pairs of distinct elements that will be related.\n\nshare|improve this answer\n\nBeing reflexive means that $(x,x)\\in R$ for all $x\\in A$. Being symmetric means that $(x,y)\\in R$ implies that $(y,x)\\in R$ as well.\n\nBegin by listing $A$ as $A=\\{a_1,\\dots,a_n\\}$. Then let $B$ be the set $$\\{(a_i,a_j)\\mid 1\\le i<j\\le n\\}.$$ Note that if $x\\ne y$ are elements of $A$, then either $(x,y)\\in B$ or $(y,x)\\in B$ but not both.\n\nLet $S$ be any subset of $B$. Let $$R_S=S\\cup\\{(y,x)\\mid (x,y)\\in S\\}\\cup\\{(x,x)\\mid x\\in A\\}.$$ Then $R_S$ is a symmetric and reflexive relation on $A$.\n\nNote that there are $2^{|B|}$ subsets of $B$, and that if $S\\ne S'$ are subsets of $B$, then $R_S\\ne R_{S'}$. Also, note that $|B|=\\binom{n}2$. (If the last equality is not clear, note that $$B=\\{(a_1,a_j)\\mid j>1\\}\\cup\\{(a_2,a_j)\\mid j>2\\}\\cup\\dots$$ so $|B|=(n-1)+(n-2)+\\dots+1$, and it is well-known that the last sum equals $n(n-1)/2=\\binom n2$.\n\nThis shows that the number of symmetric, reflexive relations on $A$ is at least $2^p$ with $p=\\binom n2$.\n\nTo see the equality, it is enough to check that any such relation $R$ is $R_S$ for some $S\\subseteq B$. But, given $R$, let $S=\\{(a_i,a_j)\\in R\\mid i<j\\}$. This is a subset of $B$, and it is easy to check that $R=R_S$.\n\nshare|improve this answer\n\nMaybe you can see it like this: a relation $R$ on $A$ is a subset of $A\\times A$, and it is symmetric if and only if $(x,y)\\in R \\implies (y,x)\\in R$, moreover, if the relation is reflexive, then $(x,x)\\in R$ for all $x\\in A$. Then you can determine uniquely such a relation by saying which subsets of two distinct elements of $A$ \"belong\" to $R$, in the sense that $\\{x,y\\}\\in R \\iff (x,y),(y,x)\\in R$. Now, you know that the number of subsets with two distinct elements of $A$ is $\\binom{n}{2}$, and the number of subset of a set with $p$ elements is $2^p$. I'm sorry if i was too obscure.\n\nshare|improve this answer\nI had not seen that Arturo Magidin had already answered, so that i gave almost an equal explanation. Sorry again (for my bad english too!). \u2013\u00a0 Daniele A Nov 27 '10 at 23:55\n\nYou can also think of it as a matrix of $nxn$, with the elements of the matrix being $(a_i,a_j)$ with $ a_i,a_j \\in A$. The elements of the main diagonal have to be included in R because R is reflexive. For the remaining $n^2-n$, picking a pair from the upper triangle say $(a_2,a_1)$ implies that you are also picking $(a_1,a_2)$. So in reality you only have $\\frac{n^2-n}{2}$ elements to pick from. This can be done in $2^{\\frac{n^2-n}{2}}$ ways.\n\nshare|improve this answer\n\nThere is only one way to make the relation reflexive -- all ordered pairs $(x,x), x\\in A$ must be in the relation. So the number of reflexive symmetric relations on $A$ is the same as the number of ways of adding symmetric pairs $(a,b),(b,a)$, where $a\\neq b$ into the relation.\n\nLet $S$ be a subset of $2^A$ consisting of subsets of 2 elements. Then $S$ gives rise to exactly one reflexive symmetric relation on $A$. For example, if $A=\\lbrace 1,2,3,4\\rbrace$, then an example of $S$ is $\\lbrace \\lbrace 1,2\\rbrace, \\lbrace 1,4\\rbrace, \\lbrace 3,2\\rbrace\\rbrace$. The relation induced by $S$ is $$\\lbrace (1,2), (2,1), (1,4), (4,1), (2,3), (3,2)\\rbrace$$ plus all $(x,x), x\\in A$. Conversely, every reflexive symmetric relation on $A$ arises in this way.\n\nSince there are $p={n\\choose 2}$ subsets of 2 elements, there are $2^p$ such $S$'s. The answer to your question is therefore $2^p$.\n\nshare|improve this answer\nI think this is not quite right. If the number of reflexive symmetric relations on $A$ were the same as the number of symmetric relations on $A$, then every symmetric relation would have to be reflexive. \u2013\u00a0 Rahul Nov 28 '10 at 2:00\n@Rahul. I have edited my post. \u2013\u00a0 TCL Nov 28 '10 at 3:42\nI just noticed that I had a $-1$ on my reputation. In checking it out, I found out that apparently I downvoted this two days ago. I don't remember this question/answer at all, and I certainly wouldn't have marked this (correct, well written) answer down intentionally. So, I apologize. If this is important to you, edit the answer (so I can revote), and then ping me. Sorry! \u2013\u00a0 Jason DeVito Apr 19 '14 at 19:51\n@DeVito.I have just edited it. \u2013\u00a0 TCL Apr 21 '14 at 14:54\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/147320/how-to-give-a-group-structure\nText:\nTake the 2-minute tour \u00d7\n\nsuppose you have two sets $G_1$ and $G_2$ with same cardinality\n\nin $G_2$ you have the group structure and there is a bijective map from $G_1$ to $G_2$ this is just a set map. can we define a binary operation on $G_1$ with the help of binary operation on $G_2$ so that $G_1$ also become a group?\n\nshare|improve this question\nThis is a standard \"transport of structure\" argument. Conceptually, $G_1$ and $G_2$ are the \"same\" for all (non-set-theoretic) intents and purposes because they are in bijection. \u2013\u00a0 Zhen Lin May 20 '12 at 10:31\nYes. If $f:G_1\\to G_2$ is the given bijection, then letting $\\circ_1$ be defined by $x\\circ_1 y=f^{-1}(f(x)\\circ_2 f(y))$ gives you a group structure on $G_1$. \u2013\u00a0 Michael Greinecker May 20 '12 at 10:32\nbut how I will be sure that $x._1y$ is in $G_1$?I mean closoure property holds? \u2013\u00a0 La Belle Noiseuse May 20 '12 at 10:38\nI don't see your problem. $f(x)$ and $f(y)$ are in $G_2$, so $f(x)circ_2 f(y)$ is in $G_2$, since $G_2$ has a group structure. And since $f$ is bijective, $f^{-1}(f(x)circ_2 f(y))$ is a unique element in $G_1$. \u2013\u00a0 Michael Greinecker May 20 '12 at 10:41\nthank you dear sir :) \u2013\u00a0 La Belle Noiseuse May 20 '12 at 10:42\n\n1 Answer 1\n\nup vote 6 down vote accepted\n\nHINT: There\u2019s really only one reasonable thing to try, and it works. Let $f:G_1\\to G_2$ be your bijection, and let $\\cdot$ be the group operation in $G_2$. You want to use $f$ to define a group operation $\\odot$ on $G_1$. Suppose that $x,y\\in G_1$; what would $x\\odot y$ have to be in order for $f$ to be a group isomorphism?\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/95626/prove-that-lr-is-context-free-without-alphabet/95630\nText:\nI'm stuck with this problem:\n\nGiven $L$ a CFL on the alphabet $\\Sigma$. Prove that $L^r=\\{x^r|x\\in L\\}$, where for each $a\\in\\Sigma$ and $y\\in\\Sigma^*$, $$\\epsilon^r=\\epsilon,$$ $$(ay)^r=y^ra,$$ is context free or not.\n\nSince I don't have the alphabet I cannot think of a grammar that generates this language, so I decided to prove that it's not context free by applying the pumping lemma for CFL. So I started with the hypothesis that $L^r$ is context free, thus if $x\\in L^r$ that $x^r\\in L$.\n\nThen I tried to find different possible strings that once pumped didn't belong anymore to $L^r$, but I'm not able to find such string.\n\nIs this a bad aproach? Where am I wrong?\n\n\nInformally, by construction $L^r$ consists of the strings in $L$ reversed. Since $L$ is context-free, it has a Grammar in Chomsky normal form. All production rules in this grammar will fall in one of three classes:\n\n  1. $A \\rightarrow BC$\n  2. $A \\rightarrow a$\n  3. $S \\rightarrow \u03b5$\n\nThus by reversing the order of non-terminals in the RHS of all rules of category 1., a new grammar can be derived that produces $L^r$.\n\nThis new grammar is also in Chomsky normal form, thus $L^r$ is context-free.\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Oh! I was so wrong... Anyway, thank you very much now I understand. $\\endgroup$ \u2013\u00a0tokenizer Jul 26 '18 at 10:18\n  \u2022 $\\begingroup$ There is absolutely no need to use CNF here. Any context-free grammar would do. $\\endgroup$ \u2013\u00a0Yuval Filmus Jul 26 '18 at 18:24\n\nYour Answer"}
{"text": "Retrieved from https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:properties-of-matrix-multiplication/v/matrix-expressions\nText:\nMain content\nCurrent time:0:00Total duration:3:30\n\nUsing properties of matrix\u00a0operations\n\nVideo transcript\n\nVoiceover:In order to get into Battle School cadets have to pass a rigorous entrance exam which includes mathematics. Help Commander Graff grade the next wave of students' tests. The last step of a problem in the matrix multiplication section is the matrix A times B times C where A, B, and C are square matrices. Which of the following candidates have answers that are equivalent to this expression? Select all who are right for any A, B, and C. Select all that apply. I encourage you to pause this video and think about it. Which of these expressions for any square matrices A, B, and C are equivalent to this right over here. I'm assuming you've given a go at it. Let's think through each of them. This one is B, A, C so if they have changed the order and we've already seen that matrix multiplication is not commutative in general and so this will not be true for any square set of matrices A, B, and C, so this is not going to be true. Matrix multiplication is not commutative. Here you have Bernard, who says A times, C times B. We already know that that's going to be the equivalent to A, C, B which once again they've swapped the order between the B and the C, matrix multiplication is not commutative. You can't just swap order and expect to get the same product for any square matrices A, B, and C so we could rule that one out. A times, B, C, so we've already seen matrix multiplication is associative, so this is the same thing as A times B, times C which of course is the same thing as A, B, C. What Caren has right over here, that is right, that is equivalent for any square matrices A, B, and C that is equivalent to A, B, C. Now Ducheval, let's see, now this looks like a bit of a crazy expression but let's think it through a little bit. First of all matrix multiplication, as long as you keep the order right, the distributive property does hold. This first part right over here is equivalent to ... Let me write this down, this one's interesting. We have A times B, C plus A, minus A squared. You can actually distribute this A and I encourage you to prove it for yourself maybe using some two by two matrices for simplicity. This is going to be equal to, this part over here is going to be A, B, C plus A A, A times A which we could write as A squared and then we're going to subtract A squared. These two things are going to cancel out, they're going to end up being the zero matrix and if you take the zero, so these are going to be the zero matrix right over here. If you take the zero matrix and add it to A, B, C you're just going to end up with A, B, C. This one was a little bit tricky, this one actually is equivalent. This one is right and this one is right. Here this is A times B, plus C so this is kind of not-y right over here. They're not even multiplying B and C, so this one's definitely not going to be true for all square matrices A, B, and C."}
{"text": "Retrieved from http://www.riddlesandanswers.com/v/229407/once-upon-a-time-there-lived-a-king-who-wished-to-find-the-wisest-man-in-the-realm-to-be-his-assista/\nText:\nTrending Tags\n\nPopular Searches\n\nTerms \u00b7 Privacy \u00b7 Contact\nRiddles and Answers \u00a9 2020\n\nThe Red Hat\n\nOnce upon a time there lived a king who wished to find the wisest man in the realm to be his assistant. He summons the 3 known wisest men to his court and he administers the following test.\n\nHe sits them in a circle, facing each other and he says Im going to put either a red hat or a white hat on each of your heads. He proceeds to place a red hat on each of their heads. Obviously they can see each other but there are no mirrors in the room so they cant see whats on their heads. He says If you can see a red hat, raise your hand. They all raise their hands. Then he says If you can tell what color hat you have on, stand up.\n\nTime goes on, one guy looks at another guy, he looks at the other guy. The other guy looks at him. Finally one guy stands up. The question is how did he know he was wearing a red hat?\nHint: For a moment or two, nobody moved. Nobody knew for certain what color his hat was, and thats what told the wisest guy that all of the hats were red.\nStep 1:\nWiseguy #1 knows he can see two red hats.\n\nStep 2:\nWiseguy #1 thinks, \"Hey, if I were wearing a white hat, Wiseguy #2 would see one red hat and one white.\"\n\nStep 3:\nWiseguy #1 then thinks, \"If I were wearing a white hat, and Wiseguy #2 saw one red hat and one white (and if he were wearing a white hat himself), then Wiseguy #3 would have seen two white hats. So, Wiseguy #3 wouldnt have raised his hand to the first question.\n\nWiseguy #1 thinks, \"If that were true, Wiseguy #2 would be sure that he had a red hat. But since Wiseguy #2 was actually unsure about his hat color, it can only mean one thing, my hat is red.\"\nDid you answer this riddle correctly?\n\nAdd Your Riddle Here"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/45438/can-a-red-black-tree-be-constructed-of-only-black-nodes-using-rb-insert-only\nText:\nI am trying to construct a red black tree out of only black nodes. I know it is possible getting it after some deletions but I am trying to construct one only via insertion orders. Is it possible? I couldn't find a way to do so , so far even after trying to use the simulator.\n\n*** exept of a root node being added to an empty tree.\n\n  \u2022 1\n    $\\begingroup$ What have you tried? Have you tried working through some very small examples (say, exhaustively enumerating all possible insertion orders for trees of size 1, 2, and 3)? Have you tried to find a proof that it is impossible? Have you tried looking for suitable invariants that would imply it is impossible? $\\endgroup$ \u2013\u00a0D.W. Aug 20 '15 at 17:01\n  \u2022 $\\begingroup$ Hello and thank you for your comment. I have tried to do so. I couldn't find any invariants though. Can I assume it is impossible since we always insert a red node and thus an only black nodes tree is impossible to construst without a deletion after an insertion? The balancing menipulations taken on the nodes ( rotations and recoloring) don't allow that \"only black\" situtaion ( not reffering a single node tree). $\\endgroup$ \u2013\u00a0user118972 Aug 20 '15 at 17:09\n  \u2022 $\\begingroup$ I am quite convinced after trying a lot of diferent insertions that it isn't possible but I can't find the invariant. $\\endgroup$ \u2013\u00a0user118972 Aug 20 '15 at 17:19\n  \u2022 $\\begingroup$ Hints: 1) Can you quickly name a tree shape that allows you to color everything black? 2) Given any (balanced) target shape, what is a simple insertion order to obtain exactly that shape? $\\endgroup$ \u2013\u00a0Raphael Aug 20 '15 at 17:57\n  \u2022 $\\begingroup$ RBT have properties you must obey. Which of those could be violated? When? $\\endgroup$ \u2013\u00a0Evil Aug 20 '15 at 18:12\n\nProperties of Red Black Tree:\n\n0) Every node is black or red. Ok, no problem.\n\n1) Root is black. Ok, no problem.\n\n2) All leaves (empty nodes) are black. Ok, no problem.\n\n3) Every red node must have two black childs. Ok, no problem.\n\n4) Every path from any node to leaf has equal number of black nodes. It seems problematic.\n\nSo now comes problems: When you insert element it's color is red. (In fact this not comes from properties but observation that adding red node does not violate $4$th rule, so it is easier to implement).\n\nSo for start you add one element, let me say 10. It is black root. Ok.\n\nNow You add 13. It must be red, otherwise it violates rule 4.\n\nRed Black Tree elements 10; 13\n\nNow you add 19. Depending on implementation you can leave all black, or recolor.\n\nRed Black Tree elements 10; 13; 19\n\nNow adding 12 gives recoloring and comes red.\n\nRed Black Tree elements 10; 13; 19; 12\n\nAnd after several numbers\n\nRed Black Tree elements 10; 13; 19; 12; 41; 43; 26; 10; 82\n\nAnd now it starts nightmare, as you should propagate changes from one side of tree to another convincing somehow that you will change everything to black after insertion.\n\nBasically I asked you about rules to obey, as it comes to mind that with $4$th can be fulfilled only in perfectly balanced trees.\n\nSo to answer your questions:\n\nNo you cannot with common implementations of RBT, but extending balance operation to recolor when it is possible - it does not violate rules, so it is possible. Also with extension that whenever there is $n = 2^k - 1$ nodes, restructure it to perfectly balanced tree and recolor everything to black, it would be also possible.\n\nI did firstly answer \"no\" as purpose of balancing operation is to guarantee bound on worst case search / insert, and such extensions comes at price of time complexity. It does not violate rules, but is not implicitly implemented in standard RBT.\n\nGiven only root, you have it. Given three nodes inserted in order with implementation changing all to black (rather rare case and counterproductive), you can. But this is last one that is without deletions possible.\n\nWhen you are about to insert element and want all tree to be black that would mean there is violated rule $4$ (so not possible) or you have to rebalance tree, which would recolor nodes, so it is not pure black anymore.\n\nWith deletions on the other hand ;)\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Well, for $n=2^k$ you can. :) $\\endgroup$ \u2013\u00a0Raphael Aug 21 '15 at 16:34\n  \u2022 $\\begingroup$ Well, not by only insertions ;) And recoloring is possible, but it needs traversing whole tree. Otherwise, if we implement such feature that perfectly balanced tree we switch all colors to black, then yes. But not for $n = 2^k$ as it must have one red node, but $n = 2^k -1$ $\\endgroup$ \u2013\u00a0Evil Aug 21 '15 at 16:37\n  \u2022 $\\begingroup$ Right, wrong $n$. :D I understand the question to ask for the final tree being all black. Inserting the values in breadth-first order definitely gets the right shape; whether all nodes are black probably depends on the implementation (they all can be). $\\endgroup$ \u2013\u00a0Raphael Aug 21 '15 at 16:40\n  \u2022 $\\begingroup$ BFS is just level ordering, ok I am mixing two things one is impementation dependence - and one is recoloring. $n = 2^k - 1$ nodes and then it can be all black, but none existing implementation has it. $\\endgroup$ \u2013\u00a0Evil Aug 21 '15 at 16:57\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/137077/spreading-out-integers-via-multiplication\nText:\nLet $a_1,...,a_n\\in [0,m]$ be a set of $n$ positive integers, where $n<<m$, $m=poly(n)$. One can assume $m$ is prime. Is there an efficient, possibly randomized, way to find an integer $N=poly(n)$, such that $(a_i \\cdot N) (mod \\ m)$ is approximately uniform on $[0,m]$. The value of $N$ may also depend on the approximation parameter.\n\n  \u2022 $\\begingroup$ Should there be some additional hypothesis to prevent, for example, the situation where all the $a_i$ are equal? $\\endgroup$ \u2013\u00a0Andreas Blass Jul 18 '13 at 14:52\n  \u2022 $\\begingroup$ Yes, let's assume they are all different. $\\endgroup$ \u2013\u00a0Lior Eldar Jul 18 '13 at 15:04\n  \u2022 $\\begingroup$ \"All different\" won't work because there are $n$ of the integers $a_i$'s, all in $[0,m]$ with $m < n$ $\\endgroup$ \u2013\u00a0Andreas Blass Jul 18 '13 at 15:08\n  \u2022 $\\begingroup$ Of corse! - fixed the mistake above. $\\endgroup$ \u2013\u00a0Lior Eldar Jul 18 '13 at 15:49\n\nChoosing $N$ at random and checking should work. Put $e(t)=e^{2\\pi i t/m}$. Then we have \\begin{eqnarray*} \\sum_{N=1}^m\\sum_{k=1}^K\\left|\\sum_{i=1}^ne(k N a_i)\\right|^2 & = & \\sum_{N=1}^m\\sum_{k=1}^K\\sum_1\\leq i,j\\leq n e(kN(a_i-a_j))\\\\ & = & m\\sum_{k\\leq K} \\#\\{(i,j)|a_i\\equiv a_j\\pmod{\\frac{m}{(m, k)}}\\}. \\end{eqnarray*} Since the $a_i$ are all different and in $[0, m]$, for fixed $a_i$ the number of $a_j$ satisfying the last congruence is $(m,k)$ at most, and the last sum is bounded above by $mn\\sum_{k\\leq K}(k,m)\\leq mnK^2$.\n\nDenote by $D_N$ the discrepancy of $a_iN\\bmod m$. Then we have $$ D_N\\ll \\frac{n}{K}+\\sum_{k\\leq K}\\frac{1}{k}\\left|\\sum_{i=1}^n e(kNa_i)\\right|, $$ thus $$ \\frac{1}{m}\\sum_{N=1}^m D_N \\ll \\frac{n}{K} + \\sqrt{nK}\\log K. $$ Hence for most $N$ we have $D_N\\ll n^{2/3}\\log n$, which is reasonable good equidistribution.\n\nChecking whether for a random $N$ we have that $D_N<n$ is small requires between $n^{1+\\epsilon}$ and $n^{3/2}$ steps, depending on how small $D_N$ has to be.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/86019/how-can-i-partially-evaluate-a-function/86031\nText:\nI have a multivariable function, from which I'd like to define a marginalization:\n\nf(a,b,c,d,...,z) ---> g(a,1,c,d,...,z)\n\nGenerally, g will have fewer argument than f, possibly none (full evaluation). Is it possible to take the output of a function and transform it into a second function?\n\nThis is part of a looped Block[] segment in a larger code, where the number of variables, slot positions, and their values are specified anew on each iteration.\n\nHere is my best failed attempt:\n\nPartialEvaluate[func_, totargs_, args_, targets_] :=\n\nBlock[{tmp, g, r},\n\ntmp = Table[Slot[i], {i, 1, totargs}];\n\nDo[tmp[[targets[[slot]]]] = args[[slot]];, {slot, 1, Length[targets]}];\n\ng = Function[func @@ tmp]\n\n\n\n  \u2022 2\n    $\\begingroup$ g[a_,c_]:= f[a, 1, c]? $\\endgroup$ \u2013\u00a0Dr. belisarius Jun 16 '15 at 0:58\n  \u2022 $\\begingroup$ How are the variables specified? $\\endgroup$ \u2013\u00a0C. E. Jun 16 '15 at 1:02\n  \u2022 $\\begingroup$ I've updated the post with an example. $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 1:09\n  \u2022 1\n    $\\begingroup$ You mean partial application? $\\endgroup$ \u2013\u00a0ciao Jun 16 '15 at 1:24\n  \u2022 $\\begingroup$ Somewhat related: mathematica.stackexchange.com/q/48137/7936 $\\endgroup$ \u2013\u00a0evanb Jan 14 '17 at 9:11\n\nUpdated version\n\nTo be more in line with what the OP wanted, we have the following updated code. Given inputs (in order) g, totargs = 5, args = {x[1],x[4]}, and targets = {1,4}, if we call the function\n\npartialEvaluate[func_, totargs_, args_, targets_] := Block[{argsEvaluated = 1, newArgs = 1}\n , Evaluate[func @@ Table[\n    If[MemberQ[targets, i], args[[argsEvaluated++]], Slot[newArgs++]]\n    , {i, 1, totargs}]\n   ] &\n\nthe result is\n\ng[x[1], #1, #2, x[4], #3] &\n\nThe main reason the OP's original code didn't work is that Function has the Attribute HoldAll:\n\n(* {HoldAll, Protected} *)\n\nIf you want the insides of Function to be evaluated, you have to explicitly Evaluate it, as I've done.\n\nOriginal post\n\nI'm not sure of exactly what the inputs and outputs should be, but here's my best guess as to what you want, with minimal changes to your code. For the purpose of concreteness, let's suppose that totargs = 5, args = {x[1],x[2],x[3],x[4],x[5]}, and the target variables to which the function is going to be applied to are targets = {1,4}. Then if we call the function\n\npartialEvaluate[func_, totargs_, args_, targets_] := Block[{tmp}\n  ; tmp[[targets]] = args[[targets]]\n  ; Evaluate[func @@ tmp] &\n\nwith the input\n\npartialEvaluate[g, 5, {x[1], x[2], x[3], x[4], x[5]}, {1, 4}]\n\nwe get the pure function\n\ng[x[1], #2, #3, x[4], #5] &\n| improve this answer | |\n  \u2022 $\\begingroup$ This is what I was looking for, thank you! $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 4:25\n  \u2022 $\\begingroup$ Thank you for the accept! However, are you sure? Is it possible that what you actually want is g[x[1], #1, #2, x[4], #3] &? Because I imagine you will want to apply this new function to a three-element list, rather than still a five element list. If so, I can update with a new version that returns this alternative version $\\endgroup$ \u2013\u00a0march Jun 16 '15 at 5:09\n  \u2022 $\\begingroup$ Ah, I forgot to share. I added a simple j=1;Do[If[tmp[[i]]==Slot[i],tmp[[i]]=Slot[j++],{i,Range[totargs]}] fix. before the evaluation step. Share your solution anyway, it's probably more clever! $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 5:43\n  \u2022 $\\begingroup$ That's essentially what I did, actually, but I'll post anyway, since it's slightly cleaner. $\\endgroup$ \u2013\u00a0march Jun 16 '15 at 5:47\n  \u2022 $\\begingroup$ A pedantic difference, but my ugly do loop was to account for a Length[args]=Length[targets] constraint which I didn't mention earlier. Thanks a lot for your help. $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 5:51\n\nSince mathematica does not use currying evaluation like language like haskell, you should do the currying for partial evaluation by yourself.\n\nHere is some simple example:\n\nIn[1]:= addx[x_] := Function[y, x + y]\nIn[2]:= addx[3][4]\nOut[2]:= 7\nIn[3]:= add3 = addx[3]\nOut[3]:= Function[y$, 3 + y$]\nIn[4]:= add3[4]\nOut[4]:= 7\n\nIn general, you should make the function you want to partial evaluate take arguments and return another function which take the remaining arguments. And then you can pass few arguments to the function and you will get another function which can be applied to the remaining arguments.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Thanks for your suggestion, didn't know about 'currying'. Unfortunately the structure of func is fixed by other elements of the larger code. I was hoping to find a solution to the problem as I posted it above. it is sufficiently general and presumably will be simple to solve. but I'm not sure why the application of the Function fails to recruit the slots in the output of Apply [func]. $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 3:16\n\nMarch's version is problematic: in case the original function uses itself pure functions in its definition then this can lead to unintended results and errors. Consider the following example:\n\nfoo[x_,y_] := (x #)& /@ {x,y}\n\nPartial evaluation of foo with the second argument set to three should result in a function that is equivalent to:\n\nfooPartial[x_] := (x #)& /@ {x,3}\n\nIf we now use march's method for partial evaluation we get the following pure function\n\n{#1^2, 9}&\n\nwhich is equivalent to\n\nfooPartialWrong[x_] := (# #)& /@ {x,3}\n\nwhich is not equivalent to fooPartial! The problem is that the #'s in the argument of foo and in the definition get mixed up.\n\nA further problem (probably even more problematic in this case) is that Evaluate \"breaks\" scoping\n\nIn[1]:= x = 3                                                                   \n\nOut[1]= 3\n\nIn[2]:= foo2[x_,y_]:= Evaluate[x y]                                              \n\nIn[3]:= ?foo2                                                                    \n\nfoo2[x_, y_] := 3*y\n\nA better method is to exploit the fact that List does not have the attribute HoldAll (see Enforcing correct variable bindings and avoiding renamings for conflicting variables in nested scoping constructs):\n\nModule[{x},SetDelayed @@ {fooPartial[x_],foo[x,3]}]\n\nIn rewriting partialEvaluate one cannot use Module as above since the number of variables scoped by Module is fixed, so I use Unique instead to avoid side-effects.\n\npartialEvaluate2[func_, funcPartial_, totargs_, args_, targets_] :=\n Module[{num1 = 1,num2 = 1,variablesNames,variablesNamesUnderscore},\n  variablesNames = Unique /@ ConstantArray[\"x\",totargs - Length[args]];\n  variablesNamesUnderscore = Pattern[#,Blank[]]& /@ variablesNames;\n  SetDelayed @@ {funcPartial@@variablesNamesUnderscore, func @@ Table[\n    If[MemberQ[targets, i], args[[num1++]], variablesNames[[num2++]]],\n    {i, 1, totargs}]}\n\nAnd we now get as desired:\n\nIn[1]:= partialEvaluate2[foo,fooPartial,2,{3},{2}] \nIn[2]:= ?fooPartial                                                                                                                           \n\nfooPartial[x31_] := {x31^2, 3*x31}\n| improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/261812/vectors-that-are-almost-orthogonal-on-average-lower-bounds-on-dimension/261821\nText:\nLet $v_1,\\dotsc,v_k \\in \\mathbb{R}^d$ be unit-length vectors such that $$\\sum_{1\\leq i,j\\leq k} |\\langle v_i,v_j\\rangle|^2 \\leq \\epsilon k^2.$$ What sort of lower bound can we give on $d$ in terms of $k$ and $\\epsilon$?\n\nMust it be the case that $d\\gg \\min(\\log k,\\epsilon^{-1})$, say, or anything of the sort? Is that tight?\n\n  \u2022 $\\begingroup$ I guess a more flexible reformulation is to let $v_1,\\ldots,v_k$ be unit-length vectors in some vector space of large (infinite?) dimension, and ask for a lower bound on the dimension of their span given the almost-orthogonal condition. $\\endgroup$ \u2013\u00a0Peter Humphries Feb 9 '17 at 22:05\n  \u2022 1\n    $\\begingroup$ Isn't this equivalent? $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 22:12\n  \u2022 $\\begingroup$ Yes of course.. $\\endgroup$ \u2013\u00a0Peter Humphries Feb 9 '17 at 22:13\n\nThe Johnson Lindenstrauss Lemma states that there are $k$ vectors achieving $\\epsilon$ provided $d\\geq C \\epsilon^{-2} \\log k.$\n\nIf you actually want to bound the maximum absolute value of the inner product for distinct vectors, instead of the average as you stated which is of course stronger, then tighter bounds apply.\n\nRelevant results for this case are due to Welch, Kabatianski, Levenshtein, Sidelnikov. Welch's applies to arbitrary vectors, real or complex. The others apply to vectors constructed from complex roots of unity of some finite order. Welch's bound states\n\nLet $e\\geq 1$ be an integer and let $a_1,\\ldots,a_k$ be distinct vectors in $\\mathbb{C}^d.$ Then the following inequalities hold $$ \\sum_{i=1}^k \\sum_{j=1}^k \\left| \\langle a_i, a_j \\rangle \\right|^{2e} \\geq \\frac{\\left(\\sum_{i=1}^k \\lVert a_i \\rVert^{2e}\\right)^2}{\\binom{d+e-1}{e}}, $$ If the set of vectors you are interested in is of size roughly $d^u,$ the tightest lower bound is obtained by choosing $e=\\lfloor u\\rfloor.$\n\n\nSince you required $\\langle a_i,a_i\\rangle=1,1\\leq i\\leq k,$ if I subtract the diagonal inner products, I obtain $$ \\sum_{1\\leq i\\neq j\\leq k} \\left| \\langle a_i, a_j \\rangle \\right|^{2} \\geq \\frac{k^2-kd}{d}, $$ recovering the dependence on $k.$\n\nEdit 2:\n\nThe Johnson Lindenstrauss Lemma is tight up to a constant factor. The Welch bound is tight for some cases, when so-called Welch Bound with Equality sets of vectors exist, which correspond to all unequal innner products being the same in absolute value.\n\n\nV.M. Sidelnikov, On mutual correlation of sequences, Soviet Math Dokl. 12:197-201, 1971.\n\nV.M. Sidelnikov, Cross correlation of sequences, Problemy Kybernitiki, 24:15-42, 1971 (in Russian)\n\nWelch, L.R. Lower Bounds on the Maximum Cross Correlation of Signals. IEEE Transactions on Information Theory. 20 (3): 397\u2013399, 1974.\n\nKabatianskii, G. A.; Levenshtein, V. I. Bounds for packings on the sphere and in space. (Russian) Problemy Pereda\u010di Informacii 14 (1978), no. 1, 3\u201325. (A version of this might be available in English translation, in Problems of Information Transmission)\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Wait. Doesn't the inequality you cite as Welch's imply that $d\\geq \\epsilon^{-1}$, with no dependence on $k$? This seems a little too strong. $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 23:13\n  \u2022 $\\begingroup$ @HAHelfgott, please see edit. $\\endgroup$ \u2013\u00a0kodlu Feb 9 '17 at 23:31\n  \u2022 $\\begingroup$ Thanks. That answers the question, then. But how far is it from being tight? Is the Johnson Lindenstrauss Lemma tight? $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 23:52\n  \u2022 1\n    $\\begingroup$ As I pointed out earlier in a now deleted comment, we can (trivially) achieve the bound for a given $\\epsilon$ without any real size restrictions on $k$ if $d\\ge\\epsilon^{-1}$ by just repeating an ONB of $\\mathbb R^d$. (I guess it would be more honest to say that if $d$ is very close to $\\epsilon^{-1}$, then $k$ should be a multiple of $d$ to be safe.) $\\endgroup$ \u2013\u00a0Christian Remling Feb 10 '17 at 1:51\n  \u2022 $\\begingroup$ May you give references to \"Welch, Kabatianski, Levenshtein, Sidelnikov\", please. $\\endgroup$ \u2013\u00a0Sergei Feb 11 '17 at 5:37\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/295300/recurrence-finding-asymptotic-bounds-for-tn-tn-2-n2\nText:\nTake the 2-minute tour \u00d7\n\nI've been working on a problem set for a bit now and I seem to have gotten the master method down for recurrence examples. However, I find myself having difficulties with other methods (recurrence trees, substitution). here is the question I am stuck on: $$T(n) = T(n-2) + n^2$$ Is there a pattern as follows? $$n^2 + T(n-2) + T(n-4) +...$$ where it goes until there is no more n left. so around n/2 times and would that mean that $$n^2 + (n-2)^2 + (n-i) ^2$$ so the asymptotic bound would be $\\theta(n^2)$?\n\nI am honestly taking a shot in the dark here, so I was hoping someone could help guide me in how to approach these questions.\n\nThank you,\n\n\nshare|improve this question\nperhaps an indirect answer would even do, something to show how to solve questions of form t(n-i) + f(n) \u2013\u00a0 Tyler Feb 5 '13 at 9:31\n\n2 Answers 2\n\n$$T(n) = T(n-2) + n^2 = T(n-4) + (n-2)^2 + n^2 = T(n-2k) + \\sum\\limits_{i = 0}^{k - 1}(n - 2i)^2$$\n\nThis goes down till $n - 2k \\ge 0$. Assuming even $n$ (for asymptotic complexity, it does not really matter, and you can do similar calculations for odd $n$ also, with the same asymptotic results), we have $k = \\frac{n}{2}$ at the end.\n\n$$T(n) = T(0) + \\sum\\limits_{i = 0}^{\\frac{n}{2} - 1}(n - 2i)^2 = \\sum\\limits_{i = 0}^{\\frac{n}{2} - 1}(n^2 - 4ni + 4i^2) + C$$ $$T(n) = n^2\\cdot\\left(\\frac{n}{2}-1\\right) - 4n\\cdot\\frac{1}{2}\\cdot\\frac{n}{2}\\cdot\\left(\\frac{n}{2} - 1\\right) + 4\\cdot\\frac{1}{6}\\cdot\\left(\\frac{n}{2} - 1\\right)\\cdot\\frac{n}{2}\\cdot n + C$$ $$\\therefore \\ T(n) = \\Theta(n^3)$$\n\nshare|improve this answer\n\nNote that if $n=2k$ is even, then $$ T(n)+T(n-1) = n^2+(n-1)^2+ \\cdots+4^2+3^2 + T(2)+T(1) =\\frac{n(n+1)(2n+1)}{6} + C. $$ Here $C=T(2)+T(1) -2^2-1^2$ and we used the formula $\\sum_{i=0}^n i^2 = \\frac{n(n+1)(2n+1)}{6}$. We also note that $T(n) \\sim T(n-1)$, so we may conclude that $$ T(n) \\sim n^3/12. $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://magic.aladdin.cs.cmu.edu/category/mathematics/combinatorics/\nText:\nCategory Archives: Combinatorics\n\nAn Annoying Combinatorial Problem\n\nHere is an \u201cinnocent\u201d combinatorial problem, with the best known bounds being very simple (but nobody managed to improve them since 1978). Disclaimer: the problem is very catchy (I struggled with it for quite a while), so do not read any further if, for example, you are writing a PhD thesis :-)\n\nMaker and Breaker alternatively select 1 and q edges of K_n (the complete graph on n vertices) until all edges have been claimed. Maker wins if his graph has a triangle. What is the smallest q=q(n) such that Breaker has a winning strategy?\n\nThe best known strategy for Maker is to claim edges incident to some vertex x (and never miss a one-step win). If Breaker managed to block x completely, say after m rounds, then Breaker made n-1-m + {m\\choose 2}\\le m q(n) moves. This implies that q(n) is approximately at least \\sqrt{2n}.\n\nOn the other hand, Breaker can win if q> 2\\sqrt{n}: for each edge xy claimed by Maker, Breaker selects \\sqrt{n} edges at x and \\sqrt{n} edges at y. Thus Maker\u2019s graph has maximum degree at most (n-1)/\\sqrt{n}+1 and Breaker can always block all immediate threats.\n\nReference: V.Chvatal and P.Erdos, Biased positional games, Ann. Discrete Math. 2 (1978), 221-229.\n\nI would bet on the \\sqrt{2n} bound :-)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/229370/solve-2a-5b-20/229379\nText:\nTake the 2-minute tour \u00d7\n\nIs this equation solvable? It seems like you should be able to get a right number! If this is solvable can you tell me step by step on how you solved it. $$\\begin{align} {2a + 5b} & = {20} \\end{align}$$\n\nMy thinking process: $$\\begin{align} {2a + 5b} & = {20} & {2a + 5b} & = {20} \\\\ {0a + 5b} & = {20} & {a + 0b} & = {20} \\\\ {0a + b} & = {4} & {a + 0b} & = {10} \\\\ {0a + b} & = {4/2} & {a + 0b} & = {10/2} \\\\ {0a + b} & = {2} & {a + 0b} & = {5} \\\\ \\end{align}$$\n\nThe problem comes out to equal: $$\\begin{align} {2(5) + 5(2)} & = {20} \\\\ {10 + 10} & = {20} \\\\ {20} & = {20} \\end{align}$$\n\nsince the there are two different variables could it not be solved with the right answer , but only \"a answer?\" What do you guys think?\n\nshare|improve this question\nAre $a$ and $b$ supposed to be integers or real numbers? I don't really know a lot about number theory, but I know that if they're real numbers then there are infinite solutions. \u2013\u00a0 Javier Badia Nov 5 '12 at 2:05\nThere are infinite solutions either way (for this one anyways). See here. \u2013\u00a0 EuYu Nov 5 '12 at 2:07\nAnyway, I don't understand the thinking process. How do you get from $2a+5b =20$ to $0a+5b=20$? That's certainly not a valid step. \u2013\u00a0 Javier Badia Nov 5 '12 at 2:09\nI have no vaild reason why I put 2a to 0a. My thinking process was that if i had just magicly put it to 0 that i could get \"a answer.\" but that I look at it makes me feel dumb! \u2013\u00a0 Hobbs Nov 5 '12 at 13:57\n\n5 Answers 5\n\nup vote 2 down vote accepted\n\nYou have what is known as a linear diophantine equation. An equation of the form $$ax + by = c$$ is solvable in $x$ and $y$ if and only if $\\gcd(a,\\ b)\\mid c$. In your particular case the equation is solvable.\n\nYou've generated one solution already, the pair $(x,\\ y)=(5,\\ 2)$. All the other solutions are then given by $$(x,\\ y)=\\left(5 + 5k,\\ 2-2k\\right)$$ for $k\\in \\mathbb{Z}$.\n\nshare|improve this answer\n\nAlso, this equation has solutions in the integers in the greatest common divisor of 2 and 5 is 1, which divides 20.\n\nTo get an explicit solution, use the Euclidean algorithm. (BTW these are called Diophantine equations if you want to do further reading on them)\n\nshare|improve this answer\n\nNote that $2a$ must have as its unit digit $0, 2, 4, 6,$ or $8$ (because it's even!).\n\nSimilarly, note that $5b$ must have as its unit digit $0$ or $5$.\n\nWith a bit of thinking, you can see that for $2a + 5b$ to be $20$, we need to ensure that $2a$ has a unit digit of $0$ (hence $a$ is a multiple of $5$).\n\nSo let $a$ be a multiple of $5$. That is, let $a = 5k$, for some integer $k$.\n\nThen $2a + 5b = 20$ becomes $10k + 5b = 20$, so that $5b = 20 - 10k$.\n\nDividing both sides of our last equation by $5$, we have $b = 4 - 2k$.\n\nThis gives you all the possible answers for $(a, b)$, namely, $(5k, 4-2k)$.\n\nFor example, when $k = 1$ you get $(5 \\cdot 1, 4 - 2 \\cdot 1) = (5, 2)$, which is the answer you came to.\n\nshare|improve this answer\n\nGenerally one can use the Extended Euclidean algorithm, but that's overkill here. First note that since $\\rm\\,2a+5b = 20\\:$ we see $\\rm\\,b\\,$ is even, say $\\rm\\:b = 2n,\\:$ hence dividing by $\\,2\\,$ yields $\\rm\\:a = 10-5n.$\n\nRemark $\\ $ The solution $\\rm\\:(a,b) = (10-5n,2n) = (10,0) + (-5,2)\\,n\\:$ is the (obvious) particular solution $(10,0)\\,$ summed with the general solution $\\rm\\,(-5,2)\\,n\\,$ of the associated homogeneous equation $\\rm\\,2a+5b = 0,\\:$ i.e. the general form of a solution of a nonhomogeneous linear equation.\n\nshare|improve this answer\n\nThere are infinite solutions to this problem. Why? Fix a value of a. say that you wanted a to be 1. Then you get the equation 2+5b=20. 5b=18 so b=17/5. lets do it more generally. 2a+5b=20 so then 5b=20-2a and b=4-2a/5. If b=4-2a/5. Simply plug it into the original equation to get 2a+5(2-a/5)=20 which then gets to 20=20. so then for any a: (a,4-2a/5) will be an answer, you need both a and b to be integers. just take an a that is a multiple of 5 and you will have two integer solutions.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162301/normal-subgroups-of-p-groups?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a group of order $p^\\alpha$, where $p$ is prime. If $H\\lhd G$, then can we find a normal subgroup of $G/H$ that has order $p$?\n\nshare|improve this question\nNot if $H=G$. Otherwise, of course: order of $G/H$ divides order of $G$, so it's a power of $p$, so it has an element of order $p$, done. \u2013\u00a0 Gerry Myerson Jun 24 '12 at 7:59\nOk, I mistyped my question. I was wondering if we can find a normal subgroup of $G/H$ that has order $p$. \u2013\u00a0 youngtableaux Jun 24 '12 at 8:10\nI saw somewhere, if $|G|=m$ and $p$ is the smallest prime number dividing the order of $G$ then every subgroup of $G$ with index $p$ is normal in $G$. As Gerry noted; $|\\frac{G}{H}|=p^s$ for any $s$. I think by taking $m=p^s$ we can solve the problem. I hope it help. \u2013\u00a0 Babak S. Jun 24 '12 at 8:24\nI repeat: not if $H=G$. Other than that, I don't think $G/H$ differs form any other $p$-group. Does every finite $p$ group have a normal subgroup of order $p$? If so, then the answer t your question is yes. If no, let $A$ be a $p$-group with no normal subgroup of order $p$, let $G=A\\times B$ for some $p$-group $B$, then $1\\times B$ is normal in $G$, etc. \u2013\u00a0 Gerry Myerson Jun 24 '12 at 8:56\nIt may help you to note that finite non-trivial $p$-groups have non-trivial centers. \u2013\u00a0 Geoff Robinson Jun 24 '12 at 9:47\n\n1 Answer 1\n\nTheorem: a group $\\,G\\,$ of order $\\,p^n\\,,\\,p\\,$ a prime, $\\,n\\in\\mathbb N\\,$ , always has normal subgroup of order $\\,p^m\\,\\,,\\,\\,\\forall\\, m\\leq n\\,\\,,\\,m\\in \\mathbb N$\n\nProof: Exercise, using that always $|Z(G)|>1\\,$ and induction on $\\,n\\,$\n\nSo the comments by Gerry and Geoff close the matter.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296817/n-arcs-on-a-ring-which-are-either-blue-or-red-find-expectation-and-variance-of\nText:\nTake the 2-minute tour \u00d7\n\nThere are n distinct points marked on the ring, each of which is either blue or red with equal probabilities independently of each other. These n points divide the ring into n arcs. If an arc has both endpoints red, the arc is also considered red. If N is the number of red arcs, compute E[N] and var(N).\n\nI do not understand where to start this problem, I understand one will need to use indicators but how would one go about this? Also, The condition that if both end points are red then the arc is, is a bit confusing, how will this be utilized in solving the problem?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nExplanation of problem: There are $n$ arcs. They are all \"short,\" just joining two consecutive points on the circle. We colour an arc red iff both of its endpoints are red. We are only interested in arcs, the colours of the points are irrelevant except insofar as they determine whether an arc will be coloured red or not. Or to put it another way, we want to count the situations in which we have two consecutive red points.\n\nSo for example the pattern BRRRB gives us $2$ red arcs. For further information about how indicator functions can be used, please read the first four lines only of the solution outline.\n\nOutline of solution: Call the points $P_1,P_2,\\dots,P_n$, with the understanding that $P_{n+1}=P_1$.\nSuppose they are arranged counterclockwise in that order around the circle.\n\nLet random variable $X_i$ be $1$ if $P_i$ is red and $P_{i+1}$ are red. Otherwise, let $X_i=0$.\n\nThen the number of $N$ of red arcs is $X_1+X_2+\\cdots+X_n$.\n\nThe expectation of this sum is the sum of the expectations. It should be easy for you to find $\\Pr(X_i=1)$, and hence $E(X_i)$.\n\nThe variance is more complicated. We use the fact that $\\text{Var}(N)=E(N^2)-(E(N))^2$.\n\nSo we need $E(N^2)$. Expand $(X_1+X_2+\\cdots +X_n)^2$. By the linearity of expectation, we need $E(X_i^2)$ and $E(X_iX_j)$. The first is no problem, since $X_i^2=X_i$. For the second, there is a need to distinguish between the cases where $P_i$ and $P_j$ are neighbours, and the cases where they are not.\n\nshare|improve this answer\n@Olivia, For Variance, you may expand it using covariance, and note that $Cov (V_i V_j) = 0 $ if $j\\neq i \\pm 1$, and calculate it otherwise. \u2013\u00a0 Calvin Lin Feb 7 '13 at 2:43\nthe direct expansion isn't hard. $Cov (V_i V_{i+1} ) = E[V_i V_{i+1}] - E[V_i]E[V_{i+1}] = \\frac {1}{8} - \\frac {1}{16} = \\frac {1}{16}$. So the variance is $\\sum Var (V_i) - 2\\sum Cov(V_i V_j) = \\frac {3n}{16} - \\frac {2n}{16} = \\frac {n}{16}$. \u2013\u00a0 Calvin Lin Feb 7 '13 at 2:45\n@CalvinLin: The procedure I suggested for variance uses only very basic machinery. Yours is smoother if the OP has some background. \u2013\u00a0 Andr\u00e9 Nicolas Feb 7 '13 at 2:50\nThe expectation of this sum is the sum of the expectations. It should be easy for you to find Pr(Xi=1), and hence E(Xi). This phrase,while helpful, does not help me, I am confused as to how to find out the probability, they give me I have n arcs each equally likely to be blue or red, so 1/2 chance blue or red right? The confusion is what the whole 2 ends being red condition comes in. otherwise I understand what you had up til there. Also can you be a little more explicit. I know this is quite trivial but I need to understand the reasoning behind the approach. \u2013\u00a0 Olivia Irving Feb 7 '13 at 2:56\n@Andr\u00e9Nicolas I thought that using of Indicator Variables would indicate knowledge of Expectation / Variance formulas, but apparently no necessarily. \u2013\u00a0 Calvin Lin Feb 7 '13 at 3:03\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59450/boundaries-of-the-eigenvalues-of-a-symmetric-matrix-or-of-its-lapacian/59474\nText:\nTake the 2-minute tour \u00d7\n\nGiven the adjacency matrix $A_{ij}$ of a graph with $N$ vertices and $M$ links (or any binary symmetric matrix of size $N \\times N$), is it possible to establish lower and upper boundaries of its eigenvalues? I mean, do $N$ and $M$ determine the lowest and the largest possible eigenvalues of the matrix?\n\nIn other words, let $L$ be the Lapacian of $A_{ij}$. We know that its eigenvalues obbey the following: $\\lambda_1 = 0 \\leq \\lambda_2 \\leq \\lambda_3 \\leq \\ldots \\leq \\lambda_N$. The lowest eigenvalue is always $\\lambda_1 = 0$ and hence, the eigenvalues of $L$ have a lower bound. Is there an upper bound for $\\lambda_N$ that depends only on the size $N$ of the graph and/or on $M$?\n\nStated yet in another manner. Does anyone know a graph $G'$ whose $\\lambda'_N$ is largest than the $\\lambda_N$ of any other graph of the same size $N$ and/or number of links $M$?\n\nThank you!\n\nshare|improve this question\n\n4 Answers 4\n\nThere are several notions of Laplacian for graphs. For instance, there is the normalized Laplacian, the classical Laplacian and Laplacians with boundary conditions as the Dirichlet Laplacian and so on. Assuming that you are taking about the classical Laplacian then its eigenvalues are $$ 0=\\lambda_1\\leq \\lambda_2\\leq \\ldots\\leq\\lambda_{n} $$ where $n$ is the number of nodes. Typically it is $\\lambda_2$ the eigenvalue that gives the most information about the graph (like expanding properties, connectivity, isoperimetric properties, etc). For instance, $\\lambda_2>0$ iff the graph is connected.\n\nHere are a few known results:\n\n  \u2022 [Fiedler] $\\lambda_2\\leq \\frac{n}{n-1}\\min\\{d(v):v\\in V\\}$ where $d(v)$ is the degree of the node $v$.\n\n  \u2022 [Anderson and Moreley] The maximum eigenvalue satisfies $$ \\lambda_n\\leq\\max\\{ d(u)+d(v):uv\\in E\\}. $$ If the graph $G$ is connected then the equality holds iff the graph is bipartite.\n\n  \u2022 [Kelmans] If the graph is simple (no multiple edges or loops) then $\\lambda_n\\leq n$ with equality iff the complement of $G$ is not connected.\n\n  \u2022 $\\sum_{i}^{n}{\\lambda_i}=2m=\\sum_{v}{d(v)}$ where $m$ is the number of edges in $G$.\n\n  \u2022 [Fiedler] $\\lambda_{n}\\geq \\frac{n}{n-1}\\max\\{d(v):v\\in V\\}$.\n\nThe second and last bullet give you lower and upper bounds for the maximum eigenvalue in terms of the degree of the nodes. If the graph is regular of course much more can be said.\n\nI hope it helps!\n\nshare|improve this answer\n\nLet $L(G)$ denote the Laplacian of $G$. Then $L(G)$ is positive semidefinite. If $\\bar{G}$ denotes the complement of $G$ then $$ L(K_n) = L(\\bar{G}) + L(G) $$ and so $L(K_n)-L(G)$ is positive semidefinite. Hence the largest eigenvalue of $L(K_n)$ is an upper bound on the largest eigenvalue of $L(G)$. Since $L(K_n)=nI-J$ (where $J$ is all-ones matrix), the eigenvalues of $L(K_n)$ are $n$ with multiplicity $n-1$ and 0, and so $n$ is a sharp upper bound on the largest eigenvalue of $L(G)$.\n\nshare|improve this answer\n\nLost of work both for Laplacian an adjacency matrix eigenvalues bound has been done by Vladimir Nikiforov, I suggest to take a look hat his two main papers on arxiv.org\n\nBounds on graph eigenvalues I and Bounds on graph eigenvalues II\n\nPiero Giacomelli\n\nshare|improve this answer\n\nThere's a whole area of algebraic graph theory, but without any information on a the graph, I can't remember anything graph specific right now\n\nWhat is relevant is Gershgorin circle theorem\n\nWhich for example would mean that a undirected graph without loops, the adjacency matrix would have eigenvalues smaller than the maximum degree of a vertex, that is |M-1|. And for the Laplacian we should get something like 2|M|.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/30614/path-traced-out-by-a-point\nText:\nTake the 2-minute tour \u00d7\n\nWhile studying uniform circular motion at school, one of my friends asked a question:\n\n\"How do I prove that the path traced out by a particle such that an applied force of constant magnitude acts on it perpendicular to its velocity is a circle?\" Our physics teacher said it was not exactly a very simple thing to prove.\n\nI really wish to know how one can prove it.Thank you!\n\nshare|improve this question\nHow easy this can prove depends on your level of mathematics. Do you understand analytic geometry or even calculus? \u2013\u00a0 C.R. Jun 22 '12 at 13:35\nYou'll come away with so much more if spend the time to think more deeply about the problem and earn the knowledge of how to prove it. \u2013\u00a0 Alfred Centauri Jun 22 '12 at 13:40\nIt is an extremely simple thing to prove! You should not listen to your teacher. \u2013\u00a0 Ron Maimon Jun 23 '12 at 8:37\nThank you.I did prove it eventually,I was doing something extremely stupid. :) I am least bothered about how tough something is as long as I have the background to attack it. \u2013\u00a0 user10060 Jun 23 '12 at 8:49\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nOne can prove it in a more-or-less elementary way by solving a pair of simultaneous differential equations. In two dimensions, a vector that is perpendicular to a velocity $$\\left(\\begin{matrix}u(t)\\cr v(t)\\end{matrix}\\right)\\quad\\mathrm{is}\\quad\\left(\\begin{matrix}-v(t)\\cr u(t)\\end{matrix}\\right).$$ The acceleration, the time derivative of the velocity, is proportional to this vector, so we have the two differential equations $$\\left(\\begin{matrix}\\dot u(t)\\cr \\dot v(t)\\end{matrix}\\right)=\\lambda\\left(\\begin{matrix}-v(t)\\cr u(t)\\end{matrix}\\right).$$ If $\\lambda$ is negative, the circle goes \"the opposite way\". If $\\lambda$ is zero, the circle is a straight line. If you know differentiation and how to solve differential equations, you should be able to solve this pair of equations, and then integrate it to obtain the way in which the position changes over time. If you don't, then it may be better to be patient and wait until you come across it in the course of your studies. Learning calculus on your own to the level needed to solve this differential equation is possible, however.\n\nshare|improve this answer\n\nTry looking for uniform circular motion in google. It is not hard to prove it if you know something about vectors and what taking a derivative of vector function means. Force is a vector it is proportional to acceleration. Acceleration is change in velocity(remember a vector) divided by time(really shot period of time). Try to draw a circle yourself and some velocity, acceleration and position vectors\n\nshare|improve this answer\n\nIf you don't want or know how to solve a pair of simultaneous differential equations, try this more elementary approach using complex numbers and ordinary time derivatives.\n\nConsider the arbitrary path, with parameter t, in the complex plane:\n\n\nThe \"velocity\" is the time derivative:\n\n$[\\frac{dr}{dt} + ir(t)\\frac{d\\theta}{dt}] e^{i\\theta(t)}$\n\nThe \"acceleration\" is the 2nd time derivative:\n\n$\\{[\\frac{d^2r}{dt^2} - r(t)(\\frac{d\\theta}{dt})^2] + i[2(\\frac{dr}{dt}\\frac{d\\theta}{dt}) + r(t)\\frac{d^2\\theta}{dt^2}]\\}e^{i\\theta(t)}$\n\nWe require that the \"acceleration\" be orthogonal to the \"velocity\". In polar representation, this just means that the ratio of the two complex numbers is an imaginary number (multiplication by $i$ is a rotation of 90 degrees in the complex plane).\n\nIf you stare at the two derivatives a bit, you see that this condition only holds if $r$ and $\\frac{d\\theta}{dt}$ are constants:\n\n$r(t) = R$\n\n$\\frac{d\\theta}{dt} = \\omega$\n\nThen the \"velocity\" is just:\n\n$iR\\omega e^{i\\omega t}$\n\nand the \"acceleration\" is just:\n\n$-R\\omega^2e^{i\\omega t}$\n\nSo, the \"velocity\" and \"acceleration\" are indeed orthogonal. The path then is just:\n\n$Re^{i\\omega t}$\n\nThis is just a circle in the complex plane.\n\nOf course, you could have done this with polar coordinates in the x-y plane but polar complex numbers make the derivatives so much easier!\n\nshare|improve this answer\n\nI think you can prove it you can prove that the acceleration vector $\\vec{a}$ is decomposed into two components $$\\vec{a} = \\dot{v}\\, \\hat{e} + \\frac{v^2}{r} \\hat{n}$$ one tangential to motion along the unit direction vector $\\hat{e}$ and one perpendicular to along the unit direction $\\hat{n}$, with tangential speed $v$, change in speed $\\dot v$ and path radius of curvature $r$.\n\nSo if the path was not a circle, there would be a component of $\\vec{a}=\\frac{\\vec{F}}{m}$ along the tangential vector $\\hat{e}$ changing the speed $v$ as to moves along. The hole thing hinges on the fact that speed does not change in uniform circular motion.\n\nThe above comes from math called Differential Geometry along a curve, and it is related to accelerations here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262115/why-are-hyperbolic-toral-automorphisms-e-g-arnolds-cat-map-ergodic\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\varphi : \\mathbb{T}^2 \\to \\mathbb{T}^2$ be a hyperbolic automorphism of the torus, induced by a linear map $A : \\mathbb{R}^2 \\to \\mathbb{R}^2$ of determinant $\\pm 1$ with no eigenvalues of modulus 1. What is an easy way to prove that $\\varphi$ is ergodic?\n\nIt's true that the stable and unstable manifolds at $(0,0) \\in \\mathbb{T}^2$ (projections of the eigenspaces of $A$ to the torus) are dense in the torus, which can be used to prove that such maps are topologically mixing. An example is Arnold's cat map.\n\nArnold and Avez show in Ergodic Problems in Classical Mechanics that Arnold's cat map is ergodic by proving that it has \"Lebesgue spectrum\", which implies that it is strong mixing, which implies that it is ergodic. Is there a more direct way to prove this?\n\nshare|improve this question\nA few weeks ago, someone here asked for a proof that these maps are chaotic. I found one in a textbook by Elaydi on discrete dynamical systems. The hardest part was proving the map transitive. \u2013\u00a0 Gerry Myerson Dec 20 '12 at 4:57\n@GerryMyerson I saw that thread. I found a simpler proof of a stronger statement (topologically mixing) in the book by Broer and Takens (proposition 2.15, page 111). But I don't see how topological transitivity or mixing can help me prove that these maps are ergodic. \u2013\u00a0 Ricardo Buring Dec 20 '12 at 11:25\nadd comment\n\n1 Answer\n\nI suggest using the following characterization of ergodicity:\n\n$\\varphi$ is ergodic if and only if every $f\\in L^2(\\mathbb{T}^2)$ such that $f\\circ \\varphi = \\varphi$ is constant function.\n\nNow let's use this criterion to prove $\\varphi$ is ergodic. Suppose $f\\in L^2$ with $f\\circ \\varphi = \\varphi$. Decompose $f$ into its Fourier series $$f = \\sum_{m,n\\in \\mathbb{Z}} = \\alpha_{(m\\,n)}e^{2\\pi imx}e^{2\\pi iny},$$ with coefficients $\\alpha_{(m\\,n)}\\in \\mathbb{C}$. Then, if $\\varphi$ is given by the matrix $$A = \\left(\\begin{matrix} a & b\\\\c & d\\end{matrix}\\right),$$ it is easy to compute that $$f\\circ \\varphi = \\sum_{m,n}\\alpha_{(m\\,n)}e^{2\\pi i(ma+nc)x}e^{2\\pi i(mb+nd)y}.$$ Since $f$ is invariant, the Fourier series for $f$ and $f\\circ \\varphi$ must agree, so $\\alpha_{(m\\,n)} = \\alpha_{(ma+nc\\,mb+nd)}$ for all $m,n\\in \\mathbb{Z}$. We can express this more simply as follows. If $v = (m\\,\\,n)\\in \\mathbb{Z}^2$, then $\\alpha_v = \\alpha_{vA}$. By iterating, $\\alpha_v = \\alpha_{vA^k}$ for each $k\\in \\mathbb{Z}$.\n\nSuppose that $v\\in \\mathbb{Z}^2$. Either the sequence $vA^k$ of vectors with integer coordinates is periodic, or else $\\|vA^k\\|\\to \\infty$ as $k\\to \\infty$. Note that the first case cannot happen unless $v = 0$, since if $v = vA^k$ for some $k$, then $A^k$ would have $1$ as an eigenvalue, which contradicts the assumption of hyperbolicity. Thus either $v = 0$, or $\\|vA^k\\|\\to \\infty$. Suppose $v\\neq 0$. Since $f\\in L^2$, the coefficients $\\alpha_{(m\\,n)}\\to 0$ as $\\|(m\\,\\,n)\\|\\to \\infty$, and thus $\\alpha_v = \\alpha_{vA^k}\\to 0$, i.e., $\\alpha_v = 0$. We have therefore shown that the only way $\\alpha_v$ can be nonzero is if $v = 0$. The Fourier series for $f$ is then $f = \\alpha_0$, so $f$ is a constant function.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/294969/show-that-the-given-series-for-z1-is-fracz1-z\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nProve the following equation of complex power series.\n\nI must show for $|z|<1$ that $$\\sum_{k=0}^\\infty \\frac{z^{2^k}}{1-z^{2^{k+1}}} = \\frac{z}{1-z}.$$ I'm not really sure where to start or how to simplify the problem at all. Any help would be great.\n\nshare|improve this question\nWhat do you get for the partial sum $S_n$? Note that $(1-z^{2^{k+1}})=(1-z^{2^k})(1+z^{2^k})$. \u2013\u00a0 Calvin Lin Feb 5 '13 at 0:37\nadd comment\n\nmarked as duplicate by Micah, Cameron Buie, Calvin Lin, David Moews, Thomas Feb 5 '13 at 1:09\n\n\n1 Answer\n\nThis looks nasty, but with the following approach it should boil down to a straight forward calculation:\n\nYou can write the RHS as a power-series: $$\\frac{z}{1-z} = z \\sum_{k=0}^{\\infty} z^k = \\sum_{k=0}^{\\infty} z^{k+1}$$\n\nNow try to rewrite you LHS as power-series as well and compare the coeffecients: $$\\sum_{k=0}^{\\infty} \\frac{z^{2^k}}{1-z^{2^{k+1}}} = \\sum_{k=0}^{\\infty} \\left(z^{2^k} \\frac{1}{1 - z^{2^{k+1}}}\\right) = \\sum_{k=0}^{\\infty} \\left(z^{2^k} \\sum_{j=0}^{\\infty} \\left(z^{2^{k+1}}\\right)^j\\right) \\\\= \\sum_{k=0}^{\\infty} \\left(z^{2^k} \\sum_{j=0}^{\\infty} z^{2^{k+1}j}\\right) = \\sum_{k=0}^{\\infty}\\sum_{j=0}^{\\infty} z^{2^k + j2^{k+1}}$$\n\nTo see that both power-series are the same note that every $n \\in \\mathbb{Z}$, $n\\geq 1$ there exists unique integers $k$ and $j$ such that $n=2^k + j2^{k+1}$ (namely $2^k$ is the gratest power of $2$ which divides $n$).\n\nI guess there are more elegant ways to prove this, but since you didn't know how to start it might be usefull to see this approach.\n\nshare|improve this answer\nHow exactly does the LHS break down like that? That is the only part I can't follow. The step with the double summation throws me off \u2013\u00a0 Moses G Feb 5 '13 at 4:26\nI added two more steps to the calculation. I use the geometric series to rewrite the fraction as a power-series: $1/(1-w) = 1 + w^2 + w^3 + \\cdots$ with $w = z^{2^{k+1}}$. \u2013\u00a0 Sam Feb 5 '13 at 9:43\nadd comment"}
{"text": "Retrieved from http://www.mathworks.com/matlabcentral/answers/68186\nText:\nDiscover MakerZone\n\nMATLAB and Simulink resources for Arduino, LEGO, and Raspberry Pi\n\nLearn more\n\nDiscover what MATLAB\u00ae can do for your career.\n\nOpportunities for recent engineering grads.\n\nApply Today\n\nCan I solve this with Matlab Optimization Toolbox?\n\nAsked by GFX on 22 Mar 2013\n\nDear all,\n\nHi, I'm new to Matlab and also to optimization problems. I need help on an optimization problem. The problem is as follows:\n\nfind x=(est_pos_1, ... est_pos_n)\nminimizing the sum of squared difference between elements in matrix A and B\na_ij = 1 if Euclidean distance between est_pos_i and est_pos_j is less than constant R and 0 otherwise, 0 < i, j < m + n, m is number of points with known position, n of points with unknown positions to be estimated, b_ij = 1 if Euclidean distance between actual_pos_i and actual_pos_j is less than R and 0 otherwise. Matrix B is given.\n\nI tried solving it using Particle Swarm Optimization with poor success, i.e. the error between the estimated and actual positions is high.\n\n\nWalter Roberson on 22 Mar 2013\n\nThe two matrices A and B appear to be different sizes, as B only goes as far as the known positions but A extends to estimated positions. I am not sure what the sum of the squared difference would mean for different sized matrices?\n\nIf the values are all 0's and 1's, then squared difference would be the same as absolute difference, right? And in turn would be the same as \"not equal\" ?\n\nWhat does it mean to estimate position (i,j) for points whose actual position is known?\n\nGFX on 29 Mar 2013\n\nHi, the size of A an B are of the same size. However, instead of determine all m+n points, we are to decide only on the position of n unknown points, since the m points we already known their position from prior knowledge. We are to determine positions of est_pos_i (estimated positions of unknown points i, n of these) given some connectivity constrains, given by B. So, we are trying to recreate the position of all points based on connectivity readings. In actual, B can be obtained for e.g. say the points know who their neighboring points are. However, for simulation, B can simply be calculated by determining if the distances between the actual positions between any pair of points. In simulation, we also have the exact positions of all points. I hope I am clear. Thank you.\n\nGFX on 29 Mar 2013\n\nAnd the objective here is to recreate the configuration (positioning) of points that resembles the exact configuration. Hence the sum of square difference objective.\n\nThank you.\n\n\n\nNo products are associated with this question.\n\n1 Answer\n\nAnswer by Matt J on 29 Mar 2013\nEdited by Matt J on 29 Mar 2013\nAccepted answer\n\nNo, you can't use the Optimization Toolbox. The solvers in the Toolbox are smooth algorithms (except for bintprog) and therefore apply to differentiable functions.\n\nHowever, your matrix A, and therefore the objective function overall, is a piecewise constant, non-differentiable, function of x. The piecewise constant behavior will also mean that the objective function is flat almost everywhere, making almost every point a local minimum where the optimization can get stuck.\n\n\nGFX on 29 Mar 2013\n\nFor example, how do I easily and quickly determine if such a problem is say linear, convex, or non linear? I know about the standard forms of LP, convex programs and such, but for eg. in my original question, how do you determine them?\n\nMatt J on 29 Mar 2013\n\nWell, I don't think there's always an easy way. Certainly optimization textbooks will always give examples of functions that are convex etc... and you build your analysis skills from that.\n\nHowever, in your case, the A matrix can only take on values 0 or 1. Discrete-valued functions like that have to be piecewise constant.\n\nGFX on 31 Mar 2013\n\nThanks Matt J, thanks all. :-)\n\nMatt J\n\nContact us"}
{"text": "Retrieved from http://math.stackexchange.com/questions/72222/existence-of-least-squares-solution-to-ax-b\nText:\nTake the 2-minute tour \u00d7\n\nDoes a least squares solution to $Ax=b$ always exist?\n\nshare|improve this question\nRelevant: en.wikipedia.org/wiki/\u2026 (P.S. I didn't vote.) \u2013\u00a0 anon Oct 13 '11 at 7:11\nSorry, I don't really understand what is written on wiki. So, is the answer affirmative or not? \u2013\u00a0 dkdsj93 Oct 13 '11 at 7:16\nQuoting the Wikipedia page: \"The pseudoinverse solves the least-squares problem as follows...\" \u2013\u00a0 Dirk Oct 13 '11 at 7:18\nadd comment\n\n6 Answers\n\nIf you think at the least squares problem geometrically, the answer is obviously \"yes\", by definition.\n\nLet me try to explain why. For the sake of simplicity, assume the number of rows of $A$ is greater or equal than the number of its columns and it has full rang (i.e., its columns are linearly independent vectors). Without these hypotheses the answer is still \"yes\", but the explanation is a little bit more involved.\n\nIf you have a system of linear equations\n\n$$ Ax = b \\ , $$\n\nyou can look at it as the following equivalent problem: does the vector $b$ belong to the span of the columns of $A$? That is,\n\n$$ Ax = b \\qquad \\Longleftrightarrow \\qquad \\exists \\ x_1, \\dots , x_n \\quad \\text{such that }\\quad x_1a_1 + \\dots + x_na_n = b \\ . $$\n\nHere, $a_1, \\dots , a_n$ are the columns of $A$ and $x = (x_1, \\dots , x_n)^t$. If the answer is \"yes\", then the system has a solution. Otherwise, it hasn't.\n\nSo, in this latter case, when $b\\notin \\mathrm{span }(a_1, \\dots , a_n)$, that is, when your system hasn't a solution, you \"change\" your original system for another one which by definition has a solution. Namely, you change vector $b$ for the nearest vector $b' \\in \\mathrm{span }(a_1, \\dots , a_n)$. This nearest vector $b'$ is the orthogonal projection of $b$ onto $\\mathrm{span }(a_1, \\dots , a_n)$. So the least squares solution to your system is, by definition, the solution of\n\n$$ Ax = b' \\ , $$\n\nand your original system, with this change and the aforementioned hypotheses, becomes\n\n$$ A^t A x = A^tb \\ . $$\n\nshare|improve this answer\nadd comment\n\nAssume there is an exact solution $\\small A \\cdot x_s = b $ and reformulate your problem as $\\small A \\cdot x = b + e $ where e is an error ( thus $\\small A \\cdot x = b $ is then only an approximation as required) we have then that $\\small A \\cdot (x_s - x) = e $\n\nClearly there are arbitrary/infinitely many solutions for x possible, or say it even more clear: you may fill in any values you want into x and always get some e. The least-squares idea is to find that x such that the sum of squares of components in e ( define $\\small \\operatorname{ssq}(e) = \\sum_{k=1}^n e_k^2 $) is minimal. But if our data are all real data (what is usually assumed) then the smallest possible sum of squares of numbers is zero, so there in fact exists an effective minimum for the sum.\nThen restrictions on x may cause, that actually the error ssq(e) is bigger but always there will be a minimum $\\small \\operatorname{ssq}(e) \\ge 0 $.\n\nSo the question is answered in the affirmative.\n\n(A remaining question is, whether it is unique, but that was not in your original post.)\n\nshare|improve this answer\nadd comment\n\nTo see that a solution always exists, recall that the definition of a least-squares solution is one that minimizes $\\|Ax-b\\|_2$. To get the solution, you'd use something like the pseudoinverse on paper or some nice minimization algorithm in practice. We don't even need to refer to the rank of the matrix or anything like that to assertain the existance of a solution. Minimizing $\\|Ax-b\\|_2$ in $x$ amounts to minimimizing a nonnegative quadratic equation in $n$ variables (the $x_i$'s). Simple calculus alone justifies the existence of a minimum.\n\nshare|improve this answer\nadd comment\n\nWe just need to prove that the rank of matrix $A^TA$ equals the rank of augmented matrix $[A^TA,A^Tb]$. We prove it below:\n\ndenote the rank of matrix as rank A=k. By using the rank equality(can be found in nearly every algebra textbook.):rank $A^TA$=rank $A$=rank $A^T$. We know rank $[A^TA,A^Tb]\\ge$rank A, since the former has one more column than the latter. But, on the other hand, $[A^TA,A^Tb]=A^T[A,b]$, and by using the rank inequality(can be found in some algebra textbooks): rank $AB\\le$ min{rank A, rank B}. so rank $A^T[A,b]$$\\le$rank $A^T$=rank A=k. Combining the two inequality, we have rank $[A^TA,A^Tb]$=k.\n\nSo the rank of matrix$[A^TA]$ is always equal to the rank of the augmented matrix$[A^TA,A^Tb]$. By the theorem of existence and uniqueness of vector equation, we know the least square problem always has at least one solution. Thus we finish our proof. Q.E.D.\n\nshare|improve this answer\nadd comment\n\n\n$\\large{\\sf Example}:$ $2x = 5$ and $3x = 7$ becomes $$ {2 \\choose 3}\\pars{x} = {5 \\choose 7} \\quad\\imp\\quad \\pars{2 \\quad 3}{2 \\choose 3}\\pars{x} = \\pars{2 \\quad 3}{5 \\choose 7} \\quad\\imp\\quad \\pars{13}\\pars{x} = \\pars{31} $$\n\n$$ x = {31 \\over 13} $$ which is the minimum of the function $\\pars{2x - 5}^{2} + \\pars{3x - 7}^{2}$.\n\nshare|improve this answer\nadd comment\n\nI do not think it is true because solving finding a least squares solution amounts to solving A^{T}Ax=A^{T}b, and that A^{T}A might not always be invertible. If A^{T}A is not invertible it follows, from the invertible matrix theorem, that the transformation it represents is neither onto nor one-to-one .\n\nshare|improve this answer\nThis doesn't make sense. The whole point of least squares is that in the case that $A$ (or $A^TA$) is not invertible you get a solution which minimizes $\\|Ax-b\\|_2$. The pseudoinverse is precisely what gives the minimizer and it always exists. \u2013\u00a0 Alex R. Apr 25 '13 at 19:50\nI was just talking about finding a least squares solution by solving A^{T}Ax=A^{T}b. math.stackexchange.com/questions/253692/least-squares-method/\u2026 \u2013\u00a0 lopi Apr 25 '13 at 20:00\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/239697/huffman-code-with-probabilities-p-1-p-2-ldots-p-n?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have solved the first two subsections of an assignment, but I can't solve the last subsection.\n\nWe have a Huffman code with probabilities $p_1,p_2,\\ldots, p_n$ and we know that $p_1>p_2>\\cdots>p_n>0$.\n\n$y_1$ - the code for the character whose probability is $p_1$? And $|y1|$ is the length of $y_1$.\n\nI proved that:\n\n  \u2022 if $|y_1| = 1$ then $p_1 \\geq 1/3$.\n  \u2022 if $p_1 < 1/3$ then $|y_1| \\geq 2$ (it is not the same as above).\n\nI can't prove:\n\n  \u2022 if $p_1 > 2/5$ then $|y_1| = 1$.\n\nThanks for all kind of help.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nSince you say it's an assignment I won't give you the full answer, but here's an orientation. You can build a proof by contradiction from two components: Dirichlet's principle and the construction of the Huffman tree.\n\nFirst prove that given that $p_1 = 2/5 + \\epsilon$ and $|y_1| > 1$ there must be a merge step where the words are partitioned into three disjoint sets: $\\{y_1\\}$, $A$, and $B$ such that the total probability of the words in $A$ is more than $p_1$ (and hence the total probability of the words in B is less than $1/5 - 2\\epsilon$).\n\nThen prove that the step which generated $A$ by merging the two smallest sets was performed incorrectly because $B$ was actually smaller than one of them.\n\nshare|improve this answer\nthank you, I solved this assignment an another way. \u2013\u00a0 Tatar Elem\u00e9r Nov 18 '12 at 22:30\nadd comment\n\nI use this:\n\nif p1 > 2/5 then at least one symbol is encoded by a codeword of length 1. (Hint: Suppose not and consider the vertices of the Hu\ufb00man tree which are distance 2 from the root.) Solution: Suppose not. This immediately implies that at distance 2 from the root of the encoding tree there are exactly 4 vertices, say a1, a2, a3, a4 with probabilities p1, p2, p3, p4 . One of these, say a1 corresponds to a1 or was obtained by merging it. It follows that p1 > p1 > 2/5. Suppose a3 and a4 are merged at the next step to form a new symbol a with probability p. Since a1 must be merged before the \ufb01nal step, we must have that p > p1 (otherwise we would merge a2 with a). Since also 2p2 > p3 + p4 = p > p1 and p1 + p2 + p = 1, we obtain that 1 > p1 + p1/2 + p1 = 5p1/2 > 5p1/2, a contradiction.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/298191/lower-bound-for-matrix-sorting\nText:\nTake the 2-minute tour \u00d7\n\nConsider the problem of sorting a $n$ by $n$ matrix i.e. the rows and columns are in ascending order. I want to find the lower and upper bound of this problem.\n\nI found that it is $O(n^2logn)$ by just sorting the elements and then outputting the first $n$ elements as the first row, the next $n$ elements as the second row, and so on. However, I want to prove that it is also $\\Omega(n^2logn)$.\n\nAfter trying smaller examples, I think I should prove that if I can solve this problem using less than $n^2log(\\frac{n}{e})$ comparisons, it would violates the $log(m!)$ lower bound for comparisons needed to sort $m$ elements. Any ideas on how to prove that?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nHere is the argument I alluded to in my earliest comment. I claim that a sorted $n\\times n$ matrix $A$ can be linearly sorted in $n^2 \\log_2 n + O(n^2)$ comparisons. To do this, we maintain a vector $v$ which records up to $n$ values of $A$ in increasing order (and their corresponding locations $i,j$). Initially, take $v$ to be the first row of $A$.\n\nWe then iterate the following procedure $n^2$ times: output the least value of $v$, delete it from $v$, and insert into $v$ the entry directly underneath it in $A$ (if there is one). Since $v$ is sorted, finding the lowest value takes $0$ comparisons, but insertion of the new value requires a binary search on $v$, which is $\\lceil \\log_2 m \\rceil \\le \\log_2 m + 1$ comparisons, where $m \\le n$ is the length of $v$.\n\nIt should be clear that we never insert any value into $v$ before exhausting all smaller values, so if we iterate $n^2$ times this gives a linearly sorted list. The number of comparisons is at most $n^2 (\\log_2 n + 1) = n^2 \\log_2 n + O(n^2)$, proving the claim.\n\nHowever, to sort an arbitrary matrix of $n^2$ elements requires at least $\\log_2(n^2!)$ comparisons in the worst case, and this is equal to $n^2 \\log_2 n^2 - O(n^2) = 2n^2 \\log_2 n - O(n^2)$ . Therefore, getting from an arbitrary matrix to a sorted matrix must consume at least the difference of these two amounts of comparisons in the worst case, namely $n^2 \\log_2 n - O(n^2)$.\n\nshare|improve this answer\nI don't understand your conclusion (Therfore, ... ). How do you go from the problem of sorting the elements of a sorted matrix to the problem of sorting the matrix itself. Please, can you explain it to me? \u2013\u00a0 J Mint Feb 9 '13 at 9:41\n@jiji777 Do you understand what the lower bound for sorting means? There is no comparison-based way to sort $n^2$ numbers without spending about $2n^2 \\log n$ comparisons. Yet if we could matrix-sort cheaply it would only cost about half that many. \u2013\u00a0 Erick Wong Feb 9 '13 at 15:00\nNo, I understand that. But if T(n) is the time spent to get from an arbitrary matrix to a sorted matrix and S(n) is the time spent to get from a sorted matrix to a sorted array. Shouldn't you prove that $S(n)$ cannot be done in less than $n^2logn$ to prove that $T(n) \\geq n^2logn+log(n^2!)$. Is giving one algorithm that runs in $n^2logn$ sufficient or do we have to prove it for all algorithms? \u2013\u00a0 J Mint Feb 9 '13 at 20:21\n@jiji777 You have it backwards. We know that $T(n) + S(n) \\ge 2n^2 \\log n$, because the RHS is how long it takes to go from arbitrary matrix to sorted list, and the LHS is one possible way of doing so. A lower bound for $S(n)$ wouldn't help at all to control $T(n)$. \u2013\u00a0 Erick Wong Feb 9 '13 at 20:23\nright. Ok, thanks. \u2013\u00a0 J Mint Feb 9 '13 at 20:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/227794/in-field-f-cdot-how-can-i-prove-x2-1-implies-x-1-1/227796\nText:\nTake the 2-minute tour \u00d7\n\nI'm a really confused about fields.\n\nI know that it means $x$ is the reciprocal element of itself, and I can easily show that $1^2=1$ (not as trivial for $(-1)^2$ though), but I'm not sure how it helps me.\n\nedit: oh... I can only approve one answer. Well Rankeya was first (by a very short time) so I guess I'll approve his though, I don't really have any idea what it means. Thanks to both Brian M. Scott and Rankeya for the help.\n\nshare|improve this question\nDear @Nescio: You accept an answer that you feel is most helpful to you. It does not have to be the first answer that is posted. (But, make sure that you always accept answers if you feel you are satisfied with them. It encourages people to answer your questions, and also brings a sense of completeness/closure.) \u2013\u00a0 Rankeya Nov 3 '12 at 1:19\nadd comment\n\n2 Answers\n\nup vote 15 down vote accepted\n\nA field is a domain, which in particular means that $ab = 0 \\Rightarrow a = 0$ or $b = 0$. Write $x^2 = 1$ as $x^2 - 1 = 0$, and try to proceed from there.\n\nAlso, welcome to MSE!\n\nshare|improve this answer\nwow, that was so simple I feel stupid now... Thanks \u2013\u00a0 Nescio Nov 2 '12 at 20:26\nIt happens to the best of mathematicians. So, don't worry too much about it. \u2013\u00a0 Rankeya Nov 2 '12 at 20:27\nActually, I have been told by other mathematicians that it happens to the best of mathematicians. I often disbelieve them when they say this, and continue to feel stupid :) \u2013\u00a0 Rankeya Nov 2 '12 at 20:30\n@Rankeya: The best way to believe it is to see enough people who are more experienced and smarter than you do the same. Then again, even if you do believe it, it doesn't mean it won't make you feel stupid when you it happens to you. \u2013\u00a0 tomasz Nov 2 '12 at 20:42\nadd comment\n\nHINT: $x^2=1$ if and only if $x^2-1=0$. In any field $x^2-1=(x-1)(x+1)$, so $x^2=1$ if and only if $(x-1)(x+1)=0$. Now prove that for any $a,b\\in F$, $ab=0$ if and only if at least one of $a$ and $b$ is $0$.\n\nshare|improve this answer\n+1 But you solved the problem for him. :) \u2013\u00a0 B. S. Nov 2 '12 at 20:24\n@Babak: He may not agree. :-) \u2013\u00a0 Brian M. Scott Nov 2 '12 at 20:25\nstill feeling stupid... Thanks for the quick response both of you. \u2013\u00a0 Nescio Nov 2 '12 at 20:27\n@Andrey: You\u2019re welcome. And don\u2019t worry about it: it\u2019s happened to all of us. \u2013\u00a0 Brian M. Scott Nov 2 '12 at 20:28\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/127546/is-the-solution-to-a-driftless-sde-with-lipschitz-variation-a-martingale\nText:\nTake the 2-minute tour \u00d7\n\nIf $\\sigma$ is Lipschitz, with Lipschitz constant $K$, and $(X_t)_{t\\geq 0}$ solves\n\n$$dX_t=\\sigma(X_t)dB_t,$$ where $B$ is a Brownian motion, then is $X$ a martingale? I'm having difficulty getting past the self-reference here. I tried showing that, for $t\\geq 0$, $\\mathbb{E}[X]_t$ is finite. Perhaps Gronwall's lemma is needed?\n\nThank you.\n\nshare|improve this question\nYou could try and have a look at Theorem 4.40 (b) (and the above definition 4.39) in Jacod and Shiryaev's Limit Theorems for Stochastic Processes. If we are in the scope of that Theorem then $(X_t)$ is in fact a square integrable martingale. \u2013\u00a0 Stefan Hansen Apr 3 '12 at 10:57\n@StefanHansen I'm away from a library at the moment. If this works, put it as an answer, and I'll find the book later. :) \u2013\u00a0 Ben Derrett Apr 3 '12 at 12:32\nadd comment\n\n2 Answers\n\nUnfortunately, it didn't work in general (not saying that your claim is false though). Here is what I was trying to do. Maybe it can help you come up with ideas, otherwise just nevermind it.\n\nLet $L^2(X)$ be the set of all predictable processes $H$ such that the process $(\\int_0^t H^2_s d\\langle X\\rangle_s)_{t\\geq 0}$ is integrable, where $(\\langle X \\rangle_t)_{t\\geq 0}$ denotes the predictable quadratic variation process.\n\nIn the following $\\mathcal{H}^2$ (resp. $\\mathcal{H}_{\\text{loc}}^2$) denotes the set of all square integrable martingales (resp. locally square integrable martingales). Then we have the following theorem from Jacod & Shiryaev:\n\nTheorem 4.40(b). Let $(X_t)_{t\\geq 0}\\in \\mathcal{H}_{\\text{loc}}^2$. Then $(\\int_0^t H_s d X_s)_{t\\geq 0} \\in \\mathcal{H}^2$ if and only if $H\\in L^2(X)$.\n\nObviously we are in the scope of this theorem as $(B_t)_{t\\geq 0}\\in\\mathcal{H}^2$ with predictable quadratic variation $\\langle B_t\\rangle = t$, $t\\geq 0$. Furthermore if $(X_t)_{t\\geq 0}$ is the solution to the SDE of the original post, i.e. $$ X_t=\\int_0^t \\sigma(X_s) dB_s,\\quad t\\geq 0, $$ then $(X_t)$ is adapted and continuous and hence it is a predictable process. The theorem now yields that $(X_t)_{t\\geq 0}\\in \\mathcal{H}^2$ if and only if $$ E\\left[\\int_0^t \\sigma(X_s)^2 d \\langle B\\rangle_s\\right]=E\\left[\\int_0^t \\sigma(X_s)^2 ds\\right]=\\int_0^t E\\left[\\sigma(X_s)^2\\right] ds<\\infty $$ holds for all $t\\geq 0$. Using the Lipschitz assumption we get a sufficient condition for $(X_t)$ being a square integrable martingale: $$ \\int_0^t E[|X_s|]ds<\\infty, \\quad t\\geq 0. $$\n\nshare|improve this answer\nadd comment\nup vote 0 down vote accepted\n\n\n$$[X]_t = \\int_0^t\\sigma(X_u)^2du,$$\n\n\n$$\\begin{align} \\mathbb{E}([X]_t) \\le \\int_0^t \\mathbb{E}\\left[(x_0 + K|X_u-x_0|)^2\\right]du.\\\\ \\end{align} $$\n\n$X$ is locally bounded in $L^2$. See, for example, Karatzas and Shreve equation 5.2.15 (p. 289). So it follows easily that $\\mathbb{E}([X]_t)<\\infty$, for each $t$. Hence $X$ is a martingale.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/39043/prove-for-bell-numbers\nText:\nTake the 2-minute tour \u00d7\n\nI need to prove the following formula for Bell numbers:\n\n$$ B(n) = \\sum_{a_1 + \\cdots + a_k = n, a_i \\geq 1} \\frac{1}{k!} \\binom{n}{a_1 \\cdots a_k} $$\n\nDo you have any hint for me for getting this done?\n\nThank you in advance!\n\nshare|improve this question\nThis is an immediate consequence of the definitions of the Bell numbers and the multinomial coefficient. \u2013\u00a0 Phira May 14 '11 at 11:36\nWe defined the Bell numbers quite short as \"B(0) := 1, B(n) for n $\\geq$ 1 := the quantity of set partitions of $[n]$\". $[n]$ is defined as $\\{1,\\cdots,n\\}$. How do I combine that defintion and the one of the multinomial coefficient with the given formula? \u2013\u00a0 muffel May 14 '11 at 11:44\nI am struggling with this sum. Do you have a definition for $\\sum_{a_1+...+a_k = n, \\, a_k \\geq 1}$ \u2013\u00a0 monoid May 14 '11 at 13:43\nIt means \"sum over all tuples $(a_1,\\dotsc,a_k)$ such that their sum is $n$ and they're all greater or equal to $1$\". \u2013\u00a0 joriki May 15 '11 at 17:13\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nTo count the number of partitions of $[n]$, you can go through all the ways of carving $n$ up into bin sizes $a_1,\\dotsc,a_k$ that add up to $n$ and then count the number of ways of distributing $n$ objects into those bins, which is the multinomial coefficient. However, this overcounts, since if you swap two bins, you get the same partition, but you get a separate count in the sum. So you have to divide by the number of permutations of the $k$ bins, which is $k!$.\n\nWhile this is the easiest way to get the factor of $k!$, it's also instructive to look at how different permutations of the bins are (over)counted in the sum. If you swap two bins of the same size, you get another distribution of the elements over the same bin sizes, so this overcounting is in the multinomial coefficient, so to speak. On the other hand, if you swap two bins of different sizes, you get a different arrangement of the same bin sizes, so this overcounting is in the sum, so to speak.\n\nshare|improve this answer\ngreat, thank you for this explanation! \u2013\u00a0 muffel May 15 '11 at 17:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/140147/brownian-motion-convergence\nText:\nTake the 2-minute tour \u00d7\n\nIf $X$ is a standard 1d brownian motion and $M_t$ $= \\mbox{max}\\{X_S: 0 \\le s \\le t\\} $, what can we say about $M_t/t$ as $t \\rightarrow \\infty$?\n\nMainly, what can we say about the behavior of this martingale?\n\nMy attempt: P(Msubt > a) = 2P(B(t) >a), but what integral does this fit in with?\n\nshare|improve this question\nHint: The reflection principle gives that $M_t$ has the same distribution as $|B_t|$. \u2013\u00a0 Chris Janjigian May 2 '12 at 23:46\nSorry I used $B_t$ as my notation for a Brownian motion there. \u2013\u00a0 Chris Janjigian May 2 '12 at 23:52\nIt also might help you at some point when estimating the tail of the normal distribution that there is a really stupid bound: $e^{-x^2}\\leq xe^{-x^2}$ for $x$ large. \u2013\u00a0 Alex R. May 3 '12 at 0:27\nSo you are saying to use Hoeffdings inequality? will it help? \u2013\u00a0 mary May 3 '12 at 1:59\nPerhaps I was being too cryptic. Chris suggested that the distribution of $M_t$ is the same as $|B_t|$. You can easily calculate the probability that $|B_t|\\geq at$ for $a$ a positive constant, as a Gaussian integral but you'll need to do some estimates for how this \"tail\" probability behaves for large $t$. I believe my prior hint will help. \u2013\u00a0 Alex R. May 3 '12 at 2:53\nshow 2 more comments\n\n1 Answer\n\nSince $B_t$ is symmetric, the result recalled in the post reads $\\mathrm P(M_t\\gt at)=\\mathrm P(|B_t|\\gt at)$ $(\\ast)$.\n\nSince $B_t$ equals $\\sqrt{t}B_1$ in distribution, $(\\ast)$ is $\\mathrm P(|B_1|\\gt a\\sqrt{t})$. Since $|B_1|$ is almost surely finite and $a\\sqrt{t}\\to+\\infty$ for every $a\\gt0$, the last probability goes to zero, hence $\\mathrm P(M_t/t\\gt a)\\to0$ for every $a\\gt0$. That is, $M_t/t\\to0$ in probability.\n\nOne can strengthen this convergence, noting that the series $\\sum\\limits_n\\mathrm P(|B_1|\\gt a\\sqrt{n})$ converges since $\\mathrm P(|B_1|\\gt a\\sqrt{n})$ is $\\mathrm e^{-\\frac12a^2n+o(n)}$. By the first Borel-Cantelli lemma, $M_n/n\\to0$ almost surely when the integer $n$ goes to infinity. For every $t\\geqslant1$ there exists an integer $n\\geqslant1$ such that $n\\leqslant t\\lt n+1$, and $(M_t)_t$ is nondecreasing hence $M_t/t\\leqslant M_{n+1}/n\\leqslant 2M_{n+1}/(n+1)$. This proves that $M_t/t\\to0$ almost surely when the real number $t$ goes to infinity.\n\nThe same identity $(\\ast)$ shows the convergence in $L^p$ for every finite $p\\geqslant1$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232634/a-question-about-fourier-transform/232707\nText:\nTake the 2-minute tour \u00d7\n\nI just don't know how to calculate the the fourier transform of $1/(1+x^2)$.Can you help me guys? Thx\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nYou need to use the duality property of the Fourier transform:\n\nTheorem: Let $\\hat{f}(w) = $$\\mathcal{F}[f(t)]$, then the following duality property holds:\n\n$$\\mathcal{F} \\, \\big [\\hat{f}(t) \\big ] = 2 \\pi f(-w).$$\n\nSo, look at your table and see this convenient identity:\n\n$$\\mathcal{F} \\, \\Big [\\frac{1}{2a}e^{-a|t|} \\Big ] = \\frac{1}{a^2 + w^2}.$$\n\nNow apply the duality property:\n\n$$\\mathcal{F} \\, \\Big [ \\frac{1}{a^2 + t^2} \\Big ] = \\frac{\\pi}{a} e^{-a|w|}$$\n\nThen, the answer to your question is:\n\n$$\\mathcal{F} \\, \\Big [ \\frac{1}{1 + t^2} \\Big ] = \\pi e^{-|w|}.$$\n\nshare|improve this answer\nI got , THANK YOU VERY MUCH \u2013\u00a0 dbzhu Nov 8 '12 at 8:12\nIf my answer was helpful, then please upvote/accept it. Thanks. \u2013\u00a0 Charles Boyd Nov 8 '12 at 9:13\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/49631/when-random-walk-is-upper-unbounded\nText:\nTake the 2-minute tour \u00d7\n\nConsider a random walk $S_n = a_1+\\dots+a_n$ where $a_n$ are iid random variables with $Ea_1 = a$ and $E|a_1|<\\infty$.\n\nI am interested in the case when $\\sup\\limits_n S_n>M$ for all $M$ a.s. Can you refer me to a rigorous proof that it not hold for $a<0$?\n\nFor $a>0$ it holds by Law of Large Numbers since if $P(\\sup\\limits_n S_n\\leq M) = p$ then either $\\lim\\limits_n\\frac1n S_n$ does not exists, or $\\lim\\limits_n\\frac1n S_n\\leq 0$ with probability $p$.\n\nFor $a=0$ it holds if $0<Var(a_1)<\\infty$ due to the Law of Iterated Logarithm. For $Var(a_1) = 0$ it certainly does not hold.\n\nshare|improve this question\nAs far as I know, the Law of Iterated Logarithm only applies if ${\\rm Var}(a_1) < \\infty$. \u2013\u00a0 George Lowther Jul 5 '11 at 21:09\nYes, sure - I fixed it. \u2013\u00a0 Ilya Jul 6 '11 at 6:13\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nWhen $a<0$, $S_n/n\\to a$ almost surely, in particular $S_n\\to-\\infty$ almost surely, in particular $(S_n)$ is almost surely upper bounded. This implies that $P(\\sup_nS_n\\ge M)\\to0$ when $M\\to+\\infty$, in particular $P(\\sup_nS_n\\ge M)<1$ for every $M$ large enough. (Actually, $P(\\sup_nS_n\\ge M)<1$ for every positive $M$.)\n\nI see no other question in your post.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/116525/the-form-of-the-states-on-an-algebra-of-n-times-n-matrices-with-complex-entrie\nText:\nTake the 2-minute tour \u00d7\n\nI have a question concerning $n \\times n$ matrices.\n\nDenote by $M_n(\\mathbb{C})$ the algebra of all $n \\times n$ matrices with complex entries. Let $\\phi$ be a state on $M_n(\\mathbb{C})$ i.e. a linear functional $\\phi \\colon M_n(\\mathbb{C}) \\rightarrow \\mathbb{C}$ such that $\\phi(Id)=1$ and $\\phi(A^*A) \\geq 0$, for each $A \\in M_n(\\mathbb{C})$.\n\nShow that $\\phi$ must be of the form $\\phi(A) = \\text{tr}(\\rho A)$, where $\\rho$ is a positive-definite matrix such that $\\mbox{tr}(\\rho)=1$.\n\nThank you for any help.\n\nshare|improve this question\nThis looks like a (homework) question. \u2013\u00a0 user2468 Mar 5 '12 at 2:50\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThis is the well known fact in Functional Analysis that the trace-class operators are the dual of the compact operators.\n\nIf you fix matrix units $\\{E_{kj}\\}$, let $$ \\rho=\\sum_{k,j}\\phi(E_{jk})E_{kj}. $$ Then, for any $A=\\sum_{kj}a_{kj}E_{kj}$, $$ \\text{tr}(\\rho A)=\\sum_{h}(\\rho A)_{hh}=\\sum_{h,k}\\rho_{hk}a_{kh}=\\sum_{h,k}\\phi(E_{kh})\\alpha_{kh}=\\phi(A). $$ The positivity of $\\phi$ implies that $\\rho$ is selfadjoint (i.e. hermitian). We also have $\\text{tr}(\\rho)=\\phi(\\text{Id})=1$.\n\nIt only remains to see that $\\rho$ has non-negative eigenvalues. Since $\\rho$ is selfadjoint, we have $$ \\rho=\\sum_{k}\\lambda_kP_k, $$ where $\\lambda_1,\\ldots,\\lambda_n$ are the eigenvalues of $\\rho$, and $P_k$ are rank-one pairwise orthogonal projections with sum $\\text{Id}$. Since $\\text{tr}(P_k)=1$ for all $k$, we have $$ \\lambda_k=\\text{tr}(\\rho P_k)=\\phi(P_k)=\\phi(P_k^*P_k)\\geq0 $$ by the positivity of $\\phi$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/112411/solving-the-system-sum-sin-sum-cos-0/113612\nText:\nTake the 2-minute tour \u00d7\n\nCan we solve the system of equations:\n\n$$\\sin \\alpha + \\sin \\beta + \\sin \\gamma = 0$$\n\n$$\\cos \\alpha + \\cos \\beta + \\cos \\gamma = 0$$\n\n\n(i.e. find the possible values of $\\alpha, \\beta, \\gamma$)\n\nshare|improve this question\nadd comment\n\n5 Answers\n\nup vote 11 down vote accepted\n\nTry something similar to what has been posted yet. Take one variable to the other side, then square and add the equations. What you get is $\\alpha-\\beta=120\u00b0$ and same for cyclic permutations (or negating all angles). The solutions is the three angles $\\delta$, $\\delta+120\u00b0$, $\\delta-120\u00b0$ (arbitrary $\\delta$) in any order.\n\nEDIT: Or simply realize that the equations are equivalent to $\\exp(i\\alpha)+\\exp(i\\beta)+\\exp(i\\gamma)=0$ which make the answer immediately obvious.\n\nshare|improve this answer\nadd comment\n\nDeveloping on Gerenuk's answer, you could consider the complex numbers\n\n$$ z_1=\\cos \\alpha+i\\sin \\alpha,\\ z_2=\\cos \\beta+i\\sin\\beta,\\ z_3=\\cos \\gamma+i\\sin \\gamma$$\n\nThen you know that $z_1,z_2,z_3$ are on the unit circle, and the centroid of the triangle formed by the points of afixes $z_i$ is of afix $\\frac{z_1+z_2+z_3}{3}=0$. From classical geometry, we can see that if the centroid of a triangle is the same as the center of the circumscribed circle, then the triangle is equilateral. This proves that $\\alpha,\\beta,\\gamma$ are of the form $\\theta,\\theta+\\frac{2\\pi}{3},\\theta+\\frac{4\\pi}{3}$.\n\nshare|improve this answer\nadd comment\n\nTry writing $$ \\sin^2(\\alpha)=(\\sin(\\beta)+\\sin(\\gamma))^2=\\sin^2(\\beta)+\\sin^2(\\gamma)+2\\sin(\\beta)\\sin(\\gamma)\\tag{1} $$ and $$ \\cos^2(\\alpha)=(\\cos(\\beta)+\\cos(\\gamma))^2=\\cos^2(\\beta)+\\cos^2(\\gamma)+2\\cos(\\beta)\\cos(\\gamma)\\tag{2} $$ then add $(1)$ and $(2)$ to get $$ 1=1+1+2\\cos(\\beta-\\gamma)\\tag{3} $$ which means $\\cos(\\beta-\\gamma)=-\\frac12$. The same is true for the other pairs, so we get that each of $\\alpha$, $\\beta$, and $\\gamma$ differ from each other by $\\frac{2\\pi}{3}$, which is the same answer that was achieved using complex means already.\n\nshare|improve this answer\nNice Answer without complex numbers. \u2013\u00a0 user21436 Feb 26 '12 at 15:25\nadd comment\n\nHere's an algebraic proof : Write $z_k = e^{i \\alpha_k}$. Then your equations are equivalent to $z_1 + z_2 + z_3 = 0$. Write $\\theta = \\frac{\\alpha_1 + \\alpha_2 + \\alpha_3}{3}$ and $z = e^{i \\theta}$\n\nExpand the polynomial $P = (X-z_1)(X-z_2)(X-z_3)$. The $X^2$ term is $0$ by hypothetis, and the $X$ term can be written as $z_1 z_2 z_3 (z_1^* + z_2^* + z_3^*) = 0$. So $P = X^3 - z_1 z_2 z_3 = X^3 - z^3$. So the roots are $z . e^{2i k \\pi /3}$.\n\nshare|improve this answer\nadd comment\n\nMore of a comment and less of an answer!\n\nWell, your information seems to tell us that,\n\n\n(To see this, square both equalities and add.)\n\nI don't see any other obvious thing, you can do with these equations. If any thought plops up, I will type it in here.\n\nshare|improve this answer\nYour relation should be with $\\alpha-\\beta,\\beta-\\gamma$ and $\\gamma-\\alpha$ \u2013\u00a0 Beni Bogosel Feb 23 '12 at 17:58\n@BeniBogosel I am sorry for having made that blunder. Thanks for the pointer. That the answer has posted, I'll flag it for the moderator to make it CW. \u2013\u00a0 user21436 Feb 24 '12 at 8:01\nYour result follows from my answer which shows that $$\\cos(\\alpha-\\beta)=\\cos(\\beta-\\gamma)=\\cos(\\gamma-\\alpha)=-\\frac12$$ \u2013\u00a0 robjohn Feb 26 '12 at 23:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/208851/need-a-tip-hint-evaluating-a-limit?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have the following limit:\n\n\nwhere $0<b<a$.\n\nI care for the case where $\\epsilon>-1/2$. I suspect that for $\\epsilon>0$ this limit evaluates to 1, and for $-1/2<\\epsilon\\leq0$ it evaluates to 0. However, I am having hard time evaluating this. I have tried taking the log of the expression (moving the $x$ in the exponent down), substituting $y=1/x$ and then Taylor-expanding the log, but didn't get anywhere.\n\nDoes anyone have any tips/hints that might help me evaluate this?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nSince $c=1/2+\\varepsilon\\gt0$, one knows that $1-\\exp(-bx^{-c})\\sim bx^{-c}$ and $\\log(ax^{-c})\\sim-c\\log(x)$ when $x\\to+\\infty$. Thus, the function to be evaluated is $$ f(x)=(1-kg(x))^x,\\quad k=abc\\gt0,\\quad g(x)\\sim x^{-2c}\\log x. $$ Since $g(x)\\to0$ and $\\log(1+u)\\sim u$ when $u\\to0$, $$ f(x)=\\exp\\left[x\\log(1-kg(x))\\right]=\\exp\\left[-kxg(x)\\cdot(1+o(1))\\right]. $$ Note that $xg(x)\\sim x^{-2\\varepsilon}\\log x$ and recall that $k\\gt0$. This yields:\n\n  \u2022 If $-1/2\\lt\\varepsilon\\leqslant0$, then $xg(x)\\to+\\infty$ hence $f(x)\\to0$ when $x\\to+\\infty$.\n  \u2022 If $\\varepsilon\\gt0$, then $xg(x)\\to0$ hence $f(x)\\to1$ when $x\\to+\\infty$.\nshare|improve this answer\nSo it turns out I made a mistake in the original definition of the problem: I flipped the plus sign after the first 1 to a minus sign when I was typing this up (I've edited the question since I saw your answer and my mistake). However, you solved the problem that I originally had in mind (otherwise the minus in $-c\\log(x)$ would've flipped the minus in your re-definition of $f(x)=(1-kg(x))^x$ to a plus). Thank you, this confirms my intuition (which was backed up by numerical evaluations)! \u2013\u00a0 M.B.M. Oct 8 '12 at 5:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122257/finding-the-formula-for-bezier-curve-ratios-hull-point-point-baseline\nText:\nTake the 2-minute tour \u00d7\n\nGiven a cubic Bezier curve defined by points p\u2081, p\u2082, p\u2083, and p\u2084, a point B on that curve at some t value (where 0 \u2264 t \u2264 1), a point A on the line (p\u2082p\u2083) at distance ratio t from p\u2082, and a point C that is the intersection of the line (p\u2081p\u2084) and the line that goes through A and B, the ratio between distance d1 = (AB) and d2 = (BC) is a fixed value, regardless of the values for coordinates p\u2081, p\u2082, p\u2083, and p\u2084\n\nI'd like to find the formula that expresses this ratio as a function of t (all interactive graphing experiments suggest that this function is an identity function for cubic Bezier curves, not actually being dependent on the coordinates used for the curve) but I'm having little success coming up with something satisfactory. My math skills are not sufficient...\n\nI initially wrote up a quick data-generator using the \"Processing\" programming language to see if I could use that data for polynomial regression (based on the fact that the function is symmetrical around t = 0.5, finding the expression for the interval t=0.5 to t=1), but the fact that the ratio is actually asymptotic at t = 0 and t = 1 (towards positive infinity) means that it's not a straight-forward power function.\n\ncurve parameter -> ratio plot.\n\n(note: the jsfiddle link doesn't actually log all 5000 step values; normal Processing does)\n\nWould anyone know how to express this ratio function as a proper formula? I don't quite know how to approach this symbolically, as I'm using de Casteljau's algorithm to determine my red and green lines; since I don't know how to symbolically express the values d1 and d2, expressing the ratio d1/d2 as a function is quite hard.\n\nN.B.: Apologies if the tags don't fit the question. I'll take suggestions on using the right ones instead; first question on MathOverflow.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nA cubic bezier defined by $p_1, p_2, p_3, p_4$ has parametric equation $$B(t) = (1-t)^3p_1 + 3(1-t)^2tp_2 + 3(1-t)t^2p_3 + t^3p_4.$$\n\nThe setup here also defines $A(t) = (1-t) p_2 + tp_3$.\n\nThe way $C$ is defined, there are some real $s(t)$ and $u(t)$, both possibly depending on $p_1,\\ldots,p_4$ such that $C = sA + (1-s)B = up_1 + (1-u)p_4$.\n\nSo $B - C = B - sA - (1-s)B = s(B-A)$. Hence $\\frac{|B - C|}{|A - B|} = |s|$.\n\nOn the other hand, we want $sA + (1-s)B - up_1 - (1-u)p_4 = 0$. That comes out to\n\n$$((1-s)(1-t)^3 - u)p_1 + (s(1-t) + 3(1-s)t(1-t)^2)p_2 + (st + 3(1-s)t^2(1-t))p_3 + ((1-s)t^3 - (1-u))p_4 = 0.$$\n\nSet $$s = \\frac{t^3+(1-t)^3-1}{t^3 + (1-t)^3}$$ and $$u = \\frac{(1-t)^3}{t^3 + (1-t)^3}.$$\n\nThen the coefficents of $p_1,\\ldots,p_4$ in the above expression become identically 0. Note that the denominators of these expressions are never 0 for $t \\in [0,1]$, so the divisions are ok.\n\nSo your ratio is given by the $|s|$ above (or its reciprocal, depending on how you're taking the ratio).\n\nshare|improve this answer\nyou are a hero, thanks! \u2013\u00a0 Mike 'Pomax' Kamermans Feb 19 '13 at 18:34\nadd comment\n\nJust in case someone finds this question using google at some point, and is also curious about the solution for the quadratic case, its solution is similar:\n\n$A(t) = p_2$\n\n$B(t) = (1-t)^2p_1 + 2t(1-t)p_2 + t^2p_3$\n\n$C(t) = sA(t) + (1-s)B(t) = up_1 + (1-u)p_2$\n\nThis requires solving:\n\n$$sp_2 + (1-s)((1-t)^2p_1 + 2t(1-t)p_2 + t^2p_3) - up_1 + (1-u)p_2 = 0$$\n\nwhich, expressed in terms of the control points, is:\n\n$$((1-s)(1-t)^2 - u)p_1 + (s+2t(1-s)(1-t))p_2 + ((1-s)t^2 + u - 1)p_3 = 0$$\n\nIf we want these coefficients to become identically zero, we can determine s(t):\n\n$$(1-s)(1-t)^2 = u = -((1-s)t^2 - 1)$$\n\nwhich means solving:\n\n$$(1-s)(1-t)^2 + ((1-s)t^2 - 1) = 0$$\n\nwhich gives us the following expressions for s and u (after substituting s into either of the identities for u and solving):\n\n$$s(t) = \\frac{2t^2 - 2t}{2t^2 - 2t + 1}$$\n\n$$u(t) = \\frac{(t-1)^2}{2t^2 - 2t + 1}$$\n\n(Also note that there are no solutions for curves of order 4 and higher; unlike for quadratic and cubic curves, the ratio between the two distances is not a fixed value for higher order curves, unfortunately)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/241795/show-that-there-cannot-be-an-entire-function-f-that-satisfy-the-following-cond\nText:\nTake the 2-minute tour \u00d7\n\nShow that there cannot be an entire function $F$ such that $F(x) = 1-\\exp(2\\pi i/x)$ for $1 \\leq x \\leq 2$. I think this has got something to do with Rouche's Theorem or the Argument Principle, but I'm not sure how to apply either of these to this specific problem. Can anyone shed some light?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nIf $F(x)=1-\\exp(2\\pi i/x)$ for $1\\leq x\\leq 2$ and $f$ is entire, then in fact that equality holds over the whole of $\\Omega=\\mathbb C\\setminus\\{0\\}$. Indeed, the two sides of the equality are holomorphic functions on the connected set $\\Omega$ which coincide in a set which accumulates inside $\\Omega$.\n\nNow you should be able to check that there is no entire function which coincides with $1-\\exp(2\\pi i/x)$ on all of $\\Omega$.\n\nshare|improve this answer\nCan you elaborate a bit more? I don't understand why the equality has to hold over the punctured complex plane. \u2013\u00a0 Aden Dong Nov 21 '12 at 18:54\nSee the \u00abimprovement\u00bb section in this Wikipedia page. This should be done in all complex analysis textbooks. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Nov 21 '12 at 19:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/131336/help-with-this-diophantine-equation\nText:\nTell me more \u00d7\n\nNote: This question was posted in error, and should be closed as no longer relevant. The correct question is posted at Help with this system of Diophantine equations (End of note)\n\nFor a research problem that I'm working on, I need to solve this Diophantine equation:-\n\n$a^3+b^3+c^3-3d=-83449$, where $a,b,c,d>0$ are all DISTINCT positive integers and$ a,b,c\u2209 ${$2,9,15,16,33,34$}.\n\nHow does one go about solving this? Is brute-force the only possible way? Or could there be a case that no integer solutions exist for this equation?\n\nAlso, are there any online computing engines, that allow me to set constraints, and solve Diophantine equations of this sort?\n\nAny and all help is appreciated! Thanks!\n\nshare|improve this question\nYour conditions imply a is less than 70, and from this you can get small bounds on b and c. This is well within a brute force search with a laptop, and you can use digital considerations and perhaps a table of cubes to do much of the search by hand. Gerhard \"Ask Me About System Design\" Paseman, 2013.05.21 \u2013\u00a0 Gerhard Paseman May 21 at 13:49\n@Gerhard: Why do the conditions imply that $a < 70$? \u2013\u00a0 Stefan Kohl May 21 at 13:55\nStefan, I made the mistake of assuming b and c were both larger than a. I see now that there is no bound on $a^3$ when it is larger than one of the cubes. There are some restrictions mod 3 on b-a and c-a, but they don't seem as useful now. Gerhard \"Missed It By A Lot\" Paseman, 2013.05.21 \u2013\u00a0 Gerhard Paseman May 21 at 14:50\nThank you guys, for the replies! But sorry to say, my original equation was at fault. I've edited the question now. \u2013\u00a0 Jobin Idiculla May 21 at 15:15\nThis question (in its original form) was posted at\u2026 -- @Jobin, please do not cross-post the same question at both sites -- it can result in unnecessary duplication of effort. (It is sometimes OK to do so, if time has passed and you haven't gotten an answer at math.stackexchange, but even then you should say so and include the link.) \u2013\u00a0 Barry Cipra May 21 at 15:59\nshow 5 more comments\n\n3 Answers\n\nFor $0 < a \\le3966887 $ solutions are $(9419, 10418, 8146),(69167, 10776, 87090)$ and (added) $(3966887, 2434179, 4797573)$.\n\nHere is an idea for searching. Loop $a$ from $1$ to certain bound.\n\nYou have to solve $x^3 + y^3 = C + 2 a^3 = N$. This is easy to solve if $N$ can be factored since $x^3+y^3$ factors nicely.\n\nAdded to the edited question\n\nYou have to solve $ a^3+b^3+c^3 + 83449 = 3 d $\n\nJust pick \"random\" $a,b,c$ such the the lhs is divisible by $3$ like $(300,301,304)$ and $d=27482938$\n\nHere is a pari/gp script which found the solutions.\n\n if(v == [],next);\nshare|improve this answer\nI just realized I'd made a huge mistake in my assumptions for the problem. Subsequent calculations reveal my required Diophantine equation to be a^3 + b^3 + c^3 - 3d = -83449. Here, 'd' is also a positive integer, but NOT subjected to the constraint that d be in {2,9,15,16,33,34}. Could you help solve this, please? \u2013\u00a0 Jobin Idiculla May 21 at 15:07\nDo you mean \"that $d$ not be in\"? \u2013\u00a0 Joel Reyes Noche May 21 at 15:30\nI'm terribly sorry for troubling you again, joro. I'd committed a blatant \"freshman\" error again. I've newly posted the question I'd actually meant to ask here:-\u2026 \u2013\u00a0 Jobin Idiculla May 21 at 16:03\nadd comment\n\nSorry for a long comment. Joro has given a nice answer already. Writing $36650=b^3+c^3-a^3-a^3$, the question is related to the problem which numbers can be represented by the sum of $4$ signed cubes. A result of Demjanenko says that all numbers not of the form $9n \\pm 4$ are representable as a sum of four signed cubes. Indeed, all integers $n\\le 10^7$ have such a representation, and for $n$ sufficently large the representation also exists (see the artcle Kenji Koyama, On searching for solutions of the Diophantine equation $x^3 + y^3 + 2z^3 = n$ , Math. Comput. 69 (2000).\n\nEDIT: the new equation seems to be $a^3+b^3+c^3=n=3d-83449$. The conjecture is that this has solutions if and only if $n$ is not of the form $9k\\pm 4$.\n\nshare|improve this answer\nNot sure if this is correct, check the counterexamples in my answer. \u2013\u00a0 joro May 21 at 15:03\nSorry guys for the trouble, but my question was in error. I've edited it accordingly now. \u2013\u00a0 Jobin Idiculla May 21 at 15:18\nFrom (\"On partitions into four cubes\" by Moreno and Palma): Demjanenko [7] proved that every number $n \\nequiv \\pm4 \\mod 9$ can be expressed as the sum of four positive or negative cubes: $x^3 + y^3 + z^3 + w^3$. \u2013\u00a0 Barry Cipra May 21 at 15:36\nsorry, that \"\\nequiv\" was meant to be a $\\not\\equiv$. \u2013\u00a0 Barry Cipra May 21 at 15:38\nadd comment\n\nLet a,b,c satisfy the restrictions given, as well as $1 + a + b + c $ is a multiple of $3$. Then $83449 + a^3 + b^3 + c^3$ is also a multiple of 3, and then $d$ can be chosen to be $1/3$ of the last quantity.\n\nGerhard \"3D Makes It So Easy\" Paseman, 2013.05.21\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/351623/does-an-mid-bn-imply-a-mid-b\nText:\nTell me more \u00d7\n\nDoes $a^n \\mid b^n$ imply $a\\mid b$? I think it does but haven't been able to prove it. I don't know much number theory so an elementary answer would be great.\n\nshare|improve this question\nHint: Look at prime factors. \u2013\u00a0 Brett Frankel Apr 5 at 0:29\nYou can start with the fundamental theorem of arithmetic. \u2013\u00a0 julien Apr 5 at 0:30\nConsider this. Might I call yhis a duplicate? Since they end up in asking the same question. \u2013\u00a0 awllower Apr 5 at 13:32\n@awllower: you're right that it's a duplicate, but I think this one has better answers. \u2013\u00a0 Javier Badia Apr 5 at 14:16\n@JavierBadia Probably because the previous one prohibited the use of GCD and UFD. \u2013\u00a0 awllower Apr 5 at 15:01\nadd comment\n\n3 Answers\n\nup vote 6 down vote accepted\n\nIf you can assume the fundamental theorem of arithmetic (that each integer has a unique factorization in prime numbers), you can write: $$ \\begin{align*} a &= p_1^{e_1} p_2^{e_2} \\ldots p_r^{e_r} \\\\ b &= q_1^{d_1} q_2^{d_2} \\ldots q_s^{d_s} \\end{align*} $$ Here the $p_i$, $q_i$ are primes, and $e_i$ and $d_i$ are all greater than 0. If $a^n \\mid b^n$, then $p_i^{n e_i}$ must have a counterpart in a $q_j^{n d_j}$, in that $p_i = q_j$ and $n e_i \\le n d_j$, so it must then also be that $e_i \\le d_j$; and this means $a \\mid b$.\n\nshare|improve this answer\nadd comment\n\nHint $\\ $ Either examine exponents in unique prime factorizations, or, by the Rational Root Test, the reduced rational root $\\rm\\:x = b/a\\:$ of $\\rm\\:x^n = c\\in\\Bbb Z\\:$ must be integral, so $\\rm\\:b/a\\in\\Bbb Z\\:\\Rightarrow\\:a\\mid b.$\n\nshare|improve this answer\n@Peter For that, after cancelling any common factor, one needs only $\\rm\\:(a,b)=1\\:\\Rightarrow\\:(a,b^n)=1,\\:$ true by iterating Euclid's Lemma. Thus $\\rm\\:1 < a\\nmid b^n,\\:$ so $\\rm\\:a^n\\nmid b^n.\\ \\ $ \u2013\u00a0 Math Gems Apr 5 at 0:41\nYes, that was my idea. I was awfully unclear, sorry. \u2013\u00a0 Pedro Tamaroff Apr 5 at 0:44\nadd comment\n\nHint: $p$ is a prime factor of $k$ if and only if $p^n$ is a factor of $k^n$. This holds for any prime $p$, integer $k$, and positive integer $n$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/63491.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nMean Latitude/Longitude\n\nDate: 07/10/2003 at 14:21:30\nFrom: Peter Richard\nSubject: Spherical Trigonometry\n\nIf we have three points on the earth measured in latitude/longitude, \nsuch as 'A'= 33S54;151E12 / 'B'= 37S49;144E58 / 'C'= 51N30;0W10 \nwhat is the formula to calculate a mean latitude/longitude for this \ngroup of 3?\n\nWhen I say 'mean latitude/longitude' I am referring to a 'midpoint in \nspace' between the three. So perhaps if I used the term 'equidistant' \nrather than 'mean' it might make it clearer.\n\nDate: 07/15/2003 at 14:47:57\nFrom: Doctor Rick\nSubject: Re: Spherical Trigonometry\n\nHi, Peter.\n\nI might approach this as follows: \n\nConvert the lat-long positions into x,y,z coordinates, find the mean \nposition in 3-dimensional space, and project this point back onto the \nsphere, and convert back to latitude and longitude. (I am assuming - \nand hoping - that a spherical approximation to the earth's surface \nis sufficient.)\n\nThis method will give the correct result in the \"flat-earth \napproximation\" in which the points are close enough together that the \ncurvature of the earth can be ignored. It seems like a reasonable \noperational definition of an average position on the earth, but I'm \nbeing rather intuitive at this point.\n\nTo convert each location to (x,y,z) coordinates, use the formulas\n\n  x_n = cos(lat_n)*cos(lon_n)\n  y_n = cos(lat_n)*sin(lon_n)\n  z_n = sin(lat_n)\n\nwhere location n has latitude lat_n and longitude lon_n. I have set \nthe radius of the earth equal to 1 since we aren't interested in \nactual distances; the radius would cancel out eventually anyway.\n\nAverage the coordinates independently:\n\n  x = (x_1 + x_2 + x_3)/3\n  y = (y_1 + y_2 + y_3)/3\n  z = (z_1 + z_2 + z_3)/3\n\nNow convert to latitude and longitude using the inverse transformation\n\n  lat = arcsin(z/r)\n  lon = arctan(y/x)\n\nI haven't tested this, so let me know if you have any trouble with \nit. If you're programming, you should use the atan2() function found \nin many programming languages, spreadsheets etc. Otherwise you'll \nhave to do some extra stuff if x = 0 or if the longitude is more than \n90 degrees from the Prime Meridian.\n\nThe \"mean\" in any ordinary sense can be quite different from the \npoint that is equidistant from three points. To demonstrate, draw a \ncircle and pick three points on the circle, all on the right side. \nThe point that is equidistant from the three points is the center of \nthe circle. I doubt that this is what you mean by \"mean\"! (However, \nit could be what you want: If you expect a structure to be circular \nand you have found three points on the edge of the structure, you \ncould use such a method to find the center of the structure.)\n\n- Doctor Rick, The Math Forum\nAssociated Topics:\nHigh School Higher-Dimensional Geometry\nHigh School Trigonometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/88486/probability-of-iid-sum-being-positive/88541\nText:\nTell me more \u00d7\n\nLet $X_1,X_2,...$ be iid random variable with mean zero. If $X_1$ has second moment then by the CLT we have $P(X_1+X_2+...+X_n\\geq 0)\\rightarrow \\frac{1}{2}$, as $n$ goes to infinity. I am curious about whether does this hold without the second moment assumption? I think this might be a well studied problem. Could anyone provide an answer or reference to me? Many thank!\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nNo, this does not hold without the finite second-moment assumption, in general.\n\nConsider the Levy $\\alpha$-stable distributions, which will yield a whole family of examples. Using the parametrization, e.g., on the Wikipedia page, if $X$ is $\\alpha$-stable, for $1 < \\alpha < 2$, then it has characteristic function $$ \\varphi(t) = \\mathbb E e^{i t X} = \\exp(i t \\mu - |ct|^{\\alpha} (1 - i \\beta \\mathrm{sgn}(t) \\tan(\\pi \\alpha/2))) ~. $$\n\nFor the given range of $\\alpha$, we also have that $\\mathbb E X = \\mu$ and $\\mathbb E X^2 = \\infty$.\n\nTake $\\mu = 0$, $c = \\beta = 1$ and $\\alpha = 3/2$, for simplicity and concreteness. Then, we get $$ \\varphi(t) = \\exp(- |t|^{3/2} (1 + i \\mathrm{sgn}(t))) ~. $$\n\nClearly, $\\varphi(t) \\neq \\varphi(-t)$, so, in particular, $X$ is not symmetric.\n\nHowever, observe that if $X_1,\\ldots,X_n$ are iid with this distribution and $S_n = X_1 + \\cdots + X_n$, then $n^{-2/3} S_n$ has the same characteristic function as $X$ since $(\\varphi(n^{-2/3}t))^n = \\varphi(t)$, and, hence the same distribution.\n\nTherefore, $\\mathbb P(S_n \\geq 0) = \\mathbb P(X \\geq 0) \\neq 1/2$.\n\nshare|improve this answer\n$X$ being asymmetric is not sufficient for $\\mathbf P(X\\ge 0)\\ne \\mathbf P(X\\le 0)$, so there needs more work than symmetry to show the latter claim. \u2013\u00a0 Hansen 2 days ago\nadd comment\n\nI suspect not. Let $(p^{(n)})$ be a sequence tending to 0 fast and for each $n$, let $X^{(n)}_j$ be an iid sequence of random variables taking the value $1/p^{(n)}$ with probability $p^{(n)}$ and 0 otherwise (so that $\\mathbb EX^{(n)}_j=1$ for each $n$ and $j$).\n\nNow let $Z_j=X^{(1)}_j/3-\\sum _{n=2}^\\infty (-1/2)^nX^{(n)}_j$. (This is chosen to make sure that $\\mathbb EZ_j=0$.\n\nNow if the $p^{(n)}$ are chosen to go to 0 rapidly enough, I claim that the $Z_j$ fail to have the property you're looking for. For example, let $N^{(n)}=10\\uparrow 10\\uparrow\\ldots\\uparrow10$ (i.e. a tower of height $n$) and $p^{(n)}=1/N^{(n)}$. Then for $N^{(n-1)}\\ll J\\ll N^{(n)}$, the chances of having seen a contribution at level $n$ or higher is negligible, whereas it's likely that contributions at the previous level will have equilibriated. So the partial sum should be negative with very high probability if $n$ is odd and positive with very high probability if $n$ is even...\n\nshare|improve this answer\nadd comment\n\nI think this is false without the second moment assumption. Construct $X_n$ of the form $$ X_n = -1+\\sum_{k\\ge 1} Y_n^k, $$ where $Y_n^k\\ge 0$, $E[Y_n^k]=2^{-k}$, $P(Y_n^k>0)=\\epsilon_k$ and $(Y_n^{k+1}>0)\\subset(Y_n^k>0)$. Choose the $\\epsilon_k$ inductively as follows: Assume $\\epsilon_1,\\ldots,\\epsilon_k$ have already been chosen, so that $$ X_n^k := -1+\\sum_{j=1}^k Y_n^j $$ is already defined. Observe that $X_n^k$ has negative expectation, so that by the law of large numbers you can find an arbitrarily large integer $n_k$ such that $$ P\\left(\\frac{1}{n_k} \\sum_{n=1}^{n_k} X_n^k < 0 \\right) > 99/100. $$ Then choose $\\epsilon_{k+1}$ so small that $$ P\\left( Y_1^{k+1}=0,\\ldots,Y_{n_k}^{k+1}=0 \\right) > 99/100, $$ then $$ P\\left(\\frac{1}{n_k} \\sum_{n=1}^{n_k} X_n < 0 \\right) > 98/100. $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/9551/concentration-of-measure-for-gaussian-inner-products?sort=votes\nText:\nTake the tour \u00d7\n\nThere exists extensive theory for the concentration of Gaussian measure. Through that, it can be easily proved that the square of the $\\ell_2$ norm of a length $n$ zero mean Gaussian vector ${\\bf x}$ with covariance matrix ${\\bf I}_n$ is concentrated around $n$ with overwhelming probability. Such a result also follows immediately from the Restricted Isometry Property that holds for Gaussian matrices. I was wondering if any concentration results could be inferred for inner products of Gaussian i.i.d random variables. Namely, if $\\Pr(|{\\bf x}{\\bf y}|<\\alpha)$ is overwhelming (or exponentially vanishing in $n$) for some meaningful $\\alpha$.\n\nshare|improve this question\nYour notation isn't clear. Do you want a concentration result for ${\\rm Pr}(| |\\langle x,y\\rangle| - \\mu | < \\epsilon$? Where $\\mu$ is say a mean or median and $x$ and $y$ are independent Gaussian vectors? If so, this is a standard result. \u2013\u00a0 Steve Flammia Dec 22 '09 at 17:39\nI was looking for $\\Pr(||\\langle x,y\\rangle|-\\sqrt{n}|<\\epsilon)$ and x,y are i.i.d Gaussian zero mean vector with covariance matrix the identity of size $n\\times n$ \u2013\u00a0 anadim Dec 22 '09 at 17:54\nyes, this is true for any alpha> pi/2 \u2013\u00a0 Gil Kalai Dec 22 '09 at 18:26\nOne way to say it is that most ponts in the sphere are near the equator. (You can assume x is the north pole.) This follows from the formulas for volumes of spherical caps. \u2013\u00a0 Gil Kalai Dec 22 '09 at 18:28\nGil, you should post this as an answer! \u2013\u00a0 Greg Kuperberg Dec 23 '09 at 6:58\nadd comment\n\n2 Answers\n\nIf you have 2 standard Gaussians in $\\mathbb{R}^n$, their inner product is the sum of $n$ i.i.d. variables, with their common distribution fixed (and having finite moments), so you will get convergence to the appropriate Gaussian distribution in line with the central limit theorem, with exponential bounds coming from Hoeffding's inequality, say. Do you need tight bounds or asymptotics is enough?\n\nshare|improve this answer\nAlso, what Gil Kalai said: testing for $|\\langle x,y \\rangle|<\\alpha$ is with high probability in $x$ testing for $y$ to fall within a layer of width $2\\alpha/\\sqrt{n}$ centered around the origin, so up to an exponentially decaying error you get $2\\Phi\\left(\\frac{\\alpha}{\\sqrt{n}}\\right)$, so you will get exponential bounds for $\\alpha >> \\sqrt{n \\log n}$. \u2013\u00a0 Thorny Dec 23 '09 at 8:55\nadd comment\n\nI am not sure if I am understanding you quite clearly: you have i.i.d Gaussian random variables $x_i, y_i$ so that for any $\\alpha > 0$ the quantity $P[|\\sum_i x_i y_i| < \\alpha]$ goes to zero. What you are looking for is the rate of convergence to zero ? Or you are looking for a function $\\phi$ that gives non-trivial bounds like $P[|\\sum_{i=1}^n x_i y_i| < \\alpha] \\leq \\phi(\\alpha, n)$ ?\n\nshare|improve this answer\nI am trying to find such a function $\\phi$ that is exponentially vanishing in $n$. \u2013\u00a0 anadim Dec 22 '09 at 18:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/242473/connected-manifold-hole-connected-manifold/242685\nText:\nTake the tour \u00d7\n\nIf I have a connected manifold and I poke a hole in the interior of the manifold, it seems obvious that the manifold is still connected. But how would you prove this?\n\nMore precisely, let $M$ be a connected $n$-manifold with $n>1$ and let $B$ be a subset of $\\operatorname{Int} M$ homeomorphic to the unit closed ball in $\\mathbb{R}^n$. Is $M \\setminus B$ connected? Can $B$ be any simply connected closed set?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nI think the result is true if $B$ is any connected $n$-dimensional submanifold whose boundary is also connected. That includes a closed $n$-ball. I'm assuming the manifolds and embedding are piecewise linear (PL), and that we're talking about path-connectedness rather than general connectedness.\n\nHere's a proof. Consider a path $\\gamma$ with endpoints in $M - B$. The intersection of $\\gamma$ with $B$ is a disjoint union of paths $\\sigma$, each with its endpoints in the boundary Bd $B$. Since Bd $B$ is connected, we can replace each $\\sigma$ with a $\\sigma'$ with the same endpoints which lies entirely in Bd $B$.\n\nNow we want to push $\\sigma'$ slightly away from $B$ so that it doesn't meet $B$ at all. Choose a small regular neighborhood $N$ of Bd $B$. $N$ is an $I$-bundle over Bd $B$, in which Bd $B$ embeds as a section and each fiber has one end inside $B$ and one end outside $B$. So the bundle is trivial, and we have an embedding $f: N \\times [0, 1] \\rightarrow M$ with $f(N \\times \\{0\\})$ in the interior of $B$, $f(N \\times \\{1/2\\}) =$ Bd $B$, and $f(N \\times \\{1\\})$ outside $B$. In particular the obvious projection $f(N \\times [1/2, 1]) \\rightarrow f(N \\times \\{1\\})$ is a retraction which pushes $\\sigma'$ out of $B$.\n\nDoing this for each $\\sigma$, we get a path $\\gamma'$ which doesn't meet $B$. QED.\n\nIt's not actually necessary for $B$ to be connected, as long as each of its connected components has connected boundary. So you can poke multiple holes in the original manifold and it will still be connected. Nor is it necessary for $B$ to be simply connected: it can be a solid torus, for example.\n\nHowever, we do need that connected-boundary condition on $B$. For example, $\\mathbb{R} \\times [0, 1]$ as a subset of $M = \\mathbb{R}^2$ is closed and simply connected, and it lies in the interior of $M$ because $M$ has no boundary, but removing that subspace divides $\\mathbb{R}^2$ into two connected components.\n\nI don't know about closed subsets in general, but I would bet that the result holds for any compact PL subset $B$.\n\nshare|improve this answer\nNice proof! If we're considering the general case, things get a little tricky if $B$ is something like a line segment in $\\mathbb R^2$. \u2013\u00a0 Rahul Narain Nov 22 '12 at 17:37\nCan you be a bit more explicit with how you modify the path so it doesn't enter $B$? \u2013\u00a0 wj32 Nov 22 '12 at 21:12\nGood point. I added a bit about how to use that regular neighborhood of Bd $B$ -- see if you believe it. \u2013\u00a0 Hew Wolff Nov 23 '12 at 19:40\n@HewWolff: I don't know anything about fiber bundles yet. Give me a few months to think about this... \u2013\u00a0 wj32 Nov 24 '12 at 1:36\nOK. Intuitively, I just want to argue that there's a well-defined direction for us to push $\\gamma'$, because every point in Bd $B$ has an \"inward\" and an \"outward\" direction. There may be an easier way to do that. \u2013\u00a0 Hew Wolff Nov 24 '12 at 19:16\nadd comment\n\nTake local charts around each point in the boundary $\\partial B$. By compactness of $\\partial B$, finitely many local charts suffice. Then, if $\\gamma$ was a path that ran through $B$ and connected two points not in $B$, we should be able to modify it to $\\gamma'$ by pushing it around the boundary of $B$ by working in these finitely many local charts.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/177659/how-to-solve-m-su-us?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nThis is from Berkeley Problems in Mathematics, Spring 1979:\n\nLet $M$ be a $3\\times 3$ non-singular real matrix. Prove that there are real matrices $S$ and $U$ such that $M=SU=US$, all the eigenvalues of $U$ equal 1, and $S$ is diagonalizable over $\\mathbb{C}$.\n\nI am thinking that since $U$'s eigenvalues are all 1, we have $(U-I)^{3}=0$. Thus up to Jordon canonical form $U$ should be either a whole Jordan block or has a rank 2 Jordan block. But I do not know how to use this to approach this problem. On the other hand $S$ can be expressed in $PDP^{-1}$, and we are supposed to solve $A=PDP^{-1}U=UPDP^{-1}$. Again no familiar formula can be obtained this way. So I venture to ask for a hint. This may be related to Schur decomposition but I do not know it well enough to solve it.\n\nshare|improve this question\nThe original Problem 7.7.13 (Sp79) requires $M$, $S$, $U$ real and $M$ non singular: tinyurl.com/brr37v7. \u2013\u00a0 enzotib Aug 1 '12 at 17:38\nsorry for the typo. shall fix it. \u2013\u00a0 user32240 Aug 1 '12 at 17:48\nI feel you can use the polar decomposition of a matrix, but could not say exactly how. \u2013\u00a0 enzotib Aug 1 '12 at 18:26\nThe main catch (for me) is the real requirement. \u2013\u00a0 copper.hat Aug 1 '12 at 18:48\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nHere is a rather tedious proof:\n\nSince $M$ is real, either the eigenvalues are all real, or there is one real and a pair of conjugate eigenvalues.\n\nThe key result here is that a real matrix has a real Jordan form, not quite upper triangular, but 'almost'. In the invertible $3 \\times 3$ case, this means that there exists a real $V$ such that $J = V^{-1}MV$ has one of the following forms:\n\n$$J = \\begin{bmatrix} \\lambda_1 & M_{12} & 0 \\\\ 0 & \\lambda_2 & M_{23} \\\\ 0 & 0 & \\lambda_3\\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ J = \\begin{bmatrix} \\lambda_1 & 0 & 0 \\\\ 0 & a & b \\\\ 0 & -b & a\\end{bmatrix},$$\n\nwhere all the entries are real, $M_{12}, M_{23} \\in \\{0,1\\}$, $\\lambda_i \\neq 0$ and $b \\neq 0$.\n\nIn the second case, since all eigenvalues are distinct ($b \\neq 0$), $S$ is diagonalizable over $\\mathbb{C}$. We can take $S= V J V^{-1}$, $U= I$ and we are finished.\n\nNow for the first case. Since this is the Jordan form, we have $(\\lambda_1 \\neq \\lambda_2) \\Rightarrow M_{12} = 0$, and similarly $(\\lambda_2 \\neq \\lambda_3) \\Rightarrow M_{23} = 0$.\n\nLet $\\Sigma = \\mathbb{diag}(\\lambda_1, \\lambda_2, \\lambda_3)$, and let $W = I + \\alpha E_{12} + \\beta E_{23}$, where $E_{12}$ is the matrix with zeros everywhere except a one in the $1,2$ position, and similarly for $E_{23}$. We want to determine constants $\\alpha, \\beta$ so that $J = \\Sigma W = W \\Sigma$. We have: $$ \\Sigma W = \\Sigma + \\alpha \\lambda_1 E_{12} + \\beta \\lambda_2 E_{23}\\\\ W \\Sigma = \\Sigma + \\alpha \\lambda_2 E_{12} + \\beta \\lambda_3 E_{23}$$\n\nThis shows that $\\Sigma W = W \\Sigma$ iff $\\alpha( \\lambda_1 - \\lambda_2) = 0$ and $\\beta( \\lambda_2 - \\lambda_3) = 0$. Furthermore, we want J$ = \\Sigma W$, and this will be true iff $M_{12} = \\alpha \\lambda_1$, and $M_{23} = \\beta \\lambda_2$.\n\nLet $\\alpha = \\frac{M_{12}}{\\lambda_1}$ and $\\beta = \\frac{M_{23}}{\\lambda_2}$, then it is easy to verify that all the conditions are satisfied. Then we can take $S = V \\Sigma V^{-1}$, and $U = V W V^{-1}$, and we are finished.\n\nshare|improve this answer\nexcuse me for my low level, but where can I find information related to the real normal form you are talking about? Is it just the rational canonical form? \u2013\u00a0 user32240 Aug 2 '12 at 6:57\nIt is real Jordan form, unfortunately my library is off the shelves at the moment so I can't give you a book reference, but wikipedia has one en.wikipedia.org/wiki/Jordan_normal_form#Real_matrices. It follows from the usual (possibly complex) Jordan form. \u2013\u00a0 copper.hat Aug 2 '12 at 7:00\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/29279/why-is-the-orthogonal-group-operatornameo2n-mathbb-r-not-the-direct-prod\nText:\nTake the 2-minute tour \u00d7\n\nWe know that when $n$ is odd, $\\operatorname{O}_n(\\mathbb R) \\simeq \\operatorname{SO}_n (\\mathbb R) \\times \\mathbb Z_2$.\n\nHowever, this seems not true when $n$ is even. But I have no idea how to prove something is not a direct product.\n\nI have tried to verify some basic properties of direct product. For example, $\\operatorname{SO}_n(\\mathbb R)$ is a normal subgroup of $\\operatorname{O}_n(\\mathbb R)$, whenever $n$ is odd or even. But they are not helpful.\n\nSo, is this statement true and how to prove it?\n\nThank you!\n\nshare|improve this question\n$O(2)=\\mathbb{Z}/(2)\\rtimes SO(2)$. $\\mathbb{Z}/(2)$ conjugation is inversion: reflect rotate reflect=rotate inverse. \u2013\u00a0 yoyo Mar 27 '11 at 19:15\nadd comment\n\n1 Answer\n\nup vote 10 down vote accepted\n\nLook at the centers: the center of $\\operatorname{O}(n)$ is $\\pm \\operatorname{Id}$. When $n$ is even, this is also the center of $\\operatorname{SO}(n)$. Therefore for even $n$ the center of $\\operatorname{SO}(n) \\times \\mathbb Z_2$ is $\\{\\pm \\operatorname{Id} \\} \\times \\mathbb Z_2$, which is bigger than the center of $\\operatorname{O}(n)$.\n\nEDIT: This works for $n \\ge 3$. For $n=2$, $\\operatorname{O}(2)$ is non-abelian while $\\operatorname{SO}(2) \\times \\mathbb Z_2$ is.\n\nshare|improve this answer\nTypo: \"...the center of SO(n)xZ_2 is...\" (not SO(n)). Thanks for the answer though! \u2013\u00a0 gnometorule Nov 4 '12 at 23:39\n@gnometorule: thanks, I just edited it. \u2013\u00a0 Eric O. Korman Nov 5 '12 at 3:29\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/93194/integer-polynomials-mapping-the-unit-disk-into-itself/93195\nText:\nTake the 2-minute tour \u00d7\n\nIs there a complete characterization of those integer polynomials, that is $P\\in{\\mathbb Z}[X]$, such that $P(D)\\subset D$, where $D$ is the unit disk ? At least, $P(X)=\\pm X^k$ works, when $k\\in\\mathbb N$. But are there other ones, many other ones ?\n\nshare|improve this question\nI apologize for having posted that an easy question. \u2013\u00a0 Denis Serre Apr 5 '12 at 9:08\nadd comment\n\n1 Answer\n\nup vote 17 down vote accepted\n\nSince $P\\in \\mathbb{Z}[X]$, We have $P(0)\\in \\mathbb{Z}$. Suppose that $P(0)\\neq 0$, then $|P(0)|\\geq 1$. In that case $P(D)\\subset D$ is not satisfied unless $P$ is constant by open mapping theorem. So, if $P$ is non-constant, then we must have $P(0)=0$.\n\nWrite $P(X)=XQ(X)$. Then $Q(X)=P(X)/X$. On a disk $D_r$ of radius $0< r<1$ centered at $0$, We have by Maximum modulus theorem that\n$$|Q(X)|\\leq 1/r$$\n\nsince $|P(X)|\\leq 1$. Letting $r\\rightarrow 1$, we have also that $|Q(X)|\\leq 1$ whenever $|X|\\leq 1$. By repeating the same argument for $Q(X)$, we obtain that $P(X)=\\pm X^k$, when $k\\in \\mathbb{N}$ are the only polynomials in $\\mathbb{Z}[X]$ satisfying the property.\n\nshare|improve this answer\nWell, and constant 0. \u2013\u00a0 Harry Altman Apr 5 '12 at 9:07\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/113840/for-consecutive-primes-a-lt-b-lt-c-prove-that-ab-ge-c/113843\nText:\nTake the 2-minute tour \u00d7\n\nFor consecutive primes $a\\lt b\\lt c$, prove that $a+b\\ge c$.\n\nI cannot find a counter-example to this. Do we know if this inequality is true? Alternatively, is this some documented problem (solved or unsolved)?\n\nshare|improve this question\nJust to complement the responses below: The prime number theorem says that the $n$-th prime is asymptotically $n\\log n$, whence your sum $a+b$ is asymptotically $2c$. So your inequality holds for large $c$ without any calculation, in fact $2.001 c>a+b>1.999 c$ for large $c$. \u2013\u00a0 GH from MO Nov 20 '12 at 0:10\n(Of course 2.001 can be replaced by 2 unconditionally.) \u2013\u00a0 Charles Feb 10 '13 at 4:13\nadd comment\n\n3 Answers\n\nup vote 29 down vote accepted\n\nYes, this is true. In 1952, Nagura proved that for $n \\geq 25$, there is always a prime between $n$ and $(6/5)n$. Thus, let $p_k$ be a prime at least 25. Then $p_k+p_{k+1} > 2p_k$. But by Nagura's result we have that $p_{k+2} \\leq 36/25 p_k < 2p_k$. It is easy to verify the conjecture for small values of $p$.\n\nshare|improve this answer\nHard to believe that math as modern as 1952 is needed in order to prove such an elementary-sounding statement. The 1850 Bertrand\u2013Chebyshev theorem almost, but not quite, does the job. \u2013\u00a0 Ben Crowell Nov 19 '12 at 21:58\n@Ben: I think the statement quoted from 1952 is elementary and can be proved in much the same way as Bertrand-Chebyshev. \u2013\u00a0 GH from MO Nov 20 '12 at 0:04\nYou can get away with only using work of Chebyshev for large enough a: Let f(n) = \\sum log(p) over all primes p up to n (usually denoted theta(n)). If a+b<c then c>2a and so there's at most one prime between a+1 and 2a, hence f(2a)-f(a) < log(2a). He showed that f(a) < a*log(4), and he proved a bound pi(N) > 0.9N/log(N) for N large, so we should have f(a) >= 0.7a for a large. Then for such a we have log(2a) > f(2a)-f(a) >= (1.4-log(4))a > 0.0137a, which is impossible if a is large in the above sense and at least 505. \u2013\u00a0 Steven Sivek Nov 20 '12 at 0:42\n@Steven: Thanks for this argument. I believe Chebyshev proved $f(a)<a *\\log 4$ with a better constant than $\\log 4$. The factor $\\log 4$ comes from Erd\u0151s's elegant proof based on $\\prod_{n<p<2n}p\\leq\\binom{2n}{n}$. Apologies in advance if I am wrong here. \u2013\u00a0 GH from MO Nov 20 '12 at 1:52\nadd comment\n\nRamanujan (1919), see Eq. (18):\n\n$$\\pi(x) - \\pi(x/2) \\ge 2 \\quad \\text{ for } x\\ge 11 $$\n\nWhence, with $x= 2p_k$ for $p_k \\ge 7$, $$p_{k+2} \\le 2 p_k \\lt p_k+p_{k+1}, $$ and $5\\le 2+3$, $7\\le 3+ 5$, $11 \\le 5+7$.\n\nshare|improve this answer\nadd comment\n\nAs a matter of fact, P. L. Chebyshev knew already that for any $\\epsilon > \\frac{1}{5}$, there exists an $n(\\epsilon) \\in \\mathbb{N}$ such that for all $n\\geq n(\\epsilon),$\n\n\nIn [2], one can find a short report on the problem of determining the smallest $n(\\epsilon)$ explicitly once that $\\epsilon$ has been fixed.\n\n\n[1] P. L. Chebyshev. M\u00e9moire sur les nombres premiers. M\u00e9moires de l'Acad. Imp. Sci. de St. P\u00e9tersbourg, VII, 1850.\n\n[2] H. Harborth & A. Kemnitz. Calculations for Bertrand's Postulate. Mathematics Magazine, 54 (1), pp. 33-34.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/36851/how-many-permutations-of-a-word-do-not-contain-consecutive-vowels/36854\nText:\nTake the 2-minute tour \u00d7\n\nThe word is \"ENGINEERING\".\n\nThe number of ways that the consonants can be ordered is 6! / 3!2!\n\nThe number of ways that the vowels can be ordered is 5! / 3!2!\n\nBut how would I determine how many ways vowels can be ordered so that they are not next to each other?\n\nshare|improve this question\nThink of using the vowels as separators, and thus you'll have 6 bins to place 6 consonants. Then you need to place a consonant between each spacer, and you'll be left with 2 consonants to place in any of the 6 bins. And of course take into account the double letters. \u2013\u00a0 Nicolas Villanueva May 4 '11 at 3:19\nI slightly edited as the capital letters were really offensive on the front page. \u2013\u00a0 Asaf Karagila May 4 '11 at 7:02\nIf your question has been answered satisfactorily, you should upvote and accept the answer so that it doesn't keep popping up in the frontpage unnecessarily. \u2013\u00a0 svenkatr May 5 '11 at 16:29\nadd comment\n\n2 Answers\n\nup vote 7 down vote accepted\n\nImagine that you arrange the consonants first. There are six consonants which you can arrange in $6!/(3!2!)$ ways.\n\nNow there are 7 spaces for the 5 vowels to go into but only one vowel can go into each space. So you choose 5 of the 7 available spaces and put a permutation of the vowels into these spaces.\n\nTotal number of arrangements with no consectutive vowels $= 6!/(3!2!) \\times 5!/(3!2!) \\times \\binom{7}{5}$.\n\nshare|improve this answer\nHow do you know that there are 7 spaces for the 5 vowels to go in? \u2013\u00a0 Krysten May 4 '11 at 3:38\n@krysten - You know that the consonants have to separate the vowels. Counting one space in front of the consonants, one at the end and the five in the middle gives us 7 seven spaces. For example, look at .N.G.N.R.N.G. which is an arrangement of consonants with the dots representing places where vowels can go. There are seven dots, which are the seven places where a vowel can go into. \u2013\u00a0 svenkatr May 4 '11 at 3:42\nalright thanks. \u2013\u00a0 Krysten May 4 '11 at 3:53\nadd comment\n\n(edit: Answer has been updated to include four missed combinations and the fact that permutations are not considered unique if their spelling matches that of another permutation.)\n\n12345678901  (11 letters in ENGINEERING)\nC.C.C.C.C.C (alternating sequence, bounded on both sides by C)\n.C.C.C.C.CC  (start single consecutive C pair, one end bounded by C)\nC.C.C.C.CC. (count: 10)\n.CC.CC.C.C. (start double consecutive C pair)\n.C.C.CC.CC. (count: 6)\n.CCC.C.C.C. (start triple C string)\n.C.C.C.CCC. (count: 4)\n\nIn all of these formats, there are 6!/(3!2!) ways to order the C's (i.e. consonants) and 5!/(3!2!) ways to order the .'s (i.e. vowels,) so there should be (21)(6!/3!2!)(5!/3!2!), or 12,600, permutations in which there are no adjacent vowels.\n\nshare|improve this answer\nI forgot one possible combination: C1 C2 V1 C3 V2 C4 V3 C5 V4 C6 V5. I went back and edited the post, bringing the total up to (17)6!5!. \u2013\u00a0 Michael May 4 '11 at 3:48\n@Michael - your starting count of $6!5!$ is wrong because there are repeating vowels and consonants. Also, I don't see how you can get a factor of 17. I suspect you have made a mistake when you manually count the possible arrangements. \u2013\u00a0 svenkatr May 4 '11 at 3:53\n@Michael - That's a very interesting way to look at it. I guess if all else fails you can just look at all the different possibilities. However, I believe the answer is 12,600. \u2013\u00a0 Krysten May 4 '11 at 3:55\n@svenkar I made a prettier version of it, showing all 17 formats that the vowels and consonants can follow. If you can find anything wrong with the formats, please explain! \u2013\u00a0 Michael May 4 '11 at 4:07\n@Krysten I've noticed a problem! The subject/title of this question is \"How many permutations of ENGINEERING do not contain consecutive vowels,\" which is the question that I answered. This, however, does not match up with the question that you ask in the body of your post, which asks, \"how would I determine how many ways vowels can be ordered so that they are not next to each other?,\" which I find to be both ambiguous and quite different than the subject/title. \u2013\u00a0 Michael May 4 '11 at 4:08\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/41318/probability-of-achieving-a-given-density-of-iid-random-variables\nText:\nTake the 2-minute tour \u00d7\n\nI have a sequence of IID random variables $X_1, X_2, \\dots, X_n$. In this particular case, each of the variables is L\u00e9vy distributed with PDF\n\n$f(x) = (\\lambda / 2 \\pi x^3)^{-1/2} \\exp(-\\lambda/2x)$\n\nfor $x > 0$, and $f(x) = 0$ otherwise.\n\nI'm trying to find the probability, given constants $\\tau > 0$ and $b < n$, that there exists an interval of length $\\tau$ which contains at least $b$ of the $n$ random variables.\n\nMy first approach was to use order statistics; for example, if $X_{(1)}, X_{(2)}, \\dots, X_{(n)}$ are the order statistics, the probability that the $b$ smallest fall in an interval of length $\\tau$ could be found using the joint distribution of $X_{(1)}$ and $X_{(b)}$. From the Wikipedia article,\n\n\nThis could then be integrated over the simplex $0 \\leq x \\leq y \\leq x + \\tau$, and the result could be repeated for each group of $b$ random variables and summed. However, I feel that this approach leads to double counting (for example, both $X_{(1)} \\dots X_{(b)}$ and $X_{(n-b+1)} \\dots X_{(n)}$ could fall in disjoint intervals of length $\\tau$) and also seems to be difficult to obtain in closed form.\n\nThe other approach I considered was to use the joint density of all order statistics:\n\n$f_{X_{(1)},\\ldots,X_{(n)}}(x_1,\\ldots,x_n)\\,dx_1\\cdots dx_n=n!f_X(x_1)\\cdots f_X(x_n)\\,dx_1\\cdots dx_n$\n\nHowever, I can't determine how to express the region of integration in any meaningful way. Any thoughts or pointers would be appreciated!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe nonexistence of such interval is equivalent to $X_{(i+b-1)} > X_{(i)}+r$ for $i=1\\ldots n-b+1$. So for the probability of the complement of your event, integrate $n! f(x_1) \\ldots f(x_n)$ over the region defined by $$ x_{b-1} > x_{b-2}> \\ldots >x_2 > x_1>0 $$ and $$ x_b > \\max(x_{b-1}, x_1 + r), \\ldots, x_n > \\max(x_{n-1}, x_{n-b+1} + r). $$\n\nshare|improve this answer\nThanks, that makes a lot of sense. This helps when using numerical approximations, but the bounds don't seem to lead to a closed form solution - I suppose this is unlikely anyways. \u2013\u00a0 sciyoshi May 25 '11 at 18:19\nadd comment\n\nAs said before, there is no simple closed form solution. But one can prove some upper and lower bounds, which yield a precise value in a semi-explicit range of values of $b$, $n$ and $\\tau$.\n\nWe start with some notations. For $x\\le y$, call $g(x,y)=P(x\\le X_1\\le y)$ the integral of the density function $f$ of $X_1$ from $x$ to $y$. For any subset $I$ of $\\{1,2,\\ldots,n\\}$ of size $b$, call $A_I=[R_I\\le\\tau]$ where $R_I$ is the range of the sample $(X_k)$ over $I$, that is, $$ A_I=[R_I\\le\\tau],\\qquad R_I=\\max\\{X_k;k\\in I\\}-\\min\\{X_k;k\\in I\\}. $$ Using the fact that the event $[x\\le\\min\\{X_k;k\\in I\\},\\max\\{X_k;k\\in I\\}\\le y]$ has probability $g(x,y)^b$, one sees that $P(A_I)=\\alpha_b$ for every $I$ of size $b$, with\n\n$$ \\alpha_b=\\int bf(x)g(x,x+\\tau)^{b-1}\\mathrm{d}x. $$\n\nThe event $A$ that there exists an interval of length (at most) $\\tau$ which contains (at least) $b$ values from the sample of size $n$ is $$ A=\\bigcup_IA_I,\\quad A_I=[R_I\\le\\tau], $$ where the union is over the subsets $I$ of $\\{1,2,\\ldots,n\\}$ of size $b$. By the inclusion-exclusion principle, $$ S-S'\\le P(A)\\le S,\\quad S=\\sum_{I}P(A_I),\\ S'=\\sum_{I\\ne J}P(A_I\\cap A_J). $$ For every $I$ of size $b$, $P(A_I)=\\alpha_b$. For every $I\\ne J$ of size $b$, $A_I$ and $A_J$ are independent if $I\\cap J=\\emptyset$ and positively correlated otherwise, hence $P(A_I\\cap A_J)\\ge \\alpha_b^2$. Finally,\n\n$$ {n\\choose b}\\alpha_b-\\frac12\\left({n\\choose b}^2-{n\\choose b}\\right)\\alpha_b^2\\le P(A)\\le{n\\choose b}\\alpha_b. $$\n\nThis reads approximately as $p-\\frac12p^2\\le P(A)\\le p$ with $p=\\displaystyle{n\\choose b}\\alpha_b$ hence this estimation of $P(A)$ is as precise as the upper bound $p$ is small.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/25874/what-is-the-minimal-size-of-a-partial-order-that-is-universal-for-all-partial-or\nText:\nTake the tour \u00d7\n\nA partial order $\\mathbb{B}$ is universal for a class $\\cal{P}$ of partial orders if every order in $\\cal{P}$ embeds order-preservingly into $\\mathbb{B}$.\n\nFor example, every partial order $\\langle\\mathbb{P},\\lt\\rangle$ maps order-preservingly into its power set by the map $$p\\mapsto\\{q\\in\\mathbb{P}\\mid q\\leq p\\}$$ that sends each element $p$ to its lower cone.\n\nThus, the power set order $\\langle P(\\{1,2,\\ldots,n\\}),{\\subseteq}\\rangle$ is universal for the class of partial orders of size $n$. This provides an order of size $2^n$ that is universal for orders of size $n$.\n\nQuestion. What is the minimal size of a partial order that is universal for orders of size $n$?\n\nIn particular, is there a polynomial upper bound?\n\nOne can make at least slight improvements to the $2^n$ upper bound, by observing that the emptyset was not needed, as it never arises as a lower cone, and we don't need all the atoms, since if they are needed, then one can use the co-atoms instead. I suspect that there is a lot of waste in the power set order, but the best upper bound I know is still exponential.\n\nFor a lower bound, my current knowledge is weak and far from exponential. Any order that is universal for orders of size $n$ will contain a chain and an antichain, making it have size at least $2n-1$. (That bound is exact for $n\\leq 3$.) A student in my intro logic course extended this to $n\\log(n)$ by considering $k$ chains (and antichains) of size $n/k$.\n\nCan one find better lower bounds?\n\nInterestingly, the same student observed that we cannot in general expect to find unique smallest universal orders, since he found several orders of size 5 that are universal for orders of size 3 and which are minimal with that property. So in general, we cannot expect a unique optimal universal order. Does this phenomenon occur for every $n$? (He also found minimal universal orders of size larger than the minimal size universal order.)\n\nshare|improve this question\nNeat question. I guess the logic tag is because it came up in your logic class? \u2013\u00a0 Pete L. Clark May 25 '10 at 13:58\nThe concept of universal structures is important in model theory and used in set theory (although usually for infinite structures). Also, the easiest way to show that every countable partial order embeds into the Turing degrees is to consider orders that are universal for countable orders (and there are countable such orders). For the warm-up to that theorem, we first embedded the finite powersets into the Turing degrees, and then concluded that all finite orders embed by universality. \u2013\u00a0 Joel David Hamkins May 25 '10 at 14:09\nCorrection: my student's lower bound is $n\\log(n)-n$. \u2013\u00a0 Joel David Hamkins May 25 '10 at 14:41\nadd comment\n\n2 Answers\n\nDenote by $F(n)$ the number of different partial orders on the set of cardinality $n$. Then the minimal size $N$ of a partial order that is universal for orders of size $n$ satisfies $\\binom{N}{n}\\geq F(n)$ (that's captain obvious advice, yes). Since $\\log F(n)$ behaves like $cn^2$ (the lower estimate, which we need, is proved as follows: take $n/2$ blue elements and $n/2$ red elements, then decide for each pair of red and blue elements $r_i$, $b_j$, whether $r_i > b_j$ or not. We get $2^{n^2/4}$ patial orders, each isomorphism class is counted at most $n!$ times). So, $N^n> \\binom{N}{n}\\geq F(n)$, taking logarithms we get $n\\log N > cn^2$, so $N$ should grow at least exponentially.\n\nshare|improve this answer\nThanks very much for this excellent answer! I appreciate it very much. Could I ask kindly whether you might carry your argument through to the conclusion of an explicit lower bound? \u2013\u00a0 Joel David Hamkins May 25 '10 at 17:46\nOf course, but if you carry on the sharp constant in the exponent, I have to think bit more:) Now the lower estimate is $2^{n/4+o(n)}$ . But I suppose that calculating the best constant is very hard, similar to Ramsey numbers precise asymptotics. \u2013\u00a0 Fedor Petrov May 25 '10 at 20:13\nadd comment\n\nThere does not exist a polynomial upper bound.\n\nLet $P_n$ be the number of partial orders on $n$ elements. It is know that $P_n \\geq 2^{n^2/4}$. Thus, any method of uniquely representing the partial orders on $n$ elements, say in binary, will require at least $log_2(2^{n^2/4}) = O(n^2)$ bits.\n\nNow assume that for every $n$ there is a partial order on $n^k$, or fewer, elements, where $k$ is a constant, that is universal for the class of partial orders on $n$ elements. Fix some canonical ordering of the partial orders and let $U(n)$ be the first universal partial orders on $n^k$, or fewer elements.\n\nLabel each of the elements in $U(n)$ with a unique number from $1$ up to $log_2(f(n)) = O(log(n))$ in some fixed canonical way. Now each partial order on $n$ elements can be uniquely described by writing down for each element that elements corresponding label in $U(n)$. This takes $O(nlog(n))$ bits. However; this representation is not quite complete, as it seems to require the description of $U(n)$ to actually reconstruct a partial order given its representation in this form.\n\nHowever, since $U(n)$ is the first universal partial order on $n^k$ or fewer elements, rather than appending an encoding of $U(n)$ to each partial order directly we can instead append an encoding of the following Turing machine $M$. $M$ takes in three arguments $n$, $i$ and $j$ and accepts if element $i$ is less than element $j$ in $U(n)$ and rejects otherwise. Given such a Turing machine we can clearly reconstruct the partial order. $M$ simply enumerates all partial orders of size between $n$ and $n^k$ and stops at the first partial order that is universal for all partial orders on $n$ elements. It then labels the elements of $U(n)$ in the canonical manner and accepts if the element labeled $i$ in $U(n)$ is less than the element labeled $j$ in $U(n)$. This TM has constant size.\n\nWe can thus uniquely and completely represent all partial orders on $n$ elements by $O(nlog(n)) + O(1) = O(nlog(n))$ bits, which is a contradiction as there are too many partial orders on $n$ elements to be represented in only $O(nlog(n))$ bits.\n\nshare|improve this answer\nIt is not true that $P_n \\geq 2^{n^2/4}$. Also, LaTeX knows \\log. \u2013\u00a0 JBL May 25 '10 at 17:19\nIf you consider distinguishable elements then it is true that $P_n \\geq 2^{n^2/4}$. If you consider indistinguishable elements then the there are still at least $\\frac{2^{n^2/4}}{n!} \\geq 2^{n^2/4 - n\\log{n}} = 2^{\\Theta(n^2)}$ partial orders on $n$ elements and the proof still holds. \u2013\u00a0 Travis Service May 25 '10 at 18:19\n+1. Travis, thanks very much for the argument--your information-theoretic way of analyzing it appeals to me very much. \u2013\u00a0 Joel David Hamkins May 25 '10 at 18:49\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/276865/verify-a-given-svd-of-an-operator\nText:\nTake the tour \u00d7\n\nShow that the Singular Value Decomposition of the operator\n\n$$ A\\colon L^2([0,1])\\to L^2([0,1]), x\\mapsto\\int\\limits_0^t x(s)\\, ds $$\n\nis given by\n\n$$ \\sigma_j=\\frac{1}{(j-1/2)\\pi},~~~~~v_j(x)=\\sqrt{2}\\cos((j-1/2)\\pi x),~~~~~u_j(x)=\\sqrt{2}\\sin((j-1/2)\\pi x). $$\n\nMy first question is: Is this operator compact at all so that it makes sense to talk of a SVD?\n\nThen: What do I have to do to solve the task?\n\nFirst, I determined the adjoint operator $A^*$; it is given by $x\\mapsto\\int\\limits_t^1 x(s)\\, ds$. Then I attested that $Av_j=\\sigma_ju_j$ and $A^*u_j=\\sigma_jv_j$.\n\nMoreover, I showed with substitution $\\omega=(j-1/2)\\pi x$ that\n\n$\\langle v_j,v_j\\rangle_{L^2([0,1])}=\\frac{2}{(j-1/2)\\pi}\\int\\limits_0^{(j-1/2)\\pi}\\lvert\\cos(\\omega)\\rvert^2\\, d\\omega=1$ and similarly $\\langle u_j,u_j\\rangle_{L^2([0,1])}=1$.\n\nFurthermore, I calculated for $k\\neq j$ that\n\n$\\langle v_j,v_k\\rangle_{L^2([0,1])}=\\int\\limits_0^1 v_j(x)\\overline{v_k(x)}\\, dx=\\int\\limits_0^1 v_j(x)v_k(\\overline{x})\\, dx=\\int\\limits_0^1 v_j(x)v_k(x)\\, dx$ because $x\\in [0,1]$. This integral is 0.\n\nSimilarly $\\langle u_j,u_k\\rangle_{L^2([0,1])}=0$.\n\nSo far so good. But is this the whole task? Is there something i have to show additionally?\n\nshare|improve this question\nConcerning compactness, write $(Ax)(t) = \\int_0^1 a(t,s)x(s)\\,ds$ with $a(t,s) := \\chi_{[0,t]}(s)$. Then $\\int_0^1 \\int_0^1 |a(t,s)|^2 \\,ds\\,dt < \\infty$, hence $A$ defines a Hilbert-Schmidt operator which is compact (see en.wikipedia.org/wiki/Hilbert-Schmidt_integral_operator) \u2013\u00a0 fbg Jan 13 at 13:29\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://physics.stackexchange.com/questions/35259/how-to-measure-g-using-a-metre-stick-and-a-ball?answertab=votes\nText:\nTake the tour \u00d7\n\nCan I measure the value of g using only a metre stick and a ball? I am not supposed to use a stopwatch and that has been the problem. NOTE: I do not know if a solution exists or not.\n\nshare|improve this question\nAs @Ron has answered we can not measure value of g using a stick and a ball; however if we take unit of length to be stick's length and define one \"stick time\" to be amount of time required for anything to fall from rest from a height equal to length of given stick, then value of g in these units would be 2. \u2013\u00a0 user10001 Aug 31 '12 at 4:05\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nNo you can't. You can see this because you are only given things that can define a units of length and mass (the meterstick and the ball), so you need something that can define the unit of time. If there was another process, nongravitational, with which you could define a unit of time, then you can find g relative to this unit of time, but absent such a thing, you can only define the unit of time by dropping something or measuring something oscillate in gravity, and then you are stuck.\n\nshare|improve this answer\nadd comment\n\nGalileo used his heartbeat to measure the period of oscillations of a chandelier. You can also use your heartbeat as a kind of stopwatch. You make a pendulum from a stick and a ball and let it swing with a small amplitude. The period of oscillations is:\n\n\nThus $g$:\n\n$$g = \\frac{4 \\pi^2 l}{T^2}$$\n\nTo find $T$ you let the pendulum swing $n$ times and count the number of your heartbeats $N$. Then $T = N /n$ in heartbeats.\n\nHowever note, that your $g$ would have dimensions of $\\frac{\\text{meter}}{\\text{heart beat}^2}$. And you can't translate heart beats into seconds without a clock of some kind.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/195393/an-iterated-function-system-with-probabilities-and-overlapping-supports-of-its-i\nText:\nTake the tour \u00d7\n\nLet $(X, \\rho)$ be a Polish space. Consider an Iterated Function System $(S_i,p_i)_{i=1,...,N}$, where $S_i:X\\rightarrow X$, $p_i: X\\rightarrow \\left[0,1\\right]$ are continuous functions and $\\sum_{i=1}^N p_i(x)=1$, for all $x\\in X$. We assume that there exists $0<r<1$ such that $$(*) \\quad \\sum_{i=1}^N p_i(x) \\rho(S_i(x), S_i(y))\\leq r \\rho(x,y)\\;\\;\\; (x,y \\in X)$$ and $\\inf_x p_i(x)>0$, $i=1,...,N$. Clearly, the transition operator of our IFS is given by: $$\\mu P=\\sum_{i=1}^N \\int_{X} 1_A(S_i(x))p_i(x)\\,\\mu(dx)\\;\\;\\; (\\mu\\in\\mathcal{M}_{prob}(X), \\; A\\in\\mathcal{B}(X))$$\n\nMy question is the following:\n\nAssume that $\\delta_xP^n\\stackrel{w}{\\rightarrow}\\pi_x$ and $\\delta_yP^n\\stackrel{w}{\\rightarrow}\\pi_y$ (as usual $P^n$ is determined by the Chapman-Kolmogorov equation), where $\\pi_x$ and $\\pi_y$ are invariant distributions of $P$. Is true that $\\mbox{supp } \\pi_x \\cap \\mbox{supp }\\pi_y\\neq \\emptyset$?\n\nIt seems to be true because one can show that $\\mbox{supp }\\delta_x P^n=\\{(S_{i_n}\\circ ...S_{i_1})(x): i_1,..,i_n\\in\\{1...,N\\}\\}$ and from (*) it follows that for any $x,y \\in X$ we can choose $i_1,...,i_m$ such that $$\\rho((S_{i_m}\\circ ...S_{i_1})(x),(S_{i_m}\\circ ...S_{i_1})(y))\\leq r^m\\rho(x,y).$$\n\nHowever, I was able to show only that $\\mbox{dist } (\\mbox{supp } \\pi_x, \\mbox{supp }\\pi_y)=0$\n\nshare|improve this question\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/180520/sqrtx-y-4-x-sqrty-6-find-the-solution-x-y\nText:\nTake the 2-minute tour \u00d7\n\n$\\sqrt{x} +y = 4$, $\\sqrt{y} +x= 6$, find the solution (x,y). $NOTE$ : $\\sqrt{4}+1= 4-1$, $\\sqrt{1} +4 =1+4$\n\nshare|improve this question\n$(\\sqrt{2}+1) \\lt (2+\\sqrt{1})$, $(\\sqrt{4}+1) \\lt (4+\\sqrt{1})$ \u2013\u00a0 Rajesh K Singh Aug 9 '12 at 5:09\n$\\sqrt x=4-y$, $x=y^2-8y+16=6-\\sqrt y$, $y=(y^2-8y+10)^2$ gives you an equation of degree 4 in $y$. If you can solve it, you win. \u2013\u00a0 Gerry Myerson Aug 9 '12 at 6:00\nAnother approach is $y=4-\\sqrt x$, $\\sqrt y = 6-x$ implies $y=(6-x)^2$. Since $y=y$, we can set the right side of both equations equal to each other. Then we get an 4th degree equation in $\\sqrt x$. \u2013\u00a0 Matt Groff Aug 9 '12 at 6:07\nlet $u=\\sqrt{x}, v=\\sqrt{y}$. Then $u^2+v=4, u+v^2=6$ Hence $v=4-u^2$. Hence $u+16-8u^2+u^4=6 \\iff u^4-8u^2+u+10=0$. Wolframalpha gives some disgusting solutions to this quartic equation: wolframalpha.com/input/?i=u%5E4-8u%5E2%2Bu%2B10%3D0 \u2013\u00a0 progressiveforest Aug 9 '12 at 6:07\nBeautiful question with ugly answer... \u2013\u00a0 \u1d0a \u1d00 s \u1d0f \u0274 Aug 9 '12 at 6:13\nshow 1 more comment\n\n2 Answers\n\nThis is basically the method which was suggested in the comments above - turning this into a quartic equation. We will see whether someone suggest a substantially more elegant solution.\n\n$$\\sqrt{x}+y=4\\\\ x+\\sqrt{y}=6$$\n\nUsing the substitution $\\sqrt{x}=s$ and $\\sqrt{y}=t$ we get: $$s+t^2=4\\\\ t+s^2=6$$\n\nWhich gives $$s=4-t^2=4-(6-s^2)^2\\\\ (s^2-6)^2+s-4=0\\\\ s^4-12s^2+s+32=0$$\n\nIt should be possible to solve this as a quartic equation, although it would be quite laborious. You can check what WolframAlpha is able to find out here and here\n\nshare|improve this answer\ngreat attempt indeed \u2013\u00a0 Rajesh K Singh Aug 9 '12 at 6:20\nadd comment\n\nLet, $\\sqrt{x}=s$, $\\sqrt{y}=t$\n\nwe have, $s^4 -12s^2+s+32=0$, which is a 'biquadratic' equation of the form,\n\n\ni.e. $$s^4 -12s^2+s+32=(s^2+ks+l)(s^2-ks+m)$$\n\nnow by equating coefficients, we have\n\n$$l+m-k^2 = -12, k(m-l) = 1, lm = 32$$\n\nfrom the first two of these equations, we obtain\n\n$$2m=k^2-12+(1/k), 2l=k^2-12-(1/k)$$\n\nhence substituting in the third equation, the values of l,m,\n\n\n\n\n\nthis is a cubic in $k^2$ which always has one real positive solution and we can find $k^{2}$,$l$,$m$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/97118/problem-about-gradients-and-directional-derivatives\nText:\nTake the 2-minute tour \u00d7\n\nLet $f(x,y)=x^2+y^2$ and it is easy to observe that $\\operatorname{grad} f(a,b)$ is always perpendicular to the tangent line at point $(a,b)$ and I just can't prove why it would be like that.\n\nshare|improve this question\nI am a bit puzzled. Are you looking at the surface $\\{(x,y,z)\\in\\mathbb{R}^3: x^2 + y^2 = z\\}$, or are you looking at the circle $y = \\pm\\sqrt{r^2 - x^2}$ for some fixed $r > 0$ and $x\\in[-r, r]$? In either case, it doesn't quite matter; in the former case you have a tangent plane, in the latter - a tangent line. For the line case, compute the gradient and take the inner product of the gradient with the tangent vector, and observe that it is zero. \u2013\u00a0 William Jan 7 '12 at 6:53\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nSo, you are essentially trying to show the following\n\n$(\\nabla f) \\perp (f=c)$, which is that the gradient of the function is perpendicular to the level surface (f = constant).\n\nConsider in general a curve $r=r(t)$ that stays on the level surface $f=c$. By definition $v = \\frac{dr}{dt}$ is tangent to the level curve $f=c$. By the chain rule, the total differential $\\frac{df}{dt}$ gives, $$\\frac{df}{dt} =\\frac{\\partial f}{\\partial x} \\cdot \\frac{dx}{dt} + \\frac{\\partial f}{\\partial y} \\cdot \\frac{dy}{dt} + \\frac{\\partial f}{\\partial z} \\cdot \\frac{dz}{dt} = \\nabla f \\cdot \\frac{dr}{dt} = \\nabla f \\cdot v = 0$$ since $f(t)=c$. So, the gradient vector $\\nabla f$ is perpendicular to $v$. This is true for any motion on $f=c$, and $v$ can be any vector tangent to $f=c$.\n\nSo, given any vector $v$ tangent to the level curve, $\\nabla f \\perp v$, so $\\nabla f \\perp$ tangent plane.\n\nLet me know if you need clarification about anything.\n\nshare|improve this answer\nadd comment\n\nHere, the assumption is that $f(x,y)$ can be parametrized by a continuously differentiable function in a neighborhood $I$ of a point $(x_0,y_0)$ in the domain wrt to a parameter, say $t$ as\n\n$r(t)=x(t)i+jy(t)$ such that it has a non-zero tangent vector, say $r'(t)$ and that If $t\\epsilon I,$ $f(r(t))=c$, where c is a constant.\n\nHence, $\\displaystyle\\frac{d}{dt} f(r(t))=\\nabla{f(r(t)).r'(t)}=0.$\n\nThus, gradient of $f(r(t))$ i.e. of $f(x,y)$ is perpendicular to the tangent at the level curve at any given point $(x_0,y_0)$.\n\nTake a look at this link\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/4768/every-permutation-is-either-even-or-odd-but-not-both?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nHow we can show every permutation is either even or odd,but not both......I can't arrive at a proof for this ..... Can anybody give me the proof...\n\nThanks in advance...\n\nshare|improve this question\nThere are three well explained answers to this question on en.wikipedia.org/wiki/Parity_of_a_permutation \u2013\u00a0 alext87 Sep 16 '10 at 10:44\nUnless I'm having a particularly daft day... I question the validity of the first two proofs on wikipedia: they don't seem to eliminate the possibility that every permutation is both even and odd. \u2013\u00a0 Douglas S. Stones Sep 16 '10 at 10:56\nThe identity permuation is even. \u2013\u00a0 alext87 Sep 16 '10 at 11:19\nDepends on your definition of parity of the permutation. If you simply define it as the parity of number of inversion pairs, this is a no-brainer. \u2013\u00a0 Aryabhata Sep 16 '10 at 18:26\nSee my answer here: math.stackexchange.com/questions/46403/\u2026 \u2013\u00a0 Grumpy Parsnip Feb 18 '12 at 23:51\nadd comment\n\n4 Answers\n\nThere is a proof given here: An Historical Note on the Parity of Permutations, T. L. Bartlow, American Mathematical Monthly Vol. 79, No. 7 (Aug. - Sep., 1972), pp. 766-769.\n\nHere's an outline of Bartlow's proof (it matches the proof given in Ted's answer).\n\n  \u2022 Divide $S_n$ (the symmetric group on $n$ letters) into two classes according to the parity of the number of cycles (fixed points counted as 1-cycles) in their unique decomposition into disjoint cycles. [E.g. in $S_5$ the permutation $(1,2,3)(4)(5)$ has 3 disjoint cycles.]\n\n  \u2022 These classes are thus well-defined and disjoint, and the identity permutation belongs to exactly one class (since it decomposes into $n$ disjoint cycles, and $n$ is either even or odd).\n\n  \u2022 He showed that by multiplying a permutation in one class by a transposition, will result in a permutation in the other class.\n\n  \u2022 He concludes that the two classes are, in fact, the sets of even and odd permutations in $S_n$.\n\n(NB. In earlier versions of this answer I incorrectly labelled this proof as faulty. In fact, this is an excellent proof, and doesn't rely on any auxiliary functions or unrelated concepts.)\n\nI claim all three \"proofs\" of this result (currently) on wikipedia are incomplete. Let's begin with the observation that, assuming that identity permutation is not an odd permutation, then the result follows fairly easily.\n\nTheorem: Assuming the identity permutation is not an odd permutation, then all permutations are either even xor odd.\n\nProof: Let $\\sigma$ be both an even and an odd permutation. Then there exists transpositions $t_i$ and $s_j$ such that \\[\\sigma=t_1 \\circ t_2 \\circ \\cdots \\circ t_k=s_1 \\circ s_2 \\circ \\cdots \\circ s_m\\] where $k$ is even and $m$ is odd. Note that \\[\\sigma^{-1}=s_m \\circ s_{m-1} \\circ \\cdots \\circ s_1.\\]\n\nThen the identity permutation $\\sigma \\circ \\sigma^{-1}$ is the odd permutation \\[t_1 \\circ t_2 \\circ \\cdots \\circ t_k \\circ s_m \\circ s_{m-1} \\circ \\cdots \\circ s_1,\\] giving a contradiction. Thus completing the proof of the theorem.\n\nThe problem is that we cannot just assume that the identity permutation not an odd permutation (yes, it's an even permutation, but what's to stop it being an odd permutation also?), it does not follow from the definition and it is the base case of the \"induction\". To prove it, we need to show that the identity permutation cannot be decomposed into an odd number of transpositions (without using the theorem itself).\n\nHowever, we can deduce from the above theorem that either (a) all permutations are both even and odd or (b) all permutations are either even xor odd.\n\nOn wikipedia: Proof 1 states that the identity permutation is an even permutation (which it is) then assumes that the identity permutation is not also an odd permutation (this is analogous to assuming that a closed set is not an open set). Proof 2 essentially says that we can switch signs by multiplying by a transposition (which is fine, if you know a priori that there exists some permutation that is not even or not odd). Proof 3 neglects the possibility that an even-length word might be equal to an odd-length word.\n\nKeith Conrad also gave a proof that the identity permutation is not an odd permutation here. It is almost a page long (and is the majority of the proof of the result in question).\n\nshare|improve this answer\nI think that the Wikipedia article is technically correct, because it is explicit that the well-definedness of the transposition-based definition is assumed (with a reference). However, I cannot see the point of stating a proof of the equivalence of the inversion-based definition and the transposition-based definition in the article without stating a proof of the well-definedness of the latter. As is often the case with Wikipedia, I do not know whom the article is intended for. \u2013\u00a0 Tsuyoshi Ito Sep 16 '10 at 12:32\n@Douglas: The wiki page has this definition: \"Parity of permutation is the parity of the number of inversion pairs\". This trivially implies that a permutation cannot be both even and odd. \u2013\u00a0 Aryabhata Sep 16 '10 at 18:26\nA permutation can be written as the composition of transpositions in an infinite number of ways... how do you check all infinity of them? [besides, the alarm bells should be going off: you're claiming that the OP's theorem is trivial from the definition] \u2013\u00a0 Douglas S. Stones Sep 17 '10 at 1:37\n@Douglas: What I am claiming is that it depends on the definition. OP never provided one. The wiki page provided one in terms of inversion pairs (transpositions was proven equivalent) and so is probably correct (I didn't go through the whole thing) in assuming it is either even or odd, but not both. The question asked by OP is trivial under the definition in terms of inversion pairs. I do agree, if we go via transpositions, we have work to do. \u2013\u00a0 Aryabhata Sep 17 '10 at 5:01\nHmm... I equated \"inversion pairs\" with \"transpositions\" in the earlier comment (which is incorrect). But there's still an infinite number of ways to write a permutation as the composition of inversion pairs. I'm might be missing something obvious here, but why is this now a no-brainer? \u2013\u00a0 Douglas S. Stones Sep 17 '10 at 5:39\nshow 3 more comments\n\nOne way is to define the sign of a permutation $\\sigma$ using the polynomial $\\Delta = \\Pi (x_i-x_j)$ with $1\\le i < j \\le n$.\n\nIt is easy to see that $\\sigma(\\Delta) = \\Pi (x_{\\sigma(i)}-x_{\\sigma(j)})$ satisfies $\\sigma(\\Delta)=\\pm\\Delta$. Now define the sign by $sign(\\sigma)=\\frac{\\Delta}{\\sigma(\\Delta)}$\n\nWith a little more work you can show that this function is a homomorphism of groups, and that on transpositions it return -1. Therefore, if $\\sigma=\\tau_1\\cdots\\tau_k$ is a way to write $\\sigma$ as a product of transpositions, we have $sign(\\sigma)=(-1)^k$ and so for even permutations (permutations whose sign is 1) k must always be even, and for odd permutations (whose sign is -1) it must always be odd.\n\nshare|improve this answer\nI've often wondered why people use that polynomial instead of simply the integer $\\prod_{1\\le i<j\\le n} (i-j)$, which seems to me more elementary than using a polynomial in several variables. \u2013\u00a0 lhf Sep 16 '10 at 13:56\nI can't see a reason myself. It might be because algebraists are used to working with symmetric polynomials, and this is a private case. \u2013\u00a0 Gadi A Sep 16 '10 at 14:08\n@lhf: The symmetric group cannot act on that integer per se; it acts on the form in which you have expressed it! Thus you are computing with it as if it were a polynomial in which the indexes are names for the variables. \u2013\u00a0 whuber Sep 16 '10 at 15:14\nI think this is proof is really interesting because it's not very difficult and provides an easy way to see that the definition with inversion pairs is equivalent to the one with transpositions. \u2013\u00a0 Joel Cohen Oct 14 '11 at 12:03\n@JoelCohen- good point! You have totally demystified the inversion-pairs definition for me. \u2013\u00a0 Ben Blum-Smith Feb 19 '12 at 0:15\nadd comment\n\nThis is overkill, but it follows from general facts about Coxeter groups as outlined here. In particular, it follows from the fact that $S_n$ has presentation $s_i^2 = 1, (s_i s_{i+1})^3 = 1, s_i s_j = s_j s_i, |i - j| \\ge 2$ (which follows from the faithfulness of the geometric representation) that the homomorphism $s_i \\to -1$ is well-defined.\n\nshare|improve this answer\nAnother general fact about Coxeter groups (the first proposition at qchu.wordpress.com/2010/07/08/the-strong-exchange-condition) also implies that this definition agrees with the definition by inversion number. \u2013\u00a0 Qiaochu Yuan Sep 16 '10 at 19:49\nadd comment\n\nIt is enough to show that the product of an odd number of transpositions cannot be the identity.\n\nEvery permutation of a finite set $S$ is a unique product of disjoint cycles in which every element of $S$ occurs exactly once (where we include fixed points as 1-cycles). Let $p$ be any permutation of $S$, let $(ij)$ be a transposition ($i,j \\in S$), and let $q=p \\cdot (ij)$. It is easy to check that if $i$ and $j$ are in the same cycle in $p$, then that cycle splits into two in $q$; if $i$ and $j$ are in different cycles in $p$, then those cycles merge into one in $q$. Cycles of $p$ not containing either $i$ or $j$ remain the same in $q$. Therefore, $q$ has either one more or one less cycle than $p$ does.\n\nNow let $t$ be any product of an odd number of transpositions. Then by the above, multiplying any permutation by $t$ changes the parity of the number of cycles in the permutation. Therefore $t$ cannot be the identity.\n\nshare|improve this answer\nExcellent answer. Gallian uses this argument. \u2013\u00a0 Stefan Smith Jan 9 '13 at 14:42\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55736/a-problem-in-finite-group-theory?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThis is a problem I encountered in Martin Isaacs' 'Finite Group Theory'. It's located at the end of Chapter II which deals with subnormality, and the particular paragraph is concerned with a couple of not so well-known results which I quote for reference:\n\n(In what follows $F$ is the Fitting subgroup)\n\nTheorem (Zenkov)\nLet $A$ and $B$ be abelian subgroups of the finite group G, and let $M$ be a minimal (in the sense of containment) member of the set {$A \\cap B^g : g \\in G$}. Then $M\\subseteq F(G)$.\n\nAn easy corollary follows which establishes the existence of a subnormal subgroup:\n\nIf $A$ is an abelian subgroup of the finite group $G$ and $|A|\\geq|G:A|$, then $A \\cap F(G)>1$.\n\nIn fact, if $A$ is cyclic, then a normal subgroup is guaranteed:\n\nTheorem (Lucchini)\nLet A be a cyclic proper subgroup of a finite group G, and let $K=core_G(A)$. Then $|A:K|<|G:A|$, and in particular, if $|A|\\geq|G:A|$, then $K>1$.\n\nLet G be a finite group such that $G=AN$, where $A$ is abelian, $N \\unlhd G$, $C_A(N)=1$ and $F(N)=1$. Show that $|A|<|N|$.\n\nNote that, since $N \\unlhd G$, it follows that $F(N)= N \\cap F(G)$. So, if $|A|\\geq|N|$ in the problem, then $|A|\\geq|N:N \\cap A|=|NA:A|=|G:A|$ and the corollary applies to give $A \\cap F(G)>1$.\n\nHow does one proceed from here to obtain a contradiction? In particular, how can the condition on the centralizer be utilized effectively?\n\nshare|improve this question\nI'm not sure this is the right site to visit for this kind of question, which is somewhat advanced but based on a textbook problem. I hope it's not a homework problem. (The issue would be different if you thought you found a serious gap or error in a published proof. Anyway, Isaacs himself is still active in mathematics and could be consulted in that case.) \u2013\u00a0 Jim Humphreys Feb 17 '11 at 18:17\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou were almost there: Since $N$ and $F(G)$ are two normal subgroups intersecting trivially, they commute. But now take a non-trivial element $a \\in A \\cap F(G)$; then by the previous observation, $a$ commutes with every element of $N$. But this contradicts the fact that $C_A(N) = 1$.\n\nshare|improve this answer\nIndeed. What if we replace the condition on the Fitting subgroup with the requirement that A and N have relatively prime orders. Is it still true that |A|<|N|? \u2013\u00a0 user13040 Feb 20 '11 at 23:15\nYes: if $A$ is a $\\pi$-group (where $\\pi$ is a set of primes), then the fact that $A \\cap F(G) > 1$ gives $A \\cap O_\\pi(G) > 1$. Now proceed as in the previous problem with $F(G)$ replaced by $O_\\pi(G)$. \u2013\u00a0 Tom De Medts Feb 21 '11 at 13:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/33834/calculating-impact-force-for-a-falling-object?answertab=oldest\nText:\nTake the tour \u00d7\n\nGood evening, I'm trying to calculate what kind of impact force a falling object would have once it hit something. This is my attempt so far:\n\nBecause $x= \\frac{1}{2} at^2$, $t=\\sqrt{2x/a}$\n$v=at$, therefore $v=a \\sqrt{2x/a}$\n$E_k=\\frac{1}{2} mv^2$, so $E_k=\\frac{1}{2} m(2ax)=m \\cdot a \\cdot x$\nSince $W=E_k=F_i s$, $F_i=E_k/s=(m \\cdot a \\cdot x)/s$\n\nFor an object weighing about as much as an apple, $0.182$ kg, falling $2.00$ m straight down and creating a dent of $0.00500$ m, this would result in:\n\n$$F_i=(m \\cdot a \\cdot x)/s$$\n\n$$F_i=(0.182 \\cdot 9.81 \\cdot 2.00)/0.00500=706 \\, \\text{N}$$\n\nDoes this make any sense? I wouldn't be surprised at all to find out I'm missing something here.\n\nAny input would be appreciated,\n\nthanks in advance!\n\nshare|improve this question\nYou forget air resistance. \u2013\u00a0 sidht Aug 9 '12 at 19:38\nRegarding Qmechanic's edit: While I know this is high-school level physics, please note that this is not, in fact, homework, as the tag would suggest. I do not have any assignment to go from nor any way to look up the answer. \u2013\u00a0 Chris Aug 9 '12 at 20:06\nYour calculations are ok and the model you used (constant hitting force) is reasonable. Though remember that's just a model, real apples hit the ground in a more complicated way, but I think for what you might use your calculations, your model is accurate enough. Unless, of course, you are not allow for the apple to bounce. \u2013\u00a0 Yrogirg Aug 10 '12 at 8:20\nRead all replies and marked an answer, thanks all for your help! \u2013\u00a0 Chris Aug 10 '12 at 9:29\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nIf your apple falls $2m$ it's velocity is calculated using the equation you give:\n\n$$ v^2 = 2as $$\n\nand you get $v^2 = 39.24 \\space m^2s^{-2}$ (I've haven't taken the square root for reasons that will become obvious). You know the apple is slowed to rest in $0.005m$, so you just need to work out what acceleration is needed when $v^2 = 39.24$ and $s = 0.005$. A quick rearrangement of your equation gives:\n\n$$ a = \\frac{v^2}{2s} $$\n\nand plugging in $v^2 = 39.24$ and $s = 0.005$ gives $a = 3925 \\space ms^{-2}$. To get the force just use Newton's equation:\n\n$$ F = ma $$\n\nwhere $m$ is the mass of the apple, $0.18 kg$, and you get $F = 706.32N$. So you got the correct answer (my answer differs from yours only because I used $g = 9.81 \\space ms^{-2}$).\n\nTo get a more general result substitute for $v^2$ in the second equation to get:\n\n$$ F = ma = m\\frac{2gs_1}{2s_2} = mg\\frac{s_1}{s_2}$$\n\nwhere $s_1$ is the distance the apple falls and $s_2$ is the distance it takes to stop.\n\nshare|improve this answer\nExactly what I was looking for, explanation and confirmation. Thank you very much! \u2013\u00a0 Chris Aug 10 '12 at 9:26\nadd comment\n\nI would have done this calculus if there was a uniform constant breaking force applied all all along the trajectory and if at impact, the ball had a zero velocity. The work done by such a force must exactly balance the initial mechanical energy of the ball. For a shock, I would rather use something like: d(mV)/dt=mg-F and use for instance a contact time dt=0.001s\n\nBefore impact: v=sqrt(2*g*x) After impact: v=0 Duration of the impact: dt=0.001s\n\n\nF=1140 N\n\nshare|improve this answer\nadd comment\n\nI'm not sure where you're going with the .0050 being treated as time, unless you meant to say it's in contact with the ground for .005 seconds. In that case, what you have would work algebraically.\n\nshare|improve this answer\nadd comment\n\nCalculate Potential energy using the following formula $PE = mgh = 0.182 \\cdot 9.81 \\cdot 2\\: \\mathrm{Joules}$\n\nAverage Impact Force = $0.182 \\cdot 9.81 \\cdot 2 \\cdot 0.005\\: \\mathrm{Newtons}$ (that is the answer)\n\nshare|improve this answer\nadd comment\n\nprotected by Qmechanic May 12 at 0:00"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234782/cyclotomic-polynomials\nText:\nTake the tour \u00d7\n\nLet $E(n)$ denote an nth root of unity. (For convenience, we may take $E(n) = \\exp(\\frac{2\u03c0i}{n})$.)\n\nProve that for any prime $p$ and any natural number $r$, we have $$ \\prod_{\\substack{j\\\\ \\gcd(p^r, j) = 1}} \\left(1 \u2013 E(p^r)^j\\right) = p,$$ without using the formula to get the cyclotomic polynomial of $p^r$.\n\nshare|improve this question\nWithout using what formula? And why without using it? \u2013\u00a0 Phira Nov 11 '12 at 10:49\n@Phira, because with using the formula it would be really direct. I wanted to see a proof without using the formula. The formula is Phi(x) = sum i= 1 to p-1 ( x^(i*p^(k-1))) \u2013\u00a0 John Chang Nov 11 '12 at 13:20\nIt should be $\\displaystyle{\\prod_{\\left(p^r,j\\right)=1} \\left(1 \u2013 E\\left(p^r\\right)^j\\right) = p^r}$. \u2013\u00a0 P.. Nov 12 '12 at 11:57\n@Pambos, the cyclotomic polynomial of p^r, Phi(x) = sum i= 1 to p-1 ( x^(i*p^(k-1))) gives us that it is indeed p. I think. But I wanted to see a more detailed proof without using this formula. \u2013\u00a0 John Chang Nov 12 '12 at 12:00\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nLet $n$ be a natural number and let $E_n=e^{2\\pi i/n}$. Then the polynomial $x^n - 1$ splits in $\\mathbb{Q}(E_n)$ as\n\n$x^n - 1 = (x - 1)(x - E_n)\\cdots(x-E_n^{n-1})$, which yields:\n\n$1+x+\\cdots+x^{n-1} = \\frac{x^n-1}{x-1} = (x - E_n)(x - E_n^2)\\cdots(x-E_n^{n-1})$\n\nand so we get the following result.\n\n$\\prod_{j=1}^{n-1}(1-E_n^j) = n$\n\nNow let $n = p^m$, for some natural number $m$. Thus,\n\n$p^m = \\prod_{j=1}^{p^m-1}(1-E_{p^m}^j) = \\prod_{(j, p^m)=1}(1-E_{p^m}^j)\\prod_{(j, p^{m-1})=1}(1-E_{p^{m-1}}^j)\\cdots\\prod_{(j, p)=1}(1-E_p^j)$\n\nNow look at the right side of the last equation. Each product $\\prod_{(j, p^r)=1}(1-E_{p}^j)$ is greater than 1, and there are a total of $m$ factors of this form. Since the product of these $m$ factors is $p^m$, then each factor must be equal to $p$.\n\nTherefore, $\\prod_{(j, p^r)=1}(1-E_{p^r}^j) = p$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/240175/computing-lim-n-rightarrow-infty-sqrtn1-sqrtn2-cdots-sqrtn2\nText:\nTake the tour \u00d7\n\nI'm trying to find:\n\n$$ \\lim_{n\\rightarrow\\infty} (\\sqrt[n]{1}+\\sqrt[n]{2}+\\cdots+\\sqrt[n]{2007}-2006)^n $$\n\n(Problem from CMJ)\n\nWe have:\n\n$$ k^{1/n}=1+\\frac{\\ln k}{n}+O(1/n^2) $$\n\n$$ \\left( \\sum_{k=1}^{2007}k^{1/n}-2006 \\right)^n= \\left(1+\\frac{1}{n}\\sum_{k=1}^{2007}\\ln k+O(1/n^2) \\right)^n \\sim_{n\\rightarrow\\infty} \\exp \\left( \\sum_{k=1}^{2007} \\ln k \\right)(=2007!)$$\n\nI'm quite sure of my result but I could not check it numerically.\n\nDo you agree with this limit?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nYes. Your limit looks fine. You can simplify it further into $$\\exp \\left( \\sum_{k=1}^{2007} \\log (k) \\right) = \\exp \\left( \\log \\left(\\prod_{k=1}^{2007} k \\right) \\right) = \\exp \\left( \\log (2007!) \\right) = 2007!$$\n\nshare|improve this answer\nOK, thank you Marvis! \u2013\u00a0 Chon Nov 18 '12 at 22:24\nadd comment\n\nTake the log of your expression and replace $x=\\frac{1}{n}$, you get the expression:\n\n$$\\frac{\\log\\left((\\sum_{k=1}^{2007} k^x) - 2006\\right)}{x}$$\n\nFirst, show the numerator approaches zero as $x\\to 0$. Then apply L'Hopital's rule, yielding a limit:\n\n$$ \\sum_{k=1}^{2007} \\log k = \\log 2007!$$\n\nThat is the log of your limit, so your limit is $e^{\\log 2007!}=2007!$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/79373/some-questions-concerning-a-random-number-process/79387\nText:\nTake the tour \u00d7\n\nConsider the following Markov process: Start with an integer $N = N_0$. Now repeatedly choose an $N_i$ uniformly at random in the range $[1...N_{i-1}]$ until $N_i = 1$ at which point one terminates the process. This produces a nonincreasing integer sequence $\\{N_0,N_1,\\ldots,N_{k-1},N_k = 1\\}$.\n\nExperimental evidence shows that as $N_0$ grows large, the expected length $E(N_0)$ of such a sequence seems to approach $ln(N_0)$. Equivalently, one expects that the average over many steps of $N_i/N_{i+1}$ is approximately $e$. Convergence to this expectation is slow however; for example if $N_0$ is a 1000-bit integer one finds that $E(N_0)$ satisfies roughly $2.71^{E(N_0)} = N_0$ and in particular the base agrees with $e$ to only around 2 decimal places.\n\nBecause the $N_i$ were chosen uniformly at random, for any given $i$ the expectation of $N_i/N_{i+1}$ is 2, so this seems to contradict the above observation that the average of $N_i/N_{i+1}$ is approximately $e$. To understand this discrepancy, consider a toy example where $N_1 = qN_0$ and $N_2 = (1-q)N_1$ for some $0\\leq q\\leq 1$. One sees that $N_2 \\leq \\frac{1}{4}N_0$ with equality iff $q=\\frac{1}{2}$; clearly the average of the step ratios $q$ and $1-q$ is equal to the expected single step ratio $\\frac{1}{2}$, but the composition of the steps has led to an overall decrease in the sequence at a rate faster than division by 2. Hence the above observation that the overall step decrease rate is approximately division by $e$ is plausible.\n\nMain Question: How does one understand the appearance of $e$ in the expected step down rate (as opposed to some other constant)? Presumably it should appear as a result of some averaging of all possible step ratios, but I can't seem to see what the correct average to be considering is.\n\nSecondary question: At the risk of being vague, does anyone know what an inverse to this process looks like? That is, a process where $M_0 = 1$ and at each step one chooses an $M_i\\geq M_{i-1}$ at random such that the expected growth rate is roughly multiplication by $e$ but such that the expected growth at any step should be multiplication by 2. Clearly one cannot choose the next number uniformly at random since this would lead to infinite step and expected growth, so what probability distribution (if any) can be put on the integers greater than $N_i$ so that choosing a next element will lead to a process which looks roughly like the original process in reverse?\n\nshare|improve this question\nAbout the main question: $e^{-1}=\\lim_{n\\to \\infty}(1-1/n)^n$: if $N_i$ is close to $N_{i-1}$ then the process takes longer. \u2013\u00a0 Mark Sapir Oct 28 '11 at 12:09\nWhen I answered this question I didn't realize I knew its author. Hi! \u2013\u00a0 Michael Lugo Oct 28 '11 at 13:50\nThanks for the various explanations everyone... the $e$ appearing as the result of geometric means is obvious in retrospect. \u2013\u00a0 ARupinski Oct 28 '11 at 23:02\nadd comment\n\n5 Answers\n\nup vote 9 down vote accepted\n\nFor the main question, your process is \"roughly\" the same as the one starting at $N_0=N$, and defined by $N_{i+1} = U_{i+1} N_{i}$, where $U_i$ are iid uniform in $[0,1]$. I guess that the \"roughly\" can be easily made more precise.\n\nFor this modified process, your question becomes: what is $k(N)$, the smallest $k$ such that $U_1\\dots U_k < 1/N$, or equivalently $\\ln U_1 + \\dots + \\ln U_k < -\\ln N$?\n\nBut the expected value of $\\ln U$ is $-1$, so that by the law of large numbers $\\ln U_1 + \\dots + \\ln U_k$ is equivalent to $-k$, which give that $k(N) \\sim \\ln N$.\n\nEdit: the following coupling argument makes the \"roughly\" more precise, as requested in the comments.\n\nGiven $(U_i)_{i \\geq 1}$ an iid sequence of uniform variables in $[0,1]$ and an integer $N$, consider the two processes $N_i$ and $\\widetilde N_i$ defined by $N_0 = \\widetilde N_0 = N$, and $N_{i+1} = U_{i+1} N_i$, and $\\widetilde N_{i+1} = 1+E(U_{i+1} \\widetilde N_i)$, where $E(\\cdot)$ is the integer part. The inequalities $N_i \\leq \\widetilde N_i \\leq N_i+i$ are obvious, and the process $\\widetilde N$ has the same law as the process described in the question.\n\nshare|improve this answer\nMikael: If the roughly can easily be made more precise, why do you omit the proof? This reminds of the old warning that when a mathermatician declares something is trivial but does not prove it, something is amiss... :-) (Nice post, by the way.) \u2013\u00a0 Did Oct 29 '11 at 16:47\nDidier: I did not have time to expand my answer (and check the details) when I first wrote it. But this is now done. \u2013\u00a0 Mikael de la Salle Oct 30 '11 at 20:26\nI agree with you that sentences containing \"can easily be made more precise\" can look suspicious... but I believe that my answer was enough for MO, which is meant for research-level questions (and I am sure that any researcher with some interest in the question could have made the roughly more precise). :-) \u2013\u00a0 Mikael de la Salle Oct 30 '11 at 20:34\nOn $[k(N)=i]=[N_i<1\\leqslant N_{i-1}]$, $\\widetilde{N}_i<i+1$ and $1\\leqslant \\widetilde{N}_{i-1}$, hence $\\widetilde{k}(N)\\geqslant i$ is all one can be sure of. It seems $\\widetilde{k}(N)$ may be quite larger than $k(N)$ when $N$ is large hence this comparison is not enough to characterize the asymptotic behaviour of $\\widetilde{k}(N)$. Or maybe you know how to bound the difference between $k(N)$ and $\\widetilde{k}(N)$, using arguments not in the post... \u2013\u00a0 Did Nov 2 '11 at 20:58\nI agree with you. If one wants to prove with this method that $a_N := E(\\widetilde k(N))\\sim\\ln N$, there is some more work: what follows from the coupling argument is that $a_N \\leq E(k(N)+a_{k(N)})$. One then uses some a priori bound on $a_N$ (as $a_N\\leq 2N$). But I think that the shortest way to prove that $a_N \\sim \\ln N$ is using Markov's property to express $a_N$ in term of the $a_n$'s for $n < N$ as Byron Schmuland explains. My answer was more meant as an informal explanation for the $1/e = \\exp(E(ln U))$ appearing instead of $1/2 = E(U)$. \u2013\u00a0 Mikael de la Salle Nov 3 '11 at 0:33\nadd comment\n\nRegarding the secondary question: If we start the process from a large $N$, it will always reach 1 sooner or later. The probability that it passes through the number 2 is $1/2$, since as long as the numbers are larger than 2, going in the next step to 2 is as likely as going to 1, and when the process reaches 1 or 2 for the first time, where it went decides whether it ever passes through 2. Similarly the probability that the process ever visits a number $n$ is $1/n$, since this happens precisely when the first visit to any of $1,\\dots,n$ is to $n$.\n\nNow it's easy in principle to see what the inverse is: For each pair of numbers $m < n$, the probability that a process starting at a larger $N$ will include a step from $n$ to $m$ is $$\\frac1{n(n-1)},$$ since it will reach $n$ with probability $1/n$, and the next number distinct from $n$ is uniform on $1,\\dots,n-1$. In particular, for \"infinite $N$\", the last number visited before reaching 1 is $n$ with this probability.\n\nFor $m>1$, the probability that $m$ was reached from $n$ given that the process reached $m$ is $m/(n(n-1))$, since we get a factor $m$ from conditioning on the process ever reaching $m$. It might be easier to sort out the details if we assume that the process never repeats the same number.\n\nADDED: The inverse process constructed this way has the property that at any $m$, the expectation of the next (previous in the original process) step is infinite. But it does have the nice property that the probability of going from $m$ to a number $\\leq 2m$ is $1/2$, so the median growth factor over one step is 2.\n\nNEW UPDATE: If we discard repetitions, then one way to understand the inverse is that from a number $m$, the next step is $$m\\mapsto \\left\\lceil\\frac{m}{U}\\right\\rceil,$$ where $U$ is uniform on the interval $[0,1]$. When $m$ is large, the growth factor is therefore asymptotically the reciprocal of a uniform $[0,1]$, which is the same thing as an \"exponential of an exponential\" ($e$ to an exponential variable). The median growth factor over one step is 2, but over a large number of steps approaches $e$.\n\nshare|improve this answer\nThe first paragraph also shows that the expected number of steps is exactly $1 + (1/2) + (1/3) + \\cdots + (1/N) = H_N = \\log(N) + C + O(1/N)$ where $C = 0.5772157\\ldots$ is the Euler(-Mascheroni) constant. This explains the OP's observation that $E(N)$ looks like $\\log N$ but the convergence in $N^{1/E(N)} \\rightarrow e$ is slow. \u2013\u00a0 Noam D. Elkies Oct 30 '11 at 1:33\nadd comment\n\nUsing Markov chain theory, it is not hard to show that the expected time until the process hits state \"1\" starting at $N_0$ is $1+1+1/2+\\cdots+1/(N_0-1)$.\n\n\nIn my previous answer, I mistakenly chose a new state uniformly from $[1,\\dots, N_i]$ instead of $[1,\\dots, N_{i-1}]$. The expected hitting time of state \"1\" for the OP's model starting at $N_0$ is $1+1/2+\\cdots+1/(N_0-1)$. This is one less than my first answer.\n\nshare|improve this answer\nadd comment\n\nThe average you want in the main question is the geometric mean, as Mikael de la Salle has already alluded to.\n\nAbout the secondary question: I'd start by looking for a random variable $X$, which always takes value at least 1, which has expectation 2 and geometric mean $e$. Let $X_1, X_2, \\ldots$ be independent, and let each have the distribution of $X$. Then take $M_i$ to be $M_{i-1} X_i$ rounded to the nearest integer. Unfortunately there is no such random variable, by the arithmetic-geometric mean inequality. So it seems very likely to me that there is no such process.\n\nshare|improve this answer\nExpectation is actually supposed to be the harmonic mean of [0,1], not the arithmetic mean. The harmonic mean is, of course, infinite. Such a random variable exists, and can, in fact, be derived from the above solution by Johan. \u2013\u00a0 Will Sawin Oct 28 '11 at 17:35\nYou're right! My proof of nonexistence didn't feel right to me, but I think I hadn't had coffee yet. \u2013\u00a0 Michael Lugo Oct 28 '11 at 18:41\nadd comment\n\nThe process described is also known as the stick-breaking process for sampling the cycle type of a uniformly chosen permutation in $S_n$. So we have the set $[n]$ and we want to choose a uniformly random permutation $\\sigma$ in $S_n$, viewed as an automorphism of $[n]$. So we can choose $n$ target values for $\\sigma(1)$ and $n-1$ values for $\\sigma(\\sigma(1))$ etc. This process stops when $\\sigma^k(1) = 1$ for some least $k > 0$. It's an easy computation to show that the chance that the process stops at step $k$ is always $1/n$ regardless of what $k$ is: for instance, if $k = 1$, then that means $1$ has to map to itself, which if done uniformly has chance $1/n$, and if $k=2$, then there are $n-1$ out of $n$ choices for $\\sigma(1)$ (because we have to exclude $1$), and $1$ out of $n-1$ choices for $\\sigma(\\sigma(1))$, namely it has to be $1$. So the probability in that case is $\\frac{n-1}{n} \\frac{1}{n-1} = 1/n$ again! This corresponds to a uniform \"cut\" in $[n]$ such that everything to the left of that cut gives the length of the cycle containing $1$. Now we continue by picking a number not in the first cycle, and the process is indeed self-similar by inspection.\n\nThe number of cycles of a ramdom permutation is concentrated at $\\log n$ with variance $\\log n$ and satisfies a Central limit theorem. Therefore we expect $\\log n$ on average for the finishing time of the original problem.\n\nshare|improve this answer\n+1, but you should explain your answer. \u2013\u00a0 Ori Gurel-Gurevich Oct 31 '11 at 1:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/41030/why-is-int-dp-2-pi-p-rangle-langle-p-1\nText:\nTake the tour \u00d7\n\nIn quantum mechanics, why is $\\int (dp/2\\pi) |p \\rangle\\langle p| = 1 $ where $|p \\rangle$ represents momentum eigenstate?\n\nshare|improve this question\nAre you sure about the two pi? A family of orthonormal vectors spans the whole space (is 'complete') is the sum of all the projectors onto each single basis vector gives the identity operator. A projector onto the normalized state |p> is |p><p|, the sum over all projectors $\\int dp |p><p|$, and the identity operator is just 1 \u2013\u00a0 A.O.Tell Oct 17 '12 at 16:33\nIt's from A.Zee's Quantum Field Theory page 11.. So it is wrong? \u2013\u00a0 RRRR Oct 17 '12 at 17:51\nIt's not wrong, it's just a way to normalize states that is a bit unconventional. Maybe it has advantages elsewhere. I'll check Zee later \u2013\u00a0 A.O.Tell Oct 17 '12 at 18:10\nadd comment\n\n3 Answers\n\nup vote 4 down vote accepted\n\nThe factor of $2\\pi$ is a convention Zee uses which normalizes the $|p\\rangle$ states so that they are not quite orthonormal:\n\n$$ \\langle p | p' \\rangle = 2\\pi \\delta(p-p') $$\n\nwhich means that Zee's $p$ states are different from Ahmed's $p$ states by a factor of $\\sqrt{2\\pi}$. Let me call these unit normalized $p$ states $||p\\rangle$, then\n\n$$ \\sqrt{2\\pi} || p \\rangle = |p\\rangle $$\n\nThis is something Dirac does also, and it becomes essential for relativistic states, when you want\n\n$$ \\int {d^3 p \\over (2\\pi)^3 2\\omega_p} |p\\rangle\\langle p| = 1 , $$\n\nbecause then all the parts are manifestly invariant andso the integral over $p$ is an integral over the mass-shell hyperboloid:\n\n$$ \\int {d^4 p \\over (2\\pi)^4} (2\\pi) \\delta(p_\\mu p^\\mu - m ^2) = \\int {d^3 p\\over (2\\pi)^3 (2\\omega_p)} , $$\n\nwhere the delta function projects you onto the mass shell in a relativistically invariant way. But for this to be true, you need\n\n$$ |p\\rangle = (\\sqrt{2\\pi})^3 \\sqrt{2\\omega_p} || p \\rangle $$\n\nwhere $\\omega_p = \\sqrt{p^2 + m^2} $. This is called a relativistically normalized state. The relativistically normalized states are natural, and define relativistically normalized creation operators,\n\n$$ \\alpha(k) |0\\rangle = |k\\rangle , $$\n\nwhich are related to the usual nonrelativistically normalized creation operators as follows:\n\n$$ \\alpha(k) = (\\sqrt{2\\pi})^3 \\sqrt{2\\omega_k} a_k . $$\n\nIn terms of the $\\alpha(k)$'s and their conjugates, the field Fourier expansion is manifestly invariant:\n\n$$ \\phi(x) = \\int e^{ikx} \\alpha(k) + e^{-ikx} \\alpha^\\dagger(x) {d^3p \\over (2\\pi)^3 2\\omega_k} . $$\n\nThis looks trivial, but it makes everything in scattering theory and mode expansions relativistically consistent. So you can make trivial all the first chapters of any old quantum field theory books with mode expansions which look opaque, because they are noncovariant.\n\nshare|improve this answer\nadd comment\n\nI don't think this question has been answered. The original poster asked: why is \\begin{align} \\int dp |p\\rangle \\langle p| = 1, \\end{align} up to unimportant normalization issues that have been discussed extensively (but are off the point).\n\nThe above statement is equivalent to the question of completeness of a set of states on an Hilbert space (which ahmed addressed but did not answer the question why the LHS of the original poster's equation is equal to the RHS).\n\nCompleteness is, heuristically, the statement that a set of vectors (functions on a Hilbert space) spans the space of possible (piecewise continuous and some degree of smoothness (differentiable)) functions on that space. In other words, just about any \"well-behaved\" function can be expanded in a basis of states that is complete.\n\nA proof of completeness of eigenfunctions of differential equations is given in Chapter VI, Section 3, p. 424 of Courant & Hilbert's Methods of Mathematical Physics, Vol. 1, first English edition. It's too lengthy to reproduce here.\n\nBut motivation (not a \"proof\") for the completeness relation can be given as follows. We consider the expansion of the Dirac $\\delta$ function in a particular basis, say the position basis. We assume that it can be written as an expansion over momentum eigenstates in the position basis, $e^{-ipx'}$: \\begin{align} \\delta(x-x') &= \\int_{-\\infty}^\\infty\\!dp\\,c_p(x)\\frac{e^{-ipx'}}{\\sqrt{2\\pi}}. \\end{align} Clearly the coefficient, $c_p$ in the expansion must depend on $x$ since the $\\delta$ function on the LHS does.\n\nThe completeness relation is determined as follows. Mulitply the above equation by $e^{ip'x'}/\\sqrt{2\\pi}$, interchange the order of the two integrals, and integrate over $x'$ on the interval $(-\\infty,\\infty)$. Use orthonormality of the plane waves, $\\int_{-\\infty}^\\infty \\frac{dx'}{2\\pi} e^{i(p'-p)x'}=\\delta(p'-p)$ to get \\begin{align} c_{p'}(x) &= \\frac{1}{\\sqrt{2\\pi}} e^{ip'x}. \\end{align} Substitution back into the expression for $\\delta(x-x')$ gives \\begin{align} \\delta(x-x') = \\int_{-\\infty}^\\infty \\frac{dp}{2\\pi}e^{ip(x-x')}. \\end{align} Rewriting this \\begin{align} \\delta(x-x') &= \\langle x|x' \\rangle = \\langle x|1|x' \\rangle \\\\ &= \\int_{-\\infty}^\\infty\\! dp\\, \\langle x|p\\rangle\\langle p|x'\\rangle \\\\ \\langle x|1|x' \\rangle &= \\langle x| \\cdot\\Big[\\int_{-\\infty}^\\infty\\! dp\\, |p\\rangle\\langle p|\\Big] \\cdot |x'\\rangle. \\end{align} And completeness follows from the arbitrariness of the values of $x,x'$.\n\nNota Bene: This is not a proof as we have made several questionable steps (like reversing the orders of integration $dx' \\leftrightarrow dp$) and essentially assumed the result we wanted (by using orthonormality).\n\nWhat this does, though, is to make plausible the idea that if you need to expand a function in a complete set of states, you need a relation like $\\int\\! dp\\, |p\\rangle\\langle p| =1$ to hold.\n\nshare|improve this answer\n-1: OP was asking about why the $2\\pi$ factors appear in some books and not others, not about why basis states are supposed to be orthonormal. \u2013\u00a0 Ron Maimon Mar 28 at 3:15\nYou need to read the question again, Maimon: \"In quantum mechanics, why is \u222b(dp/2\u03c0)|p\u27e9\u27e8p|=1 where |p\u27e9 represents momentum eigenstate?\" This is asking about completeness not normalization. -1 for being off-topic. \u2013\u00a0 MarkWayne Mar 28 at 4:49\nI was here when OP asked the question, the issue was the 2pi factor, which confused OP, because it is not orthonormal, but a different convention from other books. I understand what was being asked, really, I am not offtopic. I shouldn't have downvoted you, I suppose, you didn't say wrong things, just things OP already knows. \u2013\u00a0 Ron Maimon Mar 28 at 19:20\nadd comment\n\nThe composition of any state in terms of the momentum eigenstates is $\\lvert\\psi\\rangle = k\\int \\mathrm{d}^{3}p\\lvert p\\rangle\\langle\\psi \\vert p\\rangle$. The set of momentum eigenstates form a complete set of orthogonal state vectors in Hilbert space (this set is uncountably infinite). The components of this decomposition are the $\\langle\\psi \\vert p\\rangle$ for each $p$ (a complex number).\n\nTo simplify things, $\\int \\mathrm{d}^{3}p\\lvert p\\rangle \\langle p\\rvert$ is an operator. Let $\\int \\mathrm{d}^{3}p\\lvert p\\rangle\\langle p\\rvert = A$, then $A\\lvert\\psi\\rangle = \\lvert\\psi\\rangle$ for an arbitrary $\\lvert\\psi\\rangle$ then $A$ must be the identity operator.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/65424/determinant-of-sum-of-positive-definite-matrices/65430\nText:\nTake the 2-minute tour \u00d7\n\nSay $A$ and $B$ are symmetric, positive definite matrices.\n\nI've proved that $\\det(A+B) \\ge \\det(A) + \\det(B)$ in the case that $A$ and $B$ are two dimensional.\n\nIs this true in general for $n$-dimensional matrices?\n\nIs it even true that $\\det(A+B) \\ge \\det(A)$ [as this would also be enough..]\n\n\nshare|improve this question\n\n6 Answers 6\n\nup vote 32 down vote accepted\n\nThe inequality $$\\det(A+B)\\geq \\det A +\\det B$$ is implied by the Minkowski determinant theorem $$(\\det(A+B))^{1/n}\\geq (\\det A)^{1/n}+(\\det B)^{1/n}$$ which holds true for any non-negative $n\\times n$ Hermitian matrices $A$ and $B$. The latter inequality is equivalent to the fact that the function $A\\mapsto(\\det A )^{1/n}$ is concave on the set of $n\\times n$ non-negative Hermitian matrices (see e.g., A Survey of Matrix Theory and Matrix Inequalities by Marcus and Minc, Dover, 1992, P. 115 and also the previous MO thread).\n\nshare|improve this answer\nlooks nice, but isn't it somewhat overkill to invoke the Minkowski theorem here? \u2013\u00a0 Suvrit May 19 '11 at 17:05\nThanks very much! \u2013\u00a0 user15221 May 19 '11 at 17:44\nThis is really misleading since it makes the question look like complicated, while is almost obvious that $\\det(A+B) = \\det(A) \\det(1+A^{-1/2}BA^{-1/2}) \\geq \\det(A) (1+\\det(A^{-1/2}BA^{-1/2})) = \\det(A) + \\det(B)$. In the second step, it is just used that $\\prod_i (1+ \\mu_i) \\geq 1 + \\prod_i \\mu_i$, where $\\mu_i$ are the eigenvalues of $A^{-1/2}BA^{-1/2}$. \u2013\u00a0 Andreas Thom Jun 28 at 20:02\n\nYet another way to see this is to note that $A = \\overline{Q}^{t}Q$ for some invertible matrix $Q$. Then ${\\rm det}(A+B) = |{\\rm det}(Q)|^{2}{\\rm det}{( I + (\\overline{Q}^{-1}})^{t}BQ^{-1})$.` Now $(\\overline{Q}^{-1})^{t}BQ^{-1}$ is Hermitian, and positive definite. It suffices to prove that if $X$ is positive definite and Hermitian, then ${\\rm det}(I+X) \\geq (1 + {\\rm det}X)$. We may conjugate $X$ by a unitary matrix $U$ and assume that $X$ is diagonal. Let the eigenvalues of $X$ be $\\lambda_{1},\\ldots, \\lambda_{n}$, (allowing repetitions). Then ${\\rm det}(I+X) = \\prod_{i=1}^{n}(1 + \\lambda_{i}) \\geq 1 + \\prod_{i=1}^{n} \\lambda_{i} = 1 + {\\rm det}X.$ Such an argument appears in some proofs by R. Brauer, though I do not know whether it originates with him.\n\nLater edit: Incidentally, I think that with the arithemetic-geometric mean inequality and a slightly more careful analysis, you can see by this approach that for $X$ as above, you do have ${\\rm det}(I+X) \\geq (1 +({\\rm det}X)^{1/n})^{n}$ (a special case of the inequality of Minkowski mentioned in the accepted answer, but enough to prove the general case by an argument similar to that above). For set $d = {\\rm det}X$. Let $s_{m}(\\lambda_{1},\\ldots ,\\lambda_{n})$ denote the $m$-th elementary symmetric function evaluated at the eigenvalues. Using the arithmetic-geometric mean inequality yields that $s_{m}(\\lambda_{1},\\ldots ,\\lambda_{n}) \\geq \\left( \\begin{array}{clcr} n\\\\m \\end{array} \\right)d^{m/n}$, so we obtain ${\\rm det}(I+X) \\geq (1+d^{1/n})^{n}.$\n\nshare|improve this answer\n\nWe have $((A+B)x,x)\\ge (Ax,x)$. It then follows from the variational characterization of eigenvalues (min-max theorem) that the eigenvalues of $A+B$ are greater than or equal to those of $A$. This implies $det(A+B)\\ge det(A)$.\n\nshare|improve this answer\n\nHere is yet another overkill, but hopefully not too bad a way to prove this inequality.\n\nWe have the following proof sketch.\n\n$$\\begin{eqnarray} x^T(A+B)x &\\ge& x^TAx\\quad\\forall x\\\\\\\\ -x^T(A+B)x &\\le& -x^TAx\\\\\\\\ \\exp(-x^T(A+B)x) &\\le& \\exp(-x^TAx)\\\\\\\\ \\int\\exp(-x^T(A+B)x)dx &\\le& \\int\\exp(-x^TAx)dx\\\\\\\\ \\frac{1}{\\sqrt{\\det(A+B)}} &\\le& \\frac{1}{\\sqrt{\\det(A)}}\\\\\\\\ \\det(A+B) &\\ge& \\det(A) \\end{eqnarray} $$\n\nThe only fancy thing that happened is in the second last line, where I used the formula for the Gaussian integral (see multivariate section)\n\nshare|improve this answer\n\nThe determinant of a positive definite matrix $G$ is proportional to $(1/\\hbox{Volume}(\\mathcal B(G)))^2$ where $\\mathcal B(G)$ denotes the unit ball with respect to the metric defined by $G$. If $A$ and $B$ are positive definite then the volume of $\\mathcal B(A+B)$ is smaller than the volume of $\\mathcal B(A)$ or $\\mathcal B(B)$.\n\nshare|improve this answer\nIt's worth noting that this is secretly the same as Suvrit's answer. \u2013\u00a0 Mark Meckes May 20 '11 at 14:20\nNot really: You don't need exponentials for proving that $\\det(G)$ is proportional to $1/\\hbox{Volume}(G)^2$ : It is enough to stare at an orthogonal basis formed of eigenvectors for $G$. In this sense this proof is more elementary. \u2013\u00a0 Roland Bacher May 25 '11 at 7:18\nFair enough.$ $ \u2013\u00a0 Mark Meckes May 29 '11 at 0:49\n\nLet me add some more. If $A, B, C$ are positive semidefinite, then $$\\det (A+B+C)+\\det C\\ge \\det (A+C)+\\det (B+C). \\quad (\\star)$$\n\nWhen $C=0$, this reduces to OP's question.\n\nA remarkable extension of ($\\star$) were recently obtained by V. Paksoy, R. Turkmen, F. Zhang [ Electron. J. Linear Algebra 27 (2014) 332-341], which says that the determinant functional can be replaced by any generalized matrix function.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/322851/on-the-precise-asymptotic-scaling-of-n-n-k-as-n-k-to-infty\nText:\nTake the 2-minute tour \u00d7\n\nOn page 23 of [Erd\u0151s+R\u00e9nyi 1960, \"On the evolution of random graphs\"], the following asymptotic formula is stated without proof: $$ \\binom{n}{k} \\sim \\frac{n^k \\mathrm e^{-\\frac{k^2}{2n} - \\frac{k^3}{6n^2}}}{k!} $$ valid for $k \\in o(n^{\\text{[some illegible fraction]}})$. That is, we have $$ \\frac{n!}{(n-k)!} \\;=\\; n^k \\exp\\left(-\\tfrac{k^2}{2n} - \\tfrac{k^3}{6n^2}\\right) \\cdot \\Bigl[1 \\pm o(1)\\Bigr].$$ I was curious about what the limitations of the illegible upper bound on $k$ were for this approximation, and hoped that I could use at least some useful scaling for $k \\in \\Theta(n^{2/3})$, so I tried to rederive it. However, using Stirling's approximation for the factorial, $$ n! = n^{n+\\frac{1}{2}} \\mathrm e^{-n}\\cdot \\Bigl[\\sqrt{2\\pi} + o(1)\\Bigr], $$ the best that I could rederive was the following: $$\\begin{align} \\frac{n!}{(n-k)!} \\;&=\\; \\frac{n^{n-k+\\frac{1}{2}} n^k \\mathrm e^{n-k}}{(n-k)^{n - k + \\frac{1}{2}} \\mathrm e^n} \\cdot \\Bigl[1 \\pm o(1)\\Bigr] \\\\&=\\; n^k \\left(1 - \\frac{k}{n}\\right)^{-n+k-\\frac{1}{2}} \\mathrm{e}^{-k} \\cdot \\Bigl[1 \\pm o(1)\\Bigr]\\end{align}$$ which looks as though it should scale like $$ \\frac{n!}{(n-k)!} \\;\\;\\stackrel{\\;?\\,}\\sim\\;\\; n^k \\exp\\Bigl( - \\tfrac{k^2}{n} + \\tfrac{k}{2n} \\Bigr),$$ for all $k \\in o(n)$. This is close, but no cigar. Is there anything that I'm missing?\n\nshare|improve this question\nA comment on the \"illegible fraction\": the denominator seems to be a $4$. The numerator looks like a $2$, which doesn't make sense. It might also be a $3$. \u2013\u00a0 Andrew Uzzell Mar 6 '13 at 19:18\n@AndrewUzzell: that's more or less what I thought, too. Mind you, if it's as trivial a formula as they imply (and it doesn't seem as though it should be too hard to prove in principle if correct, right?) then it shouldn't be too hard to show it, and possibly discover that the value of the exponent plays a particular role. \u2013\u00a0 Niel de Beaudrap Mar 6 '13 at 19:19\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nAs you say, if $n$ approaches infinity so that $k/n\\to 0$, by Stirling's approximation $$ k! n^{-k} \\binom{n}{k} = (1 + o(1)) (1-\\frac{k}{n})^{-(n-k)} e^{-k}. \\qquad\\ \\ \\ (*) $$ Then, taking logarithms and expanding in a Taylor series with remainder gives \\begin{eqnarray*} \\log\\left((1-\\frac kn)^{-(n-k)} e^{-k}\\right)&=&-k-(n-k)\\log(1-\\frac kn)\\\\ &=& -k + (n-k) \\left(\\sum_{1\\le i\\le j} \\frac 1i (\\frac kn)^i + O((\\frac kn)^{j+1})\\right)\\\\ &=& -\\sum_{1\\le i\\le j-1} \\frac 1 {i(i+1)} \\frac{k^{i+1}}{n^i}+ O(\\frac{k^{j+1}}{n^j}) \\end{eqnarray*} for any fixed $j\\ge 1$. Exponentiating and substituting this back into $(*)$ gives, as $n\\to\\infty$, $$ \\binom{n}{k} = (1 + o(1)) \\frac{n^k}{k!} \\exp\\left(-\\sum_{1\\le i\\le j-1}\\frac{1}{i(i+1)} \\frac{k^{i+1}}{n^i} \\right),\\ \\ \\ \\text{where } k=o(n^{j/(j+1)}). $$ The formula in the Erd\u0151s-R\u00e9nyi paper is obtained by setting $j:=3$. The illegible exponent should then be $3/4$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/206854/whats-the-probability-that-abe-will-win\nText:\nTake the 2-minute tour \u00d7\n\nAbe and Bill are playing a fun game. Each of them roll a dice every turn. Abe succeeds if he rolls either a 1 or 2. Bill succeeds is he rolls either a 3, 4, or 5.\n\nIf they both succeed on a turn, then they tie the game. If exactly 1 player succeeds on a turn, then the succeeding player wins. If neither player succeeds on a turn, another turn occurs.\n\nWhat's the probability that Abe will win? I originally thought that the answer was $\\frac{2}{5}$, but I realized that the players could tie as well.\n\nshare|improve this question\nDoes Bill succeed if Abe rolls a $3$, $4$, or $5$? Or do they need to roll \"their\" number? \u2013\u00a0 Andr\u00e9 Nicolas Oct 4 '12 at 0:12\nThey both need to roll one of their numbers on their own dice. Good point. \u2013\u00a0 David Faux Oct 4 '12 at 0:13\nA non-mathematical comment: dice is plural, the singular being die. \u2013\u00a0 Brian M. Scott Oct 4 '12 at 0:28\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nOut of 36 (6x6) combinations of die rolls:\n\nAbe will win in 6 of them: (Abe rolls 1 or 2) AND (Bill rolls 1 or 2 or 6)\n\nBill will win in 12 of them: (Abe rolls 3 or 4 or 5 or 6) AND (Bill rolls 3 or 4 or 5)\n\nThe remaining lead to another roll, so they became irrelevant as only one of the 18 situation above finishes up the game.\n\nOut of 18 possible, and equally likely, game ends, Abe wins 6 times, thus:\n\nP{Abe wins} = 6/18 = 1/3\n\nshare|improve this answer\n\nLet $p$ be the probability that Abe eventually wins the game. This can happen in three ways:\n\n(i) (Immediately) Abe succeeds and Bill fails.\n\n(ii) Abe succeeds, and Bill does. Then they are tied. Given this, Abe's probability of ultimately winning is $p$.\n\n(iii) Abe and Bill both fail. Then we are in a situation similar to (ii).\n\nSo $$p=\\frac{2}{6}\\cdot\\frac{3}{6}+\\left(\\frac{2}{6}\\cdot\\frac{3}{6}\\right)p+\\left(\\frac{4}{6}\\cdot\\frac{3}{6}\\right)p.$$\n\nSolve. We get $p=\\dfrac{1}{3}$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/12122/deriving-newtons-third-law-from-homogeneity-of-space/12126\nText:\nTake the 2-minute tour \u00d7\n\nI am following the first volume of the course of theoretical physics by Landau. So, whatever I say below mainly talks regarding the first 2 chapters of Landau and the approach of deriving Newton's laws from Lagrangian principle supposing Hamilton's principle of extremum action. Please keep this view in mind while reading and answering my queries and kindly neglect the systems to which Action Principle is not applicable:\n\nIf we use homogeneity of space in Euler-Lagrange equations, we obtain a remarkable result i.e. the conservation of momentum for a closed system.\n\nNow, this result, using the form of Lagrange for a closed system of particles, transforms into $ \\Sigma F = 0 $ . Now, how from this can we conclude that the internal forces that particles exert come in equal and opposite pairs?\n\nIs it because for 2 particles this comes out as $ F_{1} + F_{2} = 0 $ and we take the forces exerted by particles on one other to be independent of other particles (i.e. Superposition Principle) as an experimental fact?\n\nI doubt it as whole of Newtonian Mechanics is derivable from Lagrangian Mechanics and supposed Symmetries. So, according to me, a fact like Newton's Third Law should be derivable from it without using an additional experimental fact.\n\nI have an idea to prove it rigorously. Consider two particles $i$ and $j$. Let the force on $i$ by $j$ be $F_{ij}$ and on $j$ by $i$ be $k_{ij}F_{ij}$. Now the condition becomes $\\Sigma (1+k_{ij})F_{ij}=0$ where the terms to be included and rejected in summation understood. As this must be true for any value of $F_{ij}$, we get $k_{ij}=-1$. I don't know if this argument or refinement of such an argument holds or not. I can see many questions arising in this argument and it's not very convincing to me.\n\nI would like to hear from you people as to if it is an experimental result used or not? If not, then is the method given above right or wrong? If wrong, how can we prove it?\n\n\nMy method of proof uses the fact of superposition of forces itself, so it is flawed. I have assumed that the coefficients $k_{ij}$ are constants and don't change in the influence of all other particles which is exactly what superposition principle says.\n\nAs the superposition of Forces can be derived by superposition of potential energies at a point in space and potential energy being more fundamental in Lagrangian Mechanics, I restate my question as follows:\n\nIs the principle of superposition of potential energies by different sources at a point in space derivable from the inside of Lagrangian Mechanics or is it an experimental fact used in Lagrangian Mechanics?\n\nI, now, doubt this to be derivable as the fundamental assumption about potential energy is only that it is a function of coordinates of particles and this function may or may not respect superposition.\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 10 down vote accepted\n\nThe derivation in Landau and Lifschitz is making some additional implicit assumptions. They assume that all forces come from pair-interactions, and that the pair forces are rotationally invariant. With these two assumptions, the potential function in the Lagrangian is\n\n$V(x1,...,xn) = \\sum_{\\langle i,j\\rangle} V(|x_i - x_j|)$\n\nAnd then it is easy to prove Newton's third law, because the derivative of the distance function is equal and opposite for each pair of particles.\n\nThis type of derivation is reasonable from a physical point of view for macroscopic objects, but it is not mathematically ok, because it omits important examples.\n\nNo rotational invariance, no third law\n\nDropping the assumption of rotational invariance, but keeping the assumption of pair-wise interaction, one gets the following counterexample in 2 dimensions, with two particles (A,B) with position vectors $(A_x,A_y)$ $(B_x,B_y)$ respectively:\n\n$V(A_x,A_y,B_x,B_y) = f(A_x-B_x) + f(A_y - B_y) $\n\nwhere f is any function other than $f(x)=x^2$. This pair potential leads to equal and opposite forces, but not collinear ones. Linear momentum and energy are conserved, but angular momentum is not, except when both particles are on the lines $y=\\pm x$ relative to each other. The potential is unphysical of course, in the absence of a medium like a lattice that breaks rotational invariance.\n\nMany-body direct interactions, no reflection symmetry, no third law\n\nThere is another class of counterexamples which is much more interesting, because they do not break angular momentum or center of mass conservation laws, and so they are physically possible interactions in vacuum, but they do break Newton's third law. This is the chiral three-body interaction.\n\nConsider 3 particles A,B,C in two dimensions whose potential function is equal to the signed area of the triangle formed by the points A,B,C.\n\n$V(A,B,C) = B_x C_y - A_x C_y -B_x A_y - C_x B_y + C_x A_y + A_x B_y$\n\nIf all 3 particles are collinear, the forces for this 3-body potential are perpendicular to the common line they lie on. The derivative of the area is maximum by moving the points away from the common line. So you obviously cannot write the force as any sum of pairwise interactions along the line of separation, equal and opposite or not. The forces and torques still add up to zero, since this potential is translationally and rotationally invariant.\n\nMany body direct interaction, spatial reflection symmetry, crappy third law\n\nIf the force on k particles is reflection invariant, it never gets out of the subspace spanned by their mutual separation. This is because if they lie in a lower dimensional subspace, the system is invariant with respect to reflections perpendicular to that subspace, so the forces must be as well.\n\nThis means that you can always cook up equal and opposite forces between the particles that add up to the total force, and pretend that these forces are physically meaningful. This allows you to salvage Newton's third law, in a way. But it gives nonsense forces.\n\nTo see that this is nonsense, consider the three-particle triangle area potential from before, but this time take the absolute value. The result is reflection invariant, but contains a discontinuity in the derivative when the particles become collinear. Near collinearity, the forces perpendicular have a finite limit. But in order to write these finite forces as a sum of equal and opposite contributions from the three-particles, you need the forces between the particles to diverge at collinearity.\n\nThree body interactions are natural\n\nThere is natural physics that gives such a three-body interaction. You can imagine the three bodies are connected by rigid frictionless struts that are free to expand and contract like collapsible antennas, and a very high-quality massless soap bubble is stretched between the struts. The soap bubble prefers to have less area according to its nonzero surface tension. If the dynamics of the soap bubble and the struts are fast compared to the particles, you can integrate out the soap bubble degrees of freedom and you will get just such a three-body interaction.\n\nThen the reason the bodies snap together near collinearity with a finite transverse force is clear--- the soap bubble wants to collapse to zero area, so it pulls them in. It is then obvious that there is no sense in which they have any diverging pairwise forces, or any pairwise forces at all.\n\nOther cases where you get three body interactions directly is when you have a nonlinear field between the three objects, and the field dynamics are fast. Consider a cubically self-interacting massive scalar field (with cubic coupling $\\lambda$) sourced by classical stationary delta-function sources of strength g. The leading nonlinear contribution to the classical potential is a tree-level, classical, three-body interaction of the form\n\n$V(x,y,z) \\propto g^3 \\lambda \\int d^3k_1 d^3k_2 { e^{i(k_1\\cdot (x-z) + k_2\\cdot(y-z))} \\over (k_1^2 + m^2) (k_2^2 + m^2)((k_1+k_2)^2 + m^2)}$\n\nwhich heuristically goes something like ${e^{-mr_{123}}r_{123}\\over r_{12}r_{23}r_{13}}$ where the r's are the side lengths of the triangle and $r_{123}$ is the perimeter (this is just a scaling estimate). For nucleons, many body potentials are significant.\n\nThe forces from the crappy third law are not integrable\n\nIf you still insist on a Newton's third law description of three-body interactions like the soap bubble particles, and you give a pairwise force for each pair of particles which adds up to the full many-body interaction, these pairwise forces cannot be thought of as coming from a potential function. They are not integrable.\n\nThe example of the soap-bubble force makes it clear--- if A,B,C are nearly collinear with B between A and C, closer to A, you can slide B away from A towards C very very close to collinearity, and bring it back less close to collinear. The A-B force is along the line of separation, and it diverges at collinearity, so the integral of the force along this loop cannot be zero.\n\nThe force is still conservative of course, it comes from a three-body potential after all. This means that the two-body A-B force plus the two-body B-C force is integrable. It's just that the A-C two body force is not. So the separation is completely silly.\n\nAbsence of multi-body interactions for macroscopic objects in empty space\n\nThe interactions of macroscopic objects are through contact forces, which are necessarily pairwise since all other contacts are far away, and electromagnetic and gravitational fields, which are very close to linear at these scales. The electromagnetic and gravitational forces end up being linearly additive between pairs, and the result is a potential of the form Landau and Lifschitz consider--- pairwise interactions which are individually rotationally invariant.\n\nBut for close packed atoms in a crystal, there is no reason to ignore 3-body potentials. It is certainly true that in the nucleus three-body and four-body potentials are necessary, but in both cases you are dealing with quantum systems.\n\nSo I don't think the third law is particularly fundamental. As a philosophical thing, that nothing can act without being acted upon, it's as valid as any other general principle. But as a mathematical statement of the nature of interactions between particles, it is completely dated. The fundamental things are the conservation of linear momentum, angular momentum, and center of mass, which are independent laws, derived from translation invariance, rotational invariance, and Galilean invariance respectively. The pair-wise forces acting along the separation direction are just an accident.\n\nshare|improve this answer\n\nWithin the framework of classical mechanics, the Newton's third law is an independent postulate.\n\nNewton's third law in its strong form says that not only are mutual forces of action and reaction equal and opposite between two bodies at position $\\vec{r}_1$ and $\\vec{r}_2$, they are also collinear, i.e. parallel to $\\vec{r}_2-\\vec{r}_1$.\n\nWhen we derive Lagrange equations from Newton's laws (see e.g. Herbert Goldstein, \"Classical Mechanics\", chapter 1), it may appear a bit hidden when we actually use Newton's third law.\n\nIn the derivation, we assume that forces of constraints do no virtual work$^{1}$. Consider now a rigid body. It's a fact that we rely heavily on Newton's third law in its strong form to argue that the internal forces of constraints (which hold the rigid body together) do no virtual work.\n\nSee also D'Alembert's principle and the principle of virtual work for more information.\n\n\n$^{1}$ This does not hold for, e.g., sliding friction forces, which we therefore have to exclude.\n\nshare|improve this answer\nHi, actually I am referring to the approach used by Landau in his Course of Theoretical Physics Volume 1 Mechanics. In it, he supposes a function Lagrange and uses symmetry and experimental facts to derive various properties of Lagrange and Newtonian Mechanics. Now, I would request you to view the question in above limelight and edit your answer as necessary. Yes, I agree, that Lagrange equations are derivable from newton's laws but I am talking about the approach of deriving Newton's Laws from Lagrangian Mechanics. Mathematically, both are equivalent formulations. \u2013\u00a0 Lakshya Bhardwaj Jul 10 '11 at 15:40\n@Lakshya Bhardwaj: Landau and Lifshitz, \"Mechanics\", starts on page 2 by assuming an action principle. However there are systems that have no action principle, e.g., systems with non-holonomic constraints. For this and other reasons, Newton's laws are more fundamental (within the framework of classical non-relativistic mechanics). \u2013\u00a0 Qmechanic Jul 10 '11 at 20:37\nThank you, I didn't know about the limitations of action principle. So, let's frame the question like this: Given that we talk only about systems which follow action principle and we start using Lagrange formalism to derive Newton's Laws.... read the question as rest. I would be very thankful to you if you would see the question in a mathematical framework which is not general and try to answer it in that system only. I am not interested in general answers as I have just started in Classical Mechanics. Please review the last paragraph of my question. Thank You. \u2013\u00a0 Lakshya Bhardwaj Jul 11 '11 at 11:04\n@Lakshya Bhardwaj: Well, if we start with a Lagrangian $L$ that (among its, in general, many terms) contains a potential term of the form $V(|\\vec{r}_2-\\vec{r}_1|)$, where $\\vec{r}_1$ and $\\vec{r}_2$ are the positions of two point particles, then it is straightforward to show that the corresponding forces between the two particles obey the strong Newton's third law. \u2013\u00a0 Qmechanic Jul 11 '11 at 16:45\nYes, it is Sir. But, I want to extend the case. My question is that if we take many particles, i.e. more than two. Can we definitely conclude theoretically that the internal forces would be equal and opposite between a pair of particles? Although my question is only about weak form, I would be interested in knowing the proof for strong form also. What you have indicated in your comment is for two particles. But for multi-particles we have to assume principle of superposition to establish Newton's third law in weak form. I want to ask, if that's derivable or is it experimental observation? \u2013\u00a0 Lakshya Bhardwaj Jul 12 '11 at 11:43\n\nIt might be a little crude, but doesn't time reversal symmetry help to prove this? I can't quite think of a rigorous proof, but it seems to me that the matrix Fij should be transposed somehow if you change t->-t.\n\nshare|improve this answer\nNice idea. But, forces aren't changed in time reversal. Can you please clarify how this would lead us to derive it? \u2013\u00a0 Lakshya Bhardwaj Jul 11 '11 at 11:11\nWhat you are saying is using isotropy of time. So, does that mean we need homogeneity of space and isotropy of time, i.e. two things? That's interesting. :) I am very much looking forward to your reply. \u2013\u00a0 Lakshya Bhardwaj Jul 11 '11 at 13:30\n\nOnce you got that the sum of all the forces is zero, why did you assume that the internal forces will have the same collinear direction (i.e. why would they be opposite along the same line. They can be along any direction as long as the sum is zero?) Also, you consider 2 particles; $\\vec{F_1}$+$\\vec{F_2}$=$0$ might give you an idea on how the forces behave. Generalise to 3 and more directions.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/1956/is-there-an-integral-that-proves-pi-333-106\nText:\nTake the 2-minute tour \u00d7\n\nThe following integral,\n\n$$ \\int_0^1 \\frac{x^4(1-x)^4}{x^2 + 1} \\mathrm{d}x = \\frac{22}{7} - \\pi $$\n\nis clearly positive, which proves that $\\pi < 22/7$.\n\nIs there a similar integral which proves $\\pi > 333/106$?\n\nshare|improve this question\nHey, how do you know that it is clearly positive? is there something about the integral that makes it positive? \u2013\u00a0 Tyler Hilton Aug 10 '10 at 20:01\nIf $f(x)>0$ then $$\\int\\limits_{a}^{0} f(x)>0$$ \u2013\u00a0 anonymous Aug 10 '10 at 20:06\n@Affan, you're integrating a fraction of even powers: it can't be negative. \u2013\u00a0 Andrea Ambu Aug 11 '10 at 7:13\nYou can use $\\pi = \\int_0^1 \\frac{4}{1+x^2}$. Now the power series of $\\frac{4}{1+x^2}$ is alternating, thus stopping after odd/even numbers of terms gives under and overevaluations. Thus, for all $a< \\pi <b$ you can find $m, n$ so that $a< \\int_0^1 P_m(x) dx < \\pi < \\int_0^1 P_n(x) < b$, where $P_n$ denotes a Taylor Polynomial. \u2013\u00a0 N. S. Aug 3 '12 at 13:25\nadd comment\n\n3 Answers\n\nup vote 57 down vote accepted\n\nThis integral would do the job:\n\n$$\\int_0^1 \\frac{x^5(1-x)^6(197+462x^2)}{530(1+x^2)}= \\pi -\\frac{333}{106}$$\n\n  \u2022 Also you can refer to S.K. Lucas Integral proofs that $355/113 > \\pi$, Gazette, Aust. Math. Soc. 32 (2005), 263-266.\n\n  \u2022 This is the link. (Thanks to lhf for pointing out.)\n\nshare|improve this answer\nGreat! I had not expected anyone to answer this so quickly! \u2013\u00a0 anon Aug 9 '10 at 21:10\nHow does one come up with that integral, may I ask? \u2013\u00a0 ShreevatsaR Aug 9 '10 at 21:33\nmath.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf Please read this article \u2013\u00a0 anonymous Aug 9 '10 at 21:38\nThe link above is broken. The current one is educ.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf \u2013\u00a0 lhf Jun 10 '11 at 19:05\n@lhf: Thanks for the link. \u2013\u00a0 user9413 Jun 10 '11 at 19:09\nadd comment\n\nAlthough this is not exactly an answer to the question, it seems sufficiently related to mention: there are some direct generalizations, given on the Wikipedia page about this integral. For instance, $$0 < \\frac14\\int_0^1\\frac{x^8(1-x)^8}{1+x^2}\\ dx=\\pi -\\frac{47171}{15015}$$\n\nIn general, $$\\frac1{2^{2n-1}}\\int_0^1 x^{4n}(1-x)^{4n}\\ dx <\\frac1{2^{2n-2}}\\int_0^1\\frac{x^{4n}(1-x)^{4n}}{1+x^2}\\ dx <\\frac1{2^{2n-2}}\\int_0^1 x^{4n}(1-x)^{4n}\\ dx$$\n\nwhich for $n=1$ (the integral in the question) gives slightly better bounds than just $\\pi < 22/7$: $$ \\frac{1}{1260} < \\frac{22}{7} - \\pi < \\frac{1}{630}$$\n\nshare|improve this answer\nThank you! Doesn't that imply that pi is irrational? \u2013\u00a0 anon Aug 9 '10 at 21:17\n@muad: Without checking the asymptotics of the respective numerators and denominators, I'm not sure. It doesn't follow simply from the fact that the left and right expressions go to 0: for instance 1 is rational, but you could still find sequences of rational numbers $x_n, y_n, z_n$ such that $x_n$ and $y_n$ go to 0, but $x_n < 1 - z_n < y_n$ for all $n$. \u2013\u00a0 ShreevatsaR Aug 9 '10 at 21:31\n@anon For this to work, you'd have to show that the rational approximants converged suitably fast. See Dirichlet's irrationality test. \u2013\u00a0 A Walker Oct 19 '11 at 6:23\nadd comment\n\nIn the beginning of 2009 I was posting re similar issue at several sites, namely, at sci.math.symbolic, www.math.utexas.edu, etc.\n\nTo repeat: In Paper 1 Lucas found, by brute-force search using Maple programming, several different variants of integral identities which relate each of several first Pi convergents (described in terms of OEIS sequences as A002485(n)/A002486(n)) to Pi.\n\nFurther, in my above-mentioned postings, I conjectured the following identity below, which represents a generalization of Stephen Lucas' experimentally obtained identities between Pi and its convergents:\n\n$$(-1)^n\\cdot(\\pi - \\text{A002485}(n)/\\text{A002486}(n))$$\n\n$$=(|i|\\cdot2^j)^{-1} \\int_0^1 \\big(x^l(1-x)^m(k+(i+k)x^2)\\big)/(1+x^2)\\; dx$$\n\nwhere integer n = 0,1,2,3,... serves as index for terms in OEIS A002485(n) and A002486(n), and {i, j, k, l, m} are some integers (to be found experimentally or otherwise), which are probably some functions of n.\n\nThe \"interesting\" (I think) part of my generalization conjecture is that \"i\" is present in both:\n\ndenominator of the coefficient in front of the integral and in the body of the integral itself\n\nFor example, in cited by Lucas old known formula for 22/7\n\n22/7 - Pi = Int(x^4*(1-x)^4*/(1+x^2),x = 0 .. 1)\n\nn=3, i=-1, j=0, k=1, l=4, m=4\n\nIn Lucas's formula for 333/106 (mentioned above in the comment by Chandrasekhar)\n\nPi - 333/106 = 1/530*Int(x^5*(1-x)^6*(197+462*x^2)/(1+x^2),x = 0 .. 1)\n\nn=4, i=265, j=1, k=197, l=5, m=6\n\nIn Lucas's formula for 355/113\n\n355/113 - Pi = 1/3164*Int(x^8*(1-x)^8*(25+816*x^2)/(1+x^2),x = 0 .. 1)\n\nn=5, i=791, j=2, k=25, l=8, m=8\n\nIn Lucas's formula for 103993/33102\n\nPi - 103993/33102 = 1/75521*Int(x^14*(1-x)^12*(124360-77159*x^2)/(1+x^2),x = 0 .. 1)\n\nn=6, i= 47201, j=4, k=77159, l=14, m=12\n\nIn Lucas's formula for 104348/33215\n\n104348/33215 - Pi = 1/38544*Int(x^12*(1-x)^12*(1349-1060*x^2)/(1+x^2),x = 0 .. 1)\n\nn=7, i= -2409, j=4, k=1349, l=12, m=12\n\nI do not have computer math resources (Mathematica, Maple, etc.) to experimentally prove or disprove it for all larger n (but see my comment below).\n\nBest Regards, Alexander R. Povolotsky\n\nshare|improve this answer\nOne also could check and see that my above generalization formula also applies to identities obtained by Jaume Oliver Lafont, described in the \"Following Lucas (2009)\" section in oeis.org/wiki/User:Jaume_Oliver_Lafont/\u2026 \u2013\u00a0 Alex Apr 8 '12 at 21:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/240803/how-do-i-subtract-times/240808\nText:\nTake the 2-minute tour \u00d7\n\nI have an embarrassingly basic modular arithmetic question. I understand that I can subtract, for example, 1 hour from 10 o'clock to get 9 o'clock, or even 2 hours from 1 o'clock to get 11 o'clock; but how do I subtract 2 o'clock from 11 o'clock to get 3 hours.\n\nThat is, I want a function that takes two times on the face of a clock, and gives me the interval between them.\n\nFor example: I have two angular values measured in \"hours\". One value is the right ascension of the apparent sun, $\\alpha(t)$, while the other is the right ascension of the \"mean sun\", $\\langle\\alpha\\rangle(t)$; both are mod 24. I'm interested in the angular difference between these two values $$E(t) = \\langle\\alpha\\rangle(t) - \\alpha(t)$$ Is this just inherently ambiguous, so that I need to impose some additional constraint based on information about the system (e.g., here that the values can be positive or negative, and are always small, so that, say $\\pm 22$ should be interpreted as $\\mp 2$), or is there some simple systematic way to esnure that I get the correct values?\n\nshare|improve this question\nmath.stackexchange.com/questions/388361/\u2026 check this answer \u2013\u00a0 iostream007 May 11 '13 at 16:50\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nJust subtract. Your answer will only be well-defined mod 12 (because maybe 15 hours passed between 11 and 2 o clock). If you want a \"canonical\" answer, you can always take the least residue mod 12. In this case, we get $(2 - 11) = -9 = 3.$\n\nIn fancy language, the times on a clock are a torsor for $\\frac{\\mathbb{Z}}{12}$. John Baez has a great blog entry on this.\n\nshare|improve this answer\n@Jean-S\u00e9bastien: I've added an example of my application to make things a bit more concrete. \u2013\u00a0 raxacoricofallapatorius Nov 19 '12 at 20:01\nadd comment\n\n2 o'clock - 11 o'clock = -9 = 3 mod 12 ?\n\nshare|improve this answer\nadd comment\n\n$$ 2-11=-9\\equiv 3 \\mod 12 $$ you can take the absolute value of that, or work with the $24$ hours format and use the fact that $2$ is also $14$ and then have $$ 14-11=3 $$\n\nshare|improve this answer\nI think I need a nap... :-S \u2013\u00a0 amWhy Nov 19 '12 at 19:17\n@amWhy you only needed to add the fact that we work mod $12$ \u2013\u00a0 Jean-S\u00e9bastien Nov 19 '12 at 19:17\nI saw that others already covered that...I knew what I was thinking, but that's hardly the same as being clear and explicit in the first place! (+1) by the way! \u2013\u00a0 amWhy Nov 19 '12 at 19:36\n@amWhy I'd be down for a nap as well, great idea ;). I like the 24 hours format for that kind of thing. Obviously you could argue that the problem comes back if you want ot know the time difference between say $23$ hours and $2$ but that is equivalent to $11$ and $14$ anywya so \u2013\u00a0 Jean-S\u00e9bastien Nov 19 '12 at 19:46\nadd comment\n\nIf you just have times with no dates attached, you can't tell +2 from -22. You can choose to have the result be in the range $[-12,+12)$ or any other range of length $24$ like $(-5,19]$ that you like. Based on what you day, I would opt for one centered at zero.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/372638/100-sided-die-probability/372644\nText:\nTake the 2-minute tour \u00d7\n\nThe question is as follows: You are given a 100-sided die. After you roll once, you can choose to either get paid the dollar amount of that roll OR pay one dollar for one more roll. What is the expected value of the game? There is no limit on number of rolls.\n\nThe EV for a 100-sided die roll is 50.5, but the fact that you can pay a dollar for an extra roll complicates things. Not quite sure how to proceed.\n\nshare|improve this question\nUnless I'm misreading the question, the EV should be infinite. The WORST you can do is an infinite string of {1}s, with probability 0, in which case you end up with $0. However, EVERY other roll you get nets you money. \u2013\u00a0 Foo Barrigno Apr 25 '13 at 17:07\n@FooBarrigno No, the payout is the last value you rolled, not the sum. \u2013\u00a0 gt6989b Apr 25 '13 at 17:10\nwouldn't it just be 50? Your EV of the first roll is 50.5 and your EV of the second roll is 49.5 since you've paid a dollar. This problem also has the constraint that you can choose to roll again or keep your money, so doesn't that play in to calculating this stuff? \u2013\u00a0 Eleven-Eleven Apr 25 '13 at 17:23\n@gr6968b Ah, that clears it up then. I'm not sure how I missed the words \"that roll\" in the problem statement. \u2013\u00a0 Foo Barrigno Apr 26 '13 at 18:00\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nIf the expected value of this game is $a$, then at a die roll of $X$ you have the choice of either collecting $X$ or paying a dollar and restart, which gives you an expected value of $a-1$. To maximize the expected value, you should take $X$ if $X> a-1$ and start over if $X\\le a-1$ (it does not really matter what we do when $X=a-1$). We obtain therefore $$ a = \\frac1{100}\\left(\\lfloor a-1\\rfloor\\cdot a+\\sum_{k=\\lfloor a-1\\rfloor+1}^{100}k\\right) =\\frac1{100}\\left(\\lfloor a-1\\rfloor\\cdot a+\\frac{100\\cdot101}{2}-\\frac{\\lfloor a-1\\rfloor \\cdot\\lfloor a\\rfloor}{2}\\right). $$ I find numerically (didn't do much code checking, but the results are somewhat plausible) $$a\\approx87.3571 $$ which seems to be exactly (and of course the true result must be rational) $$a=87\\frac{5}{14}.$$ But I'm sure you can do the justification after the fact, i.e. show that the strategy that consists in continuing until you roll at least $87$ gives you $87\\frac{5}{14}$ as expected value.\n\nFor your convenience, here is the PARI one-liner:\n\n\nIf an extra roll costs two dollars instead of one, the result would be $$a=82\\frac12$$ instead, and with a cost of only $0.1$ dollars it would be $$a=96\\frac1{10}.$$\n\nshare|improve this answer\nI get an expected value of 1135/13 = 87.30... for the strategy \"Roll until you get higher than 87\" and an expected value of 1223/14 = 87.35... for the strategy \"Roll until you get higher than 86\". This seems to be the best strategy. \u2013\u00a0 Charles Apr 25 '13 at 17:55\nadd comment\n\n\nIf your value now is $X_t$, what is the marginal value of the roll? If you roll $R \\sim \\mathcal{U}[1,100]$, then if $R > X_t+1$ you gained and if $R \\leq X_t+1$, you either lost or became indifferent. So what is the marginal value?\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/106571/a-space-in-which-sequences-have-unique-limits-but-compact-sets-need-not-be-close?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nA topological space is KC if every compact subspace is closed. A topological space is US if every convergent sequences has exactly one limit. Does someone know an easy example of a US space which is not KC? Thanks.\n\nshare|improve this question\nThese terms happen to both 1) be terrible search terms and 2) have unguessable meanings if you're not familiar with them, so you might want to include definitions. \u2013\u00a0 Qiaochu Yuan Sep 7 '12 at 5:28\nSorry, I edit to include definitions. \u2013\u00a0 Pedro Perez Sep 7 '12 at 6:15\nTake the finite complement topology on any infinite set. \u2013\u00a0 Evan Jenkins Sep 7 '12 at 6:39\nThat space is not US. \u2013\u00a0 Pedro Perez Sep 7 '12 at 7:53\nBy the way, what do KC and US stand for? I imagine KC means \"kompact closed\", but US is puzzling me. (\"unique sequence\"?) \u2013\u00a0 Henry Cohn Sep 7 '12 at 12:32\nshow 1 more comment\n\n3 Answers\n\nTo create a counterexample X, start with the closed interval [0,1] (with the usual topology) and attach a new point z whose neighborhoods are open dense subsets of [0,1].\n\nObserve [0,1] is a compact nonclosed subspace of X and thus X is not a KC space. However no sequence in [0,1] converges to z and in particular all convergent sequences in X have unique limits.\n\nThe finite complement topology on an infinite set does not yield a counterexample since every infinite sequence converges to every point of the space.\n\nIn general no counterexample Y can be a sequential space since if Y is a sequential space then Y is a KC space iff Y is a US space. ( Recall Y is a sequential space if every nonclosed set B contains a convergent sequence whose limit lies outside B).\n\nshare|improve this answer\nadd comment\n\nStart with the one point compactification of the minimal uncountable well ordered space and then split the maximum point into two points.\n\nshare|improve this answer\nadd comment\n\nI refer to COROLLARY 1 of This Article.\n\nIn COROLLARY 1 of it, $X^+$ denotes the one point compactification of the topological space $X$:\n\nCOROLLARY: Let $X$ be a Hausdorff space.Then:\n\n(a) $X^+$ is always $US$.\n\n(b) $X^+$ is $KC$ if and only if $X$ is a $\\kappa$ space.\n\nSo it suffices to choose a Hausdorff space $X$, which is not $\\kappa$ space. then $X^+$ is $US$ but is not $KC$.\n\nPS: The topological space $X$ is called $\\kappa$ space, if A subspace $A$ is closed in $X$ if and only if $A \\cap K$ is closed in $K$, for all compact subset $K \\subset X$.\n\nshare|improve this answer\n+1 for the link. Theorem 1 says: $T_2 \\implies KC \\implies US \\implies T_1$ and none of the implications reverses even for compact spaces. \u2013\u00a0 Ramiro de la Vega Sep 7 '12 at 14:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/27524/fair-value-of-a-hat-drawing-game\nText:\nTell me more \u00d7\n\nI've been going through a problem solving book, and I'm a little stumped on the following question:\n\nAt each round, draw a number 1-100 out of a hat (and replace the number after you draw). You can play as many rounds as you want, and the last number you draw is the number of dollars you win, but each round costs an extra $1. What is a fair value to charge for entering this game?\n\nOne thought I had was to suppose I only have N rounds, instead of an unlimited number. (I'd then let N approach infinity.) Then my expected payoff at the Nth round is (Expected number I draw - N) = 50.5 - N. So if I draw a number d at the (N-1)th round, my current payoff would be d - (N-1), so I should redraw if d - (N-1) < 50.5 - N, i.e., if d < 49.5. So my expected payoff at the (N-1)th round is 49(50.5-N) + 1/100*[(50 - (N-1)) + (51 - (N-1)) + ... + (100 - (N-1))] = 62.995 - N (if I did my calculations correctly), and so on.\n\nThe problem is that this gets messy, so I think I'm doing something wrong. Any hints/suggestions to the right approach?\n\nshare|improve this question\ncan you share which book you found this problem? thanks. \u2013\u00a0 Qiang Li Mar 17 '11 at 21:18\nadd comment\n\n3 Answers\n\nConsider what happens in the first stage. You get a number out of the hat, and either stop or go on. And you do it in some \"optimal\" way (maximizes expectation). If you do go on, the rule that will ensure you the maximal expectation is the same rule you used before - your original optimal rule.\n\nThis shows that your stopping rule can be characterized by some threshold $X$, which is the minimal number for which you'd stop (alternatively we could have chosen $X-1$, which is the maximal number for which you'd go on). Denote the expected gain by $E$. We have $$ E = -1 + \\frac{X-1}{100}E + \\frac{\\sum_{t=X}^{100} t}{100} = -1 + \\frac{X-1}{100} + \\frac{(100-X+1)(100+X)}{200}. $$ Multiplying by $200$ and rearranging, we get $$ 2(101-X)E = (101-X)(100+X) - 200. $$ Therefore $$ E = \\frac{(101-X)(100+X) - 200}{2(101-X)}. $$ This is maximized by $101 - 10\\sqrt{2} \\approx 86.86$. Thus the best value for $X$ is either $86$ or $87$. These values give $E \\approx 86.33$ and $E \\approx 86.37$, so $X = 87$ is better, and the value of the game is $1209/14$.\n\nMy calculations don't agree with Ross's, so there's probably a mistake somewhere; this doesn't invalidate the method.\n\nshare|improve this answer\nOur philosophies are the same. I think the difference is the factor $\\frac{100\u2212\u230aR\u230b}{100}$ in my first term, which is the chance that the next draw will be accepted. I think that should multiply your third term, which is the $\\frac{100+\u230aR\u230b}{2}$ part. I just edited my subtraction of the cost of another play, which decreased the expected value by 1. It appears it \"wants\" the expected value to be just below a natural. \u2013\u00a0 Ross Millikan Mar 17 '11 at 6:12\nadd comment\n\nYour expected return if you draw a number on the last round is 49.5 (because it costs a dollar to make the draw). On round N-1, you should keep what you have if it is greater than 49.5, or take your chances if it is less. The expected value if N=2 is then $\\frac {51}{100}\\frac {100+50}{2} -1 + \\frac {49}{100}49.5=61.505$ where the first term is the chance that you keep the first draw times the expectation of that draw (assuming you will keep it), the second is the cost of the first draw, and the third is the chance that you will decline the first draw and take your chances on the second times the expectation of the second draw.\n\nAdded: As Yuval makes more explicit, your strategy will be to quit when you get a number at least $X$. The gain then is $\\frac{100+X}{2}-\\frac{100}{101-X}$ where the first is the payoff and the second is the cost of the expected number of plays. As he says, this is maximized at X=87 with value $\\frac{1209}{14}=86.3571$. I'll have to think where I was a bit off.\n\nshare|improve this answer\nadd comment\n\nEdit: I've added some information about the game with a restricted number $N$ of rounds, since the OP mentioned this.\n\nJust a comment to complement the nice answers we have already.\n\nThere is an algorithm that calculates the optimal strategy and the value of each state for such an optimal stopping problem.\n\nLet $f(x)$ be the payout at each state $x\\in {\\cal S}$ for the underlying Markov chain $(X_n)$, and let $g(x)$ be the cost of leaving state $x$.\n\nSet $u_0=f$ and for $N\\geq 1$ put $u_N=\\max(Pu_{N-1}-g,f)$. Here $P$ is the transition matrix of the Markov chain. Then $u_N$ is the value function for the restricted game with at most $N$ rounds; that is, $$u_N(x)=\\sup_{T\\leq N}\\ \\mathbb{E}\\left[ f(X_T)\\, | \\, X_0=x\\right],$$ where the supremum is over all stopping times $T$ that satisfy $T\\leq N$.\n\nAs $N\\to\\infty$, we get $u_N\\uparrow v$ where $v$ is the value function for the unrestricted game. The optimal strategy is to stop when the chain hits the set $\\lbrace x: f(x)=v(x)\\rbrace$. Here $v(x)$ means the value of state $x$, i.e., $v(x)$ is the maximum expected payout starting in state $x$ and using any finite stopping time $T$ as a strategy:\n\n$$v(x)=\\sup_T\\ \\mathbb{E}\\left[ f(X_T)\\, | \\, X_0=x\\right].$$\n\nThis is all nicely explained in the section on Optimal Stopping in Gregory Lawler's book \"Introduction to Stochastic Processes\".\n\nIn your problem we have $f(x)=x$ for $1\\leq x\\leq 100$, and $g(x)\\equiv 1$. Your Markov chain $(X_n)$ is a sequence of independent, uniform $\\lbrace 1,2,\\dots, 100\\rbrace $ random variables. Thus the $P$ operator applied to $h$ gives the constant function whose value is the average value of $h$, that is, $Ph(x)\\equiv \\sum_{i=1}^{100} h(i)/100$. So we calculate $$u_0(x)=x,\\quad u_1(x)=\\max\\left(x,{99\\over 2}\\right), \\quad u_2(x)=\\max\\left(x,{12301\\over 200}\\right). $$\n\nTaking very large $N$ gives $$v(x)\\approx \\max\\left(x,{86.35714}\\right),$$ which shows that the optimal strategy (over all finite stopping times!) is to quit as soon as we get $87$ or higher, and the value of the game is $86.35714$ dollars.\n\nIn your problem it is pretty straightforward to calculate the exact answer, but this algorithm also gives the answer for more complicated games where exact calculations are not so easy.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/62426/generating-bernoulli-correlated-random-variables-with-space-decaying-correlation\nText:\nTell me more \u00d7\n\n\nI have a set of N objects randomly distributed in a 2D physical space. Each object (i) generates a bernoulli random number (0 or 1) based on a marginal probability Pr(xi = 1) = p. These objects a correlated by physical distance. The closer the objects are, the larger their correlation is.\n\nE.g. If objects i and j are co-located, they are expected to generate correlated results. For Example, if P(Xi=1)= 0.6 and P(Xj=1)=0.3 they would produce something like:\n\nXi= 0 1 0 1 1 1 0 1 0 1\n\nXj= 0 1 0 0 0 1 0 1 0 0\n\nSuch that Pr(Xi|Xj)=1\n\nOn the other hand if i and j are distant they would produce uncorrelated results such that Pr(Xi|Xj)=Pr(Xi)\n\nI have tried to use some of the packages in Matlab (Sampling from multivariate correlated binary and poisson random variables) and R (bindata) but I could not produce an acceptable correlation matrix.\n\nAny ideas how I can produce an acceptable correlation matrix?\n\nBTW, I have checked the following earlier posts discrete stochastic process: exponentially correlated Bernoulli?\n\n\nConstructing Bernoulli random variables with prescribed correlation\n\nBut I am not sure how I can relate to them.\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHere's a suggestion:\n\nDefine a non-negative decreasing function $w(r)$ measuring interaction strength. Given each object its own independent $N(0,1)$ random variable $N_i$. Now set $$ Y_i=\\frac{\\sum_{j}w(\\|x_i-x_j\\|)N_j}{\\sqrt{\\sum_j w(\\|x_i-x_j\\|)^2}}, $$ where $x_i$ denotes the location of the $i$th object.\n\nThen the $Y_i$ are correlated $N(0,1)$ random variables. If two objects are co-located the normal random variables agree.\n\nFinally set $t_i=\\Phi^{-1}(p_i)$ (i.e. $\\mathbb P(N < t_i)=p_i$) and set $X_i=1$ if $Y_i < p_i$ and 0 otherwise.\n\nWith this setup you can write down the covariance of $Y_i$ and $Y_k$ explicitly: it's just $$ \\text{Cov}(Y_i,Y_k)=\\frac{\\sum_j w(\\|x_i-x_j\\|)w(\\|x_k-x_j\\|)} {\\sqrt{\\sum_j w(\\|x_i-x_j\\|)^2\\sum_j w(\\|x_k-x_j\\|)^2}}. $$\n\nIf you write this as $\\cos\\theta_{ik}$ then you can write the covariance of $X_i$ and $X_k$ as an integral: $$ 1/(2\\pi)\\int_{ x < t_1\\;,\\; cos\\theta_{ik}x+\\sin\\theta_{ik}y < t_2} e^{-(x^2+y^2)/2}\\,dxdy-p_ip_k. $$\n\nshare|improve this answer\nIf i understood you correctly, what you are saying is to simply use the Cov(Yi,Yk) above as the covariance matrix and plug it in the bernoulli generator. If so, then Unfortunately, I tried that but I keep getting an Unacceptable correlation matrix, which seams to be not positive definite. \u2013\u00a0 alandalusi Apr 26 '11 at 21:44\nNo you didn't understand me correctly. Here is my concrete suggestion. (1) Compute $t_i=\\Phi^{-1}(p_i)$; (2) Compute the matrix $Cov(Y_i,Y_k)$ as above (3) Use a multivariate normal generator to build some $Y_i$'s. (4) Set $X_i=1$ if $Y_i<t_i$ and 0 otherwise. You could compute the covariance of the Bernoulli's (using the nasty integral formula I wrote down), but if your purpose is to just generate the random #s, then the procedure I described will work just as well. \u2013\u00a0 Anthony Quas Apr 26 '11 at 22:59\nAcually, It is positive definite, but does not have a dichotomized Gaussian distribution for the correlation matrix. \u2013\u00a0 alandalusi Apr 26 '11 at 23:03\nOK, I think I understand your suggestion now. I will test it right away. \u2013\u00a0 alandalusi Apr 26 '11 at 23:32\nIt works!, but I noticed that the Correlation (or Conditional Probabilities) $Pr(X{_i}=1|X{_k}=1)$ between any fixed pair (i and k) slightly change as we add more objects into the physical space. So, I changed $Cov(Y{_i},Y{_k})$ to be $w(||x{_i}-x{_k}||)$ and it worked with fixed conditional probabilities, even if I add more objects. I am still testing it, but does this make sense to you? For your information, my distance functions is $e^{(-\\frac{eucaliandistance}{dcorr})}$ \u2013\u00a0 alandalusi Apr 27 '11 at 16:33\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/346134/packing-radios-into-cartons-why-is-my-solution-wrong/346141\nText:\nTake the 2-minute tour \u00d7\n\nA manufacturer of car radios ships them to retailers in cartons of $n$ radios. The profit per radio is $\\$59.50$, minus shipping cost of $\\$25$ per carton, so the profit is $59.5n-25$ dollars per carton. To promote sales by assuring high quality, the manufacturer promises to pay the retailer $\\$200X^2$ if $X$ radios in the carton are defective. Suppose radios are produced independently and that $5\\%$ of radios are defective. How many radios should be packed per carton to maximize expected net profit per carton?\n\nMy solution:\n\nSuppose that $n$ radios are packed into a carton. Then, the expected profit is clearly $$\\mu = 59.5n-25-200(0.05n)^2$$ Simplifying we get $$\\mu = 59.5n-25-0.5n^2$$\n\nWe want to find a maximum, so we find a derivative:\n\n\nClearly there is just one maximum, so set $\\mu'=0$ we find that $$n^2=59.5$$ and thus $$n\\approx 7.7136\\dots$$This however seems to be wrong. The textbook gives an answer of exactly $50$ in the solution without any explanation of the steps.\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\n$X$ is binomially distributed with $n$ trials and success probability $0.05$. For any random variable $X$ whose mean and variance exist, \\begin{eqnarray*} {\\Bbb E}X^2&=&({\\Bbb E}X)^2+\\text{Var } X, \\end{eqnarray*} and since the mean and variance of a binomial distribution with $n$ trials and success probability $p$ are $np$ and $np(1-p)$, in this case this equals \\begin{eqnarray*} &&(0.05 n)^2+n\\cdot 0.05 \\cdot (1-0.05)\\\\ &=& 0.0025 n^2+0.0475 n \\end{eqnarray*} and the expected profit is \\begin{eqnarray*} &\\ &59.5n-25-200{\\Bbb E}X^2\\\\ &=&59.5n-25-0.5n^2-9.5n\\\\ &=&1225-\\frac 12 (n-50)^2, \\end{eqnarray*} which is maximized at $n=50$.\n\nshare|improve this answer\nadd comment\n\nThe expected loss isn't just $(0.05n)^2$, you must compute its average the hard way ($\\mathbb{E}(x^2) \\ne (\\mathbb{E}(x))^2$ in general!). If the probability of $n$ ones broken is $p_n$, your expected loss due to breakage is $$ \\sum_{n \\ge 0} p_n \\cdot 200 n^2 = 200 \\sum_{n \\ge 0} p_n n^2 $$ Presumably you can start assuming that the number of radios in each box isn't limited, that should give a starting point. Once you have an approximate number of radios per box, refine.\n\nshare|improve this answer\nadd comment\n\nThe profit $Y$ is given by $$Y=59.5n -25-200 X^2,$$ where $X$ is the number of defectives.\n\nThe number of defectives has binomial distribution, with $p=0.05$.\n\nWe want to find $E(X^2)$. There are various ways to do this. One way is to recall that the relevant binomial has mean $np$ and variance $np(1-p)$. But the variance of $X$ is $E(X^2)-(E(X))^2. So E(X^2)=np(1-p) +n^2p^2$.\n\nThere are various other ways to find $E(X^2)$.\n\nSo we are maximizing $59.5n-25-200np(1-p)-200n^2p^2$, which in this case is $-(0.5n^2 -50n +25)$.\n\nFor the maximization, complete the square, or use calculus.\n\nThe answer does turn out to be exactly $50$.\n\nRemark: You asked why your answer was wrong. One way was uninteresting. You differentiated $59.5n-0.5n^2$ and got $59.5-n^2$ instead of the correct $59.5-n$.\n\nThat would have given an answer of $59.5$, say $60$-ish.\n\nThe actual answer is less, and for an interesting reason. The penalty for bad radios is $200X^2$. This is quite sensitive to large values of $X$. Roughly speaking that explains why the optimal number of radios is smaller than the $59.5$ given by your method.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/114879/an-optimization-problem-non-complete-bipartite-graph-and-hungarian-algorithm/114954\nText:\nTake the 2-minute tour \u00d7\n\nI have two tables at my disposal, one work dataset and one reference dataset. Each dataset has got two columns, lets say these are fields A and B. I would like the rows in reference dataset with the rows in work dataset that are 'closest' w.r.t. some distance. I have more rows in work dataset than in reference dataset, and i will match all rows in reference dataset to some rows in work dataset.\n\nI can define distance between two rows in reference and wrk dataset like this:\n\n$ d_{i,j} = (A_{w}(i) - A_{r}(j))^{2} + (B_{w}(i) - B_{r}(j))^{2} $\n\nwith $A_{w}, A_{r}, B_{w}, B_{r} $ the A and B columns work and reference datasets with obvious notation.\n\nIn other word, i want to minimize over all permutations of rows from the work dataset (with the same number of rows as in reference dataset) the sum of distances between one row in reference dataset and one row in wrk dataset.\n\nI do not know how to proceed if not examining all permutations.\n\nThis is combinatorial problem. What about stochastic methods: genetic algorithm, swarm...\n\nCould you hint at some idea for a start ?\n\nI had a look at linear assignment problem. However, my problem is not a complete bipartatite graph representation, it is not complete since there can be more peaks in work signal than there are in reference signal.\n\nThanks !\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's a standard trick to convert the min cost matching problem on a balanced bipartite graph to one on an unbalanced bipartite graph. Let $G = (X \\cup Y, E, w)$ be the bipartite graph where $E \\subset X \\times Y$ and $|X| \\le |Y|$.\n\nNow create a copy of $G$ and add it \"reversed\", so that in the new graph both sides have exactly $|X| + |Y|$ vertices. All old edges have their same weight: edges between vertices in $X$ and their copies have weight $\\infty$, and edges between vertices in $Y$ and their copies have weight zero.\n\nNow run the usual algorithm, and the solution will have cost exactly twice the unbalanced cost.\n\np.s the fact that the graph is not complete is irrelevant - you can always pretend that there are dummy edges with infinite weight.\n\nWhile the above method works, it's inefficient. there's a recent (2012) paper by Ramshaw and Tarjan on exactly this problem.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/133782/existence-of-non-trivial-solution-to-non-linear-polynomial-system\nText:\nTake the 2-minute tour \u00d7\n\nI need to find conditions for the existence of non-trivial solutions to a multivariable polynomial system in two cases:\n\nThe first case:\n\n$f1: a_1x^2+a_2xy+a_3y^2+a_4z^2=0$\n\n$f2: b_1x^2+b_2xy+b_3y^2+b_4z^2=0$\n\nThe second case:\n\n$f3: a_1x^2+a_2xy+a_3y^2+a_3z^2+a_5xz=0$\n\n$f4: b_1x^2+b_2xy+b_3y^2+b_3z^2+b_5xz=0$\n\n(note that the coefficient of y2 and z2 are equal)\n\nAll the coefficient are reals number and the variable x,y,z should be real too.\n\nI tried to use resultant and eliminating one variable, for even a more simple case:\n\n$f5: a_1x^2+a_2xy+a_3y^2+a_3z^2=0$\n\n$f6: b_1x^2+b_2xy+b_3y^2+b_3z^2=0$\n\nThe problem that i get different solution:\n\n1: if I try to eliminate $z$, I get $RES(f5,f6,z)=x^2[(a_2c_1\u2212a_1c_2)x+2(b_2c_1\u2212b_1c_2)y]^2$ So there is always non trivial (x\u22600 or y\u22600) real x,y such that RES(f5,f6,z)=0\n\n2: On the other hand if I eliminte $x$ I get: $ \\small RES(f5,f6,x)=[(a_2c_1\u2212a_1c_2)^2+4(a_2b_1\u2212a_1b_2)(b_2c_1\u2212b_1c_2)]x^4+4(b_2c_1\u2212b_1c_2)^2x^2z^2$\n\nthus a non-trivial solution exist only if $(a_2c_1\u2212a_1c_2)^2+4(a_2b_1\u2212a_1b_2)(b_2c_1\u2212b_1c_2)\u22640$.\n\nI tried to check this numerically and it seems like the second condition is the right one, so why the first attempt eliminating z is wrong?\n\nAny help will be appreciated\n\nshare|improve this question\nYour equations define conics in $\\mathbb{P}^2$, so you always have solutions, at least over an algebraically closed field. In general you will find $4$ points, but it could be less in particular cases if the curves intersect with tangency. If you want to work over the field of reals (which seems to be because of inequalities), then your first conic need to have at least one point, in which case it is rational, so you can parametrise and obtain a polynomial in degree $4$. \u2013\u00a0 J\u00e9r\u00e9my Blanc Jun 14 '13 at 20:11\nI didn't unerstand- why the first conic must have one rational point and how can I parametrise it. Can you please give an example? \u2013\u00a0 user34985 Jun 16 '13 at 18:47\nadd comment\n\n2 Answers\n\nUsing Groebner bases (or even direct computing) we see, that the solutions of your system $f_5=f_6=0$ are as follows:\n\nCase 1: $a_1b_2-a_2b_1=0$. Then it follows $y^2+z^2=0$. Over the real numbers this means $y=z=0$, and $a_1x=b_1x=0$. For $a_1=b_1=0$ we have always a solution with $x\\neq 0$.\n\nCase 2: $a_1b_2-a_2b_1\\neq 0$. Then we obtain either $y=0$ and $x=z=0$, or if $y\\neq 0$, then $$ x=\\frac{(a_3b_1-a_1b_3)(y^2+z^2)}{(a_1b_2-a_2b_1)y}, $$\n\nand $ry^2+sz^2=0$ with $$ r:= a_1^2b_3^2 - a_1a_2b_2b_3 - 2a_1a_3b_1b_3 + a_1a_3b_2^2 + a_2^2b_1b_3 - a_2a_3b_1b_2 + a_3^2b_1^2 $$ and $$ s:= (a_1b_3 - a_3b_1)^2. $$ Here you have the case 2, i.e., either $y=z=0$ again (we have required $y\\neq 0$, so this was solved earlier), or some non-trivial solution. The other systems can be solved too, using Groebner bases.\n\nshare|improve this answer\nadd comment\n\nthank you very much!!\n\nI am not familiar with the Groebner bases so I have a few more questions:\n\n  1. As far as I understood, Groebner bases give me a new set of equations, which theirs solution is exactly as the original equations. This is always true? is there any restrictions on the coefficient?\n  2. I see that (using computer software such as 'mathematica') for each ordering of the variable i get different bases. Can I just choose any order which will give me easiest set of equation?\n  3. If I choose an ordering (let say $x>y>z$) and get a condition, let's say about $x$ (as in the example). Is it possible to substitute it in the original equations, and get a new Groebner bases using different order of the variable (for exmple $z>x>y$)? Can I solve directly the original equations without using Groebner bases (after substitute $x$)?\n  4. Is there any recommended book about Groebner bases? I am not a mathematician so I don't familiar with all the terminology such as Ideal? A book with full examples solution will be the best one for me.\n  5. Is there a way to utilize the fact that my equations are quadratic forms? I know that for two equations with two variables, the Sylvester matrix give an immediate solution. I also found that there are known result for three quadratic equations with three variable (using resultant). Isn't any general result for any two homogeneous equations with three variable??\n\nThanks a lot,\n\nshare|improve this answer\nThank, just a few last clarification: 1.Regarding the first question, what about over $\\mathbb{R}$, which is my case? what are the restrictions? what's are the points that it should be take care? 2.Regarding question 5- In fact I need for other problem, the general case of two quadratics forms. I tried to look on that most general case, but it seems that the equations derived from Groebner bases are hard, so if there some source which give a closed solution for that case, it would be great. Nonetheless i'm always happy to learn new stuff, and surely I will read yours lecture notes. \u2013\u00a0 user34985 Jun 16 '13 at 19:58\nPlease do not use answers to ask further questions. Either edit the question to include the new part or, better, ask a new question. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Oct 18 '13 at 23:49\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/149325/finding-extremas-of-a-three-variable-function\nText:\nTake the 2-minute tour \u00d7\n\nFind all points on he portion of the plane $x+y+z=5$ in the first octant at which $f(x,y,z)=xy^2z^2$ has a maximum value.\n\nAttempt; Since $x+y+z=5$; $x=5-y-z$. I plug this into the $f(x,y,z)$: $$f(5-y-z,y,z)=u(y,z)=y^2 z^2 (5-y-z)=\\text{5 }y^2 z^2-y^3 z^2-y^2 z^3$$\n\nNow I find critical points: $$u_y=10 yz^2-3y^2z^2-2yz^3=0$$ $$u_z=10 y^2 z-2 y^3 z-3 y^2 z^2=0$$\n\nThe solution for this system of equations is $y=z=0$.Therefore, $x=5$. So thats the only critical point $(0,0,5)$ I get and $f(0,0,5)=0$. The answer should be a max at $(1,1,2)$ according to the answer key. How do I get it? Any hints please.\n\nshare|improve this question\nit's $(1,2,2)$. Typing sol \u2013\u00a0 Simon Markett May 24 '12 at 19:03\nYou missed a solution of the system of two equations. Not surprising, they are messy equations. \u2013\u00a0 Andr\u00e9 Nicolas May 24 '12 at 19:05\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe maximum is at $(1,2,2)$ (I assume there is a typo, either in your question or in the answer key.)\n\nYou did everything correctly up to the point where you determine the critical points. We have\n\n$$10yz^2-3y^2z^2-2yz^3=0$$ and $$10y^2z-2y^3z-3y^2z^2=0$$\n\nThe solution is not only $z=y=0$, but it is a sufficient condition if either $y$ or $z$ is $0$. You also get a solution where $z,y\\neq 0$.\n\nFirst look at the original function. In the first octant the values are non-negative. If $y=0$ or $z=0$ the value is also $0$. So let us assume both are positive. Then the equations simplify to\n\n$$10-3y-2z=0$$ and $$10-2y-3z=0$$\n\nWe see easily that the only solution is $y=z=2$ which yields $x=1$.\n\nshare|improve this answer\nI see. But, how do you come to a conclusion that if $y$ and $z$ are positive then the equations simplify in that way? \u2013\u00a0 Koba May 24 '12 at 19:32\n@Dostre :The kicker is that we can write them in factored form as $(10-3y-2z)yz^2=0$ and $(10-2y-3z)y^2z=0$, so if we take $y,z$ to be non-$0$ (we don't actually need to assume positive), then we may divide the two equations by $yz^2,y^2z$ (respectively) to get the simplified equations given by Simon. Now, of course, we are looking for a solution in the first octant, so if the solution to that system of equations didn't have $y,z$ positive, then it wouldn't actually be the solution we wanted, at all. \u2013\u00a0 Cameron Buie May 24 '12 at 20:40\nYeah. Now I understand it completely. Thanks. \u2013\u00a0 Koba May 25 '12 at 4:58\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/270578/laplace-boundary-problem\nText:\nTake the 2-minute tour \u00d7\n\nConsider a boundary given by vertices $(0,a)$, $(0,0)$ and $(1,0)$ (an 'L' shaped boundary).\n\nThe problem is to find the equation that passes between the endpoints $(0,a)$ $(1,0)$ of minimum length that encloses a specified area $A$.\n\nA trivial case would be $A=a/2$ in which case the solution would be a line.\n\nThis is one dimensional Laplace problem with two boundaries (area and lenth) but how do I try to get a series solution for $A < a/2$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nThe formulation is as follows: Maximize $$L[y]=\\int_{x_1}^{x_2}\\sqrt{1+y'\\ ^2}\\ dx$$ subject to $$A=\\int_{x_1}^{x_2}y\\ dx$$ We can use Lagrange multipliers for a new formulation such as $$G=\\sqrt{1+y'\\ ^2}+\\lambda \\ y$$ and the Euler equation is $$\\frac{\\partial G}{\\partial y}-\\frac{d}{dx}\\frac{\\partial G}{\\partial y'}=\\lambda-\\frac{d}{dx}\\bigg(\\frac{y'}{\\sqrt{1+y'\\ ^2}}\\bigg)=0$$ where the open formulation is $$\\lambda-\\frac{1}{\\big(1+y'\\ ^2\\big)^{3/2}}=0$$ and can be solved for y such as $$y[x]=\\alpha \\ x^2+\\beta \\ x +\\gamma\\qquad \\alpha=\\frac{1}{2}\\sqrt{\\frac{1}{\\lambda^{2/3}}-1}$$ To satisfy the conditions to pass through points $(0,a)$ and $(1,0)$; and $A=\\int_{x_1}^{x_2}y\\ dx$ $$y[x]=(3a-6A)\\ x^2+(6A-4a)\\ x +a$$\n\nshare|improve this answer\nadd comment\n\nWelcome to Math.SE! This is an interesting question which would be approached in different ways depending on the context in which it arrives (e.g., level of a course). For example, the curves could be assumed to be smooth or merely rectifiable. They could be assumed to be graphs, or not. The attainment of minimal length could be taken for granted, or require a proof. All this makes it hard to pitch the answer at the right level, and I'm most likely going to fail at that. Indeed, I do not see how one would get a solution in the form of a series, because in general the minimizer is not analytic. If this problem comes from a textbook, it would be helpful to have a reference so that an answer can be given within the context of that book.\n\nIf the existence and differentiability of a minimizing curve can be granted, then there is a variational argument to show it must have the same curvature at all points where it does not meet the constraint (i.e, does not lie on the vertical or horizontal axis). Indeed, write the curve in vector form $\\gamma(t)$, parametrized by arclength, and consider the perturbation $$\\Gamma(t)=\\gamma(t)+\\epsilon \\eta(t) R\\gamma'(t)$$ where $\\epsilon$ is a parameter, $\\eta$ is a smooth function with compact support, and $R$ denotes rotation by $\\pi/2$ clockwise. Note that $(Ru)\\times v =u\\cdot v$ and $u\\times Rv=-u\\cdot v$. The area bounded by $\\Gamma$ is expressed as an integral of $\\Gamma\\times \\Gamma'$, in which the linear term in $\\epsilon $ simplifies to $$2\\epsilon \\eta \\gamma'\\cdot \\gamma' - \\epsilon (\\eta \\gamma\\cdot \\gamma')' $$ Here the first term yields $2\\epsilon \\int \\eta$ and the second integrates to zero. Thus, we should have $\\int \\eta=0$ to preserve the area up to $O(\\epsilon^2)$.\n\nThe length of $\\Gamma$ is given by the integral of $|\\Gamma'(t)| = (\\Gamma'(t)\\cdot \\Gamma'(t))^{1/2}$ in which the linear term simplifies to\n$$ \\epsilon \\eta (\\gamma' \\cdot R\\gamma'') = \\epsilon \\eta \\kappa $$ where $\\kappa$ is the curvature of $\\gamma$. The conclusion is that $\\int \\eta \\kappa =0$ for any $\\eta$ such that $\\int \\eta =0$. Equivalently, $\\kappa$ is constant.\n\nThus, the minimizing curve will be a circular arc as long as it is free to move; i.e., as long as it does not hit the obstacle (vertical or horizontal axes). And the obstacle does get involved when $A$ is so small that no circular arc through $(0,a)$ and $(1,0)$ can bound area $A$ and stay within the first quadrant. When the obstacle takes effect, the minimizing curve consists of parts of the vertical and/or horizontal axes joined by a circular arc that is tangent to them. An obstacle must always be met tangentially: otherwise the point of contact could slide along the obstacle, decreasing length. This takes a separate perturbation argument, into which I will not go.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mechanics.stackexchange.com/questions/5627/2006-nissan-titan-makes-odd-sound-but-only-at-certain-speeds?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nMy 2006 Nissan Titan makes an odd sound, like a grinder, mostly when travelling steady at 35, 40 or 45 miles per hour. Even 1-2 mile per hour difference will cause the noise to stop.\n\nThe noise will go away if I accelerate slightly or slow down by letting off the gas. I've noticed that it will also make the same sound around 20 miles an hour, sometimes when turning, sometimes not. It will not make the sounds during steady acceleration passing through 45 miles an hour.\n\nCould this be a wheel bearing, or possibly the fuel pump? It's a difficult sound to locate whether I'm a passenger or driving, as I have a custom exhaust that's rather loud.\n\nThanks for the ideas!\n\nshare|improve this question\nIf it is only at those speeds then there is a resonance somewhere. Do those speeds correspond to a specific RPM? If so then there is something related to engine speed - perhaps mounts. If it is not related to RPM then check wheels, shocks, bearings etc \u2013\u00a0 Rory Alsop Mar 16 '13 at 18:09\nI'll definitely check and see if it corresponds to a specific RPM. \u2013\u00a0 Brandon Mar 16 '13 at 18:12\nadd comment\n\n2 Answers\n\nWheel bearing was my first thought but it should get louder at higher speeds and remain during accel and decel.\n\npossibly some issue with the torque converter not locking or slipping at certain speeds? Does it only happen in the highest gear of the transmission?\n\nthe turning at low speed leads me to think power steering pump. The sound should change with engine rpm. Try revving the engine at different speeds in neutral.\n\nshare|improve this answer\nThe sound stays constant in volume, no matter which speed, and only happens at the specific speeds. I'll check to see which gear I'm in when it makes the noise and also check in neutral. \u2013\u00a0 Brandon Mar 16 '13 at 18:16\nAn issue with the converter lock-out clutch would give a feel similar to a failed Mass Air Flow Sensor. The steady jerking or bucking at a constant cruise speed on the highway, or a slight load when going uphill at highway speeds. \u2013\u00a0 cinelli Mar 22 '13 at 14:03\nadd comment\n\nI would imagine that something is just rattling.. I say this because if it was an issue of possibly a pulley or a wheel bearing or anything at all for that matter. Then the noise would be more consistent. It isn't too often where you have a vehicle that only has an issue in that tight of a situation.\n\nmostly when traveling steady at 35, 40 or 45 miles per hour. Even 1-2 mile per hour difference will cause the noise to stop. The noise will go away if I accelerate slightly or slow down by letting off the gas. I've noticed that it will also make the same sound around 20 miles an hour,\n\nThis leads me to believe that it's an issue of something vibrating. At a stead 35 to 45 miles per hour the engine should be I'd say about 2500rpm on the highway. Around the same rpm that it would be at when coasting 20 miles per hour. A slight increase in speed also is directly related to a slight increase in RPM, and the noise is gone. Turning, (lets build a scenario of you turning right at a read light) you touch the gas slightly and turn. Most likely hitting right around that 2300-2500rpm mark to get the noise to occur.\n\nNext time you're in the vehicle and you hear the noise take note to where in the RPM range the motor is at at the given time. Then when you get back to your parking spot try to replicate the noise while stopped. If you cannot get it to happen while stopped then perform the following test.\n\nFully engage the parking brake, place the vehicle in drive, and place your left food on the brake pedal. Then with your right foot start to bring the RPM level up (use common sense here, don't just put a brick on the gas pedal because you'll end up slamming into whatever it is in front of you).\n\nUsing the second method if the first one fails will ensure that all the components are engaged and being torqued as if you were driving the vehicle down the road. You'll feel the entire car lurch up (resembling a cat ready to pounce).\n\nIf you can get the noise to reoccur at will then you can have someone assist you in pinpointing it's location.\n\nshare|improve this answer\nThanks for the ideas. I'll try the parking brake/brake/gas method - with a lot of room in front of me - this truck has 313 HP :) \u2013\u00a0 Brandon Mar 17 '13 at 12:06\nIf you get a chance, slide under the truck and make sure that the the heat-shields around the exhaust aren't touching on the exhaust. This usually happens from going through a nice puddle. They're made of a rather thin aluminum so you can just push them back with a long flat-head screwdriver or if you can reach them safely then just use your hand. \u2013\u00a0 cinelli Mar 17 '13 at 21:58\nI wouldn't describe a vibration as a \"grinding\" sound. Usually you would hear a rattle or ping. Grinding makes me think something that is rotating. I guess it is possible that something is intermittently touching the driveshaft? \u2013\u00a0 Mike Saull Mar 20 '13 at 16:17\nIt's also possible the noise wasn't explained correctly. When giving my answer, tried to think of the symptoms given and forget about the description of the noise. I can see see how a low pitched heat-shield could be processed as a \"grinding\" noise to a customer. Do you agree? \u2013\u00a0 cinelli Mar 22 '13 at 14:01\n@cinelli Yeah I agree its possible. Just if you are looking for \"grinding\" specifically that isn't where I would start looking. If you disregard the description of \"grinding\" then you have to start looking at suspension springs, bushings, shocks etc the list of possibilities goes up like crazy. \u2013\u00a0 Mike Saull Mar 22 '13 at 15:32\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://tcsmath.wordpress.com/tag/expander-graphs/\nText:\ntcs math \u2013 some mathematics of theoretical computer science\n\nFebruary 7, 2013\n\nA bit more on expanders\u2026\n\nFiled under: Math \u2014 Tags: , , \u2014 James Lee @ 11:56 am\n\nSo the lecture notes I posted a year ago giving a \u201csimpler proof\u201d of expansion for the Margulis-Gabber-Galil graphs turns out to be very similar to arguments of M. Berger (1991) and Y. Shalom (1999) for proving that SL_2(\\mathbb Z) \\ltimes \\mathbb Z^2  has property (T). See Section 4.2 of the book of Bekka, de la Harpe, and Valette.\n\nAnyone interested in expander graphs should take a look at Amir Yehudayo\ufb00\u2019s recent article in the SIGACT newsletter: Proving expansion in three steps. Amir uses a ping-pong lemma argument (which is essentially the same as the \u201ccombinatorial lemma\u201d in the preceding post) to exemplify the \u201copening\u201d of the three part strategy of Bourgain and Gamburd to proving expansion in Cayley graphs.\n\nApril 18, 2012\n\nGabber-Galil analysis of Margulis\u2019\u00a0expanders\n\nFiled under: Math \u2014 Tags: , , \u2014 James Lee @ 8:11 pm\n\nI\u2019m currently teaching a course on spectral graph theory, and I decided to lecture on Margulis\u2019 expander construction and the analysis of its spectral gap by Gabber and Galil. I had never realized how intuitive the analysis could be; the lectures notes I had seen didn\u2019t quite reflect this. In particular, we won\u2019t do any unsightly calculations. Everything I\u2019m about to say is probably well-known, but I thought I would write it down anyway.\n\nThe idea is to first start with an initial \u201cexpanding object,\u201d and then try to construct a family of graphs out of it. First, consider the infinite graph {G} with vertex set {\\mathbb Z^2} . The edges are given by two maps {S} and {T} , where {S(x,y) = (x,x+y)} and {T(x,y) = (x+y,y)} . So the edges are {\\{(x,y), S(x,y)\\}} and {\\{(x,y), T(x,y)\\}} . Clearly {(0,0)} is not adjacent to anything. Except for the origin, this graph is an expander in the following sense.\n\nLemma 1 For any subset {A \\subseteq \\mathbb Z^2 \\setminus \\{0\\}} , we have\n\n\\displaystyle  |E(A)| \\geq \\frac{1}{3} |A|\\,,\n\nwhere {E(A)} denotes the edges leaving {A} .\n\nThe following simple proof is inspired by a paper of Linial and London.\n\nProof: First consider a subset {A} that does not intersect the coordinate axes. Let {Q_1, Q_2, Q_3, Q_4} represent the four quadrants of {\\mathbb Z^2} , and let {A_i = A \\cap Q_i} . Consider that {S(A_1), T(A_1) \\subseteq Q_1} and {S(A_1) \\cap T(A_1) = \\emptyset} . The latter fact follows because if {(x,x+y)=(x'+y',y')} then {x'=-y} . Similarly, {S^{-1}(A_2), T^{-1}(A_2) \\subseteq Q_2} and {S(A_3), T(A_3) \\subseteq Q_3} and {S^{-1}(A_4), T^{-1}(A_4) \\subseteq Q_4} , while all the respective pairs {S^{-1}(A_2), T^{-1}(A_2)} and {S(A_3), T(A_3)} and {S^{-1}(A_4), T^{-1}(A_4)} are disjoint.\n\nCombining this with the fact that {S} and {T} are bijections on {\\mathbb Z^2} immediately shows that {|S(A) \\cup S^{-1}(A) \\cup T(A) \\cup T^{-1}(A)|} is at least\n\n\\displaystyle  |S(A_1)| + |T(A_1)| + |S^{-1}(A_2)| + |T^{-1}(A_2)|\n\n\\displaystyle  + |S(A_3)| + |T(A_3)| + |S^{-1}(A_4)| + |T^{-1}(A_4)|\n\n\\displaystyle  = 2(|A_1| + |A_2| + |A_3| + |A_4|)\n\n\\displaystyle  = 2 |A|\\,.\n\nDealing with the coordinate axes is not too hard. Suppose now that {A \\subseteq \\mathbb Z^2 \\setminus \\{0\\}} is arbitrary. Let {A_{+} = A \\cap \\{ (x,0), (0,x) : x \\in \\mathbb Z \\}} . The preceding argument shows {|E(A)| \\geq |A\\setminus A_+|-|A_+| = |A|-2|A_+|} . We will show that {|E(A)| \\geq |A_+|} . Averaging these two inequalities with weights {1/3} and {2/3} completes the proof.\n\nLet {A_\\times = A \\cap \\{ (x,x), (x,-x) : x \\in \\mathbb Z \\}} , and {A_\\circ = A \\setminus (A_1 \\cup A_2)} . Then we have the bounds:\n\n\\displaystyle |E(A_+, \\bar A)| \\geq |A_+| - |A_\\times|\n\n\\displaystyle |E(A_\\times, \\bar A)| \\geq 2|A_\\times| - |A_\\circ|\n\n\\displaystyle |E(A_\\circ, \\bar A)| \\geq |A_\\circ| - |A_\\times|\\,.\n\nThe first equation follows since each element of {A_+} is connected to exactly two elements of {A_{\\times}} , and each element of {A_{\\times}} is connected to exactly two elements of {A_+} . For instance, {(x,0)} is connected to {(x,x)} and {(x,-x)} , while {(x,x)} is connected to {(x,0)} and {(0,x)} .\n\nThe second follows because every point of {A_\\times} is connected to two unique points of {A_\\circ} , e.g. {(x,x)} is connected to {(x,2x)} and {(2x,x)} . The final inequality follows from the fact that {|E(A_\\circ)| \\geq |A_\\circ|} from our first argument (since {A_{\\circ}} does not touch the axes), and because {A_\\circ} has no edges to {A_+} . Summing these three inequalities yields {|E(A)| \\geq |A_+|} . \\Box\n\nOf course, {\\mathbb Z^2} is not a finite graph, so for a parameter {n} , we define the graph {G_n=(V_n,E_n)} with vertex set {V_n = \\mathbb Z_n \\oplus \\mathbb Z_n} , where {\\mathbb Z_n = \\mathbb Z/(n \\mathbb Z)} . There are four types of edges in {E_n} : A vertex {(x,y)} is connected to the vertices\n\n\\displaystyle \\{(x,y+1), (x+1, y), (x,x+y), (x+y,y)\\}\\,.\n\nThis yields a graph of degree at most 8.\n\nTheorem 2 There is a constant {c > 0} such that for every {n \\in \\mathbb N} ,\n\n\\displaystyle  \\lambda_2(G_n) \\geq c\\,,\n\nwhere {\\lambda_2} is the second-smallest eigenvalue of the Laplacian on {G_n} .\n\nOf course, the graphs {\\{G_n\\}} now have torsion, and thus our expansion result for {\\mathbb Z^2} is not, a priori, very useful. The non-trivial idea of the proof is that the torsion doesn\u2019t matter, making Lemma 1 applicable. This is not difficult to show using some Fourier analysis. It turns out to be better though, if we first move to the continuous torus.\n\nRecall that,\n\n\\displaystyle  \\lambda_2(G_n) = \\min_{f : V_n \\rightarrow \\mathbb R} \\left\\{\\frac{\\sum_{uv \\in E_n} (f(u)-f(v))^2}{\\sum_{u \\in V_n} f(u)^2} : \\sum_{u \\in V_n} f(u) = 0\\right\\}\\,,\n\nLet {\\mathbb T^2 = \\mathbb R^2/\\mathbb Z^2} be the 2-dimensional torus equipped with the Lebesgue measure, and consider the complex Hilbert space\n\n\\displaystyle  L^2(\\mathbb T^2) = \\left\\{ f : \\mathbb T^2 \\rightarrow \\mathbb C : \\int_{\\mathbb T^2} |f|^2 < \\infty \\right\\}\\,.\n\nequipped with the inner product {\\langle f,g\\rangle_{L^2} = \\int_{\\mathbb T^2} f \\bar g} .\n\nWe might also define a related value,\n\n\\displaystyle   \\lambda_2(\\mathbb T^2) = \\min_{f \\in L^2(\\mathbb T^2)} \\left\\{\\frac{\\|f-f\\circ S\\|_{L^2}^2 + \\|f-f \\circ T\\|_{L^2}^2}{\\|f\\|_{L^2}^2} : \\int_{\\mathbb T^2} f = 0\\right\\}\\,. \\ \\ \\ \\ \\ (1)\n\nNote that this is just defined as a number; the eigenvalue notation is merely suggestive, but we have not introduced an operator on the torus.\n\nClaim 1 There is some {\\varepsilon > 0} such that for any {n \\in \\mathbb N} , we have {\\lambda_2(G_n) \\geq \\varepsilon \\lambda_2(\\mathbb T^2)} \\\n\nProof: We simply sketch a proof, which is rather intuitive. Suppose we are given some map {f : V_n \\rightarrow \\mathbb R} such that {\\sum_{u \\in V_n} f(u)=0} . Define its continuous extension {\\tilde f : \\mathbb T^2 \\rightarrow \\mathbb R} as follows: Under the natural embedding of {\\mathbb Z_n \\oplus \\mathbb Z_n} into {\\mathbb T^2} , every point {z \\in \\mathbb T^2} sits inside a grid square with four corners {u_1,u_2,u_3,u_4 \\in \\mathbb Z_n \\oplus \\mathbb Z_n} . Writing a local convex combination {z = \\lambda_1 u_1 + \\lambda_2 u_2 + \\lambda_3 u_3 + \\lambda_4 u_4} , we define\n\n\\displaystyle  \\tilde f(z) = \\lambda_1 f(u_1) + \\lambda_2 f(u_2) + \\lambda_3 f(u_3) + \\lambda_4 f(u_4)\\,.\n\nNow it is elementary to verify that {\\int_{\\mathbb T^2} \\tilde f = 0} . It is also easy to verify that {\\|\\tilde f\\|^2_{L^2} \\geq c\\frac{1}{n} \\sum_{v \\in V} f(v)^2} for some {c > 0} . (Even if {f(u_1)+f(u_2)+f(u_3)+f(u_4)=0} , we still get a contribution from {f(u_1)^2 + f(u_2)^2 + f(u_3)^2 + f(u_4)^2} to {\\|\\tilde f\\|_{L^2}} on this square because we are taking a weighted average.)\n\nFinally, for any {z \\in \\mathbb T^2} , there is a path of length {O(1)} in {G_n} connecting each of the corners of {z} \u2018s square to the corners of {S(z)} \u2018s square. A similar fact holds for {T(z)} . In fact, this is the only place where we need to use the fact that edges of the form {(x,y) \\leftrightarrow (x,y+1)} and {(x,y) \\leftrightarrow (x+1,y)} are present in {G_n} . Thus any contribution {|\\tilde f(z)-\\tilde f(S(z))|^2} to {\\|\\tilde f-\\tilde f\\circ S\\|_{L^2}^2} can be charged against a term in {\\sum_{uv \\in E_n} (f(u)-f(v))^2} , and similarly for {T} . \\Box\n\nNow our goal is to show that {\\lambda_2(\\mathbb T^2) > 0} . We will use the Fourier transform to \u201cremove the torsion.\u201d The point is that {S} and {T} , being shift operators, will act rather nicely on the Fourier basis.\n\nWe recall that if {m,n \\in \\mathbb N} and we define {\\chi_{m,n} \\in L^2(\\mathbb T^2)} by {\\chi_{m,n}(x,y) = \\exp(2\\pi i(mx+ny))} , then {\\{\\chi_{m,n}\\}} forms an orthonormal Hilbert basis for {L^2(\\mathbb T^2)} . In particular, every {f \\in L^2(\\mathbb T^2)} can be written uniquely as\n\n\\displaystyle  f = \\sum_{m,n \\in \\mathbb Z} \\hat f_{m,n} \\chi_{m,n}\\,,\n\nwhere {\\hat f_{m,n} = \\langle f, \\chi_{m,n}\\rangle_{L^2}} . The Fourier transform is defined as a map {\\mathcal F~:~L^2(\\mathbb T^2) \\rightarrow \\ell^2(\\mathbb Z^2)} , where {\\mathcal F f(m,n) = \\hat f_{m,n}} . In particular, {\\mathcal F} is a linear isometry.\n\nDefine {S^*(f) = f \\circ S} and {T^*(f) = f \\circ T} . Then for any {m,n \\in \\mathbb Z} , we have\n\n\\displaystyle  S^*(\\chi_{m,n}) = \\chi_{m+n,n} \\quad\\textrm{ and }\\quad T^*(\\chi_{m,n}) = \\chi_{m,n+m}.\n\nIn particular, for any {f \\in L^2(\\mathbb T^2)} , we have {\\widehat{S^*(f)} = \\sum_{m,n} \\hat f_{m-n,n} \\chi_{m,n}} and {\\widehat{T^*(f)} = \\sum_{m,n} \\hat f_{m,n-m} \\chi_{m,n}} . The final thing to note is that {\\hat f(0,0) = \\langle f, \\chi_{0,0} \\rangle = \\int_{\\mathbb T^2} f} . So now if we simply apply the Fourier transform (a linear isometry) to the expression in (1), we get a reformulation that {\\lambda_2(\\mathbb T^2)} is precisely\n\n\\displaystyle  \\min_{g \\in \\ell^2(\\mathbb Z^2)} \\left\\{ \\frac{\\sum_{z \\in \\mathbb Z^2} |g(z)-g(S(z))|^2 + |g(z)-g(T(z))|^2}{\\|g\\|^2_{\\ell^2}}: g(0,0)=0 \\right\\}\\,.\n\nHere we have simply replaced {f} by {\\mathcal F f} in (1), and then written {g = \\mathcal F f} .\n\nBut now recall our initial infinite graph {G} on {\\mathbb Z^2} . If we denote by {L_G} the Laplacian on {G} , then we can rewrite this as,\n\n\\displaystyle  \\lambda_2(\\mathbb T^2) = \\min_{g \\in \\ell^2(\\mathbb Z^2)} \\left\\{ \\frac{\\langle g, L_G g\\rangle_{\\ell^2}}{\\|g\\|^2_{\\ell^2}}: g(0,0)=0 \\right\\}\\,.\n\nIn other words, it is precisely the first Dirichlet eigenvalue on {G} , subject to the boundary condition {g(0,0)=0} .\n\nBut now the discrete Cheeger inequality tells us that\n\n\\displaystyle  \\lambda_2(\\mathbb T^2) \\geq \\frac1{2 d_{\\max}} h^2,\n\nwhere {h} is the minimal expansion of any set not containing the origin. Thus we have indeed unwrapped the torsion and returned to our initial question. Lemma 1 shows that {h \\geq 1/3} , yielding the desired lower bound on {\\lambda_2(\\mathbb T^2)} .\n\nMay 4, 2008\n\nThe pseudorandom subspace\u00a0problem\n\nFiled under: Math \u2014 Tags: , , , \u2014 James Lee @ 7:31 pm\n\nIn this post, I will talk about the existence and construction of subspaces of \\ell_1^N which are \u201calmost Euclidean.\u201d In the next few, I\u2019ll discuss the relationship between such subspaces, compressed sensing, and error-correcting codes over the reals.\n\nA good starting point is Dvoretzky\u2019s theorem:\n\nFor every N \\in \\mathbb N and \\varepsilon > 0, the following holds. Let |\\cdot| be the Euclidean norm on \\mathbb R^N, and let \\|\\cdot\\| be an arbitrary norm. Then there exists a subspace X \\subseteq \\mathbb R^N with \\mathrm{dim}(X) \\geq c(\\varepsilon) \\log N, and a number A > 0 so that for every x\\in X,\n\n\\displaystyle A|x| \\leq \\|x\\| \\leq (1+\\varepsilon) A |x|.\n\nHere, c(\\varepsilon) > 0 is a constant that depends only on \\varepsilon.\n\nThe theorem as stated is due to Vitali Milman, who gave the (optimal) dependence of \\log N on the dimension of X, and proved that the above fact actually holds with high probability when X is chosen uniformly at random from all subspaces of this dimension. In other words, for d \\approx \\log N, a random d-dimensional subspace of an arbitrary N-dimensional normed space is almost Euclidean. Milman\u2019s proof was one of the starting points for the \u201clocal theory\u201d of Banach spaces, which views Banach spaces through the lens of sequences of finite-dimensional subspaces whose dimension goes to infinity. It\u2019s a very TCS-like philosophy; see the book of Milman and Schechtman.\n\nOne can associate to any norm its unit ball B = \\left\\{ x \\in \\mathbb R^N : \\|x\\| \\leq 1 \\right\\}, which will be a centrally symmetric convex body. Thus we can restate Milman\u2019s proof of Dvoretzky\u2019s theorem geometrically: If B is an arbitrary convex body, and H is a random c(\\varepsilon) \\log N-dimensional hyperplane through the origin, then with high probability, B \\cap H will almost be a Euclidean ball. This is quite surprising if one starts, for instance, with a polytope like the unit cube or the cross polytope. The intersection B \\cap H is again a polytope, but which is approximated closely by a smooth ball. Here\u2019s a pictorial representation lifted from a talk I once gave:\n\n(Note: Strictly speaking, the intersection will only be an ellipsoid, and one might have to pass to a subsection to actually get a Euclidean sphere.)\n\nEuclidean subspaces of \\ell_1^N and Error-Correcting Codes.\n\nIt is not too difficult to see that the dependence \\mathrm{dim}(X) \\approx \\log N is tight when we consider \\mathbb R^N equipped with the \\ell_\\infty norm (see e.g. Claim 3.10 in these notes), but rather remarkably, results of Kasin and Figiel, Lindenstrauss, and Milman show that if we consider the \\ell_1 norm, we can find Euclidean subspaces of proportional dimension, i.e. \\mathrm{dim}(X) \\approx N.\n\nFor any x \\in \\mathbb R^N, Cauchy-Schwarz gives us\n\n\\|x\\|_2 \\leq \\|x\\|_1 \\leq \\sqrt{N} \\|x\\|_2.\n\nTo this end, for a subspace X \\subseteq \\mathbb R^N, let\u2019s define\n\n\\displaystyle \\Delta(X) = \\max_{0 \\neq x \\in \\mathbb R^N} \\frac{\\sqrt{N} \\|x\\|_2}{\\|x\\|_1},\n\nwhich measures how well-spread the \\ell_2-mass is among the coordinates of vectors x \\in X. For instance, if \\Delta(X) = O(1), then every non-zero x \\in \\mathbb X has at least \\Omega(N) non-zero coordinates (because \\|x\\|_1 \\leq \\sqrt{|\\mathrm{supp}(x)|} \\|x\\|_2). This has an obvious analogy with the setting of linear error-correcting codes, where one would like the same property from the kernel of the check matrix. Over the next few posts, I\u2019ll show how such subspaces actually give rise to error-correcting codes over \\mathbb R that always have efficient decoding algorithms.\n\nThe Kasin and Figiel-Lindenstrauss-Milman results actually describe two different regimes. Kasin shows that for every \\eta > 0, there exists a subspace X \\subseteq \\mathbb R^N with \\dim(X) \\geq (1-\\eta) N, and \\Delta(X) = O_{\\eta}(1). The FLM result shows that for every \\varepsilon > 0, one can get \\Delta(X) \\leq 1 + \\varepsilon and \\dim(X) \\geq \\Omega_{\\varepsilon}(N). In coding terminology, the former approach maximizes the rate of the code, while the latter maximizes the minimum distance. In this post, we will be more interested in Kasin\u2019s \u201cnearly full dimensional\u201d setting, since this has the most relevance to sensing and coding. Work of Indyk (see also this) shows that the \u201cnearly isometric\u201d setting is useful for applications in high-dimensional nearest-neighbor search.\n\nThe search for explicit constructions\n\nBoth approaches show that the bounds hold for a random subspace of the proper dimension (where \u201crandom\u201d can mean different things;we\u2019ll see one example below). In light of this, many authors have asked whether there are explicit constructions of such subspaces exist, see e.g. Johnson and Schechtman (Section 2.2), Milman (Problem 8), and Szarek (Section 4). As I\u2019ll discuss in future posts, this would also yield explicit constructions of codes over the reals, and of compressed sensing matrices.\n\nDepending on the circles you run in, \u201cexplicit\u201d can mean different things. Let\u2019s fix a TCS-style definition: An explicit construction means a deterministic algorithm which, give N as input, outputs a description of a subspace X (e.g. in the form of a set of basis vectors), and runs in time \\mathrm{poly}(N). Fortunately, the constructions I\u2019ll discuss later will satisfy just about everyone\u2019s sense of explicitness.\n\nIn light of the difficulty of obtaining explicit constructions, people have started looking at weaker results and partial derandomizations. One starting point is Kasin\u2019s method of proof: He shows, for instance, that if one chooses a uniformly random N/2 \\times N sign matrix A (i.e. one whose entries are chosen independently and uniformly from \\{-1,1\\}), then with high probability, one has \\Delta(\\mathrm{ker}(A)) = O(1). Of course this bears a strong resemblance to random parity check codes. Clearly we also get \\dim(\\mathrm{ker}(A)) \\geq N/2.\n\nIn work of Guruswami, myself, and Razborov, we show that there exist explicit N/2 \\times N sign matrices A for which \\Delta(\\mathrm{ker}(A)) \\leq (\\log N)^{O(\\log \\log \\log N)} (recall that the trivial bound is \\Delta(\\cdot) \\leq \\sqrt{N}). Our approach is inspired by the construction and analysis of expander codes. Preceding our work, Artstein-Avidan and Milman pursued a different direction, by asking whether one can reduce the dependence on the number of random bits from the trivial O(N^2) bound (and still achieve \\Delta(\\mathrm{ker}(A)) = O(1)). Using random walks on expander graphs, they showed that one only needs O(N \\log N) random bits to construct such a subspace. Lovett and Sodin later reduced this dependency to O(N). (Indyk\u2019s approach based on Nisan\u2019s pseudorandom generator can also be used to get O(N \\log^2 N).) In upcoming work with Guruswami and Wigderson, we show that the dependence can be reduced to O(N^{\\delta}) for any \\delta > 0.\n\nKernels of random sign matrices\n\nIt makes sense to end this discussion with an analysis of the random case. We will prove that if A is a random N/2 \\times N sign matrix (assume for simplicity that N is even), then with high probability \\Delta(\\mathrm{ker}(A)) = O(1). It might help first to recall why a uniformly random N/2 \\times N matrix B with \\{0,1\\} entries is almost surely the check matrix of a good linear code.\n\nLet \\mathbb F_2 = \\{0,1\\} be the finite field of order 2. We would like to show that, with high probability, there does not exist a non-zero vector x \\in \\mathbb F_2^N with hamming weight o(N), and which satisfies Bx=0 (this equation is considered over \\mathbb F_2). The proof is simple: Let B_1, B_2, \\ldots, B_{N/2} be the rows of B. If x \\neq 0, then \\Pr[\\langle B_i, x \\rangle = 0] \\leq \\frac12. Therefore, for any non-zero x, we have\n\n\\Pr[Bx = 0] \\leq 2^{-N/2}. (**)\n\nOn the other hand, for \\delta > 0 small enough, there are fewer than 2^{N/2} non-zero vectors of hamming weight at most \\delta N, so a union bound finishes the argument.\n\nThe proof that \\Delta(\\mathrm{ker}(A)) = O(1) proceeds along similar lines, except that we can no longer take a naive union bound since there are now infinitely many \u201cbad\u201d vectors. Of course the solution is to take a sufficiently fine discretization of the set of bad vectors. This proceeds in three steps:\n\n  1. If x is far from \\mathrm{ker}(A), then any x' with \\|x-x'\\|_2 small is also far from \\mathrm{ker}(A).\n  2. Any fixed vector x \\in \\mathbb R^N with \\|x\\|_2 = 1 is far from \\mathrm{ker}(A) with very high probability. This is the analog of (**) in the coding setting.\n  3. There exists a small set of vectors that well-approximates the set of bad vectors.\n\nCombining (1), (2), and (3) we will conclude that every bad vector is far from the kernel of A (and, in particular, not contained in the kernel).\n\nTo verify (1), we need to show that almost surely the operator norm \\|A\\| = \\max \\left\\{ \\|Ax\\|_2 : \\|x\\|_2 = 1\\right\\} is small, because if we define\n\n\\mathrm{dist}(x, \\mathrm{ker}(A)) = \\min_{y \\in \\mathrm{ker}(A)} \\|x-y\\|_2,\n\n\n\\mathrm{dist}(x', \\mathrm{ker}(A)) \\geq \\mathrm{dist}(x,\\mathrm{ker}(A)) - \\|A\\| \\cdot \\|x-x'\\|_2\n\nIn order to proceed, we first need a tail bound on random Bernoulli sums, which follows immediately from Hoeffding\u2019s inequality.\n\nLemma 1: If v \\in \\mathbb R^k and X \\in \\{-1,1\\}^k is chosen uniformly at random, then\n\n\\displaystyle \\Pr\\left[|\\langle v, X \\rangle| \\geq t\\right] \\leq 2 \\exp\\left(\\frac{-t^2}{2 \\|v\\|_2^2}\\right)\n\nIn particular, for y \\in \\mathbb R^{N/2} and x \\in \\mathbb R^N, we have \\langle y, Ax \\rangle = \\sum_{i=1}^{N/2} \\sum_{j=1}^N A_{ij} y_i x_j. We conclude that if we take \\|x\\|_2 = 1 and \\|y\\|_2 = 1, then\n\n\\Pr\\left[ |\\langle y, Ax \\rangle| \\geq t \\sqrt{2N}\\right] \\leq 2 \\exp\\left(-t^2 N\\right), (4)\n\nobserving that \\sum_{i,j} y_i^2 x_j^2 = 1, and applying Lemma 1. Now we can prove that \\|A\\| is usually not too big.\n\nTheorem 1: If A is a random N/2 \\times N sign matrix, then\n\n\\Pr[\\|A\\| \\geq 10 \\sqrt{N}] \\leq 2 e^{-6N}.\n\n\nFor convenience, let m = N/2, and let \\Gamma_m and \\Gamma_N be (1/3)-nets on the unit spheres of \\mathbb R^m and \\mathbb R^N, respectively. In other words, for every x \\in \\mathbb R^m with \\|x\\|_2 = 1, there should exist a point x' \\in \\Gamma_m for which \\|x-x'\\|_2 \\leq 1/3, and similarly for \\Gamma_N. It is well-known that one can choose such nets with |\\Gamma_m| \\leq 7^m and |\\Gamma_N| \\leq 7^N (see, e.g. the book of Milman and Schechtman mentioned earlier).\n\nSo applying (4) and a union bound, we have\n\n\\displaystyle \\Pr\\left[\\exists y \\in \\Gamma_m, x \\in \\Gamma_N\\,\\, |\\langle y, Ax \\rangle| \\geq 3\\sqrt{2N}\\right] \\leq 2 |\\Gamma_m| |\\Gamma_N| \\exp(-9N) \\leq 2 \\exp(-6N).\n\nSo let\u2019s assume that no such x \\in \\Gamma_N and y \\in \\Gamma_m exist. Let u \\in \\mathbb R^N and v \\in \\mathbb R^m be arbitrary vectors with \\|u\\|_2=1,\\|v\\|_2=1, and write u = \\sum_{i \\geq 0} \\alpha_i x_i and v = \\sum_{i \\geq 0} \\beta_i y_i, where \\{x_i\\} \\subseteq \\Gamma_N and \\{y_i\\} \\subseteq \\Gamma_m, where |\\alpha_i|, |\\beta_i| \\leq 3^{-i} (by choosing successive approximations). Then we have,\n\n|\\langle v, A u\\rangle| \\leq \\sum_{i,j \\geq 0} 3^{-i-j} |\\langle y_i, A x_i\\rangle| \\leq (3/2)^2 3\\sqrt{2N} \\leq 10 \\sqrt{N}.\n\nWe conclude by nothing that \\|A\\| = \\max \\left\\{ |\\langle u, Av \\rangle| : \\|u\\|_2 = 1, \\|v\\|_2=1 \\right\\}.\n\nThis concludes the verification of (1). In the next post, we\u2019ll see how (2) and (3) are proved.\n\nThe Shocking Blue Green Theme Blog at\n\n\nGet every new post delivered to your Inbox.\n\nJoin 57 other followers"}
{"text": "Retrieved from http://www.math.niu.edu/~rusin/known-math/95/volume.polyh\nText:\nFrom: (Boyan I. Boyanov) Newsgroups: sci.math Subject: Volume of a tetrahedron Date: 27 Mar 1995 00:30:42 GMT Hi, I have a stupid question that I cannot solve myself and cannot find the answer to in any of the math handbooks I've looked at. Is there a general formula for the volume of an ARBITRARY polyhedron? I know everything there is to know about the polyhedron - the coordinates of the vertices, the equations of the planes that form the walls, the number of walls, the number of sides, the number of vertices, etc. About the only restriction that is put on the polyherdon is that it is \"convex\", i.e. all vertices lie in a single \"half-space\" relative to any wall. I was trying to do it by breaking up the polyhedron into a collection of tetrahedra and summing up the volumes of the tetrahedra, but I can't seem to come up with an algorithm that allows me to determine which vertices form the tetrahedra that make up the polyhedron. Any ideas? Is there a better nad easier way to do this? Please Cc: me if you post a followup, if at all possible. Thanks! Boyan -- Boyan I. Boyanov ============================================================================== From: (Dave Rusin) Newsgroups: sci.math Subject: Re: Volume of a tetrahedron Date: 27 Mar 1995 22:52:56 GMT In article <3l50vi$>, Boyan I. Boyanov wrote: >Is there a general formula for the volume of an ARBITRARY polyhedron? Well, I suppose I ought to answer this since I just advertised Green's theorem for a similar purpose. In this question, the author wants a space integral integral_P 1 dxdydz where P is the polyhedron. The corresponding technique is to use Stokes' Theorem, whose general form _ _ _/ w = _/ dw boundary(S) S (for w any differential form on S) specializes for 2-forms to _ _ _/ P dxdy + Q dydz + R dzdx = _/ (dP/dz + dQ/dx + dR/dy) dxdydz so we can get the space integral of 1, for example, by integrating the 2-form z dxdy over the surface of the polyhedron. We can compute the surface integrals face-by-face. The quick answer here is that the individual surface integrals, when divided by the area of the face, would compute the average value of the z coordinate on the face. Therefore, we can compute the surface integrals easily by averaging the z coordinates of the vertices of the face, and multiplying by an area: the surface integral int( zdxdy ) over a face spanned by (x0 y0 z0), (x1 y1 z1), and (x2 y2 z2) is (z0+z1+z2)/3 . | (1/2)( y1.(x0-x2) + y2.(x1-x0) + y0.(x2-x1) ) | This surface integral is added to the total if the three points are in counterclockwise order as seen from the outside of the polyhedron, subtracted otherwise. A proof is appended as a postscript to this post; it may perhaps reinforce an understanding of surface integrals. It perhaps bears mentioning that this procedure does not assume the polyhedron is convex, nor indeed homeomorphic to a sphere. It does assume that the polyhedron is closed (no boundary) and a triangularization of a manifold (which will then be compact and orientable, conditions which I would otherwise have to add). It is not necessary that all the faces be triangles, really, although any other polygons may be so divided. The method may also be extended to other surface integrals besides volume, and so for example may be used to compute the center of mass. One can remove the absolute values and simply add in the polynomial expression if an orientation is chosen consistent with the \"right-hand-rule\" for outward pointing normals. As in the previous post I will concede that there is some redundant calculation here, so that if it is important that the computation be done quickly it pays to watch for repeated line integrals and so on. dave __Derivation of formula for surface integral over one face__ Assuming that the face is not vertical, we can write z = Ax+By+C for some constants A, B and C (easily computed from any three non-collinear vertices on the face). Then that face contributes to the surface integral the sum A integral(x) + B integral(y) + C integral(1) where the integral may be taken over the projection of the face to the xy-plane (translation: ignore the z coordinates on the face). There is an orientation problem: the integral over the projection to the xy-plane will be off by a sign if the polyhedron faces \"in\" rather than \"out\", so you will need to know whether the interior of the polyhedron contains those points whose z coordinates are just larger than Ax+By+C or just smaller. In a previous post, I discussed integrating these very three surface integrals around a polygon. (These were done with Green's theorem.) The upshot is that these integrals may be computed as simple sums around the perimeter of the polygon. The segment from (x0, y0) to (x1, y1) contributes (x0 + x1)/2 . (y1-y0) to the integral of 1 over the polygon, (x0^2 + x0 x1 + x1^2)/6 . (y1-y0) to the integral of x, and ( (y0 x1 + x0 y1) + 2(x1 y1 + x0 y0) )/6 . (y1 - y0) to the integral of y. So, for example, if one face of your polyhedron is a triangle with vertices (x0,y0,z0), (x1,y1,z1), and (x2,y2,z2), then the equation for the plane is z = Ax + By + C where A, B, and C are determined by ( A ) ( x0 y0 1 )^{-1} ( z0 ) ( B ) = ( x1 y1 1 ) ( z1 ) ( C ) ( x2 y2 1 ) ( z2 ) We compute the line integrals around the triangle in the xy-plane: the integral of 1 is I1 = (1/2)( y1.(x0-x2) + y2.(x1-x0) + y0.(x2-x1) ) as in a followup I made to the previous post; the integral of x is this times (x0+x1+x2)/3, and the integral of y is the same factor I1 times (y0+y1+y2)/3. (All these should have their sign adjusted in case the points (x0,y0), (x1,y1), (x2,y2) do not wrap counterclockwise around the triangle. The correction is easy: since integral(1)=Area > 0, the sign correction to multiply by is just the sign S1 of I1. Thus, the surface integral over this face is the linear combination [ A(x0+x1+x2)/3 + B(y0+y1+y2)/3 + C ] . (S1 I1) As it happens, I1 is precisely the determinant of the matrix to be inverted above, so multiplyng thru we see that A B and C may be replaced by the cofactors, making division unnecessary. Apart from the sign correction, the previous surface integral may thus be written (z0.(y1-y2)+z1.(y2-y0)+z2.(y0-y1)) . (x0+x1+x2)/3 + (z0.(x2-x1)+z1.(x0-x2)+z2.(x1-x0)) . (y0+y1+y2)/3 + (z0.(x1y2-x2y1)+z1.(x2y0-x0y2)+z2.(x0y1-x1y0)) This, in turn, simplifies to just (z0+z1+z2)/3 . (I1) (again, times the sign correction so that S1 I1 > 0 ) This is the formula given above."}
{"text": "Retrieved from http://math.stackexchange.com/questions/334375/conditional-probability-uniform-distributions\nText:\nTake the 2-minute tour \u00d7\n\nProblem: Suppose that the random variable X is uniformly distributed symmetrically around zero, but in such a way that the parameter is uniform on (0, 1); that is, suppose that $X\\mid (A=a) \\sim U(-a,a)$ with $A \\sim U(0,1)$. Find the distribution of X.\n\nMy attemt: $f_{A,X}(a,x)=f_{X\\mid A=a}(x) \\cdot f_{A} (a)$.\n\n$f_{A}(a)=1$ for $0<a<1$ and $f_{X,A=a}(x)=\\frac{1}{2a}$ for $-a<x<a$ which means that $f_{A,X}(a,x)=\\frac{1}{2a}$ for $0<a<1$ and $-a<x<a$. Next I integrate the joint distribution over a to find $f_{X}(x)$.\n\n$f_{X}(x)=\\int_0^1 f_{A,X}(a,x) da=\\int_0^1 \\frac{1}{2a}da$, but this integral is not convergent. Where do I go wrong?\n\n\nshare|improve this question\nI think the standard symbol where you use $\\in$ would be $\\sim$. \u2013\u00a0 joriki Mar 19 '13 at 2:04\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou were correct up until setting up the integral for the marginal density: $$ f_X(x) = \\int_0^1 f_{A,X}(a,x) \\mathrm{d}a = \\int_0^1 \\frac{1}{2a} [-a<x<a] \\mathrm{d}x $$ For a given $-1<x<1$, the indicator function $[-a<x<a]$ is non-zero for $|x|<a<1$, therefore $$ f_X(x) = \\int_{|x|}^a \\frac{\\mathrm{d}a}{2a} = \\frac{1}{2} \\ln \\frac{1}{|x|} $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.jiskha.com/questions/360191/n2h4-g-h2-g-2-nh3-g-h1-1876kj-3-h2-g-n2-g-2-nh3-g-h2-922-kj-the\nText:\nEnthalpy of Formation\n\nN2H4(g) + H2(g)--> 2 NH3(g) H1 = \u20131876kJ\n\n3 H2(g) + N2(g)--> 2 NH3(g) H2 = \u2013922 kJ\n\nThe H.f for the formation of hydrazine: 2 H2(g) + N2(g)--> N2H4(g) will be______kj/mol\n\nI am very confused here. I thought I would just add H1 and H2 and divide by the molar mass of N2H4, but that is not correct. Please Help. Thank You!\n\n  1. \ud83d\udc4d\n  2. \ud83d\udc4e\n  3. \ud83d\udc41\n  1. I got the answer to be 95.4 kj/mol\n    I reversed the 1st equation to get an overall 187.6 kj = h1\n    then I just added that to H2 and I got the answer.\n    But I still don't really understand the processes. If someone could explain that to me I would truly appreciate it.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n  2. You have to reverse the direction of one reaction and change the sign of H.\n\n    3 H2+ N2--> 2 NH3 H2 = -922 kJ/mole\n    2NH3 -> N2H4 + H2 H = +1876 kJ/mole\n\n    NOW add, and cancel out terms that appear on both sides.\n\n    N2 + 2H2 -> N2H4 H = -954 kJ\n\n    There is another problem. Your heat of formation of NH3 does not agree with accepted data. It should be -10.97 kJ/per mole of NH3, or twice that much for the reaction as written (which forms two moles). Also, the standard form of N2H4 at room temperature is a liquid, and your reaction involves the gas.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n  3. For what it is worth, the correct heat of formation of N2H4 (liq.) is +12.10 kcal/mole and for N2H4(g) it is +22.79 kcal/mole. Those values are at 298 K. They are a few kcal/mole different at 0 K. Multiply by 4.18 for kJ/mole. That gives +95.3 kJ/mole for the N2H4(g) heat of formation, which agrees well with your second answer. You seem to have misplaced decimal points in your first version of the question.\n\n    Those values come from the JANAF Thermochemcial Tables of the U.S National Bureau of Standards, 2nd edition.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n\nRespond to this Question\n\nFirst Name\n\nYour Response\n\nSimilar Questions\n\n  1. Honors Chemistry\n\n\n  2. Chemistry\n\n    Calculate the molarity and the molality of an NH3 solution made up of 30 g of NH3 in 70 g of water. The density of the solution is 0.982 g/ml. Molar Mass of NH3 = 17.04 g\n\n  3. chemistry\n\n    Nitrogen (N2) and hydrogen (H2) react to form ammonia (NH3). Consider a mixture of six nitrogen molecules and six hydrogen molecules in a closed container. Assuming the reaction goes to completion, what will the final product\n\n  4. Chemistry\n\n    If 2.50 g of CuSO4 are dissolved in 9.4 102 mL of 0.34 M NH3, what are the concentrations of Cu(NH3)42+, NH3 and Cu2+ at equilibrium? i tried doing Cu2+ first and i did Kf=5e13= salt/cu2+ nh3+^4 and i did molesCuSO4/.94 L = .01666\n\n  1. chemistry\n\n    How many moles are in 1.50 x 1023 molecules NH3? A. 2.49 x 10 -1 mol NH3 B. 2.49 x 101 mol NH3 C. 2.65 x 10 -1 mol NH3 D. 2.78 x 10 1 mol NH3 maybe B\n\n  2. Chem help\n\n    Which reaction of ammonia does not involve the non-bonding pair of electrons on the nitrogen atom? A NH3(g) + CH3I(g) \u2192 CH3NH 3+ I \u2013(s) B NH3(g) + HCl (g) \u2192 NH4Cl (s) C 2NH3(l) + 2Na(s) \u2192 2NaNH2(s) + H2(g) D 2NH3(aq) +\n\n  3. Chemistry\n\n    Consider this equilibrium N2(g) + H2(g) NH3(g) +94 kJ The equilibrium law exoression for the balanced chemical equationwould be A. [N2][H2]/[NH3] B. [NH3]/[H2][N2] C. [NH3]2/[H2][N2] D. [NH3]2/[H2]3[N2] E. 2[NH3]2/3[H2]3[N2]\n\n  4. science\n\n    Calculate the solubility of silver chloride in 10.0 M ammonia given the following information: Ksp (AgCl) = 1.6 x 10^\u201310 Ag+ + NH3--->AgNH3+ K=2.1x10^3 AgNH3+ + NH3-----> Ag(NH3)2+ K=8.2x10^3 Answer : 0.48 M Calculate the\n\n  1. Chemistry\n\n\n  2. AP Chem\n\n    At a certain temperature, 4.0 mol NH3 is introduced into a 2.0 L container, and the NH3 partially dissociates by the reaction. 2 NH3(g) N2(g) + 3 H2(g) At equilibrium, 2.0 mol NH3 remains. What is the value of K for this reaction?\n\n  3. chemistry\n\n    from the balanced equation 4NH3 +7O2 - 4NO2 + 6H2O How many molecules of water are produced when 2.25 moles of ammonia are completely reacted? The equation tells us that 4 mol NH3 will produce 6 mols water. That means 2 mols NH3\n\n  4. Chemistry\n\n    Calculate the molar concentration of uncomplexed Zn2+ (aq) in a solution that contains 0.22 mol of Zn(NH3)4 2+ per liter and 0.3109 M NH3 at equilibrium. Kf for Zn(NH3)4 2+ is 2.9 X 10^9 I started this way... (0.3109 +\n\nYou can view more similar questions or ask a new question."}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/6917/measuring-output-impedance/6920\nText:\nGiven I have designed and produced an RF circuit with an output for connecting an antenna. I know this antenna has an input impedance of 50\u03a9. I now wish to measure the actual output impedance of my circuit, before connecting the antenna, to ensure that the impedance matches.\n\nHow do I actually measure the output impedance of my circuit?\n\nAnd additionally, can I do this with hobby friendly priced equipment?\n\nUpdate: I know the basic theory of impedance matching, but I have never understood how to actually do it. So I am really asking for input on the specific hardware and equipment to use, and how to perform actual tests.\n\nThe RF circuit is operating in the UHF range, and transmits about 10dBm, if this helps.\n\n  \u2022 1\n    \\$\\begingroup\\$ Does \"Hobby Friendly\" include an oscilloscope? Also, do you wish to know the physical output impedance, or calculate the theoretical output impedance? \\$\\endgroup\\$ \u2013\u00a0Kevin Vermeer Nov 18 '10 at 19:09\n  \u2022 \\$\\begingroup\\$ Well, yes, I consider oscilloscopes in the hobby friendly zone. However I don't think a spectrum analyzer is in the hobby friendly zone, and I know any oscilloscope which has a high enough bandwidth to measure UHF and above (directly). \\$\\endgroup\\$ \u2013\u00a0bjarkef Nov 18 '10 at 19:20\n  \u2022 \\$\\begingroup\\$ I asked a similar question about trace impedance: electronics.stackexchange.com/questions/5778/\u2026. I think the answer is to design in the 50 ohms impedance, not to calibrate it after manufacture. \\$\\endgroup\\$ \u2013\u00a0Thomas O Nov 18 '10 at 19:21\n  \u2022 \\$\\begingroup\\$ Hi Thomas. I looked at your question, but I still do not understand how to actually measure what output impedance I have achieved, or how to design that in for that matter. Your question concerns the characteristic impedance for a transmission line. I am interested in the output impedance of a RF generator circuit (+ possibly the transmission line), and I don't understand how this relates. Please enlighten me? :) \\$\\endgroup\\$ \u2013\u00a0bjarkef Nov 18 '10 at 19:34\n  \u2022 \\$\\begingroup\\$ @bjarkef, Thomas is incorrect here, although they are both RF related, your applications are fundamentally different. I have done both, designing a trace to be 50 ohms is very easy, getting an RF generator to match can be quite challenging. \\$\\endgroup\\$ \u2013\u00a0Kortuk Nov 18 '10 at 21:51\n\nYou really need one of a number of options, none of them are hobby friendly if you are above a few MHz. I would guess you are at 2.4GHz, or at 900MHz.\n\nProfessional Options\n\nIf you might know someone whom has access to equipment that would help you have a few options.\n\n  1. VNA- Vector Network Analyzer. This can give you a smith chart over a frequency range and make sure it shows you at 50 ohms. You can also measure S11 which should be less than -20dB\n  2. Spectrum Analyzer- This should allow you to determine your power received at your frequency. This is not ideal, but it should get more output power as you get closer to a proper match.\n  3. SWR Meter-As Is noted in another answer and I always forget about, you can use an Standing Wave Ratio meter, but I would still suggest a VNA. They have significantly more features, and can do anything a spectrum analyzer or SWR meter can do.\n\nHacker style ways to approach it\n\nThere is another funny way to approach this, the problem being you will need to build one of a few microwave components.\n\nYou could use an isolator and measure its temperature, hotter isolator is equivalent to a worse mismatch. this is not even close to good method as at 10dBm it will be very hard to detect a temperature failure.\n\nYou could build your own mixer and feedback your output signal and mix it with your signal returning from the connection. To take away your signal from the feedback you need to use what is called a circulator. This is not fun, but it is doable.\n\nIf you would like to try either method, which is similar to creating your own VNA, I can get you more information on how to build these devices.\n\n  \u2022 \\$\\begingroup\\$ I'm interested in the mixer method... got any more links? Thanks. \\$\\endgroup\\$ \u2013\u00a0cksa361 Dec 4 '10 at 7:56\n  \u2022 \\$\\begingroup\\$ @cksa361, There are a number of options here. I would suggest you look into a \"gilbert cell\" to design this yourself, but there are many different approaches. Here google.com/\u2026 they have someone trying to analyze one. You will probably need a signal generator, like a Phased-locked-loop to generate your signal. This will not be any easy task. \\$\\endgroup\\$ \u2013\u00a0Kortuk Dec 4 '10 at 20:53\n  \u2022 \\$\\begingroup\\$ What is your budget like? I think I can find you some hobbyist projects that actually make most of what you need, then you only need to do a tiny bit of design. \\$\\endgroup\\$ \u2013\u00a0Kortuk Dec 4 '10 at 20:55\n\nIn general, to measure an output impedance, you just connect a known impedance across it and measure the drop in voltage level. You can then calculate the source impedance using the voltage divider rule.\n\nvoltage divider\n\nVout = Z2/(Z1+Z2)*Vin\n\nYou know these:\n\n  \u2022 Z2 (known load)\n  \u2022 Vout (voltage with load)\n  \u2022 Vin (unloaded voltage)\n\nSo you can calculate the output impedance:\n\nZ1 = ((Vin - Vout)*Z2)/Vout\n\nIn other words, Vin and Z1 are inside your device that you're measuring, and Z2 is the test load you connect across its output.\n\nalt text\n\nIf the impedance varies with frequency, you can do the same measurement multiple times with sine waves of different frequencies. If you need to know the reactance, you'll have to measure the phase change with and without the load connected.\n\nAt low frequencies, this can all be done with a single channel scope and hobbyist equipment. At UHF I'm not sure how much effect the test equipment, scope's impedance, probe capacitance and line length, etc. will have on the measurements.\n\n  \u2022 \\$\\begingroup\\$ Thanks for the answer. However this is where I get lost when I try to put theory into practice: I don't really have a Vin, this is not some passive circuit with an input and an output. It is a circuit with a microcontroller, and a radio IC, and some RF low-pass filters, and some sensors, and maybe other things. Sure the input is a battery with around 2.7v, but that may vary with time, and I don't really think that is meant by Vin. \\$\\endgroup\\$ \u2013\u00a0bjarkef Nov 18 '10 at 20:23\n  \u2022 \\$\\begingroup\\$ Vin is the voltage at the output with no load attached. If you measure with a high enough input impedance, the effect of the source's impedance should be negligible. Vout is the voltage with a load attached. In other words, Vin and Z1 are inside your source that you're measuring, and Z2 is the test load you connect across its output. \\$\\endgroup\\$ \u2013\u00a0endolith Nov 18 '10 at 20:27\n  \u2022 \\$\\begingroup\\$ This is great information, but as I note, this is applicable at RF frequencies, I note that you say this, I am just adding and extra note. \\$\\endgroup\\$ \u2013\u00a0Kortuk Nov 18 '10 at 21:17\n  \u2022 \\$\\begingroup\\$ Good information for low frequencies but you would have a really hard time taking this approach to design a matching circuit for RF frequencies. At least without some really expensive equipment. \\$\\endgroup\\$ \u2013\u00a0Mark Nov 18 '10 at 23:55\n\nAnother approach would be to use what is known as a \"dummy\" load. It basically a large resistor with the same impedance as your antenna. This will simulate your antenna.\n\nFor \"tuning\" most people use a SWR meter. If the impedance does not match a standing wave is reflected back to the transmitter from the antenna. With a prefect match the SWR ratio should be 1 to 1. There are several ways to adjust the impedance including shortening the antenna.\n\n\nYou can measure the source resistance of a transmitter by recording the RF output voltage with a 50 ohm load and paralleling a high value resistor (should be above 1000 ohms) and recording the new RF voltage and recording the calculated new value of the load resistance due to the added resistor.\n\nCall the voltage ratio (first rf meas./second rf meas.) = N\nCall the parallel load resistor = Rn\nCall the source resistance = Rs\n\nRs = 50 x Rn x (N-1)/(50 - (N x Rn))\n\nUsing a high value resistor minimizes the Rs measurement error due to the transmitter source resistance being a dependent generator (value depending on the load resistance)."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/51738/algorithm-to-find-the-shortest-walk-with-k-leaf-nodes-on-a-tree\nText:\nLet's say I have a general tree. What algorithm can I use to find a shortest walk that starts at the root, passes through exactly $k$ different leaves, and ends at the root? Passing through a node/edge more than once is allowed.\n\nFor example, consider this graph:\n\n\nFor $k = 1$, the shortest walk would have the node 4. For $k = 2$, the leaf nodes would be 4 and 12. For $k = 3$, the leaves would be 4, 16 and 17.\n\nWhat I actually need is the length of the shortest walk (if this simplifies anything).\n\nI could not find an algorithm for this, but maybe I searched with the wrong terms.\n\n  \u2022 $\\begingroup$ What have you tried? Where did you get stuck? We do not want to just do your exercise for you; we want you to gain understanding. However, as it is we do not know what your underlying problem is, so we can not begin to help. See here for a relevant discussion. $\\endgroup$ \u2013\u00a0D.W. Jan 12 '16 at 0:21\n\nThis can be solved by a fairly standard dynamic programming algorithm. For a given node $v$, let $C(v,k)$ be the minimum length of a (closed) walk through the subtree rooted at $v$ passing through exactly $k$ leaf nodes ($C(v,k)=\\infty$ if there is no such walk).\n\nIf a node $v$ has children $c_1,\\ldots c_m$, then $C(v,k) = min_{k=a_1 + \\ldots + a_m} \\Sigma_{\\{i:a_i\\not = 0\\}} 2 + C(c_i, a_i)$ (i.e. taking the minimum over all ways to split up $k$ over the children of the node).\n\nWith some modification, this can be made to run in $O(n^3)$.\n\n  \u2022 $\\begingroup$ $O(n^2)$? Interesting. $\\endgroup$ \u2013\u00a0Hendrik Jan Jan 12 '16 at 17:40\n  \u2022 $\\begingroup$ Whoops, now that I think about it I can only do $O(n^3)$, but you definitely don't need to iterate over the exponentially many ways to split up $k$. $\\endgroup$ \u2013\u00a0Tom van der Zanden Jan 12 '16 at 17:47\n  \u2022 $\\begingroup$ How to achieve $O(n^3)$? $\\endgroup$ \u2013\u00a0hengxin May 26 '16 at 12:39\n\nYour Answer"}
{"text": "Retrieved from https://in.mathworks.com/matlabcentral/answers/636780-how-can-i-obtain-the-mean-and-standard-deviation-of-a-gaussian-pdf\nText:\nMATLAB Answers\n\nHow can I obtain the mean and standard deviation of a gaussian PDF\n\n3 views (last 30 days)\nThis might be a trivial question but i calculated 3 gaussian pdf's on the domain\nx = [0 : 0.1 : 200],\nand computed the pdf's as:\ny1 = normpdf(x,mu1,sigma1)\ny2 = normpdf(x,mu2,sigma2)\ny3 = normpdf(x,mu3,sigma3)\nI averaged them together such that:\ny_final = (y1+y2+y3)./3\nMy question is how can I obtain the the mean and standard deviation of the y_final?\n\n\nSign in to comment.\n\nAccepted Answer\n\nDavid Goodmanson\nDavid Goodmanson on 5 Nov 2020\nHi Matthew,\nhere is an example, where mu and sigma are calculated by numerical integration. Also shown are analytical results for those, which agree with the numerical results. For the mean of y = (y1 +y2 +y3)/3,\nmu = (mu1 + mu2 + mu3)/3\nwhich is not a big surprise. The variance of y is\nvar = Integral (x-mu)^2*(y1 +y2 +y3)/3 dx\nIf y1 has mean mu1 and standard deviation sigma1 then the integral involving y1 above is\nsigma1^2 + (mu-mu1)^2\nand similarly for y2 and y3. The analytic expression for the variance and standard deviation is shown below.\nNote that none of these results has anything to do with whether or not the pdfs are normal distributions. The pdfs could be anything, not even of the same type (as long as each is normalized to 1), and the result is the same.\nxplot = -20:.001:38; % use plenty of points\ngrid on\nN = integral(@(x) y(x), -inf,inf) % should be 1\nmu = integral(@(x) x.*y(x), -inf,inf) % mean\nvar = integral(@(x) (x-mu).^2.*y(x),-inf,inf) % variance\nsig = sqrt(var) % standard deviation\n% analytical calculations of mu, variance, std deviation\nmus = [16 3 9];\nsigs = [ 2 1 3];\nmuA = (1/3)*sum(mus)\nvarA = (1/3)*(sigs(1)^2 + (mu-mus(1))^2 ...\n+ sigs(2)^2 + (mu-mus(2))^2 ...\n+ sigs(3)^2 + (mu-mus(3))^2)\nsigA = sqrt(varA)\nfunction a = y(x)\n% sum of three pdfs\nmus = [16 3 9];\nsigs = [ 2 1 3];\ny1 = normpdf(x,mus(1),sigs(1));\ny2 = normpdf(x,mus(2),sigs(2));\ny3 = normpdf(x,mus(3),sigs(3));\na = (1/3)*(y1+y2+y3);\n\n\nSign in to comment.\n\nMore Answers (0)\n\n\n\n\n\nCommunity Treasure Hunt\n\n\nStart Hunting!"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/176554/evaluate-arguments-in-a-curried-function-left-to-right\nText:\nI have an inner pattern\n\nf[g, n_] := inner\n\nand I want to define an outer curried pattern\n\nf[h, m_][f[g, n_]] := ...\n\nwhich has unrelated behaviour to f[g,n] and so should receive expression f[g,n] rather than inner. Alas, f[h,m][f[g,n]] is undesiredly first evaluated as f[h,m][inner]. How can I prevent Mathematica from evaluating the inner f[g,n] whilst still recognising a pattern for f[h,m_][..] without having to explicitly insert Hold into the outermost expression?\n\nOf course SetAttribute[f, HoldAll] doesn't work, and I can't exactly set an attribute for the experssion f[h].\n\nMy motivation: I'm creating inner \"functions\" with subscript \"arguments\", and I want to define an outer \"functional\" which also has subscript \"arguments\" which should start evaluating before the passed inner functions are evaluated.\n\n\nSubscript[g1, n_] := bad[n]\nSubscript[g2, n_] := bad[n] \n\nSubscript[h, m_][ Subscript[g_,n_] ] := good[g,m,n]\n\nI want the behaviourwhere $g1_n$ gives bad[n], but $h_m[g1_n]$ gives good[g1,m,n]. The above code instead gives $h_m[bad[n]]$.\n\nI notice that the last line of the above code doesn't affect the DownValues of Subscript:\n\n\n    {HoldPattern[Subscript[g1, n_]] :> bad[n], \n    HoldPattern[Subscript[g2, n_]] :> bad[n]}\n\nIs this at all possible?\n\n  \u2022 $\\begingroup$ @kglr Actually the \"inner\" arguments aren't declared verbatim (see my motivation) $\\endgroup$ \u2013\u00a0Anti Earth Jul 3 '18 at 14:24\n  \u2022 $\\begingroup$ @kglr Pardon the over-simplicity in the original statement of my problem - please see 'my motivation' $\\endgroup$ \u2013\u00a0Anti Earth Jul 3 '18 at 14:35\n  \u2022 $\\begingroup$ Some of us here think that using Subscript while defining symbols (variables) should be avoided. Subscript[x, 1] is not a symbol, but a composite expression where Subscript is an operator without built-in meaning. You expect to do $x_1=2$ but you are actually doing Set[Subscript[x, 1], 2] which is to assign a DownValues to the operator Subscript and not an OwnValues to an indexed x as you may intend. Read how to properly define indexed variables here $\\endgroup$ \u2013\u00a0rhermans Jul 4 '18 at 8:18\n  \u2022 $\\begingroup$ I agree, but I'm still looking to do it :) I can use /: to attach an OwnValues to x if that was really a problem $\\endgroup$ \u2013\u00a0Anti Earth Jul 4 '18 at 13:19\n\nWhen I run into problems like this, I workaround it by using ReplaceAll like so:\n\nrules = {\n  f[g, n_] :> inner,\n  f[h, m_][f[g, n_]] :> outer\n\nf[h, m][f[g, n]] //. rules\n\n(* outer *)\n\nThat's because while the standard evaluation procedure looks at elements before moving up, ReplaceAll works by first trying to match the whole expression before going deeper.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Works fantastic. I'll hopelessly wait a little longer for I accept this answer :) $\\endgroup$ \u2013\u00a0Anti Earth Jul 4 '18 at 16:30\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/24149/how-can-i-identify-that-a-restricted-variant-of-boolean-sat-remains-hard-or-not\nText:\nWhile I was studying SAT problem and its different instances, in Algorithms for the Satisfiability (SAT) Problem: A Survey by J. Gu et. al PDF, I came up with this variant (not mentioned there, but I though of it) and searched, but could not find anything useful.\n\nConsider this variant:\n\nSuppose $f$ is a boolean function in $n$ boolean variables, but with this extra property, that $f$ is increasing. I have thought of $n$ boolean variables, $X_1, \\ldots, x_n$ as representation of subsets of a set with $n$ elements, and if some subset like $X$ satisfies $f$, then all $Y$ s.t. $X \\subseteq Y$ satisfy $f$, too. What I want is finding the collection of all minimal $X$ where $f$ satisfies each of them, but not any $Z$ where $Z \\subsetneq X$?\n\nIs this problem still hard?\n\nIf I consider the $x_1, \\ldots, x_n$ as a number, then increasing property of $f$ helps solving it in polynomial time, just a binary search suffices! So, I made it a little bit harder.\n\nAny help, even offers of search terms is appreciated.\n\n  \u2022 $\\begingroup$ What is the problem you are trying to solve? Please specify it completely. You might also want to consult Schaefer's dichotomy theorem. $\\endgroup$ \u2013\u00a0Yuval Filmus Apr 27 '14 at 5:08\n  \u2022 $\\begingroup$ Thanks for your tip, it is of a great help. The problem is as stated, it is a theoretical curiosity, we have a boolean function $f$ in $n$ variables, and we want to find the smallest $X$ such that its binary representation as $x_1 , \\ldots , x_n$ satisfies $f$, with this in mind that $f$ is increasing, a term I use, is the problem still NP-hard? I think it is, but I cannot do the reduction since of this bothering increasing nature. By the way, your comment helps and I was introduced to some thing new. $\\endgroup$ \u2013\u00a0Ali Shakiba Apr 27 '14 at 5:28\n  \u2022 1\n    $\\begingroup$ It seems that this cs.stackexchange.com/questions/11558/\u2026 answers your question. Even monotone formulas are hard by a reduction from dominating set. $\\endgroup$ \u2013\u00a0Andrej Bauer Apr 27 '14 at 9:36\n  \u2022 $\\begingroup$ @AndrejBauer Thanks for the link, I shall think more about applying the method there to this instance. I will post it if I've found a proof. $\\endgroup$ \u2013\u00a0Ali Shakiba Apr 27 '14 at 9:42\n\nYour problem cannot be solved in polynomial time, for a boring reason: the size of the output might be exponential in the time of the input. Therefore, there is no hope for a polynomial-time algorithm.\n\nFor instance, consider the boolean function $f:\\{0,1\\}^n \\to \\{0,1\\}$ that outputs $1$ if its input vector has at least $n/2$ ones (i.e., its Hamming weight is at least $n/2$), and $0$ otherwise. This function can be represented by a polynomial-size monotone formula. However, there are exponentially many minimal $x$ such that $f(x)=1$. In particular, each $x$ of Hamming weight $n/2$ is such a minimal input, and there are ${n \\choose n/2} \\approx 2^n/\\sqrt{n}$ such inputs.\n\nSo, there's no hope.\n\nAs Andrej Bauer points out, a related problem (testing whether there exists an input of Hamming weight at most $k$ that causes the boolean function to output $1$) is also NP-complete; see Prove NP-completeness of deciding satisfiability of monotone boolean formula.\n\n  \u2022 $\\begingroup$ Thanks for both the reasoning and the link provided at the end of the answer. That's right. $\\endgroup$ \u2013\u00a0Ali Shakiba Apr 28 '14 at 6:34\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1486538/proving-an-asymptotic-relation/1486566\nText:\nI want to show that $$ \\sum_{k=1}^{n} k^{\\alpha} \\sim \\frac{n^{\\alpha+1}}{\\alpha+1} \\ \\ \\ \\ \\ \\ n\\to \\infty$$\n\nfor $\\alpha > -1$ . So I need to show that the following limit exists and is equal to $1$ : $$ \\displaystyle \\lim_{n \\to \\infty} \\frac{\\sum_{k=1}^{n} k^{\\alpha}}{\\frac{n^{\\alpha+1}}{\\alpha+1}} $$\n\nBecause $\\alpha > -1$, it is clear that the above limit is of the type $\\frac{\\infty}{\\infty}$. Here I have doubts about using the L'Hospital's rule, because that means differentiating with respect to the upper bound of the sum which is a discrete variable, then how shoud I proceed with the computation of this limit?\n\n\n  \u2022 $\\begingroup$ use euler mac-laurin summation formula $\\endgroup$ \u2013\u00a0tired Oct 18 '15 at 21:50\n  \u2022 1\n    $\\begingroup$ Or simply look at $$\\frac{1}{n^{\\alpha+1}}\\sum_{k = 1}^n k^\\alpha$$ and think Riemann sum. $\\endgroup$ \u2013\u00a0Daniel Fischer Oct 18 '15 at 21:54\n\nUse the inequality\n\n\nwhich holds because the middle term is an upper sum for the left integral and a lower sum for the right integral. Equality holds if and only if $\\alpha=0$. Now compute both integrals, divide throughout by ${n^{\\alpha+1}}$ and let $n\\to\\infty$.\n\nAs pointed out by the8thone, the above holds for $\\alpha\\geq 0$, and for $-1<\\alpha<0$ both inequalities are reversed, but the limits are still the same.\n\n  \u2022 $\\begingroup$ Thank you, however , the inequality you wrote is true for $\\alpha \\geq 0$, for $\\alpha < 0$ we have the reverse inequalty, which finally gives the desired answer. $\\endgroup$ \u2013\u00a0the8thone Oct 18 '15 at 22:16\n  \u2022 $\\begingroup$ You are absolutely correct. I'll fix it. $\\endgroup$ \u2013\u00a0uniquesolution Oct 18 '15 at 22:16\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/297250/how-many-naked-eye-stars-have-died-since-they-emitted-the-light-we-are-seeing\nText:\nThis question is sort of in the spirit of this xkcd:\n\nThe light we get from stars was emitted many years in the past, but the distances to stars which are bright enough to be visible to the naked eye are not that great, so the light we received likely wasn't emitted long enough ago that the stars would have undertaken significant changes.\n\nOn the other hand, some bright stars are red giants, which are very bright, very far away, and pretty close to the end of their lives, so there is a higher chance that they have collapsed in the meantime.\n\nSo: what numerical fraction of stars which are visible by naked eye are likely to have undertaken significant steps in their stellar evolution? Here I'm interested both in main-sequence stars evolving into red giants, giants undergoing collapse, and similar events. Similarly, how does this answer change if you increase the range to stars that are visible using a reasonable pair of binoculars?\n\nIn case special relativistic effects are important, for the purposes of this thread, both the current frame of reference of the solar system and the rest frame of the galaxy are interesting.\n\n  \u2022 $\\begingroup$ I'd say about 0% for stars going SNe. The few in our galaxy we think we'll go SNe 'soon' are $\\lesssim1000$ ly away and not expected to go off for a few hundred thousand years. $\\endgroup$ \u2013\u00a0Kyle Kanos Dec 7 '16 at 21:03\n  \u2022 $\\begingroup$ @KyleKanos Interesting. Null results are still answers, btw ;-). $\\endgroup$ \u2013\u00a0Emilio Pisanty Dec 7 '16 at 21:08\n  \u2022 $\\begingroup$ Probably, but I'm at work (using mobile) and that comment is half an answer b/c it doesn't address evolution (there could be some candidates for helium flash, not sure) $\\endgroup$ \u2013\u00a0Kyle Kanos Dec 7 '16 at 21:11\n  \u2022 $\\begingroup$ Oh, no pressure. Astronomy is a waiting game after all ;-). $\\endgroup$ \u2013\u00a0Emilio Pisanty Dec 7 '16 at 21:12\n  \u2022 $\\begingroup$ Just a comment, I suspect the fraction decreases with a reasonable pair of binoculars, and even more with a reasonable backyard telescope. You'll be able to see a few red dwarfs with binoculars, and quite a few more with a telescope. (Plus a bunch more G and K class stars.) Nothing's go to happen to those low mass stars (which represent ~95% of all stars) in a long, long time. $\\endgroup$ \u2013\u00a0David Hammen Dec 7 '16 at 21:23\n\nThere are about 10,000 naked-eye stars (likely optimistic). Typical distances are less than a kiloparsec (3000 light-years, see for example post by @RobJeffries). Red-Giants (RG) still have a lifetime of about 10 Million years*, so only something like $10^{-4}$ would have already \"died\"... which means even if every single naked-eye star were a RG, only about 1 of those 10,000 would likely have already died. So the answer is probably 0-1 stars.\n\nSince the list of naked-eye (ish) stars is compiled, it wouldn't be too hard to just go through and see which (if any) have a non-negligible probability of having died... would be a good class project for someone! This, of course, completely neglects binarity... which is hard to model, even in detail. Naively, I think binaries are more likely to extend lifetimes than shorten them, however - so that probably makes this estimate even more optimistic.\n\nIn regards to the change from using Binoculars instead: again this could be explored using the above-linked catalog but I suspect @DavidHammen is right (in the comments above) - that the bulk of stars that become visible with Binoculars are low-mass dwarfs, decreasing the fraction of likely-to-have-died-visible-stars, and negligibly increasing the total expected number of dead stars.\n\n*Regarding RG lifetime, I'm not finding any great sources for lifetimes, but 10 Myr is the number of remember offhand. It looks like that might be on the lower end---again making this estimate more optimistic.\n\n  \u2022 $\\begingroup$ I think 1 Myr is more realistic for red giant evolution. Main sequence lifetimes for the most massive visible stars eg. Gamma Vel, are already less than 10 Myr. $\\endgroup$ \u2013\u00a0ProfRob Dec 8 '16 at 0:05\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1664140/4-married-couples-and-2-single-men-will-sit-at-a-circular-table\nText:\n$4$ married couples and $2$ single men sit at a circular table. In how many ways can they sit so that a man can't sit next to a woman who is not his wife?\n\nI have tried but I am not sure to the following answer :\n\nFirst, the husbands sit in the circular table of which the possible ways is $3!$.\n\nThe wives should sit next to her husband which is only $1$ way.\n\nThe two men can only be put between two husbands in only $2$ ways and they then can be permuted in $2$ ways. So the number of ways is $4$.\n\nBy applying the multiplication principle, the total number of ways for this possibility is $3! \\times 4$ = $24$.\n\nThe second possibility is similar which is making the wives sit first and put each husband next to his own wife and then put the single men. The total number of ways is also $24$.\n\nSo the answer is $24 + 24 = 48$.\n\n\nAs each woman has two neighbors, one way to have a woman not sit next to a man who is not her husband is to line up husband$_1$ wife$_1$ wife$_2$ husband$_2$ twice. Then we have three ways to pair up the couples and two ways to flip each pair left/right. We might as well put the leftmost of the pair including husband A at seat $1$ to break the rotational symmetry. Then there are three groups of seats for the other married couple and a factor two for placing the single men. Total is $$3 \\cdot 2^2 \\cdot 3 \\cdot 2=72$$\nThe other way to deal with the women is to place all four together in some order, $4!$ ways and seat the husbands of the end ones next to them. Again break the symmetry by seating the leftmost woman in seat $1$. Now you can arrange the other four men any way you want, another $4!$ ways, giving $$4!^2=576$$ The total is then $$72+576=648$$\n\n  \u2022 $\\begingroup$ Do you think OP wants to consider rotational overcounts? $\\endgroup$ \u2013\u00a0K. Jiang Feb 20 '16 at 13:42\n  \u2022 $\\begingroup$ +1 for rechecking an earlier answer that had been wrong. $\\endgroup$ \u2013\u00a0Oscar Lanzi Feb 21 '16 at 3:38\n\nI get 648.\n\nThe women must sit in two pairs of adjacent seats, and if the pairs are separated there must be at least two intervening positions (for different husbands) in each direction.\n\nThis leads to three distinct arrangements for the women: 1-2-3-4, 1-2-5-6, 1-2-6-7. In the first case two men must sit next to their respecive wives in positions 5 and 10, while the other four men sit in any fashion that choose in positions 6-7-8-9. Thus 24\u00d724 = 576 permutations. For the second arrangement of the women, all four husbands must sit next to their wives leaving only the two single men with any free choice. Thus 24\u00d72 = 48 permutations.\n\nThe third female arrangement is tricky, in fact I had to edit my answer because I got it wrong the first time. If we count 24 permjtations for the women and two for the single men we seem to get 48. But because the women (and their husbands) are in a twofold rotationally symmetric arrangemet only half of these 48 are actually distinct. So we can really count only 24 additional permutations to go with the 576+48 from the other cases. Total: 648.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/307752/2d-elastic-collision-in-the-center-of-mass-frame-of-reference/307799\nText:\nIn a collision between two spheres $A$ and $B$, their velocities are symmetric ($v$ and $-v$, respectively) in the center-of-mass frame of reference. The final speed of $A$ does a $45\u00b0$ angle with its initial velocity.\n\nDetermine the final speed of the spheres if the collision is elastic, in the frame of reference where the sphere B is initially at rest.\n\nHow do I solve this? I am not used to solve these problems with the center-of-mass frame of reference.\n\n\nThe centre of mass frame information is there to give you some information about the relative masses of the two spheres and the initial speed of sphere $A$ in terms of speed $v$.\nThe rest of the problem can then be done in the reference frame of sphere $B$ which you would have done many times before.\n\nIf you decide correctly about the relative masses the problem can be solved fairly easily by writing the conservation of kinetic energy equation from which the shape of the momentum vector addition triangle can be inferred.\n\n\nFinish the calculation in the CoM frame of reference. That is the frame in which the problem is set.\n\nThen transform from the CoM frame to the frame of reference in which B is initially at rest by adding the reverse of the initial velocity vector of B (ie $-\\vec{u_B}=+\\vec{v}$) to each of the final velocities in the CoM frame.\n\nThe wording of the question does not make clear whether the collision is elastic in the CoM frame or in the frame in which B is initially at rest. Does this matter? No. The amount of KE each sphere has depends on which frame you are measuring it in, but the fact that total (kinetic) energy is conserved in the collision does not depend on which frame of reference you are using. If the collision is elastic in the CoM frame, it is elastic in the rest frame of B also.\n\n  \u2022 $\\begingroup$ Why do we transform in the COM frame tho.....is it because of it being momentum conserved frame and elastic collision is known to have its momentum conserved so why do we have to change back then $\\endgroup$ \u2013\u00a0user195235 Aug 15 '18 at 11:25\n  \u2022 $\\begingroup$ @user195235 The COM frame is specified in the question, so we have to use it to solve the problem. And we have to change to another frame because that is what the question asks for. However, generally there is no requirement to use one frame or another if the question does not require it. You can use whatever frame you find convenient. The COM frame sometimes makes the problem easier. In other cases the solution might be obvious or more intuitive in a non-inertial frame of reference. $\\endgroup$ \u2013\u00a0sammy gerbil Aug 19 '18 at 17:35"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/69910/how-to-solve-this-partial-order-reduction-in-on2/69934\nText:\nThere are two orderings of numbers from the same set. Number $a$ is \"immediately before\" $b$ iff $a$ appears before $b$ in both sequences and there is no other number that appears between them in both sequences.\n\nSo in this example:\n\nSeq 1: 1 2 3 4 5 6\nSeq 2: 6 2 1 3 5 4\n  \u2022 1 is not immediately before 2 because they appear in opposite orders.\n  \u2022 1 is not immediately before 4 because 3 appears between them in both sequences.\n  \u2022 2 is immediately before 3 and 3 is immediately before 4.\n\nThe problem is to find all pairs $a$, $b$ such that $a$ is immediately before $b$ in $O(n^2)$ time. How can this be done?\n\nI understand that the naive solution can work in $O(n^3)$: For each pair in the first sequence ($n^2$ pairs) verify it using the second sequence ($O(n)$ time).\n\n\nYour solution looks good to me, except that your lookup arrays are a bit handwavy: What happens if the set contains negative numbers? Or what if it contains an extremely large number ($\\gg n^2$), so that the arrays would need to be massive?\n\nTo address this, I'd suggest creating just a single lookup table, that instead of mapping from values to indices, maps from indices in one sequence to indices in the other. Thus seq2[i] = seq1[translator[i]]. You can build that table in $\\mathcal{O}\\left(n^2\\right)$ time using nested loops. You can then ignore seq1 and seq2 in all of your logic: the problem becomes, \"find all pairs of indices (i, j) such that i < j, that translator[i] < translator[j], and that i < k < j precludes translator[i] < translator[k] < translator[j]\" (which you can solve using basically the same approach as what you've written). The only time you'd refer to seq1 or seq2 again is when you're adding an entry to the result (since for that you want the actual values rather than the indices).\n\n\nI think I am able to solve it.\n\nFirst, have a lookup array for each sequence where array[element] = element's position in sequence [O(1)].\n\nPhrased another way, this algorithm will find all \"successors\" for each of the elements in the first sequence. Finding successors for each element will take O(n) time.\n\nFor i in range(0,n):\n    initialize most_recent_successor to None\n    For j in range(i+1, n):\n        if pos. of seq_1[j] > pos. of most_recent_successor in both sequences:\n            advance j\n            most_recent_successor = seq_1[j]\n            add (seq_1[i], seq_1[j]) to result\n\nEssentially, if a valid pair (seq_1[i], seq_1[j]) exists, then any pair (seq_1[i], seq_1[k]) will not be valid if the position of seq_1[k] in comes after the position of seq_1[j] in both sequences.\n\nSo, for the example in the question, (1, 3) is a valid pair. Therefore, (1,4) and (1, 5) are not valid pairs since 4 and 5 come after 3 in both sequences.\n\nEdit: Please look at ruakh's insightful answer on lookup arrays I used here.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/double-integral.349791/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nDouble Integral\n\n  1. Oct 28, 2009 #1\n    I need to find the area of the hyperbolic paraboloid z=xy contained within the cylinder x^2+y^2=1. I know I need to take a double integral but am having real difficulty finding the correct limits, so far I've got that;\n\n    [tex]\\int dx[/tex][tex]\\int dy[/tex]\n\n    With the x limits being 1 and -1 and the upper y limit to be sqrt(1-x^2) I'm having trouble finding the lower y limit. Although to be honest I'm not completely sure about the other three limits! Sorry about my awful attempt at Latex-ing I don't know how to do it so couldn't write the limits of the integrals on the integral. Any help would be great! Thanks.\n  2. jcsd\n  3. Oct 29, 2009 #2\n    the problem is symmetric by pi/2 so I'd just stick to the (+,+) quadrant and your lower limit is y=0. Then your x limits would be 1 and 0.\n\n    The area in the entire domain is then four times the area in a single quadrant.\n  4. Oct 29, 2009 #3\n\n\n    User Avatar\n    Science Advisor\n\n    I have no idea what you mean by\n    Shouldn't there be some function to be integrated in that? And it probably is NOT\n    [tex]\\int dx\\int dy[/tex]\n    but rather\n    [tex]\\int f(x,y) dxdy[/tex]\n    Even ignoring the \"f(x,y)\" the two separate integrals implies that the two coordinates can be separated- which is not the case here- at least not in Cartesian coordinates.\n\n    The surface area of z= f(x,y) is given by\n    [tex]\\int\\int \\sqrt{1+ \\left(\\frac{\\partial f}{\\partial x}\\right)^2+ \\left(\\frac{\\partial f}{\\partial y}\\right)^2} dA[/tex]\n    where dA is the differential of area in whatever coordinate system you are using, in the xy-plane. Because of the circular symmetry I would recommend changing to polar coordinates- where the two coordinate variables can be separated."}
{"text": "Retrieved from https://www.physicsforums.com/threads/orbital-mechanics.839274/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nOrbital mechanics\n\n  1. Oct 23, 2015 #1\n    I'm having trouble with orbItal mechanics, I'm trying to determine the total potential energy of an orbiting satellite, what I've done so far is this:\n    I know m*g*h is potential energy, but I also know that gravity deceases with distance avoiding to the inverse square law. I know I Just can't use the satellites current Ag because that will increase as it falls towards the earth, and I'm having trouble determining exactly what that is.\n    This is giving me serious trouble because I want to calculate periapsis or apoapsis given just one of those two, and the velocity at that point.\n  2. jcsd\n  3. Oct 23, 2015 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    The gravitational potential energy of an orbiting body is different from mgh, which applies only to something located close to the surface of a planet, like earth.\n\n\n    U = -GMm / r\n\n\n    M - Mass of the planet, kg\n    m - mass of the orbiting body, kg\n    G - Universal Gravitational Constant = 6.67408 \u00d7 10-11 m3/kg-s2\n    r - distance between the centers of mass of M and m, in meters\n    U - gravitational potential energy (= 0 when r \u2192 \u221e)\n  4. Oct 23, 2015 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'd make one adjustment to SteamKing's equation. Use specific energy per unit of mass.\n\n    F= -GMm/r^2\n    therefore, a=GM/r^2\n\n    All objects accelerate at the same rate (due to gravity).\n\n    Since it's the motion you're interested in, you can do the same with the energy (divide out the mass). And, if you do need to know the energy (to determine how much fuel to do a delta V, for example), you just multiply the specific energy (or the change in specific energy) by the mass when you need that info.\n\n    Likewise, your specific kinetic energy would be (v^2)/2. And your total specific energy would be (GM)/(-2a), where a is the semi-major axis of your orbit.\n\n    Given that you mentioned Earth, I assume you're talking about a satellite orbiting Earth? The universal gravitational constant and the mass of the Earth are constant. Once you've multiplied them together once, you can just remember the answer. You can even look up the answer in a book. It's your geocentric gravitational constant (3.986 x 10^5 km^3/sec^2).\n  5. Oct 28, 2015 #4\n    Is it really that simple? It makes sense but It seems too simple. I came up with that about two weeks ago but I didn't believe myself when I did it. I guess I'll just have to launch a scientific mission in KSP to verify it.\n  6. Oct 28, 2015 #5\n    Wait, that doesn't make sense, by getting higher your potential energy decreases? And in a higher orbit you move slower so your kinetic energy decreases too, that can't be right.\n    I'm looking for \u03a3 specific potential energy, our the whole of all the specific kinetic energy that would be gained from a fall of such altitude.\n  7. Oct 28, 2015 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    First, you were looking for orbital elements; now, you're looking for the K.E. a satellite gains by falling out of orbit.\n\n    This article discusses orbital mechanics in some detail:\n\n\n    This article talks about the relationship between gravitational P.E. into K.E. for an orbiting body:\n\n  8. Oct 28, 2015 #7\n    No. Notice the minus sign in front of the expression fro PE.\n    The PE increase as you go higher, the maximum value being zero. This is so because the reference is chosen to be at infinite distance.\n  9. Oct 28, 2015 #8\n    I don't see how my request has changed. if an object has 25,000,000 Joules of kinetic energy when it impacts, then it must have had 25,000,000 Joules of potential energy when it began to fall. I am just looking for the potential energy of an object in freefall beginning at a distance where the gravitational inverse-square law becomes relevant, as I always have been. maybe I was sloppy with my wording before, but I truly do not see a difference between what I was originally asking for and the description you gave here.\n  10. Oct 28, 2015 #9\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    The gravitational inverse square law is always relevant, regardless of distance. After all, this law still works between Pluto and the Sun, even though these two bodies are separated by a distance of some 4.5 billion kilometers.\n\n    If you want to calculate the periapsis or apoapsis of an orbiting body, then application of Newton's laws of motion can tell you this.\n\n    If you want to calculate the impact energy of a body falling out of orbit, a different application of the same laws is required.\n\n    Depending on the problem you want to solve, you have to tailor the analysis to obtain the solution. It is not immediately obvious how knowing the periapsis of an orbiting body will necessarily convert into the K.E. of that body hitting the ground.\n  11. Oct 28, 2015 #10\n\n\n    User Avatar\n    Science Advisor\n\n    No, it must have had 25,000,000 more Joules of potential energy when it began to fall than when it impacts. Zero is 25,000,000 more than -25,000,000.\n  12. Oct 28, 2015 #11\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    The total orbital energy of your satellite is the sum of it's kinetic and potential energies.\n    KE = mv2/2\n    GPE = - GMm/r\n    (note since r is measured from the center of M, working out the potential energy difference between the satellite in orbit vs on the ground means solving the following\n    [tex]\\Delta GPE = \\frac{GMm}{r_E}- \\frac{GMm}{r_o}[/tex]\n\n    Where rE and ro are the Earth's radius and orbit radial distance\n\n    Now, to get to your orbital question:\n\n    We start with:\n\n    (1)[tex]E= \\frac{mv^2}{2}- \\frac{GMm}{r}[/tex]\n\n    If we assume a circular orbit, we know that [itex]v= sqrt{\\frac{GM}{r}}[/itex]\n\n    subbing for v, and reducing the equation gives\n\n    (2)[tex]E=- \\frac{GMm}{2r}[/tex]\n\n    It also turns out that this equation holds for elliptical orbits if we use a, the semi-major axis for r:\n\n    (3)[tex]E=- \\frac{GMm}{2a}[/tex]\n\n    If we equate equation 1 and 3 and solve for a, we get\n\n    [tex]a =\\frac{1}{\\frac{2}{r}-\\frac{v^2}{GM}}[/tex]\n\n    which gives us the semi-major axis if we know the velocity at r\n    (This last equation is a re-arrangement of the vis viva equation)\n\n    Now its just a simple case of knowing that\n\n    [tex]a= \\frac{r_{per}+r_{app}}{2}[/tex]\n\n    to find either apogee or perigee if you know the other and the velocity at it."}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-harmonic-motion-inside-earth.164142/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Harmonic Motion Inside earth\n\n  1. Apr 4, 2007 #1\n    A particle is dropped into a hole drilled straight through the center of the Earth. Neglecting rotational effects, show that the particle's motion is simple harmonic if you assume Earth has uniform density. Show that the period of the oscillation is about 84 min.\n\n    2. Relevant equations\n    [tex]F = -G m \\int_V \\frac{\\rho(r') e_r}{r^2}dv'[/tex]\n\n    3. The attempt at a solution\n\n    I was going to use Newton's second law to show that\n    [tex] m \\frac{d^2 r}{dt^2} = -G m \\int_V \\frac{\\rho(r') e_r}{r^2}dv'[/tex]\n\n    Where the volume integral should produce some function of r. So, I started off the integration by choosing an arbitrary point in the sphere a distance r' away, and using R as the distance from the origin to the point mass, r as the distance between the arbitrary distance and the distance of the point mass, theta as the asimuthal angle, and phi as the rotational angle I got.\n\n    [tex]m \\frac{d^2 r}{dt^2} = -G m \\int_0^{R} \\int_0^\\pi \\int_0^{2\\pi} \\frac{\\rho r'^2 sin\\theta}{r^2}dr' d\\theta d\\phi[/tex]\n\n    integrating with respect to phi brings in a factor of 2\u03c0, and now I used law of cosines\n\n    [tex]r^2 = r'^2 + R^2 - 2r'Rcos\\theta[/tex]\n\n    [tex] 2r dr = 2r'Rsin\\theta d\\theta[/tex]\n\n    [tex]\\frac{sin\\theta}{r}d\\theta = \\frac{dr}{r'R}[/tex]\n\n    so the substitute the law of cosines stuff into the force equation\n\n    [tex]F = \\frac{-2 \\pi G m \\rho}{R} \\int_0^R r'^2 dr \\int_{r'-R}^{r'+R} \\frac{1}{r}dr[/tex]\n\n    doing the r' integral I can see that this ultimately won't give a linear function of R\n\n    [tex]\\frac{2 \\pi}{3} \\frac{G m \\rho}{R} R^3 \\int_{r'-R}^{r'+R} \\frac{1}{r}dr [/tex]\n\n    Can someone help me out, point out what I did wrong, put me on the right track?\n\n    I think that once I find the right equation for force, which I actually know from experience should be [tex]F(r) = -\\frac{4 \\pi}{3}G m r \\rho[/tex], that I can do the differential equation stuff.\n  2. jcsd\n  3. Apr 5, 2007 #2\n    You're making it too complicated. Assume that the density of the earth is a constant function, and realize that because of the character of the 1/r^2 force law, you can turn this into a surface integral. Once you do that, you're golden.\n  4. Apr 5, 2007 #3\n\n\n    User Avatar\n    Gold Member\n\n    At any point in the fall, the only mass exerting a nett force on the test body is that contained inside the current radius because the shell of matter outside the radius has no effect. So the force at point x is\n\n    [tex]F(x) = -\\frac{4}{3}\\pi Gm\\rho x^3/x^2[/tex]\n\n    which gives\n\n    [tex]F(x) = -Kx[/tex]\n\n    QED I think. Assuming uniform density.\n    Last edited: Apr 5, 2007"}
{"text": "Retrieved from https://www.physicsforums.com/threads/coupled-oscillator.330209/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCoupled Oscillator\n\n  1. Aug 11, 2009 #1\n\n\n    User Avatar\n\n\n    One mass [itex]m[/itex] constrained to the x-axis, another mass [itex]m[/itex] constrained to the y-axis. Each mass has a spring connecting it to the origin with elastic constant [itex]k[/itex] and they are connected together by elastic constant [itex]c[/itex]. I.e. we have a right-angle triangle made from the springs with lengths [itex]b[/itex], [itex]b[/itex], and [itex]\\sqrt{2} b[/itex].\n\n    Write the Lagrangian, find the normal mode frequencies.\n\n    3. The attempt at a solution\n\n    Again having trouble with the coupling. For the two springs connected to the origin the potentials are straightforward:\n\n    [tex]V = \\frac{1}{2} k x^2 + \\frac{1}{2} k y^2[/tex]\n\n    Given the geometry wouldn't the coupling spring add the potential,\n\n    [tex]V = \\frac{1}{2} c \\left [ \\sqrt{x^2 + y^2} - \\sqrt{2} b \\right ]^2 = \\frac{1}{2} c \\left [ x^2 + y^2 - 2 \\sqrt{2 x^2 + 2 y^2} + 2 b^2 \\right ][/tex]\n\n    But I don't know how to put this in matrix form...\n    Last edited: Aug 11, 2009\n  2. jcsd\n  3. Aug 11, 2009 #2\n    I reworked the problem and got the same potential as you, so it looks like you do indeed have the spring interaction potential correct. It looks a bit pesky because of the presence of the square root. This would make a closed form solution a bit difficult.\n\n    I did think of a potential trick you could use (I don't remember if I read this in a textbook or came up with it myself...hopefully the former). You could try converting to polar coordinates with,\n\n    [tex]x = r cos(\\theta)[/tex]\n    [tex]y = r sin(\\theta)[/tex]\n\n    Be careful here, because in this context [tex]r[/tex] and [tex]\\theta[/tex] don't have any physical meaning; it's merely a math trick. You can then rewrite the Lagrangian with these new generalized coordinates. If my algebra/calculus are right, you should get the following set of differential equations:\n\n    [tex]m\\ddot{r} = -(k + c)r + cb[/tex]\n    [tex]\\ddot{\\theta} = 0[/tex]\n\n    This seems comparatively a lot easier than what you would likely get by writing the Lagrangian using the generalized coordinates that you were working with. And the first differential equation looks like it will give you the oscillatory motion (without damping) that you would expect. After you solve for the two coordinates, you can transform back into the coordinates given in the problem.\n\n    Disclaimer: I don't know if this method will work, and indeed I see one potential pitfall. When you transform into polar coordinates, you get the weird effect of [tex]\\theta = \\theta + 2\\pi[/tex]. I normally leave it to the mathematicians to prove that physics math tricks actually work, but in this case I could see this as possibly being the cause of an incorrect solution. But hey, try it out and see what happens\n  4. Aug 11, 2009 #3\n\n\n    User Avatar\n\n    Thanks for your insight. I may have misled you into thinking I needed to the differential equations because I asked for the Lagrangian. I'm trying to get the normal mode frequencies by solving the eigenvalue problem.\n\n    I was thinking your trick might help still but it seems [itex]\\theta[/itex] drops out of the expression for V.\n\n    [tex]T = \\frac{1}{2} m \\dot{r}^2[/tex]\n\n    [tex]V = \\frac{1}{2} c (r^2 - 2 \\sqrt{2} r)[/tex]\n\n    (constant term dropped in V)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/spring-with-mass.127950/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSpring with Mass\n\n  1. Aug 3, 2006 #1\n    Suppose a spring with mass m and length L is connected to a rigid wall and a mass of M. Assuming no damping how do we find the frequency?\n\n    for the spring Density = m/L = D; dm = D dx\n    I don't know where to go from there.\n  2. jcsd\n  3. Aug 3, 2006 #2\n    The effective mass of a spring undergoing oscillatory motion is considered\n    to be 1/3 the mass of the spring. For any portion of the spring the\n    KE of dm is 1/2 dm * v^2. For a spring fixed at one end the velocity of an\n    element dm will be proportional to the distance from the fixed end - so\n    v = V*(y/Y) where Y is the length of the spring and V is the velocity of the moving end. Also, you can write dm = M * (dy/Y). Using these values\n    integrate 1/2 v^2 dm over the length of the spring to get the KE of the\n    oscillating spring and determine the effective mass of the spring.\n  4. Aug 5, 2006 #3\n    Thanks, I understand now."}
{"text": "Retrieved from https://www.physicsforums.com/threads/probability-choice-of-boxes.303637/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nProbability: choice of boxes\n\n  1. Mar 30, 2009 #1\n    hi, I am writing a computer algorithm which descibes the change of choice.\n\n    1.your friend puts $10 in a box among three (there are three boxes) but you don't know which.\n    2.you choose one of them but do not open it.\n    3.your friend opens (eliminates) one of empty boxes\n    i.e. if you choose the lucky box, he eliminate either one of two empty boxes at equal probability\n    and if you choose an unlucky one, he eliminates the empty remainder.\n    4.then you decide, whether or not you change your choice between two remainings.\n    5.repeat 1~4 many times and expect the maximum result(in $).\n\n    Question: you'd better change your choice? or should not change? for the maximum outcome.\n\n    I expected that the change of choice should not matter: the equal probabilities.\n\n    but my computer algorithm tells that \"if you change the choice, better\"\n\n    Can someone tell me whether I am wrong or my algorithm is wrong?\n  2. jcsd\n  3. Mar 30, 2009 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The algorithm is right. Search for Monty Hall problem (here or on the search engine of your choice). It's a popular topic. In short: picking the remaining box is really as good as picking both remaining boxes, and there's a better chance it's in one of the two remaining boxes than in your original 1.\n  4. Mar 30, 2009 #3\n    Thank you for such a quick reply!\n    I will check it out. but your explanation helped a lot, CRGreathouse!"}
{"text": "Retrieved from http://math.stackexchange.com/questions/97602/finding-the-minimum-grade/97606\nText:\nTake the 2-minute tour \u00d7\n\nProfessor sent the following data to his students: Full Grade: 25, Max. grade: 22.5, Mean: 19.9, Median: 20\n\nAssuming the number of students is n. Is it possible to calculate the minimum grade from the given data only?\n\nshare|improve this question\nPS: you may know some of other students' grades. For example you heard that student x1 got 21, another student x2 got 18 and so on .. but you don't know all the students' grades of course \u2013\u00a0 Osama Gamal Jan 9 '12 at 11:27\nWhat does \"full grade\" mean? \u2013\u00a0 Dan Brumleve Jan 9 '12 at 11:29\n@Dan Probably \"Full Grade\" is the maximum grade you can get in the exam. For instance there are 5 questions 5 points each. \u2013\u00a0 marvinthemartian Jan 9 '12 at 11:36\n@marvinthemartian, is that information relevant? \u2013\u00a0 Dan Brumleve Jan 9 '12 at 11:38\n@Dan Frankly, I do not think it is. But I do not know the answer yet, so maybe. \u2013\u00a0 marvinthemartian Jan 9 '12 at 11:41\nshow 2 more comments\n\n2 Answers\n\nThe answer is no. Let us look for an easier example:\n\nAssume $n=5$, our students are called \"A\",\"B\",\"C\",\"D\",\"E\" and the grades are given by:\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 2&1&1&1&0 \\end{array}\n\nClearly Maximum, Median and Mean are given by {2,1,1}. But the dataset\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 2&1&1&1/2&1/2 \\end{array}\n\nAlso has the same Mean, Median and Maximum. You can always do this by using a convex combination of the last two values as long as they stay below the median. They will not affect the median, nor the mean or the maximal element but they will change the minimal grade given.\n\nEdit: Now with this knowledge we can come back to your question and easily construct a counterexample flor $n=5$:\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 22.5&20&20&20&17 \\end{array}\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 22.5&20&20&19&18 \\end{array}\n\nThose do both fit to your data. For higher $n$ you can pad with the mean $19.9$ on the left and right side of the median (odd $n$). For even $n$ there is a similar counterexample. For $n \\in \\{3,4\\}$ refer to the answer given by tom.\n\nshare|improve this answer\nadd comment\n\nI don't believe so, not for general n at least. We can for some isolated cases:\n\nFor $n = 2$, the problem simply doesn't work\n\nFor $n = 3$, we need one student to get 22.5, another student to get 20, and the other to get $s_3$ so that:\n\n$$\\frac{22.5+20+s_3}{3}=19.9$$ Which works out for $s_3=17.2$, the minimum grade\n\nFor $n=4$, lets say we have 4 students with 4 grades $s_1 \\geq s_2\\geq s_3\\geq s_4$. We know then that $s_1=22.5$, that: $$\\frac{s_2+s_3}{2}=20$$\n\nand $$\\frac{22.5+s_2+s_3+s_4}{4}=19.9$$ We can then solve this for $s_4$ using the fact that $s_2+s_3=40$ to get $s_4=17.1$.\n\nHowever, for $n=5$, we run into difficulties. We know (using the same system of notation) that $s_1=22.5$, and that $s_3=20$, but beyond that, the fact that\n\n\nWill never allow us to say any more about $s_5$. Indeed, this is true for any $n\\geq5$ (is this clear?).\n\nshare|improve this answer\nNote that you are searching for integer numbers (for simplification since grades can only be x.0 or x.5) and note that s_2 > s_4 > s_5 \u2013\u00a0 Osama Gamal Jan 9 '12 at 12:17\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/131678/positive-series-problem\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\sum\\limits_{n\\geq1}a_n$ be a positive series, and $\\sum\\limits_{n\\geq1}a_n=+\\infty$, prove that: $$\\sum_{n\\geq1}\\frac{a_n}{1+a_n}=+\\infty.$$\n\nshare|improve this question\nPlease try to add in the question as to what progress you have made. People here will help you build up on that. \u2013\u00a0 user9413 Apr 14 '12 at 11:20\nThis is a question in the text book in Rudin's Principles of Mathematical Analysis. \u2013\u00a0 Riemann Apr 14 '12 at 11:29\nfantastic. thanks for referring to the book. \u2013\u00a0 vondip May 18 '13 at 11:18\nadd comment\n\n5 Answers\n\nup vote 9 down vote accepted\n\nProving the contrapositive statement seems cleaner to me. Suppose $\\sum{a_n\\over 1+{a_n}}$ converges. Then ${a_n\\over 1+\\color{maroon}{a_n}}\\rightarrow 0$. This implies that $\\color{maroon}{a_n}$ is eventually less than one, so ${a_n\\over2}\\le {a_n\\over a_n+1}$ for $n$ sufficiently large. The comparision test then shows that $\\sum a_n$ converges.\n\nshare|improve this answer\nHow do you prove a(n) is less than one ? If a(n) is bounded you can multiply and divide a(n) by 1+a(n) and you get bounded multiplied by a factor which converges to zero, then a(n) converges to zero ad you continue in that way ypu wrote. \u2013\u00a0 alpha.Debi Apr 14 '12 at 13:31\n@alpha.Debi $${a_n\\over 1+a_n}<{1\\over2}\\ \\Longrightarrow\\ a_n<{1\\over2}+{a_n\\over2}\\ \\Longrightarrow\\ {a_n\\over2}<{1\\over2}\\ \\Longrightarrow\\ {a_n<1}.$$ \u2013\u00a0 David Mitra Apr 14 '12 at 13:34\nNice proof (all the proof) , thanks. \u2013\u00a0 alpha.Debi Apr 14 '12 at 13:38\nThank you for your answer, your answer is always nice!!! \u2013\u00a0 Riemann Apr 14 '12 at 14:06\nadd comment\n\nI would argue by cases.\n\nCase 1. $a_n\\ge1$ for infinitely many $n\\in\\mathbb N$.\n\nIn this case, for each such $n$ we have $\\frac{a_n}{1+a_n}=1-\\frac{1}{1+a_n}\\ge1-\\frac12$, from which the claim easily follows.\n\nCase 2. $a_n\\ge1$ for only finitely many $n\\in\\mathbb N$.\n\nIn this case for every other $n$ we have $a_n<1$ and thus $\\frac{a_n}{1+a_n}\\ge\\frac{a_n}{1+1}=\\frac{a_n}2$. Since finitely many terms can't affect the convergence/divergence of a series, this will also diverge. (Since $\\sum\\limits_{n=1}^\\infty\\frac{a_n}{2}$ does.)\n\nshare|improve this answer\nadd comment\n\nAlternatively, split the problem up in cases:\n\n1, If there is a natural $N\\in\\mathbb{N}$ s.t $a_n\\leq{1}$ for $n\\geq N$, what can you conclude?\n\n2, If (1) is not true, for every natural $N$ we can find a $n\\geq{N}$ s.t $a_n>1.$ Now passing to a subsequence and comparing with a series with each term equal to a constant (more precisely $1/2$ or lower), the result follows.\n\nshare|improve this answer\nadd comment\n\nYou can suppose that $(a_n) \\rightarrow 0$ (if not the problem is trivial). Then what can you say asymptotically about $\\frac{a_n}{1+a_n}$ ?\n\nshare|improve this answer\nadd comment\n\nWe can divide into cases:\n\n  1. If a(n) has limit zero : It is lower than 1 for all n bigger than n0, then we can compare with a(n)/2 which is lower than a(n)/(1+a(n)).\n\n  2. If a(n) has limit different to zero , also a(n)/1+a(n) and then the series diverges\n\n  3. If a(n) is not bounded it ha a subsequence that converges to infinite, then a(n)/1+a(n) converges to 1 then the series diverges to infinite.\n\n  4. If a(n) is bounded , we can take a subsequence that is convergent.\n\nIf it does not converges to zero also the sequence a(n)/1+a(n). If all subsequences converge to zero ,then also a(n) and we can apply 1.\n\nshare|improve this answer\nWe can restrict to the last two cases but I started with the most common to think about. \u2013\u00a0 alpha.Debi Apr 14 '12 at 12:14\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.co.kr/kr/help/optim/ug/two-dimensional-semi-infinite-constraint.html?s_tid=gn_loc_drop&nocookie=true\nText:\nDocumentation Center\n\n  \u2022 Trial Software\n  \u2022 Product Updates\n\nTwo-Dimensional Semi-Infinite Constraint\n\nFind values of x that minimize\n\nf(x) = (x1 \u2013 0.2)2 + (x2\u2013 0.2)2 + (x3\u2013 0.2)2,\n\n\nfor all values of w1 and w2 over the ranges\n\n1 \u2264 w1 \u2264 100,\n1 \u2264 w2 \u2264 100,\n\nstarting at the point x\u00a0=\u00a0[0.25,0.25,0.25].\n\nNote that the semi-infinite constraint is two-dimensional, that is, a matrix.\n\nFirst, write a file that computes the objective function.\n\nfunction f = myfun(x,s)\n% Objective function\nf = sum((x-0.2).^2);\n\nSecond, write a file for the constraints, called mycon.m. Include code to draw the surface plot of the semi-infinite constraint each time mycon is called. This enables you to see how the constraint changes as X is being minimized.\n\nfunction [c,ceq,K1,s] = mycon(X,s)\n% Initial sampling interval\nif isnan(s(1,1)),\n   s = [2 2];\n\n% Sampling set\nw1x = 1:s(1,1):100;\nw1y = 1:s(1,2):100;\n[wx,wy] = meshgrid(w1x,w1y);\n\n% Semi-infinite constraint \nK1 = sin(wx*X(1)).*cos(wx*X(2))-1/1000*(wx-50).^2 -...\n\n% No finite nonlinear constraints\nc = []; ceq=[];\n\n% Mesh plot\nm = surf(wx,wy,K1,'edgecolor','none','facecolor','interp');\ncamlight headlight\ntitle('Semi-infinite constraint')\n\nNext, invoke an optimization routine.\n\nx0 = [0.25, 0.25, 0.25];    % Starting guess\n[x,fval] = fseminf(@myfun,x0,1,@mycon)\n\nAfter nine iterations, the solution is\n\nx =\n    0.2522    0.1714    0.1936\n\nand the function value at the solution is\n\nfval =\n\nThe goal was to minimize the objective f(x) such that the semi-infinite constraint satisfied K1(x,w)\u00a0\u2264\u00a01.5. Evaluating mycon at the solution x and looking at the maximum element of the matrix K1 shows the constraint is easily satisfied.\n\n[c,ceq,K1] = mycon(x,[0.5,0.5]);  % Sampling interval 0.5\n\nans =\n\nThis call to mycon produces the following surf plot, which shows the semi-infinite constraint at x.\n\nWas this topic helpful?"}
{"text": "Retrieved from http://mathoverflow.net/questions/7039/typical-value-of-totient-function\nText:\nTake the 2-minute tour \u00d7\n\nCan anyone tell me what the expected value of Euler's totient function \u03c6$(n)$ is (roughly) if you choose a random integer $n$ in the range $[N,N+M]$, where $M$ is large and $N$ is larger than $M$? (I think of $M$ as being $cN$ for some small constant $c$, which, if one wanted an answer accurate to $1+o(1)$, would in reality be a slowly decreasing function of $N$.)\n\nshare|improve this question\nIIRC Hardy and Wright says a lot about average values of arithmetic functions such as as phi. (there's a chapter or two on it). \u2013\u00a0 Kevin Buzzard Nov 28 '09 at 11:59\nadd comment\n\n2 Answers\n\nI've just realized I was being a little bit slow. I had already found on the internet that $n^{-2}\\sum_{k=1}^n&phi;(k)$ is roughly $3/&pi;^2$ and stupidly didn't notice that I could \"differentiate\" this to get exactly what I want. That is, $\\sum_1^N &phi;(k)$ is about $3N^2/&pi;^2$, so the difference between the sum to $N+M$ and the sum to $N$ is around $6NM/&pi;^2$, from which it follows that the average value near $N$ is around $6N/&pi;^2$, which is entirely consistent with the well-known fact that the probability that two random integers are coprime is $6/&pi;^2$.\n\nI'm adding this paragraph after Greg's comment. To argue that the probability that two random integers are coprime, you observe that the probability that they do not have p as a common factor is (1-1/p^2). If you take the product of that over all p then you've got the reciprocal of the Euler product formula for \u03b6(2), or 1^{-2}+2^{-2}+... = \u03c0^2/6. It's not that hard to turn these formal arguments into a rigorous proof, since everything converges nicely.\n\nshare|improve this answer\nIt isn't difficult to argue $6N/\\pi^2$ directly either. You should accept your own answer! You get a badge for that. \u2013\u00a0 Greg Kuperberg Nov 28 '09 at 16:15\nadd comment\n\nLet me also mention the following: You can adapt Schoenberg's result to prove that 1/M * {N <= n <= N + M : phi(n) / n <= t} --> F(t) uniformly in t, where F is a distribution function. The proof goes by computing the moments sum((phi(n)/n)^k , N <= n <= N + M). You can probably get a O(loglog N / log N) rate of convergence (as was done by Levin ... if I recall correctly).\n\nshare|improve this answer\n+ If this is of interest the distribution function F(t) decays doubly exponentially at 0, that is F(1/t) << exp(-C*exp(t)) for some constant C. This was investigated by Erdos and more recently Weingartner (mrlonline.org/proc/2007-135-09/S0002-9939-07-08771-0/\u2026). Asymptotics for 1 - F(t) when t is close to 1 where studied by Tenenbaum and Toulmonde (a reference is in the paper above). In this case the asymptotic behaviour is more tame. There should be no problem adapting all these results to the case of the interval [N; N + M] with M as you described... \u2013\u00a0 mrm Nov 29 '09 at 17:59\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/74293/non-trivial-isotrivial-family-of-elliptic-curves-over-c-times/74343\nText:\nTake the 2-minute tour \u00d7\n\nSo How does one prove (rigorously) that $$ Frac(\\mathbb{C}[x,y,t]/(y^2-x^3-t)) \\not\\simeq Frac(\\mathbb{C}[t][x,y]/(y^2-x^3-1))? $$ So here $Frac$ denotes the fraction field of an integral domain.\n\nNote that this gives an example of (a non-trivial) isotrivial family over $\\mathbf{C}^{\\times}$.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nThere is a slightly different proof which works over any field $k$ (of characteristic different from 2 and 3). The first field is just $k(x,y)$. As Rita indicated, if it is isomorphic to the second field as $k$-extension, than there exists a birational map $f: \\mathbb P^2\\to \\mathbb P^1\\times E$. This birational map induces a birational map over the algebraic closure of $k$, so we can suppose $k$ is algebraically closed. Composing with the projection to $E$, we get a dominant rational map $g: \\mathbb P^2\\to E$. By two arbitrary points where $g$ is defined, it passes a line $L$. As $E$ is not rational, by L\u00fcroth $g|_L$ is constant. So $g$ is constant, contradiction. More quickly, one can say that the existence of $g$ implies that $E$ is unirational and this is impossible.\n\nEDIT: the rational map $\\mathbb P^2\\to E$ is not birational ! but dominant.\n\nshare|improve this answer\nThis is not so much different as it looks from the proof I gave. $h^1({\\mathcal O})$ is the dimension of the Albanese variety, that for the non rational surface is precisely $E$. Now your argument shows precisely that the Albanese variety of a unirational variety is $0$. \u2013\u00a0 rita Sep 2 '11 at 12:42\nThanks a lot Qing for the very slick argument! It is completely self contained and the key result that you use is that there is no non-constant rational map going form $\\mathbb{P}^1\\rightarrow E$ which as you pointed is a consequence of Luroth's theorem. Cool! \u2013\u00a0 Hugo Chapdelaine Sep 2 '11 at 14:12\nStill, you need to know that $E$ is not rational... The only way I know to show that is by computing the genus. \u2013\u00a0 rita Sep 4 '11 at 16:24\nTo show that $E$ is not rational, one can aslo compute directly $H^0(E, O_E(\\infty))$ which is equal to $k$, and would be of dimension $2$ over $k$ if $E$ was rational. \u2013\u00a0 Qing Liu Sep 5 '11 at 11:51\nTo prove that $\\mathbb P^1\\times E$ is not rational, one can also use the fact that its $\\pi_1$ is obviously non-trivial. \u2013\u00a0 Qing Liu Sep 5 '11 at 11:58\nshow 1 more comment\n\nThe second field is the function field of $X_2:=E\\times {\\mathbb P}^1$, where $E$ is a smooth elliptic curve; the first one is the function field of $X_1:=\\{zy^2-x^3-tz^2=0\\}\\subset {\\mathbb P}^3$. The surface $X_1$ is rational, as one can see by projecting onto ${\\mathbb P}^2$ from the point $P$ given by $x=y=z=0$, which is a double point of $X_1$. The surface $X_2$ is not rational, since it has $h^1({\\mathcal O}_{X_2})=1$. So $X_1$ and $X_2$ are not birational, and the two fields are not isomorphic (as extensions of $\\mathbb C$).\n\nshare|improve this answer\nSo I guess the first $X_2$ should read as $X_1$. Is it completely obvious that $h^1(\\mathcal{O}_X)$ is a birational invariant? After all $\\mathcal{O}_X$ is the sheaf of regular functions on $X$ which a priori could change under birational maps. \u2013\u00a0 Hugo Chapdelaine Sep 2 '11 at 1:18\n@Georges: I've edited and fixed the typos (I hope). Thanks! @Hugo: $h^1({\\mathcal O})$ is a birational invariant because by Hodge theory it is equal to $h^0(\\Omega^1) \u2013\u00a0 rita Sep 2 '11 at 6:27\n@Hugo (continued): there is also a famous rationality criterion by Castelnuovo, that says that a surface $S$ is rational iff $h^1({\\mathcal O})=h^0(2K_S)=0$. \u2013\u00a0 rita Sep 2 '11 at 8:36\nI'm quite happy with your proof but I think there should be a more elementary proof which is self contained. You see the whole point of this question is to come up with a birational invariant and if we assume from the outset that $h^1(\\mathcal{O})$ is a birational invariant then it (almost) kills the problem. \u2013\u00a0 Hugo Chapdelaine Sep 2 '11 at 12:10\nThe last statement is a well known fact, have a look at Beauville's book on surfaces, the chapter on birational maps of surfaces. \u2013\u00a0 rita Sep 2 '11 at 12:37\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/173427/what-is-ft-x-t1-if-x-t1-1-p1-x-tpx-t-and-x-0-p-in-0-1\nText:\nTake the 2-minute tour \u00d7\n\nWhat is $f(t)=X_{t+1}$, if $X_{t+1}=(1-p)(1-X_{t})+pX_{t}$ and $X_{0},p \\in [0,1]$?\n\nAnd what are general methods for finding functions defined by such recurrent equations?\n\nshare|improve this question\nI'm not sure that the ~s were for, so I got rid of them. Also, it's probably better to use *words* to get italics, rather than math mode. I thought it looked kind of funky so I put it in a block quote. \u2013\u00a0 Dylan Moreland Jul 20 '12 at 23:14\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nI will assume that $t$ ranges over, say, the non-negative integers.\n\nFor your particular example, we have $$\\begin{align*}X_{t+2}&=(1-p)(1-X_{t+1})+pX_{t+1},\\\\ X_{t+1}&=(1-p)(1-X_t)+pX_t.\\end{align*}$$\n\nSubtract and simplify. We get $$X_{t+2}-X_{t+1}=(2p-1)(X_{t+1}-X_t).$$ So if $Y_t=X_{t+1}-X_t$, we find that $Y_{t+1}=(2p-1)Y_t$, which is easily solved, and therefore $X_t$ is $X_0$ plus the sum of a geometric series.\n\nRemark: There are a number of good general methods for solving linear recurrences with constant coefficients. The generating functions approach is quite useful. Or else in our case we can rewrite our recurrence as $$X_{t+1}=(2p-1)X_t + 1-p.$$ First find a general solution of the homogeneous recurrence $X_{t+1}=(2p-1)X_t$. This is easy. Then find a particular solution of our non-homogeneous recurrence. Easy, by guessing that a constant might work. Then the general solution of our recurrence is the general solution of the homogeneous recurrence, plus our particular solution.\n\nshare|improve this answer\n@TMM: Thank you, fixed. Someday I may write a typo-free answer. \u2013\u00a0 Andr\u00e9 Nicolas Jul 20 '12 at 23:30\nSurely with your 80k worth of contributions to this site, you will be forgiven for the occasional typo :) \u2013\u00a0 TMM Jul 20 '12 at 23:32\nadd comment\n\nWell, you have $X_{t+1}$ equal to a weighted average between $X_{t}$ and $1 - X_{t}$. So there's a fixed point where these are equal, i.e., at $X=1/2$. To find the behavior away from that fixed point, define $Y_{t} = X_{t} - 1/2$: then $$ \\begin{eqnarray} Y_{t+1}&=&X_{t+1}-\\frac{1}{2} \\\\ &=& \\left(1-p\\right)\\left(1 - X_{t}\\right) + pX_{t} - \\frac{1}{2}\\\\ &=& \\left(1 - p\\right)\\left(\\frac{1}{2} - Y_t\\right) + p\\left(Y_{t} + \\frac{1}{2}\\right) -\\frac{1}{2}\\\\ &=& (2p-1)Y_{t}. \\end{eqnarray} $$ So $Y_{t}$ is multiplied by a constant at each step, giving $$ X_{t} = Y_{t} + \\frac{1}{2} = \\left(2p-1\\right)^{t} Y_{0} + \\frac{1}{2} = \\left(2p-1\\right)^{t} \\left(X_{0} - \\frac{1}{2}\\right) + \\frac{1}{2}. $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18482/find-the-subset-of-a-line-on-a-sphere-far-from-a-set-of-points-on-the-sphere/18521\nText:\nTake the 2-minute tour \u00d7\n\nI have some code where the \"hot part\" relies on an inefficient solution to this problem.\n\nProblem: I have 3 inputs: a. A collection of N points on the surface of a sphere.\nb. A line segment on the sphere.\nc. A distance X (distance can be on the surface or in 3D as it's trivial to map between them)\n\nOutput: Find the subset of the line segment which is more than distance X from the collection of points.\n\n(My problem actually involves a curve on the sphere, but I can reduce it to a line segment by chopping it up into smaller pieces.)\n\nAt present, I parametrize the line and created a distance function, subtract X then slam it into a method that finds the times when a function is positive. VERY slow.\n\nAlso, precomputations count in this algorithm. That is, the set does change over time, but it changes less frequently than I need this result for different line segments. Maybe 5 queries to every set change? That's worst case.\n\nX is fixed over time.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nBy a line on the sphere, I assume you mean a part of a great circle spanning less than 180\u00b0.\n\nFor each of the N points, find what part of the line is closer than X to that point. This is at most a single segment. Find their union C as a disjoint union of segments. This is probably easier if you sort them by their starting point, and the obvious algorithm gives you the union as a sorted list as well \u2013 which makes the last part trivial: Find the complement of C.\n\nOh, and the first part can be done with some simple linear algebra.\n\nshare|improve this answer\nadd comment\n\nIf the querying aspect is important for you (i.e the lines keep appearing), then you should really build a data structure on the disks. Here's what you need to do. You need to build the arrangement on disks of radius X centered at each point (the arrangement being the way in which the sphere is decomposed into patches by the boundaries of the disks). Then, a point location query for each endpoint locates the start and end cells, and walking through the arrangement along the line gives you the subset of the line not covered by the disks.\n\nWhile this is overkill for a single line (and Harald's solution is fine), it'll be more efficient if the lines are short and there are many of them (since the point location queries will run in time logarithmic in the number of points, and you hopefully won't have to walk through too many cells). To implement this is a little tricky though: luckily, CGAL has packages that you can use for this purpose. A source paper on this topic is here.\n\nshare|improve this answer\nVery nice paper. That is kind of what I had in mind, but Harald's answer looks to be a lot easier to code, and probably is going to be good enough for me as long as X is large enough. (The exact final values of X are TBD.) THANKS! \u2013\u00a0 John Mar 17 '10 at 22:16\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/135478/using-linear-algebra-how-is-the-binet-formula-for-finding-the-nth-fibonacci-nu?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nIf possible, please refrain from any type of proof besides linear algebra. So, using the recursion formula $F_{n+1} = F_{n-1} + F_n$, for $n\\gt 1$, and where $F_0 = 0$ and $F_1 = 1$, and the Fibonacci matrix, derive the golden ratio and ultimately the Binet formula.\n\nshare|improve this question\nI haven't done eigenvectors yet (I do that in about a week in my L.A. course). Is there a way to derive all that without using those concepts? \u2013\u00a0 Nico Bellic Apr 22 '12 at 20:08\nYou could use the shift operator $S$ in the space of sequences. Then $F$ satisfies $S^2 F=SF+F$ and so $(S^2-S-I)F=0$. You now factor $S^2-S-I$ to find its kernel. @BillDubuque has proposed this approach several times here but I can't find a good link right now. \u2013\u00a0 lhf Apr 22 '12 at 20:10\nI'm truly, really sorry, but I'm not sure if I'm able to follow you. \u2013\u00a0 Nico Bellic Apr 22 '12 at 20:15\nSee for instance cs-netlab-01.lynchburg.edu/courses/algorithms/recurenc.htm (Example - solving the Fibonacci numbers) This is a random link found by Google. I could not find anything in Wikipedia. \u2013\u00a0 lhf Apr 22 '12 at 20:20\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI am not sure to which extent this will be helpful for OP, but I'll post this anyway. This is basically the same solution as the one posted by Zhen Lin, but without any explicit reference to eigenvalues or eigenvectors.\n\nSo the sequence given by $F_{n+2}=F_{n+1}+F_n$ seems to be complicated. But there is a wide class of sequences we understand very good - geometric progressions.\n\nLet us ask the question whether we can modify the sequence $F_n$ to get a geometric progression. E.g. we can ask whether there is an $x$ such that the sequcence $G_n=xF_n+F_{n-1}$ is a geometric progression.\n\nFrom $$\\begin{align} F_{n+1}&=F_n+F_{n-1}\\\\ F_{n}&=F_{n-1}+F_{n-2} \\end{align} $$ we get $$G_{n+1}=xF_{n+1}+F_n=xF_n+(x+1)F_{n-1}+F_{n-2}= xF_n+(x+1)F_{n-1}+F_n-F_{n-1}=(x+1)F_n+xF_{n-1}.$$ If we want the RHS to be a multiple of $G_n$, then we must have $$\\frac{x+1}x=x,$$ i.e. $x+1=x^2$ or $x^2-x-1=0$, which has the two solutions $\\lambda_{1,2}=\\frac{1\\pm\\sqrt5}2$.\n\nNotice that $\\lambda_1+\\lambda_2=1$, $\\lambda_1\\lambda_2=-1$.\n\nFor any of the above values we have $$G_{n+1}=(\\lambda+1)F_n+\\lambda F_{n-1}=\\lambda\\left(\\frac{\\lambda+1}\\lambda F_n+F_{n-1}\\right)=\\lambda G_n.$$ We also have $G_1=\\lambda$, $G_0=1$.\n\nSo we get $$ \\begin{align} \\lambda_1F_{n}+F_{n-1}&=\\lambda_1^n\\\\ \\lambda_2F_{n}+F_{n-1}&=\\lambda_2^n \\end{align} $$ If we subtract the above two equations, we get $$(\\lambda_1-\\lambda_2)F_{n}=\\lambda_1^n-\\lambda_2^n$$ which gives $$F_n=\\frac{\\lambda_1^n-\\lambda_2^n}{\\lambda_1-\\lambda_2}.$$\n\nIn the solution, which used the diagonal form and eigenvalues, we did not have to guess, that it is possible to obtain geometric progressions combining Fibonacci sequence and shifted Fibonacci sequence - we get this fact from that diagonal matrix.\n\nOr we can look at this the other way round - many applications of diagonal matrices similar to given matrix (e.g. in linear recurrences, ordinary differential equations) can be viewed as an effort to transform the original problem to a simpler form; in this case the simpler form was a geometric progression.\n\nshare|improve this answer\nadd comment\n\nThe Fibonacci numbers are defined by a second-order linear recurrence equation: $$F_{n+2} = F_{n+1} + F_n$$ This means we can treat the solution of $F_n$ in terms of $n$ as a problem in linear algebra involving only $2$-dimensional vectors. In some sense, what we are doing is modelling this as a dynamical process on a $2$-dimensional state space.\n\nLet $V = \\mathbb{R}^2$. We define a linear operator $T : V \\to V$ by $$T(x, y) = (y, x + y)$$ Notice that $T(F_{n}, F_{n+1}) = (F_{n+1}, F_{n+2})$, so you can think of $V$ as being a sliding $2$-entry window on the Fibonacci sequence and $T$ as the operator which advances the window along the Fibonacci sequence. The initial conditions $F_0 = 0, F_1 = 1$ then imply that $$T^n(0, 1) = (F_n, F_{n+1})$$ so all we need to do to find $F_n$ in terms of $n$ is to find an effective way to compute iterates of the operator $T$!\n\nNow, we get our hands dirty and represent $T$ as a matrix: $$T = \\begin{pmatrix} 0 & 1 \\\\ 1 & 1 \\end{pmatrix}$$ Imagine if we could somehow find an invertible matrix $P$ and a diagonal matrix $D$ such that $T = P D P^{-1}$; then, by matrix algebra, we would have $T^n = P D^n P^{-1}$, and it is easy to compute powers of diagonal matrices. The theory of eigenvectors and eigenvalues gives us one way to find such a factorisation of $T$. Notice that $$\\det (T - x I) = \\det (P(D - x I)P^{-1}) = (\\det P)(\\det (D - x I))(\\det P^{-1}) = \\det (D - x I)$$ but a simple calculation shows $$\\det (D - x I) = \\det \\begin{pmatrix} \\lambda_1 - x & 0 \\\\ 0 & \\lambda_2 - x \\end{pmatrix} = (\\lambda_1 - x)(\\lambda_2 - x)$$ so whatever $\\lambda_1$ and $\\lambda_2$ are, they must be the zeros of the polynomial $$\\det (T - x I) = \\det \\begin{pmatrix} -x & 1 \\\\ 1 & 1 - x \\end{pmatrix} = x^2 - x - 1$$ which, surprise surprise, is the minimal polynomial of the golden ratio. So let $\\lambda_1 = \\frac{1}{2} (1 + \\sqrt{5})$ and $\\lambda_2 = \\frac{1}{2} (1 - \\sqrt{5})$. These are the eigenvalues of $T$. By construction, $\\det (T - \\lambda_1 I) = \\det (T - \\lambda_2 I) = 0$, so there must be non-zero vectors $\\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix}$ and $\\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix}$ such that $$ T \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} = \\lambda_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} $$ $$ T \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = \\lambda_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} $$ These vectors are called the eigenvectors of $T$. I leave you to verify that $x_1 = \\lambda_1 - 1$, $y_1 = 1$, $x_2 = \\lambda_2 - 1$, $y_2 = 1$ works, but there are other solutions.\n\nDefine the matrix $P$ by $$P = \\begin{pmatrix} x_1 & x_2 \\\\ y_1 & y_2 \\end{pmatrix}$$ Notice that $$\\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\alpha_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} + \\alpha_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = P \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$$ so by linearity we have $$T \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\lambda_1 \\alpha_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} + \\lambda_2 \\alpha_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = P \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix} \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$$ but we can invert $P$ to find $\\alpha_1$ and $\\alpha_2$ in terms of $x$ and $y$, so we have obtained the desired factorisation of $T$ as $P D P^{-1}$ with $D$ diagonal. Putting everything together, we get the formula $$T^n = P \\begin{pmatrix} {\\lambda_1}^n & 0 \\\\ 0 & {\\lambda_2}^n \\end{pmatrix} P^{-1}$$ and applying this to the vector $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ gives Binet's formula.\n\nshare|improve this answer\nThe OP seems to want to avoid eigenvalue decompositions. \u2013\u00a0 lhf Apr 23 '12 at 1:09\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/260842/the-maximum-of-fg-is-in-the-boundary\nText:\nTake the 2-minute tour \u00d7\n\n$f$ and $g$ are holomoprphic functions in $G \\subset \\mathbb C$ and continuous on the boundary of $G$. Prove that $|f| + |g|$ gets its maximum in the boundary of $G$.\n\nI know this has something to do with the maximum principle, but I'd be happy for a hint.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nI think $G$ is supposed to be bounded and hence $\\overline{G}$ is compact. By continuity of $|f|+|g|$ and compactness of $\\overline{G}$, there exists $z_0\\in\\overline{G}$ and $M\\ge 0$, such that $|f|+|g|$ attains its maximum $M$ at $z_0$. Let $a,b\\in\\mathbb{C}$ with $|a|=|b|=1$, such that $|f(z_0)|=af(z_0)$ and $|g(z_0)|=bg(z_0)$. Define $h=af+bg$. Then $h$ is holomorhic on $G$ and continous on $\\overline{G}$. Moreover, $|h(z)|\\le M$ on $\\overline{G}$ and $h(z_0)=M$. Then the conclusion follows from maximum modulus principle.\n\nshare|improve this answer\nadd comment\n\nIf $\\omega \\in \\mathbb{C}$ and $|\\omega| = 1$ then $f + \\omega g$ is holomorphic on $G$ and $|f + \\omega g| \\leq |f| + |g|$. Given some fixed $z \\in G$ there is such an omega (depending on $z$) such that $|f(z) + \\omega g(z)| = |f(z)| + |g(z)|$. Now apply the maximum modulus principle to $f + \\omega g$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207076/convex-combination?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $I$ is a countable set, and we have $u_i\\in \\mathbb{R}^n$ for $i\\in I$. Suppose that $v=\\sum_{i\\in I} a_i u_i$ and $\\sum_{i\\in I}a_i=1$ and $a_i\\geq 0$.\n\nCan one show that there exists a finite $J\\subseteq I$ and $b_j$ for $j\\in J$ such that $\\sum_{j\\in J}b_j=1$, $b_j\\geq 0$, and $v=\\sum_{j\\in J} b_j u_j$?\n\nIs this some well-known result?\n\nshare|improve this question\nCarath\u00e9odory's theorem almost says that you can get away with just $n+1$ elements in $J$. Except here you start with an infinite convex combination, and then the theorem does not apply, at least not without further work. \u2013\u00a0 Harald Hanche-Olsen Oct 4 '12 at 10:41\nI like this question. Too bad your 0% accept rate won't help in attracting answers to it... \u2013\u00a0 joriki Oct 4 '12 at 11:55\nI second joriki's comment. Do you not know about accepting answers to questions you post on this site? \u2013\u00a0 Gerry Myerson Oct 4 '12 at 12:34\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nYes, one can.\n\nWithout loss of generality, assume $a_i\\gt0$ and let $I=\\mathbb N$. For any subset $A\\subseteq\\mathbb N$, call\n\n$$ W_A=\\frac{\\sum_{i\\in A}a_iu_i}{\\sum_{i\\in A}a_i} $$\n\nthe weighted average for $A$. If the $u_i$ all lie in some proper affine subspace of $\\mathbb R^n$, we can restrict to that subspace, so without loss of generality we can assume that their affine span is $\\mathbb R^n$. Then at some finite index $k$ there are positive contributions from $n+1$ affinely independent vectors $A=\\{u_{i_1},\\dotsc,u_{i_{n+1}}\\}$, and $W_A$ is therefore in the interior of their convex hull $H$. Thus, since both $\\sum_ia_i$ and $\\sum_ia_iu_i$ converge (so their tails converge to zero) there is some $l\\ge k$ such that the weighted average remains inside $H$ if the tail $\\{i\\in\\mathbb N\\mid i\\ge l\\}$ is added to $A$. Then the desired finite sum can be obtained by replacing the contributions from the tail by corresponding linear combinations of $u_{i_1},\\dotsc,u_{i_{n+1}}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/205260/solutions-of-diophantine-equations-xy-yx/205264\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\n$x^y = y^x$ for integers $x$ and $y$\n\nHow to prove that $(2,4)$ and $(4,2)$ are the only solutions of Diophantine equations ${x^y} = {y^x}$ for $x \\ne y$?\n\nshare|improve this question\n@DavidWallace For $x \\ne y$. \u2013\u00a0 glebovg Oct 1 '12 at 5:02\nHah! Sorry, I can't read. \u2013\u00a0 user22805 Oct 1 '12 at 5:04\nadd comment\n\nmarked as duplicate by Cameron Buie, Thomas, Noah Snyder, Chris Eagle, \uff2a. \uff2d. Oct 5 '12 at 13:00\n\n\n1 Answer\n\nup vote 3 down vote accepted\n\nTaking logarithms:\n\n$$x\\ln y=y\\ln x$$ $$\\frac{\\ln y}y=\\frac{\\ln x}x$$\n\nFor this to be true, the function has to take the same value at two different locations. Take the function\n\n$$f(x)=\\frac{\\ln x}x$$ $$f'(x)=\\frac{1-\\ln x}{x^2}$$\n\nIt has a maximum at $x=e$, is decreasing for $x>e$ and increasing for $x<e$. So if two values are equal, one has to be greater than $e$ and the other must be less. So for the lower value we only have $x=1,2$ as options. Our problem amounts to proving that there is no other number that gives the same value as $x=1$. Since $f(1)=0$, and $\\ln(x)$ only has a single root at $1$, we know this can't happen, so we're done.\n\nshare|improve this answer\nKeep in mind that logarithms assume the numbers are positive. $x=-4, y=-2$ works as well. Cases of negative integers either reduce to the positive case in disguise (when both are negative) or are trivial (when only one is). \u2013\u00a0 Robert Mastragostino Oct 1 '12 at 5:29\nI used a very similar argument, but I was not convinced. Thanks. \u2013\u00a0 glebovg Oct 1 '12 at 5:30\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/103588/expression-that-hits-integer-multiples-of-two-variables/103777\nText:\nTake the 2-minute tour \u00d7\n\nIs there a way to generate am expression that will get all integer multiples of an arbitrary pair of integers?\n\nI.e. Some function that will spit out ${0,2,3,4,6,8,9,10, ... }$ and all of the other multiples of 2 and 3 given integer arguments. It should not generate results for integer arguments that are not multiples of 2 and 3.\n\nBy function I mean using elementary mathematical operations.\n\nI would prefer a single variable expression.\n\nshare|improve this question\nI'm confused. Your $f(x,y)$ outputs many more integers than the multiples of a and b. But if that's allowed, then just take your single-variable function to be $f(x)=x$, and then you get all your multiples out. \u2013\u00a0 Cam McLeman Jan 29 '12 at 15:25\nDoes $$f(n)=\\text{the }n\\text{th natural number that is a multiple of either }a\\text{ or }b\\text{ (or both)}$$ count for you? If not, then you'll have to specify more precisely what you mean by \"function\". \u2013\u00a0 Henning Makholm Jan 29 '12 at 15:25\n@CamMcLeman, Henning, edited, you are correct. \u2013\u00a0 soandos Jan 29 '12 at 15:30\nSo what you want is not just a function (which in mathematics can be just about anything you are able to define unambiguously), but an expression with one or more free variables. But then you need to specify what is an \"elementary mathematical operation\" to you. \u2013\u00a0 Henning Makholm Jan 29 '12 at 15:32\nStandard definition, composition of constants, logarithms, exponentiation, extractions of nth roots by using $(+,-,*,/)$. \u2013\u00a0 soandos Jan 29 '12 at 15:34\nshow 6 more comments\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThe function $$f(n)={3\\over2}n+{i^n-i^{-n}\\over4i}$$ (where $i$ is a square root of minus one) gives the outputs $0,2,3,4,6,8,9,10,\\dots$ on being given the inputs $0,1,2,3,4,5,6,7,\\dots$.\n\nEDIT: In general, suppose you're given positive intgers $a,b$, and want the output to be all $n$ divisible by one or the other. First find the least common multiple $L$ of $a$ and $b$ (in the example, $L=6$). Then find the number $N$ of multiples of $a$ and/or $b$ in $0,1,2,\\dots,L-1$ (in our example, $N=4$; in general, this is a simple exercise). The main term of $f(n)$ will be $(L/N)n$. The difference, $f(n)-(L/N)n$, will be periodic with period $N$, so it will be a linear combination of the functions $g_j(n)=e^{2\\pi ijn/N}$, $j=0,1,\\dots,N-1$. You find the coefficients in this linear combination by the standard techniques of intro linear algebra - it's just solving $N$ linear equations in $N$ unknowns.\n\nshare|improve this answer\nHow could I generalize this for arbitrary multiples? \u2013\u00a0 soandos Jan 29 '12 at 23:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/9075/nl-definition-and-a-problem\nText:\nTake the 2-minute tour \u00d7\n\nThe question is: What is the smallest complexity class in which the following problem is contained: Given a graph with $n$ nodes, Is there independent set of size of at least $n-10$?\n\nI have a little difficulty to understand the meaning of being in ${\\sf L}$ and examine problems in a correct way for deciding if they are in ${\\sf NL}$ or ${\\sf L}$\n\nFirst I know that for being in ${\\sf NL}$ I need to provide a verifier for a Turing machine which uses only $O(\\log n)$ space on its working tape- So I wonder- I can give as a verifier this set of nodes to be independent set as requested, but how does the checking work? Can it go to all the lists of the pointers to the neighbors of each node , and for every node to check whether all the other nodes in the set given as independent set is not on that list- Is this considered of not using any space and I only need to count the nodes in the list that fulfill the requirement and therefore use only $O(\\log n)$ space? Is this correct? Is there a way to prove that the problem is in ${\\sf L}$?\n\nshare|improve this question\nHaving an independent set of size $n-10$ means that the graph has a vertex cover of size $10$, no? There is an exact algorithm solving this problem in $O(1.3^{10} \\cdot n^2)$ time, hence in $O(n^2)$ time. I don't know any lower complexity class than $\\mbox{P}$ for which constant-sized vertex cover is a member. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 20:26\n@P\u00e5lGD, I think you're wrong. Consider a graph of $n$ vertices and no edges. Any subset of it's vertices is independent, but only all $n$ form a cover. \u2013\u00a0 Karolis Juodel\u0117 Jan 21 '13 at 20:35\n@KarolisJuodel\u0117 A vertex cover is a set of vertices \"covering\" all the edges. In an edgeless graph the empty set is a vertex cover. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 20:59\n@P\u00e5l The idea is to go over all sets of $10$ vertices. That requires only logarithmic space. \u2013\u00a0 Yuval Filmus Jan 21 '13 at 21:35\n@YuvalFilmus Yes, I see now. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 21:45\nadd comment\n\n1 Answer\n\nHint: How much space do you need to store a set of $10$ vertices? How much space does it take to go over all pairs of nodes in a graph?\n\nAnother hint: How much space does it take to implement the following algorithm? (I replaced 10 with 3 to make it easier to follow)\n\n int algorithm(int n, int G[n][n]) {\n   int x, y, flag;\n   int v1, v2, v3;\n\n   for (v1 = 0; v1 < n; v1++)\n     for (v2 = 0; v2 < n; v2++)\n       for (v3 = 0; v3 < n; v3++) {\n         flag = 0;\n         for (x = 0; x < n; x++)\n           for (y = 0; y < n; y++)\n             if ((x != v1) && (x != v2) && (x != v3) &&\n                 (y != v1) && (y != v2) && (y != v3))\n               flag |= G[x][y];\n         if (flag == 0)\n           return 1;\n   return 0;\nshare|improve this answer\nI'm not really sure, as you can read I don't understand the meaning of storing vertices, in which representation I keep them? Your questions is exactly what I dont know and I wondered in my question. \u2013\u00a0 Ben Benli Jan 21 '13 at 21:20\nThis is not homework if you are concerned. \u2013\u00a0 Ben Benli Jan 21 '13 at 22:14\nLet's say your Turing machine gets as input $n$ (assuming the vertices are labeled from 1 to $n$) and then a list of which vertices are connected. You are looking for a vertex cover of, in Yuval's example, size 3. First you need to iterate through all combinations $(v_1,v_2,v_3)$ for $v_i \\leq n$. Then you go through the edges an confirm that all of them has at least one endpoint in $(v_1,v_2,v_3)$. You store $3 \\log n$ bits plus some constant for spacings. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 22:47\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/291956/if-p-is-prime-and-p-5-show-that-when-p-is-divided-by-10-the-remainder\nText:\nTake the 2-minute tour \u00d7\n\nIf $p$ is prime and $p > 5$, show that when $p$ is divided by 10, the remainder is 1, 3, 7, or 9.\n\nThis is a problem from Hungerford's Abstract Algebra: An Introduction. I would like some help on it, it was an example in class. Thanks.\n\nshare|improve this question\nConsider the case when the remainder is 2. Then $p = 10 q + 2$ for some integer $q$, so that $p = 2 (5 q + 1)$ is even, but cannot be 2 by the assumption $p > 5$. The other cases are entirely similar, it is useful for you to work them out yourself. \u2013\u00a0 Andreas Caranti Feb 1 '13 at 7:27\nSince you are new, I want to give some advice about the site: To get the best possible answers, you should explain what your thoughts on the problem are so far. That way, people won't tell you things you already know, and they can write answers at an appropriate level; also, people are much more willing to help you if you show that you've tried the problem yourself. If this is homework, please add the [homework] tag; people will still help, so don't worry. Also, many would consider your post rude because it simply states the problem, and is not a request for help, so consider rewriting it. \u2013\u00a0 Zev Chonoles Feb 1 '13 at 7:34\n$p > 5$ prime means $p$ not divisible by $2$ or $5$. \u2013\u00a0 Benjamin Dickman Feb 1 '13 at 8:26\nadd comment\n\n6 Answers\n\nup vote 5 down vote accepted\n\nBy the division algorithm, we can write each $p$ as $$p = 10q + r$$ for some quotient $q$ and remainder $0\\le r < 10$. As $p$ is prime, clearly $r\\neq 0$. $r$ also cannot be even, otherwise $p$ is even. Finally, note that $r \\neq 5$ or $5 \\mid p$.\n\nFor a more brief and algebraic solution, note that $(p,\\ 10) = 1$ implies that $p$ is a unit in $\\mathbb{Z}/10\\mathbb{Z}$. The units of the ring are precisely $1,\\ 3,\\ 7$ and $9$.\n\nFor completeness, you should probably show that there exists primes for each of the remaining congruence classes.\n\nshare|improve this answer\nadd comment\n\nYou already have a couple of nice \u2018mathematical-looking\u2019 answers. In attacking a question like this, though, you might want to start with simple, familiar facts.\n\nThe remainder when $p$ is divided by $10$ is simply the last digit of $p$. If the last digit of a number $n$ is $0,2,4,6$, or $8$, what kind of number is $n$? Can it be prime if it\u2019s greater than $2$? If the last digit is $0$ or $5$, what can you say about $n$? Can it be prime and greater than $5$?\n\nThese are enough to tell you, at least informally, why the prime $p>5$ must end in $1,3,7$, or $9$, and now you can worry about explaining the reasoning in the previous paragraph a bit more formally.\n\nshare|improve this answer\nThank you for the tip, I was not sure how to best ask questions here but I'm learning and will remember that. \u2013\u00a0 grayQuant Feb 1 '13 at 14:36\nadd comment\n\nTo say that a prime $p > 5$ gives a remainder of $1, 3, 7$ or $9$ when divided by $10$ is merely remarking that the prime is odd (and not $5$, since all integers ending in five are multiples thereof).\n\nAfter all, the remainder when divided by $10$ is simply the unit of the number itself, and if that unit was any of $0, 2, 4, 6, 8$ we'd plainly see that it was an even number, and therefore not prime. Likewise with the five.\n\nThat said, we could come to the conclusion of your statement by, say, basing an argument on how all primes above $3$ are of the form $6n \\pm 1$ (mind you, this follows from an argument akin to the above): the multiples of $6$ begin as follows: $$6, 12, 18, 24, 30\\ldots$$ From which we father that the units of such multiples are either $0, 2, 4, 6$ or $8$. Now take the '$\\pm 1$' bit into consideration and we find that we have the following units possible: $$1, 3, 5, 7, 9$$ (Remember, a remainder of $-1$ when divided by $10$ is equivalent to a remainder of $9$.)\n\nSo, much like the above, we disregard the $5$ since that certainly isn't prime, and we have $1, 3, 7, 9$ leftover, as desired.\n\nshare|improve this answer\nadd comment\n\nAny natural number $n$ can be expressed as $$n=a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$$\n\nfor some natural numbers (including $0$) $k,a_k,\\dots , a_1, a_0$. This representation is unique (up to commutation of the products and sums).\n\nSuppose $p\\in \\mathbb{P}$. Then $p=a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$.\n\nClearly the remainder of $a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$ when divided by $10$ is $a_0$.\n\nCan you conclude?\n\nshare|improve this answer\nThis helped me think about the problem. I think using the division algorithm is what the author of the book had in mind, just because it was in the previous section. \u2013\u00a0 grayQuant Feb 1 '13 at 22:03\nadd comment\n\nyou are looking for the unit digit of the prime.For prime $p\\neq 2$, unit digit is odd which means $p\\pmod {10}\\in\\{1,3,5,7,9\\}$\n\nNow, for any prime $p\\gt 5$, unit git can't be $5$ otherwise it would be divisible by $5$ and hence won't be a prime.\n\nThus only possible candidates for unit digit of a prime $p\\gt 5$ are $\\{1,3,7,9\\}$\n\nshare|improve this answer\nadd comment\n\nThis is clear from the Euclidean algorithm. Write the remainder $\\rm\\: r = (p\\ mod\\ 10).\\:$ By Euclid\n\n$$\\rm p\\equiv r\\,\\ (mod\\ 10)\\ \\Rightarrow\\ gcd(p,10) = gcd(r,10)$$\n\nIn particular, $ $ when the $ $ gcd $= 1,\\, $ then: $\\rm\\,\\ p\\,$ is coprime to $10$ $\\iff$ $\\rm\\,r\\,$ is coprime to $10$\n\nNow, by hypothesis, $\\rm\\, p\\,$ is prime $ > 5,\\,$ so $\\rm\\, p\\,$ is coprime to $10,\\ $ thus $\\rm\\ r\\,$ is coprime to $10,\\:$ so we infer that $\\rm\\,r\\,$ is odd and coprime to $\\,5,\\:$ hence $\\rm\\:r\\in \\{1,3,7,9\\},\\,$ since the remainder $\\rm\\,r\\in [0,9].$\n\nRemark $\\ $ Ditto if we generalize $\\rm\\,10\\,$ to any modulus $\\rm\\,m\\!:\\ $ if prime $\\rm\\,p\\nmid m\\:$ then its remainder $\\rm\\, p\\ mod\\ m\\,$ is one of the $\\,\\varphi(m)\\,$ remainders coprime to $\\rm\\,m.\\:$ Or, expressed in radix language:\n\n$\\quad$ in radix $\\rm\\,m\\!:\\ $ if $\\rm\\,n\\,$ has units digits $\\rm\\,r,\\ $ then $\\rm\\ n\\,$ is coprime to $\\rm\\, m\\iff r\\,$ is coprime to $\\rm\\,m$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/31554/is-the-feedback-vertex-number-bounded-by-the-maximum-number-of-leaves-in-a-spann\nText:\nTake the 2-minute tour \u00d7\n\nI have a graph-theoretical conjecture which I think would have been studied before, but for which I cannot find anything in the literature.\n\nLet G be a finite, simple, connected graph. Let the feedback vertex number $FVS(G)$ be the minimum number of vertices that have to be deleted from $G$ to break all cycles, so the minimum number of deletions needed to turn $G$ into a forest. Let the max leaf number $MaxLeaf(G)$ be the maximum number of leaves in any spanning tree for $G$.\n\nMy conjecture is that $FVS(G) \\leq MaxLeaf(G)$.\n\nThe two numbers come close for complete graphs: a $K_t$ has a spanning tree with $(t-1)$ leaves, and $(t-2)$ deletions are needed to turn $K_t$ into a forest. Since a forest can have an arbitrary number of leaves and has FVS number 0, the MaxLeaf number cannot be bounded by a function of the FVS number.\n\nI can prove that $FVS(G) \\leq 6 \\cdot MaxLeaf(G)$ through a lemma on spanning trees which says that for every connected graph G containing m vertices of degree $\\neq 2$, there is a spanning tree for G with at least $m/6$ leaves. Since the deletion of the set of vertices of degree $\\neq 2$ turns a graph into a forest if the graph is not a simple cycle, this shows that $FVS(G) \\leq 6 \\cdot MaxLeaf(G)$ when $G$ is not a simple cycle; and it is easy to see that the claim also holds when $G$ is a simple cycle since $MaxLeaf(C_n) = 2$ and $FVS(C_n) = 1$ for $n \\geq 3$.\n\nSince the complement of the leaves in a spanning tree form a connected dominating set, and since the complement of a feedback vertex set is a maximum induced forest, an alternative way to state the conjecture is: For any connected graph $G$ the number of vertices in the largest induced subforest of $G$ is at least as large as the minimum size of a connected dominating set in $G$.\n\nSo my question is: is this conjecture true, and does anyone know of any research related to it?\n\nshare|improve this question\nYou might consider looking at this circle of ideas for planar graphs. David Barnette showed that for a planar 3-connected graph there is always a spanning tree of maximum valence 3. However, if I remember properly, he also showed that for d-polytopal graphs (d more than 3) that there is no uniform upper bound for the valence of a spanning tree. d-polytopal graphs are known to be d-connected. This paper might also be of interest: citeseerx.ist.psu.edu/viewdoc/\u2026 \u2013\u00a0 Joseph Malkevitch Jul 13 '10 at 12:39\nadd comment\n\n2 Answers\n\nup vote 6 down vote accepted\n\nBill Waller and I proved the stronger statement that for G a graph on n(G) > 1 vertices, the order of a largest induced linear forest is at least one plus the connected domination number. See our preprint. A linear forest is a forest in which each connected component is a path, and clearly a lower bound for the order of a largest forest.\n\nshare|improve this answer\nExcellente, thanks a lot! I actually looked at the preprint briefly during my web search, but missed the theorem. Nice work. \u2013\u00a0 Bart Jansen Jul 13 '10 at 21:43\nadd comment\n\nThis isn't a complete answer, but at least it's a step. I think it should be possible to prove that FVS(G) < 2 MaxLeaf(G).\n\nMore specifically, if NonTwo(T) is the number of nodes in spanning tree T that do not have degree two, and MaxNonTwo(G) is the maximum value of NonTwo(T) over all spanning trees of G, then I think that\n\n  \u2022 MaxNonTwo(G) < 2 MaxLeaf(G). This is obvious: in any tree, the number of leaves in T is greater than half of NonTwo(T), so the tree T that maximizes NonTwo(T) has greater than NonTwo(T)/2 leaves, and the max leaf spanning tree can only have even more leaves.\n\n  \u2022 FVS(G) \u2264 MaxNonTwo(G). More specifically, in every tree T maximizing NonTwo(T), the set of vertices of degree \u2260 2 form a feedback vertex set. For, if there's a cycle induced by the degree-2 vertices of T, then some edge e of the cycle does not belong to T. If the path in T connecting the endpoints of e passes through a vertex v that does not have degree three, then adding e and removing an edge incident to v produces a tree with a larger value of NonTwo(T). If this situation does not occur, then all edges in the induced cycle are non-tree edges; adding two consecutive edges from the cycle to T and removing two of the edges from T (two of the three edges at the median in T of the endpoints of the added cycle edges) produces a new tree with greater NonTwo again (the three endpoints of the added edges get their degree increased above two, the median goes from degree three to degree one, and two other vertices get their degrees decreased from three to two).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64940/zeros-of-a-sequence-related-to-roots-of-unity\nText:\nTake the 2-minute tour \u00d7\n\nConsider the sequence\n\n$$ a(n) = \\prod_{u^n=1,u \\neq 1}( (1+u)^n+1) $$\n\nSome terms are: $$ 1,1,0,9,121,2704,118336, 4092529,0,97734390625, \\ldots $$\n\nAlonso del Arte asks:\n\nQuestion: What are the multiples of $3$ such that\n\n$$ a(3k) =0 $$\n\nI tried some factorization of cyclotomic polynomials without success. May be true for all odd $k$ ???\n\nEDIT: Another simple property of the sequence is\n\n(hope this may please the negative voter (???))\n\n$$ a(p) \\equiv 1 \\pmod{p} $$\n\nfor any prime $p>3$\n\n\n$$ a(n) (2^n+1) $$ is the determinant of a circulant matrix with first line $$ 3,\\binom{n}{1}, \\ldots,\\binom{n-1}{n} $$\n\nshare|improve this question\nWhy does this question deserve negative feedback? \u2013\u00a0 Daniel Parry May 14 '11 at 22:38\n@Daniel: faq, first line, first paragraph \u2013\u00a0 Franz Lemmermeyer May 15 '11 at 18:37\n\n2 Answers 2\n\nup vote 9 down vote accepted\n\nSuppose that $n=3m$, where $m$ is odd, and $u=e^{2\\pi i/3}$. Then $$ (1+u)^n+1 = ((1+u)^3)^m+1 = (-1)^m+1=0, $$ so $a(n)=0$.\n\nshare|improve this answer\nnice ! I do not see that... \u2013\u00a0 Luis H Gallardo May 13 '11 at 23:03\nReminds me of the old joke about how to simplify the expression $(x-a) (x-b) \\ldots (x-z)$. \u2013\u00a0 Terry Tao May 15 '11 at 18:37\n\nThe complex number $a(n)$ is the resultant of the polynomials $P=(X^n-1)/(X-1)$ and $Q=(X+1)^n+1$; similarly, $(2^n+1)a(n)$ is the resultant of $X^n-1$ and $(X+1)^n+1$. Since these polynomials have integer coefficients, their resultant is a rational integer.\n\nThe resultant of two polynomials vanishes whenever they have a common root. So $a(n)=0$ if and only if there exists a $n$th root of unity $u$ such that $(u+1)^n+1=0$. This implies that $u$ and $u+1$ are both roots of unity, in particular they belong to the unit circle, so that necessarily $u=e^{2\\pi i/3}$ or $u=e^{-2\\pi i/3}$, and $u+1=e^{\\pm i\\pi/3}$. If $u$ is a $n$th root of unity, one gets $3|n$; if $(u+1)^n=-1$, one obtains that $n/3$ is odd. Conversely, if $n=3m$ with $m$ odd, $u=e^{2\\pi i/3}$ satisfies $u^n=1$, $u\\neq 1$, and $(u+1)^n=-1$, hence $a(n)=0$.\n\nSince the two polynomials $P$ and $Q$ above are monic, their resultant vanishes mod $p$ if and only if they have a common root when considered as polynomials modulo $p$. If $n=p$ is prime, then $X^n-1=(X-1)^p$, so $1$ is the only root of $P$, with multiplicity $p-1$; it follows that $$\u00a0a(n)\\equiv ((1+1)^p+1)^{p-1}\\equiv (2^p+1)^{p-1}\\equiv 3^{p-1} \\pmod p.$$ If, moreover, $p\\neq 3$, then $a(n)\\equiv 1\\pmod p$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/92827/almost-all-graphs-have-a-subgraph-from-a-large-class-of-graphs-with-constant-ord\nText:\nTake the 2-minute tour \u00d7\n\nI will pose the question in relation to trees but the more general question that can be deduced from the title of this post is also very interesting.\n\nI suspect the question might have a very trivial answer using some of the relatively modern tools of which I am unaware.\n\nDenote by $T_k$ the set of all trees on $k$ vertices (up to isomorphism). Let $c$ be a positive integer and let $T$ be a subset of $T_c$ such that $$ |T| > \\frac{|T_c|}{2} $$\n\nFor $n \\geq c$ let $p_n$ be the probability that a tree, chosen uniformly at random from $T_n$ contains as a subgraph at least one tree from $T.$\n\nIs the following statement true or false?\n\n$p_n \\rightarrow 1$ as $n \\rightarrow > \\infty \\; \\; (1)$ ?\n\nIt seems to me that the following does not hold if we consider labeled trees, but I am not sure how to smartly compute the ratio $\\frac{T_n'}{T_n}$ where $T_n'$ is the subset of all trees from $T_n$ such that every graph in $T_n'$ has some subgraph from $T.$\n\nIs the above statement true? Is there any way to relax the inequality? If not, is there a way to (non trivially) restrict the inequality so that $(1)$ holds?\n\nshare|improve this question\n\n3 Answers 3\n\nLet $T$ be any tree of size $c$, and let $p_n(T)$ be the probability that a uniformly chosen tree $T_n$ of size $n$ contains a copy of $T$. I claim that $p_n(T)\\to1$ as $n\\to\\infty$ (which implies what you want).\n\nA tree can be coded by its contour function (or Dick path); a random tree of size $n$ (say, of $n$ edges) corresponds to a random walk excursion conditioned to come back to $0$ after $2n$. Now, look at the contour function of $c$: we want to know whether this occurs somewhere along that of $T_n$ (this will imply that $T_n$ contains a copy of $T$). But given the first $m$ steps of $T_n$ (for $m \\leq n/2-2c$), this occurs on the interval $[m,m+2c]$ with probability of order $e^{-\\lambda c}$, so it will occur /somewhere/ with probability going to $1$ as long as $c$ is fixed.\n\nMaybe there is some bookkeeping to be done, e.g. maybe this is only for binary trees or something; and certainly the lower bound on $p_n$ is very bad. But it seems to at least partially answer the question.\n\nshare|improve this answer\n\nWe can ask not only that something appears as a subtree, but that it appears as a \"limb\". A limb of a tree $T$ at a vertex $v$ is a maximal subtree of $T$ that includes $v$ and a neighbouring vertex. (Informally, separate $T$ at $v$ with each fragment getting its own copy of $v$; these fragments are the limbs.) Schwenk proved in 1971 that the number of (unlabeled) trees of order $n$ containing a given limb depends only on the size of the limb and not on its structure. From this he proved that almost all trees contain any given subtree as a limb. This is quite a bit stronger than what you request.\n\nMR0384582. Schwenk, Allen J. Almost all trees are cospectral. New directions in the theory of graphs (Proc. Third Ann Arbor Conf., Univ. Michigan, Ann Arbor, Mich., 1971), pp. 275\u2013307. Academic Press, New York, 1973.\n\nshare|improve this answer\nHehe, let me write a bit about the motivation behind my question :-) I am currently studying cospectrality results, more precisely, I'd like to see if there is anything to be deduced from the proof of tree cospectrality in relation with bipartite cospectrality. In the book \"Topics in Algebraic Graph Theory\" there's a sketch of the proof of Schenwk, but some critical part of it is missing. Since I am not able to get access to the cited paper, I tried to came up with my own proof and got stuck in the part posted here :-) \u2013\u00a0 Jernej Apr 5 '12 at 15:09\n\nThis sort of statement is often very strongly true - look at the pendant appearances theorem of McDiarmid, Steger and Welsh, which guarantees that for several natural graph classes (trees and planar are both included, IIRC the theorem is for monotone addable families), not only do you see one copy of any given small object from the class in a randomly chosen large member, you actually see linearly many copies as pendant subgraphs with exponentially good probability. But you have to be slightly careful generalising: I think that it is not true that graphs with genus g contain all small graphs with genus g: you are unlikely to find a large clique (even if that clique does have genus g) as what is left after removing the clique has to have genus much smaller than g, which is too restrictive to be likely.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://electronics.stackexchange.com/questions/112144/why-cant-one-battery-power-an-infinite-number-of-leds-or-anything-else\nText:\nTake the 2-minute tour \u00d7\n\nIf voltage is equal across parallel resistors, then why can't one battery supply power to a infinite number of leds, if they are all in parallel?\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 11 down vote accepted\n\nBecause a battery, like any real power source, has an output impedance. The more current you draw, the lower the voltage output. Granted, for a battery the output is not simply a fixed resistor, but the principle remains the same.\n\nAs an example, let's pretend that a 12-volt battery has a 0.1 ohm output impedance. If you were to short the outputs of this notional battery, the current would be 12 v / 0.1 ohms, or 120 amps. By the same token, if a load were to draw 60 amps, the output of the battery would be 12 - (60 * 0.1), or 6 volts.\n\nAnother way to put it is that the output impedance sets an upper limit on the amount of power a battery (or any power source) can provide. For DC, this upper limit is (V * V / R) /4. In the case of our notional battery, this upper limit is 360 watts.\n\nshare|improve this answer\n\nBecause it doesn't store an infinite amount of energy, nor can it move the energy it does store at an infinite rate. A chemical process is happening when the battery provides current and it can't happen faster or for longer than the chemicals can proceed.\n\nEven a huge voltage supply powered directly from the electrical grid couldn't power an \"infinite\" number of LEDs. Infinity is a number beyond the capacity of electrical engineers to design around. In a simulator where you can define a voltage source to have infinite capacity to deliver current it might work fine, but never in the real world.\n\nshare|improve this answer\n\"In a simulator where you can define a voltage source to have infinite capacity to deliver current it might work fine, but never in the real world\" Why would one oven dare to use the term \"infinity' carelessly in the engineering context. Simulation can get you the best fires burning inside the ocean but only in the screen of the simulation and not in the Atlantic. Simply Overall Output can never be greater than Overall input and we all know that from the high school. \u2013\u00a0 javaprince May 28 at 21:34\nWhy bother to use the term \"infinity\" in any context? We can't see past the edge of the observable universe, so we'll never have access to an infinite amount of anything. It's a mathematical construct. In engineering it's more of a placeholder for \"a number so big that we don't have to care about how big it is.\" Maybe OP is a teenage hobbyist building LED blinkies and didn't take high school calculus yet. \u2013\u00a0 Matt B. May 29 at 20:22\n\nA single LED requires a finite amount current. To have infinite LEDs means you need infinite current. This is not possible. Aside from the fact that batteries can not provide infinite current (they have internal impedance), to supply infinite current requires infinite power, to supply infinite power for any duration at all requires infinite energy. Incidentally, batteries do not contain infinite energy.\n\nYou can not hook up an infinite number of LEDs because you can not do impossible things. Sorry about that.\n\nshare|improve this answer\n\nIn this case more LEDs in parallel, with the same battery, will imply less current available to each branch of the circuit. Bellow a certain point the LEDs will stop producing light and the current will tend to zero:\n\n  \u2022 3 LED -> I/3 A\n  \u2022 5 LED -> I/5 A\n  \u2022 INF LED -> I/INF -> ~0 A\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/111066/is-there-any-techniques-for-solving-a-differential-equation-including-iterated-f/111073\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to solve this differential equation but I have no idea how.\n\n$f ' (x) = f( f( x ) ) $\n\nAlthough I don't think this differential equation is solvable, I'd like to know if there is any interesting approach on solving a differential equation of this kind, or at least a non-trivial solution of the equation.\n\nP.S. I don't think chain rule is useful for this\n\nshare|improve this question\nI think this is more suitable for math.stackexchange.com \u2013\u00a0 Beni Bogosel Oct 30 '12 at 10:49\nBeni, why do you say that? \u2013\u00a0 Vidit Nanda Oct 30 '12 at 11:57\n@Vel Nias I think math analysis questions are not welcome here. \u2013\u00a0 Anixx Nov 1 '12 at 11:03\n@Anixx. For the best of my knowledge, this claim is plain wrong. However, I agree that the remarks like \"this is homework\" or \"ask that on MSE\" that are not supported by any evidence that the person making them can solve the problem himself can be somewhat irritating... As to Beni's recommendation itself, MSE is not a bad site per se but it is just DROWNED in \"homeworks\" nowadays. MO and AoPS are much better choices for something nontrivial IMHO. \u2013\u00a0 fedja Nov 1 '12 at 12:33\nIs that a delay differential equation? \u2013\u00a0 Zsb\u00e1n Ambrus Nov 1 '12 at 14:03\nshow 2 more comments\n\n5 Answers\n\nup vote 14 down vote accepted\n\nNothing is new under the Moon...\n\n\nshare|improve this answer\nwow! Thank you very much! Did you solve it by yourself? You're amazing! \u2013\u00a0 frigen Nov 1 '12 at 3:17\nI see no solution following the link. \u2013\u00a0 Anixx Nov 1 '12 at 3:27\nMeaning you haven't scrolled down or you failed to understand what is written there? In the latter case you are welcome to ask questions. \u2013\u00a0 fedja Nov 1 '12 at 3:32\n@fedja I only see the supposed proofs of existence. Regarding the solution, you yourself wrote \"I have no hope for an explicit elementary formula for it.\" \u2013\u00a0 Anixx Nov 1 '12 at 3:34\nExistence and uniqueness of a one-parameter family of solutions, to be exact ;). Do you believe one can come with a formula? We can, probably, give it a shot and try to prove that the functions in question are not elementary but that is quite another story (and, most likely, quite a non-trivial one given that there exist formal elementary pseudo-solutions like the ones you mentioned). If you are interested in such a project, I can think of what might be the right approach here (but a bit later :)). \u2013\u00a0 fedja Nov 1 '12 at 3:46\nshow 3 more comments\n\nThere are two closed form solutions:\n\n$$\\displaystyle f_1(x) = e^{\\frac{\\pi}{3} (-1)^{1/6}} x^{\\frac{1}{2}+\\frac{i \\sqrt{3}}{2}}$$ $$\\displaystyle f_2(x) = e^{\\frac{\\pi}{3} (-1)^{11/6}} x^{\\frac{1}{2}+\\frac{i \\sqrt{3}}{2}}$$\n\nThe solution technique can be found in this paper.\n\nFor a general case, solution of the equation\n\n\nhas the form\n\n$$f(z)=\\beta z^\\gamma$$\n\nwhere $\\beta$ and $\\gamma$ should be obtained from the system\n\n$$\\gamma^m=\\gamma-1$$ $$\\beta^{\\gamma^{m-1}+...+\\gamma}=\\gamma$$\n\nIn your case $m=2$.\n\nshare|improve this answer\nSee also my answer regarding real solutions below. \u2013\u00a0 Anixx Nov 2 '12 at 10:36\nadd comment\n\nI don't know, but one answer is $f(x)=ax^c$ where $a=\\frac12(\\sqrt {3}+i){ e^{\\frac16\\pi\\sqrt {3}}}$ and $c=\\frac12+\\frac12i\\sqrt{3}$. Another is obtained by taking the complex conjugate of both $a$ and $b$.\n\nshare|improve this answer\nThe only unclear thing is where this function is defined. Note that complex powers of real numbers are complex and complex powers of complex numbers are branching like crazy... \u2013\u00a0 fedja Nov 1 '12 at 2:41\nadd comment\n\nFor what I know, the standard method is the Taylor series expansion at a fixed point, i.e. at a point $x=a$ such that $f(a)=a$.\n\nshare|improve this answer\nYes. +1 And I will give the expansion in another answer. \u2013\u00a0 Anixx Nov 1 '12 at 11:04\nadd comment\n\nAnd regarding real solutions to the question, Alex Gavrilov is completely correct. A Taylor expansion at fixed point $p$ gives us the real solution. Existence of this solution is proven in the paper which I already referenced from my another answer.\n\n$$f(z)=\\sum_{n=0}^\\infty \\frac{d_n (z-p)^n}{n!}$$\n\nwhere $d_n$ is defined as follows:\n\n$$d_0=p$$ $$d_{n+1}=\\sum _{k=0}^n d_k \\operatorname{B}_{n,k}(d_1,...,d_{n-k+1})$$\n\nwhere $B_{n,k}$ are the Bell polynomials\n\nThis gives the following starting coefficients:\n\n$$d_1=p^2$$ $$d_2=p^3+p^4$$ $$d_3=p^4 + 4 p^5 + p^6 + p^7$$ $$d_4=p^5 + 11 p^6 + 11 p^7 + 8 p^8 + 4 p^9 + p^{10} + p^{11}$$\n\n\nThe fixed point $p$ here serves as a parameter, which determines the family of solutions. According the linked theorem, the expansion should converge in the neighborhood of $p$ for $0 < |p| < 1 $ or $p$ being a Siegel number.\n\nshare|improve this answer\nAnixx, this becomes boring. Yeah, if $p$ is small enough, this has a chance to work (though I wonder how you prove that there are no other solutions). However, for large $p$, you have a polynomial with the leading term $p^N$ with $N\\approx k^2$ for the $k$'th coefficient. The miraculous cancellations can shave only something like $8^{N}$ off it for a typical $p$ (Remez). So, you are left with $(p/8)^{ck^2}$ which eats up the factorial and the geometrical progression for breakfast and happily flies to infinity by the lunchtime if $p$ is like $-20$. \u2013\u00a0 fedja Nov 2 '12 at 2:50\n@fedja yes, the proof in the linked paper requires p<1 or a Siegel number. I wiil add this to the answer. \u2013\u00a0 Anixx Nov 2 '12 at 10:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/236687/finding-the-volume-of-a-cylinder-without-using-pi?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nGiven a cylinder's radius and height, $a$ and $z$, and given that $z\\ll a$, what is it's volume without using $\\pi$?\n\nI was thinking that I could integrate to get the cylinder's circumference, and then divide this by the diameter to get $\\pi$, but I haven't tried it yet. Is this correct?\n\nshare|improve this question\nJust out of curiosity, why do you want to avoid $\\pi$? \u2013\u00a0 EuYu Nov 13 '12 at 20:50\nYou need $\\pi$ to get the cylinder's circumference. \u2013\u00a0 timvermeulen Nov 13 '12 at 20:52\nIt is simply a mind-bender, a challenging question designed to make me think. However, every solution I've tried so far has not worked. \u2013\u00a0 Stan Harvey Nov 13 '12 at 20:53\nIf the area of the base is $A$, the volume is $zA$. Or if the circumference is $C$ the volume is $aCz/2$ \u2013\u00a0 Ross Millikan Nov 13 '12 at 21:29\nYou could always take the Archimedes route: place it in a bowl full of water (or a measuring jug) and measure the volume of liquid displaced. \u2013\u00a0 Mark Bennet Nov 13 '12 at 21:51\nshow 1 more comment\n\n4 Answers\n\nIn order to exactly find the volume, you must use $\\pi$, as volume of a cylinder is given by\n\n$$V = \\pi a^2 z$$\n\nshare|improve this answer\nOver 6k now ${}$ :D \u2013\u00a0 amWhy Nov 27 '12 at 2:07\n@amWhy Haha, thank you! \u2013\u00a0 Argon Nov 27 '12 at 2:50\nadd comment\n\nThe area of the base is $\\dfrac{\\tau a^2}{2}$, so the volume is $\\dfrac{\\tau a^2 z}{2}$.\n\nshare|improve this answer\nHaha, I know about $\\tau$! It does seem like the easy way out, though... \u2013\u00a0 Stan Harvey Nov 13 '12 at 20:55\nI think $\\tau$ is cheating a bit, because $\\tau = 2\\pi$! \u2013\u00a0 Argon Nov 13 '12 at 20:56\nIt reminds me of a cure for hiccups that I was told about as a child: Run three times around the house without thinking of wolves. It is very important not to think of wolves. If you do, the hiccups will continue. Anyway, to get more mathematical, just use the first positive zero of the sine function. No \u03c0 needed. \u2013\u00a0 Harald Hanche-Olsen Nov 13 '12 at 21:16\nadd comment\n\nWhy don't you inscribe the cylinder into a prism whose base is a regular polygon and has $h=z$, and then compute its volume as a function of $n$? The resulting expression does not involve $\\pi$ and if you take the limit when $n$ goes to $\\infty$ you get the volume of the cylinder. The tricky part is to express the apothema in terms of $n$, so you can check that the limit is actually finite, but it can be done.\n\nTo me, this sounds like a typical application of the density of $\\mathbb{Q}$ in $\\mathbb{R}$.\n\nshare|improve this answer\nadd comment\n\nSure you can without pi. Remove the top of the cylinder. Fill it with fine-grained sand. Then pour the sand into a rectangular box, and measure how far it comes up. Of course, it will be an estimate, but not a bad one. (Get an even finer grade sand.) You can do the same by unscrewing the top of a sphere.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/35054/help-on-unit-conversion-problem/35061\nText:\nTake the 2-minute tour \u00d7\n\nThis is a problem from school. I will show my attempt.\n\nThe question:\n\n\"The gas constant for dry air R is 287 $\\frac{m^2}{s^2*K}$. Assuming the temperature is 330 K and the pressure is 1050 hPa, what is the atmospheric density.\"\n\nThe professor said DO NOT produce an answer by finding a formula, but to use the magic of unit conversion to try to solve things.\n\nI know density is measured in kg/m^3 or thereabouts so I tried the following:\n\n1050 hPA = 105, 000 Pa\n\n1 Pa = 1 kg/m*s^2\n\n105,000 $\\frac{kg}{m*s^2}$ * 330 K * 287 $\\frac{m^2}{s^2*K}$.\n\nThis cancels some units... but not enough...in fact it cancels just K, so far as I understand, far from what I need for my density unit.\n\nAny ideas on what Im doing foolishly here?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nthe line you wrote\n\n\nhas to read in fact\n\n$\\frac{105,000 \\frac{kg}{m*s^2} }{ 330 K * 287 \\frac{m^2}{s^2*K}} = 1.11 \\frac{kg}{m^3}$.\n\nThis comes from the gas law\n\n$p=\\rho \\ R \\ T $\n\nwhere $p$ is the air pressure and $\\rho$ is the air density. Solving for $\\rho$ you get\n\n$\\rho =\\frac{p}{R T} $\n\nfrom which the numerical solution follows.\n\nshare|improve this answer\nThank you - this is excellent and uses what I already did to show me how to arrive to a solution for problems like these! \u2013\u00a0 Anne Aug 28 '12 at 0:28\nWelcome! You started well but you have to write more carefully the units. Now and then write also the formulas you are going to use, even if they look very simple. This helps to cross-check the numerical calculation in each step. Longer multiplications with unit conversions come very quickly out of control (you are not the only one!) \u2013\u00a0 Lupercus Aug 28 '12 at 0:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/87914/linear-mmse-estimate-of-mmse-estimator\nText:\nTake the 2-minute tour \u00d7\n\nThis question is prompted by a recent discussion about the relationship between conditional expectation and covariance.\n\nSuppose that $X$ and $Y$ are zero-mean unit-variance random variables with covariance (and correlation coefficient) $\\rho$. The minimum-mean-square error (MMSE) estimator of $Y$ given $X$ is the random variable $g(X)$ that minimizes $E[(Y-g(X))^2]$, and as is well known, $$g(X) = E[Y \\mid X] ~\\text{minimizes}~E[(Y-g(X))^2]$$ It is also well known that $E[g(X)] = E[E[Y\\mid X]] = E[Y] = 0$. In general, $g(X)$ is a nonlinear function. On the other hand, if the estimator is restricted to being of the form $\\hat{Y} = aX + b$ where $a$ and $b$ are real numbers, then the linear MMSE estimator of $Y$ given $X$ is $\\hat{Y} = \\rho X$, that is, $$a = \\rho, ~ b = 0, ~\\text{minimizes}~E[(Y-aX-b)^2].$$ The linear MMSE estimator $\\rho X$ has a mean-square-error $E[(Y-\\rho X)^2] = 1 - \\rho^2$ and so the mean-square-error of the MMSE estimator $g(X)$ can be no larger:\n$$E[(Y-g(X))^2] \\leq 1 - \\rho^2.$$\n\nA simplified version of the question in the previous discussion is: if $g(\\cdot)$ is a decreasing function of its argument, show that $\\rho$ is nonpositive.\n\nMy question is: what is the linear MMSE estimate of $g(X) = E[Y \\mid X]$ given $X$? That is, what choice of real numbers $c$ and $d$ minimizes $E[(g(X) - cX - d)^2]$? Since $g(X)$ and $X$ both have zero mean and $X$ has unit variance, standard linear MMSE estimator theory gives that $d = 0$ and $$c = \\frac{\\text{cov}(g(X),X)}{\\text{var}(X)} = \\text{cov}(g(X),X) = E[Xg(X)]$$ which I think might work out to be $\\rho$, but I am not sure about this. Any suggestions on how to proceed further would be appreciated.\n\nshare|improve this question\nYour final result is correct: for simple least-squares regression of $Y$ on $X$, the line passes through the point $(\\mu_X,\\mu_Y)$ with gradient $\\rho \\dfrac{\\sigma_Y}{\\sigma_X} = \\dfrac{\\text{cov}(X,Y)}{\\sigma_X^2}$. So here it is just $\\rho$. \u2013\u00a0 Henry Dec 3 '11 at 3:36\nI am somewhat uncomfortable with your language, since I fear that this way of using the word \"linear\" might feed into the popular misunderstanding that the reason why linear regression in called linear regression is that one is fitting a line. People who think that then find it confusing when a statistician insists that one is doing linear regression when one fits a parabola or a sine wave, etc. \u2013\u00a0 Michael Hardy Dec 3 '11 at 5:38\n@MichaelHardy I thought about editing the question to say something like \"straight-line MMSE estimation\" instead of \"linear MMSE estimation\" but decided against it because linear MMSE estimation is reasonably well-established, at least in the engineering literature: Google provides over $900,000$ hits. But, thanks for your answer which I am accepting. I was able to show $E[Xg(X)] = \\rho$ for discrete and for jointly continuous random variables but wanted a proof that did not rely on special cases, and your answer gave me exactly what I wanted. \u2013\u00a0 Dilip Sarwate Dec 4 '11 at 3:56\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nYour conjecture is correct. By the law of total expectation we have $$ \\begin{align} E(X(Y-g(X)) & = E(\\;E(X(Y-g(X))\\mid X)\\;) \\\\ \\\\ & = E(\\; E(XY\\mid X) - E(Xg(X)\\mid X)\\;) \\\\ \\\\ & = E(\\; XE(Y\\mid X) - Xg(X) \\;) \\\\ \\\\ & = E( Xg(X) - Xg(X)) = 0. \\end{align} $$ Therefore $$ E(XY) = E(Xg(X)). $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54889.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nLines Intersecting within a Polygon\n\nDate: 10/24/96 at 18:12:24\nFrom: Keith Loveland\nSubject: geometry\n\nA fellow math teacher asked me this the other day:\n\nGiven an n-sided regular polygon with each vertex connected to each \nother vertex by a straight line segment, how do you determine the \nnumber of intersection points within the polygon? I tried n = 3 \nthrough n = 8, looked for a pattern, and noticed some things but \nnothing definitive. I plotted these points with the intersection \npoints as a function of n and tried curve fitting, but couldn't get an \nexact fit. Do you know a rule for this? Is there an odd and even set \nof rules?\n\nThanks for any help you're able to give me,\nKeith Loveland \n\nDate: 10/24/96 at 20:48:14\nFrom: Doctor Tom\nSubject: Re: geometry\n\nHi Keith,\n\nWell, this isn't a complete answer, but it may help some. I can solve \nthe problem if the points are \"unevenly\" spaced around the polygon, \nbut not if they're evenly spaced.\n\nWhat I mean is this - I can count the number of times pairs of lines \ncross each other, but the simplest case where this goes bad is the \nperfect hexagon. Three lines go through the center, and if those are \ncalled lines A, B, and C, then my method counts AB, BC, and CA as \nthree points when it probably should be counted as one. Notice that \nif the vertices are moved just a little, instead of hitting at a \nsingle point, there would be a tiny triangle with 3 intersections.\n\nAs the number of lines goes up, the number of these multiple\nintersections increases, and in a funny way that has to do with the \nprime factorization of the numbers.  My formula should work exactly \nfor all prime-sided polygons, for example.\n\nHere's how I did it:\n\nFor a triangle, there are no intersections.\n\nFor a square connecting points 1,2,3,4, break it into two parts: those \ninvolving a line from 1, and those not involving a line from 1.\n\nThose not involving a line from 1 include all the crossings made by \nthe triangle 234: zero to be exact.\n\nThose involving a line from 1 include 13 crossing 24, or one \nintersection.  So for a square, there is 1 total.\n\nI'll jump up a bit so you can see more easily, I think, what's going\non.  Consider a 7-sided polygon 1,2,3,4,5,6,7.\n\nSuppose you've got the crossing number for the 6 sided 2,3,4,5,6,7,\nand you just need to count the number of lines involving point 1.\n\nIf 1 connects to 4, those crossing it must connect 2 or 3 with 5, 6, \nor 7.  If 1 connects to 3, those crossing it must connect 2 with 4, 5, \n6, or 7, and so on.  If 1 connects to 2, nothing crosses it.  So \nconsider all the lines starting from 1:\n\n   1-2:  nothing               0   ways\n   1-3:  {2} to {4,5,6,7}      1x4 ways\n   1-4:  {2,3} to {5,6,7}      2x3 ways\n   1-5:  {2,3,4} to {6,7}      3x2 ways\n   1-6:  {2,3,4,5} to {7}      4x1 ways\n   1-7:  nothing               0   ways\n\nSo the answer is whatever your answer for 6 was plus 1x4+2x3+3x2+4x1.\n\nSo here's the full method, where f(n) is the number of ways to do this \nwith n points:\n\n   f(3) = 0\n   f(4) = f(3) + 1x1 = 0 + 1 = 1\n   f(5) = f(4) + 1x2 + 2x1 = 1 + 2 + 2 = 5\n   f(6) = f(5) + 1x3 + 2x2 + 3x1 = 5 + 3 + 4 + 3 = 15\n   f(7) = f(6) + 1x4 + 2x3 + 3x2 + 4x1 = 15 + 4 + 6 + 6 + 4 = 35\n\net cetera.\n\nMy intuition tells me that these numbers will satisfy a fourth-power \nequation (I am 99% sure of this for reasons that I can't explain).\n\nSo if you work out a few more terms for f(8), f(9), and so on, and \nthen imagine that the solution must look like this:\n\n   f(n) = A*n^4 + B*n^3 + C*n^2 + D*n + E\n\nPlug in n = 3, 4, 5, 6, 7, and consider A, B, C, D, and E to be \nunknowns, you'll get 5 equations in 5 unknowns, and you can work out \nA, B, C, D, and E.\n\nBut as I said, I have no idea how to take into account the multiple \n\nGood luck.\n\n-Doctor Tom,  The Math Forum\nAssociated Topics:\nHigh School Geometry\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/101140/a-question-about-collections-of-sets\nText:\nTake the tour \u00d7\n\nIs there anything known about the following problem? Which (sub)field to look into for questions of this flavor?\n\nConsider a collection $F$ of subsets of $[n]$, excluding the empty set, with the property that every element of $[n]$ is contained in exactly $n$ sets. The same set might appear more than once in $F$ (The number of sets in $F$ is thus between $n$ and $n^2$ and the sum of cardinalities is $n^2$).\n\nIs there a sequence (possibly with repetitions) of the numbers $1 \\dots n$, of length at most $n^\\alpha$, such that each set appears somewhere in the sequence in at most $n^\\beta$ contiguous blocks.\n\nHere's a small example: F = { {1,2}, {1,3}, {2,3}, {1,2,3} }. In the sequence (1,2,3) the set {1,3} can be mapped to two blocks only. In the sequence (1,2,3,1) all sets can be mapped to a single block.\n\n$\\alpha = 1, \\beta=1$ works if we use any permutation of the numbers.\n\n$\\alpha = 2, \\beta =0$ works if we concatenate all sets of F.\n\nCan we get something \"in between\" ?\n\nEDIT: as an important special case, F could consist of n \"partitions\" of [n].\n\nshare|improve this question\nUnfortunately, I do not understand the important special case when $F$ consists of $n$ partitions of $[n] := \\{ 1,2,\\dots,n \\}$. If $F$ is to have size $n$, then necessarily $F$ must consist of $n$-many copies of $\\{ 1,2,\\dots,n \\}$. Right? \u2013\u00a0 Asher M. Kach Jul 2 '12 at 23:08\nYes, if $F$ has size $n$, then $F$ just contains $n$ copies of $[n]$, in other words, $F$ contains $n$ copies of the partition, which is just the whole set itself. In this sense, it contains $n$ partitions of $[n]$ in this case too. For example, for n=3, $F$ could be {{1,2,3},{1,2,3},{1,2,3}} or {{1},{2,3},{1,2},{3},{1,2,3}} or {{1},{2},{3},{1},{2},{3},{1},{2},{3}}, etc. \u2013\u00a0 Laszlo Kozma Jul 3 '12 at 8:59\nBut $F$ is not necessarily of size $n$, it is just $\\geq n$ and $\\leq n^2$. \u2013\u00a0 Laszlo Kozma Jul 3 '12 at 9:01\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/34814/how-to-release-mathematica-from-the-pre-holdallcomplete-lock/34815\nText:\nTake the tour \u00d7\n\nNot sure if posted before, but I'm asking this question from a Mathematica fellow user who tried to load expressions, whose problem soon turned into a prison break game featuring the following code.\n\nSetAttributes[hold, HoldAllComplete];\nGetOut /: hold[GetOut] := Unset[$Pre];\n\n$Pre = hold;\n\nAfter executing this code, all subsequent evaluations are hold, including the GetOut \"key\" and the reset expression.\n\n$Pre = .\n\nAre there any ways to unhold subsequent evaluations, in addition to rebooting Mathematica?\n\nshare|improve this question\nAre you looking for a good solution, or the user's physical integrity should be preserved? \u2013\u00a0 belisarius Oct 26 at 2:36\n@belisarius Definitely both, if possible. I don't feel like hurting executed evaluations preceeding the lock. \u2013\u00a0 FrenzY DT. Oct 26 at 2:39\nGood question. I've always just restarted my kernel when I bungle up $Pre or $PreRead, since I didn't think there was any other way around. Would be interesting if there was... \u2013\u00a0 rm -rf Oct 26 at 2:46\n@rm-rf It's interesting that once we change HoldAllComplete to Hold, both the original attempts work. \u2013\u00a0 FrenzY DT. Oct 26 at 2:49\nOoh... I have a way out. Writing an answer. \u2013\u00a0 rm -rf Oct 26 at 2:52\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's nothing that can break out of a HoldAllComplete as long as it has to pass through the kernel. But what if we had a way to bypass the kernel? Hmmm... buttons!\n\nI suggest using the following button as an escape mechanism instead of your GetOut:\n\nButton[\"Clear $Pre\", Unset[$Pre]]\n\nWith this, you can clear $Pre by simply clicking it \u2014 even with the HoldAllComplete. It works because the evaluation is done via the Front End and not the kernel, thus bypassing $Pre.\n\nshare|improve this answer\nHow does the Button function get evaluated? Is it through the Front End? \u2013\u00a0 FrenzY DT. Oct 26 at 4:34\n@FrenzYDT. Read the last paragraph? \u2013\u00a0 Sjoerd C. de Vries Oct 26 at 6:45\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/77063/sequences-of-linear-combinations-of-measures/77347\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a Polish space. Let $J\\in\\mathbb{N}$.\n\nLet $\\lbrace a^n_1\\rbrace_n,\\dots,\\lbrace a^n_J\\rbrace_n$ be $J$ sequences of reals.\n\nLet $\\lbrace \\mu^n_1\\rbrace_n,\\dots,\\lbrace \\mu^n_J\\rbrace_n$ be $J$ sequences of probability measures in $\\Delta(X)$.\n\nFor each $j\\leq J$, let $\\mu^n_j$ weakly converge to $\\mu_j \\in \\Delta(X)$.\n\nLet $\\sum_{j\\leq J} a^n_j \\mu^n_j \\in \\Delta(X)$ weakly converge to $\\mu^* \\in \\Delta(X)$.\n\nConjecture: Does there exist a vector $(\\beta_1,\\dots,\\beta_J)$ of reals such that $\\mu^* = \\sum_{j\\leq J} \\beta_j\\mu_j$? It need not be unique.\n\nProof for when $J=2$:\n\n$a^n_1\\mu^n_1+a^n_2\\mu^n_2$ is a probability measure. Therefore $a^n_2 = 1-a^n_1$.\n\n$a^n_1\\mu^n_1+(1-a^n_1)\\mu^n_2 = a^n_1 (\\mu^n_1-\\mu^n_2)+\\mu^n_2 \\to \\mu^*$. Since $\\mu^n_2 \\to \\mu_2$, it follows that $a^n_1 (\\mu^n_1-\\mu^n_2)$ converges.\n\nIf $\\mu_2 = \\mu_1$, then $\\mu^* = \\mu_2$.\n\nIf $\\mu_2 \\neq \\mu_1$, then $a^n_1$ must converge since $a_1^n\\int g\\ d(\\mu^n_1-\\mu^n_2)$ must converge for all continuous bounded functions $g: X \\to \\mathbb{R}$.\n\nSome comments The proof above does not seem to generalize to $J>2$. We can also view the problem more generally as an infinite dimensional vector space problem.\n\nThat is, we can look at $\\lbrace \\mu^n_1,\\dots,\\mu^n_J \\rbrace$ as the vector subspace defined by the linear span of its elements. If $\\mu^n$ is a convergent sequence ($\\mu^n \\to \\mu^*$) such that $\\mu^n \\in span(\\mu^n_1,\\dots,\\mu^n_J)$ and $\\mu^n_j \\to \\mu_j$, is it the case that $\\mu^* \\in span(\\mu_1,\\dots,\\mu_J)$?\n\nI think the original problem places additional constraints on the problem by requiring that certain objects are probability measures (as opposed to any vector in the space of finite signed measures), but these two problems seem reasonable close.\n\nAny hints? Could the original conjecture be wrong? Strange things happen in infinite dimensional spaces...\n\nshare|improve this question\nAs it is, the generalization is false, even in $\\mathbb{R}$ (as a TVS) and $J=1$. Take $\\mu^n_1:=1/n\\to\\mu_1:=0$, and $\\mu^n=\\mu^*=1$, for all $n$. \u2013\u00a0 Pietro Majer Oct 3 '11 at 19:27\nThanks Pietro. You are right about the generalization. About your comment regarding linear independence: What if $\\lbrace\\mu_1^n,\\dots,\\mu_J^n\\rbrace$ was always a linearly independent set for each given $n\\in\\mathbb{N}$? It happens that the particular research problem I am working on does have that restriction \u2013\u00a0 BSL Oct 3 '11 at 19:52\nActually I think what is needed is the linear independence of the limit family; see below. \u2013\u00a0 Pietro Majer Oct 3 '11 at 21:39\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe generalization you suggest is true in any real topological vector space $X$ (Hausdorff or not), under the further assumption that the limit family $(\\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$ be linearly independent. The natural generalization to net convergence is also true (with essentially the same proof) .\n\nFact. The set $D _ J$ of all linearly dependent $J$-uples of elements of $X$ is a closed subset of $X^J$. Indeed, let $\\mathbb{S}$ be the unit sphere of $\\mathbb{R}^J$. Then $D _ J$ is the projection on the second factor of the closed subset of $\\mathbb{S}\\times X^J$ $$F_J:=\\Big\\{ (\\lambda,\\mu) \\in \\mathbb{S}\\times X^J\\ : \\ \\sum_{j=1}^J\\ \\lambda_ j \\mu _ j=0 \\Big\\} , $$ and the projection $\\mathbb{S}\\times X^J\\to X^J$ is a closed map because $\\mathbb{S}$ is compact.\n\nConsequence. Let $\\mu ^ n _ 0 \\in \\operatorname{span} (\\mu ^ n _ 1,\\dots,\\mu ^ n _ J)$ for all $n \\in \\mathbb{N}$ and assume that $\\mu ^ n _ j \\to \\mu ^ \\infty _ j$ as $n\\to\\infty$, for $j=0,1,\\dots, J$. Then the $(J + 1)$-uple $(\\mu ^n _ 0, \\mu ^ n _ 1,\\dots,\\mu ^ n _ J)$ is linearly dependent, so by the above fact the limit $(J +1)$-uple $(\\mu ^\\infty _ 0, \\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$ is linearly dependent too. However, by assumption $(\\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$ is linearly independent, which implies that $\\mu ^ \\infty _ 0 \\in \\operatorname{span} (\\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$.\n\nRmk. Assuming the linear independence of the limit $J$-uple is necessary, otherwise the statement is false even for $J=1$ and $X=\\mathbb{R}$ as shown in my comment above. Also, assuming that the limit $J$-uple are probability measures as in your first conjecture, is still not sufficient already for $J=2$, and in fact there's a problem in your proof. In your notation, if $\\mu_2=\\mu_1$, it is not guaranteed that $\\mu^*=\\mu_2$. Take e.g. $X=\\{0,1\\}$, a discrete two\u2212points space. Take $\\mu^n_1:=\\delta_1$ and $\\mu^n_2:=\\big(1-\\frac{1}{n}\\big)\\delta_1+\\frac{1}{n}\\delta_0$.They both converge to $\\mu_1=\\mu_2=\\delta_1$, but a linear combination of them, namely $n\\mu^n_2 - (n-1) \\mu^n_1=\\delta_0$ converges to $\\mu^*:=\\delta_0$, which is not in the span of $\\delta_1$.\n\nshare|improve this answer\nI've rewritten the whole answer. \u2013\u00a0 Pietro Majer Oct 6 '11 at 9:53\nThanks! Even though this wasn't my original problem, it will be helpful. I was interested in the original problem as an intermediate result for something else, and I can see that your solution of the modified problem might help me in other ways. It also helps that my original conjecture was proven wrong in your answer. \u2013\u00a0 BSL Oct 6 '11 at 20:34\nadd comment\n\nHere's a preliminary answer.\n\nIf you consider convex combinations, so that in particular we have $a^n_j \\in [0,1]$, then this is true. By the compactness of $[0,1]^J$, we can assume (passing to a subsequence) that $a^n_j$ converges for each $j$. If we call $\\beta_j$ the limit, then weak continuity of addition and scalar multiplication shows that $\\sum_j a^n_j \\mu^n_j \\to \\sum \\beta_j \\mu_j$, so uniqueness of weak limits gives $\\mu^* = \\sum_j \\beta_j \\mu_j$.\n\nReally, all we're using is that the space of measures with the weak topology is a Hausdorff topological vector space.\n\nI have a suspicion that any probability measure $\\mu$ that can be written as a linear combination of probability measures can also be written as a convex combination of those same probability measures, which would settle the general case. This may be a basic fact about cones in vector spaces. I'll think about it a little more.\n\nshare|improve this answer\nThanks for the preliminary reply. I will wait for your full reply. Your ideas seem promising at least. However, one note about linear combinations of probability measures: If $X=\\lbrace a, b, c\\rbrace$, $p = (1/3,1/3,1/3), q = (1/4,1/4,1/2), r = (0,0,1) \\in \\Delta(X)$. $r = -3p + 4q$. There cannot exist an $a \\in [0,1]$ such that $r= ap +(1-a)q$. \u2013\u00a0 BSL Oct 3 '11 at 19:51\nOk, good counterexample. \u2013\u00a0 Nate Eldredge Oct 3 '11 at 21:01\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/40808/velocity-of-electron-in-electrostatic-field-does-radiation-matter\nText:\nTake the 2-minute tour \u00d7\n\nThere's a voltage difference of 1000 Volts between two points 2 meters apart. An electron starts at the point of lower potential and is left to travel alone in a straight line until it reaches the other point. Question: What speed does the electron have when it reaches the second point?\n\nMy concern is whether the retardation effects of the radiation of the electron are important here. I tried doing it using the relativistic formulae for the kinetic energy and got\n\n\nwhere $m_e$ is the electron mass, $c$ the speed of light, $V$ the voltage difference between the two points, and $v$ the final speed of the electron.\n\nThis is not a homework exercise. I am just curious as to the effects of radiation.\n\nEdit: What if the potential difference was 10 000 Volts in 2 meters? What if it was 1 000 000 Volts in 2 meters?\n\nshare|improve this question\nIn principle yes, there is some loss to Bremsstrahlung, but...half a kilovolt per meter over two meters is chump change. The electron is still mostly non-relativistic (around 2% of c) and the acceleration is quite modest (by accelerator physics standards). For comparison, high gradients are measured in MV/m. \u2013\u00a0 dmckee Oct 15 '12 at 2:44\nBy the way, you'll find the math easier if you work in $c = 1$ units. Then $m_e \\approx 511\\text{ keV}$, and the above claim about the velocity becomes reasonably clear. \u2013\u00a0 dmckee Oct 15 '12 at 2:47\n@dmckee I added two additional cases. So at about a million Volts per meter is that the retardation effects of radiation start to be felt? \u2013\u00a0 becko Oct 15 '12 at 3:36\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou need to distinguish between retardation and radiation.\n\nRetardation usual refers to the effect of limited propogation seeds on interactions. That is we replace $$a_g = G\\frac{M}{r^2}$$ with $$a_{g,\\mathrm{ret}} = G\\frac{M}{r(t - \\frac{r}{c})^2} .$$\n\nThis only matters if\n\n  1. The ration of velocities in the system to propogation speeds are significant, or\n  2. The effect is constantly in one direction\n\nin other cases (as in retarded Newtonian gravity in the solar system) it simply results in a constant correction to some effective parameter of the system (reduced mass in our example).\n\nIn your case, you have a static field which means that $\\mathcal{E}(t) = \\mathcal{E}$ and the problem reduced to original case. There is no effect due to retardation.\n\nI'm taking \"radiation\" to mean the loss of energy by accelerating charges known as Bremsstrahlung.\n\nEverything you really want to know is in the Wikipedia link. You propose a linear acceleration case, so we can use $$ P_{a\\parallel v} = \\frac{q^2 a^2 E^6}{6 \\pi^2 \\epsilon_0 m^6 c^{15}}$$ for the power lost to radiation. Here I have used $E = \\gamma m c^2$ for the total energy of the electron (including it's mass).\n\nAs I noted above, the energies involved are such that the electron remains largely non-relativistic, so we'll stick to the Physics 101 for of the kinematic equations. The average velocity is about 1% of the speed of light, so the time to cover the distance is about 600 ns, and the acceleration is $a = \\frac{0.02 * 3\\times10^8\\text{ m/s}}{6\\times10^{-7}\\text{ s}} = 10^{13}\\text{ m/s}^2$.\n\nBecause the electron's energy only changes by about 2% over the whole range I'm not going to bother with a proper integration of the power, and instead just multiply (I make an error on order of 6% by doing so). The energy lost to radiation is about $$E_l = P_{a \\parallel v} t = \\frac{q^2 a^2 \\left(1.01*mc^2\\right)^6}{6 \\pi^2 \\epsilon_0 m^6 c^{15}} t = \\left(1.01\\right)^6 \\frac{q^2 a^2}{6 \\pi^2 \\epsilon_0 c^3} t$$ and (after furiously checking the units) I just start plugging in\n\n  \u2022 $q = 1.6 \\times 10^{-16}\\text{ C}$\n  \u2022 $\\epsilon_0 = 8.8 \\times 10^{-12} \\text{ m}^{-3} \\text{ kg}^{-1} \\text{ s}^2 \\text{ C}^2$\n  \u2022 $c = 3\\times10^8\\text{ m/s}$\n  \u2022 $t = 6\\times10^{-6}\\text{ s}$\n\n$$E_l \\approx 1.2\\times 10^{-28}\\text{ J} = 7 \\times 10^{-10}\\text{ eV}$$.\n\nSo the losses are trivial.\n\nThis isn't surprising since a typical CRT runs at 10+ keV over a few centimeters and doesn't spew lots of x-rays around the room.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/180974/explanation-of-why-the-height-of-a-binary-tree-thetalgn\nText:\nTake the 2-minute tour \u00d7\n\nFrom Heap Sort chapter of Introduction to algorithms :\n\nSince a heap of n elements is based on a complete binary tree , its height is $\\theta({lg}(n))$.\n\nI know this is correct but how can this be proved ?\n\nshare|improve this question\nHint: prove that a complete binary tree of hight $h$ has $2^h$ elements \u2013\u00a0 pritam Aug 10 '12 at 9:03\n@pritam thats a pretty good way of coming to this conclusion . Can you throw an answer so that I can accept it as the accepted answer . \u2013\u00a0 Geek Aug 10 '12 at 9:11\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nIf we write down the series counting the number of elements at each level of the tree, then we get $$ \\mbox{Number of elements} = n = 1 + 2 + 4 + 8 + ... + k \\tag{1}$$ That is, at the first level, there is only one node, the root of the tree. At the second level are the root's two children. At the third, each of those two children's two children (making the total four at the third level). And so on until the last level, in which there are $k$ leaves of the tree.\n\n$n$ is a finite geometric series whose first element is $a = 1$, ratio is $r = 2$. Using the formula for a geometric series, we get: $$ n = \\frac{a(1 - r^i)}{1 - r} = 2^i - 1 $$ We seek $i$, which is the number of elements in the sequence given by $(1)$: $$ n = 2^i - 1 \\Rightarrow i = \\lceil\\lg(n + 1)\\rceil $$\n\nThis means there are $\\lceil\\lg(n + 1)\\rceil$ levels in the tree, or $\\lceil\\lg(n + 1)\\rceil$ terms in the series in $(1)$. The ceiling is required because nodes taking up part of a level warrant an extra count to the number of levels. We're interested in the height of the tree, not the number of levels. A keen observation will reveal that the height $h$ of a complete binary tree is one less than the number of levels. In other words, the height is the number of plus signs in $(1)$. So the height $h$ of a complete binary tree in terms of its $n$ elements is $$ h(n) = \\lceil\\lg(n + 1)\\rceil - 1 \\tag{2}$$\n\nTo show that $h(n) \\in \\Theta(\\lg(n))$, first note the ceiling function will not affect the asymptotic behavior of $h(n)$, so the rounding up will be ignored for the rest of the discussion.\n\n$h(n)$ is in $\\Theta(\\lg(n))$ if $$ \\exists n_0 \\in \\mathbb{N},\\; c_1, c_2 \\in \\mathbb{R},\\; c_1, c_2 > 0 : c_1 \\lg(n) \\le \\lg(n + 1) - 1 \\le c_2 \\lg(n), \\quad \\forall n \\ge n_0 \\tag{3}$$\n\nFor the lower bound, let $c_1 = \\frac{1}{2}$. Then we have: $$\\frac{1}{2}\\lg(n) = \\lg(\\sqrt{n}) \\le \\lg(n + 1) - 1, \\quad \\forall n \\ge 1 \\tag{4}$$ In $(4)$, $n_0 = 1$.\n\nFor the upper bound, let $c_2 = 2$. We have: $$2\\lg(n) = \\lg(n^2) \\ge \\lg(n + 1) - 1, \\quad \\forall n \\ge 1 \\tag{5}$$ where $n_0 = 1$ here too.\n\nSo, for $c_1 = \\frac{1}{2}$, $c_2 = 2$, and $n_0 = 1$, $(3)$ holds. Therefore $h(n) \\in \\Theta(\\lg(n))$.\n\nshare|improve this answer\n@ladadhini I changes my accepted answer as it has proved it rigorously . Can you explain a little bit more why the ceiling is required ?I guess the ceiling is required when it is near complete binary tree and not a complete binary tree ? Thanks . \u2013\u00a0 Geek Aug 10 '12 at 11:31\n@Geek: Yes, you're on the right track, though a complete binary tree, despite its name, permits the last level to not be \"full.\" The reason we must round up is the same reason we round up for the following situation: if a school bus has a capacity of 30 children, how many buses are need to transport 100 children? \u2013\u00a0 ladaghini Aug 10 '12 at 12:54\nI have posted another question related to this here . can you try to clear my doubts on that too ? \u2013\u00a0 Geek Aug 10 '12 at 13:03\nadd comment\n\nUsing induction one can prove that a complete binary tree of hight $h$ has $2^h-1$ elements. So you have $n=2^h-1$, i.e. $h=\\lg (n+1)=\\theta(\\lg n)$.\n\nshare|improve this answer\nShouldn't that be $2^h-1$? \u2013\u00a0 Mike Aug 10 '12 at 9:17\n@Mike the number of internal nodes in a complete binary tree is 2^h-1 . \u2013\u00a0 Geek Aug 10 '12 at 9:21\n@Mike Yeah you are correct, actually i was thiking $\\theta(2^h)$; anyway corrected it \u2013\u00a0 pritam Aug 10 '12 at 9:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/105217/how-to-easy-calculate-card-of-union-of-sets/105218\nText:\nTake the 2-minute tour \u00d7\n\nFor example I have sets\n\n\nfor some reason I can't do |AUBUC|, only what i can do is calculate |A|, |B|, |C|.\n\nHow do I do to calculate |AUBUC| in this situation? is there any algorithm?\n\nshare|improve this question\nI am not sure whether this question better fits MO, or MSE. \u2013\u00a0 Ilya Aug 22 '12 at 9:44\nWithout further information, you can't do it. \u2013\u00a0 Yemon Choi Aug 22 '12 at 10:24\nMark, your question isn't a good fit for this site. You'd be better off trying one of the other math sites listed in the FAQ. Good luck. \u2013\u00a0 Tom Leinster Aug 22 '12 at 10:42\nthanks all, Actually it is computer-science relative question \u2013\u00a0 mark Aug 23 '12 at 3:00\nThis is an enumerative combinatorics question, even if it originates in computer science. (Many enumerative combinatorics do arise in computer science.) To learn more about this sort of thing, I'd suggest reading an enumerative combinatorics textbook. \u2013\u00a0 Patricia Hersh Aug 23 '12 at 12:47\nshow 1 more comment\n\nclosed as too localized by Yemon Choi, Tom Leinster, Felipe Voloch, Asaf Karagila, quid Aug 22 '12 at 11:34\n\n\n2 Answers\n\nTo extend the last sentence of Ilya's reply have a look in Wikipedia for the inclusion-exclusion principle which accounts for the size of the intersections by the formula\n\n$$ \\left| A \\cup B \\cup C \\right | = \\left| A \\right| + \\left| B \\right| + \\left| C \\right| - \\left| A \\cap B\\right| - \\left| B \\cap C \\right| - \\left| A \\cap C \\right| + \\left| A \\cap B \\cap C\\right|. $$\n\nThere is an obvious generalisation to an alternating sum over the cardinalities of all the $k$-fold intersections in the case of $n$ sets. Of course if you don't know the cardinalities of the intersections this is not so useful!\n\nshare|improve this answer\nyes, I agree with you, the info is not enough so that it's nearly impossible to calculate the result. \u2013\u00a0 mark Aug 23 '12 at 3:02\n@Michael: Sorry I couldn't resist correcting \"principal\" to \"principle\". \u2013\u00a0 Mark Grant Aug 23 '12 at 17:48\n@Mark. Ah thanks for fixing that. Too many principal bundles in my past perhaps ? \u2013\u00a0 Michael Murray Aug 24 '12 at 10:09\n@Michael: Better that than a lack of principles! \u2013\u00a0 Mark Grant Aug 24 '12 at 20:43\nadd comment\n\nI do not know, how much is it related to set-theory, but from the measure-theoretical point of view, $|A| = \\mu(A)$ where $\\mu$ is a counting measure, i.e. the one which assigns the unit weight to each element of the set. In general, if you have a finite number of sets $A_1,\\dots,A_n$ then $$ \\mu(A_1\\cup\\dots\\cup A_n)\\leq\\sum\\limits_{i=1}^n\\mu( A_i) $$ which is quite a trivial fact in your case. The strict inequality only holds when the sets are not disjoint, i.e. $A_i\\cap A_j$ is not empty for some $i\\neq j$. In that case, you have also to account for how many element are in the intersection - and to be able to compute $\\mu(A_1\\cap A_2)$, $\\mu(A_1\\cap A_2\\cap A_3)$ etc.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/1556/is-a-w-in-a-b-c-mid-aw-2-bw-3-cw-a-cfg\nText:\nTake the 2-minute tour \u00d7\n\nI wonder whether the following language is a context free language: $$A = \\{w \\in \\{a,b,c\\}^* \\mid \\#_a(w) + 2\\#_b(w) = 3\\#c(w)\\}$$ where $\\#_x(w)$ is the number of occurrences of $x$ in $w$. I can't find any word that would be useful to refute by the pumping lemma, on the other hand I haven't been able to find a context free grammar generating it. It looks like it has to remember more than one PDA can handle.\n\nWhat do you say?\n\nshare|improve this question\nIs the # meant to be part of the alphabet or is it a separate symbol? What does it mean to add #a and 2#b? \u2013\u00a0 Sam Jones Apr 28 '12 at 21:51\nIn eastern Europe # is used to mean number of so #a should mean number of times the symbol a is present \u2013\u00a0 Vitalij Zadneprovskij Apr 28 '12 at 21:53\nThat's a nice question. It is tempting to say $A = \\{w \\mid |w|_a = |w|_b = |w_c|\\}$ which is not context-free (by intersection with $a^*b^*c^*$ and the canonical $\\{a^nb^nc^n \\mid n \\in \\mathbb{N}\\}$). \u2013\u00a0 Raphael May 9 '12 at 8:57\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nYes, $A$ is a CFL. Use the context free language (with the notation $|x|_0$ meaning what you have as #0's in $x$):\n\n$B=\\{x\\in \\{0,1\\}^*:3\\cdot|x|_0=|x|_1\\}$\n\nand the morphism $f:\\{a,b,c\\}^*\\rightarrow\\{0,1\\}^*:$ $ f(a)=0, f(b)=00, f(c)=1$\n\nso that\n\n\nSince the CFL's are closed under inverse morphism, $A$ is a CFL.\n\nThe proof that $B$ is a CFL is a bit tricky. Let's do it for the simpler case $C=\\{x:|x|_0=|x|_1\\}$, which can fairly easily be generalized to work for $B$ (or use another morphism).\n\nDesign a PDA which keeps track of $|x|_0-|x|_1$ at all points of the input, using the stack to keep track of the difference, having read $x$. The PDA accepts only when that difference is zero, that is, the stack is empty. The idea is to push a $0$ on seeing a $0$ on the input string, and pop a $0$ when seeing a $1$ in the input. The problem is that difference might go negative at times, and you can't pop an empty stack. In that case, however, the PDA goes into another mode (a different set of states) where it pushes a $1$ on seeing an input of $1$ and pops a $1$ on seeing an input of $0$. So the second mode handles the negative case. It alternates between the two modes, accepting only if the stack if totally empty, that is, in-between the modes.\n\nOr, you can do it with the grammar: $S\\rightarrow 0S1|1S0|SS|\\epsilon$. That clearly generates only strings of C, but proving that it generates all of $C$ is a bit involved, but here's a sketch, by induction on string length.\n\nAn isosymbolic string $x$ (that is $|x|_0 = |x|_1$) could be null, in which case the $\\epsilon$ production applies giving the basis of the induction. Otherwise $x$ either starts and ends in different symbols (one end $0$ and the other end $1$), or the same symbol (both $0$ or both $1$). In the not-equal case, the last production to apply is either the $0S1$ or the $1S0$ production, allowing us to strip off the first and last symbols, getting a shorter isosymbolic string, so the induction applies.\n\nIn the equal case, as with the PDA, we keep track of $|y|_0-|y|_1$ as we move from left to right through prefixes $y$ of $x$. If the first and last symbols of $x$ are the same, it's fairly easy to see that that expression must be zero somewhere in the interior of the string. For example, if $x$ starts and ends with $0$, then after the first symbol the difference is $+1$ and before the last symbol it is $-1$, so it must have crossed zero in the interior. Split the string in two at that spot (reversing the $SS$ production) and the two halves, both shorter than $x$, are both isosymbolic. So the induction works there too, and we are done.\n\nshare|improve this answer\nIt's not too difficult to see that the PDA accepting $B$ can be modified to accept $A$. It simply pushes one stack symbol when it sees $a$'s, two symbols when it sees $b$'s and pops three symbols when it sees $c$'s. Again, one has to be careful when the difference becomes negative. We also have only used one stack symbol here so the language is, in fact, a one-counter language (the one-counter languages are a strict subset of the context-free languages). \u2013\u00a0 Sam Jones Apr 28 '12 at 22:49\n@Sam Jones -- Absolutely correct. But (a) the result about $C$ is fairly well known, so most of the work is done if you accept it as a basic result (I included the proof sketch just for completeness); (b) Proving things about formal languages with morphisms (and transducers, relations, etc) is not only neat and often quite efficient, it's the basis of a very general algebraic theory, that stands in relation to automata and grammars much the way usual algebra relates to geometry. So it's worthwhile building those muscles. \u2013\u00a0 David Lewis Apr 29 '12 at 1:04\nI couldn't agree more. \u2013\u00a0 Sam Jones Apr 29 '12 at 11:11\nGreat approach. But why did you not use another morphism, as you suggest in your answer, i.e., mapping to $C$ by having $f(c) = 111$ instead? \u2013\u00a0 Hendrik Jan Dec 22 '12 at 12:04\nadd comment\n\nAll an automaton has to remember is the balance of the equation: $\\#_a + 2 \\#_b - 3 \\#c$. It can do this by maintaining a unary counter on the stack, using two symbols - and +:\n\n  \u2022 On encountering $a$, pop - if possible, otherwise push +.\n  \u2022 On encountering $b$, pop two - if possible, otherwise pop - and push + if possible, otherwise push ++.\n  \u2022 On encountering $c$, pop three + if possible, or pop ++ and push -, or pop + and push --, or push --- (so that there is never both a + and a - on the stack).\n\nThe automaton accepts the input only if the stack is empty.\n\nTo build a grammar, decompose each word in $A$ into disconnected groups such that the letter that pushes a symbol is grouped with the letter that pops it. (\u201cGroup\u201d is to be taken in the intuitive sense, this has nothing to do with the mathematical concept.) For example (each color represents a different group):\n$\\quad \\color{red}{aa}\\color{blue}{abc}\\color{red}{ca}\\color{magenta}{cab} $\n$\\quad \\color{red}{b}\\color{blue}{abc}\\color{red}{ac}\\color{magenta}{acaa} $\n$\\quad \\color{red}{a}\\color{blue}{abc}\\color{red}{cacaab} $\n$\\quad \\color{red}{b}\\color{blue}{abc}\\color{red}{cb}\\color{magenta}{cab}\\color{red}{aca} $\n$\\quad \\color{red}{bcbcb} $\n\nBetween the elements of a group, what you have is an element of $A$ (since it brings the balance back to where it was). Furthermore, there are only a finite number of possible groups if you decompose as much as possible, because the length of each group is at most the least common multiple of the coefficients of the equation ($\\mathrm{lcm}(1,2,3)=6$): if there was a longer group, you could find a decomposable subgroup inside it. This leads to the following grammar, which expresses that a word in $A$ is the group that it starts with with words in $A$ interspersed at any point:\n\n$$\\begin{align*} S ::=& \\epsilon \\\\ |& a \\,S\\, a \\,S\\, a \\,S\\, c \\,S\\, \\\\ |& a \\,S\\, b \\,S\\, c \\,S\\, \\\\ |& b \\,S\\, b \\,S\\, b \\,S\\, c \\,S\\, c \\,S\\, \\\\ |& b \\,S\\, a \\,S\\, c \\,S\\, \\\\ |& \\ldots & \\text{(all permutations of \\(a,b,c\\) above)} \\\\ \\end{align*}$$\n\nThis approach generalizes to any (one) linear equation between the number of occurrences of various letters.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64233/could-this-be-a-np-complete?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\n Given a undirected and unweighted graph G(V,E). M is a subset of vertices of V. \n s is a vertex in V - M.\n Find an optimal tree T of G defined as:\n (1) M and s are in V(T)\n (2) Distance (which is length of the shortest path) from s to any vertex in M in tree T is equal to distance from s to these vertices in G\n (3) No other tree T' satisfying condition (1) and (2) can have fewer nodes than T  \nMy idea was to use Dijkstra's algorithm to find shortest path from s to all vertices in M. However, there could be many shortest paths from vertex s to a vertex v. So, I will pick the shortest path that has the most number of vertices in M.\n Merge all these paths together to get tree T.  \nThis seems to solve the problem in polynomial time. However, my concern is the number of shortest path from vertex s to a vertex v could be very large that can make this algorithm be exponential. I don't know if there is any upper bound for the number of shortest path between 2 vertex in a graph.  \nAlso, does any one know if this problem is NP problem or it could be solved in polynomial time?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nThe problem is NP-complete.\n\nI think that the following algorithm describes a polynomial reduction of SAT to your problem.\n\nLet S be an instance of SAT. So you have a finite set of clauses $C_1$, $C_2$, ...,$C_n$.\nand a finite set of variables $p_1$, $p_2$, ..., $p_k$. Each clause contains some literals, i.e., variables $p_i$ and/or negated variable $\\lnot p_i$. (in 3sat we assume that each clause contains at most 3 literals.) We may assume that for each variable $p$ there is a clause $C_p$ containing only $p$ and $\\lnot p$, so $n\\ge k$.\n\nMake S into a graph as follows: There is a special vertex $ s$. For each variable $p$ there are two vertices $p$ and $\\lnot p$, both connected to $s$ (EDITED to simplify) by an edge. There is a vertex for every clause. Each literal $L$ is connected by an edge to each clause $C$ in which $L$ appears.\n\nThe set $M$ will be the set of all clauses.\n\nIf the original problem S was satisfiable, say with an assignment $A$, then then there is an optimal tree with $n+k$ edges: Connect $s$ with all literals which are true under $A$, and connect each clause $C$ with a literal $L$ in $C$ that is true under $A$.\n\n(EDITED to clarify and to close a gap:) Conversely, if there is an optimal graph with at most $n +k$ edges, then:\n\n  1. Each clause has to be on the tree, so it has to be connected to some literal. This costs $n$ edges.\n\n  2. For each variable $p$, either $p$ or $\\lnot p$ has to be on the tree (because of $C_p$), so either $p$ or $\\lnot p$ has to be connected (by an edge) to $s$ (because the distance has to be $1$). These connections cost $k$ edges.\n\n  3. So from each such pair EXACTLY one is connected with $s$. Those literals which are connected to $s$ now define a satisfying truth assignment.\n\nHence the instance $G,M$ of your problem that I constructed from the SAT problem $S$ has a solution of size at most $n+k$ iff $S$ is satisfiable. So any algorithm to solve your problem also solves SAT. Hence your problem is NP-complete.\n\nshare|improve this answer\nThanks a lot goldstern. I thinks this transformation is correct. I just wonder why we don't connect s directly to each variable instead of going through path o length n. That way we can have a tree of n + k edges, can't we? \u2013\u00a0 chepukha May 8 '11 at 1:18\nanother problem with this transformation is that you're trying to limit the number of edges while the optimal tree must have minimum number of vertices. With the way you select the tree, the number of vertices is not minimum. \u2013\u00a0 chepukha May 8 '11 at 5:02\nYou are right, the paths are not necessary. I edited my answer to simplify it (and also to clarify some points). \u2013\u00a0 Goldstern May 8 '11 at 8:19\nI do not understand your question about edges vs vertices. A tree with v vertices has v-1 edges. So you minimize the number of edges iff you minimize the number of vertices. \u2013\u00a0 Goldstern May 8 '11 at 8:20\nMaybe I didn't quite understand your proof. So let me give an example. Let say I have a 3SAT (x+y+z)(x+\u00acy+z). We can assign x=y=z=T. So, if we follow the proof, then we will get a tree with 6 vertices and n+k=2+3=5 edges. However, I can have another smaller tree that can have the same shortest paths to vertices in M={C1, C2}. That tree has 3 edges connecting the vertex representing x with s, C1, and C2. It also has only 4 vertices. Am I missing something here? \u2013\u00a0 chepukha May 8 '11 at 8:48\n\nJust a rough idea: (I am not really an expert on graph theory, so there may be a much better upper bound.)\n\nYou can group the vertices according to their distance to $s$, say\n\n$L_i=\\{v\\in V|dist(s,v)=i\\}$\n\nThen of course the $L_i$ are pairwise disjoint. Any shortest path from $s$ to a given vertex $v$ has to pass the $L_i$ ascending (you can easily proof this fact), so first a vertex from $L_1$, then one from $L_2$, and so on. That means there are at most $\\prod_{i=1}^{dist(s,v)-1}|L_i|$ shortest paths. As $|L_i|\\leq |V|$, you have a polynomial upper bound.\n\nWhile thinking about it: There might be a way to press this bound much lower, as $|L_i|=|V|$ only happens when all vertices have distance 1, which means the shortest path is the direct connection between $s$ and $v$. For decreasing amount of vertices in the $L_i$, the possible length of the path grows. You probably could use this to get a better bound.\n\nI do not see why the rest of your algorithm should not work.\n\nshare|improve this answer\nThank you. I didn't have time to verify your proof here but I think the above transformation is correct. \u2013\u00a0 chepukha May 8 '11 at 1:19\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/18115/databaselink-mysql-query-with-client-server-compression/18935\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to reduce transfer time when accessing rows of a mysql table over a network, where each row has a lot of data. Is there a way to enable client-server compression when accessing a mysql database via ``DatabaseLink```?\n\nAs a workaround, I could request a column with COMPRESS(column_with_lots_of_data) in my SQLExecute query, but it is not clear how to uncompress the result on the Mathematica side.\n\nshare|improve this question\n\n2 Answers 2\n\nYou can decompress on the Mathematica side easily.\n\nCompressed MySQL reply has the following format:\n\n  \u2022 first four bytes are size of uncompressed data (lowest byte first)\n  \u2022 the rest is the string compressed with deflate algorithm (zlib library)\n\nHere is an example of a reply:\n\n{10, 0, 0, 0, 120, 156, 243, 72, 205, 201, 201, 87, 240, 170, 112, 82, 4, 0, 19, 42, 3, 58}\n\nTo decompress it in Mathematica you can use Developer`RawUncompress function.\n\nFromCharacterCode[Developer`RawUncompress[Drop[%, 4]]]\nshare|improve this answer\nNick, your ``DeveloperRawUncompress is useful, and I've been using it. But this afternoon I found the answer to the question on client/server compress in the official Connector/J docs. \u2013\u00a0 JxB Feb 2 '13 at 19:58\nup vote 0 down vote accepted\n\nThe official documentation for MySQL Connector/J has the answer. Setting the useCompression connection property to true enables zlib compression between client and server.\n\nYou can set this property when creating a new resource name:\n\n\nFrom the menu, open a connection, click \"New\", then \"Next\", give the source a name, and select \"MySQL(Connector/J)\" as the type. Specify the host info, user, password, database, and when prompted for connection properties, click \"Add Property\", and set the property name to useCompression and the value to true.\n\nI've seen speedups of 70% when transferring large amounts of data (your mileage may vary).\n\nAlternatively, client/server compression can be set programmatically using WriteDataSource:\n\nWriteDataSource[\"testSQL\", \"MySQL(Connector/J)\", URL -> \"main/test\", \n    Username -> \"user\", Password -> \"password\", Location -> \"System\",\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/112671/showing-a-coercivity-condition-for-this-bilinear-form/112706\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $\\Omega \\subset \\mathbb{R}^n$ is a compact domain. Let $f$ and $J$ (and also $\\frac 1J$) be $C^1$ functions on $\\Omega$. Consider the bilinear form $a:H^1(\\Omega) \\times H^1(\\Omega) \\to \\mathbb{R}$ $$a(u,v) = \\int_\\Omega uvf + \\int_\\Omega \\nabla u MM^T\\nabla v - \\int_\\Omega \\nabla u MM^T\\nabla J \\frac{v}{J}$$ where $M = D\\Phi$ is the matrix representation of the derivative of a diffeomorphism $\\Phi$ between two compact hypersurfaces in $\\mathbb{R}^n$ (so $\\Phi$ and its derivatives are bounded).\n\nHow do I show that there exists a $C$ such that $$a(u,u) + C\\lVert u \\rVert^2_{L^2(\\Omega)} \\geq K\\lVert u \\rVert^2_{H^1(\\Omega)}$$ for some $K$. (i.e. that $a$ satisfies a coercivity condition).\n\nI don't know how to show this. How do I deal with the last term in $a$, which has a minus sign? The second term is fine since it becomes $|\\nabla u M|^2 > 0$ since $M$ represents derivative of the diffeomorphism $\\Phi$ and therefore has full rank. But basically I can't get a positive constant in front of $\\lVert \\nabla u \\rVert_{L^2}$ term.\n\nshare|improve this question\nCross-posted at math.stackexchange: math.stackexchange.com/questions/237955/\u2026. \u2013\u00a0 Davide Giraudo Nov 17 '12 at 17:28\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nI think the first thing to iron out is that $\\Omega$ should be open, since compact would be closed and then even defining $H^1(\\Omega)$ is not trivial. Maybe assume $\\Omega \\subset \\mathbb{R}^N$ is open and $J,f$ being $C^1(\\overline{\\Omega})$.\n\nHowever, this is not the issue you are interested in. You want to know the relationship between\n\n$\\int_\\Omega \\nabla u MM^t \\nabla u\\;dx$\n\n\n$||\\nabla u||_{L^2(\\Omega) }$.\n\nGiven $M$, can you show that the eigenvalues of $MM^t$ are strictly positive? The ellipticity constant is just a statement on the eigenvalues of the matrix associated with the coefficients. So what you are looking to do is to prove that this matrix is strictly positive definite. I hope you can compute this successfully.\n\nEDIT: The result you are looking for in this case is to show that $\\xi MM^t\\xi \\geq c$ for all $\\xi \\in S^{N-1}$, which would imply the coercivity you are looking for. A priori, $MM^t$ positive definite means you can this inequality with $c=0$, but you need a little better if this is your approach. For example, if the eigenvalues of $MM^t$ are $\\{\\lambda_i\\}_{i=1..N}$, with $\\min_i \\lambda_i = \\tilde{\\lambda}>0$, and these eigenvalues correspond to eigenvectors $x_i$ which form an orthogonal basis for $\\mathbb{R}^N$, then this is true, as follows.\n\nAny $x\\in S^{N-1}$ can be represented as $x=\\sum_{i=1}^N c_i x_i$, where $\\sum_i c_i^2=1$, and we compute $MM^t x = \\sum_i c_i MM^t x_i = \\sum_i c_i \\lambda_i x_i$, therefore $xMM^tx = \\sum_i c_i^2 \\lambda_i \\geq \\tilde{\\lambda}$, where we have used $\\sum_i c_i^2=1$.\n\nThis is only an example - you should verify that the eigenvalues correspond to orthonormal eigenvectors to do this, or adapt the proof to something which is close and true in your case.\n\nshare|improve this answer\n@Daniel Thanks for the answer. MM^T is symmetric and positive definite (by assumption), so a theorem says all the eigenvalues are positive. This is enough, right? \u2013\u00a0 user28178 Nov 17 '12 at 22:22\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/236851/how-to-show-that-two-equivalence-classes-are-either-equal-or-have-an-empty-inter/237523\nText:\nTake the 2-minute tour \u00d7\n\nFor $x \\in X$, let $[x]$ be the set $[x] = \\{a \\in X | \\ x \\sim a\\}$.\n\nShow that given two elements $x,y \\in X$, either\n\na) $[x]=[y]$ or\n\nb) $[x] \\cap [y] = \\varnothing$.\n\nHow I started it is, if $[x] \\cap [y]$ is not empty, then $[x]=[y]$, but then I am kind of lost.\n\nshare|improve this question\nI made some edits to this question, mostly for presentation; please continue to edit (or revert back) if I have (inadvertently) changed the meaning. \u2013\u00a0 Douglas S. Stones Nov 14 '12 at 1:13\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nThe problem with your \"start\" is that you are assuming exactly what you want to prove.\n\nYou need to apply what you know about the properties of an equivalence relation, in this case, denoted by $\\;\\sim\\;$ You'll need to use the definitions of $[x], [y]$: $$[x] = \\{a \\in X | \\ x \\sim a\\} \\text{ and}\\;\\;[y] = \\{a \\in X | y \\sim a\\}.\\tag{1}$$\n\nNote that $[x]$ and $[y]$ are defined to be sets, which happen also to be equivalence classes. To prove that two sets are equal, show that each is the subset of the other.\n\n$$\\text{Now, suppose that}\\;\\; [x] \\cap [y] \\neq \\varnothing.\\tag{2}$$\n\nThen there must be at least one element $a\\in X$ that is in both equivalence classes. So we have $a \\in [x]$ and $a\\in [y]$. Here's where the definitions given by $(1)$ come in to play; together with the definition of an equivalence relation (the fact that $\\sim$ is reflexive, symmetric, transitive), you can show that:\n\n  \u2022 $a \\in [x]$ and $a \\in [y] \\rightarrow x \\sim y$ and $y\\sim x\\;\\;\\forall x\\in [x],~\\text{and}~ \\forall y \\in [y]$.\n\nAnd so we have, trivially $$[x]\\subset [y] \\;\\;\\text{and}\\;\\; [y]\\subset [x]\\iff [x]=[y].$$ Therefore, having assumed $(2)$, it follows that $[x] = [y]$.\n\nThe only other option is that $(2)$ is false, in which case we have $[x] \\cap [y] = \\varnothing$.\n\n$\\therefore$ either $[x] = [y]$ OR $[x] \\cap [y] = \\varnothing$.\n\nshare|improve this answer\n+1. sorry Amy. There's just a small edit. \u2013\u00a0 Babak S. Aug 13 '13 at 10:40\n\nOnce you proved that $[x] \\cap [y] \\neq \\varnothing$ implies $[x] = [y]$ then you are done. To do so, just notice that if the intersection is not empty (say it contains $a$), then any element in $[x]$ is equivalent to $a$, and so is any element in $[y]$, so you get your result by transitivity ($[x] \\subset [y]$ and $[y] \\subset [x]$).\n\nshare|improve this answer\n\nLemma If $u \\in [v]$ then $[u] = [v]$ proof: If $u \\in [v]$ then by definition of equivalence class we have $v\\sim u$, by transitivity of equivalence relations we have $\\forall a \\in X$, $\\ v \\sim a$ iff $\\ u \\sim a$. Hence we conclude $[v] = \\{a \\in X | \\ v \\sim a\\} = \\{a \\in X | \\ u \\sim a\\} = [u]$.\n\nCorollary Suppose $u \\in [x] \\cap [y]$ then $[u] = [x]$ and $[u] = [y]$ so $[x] = [y]$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://www.chegg.com/homework-help/questions-and-answers/satellite-moves-circular-orbit-around-earth-speed-64-km-s-determine-satellite-s-altitude-s-q1065421\nText:\nA satellite moves in a circular orbit around the Earth at a speed of 6.4 km/s.\nDetermine the satellite\u2019s altitude above the surface of the Earth. Assume the\nEarth is a homogeneous sphere of radius 6370 km and mass 5.98 \u00d7 1024 kg. The\nvalue of the universal gravitational constant is 6.67259 \u00d7 10-11 N \u00b7 m2/k2\nAnswer in units of km.\n\n\nDetailed answers to tough\nhomework problems"}
{"text": "Retrieved from http://math.stackexchange.com/questions/245397/can-i-execute-this-division-at-this-point\nText:\nTake the 2-minute tour \u00d7\n\nI realize this is basic, but this little doubt has been around with me for quite a while:\n\nI have this:\n\n\nI need it to end up with this shape:\n\n\nAt first, I thought \"well, I simply remove the $(2n+3)$ from the numerator and from the denominator and done!\", but I would like to know if there are any other steps in the middle I am \"jumping\" by doing so.\n\nBasically, I would like to do it as \"slowly\" as possible (because my professor will want to during the tests...). Is there any small step I am missing?\n\nshare|improve this question\n@WillHunting: Ah! I see! After seeing the answers below, I realized that.. you're right. Thank you :) \u2013\u00a0 Zol Tun Kul Nov 27 '12 at 2:19\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\n$\\quad\\dfrac{(2n+3)(n+1)}{(2n+1)(2n+3)}\\quad$ can be simplified to $\\quad\\dfrac{n+1}{2n+1}\\quad$ by canceling out the common factor of\n\n$(2n + 3)$ in the numerator and denominator.\n\nBut then you need to check for what happens at $\\;n = -\\dfrac{3}{2}$.\n\nAt $n = -\\dfrac{3}{2}$, the original fraction is undefined (division by zero). You lose that information when simplifying.\n\nFor $\\quad\\dfrac{(2n+3)n+1}{(2n+1)(2n+3)},\\quad$ multiply out the numerator: $(2n+3)n+1 = 2n^2 + 3n +1$. You can then factor the numerator to obtain $(2n+1)(n+1)$. This gives you:\n\n$$\\frac{(2n+1)(n+1)}{(2n+1)(2n+3)} = \\frac{n+1}{2n+3}.$$\n\nBut in this case, you need to consider that $2n + 1 = 0 \\rightarrow n = -\\dfrac12$, where the original fraction is undefined.\n\nshare|improve this answer\n+1 for the $\\frac{-3}{2}$ undefinition thing. Didn't think about it (not sure if it will really destroy my proof, but it is nice to keep in mind). \u2013\u00a0 Zol Tun Kul Nov 27 '12 at 2:36\nIt is good to keep in mind! You need to rule out any values of $n$, in this case, for which the denominator evaluates to zero. \u2013\u00a0 amWhy Nov 27 '12 at 2:38\n\nThis will take you there $$(2n+3)n + 1 = 2n^2 + 3n + 1 = (2n +1)(n+1). $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/93403/proof-that-sum-limits-i-1k-logi-belongs-to-ok\nText:\nTake the 2-minute tour \u00d7\n\nI'm studying time complexity of binomial heaps and there's one operation (the make-heap operation) that does not make sense to me unless the following is true.\n\n$\\sum\\limits_{i=1}^k \\log(i)$ belongs to $O(k)$\n\nPlease help me find a proof for that statement.\n\nAny help appreciated.\n\nshare|improve this question\nWikipedia has a different sum with a proof that it's $O(k)$. \u2013\u00a0 Peter Taylor Dec 22 '11 at 9:50\nThank you but I am currently interested in binomial (not binary) heaps. \u2013\u00a0 Du\u0161an Rychnovsk\u00fd Dec 22 '11 at 10:32\n\n2 Answers 2\n\nup vote 9 down vote accepted\n\nWell, I am sorry but this is an $O\\left( \\int_1^k \\log x\\mathrm d x\\right)$, and $$\\int_1^k \\log x\\mathrm d x = \\left[ x\\log x - x \\right]_1^k = O(k \\log k).$$\n\nshare|improve this answer\n+1. Also, by Stirling's approximation, $\\log(k!)\\sim \\frac{1}{2}\\log(2\\pi k) +k\\log(k)-k=O(k\\log k)$, and not $O(k)$. \u2013\u00a0 Jonas Meyer Dec 22 '11 at 9:02\n\nElvis's answer is nicer than this, but since the question comes from intro algorithms, I'd point out that for many elementary CS applications the trivial bounds like: $$ (n/2)\\log(n/2) = (n/2)(\\log n - 1) \\le \\sum_{i=1}^n \\log i\\le n\\log n $$ are good enough and worth trying if you're just doing homework.\n\nUpdate: The lower bound here can be obtained by noticing that half of the terms in the sum are at least $\\log(n/2)$, since log is monotone. Also, fixed a dropped set of brackets.\n\nshare|improve this answer\nWell, I think this is very nice; you should precise that the first inequality comes from Jensen inequality. It is nice because it is quick, simple and it applies to a wide range of discrete sums, my method is ok because we have the luck to know a primitive of $\\log x$. \u2013\u00a0 Elvis Dec 22 '11 at 13:03\n@Elvis, The first part does not use Jensen. You only need to note that the last $n/2$ terms in the equality (namely, $\\log i$ for $i \\geq n/2$) are at least $\\log (n/2)$ each. \u2013\u00a0 Srivatsan Dec 22 '11 at 14:22\nOups, my mistake, its even better. \u2013\u00a0 Elvis Dec 22 '11 at 14:38\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/35351/minimum-differences-in-vectors-of-naturals?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI have run into this problem (or something similar to it) a few times now and I am wondering if the answer is known.\n\nGiven an vector $s$ of integers let $d(s)$ be the minimum difference between any two integers in $s$, that is $$d(s) = \\min_{i,j \\in s} |i - j|.$$ For $s$ a vector of length $m$ from $\\lbrace 1,2,\\dots,n\\rbrace^m$ we must have $0 \\leq d(s) < n$.\n\nGiven $0 \\leq k < n$, how may such vectors have $d(s) = k$ ?\n\nI'm more interested in the case where $n$ is much larger than $m$.\n\nNote: If $N_k$ is the answer for $k$. Then you should have $n^m = \\sum_{k=0}^{n-1}N_k$\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nThe number of $m$-subsets of {$1,2,\\ldots,n$} with distance at least $k$ between any pair is $n - (k-1)(m-1) \\choose m$.\n\nProof: for any subset of size $m$ of the first $n-(k-1)(m-1)$ integers, you can get a subset $S$ of the first $n$ with $d(S)\\geq k$ by just adding $k-1$ consecutive integers after each of the first $m-1$ elements of $S$.\n\nSo your answer is ${ n - (k-1)(m-1) \\choose m } -{ n - k(m-1) \\choose m }$ .\n\nUPDATE The intended question was about vectors and not sets. Essentially the same proof works; see the comments.\n\nshare|improve this answer\nHi Peter, I don't think this is correct. With ''m-subsets of $\\{1,2,\\cdots,n\\}$'' you are not allowing repetition, but I mean for the question to allow repetition. This is wholly my fault, I should never have called $S$ a set! \u2013\u00a0 Robby McKilliam Aug 12 '10 at 21:57\nMy comment makes no sense! Repetition implies that $d(S) = 0$. I'm going to have to stop and think about what I am asking. \u2013\u00a0 Robby McKilliam Aug 12 '10 at 22:14\nThat is the answer for sets since one gets just those sets, and once each. Then $\\binom {n}{m} = \\sum_{k=1}^{n-1}N_k$. If you want to have an $N_0$ and $n^m = \\sum_{k=0}^{n-1}N_k$ then you really are talking about vectors. Then, for $k \\gt 0$, multiply the answer above by $m!$. And then $N_0$ is what it would have to be, $n^m-\\frac{n!}{(n-m)!}$ \u2013\u00a0 Aaron Meyerowitz Aug 12 '10 at 23:18\nIt seems that you really do mean vectors and not multisets as in your amended title. But the answer for multisets is cute. Then $N_k$ is as Peter said for $k \\gt 0$ and $N_0=\\binom{n+m-1}{m}-\\binom{n}{m}$ which is the $k=0$ case of the formula. \u2013\u00a0 Aaron Meyerowitz Aug 12 '10 at 23:44\nIndeed, I mean vectors. I have fixed the title. I have made a bit of a mess of this question! And multiplying Peters answer by $m!$ as you have said give the desired result. \u2013\u00a0 Robby McKilliam Aug 13 '10 at 0:28\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/210352/boolean-simplification?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm having some trouble getting a handle with this course. We are starting Boolean algebra and my professor wants us simplify the following:\n\n\n\nI am assuming the \"()\" with \"'\" means the over-score above the variables.\n\nForgive my ignorance but my professor does not explain anything. He just says \"Do!\" in a Russian accent. I just want to understand.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nBy de Morgan\u2019s law $(AB)'=A'+B\\,'$, and it\u2019s always true that $X+X'=1$, so $$(AB)'+(A'+B\\,')'=(A'+B\\,')+(A'+B\\,')'=1\\;.$$\n\nSimilarly, we can start simplifying $(AB)'+BC+A'B\\,'C\\,'$ by using de Morgan\u2019s law to expand the first term, getting $A'+B\\,'+BC+A'B\\,'C'$. Now use one of the distributive laws to get $$A'+A'B\\,'C\\,'=A'1+A'B\\,'C\\,'=A'(1+B\\,'C\\,')$$ and then an absorption law to get $$A'+A'B\\,'C\\,'=A'(1+B\\,'C\\,')=A'1=A'\\;.$$ Thus, $$A'+B\\,'+BC+A'B\\,'C'=A'+B\\,'+BC\\;.$$\n\nNote that I could have reached the same final result by simplifying $B\\,'+A'B\\,'C\\,'$ to $B\\,'$, using exactly the same approach.\n\nAdded: As StainlessSteelRat notes in the comments, the simplification can be taken a step further. Specifically,\n\n\nso $A'+B\\,'+BC=A'+B\\,'+C$.\n\nshare|improve this answer\nAlright that makes sense. My question is now do we always follow those same steps? i.e. de Morgans, distribute laws, absorption laws. Or does each equation go through a different approach, depending how it is presented? \u2013\u00a0 Leo Oct 10 '12 at 9:29\n@Leo: In general it\u2019ll be a different approach each time, just as it was back in eighth- or ninth-grade algebra when you were asked to simplify an expression. In fact it is just algebra, though the rules are a little different from the ones for the familiar algebra of real numbers. \u2013\u00a0 Brian M. Scott Oct 10 '12 at 9:35\nThanks Brain for help. \u2013\u00a0 Leo Oct 10 '12 at 9:48\n@Leo: You\u2019re welcome. \u2013\u00a0 Brian M. Scott Oct 10 '12 at 10:03\n@Brian Since B' is there the B in BC is not required, so it reduces to A' + B' + C. \u2013\u00a0 StainlessSteelRat Apr 8 at 15:56\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/98270/can-we-determine-which-monodromy-of-surface-gives-a-fibered-knot\nText:\nTake the 2-minute tour \u00d7\n\nA fibered knot is a knot with a homeomorhism on compact surface with one boundary component. On the contrary, for a given homeomorohism on a compact surface with one boundary component, is there any way to determine whether it is a monodromy of a fibered knot?\n\nshare|improve this question\nYou might be interested in qwerty1793's answer here: mathoverflow.net/questions/58987/\u2026 . \u2013\u00a0 Marco Golla May 29 '12 at 13:17\nadd comment\n\n1 Answer\n\nForm the mapping torus $M$, check whether $H_1(M;\\mathbb{Z})=1$ and is generated by a loop on the torus boundary. If not, it isn't a fibered knot complement. If so, do Dehn filling to produce a closed 3-manifold. Use sphere recognition algorithms to check if the result of Dehn filling is homeomorphic to the 3-sphere.\n\n--- Edit ---\n\nAs emphasized by the comments of Agol and Igor Rivin, this is not an algorithm until one specifies exactly how to compute which Dehn filling curves in $\\partial M$ need to be checked. I'll say how to do this when the monodromy $\\phi : S \\to S$ is pseudo-Anosov, which corresponds to checking whether $M$ is a fibered hyperbolic knot complement (something similar will work to check whether $M$ is a satellite knot whose torus decomposition has a hyperbolic component incident to $\\partial M$; something different needs to be done when $M$ is Seifert fibered or is a satellite knot complement whose torus decomposition has a Seifert fibered component incident to $\\partial M$).\n\nFirst compute the longitude and the degeneracy curves $\\ell,\\delta \\in H_1(\\partial M;\\mathbb{Z})$.\n\nThe longitude $\\ell$ is the generator of the kernel of $H_1(\\partial M;\\mathbb{Z}) \\to H_1(M;\\mathbb{Z}) \\approx \\mathbb{Z}$.\n\nTo compute $\\delta$, first compute an invariant train track $\\tau \\subset S$ such that some component $C$ of $S \\setminus \\tau$ is a crown surface containing $\\partial S$; one can use standard train track algorithms to do this, such as the Bestvina-Handel algorithm. Then suspend $\\tau$ to get a branched surface $B$ in $M$. On $B$, take the suspension curve of a cusp of $C$. Isotope that curve through an annulus$\\times [0,1]$ component of $M \\setminus B$ to get $\\delta \\subset \\partial M$. From a more invariant but less algorithmic point of view, if one suspends the stable geodesic measured lamination $\\lambda \\subset S$ of $\\phi$ to get an essential lamination $\\Lambda$ in $M$, the curve $\\delta$ is the unique one which is isotopic to a curve in a leaf of $\\Lambda$.\n\nNow compute the three curves on $\\partial M$ whose geometric intersection with $\\ell$ equals $1$ and whose geometric intersection with $\\delta$ equals $0$ or $1$. Those are the only three possible curves along which Dehn filling can give a 3-sphere: every Dehn filling along a curve which intersects $\\ell$ either $0$ times or $\\ge 2$ times has nontrivial 1st homology with $\\mathbb{Z}$ coefficients; and every Dehn filling along a curve which intersects $\\delta$ more than $1$ time has an essential lamination.\n\nshare|improve this answer\nI think you want to do Dehn filling along a slope which is either the loop generating the monodromy on the boundary, or a curve intersecting it once. But there are still only finitely many choices of slope by restricting to Dehn fillings which are homology spheres, since the slope must also intersect the longitude just once. \u2013\u00a0 Ian Agol May 29 '12 at 14:36\nHow many is \"finite\"? Is there nan effective bound given OP's data (the monodromy), with the homology constraint? \u2013\u00a0 Igor Rivin May 29 '12 at 18:26\n@ Igor: 3, since the slope has to have intersection number $\\leq 1$ with both the longitude and degeneracy slope, which can therefore be at most 3 curves. \u2013\u00a0 Ian Agol May 29 '12 at 21:12\n@Ian, I can see only one intrinsecally well-defined curve in the torus boundary, the boundary of the surface (is this what you call the longitude?). How can you tell among the infinitely many slopes intersecting it once, which all produce homology spheres (assuming H_1(M)=Z), those that give you S^3? \u2013\u00a0 Bruno Martelli May 30 '12 at 15:37\n@Bruno: the longitude is the generator of the kernel of $H_1(\\partial M;Z) \\to H_1(M;Z)$. The degeneracy slope is defined under the assumption that the mapping class is pseudo-Anosov, so in $M$ there is an essential lamination $\\Lambda$ which is the suspension of the stable measured lamination, and there is an embedded annulus $A \\subset M$ which intersects $\\Lambda$ in one component of $\\partial A$ and intersects $\\partial M$ in the other component of $\\partial A$ which by definition is the degeneracy slope. \u2013\u00a0 Lee Mosher May 30 '12 at 19:00\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96268/square-roots-of-the-laplace-operator/96355\nText:\nTake the 2-minute tour \u00d7\n\nIn several places in the literature (e.g. this paper of Caffarelli and Silvestre), I've seen an integral formula for fractional Laplacians. I'd like to understand it. In this question, I'll stick to the case of the square root.\n\nThe formula I've seen is this: $$((-\\triangle)^{1/2}f)(x)= C_n \\int_{\\mathbb{R}^n}\\frac{f(x) - f(y)}{\\|x - y\\|^{n + 1}}\\ dy. $$ Here $x \\in \\mathbb{R}^n$ and $C_n$ is a constant. Also, $f$ is a function $\\mathbb{R}^n \\to \\mathbb{R}$, but I'm not sure what regularity assumptions it's supposed to satisfy.\n\nFor this notation to be justified, it must surely be the case that $$ (-\\triangle)^{1/2} \\bigl((-\\triangle)^{1/2} f\\bigr) = -\\triangle f $$ for all nice enough $f$. My question is: why? I haven't been able to prove this identity even in the case $n = 1$.\n\n\n  1. It's clearly the case that the Laplace operator has a square root defined by $$ \\widehat{((-\\triangle)^{1/2}f)}(\\xi) = \\|\\xi\\| \\hat{f}(\\xi). $$ The paper linked to says that this operator $(-\\triangle)^{1/2}$ is the same as the operator $E$ defined by the integral formula. If I'm understanding correctly, proving this is equivalent to proving (i) that $E$ really is a square root of the Laplacian, and (ii) that $E$ is a positive operator on functions of compact support.\n\n  2. I've seen a couple of references to Landkof's 1972 book Foundations of Modern Potential Theory. Unfortunately, those citing Landkof's book don't say which part of the book they're referring to, and I've been unable to find the relevant part myself. I'd be happy for someone to simply tell me where in that book to look.\n\n  3. I can see that the integral formula has something to do with Laplacians. Switching to spherical coordinates, the formula is $$ ((-\\triangle)^{1/2}f)(x) = \\text{const}\\cdot\\int_0^\\infty \\frac{\\int_{S^{n-1}} f(x + ru)\\ du - f(x)}{r^2}\\ dr $$ where $du$ is surface area measure on $S^{n-1}$ normalized to a probability measure. The integrand converges to $(\\triangle f)(x)$ as $r \\to 0$ (up to a constant factor). Also, the integrand is identically zero if $f$ is harmonic, which is promising.\n\nshare|improve this question\nHi Tom, A basic reference for this sort of things is the classic paper of Seeley \"Complex powers of an elliptic operator\". Since this is one of the early papers on pseudo-differential operators, I'm sure you can find something about this in a book (H\u00f4rmander or Taylor are good bets). \u2013\u00a0 alvarezpaiva May 9 '12 at 6:13\nThanks; that's very helpful. \u2013\u00a0 Tom Leinster May 11 '12 at 0:29\nadd comment\n\n6 Answers\n\nThe Fourier transform of a radially symmetric function is a radially symmetric function. Basic scaling shows that the Fourier transform of $\\|\\xi\\|$ must be $\\|x\\|^{-n-1}$ in some sense. Some care must be taken in interpreting this, since this function is not integrable. A good reference for this is Gelfand and Shilov, Generalized Functions.\n\nEdit by Tom Leinster Here I'll try to flesh out Michael's answer. Michael: please feel free to edit.\n\nWe begin by finding the Fourier transform of $\\|\\xi\\|$. A priori this doesn't make sense as $\\|\\xi\\|$ isn't integrable, but I'll proceed formally anyway, hoping that there's a world in which this is all kosher. Write $g(\\xi) = \\|\\xi\\|$ and $g_a(\\xi) = g(a\\xi)$ (for $a > 0$). For completely general reasons, $$ \\widehat{g_a}(x) = a^{-n} \\hat{g}(x/a). $$ Also, for this particular $g$ we have $g_a = a g$, so $\\widehat{g_a} = a\\hat{g}$. Hence $\\hat{g}(x) = a^{-(n+1)} \\hat{g}(x/a)$, giving $$ \\hat{g}(x) = \\|x\\|^{-(n+1)} g(x/\\|x\\|). $$ On the other hand, $g$ is spherically symmetric, so $\\hat{g}$ is too; hence $\\hat{g}$ has constant value $C$ on the unit sphere. So the Fourier transform of $\\|\\xi\\|$ is $C\\|x\\|^{-(n+1)}$.\n\nNow we take the Fourier transform of each side of the equation $(\\widehat{(-\\Delta)^{1/2}}f)(\\xi) = \\|\\xi\\|\\hat{f}(\\xi)$. This gives $$ ((-\\Delta)^{1/2}f)(x) = C\\|x\\|^{-(n+1)} * f = C\\int_{\\mathbb{R}^n} \\frac{f(y)}{\\|x-y\\|^{n+1}} \\ dy. $$ That seems good, but now I have three problems. First, this isn't the integral formula I was looking for. (Maybe I'm missing a simple trick.) Second, I don't know the value of $C$. Third, I don't know how to make this all rigorous: what are some sufficient conditions on $f$ guaranteeing that $(-\\Delta)^{1/2}\\bigl((-\\Delta)^{1/2}f\\bigr)$ is defined (in the sense of the integrals existing) and equal to $f$?\n\nEdit by Michael Renardy:\n\nThe problem is that $\\|x\\|^{-n-1}$ is not integrable at zero. Therefore it needs to be replaced by a regularization. The theory of such regularizations is developed in detail in Section 3 of Chapter I in Gelfand and Shilov.\n\nshare|improve this answer\nThanks for the answer, Michael. I'd been slightly frustrated at people citing Landkof's book of 400+ pages without saying which part of it they were referring to. But you've gone one better, by citing a three-volume collection without saying which part of it you're referring to :-) \u2013\u00a0 Tom Leinster May 7 '12 at 23:19\nMore seriously, could you elaborate? I think I see what you mean and can guess what strategy you have in mind, but when I carry it out, it leads me to an integral formula different from the one above. \u2013\u00a0 Tom Leinster May 7 '12 at 23:46\nI'll provide chapter numbers after I get to my office where I can look it up. But it will be the morning before that happens. If you can look at the table of contents before that, good for you! \u2013\u00a0 Michael Renardy May 7 '12 at 23:53\nGreat, thanks. I have it on my shelf, but I don't really know what I'm looking for. \u2013\u00a0 Tom Leinster May 7 '12 at 23:55\nThe relevant sections are Chapter I, Section 3.9 and Chapter II, Section 3.3 in Volume I. \u2013\u00a0 Michael Renardy May 8 '12 at 13:03\nshow 1 more comment\n\nA very nice way to see all of this is to look start with the Poisson semi-group $f \\mapsto e^{-t\\sqrt{-\\Delta}}f$ for $t>0$. These operators are defined by Fourier Transform as $$\\widehat{e^{-t\\sqrt{-\\Delta}}f}(p)=e^{-t|p|}\\widehat{f}(p),$$ for any function $f$ so that the right hand side makes sense. Then for $f$, say in $ L^1$, we have $$e^{-t\\sqrt{-\\Delta}}f(x)=\\int_{\\mathbb{R}^n} P_t(x-y)f(y) dy$$ where $P_t(x)$ is the Poisson kernel $$P_t(x)=\\frac{1}{(2\\pi)^n} \\int_{\\mathbb{R}^n} e^{ix\\cdot p} e^{-t|p|} dp = C_n \\frac{t}{(t^2 +|x|^2)^\\frac{n+1}{2}}. $$ (The computation of $P_t(x)$ is carried out in the first chapter of Stein and Weiss, Fourier Analysis on Euclidean Spaces.) The formula for $\\sqrt{-\\Delta}$ follows by taking the limit $$\\sqrt{-\\Delta}f = \\lim_{t\\downarrow 0} \\frac{f- e^{-t\\sqrt{-\\Delta}}f}{t}$$ whenever this limit exists in a suitable sense. Because $\\int P_t(x)dx=1$ we have $$\\frac{1}{t} \\left (f(x)-e^{-t\\sqrt{-\\Delta}}f(x) \\right ) = C_n \\int_{\\mathbb{R}^n} \\frac{f(x)-f(y)}{(t^2 +|x-y|^2)^{\\frac{n+1}{2}}}dy.$$ Your identity now follows whenever $f$ is smooth enough and decays fast enough for the integral to make sense.\n\nshare|improve this answer\nThanks; that's very helpful. \u2013\u00a0 Tom Leinster May 11 '12 at 0:27\nadd comment\n\nSo you believe expression (1)? Have you tried taking the inverse Fourier transform of the right side of this expression? This will give you the convolution of f with the inverse Fourier transform of $|\\xi|$, at least morally speaking. The inverse Fourier transform of $|\\xi|^{\\alpha}$ can be made sense of.\n\nWhen $n=1$, for example, and $-1<\\alpha<0$, this is relatively easy to compute directly, and is something like $C_\\alpha |x|^{-\\alpha-1}$. This kind of computation would probably be done in a textbook in a section like 'tempered distributions'. You can see that that $\\alpha=1$ doesn't fit into this range, which is clear since the formulas wouldn't match up in such a case. But if one naively input this value, we'd get a convolution with $|x|^{-2}$, which is nice. So you clearly should be guessing that the inverse Fourier transform of $|\\xi|$ is convolution with $|x|^{-2}$ plus a delta function, modulo constants.\n\nThis can be made rigorous, but the computation involves knowing some stuff about distributions. Try looking up 'homogeneous distribution'. I think actually with the information on the wikipedia pages for Fourier transform and homogeneous distribution, you should be able to do the computation. This older mathoverflow question might also be helpful: The fourier transform of homogeneous distribution and related topics\n\nshare|improve this answer\nThanks, Peter. My edit to Michael's answer shows my attempt to do what you're suggesting in your first paragraph. I'll go and look up homogeneous distributions. I learned about tempered distributions and their Fourier transforms from Friedlander and Joshi's text, but the treatment there is quite concise. \u2013\u00a0 Tom Leinster May 8 '12 at 14:42\nYes, much of this stuff is fairly disjointed, as I recall, which is unfortunate. Many of the basic computations are not terribly difficult (just tricky), so I think they are not written down in many places. The issue you are having in the computation in your comment comes from having to use some analytic continuation technique to extend the range of possible $\\alpha$s in the inverse transform of $|\\xi|^\\alpha$. $|x|^{-n-1}$ is not locally integrable, as Tom pointed out, so its a bit more delicate. \u2013\u00a0 Peter Luthy May 8 '12 at 15:05\nNow that I think about it, the analytic continuation might need some additional work... there might be some poles at certain integers $\\alpha$, so you would need to add an additional term to balance things out. This computation has to be written down someplace. Sorry that I don't know of a good place. \u2013\u00a0 Peter Luthy May 8 '12 at 16:12\nadd comment\n\nDenote integral operator as follows:$$Lu=P.V.\\int_{\\mathbb{R}^n}\\frac{u(x) - u(y)}{\\|x - y\\|^{n + 1}}\\ dy$$.when $u\\in \\varphi$.It can also been writen as(after changing variable y to -y and then taking average)a more symmetric form $$Lu=\\int_{\\mathbb{R}^n}\\frac{u(x+y) +u(x-y)- 2u(x)}{\\|y\\|^{n + 1}}\\ dy$$.Thus the sigularity can be cancelled. We are looking for its symbol (or multipler),that is $$\\mathcal {F}(Lu)(\\xi)=m(\\xi)\\mathcal {F}u$$and we want to prove that m(\\xi) is exactly $c_{n}|\\xi|$,where $c_{n}$ is a constant determinated later which is the answer of the second question of Tom Leinster. First for $u\\in \\varphi$,we have $\\frac{u(x+y) +u(x-y)- 2u(x)}{\\|x - y\\|^{n + 1}}\\in L^{1}{\\mathbb{R}^n}$.By fubini theorem(we exchange the integral in y with fourier transform in x),we obtain $$\\mathcal {F}(Lu)=\\int_{\\mathbb{R}^n}\\frac{\\mathcal {F}(u(x+y) +u(x-y)- 2u(x))}{\\| y\\|^{n + 1}}\\ dy.= \\int_{\\mathbb{R}^n}\\frac{e^{i\\xi\\cdot y}+e^{-i\\xi \\cdot y}-2}{\\|y\\|^{n + 1}}\\ dy \\mathcal {F}(u)$$ hence,in order to get the desired result,it suffices to show that $\\int_{\\mathbb{R}^n}\\frac{e^{i\\xi y}+e^{-i\\xi y}-2}{\\|y\\|^{n + 1}}\\ dy=c_{n}|\\xi|$. Define $$I(\\xi)=\\int_{\\mathbb{R}^n}\\frac{1-cos(y \\xi)}{\\|y\\|^{n + 1}}\\ dy$$.Since $I(\\xi)$ is rotatonally invariant.so $I(\\xi)=I(|\\xi|e_{1})$ where $e_{1}$ denotes the first direction vector.So $$I(\\xi)=I(|\\xi|e_{1})=|\\xi|\\int\\frac{1-cos(z_{1})}{\\|z\\|^{n + 1}}dz$$.so we take $c_{n}=\\int\\frac{1-cos(z_{1})}{\\|z\\|^{n + 1}}\\ dz$.And we have $(-\\triangle)^{1/2}=\\frac{1}{c_{n}}L$ as desired.\n\nshare|improve this answer\nit's really nice to start from the poisson semigroup,but the mathod pressented here is applied for any $0<\\alpha<1$ with $(-\\triangle)^{\\alpha}$ \u2013\u00a0 user23078 May 8 '12 at 23:17\nGood job. Your answer also clarifies the meaning of the original integral, which of course does not converge as a Lebesgue integral but only if interpreted as a singular integral or a principal value. \u2013\u00a0 Piero D'Ancona May 9 '12 at 8:17\nThanks very much! \u2013\u00a0 Tom Leinster May 11 '12 at 0:26\nadd comment\n\nThis answer is a modified version of Tom's edit on Michael's answer just to make it a bit more rigorous.\n\nTake $b(\\xi)$ to be a smooth non negative radially symmetric function supported in $1< |\\xi| <2$. Then we see that $|\\xi|^\\alpha = c \\int_0^\\infty t^{\\alpha-1} b(\\xi/t) dt$.\n\nNow, let us say $b$ is the fourier transform of some kernel $k$, which will also be smooth, radially symmetric, and its integral is zero because $b(0)=0$. Then $b \\cdot \\hat u = \\widehat{k \\ast u}$. Moreoever, since k has integral zero and is symmetric $$ b \\cdot \\hat u = \\left(\\int k(y) (u(x+y)-u(x)) dy\\right)^\\wedge. $$\n\nLet us assume that $\\alpha \\in (0,2)$.\n\nI want to use the identity above for $|\\xi|^\\alpha$ as an integral of scaled versions of $b$. For that recall that $b(\\cdot/t)^\\\\wedge = t k(t\\cdot)$. So, we have $$ |\\xi|^\\alpha \\cdot \\hat u = \\left( c \\int_0^\\infty t^{\\alpha-1} \\int t k(ty) (u(x+y)-u(x)) \\ dy dt \\right)^\\wedge$$ Exchanging the order of integration we have that $$ |\\xi|^\\alpha \\cdot \\hat u = \\left( \\int (u(x+y)-u(x)) K(y) dy \\right)^\\wedge$$ for $$ K(y) = c \\int_0^\\infty t^{\\alpha} k(ty) dt = c_0 |y|^{-n-\\alpha}.$$ The last identity is obtained from the change of variables $s = t|y|$.\n\nThere are still a few things that should be clarified, like the application of Fubini, and that the integrals may be principal values when $\\alpha \\geq 1$. But everything should be fine if $u$ is smooth enough.\n\nshare|improve this answer\nadd comment\n\nPerhaps you could see what the right-hand-side evaluates to for the eigen-functions of the Laplacian (I don't know what they are offhand but I would guess that the eigenbasis for the Laplacian on L^2(R) is well known). You should get that the eigen-functions are still eigen-functions of the right-hand-side but with each of the eigen-values raised to the 1/2 power.\n\nAlso, your question leads me to a question of my own: From the probabilistic perspective, the right-hand-side integral operator is associated to a Markov jump process. So this statement seems to imply that in some way \"The square of a jump process gives a true diffusion\" or maybe \"if you jump and jump again you get a true diffusion\". I am wondering if anyone knows anymore on this line of thought or a reference where it is made precise?\n\nshare|improve this answer\nThat is it: there are no eigenfunctions here unfortunately. And you should ask your question separately, it will not be noticed here. \u2013\u00a0 Andr\u00e1s B\u00e1tkai May 8 '12 at 20:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232989/finding-radius-of-convergence-for-power-series\nText:\nTake the 2-minute tour \u00d7\n\nFind the radius of convergence of the given power series:\n\n$$\\sum _{n=0}^{ \\infty} \\frac{8n!x^n}{2^n}$$\n\nAfter taking the limits as n-> $\\infty$, I get $\\frac{8x}{2}$, and Radius of convergence is R = 2. Is this correct?\n\nshare|improve this question\nThis is a very standard, very straightforward problem; what have you tried? \u2013\u00a0 Brian M. Scott Nov 8 '12 at 16:59\nUse the Ratio Test. Informally, the problem is that $n!$ grows hugely fast. \u2013\u00a0 Andr\u00e9 Nicolas Nov 8 '12 at 17:01\nTry by using the ratio test \u2013\u00a0 M. Strochyk Nov 8 '12 at 17:02\n@everyone except the OP: meta.math.stackexchange.com/a/2179/7850 \u2013\u00a0 The Chaz 2.0 Nov 8 '12 at 17:40\nshow 1 more comment\n\n2 Answers\n\nup vote 0 down vote accepted\n\nUsing the Ratio Test, it looks like we get $R=0$.\n\n$$\\left|a_{n+1}\\over a_{n}\\right| = \\left| \\frac{8(n+1)! \\cdot x^{n+1} \\cdot 2^n}{2^{n+1} \\cdot 8n! \\cdot x^n} \\right| = \\left| \\frac{8(n+1)n! \\cdot x \\cdot x^n \\cdot 2^n}{2\\cdot 2^n \\cdot 8n! \\cdot x^n} \\right|$$\n\n$$=\\frac{\\left|x\\right|} {2} \\lim_{n\\to\\infty} (n+1) \\to \\infty \\ \\ \\forall x \\ne 0\\implies R=0$$\n\nThus, the power series only converges when $x=c$, which is at $x=0$ here.\n\nshare|improve this answer\nadd comment\n\nThis can help you solve this problem.\n\nThe answer is:\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/147332/can-a-herglotz-nevanlinna-function-attain-real-values\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbb{H}^+=\\{z \\in \\mathbb{C}\\mid \\Im(z)>0\\}$. We say that an analytic $F\\colon \\mathbb{H}^+\\to\\overline{\\mathbb{H}^+}$ is a Herglotz-Nevanlinna's function.\n\nQuestion Can it be that $F(z)\\in \\mathbb{R}$ for some $z \\in \\mathbb{H}^+$?\n\nI guess that the answer is no, because if this happened then we could find a small loop $\\gamma$ around $z$ such that $F\\circ \\gamma$ slips outside $\\overline{\\mathbb{H}^+}$, but I'm not sure this is true and how to formalize this little argument.\n\nThank you.\n\nshare|improve this question\nOf course in both this question and the answer by Davide Giraudo it is assumed that $F$ is not constant. \u2013\u00a0 Giuseppe Negro May 22 '12 at 9:57\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nIf $F$ is constant it's clear, otherwise, since $\\mathbb H^+$ is connected, by the open mapping theorem, $F(\\mathbb H^+)$ is open in $\\mathbb C$. If $F(z)\\in\\Bbb R$ for some $z\\in\\mathbb H^+$, then we can find $r$ such that if $|y-F(z)|<2r$ then $y=F(y')$ for some $y'\\in\\mathbb H^+$. If we consider $F(z)-ri$, we get a contradiction.\n\nshare|improve this answer\nAw, thank you! This was a good occasion to review the open mapping theorem (which evidently I had forgotten! :-) ). \u2013\u00a0 Giuseppe Negro May 20 '12 at 17:14\nYou are welcome. In which context do we use such maps? \u2013\u00a0 Davide Giraudo May 20 '12 at 17:15\nMeasure theory and spectral analysis. Specifically I am reading this lecture by Terence Tao: terrytao.wordpress.com/2011/12/20/\u2026 . Have a look at Theorem 4. \u2013\u00a0 Giuseppe Negro May 20 '12 at 17:18\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/8182/is-a-polynomial-with-1-very-large-coefficient-irreducible?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI am asking for some sort of generalization to Perron's criterion which is not dependent on the index of the \"large\" coefficient. (the criterion says that for a polynomial $x^n+\\sum_{k=0}^{n-1} a_kx^k\\in \\mathbb{Z}[x]$ if the condition $|a_{n-1}|>1+|a_0|+\\cdots+|a_{n-2}|$ and $a_0\\neq 0$ holds then it is irreducible.)\n\nThis would answer a second question about the existence of n+1-tuples $(a_0,\\dots,a_n)$ of integers for which $\\sum_{k=0}^n a_{\\sigma(k)}x^k$ is always irreducible for any permutation $\\sigma$. What happens if we restrict $|a_i| \\le O(n)$ ? $ |a_i| \\le O(\\log n)$ ?\n\nshare|improve this question\nAs far as I checked (didn't check linear terms) Vladimir's example can be simplified to taking the coefficients $p, q, pq, pq, \\dots, pq$ for primes $p\\ne q$. \u2013\u00a0 j.p. Dec 12 '09 at 17:59\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nOK, about your second question. Let's consider the polynomial $x^n+2(x^{n-1}+\\ldots+x^2+x)+4$. I claim that this polynomial is almost good for your purposes: if we permute all coefficients except for the leading one, it remains irreducible. Proof: if the constant term becomes 2 after the permutation, use Eisenstein, if not, look at the Newton polygon of this polynomial mod 2 - you can observe that if it is irreducible, it has to have a linear factor, which is easily impossible.\n\n[If we allow to permute all coefficients, I would expect that something like $9x^n+6(x^{n-1}+\\ldots+x^2+x)+4$ would work for nearly the same reasons...]\n\nshare|improve this answer\nThanks! The suggestion works (I think) with (4,9,25,30,30...,30). The problem with (4,9,6...) is when a_k=4,a_{n-k}=9 for some k, which by looking at the Newton polygon mod2, mod3 gives the polynomial as a product fg where f is degree k and f,g are irreducible mod2, mod3. I couldn't find a contradiction in that case. When we introduce 25 such \"symmetric\" factorizations are ruled out. I haven't checked when 4,9 or 25 are leading yet (Eisenstein doesn't apply anymore). \u2013\u00a0 Gjergji Zaimi Dec 9 '09 at 16:08\nIf someone needs a reference for the statement about the Newton polygon (like I did), take a look at the corollary at the bottom of page two in math.umn.edu/~garrett/m/number_theory/newton_polygon.pdf \u2013\u00a0 j.p. Dec 9 '09 at 16:19\n@Gjergji: good point - I was thinking along the same line after I walked in the street having written that suggestion. However, what you say about how to mend my example seems to be a good idea. \u2013\u00a0 Vladimir Dotsenko Dec 9 '09 at 18:11\n@jp: sorry for not providing a reference - I was in a hurry. An excellent source on many a theorem about polynomials is <a href=\"books.google.com/\u2026 book</a> (for facts I am referring to, see page 53, Dumas' theorem (and a bit before this theorem), but there are lots of other useful things there). \u2013\u00a0 Vladimir Dotsenko Dec 9 '09 at 18:12\nokay, I don't know what happened to the long google books url in the previous comment, so let me re-type it in a better way: tinyurl.com/prasolov \u2013\u00a0 Vladimir Dotsenko Dec 9 '09 at 18:15\nshow 3 more comments\n\nThinking of what Perron's criterion essentially means, I would not really expect anything similar to hold for other coefficient. Basically, if the absolute value of the k-th coefficient is greater than the sum of absolute values of other coefficients, it's easy to show that k zeros of the polynomial are strictly inside the unit circle, and $(n-k)$ --- strictly outside it (by Rouche's theorem). So, easy contradictions are to be expected only for $k=n-1$ (and $k=1$ if we invert $x$). Two other remarks supporting this comment: polynomials $x^n-N^n$ suggest that you should not expect anything for the constant term, and polynomials $(x^2-Nx+1)(x^2+Nx+1)=x^4+(2-N^2)x^2+1$ show that $k=2$ (or $n-2$) would not work...\n\nAs for the second question, it seems quite likely that such examples exist, even with rather restrictive bounds on coefficients.\n\nshare|improve this answer\nadd comment\n\nTo your 2nd question:\n\nTaking n+1 different primes $p_0, p_1, \\dots, p_n$ you can define $a_i := \\prod_{j \\ne i} p_j$. By a theorem of Eisenstein (\"Eisenstein's irreducibility criterion\"), you get that any permutation yields an irreducible polynomial.\n\nshare|improve this answer\nCute! But it badly fails the desired restriction $|a_i|=O(n)$. \u2013\u00a0 Mark Meckes Dec 8 '09 at 17:59\nadd comment\n\nMaybe this should have gone in the comments, but I couldn't see the button.\n\nIn any case, I'm wondering what you hope to be true. There are some obvious 'bad' examples (i.e. $10^{20} x^{2} - 1$, or $x^{2} - 10^{20}$, or $x^{2} - 2 10^{10} x + 10^{20}$) s.t. some coefficients can be arbitrarily larger than (any function of) the others, while the polynomial remains reducible. This isn't terrible (I can't come up with examples like this for all coefficients and all degrees), but certainly means you can't get a condition which just involves the largest coefficient, without regards to spacing.\n\nThere are also some 'nice' examples. In the same paper that he proves the criterion you mention above, Perron also proves that a polynomial is irreducible if $a_{n-2}$ is sufficiently larger than the rest.\n\nThe paper 'irreducibility of polynomials' by Dorwart (from the monthly in 1935 (!)) came up on a quick google search, and may be worth looking at.\n\nFor the last question, playing around with the various divisibility criteria (and Maple) seems to give many, many examples for moderate degree, but my algebra is not strong enough to turn this into a theorem. Of course, if you are only interested in infinitely many n (not all n, since this only works for n being a prime - 1), the cyclotomic polynomials seem like good examples, with all coefficients 1! Is there any reason that you believe a restriction on the size of the coefficients would do something?\n\nshare|improve this answer\nWell, I was trying (1,1,..,k) for large enough k, restricting the height makes the search...harder. The cyclotomic polynomials are unfortunately the only family of arbitrarily large degree I know. Then there are values like (1,1,1,0,...,0,0) which for all n have a very small fraction of reducible polynomials. \u2013\u00a0 Gjergji Zaimi Dec 8 '09 at 15:33\nHow about if the polynomial is monic and has constant term 1, and the total norm of all of the small coefficients is bounded by a constant. \u2013\u00a0 Greg Kuperberg Dec 8 '09 at 19:33\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/65791/reducible-trinomials-xoddx2st-in-characteristic-2/66911\nText:\nTake the 2-minute tour \u00d7\n\nLet $F$ be a finite field of characteristic $2$. Let $m \\geq 2 $ be a positive integer. Seems unknown if the trinomial $$ T(t,x) = x^{2m+1}+x^2+s(t) \\in F[t][x] $$ (more explicitly, the constant coefficient $s(t)$ is a polynomial in $t$, i.e., $s(t) \\in F[t]$)\n\nhas monic factors $D(t,x)$ in $F[t][x]$ with degree $3$ relative to $x$.\n\nI.e., $$ D(t,x) = x^3+ a_2(t)x^2+a_1(t)x + a_0(t) $$ with $a_2(t), a_1(t),a_0(t) \\in F[t]$ and $T(t,x) = D(t,x)K(t,x)$ for some $K(t,x) \\in F[t][x].$\n\nWe will then say that $T(t,x)$ have $D(t,x)$ as a factor or that $D(t,x)$ divides $T(t,x)$.\n\nQuestion: Assume that $D(t,x)$ as above divides the trinomial $T(t,x).$\n\nDo we have $$ \\deg(a_1(t)) = 2 \\deg(a_2(t)),\\;\\;\\deg(a_0(t))=3\\deg(a_2(t)). $$ ???\n\nI am aware of the work of Schinzel on trinomials. The trinomials $T(t,x)$ do not seem to be worked out in these papers.\n\nshare|improve this question\nIs $s(t)$ an arbitrary element of $F(t)$? \u2013\u00a0 S. Carnahan May 24 '11 at 4:56\nIn line 3, we take $s(t)$ as an arbitrary element of $F[t]$. You think is more useful to take the $s(t)$ in the full ring of quotients $F(t)$ ? \u2013\u00a0 Luis H Gallardo May 24 '11 at 7:53\nSorry, that was a typo. I meant square brackets. \u2013\u00a0 S. Carnahan May 24 '11 at 10:08\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nWe show the following:\n\nTheorem. Let $F$ be a field of characteristic $2$, and $s(t)\\in F[t]$ a non-constant polynomial. Then $f(t,X)=X^{2m+1}+X^2+s(t)$ (where $m\\in\\mathbb N$) is either irreducible, or a product of irreducible factors of degrees $1$ and $2m$.\n\nIn particular, this answers the question about the non-existence of cubic factors for $m\\ge2$.\n\nWe use Galois theory, group theory and a little bit of valuation theory: Set $y=s(t)$, and let $x$ be a root of an irreducible factor of degree $k$ of $f(t,X)$. Note that $x^{2m+1}+x^2=s(t)=y$. We obtain the following field degrees: $[F(x):F(y)]=2m+1$ and $[F(x,t):F(t)]=k$.\n\nIt is easy to see that we may assume that $s(t)$ is not a polynomial in $t^2$. (Take the derivative with respect to $t$ of a factorization). So $x$ and $t$ are separable over $F(y)$. Let $L$ be the smallest Galois extension of $F(y)$ which contains $x$ and $t$, and set $G=\\text{Gal}(L/K(y))$.\n\nThe group $G$ need not act faithfully on the conjugates of $x$. Let $N$ be the kernel of this action. So $G/N$ acts faithfully on the conjugates of $x$. Note that $G/N$ is the Galois group of $X^{2m+1}+X^2+y$ over $F(y)$.\n\nWe first claim that $G/N$ is the symmetric group $S_{2m+1}$: The polynomial $X^{2m+1}+X^2$ is functionally indecomposable. To see this, take the derivative of $X^{2m+1}+X^2=A(B(X))$. A short calculation shows that either $A$ or $B$ is linear. So, by Luroth's Theorem, $G/N$ is primitive. Furthermore, $X^{2m+1}+X^2=(X^{2m-1}-1)X^2$, with the first factor being separable. Valuation theory shows that the inertia generator of a place of $L$ lying above the place $y\\mapsto 0$ is a transposition on the conjugates of $x$. A well-known theorem of group theory then shows that $G/N$ acts as the symmetric group $S_{2m+1}$ on the conjugates of $x$. Let $G_x$ and $G_t$ be the stabilizers of $x$ and $t$ in $G$. As $x$ has degree $k$ over $F(t)$, we get that $G_t$ has an orbit of length $k$ on the conjugates of $x$. But $NG_t$ has the same orbits as $G_t$ on this set. Thus, we may (and do) replace $G_t$ with $NG_t$, which amounts to replacing $s(t)$ with a polynomial $s_1(t)$ such that $s(t)=s_1(s_2(t))$ for another polynomial $s_2(t)$, and $X^{2m+1}+X^2+s_1(t)$ has the same factorization pattern as $f(t,X)$.\n\nSo we have $N\\le G_t$, that is $N$ fixes $t$. But $N$ is normal in $G$, so $N$ fixes all conjugates of $t$ (and those of $x$ by definition), hence $N=1$.\n\nSo $G=S_{2m+1}$ acts faithfully on the conjugates of $x$.\n\nNow let $T$ be the inertia group of a place of $L$ lying above the place $p=(y\\mapsto\\infty)$. As $p$ is totally ramified in $F(x)$, and $F(x)/F(y)$ is tame, we get that $T$ is a cyclic group permuting regularly the conjugates of $x$. In particular, $T$ has order $2m+1$. However, $p$ is totally ramified in $K(t)$ too, so $T$ permutes the conjugates of $t$ transitively as well. Therefore $[G:G_t]\\le 2m+1$.\n\nNow suppose that $2\\le k\\le 2m-1$, so $G_t$ has an orbit of length $k$ on the conjugates of $x$. This yields $\\lvert G_t\\rvert\\le k!(2m+1-k)!$, hence $[G:G_t]\\ge\\binom{2m+1}{k}>2m+1$, contrary to the inequality above.\n\nIf $k=1$, then $G_x$ and $G_t$ are conjugate in $G$. In particular $G_t$ has orbit lengths $1$ and $2m$ on the conjugates of $x$, and the claim follows again.\n\nshare|improve this answer\nVery nice argument! \u2013\u00a0 Igor Rivin Nov 22 '12 at 18:00\nadd comment\n\nSorry, this is only worth a comment, but I'm a new guy here, so not enough rep to do that :-)\n\nAs you discuss trinomials, the silly counterexample of $(x^3+x^2+x)(x^2+x)=x^5+x^2$ is probably not interesting. Anyway, for which values of $m$ have you verified this? Here's how it goes in the case $m=2$ (you undoubtedly know this, but let's get the ball rolling).\n\nSo assume $m=2$. In order to make the quartic and cubic terms vanish from the product, we must set $K(x)=x^2+a_2(t) x+ [a_1(t)+a_2(t)^2]$, so we can compute the product (I leave out the $t$:s for now): $$ D(x)K(x)=x^5+x^2(a_0+a_2^3)+x(a_0a_2+a_1a_2^2+a_1^2)+(a_0a_1+a_0a_2^2)=T(x). $$ A comparison of quadratic terms gives us the relation $a_0=1+a_2^3$. This gives your second claimed relation unless $a_2(t)=1$ (, which leads to the silly case above). Then a comparison of the linear terms gives the relation $$ 0=a_2+a_2^4+a_1a_2^2+a_1^2. $$ If here $\\deg a_1>2\\deg a_2$, then the last term has a higher degree than the others, which is no-no (non-archimedean triangle inequality w.r.t to the infinite place). OTOH if $\\deg a_1<2\\deg a_2$, then the term $a_2^4$ dominates the others, and we again have a contradiction.\n\nThis is admittedly a very elementary approach, but do you know how far you can go with methods like this? We can always determine the coefficients of the other factor by using the known coefficients (down to the cubic term) of the product, and then get conditions by comparing the quadratic and linear terms. I am uncertain as to how many values of $m$ I want to check by hand :-)\n\nshare|improve this answer\nThanks for discussing these case. \u2013\u00a0 Luis H Gallardo Jun 5 '11 at 17:19\n@Luis: Was an example like the case $m=2$ above the basis of your conjecture/question? \u2013\u00a0 Jyrki Lahtonen Jun 6 '11 at 9:22\n@Jyrki: Not indeed, instead the study of the possible degree $2$ factors of the trinomial. See my paper with Berrondo on the question. \u2013\u00a0 Luis H Gallardo Jun 6 '11 at 11:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/46792/how-long-does-it-take-for-every-node-of-a-graph-to-become-infected/46793\nText:\nTake the 2-minute tour \u00d7\n\nConsider the following stochastic process.\n\nWe begin with an undirected graph on $n$ vertices, exactly one of which is ''infected.'' Now at every time step, each infected node infects one of its non-infected neighbors uniformly at random. For example, if a given node has $3$ neighbors that are infected and $5$ that are not, then it infects exactly one of those latter $5$, each of which has probability $1/5$ of being the one chosen.\n\nNow its clear that after $n-1$ steps every node becomes infected, since at every step at least one non-infected node becomes infected. However, I suspect that the infection actually spreads faster, because as the number of infected nodes grows, more and more non-infected nodes become infected at every stage.\n\nMy question: Is it actually true that every node is infected after $O(D)$ steps, where $D$ is the diameter of the graph?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 6 down vote accepted\n\nConsider a tree of $n$ layers where each node at layer $n$ (up to $n-1$)has $n$ branches leading upward. The last node will be infected after $1+2+3 \\ldots +(n-1)=\\frac{n(n-1)}{2}$, but the diameter is $2n-2$\n\nshare|improve this answer\nadd comment\n\nConsider a starlike graph of n+1 nodes in which every node except node A is adjacent to A and only to A.\n\nIf A is infected, exactly one of its neighbors becomes infected at each step until all are. So the number of steps until every node is infected is n, not O(D) since D = 2.\n\nshare|improve this answer\nSimpler than mine. This one deserves the check mark. \u2013\u00a0 Ross Millikan Jun 22 '11 at 14:38\n@Ross: No, you had the answer first. I only posted because I thought I could add something. \u2013\u00a0 hardmath Jun 22 '11 at 16:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54364.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSum of Unit Fractions\n\nDate: 07/17/2001 at 20:28:27\nFrom: Candyce\nSubject: Java programing class\n\nSuppose that p/q is a fraction in lowest terms such that \n1/(n+1) < p/q < 1/n for some positive integer n. Show that \n(p/q) - (1/(n+1)) is a fraction which in its lowest terms has \nnumerator less than p. Hence by induction, prove that every proper \nfraction p/q with p < q can be written as a finite sum of distinct \nreciprocals of positive integers. \n\nFor example, 19/15 = 1/2 + 1/3 + 1/4 + 1/6 + 1/60. \n\nUse this technique to express 5/7 as a sum of reciprocals.\n\nThe example given here is correct, though it's not true that all \nfractions greater than 1 can be expressed finitely in this way \n(e.g. 2) - you've been asked to prove the statement only when the \nfraction is less than 1 (which is always true). If you want an \nexample for this case, then 14/17 = 1/2 + 1/4 + 1/14 + 1/476. \n\nThe problem is the PROFF part. I can understand that it works.\n\nDate: 07/18/2001 at 10:53:15\nFrom: Doctor Paul\nSubject: Re: Java programing class\n\nHere's how to do it for fractions less than one (assumed to be in \nlowest terms):\n\nI'll show you how it works for 14/17 and you should be able to \nit for any p/q.\n\nGiven 14/17, find the largest unit fraction less than 14/17. I think \nthe easiest way to do this is to systematically increment the \ndenominator by one until the fraction reduces to a unit fraction. The \nreduced unit fraction will be the largest unit fraction less than the \ngiven number. In the case of 14/17, we first consider: 14/18 = 7/9, \nwhich is not a unit fraction, so we next consider 14/19, 14/20 = 7/10, \n14/21 = 2/3, which is not a unit fraction, so we next consider 14/22, \n.... , 14/28 = 1/2.\n\nSo we know that 1/2 is a unit fraction and we know that it is less \nthan 14/17.\n\nThus we can write:\n\n  14/17 = 1/2 + a/b where a/b is to be determined.\n\nsubtract 1/2 from both sides to obtain:\n\n  a/b = 14/17 - 1/2 = 11/34\n\nThus we have:\n\n  14/17 = 1/2 + 11/34\n\nIf a/b had turned out to be a unit fraction, we would be done. But \nsince it isn't a unit fraction, we do the process again. We now want \nto convert 11/34 into a sum of unit fractions:\n\nIncrease the denominator until you get a unit fraction:\n\n  11/35, 11/36, ... , 11/44 = 1/4\n\n  so 11/34 = 1/4 + c/d\n\n\n  c/d = 11/34 - 1/4 = 5/68\n\nSo we have:\n\n  14/17 = 1/2 + 1/4 + 5/68\n\nIf c/d had been a unit fraction, we would be done. But since c/d was \nequal to 5/68, we now need to repeat the process and convert 5/68 into \na unit fraction.\n\nincrease denominators:\n\n  5/68, ..., 5/70 = 1/14\n\nso we have:\n\n  5/68 = 1/14 + e/f\n\n  e/f = 1/476\n\nSince e/f is a unit fraction, we're done.\n\nWe can now write the final result:\n\n\nwhich is exactly the answer you gave above.\n\nThis method is attributed to the British mathematician J.J. Sylvester \n\nIn general, the decomposition of a fraction into a sum of unit \nfractions is not unique. For example, 3/8 = 1/4 + 1/8 = 1/3 + 1/24.\n\nSince your subject is \"Java programming class\" I'm guessing that you \nhave to implement this algorithm in Java. Obviously, you're going to \nneed to run some sort of 'for' or 'until' loop to get this thing to \nrun properly. I've never programmed in Java, but I think it's a great \nassignment in any programming language! Good luck.\n\n- Doctor Paul, The Math Forum\nAssociated Topics:\nHigh School Calculators, Computers\nHigh School Number Theory\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/49141/galois-theory-splitting-field-of-cubic-as-a-vector-space?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to express the splitting field of a cubic equation as a vector space over the rationals. Specifically I am looking for a set of six independent vectors that span the space. If the roots are a,b, and c then I know I need to be able to express all expressions in a,b and c up to second degree: namely,\n\na, a^2\n\nb, b^2\n\nc, c^2\n\nab, bc, ca\n\na^2b, b^2c, c^2a, ab^2, bc^2, ca^2\n\nObviously there are 15 of these and they are not all independent. Given a and b, I easily get c as a linear term in a, b, and (a+b+c). Likewise c^2 is not independent of a^2 and b^2. And I find that I can generate ab etc as linear combinations of c, c^2, and abc.\n\nSo what are my six vectors? I have allowed myself 1, a, b, a^2, and b^2 ....this gives me five and I think they are all linearly independent. I'm only allowed one more and I can't get it to work. I'm inclined to try (a^2b + b^2c + c^2a) because I'm pretty sure I need it, but having done so I can't see how I generate terms like a^2b on their own.\n\nAny ideas? I'd be especially interesteds if there is a basis which is more symmetric in some sense than the arbitrary collection of terms which I'm cobbling together.\n\nshare|improve this question\nA cubic extension has degree $3$, not degree $6$. Or do you mean the splitting field of a cubic? In that case, it depends on the Galois group of the cubic. \u2013\u00a0 Qiaochu Yuan Jul 3 '11 at 5:01\nHave you tried a Gr\u00f6bner basis algorithm (Buchberger?) on the obvious set of generators? Also, is it immediately clear that you don't need to worry about monomials like $a^2b^2$? \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 5:25\n@qiaochu Although English is my first language, I am very weak on the terminology in this subject. Yes, I think I meant the splitting field of the cubic; and I know that some cubics have a different Galois group, but I meant the most general case of S3. \u2013\u00a0 Marty Green Jul 3 '11 at 5:45\n@Jyrki I don't know anything about the methods you refered to; but yes, I forgot about terms like a^2b^2 when I posted my question. In fact, I get them the same way I got terms like ab; since a^2b^2c^2 is an integer, I divide by c^2 which is the same as multiplying by a linear term in c. I think. \u2013\u00a0 Marty Green Jul 3 '11 at 5:48\n@Marty: Sorry about bringing up Gr\u00f6bner here. Too heavy a tool for this job. \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 8:17\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nThe simplest basis I can think of consists of monomials $\\mathcal{B}=\\{1,a,a^2,b,ab,a^2b\\}$. One way to see this goes as follows. Let's first write $$ P(x)=(x-a)(x-b)(x-c)=x^3-s_1x^2+s_2x-s_3, $$ with the elementary symmetric polynomials $s_1=a+b+c$, $s_2=ab+bc+ac$ and $s_3=abc$. If $K$ is your base field, I claim that all the monomials $a^ib^jc^k$ can be written as linear combinations of monomials from the set $\\mathcal{B}$ with coefficients from the field $L=K(s_1,s_2,s_3)$ (in your case surely $s_1,s_2,s_3\\in K$, so the combinations are really $K$-linear).\n\nThe first and most obvious thing is to replace everywhere $c$ with $s_1-a-b$. After that we only need to take care of monomials $a^ib^j$. The quantities $a$ and $b$ are zeros of $P(x)$, so we know how to replace $a^i, i\\ge 3$ and $b^j, j\\ge3$ with lower powers. So we are left with the 9 monomials $\\mathcal{B}\\cup\\{b^2,ab^2,a^2b^2\\}$. Substituting $c=s_1-a-b$ to the equation $ab+ac+bc-s_2=0$ gives us a relation $$ b^2=ab+a(s_1-a-b)+b(s_1-a)-s_2 $$ that allows us to write $b^2$ as an $L$-linear combination of $a^2,ab,a,b$ and $1$. When we do this substitution to a monomial like $ab^2$ or $a^2b^2$ we introduce higher powers of $a$. But we can reduce these to lower powers of $a$ as before. It may feel like $s_3$ wasn't really used, but it did make an appearance, when we reduced the higher powers of $a$ and $b$.\n\nshare|improve this answer\nNicely done, and very well explained. Thanks. \u2013\u00a0 Marty Green Jul 3 '11 at 12:23\nIn retrospect the basis is obvious given that this is the usual way of getting a basis for a tower of field extensions. $L(a)/L$ has a basis $\\{1,a,a^2\\}$ and $L(a,b)/L(a)$ a basis $\\{1,b\\}$. A basis for $L(a,b)/L$ is gotten by including all the products of elements of the two bases. \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 18:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/124556/signing-a-strongly-regular-graph/124705\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be the adjacency matrix of a strongly regular graph. When is it possible to sign $A$ (i.e. replace some of the +1 entries by -1) so that the resulting matrix has exactly two eigenvalues?\n\nI know of one interesting case where this is possible. Namely, define a graph $G$ where $V(G)$ is the set of 120 lines in ${\\mathbb R}^8$ given by the $E_8$ root system, and two vertices are adjacent if these lines make an angle of $\\pi/3$. This graph is strongly regular with parameters $(120, 56, 28, 24)$. To sign it, choose one vector in $E_8$ from each of these lines, and let $B$ be the associated Gram matrix. Then $C = B - 2I$ is a signing of the adjacency matrix of $G$ with just two eigenvalues ($-2$ and $28$).\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nSuppose we have a set of unit vectors $x_1,\\ldots,x_m$ in $\\mathbb{R}^d$ such that (for $i=j$) either $x_i^Tx_j=0$ or $|x_i^Tx_j|=a$. The Gram matrix of these vectors can be written as $I+aS$, where $S$ is symmetric, has zero diagonal, and entries in $\\{0,\\pm\\}$. So we have a signed graph. (Hi Tom.) Replacing $x_i$ by $-x_i$ for some $i$'s does not change anything of interest, we're really dealing with sets of lines.\n\nBy results of Delsarte, Goethals and Seidel \"Spherical Codes and designs\" we know that $m\\le \\binom{n+2}3$. They mention two examples where this bound is tight: $d=8$ as in your question and 2300 lines when $d=23$. It's likely that these are the only known examples where the bound is tight. I think DGS supply enough theory to show that the underlying graph will be strongly regular in this case.\n\nDGS also derive a bound $$ m \\le \\frac{d(d+2)(1-a^2)}{3-(d+2)a^2}. $$ I'd expect that sets of lines meeting these bounds will give strongly regular graphs (but I could not see exactly what I needed in a quick skim and my coffee break is coming to an end).\n\nForgive me if you knew all this and were really fishing for more examples.\n\nEdit: Let $H$ be an $n\\times n$ Hadamard matrix and let $A$ be given by $$ A =\\begin{pmatrix}0&H^T\\\\\\ H&0\\end{pmatrix} $$ Then $A^2=nI$ and $A$ is a signing of the complete bipartite graph. These examples may appear a bit trivial, but there are a lot of them. More generally any antipodal distance-regular graph with diameter four (and antipodal fibres of size two) will give rise to examples. Unfortunately this will only produce three further examples, and the margin is too small to deal with these.\n\nEdit2: The fact equality in the given bound implies that the graph on the lines is strongly regular appears as (part of) Proposition 3.12 in the paper by Calderbank, Cameron, Kantor and Seidel on Kerdock codes over $\\mathbb{Z}_4$. They also prove that equality in the bound imples that the signed adjacency matrix has exactly to eigenvalues.\n\nshare|improve this answer\nI am aware of the construction using lines which are all either pairwise orthogonal or at a given angle. If you have n lines spanning a d dimensional space with n > d, then the resulting matrix you construct will have smallest eigenvalue of multiplicity n-d. However, I don't understand anything about the interaction between the geometry of these lines and the behaviour of any other eigenvalues. I didn't have any secret agenda here, but I am certainly delighted to learn of this result from Delsarte Goethals and Seidel, and of another magic configuration. Thanks!! \u2013\u00a0 mdevos Mar 20 '13 at 4:38\nadd comment\n\nHere are a few ideas on places to look for examples. You may not find (m)any this way.\n\nFirst to eliminate a trivial case: For some people a complete graph or disjoint union of isomorphic complete graphs is a SRG. These only have two eigenvalues even without making any changes.\n\nA SRG need not have any automorphisms but many do. This allows an easier complete search of very small cases. In a very modest search I found one legit example and a few questionable ones. Then it seems reasonable to look for ways to sign the matrix and preserve a large subgroup of the automorphism group (but I did not get anything from that.)\n\nEssentially we are taking a graph with $e$ edges, viewing it as having $2e$ directed edges, and then giving some of them a weight of $-1$.\n\nA 4-cycle has 4 edges or $8$ directed edges (aka $+1$ entries of the Adjacency matrix $A$)\n\n  \u2022 Changing a single $1$ to $-1$ does not work.\n  \u2022 There are $28$ ways to choose two entries, but only $6$ up to action of the Dihedral group. Changing two entries , both from the same edge, gives eigenvalues $\\pm\\sqrt{2}$ twice each. (That is my sole good example so enjoy it). There are also three ways to change two entries to $-1$ and get all eigenvalues $0$: the two edges leaving a vertex, the two going into a vertex, and two parallel directed edges.\n  \u2022 there are no successful ways to change three entries.\n  \u2022 There are $\\binom84=70$ ways to choose $4$ entries to change but only $13$ up to isomorphism (maybe less but at worst I looked at some cases twice.) Four of them give all eigenvalues $0.$\n\nNote that with two eigenvalues $\\theta_1,\\theta_2$ taken $k$ and $n-k$ times we need $\\frac{\\theta_1}{\\theta2}=-\\frac{n-k}{k}$ unless it is actually a single eigenvalue of $0$.\n\n  \u2022 A pentagon amounts to $10$ directed edges, There is no way to change some of the entries of $A$ to $-1$ and get only two eigenvalues. There are $\\binom{10}{5}=252$ ways to change $5$ of them but only $26$ up to isomorphism.\n\n  \u2022 The complete bipartite graph has $18$ directed edges. Nothing works there. There would be $\\binom{18}{9}=24310$ ways to change half the edges but only $681$ up to isomorphism.\n\nI'd hoped to find an example which generalized. I did not give up after two tries but did after three. Maybe someone else will find something by looking a bit harder. Perhaps $K_{2,2,2}$ , $K_{4,4}$, or some other small case.\n\nI also looked, without results at a few ways to weight the $2 \\cdot 15=30$ directed edges from a Peterson Graph.\n\n  \u2022 The obvious order $5$ rotation gives $3$ pairs of $5$ edge orbits so $64$ (or $32$ or $16$ depending how hard you wish to think) ways to sign some orbits $-1$. None worked ( assuming I programmed correctly).\n  \u2022 Fixing a point gives orbits of sizes $3,3,6,6$ and $12$ (Probably the $12$ could be split $6,6$ but I did not try that variation. ) That does not yield anything.\n  \u2022 I did not look at fixing a pair of vertices (setwise). This would give orbits of sizes $1,1,4,4,8,8,2?,2?.$\n\nA similar attempt could be made for other graphs.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/32281/inverse-of-baker-campbell-hausdorff\nText:\nTake the 2-minute tour \u00d7\n\nThis should be quite simple to answer. I have a situation in which I must have an explicit expression for the inverse of Baker-Campbell-Hausdorff. More precisely:\n\nI have two power series $P_1(X,Y)$, $P_2(X,Y)$ in noncommuting variables $X,Y$. I want an expression for\n\n$$exp\\left(log(1+P_1) + \\ log(1 +P_2) \\right) .$$\n\nI searched some books and google; but beyond the fact that it exists, I am unable to find an explicit expression. If it already exists in print, it would save me some work of trying to derive it myself.\n\nThank you very much.\n\nshare|improve this question\nI assume that should be $\\log(1+P_1)+\\log(1+P_2)$? \u2013\u00a0 David Speyer Jul 17 '10 at 13:01\nYes, thanks. I fixed it. Sorry for the mistake. \u2013\u00a0 Anweshi Jul 17 '10 at 13:02\nDeriving it yourself is fun! By the way, what is the significance of $P_1$ and $P_2$ as opposed to $X$ and $Y$? Even if one or both $P_i$s have a non-zero constant term, it can be absorbed into the constant 1 inside the $\\log.$ \u2013\u00a0 Victor Protsak Jul 17 '10 at 19:17\nThere is no significance, except that when I needed to work it out, it came up as two arbitrary power series, rather than just X and Y. \u2013\u00a0 Anweshi Jul 17 '10 at 21:06\nI don't remember if you are automatically updated when I edit an answer. If not, this note is to mention that I have added some content, answering a question I asked in the comments. \u2013\u00a0 Theo Johnson-Freyd Jul 19 '10 at 5:37\nshow 1 more comment\n\n2 Answers\n\nThe following recursion formula for the homogeneous factors of $A(P,Q)$ exists:\n\n\n$A(tP,tQ) = 1 + t \\frac{B_1}{1!}+t^2 \\frac{B_2}{2!}+t^3 \\frac{B_3}{3!}+...$\n\n$C_n = P^n+Q^n$\n\n$\\Delta C_n = -n C_{n+1}$\n\n\n$B_1 = C_1$\n\n$n! B_n = [(\\Delta+C_1) B_{n-1}] _{symm}$\n\nWhere the symmetrization is of all words of the type $C_{i1} C_{i2} C_{i3} ... $\n\nThis formula can be obtained by differentiation with respect to t. I compared the results up to the cubic term to Theo's expression with a full agreement.\n\nThe coefficient of the string $\\[(C_{i1} C_{i2} C_{i3} ...]_{symm}$ in $B_n$ is equal to the coefficient of $tr(M^{i1}) tr(M^{i2}) tr(M^{i3})...$ in the coefficient of $t^n$ in $det(I-tM)$. These coefficients are the charcters of $\\{{{1^n\\}}}$ of $S_n$.\n\nshare|improve this answer\nadd comment\n\nGiving your series a name, I'll set $$A(P,Q) \\overset{\\rm def}= \\exp\\bigl( \\log(1 + P) + \\log(1 + Q) \\bigr) $$ to be your power series, where $P,Q$ are free (noncommuting) variables. I'm not sure what you want to know about this series: it exists, I don't think it has a name, the first few terms are $$ A(P,Q) = 1 + P + Q + \\frac12(PQ + QP) + \\frac1{3! \\cdot 2}\\left(-P^2 Q + 2PQP - Q^2 P-PQ^2 + 2QPQ - Q P^2\\right) + $$ $$ + \\frac1{4!}\\left( P^3 Q - P^2QP -PQP^2 + QP^3 - PQ^2P + PQPQ + \\{P\\leftrightarrow Q\\} \\right) + \\dots.$$ I don't see much of a pattern in the coefficients, and I haven't worked out the next term. If the cubic term didn't have that $\\frac12$, or if the quartic terms had more fractions, I would be happier. As it should, when $[P,Q] = 0$, the series truncates to $A(P,Q) = 1 + P + Q + PQ$. It is left-right symmetric and symmetric in $P\\leftrightarrow Q$.\n\nHere's one remark that might be useful for your intended application. Let $K = k\\langle\\langle X,Y\\rangle\\rangle$ be the ring of power series in two noncommuting variables. Then there is an algebra homomorphism $\\Delta: K \\to K \\hat\\otimes K$, where $\\hat\\otimes$ denotes that you should complete the tensor product w.r.t. the adic topology, given on generators by $\\Delta(X) = 1 \\otimes X + X\\otimes 1$ and $\\Delta(Y) = 1 \\otimes Y + Y \\otimes 1$. Recall that an element $P \\in K$ is primitive if $\\Delta(P) = 1 \\otimes P + P\\otimes 1$. Then the primitive elements form a Lie subalgebra of $K$, and consist precisely of the Lie series: the power series that can be expressed without ever referring to multiplication in $K$, only to the Lie bracket $[x,y] = xy - yx$ (and that begin in degree $1$). Recall also that an element $P\\in K$ is grouplike if $\\Delta(P) = P\\otimes P$. Then the grouplike elements if $K$ form a group under multiplication; in particular, they are all units.\n\nIf $P,Q$ are primitive, then there's no particular reason for $A(P,Q)$ to be primitive, and actually I think it never will be. However, by construction $\\Delta$ is continuous w.r.t. the adic topology, and it is a homomorphism, and so $\\Delta(f(P)) = f(\\Delta(P))$ for any power series $f$ in one variable. Also, an element $P\\in K$ is primitive iff $\\exp(P)$ is grouplike. So it follows that if $1+P$ and $1+Q$ are both grouplike, then so is $A(P,Q)$.\n\nI'll close by saying that, to me anyway, you already have an \"explicit expression\" for the power series, and even a \"geometric interpretation\", which is that it moves the additive structure of the Lie algebra to the (formal) group (whereas the BCH series moves the group multiplication to the Lie algebra). You shouldn't strongly hope for a simple description of the coefficients in terms of combinatorics, because similar descriptions for BCH, although they do exist, can be rather complicated.\n\n\nAbove I observed that $A(P,Q)$ is not a Lie series in $P,Q$. This can be seen directly: any Lie series truncates to its linear and constant terms when $[P,Q] = 0$, whereas $A(P,Q) = (1+P)(1+Q) = 1 + P + Q + PQ$ in commuting land.\n\nSo the next best thing, as I asked in the comments, is whether $$A(P,Q) - (1+P)(1+Q) = -\\frac12[P,Q] - \\frac1{12} \\bigl( [P,[P,Q]] + [Q,[Q,P]] \\bigr) + \\dots $$ is a Lie series. Alas, this also fails, as can be seen at the quartic part. Indeed, by Jacobi and antisymmetry, $$ [P,[Q,[P,Q]]] = [[P,Q],[P,Q]] + [Q,[P,[P,Q]] = [Q,[P,[P,Q]] = -[Q,[P,[Q,P]] $$ is the unique Lie monomial (up to scalar) of degree $P^2Q^2$. But it is antisymmetric under $P\\leftrightarrow Q$, whereas $A(P,Q)$ is symmetric under the same transposition. Thus if $A(P,Q) - (1+P)(1+Q)$ were a Lie series, then it could not have any terms of degree $P^2Q^2$, whereas by direct calculation: $$ A(P,Q) \\ni \\frac1{4!} \\bigl( PQPQ - PQ^2P - QP^2Q + QPQP \\bigr) = \\frac1{24} [P,Q] ^2 $$\n\nshare|improve this answer\nThanks. This was helpful. The application was the following. I wanted to define a sort of \"geometric mean\" for some finite number of noncommutative power series and see how badly it behaves, and how much can be salvaged. That is why I asked for an explicit expression, and I was imagining that something may exist using nested Lie brackets, like in BCH. I was hoping that such an expression was already worked out in the literature. Thanks for your effort. I will wait for some time and if no better answer comes, I will accept yours. \u2013\u00a0 Anweshi Jul 17 '10 at 21:10\n@Anweshi: well, I hope you get something closer to what you're looking for. But you can see explicitly, and also from the abstract nonsense about primitive versus grouplike elements, that there will not be a formula with nested brackets. OTOH, I don't see immediately whether $A(P,Q) - (1+P)(1+Q)$ is a Lie series. It does vanish when $[P,Q] = 0$, which is promising, but not sufficient. \u2013\u00a0 Theo Johnson-Freyd Jul 18 '10 at 1:48\nSince this is in the group (as opposed to the Lie algebra), the right kind of \"bracket\" is a group commutator. Anweshi: the \"geometric mean\" that you allude to is probably related to non-commutative exponential function (given by the multiplicative integral). You may find some general theory in books by Maslov and coauthors. \u2013\u00a0 Victor Protsak Jul 18 '10 at 2:24\n@Victor: Yes, this (use the group commutator) occurred to me. But with only multiplication and inverses, I'm dubious that I'd be able to write down an infinite product that converges to the operation in question. OTOH, the series $A(x,y)$, when $x,y$ are the generators of the noncommutative power series ring, is the limit of $\\bigl((1+x)^{1/n}(1+y)^{1/n}\\bigr)^n$ --- note that $(1+x)^{1/n}$ converges in the power series ring. There is certainly an infinite product whose $n$th partial product is $\\bigl((1+x)^{1/n}(1+y)^{1/n}\\bigr)^n$, but I don't find that enlightening. \u2013\u00a0 Theo Johnson-Freyd Jul 18 '10 at 3:25\nWell, I was not saying that group commutator $\\textit{would}$ work (cf Hall's identity, which is a nontrivial group-like analogue of the Jacobi identity), merely stating an obvious reason why the Lie bracket wouldn't. \u2013\u00a0 Victor Protsak Jul 18 '10 at 9:11\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/36743/solving-series-of-linear-systems-with-diagonal-perturbations/36754\nText:\nTake the 2-minute tour \u00d7\n\nI would like to solve a series of linear systems Ax=b as quickly as quickly as possible. However, the systems are related. Specifically, each matrix A is given by:\n\ncI + E\n\nwhere E is a fixed sparse, symmetric positive definite real matrix (unchanged in all the linear systems), I is the identity matrix, and c is a varying complex number.\n\nIn other words, I am wondering how to quickly solve a series of complex linear systems which are all identical except for complex perturbations along the diagonal. I should say that the resulting matrices are not necessarily Hermitian, so currently I compute the LU decomposition. This works, but given the large number of rather closely related systems to be solved, I wonder if there is a better way to solve the problem, perhaps by using a more expensive (e.g. QR) decomposition up front.\n\n(Edit for Jiahao: Yes, the bs are all the same.) (Edit for J. Mangaldan: The matrices are of order n=10^5 ~ 10^6, with about 10 times that many nonzeros.)\n\n\nI'd like to thank everyone here for their suggestions. My implementation is ugly, but in the end interpolation was the key to a reasonable (10x) speedup. Since the c are quite close (imagine a small region of the complex plane, small in the sense that the spectrum of the matrix E is much larger) I could get away with computing solutions for a subset of the values of c and interpolating a solution for a given value of c using the precomputed values. It isn't elegant at all but it's something.\n\nshare|improve this question\nI assume the bs are all the same then? \u2013\u00a0 Jiahao Chen Aug 26 '10 at 11:55\nExactly how big are your matrices anyway? This can crucially affect the practicality of proposed solutions. \u2013\u00a0 J. M. Aug 26 '10 at 12:33\n$10^6$... you've essentially said none of the proposals thus far are practical. ;) So what you in fact want is the vector $(E+cI)^{-1}b$ with varying c; I'll check my notes on special methods for sparse matrices and report back. Only one thing: definitely QR decomposition will not be a practical solution to your problem either! \u2013\u00a0 J. M. Aug 26 '10 at 12:51\nadd comment\n\n3 Answers\n\nup vote 1 down vote accepted\n\nYou want the resolvent of $E$ (at $z:=-c$). Recall it's an analytic function of $z$ defined on the resolvent set, $\\mathbb{C}\\setminus\\operatorname{spec}(E)$. According to the complexity of the matrix $E$, and with the number and the location of the $c$ you need to consider, it may be worth computing a power series expansion at various centers so as to cover the set $\\{c\\}$ of the data. For $|z|$ larger than the spectral radius you have of course the Laurent expansion $(z-E)^{-1}=1/z+ E/z^2+ E^2/z^3+\\dots$\n\nshare|improve this answer\nWell, (E+cI)x=b can indeed be turned into something like (E/c+I)x=b/c, and thus you can use the geometric series technique. Of course, if the spectral radius of E/c is bigger than 1, this idea is shot. \u2013\u00a0 J. M. Aug 26 '10 at 12:29\nIs there a method to use the resolvent without computing it explicitly? It seems to use the resolvent would have to be recalculated for all cs, and explicit computation could result in massive fill-in (loss of sparsity) as @J. Mangaldan pointed out above once products like E^2 are computed. \u2013\u00a0 Jiahao Chen Aug 26 '10 at 12:50\nWell, one can do it Krylov-style, assuming there is a nice black box for matrix-vector multiplications. Maintain a vector v initialized to the right-hand side, and at every iteration multiply this by E. But again, this is only feasible if it can be assured that the spectral radius of E/c never exceeds unity. \u2013\u00a0 J. M. Aug 26 '10 at 13:00\nYes, as I wrote. Nevertheless, finitely many expansions suffice to cover the set of {c}; whether this approach is efficient depends on the details. \u2013\u00a0 Pietro Majer Aug 26 '10 at 14:22\nadd comment\n\na) There are formulae such as the Woodbury identity that allow for rank k updates to a previously solved problem, which I think fits your problem nicely.\n\nb) In addition, using a reasonably smart iterative algorithm such as conjugate gradients (or whatever is appropriate for your problem) will also be helpful since you can feed it the solution from your previous problem, and for small perturbations the new solution can be computed very quickly.\n\nIn practice I have found it sufficient to use just (b), but it might be worth trying both separately or together.\n\nshare|improve this answer\n(a) does not look useful since the updates are full-rank (b) seems useful only if the $c$s are close. Or am I missing something? \u2013\u00a0 Federico Poloni Aug 26 '10 at 12:14\nSherman-Morrison-Woodbury, as already stated, is of no help since it is intended for low-rank corrections; e.g., corrections expressible in the form $UV^T$, where $U$ and $V$ are rectangular. CG is of no use since he said in the problem statement \"I should say that the resulting matrices are not necessarily Hermitian\", and computing $(E+cI)^T(E+cI)$ so that you can apply CG can result in a much denser matrix. \u2013\u00a0 J. M. Aug 26 '10 at 12:24\n@Frederico: That's true, I forgot about fill-in, since using Woodbury would require the computation of E^-1 . E^-1. I am assuming that the c's are small since the OP did say diagonal perturbations. \u2013\u00a0 Jiahao Chen Aug 26 '10 at 12:54\n@J. Mangaldan: that is true, CG is not guaranteed to work. Sometimes it does anyway though! But really without knowing more about the problem it is difficult to recommend any particular iterative solver. Tricks like level shifting (regularizing the matrix A to make it always posdef) can sometimes be useful in using CG. BCG certainly doesn't seem feasible due to fillin. My first thought was regularized CG or GMRES. \u2013\u00a0 Jiahao Chen Aug 26 '10 at 12:54\nA method that sometimes works and sometimes doesn't, IMHO, cannot be recommended in good conscience to somebody whose problem's properties still have to be explored fully. Besides, he said c can be complex, and that can play havoc with regularization. \u2013\u00a0 J. M. Aug 26 '10 at 12:57\nshow 1 more comment\n\nIf you're doing a full LU decomposition and ignoring sparsity, then you could switch to a Schur decomposition (costs $25n^3$ instead of $2/3n^3$, but allows you to solve any of the resulting systems within $O(n^2)$). If you're using sparsity, as far as I know it is an open research problem how to exploit fully this property (see e.g. the rational Krylov method).\n\nshare|improve this answer\nE might be sparse, the Schur decomposition is definitely dense, and computational time and storage can be prohibitive. I'm assuming that E is a large enough matrix that the \"LU decomposition\" alluded to in the original post is in fact set to do something like the Cuthill-McKee ordering to maintain sparsity in the triangular factors. \u2013\u00a0 J. M. Aug 26 '10 at 12:32\nUnfortunately, I do need to maintain sparsity or the problem becomes too big to handle. (I am using the KLU package, but I expect that most LU solvers would be able to handle the linear systems I have.) \u2013\u00a0 Fumiyo Eda Aug 26 '10 at 12:47\nAs I said, the reason why those LU solvers can manage your large matrices is that they do a preliminary analysis of sparsity pattern before performing the LU decomposition. Blindly triangularizing or pivoting can result in disastrous fill-in, and thus pattern analysis is a crucial step for these LU solvers. \u2013\u00a0 J. M. Aug 26 '10 at 12:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/112290/heuristic-for-partitioning-n-partite-weighted-graphs-into-bounded-n-cliques\nText:\nTake the 2-minute tour \u00d7\n\nConsider a complete $N$-partite graph $X$ with $X_n$ denoting the $n$-th vertex bin for $1 \\leq n \\leq N$, where we may assume that each $X_n$ has $k$ vertices for some universal constant $k$. Assume that the edges have positive real weights and also consider a real number $r \\geq 0$.\n\nA clique is a collection of $N$ vertices, one from each bin. By completeness of $X$, any two such vertices are connected by an edge. The weight of a clique is defined to be the maximal weight among all edges contained in that clique.\n\nGiven $X$ and $r$ as above, is there an efficient algorithm that answers yes if it is possible decompose $X$ into $k$ cliques so that the weight of each clique is less than or equal to $r$, and no if there is no such decomposition?\n\nMy question is similar to the one here but I am not looking to minimize the clique weight across all possible decompositions, just to confirm that there is a decomposition satisfying the upper bound of $r$.\n\nUpdate: Since the problem is unfortunately NP complete (see the answer below),\n\nAre there any known polynomial-time approximations and/or practical heuristics to attack such a problem?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe reduction in the answer to the question you have linked to shows that your problem is NP-complete. For a complete 3-partite graph with edge weights 1 and 2 it is NP-complete to decide if there is a decomposition into triangles of weight 1 (your weight function). Actually, usually NP-completeness of an optimization problem is defined by NP-completeness of the corresponding decision problem, if there exists a solution reaching a given threshold.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/367639/proof-of-the-number-of-partitions\nText:\nTake the 2-minute tour \u00d7\n\nProve that the number of partitions of $n$ for which no part occur more than $9$ times is equal to the nujmber of partitions of $n$ with no parts divisible by $10$.\n\nshare|improve this question\nKeyword: Glaisher's theorem. \u2013\u00a0 darij grinberg Apr 20 '13 at 20:54\nHint: Do you know the diamond lemma (about confluence and local confluence of rewriting systems)? Start with a partition with no parts occuring more than $9$ times. As long as there is a part divisible by $10$, break it into $10$ equal parts. Iterate, until no part is divisible by $10$. Conversely, start with a partition with no parts divisible by $10$. As long as there exist $10$ equal parts, take such $10$ parts and combine them into one big part. Iterate, until there are no $10$ equal parts. The only thing you need to show is that the final result of such an iterative procedure does not ... \u2013\u00a0 darij grinberg Apr 20 '13 at 20:56\n... depend on the choices you made during the procedure (i. e., which parts to break or combine first). This is where the diamond lemma comes in, but you can also avoid it by arguing digits (in the $10$-adic system, apparently an attempt of the problem poser to make things more intuitive). \u2013\u00a0 darij grinberg Apr 20 '13 at 20:58\nYou can replace the integer $9$ by any positive integer $k$ and $10$ by $k + 1$ and the result is easy to establish via generating functions. \u2013\u00a0 Paramanand Singh Aug 3 '13 at 4:53\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThe generating function for the first case is given by $$ f(z) =\\prod_{k\\ge 1} (1 + z^k + z^{2k} + \\cdots + z^{9k}) = \\prod_{k\\ge 1} \\frac{1-z^{10k}}{1-z^k}.$$\n\nThe generating function for the second case is given by $$ g(z) = \\prod_{k\\ge 1} \\frac{1}{1-z^k} \\prod_{m\\ge 1} (1-z^{10m}).$$\n\nThese two are the same and we are done. The first GF lists the contribution from each value from zero to nine times. The second GF includes all partitions through the first product and then cancels those that correspond to parts that are divisible by ten.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/81944/whats-the-expected-matched-pair-of-shoes-when-10-pairs-mixed-up\nText:\nTake the 2-minute tour \u00d7\n\nWe've got $10$ different pairs of shoes. Now we mix them up and randomly regroup them into $10$ \"pairs\". Of course some \"pairs\" are not matched and maybe some of them are. So what's the expect number of pairs that are matched?\n\nBy \"randomly group\", I mean you can randomly pick one from the $20$, then choose one from the remaining $19$ to pair it up, and so on.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nLet $X$ be the number of pairs of shoes that are matched. It is somewhat complicated to work with $X$ directly, so we think of $X$ as a sum of simpler variables:\n\nFor $i=1,2,\\ldots10$, let $X_i=\\cases{1 & \\text{if the }i\\text{th pair is matched},\\\\ 0 & \\text{otherwise}.}$\n\nThen each $X_i$ is a Bernoulli variable and $X=\\sum_{i=1}^{10}X_i$.\n\nExpectation is linear, so $$ \\Bbb E(X)=\\sum_{i=1}^{10}\\,\\Bbb E(X_i). $$\n\nNow we fix $i$ and find $\\Bbb E(X_i) $:\n\nSince $X_i$ is a Bernoulli variable, $\\Bbb E(X_i)=P[X_i=1]$. But the probability that $X_i=1$ is the probability that the $i$th pair was matched. Since it is equally likely that any one of the other 19 shoes is paired with the left shoe of the $i$th pair, $P[X_i=1]={1\\over19}$.\n\nSo $\\Bbb E(X_i)={1\\over19}$.\n\nFinally, we have:\n\n$$\\Bbb E(X)=\\sum_{i=1}^{10}\\Bbb E(X_i)=\\sum_{i=1}^{10}{1\\over19}=10/19.$$\n\nshare|improve this answer\nI should mention why $P[X_i=1]={1\\over19}$ without \"hand waving\": there are ${20!\\over2^{10}}\\cdot{1\\over10!}$ ways to divide the 20 shoes into pairs and there are ${18!\\over2^9}\\cdot{1\\over9!}$ ways to divide them into pairs with the $i$th pair matched. $P[X_i=1]$ is the ratio of these quantities, which is $1/19$. \u2013\u00a0 David Mitra Nov 14 '11 at 10:15\nInteresting that you're allowed to pair a right shoe with another right shoe. I might have stated the problem differently---maybe using socks, since with those you can't tell left from right. \u2013\u00a0 Michael Hardy Nov 14 '11 at 11:45\nI'm thinking of the problem as the same as \"10 married couples are split into 10 groups, each of size 2\". Find the expected number of groups consisting of a married couple. (That is, a pair of shoes consists of two distinct objects.) \u2013\u00a0 David Mitra Nov 14 '11 at 11:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/83958/combinatorial-geometry-covering-a-square?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm stuck with this problem. can anyone help me?\n\nA finite collection of squares has total area 4. show that they can be arranged to cover a square of side 1.\n\nshare|improve this question\nSquare overlapping is allowed, right ? If, for exemple, you have 21 small squares with areas $a_1,a_2, \\ldots ,a_{21}$ given by $a_k=\\frac{19}{105}+\\frac{k-1}{1050}$, then all the $a_k$'s are different and smaller than $a_{21}=\\frac{1}{5}$, so if we cover a unit square with those small squares, some small squares will necessarily overlap. \u2013\u00a0 Ewan Delanoy Nov 20 '11 at 17:16\nyes, overlapping is allowed. \u2013\u00a0 Goodarz Mehr Nov 20 '11 at 17:37\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nHere's a proof using the following simple combinatorial\n\nLemma. Let a positive integer $k$ and a nonempty finite multiset $P$ of powers $k^i$ with $i\\in\\mathbf{Z}$ be given. Put $s=\\sum P$, the sum of all the powers, and $k^m$ the greatest power occurring in $P$; let the integer $q>0$ be such that $s\\geq qk^m$. Then there exists a partition of a sub-multiset of $P$ into $q$ parts each of sum exactly $k^m$.\n\n(Finding a decent formulation is more difficult here than finding a proof.) One can obviously take $q$ the quotient of the Euclidean division of $s$ by $k^m$, but for the proof it will be convenient to have a bit more freedom. The condition for a collection of multisets of being a partition of a sub-multiset of $P$ is what the terminology suggests: it just means that for any element, the sum of its multiplicities of occurrence in members of the collection is no more than its multiplicity of occurrence in $P$.\n\nProof. By induction on the number $n\\geq1$ of elements in $P$. Split off from $P$ the singleton $\\{k^m\\}$ of its greatest element, which will be one part of the partition sought, leaving a remainder $P'$. If $q=1$, then the one-part partition $\\{k^m\\}$ is a solution. In the remaining case one certainly has $n>1$, so $P'$ is non-empty; let $k^{m'}$ be the greatest element of $P'$, with obviously $m'\\leq m$. Applying the induction hypothesis to $P'$ and $q'=(q-1)\\,k^{m-m'}$, one obtains a partition of a sub-multiset of $P'$ into $q'$ parts each of sum $k^{m'}$. Grouping them together $k^{m-m'}$ at a time (in an arbitrary way) provides a partition of the same sub-multiset of $P'$ into $q-1$ parts, which together with $\\{k^m\\}$ give a solution. QED\n\nNow for the problem of the squares, round the lengths of their sides down, each to a (probably negative) integer power of $2$. Each square will certainly cover a square of the rounded-down size, and replacing the collection by the so rounded-down squares gives a multiset of squares whose total area is greater than a quarter of the original area, that is greater than 1. Excluding the trivial case of a single square of area $4$, the largest square has size $2^{-l}$ with $l\\in\\mathbf{N}$. Apply the lemma with $k=4$, the multiset of the areas of the rounded-down squares, and $q=4^l\\in\\mathbf{N}$. This provides a partition of a sub-multiset of the squares into $q$ parts, each of which parts will cover one of the $q$ squares of the $2^l\\times2^l$ subdivision of the unit square. (One needs to check that the regrouping of $4^{m-m'}$ multisets done in the proof of the lemma can be realised geometrically, but this is obvious by a similar $2^{m-m'}\\times2^{m-m'}$ subdivision.)\n\nshare|improve this answer\n\"...the greatest power occurring in S\" - what is S? Did you mean P? \u2013\u00a0 Erel Segal Halevi May 19 '13 at 10:30\n@ErelSegalHalevi Yes, thank you. Corrected now. \u2013\u00a0 Marc van Leeuwen May 19 '13 at 10:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/90189/checking-consistency-of-a-system-of-linear-equations-and-inequalities/90199\nText:\nTake the 2-minute tour \u00d7\n\nI have a lot of systems of equations and inequalities of the following form:\n\n$$ a_{1,1}x+a_{1,2}y+a_{1,3}z+a_{1,4}w = 2 $$ $$ \\ldots $$ $$ 0 < x < 2 $$ $$ 0 < y < 2 $$ $$ 0 < z < 2 $$ $$ 0 < w < 2 $$\n\nThere are always at least two equations, and I probably won't consider cases with more than twenty equations. All coefficients $a_{i,j}$ are positive integers and some can be zero. We also have the property that $\\sum_{j=1}^4a_{i,j}\\geq3$ for all $i$. The solutions are real numbers.\n\nI don't need to solve these systems, but I need to be able to tell whether there exists a solutions. If it isn't possible to tell for each system whether it is consistent or not, any method which identifies as many inconsistent systems as possible is greatly appreciated.\n\nI have a few hundred millions of these systems, so I'm specifically looking for things that can easily be turned into a program. (I know the basic techniques to do this by hand, and am looking for some handy tricks that can be done by a computer. I have some programming experience, but not really with programming this kind of problems.)\n\nshare|improve this question\nIts difficult to give an appropriate answer here but a very simple approach would be to use view this as a convex feasibility problem: You try to decide if the intersection of the solution space of the linear equation with the cube defined by the inequalities is not empty. Since your linear systems seem to be small and it looks like projecting a point onto the polytope formed by the linear constraints is also easy, alternating projections should be easy and fast. \u2013\u00a0 Dirk Mar 4 '12 at 10:43\nHave a look at constraint-logic programming (in particular, over the reals -- CLP(R)) which is designed for just such problems. Typically these are implemented as Prolog libraries (Sicstus, SWI), but I believe that stand-alone versions are available too. \u2013\u00a0 J.J. Green Mar 4 '12 at 11:21\nFor these systems solving them is no harder than detecting feasibility. So just add an objective function, e.g., x+y+w+z, and now you have a linear program. Stuff this into an LP solver and it will tell if your feasible region is empty. If you read the manual, there may a flag you can set to avoid dding the objective function. This question would be just as well answered at math.stackexchange, and is not appropriate for this site. \u2013\u00a0 Chris Godsil Mar 4 '12 at 15:10\nChris, the inequalities there are strict, and these need a bit of work. A solution to your LP would likely violate the feasibility of these strict inequalities. \u2013\u00a0 Dima Pasechnik Mar 4 '12 at 15:28\nDima: you're right, of course. \u2013\u00a0 Chris Godsil Mar 4 '12 at 17:02\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nThere is a criterion for solvability of a system of strict inequalities $Mt\\lt b$ due to Carver (cf. A.Schrijver \"Theory of linear and integer programming\", Sect. 3.7.8). It says that $Mt\\lt b$ is solvable if and only if $v=0$ is the only solution of the system \\begin{equation}\\label{eee} v\\geq 0,\\ M^\\top v=0,\\ v^\\top b\\leq 0.\\qquad \\qquad (*)\\end{equation}\n\nLet us see how to get $Mt\\lt b$. To do this, let $\\zeta=\\frac{1}{2}(x,y,z,w)$, and write your linear equations as $A\\zeta=e$, where $e$ denotes all-1 vector. If this system has no solution, done. If it has only one solution, you can check it with your inequalities directly. If there are several solutions, linear algebra software will be able to rewrite your system in the form $(I\\ B)\\zeta'=d$, where $I$ is the identity matrix of size 1, 2, or 3, $B$ is a matrix of the appropriate size, and $\\zeta'$ is a permutation of the original variables $\\zeta$. In other words it gives you expressions $\\zeta'_k=d_k-\\sum_{j\\neq k} B_{kj}\\zeta'_j$, for $1\\leq k\\leq m$, and $m$ being 1, 2, or 3, depending upon $A$.\n\nThis reduces your original system to the system of strict inequalities in the remaining unexpressed $\\zeta'$. (i.e. in $4-m$ variables).\n\nFinally, apply Carver's criterion by solving a linear programming problem: $\\max\\sum_{i} v_i$ subject to $(*)$. If this maximum is strictly bigger than 0 then the original system $Mt\\lt b$ has no solution, otherwise it does have one.\n\nshare|improve this answer\nadd comment\n\nTo simplify the notation, let $A$ be the coefficient matrix in a given instance of your problem, let $\\xi = ((x,y,z,w)^T)/2$, and let $O = (0,0,0,0)^T$, $e = (1,1,1,1,...)^T$, $e_4 = (1,1,1,1)^T$. The problem then can be written in shorthand as $$ A \\xi = e, O < \\xi < e_4 $$ where $O < \\xi < e_4$ is understood component wise.\n\nTo check if there is a feasible solution, proceed in two steps:\n\n  1. Check if there is a feasible solution of the linear system $A \\xi = e$. If there is one, it can be found as $\\xi = (A^TA)A^Te$ and therefore $A(A^TA)^{-1}A^Te = e$ must hold. In practice, compute the $QR$ decomposition of $A$, $A = QR$ where $R$ is square and upper triangular and $Q$ has the same dimensions as $A$ and satisfies $Q^TQ = I$ (identity matrix) and look at the system $R \\xi = Q^T e$. If $R$ has full rank, you can find $\\xi$ and compare $A \\xi $ to $e$. If $R$ does not have full rank (i.e. there are zero rows at the bottom), this also tells you if there is a solution.\n\n  2. Suppose now there is a nontrivial solution of $A \\xi = e$. Then choose a small number $\\epsilon$, e.g. $\\epsilon = 10^{-8}$, and solve the linear program $$ A \\xi = e, \\epsilon e_4 \\le \\xi \\le (1 - \\epsilon) e_4, c^T \\xi \\to \\max $$ with any vector $c$. If there is a feasible solution to the full problem, it will show up as the optimum (and some of its components may be equal to $\\epsilon$ or $1 - \\epsilon$). By varying $\\epsilon$ for these problems, you may be able to find solutions which are further in the interior of the four-dimensional cube in which your solution is supposed to be.\n\nThe entire method should be easily implementable in e.g. R (package lpSolve) and it is obvious how to parallelize it.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/24637/p-adic-numbers-and-binomial-coefficients\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\alpha\\in \\mathbb{Z}_p$ be an $p$-adic integer and define for $n\\in \\mathbb{Z}_{\\geq 0}$ $${\\alpha\\choose n} := \\frac{\\alpha(\\alpha-1)\\cdot\\ldots\\cdot(\\alpha-n+1)}{n!}.$$\n\nThis is again a $p$-adic integer, and we can define $$\\alpha_1:=\\sum_{n=0}^\\infty \\overline{{\\alpha \\choose n}} p^n$$ and $$\\alpha_2:=\\sum_{n=0}^\\infty \\overline{{\\alpha \\choose p^n}} p^n,$$\n\nwhere $\\overline{(\\cdot)}$ means reduction modulo $p$. How are $\\alpha,\\alpha_1,\\alpha_2$ related? Are there formulas expressing this relation?\n\nThanks a lot!\n\nEdit: Some thinking led me to the following conclusion: Using continuity of $x\\mapsto {x\\choose p^n}$ as a function $\\mathbb{Z}_p\\rightarrow \\mathbb{Q}_p$ and Lucas' Theorem it follows that $\\alpha=\\alpha_2$. Does this seem correct?\n\nshare|improve this question\nIt is not very clear to me what you mean by \"reduction modulo $p$\". Classes mod $p$ live in the finite field ${\\Bbb F}_p$ and the sums $\\alpha_1$ and $\\alpha_2$ wouldn't make much sense there. Are you saying that you are taking some fixed representants of the classes mod $p$ such as $\\{0,1,\\ldots,p-1\\}$ ? \u2013\u00a0 Andrea Mori Mar 2 '11 at 16:39\nOh, yes, the unique nonnegative representative $<p$. \u2013\u00a0 user7698 Mar 2 '11 at 17:55\nYou can determine whether $p$ divides $\\binom{m+n}{n}$ by seeing whether there are any carries when adding $m$ and $n$ in base $p$. $\\binom{\\alpha}{p^n}$ is particularly simple, since $p^n$ in base $p$ is very easy. \u2013\u00a0 Arturo Magidin Mar 2 '11 at 20:30\nadd comment\n\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/152911/showing-sin1-x-is-not-a-rectifiable-curve\nText:\nTake the 2-minute tour \u00d7\n\nIntuitively it looks like near $0$, $\\sin(1/x)$ oscillates wildly so that two points will be very far apart, but how can I properly formulate this?\n\nshare|improve this question\nProbably it is intuitively obvious, and we can leave it at that! But if you want to be more formal, look at the arclength from $0$ to $1$. Set up the integral and show it does not converge. Or even more properly, look at arclength from $\\epsilon>0$ to $1$, and show it blows up as $\\epsilon$ approaches $0$. So we calculate $\\sqrt{1+(f'(x))^2}$. You will see this is real big near $0$. \u2013\u00a0 Andr\u00e9 Nicolas Jun 2 '12 at 15:50\nHint: Remember that the supremum is taken over all partitions of an interval, and notice that as $x$ approaches 0, the function will go from +1 to -1 and back an unbounded number of times, so the supremum must also be unbounded. \u2013\u00a0 Old John Jun 2 '12 at 15:51\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $x_n = \\frac{1}{\\pi(\\frac{1}{2}+n)}$, $n=0,1,...$. Note that $\\sin x_n = (-1)^n$. Note that $x_n$ monotonically decreases to $0$.\n\nConsider the function on the interval $[x_n,x_0]$, using the partition $t_k = x_{n-k}$. Then the variation is exactly $2n$. Hence the variation is unbounded on the interval $(0,1)$ (or any open interval with $0$ as the left most point).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262199/relating-the-genus-of-a-curve-to-its-degree-via-n-canonical-embedding\nText:\nTake the 2-minute tour \u00d7\n\nLet $n\\geq 3$ be an integer. If we embed a connected curve $C$ (e.g. a stable curve) of genus $g$ in $\\mathbb P^N$ by an $n$-canonical embedding, i.e. using the very ample linear system $|nK_C|$, we have that $N=(2n-1)(g-1)-1$. This is clear. But I do not see how to deduce that the degree of $C$ is $2n(g-1)$. This is equivalent to the assertion \\begin{equation} g+\\deg C=N, \\end{equation} which I am not able to justify. Does anyone have any hint? Is it possible to use some adjunction formula argument even if we are not in the plane case?\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nThe degree of $C$ in $\\mathbb P^N$ is the intersection number of a hyperplane with $C$, or equivalently, the degree (as divisor on $C$) of the restriction of a hyperplane to $C$. In terms of invertible sheaf, a hyperplane corresponds to $O_{\\mathbb P^N}(1)$ and its restriction to $C$ is, by construction, $nK_C$. So the degree of $C$ in $\\mathbb P^N$ is just the degree on $C$ of $nK_C$, which is $n(2g-2)=2n(g-1)$ by Riemann-Roch.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/570088/prove-that-if-f-is-continuous-at-0-it-is-continuous-on-mathbbr\nText:\nTake the 2-minute tour \u00d7\n\nLong story short, the question I'm stuck on is as follows:\n\nLet $f$ be a positive-definite function. Prove that if $f$ is continuous at $0$, then it is continuous everywhere.\n\nHere's the long version:\n\nWe say that a function $f:\\mathbb{R}\\to \\mathbb{C}$ is positive definite if the matrix $A_f[\\{t_1,t_2,\\dots,t_n\\}]$, whose entries are given by $$ A_f[\\{t_1,t_2,\\dots,t_n\\}]=[f(t_i-t_j)]_{i,j=1}^n $$ Is positive semidefinite for all choices of $t_1,\\dots,t_n \\in \\mathbb{R}$. In the whole problem, we are meant to show that $f$ has the following properties:\n\n  \u2022 $f(-t) = \\overline{f(t)}$\n  \u2022 $f(0) \\in \\mathbb{R}$ and $f(0) \\geq 0$\n  \u2022 $|f(t)|\\leq f(0)$ for all $t \\in \\mathbb{R}$\n  \u2022 if $f$ is continuous at $0$, then it is continuous everywhere\n\nThe first three parts may all be solved by considering the $2\\times 2$ matrix $A_f[0,t]$ where $t\\in \\mathbb{R}$ is arbitrary. Because $A_f[0,t]$ is Hermitian, the first statement holds. Because $A_f[0,t]$ must have non-negative trace, we conclude that the second statement holds. Becuase $A_f[0,t]$ has a non-negative determinant, we conclude that the third statement holds. That fourth statement, however, has me stumped.\n\nAs far as I can tell, there is no more insight to be gleaned from $2\\times 2$ matrices. Presumably, I need to find an upper bound for $|f(t) - f(t+\\delta)|$ given that $|f(\\delta) - f(0)|$ can be made arbitrarily small. I've noticed that $\\det A_f[0,t,t+\\delta]$ can be finagled into something like $f(0)|f(t) - f(t+\\delta)|^2$. However, it's not clear to me how I would use this to the desired ends.\n\nThere's also a good chance that I've managed to think myself into a hole, given that this one small part of one problem has given me more trouble than the rest of the assignment. The question claims that this problem can be solved using the fact that a semi-definite matrix has a non-negative trace and determinant, and that all principal submatrices have a non-negative determinant.\n\nI think that just about covers it. If you've made it this far, thank you for your time; I tried not to make this a wall of text. Any helpful nudges in the right direction would be very much appreciated; an attempt at an answer doubly so.\n\nshare|improve this question\nHaving finally typed out this question, I wondered if there was a hint for this problem in the back of the book. There was. It turns out I'm on the right track now that I am (finally) considering $3\\times 3$ matrices (the hint is simply \"consider the $n=3$ case.\"). Things are looking much more hopeful now, but I don't feel like the solution is quite at hand. At any rate, I plan to sleep on it. All input is, however, still (and always) welcome. \u2013\u00a0 Omnomnomnom Nov 17 '13 at 6:38\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nHint: The matrix $$ A=\\pmatrix{ f(0) &f(-t) &f(-t-h)\\\\ f(t) &f(0) &f(-h)\\\\ f(t+h) &f(h) &f(0)} $$ is congruent to $$ B=\\pmatrix{ f(0) &f(-t) &f(-t-h)-f(-t)\\\\ f(t) &f(0) &f(-h)-f(0)\\\\ f(t+h)-f(t) &f(h)-f(0) &2f(0)-f(h)-f(-h)}. $$ Now consider the $2\\times2$ submatrix taken from the entries at the four corners of $B$.\n\nshare|improve this answer\nBrilliant idea to use a congruent matrix! I know it's an elegant solution because I can't help but feeling stupid for not having thought of it myself (I had considered matrix similarity, which can be used to the same effect, but had only considered it in the $2\\times 2$ case, and not quite with this end in mind). This will definitely go into my bag of tricks. Thank you. \u2013\u00a0 Omnomnomnom Nov 17 '13 at 14:56\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56582.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nProbability Distribution\n\nDate: 12/22/97 at 19:15:33\nFrom: Smith, Cassandra\nSubject: Probability distribution\n\nI have written to you before with much success. I am once again\nstumped. I have tried several times to answer this question and even\nthough the answers are available to me, I am unable to solve it.\n\nA county containing a large number of rural homes is thought to have \n60% of those homes insured against fire. Four homeowners are chosen \nat random and x are found to be insured against fire. Find the\nprobability distribution for x. What is the probability that at least \n3 of the 4 are insured?\n\nI am able to find p(0) = 0.0256  and the p(4) = 0.1296\nThe answers to p(1) = 0.1536   p(2) = 0.3456  p(3) = 0.3456\nProbability of 3 out of 4 = 0.4572\n\nI have tried to work towards these answers without any success.  \nPlease show me how to solve this problem.  \n\nThank you.\n\nDate: 01/28/98 at 13:54:14\nFrom: Doctor Sonya\nSubject: Re: Probability distribution\n\nWhat you have described is known as a Bernoulli trial.  \n\nYou use a Bernoulli trial when you want to know the number of \nsuccesses in n trials. For example, if I have a probablity of 0.34 of \nwinning a game, I could use Bernoulli trials to tell me my probability \nof winning three out of five.\n\n\"What does this have to do with insurance?\" you may ask. Well, if my \ngame is picking a house, and I win that game if the house is insured, \nwe can use Bernoulli trials to find the probability of \"winning\" 0, 1, \n2, 3, or 4 times. This is also the probability that 0, 1, 2, 3, or 4 \nof the houses are insured.\nOne thing that has to be true about our game before we can use \nBernoulli trials is that each play must be independent. This means \nthat one house having insurance has nothing to do with its neighbor \nalso having insurance.\n\nI'm sure there's a chapter about Bernoulli trials in your textbook if \nyou want more information. \n\nLet's say I have n trials (or n plays of a game), with a probability p \nfor success. Then the probability that I will win EXACTLY k of these \nn trials is given by\n\n  P(X = k) = (n choose k) * (p^k) * (1 - p)^(n-k)\n\nSo for our problem, if n = 4, and k = 3, and p = .6 we have\n\n  P(X = 3) = (4 choose 3) * (.6^3) * (.4)^1\n           = (4) * (.6^3) * .4\n           = (4) * (.216) * .4\n           = .3456\n\nHowever, this isn't all.  Your problem asked for the probability of \n\"at least 3\" being insured. So if 4 of the 4 get insurance, then the \nproblem is also solved. \n\nI'll let you use the Bernoulli trials for P(X=4). (Remember that k=4.)\n\nThus the probability that at least 3 of the four houses are insured \n\n  P(X=4) + P(X=3) \n\nand you'll see that these are the answers you're looking for.\n\nGood luck, and don't hesitate to write back with more questions.\n\n-Doctor Sonya,  The Math Forum\nAssociated Topics:\nHigh School Probability\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/309536/quaternions-torque-and-impulse\nText:\nTake the 2-minute tour \u00d7\n\nIn a physics simulation I have a solid ball of mass $m$ and moment of interia $M$ (which is a diagonal matrix with all entries equal to ${2\\over5}mr^2=i$). Its instantaneous rotation is given by a quaternion $q$.\n\nThis body is touching another rotating body which applys a force $f$ at a point $p$ measured from the centre of the ball. $f$ resolves into a push into the radius (which we can disregard here) and a tangential torque $f^T$.\n\nThe simulation advances in a time step of $t$ seconds. How should I update $q$?\n\nI have a basic understanding of quaternions but not enough familiarity to approach this. Computational efficiency matters so I'd like to avoid converting $q$ into a matrix and back again. I imagine that $f^T$ and $p$ combine to some kind of \"impulse\" rotation $r_t$ so I can just do $q \\to qr_t$. Is this at all the right way to do it?\n\nshare|improve this question\n\n1 Answer 1\n\nI don't know the term \"instantaneous rotation\", so I don't know whether you mean the instantaneous orientation or the instantaneous angular momentum or angular velocity; whichever one you mean, the other one seems to be missing from your state description. I also don't know what to make of a force resolving into a push and a torque, since a torque doesn't have the same dimensions as a force. Further it's unclear to me what you mean by \"$f^T$ and $p$ combine\", since $f^T$ is a force or a torque and $p$ is a point. I'll restate the problem in a form and notation that I understand, and I hope you'll be able to map that onto what you're doing.\n\nThe orientation of the body at time $t$ can be described by a quaternion $s(t)$ corresponding to the rotation required to get to that orientation from some reference orientation. Its rotational state can be described by either its angular momentum $L$ or its angular velocity $\\omega$; since the body is symmetric and its moment of inertia $I=\\frac25mr^2$ is a scalar, these two are proportional to each other, $L=I\\omega$. The angular velocity can be regarded as an element of the Lie algebra of the quaternions, specified by a three-dimensional vector whose direction is the instantaneous axis of rotation and whose magnitude is the instantaneous angular speed. The body's orientation evolves according to $\\dot s(t)=\\Omega(t)s(t)$, where the dot denotes differentiation with respect to the time $t$ and $\\Omega(t)=(0,\\omega(t))$ is the purely imaginary quaternion corresponding to the angular velocity $\\omega(t)$. In the absence of torques, the angular velocity is constant and the motion can be integrated to $s(t)=\\exp(\\omega t)s(0)$, where $\\exp$ is the exponential map from the Lie algebra to the quaternions,\n\n$$\\exp(x)=\\left(\\cos|x|,\\sin|x|\\frac x{|x|}\\right)\\;.$$\n\nA torque is by definition a rate of change of the angular momentum. A force $F$ acting at a point $p$ exerts a torque $\\tau=r\\times F$ on the ball, where $r$ is the vector from the ball's centre to $p$. This causes the angular momentum to change according to $\\dot L=\\tau$, so the angular velocity changes according to $\\dot\\omega=\\tau/I$. Section $3$ of this paper gives what might be called a closed form for the resulting motion, but it's rather complicated and I gather you want to approximate the motion in finite time steps $\\Delta t$. Since $\\omega$ changes linearly, its update is exactly given by $\\omega(t+\\Delta t)=\\omega(t)+\\Delta t\\tau/I$. To update the orientation $s$, you could take the average angular velocity $\\bar\\omega=\\omega(t+\\Delta t/2)=\\omega(t)+\\Delta t\\tau/(2I)$ during the time step and update $s$ according to $s(t+\\Delta t)\\approx\\exp(\\bar\\omega\\Delta t)s(t)$. If you want, you can also approximate the exponential map by\n\n$$ \\exp(x)\\approx\\left(\\sqrt{1-|x|^2},x\\right) $$\n\nfor small time steps.\n\nI hope you can translate that into how you're thinking about the problem; if not, feel free to ask.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/168965/calculating-taylor-polynomials-for-a-function-in-mathbbr3?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nHello how does one apply the Taylor polynomials in a function of three variables?\n\nIf we consider the function $f: \\mathbb{R}^3$ to $\\mathbb{R}$ with $(x_1, x_2, x_3)$ mapped to $\\sin(x^2_1) + \\exp(x_2) + \\cos(x_1x_3)$.\n\nHow can one calculate the Taylor polynomials of order one, two and three evaluated at the point $x = 0$?\n\nCan someone please give me an idea as to how one tackles it.\n\nshare|improve this question\n\n1 Answer 1\n\nComputationally simplest is using the known Taylor expansions of the functions $\\sin$, $\\exp$, and $\\cos$. This would give $$\\eqalign{\\sin(x_1^2)&=x_1^2-{1\\over6}x_1^6 +{1\\over120}x_1^{10}-\\ldots\\ ,\\cr \\exp(x_2)&=1+x_2+{1\\over 2}x_2^2+{1\\over 6}x_2^3 +\\ldots\\ ,\\cr \\cos(x_1x_3)&=1-{1\\over2}x_1^2x_3^2 +{1\\over24}x_1^4x_3^4 -\\ldots\\ .\\cr}$$ Now collect all terms up to the desired order. E.g., the third order taylor expansion of $f$ at ${\\bf 0}=(0,0,0)$ is given by $$f(x_1,x_2,x_3)=2+x_2+x_1^2+{1\\over2}x_2^2+{1\\over6}x_2^3+ R_3({\\bf x})\\ ,$$ where the remainder term is $o(|{\\bf x}|^3)$ when ${\\bf x}\\to{\\bf 0}$.\n\nOf course there is also a general procedure for the Taylor expansion in several variables. When $f:{\\mathbb R}^n\\to{\\mathbb R}$ is sufficiently smooth then at any point ${\\bf p}$ it has differentials of order $0$, $1$, $2$, $3$, etc.. The differential of order $r$ at ${\\bf p}$, denoted by $d^r f({\\bf p})$, is a homogeneous polynomial in the auxiliary variable ${\\bf X}=(X_1, \\ldots, X_n)$ and is given by $$d^r f({\\bf p}).{\\bf X}=\\sum_{k_1,\\ldots, k_r} f_{.k_1\\ldots k_r}({\\bf p}) X_{k_1}\\cdot\\ldots\\cdot X_{k_r}\\ .$$ Here the summation variables $k_j$ run independently from $1$ to $n$, so formally there are $n^r$ terms in this sum. The zeroth differential is just the constant function with value $f({\\bf p)}$, and $d^1f({\\bf p}).{\\bf X}=f_{.1}X_1+\\ldots+f_{.n}X_n$ (the $f_{.k}$ evaluated at ${\\bf p}$) is the usual \"differential\" of $f$ at ${\\bf p}$.\n\nThe Taylor expansion of $f$ at ${\\bf p}$ can then be written as $$f({\\bf p}+{\\bf X})=\\sum_{r=0}^N{1\\over r!}d^r f({\\bf p}).{\\bf X} + R_N$$ where $R_N$ denotes the remainder term. The Taylor theorem says, e.g., that $R_N=o(|{\\bf X}|^N)$ when ${\\bf X}\\to{\\bf 0}$.\n\nWhen ${\\bf p}={\\bf 0}$ we can replace ${\\bf X}=(X_1,\\ldots ,X_n)$ by ${\\bf x}=(x_1,\\ldots,x_n)$ and simply write $f({\\bf x})=\\sum_{r=0}^N\\ldots + R_N$.\n\nshare|improve this answer\nConsidering the first method, for 1, 2 and 3, we get x2, (x1)^2, (1/6)(x2)^3 respectively. So in this question, why have we been given the third term (i.e., cos(x1.x3)? \u2013\u00a0 carla Jul 10 '12 at 10:31\nI mean, we get the polynomials of order 1, 2 and 3 as 2 + x2,, 2 + x2 + (x1)^2, 2 + x2 + (x1)^2 +(1/6)(x2)^3. So how does the third term help? \u2013\u00a0 carla Jul 10 '12 at 10:47\n@carla: The third term in $f$ is given for whatever reason. In the third order Taylor polynomial of $f$ at ${\\bf 0}$ it only contributes $1$ to the constant term but nothing further. \u2013\u00a0 Christian Blatter Jul 10 '12 at 11:30\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/14094/if-a-kerr-newman-black-hole-is-like-a-charged-spinning-heavy-magnet-what-kind/14098\nText:\nTell me more \u00d7\n\nI was reading up on De Sitter spaces, which states that the gravitational effects from a black hole is indistinguishable from any other spherically symmetric mass distribution. This makes a lot of sense to me.\n\nI'm now super curious, can we just formulate all the properties of a black hole beyond the limit at which GR is needed in a completely Maxwellian / Newtonian sense? The Wikipedia article on the Kerr-Newman metric seems to indicate so, but the equations are in terms of the GR metrics. This is not what I want, I want a simplification, a limit-case of that math.\n\nTed Bunn answered a part of my question in Detection of the Electric Charge of a Black Hole. Let me repeat the stupidly simple form of the gravitational and electric field for a black hole beyond the point at which GR is needed.\n\n$$\\vec{g} = \\frac{GM}{r^2} \\hat{r}$$\n\n$$\\vec{E} = \\frac{Q}{4\\pi\\epsilon_0 r^2} \\hat{r}$$\n\nCorrect me if I'm wrong, but these would be a meaningful and accurate approximation in many, in fact, most situations where we would plausibly interact with a black hole (if we were close enough that these are no longer representative, we'd be risking a date with eternity).\n\nQuestion: Fill in the blank; what would the magnetic field $\\vec{B}$ around a black hole be?\n\nHere is why I find it non-trivial: Every magnet in \"our\" world has some significant waist to it. So here is a normal magnet.\n\nnormal magnet\n\nWhat happens when this is a black hole? Would the approximation for $\\vec{B}$ that I'm asking for have all the magnetic field lines pass through the singularity? Or would they all pass through the event horizon radius but not necessarily a single point?\n\nI think most people who have understood this already, but ideally the answer would use the 3 fundamental metrics of a black hole. Mass $M$, charge $Q$, and angular momentum $L$. The prior equations for gravity and electric field already fit this criteria. So the answer I'm looking for should be doable in the following form.\n\n$$\\vec{B} = f \\left( M, Q, L, \\vec{r} \\right) $$\n\nshare|improve this question\nKeep in mind that rotating black holes won't have a single point singularity, but in fact will have a ring singularity, but that is a minor fact. \u2013\u00a0 Benjamin Horowitz Aug 29 '11 at 3:46\n@Benjamin ooooh, you're right! That had not occurred to me. Well that's already on the way to answering the question! \u2013\u00a0 AlanSE Aug 29 '11 at 3:53\nYou should first ask yourself what you mean by a magnetic field. Maxwell theory is inherently Lorentz invariant, and it is well known that (even just in special relativity) changing the reference frame can change the measured electric/magnetic fields.\u2026 If you fixed your coordinates in Kerr-Schild form, doesn't the Kerr-Newman article you linked to already give you an expression of the magnetic field? \u2013\u00a0 Willie Wong Aug 29 '11 at 14:46\n@Willie I believe that I can very explicitly define the reference frame in question here, which is the frame in which $\\vec{p}=0$ for the BH and at a distance from the black hole at which $GM/r \\ll c^2$. In that case, we can ditch the GR coordinates. So maybe we would be left with just the classical perfect magnetic dipole equation (which would be fine). But even IF this is the case, I don't know what the magnetic moment is since a self-gravitating loop singularity is impossible with Newtonian gravity. \u2013\u00a0 AlanSE Aug 29 '11 at 15:22\nThe answer is the same as for any other current loop with a magnetic dipole. There is nothing special about black holes. You just need the dipole moment to get the far field. The field lines end on the horizon for an external observer. \u2013\u00a0 Ron Maimon Sep 4 '11 at 2:10\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nIt's a little tricky giving a formal answer to this, but here is a sketch:. The electromagnetic potential of the Kerr-Newman hole is given by:\n\n$$A_{a}dx^{a}=-\\frac{Qr}{r^{2}+a^{2}\\cos^{2}\\theta}\\left(dt-a \\sin^{2}\\theta d\\phi\\right)$$\n\nThis field will acquire a magnetic field from the fact that $\\frac{\\partial A_{\\phi}}{\\partial r}$ and $\\frac{\\partial A_{\\phi}}{\\partial \\theta}$ are both nonzero. The problem is that the magnetic field, when re-phrased in terms of vectors and not one-forms, will fall off as $\\frac{1}{r^{3}}$. At that point, if we're keeping terms that fall off that quickly, then we need to have a discussion about that asymptotic form of the metric you imply above, because there are terms in the metric that we need to keep, arising from frame-dragging effects of the black hole. If you want, I can go into more detail.\n\n\nOK, so once we have the vector potential, we can calculate the magnetic field according to the rule: $B^{i}=\\frac{1}{\\sqrt{\\left|g\\right|}}\\epsilon^{ijk}\\left(\\frac{\\partial A_{j}}{dx^{k}}-\\frac{\\partial A_{k}}{dx^{j}}\\right)$, where $\\epsilon^{r\\theta\\phi}=1$, $\\epsilon^{ijk}=-\\epsilon^{jik}=-\\epsilon^{ikj}$ and $\\epsilon^{ijk}=0$ if $i=j$, $i=k$ or $j=k$. So, now, we just plug in the above expression for the spatial components of $A_{a}$, the metric tensor, and turn the crank.\n\nAfter doing this, and taking the limit that $r$ is larger than everything else, we find that\n\n$${\\vec B}=\\frac{2Qa\\cos\\theta}{r^{3}}{\\hat e}_{r} + \\frac{Qa \\sin \\theta}{r^{3}}{\\hat e}_{\\theta}$$\n\nSensibly, this is zero if either $Q=0$ or $a=0$. And I will once again assert that there are $\\frac{1}{r^{3}}$ corrections to the gravitational force that must be taken into account in your high $r$ limit if you are going to keep this magnetic field.\n\nshare|improve this answer\nI'm a little confused by the occurrence of $d\\phi$, since I'd imagine that the solution will have rotational symmetry about the axis of rotation, GR or not. I think that solving for the one-form of magnetic scalar potential would be sufficient, since I think $\\vec{B}$ follows directly from that unless I completely don't know what I'm talking about. But for a classical magnetic dipole, these things would fall off as $1/r^3$, although there are other terms. Right now I'm most interested to ask if there should be anything fundamentally different for a BH. \u2013\u00a0 AlanSE Aug 29 '11 at 14:57\nfall off as $\\frac{1}{r^{3}}$ though, so you would need to keep those if you are going to keep the magnetic field. \u2013\u00a0 Jerry Schirmer Aug 29 '11 at 15:27\n@Zasso: the field is axially symmetric. But unlike the case of spherical symmetry, axially symmetric vector fields can have components tangent to the circle action. Just imagine the magnetic field generated by an infinitely long wire carrying current along the $z$ axis. For the multipole moments, there is a paper by Sotiriou et al in Class. Quan. Gravitiy in 2004 that does some of these computations. (For example in regards to the Gravitomagnetic effect that Jerry mentioned.) \u2013\u00a0 Willie Wong Aug 29 '11 at 15:28\ncan you please fix the answer to put the correct falloff from the comments in? It's like any other magnet. \u2013\u00a0 Ron Maimon Sep 3 '11 at 22:40\n@Ron I know, and I thought someone would see this a an easy 50 reputation... I like how you said it \"The answer is the same as for any other current loop with a magnetic dipole. There is nothing special about black holes.\" However, that statement is novel to me, and I want to select an answer that answers the question and is written by someone with a background in this (not me). \u2013\u00a0 AlanSE Sep 4 '11 at 20:08\nshow 4 more comments\n\nI'm going to answer this question with the a priori assumption that if some amount of matter collapses with a given field, then those fields are maintained as it collapses into a black hole. I see nothing to refute this assumption, but the validity of it is beyond my knowledge. As I was pointing out before, this sufficiently far from the singularity such that GR specific concepts aren't needed. The cutoff for this is formalized by the following condition.\n\n$$GM/r \\ll c^2/2$$\n\nAgain, we have $Q$, $M$, and $L$ to describe the black hole. Obviously the black hole, and the singularity itself is some amount of mass rotating. I find this problematic due to difficulties with loop singularities in a completely Newtonian sense. Anyway, I need to make statements about the angular momentum.\n\n$$L = M a V$$\n\nThis is to say, the angular momentum is due to the fact that the mass of the singularity is located at some position away from the axis of rotation, $a$ and spinning at speed $V$. With the above statement we can make some meaningful statement about the magnetic moment, $\\vec{m}$. I'll assume the axis of rotation is the z-axis and denote that unit vector with $\\hat{k}$. The following equation comes from Wikipedia. I will then combine this with the prior equation. Doing this algebra makes the assumption that the mass has the same distribution as the charge.\n\n$$\\vec{m} = \\frac{1}{2} Q a V \\hat{k}$$\n\n$$\\vec{m} = \\frac{Q L}{2 M} \\hat{k} $$\n\nThis does make intuitive sense to me. The more angular momentum, the stronger I expect the magnetic field from it to be. Also, since angular momentum has mass as a component, we basically have to divide that back out. Next, I would just use the equation for a perfect magnetic dipole. This is to say the waist is zero, basically assuming it's a singularity. I think this would be fine unless the rotational energy was a significant part of the energy contained in it. I'll just ignore the delta function for the infinite magnetic field at the origin, because this isn't valid there anyway.\n\n$$\\vec{B}(\\vec{m}, \\vec{r}) = \\frac {\\mu_0} {4\\pi r^3} \\left(3(\\vec{m}\\cdot\\hat{r})\\hat{r}-\\vec{m}\\right)$$\n\n$$\\vec{B}(M,Q,L,\\vec{r}) = \\frac {\\mu_0 Q L} {8 \\pi r^3 M} \\left(3 \\frac{r_z}{r} \\hat{r}-\\hat{k}\\right)$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204210/cosets-of-a-perfect-code\nText:\nTell me more \u00d7\n\nI've been reading about perfect codes and working on various exercises to get a better understanding about these types of codes. I came across an interesting statement that I am having trouble showing.\n\nA coset of a linear perfect code is also a perfect code.\n\nCan anyone help? Thanks in advance!\n\nshare|improve this question\nsource and page? \u2013\u00a0 Will Jagy Sep 28 '12 at 22:57\nSPLAG says a perfect code is one for which the covering radius and the packing radius agree. Meanwhile, they say this is not related to another notion of perfection I would have known. They do say these are essentially classified, see chapter 6 of G. W. Mackey, The Theory of Error-Correcting Codes. They also refer to van Lint, Introduction to Coding Theory. Then they list the perfect codes. Pages 85-86 in the first edition. SPLAG is Sphere Packings, Lattices and Groups by Conway and Sloane, I have the first edition. \u2013\u00a0 Will Jagy Sep 28 '12 at 23:58\nthe second edition of Lattices and Codes by Wolfgang Ebeling, on page 66, deines a perfect code in a way you might like better. About five pages on this. \u2013\u00a0 Will Jagy Sep 29 '12 at 0:06\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nLet $C$ be a linear code, let $v+C$ be a coset. Given two elements $x,y$ in the coset, we have $x=v+a$, $y=v+b$ for some $a,b$ in $C$. Can you show that the distance between $x$ and $y$ is the same as the distance between $a$ and $b$? Can you see how to apply that to your question?\n\nshare|improve this answer\nIf $C$ is linear perfect code of legnth $n$ with min. distance $d$, $v + C$ a coset, and $x, y \\in v + C$. Then, $x = v + a$ and $y = v + b$ for some $a, b \\in C$. Also, $d(x, y) = wt(x - y) = wt(v + a -(v + b)) = wt(a - b) = d(a, b)$. If $M$ is the number of codewords in $C$, then $M = \\frac{q^n}{\\sum_{i=0}^{t} {n \\choose i} (q - 1)^{i}}$ ($\\ast$), where $t = \\lfloor \\frac{d-1}{2}\\rfloor$. Since the corresponding distances in $C$ and $v+C$ are the same, can I automatically say that $v + C$ satisfies ($\\ast$) since $|C| = |v+C|$? I'm not sure how to conclude that $v+C$ is perfect. \u2013\u00a0 josh Sep 29 '12 at 22:30\nIt's certainly true that $C$ and $v+C$ have the same number of elements, so $v+C$ certainly satisfies (*) if $C$ does. Are you asking whether $v+C$ has the same minimal distance as $C$? Well, you've proved all distances in $v+C$ are the same as distances in $C$, so that's not an issue. I'm not sure what more is to be said, unless you're leaving out part of the definition of a perfect code. \u2013\u00a0 Gerry Myerson Sep 30 '12 at 5:27\nOk, I think I understand how to use the distance property. The book also says that a perfect code $C$ is one for which $\\mathbb{F}_{q}^{n}$ is partitioned into disjoint spheres of radius $t$ centered about each of the codewords in $C$. Since all distances in $v + C$ are the same as distances in $C$, it would also follow that $\\mathbb{F}_{q}^{n}$ would be partitioned into disjoint spheres of radius $t$ centered about the elements ${v + c}$, where $c$ runs over all of $C$. \u2013\u00a0 josh Sep 30 '12 at 6:29\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mechanics.stackexchange.com/questions/235/how-to-diagnose-excessive-coolant-consumption\nText:\nTell me more \u00d7\n\nWhats the best way to determine the source of coolant consumption? How should one differentiate between say a leaking radiator, leaking waterpump, leaking hoses, a blown head gasket, or crack in the block/head(s)?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nFirst thing is to initially determine if you're burning it or leaking it. Assuming your car isn't spewing a plume of white smoke when you're driving - you will have to do some additional diagnosis to determine the method of consumption.\n\nFirst check the oil and coolant - if either contain a milky substance you have a cracked something or a blown HG. Possibly a failed oil cooler (if it's of the water cooled variety) Only a leakdown test can determine anything further beyond a teardown. I have heard of some cars having poor intake manifold sealing which can cause coolant to be sucked into the intake tract and burned without the telltale white smoke.\n\nIf the fluids looks okay, have the system pressure tested. Basically it's like hooking up a bicycle pump to your radiator to pressurize the system while cold. If the leak isn't obvious you can use a UV dye to pinpoint weepage or very minute leaks.\n\nshare|improve this answer\n+1 for pressure test. In theory, a pressure test can also be used with the engine running to see if there is a blown head gasket. The high combustion pressure should cause an above normal reading on the pressure gauge. I've never gotten to test this in the field though, as usually when the head gasket is that far gone, it's already smoking like crazy. \u2013\u00a0 S_Niles Mar 9 '11 at 23:23\nDon't forget to check your A/C drain when doing the pressure test. Usually if the heater core is leaking, you can smell it in the car, but it's an often overlooked source of leaks. \u2013\u00a0 S_Niles Mar 9 '11 at 23:29\nadd comment\n\nOne way would be to have the vehicle running, and look for where the leak would be coming from. You may want to top off the coolant first for best results. However, if its a slower leak, this technique may not work as well. But, you should still be able to get some indication of where the problem is occurring.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/56265/np-not-equal-to-spacen/56268\nText:\nTell me more \u00d7\n\nExercise 3.2 of Computational Complexity, a Modern Approach states:\n\nProve: NP != SPACE(n) [Hint: we don't know if either is a subset of the other.]\n\nI don't know how to solve this problem. It's in the diagonalization chapter.\n\nI've looked around google a bit, but it basically ends up linking back to the Arora/Barak book.\n\nAnyone know how to attack this?\n\n\nMore generally: to prove a language to be uncommputable, I can use diagonalization -- but to prove that two sets of languages (Space(N) and NP) are different, when it's not known that either is contained in the other -- what techniques are there for these proofs?\n\nThanks again!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 6 down vote accepted\n\nI think that a common technique for proving such statements is for example the following type:\n\nOne class shares a closure property, while the other cannot because of a hierarchy theorem. Thus they cannot be equal.\n\nIn this particular case a proof could proceed along these lines: Since NP is closed under polynomial time reductions, so would SPACE(n), if they were equal. Then deduce that polynomial time reductions would imply that SPACE(n^2) is contained in SPACE(n), which is impossible by the space hierarchy theorem.\n\nshare|improve this answer\nCould you expand on the \"closed under polynomial time reduction\" implies \"Space(n^2) contained in Space(n)\" part? [In particular, I haven't read chapter 4, so not familiar with space reductions; but I don't immediately see why a polytime TM can map all of space(n^2) into space(n)]. Thanks! \u2013\u00a0 LowerBounds Feb 22 '11 at 11:02\nSuppose you get an input string of size n which would be decided in space n^2. Now a polynomial time reduction can blow up this string to size n^2 - just adding zeros for example. This is called padding. But then there is a TM which will decide this in in linear time, since it can just skip the zeros and run the original string which takes n^2 space. But since we blew the string up to size n^2, this is linear in the new input. \u2013\u00a0 wood Feb 22 '11 at 11:10\n@wood: Awesome, thanks for the clarification! \u2013\u00a0 LowerBounds Feb 22 '11 at 18:44\nadd comment\n\nScott Aaronson has a blog post, Sidesplitting Proofs, which is a highly recommended read for a variety of reasons. The first proof in the list, which is said to be folklore, is that E, the class of problems solvable in $2^{O(n)}$ time, is not equal to PSPACE. The key is again padding: if the two are equal, then E=EXP, and we derive a contradiction. Like in your case, which is bigger (if one is even contained in the other) is not known.\n\nshare|improve this answer\n@Thierry : Nice, the blog post looks awesome! (Upvoted you; would accept your answer too for all the new techniques, but can only accept one.) \u2013\u00a0 LowerBounds Feb 22 '11 at 18:44\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.hackmath.net/en/math-problem/1271?tag_id=124_9\nText:\nDiagonals in the diamond\n\nThe length of one diagonal in diamond is 24 cm greater than the length of the second diagonal and diamond area is 50 m2. Determine the sizes of the diagonals.\n\nCorrect result:\n\nu1 = \u00a01012.07 cm\nu2 = \u00a0988.07 cm\n\n\nu2=u124\u00a0S=u1u22=u1(u124)2=50\u00a0m2=500000\u00a0cm2\u00a02S=u1224u1\u00a0u224u1000000=0\u00a0\u00a0a=1;b=24;c=1000000\u00a0D=b24ac=24241(1000000)=4000576\u00a0D>0\u00a0\u00a0u1,2=b\u00b1D2a=24\u00b140005762=24\u00b18625092\u00a0u1,2=12\u00b11000.0719974082\u00a0u1=1012.0719974082\u00a0u2=988.07199740819\u00a0\u00a0\u00a0Factored\u00a0form\u00a0of\u00a0the\u00a0equation:\u00a0\u00a0(u1012.0719974082)(u+988.07199740819)=0\u00a0\u00a0u>0\u00a0u1=1012.07\u00a0cmu_2 = u_1 - 24 \\ \\\\ S = \\dfrac{u_1 \\cdot u_2}{2 } = \\dfrac{u_1 \\cdot (u_1-24)}{2 } = 50 \\ m^2 = 500000 \\ cm^2 \\ \\\\ 2S = u_1^2-24 u_1 \\ \\\\ u^2 -24u -1000000 =0 \\ \\\\ \\ \\\\ a=1; b=-24; c=-1000000 \\ \\\\ D = b^2 - 4ac = 24^2 - 4\\cdot 1 \\cdot (-1000000) = 4000576 \\ \\\\ D>0 \\ \\\\ \\ \\\\ u_{1,2} = \\dfrac{ -b \\pm \\sqrt{ D } }{ 2a } = \\dfrac{ 24 \\pm \\sqrt{ 4000576 } }{ 2 } = \\dfrac{ 24 \\pm 8 \\sqrt{ 62509 } }{ 2 } \\ \\\\ u_{1,2} = 12 \\pm 1000.0719974082 \\ \\\\ u_{1} = 1012.0719974082 \\ \\\\ u_{2} = -988.07199740819 \\ \\\\ \\ \\\\ \\text{ Factored form of the equation: } \\ \\\\ (u -1012.0719974082) (u +988.07199740819) = 0 \\ \\\\ \\ \\\\ u>0 \\ \\\\ u_1 = 1012.07 \\ \\text{cm}\nu2=u124=988.07\u00a0cmu_2 = u_1 - 24 = 988.07 \\ \\text{cm}\n\n\nShowing 2 comments:\nMath student\nHow comes about U1 and U2\n\nDr Math\nu1, u2 = unknown diagonals.\n\n\nTips to related online calculators\nLooking for help with calculating roots of a quadratic equation?\nDo you want to convert area units?\nDo you want to convert length units?\n\n\nNext similar math problems:\n\n  \u2022 Alopecia\n    alopecia Medical literature indicates that 45% of men suffer from alopecia. For random sample of 8 men, calculate the probability that: (a) exactly four men suffer from alopecia. (b) at most two men suffer from alopecia.\n  \u2022 Assembly time\n    mean_normal The assembly time for the toy follows a normal distribution with a mean of 75 minutes and a standard deviation of 9 minutes. The company closes at 5 pm every day. If one starts assembling at 4 pm what is the probability that he will finish before the comp\n  \u2022 Pascal's law\n    lis Please calculate according to Pascal's law. Krupp's machines were known for their large size. In 1861, a blacksmith's steam hydraulic press was put into operation in Essen. What was the cross-sectional area of the larger piston if a compressive force of 1\n  \u2022 RC time constant\n    capacitor You introduced 1 Coulomb worth of electrons into the inner volume of a dielectric material with \u03f5r=6. 30 minutes later, you found that only 36.79% of the electrons were in the inner volume. Determine the conductivity \u03c3 of the dielectric material.\n  \u2022 Decibel\n    tv_1 By what percentage does the sound intensity increase if the sound intensity level increases by 1 dB?\n  \u2022 Natural fertilizer\n    garden_1 The rectangular garden measuring 120m and 60m was fertilized with 16kg of natural fertilizer. Natural fertilizer contains 45% organic matter. How much organic matter falls on 1 m2 of garden?\n  \u2022 Sphere in cone\n  \u2022 Hiking trip\n    walker Rosie went on a hiking trip. The first day she walked 18kilometers. Each day since she walked 90 percent of what she walked the day before. What is the total distance Rosie has traveled by the end of the 10th day? Round your final answer to the nearest ki\n  \u2022 2 cyclists and car\n    cyclist_1 One cyclist rides at a constant speed over a bridge. It is 100 meters long. When he is 40 meters behind him, he meets an oncoming cyclist who is riding at the same speed. The car travels along the bridge in the same direction as the first cyclist at a spe\n  \u2022 Water mixing\n    watermixing We have 520 ml of hot water and 640 ml of water at 48\u00b0C. What is the temperature of approximately hot water when the resulting mixture has a temperature of 65\u00b0C?\n  \u2022 Closed circuit\n  \u2022 Energy consumption\n    elektromer The device is connected to 230V and draws 3.5A current. Power consumption is 1932kJ. How many minutes has this device been in operation?\n  \u2022 Permille of alcohol\n    heart I have 2 per mille of alcohol in my blood. How many milliliters is it when I have 5 liters of blood?\n  \u2022 Wall thickness\n    sphere_Nickel The hollow metal ball has an outside diameter of 40 cm. Determine the wall thickness if the weight is 25 kg and the metal density is 8.45 g/cm3.\n  \u2022 What percentage\n    astronaut What percentage of the Earth\u2019s surface is seen by an astronaut from a height of h = 350 km. Take the Earth as a sphere with the radius R = 6370 km\n  \u2022 Self-oscillation period\n    lambda The water in the vessel carried by the boy has a self-oscillation period of 0.8 s. What is the size of the boy's movement speed when the length of the boy's step is 60 cm? Give the result in m/s.\n  \u2022 Power line pole\n    pole From point A, the power line pole is seen at an angle of 18 degrees. From point B to which we get when going from point A 30m away from the column at an angle of 10 degrees. Find the height of the power pole."}
{"text": "Retrieved from https://robotics.stackexchange.com/questions/16759/jacobian-of-a-6dof-arm\nText:\nI have a robot with 6 DOF. I read a lot of tutorial on how to compute the Jacobian, but usually all examples are for planar robots with 2DOF.\n\nI don't understand how can I get the Jacobian of a 6 DOF robot.\n\nI know that Torque = J_transpose * Force.\n\nI want to compute the force of my end effector when I apply some torque. For this reason I need the Jacobian.\n\nThank you very much\n\n\nWrite the forward kinematic equations $$\\vec(x) = F\\vec(\\theta)$$\n\nTaking the partial derivatives of each $\\vec (x)$ term with respect to each joint variable $\\vec(\\theta)$ will give you $J$.\n\n  \u2022 $\\begingroup$ Typically F(.) has a value in SE(3) so there are 12 partial derivatives (actually 16 but the bottom row are all zero since the elements are constant). Nine of those partial derivatives, the rotation part $\\dot{R}$ are related to the angular velocity, 3 elements, via Rdot = [omega]_x R. [Pity no math notation allowed in comments] $\\endgroup$ \u2013\u00a0Peter Corke Dec 30 '18 at 2:45\n\nBy taking the time derivative of the forward kinematics equation, you get a Jacobian equation, as @steveo said in his answer. What is interesting is that by using some properties of rotation matrices, we can derive a rather impressive formula for computing a Jacobian.\n\nIn short, a Jacobian can be computed as\n\n$$J = \\begin{bmatrix}J_1 & J_2 & \\cdots J_n\\end{bmatrix},$$\n\n\n$$J_i = \\begin{cases} \\begin{bmatrix}z_{i - 1}\\\\0_{3\\times1}\\end{bmatrix} & \\text{the $i^\\text{th}$ joint is revolute}\\\\ \\begin{bmatrix}z_{i - 1} \\times (o_n - o_{i - 1})\\\\z_{i - 1}\\end{bmatrix} & \\text{the $i^\\text{th}$ joint is prismatic (linear)} \\end{cases},$$ $z_i$ is the axis of the $i^\\text{th}$ joint and $o_i$ is the origin of the $i^\\text{th}$ frame.\n\nNote that a Jacobian matrix $J$ is actually a function of a joint value $q$. (We can also see this from the above equation as the joint position $o_i$ and the joint orientation $z_i$ change when the robot changes joint values.) For 6-DOF robots, although it is very unlikely that you will be able to obtain a closed form formula for $J(q)$, computing $J$ for a given $q$ is pretty straightforward.\n\nFor more details, see Chapter 5 of Robots Dynamics and Control (Spong et al.).\n\n  \u2022 $\\begingroup$ Please note that, in contrary to @SteveO `s answer this method only works if the DH Convention was used to for defining the coordinate systems. Also, if it is a serial manipulator the Jacobi will have a closed form expression. $\\endgroup$ \u2013\u00a050k4 Nov 28 '18 at 15:06\n  \u2022 $\\begingroup$ @50k4 Interesting points. Thanks a lot. $\\endgroup$ \u2013\u00a0Petch Puttichai Nov 28 '18 at 15:11\n  \u2022 $\\begingroup$ @50k4 By the way, could you help elaborate a bit more why the above formulation breaks when a convention other than DH convention is used? $\\endgroup$ \u2013\u00a0Petch Puttichai Nov 28 '18 at 15:25\n  \u2022 2\n    $\\begingroup$ you are using z-axis coordinates. if the motor axis is not the z axis, multiplying it with the axis velocity returns nonsence. The motor axis is z-axis only because DH says so... $\\endgroup$ \u2013\u00a050k4 Nov 28 '18 at 15:28\n  \u2022 $\\begingroup$ Thank you for your clarifications. I am using DH convention. I found libraries to compute the Jacobian but I want to understand and do it by myself. $\\endgroup$ \u2013\u00a0user3018940 Nov 29 '18 at 4:19\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/88180/how-to-determine-the-maximum-valued-play-in-rummikub/128553\nText:\nThis question is meant as a follow-up this question and my answer here.\n\nThe question asked multiple questions about algorithms for playing Rummikub and my answer provided an algorithm that, given a set of Rummikub pieces $S$, determines whether they can be arranged as a set of valid plays (called an arrangement).\n\nHowever, when we actually play Rummikub, the situation is slightly different: there is a given board state $B$ and a hand $H$. We want to empty our hand by adding pieces to the board. We assume the board $B$ has a valid arrangement.\n\nSo, the problem now becomes:\n\n  1. Does there exists a subcollection $S\\subseteq H$ such that there exists a valid arrangement for $S \\cup B$; and\n  2. What is the largest such subcollection $S$ ?\n\nObviously, we can iterate over every subcollection $S$ of $H$ and test validity for each of them, but that is inefficient. To make precise what I mean by 'efficient' here, consider the game to be played with $3,4$ or $5$ colours and the numbers $1\\ldots n$ for each color.\n\nDoes there exist an polynomial (in $n$) time algorithm that solves problem 1 or 2? Or this 1 or 2 intractable (e.g. NP-hard)? Feel free ignore complications such as jokers or assume all tiles are distinct.\n\n\nI will describe a polynomial time algorithm that solves both problem 1 and problem 2. I learned of the algorithm from this paper.\n\nI am going to make the following assumptions:\n\n  1. No jokers (adding them is a small change).\n  2. There are only four colors.\n  3. There are at most two copies of each tile.\n  4. The face values range from 1 to 13.\n\nTo find the maximum value play, complete these steps:\n\n  1. Recursively enumerate every valid configuration that can be built from tiles in $hand \\cup board$\n  2. Ignore any configuration where not all tiles from board are used (the board constraint).\n  3. Of the visited configurations, choose one with maximal score. Where score is the sum of values of tiles played or number of tiles played (whichever you prefer to maximize).\n\nStep 1\n\nHow do we build a configuration from a given set of tiles? We proceed by playing tiles in order of their face value. First play all tiles of value 1. Then play all tiles of value 2, and so on. We can visit every configuration by recursing for each way to play tiles of the current value.\n\nLet's look at the different ways to form runs. Assume we are playing tiles of value 5, that we have a red 5, and that we will use it in a run. Our tile can be used to start a new run or it can be used to extend any existing run (or partial run) that contains a red 4. If we extend an existing run then there is at most two choices for where to put it since there is at most two runs that contain a red 4 (there are at most two red 4's). If we have two copies of our tile then we can extend or start two runs.\n\nIn forming runs there is an optimization that can be made. We should not start a new run if we know in advance that there is no way we could finish the run. This can be implemented by counting the number of tiles of greater value.\n\nNow on to forming groups. For a given way to play runs we should recurse for every way to play groups using the remaining tiles since we want to enumerate all possible valid configurations. However this would be very slow and in the end we really only care about finding the best configuration. So instead we recurse for only the best way to play groups. Notice, for a given choice of how to form runs, how we form groups does not effect what choices we have in forming groups and runs using tiles of greater value. So given a choice of how to form runs, we should use as many of the remaining tiles in groups as possible. To do this enumerate all ways to pick groups and choose the one containing the most tiles.\n\nFinally after choosing how to play all tiles, discard any tile not used in a valid set.\n\nStep 2\n\nHow do we ensure every valid configuration we visit uses all tiles from board? After choosing how to play all tiles and discarding invalid sets, do not accept the configuration as valid if not all tiles from board are contained in it. This is correct but it would be inefficient. Instead we check at each step, after choosing how to form runs and groups, whether we have used enough tiles of the current value. For example, if the current value is 5 and we have chosen a way to play the red 5's, then we need to check if we have played at least as many red 5's as are contained in board. If we have not, then we choose another way to play red 5's before moving to the next value. Note if we have played $n+m$ red 5's where $n$ is the number of red 5's in board, then we have played $m$ red 5's from our hand. If there is no way to play red 5's (including not playing red 5's) then this branch of the recursion tree does not lead to a valid configuration and we should return.\n\nHowever, these checks are not sufficient to guarantee we never violate the board constraint. Why? Because when forming runs using tiles of value 6 we can choose to not extend a run that has length one or two. The tiles in that run would have to be discarded which could violate the board constraint due to not having enough 4's or 5's. In this case we would not be able to catch this error because so far we only know how to check the board constraint for the current value. The way to fix this is to keep count of how many tiles we have played of the previous two values (for each color separately). Then when forming runs with red 6's we can check if not extending a red run (of length one or two) puts us in a state where not enough red 4's or 5's have been played. Note that if a run has length at least three then not extending it does not force us to discard any tiles and so can not violate the board constraint (so we do not have to check in this case).\n\nWe do not have to do anything special for choosing groups. In the following proof of this fact I will use 'configuration' to mean a set of groups. Also, I will use 'maximal configuration' to mean a configuration containing the most tiles possible among all configurations where tiles come from some set $S$. Note that if we have $n$ tiles of color $c$ in a configuration then there are at least $n$ groups in the configuration. Also if a subset of the available tiles can be arranged into a configuration of $n$ groups then a maximal configuration contains at least $n$ groups (there are at most three groups, if using two jokers, and at most two groups of four in any configuration). Now assume a subset $S$ of the available tiles can be arranged into a configuration with $n$ tiles of color $c$ and that we have arranged some maximal configuration $M$. If $M$ contains $k < n$ tiles of color $c$ then $M$ contains at least $n - k$ groups which do not contain a tile of color $c$ (groups of size three). In this case we can add $n-k$ tiles of color $c$ from $S$ to $n-k$ groups of three in $M$ which contradicts that $M$ is a maximal configuration. Thus $k\\geq n$. This shows that if there are $n$ tiles of color $c$ in the set of tiles of current value that remain after playing runs and if those $n$ tiles can be played in some configuration then every maximal configuration contains those $n$ tiles. So choosing a maximal group guarantees that we satisfy the board constraint if it is possible to satisfy the board constraint by playing groups.\n\nStep 3\n\nA simple way to do step 3 would be to compute the score of a configuration when you accept it as valid then update some global variable with the configuration of max score ('configuration' meaning set of runs & groups). But this solves the same subproblem many times (compute score for sets common to more than one valid configuration). Instead make use of the fact that we know at each step how many tiles of the current value we will play. Multiply this number of tiles by the current value to find how much these choices contribute to the score. Sum the contribution with the return value of the recursive call and then update the max if necessary. Instead of updating a global max variable, we will update a local (available only in scope of recursive call) max variable which will hold the score of the best way to play tiles of the current value. The recursive function should return the value of this max variable. After attempting to play tiles of current value in all ways, if no play leads to a valid configuration (every play violates the board constraint), then return $-\\infty$. Returning $-\\infty$ is useful because even if we have a high contribution (from runs & groups), adding that contribution to $-\\infty$ is still $-\\infty$.\n\nNote that we cannot know the contribution of extending a length zero or length one run. This is because, when playing tiles of the next greater value, we may choose to not extend a run of length one or two and so the tiles in those runs would be discarded. Instead we say the contribution of extending a length zero run (starting a run) or length one run is 0. When a run is extended from length two to length three then we say it's contribution is the sum of the values of the three tiles in the run. When extending a run that has length at least three then the contribution is just the value of the tile played into the run.\n\nThere are other things you can do here too. For example, It may be desireable to find a configuration that is maximally similar to the previous configuration of the board. This can be done by maximizing score and then maximizing some similarity function. This would inflate the dp table size by two.\n\nState, Memoization, & Time Complexity\n\nThe only state we need to know is the current value and the length of the runs that we could possibly extend. The length of runs can be recorded in a list of pairs, for example [(0,0), (0,0), (0,1), (0,3)], where the $i^{th}$ pair is the length of the two possible runs of color $i$. The order of the numbers in the pairs does not matter so the above state is the same as [(0,0), (0,0), (1,0), (0,3)]. A particular extension (i.e. child state) of those runs could be [(1,1), (0,1), (0,0), (1,3)]. Also, we never need to know if a run is longer than three tiles (so an extension of (3,3) is (3,3)). We will only need to distinguish between when a run is of length 0, 1, 2, or 3. A benefit of this is the size of the state space is reduced which makes memoization much more effective.\n\nThis algorithm is exponential in the number of distinct values in $hand \\cup board$. However it can be made linear by memoization.\n\nTo memoize, store in a dictionary the key-value pair key=(currentTileValue, runLengthsList) and value=localMaxValue. Other inputs like the board, $hand\\cup board$, number of jokers available, number of tiles played per color on the last two turns, etc, are just used to bound the search and so we do not need to memoize them.\n\nHopefully I have been able to effectively communicate most of the ideas of this algorithm. For more details see the paper and my implementation. Note, the paper claims that the dynamic programming state space (number of unique inputs, max size of dp table needed, i think) is of size $n * k * f(m)$. Where $n$ is the number of possible tiles, $k$ is the number of colors, $m$ is the max number of copies of a tile, and $f(x)$ computes 4 choose $x$ with replacement. This might be a typo, I do not know. In any case the state space of the algorithm I've described is $n * f(m)^k$.\n\nNote both the paper and my implementation refer to what you call the board as the table.\n\nBy the way, before learning of this algorithm, I tried to understand the algorithm you gave here. I could not understand how to deal with duplicates. I can see how breaking into sublists, ordering those sublists, and then combining them into a single list again would allow your recursive formula to handle duplicates for some inputs. But you did not describe how exactly to break the original list into sublists nor how to combine them into a single list again. For some inputs, your recursive formula will give different answers depending on how sublists are split/recombined. Unfortunately, I do not have enough stackoverflow reputation to comment on your answer to ask for clarification. Thanks for giving the answer though, your recursive formula is nice.\n\n\nI did not read your long answer at the linked thread. However, you did mention proceeding in order of number and using a recursive relation. You can do the same here. Define $Q(x,k,m)$ to be true iff there is a valid grouping $G$ of $B\u222aS$ for some $S\u2286H$ such that exactly $k$ pieces in $S$ have numbers at most $m$ and $x$ is the multiset of colours of runs in $G$ that include the number $m$. Since there are a fixed number $c$ of colours, $x$ is encoded as a $c$-tuple of naturals with sum $O(n)$. Each state transition either stops or extends each of these runs (by adding an $m{+}1$), and may also form groups of $m{+}1$, such that all $m{+}1$-tiles from $B$ with number are used (either in extending runs or in forming groups), and the number of $m{+}1$-tiles used from $H$ are reflected in the change in $k$. I will leave the details as an exercise for you.\n\nAlso, there seems to be an incorrect assumption in your question, because the actual games rules do not allow arbitrary rearrangement of the played tiles. For instance, if the played tiles are the three sets 1a 1b 1c + 2a 2b 2c + 3a 3b 3c, then you cannot play 4a by rearranging the tiles to form 1a 2a 3a 4a + 1b 2b 3b + 1c 2c 3c. In other words, a solution to your question does not provide a solution to finding the maximal number of tiles that can be played given an actual game position. I did not check but I do think there is an algorithm along the same lines as above to solve that actual game-based problem.\n\n  \u2022 $\\begingroup$ This does not assume all tiles are distinct, and furthermore a slight modification can also handle any number of jokers. $\\endgroup$ \u2013\u00a0user21820 Jul 20 '20 at 16:33\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/128423/equivalence-of-horn-formulas-tractable\nText:\nAssume I have two Horn formulas $\\phi_1, \\phi_2$. Horn formulas are CNF formulas so that each clause has at most one unnegated literal. For example:\n\n$x_1 \\wedge (\\neg x_1 \\vee \\neg x_2 \\vee x_3 )\\wedge (x_3 \\vee \\neg x_4)$\n\nI want to decide whether $\\phi_1,\\phi_2$ are logically equivalent, i.e., $\\phi_1 \\leftrightarrow \\phi_2$. Equivalently, I want to test whether $F=(\\phi_1 \\vee \\neg\\phi_2)\\wedge (\\neg \\phi_1 \\vee \\phi_2)$ is true for all assignments of $x_1,\\dots,x_n$.\n\nIs this problem tractable?\n\n\nYes, you can check equivalence in polynomial time (in fact, in quadratic time).\n\nBy similar logic to my answer to your previous question, it suffices to test satisfiability of $\\phi_1 \\land \\neg c$ where $c$ ranges over the clauses of $\\phi_2$. If any of these are satisfiable, then $\\phi_1,\\phi_2$ are inequivalent. Otherwise, if they're all unsatisfiable, and the same for $\\phi_2 \\land \\neg c'$ where $c'$ ranges over all clauses of $\\phi_1$, then $\\phi_1,\\phi_2$ are equivalent.\n\nSo, let's investigate how to test satisfiability of $\\phi_1 \\land \\neg c$ where $c$ is a clause of $\\phi_2$. By assumption, $c$ is a Horn clause, so it has the form $\\neg x_1 \\lor \\dots \\lor \\neg x_k \\lor x_{k+1}$. So, $\\phi_1 \\land \\neg c$ has the form\n\n$$\\phi_1 \\land x_1 \\land \\dots \\land x_k \\land \\neg x_{k+1}.$$\n\nThis turns out to be a Horn formula, so you can its test satisfiability with the standard algorithm for testing satisfiability of Horn formula. This takes linear time per clause, and there are linearly many clauses, so the total running time is quadratic.\n\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/263262/dodgy-turing-degrees\nText:\nThis question was originally asked and bountied at MSE, but received no answer there, so I'm asking it again here.\n\nBelow, I'm specifically interested in weak truth table (wtt) reducibility, but other reducibilities between truth table and Turing are interesting to me, too, if the question happens to be easier to answer for them.\n\nLet $d$ be a Turing degree, and fix a representative $X\\in d$. Say $d$ is (wtt-)dodgy if there is some $d$-computable functional $F=\\Phi_e^{X\\oplus -}$ such that for all $Y$ with $deg(Y)=d$, we have\n\n  \u2022 $\\Phi_e^{X\\oplus Y}=F(Y)$ is total,\n\n  \u2022 $F(Y)\\equiv_TY$, but\n\n  \u2022 $F(Y)\\not\\le_{wtt}Y$.\n\n(Note that I demand nothing about $F(Z)$ for $Z\\not\\in d$; in particular, $F$ only needs to output reals when fed elements of $d$, it may fail to be total elsewhere.)\n\nDodginess is most interesting for \"sufficiently large\" degrees - for example, above $0'$ every Turing degree splits into infinitely many $wtt$-degrees, so the question is nontrivial. Dodginess is a reasonably definable property, so by Martin's Cone Theorem, either every sufficiently large degree is dodgy or every sufficiently large degree is not dodgy. My question is, Which of these two holds?\n\nMy feeling is that a fairly simple trick should show that every sufficiently large (indeed, $\\ge_T0'$) degree will not be dodgy; however, I don't see how to do this. In particular, the Recursion Theorem doesn't seem to immediately kill it: suppose $d$ is a sufficiently large degree, and fix $X\\in d$. Then $F$ can be identified with a total computable function $g$: $F(\\Phi_e^X)\\sim\\Phi_{g(e)}^X$. Now $g$ is total computable, so it has a fixed point $c$: $\\Phi_c^X\\sim \\Phi_{g(c)}^X$. However, there's no reason to believe that $\\Phi_c^X$ is total, let alone an element of $d$, so I don't see how to get any leverage here.\n\n\nEvery sufficiently large degree is dodgy. Assuming $X \\geq_T \\emptyset'$, we can define $F(Y)$ as follows. First compute a set $Z$ from $X$ and $Y$: Given $n = \\langle i,j \\rangle$, ask $X$ whether $\\Phi_i(n)$ converges. If not then $Z(n)=0$. If yes then ask $X$ whether $\\Phi_j^{Y \\upharpoonright \\Phi_i(n)}(n)$ converges. If not then $Z(n)=0$. If yes then $Z(n)=1-\\Phi_j^{Y \\upharpoonright \\Phi_i(n)}(n)$. This ensures that $Z \\nleq_{wtt} Y$. Now let $F(Y)=X \\oplus Z$. Then $F$ is total and $F(Y) \\nleq_{wtt} Y$ for all $Y$, and if $Y \\equiv_T X$ then also $F(Y) \\equiv_T Y$.\n\n  \u2022 $\\begingroup$ Thanks! Do you know of any reducibilities stronger than Turing (but, necessarily, weaker than wtt) for which the corresponding notion of dodginess might fail on a cone? $\\endgroup$ \u2013\u00a0Noah Schweber Mar 1 '17 at 21:54\n  \u2022 $\\begingroup$ No, I can't think of any. $\\endgroup$ \u2013\u00a0Denis Hirschfeldt Mar 1 '17 at 23:21\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/567929/heat-absorbed-from-a-reservoir-by-a-moving-object\nText:\nImagine two bodies, say a body A with an infinite heat capacity(reservoir) and the another body B with some finite heat capacity($C = \\alpha \\ T_{B}(t) $).\n\nThey come into direct contact with each other for a limited time, as B moves along the surface of A with a constant velocity v.\n\nGiven the thermal conductivity $\\kappa$ of the moving object B, the temperatures of the reservoir $T_{A}$ and the moving object $T_{B}(t)$.\n\nHow to calculate the amount of heat transferred in the process as a function of time?\n\n  \u2022 $\\begingroup$ What does $C \\propto \\alpha \\ T_{B}(t)$ mean precisely? What is $\\alpha$? $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 17:27\n  \u2022 $\\begingroup$ actually $\\alpha $ is just a constant that depends on the type of the material of B $\\endgroup$ \u2013\u00a0EverydayFoolish Jul 24 '20 at 20:01\n  \u2022 $\\begingroup$ In thermodynamics we normally write: $\\Delta Q=mc_p\\Delta T$: the heat absorbed (or shed) by a change of temperature of an object of mass $m$ and specific heat capacity $c_p$. $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 20:06\n  \u2022 $\\begingroup$ I made another edit. $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 22:14\n\n\nThe calculation will first of all depend on the Biot Number:\n\n\nwhere $h$ is the convective heat transfer coefficient, $\\kappa$ the thermal conductivity and $L$ a characteristic length of the object (a length or diameter, typically)\n\n  1. Low Biot Number:\n\nThe interior of the object may be considered of uniform temperature distribution (no or low temperature gradient inside the object $B$)\n\nHere lumped thermal analysis can be used by means of Newton's Law of Cooling. It states:\n\n$$\\dot{Q}=hA[T(t)-T_A]=hA\\Delta T(t)\\tag{1}$$ where:\n\n  \u2022 $\\dot{Q}$ is the rate of heat transfer out of the body ($B$)\n  \u2022 $A$ is the surface area shared by $A$ and $B$\n  \u2022 $T(t)$ the temperature of body $B$ and $T_A$ the (constant) temperature of $A$\n\nNote that due to cooling (or heating) of $B$, $\\Delta T(t)\\neq \\text{constant}$. To calculate the heat transfer in a given amount of time, the evolution of $T(t)$ has to be (and can be) calculated.\n\n$\\text{NLC}$ is mathematically simple to use.\n\nEq. $(1)$ is a separable differential equation that solves to:\n\n$$\\Delta T(t)=(T_0-T_A)e^{-kt}\\text{ where }k=\\frac{hA}{mc_p}$$\n\n($T_0$ is the initial temperature of $B$)\n\nSo with $(1)$ we get:\n\n\nThe heat transferred in a time-interval $\\Delta t$ is:\n\n$$Q=\\int_0^{\\Delta t}hA(T_0-T_A)e^{-kt}\\text{d}t$$\n\n\n$$Q=-mc_p(T_0-T_A) e^{-k\\Delta t}$$\n\n  1. High Biot Number:\n\nHere significant temperature gradients in the body $B$ must be assumed and heat conduction will play a significant part in the heat transfer process.\n\nThe 'go to' equation here is Fourier's Heat Equation:\n\n$$\\frac{\\partial T}{\\partial t}=\\alpha \\nabla^2T\\text{ with }\\alpha=\\frac{\\kappa}{c_p\\rho}$$\n\nwhich is a partial differential equation (PDE) and will require boundary conditions and an initial condition. From the obtained spatial distribution of temperature can then be calculated the heat transferred in a given time-interval.\n\nIn many cases solving Fourier's equation is mathematically very demanding, requiring higher calculus. Analytical solutions are really only possible for simple geometries (rod, plate, sphere for instance)\n\nAn example for an internally heated sphere can be found here."}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/133361/get-the-name-of-a-time-series-while-using-table\nText:\nI saw a number of related questions to the one I'm about to post; they helped, but none of them solved my problem entirely.\n\nGet the name of a symbol passed to a function\n\nObtaining the name of a variable as a string\n\nThe general question is how to get the name of something (a function, a list...). From the previous questions, I learned that you could use a function with the HoldFirst attribute:\n\nSetAttributes[f, HoldFirst]\nf[x_] := SymbolName[Unevaluated@x]\n\nThis function works well when it's input is directly the element of which you want to get the name. However, in my case, I have to use Table[] and I want to get the name of multiple time series. For example, I have three time series, ts1, ts2 ts3. I then want to produce two list plots, both with ts1 on the x axis and then respectively one that has ts2 on the y axis and another that has ts3 on the y axis. Here is the code I used:\n\n\nListPlot[\u00a0Transpose[{ts1[\"Values\"],i[\"Values\"]}]\n\n\u00a0,{i,{ts2,ts3}}\u00a0]\n\nBut the y axis labels, on both plots, are the time series objects, not their names. If I use the function f[_x] that I linked above, I get:\n\n\n\n\u00a0,{i,{ts2,ts3}}\u00a0]\n\nThen the y axis label is just \"i\"... So what I need is a function that evaluates i \"just enough\" (forget the imprecise formulation) so that it is replaced by, let's say, ts2, but then holds the form and convert it to a symbol. I do not know how to do that.\n\nHere are three time series if you want to try and mess around with them:\n\n\n\n\nProposed alternatives\n\nThis is a matter of controlling evaluation. You can do this with varying degrees of difficulty using things like HoldFirst, Unevaluated, etc., or you can simply avoid the problem in the first place which is what I greatly prefer.\n\nTo do this you can separate the names from the data using indexed objects, Rules, or Associations. Instead of defining ts1 = TimeSeries[. . .] you would write one of the following:\n\nts[1] = TimeSeries[. . .]\n\ndata[\"ts1\"] = TimeSeries[. . .]\n\nts1[] = TimeSeries[. . .]\n\nrules = {\"ts1\" -> TimeSeries[. . .], \"ts2\" -> TimeSeries[. . .]}\n\nasc = <|\"ts1\" -> TimeSeries[. . .], \"ts2\" -> TimeSeries[. . .]|>\n\nIn each case you can freely pass around a reference (name) for the TimeSeries expression without it automatically evaluating to anything.\n\nYou would reference each of these in the respective manner:\n\nTable[Labeled[ts[i], Row[{\"ts\", i}]], {i, 1, 3}]\n\nTable[Labeled[data[name], name], {name, {\"ts1\", \"ts2\", \"ts3\"}}]\n\nTable[Labeled[ts[], ts], {ts, {ts1, ts2, ts3}}]\n\nTable[Labeled[name /. rules, name], {name, {\"ts1\", \"ts2\", \"ts3\"}}]\n\nTable[Labeled[asc[name], name], {name, {\"ts1\", \"ts2\", \"ts3\"}}]\n\nSelf-contained examples\n\nLet me see if I can provide a concrete example using your data.\n\nt = {3686428800, 3686515200, 3686601600, 3686688000, 3686774400, 3686860800, \\\n3687033600, 3687120000, 3687206400, 3687379200, 3687465600, 3687552000, 3687638400, \\\n3687724800, 3687897600, 3687984000, 3688243200, 3688329600, 3688502400, 3688588800, \\\n3688675200, 3688761600, 3688848000, 3689020800, 3689107200, 3689193600, 3689366400, \\\n3689452800, 3689539200, 3689625600, 3689712000, 3689798400, 3689884800, 3689971200, \\\n3690057600, 3690144000, 3690230400, 3690316800};\n\nvaleurs = {{2,2,1,1.4,1.9,1.8,1.7,1.5,2,2,2,2.2,1.7,1.7,1.7,1.7,2,2,1.7,2.3,1.7,1.7,1.7,1.7,2,1.7,2.4,1.7,0.5,2,1.7,1.7,1.7,1.7,2.1,1.7,2.1,3.4},\n\nnomsVariables = {ts1, ts2, ts3};\n\n\nMapThread[(#1[] = TimeSeries[#2, {t}]) &, {nomsVariables, valeurs}];\n\nAccess and labeling of various time series as an illusration:\n\nLabeled[#[], #] & /@ nomsVariables\n\nIf nomsVariables is a list of Strings rather than Symbols I recommend that you use the second, fourth or fifth forms shown earlier so as to avoid the need to convert to Symbols:\n\nnomsVariables = {\"ts1\", \"ts2\", \"ts3\"};\n\nMapThread[(data[#1] = TimeSeries[#2, {t}]) &, {nomsVariables, valeurs}]\n\nLabeled[data[#], #] & /@ nomsVariables\n\nThe question at face value\n\nTo leave no stone unturned I should address the actual question as asked rather than only proposing an alternative. You can HoldForm the individual Symbols in the Table and then ReleaseHold that expression when you need it to resolve to the TimeSeries:\n\nTable[ListPlot[Transpose[{ts1[\"Values\"], ReleaseHold[i][\"Values\"]}], Frame -> True, \n  FrameLabel -> {\"ts1\", i}], {i, {HoldForm[ts2], HoldForm[ts3]}}]\n\nThis works for the example given but it introduces other question like how to create the list {HoldForm[ts2], HoldForm[ts3]} apart from typing it in. Typically you would start with an expression of held Symbols before they (ts2, ts3, etc.) are assigned values. Another question exists that addresses the use of this form to some degree: Elegant manipulation of the variables list Nevertheless IMHO this should not be used commonly but rather as a special purpose tool.\n\n  \u2022 $\\begingroup$ Thank you for your answer. I'm trying out what you proposed by using the indexed objects ts1[]. It is indeed much simpler than messing around with the evaluation. However, I do have another question related to these indexed objects. As I dont have 3, but around 50 times series to define, I'm trying to define them as a bunch, but I get the error message Set::write: Tag Map in (#1[]&)/@{liquide,travail} is Protected.. Here is what I tried: Map[#[] &, Symbol /@ nomsVariables[[;; 2]]] = Map[TimeSeries[#, {t}] &, valeurs[[;; 2]], {1}]. $\\endgroup$ \u2013\u00a0EBassal Dec 12 '16 at 19:42\n  \u2022 $\\begingroup$ Where nomsVariables contains the names of all the variables, t contains the different dates and where valeurs contains the different variables (one sublist per variable). $\\endgroup$ \u2013\u00a0EBassal Dec 12 '16 at 19:43\n  \u2022 $\\begingroup$ Never mind, I just added an Evaluate...: Evaluate[Map[#[] &, Symbol /@ nomsVariables[[;; 2]]]] = Map[TimeSeries[#, {t}] &, valeurs[[;; 2]], {1}]. $\\endgroup$ \u2013\u00a0EBassal Dec 12 '16 at 19:55\n  \u2022 $\\begingroup$ @EBassal give me a minute; I am looking at your example. If you've found a solution in the mean time that's fine. $\\endgroup$ \u2013\u00a0Mr.Wizard Dec 12 '16 at 19:55\n  \u2022 1\n    $\\begingroup$ @EBassal Please see my update. I hope you find the examples useful, but if not it seems you found what you need. Thanks for the Accept. $\\endgroup$ \u2013\u00a0Mr.Wizard Dec 12 '16 at 20:04\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/47101/maximum-independent-nodes-subset-algorithm-with-strong-constraint\nText:\nI've a tree with weighed nodes, the problem is to flag a subset of nodes with the following constraints:\n\n  \u2022 The selected nodes must be the optimal solution (maximal sum of weight).\n  \u2022 If one node is flagged no adjacent nodes can be flagged.\n  \u2022 If a node is flagged it will be called: \"directly controlled\", the adjacent nodes instead will be called: \"indirectly controlled\", all nodes must be directly or indirectly controlled.\n\nI think is a dynamic programming problem (a greedy approach didn't find always a optimal solution), the first two constraints are a typical maximum independent subset problems, but i cannot find a solution with the third constraint included. Any idea? Thanks\n\n\nA set satisfying condition (3) is known as a dominating set. The exercise asks for a maximum weight dominating independent set.\n\nIf all node weights are positive, then every optimal solution is automatically a dominating set (why?), regardless of whether the graph is a tree or not. In the more general case in which negative weights are allowed, you can use a standard dynamic programming approach. Root the tree at an arbitrary node, and for every subtree rooted at some internal node $v$, compute the maximum weight independent set in the following three cases:\n\n  \u2022 The independent set is dominating and includes $v$.\n  \u2022 The independent set is dominating and doesn't include $v$.\n  \u2022 The independent set is dominating if $v$ is removed (it is allowed to dominate $v$ as well), and doesn't include $v$.\n\nI'll let you complete the details.\n\n  \u2022 $\\begingroup$ Thanks for your help. My tree have all positive weights, i've tried the independent set algorithm with some particular tree and, as you said, is always a dominating set, so intuitively i've understood that it's true, now i'm trying to find a better formal demonstration. $\\endgroup$ \u2013\u00a0FabioL Sep 12 '15 at 14:39\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/104570/algorithm-calculate-every-number-in-a-given-list-using-addition-and-numbers-you\nText:\nI'm creating an algorithm to calculate every number in an array using only addition and numbers we've created - in the shortest amount of steps. That's confusing so here is an example:\n\ninput: [5, 11], used numbers (start with 1): [1]\n1+1=2, used: [1, 2]\n2+2=4, used: [1, 2, 4]\n1+4=5, [1, 2, 4, 5]\n5+5=10, [1, 2, 4, 5, 10]\n10+1=11, [1, 2, 4, 5, 10, 11]\n\nWe have hit 5 and 11 so we are done in 5 steps. There are other ways to get [5, 11], eg. [1, 2, 3, 5, 6, 11]. They are the same amount of steps. Imagine we have input [5, 11, 20]. Now it matters which we choose above because [1, 2, 4, 5, 10, 11] only requires one more step, 10+10.\n\nThe input can be hundreds of numbers. Certainly I can't attempt every possibility. I was thinking about an \"elegant\" solution using prime factors. If my input is [16, 30, 36, 40], does it help me to think about this as [2*2*2*2, 2*3*5, 2*2*3*3, 2*2*2*5]? I'm not sure. I've also thought about using the differences of each input, eg. [16, 30, 36, 40] would give me [14, 6, 4, 20, 24, 10], but I'm not sure how to use that either.\n\nAny thoughts?\n\n\nIt's NP complete, but you may have a chance in many practical cases, especially if you need to produce a lot of numbers in a not very large range. I'll call the numbers you want to produce \"desired numbers\", and assume that 1 is not one of the \"desired numbers\".\n\nAn important observation is that in any chain, performing an addition that produces one of the desired numbers is optimal. Therefore, we need only count the additions that don't produce one of the desired numbers (and if you want to produce 100 numbers from 1 to 200 those additions might be very few).\n\nSo instead of the initial set { 1 }, we add { 2 } if it is one of the desired numbers, then add 3 or 4 if they are among the desired numbers, and so on. If you wanted { 2, 3, 5, 6, 10, 19, 20, 21, 50 } then you start with the initial set { 1, 2 = 1+1, 3 = 2+1, 5 = 3+2, 6 = 5+1, 10 = 5+5, 20 = 10+10, 21 = 20+1 } and you only need to find 19 and 50.\n\nThen each move consists of adding the sum of two numbers, and then adding all of the desired numbers that can now be produced. In the example, one move would be adding 16 and 19, another move adding 40 and 50. All this really cuts down on the number of possibilities you need to try out.\n\nSome more ways to cut down on the possibilities: We can require that the non-desired numbers are produced in increasing order. So if you produced 2 and 4, you cannot produce the number 3 anymore. Or if you produced 2, 3, 5, you cannot produce the number 4 anymore - if you wanted it, you should have produced it earlier.\n\nObviously you don't ever produce a number larger than the highest desired number. Or higher than the highest desired number that wasn't produced yet. And all numbers greater than the highest desired number that wasn't produced yet must have been used producing one of the higher desired numbers.\n\nAnd you cannot ever produce a number larger than the smallest desired number not found yet.\n\nApart from that, I cannot think of any \"elegant\" algorithm. I'd try all the possibilities, producing large numbers first, and of course stopping when you can prove you are not going to find a solution than the best so far.\n\nYour example: [16, 30, 36, 40].\n\nFirst attempt, always adding the largest number possible according to the rules: 2, 4, 8+16, 24, 28+30, 34+36+40. That's six moves, so you can try to find a better solution using five or fewer moves using backtracking. (Note that in move 4 and 5 we couldn't produce a number > 30 according to the rules).\n\nProducing 26 or 25 in step 5 doesn't help. In step 4, we could produce 20+36+40, 18+36+40, 17, 12, 10, 9. 20+36+40 can be followed by 28+30, so we found a better solution using five moves only (2, 4, 8+16, 20+36+40, 28+30). Now the goal is to find a chain with four or fewer extra additions.\n\n2, 4, 8+16 doesn't give success with four extra additions. We can try 2, 4, 6 or 2, 4, 5 or 2, 3, 6 or 2, 3, 5 or 2, 3, 4 which all don't solve the problem in four moves. So (2, 4, 8+16, 20+36+40, 28+30) with five moves plus four moves adding the four desired numbers is an optimal solution.\n\n\nYou're looking for an algorithm to generate an addition chain that includes each of the specified numbers. As Wikipedia explains, the problem is NP-complete in general. However, there are approximation algorithms and heuristics. Searching for algorithms for computing addition chains should give you some candidate methods.\n\n\nThis is the addition sequence problem. You can transform the addition sequence problem into the vector addition chain problem as well. The best known algorithm for computing these is:\n\nD. Bleichenbacher and A. Flammenkamp \"An Efficient Algorithm for Computing Shortest Addition Chains\"\n\nThis is unpublished but you can find it on the addition chain website:\n\n\nYou essentially need to write a function what will approximate (find a lower bound) the size of an addition sequence. For this I use the bounding sequences in this paper:\n\nE. G. Thurber \"Efficient Generation of Minimal Length Addition Chains\", SIAM Journal of Computing, V. 28(4) 1999 pp 1247-1263.\n\nMyself and Ed have an update to this paper with better bounds. Now you work in reverse with the algorithm of Flammenkamp etc by removing the largest element in the set and splitting it as per the paper. You then prune with known l(n) values that I have already calculated as well as using your lower bound for the addition sequence that is updated with the split values. You will need to understand the graph representation of addition chains to understand this algorithm. I have numerous unpublished updates to this algorithm in the code that I use. This is quite old work of mine as there are better approaches for the single number addition chain problem I study.\n\n  \u2022 $\\begingroup$ I don't see how this would work. For example, given just two numbers x and y, it is quite possible that the best way to produce two numbers doesn't involve a shortest addition chain for either number, but two non-optimal chains with common elements. $\\endgroup$ \u2013\u00a0gnasher729 Mar 31 '19 at 0:14\n  \u2022 $\\begingroup$ The algorithm described by Flammenkamp works on a set of numbers. It transforms a set say {a,b} with b > a by enumerating on the largest reduced vertex that is an input to b. Lets call that i. So you actually them process the set {a,i,b-i}. If i > b it actually skips a step working on {a,i,b-2i}. Nothing in this algorithm means we are using an optimal chain for a or b. We can clearly pune using l(a) and l(b) since l({a,b}) >= max(l(a),l(b)). You can do much better though with Thurber bounds though since you can calculate the min distance between a and b. So l({a,b}) >= l(a) + dist(a,b). $\\endgroup$ \u2013\u00a0Neill Clift Mar 31 '19 at 5:12\n  \u2022 $\\begingroup$ Need i > a above sorry. $\\endgroup$ \u2013\u00a0Neill Clift Mar 31 '19 at 5:20\n\nYour Answer"}
{"text": "Retrieved from https://www.flyingcoloursmaths.co.uk/minecraft-circles/\nText:\nMinecraft circles\n\n\nSorry, buddy. I've tried it. I love that you love it -- honestly, creative games are awesome for your problem-solving skills and breaking down the barriers between art and science, so I'm all for it in principle -- it's just not my cup of tea.\n\nAll the same, I'm happy to help you solve problems! Of course I am. That's what uncles are for.\n\nSo, you want to make a circle? Awesome. One tiny problem: the Minecraft world is made of squares, and you can't make a perfect circle out of squares. You can, however, make something that looks pretty much like a circle -- that's what happens when your computer draws a circle; using lots of tiny dots means you can get close enough!\n\nSo, how would you draw a circle that was, say, 21 squares wide? That would be a circle with a radius of 10 units.\n\nIt's easy to find a few places blocks need to go: ten squares north of the centre of the circle, you'll have a block. Same thing 10 squares east, south and west of the centre -- four points making a sort of cross with the centre.\n\nAfter that, it gets trickier -- how about a square to the north-east of the centre? It needs to be 10 units away from the centre, so you'd think you'd go ten squares diagonally -- but unfortunately, that's too far! That would make a big square. Why is it too far? It's because a diagonal step is bigger than a north/south/east/west step. It's not twice as far, though: if you go five squares to the northeast of the centre, you end up midway between your compass points, which isn't right, either. The right answer is somewhere in between five and ten.\n\nIt turns out to be seven squares1, because of Pythagoras's Theorem. You might have come across this, you might not: in a Minecraft context, it says, if you go east one number of squares and north another number, you can work out how far from the centre of the circle you are by using the recipe:\n\n  \u2022 multiply the east/west number by itself\n  \u2022 multiply the north/south number by itself\n  \u2022 add the two numbers together\n  \u2022 find the square root, probably using a calculator\n\nHow does it help? Well, if you go seven squares across and seven squares up, following those steps gives you 49 and 49, which add up to 98. The calculator says the square root of 98 is about 9.9, which rounds up to 10 -- the square seven east and seven north of the centre is pretty close to 10 units away from it, which is what we want from a circle with radius 10!\n\nWe can change the recipe slightly to work out how far north we need to go if we go any distance to the east. Here's how it looks:\n\n  \u2022 multiply the east/west number by itself\n  \u2022 multiply the radius by itself\n  \u2022 find the difference between them\n  \u2022 find the square root, probably using a calculator\n\nIf you go one to the east, the steps give you 1, 100, a difference of 99, and the square root is 9.95 or so -- which rounds up to 10, so the square one to the east and 10 north is on the circle. You can write this efficiently as (1, 10).\n\nWorking the same way for the next few numbers gives (2, 10), (3, 10), (4, 9), (5, 9), (6, 8) and (7,7) -- and surprisingly, that's all the hard work we need to do! We can now use the idea of symmetry to find all of the other coordinates.\n\nOne kind of symmetry means you can swap the numbers in a pair of coordinates: because (1, 10) is on the circle, so is (10, 1). In the same way, you know (10, 2), (10, 3), (9, 4), (9, 5) and (8, 6) are also on the circle.\n\nNow you've got a quarter-circle! (I believe, in Minecraft, that's enough; you can set it up to build the whole circle using symmetry. But let's keep going!)\n\nHow do you get the rest of the circle? Simple. The coordinates count how far east and how far north you need to go -- but you can switch the directions around! Instead of going east and north, you could go west and north, or east and south, or west and south -- making up the four quarters of the circle! (The important thing to remember is that you always need one sideways direction and one up/down direction for it to work.)\n\nI hope that's enough for you to get going -- and that it's practical enough for you to draw your circle!\n\n\n\n  1. roughly []\n\n\n4 comments on \u201cMinecraft circles\n\nLeave a Reply\n\n\n\n\nNo spam ever, obviously.\n\nWhere do you teach?\n\nI teach in my home in Abbotsbury Road, Weymouth.\n\n\nOn twitter"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/119227/undecidability-of-two-turing-machines-acting-the-same-way-on-an-input\nText:\nSo I need to find a reduction to the (undecidable) problem of deciding if two Turing machines $M_1$ and $M_2$ behave the same way on an input $x$. \"Behaving the same way\" is defined like this:\n\n$M_1$ and $M_2$ behave the same way on an input $x$, when they both don't halt, or when they both accept $x$ or when they both halt and reject $x$.\n\nI found a reduction from the halting problem which uses the fact that if the Turing machines behave in the same way, than they must have the same language. But this all breaks down in the case that $M_1$ rejects $x$ and $M_2$ doesn't halt, obviously they could have the same language, but they don't act in the same way.\n\nI do think the best way to approach this is by reducing from the halting problem, but I just can't find a valid reduction. Any help would be appreciated.\n\n\nYou were very close to the answer. The special case you mentioned can be handled by hand. Modify the machines resulting from the reduction such that, for each transition, where the machine halts and rejects, let the resulting machine go into an endless loop instead.\n\nNow each machine either accepts or goes into an endless loop. That means, checking if both machines are equivalent on an input $x$ is checking whether both accept the input $x$.\n\n  \u2022 1\n    $\\begingroup$ \"each time the machine halts and rejects\" We don't have this information. The halting problem: $H = \\left\\{ \\left \\langle M \\rangle, x \\: \\right| x \\in L(M) \\right\\} $. Either $M$ accepts $x$ or it doesn't. If $x \\notin L(M)$, $M$ either doesn't halt or it halts and rejects, but we can't tell which. $\\endgroup$ \u2013\u00a0Karla Jan 5 '20 at 20:44\n  \u2022 $\\begingroup$ I probably did not formulate the idea correctly, I meant to look into the transitions function, and instead of transition to the state \"no\", go into an endless loop. I updated the answer correspondingly $\\endgroup$ \u2013\u00a0narek Bojikian Jan 5 '20 at 21:00\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/help-on-fredholm-eqn-of-the-first-kind.622208/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHelp on Fredholm Eqn of the First Kind\n\n  1. Jul 20, 2012 #1\n    Hello humans,\n    Can you offer advice on the following situation?\n    [itex] g(s)=\\int_{a}^{b}K(t,s)f(t)dt [/itex]\n    However I understand that if K can be expressed as\n    [itex] K(t,s)=K(t-s) [/itex]\n    then we can say\n    [itex]f(t)=\\mathcal{F}^{-1}\\left [ \\frac{\\mathcal{F}[g(t)]}{\\mathcal{F}[K(t)]} \\right ] [/itex]\n    Where the fancy F is Fourier, natch. Although I am fuzzy on what happened to a and b. Anyway, in my case, my function looks like this:\n    [itex] g(s)=\\int_{0}^{\\infty}t f(t)dt [/itex]\n    Can you offer any tips, advice, et cetera?\n  2. jcsd\n  3. Jul 20, 2012 #2\n    By the way the idea here is to solve for f, knowing g.\n  4. Jul 20, 2012 #3\n\n\n    User Avatar\n    Homework Helper\n\n    K(t,s) = K(t-s) is not a good enough condition to be able to use the fourier transform method to solve the equation. Your integration limits also have to be [itex]\\pm \\infty[/itex].\n\n    You could solve the equation numerically using quadrature methods, since then it's basically a linear algebra problem [itex]\\mathbf{g} = K\\mathbf{f}[/itex].\n  5. Jul 20, 2012 #4\n    Thanks man. I appreciate it.\n  6. Jul 20, 2012 #5\n    What if we say\n    [itex] t=e^{\\omega u/2} [/itex], so [itex] dt=\\frac{\\omega}{2}e^{\\omega u/2}du [/itex]\n    and then\n    [itex] g=\\int_{0}^{\\infty}\\frac{\\omega}{2}e^{\\omega u}f(u)du [/itex]\n    which means just taking the inverse Laplace transform of g in order to get f?\n    Just an idea?\n  7. Jul 20, 2012 #6\n\n\n    User Avatar\n    Homework Helper\n\n    I overlooked the part of your original post where you said your equation was\n\n    [tex]g(s) = \\int_0^\\infty dt~t f(t).[/tex]\n\n    Unless g(s) happens to be a constant, that is an ill-formed equation. The integration kernel does not depend on s, so the integral is a constant. If g is constant, you can have infinitely many solutions for f.\n  8. Jul 20, 2012 #7\n    Good point, you're right, in the interest of expedience I haven't written it right. The real problem looks like this:\n    [itex] g(s)=\\int_{0}^{\\infty}tf(t,s)dt [/itex]\n    I know g, I am trying to find f.\n    Last edited: Jul 20, 2012\n  9. Jul 20, 2012 #8\n\n\n    User Avatar\n    Homework Helper\n\n    Hm, well, general solutions to integral equations are hard to come by. You can't apply the Laplace transform as is, for instance, since it will only decouple the integrand if the upper limit is s. You could try, for example, assuming that [itex]f(t,s) = \\tilde{f}(s-t)\\Theta(s-t)[/itex], where Theta is a Heaviside side function. Then your equation would be of the form\n\n    [tex]g(s) = \\int_0^s dt~t \\tilde{f}(s-t),[/tex]\n\n    and the Laplace transform would factor the integral for you:\n\n    [tex]\\mathcal L g(u) = \\frac{\\mathcal L f(u)}{u},[/tex]\n    which you could then inverse Laplace transform. However, since you have to assume a particular form of the solution here, it might not be general, or perhaps the inverse transform won't exist, etc.\n\n    Another possibility is to consider the Mellin transform. The Mellin transform of a function f(x) is\n\n    [tex]\\varphi(y) = \\int_0^\\infty dx x^{y-1} f(x).[/tex]\n    (it's actually related to the Laplace transform by a change of variables). This is almost the form of your equation, if your g were g(s,y=2). If you can choose a suitable generalization of g(s) to some g(s,y), then the solution to\n\n    [tex]g(s,y) = \\int_0^\\infty dt~t^{y-1} f(t,s)[/tex]\n    would simply be the inverse Mellin transform of g:\n\n    [tex]f(t,s) = \\frac{1}{2\\pi i}\\mathcal M^{-1}[g(s,y)](t) = \\int_{c-i\\infty}^{c+i\\infty} dy t^{-y} g(s,y).[/tex]\n\n    (see the wikipedia page for the Mellin transform definition and what the inverse equation means)\n\n    But I'm not sure if you can really get the f(t,s) that you actually want out of that solution.\n\n    Another cause for concern that I have with this approach is that there are effectively infinitely many ways you might generalize g(s) to g(s,y) such that g(s,2) is the g(s) you're starting with. I don't know if that means there are infinitely many solutions, or if some solutions just won't work (e.g., the inverse Mellin transform doesn't exist because your g doesn't satisfy the Mellin inversion theorem requirements), or something else.\n    Last edited: Jul 20, 2012\n  10. Jul 20, 2012 #9\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    My immediate reaction is to get rid of the t factor by change of variable, u = t2, f(t) = 2h(u).\n    If g(s) can be written as \u01a9ans-n, n > 0, then there's a solution h(u, s) = e-us\u01a9anun-1/(n-1)! (the details may be wrong).\n    Given any solution h = h(u, s), h + k(u,s) is also a solution iff \u222b0k(u,s)du is identically 0.\n\nSimilar Discussions: Help on Fredholm Eqn of the First Kind\n  1. Logrithmic eqn (Replies: 9)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/is-this-the-right-working-out-for-integral-x-3sin-x-dx-x-2-1-x-2-9.171431/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIs this the right working out for integral x^3sin(x)dx/[(x^2+1)(x^2+9)]\n\n  1. May 23, 2007 #1\n    [tex] int^{infty}_{0} \\frac{x^3sinx}{(x^2+1)(x^2+9)} dx [/tex]\n\n    2. Relevant equations\n\n    I understand the value of the integral will be 2 * pi * [sum of residues]\n    and I am also aware of the formula\n\n    Res_{z=z_0} f(z) = [tex] \\frac{g^{m-1} (z_0)}{(m-1)!} [/tex]\n\n    3. The attempt at a solution\n\n    I know the poles exsit and are x= + / - i and x = +/- 3i\n\n    only 2 in the countour and that is x=i and x=3i\n\n    so I get stuck here because all the examples have a bit of working out with a less than or equal to sign and an absolule value, which shows as it goes to zero R goes to inifity... I just don't understand how to set that bit up and why it is necessary, if you know what i'm talking about, can you please explain it to me?\n\n\n  2. jcsd\n  3. May 23, 2007 #2\n\n\n    User Avatar\n    Homework Helper\n\n    ok, to cut a long story short...\n    you wish to apply Cauchy integral theorem to help you doing this integral...because it seems \"hard\" to do if we stay on the real line. Therefore the idea is to analytically continue the function onto the complex plane and treat it as a contour integration. Here you have nice theorems like Cauchy integral theorems, Jordan lemma...etc. to help you do things.\n\n    ok, so you are looking for a \"closed\" contour such that you can apply your theorems. now, however, your initial integral is only from 0 to infty, so you need to make sure that the \"extra piece\" used to close the contour actually vanishes in the desire limit. (that's where the R->infty bit comes from) let me list the procedure:\n\n    1. goto complex plane x->z\n    2. close contour (from a straight line 0->infty, you add an arc of radius R, then return to zero vertically from iR ->0)\n    3. wish to make sure the arc bit disappear in the limit of R->infty, the vertical bit may require more work such as change of variables and other tricks (can't remember off top of my head for this specific case)\n    4. now to see whether the arc really disappear, you do a \"test\" on what happen to the integral\n    [tex]\\int_{\\text{arc}}\\ldots = \\int_{0}^{\\pi/2}\\ldots d\\theta [/tex]\n    where [tex]\\ldots[/tex] means the integral in polar form (with R and theta instead of z)\n    5. you would really want to just look at absolute value because, phases don't matter, only R matters since R->infty eventually\n    6. now, if the function/integrand is bounded from above by some function that goes to zero when R becomes large, then you can say this integral involving the \"arc\" really vanishes (that's where those less than or equal to sign comes from .... i presume)\n    7. once, all auxiliary stuffs are proved to be \"OK\" you can then proceed to solve the problem using those theorems\n  4. May 23, 2007 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Split sin(x) up as (exp(ix)-exp(-ix))/(2i) and split the integral into two parts. For the part with exp(ix) in it you can argue the contribution from the extra part of the contour can be ignored if you close it in the upper half plane. For the exp(-ix) part you will want to close in the lower half plane (use the other set of poles and reverse the overall sign since the contour is going in the opposite direction)."}
{"text": "Retrieved from https://www.physicsforums.com/threads/electric-generators.391517/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nElectric generators\n\n  1. Apr 1, 2010 #1\n    I know that the iron core of a solenoid will result in a higher magnetic field than a hollow core when a current is running through it.\n\n    I'm wondering if the reverse is true. Will an iron core result in a larger current when the solenoid is exposed to a changing magnetic field?\n\n    I want to create a simple generator where one or two electric coils are rotating between some magnets and I am wondering if having an iron core will create a larger current.\n\n    Any explanation as to why would be appreciated too.\n\n  2. jcsd\n  3. Apr 3, 2010 #2\n    Let's see here. We have the following from Ampere's law:\n    B = mu NI/h\n    Solving this for the current, we get:\n    I = Bh/(N mu)\n    Where mu depends on the core material. Using iron (or most other metals) this value will be greater than mu_nought = 1/(4pi x10^-7) ~ 1.2566650\u00d710^-6.\n    The movement of the core inside the solenoid causes a changing magnetic field ([tex]\\hat{B}[/tex]) which causes an induced current (I). As such, the current depends on the changing magnetic field, as well as the permeability of the space inside (our mu.) As mu_iron > mu_hollow, where mu_hollow=mu_nought, we will get a smaller induced current using an iron core from the same changing magnetic field, [tex]\\hat{B}[/tex]. This would mean changing the position of the core inside of the solenoid by the same amount and at the same rate.\n\n    So, if the changing magnetic field is the same in both trials (one with a hollow solenoid, one with an iron core) we get a larger induced current using a hollow core as a result of the smaller permeability value. As such, we will get a smaller induced current when using an iron core as a result of its larger permeability value.\n  4. Apr 6, 2010 #3\n    Since there is the above exposition, I'll just add in simpler language also that the added resistance of the iron core, if the solenoid is formed of uninsulated wire so there is contact, will add to the resistance of the system and therefore reduce current flow per \"V=P/I.\"\n\n    This rarely has any purpose to be considered since most solenoids are insulated... but... life happens."}
{"text": "Retrieved from https://www.physicsforums.com/threads/molar-volume-of-gas-in-function-of-temperature-and-pressure.672926/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMolar volume of gas in function of temperature and pressure\n\n  1. Feb 19, 2013 #1\n\n    Given are two relations for the molar volume. Are they possible? If so, give the formula for v in function of P and T.\n    a) dv =R/P dT - RT/P\u00b2 dP\n    b) dv = 2R/P dT - RT/2P\u00b2 dP\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    If I integrate dv I get \u222bR/P dT - \u222bRT/P\u00b2 dP= RT/P + RT/P (in case a) and 5/4 * RT/P (in case b).\n    does this mean they are both 'possible'?\n\n    intuitively I would say only a is possible\n\n    another thing that struck me - probably resulting from some kind of error I made- was the following discrepancy:\n    say v=RT/P then dv=dv/dT dT + dv/dP dP = R/P dT - RT/P\u00b2 dP.\n    So according to this v=RT/P might well be the solution to the integral \u222bdv (in the case of a).\n  2. jcsd\n  3. Feb 20, 2013 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    The molar volume v is function of P and T: v(T,P). If its first and second partial derivatives exist and continuous its differential is\n\n    dv=\u2202v/\u2202T dT + \u2202v/\u2202P dp.\n\n    an the mixed second partial derivatives are equal:\n\n\n    The integral of dv is independent of he path taken, v is a \"potential\", only if that condition holds.\n\n    In case of the first example, \u2202v/\u2202T=R/P and \u2202v/\u2202P=-RT/P2. The mixed derivatives are equal.\n\n    Now you have \u2202v/\u2202T=R/P, and integrate with respect to T: V=RT/P + integration constant. But that constant can depend on P, so v(T,P)=R/P+f(P). You can find f(P) from the condition that the derivative of v with respect to P has to be -RT/P2:\n    \u2202v/\u2202P= -RT/P2+df/dP=-R/P2, so f=constant.\n\n    Check if the other dv can be the perfect differential of a potential function."}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculating-battery-usage.581732/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculating battery usage?\n\n  1. Feb 26, 2012 #1\n    I have a phone. Since it was last charged, I used it for 8 hours and it was on standby for 16. Now my battery's down to 50%. How much battery did I use when I used the phone?\n\n    I'm thinking it's as simple as x + 2x = 50%.\n  2. jcsd\n  3. Feb 27, 2012 #2\n\n\n    Staff: Mentor\n\n    Maybe or maybe not. You're assuming that the battery draw is the same when the phone is in use versus when it's in standby mode. It's possible and maybe likely that the phone uses less power when it's in standby mode, since it might not need to use power to drive the screen. If so, your equation doesn't take this reduced current draw into account.\n  4. Feb 27, 2012 #3\n    Yes, the screen shuts off in standby mode.\n  5. Feb 27, 2012 #4\n\n\n    User Avatar\n    Science Advisor\n\n    So the phone uses less energy in standby mode. Unfortunately, you do not know how much less. If you knew, for example, that in standby mode you phone uses fraction m of the amount of energy it uses when in use, you could argue that, since it was in standby twice as long as in use, the total energy uses is E+ 2mE= 0.5. That gives (1+ 2m)E=0.5 so the amount of energy used while in use would be E= (0.5)/(1+ 2m).\n\nSimilar Discussions: Calculating battery usage?\n  1. Calculate the variance (Replies: 3)\n\n  2. Log calculation (Replies: 16)"}
{"text": "Retrieved from https://math.libretexts.org/TextMaps/Combinatorics/Map%3A_Combinatorics_and_Graph_Theory_(Guichard)/5%3A_Graph_Theory/5.06%3A_Optimal_Spanning_Trees\nText:\nSkip to main content\nMathematics LibreTexts\n\n5.6: Optimal Spanning Trees\n\nIn some applications, a graph \\(G\\) is augmented by associating a weight or cost with each edge; such a graph is called a weighted graph. For example, if a graph represents a network of roads, the weight of an edge might be the length of the road between its two endpoints, or the amount of time required to travel from one endpoint to the other, or the cost to bury cable along the road from one end to the other. In such cases, instead of being interested in just any spanning tree, we may be interested in a least cost spanning tree, that is, a spanning tree such that the sum of the costs of the edges of the tree is as small as possible. For example, this would be the least expensive way to connect a set of towns by a communication network, burying the cable in such a way as to minimize the total cost of laying the cable.\n\nThis problem is one that can be solved by a greedy algorithm. Roughly speaking, a greedy algorithm is one that makes choices that are optimal in the short run. Typically this strategy does not result in an optimal solution in the long run, but in this case this approach works.\n\nDefinition:\u00a0weighted graph\n\nA weighted graph is a graph \\(G\\) together with a cost function \\(c\\colon E(G)\\to \\R^{>0}\\). If \\(H\\) is a subgraph of \\(G\\), the cost of \\(H\\) is \\(c(H)=\\sum_{e\\in E(H)} c(e)\\).\n\nThe Jarn\u00edk Algorithm\n\nGiven a weighted connected graph \\(G\\), we construct a minimum cost spanning tree \\(T\\) as follows. Choose any vertex \\(v_0\\) in \\(G\\) and include it in \\(T\\). If vertices \\(S=\\{v_0, v_1,\\ldots,v_k\\}\\) have been chosen, choose an edge with one endpoint in \\(S\\) and one endpoint not in \\(S\\) and with smallest weight among all such edges. Let \\(v_{k+1}\\) be the endpoint of this edge not in \\(S\\), and add it and the associated edge to \\(T\\). Continue until all vertices of \\(G\\) are in \\(T\\).\n\nThis algorithm was discovered by Vojt\u011bch Jarn\u00edk in 1930, and rediscovered independently by Robert C. Prim in 1957 and Edsger Dijkstra in 1959. It is often called Prim's Algorithm. The algorithm proceeds by constructing a sequence of trees \\(T_1, T_2,\\ldots,T_{n-1}\\), with \\(T_{n-1}\\) a spanning tree for \\(G\\). At each step, the algorithm adds an edge that will make \\(c(T_{i+1})\\) as small as possible among all trees that consist of \\(T_i\\) plus one edge. This is the best choice in the short run, but it is not obvious that in the long run, that is, by the time \\(T_{n-1}\\) is constructed, that this will turn out to have been the best choice.\n\nTheorem 5.6.2\n\nThe Jarn\u00edk Algorithm produces a minimum cost spanning tree.\n\n\nSuppose \\(G\\) is connected on \\(n\\) vertices. Let \\(T\\) be the spanning tree produced by the algorithm, and \\(T_m\\) a minimum cost spanning tree. We prove that \\(c(T)=c(T_m)\\).\n\nLet \\(e_1, e_2,\\ldots,e_{n-1}\\) be the edges of \\(T\\) in the order in which they were added to \\(T\\); one endpoint of \\(e_i\\) is \\(v_i\\), the other is in \\(\\{v_0,\\ldots,v_{i-1}\\}\\). We form a sequence of trees \\(T_m=T_0, T_1,\\ldots, T_{n-1}=T\\) such that for each \\(i\\), \\(c(T_i)=c(T_{i+1})\\), and we conclude that \\(c(T_m)=c(T)\\).\n\nIf \\(e_1\\) is in \\(T_0\\), let \\(T_1=T_0\\). Otherwise, add edge \\(e_1\\) to \\(T_0\\). This creates a cycle containing \\(e_1\\) and another edge incident at \\(v_0\\), say \\(f_1\\). Remove \\(f_1\\) to form \\(T_1\\). Since the algorithm added edge \\(e_1\\), \\(c(e_1)\\le c(f_1)\\). If \\(c(e_1)< c(f_1)\\), then \\(c(T_1)< c(T_0)=c(T_m)\\), a contradiction, so \\(c(e_1)=c(f_1)\\) and \\(c(T_1)=c(T_0)\\).\n\nSuppose we have constructed tree \\(T_i\\). If \\(e_{i+1}\\) is in \\(T_i\\), let \\(T_{i+1}=T_i\\). Otherwise, add edge \\(e_{i+1}\\) to \\(T_i\\). This creates a cycle, one of whose edges, call it \\(f_{i+1}\\), is not in \\(e_1, e_2,\\ldots,e_i\\) and has exactly one endpoint in \\(\\{v_0,\\ldots,v_i\\}\\). Remove \\(f_{i+1}\\) to create \\(T_{i+1}\\). Since the algorithm added \\(e_{i+1}\\), \\(c(e_{i+1})\\le c(f_{i+1})\\). If \\(c(e_{i+1})< c(f_{i+1})\\), then \\(c(T_{i+1})< c(T_i)=c(T_m)\\), a contradiction, so \\(c(e_{i+1})=c(f_{i+1})\\) and \\(c(T_{i+1})=c(T_i)\\)."}
{"text": "Retrieved from https://www.physicsforums.com/threads/f-ma-2009-14-momentum-quick-conceptual-question.667948/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nF = MA 2009 # 14 (Momentum Quick Conceptual Question)\n\n  1. Jan 29, 2013 #1\n    See # 14\n\n    2. Relevant equations\n    None really, perhaps keep in mind that\n    1) p is conserved in the absence of external forces\n    2) L is conserved in the absence of external torque\n    3) Mech E is conserved if no energy is lost due to external forces\n\n    3. The attempt at a solution\n    I'm not sure how to attack this problem. My reasoning was that the bullet, as it is embedded into the block, has most of its velocity absorbed by the interior of the block (not rigorous at all). This means that the block does not move at the velocity it should and thus all A, B, C, D are false.\n\n    How can I do this rigorously?\n  2. jcsd\n  3. Jan 29, 2013 #2\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    14. A wooden block (mass M) is hung from a peg by a massless rope. A speeding bullet (with mass m and initial speed v0) collides with the block at time t = 0 and embeds in it. Let S be the system consisting of the block and bullet. Which quantities are conserved between t = \u221210 s and t = +10 s?\n\n    (A) The total linear momentum of S.\n    (B) The horizontal component of the linear momentum of S.\n    (C) The mechanical energy of S.\n    (D) The angular momentum of S as measured about a perpendicular axis through the peg.\n    (E) None of the above are conserved.\n\n    ... and then what happens?\n\n    Usually it is quicker to take each option one at a time.\n    But you have a nice list ...\n    ... \"external\" to what? Anyway - rephrase your list as questions:\n\n    1. are their any external forces to the system being brought to bear?\n    2. are their any external torques to the rotating part?\n    3. is their any energy loss (note: does not have to be due to \"external forces\")?\n    ... from those answers you have characterized the system so the options will make sense.\n\n    Science is not about knowing answers, it is about asking uncomfortable questions.\n    Learning how to ask hard questions is basically the main point of science education.\n  4. Jan 29, 2013 #3\n    I thought\n    1) no external forces\n    2) no external torque\n    3) energy loss due to heat/friction inside the block\n\n    So the fact that there's an energy loss due to thermal energy negates everything?\n  5. Jan 30, 2013 #4\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    Well... no: that's not what your list is telling you. You can conserve momentum and not (mech) energy ...\n\n    You want to take another look at #2, at t<0 what is the angular momentum? What is it at t>0? Are these numbers the same?\n\n    Now compare your answers to the three questions with each option provided.\n    Last edited: Jan 30, 2013\n  6. Jan 30, 2013 #5\n\n\n    User Avatar\n\n    UPDATE: I had misread the problem, nevermind what I said before :P\n\n    UPDATE2: I read it right, I erased my comment for nothing \u00ac\u00ac Will re-write. Sorry.\n\n    Something like that: In these \"simple\" problems, forces essentially come from gravity or contact. An external force will come from contact to the external world (or existance of gravity with an external object), and an external torque will have to be produced by that external force.\n\n    Is any part of the system (bullet + block) in contact to the external world (rope, Earth, etc.)? Does if feel a force from those parts? Does this force produce a torque about an axis through the peg? :)\n\n    Also, notice that the problem considers a \"long\" time interval before and after the collision. Try to visualize how the system will behave when the block is hit by the bullet, it really helps!\n    Last edited: Jan 30, 2013\n  7. Jan 30, 2013 #6\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    Case in point - let the bullet be mass m and speed v\n    block is mass M, initial speed 0\n    if the final speed of m+M is u, then:\n\n    conserving momentum: ##mv = (m+M)u##\n\n    this means that ##u=mv/(m+M)##\n    ... so the final speed is slower than the initial speed like you intuited - but the overall momentum still stays the same.\n\n    now look at the kinetic energy:\n\n    initially: ##K_i = \\frac{1}{2}mv^2##\n    finally: ##K_f = \\frac{1}{2}(m+M)u^2 = \\frac{1}{2}(m+M)[mv/(m+M)]^2 =\\frac{1}{2}(mv)^2/(m+M)##\n\n    comparing them: $$\\frac{K_f}{K_i} = \\frac{m}{m+M}$$ i.e. ##K_i > K_f## and kinetic energy is not conserved even though momentum is.\n\n    What happened to it?\n    Well it got lost in heat, sound and so on... which was your original thought.\n\n    Note: fgb has a valid point about how gravity (etc) applies here though - modifying the above.\n  8. Jan 30, 2013 #7\n\n\n    User Avatar\n\n    At first I had thought that the correct answer was D. Since as the block moves it feels a force due to the rope (which has a horizontal component after the rope tilts a little) there are external forces and no conservation of linear momentum. Tricky question since you are told to consider a fairly large time interval - momentum is still conserved during and short after the collision, but not a little later as the block moves.\n\n    Mechanical energy is lost in the collision due to deformation, as the bullet sticks inside the block.\n\n    The force due to the rope (the external force), also, always passes through the axis, so it does not produce an external torque and at first I thought angular momentum is conserved. However, taking gravity into account, gravity indeed produces an external torque and therefore no quantity is conserved, so I would say the correct answer is E.\n  9. Jan 30, 2013 #8\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    Actually the question kinda defines \"before\" as at the instant t=-10s, and \"after\" as the instant t=+10s. Anyhow: if we include gravity - then there is an external force messing with the system. Anything with momentum being conserved will get messed up. That leaves energy - but the collision is inelastic - and \"none of the above\".\n\n    I had misread the question - I thought it referred to the collision at t=0, which is where it usually appears.\n\n    To be super-rigorous, you'd have to construct the equations for each case.\n    However, most of the questions in this paper can be tackled by just going through each of the alternatives one at a time after stopping to think of the processes involved. There's usually two options that look likely, which is where you look harder.\n\nSimilar Discussions: F = MA 2009 # 14 (Momentum Quick Conceptual Question)\n  1. 2009 f=ma #24 (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inequalities-with-two-different-fractions-which-include-x-in-the-denominator.664277/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nInequalities with two different fractions which include x in the denominator.\n\n  1. Jan 14, 2013 #1\n\n    (x-2)/(x+3) less than (x+1)/(x)\n\n    3. The attempt at a solution\n\n    I broke it up into cases.\n\n    When x+3 less than 0 and x less than 0\n\n    and then when both are positive, when one is positive and the other is negative and then the other way around.\n\n    I'm not sure if that's the right way though. I was thinking that maybe you can say:\n\n    (x+3)(x) less than 0\n\n    and a second case\n\n    (x+3)(x) greater than 0\n  2. jcsd\n  3. Jan 14, 2013 #2\n    (x+3) and x are not independent. You have to consider the value ranges of x.\n\n    Perhaps a good place to start is to consider the value of each expression as they pass the \"difficult\" value of x in each case, and how those behave as x is large-negative and large-positive in each case again.\n\n    There are three relevant ranges of x, one of which is a little trickier than the other two.\n  4. Jan 14, 2013 #3\n    So you mean to say x\u2260-3 and x\u22600 and x\u2260 some other number?\n  5. Jan 14, 2013 #4\n    One of the ranges is x < -3\n  6. Jan 14, 2013 #5\n    You mean x < -3 is not in the 'solution set' right? x is -4 makes it not a true statement.\n\n    After trying the first method again (the textbook's method except they didn't show any examples with two fractions both with x in the denominator) I found that x > -3 , x cannot equal -1/2 , 0\n  7. Jan 14, 2013 #6\n    x can equal anything. Of the two expressions being considered in the question, each one is undefined at one value of x (which you already have indicated you know).\n\n    {x<-3} is a range of values where both expressions are well-defined. You might like to explore this range with some values of x (like -4, -5, -10) to see how the functions are behaving.\n  8. Jan 14, 2013 #7\n    When you input -4 for x, you get 6 < 0.75 which means that x < -3 is not a part of the solution right?\n\n    When you input -1/2 for x, you get -1 < -1 which again is not true.\n\n    Although plugging values is good to check answers, I wanted to know if my method was correct. I don't have the answer to this question though.\n\n    What I did was solve for x under all circumstances. When x+3 > 0 and x > 0 and then when x+3 < 0 and x < 0 and then when x+3 > 0 but x < 0 then when x+3 < 0 and x > 0\n\n    The idea behind this is that when solving for x, multiplying by -(x+3) or -(x) would switch the inequality sign. So the possibility that one or the other or both are positive or negative becomes an issue. Is this a correct way to solve this inequality?\n  9. Jan 14, 2013 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    It seems a lot easier to write [itex]\\displaystyle \\ \\ \\frac{x-2}{x+3}<\\frac{x+1}{x}[/itex]\n\n    as the equivalent inequality: [itex]\\displaystyle \\ \\ \\frac{x-2}{x+3}-\\frac{x+1}{x}<0\\ .[/itex]\n\n    Then use a common denominator to combine the two fractions into one fraction.\n  10. Jan 14, 2013 #9\n    Don't you still have to consider that x + 3 and x could be negative?\n  11. Jan 14, 2013 #10\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, it is really the same thing.\n\n    Well, x+3< 0 is the same as x< -3 and, then, of course, x< 0.\n    The three cases you want to consider are\n    x< -3 when x+3< 0 and x< 0 are BOTH true.\n\n    [itex]-3\\le x< 0[/itex] when [itex]x+ 3\\le 0[/itex] and x< 0.\n\n    [itex]0\\le x[/itex] when both x+3> 0 and [itex]x\\ge 0[/itex].\n  12. Jan 14, 2013 #11\n    Yes, I quickly found out that when both are negative and when x+3<0 and x>0 there are no solutions. Maybe in the future I will have the instinct to realize that from the start. But for now I am just trying to get the medthod down.\n\n    I got the same answer by putting both terms together and finding the commoj denomintor. Surely the answer must be correct.\n\n    I thank you all for your help in rehabilitating my mathematics.\n  13. Jan 15, 2013 #12\n    You're not done yet.\n\n    It's possible to establish the answer for the ranges {x<-3} and {x>0} just by considering function values relative to 1 (= x/x).\n\n    However, the intermediate range {-3<x<0} is more complicated. Look at both function values at -2.9 and at -0.1 which should tell you there is more to discover.\n    Last edited: Jan 15, 2013\n  14. Jan 15, 2013 #13\n    Are you supposed to state that there are asymptotes at -3 and 0 ?\n\n    x cannot be -1/2 is that what you're referring to?\n  15. Jan 15, 2013 #14\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    The resulting inequality is: [itex]\\displaystyle \\ \\ \\frac{-6x-3}{x(x+3)}<0\\ .[/itex]\n\n    This simplifies to: [itex]\\displaystyle \\ \\ \\frac{2x+1}{x(x+3)}>0\\ .[/itex]\n\n    You have three factors, one in the numerator and two in the denominator. Either all three must be positive, or one must be positive and two of them negative.\n  16. Jan 15, 2013 #15\n    There is another range for x which satisfies the condition.\n\n    Both original expressions - and the combined expression too - are valid for ##x = -\\frac 12##\n\n    SammyS's simplified expression can also be expressed as $$ \\frac{x+\\frac 12}{x(x+3)}>0 $$\n  17. Jan 15, 2013 #16\n    It seems like I kept making careless errors. Thank you all for being patient with me.\n\n    -3 < x < -1/2 , x > 0\n\n    That should be the right answer.\n  18. Jan 16, 2013 #17\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    You want to determine when [itex](x-2)/(x+3)< (x+1)/(x)[/itex].\n\n    As I said before, since we clearly want to multiply both sides by x+ 3 and x, to clear the fractions, we need to consider when they are positive of negative. So consider 3 cases:\n    1) x< -3. Then both x+ 3 and x are negative. Multiplying the above inequality by x(x+ 3) is multiplying by a positive number (the product of two negatives) so the direction of inequality does not change. [itex](x- 2)(x)< (x+ 3)(x+ 1)[/itex]. [itex]x^2- 2x< x^2+ 4x+ 3[/itex]. Subtract [itex]x^2[/itex] from both sides to get [itex]-2x< 4x+ 3[/itex] so that [itex]0< 6x+ 3= 3(x+ 1)[/itex]. Dividing both sides by the positive number 3, we have [itex]0< x+ 1[/itex] or [itex]x< -1[/itex] which can't happen when x< -3.\n\n    2) -3< x< 0. Now x+ 3 is positive but x is still negative. Multiplying both sides by x(x+ 3) is now multiplying by a negative number and changes the direction of the inequality: [itex](x- 2)(x)> (x+ 3)(x+ 1)[/itex]. The same calculations as before go through with the changed inequality sign: [itex]x< -2[/itex]. That tells us that the orignal inequality is true for [itex]-3< x< -2[/itex].\n\n    3) x> 0. Now both x+ 3 and x are positive so j=multiplying both sides of the inequality by x(x+ 3) does not change the sign: [itex](x- 2)(x)< (x+ 3)(x+ 1)[/itex] and again we get [itex]x> -1[/itex]. Of course that is true for all x> 0 so we have the inequality true for all x> 0.\n\n    We have, so far, that the inequality is true for -3< x< -2 and x> 0. You should also check to see if it is true at x= -3, x= -2, and x= 0.\n    Last edited: Jan 17, 2013\n  19. Jan 16, 2013 #18\n    I think you made a mistake in the firsf case where you ended up with 3(x+2)\n\n    Also the question didn't include any inequality symbols with equal signs. (No line under the inequality is what I mean.\n  20. Jan 17, 2013 #19\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Oh, bother! Thanks. I have gone back and edited my post.\n  21. Jan 17, 2013 #20\n    ## (x\u22122)(x) > (x+3)(x+1) ##\n\n    ## x^2-2x > x^2 +4x +3 ##\n\n    ## -2x > 4x +3 ##\n\n    ## 0 > 6x +3 ##\n\n    ## x < -\\frac 36 = -\\frac 12 ##"}
{"text": "Retrieved from https://www.physicsforums.com/threads/unitarily-equivalent.591586/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nUnitarily equivalent\n\n  1. Mar 29, 2012 #1\n    I've had the flu all week.\n\n    Of course, the book defines unitary equivalent, but it doesn't talk about an efficient method of determining if two matrices are unitarily equivalent.\n\n    Is there an efficient way to determine if these matrices are unitarily equivalent?\n\n    0 & 1 & 0\\\\\n    -1 & 0 &0 \\\\\n    0 &0 &1\n\n    1 & 0 & 0\\\\\n    0 & i &0 \\\\\n    0 &0 &-i\n  2. jcsd\n  3. Mar 29, 2012 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n    2016 Award\n\n    You can easily find the eigenvalues, no?\n  4. Mar 29, 2012 #3\n    How does that relate to unitary equivalence?\n  5. Mar 29, 2012 #4\n    I found that A and B are unitarily equivalent if they have the same sets of eigenvalues, counting multiplicity.\n\n    A = P*BP (unitarily equivalent)\n\n    det(A) = det(P*BP) = det(P*)det(B)det(P) = det(P*)det(P)det(B) = det(B)\n    det(A) = det(B)\n\n    Their characteristic polynomials must be equal.\n  6. Mar 29, 2012 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    No, that is not true. The matrices\n    [tex]A= \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}[/tex]\n    [tex]B= \\begin{bmatrix}1 & 1 \\\\ 0 & 1\\end{bmatrix}[/tex]\n    have the same eigenvalues (1 with multiplicity two) but are not unitarily equivalent because they do not have the same eigenvectors. A has every vector as eigenvector while B has only multiples of <1, 0> as eigenvectors.\n\n    Two matrices are \"unitarily equivalent\" if and only if they have the same eigenvalues and the same corresponding eigenvectors.\n\n  7. Mar 29, 2012 #6\n    Okay, so I found the eigenvalues of each of the matrices: 1, -i, +i. Now I have the tedious job of finding the eigenvectors. -_-\n  8. Mar 29, 2012 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Halls is definitely wrong to say that they have to have the same eigenvectors. You just have to have the same number of linearly independent eigenvectors for every eigenvalue. You have three distinct eigenvalues. That means you don't have to compute the eigenvectors. Why?\n    Last edited: Mar 29, 2012\n  9. Mar 29, 2012 #8\n    Ah, you're right. The dimensions of the eigenspaces are equal - 3."}
{"text": "Retrieved from https://www.physicsforums.com/threads/integration-by-parts.68260/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntegration by parts\n\n  1. Mar 22, 2005 #1\n    ok i`m really struggling with the concept.\n    I've been asked to find the indefinite integral of;\n\n    [tex] \\int \\frac{x^2}{(2+ x^3)} dx [/tex]\n\n    so before i beg for the answer could someone confirm that i`ve got the right rule to solve this;\n\n    [tex] \\int u(x) v'(x) = [ u(x) v(x)] - \\int v(x) u'(x) [/tex]\n\n    if this is right would you mind giving a suggestion to what u(x) to use?\n\n    p.s. i may have to edit this if latex doesn`t come out right I've been having trouble with it and only jointed the forum a few day's ago!\n    Last edited: Mar 22, 2005\n  2. jcsd\n  3. Mar 22, 2005 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, that is the correct formula (it's surely in your text book), but I don't see any good reason for using integration by parts. That's a fairly standard anti-derivative: look up \"arctangent\".\n  4. Mar 22, 2005 #3\n    I`ve just edited it. Now it`s integration by parts! see I`m getting all flustered\n  5. Mar 22, 2005 #4\n    Actually, you still don't need integration by parts. Substituting [itex]u = x^3[/itex] will simplify it to a standard form.\n\n    Anyways, since differentiation is in some sense the inverse operation to integration, every differentiation rule yields an integration rule. I'm sure you remember the product rule:\n\n    [tex] \\frac{d}{dx}(f(x) g(x)) = f^\\prime (x) g(x) + g^\\prime (x) f(x)[/tex]\n\n    Rearraging the equation above gives\n\n    [tex] f(x) g^\\prime (x) = \\left[f(x) g(x)\\right]^\\prime - f^\\prime(x)g(x)[/tex]\n\n    And integrating both sides with respect to x gives\n\n    [tex] \\int f(x) g^\\prime (x) \\ dx = \\int \\left(\\frac{d}{dx} (f(x) g(x)) - f^\\prime(x)g(x)\\right) \\ dx[/tex]\n\n    but certainly, [tex] \\int \\frac{d}{dx}(f(x)g(x)) \\ dx = f(x)g(x)[/tex], so this just reduces to\n\n    [tex] \\int f(x)g^\\prime (x) \\ dx = f(x)g(x) - \\int g(x) f^\\prime (x) \\ dx[/tex]\n\n    which is what your teacher probably called the formula for integration by parts.\n    Last edited: Mar 22, 2005\n  6. Mar 22, 2005 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    [tex] x^{2}dx=\\frac{1}{3}d(2+x^{3}) [/tex] so the integration is simple...\n\n  7. Mar 22, 2005 #6\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    As others have said, you don't have to use integration by parts to solve this, but .....\n\n    Pick the term whose derivative will eventually go to zero (the soonest). In this case, it's x^2. First derivative is 2x. Second derivative is 2. Third derivative is 0.\n\nSimilar Discussions: Integration by parts"}
{"text": "Retrieved from https://www.physicsforums.com/threads/composition-of-infinite-deformation-retracts.620651/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nComposition of infinite deformation retracts\n\n  1. Jul 13, 2012 #1\n    I'm trying to give an answer to the following problem, I hope someone could come in help! Consider a smooth [itex]n[/itex]-dimensional manifold [itex]M[/itex] with smooth (nonempty) boundary [itex]\\partial M[/itex], and suppose given a function [itex]f: M\\setminus \\partial M \\to \\mathbb{R}[/itex] (which one can assume to be differentiable) satisfying the property that there exists [itex]A > 0[/itex] such that for any [itex]A \\le \\alpha \\le \\beta[/itex], one has that the sublevel [itex]\\left\\{F\\le -\\beta\\right\\}[/itex] is a deformation retract of [itex]\\left\\{F\\le -\\alpha \\right\\}[/itex]. The question is: is it true that [itex]\\partial M[/itex] is a deformation retract of [itex]\\left\\{F\\le -A\\right\\}\\cup \\partial M[/itex] (i.e., is it true that a composition of infinitely many of such deformation retracts is a deformation retract)?\n  2. jcsd\n  3. Jul 14, 2012 #2\n    I don't have a full answer for you, but as a rule of thumb, infinite compositions of maps don't necessarily retain the properties of the individual maps. I think in this case a compactness argument might work, although I think either I'm missing something from your statement, or it's incomplete. Do we know what [itex]f\\big|_{\\partial M}[/itex] is? I was assuming it's identically zero, but I realize the problem doesn't say, nor does it say anything about what happens on the levels between zero and A.\n  4. Jul 15, 2012 #3\n    First of all, thank you for your reply. Next, you're right, I forgot an hypothesis that could be crucial: [itex]f(p)\\to -\\infty[/itex] as [itex]p[/itex] approaches the boundary [itex]\\partial M[/itex]. Could this do any difference?\n    Maybe, (but I don't know if this makes any sense...) an idea could be to work with the extended function [itex]\\hat{f}: M \\to \\mathbb{R}^*[/itex], where [itex]\\mathbb{R}^*:=\\mathbb{R}\\cup \\left\\{\\infty\\right\\}[/itex] (the Alexandroff compactification of [itex]\\mathbb{R}[/itex]), [itex]\\hat{f}(p):=f(p)[/itex] if [itex]p \\in M\\setminus \\partial M[/itex] and [itex]\\hat{f}:=\\infty[/itex] if [itex]f \\in \\partial M[/itex] (hoping that this [itex]\\hat{f}[/itex] inherits some regularity from [itex]f[/itex]...). In this way, [itex]\\partial M[/itex] would become the level [itex]\\left\\{f=\\infty\\right\\}[/itex]...\n  5. Jul 15, 2012 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Slice the north polar ice cap off of a sphere to get a manifold with boundary. Then remove the South pole. Let f be the reciprocal of the minimum of the distances along a great circles to the South pole and to the edge of the removed polar cap. This function is continuous and f(p) -> -\u221e as p approaches the edge of the removed ice cap.\n\n    But but the set,\n\n    f < - the distance of the meridian where both distances are the same\n\n    does not deform onto the edge circle of the ice cap.\n\n    it seems that you need to assume that f(p) -> -\u221e if and only if p approaches the boundary.\n    Last edited: Jul 15, 2012\n  6. Jul 15, 2012 #5\n    I really apologize with all of you for the incompleteness of the provided hypothesis. Actually, the manifold [itex]M[/itex] is simply connected as well as its boundary [itex]\\partial M[/itex], and these restrictions seems to exclude the latter counterexample (if I'm not wrong).\n    And (finally) these are all the hypothesis I have...\n\nSimilar Discussions: Composition of infinite deformation retracts\n  1. Deformation retract (Replies: 9)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/equations-of-speed-and-position-under-a-constant-force.86698/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEquations of speed and position under a constant force\n\n  1. Aug 28, 2005 #1\n    there's a question in my book that says \"If you jump upward with a speed of 2 m/s, how long will it take before you stop rising?\" anyone have a hint as to how i would go about answering this?\n  2. jcsd\n  3. Aug 28, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Use the equations of speed and position under a constant force (in this case the gravitational force).\n\n    v(t) = v_0 + a*t\n    x(t) = x_0 + v_0*t + 0.5at\u00b2\n  4. Aug 29, 2005 #3\n    Assuming no air resistance, right?\n    Since you're jumping [itex] vertically [/itex],\n    *Set your initial position at y=0, then apply that equation\n    [tex] y\\left( t \\right) = t\\left( {2\\frac{m}{s}} \\right) - \\frac{{t^2 }}{2}\\left( {9.8\\frac{m}{{s^2 }}} \\right) [/tex].\n    Simply then, set [itex] y\\left( t \\right) = 0s [/tex] to find your jump duration (*Note: [itex] t \\ne 0s [/itex] :smile: )\n\n    The answer is 0.41 seconds :biggrin:\n  5. Aug 29, 2005 #4\n\n\n    User Avatar\n    Homework Helper\n\n    1) Bomba's \"jump duration\" is 2x as long as the\n    duration of upward travel. No big deal ...\n\n\n    2) It is important to find out how to READ the WORDS of a question!\n    Otherwise it's going to be a long, hard, confusing, frustrating year.\n    The key is knowing what event-condition tells you to stop timing...\n    here, \"stop rising\" is translated into \"upward speed = 0\".\n\n    So Quasar's first equation is all you need to answer this question.\n    Bomba's approach will get you the right answer\n    (if you divide by 2, and if there's no air resistance)\n    but can't be generalized to, say, when does a police car catch up.\n    Quasar's APPROACH even works (slight mod of eq'n) if there IS drag."}
{"text": "Retrieved from https://www.physicsforums.com/threads/y-x-2-1-and-y-x-2-tangent.67554/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nY=(x^2) +1 and y = - (x^2)? tangent\n\n  1. Mar 16, 2005 #1\n    Find the equations of the lines that are tangent to both curves simultaneously:y=(x^2) +1 and y = - (x^2)? :eek:\n  2. jcsd\n  3. Mar 16, 2005 #2\n    Find the equations for the tangent lines to both curves and set them equal to each other. You will find when the slope of the tangents are equal and then can make an equation(s) of of it.\n  4. Mar 17, 2005 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Jameson is correct but it's a bit more complicated than he implies.\n\n    Suppose a line is tangent to y= x2+ 1 at (x0,x02+ 1) and tangent to y= -x2 at (x1,-x12).\n    Any (non-vertical) line can be written as y= mx+ b. m is equal to the derivative of the functions at the given points: m= 2x0= -2x1 so x1= -x0. We must have x02+1= (2x0)x0+ 1 or b= 1- x02. We must also have -x12= (-2x1)x1+ b or b= x12. That is, b= x12= 1- x02. But since x1= -x0, x12= x02 so 1- x02= x02.\n\n    Solve that for x0 and then you can find m and b.\n\n    Because of the squares, there are, of course, two symmetric solutions,.\n    Last edited: Mar 17, 2005\n\nSimilar Discussions: Y=(x^2) +1 and y = - (x^2)? tangent\n  1. Integral of 2/(y+1)? (Replies: 4)\n\n  2. Integrate ln(4+y^2)dy? (Replies: 8)\n\n  3. D/dx y^2 help (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/investigating-max-and-min-value-of-a-function.222944/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nInvestigating max and min value of a function\n\n  1. Mar 19, 2008 #1\n\n    [tex] f(x) = (1/2)sin2x + cosx [/tex]\n\n\n    [tex] f^2 min +f^2 max = ? [/tex]\n\n    2. Relevant equations\n\n    Differentiation not allowed... only by transformations and analysis.\n\n    3. The attempt at a solution\n\n    I am confused by what it means by f^2 min +f^2 max... does it imply we have to find max and min values seperately, square them and add them? Or does this formulation imply we can directly get the required value?\n\n    Do we have to square the function before investigating it?\n  2. jcsd\n  3. Mar 20, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n\n    I think what they're asking you to do is find the sum of the squares of the maximum and minimum values of this function.\n\n    I'd suggest first writing out what sin(2x) is: you'll find that f(x) can be expressed as a product of two factors. It should be reasonably straightforward to see what the greatest and least values of that product are. Can f(x) be zero?\n  4. Mar 20, 2008 #3\n    you need to take the derivative of that..\n\n\n    after that you solve f'(x)=0\n    find the extreme points and put the y values in the asked equation\n\n  5. Mar 20, 2008 #4\n\n\n    User Avatar\n    Homework Helper\n\n    The problem statement says no differentiation allowed...\n\n    (If it were, the derivative would be f'(x)=1*cos2x - sinx .)\n    Last edited: Mar 20, 2008\n  6. Mar 21, 2008 #5\n    i'm getting\n\n    [tex]f(x) = cosx(1+sinx)[/tex]\n\n    ok i got min value = 0 (the problem says 0 <= x <= pi/2)\n    how do we get the max value of the product?\n  7. Mar 21, 2008 #6\n    you have a point in x=pi/2 +pi*k\n    and for x=3/4*pi +2pi*k\n\n    substitute them in the fuction and find their y values\n    Last edited: Mar 21, 2008\n  8. Mar 21, 2008 #7\n    how does that work?\n  9. Mar 21, 2008 #8\n\n\n    User Avatar\n    Homework Helper\n\n    If the interval is [0, pi/2], then you don't have to worry about the other periodic values of sine and cosine. (You didn't mention the interval earlier...)\n\n    The minimum is zero at pi/2 because of the cosine term. For the maximum, you could either look at the terms in f(x) or square your result for f(x) first. In any case, using x = 0 would give you\n    f(0) = 1, but there's a place where we can do better. The problem with the endpoints is that sine is high when cosine is low and vice versa. What value of x gives both fairly high values for sine and cosine? (Consider graphs of those functions.)\n  10. Mar 22, 2008 #9\n    pi/4 gives equal values for sine and cosine... however, how do we know there isn't a value thats higher? i think there may be a more rigorous proof...\n\n    e.g. on another similar problem i could obtain a quadratic equation containing f(x) in a constant term (by squaring function) and getting something like:\n\n    [tex] ax^2 +bx + c = f^2(x) [/tex]\n\n    [tex] ax^2 +bx + (c - f^2(x)) = 0 [/tex]\n\n    [tex] b^2 - 4a(c - f^2(x)) >or= 0 [/tex] (for real f(x))\n\n    thus obtaining min and max values simultaneously...\n\n    on this example, on squaring i get a quartic equation on sin(x)... i'm unable to bring it to a simpler (quadratic) form or otherwise...\n    Last edited: Mar 22, 2008\n  11. Mar 22, 2008 #10\n\n\n    User Avatar\n    Homework Helper\n\n    Maybe we shouldn't look at the quartic polynomial, but rather the factored form. The function squared is\n\n    [tex] (cos x)^{2} (1+sin x)^{2} = (1 - [sin x]^{2})(1+sin x)^{2} = (1 - sin x)(1+sin x)^{3}\n\n    So we make the substitution t = sin x and ask for the maximum on the interval [0,1] of\n\n    [tex] (1 - t)(1+ t)^{3}\n\n    [I'm still thinking about how to solve this without calculus. (The maximum turns out to occur at sin x = 1/2 , BTW, not {sqrt(2)}/2 , as I'd earlier thought.) The instruction \"use transformations and analysis\" isn't very descriptive, so I'm still trying out ideas...]\n    Last edited: Mar 22, 2008\n\nHave something to add?\n\nSimilar Discussions: Investigating max and min value of a function"}
{"text": "Retrieved from http://math.stackexchange.com/questions/23228/which-is-bigger-9999999999-or-9/23235\nText:\nTake the 2-minute tour \u00d7\n\nIn my classes I sometimes have a contest concerning who can write the largest number in ten symbols. It almost never comes up, but I'm torn between two \"best\" answers: a stack of ten 9's (exponents) or a 9 followed by nine factorial symbols. Both are undoubtedly huge, but I haven't been able to produce an argument that one is larger (surely they aren't equal). Any insight into which of these two numbers is bigger would be greatly appreciated.\n\nshare|improve this question\nYou can always define new symbols which give you higher number than before. You want perhaps to limit your alphabet to digits, addition, multiplication, exponentiation, factorial. \u2013\u00a0 Asaf Karagila Feb 22 '11 at 15:20\nTry taking the logarithm several times, estimating the results using Stirling's formula: en.wikipedia.org/wiki/Stirling's_approximation \u2013\u00a0 Qiaochu Yuan Feb 22 '11 at 15:30\n@Fdart17: $9^{999999999}$ is enormously smaller than the exponential tower of ten 9s, which is the number being considered here. \u2013\u00a0 Chris Eagle Feb 22 '11 at 15:35\nDepending on what you're willing to allow without bracketing, neither of these is the best you can do with these symbols. $9!!!!!!!!!$ is smaller than $9^9!!!!!!!!$, while (tower of ten 9s) is smaller than (tower of nine 9s)!. \u2013\u00a0 Chris Eagle Feb 22 '11 at 15:38\n\"(surely they aren't equal)\": One way to see that the exponential tower is not equal to 9!!!!!!!!! is to note that the first is odd and the second is even. \u2013\u00a0 Jonas Meyer Feb 22 '11 at 18:58\n\n3 Answers 3\n\nup vote 33 down vote accepted\n\n$n!$ grows more rapidly than $9^n$ (it grows approximately with $n^n$), so eventually it wins out; in fact, a few moments with Wolfram Alpha suggests that for all $n\\gt 21$, $n! \\gt 9^n$. This means that the best solution is mixed: after the first exponentiation (since $9^9$ is greater than $9!$), you're better off using factorials, giving the answer $9^9!!!!!!!!$. (Also, note that we're all assuming that the correct parentheses here are implicit, since there's a big difference between $\\left(9^9\\right)^9$ and $9^{\\left(9^9\\right)}$.)\n\nOn the other hand, if you're allowed to use more-or-less stock mathematical notation, you may want to have a look at Knuth's arrow notation; $9\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow9$ is bigger by far than the rest of these. (And numbers even larger than this have come up in mathematics - have a look, for instance, at Graham's Number, which most conveniently uses the arrow notation in its definition.)\n\nEDIT: In fact it's pretty straightforward to prove that the answer in the first paragraph, $9^9!!!!!!!!$, is the best that can be done (with these operations). First, as long as $a$ is at least two symbols (for this group of symbols), then $a^9 \\lt 9^a\\lt a!$, so adding a factorial symbol is always going to be better than adding a $9$ onto your tower. But what about structures like $9!^{9!}$? Well, if both $a$ and $b$ are at least two symbols long, then $a^b\\lt \\mathrm{max}(a,b)!!$; assuming for the moment that $b$ is larger (because if $a$ were larger, then $b^a\\gt a^b$), then $b! \\approx b^b$, and while this isn't enough to ensure that it's greater than $a^b$ (consider the case where $a$ = $b$ = $9!$), it's close enough that we can be certain taking a second factorial will be larger - so those extra symbols you spent on exponentiation should retroactively have just gone into more exclamation points, and this is enough to guarantee that $9^9!!!!!!!!$ is the largest possible combination of these particular operations.\n\nshare|improve this answer\nWhat do you mean by \"so eventually it wins out\" ? Of course I agree that $9^9!!!!...$ is best possible, but what about the original structures the OP is asking about? I think you can you prove that for any number of characters $n$, the power tower of nines will be larger than the iterated factorials. \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:38\n+1 for mentioning Grahams Number. I always have little chuckle when I see it's definition. \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:50\nSorry - by 'eventually it wins out' I just meant that for some n, n! will be greater than 9^n - but as Jonas points out, that doesn't imply that the iterated-factorial will be larger than the iterated-exponential with one additional iteration. \u2013\u00a0 Steven Stadnicki Feb 22 '11 at 18:14\n\nWolfram Alpha shows $$9^{9^9}\\approx 10^{10^{8.56}}$$ while $$(9!)! \\approx 10^{10^{6.26}}$$ Adding another character adds another 10 to the bottom of the stack without changing the upper exponent much at all. It will even do the full stack of 10. The exponents have 8.5678 atop the tower of 10's, while the factorials have 6.26949. So the exponents win.\n\nAdded: In Douglas Hofstadter's May, 1982 column \"On Number Numbness\" he declares these essentially equal. For numbers of this size, the first thing you should look at is how many times you have to take a log to make it reasonable, which is 9 for both of them. Then look at the number on top of the stack, which is the only one that matters. So it is like 9.85678 compared with 9.626949, which are very close.\n\nshare|improve this answer\n+1 for being the only one to answer the OP's original question, namely that the tower of nines is larger than the factorials. In fact, I think you can you prove it is true no matter how many times we iterate. That is for any number of characters, say $n$, the power tower of nines will be larger than the iterated factorials. (I find that shocking since factorials is basically $n^n$) \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:32\nI have to admit, I find this really surprising too, but no less impressive for it! \u2013\u00a0 Steven Stadnicki Feb 22 '11 at 18:26\nFor comparison $(9^9)! \\approx 10^{10^9.5}$ \u2013\u00a0 Henry Feb 22 '11 at 18:27\n@Eric: thanks for noticing. Sometimes these questions take on a life of their own, but there was an original question that prompted it. \u2013\u00a0 Ross Millikan Feb 23 '11 at 3:25\n$9!!!$ is roughly $(10^{10^{6.26}})^{10^{10^{6.26}}}$, much greater than $9^{10^{10^{8.56}}}$ (most likely), so adding a character (a factorial in one case and an exponent to the tower in the other), seems to favor factorials here by quite a bit. \u2013\u00a0 Mitch May 14 '11 at 17:51\n\nA thorough study of this question is given in the article \"Exponential vs. Factorial\" by Velleman (American Mathematical Monthly Vol. 113, No. 8, Oct. 2006, pp. 689-704). In the motivating example there are 5 characters instead of 10. Of course, the conclusion is the same as in Steven Stadnicki's answer, that $9^9!!!!!!!!$ (or $9^9!!!$ in the case of 5 characters) is the largest possible.\n\nThe article also addresses your original question, proving that the exponential tower of $n$ $9$s is always larger than a $9$ with $n-1$ factorials applied (and many more general statements).\n\nshare|improve this answer\nExcellent answer! +1! No need to say more. \u2013\u00a0 Eric Naslund Feb 22 '11 at 18:00\n@Eric: Thanks. I just knew where to look because I remembered skimming the article when that Monthly was new. \u2013\u00a0 Jonas Meyer Feb 22 '11 at 18:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/22461/verifying-carmichael-numbers\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to understand a solution I was given in a tutorial regarding a problem with Carmichael numbers and I was wondering if you guys can help clarify things:\n\nA composite number $m$ is called a Carmichael number if the congruence $a^{m-1} \\equiv 1 \\pmod{m}$ is true for every number a with $\\gcd(a,m) = 1$.\n\nVerify that $m = 561 = 3 \\times 11 \\times 17$ is a Carmichael number.\n\nSolution given:\n\nApply Fermat's Little Theorem to each prime divisor of $m$: \\begin{align*} a^2 &\\equiv 1 \\pmod{3}\\\\ a^{10} &\\equiv 1 \\pmod{11}\\\\ a^{16} &\\equiv 1 \\pmod{17} \\end{align*} This somehow then implies that $a^{80} \\equiv 1 \\pmod{561}$ then accordingly $a^{560} \\equiv 1 \\pmod{561}$.\n\nI am lost as to how the 3 congruences imply $a^{80} \\equiv 1 \\pmod{561}$ ($80 = \\mathrm{LCM}(2,10,16)$).\n\nCan somebody clarify this for me?\n\n\nshare|improve this question\nfor equivalence, use \\equiv and put your $LaTeX$ in dollar signs. So you would write a^2 \\equiv 1 \\pmod 3 and get $a^2 \\equiv 1 \\pmod 3$ \u2013\u00a0 Ross Millikan Feb 17 '11 at 15:33\n\n2 Answers 2\n\nup vote 8 down vote accepted\n\nNote that $80 = \\mathrm{lcm}(2,10,16)$. So you can write $a^{80} = (a^2)^{40} = (a^{10})^{8} = (a^{16})^5$. So, \\begin{align*} a^{80}= (a^2)^{40} &\\equiv 1^{40} = 1\\pmod{3},\\\\ a^{80}= (a^{10})^{8} &\\equiv 1^8 = 1 \\pmod{11},\\\\ a^{80}= (a^{16})^5 &\\equiv 1^5 = 1\\pmod{17}. \\end{align*}\n\nBy the Chinese Remainder Theorem, the system of congruences \\begin{align*} x&\\equiv 1\\pmod{3}\\\\ x&\\equiv 1\\pmod{11}\\\\ x&\\equiv 1\\pmod{17} \\end{align*} has a unique solution modulo $3\\times 11\\times 17 = 561$. But both $x=1$ and $x=a^{80}$ are solutions. Since the solution is unique modulo $561$, then the two solutions we found must be congruent. That is, $$a^{80}\\equiv 1\\pmod{561}.$$\n\n(Added. Or, more simply, as Andres points out, since $3$, $11$, and $17$ each divide $a^{80}-1$, and are pairwise relatively prime, then their product divides $a^{80}-1$).\n\nOnce you have that $a^{80}\\equiv 1\\pmod{561}$, then any power of $a^{80}$ is also congruent to $1$ modulo $561$. In particular, $$a^{560} = (a^{80})^{7} \\equiv 1^7 = 1 \\pmod{561}$$ as desired.\n\nshare|improve this answer\nArturo, I think you can do this more easily: Simply note that since $a^{80}-1$ is divisible by 3, 11, and 17, and these numbers are relatively prime, then it is divisible by their product. There is no need to invoke the Chinese Remainder Theorem. \u2013\u00a0 Andres Caicedo Feb 17 '11 at 7:35\n@Andres: Yes; I mentioned the CRT argument because it's a very common argument that shows up a lot as well. \u2013\u00a0 Arturo Magidin Feb 17 '11 at 14:12\n@Andres: ... and it was after 1am at the time. (-; \u2013\u00a0 Arturo Magidin Feb 17 '11 at 16:03\n\nHINT $\\: $ For primes $\\rm\\ p\\neq q\\:$ coprime to $\\rm\\:a\\:,\\:$ if $\\rm\\ p-1,q-1\\ |\\ m\\ $ then $\\rm\\ p,q\\ |\\ a^m - 1\\ \\Rightarrow\\ pq\\ |\\ a^m - 1$ since lcm = product for coprime integers (here distinct primes).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/67129/groups-of-order-pq-without-using-sylow-theorems\nText:\nTake the 2-minute tour \u00d7\n\nIf $|G| = pq$, $p,q$ primes, $p \\gt q, q \\nmid p-1 $, then how do I prove $G$ is cyclic without using Sylow's theorems?\n\nshare|improve this question\nTry counting elements of order $p$ and elements of order $q$ - there can't be any elements of order $pq$ (why?) and the subgroups of prime order are disjoint apart from the identity (why?) so the identity plus elements of order $p$ plus elements of order $q$ form the whole group. \u2013\u00a0 Mark Bennet Sep 24 '11 at 8:10\njust curious but, why would you not want to use the sylow theorems? \u2013\u00a0 user12205 Sep 24 '11 at 11:32\n\n5 Answers 5\n\nup vote 4 down vote accepted\n\nOnce again, Burnside's book (Theory of Groups of Finite Order) contains the classification of groups of order $pq$ before it tackles Sylow's Theorems. In the Dover print of the Second Edition this is contained in Page 48 (Section 36), with Sylow Theorems not occurring until section 120 (pages 149-151).\n\nThe argument relies on Cauchy's Theorem; here's the quote. I put in brackets the modern terms for some of the ones used by Burnside.\n\nA group of order $pq$ must contain a subgroup of order $p$ and a subgroup of order $q$. If the latter is not self-conjugate [normal] it must be one of $p$ conjugate sub-groups, which contain $p(q-1)$ distinct operations [elements] of order $q$. The remaining $p$ operations [elements] must constitute a subgroup of order $p$, which is therefore self-conjugate [normal]. A group of order $pq$ has therefore either a self-conjugate subgroup [normal subgroup] of order $p$, or one of order $q$. Take $p\\lt q$, and suppose first that there is a self-conjugate [normal] subgroup $\\{P\\}$ [$\\langle P\\rangle$] of order $p$. Let $Q$ be an operation [element] of order $q$. Then:\n\n$$\\begin{align*} Q^{-1}PQ &= P^{\\alpha}\\\\ Q^{-q}PQ^q &= P^{\\alpha^q},\\\\ \\alpha^q\\equiv 1&\\pmod{p},\\\\ \\text{and therefore }\\alpha\\equiv 1&\\pmod{p}. \\end{align*}$$\n\nIn this case, $P$ and $Q$ are permutable [commute] and the group is cyclical. Suppose secondly that there is no self-conjugate [normal] subgroup of order $p$. There is then necessarily a self-conjugate [normal] subgruop $\\{Q\\}$ of order $q$; and if $P$ is an operation of order $p$, $$\\begin{align*} P^{-1}QP &= Q^{\\beta}\\\\ P^{-p}QP^{p} &= Q^{\\beta^p}\\\\ \\beta^p\\equiv 1 &\\pmod{q}. \\end{align*}$$ If $q\\not\\equiv 1\\pmod{p}$ this would involve $\\beta=1$, and $\\{P\\}$ would be self-conjugate, contrary to supposition. Hence if the group is non-cyclical, $q\\equiv 1 \\pmod{p}$ and $P^{-1}QP=Q^{\\beta}$, where $\\beta$ is a root, other than unity, of the congruence $\\beta^p\\equiv 1\\pmod{p}$. Between the groups defined by [$E$ is the identity] $$\\begin{align*} P^p&=E, &\\qquad Q^q&=E,&\\qquad P^{-1}QP &= Q^{\\beta},\\\\ \\text{and }P'^p&=E, & Q'^q&=E, & P'^{-1}Q'P'&=Q^{\\beta^a}, \\end{align*}$$ a simple isomorphism is established by taking $P'$ and $P^a$, $Q'$ and $Q$, as corresponding operations [elements]. Hence when $q\\equiv 1\\pmod{p}$ there is a single type of non-cyclical group of order $pq$.\n\nshare|improve this answer\nIf $Q_1, Q_2$ are two subgroups of order q, then $<Q_1, Q_2> \\supseteq Q_1Q_2$, and so $|<Q_1, Q_2>|\\geq |Q_1Q_2|=q.q/1=q^2 >qp=|G|$, contradiction; so there is unique subgroup of order $q$, hence normal. \u2013\u00a0 Marshal Kurosh Sep 29 '11 at 5:30\n@MarshalKurosh: Perhaps you can contact your local medium and let Burnside know, instead of letting me know? \u2013\u00a0 Arturo Magidin Sep 29 '11 at 13:20\n\nThis solution will mostly use Lagrange and the fact that |G| has so few divisors. This is mostly an example of how looking at cosets and permutations is useful. Sylow's theorem is just an example of doing that in a more general situation. Like Sylow's theorem, we gain a lot by finding fixed points of permutations.\n\nBy Lagrange's theorem, an element of G has order 1, p, q, or pq. There is only one element of order 1. If there is an element of order pq, then G is the cyclic group generated by it. Otherwise, every non-identity element of G has order p or q, and there is at least one such element, x. Let H be the subgroup generated by x.\n\nCase I: If x has order q, then Lagrange says that there are p cosets of H in G and x acts as a permutation on them. The order of that permutation is either 1 or q (by Lagrange again), but q > p is impossibly big, and so x leaves all the cosets gH alone. That means H is normal in G, because xgH = gH and so g\u22121xg in H for all g in G, and H is generated by x. Let y be any element of G not contained in H. Then y normalizes H, and so conjugation by y is an automorphism of H. The automorphism group of H has order q\u22121, and so the order of that automorphism is a divisor of gcd(q\u22121,\u00a0pq) = 1 by Lagrange, so conjugation by y is the identity automorphism on H. In other words, y\u22121xy = x and xy = yx. In particular, x and y commute and xy has order pq, so G is cyclic.\n\nCase II: If x has order p, then there are q cosets of H in G, by Lagrange. Note that xH = H, so x does not move the coset 1H. We examine two subcases based on whether it leaves any other cosets alone:\n\nCase IIa: Suppose x moves all the other cosets. By Lagrange, those other cosets are collected into p-tuples (the \"orbits\" of x), and so we get that q = 1 + kp, where k is the number of orbits. This explicitly contradicts the non-divisibility hypothesis.\n\nCase IIb: Suppose x leaves at least one more coset alone, say yH for some y not contained in H. In other words, xyH = yH, or y\u22121xy is in H. This means that y acts by conjugation on the elements of H. However, the automorphism group of H has order p\u22121, and so the automorphism by y is a divisor or p\u22121 and a divisor of pq, but gcd(p\u22121,\u00a0pq) = 1. Hence conjugation by y is the identity automorphism: y\u22121xy = x and xy = yx. In particular, x and y commute and xy has order pq, so G is cyclic.\n\nshare|improve this answer\nIn Case 1, Why can you claim that $x$ acts as a permutation on the set of left cosets of $H$ ? i.e. suppose $\\{g_1H, \\ldots g_pH\\}$ are left cosets of H, what goes wrong if $xg_iH=xg_jH$ for $1 \\leq i < j \\leq p$ ? \u2013\u00a0 the8thone Oct 14 '14 at 20:31\n\nFor any group $G$ and a normal subgroup $H$, $G$ acts on $H$ by conjugation as automorphisms of $H$. This gives a map from $G \\to \\text{Aut}(H)$ via the permutation representation with kernel $C_G(H)$. So by the First Isomorphism Theorem we have $G/C_G(H) \\hookrightarrow \\text{Aut}(H)$.\n\nNow let $G$ be a group of order $pq$ as above. Clearly if $Z(G)$ is nontrivial then $G/Z(G)$ is cyclic, and thus $G$ is abelian. So we may assume that $Z(G) = \\{e\\}$. If every element of $G$ besides the identity has order $q$, then the size of each conjugacy class must be $p$ for every nontrivial element. Then we would have the class equation $pq = 1 + kp$ for some $k \\in \\mathbb{Z}$. But clearly this is impossible as $p$ divides $pq$ but not $1 + kp$. So $G$ must have an element of order $p$, say $g$. Define $H = \\langle x \\rangle$. Then $|G:H| = q$, and since $q$ is the smallest prime dividing $|G|$, we have that $H$ must be normal. So $N_G(H) = G$ and since $Z(G) = \\{e\\}$, we must have that $C_G(H) = H$. Then by the above work, $G/C_G(H) \\hookrightarrow \\text{Aut}(H)$. But since $H$ is cyclic, we have that $\\text{Aut}(H) \\simeq (\\mathbb{Z}/p\\mathbb{Z})^\\times$ by a standard result in group theory. Since $C_G(H) = H$, $|G/C_G(H)| = q$. But $|\\text{Aut}(H)|=p-1$. Since $G/C_G(H) \\hookrightarrow \\text{Aut}(H)$, this implies that $\\text{Aut}(H)$ has a subgroup of order $q$, but this would imply that $q \\mid p-1$, which is a contradiction. Hence $G$ must be abelian. From here you just need a single element of order $p$ and one of order $q$. Their product has order $pq$ and thus generates $G$.\n\nshare|improve this answer\nIn your argument you have not used the fact that $p \\neq q$, in fact if $p=q$, A group of order $p^2$ is not necessarily cyclic , i.e. it can be isomorphic to $\\mathbb{Z}_p \\times \\mathbb{Z}_p$ \u2013\u00a0 the8thone Oct 14 '14 at 20:18\n@the8thone That fact is used in the last line. The product of two elements of order $p$ need not be of order $p^2$. \u2013\u00a0 Brandon Carter Oct 14 '14 at 20:53\n\nLet $G$ be a group of order $pq$. Then order of element should be $1,p,q,pq$.\n\nIt is sufficient to show existance of subgroups of order $p$ and $q$.\n\n  \u2022 If all elements of $G$ are of order $p$ (except identity), then consider a subgroup $H$ of order $p$ and take $y\\in G\\backslash H$, let $K=\\langle y\\rangle$.\n\n    Now $H$ can not be normalised by $y$ in $G$, otherwise $HK$ will be an abelian subgroup of $G$ of order $p^2$, contradiction. Therefore, $yHy^{-1}$ is another conjugate subgroup of order $p$. Now number of conjugates of $H$ will be the index $[G\\colon N(H)]$ of normalizer of $H$ in $G$; since there are at least two conjugates, ($H,yHy^{-1}$) so $[G\\colon N(H)]>1$, we deduce that $N(H)=H$. Therefore there are exactly $q$ conjugates of $H$. The non-trivial elements in collection of conjugates of $H$ will be $(p-1)q$. Then take element $z$ of $G$ outside these counted elements, proceed further for $\\langle z\\rangle$. We will get $(p-1)q$ non-trivial elements in the collection of all conjuagtes of $\\langle z\\rangle$. After some finite steps, say $m\\geq 1$, we will get all non-trivial elements of $G$ (of order $p$); they will be $m(p-1)q$ in number.\n\n    Therefore, $m(p-1)q+1=pq$, which is not valid, since $pq-m(p-1)q$ is divisible by $q$ (here all terms are non-zero).\n\n    Therefore, we conclude that all non-trivial elements of $G$ can-not be of same order $p$.\n\n    Similarly, we can conclude that all non-trivial elements can not have same order $q$.\n\n    \u2022 If $G$ has element of order $pq$ then it will be cyclic.\n\n    \u2022 Otherwise, now we must have atleast one element of order $q$, hence a subgroup $Q$ of order $q$. This subgroup must be be unique (hence normal): if $Q_1$ is another subgroup of order $q$, then $\\langle Q, Q_1\\rangle \\supseteq QQ_1$, so $|\\langle Q,Q_1\\rangle | \\geq |QQ_1|=q.q/1=q^2>qp = |G|$, contradiction.\n\n    Take a subgroup $P$ of order $p$. Now $Q \\triangleleft G$, $P\\leq G$, hence $PQ\\leq G$; in fact this is equality - $PQ=G$ (computing orders). So $G=Q\\rtimes P$. Using two basic theorems on semi-direct product of groups ( Ref. Alperin-Bell - Groups and Representations), we can conclude that $G=Q\\times P$, hence it is cyclic.\n\n    (The crucial step stated in proof is existance of subgroups of order $p$ and $q$. Using theorems on semi-direct products doesn't uses Sylow's theorems.)\n\nshare|improve this answer\n\n(We only consider the complex representation) Suppose that $G$ is non-Abelian. Then there is an irred repr. $\\rho$ s.t. it is $d$-dim'l, $d>1$. By dimension theorem, we get $d=p,q$, or $pq$, but we know that $d$ must be $p$; otherwise by the property that $\\sum_{\\chi'\\in\\text{Irr}(G)}d_\\chi^2=|G|$, we will get $d^2>pq$ because of the condition $p<q$. So the dimension of the irred repr's can only be $1$ or $p$, and hence we get $$ mp^2+n=pq, $$ where $m,n$ stand for the number of $p$-dim'l and $1$-dim'l irred repr's, respectively. Furthermore, let $\\mathcal{L}(G)$ be the set of all $1$-dim'l characters of $G$. Then we have $$ n=|\\mathcal{L}(G)|=|\\text{Irr}(G/[G,G])|=\\frac{|G|}{|[G,G]|}, $$ where $[G,G]$ is the commutator subgroup of $G$. Since $G$ is non-Abelian, $[G,G]$ is nontrivial. So $n=1,p$, or $q$.\n\n[Case 1]: If $n=1$, then $mp^2=pq-1$. So we get $pq\\equiv1\\;(\\text{mod}\\,p^2)$. However, since $q\\equiv 1\\;(\\text{mod}\\,p^2)$, we get $$ pq\\equiv p\\equiv 1 (\\text{mod}\\,p^2), $$ which is a contradiction.\n\n[Case 2]: If $n=p$, then $\\displaystyle m=\\frac{q-1}{p}\\notin\\Bbb N$ because $p\\nmid(q-1)$. Contradiction.\n\n[Case 3]: If $n=q$, then $\\displaystyle m=\\frac{(p-1)q}{p^2}\\notin\\Bbb N$, still a contradiction.\n\nTherefore, in conclusion, we find $G$ must be Abelian, and hence, by the fundamental theorem of Abelian groups, $G\\cong \\Bbb Z_{pq}$ or $\\Bbb Z_p\\times \\Bbb Z_q$. So in any case $G$ is a cyclic group.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/95995/there-is-no-simple-group-of-order-448-26-cdot-7?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nHow can I prove that there is no simple group of order $448=2^6\\cdot 7$? I tried with Sylow's theorems, I proved that (if $G$ is simple) the number of 2-Sylows is 7 and that the number of 7-Sylows is 8 or 64, but I don't know how to continue, could you help me please?\n\nshare|improve this question\n(There is a monthly maximum for questions... :D ) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 3 '12 at 5:36\nHint: If there are 64 Sylow 7-subgroups, consider how may elements of order 7 there are. \u2013\u00a0 Geoff Robinson Jan 3 '12 at 5:45\n@Alex: Well, if there are 384 elements of order $7,$ how many Sylow $2$-subgroups can there be? (Actually, I see a more direct approach to the question than this anyway). \u2013\u00a0 Geoff Robinson Jan 3 '12 at 5:53\nonly 1, right thank you \u2013\u00a0 Alex M Jan 3 '12 at 5:59\n@Jack, Jyrki: I do not believe the statement about groups of order $q^{n}p.$ For example, the symmetric group $S_4$ has order $2{3}.3,$ and a Sylow $3$-subgroup normalizes the normal Klein $4$-group, but not a whole Sylow $2$-subgroup (there is noting special about these primes for this question). \u2013\u00a0 Geoff Robinson Jan 3 '12 at 9:12\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nLet $n_2$ be the number of $2$-Sylow subgroups of $G.$ Then, $n_2$ is odd and divides $7.$ If $n_2=1$ we're done, but if $n_2=7$, by Sylow theorem, conjugation of these seven $2$-Sylow subgroups defines a homomorphism $G \\to S_7.$ The kernel of this homomorphism cannot be trivial so we're done.\n\nshare|improve this answer\nwhy the kernel cannot be trivial? \u2013\u00a0 Alex M Jan 3 '12 at 7:42\n+1: This works for groups of size $2^6\\cdot 7$, because that number does not divide $7!$. But curiously it wouldn't work for $2^4\\cdot 7$ :-) \u2013\u00a0 Jyrki Lahtonen Jan 3 '12 at 7:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164264/do-elliptic-operators-on-riemannian-manifolds-have-a-regularizing-effect?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm working on my master thesis and need to handle some spectral theory of the Laplace operator on compact Riemannian manifolds and especially on the sphere. While investigating essential self-adjointness I stumbled on the following problem.\n\n*Problem*$\\quad$ In a compact Riemannian manifold $M$ let $$\\Delta=\\operatorname{div}\\operatorname{grad}$$ and let $f\\in L^2(M)$ be such that $(f, u-\\Delta u)=0$ for every $u \\in C^{\\infty}(M)$. Prove that $f=0$.\n\nI believe that the claim is true, because the condition $(f, u-\\Delta u)=0$ means exactly that $f$ is a distributional solution of the elliptic equation $-\\Delta f + f=0$, and so I expect it to be a $H^2_{\\text{loc}}$ function (see Theorem 2.1 of Berezin - Shubin's book). Since $M$ is compact this must imply that $f\\in H^1(M)$ so that integrating by parts we get $\\lVert f \\rVert_{H^1}^2=(f, f)+(\\operatorname{grad}f, \\operatorname{grad}f)=0$.\n\nUnfortunately Theorem 2.1 above is set in an open subset of the Euclidean space and I don't know if it is applicable verbatim in a Riemannian manifold. Can you point me to some reference on this?\n\nThank you.\n\nshare|improve this question\nI don't know the answer to this but would first try to look in Chavel's book 'Eigenvalues in Riemannian Geometry'. \u2013\u00a0 user20266 Jun 28 '12 at 18:07\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nYes. Write your equation in local coordinates and then use the usual elliptic theory there.\n\nHere is an example. The equation $$\\Delta_g u = h$$ in local coordinates is $$g^{ij}\\frac{\\partial^2u}{\\partial x^i\\partial x^j} - \\frac{1}{\\sqrt g} \\frac{\\partial}{\\partial x^i}(\\sqrt g g^{ij})\\frac{\\partial u}{\\partial x^j} = h$$\n\nNotice that the operator on the LHS is still an elliptic operator on $\\mathbb R^n$ in the given local coordinates, due to the fact that the Riemannian metric is positive definite. Therefore all of the standard elliptic regularity theorems you know for operators on $\\mathbb R^n$ still apply.\n\nThere isn't really a standard reference for this, although it probably appears as a remark buried in most PDE books.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296931/find-x-such-that-1213x-be-a-perfect-square/297410\nText:\nTake the 2-minute tour \u00d7\n\nFind $x \\in N$ such that $12+13^x$ be a perfect square\n\nI am going to limit $k < 12 + 13^x < k+i$ so that I can have $t<x<t+u$, I don't know how to do it, if $x=2k$, it pretty easy but x can also equal $2k +1$ too. So... Stuck here\n\nUpdate 2: I can prove that $x$ can't be $2k$, if so, x = 2k $(k \\in \\mathbb{N})$ then $13^{2k}<12+13^x = 12 + 13^{2k}<(13^k+1)^2$ => $12+13^x$ can't be a perfect square.\n\n~# if $x=2k+1$\n\n=> $12+13^x = 12+13^{2k+1}$. Now we need prove that $k$ can not greater than $1$ (how to do that ?, stuck again)\n\nshare|improve this question\n$x=1$ works, but you probably knew that. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 5:03\nWhere is this question from? \u2013\u00a0 Will Jagy Feb 7 '13 at 5:40\nRamanujan and Nagell are associated with the similar equation $-7+2^x=y^2$, which has several solutions. The methods used for finding all the solutions would probably be a good starting point for the current problem. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 6:00\nHow were you led to this question? \u2013\u00a0 Will Jagy Feb 7 '13 at 6:01\nA couple of papers that might be relevant: MR0856715 (87m:11027a) Peth\u00f6, A.; de Weger, B. M. M., Products of prime powers in binary recurrence sequences, I, The hyperbolic case, with an application to the generalized Ramanujan-Nagell equation, Math. Comp. 47 (1986), no. 176, 713\u2013727 and MR0856716 (87m:11027b) de Weger, B. M. M., Products of prime powers in binary recurrence sequences, II, The elliptic case, with an application to a mixed quadratic-exponential equation, Math. Comp. 47 (1986), no. 176, 729\u2013739. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 6:09\n\n5 Answers 5\n\nThere are many ways to solve such problems -- I'm not sure that any of them are particularly easy. One way, since you've observed that your exponent $x$ is necessarily odd, would be to find all the integral points on the elliptic curves given by the equations $$ y^2 = 13^\\delta u^4+12 \\; \\mbox{ for } \\; \\delta \\in \\{ 1, 3 \\}. $$ One can do this in, for example, magma by typing : IntegralQuarticPoints([13,0,0,0,12]); and IntegralQuarticPoints([13^3,0,0,0,12]); which lead to the two known solutions (with $|u|=1$ and $|y| =5$ and $47$). These routines are using lower bounds for linear forms in logarithms (elliptic, I believe).\n\nAnother approach (which has some similarities) would be to use an argument of de Weger (from his thesis, again based on linear forms in logarithms). This would enable you, for example, to tackle the more general equation $$ 13^x + 2^y 3^z = w^2. $$ I haven't worked out the details, but one should be able to show that the only solutions are with $$ \\begin{array}{r} (x,y,z) = (0,0,1), (0,3,0), (0,3,1), (0,4,1), (0,5,2), (1,0,1), (1,0,5), \\\\ (1,2,1), (1,2,2), (1,2,3), (2,0,3), (2,6,1), (2,10,5), (3,2,1). \\\\ \\end{array} $$\n\nYet another way to solve such problems is to use the hypergeometric method of Thue and Siegel. In this context, it enables one to prove an inequality of the shape $$ \\left| y^2 - 13^x \\right| > |y|^{0.4}, $$ valid for all integers $y$ and odd $x$. Such an approach is also useful for bounding the number of solutions to equations like the one under consideration here. One can, for example, show that given any odd prime $p$ and integer $D$, there are at most $3$ positive integers $x$ such that $$ p^x+D = y^2 $$ for integer $y$. This is, of course, not quite sharp when $p=13$ and $D=12$, but it's close.\n\nshare|improve this answer\nI may be two weeks late, but welcome to Math Stack Exchange professor Bennett! \u2013\u00a0 Eric Naslund Feb 7 '13 at 18:59\nThank you, Eric. \u2013\u00a0 Mike Bennett Feb 8 '13 at 1:57\n\n$x=3 \\implies 13^x+12=2209=47^2$.\n\nshare|improve this answer\n\nI don't think there's a nice way to do this. You can, however, use a calculator or a computer to find solutions. I used the following line in Mathematica:\n\n      Intersection[12+13^(2#-1) & /@Range[100000],#^2&/@Range[300000]]\n\nAnd it returned\n\n{25, 2209}\n\nImplying the only answers less than $100000$ are $1$ and $3$.\n\nEDIT: changed code and results\n\nshare|improve this answer\n\nWe want: $$13^x + 12 = a^2$$ Not an answer just compiling results:\n$$ x=1,3 $$ Are the first two solutions.\nThere are no solutions for $$ 3<x<100000 $$ Note that $$ 12+13^x \\equiv 1 \\mod 8, \\;\\; \\forall x>1, \\mbox{ such that $x$ is odd}\\\\ 12+13^x \\equiv 5 \\mod 8, \\;\\; \\forall x>1, \\mbox{ such that $x$ is even}\\\\ $$ Hence $$ a^2 \\equiv 1 \\ $$ So we have that: $$ a \\equiv 1,3,5 \\text{ or } 7 \\mod 8 $$\nand $x$ is odd since $5$ is a non-residue $\\mod 8$\n\nA similar result yields that: $$ a \\equiv 2 \\text{ or } 5 \\mod 7 $$\n\nshare|improve this answer\n\nI think algebraic approach is appropriate to this problem. With some calculation, we get $$(y+2\\sqrt{3})(y-2\\sqrt{3})=(4+\\sqrt{3})^x (4-\\sqrt{3})^x.$$ and $4\\pm\\sqrt{3}$ is prime on $\\mathbb{Z}[\\sqrt{3}]$. And $$\\frac{5-2\\sqrt{3}}{4+\\sqrt{3}}=2-\\sqrt{3}$$ $$\\frac{47+2\\sqrt{3}}{(4+\\sqrt{3})^3}=2-\\sqrt{3}$$\n\nSo I conjectured following propositions:\n\n  1. If $(x,y)$ is solution of this equation, then $y+2\\sqrt{3}$ associates $(4+\\sqrt{3})^x$ or $(4-\\sqrt{3})^x$.\n\n  2. And each case ($(4+\\sqrt{3})^x$ associates $y+2\\sqrt{3}$ or $(4-\\sqrt{3})^x$ associates $y+2\\sqrt{3}$) gives only one solution.\n\nBut I can't get more.\n\nshare|improve this answer\nBy working out the unit group, you have $$y \\pm 2 \\sqrt{3} = (4 + \\sqrt{3})^x (2 - \\sqrt{3})^a$$ for some integer $a$ and positive integer $y$. A quick exhaust shows $a > 0$ too. Subtracting the conjugates on both sides, you get what is essentially a quadratic equation in $(2 - \\sqrt{3})^a$, so there is effectively one solution for each choice of $(4 \\pm \\sqrt{3})^x$. But there isn't always a solution where $a$ is an integer. \u2013\u00a0 Hurkyl Feb 7 '13 at 8:54\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/334585/use-fund-thm-to-evaluate-the-integral-of-zex2-dydz-3ys-dydz-2-yz7dx\nText:\nTake the 2-minute tour \u00d7\n\nUse the Fundamental Theorem to evaluate the integral of $ ze^{x^2} dydz + 3ys dydz + (2-yz^7)dxdy $ over the surface of the unit cube, except the bottom face.\n\nshare|improve this question\nWhat is $s$, a constant? \u2013\u00a0 Ron Gordon Mar 19 '13 at 9:05\nI assumed so. It is not a typo on my part. \u2013\u00a0 GaMbiT Mar 19 '13 at 9:14\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nBy \"unit cube,\" I assume you mean $[0,1]^3$. In any case, use the divergence theorem to get the net surface integral, i.e., the net outward flow across all faces of the cube. Then subtract the specific surface contribution from the bottom face to get the quantity you seek.\n\nThe vector field described above is\n\n$$\\vec{F} = (z\\, e^{x^2}, 3 s y, 2-y z^7)$$\n\nThen its divergence is\n\n$$\\vec{\\nabla}\\cdot \\vec{F} = 2 x z e^{x^2} + 3 s - 7 y z^6 $$\n\nThe net surface integral is then the integral of the divergence over the unit cube. I assume you can do this relatively simple integral; I get\n\n$$\\iiint_{[0,1]^3} dx\\,dy\\,dz\\: \\vec{\\nabla}\\cdot \\vec{F} = \\frac{1}{2} (e-3) + 3 s$$\n\nThen you must subtract out the contribution from the bottom face, i.e. $z=0$. Since the flow is outward, i.e., down in the negative $z$ direction, you add back in the integral\n\n$$2 \\iint_{[0,1]^2} dx \\,dy 2 = 2$$\n\nso the quantity you seek is\n\n$$\\frac{1}{2} (e+1) + 3 s$$\n\nshare|improve this answer\n*(e - 1), instead of (e + 1)? Thank you very much for the help, by the way. \u2013\u00a0 GaMbiT Apr 19 '13 at 14:18\n@XxGaMbiT: No, because of the factor of $1/2$. \u2013\u00a0 Ron Gordon Apr 19 '13 at 14:19\nOh, right. Careless mistake. Sorry. \u2013\u00a0 GaMbiT Apr 19 '13 at 14:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/318038/monte-carlo-for-the-wasserstein-metric\nText:\nTake the 2-minute tour \u00d7\n\nLet $(X,d)$ be some metric space and assume that $d\\leq 1$. Further, let $\\mu, $ $\\nu$ be two Borel probability measures on $X$ and let $$ \\Gamma(\\mu,\\nu) = \\{\\gamma - \\text{measure on }X\\times X:\\gamma(A,X) = \\mu(A),\\gamma(X,A) = \\nu(A) \\} $$ to be the space of all couplings of $\\mu$ and $\\nu$. Define $$ W_1(\\mu,\\nu) = \\inf_{\\gamma\\in \\Gamma(\\mu,\\nu)}\\int_{X\\times X} d(x,y)\\gamma(\\mathrm dx\\times\\mathrm dy) $$ to be the Wasserstein distance (of order $1$) between $\\mu$ and $\\nu$.\n\nSuppose, we are able to draw two sets of random elements according to these distributions. E.g. $\\{X_i\\}$ is iid such that $X_i\\sim \\mu$ and $\\{Y_j\\}$ is iid such that $Y_j\\sim \\nu$ where $1\\leq i,j\\leq n$.\n\nIs it possible to derive any results on $W_1(\\mu,\\nu)$ using $\\{d(X_i,Y_j)\\}_{ij}$, with some confidence-like bounds?\n\nSome thoughts: let $\\gamma(d):=\\int_{X\\times X}d(x,y)\\mathrm d\\gamma$. A dummy way is for a fixed $\\gamma$, we can simulate pairs $(X_i,Y_i)\\sim \\gamma$ and then define $$ \\overline{\\gamma(d)}:=\\frac1n\\sum d(X_i,Y_i). $$ By the Hoeffding inequality we get $$ \\Bbb P\\left(\\left|\\gamma(d) - \\overline{\\gamma(d)}\\right|\\geq t\\right)\\leq 2 \\mathrm e^{-nt^2} $$ and since $\\gamma(d) \\geq W_1(\\mu,\\nu)$ we can get some conservative upper bounds on the distance. The conservatism clearly depends on how $\\gamma$ is far from the optimal coupling.\n\nPerhaps, we can do something like that: simulate $\\{X_i\\}$ and $\\{Y_j\\}$ and consider $$ \\bar W:= \\frac1n\\sum_{i=1}^n \\min_j d(X_i,Y_j) $$ thus \"coupling\" $X$ and $Y$ on-the-run. But I am not sure whether this is an unbiased estimate and whether it allows for some bounds on the error.\n\nPlease feel free to retag. Perhaps I shall better ask it on statistics.SE?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nThe authors of the recent paper \"On the empirical estimation of integral probability metrics (2012, Electronic Journal of Statistics)\" have a setting where they present an estimator for Wasserstein metrics based on data and where they derive consistency of the estimator with convergence rates. It could be directly applied to a Monte Carlo setting.\n\nshare|improve this answer\nAwesome, that shall be a benchmark example of how the bounty helps :) \u2013\u00a0 Ilya Mar 4 '13 at 13:24\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/445123/how-to-solve-the-advection-equation-with-spiral-motion\nText:\nTake the 2-minute tour \u00d7\n\nThe advection equation is :\n\n$$\\frac{\\partial f(x,y,t)}{\\partial t} + \\nabla_{(x,y)} \\cdot (A f)= 0$$\n\nWith initial condition $f(x,y,0) = f_0(x,y)$.\n\nIf the vector $A$ is constant, ie. $A = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix}$ we have a linear advection. Using the characteristic method we found\n\n$$\\frac{dX}{dt} = a_1\\implies X(t) = x_0 + a_1t \\\\ \\frac{dY}{dt} = a_2\\implies Y(t) = y_0 + a_2t$$\n\nIf $A = \\begin{pmatrix} -x \\\\ y \\end{pmatrix}$ the motion of the advection is a circle :\n\n$$\\frac{dX}{dt} = y \\implies X(t) = c_0\\sin(t+c_1) \\\\ \\frac{dY}{dt} = -x\\implies Y(t) = c_0 \\cos(t+c_1)$$\n\nSo I was wondering what can I do to have a spiral advection ? Let's say I want to found :\n\n$$X(t) = t\\cos(t+\\theta_0) \\\\ Y(t) = t\\sin(t+\\theta_0)$$\n\nif we derivate this system :\n\n$$\\frac {dX(t)}{dt} = -t\\sin(t+\\theta_0) + \\cos(t+\\theta_0) = x/t - y = a_1(t,x,y)$$\n\n$$\\frac {dY(t)}{dt} = t\\cos(t+\\theta_0) + \\sin(t+\\theta_0) = y/t + x = a_2(t,x,y)$$\n\nWe can notice then that $\\nabla \\cdot A = \\dfrac{2}{t}$\n\nThen the equation is :\n\n$$\\frac{\\partial f(x,y,t)}{\\partial t} + A \\cdot \\nabla_{(x,y)} f = - \\dfrac{2}{t} f$$\n\nBut I don't manage to solve it. Using the characteristic method we found the spiral equation for X and Y but for the last element I have :\n\n$$\\dfrac{dF(x,y,t)}{dt} = - \\dfrac{2}{t}f \\implies f = C_0 / t^2$$\n\nwhich is not defined when $t=0$ so I don't know how to apply the initial condition.\n\nHow can I solve this equation ?\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/193944/closed-form-for-a-sum-of-values-of-a-quadratic\nText:\nTake the 2-minute tour \u00d7\n\nToday in class we were analyzing the number of half-spaces created by $n$ number of planes. For two planes there are 4 spaces, 3 there are 8, 4 there are 15, etc. our teacher challenged us to find the formula for $n$ planes. Me and my friend came up with $$ 1+\\sum^n_{x=1} \\left(\\frac{x(x+1)}{2}+1\\right) $$ Because based on that when a line cuts a plane in half, the formula for the number of half-planes it creates is $$ \\frac{n(n+1)}{2} + 1 $$ and the difference in the number of half-spaces between each $n$ plane is equal to adding on the same number of half-planes.\n\n+--#of planes--+--1--+--2--+--3--+--4--+--5--+--50--+\n|separates into|  2  |  4  |  8  |  15 | 26  |20,876|\n| _ half-spaces|     |     |     |     |     |      |\n\nMy teacher said that this was correct, but it would be better if it was a formula/function, where you plug in the variables rather than have to evaluate the summation. I know that the final answer is $$ \\frac{n^3+5n+6}{6} $$ but I need to show my work, and am unsure of how to get from a sum to that formula. Am I approaching this incorrectly? How was the original formula derived?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe reasoning is basically right, with slight glitches in the details. The desired number is $$2+\\sum_{x=1}^{n-1} \\left(\\frac{x(x+1)}{2}+1\\right).\\tag{$1$}$$ Or else, if you want to sum from $1$ to $n$, the desired number is $$1+\\sum_{x=1}^{n} \\left(\\frac{x(x-1)}{2}+1\\right).\\tag{$2$}$$\n\nNote that $(x+1)^3-x^3=3x^2+3x+1$. So $$\\frac{x^2+x}{2}=\\frac{1}{6}\\left((x+1)^3-x^3-1\\right).$$ Adding $1$, we get $$\\frac{x^2+x}{2}+1=\\frac{1}{6}\\left((x+1)^3-x^3+5\\right).$$\nWe will add up $(x+1)^3-x^3+4$ from $x=1$ to $x=n-1$, and divide by $6$ at the end. We have $n-1$ $5$'s, which add up to $5n-5$. Now add up the $(x+1)^3-x^3$ from $x=1$ to $x=n-1$. The sum is $$(2^3-1^3)+(3^3-2^3)+(4^3-3^3)+\\cdots +(n^3-(n-1)^3).$$ Note the beautiful cancellations! Almost everything disappears, and we end up with $n^3-1^3$. Add the $5n-5$. We get $n^3+5n-6$.\n\nSo our answer is $2+\\dfrac{n^3+5n-6}{6}$, which simplifies to $\\dfrac{n^3+5n+6}{6}$.\n\nRemarks: $1$. If you want to work with expression $(2)$ instead of $(1)$, you may want to use the identity $x^3-(x-1)^3=3x^2-3x+1$, though the one we used works fine.\n\n$2$. The kind of collapsing that we saw comes up surprisingly often. You may want to look into telescoping sums.\n\n$3$. There are many many other ways to find a closed form for the sm. Here is another idea. It is known that for any quadratic $q(k)$, $\\sum_{k=1}^{n-1}$ is a cubic. (And for any cubic $c(k)$, $\\sum_{1}^{n-1}c(k)$ is a quartic, and so on.). So our answer must have shape $p(n)=an^3+bn^2+cn+d$. If we know the values of our function at $4$ different $n$, we get $4$ linear equations in the coefficients $a$, $b$, $c$, $d$. Solve.\n\nshare|improve this answer\nWhere does the $(x+1)^6-x^6+4$ come from? Shouldn't it be $(x+1)^3-x^3+4$? \u2013\u00a0 SomekidwithHTML Sep 12 '12 at 1:55\n@SomekidwithHTML: It comes from a typo. Thanks! \u2013\u00a0 Andr\u00e9 Nicolas Sep 12 '12 at 2:47\n\nYour question amounts to evaluating\n\n$$\\sum_{x=1}^n x^2\\,\\,\\,\\text{and}\\;\\;\\sum_{x=1}^n x$$\n\n(upon expanding your original sum). Specifically,\n\n\n$$\\sum_{x=1}^n x^2=\\frac{x(x+1)(2x+1)}{6}$$\n\nwhich can be shown by induction.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/properly-divergent-sequences.268043/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProperly Divergent Sequences\n\n  1. Oct 29, 2008 #1\n    Suppose that (x_n) is a properly divergent sequence, and suppose that (x_n) is unbounded above. Suppose that there exists a sequence (y_n) such that limit (x_n * y_n) exists. Prove that (y_n) ===> 0.\n\n    2. Relevant equations\n    (x_n) ===> 0 <====> (1/x_n) ===> 0\n\n    3. The attempt at a solution\n    One can say with certanty that (y_n) must be bounded, as if it weren't, for all K in Naturals, there exists a b_1 in (x_n) > |K| and b_2 > |K|, and there product is unbounded.\n\n    If (y_n) is bounded, and does not converge to 0, then... what?\n\n    That's where I'm stuck. How do I finish this?\n\n  2. jcsd\n  3. Oct 29, 2008 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If y_n does not converge to zero then there is an e>0 such that for all N there is an n>N such that |y_n|>e. If x_n is unbounded, what does this tell about y_n*x_n?\n  4. Oct 30, 2008 #3\n    When I was trying to prove it directly (for fun), I met some problems.\n    What is a *properly* divergent sequence?( I cannot find its definition in books)\n    If x_n is defined as follows:\n    x_n = 0 when n is even, x_n = n when n is odd\n    is it of such kind?\n    If so, define y_n as:\n    y_n = 1 when n is even, y_n = 0 when n is odd\n\n    does this gives x_n*y_n = 0, as a counter??\n    Last edited: Oct 30, 2008\n  5. Oct 30, 2008 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The crucial part of the problem is \"suppose that (x_n) is unbounded above\". Your example does not satisfy that.\n  6. Oct 30, 2008 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    A properly divergent series is one such that\n\n    (mathematics) A series whose partial sums become either arbitrarily large or arbitrarily small (algebraically).\n\n    So turning each partial sum into an element of the sequence, I believe a properly divergent sequence is one in which for all M there exists k s.t. j>k => |xj|>M\n  7. Oct 30, 2008 #6\n    Thanks..I forgot to search the web.... That would make sense. So a direct proof is also not hard.\n\n    BTW, to HallsofIvy, my x_n do satisfy the unboundedness, IMO.\n\nHave something to add?\n\nSimilar Discussions: Properly Divergent Sequences\n  1. Diverging sequence (Replies: 11)"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/62867.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPrimitive Pythagorean Triple Congruences\n\nDate: 04/17/2003 at 15:09:28\nFrom: Ronnie\nSubject: Primitive Pythagorean Triples\n\nIf x,y,z are primitive Pythagorean triples, prove that x+y and x-y \nare congruent modulo 8 to either 1 or 7.\n\nI'm trying to solve the problem in the general form. By looking at \nknown Pythagorean triples, it is easy to see that for the values of x \nand y, the assertion holds true.  I just can't find the relation for \nthe general case.\n\nDate: 05/01/2003 at 12:39:05\nFrom: Doctor Nitrogen\nSubject: Re: Primitive Pythagorean Triples\n\nHi, Ron:\n\nFor selected integers u, v, the primitive Pythagorean triples \n\n   (x, y, z) usually have the form \n\n    x = uv, y = (u^2 - v^2)/2, z = (u^2 + v^2)/2.\n\nIt can be proved that\n\n   4 | y (\"4 divides y\"), meaning \n\n   y = 4m \n\nfor some positive integer m. I will prove this now:\n\nAs x = uv is odd, y = (u^2 - v^2)/2 is even, since x and y have \nopposite parity. This means \n\n   u^2 - v^2\n\nmust be of the form u^2 - v^2 = (2^r)s for some integer r > 1 and for \nsome odd integer s. Otherwise if r = 1, (u^2 - v^2)/2 will be equal \nto s, which is an odd integer, which is impossible as x is odd and x \nand y must have opposite parity. Therefore r > 1 and y has the form\n\n   y = (u^2 - v^2)/2 = 2^2(2^r-2)(s)\n\n     = 4(2^r-2)(s)\n\n     = 4m for some positive integer\n\n   m = (2^r-2)(s)\n\nNow note that all the possible congruence classes for the integers \n\n   4m + x and 4m - x \n\nare 4m + x, 4m - x in turn, is congruent to:\n\n   0 modulo 8\n   1 modulo 8\n   2 modulo 8\n   3 modulo 8\n   4 modulo 8\n   5 modulo 8\n   6 modulo 8\n   7 modulo 8\n\nNow since 4m + x and 4m - x are both odd, and since 8 cannot divide \nan odd integer, the only possible relevant congruences above would be\n\n4m + x and 4m - x are congruent to\n\n   1 modulo 8\n   3 modulo 8\n   5 modulo 8\n   7 modulo 8\n\nor involving the set {1, 3, 5, 7} of integers less than 8 and \nrelatively prime to 8.\n\nNow since both 4m + x and 4m - x, with y = 4m, are congruent to either \n1, 3, 5, or 7 modulo 8, all that is left for you to do is rule out the \ncongruences 3 and 5 modulo 8.\n\n- Doctor Nitrogen, The Math Forum\nAssociated Topics:\nCollege Number Theory\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM"}
{"text": "Retrieved from https://www.physicsforums.com/threads/elastic-collision-is-outer-space.116432/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nElastic Collision is outer space\n\n  1. Apr 3, 2006 #1\n    I think I'm getting lost in the numbers somewhere here.\n\n    Two astronauts, one of mass 60 kg and the other 84 kg, are initially at rest in outer space. They then push each other apart. How far apart are they when the lighter astronaut has moved 10 m?\n\n    m1= 60 kg\n    m2=84 kg\n    X initial = 0\n    X1 final= 10 m\n    V1 inital = 0\n    V2 initial= 0\n    V 1 final= 10m/s\n    T=1 S\n\n    .5*60*0^2 + .5*84*0^2 = .5*60*10^2 +.5*84*V2Final^2\n    0=3000 + 42* V2Final^2\n    V2Final = -8.5 m/s\n\n    8.5+10=18.5 m\n  2. jcsd\n  3. Apr 3, 2006 #2\n\n    Physics Monkey\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Why did you say the final velocity for astronaut one is 10 m/s? This isn't right. You need to determine the velocity of each astronaut after they push off each other. Since the collision is elastic, you can use conservation of energy and momentum to find the two velocities. Notice that as it stands now, your astronauts have not conserved momentum!\n\n    Edit: Yikes, I knew there was some reason this question was bothering me. Redburns, I'm sorry, but I didn't read the question or your response very carefully. The square root of a negative number is imaginary, not another negative number. Clearly the \"collision\" or push can't be elastic since they start out with no kinetic energy. My apologies for posting too quickly without reading things carefully. You do need to use conservation of momentum.\n    Last edited: Apr 4, 2006\n  4. Apr 4, 2006 #3\n\n\n    User Avatar\n    Homework Helper\n\n    Their combined centre of mass will stay at the initial point and will not move after the interaction since they are experiencing only internal forces.\n  5. Apr 4, 2006 #4\n    In the question you posted no information is given about the strength of the push given and so finding the *numerical* velocity of either person A or B is gonna be a bit tricky (did one push very gently with his little finger or give him a mighty big shove!)...knowing these facts are not necessary!\n\n    What is important is that the impulse that A exerts on B is the same impulse that B imparts on A\n\n    Whether the lighter dudes velocity was 5m/s or 0.0001m/s he is always going to have travelled a distance of 10 meters at precisely the same point when the heavy dude has travelled 'a' meters (where 'a' is constant) (assuming no other forces are acting)\n    Last edited: Apr 4, 2006\n  6. Apr 4, 2006 #5\n    Thanks! I though I might be making this one harder than it should be.\n\nHave something to add?\n\nSimilar Discussions: Elastic Collision is outer space"}
{"text": "Retrieved from https://www.physicsforums.com/threads/keplers-third-law.75968/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nKepler's third law\n\n  1. May 17, 2005 #1\n    not sure what to do here..\n\n    Im being asked to compare the periods of 2 different satellites in orbit around a planet.\n\n    the first one is a circular orbit of radius = r\n\n    the second one orbits 1r to the left and 3r to the right around the planet.\n\n    I'll attempt to draw it here :tongue:\n\n    0 is the planet\n\n\n    I understand how the period works in the first circular orbit.. but not the second one. any ideas?\n  2. jcsd\n  3. May 17, 2005 #2\n\n    Doc Al\n\n    User Avatar\n\n    Staff: Mentor\n\n    Start by reviewing what Kepler's 3rd law says.\n  4. May 17, 2005 #3\n    it states that r^3/T^2 = K\n\n    is it just the average radius of the second satellite? (in this case 2r ?)\n  5. May 17, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Yes, the mean distance, average radius, or, more commonly, the semi-major axis.\n\n    The shape of the orbit doesn't matter (your second orbit has an eccentricity of .5)\n  6. May 17, 2005 #5\n\n\n    User Avatar\n    Gold Member\n\n    So, a satellite in an eccentric orbit will have a period that is equivalent to a circular orbit whose radius is equal to (aphelion minus perihelion) of the eccentric orbit?\n\n    So, if an asteroid happened to be on an orbit that went out as far as Jupiter, and in as far as Mercury, its orbital period would be equivalent to a circular orbit whose radius is (Jupiter's - Mercury's) orbit?\n\n    I'd always wondered that.\n  7. May 17, 2005 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    A circular orbit whose radius is equal to the semimajor axis of the ellipse. Perihelion is\n\n\n    where a is the semimajor axis and e is the eccentricity. Aphelion is\n\n\n    So, the semimajor axis is given not by r_ap - r_peri, but rather:\n\n\n    This is what scales with period in Kepler's 3rd law:\n\n    [tex]P^2 \\propto a^3[/tex]\n  8. May 17, 2005 #7\n\n    James R\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n\nHave something to add?\n\nSimilar Discussions: Kepler's third law\n  1. Kepler's Third Law (Replies: 7)\n\n  2. Kepler's Third Law (Replies: 11)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/156795/uniform-convergence-on-a-closed-and-bounded-interval\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $f_n\\colon [a,b] \\to \\mathbb{R}$ be a sequence of continuous functions converging uniformly to a function $f$. Show that if each $f_n$ has a zero then $f$ also has a zero.\n\nThanks for any help.\n\nshare|cite|improve this question\nDo you mean all the $\\,f_n\\,$ have the same zero or just some zero? \u2013\u00a0DonAntonio Jun 11 '12 at 4:06\n@DonAntonio some zero \u2013\u00a0Ester Jun 11 '12 at 4:09\nThanks. Copper's answer has already cracked up the problem. \u2013\u00a0DonAntonio Jun 11 '12 at 4:24\nup vote 3 down vote accepted\n\nSince each $f_n$ has a zero, there is a number $x_n \\in [a,b]$ such that $f_n(x_n) = 0$. The set $[a,b]$ is compact, so $x_n$ has a convergent subsequence, call it $x_{n_k}$, and let $x_{n_k} \\to x$.\n\nSince $f_n$ converges to $f$ uniformly, and $f_n$ are continuous, then $f$ is continuous.\n\nNow consider $|f_{n_k}(x_{n_k}) - f (x_{n_k})| = | f (x_{n_k})|$. By uniform convergence we have $|f(x_{n_k})| \\to 0$, and by continuity of $f$, we have $f(x) = 0$.\n\nAlternative proof:\n\nAnother version would be to proceed by contradiction. Suppose $f(x) \\neq 0 $ $\\forall x \\in [a,b]$. Then since $[a,b]$ is compact (and $|f|$ is continuous), there exists $\\delta>0$ such that $|f(x)| \\geq \\delta$, $\\forall x \\in [a,b]$. By assumption of uniform convergence, we can choose $N$ so that $|f_n(x) - f(x)| < \\frac{\\delta}{2}$, $\\forall n \\geq N$, $\\forall x$. Since $f_N$ has a zero, we have $f_N(z) = 0$ for some $z \\in [a,b]$, then the previous inequality gives $|f(z)| < \\frac{\\delta}{2}$, which is a contradiction.\n\nshare|cite|improve this answer\nThanks a lot to both of you . \u2013\u00a0Ester Jun 11 '12 at 4:14\n\nHint: For each $n$, let $x_n\\in[a,b]$ be a zero of $f_n$. By compactness there exists a subsequence $(x_{n_k})_{k=1}^\\infty$ convergent to some $x\\in[a,b]$. Now what can you say about $f(x)$?\n\nshare|cite|improve this answer\n\nLet us denote $ x_n$ the $f_n$ zero Since $[a,b]$ is compact there existe a subsequence $x_{\\phi(n)}$ of $(x_n)$ such that $x_{\\phi(n)}$ converges to $\\ell \\in [a,b]$ You can try proove that $f(\\ell)=0$ by using $f_{\\phi(n)} (x_{\\phi(n)})=0$ for all $n$ and uniforme convergence ...\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/279860/probability-of-rolling-the-same-number-twice/279862\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nMath novice here. With a 10-sided die, the probably of rolling '1' is 10%. I'm tempted to think the probability of rolling '1' with two consecutive rolls is 20%. Would I be correct?\n\nNot sure if I need to factor in the first roll i.e. 10% + (10% - probability of NOT rolling 1 in the first roll). Or am I overthinking this?\n\nCLARIFICATION: I mean the probability of rolling a 1, then another 1.\n\nshare|cite|improve this question\nYou need to clarify your question. Do you mean the probability of rolling a $1$ at least once, exactly once, or both times? \u2013\u00a0Isaac Solomon Jan 16 '13 at 5:38\nGetting two $1$'s in a row must be less probable than getting the first one. You have to start with the first one, then can fail on the second roll. B.D has the correct answer, but this might help with intuition. \u2013\u00a0Ross Millikan Jan 16 '13 at 5:45\n@RossMillikan makes an excellent point. If you are trying to sync this intuition up with the array visualization I posted below, the single $1$ probability corresponds to the top-left square among just the squares in the top row; the two consecutive $1$s probability corresponds to that same square among all $100$ squares. \u2013\u00a0Benjamin Dickman Jan 16 '13 at 6:03\nup vote 3 down vote accepted\n\nThink of a $10 \\times 10$ array of squares, where each square represents a possible roll. For example, we could say the square in row $a$ column $b$ corresponds to rolling an $a$ first, and then rolling a $b$.\n\nWith these $100$ different possibilities, only one of them - the one in the top left hand corner - corresponds to rolling two consecutive $1$s.\n\nTherefore, the probability is $1/100 = 1\\%$.\n\n(More generally, you want to be multiplying the probabilities of independent events rather than adding them. This sometimes goes by the name of the \"multiplication rule.\")\n\nshare|cite|improve this answer\nWhat a wonderful way of visualizing it. Thank you very much. \u2013\u00a0hoipolloi Jan 16 '13 at 5:46\nYou could also visualize it by drawing a tree: 10 different points for each of the possible rolls, then each of those points gets 10 possible points for the subsequent roll. Again, you will end up with 100 possible two roll scenarios, of which only one is 1 followed by 1. This \"tree approach\" might make it clearer why you are multiplying probabilities instead of adding them. \u2013\u00a0Benjamin Dickman Jan 16 '13 at 5:48\n\nThe probability of rolling the same number twice on a $10$-sided die is $1\\over 10^2$, which is $1\\over 100$. This means that the probability is $1$%, so it's extremely unlikely that you'll make it.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/178841/leibniz-rule-of-a-product/179394\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWhy can't I apply Leibniz' rule in the following way?\n\n$$\\frac{d}{ds} g(s)\\int_0^\\infty f(s,x,u) \\, du = \\int_0^\\infty \\frac{d}{ds}g(s)f(s,x,u)\\,du,$$\n\nassuming $gf$ and $(gf)'$ are continuous on $[0,+\\infty]\\times [s_0,s_1]$ for some $s_0<s_1\\in\\mathbb{R}$.\n\nshare|cite|improve this question\nIt is unclear if there is any relationship between $s$, $x$ and $u$. Are $x$ and $u$ functions of $s$? \u2013\u00a0Siminore Aug 4 '12 at 16:51\n@Siminore, well, the $u$ is a dummy variable, so... \u2013\u00a0J. M. Aug 4 '12 at 16:57\nAs written, the domain of $f$ seems to be a subset of $\\mathbf R^2$, so the expression you've written doesn't make sense (saying that it is continuous in something two-dimensional). Unless you mean that for all $x$, $f(s,x,u)$ is continuous as a function of $s,u$ in the specified range. But in this case the usage of $x$ as a bound of the range is very confusing. \u2013\u00a0tomasz Aug 4 '12 at 20:13\nup vote 0 down vote accepted\n\nThe problem I was originally having was in thinking that $g(s)$ was a constant coefficient of the definite integral. However, since we wish to differentiate w.r.t. $s$ it seems we can not think of $g$ as a constant, which seems obvious now. Instead, we must treat $g\\int$ as a product and apply the product rule of differentiation, e.g.\n\n$$\\frac{\\partial}{\\partial s}g(s)\\int_0^\\infty f(s,x,u)du = g(s)\\frac{\\partial}{\\partial s}\\int_0^\\infty f(s,x,u)du + \\left(\\frac{d}{d s}g(s)\\right)\\int_0^\\infty f(s,x,u)du.$$\n\nWe can then take the $\\partial/\\partial s$ inside the integral as required.\n\nshare|cite|improve this answer\nIndeed, as long as you take a partial derivative, the other variables are as good as constants. I recommend using the standard notation \\partial for partial derivatives. \u2013\u00a0user31373 Aug 8 '12 at 3:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/554546/induction-proof-with-fibonacci-numbers\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nProve by induction that for Fibonacci numbers from some index $i > 10$\n\n$1.5^i \u2264 f_i \u2264 2^i$\n\nNotice! Because Fibonacci number is a sum of 2 previous Fibonacci numbers, in the induction hypothesis we must assume that the expression holds for k+1 (and in that case also for k) and on the basis of this prove that it also holds for k+2.\n\nThis where I've got so far:\n\nBase case: $i = 11$\n$f_{11} = 89 $\n$1.5^{11} \u2264 89 \u2264 2^{11} $ OK!\n\nInduction hypothesis:\n$1.5^{k+1} \u2264 f_{k+1} \u2264 2^{k+1}$\n\nInduction step:\n$1.5^{k+2} \u2264 f_{k+2} \u2264 2^{k+2}$\n\nNow I have no idea how to continue from here. Could someone help?\n\nshare|cite|improve this question\nup vote 2 down vote accepted\n\nWhen dealing with induction results about Fibonacci numbers, we will typically need two base cases and two induction hypotheses, as your problem hinted.\n\nYou forgot to check your second base case: $1.5^{12}\\le 144\\le 2^{12}$\n\nNow, for your induction step, you must assume that $1.5^k\\le f_k\\le 2^k$ and that $1.5^{k+1}\\le f_{k+1}\\le 2^{k+1}.$ We can immediately see, then, that $$f_{k+2}=f_k+f_{k+1}\\le 2^k+f_{k+1}\\le 2^k+2^{k+1}= 2^k(1+2)\\le 2^k\\cdot 4=2^{k+2}$$ As for the other inequality, we similarly see that $$f_{k+2}=f_k+f_{k+1}\\ge 1.5^k+1.5^{k+1}=1.5^k(1+1.5)=1.5^k\\cdot 2.5\\ge1.5^k\\cdot 2.25=1.5^{k+2}$$\n\nshare|cite|improve this answer\nThanks for the great answer! :) \u2013\u00a0JZ555 Nov 6 '13 at 17:24\n\nIf $\\alpha^k\\le f_k\\le \\beta^k$ and $\\alpha^{k+1}\\le f_{k+1}\\le \\beta^k$, then $$f_{k+2}=f_k+f_{k+1}\\ge \\alpha^k+\\alpha^{k+1}=\\alpha^{k+2}\\cdot(\\frac1{\\alpha^2}+\\frac1\\alpha)$$ and $$f_{k+2}=f_k+f_{k+1}\\le \\beta^k+\\beta^{k+1}=\\beta^{k+2}\\cdot(\\frac1{\\beta^2}+\\frac1\\beta),$$ so in order to conclude $$\\alpha^{k+2}\\le f_{k+2}\\le \\beta^{k+2} $$ is is sufficent to have $\\frac1{\\alpha^2}+\\frac1\\alpha\\ge 1$ and $\\frac1{\\beta^2}+\\frac1\\beta\\le 1$. You can verify that this is indeed true for $\\alpha=\\frac32$ and $\\beta=2$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/193739/intersection-of-a-cone-and-sphere\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nShow that a the cone $xy + yz + xz = 0$ cuts the sphere $x^2 + y^2 + z^2 = r^2$ into two equal circles and find their area.\n\nI have been trying to substitute one of the variables, say $z$, from the equation of the cone and putting that into the sphere; this looks like the wrong approach though. Could someone please help me with this?\n\nshare|cite|improve this question\n\nI would start with a change of variables (orthogonal transformation) to diagonalize the quadratic form $xy + yz + xz$. Try $u = (x+y+z)/\\sqrt{3}$, $v = (x - y)/\\sqrt{2}$, $w = (x + y - 2 z)/\\sqrt{6}$.\n\nshare|cite|improve this answer\nAmazing! That's exactly the new choice of coordinates that I was about to recommend. \u2013\u00a0Lubin Sep 10 '12 at 20:07\nHi, Thanks a lot for your comment, I will try this approach too. \u2013\u00a0coolbootgeek Sep 10 '12 at 20:26\n\nThe cone's apex is at the origin, so it definitely intersects the origin-centered sphere in equal circles.\n\nNote that the cone contains the coordinate axes. (Simply set any two variables to zero, and see that the last can be arbitrary.) Consequently, it meets the sphere at the points $(\\pm r, 0, 0)$, $(0, \\pm r, 0)$, $(0,0,\\pm r)$, so that the circles of intersection must be circumcircles of equilateral triangles with side-length $r\\sqrt{2}$. So ...\n\nshare|cite|improve this answer\nGreat, thanks for the answer \u2013\u00a0coolbootgeek Sep 10 '12 at 20:25\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56764.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPerilous Ping-Pong\n\nDate: 11/14/97 at 10:16:11\nFrom: Amanda Stone\nSubject: Perilous ping-pong\n\nThe President is going to a ping-pong match in Tokyo. He is taking\n8 balls with him. A terrorist has implanted one of the balls with \nexplosives, but they add such a small amount that no one can tell the \ndifference. The CIA has only enough time for TWO weighings before the \n\nI know that you must weigh more than one ball on each scale and that \nyou can get information from the good batch of balls. Can you help?\n\n\nDate: 11/14/97 at 13:34:37\nFrom: Doctor Tom\nSubject: Re: Perilous ping-pong\n\nHi Amanda,\n\nI assume the explosive (bad) ball is heavier and the others all weigh \nthe same, or the problem is totally hopeless.\n\nThis isn't possible to solve if all you can do is weigh them. It can \nbe done in 3 weighings, assuming you already know what a normal ball \nweighs. In 3 weighings, here's how to do it:\n\n  Weigh 4 balls. If it is exactly 4 times as heavy as\n  one ball, the explosive ball is in the other batch, and\n  in any case, you've now got it down to 4.\n\n  Take the set of four with the bad ball and weigh 2 of them.\n  You now know which set of 2 is bad.\n\n  Weigh one of the 2 bad balls. If it's normal, the other is bad.\n\nI can prove that the problem, as stated, can't be solved in two\nweighings. Each weighing will give only one bit of information, and \nthere are 8 balls, so 8 possible solutions, which is 3 bits of \ninformation. With only 2 bits in two weighings, you can't possibly \nwork the problem.\n\nThe other possibility is that maybe the question means to use a\nbalance (where you can compare 2 weights). In this case, the problem \ncan be solved, even without knowing what a good ball weighs. In fact, \nyou could do it with up to 9 balls.\n\n  First, balance 3 against 3. If they balance, the heavy ball must\n  be among the other two, and a single comparison of those two on\n  the balance shows which one is heavy.\n\n  If not, the set of 3 that's heavier contains the bad one. Put\n  one of those on each side of the balance, and if one is heavier,\n  it's the bad one.  If they match, the other ball is bad.\n\n-Doctor Tom,  The Math Forum\n\nAssociated Topics:\nHigh School Puzzles\nMiddle School Puzzles\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/148897/determining-position-at-some-point-in-time\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI try to solve the following problem.\n\nOn $n$ parallel railway tracks $n$ trains are going with constant speeds $v_1$, $v_2$, . . . , $v_n$. At time $t$ = 0 the trains are at positions $k_1$, $k_2$, . . . , $k_n$. Give an $O(n\\log n)$ time algorithm that detects all trains that at some moment in time are leading.\n\nThe problem is I don't know how to approach the above problem. I assume it's should very popular problem in computational geometry. I saw it few times before, but never considered to solve it.\n\nIt looks like that the problem assumes preprocessing the data before giving input the moment of time.\n\nComplexity $O(n\\log n)$ points out to process similar to sorting.\n\nshare|cite|improve this question\nForgive my ignorance, but if you have the current time can't you just do $d=v*t+k$, loop through the trains one by one, and keep track of the farthest? That would be $O(n)$ if I understand the problem correctly. Or do they specifically want $O(n\\log n)$? It seems that fundamentally you're sorting an array of tuples $(train_n, v_nt+k_n)$ by their second element. \u2013\u00a0Robert Mastragostino May 24 '12 at 4:39\n@Robert: For the question to be interesting it probably means that the desired output is a list of indices $i$ such that train $\\#i$ was leading at some instant of time $t_i\\in[0,\\infty)$. \u2013\u00a0Jyrki Lahtonen May 24 '12 at 5:44\nHint: This should have the computational-geometry tag. \u2013\u00a0JeffE May 24 '12 at 8:08\nIf you view the train positions as lines in $t-v$ space, the region to the right of all lines is convex. You are looking for all trains that contribute a segment to the boundary. Maybe you can adapt one of the convex hull algorithms. \u2013\u00a0Ross Millikan May 24 '12 at 8:17\n@RossMillikan, Thank you for the comment. Let's say I almost get the idea. But could you please elaborate a little more please, I don't understand how to represent a position. \u2013\u00a0fog May 24 '12 at 18:20\nup vote 2 down vote accepted\n\nFollow-up on my comment, long for another: For any given train, the position at time $t$ is $v_it+x_{i0}$ where $v_i$ is the velocity of train $i$ and $x_i0$ is its position at $t=0$. This defines a line in the plane. The set of all lines defines a region to the left where at a given time there is at least one train to the right and a region to the right were there is no train to the right. The rightward region is convex. A train is rightmost precisely when its line is the boundary. For example, if train 1 starts at 0 with speed 1 and train 2 starts at -1 with speed 2, they meet at (1,1). Train $1$ is rightmost before $t=1$, and train $2$ is after $t=1$. If train 3 starts at -2 with speed $3/2$, it is never rightmost. If you plot the three lines you can see that. This forms the basis of my statement that you want a convex hull of the right region.\n\nshare|cite|improve this answer\nAnother term occasionally used for this concept is the upper envelope of the set of lines (for instance, in the generalization of this question to arbitrary convex curves instead of just lines, which leads to the study of Davenport-Schinzel sequences). \u2013\u00a0Steven Stadnicki May 24 '12 at 22:53\nThank you Ross Millikan, so $x$ it's a positions of the train, on $y$ it's a time. Therefore the task is to find the rightmost train on the given time, which can be done by sorting in $O(nlogn)$. \u2013\u00a0fog May 25 '12 at 4:40\n@fog: In you original post, it seemed you were to find a list of trains that were rightmost at any time, a different problem. You are right that at a given time you can calculate each train position in $O(n)$, then sort in $O(n\\log n)$ \u2013\u00a0Ross Millikan May 25 '12 at 11:00\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/can-this-be-simlified.117578/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCan this be simlified?\n\n  1. Apr 15, 2006 #1\n    Can this be simPlified?:rofl:\n\n    A = B - sin(degtorad(C)) * sqrt(abs(sqr(D/2) - sqr(sqrt(sqr(E - F) + sqr(B - G))/2)))\n\n    A, B, C, D, E, F, G are variables. I don't need to simlify down to a numerical value of a variable just now; I'm just wondering if the equation can be simplified.\n\n    Other terms\n    degtorad() means the amount inside the paranthese is converted from degrees to radians.\n    radtodeg() converts radians to degrees.\n    abs() means absolute value\n    sqr() and sqrt() are square and square root\n\n    Last edited: Apr 15, 2006\n  2. jcsd\n  3. Apr 15, 2006 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Well, there's the obvious point that\n    sqr(sqrt(sqrt(sqr(E - F) + sqr(B - G))/2)= (sqrt(sqr(E - F) + sqr(B - G))/4\n    That is, that\n    [tex]\\frac{\\left(\\sqrt{(E-F)^2+ \\sqrt{B-G}}\\right)^2}{2}= \\frac{\\sqrt{(E-F)^2+ \\sqrt{B-G}}}{4}[/tex]\n\nHave something to add?\n\nSimilar Discussions: Can this be simlified?\n  1. Can this be solved? (Replies: 1)\n\n  2. Can this be proven? (Replies: 17)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/valid-proof.126427/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nValid proof?\n\n  1. Jul 17, 2006 #1\n    valid proof? (Intro to Analysis)\n\n    Hey all,\n\n    Great forum here! I am working through \"Elementary Analysis\" by Kenneth Ross in preparation for an intro to analysis course I am taking in the fall. I was wondering if the following is a valid proof? Included are the axioms I used in the proof, but if you need the complete list I will post them. I'm still learning to use LaTeX so my appologies for not using it here.\n\n    <= \"is less than or equal to (or > for greater)\"\n    != \"does not equal\"\n\n    Problem 3.4: Prove 0 < 1\n\n    The following properties hold:\n    M4. For each a != 0, there is an element a^(-1) such that aa^(1) = 1\n    02. If a <= b and b <= a, then a = b.\n\n    The following are consequences of an ordered field:\n    (iv) 0 <= a^2 for all a\n\n    Proof by contradiction: Suppose that 0>=1. By (iv), we also have that 0 <= 1^2 = 1. Therefore 0 <= 1 and 1 <= 0, and hence 0 = 1, by O2. But there is an element 1^(-1) = 1 such that (1)(1)^(-1) = 1, and 0 != 1, by M4. Thus 0 = 1 and 0 != 1, a contradiction. Therefore 0 >= 1 is false, and hence 0 < 1.\n\n    I am not sure about using M4 to prove 0 != 1, I am pretty shaky on my logic when it comes to quantifiers.\n\n    Thanks for any input!\n    Last edited: Jul 18, 2006\n  2. jcsd\n  3. Jul 18, 2006 #2\n    The only ring/field where you could have 1=0 is the singleton set {0}, ie: the ring/field whose only element is 0. So when talking about the reals or the rationals, it is taken as an axiom that 1 != 0.\n\n    edit: Actually it is implied in the definition of a field that 1 != 0, so this is only true for rings (see my second post below). To arrive at a list of properties that defines a ring, just remove the following properties for a field\n    - multiplication is commutative\n    - existence of multiplicative identity\n    - existence of multiplicative inverses for nonzero elements\n\n    Here is where you should end your proof. You have just contradicted the axiom that 1!=0.\n\n    Alternatively, it is not necessary to do a proof by contradiction, you could simply assert that 1 = (1^2) >= 0, and since 1 != 0 it must be that 1>0.\n    Last edited: Jul 18, 2006\n  4. Jul 18, 2006 #3\n    Thanks. I guess that's where my confusion was, I wasn't sure if 0 != 1 was an axiom. It is not stated explicitly in the text I am using, but the author did present the axioms as properties of the rationals, so I guess 0 != 1 is assumed. Is it not possible to prove that 0 != 1 from the basic axioms of an ordered field?\n  5. Jul 18, 2006 #4\n    No, you can't deduce that 0 !=1 from the axioms of an ordered field. In fact it is stated in the defintion of a field that 1 != 0, and this is certainly true for ordered fields as well.\n\n    In my first post, I stated the axioms for a ring (see edit). A ring with a multiplicative identity element which we call 1 is called a ring with unity.\n    I showed you an example of a ring with unity in which 0 = 1\n    Ie: The set {0} where addition and multiplication are defined by 0+0 = 0 and 0x0 = 0.\n    Verify on your own that this set with the two operations defined above satisfies all the ring axioms. Notice in this case that 0 acts as both the additive and multiplicative identity.\n\n    I also stated, that this is the only example of a ring where 0 = 1.\n    To see this, note that for any ring K, we have\n    0a = a0 = 0 , for all a in K, where 0 denotes the additive identity of K.\n    (you should prove this on your own using only the ring axioms)\n    Then you can deduce that for any ring with multiplicative identity 0, that\n    a = 0 for all a in F, that is F = {0}.\n\n    Since fields are rings with some added axioms, the above discussion must hold for fields also. But as I said, fields are defined such that 1 !=0 since the only possible candidate for a field with 1 = 0 would be {0}.\n\n    I hope this is not too confusing. If so, it should relieve you to know, that this will be covered (in depth) if you take any course in abstract algebra, which covers topics in groups, rings, and fields.\n\nHave something to add?"}
{"text": "Retrieved from http://mathcentral.uregina.ca/QQ/database/QQ.09.06/jay1.html\nText:\nSubject: Calculus\nName: Jay\nWho are you: Student\n\nA snowball melts at a rate proportional to its surface area. Show that its radius shrinks at a constant rate. If it melts to 8/27 of its original volume in 20 minutes, how long will it take to melt completely? Please I need your help.\n\n\nHi Jay.\n\nLet's take this question step by step: first, the \"snowball melts at a rate...\" is clearly referring to the change in volume of the snowball with respect to time. If V = volume,\nA = surface area and R = radius, then dV/dt is what this phrase means.\n\nNow \"...proportional to its surface area.\" means that the dV/dt (the first part of the sentence) varies directly with the surface area A. Varies directly just means that the two terms are equal, but there is a constant of proportionality (usually called k) as a factor (usually attached to the second term). That means:\n\ndV/dt = kA.\n\nSo that's all the first sentence says.\n\nThe question is \"show that the radius shrinks at a constant rate\". That means the change in radius with respect to time is constant (let's call this constant q). So that means you are asked to show dr/dt is some constant.\n\nThe way to do this is to know the formulas for the volume and surface area of a sphere:\n\nV = (4/3) \u03c0 r3 and A = 4 \u03c0 r2\n\nand take derivatives.\n\ndV/dt is the derivative of volume with respect to time, but remember that r is also changing, so you have to use the chain rule:\n\ndV/dt = d/dt((4/3) \u03c0 r3) = (4/3) \u03c0 3 r2 (dr/dt)\n\nNow let's plug that into the first equation:\n\n(4/3) \u03c0 3 r2 (dr/dt) = k A = k(4 \u03c0 r2) = 4 \u03c0 k r2\n\nSo when we simplify by dividing left and right sides by 4 \u03c0 r2, we get:\n\ndr/dt = k\n\nwhich is saying exactly what we wanted to prove: that dr/dt is constant.\n\nFor the second (numerical) part of the question, you don't know the\noriginal volume (call it V again), but hopefully it will cancel out\nlater, so just start with what you know. Call the original radius R,\nthe radius after 20 minutes r, and the volume after 20 minutes v,.\n\nV = 4/3 \u03c0 R3\nv = 4/3 \u03c0 r3\nv = (8/27)V\n\nNow use this last equation to tie together the two volume equations:\n\n4/3 \u03c0 r3 = (8/27) (4/3 \u03c0 R3)\n\nso when you simplify and take the cube root,\n\nr = 2/3 R\n\nThat's very useful, because it is saying that the new radius is 2/3 the initial radius. But since the change in radius with respect to time is constant, the radius is shrinking at a constant rate. So if the radius lost 1/3 its length in 20 minutes, it will take another 40 minutes to melt away completely.\n\nStephen La Rocque.>"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/96642/block-on-cart-equation-of-motion\nText:\nTake the 2-minute tour \u00d7\n\nConsider a rigid block of $b \\times h$ having mass $m$ on cart (as depicted below). The cart is given an acceleration $a$, this leads to overturning of the block. The angle of rotation is indicated by $\\theta$.\n\nThis is how far I got (not considering the movement of the cart): The Lagrangian $L=T-V$ is calculated using $$T = \\frac12 J \\dot{\\theta}^2$$ $$V = m g \\Delta_y = m g \\bigg(r \\cos(\\alpha - \\theta) - \\frac{h}{2}\\bigg) $$ so that $$\\frac{\\mathrm{d}}{\\mathrm{d} t} \\bigg( \\frac{\\mathrm{d} L}{\\mathrm{d} \\dot{\\theta}} \\bigg) - \\frac{\\mathrm{d} L}{\\mathrm{d} \\theta} = 0$$ yields the EOM $$J\\ddot{\\theta} + m g r \\sin(\\alpha-\\theta) = 0$$ Now, my question is: how do I add the acceleration of the cart to the RHS? My initial guess would be $$J\\ddot{\\theta} + m g r \\sin(\\alpha-\\theta) = m a r \\cos(\\alpha - \\theta) $$ where $ma$ is the force and $r \\cos(\\alpha - \\theta)$ the lever arm. But I don't believe this is true since the block does not experience the acceleration $a$ over its full body. Can anyone help or provide some literature? Thanks.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nVerified it with FEA, it is correct.\n\nAlso, taking into account the \"rocking\" effect requires the piece-wise description: $$ J\\ddot{\\theta} + \\bigg\\lbrace\\begin{matrix} -m g r \\sin(\\alpha + \\theta) & \\theta < 0 \\\\ m g r \\sin(\\alpha - \\theta) & \\theta \\geq 0 \\end{matrix} = m a r \\cos(\\alpha - \\theta) $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/102358/is-the-following-curve-a-circle?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\gamma(\\theta)=(\\sin(\\theta+\\alpha)\\cos\\theta,\\sin(\\theta+\\alpha)\\sin\\theta),\\theta\\in[0,2\\pi]$. Is $\\gamma(\\theta)$ a circle? What is the radius of it?\n\nshare|improve this question\nHint en.wikipedia.org/wiki/\u2026 \u2013\u00a0 David Speyer Jan 25 '12 at 17:13\nPlot it (for some suitably chosen values of $\\alpha$, such as $0$ and $\\pi/2$). Does is look like a circle? If so, what does its center and radius appear to be? If you write down the naive parameterization of a circle with that center and radius, can you prove that it equals your $\\gamma$? \u2013\u00a0 Henning Makholm Jan 25 '12 at 17:15\nPedantic note: $\\gamma$ might or might not be (the equation of) a circle (here, it is) but $\\gamma(\\theta)$ is a point in the plane. \u2013\u00a0 Did Jan 25 '12 at 17:20\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nLet's recall two trigonometric identities: $$ \\begin{align} \\sin\\gamma\\cos\\delta & = \\frac{\\sin(\\gamma+\\delta)+\\sin(\\gamma-\\delta)}{2} \\\\ \\\\ \\sin\\gamma\\sin\\delta & = \\frac{\\cos(\\gamma-\\delta)-\\cos(\\gamma+\\delta)}{2} \\end{align} $$ So put $\\theta+\\alpha$ in the role of $\\gamma$ and $\\theta$ in the role of $\\delta$. Then we have $$ \\begin{align} \\sin(\\theta+\\alpha)\\cos\\theta & = \\frac{\\sin\\alpha+\\sin(2\\theta+\\alpha)}{2} \\\\ \\\\ \\sin(\\theta+\\alpha)\\sin\\theta & = \\frac{\\cos\\alpha-\\cos(2\\theta+\\alpha)}{2} \\end{align} $$ As $\\theta$ goes from $0$ to $2\\pi$, this point goes twice around a circle centered at $(\\sin\\alpha,\\cos\\alpha)/2$, with radius $1/2$ (and diameter $1$).\n\nshare|improve this answer\n\nUsing polar coordinates $(r,\\theta)$, the equation of this curve is $$ r=\\sin(\\theta+\\alpha)=\\sin(\\theta)\\cos(\\alpha)+\\cos(\\theta)\\sin(\\alpha). $$ One sees that $r^2=r\\sin(\\theta)\\cos(\\alpha)+r\\cos(\\theta)\\sin(\\alpha)=y\\cos(\\alpha)+x\\sin(\\alpha)$, hence $$ x^2+y^2-x\\sin(\\alpha)-y\\cos(\\alpha)=0. $$ This is indeed the equation of a circle. Let me indicate its radius is $ \\frac12$ and leave you the joy to find its center.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/25119/understanding-some-basics\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $x_1,\\ldots,x_n$ be any numbers and $\\bar{x} = (x_1+ \\ldots + x_n)/n$. Then I need to prove that $$min_a \\sum_{i=1}^n (x_i - a)^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\nI do not need the answer but I need an visual/intuitive understanding of the question. I do not understand what min$_a$ mean. Actually I'm kind of struggling to understand \"minimization concepts\" i.e. the value $a$ is not defined or anything so what does minimization of $a$ mean ? It would be great if someone can explain the concept in general too. Thanks.\n\nI got the answer perfectly for what I asked. I tried to solve the problem as well. I got stuck but here is my try.\n\n$$\\sum_{i=1}^n (x_i - a)^2 = \\sum_{i=1}^n (x_i - \\bar{x} + \\bar{x} - a)^2$$ $$= \\sum_{i=1}^n (x_i - \\bar{x})^2 + 2 \\sum_{i=1}^n (x_i - \\bar{x})(x_i - a) + \\sum_{i=1}^n(x_i - a)^2 $$ ...\n\nCan anyone help me after this ? Thanks again.\n\nshare|cite|improve this question\nKind of trying to get the answer with Yuval's explanation. If I'm not wrong $a$ should be minimized at $\\bar{x}$ but how to prove it ? \u2013\u00a0Sunil Mar 5 '11 at 6:46\nup vote 5 down vote accepted\n\nGiven $x_1,\\ldots,x_n$, you can define a function $$f(a) = \\sum_{i=1}^n (x_i-a)^2.$$ This function is defined for all real $a$, and in some sense it measures the centrality of $a$.\n\nYou can try some simple example on Wolfram alpha, say \"plot((a-1)^2+(a-2)^2+(a-4)^2,a=0..5)\". In this case the data points are $1,2,4$, and you get a nice, parabolic-like shape (this is no coincidence). The lowest point of the function is the minimum.\n\nThe function $f(a)$ is bounded from below (since $f(a) \\geq 0$), and so it cannot happen that $f(a)$ can be arbitrarily small. Therefore there must be a value below which $f(a)$ cannot reach, and moreover an optimal one - this is known as the infimum. The infimum is a value $L$ such that $f(a) \\geq L$ always, and moreover for each $l > L$, there is some value of $a$ such that $f(a) < l$; that expresses the fact that $L$ is optimal.\n\nIn general, it might be that $f(a)$ can get arbitrarily close to the infimum, but never reach it. In the case at hand, this doesn't happen, and the function $f(a)$ is actually minimized at some point, namely the average (or mean).\n\nThe equation you state can be used to justify the definition of average - the average is the value that minimizes the average squared distance from the datapoints. You could choose other criteria - for example, if you replace squared distance by absolute distance, then the optimal value of $a$ is the median.\n\nThe reason that people care about squared distance is that it's much easier to work with, and the resulting theory is very nice. For example, the central limit theorem states that in many cases, processes converge to a normal distribution whose parameters depend on the mean and variance of the original distribution - the variance is just $\\min f(a)$ (normalized).\n\nshare|cite|improve this answer\nVery clear and a perfect answer. Thank you very much. \u2013\u00a0Sunil Mar 5 '11 at 6:36\n\nThe question is about minimization with respect to a variable a. For this we use the derivative: the minimum of the function $f(a)$ is where the first derivative is zero and the second is positive.\nNow write $$f(a) = \\sum_{i=1}^n(x_i-a)^2 = \\sum_{i=1}^n a^2-2ax_i+x_i^2 $$ Then the derivative is $$f'(a) = \\sum_{i=1}^n (2a - 2x_i) = 2(an - \\sum_{i=1}^n x_i) $$ We see: if $a*n$ equals the sum we have $f'(a)$ a zero. So we can compute $a_0$ by $$ a_0 = \\frac{\\sum_{i=1}^n x_i }n $$ Next, if the second derivative is positive, then indeed $f(a_0)$ is also a minimum: $$ f''(a) = 2n $$ and this is positive - independent of a and/or the $x_i$ . But the formula for $a_0 $ is just the definition of the mean: $ x_{mean} =\\frac{\\sum_{i=1}^n x_i }n $\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/536810/number-of-fibonacci-numbers-in-a-range?answertab=active\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nThe definition of the Fibonacci numbers is given by:\n\n$$\\begin{align}f_1 &= 1;\\\\ f_2 &= 2;\\\\ f_n &= f_{n-1} + f_{n-2},\\qquad (n >= 3); \\end{align}$$\n\nnow we are given two numbers $a$ and $b$, and we have to calculate how many Fibonacci numbers are in the range $[a,b]$. How can we calculate it?\n\nshare|cite|improve this question\nNaively just compute all Fibonacci numbers smaller or equal to $b$ and count. Maybe you should clarify what you mean by 'calculate'. A closed form dependent on $a$ and $b$ will probably not exist. \u2013\u00a0Simon Markett Oct 23 '13 at 10:22\nYour definition of Fibonacci numbers is off by one from the standard indexing. Normally $f_2=1, f_3=2$. My answer uses the standard indexing. The final answer doesn't change as we are subtracting two indices. \u2013\u00a0Ross Millikan Oct 23 '13 at 10:43\n'calculate'means total fibonacci numbers between the range... \u2013\u00a0rock321987 Oct 23 '13 at 11:05 it \u2013\u00a0rock321987 Oct 23 '13 at 11:06\nup vote 1 down vote accepted\n\nThis question is asked in Skiena's programming challenges. Now, to find the $ n^{\\text{th}} $ fibonacci number, we have the following closed form expression.\n\n$$ \\Large F(n) = \\dfrac{1}{\\sqrt{5}} \\left( \\left( \\dfrac{1 + \\sqrt{5}}{2}\\right)^n - \\left( \\dfrac{1 - \\sqrt{5}}{2} \\right)^n\\right) $$\n\nNow, given $ F(n) $, we can find approximately the index of the closest fibonacci number to it. Therefore, we find one $ n_1 $ such that $ F(n_1) = a $ and another $n_2 $ such that $ F(n_2) = b $. Then our answer is $\\mathsf{round(n_2)} - \\mathsf{round(n_1)}$ where $ \\mathsf{round(x)} $ find the nearest integer to $ x $.\n\nshare|cite|improve this answer\nIs the PDF in the link really freely available or is it a copyright violation? \u2013\u00a0lhf Apr 29 '14 at 12:13\nI'll change the link, since I am not sure. \u2013\u00a0adijo Apr 29 '14 at 12:20\n\nWe know that $F_n\\approx \\frac {\\phi^n}{\\sqrt 5}$, so given $a$, the next larger Fibonacci number is $F_k$, where $k= \\left \\lceil\\frac {\\log (a\\sqrt 5)}{\\log \\phi }\\right \\rceil$. Similarly the $F_m$ below $b$ is $m= \\left \\lfloor\\frac {\\log (b\\sqrt 5)}{\\log \\phi }\\right \\rfloor$, then there are $m-k+1$ between $a$ and $b$. You have to think about what you want if $a$ or $b$ are themselves Fibonacci numbers.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/270904/exponential-equation-with-three-summands/270907\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI had a simple looking math problem the other day:\n\nSolve for $y(x) = 0$: $$ 10^{2x} - 101 \\cdot 10^x + 100 = 0$$\n\nSince I have three summands, I cannot just put them to either side of the equation and apply $\\log_{10}$ to it. And I cannot see how I could factor this to get it into a product to use $\\log_{10}$.\n\nMathematica gave me $x = 2$ as a result which seems correct. How can I find the solution to this one? It is supposed to be an elementary problem for an applied math class.\n\nshare|cite|improve this question\nHave you considered substituting something? \u2013\u00a0barto Jan 5 '13 at 12:29\nHint: notice that $10^{2x} = (10^x)^2$ ... and think of quadratic equations. \u2013\u00a0Old John Jan 5 '13 at 12:32\nHow could I not see this? Thanks! \u2013\u00a0Martin Ueding Jan 5 '13 at 12:35\nSomething else to look out for in this sort of question: sometimes they might give an equation that starts $10^{2x+1}\\dots$ and then you have to notice that this can be written as $10\\times (10^x)^2 \\dots$ \u2013\u00a0Old John Jan 5 '13 at 13:04\nup vote 2 down vote accepted\n\nThe key here is to note that $10^{2x} = (10^x)^2$. So we have $$10^{2x} - 101\\cdot 10^x + 100 = (10^x)^2 - 101\\cdot 10^x + 100.$$ Now letting $y = 10^x$, we are trying to solve $$y^2 - 101y + 100 = 0.$$ This has solutions $y = 1$ and $y = 100$ which correspond to $x = 0$ and $x = 2$.\n\nshare|cite|improve this answer\n\nIt is a quadratic equation in $10^x$. So that would make it: $$ 10^x = \\frac{101}{2} \\pm \\sqrt{\\frac{101^2}{4} - 100} $$ $$ \\implies 10^x = 1 \\lor 10^x = 100 \\iff x = 0 \\lor x = 2 $$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/182375/relationship-of-a-point-to-a-rotating-plane\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI have three points in space, which cannot move relative to one another, and create a reference plane.\n\nThere is a forth point, that lays off/on the plane (off will be more general solution, on will be a private case I guess).\n\nHow can I use the information I just described to predict where the point off/on the plane will lie when the plane moves? The point is constrained by the original relationship.\n\nFor example: $P_1$, $P_2$, $P_3$ define a plane and they are respectively $(1,1,5) , (0,1,5) , (-1,0,5)$.\nThe fourth point $P$ is $(-5,2,5)$ on the plane defined by $P_{1,2,3}$. What would be the coordinates of $P$ when the plane moves (arbitrary rotation in space) and $P_{1,2,3}$ have new values. In the example all points are on the same $z$ plane $(5)$ in the initial reference state.\n\n\nshare|cite|improve this question\nAre only rotations allowed? When you say 'rotation' you mean rotations around any axis, right? Are the old values of $P_i$ mapped onto the new ones (meaning that the angles of the triangle $P_1P_2P_3$ are preserved)? \u2013\u00a0Karolis Juodel\u0117 Aug 14 '12 at 9:11\nrotation could be any rotation, not just around specific axis. the old values are mapped. imagine a tool with 4 significant points that travels freely in the 3d space. \u2013\u00a0ButterFly Aug 14 '12 at 14:32\n\nConstruct the transformation matrix used on the plane and multiply $P$ by it. The matrix is $BA^{-1}$ where matrices $A$ and $B$ move the $xOy$ plane to the one defined by old and new values of $P_i$ respectively.\n\nHere's a way to construct $A$ and $B$. It makes sense to use $4 \\times 4$ matrices. Otherwise you couldn't map $(0, 0, 0)$ to anything else. The columns of the matrices could be as follows. $(P_2-P_1, 0)$, $(P_3-P_1, 0)$, $((P_2-P_1) \\times (P_3-P_1), 0)$ and $(P_1, 1)$. The first $3$ rows are filled with the values of the vectors I wrote and the last row is $(0, 0, 0, 1)$. Note that the third column could be anything. A perpendicular vector is probably what you are looking for, though. Notice that, for example, $A*(1, 0, 0, 1) = (P_2, 1)$. Finally, $BA^{-1}*(P, 1)$ is the new value of $P$.\n\nshare|cite|improve this answer\nA is perpendicular to the old or new plane ? is it a norm vector ? \u2013\u00a0ButterFly Aug 14 '12 at 14:36\nA and B are matrices. The upper left $3 \\times 3$ part of either is supposed to have orthonormal vectors for columns. Since we are combining two matrices, these vectors can be 'wrong', as long as they are 'wrong' the same way in A and B. The third vector is the normal of the plane - the old plane in A and the new plane in B. \u2013\u00a0Karolis Juodel\u0117 Aug 14 '12 at 15:04\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/65952/n-partite-n-clique\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWe are given an $n$-partite graph $G$. Each partition has $n$ vertices, some of which may be isolated. Let us number the vertices in some $i^{th}$ partition as $V_{i1},V_{i2},...,V_{in}$.\n\nNow each non-isolated vertex $V_{ij}$ has at least one neighbor in each of the remaining $n-1$ partitions s.t. for a given numbering of the vertices, the $n$ vertices (vertex $V_{ij}$ and its $n-1$ neighbors) form a permutation on the second index. For e.g., consider a 4-partite graph. Each partition has 4 vertices.\n\nUsing the numbering as given above, vertex $V_{12}$ has as neighbors vertices $V_{21},V_{34},V_{43}$. Vertex $V_{12}$ can have other neighbors as well. We need to show that the graph $G$ will always contain $n$-clique.\n\nA stronger claim would be to say that every vertex is part of some $n$-clique.\n\nshare|cite|improve this question\nFWIW here is a reformulation (I think). Let G be a graph with vertex set the edges of the complete bipartite graph K(n,n). Suppose that each vertex of G is contained in a perfect matching in K(n,n) and is joined to all the other edges in that perfect matching. Prove that G contains an n-clique. \u2013\u00a0gowers May 25 '11 at 12:44\nI haven't checked, but it seems likely to me that a random graph will be a counterexample: you need a very high edge probability to get an n-clique and I think probably a lot lower to satisfy your conditions with high probability. \u2013\u00a0gowers May 25 '11 at 12:52\nYou would need at least some constraint on the number of isolated vertices, wouldn't you? Currently, the graph with no edges at all is a counterexample. \u2013\u00a0Klaus Draeger May 25 '11 at 13:45\nYes, of course. I posted the details to finish it off. \u2013\u00a0fedja May 25 '11 at 13:46\nup vote 3 down vote accepted\n\nFalse as stated: take large $n$ and for each vertex $V_{ij}$ choose some random permutation and draw the corresponding edges. Now, we have $n^n$ possible cliques to form. Let's look at the probability that $V_{11},\\dots, V_{nn}$ is a clique. The chance that $V_{11}$ acquires $k$ fixed neighbors in this subgraph when its edges are drawn is $\\frac{(n-1-k)!}{(n-1)!}$. Multiplying by ${n-1\\choose k}$, we see that the chance to get $k$ vertices is less than $\\frac 1{k!}$. Thus, if $X_1$ is the number of acquired neighbors for $V_{11}$, then $Ee^{X_1}\\le e^e$. Thus $Ee^{\\sum X_j}\\le e^{en}$ by independence. But the clique means that $\\sum X_j\\ge n(n-1)/2$, so the probability that we have a given clique is at most $e^{en}e^{-\\frac{n(n-1)}2}$, which is smaller than $n^{-n}$ by an order of magnitude.\n\nI strongly suspect that you meant something else. Actually, my first impulse when seeing your post was to say \"Consider the graph consisting of isolated vertices only\" but then I decided that it would be too cheap.\n\nshare|cite|improve this answer\nIn your analysis, do you account for the edges that get added due to the permutations chosen by other vertices? I guess what I am trying to say is that once you have chosen the permutations for the vertices in a partition and added edges, when you are choosing permutations for vertices in the next partition, you only choose from the remaining $(n-2)!$ and so on. \u2013\u00a0Pawan Aurora May 26 '11 at 5:24\nAnd yes, each partition must contain at least one non-isolated vertex. The structure of the graph should remain consistent with the condition that each non-isolated vertex $V_{ij}$ has a set of $n-1$ neighbors (one in each of the remaining $n-1$ partitions) that form a permutation with $j$. What it means is that if there is some vertex in a partition that does not get any neighbor from a particular partition when adding edges, then that vertex must be isolated. \u2013\u00a0Pawan Aurora May 26 '11 at 5:24\nNot really. You said that you do not mind extra edges and you didn't say that the good edge sets must not overlap, so I run full drawing for each vertex. If I get some edges twice, I just consider myself lucky. \u2013\u00a0fedja May 26 '11 at 22:03\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/157784/can-we-always-find-a-primitive-element-that-is-a-square\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $L/\\mathbb Q$ be a galois extension. The Primitive element theorem says, that there is an element $\\alpha \\in L$, so that $L=\\mathbb Q(\\alpha)$.\n\nCan I always find an element $\\beta \\in L$, so that $L=\\mathbb Q(\\beta^2)$ ?\n\nshare|cite|improve this question\nGreat question! Just a small point: the primitive element theorem only applies to finite extensions. \u2013\u00a0Zev Chonoles Jun 13 '12 at 14:04\nAlso, the extension doesn't need to be Galois, just separable. [And over $\\mathbf Q$ everything is separable.] \u2013\u00a0Dylan Moreland Jun 13 '12 at 14:05\nThis is certainly true if $L$ has odd degree over $\\mathbf Q$. Do you see why? \u2013\u00a0Dylan Moreland Jun 13 '12 at 14:08\nup vote 7 down vote accepted\n\n$\\newcommand{\\Q}{\\mathbb Q}$\n\nI think this works. Let $K/\\Q$ be a finite field extension. Note that $K$ has finitely many subfields, call them $F_1,\\dots,F_t$ and let $W$ be their union. Then any element in $K \\setminus W$ is necessarily a primitive element. So it suffices to show their exists some $\\alpha \\in K \\setminus W$ that has a squareroot. Pick $\\alpha \\in K \\setminus W$, note that for $k \\in \\Q$ we still have $\\alpha_k=\\alpha + k \\in K \\setminus W$ otherwise $\\alpha \\in W$. Consider $\\alpha_k^2=(\\alpha+k)^2=\\alpha^2+2k\\alpha+k^2$ suppose that for every $k \\in \\Q \\setminus {0}$ we have $\\alpha_k^2 \\in W$. Then by the pigeonhole principle we must have some $j$ and $k_1 \\neq k_2$ such that $\\alpha_{k_1}^2,\\alpha_{k_2}^2 \\in F_j$. So we have\n\n$$\\frac{\\alpha_{k_1}^2-\\alpha_{k_2}^2-(k_1^2+k_2^2)}{2(k_1-k_2)} \\in F_j$$\n\n\n$$ \\frac{\\alpha_{k_1}^2-\\alpha_{k_2}^2-(k_1^2+k_2^2)}{2(k_1-k_2)} =\\frac{2\\alpha(k_1-k_2)}{2(k_1-k_2)}=\\alpha. $$\n\nWhich would imply that $\\alpha \\in F_j \\subset W$ so we have some $k \\in \\Q\\setminus \\{0\\}$ such that $(\\alpha+k)^2 \\in K \\setminus W$ and thereby $\\Q((\\alpha+k)^2)=K$.\n\nI think this could be turned into a constructive argument fairly easy. Take one of the primitive elements given to you by the primitive element theorem then add $t+1$ non-zero rational numbers to it and the square of one of those will be the desired element.\n\nAmmendum: This could also extend to a proof that there always exists an element $\\alpha \\in K$ such that $\\Q(\\alpha^n)=K$. Essentially use the same argument except find $t$ such distinct $c_i$ so that $\\alpha_{c_i}^n \\in F_t$ then notice that the matrix given by $A_{ij}=\\binom{m}{j}c_i^j$ has determinant a constant multiple of the vandermode matrix $A_{ij}=c_i^j$. Thereby the determinant is nonzero and so we can find a linear combination of the $\\alpha_{c_i}^n$ that gives us $\\alpha$.\n\nshare|cite|improve this answer\nThank you very much. It is a nice proof. \u2013\u00a0Lisa Mainhard Jun 14 '12 at 13:18\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/844231/polynomial-multiplication-modulo-polynomial\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nSuppose we are working on finite field $F_{16}$ and have pritimive polynomial $z^4+z+1$. I stuck at how to compute polynomial modulo. For example, we have $z^5+z+1$ mod $z^4+z+1$. I use the usual division, I obtain the remainder is $-z^2+1=z^2+1$ because each coefficient is over $F_2$. But I don't know whether this is the correct way to compute remainder. Can anyone help me?\n\nshare|cite|improve this question\nis the polynomial $x^4+x+1$ used to construct the field as in $\\mathbb{Z}_2[x]/\\langle x^4+x+1\\rangle$? \u2013\u00a0Anurag A Jun 23 '14 at 4:21 i refer to this website. For $x^3+2x^2$ mod $x^2-1$, I don't understand how the author obtains $x+2$. I use normal long division to solve, I obtain the remainder is $x-1$ \u2013\u00a0Idonknow Jun 23 '14 at 4:26\nup vote 4 down vote accepted\n\nI am assuming that $z^4+z+1$ is the irreducible polynomial used to construct the field $\\mathbb{F}_{16}$ (this is different from the concept of primitive element). In that case $z^4+z+1 \\equiv 0$.\n\n\\begin{align*} z^4+z+1 & \\equiv 0 \\pmod{z^4+z+1}\\\\ z^4 & \\equiv z+1 \\pmod{z^4+z+1}\\\\ z^5 & \\equiv z^2+z \\pmod{z^4+z+1}\\\\ z^5+z+1 & \\equiv z^2+1 \\pmod{z^4+z+1} \\end{align*} So you have the right answer but using the above congruences can help you reduce your work.\n\nshare|cite|improve this answer\n+1 But $z^4+z+1$ is a primitive polynomial. It is the most popular choice for a primitive quartic over $\\Bbb{F}_2$. Mind you, there isn't much competition as the reciprocal $z^4+z^3+1$ is the only other quartic primitive polynomial. Consequently any zero of $z^4+z+1$ in this field is a primitive element. \u2013\u00a0Jyrki Lahtonen Jun 23 '14 at 5:24\n\nIn general, long division will always give you the right answer, but is often tedious. An approach like in Anurag A's answer will often make that calculation easier, but sometimes requires a bit of cleverness.\n\nAs for the example in your comment, a similar idea works. If you're computing modulo $x^{2}-1$, you're saying that $x^{2} -1 \\equiv 0$, or $x^{2} \\equiv 1$. So, we get:\n\n$$ x^{3} + 2x^{2} = x \\cdot x^{2} + 2 \\cdot x^{2} \\equiv x \\cdot 1 + 2 \\cdot 1 = x+2 . $$\n\nI'm thinking you should double check your long division on that one.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55839.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nIrrationality of Root 2\n\nDate: 03/26/98 at 13:08:04\nFrom: mike lord\nSubject: DIRECT proof that root 2 is irrational\n\nMy question is this:\n\nI know that there are many ways to prove that root 2 is irrational.\nI've already seen the contradiction proof as well as the geometric \nproof. But I've heard that there is a way to prove that root 2 is \nirrational using a DIRECT method of proof. Could you please help?\n\nDate: 03/26/98 at 14:03:57\nFrom: Doctor Rob\nSubject: Re: DIRECT proof that root 2 is irrational\n\nThere is a proof using the simple continued fraction expansion of \n\n   sqrt(2) = 1 + 1/(2 + 1/(2 + 1/(2 + 1/(2 + 1/(2 + ...))))).\n\nThis expansion never ends. The \"convergents\" are obtained from this\nexpansion by stopping after any finite number of steps, and evaluating \nthe compound fraction as a simple fraction. It is a theorem that the\nconvergents are closer to the number being expanded than any other \nrational numbers with equal or smaller denominators. Since the \ndenominators of the convergents go to infinity as the number of steps \ndoes, it is clear that sqrt(2) could not be rational. At each step you \nhave a proof that sqrt(2) is not a rational number whose denominator \nis smaller than some bound, and that bound eventually exceeds any \nnumber after a sufficient number of steps.\n\nDoes that qualify as a \"direct\" proof?\n\nThere is also a proof by induction (in the form of Fermat's Method of\nDescent), but it has a definite indirect flavor:\n\nSuppose sqrt(2) = a/b, reduced to lowest terms. Note that \n1 < sqrt(2) < 2, so 0 < b < a < 2*b.  Then:\n\n           a^2 = 2*b^2\n     a^2 - a*b = 2*b^2 - a*b\n       a*(a-b) = b*(2*b-a)\n           a/b = (2*b-a)/(a-b)\n       sqrt(2) = (2*b-a)/(a-b)\n\nFurthermore, 0 < a - b < a, and 0 < 2*b - a < b.  This means that \nthere is a smaller numerator and denominator which will work. Repeat \nthis. You will get an infinite sequence of smaller and smaller \npositive integer denominators, but any decreasing sequence of positive \nintegers must be finite. This contradiction means that no such \nfraction a/b can exist.\n\nThis proof can be generalized to prove the irrationality of sqrt(d) \nfor any d not a perfect square:\n\nLet c < sqrt(d) = a/b < c + 1, with a, b, c, and d positive integers.\n\n           a^2 = d*b^2\n   a^2 - c*a*b = d*b^2 - c*a*b\n     a*(a-c*b) = b*(d*b-c*a)\n           a/b = (d*b-c*a)/(a-c*b)\n       sqrt(d) = (d*b-c*a)/(a-c*b)\n\nFurthermore, 0 < a - c*b < b, and 0 < d*b - c*a < a.  Repeat the above\n\n-Doctor Rob,  The Math Forum\nAssociated Topics:\nHigh School Number Theory\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/67041/how-many-elements-with-a-hamming-distance-of-3-or-less/67104\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\n[This is a complete rewrite which makes some of the comments redundant or irrelevant.]\n\nTake a set of $50$ elements. How many subsets of size $5$ are needed so that every subset of size $5$ will intersect at least one of these in at least $2$ points?\n\nThis collection of subsets is known as a lottery wheel or a lotto design. $L(v,k,p,t)$ is the minimum number of subsets of a $v$ element set so that each subset has size $k$ with the property that every $p$ element subset intersects at least one $k$-subset in at least $t$ points. If you select $5$ out of $50$ numbers in a lottery which pays a prize for getting at least $2$ numbers right, then you can ensure getting a prize if you buy a particular collection of $L(50,5,5,2)$ tickets. The question is to find $L(50,5,5,2)$.\n\nshare|cite|improve this question\nCould you explain your definition of $d_h$ a bit more? (By the way, that formula defining $S$ is horrendous! Words really are better for these things.) \u2013\u00a0James Cranch Jun 6 '11 at 13:58\nThis sounds like lottery wheels or lottery designs. I suggest a web search. Gerhard \"Ask Me About System Design\" Paseman, 2011.06.06 \u2013\u00a0Gerhard Paseman Jun 6 '11 at 18:53\n@chous: you have not really defined $S_3$ uniquely. I think what you're really saying is that you want some set $T$ such that for every $s \\in S$ there is some $t \\in T$ with $d_h(s,t) \\le 3$. There are lots of such sets, for example $S$ itself. But perhaps what you want is one with minimum cardinality: you're talking about a \"minimal cover problem\" in a graph $G$ consisting of the elements of $S$, with edges corresponding to pairs with Hamming distance $\\le 3$. \u2013\u00a0Robert Israel Jun 7 '11 at 0:54\nHamming distance works better on sequences than on sets. Although we could phrase your distance in terms of the symmetric distance of two sets, I think it easier to say \"For any 5-set t, I want there to be at least one of my 5-sets s in S such that s intersect t has at least two elements. Further, I want S chosen so that S has as few 5-sets in it as can be managed.\" The La Jolla Covering Repository answers this sort of question (if I read it right). Do a web search and check it out if you agree. Gerhard \"Donates Regularly To Mega Millions\" Paseman, 2011.06.06 \u2013\u00a0Gerhard Paseman Jun 7 '11 at 1:44\nYou are asking for a wheel with parameters $(50,5,2)$. A covering design is different, which is unfortunate because there is a nice searchable database of covering designs, the La Jolla Covering Repository which Gerhard Paseman mentions. Most of the web hits when you search for lottery wheels are trying to sell junk to lottery players. \u2013\u00a0Douglas Zare Jun 7 '11 at 8:29\nup vote 7 down vote accepted\n\nYou are not using the positions at all. You have 50 points. $S$ is the set of all $\\binom{50}{5}=2118760$ selections of 5 points. You want a subset $B \\subset S$ such that any $s \\in S$ intersects at least one $b \\in B$ in at least 2 points. That is an interesting problem and does not immediately strike me as familiar. Call a member of $B$ a block. A given block intersects $152026$ members of $S$ in 2 or more points. This gives a lower bound of $14$ for the possible size of $B$. Of course this a weak bound since two disjoint blocks determine $200$ members of $S$ intersecting one in 2 points and the other in 3 and another $4000$ intersecting each in 2 points. If my calculations are correct, that raises the lower bound to at least $19$ blocks. I doubt that $20$ would suffice.\n\nSo far my record is 44 blocks.\n\nLet me digress for some terminology (which I'll try to keep fairly standard). a design is a pair $D=(V,B)$ where $V$ is a set of $v$ vertices and a $B$ is a collection of subsets called blocks There are various names for designs which satisfy additional conditions. Two are\n\nEvery pair of points is in exactly one common block. (Then $D$ is called a linear space)\n\nEvery pair of points is in at least one common block and every block has the same number $k$ of points. (Then $D$ is called a $(v,k,2)$-covering design and the La Jolla Repository has information about these.)\n\nWhen both conditions hold, $D$ is called a Steiner System $S(2,k,v).$ Many that one encounters arise from algebraic constructions. This is perhaps due to the Streetlight effect.\n\nI'll coin the term super-linear space for a design such that every pair of points from $V$ occur in at least one common block but the blocks may have various sizes (since I don't know a standard name. It turns out that this might be called a lottery wheel although that term is not very specific)\n\nYou have $50$ points and do not require that every pair of points is in a block but do wish that from every 5 points (element of $S$), at least one pair is in at least one block. You also want all blocks to have $5$ points. I'll find it convenient to only require that each block have at most 5 points, then one can arbitrarily enlarge blocks to size 5.\n\nAll my constructions have this form: Split the points into 4 groups (or 2 or 3) and for each group take a super-linear space with no block having more than 6 points. Then any element of $S$ has two points in the same group and those two points are in a common block. Perhaps one can do better without this restriction. I include a few other possibilities in case it inspires anyone to get a better result.\n\n44* blocks. Split into 4 groups of size 21,21,4 and 4. For each of the large groups take the 21 lines of a projective plane of order 4 and let the two small groups be 4 point blocks. Now any set in $S$ has at least two points in a common group and those two pints determine a unique block.\n\n60 blocks: split the points into two sets of 25 and use the 30 lines of an affine plane of order 5 on each. This is overkill because any 3 element set has two points in some block. Perhaps there is a way to cull out some of the lines.\n\nUnder 52 blocks If the points are partitioned into 3 groups of 13 and one of 11 (with two fake points added in) then (for each group) the lines of a projective plane of order 3 were taken as blocks this would give a solution with 52 blocks of size 4. Delete $X,Y$ to improve this to 45 of size 4 and 6 of size 3 and one of size two. Now tack the block of size 2 onto a block of size 3 to get $51$ blocks (one of size 5). (If $X,Y$ are in different groups it might be better, I haven't checked.) One can also get rid of at least 3 more blocks as follows: take a block abcd, delete it and add b as a fifth point to a block containing c and another containing c, add c as a fifth point to two blocks containing d and a and add d as a fifth point to two blocks containing a and b.\n\nshare|cite|improve this answer\nThanks a lot! How would you recommend to build the projective 3 space of order 4? I think I'm currently not ready for this task :(. \u2013\u00a0chous Jun 7 '11 at 12:18\nAaron Meyerowitz's construction for $42$ blocks used $F_3$ rather than $F_4$, which should make it easier. The construction is just like that of $\\mathbb{RP}^3$ so that the points are lines passing through the origin in $\\mathbb{R}^4$ and the lines of $\\mathbb{P}^3$ correspond to (two-dimensional) planes passing through the origin. $\\mathbb{P}^3(F_4)$ has $(4^4-1)/(4-1)=85$ points, though. \u2013\u00a0Douglas Zare Jun 7 '11 at 17:53\n$\\mathbb{P}^3(F_3)$ has ${40 \\choose 2}/{4 \\choose 2} = 130$ lines, not $40$, so the construction for $42$ blocks actually uses $132$ blocks. It was a little too good to be true since it would mean any quadruple would intersect a block in $2$ points, and it would be easy to use the $5$th points to make a line redundant. \u2013\u00a0Douglas Zare Jun 7 '11 at 18:40\n\nHere is a construction of size $38$. Call the points cards and divide the deck into $4$ suits, so that $2$ suits have ranks $1,...,13$ and $2$ suits have ranks $1,...,12$. Every hand of $5$ cards must have at least $2$ cards in some suit. So, if we cover all possible pairs in each suit, the result will be a wheel.\n\nThe La Jolla Covering Repository says that $C(12,5,2)=9$ so we can cover all pairs within the short suits with $9$ hands each:\n\n1  2  4  7  9 \n1  3  4  6 12 \n1  3  7 10 11 \n1  5  6  8 12 \n2  3  5  7  8 \n2  6 10 11 12 \n3  6  7  9 12 \n4  5  8 10 11 \n5  8  9 10 11 \n\nSimilarly, it says $C(13,5,2) \\le 10$ so we can cover all pairs within the long suits with $10$ hands each:\n\n1  2  3  4  5\n1  6  7  8  9\n1 10 11 12 13\n2  3  6  7 10\n2  3  8  9 11\n4  5  6  7 11\n4  5  8  9 10\n2  3  4 12 13\n5  6  7 12 13\n1  8  9 12 13\n\nThe total is $38$ hands which intersect each hand of $5$ cards in at least $2$ cards. So, $L(50,5,5,2) \\le 38$.\n\nEdit: The best this method can do with the coverings known in the La Jolla Repository is $37$. That can be done by splitting a $50$ card deck into suits of sizes $(17, 11, 11, 11),$ $(13,13,13,11)$, or $(15, 13, 11, 11)$.\n\n$C(17,5,2) \\le 16$.\n\n$C(15,5,2) \\le 13$.\n\n$C(13,5,2) \\le 10$ as shown above.\n\n$C(11,5,2) \\le 7$.\n\nshare|cite|improve this answer\nThanks (truly!) for clarifying the question and making my LJCR comment less useful (since a covering design was not wanted) and also more useful (by showing how two covering designs could help). Gerhard \"Likes To Feel Really Useful\" Paseman, 2011.06.07 \u2013\u00a0Gerhard Paseman Jun 7 '11 at 23:47\nThanks! I wish I could mark more than one answers. Searching in the Internet I found a solution with 36 tuples, and I'll try to find more using your suggestions, but I'm not discarding using a \"branch and bound\" algorithm. \u2013\u00a0chous Jun 8 '11 at 19:45\n@Douglas Zare: Thanks for rewriting the question. It's much clearer now. \u2013\u00a0chous Jun 8 '11 at 19:50\nPlease post at least a link to the wheel of size $36$, since it must have been constructed using a different method. It's ok to answer your own question. \u2013\u00a0Douglas Zare Jun 8 '11 at 20:01\nThis 36 block solution is nice. It is actually close to one of the 37 block solutions by @Douglas. In the solution with suits of size 11,11,11,17 and covering designs of sizes 7,7,7,16, each covering design has a block which can be reduced to 3 cards. Take the 3 card blocks abc def ghi jkl and replace them by abcjk defjl ghikl. In fact one of the pairs from jkl ( in the 17 card suit) has a pair already covered so one could leave one of the hands with three cards. \u2013\u00a0Aaron Meyerowitz Jun 10 '11 at 5:38\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/690866/triangle-geometric-problem\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn triangle ABC, AB=BC=12. Side AC extended through C a length equal to itself to a point D. Point E is on AB; DE intersects BC at F and BF equal to 8. Find AE ?\n\nshare|cite|improve this question\n\nThe answer is $AE=BE=6$ because in the triangle ABD, BC is a median and F is the intersection point of medians, therefore DE is also median. Since, $BF=8$ then $CF=4$, but we know that the intersection point of medians splits them into two segments which lenghts have quatient 2:1 from the vertex.\n\nshare|cite|improve this answer\n+1 Nice way of seeing it, in this special setup. You could fill in a bit more details about why F is the centroid (of what triangle). \u2013\u00a0Calvin Lin Feb 26 '14 at 6:56\n\nBC divides AD in half. So in triangle ABD, BC is the median. BF:FC = 2:1, so F is the centroid. Since ED passes through centroid, it is also a median. Hence AE = BE = 6.\n\nshare|cite|improve this answer\n\nHint: Apply Menelaus' theorem to triangle $ABC$ and transversal $DEF$.\n\nshare|cite|improve this answer\nYes, more \"classical\" theorems that don't get much \"air play\" nowadays... \u2013\u00a0RecklessReckoner Feb 26 '14 at 7:16\n@RecklessReckoner If you are a student training for olympiads, they are important. But once you are out of that phrase of your life, very few people care about Euclidean Geometry anymore. \u2013\u00a0Calvin Lin Feb 26 '14 at 8:05\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-expected-frequencies-of-3-4-5-and-6-eggs.105383/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the expected frequencies of 3,4,5 and 6 eggs\n\n  1. Dec 30, 2005 #1\n    Hello, i found one question really difficult and I cant solve it. Please help.\n\n    Six hens are observed over a period of 20 days and the number of eggs laid each day is summarised in the following table:\n\n    No. of eggs: 3 4 5 6\n    No. of days: 2 2 10 6\n\n    This can be considered as a binomial model, with n=6, for the total number of eggs laid in a day. State the probability that a randomly chosen hen lays an egg on a given day. Calculate the expected frequencies of 3,4,5 and 6 eggs.\n\n    I know the probability required is 5/6. but i dont know how to find the expected frequencies.\n  2. jcsd\n  3. Dec 30, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You said it is a binomial distribution so the frequencies (probabilities) are\n\n    [tex]p_j = \\binom {6}{j} \\left( \\frac {5}{6} \\right)^j \\left( \\frac {1}{6} \\right)^{6-j}[/tex]\n  4. Dec 30, 2005 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Tide, that's assuming the base probability is 5/6 which is one of the things Clari needs to determine.\n\n    Clari, you should know that the expected value for a binomial distribution with base probability p is np. The 6 chickens laid a total of 100 eggs in 20 days or an average of 5 eggs per day. Assuming that the sample does reflect the actual expected value, np= 6p= 5 so p= 5/6.\n\n    Now use Tides's suggestion to answer the rest of the problem.\n  5. Dec 30, 2005 #4\n    Thanks for your help,Tide and HallsofIvy ^-^\n\nHave something to add?\n\nSimilar Discussions: Calculate the expected frequencies of 3,4,5 and 6 eggs"}
{"text": "Retrieved from https://www.physicsforums.com/threads/momentum-question.134264/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMomentum question.\n\n  1. Sep 30, 2006 #1\n    Guys I'm having a little problem in undersatnding a few things:\n    We have a wall and a ball of mass 'm'. The ball is thrown towards the wall with speed u and rebounds with speed 'v'. The coefficient of restitution is, e is 1/3. The question is to find the value of 'v'.\n    Thats how I think it should be solved:\n    mu=mv (since the final velocity of the wall is \"CONSIDERED\" zero)\n    => u=v\n\n    Now if I apply newton's law of restitution and simplify:\n    v=-eu (putting this into u=v gives us)\n    cancelling u gives e=-1 but e=1/3. Where did I go wrong? I just cant understand it.\n    Any help will be greatly appreciated.\n    Last edited: Oct 1, 2006\n  2. jcsd\n  3. Oct 1, 2006 #2\n    How can v=u given than e=1/3? The energy need not always be spent in speeding up an object. v = -1/3u.\n  4. Oct 1, 2006 #3\n    Oh my mistake. It is v=-eu. Original post edited.\n\n    I asked this question because nowadays we are doing oblique collisions between a wall and a ball in mathematics.\n    This is an example question(it appeared in exams a few years ago).\n    Velocity of the ball=u\n    angle which the ball makes with the smooth wall when it collides=45deg.\n    angle after collision=theta\n    velocity after collision=20m/s\n    Find u and angle theta.\n    I've got the answer by considering the component of velocity parallel and perpendicular to the wall. What I want to know is why Law of conservation momentum gives us false result considering it momemtum is conserved in ALL collision.\n  5. Oct 1, 2006 #4\n    Lets say you throw the ball against the wall and no energy is lost whatsoever. You would expect the ball to hit the wall and bounce back. If the ball loses no energy, then you also expect that its final speed is equal to its initial speed (in the opposite direction). Now examine it's momentum. Initially it had\n\n    p_0 = +mv\n\n    while finally it has\n\n    P_1 = -mv\n\n    This is a net momentum \"gain\" of |2mv| for the ball in the direction anti-parrallel to its initial velocity. Where has the momentum gone (or come from)?\n\n    The answer is that the wall suffers a net \"gain\" of -|2mv| of momentum. If the wall is fixed then the gain in momentum will be manifest as phonons (vibrations) in the wall. This is why someone else on the other side of the wall would hear you throwing the ball against it.\n\n    So momentum is conserved in the entire collision. It's just not very useful for calculating the longitudinal component of momentum for your ball.\n\nHave something to add?\n\nSimilar Discussions: Momentum question.\n  1. Momentum Question (Replies: 4)\n\n  2. Momentum questions (Replies: 4)\n\n  3. Momentum questions (Replies: 9)\n\n  4. Momentum Question (Replies: 5)\n\n  5. Momentum question (Replies: 5)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/333310/mathbb-ex4-with-x-sim-mathcal-n0-1?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have to calculate $(Y = X^2)$ $$ \\rho_{X,Y} = \\frac{\\mathbb Cov(X,Y)}{\\sigma_X \\cdot \\sigma_Y} $$ But for this I have to calculate $\\mathbb Var(Y)$ and thus $\\mathbb E[Y^2] = \\mathbb E[X^4]$. I dont think that integration helps. I would appreciate some litte hint :)\n\nshare|improve this question\nIntegration does help. The basic idea is to integrate by parts using $u\\,dv = x^3\\cdot xe^{-x^2/2}$ since $v = -e^{-x^2/2}$ is a known quantity. Hopefully, then you can recognize the integral $\\int v\\,du$ as something whose value you can deduce without the formality of integration. \u2013\u00a0 Dilip Sarwate Mar 18 '13 at 0:25\nIndeed. Thank you. \u2013\u00a0 Andr\u00e9 Mar 18 '13 at 0:26\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\n$\\newcommand{\\cov}{\\operatorname{cov}}$ $\\newcommand{\\E}{\\mathbb E}$ $$ \\cov(Y,X)=\\E(YX) - \\E(Y)\\E(X) = \\E(X^3)-\\E(Y)\\E(X). $$ Notice that $\\E(X^3)=0$ because the distribution of $X^3$ is symmetric about $0$ (and you can show the integral converges by a comparison test), and $\\E(X)=0$. Therefore $\\cov(Y,X)=0$.\n\nYou don't need $\\sigma_Y$ because the numerator is $0$. (But one can evaluate the integral.)\n\nAlso, it wouldn't hurt to notice what the graph of $y=x^2$ looks like and consider the implications of the symmetry of the distibution of $X$ and the symmetry of that curve about the $y$-axis. If $\\rho>0$, that would mean that on average, $Y$ increases as $X$ increases, and if $\\rho<0$, that would mean that on average, $Y$ decreases as $X$ increases. But the symmetries tell you that neither of those happens.\n\nshare|improve this answer\nThanks. I like answers which give some more intuition behind the pure math:) \u2013\u00a0 Andr\u00e9 Mar 18 '13 at 17:35\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/128993/on-solution-of-a-discrete-time-equation\nText:\nTake the 2-minute tour \u00d7\n\nHello, members. I have a problem for the following problem when I derive an optimization algorithm for stochastic singular systems $$S(k+1)=A(k)S(k)A^{T}(k)+R(k)+F(k)S(k+1)F^{T}(k)$$ where $R(k)>=0$ So, how to calculate $S$, is there analytic solution or numerical solution to $S$?\n\nThis problem is different from the following one On solution of a recursion with rectangular matrices\n\nThanks for your help\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nyou'll want to solve this equation iteratively, considering $S(k)$ as known and $S(k+1)$ as unknown; for $F(k)$ invertible you then have a Sylvester equation, of the form $F^{-1}(k)S(k+1)-S(k+1)F^{T}(k)=C(k)$, which has a unique solution iff $F^{-1}(k)$ and $F(k)$ have no common eigenvalue. The Wikipedia page gives algorithms to solve this equation, implemented in several software packages.\n\nshare|improve this answer\nThere are numerical methods dealing directly with the equation $X-FXF^T=C$, known as discrete-time Lyapunov equation, or Stein equation. There is no need to invert $F$ and convert it to a Sylvester; sometimes algorithms even go the other way round and convert a continuous-time Lyapunov equation to a discrete-time one to solve it. \u2013\u00a0 Federico Poloni Apr 28 '13 at 18:37\nThanks for your kind help, Dr. Carlo and Dr. Federico. When $F$ is singular, The Sylvester method may fail to work. So, would you please give me some links or references on the equation $X-FXF^{T}=C$. It seems we can solve it using LMI techniques for obtaining numerical solutions. \u2013\u00a0 eolithr Apr 29 '13 at 1:07\nNo, I made the problem too complex. By using 'dlyap' in Matlab can solve this equation. \u2013\u00a0 eolithr Apr 29 '13 at 3:04\nYep. dlyap will be fine for a small-scale problem; it should use a variant of the same Bartels-Stewart method that is used for continous-time lyapunov eqs; essentially, take a Schur form of $F$ and solve directly via back-substitution for each entry of $X$ \"in the right order\". For large-scale problems, you can truncate the series $X=\\sum_{i=0}^{\\infty} F^{i}CF^{Ti}$, or obtain the partial sum truncated at the term $2^{k}$ directly from the one truncated at $2^{k-1}$ with some manipulations (Smith methods). You can apply some M\u00f6bius transforms to $F$ without changing the solution to make... \u2013\u00a0 Federico Poloni Apr 29 '13 at 7:09\nit more stable, and ultimately obtain a discrete-time version of the ADI method for Lyapunov equations. In short, with some algebraic manipulations everything that works in the continuous-time case rates to work in the discrete-time case as well. \u2013\u00a0 Federico Poloni Apr 29 '13 at 7:10\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/88334/isomorphism-of-cobordisms\nText:\nTake the 2-minute tour \u00d7\n\nLet $(M, \\partial_{-}M, \\partial_{+}M)$ be a decorated 3-cobordism, where $M$ be a (topological) 3-manifold and $\\partial M=-\\partial_{-}M \\cup \\partial_{+}M$. (decorated in a sense of Turaev, Quantum invariants of knots and 3-anifold, on page 159.) Suppose $M$ is homeomorphic to a cylinder over a torus $\\Sigma \\times I$, where $\\Sigma$ is a torus $S^1 \\times S^1$.\n\nLet $f_{-}: \\Sigma \\to \\partial_{-}M$ and $f_{+}: \\Sigma \\to \\partial_{+}M$ be parametrizations of bottom and top boundaries respectively.\n\nConsider the composition\n\n$H_1(\\Sigma; \\mathbb{Z}) \\to H_1(\\partial_{-}M; \\mathbb{Z}) \\to H_1(\\partial_{+}M; \\mathbb{Z}) \\to H_1(\\Sigma; \\mathbb{Z})$.\n\nHere the first and the third ismorphism are induced by the parametrizations $f_{\\pm}$ respectively and the second isomorphism (let's say $h$) is obtained by pushing loops in the bottom base of $M$ to the top base using the cylindrical structure on $M$.\n\n\nIs this cobordism $(M, \\partial_{-}M, \\partial_{+}M)$ (d-)homeomorphic to a cobordims $(\\Sigma \\times I, \\Sigma \\times 0, \\Sigma \\times 1)$, where the parametrization on the top is given by the identity of $\\Sigma$ and the bottom is given by $f_{+}^{-1}hf_{-}$?\n\nPlease give me a proof. Thanks.\n\n\nIn this context, \"decorated\" can be almost ignored. What important here is that the homeomorphism of two cobordism is a homeomorphism of the two manifolds and if it is restricted on boundaries, it should commute with the given parametrizations.\n\nThe parametrization in this context means a degree 1 homeomorphism from a fixed torus to $\\partial_{-}M$ and $\\partial_{+}M$\n\nshare|improve this question\nI don't have Turaev's book in front of me but it looks like either the result follows immediately or it might be slightly sensitive to the definition of \"parametrization\" together with the structure of the mapping class group of $\\Sigma$. It would help if you could make your question more self-contained, including the conventions Turaev uses. \u2013\u00a0 Ryan Budney Feb 13 '12 at 8:07\nI agree with what Ryan said. If it's just a question of whether the homeomorphism between the 3-manifolds commutes with the boundary parameterizations, then the answer to you question is clearly yes. Also, if anyone cares, this question is a continuation of mathoverflow.net/questions/87567 \u2013\u00a0 Kevin Walker Feb 13 '12 at 13:42\nI think it should be trivial but I don't know how to prove it. Can you construct a homeomorphism? \u2013\u00a0 knot Feb 14 '12 at 2:02\nI don't understand your question (in the above comment). You wrote \"Suppose $M$ is homeomorphic to a cylinder...\", so the homeomorphism between $M$ and $\\Sigma\\times I$ exists by assumption; there is no need to construct it. \u2013\u00a0 Kevin Walker Feb 14 '12 at 14:59\nYes, by assumption we have a homeomorphism $\\varphi: M \\to \\Sigma \\times I$. The parametrization of this cobordism is given by $f_{\\pm}$ on top and bottom respectively. What I want to have is a homeomorphism from this cobordism to a cobordism $(\\Sigma \\times I, \\Sigma \\times 0, \\Sigma \\times 1 )$, whose parametrization is given by the identity on the top and $f_{+}^{-1}hf_{-}$ on the botton as in the question above. Does it make sence? \u2013\u00a0 knot Feb 14 '12 at 16:59\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/45759/find-the-limit-lim-limits-n-to-infty-cos-left-pi-sqrtn2-n-right/45760\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'd love your help with finding the following limit: $$\\lim_{n\\to \\infty }\\cos (\\pi\\sqrt{n^{2}-n}).$$\n\nI was asked to find this limit, but honestly I believe that it doesn't exist.\n\nAccording to Heine Theorem of limit of functions, I can choose two sequences:\n\n$x_{k}=2\\pi k$ and $y_{k}=2\\pi k+\\pi$ and notice that when I apply the function on both of them, I'll get -1 and 1, respectively.\n\nAm I right?\n\nThank you again.\n\nshare|cite|improve this question\nDo you mean to have that $\\pi$ in your sequences? There's already multiplication by $\\pi$ inside the cosine. Or did you plan to start with, say, $x_k$, and work backwards to a sequence of $n_k$ such that $\\cos\\pi\\sqrt{n_k^2-n_k} = \\cos{x_k}$? \u2013\u00a0MartianInvader Jun 16 '11 at 17:12\nYes, my mistake. without the $\\pi$'s. thanks. \u2013\u00a0user6163 Jun 17 '11 at 7:05\nYou kinda started the wrong way, by asking what tool to use. Your first question should have been \"what's happening here?\" It is then natural to calculate, for largish but not too large $n$. (Not too large because if you take $n=10^9$, roundoff error kills you.) So look at $n=100, 101, 102$. Calculate. You will get answers near $0$. And while you are taking $\\sqrt{n^2-n}$, you may notice it is almost exactly halfway between consecutive integers. Now an idea for a proof may come. \u2013\u00a0Andr\u00e9 Nicolas Jun 18 '11 at 3:39\nup vote 56 down vote accepted\n\nWe have \\begin{align*} \\cos (\\pi\\sqrt{n^2-n})&= (-1)^n\\cos(\\pi(\\sqrt{n^2-n}-n))\\\\ &= (-1)^n \\cos\\pi\\frac{-n}{\\sqrt{n^2-n}+n}\\\\ &=(-1)^n\\cos \\pi\\frac 1{\\sqrt{1-\\frac 1n }+1}, \\end{align*} hence $|\\cos(\\pi\\sqrt{n^2-n})| = \\left|\\cos \\left(\\pi\\frac 1{\\sqrt{1-\\frac 1n }+1}\\right)\\right|$. Since $\\lim \\limits_{n\\to +\\infty}\\pi\\frac 1{\\sqrt{1-\\frac 1n }+1} =\\frac{\\pi}2$, the $\\cos$ is continuous and $\\cos \\frac{\\pi}2 =0$ we conclude that the limit is $0$.\n\nshare|cite|improve this answer\nIt is intresting that when you go by intuition and write the limit as $\\cos \\pi n\\sqrt{1-\\frac{1}{n}}$ you sincerely might think that the limit does not exist. \u2013\u00a0user6163 Jun 18 '11 at 10:14\n@Nir Yes, I agree. The idea comes from an exercise that I've done some years ago. I had to look at the convergence of the series $\\sum_{n\\geq 0}\\sin(\\pi\\sqrt{n^2+1})$. \u2013\u00a0Davide Giraudo Jun 18 '11 at 10:25\nAre you sure of this answer?*sqrt+%28n^2-n%29%29 \u2013\u00a0user6163 Jun 18 '11 at 10:37\n@Nir: it is very important that $n$ here is integer. \u2013\u00a0Marek Jun 18 '11 at 12:18\n\nSince a nice formal argument has been supplied by Davide Giraudo, I will allow myself the luxury of informality.\n\nLet $n$ be a large positive integer. Complete the square. We have $$n^2-n=\\left(n-\\frac{1}{2}\\right)^2 -\\frac{1}{4}$$\n\nTake the square root. When $n$ is very large, the term $-1/4$ makes a vanishingly small contribution to the square root.\n\nSo our square root is nearly equal to $n-1/2$. And the cosine of $\\pi n -\\pi/2$ is $0$.\n\nshare|cite|improve this answer\n\nConsidering the form $\\cos(\\pi n \\sqrt{1-\\frac{1}{n}})$ and using Taylor's expansion for $\\sqrt{1-\\frac{1}{x}}$ $\\to$ see here, we get that when n is large $\\cos (\\pi\\sqrt{n^{2}-n}) \\approx \\cos( \\pi n -\\frac{\\pi}{2})$. Therefore, $L=0$.\n\n\nshare|cite|improve this answer\nNice answer Chris's sis........ \u2013\u00a0juantheron Nov 3 '13 at 13:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/609700/in-how-many-ways-can-we-select-n-objects-from-a-collection-of-size-2n-that-consi\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn how many ways can we select $n$ objects from a collection of size $2n$ that consists of $n$ distinct and $n$ identical objects?\n\nThe answer is $2^n$ and I really don't see how they get this. Selecting $n$ distinct from $2n$ is $\\binom{2n}{n}$.\n\nshare|cite|improve this question\nTry working a small example: one white sock, one red sock, two black socks. Hint: sort the 12 possibilities in order by number of black socks. \u2013\u00a0Eric Lippert Dec 17 '13 at 0:31\n\nLet $A=\\{a_1,\\ldots,a_n\\}$, where the $a_k$ are mutually distinguishable, and let $S$ be $A$ together with $n$ indistinguishable objects. An $n$-element subset $X$ of $S$ is completely determined when you know $X\\cap A$: if $|X\\cap A|=k$, the remainder of $X$ is just $n-k$ of the indistinguishable objects. $A$ has $2^n$ subsets, so there are exactly $2^n$ different possibilities for $X\\cap A$ and therefore for distinguishable sets $X\\subseteq S$ of cardinality $n$.\n\nshare|cite|improve this answer\n\nHint. If you choose $k$ elements from the $n$ distinct, and $n-k$ from the $n$ identical, there are:\n\n$$\\binom{n}{k}\\cdot 1$$\n\nways to do this. Now sum from $k=0$ to $k=n$.\n\nshare|cite|improve this answer\n\nNote that the set of objects chosen is determined by which of the distinct objects are chosen and how many of the identical objects are chosen. For each of the $2^n$ subsets of the $n$ distinct objects, the number of identical objects we need to take in order to fill our quota of $n$ total objects is uniquely determined. Hence there are $2^n$ total ways to take $n$ total objects from $n$ distinct and $n$ identical objects.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/63283/proof-that-lnn2-lnn-1-n-for-all-n-in-mathbbn\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI would like to know which proof strategy to use when proving the next inequality: $\\ln(n^2)(\\ln(n) - 1) < n,\\quad\\forall n \\in \\mathbb{N}$. I have been trying to use this two proved inequalities $\\dfrac{n}{n+1} < \\ln(n+1) < n$ ,but it did not give me solution.\n\nshare|cite|improve this question\nHint: $log(n^2)(log(n)-1) \\le 2 log(n)^2$. \u2013\u00a0Dan Brumleve Sep 10 '11 at 9:08\n@Dan,I think that it is wrong approach \u2013\u00a0pedja Sep 10 '11 at 9:32\npedja, try $n \\ge 14$. Can you show inductively that the inequality continues to be satified? Then check the finite cases. \u2013\u00a0Dan Brumleve Sep 10 '11 at 9:41\n@pedja, please DO NOT CHANGE (substantially) THE QUESTION, it invalidates correct answers to the question as was asked. If you want to ask a different question, you can leave this one as is and go ask a different question. \u2013\u00a0Did Sep 11 '11 at 8:50\n@pedja Also, I do not think that the [algebra] tag means what you take it to mean. The [algebra-precalculus] tag seems more appropriate (even though most solutions till now seem to employ calculus in some form). \u2013\u00a0Srivatsan Sep 11 '11 at 8:57\nup vote 7 down vote accepted\n\nDefine a function $u$ on $x>0$ by $u(x)=x-\\log(x^2)(\\log(x)-1)=x-2\\log(x)^2+2\\log(x)$. The goal is to prove that $u(n)>0$ for every positive integer $n$, let us prove the stronger statement that $u(x)\\ge1$ for every real number $x\\ge1$.\n\nTo do so, first note that $u'(x)=v(x)/x$ with $v(x)=x-4\\log(x)+2$ and that $v'(x)=1-4/x$, hence $v$ is decreasing on $(1,4)$ and increasing on $(4,+\\infty)$.\n\nSince $v(4)=6-8\\log(2)=.4548>0$, $v>0$ everywhere and $u$ is increasing. In particular, $u(x)\\ge u(1)=1$ for every $x\\ge1$.\n\nFinally, for every positive integer $n$, $$ \\log(n^2)(\\log(n)-1)\\le n-1<n. $$\n\nshare|cite|improve this answer\n,I was looking for more \"algebraic\" proof but this looks nice also....I will wait bit more before accepting answer \u2013\u00a0pedja Sep 10 '11 at 13:10\n\nMake the substituting $x = \\log n$, so $x \\geq 0$. The inequality now reads $$ 2x(x-1) < \\exp(x). $$ All we have to do know is to take the Taylor expansion of $\\exp(x)$ and stop at the right place. For example, $$ 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\frac{x^4}{24} < \\exp(x), $$ and it so happens that when $x \\geq 0$, $$ 2x(x-1) < 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\frac{x^4}{24}. $$ This can be verified formally using e.g. Sturm sequences (or by finding explicitly all the roots using the quartic formula).\n\nshare|cite|improve this answer\n,using quartic formula is not so elegant solution but may give positive result... \u2013\u00a0pedja Sep 11 '11 at 5:07\nquartic formula \u2013\u00a0pedja Sep 11 '11 at 5:36\n\nHere's a simple approach. Verify the inequality for the base cases $n=1$ and $n=2$; we will assume $n \\geq 3$ from now on. Let us now make the substitution $x = \\ln n$ (where $x \\geq \\ln 3 > 1$), and rewrite the inequality as $e^x \\geq 2x(x-1)$.\n\nUsing the famous inequality $e^{t} \\geq t+1$, we get $$ e^{x- \\frac{3}{2}} \\geq x- \\frac{1}{2}. $$ for all real $x$. Integrating between the limits $0$ and $x > 0$, we get: $$ e^{x- \\frac{3}{2}} - e^{-\\frac{3}{2}} \\geq \\frac{1}{2}(x^2-x). $$ Rearranging this slightly (and dropping one term), we get $$ e^x \\geq \\frac{e^{3/2}}{4} \\cdot 2x(x-1), $$ which implies the claim since $\\frac{e^{3/2}}{4} \\geq 1.1 > 1$. (Note that the final step is valid only if $2x(x-1)$ is positive, but this is the true since $x \\geq 1$.)\n\nshare|cite|improve this answer\nIt is funny that the numerical evaluation your solution relies on, namely that $\\log(2)<\\frac34$, is exactly the one needed in my solution, although the rest of our proofs seem to use different arguments. \u2013\u00a0Did Sep 11 '11 at 7:18\n@Didier That's true, I didn't see that till now. :-) There should be some explanation I guess... \u2013\u00a0Srivatsan Sep 11 '11 at 7:25\n@SrivatsanNarayanan,Brilliant but not strictly algebraic since integration is involved \u2013\u00a0pedja Sep 11 '11 at 8:01\n@pedja I do not know what Didier thinks, but my answer is: it depends. Since you did not (!) object to my first inequality $e^t \\geq t+1$, if you are ok with using it, I can actually believe that there is an algebraic proof that uses only that inequality. Otherwise I cannot imagine any way... \u2013\u00a0Srivatsan Sep 11 '11 at 8:13\n@pedja, I usually try to avoid thinking, it gives me headaches... More seriously, I wanted to draw your attention to the fact that the logarithm is not a priori an algebraic object (whatever that means), hence that your motto of a purely algebraic proof was odd, mathematically speaking. (As regards MO etiquette, you did not mention this requirement in the question itself and you gave no motivation for it). \u2013\u00a0Did Sep 11 '11 at 8:21\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-can-one-find-the-area-between-the-curves.90727/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHow can one find the area between the curves\n\n  1. Sep 25, 2005 #1\n    when three curves intersect,i mean like the intersection of three straight lines to give a triangle,how can one find the area between the curves\n  2. jcsd\n  3. Sep 25, 2005 #2\n    area of a triangle is given by 1/2 * b * h\n  4. Sep 25, 2005 #3\n    I think mathelord means any three curves. You can use a double integral. Do you know calculus?\n  5. Sep 25, 2005 #4\n    If you don't know calculus you calculate the height. The factor of two perpendicular slopes is -1.\n  6. Sep 26, 2005 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The man said curves! Assuming he is asking about the area of the region formed by three general curves, he will need to use caluculus.\n\n    Exactly how that is done depends on the curves themselves. In the very common situation, a sort of \"curvy\" triangle, where you have one curve under the other two (between the points where the other two intersect it), then you don't need a double integral. You will need to break the integral into two parts. I'm going to call the curve on the bottom C1, the graph of y= f1(x), and the other two C1 and C2, graphs of y=f2(x), y= f3(x) respectively. Let's say that C2 intersect C1 at x=a, C3 intersects C1 at x= c, and that C2 is below C3 until they intersect at x= b after which C3 is below C2.\n\n    Then the area is given by two separate integrals:\n    [tex]\\int_a^b(f2(x)-f1(x))dx+ \\int_b^c(f3(x)-f1(x)dx[/tex]\n\nHave something to add?\n\nSimilar Discussions: How can one find the area between the curves\n  1. How do i find the area (Replies: 1)\n\n  2. How can one prove (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limit-of-a-long-trig-function.268716/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLimit of a long trig function.\n\n  1. Nov 2, 2008 #1\n    x->0 ((sin5x)/(sin2x) - (sin3x)/(4x))\n\n    2. Relevant equations\n    i guess sinx/x as x approaches zero is 1.\n\n    3. The attempt at a solution\n    lets be honest, this is a simple question. i am getting a final answer of 4, but it is wrong apperently according to the book's solution. i want to see if anyone else got this answer\n\n    I separated the limit into two limits, divided by 5x's and 2x's on the left limit and divided by 3x's on the right limit. this shouldnt be a problem (and yes i divided top and bottom by the same amounts so they would cancel out; thats not my mistake). please someone help\n  2. jcsd\n  3. Nov 2, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    You've obviously made an algebra error somewhere, If you show your work, we can tell you where your error is.\n  4. Nov 2, 2008 #3\n\n\n    Staff: Mentor\n\n    Are you sure you have given us the problem as it appears in your book or assignment? Could it be lim sin(5x)/(2x) - sin(3x)/(4x)? If so, that's a much simpler problem, whose limit is 1.75, as x approaches 0.\n  5. Nov 2, 2008 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    [tex]\\frac{sin(3x)}{4x}= \\frac{3}{4}\\frac{sin(3x)}{3x}[/tex]\n\n    [tex]\\frac{sin(5x)}{sin(2x)}= \\frac{5}{2}\\frac{sin(5x)}{5x}\\frac{sin(2x)}{2x}[/tex]\n  6. Nov 2, 2008 #5\n    HOW IS IT 1.75!!!!!!!!!!!!!!!!!!!! wheres the flaw in my logic.\n\n    (sin5x)/sin2x = [((sin5x)/(5x*2x)]/[(sin2x)/(5x*2x)]\n    = (5/2x)/(2/5x))\n    = 25/4\n\n    (sin3x)/4x = [(sin3x/3x)]/[(4x/3x)]\n    = 3/(4x/3x)\n    = 3/(4/3)\n    = 9/4\n\n    25/4 - 9/4 = 16/4 = 4 where is my flaw!!!???\n  7. Nov 2, 2008 #6\n\n\n    Staff: Mentor\n\n    Halls, are you missing a division symbol in your second equation?\n  8. Nov 2, 2008 #7\n\n\n    Staff: Mentor\n\n    How did you get (5/2x)/(2/5x)) from the expression above it? lim (as x [tex]\\rightarrow[/tex] 0) of sin(5x) / (5x) is 1, not 5, if that's what you did.\n\n    The expression on the right side of your first line is equal to\n    [tex]\\frac{sin(5x)}{5x} * \\frac{5x}{2x} * \\frac{2x}{sin(2x)}[/tex]\n    As x [tex]\\rightarrow[/tex] 0, this expression approaches 1 * 5/2 * 1 = 5/2. Similarly sin(3x)/(4x) approaches 3/4, so the difference approaches 7/4 = 1.75.\n\n    Regarding my earlier question about whether the denominator of the first fraction should have been 2x rather than sin(2x), it doesn't matter. For x close to 0, sin(x) [tex]\\approx[/tex] x, and sin(2x) [tex]\\approx[/tex] 2x.\n\n\nHave something to add?\n\nSimilar Discussions: Limit of a long trig function.\n  1. Limit of trig function (Replies: 23)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/371176/the-limit-of-the-integrals-int-02-pi-sinnx-fx-dx\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nHow to prove that if $f \\in C[0,2 \\pi]$, then $$ 2\\pi \\lim_{n \\to \\infty} \\int_0^{2 \\pi} |\\sin(nx)-f(x)| \\, dx = \\int_0^{2 \\pi} \\int_0^{2 \\pi} |\\sin(y)-f(x)| \\,dx \\, dy\\ ? $$ This is true for constant functions, by direct calculation.\n\nshare|cite|improve this question\nWhat did you try? (Personally, I see no direct connectin between the two sides \u2013 but I would start by switching the order of the integrals on the right, then evaluating the inner integral explicitly. Perhaps as a warmup exercise, try to prove it when $f$ is a constant.) \u2013\u00a0Harald Hanche-Olsen Apr 24 '13 at 5:35\nThis statement is trivial for constant functions. \u2013\u00a0user64494 Apr 24 '13 at 5:46\nIndeed. But what if $f$ is a constant times the characteristic function of an interval inside $[0,2\\pi]$? (That's not continuous, but this should not matter.) Or a step function? We lack linearity here, so you have to be careful. But I still imagine you might get something out of these cases. \u2013\u00a0Harald Hanche-Olsen Apr 24 '13 at 10:05\nup vote 3 down vote accepted\n\nStart writing \\begin{align} \\int_0^{2\\pi}|\\sin(nx)-f(x)|dx&=\\frac 1n\\int_0^{2n\\pi}|\\sin(t)-f(tn^{-1})|dt\\\\ &=\\frac 1n\\sum_{k=0}^{n-1}\\int_{2k\\pi}^{2(k+1)\\pi}|\\sin t-f(tn^{-1})|dt\\\\ &=\\frac 1n\\sum_{k=0}^{n-1}\\int_0^{2\\pi}\\left|\\sin t-f\\left(\\frac tn+\\frac{2\\pi}nk\\right)\\right|dt. \\end{align} It's a Riemann sum and the terms $tn^{-1}$ doesn't matter by uniform continuity.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/9840/finding-roots-of-polynomials-negative-square-root/9843\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nThe formula for finding the roots of a polynomial is as follows\n\n$$x = \\frac {-b \\pm \\sqrt{ b^2 - 4ac }}{2a} $$ what happens if you want to find the roots of a polynomial like this simplified one $$ 3x^2 + x + 24 = 0 $$ then the square root value becomes $$ \\sqrt{ 1^2 - 4\\cdot3\\cdot24 } $$ $$ = \\sqrt{ -287 } $$\n\nwhich is the square root of a negative number, which isn't allowed. What do you do in this case? I know there are other methods, i.e. factorisation and completing the square, but does this mean that this formula can only be used in specialised cases or have i gone wrong somewhere along the path?\n\nshare|cite|improve this question\n@Chandru1: Also, \\cdot looks better than * don't you agree? \u2013\u00a0AD. Nov 11 '10 at 10:00\nThe answers explain what is $\\sqrt{-287}$. You can verify that $3x^{2}+x+24$ (like any other quadratic polynomial) can be factored as $3(x-x_{1})(x-x_{2}) $, even in this case where $x_{1,2}$ are non real roots, $3$ being the coefficient of $x^{2}$: $3\\left( x+\\frac{1}{6}+\\frac{\\sqrt{-287}}{6}\\right) \\left( x+\\frac{1}{6}-\\frac{-\\sqrt{-287}}{6}\\right) $ $=3\\left( x+\\frac{1}{6}\\right) ^{2}-3\\left( \\frac{\\sqrt{-287}}{6}\\right) ^{2} $ $=3x^{2}+x+\\frac{1}{12}-\\frac{-287}{12}=3x^{2}+x+24$ \u2013\u00a0Am\u00e9rico Tavares Nov 11 '10 at 13:02\nRemember that the quadratic formula is just a generalization of completing the square, so it's really all the same. \u2013\u00a0friedo Nov 11 '10 at 15:58\nIn the last factor of my comment the minus signal before $\\sqrt{-287}$ is a typo. \u2013\u00a0Am\u00e9rico Tavares Nov 12 '10 at 10:24\nup vote 11 down vote accepted\n\nThe other answers are nice, so I won't reiterate them. It's worth pointing out, though, that when you say \"I know there are other methods, i.e. factorisation and completing the square, but does this mean that this formula can only be used in specialised cases\", you seem to be implying that these other methods might yield different results.\n\nThis isn't the case. If the quadratic formula fails to give you real-valued answers, then the other two methods (and every applicable method) will also fail, because the quadratic polynomial itself simply doesn't have any real-valued roots.\n\nYou can visualize this easily: as you may know, the graph of a quadratic polynomial is a parabola, and the real roots of a polynomial correspond to its graphs' zeros, i.e. points where the graph crosses the $x$-axis. So if you imagine a parabola with its vertex above the $x$-axis and opening upwards, you can see that it will never cross the $x$-axis -- it has no real zeros at all! alt graph of quadratic polynomial\n\nThis is exactly the situation with $y = 3x^2 + x + 24$ and every other quadratic polynomial for which $b^2 - 4ac$ (the discriminant) is negative.\n\nLastly (since it seems as though this may be one of your first introductions to complex numbers) let me clarify something that confuses my students greatly: don't let the words \"real\" and \"imaginary\" mislead you into thinking that real numbers are somehow genuine or actual and imaginary numbers are somehow fake.\n\nJust like a \"negative\" number isn't sad, cynical, or irritated, and just as an \"irrational\" number isn't my crazy ex-girlfriend, \"real\" and \"imaginary\" are technical terms, and not meant to carry with them their English connotations. Although they earned those names due to prior misunderstandings about numbers, today we know that imaginary numbers are just as actual and valid as real numbers, and in fact complex (not \"complicated\") numbers have huge real-world applications and consequences.\n\nAlong these same lines: you say that taking the square root of a negative number \"isn't allowed\". More accurate would be to say that the square root of a negative number isn't a real number (\"real\", again, in the technical sense). If you require the result of taking the square root to be a real number, then you're right, taking the square root of a negative isn't allowed. But otherwise it's perfectly fine.\n\nBy analogy: you're allowed to divide the whole number 6 by the whole number 3, and the result is the whole number 2. But if you divide the whole number 1 by the whole number 2, then the result, $\\frac{1}{2}$, isn't a whole number. If you require your operations on a certain class of numbers to produce a result from that same class of numbers, then lots of operations (like division, and subtraction too, for that matter) will have situations in which they aren't \"allowed\" to occur.\n\nThis requirement is sometimes very desirable, and there are certainly contexts in which you will want to impose it. But you should understand that imposing this requirement is a choice that you make because it fits the context of the problems you're working on. It's not divine law. If you find yourself in a situation in which you would like to take the square root of a negative number and produce the corresponding imaginary number, you are definitely \"allowed\" to do so.\n\nshare|cite|improve this answer\nI believe even Gauss himself lamented the poor choice of words \u2013\u00a0J. M. Nov 11 '10 at 12:32\nThanks Alex, your answer leads to a clear understanding of why the discriminant is negative, as well as why the method fails, which is actually more important to understanding the problem than the mechanics of working out the roots on the complex plane. Also a graph always helps. \u2013\u00a0Aran Mulholland Nov 12 '10 at 0:07\n+1 just because it has a nice graph. \u2013\u00a0Djaian Nov 12 '10 at 7:06\n\n100% correct, and good observation.\n\nTo solve this, we define $\\sqrt{-1}=i$ where $i$ is the imaginary unit\n\nThen $\\sqrt{-287}=\\sqrt{287}i$, and we can solve as per the general quadratic formula. Numbers of the form $a+bi$ are known as complex numbers and are extremely useful.\n\nIn general the term $b^2-4ac$ is known as the discriminant of the quadratic equation. It should be clear that if $b^2-4ac>0$ there exists two real solutions, if $b^2-4ac=0$ there is one solution (the repeated root) and if $$b^2-4ac \\lt 0$$ there are two complex solutions.\n\nThe quadratic formula is the most general way to solve the quadratic equation - so you are doing the right thing.\n\nshare|cite|improve this answer\nyour explanation cuts off (i think the markup might be at fault), could you edit it so i can read the rest of it? It's good so far. \u2013\u00a0Aran Mulholland Nov 11 '10 at 9:24\n@Aran Mulholland: this is a rare bug, did you try reloading the site? \u2013\u00a0Tobias Kienzler Nov 11 '10 at 9:51\n@Aran Mullholland: Yes, it doesn't appear to format correctly, but I believe it is. Hopefully, if it is not just a site bug, someone will edit it for me \u2013\u00a0Juan S Nov 11 '10 at 10:07\nyep tried reloading a few times, the explanation cuts off \"there is one solution (the repeated root) and if $b^2-4ac\" (so you can see part of the markup is probably at fault as i assume this is mid sentence) - c'mon admins help us out! \u2013\u00a0Aran Mulholland Nov 11 '10 at 10:18\n\nYeah so have you read about complex numbers. The root will be $$x = \\frac{-1 \\pm{i} \\sqrt{287}}{2 \\times 3}$$ where $i=\\sqrt{-1}$. Read more about complex numbers and when a polynomial can have complex roots, that happens when the *Discriminant* factor $b^{2}-4ac <0$.\n\nshare|cite|improve this answer\nso does that mean there is no general solution for solving polynomials, without straying into the complex plane? \u2013\u00a0Aran Mulholland Nov 11 '10 at 10:23\n@Aran: Part of the reason for coming up with the concept of complex numbers was to be able to solve polynomial equations. And it gets crazier with cubic equations: the case where all roots are real requires in general radicals of complex numbers to express the solutions. \u2013\u00a0J. M. Nov 11 '10 at 10:33\nHmm, $\\sqrt{-1} = i$, that feels a bit odd because the normal square root is not defined for negative numbers and the complex one is multivalued. \u2013\u00a0Jonas Teuwen Nov 11 '10 at 10:35\n@Jonas: I prefer couching it as $i^2=-1$ just so we can sweep Riemann sheet arguments under the rug for a while (at least, up until the student gains the firepower to see what's going on). ;) \u2013\u00a0J. M. Nov 11 '10 at 10:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/148444/how-to-solve-the-limit-of-a-succession-on-this-particular-circumstances\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nGiven this limit $\\displaystyle\\lim_{n \\to{+}\\infty}{\\frac{\\sqrt{16n^2+3}}{(1+a_n)n+5cos n}=\\frac{7}{6}}$ I need to calculate this one : $\\displaystyle\\lim_{n \\to{+}\\infty}{a_n}$\n\nAny ideas of how to solve it. Thanks!!!\n\nshare|cite|improve this question\nHint: Divide top and bottom by $n$, let $n$ get big. Top approaches $4$. Term $(5\\cos n)/n$ at the bottom dies. So for large $n$, $4/[(1+a_n)]$ is very close to $7/6$, and therefore $\\dots$ \u2013\u00a0Andr\u00e9 Nicolas May 22 '12 at 22:40\nup vote 1 down vote accepted\n\nHint: write $$ {\\sqrt{16n^2+3}\\over (1+a_n) n +5\\cos n} = {n\\cdot\\sqrt{16+{3\\over n^2} }\\over n\\cdot\\bigl( (1+a_n)+{5\\cos n\\over n}\\bigr)} = {\\sqrt{16+{3\\over n^2} }\\over (1+a_n)+{5\\cos n\\over n}}. $$ Then note $$ \\lim_{n\\rightarrow\\infty} {\\sqrt{16+{3\\over n^2} }\\over (1+a_n)+{5\\cos n\\over n}} ={4\\over 1+\\lim\\limits_{n\\rightarrow\\infty}a_n}. $$\n\nshare|cite|improve this answer\nPerfect. Thank you so much. I have a test tomorrow, and this exercise was killing me! \u2013\u00a0limoragni May 22 '12 at 23:12\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/27479/calculating-correlation-functions-of-exponentials-of-fields\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn their book Condensed Matter Field Theory, Altland and Simons often use the following formula for calculating thermal expectation values of exponentials of a real field $\\theta$:\n\n$$ \\langle e^{i(\\theta(x,\\tau)-\\theta(0,0))} \\rangle = e^{-\\frac12 \\langle (\\theta(x,\\tau)-\\theta(0,0))^2 \\rangle} $$\n\nAn example can be found in chapter 4.5, problem \"Boson-fermion duality\", part c). (This refers to the second edition of the book, page 185.)\n\nIn other words, expectation values of exponentials can be cast as exponentials of expectation values under certain conditions. Unfortunately, I seem to be unable to find an explanation of why this can be done and what the conditions on the Lagrangian of $\\theta$ are.\n\nHence, my question is:\n\nHow to derive the above formula? What do we need to know about $\\theta$ for it to be valid in the first place?\n\nIdeally, I am looking for a derivation using the path integral formalism. (I managed to rederive a very special case in terms of operators and the Baker-Campbell-Hausdorff formula, but I'd like to gain a more thorough understanding.)\n\nshare|cite|improve this question\nup vote 17 down vote accepted\n\nThis is just a property of Gaussian averaging analogous to the finite dimensional case:\n\n$\\langle e^{ix} \\rangle=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty} e^{ix}e^{-\\frac{x^2}{2\\sigma^2}}=e^{-\\frac{\\sigma^2}{2}}= e^{-\\frac{\\langle x^2 \\rangle}{2}}$\n\nThe field can be decomposed into its independent Gaussian modes and integrated for each mode separately.\n\nshare|cite|improve this answer\nThe simplest answers are simply the best. \u2013\u00a0Greg Graviton Oct 7 '11 at 7:50\nSo this formula only holds in the noninteracting case. \u2013\u00a0Arnold Neumaier May 2 '12 at 18:48\n\nDavid Bar Moshe's derivation is of course right. Let me offer you a Taylor-expansion-based alternative proof: $$ \\left\\langle e^{ix} \\right \\rangle = \\left\\langle \\sum_{n=1}^\\infty \\frac{(ix)^n}{n!} \\right \\rangle = \\left\\langle \\sum_{k=1}^\\infty \\frac{(ix)^{2k}}{(2k)!} \\right \\rangle $$ Here, I just used that by some odd-ness, the odd powers have a vanishing expectation value. In the formula above, $x$ is whatever linear function of the elementary fields you want, including your coefficient. But the expectation value of $x^{2k}$ is $$ \\left\\langle x^{2k} \\right \\rangle = \\frac{ \\int_{-\\infty}^\\infty {\\rm d}x \\,x^{2k}\\exp(-x^2/2x_0^2)}{ \\int_{-\\infty}^\\infty {\\rm d}x \\,\\exp(-x^2/2x_0^2)} = 1\\times 3\\times \\cdots \\times (2k-1) \\times x_0^{2k} $$ which may be computed by integrating by parts or by converting it to the Euler integral (which is also evaluated by parts) so when you combine it with the $1/(2k)!$ factor, the odd integers cancel, only the product of the even integers which is equal to $2^k k!$ is left, and the original sum from the first line is $$\\sum_{k=1}^\\infty \\frac{(-x_0^2)^k}{2^k k!} = \\exp(-x_0^2/2) $$ where $x_0^2$ is the expectation value of $\\langle x^2\\rangle$ because I used it in the probabilistic distribution. Again, you may set $x=\\theta(x_1,t_1)-\\theta(x_2,t_2)$ or whatever linear function of variables and my derivation still holds.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/121961/is-there-a-n-2-version-of-the-erdos-hanani-conjecture?answertab=votes\nText:\nTell me more \u00d7\n\nThis question comes out of REU research from this past summer. Unfortunately weeks of thought led to only trivial observations and the conclusion that the problem is quite hard.\n\nFix $k,t$. Let $F$ be a set of $k$-subsets of $[n] := \\{1,\\ldots,n\\}$ of minimal cardinality such that $F$ covers all $t$-subsets of $[n]$ (covers in the sense that any $t$-subset of $[n]$ is a subset of an element of $F$.) Let $\\kappa_n := |F|$. The Erd\u0151s-Hanani conjecture states that\n\n$\\kappa_n = \\binom{n}{t} / \\binom{k}{t}(1 + o(1))$.\n\nOf course $\\binom{n}{t} / \\binom{k}{t}$ is a lower bound on $\\kappa_n$, so the EH conjecture is saying that the obvious necessary condition is asymptotically sufficient. R\u00f6dl proved the EH conjecture in 1985.\n\nThis question is about what happens when $k$ and $t$ are not fixed. Specifically, take $k = \\lfloor n/2 \\rfloor$ and $t = \\lfloor n/2\\rfloor - 1$. Define $F$ and $\\kappa_n$ as above. Is it true that\n\n$\\kappa_n = \\frac{1}{\\lfloor n / 2 \\rfloor} \\binom{n}{\\lfloor n/2 \\rfloor}(1 + o(1))$?\n\n\nThe EH conjecture lead to the study of what is called \"packing in a hypergraph.\" See R\u00f6dl's proof introduced what is now called the \"R\u00f6dl nibble\" and is pseudo-random in nature. Spencer gave a lovely proof using branching processes. There are a lot of results from the late 80s to 90s that say, as Kahn puts it in \"Asymptotics of Hypergraph Matching, Covering and Coloring Problems\", that hypergraphs are asymptotically well-behaved as long as their edge sizes are bounded! Unfortunately the $n/2$ version of EH involves hypergraphs of unbounded edge size and the existing methods appear useless.\n\nSome ideas\n\nA straightforward application of the method of alterations (or equivalently, some easy analysis of the greedy algorithm) gives that $\\kappa_n \\leq \\log n \\frac{1}{\\lfloor n / 2 \\rfloor} \\binom{n}{\\lfloor n/2 \\rfloor} (1 + o(1))$, so the whole question is whether we can eliminate this log factor.\n\nA set of $\\lfloor n/2 \\rfloor$-subsets has maximum coverage of $(\\lfloor n/2 \\rfloor - 1)$-subsets when all its elements have pairwise symmetric difference of at least 4. So really this is a coding theory problem. The paper \"Lower bounds for constant weight codes\" by Graham and Sloane shows that we can find a set $H$ of $\\lfloor n /2\\rfloor$-subsets of $[n]$ such that $|H| \\geq \\frac{1}{2}\\binom{n}{\\lfloor n/2 \\rfloor}$ and the hamming distance between elements is at least 4. Let $G$ be the set of $(\\lfloor n/2 \\rfloor - 1)$-subsets covered by $H$. $G$ is half the size we want it to be, but we only used half as many elements are we are allowed. So we might be optimistic that by allowing some small overlap we can cover everything we want. If we take a permutation $\\sigma \\in S_n$ and look at $\\sigma(H)$ (i.e. apply the permutation to the elements of the elements of $H$) it covers $\\sigma(G)$. Of course $|\\sigma(G)| = |G|$. We could hope that a good choice of $\\sigma$ gives $|G \\cup \\sigma(G)| \\approx 2|G|$ and we have found an appropriate set $F := H \\cup \\sigma(H)$. I asked the question of whether such a $\\sigma$ must exist before: Size of union of a set of subsets and its permutations. That question is interesting in its own right, but this EH conjecture is really why I wanted an answer.\n\nshare|improve this question\nHave you checked out the La Jolla Covering Repository online? That might give a nice suggestion of what to expect. Gerhard \"Ask Me About System Design\" Paseman, 2013.02.15 \u2013\u00a0 Gerhard Paseman Feb 16 at 1:32\nDoes your description have $t$ and $l$ mixed up? If so, please edit. \u2013\u00a0 Brendan McKay Feb 16 at 1:36\n@Brendan McKay: Yes, thank you. It is corrected. \u2013\u00a0 Sam Hopkins Feb 16 at 2:04\nI should mention also that the Graham-Sloane construction means that the EH-conjecture for $k = \\phi(n)$ and $t = k - 1$ has a positive answer when $\\phi(n) = o(n)$, so $n/2$ is in fact the \"hard case.\" \u2013\u00a0 Sam Hopkins Feb 16 at 2:15\nSome structural results on this part of the boolean lattice can be found with the search phrases \"middle levels\" and \"boolean\" together. For example, see the references in . \u2013\u00a0 Brendan McKay Feb 16 at 3:09\nshow 1 more comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/133065/a-curious-binomial-coefficient-sum\nText:\nTell me more \u00d7\n\nLet $k, l \\leq n$ be non-negative integers. Does the following identity simplify? \\begin{align} \\sum_{j = 0}^{k} \\binom{k}{j} \\binom{j + n -l + 1}{n} = \\binom{n - l + 1}{n} \\phantom1_{2}\\mathsf{F}_{1}(-k,n - l + 2, 2- l; -1) \\end{align} where $\\!\\!\\! \\phantom1_{2}\\mathsf{F}_{1}$ is a hypergeometric function. That is, does the right side have another representation in terms of simple functions given that $k,l$ and $n$ are non-negative integers?\n\nshare|improve this question\n$\\binom{n-l+1}{n}=0$ if $l > 1$ I guess \u2013\u00a0 GEdgar Apr 17 '12 at 19:27\nSuperficially it appears that the right side vanishes, but you must also consider the hypergeometric function. The sum is equal to $2^{k-1} k$ if $l = 2$ and $n = 1$. \u2013\u00a0 user02138 Apr 17 '12 at 19:46\nWhat do you consider to be a \"simple function\"? The theory behind Gosper's algorithm will tell you that if the sum exists as a hypergeometric then it's a rational polynomial times the summand. \u2013\u00a0 Peter Taylor Apr 17 '12 at 20:44\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://pari.math.u-bordeaux.fr/archives/pari-users-0903/msg00004.html\nText:\nKurt Foster on Sat, 14 Mar 2009 17:10:41 +0100\n\n\nAvoiding a znlog() computation\n\nSuppose that a and b are given, and for some prime p you know that\n\nn1 = znorder(Mod(a,p),p-1)\n\n\nMod(b,p)^n1 == Mod(1,p).\n\nThen the multiplicative order n2 of b (mod p) is automatically a divisor of n1, so we can compute it using n2 = znorder(Mod(b.p),n1).\n\nThen alpha = Mod(a,p)^(n1/n2) has multiplicative order n2, so\n\nMod(b,p) = alpha^k\n\nfor a unique k in (0, n2) with gcd(k, n2) ==1.\n\nThe problem is, how to determine k.  One way is to let\n\ng = znprimroot(p); l1 = znlog(alpha,g);l2 =znlog(b,p);k=lift(Mod(l2/ l1,n2))\n\nbut this entails finding a primitive root and TWO znlog()s. Given that Mod(k,n2) is already known to be well defined, is there a more direct/faster way to compute it?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/193542/behavior-of-sum-n-1-infty-n-1zn-on-the-circle-of-convergence\nText:\nSign up \u00d7\n\nConsider the following complex power series :$$\\sum_{n=1}^\\infty\\frac{z^n}{n}$$ The radius of convergence of this series is $1$ and the series is divergent for $z=1$. I want to know what are the values of $z\\in C:=\\lbrace z\\in\\mathbb{C}: |z|=1\\rbrace$, the circle of convergence, for which the given series converges.\n\nshare|cite|improve this question\nTo find any value you may rewrite it as $\\ -\\ln(1-z)\\ $ (for $z\\not =1$) \u2013\u00a0 Raymond Manzoni Sep 10 '12 at 11:41\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nHINT: Look at Dirichlet test. In your case, choose $a_n = \\dfrac1n$ and $b_n = z^n$.\n\nFrom the Dirichlet test, you will get that the series converges everywhere on the boundary of the unit disc except at $z=1$.\n\nshare|cite|improve this answer\nAlthough it ultimately amounts to the same, I'd suggest to consider $(1-z)f(z)$ where $f(z)$ is the given series. \u2013\u00a0 t.b. Sep 10 '12 at 10:20\n\nHint: This is a classical example for Abel's Test.\n\nshare|cite|improve this answer\nAccording to this statement of Abel's Test, it doesn't apply, since $\\sum\\limits_{n=1}^\\infty z^n$ doesn't converge. Would you explain what you mean by Abel's Test? \u2013\u00a0 robjohn Sep 14 '12 at 6:03\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/24609/are-there-primes-p-q-such-that-p41-2q2?answertab=active\nText:\nSign up \u00d7\n\n$\\exists p, q \\in \\mathbb{P}: p^4+1 = 2q^2$? I suspect there is some simple proof that no such p, q can exist, but I haven't been able to find one.\n\nSolving the Pell equation gives candidates for p^2=x and q=y, with x=y=1 as the first candidate solution and subsequent ones given by x'=3x+4y, y'=2x+3y; chances of a prime square seem vanishingly unlikely as x increases, but I don't have a proof.\n\nMeta: how do you search for a question like this? I looked for a searching HOWTO here and on meta, and couldn't find one. That the search appears to strip '^' and '=' makes it all the harder.\n\nshare|cite|improve this question\nIf you're looking for a simple proof, you probably have to a) factor the left hand side over Z[i]; b) subtract 1 and factor the right hand side over Z[sqrt{2}], or c) multiply by 2 and use the classification of Pythagorean triples (or subtract a square and factor the right hand side, which is a difference of squares). \u2013\u00a0 Franz Lemmermeyer May 14 '10 at 12:31\nYes, $\\mathbb{P}$ is the primes. That is standard isn't it? \u2013\u00a0 Hugo van der Sanden May 14 '10 at 12:32\n@Franz: This is a variation of Pell's equation, so $p^2+q\\sqrt2=(1+\\sqrt2)^{2k+1}$ (it can be shown by modular argument that $k$ is multiple of 4). Thus (a) can't work, (b) is used in derivation of the above formula (there are useless recursions mentioned by the author), and for (c) I have no idea of what do you mean (how to relate the equation with Pythagorean triples?) \u2013\u00a0 Wadim Zudilin May 14 '10 at 13:45\nInterestingly enough, the similar equation p^2 + 1 = 2q^4 DOES have an interesting solution, namely (p,q) = (239,13). This is related to Machin's identity pi/4 = 4 arctan(1/5) - arctan(1/239). (See Ribenboim's book on Catalan Conjecture for this.) See p.7-8 of for an \"explanation\" of this solution via a congruence mod 5 between a weight-2 cuspform in conductor 1024 and an Eisenstein series. \u2013\u00a0 JSE May 14 '10 at 20:45\n@Wadim: I can't see why a) cannot work. As for c), 2p^4 + 2 = (p^2+1)^2 + (p^2-1)^2 = (2q)^2. \u2013\u00a0 Franz Lemmermeyer May 16 '10 at 16:10\n\n3 Answers 3\n\nup vote 20 down vote accepted\n\nThis is not my solution, but I don't remember where I learned it.\n\nSquare both sides, subtract $4p^4$, and divide by 4 to obtain $({p^4-1\\over 2})^2=q^4-p^4$.\n\nHowever, $z^2=x^4-y^4$ has no solutions in non-zero integers. This is Exercise 1.6 in Edwards's book on Fermat's Last Theorem. The proof uses the representation of Pythagorean triples and infinite descent.\n\nSo you must have $p=\\pm 1$.\n\nshare|cite|improve this answer\nThanks, this does solve it. I also found the infinite descent proof of the lemma at\u2026 \u2013\u00a0 Hugo van der Sanden May 14 '10 at 15:42\n\nI think -- correct me if I am wrong -- that it is known that the equation $x^4+1=Dy^2$ with given squarefree $D$ has at most one solution in integers, primes or no primes. See for example J. H. E. Cohn., Math. Comp. 66 (1997), 1347-1351. ( The article cites an original proof by Ljunggren in 1942, which I can't find online.\n\nshare|cite|improve this answer\nAh, excellent. That suggests x=y=1 is the only solution; I'll take a look at the paper to see if it constitues a proof. \u2013\u00a0 Hugo van der Sanden May 14 '10 at 14:07\nOh, it is the Ljunggren paper I'd need. \u2013\u00a0 Hugo van der Sanden May 14 '10 at 15:40\n\nI don't know if there is a simple proof, but I know one which is easy to do because it lets a computer do all the work (but the work is perhaps complicated): you simply ask a computer to solve Y^2=2X^4+2 in integers for you, like this (in MAGMA, but other packages will do it too):\n\n> IntegralQuarticPoints([2,0,0,0,2]);\n    [ 1, 2 ],\n    [ -1, 2 ]\n\nso the only solution with p,q integers is p,q=+-1 and that's it.\n\nshare|cite|improve this answer\nHow can Magma be used with confidence, their code is not open. \u2013\u00a0 teil May 14 '10 at 13:39\nNegative's point is a valid one, but I think Kevin's answer points to the fact that there is a standard algorithm to solve these kinds of problems. Maybe it is also implemented in other packages. \u2013\u00a0 Felipe Voloch May 14 '10 at 14:59\nThis is only semi-true. The outer code of SIntegralPoints in Magma can be viewed easily. As Felipe Voloch says in part, this lists the algorithm. Low-level functions (eg. Height) cannot be seen, though \"open\" is technically true as you can decompile. From the philosophy of science, no system is used with confidence, and only independent verification can be partially satisfactory. We still have at least two chip manufacturers, so hardware independence is possible. For using software, too many packages throw eggs into a large basket (like GMP), and so I see a scarcity of true independence often. \u2013\u00a0 Junkie May 15 '10 at 6:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/27690/convergence-of-the-maximum-of-a-series-of-identically-distributed-variables?answertab=oldest\nText:\nSign up \u00d7\n\nMy friend and I have been stumped on this problem for a little while and I thought asking for tips couldn't hurt (we did ask the teacher, but we got other problems after)\n\nHere is the question :\n\nLet $\\{X_n\\}_{n \\geq 1}$ be a sequence of random variables defined on the same probability space $(\\Omega, F, \\mathbb{P})$ with the same law of finite expected value (E(|X_1|)<\\infty ). Let\n\n$Y_n = n^{-1} \\max_{1 \\leq i \\leq n} |X_i|$.\n\nShow that\n\n$\\lim_{n\\rightarrow \\infty} E(Y_n) = 0$\n\n\n$Y_n \\rightarrow 0$ almost surely.\n\nWe have ideas of many parts of the proof, for example for the first one it would suffice to show that the expected value of the max of all $|X_i|$ is finite... and since the max is one of the $|X_i|$ for each $\\omega \\in \\Omega$ it seems reasonable but we're not sure how to show it.\n\nWe also tried splitting the integral for the expected value into a partition of $\\Omega$ considering the sets on which $X_i$ is the max, but didn't get too far with that.\n\nFor the second part, I think we could show it if we knew that $X_i(\\omega)$ diverges for only a measure 0 set, but it's not that obvious (I think).\n\nAny pointers to the right direction appreciated!\n\nshare|cite|improve this question\nIt's been a long time since I had anything to do with random variables and the like, but I can't see how this isn't just plain wrong? E.g. take $\\Omega = \\{\\omega\\}$ (IOW a singleton) and $X_n(\\omega) = n^2$ \u2013\u00a0 kahen Mar 17 '11 at 23:08\n@kahen The random variables $X_n$ are supposed to be identically distributed. \u2013\u00a0 Byron Schmuland Mar 17 '11 at 23:13\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAssume without loss of generality that $X_1$ is almost surely nonnegative.\n\nAlmost sure convergence\n\nThis is a consequence of the first Borel-Cantelli lemma. To see this, fix any positive $x$. Then $P(X_n\\ge nx)=P(X_1\\ge nx)$ for every $n$ and $$\\sum_{n\\ge1}P(X_1\\ge nx)\\le x^{-1}E(X_1), $$ hence the series of general term $P(X_n\\ge nx)$ converges. By the first Borel-Cantelli lemma, the limsup of the events $[X_n\\ge nx]$ has probability $0$. This means that $X_n<nx$ for every $n$ large enough and can be translated as $X_n\\le Z+nx$ for every $n$, for an almost surely finite $Z$. Hence $nY_n\\le Z+nx$ for every $n$, and $\\limsup Y_n\\le x$ almost surely. This holds for every positive $x$, hence $Y_n\\to0$ almost surely.\n\nConvergence of the expectations\n\nTwo ingredients are useful here: the fact that, for every nonnegative $Z$, $E(Z)$ is the integral of the function $x\\mapsto P(Z\\ge x)$ over $x\\ge0$, and the fact that if $nY_n\\ge x$, then $X_k\\ge x$ for at least one integer $k$ between $1$ and $n$, hence $P(nY_n\\ge x)\\le nP(X_1\\ge x)$.\n\nThanks to the first ingredient, $E(Y_n)$ is the integral of $g_n$ with $g_n(x)=P(nY_n\\ge x)/n$. Thanks to the second ingredient, $g_n(x)\\le P(X_1\\ge x)=g_1(x)$. Now, $g_n(x)\\le1/n$ hence $g_n(x)\\to0$, and since $E(X_1)$ is finite, $g_1$ is integrable. By dominated convergence, the integral of $g_n$ converges to $0$, that is, $E(Y_n)\\to0$.\n\nRemark You do not say where you found the exercise but your source is to be complimented because many people add the hypothesis that the sequence $(X_n)$ is independent although it is not necessary.\n\nAdded later on The upper bound of a series by $x^{-1}E(X_1)$ used above can be proved as follows. First assume that $x=1$ and note that for any nonnegative $Z$ (random or deterministic), $$ \\sum_{n\\ge1}\\mathbf{1}_{Z\\ge n}=\\lfloor Z\\rfloor\\le Z, $$ where $\\lfloor \\ \\rfloor$ denotes the integer part. Integrating both sides of the inequality with respect to $P$ yields, for any nonnegative random variable $Z$, $$ \\sum_{n\\ge1}P(Z\\ge n)=E(\\lfloor Z\\rfloor)\\le E(Z). $$ For the case at hand, apply this inequality to the random variable $Z=x^{-1}X_1$, using $$ \\sum_{n\\ge1}\\mathbf{1}_{X_1\\ge nx}=\\lfloor x^{-1}X_1\\rfloor\\le x^{-1}X_1. $$\n\nshare|cite|improve this answer\nI am not sure about the first inequality... could there by any chance be a confusion in the multiple \"n\" present in the solution? By the way, thank you very much! \u2013\u00a0 Vhailor Mar 18 '11 at 0:47\n@Vhailor, for a nonnegative random variable $X$ with $G(x) = \\mathbb{P}(X > x)$ it is a fact that $\\mathbb{E}(X) = \\int_0^\\infty G(x) \\,\\mathrm{d}x$. Now $s_m = \\sum_{n=1}^m P(X_n > n x) \\leq \\int_0^m G(ux) \\mathrm{d}u = x^{-1} \\int_0^{m x} G(v) \\mathrm{d}v$ where the inequality follows since $G$ is nonincreasing. So, $s_m \\leq x^{-1} \\mathbb{E} X$ for all $m$. Hence $\\limsup_m s_m < \\infty$, which by Borel--Cantelli let's one conclude that $\\mathbb{P}(X_n > n x \\; \\mathrm{ i.o.}) = 0$. Does that help? \u2013\u00a0 cardinal Mar 18 '11 at 3:28\n@Vhailor No confusion. I added a proof of the inequality at the end of my post. @cardinal Thanks. \u2013\u00a0 Did Mar 18 '11 at 6:53\n\nNote first that $E \\max_{i \\ge 0} |X_i|$ (one should really write $\\sup$ instead of $\\max$) need not be finite. Indeed, if the $X_i$ are, say, iid normal, then one can show $\\sup_{i \\ge 0} |X_i| = +\\infty$ almost surely.\n\nTo get $L^1$ convergence, the trick is to split into the events where the $X_i$ are small and where they are large. When they are small they do not contribute much to $Y_n$, and they can be large only with small probability. So fix $M$ and let $U_i = |X_i| 1_{\\{|X_i| \\le M\\}}$, $V_i = |X_i| 1_{\\{|X_i| > M\\}}$. Then $Y_n \\le \\frac{1}{n} (\\max_{i \\le n} U_i + \\max_{i \\le n} V_i)$. The first term is bounded by $M$, and the second by $V_1 + \\dots + V_n$. Taking expectations, $E Y_n \\le \\frac{M}{n} + E V_1$, so $\\limsup_{n \\to \\infty} E Y_n \\le E V_1$. By choosing $M$ large enough, $E V_1$ can be made as small as desired (think dominated convergence).\n\nFor almost sure convergence, the argument that went here previously was wrong.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/46590/whats-the-minimum-of-int-01-fx2-dx-subject-to-int-01-fx-dx/46603\nText:\nSign up \u00d7\n\nThe question is as in the title: what's the minimum of $\\int_0^1 f(x)^2 \\: dx$, subject to $\\int_0^1 f(x) \\: dx = 0, \\int_0^1 x f(x) \\: dx = 1$? (Assume suitable smoothness conditions.)\n\nA problem in the textbook for the course I am TEACHING (not taking) reduces to minimizing $w_1^2 + w_2^2 + w_3^2$ subject to $w_1 + w_2 + w_3 = 0, w_1 + 2w_2 + 3w_3 = 1$. Of course there's nothing special about the number $3$ here, and so one can ask for the minimum of $\\sum_{i=1}^n w_i^2$ subject to $\\sum_{i=1}^n w_i = 0, \\sum_{i=1}^n iw_i = 1$. At least when $n = 3, 4, 5$, we get $w_i = c_n(i-(n+1)/2)$, for some constant $c_n$ which depends on $n$. So for fixed $n$, $w_i$ is a linear function of $i$. (This is a bit of an annoying computation, so I won't reproduce it here.)\n\nSo it seems like there should be a continuous analogue of this. If we have $$ \\int_0^1 f(x) \\: dx = 0, \\int_0^1 x f(x) \\: dx = 1 $$ and $f(x)$ is linear, then we get $f(x) = 12(x-1/2)$, and $\\int_0^1 f(x)^2 \\: dx = 12$. Is this the function satisfying these integral conditions with smallest $\\int_0^1 f(x)^2 \\: dx$? That is, is it the case that $$ \\int_0^1 f(x)^2 \\: dx \\ge 12 $$ for every $f(x)$ satisfying the two conditions above and whatever smoothness conditions are necessary?\n\nI've tagged this calculus-of-variations because that's what it looks like to me. But I don't know the calculus of variations, which is why I can't just solve the problem myself.\n\nshare|cite|improve this question\nIn my answer here I proved that if $f \\in C^1$, $\\int_{0}^{1} f = 0$ and $m \\leq f' \\leq M$ then $$\\frac{m}{12} \\leq \\int_{0}^{1} x f(x) \\leq \\frac{M}{12}.$$ I'm not sure if that helps immediately but it seems related and I'd try a few integrations by parts. It's getting late here, so I'm not sure that I could succeed now. \u2013\u00a0 t.b. Jun 20 '11 at 23:33\nWell, there is the same mysterious constant of 12. I may give it a shot. \u2013\u00a0 Michael Lugo Jun 20 '11 at 23:36\n\n3 Answers 3\n\nup vote 24 down vote accepted\n\nThe integrals above can be interpreted using the $L^2$ inner product $$ \\langle f,g\\rangle \\;=\\; \\int_0^1 f(x)\\,g(x)\\,dx. $$ Specifically, we are given that $\\langle 1,f\\rangle = 0$ and $\\langle x,f\\rangle =1 $, and we are asked to find the minimum possible value of $\\langle f,f\\rangle$.\n\nSince components of $f$ orthogonal to both $1$ and $x$ will only increase the norm of $f$, the minimizing function must lie in the subspace spanned by $1$ and $x$. A simple calculation shows that the minimum is obtained when $f(x) = 12x - 6$, in which case $\\langle f,f\\rangle = 12$.\n\nshare|cite|improve this answer\nIndeed, there are nice exercises at the end of chapter 4 of Walter Rudin's Real and Complex Analysis that provide practice with this technique. \u2013\u00a0 Amitesh Datta Jun 21 '11 at 0:24\n\nYes, it is true.\n\nConsider the Hilbert space $L^2([0,1])$ of square integrable functions $f\\colon[0,1]\\to\\mathbb{R}$ with inner product $\\langle f,g\\rangle = \\int_0^1 f(x)g(x)\\,dx$. Letting $V$ be two dimensional subspace generated by $u(x)=1$ and $v(x)=x$, then the function $g(x)=12(x-1/2)$ is in $V$ and satisfies $\\langle g,u\\rangle=0$ and $\\langle g,v\\rangle=1$. So, your question is equivalent to choosing $f$ to minimize $\\langle f,f\\rangle$ subject to $\\langle f,h\\rangle=\\langle g,h\\rangle$ for all $h\\in V$. This condition is just saying that $g$ is the orthogonal projection of $f$ onto $V$.\n\nSo, any $f\\in L^2$ satisfying the condition can be written as $$ f = g + h $$ where $h$ is in the orthogonal complement of $V$ and, therefore, $$ \\langle f,f\\rangle = \\langle g,g\\rangle+\\langle h,h\\rangle\\ge \\langle g,g\\rangle=12 $$ with equality if and only if $f=g$ almost everywhere.\n\nshare|cite|improve this answer\nThis solution is so beautiful and simple that it's almost disappointing. \u2013\u00a0 t.b. Jun 21 '11 at 0:23\nNote that you could alternatively try varying $f$ by an (infinitesimal) amount $\\delta f$, giving $0=\\delta\\int_0^1f^2\\,dx=\\int_0^1f\\delta f\\,dx$ for the optimal $f$. In order that the conditions remain satisfied, you must choose $\\int u\\delta f\\,dx=0$ for $u=1$ and $u=x$. This means that $f$ is orthogonal to any $\\delta f$ orthogonal to both $1$ and $x$. As the orthogonal complement of the orthogonal complement of a closed subspace gets you back to the original space, this means that $f$ is in the linear span of $1,x$. Making this a bit cleaner and more rigorous gives the argument above. \u2013\u00a0 George Lowther Jun 21 '11 at 0:28\n\nSeeing the very nice solutions using linear algebra that have been posted, I am again reminded that the calculus of variations is a bigger and less elegant hammer than is necessary for most nails. For what it's worth, here is how you could solve this problem with the calculus of variations. Jos\u00e9 Figueroa-O'Farrill has some nice notes which cover this:\n\nAs we have two constraints, we introduce two Lagrange multipliers $\\lambda$ and $\\mu$, and attempt to extremize the functional $$S[f] = \\int_0^1 \\big( f(x)^2 + \\lambda f(x) + \\mu x f(x) \\big) dx.$$ Let us denote the integrand by $$L\\big(x,f(x),f'(x)\\big) = f(x)^2 + \\lambda f(x) + \\mu x f(x).$$\n\nThe function $f$ which is a stationary point of the functional $S[f]$ satisfies the corresponding Euler-Lagrange equation, $$\\frac{\\partial L}{\\partial f} = \\frac{d}{dx} \\frac{\\partial L}{\\partial f'}$$ which in this case reduces to $$2f(x) + \\lambda + \\mu x = 0.$$ So we see that the extremal $f(x)$ is indeed linear, and the values of $\\lambda$ and $\\mu$ can be obtained from the constraints $\\int_0^1 f(x) dx = 0$ and $\\int_0^1 xf(x) dx = 1$.\n\nshare|cite|improve this answer\nOut of curiosity what was your air in jee? i might be your junior... \u2013\u00a0 kuch nahi Jun 21 '11 at 5:05\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/157866/derivative-for-matrix-function?answertab=active\nText:\nSign up \u00d7\n\nI have a matrix kernel function which I am trying to find the derivative to. Function is K = c * exp[-1/2 * (P(X1 - X2))' * P(X1 -X2)] where uppercase are matrices and lower case are scalars (and ' denotes transpose). I'm trying to find dK/dP. I'm pretty rusty on matrix calculus, can anyone give me a hand here?\n\n\nshare|cite|improve this question\nYour notation is not very clear. Is $P$ a matrix? then did you mean something like $K(P) = c \\exp[-\\frac12 \\| P(X_1 - X_2) \\|^2]$? In that case you should probably write (P(X1-X2))', the transpose should be around everything and maybe a trace before it? Is P symmetric or not? \u2013\u00a0 passerby51 Jun 13 '12 at 17:43\nI was assuming this is a matrix valued function. If that's true I'd undelete my (by now corrected) answer. If @passerby51 assumption is correct, the derivative is just $$ D_V K = -1/2K \\langle V(X_1-X_2), P(X_1-X_2)\\rangle$$ with $\\langle.,.\\rangle$ the scalar product on the vector space of matrices. \u2013\u00a0 user20266 Jun 13 '12 at 17:50\nSorry yeah the transpose is around the whole thing. P is not symmetric. \u2013\u00a0 tomas Jun 13 '12 at 17:50\nYeah it is a matrix valued function. I didn't quite get a chance to see your deleted answer Thomas. What was it? Thanks for the response guys. \u2013\u00a0 tomas Jun 13 '12 at 17:53\nundeleted my reply. \u2013\u00a0 user20266 Jun 13 '12 at 17:53\n\n1 Answer 1\n\nLet $$Z(P)=(P(X_1-X_2))^TP(X_1-X_2)$$ If $K$ is viewed as depending only on $P$ and if you differentiate in direction $V$ you get $$ D_V K = K*\\frac{-1}{2} \\left\\{\\frac{I-e^{-ad_{Z(P)}}}{ad_{Z(p)}} \\left[ (V(X_1-X_2))^TP(X_1-X_2) + P(X_1-X_2)^TV(X_1-X_2) \\right] \\right\\}$$\n\nThe term on the right hand side in curly parenthesis needs explanation. It is the matrix valued function $\\frac{I-e^{-ad_{Z(P)}}}{ad_{Z(P))}}$ applied to the term in square brackets. This in turn means\n\n$$\\frac{I-e^{-ad_{Z}}}{ad_{Z}}[Y] = Y-\\frac{[Z,Y]}{2!} + \\frac{[Z,[Z,Y]]}{3!} - \\ldots$$\n\nSee, e.g., Chapter 3.3 in Brian C. Halls Book 'Lie Groups, Lie Algebras and Representations for a derivation of the derivative of the exponential.\n\n(Sorry for posting a too simple and wrong answer first, which is true only if $Z$ and $D_VZ $ commute). (I don't like the $\\frac{d}{dP}$ notation).\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/45061/linear-ordering-of-color-balls\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $n+m$ balls of which $n$ are red and $m$ are blue, are arranged in a linear order, we know there are $(n+m)!$ possible orderings. If all red balls are alike and all blue ball are alike, we know there are $\\frac{(n+m)!}{n!m!}$ possible orderings.\n\nFor example, 2 red and 3 blue balls:\n\nR1 R2 B1 B2 B3\n\nR2 R1 B2 B3 B1\n\nThe above two orderings are equivalent and can be denoted as:\n\n\nNow here is the problem: what if we further concentrate on the color, and record consecutive balls of the same color with the just ONE color code?\n\nFor example the color code for the afore-mentioned example would be:\n\n\nHow many possible color code orderings are there?\n\nshare|improve this question\nShould be tagged co.combinatorics instead of pr.probability? \u2013\u00a0 Emil Nov 6 '10 at 12:27\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nSuch a color-code ordering starts with either R or B and continues with strictly alternating R and B. The string can be of any length up to the smaller of $n$ or $m$, meaning it can be twice that smaller value, but that can be followed by one more character if there are enough of the other color. Moreover, every such string is a color-code ordering for some linear ordering of balls. There are a couple of special cases, namely that if either $n$ or $m$ is zero then there is exactly one color-code ordering and there aren't any if both are zero. Also, if neither is zero, we must have at least one instance of each letter.\n\n\nIf $n = m = 0$, the answer is 0.\n\nIf exactly one of $n$ and $m$ is zero, the answer is 1.\n\nIf $n = m > 0$, the answer is $4n - 2$.\n\nOtherwise, let $p$ be the minimum of $n$ and $m$. The answer is $4p-1$.\n\nshare|improve this answer\nadd comment\n\nWithout loss of generality, assume $n \\leq m$. Such a colour code ordering is just a sequence of alternating $R$ and $B$ letters. There are four types of such sequences, depending which letter they start and end with. Say a sequence is of type $(X,Y)$ if it begins with $X$ and ends with $Y$.\n\nSo, there are\n\n  1. $n$ sequences of type $(R,B)$\n  2. $n$ sequences of type $(B,R)$\n  3. $n-1$ sequences of type $(R,R)$\n  4. $n$ sequences of type $(B,B)$ (and only $n-1$ of them if $n=m$).\n\nThus, the answer is $4n-1$ if $n < m$, and $4n-2$ if $n=m$.\n\nEdit. As Larry Denenberg mentions, in the degenerate case of $n=0$, the answer is always 1 (I count the empty string if $n=m=0$).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/93817/sum-of-two-cubes/93828\nText:\nTake the 2-minute tour \u00d7\n\nDoes anyone know how to get all solutions of the equation $a^3=b^3+c^3$ when $b,c$ quadratic irrationals or $b$ rational and $c$ quadratic irrational?\n\nshare|improve this question\nWhat are the conditions on $a$? ${}$ \u2013\u00a0 jspecter Dec 24 '11 at 4:32\nTo emphasize the importance of answering jspecter's question, take arbitrary $b$ and $c$ satisfying the given conditions, then define $a=\\sqrt[3]{b^3+c^3}$ and you have described all solutions to the problem as stated. \u2013\u00a0 Jonas Meyer Dec 24 '11 at 4:38\n@Vassili: That would be better edited into the question. \u2013\u00a0 Jonas Meyer Dec 24 '11 at 4:58\n@QED: Off topic, but I am one of the 2 people who has downvoted this question \"so heavily\" and I did it because of this post, not because of any other post by the same user, and certainly not because of the person. \u2013\u00a0 Jonas Meyer Dec 24 '11 at 18:52\n@QED: I have just downvoted; the post fits the first reason indicated when you mouse over the downvoting arrow: \"This question does not show any research effort.\" If Vassili does manage to explain why he's looking at these things in the first place, and edits the explanation into this question, I'll be more than willing to revoke my downvote. \u2013\u00a0 \uff2a. \uff2d. Dec 25 '11 at 4:36\nshow 6 more comments\n\n2 Answers\n\nup vote 2 down vote accepted\n\nHere is an explicit calculation of what jspecter outlined:\n\nThe line described is $c = ma - m$ and with this $a^3 - c^3 - 1 = 0$ reduces to $(-m^3 + 1)a^3 + 3m^3a^2 - 3m^3a + (m^3 - 1) = 0$. Dividing both sides by $a-1$ (to factor out the point $O$) leaves us with $(-m^3 + 1)a^2 + (2m^3 + 1)a + (-m^3 + 1)$ which has roots $$a = \\frac{1 + 2m^3 \\pm \\sqrt{12m^3 - 3}}{2 - 2m^3}.$$\n\nFor example if we let $m = 7$ we find the pair $(a,c) = (\\frac{229 + \\sqrt{457}}{228},\\frac{7 + 7 \\sqrt{457}}{228})$ and you can check that $a^3 = c^3 + 1$. In particular $$(7+7\\sqrt{457})^3 + 228^3 = (229+\\sqrt{457})^3.$$\n\nshare|improve this answer\n:The number 228 is an integer not an irrational number. \u2013\u00a0 Vassilis Parassidis Dec 25 '11 at 5:34\n@Vassili, why do you tell me this? \u2013\u00a0 user16697 Dec 25 '11 at 5:36\n:because i ask for all solutions. \u2013\u00a0 Vassilis Parassidis Dec 25 '11 at 5:41\n@Vassili, I don't understand. \u2013\u00a0 user16697 Dec 25 '11 at 5:41\nI want to know if with the above method we obtain all solutions. All the solutions of the sum of two cubes with the outlined conditions contain a case where all three numbers are quadratic irrationals. \u2013\u00a0 Vassilis Parassidis Dec 25 '11 at 5:48\nshow 1 more comment\n\nHere's an idea to think about.\n\nAssume $b \\ne 0.$ In this case, it is equivalent to classify all pairs $(A,C)$ where $A$ and $C$ lie a quadratic extension of $\\mathbb{Q}$ and satisfy the equation\n\n$$A^3 - C^3 = 1. \\mbox{ }\\mbox{ }\\mbox{ }\\mbox{ }\\mbox{ }\\mbox{ } (1)$$\n\nWe denote by $V$ the set of all pairs in $\\overline{\\mathbb{Q}}$ which satisfy $(1).$\n\nNote $O := (1,0)$ is such a pair. Fix a slope $m \\in \\mathbb{Q}$ (you can also take $m = \\infty$) and consider line $L$ of slope $m$ through $O.$ The line $L$ intersects $V$ in three points and each coordinate of these points is cut out by a cubic polynomial in one varriable over $\\mathbb{Q}.$ However, one of the points of intersection is $O,$ so one root of each of the polynomials is rational. Factoring out this root, it follows that the remaining roots satisfy a degree 2 rational polynomial and therefore lie in quadratic extensions of $\\mathbb{Q}.$\n\nNow this won't get you all the points, for example $P = (0,\\zeta_6)$ lies on $V,$ but doesn't lie on a line through $O$ with rational slope. However, $P$ does lie on the line through $(0,-1) \\in V$ with infinite slope. So the above technique can be adapted to obtain $P.$\n\nI claim that the idea above can be used to obtain all points on $V$ in quadratic extensions. That is if you know all points on $V$ in $\\mathbb{Q}.$\n\nBut even Fermat \"knew\" that.\n\nshare|improve this answer\nBTW, a good resource to look at would be the first couple pages of Rational Points on Elliptic Curves by Silverman and Tate. amazon.com/Rational-Points-Elliptic-Undergraduate-Mathematics/\u2026 \u2013\u00a0 jspecter Dec 24 '11 at 5:29\n@jspecter.Can you give me an examble where a,b,c are all quadratic irrationals. \u2013\u00a0 Vassilis Parassidis Dec 24 '11 at 5:58\nTry to follow through the recipe with different slopes. See what you get. I would post one, but I have to catch a flight. \u2013\u00a0 jspecter Dec 24 '11 at 6:07\ncan someone give me an example on posted question where a,b,c are all quadratic irrationals? \u2013\u00a0 Vassilis Parassidis Dec 24 '11 at 6:42\n@Gerry, Vassili, I've cleaned up some of the more chatty comments on this post. \u2013\u00a0 Willie Wong Feb 24 '12 at 13:51\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/63055/bridging-uniform-and-mass-distributions\nText:\nTake the 2-minute tour \u00d7\n\nForeword. The original formulation of this problem was inaccurate; chamomille and Didier Piau came up with a simple example which would not solve the problem in its accurate formulation. Sorry for my inaccuracy. Below is an edited version.\n\nMy goal is to find a family X(a, b) of random variables (continuously) depending on two non-negative parameters a and b . The family should have the following properties:\n\n(1) X(a, b) take values in the unit interval [0, 1] for all a, b;\n\n(2) For dependent random variables Y(a, b) defined as 1/(a+b*X(a, b)) the expected values E[Y(a, b)] exist;\n\n(3) When b/a is close to 0, the distribution of X(a, b) is close to uniform on [0, 1];\n\n(4) When a/b is close 0, the distribution of X(a, b) is close to \u201cmass\u201c distribution (that is, X(a, b) equals 1 with probability 1).\n\nSo my goal is to find a family of random variables parameterized by a and b to \u201cbridge\u201d the uniform and \u201cmass\u201d distributions.\n\nI tried different parameterizations but was not able to find a parameterization satisfying all conditions (1)-(4).\n\nshare|improve this question\nI do not understand why you are not happy with the choice $X(a,b)=1$ for all $a,b>0$. \u2013\u00a0 camomille Apr 26 '11 at 16:39\nThank you, camomille. I agree. In my original post I missed an additional condition (required for the purpose of my investigation) that would not permit this obvious choice. My fault. Sorry and thank you again. \u2013\u00a0 Max1 Apr 26 '11 at 18:14\nadd comment\n\n1 Answer\n\nThese conditions are met if $X(a,b)\\in[0,1]$ almost surely for every $a$ and $b$ and if $X(a,b)\\to1$ in probability when $a\\to0$. Hence $X(a,b)=1$ almost surely solves the problem. If one wants to avoid Dirac masses, $X(a,b)$ uniform on $[1/(1+a),1]$ (or on any interval $[c(a),1]$ with $c(a)$ in $[0,1)$ and $c(a)\\to1$ when $a\\to0$) will do.\n\nEdit This is to answer the edited version of the question. A solution is to consider $X(a,b)$ uniform on $[b/(a+b),1]$ or on any interval $[k(a/b),1]$ where the function $k(\\ )$ is such that $k(r)$ in $[0,1]$ for every $r\\ge0$, $k(r)\\to1$ when $r\\to0$ and $k(r)\\to0$ when $r\\to+\\infty$, for example $k(r)=1/(1+r)$ or $k(r)=\\mathrm{e}^{-r}$.\n\nSecond edit Still another solution, such that the support of $X(a,b)$ is the full interval $(0,1)$ for every $(a,b)$, is to assume that $X(a,b)$ has density $c(b/a)x^{c(b/a)-1}$ for $x$ in $(0,1)$, where the function $c(\\ )$ is such that $c(r)\\to1$ when $r\\to0$ and $c(r)\\to0$ when $r\\to+\\infty$. A realization is $X(a,b)=U^{1/c(b/a)}$ with $U$ uniform on $(0,1)$, for example $$ X(a,b)=U^{a/(b+a)}. $$\n\nshare|improve this answer\nThank you, Didier. I should have formulated my goal more accurately to avoid this example. \u2013\u00a0 Max1 Apr 26 '11 at 18:18\nThank you again, Didier! \u2013\u00a0 Max1 Apr 27 '11 at 14:11\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/225602/for-nu-a-probability-measure-on-mathbbr-mathcalb-mathbbr-the-s\nText:\nTake the 2-minute tour \u00d7\n\nGiven a probability measure $\\nu$ on $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$, how do I show that the set (call it $S$) of all $x\\in \\mathbb{R}$ where $\\nu(x)>0$ holds is at most countable?\n\nI thought about utilizing countable additivity of measures and the fact that we have $\\nu(A) < 1$ for all countable subsets $A\\subset S$. How do I conclude rigorously?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nGiven $n\\in\\mathbb N$, consider the set $$A_n=\\{x\\in\\mathbb R:\\nu(\\{x\\})\\geq\\tfrac{1}{n}\\}$$ It must be finite; otherwise, the probability of $A_n$ would be infinite since $\\nu$ is additive. Thus, $A=\\cup_{n\\in\\mathbb N}A_n$ is countable as a countable union of finite sets, but it is clear that $$A=\\{x\\in\\mathbb R:\\nu(\\{x\\})>0\\}$$ so you are done.\n\nshare|improve this answer\nadd comment\n\nLet $S_n:=\\{x,\\nu(\\{x\\})\\geq n^{-1}\\}$. Using $\\sigma$-additivity, we have that $S_n$ is finite (it contains actually at most $n$ elements, as $\\nu$ is a probability measure). Then $S=\\bigcup_{n\\geq 1}S_n$ is countable as an union of such sets.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/8782/multidimensional-array-reduction-through-summation-over-one-of-its-dimensions/8785\nText:\nTake the 2-minute tour \u00d7\n\n1. Introduction\n\nI am using an array of dimension 3 (might become more) to store some values. I would like to implement a function that takes as argument the array and a couple of numbers smaller than the array dimension and returns a standard matrix (dim=2) which is obtained by reduction or \"projection\" (I don't really know how to call it) of the array along all the \"other\" dimensions. First a quick example with an array of dimension/depth 3\n\ndata=Table[10 (i - 1) + 3 (j - 1) + k, {i, 2}, {j, 3}, {k, 4}]\n--> data = {{{1, 2, 3, 4}, {4, 5, 6, 7}, {7, 8, 9, 10}},\n           {{11, 12, 13, 14}, {14, 15, 16, 17}, {17, 18, 19, 20}}}\n\nMy desired function would do, for example, the following\n\nMyfunction[data,{1,2}] = {{10,22,34},{50,62,74}}\n\nAfter this brief introduction, let me explain where I've arrived. First let's generalize a little bit, as it is my goal, eventually.\n\n2. Definitions\n\nLet $M \\in \\mathbb{R}^{\\Pi d_i}$ be an array of dimension $N \\in \\mathbb{N}$.\n\nLet $d_i \\in \\mathbb{N}, \\quad i=1,\\dots,N\\quad$ be the sublengths of each of the dimensions.\n\nWhat I will call in the following the projection of the array along the dimension $q$ is the following surjective function : $$ \\textrm{For } q\\leq N \\in \\mathbb{N}_0,\\quad P(M,q) : \\mathbb{R}^{\\Pi d_i} \\rightarrow\\mathbb{R}^{\\frac{\\Pi d_i}{d_q}} : M(n_1,\\dots,n_N) \\mapsto \\sum_{j=1}^{n_q}M(n_1,\\dots,n_{q-1},j,n_{q+1},\\dots,n_N) $$\n\n3. Goal\n\nThe goal is to write a function that takes any multidimensional array as well as a list of all the dimensions that will be \"kept\" in the final array. For the sake of any representation, the obtained array should be of dimension $\\leq$ 2 but I would like to stay as general as I (we) could.\n\nThe dimensions ordering should simply be the one used to implement the array, and the code should be consistent in order to keep the dimensions in the same order at any time.\n\n4. Implementation\n\nProjectedColumns[len_,cols_]:= Complement[Range[len],cols]\n\nProjectedColumns is a function that returns a list of the dimensions to project, where cols is the list of dimensions to be kept and len is the dimension of the array.\n\nCompoundProjection[data_, cols_] :=\nModule[{len, vect},\n    len = Depth[data] - 1;\n    vect = ProjectedColumns[len, cols];\n        SingleProjection[data, vect[[i]]],\n        {i, Length[vect]}\n\nCompoundProjection is a function that will project all the dimensions sequentially in order to arrive to the final result (The projection is commutative).\n\nSingleProjection[data_, dimnumber_] := ???\n\nNow what I need and I don't manage to get is the function that will actually perfom a one-dimensional projection. In my mind, I would need to have a number of Do loops which equals the dimension of the array.\n\nIn that case, I simply parse through the array and do the summation over the one I'm interested in. Is it possible to set up such a structure with all the commands that Mathematica offers and that I probably don't know ?\n\n5. In summary\n\n  1. Has anyone followed this nonsense ?\n  2. Is there a Mathematica command that makes what I want directly ?\n\n(If Yes then No to the previous questions, then I'm happy)\n\n  1. Is there a way to improve the correctness or elegance of what I did ?\n  2. Is there a way to intricate a dynamic number of Do loops ?\n  3. Or, in general, is there another way to achieve the goal described in 3.\nshare|improve this question\nMaybe you can start from this : Map[Total , data, {2}], which will do what you seek with Myfunction \u2013\u00a0 b.gatessucks Jul 27 '12 at 18:07\nSeems that @b.gatessucks is right. But I would like to see a few more examples for the {1,2} parameter in your first code snippet \u2013\u00a0 belisarius Jul 27 '12 at 18:10\nadd comment\n\n3 Answers\n\nup vote 10 down vote accepted\n\nDid you know about the second argument of Total, which lets you sum up element at a certain level, which in practice means along a certain dimensions?\n\nFor example, if you want to keep levels 1 and 2, and sum up along level 3, you can use\n\nTotal[data, {3}]\n\n(* ==> {{10, 22, 34}, {50, 62, 74}} *)\n\nOr sum up along dimension 1:\n\nTotal[data, {1}]\n\n(* ==> {{12, 14, 16, 18}, {18, 20, 22, 24}, {24, 26, 28, 30}} *) \n\nThis is the same as removeDimensions[data, {3, 1}].\n\nshare|improve this answer\nReading this I though initially that you could actually get all the desired functionality out of just Total and complement, however you run into trouble with it if you want to remove for example dimension 1 and 4 in a 6 dimensional structure, and then you need to reorder the arguments, or call Total continually while recalculating the dimensions on each pass. \u2013\u00a0 jVincent Jul 27 '12 at 18:27\n@jVincent Yes, for that it's necessary to call Total two times. \u2013\u00a0 Szabolcs Jul 27 '12 at 19:03\nTotal seems to be a good tool indeed. I've come up with a way of using it recursively. You don't need to relaculate anything in the process. You just apply the reduction beginning by the deepest dimensions and then it works fine. \u2013\u00a0 Pschoofs Jul 30 '12 at 9:08\nadd comment\n\nI may be misunderstanding what you need, however consider this. If you have an structure of nested lists such as your data, then summing across the deepest list is easily accomplished using Map[Total,data,{-2}]. So, as long as you want to remove dimensions from \"the back\" you are good to go. And if we need to remove for example the second dimension, then you can just transpose it to the back, and then remove it:\n\n\nSumming out more then one dimension would then just be pushing them all to the back, and applying Total at a higher level and summing all the way down. Which can be done as:\n\n transposeOrder[data_, dimensions_] := \n    Join[dimensions, Complement[Range[Depth[data] - 1], dimensions]]\n\n removeDimensions[data_, dimensions_] /; (Length[dimensions] < Depth[data] - 1) := \n    Map[Total[#, Infinity] &, \n    Transpose[data, transposeOrder[data, dimensions]],\n    {-1 + Length[dimensions] - (Depth[data] - 1)}]\n\nAnd for the case where you aren't removing any dimensions, I suppose it should just fall back to reordering them:\n\n sumOutDimensions[data_, def_] /; Length[def] == Depth[data] - 1 := Transpose[data, def]\n\nNow these functions output the results with dimensions in the order given by the input, if you want to retain the order of the data structure, you could just sort the arguments to it.\n\n removeDimensions[data, {1, 2}]\nshare|improve this answer\nadd comment\n\nHere's a version using Flatten to push all the \"unwanted\" dimensions down to the innermost level before applying the desired function.\n\nkeepDimensions[data_, dims_List, func_:Total]:=\n\nExamples :\n\nkeepDimensions[data, {1,2}]\n\nAny combination of dimensions can be kept\n\nkeepDimensions[data, {1,3}]\n\nKept dimensions can be re-ordered\n\nkeepDimensions[data, {3,1}]\n\nAn optional third argument can be supplied to do something other than summation:\n\nkeepDimensions[data, {1,3}, Max]\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/kb/thread.jspa?threadID=2616226\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nSearch All of the Math Forum:\n\n\nMath Forum \u00bb Discussions \u00bb sci.math.* \u00bb sci.math.independent\n\nTopic: Final Detailed Constructive proof of No Odd Perfect Number beyond 1\n#1449 Correcting Math\n\nReplies: 4 \u00a0 Last Post: Jan 21, 2014 8:59 PM\n\nAdvanced Search\n\n\nPosts: 8,731\nRegistered: 3/31/08\nFinal Detailed Constructive proof of No Odd Perfect Number beyond 1\n#1449 Correcting Math\n\nPosted: Jan 20, 2014 1:36 AM\n\nFinal Detailed Constructive proof of No Odd Perfect Number beyond 1 #1449 Correcting Math\n\nAlright, I am sorry for the hundreds or more posts of \"proof of No Odd Perfect Number\" that I posted on the sci.math newsgroup. Sorry because all of them were tentative and not actually a proof. Because I now have the proof, as the below shows. So that all those hundreds of tentative proofs finally lead to the true one. So I guess, then, No Odd Perfect was the hardest of these 6 proofs: Goldbach, Bertrand's postulate, AP-postulate, Fermat's Last Theorem FLT, Beal's conjecture, No Odd Perfect, for it took the longest to resolve. Maybe there is a lesson in it, which I am not going to try to seek. Maybe it is the oldest unsolved math problem for a good reason, in that it hides in the shadows and you need to solve it with a minimum facts such as k-1. No Odd Perfect turns out to be more difficult of finding that unwanted \"2\", whereas square root of 2 the unwanted \"2\" pops up soon. But one of the reasons No Odd Perfect took so long is the contorted and arbitrary definition of what is a factor and what is not. There are still some illogical folk who think the factors of 9 are just 1,3, or think that 1,3,9, when in truth, with a proper logic the factors of 9 are cofactors of 1x9 and then 3x3 for four numbers in full. So that No Odd Perfect could ever be proven if one batch of mathematicians counts 9 as only 2 factors, another batch counts 3 factors and then I count 4 factors.\n\nDetailed Constructive proof No Odd Perfect Number\n\n\nExample is 6 and 15:\n\nThe number 6 has cofactors of 1 with 6, and 2 with 3 and represented as this:\n\n\n\n\nNow we omit or delete the number itself and 1 factor and for 6 we omit the 1 and 6 and have remaining the 2,3 cofactors so we have k-1 when k is the number. For 6, k-1 is 5 where 2+3 = 5. For 15, k-1 is 14 and where we have 3+5 = 8.\n\nFor 18 we have\n\nand for k-1 we have 17, but we have 2+9+3+6 = 20\n\nFor 20 we have\n\n(1 + 20) + (2 + 10) + (4 + 5) = 42 and for k-1 we have 19, but we have\n2+10+4+5 = 21\n\nFor 9 we have\n\n(1 + 9) + (3 + 3) = 16 and for k-1 we have 8, but we have 3+3=6\n\nFor 28 we have\n(1 + 28) + (2 + 14) + (4 + 7) = 56, and for k-1 we have 27, and we have\n2 + 14 + 4 + 7 = 27\n\nConstructive Definition of a Perfect Number\nNow let me define the Perfect Number in general with a formula. Summation of cofactors with the 1 and k omitted must equal k-1.\n\nConstruction proof\n\n\nMeans that the cofactor summation is k-1 once the 1 and k cofactors are omitted.\n\nSince k is Odd Perfect, all its cofactors below k-1 are odd numbers. That means their sum is an even number.\n\nHere we have two possibilities: either the smallest divisor of k is 2 or is 3.\n\nCan 3 be the smallest cofactor divisor of this arbitrary odd perfect number k, would mean that we can separate the divisors into two groups, one of which is 1/3(k-1) and the the remaining terms are 2/3(k-1).\n\nOr, is 2 the smallest cofactor divisor, would mean that the two groups are both 1/2(k-1).\n\n\n(1 + 945) omitted\n\nFor 945 the k-1 is 944, but in actuality, once we omit the 1 and 945. We have remaining the sum\n\nI displayed the abundant odd number to compare with the deficient odd number of 15. Few people know that some odd numbers can be abundant.\n\nNow for the impossibilty of the construction of the Odd Perfect.\nThe Odd Perfect has a k-1 that is even, for odd +odd is even. The smallest cofactor divisor of the Odd Perfect number must be either 3 or 2, or if you want the smallest to be say 5, the argument works the same. If 3 is the smallest divisor of k, then 1/3(k-1) is the sum of factors and 2/3(k-1) the remaining sum of factors for k-1. That makes for an impossible construction situation, since the sum of k-1 is even, and a portion of the factors is to add together to be 1/3* even number k-1 and the other portion to be 2/3*even number k-1. You cannot divide an even number k-1 into two portions of 1/3 and 2/3.\n\nSo here we grasp the impossible construction of a even number k-1 with 1/3 portion and 2/3 portion of an even number. Now if 5 were the smallest divisor we run into the problem of 1/5 and 4/5 and the same goes for larger odd numbers as the smallest divisor.\n\nThe only other alternative is that 2 is the smallest divisor of k-1 and that implies that 2 is a divisor of k. But that is impossible for then an odd number k has 2 as a divisor.\n\nSo basically, the proof hinges on the fact that we take the arbitrary odd perfect number and force it to have a sum that is even. That means we separate k into k-1 where we are guaranteed of a even number sum since pairs of odd numbers is always even. Now, the final operation of construction is ask what the lowest or smallest divisor could possibly be for the k-1. Is it 3 or 2 or some larger odd number? We then show it cannot be 3, nor 2 nor any larger odd number.\n\n\n\n\nArchimedes Plutonium\n\n\n[Privacy Policy] [Terms of Use]\n\n\u00a9 Drexel University 1994-2014. All Rights Reserved."}
{"text": "Retrieved from http://math.stackexchange.com/questions/432652/confusion-regarding-change-of-variables-in-odes\nText:\nTake the 2-minute tour \u00d7\n\nConsider the following exercise:\n\nUsing the Laplace transform, find a solution $y(x)$ of the following initial value problem:\n\n$$\\begin{cases} y'' +y = x + 1, \\quad x > \\pi \\\\ y(\\pi) = \\pi^2 \\\\ y'(\\pi) = 2\\pi \\end{cases}$$\n\nSuggestion: Make the change of variables $t = x - \\pi$.\n\nOf course, this equation is pretty easy to solve without the Laplace transform, but the whole point of the exercise is to use it. That's not the problem, though. I'm having some trouble with the change of variables.\n\nI know that for the derivatives you have to use the chain rule; in this case, since $dt = dx$ there's no difference. My main issue is with the initial conditions. I'm not very sure how to restate them in terms of $t$, and I think that's because I don't really know a precise definition of change of variables. How is it done? Do we define a new function, something like $g(t) = y(x-\\pi)$, if that even makes sense? What would be a general method to make sure one does things like this carefully?\n\nI apologize if the question is rather vague. Just to be clear, I'm not asking how to solve this particular differential equation; I've realized I get confused in general when using change of variables in an ODE.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nTry to use Laplace transform to solve: $$\\begin{cases} g'' +g = t+ \\pi + 1, \\quad t > 0 ,\\\\ g(0) = \\pi^2, \\\\ g'(0) = 2\\pi. \\end{cases}$$\n\nLike you said, but it is not letting $g(t) = y(x-\\pi)$, rather it is letting $g(t) := y(t+\\pi) = y(x)$. Basically the equation is translated by $\\pi$ in the independent variable, so when originally the initial condition is at $x = \\pi$, now it is at $t = x-\\pi = 0$.\n\nshare|improve this answer\nThat works. But what's the point then ofusing two different \u2013\u00a0 Javier Badia Jun 30 '13 at 13:09\n@JavierBadia Because Laplace transform's formula for derivatives involve the initial value at 0: $\\mathcal{L}\\{f'\\} = s\\mathcal{L}\\{f \\}-f(0)$. You can use the initial value at $\\pi$ as well, but whenever you perform the integration by parts using the definition of Laplace transform, you will find it essentially you are translating the coordinates as well, so it is easier to do it before going into the Laplace transform stage. \u2013\u00a0 Shuhao Cao Jun 30 '13 at 16:03\n@Shuhaho: I'm sorry, I accidentally submitted that comment early and was going to fix it but I forgot. I understand that. What I was going to say is, what's the point of using a different variable name? Like you said; isn't it clearer to say \"use $g(x) = g(x+\\pi)$\" instead of \"use $t = x - \\pi$\"? \u2013\u00a0 Javier Badia Jun 30 '13 at 16:43\n@JavierBadia Using the same letter would cause confusion, for $g(x) = g(x+\\pi)$ means periodicity for the same function $g$, using a different letter just avoid this: say $y(x) = x^2$, then letting $g(t) := y(t+\\pi) = t^2 + 2\\pi t + \\pi^2$, this can be also written as $g(x) := y(x+\\pi) = x^2 + 2\\pi x + \\pi^2$, $g$ and $y$ are simply different functions, one of which is a translation in $x$ of the other. \u2013\u00a0 Shuhao Cao Jun 30 '13 at 16:58\nIt seems I just can't write comments today. I meant $g(x) = y(x+\\pi)$. \u2013\u00a0 Javier Badia Jun 30 '13 at 17:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/68907/associativity-of-moyal-like-products/68929\nText:\nTake the 2-minute tour \u00d7\n\nThe Moyal product of two smooth functions $f,g$ on $\\mathbb R^{2n}$ can be defined as $$ f\\star g = \\exp\\left(-\\omega^{ij} \\frac{\\partial}{\\partial y^i} \\frac{\\partial}{\\partial z^j}\\right) f(y)g(z) \\vert_{z=y}. $$\n\nwhere $\\omega^{ij}$ are the components of a symplectic form. There is a similar formula for the Clifford product (where instead of derivatives there are interior products) when translated to the exterior algebra.\n\nIn both cases the product is associative and I've seen many references say that it is easy to check that the Moyal product is associative (directly, without appealing to a symbol map).\n\nUnfortunately I do not see an easy way to check associativity. I was also wondering if this sort of product is a standard thing, considering that I've seen it in two contexts (though I guess they are very much related as the Clifford algebra is a deformation of the exterior algebra and the Moyal product gives a deformation quantization of $\\mathbb R^{2n}$).\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\n$\\def\\dd#1{\\tfrac{\\partial}{\\partial #1}}$Observe first that $$\\dd{x}\\Big(f(x,y)|_{x=y}\\Big) = \\Bigg(\\Big(\\dd x+\\dd y\\Big)f(x,y)\\Bigg)\\Bigg|_{x=y}$$\n\nLet us write $E(\\dd{y}, \\dd{z})=\\exp(-\\omega^{i,j}\\dd{y^i}\\dd{z^j})$, so that $$ (f\\star g)(x)=\\Big(E(\\dd{x},\\dd{y})\\cdot\\big(f(x)g(y)\\big)\\Big)\\Big|_{x=y}$$ and consequently \\begin{align} ((f\\star g)\\star h)(x)&=\\Bigg[E(\\dd x,\\dd z)\\cdot\\Bigg(\\Big(E(\\dd{x},\\dd{y})\\cdot\\big(f(x)g(y)\\big)\\Big)\\Big|_{x=y} h(z)\\Bigg)\\Bigg]\\Bigg|_{x=z}\\\\ &=\\Bigg[E(\\dd x+\\dd y,\\dd z)E(\\dd x,\\dd y)\\cdot f(x)g(y)h(z)\\Bigg]\\Bigg|_{x=y=z} \\\\ &=\\Bigg[E(\\dd x,\\dd z)E(\\dd y,\\dd z)E(\\dd x,\\dd y)\\cdot f(x)g(y)h(z)\\Bigg]\\Bigg|_{x=y=z}\\end{align}\n\nComputing the product in the other order, we get a similar expression, which only differs in the differential operator involved: it is a product of the same three factors in a different order. Since these factors commute, this is not a problem.\n\nshare|improve this answer\nAh, thanks a lot for the answer, Mariano! That crucial step in the last line of using the properties of $\\exp$ is what I kept missing. \u2013\u00a0 Eric O. Korman Oct 1 '11 at 2:59\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/permutation-groups.52613/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nPermutation groups\n\n  1. Nov 14, 2004 #1\n    what is the number of elements of order 5 in the permutaion group S7??\n    so what we're concerned with here is, after decompositon into disjoint cycles the l.c.m of the lengths must be 5. since 5 is a prime, the only possible way we could get 5 as l.c.m would be to fix ANY 2 elements amongst the 7 to themselves....so we end up getting 2 cycles of length 1 each. the remaining five elements can be arranged in 4! ways...\n    so, the answer is 7C2 * 4! = 21*24 = 504.\n    :smile: but unfortunately, this answer is WRONG!!\n  2. jcsd\n  3. Nov 14, 2004 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Since 5 is prime, you MUST have cycle of length 5.\n    Then there could be a 2-cycle in addition.\n  4. Nov 15, 2004 #3\n\n    well....yes, it's possible to have a cycle of length 2 in addition to the 5 cycle...but then the l.c.m becomes 10. so that rules out such a consideration!\n  5. Nov 15, 2004 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Yes, so the only permutations in S7 of order 5 are the 5-cycles.\n  6. Nov 15, 2004 #5\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Your answer is wrong because you've counted, for example:\n\n    12345, 23451, 34512, 45123, and 51234 as different elements.\n  7. Nov 15, 2004 #6\n    ya....so what further? that's a valid point you've raised...\n    so do you divide by 4?\n  8. Nov 15, 2004 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have [itex]{7 \\choose 5}[/itex] ways to pick 5 elements from a set of 7.\n    There are 5! ways you can order 5 elements in a cycle.\n    For a given cycle of length 5, 5 orderings are give the same permutation.\n  9. Nov 16, 2004 #8\n    hey galileo\n\n    please read stuff carefully...\n    we left this a long while ago, right astronut?! :smile:\n  10. Nov 21, 2004 #9\n    i think the solution 504 is correct....\n    i don't see any fallacy in it.\n  11. Nov 21, 2004 #10\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The general solution is:\n\n    suppose t is a permutation of type\n\n\n    then the order of the centralizer is\n\n    [tex]\\prod_i i^{m_i}m_i![/tex]\n\n    in this case it is 1^2.5\n\n    so the centralizer's order is\n\n\n    hence the conjugacy class has order\n\n\n    which is indeed 504\n\nHave something to add?\n\nSimilar Discussions: Permutation groups\n  1. Permutation Group (Replies: 2)\n\n  2. Permutation Group (Replies: 29)"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/9831/context-free-grammar-for-language-l\nText:\nTake the 2-minute tour \u00d7\n\nCan someone help with this:\n\n$L=\\{a^ib^j \\mid i,j \\ge 1 \\text{ and } i \\ne j \\text{ and } i<2j\\}$\n\nI'm trying to write a grammar for this language? I tried this:\n\n$S \\to S_1 \\mid S_2 \\\\ S_1 \\to aXb \\\\ X \\to aXb \\mid aaXb \\mid aab \\\\ S_2 \\to aYb \\\\ Y \\to aYb \\mid Yb \\mid b \\\\ $\n\nWhat do you think?\n\nshare|improve this question\nSeems correct. Is there a problem? \u2013\u00a0 Karolis Juodel\u0117 Feb 16 '13 at 11:46\nYou should format your questions using MathJax in the future. You can learn more about the formatting by clicking on the \"edit\" link of a question to see its source. Most latex symbols work when used within '$' signs. You can look this up for a quick reference. \u2013\u00a0 Paresh Feb 16 '13 at 13:37\n\n1 Answer 1\n\nThe solution in the question is correct.\n\nThe constraint $i\\ne j$ is the one that gives us trouble. To get around it we have to split into two cases: (i) $i<j$, and (ii) $i>j$ (but still $i<2j$)\n\n$S\\to S_{(i)} \\mid S_{(ii)}$\nas the first production splits into this two cases.\n\nNow, divide and conquer: case (i) is very simple, since we only need $i<j$,\n$S_{(i)} \\to aS_{(i)}b \\mid B$\n$ B \\to Bb \\mid b$\n\nThis is your $S_2$.\n\nFor case (ii), we need to $j< i < 2j$, so for every single $a$, the variable $C$ will generate exactly one $b$, and at a certain point we switch to the variable $D$ that will generate two $a$'s for each $b$.\n$S_{(ii)} \\to aCb $\n$ C \\to aCb \\mid D$\n$ D \\to aaDb \\mid aab$\n\nThis is your $S_1$.\n\nshare|improve this answer\nTo get $i < j$ you need $S_{(i)} \\rightarrow a S_{(i)} b \\mid B b$, $B \\rightarrow B b \\mid \\epsilon$. The $B$ alternative adds at least one $b$ here. \u2013\u00a0 vonbrand Mar 20 '13 at 13:29\nyes, you're right. \u2013\u00a0 Ran G. Mar 20 '13 at 16:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/76824/prove-an-orthogonal-map-has-orthogonal-matrix-with-respect-to-orthonormal-basis?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nLet $V$ be a vector space with the orthonormal basis $Q = \\{ \\vec{q_1},\\ldots, \\vec{q_n} \\}$ and let $\\ell:V\\to V$ be an orthogonal map. Prove that the matrix $L$ of of $\\ell$ with respect to $Q$ is orthogonal.\n\nNote: By orthogonal map I mean that $\\ell$ is linear and satisfies $\\left\\Vert \\ell(\\vec{x}) \\right\\Vert = \\left\\Vert \\vec{x} \\right\\Vert$ for all $x \\in V$. By orthogonal matrix I mean that $L$ has orthonormal columns.\n\nI have that $$ L=\\left[ \\begin{array}{ccc} [\\ell(\\vec{q_1})]_Q & \\cdots & [\\ell(\\vec{q_n})]_Q \\end{array} \\right] $$\n\nbut I don't have any idea how to proceed.\n\nshare|improve this question\nIf you are in a real vector space do you mean that $l : V \\mapsto V$ is a unitary operator? \u2013\u00a0 user38268 Oct 29 '11 at 0:44\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nA proof sketch.\n\n  1. Show that $\\langle \\ell(\\vec x), \\ell(\\vec {y}) \\rangle = \\langle \\vec x , \\vec y \\rangle$ holds for all $\\vec x, \\vec y \\in V$. For this step, you may need the following hint: $$\\langle \\vec x, \\vec y \\rangle = \\frac{1}{2} (\\| \\vec x+\\vec y \\|^2 - \\| \\vec x \\|^2 - \\| \\vec y \\|^2) .$$\n\n  2. Show that if the $i^{\\rm th}$ column of $L$ is $c_i \\in \\mathbb R^n$, then $$ \\ell(\\vec {q_i}) = \\sum_{k = 1}^n c_{i,k} \\cdot \\vec {q_k}. $$\n\n  3. Show that for $1 \\leq i, j \\leq n$, we have $$ \\langle \\ell(\\vec {q_i}) , \\ell(\\vec {q_j}) \\rangle = \\langle c_i, c_j \\rangle. $$\n\n  4. Using (1.), what can you say about $\\langle \\ell(\\vec {q_i}) , \\ell(\\vec {q_j}) \\rangle$? What does this mean about $\\langle c_i, c_j \\rangle$?\n\nshare|improve this answer\nI assumed real base field, but the complex case shouldn't be much more difficult. \u2013\u00a0 Srivatsan Oct 29 '11 at 0:47\nI am making no assumptions about the base field. It could be real, complex, finite, etc. I have shown now that the columns are orthogonal, but how can I show they are still length 1? I only used your first step to show orthogonality, and I don't really follow the other steps. \u2013\u00a0 nullUser Oct 29 '11 at 0:56\nDid you understand what $c_i$ means? Where exactly are you stuck in (2.)? \u2013\u00a0 Srivatsan Oct 29 '11 at 0:59\nI have shown that $[\\ell(\\vec{q_i})]_Q = \\sum_j \\langle \\ell(\\vec{q_i}),\\vec{q_j} \\rangle \\vec{q_j}$ if that helps. \u2013\u00a0 nullUser Oct 29 '11 at 1:05\n@Kb100 the base field must be either real or complex. Otherwise the inner product doesn't make sense. \u2013\u00a0 user12014 Oct 29 '11 at 1:25\n\nSuppose $T: V \\to V$ is an isometry, i.e. $\\|Tx\\| = \\|x\\|$ for all $x \\in V$. Then $T$ is clearly injective, so since $V$ is finite-dimensional, it is also surjective. This means $T^{-1}$ exists. By the polarization identity we have $$\\langle Tx, Ty \\rangle = \\frac{1}{2}(\\|T(x+y) \\|^2- \\|Tx\\|^2 - \\|Ty\\|^2)$$ $$ = \\frac{1}{2}(\\|x+y \\|^2- \\|x\\|^2 - \\|y\\|^2) = \\langle x, y \\rangle$$ which implies $$\\langle Tx, y \\rangle = \\langle x, T^{-1}y\\rangle$$ Hence $T^{-1} = T^*$. But the matrix for $T^*$ with respect to an orthornormal basis $Q = \\{q_1, ..., q_n\\}$ is Hermitian transpose of the matrix for $T$: $$[T]_Q^* = [T^*]_Q = [T^{-1}]_Q = [T]_Q^{-1}$$ So $$[T]_Q[T^*]_Q = [T]_Q[T]^{-1}_Q = I$$ Let $(A)_i$ and $(A)^j$ denote the $i$-th row and $j$-th column of $A$ respectively. Then by the definition of matrix multiplication and Hermititan transpose $$[T]_Q{[T^*]_Q}_{ij} = \\langle ([T]_Q)^i, {([T]^*_Q)}_j \\rangle = \\langle ([T]_Q)^i, {([T]_Q)}^j \\rangle = \\delta_{ij}$$ So the columns of $[T]_Q$ are orthonormal.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53536.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nRate of Change of Angle\n\nDate: 8/12/96 at 0:31:2\nFrom: da bellm\nSubject: Rate of Change of Angle\n\nDear Dr. Math,\n\nI'm an engineering student at the University of Adelaide in South \nAustralia.  This is a problem that I was given about 4 years ago,  \nback in high school.  No one I've asked has been able to give me a \nsatisfactory answer to it.\n\nTwo roads, BA and CA, meet at an angle of 60 degrees. A landmark \nsituated at B, 500 metres from A, is visible to drivers approaching \nA along CA. A vehicle at X is moving along CA towards A at \n72 kilometres per hour.\n           /  o\n         /  60\n      A                   X           C\n\na)  Find the rate at which BX is changing when the vehicle is 500m \nfrom A. (This bit is easy,  but leads on to part b.)\n\nb)  Find the rate at which angle BXA is changing in radians per second \nwhen the distance BX is least,  and give a physical explanation of why \nit is whatever it is. (This is the hard bit!)\n\nHave a nice day, \n\nDate: 8/24/96 at 19:30:46\nFrom: Doctor Mike\nSubject: Re: Rate of Change of Angle\n\nHi  Dave, \nSince you already understand part (a) I'll skip that one. \nPart (b) is a fantastic calculus problem! The straightforward way\nis incredibly long and messy, but there's a quick way if you look\nat it right.  The key is the Chain Rule for derivatives.\nDrop a perpendicular from B to the road CA and let that be the\norigin of a coordinate system with +x toward C and +y toward B.\nThis origin is 250 metres from A and 250*sqrt(3) metres from B.\nThe only *physical explanation* I see is the observation that\nBX is least exactly when the vehicle location X is at the origin.\nTo keep consistent units, use 20 metres per second rather than \n72kph.  With respect to some arbitrary reference time t=0 let p(t)\nbe the x-coordinate of the vehicle location on road CA at time \nt seconds.  If the reference time is when the vehicle is M metres\nfrom the origin, then p(t) = M-20t and p'(t) = -20 is constant.\nLet d(t) be the distance BX at time t seconds, and a(t) be the\nangle BXA at time t seconds.  Then cos(a(t)) = p(t)/d(t).  \nTake derivatives of both sides to get : \n                             d(t)*p'(t) - p(t)*d'(t)  \n       -sin(a(t)) * a'(t) = ------------------------- \nYou want to solve for a'(t) when BX is least, which is when X is\nat the origin, a(t) = pi/2, and d'(t) = 0 for a d(t) minimum.\nAnswer: (2/75)*sqrt(3) or about 0.046188 radians per second.\nI hope this is what you were looking for. \n\n-Doctor Mike,  The Math Forum\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/22937/a-simple-pendulum-moving-at-a-relativistic-speed-how-does-the-period-change\nText:\nTake the 2-minute tour \u00d7\n\nI've been pondering the precise mechanism of time dilation for the example of a simple pendulum in two different situations:\n\n  1. The observer and ground are at rest in one frame of reference; the pendulum is moving at high speed with respect to that frame.\n\n  2. The observer is at rest in one frame of reference; the pendulum and the ground together move at high speed with respect to that frame.\n\nuser8260 has pointed out that in situation 1, in the pendulum's frame $g$ is greater by $\\gamma^2$ compared to $g$ in the observer's frame. Thus in the pendulum's frame the period is less than it is in the observer's frame by a factor of $1/\\gamma$, just as one would expect from time dilation.\n\nBut what about situation 2? Here, compared to the pendulum frame, the observer sees the pendulum with the same length in a stronger gravitational field, yet observes a longer period. Does the inertial mass of the pendulum change differently than its gravitational mass? Also, does the analysis depend on whether the plane of swing is perpendicular or parallel the direction of motion?\n\nshare|improve this question\nUser8260 is not right. The first case does not require time dilation changes because the Earth define a ret frame. Only in the second case do you see pure time dilation. \u2013\u00a0 Ron Maimon Apr 5 '12 at 3:14\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nAs in physics in general, a suitable choice of coordinates makes our life so much better. Time dilation in this problem is somewhat a more trivial effect, and the transformation of gravitational field is somewhat a more complicated phenomenon. With this in mind, let me reformulate slightly the two situations:\n\nCase 2. Pendulum is at rest with respect to the Earth (and some observer moves with respect to them, observes time dilation etc etc)\n\nCase 1. Pendulum is set above the Earth, which moves relativistically below it (and some observer moves with the Earth, observes time dilation etc)\n\nSo, let us settle the physics first, and the observer effects last.\n\nCase 2: Classical physics problem, nothing to settle.\n\nCase 1: From the pendulum's point of view, the gravitational field is generated by a moving body (=>the field is unknown). From the Earth frame, a relativistic body moves in a gravity field (=>the equations of motion are unknown).\n\nOne might transform the energy-momentum tensor of the Earth from the Earth rest frame to the pendulum frame, but special care should be taken about the fact that the Earth ceases to be spherical in the new frame (though its density does increase as $\\gamma^2$). Additionally, it is not clear appriori that the motion of the Earth doesn't cause any additional forces.\n\nI propose to use a straightforward yet more secure method of transforming the metric tensor from the Earth frame to the pendulum frame, and hence obtain the gravity, acting on the pendulum.\n\nIn the Earth rest frame the metric tensor is known to be $$g_{\\mu\\nu}=\\left(\\begin{array}{cccc} &1-2U & 0 & 0 & 0 &\\\\ &0 & 1-2U & 0 & 0 &\\\\ &0 & 0 & 1-2U & 0 &\\\\ &0 & 0 & 0 & -1-2U &\\\\ \\end{array} \\right),$$\n\nwhere $U$ is the Newtonian potential of the Earth. This expression corresponds to the so called weak field limit, when the metric tensor is nearly flat. We use the standard notation of MTW ($c=1$, signature $(+++ -)$, Einstein's summation rule etc) and refer to this book for further details on linearized gravity.\n\nTransformation of the field to the pendulum frame:\n\nLorentz tranformation matrix is given by:\n\n$$ \\Lambda_{\\mu'}^{~\\mu}=\\left(\\begin{array}{cccc} &\\gamma & 0 & 0 & \\beta \\gamma &\\\\ &0 & 1 & 0 & 0 &\\\\ &0 & 0 & 1 & 0 &\\\\ &\\beta\\gamma & 0 & 0 & \\gamma &\\\\ \\end{array} \\right), $$ with $\\beta=\\dfrac{v}{c}, \\gamma=(1-\\beta^2)^{-1/2}$ and $v$ being the relative velocity of the pendulum with respect to the Earth rest frame.\n\nThe transformed metric tensor is obtained by: $$g_{\\mu'\\nu'}=\\Lambda_{\\mu'}^{~\\mu}\\Lambda_{\\nu'}^{~\\nu} g_{\\mu\\nu}=\\left(\\begin{array}{cccc} &1-2U\\dfrac{1+\\beta^2}{1-\\beta^2} & 0 & 0 & -\\dfrac{4 U \\beta}{1-\\beta^2} &\\\\ &0 & 1-2U & 0 & 0 &\\\\ &0 & 0 & 1-2U & 0 &\\\\ &-\\dfrac{4 U \\beta}{1-\\beta^2} & 0 & 0 & -1-2U\\dfrac{1+\\beta^2}{1-\\beta^2} &\\\\ \\end{array} \\right)$$\n\nIn the pendulum frame (further primes in the indices are omitted!):\n\nIt is known that only the term $g_{44}$ determines the newtonian potential. One can see that by writing out the lagrangian for the pendulum:\n\n$$ \\mathcal{L}=\\dfrac{1}{2}g_{\\mu\\nu} u^\\mu u^\\nu=\\\\ =\\dfrac{1}{2}((u^1)^2+(u^2)^2+(u^3)^2-(u^4)^2)-\\\\ -U((u^2)^2+(u^3)^2+4 u^1 u^4 \\beta \\gamma^2+((u^1)^2+(u^4)^2)\\dfrac{1+\\beta^2}{1-\\beta^2}) $$\n\nHere $u^\\mu$ is the 4-velocity of the pendulum. As the latter moves non-relativistically (in its own frame), we may consider $u^4\\gg u^1,u^2,u^3$ and $u^4\\approx \\mathrm{const}$, which leaves:\n\n$$ \\mathcal{L}=\\dfrac{1}{2}((u^1)^2+(u^2)^2+(u^3)^2)-U(u^4)^2\\dfrac{1+\\beta^2}{1-\\beta^2} $$\n\nIf the pendulum as a whole didn't move with respect to the Earth, we would have $\\beta = 0$ and\n\n$$ \\mathcal{L}_0=\\dfrac{1}{2}((u^1)^2+(u^2)^2+(u^3)^2)-U(u^4)^2 $$\n\nEffectively, therefore, the pendulum in its rest frame experiences the gravitational field magnified by the factor of $\\dfrac{1+\\beta^2}{1-\\beta^2}$. The pendulum frequency is thus magnified by $\\dfrac{(1+\\beta^2)^{1/2}}{(1-\\beta^2)^{1/2}}$.\n\nRemarks: the neglected terms in the lagrangian are either $\\dfrac{v}{c}$ or $(\\dfrac{v}{c})^2$ smaller than the kept leading terms. Hence, up to $\\dfrac{v}{c}$ accuracy the direction of motion doesn't affect the pendulum frequency.\n\nFinally, lets add time dilations to get the final answers. Let the period of the pendulum in the case when observer, the Earth, and the pendulum do not move with respect to each other be $T_0$. Then:\n\nCase 1: In the pendulum frame, as we have seen it has the period of $\\dfrac{(1-\\beta^2)^{1/2}}{(1+\\beta^2)^{1/2}} T_0$. Then in the observer frame, due to time dilation, the period is $\\dfrac{1}{(1+\\beta^2)^{1/2}}T_0$.\n\nCase 2: In the pendulum frame the period is $T_0$. In the observer frame the period is $\\dfrac{T_0}{(1-\\beta^2)^{1/2}}$.\n\nTo conclude, the two cases are quite different due to the different physics happening. In one case the observed period changes due to the change of the reference frame, whereas in the other there is an additional factor due to the fact that the gravity of a moving source is not the same as that of a still source.\n\nshare|improve this answer\nThe question for case 2 in the observer frame isn't \"can it be solved with the time dilation formula?\" That must be true. The question is \"can the observer attribute this time dilation to some physical mechanism?\" In his frame there's a pendulum in a gravitational field that is stronger than it would be in the pendulum frame, yet it swings more slowly. \u2013\u00a0 Noah Apr 5 '12 at 13:49\nThe answer is yes. In the lagrangian $u^4\\gg u^1$ stops being true if the pendulum is flying relativistically over the ground (which also moves). Then one has to consider all the terms in the lagrangian, which will lead to the same result as given by the dilation formula. \u2013\u00a0 Alexey Bobrick Apr 5 '12 at 15:39\nAs a follow-up, the gravitational field, which acts on a relativistically moving source is not a newtonian-like potential, it is more complicated (other components of the metric tensor start producing significant effects). Then it is somewhat unsafe to compare the newtonian-like potential acting on a moving body and on a body at rest. In other words the reasoning \"the field is stronger, the effect is different\" cannot apply. Strictly, one should also consider the so-called post-newtonian corrections to the forces (which are represented as the terms in the lagrangian), which change the field. \u2013\u00a0 Alexey Bobrick Apr 5 '12 at 15:45\n\nWhen g increases in the moving frame the period should decrease, not increase. Recall, the period goes like $\\sqrt\\frac{l}{g}$, so a large gravitational acceleration translates to fast oscillations, or a short period. In any case, the stationary reference frame should always measure a period that is larger by a factor of $\\gamma$ than what the moving frame sees. This time dilation shouldn't be correlated with the changing of the effective density in the moving frame - that is something of a red herring. Really, this isn't a lorentz invariant system (because of the large stationary mass defining the gravitational field) so this might cause some of the confusion. Yes, the gravitational field looks different in a moving frame, and yes, this should cause a change in the period, but this isn't the same thing as the usual time dilation effect one expects in special relativity. Both effects are at play here. Finally, the density of the earth that the moving observer sees will change by $\\gamma^2$, not simply $\\gamma$. However, as detailed in the answer above, one cannot simply deduce the the moving pendulum's frequency from the density alone because this is a non-inertial frame and one should do a full calculation.\n\nThe situation in question 2 is analogous, but now, from the moving frame's perspective, we have a moving pendulum in an altered gravitational field. We should really formulate this problem properly in the language of tensors. From the moving frame's viewpoint the equation of motion of the mass at the end of the pendulum is (very roughly)$(dv/dt+v\\Gamma'v)=F'$, where $\\gamma'$ is the christoffel symbol in the moving frame and F' is the force. F' transforms as a vector, while $\\gamma$ almost transforms as a vector, but with an extra additive piece. In any case, it is the christoffel symbol built from the metric g'_uv in the moving frame, which does transform as a tensor. We may thus obtain g'_uv by acting on g_uv with the usual transformation matrix, and we know g_uv since it's zero-zero component is simply related to the usual Newtonian potential.\n\nNow, one could do all the algebra here, but the main point is that since both sides are tensors that transform the same way, the end result is guaranteed to be invariant. Thus, if we just wanted to get some answer we would naturally use the stationary frame where the calculation is easier. Thus, we may conclude that the stationary frame gets $\\sqrt(l/g)$ and the moving frame sees $\\gamma$ times this.\n\nOne further note. This question is somewhat analogous to the following problem. Let observer A be stationary and let B be moving. Observer A measures the time, $t_a$, between two events and observer B likewise measures $t_b$. Now, observer A thinks $t_a < t_b$, while observer B thinks $t_b < t_a$. These are just real numbers, so $t_a=t_b$! Obviously something went wrong and this is a standard \"paradox\" in special relativity. The answer is the same: we have to consider the transformation of the non-time components of the four-vector connecting the two events in order to see how one observer interprets the measurements of another. As an exercise, try to calculate B's coordinates for the events and t_b given A's coordinates, and then use this to go back and get A's coordinates from B's coordinates. I.e., transform from A to B to A. One might think that the time is getting \"slower\" with each boost but the two transforms cancel each other (obviously). I think that this is essentially a simplified version of the problem here.\n\nshare|improve this answer\nWhy would the density of the earth in the pendulum support's frame change by gamma squared instead of gamma? \u2013\u00a0 Noah Mar 29 '12 at 0:04\nThe density changes as gamma squared because it is the zero-zero component of the stress energy tensor. Tensors change by acting with the transformation matrix twice, one for each index. For the zero-zero component this is simply gamma squared. \u2013\u00a0 user8260 Mar 30 '12 at 0:57\nThanks. I had hoped there would be a more straightforward dynamical explanation for how an observer moving with respect to the pendulum would describe the difference in period, similar to how an observed watching an object accelerate to high speed might explain the length contraction as an electromagnetic effect - moving atomic nucleic producing distorted fields that reduce bond lengths. \u2013\u00a0 Noah Apr 4 '12 at 20:03\nOkay, I concur with Alexey's answer below. You really can't get the pendulum's period just by considering the change in the density, this was just laziness. A full calculation seems necessary, verbal hand waving won't suffice. \u2013\u00a0 user8260 Apr 4 '12 at 22:39\n-1: this is totally wrong. The Earth defines a rest frame, and only if you move both the Earth and the pendulum do you see time dilation. \u2013\u00a0 Ron Maimon Apr 5 '12 at 3:13\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204036/simplify-sum-i-0n-1-2n-choosei-cdot-xi/204049\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to simplify an expression involving summation as follows:\n\n$$\\sum_{i=0}^{n-1} { {2n}\\choose{i}}\\cdot x^i$$\n\nwhere $n$ is an integer, and $x$ is a positive real number.\n\nAt a first glance, I can see that\n\n$$\\sum_{i=0}^{2n} { {2n}\\choose{i}}\\cdot x^i = {(1+x)}^{2n}.$$\n\nBut what if in the case when $i$ goes from 0 to $n-1$?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nIf you sum from $0$ to $n-1$, then no longer you get an easy espression. Instead, you can get the sum in terms of the hypergeometric function\n\n$$ \\left( x+1 \\right) ^{2\\,n}-{2\\,n\\choose n}{x}^{n} {F (1,-n;\\,n+1;\\,-x)}\\,.$$\n\nshare|improve this answer\n\nIt's just a partial answer.\n\nLet $S_1(x):=\\sum_{i=0}^{n-1}\\binom{2n}ix^i$, and $S_2(x):=\\sum_{i=n+1}^{2n}\\binom{2n}ix^i$. Then writing $j=2n-i$, we get $$S_2(x)=\\sum_{j=0}^{n-1}\\binom{2n}jx^{2n-j}=S_1(x^{-1})x^{2n}.$$ So $$(1+x)^{2n}=S_1(x)+\\binom{2n}nx^n+S_2(x)=S_1(x)+\\binom{2n}nx^n+S_1(x^{-1})x^{2n}.$$ Writing $f(x):=\\frac{S_1(x)}{x^n}$, we get that $f$ satisfies the functional equation $$f(x)+f(x^{-1})=\\left(1+\\frac 1x\\right)^n(1+x)^n-\\binom{2n}n.$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/257875/a-difficult-symmetric-inequality\nText:\nTake the 2-minute tour \u00d7\n\nIn my studies of various geometric inequalities I reached an inequality which seems true (numerically) but I cannot prove it. Let $p$, $q$, and $r$ be real numbers from the interval $(0,1)$. Let's also define the following function $$f({p})=\\frac{\\sqrt{1-p}}{(2-p)^2}$$ Prove (or disprove) that: $$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq \\frac{f(p)}{p\\sqrt{p}}+\\frac{f(q)}{q\\sqrt{q}}+\\frac{f(r)}{r\\sqrt{r}} $$\n\nI've tried Lagrange multipliers but the resulting equations do not seem tractable.\n\nEDIT: The original question had the condition $p+q+r=2$ which apparently is not necessary, so I dropped it. I can prove that the inequality holds for $p=q$. A possible strategy is to try to establish monotonicity in one of the parameters under certain conditions. Unfortunately I can't manage the calculations.\n\nshare|improve this question\nI've noticed that this inequality seems to be true for other functions $f(x)$. Which suggests an additional question - what conditions are needed for $f(x)$ so that the inequality holds given the initial conditions. \u2013\u00a0 ivan Dec 14 '12 at 7:28\nHi ivan, the inequality would not be contrary? \u2013\u00a0 Elias Dec 15 '12 at 15:04\nNo, it is like this. \u2013\u00a0 ivan Dec 15 '12 at 16:57\n@ivan : of course, it is no coincidence that you treated the $p=q$ case. For a fixed $r$, and when we let $p$ and $q$ vary, numerically it seems that the minimum of the difference is attained when $p=q$. This is a familiar pattern in symmetrical inequalities : optimality is reached when the variables are equal. \u2013\u00a0 Ewan Delanoy Dec 17 '12 at 8:51\nI would be tempted to study $$g(p,q,r)= \\frac{f(p)}{p\\sqrt{p}}+\\frac{f(q)}{q\\sqrt{q}}+\\frac{f(r)}{r\\sqrt{r}}-\\frac{f(p)+\u200c\u200bf(q)+f(r)}{\\sqrt{p q r}}\\,.$$ It is clear that $g(1,1,1)=0$ (and even $g(p,1,1)\\geq0$). If one could prove that $\\frac{\\partial}{\\partial p} g(p,q,r)\\leq 0$ on $(0,1]^3$, it would be sufficient (using the symmetry in $p$, $q$, $r$) to conclude on $(0,1]^3$, and then I guess the case with one or several of the other variables equal to $0$ could be handled separately. But the partial derivative does not seem to be very nice, as a maple computation indicates. \u2013\u00a0 Sebastien B Dec 17 '12 at 13:39\n\n2 Answers 2\n\nThis is a comment too long to fit in the usual format. Put $g(x)=\\frac{f(x)}{x\\sqrt{x}}$. Then the inequality to be shown is\n\n$$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq g( p ) +g( q ) +g( r ) \\tag{1} $$\n\nI can show this inequality in a special case, when $r=\\frac{1}{10}$. Indeed, a stronger inequality holds in this case :\n\n$$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq g( r ) \\tag{2} $$\n\nTo show (2), it will suffice to show the following four inequalities :\n\n$$ \\begin{array}{lc} \\frac{f(p)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (3) \\\\ \\frac{f(q)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (4) \\\\ \\frac{f(r)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (5) \\\\ 6 \\leq g(r) & (6) \\\\ \\end{array} $$\n\nConsider the term $$T_1=\\bigg(\\frac{9}{10} (2-p)^2\\bigg)^2pqr - (1-p) $$ Using the fact that $r=\\frac{1}{10}$ and $q=(19/10)-p$, $T_1$ can be rewritten $$ T_1=\\frac{673289}{10^8}+\\frac{62373961}{10^8}(1-q)+\\frac{29403}{80000}(1-q)^2+ (1-q)^3\\Bigg(\\frac{81}{1000}(1-p)^3 + \\frac{1701}{5000}(1-p)^2 + \\frac{48033}{100000}(1-p) + \\frac{58887}{500000}\\Bigg) $$ So $T_1$ is nonnegative, which yields (3). Interchanging $p$ and $q$, we obtain (4). We have $$ f ( r )=\\frac{1}{(2-\\frac{1}{10})^2} \\sqrt{1-\\frac{1}{10}}=\\frac{300}{361\\sqrt{10}} \\tag{7} $$ and hence $$ \\frac{f ( r )}{\\sqrt{pqr}} = \\frac{300}{361\\sqrt{pq}} $$ The identity $$ pq-(\\frac{10}{9} \\times \\frac{300}{361})^2=\\frac{556001}{11728890}+(1-p)(1-q) $$ shows that $pq \\geq (\\frac{10}{9} \\times \\frac{300}{361})^2$, which yields (5). Finally, we deduce from (7) that $$ g ( r )=\\frac{f ( r ) }{r\\sqrt{r}}=\\frac{300}{361\\sqrt{10}} \\times 10\\sqrt{10}=\\frac{3000}{361} $$ and this is indeed larger than $6$, which proves (6) and settles the $r=\\frac{1}{10}$case.\n\nshare|improve this answer\nNice. I tried to generalize this without using $p+q+r=2$ (which seems not to be necessary) but couldn't do it. \u2013\u00a0 ivan Dec 17 '12 at 7:42\nup vote 2 down vote accepted\n\nI was able to prove this, finally. Here is a brief sketch of the proof. I will use the following simple fact:\n\nLemma. For positive numbers, if $a\\geq b\\geq c$ and $(x_1,x_2,x_3)\\succ(y_1,y_2,y_3)$ then $ax_1+bx_2+cx_3\\geq ay_1+by_2+cy_3\\geq ay_i+by_j+cy_k$ where $(i,j,k)$ is an arbitrary permutation of $(1,2,3)$\n\nNow notice that the function : $g(p)=f(p)/\\sqrt{p}$ is decreasing in $(0,1)$. Assume $p\\leq q\\leq r$. Our inequality is equivalent to:$$\\frac{g(p)}{p}+\\frac{g(q)}{q}+\\frac{g(r)}{r}\\geq\\frac{g(p)}{\\sqrt{q r}}+\\frac{g(q)}{\\sqrt{p r}}+\\frac{g(r)}{\\sqrt{p q}}$$ Let's put $x_1=1/p, x_2=1/q$, $x_3=1/r$ and $y_1=(x_1+x_2)/2, y_2=(x_1+x_3)/2, y_3=(x_2+x_3)/2$. Notice that $x_1\\geq x_2\\geq x_3$, $y_1\\geq y_2\\geq y_3$ and $(x_1,x_2,x_3)\\succ(y_1,y_2,y_3)$. Applying the lemma for $a=g(p), b=g(q)$ and $c=g(r)$ ($a\\geq b\\geq c$ because $g(x)$ is decreasing) we get: $$ ax_1+bx_2+cx_3\\geq ay_3+by_2+cy_1=a\\frac{x_2+x_3}{2}+b\\frac{x_1+x_3}{2}+c\\frac{x_1+x_2}{2}\\geq a\\sqrt{x_2 x_3}+b\\sqrt{x_1 x_3} + c\\sqrt{x_1 x_2} $$\n\nand this is exactly what we are trying to prove.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/156218/covering-points-on-a-sphere-with-a-disk?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $m$ points (\"sites\") are selected on the unit sphere $S^2$. For a given radius $r < \\pi$, we can define a disk around any point on the sphere as the set of points at geodesic distance at most $r$ from it. Let $k$ be the maximum number of sites contained in any such disk. Is there a nice lower bound on $k$ in terms of $r$? In other words, what should the function $k(r)$ be so that, no matter where the $m$ sites are placed, we can always find a disk of radius $r$ containing $k(r)$ of them?\n\nI would hope it is simply $m$ times the fraction of the surface area of the sphere covered by a disk. After all, if the average density of sites on the sphere is $m/A$, there must be some disk whose density is at least the average, right? This would be easily proved if you could tile the sphere with disks with no overlap, but you can't, so I'm not sure. If it turns out to depend on the packing density of disks on a sphere, I'll be happy with a reasonable lower bound.\n\nIf you replace the unit sphere and the disks with unit ball and smaller balls of radius $r < 1$ in $\\mathbb R^3$, and the area ratio with the volume ratio, then the naive guess doesn't work. You can have $m/2$ sites clustered around one point near the surface of the unit ball and the other $m/2$ sites around the antipodal point, so that for $\\sqrt[3]{\\frac1{2}} < r < 1$, the volume of a ball of radius $r$ is more half that of the unit ball, but you can't get more than $m/2$ sites inside it. Perhaps it still works in some asymptotic sense; I'm curious about anything rigorous that can be said in this case too.\n\nFinally, although I've stated the above question for the 2-sphere and ball in $\\mathbb R^3$, I'm also interested in the generalization to higher dimensions.\n\nshare|improve this question\n\n1 Answer 1\n\nIt turns out that the answer to my first question is really very simple.\n\nSuppose you pick the center of the disk randomly from a uniform distribution on the sphere. Appealing to symmetry, we may infer that the probability that a given site lies within the disk is precisely the fraction of the surface area of the sphere covered by the disk; if the areas of the disk and the sphere are $a$ and $A$ respectively, this probability is $a/A$. By linearity of expectation, the expected number of sites contained in a randomly chosen disk is $ma/A$. Therefore, there must exist some disk which contains at least this many points.\n\nThe second question remains open, namely the problem of covering as many as possible of $m$ sites in a unit ball with a smaller ball of radius $r < 1$.\n\nEdit: I hate to edit merely to bump this to the front page, but I wanted to use this solution to answer another question on math.SE, and I'd rather not do that if it has a negative score. For all I know, it might have an error that I haven't noticed. The one person who downvoted did not leave a reason; can anyone else let me know if this solution is incorrect?\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/644861/if-both-integers-x-and-y-can-be-represented-as-a2-b2-4ab-prove-that\nText:\nTake the 2-minute tour \u00d7\n\nThere is a set $Q$ which contains all integral values that can be represented by $$a^2 + b^2 + 4ab$$, where $a$ and $b$ are also integers. If some integers $x$ and $y$ exist in this set, prove that $xy$ does too.\n\nI really have no idea how I can go about solving this. I tried simple multiplication of the two assuming one to be $(a^2 + 4ab + b^2)$ and other as $(c^2 + 4cd + d^2)$ but ultimately it leads to a long equation I can make no tail of :/\n\nAny help whatsoever would be greatly appreciated\n\nshare|improve this question\nI have updated your post to LaTeX. Please see that the updates are correct. \u2013\u00a0 gekkostate Jan 20 at 12:48\n@hardmath Fixed! Thanks for the catch! \u2013\u00a0 gekkostate Jan 20 at 13:01\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nSince $a^2+b^2+4ab=(a+2b)^2-3b^2$, your numbers are exactly the numbers of the form $x^2-3y^2$. Now $x^2-3y^2$ is the norm of the algrebraic number $x+y\\sqrt{3}$, so you have the identity\n\n$$ (x^2-3y^2)(u^2-3v^2)=(xu+3yv)^2-3(xv+yu)^2 $$\n\n(multiplicativity of norms).\n\nshare|improve this answer\nThank you so much, now I can finally sleep with this homework done. \u2013\u00a0 skatter Jan 20 at 12:54\nTo make the resulting identity explicit in terms of $a, b, c, d$, if $f(x,y) = x^2 + 4xy + y^2$, then $$f(ac-bd,ad+4bd+bc) = f(a,b) f(c,d).$$ \u2013\u00a0 heropup Jan 20 at 13:13\n\n\nUsing Brahmagupta-Fibonacci Identity,\n\n\n$$n=-m\\implies (a^2-mb^2)(c^2-md^2)=(ac\\mp mbd)^2-m(ad\\mp bc)^2$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/31009/action-of-the-group-of-isometries-on-a-manifold?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nHi guys,\n\nI am able to prove that any symmetric manifold is complete (Consider a local geodesic and use the symmetry to flip it, effectively doubling the length of the geodesic, ad infinitum). I want to use a similar procedure to prove that a manifold whose isometries act transitively is complete, i.e there is always an isometry which maps the start point of a local geodesic to its end point, preserving the geodesic. I am, however, unable to ensure that it is not `rotated' in the process, i.e I want the pushforward of the initial tangent, by the isometry, to be the final tangent, ensuring the resultant doubled geodesic is smooth.\n\nMy Lie group theory is a bit scratchy but I assume there is a method which allows me to construct the correct pushforward using only transitivity.\n\nAny ideas would be great,\n\n\n\nshare|improve this question\nThe result you want is not true in indefinite signature, so you need to assume that you are working with positive-definite riemannian manifolds. (Perhaps this is implicit in your tag, but a growing number of people use riemannian geometry to include also the indefinite case.) \u2013\u00a0 Jos\u00e9 Figueroa-O'Farrill Jul 8 '10 at 15:56\n\n2 Answers 2\n\nup vote 8 down vote accepted\n\nBy the Hopf-Rinow theorem, you only have to prove that the manifold is a complete metric space. By homogeneity, the injectivity radius is bounded from below by a uniform positive constant. Using this and the compacity of balls whose radius is smaller than the injectivity radius of their center it is easy to check the convergence of Cauchy sequences.\n\nAnother way to do this is to interpret the bound on injectivity radius, $r$ say, in term of geodesic extension: a geodesic $\\gamma$ defined on $[a,b]$ can be extended to a geodesic defined on $(a-r,b+r)$. From this the conclusion follows.\n\nshare|improve this answer\nNeedless to say, but just in case and since the OP has not made this clear: this will not work in indefinite signature, where Hopf-Rinow fails. There are incomplete homogeneous lorentzian manifolds, for example. \u2013\u00a0 Jos\u00e9 Figueroa-O'Farrill Jul 8 '10 at 15:54\n\nIt is easy to see that any metrically homogeneous, locally compact, metric space, $X$, is complete. If $p$ is some point of $X$ then, by local compactness, for some $\\epsilon > 0$, the closed $\\epsilon$-ball about $p$ is compact and hence complete. Then, by metric homogeneity, the closed $\\epsilon$-ball about every point is complete. Then, if $x_n$ is a Cauchy sequence in X, eventually the $x_n$ are all within $\\epsilon/2$ of eachother, and so by the triangle inequality they eventually lie in a closed $\\epsilon$ ball about one of them. qed (Of course, the same argument shows more generally that if a metrically homogeneous metric space has one point with a complete neighborhood then it is complete.)\n\nshare|improve this answer\nthank you to everybody. \u2013\u00a0 kangdon Jul 11 '10 at 1:38\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49532/partitioning-a-matrix-with-bounded-row-sums?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be a $n \\times n$ matrix with non-negative entries $a_{ij}$, where $a_{ij}$ is the entry in the $i^{th}$ row and $j^{th}$ column. Assume $\\sum_{1 \\leq j \\leq n} a_{ij} \\leq 1$ for all $1 \\leq i \\leq n$. Also assume $a_{ii} = 0$ for all $1 \\leq i \\leq n$.\n\nI want to partition the index set $I = \\{1, 2 \\ldots n\\}$ into minimum number of sets $I_1, I_2, \\ldots I_t$ so that the column sum is bounded by $1$ in each sub-matrix defined by the sets, or more formally:\n\n  1. $\\cup_{1 \\leq k \\leq t} I_k = I$\n  2. For all $1 \\leq k \\leq t$, $\\sum_{i \\in I_k}a_{ij} \\leq 1$ for all $j \\in I_k$\n  3. The number $t$ is minimized\n\nI can construct examples where $t$ has to be at least $2$, on the other hand, $t = \\Theta(\\log n)$ would suffice for all such matrices. I am wondering if a tighter bound exists.\n\nMotivation: this is a sort of generalization of the coloring problem in bounded out-degree digraphs. If a di-graph has out-degree upper bounded by $k$ it can be colored with $k + 1$ colors.\n\nshare|improve this question\nSo to rephrase the question, you take an edge-weighted digraph with maximum in-degree $k$, and you want to $t$-colour the vertices such that the maximum out-degree to any colour is $k$, right? (I guess you know about the Alon-Tarsi list colouring theorem.) \u2013\u00a0 Andrew D. King Dec 15 '10 at 15:08\nLook at A remark on finite-dimensional $P\\sb{\\lambda }$-spaces by J. Bourgain Studia Mathematica [0039-3223] Bourgain yr: 1982 vol: 72 iss: 3 pg: 285 -289. \u2013\u00a0 Bill Johnson Dec 15 '10 at 16:08\nWell, when you say \"the maximum out-degree to any colour\" if you mean, the maximum weighted out-degree from any node to nodes of the same color, they yes. I actually didn\u2019t know about the theorem you mention :) \u2013\u00a0 Pradipta Dec 15 '10 at 16:09\nYes, that's what I mean. Here is the link for the original Alon-Tarsi paper springerlink.com/content/u627qn50r7013363 , but you might get more out of it by looking at the papers which cite it, for example onlinelibrary.wiley.com/doi/10.1002/jgt.20500/abstract . The proof of their result, which relates to list colourings, uses combinatorial nullstellensatz, which is useful but intimidating. Better to look at what you can do using their theorem as a black box, first. \u2013\u00a0 Andrew D. King Dec 15 '10 at 16:21\nThanks to both Andrew and Bill. I\u2019ll take a look at both papers. \u2013\u00a0 Pradipta Dec 15 '10 at 16:24\n\n2 Answers 2\n\nWhy the qualification \"bounded row-sums\" for a matrix of finite dimension?\n\nshare|improve this answer\nJust emphasizing the upper bound of 1. I guess one could rephrase in the terms the maximum row sum as well. \u2013\u00a0 Pradipta Dec 15 '10 at 19:42\nup vote 0 down vote accepted\n\nOk, I think there are examples where $\\Omega(\\log n)$ colors are needed.\n\nHere\u2019s an example, let $a_{ij} = \\frac{1}{i}$ for $j < i$ and $a_{ij} = \\frac{1}{j^2}$ for $j > i$. Then $\\sum_{j} a_{ij} = \\frac{i-1}{i} + \\sum_{j > i} \\frac{1}{j^2} = O(1)$. Of course, the bound is $O(1)$ instead of $1$, but that can be normalized and all that.\n\nHowever, note that $\\sum_j a_{j1} = \\Omega(\\log n)$ and if we only have $o(\\log n)$ partitions, this sum cannot be \"distributed\" into small enough parts.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/151921/a-hard-proof-of-two-matrixs-elements\nText:\nTake the 2-minute tour \u00d7\n\nThis is not duplicate of A matrix's element proof, but it is harder than that one.\n\nGiven an constant $\\alpha \\in (0,1)$, and an $n \\times n$ matrix $X$ whose all entries are between 0 and 1, and each row sum of $X$ is 1, and ${\\|X\\|}_{\\infty} \\le 1$. Suppose $$A=\\sum_{i=0}^{\\infty} {\\alpha}^i X^i ,$$ $$B=\\sum_{i=0}^{\\infty} \\frac {{\\alpha}^i}{i!} X^i ,$$\n\nI've done some experiments and found that :\n\nFor every two entries $(a,b)$ and $(c,d)$ ,\n\n  \u2022 if $[A]_{a,b} \\ge [A]_{c,d}$, then $[B]_{a,b} \\ge [B]_{c,d}.$\n\n(Note that I use $[A]_{i,j}$ to denote the $(i,j)$-entry of the matrix $A$)\n\nHow can I prove this result mathmetrically? Any suggestions are warmly welcome.\n\n\n** I leak out one condition that each row sum of $X$ is 1.\n\n** The subscript of sum should be starting from 0 (rather than 1) that is, $$A=\\sum_{i=0}^{\\infty} {\\alpha}^i X^i $$\n\nshare|improve this question\nI edited your other question and corrected the typos, perhaps you would do the same for this version of your question! \u2013\u00a0 Gigili May 31 '12 at 7:58\nThe assumption seems to be the same, but the conclusion is much harder for me to prove. \u2013\u00a0 John Smith May 31 '12 at 8:03\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nIt's not true. Note that $A = (I-\\alpha X)^{-1} - I$ and $B = \\exp(\\alpha X) - I$. A consequence of your claim would be that if $A_{ab} = A_{cd}$ then $B_{ab} = B_{cd}$. Try $X = \\pmatrix{1/10 & 29/40\\cr 1/5 & 1/5\\cr}$ and $\\alpha = 4/5$. I get $A = \\pmatrix{4/17 & 29/34\\cr 4/17 & 6/17\\cr}$ so $A_{11} = A_{21}$. But $B \\approx \\pmatrix{.135321868 & .6642856308 \\cr .1832512085 & .226947472\\cr}$ so $B_{11} \\ne B_{21}$.\n\nEDIT: If the sum starts at $0$, then $A = (I-\\alpha X)^{-1}$ and $B = \\exp(\\alpha X)$. Let's try for a $3 \\times 3$ matrix where $A_{12} = A_{23}$ with $\\alpha = 1/2$. $$ X = \\left( \\begin {array}{ccc} \\frac15&\\frac15&\\frac35\\\\ {\\frac {23}{60}}&\\frac25&{\\frac {13}{60}}\\\\ \\frac{1}{10}&\\frac{1}{2}&\\frac25 \\end {array} \\right),\\ A = \\left( \\begin {array}{ccc} {\\frac {2942}{2445}}&{\\frac {248}{815}}&{\\frac {1204}{2445}}\\\\ {\\frac {254}{815}}&{\\frac { 1128}{815}}&{\\frac {248}{815}}\\\\ {\\frac {422}{2445}} &{\\frac {368}{815}}&{\\frac {3364}{2445}}\\end {array} \\right)$$ $$ \\ B \\approx \\left( \\begin {array}{ccc} 1.127701142& 0.1620598118& 0.3589603173\\\\ 0.2284419794& 1.252387244& 0.1678920478 \\\\ 0.0872176063& 0.3115915010& 1.249912163 \\end {array} \\right)$$\n\nshare|improve this answer\nSorry, I leak out that each row sum of $X$ is 1. \u2013\u00a0 John Smith May 31 '12 at 8:33\nI also corrected one mistake that the index of summations in $A$ and $B$ should go from 0 (rather than 1). This would ensure that $A$ and $B$ are diagonally dominant. I think in this case, your counterexample won't apply. \u2013\u00a0 John Smith May 31 '12 at 9:07\n@Robert: I copied your TeX for your matrices to write mine, and it's different from how I usually make matrices. Does \\pmatrix just know how big to make the matrix, and then put parentheses around it? And what is \\cr? \u2013\u00a0 mixedmath May 31 '12 at 10:08\n\\pmatrix is plain TeX rather than LaTeX. It just happens to be what I'm used to. It makes a matrix delimited by parentheses. \\cr goes to the next row. \u2013\u00a0 Robert Israel May 31 '12 at 16:21\n\nThe result is still not true.\n\nSuppose $X = \\pmatrix{1/10 & 9/10 \\cr 1/2 & 1/2 \\cr}$ and $\\alpha = 4/5$.\n\nThen I get\n\n$$A \\approx \\pmatrix{2.272 & 2.727 \\cr 1.515 & 3.484 \\cr} \\qquad B \\approx \\pmatrix{1.261 & 0.963 \\cr .535 & 1.690 \\cr}$$\n\nAnd $[A]_{(1,2)} > [A]_{(1,1)}$ but $[B]_{(1,2)} <[B]_{(1,1)}$\n\nshare|improve this answer\nI corrected the index $i$ goes from 0, not start from 1. So $A$ and $B$ should be diagonally dominant. \u2013\u00a0 John Smith May 31 '12 at 9:53\n@John: These are the sums from $0$. I'll note that in this case, even $\\sum_0^8 \\alpha^i X^i$ has that $[A]_{(1,2)} > [A]_{(1,1)}$ \u2013\u00a0 mixedmath May 31 '12 at 10:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/5874/existence-of-a-perfect-measurable-set\nText:\nTake the 2-minute tour \u00d7\n\nGiven a set $E$ which is bounded, measurable and $m^{\\ast}(E)=x >0$, then for each $y \\in (0,x)$ we can find a measurable set $A \\subset E$, such that $m^{\\ast}(A)=y$. To see this one considers measure as a continuous function and applies the Intermediate Value property.\n\nNow we extend the question in the following manner: Suppose $E$ is a set which has finite measure, then for each positive $x < m^{\\ast}(E)$ prove that there exists a perfect set $A \\subset E$, such that $m^{\\ast}(A)=x$.\n\nshare|improve this question\nen.wikipedia.org/wiki/Smith%E2%80%93Volterra%E2%80%93Cantor_set - something like that? \u2013\u00a0 Asaf Karagila Oct 2 '10 at 13:40\nIs $m^*$ a particular type of measure? The term is impossible to google, and I don't see it used in Kolmogorov & Fomin. \u2013\u00a0 aschepler Oct 2 '10 at 14:20\nthe general lebesgue measure \u2013\u00a0 anonymous Oct 2 '10 at 15:09\n@Asaf: I have edited the question \u2013\u00a0 anonymous Oct 2 '10 at 15:11\nBy the continuity argument, I think he meant to look at $m(E\\cap [0,y])$ as $y$ increases, which is continuous. \u2013\u00a0 JDH Oct 2 '10 at 17:36\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nSuppose first that $E$ is contained in the closed interval $[a,b]$ and let $E' = [a,b] \\setminus E$. By definition of Lebesgue measure, we can find an open set $G$ containing $E'$ such that $m(G) = m(E') + \\varepsilon = (b - a) - m(E) + \\varepsilon$, where $\\varepsilon$ is small enough. Then $F = [a,b] \\setminus G$ is a compact set contained in $E$ with measure $m(F) = m(E) - \\varepsilon$.\n\nSuppose we have chosen $\\varepsilon$ small enough that $x \\leq m(E)-\\varepsilon = m(F)$. Your intermediate value argument proves the existence of some point $c \\in [a,b]$ such that $m(F \\cap [a,c]) = x$. By the Cantor-Bendixson Theorem, we have a decomposition $F \\cap [a,c] = K \\cup H$ where $K$ is perfect and $H$ is countable. Since $m(H) = 0$, it follows that $m(K) = m(F \\cap [a,c]) = x$.\n\nIf $E$ is unbounded, then pick $[a,b]$ such that $m(E \\cap [a,b]) = m(E) - \\delta$, where $\\delta$ is small enough, and apply the above argument to $E \\cap [a,b]$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166550/solving-non-linear-differential-equation\nText:\nTake the 2-minute tour \u00d7\n\n$\\frac{d}{dt}\\left(\\frac{x'(t)}{x(t)}\\right)=x(t)-x^2(t)$ where $x'(t)=\\frac{d}{dt}x(t)$ What reasoning (if it exists) I can apply to solve this differential equation? Thanks.\n\nshare|improve this question\nA good motivation for Juli\u00e1n's method is to notice that the $\\frac{x'}{x}$ term is just $(\\ln x)'$, so the desired function is the exponential of another. \u2013\u00a0 Eugene Shvarts Jul 4 '12 at 13:50\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nLet $x=e^u$; then $u$ satisfies de differential equation $$ u''=e^u-e^{2u}. $$ Multiply by $u\u00b4$ and integrate once to get $$ \\frac12(u')^2=e^u-\\frac12\\,e^{2u}+C_1. $$ This is a differential equation in separeted variables, whose solution is $$ \\int\\frac{du}{\\sqrt{2\\,e^u-e^{2u}+2\\,C_1}}=\\pm t+C_2. $$\n\nshare|improve this answer\nIf we let $x=e^u$, then $\\dfrac{d}{du}(e^u/e^u)=0=e^u-e^{2u}$. Aren't we thinking of $x$ as a function of $u$? So what does $u''$ mean (does it mean $-\\dfrac{1}{x^2}$)? I'm just curious and wanting to learn. =) Shouldn't one write $(xx''-(x')^2)/x^2=e^u-e^{2u}$? Here on the LHS, I just took the derivative of $x'/x$ with respect to $u$. \u2013\u00a0 math-visitor Jul 6 '12 at 7:21\n@math-visitor $x$ and $u$ are unknowns functions of the independent variable $t$. The definition of $u$ is $x(t)=e^{u(t)}$. \u2013\u00a0 Juli\u00e1n Aguirre Jul 6 '12 at 9:39\nOh, I see. I was speculating that, but I wasn't sure. Thank you Julian! \u2013\u00a0 math-visitor Jul 6 '12 at 18:59\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/682420/find-the-mle-of-bivariate-normal\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $X = (x_{ij})n*2$ follows a bivariate normal distribution $\\mathcal{N}(\\mu, \\sigma^2I)$, where I is the $2\\times 2$ identity matrix. How to find the maximum likelihood estimates of $\\mu$ and $\\sigma^2$? Specifically, how to deal with the determinant part in the density formula of bivariate normal distribution? Thanks!\n\nshare|improve this question\nCan you please explain what you want to mean by $(x_{ij})n*2$? Does it mean a $n\\times 2$ matrix $X$? \u2013\u00a0 Samrat Mukhopadhyay Feb 19 at 18:28\nit's a n*2 matrix, has n rows and 2 columns \u2013\u00a0 user2350622 Feb 19 at 18:37\n\n1 Answer 1\n\nIf $X$ is a $m\\times n$ matrix with $n$ random vectors distributed identically as $\\mathcal{N}(\\mu,\\sigma^2 I_{m\\times m})$, and if the random vectors are independent then you can write the joint distribution of the vectors as $$p(x_1,x_2,\\cdots,\\ x_n)=\\prod_{i=1}^np(x_i)\\\\=\\frac{1}{(2\\pi)^{mn/2} \\sigma^{mn}}\\exp\\left(-\\frac{\\sum_{i=1}^n\\sum_{j=1}^m(x_{ji}-\\mu_{j})^2}{2\\sigma^2}\\right)$$ So, to find the MLE of $\\mu$ and $\\sigma^2$ find the simultaneous solutions of $$\\nabla_{\\mu}p(x_1,x_2,\\cdots,x_n)=0\\\\ \\frac{\\partial p(x_1,x_2,\\cdots,x_n)}{\\partial \\sigma^2}=0$$\n\nshare|improve this answer\nI solved the equations but I ended up getting a strange MLE for sigma^2. I got 1/2*variance of X. \u2013\u00a0 user2350622 Feb 19 at 19:07\nIf by variance you mean the sample variance of $X$, then it is fine. \u2013\u00a0 Samrat Mukhopadhyay Feb 19 at 19:16\nokay! It just seemed to be wired to me because usually MLE variance does not have a 1/2 in front of it \u2013\u00a0 user2350622 Feb 20 at 0:04\nIf you do the math, then you'll see that for the case where you have $m$ samples, a factor of $1/m$ is coming in front of the sample variance. \u2013\u00a0 Samrat Mukhopadhyay Feb 20 at 6:47\nyes but I tried in R and the variance of the samples should be really close to the true sigma. \u2013\u00a0 user2350622 Feb 24 at 1:57\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/95889/cardinality-of-a-certain-set-of-distinct-subsets-of-mathbbn/95913\nText:\nTake the 2-minute tour \u00d7\n\nA recent question here has convinced me that folks here have a warm heart for the foundations of quantum mechanics, so I decided to ask a question that has been bothering me for a while.\n\nQuantum motivation\n\nHardy has proved a theorem saying the the cardinality of the ontic space $\\Lambda$ must always be infinite. As Spekkens put it more clearly, his proof works by making a injection of the set of pure quantum states into the set of distinct subsets of $\\Lambda$. Since the set of pure states is continuous, it follows that $\\Lambda$ must be infinite.\n\nBut the injection isn't exactly onto $\\mathcal{P}(\\Lambda)$, but rather onto a set $D$ of distinct subsets of $\\Lambda$ such that that for no $A,A'\\in D$ is it true that $A \\subset A'$. My question is then: is this additional restriction enough to show that $\\Lambda$ must be continuous? Or is there a countable $\\Lambda$ such that $D$ is uncountable?\n\nQuantum-free question\n\nLet $D$ be a set of distinct subsets of $\\mathbb{N}$ such that for no $A,A'\\in D$ is it true that $A \\subset A'$. What is the maximal cardinality of such a $D$?\n\nThis question seems simple enough, but I haven't been able to answer it.\n\nshare|improve this question\nThe cardinality is the largest possible, $|2^{\\mathbb N}|$. For eample: Identify ${\\mathbb N}$ with ${\\mathbb Q}$, and assign to each real (the range of) a strictly increasing sequence of rationals converging to it. \u2013\u00a0 Andres Caicedo May 3 '12 at 16:21\nYou can have continuum many infinite subsets of $\\mathbb{N}$ such that any two of them are almost disjoint (have finite intersection). \u2013\u00a0 Ramiro de la Vega May 3 '12 at 16:23\nSo the question was in fact simple. Andres, could you please post your comment as an answer so I can accept it? Ramiro, could you please provide an example of your family of subsets of $\\mathbb{N}$? \u2013\u00a0 Mateus Ara\u00fajo May 3 '12 at 16:53\nMateus, the example Andres gave satisfies what I said. \u2013\u00a0 Ramiro de la Vega May 3 '12 at 17:16\n\n3 Answers 3\n\nup vote 8 down vote accepted\n\nA simpler construction, which yields pairwise incomparable sets (but not almost disjoint sets):\n\nFor any subset $A\\subseteq \\mathbb N$, let $X_A:= \\{ 2n: n\\in A\\}$, and let $Y_A:= \\{ 2n+1: n\\notin A\\}$, and let $Z_A:= X_A \\cup Y_A$.\n\nThen the family of all $Z_A$ has size continuum, and $Z_A \\subseteq Z_B$ implies both\n\n  \u2022 $A\\subseteq B$ (because of $X_A\\subseteq X_B$)\n  \u2022 and also $B \\subseteq A$ (because $Y_A\\subseteq Y_B$),\n\nhence $A=B$. So the $Z_A$ are pairwise incomparable.\n\n(A similar construction works also for larger cardinalities; a set of size $\\kappa$ has $2^\\kappa$ many pairwise incomparable subsets; here I use a bijection between $\\kappa$ and $\\kappa\\times 2$.)\n\nshare|improve this answer\nSince I only need pairwise incomparable sets and your construction is simpler, I'm going to accept your answer. \u2013\u00a0 Mateus Ara\u00fajo May 4 '12 at 15:02\n\nMateus, say that a family ${\\mathcal F}$ of infinite subsets of ${\\mathbb N}$ is almost disjoint iff $A\\cap B$ is finite for any distinct sets $A,B$ in ${\\mathcal F}$.\n\nThe answer to your question is that there is a family as you require of size $|{\\mathcal P}({\\mathbb N})|=|{\\mathbb R}|$, which is of course largest possible. In fact, one can find an almost disjoint such family.\n\nThere are several ways of exhibiting an example. I am fond of this construction: Identify ${\\mathbb N}$ with ${\\mathbb Q}$, and assign to each real $r$ (the range of) a strictly increasing sequence of rationals converging to $r$.\n\nAnother way is to identify ${\\mathbb N}$ with the nodes of the binary tree $\\{0,1\\}^{<\\mathbb N}$ whose elements are finite sequences of $0$s and $1$s. Now, each infinite sequence of $0$s and $1$s (and there are $|\\{0,1\\}^{\\mathbb N}|=|{\\mathcal P}({\\mathbb N})|$ many such sequences) can be thought of as an infinite branch through this tree. Associate to it the collection of its initial segments (its \"path\"). This uniquely identifies the branch, and any two different paths eventually diverge, so they have finite intersection.\n\nIf $|X|=\\kappa$ is infinite, the question of the size of a maximal almost disjoint family of subsets of $X$, where we now require $|A\\cap B|<\\kappa$ for distinct $A,B$ in the family, is more delicate if $2^{<\\kappa}>\\kappa$ (otherwise the second argument above adapts to give a family of size $2^\\kappa$). For example, (Baumgartner showed that) it is independent of the usual axioms of set theory with choice whether there is a family of almost disjoint subsets of $\\omega_1$ of size $2^{\\omega_1}$.\n\nshare|improve this answer\nBeautiful answer, thank you! Fortunately the physical question does not depend on the general case =) \u2013\u00a0 Mateus Ara\u00fajo May 3 '12 at 21:26\n\nHere's a way of showing the existence of a family $\\mathcal{D}$ of sets with $\\vert \\mathcal{D}\\vert=2^{\\aleph_0}$ and $\\forall A\\not=A'\\in\\mathcal{D}(A\\not\\subseteq A')$, using computability theory:\n\nSay that a set $A\\subseteq \\mathbb{N}$ is introreducible if it is infinite and is computed by all of its infinite subsets (i.e., $\\forall B\\subseteq A, B\\ge_T A)$.\n\nClaim: for all $X\\subseteq\\mathbb{N}$, there is an introreducible set $Y\\subseteq \\mathbb{N}$ with $Y\\equiv_T X$.\n\nProof: Assume WLOG that $X$ is infinite (otherwise $X$ is computable, and $Y=\\mathbb{N}$ fulfills the claim), and write $X=\\lbrace x_0 < x_1 < . . .\\rbrace $. Let $Y=\\lbrace \\langle x_0, x_1, . . . , x_n\\rangle: n\\in\\mathbb{N}\\rbrace$. Clearly $Y$ is introreducible and $Y\\equiv_T X$.\n\nNow it is known that there exist antichains of size $2^{\\aleph_0}$ in the Turing degrees (i.e., families $\\mathcal{C}=(X_r)_{r\\in\\mathbb{R}}$ with $X_r\\not\\le_T X_s$ whenever $r\\not=s$). Let $Y_r$ be an introreducible set of the same degree as $X_r$ for each $r\\in\\mathbb{R}$. Then clearly $\\mathcal{D}=\\lbrace Y_r: r\\in\\mathbb{R}\\rbrace$ is a family of sets of size $2^{\\aleph_0}$ no one of which is a proper subset of another.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/99007/rate-of-convergence-of-series-of-squared-prime-reciprocals\nText:\nTake the 2-minute tour \u00d7\n\nIt is well known that $\\sum_{p \\text{ prime}} \\frac{1}{p}$ diverges, and in fact - it behaves like log of the harmonic series: $$ \\sum_{p \\le x} \\frac{1}{p} = \\log \\log x + O(1). $$ It is also well known that $\\sum\\limits_{p \\text{ prime}} \\frac{1}{p^2}$ converges. What is known about the rate? Letting $C = \\sum\\limits_{p \\text{ prime}} \\frac{1}{p^2}$, what can be said about $C - \\sum\\limits_{p \\le x} \\frac{1}{p^2}$?\n\nI am reading an article (a survey of Artin's Primitive Root Conjecture - which follows from the GRH). I am trying to understand what are the condition on functions $f_1\\le f_2$ tending to infinity in order that $$ \\sum_{f_1(x) \\le p \\le f_2(x)} \\frac{1}{p^2} = O\\left(\\frac{1}{\\log x}\\right). $$ Of course I can take $f_1(x) = \\log\\log\\log x$, $f_2(x) = \\log\\log x$, but I want the general conditions.\n\nshare|improve this question\nThe sum from $x$ to infinity of $1/p^2$ is bounded by the sum from $x$ to infinity of $1/n^2$ which, by comparison with the integral, is on the order of $1/x$. 29% accept rate - do you understand the value of accepting answers to your questions here? \u2013\u00a0 Gerry Myerson Jan 14 '12 at 23:20\n\n1 Answer 1\n\nup vote 6 down vote accepted\n\nLets rearrange the sum $C-\\sum_{p\\leq x}\\frac{1}{p^{2}}=\\sum_{p>x}\\frac{1}{p^{2}}$. Using integration by parts this is $$\\sum_{p>x}\\frac{1}{p^{2}}=\\int_{x}^{\\infty}\\frac{1}{t^{2}}d\\left(\\pi(t)\\right)=\\frac{\\pi(t)}{t^{2}}\\biggr|_x^\\infty+2\\int_{x}^{\\infty}\\frac{\\pi(t)}{t^{3}}dt.$$ Using the prime number theorem, that is the asymptotic for $\\pi(x),$ you can deduce that the quantity on the right hand side is $\\sim\\frac{1}{x\\log x},$ which is your rate of convergence.\n\nJust worth noting, this is exactly what we would expect. The tail of the sum over all integers has size $\\frac{1}{x}$, that is $\\sum_{n>x} \\frac{1}{n^2}\\sim \\frac{1}{x}$ and the primes occur with density $\\frac{1}{\\log n}$ around $n$, so we would expect the tail of the sum to be of size $\\frac{1}{x\\log x}$. Partial summation/integration allows to prove this.\n\nEdit: Replaced $\\asymp$ with $\\sim$, since as pointed out by Greg Martin in the comments, the Prime Number Theorem is strong enough to yield this/\n\nshare|improve this answer\nUsing the prime number theorem actually gives an asymptotic formula for the tail of the series, not just the order of magnitude, right? \u2013\u00a0 Greg Martin Jan 22 '12 at 10:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/136831/factorial-number-of-digits\nText:\nTake the 2-minute tour \u00d7\n\nIs there any neat way to solve how many digits the number $20!$ have? I'm looking a solution which does not use computers, calculators nor log tables, just pen and paper.\n\nshare|improve this question\nI suspect Stirling's approximation will help. \u2013\u00a0 David Mitra Apr 25 '12 at 15:43\nThe simplest way is just to compute $20!$. $20$ is small enough that this shouldn't take too much time (or paper). \u2013\u00a0 Chris Eagle Apr 25 '12 at 15:45\nSee \"D. FACTORIALS OF LARGE NUMBERS\" in groups.google.com/group/sci.math/msg/d12962e3af2c74b7 \u2013\u00a0 Dave L. Renfro Apr 25 '12 at 15:45\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAs a rough approximation, multiplying an $n$-digit number by an $m$-digit number yields a result with about $n+m$ digits. So the numbers from 2 to 9 are all 1-digit numbers. From 10 to 20 are all 2-digit numbers. That suggests we should have about 18 digits or so.\n\nWolfram|Alpha claims that $20! = 2.4 \\times 10^{18}$. Not far off! :-D\n\nshare|improve this answer\n(Exponents of more than one character require {} to render properly) \u2013\u00a0 The Chaz 2.0 Apr 25 '12 at 16:00\nApparently I fail basic math. If you actually count 2 for all of the 2-digit numbers, you come up with 28, which is quite a way out. sigh \u2013\u00a0 MathematicalOrchid Apr 25 '12 at 20:34\n@TheChaz Thanks for that... \u2013\u00a0 MathematicalOrchid Apr 25 '12 at 20:35\n\nI come from a background in computers, so here's my two cents. Taking the logarithm to the base 10 of n!. If the log comes out to be x, it is not hard to see that the number of digits must be the lowest integer greater than or equal to x, i.e, $floor(x)+1$. Now the question comes down to approximating the $log(n!)$ It is possible to prove by induction that n! lies between $(\\frac{n}{2})^n$ and $(\\frac{n}{3})^n$. Thus the log(n!) lies between $nlog(\\frac{n}{2})$ and $nlog(\\frac{n}{3})$. We can get a pretty tight bound if we used log tables for log(20/3), but as you have disallowed that, using the upper limit(which becomes log(10) = 1) will do quite nicely too. The answer comes to 20*log(10) = 20, which should tell you that the expected number of digit is about 19 or 20.(Since 20 is only the upper bound). And 19 happens to be the answer.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/607793/let-f-be-a-field-langle-x-y-rangle-is-a-maximal-ideal-of-fx-y/607799\nText:\nTake the 2-minute tour \u00d7\n\nLet $F$ be a field. Prove that $\\langle X,Y\\rangle$ is a maximal ideal of $F[X,Y]$.\n\nshare|improve this question\nHi: I notice in the past several posts you're in the habit of just posting problem statements. To get better help, you should include whatever partial progress you've made, and it would be better if you phrased the post as a question and not as an imperative task. Posters who persist using this pattern often experience a backlash of downvotes, closures, and can become ignored. Don't let that happen: spend a little more time on your posts! \u2013\u00a0 rschwieb Dec 15 '13 at 14:15\nAn small add to the above comment: you also didn't accept (and probably upvote) any answer so far. Although this is not mandatory, it is however the best way to show your gratitude to the answerers. \u2013\u00a0 user89712 Dec 15 '13 at 16:19\n\n3 Answers 3\n\nHint: The following result is fundamental and you should always keep it in mind:\n\nIf $R$ is a commutative ring and $P$ is an ideal in $R$, then the quotient ring $R/P$ is a field if and only if $P$ is a maximal ideal.\n\nshare|improve this answer\nI can think of a few situations when having this in mind would be considered strange, or maybe even inappropriate. ;) \u2013\u00a0 tomasz Dec 15 '13 at 13:42\nIs F[X,Y]/<X,Y> a field? I dont know. \u2013\u00a0 EuReka Dec 15 '13 at 13:43\nYou should compute that quotient. Hint: you are expecting to get a field... what object is a field in your hypothesis? \u2013\u00a0 Abramo Dec 15 '13 at 13:45\n@EuReka : Are you familiar with quotient-ing a ring by some ideal? \u2013\u00a0 Praphulla Koushik Dec 15 '13 at 14:08\nnnnnnnnnnnnnnnnnnnnnot getting. plz explain. \u2013\u00a0 EuReka Dec 15 '13 at 14:09\n\nI am sorry to say this but it would be fruitful if you can identify definitions of terms you are using...\n\nBy $F[X]/(X)$ we mean $X$ is zero in $F[X]$, we would not have $X$ terms in $F[X]$..\n\nWhat is $F[X]$??\n\nCollection of all polynomials with coefficients in $F$\n\nIf $X=0$ then what would we left with?\n\n$F[X]=\\{a_0+a_1X+a_2X^2+\\dots+a_nX^n : n\\in \\mathbb{N}; a_i\\in F\\}$\n\nNow what would be $F[X,Y]$??\n\nwhat would be result if we see $(X,Y)=0$ in $F[X,Y]$\n\nAs $X,Y$ are independent we would then have $X=0,Y=0$ when we say $(X,Y)=0$\n\nSo, Now what would we will be left with when we say $F[X,Y]/(X,Y)$??\n\nI would prefer not to interrupt in some one else answer..\n\nHope this helps you some how...\n\nBefore commenting anything Please read what do we mean by quotient..\n\nGood luck!\n\nshare|improve this answer\n\nWithout using quotient operations:\n\nLet $I$ be an ideal of $F[X,Y]$ containing $X$ and $Y$. Let $P$ be in $I$. Then $P = \\sum_{n\\geq 0, m\\geq 0} a_{nm} X^n Y^m$. So $P = a_{00} + \\sum_{m \\geq 1} a_{0m} Y^m + \\sum_{n \\geq 1} a_{n0}X^n + \\sum_{n \\geq 1, m\\geq 1} a_{nm} X^n Y^m$.\n\nThe second term is in the ideal generated by $Y$, the third in the ideal generated by $X$ and the fourth in both. Since $I$ contains these ideals, it shows that $a_{00} \\in I$. If all $P$ in $I$ have $a_{00} = 0$, then $I$ is the ideal generated by $X$ and $Y$. If one $P$ has $a_{00} \\neq 1$, then $a_{00}$ is an invertible and belongs to $I$, showing that $I = F[X,Y]$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/11872/is-nth-root-of-2-an-irrational-number?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\n$a^{1/2}$ is either an integer or an irrational number.\n\nWill every $n^{th}$ root of $2$ be an irrational number? If yes, how can I prove that?\n\nshare|improve this question\n\nmarked as duplicate by Arturo Magidin, Qiaochu Yuan, \uff2a. \uff2d., Aryabhata, Pete L. Clark Nov 26 '10 at 20:05\n\n\nHint: Fermat's last theorem comes to mind when you want to prove it for n>2. Then proof it for n=2 and you got it. \u2013\u00a0 Max Muller Nov 25 '10 at 20:39\n@Max: pretty much the worst way to do this problem... \u2013\u00a0 Qiaochu Yuan Nov 26 '10 at 1:09\n@Qiaochu: I believe there was a mention of that in the \"mosquito-nuking\" thread in MO... \u2013\u00a0 \uff2a. \uff2d. Nov 26 '10 at 1:11\nI think that the most important thing is that the mosquito, bacteria or whatever is dead because of the FLT-nuke. \u2013\u00a0 Max Muller Nov 26 '10 at 17:58\nLook, @Bill, we're trying to eradicate an exceedingly ambiguous tag here... I can see why you'd add abstract-algebra, but your removal of algebra-precalculus sounds iffy to me. But hey, you're the \"expert\", good sir. \u2013\u00a0 \uff2a. \uff2d. Jan 3 '12 at 2:53\n\n2 Answers 2\n\nYes. In fact, for every integer $k$ and every $n\\gt 1$, the $n$th root of $k$ is either an integer or irrational.\n\nOne way to prove it is to use exactly the same idea as for proving the square root of $2$ is irrational: suppose $\\sqrt[n]{k} =\\frac{p}{q}$, with $p$ and $q$ integers, relatively prime. Then $q^nk = p^n$. Now think about the prime factorizations: every prime that divides $q$ must divide $p$, but $p$ and $q$ are relatively prime, so $q=1$. That means that you must have $k=p^n$ with $p$ an integer. That is, the only way for the $n$th root of $k$ to be a rational is if $k$ is an $n$th power of an integer.\n\nOr you can use the Rational Root Test: an $n$th root of $k$ is a root of the polynomial $x^n - k$. But a rational root of a polynomial with integer coefficients that is written in lowest term $\\frac{p}{q}$ must have denominator $q$ that divides the leading coefficient and numerator $q$ that divides the constant coefficient. So any rational root of $x^n-k$ must be an integer.\n\nGetting this back to your question, since $2$ is not an $n$th power of an integer for any $n\\gt 0$, $\\sqrt[n]{2}$ is not a rational for any integer $n\\gt 0$.\n\nshare|improve this answer\n\nIf $\\rm\\ \\sqrt[n] c = a/b,\\ \\ gcd(a,b) = 1\\ $ then $\\rm\\ c\\ b^n = a^n\\ \\Rightarrow \\ b\\:|\\: a^n\\:.\\: $ But $\\rm\\ gcd(a,b) = 1\\ \\Rightarrow\\ gcd(a^n,b) = 1\\ $ by Euclid's Lemma. Thus $\\rm b = 1\\ $ hence $\\rm\\:\\ c \\ =\\ a^n\\:.\\ $ In particular $\\rm\\ c = 2\\ \\Rightarrow\\ n = 1\\:.$\n\nThere are many possible variations on such irrationality proofs, e.g. using the Rational Root Test or directly using Unique Factorization of integers, or using the principality of denominator ideals. Perhaps the most elegant is to employ Dedekind's notion of the conductor ideal - which yields a one-line proof that a $\\rm PID$ is integrally closed, i.e. satisfies the monic case of the rational root test.\n\nshare|improve this answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/243062/basis-for-a-uncountable-product-hilbert-space\nText:\nTake the 2-minute tour \u00d7\n\nLet $(H_\\alpha)_{\\alpha\\in A}$ be an uncountable family of Hilbert spaces. (the countable case is discussed here: Basis for a product Hilbert space.)\n\nLet H be the set of tuples $x = (x)_{\\alpha\\in A} \\in \\prod_{\\alpha\\in A} H_\\alpha$ with the property that $$\\|x \\| ^2 =\\sum_{\\alpha\\in A} \\| x_\\alpha \\| _{H_\\alpha}^2 <\\infty.$$ Show that this is an hilbert space. Prove that H is non-separable and determine an orthonormal basis in this space. The triangle inequality for the countable case is discussed here: Countable family of Hilbert spaces is complete. The positivity and Homogenity seems obvious.\n\nHow do we find the basis and is the space always non-separable because its uncountable?\n\nshare|improve this question\nWhat exactly do you mean by $H_{1},...,H_{n}$ being an uncountable family? At the moment it looks like a finite family of $n\\in\\mathbb{N}$ many members. Also if $\\{H_{i}\\}_{i\\in I}$ is such that $I$ is uncountable, then how do you define a tuple $(x_{1},x_{2},...)\\in\\Pi \\,H_{i}$, as it is indexed by $\\mathbb{N}$? \u2013\u00a0 Thomas E. Nov 23 '12 at 10:07\nNote that in particular, at most countably many terms $x_{\\alpha}$ are non-zero. \u2013\u00a0 Patrick Da Silva Nov 23 '12 at 10:12\nSorry for that, I edited it now. \u2013\u00a0 Johan Nov 23 '12 at 10:12\nPatrick: Yes so I understand it to, What happens to the separability then? And how does that affect the basis? \u2013\u00a0 Johan Nov 23 '12 at 10:14\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYou can define an inner product on this space by letting $$ ( (x_{\\alpha} )_{\\alpha \\in A}), (y_{\\alpha})_{\\alpha \\in A}) \\overset{def}= \\sum_{\\alpha \\in A} (x_{\\alpha},y_{\\alpha})_{H_{\\alpha}}. $$ By assumption, there are only at most countably many terms in this sum. Note that if you see those $A$-tuples as subsets of the Hilbert space where you only take the product over those Hilbert spaces where you're currently working with index $\\alpha$ such that $x_{\\alpha},y_{\\alpha}\\neq 0$, the Cauchy-Schwarz inequality holds, so that this sum is well defined. You can see that it defines an inner product and that everything works fine.\n\nOf course, the issue with separability is the uncountable amount of Hilbert spaces you're taking the product with. A countable subset is clearly not dense if the product is uncountable, since for every countable subset $\\{ (x_{n_{\\alpha}})_{\\alpha \\in A} \\}$of $H$, you can find an uncountable set $B \\subseteq A$ of indices over which every element of your subset will satisfy $x_{n_{\\beta}} = 0$ for all $\\beta \\in B$, which shows $\\{x_n\\}$ is not dense.\n\nThe reason for the existence of $B$ is simple : since every element $x_n$ will vanish on the complement of a countable set of indices $\\alpha \\in A$, if this set where $x_n$ does not vanish is called $B_n$, then $B_n$ is countable, hence so is $\\bigcup_n B_n$, i.e. the set of indices where at least one $x_n$ has a non-zero component. Therefore, outside this countable set, all the $x_n$'s vanish.\n\nAs a basis, if $\\mathcal E_{\\alpha}$ is a basis of $H_{\\alpha}$, define $\\tilde e_{\\alpha_0}$ to be the tuple that is zero in every $\\alpha$-component but is $e_{\\alpha_0}$ in the $\\alpha_0$-component. Using the above-defined inner product you see that you can project on those and get your basis.\n\nHope that helps,\n\nshare|improve this answer\nvery good! thanks! \u2013\u00a0 Johan Nov 23 '12 at 13:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247808/prove-that-m-n-leq-3n-for-all-n-in-bbbz?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nGiven that $m_1= 2$ and $m_2 = 9$ and that $m_n = 2m_{n-1} + 3m_{n-2}$ for $n \\geq 3$\n\nThis is what I've done so far.\n\n$3^{n+1}$ = $3^n \\cdot 3$\n\n$3^{n+1} \\geq 3 \\cdot (2m_{n-1} + 3m_{n-2})$\n\n$3^{n+1} \\geq 6m_{n-1} + 9m_{n-2}$\n\n$m_{n+1} = 7m_{n-1} + 6m_{n-2}$\n\nProve by induction.\n\nshare|improve this question\n\n2 Answers 2\n\nBy induction:\n\n$$m_{n+1}:=2m_n+3m_{n-1}\\leq 2\\cdot 3^n+3\\cdot 3^{n-1}=3^n(2+1)=3^{n+1}$$\n\nshare|improve this answer\nI might add, since you (@Eric) seem to be learning to do proofs, that @DonAntonio used strong induction in his proof. \u2013\u00a0 anegligibleperson Nov 30 '12 at 4:18\nUmm ok... i would have never thought of that \u2013\u00a0 Eric Nov 30 '12 at 4:23\nIs it really strong induction? He didn't check for P(1) and P(2). \u2013\u00a0 Eric Nov 30 '12 at 4:24\nYes, it is @Eric, and I didn't check those two first because they're obvious from the given data. \u2013\u00a0 DonAntonio Nov 30 '12 at 4:35\n@Eric: In practice you should make it automatic to think of strong induction and at the induction step simply assume that the proposition is true for all earlier values of $n$; if it turns out that you don\u2019t actually need all of that assumption, no harm is done. (I think that the usual textbook approach of carefully distinguishing between strong and ordinary induction does the student no favor in the long run: they\u2019re simply a special case and a very special case of the general notion of induction, and the sooner you can see them as at heart the same idea, the better off you\u2019ll be.) \u2013\u00a0 Brian M. Scott Nov 30 '12 at 5:18\n\nHint $\\ $ Both $\\:3^n$ and $\\rm\\:m_n$ are solutions of $\\rm\\:f_{n+2} = 2\\, f_{n+1} + 3\\, f_n,\\:$ therefore, by linearity, their difference $\\rm\\:f_n = 3^n\\!-m_n\\:$ is also a solution. But it is straightforward to prove by induction that $\\rm\\:f_1,f_2\\ge 0\\:$ $\\Rightarrow$ $\\rm\\:f_n \\ge 0,\\:$ for all $\\rm\\:n\\ge 1,\\:$ because $\\rm\\:f_n,f_{n+1} \\ge 0\\:$ $\\Rightarrow$ $\\rm\\:f_{n+2} = 2\\,f_{n+1}+3\\,f_n\\ge 0.\\:$ Therefore $\\rm\\: f_n = 3^n\\! - m_n \\ge 0,\\:$ so $\\rm\\:3^n \\ge m_n\\:$\n\nRemark $\\ $ Note how reformulating it this way makes the essence of the matter obvious, viz. if the recurrence is an increasing function of the prior values, then if the sequence starts with initial values $\\ge 0$ then it must remain $\\ge 0$ for all greater values, since each successive step is increasing.\n\nshare|improve this answer\nWhen you say \"by linearity, their difference is also a solution\", can't you also say that $f_n = m_n - 3^n$ is also a solution by the same argument? In that case, won't the conclusion $m_n \\ge 3^n$ also be correct? Am I missing something here? \u2013\u00a0 Paresh Nov 30 '12 at 7:14\n@Paresh I don't know what the \"same argument\" refers to. If you mean that one could replace the appeal to linearity by brute force verification that $\\rm\\,3^n - m_n\\,$ is a solution then, yes, one could do that, but it amounts to the same thing, with the higher-level (linear) conceptual structure stripped away. \u2013\u00a0 Bill Dubuque Nov 30 '12 at 7:32\nWell, this is probably a stupid question. But I was thinking that by \"linearity\", you mean $f_n = \\alpha 3^n + \\beta m_n$ is also a solution. Which probably means $m_n - 3^n$ is also a solution. But, as you show, $f_n \\ge 0$, but then that would mean $m_n \\ge 3^n$. Why am I getting this contradiction? Sorry if I making some elementary mistake. \u2013\u00a0 Paresh Nov 30 '12 at 7:49\nYes, that's what linearity means. But the proof shows that if a solution $\\rm\\,f_n\\,$ has initial conditions $\\rm\\:f_1,f_2 \\ge 0\\:$ then $\\rm\\,f_n$ remains $\\ge 0$ for all $\\rm\\:n\\ge 1.\\:$ This is true for the solution $\\rm\\:f_n = 3^n - m_n\\:$ since $\\rm\\:f_1 = 1,\\, f_2 = 0,\\:$ but it is false for $\\rm\\,\\hat f_n = -f_n = m_n-3^n\\:$ since $\\rm\\:\\hat f_1 = -f_1 = -1\\:$ is not $\\ge 0.\\ \\ $ \u2013\u00a0 Bill Dubuque Nov 30 '12 at 8:22\nAah ... got it. Thank you! \u2013\u00a0 Paresh Nov 30 '12 at 9:31\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/9609/neutrino-speed-in-supernova\nText:\nTake the 2-minute tour \u00d7\n\nI've read that neutrinos in supernova can be affected by \"neutrino refraction.\" Is this analagous to the refraction of light, and if so, is the speed of these neutrinos similarly reduced from their near c speeds via this index of refraction?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nFirst, check this reference on Wikipedia.\n\nNow, it is generally true that the \"speed\" (or, more accurately, the dispersion relation) of any particle is affected by a medium, where it travels. Well, of course, if the particle interacts with the medium.\n\nFor neutrinos the \"slowing down\" itself is absolutely negligible even in very dense media. What is important is that interaction of the electron neutrino with ordinary matter is much stronger, so it affects the patterns of neutrino oscillations -- the effect is known as MSW effect.\n\nFinally, this is not particularly related to supernovae. The idea behind interest in supernovae is that during an explosion there are a lot of neutrinos so one must account for the \"neutrino matter\" and its effect on oscillations as well.\n\nshare|improve this answer\nThank you Kostya for the very helpful explaination. \u2013\u00a0 Michael Luciuk May 9 '11 at 11:28\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/53855/an-l0-khintchine-inequality?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $\\epsilon_1,\\epsilon_2,\\ldots$ are IID random variables with the Bernoulli distribution $\\mathbb{P}(\\epsilon_n=\\pm1)=1/2$, and $a_1,a_2,\\ldots$ is a real sequence with $\\sum_na_n^2=1$. Letting $S=\\sum_n\\epsilon_na_n$, the question is whether there exists a constant $c > 0$, independent of the choice of $a$, with $$ \\mathbb{P}(\\vert S\\vert\\ge1)\\ge c.\\qquad\\qquad{\\rm(1)} $$ That is, I am interested in finding a bound on the probability of the sum being within one standard deviation of its mean. If true, this represents a particularly sharp version of the $L^0$ Khintchine inequality. Considering the example with $a_1=1$ and all other $a_i$ set to zero, for which $\\mathbb{P}(\\vert S\\vert > 1)=0$, it is necessary that the inequality inside the probability in (1) is not strict. Also, considering the example with $(a_1,a_2,a_3)=(1/\\sqrt2,1/2,1/2)$, it can be seen that $c\\le1/4$. I wonder if it is possible to construct further examples showing that $c$ must, in fact, be zero?\n\nFor any $0 < u < 1$, it is easy to find a bound $$ \\mathbb{P}(\\vert S\\vert > u)\\ge c_u $$ for $c_u > 0$ a constant independent of $a$. Considering the case with $a_1=a_2=1/\\sqrt{2}$ and all other $a_i$ set to zero, it is clear that $c_u \\le 1/2$. In fact, it can be shown that $c_u=(1-u^2)^2/3$ will suffice (see my answer to this other MO question), but $c_u$ decreases to zero as $u$ goes to $1$, so this does not help with (1). Combining the Paley-Zygmund inequality with the optimal constants in the $L^p$-versions of the Khintchine inequality for $p > 0$ (see ref. 1 or 2) it is possible to give improved values for $c_u$, but it still tends to zero as $u$ goes to 1.\n\nMy apologies if this is either obvious or some well-known fact that I have missed, but I could not find any reference for it. This question is something that I originally thought about while writing up some notes on stochastic integration (posted on my blog), as the $L^0$-version of the Khintchine inequality can be used to prove the existence of the stochastic integral. However, it is not necessary to have something as strong as (1) in that case. More recently, it came up again while answering this MO question.\n\n\n  1. Haagerup, The best constants in the Khintchine inequality, Studia Math., 70 (3) (1982), 231-283.\n  2. Nazarov & Podkorytov, Ball, Haagerup, and distribution functions, Preprint (1997). Available from Fedja Nazarov's homepage.\nshare|improve this question\n${\\rm P}(|S| \\geq 1) = 2[1-{\\rm P}(S \\lt 1)]$; ${\\bf Problem 10} \\star$ in math.leidenuniv.nl/~naw/home/ps/pdf/2008-2.pdf (perhaps open) asks for the probability ${\\rm P}(S \\lt 1)$. \u2013\u00a0 Shai Covo Jan 31 '11 at 11:08\nConsidering $a=(1,1,1,1,1,1)/\\sqrt{6}$ gives a probability of $7/2^5=0.21875$. Wonder how close that is to optimal? \u2013\u00a0 George Lowther Jan 31 '11 at 12:52\n\n1 Answer 1\n\nup vote 12 down vote accepted\n\nOK. Here's a proof that $c > 0.002$. No doubt it can be substantially improved. We can assume the $a_i$ are arranged in decreasing order. Write $a$ for $a_1$.\n\nIf $a\\ge 1/2$, let $X=a_1\\epsilon_1$ and $Y=(1-a^2)^{-1/2}(a_2\\epsilon_2+\\ldots+a_n\\epsilon_n)$ so that $S=X+\\sqrt{1-a^2}Y$. Notice that $Y$ is of the form so that the inequality in the question applies.\n\nNow $\\mathbb P(|\\sqrt{1-a^2}Y|\\ge 1-a)=\\mathbb P(|Y|\\ge \\sqrt{\\frac{1-a}{1+a}})\\ge \\left(1-\\frac{1-a}{1+a}\\right)^2/3=4a^2/(3(1+a)^2)$. Since $a\\ge 1/2$, this exceeds 4/27, so that provided $\\epsilon_1$ has the same sign as $Y$, the sum is at least 1. This occurs with probability at least 2/27.\n\nIf on the other hand $a<1/2$ then we have $a_i^2<1/4$ for each $i$. In particular there exists a partition of $\\{1,\\ldots,n\\}$ into two sets $A$ and $B$ such that $3/8\\le \\sum_{i\\in A}a_i^2\\le \\sum_{i\\in B}a_i^2\\le 5/8$. Let $\\alpha^2=\\sum_{i\\in A}a_i^2$ and $\\beta^2=\\sum_{i\\in B}a_i^2$. Let $X=\\sum_{i\\in A}(a_i/\\alpha)\\epsilon_i$ and $Y=\\sum_{i\\in B}(a_i/\\beta)\\epsilon_i$. Then $\\mathbb P(|X|\\ge 3/4)\\ge 49/768$ by the given inequality. Similarly $\\mathbb P(|Y|\\ge 3/4)\\ge 49/768$. The probability that they both exceed $3/4$ and have the same sign is at least $1/2(49/768)^2$. If this is the case $|S|=\\alpha |X|+\\beta |Y|\\ge (3/4)(\\alpha+\\beta)$. In the worst case $\\alpha=\\sqrt{3/8}$ and $\\beta=\\sqrt{5/8}$, but even in this case the right side exceeds 1.\n\nshare|improve this answer\nThat's fantastic, thanks! Worked out easier than I expected. \u2013\u00a0 George Lowther Jan 31 '11 at 12:20\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/133636/proof-of-the-area-of-a-right-triangle\nText:\nTake the 2-minute tour \u00d7\n\nProve that every right triangular region is measurable because it can be obtained as the intersection of two rectangles. Prove that every triangular region is measurable and its area is one half the product of its base and altitude.\n\nI'm supposed to prove the above statement from the following area axioms:\n\nWe assume that there exists a class of measurable sets in the plane and a set function $a$ whose domain is $M$ with the following properties:\n\n1) $a(S) \\geq 0$ for each set $S$ in $M$.\n\n2) If $S$ and $T$ are two sets in $M$ their intersection and union is also in $M$ and we have: $a(S \\cup T) = a(S) + a(T) - a(S \\cap T)$\n\n3)If $S$ and $T$ are in $M$ with $S \\subseteq T$ then $T \u2212 S$ is in $M$ and $a(T \u2212 S) = a(T) \u2212 a(S)$.\n\n4) If a set $S$ is in $M$ and $S$ is congruent to $T$ then $T$ is also in $M$ and $a(S) = a(T)$.\n\n5) Every rectangle $R$ is in $M$. If the rectangle has length $h$ and breadth $k$ then $a(R) = hk$.\n\n6) Let $Q$ be a set enclosed between two step regions $S$ and $T$ so that $S \\subseteq Q \\subseteq T$. If there is a unique number $c$ such that $a(S) \\leq c \\leq a(T)$ for all such step regions $S$ and $T$, then $a(Q) = c$.\n\nI can see from axiom 2 that the intersection of 2 rectangles is measurable, but I can't think of how to use that to get that the area of the intersection is $bh \\over 2$.\n\nshare|improve this question\nHint: the rectangles will not have parallel sides. Once you show that half of a rectangle is measurable, the other half will be too, and as both regions are congruent, the formula for the area will follow from 4 and 5 \u2013\u00a0 Barry Smith Apr 18 '12 at 21:39\n\n2 Answers 2\n\nLet $ABC$ be a right triangle, with right angle at $C$. Form two rectangles $R$ and $S$ as follows.\n\nRectangle $R$ is the natural one with $AB$ as a diagonal that splits $R$ into two halves, with $\\triangle ABC$ as one of the halves.\n\nRectangle $S$ has $AB$ as one side, and the side parallel to $AB$ passes through $C$.\n\nThe intersection of $R$ and $S$ is $\\triangle ABC$.\n\nTo decompose any triangle into two right triangles with uninteresting intersection, there is a natural construction. Be a little careful in describing the construction.\n\nshare|improve this answer\nWell, that's the first piece of the problem nicely done. \u2013\u00a0 Gerry Myerson Apr 19 '12 at 0:13\n\nFor the second piece of the problem, can you see that every triangle is the union of two right triangles?\n\nEDIT: For the last part of the problem, a right triangle is half a rectangle, so properties 2) and 5) should get you the formula for right triangles. Then as noted every triangle is a union of two right triangles, so property 2 and the result for right triangles should get you the result for all triangles.\n\nshare|improve this answer\nIf a base angle is obtuse, the triangle is also the difference of two right triangle. \u2013\u00a0 marty cohen Apr 19 '12 at 2:27\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/282743/what-are-the-probabilities-in-this-particular-spin-off-of-blackjack\nText:\nTake the 2-minute tour \u00d7\n\nA few of my friends are playing on a gaming server where this game exists. I was curious about the probabilities in it but i was unable to derive them. Any help would be MUCH appreciated. Note: For this problem, please assume that /dice is absolutely random. It is generated by a computer using a pseudo random code but i would appreciate it if that didnt work its way in here.\n\nAs for the game itself, here is how it works, there are two people who play the game, The Player and The Dealer.\n\nAs the game begins, the player uses /dice as many times as he wants(Each /dice has 6 outcomes which have absolutely equal chances). The player then dices as many times as he wants but his total must not go over 21.\n\nFor example when the total reaches 19, it would be a good choice to stop. If he gets 22, 23 or so on then he automatically loses.\n\nOnce he has \"stayed\" at a particular amount the dealer then rolls. His aim is to ensure that he gets a number higher than the player. If he succeeds, he wins. If he trips and gets 22, 23 or so on then he loses.\n\nNow what is the probability that the dealer will win? What is the probability that the player will win? On a average game what is the probability of a 21 being rolled.\n\nshare|improve this question\nJust to be clear, that unless the the player went bust, the dealers strategy is always to roll until he has higher number then the player so that ties are impossible? (so that if the players rolls 21 the dealer always loses) \u2013\u00a0 Shard Jan 20 '13 at 13:54\nWhat's the significance of the slash in front of \"dice\"? \u2013\u00a0 joriki Jan 20 '13 at 14:18\nWhat do you mean by \"On a average game what is the probablity of a $21$ being rolled.\"? How does this differ from \"what is the probablity of a $21$ being rolled?\"? \u2013\u00a0 joriki Jan 20 '13 at 14:40\n1 - In case of a tie, the player re-rolls. I am sorry i forgot to mention that. 2- / signifies a command, i should of probably mentioned that. 3 - Both are one and the same, my bad again :/ \u2013\u00a0 Aayush Agrawal Jan 20 '13 at 18:25\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nWith Shard's notation, the probability that the player wins if she rolls until she has at least $b$ is\n\n$$ p_b=\\sum_{a=b}^{21}\\sum_{c=22}^{a+6}p(a,b)p(c,a+1)\\;, $$\n\nand she will choose $b$ to maximize this. Here's code that calculates these probabilities using Shard's recurrence:\n\n$$ \\begin{array}{c|c} b&p_b\\\\\\hline 16&0.28518\\\\ 17&0.39679\\\\ 18&0.47400\\\\ 19&0.49650\\\\ 20&0.44231\\\\ 21&0.28597\\\\ \\end{array} $$\n\nThus the player should roll until she has at least $19$, and then her winning probability is very nearly even. The probability that she rolls $21$ is $p(21,19)\\approx0.19091$, and the probability that the dealer rolls $21$ is $p(19,19)p(21,20)+p(20,19)p(21,21)\\approx0.13597$, for a total of about $0.32689$.\n\nshare|improve this answer\nI am not very accurate with high level math(13 years old, just learnt 2 variable algebra).What i dont get is why are the probablities that the dealer rolls a 21 different than the players rolling a 21? The dice is fair to both ends right? Also the table describes the probablity of landing on any of those numbers but it doesnt mention the chances of a bust. I am sorry but i am a bit confused :/ \u2013\u00a0 Aayush Agrawal Jan 20 '13 at 18:30\nAlso the probablity of rolling a 21 is given thx but what are the probablities of any random game being won by the player or the dealer? \u2013\u00a0 Aayush Agrawal Jan 20 '13 at 18:34\n@Aayush: I think you misunderstood the table. The probabilities $p(a,b)$ that Shard introduced are the probabilities for landing on $a$ if you keep rolling until you have at least $b$. The probabilities $p_b$ that I introduced are not probabilities for landing on any particular number; they're winning probabilities, which I believe is what you asked for. The table shows that the highest winning probability is achieved if the player rolls until she has at least $19$. I'll explain it in more detail later if I find the time. \u2013\u00a0 joriki Jan 20 '13 at 21:00\n@Aayush: If the player rolls until she has at least $b$, she might win if she ends up with anything from $b$ to $21$. That's reflected in the first sum in the equation, where $a$ is the number she ends up with and the probabilities for these cases are $p(a,b)$. Then the dealer will roll until he has at least one more than $a$ (that's the second argument in $p(c,a+1)$), and the player will win if he ends up with anything from $22$ to $a+6$ -- that's reflected in the second sum and in the first argument of $p(c,a+1)$. Summing over all these cases yields the probability for the player to win. \u2013\u00a0 joriki Jan 20 '13 at 22:39\n@Aayush: Note that this answers the question as originally posed, not the one as modified in your comment under the question. Regarding the probabilities of rolling a $21$: It's not the dice that cause the difference in these probabilities, but the different roles of the player and the dealer. They play with different targets, $b$ and $a+1$, respectively, and the dealer's target $a+1$ depends on the player's result $a$. If they'd play with the same target, they'd have the same probability of hitting $21$. \u2013\u00a0 joriki Jan 20 '13 at 22:42\n\nEach players turn can be described by a set of probabilities based on the \"sticking number\" $b$ they choose which is the lowest total number at which they will stop rolling the dice. The dealer always picks $b=n+1$ where $n$ is the score the player got to try and beat them. The player has a more tricky decision which will be based off what the probabilities are of him winning after sticking vs the probability of immediately going bust.\n\nLet $p(a,b)$ be the probability that the the total = $a$ given we keep rolling until the total is $\\ge b$. Clearly $p(a,b)=0$ if $a<b$ as we are supposed to keep rolling until $a\\ge b$. Also $p(a,b)=0$ for $a>=b+6$ since a single roll of the die cannot take us from a number less then $b$ to one greater then or equal to $b+6$.\n\nAlso if we choose $b=1$ then clearly we stop after our very first roll and so $$p(1,1)=p(2,1)=p(3,1)=p(4,1)=p(5,1)=p(6,1)=\\frac16$$ Now let us consider $b=2$. After our first roll we would only choose to roll again if we rolled a one, and so we end up with\n\n$p(2,2)=p(3,2)=p(4,2)=p(5,2)=p(6,2)=\\frac16+\\frac1{6^2}$ and $p(7,2)=\\frac1{6^2}$\n\nIn general we end up with the recurrence relation $$p(a,b)=p(a,b-1)+\\frac{p(b-1,b-1)}6$$ where $b\\le a\\le b+5$ and zero for other values of $a$.\n\nIt should be easy to calculate the table of probabilities up to $b=21$, and thus work out the chance the dealer wins given that the player \"stuck\" on a certain number. Knowing these probabilities the player can now decide their own sticking number by working out if the chance of going \"bust\" on the next roll is less then the chance they would lose anyway by \"sticking\" and letting the dealer play.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/213374/group-homomorphisms-between-two-abelian-groups-with-different-kernel\nText:\nTake the 2-minute tour \u00d7\n\nDoes there exist two abelian groups $A,B$ with an epimorphism $f: A\\to B$, and two other abelian groups $A', B'$ along with an epimorphism $g: A'\\to B'$ such that $A\\cong A'$, $B\\cong B'$ and $ker\\,f \\not\\cong ker\\,g$? It seems to me that the groups must be infinite, since we have $B\\cong A/ker\\,f$ and $B'\\cong A'/ker\\,g$.\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet me reformulate the question: you want an abelian group $G$ with two subgroups $H, H'$ which are not isomorphic but such that the quotients $G/H, G/H'$ are isomorphic.\n\nThe smallest example is $G = C_2 \\times C_4, H = C_2 \\times C_2, H' = 1 \\times C_4$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/303939/planar-graph-number-of-faces\nText:\nTake the 2-minute tour \u00d7\n\nI need to determine the number of faces of a planar graph with $n$ vertices, $m$ edges and $k$ connected components. I was thinking of using Euler's formula $f=m-n+2$ but that is for a connected graph. Because I have $k$ components I was thinking $k$ times Euler formula, for each connected component.\n\nAny advice or help is welcome.\n\nshare|improve this question\nMy advice would be to draw a bunch of examples with, say, three connected components, and calculate $f-m+n$ for each of them, and make a conjecture, and prove it. If you get stuck along the way, come back, tell us what you've done, and someone will help. \u2013\u00a0 Gerry Myerson Feb 14 '13 at 12:34\nIn the Euler's formula for a connected planar graph $f-m+n=2$, one of the face is the exterior face. If you only count the inner face, it is $f_{inner}-m+n=1$. If you have $k$ connected component, you get $f_{inner}-m+n=k$. Add back the exterior face, you get $f-m+n=k+1$. \u2013\u00a0 achille hui Feb 14 '13 at 13:01\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nEuler's formula can be extended $$ V+F = E +C+\\chi, $$ where $C$ is the number of components and $\\chi$ is Euler's characteristic of the surface where the graph lives on. If you deal with $k$-regular planar graphs the mean face degree obeys: $$ \\frac{\\sum f_k}{F}=\\frac {2k}{k -2} \\left( 1-\\frac{1+\\chi}{F}\\right) $$ (see here)\n\nshare|improve this answer\n\nWe will count the outer face as its own face. So a cycle has two faces, for example.\n\nThe idea is to take each connected component $C_1$, $C_2$, etc., and connect them by drawing a bridge between $C_1$ and $C_2$, $C_2$ and $C_3$, etc. We will thus add $n-1$ edges (the restriction is if you contract the connected components we had previously, you must form a tree).\n\n  \u2022 $F = f$ remains the same.\n  \u2022 $V = n$ since no vertices were added.\n  \u2022 $E = m + k - 1$ since $k-1$ edges were added.\n\nNow apply Euler's formula.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/645289/properties-of-modular-arithemtic-mod-primes-and-quadratic-residues\nText:\nTake the 2-minute tour \u00d7\n\nI have the following two equations:\n\n$$z_1 = x_1^2 \\pmod p$$ $$z_2 = x_2^2 \\pmod q$$\n\nand p and q are prime.\n\nand I want to show $x^2$ and $z^2$ are equal mod pq\n\n$$x^2 = x_1^2 c_1^2 + x_2^2 c^2_2$$ $$z^2 = z_1 c_1^2 + z_2 c^2_2$$\n\nIntuitively, it seems \"obvious that they are equal since $z_1 = x_1^2$ and $z_2 = x_2^2$\" but these statements are only true mod p and q respectively. Then how can one claim that they are indeed equal? I guess I was wondering if I was missing some \"obvious\" property of modular arithmetic or/and quadratic residues?\n\nAlso for reference $c_1$ and $c_1$ are Chinese remainder theorem coefficients. i.e.\n\n$c_1 = 1 \\pmod p$\n\n$c_1 = 0 \\pmod q$\n\n$c_2 = 0 \\pmod p$\n\n$c_2 = 1 \\pmod q$\n\n\nI ran into that doubt when trying to prove:\n\n$ z \\in \\mathbb{QR}_{pq} \\iff z \\in \\mathbb{QR}_p$ and $z \\in \\mathbb{QR}_q$\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nYour equations imply $x^2$ and $z^2$ are $\\,\\equiv z_1\\pmod p,$ and $\\,\\equiv z_2\\pmod{q},\\,$ so $\\,x^2\\equiv z^2 \\pmod{pq}\\,$ by CRT. Or, directly $\\,p,q\\mid x^2-z^2\\Rightarrow\\, pq\\mid x^2-z^2,\\,$ since $\\,p,q\\,$ coprime $\\Rightarrow {\\rm lcm}(p,q) = pq.$\n\nTo be explicit: $\\ {\\rm mod}\\ p\\!:\\ x^2 = x_1^2\\color{#c00}{c_1}^{\\!2}+x_2^2\\color{#0a0}{c_2}^{\\!2} \\equiv x_1^2\\equiv z_1\\ $ by $\\color{#c00}{c_1\\equiv 1},\\,\\ \\color{#0a0}{c_2\\equiv 0}.\\,$\n\nAnd, similarly $\\ {\\rm mod}\\ p\\!:\\ z^2 \\equiv z_1 \\color{#c00}{c_1}^{\\!2} + z_2 \\color{#0a0}{c_2}^{\\!2} \\equiv z_1.\\ $ And similarly $\\,{\\rm mod}\\ q.$\n\nRemark $\\ $ Essentially it concerns the uniqueness mod $pq\\,$ of the solution $X$ of\n\n$$\\begin{eqnarray} X &\\equiv& x_1^2\\pmod p\\\\ X &\\equiv& x_2^2 \\pmod{q}\\end{eqnarray}$$\n\nThis follows by CRT (the easy direction). One doesn't need to write the explicit solution given by CRT, viz. $\\, X = c_1 x_1^2 + c_2 x_2^2.\\,$ (Why do use $\\,c_i^2$ vs. $c_i\\,?)\\,$ What is the context of your problem?\n\nshare|improve this answer\nHi Bill, ur always so helpful to my questions :). The context was that I was trying to prove the following $ z \\in \\mathbb{QR}_{pq} \\iff z \\in \\mathbb{QR}_p$ and $z \\in \\mathbb{QR}_q$ and then ran into the doubt I pointed out. \u2013\u00a0 Pinocchio Jan 20 '14 at 20:11\nWhat does \"viz\" mean? \u2013\u00a0 Pinocchio Jan 20 '14 at 20:43\n@Pinocchio \"namely\", see here \u2013\u00a0 Bill Dubuque Jan 20 '14 at 20:56\nLet me tell you why I used that $c^2$.I wanted to show $x=x_1c_1+x_2c_2$ and $z=z_1c_1+z_2c_2$ satisfied $z=x^2 \\pmod {pq}$.So I computed $x^2 = (x_1c_1)^2+(x_2c_2)^2 +2x_1x_2c_1c_2$.Then I applied modpq leading to: $x^2 = (x_1c_1)^2+(x_2c_2)^2 \\pmod {pq}$ since the way that $c_1$ and $c_2$ is defined,means $c_1c_2$ is divisible by pq.Then I realized that if I just changed the way z was originally defined I would be very close of showing that z was indeed a quadratic residue.So I just changed the definition of it to make it look more similar to what I was looking for i.e. $z=z_1c_1^2+z_2c_2^2$ \u2013\u00a0 Pinocchio Jan 20 '14 at 21:20\nWhich lead me to the exact problem I posted about, because I had the problem that $z_1 = x_1^2 \\pmod p$ and $z_2 = x_2^2 \\pmod q$ only applied in mod p and mod q but I had my final stuff in mod pq. Which I felt there was just something not right going on. Which lead to my post and which your answer resolved because the way that you did stuff with my \"wrong\" stuff made me realize that the technique you used worked on the original problem. :) \u2013\u00a0 Pinocchio Jan 20 '14 at 21:25\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/158425/integrating-factor-how-to-solve-it\nText:\nTake the 2-minute tour \u00d7\n\nVerify that: $$\\frac12(Mx+Ny)d(\\ln(xy))+\\frac12(Mx-Ny)d(\\ln(x/y))=Mdx+Ndy$$\n\nHence show that, if the de $Mdx+Ndy=0$ is homogenous, then $Mx+Ny$ is an integrating factor unless $Mx+Ny=0$\n\nNote: Verification is trivial, hence nothing much to be done there, but I couldnt solve the second part of the question \"Hence...\" so for the completeness of the problem I added it. Further on, isnt the statement \" $Mdx+Ndy=0$ is homogenous \" superfluous as RHS is already zero, so why add the word homogenous. Perhaps I am being pedantic? And lastly I would like to have some hints in solving the INTEGRATING Factor part.\n\nEDIT: My approach I approached like this: I multiplied the function $Mx+Ny$ to both sides of the equation $Mdx+Ndy=0$ and tried to show, that $d(u(x,y))=0$ but I couldnt prove it.\n\n\nshare|improve this question\nI think that in this context \"homogeneous\" might mean that $M$ and $N$ are homogeneous polynomials in $x$ and $y$, and of the same degree. E.g., $$(2x^2+3xy+4y^2)dx+(5x^2-6xy-7y^2)dy=0$$ \u2013\u00a0 Gerry Myerson Jun 14 '12 at 23:53\naah.. I see.... \u2013\u00a0 Soham Jun 15 '12 at 5:16\n\n1 Answer 1\n\nThe statement of the question is not entirely correct. In fact the integrating factor for equation $$Mdx+Ndy=0$$ where $M$ and $N$ are homogeneous functions of both $x$ and $y$ (i.e. $M(x,y)=x^m M(1,\\frac{y}{x})$, see Gerry Myerson's comment for an example) will be $$\\mu = \\frac{1}{Mx+Ny}$$ in order to ascertain this divide both sides of your equality by $Mx+Ny$: $$\\frac12d(\\ln(xy))+\\frac12\\frac{Mx-Ny}{Mx+Ny}d(\\ln(x/y))=\\frac{Mdx+Ndy}{Mx+Ny}$$ $$\\frac12d(\\ln(xy))+\\frac12\\frac{M(x,y)\\frac{x}{y}-N(x,y)}{M(x,y)\\frac{x}{y}+N(x,y)}d(\\ln(x/y))=\\frac{Mdx+Ndy}{Mx+Ny}$$ Using homogeneity: $$\\frac12d(\\ln(xy))+\\frac12\\frac{M(\\frac{x}{y},1)\\frac{x}{y}-N(\\frac{x}{y},1)}{M(\\frac{x}{y},1)\\frac{x}{y}+N(\\frac{x}{y},1)}d(\\ln(x/y))=\\frac{Mdx+Ndy}{Mx+Ny}$$ On the LHS variables are separated, so it is effectively an exact differential (you can let $\\frac{x}{y}=e^t$ to complete the form. Therefore, $\\mu$ as given above is an integrating factor.\n\nConstructive proof goes in a somewhat similar way. Let $u=\\frac{x}{y}$. Then again, using homogeneity (assuming $M$ and $N$ are homogeneous of the order $m$): $$M(x,y)=M(x,ux)=x^m M(1,u)$$ Similarly $$N(x,y)=x^m N(1,u)$$ Now $$dy=udx+xdu$$ Inserting in the original equation we obtain $$x^m (M(1,u)+uN(1,u))dx+x^{m+1}N(1,u)du$$In order to separate variables we must divide both sides by $x^{m+1}(M(1,u)+uN(1,u)$. However $$\\mu = \\frac{1}{x^{m+1}(M(1,u)+uN(1,u)}=\\frac{1}{x\\cdot x^m(M(1,u)+y\\cdot x^m N(1,u)}=\\frac{1}{xM(x,y)+yN(x,y)}$$\n\nshare|improve this answer\nCouple of questions: 1. In the last step how did you arrive at the value of $\\mu$ 2. Can you talk a bit more how the LHS is separated? 3. Does an exact de always need an equation in the form of $Idx+Jdy=0$ ? [To be frank, I am stunned at this question. I could easily solve the questions on integrating factor from my text, but when given this sum I couldnt. Not only that, I didnt get a clue how to go about it] \u2013\u00a0 Soham Jun 15 '12 at 6:02\nSure. 1) effectively, you have here an equation of the form: $$P(x)Q(u)dx+R(x)S(u)du=0$$ which is obviously separated: $$\\frac{P(x)}{R(x)}dx+\\frac{S(u)}{R(u)}du=0$$ Note thatt solving any separable equation amounts to multiplying it by an integrating factor. 2. LHS can be cast in the form $$d(A(xy))+B(\\ln(x/y))d(ln(x/y))$$ which is an exact differential.3. This particular IF is specific to this form of equation. Personally, I never use it and treat IF problems on a case by case basis. \u2013\u00a0 Valentin Jun 15 '12 at 9:51\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/102383/validating-results-of-a-monte-carlo-integration\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I want to use the Monte Carlo integration method to compute the following integral\n\n$\\int_D (e^{x^{2}} + e^{y^{2}}) \\; dx \\; dy$ where $D$ is some regular hexagon. I have managed to write the code and everything and the results I'm getting seem valid.\n\nThe problem is now that I do not know how can I show that the algorithm does what it's supposed to do. Is there another way to compute that integral? Is there any way to validate my results?\n\nEDIT: I'm talking about the \"sample-mean\" method\n\nshare|improve this question\nThis is just a guess, but maybe you have a typo and you really want to integrate over $e^{-(x^2 + y^2)}$ instead? This would be a 2d gaussian which is probably more common than the function you wrote. \u2013\u00a0 opt Jan 25 '12 at 18:54\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nLet $f(x,y) = \\mathrm{e}^{x^2} + \\mathrm{e}^{y^2}$, and suppose we would like to integrate this function over a valid triangle with vertices at $p_1 = (x_1,y_1)$, $p_2 (x_2,y_2)$ and $p_3 = (x_3,y_3)$.\n\nThis can be computed in closed form, because $\\int_D f(x,y) \\mathrm{d} x \\mathrm{d} y = \\int_D \\mathrm{e}^{x^2} \\mathrm{d} y \\mathrm{d} x + \\int_D \\mathrm{e}^{y^2} \\mathrm{d} x \\mathrm{d} y $ Now integration over $y$ for each fixed $x$ in the first integral, and over $x$ for each fixed $y$ in the second can be easily done, and will yield a linear function of $x$ and $y$ respectively.\n\nThen you are down to $$ \\int_a^b (c x+d) \\mathrm{e}^{x^2} \\mathrm{d} x = \\frac{c}{2} \\left( \\mathrm{e}^{b^2}- \\mathrm{e}^{a^2} \\right) + \\frac{d \\sqrt{\\pi}}{2} \\left( \\operatorname{erfi}(b) - \\operatorname{erfi}(a) \\right) $$\n\nComing back to the setting stated at the beginning of the post, here is a little code in Mathematica that will do the computation exactly:\n\nIn[6]:= pred[{x_, y_}, {x1_, y1_}, {x2_, y2_}, {x3_, \n   y3_}] := ((x - x1) (y2 - y1) - (y - y1) (x2 - x1)) ((x3 - x1) (y2 -\n         y1) - (y3 - y1) (x2 - x1)) > 0\n\nIn[7]:= InTriangle[px_, p1_, p2_, p3_] := \n pred[px, p1, p2, p3] && pred[px, p2, p3, p1] && pred[px, p3, p1, p2]\n\nIn[10]:= int[p1 : {x1_, y1_}, p2 : {x2_, y2_}, p3 : {x3_, y3_}] := \n Block[{x, y},\n  Integrate[(Exp[x^2] + Exp[y^2]) Boole[\n     InTriangle[{x, y}, p1, p2, p3]], {x, Min[x1, x2, x3], \n    Max[x1, x2, x3]}, {y, Min[y1, y2, y3], Max[y1, y2, y3]}]]\n\nIn[13]:= int[{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}] // FunctionExpand\n\nOut[13]= 1/6 (-Sqrt[3] + 6 Sqrt[3] E^(1/4) - 2 Sqrt[3] E^(3/4) - \n   3 Sqrt[3] E - 3 Sqrt[3 Pi ] Erfi[1/2] + \n   3 Sqrt[3 Pi] Erfi[1] + 3 Sqrt[ Pi] Erfi[Sqrt[3]/2])\nshare|improve this answer\n\nThe simplest way to validate your Monte Carlo results would be to use numerical quadrature of modestly accurate order on the region D. Since D is a regular hexagon (but otherwise unspecified), it can be split into six equilateral triangles.\n\nQuadrature rules in one-dimension are well introduced in undergraduate numerical methods courses, but if you want, take a formula from this article on quadrature rules for triangles.\n\nTypically a series of such approximations is done, either with increasingly small subdivisions of area or with increasingly higher-order accuracy formulas, so that the convergence of the approximations can be seen.\n\nshare|improve this answer\n\nBecause the integrand is positive you can easily find lower and upper bounds by integrating over nicer domains that are subsets or supersets of the hexagon domain.\n\nshare|improve this answer\nWhile this is true, such an approach require fine mesh triangulation of the hexagon to achieve modest precision, as $\\exp(x^2) + \\exp(y^2)$ grow rather fast. \u2013\u00a0 Sasha Jan 25 '12 at 18:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/159970/chain-rule-and-inverse-in-matrix-calculus\nText:\nTake the 2-minute tour \u00d7\n\nI am having trouble understanding the derivation of some seemingly simple matrix derivatives and am wondering if there is an intuitive (perhaps geometric) explanation. I am reasonably well-versed in multivariate calculus and linear algebra, but am not comfortable with tensor math.\n\nThe function I am interested in is $f(t)=\\mathbf{B}^T(\\mathbf{X}+t\\mathbf{Y})^{-1}\\mathbf{A}$, where $t$ is a scalar, and $\\mathbf{A},\\mathbf{B},\\mathbf{X},\\mathbf{Y}$ are matrices with conformant dimensions.\n\nOn the page 24 of the pdf of the appendix on matrix calculus in the book by Jon Dattorro (page 600 of the book), I find the formula for the first derivative of $f(t)$:\n\n\nThis sort of makes sense to me from my knowledge of calculus of functions of single variable: if you have $g(t)=a(x+ty)^{-1}b=ab(x+ty)^{-1}$, then $\\frac{dg}{dt}=-ab(x+ty)^{-2}y=-a(x+ty)^{-1}y(x+ty)^{-1}b$ (from the chain rule and the power rule). That is, there is a clear similarity in the form.\n\nWhat I don't understand is why the matrix equation for $\\frac{df}{dt}$ looks the way it does. Is it due to non-commutativity of matrix multiplication? But how does that come in to this problem exactly? I've found the chain rule for matrix-valued function in the same pdf on page 8 (eq 1749) but I am not sure how to apply it here. Maybe I don't understand something about the calculus of the single-variable functions.\n\nI guess I am asking if there is a way to derive the equation for $\\frac{df}{dt}$ \"from first principles\" without using tensors.\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 3 down vote accepted\n\nI think this follows more quickly from the product rule. The derivative of $t \\mapsto X + tY$ is $Y$. You have $$0 = \\frac{d}{dt}I = \\frac{d}{dt} [(X+tY)^{-1}(X+tY)] = \\frac{d}{dt}(X+tY)^{-1} * (X+tY) + (X+tY)^{-1}Y$$ and so $$\\frac{d}{dt} (X+tY)^{-1} = -(X+tY)^{-1} Y (X+tY)^{-1}.$$ Multiplying on the left and right by $B^T$ and $A$ won't change much.\n\nshare|improve this answer\nWow, nice explanation! Thanks! \u2013\u00a0 M.B.M. Jun 18 '12 at 17:56\n\nLet $C=X+tY$ and $D=C^{-1}$. As $C D = I$, then $C' D +C D'=0$. Therefore $D'=-C^{-1} C' C^{-1}$. As $C'=Y$, then $[(X+tY)^{-1}]'=-(X+tY)^{-1}Y~(X+tY)^{-1}$. Finally, $A$ and $B$ are constant matrices, and then $[B(X+tY)^{-1}A]'=-B(X+tY)^{-1}Y~(X+tY)^{-1}A$.\n\nshare|improve this answer\n\nHint: The mape : $i: GL_n \\to GL_n$ sush that $i(u)=u^{-1}$ for all $u \\in GL_n$ (where $GL_n$ is the linear group : invertibles matrices so) is differentiable and $i'(u).h=-u^{-1}hu^{-1}$ forall squarre matrixe $h$ and invertible matrix $u$. By composition , and using $v: t \\mapsto X+tY$ differentiable $v'(t)=Y$ you can ask to this question.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/21274/lukasiewicz-logic-tautology\nText:\nTake the 2-minute tour \u00d7\n\nSuppose a statement form $\\varphi$ always has value T or U. Show $\\varphi$ is a classical tautology.\n\nshare|improve this question\nThis question is quite badly formulated. What is T? What is U? Do you mean first-order or just propositional? \u2013\u00a0 boumol Feb 10 '11 at 0:34\nSee en.wikipedia.org/wiki/Three-valued_logic \u2013\u00a0 JDH Feb 10 '11 at 0:38\nDid you write out the truth table? \u2013\u00a0 Doug Spoonwood Jun 19 '13 at 4:59\n\n1 Answer 1\n\nSuppose that a statement $\\varphi$ of propositional logic (using only $\\wedge$, $\\vee$ and $\\to$) is not a propositional tautology in classical logic. It follows that some row of the truth table for $\\varphi$ has value $F$.\n\nNow, consider the truth table of $\\varphi$ in \u0141ukasiewicz three-valued logic, which is called Kleene logic on the Wikipedia page. The key observation is that \u0141ukasiewicz three-valued logic agrees with classical logic on classical logic input. In other words, if all the propositional variables of $\\varphi$ are given classical T/F values, then the truth value of $\\varphi$ will agree with the classical logic value. Thus, since $\\varphi$ had a classical row with value $F$, the very same row will have value F in the \u0141ukasiewicz truth table of $\\varphi$, contrary to the assumption that $\\varphi$ had only values T or U.\n\nshare|improve this answer\nThe Wikipedia page actually has the correct table for Lukasiewicz three-valued logic. \u2013\u00a0 Doug Spoonwood Jun 19 '13 at 4:59\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/115544/integration-involving-partial-fractions\nText:\nTake the 2-minute tour \u00d7\n\nI have to integrate the following and I was having trouble with it because I am pretty new to the concept of using partial fractions. I did as much as I could and I need help in moving forward:\n\n\nI did some long division and got:\n\n\nFactored the denominator:\n\n\nand got the following:\n\n\nNow I think that I should have something like this, but I'm not sure:\n\n\nWould appreciate any help. Thanks.\n\nshare|improve this question\nYour error is only in the set-up. Because of the quadratic denominator in the first partial fraction, you need a linear numerator, $\\frac{A+Dx}{x^2}$. Alternatively, use the set-up given by Pete Clark. \u2013\u00a0 Arturo Magidin Mar 2 '12 at 3:59\nI think the above comment is most helpful. In general, should the numerator be a polynomial of one degree lower than the denominator? Should we have Ax+B/(x^2) + C/(x+1) + Dx+E/(x^2-x+1)? \u2013\u00a0 Ziggy Jul 16 '12 at 18:54\n\n2 Answers 2\n\nThe polynomial $x^2 - x + 1$ has discriminant $(-1)^2 - 4(1)(1) = -3 < 0$, so it has no real roots. According to the partial fractions recipe, there are unique real constants $A,B,C,D,E$ such that\n\n$$\\frac{2x^2+1}{x^5+x^2} = \\frac{A}{x} + \\frac{B}{x^2} + \\frac{C}{x+1} + \\frac{Dx+E}{x^2-x+1}$$\n\nfor all $x \\in \\mathbb{R}$. In other words, you did not postulate a sufficiently general expression for the partial fractions decomposition, so -- except in the unlikely event that $A = D = 0$ -- you will not be able to achieve a decomposition in the form you have given.\n\nI happened to cover partial fractions quite recently in a class I am teaching this semester. A student asked me why you need a term like $\\frac{A}{x}$. My answer at the time was to think of taking a sum which did have a $\\frac{A}{x}$ term, put it over a common denominator, and then apply a partial fractions decomposition: we would then be saying that there are some real constants $\\alpha,\\beta,\\gamma,\\delta$ such that\n\n$$\\frac{A}{x} + \\frac{B}{x^2} + \\frac{C}{x+1} + \\frac{Dx+E}{x^2-x+1} = \\frac{\\alpha}{x^2} + \\frac{\\beta}{x+1} + \\frac{\\gamma x + \\delta}{x^2-x+1},$$\n\nwhich seems unlikely. Actually I think I could say it a bit better: a general proper rational function with denominator $x^5+x^2$ is of the form\n\n$$\\frac{ax^4 + bx^3 + cx^2 + dx + e}{x^5+x^2},$$\n\nthus there is in a sense a five parameter family of such things. Therefore whatever your partial fractions decomposition should be, it should also have five parameters $A,B,C,D,E$. That's a more convincing answer as to why your proposed expansion is (very probably) not achievable -- isn't it? -- you are trying to express a five parameter family of functions using only three parameters: no good.\n\nThis business with \"parameters\" can be made rigorous using the language of linear algebra, and in fact dimension-counting can be used to give a proof of the existence and uniqueness of the partial fraction decomposition. See this note which I wrote just a few days ago.\n\nshare|improve this answer\nPete, my understanding of mathematics is very elementary compared to yours so please bear with me on this; I used this expression $\\frac{A}{x} + \\frac{B}{x^2} + \\frac{C}{x+1} + \\frac{Dx + E}{x^2 -x +1}$ and got the following $x^5(A+C+D)+x^4(B-C+D+E)+x^3(C+E)+Ax^2-Bx$ Am I on the right path? If so, how do I equate these 5 expressions to $2x^2+1$ \u2013\u00a0 user754950 Mar 2 '12 at 4:47\n@user754950: (i) You have an $x$ too many; you can factor out one $x$ and cancel it with the $x^3$ that you undoubtedly have in your denominator. The least common denominator is $x^2(x+1)(x^2-x+1)$, not $xx^2(x+1)(x^2-x+1)$. It's easier if you leave the products indicated and then you use Heaviside's cover-up method. You have $Ax(x+1)(x^2-x+1) + B(x+1)(x^2-x+1) + Cx^2(x^2-x+1)+(Dx+e)x^2(x+1) = 2x^2+1$. Plug in $x=0$ to get the value of $B$; plug in $x=-1$ to get $C$; etc. \u2013\u00a0 Arturo Magidin Mar 2 '12 at 5:06\nYou have an extra factor of $x$ - you want to have $x^4(A+C+D)+$ etc. Then you compare coefficients to those in $2x^2+1$, giving you five equations for the five unknowns $A,B,C,D,E$. \u2013\u00a0 Gerry Myerson Mar 2 '12 at 5:08\nThis is a good answer, but I had to read it two or three times before I was convinced of its merit. I'm glad I did though! :) \u2013\u00a0 Ziggy Jul 16 '12 at 19:03\n\nAs a rule of thumb, you should remember that the number of partial fractions that you need is the same as the degree of the polynomial appearing in the denominator. Therefore consider an expression like\n\n\nThus repeated roots need extra terms (the presence of the $\\dfrac{1}{x}$ and the $\\dfrac{1}{x^2}$) and if the denominator of the partial fraction is an irreducible degree $2$ polynomial then you will need a linear factor on top.\n\nWhy should you need $5$ partial fractions for a degree $5$ denominator? Intuitively, the reason is that you want to get a system that has the same number of equations as unknowns. When you set up the equations to solve for the coefficients, a degree $5$ polynomial gives you $5$ equations, so you want enough coefficients to ensure that there is one and only one solution.\n\nEdit: to answer the question in the comment, let me give you an example of why the extra partial fractions are necessary:\n\nConsider the function\n\n\nLet's try to do a partial fractions decomposition. If I tried to write\n\n$$\\frac{3x+2}{x^2(x+1)} = \\frac{A}{x^2} + \\frac{B}{x+1}$$\n\nThen this gives me the equation $$\\frac{3x+2}{x^2(x+1)} = \\frac{Bx^2 + Ax + A}{x^2(x+1)}$$\n\nWhich would imply that $B= 0$, $A= 2$ and $A=3$ (Notice that I have three equations and only two constants $A$ and $B$). This is, of course, impossible. This means that I need to add in another term when I write down the partial fraction decomposition in the first place. I can get around this by adding in an extra term for each repeated root. The correct equation is:\n\n\nNow in this case it is possible to determine $A$, $B$, $C$.\n\nSee also Pete's more general answer- I was writing this as he finished his edit.\n\nshare|improve this answer\nHow did you get this: $\\frac{A}{x} + \\frac{B}{x^2}$? I only had 3 denominators. \u2013\u00a0 user754950 Mar 2 '12 at 3:40\nIn each fraction, the degree of the numerator can be up to one less than the degree of the denominator. So the factor with $x^2$ in the denominator can be of the form $$\\frac{Ax+B}{x^2} = \\frac{Ax}{x^2}+\\frac{B}{x^2} = \\frac{A}{x}+\\frac{B}{x^2}.$$ You need to allow the possibility of a degree 1 numerator. \u2013\u00a0 Arturo Magidin Mar 2 '12 at 4:01\n\"can\" be up to one less? Why not just leave it in the form Ax+B/(x^2)? \u2013\u00a0 Ziggy Jul 16 '12 at 19:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204659/finding-the-winning-probability-of-the-game\nText:\nTake the 2-minute tour \u00d7\n\nSuppose in an independent game which has 2 players, player 1 and player 2, the probability of player 1 to win each game is $r$. To be the overall winner of the game, one of the players needs to win 2 more games than the other. What is the probability that player 1 will be the overall winner?\n\nMy sketch to solve the question: Note that to be the overall winner, one player should have won 2 games consecutively. So if player 1 is the winner, the outcome should either a draw, i.e. each player wins a game consecutively or player one won 2 games consecutively. But I am not sure how to start calculating.\n\nshare|improve this question\nJust to clarify, they play a game, say head or tail, until one of them has a $2$ games lead onto the other? \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 0:54\nI am not sure as in a head tail game, it is possible to have 2 winner at the same time, i think may be consider a simplier case first, i.e.each game always have one winner \u2013\u00a0 abc Sep 30 '12 at 1:01\nWhat is the tie probability? \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:07\n\n2 Answers 2\n\nLet $a$ be the probability that the first player (ultimately) wins if the two players are tied in wins. Let $b$ be the probability that she wins if she is $1$ ahead. And let $c$ be the probability she wins if she is $1$ behind. We have the equations $$\\begin{align}a&=rb+(1-r)c,\\\\ b&=r+(1-r)a, \\\\ c&=ra.\\end{align}$$\n\nSolve the system of linear equations.\n\nshare|improve this answer\nWould you mind briefly explain how you get the equations \u2013\u00a0 Mathematics Oct 9 '12 at 14:45\nWe justify the first equation. Suppose the two are tied. Player $1$ can ultimately win if (i) she wins next game and ultimately wins or (ii) she loses next game but ultimately wins. For (i), the probability she wins next game is $r$, and given that, she will be $1$ ahead, and the probability she ultimately wins is by definition $b$. So the probability of (i) is $rb$. For (ii), the probability she loses the next game is $1-r$, and given that, she will be $1$ behind, so by definition the probability she ultimately wins is $c$. So the probability of (ii) is $(1-r)c$. (Continued $\\dots$) \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 14:56\nNow we add the probabilities of (i) and (ii). We get $a=rb+(1-r)c$. The other two equations are obtained the same way, except that for the third, if Player $1$ is $1$ behind and wins (probability $r$, they are tied, but if she loses the game, then it's all over, Player $1$ has lost. So probability Player $1$ ultimately wins if she is $1$ behind is $ra$. \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 15:01\nI did the problem this way because it is a general approach to similar problems. A system can be in any one of several states. In our case there are $3$ states (tied, $1$ ahead, $1$ behind). There are various transition probabilities between states. We form a matrix with these transition probabilities, and multiplying by that matrix lets us trace out the evolution of the system. If you are familiar with Linear Algebra, you will note we found an eigenvector of the matrix with eigenvalue $1$. \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 15:12\nWhat a gorgeous solution, Thank you very much. \u2013\u00a0 Mathematics Oct 9 '12 at 15:23\n\nThe probability player 1 wins the first two games is $r^2$ while the probability player 2 wins the first two is $(1-r)^2$; otherwise they start again.\n\nSo the probability player 1 wins the first two games given that either of the players does is $\\dfrac{r^2}{r^2 + (1-r)^2}$ and this is therefore the probability overall that player 1 wins overall.\n\nshare|improve this answer\nSituation is not that clear, as mentionned in a comment, the games can tie... \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:04\n@Jean-S\u00e9bastien: if that was a possibility then the question could not be answered without knowing the probability of player 2 winning an individual game. abc's comment says \"each game always has one winner\" \u2013\u00a0 Henry Sep 30 '12 at 1:08\nyes right, he said that he could consider a simpler case. I asked him to specify what is the Tie probability, or player 2's \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:11\n@Jean-S\u00e9bastien: The probability of an overall tie is $0$. \u2013\u00a0 Brian M. Scott Sep 30 '12 at 1:11\nhow do you get that form? \u2013\u00a0 abc Sep 30 '12 at 1:23\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/45618/probability-of-market-movement-trends\nText:\nTake the 2-minute tour \u00d7\n\nIf you imagine a scale from -100 to 100, if the market has moved up from 0 to 40, what is the probability is will continue to 100?\n\nThere is a 50-50 chance to move up or down from 0, but what is the probability of moving to 100 when it has already moved to 40?\n\nThis may be a simple question, but I am struggling! Can someone share the the algorithm that solves this problem?\n\nIs the answer 70%, ie. if at 0 it is 50-50 to go up or down, if it moves to 40 there is 70% chance it will rise to 100 and a 30% chance it will not?\n\nshare|improve this question\nIt depends on which model you choose for the stockmarket. For example the simplest model would be the binomial model ( en.wikipedia.org/wiki/Binomial_options_pricing_model ) \u2013\u00a0 Listing Jun 15 '11 at 22:03\nWow... that is complicated! Thank you though. Is there some simplier answer? Maybe the mention of the stockmarket made it more complex than it need to be. \u2013\u00a0 user12170 Jun 15 '11 at 22:20\nDo a search on \"stochastic calculus\" to see how truly bad things can get when transitioning from discrete models, such as the binomial model, to continous models. \u2013\u00a0 ItsNotObvious Jun 15 '11 at 22:41\nThank you. What if this was a straight case of up or down movement, not stock market movement.... this is complicating things... lets just imagine a straight up or down. \u2013\u00a0 user12170 Jun 15 '11 at 22:42\n\n2 Answers 2\n\nIt's a well established 'empirical fact' that there is no significant autocorrelation in market returns. That is, knowing that the market moved up in the last period provides no information about what it will do in the next period.\n\nSo the answer to your question (as backed up by a lot of data) is that it is still 50/50 whether the market goes up or down next, no matter what just happened.\n\nYou haven't really asked a mathematical question, which is why I haven't give you a mathematical answer.\n\nshare|improve this answer\nThank you Chris... your logic makes sense to me. \u2013\u00a0 user12170 Jun 16 '11 at 5:15\n\nIf (and this is a big if) you are considering a symmetric $\\pm1$ random walk or a driftless Brownian motion starting from $x=40$ and you are wondering about the probability $u(x)$ that it hits $x_1=100$ before hitting $x_0=-100$, then indeed the answer is $$ u(x)=\\frac{x-x_0}{x_1-x_0}=70\\%. $$ Briefly, an elementary method in the random walk case is to compute $u(x)$ for every integer starting point $x$ between $x_0$ and $x_1$. For every such $x$, one has $50\\%$ chances that the first step is to $x+1$ and $50\\%$ chances that the first step is to $x-1$, and from there, one looks for the probability $u(x\\pm1)$ to hit $x_1$ before $x_0$. Hence, $u(x)=\\frac12(u(x+1)+u(x-1))$.\n\nThis means that $x\\mapsto u(x)$ is a straight line on the integer interval $[x_0,x_1]$. Obviously, $u(x_0)=0$ and $u(x_1)=1$ hence $u(x)$ is as written above.\n\nA slightly more advanced method is to consider the position $X_n$ of the random walk at time $n\\wedge\\tau_0\\wedge\\tau_1$ where $\\tau_0$ is the first hitting time of $x_0$ and $\\tau_1$ is the first hitting time of $x_1$. This means that the random walk performs equiprobable independent $\\pm1$ steps and that one stops it as soon as it hits $x_0$ or $x_1$. Then $(X_n)$ is a bounded martingale hence its expectation does not depend on $n$. Now $X_0=x$, $X_n\\to x_1$ on $S=[\\tau_1<\\tau_0]$, $X_n\\to x_0$ on $[\\tau_0<\\tau_1]=S^c$, and one gets $$ x=X_0=\\lim\\limits_{n\\to\\infty}E(X_n)=E(\\lim\\limits_{n\\to\\infty}X_n)=x_0P(S^c)+x_1P(S). $$ Since $P(S)+P(S^c)=1$, this yields the result.\n\nIn the Brownian motion case, one can still use the idea of the second method, replacing finite differences by a differential operator: one gets that $u(x_0)=0$, $u(x_1)=1$ and $u''(x)=0$ for every real number $x$ in the interval $(x_0,x_1)$. This means that $u$ is affine in this case as well hence $u(x)$ is given by our first displayed formula, where now the argument $x$ is a real number.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/177125/holomorphic-function-on-the-complex-plane\nText:\nTake the 2-minute tour \u00d7\n\nlet $ f(z) \\in Hol(\\mathbb{C}) $ holomorphic function such that for each $ z_0 \\in \\mathbb{C} $ there exists $ N(z_0) $ such that $ f^{(N(z_0))}(z_0) = 0 $\nProve: that f is a polynom\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nModifying Davide's argument but avoiding Baire's category theorem: Let $\\overline{\\mathbb E}$ be the closed unit ball and $$F_n := \\{ z \\in \\overline{\\mathbb E} : f^{(n)}(z) = 0 \\}.$$ Then, by assumption, $\\overline{\\mathbb E} = \\bigcup_n F_n$. Since $\\overline{\\mathbb E}$ is uncountable, not all $F_n$ can be finite. Let $n \\in \\mathbb N$ s.t. $F_n$ is infinite. Since $\\overline{\\mathbb E}$ is compact, $F_n$ has a limit point in $\\overline{\\mathbb E}$, i.e. there is a $z_0 \\in \\overline{\\mathbb E}$ and a sequence $(z_k)$ in $F_n \\setminus \\{z_0\\}$ that converges to $z_0$. We have $f^{(n)}(z_k) = 0$ for all $k$, hence $f^{(n)} = 0$ by the identity theorem, so $f$ is a polynomial.\n\nshare|improve this answer\n+1 Damn, that was beautiful! \u2013\u00a0 DonAntonio Aug 2 '12 at 21:06\n$f^n=0$ means $f$ is a polynomial? how? \u2013\u00a0 La Belle Noiseuse Aug 3 '12 at 4:15\n$f^{(n)}$ means $f$ power n or what? \u2013\u00a0 La Belle Noiseuse Aug 3 '12 at 4:27\n$f^{(n)}$ denotes the $n$-th derivative of $f$. I assumed that you know that since you used that notation in your question. To see that $f^{(n)} = 0$ implies that $f$ is a polynomial just look at the Taylor expansion of $f$. \u2013\u00a0 marlu Aug 3 '12 at 15:19\n\nLet $F_n:=\\{z\\in\\Bbb C, f^{(n)}(z)=0\\}$. Since $f^{(n)}$ is continuous, $F_n$ is closed and by hypothesis, $\\Bbb C=\\bigcup_{n\\in\\Bbb N}F_n$. By Baire's theorem, there exists a $n_0$ such that $F_{n_0}$ has a non-empty interior. Hence $f^{(n_0)}$ vanishes on a ball, and it's necessarily the null function. This proves that $f$ is a polynomial.\n\nNote that there is a similar result for $C^{\\infty}$ functions from $\\Bbb R$ to $\\Bbb R$, but it's harder to show. It has been discussed here.\n\nshare|improve this answer\nis there a proof without baire theorem? i didnt learn that in the complex analysis course \u2013\u00a0 bar Jul 31 '12 at 11:33\nAnd what did you learn? In which chapter such an exercise appear? Actually, Baire is more a theorem from topology than complex analysis. \u2013\u00a0 Davide Giraudo Jul 31 '12 at 11:38\ni think the relevant theorems for this exercise are: uniqeness theorem: if $ f\\in Hol(D) $ D is a domain and there is U a subset of D such that U has accumulation point and $ \\forall z \\in U f(z)=0 $ then $ \\forall z\\in D f(z) = 0 $ \u2013\u00a0 bar Jul 31 '12 at 11:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/294007/system-of-linear-equations-for-congruency?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nSo this is my question:\nFind all x such that $4x=3 \\pmod{21}$, $3x=2 \\pmod{20},$ and $7x=3 \\pmod{19}$\n\nSo I know I have to use chinese remainder theorem and I know how to do it if $x$ didn't have a coefficient in front of it. In other words, if it was like:\n$x=3 \\pmod{21}$, $x=2 \\pmod{20},$ and $x=3 \\pmod{19}$\n\nThen I would be able to do it. All you would have to do is pick a pair, list out the congruency and find the commonality. But how do I do it with the coefficients?\n\nshare|improve this question\n\n2 Answers 2\n\nYou can use the fact that the coefficient of $x$ is coprime to the modulus in each case, hence a unit. In the first case, $4\\cdot 16=1\\pmod{21}$, so $$ 4x=3\\pmod{21}\\iff x=3\\cdot 16=6\\pmod{21}. $$\n\nAlso, $3\\cdot 7=1\\pmod{20}$, so $$ 3x=2\\pmod{20}\\iff x=14\\pmod{20}. $$\n\nI'll leave the last one for you. Try using the Euclidean Algorithm on $7$ and $19$ to find an inverse if you get stuck. So you can get an equivalence system of congruences, and solve with CRT, as you mention you are familiar with.\n\nshare|improve this answer\n\nUsing the Convergent proeprty of continued fraction, $$\\frac{21}4=5+\\frac14$$\n\nThe last but one convergent is $5$ $\\implies 21-4\\cdot5=1\\implies 4\\cdot5\\equiv-1\\pmod{21}\\implies 4^{-1}\\equiv-5\\equiv16$\n\nSo, $4x\\equiv 3\\pmod{21}$ becomes $x\\equiv16\\pmod{21}--->(1)$\n\n$$\\frac{20}3=6+\\frac23=6+\\frac1{\\frac32}=6+\\frac1{1+\\frac12}$$ The last but one convergent is $6+\\frac11=7$ $\\implies 20\\cdot1-3\\cdot7=-1\\implies 3\\cdot7\\equiv1\\pmod{20}\\implies 3^{-1}\\equiv7$\n\n$3x\\equiv2\\pmod{20}$ becomes $x\\equiv2\\cdot7\\pmod{20}\\equiv14--->(2)$\n\n\nThe last but one convergent is $2+\\frac1{1+\\frac1{2}}=\\frac83$ $\\implies 19\\cdot3-7\\cdot8=1\\implies 7\\cdot8\\equiv-1\\pmod{19}\\implies 7\\equiv-8\\equiv11$\n\n$7x\\equiv3\\pmod{19}$ becomes $x\\equiv3\\cdot11\\pmod{19}\\equiv14--->(3)$\n\nApplying Chinese Remainder Theorem on $(1),(2),(3)$, $$x\\equiv 16\\cdot19\\cdot20\\cdot b_1+14\\cdot19\\cdot21\\cdot b_2+14\\cdot20\\cdot21\\cdot b_3\\pmod{ 19\\cdot20\\cdot21} $$ where\n\n$19\\cdot20\\cdot b_1\\equiv1\\pmod {21}\\implies (-2)(-1)b_1\\equiv1\\pmod {21}\\implies b_1\\equiv11\\pmod{21}$ as $\\frac{21}2=10+\\frac12\\implies 21\\cdot1-2\\cdot10=1\\implies 2^{-1}\\equiv-10\\pmod{21}\\equiv11$\n\n$19\\cdot21\\cdot b_2\\equiv1\\pmod {20}\\implies (-1)(1)\\cdot b_2\\equiv1\\pmod {20}\\implies -b\\equiv1$ or $b\\equiv-1\\equiv19\\pmod{20}$\n\n$20\\cdot21\\cdot b_3\\equiv1\\pmod {19}\\implies (1)(2)b_3\\equiv1\\pmod {19}\\implies b_3\\equiv10\\pmod{19} $ as $\\frac{19}2=9+\\frac12\\implies 19\\cdot1-10\\cdot2=-1\\implies 2^{-1}\\equiv10\\pmod{19}$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/39331/how-to-replace-multiple-variables-at-once/39337\nText:\nTake the 2-minute tour \u00d7\n\nI would like to make a replacement \"c1 C1 -> F1, c2 C2-> F2....\" such that the expression like this \"c1 C1 c2 C2 c3 C3 c4 C4\" becomes \"F1 F2 F3 F4\".\n\nI used the standard replacement method: c1 C1 c2 C2 c3 C3 c4 C4 /. {c1 C1 ->F1, c2 C2 -> F2, c3 C3-> F3, c4 C4-> F4}. But mathematica only gives \"F1 c2 C2 c3 C3 c4 C4\", it only replace the first product.\n\nWhat is the reason this replacement does not work? How could I make such a replacement at once?\n\nThanks a lot.\n\nshare|improve this question\nuse //. instead of /. \u2013\u00a0 belisarius Dec 24 '13 at 3:08\nIt works! Thanks a lot! In fact, I used /. for the multiple variables replacement before but never have problems. May I ask why this does not work this time? \u2013\u00a0 skippyho Dec 24 '13 at 3:12\nCheck out the help files for ReplaceAll and ReplaceRepeated \u2013\u00a0 bill s Dec 24 '13 at 4:49\nSome of the discussion here is related. There are probably other questions where issues related to matching subexpressions of Plus and Times are discussed. \u2013\u00a0 Michael E2 Dec 24 '13 at 5:16\nadd comment\n\n1 Answer\n\nWhen it's not more complicated than your example, I do the replacement in the form\n\nc1 C1 c2 C2 c3 C3 c4 C4 /. {C1 -> F1 / c1, C2 -> F2 / c2, C3 -> F3 / c3, C4 -> F4 / c4}\n\nwith simplified patterns that avoid tricky issues of pattern-matching.\n\nThe trouble is that the FullForm of c1 C1 is Times[c1, C1] which on the face of it doesn't exactly match the FullForm of c1 C1 c2 C2 c3 C3 c4 C4, which is\n\nTimes[c1, C1, c2, C2, c3, C3, c4, C4]\n\nBut the pattern-matcher does match them and replaces only a subsequence of the arguments of Times. But since the Times expression has matched already, further rules are not applied. We're lucky (as users) that it matches once, but unlucky that it doesn't match repeatedly. That's why ReplaceRepeated (//.) works: it keeps applying the rules until there are no more matches. First rule will be applied the first time but not on subsequent tries since it will no longer match; and second on the second try, etc.\n\nshare|improve this answer\nNice explanation and recommendations! \u2013\u00a0 belisarius Dec 24 '13 at 13:31\nThanks a lot for such a nice explanation!! \u2013\u00a0 skippyho Dec 25 '13 at 6:01\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234775/troubles-proving-every-subset-of-a-finite-set-is-finite-with-naive-set-theory\nText:\nTake the 2-minute tour \u00d7\n\nIn a first undergraduate course in analysis, they have established a model of the natural numbers (without zero), proof by induction, recursive definition, injectivity, surjectivity, bijectivity of maps and elementary properties and the following definitions and facts:\n\n  \u2022 for every $m \\in \\mathbb{N}$ the set $A_m := \\{k \\in \\mathbb{N};\\ 1 \\leq k \\leq m\\}$,\n  \u2022 two sets $M$ and $N$ are equipotent if there is a bijection $f \\colon M \\to N$, written $M \\sim N$,\n  \u2022 a set $M$ is finite if it is empty or equipotent to $A_m$ for some $m \\in \\mathbb{N}$,\n  \u2022 $\\forall m, n \\in \\mathbb{N}\\colon A_m \\sim A_n \\Leftrightarrow m = n$,\n  \u2022 the cardinality of a finite nonempty set $M$ is $\\#M = m$, where $M \\sim A_m$, and\n  \u2022 every nonempty subset of the natural numbers has a minimal element.\n\nNow they have to prove that a subset of a nonempty finite set is again finite.\n\nI have to present a solution to them. It's clear that one can restrict this problem to:\n\nFor $m \\in \\mathbb{N}$ if $T \\subseteq A_m$, then there is a $n \\in \\mathbb{N},\\ n \\leq m: T \\sim A_n$.\n\nI tried to define $T_1 = T$ and for $k \\in \\mathbb{N}$ $T_{k+1} := T_k \\setminus \\{\\min T_k\\}$ if $T_k \\neq \\emptyset$ and $T_{k+1} := \\emptyset$ if $T_k = \\emptyset$. Now I want to prove that there is a $n \\in \\mathbb{N} \\colon T_{n+1} = \\emptyset$. This would make $A_n \\to T, k \\mapsto \\min T_k$ a bijection.\n\nHow can I proceed? I thought maybe one can use induction on the cardinality of the $T_k$, but I don't see it immediately and I have little time. One can try to show that for any $k \\in \\mathbb{N}$ the set $T_k$ is finite and if $T_k \\neq \\emptyset$, then $\\# T_{k+1} + 1 = \\#T_k$, but then what?\n\nshare|improve this question\nRemark: I'm a tutor, not a freshmen. : - ) I must say I find no reasonable level of rigour to prove this. \u2013\u00a0 k.stm Nov 11 '12 at 11:12\n+1 for clear question statement. \u2013\u00a0 akkkk Nov 11 '12 at 12:04\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nTo show that there is an $n$ such that $T_{n+1} = \\emptyset$, just note that $\\min ( T_k ) \\geq k$ (actually, $T_k \\cap A_{k-1} = \\emptyset$; an easy proof by induction), and so $T_{m+1}$ must be empty (if $T \\subseteq A_m$).\n\nI would personally proceed in a different fashion, and not bother so much in trying to exhibit a bijection. Instead, by induction show that for each $m$ every nonempty $T \\subseteq A_m$ is finite. The base case $m = 1$ is trivial. Suppose it is known for $m$, and let $T \\subseteq A_{m+1}$ be nonempty. There are three cases:\n\n  1. If $T = A_{m+1}$, then we're done.\n  2. If $m+1 \\notin T$, then actually $T \\subseteq A_m$, and we're done by hypothesis.\n  3. If $T \\neq A_{m+1}$ and $m+1 \\in T$, we can swap $m+1 \\in T$ out for something not in $T$ to get a subset $S \\subseteq A_m$ equipotent with $T$. (And so $T$ is equipotent with a finite set.)\nshare|improve this answer\nAh, thanks. Yes. That is much simpler, I've been blind. \u2013\u00a0 k.stm Nov 11 '12 at 11:44\nadd comment\n\nLet $f : k \\mapsto \\min T_k$.\n\nUse the fact that $b \\notin A \\setminus \\{b\\}$ and induction to prove that $\\min T_i = \\min T_j \\implies \\min T_j \\in T_i \\implies i = j$ (assuming $i \\geq j$) and thus that $f$ is an injection.\n\nUse the fact that $(A \\setminus \\{b\\}) \\cup \\{b\\} = A$ (assuming $b \\in A$) to prove that $\\bigcup \\{\\min T_i \\} = T$ and thus $f$ is a surjection.\n\nshare|improve this answer\nWhy is there a $m \\in \\mathbb{N}$ such that $T_{m+1} = \\emptyset$? \u2013\u00a0 k.stm Nov 11 '12 at 11:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/336429/in-this-cumulative-distribution-function-am-i-finding-the-wrong-term\nText:\nTake the 2-minute tour \u00d7\n\nQuestion I was given: Let V be a uniform random variable distributed over the interval (0,1). Let $\\ X = \\frac{1}{\\sqrt(U)}$. What is the cumulative distribution function and probability density function of X?\n\nI understand the basic concept here behind cumulative distribution functions and probability density functions. What's throwing me off here is the additional parameter saying that V is a uniform random variable.\n\nIs the cumulative distance function just: $\\ \\int\\limits_0^1 \\frac{1}{\\sqrt(V)}dV $ which would then just equal 2?\n\nThen the prob dens function would be: $$ \\frac{1}{\\sqrt(V)}-----0<V<1 $$ $$ 0------otherwise $$ This seems too simple to me to be the correct answer though. Am I missing something? Am I finding the cumulative distance function of V rather than of X?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nWe find the cumulative distribution function $F_X(x)$ of $X$. So we want to find $\\Pr(X\\le x)$.\n\nIf $x\\le 1$, then $F_X(x)=0$. For since $0\\lt U\\lt 1$, it is impossible for $\\dfrac{1}{\\sqrt{U}}$ to be $\\le 1$.\n\nNow we find $F_X(x)$ for $x\\gt 1$.\n\nWe have $X\\le x$ if and only if $\\dfrac{1}{\\sqrt{U}}\\le x$. Flip it over. So $X\\le x$ if and omly if $\\sqrt{U}\\ge \\dfrac{1}{x}$, that is, if and only if $U\\ge \\dfrac{1}{x^2}$.\n\nBut $\\Pr\\left(U\\ge \\dfrac{1}{x^2}\\right)=1-\\Pr\\left(U\\le \\dfrac{1}{x^2}\\right)$. Since $U$ is uniform, this is simply $1-\\dfrac{1}{x^2}$. Thus for $X\\gt 1$, $$F_X(x)= 1-\\frac{1}{x^2}.$$\n\nFor the density function $f_X(x)$, differentiate the cdf.\n\nshare|improve this answer\nWhich would just yield 2/X^3 for X>1 and 0 otherwise? \u2013\u00a0 chrisbster Mar 21 '13 at 2:24\nAnd thank you - that clarification was fantastic! \u2013\u00a0 chrisbster Mar 21 '13 at 2:24\nYou are welcome. Yes, the density function (for $x\\gt 1$) is $\\frac{2}{x^3}$. \u2013\u00a0 Andr\u00e9 Nicolas Mar 21 '13 at 2:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.newton.dep.anl.gov/newton/askasci/1993/math/MATH029.HTM\nText:\nNEWTON, Ask A Scientist!\nNEWTON Home Page NEWTON Teachers Visit Our Archives Ask A Question How To Ask A Question Question of the Week Our Expert Scientists Volunteer at NEWTON! Frequently Asked Questions Referencing NEWTON About NEWTON About Ask A Scientist Education At Argonne Spirals... Circles... Radius\nName: Name\nStatus: N/A\nAge: N/A\nLocation: N/A\nCountry: N/A\nDate: Around 1993\n\nQuestion: Is there any mathematical formula for determining the un-rolled length of a spiral? For instance, if I had a roll of ribbon that had a radius of two inches, and the ribbon was one sixteenth of an inch thick, how long would the ribbon be? If there is not a formula for it, what would be the best way to determine this?\n\nA very close approximation for this kind of spiral is to pretend that the roll of ribbon is a series of concentric circular loops of ribbon. Then, the length of each loop is 2 * pi * r, where r = the loop's radius and pi = 3.1415926...so the answer for your example would be: 2 * pi * (1/16 + 2/16 + 3/16 + ... + 32/16) = 2 * pi * 528/16. If the ribbon was on a spindle of radius, say, 1 inch, the sum would be (16/16 + 17/16 + ... + 32/16). An interesting related problem is find (and prove) a formula for ( 1 + 2 + 3 + ... + N ) John Hawley\n\nHere is another approach. If we assume that the ribbon is tightly wound up (i.e., no gaps between the layers of ribbon), then the volume occupied by the 'disk' of wound-up ribbon equals the volume of the unwound strip (a very flat and long 'box'). Let R denote the radius of the 'disk', T the thickness of the ribbon, L its unwound length (the quantity we want to compute), and W its width. The wound-up volume is pi*R^2*W (\"R^2 means \"R squared\"), and the unwound volume is L*W*T. Setting these equal and solving for L, we get L = pi*R^2/T. For the values given (R=2 in., T=1/16 in.), we get L = 64*pi (about 201) inches. By the way, your idea of using a spiral would work. One could write an equation (polar coordinates would be the easiest choice) for a curve that would lie within the ribbon-say, at mid- interior. There is a formula for length of a curve, using integral calculus. As it happens, the answer you get is the same as that obtained above. If you would like more details on this calculus approach, please ask (here or via e- mail).\n\nRon Winther\n\nClick here to return to the Mathematics Archives\n\n\n\nEducational Programs\nBuilding 360\n9700 S. Cass Ave.\nArgonne, Illinois\n60439-4845, USA\nUpdate: June 2012\nWeclome To Newton\n\nArgonne National Laboratory"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207415/second-countable-topological-space\nText:\nTake the 2-minute tour \u00d7\n\nI think I solved a problem from Lee's book and I just like to see if it has any mistake,\n\nProblem Let $X$ be a topological space and let $\\mathcal{U}$ be an open cover of $X$. Show that if $\\mathcal{U}$ is countable and each $U$ $\\in$ $\\mathcal{U}$ is second countable, then $X$ is second countable.\n\n\nFor each $U$ $\\in$ $\\mathcal{U}$, let $\\mathcal{B}_{U}$ be a countable basis for $U$. We have that the union $\\mathcal{B}$ of all such bases is countable and it's a basis for X. Indeed, each of them is open in X and, let $A$ be an arbitraty open set of $X$, we have that $A$ can be written as the union of all the intersections $A$$\\cap$$U$, for all $U$ $\\in$ $\\mathcal{U}$, each such intersection being written as a union of elements of $\\mathcal{B}_{U}$. Then $\\mathcal{B}$ is a countable basis for $X$.\n\nshare|improve this question\nYes, this is fine. \u2013\u00a0 Brian M. Scott Oct 4 '12 at 21:33\nThank you, Brian. =] \u2013\u00a0 Br09 Oct 4 '12 at 21:40\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe proof is fine.\n\nNote that it relies on the axiom of choice to prove that countable unions of countable sets are countable. But then again, topology without choice is a horror story anyway.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/26167/expectation-of-the-maximum-of-iid-geometric-random-variables/26214\nText:\nTake the 2-minute tour \u00d7\n\nGiven $n$ independent geometric random variables $X_n$, each with probability parameter $p$ (and thus expectation $E\\left(X_n\\right) = \\frac{1}{p}$), what is $$E_n = E\\left(\\max_{i \\in 1 .. n}X_n\\right)$$\n\nIf we instead look at a continuous-time analogue, e.g. exponential random variables $Y_n$ with rate parameter $\\lambda$, this is simple: $$E\\left(\\max_{i \\in 1 .. n}Y_n\\right) = \\sum_{i=1}^n\\frac{1}{i\\lambda}$$\n\n(I think this is right... that's the time for the first plus the time for the second plus ... plus the time for the last.)\n\nHowever, I can't find something similarly nice for the discrete-time case.\n\nWhat I have done is to construct a Markov chain modelling the number of the $X_n$ that haven't yet \"hit\". (i.e. at each time interval, perform a binomial trial on the number of $X_n$ remaining to see which \"hit\", and then move to the number that didn't \"hit\".) This gives $$E_n = 1 + \\sum_{i=0}^n \\left(\\begin{matrix}n\\\\i\\end{matrix}\\right)p^{n-i}(1-p)^iE_i$$ which gives the correct answer, but is a nightmare of recursion to calculate. I'm hoping for something in a shorter form.\n\nshare|improve this question\nIs there are typo there? How did $32$ get into it? \u2013\u00a0 joriki Mar 10 '11 at 8:58\nOh yes, whoops. This question arises from a concrete example, where n was 32. \u2013\u00a0 Rawling Mar 10 '11 at 9:04\nIs there a reason for the \"RV\" abbreviation? The main page has plenty of space for two lines... \u2013\u00a0 Uticensis Mar 10 '11 at 9:15\nForce of habit. I can now see all the other questions in \"Related\" with \"random variable\" in their titles :) \u2013\u00a0 Rawling Mar 10 '11 at 9:17\n\n3 Answers 3\n\nup vote 14 down vote accepted\n\nFirst principle:\n\nTo deal with maxima $M$ of independent random variables, use as much as possible events of the form $[M\\leqslant x]$.\n\nSecond principle:\n\nTo compute the expectation of a nonnegative random variable $Z$, use as much as possible the complementary cumulative distribution function $\\mathrm P(Z\\geqslant z)$.\n\nIn the discrete case, $\\mathrm E(M)=\\displaystyle\\sum_{k\\ge0}\\mathrm P(M>k)$, the event $[M>k]$ is the complement of $[M\\leqslant k]$, and the event $[M\\leqslant k]$ is the intersection of the independent events $[X_i\\leqslant k]$, each of probability $F_X(k)$. Hence, $$ \\mathrm E(M)=\\sum_{k\\geqslant0}(1-\\mathrm P(M\\leqslant k))=\\sum_{k\\geqslant0}(1-\\mathrm P(X\\leqslant k)^n)=\\sum_{k\\geqslant0}(1-F_X(k)^n). $$ The continuous case is even simpler. For i.i.d. nonnegative $X_1$, $X_2$, ..., $X_n$, $$ \\mathrm E(M)=\\int_0^{+\\infty}(1-F_X(t)^n)\\mathrm{d}t. $$\n\nshare|improve this answer\nThese are very nice principles. I'd just add that what Didier has called \"repartition function\" is called \"cumulative distribution function\" in English. \u2013\u00a0 Michael Lugo Mar 10 '11 at 19:27\n@Michael Thanks, post modified. \u2013\u00a0 Did Mar 10 '11 at 21:01\n@Did sorry to bother you over such an old answer but I am unclear on what F_X(k) is. For a geometric distribution of parameter p, I think it is the c.d.f. or (1-(1-p)^{k+1}). Is this correct? \u2013\u00a0 Dale M Apr 2 '13 at 1:52\n@DaleM If $P(X=k)=p(1-p)^k$ for every $k\\geqslant0$, yes. \u2013\u00a0 Did Apr 2 '13 at 5:08\n\nThere is no nice, closed-form expression for the expected maximum of IID geometric random variables. However, the expected maximum of the corresponding IID exponential random variables turns out to be a very good approximation. More specifically, we have the hard bounds\n\n$$\\frac{1}{\\lambda} H_n \\leq E_n \\leq 1 + \\frac{1}{\\lambda} H_n,$$ and the close approximation $$E_n \\approx \\frac{1}{2} + \\frac{1}{\\lambda} H_n,$$ where $H_n$ is the $n$th harmonic number $H_n = \\sum_{k=1}^n \\frac{1}{k}$, and $\\lambda = -\\log (1-p)$, the parameter for the corresponding exponential distribution.\n\nHere's the derivation. Let $q = 1-p$. Use Did's expression with the fact that if $X$ is geometric with parameter $p$ then $P(X \\leq k) = 1-q^k$ to get\n\n$$E_n = \\sum_{k=0}^{\\infty} (1 - (1-q^k)^n).$$\n\nBy viewing this infinite sum as right- and left-hand Riemann sum approximations of the corresponding integral we obtain\n\n$$\\int_0^{\\infty} (1 - (1 - q^x)^n) dx \\leq E_n \\leq 1 + \\int_0^{\\infty} (1 - (1 - q^x)^n) dx.$$\n\nThe analysis now comes down to understanding the behavior of the integral. With the variable switch $u = 1 - q^x$ we have\n\n$$\\int_0^{\\infty} (1 - (1 - q^x)^n) dx = -\\frac{1}{\\log q} \\int_0^1 \\frac{1 - u^n}{1-u} du = -\\frac{1}{\\log q} \\int_0^1 \\left(1 + u + \\cdots + u^{n-1}\\right) du $$ $$= -\\frac{1}{\\log q} \\left(1 + \\frac{1}{2} + \\cdots + \\frac{1}{n}\\right) = -\\frac{1}{\\log q} H_n,$$ which is exactly the expression the OP has above for the expected maximum of $n$ corresponding IID exponential random variables, with $\\lambda = - \\log q$.\n\nThis proves the hard bounds, but what about the more precise approximation? The easiest way to see that is probably to use the Euler-Maclaurin summation formula for approximating a sum by an integral. Up to a first-order error term, it says exactly that\n\n$$E_n = \\sum_{k=0}^{\\infty} (1 - (1-q^k)^n) \\approx \\int_0^{\\infty} (1 - (1 - q^x)^n) dx + \\frac{1}{2},$$ yielding the approximation $$E_n \\approx -\\frac{1}{\\log q} H_n + \\frac{1}{2},$$ with error term given by $$\\int_0^{\\infty} n (\\log q) q^x (1 - q^x)^{n-1} \\left(x - \\lfloor x \\rfloor - \\frac{1}{2}\\right) dx.$$ One can verify that this is quite small unless $n$ is also small or $q$ is extreme.\n\nAll of these results, including a more rigorous justification of the approximation, the OP's recursive formula, and the additional expression $$E_n = \\sum_{i=1}^n \\binom{n}{i} (-1)^{i+1} \\frac{1}{1-q^i},$$ are in Bennett Eisenberg's paper \"On the expectation of the maximum of IID geometric random variables\" (Statistics and Probability Letters 78 (2008) 135-143).\n\nshare|improve this answer\nIs the log here based 2 or mathematical constant? \u2013\u00a0 Fan Zhang Apr 2 '12 at 4:35\n@FanZhang: It's log base $e$. \u2013\u00a0 Mike Spivey Apr 2 '12 at 13:59\n\n$$\\begin{align} P(\\max Y_i=k)&=P(\\max Y_i\\leq k)-P(\\max Y_i<k)\\\\\\\\&=F(k)^n-(F(k)-f(k))^n. \\end{align}$$ Thus $$\\begin{align} E(\\max Y_i) &= \\sum_{k=0}^{\\infty} k\\left[F(k)^n-(F(k)-f(k))^n\\right] \\\\\\\\ &=\\sum_{k=1}^{\\infty}k\\left[\\left(1-(1-p)^k\\right)^n-\\left(1-(1-p)^{k-1}\\right)^n\\right]. \\end{align}$$\n\nNot a closed form though.\n\nSee also Order statistic for both continuous and discrete case. The formula for the continuous case appears in Shai Covo's post here.\n\nshare|improve this answer\nVery nice. No recursion required to calculate, works with any distribution, and gives me a whole new concept to look into. I'll have to try with the continuous case to see if it gives me the same answer as I have above. \u2013\u00a0 Rawling Mar 10 '11 at 9:48\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/94105/find-the-limit-of-a-sequence-defined-as-solution-to-equation\nText:\nTake the 2-minute tour \u00d7\n\nWe can easily prove that the equation of variable $x$ $$(E_{n}): \\frac{x(\\ln x)^n}{1+x}=\\frac{e}{2(e+1)}$$ has a unique solution $u_{n}$ in $[1,e]$ for all integers $n$ greater than $1$. Let's call it $u_{n}$.\n\nCan you help me prove that\n\n$$\\lim_{n \\to \\infty} (\\ln u_{n})^n=\\frac{1}{2}$$\n\n\nNote : This is a homework question. The general question which we aim to prove is that there exists a sequence $(\\varepsilon_{n})_{n \\geq 2} $ tending to $0$ and satisfying for all $n \\geq 2$ : $u_{n}=e-\\frac{e}{2n}+\\frac{1}{n}\\varepsilon_{n}$. I have been able to prove that $\\varepsilon_{n}=n(u_{n}-e)+\\frac{e}{2}$ and answering the question I am asking would allow me to prove that $\\lim_{n \\to \\infty}n(u_{n}-e)=-\\frac{e}{2}$ (since I know that $\\lim_{n \\to \\infty}\\frac{(\\ln u_{n})^n-1}{n(u_{n}-e)}=\\frac{1}{e}$ from a previous question). Hope it's not too unclear. Thank you.\n\nshare|improve this question\nWhat you seek to prove is equivalent to the fact that $u_n\\to\\mathrm e$. Can you show that $u_n\\gt v$ for $n$ large enough, for every $v\\lt\\mathrm e$? \u2013\u00a0 Did Dec 25 '11 at 20:46\nWell, this is something I have actually already proved ! But how can it help me ? \u2013\u00a0 user20010 Dec 25 '11 at 22:26\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYou said in comments that you were able to show that $u_n\\to\\mathrm e$. Since there exists a nonzero constant $c$ such that, for each $n$, equation $(E_n)$ reads as $(\\log u_n)^n=c\\cdot(1+u_n)/u_n$, the asymptotics $(\\log u_n)^n\\to c\\cdot(1+\\mathrm e)/\\mathrm e$ follows.\n\nshare|improve this answer\nThank you. How stupid I am ! \u2013\u00a0 user20010 Dec 26 '11 at 18:22\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/104946/poisson-process-courts?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nIITK sports facility has $4$ tennis courts. Players arrive at the courts at a Poisson rate of one pair per $10$ min and use a court for an exponentially distributed time with mean $40$ min. Suppose that a pair of players arrives and finds all courts busy and $k$ other pairs waiting in queue. How long will they have to wait to get a court on the average?\n\nshare|improve this question\n\n1 Answer 1\n\nThey need to wait for $k+1$ pairs to finish before they can start.\n\nSince the exponential distribution is memoryless, the expected time for a given pair to finish once started is $40$ minutes, and there are four courts, the expected time for any of the four courts to finish is $\\frac{40}{4}=10$ minutes, and so their expected waiting time is $10(k+1)$ minutes.\n\nSlightly more worryingly, since the service rate of the courts is equal to the arrival rate, the expected waiting time (in effect summing over $k$ weighted by the probability that there are $k$ queuing at any one time) is infinite.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1815268/how-might-i-solve-the-following-equation\nText:\n$$x * 0.98^{\\sqrt x / 321868} = 9.46 * 10^8$$\n\nI mean is there any way to do this algebraically? There's a single variable, but I don't know of any way to manipulate it such that I can get x on one side -- or even get it out of the exponent, since I can't take the log base 0.98 of the right hand side over a variable...\n\n  \u2022 $\\begingroup$ You can't do it algebraically. $\\endgroup$ Jun 6 '16 at 1:25\n  \u2022 $\\begingroup$ You're right. Is there even a solution? Wolfram $\\endgroup$\n    \u2013\u00a0rb612\n    Jun 6 '16 at 1:27\n  \u2022 $\\begingroup$ Lol it timed out...even with extended computing time $\\endgroup$\n    \u2013\u00a0James\n    Jun 6 '16 at 1:38\n  \u2022 1\n    $\\begingroup$ I think there is a solution. I wrote a program to plug in one x and get the other. I find that 9.4783 * 10^8 works. Of course this is limited precision, and it's not what OP asked for. $\\endgroup$ Jun 6 '16 at 1:52\n\nAny equation which can write as $$A+Bx+C\\log(D+Ex)=0$$ shows solutions which can be expressed in terms of Lambert function.\n\nFor the case of $$x\\, a^{b \\sqrt{x}}=c$$ the solution is given by $$x=\\frac{4 W\\left(\\pm\\frac{1}{2} b \\sqrt{c} \\log (a)\\right)^2}{b^2 \\log ^2(a)}$$ where $W(z)$ denotes Lambert function.\n\nFor your values of $a,b,c$, this will give, as roots, $x_1\\approx 9.4783\\times 10^8$ and $x_2 \\approx 8.5147\\times 10^{16}$.\n\nIn your specific case, the value of the argument is quite small $(z\\approx -0.000965267)$ and you can use the approximation around $z=0$ given in the Wikipedia page $$W(z)=z-z^2+\\frac{3 z^3}{2}-\\frac{8 z^4}{3}+\\frac{125 z^5}{24}+O\\left(z^6\\right)$$\n\nFrom a practical point of view, since you handle very large numbers, I would suggest, for a better scaling, some preliminary change of variable such as $$\\frac{\\sqrt{x}}{321868}=y\\implies x=103599009424 y^2$$ which would reduce the equation to $$y^2 \\times \\left(\\frac{49}{50}\\right)^y=\\frac{59125000}{6474938089}$$ and, taking logarithms, consider the plot of function $$f(y)=2\\log(y)+y \\log\\left(\\frac{49}{50}\\right)-\\log\\left(\\frac{59125000}{6474938089}\\right)$$\n\n$f'(y)$ cancels at $y_*=\\frac{2}{\\log \\left(\\frac{50}{49}\\right)}\\approx 98.9966$ and $f(y_*)\\approx 11.8862$. $f''(y)$ being negative for all $y$, $y_*$ corresponds to a maximum and two roots are expected. Graphing the function to locate more or less the roots, then Newton method will lead to solutions $y_1\\approx 0.0956505$ and $y_2\\approx 906.582$. From here, go back to the solutions for $x$.\n\n  \u2022 $\\begingroup$ Woah - cool solution $\\endgroup$\n    \u2013\u00a0James\n    Jun 6 '16 at 4:43\n  \u2022 $\\begingroup$ @James. This is a fantastic function with a lot of applications. Search on this site. You will find plenty of problems using Lambert function. $\\endgroup$ Jun 6 '16 at 4:45\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/257313/when-do-27-lines-lie-on-a-cubic-surface/257593\nText:\nConsider $27$ (pairwise distinct!) lines in $\\mathbb{P}^3$ whose intersection graph is that expected\u00b9 of the $27$ lines on a smooth cubic surface. Question: Is there a simple necessary and sufficient condition for these $27$ lines to indeed lie on a smooth cubic surface?\n\nFor a long time I thought this was always the case, but there is at least one obvious necessary condition\u00b2:\n\n(T) Whenever three lines pairwise intersect (i.e., are pairwise coplanar), all three lie on a common plane.\n\n(Because the plane through two mutually intersecting lines on a cubic surface cuts the surface as the union of three distinct lines. There are $45$ such tritangent planes on the cubic surface.)\n\nIs this condition (T) sufficient?\n\nFurther comment and bonus question: The locally closed subvariety of $\\mathrm{Gr}(2,4)^{27}$ (or $\\mathrm{Sym}^{27}(\\mathrm{Gr}(2,4))$) consisting of configurations of $27$ lines satisfying the incidence conditions (made explicit in note\u00a0(1) below) is not irreducible (because of the first sentence of note\u00a0(2) below). What are its irreducible components?\n\n\n  1. I.e., we can label the lines as $a_1,\\ldots,a_6$, $b_1,\\ldots,b_6$ and $c_{12},\\ldots,c_{56}$ (the latter indexed by the $15$ unordered pairs in $\\{1,\\ldots,6\\}$) such that the $a_i$ mutually don't intersect, the $b_i$ mutually don't intersect, each $a_i$ intersects each $b_j$ except exactly when $i=j$, the $c_{ij}$ intersect exactly when their index pairs are disjoint, and $c_{ij}$ intersects exactly $a_i,a_j,b_i,b_j$ among the $a_k$ and $b_k$. Equivalently, the intersection graph is the complement of the vertex graph of the Gosset $2_{21}$ polytope. Equivalently, the faithful transitive action of $W(E_6)$ on $27$ elements where the incidence relation is given by the orbit on the unordered pairs such that every line is incident to exactly $10$ others.\n\n  2. Three distinct mutually intersecting lines in $\\mathbb{P}^3$ either lie on a common plane or, dually, meet at a common point. (Apologies for pointing out something so obvious, but I'm sure I'm not the only one who might have missed this trivial fact.) If we take the $27$ lines on a smooth cubic surface $X$ and dualize (i.e., replace them by their polars w.r.t. some fixed nondegenerate quadric), we get another configuration of $27$ lines (lying on the projective dual $X^\\vee$ to the cubic surface) which have $45$ points of intersection of triples of lines, but in general (unless $X$ had some Eckardt points) no planes in which three lines lie; so this configuration does not lie on a cubic surface (and indeed, $X^\\vee$ is not a cubic surface).\n\n  \u2022 2\n    $\\begingroup$ there is something I don't understand in the last paragraph: in the configuration of the 27 lines on the cubic there are just 45 points of (triple) intersection, not 135. $\\endgroup$ Dec 16 '16 at 0:19\n  \u2022 $\\begingroup$ I agree with Dima Pasechnik: there are 45 2-planes that intersect the cubic surface in a \"triangle\", not 135. $\\endgroup$ Dec 16 '16 at 12:38\n  \u2022 $\\begingroup$ Indeed, I miscounted (135 is the number of pairs of intersecting lines, so it counts every tritangent plane three times). Fixed. $\\endgroup$\n    \u2013\u00a0Gro-Tsen\n    Dec 19 '16 at 16:08\n\nIt turns out that condition (T) is, indeed, sufficient for the $27$ lines (distinct and intersecting as expected) to lie on a cubic surface.\n\nTo see this, consider the lines $a_1,a_2,a_3,a_4,a_5$ and $b_6$, where the labeling is as in note\u00a0(2) of the question: $a_1$ through $a_5$ are pairwise skew, and $b_6$ intersects all of them. Choose $4$ distinct points on $b_6$, and $3$ distinct points on each of $a_1$ through $a_5$ also distinct from the intersection point with $b_6$: this makes $4+5\\times3=19$ points in total; since there are $20$ coefficients in a cubic form on $4$ variables, there exists a cubic surface $S$ passing through these $19$ points. Since $S$ contains four distinct points on $b_6$, it contains $b_6$ entirely, and since it contains four points (viz., the intersection with $b_6$ and the three additional chosen points) on each of $a_1$ through $a_5$, it contains these also.\n\nNow $b_1$ intersects the four lines $a_2$ through $a_5$ in four distinct points since $a_2$ through $a_5$ are pairwise skew; and since these four points lie on $S$, it follows that $b_1$ lies entirely on\u00a0$S$; similarly, $b_2$ through $b_5$, and finally $a_6$ (which intersects $b_1$ through\u00a0$b_5$ in distinct points), all lie on\u00a0$S$. So $S$ contains the \"double-six\" $\\{a_1,\\ldots,a_6,b_1,\\ldots,b_6\\}$.\n\nSo far, property (T) has not been used, only the incidence relation. Now it remains to see that the $c_{ij}$ lie on $S$. Consider the intersection line $\\ell$ of the planes $a_i\\vee b_j$ (spanned by $a_i$ and $b_j$) and $a_j\\vee b_i$ (spanned by $a_j$ and $b_i$; these planes are well-defined since $a_i$ meets $b_j$ and $a_j$ meets $b_i$, and they are distinct since $a_i$ and $a_j$ are skew): this line $\\ell$ must be equal to the $c_{ij}$ of the given configuration, because $c_{ij}$ intersects both $a_i$ and $b_j$ so property (T) implies that it lies in the plane $a_i\\vee b_j$, and similarly it lies in the plane $a_j\\vee b_i$. But $\\ell$ also lies on\u00a0$S$ for similar reasons\u00b9, in other words, $c_{ij}$ lies on\u00a0$S$, and all the given lines lie on\u00a0$S$.\n\nFinally, $S$ must be smooth because it contains the configuration of $27$ lines expected of a smooth cubic surface (it is easy to rule out the case where $S$ is a cubic cone, a reducible surface or a scroll by considering the intersecting and skew lines in the double-six; and every configuration where $S$ has double point singularities has fewer than $27$ lines).\n\n  1. Let me be very precise here, because at this stage we don't know whether $S$ is smooth (so we can't invoke (T) directly on\u00a0$S$). We have four distinct lines $a_i,a_j,b_i,b_j$ on $S$ such that $a_i$ meets $b_j$ and $a_j$ meets $b_i$ and all other pairs are skew. Call $\\pi := a_i\\vee b_j$ and $\\pi' := a_j \\vee b_i$ the planes generated by the two pairs of concurrent lines, and $\\ell := \\pi\\wedge\\pi'$ their intersection. We want to show that $\\ell$ lies on the surface\u00a0$S$. If $\\pi$ or $\\pi'$ is contained in\u00a0$S$ (reducible) then the conclusion is trivial, so we can assume this is not the case. So the (schematic) intersection of $S$ with the plane $\\pi$ is a cubic curve containing two distinct lines ($a_i$ and $b_j$), so it is the union of three lines: $a_i$, $b_j$ and a third line\u00a0$m$ (a priori possibly equal to one of the former). Consider the intersection point of $a_j$ and $\\pi$ (which is well-defined since $a_j$ is skew with $a_i$ so does not lie in\u00a0$\\pi$): it lies on $\\ell$ because it is on both $\\pi$ and $\\pi'$; and it must also lie on $m$ since it is on $\\pi$ but neither on $a_i$ nor on $b_j$ (as the two are skew with\u00a0$a_j$); similarly, the intersection point $b_i\\wedge\\pi$ is well-defined and lies on both $\\ell$ and $m$; so $\\ell=m$ lies on $S$ (and we are finished) unless perhaps the two intersections considered are equal, i.e., $a_j,b_i,\\pi$ concur at a point $P$, necessarily on $m$. Assume the latter case: $S$ must be singular at $P$ because the line $m$ through $P$ does not lie on the plane $\\pi'$ generated by two lines ($a_j,b_i$) through\u00a0$P$ (i.e., we have three non-coplanar tangent directions at\u00a0$P$). Now symmetrically, if we call $m'$ the third line of the intersection of $S$ with $\\pi'$ (besides $a_j$ and $b_i$), we are done unless $a_i,b_j,\\pi'$ concur at a point $P'$, necessarily on $m'$ and necessarily singular on $S$. The points $P$ and $P'$ are distinct because $a_i$ and $a_j$ are skew; and they are on $\\ell$ because they are on $\\pi$ and\u00a0$\\pi'$; and the line joining two singular points on a cubic surface lies on the surface, so $\\ell = P\\vee P'$ lies on\u00a0$S$ in any case. (Phew!)\n\nWhat I still don't know is whether there are configurations of $27$ distinct lines with the expected incidence relations and which satisfy neither condition (T) nor its dual (viz., whenever three lines pairwise meet, all three meet at a common point), and in particular, what are the irreducible components of the space of configurations. (I also don't know if there is a way to substantially simplify the tedious argument given in note\u00a0(1) above.)\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/2298/how-do-i-force-re-evaluation-of-a-defvar?noredirect=1\nText:\nSuppose I have an Emacs lisp buffer that contains:\n\n(defvar foo 1)\n\nIf I call eval-last-sexp or eval-buffer, foo is bound to 1. If I then edit this buffer to:\n\n(defvar foo 2)\n\neval-last-sexp and eval-buffer do not re-execute this line, so foo is still 1.\n\nThis is particularly challenging when there are multiple such statements and I have to track down which lines are not being re-evaluated.\n\nI looked at just restarting Emacs and then (require 'foo), but then I have to be careful to avoid loading any older .elc files.\n\nHow can I be absolutely, positively sure that the variables and functions defined in the current file are in the same state as loading code afresh in a new Emacs instance?\n\n  \u2022 You cannot be \"absolutely, positively sure that Emacs is in a state that is the same as loading the code afresh in a new Emacs instance\" without doing just that. If you want to be sure only wrt this and other global variables, then you can remove their values using makunbound and then re-evaluate the code in the buffer.\n    \u2013\u00a0Drew\n    Oct 17 '14 at 21:30\n  \u2022 Sure, side effects like (silly code) (incf emacs-major-version) I can live with happening repeatedly. I'm interested in hacking on code with lots of defvar forms. Oct 17 '14 at 21:36\n\nAs explained in other answers, evaluating a defvar form using eval-last-sexp does not reset the default value.\n\nInstead, you can use eval-defun (bound to C-M-x in emacs-lisp-mode by default), which implements the behaviour you want as a special exception:\n\nIf the current defun is actually a call to defvar or defcustom, evaluating it this way resets the variable using its initial value expression even if the variable already has some other value. (Normally defvar and defcustom do not alter the value if there already is one.)\n\nIf you need to evaluate the full contents of a buffer, you can write a function that walks the top-level forms in turn and calls eval-defun on each. Something like this should work:\n\n(defun my/eval-buffer ()\n  \"Execute the current buffer as Lisp code.\nTop-level forms are evaluated with `eval-defun' so that `defvar'\nand `defcustom' forms reset their default values.\"\n    (goto-char (point-min))\n    (while (not (eobp))\n      (eval-defun nil))))\n  \u2022 6\n    This is the answer. No need for fake defvars or extra setqs. Just use eval-defun instead of eval-last-sexp . You can even write a function that calls eval-defun on every form in the buffer, and use it instead of eval-buffer.\n    \u2013\u00a0Malabarba\n    Oct 17 '14 at 19:06\n  \u2022 1\n    @Malabarba This post falls far short of answering the question. Use eval-defun instead of eval-last-sexp, sure, but the difficulty is for eval-buffer. Oct 17 '14 at 21:17\n  \u2022 @Gilles yes, you're right. I added a tentative implementation of @Malabara's idea of calling eval-defun on every top-level form in the buffer. Oct 17 '14 at 21:41\n  \u2022 1\n    This approach does not seem to work if the defvar is not inside a defun. Example: (progn (defvar foo \"bar\")). Mar 13 '15 at 15:01\n  \u2022 2\n    @kaushalmodi The latter examples that you cite (variables storing regular expressions) look a lot like candidates for defconst (which is always re-evaluated). There's recently been a very enlightening post on this topic in endless parentheses Mar 13 '15 at 21:07\n\nLike the other answers say, this is just the way defvar works, but you can get around it, this is elisp after all.\n\nYou can temporarily redefine how defvar works if you'd like and during that time, reload the packages you'd like to reset.\n\nI wrote a macro where during the evaluation of the body, defvars values will always be reevaluated.\n\n(defmacro my-fake-defvar (name value &rest _)\n  \"defvar impersonator that forces reeval.\"\n  `(progn (setq ,name ,value)\n\n(defmacro with-forced-defvar-eval (&rest body)\n  \"While evaluating, any defvars encountered are reevaluated\"\n  (declare (indent defun))\n  (let ((dv-sym (make-symbol \"old-defvar\")))\n    `(let ((,dv-sym (symbol-function 'defvar)))\n             (fset 'defvar (symbol-function 'my-fake-defvar))\n         (fset 'defvar ,dv-sym)))))\n\nExample Usage:\n\n\n(defvar my-var 10)\n\n\n  (load-file \"file_a.el\")\n  (assert (= my-var 10))\n  (setq my-var 11)\n  (assert (= my-var 11)\n  (load-file \"file_a.el\")\n  (assert (= my-var 10))\n\nNote: This this should only be used for the purpose of reevaluating defvars, as it just ignores docstrings when reevaluating. You can modify the macro to support re-evaluating that applies docstrings as well, but I will leave that up to you.\n\nIn your case you could do\n\n(with-forced-defvar-eval (require 'some-package))\n\nBut know what those who write elisp do so expecting defvar to work as specified, it could be they use defvar to define and setq in some init function to specify the value, so you may end up nil'ing variables you don't intend but this is probably rare.\n\nAlternative Implementation\n\nUsing this you can just redefine defvar globally and control whether or not it will set the symbol's value to the INIT-VALUE arg even if the symbol is defined by changing the value of the new defvar-always-reeval-values symbol.\n\n;; save the original defvar definition\n(fset 'original-defvar (symbol-function 'defvar))\n\n(defvar defvar-always-reeval-values nil\n  \"When non-nil, defvar will reevaluate the init-val arg even if the symbol is defined.\")\n\n(defmacro my-new-defvar (name &optional init-value docstring)\n  \"Like defvar, but when `defvar-always-reeval-values' is non-nil, it will set the symbol's value to INIT-VALUE even if the symbol is defined.\"\n     (when defvar-always-reeval-values (condition-case nil\n         (makunbound ',name)\n       (error nil)))\n     (original-defvar ,name ,init-value ,docstring)))\n\n;; globally redefine defvar to the new form\n(fset 'defvar (symbol-function 'my-new-defvar))\n  \u2022 1\n    I'm not sure redefining the behaviour of defvar is a good idea: there are several different possible uses of defvar, with slightly different semantics. For example, one use your macro doesn't account for is the (defvar SYMBOL) form, which is used to tell the byte-compiler about the existence of a variable without setting a value. Oct 17 '14 at 19:07\n  \u2022 If you absolutely need to redefine defvar with a macro, you would probably be better off prefixing the original defvar form with a makunbound, rather than replacing it by setq. Oct 17 '14 at 19:11\n  \u2022 Yes, it is a terrible idea, and should only be used for things like reevaluting the defvars of a loaded package in your scratch buffer, you should never ship something like this. Oct 17 '14 at 19:12\n  \u2022 @Francesco also you are right about the makunbound version, I had implemented that but strayed away from the idea, I have put that code on my answer as an alternative. Oct 17 '14 at 19:15\n  \u2022 In case anyone runs across this answer and wonders why my-new-defvar might crash your Emacs, it's because if the symbol being passed is already void (like from a fresh Emacs restart) and makunbound gets involved, it throws an error (and coincidentally crashed Emacs for me). Wrap the makunbound call in a condition-case to catch that error.\n    \u2013\u00a0David\n    Nov 29 '21 at 1:29\n\nThe defvar is being evaluated and doing exactly what you've specified. However, defvar only sets an initial value:\n\nThe optional argument INITVALUE is evaluated, and used to set SYMBOL, only if SYMBOL's value is void.\n\nSo to achieve what you want you would either need to unbind the variable before re-evaluating, e.g.\n\n(makunbound 'foo)\n\nor use setq to set the value, e.g.\n\n(defvar foo nil \"My foo variable.\")\n(setq foo 1)\n\nIf you don't need to specify a docstring here you can skip the defvar altogether.\n\nIf you really want to use defvar and automatically unbind this, you will need to write a function to find defvar calls in the current buffer (or region, or last sexp, etc); call makunbound for each one; and then do the actual eval.\n\n  \u2022 I was off playing with an eval-buffer wrapper that would unbind everything first, but @Francesco's answer about eval-defun is really what you want.\n    \u2013\u00a0glucas\n    Oct 17 '14 at 19:22\n\nThe following macro was created by tracing eval-defun to its supporting functions and modifying it so that it is no longer necessary to evaluate a region of a particular buffer. I needed help in the related thread Converting an expression to a string, and @Tobias came to the rescue -- teaching me how to convert the imperfect function into a macro. I don't think we need eval-sexp-add-defvars to precede elisp--eval-defun-1, but if someone thinks that is important, please let me know.\n\n;;;   (defvar-reevaluate\n;;;     (defvar undo-auto--this-command-amalgamating \"hello-world\"\n;;;     \"My new doc-string.\"))\n\n(defmacro defvar-reevaluate (input)\n\"Force reevaluation of defvar.\"\n  (let* ((string (prin1-to-string input))\n        (form (read string))\n        (form (elisp--eval-defun-1 (macroexpand form))))\n\nThe problem is not that the line is not getting re-evaluated. The problem is that defvar defines a variable and its default value. If a variable already exists, then changing its default value does not modify the current value. Unfortunately, I think you will need to run a setq for every variable whose value you wish to update.\n\nThis may be overkill, but you could update your file like this if you want to be able to easily update foo to its new default value.\n\n(defvar foo 2)\n(setq foo 2)\n\nbut that requires that you maintain the default value in two places in your code. You could also do this:\n\n(makunbound 'foo)\n(defvar foo 2)\n\nbut if there is a chance that foo is declared elsewhere you may have some side effects to deal with.\n\n  \u2022 That's difficult when trying to test changes to a complex mode. I'd rather not change the code. eval-defun treats defvar specially, so surely there's something similar for whole buffers? Oct 17 '14 at 18:49\n  \u2022 @WilfredHughes I'm not sure what you mean by \"something for whole buffers.\" You want a single function that will makunbound any variables declared in the current buffer, and then re-evaluate it? You could write your own, but I don't think that there is an out-of-the-box function for this. EDIT: Never mind, I get what you are saying. An eval-defun that works on the whole buffer. It looks like @JordonBiondo has your solution for that.\n    \u2013\u00a0nispio\n    Oct 17 '14 at 18:53\n  \u2022 No. The problem is lack of re-evaluation: defvar does nothing if the variable already has a value (as its doc says: The optional argument INITVALUE is evaluated, and used to set SYMBOL, only if SYMBOL's value is void.). The problem is not that defvar changes the default value and not the current value. (defvar a 4) (default-value 'a) (setq a 2) (default-value 'a); then C-x C-e after the defvar sexp; then (default-value 'a). C-x C-e, eval-region, and the like on a defvar sexp do not change the default value.\n    \u2013\u00a0Drew\n    Oct 17 '14 at 20:40\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/45405/highlight-current-line-in-gud-disassembler-window/45410\nText:\nI am using GUD for debugging C code. Because many of the lines and variables have been optimized away, it is necessary to follow the C source and the corresponding disassembly simultaneously. I want the current line in the disassembler window to be highlighted each time I \"step instruction.\" Right now the cursor moves automatically, in the disassembler window, but hl-line-mode does not highlight the line that the cursor moved to. If I switch to that window, the new line gets highlighted, and remains highlighted when I move away from that window again. But each time I step, the highlighting from hl-line-mode disappears in the inactive window.\n\nHow can I get a good visual indication of the \"current line\" in the disassembler window? The tiny triangle in the fringe is not enough, because the lines are quite long, and it is difficult to tell at a glance which instruction will be executed next.\n\n  \u2022 Wherever you see gud-overlay-arrow-position (make-marker) ... set-marker, you can put something after that location using (marker-position gud-overlay-arrow-position) as the point at which to update hl-line-mode or other gizmo that suits your needs. I see two (2) locations in the version I am using: gud-display-line and gdb-frame-handler. However, I have limited experience using gdb and am unfamiliar with terms such as disassembler and step instruction ... Therefore, I am unable to write up an answer because I cannot test it myself.\n    \u2013\u00a0lawlist\n    Oct 16 '18 at 18:33\n  \u2022 Thanks, @lawlist. I tried this and found out that the gud-overlay-arrow-position is different from the gdb-disassembly-position overlay. Interestingly the gud-display-line function already has special handling for hl-line-mode, so regular source buffers already work as expected with hl-line-mode, even when the source buffer is not the active window. (re-reading this comment right after typing it, I realize that it might be more confusing than anything.)\n    \u2013\u00a0nispio\n    Oct 16 '18 at 21:57\n\nThanks to @lawlist nudging me into the source code, I found out that gdb mode will highlight the line for me, but only on the condition that the window containing the disassembly does not have fringes. The following was enough to make that happen:\n\n;; Enable automatic highlighting of the active line in disassembly window\n(defun nispio/disable-window-fringes () (set-window-fringes nil 0 0))\n(add-hook 'gdb-disassembly-mode-hook #'nispio/disable-window-fringes)\n\nBecause I usually pop the disassembly window out into a separate frame, this is okay. Otherwise, it would disable the fringes on some semi-arbitrary window.\n\n\nThis is the solution I came up with using hl-line. I needed to advise the function that updates the disassembly buffer and invoke hl-line-highlight directly to make it work.\n\n(defadvice gdb-disassembly-handler-custom\n    (after nispio/ad-after-disas-handler-hl-line activate)\n  \"Make sure that `hl-line' gets updated after updating disassembly buffer\"\n  (let* ((buffer (gdb-get-buffer 'gdb-disassembly-buffer))\n         (window (get-buffer-window buffer 0)))\n    (when (and window (featurep 'hl-line))\n      (with-current-buffer buffer\n          (goto-char gdb-disassembly-position)\n         ((and hl-line-mode hl-line-sticky-flag)\n          (goto-char gdb-disassembly-position)\n\n(add-hook 'gdb-disassembly-mode-hook #'hl-line-mode)\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/choosing-whats-integrated.150659/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nChoosing what's integrated\n\n  1. Jan 9, 2007 #1\n    Sorry for the undescriptive title, but I couldn't think of a better one.\n\n    My question is essentially this: is the following procedure correct?\n\n    a=-kx and we want v.\n\n    Multiply both sides by v to get:\n\n    [tex] \\frac {d^2x} {dt^2} * \\frac {dx} {dt} = -kx *\\frac {dx} {dt} [/tex]\n\n    Now, by dt, and some rearranging :\n\n    [tex] (\\frac {d^2x} {dt^2} dt) * \\frac {dx} {dt} = -kx *dx [/tex]\n\n    And the step which I'm not convinced can be done:\n\n    [tex]( \\int \\frac {d^2x} {dt^2} dt) * \\frac {dx} {dt} = -k \\int x *dx [/tex]\n\n    and so we end up with v^2 = -(kx^2)/2 +c which is but an errant 1/2 away from what I need.\n\n    I just don't trust integrating a wrt t, while having a v just sitting there as if it were a constant. The only reason that I haven't already disregarded it is that it checks out if you analyse the dimensions...\n  2. jcsd\n  3. Jan 9, 2007 #2\n\n\n    User Avatar\n    Homework Helper\n\n    No, that's not right. As you mention, you're treating v as a constant, and it isn't.\n\n    You started out right, you just need to rewrite:\n\n\n\n    [tex]\\frac{1}{2} \\frac{d}{dt} \\left( \\left(\\frac{dx}{dt} \\right)^2 \\right)[/tex],\n\n    then integrate.\n  4. Jan 9, 2007 #3\n    Wow, quite the nifty identity. Thanks a lot for that help."}
{"text": "Retrieved from https://math.stackexchange.com/questions/3068499/let-a-in-m-n-mathbbq-with-ak-i-n-if-j-is-a-positive-integer-with-g\nText:\nLet $A\\in M_n(\\mathbb{Q})$ with $A^k=I_n$. If $j$ is a positive integer with $\\gcd(j,k)=1$, show that $ \\operatorname{tr}(A)= \\operatorname{tr}(A^j)$.\n\nI don't know how to start to prove that. I tried to find the matrix $B$ similar with $A$, but I am stuck...\n\nThank you.\n\n\nclosed as off-topic by Saad, Namaste, Holo, Arnaud D., RRL Jan 10 at 17:28\n\n\n  \u2022 \"This question is missing context or other details: Please provide additional context, which ideally explains why the question is relevant to you and our community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc.\" \u2013 Saad, Namaste, Holo, Arnaud D., RRL\n\n\nNote that eigenvalues $\\lambda_i, i=1,\\ldots, n$ of $A$ are roots of the rational polynomial $$ p(t) = \\det(tI-A)=\\prod_{i=1}^n (t-\\lambda_i). $$ Since $Ax=\\lambda_i x$ implies $A^kx = x = \\lambda_i^k x$, we have $\\{\\lambda_i\\}\\subset \\mu_k =\\{\\zeta\\in\\mathbb{C}\\;|\\;\\zeta^k=1\\}$. Let $\\omega$ be the $k$-th primitive root of unity. Since $(j,k)=1$, we can define $\\sigma\\in \\text{Aut}(\\mathbb{Q}(\\mu_k)/\\mathbb{Q})$ by letting $$ \\sigma(\\omega)= \\omega^j. $$ Then, it holds $$ p(t) = \\sigma(p(t)) = \\sigma\\left[\\prod_{i=1}^n (t-\\lambda_i)\\right]=\\prod_{i=1}^n (t-\\sigma(\\lambda_i))=\\prod_{i=1}^n (t-\\lambda_i^j). $$ Now, it follows $$ \\text{tr}(A) = \\sum_{i=1}^n \\lambda_i = \\sum_{i=1}^n \\lambda_i^j = \\text{tr}(A^j). $$\n\n  \u2022 1\n    $\\begingroup$ This is a nice answer that also nicely shows why we do need to do this over $\\mathbb{Q}$, since it will fail in suitable extensions. $\\endgroup$ \u2013\u00a0Tobias Kildetoft Jan 10 at 11:46\n  \u2022 $\\begingroup$ I think this answer is wonderful..... I sincerely appreciate you! $\\endgroup$ \u2013\u00a0w.sdka Jan 10 at 12:00\n  \u2022 $\\begingroup$ why does an eigenvalue $\\lambda_i$ occur with the same algebraic multiplicity as an eigenvalue $\\lambda_i^j$ of $A^j$? $\\endgroup$ \u2013\u00a0M. Van Jan 10 at 13:19\n  \u2022 $\\begingroup$ @M.Van Because $\\{\\lambda_i\\} = \\{\\lambda_i^j\\}$ ..? Equality not as a set, but counted with multiplicity. $\\endgroup$ \u2013\u00a0Song Jan 10 at 13:32\n  \u2022 $\\begingroup$ Umm... Could you explain why $\\lambda_i \\in \\mu_k$?.... why $\\prod_{i=1}^n \\lambda_i^k =1$ implies $\\lambda_i \\in \\mu_k$?? $\\endgroup$ \u2013\u00a0w.sdka Jan 10 at 13:43\n\nWe must use the fact that $A\\in M_n(\\mathbb{Q})$ because the result is false over $M_n(\\mathbb{C})$. Indeed, consider $A=diag(e^{2i\\pi/3},i)$ where $k=12$; then $trace(A)\\not= trace(A^5)$.\n\n$\\textbf{Proposition.}$ When $A\\in M_n(\\mathbb{Q})$ and $(j,k)=1$, $spectrum(A)=spectrum(A^j)$.\n\n$\\textbf{Proof}.$ We may assume that $order(A)=k$ ($k=\\min\\{l;A^l=I_2\\}$) and that $j<k$. Clearly, $order(A^j)=l$. $A$ is diagonalizable over $\\mathbb{C}$ and its minimal polynomial divides $x^k-1$.\n\nTherefore, $\\chi_A$, the characteristic polynomial of $A$, is a product of (irreducible) cyclotomic polynomials $\\phi_a(x)=\\Pi_{(u,a)=1}(x-e^{2i\\pi u/a})\\in\\mathbb{Q}[x]$ where $a|k$. Since $(j,a)=1$, it is easy to see that $\\phi_a(x)=\\Pi_{(u,a)=1}(x-(e^{2i\\pi u/a})^j)$ and we are done. $\\square$"}
{"text": "Retrieved from http://polymathprogrammer.com/2012/11/30/modulo-26-and-column-names/\nText:\nModulo 26 and column names\n\nI was sitting in the lecture theatre valiantly trying to keep awake. The professor was speaking on the rigorous application and proving of the modulus function. It\u2019s basically the remainder, but I\u2019ve never been introduced to it in such, uh, rigor.\n\nHe brought up an example using modulo 26. And demonstrated the wrapping around of values. And the use of it in cryptology (a class I took later on, and I got tasked by the cryptography professor to write a program to do simple encryption. But another story perhaps\u2026).\n\nModulo 26 is similar to finding the remainder. The difference is that the remainder is unique. This is important to our discussion.\n\n\u201cAbout what?\u201d you may ask.\n\nExcel column names.\n\nThere are 2 types of cell references used in spreadsheets, the R1C1 format and the A1 format. The R1C1 is simple. If the row index is 5 and the column index is 7, the result is R5C7.\n\nThe A1 format takes on a column name and the row index. Using our example again, the result is G5, because \u201cG\u201d is the 7th alphabet. Yes, that list of 26 alphabets.\n\nThe version of Excel currently (Excel 2007 and 2010) has up to 3 letters, with XFD as the last column name (that\u2019s the 16384th column). What happens is you have column names A, B, and then up to Z. Then the next column name is AA, then AB and then up AZ. Then BA, BB and so on.\n\nBasically, it\u2019s base 26 arithmetic.\n\nAs far as I know, the typical method of getting the column name given the column index, is to run a loop. You add 1 until it hits 26, then you move to the next \u201cposition\u201d, and then start from 1 again.\n\nThere\u2019s nothing wrong with this method. It\u2019s just that you have to iterate as many times as the given column index. If you\u2019re given 16384, the loop runs 16384 times. This is regardless of the fact that the result is always the same. Given the range of values, the result can only be one of 16384 values.\n\nSo it was with this in mind, and my dabbling in game development (which said \u201cPrecalculate everything!\u201d), that I precalculated an array of strings that are the column names. The array has 16384 items. The context is a spreadsheet software library.\n\nNow to recoup that precalculation cost, I\u2019d have to access my array at least 16384 times. This is where the context of the spreadsheet library comes in. Everybody (and their dog) wants to know if my library can handle millions of cells. This means if the column name calculation is in a method, that method is called millions of times. Given the iteration loop in it, that means the method with the iteration loop thing isn\u2019t efficient (it\u2019s O(n^2)).\n\nHowever, due to technical issues, I can\u2019t keep the array of strings. The column name array needs to be static to be available throughout the library. This causes issues if multi-threads or multi-processors or multi-whatevers comes in.\n\nSo I can\u2019t use my static array anymore. Bummer. The O(n) of simple array access was working so well.\n\nBut I still want to have an efficient way of getting column names. So instead of iterating, I used simple division and modulus operations.\n\nConsider 587. How do you know there\u2019s 5 hundred? 587 / 100 equals 5 (truncating remainders). How do you know there\u2019s 8 tens? 87 / 10 equals 8 (truncating remainders).\n\nYes, it\u2019s elementary arithmetic, but it works great. So we can do the same for column names. There\u2019s a problem though.\n\nIn the case above, we divided by 100. Why 100? Because it\u2019s 10^2, and we\u2019re concerned with the 2nd position after the ones position. The ones position is 10^0 by the way, which is 1.\n\nSo for our case, for the \u201chundreds\u201d position, we divide by 676, which is 26^2. And for the \u201ctens\u201d position, we divide by 26.\n\nNow 587 is 100*5 + 10*8 + 7. I\u2019m going to use the notation (5,8,7) to denote this.\n\nNow consider a column index of 3380. 3380 is equal to 676*5 + 26*0 + 0. This is (5,0,0).\n\nHowever, in our case, our acceptable range of values is 1 through 26. It doesn\u2019t contain zero. So (5,0,0) is not valid.\n\nIn the case of 587, we\u2019re working in base 10, with the acceptable range of values being 0 to 9. This is \u201cproper\u201d remainder. Given any number in base 10, there\u2019s a unique number within [0, 9] that\u2019s the remainder.\n\nHowever, for our purposes, there\u2019s no unique number. Because we\u2019re working in modulo 26, not just \u201cremainder 26\u201d.\n\nThe correct column name corresponding to column index 3380 is \u201cDYZ\u201d. This corresponds to (4,25,26). Or\n3380 = 676*4 +26*25 + 26.\n\nNote that 3380 is also 676*5 + 26*0 + 0.\n\nMy solution is to start from the \u201cones\u201d position. If it\u2019s greater than zero, fine. If it\u2019s less than or equal to zero, borrow from the next larger position. Then we move to the next larger position, and check again. Continue to borrow until there are no zero values (or negatives) on the \u201cright\u201d side of the resulting notation (we can have \u201cleading\u201d zeroes).\n\nSo (5,0,0) becomes (5, -1, 0 + 26), or just (5,-1,26), borrowing 1 from the \u201ctens\u201d position. We cannot have -1, so that becomes (4, -1 + 26, 26), which becomes (4, 25, 26).\n\nAn interesting effect is that we typically assign 0 to A, 1 to B, and 25 to Z. In this case, 1 is assigned to A, 2 is to B, and most interestingly, both 0 and 26 map to Z. In fact, any multiple of 26 will map to Z.\n\nDon\u2019t think Z is special. Any multiple of 26 plus 1 also maps to A. So 1, 27, 53 and so on map to A. This is a property of the modulo thing.\n\nDo you have a better way of converting (5,0,0) to (4,25,26)? Let me know in the comments."}
{"text": "Retrieved from https://mathoverflow.net/questions/311084/additive-discrepancy-under-a-multiplicative-constraint\nText:\nConsider four sequences of numbers, $0 \\le a_i, b_i, c_i, d_i \\le 1$, suppose they satisfy the following constraints:\n\n(1). $\\sum_{i=1}^K a_i, \\sum_{i=1}^K b_i, \\sum_{i=1}^K c_i \\ge 1/2 + \\epsilon$;\n\n(2). $\\sum_{i=1}^K d_i \\le 1/2 - \\epsilon$;\n\n(3). $a_i d_i = b_i c_i$ for all $i=1, \\ldots, K$.\n\nIs it true that \\begin{equation} \\sum_{i=1}^K (|a_i - b_i| + |a_i - c_i|) = \\Omega(\\epsilon) ? \\end{equation}\n\nThe following example shows that the absolute value and the sum is necessary: \\begin{align*} a_1 = 1/2 + \\epsilon, \\quad &a_2 = \\epsilon^2, \\\\ b_1 = 1/2 + \\epsilon + \\epsilon^2, \\quad &b_2 = 0, \\\\ c_1 = 0, \\quad &c_2 = 1/2 + \\epsilon + \\epsilon^2, \\\\ d_1 = 0, \\quad &d_2 = 0. \\end{align*}\n\nNote that the following case is easy: if we have an explicit lower bound $b_i \\ge c > 0$ for all $i$, then let $j$ be the index that maximizes $c_i/d_i$, then \\begin{equation} a_j / b_j = c_j/d_j \\ge (\\sum_i c_i)/(\\sum_i d_i) \\ge 1 + \\epsilon. \\end{equation} Hence \\begin{equation} a_i - b_i \\ge c\\epsilon. \\end{equation} Similarly if we have a lower bound for $c_i$. Note that in these cases we don't even need the assumption that $\\sum_i a_i \\ge 1/2 + \\epsilon$.\n\n  \u2022 $\\begingroup$ There is no $d_i$ in that sum: did you mean that, or is it a mistake? Also, are the various conditions understood to hold for all $K \\in \\mathbb N$ (and the sequences to be infinite), or is $K$ fixed? $\\endgroup$ \u2013\u00a0Alex M. Sep 21 '18 at 15:47\n  \u2022 $\\begingroup$ Even though this problem has a pretty simple solution, I think it is nontrivial and somewhat intriguing. So, I don't understand the down vote. $\\endgroup$ \u2013\u00a0Iosif Pinelis Sep 21 '18 at 17:38\n\n\nIt is not hard to show (see the proof at the end of this answer) that for any real $a,b,c,d\\ge0$ such that $ad=bc$ we have \\begin{equation}\\tag{1} |a-b|+|a-c|\\ge a-d. \\end{equation} Replacing here $a,b,c,d$ by $a_i,b_i,c_i,d_i$ and summing in $i$, we have \\begin{equation} \\sum_i (|a_i - b_i| + |a_i - c_i|)\\ge\\sum_i a_i-\\sum_i d_i\\ge2\\ep, \\end{equation} as desired. (The conditions that $\\sum_i b_i, \\sum_i c_i \\ge 1/2 + \\ep$ were not needed or used here.)\n\nProof of (1). If $a=0$, then $a-d\\le0$, so that (1) holds. So, without loss of generality (wlog), $a>0$, whence $d=bc/a$ and $a-d=(a^2-bc)/a$. So, wlog $a^2>bc$ and hence $a\\ge b\\wedge c$. Also, wlog $c\\le b$. So, one of the following two cases takes place.\n\nCase 1: $0\\le c\\le b\\le a$. Here (1) can be rewritten as $$f(a,b,c):=a-b-c+bc/a\\ge0,$$ which follows because $f(a,b,c)$ is nonincreasing in $b$ (given that $c/a\\le1$) and hence $f(a,b,c)\\ge f(a,a,c)=0$. So, (1) holds in Case 1.\n\nCase 2: $0\\le c\\le a\\le b$. Here (1) can be rewritten as $$g(a,b,c):=b-c+bc/a-a\\ge0,$$ which follows because $g(a,b,c)$ is nondecreasing in $b$ and hence $g(a,b,c)\\ge g(a,a,c)=0$. So, (1) holds in Case 2 as well.\n\nInequality (1) is completely proved.\n\n\nYour Answer"}
{"text": "Retrieved from https://politics.stackexchange.com/questions/38110/can-congress-end-the-government-shutdown-without-the-presidents-agreement\nText:\nThis question already has an answer here:\n\nNegotiations over the current US government shutdown have, as far as I've heard, mainly been between the President and Congressional Democrats. So far, Republicans in Congress seem to be siding with the President in refusing any agreement not including a border wall, but there seem to be some cracks in this.\n\nSuppose that a sufficient number of Congressional Republicans decided to break with the President and reached an agreement with Democrats, but which the President still found unacceptable. As I understand it, both houses of Congress could pass a spending bill along those lines. The President might then veto it (he could stall for up to 10 days first). Suppose, however, that Congress had the votes to override the veto (2/3 of each house).\n\nIf they were to override his veto, would this end the shutdown, or would the President somehow be able to continue it anyway?\n\nI wonder if there is any argument that, even if Congress allocates money for the Government, it is up to the President to decide whether to actually spend it.\n\nmarked as duplicate by JJJ, Alexei, bytebuster, Nate Eldredge, Community Jan 19 at 15:39\n\n\n  \u2022 3\n    You mention a \"sufficient number\"; perhaps you could clarify what you mean by \"sufficient\". Suppose for instance that 99 of the 100 senators wish to pass a bill, and the 100th who does not is the Senate Majority Leader, who controls whether bills get a vote at all. Is 52 Republicans and 47 Democrats \"sufficient\" in this scenario, or not? \u2013\u00a0Eric Lippert Jan 17 at 23:43\n  \u2022 1\n    @EricLippert: Well, enough to pass a bill. I didn't want to quibble about the details. Replace \"sufficient number\" with \"sufficient set\" if you prefer. \u2013\u00a0Nate Eldredge Jan 18 at 2:51\n  \u2022 2\n    @EricLippert: Also, it seems to be presumed that 27 Republicans could remove the Majority Leader and replace him with someone more sympathetic, though apparently it has never happened. \u2013\u00a0Nate Eldredge Jan 18 at 2:59\n  \u2022 @JJJ: Thanks, I searched before but didn't find that (probably because it wasn't tagged [tag:government-shutdown, so thanks also for adding that). \u2013\u00a0Nate Eldredge Jan 19 at 15:39\n\nIf Congress has the 2/3 votes to override a Presidential veto, they can pass any budget they want with zero consideration for what the President thinks. Ever since the Impoundment Control Act of 1974, the President no longer has the authority to refuse spending Congressionally allocated funds.\n\nTherefore Republicans are free to end the shutdown by agreeing not to allocate funds for the Mexico Wall and obtaining the required number of votes from the Democrats. Likewise the Democrats could agree to fund the wall and obtain the necessary votes from the Republicans. Which side to blame for the shutdown is up to you.\n\n  \u2022 12\n    If the Democrats agreed to allocate funds for the wall, the vote threshold would probably come down to 50%+1 as there would no longer be a need to override a veto. \u2013\u00a0WBT Jan 17 at 19:44\n  \u2022 13\n    @WBT There would still be 60% needed in the Senate to overcome a filibuster (which is why the budget that did include the wall funding died upon reaching the Senate after passing in the House.) \u2013\u00a0reirab Jan 17 at 20:52\n  \u2022 4\n    @Trilarion While technically true, if the Senate passed it, it'd go to the house, where it would be highly likely to pass again. Or the Senate could approve H.R.266, which the house passed on the 11th and is virtually identical to the Senate bill that was passed last year. So that distinction is basically meaningless. \u2013\u00a0Draco18s Jan 17 at 22:11\n  \u2022 7\n    The Senate majority leader McConnell refuses to allow a vote on the budget, so you cannot have 2/3 votes if there's no voting session at all - hence the shutdown. \u2013\u00a0Katie S Jan 18 at 0:12\n  \u2022 14\n    @KatieS he could be removed from power if enough senators vote against him \u2013\u00a0JonathanReez Jan 18 at 0:20\n\n\nThis would end the shutdown.\n\n\nCongress appropriates money for specific purposes. Unless Congress specifically delegates authority to someone else in the Executive branch, every dollar is supposed to be spent as stipulated in appropriations legislation. The President choosing to do something else with the money (including not spend it) would be illegal and likely be subject to a court challenge, and has been in the past.\n\nIt is also worth noting that as a purely tactical matter, there would be no value in trying to continue the shutdown in some sneaky way in the event of a veto override, because that much popular support in ending a shutdown in that fashion would mean that the President would never get what he wants from even his own party in Congress. The only reason the shutdown is continuing now is under the theory that some number of Democrats would agree to give him something he wants (e.g. if not the stated wish for $5 billion dollars for \"The Wall\" then some less significant but still desirable thing).\n\n\nThere is a bill in the Senate at this moment that has the votes to pass. It did not make to the floor, because the great majority leader, the senator from Kentucky, refused to bring it up for the vote. Since it did not have the super majority (the 2/3 margin to override the veto from the President), so even when it is passed, it would not end the shutdown.\n\nThis is the same bill that the President \"supported\" and about to sign if it made to his desk, until his friends from Fox News and the \"conservatives\" gave him the hard times for abandoning \"his base\". Since then, he insisted on having 5.7 billion for the wall, or he would not sign anything.\n\n  \u2022 2\n    The president CLEARLY stated after signing the last continuing funding resolution bill that he would sign no more of those bills unless funding for the wall was included. Thus, your claim that the president \"supported\" a bill that he would have signed if it made it to his desk is yet another fabrication of reality that you most likely heard on some liberal fake news outlet. \u2013\u00a0Dunk Jan 18 at 21:52\n  \u2022 @Dunk - Senator McConnell appears to disagree with you. He did in fact bring forward a bill that included no funding for the wall. Clearly at that point in time he was confident that the President would sign it. And just as clearly, the President changed his mind once criticized by the right. \u2013\u00a0Joe Strazzere Jan 19 at 11:23\n  \u2022 What is your reference that the president said he would sign the bill? Without that; it's all FAKE NEWS. \u2013\u00a0Dunk Jan 23 at 20:41"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/272850/equipartition-theorem-missing-energy\nText:\nI seem to be unsure about a discrepancy in energy conservation utilizing the equipartition theorem. Let's say I have a molecule within a thermal reservoir. For example, I will use a molecule of $NH_3$. I will assume that the temperature of reservoir is sufficiently high enough that the high temperature limit can be assumed for the thermodynamical ensembles and molecule's internal energy will be share equally among its degrees of freedom. Specifically, I will focus on its translational, vibrational, and rotational motions.\n\nAccording to the equipartition theorem, $NH_3$ should have three translational degrees of freedom (each of which gives $\\displaystyle \\frac{1}{2} k_B T$\n\n$$U_{tr}=\\frac{3}{2} k_B T$$\n\nSimilarly for rotational energy\n\n$$U_{rot}=\\frac{3}{2} k_B T$$\n\nAnd for a polyatomic molecule such as $NH_3$, there are $3N-6$ vibrational degrees of freedom each of which give energy $k_B T$ which gives\n\n$$U_{vib}=6 k_B T$$\n\nTherefore the total energy of the $NH_3$ molecule is\n\n$$U_{tot}=9 k_B T$$\n\nNow what if the $NH_3$ molecule completely dissociates so that\n\n$$NH_3 \\rightarrow N + 3H$$\n\nNow we only have 3 translational degrees of freedom for each of the 4 atoms. This gives a total internal energy of the system to be\n\n$$U_{tot}=6 k_B T$$\n\nOf course due to energy conservation this energy must have gone somewhere. My question therefore is, where did the extra $3 k_B T$ worth of energy go? My best guess would be that it either was lost as heat to the surroundings when the bonds were broken or it went into the actual dissociation of the molecule. Would I be correct in any of these assumptions?\n\n\nConsider the simpler case of a diatomic molecule where there is just one degree of freedom. The potential energy as a function of bond length will look something like this:\n\n\nNear the minimum the potential is approximately quadratic, that is:\n\n$$ V(x) = kx^2 $$\n\nfor some effective force constant $x$. So if we want to make our molecule vibrate we have to (1) give the atoms some kinetic energy and (2) give them some extra potential energy. For any potential $V(r)=ar^n$ the kinetic energy $T$ and potential energy $V$ are related by the virial theorem:\n\n$$ 2T = nV $$\n\nso for a quadratic potential where $n=2$ we end up with $T=V$. And this is why the energy associated with a vibrational mode is $kT$ not $\\tfrac{1}{2}kT$, because for every $\\tfrac{1}{2}kT$ we add as kinetic energy we have to add another $\\tfrac{1}{2}kT$ as potential energy.\n\nHowever as we climb out of the potential well to large interatomic distances the potential flattens out and eventual becomes independent of distance, i.e. $n=0$ in our equation above, so now we just need to add kinetic energy without needing to add any potential energy at the same time, and the energy becomes just $\\tfrac{1}{2}kT$ i.e. the same as a free particle.\n\nSo that extra $\\tfrac{1}{2}kT$ of energy went into climbing out of the potential well.\n\n  \u2022 $\\begingroup$ I'm not convinced by the last sentence. What does $kT/2$ have to do with the height of the potential well? Can't it be arbitrarily higher or lower? $\\endgroup$ \u2013\u00a0knzhou Aug 6 '16 at 15:53\n\nThe 6$k_BT$ for the whole body (NH$_3$) and for the separated atoms is the same. In calculating this value for ammonia (translation + rotation) one considers only that the atoms move as a group. Only when using 3N-6 does the internal dynamics of a molecule come in, i.e. vibrating bonds. Thus the difference in energy (3k$_B$T) is that needed to break the bonds, i.e. to take the molecule from its potential well to separate atoms. Each of the three normal vibrational modes account for k$_B$T, (1/2)k$_B$T each for potential & kinetic energy, which make up the difference. (Each squared term in the energy (potential & kinetic) equates to (1/2)k$_B$T via the Virial Theorem)\n\n(Even if the potential energy is not harmonic and thus a different relationship between kinetic and potential energy is given by the virial theorem, when the energy from 3N-6 modes was calculated a harmonic potential was assumed, because the energy is (1/2)k$_B$T, thus it is ok to assume this when bonds are broken. Clearly if a different potential was used the energy would be different, but must still cancel when the bond is broken as the potential has to be the same.)\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/314063/conservation-of-angular-momentum-exercise?noredirect=1\nText:\nA disk of radius $R$ and moment of inertia $I_1$ rotates with angular velocity $\\omega_0$. The axis of a second disk, of radius $r$ and moment of inertia $I_2$ is at rest. The axes of the two disks are parallel. The disks are moved together so that they touch. After some initial slipping the two disks rotate together. Find the final rate of rotation of the smaller disk.\n\n\n\n$L_{1_0} = L_1 + L_2 \\rightarrow I_1\\omega_0 = I_1\\omega_1 + I_2\\omega_2$\n\n$\\omega = \\frac{v}{r} \\rightarrow v = \\omega r$\n\n$\\omega_1 R = \\omega_2 r \\rightarrow \\omega_1 = \\frac{r}{R}\\omega_2$\n\n$I_1\\omega_0 = I_1\\frac{r}{R}\\omega_2 + I_2\\omega_2 \\rightarrow \\omega_2 = \\frac{I_1\\omega_0}{\\frac{r}{R}I_1 + I_2}$\n\n$$\\omega_2 = \\frac{I_1\\omega_0}{\\frac{r}{R}I_1 + I_2}$$\n\n\nIs my solution correct? If not, where and why?\n\n  \u2022 $\\begingroup$ Angular momentum cannot be conserved as is assumed in your solution. The system starts with the clockwise angular momentum of disc 1. After contact with disc 1, disc 2 has to have an anti-clockwise angular momentum. To conserve angular momentum disc 1 would need to rotate faster in the clockwise direction which is impossible as then the kinetic energy of the system of two discs would increase with no input of energy. $\\endgroup$ \u2013\u00a0Farcher Feb 23 '17 at 8:14\n\nFront view of two disks\n\nLooking at the system above, you can write for the left disk $$I_2 \\dot{\\omega_2}=Fr$$ and for the second one $$I_1 \\dot{\\omega_1}=FR$$ where $F$ is the (unknown) friction force. Getting $F$ from the second equation $$F=\\frac{I_1}{R} \\dot{\\omega}_1$$and putting in the first we get $$\\frac{I_2}{r} \\dot{\\omega}_2-\\frac{I_1}{R}\\dot{\\omega}_1=0$$ This means that tha quantity $$\\frac{I_2}{r} \\omega_2-\\frac{I_1}{R}\\omega_1$$ is conserved. Setting it equal to the initial value we obtain $$\\frac{I_2}{r} \\omega_2-\\frac{I_1}{R}\\omega_1=-\\frac{I_1}{R}\\omega_0$$\n\nIn the final situation there is no slipping, so $\\omega_2 r=-\\omega_1 R$ and substituting $\\omega_1$ in the previous equation we get $$\\frac{R I_2}{r} \\omega_2+\\frac{r I_1}{R}\\omega_2=-I_1\\omega_0$$ which gives the final solution $$\\omega_2=-\\frac{I_1 r R }{R^2 I_2+r^2 I_1}\\omega_0$$ The angular momentum of the system is not conserved because there are external forces applied on the axes of the disks, and they apply a torque on the system.\n\n  \u2022 $\\begingroup$ In think this derivation using the friction force between the wheels and assuming that the axes of the disks are fixed and don't start to rotate around each other is correct. When the whole experiment is done in free space with a device for the pivots of the axes of known (or negligible) moment of inertia the conservation of angular momentum can probably still be used leading to an additional rotation of the axes of the disks around each other. $\\endgroup$ \u2013\u00a0freecharly Feb 23 '17 at 5:00\n  \u2022 1\n    $\\begingroup$ How is the angular momentum not conserved .....The disks was rotating and it sets the other in rotation. A angular momentum should be conserved about the center of mass. $\\endgroup$ \u2013\u00a0Shashaank Feb 23 '17 at 12:08\n  \u2022 $\\begingroup$ This is not an isolated system, there are external torques acting on it. $\\endgroup$ \u2013\u00a0GCLL Feb 23 '17 at 16:48\n  \u2022 $\\begingroup$ @Shashaank There are forces acting on the axles equal in magnitude to the frictional forces. $\\endgroup$ \u2013\u00a0Farcher Feb 23 '17 at 22:45\n  \u2022 $\\begingroup$ @GCLL Sorry , I couldn't understand . Could you tell which force in particular is giving the torque $\\endgroup$ \u2013\u00a0Shashaank Feb 24 '17 at 5:31\n\nThe solution is not correct because the angular velocities must have opposite signs after contact. Thus $$\\omega_1 = -\\frac{r}{R}\\omega_2$$ which yields the correct angular velocity of the smaller disk $$\\omega_2 = \\frac{I_1\\omega_0}{I_2-\\frac{r}{R}I_1}$$\n\n  \u2022 $\\begingroup$ Good point. I totally missed that. However, could there be more errors? The answer in the book is $\\omega_2 = \\frac{rRI_1}{r^2I_1+R^2I_2}$ (the book's answer could be wrong; it's had mistakes before). $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:30\n  \u2022 $\\begingroup$ @Sir Jony - There seems to be a problem with the use of conservation of angular momentum. When you assume equal disks, there can be no solution because then both disks rotate in opposite sense which always should result in total angular momentum zero. The formula in you comment is dimensionally incorrect, probably a factor $\\omega_0$ is missing. $\\endgroup$ \u2013\u00a0freecharly Feb 22 '17 at 20:46\n  \u2022 $\\begingroup$ Right, I forgot to multiply the RHS by $\\omega_0$. Thanks for catching that. $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:55\n  \u2022 $\\begingroup$ @Sir Jony - In order to get the correct answer you have probably to consider that the contact of the disks in the described manner will also produce a rotation of the disk axes around each other. Otherwise the paradox mentioned above likely cannot be resolved. $\\endgroup$ \u2013\u00a0freecharly Feb 22 '17 at 20:58\n  \u2022 $\\begingroup$ I assume that the axes simply represent pivot points. Other than that, I think they're meant to be ignored. $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:59"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/258765/how-to-determine-if-a-signal-path-needs-to-be-treated-as-a-transmission-line\nText:\nI remember reading this somewhere but cannot find the ratio of the rise time vs. the propagation time (i.e. the trace length?) of a signal when transmission line effects come into effect?\n\nFor example - if I have a SPI bus running at 12.5MHz. If it runs a few inches through the PCB trace, it is not a transmission line - but at what length goes it become a transmission line (at least in theory). How to calculate that?\n\n  \u2022 \\$\\begingroup\\$ It is somewhat arbitrary and may depend on what you are trying to accomplish. \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 2:50\n  \u2022 \\$\\begingroup\\$ I am trying to determine what reflections I might get. I have a SPI master and I want to run it at 12.5MHz over about 5\" of FR4 PCB trace and about 6 feet of 26awg wire. I dont know if that is even possible and how to do it. \\$\\endgroup\\$ \u2013\u00a0user1406716 Sep 20 '16 at 2:52\n  \u2022 \\$\\begingroup\\$ It will probably work. Use a dedicated GND wire for each signal wire and twist the signal with the GND. Add a series resistor on the source board (start with 0 Ohms, and change it if needed) and an AC termination on the receive board. AC termination is a cap and resistor in series. For MOSI, add the series resistor on the master, and AC termination on the slave. For MISO add series resistor on the slave board, and AC termination on the master. Don't install any AC termination to start. You might not need it. Clock is same as MOSI. \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 2:59\n  \u2022 \\$\\begingroup\\$ pericom.com/assets/App-Note-Files/AB023.pdf \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 3:00\n  \u2022 \\$\\begingroup\\$ In theory, it is a transmission line at any length. Termination always works, but sometimes you can leave it out and ignore the resulting overshoot/ringing. \\$\\endgroup\\$ \u2013\u00a0Whit3rd Sep 20 '16 at 4:37\n\nThe boundary between lumped and distributed systems is not clear-cut but there are some commonly used values. For distributed systems transmission line theory is required.\n\nThe distinction is usually made based on the effective length of a signal or the feature of a signal like an edge. So it's important to consider the rise- and fall time of a signal and not the frequency. Nevertheless the frequency imposes an upper limit on the risetime.\n\nIn air a signal travels with about 85ps/in (~ 33ps/cm). The propagation delay depends on the dielectric constant, it is proportional to the square root of it. For a PCB with a dielectric constant of 4 (like FR4 which is in the range of 3 to 5) the propagation delay doubles.\n\nA rising edge with a risetime of 1ns would occupy a trace length of 1ns/(2*85ps) ~ 6in (~ 15cm). At the driving side the signal is already high when at a 6in distance it just starts to rise.\n\nSo a 6in (15cm) track clearly is too long, since the potential varies from low to high along the track.\n\nIf the length of the track is between 1/6 or 1/4 of the effective length of a feature like an edge a system can be regarded as lumped.\n\nSo the upper limit for the example given above is between 6in / 6 (= 1 in, ~2.5cm) and 6in /4 (= 1.5in, ~4cm) for a trace on a PCB with a dielectric constant of 4.\n\n\nFor analog signals (sine waves, let's say), the rule of thumb I was taught is when the line length is 1/8 of the wavelength, you should treat it as a transmission line. Practically speaking, the propagation speed of an electromagnetic wave is determined by the dielectric the wave is traveling in. For PCB's it is typically around C/2, where C is the speed of light in space. Your wavelength will be shorter by the same scale factor (wavelength in free space / 2). So a 100 MHz signal would be 3 meters in free space. 1.5 meters in a PCB. And 1/8 of that is 18.75 cm.\n\nFor digital signals, there are several alternative ways to look at it. One way is rise time and bandwidth. The basic idea is, you use the rise time to estimate the bandwidth, then use the analog signal rule above, but with the bandwidth as the frequency. The justification for this is that the wave can be somewhat accurately reproduced provided that you have the majority of the BW. So the highest significant frequency in the signal is given by the BW.\n\nThe rule of thumb I have seen is that BW = 0.35/TR. BW is bandwidth in GHz, and TR is rise-time in nanoseconds. This formula uses the 10/90 rise time. So if your rise time is 10 ns, then your BW is 0.35/10 = 0.035 GHz = 35 MHz.\n\nAnother way to look at it is that you want the round trip flight time of your signal to be substantially less than your rise time. This means that the reflections will return to the source while the signal is still rising or falling. Reflections like this will not cause the rising and falling edges to be jagged or have \"shelves\" on them. They will still be smooth.\n\nHope this helps.\n\n  \u2022 \\$\\begingroup\\$ Thank you. This is the kind of 'rule of thumb' i was looking for. \\$\\endgroup\\$ \u2013\u00a0user1406716 Sep 22 '16 at 4:29\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1750532/alpha-exists-so-that-for-any-points-x-n-there-is-a-point-at-average-distanc\nText:\nLet $X$ be a connected and compact metric space. Prove a real number $\\alpha$ exists so that for every finite set of points $x_1,x_2,\\dots, x_n\\in X$ (not necessarily distinct) there exists $x\\in X$ such that:\n\n$\\dfrac{d(x_1,x)+d(x_2,x)+\\dots + d(x_n,x)}{n}=\\alpha$\n\n  \u2022 $\\begingroup$ Seems like something to do with the intermediate value theorem applied to a finite sum of metrics. $\\endgroup$ \u2013\u00a0Rick Sanchez Apr 20 '16 at 2:22\n  1. Let us prove the statement for a fixed $n$. Denote$$f_n(x_1,x_2,\\ldots,x_n,x) = \\frac{d(x_1, x) + d(x_2, x) + \\ldots + d(x_n, x)}{n},$$$$M(x_1,x_2,\\ldots,x_n)=\\max_{x\\in X}f_n(x_1,x_2,\\ldots,x_n, x),$$$$m(x_1,x_2,\\ldots,x_n)=\\min_{x\\in X}f_n(x_1,x_2,\\ldots,x_n,x),$$and let $I(x_1, x_2, \\ldots, x_n)$ be the closed interval $[m(x_1, x_2, \\ldots, x_n), M(x_1, x_2, \\ldots, x_n)]$. If we prove all the intervals $I(x_1, x_2, \\ldots, x_n)$, $x_i \\in X$ have a common point, we are done. To prove it, it is enough to establish any two of them have a common point, by Helly's theorem combined with the finite intersection property of a family of compact sets. Arguing by contradiction suppose $I(x_1, x_2, \\ldots, x_n)$ and $I(y_1, y_2, \\ldots, y_n)$ do not intersect and let $a$ be a real number that separates them. Suppose without loss of generality that$$f_n(x_1, x_2, \\ldots, x_n, x) < a < f_n(y_1, y_2, \\ldots, y_n, y) \\text{ for all }x,y \\in X.$$Now, in the first inequality substitute consecutively $x = y_1$, $x = y_2$, $\\ldots$ , $x = y_n$ and sum the terms. Then do the same with the second one substituting $y = x_1$, $y = x_2$, $\\ldots$ , $y = x_n$. We get that one and the same sum is both less and greater than $a$, a contradiction. Thus all the intervals have a common intersection, which is a nonempty interval $I_n$.\n  2. We prove all $I_n$, $n \\in \\mathbb{N}$ have a common point. Again, it is enough to prove it for any two of them. Let us first observe that$$m \\mid n \\implies I_n \\subset I_m.$$Indeed let $c \\in I_n$ and let $x_i \\in X$, $i = 1, 2, \\ldots, m$. Then we get $k$ copies of each $x_i$, $i = 1, 2, \\ldots, m$, where $k \\cdot m = n$ and apply what $c \\in I_n$ means for the new $n$ points in $X$. Using that observation, for any $m$, $n$ we have$$I_{mn} \\subset I_m, \\quad I_{mn} \\subset I_n,$$which means $I_n$, $I_m$ have nonempty intersection. Thus, all $I_n$ have nonempty intersection and any $\\alpha$ inside that intersection will do the job.\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/35571/3-2-approximation-probabilistic-algorithm-for-max-3-color\nText:\nI have a textbook question here regarding Max-3-Coloring and need some assistance with it. I have searched for any type of information regarding it but haven't found anything substantial. Here is the question:\n\nIn MAX-3-COLOR you are given a graph $G=(V,E)$ and your goal is to find a coloring of the vertices with only 3 colors $c: V \\rightarrow [3]$ that maximizes the quality function $q(c)$ - The number of edges whose endpoint vertices are colored with different colors:\n\n$\\sum_{(i,j)\\in E} (1_{c(i) \\neq c(j)})$\n\nGive a probabilistic $3/2$-approximation algorithm. (i.e $q(c)\\geq 2/3 \\cdot OPT$ with probability at least $1-\\frac{1}{e^{k}}$ for any $k \\in \\mathbb{N}$\n\nOK so up until now the textbook only talks about one probabilistic algorithm which fits the requirements - MAX-3-SAT. The textbook gives a probabilistic $8/7$ - approximation algorithm for it (for every literal, toss a fair coin and decide whether to set it to $True$ or $False$).\n\nI also found several other sources which prove that the 3-COLOR is NP-Complete by reducing it to the 3-SAT problem. Thus I am pretty confident that MAX-3-SAT is the way to go.\n\nAccording to this thread: 3 Colorability reduction to SAT I thought about doing the same thing:\n\nFor every $x \\in V$ create three literals: $x_1, x_2, x_3 \\in \\{{True, False}\\}$ where each literal denotes if said vertex $x$ is colored with color $i$.\n\nThen for every edge $e =(x,y)\\in E$ create the following 3-CNF formula $\\varphi$:\n\n$ \\varphi_e = (\\urcorner x_1 \\vee \\urcorner y_1 \\vee \\urcorner y_1) \\wedge (\\urcorner x_2 \\vee \\urcorner y_2 \\vee \\urcorner y_2) \\wedge (\\urcorner x_3 \\vee \\urcorner y_3 \\vee \\urcorner y_3) \\wedge (x_1 \\vee x_2 \\vee x_3)$\n\nAnd the final formula $\\phi$ is:\n\n$\\phi = \\bigwedge_{e \\in E} \\varphi_e$\n\nEvery 3-CNF formula for an edge makes sure that the two endpoints are not of the same color and that one of them is either color 1, 2 or 3.\n\nThe thing is I don't see how this would help me. This gives me a MAX-3-SAT problem since I have a 3-CNF formula for every edge and one big 3-CNF formula for the whole graph. So technically I could use the same algorithm that was given in the textbook before\n\nBut wouldn't using the same probabilistic probabilistic $8/7$ - approximation algorithm for the MAX-3-SAT give the exact same approximation? whereas I wish to achieve a $3/2$- approximation\n\nThanks to anyone who helps!\n\n\nIf you simply uniformly at random (i.i.d) color each of the vertices of $V$ by each of the three possible colors, then for every edge $e\\in E$, it's endpoint will be colored by different colors w.p. $\\frac{2}{3}$, hence the expected quality of the random coloring is exactly $\\frac{2|E|}{3}$. We know that the optimal quality is at most $q^*\\leq |E|$, hence this is a $\\frac{3}{2}$ approximation.\n\n  \u2022 $\\begingroup$ This is a $3/2$-approximation in expectation. To get the high probability result required by the original question, you need to run this algorithm several times and return the best of the resulting colorings. $\\endgroup$ \u2013\u00a0JeffE May 28 '17 at 20:36\n\nConsider the greedy algorithm that loops through the vertices in arbitrary order and assigns each vertex $v$ the least popular color among its previously-colored neighbors. Each vertex $v$ gets a different color than at least $2/3$ of its neighbors, so the quality of the greedy coloring is at least $2|E|/3$. The optimal quality is trivially at most $|E|$, so the greedy coloring is always a $3/2$-approximation. (In particular, the greedy coloring is a $3/2$-approximation with probability at least $1-e^{-k}$ for any integer $k\\in \\mathbb{N}$.)\n\n(You might object that this is not a probabilistic algorithm. Okay, whatever. In a preprocessing phase, generate a random permutation of the colors, and use this permutation to break ties in the greedy algorithm. Alternatively, flip 42 independent fair coins, and if they all come up heads, do ten jumping jacks and a lap around the football field before running the greedy algorithm.)\n\n  \u2022 $\\begingroup$ This is just the derandomization of the algorithm in the other answer, using the method of conditional expectations. $\\endgroup$ \u2013\u00a0Yuval Filmus May 28 '17 at 21:32\n  \u2022 $\\begingroup$ @YuvalFilmus In retrospect, sure. But that's not the easiest way to think about it. $\\endgroup$ \u2013\u00a0JeffE May 28 '17 at 21:35\n\nYour Answer"}
{"text": "Retrieved from https://gamestoday.info/pc/heroes-of-the-storm/can-someone-help-me-with-a-bit-of-ability-damage-math/\nText:\nHeroes of the Storm\n\nCan someone help me with a bit of ability damage math?\n\nHeroesoftheStorm 7 - Can someone help me with a bit of ability damage math?\n\nRight now, I'm working on a big spreadsheet involving damage values and scaling and I want to make sure I'm correctly applying modifiers and scaling (and not screwing up the rounding). The issue I'm running into is with Hanzo's Target Practice and Flawless Technique talents. Storm Bow's level 0 damage is 291, its scaling is the standard 1.04, Target Practice's quest completion provides 100 bonus damage (non-scaling), and Flawless Technique grants a modifier of .3 to Storm Bow. Here's some of the XML pertaining to this:\n\n <CEffectDamage id=\"HanzoStormBowDamage\" parent=\"StormSpell\"> <Amount value=\"291\" /> <MultiplicativeModifierArray index=\"FlawlessTechniqueTalentDamageBonus\" Validator=\"HanzoFlawlessTechniqueIsEmpoweredStormBowMissile\" Modifier=\"0.3\" Crit=\"1\" /> <FlatModifierArray index=\"TargetPracticeTalentFlatDamage\" Validator=\"HanzoTargetPracticeCasterHasDamageIncreaseBehavior\" Modifier=\"100\" /> <SourceButtonFace value=\"HanzoStormBow\" /> </CEffectDamage> \n\nFuther down is the scaling\u2026\n\n <LevelScalingArray Ability=\"HanzoStormBowFireTargetPoint\"> <Modifications> <Catalog value=\"Effect\" /> <Entry value=\"HanzoStormBowDamage\" /> <Field value=\"Amount\" /> <Value value=\"0.040000\" /> <AffectedByAbilityPower value=\"1\" /> <AffectedByOverdrive value=\"1\" /> </Modifications> \n\nI'm trying to calculate the value of a level 20 Storm Bow with both of these bonuses (and no spell power or armor shred from other talents). If we scale the base 291 up to level 20, we get the following:\n\n\n291 * 1.04^20 = 637.616834623\n\nNow we add the Target Practice Bonus:\n\n637.616834623 + 100 = 737.616834623\n\nAnd finally our .3 multiplier from Flawless Technique:\n\n737.616834623 * 1.3 = 958.90188501\n\nSo I end up at a value of ~958.9, which I assume the UI would normally round up to 959. However! When I take these talents, go into Try Mode, set the level to 20, and do this in practice, I get a crit hit of 960 on a Target Dummy. While this seems to confirm that my math was pretty close, it wasn't exact. I'm not sure where this extra bit of damage is coming from and I want to make sure this isn't because I'm missing something in my calculations. At the very least, I think I'm misunderstanding something about the way HotS does rounding.\n\nIt's not a big deal for me to be off by one on this spell, but I have a formula going down an entire column in Google Sheets and I don't want to mess up 500 calculations by a tiny bit.\n\nRead:\u00a0 (Inven) [Interview] Farewell from the best HotS Esports player: Jaewon 'Rich' Lee\n\nAny help is appreciated!\n\nEdit: One clue is that the UI seems to be giving me 638.1 for a level 20 Storm Bow cast on a Target Dummy with no talents. Starting from 638.1, you get:\n\n(638.1 + 100) * 1.3 = 959.53\n\nThis value rounds up to 960 quite nicely and makes perfect sense to me. But it begs the question: why is an untalented level 20 Storm Bow dealing ~638.1 damage?\n\nSource: Original link\n\n\u00a9 Post \"Can someone help me with a bit of ability damage math?\" for game Heroes of the Storm.\n\nTop 10 Most Anticipated Video Games of 2020\n\n\nTop 15 NEW Games of 2020 [FIRST HALF]\n\n\nYou Might Also Like\n\nLeave a Reply"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/171546/symbolic-integration-of-a-long-function-while-retaining-constants\nText:\nI have the following function f\n\nf=(4 (0.5 +nm) \u0393 (16 g2^4+8 g2^2 (\u03ba1 \u03ba2-4 \u03c9^2)+(\u03ba1^2+4 \u03c9^2) (\u03ba2^2+4 \u03c9^2)))/(16 \ng2^4 (\u0393^2+4 \u03c9^2)+(\u03ba2^2+4 \u03c9^2) (16 g1^4+8 g1^2 (\u0393 \u03ba1-4 \u03c9^2)+(\u0393^2+4 \u03c9^2) (\u03ba1^2+4 \n\u03c9^2))+8 g2^2 ((\u03ba1 \u03ba2-4 \u03c9^2) (\u0393^2+4 \u03c9^2)+4 g1^2 (\u0393 \u03ba2+4 \u03c9^2)))\n\n(note the white spaces between terms just refers to product/multiplication. I directly copied from my output and I apologize for any confusion caused.)\n\nMy goal is to find the symbolic integral of f from -[\\Infinity] to [\\Infinity] as a function of \u03c9 with the remaining variables (g2, g1, \u03ba1, \u03ba2, \u0393, nm) as constants. A straightforward attempt was given as follow:\n\nIntegrate[f, {\u03c9, -[\\Infinity], [Infinity]}]\n\nHowever, upon returning, I get something like\n\nConditionalExpression[-((I (0.5 + \n       nm) \u0393 ((4 g2^2 + \u03ba1 \u03ba2)^2 \\\n          16 g2^4 \u0393^2 + \n           32 g1^2 g2^2 \u0393 \u03ba2 + \n           8 g2^2 \u0393^2 \u03ba1 \u03ba2 + \n           16 g1^4 \u03ba2^2 + \n           8 g1^2 \u0393 \u03ba1 \u03ba2^2 + \\\n\u0393^2 \u03ba1^2 \u03ba2^2 + (64 g1^4 + \n             128 g1^2 g2^2 + 64 g2^4 - 32 g2^2 \u0393^2 + \n             32 g1^2 \u0393 \u03ba1 + ...\n\nand the list goes on. I am not sure what to make of it. I decided to mitigate the problem by only taking finite limits\n\nIntegrate[f, {\u03c9, -1000, 1000}]\n\nBut this takes forever for the compiler to compile (I have yet to have it compile successfully).\n\nI know it's possible to numerically integrate this using NIntegrate by defining all the constants\n\nf /. {nm -> 300, \u0393 -> 10^-2, \u03ba1 -> \n1, \u03ba2 -> 10, g1 -> 0.707, g2 -> 10}, {\u03c9, -1000, 1000}]\n\nand this returns a finite value. However I require the analytical expression of the integral so that I can study the behavior of that function in detail.\n\nI appreciate any help that I can get in advance. Thanks!\n\n  \u2022 $\\begingroup$ The solution given by Integrate seems quite complicated and this is only expected given that you have so many constants and each of them can be either positive, negative or 0, or even Complex. If you know that some of them are going to be positive (for example) then try Assumptions. $\\endgroup$ \u2013\u00a0Lotus Apr 20 '18 at 7:03\n  \u2022 $\\begingroup$ The \"list\" Mathematica evaluated is the analytic solution you're looking for! The listed conditions can be evaluated for given parameters. But it looks complicated. Perhaps you have additional information concerning the parameters, which could help to simplify the integrand using Apart[]... $\\endgroup$ \u2013\u00a0Ulrich Neumann Apr 20 '18 at 7:09\n\nIntegrate[f, {\u03c9, -[\\Infinity], [Infinity]}] works just fine. The ConditionalExpression is used as you replace the constants with the number you want. The reason for the long expression is that you did not tell Mathematica the region of the constants, so Mathematica calculates every answer for all of the different region of the constants. To avoid getting such a long answer, you should add something like Assumptions->x>0 and others in the integrate. For example,\n\nIntegrate[Exp[-c x^2], {x, -\\[Infinity], \\[Infinity]}]\n\ngives out\n\nConditionalExpression[Sqrt[\\[Pi]]/Sqrt[c], Re[c] > 0]\n\nby assuming Re[c]>0\n\nIntegrate[Exp[-c x^2], {x, -\\[Infinity], \\[Infinity]}, Assumptions -> Re[c] > 0]\n\nit gives the right result\n\n  \u2022 $\\begingroup$ I have included assumptions for g1, g2, k1, k2 and [CapitalGamma] to be element of Reals. However, I'm getting the same ConditionalExpression in my output. Particularly, it has a sqrt[Root] that appears in it and I'm not sure what to make of it. What does this mean here? $\\endgroup$ \u2013\u00a0kowalski Apr 23 '18 at 1:59\n  \u2022 $\\begingroup$ @kowalski Exactly the same? That shouldn't be. Perhaps you should check what the conditions are. $\\endgroup$ \u2013\u00a0t-smart Apr 23 '18 at 12:35\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/436201/optical-theorem-in-qft\nText:\nI've been working with the Optical theorem in the case in which final and initial states are equals and I have the following doubt. Let's write the scattering matrix $S$ as:\n\n$$S = 1 + i\u00b7T \\tag1$$\n\nwhere $T$ is the transition matrix. Therefore, the Optical theorem is:\n\n$$2\u00b7Im(T) = T^\\dagger T \\implies 2\u00b7Im(T_{ii}) = \\sum_a|T_{ai}|^2 \\tag2$$\n\nIn Eq. (2), we have imposed the particular case commented above with $a$ any state in between. So my doubt arises from here: if, for Eq. (1), $$<i|S|i> = 1 + i<i|T|i> \\implies S_{ii} = 1 + iT_{ii},\\tag3$$ then for that particular case, when I computed the $T_{ii}$ and took $$|S_{ii}|^2 = probability\\ of\\ the\\ process\\ i \\rightarrow i,\\tag4$$ I will get a probability greater than 1. But that isn't possible.\n\nWhat am I misunderstanding?\n\nThanks in advance!\n\n  \u2022 1\n    $\\begingroup$ What happened to the crossterm $-2{\\rm Im} T_{ii}$ in eq. (4)? $\\endgroup$ \u2013\u00a0Qmechanic Oct 22 '18 at 20:00\n\nYou might be assuming the matrix element $T_{ii}$ to be real. If so, then\n\n$$ \\lvert S_{ii} \\rvert^2 = 1 + \\lvert T_{ii} \\rvert^2 > 1 $$\n\nWithout such an assumption, $$ \\begin{align*} \\lvert S_{ii} \\rvert^2 &= 1 + \\lvert T_{ii} \\rvert^2 - 2\\mathrm{Im}(T_{ii})\\\\ &= 1 + \\lvert T_{ii} \\rvert^2 - \\sum_a \\lvert T_{ai} \\rvert^2 \\\\ &= 1 - \\sum_{a \\neq i} \\lvert T_{ai} \\rvert^2 \\end{align*} $$\n\nwhich is smaller than $1$.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/661801/infinite-matrix-leading-eigenvalue-problem\nText:\nI'm trying to find the leading eigenvalue and corresponding left and right eigenvectors of the following infinite matrix, for $\\lambda>0$:\n\n$$ \\mathrm{A}=\\left( \\begin{array}{cccccc} 1 &e^{-\\lambda} & 0 &0 &0 & \\dots\\\\ 1 &e^{-\\lambda} & e^{-2\\lambda} &0 &0 & \\dots\\\\ 1 &e^{-\\lambda} & e^{-2\\lambda} &e^{-3\\lambda} &0 & \\dots\\\\ \\vdots & \\vdots & \\vdots & & \\ddots \\end{array} \\right) $$\n\nNote that there are terms above the main diagonal.\n\nI know that in general infinite matrices aren't really a self-consistent idea, but from doing it numerically with $n\\times n$ matrices using power iteration it looks like the problem converges in the limit of infinite $n$. The convergence is slower for smaller values of $\\lambda$, but it looks like it probably converges for all $\\lambda>0$.\n\nNote that I only care about the leading eigenvalue, i.e. the one with the largest magnitude, which should be real and positive. Its corresponding eigenvectors should have only positive entries, due to the Perron-Frobenius theorem.\n\nAlternatively, if it's easier, a solution for the following matrix will be just as useful to me: $$ \\mathrm{B}=\\left( \\begin{array}{cccccc} 1 & 1& 0 &0 &0 & \\dots\\\\ e^{-\\lambda} &e^{-\\lambda} & e^{-\\lambda} &0 &0 & \\dots\\\\ e^{-2\\lambda} & e^{-2\\lambda} &e^{-2\\lambda} &e^{-2\\lambda} &0 & \\dots\\\\ \\vdots & \\vdots & \\vdots & & \\ddots \\end{array} \\right) $$\n\nAgain note the terms above the diagonal. (The two problems are not equivalent, it's just that either one of them will help me solve a larger problem.)\n\nThe problem is, I just don't have much of an idea how to do this. I've tried a variety of naive methods, along the lines of writing the eigenvalue equation $\\mathrm{A}\\mathbf{x} = \\eta \\mathbf{x}$ as a system of equations involving infinite sums and then trying to find $\\{x_i >0\\}$ and $\\eta>0$ to satisfy them, but this doesn't seem to lead anywhere nice.\n\nIt could be that there is no analytical solution. Or even worse it could be that these matrices have unbounded spectra after all (in which case I'd really like to know!), but if anyone has any insight into how to solve one of these two problems I'd really appreciate it.\n\n  \u2022 $\\begingroup$ Does this come about from discretizing some continuous operator? I ask because that might give some insight or inspiration for how to approach this problem, or solve it by analogy to the continuous problem. $\\endgroup$ \u2013\u00a0rajb245 Feb 10 '14 at 19:00\n  \u2022 $\\begingroup$ @rajb245 no it doesn't unfortunately. (It comes from maximising the entropy of a discrete probability distribution subject to a complex series of constraints - the full explanation is a paper's worth.) $\\endgroup$ \u2013\u00a0Nathaniel Feb 11 '14 at 0:38\n  \u2022 $\\begingroup$ I have a gut feeling that this does have a good closed form answer anyway. I have done some numerical investigations myself and agree that the dominant eigenvalue converges. I made some progress on a solution...I might post what I've got tomorrow if I can get it better shape. $\\endgroup$ \u2013\u00a0rajb245 Feb 11 '14 at 2:40\n  \u2022 $\\begingroup$ @rajb245 that's great! I look forward to it. $\\endgroup$ \u2013\u00a0Nathaniel Feb 11 '14 at 2:44\n  \u2022 $\\begingroup$ In which sequence space are you considering this operator, by the way? It may be a difference if the eigenvectors are bounded, convergent, or square-summable, for example. $\\endgroup$ \u2013\u00a0Roland Feb 11 '14 at 2:55\n\n(No promises here, because I haven't worked the algebra all the way through, but...)\n\nTry writing the matrix equation $A\\mathbf{x}= \\mu \\mathbf{x}$, and then looking at the individual equations it gives;\n\n$$ x_1 + e^{-\\lambda}x_2 = \\mu x_1 \\\\ x_1 + e^{-\\lambda}x_2 + e^{-2 \\lambda}x_3 = \\mu x_2 \\\\x_1 + e^{-\\lambda}x_2 + e^{-2 \\lambda}x_3 + e^{-3 \\lambda}x_4 = \\mu x_3 $$ etcetera.\n\nNotice that you can substitute previous equations in to each one to get that for each $i \\geq 1$, $$\\mu x_i + e^{-(i+1)\\lambda}x_{i+2} = \\mu x_{i+1} \\\\ \\Rightarrow \\mu (x_{i+1} - x_i) = e^{-(i+1)\\lambda}x_{i+2} $$\n\nYou can then solve the recurrence relation similarly to a differential equation, by finding two distinct (neither a constant multiple of the other) solutions, which gives the general solution of any linear combination of these.\n\nThen substitute the general solution into the first equation and see if you can make it consistent with that.\n\nFinding the general solution to the recurrence could still be difficult though - the $e^{-(i+1)\\lambda}$ means that the $x_i = k^i$ trick will fail to work. I'm not actually sure if there is a solution of a different form, or if actually you can show that there is no solution - in which case, it would follow that $A$ did not have eigenvalues.\n\nSorry if this is what you've tried, but you mentioned infinite sums, and this at least doesn't involve them.\n\n  \u2022 $\\begingroup$ This is pretty much what I'd tried. The problem is that solving the recurrence relation gets pretty gnarly pretty quickly. The infinite sums appear when trying to do the same thing for the left eigenvector - I tried that when I couldn't get this to work. $\\endgroup$ \u2013\u00a0Nathaniel Feb 12 '14 at 7:40\n  \u2022 $\\begingroup$ Aaah, I meant to award you the bounty for your effort, but I was really busy today and it timed out. I'm very sorry about that, maybe another time. $\\endgroup$ \u2013\u00a0Nathaniel Feb 13 '14 at 11:58\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/623172/conjugacy-class-of-g-splitting-as-conjugacy-class-of-h-unlhd-g\nText:\nAssume $H\\unlhd G$ and $\\mathcal{K}$ is a conjugacy class of $G$ contained in $H$ and let $x\\in \\mathcal{K}$.\n\nProve that $\\mathcal{K}$ is union of $k$ conjugacy classes of equal size in $H$ where $k=|G:HC_G(x)|$.\n\nI do not really understand the idea behind this :\n\n$\\mathcal{K}$ is a conjugacy class of $G$ means :\n\nGiven $x,y\\in \\mathcal{K}$ we have $g\\in G$ such that $x=gyg^{-1}$\n\nHe is saying that $\\mathcal{K}$ splits into separate classes when seen as classes over $H$.\n\nSplitting means there are two elements in $\\mathcal{K}$ that their conjugating element is not coming from $H$\n\nI am not able to proceed further..\n\nI would like to see that if it splits then it splits \"Equally\"\n\nplease help me to clear this.\n\nThank you\n\n\nDefine an action of $\\;G\\;$ on $\\;H\\;$ by conjugation:\n\n$$g\\cdot h\\mapsto h^g:=g^{-1}hg\\;\\;,\\;\\;g\\in G\\;,\\;\\;h\\in H$$\n\nWhat's the order of an orbit of an element here?\n\n$$\\left|\\mathcal O(h)\\right|:=\\left|\\{h^g\\;;\\;g\\in G\\}\\right|=[G:G_h]\\;,\\;;\\text{with}\\;\\;G_h:=\\{g\\in G\\;;\\;h^g=h\\}=:C_G(h)$$\n\nOf course, we have $\\;\\mathcal K=\\mathcal O(x)\\subset H\\;$ , which btw means also that $\\;x\\in H\\;$ ...\n\nNow let $\\;H\\;$ act on itself by conjugation, so that\n\n$$\\left|\\mathcal O_H(x)\\right|:=\\left|\\{x^h\\;;\\;h\\in H\\}\\right|=[H:H_x]$$\n\n\n$$y\\in H_x\\iff x^y=x\\iff y\\in H\\cap C_G(x)$$\n\nand by the (second, third, something) isomorphism theorem:\n\n$$[H:H_x]=\\left|H/(H\\cap C_G(x))\\right|\\cong \\left|HC_G(x)/C_G(x)\\right|=[HC_G(x):C_G(x)]$$\n\nPutting the above together:\n\n$$|\\mathcal K|=|\\mathcal O(x)|=[G:C_G(x)]=[G:HC_G(x)][HC_G(x):C_G(x)]$$\n\n  \u2022 2\n    $\\begingroup$ Doesn't the 2nd Isomorphism Theorem require, in this case, that $H \\leq N_G(C_G(x))$? In general, for $AB/B \\cong A/A \\cap B$ to hold, I thought that $A \\leq N_G(B)$ is required. $\\endgroup$ \u2013\u00a0inkievoyd Sep 24 '17 at 16:21\n\n$\\newcommand{\\Size}[1]{\\lvert #1 \\rvert}$It is probably useful to generalize this slightly. You have a group $G$ acting transitively on a set $A$, and a normal subgroup $H$ of $G$. Let $a \\in A$.\n\nWe have $$ \\lvert G \\rvert = \\lvert a^G \\rvert \\cdot \\lvert G_a \\rvert, \\qquad \\lvert H \\rvert = \\lvert a^H \\rvert \\cdot \\lvert H_a \\rvert. $$ (Here $a^G$ is the orbit of $a$ under $G$, and $G_a$ the stabilizer of $a$ in $G$.)\n\nAlso, $H_a = H \\cap G_a$, and $$ \\frac{H G_a}{H} \\cong \\frac{G_a}{H \\cap G_a}. $$ Thus $$ \\frac{\\Size{a^G}}{\\Size{a^H}} = \\frac{\\Size{G}}{\\Size{H}} \\cdot \\frac{\\Size{H_a}}{\\Size{G_a}} = \\frac{\\Size{G}}{\\Size{H}} \\cdot \\frac{\\Size{H \\cap G_a}}{\\Size{G_a}} = \\frac{\\Size{G}}{\\Size{H}} \\cdot \\frac{\\Size{H}}{\\Size{H G_a}} = \\Size{G : H G_a}. $$\n\nNote also the following argument. Let $a, b \\in A$, with $b = a^g$, for some $g \\in G$. Then $$ b^H = a^{g H} = (a^{g H g^{-1}})^g = (a^H)^g, $$ (we have used the fact that $H$ is normal in $G$) which shows that $g$ maps the orbit $a^H$ onto the orbit $b^H$, hence they have the same number of elements.\n\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/37389/efficient-algorithm-to-fulfil-a-set-of-coordinate-constraints?answertab=active\nText:\nI have a set of labelled points and a set of distance constraints between pairs of points, consisting of a lower and upper distance bound. There is definitely an arrangement of the points in 3D space that fulfils all distance constraints.\n\nI wish to generate arrangements of the points where all constraints are fulfilled. Any approach is allowed as long as each arrangement is independently generated from the others.\n\nWhat algorithm is most suitable? Mainly in terms of efficiency.\n\nAs an extension, how would I incorporate constraints on the angle defined by three points? And on the dihedral angle defined by four points (the dihedral angle between points ABCD is the angle between the plane defined by ABC and the plane defined by BCD)?\n\n\nThe simplest approach (in terms of programming effort) might be to try using an existing graph layout tool. Those solve a related problem: given a graph with distances on the edges, try to find the best layout to draw the graph on the plane. You can treat your problem as an instance of the graph layout problem: we have one vertex per point, and for each pair of points $v,w$ with distance bounds $[\\ell,u]$, we create an edge $v \\to w$ with length $(\\ell+u)/2$. However, this does have some limitations: typical graph layout algorithms try to get the distances between vertices correct, but also try to avoid edges that cross each other; whereas in your case you don't care about crossings. So, your problem might be easier.\n\nAnother possibility is to apply the ideas used for graph layout to your problem. There are several algorithmic techniques for graph layout. For instance, you could use a spring-based model, where you have a spring between each pair of vertices that have a distance bound, and the spring tries to keep those pair of vertices a suitable distance apart.\n\nA third approach is to use black-box mathematical optimization. Introduce an objective function $\\Phi$ which, given a set of locations for the points, calculates a penalty value (how \"badly\" the arrangement violates your constraints), and then try to find an arrangement that minimizes $\\Phi$.\n\nFor instance, suppose for each pair $v,w$ of points, you have a lower bound $\\ell_{v,w}$ and an upper bound $u_{v,w}$. You could define\n\n$$\\Phi(x_1,\\dots,x_n) = \\sum_{i,j} \\frac{[||x_i - x_j||_2 - (u_{i,j} + \\ell_{i,j})/2]^2}{(u_{i,j} - \\ell_{i,j})^2},$$\n\nand then use some optimization technique to find an arrangement $x_1,\\dots,x_n$ that minimizes $\\Phi(x_1,\\dots,x_n)$. For instance, you could try using hillclimbing, gradient descent, or other convex optimization methods. This approach might be sensitive to the initial values for $x_1,\\dots,x_n$, so you might want to repeat it multiple times with different random choices for the initial value, and take the best result.\n\nFinally, you could try using simulated annealing.\n\nThe latter two approaches can be easily adjusted to incorporate angle constraints, simply by modifying the objective function appropriately to add a term that penalizes angles that differ from the desired value.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3001136/0-sqrt-a-sqrt3b-epsilon-for-a-b-in-bbb-z\nText:\nI'm trying to solve the following problem:\n\nGiven $\\epsilon>0$, are there positive integers $a,b$ such that $0<|\\sqrt a-\\sqrt[3]b|<\\epsilon$ ?\n\nMy solution: given $n\\in\\Bbb N$, $$|\\sqrt{n^2}-\\sqrt[3]{n^3+1}|=\\sqrt[3]{n^3+1}-n=\\frac1{\\sqrt[3]{(n^3+1)^2}+n\\sqrt[3]{n^3+1}+n^2}<\\frac1{3n}\\to 0$$ Thus, the answer is yes.\n\nBut I was trying to find an \"optimal\" solution. That is, now the problem becomes\n\nGiven $\\epsilon>0$, find the least $b\\in \\Bbb Z_+$ such that there exists $a\\in\\Bbb Z_+$ such that $0<|\\sqrt a-\\sqrt[3]b|<\\epsilon$\n\nand now I'm totally lost. Is there some theory about this? Perhaps has it to do with the diophantine equation $a^3-b^2=\\pm1$, and hence, to Catalan's conjecture?\n\nRemark: Please note the '$0<$' in the inequality. I'm aware that $\\sqrt 1=\\sqrt[3]1$.\n\n\nListing some easy observations to get the ball rolling.\n\nMy guess is that the variable $b$ and the error $\\epsilon$ are, asymptotically, related by estimates of the form $$\\epsilon\\approx \\frac C{b^\\alpha},$$ where $C$ and $\\alpha>0$ are positive constants.\n\nThe true relation may be very complicated, but at least we can derive upper and lower bounds of the prescribed form. Your example with $b=n^3+1$, $\\root3\\of b-\\sqrt a\\le 1/(3n^2)$, shows that $$ \\epsilon\\le \\frac{1/3}{b^{2/3}} $$ is possible for infinitely many values of $b$.\n\nOn the other hand, let $\\zeta=(1+i\\sqrt3)/2$ be a primitive sixth root of unity. We have the polynomial factorization $$ x^6-y^6=(x-y)\\prod_{j=1}^5(x-\\zeta^j y).\\qquad(*) $$ Assume that integers $b, a$ are chosen in such a way that $\\root3\\of b-\\sqrt a$ is very small (but non-zero). Plug $x=\\root3\\of b, y=\\sqrt a$ into $(*)$. The left hand side $b^2-a^3$ has absolute value $\\ge1$ because it is an integer. Predalescu/Catalan says that actually it is $\\ge2$ when $b>3$ but that's insignificant, at least for now. Because $x\\approx y$, the other factors on the right hand side of $(*)$ have absolute values $\\approx x, \\sqrt{3}x,2x,\\sqrt3 x,x$ for $j=1,2,3,4,5$ respectively. Their product is thus $\\approx 6x^5$. The factorization $(*)$ thus gives the estimate $$ |\\root3\\of b-\\sqrt a|\\ge\\frac{K}{b^{5/3}} $$ with a constant $K\\approx 1/6$.\n\nI would summarize this by stating that\n\n$$2/3\\le \\alpha\\le 5/3.$$\n\nWaiting for the experts to show up with something more precise.\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/29872/how-many-bytes-are-in-the-region/29877\nText:\nAfter far too many years of counting the number of characters in the region by doing M-: (- (point) (mark)), I just discovered M-= (count-words-region). Much better! But now I'm looking for a way to obtain the number of bytes that the characters in the region occupy in the buffer's coding system--typically, or always really, UTF-8. Is there an easy way to do this?\n\nFor context, I've been doing some code golfing on codegolf.stackexchange.com in a language that supports various Unicode operators, and I need to know how many bytes my submission occupies. So far I've been saving the region to a file, doing ls -l on it, then deleting it. I could easily whip up a function to do this automatically, but it seems rather inelegant.\n\n  \u2022 You could also probably open the file in hexl mode, you could then use the regular Emacs commands to count bytes. \u2013\u00a0wvxvw Jan 8 '17 at 5:56\n  \u2022 I'm typically in a shell buffer when I want to know the byte count, so hexl-mode isn't really practical. A nice thought though. \u2013\u00a0Sean Jan 8 '17 at 20:19\n\nSounds like you are asking for something like this:\n\n(defun region-bytes ()\n  (let ((strg  (if (use-region-p)\n    (message \"Region has %d bytes\" (string-bytes strg))))\n\nYou might also be interested in showing the region size in the mode line. You can do that with library modeline-posn.el -- see Mode Line Position. One of the style choice is to show the number of bytes in the active region -- just what you are asking for here. The difference is that it would always be shown (when the region is active), instead of being reported as a message only on demand (as per the command above).\n\n\nWhile Drew's answer will work correctly in many cases (where utf-8 is pervasive and if you don't use DOS-style EOLs), if you want to make it work reliably for \"all\" buffers, you could do something like the following:\n\n(defun region-bytes (start end)\n  \"Return the number of bytes used by the region.\"\n  (interactive \"r\")\n  (message \"Region has %d bytes\"\n           (- (bufferpos-to-filepos end 'exact)\n              (bufferpos-to-filepos start 'exact))))\n\nand for cases where efficiency is more important than precision, you could pass approximate instead of exact, in which case bufferpos-to-filepos will always be very fast tho it will not handle correctly cases like GBK or utf-2022 encodings.\n\n  \u2022 +1. Good to know about bufferpos-to-file-pos. It is apparently available only in Emacs 25 and later. And it apparently presumes that the buffer is associated with a file (?). You speak of \"all\" buffers, but I imagine the quotes mean (at least) that it is limited to file buffers. \u2013\u00a0Drew Jan 27 '17 at 3:17\n  \u2022 The notion of \"bytes\" here only makes sense with respect to some encoding. bufferpos-to-file-pos uses the encoding specified by buffer-file-coding-system, but other than that it should also work in a non-file buffer (e.g. if you let-bind buffer-file-coding-system around the call). \u2013\u00a0Stefan Jan 27 '17 at 3:29\n  \u2022 I see; thanks. I did not bother to look at the code - looked at only the doc. The doc mentions only \"the file\". It might be more useful if what you say in your comment, or similar, were added. \u2013\u00a0Drew Jan 27 '17 at 3:31\n  \u2022 I see also that the doc says that bufferpos-to-file-pos with type exact \"may end up re-(en/de)coding a large part of the file/buffer\", which might not be desirable in some contexts, for performance reasons. That text seems misleading, BTW, since it suggests that the buffer can be modified, with some of its text changing coding system. If I read the code right, when b-t-f-p re-(en/de)codes the text it puts the result in a different, temporary buffer, and returns the size - the original text does not have its encoding changed. \u2013\u00a0Drew Feb 5 '17 at 17:07\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/314631/positive-real-root-separation/314813\nText:\nLet $\\beta\\in(1,2)$ and $\\gamma\\in(1,2)$ be Galois conjugates of height 1. That is, there exists a polynomial $p$ with coefficients $-1,0,1$ such that $p(\\beta)=p(\\gamma)=0$ (not necessarily minimal).\n\nNumerically, there appears to be an absolute constant $C>0$ such that $|\\gamma-\\beta|\\ge C$. Is this true/known? If it is, what is the best known value for $C$?\n\nI've looked into some literature on root separation but couldn't find this claim.\n\n  \u2022 2\n    $\\begingroup$ Chapter 9 deals with a similar problem, but the bound depends on $\\beta$ (naturally, there are many results like that). The hight could be a red herring, as any polynomial with Mahler measure less than 2, always divides a polynomial of height 1. However, asking for an absolute bound might complicate the matter, and could potentially relate to Lehmer's conjecture. $\\endgroup$ \u2013\u00a0pavl0 Nov 6 '18 at 0:18\n\nThe polynomial\n\n$$1 + x^n + x^{2n} - x^{3n} - x^{5n} - x^{6n} + x^{7n}$$\n\nis irreducible and has two Galois conjugate roots $\\beta_n$ and $\\gamma_n$ in $(1,2)$ with\n\n$$| \\beta_n - \\gamma_n| \\sim \\frac{\\log(\\beta_1/\\gamma_1)}{n} \\rightarrow 0.$$\n\n  \u2022 $\\begingroup$ Simple and beautiful! Maybe the irreducibilty (at least for infinitely many $n$, like the primes) deserves an explanation. $\\endgroup$ \u2013\u00a0Peter Mueller Nov 8 '18 at 10:46\n  \u2022 4\n    $\\begingroup$ Since the Galois group of the polynomial $p(x)$ for $n = 1$ is $S_7$, the irreducibility of $p(x^n)$ is immediate as long as a (any) root of $p(x)$ is not a perfect $n$th power for some $n > 1$. But any root is a fundamental unit in the corresponding degree $7$ field. $\\endgroup$ \u2013\u00a0user131093 Nov 8 '18 at 18:05\n  \u2022 $\\begingroup$ Thanks! I posted a follow-up question: mathoverflow.net/questions/314870/\u2026 $\\endgroup$ \u2013\u00a0Nikita Sidorov Nov 8 '18 at 20:03\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1736959/filled-suit-vs-triple-quads-which-is-more-likely-to-happen-first-on-average/1738504\nText:\nSuppose we have a standard well shuffled $52$ card deck and deal cards from it without replacement (for each hand). Which is likely to happen first on average, we deal out an entire suit (all $13$ cards of any one suit) or get $3$ quads?\n\nNone of the cards have to be in any special order, just that they show up. For example, the quads could show up with other \"irrelevant\" cards in between.\n\nNote that both of these are stopping conditions for a trial, whether you first get the full suit or the triple quads.\n\nAlso note that each case could be poised, waiting for $1$ card to \"win\" but a single card drawn could satisfy both conditions simultaneously and thus will be considered a tie or no decision and we would then reshuffle and retry a new hand. For example, if you needed the K of hearts to complete all $13$ hearts but you also have seen $5,5,5,5,3,3,3,3,K,K,K$ so far with no other quads seen yet that hand. The K of hearts would satisfy both conditions simultaneously and thus create a \"tie\" (no decision) situation, prompting a reshuffle and retrial.\n\n  \u2022 $\\begingroup$ What is a \"quad\"? $\\endgroup$ \u2013\u00a0K. Jiang Apr 11 '16 at 3:48\n  \u2022 $\\begingroup$ I gave examples. A quad in this context is $4$ cards all of the same rank such as K,K,K,K. There are $13$ different ranks in a standard $52$ card deck. $\\endgroup$ \u2013\u00a0David Apr 11 '16 at 4:00\n\nAs I said in my other answer, it is feasible to explicitly calculate all the probabilities. We generate all the distributions of cards into ranks, ${13+4\\choose4}=2380$ except the distributions that lack $3$ cards of any rank, ${13+3\\choose3}=560$. Then for each distribution we can compute the probability of having that distribution given a hand of that many cards, $$P_{dist}=\\frac{\\frac{13!}{n_0!n_1!n_2!n_3!n_4!}{4\\choose0}^{n_0}{4\\choose1}^{n_1}{4\\choose2}^{n_2}{4\\choose3}^{n_3}{4\\choose4}^{n_4}}{{52\\choose0\\cdot n_0+1\\cdot n_1+2\\cdot n_2+3\\cdot n_3+4\\cdot n_4}}$$ Where $n_i$ is the number of ranks that have $i$ cards in the distribution. Then we multiply that by the probability of ending a game requiring $n_4+1$ quads on the next card, $$P_{over}=\\frac{n_3}{52-(0\\cdot n_0+1\\cdot n_1+2\\cdot n_2+3\\cdot n_3+4\\cdot n_4)}$$ Now we have to find the probabilities of winning on that next card, drawing, or already having lost. $$\\begin{align}P_{win}&=P(0)\\\\ P_{tie}&=\\frac14P(1)\\\\ P_{lose}&=\\frac34P(1)+P(2)+P(3)+P(4)\\end{align}$$ Where $P(i)$ is the probability of having completed $i$ suits after the next card has been drawn. Then by inclusion-exclusion, we can find that $$\\begin{align}P(0)&=1-4P(\\spadesuit)+6P(\\heartsuit\\spadesuit)-4P(\\diamondsuit\\heartsuit\\spadesuit)+P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(1)&=4P(\\spadesuit)-12P(\\heartsuit\\spadesuit)+12P(\\diamondsuit\\heartsuit\\spadesuit)-4P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(2)&=6P(\\heartsuit\\spadesuit)-12P(\\diamondsuit\\heartsuit\\spadesuit)+6P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(3)&=4P(\\diamondsuit\\heartsuit\\spadesuit)-4P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(4)&=P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\end{align}$$ Where, for example $P(\\heartsuit\\spadesuit)=P_2$ is the probability of having completed both the hearts and spades suits by the time the next card is drawn. Having picked $K$ specific suits, the probability of all of those suits being present in a rank where $N$ cards has been drawn is $$P_{NK}=\\frac{{4-K\\choose N-K}}{{4\\choose N}}$$ Where ${N\\choose k}=0$ if $k<0$. So the probability of success over all ranks is $$P_K=P_{0K}^{n_0}P_{1K}^{n_1}P_{2K}^{n_2}P_{3K}^{n_3-1}P_{4K}^{n_4+1}$$ Where conventionally $0^0=1$. Putting all that stuff together we can write a program (not posted) to calculate the probabilities of winning, losing, or drawing for games requiring all numbers of quads to win.\n\n$$\\begin{array}{r|rrr} \\text{Quads}&\\text{Win}&\\text{Lose}&\\text{Tie}\\\\ \\hline 1&0.998563&0.001078&0.000359\\\\ 2&0.992344&0.005746&0.001910\\\\ 3&0.975825&0.018161&0.006013\\\\ 4&0.941256&0.044220&0.014525\\\\ 5&0.879013&0.091425&0.029562\\\\ 6&0.778897&0.168285&0.052818\\\\ 7&0.633332&0.282725&0.083944\\\\ 8&0.444088&0.438620&0.117292\\\\ 9&0.234020&0.629219&0.136761\\\\ 10&0.060783&0.826763&0.112455\\\\ 11&0.004689&0.972954&0.022357\\\\ 12&0.000048&0.999376&0.000576\\\\ 13&0.000000&1.000000&0.000000\\\\ \\end{array}$$\n\n\nWhile I can't tell you the exact likelihood of either option coming first, I can prove that getting three quads first is far more likely.\n\nConsider that after 42 cards, you are guaranteed to have at least three quads since there are only 10 cards remaining. After 42 cards, the likelihood of having a full suit would be the likelihood that the remaining 10 cards contain 3 suits or fewer. This probability is $${4*{39 \\choose 10}-6*{26 \\choose 10}+{13 \\choose 10}\\over {52 \\choose 10}}=.1587 $$\n\nThis means that at a point when you are certain you have three quads, there is still a more than 84% chance that you do not have a full suit. Hence, the three quads are more likely to come first.\n\n  \u2022 $\\begingroup$ Can anyone run a Monte Carlo simulation to help confirm this? I'd be interested to know things like the percentages of each, % of ties, average number of cards for a winner.... $\\endgroup$ \u2013\u00a0David Apr 11 '16 at 14:28\n  \u2022 $\\begingroup$ @David Thanks for the suggested edit. I changed it to 84%. $\\endgroup$ \u2013\u00a0browngreen Apr 11 '16 at 15:45\n  \u2022 $\\begingroup$ @Browngren, can you redo your calculation to see what happens when checking for $8$ quads instead of only $3$? According to the simulation by user5713492, those outcomes (one full suit vs. $8$ quads) are almost \"even steven\" (equiprobable). Thanks. $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 4:12\n  \u2022 $\\begingroup$ You are guaranteed at least 8 quads after 47 cards. At that point, the likelihood of having a full suit is $${4*{39 \\choose 5}-6*{26 \\choose 5}+{13 \\choose 5}\\over {52 \\choose 5}}=.7348$$ Based on this alone, we see that the probability of 8 quads coming first is at least .2652, but you couldn't conclude which is more likely to come first. $\\endgroup$ \u2013\u00a0browngreen Apr 12 '16 at 16:00\n\nI tried a simulation. Ran a total of $1.0\\times10^{10}$ times. Program was:\n\nprogram shuffle\n   implicit none\n   integer(INT64) deck(52)\n   integer i, j\n! The deal has 4 4-bit counters for suits and 13 2-bit counters\n! for ranks. Like this:\n! xxxx0SSSS0HHHH0DDDD0CCCC0AA0KK0QQ0JJ0TT099088077066055044033022\n! Each card has a bit set for its suit and for its rank.\n! When added to the deal it updates the appropriate suit and rank\n! counters. When a counter overflows, we know that all 4 of a\n! rank or all 13 of a suit have been dealt (the suit counters\n! were initialized to 3 so that 13 more overflowed them.)\n   integer(INT64), parameter :: initial(52) = &\n   integer(INT64), parameter :: suits = &\n   integer(INT64), parameter :: ranks = &\n   integer(INT64), parameter :: first = &\n   integer(INT64) Nsim, k, deal\n   integer(INT64) :: win = 0, tie = 0, lose = 0\n   real harvest(51)\n   integer quads\n   logical won, lost\n\n   Nsim = 1000000000\n   call random_seed()\n   do k = 1, Nsim\n      deck = initial\n      deal = first\n      call random_number(harvest)\n      do i = 1, 51\n         j = harvest(i)*(53-i)\n         if(j /= 0) deck([i,j+i]) = deck([j+i,i])\n      end do\n      do i = 1, 52\n         deal = deal+deck(i)\n         won = popcnt(iand(deal,ranks)) >= 3\n         lost = iand(deal,suits) /= 0\n         if(won .OR. lost) exit\n      end do\n      if(won) then\n         if(lost) then\n            tie = tie+1\n            win = win+1\n         end if\n         lose = lose+1\n      end if\n   end do\n   write(*,'(a,i12,1x,f12.8)') ' win = ', win, win*1.0d2/Nsim\n   write(*,'(a,i12,1x,f12.8)') 'lose = ', lose, lose*1.0d2/Nsim\n   write(*,'(a,i12,1x,f12.8)') ' tie = ', tie, tie*1.0d2/Nsim\nend program shuffle\n\nResults were as follows: $$\\begin{array}{rrr} \\text{win} & 9758240072 & 97.5824\\% \\\\ \\text{lose} & 181632175 & 1.8163\\% \\\\ \\text{tie} & 60127753 & 0.6013\\% \\end{array}$$ So it can be seen that a loss (all of a suit before 4 quads) was rare, and ties even less frequent.\n\n  \u2022 $\\begingroup$ Just curious. How many quads are needed to make it \"neck and neck\" with filling a full suit? 6? 7?...? Can you mod your program to check when the percentages approach 50% each please? $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 2:19\n  \u2022 1\n    $\\begingroup$ When I cranked it up to 8 quads, it was 44.39% win, 43.87% lose, 11.74% tie. $\\endgroup$ \u2013\u00a0user5713492 Apr 12 '16 at 2:51\n  \u2022 $\\begingroup$ Wow that tie seems very high maybe someone else should also do a Monte Carlo simulation to check. How can it be that just as you get the $8$th quad you are also finishing the first complete suit on that same exact card about $1$ out of $9$ trials? What is the average number of cards of the win, loss, and tie \"buckets\"? $8$ quads is at least $32$ cards and likely more. $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 3:52\n  \u2022 $\\begingroup$ If you think about it, the 8th quad is very likely to come in the 45th-47th card range, which is also a very reasonable range to complete the first full suit. $\\endgroup$ \u2013\u00a0browngreen Apr 12 '16 at 8:06\n  \u2022 1\n    $\\begingroup$ Another $6.0\\times10^9$ simulations, tracking mean game length: $$\\begin{array}{rr}\\text{Quads}&\\text{Length}\\\\3&35.11\\\\4&37.96\\\\5&40.19\\\\6&41.96\\\\7&43.33\\\\8&44.33\\end{array}$$ Come to think of it, it may be feasible to calculate exact probabilities -- in terms of distributions there aren't really that many possibilities. $\\endgroup$ \u2013\u00a0user5713492 Apr 12 '16 at 17:18\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1535997/prove-piecewise-function-integrable\nText:\n$$ f(x) = \\begin{cases} -2, & \\text{if }x < 0 \\\\ 1, & \\text{if }x > 0\\\\ 0, & \\text{if }x = 0 \\end{cases} $$\n\nHey guys I need some help showing that this function is integrable on the closed interval $[-1,2]$.\n\nSo far my idea has been to show $$U(f,P)-L(f,P) < \\epsilon$$ for some $\\epsilon>0$.\n\nThe only problem is the point $(0,0)$ on the function.\n\nI don't understand how to handle that.\n\nCan I just say that $U(f,P)$ for some partition will equal to $3$ and then find a partition $P$ for which $$3-L(f,P)<\\epsilon?$$\n\n  \u2022 $\\begingroup$ If you make the interval(s) containing 0 sufficiently narrow, you can make the difference between upper an lower sums as small as you want, namely at most $|1-(-2)|=3$ times this interval width. $\\endgroup$ \u2013\u00a0Henning Makholm Nov 18 '15 at 23:28\n  \u2022 $\\begingroup$ Hint: look at partitions like $\\{[-1,-\\epsilon],[-\\epsilon,\\epsilon],[\\epsilon,2]\\}$ for smaller and smaller (positive) $\\epsilon$. $\\endgroup$ \u2013\u00a0Arthur Nov 18 '15 at 23:29\n\nLet $\\sigma$ be a partition of $[-1,2]$. Taking Arthur's hint, have the partition be of the form, $$[-1,-\\delta],[-\\delta,\\delta],[\\delta,2]$$ for appropriately small $\\delta >0$.\n\nThe supremum of $f(x)$ is -2 on the first subinterval, $1$ on the second subinterval, and $1$ on the third subinterval (verify it!). Thus the upper sum is given by $$U_{f,\\sigma}=(1-\\delta)\\cdot -2 + 2\\delta \\cdot 1 + (2-\\delta)\\cdot 1=3\\delta$$ The infimum of $f$ on the first interval is $-2$, as well as $-2$ on the second subinterval, and $1$ on the last (verify). Thus the lowers sum is given by $$L_{f,\\sigma}=(1-\\delta)(-2)+2\\delta \\cdot (-2) +(2-\\delta)\\cdot 1=-3\\delta$$ Thus, $U_{f,\\sigma}-L_{f,\\sigma}=6\\delta$ and it should be clear how small to make $\\delta$.\n\n  \u2022 $\\begingroup$ So after you get 2$\\delta$ we need a $\\delta$ < $\\epsilon$ /2. We could choose $\\epsilon$ /3 and get Uf-Lf=$\\epsilon$ - $\\epsilon$ /3 which finishes the proof of 2/3 $\\epsilon$ < $\\epsilon$. Would that be correct? $\\endgroup$ \u2013\u00a0jeff Nov 19 '15 at 0:54\n  \u2022 $\\begingroup$ Yes, you got it. $\\endgroup$ \u2013\u00a0Nap D. Lover Nov 19 '15 at 1:03\n  \u2022 $\\begingroup$ Just one question though. Why isn't the infimum on the interval [-$\\delta$,$\\delta$] set as -2? $\\endgroup$ \u2013\u00a0jeff Nov 19 '15 at 1:07\n  \u2022 $\\begingroup$ Because i messed up haha. This will affect the bound $\\endgroup$ \u2013\u00a0Nap D. Lover Nov 19 '15 at 1:48\n  \u2022 $\\begingroup$ @jeff I have edited my answer with this fixed now. $\\endgroup$ \u2013\u00a0Nap D. Lover Nov 19 '15 at 1:53\n\nNotice that for any $x$ at which $f$ is discontinuous, $x$ can be contained in an interval as small as you please. Make sure to include this small interval in your partition.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/479892/problem-in-the-continuum-limit-of-a-kronecker-delta\nText:\nI am having troubles in understanding how to correctly perform the continuum limit of a double sum containing a Kronecker delta.\n\nImagine to integrate a function depending on $t$ and $t'$, both ranging from $0$ (initial time) to $T$ (final time):\n\n$$I:=\\int_0^Tdt_1\\int_0^Tdt_2 f(t_1,t_2).\\tag{1}$$\n\nThe corresponding Riemann sums, dividing the time intervals in slices of width $\\epsilon=T/N$ is:\n\n$$I_{disc}:=\\sum_{j,j'=1}^N \\epsilon^2 f(j\\epsilon,j'\\epsilon).\\tag{2}$$\n\nObviosly lim$_{N\\rightarrow\\infty}I_{disc}=I$. Now consider the case when only the diagonal elements of the double integral are different from zero i.e.\n\n$$J_{disc}:=\\sum_{j,j'=1}^N \\delta_{j,j'}\\epsilon^2 f(j\\epsilon,j'\\epsilon).\\tag{3}$$\n\nI would expect that, in the continuum limit $N\\rightarrow \\infty$ ($\\epsilon\\rightarrow 0$) it becomes\n\n$$J:=\\int_0^Tdt\\int_0^Tdt'\\delta(t-t') f(t,t'),\\tag{4}$$\n\nwhere $\\delta(t-t')$ is a Dirac delta.\n\nHere is the problem: the Kronecker delta is adimensional, while the Dirac Delta has the dimensions of seconds$^{-1}$. This implies that $J_{disc}$ and $J$ have different dimensions, which does not make any sense. Therefore, there must be some mistake I am doing in going from the discrete to the continuum version of $J$. Could you help me spotting it and, more important, suggest the way to do this limit correctly?\n\n  \u2022 $\\begingroup$ Maybe $\\delta\\left(\\frac{t-t'}{T}\\right)$? $\\endgroup$ \u2013\u00a0Cryo May 14 at 0:06\n\nThe translation between the Kronecker delta function and the Dirac delta distribution is\n\n$$ \\frac{1}{\\epsilon}\\delta_{j,j^{\\prime}}\\qquad\\longrightarrow\\qquad\\delta(t-t^{\\prime}),\\tag{A}$$\n\nwhere $\\epsilon$ is the \"volume\" of a unit-cell in the discretization. See e.g. this related Phys.SE post.\n\nIn particular, the rhs. of OP's eq. (3) should be divided with $\\epsilon$ to have a finite continuum limit.\n\n  \u2022 $\\begingroup$ Thank you very much, I think this clarifies! To summarize, if I just take (3) as it is and perform the limit I get zero, which is also consistent of doing an integral of a finite quantity (the function f) on a set with null measure (the line s=s'). $\\endgroup$ \u2013\u00a0Sandro May 15 at 14:01\n  \u2022 $\\begingroup$ $\\uparrow$ Yes. $\\endgroup$ \u2013\u00a0Qmechanic May 15 at 16:49\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/706243/alternating-series-error-bound\nText:\nThe taylor series for $ln(x)$, centered at $x=1$, is $$\\sum_{n=1}^{\\infty}(-1)^{n+1}\\frac{(x-1)^n}{n} $$ Let $f$ be the function given by the sum of the first three nonzero terms of this series. The maximum value of $|\\ln(x)-f(x)|$ for $0.3\\le\\ x \\le\\ 1.7$ is?\n\nWhen I look at this question, I instinctively think of alternating series error bound. Therefore the maximum error should be equal to the first omitted term $$= (-1)^{4+1}\\frac{(x-1)^4}{4}$$ when we substitute in the endpoints of x, the results are the same $ =0.060025$\n\nThis solution is incorrect, but I do not understand why. The correct solution is the tedious way of actually calculating $$|\\ln(0.3)-(\\frac{x-1}{1}-\\frac{(x-1)^2}{2}+\\frac{(x-1)^3}{3})|$$ $=0.145$ (assuming $\\ln(0.3)$ gives the largest answer). Why is this so? Why does using error bound give an incorrect answer?\n\n\nDoes your series really alternate?\n\nEach term you add is negative for $x = 0.3$.\n\nAddendum: When $n$ is an even number you multiply an even term by $(-1)^{(n+1)}$ to reach a negative number.\n\n  \u2022 $\\begingroup$ not when $n$ is an even number $\\endgroup$ \u2013\u00a0Harrison Mar 10 '14 at 3:53\n  \u2022 $\\begingroup$ @Harrison: user1789954 is pointing out that for $x \\lt 1$, your series is not alternating. All terms are negative. Your alternating series error bound will work for $x \\gt 1$, but not for $x$ below that \"center of the expansion\". $\\endgroup$ \u2013\u00a0hardmath Mar 10 '14 at 3:57\n  \u2022 $\\begingroup$ Ahhh..I see. Thank you! $\\endgroup$ \u2013\u00a0Harrison Mar 10 '14 at 4:01\n  \u2022 $\\begingroup$ Here are the first few terms of the series: $-.7, -.245, -.114333, -.060025...$ $\\endgroup$ \u2013\u00a0Brad Mar 10 '14 at 4:01\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/76556/gravitational-force-exerted-by-a-rod-on-a-point-mass\nText:\nI have doubts with the solution of a certain problem. I will give the entire solution below and will lay out my doubts as well.\n\nA point mass $m_1$ is separated by a distance $r$ from a long rod of mass $m_2$ and length $L$.The objective is to find the total gravitational force exerted by the rod on the point mass.\n\nThis is how a particular author solved this question in a book.\n\nThe total mass of the rod was differentiated with respect to the total length of the rod, and each mass piece was called $dm$ and each length piece was called $dx$. Hence this equation was formulated:\n\n$\\large \\frac{m_2}{L}\\ =\\ \\frac{dm}{dx}$\n\nAlso, the distance between the point mass and each individual $dm$ piece was taken as $x$. Then the gravitational force between the point mass and each mass piece is given by:\n\n$F\\ =\\ \\large \\frac{Gm_1dm}{x^2}$\n\n$dm$ was substituted using the first equation, now the new equation becomes:\n\n$F\\ =\\ \\large \\frac{Gm_1m_2}{Lx^2}\\small dx$\n\nThis is then integrated from $x\\ =\\ r$ to $x\\ =\\ r + L$.\n\nMy question is this: how can we integrate $x$ with respect to $dx$?\n$dx$ represents the tiny length pieces of the rod, and $x$ represents the distance from the centre of the point mass to any point along the rod. How can we integrate $x$ with respect to $dx$, it does not make any physical sense to me? I am new to differentiation and integration, but I understand the basics well enough. If there is something wrong with this solution please tell me the right way to solve this problem, otherwise tell me how this solution makes sense.\n\n  \u2022 $\\begingroup$ You are right. One cannot integrate $x$ wit respect to $dx$. Maybe you are misinterpreting the author. A link to that solution would help. $\\endgroup$ \u2013\u00a0udiboy1209 Sep 7 '13 at 14:54\n  \u2022 $\\begingroup$ @udiboy. It is not on a site, it is from one of the coaching center study materials. The final answer comes out to be $F\\ =\\ \\frac{Gm_1m_2}{r(L + r)}$. Is this what you would get if you solved the problem the right way? $\\endgroup$ \u2013\u00a0Ram Sidharth Sep 7 '13 at 17:21\n\nI don't think that you really understand integration. Let me clear this up for you. In that question there is a rod of length l. You know how to calculate gravitational force between two point masses but not in continuous mass bodies.\n\nIf you apply the formula to find the gravitational force you don't know what to take the distance as because it is continuous body. Let us apply the formula $F\\ =\\ \\large \\frac{Gm_1m_2}{r^2}$ by taking r as the distance between the two bodies. Obviously we get a wrong answer. Now let us consider the rod to be made up of two bodies each of mass $m_2/2$ an length $l/2$ . Now we can define the force as $F\\ =\\ \\large \\frac{Gm_1m_2/2}{r^2} + \\frac{Gm_1m_2/2}{(r+l/2)^2}$ . Again we get a wrong answer. Now let us divide it into $N$ parts. Now the force can be represented as $F\\ =\\ \\large \\frac{Gm_1m_2/N}{r^2} + \\frac{Gm_1m_2/N}{(r+l/N)^2} +\\frac{Gm_1m_2/N}{(r+2l/N)^2}+...... \\frac{Gm_1m_2/N}{(r+(N-1)l/N)^2}+\\frac{Gm_1m_2/N}{(r+l)^2}$ Or $F\\ =\\ \\large \\frac{Gm_1m_2}{N}[\\frac{1}{(r)^2} +\\frac{1}{(r+l/N)^2} + \\frac{1}{(r+2l/N)^2} + .....\\frac{1}{(r+(N-1)l/N)^2}+\\frac{1}{(r+l)^2}]$ Now if we increase the value of $N$ we get a more accurate answer as the divisions become more smaller and more like point masses. Now if we make the value of $N$ very very high then we would get an accurate answer. This is where differentiation ad integration comes in. $\\large \\frac{m_2}{N}$ represents $dm$ and $\\large \\frac{l}{N}$ represents $dx$. Now you know why $dm\\ =\\large \\frac{m_2dx}{l}$\n\nLet us now apply this in the above expression. So now we have .. $F\\ =\\ \\large \\frac{Gm_1m_2dx}{l}[\\frac{1}{(r)^2} +\\frac{1}{(r+dx)^2} + \\frac{1}{(r+2dx)^2} + \\frac{1}{(r+3dx)^2} + .....+\\frac{1}{(r+l)^2}]$ This is same as integrating $\\ \\large \\frac{Gm_1m_2dx}{lx}$ from $x=r$ to $x=r+l$\n$Note:$ Every dm mass is not at the same distance from the point mass. We can integrate $x$ with respect to $dx$ as $dx$ is a small change in $x$ . You add all the values and you add $dx$ to $x$ in every next value. Hope this helps\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/504936/existence-of-a-lagrange-multiplier-euler-lagrange-equations-holonomic-constra\nText:\nLet $I=[a,b]\\subset \\mathbb{R}, G:\\mathbb{R}^n\\to \\mathbb{R}^k$ smooth, $0<k<n, M=G^{-1}(0)$. Assume that $DG(x)$ has full rank for all $x\\in M$. Fix $p_1,p_2\\in M$ and assume $u\\in W^{1,\\infty}(I,\\mathbb{R}^n)$ minimizes the functional given by\n\n$$J(u)=\\int_a^bF(t,u(t),\\dot{u}(t))dt $$\n\non the set $$S := \\{u\\in W^{1,\\infty}(I,\\mathbb{R}^n): u(a)=p_1,u(b)=p_2, u(t)\\in M\\}.$$\n\nShow there exists a function $\\lambda \\in W^{1,\\infty}(I,\\mathbb{R}^k)$ such that\n\n$$\\frac{d}{dt}F_p(t,u(t),\\dot{u}(t)) -F_u(t,u(t),\\dot{u}(t))= DG(u(t))^T\\lambda(t).$$\n\nI got as $\\textbf{hint}$:\n\nNear $p\\in M$, there are parameterizations $\\psi:V\\to U\\subset M$ where $V\\subset \\mathbb{R}^{n-k}$ and $U\\subset M$ contains $p$. Assume first $\\bigcup_t\\{u(t)\\}\\subset U$. Define $w:I\\to\\mathbb{R}^{n-k}$ by\n\n$$w(t) = (\\psi^{-1}\\circ u)(t) $$ and find a suitable functional $\\tilde{J}$ (on a suitable space) which corresponds to $J$ and is minimized by $w$. Use the Euler-Lagrange equations for $\\tilde{J}$ and the fact that $DG(\\psi(z))D_z\\psi(z)=0.$\n\n(for the general case, cover $\\bigcup_t\\{u(t)\\}$ with coordinate patches and localize by subdividing the set into pieces that lie within thise patches).\n\nI'm simply trying to prove the simpler case, but I have hard time finding such $\\tilde{J}$. I appreciate all the help and suggestions.\n\n  \u2022 $\\begingroup$ Well, $\\tilde J$ is very similar to $J$, just use $\\psi$ to pull $F$ to $V$ and use that $\\psi^* F(w(t)) = F(u(t))$. Similarly the analogue of the set $S$ will be the set of all $W^{1,\\infty}$ paths in $V$ between $w(a)$ and $w(b)$. Does this help a little? $\\endgroup$ \u2013\u00a0Marek Sep 25 '13 at 17:02\n  \u2022 $\\begingroup$ what do you mean with $\\psi^*$? $\\endgroup$ \u2013\u00a0DinkyDoe Sep 25 '13 at 18:10\n  \u2022 $\\begingroup$ A pullback: $f^*g(x) = g(f(x))$. You can use it to \"pull\" the function from $U$ to $V$. $\\endgroup$ \u2013\u00a0Marek Sep 25 '13 at 18:18\n  \u2022 $\\begingroup$ Right so the idea is to use $\\tilde{F}(w(t)) = (F\\circ \\psi) (w(t)) = F(u(t))$ where the $w(t)$ now live in $\\tilde{S}$ (like you said.) But why are we allowed to use Euler's equations on $\\tilde{J}(w(t))$? Also, I dont quite see how this helps... $\\endgroup$ \u2013\u00a0DinkyDoe Sep 25 '13 at 23:59\n  \u2022 $\\begingroup$ The difference is that $V$ is not a curved subspace whereas $M$ is. $S$ was defined by means of a constraint that the paths land in $M$. But we got rid of this by explicit parametrization of $M$. Therefore $\\tilde S$ now only contains unconstrained paths which is where the standard calculus of variations applies. As for why you can use Euler's equation: again, standard variational argument. And Lagrange multipliers arise the same they do in fin. dim. vector calculus with constraints. Please clarify how much of this you are familiar with so that the answerers can provide a suitable answer. $\\endgroup$ \u2013\u00a0Marek Sep 26 '13 at 7:59\n\nIt might be useful for you to see how to derive Lagrange multipliers in the finite dimensional setting and then generalize it to the variational setting.\n\nLet's work with a curve in $\\mathbb R^3$ for concreteness. Assume the curve is given implicitly by the constraint $G(\\vec x) = 0$ where $G: \\mathbb R^3 \\to \\mathbb R^2$ (and the rank of $G$ is 2 along the curve). Let's assume now that the curve can be parametrized as $\\psi: \\mathbb R \\to \\mathbb R^3, \\psi: x \\mapsto (x, g(x), h(x))$ in these coordinates (such coordinates can always be found because of the maximal rank assumption by the implicit function theorem). Then we have that $G(\\psi(x)) = G(x, g(x), h(x)) = 0$ for all $x$ and therefore $D(G \\circ \\psi)^i = G^i_x + G^i_y g' + G^i_z h' = 0$ for $i = 1,2$ (the argument of $G^i$ is $\\psi(x)$ but I suppress it for notational convenience).\n\nNow let's get back to finding extremes of the function $F : \\mathbb R^3 \\to \\mathbb R$ along this curve. This is equivalent to finding extremes of $F(\\psi(x))$ on $\\mathbb R$. But the condition for the extremes is $D(F\\circ \\psi) = F_x + F_y g' + G_z h' = 0$. We note that this is very similar for the equation of constraints given by the implicit function theorem and therefore it's enough to solve $\\nabla F = \\lambda_1 \\nabla G^1 + \\lambda_2 \\nabla G^2$ for two unknown constants $\\lambda_1, \\lambda_2$. We can suggestively rewrite this equation as $DF = DG ^T \\lambda$ with $\\lambda = (\\lambda_1, \\lambda_2) \\in \\mathbb R^2$.\n\nNow, returning to the variational setting, everything works out very similarly except that you replace $D$s above with $\\delta$s. Applying standard variational arguments you can then reduce integral equations to time-local equation for every $t$ and deduce the existence of a constant $\\lambda(t)$. The function $\\lambda$ will be in $W^{1,\\infty}(I, \\mathbb R^k)$ precisely because it must satisfy the Euler-Lagrange equation and all the other functions figuring there ($F\\circ u$, $G\\circ u$ and their derivatives) belong to $W^{1,\\infty}$ spaces.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/598787/any-other-prime-numbers-that-satisfy-this-condition-2\nText:\nAny other prime numbers that satisfy this condition?\n\nI asked if $a=2$ and $b=3$, then $a^2-1$ is an integer multiple of $b$. Is there any other pair of primes $a$ and $b$ that satisfy this relationship? The answer is yes, there are infinite pairs: set $a= \\text{any prime} =p$ and $b$ to any prime divisor of $p^2-1$. If we add the condition that $a<b$, are there any other pairs?\n\nMore Clearly,\n\nAre there primes $a,b$ where $a<b$ such that $a^2 -1$ is an integer multiple of $b$, aside from $a=2,b=3$?\n\n\nNo. $a^2-1=(a+1)(a-1)$ certainly has no prime divisors $>a+1$.\n\n\nHagen von Eitzen gave a very good succinct explanation, but I had some doubts and tried to attack it differently.\n\nI noted that $a^2-1$ is necessarily even, so if $kb=a^2-1$, we must have $2pb=a^2-1$, where $p,k \\in \\mathbb{N}$. I tried to show this implies $b\\leq a$, but didn't get very far.\n\nStill having doubts, I wrote a Python script to computationally check the proposition. I know this isn't a proof at all, I'm just sharing this hoping that it might be somehow helpful.\n\nThe primes.txt file is just a copy-paste of this list of the first 1000 primes, though you could of course do it with a larger list of primes if you wanted to. The code for my script is available here.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2682123/a-sobolev-map-with-smooth-weak-derivative-is-smooth\nText:\nLet $f \\in W^{1,p}(\\mathbb{R}^d)$ be a Sobolev map. Suppose its weak derivative is smooth; i.e. it has a representative $x \\to df_x $, which is $C^{\\infty}$, considered as a map $\\mathbb{R}^d \\to \\mathbb{R}^d$.\n\nIs it true $f$ is smooth? (does it have a smooth representative?).\n\nFor $d=1$, the answer is trivially yes: Denote by $f'$ the smooth derivative, and take a smooth anti-derivative of it $F$: Then $F,f$ are both Sobolev maps, with weak derivatives $f'$. Thus $F-f$ has zero weak derivative, hence is constant a.e.\n\n  \u2022 $\\begingroup$ There is probably a more elementary way of proving it, but it also follows from elliptic regularity: If $\\nabla f$ is smooth, then also $\\Delta f = -\\mathrm{div}\\nabla f$ is smooth and thus $f$ has to be smooth. (This is true even if $f$ is a priori only a distribution.) $\\endgroup$ \u2013\u00a0Jan Bohr Mar 8 '18 at 9:49\n  \u2022 $\\begingroup$ Thanks. By the way, your previous comment was inaccurate, right? The symbol of $f \\to df$ is $p(x,\\xi)=f(x)\\xi$. $\\endgroup$ \u2013\u00a0Asaf Shachar Mar 8 '18 at 9:51\n  \u2022 $\\begingroup$ The symbol I first wrote down ($\\sigma(x,\\xi) = i\\xi$) was correct, but it is nonsensical to talk about ellipticity in that context. It would have to be invertible as a map $\\sigma(x,\\xi)\\in \\mathrm{Hom}(\\mathbb{R},\\mathbb{R}^m)$, which is impossible for $m>1$. $\\endgroup$ \u2013\u00a0Jan Bohr Mar 8 '18 at 9:55\n  \u2022 $\\begingroup$ (It should be $\\mathrm{Hom}(\\mathbb{C},\\mathbb{C}^n)$ of course.) $\\endgroup$ \u2013\u00a0Jan Bohr Mar 8 '18 at 10:03\n\nSince the weak derivative of first order has weak derivatives of arbitrary order, we have that $f \\in W^{k,p}(\\mathbb R^d)$ for all $k \\in \\mathbb N$. Now, you can use the Sobolev embedding theorem to get $f \\in C^l(\\mathbb R^d)$ for all $l \\in \\mathbb N$.\n\n  \u2022 $\\begingroup$ You don't know anything about the integrability of the higher order derivatives, i.e. it is only in $W^{k,p}_{loc}$, right? But I guess that is enough. $\\endgroup$ \u2013\u00a0Jan Bohr Mar 8 '18 at 14:12\n  \u2022 $\\begingroup$ Oh, yes, you only have local integrability. And then, you can utilize Sobolev embedding locally. $\\endgroup$ \u2013\u00a0gerw Mar 8 '18 at 15:22\n\n$df$ is exact, so it is closed, and your $d=1$ goes through. The usual argument for exactness goes through using distributions instead of smooth functions ($d^2f=0$ for any distribution $f$).\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/69875/maximization-over-vectors-seen-as-column-matrices\nText:\nI am trying to solve the following question: $$\\text{Maximize } f(x_1,x_2,\\ldots, x_n)=2\\sum\\limits_{i=1}^n x_i^t A x_i+\\sum\\limits_{i=1}^{n-1}\\sum\\limits_{j>i}^n (x_i^tAx_j+x_j^tAx_i)$$ subject to\n$$x_i^t x_j=\\left\\{\\begin{array}{cc} 1&~i=j \\\\ -\\frac{1}{n}&~i\\ne j \\end{array}\\right.$$ where $x_i$'s are column vectors ($m\\times1$ matrices) with real entries and A is an $m\\times m$ $(n<m)$ real symmetric matrix.\n\nFrom some source, I know the answer as $$f_\\max=\\frac{n+1}n \\sum\\limits_{i=1}^n\\lambda_i^\\downarrow,$$ $\\lambda_i^\\downarrow$ being the eigenvalues of $A$ sorted in non-increasing order (counting multiplicity). But I am unable to prove it. I will appreciate any help (preferably with established matrix inequality, or Lagrange's multiplier method).\n\n  \u2022 $\\begingroup$ Just checking; does $$f(x_1,x_2,\\dots,x_n)=\\sum_{i=1}^nx_i^tAx_i+u^tAu$$ where $u=x_1+x_2+\\dots+x_n$? $\\endgroup$ \u2013\u00a0robjohn Oct 4 '11 at 21:15\n  \u2022 $\\begingroup$ yes, it is. Actually, I have expanded the sum... $\\endgroup$ \u2013\u00a0Tapu Oct 4 '11 at 21:26\n  \u2022 $\\begingroup$ This looks a lot like an equation I got when I was doing a least squares regression for a rigid rotation. If that is what you are doing, you might want to take a look at something I wrote up for sci.math. $\\endgroup$ \u2013\u00a0robjohn Oct 4 '11 at 22:55\n\nWhy Lagrange multipliers? Your maximization problem can be solved in a rather straightforward manner using some standard tricks in matrix theory. Let $e=\\frac1{\\sqrt{n}}(1,\\ldots,1)^T\\in\\mathbb{R}^n$ and $X=(x_1,\\ldots,x_n)\\in M_{m,n}(\\mathbb{R})$ (hence $X$ is \"tall\" and $X^T$ is \"wide\"). The problem can be formulated as maximizing $$ f(X)=\\textrm{tr}(X^TAX)+ne^TX^TAXe=\\textrm{tr}\\left((I+nee^T)X^TAX\\right) $$ subject to the constraint $X^TX=\\frac{n+1}{n}I-ee^T$.\n\nThe eigenvalues of $X^TX$ are $\\frac{n+1}{n}$ (with multiplicities $n-1$) and $\\frac{1}{n}$ (with $e$ being an eigenvector). Pick any orthogonal matrix $V$ whose last column is $e$. Then every $X$ that satisfies $X^TX=\\frac{n+1}{n}I-ee^T$ can be written as $X=U\\Sigma V^T$, where $U$ is some $m\\times m$ orthogonal matrix, $\\Sigma$ is the $m\\times n$ (tall) diagonal matrix with diagonal $\\left(\\sqrt{\\frac{n+1}{n}},\\ldots,\\sqrt{\\frac{n+1}{n}},\\sqrt{\\frac{1}{n}}\\right)$, and $V$ is an $n\\times n$ orthogonal matrix. Now let $e_n=(0,\\ldots,0,1)^T\\in\\mathbb{R}^n$. Then $$ \\begin{align} \\Sigma V^T(I+nee^T)V\\Sigma^T &= \\Sigma\\left[I+n(V^Te)(e^TV)\\right]\\Sigma^T \\\\ &= \\Sigma(I+ne_ne_n^T)\\Sigma^T \\\\ &=\\textrm{diag}\\left(\\underbrace{\\frac{n+1}{n},\\ldots,\\frac{n+1}{n}}_{n \\textrm{ entries}},\\ \\underbrace{0,\\ldots,0}_{m-n \\textrm{ entries}}\\right) = D\\quad\\textrm{(say)}. \\end{align} $$ Hence $$ \\begin{align} f(X)&=\\textrm{tr}\\left((I+nee^T)X^TAX\\right)\\\\ &=\\textrm{tr}\\left((I+nee^T)V\\Sigma^T U^TAU\\Sigma V^T\\right)\\\\ &=\\textrm{tr}\\left(\\Sigma V^T(I+nee^T)V\\Sigma^T U^TAU\\right)\\\\ &=\\textrm{tr}\\left(DU^TAU\\right) \\end{align} $$ and the maximum of $f$ occurs when $U^TAU$ is a diagonal matrix whose diagonal entries are in descending order. Thus the answer follows.\n\n  \u2022 $\\begingroup$ Please let me verify (and how it matches with my original problem)...and I'll then accept your answer. Thanks in advance! $\\endgroup$ \u2013\u00a0Tapu Oct 10 '11 at 17:38\n\nThis is not an answer but a reformulation of the question. As robjohn stated, the question becomes: Maximize $f:\\mathbb{M}^{m\\times n}\\mapsto \\mathbb{R}$ such that\n\n$$ f(X) = \\operatorname{tr}(X^TAX) + \\underbrace{u^TAu}_{\\in\\mathbb{R}} $$ This can be combined into $$ \\operatorname{tr}(X^TAX) + \\operatorname{tr}(u^TAu) = \\operatorname{tr}\\left(\\begin{bmatrix}X&u\\end{bmatrix}^T A \\begin{bmatrix} X &u\\end{bmatrix} \\right) = \\operatorname{tr}\\left(\\pmatrix{I &\\mathbf{1}}^TX^TAX\\pmatrix{I &\\mathbf{1}}\\right) $$ where $I$ is the identity matrix and $\\mathbf{1}$ is the all-ones vector. You might want to check these lecture notes page 123. I would try something similar by myself but I am burned out and I need to rest. I will edit later if I can come with anything.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2982598/how-to-show-convergence-a-s-when-sum-of-pa-n-is-infty-and-the-sequence-i\nText:\nThere is a sequence of random variables defined by $$Y_n = \\Big(\\Big|{1-\\frac\\Theta \\pi}\\Big|\\Big)^n$$ where $\\Theta\\sim\\mathrm{unif}[0,2\\pi].$ I have shown that the sequence converges to $0$ in probability. Applying Borel Cantelli Lemma by taking $A_n = \\{|Y_n|>0\\}$ and then evaluating $\\sum_{n=1}^\\infty P(A_n)$, I get it to be $\\infty$. Since the random variables are not independent, I can't conclude anything from this result. How do I prove/disprove convergence almost surely?\n\n\n$Z=(1-\\Theta/\\pi)$ is almost surely in $(-1,1),$ in which case $Z^n\\to 0.$ Thus $Y_n = Z^n \\to 0$ almost surely.\n\n  \u2022 $\\begingroup$ Thank you for you answer. $P(\\lim_{n\\to\\infty}Y_n = 0) = 1$ implies a.s. convergence right? In this case $Y_n \\to 0$ a.s. as $n \\to \\infty$. Does that guarantee a.s. convergence? $\\endgroup$ \u2013\u00a0learner Nov 3 '18 at 6:34\n  \u2022 1\n    $\\begingroup$ @learner If it almost surely converges to zero, then it almost surely converges. More formally, $P(Y_n \\mbox{ converges}) \\ge P(Y_n\\to 0) = P(Z^n\\to 0) \\ge P(|Z|<1) = 1.$ $\\endgroup$ \u2013\u00a0spaceisdarkgreen Nov 3 '18 at 6:41\n  \u2022 $\\begingroup$ thank you so much for clarifying. $\\endgroup$ \u2013\u00a0learner Nov 3 '18 at 6:50\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/201299/wrong-output-in-self-defined-quaternionic-multiplication\nText:\nI tried to define quaternionic multiplication in terms of pairs of complex numbers where I identify $\\mathbb{C}^2$ with $\\mathbb{H}$ via $(z,w)\\mapsto z+jw$. Consequently, I used the multiplication rule\n\nQ /: Q[a_, b_]*Q[c_, d_] := \n Q[a*c - Conjugate[b]*d, Conjugate[a]*d + b*c]\n\nStrangely enough, the input\n\nQ[0, 1]*Q[0, I]\n\nGives the incorrect output\n\nQ[I, 0]\n\nHowever, typing\n\nQ[0, 1]*Q[a, I]\n\nGives the correct output\n\nQ[-I, a]\n\nDoes anyone have an idea why this is happening?\n\n\nMultiplication with * is commutative (technically, Orderless), whereas quaternionic multiplication is not. Because * automatically puts its terms in normal order before multiplying, you sometimes end up with a commuted result. In your case this happens because I comes before 1 in the alphabet, and 0 comes before a, so the two terms are commuted (exchanged) automatically (try Sort[{Q[0, 1], Q[0, I]}] and Sort[{Q[0, 1], Q[a, I]}]).\n\nThe solution is to use NonCommutativeMultiply to prevent term reordering:\n\nQ /: Q[a_, b_] ** Q[c_, d_] := Q[a*c - Conjugate[b]*d, Conjugate[a]*d + b*c]\n\nQ[0, 1] ** Q[0, I]\n(*    Q[-I, 0]    *)\n\nQ[0, 1] ** Q[a, I]\n(*    Q[-I, a]    *)\n  \u2022 $\\begingroup$ Thank you so much!:) $\\endgroup$ \u2013\u00a0deepfloe Jul 1 at 11:55\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-practical-gas-law.735502/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple practical gas law\n\n  1. Jan 29, 2014 #1\n    Hi all...!\n\n    Gas laws.\n\n    Sorry about the simplicity of the question, but that should make it easy :)\n\n    I have two rigid containers open to air. One is 10 times the volume of the other.\n\n    I cap each.\n\n    I increase the temperature of each, 50 degrees.\n\n    What can I say about the pressure inside the containers, compared to each other?\n\n    A brief explanation?\n\n    Thanks ever so much.\n    Last edited: Jan 29, 2014\n  2. jcsd\n  3. Jan 29, 2014 #2\n    The pressure will be the same.\n\n    Just look at the ideal gas law:\n\n    PV = nRT, here P is pressure, V is volume, n is the number of molecules and T is the temperature. R is just a constant.\n\n    Solving for P you get:\n\n    P = nRT / V\n\n    Now, right after you close the lid on each container, notice that the number of molecules in each container is directly proportional to the volume of the container. Therefore the pressure will be the same. When you increase the temperature, it is proportional to the pressure in both cases, so when you increase the temperature equally much in both containers, you increase the pressure equally much. So the end pressure is the same.\n  4. Jan 29, 2014 #3\n    Thanks... this is how I see it as well... but I'm in disagreement with a PhD about it... (I'm not one, so I have less cred), so I appreciate the sanity check.\n\n    I just think of a (very tough) soap bubble in a pressure cooker.\n\n    If you add or subtract heat... he would have to believe that the bubble would change size one way or the other as you changed temperature.\n\n    Intuitively, I just couldn't see that happening. The gas would become equally more active on both sides of the bubble, so the bubble would retain its size. The only way to change the bubble size would be to add or remove gas.... so even if the bubble was slowly permeable... there would be no net exchange (discounting surface tension of the bubble, of course :)\n    Last edited: Jan 29, 2014\n  5. Jan 29, 2014 #4\n    It's not quite the same problem.\n    The gas inside the bubble has a higher pressure than the environment, to start with.\n    In your OP both containers have the same initial pressure.\n  6. Jan 29, 2014 #5\n\n\n    User Avatar\n\n    I would tend to think a bubble would be pretty close to zero gauge pressure - in other words, the same pressure as the environment.\n  7. Jan 29, 2014 #6\n    That's why I said:\n\n    \"discounting surface tension of the bubble, of course :)\"\n\n    So there you go.\n\n    Thanks to all!"}
{"text": "Retrieved from http://www.learn-math.top/calculating-the-reciprocal-distance-matrix-without-inflicting-complexinfinity/\nText:\nCalculating the reciprocal distance matrix without inflicting `ComplexInfinity`\n\nGiven a list of coordinates r (r[[i]]!=r[[j]]), I\u2019d like to know the reciprocals of distances of all pairs in the list, and for the convenience subsequent operations, the trace of the resulting matrix should be all zero. I feel that this should be a frequent need, but I can\u2019t do it optimally.\n\nMy code:\n\nR = Outer[Norm, r, r, 1];\nrR = Quiet[1/R] /. {ComplexInfinity -> 0.}\n\nBut this is not such a good idea as ReplaceAll is significantly slower than the other calculations in this code. Is it a good idea to use For or Table and loop over all indices, or is there a better way to do this?\n\n\n\n\nIf you know all of the r values are different, why not just set the diagonal to 0 afterward? Do UpperTriangularize[#, 1] + LowerTriangularize[#, -1] &@Quiet[1/R]. See here.\n\u2013\u00a0march\nSep 6 at 5:41\n\n\n\nOr what\u2019s your definition of distances of all pairs?\n\u2013\u00a0goodbye_M.SE\nSep 6 at 14:07\n\n\n\nI think Outer[Norm, r, r, 1] should be Outer[EuclideanDistance, r, r, 1]?\n\u2013\u00a0xzczd\nSep 6 at 14:41\n\n\n3 Answers\n\n\nIf the coordinates are machine reals and speed is an issue, I would Compile a function:\n\nreciprocalDist = Compile[{{r, _Real, 2}},\nR = Outer[Subtract, r, r, 1]; (* Outer[Norm,..] is not supported in Compile *)\nMap[If[# == 0, 0, 1/#] &@Norm[#] &, R, {2}]\n\nSeedRandom[0]; (* for reproducibility *)\nreciprocalDist[RandomReal[{-1, 1}, {4, 3}]] // MatrixForm\n\nTheoretically one could cut the speed in half by calculating the upper triangular part. One could preallocate a zero matrix and fill the distances two at a time with a Do loop, for instance.\n\n\n\nWhy DV? I can\u2019t see what\u2019s wrong, other than the stated limitations. Since no comment, obviously a cowardly troll not sincerely interested in improving the site.\n\u2013\u00a0Michael E2\nSep 15 at 23:46\n\nSince DistanceMatrix[] is built-in, it seems natural to use it for this problem. Using Michael\u2019s example, let me present two approaches:\n\nBlockRandom[SeedRandom[0]; (*for reproducibility*)\npts = RandomReal[{-1, 1}, {4, 3}]];\n\n(* method 1 *)\nWith[{id = IdentityMatrix[Length[pts]]}, 1/(DistanceMatrix[pts] + id) \u2013 id]\n\n(* method 2 *)\nDistanceMatrix[pts, DistanceFunction -> (With[{d = EuclideanDistance[##]},\nIf[d == 0, 0, 1/d]] &)]\n\nBoth should return\n\nreci[R_] :=\nWith[{l = Length@R}, {m = SparseArray[Band[{1, 1}] -> 1, {l, l}]}, (1 \u2013 m)/(R + m)]\n\nIf you\u2019re before v10.4:\n\nreci[R_] :=\nWith[{l = Length@R},\n\n\n\nTo the downvoter, I am interested in what was missing from my answer. Did I give too little detail? Or, was it considered incorrect in some way? Either way, would you please elaborate? I\u2019m not trying to complain here, I\u2019m just curious about what I could have done instead.\n\u2013\u00a0xzczd\nOct 6 at 11:09"}
{"text": "Retrieved from https://www.physicsforums.com/threads/de-of-the-form-y-by-a.243575/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nDE of the form y'' + by' = a\n\n  1. Jul 5, 2008 #1\n    Hi, I'm trying to solve the following equation\n\n    y'' + by' = a\n\n    But my answer doesn't make sense:\n\n    The question:\n    an object is flying through space, with velocity could be approximated as:\n    v_next = v_current + a*dt - damp*v*dt\n\n    dt - time increment taken repetitively\n    a - acceleration\n    damp - a constant\n\n    For large dt the approximation is inappropriate, find an equation that will do for large dt.\n\n    My go:\n\n    it looks like the above equation is \"similar\" to\n    x'' = a - damp*x'\n    x'' + damp*x' = a\n\n    part 1: x_c\n    [tex]x'' + damp*x = 0 => r*r + damp*r = 0; r = 0, r = \\frac{-1}{damp}[/tex]\n    [tex]x_c = c_1 + c_2e^{\\frac{-t}{damp}}[/tex]\n\n    part 2: x_p\n    x(t) = k*t\n    x'' + damp*k = a\n    (k*t)'' = 0\n    [tex]k = \\frac{a}{damp}[/tex]\n    [tex]x_p = \\frac{a*t}{damp}[/tex]\n\n    part 3:\n    [tex]x = x_c + x_p = c_1 + c_2e^{\\frac{-t}{damp}} + \\frac{a*t}{damp}[/tex]\n    we want x' approximation so\n    [tex]x' = \\frac{-c_2}{damp}e^{\\frac{-t}{damp}} + \\frac{a}{damp}[/tex]\n\n    what doesn't make sense is lets say damp -> 0 then x' should be a streight line but it doesn't look like it?\n\n    Where may I have gone wrong?\n\n    Thank you\n    Last edited: Jul 5, 2008\n  2. jcsd\n  3. Jul 5, 2008 #2\n    Your solution for nonzero damp looks fine to me: the system starts with some initial speed and then approaches asymptotically the so called \"terminal speed\", v(terminal) = a/damp, at which the pulling force balances the friction exactly: m*a = m*damp*v(terminal).\n\n    Your solution doesn't apply to damp=0 case because you assumed you got two distinct roots of the characteristic equation and hence the full general solution of the homogeneous equation in part 1. That assumption breaks down when damp =0.\n\n    When damp=0, the homogeneous diff. equation in part 1 is x\" = 0.\n    You get a double zero root of the characteristic equation hence only one exponent which can't capture the full general solution required to depend on two arbitrary constants not one. In such cases the general prescription tells you to look for solution of other types not exp(kt). In this case the solution is a linear function xc = c1 + c2*t. The double zero root in the exponent produces only the c1 term.\n    Last edited: Jul 5, 2008"}
{"text": "Retrieved from https://www.physicsforums.com/threads/2-timers-on-off-command.277558/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\n2 timers on/off command\n\n  1. Dec 6, 2008 #1\n\n    I want to build a circuit to control a light bulb in such a way that Ill be able to choose the time that it'll be on [choosing from 5/10/15/20 min] and off [again, choosing from 5/10/15/20 min].\n\n    I would also like to have a counter showing how much time I have till it'll change from on to off or from off to on.\n\n    for example, I'll have 4 7-segments display and 2 buttons.\n    the first button will change the period of time the light will be on and every click will change the time and present it with the 7-segments.\n    the second button will change the period of time the light will be off and every click will change the time and present it with the other 7-segments.\n\n    Ill push the first button till ill see \"5\" and the other one till Ill see \"10\", then itll start work for 5 minutes, while showing me how much time left from that 5 min, and afterward will stop working for 10 min, showing the time left before operating again and so on.\n\n    Any help will be greatly appreciated.\n  2. jcsd\n  3. Dec 6, 2008 #2\n\n\n    User Avatar\n    Science Advisor\n\n    You can do this pretty easily with just a microcontroller (one with enough I/O pins for your 7 segment displays). Or you could go with a few 7-segment display decoder chips if you want a smaller microcontroller / pins for doing something else. You'll need to do a fair bit of programming however.\n  4. Dec 18, 2008 #3\n    Which microcontroller has enough pins for all of my demands?\n    Can you give me a specific model?\n  5. Dec 18, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n\n    Well, assuming you're not doing anything to reduce pin count, you should be doing the analysis on how many pins you'll need for your display:\n\n    -4 7-segments = 4*7\n    -3 push buttons = 3\n    -Other LEDs = 1-5\n\n    So, something like 30+ I/O lines.\n\n    Then you go to your favourite microcontroller manufacturer and START with your I/O pin count, choosing the one which has the peripherals and on-board memory / FLASH / EEPROM you need.\n\n    If you've never worked with microcontrollers before, most microcontroller manufacturers make a 40-pin part, e.g. ATMEL ATmega32, ATmega644, Microchip 16F877A or 18F425) Unfortunately, 40-pin is the max that most manufacturers make nowadays that still come in DIP (dual in-line pin) packages. Which one should you go for? In some ways, that's like asking fans which sports team is the best.\n\n    But you'll need some way of programming them. The AVRisp mkII is pretty good, and capable of programming most ATMELs (there's also a GCC-based C compiler for it). Programming PICs are a little more hit and miss, but various homebrew programmers (and semi-pro kit-based ones) exist that can program various PICs. There is a Microchip C compiler for the PIC18 (and PIC32), but they were designed from the get go to be assembler machines (as opposed to the ATMELs which were designed to be high-language machines).\n\n    You can rest easy that various forums exist on the web to help you along with whatever microcontroller you go with, and whatever language you decide to program it in. Unless you go with something really obscure."}
{"text": "Retrieved from https://www.physicsforums.com/threads/falling-from-a-boat.159671/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nFalling from a boat\n\n  1. Mar 7, 2007 #1\n\n    I am an avid kayaker, and recently got into an argument with another kayaking friend of mine over (what I think is) an issue of relative velocity. The question was this:\n\n    A person is sitting in a kayak and that kayak is in a constant velocity current (say, 3 knots), but the kayak is not moving relative to the water it is in. If he falls out of the kayak, at what speed will the person and boat separate?\n\n    My argument was that they will not separate; they will both continue to move at 3 knots with the current, but will not move relative to the water. Can anyone help settle this?\n\n  2. jcsd\n  3. Mar 7, 2007 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Ideally, you are correct. I say \"ideally,\" since obviously when you fall into the water, you will probably have some acceleration in some direction, and so will start to move in that direction. However, the answer (I think you want) is that no, the boat and person will not separate, since both the boat and the person are moving with the same constant velocity of the water.\n  4. Mar 7, 2007 #3\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Falling out of a kayak, you'll probably push it away with your feet. Once you are in the water, it will drift with the wind and you won't...\n  5. Mar 7, 2007 #4\n\n    Of course you are right, and I should have included that we were holding windspeed at zero.\n\n  6. Mar 7, 2007 #5\n    you mean, holding windspeed at 3 knots?\n  7. Mar 7, 2007 #6\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Heh - right. Assuming the wind is moving the same speed as the current, there is no motion between you and the kayak.\n  8. Mar 7, 2007 #7\n\n\n    User Avatar\n    Gold Member\n\n    Assuming wind is discounted:\n\n    There's going to be no \"residual\" velocity. Both you and the kayak will virtually instantly achieve the same velocity as the current.\n\n    Now, in practice, you and the kayak will likely drift apart from the initial push of you falling in. This distance will be in whatever direction you fall in, independent of the current. And the kayak is so light that this could become a significant distance."}
{"text": "Retrieved from https://www.physicsforums.com/threads/linear-stuff-i-never-get-the-awnser.89423/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLinear stuff: I never get the awnser\n\n  1. Sep 17, 2005 #1\n    Linear stuff: I never get the awnser...!!!\n\n    [3 1 1 1 0]\n    [5 -1 1 -1 0]\n\n    Where the variables are X1 X2 X3 X4.\n\n    I always get somethignt that is far away from the answer.\n    The answer should be x1= -s x2=-t-s x3=4s x4 = t\n\n    Help please!\n  2. jcsd\n  3. Sep 17, 2005 #2\n    What did you do to begin?\n  4. Sep 17, 2005 #3\n    At first, i putted the first number in the frist row as 1.\n\n    so i get [1 1/3 1/3 1/3 0]\n    than i eliminate the 5 to make it a 0.\n    But its after that i got ****ed!\n\n  5. Sep 17, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n\n    What was the question?? I think you have two equations in 4 unknowns and both equations are equal to 0. (It is mildly confusing that you tell us the variables are X1, X2, X3, X4 but then write x1, x2, x3, and x4!)\n\n    Do you understand that there are many different ways to write the answer depending on exactly how you do this? It might be that your answers that are \"far away from the answer\" are, in fact, exactly on the answer!\n\n    You could do this by \"row reducing\" but with a simple problem like this I think just \"substitution\" is best.\n\n    The equations are 3x1+ x2+ x3+ x4= 0 and 5x1- x2+ x3- x4= 0. I might do something like add the two equations and get 8x1+ 2x3= 0 so that x3= -4x1.\n    Now, I choose (arbitrarily) to make x1= s. Then x3= -4s. Putting those into the two equations I get 3s+ x2- 4x+ x4= 0 or x2+ x4= s and\n    5s- x2- 4s- x4= 0 or x2+ x4= s. Since those two equations are exactly the same, I choose (again arbitrarily) to let x2= t and solve for x4= s-t.\n    My solution is x1= s, x2= t, x3= -4s, x4= s-t.\n\n    Is that \"far away from the answer\", which was x1= -s x2=-t-s x3=4s x4 = t? No, not at all. It might make a little more sense if I don't use the same letters as in your given answer: In my answer use \"u\" instead of \"s\" and \"v\" instead of \"t\". Then my answer is x1= u, x2=v, x3=-4u, x4= u- v. Looking at the \"given\" answer, I see that x1=u= -s. If I just replace u by -s, I will have both x1= -s and x3= -4u= 4s as in the \"given\" answer. MY x2 was v while the \"given\" x2 is -t-s. That would be the same if v= -t-s. In that case, my x4= u- t would become x4= (-s)-(-t-s)= -s+ t+ s= t, exactly as given.\n\n    That means that the set of points from my answer and the \"given\" answer are exactly the same! For example, If you take s= 1, t= 1 in the \"given\" answer you get x1= -1, x2= -2, x3= 4, x4= 1.\n    If you take s= -1, v= -2 (in my original form. In terms of u, v, I am taking u= -s= -1, v= -t-s= -2.) so that x= s= -1, x2= t= -2, x3=-4s= 4, x4= s-t= 1, just as before.\n\n    Because there are 2 (independent) equations in 4 unknowns, we have 4-2= 2 \"degrees of freedom\". We are free to choose any two parameters, arbitrarily, and write x1, x2, x3, x4 in terms of those two parameters. Of course, the equations you get will depend upon those arbitrary choices.\n    Last edited by a moderator: Sep 17, 2005\n  6. Sep 17, 2005 #5\n    Thanks bud, i'll look at it later on. If i have any problem, i'll post.\n\nSimilar Discussions: Linear stuff: I never get the awnser"}
{"text": "Retrieved from https://www.physicsforums.com/threads/frequency-addition.226941/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nFrequency Addition\n\n  1. Apr 6, 2008 #1\n    Hi everyone, first post so go easy :)\n\n    What I want to do is design a circuit to add two square wave frequencies into one output.\n\n    The use is for a vehicle fitted with a Karman Vortex mass airflow sensor.\n    The MAF sensor has a 5V square wave output of 0~150Hz.\n    The vehicle has been modified with twin throttle bodies currently plumbed back to a single MAF.\n    The idea is to run two MAF sensors, one for each throttle body.\n\n    So how do I combine the two signals into one output to the ECU?\n    The problem that I see is that even if the two signals are 180 degrees out of phase, they must still add. Ie. 50Hz + 50Hz input, regardless of phase, must = 100Hz output.\n\n    All feedback appreciated,\n\n  2. jcsd\n  3. Apr 7, 2008 #2\n    I think I get the idea. You don't care about phase and amplitudes. If one signal has a frequency of F1 and the other F2, you want the output to have a frequency of F1+F2, correct?\n\n    This would be new to me. The first thing I would do is look at a PPL VCO (phase lock loop, voltage controled oscillator).\n  4. Apr 7, 2008 #3\n    You got it, that's exactly what I'm looking for.\n\n    Ok then. Time to hit Google and look that up. Forgive me but I'm an electronics noob.\n  5. Apr 7, 2008 #4\n    the CD4046 is a CMOS PLL-VCO---of course there's always an easier way to do something.\n  6. Apr 7, 2008 #5\n    would a mixer work?\n    it will return F1-F2 and F1+F2\n    put a high pass filter to get rid of the lower frequency\n  7. Apr 7, 2008 #6\n    I really don't know edmondng. Care to elaborate?\n    EDIT: Actually given the low frequency's I'm dealing with (30~150Hz) would it even be possible to filter out the original input frequencies?\n\n    What about a half adder? Would that work?\n    Last edited: Apr 7, 2008\n  8. Apr 7, 2008 #7\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    The biggest problems are the 0 Hz thing and the \"square wave\" thing. You will need to understand what the ECU expects out of the MAF signal, before you can pick the best way (if one exists) of combining the two MAF signals into one for the ECU.\n\n    For example, if the ECU divides the MAF square wave down by two right away (like, it is only rising edge sensitive), then it is easier to combine the two signals with an adder or some such thing, since you wouldn't care about the duty cycle, only getting the right number of rising edges. You should also find out about the response time and stability criteria for the ECU, since you could confuse it if the two MAF sensors rolled through phase and gave the ECU some jittery edges.\n\n    If the ECU expects a 50% duty cycle input signal from the MAF, then you have to do more work. And the 0 Hz part is still a problem for this. What is the minimum frequency really, that is, what is it at idle. Probably not 0 Hz, right? If it is something reasonable, then you can take the two MAF signals, add them, and phase lock a 50% duty cycle signal to them as suggested already. Your comparison in the PLL will be between the added signal divided by 2, versus the PLL output signal divided by 2. That gets rid of jitter in the comparison, and as long as your PLL output is reasonably square, the ECU should be okay with it.\n\n    But even with a PLL, you are going to have to trade off PLL lock delay and jitter numbers, versus how fast and accurate you want your ECU to be able to respond.\n\n    You might be best off just to stay with the single MAF sensor to the ECU, and maybe make a simple comparison circuit for now that measures the difference in MAF from the two sensors, and just displays that for you to see. If the two MAFs are giving about the same readings anyway, then there is no reason to go to the pretty big trouble of combining the signals, IMO.\n  9. Apr 7, 2008 #8\n    Ok, the MAF sensor outputs a 5V square wave signal of ~30Hz at idle rising to ~150Hz at WOT.\n    The MAF sensors output is 50% duty cycle.\n\n    Your example above makes the most sense to me and eliminates problems introduced by phase shift.\n\n    But your right, I need to find out if the ECU is rising edge sensitive or requires a 50% duty cycle square wave.\n    So how much delay are we talking about here?\n\n    Obviously I've got a lot to learn, I'm going to reserch about PLL's and how they work.\n\n    Thanks for the great reply even if I didn't understand half of it :)\n  10. Apr 7, 2008 #9\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    So when you go to two MAF sensors, the output frequency range of each will now be about 15Hz-75Hz, right?\n\n    I'd suggest drawing a few representative waveforms (with different phases, etc.), to start to get an idea for how you might want to combine them. You can also do a full-digital PLL without an analog VCO for this low-frequency project. You would run a higher-freq digital clock (say, 32kHz like with a watch crystal, or 10MHz with a regular crystal oscillator), and oversample the MAF digital signals, and compute what the sum waveform would be, and output that to the ECU. That would be a fun all-digital project for you.\n  11. Apr 7, 2008 #10\n    You got it.\n    Hahah, sounds way over my head but if you point me in the right direction I'll give it a go.\n  12. Apr 7, 2008 #11\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    I'm not sure I can point you to a good design reference... maybe others reading this thread will know of a good reference for you to read up on this.\n\n    If a brief description would help, I'll try that. Basically you would have two high-frequency counters running, counting the half periods of each of the MAF sensor outputs. Each time a counter finished counting a half period, that information would go toward adjusting the half period of your final output counter.\n\n    So if you used a 32kHz watch crystal as your time base, you would get to a half period count of about 425/2 for a 75Hz input square wave from a MAF, and a half period count of about 2100/2 for a 15Hz input. Each time you got an update from either MAF's counter (each rising or falling edge of the MAF output waveform), you would use that number plus the most recent number from the other MAF channel to pre-set the next terminal count for the output counter. There's a little bit of arbitration and synchronization stuff that has to happen also, but that's a bit complicated to get into in this simple explanation.\n\n    So I think you see the concept of how it would work. I still think as a practical matter, it's best to just stick with a single MAF sensor output. Well, except it just occurred to me that the MAF output will now be too low in frequency, since you have divided the airflow in half. Yikes. Any chance the ECU can be re-mapped to handle the 1/2 MAF output frequency?\n  13. Apr 8, 2008 #12\n    You could be making more work for yourself than necessary.\n\n    If you expect the two MAF to output about the same frequency, you many only need to take the signal from one, and double it.\n\n    By the way, I really like the half-adder idea. Ultimately simple, if not a bit chaotic. Of course you may never know what the ECU expects to see. But if the ECU samples the MAV infrequently, instead of every wave, or doesn't do any sort of averaging, then it wouldn't work at all.\n    Last edited: Apr 8, 2008\n  14. Apr 8, 2008 #13\n    Well this is the problem, there is no guarantee that both MAF sensors would have the same airflow. Also if one filter was to become more restricted then the other, then that would throw it out of balance. Unfortunatly this won't work reliably.\n\n    I'll do some asking around and find out what the ECU needs\n  15. Apr 8, 2008 #14\n    How about using a frequency to Voltage Converter and Voltage to frequency converter to achieve this??\n    Use F to V converter for two inputs F1 and F2 to get V1 and V2 respectively, then add those two analog voltage and again use V to F converter to get a frequency output. Dont have idea on pros and cons.... just an idea to achieve frequency addition.\n\nSimilar Discussions: Frequency Addition\n  1. Addition of decibels (Replies: 21)\n\n  2. Addition of vectors (Replies: 12)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/significant-digits-ruler-to-what-decimal-point.687574/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSignificant Digits Ruler -To what decimal point\n\n  1. Apr 23, 2013 #1\n    Significant Digits Ruler -To what decimal point\n    To what decimal point do I write the number 30 if the uncertainty is 0.0625?\n    The ruler has 1/8 marks.\n\n    Thank you :)\n  2. jcsd\n  3. Apr 23, 2013 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Welcome to the PF.\n\n    You are required to show your Attempt at a Solution before we can offer any tutorial help. How would *you* approach this problem?\n  4. Apr 23, 2013 #3\n    I thought it would be 30.000 +- 0.0625 bc there are 3 sig figs in the uncertainty, but I'm not sure. :/\n    Also, should the uncertainty be rounded since it looks very precise? I'm so sonfused\n  5. Apr 23, 2013 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    There are three sources of error here. One is that you are rounding to the nearest mark. That introduces an uncertainty of exactly \u00b10.0625. Next is any error in the placing of the marks on the ruler. You could handle that by rounding the first uncertainty up a little, \u00b10.064, say. Third is any error in your decision of which is the nearest mark. That's the same in nature as the second error, but statistically independent.\n    Now, suppose you decide the error is \u00b10.07 and you measured the value as 30.375. It would be quite appropriate to write the answer as, say, 30.375\u00b10.070, strange though that may seem. But it would also be reasonable to compromise there, e.g. with 30.37\u00b10.08.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Significant Digits Ruler -To what decimal point\n  1. Significant digits (Replies: 2)\n\n  2. Significant Digits (Replies: 3)\n\n  3. Significant Digits (Replies: 2)\n\n  4. Significant digits (Replies: 1)\n\n  5. Significant digits (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/magnitude-of-current-induced.805827/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMagnitude of current induced\n\n  1. Mar 30, 2015 #1\n    . A circular coil of radius 5.0 cm and resistance 0.20 \u03a9 is placed in a uniform magnetic field perpendicular to the plane of the coil. The magnitude of the field changes with time according to B = 0.50e-20t T. What is the magnitude of the current induced in the coil at the time t = 2.0 s?\n\n    2. Relevant equations\n\n    \u03a6 = BAcos(0) = BA\n    emf = -d\u03a6B /dt = -d(BA)/dt = -A * d(B)/dt\n\n    3. The attempt at a solution\n\n    I differentiated that magnetic field and got -10e-20t, then multiplied that times pi*(.052), and ultimately divided by .2 \u03a9. My answer is 1.66*1018, which is nowhere near any of the answers. I feel like I'm following a logical path but obviously this isn't working, so I don't know what else to do.\n  2. jcsd\n  3. Mar 30, 2015 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Your mistake is that you dont take into account the self inductance L of the coil. It will be [itex] E+L\\frac{dI}{dt}+IR=0[/itex] where E(t) exactly as you calculated and R=0.2Ohm. You still have to calculate L from the geometrical data of the coil and then solve the differential equation. In doing that becareful that E is not constant but varies with time as of course the current I(t) do so also.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/solving-an-inquality.576662/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSolving an inquality\n\n  1. Feb 11, 2012 #1\n\n    So this is the question\n\n\n    2. Relevant equations\n\n\n    3. The attempt at a solution\n\n    I tried it, the solution seems right, but i don't know if my approach is correct.\n\n  2. jcsd\n  3. Feb 11, 2012 #2\n\n\n    User Avatar\n    Homework Helper\n\n    Think about these absolute values like this:\n\n    At x=1 or x=2, one of the absolute values is 0, so you can call these the \"roots\" (thought not technically roots, I can't think of a more appropriate name for them right now), so what you want to do is check all possibilities around those roots, and the roots themselves.\n\n\n    For this range, both [itex]x-1[/itex] and [itex]x-2[/itex] will be negative, so the inequality you need to solve would be [tex]-(x-1)-(x-2)>1[/tex]\n\n    Here you will have [itex]x-1>0[/itex] and [itex]x-2<0[/itex] so what you need to solve is [tex](x-1)-(x-2)>1[/tex]\n\n    For this value, both are positive so it should be clear what you need to solve here.\n\n    And then always check the \"roots\" themselves. Plug in the values of x=1 and x=2. By this point, you've checked all possible cases and should have your solution set.\n  4. Feb 11, 2012 #3\n    The way I learned it:\n\n    To solve |ax+b|>k, solve ax+b>k and ax+b<-k. (This is basically what you did.)\n\n    Then I would plug test values into the original equation to see if it makes a true or false statement. You would use the intervals (-[itex]\\infty[/itex],1);(1,2);(2,[itex]\\infty[/itex]).\n\n    The values from those intervals that make true statements give you your solution set.\n  5. Feb 11, 2012 #4\n\n\n    User Avatar\n    Homework Helper\n\n    edit: I just realized that your question is a special case. What if it was instead [tex]|x-1|+|x-2|>2[/tex] or [tex]|x-1|+|x-2|>0[/tex] ? For the first what you need to do is check when [tex]|x-1|+|x-2|=2[/tex] and then check each interval around that.\n    Last edited: Feb 11, 2012\n  6. Feb 11, 2012 #5\n    Thanks Mentallic and Adaptation!\n\nSimilar Discussions: Solving an inquality\n  1. Solve for a (Replies: 6)\n\n  2. Solve for A (Replies: 17)\n\n  3. Solving an equation (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-integration.209566/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Integration\n\n  1. Jan 18, 2008 #1\n    [SOLVED] Simple Integration\n\n    1. Integrate the following\n\n    f(x) = sin x/(cos x )^2\n\n    3. Well i dont really want to use subsititution or anything since im pretty sure this can be done very simply but i dont know why i cannot get it...\n\n    sin x /cos ^2 x = sinx / 1- sin^2x\n\n    i know ln (cos x)^2 will give me (-2(cosx)*sinx)(1/cos^2x)\n\n    so thats not good...\n  2. jcsd\n  3. Jan 18, 2008 #2\n    How about u-substitution?\n  4. Jan 18, 2008 #3\n    You must use substitution. Using trig identities will only make it messier.\n\n    Hint: get f(x) into the form du / u ^2 .\n  5. Jan 18, 2008 #4\n    yea i just did it with u as well but that weird, cause this question was in my first section for integral calc (where we basically onyl went through basic rules like power rule, and integrals of other trig functions)\n\n    but anyways\n\n    let u = cosx\n\n    du/dx = -sinx\n\n    now i integrate - 1/(u)^2 * du\n    = integral of -u^-2 *du\n\n    = u^-1\n\n    = cos^-1 x\n\n    = 1/cos x\n\n    = sec x\n\n  6. Jan 18, 2008 #5\n\n\n    User Avatar\n    Homework Helper\n\n    Yup, that seems perfectly correct. Except for a small error, you forgot the Constant of Integration \"+ C\" at the end of the final result. :)\n  7. Jan 18, 2008 #6\n\n\n    User Avatar\n    Homework Helper\n\n    It happens in this case that there is another way to go about this, although it's not something you'd generally spot at first (you notice it after doing the u-substitution). You can also write\n    (sin x)/[(cos x)^2] as (1/cos x)\u00b7(sin x / cos x) = sec x tan x , which is the derivative of sec x . (This at least serves as a check on your result...)\n  8. Jan 20, 2008 #7\n    [tex]\\int\\frac{\\sin x}{\\cos^2 x}dx=-\\int\\frac{1}{\\cos^2 x}d(\\cos x)=-\\int (\\cos x)^{-2}d(\\cos x)=-\\frac{(\\cos x)^{-2+1}}{-2+1}+C=\\frac{1}{\\cos x} +C[/tex]\n    [tex]d(\\cos x)=-\\sin x dx[/tex]\n    [tex]dx=\\frac{d(\\cos x)}{-\\sin x}[/tex]\n    Last edited: Jan 20, 2008\n\nSimilar Discussions: Simple Integration\n  1. Simple integration (Replies: 2)\n\n  2. Simple Integral (Replies: 3)\n\n  3. Simple Integral (Replies: 10)\n\n  4. Simple integral (Replies: 7)\n\n  5. Simple Integral (Replies: 8)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calc-problem.59117/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalc problem\n\n  1. Jan 9, 2005 #1\n    We have a set of problems for hw. I am stuck on 1 where I know the answer but cant seem to get it.\n\n    If dy/dt=ky and k is a nonzero constant then y could be\n    a. 2e^kty b. 2e^kt c. e^kt d. kty+5 e. 1/2ky^2 +1/2\n\n    I know the answer is b but i cant get that answer\n    Here is my work\n    S=integral sign\n\n\n    How do u get a 2 in there for choice b\n    Last edited: Jan 9, 2005\n  2. jcsd\n  3. Jan 9, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    You forgot about the constant of integration:\n    [tex]\\frac{dy}{dt}=ky [/tex]\n    [tex] \\frac{dy}y=kdt [/tex]\n    [tex] \\int{\\frac{dy}y} = \\int{kdt} [/tex]\n    [tex] \\ln y = kt +C [/tex]\n    [tex] e^{\\ln y} = e^{kt + C} [/tex]\n    [tex] y = e^{kt}\\cdot e^C [/tex]\n    eC is also a constant, so it can be written as C1 if you like.The value of C1 will depend on the initial conditions. Unless there's a typo in your answer list, I can see two answers that are of this form:\n    b. [tex]y=2e^{kt}[/tex]\n    and c. [tex] y = e^{kt} [/tex]\n\n    I hope that helps.\n  4. Jan 9, 2005 #3\n    thanks forgot the C and yea choice c was a typo it should be e^kt +3\n\nSimilar Discussions: Calc problem\n  1. Ap calc AB problems (Replies: 1)"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3146359/pdf-of-the-product-of-two-independent-uniformly-distributed-random-variables/3146380\nText:\nSuppose that X and Y are independent U[0,1]-random variables. Find the probability density function of the product V = XY.\n\nI have seen that \ud835\udc53(\ud835\udc67)=(\u22121)^(\ud835\udc5b\u22121)log(\ud835\udc5b\u22121)(\ud835\udc67)/(\ud835\udc5b\u22121)! for the product of n independent random variables from 0 < z < 1 but I am not sure how to derive this.\n\n\n$P(XY\\leq t)=EP(XY \\leq t |Y)=E(\\frac t Y I_{Y >t}+I_{Y \\leq t})$ so $P(XY\\leq t)=t\\log (\\frac 1 t)+t$ for $0<t<1$. The density is $\\log (\\frac 1 t)$ for $0<t<1$.\n\n  \u2022 $\\begingroup$ Where did you get the -tlogt +t after the indicator functions? $\\endgroup$ \u2013\u00a0gigglegirl6 Mar 13 at 10:36\n  \u2022 $\\begingroup$ @gigglegirl6 $\\int_t^{1} \\frac t y \\, dy=t\\log\\, y|_t^{1}=-t\\log\\, t$ $\\endgroup$ \u2013\u00a0Kavi Rama Murthy Mar 13 at 11:37\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1544458/proving-that-theres-no-translation-invariant-measure-on-the-power-set-of-math?noredirect=1\nText:\nThe goal of this task given to me is to show that there is no (non-trivial) translation invariant measure on $P(\\mathbb{R})$, the power set of $\\mathbb{R}$, and I think I almost completed it, but I just can't find a way to prove the very last bit that's missing. But let's start at the beginning.\n\nLet $\\mu: P(\\mathbb{R}) \\to [0, \u221e]$ be a measure that satisfies the following conditions:\n\n$(*) \\mu([0, 1]) = 1$ and $\\mu(x + A) = \\mu(A)$ for all $x \\in \\mathbb{R}, A \\subseteq \\mathbb{R}$.\n\nThe assignment asks me to consider the equivalence relation\n\n$x \\sim y :<=> x - y \\in \\mathbb{Q}$\n\nOut of every equivalence class, we choose a representative $x \\in [0, 1]$. Let $X \\subseteq [0, 1]$ be the set of representatives that we got that way.\n\nI am now to consider the sets $\\mathbb{R} = \\cup_{x \\in X} (x + \\mathbb{Q})$ and $\\mathbb{R} = \\cup_{q \\in \\mathbb{Q}} (X + q)$, and find a contradiction by showing that $\\mu$ would need to satisfy both $\\mu(X) = 0$ aswell as $\\mu(X) > 0$.\n\nWhat I've shown so far: I showed that $\\mu(\\mathbb{R}) = \u221e$ (using the fact that $[0, 1]$ is sent to $1$), aswell as that $\\mu(\\{a\\}) = 0$ for all $a \\in \\mathbb{R}$. From this, it also follows that all countable subsets of $\\mathbb{R}$ are sent to $0$ by $\\mu$ (so especially $\\mu(\\mathbb{Q}) = 0$).\n\nI've also shown that, since $\\mu(\\cup_{q \\in \\mathbb{Q}} (X + q)) = \u221e$ and since $\\cup_{q \\in \\mathbb{Q}} (X + q)$ is a countable, disjoint union, we have that $\\mu(X) > 0$.\n\nThe only part I'm still missing is to show that $\\mu(X) = 0$ via the fact that $\\mathbb{R} = \\cup_{x \\in X} (x + \\mathbb{Q})$, as written above. I just can't get my head around how I could show this. $\\cup_{x \\in X} (x + \\mathbb{Q})$ is a disjoint, but uncountable union because $X$ contains uncountably many elements; therefore, we can't use the $\\sigma$-additivity of a measure. I see that $\\mu(x + \\mathbb{Q}) = 0$ for each $x \\in X$, because $\\mathbb{Q})$ is countable, but I don't know how that helps me.\n\nI've also thought about decomposing $[0,1]$ into a disjoint union of sets, but that didn't lead anywhere so far. If we \"remove\" countably many points of $[0,1]$, the remaining set would still be sent to $1$ by $\\mu$, for the reasons given above. So how could I conclude that $X$ must be sent to $0$? I'm out of ideas.\n\n  \u2022 1\n    $\\begingroup$ As far as i can tell the fact you are trying to prove is(maybe a bit more) is in theorem 2.22 of rudin's real and complex analysis, chapter 2. $\\endgroup$ \u2013\u00a0random123 Nov 25 '15 at 9:42\n  \u2022 $\\begingroup$ @random123 Thanks, that helped me solve it indeed. While being slightly different from what I was trying tro prove (the theorem for example used the Lebesgue measure while I was just assuming there is $any$ measure, which made 1 - 2 things a little more difficult; also I had to replace the compact set by a bounded one), the proof itself could be used almost identically. $\\endgroup$ \u2013\u00a0moran Nov 26 '15 at 12:06\n  \u2022 $\\begingroup$ I admit that i did not look carefully into the theorem. I just remembered seeing something similar and suggested the same. $\\endgroup$ \u2013\u00a0random123 Nov 26 '15 at 13:12\n\nOne way of doing this is in analogy with the construction of the Vitali set.\n\nSuppose $X$ is defined as in your question. Construct $\\tilde{X}$ by taking each $x\\in X$, and then translating it by a rational to the interval $[0,\\epsilon)$ for some fixed $0<\\epsilon<1$. Then the set $\\tilde{X}$ is just $X$ where all representatives of the equivalence classes are chosen to lie in $[0,\\epsilon)$. Arguing as you did, we can show $\\mu(\\tilde{X})>0$.\n\nNow consider the set $$E=\\cup_{q\\in\\mathbb{Q}\\cap[0,1-\\epsilon]}(\\tilde{X}+q).$$ Then $E\\subset [0,1]$, and so $\\mu(E)\\le 1$. On the other hand, as the sets $\\tilde{X}+q$ are disjoint:\n\n$$\\mu(E)=\\sum_{q\\in \\mathbb{Q}\\cap[0,1-\\epsilon]}\\mu(\\tilde{X}+q).$$ Applying translational invariance $$=\\sum_{q\\in \\mathbb{Q}\\cap[0,1-\\epsilon]}\\mu(\\tilde{X}).$$ The sum is bounded above by $1$, and has countably infinitely many terms of size $\\mu(\\tilde{X})$. We must therefore have $\\mu(\\tilde{X})=0$, which contradicts our earlier result that $\\mu(\\tilde{X})>0$.\n\n\nI think that the question is not correct. If for each $Y \\subset R$ we set $\\mu(Y)=+\\infty$ if $card(Y)>\\aleph_0$ and $\\mu(Y)=0,$ otherwise, then $\\mu$ stands an example of nontrivial translation invariant measure in $R$ which vanishes on singletons.\n\nIf you require that in addition $\\mu$ must be $\\sigma$-finite, then such stated question is very old and it is not solvable within the theory $ZF$.\n\nFor example, if we accept Axiom of Choice then by using Ulam's well known theorem, asserted that on the powerset of the $\\aleph_1$ there does not exist a $\\sigma$-finite measure which vanishes on singletons, we get a negative answer.\n\nBut if we accept Steinhauss-Mycielski determinateness axiom about the existence of winning strategy then following Mycielski and Swierczkowskievery celebrated century theorem asserted that under that axiom each subset of the real axis is Lebesgue measurable we can answer positively on your question(cf. [Mycielski J., Swierczkowski S., On the Lebesgue measurability and the axiom of determinateness, Fund.,54,(1964),67-71]).\n\n  \u2022 $\\begingroup$ Let take an additive group $G_1$ of $R$ of the cardinality $\\aleph_1$, consider equivalent classes, consider any selector . Then by the union of $\\aleph_1$ shifts of this selector you cover axis. Your measure must be zero on these shifts by the invariance. Now You can construct a probability measure which is defined on the powerset of $G_1$ and vanishes on singletons. This contradicts to Unlam,s result. $\\endgroup$ \u2013\u00a0George Nov 26 '15 at 21:16\n  \u2022 $\\begingroup$ @moran The set $X$ is Vitali set. This is not Lebesgue measurable but there exists a translation invariant extension $\\mu$ of the lebesgue measure for which $\\mu(X)=0$. Hence this way is not clever to show the validity of your fact. $\\endgroup$ \u2013\u00a0George Nov 28 '15 at 12:00\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1100198/expected-value-and-variance-of-a-stochastic-process\nText:\nHaving trouble finding expected value and variance of a stochastic process defined by SDE:\n\n$dX_{t} = a X_{t} dt + b dB_{t}$\n\n$X_0 = x$, $a$ and $b$ are constant values, $B_t$~$N(0,t)$\n\nThank you for any help or pointers. I will now post my progresses:\n\n1) Considering an auxiliary process $Z_t=X_te^{-at}$\n\n2) Using Ito's formula to derive $dZ_t$ omitting quadratic covariance term due to it being between a stochastic and a determinist process (=0):\n\n$dZ_t = e^{-at} dX_t+X_t(-ae^{-at}) dt$\n\n3) Plugging in $dX_t$:\n\n\n\n\n4) Applying the integral on both sides ( change of variable from t to s inside the integral)\n\n$\\int_{0}^{t}dZ_s = b \\int_{0}^{t}e^{-as}dB_s $\n\n$Z_t-Z_0 = b \\int_{0}^{t}e^{-as}dB_s $\n\n5) Plugging back in $Z_t=X_te^{-at}$ and isolating $X_t$\n\n\n$X_t=X_0e^{at} + be^{at}\\int_{0}^{t}e^{-as}dB_s$\n\n6) Applying expectations\n\n$\\mathbb{E}(X_t)=xe^{at} + be^{at}\\,\\mathbb{E}(\\int_{0}^{t}e^{-as}dB_s)$\n\nI end up with this expression, now I know that I should use the Dol\u00e9ans exponential to prove that the stochastic integral is 0. But how can I proceed further to recover both expected value and variance?\n\n  \u2022 $\\begingroup$ So what happens if you plug in $dX_t$? (And I suppose $(B_t)_{t \\geq 0}$ is a Brownian motion. If so, the statement \"$B_t \\sim N(0,1)$\" is not correct.) $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:01\n  \u2022 $\\begingroup$ You plugged in $dX_t$, so there should be no \"$dX_t$\" in the last 3 lines. (Note that the expression $dB_t dX_t$ doesn't even make sense...) Consequently, you end up with $$dZ_t = b dB_t.$$ Solve it! $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:07\n  \u2022 $\\begingroup$ yes, thank you I'll fix the mistakes you pointed out and try to solve it, kinda new to Latex and stoch calculus, please bear with me $\\endgroup$ \u2013\u00a0Clemente Cortile Jan 11 '15 at 17:09\n  \u2022 $\\begingroup$ You are welcome. (There is a typo in my previous comment, it should read $dZ_t = b e^{-a t} \\, dB_t$.) $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:24\n  \u2022 $\\begingroup$ So far your calculations are correct. What does this tell you about $X_t$? $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:43\n\nHint: The stochastic integral\n\n$$M_t := \\int_0^t e^{-as} \\, dB_s$$\n\nis a martingale. Hence, $\\mathbb{E}M_t = \\mathbb{E}M_0=0$. In order to calculate the variance of $X_t$ use It\u00f4's isometry.\n\nAlternative approach: Since stochastic integrals are martingales, we have\n\n$$\\mathbb{E}X_t- \\mathbb{E}X_0 = \\int_0^t a \\cdot \\mathbb{E}X_s \\, ds,$$\n\ni.e. $m(t) := \\mathbb{E}X_t$ solves the ordinary differential equation (ODE)\n\n$$m'(t) = a \\cdot m(t) \\qquad m(0) = \\mathbb{E}X_0.$$\n\nThe (unique) solution is $m(t) =e^{at} \\mathbb{E}X_0$. Similarly, using It\u00f4's formla, one can show that\n\n$$\\mathbb{E}(X_t^2)-\\mathbb{E}(X_0^2) = \\int_0^t \\left( 2a \\mathbb{E}(X_s^2) + b^2 \\right) \\, ds.$$\n\nConsequently, $\\sigma(t) := \\mathbb{E}(X_t^2)$ solves\n\n$$\\sigma'(t) = 2a \\sigma(t)+b, \\qquad \\sigma(0) = \\mathbb{E}(X_0^2).$$\n\nSolving this (linear) ODE yields $\\mathbb{E}(X_t^2)$.\n\nRemark: The process $(X_t)_{t \\geq 0}$ is called Ornstein-Uhlenbeck process.\n\n  \u2022 $\\begingroup$ How is the expected value of a process defined? Does it depend on $t$? $\\endgroup$ \u2013\u00a0user415535 Sep 13 '17 at 10:03\n  \u2022 1\n    $\\begingroup$ @user21312 Yes, it does depend on $t$; the expected value is the mapping $m(t) := \\mathbb{E}(X_t)$. $\\endgroup$ \u2013\u00a0saz Sep 13 '17 at 12:51\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1966062/how-do-you-find-the-area-of-a-parallelogram-with-the-vertices/1966509\nText:\nHow do you find the area of a parallelogram with the following vertices; $A(4,2)$, $B(8,4)$, $C(9,6)$ and $D(13,8)$.\n\n\nclosed as off-topic by user21820, Xander Henderson, Jos\u00e9 Carlos Santos, YuiTo Cheng, RRL May 18 at 2:36\n\n\n\n  \u2022 $\\begingroup$ Use the determinant. $\\endgroup$ \u2013\u00a0Steven Gubkin Oct 13 '16 at 13:05\n\nFor this, we plan to use the Shoelace formula.\n\nShoelace Formula: Given the coordinates of vertices of a polygon, its area is found by $$A=\\frac 12\\left|\\sum_{i=1}^{n-1}x_iy_{i+1}+x_ny_1-\\sum_{i=1}^{n-1}x_{i+1}y_i-x_1y_n\\right|$$ Or, in other words, we have $$A=\\frac 12|x_1y_2+x_2y_3+\\ldots x_{n-1}y_n+x_ny_1-x_2y_1-x_3y_2-\\ldots -x_ny_{n-1}-x_1y_n|$$ Where $A$ is the area of the polygon, and $(x_i,y_i)$ with $i=1,2,3\\dots$ are the vertices of the polyon\n\nSo with your case, the vertices are $A(4,2), B(8,4), C(9,6)$ and $D(13,8)$. We let $x_1=13,y_1=8,x_2=9,y_2=6,x_3=4,y_3=2,x_4=8,y_4=4$ and the area is given by $$A=\\frac 12|13\\cdot 6+9\\cdot 2+4\\cdot 4+8\\cdot 8-9\\cdot 8-4\\cdot 6-8\\cdot 2-13\\cdot 4|\\\\=\\frac 12\\cdot 12=6$$\n\n  \u2022 $\\begingroup$ You answered with another person's answer? xD $\\endgroup$ \u2013\u00a0Billy Rubina Oct 13 '16 at 8:15\n  \u2022 4\n    $\\begingroup$ This is hitting a nail with a sledge hammer. There aren't many polygons that are as simple to handle as parallelograms. Or to be more specific, it is very probably the computation for parallelograms (and derived from that, triangles) that serves as basis for deriving the shoelace formula. $\\endgroup$ \u2013\u00a0Marc van Leeuwen Oct 13 '16 at 9:14\n\nThe absolute value of the cross product of two vectors $\\vec{a}, \\vec{b} \\in \\mathbb{R}^3$ spanning the parallelogram is its area:\n\n$$A_\\text{parallelogram}= \\left|\\vec{a}\\times\\vec{b}\\right|$$\n\nSo in your case we have to write the points in $\\mathbb{R}^2$ as vectors in $\\mathbb{R}^3$ and apply the formula:\n\n$\\vec{AB}\u00a0= \\begin{pmatrix}8\\\\4\\\\0\\end{pmatrix} -\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} =\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix}$\n\n$\\vec{AD}\u00a0= \\begin{pmatrix}13\\\\8\\\\0\\end{pmatrix} -\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} =\\begin{pmatrix}9\\\\6\\\\0\\end{pmatrix}$\n\n$A_\\text{parallelogram}= \\left|\\vec{AB}\\times\\vec{AD}\\right| = \\left| \\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} \\times \\begin{pmatrix}9\\\\6\\\\0\\end{pmatrix} \\right| = \\left|\\begin{pmatrix}0\\\\0\\\\6\\end{pmatrix} \\right| = 6$\n\nYou might have noticed that this simplifies to\n\n$$A_\\text{parallelogram}= (b_1 - a_1)(d_2-a_2)-(b_2-a_2)(d_1-a_1)$$ $$= (8 - 4)(8-2)-(4-2)(13-4)=-24-(-18)=6$$\n\n\nThere are plenty of ways, such as the Shoelace Theorem and Pick's Theorem.\n\nIf you have a graph, you can also simply draw a rectangle around the shape and subtract the parts you don't want.\n\n\nI think this is a special case of shoelace theorem. A quad is made up of two triangle and area of a triangle is\n\n$${1\\over 2}{|x_1(y_2 - y_3) + x_2(y_3 - y_1) + x_3(y_1 - y_2)|}$$\n\nOr you can use distance formula\n\n$$distance = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$\n\nand then heron's formula\n\n$$A = {1\\over 2}\\sqrt{s(s-a)(s-b)(s-c))}$$ Where s is the semi-perimeter of the triangle and, a,b,c are the length of its sides.\n\n\nFor any quadrilateral the area is one-half the magnitude of the cross product of the two diagonal vectors.\n\n\nI am just providing you with the simplest shortcut to doing this\n\nPick the first three points A(4,2), B(8, 4) and C(9, 6)\n\nNegate point A to get (-4, -2) and add to the other two points B and C. Add x's and y's so you have a new point\n\n(4, 2) (5, 4) Now use determinant to find the area.\n\n16-10 = 6sq unit\n\nNeglect any negative sign that arises\n\n  \u2022 $\\begingroup$ I don't understand so much. What is 6sq unit? $\\endgroup$ \u2013\u00a0El borito Jan 25 at 4:47\n  \u2022 $\\begingroup$ square unit as in square meter or any unit of length measurement...mm, cm, m..etc $\\endgroup$ \u2013\u00a0Daniel Wasty Jan 25 at 4:49"}
{"text": "Retrieved from https://math.stackexchange.com/questions/631576/probability-of-x-heads-before-y-consecutive-tails-in-n-biased-coin-tosses\nText:\nI have another coin toss question:\n\nAssume I am tossing a biased coin n times with probability p of coming up heads. What is the probability that x heads come up, before y consecutive tails?\n\nA code example would be preferable.\n\n  \u2022 $\\begingroup$ Just to be clear about what you mean, is HTHTT a case where $x=2$ heads come up before $y=2$ consecutive tails? Or did you mean to say \"$x$ consecutive heads\"? $\\endgroup$ \u2013\u00a0Barry Cipra Jan 8 '14 at 17:42\n  \u2022 $\\begingroup$ @BarryCipra, Yes, the heads do not need to be consecutive. $\\endgroup$ \u2013\u00a0user27 Jan 8 '14 at 17:46\n\nConsider the following events:\n\n$A_{x,y}$: You observe $x$ heads before $y$ consecutive tails.\n\n$B_{x,y}$: You observe $y$ consecutive tails before $x$ heads.\n\nLet $X_{i}$ follow a Geometric(p). This means that $X_{i}$ denotes the number of tail counts until you observe the first head with a biased coin. Observe that, in particular, $P(A_{1,y}) = P(X_{1} < y)$.\n\nIn order to solve for the general case, consider $X_{1},\\ldots,X_{x}$ i.i.d. Geometric(p). I claim that:\n\n\\begin{align*} P(A_{x,y}) = P(X_{1} < y, \\ldots,X_{x} < y) = P(X_{1} < y)^{x} \\end{align*}\n\nIn order to understand the claim, you can think of $X_{i}$ as the number of observed tails it takes until you observe a head after having already observed $i-1$ heads in the past. Hence, we only need to find $P(X_{1} < y)$. This is well known and equals $1-(1-p)^{y}$.\n\nHence, in general $P(A_{x,y}) = (1-(1-p)^{y})^{x}$\n\n  \u2022 $\\begingroup$ Thank you! Though this does not answer my question exactly, since I was asking for a specific maximum number of tosses. On second thought, I don't actually need to know this, so I marked your answer as accepted. $\\endgroup$ \u2013\u00a0user27 Jan 9 '14 at 16:09\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/115540/read-switch-status-without-interfering-with-led\nText:\nI'm a software guy trying to get my head around how to measure the status of a switch connected to a LED as shown below through a digital input of a MCU.\n\nMy first try was many variations of circuit 1 below - seems every iteration I've tried causes the LED to dimly light even when SW1 is open. I've eliminated R3 and this issue still exists. I believe R3 and the MCU input provides a path to ground causing the LED to dimly light.\n\nI then stumbled upon circuit 2 below which seems to work well. I can read the status of SW1 and the LED works correctly. Unfortunately I don't know why it works and therefore don't feel comfortable with it.\n\nCan anyone suggest methods to read the status of SW1 with a MCU without interfering with the LED? Also why does circuit 2 appear to work?\n\n\n\nsimulate this circuit \u2013 Schematic created using CircuitLab\n\n  \u2022 2\n    \\$\\begingroup\\$ Is the ground of the MCU connected to the negative terminal of the battery? \\$\\endgroup\\$ \u2013\u00a0Ignacio Vazquez-Abrams Jun 16 '14 at 4:13\n  \u2022 \\$\\begingroup\\$ Yes the MCU is connected to a common ground with the battery \\$\\endgroup\\$ \u2013\u00a0user45675 Jun 16 '14 at 4:30\n\nYour second circuit is perfect, provided that the pullup on the input is enabled.\n\nWhen the switch is open, the anode of D1 is at VDD, and the cathode of D1 is at 13V-Vf. The diode prevents the higher voltage from reaching the input pin and destroying the MCU.\n\nWhen the switch is closed, the cathode of D1 is at 0V, pulling the anode down to 0.7V and registering a low at the input.\n\nYou don't need the resistor since the pullup will not source enough current to damage the diode, but you must have the diode in order to prevent the higher voltage from reaching the MCU.\n\n\nIn the second circuit, with the values of R2 and the MCU's enabled pull-up unknown, a voltage divider will be formed which might not allow the MCU's I/O to get close enough to 0V, when SW1 is made, to read a logical 0.\n\nThis will work with either the MCU's internal, or an external pull-up.\n\n                                             Vcc       MCU\n                                              |    +--------- \n                                              |    |     \n  13V    +----------------------+            [R2]  |     \n     \\   |                      |             |    |\n      |  |                  /   |                  |\n    [BAT]|                 / O  |                  |\n      |- |              SW1  |  |                  |\n         |                      |                  +----\n\nYour Answer"}
