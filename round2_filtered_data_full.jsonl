{"text": "Retrieved from http://mathforum.org/library/drmath/view/53260.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSubtracting Different Types of Units\n\nDate: 05/26/2001 at 16:41:16\nFrom: Bruce Herman\nSubject: Subtracting units of different types\n\nI have a question about the following proposed solution for this \n\nTommy bought 20 pieces of candy for 20 cents. A piece of fudge costs 4 \ncents, gumdrops are 4 for a penny, and chocolate drops are 2 for a \npenny. If he bought all these varieties, how many of each did he buy? \nHere is the solution one of my students came up with:\n\n1)  4f + g/4 + c/2 = 20     multiply everything by 4\n\n2) 16f + g   + 2c  = 80\n3)   f + g   +  c  =  2     subtract line 3 from line 2\n4) 15f       +  c  = 60\n\n5) Since 15f is a multiple of 15, 15f can only be 15, 30, or 45, from \n   f = 1, 2, or 3 respectively.\n\n6) If f = 1, then there are 45 chocolate drops; that's too many\n7) If f = 2, then there are 30 chocolate drops; that's too many\n8) If f = 3, then there are 15 chocolate drops; that's good\n\n9) So we have 3 fudge and 15 chocolate drops, so we have 2 gumdrops, \n   which works out to 3 fudge = 12 cents; 15 chocolate drops = \n   7.5 cents; and 2 gumdrops = .5 cents; that does work.\n\nThe question the class has, which I can't explain, is that when we \nsubtract line 3 from line 2, it looks as if we are subtracting the \nnumber of items from the cost of the items. How can we subtract when \nwe are looking at different units?\n\nDate: 05/26/2001 at 23:31:08\nFrom: Doctor Peterson\nSubject: Re: Subtracting units of different types\n\nHi, Bruce (and class!)\n\nInteresting question. I have two ways to look at it.\n\nFirst, in my mind when I write an equation it is abstract, and doesn't \ninvolve units. I hide the units in the definitions of the variables \n(for example, by saying \"x is the length in meters,\" so that x itself \nis merely a number); in this case, \"f is the number of pieces of \nfudge,\" and f is just a number, which becomes a number of pieces of \nfudge only when I apply my solution back to the actual problem. When \nyou write the equation for cost, you are initially thinking of units,\n\n     4 cents/piece * f pieces + 1/4 cent/piece * g pieces\n     + 1/2 cent per piece * c pieces = 20 cents\n\nbut then you drop the units (dividing the whole equation by \"cents\") \nto get merely:\n\n     4f + g/4 + c/2 = 20\n\nNow when you do the algebra, you can ignore units; the algebra doesn't \n\nSecond, I have to admit there are times when I do like to think of an \nequation as having units, so that I can check, for instance, that \nevery term represents an area, and I am not trying to add areas and \nlengths, which would indicate I made an error. If I want to do that \nhere, I will have to say that equation (2) is in cents, while \nequation (3) is in pieces, and in order to subtract the latter I have \nto multiply it by the unit fraction \"cents/piece\" (just as I might \nhave had to multiply it by 2 before subtracting) so that the units as \nwell as the numbers match and I can really subtract like terms. I \nwouldn't bother with that sort of thinking here, but it might be worth \n\nMaybe there's a third way to think this out. Often equations like \nthese can be solved concretely, as I have to do in solving this sort \nof problem with a student who hasn't had any algebra. That is, rather \nthan work with variables, I would manipulate the actual objects, \nexchanging them, moving them to the other side of a scale, and so on. \nWe would say in this case, first suppose Tommy bought four times as \nmuch of everything; then he would have spent 80 cents. (This gives \nequation 2.) Now suppose I pay him a penny for each item, regardless \nof its type (subtracting equation 3 from equation 2)... I'm not sure \nhow I would finish this, but you might like to try it and see what \nconcrete explanation you could give for that step. That would explain \nwhere the units go, and I suspect you will find it matches one of my \nanswers above.\n\n- Doctor Peterson, The Math Forum\n\nDate: 05/27/2001 at 11:16:36\nFrom: (Anonymous)\nSubject: Re: Subtracting units of different types\n\nHow would that last work?  \n\n        16f + g + 2c = 80\n     -     f + g + c = 20\n\nIf each variable in the latter equation, as you suggest, is a penny, \nthen how can you take away 20? Shouldn't you be taking away 3?\n\nDate: 05/28/2001 at 22:56:53\nFrom: Doctor Peterson\nSubject: Re: Subtracting units of different types\n\nHi, Bruce.\n\nActually, this part doesn't make any sense to me either; it was late, \nI just had this idea that _some_ concrete solution might help explain \nwhat's going on, but I couldn't come up with a good solution along \nthose lines, so I just left you with a suggestion of the kind of thing \nI had in mind, hoping you might be able to finish it, or that I would \ndream up such a solution. Let's think it through now.\n\nThe closest thing I can think of would be a concrete solution to \nsomething simpler, like:\n\n    I bought 8 items, some for 5 cents and some for 2 cents, and\n    they cost a total of 25 cents. What did I buy?\n\nAlgebraically, this becomes\n\n      x + y = 8    (items)\n    5x + 2y = 25   (cents)\n\nand we subtract twice the first from the second to get\n\n    3x = 9\n     x = 3\n\n     y = 8 - x = 5\n\nTo solve this without algebra, I would probably use an exchange \nmethod, like this:\n\n    If all 8 items cost 2 cents, the total would be only 16 cents. I\n    have to add 9 cents to that. If I replace one 2-cent item with a\n    5-cent item, I have the same number of items but add 3 cents to\n    the cost. In order to add 9 cents, I have to do this 3 times; so\n    I will have 3 5-cent items and 5 2-cent items.\n\nAlgebraically, this is equivalent to substitution:\n\n              y = 8 - x\n  5x + 2(8 - x) = 25\n        16 + 3x = 25\n             3x = 9\n              x = 3\n\nThe step that is equivalent to your addition of \"counts and costs\" is \nthe substitution; but doing it this way, there's no unit conflict; I'm \nsimply multiplying 2 cents/item by 8-x items. I think this suggests \nthat what we're really doing when we subtract equations is multiplying \nthe first equation not just by 2, but by 2 cents/item. That agrees \nwith my second suggestion last time; but I don't think it really makes \nanything any clearer.\n\nThe fact is, combining two equations is an inherently abstract \noperation, and we're not really dealing with units at all, just \nnumbers. The substitution method is more basic and intuitive, and fits \nbetter with the use of units.\n\nI'll be interested to hear whether any of these ideas help your \nstudents at all!\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nHigh School Basic Algebra\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/70523/grothendiecks-galois-theory-without-finiteness-hypotheses?sort=newest\nText:\nSign up \u00d7\n\nThis is motivated by the discussion here. The usual definition of the etale fundamental group (as in SGA 1) gives automatic profiniteness: Grothendieck's formulation of Galois theory states that any category with a \"fiber functor\" to the category of finite sets satisfying appropriate hypotheses is isomorphic to the category of finite, continuous $G$-sets for a well-defined profinite group $G$ (taken as the limit of the automorphism groups of Galois objects, or as the automorphism group of said fiber functor). In SGA1, the strategy is to take finite etale covers of a fixed (connected) scheme with the fiber functor the set of liftings of a geometric point.\n\nOne problem with this approach is that $H^1(X_{et}, G)$ for a finite group $G$ (which classifies $G$-torsors in the etale topology) is not isomorphic to $\\hom(\\pi_1(X, \\overline{x}), G)$ unless $G$ is finite. Indeed, this would imply that the cohomology of the constant sheaf $\\mathbb{Z}$ would always be trivial, but this is not true (e.g. for a nodal cubic). However, Scott Carnahan asserts on the aforementioned thread that the \"right\" etale fundamental group of a nodal cubic should be $\\mathbb{Z}$, not something profinite.\n\nHow exactly does this work? People have suggested that one can define it as a similar inverse limit of automorphism groups, but is there a similar equivalence of categories and an analogous formalism for weaker \"Galois categories\"? (Perhaps one wants not just all etale morphisms but, say, torsors: the disjoint union of two open immersions might not be the right candidate.) I'm pretty sure that the finiteness is necessary in the usual proofs of Galois theory, but maybe there's something more.\n\nshare|cite|improve this question\n\n5 Answers 5\n\nup vote 7 down vote accepted\n\nCheck out Section 2 of Noohi's paper \"Fundamental groups of topological stacks with slice property\"\n\nshare|cite|improve this answer\nThanks. This (in particular, Theorem 2.16) is very nice. \u2013\u00a0 Akhil Mathew Jul 18 '11 at 18:04\n\nIn \"The pro-\u00e9tale topology for schemes\" (, Bhatt and Scholze introduce the pro-\u00e9tale fundamental group which seems to give a good answer to your question (see, e.g., Theorem 1.10). The pro-\u00e9tale fundamental group also compares well against the usual \u00e9tale fundamental group and the \"SGA3 \u00e9tale fundamental group\".\n\nshare|cite|improve this answer\nThank you! I've been meaning to look at this paper for some time now. \u2013\u00a0 Akhil Mathew Nov 29 '13 at 22:14\n\nBesides the references already given above, one can also mention:\n\nSGA III 2 LNM 152 exp X /S 7 where Grothendieck sketches the theory of an enlarged fundamental group (\"groupe fondamental \u00e9largi\").\n\nThis was later on formalized in terms of Galois toposes in Olivier Leroy's Phd \"Groupoide Fondamental et Theoreme de van Kampen en Theorie des Topos\" which unfortunately does not seem to be widely available. Roughly, it goes at follows. A topos $E$ is locally Galois if it is locally connected and if every object is a sum of locally constant objects: $SLC(E)=E$ (equivalently, if it is generated by its Galois objects [ a Galois object is a locally constant non-empty object that is a pseudo-torsor under its automorphism group]). Such a locally Galois topos can be recovered from the groupoid (in the categorical sense) of its points in the sense that the functor $E\\rightarrow (Point(E))^\\wedge$ defines an equivalence of toposes (here for a groupoid $C$, $C^\\wedge$ denotes the topos of presheaves on $C$). To sum up, $E\\mapsto Point(E)$ defines an equivalence between locally Galois toposes and groupoids. You can find more details in Vincent Zoonekynd's paper The fundamental group of an algebraic stack at this address\n\nThen starting from a scheme $X$, you can consider the topos $SLC(\\widetilde{X_{et}})$ of locally constant sheaves for the \u00e9tale topology. This is a Galois topos, the automorphism group of a point is Grothendieck's enlarged fundamental group. If instead the \u00e9tale topology you stick to the finite \u00e9tale topology $X_{fet}$, where covers are given by surjective families of finite \u00e9tale maps, your recover the traditional profinite fundamental group of SGA1.\n\nshare|cite|improve this answer\nAs Leroy's notes are difficult to find, it might be worth mentioning that this Galois theory for topoi has been rediscovered by Ieke Moerdijk in his paper \"Prodiscrete groups and Galois toposes\", Nederl. Akad. Wetensch. Indag. Math. 51 (1989), no. 2, 219\u2013234. \u2013\u00a0 Denis-Charles Cisinski Jul 19 '11 at 17:41\nInteresting. Thanks for these references! \u2013\u00a0 Akhil Mathew Jul 20 '11 at 4:32\n\n\n\n\n(iii) $F$ preseves strict epimorphisms.\n\n\n\n\n\n\n\n\n\n\n\n\n\nshare|cite|improve this answer\n\nIn Dubuc and de la Vega's very nice write-up of Grothendieck's Galois theory they cover the pro-group case when the fibre functor is representable (see section 5.5):\n\nConsider a category $C$ and an object $A \\in C$. Axioms on $C$:\n\nR1) $C$ has a terminal object and pullbacks (thus all finite limits).\n\nR2) $C$ has coequalizers.\n\nR3) $C$ has coproducts.\n\nAxioms on $A$ (in terms of the representable functor $[A, \u2212]$):\n\nR4) $[A, \u2212]$ preserves coequalizers.\n\nR5) $[A, \u2212]$ preserves coproducts.\n\nR6) $[A, \u2212]$ reflects isomorphisms.\n\nNote that $[A,-]$, a priori a functor to $Set$, lifts to $Set^{Aut(A)}$, the category of $Aut(A)$-sets. Given these axioms, we get an adjoint equivalence between $C$ and $Set^{Aut(A)}$. Clearly this is a step in the right direction, but not what you are after.\n\nIn section 6.2 they mention the more general case -- prorepresentable but not finite -- and say they will develop it elsewhere. There is also a reference to SGA IV 2.7, where some of this is stated but not proved (as an aside, of course there is the usual warning that topos in SGA means Grothendieck topos, elementary topoi not being invented yet).\n\nI'm not sure where this 'elsewhere' is, but likely to be written down in the guise of representation theorems for Galois topoi.\n\nshare|cite|improve this answer\nThanks. This is indeed very close to what I was looking for. Though it seems that there is no reason to expect a \"universal cover\" in the etale sense. \u2013\u00a0 Akhil Mathew Jul 17 '11 at 16:31\nOf course. There are some hints in the paper I linked to, such as strengthening the behaviour of the fibre functor to preserving not just finite limits, but all copowers with a fixed object. I think the answer is out there, but I didn't have time to hunt it down, and I suspect it is not phrased in the usual language. Perhaps something like 'A connected Galois topos with a pro-point is the topos of continuous actions of a progroup' or something like that. \u2013\u00a0 David Roberts Jul 17 '11 at 22:44\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/64035/can-a-nonzero-polynomial-evaluate-to-the-zero-function-in-a-suitable-infinite-ri?answertab=votes\nText:\nSign up \u00d7\n\nI shall assume all rings to be commutative in this question. The impatient can scroll down to the \"blockquote\" to read the actual question.\n\nWhenever we have a polynomial over a ring, it defines a function from the ring to itself by evaluation. It's reasonable to ask when two different polynomials define the same function.\n\nFrom the factor theorem it follows that an $n^\\text{th}$ degree polynomial over an integral domain has at most $n$ roots. Then it's easy to show this:\n\nTheorem. Let $R$ be an infinite integral domain and let $f \\in R[X]$ such that $f(a)=0$ for all $a \\in R$, then $f = 0$.\nProof. $f$ has infinitely many roots, so it must be the zero polynomial. $\\quad\\square$\n\nFor finite rings a kind of opposite situation occurs:\n\nTheorem. For any finite ring $R$ there are polynomials over $R$ that are different but agree on all elements.\nProof. There are only finitely many functions from $R$ to itself, but $R[X]$ is infinite. $\\quad\\square$\n\nIf we make further assumptions it's of course possible to prove more, as Pete L. Clark wrote in this post: [1]\n\nThen there is the question of infinite rings that are not integral domains. It's relatively easy to come up with examples of a ring $R$ with positive characteristic and a nonzero polynomial that evaluates to the zero function, e.g.: $$ R := \\bigoplus_{n=1}^\\infty \\mathbb{Z}/6\\mathbb{Z} \\quad\\text{and}\\quad f(X) := X^3-X.$$\n\nThe Question:\n\nThis leaves open the case alluded to in this post's title: Is there a commutative ring of characteristic $0$ (hence infinite) such that a nonzero polynomial evaluates to the zero function?\n\nshare|cite|improve this question\n+1 for the hint for the impatient. \u2013\u00a0 lhf Sep 13 '11 at 0:34\n\n2 Answers 2\n\nup vote 15 down vote accepted\n\nYes. I'll give my example first. Below is the TeXing I did while thinking that I was proving the answer to be \"no\". Trying to prove the answer was \"no\" led me to this example:\n\nLet $R=\\mathbb{Z}[y]/\\langle 6y,y^2\\rangle$. This commutative ring has characteristic zero, since no integer is in the ideal $\\langle 6y,y^2\\rangle$. And now you can just slide over your polynomial example so that it always evaluates to zero: $$f(X) = y\\;X^3-y\\;X=y\\;(X^3-X)$$\n\nJust as in your example, $X^3-X$ always evaluates to a multiple of $6$ when $X$ is an integer. More generally if $X=a+b\\;y$, then since $y^2$ is modded out, we only need consider the constant term $a$.\n\nIf you changed the question to be about integral domains rather than characteristic zero rings, then the answer would be \"no\" by completing the argument below.\n\nSuppose that $f$ is such a polynomial in $R[x]$ of degree $n$: $$f(x)=\\sum_{j=0}^n\\;c_j\\;x^j$$ The equations $$f(i)=0$$ for $i=0\\ldots n$ form a system of $n+1$ linear equations in the unknowns $\\{c_j\\}$. There is one clear solution to this system, where each $c_j=0$. But can there be other solutions with $c_j\\in R$?\n\nThe system can be written as $$\\begin{bmatrix}1 & 0 & 0 & \\cdots & 0\\\\ 1 & 1 & 1 &\\cdots & 1\\\\ 1 & 2 & 4 &\\cdots & 2^n\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\ 1 & n & n^2 & \\cdots & n^n\\end{bmatrix} \\begin{bmatrix}c_0\\\\c_1\\\\c_2\\\\\\vdots\\\\ c_n\\end{bmatrix} =\\begin{bmatrix}0\\\\0\\\\0\\\\\\vdots\\\\0\\end{bmatrix}$$\n\nThe matrix on the left (which I will call $V$) is an example of a Vandermonde matrix which is invertible in $M(\\mathbb{Q})$. Now, $V$ might not have an inverse in $M(R)$, but that's not a big problem. It's still the case that in $M(R)$ there is a matrix $W$ such that $W\\;V$ is a scalar matrix $D$ with an integer $d$ running down the diagonal. You just need to rescale $V^{-1}$ by the least common multiple of the divisors that appear in $V^{-1}$. After applying $W$ to both sides, $$D \\begin{bmatrix}c_0\\\\c_1\\\\c_2\\\\\\vdots\\\\ c_n\\end{bmatrix} =\\begin{bmatrix}0\\\\0\\\\0\\\\\\vdots\\\\0\\end{bmatrix}$$\n\nSo there is some nonzero integer $d$, such that for each $j$, we have that $d\\cdot c_j=0$.\n\nHere I realized the answer is actually \"yes\".\n\nshare|cite|improve this answer\nI just came back to this again, and I realised that we can take $R := \\mathbb{Z} \\times \\mathbb{Z}/6\\mathbb{Z}$ and $f(X) := (0,1)X^3 - (0,1)X$. It's not exactly isomorphic to your example ($(0,1)^2 \\neq (0,0)$) but yours helped a lot with finding it \u2013\u00a0 kahen Sep 15 '11 at 9:17\n\nConsider the ring generated by $a$ with $a^2 = 0$, and take $p(x) = a x$.\n\nshare|cite|improve this answer\nRobert: Come on: Kahen said a ring, not a rng. Let's stay serious here... \u2013\u00a0 Pete L. Clark Sep 13 '11 at 1:26\n@Pete: thnk t was a serous and constructve answer. \u2013\u00a0 zyx Sep 13 '11 at 2:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162332/g-12-and-no-elements-of-order-2-in-zg\nText:\nTake the 2-minute tour \u00d7\n\nI am thinking on the following problem:\n\nIf $|G|=12$ and there is no element of order $2$ in its center then $3$-Sylow subgroup of $G$ cannot be normal in $G$.\n\nI was told that to assume the $3$-Sylow subgroup of $G$, say $P$, is normal in the group and go to reach a contradiction.\n\nMy attept: $|P|=3$ so it is cyclic, $P=\\langle x\\rangle=\\{1,x,x^2\\}$. As above hint, I would have for all $g\\in G$ two possibilities: $gxg^{-1}=x$ or $gxg^{-1}=x^2$. Cannot to go any further. I am in doubt if the hint leads me to a contradiction properly and if so, it does with a long proof. Any help or any other way are welcome to me. Thanks for your time.\n\nshare|improve this question\nThis is a followup to math.stackexchange.com/questions/158339/\u2026 \u2013\u00a0 Jack Schmidt Jun 24 '12 at 19:10\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nHint #1: Show that all Sylow 2-subgroups are abelian. So if an element of a Sylow 2-subgroup commutes with the elements of $P$, then it belongs to the center.\n\nHint #2: At this point the questions you should ask from yourself are: 1) What possibilities (up to isomorphism) are there for the Sylow 2-subgroup H? 2) Given that $P$ was assumed to be normal, what possibilities are there for the conjugation action for the non-trivial elements of $H$. Remember that conjugation action is a homomorphism from $H$ to $Aut(P)$.\n\nshare|improve this answer\n:About you first hint: That the Sylow 2-subgroups is abelian is obvious cause they are of order 4. So I should show that an element of one of these subgroups COMMUTE with $x$. Thanks. As you said me later, you put a loop in my mind finding the result. :-) \u2013\u00a0 Babak S. Jun 24 '12 at 10:14\nCorrect (re: the 1st hint). Be a bit careful in that the element of $H$ that commutes with $P$ should be of order two. It doesn't really matter much in this case, but for full credit... :-) \u2013\u00a0 Jyrki Lahtonen Jun 24 '12 at 10:29\nI am on the way you paved. Yes, with that element say $y$, I can see that $G$ is being generated by $x$ and $y$. Thanks. Thanks. \u2013\u00a0 Babak S. Jun 24 '12 at 10:38\n\nTo follow your attempt:\n\nFor every $g \\in G$, we have $gxg^{-1} = x$ or $gxg^{-1} = x^2$. Thus $x$ has $1$ or $2$ conjugates, in other words, $[G : C_G(x)] = 1$ or $[G : C_G(x)] = 2$. In both cases, $2$ divides the order of $C_G(x)$, and thus $C_G(x)$ contains an element $y$ of order $2$. This gives us the desired contradiction. Can you see why $y$ must belong to the center of $G$?\n\nshare|improve this answer\nThanks for your answer. It solves my problem in detail. :) \u2013\u00a0 Babak S. Jun 25 '12 at 5:39\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/433323/self-adjoint-operator-on-a-finite-dimensional-vector-space\nText:\nTake the 2-minute tour \u00d7\n\nLet $V$ be a finite-dimensional inner product space and let $x,y\\in V$ be nonzero vectors. If there is a self-adjoint operator $A:V\\rightarrow V$ such that $A(x)=y$ and $\\langle A(v),v\\rangle\\geq0$ for all $v\\in V$, then $\\langle x,y\\rangle>0$.\n\nI think we can conclude the following inequality $$\\langle x,y \\rangle=\\langle x,A(x) \\rangle=\\langle A^*(x),x \\rangle=\\langle A(x),x\\rangle\\geq 0$$\n\nbut I'm not able to show that strict inequality holds (or, in other words, that equality is not possible). Can someone give me a hint?\n\nshare|improve this question\nI added the operator theory tag since the result is true more generally (and can be proved the same way) on a Hilbert space, with $A$ a bounded self-adjoint positive operator. \u2013\u00a0 1015 Jul 1 '13 at 1:04\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nAssume for a contradiction that $(x,y)=0$. Then take an orthonormal basis $(e_j)$ of $V$ starting with $$ e_1=\\frac{x}{\\|x\\|}\\qquad e_2=\\frac{y}{\\|y\\|}. $$ The matrix $M$ of $A$ in this orthonormal basis must be symmetric semidefinite positive, and it looks like $$ M=\\pmatrix{0&t&0\\\\ t&*&*\\\\ 0&*&*}\\qquad t=\\frac{\\|y\\|}{\\|x\\|}>0 $$ by blocks, where the first and the second row are the actual first and second rows of $M$, the remaining blocks being of the ad hoc size.\n\nCan you see a contradiction?\n\nConsider the restriction of the quadratic form $(Ax,x)$ to the span of $\\{e_1,e_2\\}$, whose matrix is the upper-left $2\\times 2$ block of $M$. Since the restriction should be semidefinite positive as well, its eigenvalues, whence its determinant $-t^2<0$, must be nonnegative. Contradiction.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/275434/1st-order-linear-ode-with-tridiagonal-matrix-efficient-solutions\nText:\nTake the 2-minute tour \u00d7\n\nI have a 1st-rder linear ODE system where the system is characterized by $A$. Given an initial state $x_0$, I want the state at some later time $t$, efficiently.\n\n$A$ happens to be a symmetric tridiagonal matrix where the coefficients are the same in each diagonal line.\n\n$$ A = \\begin{pmatrix} a & b & 0 & 0 & ... \\\\ b & a & b & 0 & ... \\\\ 0 & b & a & b & ... \\\\ 0 & 0 & b & a & ... \\\\ \\vdots &&\\ddots&\\ddots&\\ddots\\end{pmatrix} $$\n\nI need to solve this for many different $A$'s and also many different $x_0$'s. The general solution to that is of course\n\n$$x_t = e^{A t}x_0$$\n\nOne way to do this is to eigen-decompose $A$ into $A = F D F^\\top$. Then the solution becomes\n\n$$x_t = (F e^{D t} F^\\top) x_0$$\n\nWhich is a little better because now the multiplication with $x_0$ is $O(n^2)$, but the eigen-decomposition is $O(n^3)$ still. But this doesn't take advantage of the constant values of $a$ and $b$ or the symmetric tridiagonal nature of $A$. So it seems like I should be able to do better.\n\nshare|improve this question\nThere is a nice paper on numerical computation of matrix exponential: Nineteen Dubious Ways to Compute the Exponential of a Matrix by Moler & Van Loan (this is an update of the original paper, 25 years later). \u2013\u00a0 Jean-Claude Arbaut Apr 30 '14 at 22:17\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nI'm not aware of any special algorithms for computing matrix exponentials for matrices with tridiagonal structure, but you probably shouldn't be solving your ODE by directly computing the matrix exponential anyway. Computing matrix exponentials is a tricky business. There's a famous paper by Cleve Moler (inventor of MATLAB) and Charles van Loan that you should check out titled \"Nineteen Dubious Ways to Compute the Matrix Exponential\". It goes through a variety of schemes people have tried over the years and discusses the problems with each one. That's not to say it can't be done but that it's something that needs to be handled with care.\n\nThe good news is that there are plenty of ways to numerically solve your ODE without having to resort to the matrix exponential, and these are all almost certainly more efficient. As an example, consider Euler's method. You want the solution at time $t = t_f$ to $x'(t) = Ax(t)$ with initial condition $x(0) = x_0$. Pick $K + 1$ equally-spaced time-points $0 = t_0 < t_1 < \\cdots < t_K = t_f$, and let $h = (t_f - t_0)/K$ be the spacing between them. Let $x_k$ denote the approximation to the solution at time $t_k$. Euler's method is just the iteration $x_{k + 1} = x_k + hAx_k$.\n\nEach step requires one matrix-vector multiply and one addition of two vectors. Since your matrix is tridiagonal, the matrix-vector multiply will be $O(3n)$, and the vector addition will be $O(n)$. With $K + 1$ steps, you're looking at an overall computational complexity of $O(nK)$. As far as accuracy goes, Euler's method converges at a rate of $O(h) = O(K^{-1})$, so if you double the number of points you use, you cut the error in half.\n\nIf you want something with better convergence properties than Euler's method, there are many other possibilities. Some things to search for are \"Runge-Kutta methods\" and \"one-step methods.\" More sophisticated methods require more function-evaluations (matrix-vector multiplies, in this case) at each time step but can attain better accuracy with fewer time steps.\n\nAt any rate, there's no need to do an $O(n^3)$ eigenvalue computation if you don't want to!\n\nshare|improve this answer\nI didn't read your answer, it looks like we have read the same article ;-) \u2013\u00a0 Jean-Claude Arbaut Apr 30 '14 at 22:19\n\nYou are able to find a closed form expression, only depending on $a$ and $b$, for the the eigenvalues and respective eigenvectors of your matrix $A$. In fact, you can prove that, for $a \\neq 0$, the eigenvalues of $A$ are given by:\n\n$$\\lambda_j=b+2a \\cos(\\frac{j\\pi}{n+1}), \\, j=1,...,n$$ and the respective eigenvectors are known to be:\n\n$${{\\bf{v}}_j} = \\left[ {\\begin{array}{*{20}{c}}{\\sin \\left( {\\frac{{1j\\pi }}{{n + 1}}} \\right)}\\\\{\\sin \\left( {\\frac{{2j\\pi }}{{n + 1}}} \\right)}\\\\ \\vdots \\\\{\\sin \\left( {\\frac{{nj\\pi }}{{n + 1}}} \\right)}\\end{array}} \\right], \\, j=1,...,n$$\n\nThus you can very easily construct the matrices $F$ and $D$ in your decomposition. Also, since $D$ will always be diagonal, as the matrix $A$ is nonsingular, it's straightforward to compute $e^D$.\n\nTo get an idea how to get the expressions I mentioned see, for example:\n\nQuick way of finding the eigenvalues and eigenvectors of the matrix $A=\\operatorname{tridiag}_n(-1,\\alpha,-1)$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/114814/does-n2nk2n2k2-ldots-nmk2-have-a-general-equation\nText:\nTake the 2-minute tour \u00d7\n\nDoes $n^2+(n+k)^2+(n+2k)^2+\\ldots+(n+mk)^2$ have a general formula?\n\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 9 down vote accepted\n\nThe sum can we written as $\\sum_{j=0}^m(n+jk)^2=\\sum_{j=0}^mn^2+2jkn+j^2k^2$ and using the formulas $\\sum_{j=0}^mj=\\frac{m(m+1)}2$, $\\sum_{j=0}^mj^2=\\frac{m(m+1)(2m+1)}6$, we get \\begin{align*}\\sum_{j=0}^m(n+jk)^2&=(m+1)n^2+knm(m+1)+k^2\\frac{m(m+1)(2m+1)}6\\\\ &=(m+1)\\left(n^2+knm+\\frac{k^2m(2m+1)}6\\right). \\end{align*}\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/99060/does-this-jumping-ahead-ordinal-function-exist?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nWhile working on a project in operator algebras with a collaborator (and fellow MO user), we are able to successfully complete a transfinite induction assuming that the following has an affirmative answer.\n\nQuestion: Let $\\delta$ be a cardinal, considered as an initial ordinal, so that it is equal to the set of all ordinals of cardinality strictly less than $\\delta$. Does there exist a nondecreasing function $\\phi \\colon \\delta \\to \\delta$ such that, for all ordinals $1 \\leq \\lambda < \\delta$, there exists $\\gamma < \\lambda$ such that $\\phi(\\gamma) \\geq \\lambda$?\n\nIf it happens to matter, we are only concerned with the case where $\\delta$ is a limit cardinal. Any reasonably (transfinitely) constructive approach to writing down such $\\phi$ seems to quickly run into issues of ordinal notation that are beyond our expertise. If an abstract existence argument is available, we will certainly still be happy. On the other hand, we fear that this may somehow depend on large cardinal issues.\n\nshare|improve this question\nYour property must fail for $\\lambda=0$, since there are no $\\gamma$ less than $0$. \u2013\u00a0 Joel David Hamkins Jun 7 '12 at 21:08\nAs Nik pointed out such functions exist only when $cf(\\delta) = \\omega$ (and trivially when $\\delta$ is a successor ordinal). However, it often happens that the $cf(\\delta) = \\omega$ and $cf(\\delta) \\gt \\omega$ cases must be dealt with using different techniques. Perhaps you want to follow up this question with another on how to handle the $cf(\\delta) \\gt \\omega$ case... \u2013\u00a0 Fran\u00e7ois G. Dorais Jun 7 '12 at 21:27\n@Joel, oops! Fixed, thank you. \u2013\u00a0 Manny Reyes Jun 7 '12 at 22:57\n@Francois, would you kindly be able to point me to a (reasonably simple) instance where the $cf(\\delta)>\\omega$ case is successfully handled by separate means? A concrete example may help jog some new ideas for me. \u2013\u00a0 Manny Reyes Jun 7 '12 at 23:03\nOne of the key things that happens with ordinals of uncountable cofinality is the existence of the club filter and stationary sets, which have tons of wonderful properties. This is often the key to handling that case - en.wikipedia.org/wiki/Club_set en.wikipedia.org/wiki/Club_filter en.wikipedia.org/wiki/Stationary_set \u2013\u00a0 Fran\u00e7ois G. Dorais Jun 7 '12 at 23:37\n\n1 Answer 1\n\nup vote 13 down vote accepted\n\nNot unless $\\delta$ has countable cofinality (e.g., $\\delta = \\aleph_\\omega$). This will fail for $\\delta = \\aleph_1$, for example. Let $\\phi: \\delta \\to \\delta$ be any increasing function and recursively define $\\lambda_0 = 0$ and $\\lambda_{n+1} = \\phi(\\lambda_n)+1$. Since $\\phi$ is increasing, the sequence $(\\lambda_n)$ is increasing, and since $\\delta$ has uncountable cofinality we have $\\lambda = \\sup \\lambda_n < \\delta$. However, for any $\\gamma < \\lambda$ we must have $\\gamma < \\lambda_n$ for some $n$, so that $\\phi(\\gamma) \\leq \\lambda_{n+1} < \\lambda$.\n\n(If $\\delta$ has countable cofinality it's easy. For instance, if $\\delta = \\aleph_\\omega$ then we define $\\phi$ by letting $\\phi(\\lambda) = \\aleph_{n+1} + \\lambda$ for $\\aleph_n \\leq \\lambda < \\aleph_{n+1}$.)\n\nshare|improve this answer\nIn the cofinality $\\omega$ case, one can also use the natural step function with $\\omega$ many values. For $\\delta=\\aleph_\\omega$, let $f(\\alpha)=|\\alpha|^+$ for infinite $\\alpha$. In the general case, where $\\delta=\\sup_n\\lambda_n$, let $f(\\alpha)=\\lambda_{n+1}$ for $\\alpha\\in[\\lambda_n,\\lambda_{n+1})$. \u2013\u00a0 Joel David Hamkins Jun 7 '12 at 22:56\nWell, that was much simpler than I expected! Thanks for setting me straight. \u2013\u00a0 Manny Reyes Jun 7 '12 at 23:04\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/22281/can-i-relate-the-l1-norm-of-a-function-to-its-fourier-expansion?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI would like to express the integral of the absolute value of a real-valued function $f$ (over a finite interval) in terms of the Fourier coefficients of $f$. Failing that, I would like to know of any constraints or statistical correlations (in a sense explained in the motivation) relating these quantities.\n\nMotivation: This comes from a biophysics application, but is perhaps best explained as follows. If a rubber band of tension $t$ is stretched along the $x$ axis from $0$ to $L$, then it is easy to calculate the thermal fluctuations of its arc-length by letting $z(x)$ be the (small) deviation from the $x$ axis, and then writing the energy (arc-length times tension) in terms of the Fourier coefficients of $z(x)$. The Boltzmann weight turns out to be a Gaussian since in the limit of small deviations the arc-length becomes a sum of squares of the Fourier coefficients. My problem is more complicated: We have two rubber bands stretched over the same interval, with deviations $z_{1}(x)$ and $z_{2}(x)$. The energy includes not only the stretching of the rubber bands, but also a term proportional to the (positive) area enclosed between them, which is\n\n$\\int_{0}^{L}|z_{1}(x) - z_{2}(x)|dx$\n\nHence my question. So it would be nice to know how this area can be related to the Fourier coefficients of $z_{1}$ and $z_{2}$ or perhaps just to the arc-lengths of the rubber bands. By \"statistical correlations\" I am referring to the Boltzmann probability distribution with energy equal to the stretching energy plus the area-energy.\n\nEdit: Specifics on the Boltzmann probability distribution, more motivation.\n\nThe state of the system is the pair of functions $z_{1}(x)$ and $z_{2}(x)$ describing the deviation of the two rubber bands from the x axis. Let's say it's the set of pairs of functions defined on [0,L] and that these functions are identified with a finite number of Fourier coefficients - I am a physicist and would like to avoid nasty functions or mathematically honest discussions of path integrals.\n\nThe probability of occurrence of a state (z_{1}, z_{2}) is (before normalization)\n\n$\\exp(-\\beta E\\left[z_{1},z_{2}\\right])$\n\nwhere $E\\left[z_{1},z_{2}\\right]$ is the energy of the system, which in this case is the functional\n\n$E\\left[z_{1},z_{2}\\right] = \\frac{t}{2}\\int_{0}^{L}\\left[(\\frac{dz_{1}}{dx})^{2}+(\\frac{dz_{2}}{dx})^{2}\\right]dx + \\kappa \\int_{0}^{L}|z_{1}(x)-z_{2}(x)|dx$\n\nWhere the tension t and the \"surface tension\" $\\kappa$ are just numbers; set them equal to 1 if you wish. The first integral is the energy cost of stretching the rubber bands (in a linearized regime) and the second is the strange term proportional to the area enclosed between them. Without the second term, it is easy to diagonalize this functional in terms of the Fourier series of the two functions. That is why I was interested in writing the second term in terms of Fourier coefficients. That may be too much to ask, but perhaps it is still possible to calculate some quantities such as the statistical average of $z_1(x)^{2}$ - that is the kind of thing I ultimately want to know.\n\nI realize this is an unnatural-looking problem, so I will just mention that it's not really about rubber bands, but rather about fluctuating interfaces which occur in lipid bilayers with coexisting phases. There are two phase boundaries (one for each monolayer) with their respective \"tensions\" but there is also a term proportional to the area between them.\n\nshare|improve this question\nA comment in passing before proper answers appear: I do not think you can write L$_1$ norm in terms of the Fourier transform but L$_1$ norm is upper bounded by the L$_2$ norm which would be related to the length of the FT vector. I don't think it is possible to have an analogue of FT for L$_p$ norm for $p<2$. \u2013\u00a0 Kaveh Khodjasteh Apr 23 '10 at 1:13\nCan you be a bit more specific about what you mean by \"Boltzmann probability distribution with energy equal to the stretching energy plus the area-energy\". What exactly are the space of states and the density function here? \u2013\u00a0 fedja Apr 23 '10 at 15:17\nYes, I'll add that to the question. \u2013\u00a0 Gregory Putzel Apr 23 '10 at 16:10\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nThis sounds difficult. For instance, a long-standing open problem of Littlewood used to be this. Let A be a set of integers of size n, and let f be the characteristic function of A. How small (up to a constant) can the sum of the absolute values of the Fourier coefficients of f be? The conjecture was that the smallest was $C\\log n$, which is what you get when A is an arithmetic progression. This conjecture is now known to be correct, but plenty of closely related questions are still open. So at least sometimes the relationship between the $L_1$ norm of a function and the Fourier transform of that function is quite hard to understand.\n\nshare|improve this answer\nCould you possibly recommend any good book/survey article on the subject? \u2013\u00a0 Andrey Rekalo Apr 23 '10 at 17:22\nWell, the question was actually whether one can write any decent expression that gives an essentially equivalent measure on the set of states (whatever that means), so we do not need an equality that is always true, just an approximation that is accurate enough most of the time. Unfortunately, as far as I can tell, this is also rather hard if not impossible... On the other hand, some averages like the one mentioned in the post may still be possible to compute. Let me think a bit... \u2013\u00a0 fedja Apr 24 '10 at 4:04\nI walked down the hall to where the high-energy physicists are and my friend pointed out that this is probably equivalent to the path-integral formulation of a single quantum mechanical particle in a V-shaped potential - which can be solved analytically in terms of Airy functions. I think he is exactly right and the averages can be worked out that way. So the specific question about L_1 norms is probably misguided (but prompted an interesting connection above), while the statistical problem which seemed more difficult to me might be surprisingly tractable analytically... \u2013\u00a0 Gregory Putzel Apr 24 '10 at 4:35\nThat last comment is about the statistical problem, by the way. \u2013\u00a0 Gregory Putzel Apr 24 '10 at 4:51\n\nThis answer really has to do with the physics of it: are you sure about the area energy term?\n\nLet me simplify a little bit: Consider a case where $z_1(x)=0$ and $z_2(x)=w(x)$. According to your formula I should get a term proportional to $w'(x)^2$ for the kinetic term which is typical and no one will object to you for that. You potential energy would then be proportional to $\\int_0 ^L |w(x)| dx$. That does raise an alarm: nonlinear problem.\n\nUnless you really have nonlinear physics going on (which is likely, see below) you should have had $w(x)^2$. That would bring back the $L_2$ norm and everything will be very simple. Just transform $z_2(x)=z_1(x)+w(x)$, get rid of $z_2$ and you will get two uncoupled (continuum of) modes, one (corresponding to $z_1$) is a free particle and the other a Harmonic oscillator. Your Boltzmann statistic will determine how these modes are filled up as you know.\n\nIf you think of your rubber band as a collection of springs and masses, $w(x)^2$ is the actual term but collections of springs and masses hardly exist outside textbooks and problem sets. As a physicist you know: molecules interact. The actual expansion (if you are still interested in writing an effective field theory) will involve (interacting) terms of the type $w(x)^2+O[w(x)^4]$. Quantitative results in this model might involve renormalization. See the wikipedia page on quartic interaction that even describes how you should quantize it (Fourier transform). My field theory is rusty so you might already know more than I do.\n\nWhat if $|w(x)|$ is what you have: If $|w(x)|$ is not too small or too large, just approximate it with $[w(x)]^2$ to linearize the problem. People might point out that this is not a mathematically good approximation but it will physically make sense: very small stretchings are not physically possible and very large stretchings would be ruled out by the Boltzmann statistics as they would correspond to exponentially rare high energy modes. So I would just introduce a factor so that $w(x)$ and $w(x)^2$ coincide where $\\kappa w(x)^2 L\\approx kT$.\n\nThere are a famous nonlinear equations that come cheerfully close to your problem but miss it. Example: Sine-Gordon Equation where instead of $|w(x)|$ you would have $1-\\cos [w(x)]$. Actually more up to the point would be the Sinh-Gordon... which reminds me of the Toda field theory which describes a Toda lattice. A Toda lattice is a nonlinear set of coupled equations that describe a set of nonlinearly coupled particles. If you are working in the liquid state, I doubt that they would be relevant. $w(x)^2$ should be good enough but the dissipative terms will be more troublesome.\n\nEdit: Couldn't resist the pun. Seems that the relevant equation is a \"SIGN-Gordon equation\": $$\\varphi_{tt}- \\varphi_{xx} + \\text{sgn}(\\varphi) = 0.$$ Not sure if it is really simple, messy, or plain difficult to solve in your case. An option is to try solve it like a wave equation with a sign changing external force term and then parametrize the solutions based on their energy and apply the Boltzmann statistics. Forgo the Hamiltonian altogether. I think it will be messy.\n\nAnother Edit: as the commenters mentioned before, the solution to the absolute value potential Schrodinger eqn. involves Airy functions. So you could in principle use the Airy function eigenstates to find the time-independent modes and fix their energy. This could quantize your problem. The solution in terms of the Airy functions can be found for example here, [PRL, 94, 176805 (2005)].\n\nYet Another Update: Apparently you have the \"Signum-Gordon\" equation. Thanks to this answer.\n\nshare|improve this answer\nHere is the link to the question I asked about SIGN-Gordon Eqn: mathoverflow.net/questions/22514/sign-gordon-equation in case something comes up. \u2013\u00a0 Kaveh Khodjasteh Apr 25 '10 at 16:09\nThanks for the comments and the SIGN-Gordon link. I am going to start working out the details using the Schrodinger eqn/ Airy function approach. Thinking about it now, it is very similar to what is commonly done in the mean-field theory of Gaussian polymers. What I'm looking for is the free energy of a Gaussian polymer in one dimension, in an external V-shaped potential. Yes, I'm pretty sure the V-potential is what I want, since upon integration along x it gives the area between the two interfaces. \u2013\u00a0 Gregory Putzel Apr 25 '10 at 22:09\nOh I see, you just posted the sign-gordon question. Curious to see what people can say... \u2013\u00a0 Gregory Putzel Apr 25 '10 at 22:11\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/63931/maximum-principle-corner/63941\nText:\nTake the 2-minute tour \u00d7\n\n\nconsider a parabolic boundary value problem, for instance\n\n$-\\partial_tu+\\Delta u=0$, in $\\Omega$,\n\n$\\partial_\\nu u=0$ on $\\partial\\Omega$,\n\nin a domain $Q=(0,T)\\times\\Omega$, where $\\Omega\\subset R^n$ is bounded. Now suppose $u$ is smooth and attains its maximum in $(T,x_0)$ for some $x_0\\in\\partial\\Omega$. Is it possible to say anything about the normal derivative $\\partial_\\nu u(T,x_0)$ similarly as in Hopf's boundary point lemma?\n\n(Hopf's boundary point lemma is not applicable, since there is no circle tangent to $\\partial Q$ at $(T,x_0)$ entirely contained in $Q$!)\n\nI came across this problem by the following thought:\n\nBy classical maximum principles the maximum can't be attained in $\\Omega$, so it has to be located on the boundary. What if the maximum is at the (in time) top end? Although the initial distribution is strictly negative, it could be positive without violating the boundary condition $\\partial_\\nu u=0$ on $\\partial\\Omega$, so there would be a change in signs. Of course one can exclude this by applying positive operator theory, but is there an elementary proof for this?\n\nI would be grateful for valuable comments on this.\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nPick 0< $\\tau$ < T, and let $$\\phi(\\tau)=\\max_{x\\in\\bar\\Omega,0\\le t\\le\\tau} u(x,t).$$ If this maximum is assumed at any point where $x\\in\\Omega$ and $t>0$, then $u$ must be constant. Suppose the maximum is at a point $(x_0,\\tau)$, where $x_0\\in\\partial\\Omega$, and $u$ is not constant. Then the function $\\phi(\\tau)$ must be increasing. This is possible only if $u_t(x_0,\\tau)\\ge 0$. But then the elliptic Hopf lemma gives a contradiction to the boundary condition.\n\nshare|improve this answer\nNice idea, haven't thought of using the elliptic Hopf lemma! In the meantime I found out that the parabolic Hopf lemma still applies in my situation. Instead if the ball K in the proof of Thm 3 on page 170 of WP one can also choose a cylinder $(0,\\tau)\\times\\Omega)$ and consider the body enclosed by the wall of that cylinder, the ball around the maximum on the boundary from the proof and the plain $\\{\\tau\\}\\times\\Omega$. Using a modified auxiliary function, one still can prove that $\\partial_\\nu>0$ (or <0 depending on whether you want positivity or negativity). Thank you very much! \u2013\u00a0 Marc May 6 '11 at 7:32\n\nYes, there is an analogue to Hopf lemma. In most general form (degenerate operators...) is it done in the works of Kamynin and Khimchenko. Boundary required to be smooth enough, e.g. from parabolic class $C^{1,\\alpha}$. That's an analogue for Lapunov class for elliptic problems. For $C^1$ boundaries Hopf lemma doesn't hold.\n\nshare|improve this answer\n\nI think what you are looking for is the parabolic Hopf lemma, given for instance in the book of Protter and Weinberger.\n\nshare|improve this answer\nYou are right. However the parabolic Hopf lemma in PW requires a circle tangent to $\\partial Q$ through $(T,x_0)$ which lies entirely in $Q$. So I am looking for a suitable extension of this result for corners. \u2013\u00a0 Marc May 4 '11 at 19:10\nThere seems to be no exactly such result for domains with corners. For example, function $f(x,y)=xy$ in the positive angle $\\{x>0,y>0\\}$ satisfy Laplace equation (stationary heat) equation. It is smooth and has a local minimum at the origin, but its derivatie in any direction is zero. \u2013\u00a0 Andrew May 5 '11 at 9:39\nFor domains of $C^1$ class there is a result of Nadirashvili, however. It states that if $x_0$ is a point of solution's local minimum at the boundary then in any neibourhood there is a point in which normal derivative is positive. For parabolic equations it was generalized by Kamynin. Since domains with angles is sort of good Lipschitz, may be something analogous holds there. For the above example it does :) \u2013\u00a0 Andrew May 5 '11 at 9:42\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/44141/limit-of-fermi-dirac-distribution-as-t-goes-to-zero\nText:\nTake the 2-minute tour \u00d7\n\nHopefully this is a simple question, I just can't seem to get my mind around it.\n\nI'm to take the limit of the Fermi-Dirac distribution for $T \\rightarrow 0$.\n\nIn this limit the chemical potential is equal to the Fermi energy $\\mu = \\epsilon_F$, and all states of energy below the Fermi energy is occupied, while all states above are empty.\n\nFollowing this argument I would say, that the Fermi-Dirac distribution tends to a step-function with argument $\\epsilon_F - \\epsilon$, such that\n\n$$ f \\rightarrow \\Theta(\\epsilon_F - \\epsilon) \\quad \\text{for} \\quad T \\rightarrow 0, $$ which is one for $ \\epsilon < \\epsilon_F $ and zero for $ \\epsilon > \\epsilon_F $.\n\nMy problem is that I have found the results stated in a textbook and a couple of other cases, where it's stated as\n\n$$ f \\rightarrow \\Theta(\\epsilon - \\epsilon_F) \\quad \\text{for} \\quad T \\rightarrow 0. $$\n\nCan someone tell me which result is correct and maybe explain why the second result is correct if it is so.\n\nshare|improve this question\nWhich textbook did you find it in? Your expression is correct by the way. \u2013\u00a0 Olaf Dec 13 '12 at 17:39\nThank you.. I believe I found it in Quantum Theory of the Electron Liquid by Giuliani & Vignale and afterwards stated the same way at least 1 or 2 places on the internet (physics forums), but I'm not a 100 % sure. I will check up on it, when I get back after Christmas. Either way if both of you agrees with my intuition, I'll stick with that. \u2013\u00a0 Rasmus S\u00f8gaard Christensen Dec 22 '12 at 22:23\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nIf we neglect the possibility of negative temperature, then OP is right:\n\nThe Fermi-Dirac distribution\n\n$$f_{FD}(\\epsilon) ~\\longrightarrow ~\\Theta(\\epsilon_F - \\epsilon) \\qquad \\text{for}\\qquad T ~\\longrightarrow ~0^{+}, $$\n\nwhere $\\Theta$ is the Heaviside step function.\n\nshare|improve this answer\nWhy the wikipedia link? \u2013\u00a0 Magpie Apr 28 '13 at 23:10\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/447059/primes-for-which-2-and-2-are-residues\nText:\nTake the 2-minute tour \u00d7\n\nI know that 2 is a residue of primes of the form $8n+1$ and $8n+7$ and so on. I want to find a purely group theoretic or field theoretic proof of these statements.\n\nFor example, for 8n+1, the multiplicative group is of the order of 8 and so there exists an element of order 8, j. Then $(j + 1/j)^2 = 2$. Similarly for $8n+5$, there is an element of order 4, $i$ and if 2 had a residue, we could construct j such that $j^2 = i$ and therefore there is an element of order 8 which is impossible.\n\nWhat I am not getting stuck on is finding something that differentiates a field of the order $8n+7$ from something of the form $8n+3$. This is how I proved the last 2 cases(there either exists or does not exist something of order 8).\n\nshare|improve this question\nIs that a homework? \u2013\u00a0 Mark Sapir May 31 '13 at 7:38\nVoted to close. \u2013\u00a0 Mark Sapir May 31 '13 at 8:59\nThe title asks about $-2$, the body doesn't. Anyway, voting to migrate to m.se \u2013\u00a0 Gerry Myerson Jul 19 '13 at 0:26\nadd comment\n\nmigrated from mathoverflow.net Jul 19 '13 at 2:25\n\nThis question came from our site for professional mathematicians.\n\n1 Answer\n\nI'm not sure that this is what you want, but I'll try anyway.\n\nIf $p$ is an odd prime, then $8\\mid p^2-1$, so when $p\\not\\equiv1\\pmod8$ we have the element $j$ in the extension field $\\mathbb{F}_{p^2}$. The zeros of the eighth cyclotomic polynomial are $$ \\phi_8(x)=x^4+1=(x-j)(x-j^3)(x-j^5)(x-j^7)=(x-j)(x-j^3)(x+j)(x+j^3). $$\n\nWe can say something extra about the minimal polynomial of $j$ over the prime field in these cases. This is because by the Galois theory of finite fields the other zero is the Frobenius conjugate $j^p$. So if $p\\equiv 3\\pmod 8$, then the minimal polynomial of $j$ is $$m(x)=(x-j)(x-j^3)=x^2-ax-j^4=x^2-ax-1.$$ The other factor of $\\phi_8(x)$ modulo $p$ is then $m(-x)=x^2+ax+1$. Vanishing of the quadratic term $-2-a^2$ of $m(x)m(-x)$ implies that $a^2=-2$. But here $a=j+j^3=j-1/j$, so in this case you have $(j-1/j)^2=-2$.\n\nOn the other hand, if $p\\equiv7\\pmod8$, then $$m(x)=(x-j)(x-j^p)=(x-j)(x-j^7)=x^2+bx+j^8=x^2+bx+1.$$ Again the other factor is $m(-x)$, and we similarly see that $b^2=2$. This time you get $b=(j+j^7)=(j+1/j)$, and $(j+1/j)^2=2$.\n\nNote that in both cases $j\\pm 1/j$ is the trace of $j$, so an element of the prime field.\n\nshare|improve this answer\nI agree that this might fit Math.SE better. \u2013\u00a0 Jyrki Lahtonen Jul 18 '13 at 13:14\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/686/combinations-of-selecting-n-objects-with-k-different-types/690\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that I am buying cakes for a party. There are k different types and I intend to buy a total of n cakes. How many different combinations of cakes could I possibly bring to the party?\n\nshare|improve this question\nSeeded question \u2013\u00a0 Casebash Jul 25 '10 at 10:54\nPS. This problem has a really nice proof. I'm pretty hopeful that someone else has seen it posts it \u2013\u00a0 Casebash Jul 25 '10 at 11:23\nWhenever I do this sort of thing, the shop runs out of the cakes I want. \u2013\u00a0 walkytalky Jul 25 '10 at 15:20\nvoting to close--because I'd do so if I saw it as a real question--no indication the asker has thought about the problem first. \u2013\u00a0 Jamie Banks Jul 25 '10 at 19:24\n@Katie: Its a perfectly valid question and I haven't seen a hasn't thought about it close reason on any of the other SO websites (maybe mathoverflow is different though). If you want someone to think about a problem, the best solution is to just not give them the whole solution. For example, show them how you go about proving it and leave out the actual formula \u2013\u00a0 Casebash Jul 25 '10 at 20:54\nshow 3 more comments\n\n3 Answers\n\nup vote 12 down vote accepted\n\nUsing a method that's often called \"stars and bars\":\n\nWe draw $n$ stars in a row to represent the cakes, and $k-1$ bars to divide them up. All of the stars to the left of the first bar are cakes of the first type; stars between the first two bars are of the second type; .\u00a0. .\u00a0.\n\n\nHere's an example with $n=6$ and $k=5$. We're getting 2 of the first type, 3 of the second type, 0 of the third type, 1 of the fourth type, and 0 of the fifth type.\n\nIn order to solve the problem, we just need to reorder the stars and bars by choosing the $k-1$ spots for the bars out of the $n+k-1$ total spots, so our answer is:\n\n$$ \\binom{n+k-1}{k-1}. $$\n\nshare|improve this answer\nExactly what I was looking for \u2013\u00a0 Casebash Jul 25 '10 at 20:51\nNote that $\\binom {n+k-1}{k-1} = \\binom {n+k-1}{n}$ - here the description picks the $k-1$ spots for the bars - equivalently we could pick the $n$ spots for the cakes. \u2013\u00a0 Mark Bennet May 28 '13 at 17:20\nHere is a derivation of your formula using the Polya Enumeration Theorem. \u2013\u00a0 Marko Riedel Oct 28 '13 at 0:42\nadd comment\n\nLet g(n,k) = # combinations of cakes.\n\nNotice that:\n\n  \u2022 g(n,1) = 1. (all the cakes are the same)\n  \u2022 g(n,2) = n+1. (e.g. for 5 cakes, the # of cakes of type 1 can be 0, 1, 2, 3, 4, 5)\n  \u2022 g(1,k) = k.\n  \u2022 g(2,k) = k*(k-1)/2 + k (the first term is two different cakes; the second term is when both cakes are the same), as long as k > 1. (otherwise g(2,1) = 1)\n  \u2022 g(3,k) = k * (k-1) * (k-2)/6 + k*(k-1)/2 * 2 + k (the first term is 3 different cakes; the second term is 2 different cakes, with a *2 since there are two choices for which one to duplicate, the third term is when all 3 cakes are the same), as long as k > 2.\n\nIf we think of k as a radix rather than the # of cakes, then this problem is equivalent to expressing the # of distinct n-digit numbers in base k whose digits are in sorted order. (e.g. 1122399 is equivalent to 9921231)\n\nI think I can express it as a nonrecursive sum:\n\ng(n,k) = sum from j=1 to max(n,k) of { (k choose j) * h(n,j) }\n\nwhere h(n,j) is the # of ways to partition N cakes using j different types. (the term in the sum is when there are j distinct cakes actually chosen.)\n\nBut that's about as far as I can get... :/\n\nedit: looks like it's combinations with repetitions = ((k+n-1) choose n). (same as the wikipedia article with n and k swapped)\n\nshare|improve this answer\nnice solution Jason S............... \u2013\u00a0 juantheron Dec 13 '13 at 3:34\nadd comment\n\nLet's assume you have $n$ items and $k$ bins. You need $k-1$ separators to get the $n$ items into the $k$ bins. There are $(n + k - 1)!$ permutations of ordering $n$ items and $(k-1)$ separators. The permutations of the $n$ items don't matter, and the permutations of the $(k-1)$ separators don't matter, so you'll need to divide by $n!$ and $(k-1)!$\n\nThus you have $$\\frac{(n + k - 1)!}{n!(k-1)!} = \\binom{n+k-1}{k-1}$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/116802/number-of-elements-in-a-ring-with-identity-s-t-x2-1-r-for-all-0-r-neq-x\nText:\nTake the 2-minute tour \u00d7\n\nI'm not sure how to go about finding the solution to this question.\n\nLet R be a ring with identity such that $x^2 = 1_R$ for all $0_R \\neq x\\in R$. How many elements are in $R$?\n\nI've just been playing around with squaring elements, like $$(x+1_R)^2 = x^2+2.x+1_R =2.x+2.1_R = 1_R.$$\n\nBut I'm not sure where to go with this. Any help?\n\nshare|improve this question\nEither $1_R+1_R=0$ or $(1_R+1_R)^2=1_R$ so $3\\cdot 1_R=0$. \u2013\u00a0 Davide Giraudo Mar 5 '12 at 20:15\nadd comment\n\n2 Answers\n\nOne possibility, of course, is $R=\\{0\\}$. Assume $1_R\\neq 0$.\n\n$R$ has no zero divisors: if $xy=0$ and $x\\neq 0$, then $y = 1_Ry = xxy = x(0)=0$.\n\n$R$ is commutative: if $x$ and $y$ are nonzero, then so is $xy$ by the above; hence $(xy)^2 = x^2y^2$; canceling from $xyxy=xxyy$ we get $yx=xy$.\n\n(Of course, the ring satisfies $x^3=x$ for all $x$, so by a famous theorem of Jacobson, the ring is necessarily commutative; but we don't need to call in that heavy cannon to the fray).\n\nSince every nonzero element is invertible, $R$ is a field. Since $x^2-1_R$ has $|R-\\{0\\}|$ solutions, we have $|R-\\{0\\}|\\leq 2$, so $|R|\\leq 3$.\n\nIf $1_R+1_R=0$, then $R$ is of characteristic $2$, so $R\\cong \\mathbb{F}_2$ and $|R|=2$. And, indeed, in this case the hypothesis holds.\n\nIf $1_R+1_R\\neq 0$, then we get $4\\cdot 1_R = 1_R$, hence $3\\cdot 1_R=0$, so $R$ is of characteristic $3$, and therefore $R\\cong\\mathbb{F}_3$ and $|R|=3$. Again, the hypothesis holds for this ring.\n\nIn summary, $R$ has either $1$, $2$, or $3$ elements, and is either the trivial ring, $\\mathbb{F}_2$, or $\\mathbb{F}_3$.\n\nshare|improve this answer\nThanks, this is very helpful, but why does $x^3=x$ imply that $R$ is commutative? \u2013\u00a0 098765 Mar 5 '12 at 20:28\n@098765: It is a common exercise in Ring Theory, and also a consequence of a famous Theorem of Jacobson, which states that a ring for which there exists $n\\gt 0$ such that $x^n=x$ for all $x$ is always commutative. But I gave a simpler derivation that does not call upon such heavy artillery in an edit. \u2013\u00a0 Arturo Magidin Mar 5 '12 at 20:33\n@ArturoMagidin am pleased you revised your answer, because the proof that $x^3 = x$ implies R is commutative isn't trivial, and is probably beyond the stage at which the asker of this question is at. \u2013\u00a0 David Wheeler Mar 5 '12 at 20:53\nDoes your proof actually depend on commutativity? (mine does not). If not, then you can omit the proof of comutativity, since it's a trivial consequence of the final result. \u2013\u00a0 Bill Dubuque Mar 5 '12 at 22:42\n@Bill: I use commutativity only to conclude that I have a field rather than a simply division ring; I believe it is equivalent to your \"$x^{-1}=x\\Rightarrow R$ field\". \u2013\u00a0 Arturo Magidin Mar 6 '12 at 3:54\nadd comment\n\n$\\rm R=0\\:$ works. Else $\\rm\\ x\\ne 0$ $\\Rightarrow$ $\\rm x^2 =1$ $\\Rightarrow$ $\\rm x^{-1} = x $ $\\Rightarrow$ $\\rm R$ field, so $\\rm\\: x\\ne 0\\!\\iff\\!\\! (x-1)(x+1) = 0$ $\\iff$ $\\rm x=\\pm 1.\\:$ But $\\rm\\: R\\backslash0 = \\{\\pm1\\}$ $\\!\\iff\\!$ $\\rm R\\:\\! \\cong\\:\\! \\mathbb Z/2\\:$ or $\\:\\mathbb Z/3$.\n\nMore generally, the finite fields $\\:\\rm\\mathbb F_p,\\: \\mathbb F_q,\\ p,q\\:$ prime, are axiomatized by the ring axioms plus $$\\rm x^n =\\: x,\\quad n\\: =\\: 1 + lcm(p\\!-\\!1,q\\!-\\!1)$$ $$\\rm q\\:(x^p-x)\\: =\\: 0\\: =\\: p\\:(x^q-x)$$ $$\\rm pq\\: =\\: 0$$\n\nThus any identity true in both of these fields has a purely equational proof from the above axioms. This theorem extends similarly to any finite set of finite fields, for example see Stanley Burris and John Lawrence, Term rewrite rules for finite fields (1991). This result is very closely related to Jacobson's model-theoretic proof of commutativity of rings satisfying the identity $\\rm\\: x^{n_x} =\\: x$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/314978/row-and-column-algorithm\nText:\nTake the 2-minute tour \u00d7\n\nLooking for help in revising my algorithm. I need to find one that will give me the row and column of a cell on a grid.\n\nThe grid is $t \\times t$. For example, this is a grid for $t=5$. Now given $n$, find the row and column. $$\\begin{array}{|c|c|c|c|c|} 1& 2& 3& 4& 5\\\\ 6& 7& 8& 9& 10\\\\ 11& 12& 13& 14& 15\\\\ 16& 17& 18& 19& 20\\\\ 21& 22& 23& 24& 25 \\end{array}$$\n\nMy attempt:\n\nrow: $n / t + 1$ column: $n \\bmod t$\n\nSecond attempt:\n\n$\\operatorname{row}(x, t) = ((x-x \\bmod t)/t)+1$\n\n$\\operatorname{column}(x,t) = (x-1) \\bmod t+1$\n\nDoesn't work for $n = t^2$\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe row is :$$r = \\lfloor \\frac{n-1}{t} \\rfloor + 1$$\n\nThe column is:$$c = n - t(r-1)$$\n\nshare|improve this answer\nIf zero indexing were to be used ($0,1,2,\\ldots$ instead of $1,2,\\ldots$) then the answer would look cleaner. $c$ could also be (n-1)%t+1. \u2013\u00a0 adam W Feb 26 '13 at 16:23\nI understand, thank you! \u2013\u00a0 \u041c\u0438\u043a\u0440\u043e\u041f\u0438\u043d\u0433\u0432\u0438\u043d Feb 26 '13 at 16:26\nGlad to hear it, your welcome! \u2013\u00a0 adam W Feb 26 '13 at 16:35\nHi, I have another question. This was just borne out of curiosity. Is there an equation for reflections over diagonals? My attempt only works for the first column down when reflected over the topleft-bottomright diagonal. n - (row - 1)(t - 1) \u2013\u00a0 \u041c\u0438\u043a\u0440\u043e\u041f\u0438\u043d\u0433\u0432\u0438\u043d Feb 26 '13 at 23:14\nThis is a common operation using matrices called the transpose, it is simply the swap of the indices $r\\leftrightarrow c$. If by reflection over diagonals you mean other than the main (top left down to the bottom right), then maybe do some sort of shifting... though that sounds inexact, since any sort of \"reflecting\" would give indices out of bounds... \u2013\u00a0 adam W Feb 26 '13 at 23:36\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/66866/maximum-angular-velocity-to-stop-in-one-rotation-with-a-known-torque\nText:\nTake the 2-minute tour \u00d7\n\nI have an object I can rotate with a given torque. I would like to stop applying torque once I've reached a defined maximum rotational speed. The maximum rotational speed should be defined so that applying maximum torque will stop the rotation of the object within one rotation. If I know my torque and moment of inertia, how can I find the maximum rotational velocity to allow me to stop the object in one rotation?\n\nTime is whatever is needed.\n\nI've tried finding the angular acceleration required to stop the object, but that leaves me with the time variable. Of the equations I've tried, I'm left with a time variable as well as the maximum angular velocity.\n\nshare|improve this question\nWhat approaches have you tried? Where are you hung up with this question? \u2013\u00a0 Jerry Schirmer Jun 2 '13 at 22:04\nI edited the question to give a little details about what I've tried. And it's not homework. More like hobby work. \u2013\u00a0 Byte56 Jun 2 '13 at 22:09\nFor people with similar homework questions: try the equivalent exercise in linear motion. E.g. the direct equivalent here is, given a stopping length L and a force F, what is the maximum velocity v ? You'll quickly spot that you need the second derivative a which you get from F=m*a. \u2013\u00a0 MSalters Jun 3 '13 at 0:00\n\n3 Answers 3\n\nup vote 2 down vote accepted\n\nTo stop the object you must do work. For a constant torque perpendicular to the moment arm, the work it does is equal to $\\tau\\cdot\\Delta\\theta$, and you want $\\Delta\\theta\\leq2\\pi$.\n\nIt should be obvious that the greatest angular velocity that a torque $\\tau$ can stop will take it the full $2\\pi$ radians to stop. In a rotating system, the rotational kinetic energy is given by $E_r=\\frac12I\\omega^2$ (a direct analogue of $E_K=\\frac12mv^2$ ). Now consider work-energy equivalence.\n\nshare|improve this answer\nGreat, I should have taken the energy approach. Been too long since physics. Thanks. \u2013\u00a0 Byte56 Jun 2 '13 at 22:29\nNo problem. J. Lowney has a full-detail solution above - you should check your algebra. A word of advice: on a problem like this, omit your direction signs and only consider magnitudes. Signs will only confuse you and freak you out when you end up with an imaginary angular velocity. \u2013\u00a0 Zen Jun 2 '13 at 22:31\n\nBuilding off of Zen's response, the energy will be $E_r = \\frac{1}{2}I\\omega^2$. The work done in one rotation is $\\tau\\Delta\\theta$. These two terms are equivalent in your case. I.e. you will have the following expression\n\n$$ E_r = \\frac{1}{2}I\\omega^2 = \\tau_\\text{max} \\Delta\\theta$$ $$ \\omega_\\text{max} = \\sqrt{\\frac{2\\tau_\\text{max}\\Delta\\theta}{I}}$$\n\nYou're treating your $\\Delta\\theta$ as $2\\pi$, for one full rotation, hence:\n\n$$\\omega_\\text{max} = \\sqrt{\\frac{4\\pi\\tau_\\text{max}}{I}}$$\n\nWhere $I$ is the moment of inertia of your object. $\\omega$ is the angular velocity. $\\tau$ is your torque.\n\nshare|improve this answer\nThanks for furthering the equation J. \u2013\u00a0 Byte56 Jun 2 '13 at 22:30\nHow would I go about expanding this to use multiple torque values at different positions around the object? \u2013\u00a0 Byte56 Jun 2 '13 at 22:43\nIf you have a function $\\tau(\\theta)$ that gives you torque at every position around the object then simply replace the naive expression for work $W=\\tau\\Delta\\theta$ by $$W=\\int_0^{2\\pi}\\tau(\\theta)d\\theta$$ \u2013\u00a0 Zen Jun 2 '13 at 22:56\n\nAlternative solution:\n\nI see you tried to do it by first finding angular acceleration $\\alpha=\\frac\\tau I$ (where tau is your applied torque). This also works! However I suspect you got stuck at $$\\alpha t=-\\omega_{max}$$ This is perfectly understandable because t is somewhere between 0 and a full period (under the original angular velocity $\\omega$ that is), but you don't know what t is.\n\nYou could try to set up some equations to solve simultaneously for $t$, but that's not necessary because you don't care about $t$, you only care about $\\omega_{max}$ There is another equation you can use, the so-called \"timeless equation\": $$\\omega_f^2=\\omega_o^2+2\\alpha\\Delta\\theta$$ where $\\omega_f$ is final angular velocity, $\\omega_o$ is initial angular velocity, $\\alpha$ is angular acceleration, and $\\Delta\\theta$ is angular displacement (this again is a direct analogue of the linear kinematic equation $v^2=v_0^2+2a\\Delta x$).\n\nLet $\\omega_f=0$ and $\\omega_0=\\omega_{max}$ (i.e., you start out at maximum velocity). By the same reasoning as above $\\Delta\\theta=2\\pi$ and if you know $\\tau$ and $I$ you can find $\\alpha$. Then you have: $$0=\\omega_{max}^2+2\\alpha\\cdot2\\pi$$ $$\\omega_{max}^2=2\\alpha\\cdot2\\pi$$ (again, ignore signs) $$\\omega_{max}=\\sqrt{4\\alpha\\pi}$$ which is the same as above, since $\\alpha=\\frac \\tau I$\n\nshare|improve this answer\nGreat, thanks Zen. \u2013\u00a0 Byte56 Jun 2 '13 at 23:39\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/318493/what-is-a-good-measure-of-controversy-given-a-support-score-and-opposition-sc/318711\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I have a topic or discussion, and a number of \"support\" and \"opposition\" points on each side (You can also think of them as \"upvotes\" and \"downvotes\") and I want to calculate a score of how \"controversial\" a topic is. (Let $p$ be the support score, $c$ be the opposition score, and $f(p, c)$ be the function that determines the controversy score.)\n\nIt should have the following properties:\n\n  \u2022 Controversy is maximized when equal support is given to both sides. Given that some property $g(p, c)$ is held constant (such that the slope of the tangent line of the level curve of $g(p, c)$ at any point is never positive), $f(p, c)$ should be maximized when $p = c$.\n  \u2022 More support on both sides means that more people care and therefore there is more controversy. Given that $p/c$ is held constant, a higher value of $p$ or $c$ should result in a higher value of $f(p, c)$.\n  \u2022 The amount of controversy is the same for the same imbalance of support no matter which side the imbalance favours. $f(p, c)$ should equal $f(c, p)$.\n  \u2022 All the support being on one side means there is no controversy. Given that either $p$ or $c$ is equal to zero, $f(p, c)$ should be equal to zero.\n\nIs there any function like this that is already in use? If not, could one be devised?\n\nshare|improve this question\nBasically I'm trying to simulate or find a better formula for Reddit's \"controversial\" section. That section doesn't even seem to work properly on most subreddits I visit. \u2013\u00a0 Joe Z. Mar 2 '13 at 15:02\nSelecting it on All made me realize that Controversial takes pretty much anything whose score is between 1 and -1 with more than 4 votes total. \u2013\u00a0 Joe Z. Mar 2 '13 at 15:09\nHere's a related question on Stack Overflow that asks the same thing. But I'm interested in it mathematically as well. \u2013\u00a0 Joe Z. Mar 6 '13 at 2:39\nadd comment\n\n4 Answers\n\nup vote 5 down vote accepted\n\n$$f = \\min$$\n\nMore generally, choose an even function $g:[-1,1]\\to\\mathbb R_{\\ge0}$ such that $g(-1)=g(1)=0$, and an increasing function $h:\\mathbb R_{\\ge0}\\to\\mathbb R_{\\ge0}$, and let $$f(p,c)=g\\left(\\frac{p-c}{p+c}\\right)h\\left(\\frac{p+c}2\\right).$$ Here $g$ controls the \"cross-section\" for a fixed number of votes, while $h$ controls the growth for a fixed $p/c$ ratio. For example, $f(p,c)=\\min(p,c)$ arises from setting $g(x)=1-\\lvert x\\rvert$ and $h(y)=y$. @michielm's solution $f(p,c)=pc/\\lvert p-c\\rvert$ corresponds to $g(x)=(1-x^2)/\\lvert x\\rvert$, $h(y)=y/2$. Another nice solution is $g(x)=\\sqrt{1-x^2}, h(y)=y \\implies f(p,c)=\\sqrt{pc}$.\n\nshare|improve this answer\n+1 and accept for the general formula class. \u2013\u00a0 Joe Z. Mar 2 '13 at 15:49\nadd comment\n\nWhat about $\\frac{p c}{|p-c|}$?\n\nThis will grow (to infinity) for $c$ and $p$ being closer together and will also grow if $p/c=constant$ with increased $p c$. All support on one side will mean that $pc$ is low (or 0)\n\nMaybe it is not perfect in its general behaviour, but the limiting behaviour seems to be right, so you can probably go from here.\n\nshare|improve this answer\nI'm not sure 1 upvote vs. 1 downvote resulting in the same amount as 100 vs. 100 (both of which are \"infinite\") is a good idea. But thanks anyway. \u2013\u00a0 Joe Z. Mar 2 '13 at 8:31\nA little adjustment like $\\frac{pc}{|p-c|+1}$ would avoid infinity. \u2013\u00a0 Hagen von Eitzen Mar 2 '13 at 9:43\nadd comment\n\nThe formula I came up with myself was: $\\displaystyle \\frac{\\min(p,c)^2}{\\max(p, c)}$\n\nI called it the \"geometric progression\" algorithm, because it represents the next term of the geometric progression lower than $\\max(p,c)$ and $\\min(p, c)$. In this way, as $p$ increases past $c$, $f(p, c)$ will get smaller, reaching its maximum of $c$ when $p = c$.\n\nIt also has the additional scaling property that the number of votes on $\\max(p,c)$ varies inversely with $f(p, c)$.\n\nshare|improve this answer\nI created a page where you can play with various upvote and downvote algorithms, with this formula on it. \u2013\u00a0 Joe Z. Mar 2 '13 at 16:02\nadd comment\n\nI would argue that a simple and natural measure of controversy is simply the product of the support vote count $p$ and the opposed vote count $c$:\n\n$$f(p,c) = pc$$\n\nIn particular, for a fixed total number of votes $p+c$, $f$ is maximized at $p = c$ (or at $p = c \\pm 1$ if the total is odd), and it also satisfies your requirements 2\u20134. It also has the convenient property that $f(p,c)$ is a non-negative integer whenever $p$ and $c$ are.\n\nOne downside is that, for a fixed vote ratio $0 < p/c < \\infty$, $f(p,c)$ grows proportionally to the square of the total number of votes $p+c$. If you'd prefer a linearly growing function instead, you can always take the square root to get the geometric mean of $p$ and $c$:\n\n$$f^*(p,c) = \\sqrt{pc}$$\n\nAs the square root is a strictly monotone increasing function, it does not affect the relative ranking of the results: $f(p,c) > f(p',c')$ if and only if $f^*(p,c) > f^*(p',c')$. However, by the AM\u2013GM inequality, we can see that $f^*(p,c)$ can never exceed half of the total vote count $p+c$.\n\nshare|improve this answer\nOne problem with using $pc$ is that there are certain $g(p, c)$ for which the maximum value isn't at $p = c$. Originally I wanted to use $\\displaystyle \\frac{2pc}{p+c}$, but then I realized that if either $p$ or $c$ is constant, $f(p, c)$ actually grows when $p$ increases past $c$ or vice versa. \u2013\u00a0 Joe Z. Mar 2 '13 at 14:55\n@Joe: Indeed, your full criterion 1 as stated is quite hard to satisfy. In particular, considering the \"worst-case\" test function $g(p,c)=\\min(p,c)$ shows that no function $f(p,c)$ that satisfies both criteria 1 and 2 can be differentiable at points where $p=c$. \u2013\u00a0 Ilmari Karonen Mar 2 '13 at 15:03\nI had a hunch that was the case. The function I've come up with now is not differentiable on $p = c$ either. \u2013\u00a0 Joe Z. Mar 2 '13 at 15:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/11737/get-rid-of-tr-in-svm-kernel-trick/11740\nText:\nTake the 2-minute tour \u00d7\n\nI designed a kernel function (to be used within SVM) which has the expression $tr(AB)$ in it. For efficient implementation of this, I was wondering if I could write $tr(AB)$ as an inner product: $\\phi(A)^T \\phi(B)$? What is the function $\\phi()$?\n\nshare|improve this question\nI'm not sure I understand your question (it would help if you eliminated or explained your jargon), but the obvious optimization is that you don't explicitly need to compute AB: tr(AB) is the sum of A_{ij}*B_{ji} over all pairs i,j. You can do this with a single pass over your matrices. \u2013\u00a0 Darsh Ranjan Jan 14 '10 at 9:25\n@darsh you beat me by 3 minutes! I can explain some of the terminology. Imagine you have data in $\\mathbb{R}^d$ (here it seems to be in $\\mathbb{R}^{d\\times d}$??) but want to work with it in $\\mathbb{R}^D$, which you can accomplish by passing everything through a mapping $\\Phi$. If $D \\gg d$, this can be expensive. But in some cases your algorithm need only compute inner products $\\langle \\Phi(a), \\Phi(b)\\rangle$, in which case there may be a functin $k(\\cdot,\\cdot)$ which computes the same thing but with much less work than the explicit mapping. this is called the 'kernel trick'. \u2013\u00a0 Matus Telgarsky Jan 14 '10 at 9:34\nNote that you don't really need the explicit mapping $\\phi$. What you want is a kernel $k(A, B)$ which has the property that $k(A, B) = \\phi(A)^T \\phi(B)$. Generally, you compute the kernel directly, instead of calculating the mapping and computing the dot product -- that's why it's called kernel `trick'. In your case, it seems you want the kernel to be $k(A, B) = tr(AB)$. So it seems you want to know how to compute the trace efficiently, rather than what the mapping is. \u2013\u00a0 user3035 Jan 14 '10 at 10:02\nThe non-efficiency-related part of this question is basic linear algebra: tr(AB) is an inner product on the space of nxn matrices and so you can find isometric isomorphisms from M_{nxn} to R^{n^2}. Any of these will do for the map phi. I do not know whether or not any of these will improve the efficiency in calculating the trace, but I doubt it. \u2013\u00a0 Andrew Stacey Jan 14 '10 at 10:20\nSorry for being ambiguous. I know that I can implement $k(A,B)$ directly and avoid needing $\\phi()$. But it would be nice if I have $\\phi()$ because then, I can use a regular linear SVM on my $\\phi()$ mapped vectors. This is much simpler and faster compared to implementing $k(A,B)$ and plugging it into SVM. \u2013\u00a0 andinos Jan 14 '10 at 21:39\nadd comment\n\n2 Answers\n\nup vote 0 down vote accepted\n\nMatus is right. But if the matrices $A$, and $B$ have certain properties like being symmetric, or diagonal, then simply just vectorizing the matrices and taking their inner product would be equal to the $tr(AB)$.\n\nshare|improve this answer\nadd comment\n\nIf $A,B$ are arbitrary $n\\times n$ matrices, by definition of trace, $\\textrm{tr}(AB) = \\sum_{i,j} A_{ij}B_{ji}$. This is $O(n^2)$, but just reading the entries of $A$ is $\\Omega(n^2)$. Without any special structure on $A,B$, you probably can't do better.\n\nIf $A,B$ are (column) vectors, you probably mean the outer product $\\textrm{tr}(AB^T) = \\sum_i A_i B_i$.\n\nEdit: andinos clarified to say he wants to know about the implicit mapping of the kernel function. Well I have bad news: It does not exist!! The proof works by showing there exist matrices $A,B$ such that the corresponding kernel matrix is not positive semi-definite. To finish, apply Mercer's theorem.\n\nIn particular, set $A = \\left(\\begin{array}{cc}1 & 1 \\\\\\\\ -1 & 1\\end{array}\\right)$ and $B = A^T = \\left(\\begin{array}{cc}1 & -1 \\\\\\\\ 1 & 1\\end{array}\\right)$. Therefore $\\textrm{tr}(AB) = \\textrm{tr}(AA^T) = 4$, and $\\textrm{tr}(BA)$ is identical. On the other hand, $\\textrm{tr}(AA) = \\textrm{tr}(BB) = 0$. therefore, the kernel matrix $K$ is $\\left(\\begin{array}{cc}0 & 4 \\\\\\\\ 4 & 0\\end{array}\\right)$. Set $x = \\left(\\begin{array}{c} 1 \\\\\\\\ -1\\end{array}\\right)$, and observe that $x^T K x = -8 < 0$, and therefore $K$ is not PSD, so the kernel $k(A,B) = \\textrm{tr}(AB)$ is not PSD.\n\nOn the other hand! If you had instead defined your kernel to be $k'(A,B) = \\textrm{tr}(AB^T)$, notice that $k'(A,B) = \\sum_{i,j}A_{ij}B_{ij} = \\Phi(A)^T\\Phi(B)$ where $\\Phi$ simply takes its input matrix and outputs it as a column vector.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/142909/fourier-transform-over-a-diagonal-matrix\nText:\nTake the 2-minute tour \u00d7\n\nLet $F$ be a $100 \\times 100$ DFT matrix, and $U$ be a diagonal matrix with its diagonal entries being all positive, denoted by $U=\\mathrm{diag}(u_1, u_2,\\cdots, u_{100})$. My question is:\n\nUnder which conditions on $U$ will the resulting matrix $FUF^\\ast$ be circulant (where $F^\\ast$ is the conjugate transpose of $F$)?\n\nshare|improve this question\nThere might be; the Fourier transform of a diagonal matrix has nice structure, being complex-symmetric and constant along its antidiagonals (Hankel)... \u2013\u00a0 \uff2a. \uff2d. May 9 '12 at 3:16\nWell, it is not too hard to show that if $U$ is diagonal with real elements, then $F U F^*$ is real iff all diagonal elements of $U$ are exactly the same, ie, $U$ is a real multiple of the identity. \u2013\u00a0 copper.hat May 9 '12 at 5:22\n...and you have $$\\mathbf U\\mathbf D\\mathbf U^\\ast=\\begin{pmatrix}0&-\\frac12-\\frac{i}{2\\sqrt 3}&-\\frac12+\\frac{i}{2\\sqrt 3}\\\\-\\frac12+\\frac{i}{2\\sqrt 3}&0&-\\frac12-\\frac{i}{2\\sqrt 3}\\\\-\\frac12-\\frac{i}{2\\sqrt 3}&-\\frac12+\\frac{i}{2\\sqrt 3}&0\\end{pmatrix}$$ \u2013\u00a0 \uff2a. \uff2d. May 9 '12 at 6:18\nI might be wrong but I think that every circulant matrix is diagonalized by the DFT matrix so something like $F_n C F_n^* = D$. Using this I'm thinking that you can assume that the result of your computation will be circulant as well and hence you have essentially $n$ (=100) terms to compute. In J.M.'s example, the matrix is circulant. [c0 c1 c2; c2 c0 c1; c1 c2 c0] \u2013\u00a0 tibL May 9 '12 at 8:33\nI think that, up to a normalisation, the (a,b) element of the product is the DFT of u at a-b. \u2013\u00a0 dmuir May 9 '12 at 9:18\nshow 10 more comments\n\n1 Answer\n\nup vote 1 down vote accepted\n\nAfter seeing this article, I see that one can in fact easily build a circulant matrix, given its eigenvalues, and vice-versa. (In short: $\\mathrm F \\mathrm U \\mathrm F^\\ast$ is always circulant.)\n\nBriefly, given the eigenvalues $u_1,u_2,\\dots,u_N$, one simply needs to take the inverse discrete Fourier transform\n\n$$a_{1,j}=\\frac1{N}\\sum_{k=0}^{N-1}u_{k+1}\\exp\\left(\\frac{2\\pi i(j-1)k}{N}\\right)$$\n\nto yield the first row of the circulant matrix $\\mathbf A=\\mathrm F \\mathrm U \\mathrm F^\\ast$, after which the successive rows of $\\mathbf A$ are easily generated. Conversely, the eigenvalues of $\\mathbf A$ are generated by taking the DFT of the first row of $\\mathbf A$.\n\nHere's a Mathematica demonstration:\n\nn = 100;\nvec = Sort[RandomReal[{0, 30}, {n}], Greater];\nma = NestList[RotateRight, \n   InverseFourier[vec, FourierParameters -> {1, -1}], n - 1];\nEigenvalues[ma] - vec // Chop\nshare|improve this answer\nThanks! It is very clear that a circulant matrix can be diagonalized via DFT, and vice-versa. \u2013\u00a0 John Smith May 9 '12 at 15:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.it/it/help/dsp/examples/adaptive-noise-canceling-anc-applied-to-fetal-electrocardiography.html?nocookie=true\nText:\nDocumentation Center\n\n  \u2022 Trials\n  \u2022 Product Updates\n\nAdaptive Noise Canceling (ANC) Applied to Fetal Electrocardiography\n\nThis example shows how to apply adaptive filters to noise removal using adaptive noise canceling. The example uses a user interface (UI) which can be launched by typing the command HelperAdaptiveNoiseCancellation. For more details, see 'Example Architecture' below.\n\n\nIn adaptive noise canceling, a measured signal d(n) contains two signals: - an unknown signal of interest v(n) - an interference signal u(n) The goal is to remove the interference signal from the measured signal by using a reference signal x(n) that is highly correlated with the interference signal. The example considered here is an application of adaptive filters to fetal electrocardiography, in which a maternal heartbeat signal is adaptively removed from a fetal heartbeat sensor signal. This example is adapted from Widrow, et al, \"Adaptive noise canceling: Principles and applications,\" Proc. IEEE\u00ae, vol. 63, no. 12, pp. 1692-1716, December 1975.\n\nCreating the Maternal Heartbeat Signal\n\nIn this example, we shall simulate the shapes of the electrocardiogram for both the mother and fetus. We use a 4000 Hz sampling rate. The heart rate for this signal is approximately 89 beats per minute, and the peak voltage of the signal is 3.5 millivolts.\n\nCreating the Fetal Heartbeat Signal\n\nThe heart of a fetus beats noticeably faster than that of its mother, with rates ranging from 120 to 160 beats per minute. The amplitude of the fetal electrocardiogram is also much weaker than that of the maternal electrocardiogram. The following series of commands creates an electrocardiogram signal corresponding to a heart rate of 139 beats per minute and a peak voltage of 0.25 millivolts.\n\nThe Measured Maternal Electrocardiogram\n\nThe maternal electrocardiogram signal is obtained from the chest of the mother. The goal of the adaptive noise canceller in this task is to adaptively remove the maternal heartbeat signal from the fetal electrocardiogram signal. The canceller needs a reference signal generated from a maternal electrocardiogram to perform this task. Just like the fetal electrocardiogram signal, the maternal electrocardiogram signal will contain some additive broadband noise.\n\nThe Measured Fetal Electrocardiogram\n\nThe measured fetal electrocardiogram signal from the abdomen of the mother is usually dominated by the maternal heartbeat signal that propagates from the chest cavity to the abdomen. We shall describe this propagation path as a linear FIR filter with 10 randomized coefficients. In addition, we shall add a small amount of uncorrelated Gaussian noise to simulate any broadband noise sources within the measurement.\n\nApplying the Adaptive Noise Canceller\n\nThe adaptive noise canceller can use most any adaptive procedure to perform its task. For simplicity, we shall use the least-mean-square (LMS) adaptive filter with 15 coefficients and a step size of 0.00007. With these settings, the adaptive noise canceller converges reasonably well after a few seconds of adaptation--certainly a reasonable period to wait given this particular diagnostic application.\n\nRecovering the Fetal Heartbeat Signal\n\nThe output signal y(n) of the adaptive filter contains the estimated maternal heartbeat signal, which is not the ultimate signal of interest. What remains in the error signal e(n) after the system has converged is an estimate of the fetal heartbeat signal along with residual measurement noise. Using the error signal, can you estimate the heart rate of the fetus?\n\nExample Architecture\n\nThe command HelperAdaptiveNoiseCancellationHelperAdaptiveNoiseCancellation launches a user interface designed to interact with the simulation. It also launches a time scope to view the the measured fetal hearbeat as well as the measured maternal heartbeat and the extracted fetal heartbeat.\n\nUsing a Generated MEX File\n\nUsing MATLAB Coder, you can generate a MEX file for the main processing algorithm by executing the command HelperANCCodeGenerationHelperANCCodeGeneration. You can use the generated MEX file by executing the command HelperAdaptiveNoiseCancellation(true).\n\nWas this topic helpful?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/52053/deforming-a-truncated-icosahedron-into-its-circumscribing-sphere\nText:\nTake the 2-minute tour \u00d7\n\nImagine that I have a truncated icosahedron consisted of 60 vertices, each of degree $deg(v) = 3$, and fixed edge length $L$. I'd like to assign some constant curvature or bending angle $\\theta$ to each edge s.t. I can deform the icosahedron into its circumscribing sphere.\n\nAs a function of the edge length $L$, what value of $\\theta$ allows me to properly perform this deformation?\n\nshare|improve this question\nI don't understand how you're using the \"bending angle\" to deform the icosahedron. Are you looking for the angle $\\theta$ that each edge makes with the circumscribing sphere? \u2013\u00a0 anon Jul 17 '11 at 23:49\n@anon, sorry for the confusion! No I'm looking for the bending angle that places each edge on the surface of the sphere. \u2013\u00a0 R.H. Jul 18 '11 at 3:04\nOh, you mean the angle formed by the arc which results from a radial projection of an edge onto the circumscribing sphere. \u2013\u00a0 anon Jul 19 '11 at 12:15\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nFix $L=1$. Then the radius of the circumscribed sphere is $r=\\frac{1}{4} \\sqrt{58+18 \\sqrt{5}} \\approx 2.478$. Now look at the isosceles triangle formed by the center of the sphere and one edge. It has sides of length $r$ and base length 1. So the angles at either end of the base are $\\cos^{-1} (1/(2r)) \\approx 78.3593^\\circ$. The angle between the tangent to the sphere at one endpoint and the edge is then about $11.6407^\\circ$.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Soccer Ball\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192928/optimize-function-lagrange-multipliers/193013\nText:\nTake the 2-minute tour \u00d7\n\nI have a function of 4 variables: (distance function)\n$d(x,x_1,y,y_1 )=(x-x_1 )^2+(y-y_1 )^2$\n\nsubject to 2 constraints:\n1. $g(x,x_1,y,y_1 )=ax^2+2hxy+2gx+by^2+2fy+c=0$\n2. $h(x,x_1,y,y_1 )= a_1 x_1^2+2h_1 x_1 y_1+2g_1 x_1+b_1 y_1^2+2f_1 y_1+c_1=0$\n\nUsing lagrange multipliers, and partial differentiation, what should be the values of $x,x_1,y,y_1$ in terms of $a,b,c,a_1,b_1,c_1,f,g,h,f_1,g_1,h_1$, with aforementioned constraints?\n\nshare|improve this question\nHave you tried writing down the gradients of all functions involved and coming up with an equation for the Lagrange multipliers? \u2013\u00a0 Alex R. Sep 9 '12 at 1:01\nYes I have tried and I have come up with equations. That was the easy part actually, the hard part is to find values of x,x1,y,y1, with which I'm struggling up to now. \u2013\u00a0 David Hoffman Sep 9 '12 at 20:49\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $\\nabla F= \\langle \\partial_x F, \\partial_{x_1} F, \\partial_y F, \\partial_{y_1} F \\rangle$. The method of Lagrange in this case requires the introduction of two multipliers. We should solve:\n\n$$ \\nabla d = \\lambda_1\\nabla g+ \\lambda_2\\nabla h $$\n\nsubject to constraints 1 and 2 as listed in your post.\n\nThe reason for this is as follows: if an extrema exists then curves $t \\mapsto \\alpha(t) $ which pass through the extremal point must make $\\eta=d \\circ \\alpha$ extreme at the corresponding point in the domain. Suppose $t=0$ gives $\\alpha(0)$ the extremal point (we can shift the parameter to make this happen, nothing is lost in this convenience).\n\nThe curve $\\alpha$ lies on the intersection of the level sets given by 1 and 2. We have\n\n$$ g (\\alpha(t)) =0 \\qquad h( \\alpha(t))=0 $$\n\nThe chain-rule yields\n\n$$ \\nabla g (\\alpha(t)) \\cdot \\alpha'(t)=0 \\qquad \\nabla h (\\alpha(t)) \\cdot \\alpha'(t)=0 $$\n\nLikewise, since $\\eta$ is extremal at $t=0$ the chain rule gives\n\n$$ \\nabla d (\\alpha(0)) \\cdot \\alpha'(0)=0 $$\n\nSummarizing, the tangent vector field $\\alpha'$ is orthogonal to the gradient fields of $g$ and $h$ where they can be compared and at $\\alpha(0)$ the tangent $\\alpha'(0)$ is orthogonal to $\\nabla d$. The point $\\alpha(0)$ is special in that we obtain orthogonality with respect to $\\nabla d, \\nabla g$ and $\\nabla h$.\n\nAt first glance this would not appear to connect $\\nabla d, \\nabla g$ and $\\nabla h$ in any particular way. However, there is not just one curve on the constraint surface. Provided the constraints 1. and 2. are nondegenerate the level set they define is two-dimensional and there will be a two-dimensional plane of tangent vectors which are found orthogonal to $\\nabla d, \\nabla g$ and $\\nabla h$. But, this means that $\\nabla d, \\nabla g$ and $\\nabla h$ are linearly dependent since $\\mathbb{R}^4$ should be the direct sum of the tangent and normal space. For these reasons we introduce multipliers to ascertain the location of the max/min solution.\n\nNotice the method is based on the existence of extreme solutions. For the continuous function $d$ these are known to exist if the constraint is a compact surface. Sometimes the method still \"works\" for non-compact constraints, but beware the limit of the method.\n\nshare|improve this answer\nI'm sorry but I can't really understand what you wrote, this math is too advanced for me. Would it be possible to explain this at a high-school level? If not, I will be absolutely ok with it. I just need to know whether a high school student is able to solve this. Thanks. \u2013\u00a0 David Hoffman Sep 9 '12 at 20:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/236495/the-mid-point-rule-as-a-function-in-matlab?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nHow would I go about creating a function in matlab which would calculate the following\n\n$$M_c(f)=h \\sum_{i=1}^N f(c_i)$$\n\n\n$h=\\frac{b-a}{N}, \\\\c_i=a+0.5(2i-1)h,\\\\ i=1,\\ldots,N$\n\nWhat I have tried so far is\n\nfunction(M(f))= composite_midpoint(f)\n\nfor i=1:1:N\n   M(f) = h*(sum + f)\n\nSorry about not inserting the matlab code directly, I'm not sure how to do it.\n\nshare|improve this question\nUpdated the formatting, you can use four spaces in front of each line to show code. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 16:41\nWhat types of 'functions' are you expecting to be able to input for f? Symbolic functions, or matlab functions? \u2013\u00a0 icurays1 Nov 13 '12 at 16:42\nIt would be a function which is smooth enough for Taylor's theorem and one which it's integral can be calculated exactly. \u2013\u00a0 Nicky Nov 13 '12 at 16:49\nYes, but with matlab functions are either .m files or \"symbolic\" functions. Its not going to work the way you have it written if you call it like \"composite_midpoint(x^2)\". It doesn't know what x^2 means. \u2013\u00a0 icurays1 Nov 13 '12 at 16:54\nIf I were to want the function to be x^2 how would I go about altering my code so that it worked for the midpoint rule? \u2013\u00a0 Nicky Nov 13 '12 at 16:59\nshow 1 more comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nFirst run this outside the function:\n\na = 6; \nb = 4.234;\nN = 10;\n\nThen save this function to a file called compositemidpoint.m (in your current directory)\n\nfunction M = compositemidpoint(a,b,N)\nh = (b-a)/N\ni = 1:N\nc_i = a+0.5*(2*i-1)*h\nf = log(c_i) + c_i.^2 % A sample function\nM = h*sum(f);\n\nThen call it by typing:\n\nshare|improve this answer\nIt does not really make sens yet, but this is how i debugged your attempted code to not-crash. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 16:52\nYour code only sums the vector $f$ and multiplies it by $h$. There is no midpoint rule occurring here - you have to create the vector $f$ by evaluating some function at the grid points $c_i$... \u2013\u00a0 icurays1 Nov 13 '12 at 16:56\nI have updated the answer to include an example function. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 17:01\nI tried running this but it wouldn't work. I've put in function out= compositemidpoint at the very begining of the function however it is still coming up with errors. \u2013\u00a0 Nicky Nov 13 '12 at 17:14\nI have included some instructions on how to call it. \u2013\u00a0 Dennis Jaheruddin Nov 13 '12 at 17:22\nadd comment\n\nHere's my solution, which is vectorized (for loops are bad in matlab).\n\nfunction Mf=midpoint_rule(a,b,N,f)\n\n%ci are your evaluation points\n%This evaluates the function f, which is another matlab function\n%you can just add up the vector y and multiply by h\n\n\nFor example, you can save another .m file Myfunction.m, that might look like:\n\nfunction y=Myfunction(x)\n\n%The dot means \"pointwise\"\n\n\nThen, in the main window, you would evaluate the integral by saying \"midpoint_rule(1,2,100,@Myfunction)\". The \"at\" symbol tells matlab you'll be using a matlab function called \"Myfunction\".\n\nshare|improve this answer\nIf you only need your midpoint rule function to run for a couple test functions, you can also hard-code them in by saying \"y=sin(x)\" etc instead of \"y=f(ci)\". But then you would have to change your code every time you have a new function to integrate! \u2013\u00a0 icurays1 Nov 13 '12 at 17:18\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/60426/generating-spaces-of-homogenous-polynomials-in-two-variables?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nConsider the $\\mathbb Z$-module that consists of the polynomials in $\\mathbb Z[x,y]$ that are homogeneous polynomials of degree $d$ in the indeterminates $x$ and $y$ (homogeneous meaning that all terms of the form $c_{ij} x^i y^j$ are such that $i+j = d$, where $d$ is the degree of the polynomial). One can see that there is a unique way of writing an homogeneous polynomial of degree $d$ in the form $$ \\sum_{j=0}^d c_k y^{d-k} \\prod_{i=0}^{k-1} (x-iy) $$ because there is precisely one term where $x$ is at the $k^{th}$ power for any $k$ in the range $[0,d]$, hence we can compute coefficients. Therefore, the polynomials $y^{d-k} \\prod (x-iy)$ form a basis of the $\\mathbb Z$-module.\n\n\nIs it possible to write any homogenous polynomial of degree $d$ in the form $$ \\sum_{k=0}^d c_k \\left( \\prod_{i=0}^{d-k-1} (y-ipx) \\right) \\left( \\prod_{i=0}^{k-1} (x-iy) \\right) $$ where $p$ is a prime number? (The larger context is a number theory context, thus the prime is the thing I need. The fact that $p$ is prime might not be needed to prove this though!) Note that the polynomials formed by the 2 products are actually homogenous polynomials of degree $d$ in $x$ and $y$, so this would be a basis of the $\\mathbb Z$-module of homogenous polynomials of degree $d$.\n\nThe reason for this question is because I am looking for a characterization for a certain class of polynomials that are always 0 with respect to a prime power modulus and the existence of this decomposition would help me very much. =)\n\nIf you have any suggestions please feel free to comment.\n\nshare|improve this question\nOne remark for those who might consider inverting some kind of matrices : the fact that it is easy to generate polynomials when there is no \"$ipx$\" term in the linear factors for $y$ is that you can rewrite this problem in the form of solving a linear equation of the form $AX = Y$, where $X$ and $Y$ are the coefficient vectors and $A$ is the coordinate switch matrix. The \"easiness\" comes from the fact that $A$ is either upper or lower triangular (depending on which way you place coefficients...), hence it is easy to see that $A$ needs to be invertible with integer non-zero determinant. \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 0:51\nRe: Your background question. You do know the classification of single variable polynomials with values (at integer points) vanishing modulo a prime power, don't you? That not-too-well-known result has been rediscovered periodically (Singmaster in '69, Niven & Warren in '57, Carlitz says that it was in Dickson's old book,...) \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 5:56\nYes, I know it, and it is quite simple to read (but took me weeks to prove...). Write $$ f(x) = \\sum_{k=0}^d c_k(x)_k. $$ It is always possible to do this in $\\mathbb Z[x]$. Now note that $f(\\ell) = \\sum_{k=0}^{\\ell} c_k k! \\begin{pmatrix} \\ell \\\\ k \\end{pmatrix}$, hence you can show by induction that $c_k k! \\equiv 0$ $\\mathrm{mod}$ $p^m$ by assuming that $f$ vanishes $\\mathrm{mod}$ $p^m$. Conversely, a polynomial with this property vanishes because $f(\\ell) = \\sum_{k=0}^{\\ell} c_k k! \\begin{pmatrix} \\ell \\\\ k \\end{pmatrix} \\equiv \\sum_{k=0}^{\\ell} 0 = 0.$ \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 7:32\nThe result I had in mind goes as follows. Write $p_k(x)=\\prod_{i=0}^{kp-1}(x-i)$. Then the values $p_k(n), n\\in\\mathbf{Z}$ are always divisible by $(kp)!$, so if you multiply these polynomials with the appropriate power of $p$ you get polynomials with values vanishing $\\pmod{p^\\ell}$. If you take such polynomials up to the first monic one, you have a generating set for the ideal of polynomials in $\\mathbf{Z}[x]$ that vanish module $p^\\ell$. \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 7:55\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nI don't think that you have a $\\mathbf{Z}$-basis. I claim that if $d>1$, then all the polynomials $q(x,y)$ in the $\\mathbf{Z}$-span of your generators have the property $p-1\\mid q(1,1)$. Thus, if $p>2$ the span cannot consist of all the homogeneous polynomials of degree $d$.\n\nProof: If you evaluate the polynomial $$p_k(x,y)=\\prod_{i=0}^{d-k-1}(y-ipx) \\prod_{i=0}^k(x-iy)$$ at $x=y=1$, the second product shows that $p_k(1,1)=0$ unless $k=0$ (if $k>0$, then the factor $x-y$ coming from $i=1$ makes this happen). But if $k=0$ and $d>1$, then the first product has a factor $y-px$ (again coming from $i=1$), and this forces $p_0(1,1)$ to be divisible by $y-px\\vert_{(x,y)=(1,1)}=1-p$. For all $k$ we have $p-1\\mid p_k(1,1)$, so the same holds for all the $\\mathbf{Z}$-linear combinations of the polynomials $p_k(x,y)$.\n\nshare|improve this answer\nGiven that $p-1$ is a unit in your eventual ring this may not ruin your approach, but it does seem to settle the question over $\\mathbf{Z}$. \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 6:10\nI am a little confused by your argument because there are many assumptions along the way... but maybe it's clear and I should read this tomorrow XD But in my ring, $p-1$ is indeed a unit, so I think that if you're right there is still work to do, and I would be really pissed to find out that it's not possible to do this... \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 7:36\nFor your curiosity : I have shown a few hours ago (heehee) that for $f(x,y)$ homogeneous of degree $d$ and $m \\le p$, vanishing mod $p^m$ is equivalent to be able to write it in the following form : $$ f(x,y) = \\sum_{j=0}^{m} \\left( \\left( p^{m-j} y^j \\prod_{i=0}^{jp-1} (x-iy) \\right) \\gamma_j (x,y) \\right) $$ where the $\\gamma_j(x,y)$'s are homogeneous polynomials of degree $d-j(p+1)$ that can be arbitrary. When working on these kind of vanishing question, understanding what happens up to $p^p$ and then moving to $p^{p+1}$ and $p^{p+2}$ in a clever manner is the key point. \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 7:38\n@Patrick: I made an attempt to make the structure of my argument clearer. \u2013\u00a0 Jyrki Lahtonen Aug 29 '11 at 10:18\nOkay, so $p-1 | q(1,1)$. So since for instance $x^2$ (or $x^d$ for generality) is such that $p-1 \\nmid q(1,1) = 1$, we're done. =) Thank you! \u2013\u00a0 Patrick Da Silva Aug 29 '11 at 14:38\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/297881/find-two-closest-points-on-two-functions\nText:\nTake the 2-minute tour \u00d7\n\nWe have two functions:\n\n$$\\begin{align*} y &= x^4-5x^3+2x^2-5 \\\\ y &= -11x-20 \\end{align*}$$\n\nMy task is to find two closest points that can be found on these two functions.\n\nCan somebody give any hints on how to solve these type of exercises?\n\nThank you!\n\nshare|improve this question\nDo you mean the closest points of the curves, or the minimum difference between the two functions? \u2013\u00a0 copper.hat Feb 8 '13 at 8:17\nThe minimum difference between the two functions. :) \u2013\u00a0 Trom Feb 8 '13 at 8:23\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nYou want to minimize $x^4-5 x^3+2 x^2+11 x+15$. Take the derivative, set that to $0$, and solve. Unfortunately this is an irreducible cubic, so the solutions are not very nice. There are three real roots: approximately $-.6828742578$, $1.275428188$, $3.157446070$. I'll leave it to you to find which of these gives the minimum.\n\nshare|improve this answer\nadd comment\n\nSince you want the minimum difference between $$\\begin{align*} y_1(x) &= x^4-5x^3+2x^2-5 \\text{ and }\\\\ y_2(x) &= -11x-20 \\end{align*}$$ you are looking for the minimum of $$ \\left| y_1(x) - y_2(x) \\right|$$ which will be a max / min of $$ z(x) = y_1(x) - y_2(x).$$ So write down the equation for $z$ as Robert Israel has done for you, differentiate $z$ and find its turning points.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/189224/defective-items-probability-question/189248\nText:\nTake the 2-minute tour \u00d7\n\nHi I'm working with probability as part of an engineering course, and I'm struggling with the following tutorial question: Components of a certain type are shipped to a supplier in batches of ten. Suppose that 50% of all such batches contain no defective components, 35% contain one defective component while 15% contain two defective components. If two components are randomly selected from the batch. What are the probabilities associated with 0, 1 and 2 defective components being in the batch under each of the following conditions? a) Neither selected component is defective. b) One of the two components is defective. c) Both components are defective.\n\nI've considered using hypergeometric probability distribution for events P(35%) and P(15%) while comparing to P(50%) but this yields no result.\n\nshare|improve this question\nHave you learned about the law of total probability? I would suggest that you try and solve the simpler problem of one item being selected at random from a randomly selected batch and finding the probability that it is defective, and then tackle the problem of two items. By the way, since this looks like homework, please add the homework tag. \u2013\u00a0 Dilip Sarwate Aug 31 '12 at 11:48\nadd comment\n\n2 Answers\n\nLet $B_0$ be the event that the batch has $0$ defectives, $B_1$ be the event the batch has $1$ defective, and $B_2$ be the event the batch has $2$ defectives.\n\nLet $D_0$ be the event that neither selected component is defective. Problem (a) asks us to find the conditional probabilities $\\Pr(B_0|D_0)$, $\\Pr(B_1|D_0)$, and $\\Pr(B_2|D_0)$. Now the hardest part, identifying precisely what we are after, has been done!\n\nFor the calculation, we use the general conditional probability formula $$\\Pr(X|Y)\\Pr(Y)=\\Pr(X\\cap Y).$$ Put $X=B_0$ and $Y=D_0$. We need $\\Pr(D_0)$ and $\\Pr(B_0\\cap D_0)$.\n\nThe event $D_0$ can happen in three different ways: (i) Our batch of $10$ is perfect, and we get no defectives in our sample of two; (ii) Our batch of $10$ has $1$ defective, but our sample of two misses them; (iii) Our batch has $2$ defective, but our sample misses them. If it helps, draw a tree that shows the three different paths through which we can end up with no defectives.\n\nFor (i), the probability is $(0.5)(1)$. For (ii), the probability that our batch has $1$ defective is $0.35$. Given that it has $1$ defective, the probability that our sample misses it is $\\binom{9}{2}/\\binom{10}{2}$, which is $8/10$. So the probability of (ii) is $(0.35)(8/10)$. For (iii), the probability our batch has $2$ defective is $0.15$. Given that it has $2$ defective, the probability that our sample misses both is $\\binom{8}{2}/\\binom{10}{2}$, which is $56/90$. So the probability of (iii) is $(0.15)(56/90)$. We have therefore found that $$\\Pr(D_0)=(0.5)(1)+(0.35)(8/10)+(0.15)(56/90).$$ The probability $\\Pr(B_0\\cap D_0)$ has been calculated during our calculation of $\\Pr(D_0)$. It is $(0.5)(1)$. We conclude that $$\\Pr(B_0|D_0)=\\frac{(0.5)(1)}{(0.5)(1)+(0.35)(8/10)+(0.15)(56/90)}.$$ The rest of the calculations for $D_0$ are easy, we have all the information needed. We get $$\\Pr(B_1|D_0)=\\frac{(0.35)(8/10)}{(0.5)(1)+(0.35)(8/10)+(0.15)(56/90)}$$ and $$\\Pr(B_2|D_0)=\\frac{(0.15)(56/90)}{(0.5)(1)+(0.35)(8/10)+(0.15)(56/90)}.$$\n\nAlternately, we could have used Bayes' Formula directly . I wanted to do it in the above more basic way so that the logic would be clear.\n\nNow unfortunately we have to deal with (b) and (c). But (c) is trivial! For (b), the calculation is as above, a little simpler, because if our sample of two has a defective, it cannot come from a perfect batch.\n\nshare|improve this answer\nAndr\u00e9, how is your calculation not a use of Bayes' formula, since you are simply replacing $P(D_i)$ in the expression $$P(B_j \\mid D_i) = \\frac{P(B_j \\cap D_i)}{P(D_i)}$$ by its value as obtained via the law of total probability? In over 35 years experience teaching probability to recalcitrant engineering undergraduate students, I have always tried to emphasize the formulation that you have used, pointing out that the numerator term is one that is computed as part of the denominator and thus need not be calculated again: cf. your \"The probability $P(B_0\\cap D_0)$ has been calculated during \" \u2013\u00a0 Dilip Sarwate Aug 31 '12 at 13:25\nIt is certainly absolutely the use of the Bayes' Formula idea. just going back one little step. (Before the divorce of Math and Stat, I used to teach the standard probability and statistics for engineers pretty often. One has to do a delicate balance between ideas and cookbook.) \u2013\u00a0 Andr\u00e9 Nicolas Aug 31 '12 at 13:37\nThanks a lot, this answer is making sense too now, this stuff isn't so bad if you really start understanding it. Thank you \u2013\u00a0 Tertius Aug 31 '12 at 14:01\nadd comment\n\nTry using Bayes' theorem: $$P(A|X) = P(X|A) \\dfrac{P(A)}{P(X)}$$\n\nFor instance, let event $A_m$ be \"there are $m$ defective components in the batch\" and let event $X_n$ be \"$n$ of the selected components are defective\". Then we have the given marginal probabilities for $A_m$:\n\n$$\\begin{aligned} P(A_0) &= 0.5 & P(A_1) &= 0.35 & P(A_2) &= 0.15 \\end{aligned}$$\n\nand the conditional probabilities for $X_n$ given $A_m$:\n\n$$\\begin{aligned} P(X_0|A_0) &= 1 & P(X_0|A_1) &= \\frac45 & P(X_0|A_2) &= \\frac{28}{45} \\\\ P(X_1|A_0) &= 0 & P(X_1|A_1) &= \\frac15 & P(X_1|A_2) &= \\frac{16}{45} \\\\ P(X_2|A_0) &= 0 & P(X_2|A_1) &= 0 & P(X_2|A_2) &= \\frac1{45} \\end{aligned}$$\n\n(Exercise: Why those probabilities? It's just a simple case of sampling without replacement.)\n\nFrom the conditional probabilities, we can also calculate the marginal probabilities for $X_n$ using the law of total probability:\n\n$$\\begin{eqnarray} P(X_0) &= 1\\cdot0.5 &+& \\frac45\\cdot0.35 &+& \\frac{28}{45}\\cdot0.15 =& \\frac{131}{150} =& 0.87333\\dots \\\\ P(X_1) &= 0\\cdot0.5 &+& \\frac15\\cdot0.35 &+& \\frac{16}{45}\\cdot0.15 =& \\frac{37}{300} =& 0.12333\\dots \\\\ P(X_2) &= 0\\cdot0.5 &+& 0\\cdot0.35 &+& \\frac{1}{45}\\cdot0.15 =& \\frac{1}{300} =& 0.00333\\dots \\\\ \\end{eqnarray}$$\n\nNow apply Bayes' theorem to get the conditional probabilities $P(A_m|X_n)$.\n\nshare|improve this answer\nThanks man, just went to see my lecturer about this problem. He confirmed everything you've said. Nice answer. \u2013\u00a0 Tertius Aug 31 '12 at 13:47\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mechanics.stackexchange.com/questions/2668/02-trailblazer-with-front-end-vibration-which-seems-to-increase-over-time?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nAbout a month ago my trailblazer developed this new features. When you get into the car and start driving, everything feels completely fine. Then after about 5 minutes you start noticing slight vibration (very slight, just feels like something isn't quite right). After about a 20 minute drive, the vibration is very noticeable. By that time, it almost sounds like low engine rumble, but its pitch and volume vary directly with car's speed, not engine speed. When it gets to that level, it is also easily felt in the steering wheel.\n\nThree weeks ago, I jacked the car up and noticed that there was a ton of grease spewed around passenger side CV boot. So I went through the motion, which took a while for various reasons, of replacing passenger CV shaft and while in there, also rebuilt 4WD disconnect with fresh bearings and seals. Yesterday I put the car back on the road and the vibration is still in there unchanged.\n\nI tugged on both wheels to check wheel hubs and at first glace the wheel bearings appear fine. I've had bad wheel bearings on this car before, left one is 5 years old. right one is 1 year old. Whenever wheel bearings were bad a) vibration would be constant through out the drive (i.e. you can feel it the second you start driving) and b) they would change in sound when turning left or right.\n\nThis current vibration is... 1) unaffected by turning left/right or going straight 2) does not change in sound if 4wd is engaged or disengaged 3) unaffected by putting the car in neutral and revving the engine\n\nI also checked the front differential fluid level (obviously destroying the fill plug in the process) and topped off the oil level. It was a little low, but no where near empty.\n\nAny ideas what would be causing it?\n\nUPDATE: Drove the car to work today. I have to take back (1) from above. If I turn the steering wheel right, vibration becomes stronger and if I turn left it gets weaker, which is actually consistent with driver's side wheel bearing being bad. The difference is that with my previous bad bearings, I only had to apply slight pressure to the steering wheel to hear sound difference, but this time, I have to push the steering wheel a bit further out (can still hear difference in a single lane going straight). Also the vibration this time seems to be distinctly lower pitch than the ones I've heard in the past with wheel bearings, but maybe they come in different shapes and sounds?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nI also have a AWD Trailblazer, and low diff oil can cause uneven gear wear (mine is perennially low because I have a leaking diff seal which the dealer can't get out). As the oil heats up, the vibration can become more prominent because the thick oil is no longer damping the vibration.\n\nYou may also want to check that your wheels are balanced. You might have chucked a wheel weight or worn a tire unevenly. But, the noise you describe (through the steering wheel) definitely sounds to me like a worn front diff.\n\nshare|improve this answer\nNick, although I appreciate a response, that is sooooo not what I wanted to hear :). Stupid TB. I did have the same suspicion, that' why I topped off the fluid, but I can't say it was that low. And btw, I did also notice that the differential pinion seal is leaking oil on my car as well. Stupid TB. \u2013\u00a0 DXM Jan 16 '12 at 20:44\nadd comment\n\nIt was driver-side wheel bearing.\n\nI've had 4 other bad wheel bearings (2 in this car, 1 in wife's BMW 330i and 1 in my old Integra) and they've always sounded the same. Smooth, mid- to high-pitch vibration which almost disappears when you turn the wheel one way or another.\n\nWhat confused me was this noise was much rougher (like I said in original question, almost low engine rumble) and at first it happened at any steering wheel angle. Past few days I did notice change in pitch/volume when moving the steering wheel but it wasn't like that at first.\n\nOne clue that told it it was probably a wheel bearing was after I came home few days ago, I felt the rims and driver side was significantly warmer than passenger side, which I would guess caused by extra friction in the bad hub.\n\nNow the car is back on the road and feels as smooth as butter.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247312/what-are-the-solutions-to-z41-0/247387\nText:\nSign up \u00d7\n\nI can't seem to find the solutions to $z^4+1=0 $. $z$ is in the complex plane.\n\nThe solutions show four roots; however, how do I find them once $z^4 = -1$?\n\nshare|cite|improve this question\nCan you find one? Do you know geometrically (in polar coordinates) what happens to a complex number $z$ when raised to power $n$? In the solution, basically you will draw a square in the unit circle. \u2013\u00a0 Berci Nov 29 '12 at 15:31\nDo you know the magic factorization $z^4+4=(z^2-2z+2)(z^2+2z+2)$? From this you can get what you\u2019re seeking. \u2013\u00a0 Lubin Nov 29 '12 at 17:10\nAfter answering, I realized I had already answered the same question, not too long ago. Duplicate of:\u2026 \u2013\u00a0 mrf Nov 29 '12 at 22:53\nNote: I think it is more appropriate to say \"find the solutions to $X$\" when $X$ is an equation; and \"find the roots of $X$\" when $X$ is a polynomial. \u2013\u00a0 Pedro Tamaroff Nov 29 '12 at 23:39\n\n5 Answers 5\n\nYou can write $z^4=-1$ as $(z^2)^2=-1$. The two square roots of $-1$ are $i$ and $-i$, so we get the two equations $z^2=\\pm i$.\n\nSince $i$ corresponds to $\\pi/2$ on the unit circle, its square root will have to correspond to $\\pi/4$ (or use De Moivre if you don't see this). So $$ z=\\pm\\frac{1+i}{\\sqrt 2},\\ \\ z=\\pm\\frac{1-i}{\\sqrt 2} $$ are the roots.\n\nshare|cite|improve this answer\n\nYou can write $-i$ in polar form: $$-i = e^{i \\cdot 3 \\pi /2} $$\n\nThen to find a fourth root...\n\nshare|cite|improve this answer\n\n$$z^4=-1=e^{\\pi i+2k\\pi i}=e^{\\pi i(1+2k)}\\Longrightarrow z=e^{\\frac{\\pi i}{4}(1+2k)}\\,\\,,\\,k=0,1,2,3$$\n\nshare|cite|improve this answer\n\nSince we have $i^2=-1$ $$z^4+1=(z^2)^2-(i)^2$$ $a^2-b^2=(a-b)(a+b)$, so we can factor to have $$z^4+1=(z^2)^2-(i)^2=(z^2-i)(z^2+i)$$ It's easy to solve from here on. $$z^4+1=0 \\implies \\left \\{ \\begin{align}&z^2-i=0\\implies z=\\pm\\sqrt i \\\\&z^2+i=0 \\implies z=\\pm\\sqrt{-i}\\end{align}\\right.$$\n\nUsing the properties\n\n  \u2022 $i=e^{i(\\pi/ 2)}$\n  \u2022 $-i=e^{i(3\\pi/ 2)}$\n  \u2022 $e^{i\\theta}=\\cos \\theta + i\\cdot \\sin \\theta$\n\nyou can express the result in much more interesting forms.\n\nshare|cite|improve this answer\n\n$$z^4+1 = (z^2+1)^2-2z^2 = (z^2+1-z\\sqrt2)(z^2+1+z\\sqrt2)$$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/18548/use-mathematica-as-a-terminal/18572\nText:\nSign up \u00d7\n\nI love how notebooks work in Mathematica.\n\nYou can edit code in real time and hit Ctrl+Shift to run it.\n\nAdditionally you copy and paste different cells around to organize and test ideas.\n\nSearch and replace, plot/visualization,etc.. are built into the system.\n\nMy question: How could you adequately adapt Mathematica to use as a terminal replacement?\n\nIf not (this might get transferred to is there a terminal editor that exists that works like Mathematica's notebook interface?\n\nshare|improve this question\nYou can call external programs with Run[] and RunThrough[] but I don't think they can work interactively. \u2013\u00a0 0xFE Jan 27 '13 at 7:25\nIn response to your second question, the BBEdit shell worksheet offers some broadly similar ideas. \u2013\u00a0 cormullion Jan 27 '13 at 9:20\nAny version of Emacs has full terminal capability, and you find a version (often several) for any OS I know of. \u2013\u00a0 m_goldberg Jan 27 '13 at 9:55\n\n1 Answer 1\n\nOne thing that we can do is exploit the CellEvaluationFunction option of cells to replace the standard evaluator with a function of our own design. In this case, that evaluation function will invoke the system shell.\n\nFirst, let's create a helper function that can create such cells:\n\nevaluatableCell[label_String, evaluationFunction_] :=\n  ( CellPrint[\n      , \"Program\"\n      , Evaluatable -> True\n      , CellEvaluationFunction -> evaluationFunction\n      , CellGroupingRules -> \"InputGrouping\"\n  ; SelectionMove[EvaluationNotebook[], All, EvaluationCell]\n  ; NotebookDelete[]\n  ; SelectionMove[EvaluationNotebook[], Next, CellContents]\n\nThis function creates a cell with the look of a Program cell, but evaluates its contents using a function we provide. So if we wanted to have the system shell evaluate the contents, we would do this:\n\n\nNote that when we evaluate this expression, the input expression is erased and replaced with a new cell. I'll say that again: the original expression is erased. This is convenient for frequent use, but if you have typed in a complex expression for testing purposes, save it before you evaluate! If you don't like this behaviour, simply remove the SelectionMove and NotebookDelete lines from evaluatableCell.\n\nThe replacement cell is treated as an evaluatable input cell. The following example was run on Windows:\n\n\nThis shell cell is very basic. The error-handling is non-existent and, on Windows at least, ignores all lines after the first. We can make this a little more robust if we write the text to be evaluated into a script file, run it, and capture the output. The following helper function captures this common idiom:\n\nOptions[runTempFile] = {FilePattern -> \"_\", FileExtension -> Automatic};\nrunTempFile[command_, text_, OptionsPattern[]] :=\n  Module[{stream, file, result}\n  , stream = OpenWrite[]\n  ; Export[stream, text, \"Text\"]\n  ; file = Close[stream]\n  ; OptionValue[FileExtension] /.\n      ext:Except[Automatic] :> (file = RenameFile[file, file~~\".\"~~ext])\n  ; result = Import[\n      StringReplace[command, OptionValue[FilePattern] -> file]\n    , \"Text\"\n  ; DeleteFile[file]\n  ; result\n\nError-recovery is still a bit lax in this example, but we'll ignore that and blunder on. Armed with this helper function, we can handle the Windows limitation a bit better:\n\nshellEvaluate[cmd_] /; $OperatingSystem == \"Windows\" :=\n  runTempFile[\"!_ 2>&1\", \"@echo off\\n\"~~cmd, FileExtension -> \"cmd\"]\n\nshellEvaluate[cmd_] :=\n  Import[\"!\"~~cmd~~\" 2>&1\", \"Text\"]\n\nshellCell[] := EvaluatableCell[\"Shell\", shellEvaluate[#]&]\n\nNote that we are now merging the standard output and standard error streams. Let's use shellCell:\n\n\n\nSo we have met our stated goal of being able to execute shell commands from within Mathematica. But why stop there? All the arguments for being able to intersperse shell commands into our notebooks apply to any other language we use. Maybe we have Haskell installed on our machine:\n\nhaskellEvaluate[source_] := runTempFile[\"!runhaskell _ 2>&1\", source]\n\nhaskellCell[] :=\n  EvaluatableCell[\"Haskell\", haskellEvaluate[#]&]\n\n\n\n\nMathematica's built-in Java also opens up some interesting possibilities. The included Rhino Javascript interpreter, for example:\n\n\nevaluateRhino[script_String] :=\n  JavaBlock @ Module[{engine}\n  , engine = JavaNew[\"javax.script.ScriptEngineManager\"]@getEngineByName[\"JavaScript\"]\n  ; engine@eval[script]\n\nrhinoCell[] :=\n  evaluatableCell[\"Rhino\", evaluateRhino[#]&]\n\nLike this:\n\n\n\nI could go on with more examples, but I think the point is made.\n\nFor an example of a user-defined input cell type that remembers state between evaluations, see this question.\n\nOnce again, I'll point out that the error-handling presented here is weak. I omitted it in order to keep this posting to a manageable size and to avoid drowning out the key ideas with boilerplate code.\n\nshare|improve this answer\nWhy do you use ~~ in evaluatableCell[\"shell\", Import[\"!\" ~~ #, \"Text\"] &] opposed to evaluatableCell[\"shell\", Import[\"!\" <> #, \"Text\"] &] ? Is this simply a style question or is their a another reason? \u2013\u00a0 William Jan 31 '13 at 1:03\n@Lime There is no deep reason for my choice... until you mentioned it I hadn't really noticed that I had switched my common usage from <> to ~~. \u2013\u00a0 WReach Jan 31 '13 at 1:17\nSomehow I missed this version of your answer. Big +1. \u2013\u00a0 Leonid Shifrin Jul 25 '13 at 14:53\nYes, I also only saw the previous version :). \u2013\u00a0 Jacob Akkerboom Jul 25 '13 at 15:03\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247855/strictly-convex-inequality-in-lp\nText:\nSign up \u00d7\n\nLet $1<p<\\infty$. Let $x,y\\in l^p$ such that $||x||_p=1$, $||y||_p=1$ and $x\\neq y$. Would you help me to show that for any $0<t<1$, $||tx+(1-t)y||_p<1$.\n\nMy answer : By using Minkowski inequality, we get $||tx+(1-t)y||_p\\leq t||x||_p+(1-t)||y||_p=t+(1-t)=1$. But I don't get the strict inequality.\n\nBut, For $p=2$: \\begin{eqnarray} ||tx+(1-t)y||_2^2&=&t^2||x||_2^2+(1-t)^2||y||_2^2+2t(1-t)\\Re(<x,y>)\\\\&=&1+2t(1-t)(\\Re(<x,y>)-1)) \\end{eqnarray}\n\nSince $x\\neq y$ and $||x||_2=||y||_2$, we conclude that $x\\neq ky$ for every scalar hence we get $\\Re(<x,y>)\\leq|<x,y>|<||x||_2||y||_2=1$. So, $||tx+(1-t)y||_2<1$.\n\nThanks everyone.\n\nshare|cite|improve this question\n\n1 Answer 1\n\nFor $1 < p < \\infty$, Minkowski's inequality is an equality if and only if one of the vectors is a multiple of the other by a nonnegative scalar.\n\nshare|cite|improve this answer\nIf the vectors is multiple of the other by scalar implies the equality is trivial. How about the converse? \u2013\u00a0 beginner Nov 30 '12 at 6:43\nYou can go back over the proof of Minkowski's inequality, and H\u00f6lder's which is usually used in that proof. At some point you may use something like the fact that the minimum of the function $f(x) = x^p/p - x$ for $x \\ge 0$ is at $x=1$. Now note that this is a unique minimum ($f$ is strictly convex)... \u2013\u00a0 Robert Israel Nov 30 '12 at 8:20\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53189.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nCombining Positive and Negative Exponents\n\nDate: 06/30/99 at 12:33:38\nFrom: Lauren Fortner\nSubject: Algebra: using the power theorem\n\nI understand how to get problems from \"beginning\" form, for example:\n\n     x (x^-3)^2 y (xy^-2)^-3\n      (y^2)^3 y^-3 (x^2)^3\n\nto \"after\" you use power theorem:\n\n     x x^-6 y x^-3 y^6\n       y^6 y^-3 x^6\n\nand then when you simplify the numerator and denominator:\n\n     x^-8 y^7\n     y^3 x^6\n\nWhat I don't understand is how you get from that to writing all \nexponential expressions with positive exponents, or negative \nexponents, or with both. I homeschool, so I don't really have anyone \nto ask.\n\nThank you for your help.\n\nDate: 07/01/99 at 17:00:53\nFrom: Doctor Peterson\nSubject: Re: Algebra: using the power theorem\n\nHi, Lauren. Thanks for a well-written question - it really helps to \nknow just what part you have trouble with.\n\nThe key to this step is that\n\n     x^-a    1           1     x^a\n     ---- = ---   and   ---- = ---\n      1     x^a         x^-a    1\n\nThat's essentially just the definition of negative exponents, and I'll \nassume you're at least aware of this as a fact. What you need is how \nto apply it.\n\nWhat these facts mean in practice is that you can move a factor from \ntop to bottom or from bottom to top and negate the exponent. Once you \nget used to it, you just think \"There's an x^-8 in the numerator, so I \ncan replace that with an x^8 in the denominator.\" To take it more \nslowly, we can pull the expression apart, apply the rule, and put it \nback together:\n\n     x^-8 y^7   x^-8   y^7    1     1     1    y^7    1     1\n     -------- = ---- * --- * --- * --- = --- * --- * --- * ---\n     y^3 x^6      1     1    y^3   x^6   x^8    1    y^3   x^6\n\n              = -----------\n                x^8 y^3 x^6\n\nThat makes all the exponents positive, but there's still another step \nyou didn't mention: combining like factors so that x and y each appear \nonly once. That's easy in the denominator now; we can just permute so \nthe x's are together and add the exponents:\n\n         y^7         y^7\n     x^8 y^3 x^6   x^14 y^3\n\nBut you still have y in two places. We can use the same rule to get \nthe y's together; since 7 > 3, let's move the y^3 to the top to keep \nthe exponents positive:\n\n       y^7      y^7    1      1    y^7    1     y^-3   y^7 y^-3   y^4\n     -------- = --- * ---- * --- = --- * ---- * ---- = -------- = ----\n     x^14 y^3    1    x^14   y^3    1    x^14     1      x^14     x^14\n\nNow we're really done.\n\nBut we've taken a lot more steps than we had to. That's fine when \nyou're starting out; this isn't a race. But here's how I'd do it \n\n     x(x^-3)^2y(xy^-2)^-3   x x^-6 y x^-3 y^6\n     (y^2)^3y^-3(x^2)^3     y^6 y^-3 x^6\n\n                          = x x^-6 y x^-3 y^6 * y^-6 y^3 x^-6\n\n                            (Here I've moved everything to the top.)\n\n                          = x x^-6 x^-3 x^-6 * y y^6 y^-6 y^3\n\n                            (Here I've gathered the x's and y's \n                             together; I'd probably mark each factor \n                             as I copied it to make sure I didn't miss \n\n                          = x^(1-6-3-6) y^(1+6-6+3)\n\n                          = x^-14 y^4\n\n                          = ----\n\nIf you're at all afraid of negative exponents, this will make you \ndizzy, but if you like to take the bull by the horns and get it over \nwith, making the negative exponents work for you, this is the way to \ndo it. Basically, I decided I'd rather deal with positive and negative \nexponents than with numerators and denominators; they're really two \nways to say the same thing, and mixing them doesn't make sense. So \neven though the goal is to have numerator and denominator and \neliminate negative exponents, I found that it's really easier to work \nwith the negatives, then change them to denominators when I'm done.\n\nIf any of this overwhelmed you, or if you have more questions, feel \nfree to write back.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nHigh School Basic Algebra\nHigh School Exponents\nMiddle School Algebra\nMiddle School Exponents\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166010/messenger-riddle?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nA column of troops one km long is moving along a straight road at a uniform pace. A messenger is sent from the head of the column, delivers a message at the rear of the column and returns. He also moves at a uniform pace and arrives back at the head of the column when it has just covered its own length. How far did the messenger travel?\n\nI can't get any ideas on how to start.\n\nThanks for any help.\n\nshare|improve this question\nHow far did the messenger travel means the distance traveled or the displacement? If its displacement then the answer should be 1km. \u2013\u00a0 Saurabh Jul 3 '12 at 6:10\nIt means distance. \u2013\u00a0 Matt Jul 3 '12 at 6:12\nYou just need to organise the information carefully and use distance = speed x time. Write down what you know about the movement of the column - say speed $u$ and the messenger say speed $v$ taking total time $t$. Split the movement of the messenger into two obvious parts. Then identify the total distance $d$ you want to find, and use the information you have to find an equation for $d$. \u2013\u00a0 Mark Bennet Jul 3 '12 at 6:19\nA trivial answer to the question would be $1$km, the length of the column. After all, the messenger starts out at the head of the column, and ends up again at the end of the column, at the point in time when it has covered its own length, and she then has advanced as much as the column has. This is probably not what the question intends, but it could be made clearer. \u2013\u00a0 Marc van Leeuwen Jul 3 '12 at 6:50\nadd comment\n\n3 Answers\n\nup vote 7 down vote accepted\n\nLet us assume that the speed of the column is $1$ km per unit of time. For convenience, call that unit an hour. The column took $1$ hour to cover its own length.\n\nLet $v$ be the speed of the messenger. When she is travelling to the back, the combined speed of approach of the messenger and the column rear is $v+1$, so the time it takes is $\\frac{1}{v+1}$. Going the other way, the speed at which the messenger gains on the head is $v-1$, so the time it takes to gain the whole $1$ km is $\\frac{1}{v-1}$. The whole task took $1$ hour, and therefore $$\\frac{1}{v+1}+\\frac{1}{v-1}=1.$$ This gives $v=1+\\sqrt{2}$. The time taken is an hour, so the distance travelled is $1+\\sqrt{2}$.\n\nshare|improve this answer\nadd comment\n\nLet the speed of troop is $u$ kmph and that of messenger is $v$ kmph.\nSo the relative speed when messenger is going backward is $v+u$ kmph.\nAnd relative speed while going forward is $v-u$ kmph $(v>u)$.\nSo the total time taken is $$t=\\frac{1}{v+u}+\\frac{1}{v-u}$$ but in this time troop had moved $1$km so the $t=\\frac{1}{u}$\n$$\\frac{1}{u}=\\frac{1}{v+u}+\\frac{1}{v-u}$$ $$v^2-2uv-u^2=0$$ which give us the following relation $$v=u(1+\\sqrt2)$$\n\nso the distance traveled is $$\\begin{align*} d= &\\underbrace{\\frac{v}{v+u}}_{backward}+\\underbrace{\\frac{v}{v-u}}_{forward}\\\\ &=\\frac{2v^2}{v^2-u^2}\\\\ &=\\frac{2v^2}{2uv}\\\\ &=\\frac{v}{u}=1+\\sqrt{2}\\text{ km}\\end{align*}$$\n\nshare|improve this answer\nMostly ok, but why did you give the answer using units of speed? Mind you, I've never seen it abbreviated \"kmph\". At least locally \"km/h\" is the only way to write it. This is different from, e.g. U.S.A., where \"mph\" is always used. I guess there are local variations :-) \u2013\u00a0 Jyrki Lahtonen Jul 3 '12 at 7:27\n@JyrkiLahtonen Oh that was a mistake .I have corrected it.Thanks \u2013\u00a0 Saurabh Jul 3 '12 at 7:32\nadd comment\n\nLet $x$ be the troops' speed and $y$ be the messenger's speed.\n\nTotal messenger travelling time is $1/x$ (as the troops moved 1km forward).\n\nIn the troops frame of reference, the messenger first moved backwards with the speed of $y+x$, and then moved forward with the speed of $y-x$ so that in the $1/x$ total time he returned to the initial position.\n\nLet $z$ be the time messenger spent to reach the rear of the column. Obviously, $z = 1/(y+x)$ (as messenger moves with the speed of $y+x$ relative to the column and has to travel $1$ km relative to the column to reach its rear).\n\nFrom the other side, we have $z \\times (y+x) + (1/x - z) \\times (y-x) = 0$, from which follows $2zx + y/x - 1 = 2/(y/x+1) + y/x - 1 = 0$.\n\nNote that the total messenger travelling distance is $d = y/x$. From the previous equation we get $2/(d+1) + d - 1 = 0$, $d^2-3 = 0$, and thus $d = \\sqrt{3}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262615/a-logic-puzzle-from-tes-arena/262653\nText:\nTake the 2-minute tour \u00d7\n\nIts nice when games have riddles hidden in them. While playing TES:Arena, I came across an unusual logical puzzle: There are 3 cells.\n\nIf Cell 3 holds worthless brass, Cell 2 holds the gold key.\n\nIf Cell 1 holds the gold key, Cell 3 holds worthless brass.\n\nIf Cell 2 holds worthless brass, Cell 1 holds the gold key.\n\nKnowing this brave fool, and knowing that all that is said cannot be true, which cell contains the gold key?\n\nThe correct answer is Cell 2 as suggested by the game. I wanted to know how one could logically arrive at the result. Could anyone help me with this?\n\nWhat I tried: I negated all the above statements. The first implication became Cell 3 holds worthless brass AND Cell 2 does not have gold key. But if this is true, then cell 2 does not have the gold key and the result is incorrect. Hence I had this doubt.\n\nPS: Choosing the wrong door causes man eating spiders to be released.\n\nshare|improve this question\nDoes each cell necessarily contain either worthless brass or a gold key? \u2013\u00a0 Sp3000 Dec 20 '12 at 12:55\nAlthough not stated in game, there is only ONE cell with a gold key. The other cells may/may not have brass. \u2013\u00a0 Gautam Shenoy Dec 20 '12 at 12:57\nadd comment\n\n4 Answers\n\nIf you label the conditions a-c, and if the gold key exists and is unique, it is enough to show that not in 2 leads to a contradiction. But 'key not in 2' leads to 'key in 2' (so a contradiction), as follows:\n\nBy (c), not in 2 implies in 1. By (b) then, not in 3. By (a) then, key is in 2. Contradiction.\n\nTo be safe, you can check if the game makers messed up:\n\nAs 'key in 1' is a sub chain of the above, it also leads to 'key in 2'. Contradiction.\n\nSimilarly, 'key in 3' means by uniqueness that 2 holds brass, which, by (c), implies 1 holds the key. Contradiction.\n\nFinally note that if the key is in 2, it doesn't lead to any contradictions. So game is correct.\n\nshare|improve this answer\nadd comment\n\nCell 2 cannot hold worthless brass, and cell 1 cannot have the gold key.\n\nIf a cell can have neither brass nor key, then that is the limit of what you can conclude. For example, your conditions are consistent with cell 3 having the key and there being nothing in the other cells.\n\nBut if every cell contains either brass or key, then you know cell 2 has the key. You can prove that by assuming cell 2 did not have the key, and hence had worthless brass. That implies that cell 1 has the key, which implies cell 3 has worthless brass which implies that cell 2 has the key. Contradiction.\n\nHowever, if that additional condition were part of the problem, then your middle condition would be redundant.\n\nshare|improve this answer\nadd comment\n\nSorry to be contrary, but I believe you need 2 assumptions for there to be a unique solution. First, that all 3 statements are indeed true. If we allow that one or more of those statements doesn't hold, the whole thing falls apart.\n\nSecond, that each cell contains either brass or the key. No empty cells. If you disagree, try looking at these 2 solutions:\n\nCell 1 = Empty, Cell 2 = Key, Cell 3 = Empty\n\nCell 1 = Empty, Cell 2 = Empty, Cell 3 = Key\n\nNone of the 3 statements apply to either of these, so they're both possible valid solutions and you're left to guess and hope the spiders don't eat your face.\n\nNow, you can brute force your way through by listing all possible solutions and checking which are valid under the given statements. In this case there aren't many possible choices, so that approach is not too bad. However, I'm assuming you're looking for a bit deeper insight, so I'll walk through a technique that can sometimes provide a quicker route to the answer, especially in more complex puzzles.\n\nSince all the implications are one way (they are \"if\", not \"if and only if\"), one approach is to start by assuming a condition from the left side of a statement and trace the implications through all the statements to look for inconsistencies.\n\nJust going in order, let's assume first that Cell 3 holds brass. Then by statement 1, Cell 2 holds the key. Since we're assuming key or brass in each and only one key, then Cell 1 would have to be brass. Given that, neither of the last 2 statements apply, so this solution is possible with no contradictions. Let's continue and check the others to be sure we have the only possible valid solution.\n\nLooking at statement 2, let's assume now that Cell 1 holds the key. By statement 2, Cell 3 holds brass. By statement 1, Cell 2 holds the key. Since only 1 cell can hold the key, this is a contradiction. Therefore our original assumption is false, so Cell 1 does not hold the key.\n\nLastly, look at the third statement. If we assume Cell 2 holds brass, then Cell 1 holds the key. But we already know by our last reasoning that if Cell 1 holds the key we end up with a contradiction. So our assumption here is false, and Cell 2 does not hold brass.\n\nSince Cell 2 cannot hold brass, it must hold the key.\n\nshare|improve this answer\nadd comment\n\nIf you take \"not all that is said is true\" to mean that at least one statement is false, you can go through negating them and see where it leads. If the first statement is false, you have 3 holds brass and 2 does not hold the gold key. Given that there is a gold key, it must be behind door 1. Then the second and third statements would be true, but we still don't know whether cell 2 holds brass.\n\nIf the second statement is false, cell 1 has gold and 3 does not have brass (so is empty). The first and third sentences are then true and we again know nothing about cell 2.\n\nIf the third statement is false, 2 holds brass and 1 does not have gold, so it must be cell 3 that has gold. The other two are then true and we don't know what 1 holds.\n\nSince we didn't reach a contradiction from any of these, we can't choose between them. I would downvote the puzzle creator. However, if you ignore the \"not all that is said is true\" and believe them all, gnometorule has shown how to get there.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/9558/the-shortest-path-in-first-passage-percolation\nText:\nTake the 2-minute tour \u00d7\n\nConsider a square planar grid. (The vertices are pair of points in the plane with integer coordinates and two vertices are adjacent if they agree in one coordinate and differ by one in the other.)\n\nGive every edge a length one with probability a half and length two with probability a half.\n\nConsider a shortest path between the origin and the vertex $(n,0)$.\n\nShow that with probability that tends to one as $n$ tends to infinity the shortest path will not contain the \"middle edge\" on the x-axis inbetween the orgin and $(n,0)$. (Namely, the edge between the vertices $(\\lfloor\\frac{n}{2}\\rfloor,0)$ and $(\\lfloor\\frac{n}{2}\\rfloor+1,0)$.)\n\nThis question is in the category of \"a missing lemma\". It is not really a full fledged open problem but rather a statement which looks correct that was needed in some paper and resisted proof. Of course, some such \"lemmas\" turn out to be very difficult, but sometimes maybe a simple argument was simply missed. The relevant paper is with Itai Benjamini and Oded Schramm: First Passage Percolation Has Sublinear Distance Variance\n\nWhile MO have chosen to accept one answer, and there were some nice suggestions, the problem is still wide open.\n\nshare|improve this question\nThanks Alon, I myself cannot see the latex (it leaves the formulas uncompiled) so I prefer the plain text. \u2013\u00a0 Gil Kalai Dec 23 '09 at 10:34\nNitpicking: is it \"a shortest path\" or \"the shortest path\"? Do you want to show there is a shortest path avoiding the given edge, or that all shortest paths avoid the given edge. \u2013\u00a0 Boris Bukh Dec 23 '09 at 11:26\nThat's really a shame, Gil. Have you tried installing jsMath along with the fonts? It's not supposed to be necessary but perhaps it'll help. \u2013\u00a0 Alon Amit Dec 23 '09 at 18:00\nBoris, I suppose I just want to show that there is a shortest path avoiding this middle edge. Alon, jsMath? where \u2013\u00a0 Gil Kalai Dec 23 '09 at 18:50\nBoris: That's not nitpicky, it's actually an important point. If the distribution of passage times is continuous, then with probability one, there is a unique minimizing path between any two points. Here, since the distribution has atoms, with positive probability, there are multiple shortest paths. \u2013\u00a0 Tom LaGatta Dec 26 '09 at 2:02\nshow 1 more comment\n\n7 Answers\n\nGil: This is a type of problem that I know little about so here I am thinking out loud about problems that seem natural to ask about this situation. It is hard to believe that people have not already thought about these questions and perhaps answered them. Where would I look to find out more?\n\nYou write you are interested in a \"square planar grid.\" So I took this to mean that you were thinking about the points of a \"square grid graph\" with lx1 squares as the cells that goes from (0,0) to (n,n) and where weights were going to be assigned to the edges of size 1 or 2.\n\nThe paths that you are talking about need not be constrained to move up and to the right but it might be interesting to contrast the behavior of general shortest paths with those that move up and to the right. It would also seem to be of interest to see what happens if one selects half of the edges at random and makes them all length 1 edges and makes all the others of length 2. Since there are 4n edges this means 2n are 1's and 2n are 2's. Furthermore, If we insist that paths move up and to the right, such paths all have length 2n, so \"very shortest\" paths would consist only on 1's.\n\nIn both settings:\n\na. What is the probability there is a shortest path to (n,n) consisting of all 1's?\n\nb. What can be said about the expected value of the length of a shortest path to (n, n)? What can be said about the expected number of paths of this value?\n\nc. When one insists that each of the two lengths appear equally often how many different ways can this happen? (One can also ask how many of these are different up to symmetry of the \"colored\" graph, treating the lengths as two colors.) One could count in the general case too but the up and to the right case seems more interesting here.\n\nshare|improve this answer\nTo whomever gave this post a negative vote: Shame on you. This post does not answer the question Gil asked, but so what? It is exploratory and raises some interesting ideas; perhaps one of those could lead to a correct answer. Posts like this are exactly what MathOverflow needs. \u2013\u00a0 Tom LaGatta Dec 26 '09 at 1:57\nJoe, it is a very good idea to consider paths from (0,0) to (n,n) and to consider also the case where you only go north and east. This restricted model is called \"directed percolation\". As far as I know the lemma is not known for directed percolation. There is one version where the distribution of edge length is exponential and you want the path of MAXIMUM length where this model is understood very well and is strongly connected to maximum eigenvalues of random symmetric matrices, largest monotone subsequences etc. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:27\nIt may be possible that for this version (directed percolation; exponential lengths, maximum path), the detailed understanding of the model may lead to a proof of the lemma; but I am not sure even about it. (There are hopes, but no proofs for universality: that various models will behave in some sense the same way.) Strangely, I dont know the answer for a) off-hand. Nice question. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:34\n@Tom. I think you are wrong --- if someone read it and find it not helpful then it is right thing to vote down. (BTW, it was not me) \u2013\u00a0 Anton Petrunin Jan 27 '10 at 19:37\nadd comment\n\nGil, as you said, this is one of those typical FPP problems which seems obvious but is hard to prove. What have you tried already? It'd be helpful to know of some na\u00efve attempts which didn't work.\n\nHere are my thoughts:\n\nClaim: There exists non-random $\\lambda$ such that, with probability one, for large n, all shortest paths between $0$ and $(n,0)$ meet $\\lambda n + o(n)$ edges. (this is a LLN-type theorem so it shouldn't be hard to prove; e.g., via energy-entropy methods, since your passage time distributions are bounded)\n\nThus one can consider the probability space $\\Omega_n$ consisting of all paths between $0$ and $(n,0)$ which meet $\\lambda n + o(n)$ edges. A shortest path is a random variable $X_n$ on this space with a certain probability distribution.\n\nClaim: There exists $\\sigma$ such that $|\\Omega_n| \\approx \\sigma^n$. (should be easy: $\\log|\\Omega_n|$ is probably subadditive)\n\nLet $\\Omega_n'$ be the subspace of paths which meet the middle edge, so that $|\\Omega_n'| \\approx \\sigma^{n/2} + \\sigma^{n/2}$.\n\nSuppose that there exists $p > 0$ such that the shortest path between $0$ and $(n,0)$ meets the middle edge with probability at least $p$. (*)\n\nHere is the part which I'm struggling to quantify. Intuitively, the distribution of $X_n$ should be smeared smoothly over $\\Omega_n$. Certainly the mean is a horizontal line segment, but even paths which veer quite far away aren't unreasonable. However, if (*) holds, with probability at least $p$, $X_n$ concentrates on the much smaller subspace $\\Omega_n'$. This seems wrong.\n\nPerhaps all I've done is to translate one \"obvious\" statement into another. Hopefully this helps a bit. Good luck!\n\nshare|improve this answer\nTom, Interseting suggestion. I dont remember so much what we tried. At the end we managed to go around this lemma. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:38\nadd comment\n\nGil, thanks for bumping this post. I think I've got a new idea for you, but it's not a proof yet. Let $\\gamma_n$ be a minimizing geodesic between $(-n,0)$ and $(n,0)$, and let $\\gamma^{\\pm}_n$ be a minimizing geodesic betwen $(\\pm n, 0)$ and the origin.\n\nDenote by $d(\\gamma_n)$ the maximal Euclidean distance from the geodesic $\\gamma_n$ to the straight line path between $(-n,0)$ and $(n,0)$, and define $d(\\gamma^\\pm_n)$ similarly for $\\gamma^\\pm_n$. By the definition of the transversal fluctuation exponent $\\xi$, $d(\\gamma^\\pm_n)$ scales like $n^\\xi$ and $d(\\gamma_n)$ scales like $(2n)^\\xi$.\n\nSince $\\tfrac 1 2$ is less than the critical probability for oriented bond percolation in two dimensions $\\approx .633$, a theorem of Licea-Newman-Piza applies and there is a rigorous lower bound $$\\xi \\ge 1/3$$ for your model. (cf. Theorem 4.3 in Howard - Models of First-Passage Percolation)\n\nSuppose that $\\gamma_n = \\gamma^-_n \\cup \\gamma^+_n$ (i.e. the geodesic $\\gamma_n$ meets the origin), so that $$2^\\xi n^\\xi \\approx d(\\gamma_n) = \\max\\{d(\\gamma^-_n), d(\\gamma^+_n)\\} \\approx n^\\xi, $$ which suggests a contradiction since $2^\\xi > 1$ by the lower bound $\\xi \\ge 1/3$.\n\nHere's why it doesn't work. The exponent $\\xi$ is precisely defined as the minimal power of $n$ such that the following hold: $$\\lim_{n\\to\\infty} \\mathbb P\\left[d(\\gamma^\\pm_n) \\le n^\\xi \\right] = 1 \\qquad \\mathrm{and} \\qquad \\lim_{n\\to\\infty} \\mathbb P\\left[d(\\gamma_n) \\le (2n)^\\xi \\right] = 1.$$ Since the $\\approx$ signs above are really inequalities, there is no contradiction above.\n\nshare|improve this answer\nThat's very interesting. I did not know that there is a (provable) lower bound for xsi and this certainly looks very relevant. (In fact stronger than my question...) \u2013\u00a0 Gil Kalai Apr 28 '10 at 6:08\nadd comment\n\nHere is a sketch of a germ of an idea that might work. But don't take it too seriously.\n\nConsider the space $E_k$ of grid paths from $(0,0)$ to $(2k+1,0)$ with nonnegative $x_2$-coordinate and Euclidean length $2k+3$. Associate such paths with functions in the obvious way. Now there are $\\binom{2k+2}{2}$ such paths, $2\\binom{k+1}{2}$ (i.e., proportionally just less than one half) of which contain the middle edge. Now there exists an assignment of edge lengths and corresponding coefficients $\\{a_j\\}_{j=1}^k \\in \\{0,1\\}^k$ s.t. the sum $\\gamma = \\sum_{j=1}^k a_j \\gamma_j$ is a shortest path (provided we require a nonnegative $x_2$-coordinate).\n\nIf the $a_j$ and $\\gamma_j$ are selected uniformly at random, then the probability that the middle edge will be contained in $\\gamma$ is asymptotically $2^{-k/2}$.\n\nshare|improve this answer\nadd comment\n\nTalking about naive attempts, I thought maybe a simple solution along these lines could be found, but I couldn't:\n\nI denote by $p_k(n,2r)$ the probability that a shortest path from the origin to $(n,2r)$ contains the segment $(\\lfloor \\frac{n}{2}\\rfloor,k)$ to $(\\lfloor \\frac{n}{2}\\rfloor +1,k)$. A simple observation is that $p_k(n,2k)=p_k(n,0)$ (consider reflecting the path on the line $y=k$ in the region $x > \\lfloor \\frac{n}{2}\\rfloor$). The idea is to show that $p_k(n,2k)$ is close to $p_0(n,0)$ for small $k$. One can do this maybe by considering a new rectangular grid spanned by $(1,\\frac{2k}{n})$ and $(-\\frac{2k}{n},1)$ (with suitable edge weight distribution) and trying to find the new $p_0'(n,0)$ which should be a good approximation of $p_k(n,2k)$.\n\nNow if one can find a slowly decreasing function $f$ so that $p_k(n,2k)\\approx f(p_0(n,0))$ in the range, say $|k|\\le \\sqrt{n}$ then $$1=\\sum_{k=-\\infty}^{\\infty}p_k(n,0)=\\sum_{k=-\\infty}^{\\infty}p_k(n,2k)\\approx \\int_{-\\sqrt{n}}^{\\sqrt{n}}f(p)dp \\geq c\\sqrt{n}p_0(n,0)$$ for some constant $c$. If $\\lim_{n\\to \\infty}p_0(n,0)>0$ then the above inequality is obviously false for large enough $n$.\n\nETA: I realize this approach works if we were able to prove $$\\liminf_{n\\to \\infty} p_{0}(n,0)=\\liminf_{n\\to \\infty} p_k(n,0)$$ for any fixed $k$.\n\nshare|improve this answer\nadd comment\n\nUPDATE: Fixed typing error in 2nd paragraph (greater than -> less than or equal to)\n\nUPDATE2: Fixed typing errors pointed out by Gil Kalai\n\nUPDATE3: I put off the detailed version from my webpage\n\nUPDATE4: The solution is wrong, as pointed out to me by Nathana\u00ebl Berestycki. It is of course not enough to consider only the path that goes directly from the origin to (n,0). I didn't read the problem properly. Sorry.\n\nI don't know whether this problem is still open, but I think I have found an elementary proof for the original question. It is almost too simple to be true, but I don't see any mistake. Here's the sketch:\n\nAll numbers here are natural numbers between $0$ and $n$, and $n$ is sufficiently large. Fix a (large) $K$. Let $x_l$ be the smallest $x < n/3$, such that for all $1\\le j \\le K$, the length of the path $(x,0)\\rightarrow (x,j) \\rightarrow (x+K,j)$ is less than or equal to the length of the path $(x,0)\\rightarrow (x+K,0)$. The arrow indicates that we take the direct path. For definiteness, set $x_l = \\lfloor n/3 \\rfloor + 1$ if such a number does not exist, but note that it exists with probability going to one as $n\\rightarrow \\infty$. Note further that since we took the smallest $x$ with the above property, conditioned on $x_l$, the lengths of the edges to the right of the vertical line $x=x_l+K$ are still independent, of the same law as before, and independent of the configuration to the left of this vertical line.\n\nNow define $x_r$ by mirroring the above definition at the line $x=n/2$ (the largest $x>2n/3$, such that ....)\n\nThen, the paths $(x_l+K,j)\\rightarrow(x_r-K,j)$ are independent for $0\\le j\\le K$, hence, with probability going to $K/(K+1)$, there exists $1\\le j \\le K$, such that the path $(x_l+K,j)\\rightarrow(x_r-K,j)$ is shorter than $(x_l+K,0)\\rightarrow(x_r-K,0)$.\n\nCombining the above observations, with probability $K/(K+1) + o(1)$, there exist $x_l < n/3$, $x_r>2n/3$ and $1\\le j \\le K$ such that the path $(0,0) \\rightarrow (x_l,0)\\rightarrow (x_l,j)\\rightarrow (x_r,j) \\rightarrow (x_r,0) \\rightarrow (n,0)$ is shorter than the path $(0,0) \\rightarrow (n,0)$. Letting first $n\\rightarrow \\infty$, then $K\\rightarrow\\infty$ finishes the proof.\n\nshare|improve this answer\nDear Pascal, it is a bit too sketchy for me to follow but it looks promising! (Also I supppose the vertical line is x=x_l+K). \u2013\u00a0 Gil Kalai Sep 25 '11 at 13:26\n@Gil: Thanks for having a look at the proof and pointing out the typos. I'd be glad to write down a detailed version, if the problem still interests you. \u2013\u00a0 Pascal Maillard Sep 25 '11 at 17:22\nDear Pascal, yes definitely it is an interesting problem on its own, several people tried to prove it (including us) and it has some applications regarding geodesics in the random metric described by FPP. \u2013\u00a0 Gil Kalai Sep 25 '11 at 19:51\nDear Pascal, the conjecture is from 2002 by Benjamini, Schramm and myself in the paper cited in the question itself .front.math.ucdavis.edu/0203.5262 . It is mentioned at the bottom of page 2 and the top of page 5. Actually on page 5 a slightly stronger version that we needed is mentioned and maybe your method apply there too. \u2013\u00a0 Gil Kalai Sep 26 '11 at 12:10\nOK, I'll have a look at it and see if the method can be applied to the stronger statement. \u2013\u00a0 Pascal Maillard Sep 26 '11 at 12:59\nshow 1 more comment\n\nMidway Problem (a reformulation only)\n\nThis is not an Answer. Start with a 2n x2n grid graph. all edges length one, all even pairs linked.\n\nThe \"both even\" numbered vertices are \"the original graph\". Add (x odd, y even) vertices half the time. Add (x even, y odd) vertices the time. The (odd, odd) vertices are always out. Seems a decent starting point. Point Midway is now (n+1, 0), and in the graph half of the time.\n\nThe two questions may then be:\n\nStrongest question, as n grows: Show with probability approaching one that the set of all shortest paths between (0,0) and (2n,0) almost never contains Midway.\n\nWeaker question, as n grows: Show with probability approaching one that there is a shortest path\nbetween (0,0) and (2n,0) that does not contain Midway.\n\nThey may even have different answers, unless the shortest path has \"uniqueness\" properties. So again, this is not an answer.\n\nBut, the fractions are gone, and the edge lengths are all one!\n\nApologies for the initial typo. Is this variation more accessible?\nThe Far Corner variant of Midway, with an exclusion somewhere, may be easier for purists; but again, I do not know the answer (Nor even close). Propertys of shortest path sets from (0,0) to (2n,2n) may shed light on the axial case. Some small variety of forbidden minor, behaving as Midway, may be worthy of considering. I would try constant sized cycles.\n\nshare|improve this answer\nThat's an interesting variation of the problem that might be easier. When you say add (x odd y even) hald the time do you mean with probability 1/2? I suppose also the (x even y odd) vertices are also added half the time. that's interesting. \u2013\u00a0 Gil Kalai Jan 31 '10 at 16:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/20583/how-to-simplify-frac-sqrt4h-2h\nText:\nTake the tour \u00d7\n\nThe following expression:\n\n\nshould be simplified to:\n\n\n(even if I don't agree that this second is more simple than the first).\n\nThe problem is that I have no idea of the first step to simplify that.. any help?\n\nshare|improve this question\nThe magic words are \"multiply by the conjugate\". For what it is worth, I would actually prefer the former form to the latter. I find it is easier to keep radicals out of denominators, so I would call the former the simplification, not the latter. \u2013\u00a0 Arturo Magidin Feb 5 '11 at 21:25\nI prefer the latter because the removable singularity is removed. But I also am prone to say $\\sin\\frac{\\pi}{4}=\\frac{1}{\\sqrt 2}$ rather than $\\frac{\\sqrt 2}{2}$. @Tom: An important use of such \"simplification\" is that the latter expression indicates how the original expression can be continuously extended to $h=0$. This allows you to determine that the slope of the tangent line to the curve $y=\\sqrt x$ at the point $(4,2)$ is $\\frac{1}{4}$. If you haven't already learned derivatives, these ideas are explained in the following article: en.wikipedia.org/wiki/Derivative \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:59\nadd comment\n\n4 Answers\n\nup vote 13 down vote accepted\n\nIf you multiply both the top and the bottom by $\\sqrt{4+h}+2$, you get $\\frac{(\\sqrt{4+h}-2)(\\sqrt{4+h}+2)}{h(\\sqrt{4+h}+2)}$, which simplifies to $\\frac{h}{h(\\sqrt{4+h}+2)}$. Then, divide both by $h$ (assuming $h\\neq 0$), and you get $\\frac{1}{\\sqrt{4+h}+2}$.\n\nshare|improve this answer\nadd comment\n\nIt is really simple. Let us just do what is most intuitive, multiply numerator and denominator with what you want to have in denominator. You get: $$ \\frac{(\\sqrt{4+h} - 2)(\\sqrt{4+h} + 2)}{h(\\sqrt{4+h}+2)} $$ Then observe the numerator has a difference of squares. Multiply the numerator easily using that and then your left with $$\\frac{h}{h(\\sqrt{4+h}+2)}$$ Just assume $ h \\neq 0 $ and get \"rid\" of it.\n\nshare|improve this answer\nadd comment\n\nHINT $\\rm\\displaystyle\\quad\\quad g^2 = 4+h\\ \\ \\Rightarrow\\ \\ \\frac{g-2}h\\ =\\ \\frac{g-2}{g^2-4}\\ =\\ \\frac{1}{g+2}$\n\nUsually the \"simplification\" is the opposite inference - known as rationalizing the denominator.\n\nshare|improve this answer\nIs that step $\\frac{g-2}{g\u00b2-4}$ correct? If you multiply g+2 up and down, you get $\\frac{g\u00b2-4}{h(g+2)}$, and you can't go on from here.. \u2013\u00a0 Tom Brito Feb 20 '11 at 19:27\n@Tom: $\\rm\\ g^2 = 4 + h\\ \\Rightarrow\\ h = g^2-4\\:.\\:$ That step results from substituting this value for $\\rm\\:h\\:$ into the denominator. \u2013\u00a0 Bill Dubuque Feb 20 '11 at 19:42\nadd comment\n\nSo its not about simplification. You just want to show they are equal. What you do is put an equal sign between them, and cancel everything you can, if you get 1=1 or similar you are done.\n\nshare|improve this answer\nI have downvoted, because I think this answer is misleading. You have to be very careful when trying to prove an identity not to start with the equation you want to prove and arrive at another equation via potentially irreversible steps. It is best to work with just one side of the alleged identity at a time. \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:04\n@Jonas What is an irreversible step ? Do you not have to be equally careful when when working with one side? \u2013\u00a0 user5904 Feb 5 '11 at 21:07\nLet us prove that $-1$ can be simplified to $1$. So I'll put an equal sign between them, $-1=1$. Now if I square both sides, $1=1$. This is true, so $-1=1$. Don't get me wrong, I'm not saying that you are advocating such an illogical step, but starting by assuming (at least in appearance) what you are supposed to prove has the potential to lead to errors. \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:11\nYou have a good point about being careful with one side, but there the rule is that you never even change what the expression is. You can multiply by $1$, add $0$, factor, cancel, etc., but you typically don't do anything that actually changes the value. (Of course, this warning is only for beginners, not those who have enough experience to recognize that there are many valid ways to prove an identity.) \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:14\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164835/how-to-match-a-discrete-distribution-to-a-continuous-distribution-in-information\nText:\nTake the tour \u00d7\n\n\n$$ S \\sim N(\\mu, \\sigma^2) $$\n\nbe a normally distributed random variable with known $\\mu$ and $\\sigma^2$. Suppose, we observe\n\n$$ X = \\begin{cases} T & \\text{if $S \\ge 0$}, \\\\ -T & \\text{if $S<0$},\\end{cases} $$ where $T \\in \\mathbb{R}$. The probability distribution of $X$ is given by: $$ p(x) = Q\\left(\\frac{-\\mu}{\\sigma}\\right)\\delta(x-T)+Q\\left(\\frac{\\mu}{\\sigma}\\right)\\delta(x+T) $$\n\nI want to optimize the value of $T$ such that $X$ conveys as much information about $S$ as possible.\n\nMy Attempt:\n\na. I tried minimizing the Kullback\u2013Leibler divergence between the distribution of $X$ and $S$, but as mentioned here, it is not possible.\n\nb. I tried to calculate the mutual information between the two distributions, it turned out to be independent of $\\alpha$.\n\nIs there any other way of formulating this problem? I feel quite confident that there must be such $T$ for which $X$ explains $S$ better, e.g., assume $\\mu=10000$ then a value of $T$ near $10000$ will better explain $S$ than say $T=2$? One method in my mind was to match the moments of the two distributions but I am not sure if it is the optimal way in the sense of maximizing the information?\n\nshare|improve this question\nYou wrote \"if $s\\ge 0$\". Could you have meant \"if $S \\ge 0$\"? \u2013\u00a0 Michael Hardy Jul 1 '12 at 4:07\n@MichaelHardy I thought we could define the function with small letters as well as capital letters because small letters show the specific values of random variable. \u2013\u00a0 ubaabd Jul 1 '12 at 5:26\nOne can write things like $\\Pr(S=s)$ or $\\Pr(S\\ge s)$, but presumably your piecewise definition should be of another random variable. \u2013\u00a0 Michael Hardy Jul 1 '12 at 20:34\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\n$P(S|X)$ is the same for any value of $T$. Hence, $X$ conveys the same information about $S$, no matter the value of $T$. No matter what $T$ you chose, you are only informing with $X$ if $S \\geq 0$ or not.\n\nA way for $X$ to be more informative about $S$ is to define it as:\n\n$$ X = \\left\\{ \\begin{array}{ll} 1 & \\mbox{if $S \\geq \\mu$};\\\\ -1 & \\mbox{if $S < \\mu$}.\\end{array} \\right. $$\n\nFrom your questions, you might be interested in Rate-distortion theory.\n\nshare|improve this answer\ncan you please elaborate on what basis you mentioned $X$ is more informative about $S$ if we choose $T=1$. \u2013\u00a0 ubaabd Jun 30 '12 at 7:41\n@ubaabd, any value of $T$ is equally informative. I'm saying that $X$ is more informative because it's value depends on $S \\geq \\mu$ and not $S \\geq 0$. \u2013\u00a0 madprob Jun 30 '12 at 7:46\nOh i missed the change in 'if' conditions. Thanks \u2013\u00a0 ubaabd Jun 30 '12 at 7:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/281206/partition-minimizing-maximum-of-eulers-totient-function-across-terms\nText:\nTake the tour \u00d7\n\nGiven natural numbers $M$ and $N$, I'd like to find a partition of $2^N$ with $M$ or fewer terms, $t_1 + t_2 + ... + t_M$, such that $\\max(\\phi(t_1), \\phi(t_2), ..., \\phi(t_M))$ is minimized, where $\\phi$ is Euler's totient function.\n\nWhat might a smart algorithm for this look like? I can approach this with raw CPU power and metaheuristic search, but maybe the partition can be found analytically? I am mostly interested in $N$ = 8, 16, 32, 64, 128 in case that somehow simplifies the problem.\n\nshare|improve this question\nHere's a suggestion, I don't know how good it is. Precompute a list of \"sparsely totient numbers,\" see oeis.org/A036913. Given $N$, find the largest sparsely totient number $x$ not exceeding $2^N$, let $t_M=x$, then apply recursively to $2^N-x$ to get $t_{M-1},\\dots,t_2$, then let $t_1$ be whatever's left over. Maybe instead of largest s.t.n not exceeding $2^N$, use largest s.t.n not exceeding $2^N/M$. \u2013\u00a0 Gerry Myerson Jan 18 at 4:46\nIt maybe a great idea. I read that the ith primorial multiplied by the ith prime is sparsely totient, and used that to quickly build a list (not all sparse totients, but for rough minimization may be OK). I tried building the partition for $2^{64}$ in the style of Euclid's algorithm for GCD -- I took the biggest number in the list < $2^{64}$ and took the remainder of dividing by it, then took the biggest sparse totient in the list under the remainder and took the remainder of dividing by it, etc. etc. Turns out a linear combination of those sparse totients exactly partitioned it. Coincidence? \u2013\u00a0 Joseph Garvin Jan 22 at 15:36\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/73142/estimating-lattice-sums-of-concave-functions/73154\nText:\nTake the tour \u00d7\n\nSuppose that $f$ is a twice-differentiable concave function from $R^2$ to $R$ that's negative outside of some bounded set (e.g. $f(x,y)=1-x^2-y^2$) and let $F=$max$(f,0)$. Let $S_n$ be the Riemann sum for the integral of $F$ over $R^2$ obtained by summing the values of $F$ at all points in the lattice $(Z/n)^2$ and dividing by $n^2$. What sort of bounds can be given for the difference between $S_n$ and the integral of $F$ over $R^2$? Is it $O(1/n)$ or $O(1/n^2)$ or what? This is a more focussed version of the question error estimates for multi-dimensional Riemann sums .\n\nshare|improve this question\nOy! Mr. Propp, are you going to accept or comment at mathoverflow.net/questions/71432/\u2026? (Also, I answered your comment at (mathoverflow.net/questions/71344/\u2026) \u2013\u00a0 Ricky Demer Aug 18 '11 at 19:04\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nIt looks like the error is in $O(1/n^2)$, with a precise and optimal bound $C/n^2$ if you have a fixed bound on (1) the second derivative of the function (2) the radius of the region where it is non-negative.\n\nAs the question is stated there are two sources for the error term:\n\n  \u2022 the error in each square, centered at a point of the lattice, on which the function is strictly positive. This terms is controled by the second derivative of the function (it clearly vanishes for a linear function) at it is bounded by $O(1/n^4)$, since the number of squares is $O(n^2)$ the estimate on this whole term is $O(1/n^2)$,\n\n  \u2022 the error term in the boundary squares, those on which the function takes both a $>0$ and a zero value. On those squares the error is $O(1/n^3)$ and the number or such boundary squares is $O(n)$ so we get again a bound $O(1/n^2)$.\n\n(Note that a complete argument has to be more precise because the function $f$ could have zero derivative at the points where it vanishes, then the number of boundary squares is $O(n^2)$ but I think the result does not change).\n\nTo check that this estimate is optimal you can think of a function which is invariant under a rotation of angle $\\pi/2$ and equal to say $N-x$ on $y>0, -y+u\\leq x\\leq y-u$ for some small $u>0$. Then the first error term can be made smaller than the second, while the second \"boundary\" error term is indeed of the order of $1/n^2$ (the boundary errors all sum up).\n\nshare|improve this answer\nThe errors in each cell tend to compensate. If instead of having a compactly supported function with limited regularity, we have a functin $F$ in the Schwartz class, then the total error is $O(n^{-k})$ for every $k>0$. This is a consequence of the Poisson summation formula and the fact that the Fourier transform of $F$ is of Schwartz class too. Therefore the question is really about the effect of the limited regularity of $F$, and whether the concavity helps. \u2013\u00a0 Denis Serre Aug 18 '11 at 16:14\nI agree but as stated the main error term comes from the boundary squares. In some cases at least no compensation occurs, as in the example I tried to described, where all centers of boundary squares are at points where $f=0$ so that all those boundary terms are positive. \u2013\u00a0 Jean-Marc Schlenker Aug 18 '11 at 17:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122818/nth-root-of-a-matrix-as-an-analytic-function\nText:\nTake the tour \u00d7\n\nLet $A$ be a $k \\times k$ invertible matrix over complex numbers.\n\nIf it possible to write its nth root as an analytic function (i.e. power series in $A$)?\n\nEDIT: Complex coefficients can be functions of $A$.\n\n\nIf a matrix $A$ has only one eigenvalue $\\lambda$, then it is simple. We take\n\n$$B = \\exp\\left[\\tfrac{1}{n} \\log (A ) \\right]$$\n\nwhere we have $B^n = A$. Using Jordan decomposition, we can simplify the logarithm to a polynomial in that matrix (as $(A - \\lambda \\mathbb{I})$ is nilpotent)\n\n$$\\log(A) = \\log(\\lambda) - \\sum_{i=1}^{k} \\frac{\\left(- \\tfrac{A}{\\lambda} + \\mathbb{I}_k \\right)^{i}}{i}.$$\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nIf I am reading this correctly, you are fine with a power series whose (scalar) coefficients depend on the matrix $A$. In this case, it suffices to take a polynomial $p$ that interpolates $\\sqrt[n]{x}$, such that for each eigenvalue $\\lambda$ with multiplicity $k_\\lambda$, the first $k_\\lambda-1$ derivatives of $p$ coincide with those of $\\sqrt[n]{x}$ (Hermite interpolant). A degree-$k$ polynomial will always do the job.\n\nshare|improve this answer\nYes, I'm fine with coefficients depending on the matrix. I don't know why I overlooked this solution. \u2013\u00a0 Piotr Migdal Feb 24 at 20:19\nHowever, it is not as simple - I cannot assume that the matrix is diagonalizable; so any function which just maps eigenvalues to their roots won't work. Take as a counterexample $A = [[1, 1], [0, 1]]$ and $f(z)=z$ (sure, another polynomial works for this $A$). \u2013\u00a0 Piotr Migdal Feb 24 at 20:30\nThe multiplicity of the eigenvalue $1$ is $2$, so you need a polynomial that matches $g(z)$ and $g'(z)$ in $z=1$, where $g(x)=\\sqrt[n]{x}$. For some more detail on this approach, you can check Higham's Functions of matrices, SIAM Press 2008. \u2013\u00a0 Federico Poloni Feb 24 at 21:08\nSorry - I meant to add Chapter 1, but I pressed \"enter\" too quickly. \u2013\u00a0 Federico Poloni Feb 24 at 21:11\n@Federico So, you have my thanks in arxiv.org/abs/1305.1506. \u2013\u00a0 Piotr Migdal May 8 at 8:54\nadd comment\n\nLet $A$ be a $k\\times k$ invertible matrix, i.e. in $Gl(k)$. Assume that the segment $[I,A]$ lies in $Gl(k)$. Let us define $$ \\text{Log}A=\\int_{[1,A]} \\frac{d\\xi}{\\xi}=\\int_0^1(I-tI+tA)^{-1}(A-I)dt. $$ It makes sense since $A$ commutes with the denominator inside the integral. The assumption is satisfied in particular whenever $A$ is symmetric invertible with a nonnegative real part. Analytic continuation arguments entail $$ \\exp(\\text{Log}A)=A\\quad \\bigl(\\exp(\\frac{1}{n}\\text{Log}A)\\bigr)^n=A. $$ Looking at the Jordan canonical form of $A$, it is not difficult to see that the only thing to be avoided for the above method to work is that eigenvalues should not be negative real numbers. Let $z=a+ib$ be an eigenvalue not in $\\mathbb R_-$ in a Jordan block $J_N$ of size $N$, with 1 above the diagonal. Considering the segment $[I_N,J_N]$, we find on the diagonal $$ (1-t)+tz\\notin \\mathbb R_-\\text{ since $z\\notin \\mathbb R_-$}, $$ and above the diagonal $ (1-t)0+t=t. $ The logarithm formula above works.\n\nshare|improve this answer\nadd comment\n\nIf all eigenvalues of $A$ are in the right half plane, there is $\\alpha > 0$ such that the circle $|z - \\alpha| < \\alpha$ contains all the eigenvalues, and the principal branch of $f(z) = z^{1/n}$ is analytic in that circle. We then have a convergent binomial series $$ A^{1/n} = \\alpha^{1/n} \\sum_{k=0}^\\infty {{1/n} \\choose k} (\\alpha^{-1} A - I)^k $$\n\nshare|improve this answer\nIt was my initial thought, but in my case I cannot make such an assumption. \u2013\u00a0 Piotr Migdal Feb 25 at 0:40\nadd comment\n\nIt easy to apply a series to a diagonalizable matrix, and diagonalizable matrices are dense. This should answer your question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/125870/counting-k-cliques-not-also-k1-on-random-graphs\nText:\nTake the tour \u00d7\n\nconsider the set of graphs with $n$ vertices and exactly half of all $\\binom n 2$ possible edges.\n\nlooking for a formula that counts the number of these graphs that have a $k$-clique but not a $(k+1)$-clique.\n\nlooked at some of the Erdos-Renyi random graph theory and related formulas but did not see this case covered so far. an estimate may be ok. also if this is used in a paper somewhere, that would be useful to know.\n\nedit as Erdos-Renyi theory & a comment points out the critical point for detection of a $k$-clique is at $k=\\log(n)$ where the probability goes from $P<0.5$ to $P>0.5$. it would be very interesting if there was a formula that could be derived independent of these regions (once called \"subcritical, critical, supercritical\"), but am seeking the answer for $k \\approx \\log(n)$ in particular.\n\nbackground/motivation: question inspired by similar constructions in theoretical computer science circuit theory proofs/theorems.\n\nshare|improve this question\nAsymptotically, for fixed $k\\ge 2$, almost all $K_{k+1}$-free graphs have $K_k$. But except for $k=2$, which is obvious, I'm not even sure that has been proved. \u2013\u00a0 Brendan McKay Mar 29 at 3:36\nParallel to Brendan's comment, if $k$ is larger than order $\\log(n)$, the probability of $\\omega(G)$ being $k+1$ is vanishingly small compared to the probability of $\\omega(G)$ being $k$. I recommend looking at Chapter 7 of Random Graphs by Janson, Luczak and Rucinski. Note that since you have half the edges, looking at the size of a maximum stable set is equivalent to looking at the size of a maximum clique. You should also look at Section 1.4 if you are unfamiliar with the asymptotic equivalence of $G(n,p)$ and $G(n,m)$. \u2013\u00a0 Andrew D. King Mar 29 at 16:31\n@andrew thanks. yes from Erdos-Renyi theory, $\\log(n)$ is the so-called \"critical point\" where existence of k-cliques switches from low (P<0.5) to high (P>0.5) probability, and am looking for the answer in exactly that region where P=0.5. should have mentioned that in the question. will edit \u2013\u00a0 vzn Mar 29 at 16:58\nDo you really expect someone can tell you a formula for the number? If you want asymptotics you should ask for asymptotics. \u2013\u00a0 Douglas Zare Mar 30 at 1:31\n@douglas are you saying a closed form formula is unlikely to exist, or hard to find, etc? \u2013\u00a0 vzn Apr 12 at 18:06\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53595.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nApplied Problems in Maxima and Minima\n\nDate: 08/30/97 at 23:40:40\nFrom: Anonymous\nSubject: Applied problems in maxima and minima\n\ntangent together with the coordinate axes determine a triangle of \nminimum area.\n\nAnswer: (2 (3)^(1/2) / 3, 8 / 3)\n\nPlease show me how to get the answer.\n\nDate: 08/31/97 at 12:38:45\nFrom: Doctor Anthony\nSubject: Re: Applied problems in maxima and minima\n\nWe can simplify the working a little by considering the curve y = x^2, \nand consider the triangle of minimum area formed by a tangent to the \ncurve, the y axis, and the line y = 4.  This allows us to use very \nsimple parametric coordinates (t,t^2) to represent the curve.\n\n  dy/dx = (dy/dt)/(dx/dt) = 2t/1  =  2t\n\nThe equation of the tangent is  \n\n                    y-t^2 = 2t(x-t)\n\nThis meets the y axis where x = 0, so \n\n                    y-t^2 = -2t^2\n\n                        y = -t^2\n\nas expected this is a distance t^2 below the x axis. The vertical side \nof the required triangle will therefore be of length 4+t^2.\n\nThe tangent meets y = 4 where  4-t^2 = 2tx-2t^2\n                             4 + t^2 = 2tx\n\n                                   x = (4+t^2)/2t\n\nArea of triangle  = (1/2)(4+t^2)(4+t^2)/2t\n\n                A = (1/4t)(16 + 8t^2 + t^4)\n\n                  = (1/4)(16/t + 8t + t^3)\n\n            dA/dt = (1/4)(-16/t^2 + 8 + 3t^2)  = 0 for max or min.\n\nSo       3t^2 + 8 = 16/t^2\n\n 3t^4 + 8t^2 - 16 = 0\n\n  (3t^2-4)(t^2+4) = 0    and so  t^2 = 4/3  \n\n                                   t = 2/sqrt(3)\n\nThus the x coordinate is 2/sqrt(3).  This is the same x value as \nfor the equation y = 4 - x^2, and therefore we can substitute \nx = 2/sqrt(3) in this equation to find the y coordinate.\n\n  y = 4 - 4/3 = 8/3\n\nCoordinates of required point   [2/sqrt(3), 8/3]\n-Doctor Anthony,  The Math Forum\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38424/how-do-you-do-an-integral-involving-the-derivative-of-a-delta-function/38450\nText:\nTake the tour \u00d7\n\nI got an integral in solving Schrodinger equation with delta function potential. It looks like\n\n$$\\int \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x}$$\n\nI'm trying to solve this by splitting it into two integrals\n\n$$\\int_{-\\infty}^{x_0 - \\epsilon} \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x} + \\int_{x_0 + \\epsilon}^{\\infty} \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x}$$\n\nand then do the limit $\\epsilon\\to 0$. Could you tell me how to solve this integral please? I used Mathematica, it gave out a weird result.\n\nshare|improve this question\nAre you trying to evaluate $\\int \\left(\\frac{y(x)}{x}\\frac{d\\delta(x-x_{0})}{dx}\\right)dx$ for an arbitrary $y(x)$? I don't understand your statement about the limits, either, are you evaluating two separate integrals with limits $\\int_{-\\infty}^{x_{0}-\\epsilon}$ and $\\int_{x_{0}+\\epsilon}^{\\infty}$? \u2013\u00a0 Jerry Schirmer Sep 26 '12 at 23:16\nThanks Jerry. Yes it is. Basically it is a part of the radial part of my Schrodinger equation and y[x] is radial component and delta function is my potential function. There is a derivative of the potential function. I am trying to solve the equation for the delta function barrier about xo.Finally I can take the limit of e->0. \u2013\u00a0 nagendra Sep 26 '12 at 23:21\nI wonder if perhaps this would be better off at Mathematics? (I'll migrate it if that is the case) \u2013\u00a0 David Z Sep 26 '12 at 23:30\n@DavidZaslavsky: it is primarily a mathematics question, but of the type that physicists will care about more than mathematicians. I'll answer this soon. \u2013\u00a0 Jerry Schirmer Sep 26 '12 at 23:41\n@Jerry yes, but I still think those sorts of questions should be sent to math.SE. \u2013\u00a0 David Z Sep 27 '12 at 3:29\nadd comment\n\n4 Answers\n\nup vote 9 down vote accepted\n\nThe $\\delta$ function is not continuous, so it's a priori not differentiable. In fact, it's not even well-defined as an ordinary real-valued function, but can be made so in terms of distributions - linear maps on a space of test functions given by $f\\mapsto\\int\\delta f=f(a)$.\n\nIt's possible to sensibly define derivatives of distributions by looking at representations as limits of functions:\n\nIf $\\delta_i$ is a family of functions so that $\\lim_{i\\rightarrow\\infty}\\int\\delta_i(x) f(x)\\mathrm dx=f(a)$ for any test function $f$, then it can be considered a representation of the Dirac delta. Now, if we take the family of derivatives $\\frac{\\mathrm d}{\\mathrm dx}\\delta_i$ we arrive at $$ \\int\\left[\\frac{\\mathrm d}{\\mathrm dx}\\delta_i(x)\\right]f(x)\\mathrm dx=-\\int\\delta_i(x)\\left[\\frac{\\mathrm d}{\\mathrm dx}f(x)\\right]\\mathrm dx $$ through integration by parts and using the fact that $f$ has by definition compact support (which makes the boundary term vanish).\n\nAs the derivative is linear as well, this defines another linear map $f\\mapsto-\\int\\delta f'$ on the space of test functions, which we call the derivative of our distribution.\n\nSymbolically, $$ \\left[\\frac{\\mathrm d}{\\mathrm dx}\\delta(x-a)\\right]f(x)=-\\delta(x-a)f'(x) $$ which you can just plug in into your formula above without any need for actual computation as it holds true by definition.\n\nshare|improve this answer\nDear Christoph. Just to clarify that the derivatives is only for the DiracDelta function. What about in that case? \u2013\u00a0 nagendra Sep 27 '12 at 13:03\n@Nagendra: added some parens to clarify - I believe this is the case you're interested in \u2013\u00a0 Christoph Sep 27 '12 at 13:48\nadd comment\n\nSo, the properties of the derivative of the delta function can be shown relatively quickly though the following ansatz: Consider a function $\\delta(x)$ such that $\\delta(x) = \\frac{1}{a^{2}}(x+a)$ if $-a<x<0$ and $\\delta(x) = \\frac{1}{a^{2}}(a-x)$ if $0<x<a$, and $\\delta(x) = 0$ elsewhere. It is easy to see that $\\delta(x)$ has area 1 irrespective of the value of $a$, so we can consider $\\delta(x)$ to be the dirac delta function in the limit $a\\rightarrow0$.\n\nNow, consider the derivative of our putative delta function. It will be $\\frac{1}{a^{2}}$ for $-a<x<0$ and $-\\frac{1}{a^{2}}$ for $0<x<a$. Let's integrate a function $f(x)$ against $\\delta^{\\prime}(x)$:\n\n$\\begin{align} \\int \\delta^{\\prime}(x)f(x)dx &= \\int_{-a}^{0}\\frac{f(x)}{a^{2}}dx - \\int_{0}^{a}\\frac{f(x)}{a^{2}}dx\\\\ &=\\int_{0}^{a}\\frac{f(-x)}{a^{2}}dx-\\int_{0}^{a}\\frac{f(x)}{a^{2}}dx\\\\ \\end{align}$\n\nExtracting the $a^{2}$ out of the integral, and taking the limit $a\\rightarrow0$, we find, after applying L'Hopital's rule once, and then using the definition of the derivative:\n\n$\\int \\delta^{\\prime}(x)f(x) = -f'(0)$\n\nshare|improve this answer\nThanks Jerry. Hope it would work for the limiting point xo. Let me check it with my problem. \u2013\u00a0 nagendra Sep 27 '12 at 2:04\nadd comment\n\nThe Dirac delta function is often defined as the following distribution:\n\n$$\\int_a^b \\delta(x - x_0) F(x)\\mathrm{d}x = \\begin{cases}F(x_0), & a < x_0 < b \\\\ 0, & \\text{otherwise}\\end{cases}$$\n\nwhere $F$ is a suitable test function. Its derivative is then defined as\n\n$$\\int_a^b \\delta'(x - x_0) F(x)\\mathrm{d}x = -\\int_a^b \\delta(x - x_0) F'(x)\\mathrm{d}x$$\n\nwhich is also the result one would get from naively applying integration by parts. You can use this result directly to calculate your integral by setting $F(x) = \\frac{y(x)}{x}$ - no need to split the integral or take any limits.\n\nshare|improve this answer\nadd comment\n\nAs noted above, if $x_0$ a regular point of the integrand one calculates the value of the desired integral simply by substituting this point in the derivative with appropriate choice of sign. The interesting part is when the singularities of the integrand and the delta derivative coincide, i.e., where $x_0=0$. In order to compute the integral in this case we use the fact that $$\\delta_0'=\\lim_{\\epsilon \\to 0^+}\\frac{\\delta_\\epsilon-\\delta_{-\\epsilon}}{2 \\epsilon},$$ the limit being in the distributional sense. A back-of-an-envelope calculation suggests that this is only defined if $y(0)=0$ and that the integral is then $\\dfrac{y''(0)}2$. (Note that since the integrand is not a smooth function, the integral is not a priori defined).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/138768/does-px-1x-2-and-px-1-x-2-where-x-1-and-x-2-are-independent-and-po\nText:\nTake the tour \u00d7\n\nLet $X_1$ and $X_2$ be independent Poisson distributed random variables with parameters $\\lambda_1$ and $\\lambda_2$, respectively.\n\nLet $a = P(X_1 > X_2)$ and $b = P(X_1 = X_2)$.\n\nQuestion: regarding $(a,b)$ as data, does it uniquely determine $\\lambda_1$ and $\\lambda_2$?\n\nIdea 1: we have the expressions $a = a(\\lambda_1,\\lambda_2) = e^{-\\lambda_1-\\lambda_2} \\sum_{k=0}^\\infty \\sum_{j > k}(\\lambda_1^j\\lambda_2^k)/(j!k!)$ and $b = b(\\lambda_1,\\lambda_2) = e^{-\\lambda_1-\\lambda_2} \\sum_{j = 0}^\\infty (\\lambda_1\\lambda_2)^j/(j!)^2$, so perhaps one can use this to directly show that $a(\\lambda_1,\\lambda_2) = a(\\mu_1,\\mu_2)$ and $b(\\lambda_1,\\lambda_2) = b(\\mu_1,\\mu_2)$ implies $(\\lambda_1,\\lambda_2) = (\\mu_1,\\mu_2)$.\n\nIdea 2: the random variable $Z = X_1 - X_2$ is Skellam distributed with parameters $(\\lambda_1,\\lambda_2)$. The conditions amount to specifying the probability mass to the right of $0$ (this is $a$), and the probability mass at $0$ (this is $b$). Perhaps there is a clever way to see that this determines the distribution of $Z$.\n\nshare|improve this question\nI've previously seen the word \"intensities\" used only when speaking of a process in which one associates with each measurable subset of some space a Poisson random variable with expected value proportional to the measure of the subset, and where the Poisson random variables are independent iff the subsets are essentially disjoint. That's not a reason why the term couldn't be used in this somewhat simpler situation, but the fact that these \"intensities\" are also expected values would make it seem simpler to just call them expected values or expectations. \u2013\u00a0 Michael Hardy Aug 8 at 1:56\nI agree @MichaelHardy, have edited to simply mention \"parameters\". \u2013\u00a0 svangen Aug 8 at 7:49\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nConsider the function $F: (\\lambda_1,\\lambda_2) \\rightarrow (a,c)$, where $a = P(X_1 > X_2)$ and $c = 1 - a - b = P(X_1 < X_2)$. We claim that $F$ is invertible, considered as a map from $(0,\\infty)^2$ to the open triangular set $T = \\{(x,y) \\in \\mathbb{R}^2; x>0, y>0, x + y < 1\\}$.\n\n$F$ is injective\n\nFirst, we compute the Jacobian. \\begin{eqnarray} \\frac{da}{d\\lambda_1} &=&-a + e^{-\\lambda_1-\\lambda_2}\\sum_{k = 0}^\\infty\\sum_{j > k}\\frac{\\lambda_1^{j-1}\\lambda_2^k}{(j-1)!k!}\\\\&=&-a + e^{-\\lambda_1-\\lambda_2}\\sum_{k = 0}^\\infty\\sum_{j \\geq k}\\frac{\\lambda_1^j\\lambda_2^k}{j!k!}\\\\ &=&-P(X_1>X_2) + P(X_1\\geq X_2)\\\\ &=&P(X_1 = X_2). \\end{eqnarray} Similar calculations for the other partial derivatives gives: $$ J = \\left(\\begin{array}{cc}P(Z = 0) &-P(Z = 1)\\\\-P(Z = -1) &P(Z=0)\\end{array}\\right), $$ where $Z = X_1 - X_2$ is the Skellam distributed random variable. The probability mass function for $Z$ is given by $P(Z=k) = e^{-\\lambda_1 -\\lambda_2}(\\lambda_1/\\lambda_2)^{k/2}I_{|k|}(2\\sqrt{\\lambda_1\\lambda_2})$, where $I_{k}$ is the modified Bessel function of the first kind.\n\nNow, $J$ is a P-matrix, i.e. all its principal minors are positive. Indeed, $P(Z=0) > 0$, and the determinant $P(Z=0)^2 - P(Z=1)P(Z=-1)$ equals $e^{-2\\lambda_1 -2\\lambda_2}(I_0(2\\sqrt{\\lambda_1\\lambda_2})^2-I_1(2\\sqrt{\\lambda_1\\lambda_2})^2)$, which is positive since $I_0 > I_1$.\n\nBut now we have everything we need to apply the \"Fundamental Global Univalence Theorem (Gale-Nikaido-Inada)\" (see On Global Univalence Theorems, Lecture Notes in Mathematics Volume 977, 1983, pp 17-27), which gives us injectivity of $F$.\n\n$F$ is surjective\n\nIt is clear by construction that $F = (a,c)$ does not take values outside the closure of $T$: $a$ and $c$ are probabilities of disjoint events, so they are non-negative and sum to at most $1$. Moreover, the range of $F$ is simply connected, since $F$ is continuous and its domain is simply connected. Consider the three line segments that constitute the boundary of $T$: $R_1 = \\{(x,0); 0 < x < 1\\}$, $R_2 = \\{(0,y); 0 < y < 1\\}$, and $R_3 = \\{(x,y); x>0,y>0,x + y = 1\\}$. We are done if we can show that $F$ attains values arbitrarily close to each point in $R_1\\cup R_2\\cup R_3$, but never takes values in that set. (One should also consider the three corners, $(0,0)$, $(1,0)$ and $(1,0)$, but the arguments are similar for these cases.)\n\nConsider a point $(x,0) \\in R_1$. It is clear that this value is never attained by $F$, since $P(X_2 > X_1) = 0$ would imply either vanishing $\\lambda_2$, or infinite $\\lambda_1$. However, values arbitrarily close to $(x,0)$ are attained: choose $\\lambda_1$ such that $P(X_1 > 0) = x$. Then $F(\\lambda_1,\\lambda_2) \\rightarrow (x,0)$ as $\\lambda_2 \\rightarrow 0$. The set $R_2$ is treated similarly.\n\nFinally, consider a point $(x,y) \\in R_3$. By symmetry, we can assume that $x > y$. This point can not be in the range of $F$, since that would imply $P(X_1 = X_2) = 0$, which is impossible for finite $\\lambda_1$ and $\\lambda_2$. Now, $1 - a - c \\rightarrow 0$ when $\\lambda_2 \\leq \\lambda_1$ and $\\lambda_2\\rightarrow \\infty$, so we can choose $\\lambda_2$ sufficiently large and send $\\lambda_1$ from $\\lambda_1 = \\lambda_2$ towards infinity: $F(\\lambda_1,\\lambda_2)$ will describe a curve from a point in the epsilon ball $B_\\varepsilon(0.5,0.5)$ to a point in $B_\\varepsilon(1,0)$, always staying at most $\\varepsilon$ away from $R_3$, hence passing within $\\varepsilon$ of $(x,y)$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/54656/when-can-one-write-a-v-cdot-dv-dx\nText:\nTake the tour \u00d7\n\nReferring to unidimensional motion, it is obvious that it doesn't always make sense to write the speed as a function of position. Seems to me that this is a necessary condition to derive formulas like:\n\n$$v^2=v_0 ^2 +2\\int_{x_0}^{x}a\\cdot dx$$\n\nIn fact, in the first step of the demonstration (the one I saw, but I think that this step is crucial) it's required to write $a=dv/dt=(dv/dx)(dx/dt)$, that doesn't make sense if $v$ isn't a function of $x$.\n\nWhen can one rigorously write $v=v(x)$?\n\nshare|improve this question\nIf you have $x(t)$, you can obtain $t(x)$ and inject it in $v(t)=v(t(x))$. \u2013\u00a0 Vladimir Kalitvianski Feb 21 at 20:03\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nGenerally, the total derivative can be broken into a sum of partial derivatives. If the acceleration $a$ is taken to be a function only of $x$ and $t$, then the total derivative is \\begin{equation} a=\\frac{\\mathrm{d} v}{\\mathrm{d} t} = \\frac{\\partial v}{\\partial t} + \\frac{\\partial v}{\\partial x}\\frac{\\partial x}{\\partial t} \\end{equation}\n\nOne can safely write $\\mathbf{a}=\\mathbf{v}\\cdot\\nabla \\mathbf v$, then, when $\\partial v /\\partial t=0$. This is true when you are considering a single particle or object, as the velocity of the particle at a point where the particle doesn't exist is not changing. However, for distributions of particles, the distinction is meaningful.\n\nshare|improve this answer\nThank you, but I don't understand the explaination of why $\\dfrac {\\partial v}{\\partial t} = 0 $ . Why is $ \\partial v / \\partial t $ evaluated at a point where the particle does not exist? \u2013\u00a0 pppqqq Feb 21 at 21:01\nThis idea comes from distributions of particles, where you might ask \"what happens at this point in space?\" Particles may move in and out, so you could talk about the velocity of particles at that point in space changing without changing the point in space that you are talking about. However, when you are talking about a single object, then you are asking about the velocity of the object at the point in space where the object is. The notion only really applies if you adopt a \"lab frame\" that is stationary, with respect to which the particles can move. \u2013\u00a0 KDN Feb 22 at 0:45\nI realize I stated that badly... the notion only really applies in the lab frame if you are interested in what is at a particular point in space, rather than following individual objects through their trajectories in space. \u2013\u00a0 KDN Feb 22 at 2:19\nUnfortunately I haven't got enough mathematical notions to fully understand the matter , however writing down the partial derivative of the function $v$ (seen as a function of \"points of my lab frame at a precise instant\") I have an intuition about what you mean by $\\partial v / \\partial t = 0 $ if we have just one particle. In fact (if the particle is not still, after the little $\\partial t $ time there is no more particle in that point in space and so no speed. Sorry if i'm simplifying too much. However thank you for the answer, that makes a lot of sense out of that. \u2013\u00a0 pppqqq Feb 22 at 10:29\nNope, that's about the gist of it. \u2013\u00a0 KDN Feb 22 at 14:09\nadd comment\n\nIt can be done in any case where the velocity can be written as a function of the position. This can be done if the velocity is not constant, and if there are no turnaround points in the motion. For instance, consider $x = r\\sin(\\omega t)$, $v = \\omega r \\cos(\\omega t)$.\n\nThen, we have:\n\n$$\\begin{align} x &= r \\sin(\\omega t)\\\\ t &= \\frac{1}{\\omega}\\sin^{-1}(x/r)\\\\ v &= \\omega r \\cos (sin^{-1}(x/r))\\\\ &= \\omega \\sqrt{r^{2} - x^{2}} \\end{align}$$\n\nWhich is a valid transformation so long as $\\sin^{-1}(x/r)$ is defined, which means that you only cover the right half of the unit circle.\n\nshare|improve this answer\nadd comment\n\nThis is going to be essentially the same in content as Jerry Schirmer's response, but I thought you might like to hear it in more mathematical terms. The velocity function $v$ is defined as $$ v(t) = \\dot{ x}(t) $$ Let's take the domain of the position function to be the open interval $(t_1, t_2)$ and suppose that it has the property that given any point $x_0$ in the range of $x$, there is a unique point $t_0$ in its domain $(t_1, t_2)$ such that $x(t_0) = x_0$. Then there exists a function $x^{-1}$ (the inverse of $x$) defined on the range of $x$ satisfying $$ x^{-1}(x(t)) = t $$ Now we define a function $\\bar v$ on the range of $x$ by $$ \\bar v(x) = v(x^{-1}(x)) $$ It is common to abuse notation here and use $v$ in place of $\\bar v$ for this function, but let's keep things notationaly rigorous. Then on one hand the chain rule gives $$ \\frac{d}{dt}\\bar v(x(t)) = \\frac{d\\bar v}{dx}(x(t))\\,\\dot x(t) = \\frac{d\\bar v}{dx}(x(t))\\,v(t) $$ While on the other hand we use the definition of $\\bar v$ to write $$ \\frac{d}{dt}\\bar v(x(t)) = \\frac{d}{dt} v(x^{-1}(x(t))) = \\frac{dv}{dt}(t) = a(t) $$ and combining these observations gives the identity you wanted $$ a(t) = \\frac{d\\bar v}{dx}(x(t))\\,v(t) $$ Notice that if we indulge in the usual abuse of notation, then we can simply write this as $$ a = v \\frac{dv}{dx} $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/49963/su3-gauge-invariance-in-qcd/49972\nText:\nTake the tour \u00d7\n\nIn QCD, the gauge-invariant lagrangian under the trasformation\n\n$ \\psi \\to \\psi' = e^{ig T^a \\theta^a(x)} \\psi$\n\nis written as:\n\n$\\mathcal{L} = \\bar{\\psi}(i\\gamma^\\mu D_\\mu - m)\\psi - \\frac{1}{4}G^a_{\\mu\\nu}G_a^{\\mu\\nu}$\n\nwhere the covariant derivative is:\n\n$D_\\mu = \\partial_\\mu - ig T^a G^a_\\mu$\n\nand the field strength tensor is defined as:\n\n$ G^a_{\\mu\\nu} = \\partial_\\mu G^a_\\nu - \\partial_\\nu G^a_\\mu + g f_{abc} G^b_\\mu G^c_\\nu $\n\nIf I impose the gauge-invariance, I find that the gauge field transforms as:\n\n$ G^a_\\mu \\to G'^a_\\mu = G^a_\\mu + \\partial_\\mu \\theta^a $\n\nAm I correct? I think I am, but if I look at how the field strength transforms, I expect it to remain invariant, but instead I find an extra term:\n\n$ G^a_{\\mu\\nu} \\to G^a_{\\mu\\nu} + g_s f_{abc}(\\partial_\\mu \\theta^b \\partial_\\nu \\theta^c + \\partial_\\mu \\theta^b G^c_\\nu + \\partial_\\nu \\theta^c G^b_\\mu) $\n\nDoes this term vanish? Why? Or am I totally wrong on the transformation of the gauge field...?\n\nshare|improve this question\nFor nonabelian gauge fields the gauge field should transform as $A^a_\\mu \\rightarrow A^a_\\mu + (D_\\mu \\theta)^a$. \u2013\u00a0 DJBunk Jan 12 at 0:39\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe Gauge field transforms as $$ G_{\\mu}^{i}\\frac{\\lambda^{i}}{2} \\rightarrow G_{\\mu}' = uG_{\\mu}u^{-1}+\\frac{i}{g}u\\partial_{\\mu}u^{-1} $$ with $u \\in SU(3)$ such that $$ u^{-1}(x)=\\exp (-i\\alpha^i \\lambda^i /2) $$ this can be expanded in a series for infinitesimal transformations.\n\n\nexpanding $u^{-1}$ $$ u^{-1} \\approx 1 -i\\alpha^i \\lambda^i/2 + \\mathcal{O}(\\alpha^2) $$ you can preform this expansion for both $u$ and it's inverse to first order and make sure to keep everything to first order in $\\alpha$, it will include a commutator.\n\nshare|improve this answer\nCan you elaborate the expansion? Is the usual expression for the derivative of an exponential not valid for matrix exponentials? \u2013\u00a0 Ganondolf Jan 11 at 22:32\n@Ganondolf see the update. \u2013\u00a0 k\u03b7ives Jan 11 at 23:18\nUhm, I think I sorted out... Most probably I missed a commutator in the interaction term, which accounts for an extra term in the transformation of G. More important, as you suggested I should keep everything to first order, that should be the way to transform correctly the field strength tensor. I still don't know how exactly, but now I should be on the right way... Dropping the problem now for lack of time, but at least I saw the light at the end of the tunnel. Thank you. \u2013\u00a0 Ganondolf Jan 12 at 0:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/37877/finding-psix-t-for-a-free-particle-starting-from-a-gaussian-wave-profile?answertab=active\nText:\nTake the tour \u00d7\n\nConsider a free-particle with a Gaussian wavefunction,\n\n$$\\psi(x)~=~\\left(\\frac{a}{\\pi}\\right)^{1/4}e^{-\\frac12a x^2},$$ find $\\psi(x,t)$.\n\nThe wavefunction is already normalized, so the next thing to find is coefficient expansion function ($\\theta(k)$), where:\n\n$$\\theta(k)=\\int_{-\\infty}^{\\infty} \\psi(x)e^{-ikx} \\,dx.$$ But this equation seems to be impossible to solve without error function (as maple 16 tells me).\n\nIs there any trick to solve this?\n\nshare|improve this question\nI am a bit confused, why are you trying to find $\\psi (k)$ ? Or as you write it, $\\theta (k)$ ? \u2013\u00a0 DJBunk Sep 20 '12 at 23:06\nCan you put what you ran through maple 16? \u2013\u00a0 Magpie Apr 8 at 1:38\nadd comment\n\n1 Answer\n\nYour question seems rather confused,\n\n  \u2022 First you ask for the time evolution of the wavefunction. For this you will need to use the Schr\u00f6dinger equation $i \\partial \\psi/\\partial t= \\hat H \\psi $ and thus will need to know the Hamiltonian ($\\hat H$).\n  \u2022 Second you seem to want to work out the Fourier transform of the wavefunction. This will not give you the wavefunction as a function of time but will give you the wavefunction in momentum space. The integral you want to calculate is the Fourier transform of a Gaussian which is itself a Gaussian: $$\\int_{-\\infty}^{\\infty} e^{-ax^2/2}e^{-i k x} \\, dx \\\\ = \\int_{-\\infty}^{\\infty} e^{-ax^2/2}\\left(\\cos{kx} - i \\sin{kx} \\right) \\, dx .$$ The second term in the above integral is odd so will give zero. The first term is a known integral and gives $$=\\sqrt{\\frac{2\\pi}{a}} e^{-k^2/2 a} , $$ a Gaussian as promised with width inversey proportional to the original.\n\nI am pretty certain Maple should also be able to calculate the integral for you as it is written in my fist line (Mathematica can), so I imagine you are just not entering it correctly.\n\nEdit: Apologies for the first comment above. I had not seen that you had written this was for a free particle, so indeed you know the Hamiltonian, the potential is $V(x,t)=0$, and so from Schr\u00f6dinger's equation we know the time evolution of the energy Eigenstates is $\\psi(x,t)=e^{-i \\omega t}\\psi(x)$. For the free particle we have $\\omega=k^2/2m$ and so you know the time evolution of the Fourier transform.\n\nSo taking the Fourier transform given above, applying the time evolution, and transforming back to position space we have $$\\psi(x,t)=\\int_{-\\infty}^{\\infty} e^{-k^2/2 a}e^{-i\\omega t}e^{ikx} \\, dk \\\\ =\\int_{-\\infty}^{\\infty} e^{-\\frac{k^2}{2 a}(1+iat/m)}e^{ikx}\\, dk \\\\ \\sim e^{\\frac12 \\frac{x^2}{1/a+imt}}$$ as #Ron pointed out in his comment. This shows how the wavepacket spreads out with time.\n\nshare|improve this answer\nThe fourier trasnform evolves by simple phases, and a reverse fourier transform gives the time evolution, which is a spreading Gaussian, so that the a gets replaced everywhere by ${1\\over {(1/a)+it}}$ \u2013\u00a0 Ron Maimon Sep 21 '12 at 6:48\nOh yeah, hadn't seen the part saying this was for a free particle (doh!). Have added an edit to the answer to complete it. Thanks for pointing that out. \u2013\u00a0 Mistake Ink Sep 21 '12 at 13:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/253958/how-to-show-that-the-complete-elliptic-integral-of-the-first-kind-increases-in-m?answertab=votes\nText:\nTake the tour \u00d7\n\nHow can you show that the complete elliptic integral of first kind $ \\displaystyle K(m)=\\int_0^\\frac{\\pi}{2}\\frac{\\mathrm du}{\\sqrt{1-m^2\\sin^2 u}}$ that is the same as a series $$K(m)=\\frac{\\pi}{2} \\left(1+\\left(\\frac{1}{2}\\right)^{2}m^2 +\\left(\\frac{1\\cdot 3}{2\\cdot 4}\\right)^{2}m^4 +...+ \\left(\\frac{(2n-1)!!}{2n!!} \\right )^2m^{2n} + ... \\right)$$\n\nincreases in m?\n\n\nshare|improve this question\nThe expansion of the integral you wrote has terms for every odd power of $m$ as well. \u2013\u00a0 Did Dec 8 '12 at 20:56\nIm sorry, can you explain again? something wrong on the expansion? \u2013\u00a0 JHughes Dec 8 '12 at 21:58\nYes, something was definitely wrong with the expansion... But it seems you saw the problem since you made the necessary correction. Note that this makes the accepted answer, which addresses (incorrectly) the original version of your question, a little odd. \u2013\u00a0 Did Dec 8 '12 at 23:42\nyeah yeah, thx, i already correct it. \u2013\u00a0 JHughes Dec 11 '12 at 1:24\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou can show that the derivative with respect to $m$ is always positive:\n\nNote that $$K'(m)=\\int_0^\\frac{\\pi}{2}\\frac{m \\sin^2 u\\, du}{(1-m^2\\sin^2 u)^{3/2}} \\geq 0$$ as the integrand is positive for all $0\\leq m \\leq 1$.\n\nshare|improve this answer\nThe numerator $m\\sin u$ should read $\\frac12\\sin^2u$. \u2013\u00a0 Did Dec 8 '12 at 23:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38040/killing-vectors-for-so3-rotational-symmetry?answertab=votes\nText:\nTake the tour \u00d7\n\nI am reading a paper$^1$ by Manton and Gibbons on the dynamics of BPS monopoles. In this, they write the Atiyah-Hitchin metric for a two-monopole system. The first part is for the one monopole moduli manifold, and other terms for a 4-dimensional hyper kahler surface which is SO(3) symmetric parameterized by the euler angles. He obtains two sets of SO(3) killing vectors. What is the systematic way to obtain these two various sets? What are the equations involved? $$\\xi^R_i=\\cot{\\theta}\\cos{\\psi}\\frac{\\partial}{\\partial{\\psi}}-\\sin{\\psi}\\frac{\\partial}{\\partial{\\theta}}+\\frac{cos{\\psi}}{\\sin{\\theta}}\\frac{\\partial}{\\partial{\\phi}}$$ $$\\xi^R_2=-\\cot{\\theta}\\sin{\\psi}\\frac{\\partial}{\\partial{\\psi}}+\\cos{\\psi}\\frac{\\partial}{\\partial{\\theta}}+\\frac{sin{\\psi}}{\\sin{\\theta}}\\frac{\\partial}{\\partial{\\psi}}$$ $$\\xi^R_3=\\frac{\\partial}{\\partial{\\psi}}$$ and the other set by $$\\xi^L_1=\\cot{\\theta}\\cos{\\phi}\\frac{\\partial}{\\partial{\\phi}}+\\sin{\\phi}\\frac{\\partial}{\\partial{\\theta}}-\\frac{\\cos{\\phi}}{\\sin{\\theta}}\\frac{\\partial}{\\partial{\\psi}}$$ $$\\xi^L_2=-\\cot{\\theta}\\sin{\\phi}\\frac{\\partial}{\\partial{\\phi}}-\\cos{\\phi}\\frac{\\partial}{\\partial{\\theta}}-\\frac{\\sin{\\psi}}{\\sin{\\theta}}\\frac{\\partial}{\\partial{\\psi}}$$ $$\\xi^L_3=-\\frac{\\partial}{\\partial{\\phi}}$$\n\n\n$^1$ G.W. Gibbons and N.S. Manton, Classical and quantum dynamics of BPS monopoles, Nucl. Phys. B274 (1986) 183.\n\nshare|improve this question\nIs this better suited for Maths SE? \u2013\u00a0 ramanujan_dirac Sep 22 '12 at 21:41\nIf you know the metric and use the natural connection, you solve $\\mathcal{L}_X g_{ab}=X_{a;b}-X_{b;a}=0$. These are the vector fields that if you follow them they leave the metric unchanged. \u2013\u00a0 k\u03b7ives Sep 22 '12 at 23:22\nadd comment\n\n1 Answer\n\nThe specific form of the Killing vectors depends on the parameterization of the group element, from the notation (and the results), one can deduce that Euler angle parameterization has been used:\n\n$ g = exp(i\\sigma_3 \\psi) exp(i \\sigma_1 \\theta) exp(i \\sigma_3 \\phi)$\n\nwhere the sigmas are the generators of rotations with respect to Cartesian axes in the three dimensional representation.\n\nAlso the two sets of killing vectors correspond to the left and right action of $SO(3)$ on itself which preserve the invariant metric. I'll describe to you the case of the left action for example.\n\nThe basic equation definining the lect killing vectors is\n\n$ K_A^L g = \\sigma_A g$ (for the right action $K_A^R g = g \\sigma_A$, I'll skip from now the superscript understanding it is a left action).\n\n$K_A$ is a differential operator:\n\n$K_A = K_A^{\\phi} \\frac{\\partial}{\\partial \\phi} +K_A^{\\theta} \\frac{\\partial}{\\partial \\theta} +K_A^{\\psi} \\frac{\\partial}{\\partial \\psi}$\n\nFor convenience we shall call $x^1 = \\phi$, $x^2 = \\theta$, $x^3 = \\psi$,\n\nSo our task is to compute $K_A^j$\n\nIn order to do that,we remember that Maurer-Cartan one form $g^{-1} dg$ is a Lie algebra valued one form, i.e.,\n\n$m = g^{-1} dg = i a_j^A \\sigma_A dx^j$ (With summation convention)\n\nThus, the first task to be done is to explicitely compute the coefficients $ a_j^A$, this is done by computing the derivatives in the given parameterization.\n\nIf we contract this form with a killing vector, we obtain:\n\n$<K_A, m> = i K_A^j a_j^B \\sigma_B = g^{-1} K_A g =g^{-1} \\sigma_A g$\n\nUsing the orthogonality relations\n\n$tr(\\sigma_A \\sigma_B) = \\delta_{AB}$\n\nWe obtain:\n\n$K_A^j a_j^B = tr(\\sigma_B g^{-1} \\sigma_A g)$\n\nThus by solving this system of linear equations or equivalently, inverting the matrix A we get the formula for the Killing vectors components:\n\n$K_A^j = (a^{-1})_B^j tr(\\sigma_B g^{-1} \\sigma_A g)$\n\nin summary, one needs to compute the coefficient matrix of the Maurer-Cartan form and invert it and to compute the traces required by the last equation, then compute the Killing vector components by matrix multiplication.\n\nshare|improve this answer\nSir, thanks for the reply. Unfortunately, I don't know anything about the Maurer-Cartan form. I am aware of the so called killing equation $V^\u03bb \u2202_\u03bb g_{\u03bc\u03bd} + \u2202_\u03bc V^\u03bb g_{\u03bb\u03bd} + \u2202_\u03bd V^\u03bb g_{\u03bc\u03bb}$ which comes from $\\nabla_\\mu V_\\nu + \\nabla_\\nu V_\\mu=0$.Can one solve this problem using the above mentioned killing equation rather than the method proposed above. \u2013\u00a0 ramanujan_dirac Sep 23 '12 at 10:04\n@ramanujan_dirac: Actually, for the construction described above, one does not need to know any property of the Maurer-Cartan form except its evaluation by the insertion of the Euler parameter formula of $g$ into its definition. This form has many interseting properties and applications, please see for further reading Shlomo Sternberg lectures: math.harvard.edu/~shlomo/docs/lie_algebras.pdf. \u2013\u00a0 David Bar Moshe Sep 23 '12 at 10:43\ncont. For the computation of the Killing vectors according to the given Wikipedia page, one needs in advance to construct the invariant metric. Furthermore, given the invariant metric, the Killing vector components satisfy differential equations which are harder to solve than the algebraic equations in the method described in the answer. \u2013\u00a0 David Bar Moshe Sep 23 '12 at 10:44\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/143925/poincar%c3%a9-recurrence-and-symplectic-packings\nText:\nTake the 2-minute tour \u00d7\n\nQuestion. Is there any example of a path connected symplectic manifold $(M,\\omega)$ that has infinite volume, but which cannot be packed by an infinite number of symplectic balls of a fixed radius $r$, for any $r > 0$?\n\nNote that on such a manifold we would be able to prove the \"Poincar\u00e9 recurrence\" of every symplectomorphism:\n\nGiven a symplectomorphism $T: M \\rightarrow M$ and an open set $U \\subset M$ there exists an integer number $k > 0$ such that $T^k(U)$ intersects $U$.\n\nAdded and edited: It seems to me that the examples suggested in the comments assume the validity of the following (to my knowledge unproved) statement:\n\nLet $(M,\\omega)$ be the symplectic manifold obtained by taking $B(R)$, the symplectic ball of radius $R$ and dimension 2n, and attaching a long thin cylinder with very large volume and very small capacity. Let $r < R$ and consider the ball $B(r)$. There exists constant $c > 0$ such that any symplectic embedding of $B(r)$ into $M$ intersects the ball $B(R) \\subset M$ in a set whose volume is at least $c$.\n\nNote that this is not quite the intuition of non-squeezing theorem which would just say that you cannot embedd $B(r)$ into $M$ if $r > R$.\n\nAdded remark (10/10/2013). I just had a conversation around this problem with Leonid Polterovich. He tells me that in the early nineties Hofer had asked him whether symplectic geometry could perhaps be used to sharpen the Poincar\u00e9 recurrence theorem. This question was part of the motivation for his work with McDuff on packing obstructions.\n\nshare|improve this question\nMy intuition is that Gromov non-squeezing might make the following example work: Start with the stupid example of a sequence of disjoint balls with radius converging to 0, but with infinite volume. Then connect these by very thin tubes (thin in the sense that Gromov's non-squeezing theorem doesn't allow large symplectic balls to pass through them.) \u2013\u00a0 Brett Parker Oct 4 '13 at 5:17\nCan I not take the infinite \"cylinder\" whose metric has decreasing ends as $\\sim\\frac{1}{ln(r)}$? (and then apply Gromov nonsqueezing) \u2013\u00a0 Chris Gerig Oct 4 '13 at 6:04\n@BrettParker and Chris Gerig, I think you are implicitly assuming that because one cannot symplectically displace a ball through a thin tube, one cannot displace a large part of its volume through it. \u2013\u00a0 alvarezpaiva Oct 5 '13 at 21:02\nI agree that my suggestion relies on this statement about not being able to pass a large volume of a ball through a thin tube. To me, this statement does not seem to follow from the usual argument for Gromov non-squeezing, and after thinking for a little while, I'm inclined to think that it is false. \u2013\u00a0 Brett Parker Oct 6 '13 at 1:10\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/49799/a-graph-with-few-edges-everywhere\nText:\nTake the 2-minute tour \u00d7\n\nGiven a graph $G(V,E)$ whose edges are colored in two colors: red and blue. Suppose the following two conditions hold:\n\n  \u2022 for any $S\\subseteq V$, there are at most $O(|S|)$ red edges in $G[S]$\n  \u2022 for any $S\\subseteq V$, if $G[S]$ contains no red edges, then it contains $O(|S|)$ blue edges\n\nMy question is: can we conclude from this that the total number of blue edges is linear? I have no strong intuition for this, but it seems that it might be possible (some averaging/probabilistic argument?). To try to give an intuition, we can rephrase it as follows. The red graph is very sparse, even locally. The blue graph is also sparse in all regions that are free of red edges. Due to the sparseness of the red graph those 'regions' are numerous, so we hope this might imply that the blue graph is also sparse.\n\nOne can maybe consider first an easier version, if we assume that the red degree of every vertex is $O(1)$. In this case I also don't know the answer.\n\nNote that it's already too weak if we replace the first condition with just: the total number of red edges is linear. Look at the example: a blue $K_{\\sqrt n,n-\\sqrt n}$ with a red $\\sqrt n$-clique added in the corresponding part. This graph has $\\Omega(n^{3/2})$ blue edges (example by D. Palvolgyi). We can still ask in this version whether one can do better than $n^{3/2}$.\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 12 down vote accepted\n\nI think one can push through the probabilistic arguments of Tim Gowers and Fedor Petrov in the general case, as follows.\n\nLet $c$ be a constant such that the number of red edges in $G[S]$ is at most $c|S|$ for every $S \\subseteq V(G)$. One can order the vertices of $G$: $v_1, v_2, \\ldots, v_n$, so that every vertex has at most $2c$ neighbors with lower indices. (Define the ordering starting with the highest index. If $v_n, \\ldots,v_{i+1}$ are defined, set $v_i$ to be the vertex with the smallest degree in the subgraph induced by the vertices which are not yet indexed. This is a standard trick.)\n\nNow we define a random subset $S$ of $V(G)$ recursively: if $S \\cap$ {$v_1, \\ldots, v_i$} is chosen put $v_{i+1}$ in $S$ with probability $1/2$ if it is not joined by a red edge to any of the vertices already in $S$, otherwise don't put it in $S$. Then $S$ is red-free and, just as in Fedor's answer, we can see that the probability that a pair of vertices $u$ and $v$ joined by a blue edge both lie in $S$ is at least $2^{-4c-2}$. Therefore the number of blue edges is at most\n\n$2^{4c+2}c' \\mathbf{E}[|S|] \\leq 2^{4c+1}c'|V(G)|,$\n\nwhere $c'$ is the constant implicitly present in the condition on the density of the blue edges.\n\nshare|improve this answer\nI think you mean that the probability that both ends of a blue edge are chosen is at least $2^{-4c-2}$, and a complete write-up should also account for the additive constants allowed by big-O notation, but I'm convinced this will work. \u2013\u00a0 Tracy Hall Dec 18 '10 at 23:13\n@Tracy: Thank you, corrected $2c$ to $4c$. Additive constants in big-O could be absorbed into multiplicative ones. \u2013\u00a0 Sergey Norin Dec 18 '10 at 23:15\nvery nice proof! thank you all for combined efforts. \u2013\u00a0 filipm Dec 19 '10 at 9:58\n\nSuppose that the red edges can be written as a union of k matchings, $M_1,\\dots,M_k$. Now choose a random set of vertices as follows. For each edge in $M_1$ choose one of its end points randomly. Put in all other vertices with probability 1/2. Then do the same for $M_2,\\dots,M_k$. This gives us sets $A_1,\\dots,A_k$. Let $A$ be the intersection of these sets. Then each vertex has a probability $2^{-k}$ of belonging to $A$. Also, $A$ contains no red edges. More importantly, given a non-red edge, there is a probability $4^{-k}$ that both its end points belong to $A$. If we choose a random pair in $A$, the probability that it is a blue edge is at most $C/n$ for some $C$. I think (I haven't checked carefully enough to be sure) that this does the bounded-degree case, showing that we have at most $4^kCn$ blue edges. Maybe it even does the general case.\n\nshare|improve this answer\nThis certainly does bounded-degree case, since edges of a graph with maximal degree $d$ lie in a union of $d+1$ matchings (it is called Vizing's theorem, $2d-1$ matchings instead $d+1$ is almost obvious). General case may be done, if we replace matchings to trees and then change the probabilistic argument as Sergey suggests: enumerate vertices of each tree by ranges (starting from the root) and take each vertex with probability 1/2 if its (unique) already considered neighbor is not still taken. \u2013\u00a0 Fedor Petrov Dec 19 '10 at 20:52\n\nIt is not an answer, but bounded degree case only. If all red degrees do not exceed $d$. choose random (w.r.t. uniform distribution) red independent set $I$. I claim that for each edge $uv$ both $u$, $v$ belong to $I$ with probability bounded from below. Indeed, denote by $N$ the union of $u$, $v$ and their red neighbors. Then if we fix an intersection of $I$ and $V\\setminus N$, then conditional probability that $u,v$ both lie in $I$ is at least $1/2^{n}$, where $n=|N|\\leq 2d+2$.\n\nshare|improve this answer\n\nHere are just a couple of ideas (too long to fit a comment window). Let $R_i$ and $B_i$ be the red and the blue degrees of the $i$-th vertex. Take your graph and remove all vertices with $B_i\\le MR_i+M$. Take the remaining subgraph and remove all vertices with $B_i\\le MR_i+M$ (using the counts in the remaining subgraph, of course), and so on. No matter how many times we go, we remove at most $O(Mn)$ blue edges. If we stop, we have a graph in which each blue degree is at least $M$ times the corresponding red degree plus $M$.\n\nNow arrange the vertices in random order and select the red-independent set as the set of all vertices that preceede all their neighbors in the ordering. Each vertex $i$ will survive with probability $(R_i+1)^{-1}$. Moreover, if $(i,j)$ is not a red edge, then the probability that both $i,j$ survive is at least $\\frac12(R_i+1)^{-1}(R_j+1)^{-1}$. This puts the expected number of surviving blue edges at $$\\frac 12\\sum_{(i,j)\\in E_{\\text{blue}}}(R_i+1)^{-1}(R_j+1)^{-1}$$ and the expectation of the surviving number of vertices at $\\sum_{i}(R_i+1)^{-1}$.\n\nIf all degrees are bounded by $K$, then we, clearly, have what we want with much better bound than $4^K$. Unfortunately, if the degrees are unbounded, we still have a problem.\n\nshare|improve this answer\nhmm, why probability that a vertex survives is $(R_j+1)^{-1}$? Is not it $(R_j!)^{-1}$? \u2013\u00a0 Fedor Petrov Dec 19 '10 at 14:40\nIt just needs to be the first in the ordering, not to dictate the whole ordering. Anyway, this post is obsolete after Sergei's construction (only, of course, the vertex has to be chosen not with probability $1/2$ but with probability $1/c$ or so, so his survial chance for the pair is $(1-1/c)^{4c}c^{-2}\\approx c^{-2}$). \u2013\u00a0 fedja Dec 19 '10 at 23:09\noh, indeed (stupid me). I think, polynomial estimate is in general better then exponential, and it may be important in some other applications (say, if red degrees slowly grow). \u2013\u00a0 Fedor Petrov Dec 19 '10 at 23:21\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/116608/clifford-algebra-is-graded-separable\nText:\nTake the 2-minute tour \u00d7\n\nLet $D$ be an algebra of odd differential operators on a free module $V$, this algebra is isomorphic to the Clifford algebra $Cl(V^* \\oplus V)$. Let $m$ denote multiplication map $$m : D\\otimes D \\to D.$$ I need an explicit formula for a bimodule splitting of this map or equivalently an element $z \\in D\\otimes D$ s.t. $az=za$ for any $a \\in D$ and $m(z)=1$.\n\nIt is possible to use isomorphism of algebras $Cl(V^* \\oplus V) \\cong End(\\wedge V)$ and for $End(\\wedge V)$ such splitting is given (up to sign) by the same formula as for matrix algebra. So, I know that such splitting exists and I want a nice formula in term of differential operators (or standard generators of Clifford algebra).\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/137678/non-amenable-groups-with-arbitrarily-large-tarski-number\nText:\nTake the 2-minute tour \u00d7\n\nJust out of curiosity, I wonder whether there are non-amenable groups with arbitrarily large Tarski numbers. The Tarski number $\\tau(G)$ of a discrete group $G$ is the smallest $n$ such that $G$ admits a paradoxical decomposition with $n$ pieces: $\\exists A_1,\\ldots,A_k,B_1\\ldots,B_l\\subset G$, $\\exists g_1,\\ldots,g_k,h_1\\ldots,h_l\\in G$ such that $k+l=n$ and $$G = \\bigsqcup_{i=1}^k A_i\\sqcup\\bigsqcup_{j=1}^l B_j = \\bigsqcup_{i=1}^k g_iA_i = \\bigsqcup_{j=1}^l h_jB_j \\quad\\mbox{(disjoint unions)}.$$ Tarski's theorem says that $\\tau(G)<\\infty$ iff $G$ is non-amenable. It is known that $\\tau(G)=4$ iff $G$ contains a non-abelian free subgroup. (See a survey paper by Ceccherini-Silberstein, Grigorchuck, and de la Harpe)\n\nIf $G$ is a non-amenable group such that every $m$ generated subgroup of it is amenable, then it satisfies $\\tau(G)>m+2$ (because one may assume $g_1=e=h_1$ in the paradoxical decomposition). Such $G$ probably exists, but I do not know any examples even for $m=2$.\n\nshare|improve this question\nI think this is still an open problem. \u2013\u00a0 Misha Jul 25 '13 at 2:03\nIf I understand correctly, despite Mark's stellar answer, all the questions about Tarski numbers listed in the survey paper remain open, right? \u2013\u00a0 Dan S\u0103l\u0103jan Jul 26 '13 at 13:16\n\n1 Answer 1\n\nup vote 111 down vote accepted\n\nIt is indeed an open problem, as Misha said. But here is a solution. In E. Golod, Some problems of Burnside type. 1968 Proc. Internat. Congr. Math. (Moscow, 1966) pp. 284-289. Izdat. \u201dMir\u201d, Moscow, Golod announced, for every $m$ an infinite finitely generated torsion group all of whose $m$-generated subgroups are finite. A proof can be found in Ershov, Mikhail Golod-Shafarevich groups: a survey. Internat. J. Algebra Comput. 22 (2012), no. 5, 1230001, 68 pp (Theorem 3.3). The proof starts with a Golod-Shafarevich group $G$. If you assume that $G$ has property (T) (such groups exist by Ershov, see the survey), the resulting group will have property (T). Thus there exists a finitely generated infinite property (T), hence non-amenable, group with arbitrary large Tarski number.\n\nCorrection. Misha Ershov sent me two corrections.\n\n  1. It is easier to deduce the answer from Theorem 3.3 and Ershov's theorem that any GS group is non-amenable, it also can be found in the survey (this does follow from existence of property (T) GS group).\n\n  2. There exists a generalized GS group with property (T) and all m-gen. subgroups finite (for every fixed m). Thus a property (T) group with arbitrary large Tarski number also exists.\n\nshare|improve this answer\nSo the problem was open when you started writing the answer, and solved by the time you'd finished!? \u2013\u00a0 HJRW Jul 25 '13 at 10:41\nThat seems eminently deserving of a +1! \u2013\u00a0 HJRW Jul 25 '13 at 10:56\nThe reason it was open was that when the problem was formulated by Ceccherini-Silberstein, Grigorchuk, and de la Harpe, GS groups with property (T) (or even with property ($\\tau$)) were not known. In fact many people believed that such groups do not exist. Also I am not sure that they considered GS groups. After Ershov found a GS group with property (T), nobody noticed that it solves the problem - till now. \u2013\u00a0 Mark Sapir Jul 25 '13 at 11:28\n@Mark: Great. It would be very nice if you could write some more details (if you have time, of course), this fact is a rather big improvement in the Von Neumann-Day question... \u2013\u00a0 Dan S\u0103l\u0103jan Jul 25 '13 at 13:12\nThis is great, indeed. I never imagined it could be solved so quickly! \u2013\u00a0 Narutaka OZAWA Jul 26 '13 at 2:54\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/275544/order-of-nontrivial-elements-is-2-implies-abelian-group?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nIf the order of all nontrivial elements in a group is 2, then the group is Abelian. I know of a proof that is just from calculations (see below). I'm wondering if there is any theory or motivation behind this fact. Perhaps to do with commutators?\n\nProof: $a \\cdot b = (b \\cdot b) \\cdot (a \\cdot b) \\cdot (a \\cdot a) = b \\cdot (b \\cdot a) \\cdot (b\\cdot a) \\cdot a = b \\cdot a$.\n\nshare|improve this question\nIt's kind of an odd thing isn't it. Maybe it could help you to understand how counterexamples exist for groups of exponent p > 2 and how these counterexamples fail when p becomes 2. \u2013\u00a0 Myself Jan 11 '13 at 1:19\n\n4 Answers 4\n\nup vote 7 down vote accepted\n\nAs every non-identity element has order two, $a^{-1} = a$ for any element of the group. Therefore $$[a, b] = aba^{-1}b^{-1} = abab = (ab)^2 = e.$$ Hence the group is abelian. Is this too calculationy?\n\nshare|improve this answer\nHaha thanks! I knew I was missing something as obvious as that. I thought the commutator subgroup was tricky, but completely forget that I could just do that ... \u2013\u00a0 Calvin Lin Jan 11 '13 at 1:19\nAs a learner, the following idea helps me: commutator subgroup is exactly what you want to force to be identity in order to make a group abelian. For example, we see that if $N \\unlhd G$. Then $G/N$ is abelian if and only if $G' \\subseteq N$. \u2013\u00a0 GYC Jan 13 '13 at 7:02\nPlus, I agree that learning/using more vocabulary (e.g. \"commutator subgroups\") is difficult. However, when you deal with more difficult problems, extra vocabulary makes those tedious steps \"obvious.\" A typical example is as follows: let $H \\leqslant G$. We see that $N_{G}(H) = \\{g \\in G : H^{g} = H\\}$ is a subgroup, just by looking at it as a stabilizer subgroup of conjugation action of $G$ on $H$. \u2013\u00a0 GYC Jan 13 '13 at 7:05\n\n$[a,b]=1$ for all $a,b\\in G$ if and only if $G$ is abelian. You proved that $[a,b]=a^{-1}b^{-1}ab=1$ above - this is the connection to commutators.\n\nI don't know of any strong motivation behind this fact aside from, I guess, knowing that any nonabelian group must have an element of order $>2$. I think that it is just a standard exercise.\n\nIt may interest you motivationally to prove that $G/H$ is abelian if and only if $G'\\leqslant H$ (if $H \\unlhd G$).\n\nshare|improve this answer\nAny hints on how to show that any non-abelian group has an element of order >2? If $ab\\neq ba$, we could still have $abab=e$. Am thinking of $S_3$ with $r, f$. \u2013\u00a0 Calvin Lin Jan 11 '13 at 2:12\n@CalvinLin Try the contrapositive. \u2013\u00a0 Alexander Gruber Jan 11 '13 at 2:26\n\nTaking inverses reverses the order of multiplication, so if every element is its own inverse multiplication must be commutative.\n\nshare|improve this answer\nThat is a nice way of saying it. \u2013\u00a0 Alexander Gruber Jan 11 '13 at 1:48\nWow, this is really nice. \u2013\u00a0 Michael Albanese Jan 11 '13 at 4:02\n\nThe idea of this approach is to work with a class of very small, finite, subgroups $H$ of $G$ in which we can prove commutativity. The reason for this is to be able to use the results like Cauchy's theorem and Lagrange's theorem.\n\nConsider the subgroup $H$ generated by two distinct, nonidentity elements $a,b$ in the given group. The group $H$ consists of strings of instances of $a$ and $b$. By induction on the length of a string, one can show that any string of length 4 or longer is equal to a string of length 3 or shorter.\n\nUsing this fact we can list the seven possible elements of $H$: $$1,a,b,ab,ba,aba,bab.$$ By (the contrapositive of) Cauchy's Theorem, the only prime divisor of $|H|$ is 2. This implies the order of $H$ is either $1$, $2$, or $4$.\n\nIf $|H|=1$ or $2$, then either $a$ or $b$ is the identity, a contradiction.\nHence $|H|$ has four elements. The subgroup generated by $a$ has order 2; its index in $H$ is 2, so it is a normal subgroup. Thus, the left coset $\\{b,ba\\}$ is the same as the right coset$\\{b,ab\\}$, and as a result $ab=ba$.\n\nshare|improve this answer\nAfter establishing $|H|=4$ we could have also said $H$ is a p-group so it has nontrivial center, and $H/Z(H)$ is cyclic, so $H$ is abelian. \u2013\u00a0 peoplepower Jan 11 '13 at 10:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/144190/factoring-a-number-pa-qb-knowing-its-totient/144197\nText:\nTake the 2-minute tour \u00d7\n\nWe are given: $n=p^aq^b$ and $\\phi(n)$, where $p,q$ are prime numbers. I have to calculate the $a,b,p,q$, possibly using computer for some calculations, but the method is supposed to be symbolically valid and proper. I know that $\\phi(n)=p^{a-1}q^{b-1}(p-1)(q-1)$, but I dont know what can I deduct from this.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nWithout loss of generality we can assume that $p<q$. I would first compute the greatest common divisor of $n$ and $\\phi(n)$, $m=\\gcd(n,\\phi(n))$. There are two possibilities.\n\n1) $m=p^{a-1}q^{b-1}$. This happens, if $p$ is not a factor of $q-1$. In this case we can calculate $$ \\frac{n}{m}=pq,\\qquad\\text{and}\\qquad \\frac{\\phi(n)}{m}=(p-1)(q-1)=pq-(p+q)+1. $$ In this case we know $r=p+q$ and $s=pq$, and can solve the primes $p$ and $q$ as the roots of the quadratic equation $$ 0=(x-p)(x-q)=x^2-(p+q)x+pq=x^2-rx+s. $$\n\n2) $m=p^aq^{b-1}$. This happens, if $p$ is a factor of $q-1$. This time $$ \\frac{n}{m}=q,\\qquad\\text{and}\\qquad\\frac{\\phi(n)}{m}=\\frac{(p-1)(q-1)}p. $$\n\nI think that is possible to build a method from these bits alone. I would assume that we have the first case, and then check that it works in a separate verification step. The roots of the quadratic need to be integers, and we can keep on dividing $n$ with the roots to verify that the number $n$ is, indeed, of the form $p^aq^b$. If something goes wrong, then we must have case 2. This time we know $q$ directly, and can solve for $p$ from the equation $$ \\frac1{q-1}\\cdot\\frac{\\phi(n)}{m}=\\frac1{q-1}\\cdot\\frac{(p-1)(q-1)}p=\\frac{p-1}p=1-\\frac1p, $$ because the LHS is known.\n\nUndoubtedly there are alternative ways of exploiting these bits. The key is to compute $m$ first.\n\nshare|improve this answer\nThank you, I was hoping there's some way to avoid the initial case guesswork but I suppose this will have to do. \u2013\u00a0 poe123 May 12 '12 at 12:21\n@poe123, if you knew about this method, you could have said so. And waited for somebody to suggest a clever trick avoiding the verification step :-) No harm done, though! \u2013\u00a0 Jyrki Lahtonen May 12 '12 at 12:25\nOnce you have $t=n/m$ you can repeatedly divide it out of $n$ to get a power of $p$ or $q$ alone. Write $n=t^ku$, then if $u=1$ it's case 1) with $a=b$, otherwise in case 1) $\\gcd(t,u)$ is $p$ or $q$, in case 2) $\\gcd(t,u)$ is 1 and $t=q$. \u2013\u00a0 Zander May 14 '12 at 17:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/85418/expectation-of-log1x-if-x-is-a-gamma-random-variable\nText:\nTake the tour \u00d7\n\nI would like to know if there is a closed form expression for the expectation of log(1+x) when x is a gamma random variable.\n\nThank you.\n\nshare|improve this question\nYes, you may need Digamma function. See en.wikipedia.org/wiki/Polygamma_function \u2013\u00a0 Anand Jan 11 '12 at 15:58\nadd comment\n\n2 Answers\n\nIf $X$ has the gamma distribution with rate $\\lambda$ and shape parameter $n$, you're asking for $$ J(\\lambda, n) = \\frac{\\lambda^n}{\\Gamma(n)} \\int_0^\\infty t^{n-1} e^{-\\lambda t} \\log(1+t)\\ dt = \\frac{1}{\\Gamma(n)} \\int_0^\\infty s^{n-1} e^{-s} \\log(1+s/\\lambda) \\ ds$$\n\nUsing Maple, I get\n\n$$\\Psi \\left( n \\right) -\\ln \\left( \\lambda \\right) +{\\frac { {\\mbox{$_2$F$_2$}(1,1;\\,2,2-n;\\lambda)}\\lambda}{n-1}}+{\\frac { \\left( -1 \\right) ^{-n}\\pi }{\\sin \\left( \\pi n \\right) }}-{\\frac { \\left( -1 \\right) ^{-n}\\pi \\Gamma \\left( n,-\\lambda \\right) }{\\sin \\left( \\pi n \\right) \\Gamma \\left( n \\right) }} $$\n\nwhich seems to be correct when $n$ is a non-integer. For integer values of $n$, the result seems to be $\\frac{\\Gamma(n,-\\lambda)}{\\Gamma(n)} Ei(1,\\lambda)$ plus a polynomial in $\\lambda$ of degree $n-2$.\n\nshare|improve this answer\nadd comment\n\nI may be mistaken, but if you are making the change of variable $s = \\lambda t$, shouldn't there be an extra factor of $\\lambda$ outside the integral?\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49365/does-every-symmetric-group-s-n-have-a-single-element-of-maximal-word-norm\nText:\nTake the tour \u00d7\n\nGenerate $S_n$ by transpositions $s_i$ of (i) and (i+1). Both $S_3$ and $S_4$ have single elements of maximal word norm associated with this presentation. In fact, the Cayley graph of $S_3$ can be seen as a tiling of $S^1$, and the Cayley graph of $S_4$ a tiling of $S^2$. The element of maximal length is then antipodal to e.\n\nDoes every symmetric group $S_n$ have a single element of maximal word norm? If so, is there a formula for its length l(n)?\n\nshare|improve this question\nThanks for the answers. All are helpful - both the basic proof and bigger theory. \u2013\u00a0 ian Dec 14 '10 at 14:57\nadd comment\n\n5 Answers\n\nup vote 23 down vote accepted\n\nIt is amazing how a fact that I was taught in a middle school can be proved using big theories where I don't understand half of the words. Let me add a straightforward proof (for $S_n$ and only $S_n$).\n\nFor a permutation $\\sigma:\\{1,\\dots,n\\}\\to\\{1,\\dots,n\\}$, let $\\lambda(\\sigma)$ denote the number of inversions in $\\sigma$, that is the number of pairs $(i,j)$ such that $i<j$ and $\\sigma(i)>\\sigma(j)$. Then $\\lambda(\\sigma)$ equals the length of $\\sigma$ with respect to the generating set $\\{s_i\\}$.\n\nIndeed, left-multiplying $\\sigma$ by $s_i$ only interchanges $\\sigma(i)$ and $\\sigma(i+1)$, and hence changes $\\lambda(\\sigma)$ by at most 1. Therefore the length is bounded below by $\\lambda$. On the other hand, if $\\sigma$ is not the identity, there exists $i$ such that $\\sigma(i+1)<\\sigma(i)$, then left-multiplying by $s_i$ decreases $\\lambda(\\sigma)$ by 1. Repeating this procedure, one reaches the identity from $\\sigma$ by exactly $\\lambda(\\sigma)$ multiplications by generators.\n\nNow it is clear that the maximum length equals $n(n-1)/2$ and is attained only at the order reversing permutation (the one given by $\\sigma(i)=n+1-i$ for all $i$).\n\nshare|improve this answer\n+1 for the first sentence :) \u2013\u00a0 JBL Dec 14 '10 at 12:40\nTo combine with Qiaochu's answer: inversions $\\sigma(i)>\\sigma(j)$ correspond to flipped roots $e_i-e_j$. So the proof here extends easily to other root systems with their own notion of inversions, e.g. for the group of signed permutations. \u2013\u00a0 Allen Knutson Dec 14 '10 at 19:06\nadd comment\n\nYes; this is known as the longest element, and it exists and is unique for every finite Coxeter group (including the ones which do not arise as Weyl groups). The length of the longest element is the number of positive roots in the corresponding root system; here that number is ${n \\choose 2}$. A standard reference here is Humphreys' Reflection groups and Coxeter groups; Proposition 5.6b is relevant, and this is the content of Exercise 2 in that section.\n\nTo be more explicit (and to explain Tobias' answer), specialized to symmetric groups Proposition 5.6b says the following: let $S_n$ act on the orthogonal complement of the all-ones vector in $\\mathbb{R}^n$ in the obvious way. This complement is spanned by elements of the form $e_i - e_j, 1 \\le i \\neq j \\le n$; a choice of positive roots for the corresponding root system can be obtained by considering the elements with $i > j$, of which there are ${n \\choose 2}$. Then the length of $w \\in S_n$ is the number of positive roots $e_i - e_j$ sent to their negatives $e_j - e_i$ (which, one readily verifies, is the number of inversions in $w$). And there is a unique permutation that does this to every positive root: just send $k$ to $n + 1 - k$.\n\nOne way to interpret this result is that the length of an element $w \\in S_n$ (with its usual Coxeter system) is the least number of steps required to sort the word $w_1 w_2 ... w_n$ using bubblesort, and of course the word $n (n-1) (n-2) ... 3 2 1$ takes ${n \\choose 2}$ steps to sort and is maximal (since $n$ is moved $n-1$ times, $n-1$ is moved $n-2$ times, etc.)\n\nshare|improve this answer\nThe bit \"...their negatives $e_j - e_i$...\" is wrong above. It should just be \"negative roots,\" but this seems like too minor an edit to bump for. \u2013\u00a0 Qiaochu Yuan Nov 20 at 7:31\nadd comment\n\nThe Cayley graph of $S_n$ is the skeleton of the Permutahedron of order $n$. This polytope is the Minkowski sum of the $\\frac{n(n-1)}{2}$ segments connecting pairs of the standard basis vectors. You can now visualize that the element of maximal length is antipodal to the identity vertex and has length exactly $\\frac{n(n-1)}{2}$.\n\nshare|improve this answer\nNote that this is just a response to the observation that the Cayley graph of $S_n$ looks like $S^n$, the simplest proof is given by Sergei Ivanov in the other answer. \u2013\u00a0 Gjergji Zaimi Dec 14 '10 at 9:51\nadd comment\n\nYes, all $S_n$ have a unique longest element. One way to see this is that $S_n$ is the Weyl-group of the simple Lie algebra of type $A_{l-1}$, and here the length can be characterized by fixing a set of simple roots (and thus of positive roots). The length is then the number of positive roots that are sent to negative roots. The unique longest element is then the one that sends each simple root to its negative (the product of the simple reflections corresponding to each simple root)\n\nshare|improve this answer\nadd comment\n\nA more explicit version of Qiaochu's answer : $S_n$ can be viewed as a Coxeter group of type $A_{n-1}$. The maximal length is $\\frac{n(n-1)}{2}$, achieved by the element $$s_1(s_2s_1)(s_3s_2s_1) \\ldots (s_{n-1}s_{n-2} \\ldots s_2s_1)$$.\n\nThis is a classical result in Coxeter groups theory. Sketch of the proof : for each $i \\in [1,n-1]$ let $G_i$ be the so-called parabolic subgroup generated by $T_i=\\lbrace s_1,s_2, \\ldots ,s_n \\rbrace $. For any $w\\in G_k (1 \\leq k \\leq n-1)$ we can write $w=w_1w_2w_3 \\ldots w_r$ where each $w_i \\in T_k$ and $r$ is minimal. Among all those decompositions, we choose the one with as many generators in $T_{k-1}$ on the left as possible. This shows that $w$ can be written $w=w'x$, with $w'\\in G_{k-1}$, and $x\\in X_k$ where $X_k$ consists of the element $x\\in G_k$ all of whose minimal decompositions start with $s_k$.\n\nIt is not hard to show that the pair $(w',x)$ is unique (this is because $G_{k-1}$ and $X_k$ are disjoint) and trivially we have $l(w)=l(w')+l(x)$. By induction, any $w\\in S_n$ can be written uniquely $w=x_1x_2 \\ldots x_n$, where each $x_i$ is in $X_i$, and furthermore $l(w)=l(x_1)+l(x_2)+ \\ldots +l(x_n)$.\n\nNow, when the group is $S_n$ it is a straightforward exercise to show that $$X_k=\\lbrace s_{k},s_{k}s_{k-1}, \\ldots, s_{k}s_{k-1} \\ldots s_{2}s_{1} \\rbrace$$ for any $k$. Therefore $X_k$ has a unique element of maximal length, $\\xi_k=s_{k}s_{k-1} \\ldots s_{2}s_{1}$, and we deduce that $S_n$ has a unique element of maximal length which is the product $\\xi_1\\xi_2 \\ldots \\xi_{n-1}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/31718/continuous-function-with-local-maxima-everywhere-but-no-global-maxima/44463\nText:\nTake the tour \u00d7\n\nCan there be such a function:\n\n$f \\colon \\mathbb R \\to \\mathbb R$ is continuous and non-constant. It has a local maxima everywhere, i.e., for all $x \\in \\mathbb R$ there is some $\\delta_x>0$ such that $f(x)\\geq f(y)$ for all $y \\in B(x,\\delta_x)$. And, yet $f$ has no global maxima?\n\nThank you.\n\nPS: $\\mathbb R$ is with the usual topology. This is true for $\\mathbb R$ with upper-limit topology.\n\nshare|improve this question\nWhat is the source of this problem? Such $f$ must be constant. \u2013\u00a0 Shai Covo Apr 8 '11 at 12:15\nadd comment\n\n3 Answers\n\nNo such function exists. If $f$ is continuous and has a local maximum everywhere, then $f$ is constant. To see this, let $a$ be a real number. By continuity, $\\{x:f(x)\\leq f(a)\\}$ is closed, and by the hypothesis on local maxima, $\\{x:f(x)\\leq f(a)\\}$ is open. The set is nonempty because it contains $a$, so it is all of $\\mathbb{R}$ by connectedness. Therefore, for all $a$ and $b$ in $\\mathbb{R}$, $f(b)\\leq f(a)$ and similarly $f(a)\\leq f(b)$.\n\nshare|improve this answer\nwhat if $f$ is not a continuous function? \u2013\u00a0 Ilya Apr 8 '11 at 14:24\nThen the proposition does not hold. Try f(x) = 1 if rational, 0 if irrational. \u2013\u00a0 user7530 Apr 8 '11 at 15:48\n@Gortaur: There would be examples if you didn't require the function to be continuous. E.g., take $f(n)=n$ for each positive integer $n$, and $f(x)=0$ otherwise. If you didn't care about having a global maximum, the characteristic function of any proper nonempty closed set would be a nonconstant function with a local maximum everywhere. \u2013\u00a0 Jonas Meyer Apr 8 '11 at 18:02\n@user7530: What is that example supposed to show? \u2013\u00a0 Jonas Meyer Apr 8 '11 at 18:03\n@user7530: for this function there are no local maximas. \u2013\u00a0 Ilya Apr 8 '11 at 19:19\nshow 3 more comments\n\nSurprisingly enough, there are a few papers on this (like here). So other people have considered variations of this problem.\n\nI think that you should also be familiar with a related but incredibly interesting fact: it is possible to have a continuous function that has a local maxima/minima at every rational number. That's a dense subset, which is astounding enough as it is. (One should note that having a countable number of local maxima is all one can ask for. To see this, note that around every maxima one can assign an interval over which it is the maximum, from the definition of a local maximum. But there is a rational number in this interval, and so there can be at most countably many).\n\nOne such function is the Weierstrass function. It seems not so hard to alter this so that it has countably many maxima and minima, but no global maxima or minima.\n\nshare|improve this answer\n(+1); concerning paragraphs 2-3, it is worth recalling math.stackexchange.com/questions/42944/\u2026 \u2013\u00a0 Shai Covo Jun 10 '11 at 7:18\nadd comment\n\nTo extend the answer Jonas gave, let me note that if $f$ is continuous and has a local minimum or maximum everywhere, then $f$ is constant. See Problem2010-4/B here for a proof (very recently published).\n\nEDIT (elaborating). If $f$ has a local minimum or maximum everywhere, then the range of $f$ is countable (a proof is provided in the above link; see also here). Hence if $f$ is further continuous it must be constant, for otherwise, by the intermediate value theorem, the range of $f$ would be uncountable, a contradiction.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/30891/explicit-formula-for-the-j-invariant-of-binary-quartic-form/30967\nText:\nTake the tour \u00d7\n\nA binary quartic form\n\n\ndecomposes as a product of linear factors $Y-t_jX$, $j=1,...,4$. I would like to have an explicit formula for symmetrization of the crossratio of $t_j$.\n\nshare|improve this question\nDo you mean the j-invariant of the elliptic curve $y^2=ax^4+bx^3+cx^2+dx+1$? \u2013\u00a0 Robin Chapman Jul 7 '10 at 13:54\nYes, that is exactly what I am looking for. \u2013\u00a0 David Mar\u00edn Jul 7 '10 at 14:00\nIf you have access to a computer algebra system, you can do the following. Let $\\xi$ denote a solution to $f(1,\\xi)=0$ where $f$ is your quartic. Then $f(X,Y+\\xi X)=b'X^3Y+\\cdots+Y^4$. The elliptic curve is now isomorphic to $y^2=b'x^3+c'x^2+d'x+1$. Transform it to the usual Weierstrass form and take the $j$-invariant. Note that $b'$ etc. will have $\\xi$s in them, but they should all cancel out via the equation $f(1,\\xi)=0$ in the final result. \u2013\u00a0 Robin Chapman Jul 7 '10 at 14:23\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nThe $j$ invariant is\n\n\n\n\n\n\nfor more details see my article J. Algebra 303 (2006) 771-788.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/48721/calculate-temperature-of-the-earth-through-blackbody-radiation/49739\nText:\nTake the tour \u00d7\n\nI don't understand the solutions to a problem about blackbody radiation and was wondering if anybody could help me out.\n\nHere is the question:\n\nThe sun can be considered as a blackbody radiation source at temperature T = 5778 K. Radiation from the sun which is incident on the earth is reflected by the atmosphere such that the intensity hitting the earth's surface is reduced by a factor R. Some of the radiation emitted from the earth's surface is reflected by the atmosphere such that only a fraction A leaves the atmosphere. If A = R = 0:1, what temperature would the earth be?\n\nThen in the solutions they state: This is obtained by first trying to find the power from the sun which passes through unit area at the earth's radial distance. This is given by:\n\n$\\frac{4 \\pi r_s^2}{4 \\pi d_e^2}\\sigma T_s^4$\n\nwhere $r_s$ is the radius of the sun, $d_e$ is the distance between the earth and sun and $T_s^4 = 5778K$ is the temperature of the sun.\n\nI know that $\\sigma T_s^4$ is from the Stefan-Boltzmann law, and that $4 \\pi r_s^2$ is the surface of the sun. What I don't understand is why the distance to the earth is important. Thanks in advance!\n\nshare|improve this question\nIf the Earth is farther from the sun it receives less radiation from the sun! Try sketching the geometry. (Hints: conservation of energy (flux); inverse square law) \u2013\u00a0 Michael Brown Jan 9 at 13:15\n@MichaelBrown So the $\\frac{1}{d_e^2}$ comes from the inverse square law? The thing that confuses me is that the earth's radius isn't needed anywhere. \u2013\u00a0 Longeyes Jan 9 at 13:35\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe standard procedure (or at least how I think about it) for getting the temperature of a planet from that of the star consists of alternating between power and power per unit area.\n\n  \u2022 You start with $\\sigma T^4$, the total power per unit area of the star.\n  \u2022 To get the total power, multiply by the area of the star.\n  \u2022 To get the power per unit area at the distance of the planet, you have to divide by the area of the sphere over which this energy is (by assumption evenly) distributed. This gets you to the quantity you have.\n  \u2022 Now you can find the total power absorbed by the planet, given the power per unit area it gets and an area1.\n  \u2022 Then you can divide by an area1 to get the power per unit area given off by the planet, which is a quantity you can set equal to $\\sigma T_\\text{planet}^4$ to find its temperature.\n\nSo there is a lot of multiplying and dividing by areas, and lots of factors of $\\pi$ will cancel when you string it all together. Note one can modify these steps to take additional complexities into account (the $R$ and $A$ of your problem, for example).\n\nFurther, note that I used the planet's radius - twice in fact. And if you go through the arithmetic, you should find that it cancels itself. Intuitively, you might expect that an object's temperature (an average thermal energy) only depends on the strength of the heat source and its distance, but not on the object's size. Both you and your pet hamster2 get to about the same temperature sitting at equal distances from the fireplace.\n\n1 Be careful about these two areas. You have to think about what area is appropriate where.\n\n2 I have no idea how I came up with this example.\n\nshare|improve this answer\nThanks! I think I understand how they got their results now :) By the first area...do you mean the \"receiving\" planet's surface? \u2013\u00a0 Longeyes Jan 11 at 10:40\n@Longeyes Yes, but there's a difference between the cross-sectional area $\\pi r^2$ and the total surface area $4 \\pi r^2$. \u2013\u00a0 Chris White Jan 11 at 15:57\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/393071/divide-by-a-number-without-dividing?answertab=active\nText:\nTake the tour \u00d7\n\nCan anyone come up with a way to divide any given x by any given y without actually dividing?\n\nFor example to add any given x to any given y without adding you would just do:\n\nAnd to subtract any given x from any given y (that is, y-x) you could do:\n*edit: well since (i) is ($\\sqrt{-1}$) and that is technically subtracting this one might not work perfectly but for the sake of the riddle and for the sake of example, I'm using that equation :)\n\nHow can you divide without dividing? Can anyone come up with equations that work for all $x$ and $y$ values? (For all intents and purposes we will leave out dividing by zero issues and what-not... don't worry about that...\n\nshare|improve this question\nI don't really see the point of this post. Divide without dividing? Sure you can do it for simple things, like solving: $2x = 6$. You could guess rational numbers until you get it right but that's pretty silly. What about something more complicated like $2x = \\pi$? How could you solve for $x$ without doing division? \u2013\u00a0 Cameron Williams May 16 at 2:20\n@CameronWilliams Exactly! How would you? That's what I want to know! I think it's a fun question! \u2013\u00a0 Albert Renshaw May 16 at 2:21\n$x/y=x\\times y^{-1}$ \u2013\u00a0 vadim123 May 16 at 2:22\n@CameronWilliams: Come now, Albert mentions $y+xe^{\\pi i}$ as a work-around for subtraction. You could not compute this without actually doing subtraction. The question is clearly about equivalent expressions with no immediate regard to practicality. We all have to learn these things at some point :) \u2013\u00a0 Eric Stucky May 16 at 2:27\nLet me just add that while the question may seem a little facetious, Paul Dirac spent some time trying to join special relativity and quantum mechanics before he discovered he could take a square root without taking a square root and revolutionise physics! (Slide 13) \u2013\u00a0 Nicolau Saker Neto May 16 at 3:32\nshow 9 more comments\n\n4 Answers\n\nup vote 7 down vote accepted\n\nLook at the equation $\\frac{1}{x}=a$. We use Newton's Method to approximate the solution.\n\nLet $f(x)=\\frac{1}{x}-a$. The standard Newton iteration gives $$x_{n+1}=x_n -\\frac{f(x_n)}{f'(x_n)}=x_n -\\frac{\\frac{1}{x_n}-a}{-\\frac{1}{x_n^2}}.$$ This simplifies to $$x_{n+1}=x_n(2-ax_n).$$\n\nRemark: Note that only subtraction and multiplication are used. If we start with $x_0$ close enough to $\\frac{1}{a}$, the method converges rapidly. It was once used to implement reciprocal in software.\n\nshare|improve this answer\n@AlbertRenshaw: You mentioned in the comments that your original idea was to try and \"guess high, guess low\" until you got to the right answer. This is a formally rigorous way of implementing a strategy similar to that one. The downside is that you'll never actually reach the number, but the upside is that for integer divisions you'll be able to see pretty quickly what you're \"headed towards,\" for example if your first guess is 0.8, this method tells you after four steps that $\\frac12\\approx 0.49999996$; it's not too much of a stretch to say, \"Oh, that's 0.5\". \u2013\u00a0 Eric Stucky May 16 at 2:49\nadd comment\n\nTake the logarithm that maps multiplication/division into addition/subtraction:\n\n$$\\frac{x}{y}=e^{\\log{x/y}}=e^{\\log x- \\log y}.$$\n\n$x,y >0$.\n\nAlso, see my answer for multiplying natural numbers here: Advocating base 12 number system\n\nshare|improve this answer\nadd comment\n\nFor $y \\neq 0$ $$\\large x\\div y = \\dfrac 1y\\times x = y^{-1}\\times x = \\large y^{\\left(e^{i\\pi}\\right)}\\times x = y^{\\left(i^2\\right)}\\times x$$\n\nshare|improve this answer\nVery nice!!! For now I will accept this, I am curious what others come up with!!! (I will accept it in 7 minutes when SE lets me) \u2013\u00a0 Albert Renshaw May 16 at 2:23\nMultiplying by the reciprocal could be thought of as the definition of division. This is analogous to saying that $x-y = x+(-y)$ is subtracting without subtracting, whereas an alternative would be to note that that is the definition of subtraction. \u2013\u00a0 Jonas Meyer May 16 at 2:30\n@JonasMeyer I'm eager to see if other's come up with solutions that don't use that... since the only way to \"really\" solve mathematically for (x^-y) is to use division. But this was more of a riddle question, in which case this is a valid answer :o) \u2013\u00a0 Albert Renshaw May 16 at 2:31\n@amWhy: I have seen all of the OP's comments. I'm not sure what part you want me to see. \u2013\u00a0 Jonas Meyer May 16 at 2:36\n@Jonas see below the answer...he simply wants to avoid using the symbol for division. \"I just meant without using the symbols in the actual equation! Haha :o) \" \u2013\u00a0 amWhy May 16 at 2:37\nshow 1 more comment\n\nLogs turn reciprocals into minus signs: $\\ln(1/y)=-\\ln(y)$. Thus, $$x/y=xe^{-\\ln y}.$$\n\n(This is assuming that $y$ is positive. If $y$ is negative, then $x/y=-xe^{-\\ln(-y)}$.)\n\nshare|improve this answer\nI like this one even better!!! :) \u2013\u00a0 Albert Renshaw May 16 at 2:33\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214234/tiling-a-minimal-perimeter-region-with-n-unit-squares?answertab=oldest\nText:\nTake the tour \u00d7\n\nSuppose I have $n$ identical unit squares and I want to use them all to tile a region with minimal perimeter $p(n)$. For instance I guess $p(n^2)=4n$, by arranging them im a $n\\times n$ square.\n\nIs there an explicit formula for $p(n)$? Or sharp bounds? How do one prove equalities or bounds for this type of quantities?\n\nI would be happy also with a recursive formula for $p(n)$, like $p(n\\cdot m) = f(p(m),p(n))$, but the factorization is not unique and I don't see how to get it easily.\n\nMy intuition is that given a certain number $n$, the minimal perimeter region is a rectangle with sides of integer lengths $l$ and $m$, where $l\\cdot m=n$ and $(l,m)$ is the pair of integer numbers \"closest\" (in some sense) to $(\\sqrt{n},\\sqrt{n})$, that's where number theory could play a role.\n\nI have no clue where to start proving something along these lines, so any hint, comment or reference is welcome!\n\nshare|improve this question\nI think it should be $p(n) \\sim 2\\sqrt{\\pi n}$ as $n\\to\\infty$ \u2013\u00a0 nikita2 Oct 15 '12 at 13:30\n@nikita2: That would be the asymptotic form for the minimal length of the convex hull; but if you measure the perimeter exactly following the sides of the squares a circular arrangement is actually worse than a square. \u2013\u00a0 joriki Oct 15 '12 at 15:03\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nFor every x in the range $n^2 \\le x < (n+1)^2$ you have $4n \\le p(x) \\le 4n+4$, so $p(x) = \\sqrt{x} + \\operatorname{O}(1)$. If you want a closed formula I would try with (putting $t=n^2-x$) $$ p(n^2+t) = \\begin{cases} 4n \\quad&\\text{if }t=0\\\\4n+2 &\\text{if }0 < t \\le n\\\\ 4n+4 &\\text{if }n < t \\le 2n\\end{cases}$$ which is the perimeter you obtain if you go from the square $n\\times n$ to the square $(n+1)\\times(n+1)$ tile by tile.\n\nEDIT (Proof sketch) We can assume that the shape with least perimeter is connected (if the shape has two pieces, connecting them by a suitable edge gives a shape with strictly less perimeter than the original).\n\nNow given $x = n^2+t$ with $0\\le t \\le 2n$ fix a shape that gives the least perimeter $p(x)$. Pick a rectangle with minimal dimensions $a\\times b$ containing the shape. The perimeter is at least $2a+2b$, (as it goes all the way from left to right and from top to bottom and back by the other side).\n\nOn the other hand $ab \\ge x$ because there are at least $x$ tiles inside the rectangle so $$ p(x) \\ge 2a + 2b \\ge 2a + 2x/a $$ the right hand side has a single minimum at $a = \\sqrt{x}$ but $a$ is an integer so we have $$ p(x) \\ge 2n + 2x/n = \\frac{ 4n^2 + 2t}{n} $$ (it is easy to see that $a=n+1$ gives a larger value). If $t = 0$ this gives $p(x) \\ge 4n$, if $t \\le n$ we have $p(x) > 4n$ but as $p(x)$ is even we have $p(x) \\ge 4n+2$ and if $t > n$ we have $p(x) > 4n+2$ so again $p(x) \\ge 4n+4$. As we have examples obtaining this bounds we are finished.\n\nshare|improve this answer\nthat was my guess as well, but does one prove it formally? \u2013\u00a0 Ale Zok Oct 15 '12 at 16:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/39822/energy-functional-in-poissons-equation-what-physical-interpretation\nText:\nTake the tour \u00d7\n\nLet's consider this boundary-value problem:\n\n$$\\begin{cases} -\\Delta V = \\rho & \\rm{in}\\ \\Omega \\\\ V=0 & \\rm{on}\\ \\partial \\Omega \\end{cases}.$$\n\nWe know that this problem has a variational formulation: its solutions are critical points of the energy functional\n\n$$I[u]=\\int_{\\Omega} \\left( \\frac{1}{2}\\lvert \\nabla u \\rvert^2 - u\\rho \\right)\\, dx,$$\n\n(cfr. Evans Partial differential equations 2nd ed., \u00a72.2.5).\n\nNow let us look at one (of the many) possible physical interpretations of this problem, the electrostatic one. If units are chosen so that $\\varepsilon_0=1$, this equation describes the electric potential $V$ in a region $\\Omega$ filled with a charge distribution $\\rho$ and whose boundary is grounded.\n\nIt would be nice if the energy functional introduced above coincided with the total energy of this physical system. Unfortunately, it seems to me not to be so. In fact, as I read in Feynman's Lectures on physics, vol.II, \u00a78-5, the total energy of this system consists of two additive parts: one is\n\n$$\\frac{1}{2}\\int_{\\Omega} \\lvert \\nabla V \\rvert^2\\, dx$$\n\nand is due to the electric field; the other is\n\n$$\\frac{1}{2}\\int_{\\Omega} V\\rho\\, dx$$\n\nand is due to the charge distribution.\n\nThis induces me to think that the energy functional should be\n\n$$U[u]=\\int_{\\Omega} \\left(\\frac{1}{2}\\lvert \\nabla u \\rvert^2 + \\frac{1}{2}u\\rho \\right)\\, dx,$$ instead of the correct $$I[u]=\\int_{\\Omega} \\left( \\frac{1}{2}\\lvert \\nabla u \\rvert^2 - u\\rho \\right)\\, dx.$$ Why am I wrong?\n\nshare|improve this question\nAs for the sign: if you instead consider $J[u] := I[-u]$, the first term doesn't change, while the second one gets a plus sign. The critical points of the functionals $J$ and $I$ also agree (up to sign, of course). As for the factor 1/2, see joriki's post. \u2013\u00a0 Gerben May 18 '11 at 11:08\nadd comment\n\n3 Answers\n\nI think this has to do with what you treat as the dynamic variables. In your first formulation, $\\rho$ was given and fixed, and you wanted to calculate $V$ by varying only $V$, not $\\rho$. In the second formulation, $V$ is just a quantity derived from $\\rho$, and this is the energy suitable for obtaining $\\rho$ by varying $\\rho$, with $V$ just a shorthand for a certain linear transformation of $\\rho$. A third possibility is to consider $V$ as given and find the motion of a charge distribution in this potential -- here, again, there would not be a factor of $\\frac{1}{2}$. This is the case, for instance, if we calculate the motion of the electron in the potential of a hydrogen nucleus, or of the Earth in the gravitational potential of the Sun.\n\nMathematically speaking, we need a factor of $\\frac{1}{2}$ in front of quadratic terms (where $V\\rho$ is quadratic in $\\rho$ if $V$ is considered as a derived quantity derived from the dynamical variable $\\rho$) but not in front of linear terms. Physically speaking, the factor of $\\frac{1}{2}$ avoids double-counting when the energy is regarded as the interaction energy of a charge distribution with itself.\n\nNow you may ask: But surely there is some well-defined energy and we can't just pick and choose the factors according to expedience? That's true, but consider again the hydrogen atom: If we consider the potential of the nucleus as given, then we're not counting the potential energy of the nucleus in the field of the electron in the integral over $\\rho V$. But the entire energy is there and has to be accounted for in the integral, hence the factor $1$. On the other hand, in treating a helium atom, where both electrons are treated as dynamic and their interaction energy enters into the Hamiltonian, we do include a factor of $\\frac{1}{2}$ to avoid double-counting the energy in the double integral over $\\rho_1\\rho_2/r_{12}$.\n\nshare|improve this answer\n+1: Maybe it is worth to add that a Legendre transform brings you from the form where $V$ is a \"dynamical\" variable to the form where $\\rho$ is the \"dynamical\" variable. \u2013\u00a0 Fabian May 18 '11 at 11:44\nadd comment\n\nIn the Lagrangian formulation of classical mechanics, the functional that we extremise to derive the Euler-Lagrange equation of motion is the Lagrangian, defined as\n\n$$L[u] = T[u] - V[u]$$\n\nwhere $T[u]$ is the kinetic part and $V[u]$ is the potential part. Contrast this with the Hamiltonian $H=T+V$ from which we derive Hamilton's equations of motion (these are equivalent to the Euler-Lagrange equations, and the two are related by Legendre transform). That should explain the minus sign discrepancy.\n\nI am not sure about the factor of 1/2. Is it possible that we are simply defining $\\rho_{\\mathrm{Feynman}} = 2\\rho_{\\mathrm{Evans}}$?\n\nshare|improve this answer\ndon't you have a problem with $L$ not being conserved? In the theory of ODE's/PDE's, you explicitly construct an energy functional to have something that stays constant along flow lines (of the solution). \u2013\u00a0 Gerben May 18 '11 at 11:10\n$L$ is not the energy functional, it is the Lagrangian. If you want something corresponding to the total energy of the system you need to be looking at the Hamiltonian $H$. \u2013\u00a0 Chris Taylor May 18 '11 at 11:17\nI'm not sure this is it, Chris. This one we have here is not an action functional, but an energy functional. It's not that we have two different kinds of energy s.t. one transforms into the other, as kinetic and potential energy do in mechanical systems. I'm more inclined to think that the error lies in the fact that I am not quantifying energy correctly, as Lubo\u0161 Motl and joriki point out. \u2013\u00a0 Giuseppe Negro May 18 '11 at 15:39\nadd comment\n\nThe energy functional has to agree with the total energy and there can't be any ambiguity or \"freedom of conventions\" that would add the factors of two, among other things. After all, the total energy/mass is a subject to conservation laws and it determines both inertial of the system as well as the strength of its gravitational field.\n\nIf you integrated Feynman's two $\\int E^2/2$ and $\\int \\rho V/2$ contributions over the whole 3-space, you would surely be double-counting the energy. The correct energy is just one of them, as given by the Evans formula. In the localized case, the two expressions may be shown to be equal.\n\nYou may also use Feynman's formula but you must be careful to use the $\\int E^2/2$ exclusively for the part of the electric fields that are \"unrelated\" to localized charged sources.\n\nshare|improve this answer\nDouble-counting the energy... In fact if we integrate by parts $$\\int_{\\Omega} \\frac{E^2}{2}\\, dx$$ we get $$\\frac{1}{2}\\int_{\\Omega} V \\rho \\, dx.$$ So you say I must take into account one or the other energy term and not the sum of the two... In the end, this must be the same suggestion joriki gives above. I need to think about this a little bit. In the meantime, thank you. \u2013\u00a0 Giuseppe Negro May 18 '11 at 15:34\nI still don't get it. In Evans' formula $$\\int_{\\Omega} \\frac{1}{2}\\lvert \\nabla V \\rvert^2 - V\\rho\\, dx$$ it looks as that $-V\\rho$ is a corrector term, that is: total energy at a point is $\\frac{1}{2}\\lvert \\nabla V \\rvert^2$ diminished by $V\\rho$. Why do we diminish energy like that? Do you mind explaining this, please? \u2013\u00a0 Giuseppe Negro May 18 '11 at 16:42\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/184729/are-bimodules-over-a-commutative-ring-always-modules?answertab=votes\nText:\nTake the tour \u00d7\n\nLet $R$ be a commutative ring. It is true that every module over $R$ is an $(R,R)$-bimodule. Is the converse true? In other words is it possible that there is an $R$-module where left multiplication and right multiplication do not co-incide?\n\nI thought perhaps a counterexample would be of the following form. If $S$ is an $R$-algebra, if we form the product $S \\otimes_R S$ and think of it as an $S$-module where multiplication is given by $s(s' \\otimes s'') = ss' \\otimes s''$ and $(s' \\otimes s'') s = s' \\otimes s''s$. If we can pick the right element $s$ it is possible those two tensors are not equal. I cannot find any concrete counterexamples though. If you do this with $\\mathbb{Q} \\otimes_\\mathbb{Z} \\mathbb Q$ for example it doesn't work.\n\nThanks for any help.\n\nshare|improve this question\nEven simpler: take a noncommutative ring $R$, and let $I$ be a left ideal which is not a right ideal. \u2013\u00a0 M Turgeon Aug 20 '12 at 18:10\nI don't know either but it's a safe bet that if you're looking for a counterexample you're going to have to pick something less well-behaved than $\\mathbb{Z}$ and $\\mathbb{Q}$. \u2013\u00a0 Paul Z Aug 20 '12 at 18:10\nTake $\\mathbb{R} \\otimes_\\mathbb{Z} \\mathbb{R}$ and let $\\mathbb{R}$ act on each side separately. \u2013\u00a0 Zhen Lin Aug 20 '12 at 18:12\nYou could also just take $\\mathbb{C}$ with the following two module structures: One is given by multiplication and the other one is given by multiplication with the conjugate. \u2013\u00a0 HenrikRueping Aug 20 '12 at 18:34\nRelated question \u2013\u00a0 Pierre-Yves Gaillard Aug 21 '12 at 7:36\nshow 5 more comments\n\n4 Answers\n\nup vote 5 down vote accepted\n\nAs Zhen Lin comments above, the converse is not true. For another example, suppose $S$ is a ring containing $R$ as a commutative subring such that $R$ is not in the center of $S$. Then $S$ is naturally an $(R,R)$-bimodule using the ring multiplication on $S$. But if $R$ is not in the center of $S$ then there exists $r \\in R$, $s \\in S$ such that $rs \\neq sr$. So the left and right actions don't agree.\n\nFor a simple example, take $R$ to be the subring of diagonal matrices in the matrix ring $\\mathbb{M}_n(k)$ for a field $k$ and $n \\geq 2$.\n\nshare|improve this answer\nadd comment\n\nSupplementing other answers and comments: first, I would argue against thinking that \"left\" and \"right\" have genuine content, but I would argue in favor of thinking of these as notational artifacts of our left-to-right writing system, etc. (I am reminded again of Herstein's advocacy of writing functions on the right of their arguments, at least in English.)\n\nE.g., an $R,S$-bimodule's main property is that the $R$-action and $S$-action commute with each other, and that the order-of-multiplication in $S$ is \"backward\", so (in English, with left-to-right conventions) an $R,S$-bimodule is equivalently a (\"left\") $R\\otimes S^{\\rm opp}$-module, with the \"opposite\" ring.\n\nIt is true that sometimes the notational left and right are mnemonically helpful, but their content should not be over-estimated.\n\n\"Even\" in looking at $Hom_?(M,N)$ with non-commutative $R$, $S,R$-bimodule $M$, and $R,T$-bimodule $N$, the \"left/right\" structures might better be called pre-composition and/or post-composition and such, refering to the more basic convention of order of composition of functions: those closest the argument are applied first. Luckily, the $M\\otimes_R N$ structures are more directly correctly suggested by left-right conventions, but, still, can be converted to other expressions, as noted above.\n\nEdit: forgot to emphasize that associativity is, or should, if done right, built into all these set-ups. So the $(rm)s=r(ms)$ principle ought not be something one is worrying about in the face of all the other issues.\n\nshare|improve this answer\nadd comment\n\nFor a commutative ring $R$, it is not true that every $R$ module is a bimodule. (Are you possibly thinking that modules which are left and right $R$ modules are called \"bimodules\"? This is not the case...)\n\nMariano Su\u00e1rez-Alvarez gave an example here: An $R$ module and $S$ module that cannot be an $R$-$S$ bimodule of a left $R$ right $S$ module that is not an $R-S$ bimodule. In his example he made his $R\\neq S$, but I don't see why that is necessary, because he only used dimensionality in his arguments. So, I think you can replace $S$ in the example with another copy of $R$, and still have a counterexample.\n\nIt will also show that the left and right actions of $R$ are not the same.\n\nOver any ring it is trivial that any $R-R$ bimodule is both a left module and a right module over $R$. It's just the restriction of the bimodule action to one side.\n\nI misled myself with the first statement, and didn't see the simple claim you were making about $R$ modules. Yes, every $R$ module has the \"naive\" $R-R$ bimodule structure. Sorry for the distraction! I think the rest of my answer pertains to your question though! It produces separate module actions which do not commute.\n\nshare|improve this answer\nEvery module is an $(R,R)$-bimodule by definition of an $R$-module. There is no distinction between left and right multiplication in a module so you automatically get that it is a bimodule \u2013\u00a0 Paul Slevin Aug 20 '12 at 18:51\n@PaulSlevin Again, $R-R$ bimodule does not mean \"Is a left and right $R$ module\". There is an additional requirement that the two actions commute with each other. It may happen in a left-right $R$ module that $(rm)s\\neq r(ms)$, and that would prevent it from being a bimodule. \u2013\u00a0 rschwieb Aug 20 '12 at 18:54\nThey do! for a bimodule you need (rm)s = r(ms) which are both just equal to (rs)m for modules. Over a commutative ring. Just to remind you I am talking about commutative rings here \u2013\u00a0 Paul Slevin Aug 20 '12 at 18:56\n@PaulSlevin I think there is some confusion of module operations here. There are two actions which we can write on the right side. Using different symbols for the actions, we need to show $(m\\ast x)\\cdot y=(m\\cdot y)\\ast x$. The rule $(m\\cdot r)\\cdot s$ doesn't cover that (right?!). Said another way: If $f:R\\rightarrow End(M)$ and $g:R\\rightarrow End(M)$ are the module actions, how do you prove that $Im(g)$ and $Im(f)$ commute with each other? \u2013\u00a0 rschwieb Aug 20 '12 at 19:30\n@PaulSlevin Aha, wait, now I see what you meant :) Adding to my answer. I should have seen what you meant earlier. (What I've written here isn't wrong though, by the way.) \u2013\u00a0 rschwieb Aug 20 '12 at 19:34\nadd comment\n\nA bit more complicated but modern example: let $A$ and $B$ be curved $A_\\infty$ algebras or differential graded curved algebras and $M$ be an $A$-$B$-$A_\\infty$-bimodule (dg curved algebras appear naturally in Hochschild theory and theoretical physics).\n\nIt follows that $M$ is neither a left $A_\\infty$-$A$-module nor a right $A_\\infty$-$B$-module due to the inclusion of the curvatures in $A$ and $B$ in the $A_\\infty$ module relations.\n\nEven simpler, if $A$ is a dg curved algebra, then it is not a left dg $A$-module, a right dg $A$-module or a dg $A$-$A$-bimodule.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/90538/interesting-property-of-numbers-in-english\nText:\nTake the tour \u00d7\n\nI was playing with the letters in numbers written in English and I found something quite funny. I found that if you count the number of letters in the number and write this as a number and then count the number of letters in this new number and keep repeating the process, you will arrive at the number 4. I've confirmed this (using a computer program) for all numbers up to 999999 and was wondering if there's a way to prove this or to find a counter example for which it does not hold.\n\nJust to give an example of the above statement, let's start with thirty seven (I chose this randomly) Thirty seven has 11 letters in it, Eleven has 6 letters in it, Six has three letters in it, Three has 5 letters in it, Five has 4 letters in it. It may look like I just picked this number, so let me show this for another random number, say 999. Nine hundred and ninety nine has 24 letters in it, Twenty four has 10 letters in it, Ten has 3 letters in it, Three has 5 letters in it, Five has 4 letters in it.\n\nWhat are your thoughts on how to prove this?\n\n(Just a note: I only confirmed this for numbers written in the standard British way of writing numbers - for example 101 is one hundred and one)\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 16 down vote accepted\n\nDefine $f: \\mathbb{N} \\to \\mathbb{N}$ as the number of letters in a given natural number spelled out.\n\nFour is the only fixed point under $f$, and it's not too difficult to see that $f$ is almost always strictly decreasing with the only exceptions being one, two, three and four. So the $n^{th}$ iterate of $f$ must eventually become smaller than 5, which doesn't leave very many cases to verify.\n\nshare|improve this answer\nIs there actually a systematic way to name arbitrarily large numbers in English? It seems that one would have to specify this before claiming that your $f$ is eventually decreasing. \u2013\u00a0 user83827 Dec 11 '11 at 19:56\n@ccc I suppose one would have to make the assumption that the numbering system is relatively uniform - and if no such nomenclature exists for a certain number, that the number of letters in that number would not spike by an enormous amount of digits. Perhaps one could adopt the convention of saying one million million for one million squared, for instance, so that all numbers may be accounted for. \u2013\u00a0 analysisj Dec 11 '11 at 20:01\n@ccc Do those Hebrew letters used for Cantor algebra accomplish that (naming arbitrarily large numbers)? I don't recall exactly though... \u2013\u00a0 Feral Oink Dec 11 '11 at 20:06\n@ccc This is a bad question: Why have you NEVER voted on any question, up or down? (That needn't be answered.) \u2013\u00a0 Feral Oink Dec 11 '11 at 20:10\nThere is such a systematic method of naming numbers in English, although the details escape me. Given that a 1000-factor increase in the size of the number results in roughly a 28-35 letter increase in name size (\"three hundred and thirty three -illion\" and so on) it's clear that the naming convention will never catch up. Consider also what it would take for the size of the name to grow as the number: you'd have to write in unary. \u2013\u00a0 jprete Dec 11 '11 at 22:11\nshow 3 more comments\n\nNote that the number of letters in the number is almost always going to be less than the number itself; in fact, this should be true for all numbers greater than four. Four is the only number which has this property (that the number of letters is equal to the number itself). Therefore, we can say that if a number repeats eventually, it must repeat at 4. Furthermore, since the value of the number of letters in the number is always less than the number itself for values greater than 4, the number is always decreasing until four.\n\nSo, all that remains is to show that the numbers 3,2, and 1 always go to 4 eventually, and then we can know that it will repeat. 3 goes to 5 which goes to 4. Both 1 and 2 go to 3 which go to 5 which go to 4. Though this is fairly informal, this is the gist of how it could be shown.\n\nshare|improve this answer\nAs an interesting side note, no such number should occur in French. There exists no number when spelled out such that the number of letters is equal to the number, but you can get patterns such as 3,5,4,6,3,5,4,6,... because 3 is trois which goes to 5 which is cinq which goes to 4 which is quatre which goes to 6 which is six, which goes back to three... \u2013\u00a0 analysisj Dec 11 '11 at 19:50\nadd comment\n\n\n$2 \\to 3 \\to 5 \\to 4$\n\n$3 \\to 5 \\to 4$\n\n$4 \\to 4$\n\n$5 \\to 4$\n\n$6 \\to 3 \\to 5 \\to 4$\n\n$7 \\to 5 \\to 4$\n\n$8 \\to 5 \\to 4$\n\n$9 \\to 4$\n\n$10 \\to 3 \\to 5 \\to 4$\n\n\nshare|improve this answer\nI don't mean this as an exhaustive list (!), as this is what you have shown for n < 999999. Rather, if you can show that the function (as Dustan writes) decreases to eventually give you a value less than 10 (or 5), then you're done. \u2013\u00a0 The Chaz 2.0 Dec 11 '11 at 19:41\nYou should edit your comment into your answer \u2013\u00a0 Henry Dec 12 '11 at 0:05\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/252638/bounds-on-a-sum-involving-the-mobius-function\nText:\nTake the tour \u00d7\n\nIn Apostol's Analytic Number Theory, Apostol defines $$A(x):= \\sum_{n \\leq x} \\frac{\\mu(n)}{n}$$ and proves that $A(x)=o(1)$ implies the Prime Number Theorem, by showing that $$\\frac{M(x)}{x}=A(x)-\\frac{1}{x}\\int_1^x A(t)dt,$$ in which $M(x):=\\sum_{n \\leq x} \\mu(n)$ is the summatory function for the M\u00f6bius function (Theorem 4.16). What are some known error bounds for the function $A(x)$? In particular, do we have $A(x)= o(1/\\log x)$ as $x \\to \\infty$?\n\nshare|improve this question\nTerence Tao has a rather interesting paper about this : 'A remark on partial sums involving the Mobius function'. See too his blog. \u2013\u00a0 Raymond Manzoni Dec 7 '12 at 1:20\nSchoenfeld's paper, Marraki's one and Cohen's paper seem interesting too (summatory function is much more studied than the $\\zeta(1)$ formula). \u2013\u00a0 Raymond Manzoni Dec 7 '12 at 1:25\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nI'll answer my own question:\n\nThe Abel Summation formula gives\n\n$$A(x)=\\frac{M(x)}{x}+ \\int_1^x \\frac{M(u)}{u^2} du = \\frac{M(x)}{x}+\\int_1^\\infty \\frac{M(u)}{u^2} du-\\int_x^\\infty \\frac{M(u)}{u^2} du.$$ As $A(x)=o(1)$, the right-hand side of the above must tend to $0$. We have $M(x)/x \\to 0$, and the estimate $$\\left\\vert \\int_x^\\infty \\frac{M(u)}{u^2} du \\right\\vert \\leq \\int_x^\\infty \\frac{\\vert M(u)\\vert}{x^2} du =\\frac{1}{x^2}O(xM(x))=O(M(x)/x)$$ implies that the rightmost integral of our first line tends to $0$ as well. Thus $$\\int_1^\\infty \\frac{M(u)}{u^2} du=0,$$ and $A(x)=O(M(x)/x)$. In particular, we can answer our question by simply bounding the growth of Mertens' function $M(x)$. We have $$M(x)=O\\left(xe^{-c\\sqrt{\\log x}}\\right)$$ for some positive constant $c$. (I believe this follows from the classical bounds in the PNT but am unable to find a proper reference. Edit: I found a mention of the process here.) Then $A(x) =O(e^{-c \\sqrt{\\log x}})$, and since $$\\lim_{x \\to \\infty} \\frac{(\\log x)^n}{e^{c \\sqrt{\\log x}}}=0$$ for all $n$, we find $A(x)=o((\\log x)^{-n})$ for all $n >0$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/325141/probability-that-n-points-on-a-circle-are-in-one-semicircle\nText:\nTake the tour \u00d7\n\nChoose n points randomly from a circle, how to calculate the probability that all the points are in one semicircle? Any hint is appreciated.\n\nshare|improve this question\nHave I taken too much of a simplistic view on the problem by thinking the probability is $\\left\\(\\dfrac{1}{2}\\right\\)^n$? \u2013\u00a0 Noble. Mar 9 at 1:10\n@Noble: Yes, you have -- that's the probability that the points are all in one particular semicircle. \u2013\u00a0 joriki Mar 9 at 1:10\n@joriki I thought as much, it's a much more interesting problem then! \u2013\u00a0 Noble. Mar 9 at 1:11\nHint: Start with a point randomly on the circle and draw a diameter from that point. All you got to do now is ensure that rest of the $n-1$ points lie on the same side of the diameter (i.e., on a semi-circle). You can place the $n-1$ points using a coin toss. \u2013\u00a0 jay-sun Mar 9 at 1:12\n@jay-sun I dont think this is the correct way, three points could still be in one semicircle even if the last two are on two different sides of the diameter joining the first point and the center. \u2013\u00a0 Shu Xiao Li Mar 9 at 1:14\nadd comment\n\n4 Answers\n\nup vote 5 down vote accepted\n\nA variation on @joriki's answer (and edited with help from @joriki):\n\nSuppose that point $i$ has angle $0$ (angle is arbitrary in this problem) -- essentially this is the event that point $i$ is the \"first\" or \"leading\" point in the semicircle. Then we want the event that all of the points are in the same semicircle -- i.e., that the remaining points end up all in the upper halfplane.\n\nThat's a coin-flip for each remaining point, so you end up with $1/2^{n-1}$. There's $n$ points, and the event that any point $i$ is the \"leading\" point is disjoint from the event that any other point $j$ is, so the final probability is $n/2^{n-1}$ (i.e. we can just add them up).\n\nA sanity check for this answer is to notice that if you have either one or two points, then the probability must be 1, which is true in both cases.\n\nshare|improve this answer\nI don't understand this answer. (Strange, since you think it's a variation on mine. :-) I presume the \"if\" in \"if the remaining points end up all in the upper halfplane\" is intended to mean \"if and only if\"? If so, why is that? And why is the final probability simply the number of points times this one probability you calculated? \u2013\u00a0 joriki Mar 9 at 1:46\n@joriki Basically I'm breaking this down into conditional probabilities. The angle around the circle is just an arbitrary assignment, so conditionally pick $i$. All of these conditional probabilities are going to be identical, and there's $n$ of them, so whatever that probability is, multiply it by $n$. That's the easy part. (cont'd...) \u2013\u00a0 John Moeller Mar 9 at 1:48\n@joriki Since you've conditionally picked $i$, then you can arbitrarily choose the upper or lower halfplane as your \"in the same semicircle\" event. That's a coin-flip for each point, and they all have to be true, so it's $1/2^{n-1}$. (cont'd...) \u2013\u00a0 John Moeller Mar 9 at 1:51\nI think I see now -- I find it rather confusingly formulated, but if I understand correctly, you mean something like this: The probability of the remaining $n-1$ points being in the semicircle clockwise of a given point is $1/2^{n-1}$. These $n$ events (one for each given point) are disjoint, and exactly one of them has to occur for the points to lie in a semicircle; thus the desired probability is their sum. That's a nice argument :-) \u2013\u00a0 joriki Mar 9 at 2:02\nThere's a slight variation of this answer that uses the inherent symmetry: instead of picking $n$ points at random, pick $n$ random diameters of the circle and pick the $n$ points by randomly picking one of the 2 poles of each diameter. By essentially the same argument, you have the probability given by $(2n)/2^n=n/2^{n-1}$. \u2013\u00a0 sai Mar 9 at 2:16\nshow 4 more comments\n\nFind the largest angle gap, and number the points, say, clockwise such that that gap is between the last and first point. Then the probability density for the angle from the first to the last point to be $\\phi\\lt\\pi$ is\n\n$$ n\\frac1{2\\pi}\\left(\\frac\\phi{2\\pi}\\right)^{n-2}\\;, $$\n\nwhere the factor $n$ arises because we mapped $n$ numberings to one, $1/2\\pi$ is the density for the angle between the first and last point, and $(\\phi/2\\pi)^{n-2}$ is the probability that the remaining $n-2$ points are between them. The integral\n\n$$ \\int_0^\\pi n\\frac1{2\\pi}\\left(\\frac\\phi{2\\pi}\\right)^{n-2}=\\frac n{(2\\pi)^{n-1}}\\pi^{n-1}=\\frac n{2^{n-1}} $$\n\nis the desired probability.\n\nP.S.: Here's code that tests this result by simulations.\n\nshare|improve this answer\nadd comment\n\n\n\nfor the general problem (when the points have any distribution that is invariant w.r.t. rotation about the origin) and\n\n\nfor a nice application.\n\nAs a curiosity, this answer can be expressed as a product of sines:\n\n\nshare|improve this answer\nadd comment\n\nHere's another way to do this:\n\nDivide the circle into $2k$ equal sectors. There are $2k$ contiguous stretches of $k$ sectors each that form a semicircle, and $2k$ slightly shorter contiguous stretches of $k-1$ sectors that almost form a semicircle. The number of the semicircles containing all the points minus the number of slightly shorter stretches containing all the points is $1$ if the points are contained in at least one of the semicircles and $0$ otherwise; that is, it's the indicator variable for the points all being contained in at least one of the semicircles. The probability of an event is the expected value of its indicator variable, which in this case is\n\n$$k\\left(\\frac k{2k}\\right)^n-k\\left(\\frac{k-1}{2k}\\right)^n=k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)\\;.$$\n\nThe limit $k\\to\\infty$ yields the desired probability:\n\n$$ \\lim_{k\\to\\infty}k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)=\\lim_{k\\to\\infty}k2^{-n}\\left(\\frac{2n}k\\right)=\\frac n{2^{n-1}}\\;. $$\n\nshare|improve this answer\nWhy is $ \\lim_{k\\to\\infty}k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)=\\lim_{k\\to\\infty\u200c\u200b}k2^{-n}\\left(\\frac{2n}k\\right)$ true? \u2013\u00a0 sai Mar 9 at 5:09\n@sai: Apply the binomial theorem to the $n$-th power -- the first term cancels the $1$, the second term yields $2n/k$ and the remaining terms have more than one inverse power of $k$ and thus go to zero as $k\\to\\infty$. Note that $n$ is fixed; it's not a question of taking $n$ and $k$ to infinity simultaneously; we're just adding a finite number of terms, so the standard rules for adding convergent sequences apply. \u2013\u00a0 joriki Mar 9 at 8:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/90495/example-of-a-discontinuous-function\nText:\nTake the tour \u00d7\n\nIs there an example of a discontinuous function, $F$, defined on some complete subset $X\\subset R^n$ such that under some metric $d$, $\\sum\\limits_{n=1}^\\infty \\|F^n(x)-F^n(y)\\|<\\infty$ and\u00a0\n\nEither for multiple $x_i\\in X$ where $i\\in I$ and $I$ is any arbitrary indexing set, we have $F(x_i)=x_i$.\n\nOr For all $x\\in X, F(x)\\neq x$?\n\nshare|improve this question\nusually the notation $||.||$ is used for a norm, do you mean norm or metric? What do you assume about $x$ and $y$ in the inequality you stated? Is this supposed to hold for any $x, y$? \u2013\u00a0 user20266 Dec 11 '11 at 17:10\nThe parts \"multiple $x_i$\" and \"any arbitrary indexing set\" seem to contradict each other -- is $I$ really completely arbitrary, or does \"multiple $x_i$\" imply that $I$ has at least two elements? \u2013\u00a0 joriki Dec 11 '11 at 17:40\nAlso the sentence seems to be missing a verb -- do you mean \"Is there an example of a discontinuous function ...\"? \u2013\u00a0 joriki Dec 11 '11 at 17:58\n@Thomas: I meant a metric. Yes, for any x,y. Thanks. \u2013\u00a0 Will Dec 11 '11 at 19:18\n@joriki: Sorry for the ambiguities. I has to bhave at least 2 elements for the \"either\" option. Yes, I should probably use of instead. Edited. :) \u2013\u00a0 Will Dec 11 '11 at 19:20\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nYes. Take $X=[0,1]$ and\n\n$$F(x)=\\begin{cases}\\frac12&x=0\\;,\\\\\\frac x2&x\\ne0\\;.\\end{cases}$$\n\n$F$ is discontinuous at $0$. The sum is a geometric series and thus convergent. And $\\forall_{ x\\in X}F(x)\\ne x$.\n\nNote that the discontinuity at $0$ isn't required to make this work; we could introduce arbitrary discontinuities within the interval, as long as the iteration eventually moves beyond them towards $0$.\n\nClearly we can't have the other case, $F(x_i)=x_i$ for multiple $x_i\\in X$, since in that case the sum would diverge for $x=x_1$, $y=x_2$, being the sum over a non-zero constant.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59317/amenable-equivalence-relation-generated-by-an-action-of-a-non-amenable-group/59698\nText:\nTake the 2-minute tour \u00d7\n\nQuestion. Give a (possibly elementary) example of a probability measure preserving action $\\rho\\colon G \\curvearrowright X$ of a finitely-generated discrete group $G$ on a standard borel space $X$ with a probability measure, such that\n\n  1. the equivalence relation generated by $\\rho$ is ergodic and amenable,\n  2. the action $\\rho$ is faithful,\n  3. the group $G$ is non-amenable.\n\nA friend of mine asked me this question couple of days ago, which led us to another question, but perhaps there is an easier way to provide an example.\n\nshare|improve this question\nThis question is discussed in: Alexander S. Kechris \"Global Aspects of Ergodic Group Actions and Equivalence Relations\", pp. 31-34. It is available on line here: citeseerx.ist.psu.edu/viewdoc/summary?doi= \u2013\u00a0 Jesse Peterson Mar 27 '11 at 7:18\nYou can use the construction known as Mackey range: take a cocycle of an amenable equivalence relation with values in a non-amenable group G. Then G induces an amenable action on the space of skew product orbits. See Zimmer's paper for details. \u2013\u00a0 SIB Mar 27 '11 at 12:21\n@Jesse Peterson - Could you be a bit more specific? \u2013\u00a0 R W Mar 27 '11 at 12:31\nThe discussion is in Chapter 1, section 4, subsection (E). In the on line version I've linked to this actually begins on page 27 (page 37 of the pdf file). Thanks RW. \u2013\u00a0 Jesse Peterson Mar 27 '11 at 13:30\n@SIB - Yes, but the problem is still to find such a cocycle for which the resulting action is faithful - which is more or less equivalent to the original question. \u2013\u00a0 R W Mar 27 '11 at 13:40\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nThe answer is yes, such an action exists.\n\nWhat is needed for the construction is the following very nice example of an action of a non-amenable group on $\\mathbb Z$, which I just learned from Gabor Elek.\n\nConsider a graph with vertices given by $\\mathbb Z$ and unoriented edges between $n$ and $n+1$.\n\nPick a random labelling of the edges by the letters $a,b$ and $c$ with no $a$, $b$ or $c$ adjacent to the same letter. This defines an action of the group $G=\\mathbb Z/2 \\mathbb Z \\ast \\mathbb Z/2 \\mathbb Z \\ast \\mathbb Z/2 \\mathbb Z$. Indeed, just act according to existing labels or fix the element.\n\nThis action has the nice feature that it keeps invariant all counting measures on $\\mathbb Z$, i.e. all $\\mathbb Z$-Folner sequences sets are also Folner sequences for the $G$-action.\n\nNow, the space of labellings (as above) of the graph is itself a probability measure space (a Bernoulli space), which carries an ergodic p.m.p. $\\mathbb Z$-action by shifting. It is easy to see that $G$ acts on this space by measure preserving transformations (just by the method described above, done orbit by orbit) and induces an action as required. Indeed, the orbits are just the $\\mathbb Z$-orbits, so its ergodic and amenable. Faithfulness follows the fact that you considered all labellings, so that with positive probability (on the space of labellings), an element will act non-trivially. Note also that $G$ is not amenable.\n\nEDIT: As requested, more details on the action. The elements of the shift space are maps $f: \\mathbb Z \\to \\lbrace a,b,c \\rbrace$ with $f(n) \\neq f(n+1)$. A letter shifts $f$ to the right if $f(1)$ equals that letter, it shifts to the left, if $f(0)$ is equal to the letter; otherwise you fix $f$. It is obvious that the orbits are just the orbits of the shift-action of $\\mathbb Z$. Hence, the induced equivalence relation is just the one induced by the action of $\\mathbb Z$.\n\nshare|improve this answer\nI may miss something, but I don't see how it becomes an action. Take the sake of example the following labelling: $a$ on the edge $(0,1)$, and $b$ on all other edges $(n,n+1)$. Then, according to what you say, $a$ maps 0 to 1 and preserves all other vertices, whereas $a^{-1}$ maps 1 to 0 and preserves all other ones (I presume you meant that if you reverse orientation of an edge, then the label changes to its inverse). But then their composition is not the identity map. \u2013\u00a0 R W Mar 27 '11 at 13:37\nThanks, I corrected the construction. \u2013\u00a0 Andreas Thom Mar 27 '11 at 21:04\nI agree that now there is an action of the free product on $\\mathbb Z$. However, I still don't see how you define an action of this free product on your space of symbol sequences (your description \"just by the method described above, done orbit by orbit\" is not clear to me at all), and why this hypothetical action should be orbit equivalent to the shift. \u2013\u00a0 R W Mar 27 '11 at 22:27\nIt is really easy; I added more details above. \u2013\u00a0 Andreas Thom Mar 28 '11 at 0:15\nThat's nice - thank you. \u2013\u00a0 R W Mar 28 '11 at 3:48\n\nI believe in this paper there is an example of such group:\n\n  \u2022 Rostyslav Grigorchuk, Volodia Nekrashevych, \"Amenable actions of nonamenable groups\" (which can be downloaded from Volodia's webpage)\n\nalso, this is related (but not quite clear if one can built examples that you ask from it):\n\n  \u2022 Yair Glasner, Nicolas Monod, \"Amenable actions, free products and a fixed point property\"\nshare|improve this answer\nLet me also mention that by taking ``generic'' (think Baire category) generators one can show that the free groups have such an action. Also, by a result of Kirchberg (ams.org/mathscinet-getitem?mr=1282231), if $\\Gamma$ has property (T) and also has such an action then it must be residually finite. \u2013\u00a0 Jesse Peterson Mar 24 '11 at 12:53\n\nLet me join the discussion. Nicolas rightly says that amenability of an action is equivalent to amenability of the orbit equivalence relation and of a.e. stabilizer. It is also true that for a finite invariant measure amenability of the action is equivalent to amenability of the acting group. However, there is no contradiction here as (at least a priori) it might be possible that the orbit equivalence relation of an action of a non-amenable group is still amenable - due to the presence of huge stabilizers (which in this case must necessarily be non-amenable).\n\nI think that the paper by Grigorchuk and Nekrashevych quoted by Kate does provide a requested example. Indeed, they construct (Sections 3 and 4) a non-amenable group which has a faithful self-similar action on a homogeneous rooted tree. This action preserves the uniform measure on the boundary of the tree. Moreover, the orbit equivalence relation is a subrelation (mod 0) of the tail (or co-final in authors' terminology) equivalence relation. Since the latter one is hyperfinite ($\\equiv$ amenable), the orbit equivalence relation is also amenable.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/153564/is-it-true-that-for-matrices-where-all-entry-are-lower-than-1-determinant-is-lo\nText:\nTake the 2-minute tour \u00d7\n\nGeneric square matrix with positive 1 bounded entries\n\nConsidering a matrix $A=(a_{i.j})$ where $0 \\leq a_{i,j} < 1 \\forall i,j$. It is important to consider that all entries are strictly lower than 1 and positive.\n\nRows sum to a number lower than 1\n\nLet us consider that the sum of all entries of matrix $A$'s rows is lower than 1: $\\sum_{j=1}^{n}a_{i,j} < 1$. Sorry, maybe I did not specify it, only wrote in the formula, I talk about rows. Rows sum to a number lower than 1.\n\n\nLet us consider $\\det(A)$ (determinant).\n\nIs it true that $\\det(A)<1$???\n\nOr maybe $|\\det(A)| < 1$???\n\nshare|improve this question\nPerhaps you want to put absolute value signs around everything? Otherwise, consider $\\begin{bmatrix}-100 & 0 \\\\ 0 & -100\\end{bmatrix}$. \u2013\u00a0 Rahul Jun 4 '12 at 2:09\nYeah, all entries are positive. Please forgive me... \u2013\u00a0 Andry Jun 4 '12 at 2:13\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nEDIT: Taking into account the condition that the sum of the entries be less than one, the determinant is a sum of $n!$ terms, each of which is at most $n^{-n}$, so the determinant is bounded by $n!/n^n$, which is certainly less than 1 (for $n\\gt1$). Each term is les than $n^{-n}$ because it's a product of $n$ numbers that add up to less than 1, and you maximize the product by taking all the number to equal $1/n$.\n\n(Never mind --- I just saw the part about the sum of all the entries, or maybe it's the sum of all the entries in each row, being less than 1.)\n\nAre we only talking about $2\\times2$ matrices? If not, then $$\\pmatrix{a&b&0\\cr0&c&d\\cr e&0&f\\cr}$$ will have determinant $acf+bde$ which can certainly exceed 1 even if all the variables stand for numbers between zero and one.\n\nshare|improve this answer\nI am talking about sum of row entries... In your case, did you take into account this in your explaination? Sorry I am still reading, wanna be sure we are talking about the same. In my case I consider sum of row entries, not all elements in the matrix \u2013\u00a0 Andry Jun 4 '12 at 2:52\nI edited my questino because I specified the condition on rowas only in the frmula and not using words... It could be misleading. Very sorry for my carelessness \u2013\u00a0 Andry Jun 4 '12 at 2:54\nWhy don't you go away and think about your question for a couple of days and come back when you're able to put into writing the actual question you want to ask instead of something with lots of conditions missing or incorrectly stated? While you're at it, look up the Hadamard bound on determinants, it might answer your question, depending, of course, on what the heck your question might really be. \u2013\u00a0 Gerry Myerson Jun 4 '12 at 3:07\nI can understand that due to my carelessness you had to go through some troubles in understanding what I was looking for. Actually the question is the one here now, no more edits. I simply had in my mind the matrix structure but failed in explaining it and providing good details. I apologized. This being said, I do not think to deserve your bad words as there are many other members in this community behaving really bad towards those who answer their questions. You could simply say to pay more attention, it would have been \"more professional\". \u2013\u00a0 Andry Jun 4 '12 at 3:37\nEach term in the sum isn't necessarily bounded by $n^{-n}$, take a constant multiple of the identity matrix for example.. making all terms ${1 \\over n}$ actually minimizes things as the determinant becomes zero. \u2013\u00a0 Zarrax Jun 4 '12 at 4:59\nshow 1 more comment\n\nNote that $\\sum_j a_{ij}^2 < \\sum_j a_{ij} < 1$. So the magnitude of each row, viewed as a vector in ${\\mathbb R}^n$, is less than one. The absolute value of the determinant of $A$ is the volume of the parallelopiped spanned by the rows, which is at most the product of the magnitudes of the row vectors, and therefore is less than one in this case.\n\nIf you want to do it algebraically, you can prove it by induction on the dimension, the $1$ by $1$ case being trivial. Then you can do a cofactor expansion along any $i$th row, getting that $$det(A) = \\sum_j (-1)^{i + j} a_{ij} \\,det(A_{ij})$$ Note that each matrix $A_{ij}$ also satisfies the conditions of the problems, so each $|det(A_{ij})| < 1$ by induction hypothesis. You then get $$|det(A)| < \\sum_j |a_{ij}||det(A_{ij})|$$ $$< \\sum_j |a_{ij}|$$ $$< 1$$\n\nshare|improve this answer\nI think you'll find that what you are using in the first paragraph is what's commonly referred to as the Hadamard bound. \u2013\u00a0 Gerry Myerson Jun 4 '12 at 6:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/223895/injectivity-of-homomorphism-in-localization\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\alpha:A\\to B$ be a ring homomorphism, $Q\\subset B$ a prime ideal, $P=\\alpha^{-1}Q\\subset A$ a prime ideal. Consider the natural map $\\alpha_Q:A_P\\to B_Q$ defined by $\\alpha_Q(a/b)=\\alpha(a)/\\alpha(b)$.\n\nSuppose that $\\alpha$ is injective. Then is $\\alpha_Q$ always injective? I think so, but I'm clearly being too dense to prove it! My argument goes as follows.\n\nLet $\\alpha(a)/\\alpha(b)=0$. Then $\\exists c \\in B\\setminus Q$ s.t. $c\\alpha(a)=0$. If $B$ is a domain we are done. If not we must exhibit some $d\\in A\\setminus P$ s.t. $da=0$. Obviously this is true if $c =\\alpha(d)$. But I don't see how I have any information to prove this!\n\nAm I wrong and this is actually false? If so could someone show me the trivial counterexample I must be missing?\n\nMany thanks!\n\nshare|improve this question\nI wish someone would provide us a counterexample. I tried to find it, but failed. \u2013\u00a0 Makoto Kato Oct 30 '12 at 0:29\nadd comment\n\n2 Answers\n\nup vote 8 down vote accepted\n\nTake $A=K[X]$, $B=K[X,Y]/(XY)$ and $\\alpha$ the following application $$A=K[X]\\subset K[X,Y]\\rightarrow K[X,Y]/(XY)=B.$$ Obviously $\\alpha$ is injective. Write $B=K[x,y]$ with $xy=0$. Let $Q=xB$. It is obvious that $Q$ is prime ($B/Q\\cong K[Y]$) and $P=\\alpha^{-1}(Q)=XA$. Now choose $\\frac{X}{1}\\in A_P$ and observe that $\\alpha(\\frac{X}{1})=\\frac{x}{1}$. But $\\frac{x}{1}=\\frac{0}{1}$ in $B_Q$ because $yx=0$ and $y\\in B-Q$.\n\nshare|improve this answer\n+1 Congratulations. \u2013\u00a0 Makoto Kato Oct 30 '12 at 6:52\nThat's a great counterexample - thanks! \u2013\u00a0 Edward Hughes Oct 30 '12 at 8:42\nadd comment\n\nSince algebraic geometry is one of the tags, let me give a geometric account of the problem: one is given Spec $B \\to $ Spec $A$ dominant, and one wants to show that this isn't necessarily dominant in a n.h. of some point $Q$ of Spec $B$. The basic way to achieve this is to arrange Spec $B$ to be the union of two components, one which maps dominantly to Spec $A$ and one which doesn't, and take $Q$ to be a point lying (only) on the component that doesn't map dominantly. This is what happens in YACP's answer: Spec $B$ is two lines crossing, Spec $A$ is a single line, and the map is the identity on the first line and constant on the second line. The point $Q$ is then taken to be the generic point of the second line.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/37709/an-identity-for-sheaf-cohomology-of-flag-varieties?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a connected complex semisimple Lie-group, $T$ a maximal torus and $B$ a Borel subgroup containing it. Let $\\phi:G\\rightarrow G/B$ denote the projection. Given a representation ($\\theta,V$) of $B$, we can define a $G$-equivariant holomorphic vector bundle over the flag variety $X:=G/B$ by $$ G\\times_B V :=(G\\times V)/\\{(g,v)\\sim(gb^{-1},\\theta(b)v),\\forall b\\in B\\}.$$ Its sheaf of sections $\\mathcal{I}(\\theta)$ may be described as the holomorphic functions $$\\mathcal{I}(\\theta)(U)=\\{f:\\phi^{-1}(U)\\rightarrow V \\mid f(gb^{-1}) = \\theta(b)f(g)\\}. $$ $G$ acts on a section by $(gf)(x)=f(g^{-1}x)$.\n\nAn integral weight $\\lambda$ of $T$ gives a character $\\chi_\\lambda$ of $B$. Let $\\theta\\otimes\\chi_\\lambda$ denote the tensor product of the representations $\\theta$ and $\\chi_\\lambda$. Suppose ($\\theta,V$) is the restriction of a representation ($\\pi,V$) of $G$, then the associated ($G$-equivariant) vector bundle is trivial (i.e. isomorphic to $ X\\times V$ with $(g,(x,v))\\mapsto (gx,\\pi(g)v)$). Is the identity $$ \\mathrm{H}^i(X,\\mathcal{I}(\\theta\\otimes\\chi_\\lambda))\\simeq \\mathrm{H}^i(X,\\mathcal{I}(\\chi_\\lambda)) \\otimes V $$ as $G$ or $\\mathfrak{g}$-modules correct?\n\n\nI have been reading about the Borel-Weil theorem lately, and\n\nEdit: This question arose from an attempt to fix a mistake in a book. The identity is indeed correct and I believe I have found the error elsewhere. Thanks Chuck and Jim!\n\nshare|improve this question\nI don't think that's correct; you should have $V$ instead of $V^*$ in the identity. For example, consider the trivial $G$-equivariant bundle on $G/B$ with fiber $V$; its global sections are isomorphic to $V$. \u2013\u00a0 Chuck Hague Sep 4 '10 at 15:00\nSilly nitpick: In the second line, $\\phi$ should map to $X$, not $B$. \u2013\u00a0 S. Carnahan Sep 5 '10 at 9:46\n@Scott: Edited. \u2013\u00a0 Jim Humphreys Sep 10 '10 at 22:36\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThis may be too naive an answer, but from my experience this kind of question fits comfortably into the foundational material for reductive algebraic groups over an algebraically closed field of arbitrary characteristic. This is for example treated in Part I of J.C. Jantzen's 2003 AMS second edition of Representations of Algebraic Groups. There the starting point is the \"tensor identity\", followed by \"generalized tensor identity\" for higher derived functors of induction, which translates for the flag variety into the language of vector bundles and sheaf cohomology. This originates basically in classical Frobenius reciprocity for finite groups but becomes quite flexible in situations involving a reductive group, a Borel (or other parabolic) subgroup, and various finite dimensional rational representations. I'm assuming your V is finite dimensional. As Chuck Hague points out, no dualization should occur in your formula.\n\nMost of what goes into the classical Borel-Weil theory has a natural formulation in any characteristic, though Bott's theorem can't be imitated so precisely for nondominant line bundles.\n\nP.S. There are quite a few literature sources (papers by H.H. Andersen, Cline-Parshall-Scott, Donkin, etc.), but Chapter II.5 in Jantzen's book gives a fairly comprehensive treatment in algebraic language of the theorems of Borel-Weil and Bott, along with a derivation of Weyl's character formula. To get back to the classical theory over $\\mathbb{C}$ does require some translation of the language. The elegant papers of Demazure using algebraic geometry in characteristic 0 are the underlying inspiration for much of this approach to ideas first developed in the setting of complex geometry or compact Lie groups.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/117194/fastest-way-to-try-all-passwords\nText:\nTake the 2-minute tour \u00d7\n\nSuppose you have a computer with a password of length $k$ in an alphabet of $n$ letters. You can write an arbitrarly long word and the computer will try all the subwords of $k$ consecutive letters. What is the smallest word that contains all combinations of $k$ letters as subword? (i.e. the fastest way to hack the computer :) )\n\nThe smallest word that contains $n^k$ subwords of size $k$ has length $k-1^+n^k$ and based on some easy cases, we would like to prove that it is in fact possible to find a word of such length that contains all possible passwords. The problem can be translated into a problem in graph theory, by taking as vertices all words of length $k$.\n\nWe tried $k=2$, where you can prove the conjecture by induction. For $n=2$ and small $k$ it also works.\n\nshare|improve this question\nSee De Bruijn sequence and De Bruijn graph \u2013\u00a0 TMM Mar 6 '12 at 19:35\n@TMM: Why not add that as an answer? \u2013\u00a0 Aryabhata Mar 6 '12 at 19:39\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nWhat you are looking for is the De Bruijn sequence and the associated graph, the De Bruijn graph.\n\nHamilton paths in the De Bruijn graph correspond to De Bruijn sequences. Hamilton paths in the De Bruijn graph of words of length $k$ also correspond to Euler tours in the De Bruijn graph of words of length $k - 1$, and since all De Bruijn graphs are regular, the existence of such sequences for each alphabet size $n$ and word length $k$ follows.\n\n(A few years ago I stumbled upon these graphs for my thesis, so I can provide more fascinating properties of these graphs if needed!)\n\nshare|improve this answer\nThat is exactly what I was looking for! Thanks \u2013\u00a0 Michalis Mar 6 '12 at 20:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/111161/nonhomeomorphic-cw-complexes-that-are-stably-homeomorphic?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nDo there exist CW-complexes $X$ and $Y$ that are not homeomorphic, but $X \\times I$ and $Y \\times I$ are homeomorphic? Here $I$ denotes the unit interval $[0, 1]$.\n\nshare|improve this question\nSee mathoverflow.net/questions/26385/\u2026 \u2013\u00a0 j.c. Nov 1 '12 at 15:26\n\n1 Answer 1\n\nYes. Take $X$ a punctured torus ($T^2\\setminus$open disk) and $Y$ a three-punctured $S^2$. Then $X\\times I=Y\\times I$ is a genus 2 handlebody.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/47072/fermis-golden-rule-and-density-of-states/47075\nText:\nTake the tour \u00d7\n\nI know Fermi's Golden Rule in the form\n\n$$\\Gamma_{fi} ~=~ \\sum_{f}\\frac{2\\pi}{\\hbar}\\delta (E_f - E_i)|M_{fi}|^2$$\n\nwhere $\\Gamma_{fi}$ is the probability transition rate, $M_{fi}$ are the transition matrix elements.\n\nI'm struggling to do a derivation based on the density of states. I know that under certain circumstances it's a good approximation to replace $\\sum_f$ with $\\int_F \\rho(E_f) \\textrm{d}E_f$ to calculate the transition probability, for some energy range $F$.\n\nDoing this calculation I obtain\n\n$$\\Gamma_{fi} ~=~ \\int \\rho(E_f) \\frac{2\\pi}{\\hbar}\\delta (E_f - E_i) |M_{fi}|^2\\textrm{d}E_f.$$\n\nNow assuming that the $M_{fi}$ are constant in the energy range under the integral we get\n\n$$\\Gamma_{fi} ~=~ \\rho(E_i) \\frac{2\\pi}{\\hbar} |M_{fi}|^2.$$\n\nNow this is absolutely not what is written anywhere else. Other sources pull the $\\rho(E_f)$ out of the integral to obtain Fermi's Golden Rule of the form\n\n$$\\Gamma_{fi} ~=~ \\rho(E_f) \\frac{2\\pi}{\\hbar} |M_{fi}|^2$$\n\nfor any $f$ with $E_f$ in $F$ which makes much more physical sense. But why is what I've done wrong? If anything it should be more precise, because I have actually done the integral! Where have I missed something?\n\nshare|improve this question\nIt's the same thing because $E_i=E_f$ in this treatment, isn't it? \u2013\u00a0 Lubo\u0161 Motl Dec 17 '12 at 14:32\nadd comment\n\n1 Answer\n\nAs proposed by Lubos, the delta function you started with $\\delta(E_i-E_f)$ forces the final result to be invariant by $E_i \\leftrightarrow E_f$.\n\nshare|improve this answer\nI'm afraid I don't quite see this - could you expand on your argument perhaps? \u2013\u00a0 Edward Hughes Dec 17 '12 at 15:09\nWell, are you familiar with identity:$$\\delta(x-x_0)f(x) = \\delta(x-x_0)f(x_0)$$ true for distributions, it implies quite directly that you can change $\\rho(E_f)$ for $\\rho(E_i)$ in your second equation. \u2013\u00a0 Learning is a mess Dec 17 '12 at 15:15\nOh of course - apologies for missing that. But surely in general $\\rho(E_i)$ and $\\rho(E_f)$ are different even if $E_i = E_f$? For example the decay of one particle into two gives you an extra degree of freedom in $\\rho(E_f)$ that you didn't have in $\\rho(E_i)$. Or is this logic wrong? \u2013\u00a0 Edward Hughes Dec 17 '12 at 15:18\nDear Edward, you're summing or integrating over $f$ and the integrand depends on $M_{fi}$ and you decided you may eliminate the summation/integral completely. This implicitly means that for each energy $E_f$, the state must actually be unique. Otherwise you would have to keep the sum over the other quantum numbers that commute with the energy. \u2013\u00a0 Lubo\u0161 Motl Dec 17 '12 at 16:17\nI think the point of confusion here is that $\\rho(E)$ is the density of final states. Perhaps the notation would be more clear if $\\rho_f(E)$ were written instead. Now it should be clear that since energy is conserved $\\rho_f(E_f)=\\rho_f(E_i)$. Note that the density of initial states, which you might write as $\\rho_i(E)$ is not equal to $\\rho_f(E)$, as your comment, \"But surely...\" seems to suggest. \u2013\u00a0 MarkWayne Dec 17 '12 at 16:58\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/543131/probability-of-a-result-from-3d6-lowest-to-highest\nText:\nTake the 2-minute tour \u00d7\n\nI have a fascination with tabletop sports games, and through that, I've developed an interest in probability. That said, it's not my strong suit, so I wanted to pose this question because I think involves a few different probability principles to solve it.\n\nHere's the premise...the game uses a roll of 3d6 to determine the result of a play. The dice are read from lowest to highest, as in:\n\na roll of 3, 6, 2 would be 2-3-6 a roll of 1, 4, 1 would be 1-1-4 etc.\n\nThat roll is then looked up on a chart to determine the result.\n\nI was curious about the probability of different results coming up so that if I wanted to make a house rule, I would know which result would be the best place to modify.\n\nSo, what I do know is that for probability, you multiply chances together, correct? So without the low to high rule I discussed above, any number would have a 1/6 * 1/6 * 1/6 chance of occurring, correct?\n\nHow would I apply this principle to any result? My guess is something like:\n\n1-1-4 = 1/6 * 1/6 * 5/6\n\nonly one chance for the first 2 die, and the last can be anything but 1, so 5 remaining numbers\n\n2-3-6 = 1/6 * 4/6 * 4/6\n\nfirst number can be 2 only = 1/6\n\nsecond number can be any number but 2 or 6 = 4/6\n\nsecond number can be any number but 2 or 3 = 4/6\n\nAm I understanding this correctly?\n\nshare|improve this question\nThis is the kind of thing that's really easy to get the computer to do. Complete results are here. \u2013\u00a0 MJD Oct 28 '13 at 18:32\nWouldn't $3,6,2$ be $2-3-6?$ \u2013\u00a0 Ross Millikan Oct 28 '13 at 18:37\nRoss, you're correct, I swear I had that typed correctly when I first posted it incorrectly on the main stack overflow page. I'll fix it... \u2013\u00a0 tjans Oct 29 '13 at 12:53\nadd comment\n\n1 Answer\n\nYour answer's not correct. For 1-1-4, you have multiplied by $\\frac56$, but it's not clear to me why. The correct calculation goes like this: there is a $\\frac16$ probability of getting a 1 on the first die, a $\\frac16$ probability of getting a 1 on the second die, and a $\\frac16$ (not $\\frac56$) probability of getting a 4 on the third die. This multiplies out to $\\frac1{216}$. But there are three different orders in which the rolls could occur to give a result of 1-1-4, since 1-4-1 or 4-1-1 give the same result. So you must multiply the $\\frac1{216}$ by 3, for a final result of $\\frac1{72}$.\n\nSimilarly, the result for 2-3-6 is again $\\frac1{216}$, but this time multiplied by 6 because there are 6 different orders in which the 2, 6, and 3 can appear; the final result is $6\\cdot\\frac1{216}=\\frac1{36}$.\n\nIn general, the answer is as follows: if the pattern you're looking up is XXX, with all three dice the same, the probability is $\\frac1{216}$. If the pattern is XXY or XYY, the probability is $\\frac1{72}$. And if the pattern is XYZ, the probability is $\\frac1{36}$.\n\nshare|improve this answer\nThe 5/6 was me overthinking things. I'll save me the embarrassment by not explaining why I thought it'd be 5/6 :) \u2013\u00a0 tjans Oct 29 '13 at 12:56\nfor 1-1-4, how are there 3 possibilities? Wouldn't there be 6 different ways for that as well, as each die is independent of the other? 1a-1b-4, 1a-4-1b, 1b-1a-4, 1b-4-1a, 4-1a-1b, 4-1b-1a \u2013\u00a0 tjans Oct 29 '13 at 13:03\nSuppose the three dice were red, blue, and green. The 4 can be on the red die, the blue die, or the green die; that's 3 ways. Saying that a green 4, a red 1 and a blue 1 is somehow different from a green 4, a blue 1 and a red 1 makes no sense at all. \u2013\u00a0 MJD Oct 29 '13 at 14:35\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59009/no-complexity-class-contains-all-recursive-languages\nText:\nTake the 2-minute tour \u00d7\n\nI want to prove that there does not exist some complexity class that contains all recursive languages.\n\nAny complexity class C is defined by a complexity measure $\\Phi$ (according to Blum axioms) and a total recursive function f:N $\\rightarrow$ N. So there does not exists C that contains all languages L for which there exists a Turing Machine M that decides L and for all x $\\Phi$(M,x)<=f(|x|).\n\nAny ideas?\n\nshare|improve this question\nI don't get it; doesn't the class R contains all the recursive languages? en.wikipedia.org/wiki/R_(complexity) \u2013\u00a0 Hsien-Chih Chang \u5f35\u986f\u4e4b Mar 21 '11 at 10:06\nThe author means a complexity class in the sense of Blum - en.wikipedia.org/wiki/Blum_axioms \u2013\u00a0 Fran\u00e7ois G. Dorais Mar 21 '11 at 10:38\nThank you Fran\u00e7ois! \u2013\u00a0 Hsien-Chih Chang \u5f35\u986f\u4e4b Mar 21 '11 at 11:02\nHave you looked at en.wikipedia.org/wiki/Blum%27s_speedup_theorem ? \u2013\u00a0 Andr\u00e1s Salamon Mar 21 '11 at 22:49\nThanks for your answer Andr\u00e1s but I really can't see how the speed up theorem implies that C can't exist. \u2013\u00a0 user13788 Mar 22 '11 at 15:34\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nLet $\\langle M_i\\rangle$ be an enumeration of all Turing Machines (TM) and $\\langle f_i\\rangle$ the corresponding ($f_i=f_{M_i}$) enumeration of the functions in $RE$. Suppose there is an $f\\in REC$ such that all the recursive languages are in the complexity class $\\mathcal{C}(f)=${$f_i\\in RE:\\forall x\\ \\Phi(i,x)\\leq f(x)$}.\n\nHere are two ways you can prove this is not possible:\n\n1) $\\Phi(i,x)=y$ is $REC$, thus let $N$ be the TM which computes it. We can use $N$ to construct a new TM $N'$ which takes as input $i$, then calculates $\\Phi(i,x)=y$ for every $x$ and all $y\\leq f(x)$ and it halts iff for some $x$, $\\Phi(i,x)=y$ is false for all $y\\leq f(x)$ or $rng(f_i(x))\\nsubseteq${$0,1$}.\n\nHaving a closer look on $N'$, we see that it recognizes exactly the language\n\n$TOT'=${$i\\in\\mathbb{N}:f_i\\mbox{ not total}\\vee f\\mbox{ is not a relation}$}.\n\nThus $TOT'\\in RE$ which can not be true because it is $\\Sigma_2$-complete. ($\\Sigma_2$ contains the relations which are $RE$ given a $co-RE$ oracle).\n\n2) We use the Recursive Relatedness Theorem, i.e.\n\nSuppose $\\Phi,\\Psi$ be complexity measures. Then there exists an $r(x,y)\\in REC$ s.t.:\n\n(i) $\\forall x,y\\ r(x,y)< r(x,y+1)$;\n\n(ii) $\\forall i\\ \\forall^* x\\ \\Phi(i,x)\\leq r(x,\\Psi(i,x))$; ($\\forall^*$ means for all but finitely many)\n\n(iii) $\\forall i\\ \\forall^* x\\ \\Psi(i,x)\\leq r(x,\\Phi(i,x))$.\n\n(This says roughly that the one measure is bounded by the other using a REC function.)\n\nLet $\\Phi$ be the measure under consideration and $T$ the usual masure of time complexity. By (iii), $T(i,x)\\leq r(x,\\Phi(i,x))$ and since $r$ is increasing for $y$ and $\\Phi(i,x)\\leq f(x)$, we get that $T(i,x)\\leq r(x,f(x))$ for all $i$ s.t. $f_i\\in \\mathcal{C}(f)$.\n\n$r(x,f(x))$ is recursive hence we can get a TM $M_{i_0}$ which given an input $x$ moves $r(x,f(x))+1$ times and halts with output $0$. $f_{i_0}$ realizes a recursive language so it is in $\\mathcal{C}(f)$, which means that $\\forall^* x\\ r(x,f(x))+1=T(i_0,x)\\leq r(x,f(x))$. But this is a contradiction.\n\nIf you want to see the proof that $TOT'$ is $\\Sigma_2$-complete (actually that $TOT=\\mathbb{N}\\setminus TOT'$ is $\\Pi_2$-complete. $TOT$ contains functions instead of relations but you can easily reduce the one to the other) you can check it in p.224 of Computability, complexity and languages of Martin Davis.\n\nInside the same book, you can find the proof of the recursive relatedness theorem in p.422. Actually the whole chapter (14) contains some useful results on abstract complexity.\n\nshare|improve this answer\nThank you Marios! \u2013\u00a0 user13788 Apr 1 '11 at 0:14\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/23053/constructing-the-most-general-two-particle-spin-interaction-with-su2-symme\nText:\nTake the tour \u00d7\n\nSuppose I want to write down an interaction term for an action for spin 1/2 fermions that is $SU(2)$-symmetric.\n\nI start from the most naive general form of such an action: $$S_{int} ~=~ \\int_{4321} \\sum_{\\alpha \\beta \\gamma \\delta} \\bar \\psi(4)_\\alpha \\bar \\psi(3)_\\beta \\psi(2)_\\gamma \\psi(1)_\\delta V(4,3,2,1)_{\\alpha \\beta \\gamma \\delta}$$\n\nwhere the indices $1$ to $4$ stand for momenta and frequencies of my fermions.\n\nNow I want to find the form $V$ must have in order to be $SU(2)$ symmetric. By transforming the fermion fields and demanding that the action must stay invariant under that, I can show that $V$ must transform as $$V_{\\alpha' \\beta' \\gamma' \\delta'} ~=~ \\sum_{\\alpha\\beta\\gamma\\delta} R^\\dagger_{\\alpha \\alpha'} R^\\dagger_{\\beta \\beta'} R_{\\gamma \\gamma'} R_{\\delta \\delta} V_{\\alpha \\beta \\gamma \\delta}$$ where $R \\in SU(2)$.\n\nWell, and now I'm stuck continuing from here. Using some handwaving I think I could argue that $V$ must preserve total spin and also total spin in $z$-direction I could probably argue that $V$ can only scatter triplets to triplets, singlets to singlets, and also can't change the $z$-component of the triplet, but I would rather use a more rigorous approach.\n\nWhich will probably involve irreducible representations? I could probably get to the singlet/triplet statement above by noting that $SU(2)$ will transform multiplets into the same multiplet, so the singlet would be invariant under $SU(2)$ and the triplets would somehow mix. But why is it appropriate then to look at an \"ingoing\" singlet or \"ingoing\" triplet formed by indices $\\gamma$ and $\\delta$ as opposed to forming such states with, e.g., indices $\\alpha$ and $\\gamma$?\n\nADDENDUM: Well, I guess I can also start with the spins in a different basis: Assuming that I can put the two \"ingoing\" and the two \"outgoing\" spins into either a singlet or one of three triplets, I guess I can write the action as $$S \\sim \\int_{1234} \\sum_{jm j'm'} (\\bar \\psi(4) \\bar \\psi(3))_{jm} (\\psi(2) \\psi(1))_{j'm'} V(4,3,2,1)_{jm;j'm'}$$ Then I can first argue that due to conservation of total spin we require $j = j'$. And then for $V$ I can look at singlet-singlet scattering and triplet-triplet scattering separately: For $j = j' = 0$, $m$ must be $0$ and so $V$ is a scalar, invariant under $SU(2)$, But for $j = j' = 1$, the states with $m = 0, \\pm 1$ transform into each other in some way, and thus I must work a bit harder to get the symmetry right. I'll think about this, but in the meantime I'm open for more suggestions.\n\nshare|improve this question\nIs your action going to be renormalizable? In how many dimensions? It's worth noting that in 3+1D renormalizability limits you to no more than two fermion fields in a single term (because each has dimension 3/2, and you need to have dimension 4 total). \u2013\u00a0 David Z Mar 30 '12 at 21:31\nIt's for a condensed matter system so I don't worry about renormalizability; I'll always assume that there is a \"natural\" cut-off \u2013\u00a0 Lagerbaer Mar 30 '12 at 22:10\nOh, OK. Ignore me then :-) \u2013\u00a0 David Z Mar 30 '12 at 23:21\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThis is very much a quick and dirty answer, I havn't though too much about it. I might update my answer if I find time in the weekend, otherwise I hope others will give more precise answers.\n\n$V_{\\alpha\\beta\\gamma\\delta}$ transforms reducibly under $SU(2)$, as tensor products of four spin $\\frac 12$ representations. Using $\\bf\\frac 12\\otimes\\frac 12 = 0 \\oplus 1$ and $\\bf 1\\otimes 1 = 0 \\oplus 1 \\oplus 2$, we find that $V_{\\alpha\\beta\\gamma\\delta}$ decomposes into these irreducible representations $$\\mathbf{\\frac 12\\otimes\\frac 12\\otimes\\frac 12\\otimes\\frac 12} = (2\\times\\mathbf{0})\\oplus (3\\times \\mathbf{1}) \\oplus \\mathbf{2},$$ two singlets, three triplets and a spin 2 (5-dimensional representation). There is an action of the permutation group $S_4$ on the indices of $V_{\\alpha\\beta\\gamma\\delta}$, for $SU(N)$ it turns out that decomposing this tensor into irreducible representations of the permutation group also corresponds to irreducible representations of $SU(N)$. This can be done rather quickly using Young Tableau, you can find the details in most representation theory books for physicists (I don't have a relevant book here and don't remember the details. I might add the answer in the weekend). In the case of a tensor product $\\bf 1\\otimes 1 = 0\\oplus 1\\oplus 2$, we get the following decomposition\n\n$$ T_{ij} = \\delta_{ij}\\frac{tr(T)}3 + \\left(\\frac{T_{ij}-T_{ji}}2\\right) + \\left(\\frac{T_{ij}+T_{ji}}2 - \\delta_{ij}\\frac{tr(T)}3\\right).$$ These three terms transform irreducibly as spin $0$, spin $1$ and spin $2$ representations of $SU(2)$, respectively. In terms for the permutation group, these are the trivial, anti-symmetric and trace less symmetric representations, respectively.\n\nSomething similar can be done for $V_{\\alpha\\beta\\gamma\\delta}$, by using Young Tableau or just by playing around with it.\n\nshare|improve this answer\nHm, when you decompose $V$ into irreducible representations you combine all four spins into total spins of $0$, $1$ or $2$. But should I, given that two of the spins transform in one direction and the other two into the \"opposite\" direction, keep the spins whose operators have a \"bar\" on top separate from those without the bar, i.e. $(0 \\oplus 1) \\otimes (0 \\oplus 1)$? \u2013\u00a0 Lagerbaer Mar 30 '12 at 22:48\nMh, I think I'm just a bit confused. Maybe for clarification: When my general operator $V_{\\alpha\\beta\\gamma\\delta}$ is decomposed as you describe, are then the two singlets the only parts that are invariant under rotation as they transform like scalars? Or am I getting things completely wrong? \u2013\u00a0 Lagerbaer Mar 31 '12 at 5:01\nYou were right; the fact that I get two terms in the action that transform like singlets is related to the irreducible representations: One singlet is obtained by combining two singlets, the other is obtained by combining two triplets. \u2013\u00a0 Lagerbaer Apr 4 '12 at 18:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/109420/is-this-a-known-solvable-problem-system-of-algebraic-equations?answertab=active\nText:\nTell me more \u00d7\n\nHi there,\n\nI am trying to find complex solutions with positive real part $\\{t_j \\;|\\;{\\rm Re}\\;t_j>0, j = 1, 2, 3, \\dots, n\\}$ of the system of equations $$0 = 1 + \\sum_j \\left(t_j^{2l+1} + {t_j^*}^{2l+1}\\right),\\; l = 1,2,3,\\dots m.$$ Where for a given $n$ I would like to make $m$ as large as possible. Since, this system is non-analytic and thus for $n=m$ most likely under-constrained, I had the idea to just fix the magnitude of all solutions to 1: $t_j = e^{i\\phi_j}$ with $-{\\pi\\over 2} < \\phi_1 \\le \\phi_2 \\le \\dots \\le \\phi_n <{\\pi\\over 2}$. In terms of these the system becomes: $$0 = 1 + 2\\sum_j \\cos{\\left[\\phi_j(2l+1)\\right]},\\; l = 1,2,3,\\dots n.$$ This definitely has solutions up to $n=m=2$, but already for $n=3$, my naive attempt at numerically solving this (Mathematica's NSolve) is taking quite long. Is there some better way to find or at least confirm the existence of such solutions?\n\nThanks, Nik\n\nshare|improve this question\nWhat is $t_j^*$? Is that the complex conjugate? \u2013\u00a0 Gerry Myerson Oct 11 '12 at 22:34\nSo letting $\\phi_0=1$ and $\\phi_{-i}=-\\phi_i$ you want that for $0 \\le \\ell \\le m$ the values $(e^{i\\phi_k})^{2\\ell+1}$ for $-n \\le k \\le n$ to have average real part $0$. If they were, in each case, equally distributed around the unit circle, that would suffice. \u2013\u00a0 Aaron Meyerowitz Oct 12 '12 at 0:42\nGerry, yes that is correct, I should have said that! \u2013\u00a0 nik Oct 12 '12 at 15:15\nAaron, yes, but is it possible to use those considerations to construct solutions with ${-\\pi\\over2} < \\phi_j < {\\pi\\over 2}$? I.e. they must lie in the positive half-plane. \u2013\u00a0 nik Oct 12 '12 at 15:22\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nI would try to get rid of the trigonometric functions, and rather rewrite the system as a polynomial system. If $x_j=\\cos(\\phi_j)$, then $\\cos(\\phi_j(2\\ell+1))=T_{2\\ell+1}(x_j)$, where $T_k$ is the $k$-th Chebychev polynomial of degree $k$. So your system of equations is \\begin{equation} 0=1+2\\sum_j T_{2\\ell+1}(x_j),\\;\\;l=1,2,\\dots,m, \\end{equation} with the requirement that $0<x_j\\le 1$. Such a system can be discussed via Groebner bases, see here how to do that with Sage. For $m=n\\le4$ there are only finitely many solutions. Among them pick those which fit your inequalities. For instance, for $m=n=4$, an approximation of a solution seems to be \\begin{align*} x_1 &= 0.963494595276259\\\\ x_2 &= 0.852773246361416\\\\ x_3 &= 0.600336170417163\\\\ x_4 &= 0.058262327046178 \\end{align*} Of course, you can use this technique also to handle the original case, where $t_j$ need not have length $1$. For instance, for $n=2$ one can show that $m\\le4$, and and approximate solution for $m=4$ is $t_1=0.466916296430820 + 0.717248344919154i$, $t_2=0.856453001234213 + 0.445264622297009i$.\n\nOne cannot expect simple expressions for the $t_j$. For instance, the absolute values of the $t_j$ are roots of an irreducible (over the rationals) polynomial of degree $60$.\n\nshare|improve this answer\nThanks! That is very helpful! \u2013\u00a0 nik Oct 12 '12 at 15:25\nSo what does the final solution for $m=n=4$ come out to be? \u2013\u00a0 Aaron Meyerowitz Oct 13 '12 at 4:57\n@Aaron: Not sure what you mean. We have $t_j=e^{i\\phi_j}=\\cos(\\phi_j)+i\\sin(\\phi_j)=x_j\\pm i\\sqrt{1-x_j^2}$. Since nik adds $t_j^{2\\ell+1}$ and its complex conjugate, it does not matter which sign you choose in $\\pm i\\sqrt{1-x_j^2}$ for each $j$. \u2013\u00a0 Peter Mueller Oct 13 '12 at 9:10\nadd comment\n\nConsider the case $m=n=4.$ If we take $t_j=\\cos(\\frac{2j\\pi}{9})+I\\sin(\\frac{2j\\pi}{9})$ then $\\sum_{j=0}^{8}t_j^q= 1 + \\sum_{j=1}^{4} \\left(t_j^{q} + {t_j^*}^{q}\\right)=0$ for $1 \\le q \\le 8.$ This is because the set of values $t_j^q$ is just the nine $9$th roots of unity (or in two cases, the third roots of unity taken three times). Admittedly, this is not exactly what you wanted.\n\nIf you take just the real parts for $j=1,2,3,4$ you get\n\n  \u2022 $t_1=t_1^*=.766044443118979$\n  \u2022 $t_2=t_2^*=.173648177666934$\n  \u2022 $t_3=t_3^*=-.500000000000$\n  \u2022 $t_4=t_4^*=-0.939692620785905$\n\nIt can be seen that this makes $1 + \\sum_{j=1}^4 \\left(t_j^{q} + {t_j^*}^{q}\\right)=0$ correct for $q=1,3,5,7.$\n\nshare|improve this answer\nHmm, maybe I am missing something, but please see my response to your comment above. \u2013\u00a0 nik Oct 12 '12 at 15:24\nadd comment\n\nYour problem may be understood as solving a system of equations and inequalities over $\\mathbb{R}$. It is solvable in the sense that there exists an algorithm to find solutions (e.g. to find a point in every connected component specified by the system just mentioned).\n\nSuch algorithms are desribed, e.g., in this book: \"Algorithms in Real Algebraic Geometry\" by Saugata Basu, Richard Pollack, Marie-Fran\u00e7oise Roy.\n\nHow practical they are at present, is another question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://michaelnielsen.org/polymath1/index.php?title=Finding_narrow_admissible_tuples&diff=7961&oldid=prev\nText:\nFinding narrow admissible tuples\n\nFrom Polymath1Wiki\n\n(Difference between revisions)\nJump to: navigation, search\nm (Benchmarks)\nm (added asymmetric HR entry for 5453 due to Sun)\nLine 182: Line 182:\n| [ 112,562]\n| [ 112,562]\n| [ 53,774]\n| [ 48,484]\n| [ 48,484]\n\nRevision as of 11:54, 19 June 2013\n\nFor any natural number k0, an admissible k0-tuple is a finite set {\\mathcal H} of integers of cardinality k0 which avoids at least one residue class modulo p for each prime p. (Note that one only needs to check those primes p of size at most k0, so this is a finitely checkable condition.) Let H(k0) denote the minimal diameter \\max {\\mathcal H} - \\min {\\mathcal H} of an admissible k0-tuple. As part of the Polymath8 project, we would like to find as good an upper bound on H(k0) as possible for given values of k0. To a lesser extent, we would also be interested in lower bounds on this quantity. There is some scattered numerical evidence that the optimal value of H is roughly of size k0logk0 + k0 for k0 in the range of interest.\n\n\nUpper bounds\n\nUpper bounds are primarily constructed through various \"sieves\" that delete one residue class modulo p from an interval for a lot of primes p. Examples of sieves, in roughly increasing order of efficiency, are listed below.\n\nZhang sieve\n\nThe Zhang sieve uses the tuple\n\n{\\mathcal H} = \\{p_{m+1}, \\ldots, p_{m+k_0}\\}\n\nwhere m is taken to optimize the diameter p_{m+k_0}-p_{m+1} while staying admissible (in practice, this basically means making m as small as possible). Certainly any m with pm + 1 > k0 works; in particular, one can just take {\\mathcal H} to be the first k0 primes past k0, but this is not optimal. Applying the prime number theorem then gives the upper bound H \\leq (1+o(1)) k_0\\log k_0.\n\nHensley-Richards sieve\n\nThe Hensley-Richards sieve [HR1973], [HR1973b], [R1974] uses the tuple\n\n{\\mathcal H} = \\{-p_{m+\\lfloor k_0/2\\rfloor - 1}, \\ldots, -p_{m+1}, -1, +1, p_{m+1},\\ldots, p_{m+\\lfloor k_0/2+1/2\\rfloor-1}\\}\n\nwhere m is again optimised to minimize the diameter while staying admissible.\n\nAsymmetric Hensley-Richards sieve\n\nThe asymmetric Hensley-Richard sieve uses the tuple\n\n{\\mathcal H} = \\{-p_{m+\\lfloor k_0/2\\rfloor - 1-i}, \\ldots, -p_{m+1}, -1, +1, p_{m+1},\\ldots, p_{m+\\lfloor k_0/2+1/2\\rfloor-1+i}\\}\n\nwhere i is an integer and i,m are optimised to minimize the diameter while staying admissible.\n\nSchinzel sieve\n\nGiven 0 < y < z < x, the Schinzel sieve (discussed in [S1961], [HR1973], [GR1998], [CJ2001]) sieves the interval [1,x] by 1mod p for primes p \\le y and by 0mod p for primes y < p \\le z. Provided that z is large enough (z = k0 clearly suffices), the first k0 survivors form an admissible k0-tuple (but not necessarily the narrowest one in the interval). The case y = 1 corresponds to a sieve of Eratosthenes; if one minimizes z and takes the first k0 survivors greater than 1, this yields the same admissible k0 tuple as Zhang, with the minimal possible value of m.\n\nShifted Schinzel sieve\n\nAs a generalization of the Schinzel sieve, one may instead sieve shifted intervals [s,s + x]. This is effectively equivalent to sieving the interval [0,x] of the residue classes -s\\ \\bmod\\ p for primes p\\le y and  1-s\\ \\bmod\\ p for primes y<p\\le z.\n\nGreedy sieve\n\nWithin a given interval, one sieves a single residue class amod p for increasing primes p=2,3,5,\\ldots, with a chosen to maximize the number of survivors. Ties can be broken in a number of ways: minimize a\\in[0,p-1], maximize a\\in [0,p-1], minimize |a-\\lfloor p/2\\rfloor|, or randomly. If not all residue classes modulo p are occupied by survivors, then a will be chosen so that no survivors are sieved. This necessarily occurs once p exceeds the number of survivors but typically happens much sooner. One then chooses the narrowest k0-tuple {\\mathcal H} among the survivors (if there are fewer than k0 survivors, retry with a wider interval).\n\nGreedy-greedy sieve\n\nHeuristically, the performance of the greedy sieve is significantly improved by starting with a shifted Schinzel sieve on [s,\\ s+x] using y = 2 and z = \\sqrt{x} and then continuing in a greedy fashion, as proposed by Sutherland. One first optimizes the shift value s over some larger interval (e.g. [-k_0\\log\\ k_0,\\ k_0\\log\\ k_0]) and then continues the sieving over primes p > z greedily choosing the best residue class for each prime according to a chosen tie-breaking rule (in Sutherland's original implementation, ties are broken downward in [0,\\ p-1]).\n\nSeeded greedy sieve\n\nGiven an initial sequence {\\mathcal S} that is known to contain an admissible k0-tuple, one can apply greedy sieving to the minimal interval containing {\\mathcal S} until an admissible sequence of survivors remains, and then choose the narrowest k0=tuple it contains. The sieving methods above can be viewed as the special case where {\\mathcal S} is the set of integers in some interval. The main difference is that the choice of {\\mathcal S} affects when ties occur and how they are broken with greedy sieving. One approach is to take {\\mathcal S} to be the union of two k0-tuples that lie in roughly the same interval (see Iterated merging) below.\n\nIterated merging\n\nGiven an admissible k0-tuple \\mathcal{H}_1, one can attempt to improve it using an iterated merging approach suggested by Castryck. One first uses a greedy (or greedy-Schinzel) sieve to construct an admissible k0-tuple \\mathcal{H}_2 in roughly the same interval as \\mathcal{H}_1, then performs a randomized greedy sieve using the seed set \\mathcal{S} = \\mathcal{H}_1 \\cup \\mathcal{H}_2 to obtain an admissible k0-tuple \\mathcal{H}_3. If \\mathcal{H}_3 is narrower than \\mathcal{H}_2, replace \\mathcal{H}_2 with \\mathcal{H}_3, otherwise try again with a new \\mathcal{H}_3. Eventually the diameter of \\mathcal{H}_2 will become less than or equal to that of \\mathcal{H}_1. As long as \\mathcal{H}_1\\ne \\mathcal{H}_2, one can continue to attempt to improve \\mathcal{H}_2, but in practice one stops after some number of retries.\n\nAs described by Sutherland, one can then replace \\mathcal{H}_1 with \\mathcal{H}_2 and begin the process anew, yielding a randomized algorithm that can be run indefinitely. Key parameters to this algorithm are the choice of the interval used when constructing \\mathcal{H}_2, which is typically made wider than the minimal interval containing \\mathcal{H}_1 by a small factor \u03b4 on each side (Sutherland suggests \u03b4 = 0.0025), and the number of failed attempts allowed while attempting to impove \\mathcal{H}_2.\n\nEventually this process will tend to converge to particular \\mathcal{H}_1 that it cannot improve (or more generally, a set of similar \\mathcal{H}_1's with the same diameter). Interleaving iterated merging with the local optimizations described below often allows the algorithm to make further progress.\n\nIterated merging can be viewed as a form of simulated annealing. The set \\mathcal{S} initially contains at least two admissible k0-tuples (typically many more), and as the algorithm proceeds the set \\mathcal{S} converges toward \\mathcal{H}_1 and the number of admissible k0-tuples it contains declines. One can regard the cardinality of the difference between \\mathcal{S} and \\mathcal{H}_1 as a measure of the \"temperature\" of a gradually cooling system, since the number of choices available to the algorithm declines as this cardinality is reduced (more precisely, one may consider the entropy of the possible sequence of tie-breaking choices available for a given \\mathcal{S}).\n\nLocal optimizations\n\nLet \\mathcal H = \\{h_1,\\ldots, h_{k_0}\\} be an admissible k0-tuple with endpoints h1 and h_{k_0}, and let \\mathcal I be the interval [h_1,h_{k_0}]. If there exists an integer h\\in\\mathcal I such that removing one of \\mathcal H's endpoints and inserting h yields an admissible k0-tuple \\mathcal H', then call \\mathcal H contractible, and if not, say that \\mathcal H non-contractible. Note that \\mathcal H' necessarily has smaller diameter than \\mathcal H. Any of the sieving methods described above may produce admissible k0-tuples that are contractible, so it is worth testing for contractibility as a post-processing step after sieving and replacing \\mathcal H by \\mathcal H' if this test succeeds.\n\nWe can also shift \\mathcal H to the left by removing its right end point h_{k_0} and replacing it with the greatest integer h0 < h1 that yields an admissible k0-tuple \\mathcal H', and we can similarly shift \\mathcal H to the right. The diameter of \\mathcal H' need not be less than \\mathcal H, but if it is, it provides a useful replacement. More generally, by shifting \\mathcal H repeatedly we can produce a sequence of admissible k0-tuples that lie successively further to the left or right. In general the diameter of these tuples may grow as we do so, but it will also occasionally decline, and we may be able to find a shifted \\mathcal H' with smaller diameter than \\mathcal H.\n\nA more sophisticated local optimization involves a process of ``adjustment\" proposed by Savitt. Let \\mathcal H be an admissible k0-tuple. For a prime p and an integer a, let [a;p] denote the residue class amod p, i.e. the set of integers {x:x = amod p}. Call [a;p] occupied if it contains an element of \\mathcal H .\n\nSuppose that [a;p] and [b;q] are occupied residue classes, for some distinct primes p and q, and that [a';p] and [b';q] are unoccupied. Let \\mathcal U be the intersection of \\mathcal H with [a;p] \\cup [b;q], and let \\mathcal V be a subset of the integers that lie in the intersection of the interval I containing H and the set [a';p] \\cup [b';q] such that the set \\mathcal H' formed by removing the elements of \\mathcal U from \\mathcal H and adding the elements of \\mathcal V is admissible. A necessary (and often sufficient) condition for and integer v to lie in \\mathcal V is that v must not lie in a residue class [c;r] that is the unique unoccupied residue class modulo r for any prime r other than p or q.\n\nThe admissible set \\mathcal H' lies in the interval \\mathcal I containing \\mathcal H, so its diameter is no greater than that of \\mathcal H, however its cardinality may differ. If it happens that \\mathcal H' contains more elements than \\mathcal H , then by eliminating points at either end of \\mathcal H' we obtain an admissible k0-tuple that is narrower than \\mathcal H and may ``adjust\" \\mathcal H by replacing it with \\mathcal H' . The process of adjustment can often be applied repeatedly, yielding a sequence of successively narrower admissible k0-tuples.\n\nFurther refinements\n\nLower bounds\n\nThere is a substantial amount of literature on bounding the quantity \u03c0(x + y) \u2212 \u03c0(x), the number of primes in a shifted interval [x + 1,x + y], where x,y are natural numbers. As a general rule, whenever a bound of the form\n\n \\pi(x+y) - \\pi(x) \\leq F(y) (*)\n\nis established for some function F(y) of y, the method of proof also gives a bound of the form\n\n k_0 \\leq F( H(k_0)+1 ). (**)\n\nIndeed, if one assumes the prime tuples conjecture, any admissible k0-tuple of diameter H can be translated into an interval of the form [x + 1,x + H + 1] for some x. In the opposite direction, all known bounds of the form (*) proceed by using the fact that for x > y, the set of primes between x + 1 and x + y is admissible, so the method of proof of (*) invariably also gives (**) as well.\n\nExamples of lower bounds are as follows;\n\nBrun-Titchmarsh inequality\n\nThe Brun-Titchmarsh theorem gives\n\n \\pi(x+y) - \\pi(x) \\leq (1 + o(1)) \\frac{2y}{\\log y}\n\nwhich then gives the lower bound\n\n H(k_0) \\geq (\\frac{1}{2}-o(1)) k_0 \\log k_0.\n\nMontgomery and Vaughan deleted the o(1) error from the Brun-Titchmarsh theorem [MV1973, Corollary 2], giving the more precise inequality\n\n k_0 \\leq 2 \\frac{H(k_0)+1}{\\log (H(k_0)+1)}.\n\nFirst Montgomery-Vaughan large sieve inequality\n\nThe first Montgomery-Vaughan large sieve inequality [MV1973, Theorem 1] gives\n\n k_0 (\\sum_{q \\leq Q} \\frac{\\mu^2(q)}{\\phi(q)}) \\leq H(k_0)+1 + Q^2\n\nfor any Q > 1, which is a parameter that one can optimise over (the optimal value is comparable to H(k0)1 / 2).\n\nSecond Montgomery-Vaughan large sieve inequality\n\nThe second Montgomery-Vaughan large sieve inequality [MV1973, Corollary 1] gives\n\n k_0 \\leq (\\sum_{q \\leq z} (H(k_0)+1+cqz)^{-1} \\mu(q)^2 \\prod_{p|q} \\frac{1}{p-1})^{-1}\n\nfor any z > 1, which is a parameter similar to Q in the previous inequality, and c is an absolute constant. In the original paper of Montgomery and Vaughan, c was taken to be 3 / 2; this was then reduced to \\sqrt{22}/\\pi [B1995, p.162] and then to 3.2 / \u03c0 [M1978]. It is conjectured that c can be taken to in fact be 1.\n\n\nEfforts to fill in the blank fields in this table are very welcome.\n\nk03,500,000 181,000 34,429 26,024 23,283 22,949 10,719 6,329 5,453 5,000\nUpper bounds\nFirst k0 primes past k0 59,874,594 2,530,338 420,878 310,134 275,082 270,698 117,714 65,924 55,892 50,840\nZhang sieve 59,093,364 2,486,370 411,932 303,558 268,536 264,414 114,806 64,176 54,488 49,578\nHensley-Richards sieve 57,554,086 2,422,558 402,790 297,454 262,794 258,780 112,868 63,708 48,634\nAsymmetric Hensley-Richards 2,418,054 401,700 296,154 262,286 258,302 112,562 53,774 48,484\nShifted Schinzel sieve 2,413,228 400,512 295,162 262,206 258,000 112,440 48,726\nGreedy-greedy sieve 2,326,476 388,076 286,308 253,968 249,992 108,694 46,968\nBest known tuple 57,554,086 2,326,476 386,382 285,210 252,804 248,898 108,450 60,726 51,526 46,810\nk0logk0 + k0 56,238,957 2,372,232 394,096 290,604 257,405 253,381 110,119 61,727 52,371 47,586\nLower bounds\nInclusion-exclusion 29,508,018 1,513,556 193,420 85,878 49,464 38,048\nPartitioning 156,614 73,094 43,130 34,068\nMV with c = 1 (conjectural) 32,503,908 1,395,694 234,872 173,420 153,691 151,298 66,314 37,274 28,781\nMV with c = 3.2 / \u03c0 32,469,985 1,393,869 234,529 173,140 153,447 151,056 66,211 37,207 28,737\nMV with c=\\sqrt{22}/\\pi 31,765,216 1,357,096 227,078 167,860 148,719 146,393 63,917 35,903 27,708\nSecond Montgomery-Vaughan 31,756,667 1,356,644 226,987 167,793 148,656 146,338 63,886 35,887 27,696\nBrun-Titchmarsh 30,137,225 1,272,083 211,046 155,555 137,756 135,599 58,863 32,916 25,351\nFirst Montgomery-Vaughan 28,080,007 1,184,954 196,729\n\n\n\n\n\n128,971 126,931 55,149\n\n\n30,982 24,012\n\n\nk0 4,000 3,405 3,000 2,000 1,000 672 342\nUpper bounds\nFirst k0 primes past k0 39,660 33,222 28,972 18,386 8,424 5,406 2,472\nZhang sieve 38,596 32,296 28,008 17,766 8,212 5,216 2,414\nHensley-Richards sieve 38,498 31,820 27,806 17,726 8,258 5,314\nAsymmetric Hensley-Richards 37,932 27,638 17,676 8,168 5,220\nShifted Schinzel sieve 38,168 27,632 17,616 8,160 5,196\nGreedy-greedy sieve 36,756 26,754 17,054 7,854 5,030\nBest known tuple 36,612 30,600 26,606 16,978 7,802 5,010* 2,328\nEngelsma data 36,622 30,606 26,622 16,978 7,802 4,998 2,328\nk0logk0 + k0 37,176 31,098 27,019 17,202 7,907 5,046 2,338\nLower bounds\nInclusion-exclusion 29,746 21,884 14,082\nPartitioning 27,248 20,434 13,620 6,802 4,574 342\nMV with c = 1 (conjectural) 22,564 18,898 16,456 10,500 4,858 3,124\nMV with c = 3.2 / \u03c0 22,523 18,866 16,428 10,480 4,847 3,118\nMV with c=\\sqrt{22}/\\pi 21,701 18,153 15,758 10,061 4,648 2,979\nSecond Montgomery-Vaughan 21,690 18,143 15,751 10,056 4,645 2,977\nBrun-Titchmarsh 19,785 16,536 14,358 9,118 4,167 2,648\nFirst Montgomery-Vaughan 18,768\n\n\n15,783 13,696 8,448\n\n\n3,959 2,558\n\nThe bold number indicates the best currently known result for a twin-prime-like theorem.\n\n* indicates that the widths listed are the best known tuples that have been found by the methods that gave the entries for larger values of k0, but are not as narrow as the literally best known tuples (due to Engelsma). For k0=342 and below the exact values of H(k0) have been determined by Engelsma (each is one less than the corresponding value of w listed in his tables).\n\nFor the Zhang tuples the optimal m < \u03c0(1010) that produced an admissible k0-tuple was used. This is not always the least m that produces an admissible k0-tuple; for k0 = 22,949, for example, the minimal m = 586 yields an admissible k0-tuple of diameter of 264,460, but m = 599 yields a narrower admissible k0-tuple with the listed diameter of 264,414. A list of table entries for which this occurs can be found here (and also for k0=6,329).\n\nThe shifted Schinzel tuples were generated with y = 2 using an optimally chosen interval contained in [ \u2212 k0logk0,k0logk0] (the interval is not in every case guaranteed to be optimal, particularly for larger values of k0, but it is believed to be so).\n\nThe greedy-greedy tuples were generated using Sutherland's original algorithm, breaking ties downward in every case (and the optimal interval in [ \u2212 k0logk0,k0logk0] was selected on this basis). As noted by Castryck, breaking ties upward may produce better results in some cases.\n\nThe lower bounds listed under in the inclusion-exclusion and partitioning rows due to Avishay and computed as described in this document (the case k0=342 corresponds to the trivial partition).\n\nPersonal tools"}
{"text": "Retrieved from http://math.stackexchange.com/questions/102090/how-do-i-evalulate-a-fraction-example-1-998001-accurately-to-100-decimal-place\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to evaluate a decimal expansion of a fractional value to a large number of digits of precision (in this example 100):\n\n\nI am trying to do this in wxMaxima, that's what the expression above works in. It's trying to take a high precision floating point value numerator and denominator, and evaluate them to a particular precision (100 digits).\n\nMy trouble is perhaps just a display issue in Maxima:\n\n    1.0020030040050060070080090100[44 digits]920930940950960970980991001b-6\n\nI am not sure what the above means, but I think it means that the middle 44 digits are not being shown on the screen even though they are available internally. What I was hoping for would be:\n\n  1. A way to get the period of the repeating decimal, if there is one,\n\n  2. The full precision (100 digits as requested above) shown on the screen as the result.\n\nPerhaps I'm just doing it wrong. So my question is really (a) how can I determine a precise value for the above, and (b) do something similar to what wolfram alpha does with respect to showing me the period of a repeating decimal if the expansion is periodic. It is very interesting that Wolfram Alpha automatically reports the period of the decimal expansion, if it repeats.\n\nshare|improve this question\nYou could also create a free account at sagenb.org and enter: ((10^3-1)^(-2)).n(digits=100). If you want to see it without scientific notation, add one to it before formatting (and ignore it in the output). \u2013\u00a0 bgins Jan 24 '12 at 20:38\nthanks. Maybe that's easier than getting this to work in maxima. It works fine in Wolfram Alpha, but I'd like a real app on my computer that I can learn to do stuff in. (The goal is to learn to do some math in a math program.) sage for windows appears to be dead... \u2013\u00a0 Warren P Jan 24 '12 at 20:48\nFor windows try this: sagemath.org/download-windows.html \u2013\u00a0 bgins Jan 24 '12 at 21:13\nThat's not really a windows version. It's a complete virtual machine packaged as an appliance. :-) I may as well just install the Linux version in my linux vm. \u2013\u00a0 Warren P Jan 24 '12 at 21:45\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\n$$ \\frac{1}{(1000-1)^2} =\\frac{10^{-6}}{(1-\\frac{1}{1000})^2} =\\frac{10^{-6}}{(1-x)^2} =10^{-6}\\left(\\sum_{n=0}^{\\infty}x^n\\right)^2 =10^{-6}\\sum_{n=1}^{\\infty}nx^{n-1} $$ for $x=.001$, which has no carries in its decimal expansion for $n<1000$. Thus the first $1000$ triplets ($3000$ digits after the decimal place) will be $0.000\\;001\\;002\\;003\\;\\dots\\;996\\;997\\;999\\;000$, which brings us up to the first digit which receives a carry. If you want to see it without the scientific notation, add one before formatting. In sage:\n\n(1+(10^3-1)^(-2)).n(digits=3001) # ignore the leading one in the output!\n\nor in scientific notation:\n\n((10^3-1)^(-2)).n(digits=3001) # note the e-6 at the end, meaning times 10^{-6}\n\nAs to the formula above, it can be derived by differentiation: $$ \\left(\\sum_{n=0}^{\\infty}x^n\\right)^2 =(1-x)^{-2} =\\frac{d}{dx}(1-x)^{-1} =\\frac{d}{dx}\\left(\\sum_{n=0}^{\\infty}x^n\\right) =\\sum_{n=1}^{\\infty}nx^{n-1} \\qquad\\text{for} \\qquad|x|<1 $$\n\nshare|improve this answer\nThis is really cool. I am now going to check out sage on Linux since it seems kind of \"not much supported\" on Windows. \u2013\u00a0 Warren P Jan 24 '12 at 21:42\n\nLooks like this works:\n\nfpprec : 100;\n\nThe first command (set display) is found in the menus as Hans stated, under \"Maxima -> Change 2d display\".\n\nThanks to Hans Ludmark for the link.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/183267/does-sum-lnn-n3-converge/183269\nText:\nTake the 2-minute tour \u00d7\n\nBy Direct Comparison Test:\n\n$$\\ln(n)/n^3 < n/n^3 = 1/n^2 $$\n\nConverges as that is a convergent a p-series\n\nBy n'th term Test:\n\n$$(\\ln(n))' = 1/n$$\n\n$$(n^3)' = 3n^2$$\n\n$$\\lim_{n\\to\\infty} (1/n) / 3n^2 = \\lim_{n\\to\\infty} (3n^2)/n =\\lim_{n\\to\\infty} 3n = \\infty$$\n\nso by $n$'th term it diverges.\n\nWhat am I doing wrong?\n\nshare|improve this question\n$\\frac{a}{b}\\neq a*b$. \u2013\u00a0 rschwieb Aug 16 '12 at 16:23\n\n4 Answers 4\n\nup vote 5 down vote accepted\n\nYou made an algebraic mistake. You have the quotient $$ 1/n\\over 3n^2.$$ If you wish to \"move the numerator $1/n$ downstairs\", you need to take its reciprocal, ${1\\over 1/n}=n$, first and do it: $$ {\\color{maroon}{1/n}\\over 3n^2}={1\\over \\color{maroon}n\\cdot 3n^2}. $$ You did this correctly.\n\nHowever, when you \"moved the denominator $3n^2$ upstairs\", you failed to use its reciprocal $1/3n^2$. Done correctly, you would have obtained $$ {1/n\\over\\color{maroon}{ 3n^2}}={(1/n)\\cdot(\\color{maroon}{1/3n^2})\\over1 }. $$\n\nNote both methods give $1\\over 3n^3$ as a result; there is no need to do both. Perhaps the simplest thing to do in order to simplify your expression is to write $$ {1/n\\over 3n^2}={1\\over n}\\cdot{1\\over 3n^2}={1\\over n\\cdot3n^2}={1\\over 3n^3}. $$\n\nshare|improve this answer\n\nYou have a \"typo\". The terms do go to zero: $\\displaystyle \\lim_{n\\to \\infty}\\frac{(1/n)}{3n^2}=\\lim_{n\\to\\infty}\\frac{1}{3n^3}=0$.\n\nshare|improve this answer\n\nYou got the division wrong. $$(1/n)/3n^2 = 1/3n^3 \\rightarrow 0$$\n\nshare|improve this answer\n\nYou're nth term test is wrong. The reason why you're getting a divergent limit is because you flipped your fractions around inccorectlly. Anyways, the nth term test dosen't involve taking derivitives. But, here is how you can do it:\n\n$\\frac{ln(n)}{n^3}>0$ for sufficently large n (i.e n>3). Now, we have that $0<\\frac{ln(n)}{n^3}<\\frac{1}{n^2}$. Clearly, $\\frac{1}{n^2}\\rightarrow 0$. Hence, by the squeeze theorem for limits, $\\frac{ln(n)}{n^3}$ $\\rightarrow 0$. Also, always remember that the nth term test is not sufficent to prove convergance, it's just a nessacary condition. i.e the harmonic series.\n\nshare|improve this answer\nHe's taking derivatives in line with L'Hopital's rule. \u2013\u00a0 process91 Aug 16 '12 at 16:50\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/74173/how-do-we-describe-standard-matrix-multiplication-using-tensor-products?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $V$ be a finite dimensional vector space over a field $F$. Consider the bilinear map $End(V) \\times End(V) \\rightarrow End(V)$ given by $(u,v) \\rightarrow u \\circ v$ and the map associated linear map of tensor productsw $m : End(V) \\otimes End(V) \\rightarrow End(V)$.\n\nI am interested in how we can identify an element of the tensor product $End(V)^* \\otimes End(V)^* \\otimes End(V)$ with the map $m$ which apperently is just another way to describe standard multiplication of matrices. In any case the question can be formulated as follows:\n\nHow do we identify $m$ with an element $u^* \\otimes v^* \\otimes w \\in End(V)^* \\otimes End(V)^* \\otimes End(V)$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI believe it will be a sum of tensors, not a simple tensor. Choosing a basis of $V$, there is an element $u^* = a_{ij}$ that takes a matrix $A$ and gives you its $i,j$th entry. Set $b_{ij} = a_{ij}$ to be a nicer name for $v^*$, and $e_{ij}$ to be the matrix unit with a 1 in the $i,j$th spot, and 0 elsewhere. Then the matrix multiplication element is: $$ \\mu = \\sum_{i=1}^n \\sum_{j=1}^n \\sum_{k=1}^n a_{ij} \\otimes b_{jk} \\otimes e_{ik}$$ In other words, it is just the formula for matrix multiplication with some tensor products instead of multiplication signs.\n\nshare|improve this answer\nadd comment\n\nDepending on taste, one might also have the \"motion\" go in the opposite direction: with $v\\otimes \\lambda$ an endomorphism given by $(v\\otimes \\lambda)(w)=\\lambda(w)\\cdot v$, for $v,w\\in V$ and $\\lambda\\in V^*$, the multiplication/composition of endomorphisms is $$ (v\\otimes \\lambda)\\circ (w\\otimes \\mu) \\;=\\; \\lambda(w)\\cdot v\\otimes \\mu $$ for $v,w\\in V$ and $\\lambda,\\mu\\in V^*$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/414023/probability-of-winning-the-game-1-2-3\nText:\nTake the 2-minute tour \u00d7\n\nOk, game is as follow, with spanish cards (you can do it with poker cards using the As as a 1)\n\nYou shuffle, put the deck face bottom, and start turning the cards one by one, saying a number each time you turn a card around ---> 1, 2, 3; 1, 2, 3; etc. If when you say 1 a 1 comes out, you lose, same with 2 and 3. If you finish the deck without losing, you win.\n\nI know some basics of probabilities, but is there a way to calculate the probability of winning the game, given a random shuffled deck?\n\nshare|improve this question\nCan you name any number $1 \\to 13$ while turning the cards? I.e. whats the range of the numbers you may name? \u2013\u00a0 JohnWO Jun 7 '13 at 17:28\nIs the player allowed to say 1, 2, or 3 at random or does he/she always have to follow the sequence 1,2,3,1,2,3,...? \u2013\u00a0 iX3 Jun 7 '13 at 17:52\nIf one wants something more general; If one could name any numerical value of a card in the deck, i.e.: If there are 52 cards in the deck, divided over 4 suits, which range from $1 \\to 13$, counting $\\text{Ace's}$ as $1$, you would have $13$ different choices. So the chances of loss are approx.: $\\frac{d}{r^2\\;s}$, where $d$ denotes the number of cards left in the deck, and $r$ denotes the numberical range of the cards in the deck, and $s$ denotes the number of suits. \u2013\u00a0 JohnWO Jun 7 '13 at 17:54\nMonte Carlo method shows the probability of $\\approx 0.008$, so the approximation with $\\left(\\frac 2 3\\right)^{12}$ is for this deck size already good enough. \u2013\u00a0 Harold Jun 7 '13 at 18:32\nYes, i am sorry, you can't say any number, you have to say JUST 1, 2, 3, 1, 2, 3, 1, 2, 3, repeat. \u2013\u00a0 Pphax Jun 7 '13 at 22:17\nadd comment\n\n3 Answers\n\nup vote 3 down vote accepted\n\nFor $i,j\\in\\{1,2,3\\}$, let $a_{i,j}$ denote the number of $i$ cards being dealt with number $j$ spoken. We have $\\sum_j a_{i,j}=4$ and for a winning game $a_{i,i}=0$. The number of winning positions for a given $(a_{i,j})$ is $$\\frac{18!}{a_{2,1}!a_{3,1}!(18-a_{2,1}-a_{3,1})!}\\cdot\\frac{17!}{a_{1,2}!a_{3,2}!(17-a_{1,2}-a_{3,2})!}\\cdot\\frac{17!}{a_{1,3}!a_{2,3}!(17-a_{1,3}-a_{2,3})!}. $$ We need to sum this over all $(a_{i,j})$ and divide by the total count $$ \\frac{52!}{4!4!4!40!}.$$ (Actually, we need just let $a_{1,2}, a_{2,3}, a_{3,1}$ run from $0$ to $4$ and this determines $a_{1,3}=4-a_{1,2}$ etc.) The final result is $$p=\\frac{58388462678560}{7151046448045500}=\\frac{24532967512}{3004641364725}\\approx 0.008165 $$ (I just noted that Harold has performed a Monte Carlo simulation with matching result)\n\nshare|improve this answer\nI did calculate the precise probability too, also using combinatorics, but this formula looks so terrifying for me :) I like the approximation explained by Byron Schmuland more. But it would be intresting to find some simplier way for a common case, it should defenitely exist. \u2013\u00a0 Harold Jun 7 '13 at 19:16\nadd comment\n\nAnother update:\n\nAs explained in the paper below, you can use rook polynomials to solve such problems. Playing with a full deck of 52 cards we will call \"one\" 18 times, we will call \"two\" 17 times, and we will call \"three\" 17 times. The forbidden positions in the 52 by 52 board consist of three \"independent\" complete rectangles; one $18\\times 4$ and the other two $17\\times 4$.\n\nThe rook polynomial for a full $m\\times n$ rectangle with $m\\geq n$ is $$\\sum_{k=0}^n{m\\choose k}\\, {n!\\over (n-k)!}\\, x^k. $$\n\nMultiply the polynomials for these three rectangles to give us the rook polynomial for our problem\n\nThe number of winning deck orders is $$\\int_0^\\infty x^N R(-1/x) \\exp(-x)\\,dx $$ so the probability is this divided by $N!$, i.e. $$\\mathbb{P}(\\text{win})= 24532967512/3004641364725= 0.008165023553.$$\n\n\nUpdate: The solution below is for a simplified version of the problem where you work with a deck of size 12: four each of ace, deuce, and trey.\n\nThis is a problem in generalized derangements and joriki's answer here tells you what to do. In general, the number of deck orders that lead to a win is $$\\int_0^\\infty L_{n_1}(x)\\cdots L_{n_r}(x)\\,\\mathrm e^{-x}\\mathrm dx.$$\n\nIn this problem, we have $r=3$ and $n_1=n_2=n_3=4$. The fourth Laguerre polynomial is $L_4(x)=(x^4-16x^3+72x^2-96x+24)/24$. Raising this to the third power and integrating against $\\exp(-x)$ gives $346$. That is, there are $346$ ways to order the deck that give a win.\n\nDivide this by the total number of orders $12!/(4!)^3$, to give $$\\mathbb{P}(\\text{win})=173/17325=0.00998.$$\n\nshare|improve this answer\nWhy does your answer differ significantly from Harold's Monte Carlo result? \u2013\u00a0 Hagen von Eitzen Jun 7 '13 at 19:05\nI am playing with a deck of size 12: four each of ace, deuce, trey. \u2013\u00a0 Byron Schmuland Jun 7 '13 at 19:07\nNow I'm playing with a full deck! \u2013\u00a0 Byron Schmuland Jun 7 '13 at 20:04\nThank you Byron, i chose Hagen's answer because he answered first, but yours is very clear too. \u2013\u00a0 Pphax Jun 7 '13 at 22:44\nadd comment\n\nThis is a hard question, if the player is using optimal strategy rather than just cycling through numbers.\n\nFor example, once the deck is down to 2 cards the player is guaranteed a win, because those two cards are known and (even if they're different) the player can name the third number. If the deck is down to 3 cards the player is guaranteed a win unless those last three cards are all different, in which case the player can't do better than guessing at random (2/3 chance) of winning.\n\nFull analysis for a deck of size 6: 2 each of $1,2,3$.\nCard 1: random, 1/3 chance of loss\nCard 2: guess whatever card 1 was, 1/5 chance of loss (if top two cards are the same)\nCard 3: guess either of the first two cards, 1/4 chance of loss\nWe now have two situations. If the first three cards are all different, there is a further 1/3 chance of loss, based on the analysis in the paragraph above, otherwise a win is assured. Each case happens half the time; two each of the four cards lead to the two cases.\n\nAltogether, the probability of loss is: $$\\frac{1}{3}+\\frac{2}{3}\\frac{1}{5} + \\frac{2}{3}\\frac{4}{5}\\frac{1}{4} + \\frac{2}{3}\\frac{4}{5}\\frac{3}{4}\\frac{1}{2}\\frac{1}{3}=\\frac{2}{3}$$\n\nThis seems too good to be true, but there it is.\n\nshare|improve this answer\nI may be misunderstanding, but I thought the player is required to call $1,2,3,1,2,3,1,\\ldots$ in that order with no scope for strategy. \u2013\u00a0 MJD Jun 7 '13 at 19:02\n@iX3 asked this question but received no answer. \u2013\u00a0 vadim123 Jun 7 '13 at 19:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/225972/bounds-for-the-size-of-a-circle-with-a-fixed-number-of-integer-points\nText:\nTake the 2-minute tour \u00d7\n\nI know that there are infinitely many rational points on the (unit) circle. I am interested in the following question:\n\nHow large has the radius of a circle to be, such that there are at least $n$ integer (lattice) points on it?\n\nActually, I am not interested in the precise number, but in some reasonable good upper bound $f(n)$. Something like, there is a circle of radius $\\leq f(n)$ that has least $n$ integer points.\n\nshare|improve this question\nThe radius must be at least about $\\sqrt{\\frac{n}{\\pi}}$. Also see: en.wikipedia.org/wiki/Gauss_circle_problem \u2013\u00a0 Dan Brumleve Oct 31 '12 at 10:13\n@DanBrumleve: Sorry, but my question was ambiguous. I meant integer points on the circle and not inside the circle. I made the question more precise. \u2013\u00a0 A.Schulz Oct 31 '12 at 10:26\nHere is a lousy bound. There are $4(e+1)$ representations of $5^e$ as a sum of two squares of integers. \u2013\u00a0 Andr\u00e9 Nicolas Oct 31 '12 at 11:10\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nEdit: In the following I suppose that the center of the circle is $(0,0)$ and this extent easily to the case where the center is a lattice point.\n\nIf the radius of a circle is $r$ and we have $n$ lattice points on it (of cource $4|n$) then $r^2 \\in \\mathbb{N}$ and $r^2$ can be written as sum of two squares in $n$ different ways (assuming of course that $(a,b) \\neq (-a,b)$ and $(a,b) \\neq (b,a)$ for $a \\neq b$).\n\nSo if you are asking if there is a function $f$ s.t. if $k \\leq f(n)$ then $k$ can be written as sum of two squares in at least $n$ different ways then according to this paper the answer is no.\n\nIn theorem 4.3 is shown that for a prime $p$ there at most $8$ different ways to write $p$ as a sum of two squares.\n\nHowever, there is a function $g$ s.t. for all $n \\in \\mathbb{N}, \\ g(n)$ can be written as sum of two squares in $n$ different ways, so if this is what you are asking the answer is yes. This is a consequence of Theorem 4.4.\n\nTheorem 4.4. says that if the prime numbers of the form $1 \\pmod4$ in $m$ appear with exponents $a_1,a_2,\\ldots , a_s$ and the prime numbers of the form $3 \\pmod4$ in $m$ appear with even exponents then $m$ can be written as sum of two squares in $4(a_1+1)(a_2+1)\\ldots(a_s+1)$ different ways.\n\nLets say that you want to find a circle with $4k$ lattice points. Then you can take the radius to be $5^{\\frac{k-1}{2}}$.\n\ne.g to find $8$ lattice points take the radius to be $\\sqrt{5}$. The lattice points are $(1,2),(1,-2),(-1,2),(-1,-2),(2,1),(2,-1),(-2,1),(-2,-1)$.\n\nThe best bound (assuming the circle is centered at zero) is the following:\n\nDenote the primes of the form $1 \\pmod 4$ as $p_1<p_2<\\ldots$. Lets say that you want to find the smallest $m$ s.t. the circle with radius $m$ has $4n$ lattice points. Factor $n$ as $n=4a_1a_2\\ldots a_s$ where $a_i$ are primes with $a_1\\leq a_2\\leq a_3 \\leq \\ldots \\leq a_s$. Then the smallest $m$ is given by $m^2=p_1^{a_s-1}p_2^{a_{s-1}-1}p_3^{a_{s-2}-1}\\ldots p_s^{a_1-1}$. This can be deduced from Theorem 4.4, the fact that for $a<b, \\ r_1,r_2 \\in \\mathbb{N}, \\ \\text{ with } a^2>b \\text{ and } r_1\\geq 2 \\Rightarrow a^{r_1r_2-1}>a^{r_1-1}b^{r_2-1}$ and the fact that $p_{i+1}<p_i^2, \\ \\forall i \\in \\mathbb{N}.$\n\nFor example the smallest radius $m$ witch give $48$ lattice points is $m=5\\cdot \\sqrt{13 \\cdot 17}$.\n\nshare|improve this answer\nI think you'll find that last circle has radius $\\sqrt5$. But in fact you can get it down to $\\sqrt5/\\sqrt2$ with center $(1/2,1/2)$. No one said the center had to be a lattice point. \u2013\u00a0 Gerry Myerson Oct 31 '12 at 12:01\nCorrect, thanks. I will edit. \u2013\u00a0 P.. Oct 31 '12 at 12:06\n@Pambos: Interesting! This is the bound that was mentioned by Andr\u00e9 Nicolas at the question's comment. Thanks for your longer answer. I am curious if one can find a better bound or if this is the best you can get. \u2013\u00a0 A.Schulz Oct 31 '12 at 13:23\nIn the same direction of @Andr\u00e9 Nicolas's bound, we can take the radius as the square root of the product of the first $m$ primes $\\equiv 1\\pmod{4}$, in order to have $4\\cdot 2^m$ integer points on a circle having a radius that grows like $m^m$. \u2013\u00a0 Jack D'Aurizio Oct 31 '12 at 14:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/88430/restrictions-of-modules-and-dimensions/89015\nText:\nTake the 2-minute tour \u00d7\n\nLet K be a finite field and let R,P be groups (with R a subgroup of P). I know that the irreducible KP-modules have dimensions 1,4 and 16 over K. I have a KP-module M, and I know that M has dimension at most 5 over K. I also know that M does not have a quotient of dimension 1 over K. Moreover, if I consider M as a module over KR, it has a 2-dimensional irreducible module. Is it necessarily the case that M is a 4-dimensional irreducible module over KP? (my initial reasoning can be found in a comment below)\n\nshare|improve this question\nThe answer is no if and only if $\\operatorname{Ext}^1(4,1)\\neq 0$ in the obvious notation. If you said what P and R are maybe someone could work it out, but a priori it is not even obvious groups with these properties exist. \u2013\u00a0 m_t Feb 14 '12 at 14:02\nSorry, P and R are parabolic subgroups of the McLaughlin Group in a minimal parabolic system. \u2013\u00a0 dward1996 Feb 14 '12 at 15:10\nI think your answer has also proved that irrespective of the answer to the question in my specific case, there is a flaw in my reasoning. Thanks for the help. \u2013\u00a0 dward1996 Feb 14 '12 at 15:24\nHaving looked at this again, I'm not sure that I follow the comment by mt. My initial reasoning was as follows. Suppose M were a 5-dimensional module. If M has a 4-dimensional submodule, then it must have a 1-dimensional quotient over K, which we know is not the case. Thus it must be the case that every irreducible submodule of M is 1-dimensional over K. However, the restriction of M to KR has a 2-dimensional irreducible submodule. A similar argument shows that M must have a 4-dimensional irreducible submodule, and thus as M has dimension at most 4, it is an irreducible 4-dimensional module \u2013\u00a0 dward1996 Feb 20 '12 at 11:07\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nI see no reason in general if $\\operatorname{Ext}_P^1(4,1) \\neq 0$ that, on restriction to R the four dimensional simple can't drop down and have a 2-dimensional submodule. I.e. On restriction to R it looks like:\n\n\\begin{equation}\\begin{array}{c} 2\\\\ 2 \\end{array} \\oplus 1 \\end{equation}\n\nIf you knew on restriction to KR the only irreducible submodule was two dimensional then this would be ruled out.\n\nshare|improve this answer\nThanks for that. I'm not sure why I thought that my justification was correct! (Sorry!) \u2013\u00a0 dward1996 Feb 21 '12 at 12:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/24829/integer-matrices-with-no-integer-eigenvalues/45779\nText:\nTake the 2-minute tour \u00d7\n\nLet $A = \\begin{pmatrix} 3&1 \\\\ 0&1 \\end{pmatrix}$ and $B = \\begin{pmatrix} 1&0\\\\ 1&2 \\end{pmatrix}$. I want to show that the only elements of the semigroup generated by $A$ and $B$ that have integer eigenvalues are elements of the form $A^n$ and $B^n$, $n \\in \\mathbb{N}$. I have tried every way that I can think of. Is it possible that a problem like this is undecidable?\n\nshare|improve this question\nCan't seem to get the latex right, but these are two by two matrices. \u2013\u00a0 Hej May 15 '10 at 22:54\nMarkdown was munching your backslashes. \u2013\u00a0 S. Carnahan May 15 '10 at 22:59\nIt could, in principle, be undecidable, but I very much doubt that. Without any further arguments, it sounds rather like defeatism to me at that point. \u2013\u00a0 Xandi Tuni May 15 '10 at 23:07\nHeuristically, the 2^n words of length n in your semigroup are going to have determinant around 6^n, so I guess the \"probability\" of the discriminant being a square is something like 6^{-n/2}; so I guess it seems reasonable to me that you'd expect only finitely many integer eigenvalues, and none if you don't find any early on. (Yes, I know there are the A^m and B^n, but hey, heuristics are heuristics...) It's much less clear to me what to expect when the matrices are in SL_2(Z). \u2013\u00a0 JSE May 16 '10 at 2:08\nAndrey, for example if $A=[3,1;0,1]$ and $B=[1,0;1,4]$, then $AB$ has integer eigenvalues. I think (3,2) is special in a mysterious way relating to the Collatz problem. \u2013\u00a0 Hej May 16 '10 at 21:14\nshow 8 more comments\n\n2 Answers\n\nThe general problem of this type is undecidable. More precisely, there is no algorithm that takes as input two $n \\times n$ integer matrices and decides whether the semigroup they generate contains a matrix all of whose eigenvalues are integers.\n\nProof: Given two $n \\times n$ integer matrices $A$ and $B$, choose a prime $p \\ge 5$ such that $p>n$, choose a degree $p$ monic integral polynomial $f(x)$ with the full symmetric group $S_p$ as Galois group, let $C$ be a $p \\times p$ integer matrix with characteristic polynomial $f(x)$, and consider the tensor products (Kronecker products) $A \\otimes C$ and $B \\otimes C$. An element of the semigroup generated by these two $np \\times np$ matrices has the form $M \\otimes C^m$ for some $M$ in the semigroup generated by $A$ and $B$ and some $m \\ge 1$. Each eigenvalue of $M$ is of degree at most $n$ over $\\mathbf{Q}$, but each eigenvalue of $C^m$ is of degree exactly $p$, so the eigenvalues of $M \\otimes C^m$ are all integers if and only if the all eigenvalues of $M$ are $0$, which holds if and only if $M$ is nilpotent. Thus the semigroup generated by $A \\otimes C$ and $B \\otimes C$ contains a matrix all of whose eigenvalues are integers if and only if the semigroup generated by $A$ and $B$ contains the zero matrix. But the latter property is undecidable: see Chapter 3 of this survey article. Thus one cannot have an algorithm that would answer the integer eigenvalue question for $A \\otimes C$ and $B \\otimes C$ in general.\n\nshare|improve this answer\n+1: wow. $ $ \u2013\u00a0 Pete L. Clark May 16 '10 at 4:53\nBut, but, but... how can there be a zero matrix in <A,B> is A and B are invertible? Maybe your general problem is too general! \u2013\u00a0 Victor Protsak May 16 '10 at 4:53\n@Bjorn: But is it an answer to the question? In general, yes, it's undecidable but in this particular case... Almost every real number has irrationality exponent 2 (metric NT) but to find the irrationality exponent of a given number, like $\\pi$, is a different task (diophantine NT). It looks like the original problem is quite diophantine, but it's really hard to write it \"in symbols\". \u2013\u00a0 Wadim Zudilin May 16 '10 at 4:58\nExactly! It seems the result of the paper is not applicable here. Besides, the authors claim that their particular problem for integer matrices is undecidable for $n\\times n$ matrices, when $n>2$ and decidable for $2\\times 2$-matrices. \u2013\u00a0 Andrey Rekalo May 16 '10 at 5:06\nWow, I didn't expect my answer to be so controversial! My proof proves what it claims to prove, nothing more. I answered only the question with a question mark: \"Is it possible that a problem like this is undecidable?\" I agree with all of you that this has no bearing on the answer for the two particular 2 by 2 matrices. @KConrad: I think that Vesa Halava is male. \u2013\u00a0 Bjorn Poonen May 16 '10 at 6:20\nshow 3 more comments\n\nI just found this problem. If you try the matrix $A^nB^m$, then your question for such matrices is equivalent to this number theory question: Can $9^n+2\\cdot 9^n\\cdot 2^m-12\\cdot 3^n\\cdot 2^m+2\\cdot 3^n+4^{m}\\cdot 9^n+4^{m}+2\\cdot 2^m+9$ be a square provided $m,n\\ne 0$. Note that if we denote $3^n$ by $x$, $2^m$ by $y$, we get a quartic polynomial in $x,y$. I hope number theorists here can say something about this exponential Diophantine equation.\n\nThe answer to problem with question mark is \"obviously NO\". To be undecidable, you should have a mass problem. For given $A,B$, you have the following problem: given a product $W(A,B)$ is it true that the matrix has an integer eigenvalue. That problem is obviously decidable. The question of whether this is true for every word $W$ requires answer \"yes\" or \"no\" and is not a mass problem. You can still ask whether it is independent from ZF or even ZFC (or unprovable in the Peano arithmetic). What Bjorn had in mind is a completely different and much harder problem when you include $A, B$ in the input and ask if for this $A$, $B$ some product $W(A,B)$ not of the form $A^n, B^m$ has an integer eigenvalue. This is a mass problem which could be undecidable (although he, of course, did not prove it). But this has nothing to do with the original question.\n\nshare|improve this answer\n@ Mark. What I was worried about is that the problem would be unprovable in the Peano arithmetic but the problem of whether there is an algorithm that can determine whether a seimgroup generated by two input matrices contains a matrix with integer eigenvalues is interesting on its own. \u2013\u00a0 Hej Nov 12 '10 at 3:00\n@Hej: As you can see even for products like $A^nB^m$ the problem is equivalent to solvability of certain exponential Diophantine equation. So the problem is not easy. As far as I know, this is not the kind of problems for which one can prove independence from PA by existing methods. In any case, you should modify the question replacing \"undecidability\" by \"unprovability in PA\". These are completely different questions. \u2013\u00a0 Mark Sapir Nov 12 '10 at 3:08\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/51793.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nThe Erdos-Mordell Theorem\n\nDate: 10/13/2000 at 14:33:11\nFrom: Rayna Zacks \nSubject: Related to Fermat Point in Triangle\n\nLet P be a point in a triangle. Let D be the sum of the distances from \nP to the 3 vertices, and let E be the sum of the shortest distances \nfrom P to the edges (trilinear coordinates of P). Prove that D > 2*E.\n\nI have beaten this to death using analytic geometry and calculus to \nfind the point P which minimizes D-2*E and then prove that D-2*E at P \nis greater than 0. I have used a number of different parameterizations \nof the triangle using 3 numbers (xy coordinates of one vertex and the \nlength of the opposite side, two angles and length of one side, length \nof all three sides) and expressed D and E in these terms, calculated \nthe partial derivative of (D-2*E) with respect to the parameters, etc. \nI continually end up with intractable expressions.\n\nI have tried all geometrical approaches that I know to construct the \nFermat point - but it's clear that point P above is not related to the \nFermat point. (I have a number of proofs now of the Fermat point \n\nI have solved special cases (e.g. if <A + <B > 90 deg. and <A < 15 \ndeg. then D-2*E > 0), and also proved it for an isosceles triangles \nwhere P is on the altitude, and for right triangles, and have found \nmany cases where point P is the vertex opposite the shortest side.\nBut I have not found a simple general proof that D > 2*E.\n\nIn xy coordinates the problem reduces to something like the following:\n\nProve H > 0 where\n     H =  cos(b) - 2*sin(B) - (X*cos(w) - Y*sin(w))\n\nand we know that at point P the two partial derivatives require that\n\n     1)  cos(a) - cos(b) + cos(c) = 2*(sin(B) - sin(C))\n     2)  sin(a) + sin(b) - sin(c) = 2*(1 - cos(B) - cos(C))  \n\nwhere A, B and C are the 3 angles of the triangle; a, b and c are the \n3 angles of the triangle with P as a vertex, and (X,Y) are the \ncoordinates of one of the vertices of the triangle. The symmetries of \nthe above are obvious, but I cannot get the last step.\n\nI am working with my father to solve a recent problem from the AMM \nproblem section and the first step is to prove D > 2*E. This is my \njob. My father says that he has seen a proof of D > *2E in a problem \nbook but he cannot find it. Neither can he prove D > 2*E.\n\n\nRayna Zacks\n\nDate: 10/13/2000 at 17:08:15\nFrom: Doctor Floor\nSubject: Re: Related to Fermat Point in Triangle\n\nDear Rayna,\n\nThanks for writing. This theorem is known as the Erdos-Mordell \ntheorem, but it should read D >= 2*E.\n\nLet's consider the following:\n\n\nWe have that D, E and F are the feet of the perpendicular altitudes \nfrom P to AB, BC and CA respectively, while E' and F' are the feet of \nthe perpendicular altitudes from E and F to AB.\n\nCFPE is a cyclic quadrilateral because the opposite angles are \nsupplementary. PC is its diameter. We also know that the radius of the \ncircumcircle of EFC is EF/(2*sin(C)), and thus the diameter is \nEF/sin(C). This means that EF = PC*sin(C). Since EF >= E'F' this gives \n\n     PC*sin(C) >= E'F'   ........................................[1]\n\nAlso, we have \n\n     F'E' = F'D + DE' \n          = PF*cos(90-A) + PE*cos(90-B)\n          = PF*sin(A) + PE*sin(B)         .......................[2]\n\nThe combination of [1] and [2] shows that\n\n     PC * sin(C) >= PF*sin(A) + PE*sin(B)\n\n                        sin(A)       sin(B)\n              PC >= PF* ----- + PE * ----- \n                        sin(C)       sin(C)\n\nIn the same way you find similar results for PA and PB. These three \nexpressions combine to:\n     PA+PB+PC >=\n\n         sin(A)  sin(B)       sin(B)  sin(C)       sin(A)  sin(C)\n     PD*(----- + -----) + PE*(----- + -----) + PF*(----- + -----)\n         sin(B)  sin(A)       sin(C)  sin(B)       sin(C)  sin(A)\n\n              >= 2*(PD + PE + PF)\n\nbecause x + 1/x >= 2.\n\nAnd we have proven the Erdos-Mordell theorem (from 1935). Good luck in \nsolving the AMM problem. If you have more questions, just write back.\n\nBest regards,\n- Doctor Floor, The Math Forum\nAssociated Topics:\nCollege Triangles and Other Polygons\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/108593/how-to-prove-that-the-normalizer-of-diagonal-matrices-in-gl-n-is-the-subgroup\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to prove that de normalizer $N(T)$ of the subgroup $T\\subset GL_n$ of diagonal matrices is the subgroup $P\\in GL_n$ of generalized permutation matrices. I guess my biggest problem is that I don't really know how diagonal and permutation matrices (don't) commute. Because it is not true that $DM=MD$ when $D\\in T$ and $M\\in P$ since the permutation is either horizontal or vertical, but sometimes it seems like you can do something like it.\n\nSo far, I have proved that $P\\subset N(T)$, in the following way. Let $M_\\sigma\\in P$. Then $M_\\sigma=VS_\\sigma$, with $V\\in T$ and $S_\\sigma$ a permutation matrix. So $M_\\sigma DM^{-1}=VS_\\sigma D S_\\sigma^T V^{-1}$. Thus if we prove that $S_\\sigma D S_\\sigma^T$ is diagonal we are done. This is true since $S_\\sigma D S_\\sigma^T=(x_1 e_{\\sigma(1)} \\dots x_n e_{\\sigma(n)}) (e_{\\sigma^{-1}(1)} \\dots e_{\\sigma^{-1}(n)})=(x_{\\sigma^{-1}(1)}e_1 \\dots x_{\\sigma^{-1}(n)}e_n)$, where $e_i$ are the standard basis vectors. Even this is hopelessly written out. I'm trying to find a way to see what the product $S_\\sigma D S_\\sigma^T$ is without writing it in vectors.\n\nFor the other way around I don't really know what to do. I'm having a hard time rewriting matrix products in a useful way. Perhaps there is a way of proving this using something completely different? Maybe you can prove it using $N(T)/T\\simeq S_n$, but this actually what I want to use my question for. When I just write what I know about a matrix $M\\in N(T)$ I just get a big system of equations that isn't really handy.\n\nshare|improve this question\nTry taking a matrix in $N(T)$, testing it on the diagonal matrices with zeros in all but one diagonal entry, and forcing it to be a generalized permutation matrix. Recall that the group $GL_{n}$ lives inside a ring of matrices (i.e. use addition and distributivity). \u2013\u00a0 Isaac Solomon Feb 12 '12 at 19:33\n@IsaacSolomon Thanks, but I don't really understand it. When I take $D_1$ for instance (with zeroes everwhere but $D_{1,1}$), and I look at $MD_1=SM$ for some diagonal matrix $S$, I can see that it follows that the first column only has one non-zero entry. But now how do I put that together. I can write $M(x_1D_1 + \\dots + x_nD_n)=SM$, but then I get confused. \u2013\u00a0 dropfruitduo Feb 12 '12 at 20:09\nadd comment\n\n4 Answers\n\nup vote 2 down vote accepted\n\nLet $S\\in N(T)$. Then $SDS^{-1}$ is diagonal for each diagonal matrix $D$. Now, conjugation preserves the spectrum, which is exactly the diagonal in the case of diagonal matrices. So the diagonal of $SDS^{-1}$ has to be the same as the diagonal of $D$ up to a permutation. From this it's not hard to setup the equations to see that $S$ has to have a unique nonzero entry per row and column, i.e. $S$ is a generalized permutation matrix.\n\nConcretely, let us write $\\{E_{kj}\\}$ for the set of canonical matrix units (i.e. $E_{kj}$ is the matrix with a $1$ in the $k,j$ position and zeroes elsewhere). Let $D=E_{11}+2E_{22}+\\cdots+n E_{nn}$ (i.e. a diagonal matrix with all different entries). From the first paragraph, we know that $SDS^{-1}$ is $W=\\sigma(1)E_{11}+\\cdots+\\sigma(n)E_{nn}$ for some permutation $\\sigma$. Since $SD=WS$, we get that $$ S_{kj}(j-\\sigma(k))=0. $$ For each $j\\ne\\sigma(k)$, we have $S_{kj}=0$; so the only nonzero entry in the $k^{\\rm th}$ row of $S$ is $S_{k,\\sigma(k)}$. In other words, each row of $S$ contains a single nonzero entry, so $S$ is a generalized permutation matrix.\n\nshare|improve this answer\nRight that makes sense! It's mostly the writing down the equation part I'm having trouble with. So can I say: $SDS^{-1}=W$ for some diagonal $W$ with the same diagonal as $D$ up to a permutation for every $D$, so also for one with all unique diagonal entries. Then when I calculate $SD$ and $WS$ I get equations $(x_j-x_{\\sigma(i)})s_{i,j}=0$ for all $i,j$. Then since $x_1-x_{\\sigma(i)}$ is only zero for one $i$, the rest of the $s_{i,1}$ must be zero, and so for all j? Or am I making it too complicated? \u2013\u00a0 dropfruitduo Feb 12 '12 at 20:59\nMostly yes, you need to play a little with the choices of different diagonals. I'll add it to the solution in a few minutes. \u2013\u00a0 Martin Argerami Feb 12 '12 at 23:45\nHow about those diagonal matrices with some identical diagonal entries? \u2013\u00a0 Eric Apr 27 '12 at 14:47\nWhat about them? \u2013\u00a0 Martin Argerami Apr 28 '12 at 11:44\nadd comment\n\nIf $P$ is the permutation matrix corresponding to permutation $\\pi$, i.e. $P_{i,\\pi(i)} = 1$ for each $i$, and $D$ is a diagonal matrix, then $(PDP^{-1})_{ij} = \\sum_k \\sum_\\ell P_{ik} D_{k\\ell} P^{-1}_{\\ell j}$. For a term to be nonzero, you need $k = \\pi(i)$, $k=\\ell$ and $\\ell = \\pi(j)$, so $\\ldots$\n\nshare|improve this answer\nadd comment\n\nLet $S \\in N(T)$. Now, $\\forall D \\in T$ we have $SDS^{-1} \\in T$. As noted, conjugation preserves the spectrum, and so $D$ and $SDS^{-1}$ have the same diagonal entries up to permutation. This allows us to write $SDS^{-1} = \\prod_kP_kDP_k'$, where $P_k, P_k' \\in P_{S_n} \\leq GL(n)$, the group of permutation matrices. This shows that $N(T) \\leq \\langle T , P_{S_n}\\rangle$. Finally, a simple calculation shows that $\\langle T , P_{S_n}\\rangle \\leq N(T)$.\n\nshare|improve this answer\nadd comment\n\nThe set of eigenvectors common to all elements of $T$ is that of the nonzero multiples of the standard basis vectors. Any element of $N(T)$ must permute these common basis vectors among each other (if $P\\in N(T)$ and $v$ is a common eigenvector of $T$, then so is $P\\cdot v$). This means all columns of $P$ must have a single nonzero entry, and of course these entries have to be in distinct rows as well. Hence $N(T)$ is contained in the set of generalised permutation matrices. The reverse inclusion follows from a simple computation to show that permutation matrices normalise $T$ (as of course do elements of $T$ itself). Or show this using the fact that $t\\in T$ whenever all standard basis vectors are eigenvectors of $t$ (nearly the converse of the property used at the beginning).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38624/determining-the-center-of-mass-of-a-cone?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm having some trouble with a simple classical mechanics problem, where I need to calculate the center of mass of a cone whose base radius is $a$ and height $h$..!\n\nI know the required equation. But, I think that I may be making a mistake either with my integral bounds or that $r$ at the last..! $$z_{cm} = \\frac{1}{M}\\int_0^h \\int_0^{2\\pi} \\int_0^{a(1-z/h)} r \\cdot r \\:dr d\\phi dz$$\n\n'Cause, once I work this out, I obtain $a \\over 2$ instead of $h \\over 4$...!\n\nCould someone help me?\n\nshare|improve this question\nHello there Coolcrab and please keep an eye on our Homework policy before asking about homework questions, 'cause they're discouraged here..! Sorry :) \u2013\u00a0 Waffle's Crazy Peanut Sep 29 '12 at 10:16\nThey are not homework, and I did do the sum just making a mistake somewhere. And asking for help with that.. \u2013\u00a0 Coolcrab Sep 29 '12 at 10:55\nWhat!? $a/2 := h/4$!? I don't think so... Increasing $a$ has no effect on $h$, this assertation is plane false. \u2013\u00a0 Killercam Sep 29 '12 at 11:14\nOfc its not, and thats my problem. It's either my bounds or the r should be a z. I'm not sure. \u2013\u00a0 Coolcrab Sep 29 '12 at 11:16\n@Killercam: Hi guys, I understood it. But, I just assumed that the center of mass would be somewhere along the axis of the cone...! Isn't that right? \u2013\u00a0 Waffle's Crazy Peanut Sep 29 '12 at 11:36\nshow 2 more comments\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI am not sure about this formula. Lets start by taking the vertex of the solid cone to be $O(0, 0, 0)$ in cylindrical coordinates ($r$, $\\theta$, $z$). Then take the height of the cone to be $h$ and the base of the cone to have radius $a$. In this case the we know that\n\n$r = \\frac{a}{h} z$.\n\nThe formula for the center of mass of this cone can be written as\n\n$Mz_{M} = \\int^{h}_{0} z \\mathrm{d}m$,\n\nwhere $M$ is the total mass of the (solid) cone and $z_{M}$ is the location of the center of mass. We can write $\\mathrm{d}m$ as\n\n$\\mathrm{d}m = \\pi \\rho \\frac{a^{2}}{h^{2}}z^{2}\\mathrm{d}z$,\n\nwhere we have considered $\\mathrm{d}m$ to be the mass of a thin disk at height $z$ and of radius $r$, with thickenss $\\mathrm{d}z$. Now we can write the full equation for the center of mass as\n\n$Mz_{M} = \\pi\\rho\\int^{h}_{0}\\frac{a^{2}}{h^{2}}z^{3}\\mathrm{d}z$,\n\nthis becomes\n\n$Mz_{M} = \\rho Vz_{M} = \\frac{1}{4}\\pi\\rho a^{2}h^{2}$.\n\nWe know that the volume of a cone $V = \\frac{1}{3}\\pi a^{2} h$, so we find\n\n$z_{M} \\rho \\frac{1}{3}\\pi a^{2} h = \\frac{1}{4}\\pi\\rho a^{2}h^{2}$,\n\n\n$z_{M} = \\frac{3}{4} h$.\n\nWhich is the distance from the vertex of the cone.\n\nI hope this helps.\n\nshare|improve this answer\nadd comment\n\nI see the problem you have here, change the r*r drd\u03d5dz there to z*r drd\u03d5dz, then you should get the correct answer\n\nshare|improve this answer\nHi Mengyu, welcome to Physics.SE. Can you please use MathJax with dollar signs and markup to make your answer more readable? See meta.math.stackexchange.com/questions/5020/\u2026 \u2013\u00a0 Brandon Enright Feb 20 at 18:37\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/311043/determining-complex-differentiability-using-cauchy-riemann-equations\nText:\nTake the 2-minute tour \u00d7\n\nI need to find where $f(x+iy)=-6(\\cos x+i\\sin x)+(2-2i)y^3+15(y^2+2y)$ is complex differentiable.\n\nI first rearranged the function into its real and imaginary parts: $f(x+iy)=(-6\\cos x+2y^3+15y^2+30y)+i(-6\\sin x-6y^2)$\n\nThat means $u(x,y)=-6\\cos x+2y^3+15y^2+30y$ and $v(x,y)=-6\\sin x-6y^3$.\n\nThen, if we take the partial derivative of u and v in terms of x and y:\n\n$u_x=6\\sin x$\n\n\n$v_x=-6\\cos x$\n\n\nThen, by the Cauchy-Riemann equations, $u_x=v_y$ and $u_y=-v_x$.\n\nThis means that: $6\\sin x=-18y^2$ and $6y^2+30y+30=6\\cos x$.\n\nThis is where I am stuck. How do I solve for x and y? I was thinking that I could proceed in this way:\n\n$\\sin^2 x + \\cos^2 x=1 \\Rightarrow (-3y^2)^2+(y^2+5y+5)^2=1 \\Rightarrow 10y^4+10y^3+35y^2+50y+24=0$\n\nHowever, from here, how do I solve for y and then solve for x? I'd appreciate any tips. Thanks for your help in advance!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nYou can see from wolfram alpha that the solutions for the pair of equations never overlap.\n\nBut using your chain of logic: $10y^4+10y^3+35y^2+50y+24=0$ has no real solutions. Therefore the function is complex-differentiable nowhere.\n\nshare|improve this answer\nadd comment\n\nWe can simplify these equations into $$ \\sin{x} = -3 y^2, \\quad y^2 + 5y + 5 = \\cos{x} $$ Now, $x$ and $y$ are real, so the only way that the first equation can be satisfied is if $y \\in [-1/\\sqrt{3}, 1/\\sqrt{3}]$, since otherwise $-3y^2$ will not be in the range of sine.\n\nNow we turn to the second equation. The graph of $y^2 + 5y + 5$ achieves its minimum at $y = -5/2$; therefore it is monotone on the interval $[-1/\\sqrt{3}, 1/\\sqrt{3}]$. So we can simply check the endpoints to verify that $y^2 + 5y + 5 > 1$ when $y \\in [-1/\\sqrt{3}, 1/\\sqrt{3}]$, and hence it can never equal $\\cos{x}$ if the first equation is satisfied.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/134011/scalar-product-of-gaussian-process/134048\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $n(t)$ is a White Gaussian Noise (WGN) process with $E[n(t)]=0$, $E[n(t)^2]=\\sigma^2$ and $x(t)$ a deterministic function defined in $[0,T]$. How can I compute from first principles the variance of $g(T)$ defined as\n\n\nAny references to elementary textbooks on stochastic processes are also welcome.\n\nshare|improve this question\nis the e(t) in the definition of g(T) the n(t) you introduced before? \u2013\u00a0 tibL Apr 19 '12 at 17:20\nYou need the autocorrelation function of the process, not just the variance. \u2013\u00a0 Dilip Sarwate Apr 19 '12 at 17:25\nYes, the noise is white and e(t)=n(t). The text is now correct. \u2013\u00a0 Arrigo Benedetti Apr 19 '12 at 21:57\nIf the autocorrelation function is $$E[n(t)n(s)] = R_n(t-s)=\\begin{cases}\\sigma^2,&t=s,\\\\0,&t\\neq s,\\end{cases}$$ then the integral expression in Nate Eldredge's answer gives $\\operatorname{var}(g(T))=0$. If the autocorrelation function is $\\sigma^2\\delta(t-s)$ (note the difference) then see my comment on that answer as well as this question. \u2013\u00a0 Dilip Sarwate Apr 20 '12 at 11:06\nadd comment\n\n1 Answer\n\nAssuming that $e(t)$ is supposed to be $n(t)$ and that you know the covariances $E[n(s) n(t)]$, then note that $$g(T)^2 = \\int_0^T \\int_0^T x(s) x(t) n(s) n(t)\\,ds\\,dt$$ and so by Fubini's theorem $$E[g(T)^2] = \\int_0^T \\int_0^T x(s) x(t) E[n(s) n(t)]\\,ds\\,dt.$$\n\nshare|improve this answer\n@ArrigoBenedetti This calculation occurs in engineering applications very often where $n(t)$ is assumed to be a white Gaussian noise process with autocorrelation function $\\sigma^2\\delta(t-s)$ and so $E[g(T)] = 0$ while the variance becomes $$\\text{var}(g(T)=\\sigma^2\\int_0^T x^2(t) \\mathrm dt.$$ See for example Appendix A of this document. \u2013\u00a0 Dilip Sarwate Apr 19 '12 at 19:11\nThese heuristics are nice, but it may be important to mention that they're not too much more than this. In particular, the integrals, as shown, don't exist. \u2013\u00a0 cardinal Apr 20 '12 at 4:20\n@cardinal Would you please comment on or respond to this question of mine on this issue? Thanks. \u2013\u00a0 Dilip Sarwate Apr 20 '12 at 11:10\nThe application of Fubini's theorem is illegal here, as mentioned by @cardinal. \u2013\u00a0 Did Jan 15 '13 at 6:55\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/260182/solving-an-equation-with-an-integral/260190\nText:\nTake the 2-minute tour \u00d7\n\nI need to solve the following equation for $v(x)$: $$\\int_0^tv(x)(x+1)dx=f(t)$$ I am given the function $f(t)$. I've done this so far:\n\nIf we derive both sides by $t$, we get $v(t)(t+1)=f'(t)$ and $\\bar{v}(t)=\\frac{f'(t)}{t+1}$. The problem is that I am still off by a constant, i.e., the above only guarantees that : $\\int_0^t\\bar{v}(x)(x+1)dx+c=f(t)$ which is not enough for me.\n\nshare|improve this question\nHint: consider taking the Fourier or Laplace transform from both sides, solve algebraic equation and making the inverse transform. \u2013\u00a0 m0nhawk Dec 16 '12 at 19:38\n@monhawk: how should that help? \u2013\u00a0 Fabian Dec 16 '12 at 19:38\nIf your $f(0)=0$, then $c\\equiv0$ for any $\\nu(x)$. Isn't it? \u2013\u00a0 0x2207 Dec 16 '12 at 19:38\n@0x2207: yes, the constant is in fact $f(0)$. \u2013\u00a0 Fabian Dec 16 '12 at 19:39\n@Fabian, from definition $\\int_{0}^{0} g(x) dx \\equiv 0$ \u2013\u00a0 0x2207 Dec 16 '12 at 19:40\nshow 7 more comments\n\n2 Answers\n\nup vote 2 down vote accepted\n\nIt is easy to see that the constant $c$ in your post is in fact $f(0)$. Furthermore, a little thought shows that your equations cannot be solved unless $f(0)=0$ (just plug in $t=0$ in your equation and you find $0=f(0)$).\n\nshare|improve this answer\nadd comment\n\nI don't see what is the problem here. Obsviously $f(0)=0$ (for the equation to have a solution) and by deriving as you said, we get $$v(t)=\\frac{f^{\\prime}(t)}{t+1}$$ If we substitue this back in the orginal equation we have $$f(t)=\\int_{0}^{t}f^{\\prime}(x)dx=f(t)-f(0)=f(t)$$ which is true\n\nshare|improve this answer\nThe problem is the given $f(0)\\neq 0$. \u2013\u00a0 Hasanhasan Hasan Dec 16 '12 at 20:27\nThen the problem has no solutions \u2013\u00a0 Nameless Dec 16 '12 at 20:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/36609/what-is-the-nature-of-this-sequence?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\n$3, 4, 10, 33, 136$\n\nwhat will be next most appropriate value? I tried finding any relation in the sequence but i couldn't.\n\n$a.276 $\n\n$b.539 $\n\n$c.612 $\n\n\nshare|improve this question\nIs this just a puzzle or do you have some context you can provide? \u2013\u00a0 Aryabhata May 3 '11 at 6:15\nI have got options with me. $a.276$ $b.539$ $c.612$ $d.685$ \u2013\u00a0 amul28 May 3 '11 at 6:18\nOne option is $685$. $3, 3*1+1 = 4, 4*2 + 2 = 10, 10*3+3 = 33, 33*4+4 = 136, 136*5 + 5 = 685$... But such questions are nonsense as Qwirk's answer shows. I am voting to close a NARQ. \u2013\u00a0 Aryabhata May 3 '11 at 6:21\n@amul: I really don't know. There is no systematic method. Really, such questions are nonsense and solving this one likely won't help you solve other nonsense questions like this. It is unfortunate, but you have to guess what the idiot who wrote the question on the entrance test was thinking of... \u2013\u00a0 Aryabhata May 3 '11 at 6:41\nI agree that questions like this can be frustrating, especially when multiple answers might fit, but I don't agree that they're completely worthless. I think the ability to look at arbitrary data, see patterns, find possible relationships, and then identify the most likely relationship is a critical skill for a mathematician to have. The question isn't \"what was the exam writer thinking when he wrote this?\", it's \"what's the simplest relationship you can find between these numbers?\" \u2013\u00a0 Kevin May 3 '11 at 15:15\nshow 10 more comments\n\n2 Answers\n\nup vote 7 down vote accepted\n\nI agree with all the complaints about this sort of problem, but still.... There are some techniques which work from time to time.\n\nTry taking differences: $4-3=1$, $10-4=6$, $33-10=23$, $136-33=103$, so now we have to explain the sequence $1,6,23,103,\\dots$. Hmm, that doesn't seem very helpful.\n\nOK, subtraction didn't work, try division: $4\\div3=1r1$, $10\\div4=2r2$, $33\\div10=3r3$, $136\\div33=4r4$ - hey, that looks much better! (When I write $arb$, I mean quotient $a$, remainder $b$.)\n\nshare|improve this answer\nseems very clear for me. \u2013\u00a0 amul28 May 3 '11 at 7:09\nWow! I never knew division could be applied. I always used subtraction. +1 for arb notation. Its really helpful. \u2013\u00a0 Shiplu Dec 21 '11 at 7:44\nadd comment\n\nI must say, I have always disliked 'find the next term in the series question'. For any sequence, it is easy to produce any number next (e.g. for a sequence of $n$ terms, pick the $n+1$ number and then fit a polynomial to those $n+1$ terms).\n\nOEIS does not give anything useful for your sequence - how has it arisen?\n\nEdit: For this question, as Moron has shown, the likely answer is 685, based on the sequence $3,3\\times 1 + 1 = 4, 4 \\times 2 + 2 = 10, 10 \\times 3 + 3 = 33, 33 \\times 4 + 4 = 136,$$136 \\times 5 + 5 = 685$ . But in general knowing how to find the pattern in this sequence, will not help (much) in finding patterns in similar sequences.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/325208/the-boundary-of-a-region-for-complex-valued-functions\nText:\nTake the 2-minute tour \u00d7\n\nFrom Chapter $3$ of Stein and Shakarchi's complex analysis book, we have the following problem ($15$):\n\nShow that if $f$ is holomorphic in the unit disc (open), bounded, and converges uniformly to zero in the sector $\\theta<\\arg z<\\varphi$ as $|z|\\to1$, then $f=0$.\n\nWe're supposed to use either the Cauchy inequalities or maximum modulus principle (per the instructions at the beginning, since this is a $4$-part problem), but I don't quite see how to do it using either of those, though the structure of the problem seems to lend itself to the maximum modulus principle. The problem with this is that we know that in the interior of the sector, the function cannot attain a maximum modulus, however, we don't know anything about the boundary of the sector that is in the interior of the circle. This is one obstacle I couldn't quite overcome.\n\nMy approach was to extend the function past the boundary of the circle, which we can do since $f$ is bounded (I think, though even this part is a little bit 'hand-wavy'), and then, since it has a cluster of zeros, the function will be identically zero.\n\nHow should I approach the problem with the intention of using the maximum modulus principle or Cauchy inequalities? Any suggestions would be appreciated. Thanks!\n\nEDIT: I've been thinking about this problem, and I've come up with the following solution:\n\nLet $f$ be an analytic function on $\\mathbb{D}$ (take note that I'm not assuming $f$ is bounded), with the property that for $\\theta<\\arg z<\\varphi$, $|f(z)|$ converges to zero uniformly as $|z|\\to1$ in this sector. Then we can make a 'bump' on the disc in this sector so that it extends in this outside of $\\mathbb{D}$, call this set $\\Omega'$. Define $$g(z)=\\begin{cases}f(z)&:\\,z\\in\\Bbb D\\\\0 &:z\\notin\\Bbb D\\end{cases}.$$ Now, clearly in $\\Bbb D$ $g(z)$ is holomorphic and outside of $\\Bbb D$, it's holomorphic as it's constant, so the only questionable part would be on the boundary of the disc in this sector. At this point, we can take a small disc around each point entirely contained in $\\Omega'$, since it's open, and apply Morera's theorem to show that $g(z)$ is holomorphic here. Therefore, on all of $\\Omega'$, $g$ is holomorphic and has a cluster of zeros, hence is identically equal to zero, therefore $f(z)=0$.\n\nIs this proof correct? Or did I miss something and there is a counterexample when $f$ is not bounded? If it is correct, it's nice in that the proof didn't rely on the shape of the region at all, only on the fact that there was a nondegenerate connected subset of the boundary with the property. Therefore, we see the exercise as a very special case of the generalized problem.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nA particular case that should help you think of a solution is when the sector is of the form $0\\leq \\text{arg}z \\leq \\pi$. In this case consider $g(z)=f(z)f(-z)$. Since $f$ is bounded, $g$ admits a continuous extension to the boundary of the circle that is $0$ on said boundary. The maximum modulus principle gives the result.\n\nshare|improve this answer\nYour argument may be fixed, but note that it's not true that any bounded analytic function admits a continuous extension to the boundary. (The assumption on $f$ in the statement of the problem is important.) \u2013\u00a0 mrf Mar 9 '13 at 16:33\n@mrf: That's why I said that $g$, not $f$, admits a continous extension (the boundedness of $f$ is used to ensure that $g$ tends to zero at the boundary, not as automatic extension). \u2013\u00a0 Jose27 Mar 9 '13 at 18:33\n@Jose27: I've updated an argument of my own; would you take a look and let me know your thoughts? \u2013\u00a0 Clayton Mar 12 '13 at 2:01\n@mrf: I've added an argument of my own; would you take a look and let me know your thoughts? Thanks! \u2013\u00a0 Clayton Mar 12 '13 at 2:01\nHow do you generalize this to arbitrary $\\theta,\\varphi$? I don't quite see it. \u2013\u00a0 Clayton Mar 12 '13 at 12:15\n\nFirst of all, I think you should upvote (if you haven't already) and accept Jos\u00e9's answer, which seems like the canonical answer.\n\nTo address the follow up questions and remarks:\n\nI think your argument is correct, but it took me a little while to see why the integral of $g$ over a curve that crosses $\\partial\\mathbb{D}$ should be zero. You should provide some more details here.\n\nThe result is certainly true without assuming that $f$ is bounded. Here is another way to see this: Instead of bumping $\\partial\\mathbb{D}$ outward, we can create an inward bump. More precisely, let $U$ be an open subset of $\\mathbb{D}$ whose closure contains a (non-empty) arc on which $f$ extends to $0$. By shrinking $U$ a little, we can assume that $f$ is bounded on $U$, that $U$ is simply connected and that the boundary of $U$ is reasonably smooth. Map $U$ biholomorphically onto the unit disc (Carath\u00e9odory's theorem assures that the Riemann map extends continuously up to the boundary, so the arc maps onto another non-empty arc). This construction reduces the problem the the case where $f$ is bounded, and we can apply Jos\u00e9's solution and pull it back. Hence $f = 0$ on an open set, and by the identity theorem, $f = 0$ everywhere.\n\nshare|improve this answer\nI've upvoted Jose's answer. I understand about half of your answer, though. It sounds legitimate, but I'm unfamiliar with what it means to map something biholomorphically, conformal mappings for Caratheodory's theorem, Riemann maps, etcetera. When I get time, I'll read into these topics as much as I can and inform myself about your answer. \u2013\u00a0 Clayton Mar 12 '13 at 13:40\n@Clayton Ok, I thought you were aware of Riemann's mapping theorem. \u2013\u00a0 mrf Mar 12 '13 at 13:56\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/151885/zeroing-out-lower-order-terms-in-generating-function/151888\nText:\nTake the 2-minute tour \u00d7\n\nGiven a generating function $F(x)=a+bx+cx^2+dx^3+\\dotsb$, how do I truncate the $n$ lower order terms to get, for example if $n=2$: $cx^2+dx^3+\\dotsb$?\n\nFor example, if I wanted to find $0a+1b+2c+\\dotsb$, I would evaluate $$\\left.\\frac{dF(x)}{dx}\\right|_{x=1}$$\n\nThis procedure can be used to find the expected value of a probability distribution given its generating function.\n\nI want something similar for truncation of lower-order terms. This would give a cdf for a probability distribution. Since the cdf has a nice form for a binomial generating function, this suggests that there might be a nice way to arrive at it using generating function operators.\n\nI vaguely remember learning this once, but flipping through the book generatingfunctionology didn't yield it.\n\nshare|improve this question\nBy what available means? Obviously subtracting $a+bx$ from $F(x)$ works for your example, and is easily generalized... \u2013\u00a0 anon May 31 '12 at 4:09\n@anon: I've added to my question to make it more clear. \u2013\u00a0 Neil G May 31 '12 at 4:12\nIf differentiation and evaluation are all you have at hand, you can truncate by subtracting a partial Taylor expansion - however, without convergence (e.g. $\\sum n!x^n$) I'm unsure if truncation is obtainable with these two operations alone. \u2013\u00a0 anon May 31 '12 at 4:16\n@anon: There are other operations available, but I don't know what they are. \u2013\u00a0 Neil G May 31 '12 at 4:23\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nIf $f(x) = \\sum\\limits_{n=0}^\\infty a_n x^n$, then $f''(x) = \\sum\\limits_{n=2}^\\infty a_n n (n-1) x^{n-2}$, and $$ \\int_0^x (x-t) f''(t)\\ dt = \\sum_{n=2}^\\infty a_n x^n. $$ EDIT: More generally, $$ \\int_0^x \\dfrac{(x-t)^{k-1}}{(k-1)!} f^{(k)}(t)\\ dt = \\sum_{n=k}^\\infty a_n x^n. $$\n\nshare|improve this answer\nAwesome! Generating functions are the first time in my adult life that math felt like magic. \u2013\u00a0 Neil G May 31 '12 at 4:32\nWould you mind adding a line or two to make it clear why the antiderivative works here? \u2013\u00a0 Neil G May 31 '12 at 4:38\n$\\int_0^t f''(s)\\ ds = \\sum_{n=2}^\\infty a_n \\int_0^t n(n-1) s^{n-2}\\ ds = \\sum_{n=2}^\\infty a_n n t^{n-1}$, and so $\\int_0^x \\int_0^t f''(s)\\ ds\\ dt = \\sum_{n=2}^\\infty a_n x^n$. Now interchange the order of integration. \u2013\u00a0 Robert Israel May 31 '12 at 4:45\nPerfect, thank you very much. \u2013\u00a0 Neil G May 31 '12 at 5:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/137592/example-of-a-functor-which-preserves-all-small-limits-but-has-no-left-adjoint?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThe General Adjoint Functor Theorem (Category Theory) states that for a locally small and complete category $D$, a functor $G\\colon D \\to C$ has a left adjoint if and only if $G$ preserves all small limits and for each object $A$ in $C$, $A \\downarrow G$) has a weakly initial set.\n\nCould someone help by giving an example of a functor $G$ that preserves all small limits but has no left adjoint?\n\nshare|improve this question\nLet $\\emptyset$ be the empty category. Then $G : \\emptyset \\to \\mathcal{C}$ preserves all limits (vacuously), but $G$ has no left adjoint if $\\mathcal{C}$ is non-empty. \u2013\u00a0 Zhen Lin Apr 27 '12 at 7:39\n\n2 Answers 2\n\nup vote 9 down vote accepted\n\nA nontrivial example is mentioned in MacLane's Categories for the Working Mathematician , on page 123: consider the category $\\mathbf{CompBool}$ of complete boolean algebras. The forgetful functor $\\mathbf{CompBool} \\to \\mathbf{Set}$ has no left adjoint, but preserves all limits ($\\mathbf{CompBool}$\u00a0is also small-complete). The reason is that, given a denumerable set $D$, one can construct an arbitrarily large complete Boolean algebra generated by $D$ (a fact that was apparently proved by Solvay in 1966), and so the solution set condition in the General AFT fails.\n\nshare|improve this answer\nThank you Martin - really helpful. \u2013\u00a0 Conan Wong May 4 '12 at 10:44\n\nMartin's answer is probably the one you want, but here's another marginally trivial example.\n\nLet $\\mathcal{C}$ be a category and let $\\mathbf{1}$ be the terminal category with only one object and one morphism. The unique functor $G : \\mathcal{C} \\to \\mathbf{1}$ obviously preserves all limits, but $G$ has a left adjoint if and only if $\\mathcal{C}$ has an initial object. Dually, $G$ preserves all colimits and has a right adjoint if and only if $\\mathcal{C}$ has a terminal object.\n\nshare|improve this answer\nThanks Zhen Lin - your example(s) are very helpful too. \u2013\u00a0 Conan Wong May 4 '12 at 10:44\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/62563/how-does-a-pierced-vacuum-move\nText:\nTell me more \u00d7\n\nIf a can of compressed air is pierced on the right, air pushes out, and the can moves to the left.\n\nIf a vacuum container is pierced on the right, which way does it move? Right? Left? Not at all? Oscillate about its original position?\n\nshare|improve this question\nThe last one oscillate about it's original position is a silly option. :D. But it must be doesn't move at all. \u2013\u00a0 Mr.\u00d8\u00d87 Apr 28 at 17:02\nadd comment\n\n1 Answer\n\nWhy does a pierced compressed air can move? One answer is: when it is not pierced at 'the target point', there is a pressure acting on the target point (I should say area, but nevermind) on the right from the inside, as well as on its mirror point on the left, and so for every pair of points, so that the total force is zero. When you pierce the can, there still is some pressure acting on the mirror point, but there is no pressure acting on the target point, so that the total force acting on the can is not zero, and is directed to the left. (One can check that the force is the same as if you use conservation of momentum for the whole can+air system). What is pressure? Pressure is transition of momentum from air to the walls. When you pierce the target point, the momentum goes not to the can, but to the environment, and gets absorbed somewhere there.\n\nWhat changes when you pierce a vacuum can? Now the pressure acts from the outside, and now, when you pierce the can, the force on the mirror point is again not compensated and is directed to the right. So one may conclude that the can should move. But one thing is different: the momentum that was to be transfered to the target point from the outside (but was not, because there is now no surface at the target point) is not absorbed \"somewhere\", it goes inside the can, and is finally absorbed by it exactly canceling the momentum received by the mirror point.\n\nSo, in this case there is a rather subtle cancelation. However, I believe that there are some further subtleties, which may cause a small difference in these momenta, and if you try to measure the force really hard, then you will see it.\n\nshare|improve this answer\n-1 Momentum must be conserved. The can will still move in a vacuum. This is how a thruster works ( \u2013\u00a0 Brandon Enright Apr 30 at 4:22\n@BrandonEnright, Please, read the question carefully. \u2013\u00a0 Peter Kravchuk Apr 30 at 4:39\nYep, my mistake. I read it as a can pierced in a vacuum container. I will take back the -1 if SE lets me. \u2013\u00a0 Brandon Enright Apr 30 at 4:44\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58571.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nHow Many Pads of Paper?\n\nDate: 10/30/2001 at 02:23:05\nFrom: Jessica\nSubject: Number Theory\n\npads did he sell?\n\nI don't understand how to solve this without knowing at least one more \nvariable, like how much or what percent they were marked down to.\n\nDate: 10/30/2001 at 08:46:16\nFrom: Doctor Paul\nSubject: Re: Number Theory\n\nThe integer 60377 has only four factors: 1, 173, 349, 60377\n\nSo 60377 = 1 * 60377 or 173 * 349\n\nIt follows then that \n\n   603.77 =  .01 * 60377   or \n            1.73 * 349     or \n             173 * 3.49    or \n               1 * 603.77\n\nBut since we know the merchant charged less than $2.00, we can assume \nhe sold them for either $1.73 each or $.01 each.\n\nIn the former case he sold 349 pads, and in the latter case he sold \n60377 pads.\n\nNotice that 1.73 * 349 = 603.7699999999999999999999999...  and \n.01 * 60377 = 603.77\n\nI'm guessing that the correct answer here is probably 349 since the \nother case is obvious and wouldn't require you to do much work. But if \nthe problem is stated exactly as you have it written above, 60377 \nwould be a legitimate answer as well.\n\nFeel free to write back if you want to talk about this some more.\n\n- Doctor Paul, The Math Forum\nAssociated Topics:\nMiddle School Factoring Numbers\nMiddle School Word Problems\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/32798/partition-function-for-the-jaynes-cummings-hamiltonian?answertab=votes\nText:\nTell me more \u00d7\n\nI was wondering if anyone here has calculated before the partition function for the Jaynes-Cummings Hamiltonian: $H_{JC}=\\omega_0 (a^\\dagger a + \\sigma^+ \\sigma^-)+g (a \\sigma^+ +a^\\dagger \\sigma^-)$ (Here I have assumed resonance and $a,a^\\dagger$ are bosonic operators and $\\sigma^-,\\sigma^+$ are ladder operators for a spin one half particle) For the Hamiltonian above the energy of the ground state is zero and corresponds to 0 excitations in the harmonic oscillator and the spin being down. The excited eigenenergies come in pairs and are given by: $\\omega_{n\\pm}=n \\omega_0 \\pm \\sqrt{n}g$. I am interested in knowing the partition function: $\\mathcal{Z}=\\text{tr}( \\exp(-\\beta H_{JC} ))=1+2\\sum_{n=1}^\\infty\\exp(-\\beta \\omega_0 n )\\cosh(\\beta g \\sqrt{n}) $ I tried Mathematica to get an analytic expression for the above sum and it did not work. Any thoughts on whether the summation can be expressed in terms of some special function or how to calculate it numerically in an efficient and reliable way?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nit is not exact and is impossible to compute exactly i recommend to use the Euler method to approximate your series by an integral plus some extra corrections , this Euler-Maclaurin summation converges fast to the exact solution with only a few terms.\n\nshare|improve this answer\nThanks a lot Jose Javier, I will just use what you just wrote :) \u2013\u00a0 Nicol\u00e1s Quesada Jul 26 '12 at 1:53\nAlso do you know any reference related to this specific problem? \u2013\u00a0 Nicol\u00e1s Quesada Jul 26 '12 at 2:32\nno, unfortunately i know no reference to this problem :/ or how the partition funciton is obtained. \u2013\u00a0 Jose Javier Garcia Jul 26 '12 at 8:42\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70851/free-product-of-boolean-algebras?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nGiven a family of Boolean algebras $\\mathcal{B}=\\{B_i\\colon i\\in I\\}$ with respective Stone spaces $S_i$. Recall that the algebra of clopen (both closed and open) subsets of the product space\n\n$$\\prod_{i\\in I}S_i$$\n\nis said to be the free product of $\\mathcal B$. This algebra is typically denoted by\n\n$$\\bigotimes_{i\\in I}B_i$$\n\n(and I will use the standard \"tensor\" notation for finite free products in the obvious manner).\n\nI am interested in the (possible) Boolean algebras which admit only very particular decomposition in terms of the free product:\n\nIs there an uncountable Boolean algebra $B$ such that if $B$ is isomorphic to $A\\otimes C$ then either $A$ or $C$ is countable?\n\nshare|improve this question\nRemark: This tensor product is just the usual tensor product of algebras over $\\mathbb{F}_2$. \u2013\u00a0 Martin Brandenburg Jul 21 '11 at 10:26\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nTranslating this to Boolean spaces, you are looking for a Boolean space X which is not second countable, but cannot be written as a product of two factors of the same type (i.e., not second countable).\n\nHave you considered the compact space $[0,\\omega_1]$? It is certainly not the product of two uncountable spaces, as such a product would contain two almost disjoint closed uncountable sets. On the other hand, a countable Boolean space cannot have uncountably many clopen sets.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58868.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nEstimating and Rounding\n\nDate: 03/04/2002 at 15:49:48\nFrom: Amy \nSubject: Division - one answer problems\n\nI am doing my math homework and we have to divide a two-digit number \ninto another number and get a one-digit quotient. For example, 192  \ndivided by 86 = . Can you please help me?\n\nDate: 03/04/2002 at 22:56:59\nFrom: Doctor Peterson\nSubject: Re: Division - one answer problems\n\nHi, Amy.\n\nYou can find some discussions of the tricks you need in our archives:\n\n   Division by Estimation\n\n   Long division, Egyptian Division, Guessing\n\n   Compatible Number Estimating\n\nThere are a couple of important things to remember: you have to \nestimate (because you don't have a multiplication table that goes up \nto the 86's), and when you estimate you expect not to be exact. \nTherefore, you will be learning not only to make the best guess you \ncan, but to correct the guess WHEN (not if) it turns out to be wrong. \nThat's just part of the process, and doesn't mean you've made a \n\nSo let's look at your example. The first thing I usually do is to \nround both numbers, generally so that there is one non-zero digit left \nin the divisor and two in the dividend (though that's not always true \n- you'll get used to how to make this decision with a little \npractice). In this case, 86 rounds up to 90, and 192 rounds down to \n190. It won't matter here, but I like to round both numbers in the \nsame direction, because that's more likely to give a good estimate. \nSo I'd round both numbers up here (giving preference to the divisor), \nmaking it\n    90 ) 200\n\nNow, we can divide both numbers by 10 and it won't change the \nquotient; so ignore the zeroes on the end:\n    9 ) 20\n\nNow we've got something we can do: the answer is 2, since 9 * 2 = 18.\n\nThat's our estimate; but is it the right answer for the real problem \nwe're doing? All we can do is check it by multiplying. We're hoping \n    86 ) 192\n\nTo check that (and also to find the remainder), we multiply the \ndivisor by the quotient: 2 * 86 = 172. This is good: it's less than \n192, but not so much less that we could fit another whole 86 into it. \nThat is, we can subtract to get a remainder, and the remainder is less \nthan the divisor:\n\n    86 } 192\n\nSo the remainder is 20.\n\nAt leat one of the links I gave you goes into how to correct an \nestimate if the check doesn't work out; briefly, you subtract one from \nthe quotient if it's too big (so that the product was too big to \nsubtract at all), and you add one if the quotient is too small (so \nthat the remainder is too big).\n\nLet me know if you need more help. You might want to send a sample \nproblem worked out, so I can see where you might be going wrong or \ngetting stuck.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Division\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/15853/disintegrations-are-measurable-measures-when-are-they-continuous?sort=oldest\nText:\nTell me more \u00d7\n\nThis is a sequel to another question I have asked.\n\nThe notion of disintegration is a refinement of conditional probability to spaces which have more structure than abstract probability spaces; sometimes this is called regular conditional probability. Let $Y$ and $X$ be two nice metric spaces, let $\\mathbb P$ be a probability measure on $Y$, and let $\\pi : Y \\to X$ be a measurable function. Let $\\mathbb P_X(B) = \\mathbb P(\\pi^{-1} B)$ denote the push-forward measure of $\\mathbb P$ on $X$. The disintegration theorem says that for $\\mathbb P_X$-almost every $x \\in X$, there exists a nice measure $\\mathbb P^x$ on $Y$ such that $\\mathbb P$ \"disintegrates\":$$\\int_Y f(y) ~d\\mathbb P(y) = \\int_X \\int_{\\pi^{-1}(x)} f(y) ~d\\mathbb P^x(y) d\\mathbb P_X(x)$$ for every measurable $f$ on $Y$.\n\nThis is a beautiful theorem, but it's not strong enough for my needs. Fix a Borel set $B \\subseteq X$, and let $p(x) = \\mathbb P^x(B)$. Part of the theorem is that $p$ is a measurable function of $x$. Suppose that the map $\\pi : Y \\to X$ is continuous instead of simply measurable. My question: What is a general sufficient condition for $p(x)$ to be continuous?\n\nTo me, this is an obvious question to ask, since if $x$ and $x'$ are two close realizations of a random $x \\in X$, then the measures $\\mathbb P^x$ and $\\mathbb P^{x'}$ should be close too, at least in many natural situations. However, in my combing through the literature, I haven't been able to find an answer to this question. My guess is that most people are content to integrate over $x$ when they use the theorem. For my purposes, I need some estimates which I get by continuity.\n\nAt this point, I've managed to prove and write down a pretty good sufficient condition for the case I care about (Banach spaces), using an abstract Wiener space-type construction. However, I am hoping that an expert can point me toward a good reference that does this in wider generality.\n\nshare|improve this question\nB must be a subset of Y? \u2013\u00a0 Andrey Gogolev Feb 20 '10 at 1:09\nAlso, sufficient condition on what, on B, on pi, both? \u2013\u00a0 Andrey Gogolev Feb 20 '10 at 1:24\nAndrey: B above is a Borel set in Y. The function pi need only be measurable for the general disintegration theorem to apply. However, in my case, pi is continuous function. \u2013\u00a0 Tom LaGatta Feb 20 '10 at 15:21\nadd comment\n\n3 Answers\n\nTue Tjur studied the existence of continuous disintegrations in a 1975 preprint \"A Constructive Definition of Conditional Distributions,\" Issue 13, Copenhagen Universitet. He gives necessary and sufficient conditions for their existence, at least in the setting of Radon measures.\n\nHe also discusses sufficient structure, and there considers a basic probability space that is an open subset of a finite-dimensional Euclidean space and the problem of conditioning on a random variable taking values in an open subsets of a Euclidean space $\\mathbb R^k$ such that, when the random variable is considered as a (measurable) function, it is surjective and continuously differentiable with differential of maximal rank. This particular special case may be too narrow for you, but perhaps the general case can give you some guidance.\n\nThe article is a bit hard to track down, so let me know if you need help finding it. The existence of continuous disintegrations arises also in the study of the computability of conditional probability, which is my interest.\n\nshare|improve this answer\nadd comment\n\nProbably is not general as you want, but if you don't think before about that can be a begining...\n\nProposition: If $\\pi:Y\\to X$ is bijective function such that $\\pi^{-1}$ is continuous then $\\mathbb{P}^{x_n}\\to\\mathbb{P}^{x}$ (weak topology) whenever $x_n\\to x$.\n\nProof: it follows from the Disintegration Theorem that for all $B\\in\\mathcal{B}(Y)$ we have\n\n$$ \\begin{array}{rcl} \\mathbb{P}(B)&=&\\displaystyle\\int_X\\int_{\\pi^{-1}(x)}\\chi_B(y)\\ d\\mathbb{P}^x(y)\\ d\\mathbb{P}_X(x) &=&\\displaystyle\\int_X \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) \\end{array} $$ For the other hand we have that $$ \\mathbb{P}(B)=\\displaystyle\\int_X \\chi_B(\\pi^{-1}(x))\\ d\\mathbb{P}_X(x) =\\displaystyle\\int_X \\chi_B(\\pi^{-1}(x))\\delta_{\\pi^{-1}(x)}(\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) $$ so $$ \\displaystyle\\int_X \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x)=\\mathbb{P}(B)=\\displaystyle\\int_X \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) $$\n\nSince $\\mathbb{P}^x$ is a probability measure and $B\\cap\\pi^{-1}(x)$ is a singleton or empty set, we have $$ \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x))\\geq \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) $$ and from previous integral equality almost surely we have $$ \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x))=\\mathbb{P}^x(B\\cap\\pi^{-1}(x)). $$ Fix $x$ and take $B=\\pi^{-1}(x)$, then from the above equality, follows that $\\mathbb{P}^x=\\delta_{\\pi^{-1}(x)}$.\n\nIf $x_n\\to x$ then $p(x_n)=\\mathbb{P}^{x_n}$ converge to $p(x)$ in the weak topology. In fact, by the continuity of $\\pi^{-1}$ we get that $\\int f\\ p(x_n) \\to\\int f\\ p(x)$ for all bounded uniformly continuous functions $f$.\n\nshare|improve this answer\nadd comment\n\nI think you need some hypothesis on the measure to be pushed, at least in the very common case where $\\pi$ is the projection to a factor in a product.\n\nTake any family $\\mathbb{P}^x$ of measures in a space $X'$, where $x$ runs over $X$, and let $Y=X'\\times X$, $\\pi$ be the projection on $X$, and $\\mathbb{P}=\\int_X \\mathbb{P}^x dx$ where $dx$ is any measure on $X$. Then $\\pi$ is very regular (smooth if $X'$ and $X$ are smooth manifolds for example) but yet, any kind of lack of regularity can appear in $\\mathbb{P}^x$ (which are by construction the disintegration measures, since they are unique up to a negligible set).\n\nI guess that in this setting, assuming $\\mathbb{P}$ to be absolutly continuous with continuous density would be sufficient.\n\nEdit: My guess seems wrong, as is shown by the restriction of Lebesgue measure to a L shaped polygon. You will probably need strong restrictions on $\\mathbb{P}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/2988/how-fast-can-we-find-all-four-square-combinations-that-sum-to-n\nText:\nTell me more \u00d7\n\nA question was asked at Stack Overflow (here):\n\nGiven an integer $N$, print out all possible combinations of integer values of $A,B,C$ and $D$ which solve the equation $A^2+B^2+C^2+D^2 = N$.\n\nThis question is of course related to Bachet's Conjecture in number theory (sometimes called Lagrange's Four Square Theorem because of his proof). There are some papers that discuss how to find a single solution, but I have been unable to find anything that talks about how fast we can find all solutions for a particular $N$ (that is, all combinations, not all permutations).\n\nI have been thinking about it quite a bit and it seems to me that it can be solved in $O(N)$ time and space, where $N$ is the desired sum. However, lacking any prior information on the subject, I am not sure if that is a significant claim on my part or just a trivial, obvious or already known result.\n\nSo, the question then is, how fast can we find all of the Four-Square Sums for a given $N$?\n\nOK, here's the (nearly) O(N) algorithm that I was thinking of. First two supporting functions, a nearest integer square root function:\n\n    // the nearest integer whose square is less than or equal to N\n    public int SquRt(int N)\n        return (int)Math.Sqrt((double)N);\n\nAnd a function to return all TwoSquare pairs summing from 0 to N:\n\n    // Returns a list of all sums of two squares less than or equal to N, in order.\n    public List<List<int[]>> TwoSquareSumsLessThan(int N)\n        //Make the index array\n        List<int[]>[] Sum2Sqs = new List<int[]>[N + 1];\n\n        //get the base square root, which is the maximum possible root value\n        int baseRt = SquRt(N);\n\n        for (int i = baseRt; i >= 0; i--)\n                int sum = (i * i) + (j * j);\n                if (sum > N)\n                    //make the new pair\n                    int[] sumPair = { i, j };\n                    //get the sumList entry\n                    List<int[]> sumLst;\n                    if (Sum2Sqs[sum] == null)\n                        // make it if we need to\n                        sumLst = new List<int[]>();\n                        Sum2Sqs[sum] = sumLst;\n                        sumLst = Sum2Sqs[sum];\n                    // add the pair to the correct list\n\n        //collapse the index array down to a sequential list\n        List<List<int[]>> result = new List<List<int[]>>();\n        for (int nn = 0; nn <= N; nn++)\n            if (Sum2Sqs[nn] != null) result.Add(Sum2Sqs[nn]);\n\n        return result;\n\nFinally, the algorithm itself:\n\n    // Return a list of all integer quads (a,b,c,d), where:\n    //      a^2 + b^2 + c^2 + d^2 = N,\n    // and  a >= b >= c >= d,\n    // and  a,b,c,d >= 0\n    public List<int[]> FindAllFourSquares(int N)\n        // get all two-square sums <= N, in descending order\n        List<List<int[]>> Sqr2s = TwoSquareSumsLessThan(N);\n\n        // Cross the descending list of two-square sums <= N with\n        // the same list in ascending order, using a Merge-Match\n        // algorithm to find all combinations of pairs of two-square\n        // sums that add up to N\n        List<int[]> hiList, loList;\n        int[] hp, lp;\n        int hiSum, loSum;\n        List<int[]> results = new List<int[]>();\n        int prevHi = -1;\n        int prevLo = -1;\n\n        //  Set the Merge sources to the highest and lowest entries in the list\n        int hi = Sqr2s.Count - 1;\n        int lo = 0;\n\n        //  Merge until done ..\n        while (hi >= lo)\n            // check to see if the points have moved\n            if (hi != prevHi)\n                hiList = Sqr2s[hi];\n                hp = hiList[0];     // these lists cannot be empty\n                hiSum = hp[0] * hp[0] + hp[1] * hp[1];\n                prevHi = hi;\n            if (lo != prevLo)\n                loList = Sqr2s[lo];\n                lp = loList[0];     // these lists cannot be empty\n                loSum = lp[0] * lp[0] + lp[1] * lp[1];\n                prevLo = lo;\n\n            // do the two entries' sums together add up to N?\n            if (hiSum + loSum == N)\n                // they add up, so cross the two sum-lists over each other\n                foreach (int[] hiPair in hiList)\n                    foreach (int[] loPair in loList)\n                        // make a new 4-tuple and fill it\n                        int[] quad = new int[4];\n                        quad[0] = hiPair[0];\n                        quad[1] = hiPair[1];\n                        quad[2] = loPair[0];\n                        quad[3] = loPair[1];\n\n                        // only keep those cases where the tuple is already sorted\n                        //(otherwise it's a duplicate entry)\n                        if (quad[1] >= quad[2]) //(only need to check this one case, the others are implicit)\n                        //(there's a special case where all values of the 4-tuple are equal\n                        // that should be handled to prevent duplicate entries, but I'm\n                        // skipping it for now)\n                // both the HI and LO points must be moved after a Match\n            else if (hiSum + loSum < N)\n                lo++;   // too low, so must increase the LO point\n            else    // must be > N\n                hi--;   // too high, so must decrease the HI point\n        return results;\n\nAs I said before, it should be pretty close to O(N), however, as Yuval Filmus points out, as the number of Four Square solutions to N can be of order (N ln ln N), then this algorithim could not be less than that.\n\nshare|improve this question\nI can think of a $O(N^2)$ time algorithm. If you want to, I can post the details. How can you do it in linear time? \u2013\u00a0 Juho Aug 1 '12 at 20:57\nYes, please post it. I'm still developing the linear algorithm details, but I'm pretty sure it's valid. \u2013\u00a0 RBarryYoung Aug 1 '12 at 21:04\nFor the record, it appears that sometimes there are as many as $\\Omega(N\\log\\log N)$ solutions, so we can't really have an $O(N)$ algorithm. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 14:37\nFrom here, it looks like the catch (and the extra non-linear factor) comes from the two foreach() loops within your main while loop; your total time is basically $\\displaystyle\\sum_{i=0}^{N/2} |hiList_{N-i}|*|loList_i|$, and the problem is that the sizes of hiList and loList aren't necessarily bounded by any constant. \u2013\u00a0 Steven Stadnicki Aug 2 '12 at 18:30\nYes, that's correct, however your formula's a little bit off because first i ranges from 0 to apprx. N*PI/8, and second only a fraction of the values of i satisfy hiList(N-i)+loList(i) = N, so they are not all added in. In any event, there's no way to fix this and I am pretty sure that this gives the minimum possible complexity of O(N*log(log(N))). \u2013\u00a0 RBarryYoung Aug 2 '12 at 21:11\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nJuho's algorithm can be improved to an $O(N)$ algorithm using meet-in-the-middle. Go over all pairs $A,B \\leq \\sqrt{N}$; for each pair such that $M=A^2+B^2 \\leq N$, store $(A,B)$ in some array $T$ of length $N$ (each position $M$ could contain several pairs, which might be stored in a linked list). Now go over pairs $M,N-M$ such that the corresponding cells in $T$ are non-empty.\n\nThis way we get an implicit representation of all quadruples. If we want to list all of them, then we can't do any better than $\\Omega(N\\log\\log N)$, since Jacobi's four square theorem shows that (for odd $N$) the number of representations is $8\\sigma(N)$, and there are infinitely many integers such that $\\sigma(N) \\geq (e^\\gamma - \\epsilon) N\\log\\log N$ (see Gr\u00f6nwall's theorem).\n\nIn order to get less trivial algorithms, one can try to factor $N$ over the appropriate quaternion ring, since we know that the representations as sums of two squares correspond (in some sense) to these factorizations, through Lagrange's four-square identity. We would still need to find all representations of any relevant prime.\n\nshare|improve this answer\nHmm, the meet-in-the-middle thing sounds very similar to what I am working on (almost done) which is an ascending/descending Merge-Match algorithm over the TwoSquare pairs. Does that sound the same? \u2013\u00a0 RBarryYoung Aug 2 '12 at 14:35\nIt's probably the same, meet-in-the-middle is such a common heuristic that it must have many different names. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 14:36\nUmm, I've been out of academia for thirty years, what's the $\\sigma(N)$ thing mean? (or can you point me to a reference?) thnx. \u2013\u00a0 RBarryYoung Aug 2 '12 at 14:40\nOr is that $\\sigma(N)$ really a $\\omicron(N)$? \u2013\u00a0 RBarryYoung Aug 2 '12 at 15:01\nSum of divisors function indeed. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 15:48\nshow 1 more comment\n\nI think a $o(N^2)$ time algorithm is not a trivial one and requires some insight if one exists. The obvious algorithm that runs in quadratic time enumerates all tuples $A,B,C,D \\leq \\sqrt[]{N}$. This can be done in four loops, so the total time complexity becomes $O(N^2)$. It also clearly enumerates all solutions.\n\nAs relating algorithms, Rabin and Shallit [1] present two randomized algorithms for decomposing integers as sum of squares. For two squares, they give a $O(\\log^2 n)$ expected time algorithm. For four squares, they give a $O(\\log^2 n \\log \\log n)$ expected time algorithm. Note that the algorithms don't give you all the solutions, but merely just one.\n\n[1] M. O. Rabin, J. O. Shallit, Randomized Algorithms in Number Theory, Communications on Pure and Applied Mathematics 39 (1986), no. S1, pp. S239\u2013S256.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/3892/do-singularities-have-a-real-as-opposed-to-mathematical-or-idealized-existence?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI was thinking of, for example a Schwarzchild metric at r=0, i.e. the gravitational singularity, a point of infinite density. I realise that there are different types of singularities--timelike, spacelike, co-ordinate singularities etc. In a short discussion with Lubos, I was a bit surprised when I assumed they are idealized and I believe he feels they exist. I am not a string theorist, so am not familiar with how singularities are dealt with in it. In GR, I know the Penrose-Hawking singularity theorems, but I also know that Hawking has introduced his no-boundary, imaginary time model for the Big Bang, eliminating the need for that singularity. Are cosmic strings and other topological defects singularities or approximations of them (if they exist). In what sense does a singularity exist in our universe? --as a real entity, as a mathematical or asymptotic idealization, as a pathology in equations to be renormalized or otherwise ignored, as not real as in LQG, or as real in Max Tegmark's over-the-top \"all mathematical structures are real\"?\n\nshare|improve this question\nAnyway, I thought string theorists were intent on eliminating black hole singularities by infesting the interior of the event horizon with fuzzballs :) \u2013\u00a0 Gordon Jan 25 '11 at 23:56\nNot sure I can answer this question very well, but let me say this: singularities in physical theories always indicate that something is wrong in the particular domain to which you are applying them. No observable variables can be infinite in value in physics. \u2013\u00a0 Noldorin Jan 26 '11 at 0:12\n\n3 Answers 3\n\nup vote 3 down vote accepted\n\nDear Gordon, I hope that other QG people will write their answers, but let me write mine, anyway.\n\nIndeed, you need to distinguish the types of singularities because their character and fate is very different, depending on the type. You rightfully mentioned timelike, spacelike, and coordinate singularities. I will divide the text accordingly.\n\nCoordinate singularities\n\nCoordinate singularities depend on the choice of coordinates and they go away if one uses more well-behaved coordinates. So for example, there seems to be a singularity on the event horizon in the Schwarzschild coordinates - because $g_{00}$ goes to zero, and so on. However, this singularity is fake. It's just the artifact of using coordinates that differ from the \"natural ones\" - where the solution is smooth - by a singular coordinate transformation.\n\nAs long as the diffeomorphism symmetry is preserved, one is always allowed to perform any coordinate transformation. For a singular one, any configuration may start to look singular. This was case in classical general relativity and it is the case for any theory that respects the symmetry structure of general relativity.\n\nThe conclusion is that coordinate singularities can never go away. One is always free to choose or end up with coordinate systems where these fake singularities appear. And some of these coordinate systems are useful - and will remain useful: for example, the Schwarzschild coordinates are great because they make it manifest that the black hole solution is static. Physics will never stop using such singularities. What about the other types of the singularities?\n\nSpacelike singularities\n\nMost famously, these include the singularity inside the Schwarzschild black hole and the initial Big Bang singularity.\n\nDespite lots of efforts by quantum cosmologists (meaning string theorists working on cosmology), especially since 1999 or so, the spacelike singularities remain badly understood. It's mainly because they inevitably break all supersymmetry. The existence of supersymmetry implies the existence of time-translational symmetry - generated by a Hamiltonian, the anticommutator of two supercharges. However, this symmetry is brutally broken by a spacelike singularity.\n\nSo physics as of 2011 doesn't really know what's happening near the very singular center of the Schwarzschild black hole; and near the initial Big Bang singularity. We don't even know whether these questions may be sharply defined - and many people guess that the answer is No. The latter problem - the initial Big Bang singularity - is almost certainly linked to the important topics of the vacuum selection. The eternal inflation answers that nothing special is happening near the initial point. A new Universe may emerge out of its parent; one should quickly skip the initial point because nothing interesting is going on at this singular place, and try to evolve the Universe. The inflationary era will make the initial conditions \"largely\" irrelevant, anyway. However, no well-defined framework to calculate in what state (the probabilities...) the new Universe is created is available at this moment.\n\nYou mentioned the no-boundary initial conditions. I am a big fan of it but it is not a part of the mainstream description of the initial singularity as of 2011 - which is eternal inflation. In eternal inflation, the initial point is indeed as singular as it can get - surely the curvatures can get Planckian and maybe arbitrarily higher - however, it's believed by the eternal inflationary cosmologists that the Universe cannot really start at this point, so they think it's incorrect to imagine that the boundary conditions are smooth near this point in any sense, especially in the Hartle-Hawking sense.\n\nThe Schwarzschild singularity is different - because it is the \"final\" spacelike singularity, not an initial condition - and it's why no one has been talking about smooth boundary conditions over there. Well, there's a paper about the \"black hole final state\" but even this paper has to assume that the final state is extremely convoluted, otherwise one would macroscopically violate the predictions of general relativity and the arrow of time near the singularity.\n\nWhile the spacelike singularities remain badly understood, there exists no solid evidence that they are completely avoided in Nature. What quantum gravity really has to do is to preserve the consistency and predictivity of the physical theory. But it is not true that a \"visible\" suppression of the singularities is the only possible way to do so - even though this is what people used to believe in the naive times (and people unfamiliar with theoretical physics of the last 20 years still believe so).\n\nTimelike singularities\n\nThe timelike singularities are the best understood ones because they may be viewed as \"classical static objects\" and many of them are compatible with supersymmetry which allowed the physicists to study them very accurately, using the protection that supersymmetry offers.\n\nAnd again, it's true that most of them, at least in the limit of unbroken supersymmetry and from the viewpoint of various probes, remained very real. The most accurate description of their geometry is singular - the spacetime fails to be a manifold, i.e. diffeomorphic to an open set near these singularities. However, this fact doesn't lead to any loss of predictivity or any inconsistency.\n\nThe simplest examples are orbifold singularities. Locally, the space looks like $R^d/\\Gamma$ where $\\Gamma$ is a discrete group. It's clear by now that such loci in spacetime are not only allowed in string theory but they're omnipresent and very important in the scheme of things. The very \"vacuum configuration\" typically makes spacetime literally equal to the $R^d/\\Gamma$ (locally) and there are no corrections to the shape, not even close to the orbifold point. Again, this fact leads to no physical problems, divergences, or inconsistencies.\n\nSome of the string vacua compactified on spaces with orbifold singularities are equivalent - dual - to other string/M-theory vacua on smooth manifolds. For example, type IIA string theory or M-theory on a singular K3 manifold is equivalent to heterotic strings on tori with Wilson lines added. The latter is non-singular throughout the moduli space - and this fact proves that the K3 compactifications are also non-singular from a physics viewpoint - they're equivalent to another well-defined theory - even at places of the moduli spaces where the spacetime becomes geometrically singular.\n\nThe same discussion applies to the conifold singularities; in fact, orbifold points are a simple special example of cones. Conifolds are singular manifolds that include points whose vicinity is geometrically a cone, usually something like a cone whose base is $S^2\\times S^3$. Many components of the Riemann curvature tensor diverge. Nevertheless, physics near this point on the moduli space that exhibits a singular spacetime manifold - and physics near the singularity on the \"manifold\" itself - remains totally well-defined.\n\nThis fact is most strikingly seen using mirror symmetry. Mirror symmetry transforms one Calabi-Yau manifold into another. Type IIA string theory on the first is equivalent to type IIB string theory on the second. One of them may have a conifold singularity but the other one is smooth. The two vacua are totally equivalent, proving that there is absolutely nothing physically wrong about the geometrically singular compactification. We may be living on one. The equivalence of the singular compactifications and non-singular compactifications may be interpreted as a generalized type of a \"coordinate singularity\" except that we have to use new coordinates on the whole \"configuration space\" of the physical theory (those related by the duality) and not just new spacetime coordinates.\n\nIt's very clear by now that some singularities will certainly stay with us and that the old notion that all singularities have to be \"disappeared\" from physics was just naive and wrong. Singularities as a concept will survive and singular points at various moduli spaces of possibilities will remain there and will remain important. Physics has many ways to keep itself consistent than to ban all points that look singular. That's surely one of the lessons physics has learned in the duality revolution started in the mid 1990s. Whenever physics near/of a singularity is understood, we may interpret the singularity type as a generalization of the coordinate singularities.\n\nAt this point, one should discuss lots of exciting physics that was found near singularities - especially new massless particles and extended objects (that help to make singularities innocent while preserving their singular geometry) or world sheet instantons wrapped on singularities (that usually modify them and make them smooth). All these insights - that are cute and very important - contradict the belief that there's no \"valid physics near singularities because singularities don't exist\". Spacetime manifolds with singularities do exist in the configuration space of quantum gravity, they are important, and they lead to new, interesting, and internally consistent phenomena and alternative dual descriptions of other compactifications that may be geometrically non-singular.\n\nshare|improve this answer\nAren't there corrections to the geometry in the vicinity of an orbifold fixed point due to radiative corrections? The radiative corrections differ from the unorbifolded case because in a quantum field theory over orbifolds, we have to eliminate zero-point modes not respecting the orbifold projections. \u2013\u00a0 QGR Jan 26 '11 at 9:37\nDear @QGR, there are corrections to various physics phenomena near the orbifold singularity - because of the projection on the spectrum as well as the existence of a twisted sector with completely new states - but the metric itself, as seen e.g. by propagating gravitons etc., remains fully uncorrected - due to a supersymmetry non-renormalization theorem. In general, cancellations implied by supersymmetry make things more consistent rather than less consistent. In this case, SUSY also cancels corrections to a singularity so it remains singular: no problems arise because of that. \u2013\u00a0 Lubo\u0161 Motl Jan 26 '11 at 12:50\nMany thanks for the detailed answer, Lubos. It was a pleasure to read. \u2013\u00a0 Gordon Jan 26 '11 at 17:16\n\u0161: Right, I was thinking of the nonsupersymmetric case. \u2013\u00a0 QGR Jan 27 '11 at 16:34\n\nThe singularity in a Schwarzschild metric is a three dimensional space where the Weyl curvature diverges. There are reasons why we might think this is \u201cquantized,\u201d for otherwise the quantum evaporation would present the outside world with a singularity.\n\nAn observer that follows a string into a black hole will observe the tidal forces on the string increase. It is extended along the radial direction and its energy increases. The extension is along the $X^+$ direction, and the gauge for the system is set on the $X^-$ direction. This is opposite the gauge condition the exterior observer employs in observing the string fill up the stretched horizon of the black hole. The analysis for the string on the horizon can be found in Susskind & Lindsey \u201cBlack Holes, Information and the String Revolution\u201d If it is desired I can work out the case of the string which falls into the black hole.\n\nThe string falling towards the singularity becomes highly excited and reaches the singularity in some state. It probably ends as an open string on a brane dual to the NS5-brane. The string ends in this state of affairs, or it reaches its upper temperature limit and becomes something we are not well acquainted with.\n\nThe density of states for a string with respect to modes n is $$ \\eta(n)~\\sim~ exp(4\\pi n \\sqrt{\\alpha\u2019}) $$ that defines a partition function $Z~=~ \\int \\eta(n)exp(-n/T)dn$. The temperature is computed by $1/T~=~\\partial Z/\\partial n$ and the path integral diverges for a temperature greater than $$ T_H~=~4\\pi \\sqrt{\\alpha\u2019} $$ which is the Hagedorn temperature. This is proportional to the reciprocal of the string length. The entropy of the system is the logarithm of the density of states the $S~\\sim~ 1/nT_H$, which in the large n limit is zero. The modes number is given by $n~=~1/(\\sqrt{d}M_s)$, for d the number of degrees of freedom and $M_s$ the string mass.\n\nThese physical conditions occur before the Planck energy is reached. Consequently the Schwarzschild singularity is valenced by quantum mechanics. The singularity is valenced by, or really replaced with, a D-brane with a gas of II strings or a D-brane with a gas of D0-brane solitons or \u2026 .\n\nshare|improve this answer\n\nOf course, not. Singularities are prohibited by the Cosmic Censorship principle.\n\nEven more: no matter can ever move under the so-called \"event horizon\" because as one approaches the horizon or any other potential well, the time slows, and on the horizon it slows infinitely. Thus if the horizon existed, nobody could reach it in finite time, and the black hole existence time is finite, so any black hole would evaporate before the falling observer reaches the event horizon.\n\nThe singularity and event horizon terminology is useful only in theory which does not account for quantum effects and thermodynamics.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/2166/bertrands-postulate/2173\nText:\nTake the 2-minute tour \u00d7\n\nStatement For every $n > 1$ there is always at least one prime $p$ such that $n < p < 2n$.\n\nI am curious to know that if I replace that $2n$ by $2n-\\epsilon$, ($\\epsilon>0$) then what is the $\\inf (\\epsilon)$ so that the inequality still holds, meaning there is always a prime between $n$ and $2n-\\epsilon$\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 2 down vote accepted\n\nThree related points are worthy of mention, showing that epsilon can be close to n.\n\nThere is a result of Finsler that approximates how many primes lie between n and 2n, which is of order o(n/log(n)) as is to be expected by the Prime Number Theorem.\n\nLiterature on prime gaps will tell you the exponent delta such that there is (for sufficiently large n) at least one prime in the interval (n , n + n^delta). I think delta is less than 11/20.\n\nObserved data suggests that n^delta can be replaced by something much smaller: for n between something like 3 and 10^14 , some function like 2(log(n))^2 works.\n\nshare|improve this answer\n\nBertrand's postulate is\n\nif n > 3 is an integer, then there always exists at least one prime number p with n < p < 2n \u2212 2.\n\nThus \u03b5 < 2 for n > 3. What if n \u2264 3?\n\n  \u2022 For n = 3, 3 < 5 < 6 - \u03b5 \u21d2 \u03b5 < 1\n  \u2022 For n = 2, 2 < 3 < 4 - \u03b5 \u21d2 \u03b5 < 1\n\nHence we have 0 < \u03b5 < 1, if \u03b5 is a constant.\n\nshare|improve this answer\nnow the question may be more interesting. I actually wanted to find the least postive $\\epsilon$ such that the condition remains true. \u2013\u00a0 anonymous Aug 11 '10 at 16:21\n@Chandru1: Any \u03b5 between 0 and 1 will do, so the infimum of all possible positive \u03b5 is 0. This is not surprising. Did you want the supremum instead? (The supremum is 1 of you want it to hold for n=2 or 3, and infinity if you only want sufficiently large n.) \u2013\u00a0 ShreevatsaR Aug 11 '10 at 16:44\n@ShreevatsaR : Hi i got it. \u2013\u00a0 anonymous Aug 11 '10 at 16:50\n\nThe answer depends if you want an answer that is true \"for all n\" or an answer that is true \"for all sufficiently large n.\" For instance, there is not always a prime in an interval of the form (n, 3n/2). Take n=7, for instance. There is always a prime in such an interval \"for sufficiently large n,\" however.\n\nshare|improve this answer\n\nThis was there in the proof of Bertrand's theorem.\n\nif $n>60$, then $\\varepsilon=\\frac{2n}{3}$.\n\nshare|improve this answer\nHi! Welcome to math.SE. This solution would be more helpful if you cited readers to the proof you are referring to. Might you be able to add that? \u2013\u00a0 rschwieb Dec 28 '12 at 14:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/128508/gluing-gerbes-over-a-spectrum-of-a-field\nText:\nTake the 2-minute tour \u00d7\n\nA theorem of Giraud says that gerbes over a scheme $X$ bounded by a sheaf of Abelian groups $A$ are classified by elements of the etale cohomology group $H^2(X,A)$. Similar statements hold in other categories (differential, topological) as well.\n\nOne of the points of view on gerbes (emphasized, for example, by Hitchin in \"Lectures on special Lagrangian manifolds\") is that a gerbe can be glued from trivial gerbes just like a vector bundle can be glued from trivial vector bundles, but the gluing data is not transition functions but A-torsors. I am trying to see if this philosophy can be applied to gerbes over a spectrum of a (perfect) field $k$. Giraud's theorem tells in this case that isomorphism classes of gerbes are in bijective correspondence with elements of the Galois cohomology group $H^2(k, A)$.\n\nLet $k'/k$ be Galois with Galois group $G$ and let $A$ be an Abelian algebraic group defined over $k$ (we use $A$ to denote the corresponding Galois module). The Hochshild-Serre spectral sequence yields the following exact sequence: $$ \\ldots \\to H^2(G,A^{G_{k'}}) \\to \\mathrm{Ker}(H^2(k,A) \\to H^2(k',A)) \\to H^1(G,H^1(k',A)) \\to H^3(G,A^{G_{k'}})\\ldots $$ where $G_{k'}$ is the absolute Galois group of $k'$. Suppose we have a gerbe over $\\mathrm{Spec}\\ k$ that trivialises after base change to $\\mathrm{Spec}\\ k'$. An element of $H^1(G,H^1(k',A))$ is the gluing data that has been mentioned above (indeed, $H^1(k',A)$ classifies $A$-torsors defined over $k'$). If also the second and third cohomology of $G$ with coeffecients in $A^{G_{k'}}$ vanished then we would have an isomorphism between two middle terms of the sequence which means that any gerbe that trivialises over $\\mathrm{Spec}\\ k'$ can be described in terms of this gluing data.\n\nI have the following question: is it true that for any gerbe over $k$ one can always find a Galois extension $k'$ with Galois group $G$ such that the gerbe trivialises after base change to $k'$ and $H^2(G,A)$ and $H^3(G,A)$ vanish?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nI don't think so. I think a gerbe bound by $A$ over the spectrum of a field $k$ gives a cohomology class $\\eta\\in H^2(k,A)$, and the gerbe trivializes over an extension $k'/k$ if and only if this cohomology class trivializes. Now take $k=\\mathbb{R}$, $A=\\mathbf{G}_{m,\\mathbb{R}}$, then $H^2(k, A)={\\rm Br}(\\mathbb{R})=\\frac{1}{2}\\mathbb{Z}/\\mathbb{Z}$. Let $\\eta\\in{\\rm Br}(\\mathbb{R})$ be the nontrivial element (corresponding to Hamilton's quaternions). Then $\\eta$ trivializes over $\\mathbb{C}$, but not over $\\mathbb{R}$, so $k'=\\mathbb{C}$, $G={\\rm Gal}(\\mathbb{C}/\\mathbb{R})$, and $H^2(G,A)=H^2(\\mathbb{C}/\\mathbb{R},\\mathbf{G}_m)={\\rm Br}(\\mathbb{R})\\neq 0$, so $H^2(G,A)$ does not vanish.\n\nshare|improve this answer\nindeed, the statement I hoped for is false. Do you think it might still be true for some classes of fields? For example, fields finitely generated over an algebraically closed field? \u2013\u00a0 Dima Sustretov Apr 24 '13 at 7:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/289375/bound-for-the-product-of-numbers/289771\nText:\nTake the 2-minute tour \u00d7\n\nLet $n \\in N$. Fix $m \\in [-n,n]$. I am curious, how to bound from above the following expression $$ (n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}}\\leq \\quad ? $$\n\nThank you.\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\n$$ (n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}} = n^{n+3/2}\\exp\\left(\\frac{n-m+2}{2}\\log(1+m/n)+\\frac{n+m+1}{2}\\log(1-m/n))\\right) \\leq n^{n+3/2}\\exp\\left(\\frac{m(n-m+2)}{2n}-\\frac{m(n+m+1)}{2n}\\right) = n^{n+3/2} \\exp\\left(\\frac{m-2m^2}{2n}\\right) \\leq n^{n+3/2} \\exp\\left(\\frac{1}{16n}\\right),$$\n\nand from the Taylor series of $\\log(1+x)$ and $\\log(1-x)$ in a neighbourhood of zero it is not difficult to derive lower bounds, too.\n\nshare|improve this answer\n\n$(n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}}\\leq (2n)^{n+1}(2n)^{n+1/2}=(2n)^{2n+3/2}$\n\nshare|improve this answer\nThank you, but I would like to get more accurate bound. I was trying to maximize this expression, but it turns out that there is no global maximum... Also, I've realized I did not mentioned that $m$ is fixed. Sorry. \u2013\u00a0 Alex Jan 29 '13 at 0:06\n\nI have had good luck tightening bounds by finding the form $(a-b)(a+b)$ which you already have. $$a^2 - b^2 \\le a^2 - b^2 \\le a^2$$ is a much better bound than the naive $$(a-b)^2 \\le (a-b)(a+b) \\le (a+b)^2$$ (with $b \\lt a$)\n\nSo for your problem, I would take as many factors of $n^2 - m^2$ as I can. Which exponent is larger switches at $m=\\frac12$ so treat each interval separately.\n\nFor $m \\ge \\frac 12$ we can break your expression as follows: $$ (n-m)^{\\frac{n-m+2}2} (n+m)^{\\frac{n-m+2}2} (n+m)^{m-\\frac12} $$ which is $$ (n^2-m^2)^{\\frac{n-m+2}2} (n+m)^{m-\\frac12} $$ To simplify the powers I will only eliminate $m$ from the quantities in parentheses. The previous expression is less than: $$ (n^2)^{\\frac{n-m+2}2} (2n)^{m-\\frac12} $$ which equals $$ n^{n-m+2} 2^{m-\\frac12} n^{m-\\frac12} $$ and $$ 2^{m-\\frac12} n^{n+\\frac32} $$\n\nYou can complete the same steps for $m \\le \\frac12$ to obtain a similar expression, then combine these for the overall upper bound.\n\nEdit: with the correction I just made it appears that both cases produce the same expression, so the result above should be the overall upper bound.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/integration-by-substitution-its-been-a-while.289116/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntegration By Substitution It's Been A While\n\n  1. Feb 1, 2009 #1\n\n    It's been god knows how long since I've had to use integration by substitution. I've totally forgotten it. I am trying to integrate to solve for the value of an electric field at a given point. The integral I am trying to solve is:\n\n    (2kz/4(pi)(epsilon_0)*1/(z^2+x^2)^(3/2) dx.\n\n    I know the answer is (2kz/4(pi)(epsilon_0)*(x/[z^2(z^2+x^2)^(1/2)]\n\n    2. Relevant equations\n\n    I'm sure I have to set u=(z^2+x^2). This makes du = 2x.\n\n    3. The attempt at a solution\n\n    I'm confused as to what to do now. The equation I'm integrating doesn't have an x in it anywhere. I don't think I can say du/2x=dx because I will have x's and u's in the integral, which is no good. However, I can't just ignore it.\n\n    Also, how did that z^2 get in there on the bottom? z is a constant in this integration and since u = z^2+x^2, the z-term drops right out. I feel terribly lost.\n  2. jcsd\n  3. Feb 1, 2009 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    That's really confusing. Why don't you just post the actual problem you are working on and how you tried to solve it?\n  4. Feb 1, 2009 #3\n    Sure thing.\n\n    I'm trying to find the electric field at an arbitrary distance z above a straight line segment, where the arbitrary distance z is measured above one of the endpoints of the line segment.\n\n    Relevant Equations:\n\n    We are given that the electric field of a line charge is [tex]\\frac{1}{4 \\pi \\epsilon_0} \\int_P \\frac{\\lambda (R)}{r^2}dl[/tex].\n\n    Attempt At Solution.\n\n    A little element of the electric field is going to be pointed in two directions. One will be in the z-direction. The other will be in the direction parallel to the line. Using the geometry of the problem, I found that\n\n    [tex] dE=\\frac{1}{4 \\pi \\epsilon_0}\\frac{\\lambda dx}{r^2}(cos(\\theta) \\textbf{z}+sin(\\theta)\\textbf{x})=\\frac{\\lambda}{4 \\pi \\epsilon_0}\\frac{\\lamda dx}{r^3}(z\\textbf{z}+x\\textbf{x})[/tex], where the bold indicates unit vectors.\n\n    I split this up into two integrals. This is where I have to integrate by parts, and where I get stuck. I have for instance, one integral which is [tex]\\frac{1}{4 \\pi \\epsilon_0} \\int_0^L \\frac{2 \\lambda z}{(z^2+x^2)^{3/2}}}dx[/tex].\n\n    I set my u = (z^2+x^2) and my du is then 2xdx. I am confused because there is no x in my numerator, and I can't just say du/2x=dx because then I am going to have both x's and u's in my equation when I integrate it.\n  5. Feb 2, 2009 #4\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Well, if [itex]u = (z^2+x^2)[/itex], then [itex]2x=2\\sqrt{u-z^2}[/itex] right?....but I don't think that makes the integral any easier!\n\n    Try the substitution [tex]u=\\frac{x}{\\sqrt{x^2+z^2}}[/tex] instead :wink:\n  6. Feb 2, 2009 #5\n    Ah, I got it, I think.\n\n    If I use the u-substitution you suggest, I get [tex]du=\\frac{1}{\\sqrt{x^2+z^2}}-\\frac{x^2}{(x^2+z^2)^{3/2}}dx[/tex], which, getting a common denominator yields:\n\n\n    So [tex]\\frac{du}{z^2}=\\frac{dx}{(x^2+z^2}dx[/tex]\n\n    My integral is then just [tex]\\frac{\\lambda z}{4 \\pi \\epsilon_0}\\int_a^b \\frac{du}{z^2}[/tex] which, after re-substituting for u back into x's, and plugging in the bounds 0 and L, I get\n\n    [tex] \\frac{1}{4 \\pi \\epsilon_0} \\frac{\\lambda z L}{z^2(z^2+x^2)^{3/2}}[/tex].\n\n    Thanks, though I still wonder how I would have thought of that particular u-substitution on my own!\n\nHave something to add?\n\nSimilar Discussions: Integration By Substitution It's Been A While\n  1. Integral substitution? (Replies: 3)\n\n  2. Integral substituting (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/group-theory-question.198217/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nGroup theory question\n\n  1. Nov 14, 2007 #1\n\n    If p is a prime and G is group of order p^2, then show that G is abelian.\n\n    2. Relevant equations\n\n\n    3. The attempt at a solution\n\n    I first consider Z(G), the centre of G. Since it is a normal subgroup of G, then by Lagrange's Theorem, |Z(G)| divides |G|. Hence |Z(G)| = 1, p or p^2. We know that Z(G) not the trivial subgroup (proof already given) hence it must be of order p^2 or p.\n\n    If |Z(G)| = p^2, then Z(G) = G and hence by definition it is abelian.\n\n    If |Z(G)| = p, then .... well this is where I am stuck! :(\n\n    Please help!\n  2. jcsd\n  3. Nov 14, 2007 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Consider an element q that is not in Z(G). How big is the subgroup generated by q and Z(G)?\n  4. Nov 14, 2007 #3\n    In the case of your argument, if [itex] |Z(G)| = p [/itex] then we have that\n\n    [itex]\\frac{|G|}{|Z(G)|} = p[/itex] which we can't have.\n\n    So on the other hand, we know that if [itex] \\exists a \\in G[/itex] such that [itex] o(a) = p^2[/itex] where [itex] o(a) [/itex] is the order of a, then [itex] G = C_{p^2} [/itex]. Thus we can assume that every non-identity element has order p, since the order of the elements must divide the order of the group.\n\n    Thus consider a non-identity element of G, say a, and the subgroup it generates. Furthemore, consider another non-identity element, say b, that is not in [itex]<a>[/itex]. Such an element is guaranteed to exist since [itex]o(a) = p \\Rightarrow |<a>|\\neq|G| [/itex]. Consider the subgroup generated by [itex]b[/itex].\n\n    What can we say about the order of [itex] <a> [/itex] and the order of [itex] <b> [/itex] ?. What can we say about their intersection? What can we say about the order of their product?\n  5. Nov 14, 2007 #4\n    If we assume that every non-identity element has order p, then <a>, <b> would have order p also. Wouldn't their intersection be the empty set if b is defined as an element not in <a>? Sorry I'm not sure where I'm supposed to go with this.\n  6. Nov 14, 2007 #5\n    That's precisely correct. They're intersection is empty, and so\n\n    [tex] |<a> \\times <b>| = \\frac{|<a>||<b>|}{|<a>\\cap<b>|} = |<a>||<b>| = p^2 [/tex]\n\n    Thus, since [itex] a \\in G, \\; b\\in G, \\; \\text{ and } |<a> \\times <b>|=|G| [/itex] then\n\n    [tex] <a> \\times <b> = G [/tex]\n\n    Now the question is, what is [itex] <a> \\times <b> [/itex] isomorphic to?\n  7. Nov 14, 2007 #6\n    for any group G, if G/Z(G) has prime order, then G/Z(G) is cyclic, hence G is abelian\n  8. Nov 14, 2007 #7\n    Cyclic group of order p^2?\n  9. Nov 14, 2007 #8\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Assume G is non-abelian and go by contradiction.\n\n    And you'll need ircdan's statement.\n\n    It's a nice question.\n  10. Nov 14, 2007 #9\n    [tex] C_p \\times C_p [/tex]\n  11. Nov 14, 2007 #10\n    Via this method we've actually proved something stronger than the actual question. Namely that every group of order [tex] p^2 [/tex] is isomorphic to either [itex]C_{p^2} \\text{ or } C_p \\times C_p [/itex]\n  12. Nov 14, 2007 #11\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    This question pretty much does that.\n  13. Nov 14, 2007 #12\n    Is [tex]C_p \\times C_p[/tex] also cyclic? How do you know it is abelian?\n  14. Nov 14, 2007 #13\n    C_p x C_p is not cyclic but it is abelian since each factor is\n  15. Nov 14, 2007 #14\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    This question tells us that all groups of order p^2 are abelian.\n\n    What kind of abelian groups are there of order p^2?\n\n    Well, it can be cyclic if it has an element of order p^2 if not, then all the elements must be of order p (Lagrange's Theorem). And you work from there.\n  16. Nov 14, 2007 #15\n    Thanks for all the help! I've written the proof both ways and they seem to be pretty much equivalent.\n\n    I'm not sure if I should open a new thread for this but I would appreciate some help on another related question:\n\n    \"If G is a group of order 48 then show that it is not simple\"\n\n    Now |G| = 2^4 * 3. I'm thinking it would be a similiar argument to how you show groups of order (p^2 * q) are not simple, but in all honesty I don't even understand the proof for that very well.\n\n    I guess if you apply Sylow's theorem, then clearly there are Sylow p-subgroups of order 2^4. Are these p-subgroups normal? If so, how would you go about showing this?\n  17. Nov 14, 2007 #16\n    A theorem by Burnside states that the center of a finite p-group is non-trivial. So if |G|=p^2 and Z(G)!=G choose x in G so that x not in Z(G). We know by divisibility that Z(G) >= p (Burnside). But that means the centralizer C(x) must be G a contradiction. So Z(G)=G.\n  18. Nov 15, 2007 #17\n    you can produce a counting arguement\n  19. Nov 15, 2007 #18\n    Can you elaborate on that? (I assume you are talking about |G| = 48 not being simple)\n  20. Nov 15, 2007 #19\n    I imagine you should exploit the class equation\n  21. Nov 15, 2007 #20\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    How many of these can we have? Let n be the number of Sylow-2's. Then n=1(mod2) and n|3. This leaves us with n=1 or n=3. If n=1, we're done, because this implies the unique Sylow-2 is normal in G (why?). So suppose n=3. One possible way you can proceed from here is via group actions. Let G act on the set X of 3 Sylow-2's by conjugation. This induces a nontrivial homomorphism from G into Sym(X). What is its kernel? (Don't think too hard about what the kernel actually is; think about what kernels are, and how they could be relevant to proving the non-simplicity of G.)\n    Last edited: Nov 15, 2007\n\nHave something to add?\n\nSimilar Discussions: Group theory question\n  1. Group theory question (Replies: 5)\n\n  2. Group theory question (Replies: 3)"}
{"text": "Retrieved from http://mathoverflow.net/questions/82332/seeking-a-solution-algorithm-to-the-3-partition-problem\nText:\nTell me more \u00d7\n\nI need to divide 48 pieces of jewelry between 3 inheritors so as to give equal, or nearly equal value, to each. I have learned that this is called the 3-partition problem. I solved it for 9 pieces of jewely by exhaustive enumeration (some 19,000 possibilities) in a spreadsheet (LibreOffice Calc). No big deal. But all 48 pieces becomes a big deal.\n\nI don't actually need a perfect solution. A heuristic algorithm would suffice if it were acknowledged as an acceptable solution scheme by some set of professionals; programmers, estate settling lawyers, etc. In other words using a technique recognized as \"good enough\" will be good enough for my purpose.\n\nThis question is also posted on StackOverflow. They suggested I post here.\n\nThank you, David\n\nshare|improve this question\nThe problem is NP-complete to find an exact 3-partition; see the short Wikipedia description: So you have two choices: An exhaustive search of all possibilities, or approximation algorithms. \u2013\u00a0 Joseph O'Rourke Dec 1 '11 at 1:58\nTo: Joseph O'Rourke: it is the approximation algorithms that I seek. Where is one described? I've been on mathisfun and codingthewheel and don't find it there. \u2013\u00a0 Grabs At Strawberries Dec 1 '11 at 3:54\nThe first thing I'd do is to take a brief look at how the appraised values are distributed. You may find that it is obviously problematic (for example, if there are just a handful of exceptionally valuable pieces, which can't themselves be divided evenly into thirds, and the remaining pieces can't make up the difference). If you are lucky, there will be many pieces with roughly comparable values. In that case, simple randomized heuristics probably get you close enough for practical purposes (since, unless you actually have an offer on the table, the appraisals will have some error anyway). \u2013\u00a0 Henry Cohn Dec 1 '11 at 4:34\nOne difficulty in giving an abstract answer is that it's not clear how to model this. For example, one could try to bound the worst-case approximation ratio; this is an interesting theoretical question, but I'm not convinced it would shed much light on what you can do in practice. It really depends on the numbers. \u2013\u00a0 Henry Cohn Dec 1 '11 at 4:40\nI suggest you hire a mathematical consultant. Mathematicians have put in the hard yards to get to where they can solve this kind of problem; they deserve to be paid for their specialist skills. \u2013\u00a0 Gerry Myerson Dec 1 '11 at 5:03\nshow 5 more comments\n\n2 Answers\n\nThere exists a pseudo-polynomial time dynamic programming solution to this problem, for which running time and storage complexity depend on the sum of costs of the pieces of jewelry, denoted $S$. If the sum of costs, $S$, is small then the algorithm would be practical as its storage is $O(S^2)$ and its running time is $O(S^2N)$, $N$ being the number of pieces (48 here).\n\nTo get a sense of the algorithm take a look at the Subset sum problem Wikipedia page--dynamic programming solution. This concerns finding a subset of items which sums to a particular cost. Clearly you can solve the 2-partition problem by using the subset sum solutions, i.e., by enumerating over all the potential subset sums, and choosing the one that you prefer for any reason.\n\nNow generalizing to 3-partition is straightforward. You basically solve the double-subset sum problem. You store $Q(i,s, t)$ to be the value (true or false) of \"whether there are two disjoint subsets of $x_1, \\ldots, x_i$ which respectively sum to $s$ and $t$\". You can easily update $Q(i, s, t)$ by adding new items. Again one can enumerate over the potential $Q(N, s, t)$'s and choose the one that is considered best.\n\nObviously even if $S$ is large, the costs can be quantized using larger cost units, which results in a measurable upper bound on the error. This also can be used combined with the solution of Brendan McKay to guide a local search algorithm.\n\nshare|improve this answer\nAs a (perhaps useless) supplement to this description, Exercise 6.25 in the Dynamic Programming chapter of Vazirani's algorithms textbook (PDF: asks to devise \"a dynamic programming algorithm for 3- PARTITION that runs in time polynomial in $n$ and in\" $S$. [p.197] \u2013\u00a0 Joseph O'Rourke Dec 1 '11 at 20:50\nadd comment\n\nTo get a good approximation, I suggest a local refinement algorithm. Define some success measure (like the maximum value of a share minus the minimum value). Start with any distribution into three shares.\n\nNow move a small number of pieces into different shares if they improve the success measure. Keep doing that until no such improvement is possible. With 48 items, you should be able to find a partition where no movement of 4 or fewer items improves the success measure, and this will be a fairly good solution.\n\nStart with different random partitions to see if you get the same final result. If so, there is a fair chance (in practice, not in theory!) that you have the best solution. If you get multiple final results, you can at least choose the best one.\n\nA variation is to allow movement of a small number of pieces with low probability even if the success gets worse. Maybe the probability can depend on how much worse the success gets. This can get you out of local minima but you will never find the global minimum if you set the probabilities too high.\n\nMore sophisticated algorithms like simulated annealing, genetic search, and tabu search are out there and can be adapted to this problem.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/10854/subvalue-and-level/10868\nText:\nTell me more \u00d7\n\nI'm interested in the arguments of f in expressions like\n\n\nBy argument I mean what is here a, b and c. I would like to know the arguments and in what order they appear. For example, the order of the arguments in\n\n f[d]@(2 x f[b])@f[c]@f[q]\n\n\n {d, b, c, q}\n\nHow can I find this from the above expression? I tried to use Level[], but the Subvalue construction is hindering me.\n\nshare|improve this question\nWhat would be an appropriate title for this question? \u2013\u00a0 sjdh Sep 20 '12 at 12:01\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nHere is another way:\n\nCases[f[d]@(2 x f[b])@f[c]@f[q], f[x_] :> x, {-2}, Heads -> True]\nshare|improve this answer\nadd comment\n\nThis works:\n\nexpr = f[d]@(2 x f[b])@f[c]@f[q];\nExtract[expr, Position[expr, f[_]], First]\n   {d, b, c, q}\n\nNote that Extract[] and Position[] are able to handle expressions with any head, not just lists.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/42818/stable-orthogonalization-procedure?sort=newest\nText:\nTell me more \u00d7\n\nAt a high level, my question is the following: given a set of $k$ vectors in Euclidean space which are pairwise \"almost orthogonal\", can one find a set of $k$ orthogonal vectors which are pairwise close to the original ones? This could be seen as a stable version of Gram-Schmidt orthogonalization, in which, under the promise that the original set of vectors is not too far from being orthogonal, one has the guarantee that they do not need to be moved too much in order to become orthogonal.\n\nMore precisely, assume given vectors $v_i$, $i=1,\\ldots,k$ in a real (or complex) $k$-dimensional space, such that $\\sum_{i\\neq j} \\langle v_i,v_j\\rangle \\leq \\epsilon k$ ($\\epsilon$ should be understood as an arbitrarily small constant, or it could even be $o(k)$ if needed -- the weaker the assumption the better). Then, does there exist a set of orthogonal vectors $w_i$ such that $\\sum_i \\|w_i - v_i\\|^2 \\leq \\epsilon' k$? (The norm is the usual Euclidean norm.) The interesting question is whether one can get an $\\epsilon'$ which depends on $\\epsilon$ only, not on $k$.\n\nA related question (the one I am originally most interested in), is that of orthogonalizing $d$-dimensional projector matrices $P_1,\\ldots,P_k$: assume $\\frac{1}{d} \\sum_{i\\neq j} \\langle P_i,P_j \\rangle \\leq \\epsilon$ (where now the inner product is the trace inner product), can you find orthogonal projectors $Q_i$ such that $\\frac{1}{d}\\sum_i \\|P_i-Q_i\\|_F^2 \\leq \\epsilon'$? (Here the norm is the Frobenius norm, the sum of squares of the coefficients.) So far using various iterative procedures I can only get a bound where $\\epsilon' = poly(\\log k) \\epsilon$, but I would like to know if the dependence on $k$ can be removed.\n\nshare|improve this question\nSo in a way Graham-Schmidt may be seen as the greedy approach to this question: Pick the \"new\" n-th vector as the vector on the orthogonal complement of the span of the already picked n-1 vectors closest to the given n-th vector. \u2013\u00a0 HenrikR\u00fcping Oct 19 '10 at 19:22\nYes. Unfortunately it is not \"stable\", in the sense that as the first t vectors get orthogonalized, the overlap of the remaining vectors on the span of the t orthogonal vectors will grow with t, so that it \"costs\" more and more (in terms of distance moved) to make each subsequent vector orthogonal to the previous ones. In my calculations this typically leads to a linear or quadratic dependence of $\\epsilon'$ on k. \u2013\u00a0 Thomas Oct 19 '10 at 19:29\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nUse a Procrustes rotation of the standard basis vectors onto your vectors. This gives the set of orthogonal vectors with the smallest sum of squares of distances to your vectors.\n\n\"The orthogonal Procrustes problem is a matrix approximation problem in linear algebra. In its classical form, one is given two matrices A and B and asked to find an orthogonal matrix R which most closely maps A to B.\"\n\nIn your case you want to find the orthogonal matrix R which most closely maps the standard basis to your matrix. Something like the columns of R should then be the set of orthogonal vectors which are nearest to your vectors, where 'nearest' is in the sense of sum of squares.\n\nshare|improve this answer\nSorry, I should have mentioned all vectors are unit. I am not familiar with Procrustes rotations; is there a good reference to start learning about them (in relation to my original problem)? \u2013\u00a0 Thomas Oct 19 '10 at 19:45\nThat turned out to work pretty well also for the case of the projectors I was mentioning, thanks! \u2013\u00a0 Thomas Oct 21 '10 at 4:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/106828/define-lim-x-rightarrow-0-frac1x-int-0x-et2-dt-what-is-the/135274\nText:\nTake the 2-minute tour \u00d7\n\nThis question is in the section about definite integrals and the task is to calculate the limit. My first idea was division-by-zero but I am very unsure about this. What is the goal here? I then thought that should I investigate things by different limits?\n\nI have simplified this question but similar questions on the page 548 6* here.\n\nshare|improve this question\nThe goal is to see if you have understood the material covered till the fundamental theorem of calculus. \u2013\u00a0 Aryabhata Feb 7 '12 at 22:15\nWhich book did you get this from? \u2013\u00a0 Aryabhata Feb 7 '12 at 22:22\nSure you've seen this theorem if you've gotten that far? The limit is the derivative of $\\int_0^x \\exp t^2 dt$ at $x=0$. \u2013\u00a0 anon Feb 7 '12 at 22:29\n\n3 Answers 3\n\nup vote 8 down vote accepted\n\nYou may re-write what you have as\n\n$$ \\lim_{x\\to 0}\\frac{1}{x-0}\\int_0^x e^{t^2}\\,dt. $$\n\nIf you haven't seen it before,\n\n$$ \\frac{1}{x-0}\\int_0^x e^{t^2}\\,dt $$\n\nis the average value of the function $e^{t^2}$ over the interval $[0,x]$. Now, imagine that $F'(t)=e^{t^2}$. Then by the Fundamental Theorem of Calculus we have\n\n$$ \\int_0^x e^{t^2}\\,dt=F(x)-F(0). $$\n\nThus, your limit becomes\n\n$$ \\lim_{x\\to 0}\\frac{F(x)-F(0)}{x-0}. $$\n\nThis is just the definition of the derivative of $F$ evaluated at $x=0$. But, we know what the derivative of $F(x)$ is, namely $e^{x^2}$.\n\nshare|improve this answer\nWhat about if the other limit is of different form such as $x^{7}$, $ln(x)$ --? Then, it is not exactly the theorem (or the average -analogy). I think I need to do some adjusting or investigation of the limit then somehow? \u2013\u00a0 hhh Feb 7 '12 at 22:53\nFor example, this is not for the def. of derivative so do I need to somehow adjust it? $$\\lim_{x\\rightarrow 3} \\frac{x^{2}-F(9)}{x-3}$$ \u2013\u00a0 hhh Feb 7 '12 at 22:59\n@hhh: Do you mean that to be $F(x^2)$? In that instance, you've got some chain rule stuff going on. \u2013\u00a0 Joe Johnson 126 Feb 8 '12 at 14:17\n\nHINT: Let $$f(x)=\\int_0^x e^{t^2}dt\\;.$$\n\n  1. What is $\\lim\\limits_{x\\to 0}f(x)$?\n  2. What is $f\\,'(x)$?\n  3. L\u2019Hospital\u2019s rule.\nshare|improve this answer\nPerhaps the downvoter would care to explain? The suggested argument is in fact both correct and easy, and the answer has the virtue of not completely doing the homework problem for the OP. \u2013\u00a0 Brian M. Scott Feb 7 '12 at 22:59\nI don't see the point of #3 but I don't get the downvote either. This is basically what I would have said. \u2013\u00a0 anon Feb 7 '12 at 23:03\n@anon: The point of (3) is that you don\u2019t have to recognize this as the limit of a difference quotient: you can also see it simply as a $0/0$ indeterminate form. \u2013\u00a0 Brian M. Scott Feb 7 '12 at 23:07\nIn my opinion, that would defeat the point of the exercise. \u2013\u00a0 anon Feb 7 '12 at 23:10\n@anon: I take a different view of the point of the exercise: I think that the point is the fundamental theorem, as in my point (2). \u2013\u00a0 Brian M. Scott Feb 7 '12 at 23:13\n\ni think that our integral should be understood as the mean value of the exponential on the interval $ (0,x)$ since $ x \\rightarrow 0 $ the mean value on the interval $ (0,0) $ is just $ exp(0)=1$ to $1$ is the answer\n\nshare|improve this answer\nDid you ask the author of the question about his intended method of solution/interpretation? \u2013\u00a0 The Chaz 2.0 Apr 22 '12 at 13:33\n+1 good observation, indeed that is the straightforward interpretation. \u2013\u00a0 hhh Apr 22 '12 at 14:06\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/121561/pigeonhole-principle-question?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThere is a row of 35 chairs. Find the minimum number of chairs that must be occupied such that there are some consecutive set of 4 chairs or more occupied.\n\nI would like to have some hints as to approach this problem. This isn't for homework or anything, I'm just curious as to what would be the best strategy for this problem.\n\nshare|improve this question\nI'd say worst case is groups of $3$ occupied with $1$ open seat between them. So that's $9 \\times 3$ occupied seats and $8 \\times 1$ open seats, i.e. $27$ occupied seats. So I think you need $28$ occupied seats. \u2013\u00a0 TMM Mar 18 '12 at 1:55\nSounds like the answer. Please add it! \u2013\u00a0 user21436 Mar 18 '12 at 2:09\nUhm the best strategy is to try and use the pigeonhole principle? i.e. the title you gave the post. So are you asking how to use pigeonhole? \u2013\u00a0 john w. Mar 18 '12 at 2:50\nSomehow everybody understands that the second sentence contains a negation (the word \"not\"), but unless my eyesight is really betraying me, there is no such negation. For me the answer is obviously $4$. \u2013\u00a0 Marc van Leeuwen Mar 27 '13 at 14:17\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nFor every $4$ seats you need to keep at least $1$ open to not have $4$ consecutive chairs occupied. So divide the row in sets $S_k = \\{4k + 1, 4k + 2, 4k + 3, 4k + 4\\}$ for $k = 0, \\ldots, 7$ and $S_8 = \\{33, 34, 35\\}$. For each set $S_0, \\ldots, S_7$ you need to keep one seat open, so you need at least $8$ open seats to not have a sequence of $4$ occupied seats. This maximum can also be achieved, by leaving seats open at positions $4k$, for $k = 1, \\ldots, 8$.\n\nWith respect to applying the pigeonhole principle: If you do have more than $35 - 8 = 27$ seats filled, then you have at least $25$ seats filled for $S_0, \\ldots, S_7$. Since $25 / 8 > 3$, by the pigeonhole principle one of them must have at least $4$ seats occupied. But then you get a sequence of $4$ occupied seats. So if $28$ or more seats are occupied, you always have $4$ or more consecutive occupied seats.\n\nshare|improve this answer\nThere are 8 pigeonholes.We need to find the minimum pigeons so that at least one pigeon hole contains 4 pigeons.In generalized pigeon hole principle if there are n pigeons and k holes at least one pigeonhole should have $\\lceil n/k \\rceil$ pigeons.Therefore if we have $\\lceil 25/4 \\rceil$=4.So why isn't the answer=25 but 28? \u2013\u00a0 sam_rox Nov 18 '14 at 3:55\n:typo not $\\lceil 25/4 \\rceil$ but $\\lceil 25/8 \\rceil$ \u2013\u00a0 sam_rox Nov 18 '14 at 4:02\nHi Sam. The reason is that there are 35 = 4\u00d78+3 seats. You can apply the pigeonhole to the first 32 seats like you did, so you know that out of those 32 seats, it is possible to fill 24 seats. Add to that the other 3 seats, and you see it is possible to fill 27 seats. (But not 28.) \u2013\u00a0 TMM Nov 19 '14 at 17:26\n\nThis is not really an answer ........Fill the pigeonholes in blocks of 3 with 1 separator (shown as ~) 123~456~789~101112~131415~161718~192021~222324~252627 You can see that 27 is the max that can be occupied with 4 in a row. So if 28 or more seats are occupied, you always have 4 or more consecutive occupied seats. I just made many people's explanation into that...........What is The GENERALISING statement for this type of pigeonhole questions?\n\nshare|improve this answer\nAs you mention, this \"is not really an answer\". Perhaps you have the germ of an idea for asking a generalized version of the question, although it isn't quite polished yet. However the Answer box is only for answers. \u2013\u00a0 hardmath Mar 27 '13 at 13:38\nThis really is an answer, but needs a bit of spit and polish. Wellcome! But consider that this site looks for complete, closed (and we also wish for brilliant, no harm in wishing so near Easter ;) answers to questions. Please try for a more complete answer next time. \u2013\u00a0 vonbrand Mar 27 '13 at 13:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/77762/equivalence-of-a-vector-norm-being-absolute?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to show that a vector norm $\\|\\cdot\\|$ being absolute ($\\|x\\| = \\|\\;|x|\\;\\|)$ is equivalent to showing that $\\|x'\\| = \\|[\\alpha_1x_1\\ldots\\alpha_nx_n]^T\\| = \\|x\\|$ for all $x\\in\\mathbb{C}^n$ and $|\\alpha_i| = 1$ for all $\\alpha_i$. I've shown that if $\\|\\cdot\\|$ is absolute, then the given statement follows, but I'm having trouble showing the reverse.\n\nFrom my proof of the first part, I know that $|x'| = |x|$, so I can either show that $\\|x'\\| = \\|\\;|x'|\\;\\|$ or take the direct route of showing that $\\|x'\\| = \\|\\;|x|\\;\\|$. Either way, I don't see how to proceed. Intuition tells me that the crucial step will revolve around using the fact that $|\\alpha_i| = 1$, so that's where I've started, but no luck so for. I'll update if I find anything more out, but a nudge in the right direction would be much appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet $x\\in\\mathbb{C}$ be arbitrary and specialize (pick out) each $\\alpha_i$ individually such that $\\alpha_ix_i=|x_i|$ and the modulus is unity ($|\\alpha_i|=1$) for each $i$ - the given hypothesis then implies $\\|x'\\|=\\|[\\alpha_ix_i]^T\\|=\\||x|\\|.$\n\nshare|improve this answer\nDoesn't this violate the hypothesis that this must hold for all $\\alpha_i$? I read \"...for all $x$ and all $y$...\" to mean any combination of arbitrary $x$ and $y$ \u2013\u00a0 brc Nov 1 '11 at 6:39\n@brc: You get $\\|x'\\|=\\|x\\|$ by hypothesis. Also, since it holds for any $|\\alpha_i|=1$, you're free to make them whatever you want in order to continue investigating - it changes nothing. By choosing them so $\\alpha_ix_i=|x_i|$ (see how this is possible) you can check directly that $\\|x'\\|=\\||x|\\|$. Hence $\\|x\\|=\\||x|\\|$. \u2013\u00a0 anon Nov 1 '11 at 6:43\nThat makes sense. The explanation is/was clear, I was just worried about the assumptions made to derive it. Thanks. \u2013\u00a0 brc Nov 1 '11 at 6:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/129195/problem-in-valuation-theory\nText:\nTake the 2-minute tour \u00d7\n\nFind $\\alpha\\in \\mathbb{Q}$, such that $v_2(\\alpha-1/3)\\ge 2$, $v_3(\\alpha-1/2)\\ge 3$ and $|\\alpha-1|_\\infty<1/2$, where $v_p$ is the $p$-adic exponential valuation and $|\\cdot|_\\infty$ is the usual absolute value.\n\nThanks in advance!\n\nshare|improve this question\nIs this homework? What have you tried? \u2013\u00a0 Alon Amit Apr 8 '12 at 6:45\n@Alon Amit, thanks for the comment. I have tried to do some 3-adic and 2-adic expansion for 1/2 and 1/3, respctively, then I may find \u03b1 by the Chinese Remainder Theorem. But I am confused with the expansions, since what I have got is quite different from what I need. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 7:38\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe first two conditions are equivalent to $v_2(3\\alpha-1)\\ge2$ and $v_3(2\\alpha-1)\\ge3$. That is,\n\n$$3\\alpha-1\\equiv 0 \\mod 2^2\\Bbb Z \\qquad and \\qquad 2\\alpha-1 \\equiv 0 \\mod 3^3\\Bbb Z.$$\n\nRewriting each side (note $2^{-1}\\equiv 14\\mod 27$), we obtain\n\n$$\\begin{cases} \\alpha\\equiv -1 \\mod 4 \\\\ \\alpha \\equiv 14 \\mod 27. \\end{cases}$$\n\nBy CRT we have $\\alpha=95 \\mod 108$. We need $|p/q-1|_\\infty <1/2$ while $pq^{-1} \\equiv 95 ~(108)$. The two nontrivial factors of $95$ are $5$ and $19$; we have $5^{-1}\\equiv 65$ and $19^{-1}\\equiv 91 \\mod 108$. The latter is close to $5+108=113$ in the $|\\cdot|_\\infty$ metric, so we check that $|113/91-1|_\\infty<1/2$ indeed holds.\n\nThis gives $\\alpha=113/91$ as one solution.\n\nshare|improve this answer\n@Qiang: If you want to do it by hand it'd be the extendend Euclidean algorithm. Otherwise cheat and consult google for an online applet. :) \u2013\u00a0 anon Apr 8 '12 at 16:22\nAnon, a thousand thanks for your answer! I want to know if there some tricks in solving the equation such as $19x\\equiv1 \\mod 108$? P.S. I thought about the weak approximation theorem later on today, feeling the problem would be solved by the constructive proof. But I didn't really do it after I read your answer. It's a really great answer! \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:25\nAnon, I got it. Thanks. It seems that your solution is actually $\\alpha=113/91$. I'm sorry I cannot @you on this computer. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:37\n@Qiang: Oops, typo. Fixed, thanks. Don't worry, comments on a person's answer always ping that person, so @anon would be redundant here. \u2013\u00a0 anon Apr 8 '12 at 16:50\n\nHint: If $\\alpha = \\frac{a}{b}$ then\n\n$\\alpha-\\frac{1}{2} = \\frac{2a-b}{2b}$\n\n$\\alpha-\\frac{1}{3} = \\frac{3a-b}{3b}$\n\nYou need to make the first fraction divisible by a high power of 3, and the second divisible by a high power of 2. It's easiest to make $b$ relatively prime to 6 so you don't have to worry about the denominators. Pick such a $b$. Can you find an $a$ such that $2a-b$ is divisible by 27? Can you find an $a$ that makes $3a-b$ divisible by 4? Can you find an $a$ that does both? Finally, can you make $a$ close enough to $b$ so that $\\frac{a}{b}$ is not too far from 1?\n\nshare|improve this answer\nAlon, thanks for your hint! I will try that. Later on today, I found that the weak approximation theorem will be useful here. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/198129/perfect-squares\nText:\nTake the 2-minute tour \u00d7\n\nWonder whether anybody here can provide me with a hint for this one.\n\nIs $c=1$ the only case in which the expression $(c^2+c-1)(c^2-3(c-1))$\n\nreturns a perfect square?\n\nshare|improve this question\n@Ben, so, what's the cutoff? and, why? \u2013\u00a0 Gerry Myerson Sep 18 '12 at 6:43\n@Ben, my experience with people at zero percent is that they are unaware of the accept mechanism and are grateful when it is pointed out to them. If they are aware of the mechanism and truly don't like any of the answers they've had on any of the questions they have asked, why would they keep asking questions here? \u2013\u00a0 Gerry Myerson Sep 18 '12 at 12:51\n@GerryMyerson: well, fair enough, but do you really think that Don Antonio's original comment was helpful in that regard? \u2013\u00a0 Ben Millwood Sep 18 '12 at 13:27\n@Ben, I'm not convinced that anything in this discussion has been helpful, especially as it really belongs elsewhere. Maybe you want to begin a thread on meta, or contribute to one of the already-existing meta threads on accepting answers. \u2013\u00a0 Gerry Myerson Sep 18 '12 at 23:10\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nYes, $c=0$ is the only such value. For the proof, it is useful to let $c=x+1$. Then our expression becomes $$(x^2+3x+1)(x^2-x+1).$$ Note that $x^2-x+1$ is always odd. Any common divisor of $x^2+3x+1$ and $x^2-x+1$ must divide the difference $4x$. But such a common divisor must be odd, so any common divisor must divide $x$. But then it must divide $1$.\n\nThus $x^2+3x+1$ and $x^2-x+1$ are relatively prime. Since $x^2-x+1$ is always positive, it follows that if their product is a perfect square, each must be a perfect square.\n\nBut that can only happen when $x=0$. To prove this, use the fact that for any integer $u$, there is no perfect square strictly between $u^2$ and $(u+1)^2$. Since you asked for a hint, I will, unless you request otherwise, leave out the rest of the argument. It is short.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/173636/putnam-problem-partitioning-integers-with-generating-functions/173675\nText:\nTake the 2-minute tour \u00d7\n\nWe were given the following A-1 problem from the 2003 Putnam Competition:\n\nLet $n$ be a fixed positive integer. How many ways are there to write $n$ as a sum of positive integers, $$ n= a_1+a_2+ \\cdots + a_k$$ With $k$ an arbitrary positive integer, and $a_1 \\le a_2 \\le \\cdots \\le a_k \\le a_1+1$. For example, with $n=4$ there are 4 ways: 2, 2+2, 1+1+2, 1+1+1+1.\n\nI managed to do this by induction, showing that there are always $n$ ways to partition an integer in such a way. In my combinatorics class however, we always solved integer partitioning problems with generating functions and I have been unable to construct one for this problem. I was wondering if the math.stackexchange community could help me out with this and at least give me a nudge in the right direction.\n\n\nshare|improve this question\nfixed, thank you \u2013\u00a0 Jeremy Jul 21 '12 at 15:58\nI assume that first way should be a 4. \u2013\u00a0 Mike Jul 21 '12 at 19:29\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nRecall exponential notation for partitions: $a^b$ signifies $b$ occurrences of $a$ in the partition. (Exponential notation can be useful for seeing the generating functions.) In exponential notation, every partition satisfying your constraints are of the form $m^k (m+1)^l$. In your $n = 4$ example, the partitions are $4^1 5^0$, $2^2 3^0$, $1^2 2^1$, and $1^4 2^0$. Notice that the smaller number, $a_1$, must have exponent at least $1$, while successor can have exponent $0$.\n\nFor a fixed $m$, the contributions from partitions of the form $m^k (m+1)^l$ are given by the following generating function:\n\n$$(x^m + x^{2m} + x^{3m} + \\cdots)(1 + x^{m+1} + x^{2(m+1)} + \\cdots)$$\n\nThis simplifies to:\n\n$$\\frac{x^m}{1-x^m} \\frac{1}{1-x^{m+1}}$$\n\nSuch contributions come from any $m \\geq 1$, and of course, the contributions are disjoint. Thus the full generating function is:\n\n$$\\sum_{m \\geq 1} \\frac{x^m}{1-x^m} \\frac{1}{1-x^{m+1}}$$\n\nThis might already be too great a nudge, but the point is that you now obtain something you can manipulate. After some obvious $1 - x$ factorings and some telescoping, I get $\\frac{x}{(1 - x)^2}$, a generating function for $n$, as desired. Let me know if you get similar results or not.\n\nshare|improve this answer\n\nThis does not really answer the question in the sense that it uses no generating functions. But think of the problem of partitioning any positive number $n$ into a given number $k$ of parts, with $1\\leq k\\leq n$, as equitably as possible, in the sense that no two parts differ by more than $1$ (for if they did, one could make it more equitable by moving a unit from the larger to the smaller part). One solution is to first make $k$ equal parts of size $\\lfloor n/k\\rfloor$, and then if $k$ does not evenly divide $n$ distribute the remaining $n\\bmod k$ units by assigning them randomly to distinct parts, making those $\\lceil n/k\\rceil$ (since the order of parts are not taken into account, it makes no difference which). Can you see why there are no other such equitable partitions of $n$ into $k$ parts? Once this is established, these are clearly the $n$ possible solutions of your problem, one for every $k$.\n\nPersonally, with such a complete description of the solution available, I'm mentally blocked to think how generating functions could be used to find an alternative solution. In fact, I think that the requirement that relates the sizes of different parts (limiting their difference to at most $1$) does not easily translate into the world of generating functions (as one can do for independent conditions on the size of parts, or on multiplicities of a given size).\n\nshare|improve this answer\nThis is a very pleasing solution, one that I prefer to a generating function based solution. As noted in the answer I gave, these partitions are uniquely realizable in exponential form as $m^k (m+1)^l$, where $k \\geq 1$ and $l \\geq 0$. So, there is a generating function approach, and as far as I can tell, the answer can be obtained solely using generating functions. \u2013\u00a0 Hugh Denoncourt Jul 22 '12 at 17:16\nYes I prefer this as well and is essentially the reasoning I used in my original solution, but I was looking for a different way, really to brush up on generating functions. \u2013\u00a0 Jeremy Jul 22 '12 at 20:14\n\nConsider the integer $n$. How are it's partitions related to the partitions of those of integers $k$ where $1 \\le k < n$? Can you find a recursive function that relates these?\n\n(FYI, Project Euler, Problem 76 is a variation of this question.)\n\nshare|improve this answer\nBut the Euler problem doesn't have the restriction that $a_k \\le a_1+1$ \u2013\u00a0 Ross Millikan Jul 22 '12 at 15:40\n@RossMillikan Thus I qualified my statment with the word \"variation.\" \u2013\u00a0 Code-Guru Jul 22 '12 at 17:37\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/51909/what-is-the-largest-family-f-of-subsets-of-n-for-which-any-two-distinct-sets-a?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nThis problem arose in the study of Latin squares with a large number of subsquares, although it appears interesting in its own right.\n\nQuestion: What is the maximum cardinality of a family $F \\subseteq 2^{[n]}$ of subsets of $[n]:=\\{1,2,\\ldots,n\\}$ for which any two distinct $A,B \\in F$ satisfy $|A \\cap B| \\leq \\tfrac{1}{2} \\min(|A|,|B|)$?\n\nSome observations:\n\n  \u2022 We have the trivial lower bound $\\max |F| \\geq {n \\choose 2}$ by taking all the subsets of size 2.\n  \u2022 When $n \\geq 3$, $F$ should not have any sets of size 1. If $\\{a\\} \\in F$, then we can replace it by $\\{a,x\\}$ for all $x \\in [n] \\setminus \\{a\\}$ for any $x$ that belongs to a set of size 2 or more (since no other set in $F$ can contain an $a$). If every set has size 1, then $|F|=n$ which can be beaten.\n  \u2022 $F$ should not have any sets of size 3. If $\\{a,b,c\\} \\in F$, then we can replace it by $\\{a,b\\},\\{a,c\\},\\{b,c\\}$ (since any other set in $F$ may intersect $\\{a,b,c\\}$ in at most one element).\n  \u2022 With the above simplifications in mind, I wrote a backtracking algorithm which says that for $3 \\leq n \\leq 7$ (and it's progressing through $n=8$), that $F$ is uniquely maximized when $F$ consists of all 2-subsets.\nshare|improve this question\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nFor an affine space over $\\mathbb{z}_2$ with $n=2^k$ we have $\\binom{n}{2}=(2^{k}-1)(2^{k-1})$ however there are $\\binom{n}{3}/4=\\frac{2^{k}(2^{k}-1)(2^{k}-2)}{24}$ 2 dimensional flats of which any pair intersect in at most two points.\n\nDetails: Consider the $n=2^k$ binary vectors of length $k$. Among the sets of 4 vectors chose only those of the form $\\lbrace x,y,z,x+y+z\\rbrace$ in other words those quadruples whose members sum to the all zero vector.\n\nI don't know how close you can get for other values of $n$ to having a family of 4-sets so that any three points is in a unique 4-set.\n\nI would expect even better numbers for bigger subsets with a big enough $n$.\n\nThe best one could do with 4-sets when $n=24$ could at the very most $\\binom{24}{3}/4=506$. The Steiner system S(5,8,24) is a family of 759 8 element subsets (blocks) of a 24 set so that each 5-set is in a unique block.\n\nshare|improve this answer\nThanks for that, that's exactly what I'm after. (...and now I'm slapping myself for not realising this already) \u2013\u00a0 Douglas S. Stones Jan 13 '11 at 5:33\nDoing the same thing with $l$-dimensional flats gives you a family of size $O(n^{l+1})$. \u2013\u00a0 Chris Eagle Jan 13 '11 at 5:38\n\nThis can be rephrased in the language of coding theory. If you have a binary code with minimal distance $d$ then the words of weight $2d$ form the kind of family you've defined. Tables of good binary codes are widely available on the web.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/58666/is-there-any-matrix-2-times-2-such-that-a-neq-i-but-a3-i?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI want to ask you this question: Is there any matrix $2\\times 2$ such that $A\\neq I$ but $A^3=I$. In my opinion: No. Thank you very much\n\nshare|improve this question\nI don't think it is a matter of opinions... \u2013\u00a0 \u00c1lvaro Lozano-Robledo Aug 20 '11 at 15:42\n\n2 Answers 2\n\nup vote 25 down vote accepted\n\nRotation by $2\\pi/3$ in the plane. Find the $2 \\times 2$ matrix that gives you this linear transformation.\n\nshare|improve this answer\nHi! How did you get that? \u2013\u00a0 Jozef Aug 20 '11 at 15:08\nImagine something when applied 3 times is the identity. How do you think? \u2013\u00a0 GEdgar Aug 20 '11 at 15:12\nOk, I'll think. thanks \u2013\u00a0 Jozef Aug 20 '11 at 15:20\n\nSince you don't specify what field the entries of this matrix have to come from, I could just take a diagonal matrix whose entries are $1$ and $\\omega$ where $\\omega=e^{2\\pi i /3}$ is a primitive cube root of 1 in the complex numbers.\n\nI guess you want real or integer entries though. If $A^3=I$ then the eigenvalues of $A$, that is, the roots of the characteristic polynomial, have to be third roots of unity. A primitive third root of unity satisfies $x^2+x+1=0$, so you could look for a matrix over the integers with that as a characteristic polynomial....\n\nshare|improve this answer\n+1. Nice! Your argument shows that this holds for any (nonzero) commutative ring. \u2013\u00a0 Pierre-Yves Gaillard Aug 20 '11 at 16:17\nAnother way to get an integral matrix that does the job it to take the automorphism of order $3$ of the torus, then the induced map on homology. In fact, there's an automorphism of order $6$ coming from the symmetry of the hexagonal tiling. \u2013\u00a0 Ryan Budney Aug 20 '11 at 16:35\n@Ryan: over $\\mathbb Z$, you have reduced to the problem to the (equivalent, I'm pretty sure---given enough technology) one of finding an automorphism of order $3$ of the torus :) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Aug 20 '11 at 22:07\nYes, $2\\times 2$ matrices of the integers of finite order all come from symmetries of the torus. This is a special case of what's called the Nielsen Realization problem -- which is solved, by-the-way. en.wikipedia.org/wiki/Nielsen_realization_problem Among other things, this gives you a fairly intuitive way to enumerate all the finite-order elements of $GL_2 \\mathbb Z$ (up to conjugacy). \u2013\u00a0 Ryan Budney Aug 20 '11 at 22:20\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/70777/a-ring-element-with-a-left-inverse-but-no-right-inverse\nText:\nTake the 2-minute tour \u00d7\n\nCan I have a hint on how to construct a ring $A$ such that there are $a, b \\in A$ for which $ab = 1$ but $ba \\neq 1$, please? It seems that square matrices over a field are out of question because of the determinants, and that implies that no faithful finite-dimensional representation must exist, and my imagination seems to have given up on me :)\n\nshare|improve this question\nThe two hints you have been given have a common thread: you need to lose information in one direction and cannot recover it in the other. \u2013\u00a0 Ross Millikan Oct 8 '11 at 4:03\n\n2 Answers 2\n\nup vote 15 down vote accepted\n\nTake the ring of linear operators on the space of polynomials. Then consider (formal) integration and differentiation. Integration is injective but not surjective. Differentiation is surjective but not injective.\n\nshare|improve this answer\nI am slightly confusing. Let $D$ denotes differentiation, and $I$ integration. I want to clarify whether $(D\\circ I)(p(x))$ is not necessarily $p(x)$ or $I\\circ D(p(x))$ is not necessarily $p(x)$. Should we take $I(0)=0$? \u2013\u00a0 Groups Dec 25 '14 at 9:53\n@Groups $I(f) = \\int_0^x f(t)dt$ works. \u2013\u00a0 Bib Apr 26 at 15:47\n\nConsider the ring of infinite matrices which have finitely many non-zero elements both in each row and in each column and the matrix $$a=\\begin{pmatrix}0&0&0&\\cdots\\\\1&0&0&\\cdots\\\\0&1&0&\\cdots\\\\\\ddots&\\ddots&\\ddots&\\ddots\\end{pmatrix}.$$\n\nA canonical example is the quotient $A$ of the free algebra $k\\langle x,y\\rangle$ by the two-sided ideal generated by $yx-1$.\n\nshare|improve this answer\nIn my example, this is the matrix of integration with respect to a suitable basis. \u2013\u00a0 lhf Oct 8 '11 at 3:37\nA very good and nontrival example! \u2013\u00a0 Mathemagician1234 Oct 8 '11 at 4:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/109782/are-sines-of-primes-dense-in-1-1?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $P$ be the set of all prime numbers. Is $\\sin(P)$ dense is $[-1,1]?$ How could we approach such a problem?\n\nshare|improve this question\n+1 Cool question. What have you tried? \u2013\u00a0 draks ... Feb 15 '12 at 22:40\nOn distributional principles it sure seems true. Very cool question. \u2013\u00a0 Brian B Feb 15 '12 at 22:53\n@draks Well, I know the proof that $\\sin(\\mathbb N)$ is dense. Actually, I just remembered it from my first course in analysis and thought about this problem. The proof of the case with $\\mathbb N$ doesn't seem to generalize, and it would be strange if it did I think. But I have simply no idea how to find another approach. \u2013\u00a0 user23211 Feb 15 '12 at 22:57\nI don't know the $\\sin(\\mathbb{N})$ proof (can you provide a link?), but would it help to think of $\\mathbb{N}$ as sum of all primes, semi-primes, k-almost primes? \u2013\u00a0 draks ... Feb 15 '12 at 23:09\n@draks There's a question about it on this site. There's a link to a paper with a proof there but I can't access it from my house so I'm not sure what's in it. \u2013\u00a0 user23211 Feb 15 '12 at 23:12\n\n1 Answer 1\n\nup vote 14 down vote accepted\n\nAccording to the Wikipedia article about the discrepancy of a sequence:\n\nThe sequence of all multiples of an irrational $\\alpha$ by successive prime numbers, $2 \\alpha$, $3 \\alpha$, $5 \\alpha$, $7 \\alpha$, $11 \\alpha$, ... is equidistributed modulo 1. This is a famous theorem of analytic number theory, proved by I. M. Vinogradov in 1935.\n\nWith $\\alpha = \\frac{1}{2 \\pi}$, this implies that $P$ is equidistributed modulo $2 \\pi$. Using this, and the continuity of the sine function, I think it is straightforward to show that $\\sin(P)$ is dense in $[-1,1]$ (although not equidistributed).\n\nshare|improve this answer\nAlso, the distribution of $sin(P)$ can be derived from the fact of the equidistribution of $P$ modulo $2\\pi$. \u2013\u00a0 Michael Lugo Feb 16 '12 at 5:37\nDan, could you post a link or a reference to Vinogradov's proof? \u2013\u00a0 user23211 Feb 16 '12 at 8:11\n@ymar, I couldn't find one with a search, but here it is claimed to be \"a byproduct of [Vinogradov's work on] the odd Goldbach conjecture\". It is said to have been proven in 1935 so probably the document can be narrowed down on that basis. \u2013\u00a0 Dan Brumleve Feb 16 '12 at 8:34\nHow about $P^{it}$? Is this dense over the unit circle? \u2013\u00a0 draks ... Jul 16 '12 at 14:40\n@draks The phase of $P^{it}$ varies extremely slowly for any fixed $t$, so there's no question that it is dense on the unit circle. One only needs $\\frac{p_{n+1}}{p_n} \\to 1$, which is slightly stronger than Bertrand's postulate and weaker than the Prime Number Theorem. \u2013\u00a0 Erick Wong Jan 6 '13 at 7:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/257873/why-isnt-the-inverse-of-the-function-x-mapsto-x-sinx-expressible-in-terms/275100\nText:\nTake the 2-minute tour \u00d7\n\nThe function\n\n\nis easily checked to be a bijection from the reals to itself, and so it has a unique inverse $y\\mapsto g(y)$ such that $f\\circ g=g\\circ f$ are both the identity map.\n\nNow $g$ will almost certainly be a function which is not expressible using \"the functions in a high-schooler's toolkit\" (by which I guess I mean $\\exp$, $\\log$, and, if you like, the usual trigonometric functions and their friends like $\\sinh$, although of course these can all be of course built from exponentials anyway). For purely recreational reasons (stemming from conversations I've had whilst teaching undergraduates) I'm interested in how one proves this sort of thing.\n\nA few years ago I was interested in a related question, and took the trouble to learn some differential Galois theory. My motivation at the time was learning how to prove things like why $h(t):=\\int_0^t e^{x^2} dx$ is not expressible in terms of these calculator-button functions (I'm sure there's a better name for them but I'm afraid I don't know it). I've realised that since then I've forgotten most of what I knew, but furthermore I am also unclear about whether this is the way one is supposed to proceed. Is the idea that I come up with some linear differential equation satisfied by $g$ and then apply some differential Galois theory technique? In fact, one of the many things that I have forgotten is the following: if $F$ is a field equipped with a differential operator $D$, and $E/F$ is the field extension obtained by adding a non-zero root of $Dh=ch$, with $c\\in F$, then the Galois group of $E/F$ is solvable, whereas the equation itself might not be, in terms of calculator-button functions, if I can't integrate $c$.\n\nCan a more enlightened soul explain to me how one is supposed to proceed? I wonder whether I am somehow conflating two ideas and the differential Galois theory business is a red herring, but it seemed simpler to ask rather than continuing to flounder around.\n\nshare|improve this question\nThe term I am familiar with is \"integration in finite terms\". \u2013\u00a0 marty cohen Dec 16 '12 at 5:10\nI think the term you are looking for (calculator button) is elementary function. \u2013\u00a0 Marc van Leeuwen Dec 16 '12 at 10:37\nYes, I'm looking for a proof that the inverse function is not an elementary function. Thanks. \u2013\u00a0 Kevin Buzzard Jan 4 '13 at 16:23\n\n3 Answers 3\n\nThis paper, titled \"Elementary functions and their inverses\" by J.F. Ritt addresses your question.\n\nSome time ago, in searching for why some functions don't have elementary integrals, I was led to the work of Liouville, as digested by Ritt in his book \"Integration in finite terms; Liouville's theory of elementary methods\". It was written in 1948 so I think the copyright has expired, and you can find a download link via a Google search.\n\nLiouville's results on elementary integrals were derived using quite basic tools (it is hard to be precise here on what I mean by \"basic tools\", best you see for yourself). The latter portions of Ritt's book explore elementary solutions of differential equations, which is based on the work of mathematicians after Liouville, and it is only from then that some differential Galois theory is used.\n\nRitt's paper uses methods somewhat similar to Liouville and in particular, does not seem to use differential Galois theory. However, it is possible there may be a more modern approach to your question that does use differential Galois theory, since the generalization of Liouville's original work develops it.\n\nAlternatively, if you can express your inverse function in terms of the Lambert W function as Nicholas suggests, then you can answer your question via the more specific methods of this paper.\n\nshare|improve this answer\nThanks for your answer and sorry it's taken so long to follow this up. I think that you're right that Ritt's paper addresses my question, but I don't think it answers it. It reduces my question to proving that $x+sin(x)$ is not expressible in some quite explicit way using $\\exp$ and $\\log$, but leaves me none the wiser about how to actually check this. \u2013\u00a0 Kevin Buzzard Jan 4 '13 at 16:22\nHere is one last comment. A theorem of Liouville gives a necessary and sufficient criterion for a function to be integrable in elementary terms. However the criterion is, in my mind, tough to verify in practice. But a paper by Brian Conrad called \"impossibility theorems for elementary integration\" states Liouville's result (Theorem 4.1) but then also deduces Theorem 4.4, which is a practical test for impossibility. Conrad uses Theorem 4.4 to prove that $Li(x)$ and $erf(x)$ aren't expressible in elementary terms. I guess I need a practical consequence of Ritt's work but don't know one. \u2013\u00a0 Kevin Buzzard Jan 4 '13 at 16:26\n\nTo answer this, let's express $\\sin(x)$ as $\\frac i 2(e^{-ix}-e^{ix})$ so we now have $x+\\frac i2(e^{-ix}-e^{ix})$. And you said that you are trying to find the inverse. From what I can see, this is relatable to $x+e^x = y$, the inverse of which is $x-W(e^x)$ where $W(x)$ is the product log function or Lambert $W$ function which cannot be expressed in terms of quote \"the functions one finds on a calulator\". Unfortunately, I am only in high school and therefore my answer may not be correct and I apologize if it is. This is only what I have gathered from my knowledge.\n\nshare|improve this answer\nI think the weak point in your answer is \"this is relatable to $x+e^x=y$\". If one could express my function in terms of Lambert $W$ this would be a step forward, but there's a world of difference between \"this looks similar\" and \"I can actually relate your function to Lambert $W$\". However, thanks for your contribution and, to be honest, you're raising another question in my mind -- how might one prove whether or not there's a way of expressing the function I'm interested in in terms of Lambert $W$? I guess you're also pointing out that perhaps the methods used to prove... \u2013\u00a0 Kevin Buzzard Dec 17 '12 at 12:27\n...that Lambert $W$ isn't expressible in terms of elementary functions can perhaps also be used to deal with the inverse of $x+\\sin(x)$... \u2013\u00a0 Kevin Buzzard Dec 17 '12 at 12:28\nup vote 4 down vote accepted\n\nI have finally found an answer to my own question, so I'll answer it myself and make the answer community wiki so I don't profit from it.\n\nLet me first explain why the other answers given here did not completely resolve the problem. Let me use standard notation -- an elementary function is a funtion you can build using the buttons on your calculator. If you allow complex coefficients then basically you only need exp and log, as you can build everything else from this.\n\nRagib Zaman's answer points us to a paper of Ritt where he proves a theorem of the form \"an elementary function whose inverse is also an elementary function must be of a very special form\", but this very special form is quite hard to work with: it is basically of the form exp(rational function(log(rational function(log(rational function(exp(...))))))) where at each stage you can choose whether to use exp or log. The problem with this is that it's very hard (for me) to prove that the function $x+\\sin(x)$ can provably not be expressed in this form.\n\nRitt's work relies on ideas of Liouville, and Liouville had a lot of ideas about this sort of question. Liouville proved a criterion for when an elementary function had an elementary integral (in fact he proved several results of this form, best phrased nowadays in the language of differential fields). One can hence use calculus as a tool: one can use strategies such as \"the inverse function of this function satisfies a certain differential equation, which implies it can't be elementary\". But here you have to be skillful to actually get your equation into the right form. This is why I can't use Nicholas' answer to answer my question. Nicholas observes that Lambert's $W$ function isn't elementary, and I know a proof of this which uses calculus and Liouville's criterion -- the trick being to write down a differential equation which (a simple function of) $W$ satisfies and then using Liouville to prove that this differential equation has no elementary solutions -- but the moment you change the problem a little, the differential equation changes, and the methods may not (and in this case don't) apply. An analogue might be this: if I can integrate $1/\\sqrt{1-x^2}$, then even though it looks quite similar, I might well not be able to integrate $1/\\sqrt{1-x^2+x^{-2}}$. This is an area where even quite a small change might derail things substantially.\n\nOn the other hand, these answers helped me immensely, because they provided me with references which enabled me to start a literature search. And today the search came to an end, because I got my hands on a copy of \"Integration in finite terms: Liouville's theory of elementary methods\" by J. F. Ritt (written in 1948), and on p56 Ritt shows how to deal with $x+\\sin(x)$ explicitly! Apparently the equation $y=x+a\\sin(x)$ ($a$ a constant) is called \"Kepler's equation\".\n\nSo the answer to the question is \"this has nothing really to do with differential Galois theory; you need Liouville's theory, and a proof is in p56 of Ritt's 1948 book mentioned above\".\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/83732/number-of-ways-to-divide-a-stick-of-integer-length-n/83751\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have a stick of integer length $N$. I'm looking for (preferably closed-form) formula that gives the numbers of ways in which we can divide the stick into 3 parts with distinct integral lengths.\n\nEDIT: Also, every part in any division has unique length which does not appear in any other division of $N$.\n\nEDIT2: Based on coffeemath's answer, just to clarify, I'm interested in maximal number of sums $F(n)$. Given some $N$, count the number of all possible ways to divide stick $N$ into 3 parts such that the length of any part in any valid division is unique number between $1$ an $N$.\n\nshare|improve this question\nUnless your three parts must have integral length the answer is obviously $\\infty$ ;) \u2013\u00a0 N. S. Nov 19 '11 at 20:23\nYes the three parts have integral length :) \u2013\u00a0 Mohammad Al-Turkistany Nov 19 '11 at 20:26\nis $0$ a valid length? \u2013\u00a0 robjohn Nov 19 '11 at 20:34\nNo, $0$ is invalid length. \u2013\u00a0 Mohammad Al-Turkistany Nov 19 '11 at 20:38\nOrder does not matter. Here you can not count both triples. \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 10:06\n\n5 Answers 5\n\nup vote 6 down vote accepted\n\nThe array $$\\matrix{1&30&16&4&24&31&7&18&13&15&28\\cr17&2&32&20&5&14&23&8&29&22&11\\cr33&19&3&27&22&6&21&25&9&10&12\\cr}$$ uses each integer $1,2,\\dots,33$ exactly once; each column sums to $51$ (so we have $11$ ways to divide a stick of length $51$ into three parts); and, as a bonus, each row sums to $187$. There's a calculator that finds such things.\n\nIt has been proved that an $m\\times n$ magic rectangle exists provided $m$ and $n$ have the same parity and exceed $1$, with the sole exception of $m=n=2$. Taking $m=3$, this gives a way of dividing a stick of length $(9n+3)/2$ into three parts in $n$ ways, where $n$ is an arbitrary odd number exceeding $1$. It's pretty clear that stick can't be divided into three parts in more than $n$ ways; if you can do it in $k$ ways, then the numbers used must add up to $k(9n+3)/2$, but they must also add up to at least $3k(3k+1)/2$, and this is easily seen to imply $k\\le n$.\n\nIn short, if $N$ is of the form $(9n+3)/2$, $n$ odd, then the number of ways is $(2N-3)/9$.\n\nThe magic rectangles theorem has been proven, and constructions given, in many papers. One, which gives references to others, is Thomas R Hagedorn, Magic rectangles revisited, Discrete Mathematics 207 (1999) 65-72. Of course, the construction is a bit of overkill for this problem, as we don't really need a magic rectangle, we just need the columns sums to be equal and don't care about the row sums. Here's a simple construction which just solves the original construction, without giving a magic rectangle: $$\\matrix{1&2&3&4&5&6&7&8&9&10&11\\cr17&18&19&20&21&22&12&13&14&15&16\\cr33&31&29&27&25&23&32&30&28&26&24\\cr}$$ The pattern should be clear.\n\nEDIT: Now, suppose $N$ is not of the form $(9n+3)/2$ with $n$ odd. Let's write $n'=n+1$ and $n''=n+2$, and $${9n+3\\over2}\\lt N\\lt{9n''+3\\over2}$$ for some odd $n$. First, we note that $F(N)\\ge n$; if $N-(1/2)(9n+3)=k$, then just add $k$ to each entry in the bottom row in the construction above. and you have $n$ ways to divide $N$ into three parts. Second, note that $F(N)\\le(2N-3)/9$, by the argument a few paragraphs up about the sum of the numbers involved. So we get\n\n  1. If $(1/2)(9n+3)\\lt N\\lt (1/2)(9n'+3)$, then $f(N)=n$;\n\n  2. If $(1/2)(9n'+3)\\le N\\lt(1/2)(9n''+3)$, then $f(N)$ is either $n$ or $n+1$.\n\nIn summary, for every $N$, we have a formula for $f(N)$ which is exact in some ranges, and off by at most $1$ in other ranges. I suspect that the $n+1$ is generally correct in the situation where we haven't pinned things down. For example, for $N=20$, we have $$((9)(4)+3)/2\\lt N\\lt((9)(5)+3)/2$$ with the left inequality barely holding, and we get $f(20)=4$ from $$\\matrix{1&2&3&4\\cr5&7&8&6\\cr14&11&9&10\\cr}$$\n\nshare|improve this answer\nThanks for your answer. May be I'm missing something but does it work for any $N$ since I'm looking for $F(N)$ for any $N$. \u2013\u00a0 Mohammad Al-Turkistany Feb 6 '13 at 0:35\nNow that you've answered it, I feel like I understand the problem for the first time!! \u2013\u00a0 hardmath Feb 6 '13 at 2:16\n\nThis is an example of achieving $a$ distinct sums for a stick of length $6a$. No specific integer occurs twice in any particular sum, or twice in two different sums, or more succinctly all the numbers involved in the sums are distinct. I think that is what the OP means in the statement of the \"EDIT\".\n\nThe triples are $T_k=[k,3a-2k+1,3a+k-1]$ for $1 \\le k \\le a.$ Each triple then has sum $6a$ as desired, and the numbers used are all distinct. The middle numbers are going down by 2 as $k$ runs through $\\{1,2,...,a\\}$ with the last one being $3a-2a-1=a+1$, just after the highest number $a$ of the first term in any triple, and the first middle number is the largest of the middle numbers namely $3a-2\\cdot 1+1=3a-1,$ which is just before the lowest of the third elements of the triples, i.e. $3a+1-1=3a$. After that the third elements of the triples increase by 1 each step until reaching the highest third element of a triple, namely $3a+a-1=4a-1$ (So the last triple $T_a$ is $[a,a+1,4a-1]$).\n\nI don't know if better can be done for a stick of length $6a$, but I haven't been able to prove that; it may be that some other sheme of getting different triples could give more than $a$ sums for the $6a$ long stick. What I tried to do was to have the middle numbers going down two each time, and make the block of them start right after the end of the first block going up one each time, and end just before the final block which again goes up one each time. I can't think of a denser way to pack the triples.\n\nBy the way in my opinion, given the restriction of no number used twice in any one triple or even anywhere on the list of triples obtained, the OP should specify whether his question is to find the maximal number of sums say $F(n)$ for a given stick length $n$, or on the other hand maybe the OP is interested in a formula of type $F(n,t)$ for the number of ways a stick of length $n$ can be cut into three parts in $t$ ways, no repeated numbers. The latter would be a lot harder, and even a provable formula for $F(n)$ would seem difficult, at least to me.\n\nEDIT In this construction the \"middle numbers\" are spaced 2 apart. And in most cases more triples can be found in the unused numbers of the middle range. For example in the case $a=4$ with stick length $6a=24$, the $a=4$ triples formed using the construction are\n\n$[1,11,12],\\ [2,9,13],\\ [3,7,14],\\ [4,5,15]$\n\nThe unused numbers of the middle range make up another triple $[6,8,10],$ so that for stick length 24 one can find 5 triples.\n\nFor the case $a=10$ (stick length 60) besides the ten automatically constructed triples, the unused middle numbers are the nine even numbers from 12 through 28, and these can be put into the three triples $[12,20,28],\\ [14,22,24],\\ [16,18,26].$ So for stick length 60 the max number of triples is at least 13.\n\nshare|improve this answer\nI'm interested in maximal number of sums $F(n)$ \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 1:18\nThanks for the comment. This narrows down what you're looking for. I'll try for some provably maximal cases. I guess each sum may as well be in say increasing order, as rearrangements of a single sum cannot appear on the list because of the uniqueness requirement... \u2013\u00a0 coffeemath Feb 5 '13 at 1:28\nThanks for helping. \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 1:47\n\nI assume that your lengths have to be integers. Let $a, b,c$ be the lengths.\n\nYou want $a+b+c=N$ and $a,b,c$ pairwise distinct.\n\nSince the equation is homogeneous in $a,b,c$ we can find the solutions for which $a<b<c$ and then by permuting we get all solutions (thus the no of solutions will be multiplied by 6).\n\nNow this is a simple counting problem.\n\n$N=a+b+c < 3c$, thus $c > \\frac{N}{3}$. Also $c=N-a-b <N-2$.\n\nFor each fixed $\\frac{N}{3} < c < N-2$ you need to count all the solutions to the equation $a+b =N-c$ with $a < b <c$. This is very easy, since any $b$ yields an unique $a$, the only thing you have to make sure is that $a < b <c$.\n\nAfter finding this number, add this by $c$ and you get your formula...\n\nshare|improve this answer\n\nI think you're asking about partitions of an integer into distinct parts. That is, you're interested in $$ q_k(N) := \\# \\{ (a_1, \\dots, a_s) \\; : \\; a_1 > \\dots > a_s > 0, \\; \\sum a_i = N \\} $$ (and $s$ is allowed to be anything). You can show that $q_k(N + \\binom{k}{2}) = p_k(N)$ where $p_k(N)$ is equal the number of partitions of $N$ into exactly $k$ parts. Then, if $N$ isn't too big you can compute $p_k(N)$ via the recurrence $p_k(N) = p_{k-1}(N-1) + p_k(N-k)$. (Base conditions are $p_k(k) = 1$ for all $k$, $p_{n-1}(n) = 1$, $p_1(n) = 1$, and $p_2(n) = \\lfloor n/2 \\rfloor$.)\n\nshare|improve this answer\n\nThese values (where the first term is the count for $N=6$ here) form sequence A001339 in the Online Encyclopedia of Integer Sequences.\n\nThe number of ways to partition $N$ into exactly three distinct positive integer parts equals the number of ways to partition $N-6$ into at most three (non-negative) integer parts. The following observation explains a one-to-one correspondence: If $N-6=a+b+c$ for non-negative integers $a \\le b \\le c$, then $N = (a+1) + (b+2) + (c+3)$ is a partition of $N$ into three distinct positive integer parts.\n\nNo closed form is provided in OEIS, so one may presume there is none.\n\n(The \"EDIT\" remark in the original question is unclear to me, so this may not be the right answer.)\n\nshare|improve this answer\n\"No closed form is provided in OEIS\"? Au contraire, several closed forms are provided in OEIS. Also, a simple, rational generating function is given, which guarantees the existence of a closed form. But, as you note, this doesn't seem to be the question OP wants answered. \u2013\u00a0 Gerry Myerson Feb 5 '13 at 11:20\nThanks, Gerry. I struck my wrong remark about closed form. \u2013\u00a0 Steve Kass Feb 5 '13 at 16:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/252298/how-to-find-sum-of-changing-binomnr-times-binomms-series\nText:\nTake the 2-minute tour \u00d7\n\nHow can we find the sum of the following series\n\n$$\\sum_{i=0}^p \\binom{m-q+1+i}{i} \\binom{n+q-1-i}{n-i}=\\sum_{i=0}^p\\frac{(m-q+1-i)!}{ i! (m-q+1)!}\\frac{ ( n + q-1-i)!}{ (q-1)! (n-i)!}$$ where $p < n,m$?\n\nshare|improve this question\nDo you denote by $!n$ the factorial? Usually it is denoted by $n!$. \u2013\u00a0 martini Dec 6 '12 at 14:21\n$!n$ is not the notation for factorial, but rather for derangements. \u2013\u00a0 Cameron Buie Dec 6 '12 at 14:30\n\n2 Answers 2\n\nHere is an answer computed by maple\n\n$${n+q-1\\choose n}{_2F_1(-n,m-q+2;\\,-n-q+1;\\,1)}-{m-q+2+p\\choose p+1}{n+q -2-p\\choose n-p-1}$$ $$\\times\\,{_3F_2(1,-n+1+p,m-q+3+p;\\,p+2,-n-q+2+p;\\,1)} $$\n\nwhere $_2F_1$ and $_3F_2$ are the hypergeometric function.\n\nThe same answer can be computed by Mathematica $9$.\n\nshare|improve this answer\n\nIf $p\\ge n$, then $$ \\begin{align} \\sum_{i=0}^p\\binom{m-q+1+i}{i}\\binom{n+q-1-i}{n-i} &=\\sum_{i=0}^p\\binom{m-q+1+i}{m-q+1}\\binom{n+q-1-i}{q-1}\\\\ &=\\binom{m+n+1}{m+1} \\end{align} $$ However, if $p\\lt n$ I don't think there is a closed form (that, in general, doesn't involve hypergeometric functions).\n\nTo confirm Mhenni Benghorbal, Mathematica 8 gives $$ \\binom{n+q-1}{n}\\,_2F_1(-n,m-q+2;-n-q+1;1) -\\binom{m+p-q+2}{p+1}\\binom{n-p+q-2}{n-p-1}\\\\ \\times\\,_3F_2(1,-n+p+1,m+p-q+3;p+2,-n+p-q+2;1) $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-to-find-antiderivative-of-product.140410/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHow to find antiderivative of product\n\n  1. Oct 29, 2006 #1\n    problem: find the anti derivative of x^5 + tan(2x)sec(2x)dx\n\n    how do you find the anti derivative of the second half of that problem tan(2x)sec(2x)\n  2. jcsd\n  3. Oct 29, 2006 #2\n    Does the function y=sec(u)tan(u) look familiar at all? Perhaps as the derivative of some common elementary function?\n  4. Oct 29, 2006 #3\n    yeah, you are going to have to use u-substitution twice. I don't know if I am correct or not, but I changed everything to sin and cos before anything and manipulated it that way. I then let u = cosx and du = -sinx. For the second u-substitution, I let v=u\u00b2-1 and (1/2)dv = udu. I hope that helps and does not confuse you and more.\n  5. Oct 29, 2006 #4\n    What are you doing? What is the derivative of secant?\n  6. Oct 29, 2006 #5\n    oh yeah... I see that the deriveitive of secx = secx tanx... Hmm... looks like I went a long.. long long long way around it.. haha. Sorry about that donjt81, I hope I didn't lead you too far the wrong way. I think it comes out to the same answer. Does it? Well, I guess we can both learn a lesson, or at least myself. And that is to really look at what's in front of you with the equation before just jumping into it. I just jumped right in and started to manipulate it, when I could have just taken a minute to think about what was really there and solved it much quicker and easier.\n\nHave something to add?\n\nSimilar Discussions: How to find antiderivative of product"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-scalars-from-vectors.43276/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestion: scalars from vectors\n\n  1. Sep 15, 2004 #1\n    I saw this question posted yesterday, and now got a similar question to work out.\n\n    A = (6i-8j) cm\n    B = (-8i+3j) cm\n    C = (26i+19j) cm\n\n\n    Determine the two scalars a and b.\n\n    Ideas anyone??\n\n\n    Last edited: Sep 15, 2004\n  2. jcsd\n  3. Sep 15, 2004 #2\n    C=0 ?? But you jsut said C=26i+19j . Is this a typo? or did you mean aA+bB-C=0\n\n    in which case aA+bB=C\n    seems pretty straightforward to me. Split it up into the vector components, and youll have 2 equations with 2 unknowns, easily solveable.\n  4. Sep 15, 2004 #3\n    Sorry. That was a tipo. I made a mistake.\n\n    aA+bB+C=0 not aA+bB=C=0 not\n  5. Sep 15, 2004 #4\n    Well, what have you done so far? How have you approached it?\n  6. Sep 15, 2004 #5\n    I used the equation a^2 + b^2 = c^2 and the coodinates (6,-8) and (-8,3) to determine that the magnitude of A is 0.5cm and that the magnitude of B is 0.7cm. But I don't know if that is what is meant by \"determine the two scalars a and b\". I'm asuming scalars in this question is the scalar quantity or \"magnitude\".\n    Last edited: Sep 15, 2004\n  7. Sep 15, 2004 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The \"equation a^2+ b^2= c^2\" doesn't even make sense here. You are given vectors A, B, C, not numbers a, b, c (and you certainly don't have any number c).\n\n    Do you know how to add vectors and multiply vectors by a number? That should have been ther first thing you learned!\n\n    If A= 6i+8j, then aA= (6a)i+ (8a)j.\n\n    If B= -8i+ 3j, then bB= (-8b)i+ (3b)j\n\n    aA+ bB = (6a- 8b)i+ (8a+ 3b)j and that must be equal to C= 26i+ 19j.\n\n    Okay, have you learned that two vectors are equal only if the respective components are equal?\n\n    To have aA+ bB= C, you must have (6a- 8b)i+ (8a+ 3b)j= 26i+ 19j and so\n    6a- 8b= 26 and -8a+ 3b= 19.\n\n    Can you solve those two equations for a and b?\n\nHave something to add?\n\nSimilar Discussions: Question: scalars from vectors\n  1. Vector and scalars (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/entropy-of-the-universe.249227/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEntropy of the universe\n\n  1. Aug 9, 2008 #1\n\n    A model universe comprises 100 atoms in system 1 and 1500 atoms in system 2. Compute the entropy for the universe when there are 3 atoms on in system 2 and 97 atoms on in system 1 (using sterlings approximation).\n\n    3. The attempt at a solution\n    I am able to find the entropy of systems 1 and 2 by initially finding the number of microstates and then the equation:\n\n    entropy = boltzmanns * ln(microstates)\n\n    Just wondering how I would get the entropy of the universe though.\n  2. jcsd\n  3. Aug 10, 2008 #2\n\n\n    User Avatar\n\n    Well, if you know how many microstates there are for systems 1 and 2, then how many microstates are possible for the combined system (1+2)?\n  4. Aug 10, 2008 #3\n    I was unsure of the terminology. So taking universe as systems 1 and 2:\n\n    I can find number of microstates using \u03a9 = C(N,n)\n    (i.e. the number of ways of moving n atoms from N sites)\n\n    Thus for system 1:\n    \u03a9 = C(1500,3)?\n    This is a massive number!\n\n    Am I on the right track?\n  5. Aug 10, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    Yup that's the correct way of doing the calculation. The calculation may be made easier by finding a formula for C(N,n) in terms of factorials, then applying Stirling's approximation.\n  6. Aug 11, 2008 #5\n    sterlings approximation only helps once I get a value of \u03a9 though correct?\n    I cannot even compute C(1500,3)=1500!/3!1497! due to overflow!\n  7. Aug 11, 2008 #6\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    Try to calculate ln(\u03a9) instead.\n  8. Aug 12, 2008 #7\n    Ok, so I managed to compute C(1500,3) and C (100,97).\n    I got 561375500 and 646800 respectively.\n\n    (I wish to keep in terms of boltzmanns)\n    Therefore for system 1:\n    entropy = K*ln(561375500) = 20.15K\n\n    and system 2:\n    entropy = K*ln(646800) = 13.38K\n\n    total = 33.53K?\n\n    Where does Sterling's Approximation come into this?\n  9. Aug 12, 2008 #8\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    ln(\u03a9) = ln(1500!/3!1497!) = ln(1500!) - ln(3!) - ln(1497!) = 1500ln(1500) - 1500 - ln(6) - 1497ln(1497) + 1497\n\n    Here's where sterling's approximation saves you from evaluating horrible factorials.\n  10. Aug 13, 2008 #9\n    yeah i completed it, thanks for help\n\nHave something to add?\n\nSimilar Discussions: Entropy of the universe\n  1. Quantum entropy and ? (Replies: 2)\n\n  2. Entropy expression (Replies: 1)\n\n  3. Finding Entropy (Replies: 3)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/finding-the-surface-flux-of-the-sun.185342/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nFinding the surface flux of the sun\n\n  1. Sep 17, 2007 #1\n\n    The flux from the Sun above the Earth's atmosphere is about 1370 watts/m^2. This quantity is called the solar constant S and equals pi*f(sun). Use the angular radius of the sun as seen from the Eart to find pi*F , the surface flux of the sun.\n\n    2. Relevant equations\n\n    possible equations that may be relevant: Flux=sigma*T^4, T being the temeperature dependence and sigma=5.669*10^-8/m^2 *K^4; Luminosity = flux*area, a\n\n    3. The attempt at a solution\n\n    I have to find the angular radius of the sun in order to find the surface flux of the sun. To find the angular radius of the sun, I would probably have to used the fact that theta=lambda/Diameter of the sun; theta=lambda/2*radius of the sun. L=4*pi*R^2 *sigma*T^4. There are still 3 unknown variables: lambda, and the Temperature. Perhaps I should approach a solution to this problem in a different fashion: I know the radius of the sun is 6.96*10^5 km and luminosity of the sun is 3.90*10^26 W and the flux from the sun over the earth's atmosphere is 1370 watts/m^2. L/A=flux => (3.90*10^26 W)/(4pi(6.96*10^8 m)^2) = 64067276.69 W/m^2. But that calculation gives me the total flux of the sun, it doesn't give me the surface flux of the sun. how do you find the surface flux of the sun?\n  2. jcsd\n  3. Sep 18, 2007 #2\n    I think you can just use the area of spheres, and the sun as a point source to calculate this.\n  4. Sep 18, 2007 #3\n\n\n    User Avatar\n    Homework Helper\n\n    I don't think you want to treat the Sun as a point source if your aim is to find its surface flux (the angular radius is not that tiny).\n  5. Sep 18, 2007 #4\n\n\n    User Avatar\n    Homework Helper\n\n    I believe you're supposed to proceed from the angular radius, *without* knowing the radius of the Sun or the distance to it from here. As BlackWyvern says, you want to use the surface areas of spheres. You want to consider that one square meter versus the entire sphere at Earth's distance, then consider how that relates to the area of the Sun's surface. Using the definition of angular radius (in the small-angle approximation), you'll notice that it can be identified in your proportional relations.\n\n    You shouldn't need to know anything about blackbody radiation or the Sun's surface temperature either.\n\n    I was puzzled by one other thing you said: what definition are they using in your course for \"surface flux\"? I've been checking around and that term generally means power or luminosity per surface area ( W/[m^2] ).\n    Last edited: Sep 18, 2007\n  6. Sep 18, 2007 #5\n    I just realized that wouldn't work because of the distance differences.\n\n    But you could do pretty much the same thing, just know that since it's a radiation, it's intensity will depreciate proportional to 1/d^2. Use this and the surface area of spheres (I think it's A = 4 (pi) r^2 ) to derive it.\n  7. Sep 18, 2007 #6\n\n\n    User Avatar\n    Homework Helper\n\n    Actually, these two statements are equivalent. This is because L = F x A, which is the key to the solution. Since intensity is power/area, it has a simple relation to flux; in fact, depending on which specialists' definition you're using, that can *be* the same thing. (That's why I asked what definition was intended in the problem.)\n  8. Sep 18, 2007 #7\n\n\n    User Avatar\n    Homework Helper\n\n    I found one source that might help with this. In Foukal's _Solar Astrophysics_ (pp.40-41), what we will find is the net flux through the Sun's surface. If we call *that* f, then f = pi*F, where F is known as the \"astrophysical flux\".\n  9. Sep 18, 2007 #8\n    I don't think the definition of angular radius is stated clearly in my textbook , but is it theta=lambda/2*radius. how do you find theta and lambda in order to find radius of the sun. Also should I assume that the luminosity of the sun is 3.90*10^26 Watts\n\n    well according to my book, theta = lambda/d , d being the size of the apeture. theta= 5e-7 rad. so the two unkwowns are lambda and d. I don't understand why d and lambda are relevant in helping me find the radius of the sun.\n\n    also, would r just be the distance from one point on earth to another point on the sun, which is just one astronomical unit ?\n\n    if so, then the surface area sun would be: SA=4*pi*r^2 = 4*pi*(1.496e11 m)^2 = 2.812e23 m^2\n\n    Since the flux of the earth is given in the problem, I can now find the luminosity of the sun, which is just L = SA *F = (2.81e21m^2)(1370 W/m^2) = 3.84e24 watts.\n\n    Now how would I find the surface flux of the Sun , now that I calculated its luminosity? Could I also used the fact that sin(theta)= R/AU. How would I find theta ?\n\n    I don't understand why my professor wants me to go through numerous calculations for finding the radius of the sun when it is given in the book. I mean whats the point of have the radius of the sun in the appendix of my textbook if I'm going to have to going to have rederived it through tedious calculations.\n    Last edited: Sep 18, 2007\n  10. Sep 18, 2007 #9\n\n\n    User Avatar\n    Homework Helper\n\n    I think they're giving you an apparent radius, based on the wavelength of observation. The theta = lambda/d is an approximate value for the angular size of the Airy disk for a point source.\n\n    In any case, that isn't what we need here. For the physical angular size of the Sun, we'd just want the angle subtended by the Sun's radius at the distance of Earth (1 AU, as you've said). Use the small-angle approximation, since this angle is much less than 0.1 radian.\n\n    I think you have the radius of Earth's orbit in there...\n\n    So you have the surface area of a sphere of 1 AU radius, but something's off because that value for the luminosity is a factor of 100 low...\n\n    You can drop the sine because the small-angle approximation will be valid (it gives entirely adequate precision).\n\n    You don't need to *find* theta, actually, as I'll explain below. Go back to the equation you gave, L = F x A. Consider that the same power leaving the Sun's surface also passes through that sphere with 1 AU radius. So you can equate F x A for each sphere and solve for F for the Sun's surface; theta will appear in your expression.\n\n    Are you in an astrophysics or experimental physics course? The point of the exercise is that you are calculating the nex flux of the Sun from two *directly measurable* quantities, the solar radiation flux at the \"top\" of Earth's atmosphere and the angular diameter of the Sun. Quantities calculated only from directly measurable ones are more reliable than those which are computed from inferred quantities, such as the solar radius or the astronomical unit (there is a whole historical literature you can look at about how these and similar quantities were found and how we got to the currently accepted values).\n\n    When you get past the introductory courses (1000-level in some systems) in the physical sciences, you start getting more into *how* various quantities and equations are derived, rather than just being told, \"Take our word for this and use it!\"\n\n    All those nicely-tabulated quantities listed in your textbook or handbooks of reference data are the result of uncounted person-years of effort and debate. It is always a good idea to know where the numbers you use came from and how reliable (precise, or even just accurate) they really are...\n\nHave something to add?"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/62018.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nEquations That Make No Sense\n\nDate: 01/15/2003 at 00:16:37\nFrom: Nicholas\nSubject: Rational Equations \n\n   x-8/5 = x+2/6\n\nI would assume you find the lowest common denominator of 5 and 6. Then \nmultiply it by x. Not sure if it's correct though.\n\nDate: 01/16/2003 at 11:30:46\nFrom: Doctor Ian\nSubject: Re: Rational Equations \n\nHi Nicholas,\n\nYou could certainly proceed by finding a common denominator, but it\nwould be kind of like driving to New York on your way from Chicago to\nLos Angeles.\n\nLet's write the equation in a slightly fuzzier way:\n\n  x - this = x + that\n\nThink about the number line for a moment.  Suppose we choose a number\non it, somewhere:\n\n\nIf we subtract something from it, we end up to the left of where we\n\n     x-this       x\n\nAnd if we add something to it, we end up to the right of where we \n\n     x-this       x        x+that\n\nIs there _anywhere_ on the number line that we could start so that\nthese two new points are in the same place?  This is what we're asking\nwhen we write the equation\n\n  x - this = x + that\n\nThere is no such place. So there is _no_ value of x that will make\nthis equation true. How can we show that 'by algebra'? \n\nWe can start by noting that we can subtract the same thing from both\nsides of an equation. Why not subtract x from both sides? Then we get\n\n      x - 8/5 - x = x + 2/6 - x\n\n             -8/5 = 2/6\n\nNow, this clearly isn't true. But we derived it from the original\nequation using valid rules. So what does that mean? It means that\nthe original equation can't be true, either.  \n\nAs I said, we could also proceed by finding a common denominator for\nthe fractions:\n\n              x - 8/5 = x + 2/6 \n\n            x - 48/30 = x + 10/30\n\n    x - 48/30 + 48/30 = x + 10/30 + 48/30\n\n                    x = x + 58/30\n\nAnd again, we have something that obviously can't be true. There is\nno number such that you can add a non-zero number to it, and end up\nwith the same thing.  \n\nSo what should you learn from this? One important lesson, I think, is\nthat it's possible to write equations that make no sense, just as it's \npossible to write sentences that make no sense: \n\n   Context, Language, and False Equations\nA second important lesson is that before you jump in and start\nexecuting the first technique that occurs to you, it's a good idea to\nstep back and think about whether there might be an easier way to get\nthe answer you're looking for:\n\n   Factoring vs. an Equation\n\nor anything else. \n\n- Doctor Ian, The Math Forum\nAssociated Topics:\nHigh School Basic Algebra\nHigh School Linear Equations\nMiddle School Algebra\nMiddle School Equations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limit-of-a-sequence.3335/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLimit of a sequence\n\n  1. Jun 26, 2003 #1\n    It isn't a homework problem but I think I better post it here instead of Mathematics forum, since it belongs to \"exam help\".\n\n    Prove that for any positive real numbers a and b,\n    lim [(an+b)1/n-1] = 0\n\n    I don't need to use things like |a-b|<epsilon. A simple way will do. I know it's an easy question but I don't know where to start. Could someone please help.\n  2. jcsd\n  3. Jun 26, 2003 #2\n\n    Tom Mattson\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    This one just screams \"L'Hopital!\"\n\n    First, rearrange it to:\n\n\n    Then take the natural log of both sides to get:\n\n    lim ln(an+b)/n=0\n\n    This goes to &infin;/&infin;, which is an indeterminate form and ripe for L'Hopital's rule.\n  4. Jun 26, 2003 #3\n    LOL, thanks Tom and L'hopital\n\n    lim ln(an+b)/n\n\n    = lim a/(an+b)\n  5. Jun 27, 2003 #4\n    Oh sorry, I forgot to mention\n    is a sequence, not a function. I think L'hopital's rule applies to differentiable functions only.\n\n    Perhaps I better rephase the question a bit.\n    A sequence {an} is defined by (an+b)1/n-1\n    Prove that\n    lim (an+b)1/n-1 = 0\n    (a and b are real numbers and n is a positive integer)\n  6. Jun 27, 2003 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    It is true that L'hopital's rule applies to functions rather than sequences.\n\n    However, IF we can convert a sequence an to a function f(x) (we can't if the sequence involves things like n! or \"floor\" or \"ceiling\" that can't be written simply as a continuous function), then f(x)-> L, an-> L. The other way doesn't necessarily work- the function might not have a limit, depending on how it is defined for non-integer values.\n  7. Jun 27, 2003 #6\n    So we can treat a sequence as a function if it is an \"elementary\" one like the one I posted, and can apply L'hopital's rule, is it correct?\n\nHave something to add?\n\nSimilar Discussions: Limit of a sequence\n  1. Limit of sequence (Replies: 13)\n\n  2. Limits of Sequences (Replies: 8)\n\n  3. Limit of a sequence (Replies: 3)\n\n  4. Limit of a sequence (Replies: 2)"}
{"text": "Retrieved from http://mathoverflow.net/questions/109106/upper-bound-on-expectation-value-of-the-product-of-two-random-variables/109110\nText:\nTake the 2-minute tour \u00d7\n\nHello, I am trying to find an upper bound on the expectation value of the product of two random variables.\n\nSo suppose x, y are two non-independent random variables, given that I know the distribution of x p(x) and the distribution of y q(y), how can I find an upper bound on E[|x * y |] that is a function of p and q?\n\nI know that Holder's inequality gives an upper bound to my problem in terms of moments of x and y, but this is a poor bound for the problem that I am considering.\n\nThank you! Best Michele\n\nshare|improve this question\n\nclosed as not a real question by Yemon Choi, Qiaochu Yuan, Andres Caicedo, Will Jagy, Bill Johnson Oct 8 '12 at 16:04\n\n\nCauchy-Schwarz? \u2013\u00a0 Yemon Choi Oct 8 '12 at 0:22\nWell if it gives you a poor bound for your problem, you need to specify more details. The Cauchy-Schwarz inequality is sharp \u2013\u00a0 Yemon Choi Oct 8 '12 at 1:42\nWhy the down-votes? I don't think that C-S is sharp for this situation. If you assume that they are non-negative valued, the sharp upper bound is obtained when the variables are monotonically coupled. I'll post a formula for this in a few minutes. \u2013\u00a0 Anthony Quas Oct 8 '12 at 3:04\nC-S is sharp if all that you know are the second moments. Here we've got far more information: the entire distribution of the random variables. \u2013\u00a0 Anthony Quas Oct 8 '12 at 3:07\nI still think, though, that the question should have included at least some examples of the kinds of distribution that the OP had in mind \u2013\u00a0 Yemon Choi Oct 8 '12 at 3:52\n\n2 Answers 2\n\nI'll assume that $X$ and $Y$ are non-negative random variables. Let $F_X$ be the cumulative distribution function of $X$ (that is $F_X(t)=\\mathbb P(X\\le t)$) and $F_Y$ be the cumulative distribution function of $Y$.\n\nIn your notation, probably $F_X(t)=\\int_0^t p(s)\\,ds$ and $F_Y(y)=\\int_0^t q(t)\\,dt$.\n\nNow define two functions on $[0,1]$: $g_X(x)=\\sup\\lbrace t\\colon \\mathbb P(X\\le t)\\le x\\rbrace $ and similarly $g_Y(x)=\\sup\\lbrace t\\colon \\mathbb P(Y\\le t)\\le x\\rbrace$. These functions are the increasing rearrangements of $X$ and $Y$. That is these are non-decreasing functions with the property that $m\\lbrace x\\colon g_X(x)\\le t\\rbrace =\\mathbb P(X\\le t)$ and $m\\lbrace x\\colon g_Y(x)\\le t\\rbrace = \\mathbb P(Y\\le t)$.\n\nNow the largest possible value of $\\mathbb E XY$ given the distributions is $\\int_0^1 g_X(t)g_Y(t)\\ dt$. Intuitively the reason for this is that the largest value for the expectation is obtained when the largest values of $X$ are multiplied by the largest values of $Y$. Slightly more precisely imagine you've arranged the $X$ values from largest to smallest. Think of these as \"weights\" for the $Y$ values. Obviously you get the biggest integral if you weight the big $Y$ values with the biggest weights.\n\nshare|improve this answer\nDear Anthony, Thank you very much for your answer! A few questions: - Is this bound better than Holder's inequality's bound \ud835\udd3c[XY] <= E[X^p]^(1/p)*E[Y^q]^(1/q) with q>1,p>1,1/p+1/q = 1? If it is, is there a way of proving or simply justifying this? - Where can I find a proof of the bound that you suggested? Thanks you Best Michele \u2013\u00a0 Michele Oct 9 '12 at 23:54\nThe justification is in my answer. For more, you could try Lindvall's book \"Lectures on the Coupling Method\". This is the best possible bound: If you let $\\omega$ be uniformly distributed in the unit interval, then $g_X(\\omega)$ has the same distribution as $X$ and $g_Y(\\omega)$ has the same distribution as $Y$ and the product of these random variables has the integral in my answer. \u2013\u00a0 Anthony Quas Oct 10 '12 at 5:19\nDear Anthony, Still, it is not clear to me how to prove the inequality that you suggested : E[X*Y] <= \\int_{0}^{1} dt g_{X}(t) * g_{Y}(t). Is the proof in the book \"Lectures on the Coupling Method\"? It it not clear either wether and why this bound is better than the Holder's inequality bound E[X^p]^(1/p)*E[Y^q]^(1/q). Can you prove this? Thanks! Michele \u2013\u00a0 Michele Oct 16 '12 at 1:05\nIf you know that $X$ is uniformly distributed on the unit interval and $Y$ are is the uniformly distributed random variable on [1,2], then the bound I'm suggesting comes from $g_X(t)=t$, $g_Y(t)=1+t$, so that $\\mathbb E XY\\le \\int (t+t^2)\\,dt=5/6$. If you use H\\\"older's inequality, you get $(1/(p+1))^{1/p}((2^{q+1}-1)/(q+1))^{1/q}$. This is greater than 5/6 for all $1/p+1/q=1$. My bound is attained if $X$ is uniform and $Y=1+X$. In general, my bound is always attained for some joint distribution on $X$ and $Y$. The Holder bound is not always attained. So mine is lower and is best poss. \u2013\u00a0 Anthony Quas Oct 16 '12 at 5:57\nApparently the inequality I'm quoting goes by the name \"Hardy-Littlewood inequality\". See math.toronto.edu/almut/rearrange.pdf \u2013\u00a0 Anthony Quas Oct 16 '12 at 6:55\n\nI would try yo apply Hoeffding's Lemma, who used his result to identify the bivariate cdfs with given marginal cdfs that minimize or maximize correlation. Let $(X,Y)$ be a random vector with bivariate cdf $H$, let $F$ and $G$ be their marginal cdfs, respectively. It is well known that a sharp upper bound for $H(x,y)$ is $\\min(F(x),G(y))$. By Hoeffding's Lemma we get that $$E(XY)\\leq E(X)E(Y)+\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\big[\\min(F(x),G(y))-F(x)G(y)\\big]dxdy$$\n\nshare|improve this answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56191.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nBalls in Boxes\n\nDate: 05/05/99 at 13:49:04\nFrom: Alp Bassa\nSubject: A combinatorial problem (putting balls in boxes)\n\n\nI tried to solve the following problem. I know the answer, but I \ndon't know how to find it. I hope you can help me:\n\nin 2 of the boxes should be more then the balls in the other box. How \nmany ways are there to do this?\n\nAnswer: t*(t+1)/2 (why?)\n\nI tried to solve it this way:\n\n\nIf there are B(n-2) ways to do this with n-2 balls, then we can to \nthis with n Balls in B(n) ways. Now we just have to find some relation \nbetween B(n) and B(n-2). So it seems like a recursion problem.\n\nThank you very much,\nAlp Bassa\n\nDate: 05/05/99 at 16:09:40\nFrom: Doctor Anthony\nSubject: Re: A combinatorial problem (putting balls in boxes)\n\nIf any box is empty one box will have more balls than the other two, \nso we know that every box has some balls. Also with 2t+1 balls no box \ncan have more than t balls or again it would not satisfy the condition \nof being outnumbered by the other two. So the generating function is\n\n(x + x^2 + x^3 + ..... + x^t)^3 and we require coefficient of x^(2t+1)\n\nWe can write the series as  \n\n                 x^3(1 - x^t)^3\n                    (1 - x)^3 \n\n       = x^3(1-x^t)^3(1-x)^(-3)\n\n  =  x^3[1 -3x^t + 3x^(2t) - x^(3t)][1 + C(3,1)x + C(4,2)x^2 + ....\n\n  = x^3 - 3x^(t+3) + 3x^(2t+3) - x^(3t+3)]SUM[C(r+2,2)x^r] \n\nWe can ignore the terms 3x^(2t+3) - x^(3t+3) as they are already \nbeyond the power of 2t+1 that we require.\n\n  We have x^3.C(2t,2t-2).x^(2t-2)  =  C(2t,2t-2).x^(2t+1)\n\n  also  -3x^(t+3).C(t,t-2).x^(t-2)  =  -3.C(t,t-2).x^(2t+1)\n\nSo required coefficient is\n\n    2t(2t-1)     3t(t-1)       4t^2 - 2t - 3t^2 + 3t\n      2!           2!                    2!\n\n                                t^2 + t        t(t+1)\n                                   2             2 \n\nand so the number of arrangements satisfying the condition is \n\n\n- Doctor Anthony, The Math Forum\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56218.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nLab Partner Pairings\n\nDate: 01/21/2001 at 22:45:08\nFrom: Don Maynard\nSubject: Finding lab partner pairs in a class of 22\n\nA friend who is a teacher would like to find all the possible pairings \nof his 22 students for science labs. Is there an algorithm for this? \n\nIt's a problem that is much more complicated than it appears at first \nsight. There should be 11 pairs and no student should be paired to the \nsame other student twice in the series. I wrote a program that could \nlist up to 14 pairings, but that was not satisfactory because we \nwanted to find all possible lists and be assured that they were all \nthere. Any ideas? \n\nThanks for your consideration.\n\nDon Maynard\nAmerican School in Japan\n\nDate: 01/29/2001 at 11:52:31\nFrom: Doctor Ian\nSubject: Re: Finding lab partner pairs in a class of 22\n\nHi Don,\n\nIf I understand your question correctly, you are using the word \n'pairing' in the following way. A class of four students has the \nfollowing pairings:\n\n   Pairing 1:  AB CD \n   Pairing 2:  AC BD\n   Pairing 3:  AD BC\n\nIf this is the correct interpretation, then you can generate all the\npossible pairings in the following way.  \n\nI'll use the following data structure to represent a single pairing.  \nIt's a list that contains two other lists. The first list is a list of \nstudent pairs. (Each pair is itself a list.) The second list is a list \nof unpaired students. \n  (((a b) (c d))            The pairing so far.\n   (e f g h))               Students yet to be paired.\n\nStart with list containing a single empty pairing:\n\n    (a b c d)))\n\nFrom this, generate the set of possible first pairs, and make a new \npairing that begins with each of those pairs:\n\n  ((((a b))\n    (c d))\n   (((a c))\n    (b d))\n   (((a d))\n    (b c))\n   (((b c))\n    (a d))\n   (((b d))\n    (a c))\n   (((c d))\n    (a b))\n\nNote what we did here - we took each possible pair from the list of\nunpaired students, and added that pair to the pairing. Then we removed\nthose students from the unpaired list. Each pair gives rise to a \ncompletely new pairing. \n\nNow do the same thing over again:\n\n  ((((a b) (c d))\n   (((a c) (b d))\n   (((a d) (b c))\n   (((b c) (a d))\n   (((b d) (a c))\n   (((c d) (a b))\n\nEach pairing is expanded until its unpaired list is empty, at which \npoint the pairing is complete. Note that in the general case (i.e., \nmore than two unpaired students), each pairing will give rise to \nseveral new pairings each time a new pair is selected, e.g.:\n\n  (((a f) (c e))\n   (b d g h))\n  (((a f) (c e) (b d))\n   (g h))\n  (((a f) (c e) (b g))\n   (d h))\n  (((a f) (c e) (b h))\n   (d g))\n  (((a f) (c e) (d g))\n   (b h))\n  (((a f) (c e) (d h))\n   (b g))\n  (((a f) (c e) (g h))\n   (b d))\nIn fact, a pairing with N unpaired students will give rise to \nN*(N-1)/2 new pairings.  \nNote that this algorithm will generate some duplicate pairings. But \nyou can sort all the pairings, which will force duplicates to appear \nnext to each other, making them easy to find and remove: \n\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a d) (b c))\n  ((b c) (a d))\n  ((b d) (a c))\n  ((c d) (a b))\n\n  == sort ==>\n\n  ((a b) (c d))\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a c) (b d))\n  ((a d) (b c))\n  ((a d) (b c))\n\n  == remove duplicates ==>\n\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a d) (b c))\n\nIn fact, since the number of possible pairings for 22 students is \ngoing to be VERY large, you might want to so this sort-and-remove step \nafter each round of selections, instead of waiting until the end.  \n\nI've used notation from the Lisp programming language, which is \nideally suited for this kind of thing; but you should be able to \nimplement the same algorithm in just about any programming language. \n\nI hope this helps.  Write back if you'd like to talk about this some \nmore, or if you have any other questions. \n\n- Doctor Ian, The Math Forum\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/117487/polynomial-rings/117538\nText:\nTake the 2-minute tour \u00d7\n\nLet $R$ and $S$ be non-zero rings with identity. Is it possible to have $R[x] \\cong S[[x]]$ ?\n\nshare|improve this question\nWhat about $R=\\mathbb{Z}[[x]]$, $S=\\mathbb{Z}[x]$? \u2013\u00a0 Piotr Achinger Dec 29 '12 at 9:17\n@Piotr: that doesn't work, or at least the natural map isn't an isomorphism. $\\mathbb{Z}[[x]] [y]$ is the subring of $\\mathbb{Z}[y][[x]]$ in which the coefficients of the $x^n$, as a polynomial in $y$, have uniformly bounded degrees. \u2013\u00a0 Qiaochu Yuan Dec 29 '12 at 9:28\n@Qiaochu: Wow, thanks, I never realized that! \u2013\u00a0 Piotr Achinger Dec 29 '12 at 10:10\n$S[[x]]$ can be given the structure of a complete metric space, by defining $d(a,b)=2^{-v_x(a-b))}$, with $v_x$ the $x$-adic valuation. On the other hand $R[x]$ is naturally a countable union of quite small subsets (polynomials of degree at most $n$ for $n=0,1,2,3,\\ldots$. Can one now try to argue topologically using some kind of Baire Category Theorem argument? Not that I can get it to work... \u2013\u00a0 user30035 Dec 29 '12 at 11:47\nI made a similar comment on your other question, but please ammend your title style to include complete questions. For example, \"Can $R[x] \\cong S[[x]]$?\" is a better title than the current one. Actually, the entire body of your question would fit in the title \u2014 titles on MO may be longer than tweets. \u2013\u00a0 Theo Johnson-Freyd Jan 1 '13 at 4:03\n\n3 Answers 3\n\nup vote 16 down vote accepted\n\nHere's a proof that no such commutative rings $R$, $S$ exist. (See the edit for an extension to noncommutative rings.)\n\nSuppose we have an isomorphism $\\phi: R[x] \\to S[[x]]$; let $a = \\phi^{-1}(x)$. First we claim that for all $b \\in R[x]$, the element $1 + ab$ is invertible in $R[x]$. Indeed, the element $\\phi(1 + ab) = 1 + (\\phi(b))x$ has an inverse given by a formal geometric series, so $\\phi^{-1}$ applied to this element must also be invertible.\n\nIn particular, $1 + ax$ must be invertible in $R[x]$. But it is well-known (in the commutative case) that any invertible polynomial $a_0 + a_1 x + \\ldots + a_n x^n$ has $a_0$ invertible and the other $a_i$ nilpotent. It follows quickly that $a$ must be nilpotent. But then $\\phi(a) = x$ is nilpotent in $S[[x]]$. We have reached an absurdity.\n\nEdit: Aided by Martin's excellent suggestion in his comment, we may easily extend the argument to noncommutative rings. Indeed, since $x$ is central in $S[[x]]$, we have that $a$ is central in $R[x]$. In particular, $a$ commutes with scalars; writing $a$ as a polynomial, it follows that each coefficient of $a$ is central in $R$. This is true also of the polynomial $1 + ax$, and now the proof that all but the unit coefficient of $1 + ax$ is nilpotent goes through as in the commutative case (see for example the nice argument given here). Thus $a$ is nilpotent.\n\nshare|improve this answer\nIn order to reduce to the commutative case, one may try to compute the centers of $R[x]$ and $S[[x]]$. \u2013\u00a0 Martin Brandenburg Dec 29 '12 at 16:18\nThanks very much for that suggestion, Martin. I have edited my answer to take it into account. \u2013\u00a0 Todd Trimble Dec 29 '12 at 16:48\n@Todd: Nice solution. Can you generalize this to skew polynomials or Ore extensions !? \u2013\u00a0 user30230 Dec 29 '12 at 17:32\n@shatich: perhaps someone else can see such a generalization, but to be honest I had to google Ore extension, so I'd have to sit down and think it over. It might be worth opening another question if you're interested. \u2013\u00a0 Todd Trimble Dec 29 '12 at 18:07\nAnother suggestion: In the end of the argument, just use the commutative case with $Z(R)[x]$. \u2013\u00a0 Martin Brandenburg Dec 30 '12 at 12:11\n\nThanks to Martin Brandenburg suggestion, if $R[x] \\cong S[[x]]$ then their centers are isomorphic too. So without loose of generality we can assume that $R$ and $S$ are commutative. In commutative case we know $J(R[x]) = Nil(R[x])$. This means that elements in the Jacobson radical of $R[x]$ are all nilpotent. On the other hand $x \\in J(S[[x]])$ and $x$ is not nilpotent. This shows that $R[x]$ and $S[[x]]$ can not be isomorphic.\n\nshare|improve this answer\nIn your argument you seem to be assuming that $R[x]$ is Jacobson. There is no reason for this to be true if $R$ is not Jacobson. \u2013\u00a0 Qiaochu Yuan Dec 29 '12 at 21:39\n@Qiaochu Yuan: I cann't see that, could you please tell exactly where he/she used that assumption ?? \u2013\u00a0 user30230 Dec 29 '12 at 22:51\nI think Qiaochu's objection arises from $J(R[x])=\\mathrm{Nil}(R[x])$. But this, in fact, holds for every commutative ring $R$, and uses the description of the units $R[x]^* = R^* + \\mathrm{Nil}(R) (x)$. @tvector: Your proof uses $Z(R[x])=Z(R)[x]$ and $Z(S[[x]])=Z(S)[[x]]$, right? \u2013\u00a0 Martin Brandenburg Dec 30 '12 at 12:17\n@Martin: Exactly, yes. \u2013\u00a0 user30276 Dec 30 '12 at 16:45\nHonestly, I think my solution is much better. Neat, Clean and short ! \u2013\u00a0 user30276 Dec 30 '12 at 16:52\n\nLet me write $R[x]=S[[y]]$ to avoid confusion.\n\nI. Note that 1+y is a unit. Therefore (thinking of y as an element of $R[x]$), we have $y\\in R$.\n\nII. Now mod out $y$ on both sides: $\\overline{R}[x]=S$.\n\nIII. This gives $R[x]=\\overline{R}[x][[y]]$\n\nIV. The ring on the right contains the element $\\sum(xy)^n$. Thus so does the ring on the left (thought of as a subring of the appropriate completion). It follows that $y$ is nilpotent in the ring on the left. But it's clearly not nilpotent in the ring on the right. Contradiction.\n\nshare|improve this answer\nI don't think that step I is correct. See also Todd's post for the units of $R[x]$. \u2013\u00a0 Martin Brandenburg Dec 29 '12 at 16:22\nMartin: Of course you're right. \u2013\u00a0 Steven Landsburg Dec 29 '12 at 17:05\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/proof-by-induction.253129/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProof by induction\n\n  1. Sep 1, 2008 #1\n    Show, by induction, that for all whole number of Roubles greater than 7, the amount can be given without change by using only 3 rouble and 5 rouble notes.\n\n    2. Relevant equations\n    In other words for all [tex]n \\in N, n > 7[/tex], there exist [tex] a, b \\in N [/tex] such that [tex] n = 5a + 3b [/tex]\n\n    3. The attempt at a solution\n    This is true for n = 8\n\n    I'm wondering if I can't use strong induction. I've noticed that all of these n's appear to be writable with [tex]a \\in \\{0,1,2\\}[/tex] while letting b take on any value, and that when you express the integers greater than 7 in order the a's when thus constrained go 1, 0, 2, 1, 0, 2, etc and each time around the b increments by one for each repetition of a. So, I don't know if I can weasel something out of this like to go from n to n+1 means either going from 1 to 0, 0 to 2, or 2 to 1 in a with the associated incrementation, but I just get the feeling that this isn't the way to go. It seems I'm missing something easier.\n  2. jcsd\n  3. Sep 1, 2008 #2\n    Looks like you're on the right track, and since it's true for n=8, it's true for n=18, n=28, etc. And if it's true for n=9...\n  4. Sep 2, 2008 #3\n    I think the real trick on this was to use strong induction and notice that P(n+1) is implied by assuming P(1)...P(n) are true. Specifically, if P(n-2) is true, then P(n+1) is implied because it is three more than it, so if P(n-2) were written as 5a+3b, P(n+1) is 5a + 3(b+1)\n\nHave something to add?\n\nSimilar Discussions: Proof by induction\n  1. Proof by induction (Replies: 2)\n\n  2. Proof by induction (Replies: 9)\n\n  3. Proof by induction (Replies: 32)\n\n  4. Induction Proof (Replies: 14)\n\n  5. Proof by Induction (Replies: 6)"}
{"text": "Retrieved from http://mathforum.org/kb/thread.jspa?threadID=2455175&messageID=8911841\nText:\nThe Math Forum\n\nSearch All of the Math Forum:\n\n\nMath Forum \u00bb Discussions \u00bb sci.math.* \u00bb sci.math\n\nTopic: probability problem\nReplies: 2 \u00a0 Last Post: May 4, 2013 11:34 AM\n\nAdvanced Search\n\n\nPosts: 419\nRegistered: 10/7/06\nRe: probability problem\nPosted: May 4, 2013 11:34 AM\n\nOn May 4, 1:43\u00a0pm, wrote:\n> Hello,\n> I am stuck with a probability problem. Here is the problem. Any help would be great.\n> There are N samples each have probability of Pi (i=0......n-1)\n> I want to find out probability of at least K of them occurs. Each is sampled only once. If probability of N events to be same it would have simpler. now since probability is different , not sure how to calculate this. Please also mention logic behind the calculations.\n\n1. What's the result if K = 0? With that out of the way, assume K >=\n\n2. Let q (i, j) be the probability that exactly j of the first i\nsamples occur, for 0 <= i <= n, 0 <= j < K. Let r (i) be the\nprobability that K or more of the first samples occur.\n\nGiven that K > 0, what is q (0, 0), what is q (0, j) for 1 <= j < K,\nwhat is r (0)? Look at the definitions of q and r, and the result\nshould be obvious.\n\nFor 1 <= i <= n: Since you know q (i-1, j) for 0 <= j < K, r (i-1),\nand p (i-1) which is the probability that the i-th sample occurs, how\ndo you calculate q (i, 0), q (i, j) for 1 <= j < K, and r (i) ?\nThere's a simple formula for each.\n\nThe desired result is r (n). Why?\n\n3. For extra points: How do you reduce the number of calculations if K\n>= n / 2?\n\n\n[Privacy Policy] [Terms of Use]"}
{"text": "Retrieved from http://math.stackexchange.com/questions/673824/generalization-of-sum-of-cube-of-any-3-consecutive-integers-is-divisible-by-3\nText:\nTake the 2-minute tour \u00d7\n\nI have this question posted by professor in graduate Number Theory class. First he asked for proof that the sum of cube of 3 consecutive integers is divisible by 3, which is very easy to prove, but then he continued by asking to prove its generalization, ie., n | 1^n + 2^n + 3^n + ... + n^n.\n\nHere you can easily find a counterexample that if n is even, the generalization fails. But if n is odd, looks like it works. I tried using mathematical induction but did not go anywhere. Then I tried using Binomial Expansion, Pascal Triangle, and using representation of consecutive numbers as ... (a-3), (a-2), (a-1), a, (a+1), (a+2), (a+3), ... in order to cancel out, but still did not go anywhere.\n\nI would appreciate any help. Thank you for your time.\n\nshare|improve this question\nHint: Use modular arithmetic. If you have $1,2,3,4,\\dots, n$, in modulo $n$, you have $1,2,3,\\dots, -3,-2,-1,0$. If $n$ is odd, then $(-a)^n = -a^n$, so that would cancel with $a^n$. \u2013\u00a0 Braindead Feb 12 '14 at 14:29\nWhy doesn't $a-3,a-2,a-1,a,a+1,a+2,a+3$ work? Add those $7$ numbers together and you get $7a$, which is divisible by $7$. \u2013\u00a0 John Habert Feb 12 '14 at 15:16\nThanks for your response! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:29\n@Braindead: Do give me example. Suppose you have 5, 6, 7, 8, 9, 10, 11 (mod 7), how do you turn them into -3, -2, -1, 0, 1, 2, 3 (mod 7) such that they will be cancel out? Thanks. \u2013\u00a0 A.Magnus Feb 14 '14 at 15:27\n@LoveMath I edited my answer to include the example. \u2013\u00a0 Braindead Feb 14 '14 at 17:01\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nSince this is a graduate level number theory class, I think it's safe to assume that you are familiar with modulo arithmetic?\n\nGiven any list of $n$ consecutive integers, $a, a+1, a+2, \\dots, a+n-1$, modulo $n$ this list is equivalent to $0,1,2,3,\\dots,n-1$ modulo $n$. (Note that I am not saying $a \\equiv 0 \\pmod{n}$). This list can be rewritten as:\n\n$1 \\equiv 1 \\pmod{n}$\n\n$2 \\equiv 2 \\pmod{n}$\n\n$3 \\equiv 3 \\pmod{n}$\n\n\n$\\dfrac{(n-1)}{2} \\equiv \\dfrac{(n-1)}{2} \\pmod{n}$\n\n$n-1 \\equiv -1 \\pmod{n}$\n\n$n-2 \\equiv -2 \\pmod{n}$\n\n$n-3 \\equiv -3 \\pmod{n}$\n\n\n$\\dfrac{(n+1)}{2} \\equiv -\\dfrac{(n-1)}{2} \\pmod{n}$\n\nSince $n$ is odd, exponentiation preserves the sign. And so\n\n$$0^n + 1^n + 2^n + \\dots + \\left(\\dfrac{n-1}{2}\\right)^n + \\left(\\dfrac{n+1}{2}\\right)^n + \\dots + (n-2)^n + (n-1)^n + n^n$$\n\nis equivalent to\n\n$$1^n + 2^n + \\dots + \\left(\\dfrac{n-1}{2}\\right)^n - \\left(\\dfrac{n-1}{2}\\right)^n + \\dots - 2^n - 1^n$$\n\nmodulo $n$, and so the sum becomes $0$ modulo $n$. Note that the exponent could be replaced by any odd integer and the statement will still hold.\n\nEDIT: Here is the example you requested in the comments.\n\nLet's say we have the list 5, 6, 7, 8, 9, 10, 11, with $n=7$.\n\nOkay, so the first thing I will do is to find their representatives in $\\mod 7$ between $0$ and $6$ inclusive.\n\n\n5, 6, 7, 8, 9, 10, 11 becomes 5, 6, 0, 1, 2, 3, 4.\n\nNow, let's look at $(n-1)/2$. For $n=7$, this number is 3. That is the cut off for the positive terms. The rest of them I turn them into negatives:\n\n$5, 6, 7, 8, 9, 10, 11$ becomes\n\n$5, 6, 0, 1, 2, 3, 4,$ which is\n\n$7-2, 7-1, 0, 1, 2, 3, 7-3$, which becomes\n\n$-2, -1, 0, 1, 2, 3, -3$.\n\nNow, take any odd power of these numbers, sum, you get 0 in modulo 7.\n\nTechnically, I could've gone directly from the original list to $-2, -1, 0, 1, 2, 3, -3$, without going through the intermediate step, but I wanted to illustrate how the proof applies to this particular example.\n\nshare|improve this answer\nThanks for your elaborate response! I actually came up with my own, but mine is good only for prime, yours is more comprehensive. (I used binomial coefficient, when n is prime then all coefficients will be divisible by n, etc.) Thanks again! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:29\nSolid Answer, nicely done. \u2013\u00a0 Newb Feb 14 '14 at 17:02\n\nThe remainders modulo $2k+1$ can be (re)written as $0,\\pm1,\\pm2,\\ldots,\\pm k$. By rising them each to any positive odd power of our choosing, they will maintain their sign, while their absolute values will be pair-wise equal, so ultimately their sum will be divisible through $n=2k+1$.\n\nshare|improve this answer\nThank you for your response! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:26\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/93466/minimum-height-trees-why-does-deleting-leaves-layer-by-layer-give-us-the-answer\nText:\nHere is the problem I tried to solve. Finally, I gave up and found a solution which was correct. Here is it.\n\nHere is the problem description:\n\nFor a undirected graph with tree characteristics, we can choose any node as the root. The result graph is then a rooted tree. Among all possible rooted trees, those with minimum height are called minimum height trees (MHTs). Given such a graph, write a function to find all the MHTs and return a list of their root labels.\n\nThe graph contains n nodes which are labeled from 0 to n - 1. You will be given the number n and a list of undirected edges (each edge is a pair of labels).\n\nYou can assume that no duplicate edges will appear in edges. Since all edges are undirected, [0, 1] is the same as [1, 0] and thus will not appear together in edges.\n\nExample 1 :\n\nInput: n = 4, edges = [[1, 0], [1, 2], [1, 3]]\n\n   / \\\n  2   3 \n\nOutput: 1\n\nExample 2 :\n\nInput: n = 6, edges = [[0, 3], [1, 3], [2, 3], [4, 3], [5, 4]]\n\n 0  1  2\n  \\ | /\n\nOutput: 3, 4\n\nHere is the solution I tried to understand:\n\nThe basic idea is \"keep deleting leaves layer-by-layer, until reach the root.\"\n\nSpecifically, first find all the leaves, then remove them. After removing, some nodes will become new leaves. So we can continue remove them. Eventually, there is only 1 or 2 nodes left. If there is only one node left, it is the root. If there are 2 nodes, either of them could be a possible root.\n\nI'm not sure I understand it so I could explain it to somebody. Why does deleting leaves layer-by-layer give us the answer?\n\n\nLet $T$ be a tree, and let $T'$ be the tree formed from $T$ by removing all leaves (vertices of degree 1). Assume that $T$ contains at least three vertices, so that $T'$ is not empty. This implies that every leaf $f \\in T$ has a (unique) neighbor $p(f) \\in T$ which is not a leaf.\n\nFor $v \\in T$, denote by $h_v(T)$ the height of $T$ when rooted at $v$. I claim that the following hold:\n\nFor every vertex $v \\in T'$, $$ h_v(T) = h_v(T') + 1. $$ For every leaf $f \\in T \\setminus T'$, $$ h_f(T) = h_{p(f)}(T) + 1. $$\n\nFor the first claim, consider $T$ rooted at a non-leaf $v$. The height of $T$ is the length of the maximal root-to-leaf path. Every such path gets shortened by one in $T'$, implying that $h_v(T) = h_v(T') + 1$.\n\nFor the second claim, let $x$ be a leaf farthest away from $p(f)$. We can assuming that $x \\neq f$ since $p(f)$ has at least two neighbors, and $f$ is at minimal distance from $p(f)$. Clearly $d(f,x) = d(p(f),x) + 1$, and so $h_f(T) \\geq h_{p(f)}(T) + 1$. The other direction follows from the triangle inequality, which implies that $d(f,y) \\leq d(p(f),y) + 1$ for all nodes $y$.\n\nThe algorithm. If $T$ contains one or two vertices, then clearly all vertices are centers (roots of minimum height trees). Otherwise, by the second claim, no leaf can be a center, and so by the first claim, the centers of $T$ are the same as the centers of $T'$. This suggests the following algorithm for computing the centers of $T$:\n\n  1. While $T$ contains at least three vertices, remove all leaves of $T$.\n  2. Once $T$ contains one or two vertices, return all vertices of $T$.\n\nThe correctness of the algorithm follows the reasoning stated above.\n\n  \u2022 $\\begingroup$ Beautiful explanation. $\\endgroup$ \u2013\u00a0Anant May 11 at 1:58\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/296975/what-goes-wrong-if-we-add-a-mass-term-for-gauge-bosons-without-the-higgs-mechani\nText:\nQuestion: Why can't we add a mass term for the gauge bosons of a non-abelian gauge theory?\n\nIn an abelian gauge theory one can freely add a mass and, while this breaks gauge invariance, as long as the coupling current is conserved everything works fine (i.e., the scalar modes decouple and the theory is renormalisable).\n\nIn non-abelian gauge theories, it is often stated that the only way to introduce a mass term is through the Higgs mechanism. If we added a mass term without introducing the Higgs field, but the coupling current is still conserved, at what point would the theory break down? It seems to me that the scalar modes decouple as well, at least to tree level. I failed to push the calculation to one loop order, so maybe the theory breaks down here. Is this the most immediate source of problems, or is there any simpler observable which fails to be gauge invariant?\n\nOne would often hear that if we break gauge invariance the theory is no longer renormalisable. I may be too na\u00efve but it seems to me that a (gauge-fixed) massive gauge boson has a $\\mathcal O(p^{-2})$ propagator and therefore (as long as the current in the vertices is conserved) the theory is (power counting) renormalisable. Or is it?\n\nTo keep things focused, let us imagine that we wanted to give gluons mass, while keeping self-interactions and the coupling to matter (and ghosts) unchanged. Could this work without a Higgs?\n\nThere are many posts about that are asking similar things. For example,\n\n  \u2022 4\n    $\\begingroup$ Nothing goes wrong, just the theory becomes strongly coupled at $4\\pi m_V/g$ where $m_V$ is the mass and $g$ the gauge coupling. It is simple to see this because the longitudinal polarization grows with energy. In fact, by a gauge redefinition one can make this apparent reintroducing the eaten Goldstone bosons. In practice, the Higgs mechanism is there in any case, it's the Higgs particle that could be missing. The theory has a cutoff which is at most $4\\pi v$, where $v=m_V/g$ is the vev, as for any theory of Goldstone bosons that are derivatively coupled. The simplest UV completion adds h. $\\endgroup$ \u2013\u00a0TwoBs Dec 6 '16 at 16:05\n  \u2022 $\\begingroup$ @TwoBs thanks for the comment. What you describe is not really true for an abelian gauge theory: the longitudinal polarisations would grow, but in fact they cancel (because of current conservation) and therefore the S matrix elements don't grow with energy (massive QED is UV finite, and perturbatively unitary). But this seems to fail for non-abelian gauge theories. Why is a non-abelia gauge theory different than an abelian one? is it because, unlike QED, the longitudinal polarisations don't cancel (even if the current is conserved)? $\\endgroup$ \u2013\u00a0AccidentalFourierTransform Dec 6 '16 at 16:20\n  \u2022 $\\begingroup$ It's very simple to understand: for the abelian case the mass gives rise just a free kinetic term for the would be goldstone bosons, whereas for the non-abelian case it give rise to a non-trivial derivatively coupled interactions. The reason is because the coset structure of$U(1)\\rightarrow 0$ is a circle which is one-dimensional and hence there is no non trivial Riemann curvature, whereas for non-abelian cosets, e.g. $SU(2)\\rightarrow U(1)$, they have non trivial Riemann ( it's a sphere above). The longitudinal polarizations, that is the Goldstones, couple with coefficients given by Riemann. $\\endgroup$ \u2013\u00a0TwoBs Dec 6 '16 at 23:05\n  \u2022 $\\begingroup$ @TwoBs nice, thanks! (it would be nice of you to post an answer some day, whenever you have the time :-) ) $\\endgroup$ \u2013\u00a0AccidentalFourierTransform Dec 6 '16 at 23:18\n  \u2022 $\\begingroup$ I will try to post an actual answer, it's just hard to find the time to make one that is at once nice, short and accurate. $\\endgroup$ \u2013\u00a0TwoBs Dec 6 '16 at 23:41\n\nWhat a great question OP! I have good news and bad news. The good news is that this exact same question is asked and answered in Quantum Field Theory, by Itzykson & Zuber, section 12-5-2. The bad news is that the answer is\n\nIf you introduce mass terms in non-abelian gauge theories by hand, the theory is non-renormalisable.\n\nThis means that one is forced to introduce the Higgs mechanism (or variations thereof, such as the St\u00fcckelberg mechanism), which for some people is rather inelegant (and plagued by problems of naturalness, etc). Oh well, that's the way the cookie crumbles.\n\nLet me quote the first paragraph of the aforementioned section, so as to summarise the main point of the problem:\n\nIs a gauge theory where mass terms are introduced by hand renormalizable?\n\nIn electrodynamics, the situation is favorable. After separation of the gauge field into transverse and longitudinal components, the longitudinal part $k_\\mu k_\\nu/M^2$ which gives rise to the bad behavior in the propagator does not contribute to the $S$ matrix. This results from the noninteraction of longitudinal and transverse components and from the coupling of the field to a conserved current. In a nonabelian theory, none of these properties is satisfied. Longitudinal and transverse parts do interact, while the current to which the gauge field is coupled is not conserved. On the other hand, unexpected cancellations of divergences at the one-loop level make the theory look like renormalizable. This explains why it took some time to reach a consensus, namely, that the theory is not renormalizable. The way out of this unpleasant situation is to appeal to the mechanism of spontaneous symmetry breaking, to be explained in the next subsection.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/431164/distributing-distinguishable-particles-in-dinstinguishable-boxes-and-computing-c\nText:\nI have n distinguishable particles and m distinguishable boxes. If all particles are in the same box the system has an energy of -$\\epsilon$ in all the other cases the energy is 0.\n\nNow I want to compute the canonical partition function. The Helmhltoz energy and the entropy of the ground state.\n\nTo start with I would count the number of possibilities to put all particles in single boxes.\n\nThere are $n!$ ways to arrange n distinguishable particles. And I have m boxes. And last I have $m!$ ways to arrange the different boxes. Therefore I have $n!*m*m!$ possibilities. The next step is to compute all possibilities to distribute n distinguishable particles in m distinguishable boxes. To distribute n particles in m boxes I have $m^{n}$ possibilities for a single configuration. Then I can arrange each configuration in $n!$ ways and last I can arrange the boxes again in $m!$ different ways. Hence the number of remaining possibilities is\n\n$$ m^{n}*n!*m!-n!*m*m!. $$\n\nThis gives the partition function:\n\n$$ Z(m,n,T)=m^{n}*n!*m!-n!*m*m!+n!*m*m!*e^{\\beta*\\epsilon}=\\\\ m!*n!*m*(m^{n-1}-1+e^{\\beta\\epsilon}) $$\n\nSince constant factors in the partition function do not matter when computing averages since they cancel I can neglect the prefactor m!*n!*m The partition function is therefore $$ Z(m,n,T)=m^{n-1}-1+e^{\\beta\\epsilon} $$\n\nThe Hemholtz free energy is then: $$ F=-k_bT*log(m^{n-1}-1+e^{\\beta\\epsilon}) $$\n\nNow I am not sure if the counting I have done above is correct and the next thing is I am not completely sure how to compute the ground state entropy.\n\nThe entropy is defined as $S=-k_{b}\\sum_{i}p_{i}log(p_i)$ and for as single state it should be $S=-k_{b}*p*log(p)$. The probability for the ground state would then be:\n\n$$ p_{G}=\\frac{e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}} $$ and hence the entropy $$ S=-\\frac{k_b*e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}}*log\\left(\\frac{e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}}\\right) $$\n\nBut still I am not quite sure if this is correct especially with the counting I feel very insecure. Thanks for your help\n\n  \u2022 $\\begingroup$ I am not sure, but here is what I think could be the right way. I am not sure why you are bothered with arranging the boxes and particles after you have considered m^n possibilities. I think that this itself includes all possible arrangements of the particles and boxes. Rearranging the order in which you consider the boxes or particles should not create more microstates. Hence I think the partition function should be (m^(n) - m) + m * e^(beta * E) $\\endgroup$ \u2013\u00a0Hari Sep 28 '18 at 15:30\n  \u2022 $\\begingroup$ @Hari. Okay but what is the criterion for creating a new microstate I think this is the point I don't quite get. So what is the criterion to be a microstate? Because I thought since the particles are distinguishable and so are the boxes any arrangement of particles and boxes would create a new microstate. Is this wrong $\\endgroup$ \u2013\u00a0zodiac Sep 29 '18 at 10:09\n  \u2022 $\\begingroup$ Suppose there are 2 boxes (B1,B2) and 2 particles (P1, P2). The microstates will be : 1) B1 (P1,P2) B2 () ; 2) B1 () B2(P1,P2) ; 3) B1 (P1) B2(P2) ; 4) B1(P2) B2(P1). I think these are the only microstates, rearranging the order in which you write B1 and B2, in this case 5) B2(P1) B1(P2) or 6) B2(P2) B1(P1) are not microstates as they are physically the same as (4) and (3) respectively. $\\endgroup$ \u2013\u00a0Hari Sep 29 '18 at 18:33\n  \u2022 $\\begingroup$ Thank but I fear I still don't get it right I guess. I mean what you are saying sounds completely reasonable. But if 5) and 6) are the same as 4) and 3) does't this mean those states have a higher entropy since they have more realizations. $\\endgroup$ \u2013\u00a0zodiac Oct 1 '18 at 6:44\n  \u2022 $\\begingroup$ And also I can place the labeled particles in different orders to the boxes since they are distinguishable. Then for example your state 1) B1 (P1,P2) B2 () could also be written as 1')B1(P2,P1) , B2(). I mean for sure those states are physically indistinguishable but dont' they have a higher a priori probability since there are more possibilities to create those states. I am sorry for bothering you again. But this seems to be a very crucial point that I don't get. I think this is also shown on this wiki page. link: en.wikipedia.org/wiki/Microstate_(statistical_mechanics). $\\endgroup$ \u2013\u00a0zodiac Oct 1 '18 at 6:44\n\nBased on Harrys comments I would like to answer this question to close this thread. It does not matter in which order I put the labeled particles in to the boxes since there are no drawers in the boxes and hence in the end I am not able to differentiate between the order of the particles anymore. This means $B(1,2,3)$ is the same as B(2,1,3) because the balls are lose in this box and are able to roll around freely. The next thing is the boxes have labels this states that box one will always be box one no matter where it is put to on the shelf. Hence there is no need to take into account the permutations of the boxes. Therefore the canonical partition function is just\n\n$$ Z(n,m,T)=(m^{n}-m)+me^{\\beta\\epsilon} $$\n\nThe Helmholtz free energy $$ F(n,m,T)=-k_{B}T=log\\left( m^{n} - m + e^{\\beta\\epsilon} \\right) $$\n\nAnd the ground state probability and the entropy stay the same since one m factors out.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/23269/differential-equation-quite-weird-task\nText:\nI'm having some trouble while trying to understand one task.. The task is as follows:\n\n$$\\ddot{x}(t) + \\dot{x}(t) + 2x(t) = \\sin(\\omega t)$$ where $x(0) = 7, t\\geq 0$\n\nThe solution is in the following form:\n\n$$x(t) = f(t) + A\\sin(\\omega t + \\varphi)$$\n\nAnd the task is: find $\\omega$ so that $A$ is max.\n\nMy understanding of this is that $f(t)$ is the solution of the homogeneous differential equation and the rest is the special solution of the nonhomogeneous equation. Still that does not give me any clue about how to evaluate the relationship between $A$ and $\\omega$. Any clues?\n\n\nSince $f$ is the (generic) homogeneous solution, you can choose to set it equal to zero; then you just have the special solution $x(t) = A\\mathrm{sin}(\\omega t+\\phi)$. You should be able to find $\\ddot{x}(t)$ and $\\dot{x}(t)$, then plug them all into your core differential equation and see what it means for both sides to be equal - if you've done it right, this will give you the relation between $\\omega$ and $A$ that you're looking for.\n\n  \u2022 $\\begingroup$ Thank you. I'm certainly able to do that, but is it right to just \"choose the solution to be equal to 0\" ? What are the consequences? $\\endgroup$ \u2013\u00a0kubal5003 Feb 22 '11 at 20:36\n  \u2022 $\\begingroup$ kubal: if you plug in the generic form for $x(t)$ into the equation and then use the fact that $f(t)$ solves the homogeneous version of the equation, you'll find that it cancels right out and you're left with exactly the same terms that you would've had if you had chosen $f(t)$ to be $0$ to begin with. $\\endgroup$ \u2013\u00a0Steven Stadnicki Feb 22 '11 at 21:37\n  \u2022 $\\begingroup$ I guess I'll have to do that in order to prove that the solution is not just a special case. This might appear on tommorows exam (I hope not) $\\endgroup$ \u2013\u00a0kubal5003 Feb 22 '11 at 22:12\n\nThe correct value of $\\omega$ is not $\\frac{\\sqrt{7}}{2} \\approx 1.32$. It's $\\sqrt{\\frac{3}{2}} \\approx 1.22$. We are looking for a near resonance effect, but you can't actually have resonance when the harmonic oscillator is damped. This makes the analysis is a little different.\n\nA reference is the section on sinusoidal forcing in the Wikipedia page on the harmonic oscillator. From the formulas there you can see that the relationship between $A$ and $\\omega$ is given by\n\n$$A = \\frac{1}{\\sqrt{\\omega^2 + (2 - \\omega^2)^2}}.$$\n\nSolving $\\frac{dA}{d \\omega} = 0$ yields $\\omega = \\sqrt{\\frac{3}{2}}$.\n\nUpdate: Here's the derivation.\n\nThe trick is to generalize, and solve the differential equation $x'' + x' + 2x = e^{i \\omega t}$. The resulting solution will have a real part and an imaginary part. Since $e^{i \\omega t} = \\cos \\omega t + i \\sin \\omega t$, you actually want the imaginary part of the solution.\n\nAs the driving force is an exponential, we know that the particular solution must be of the form $x_p(t) = c e^{i \\omega t}$. Subbing that into the differential equation produces the auxiliary equation $-c \\omega^2 + i c\\omega + 2c = 1$. Solving that for $c$ yields $$c = \\frac{1}{a + i b} = \\frac{a - i b}{a^2 + b^2},$$ where $a = 2 - \\omega^2$ and $b = \\omega$. Thus the particular solution to the complex differential equation is $$x_p(t) = \\frac{a - i b}{a^2 + b^2} (\\cos \\omega t + i \\sin \\omega t),$$ of which the imaginary part is $$-\\frac{b}{a^2 + b^2} \\cos \\omega t + \\frac{a}{a^2+b^2} \\sin \\omega t.$$ Since $A$ is just the magnitude of this solution (you're doing a rotation to the vertical axis when converting to $A \\sin (\\omega t + \\phi)$), we get $$A = \\frac{1}{\\sqrt{a^2+b^2}} = \\frac{1}{\\sqrt{\\omega^2 + (2 - \\omega^2)^2}}.$$\n\n  \u2022 $\\begingroup$ You could also get this by assuming a solution of the form $c_1 \\cos \\omega t + c_2 \\sin \\omega t$. Once you find $c_1$ and $c_2$ in terms of $\\omega$, you'll have $A = \\sqrt{c_1^2 + c_2^2}$. I like the solution with the complex exponential, though; it seems more intuitive to me. $\\endgroup$ \u2013\u00a0Mike Spivey Feb 23 '11 at 3:37\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/128614/probabilities-of-a-random-walk-exiting-a-set\nText:\nLet $F$ be a finite connected set in a graph (soon to be the Cayley graph of a group) and $\\mathrm{Ex}_x^F$ be the function on the vertices in $F^c$ which are neighbour to vertices in $F$ defined as follow $\\mathrm{Ex}_x^F(y)$ is the probability that the first time a random walker starting at $x$ exits $F$ is through $y$. To make sure this is defined, suppose the graph is transient.\n\n$\\textbf{Question}$: Assume the (transient) graph is the Cayley graph of an amenable group (for some finite generating set). Let $s$ be a neighbour of $e$. Does there exist a sequence of finite connected sets (containing $e$ and $s$) $\\{F_i\\}$ so that $\\mathrm{Ex}_e^{F_i}(y) - \\mathrm{Ex}_s^{F_i}(y) \\overset{i}{\\to} 0$ in $\\ell^1$ norm?\n\nThe hypothesis about amenability is motivated by\n\n  \u2022 the above is clearly false in the free group and most probably false in any hyperbolic group.\n  \u2022 its more plausible as the Cayley graph of amenable groups (by Kesten) are those where $P^{(n)}(e,e)^{1/n} \\to 1$, i.e. they tend to return \"often\" to where they were. Thus the random walks have bigger chance to \"fuse\", i.e. if a random walker starting at $s$, is at some time where the random walker starting at $e$ was, then the exit probabilities will be the same.\n  \u2022 1\n    $\\begingroup$ Why is it clearly false on the free group? $\\endgroup$ \u2013\u00a0Mikael de la Salle Apr 25 '13 at 8:11\n  \u2022 1\n    $\\begingroup$ I discussed your question with Vincent Beffara. We arrived at the conclusion that your question has a positive answer (for every pair (s,e)) if and only if your graph is Liouville. In particular, the lamplighter group on $\\mathbb{Z}^3$ gives a negative answer to your question. Vincent should soon write more on this as an answer. $\\endgroup$ \u2013\u00a0Mikael de la Salle Apr 25 '13 at 12:59\n  \u2022 $\\begingroup$ Thanks for the comment (and Vincent's answer). Without knowing this is equivalent to trivial Poisson boundary, on the free group (which is a tree), the intuition is that the walk is \"ballistic\", i.e. does not really come back. Since it will with relatively small probability cross the separating edge at the beginning, there is no reason that the exit probabilities will be small. With more effort, one can actually compute these exit probabilities. $\\endgroup$ \u2013\u00a0ARG Apr 26 '13 at 10:17\n\nSay that a graph $G$ has the Liouville property if all bounded (discrete-)harmonic functions on it are constant.\n\n  \u2022 If it is possible to couple random walks on $G$ started from any two starting points in such a way that they almost surely coincide after some (random) time, then the graph is Liouville. The reason for that is that one can write the value of a bounded harmonic function $f$ at $x$ as the expected value of $f(X_t)$ where $X$ is a random walk on $G$ and $t$ is any stopping time; it random walks from $x$ and $y$ couple with high probability by time $t$ this gives an upper bound on $|f(x)-f(y)|$ which shows that $f$ has to be constant.\n\n  \u2022 If your graph admits non-constant bounded harmonic functions, then the TV distance between harmonic measures from $e$ and $s$ (which is another way of naming what you are interested in) cannot go to $0$ for all pairs $(e,s)$. Indeed, if $f$ is a non-constant bounded harmonic function and $f(e) \\neq f(s)$, then writing $f$ as the expected exit value one gets a lower bound on the TV distance in terms of $|f(e)-f(s)|$.\n\n  \u2022 On the other hand, assume that the $\\ell^1$ norm you are interested in does not go to $0$. It means that there exists a sequence $g_i$ of functions bounded by $1$ in absolute value, each defined on $F_i^c$ and such that the integrals of $g_i$ through your two exit distributions differ by at least some $\\delta>0$. Taking the harmonic extension $f_i$ of $g_i$ inside $F_i$ one gets $|f_i(s) - f_i(e)| \\geq \\delta$. Letting $i$ go to infinity and using a diagonal argument one gets a bounded harmonic function $f$ defined on the union of the $F_i$ (which I am assuming to be the whole graph?) and such that $|f(s)-f(e)|>0$, i.e. it is non-constant.\n\nSo, the answer to your question is positive iff the graph is Liouville. Now for the link with amenability: it is not true that every amenable group is Liouville, and a counterexample is given by the lamplighter group on $Z^3$ (or on any transient amenable group for that mattter). One natural non-constant harmonic function is the following: given any $(\\omega,x)$ on the LL, where $\\omega$ is the lamp configuration and $x$ the location of the walker, define $f((\\omega,x))$ to be the probability, for a random walk $(\\omega_t,x_t)$ started there, that the lamp at the origin $\\omega_t(0)$ is eventually on. Note that the state of that lamp changes only finitely many times because the underlying random walk is transient.\n\nThis function is clearly harmonic and bounded. To see that it is non-constant, just take $x$ very large: the probability that $x_t$ ever visits the origin will be very small, so with high probability the eventual state of the lamp at the origin will be the same as its state at time $0$, ie its state on $\\omega$: $f((\\omega,x))-\\omega(0) = o_{x\\to\\infty}(1)$. So some places $f$ will be close to $0$ and some places it will be close to $1$.\n\n  \u2022 $\\begingroup$ @Vincent That's a nice example. What about the converse: is every Liouville group amenable? $\\endgroup$ \u2013\u00a0Sean Eberhard Apr 26 '13 at 10:09\n  \u2022 $\\begingroup$ Thankd for this nice and detailed answer! I really did not expect an \"iff\"... $\\endgroup$ \u2013\u00a0ARG Apr 26 '13 at 10:11\n  \u2022 $\\begingroup$ @Sean: the answer is yes (a result of Kaimanovich, I believe, the expert will confirm/infirm). Actually, the proper formulation is that an amenable group always has a measure for which the RW has trivial Poisson boundary, but in the case of wreath products, this measure is never finitely supported (results of Erschler? again, my memory is vague). $\\endgroup$ \u2013\u00a0ARG Apr 26 '13 at 10:22\n  \u2022 $\\begingroup$ @Vincent: In the example of harmonic function you give, are you somehow describing the space of \"limiting configuration\"? I've seen reference for this but cannot access the paper of Erschler where she describes them. $\\endgroup$ \u2013\u00a0ARG Apr 26 '13 at 10:25\n  \u2022 3\n    $\\begingroup$ @Antoine: the fact that the Cayley graphs of non-amenable groups is non-Liouville is due to Furstenberg (at least according to Erschler). The converse (amenable groups carry a Liouville random walk) is due to Kaimanovich-Vershik and Rosenblatt. This is explained in ams.org/mathscinet-getitem?mr=2025301 $\\endgroup$ \u2013\u00a0Mikael de la Salle Apr 26 '13 at 11:44\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/42930/what-is-the-expected-value-of-the-number-of-die-rolls-necessary-to-get-a-specifi\nText:\nGiven a discrete random number generator, such as a six-sided die, what is the expected value of the number of rolls necessary to roll a specific number (e.g. a six)?\n\nI think the result should be given by E$\\langle$rolls$\\rangle$ = $\\frac{1}{6}\\sum_{n=0}^\\infty{(\\frac{5}{6})^n(n+1)}$, but I don't know how to calculate the convergence of that sum.\n\nAlso, how do I calculate the variance?\n\n\nA slightly simpler recursive derivation is this. We must roll the die at least once. On the first roll we get a 6 with probability $\\frac{1}{6}$. Otherwise we start again. Hence, $E = 1 + \\frac{5}{6}E$, which gives $E=6$.\n\nHere is a more general answer:\n\nRegard rolling the die as a Bernoulli process $X_1,X_2, \\ldots$, where $X_i = $ Success, with probability $p$, and $X_i = $ Failure, with probability $1-p$. The process stops after the first success.\n\nLet $N_s$ be the length of the sequence until the first Success. This is a random integer. Then we have $$ \\Pr (N_s=k) = \\Pr(\\underbrace{FF\\cdots F}_{k-1}\\ S) = \\underbrace{(1-p)(1-p)\\cdots(1-p)}_{k-1}\\ p=(1-p)^{k-1}p=pq^{k-1}, $$ where $q=1-p$ and $k\\ge1$. This is called a Geometric Distribution, which is the discrete equivalent of the Exponential Distribution. Random variables with these distributions are called memoryless. (See Ross, Introduction to Probability Models, 9th Edition, page 284.)\n\nThe expected value and variance of $N_s \\sim \\text{Geom}(p)$ are $$ \\text{E}{N_s(p)}=\\frac{1}{p}, \\text{ and } \\text{Var}{N_s(p)} = \\frac{1-p}{p^2}. $$Proof can be found in Ross, above. Note that $$\\text{E}{N_s(p)} = 1 +(1-p)\\text{E}{N_s(p)}, \\text{ whose solution is } \\frac{1}{p}.$$\n\nIn your case $p = \\frac{1}{6}\\,$ and so E(No. rolls) = 6, and Var(No. rolls) = 30 -- Geom$(\\frac{1}{6})$ has a long tail.\n\n\nOne \"trick\" that often lets you avoid issues of convergence when solving probability problems is to use a recursive argument.\n\nYou have a 1/6 probability of rolling a 6 right away, and a 5/6 chance of rolling something else and starting the process over (but with one additional roll under your belt).\n\nLet $E$ be the expected number of rolls before getting a 6; by the reasoning above, we have:\n\n$E = (1)(1/6) + (E + 1)(5/6)$\n\nSolving for $E$ yields $E = 6$.\n\nAn alternative approach is to use the generating function. The generating function $G(t)$ for a probability distribution that only takes on integer values is defined as:\n\n$G(t) = \\Sigma_{i = 0}^{\\infty} p_i t^i$\n\nThe reason the generating function comes in handy is that $G'(1)$ gives the expected value and $G''(1) + G'(1) - (G'(1))^2$ gives the variance; one can check this directly.\n\nIn our case, the generating function is:\n\n$G(t) = (1/6)t + (1/6)(5/6)t^2 + (1/6)(5/6)^2t^3 + \\ldots$\n\nWe can rewrite this as follows:\n\n$G(t) = (1/5)(5t/6 + (5t/6)^2 + (5t/6)^3 + \\ldots)$\n\nSumming the geometric series gives $G(t) = t/(6-5t)$; from here, we can calculate $G'(t)$ and $G''(t)$, plug in $t = 1$, and use the above expressions to extract both the expected value and the variance (6 and 30, respectively).\n\n\nElliott's answer is surely the nicest. To sum the series, we can use a method similar to the geometric series.\n\nLet $$S = 1 + 2 \\cdot \\left(\\frac{5}{6}\\right) + 3 \\cdot \\left(\\frac{5}{6}\\right)^2 + \\cdots $$\n\n\n$$\\frac{5}{6}S = \\frac{5}{6} + 2 \\cdot \\left(\\frac{5}{6}\\right)^2 + 3 \\cdot \\left(\\frac{5}{6}\\right)^3 + \\cdots $$\n\n$$S - \\frac{5}{6}S = 1+ \\left(\\frac{5}{6}\\right) +\\left(\\frac{5}{6}\\right)^2 + \\cdots $$\n\nThis is just a geometric series and hence we have that\n\n$$S = 36$$\n\nNow we have that $$\\frac{1}{6} \\sum_{n=0}^\\infty \\left(\\frac{5}{6}\\right)^n (n+1) = \\frac{1}{6} \\cdot S = 6,$$ as expected.\n\n(Convergence of the series can be seen by the ratio test)\n\n  \u2022 $\\begingroup$ Very nice. It's great to see so many different ways to find the convergence value for power series. $\\endgroup$ \u2013\u00a0jeremy radcliff Jan 25 '17 at 21:12\n\nHere's an intuitive argument. Roll the die $6000$ times. You'd expect there to be $1000$ 6's among them. Consider the gaps between successive 6's in the list (plus the initial gap to the first 6). These lengths are the values of independent draws from a geometric RV with $p=1/6$, so the average gap length is the expected value you want.\n\nThe sum of these (~1000) gap lengths is 6000, and so the average gap is $6000/1000=6$ (modulo a little fudge at the end which would go to $0$ by making the string longer).\n\n\nI'm late to the party, but here's a slightly different path to the same solution. Let $X$ be the number of die rolls until we roll a specific number. Let $p$ be the probability that we roll the specific number and $q = 1-p$ be the probability that we roll any of the other numbers. We know\n\n$$ \\mathbb{E}[X] \\triangleq 1p + 2qp + 3q^2 p + 4q^3p + \\dots $$\n\nNote that the geometric series $\\sum_{x=1}^{\\infty} q^x = \\frac{q}{1-q}$. Using this fact and a little algebra and calculus, we get,\n\n$$ \\begin{align} \\mathbb{E}[X] &= 1p + 2qp + 3q^2 p + 4q^3p + \\dots \\\\ &= \\sum_{x = 0}^{\\infty} (x + 1) q^x p \\\\ &= \\sum_{x = 1}^{\\infty} x q^{x-1} p \\\\ &= \\sum_{x = 1}^{\\infty} \\frac{\\partial}{\\partial q} q^x p \\\\ &= p \\frac{\\partial}{\\partial q} \\Big( \\sum_{x = 1}^{\\infty} q^x \\Big) \\\\ &= p \\frac{\\partial}{\\partial q} \\Big( \\frac{q}{1-q} \\Big) \\\\ &= p \\frac{1}{(1 - q)^2} \\\\ &= \\frac{\\frac{1}{6}}{\\big(1 - \\frac{5}{6}\\big)^2} \\\\ &= 6 \\end{align} $$\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/35308/running-a-command-in-term-from-eshell-with-arguments\nText:\nBasically I want to run watch from eshell.\n\nSimply running watch date (for example) doesn't work (only the first header line is displayed). Apparently I should run it with term or ansi-term but these two commands take only one argument -the command, which would be watch - and I don't know where to put the arguments (i.e. date in the example above).\n\nSo, I guess my question is: What is the proper way to run watch date (or any other watch such as watch \"make myprog && ./myprog\") from eshell?\n\n\nInteresting question. I found a non-trivial answer. Looking at functions term and ansi-term, I saw that though they themselves only take one program-related argument, under the hood they both invoke functions that allow passing additional arguments to programs (make-term and term-ansi-make-term respectively). This gave me an idea about how to accomplish what you want:\n\n  \u2022 for term: (switch-to-buffer (make-term \"test-term\" \"/bin/bash\" nil \"-c\" \"watch date\"))\n  \u2022 for ansi-term: (switch-to-buffer (term-ansi-make-term \"test-ansi\" \"/bin/bash\" nil \"-c\" \"watch date\"))\n\nIt's a bit unwieldy in that form, so you might want to write a function abstracting this:\n\n(defun eshell/watch-process (process)\n                   nil \"-c\" (format \"watch %s\" process))))\n\nAnd then you can run watch-process date directly in Eshell.\n\n\nThe Eshell documentation refers to commands that are not line-oriented but are designed to run in a terminal, such as watch, as \"visual commands\". To tell Eshell that a command is a visual command, add its name to the list in the eshell-visual-commands variable as follows:\n\n(push \"watch\" eshell-visual-commands)\n\nThenceforth Eshell will automatically run watch in a term buffer.\n\nSee Input/Output in the Eshell manual.\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/4887/dijkstra-to-favor-solution-with-smallest-number-of-edges-if-several-paths-have-s\nText:\nYou can modify any graph $G$ so that Dijkstra's finds the solution with the minimal number of edges thusly:\n\nMultiply every edge weight with a number $a$, then add $1$ to the weight to penalize each additional edge in the solution, i.e.\n\n\nThis does not work for all values of $a$; $a$ needs to be at least $x$ for this to work. If $a$ is not this minimum number, it might not choose the shortest path. How do I find this minimum value $x$?\n\nPs. This was done recreationally, I'm done with homework long ago.\n\n  \u2022 $\\begingroup$ If two paths have an equal weight, the one with the fewest edges should be chosen. Sorry. I see that I did not make that clear. $\\endgroup$ \u2013\u00a0The Unfun Cat Oct 5 '12 at 19:16\n  \u2022 $\\begingroup$ You could also do it by adding $\\epsilon$ to all edge weights, where $\\epsilon < m/e$, m = minimum edge weight, e = number of edges in shortest path (or even overall, if you don't know the shortest path length). $\\endgroup$ \u2013\u00a0BlueRaja - Danny Pflughoeft Oct 5 '12 at 20:04\n  \u2022 $\\begingroup$ Interesting tidbit, thanks. Will have to look at it. $\\endgroup$ \u2013\u00a0The Unfun Cat Oct 5 '12 at 20:05\n\nGiven a graph $G = (V,E,w)$, we define $G'=(V,E,w')$ with $w'(e) = aw(e) + 1$ where $a = |E| + \\varepsilon$ for some $\\varepsilon \\geq 0$ as proposed in the comments of the question.\n\nLet $P$ a path in $G$ with cost $C$, i.e. $w(P)=C$. Then, $P$ has cost $aC + |P|$ in $G'$, i.e. $w'(P) = aC + |P|$.\n\nThe lemma follows directly from the definition of $w'$.\n\nCall the result of Dijkstra on $G'$ $P$, which is a shortest path in $G'$. Assume $P$ was not a shortest path with fewest edges (among all shortest paths) in $G$. This can happen in one of two ways.\n\n  1. $P$ is not a shortest path in $G$.\n    Then, there is a path $P'$ with $w(P') < w(P)$. As $|P|,|P'| \\leq |E| \\leq a$, this implies that also $w'(P') < w'(P)$ with above lemma\u00b9. This contradicts that $P$ was chosen as shortest path in $G'$.\n  2. $P$ is a shortest path but there is a shortest path with fewer edges.\n    Then, there is another shortest path $P'$ -- i.e. $w(P) = w(P')$ -- with $|P'| < |P|$. This implies that $w'(P') < w'(P)$ by above lemma, which again contradicts that $P$ is a shortest path in $G'$.\n\nAs both cases have led to a contradiction, $P$ is indeed a shortest path with fewest edges in $G$.\n\nThat covers one half of the proposition. What about $a < |E|$, i.e. $a = |E| - \\varepsilon$ with $\\varepsilon \\in (0,|E|)$?\n\n  1. Actually, we also need that $a$ or all weights in $G$ are integers. Otherwise, $w(P') < w(P)$ does not cause the weights in $G'$ to be at least $|E|$ apart. This is not a restriction, though; we can always scale $w$ with a constant factor so that all weights are integer, assuming we start with rational weights.\n  \u2022 $\\begingroup$ I haven't yet been able to come up with a proof that $a = |E|$ is the smallest $a$ for which this works. I'll give it some more thought. $\\endgroup$ \u2013\u00a0Raphael Oct 7 '12 at 22:17\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/189703/symbolic-integral\nText:\nI am in trouble with the following integral:\n\n$$rtartaruga(r)=\\int \\frac{\\Sigma(r') }{\\Delta(r') \\sqrt{\\Delta th}} d r'$$ Where: $$\\Delta(r) =\\left(a^2+r^2\\right) \\left(\\frac{r^2}{l^2}+1\\right)-2 m r$$ $$\\Sigma(r) =\\sqrt{\\text{$\\Delta $th} \\left(a^2+r^2\\right)^2-a^2 \\Delta \\sin ^2(\\theta )}$$ And $\\Delta th$ is a constant in $r$: $\\text{$\\Delta $th}=1-\\frac{a^2 \\cos ^2(\\theta )}{l^2}$.\n\nIn the following region of parameters: $|a|<l$ and $m>m_c$ (where $m_c$ is a certain positive constant $\\Delta (r)$ has two positive roots and the integrand is divergent in these points.\n\nI would really like to have an analytical solution for the above integral so i try to evaluate it symbolically:\n\n\\[CapitalSigma] = \n  Sqrt[(r^2 + a^2)^2 \\[CapitalDelta]th - \n    a^2 \\[CapitalDelta] Sin[\\[Theta]]^2];\n\n\\[CapitalDelta] = (r^2 + a^2) (1 + r^2/l^2) - 2 m r;\n\n\\[CapitalDelta]th = 1 - a^2/l^2 Cos[\\[Theta]]^2;\n\n mc = l/(3 Sqrt[6]) (Sqrt[(1 + a^2/l^2) + 12/l^2 a^2] + 2 a^2/l^2 + 2)*\n   Sqrt[(Sqrt[(1 + a^2/l^2) + 12/l^2 a^2] - a^2/l^2 - 1)];\n\n\n rtartaruga[r_] = \n  r, Assumptions -> {{r, m, \\[Theta], a, l} \\[Element] Reals, \n    Abs[a] < l, m > mc, r > 0, l > 0, \\[Theta] >= 0, \\[Theta] <= Pi}, \n  PrincipalValue -> True]\n\nThe output is a very long one and includes special functions. When i try to evaluate it at some point:\n\na = 1/2;\nl = 2;\nm = 1;\n\\[Theta] = Pi/4;\nClear[a, l, m, \\[Theta]]  \n\nI get:\n\n-0.274199 - 0.47465 I\n\nBut the result has to be real as the integrand!\n\nI know that there are other similar questions on this issue, and i understand that the problem is about branch cuts on the complex plane, but practically i can't find a way to get out my problem (if it's possible).\n\nMay someone help me please?\n\nThanks in advance!\n\n  \u2022 $\\begingroup$ If I am reading this correctly, it is an antiderivative as opposed to a definite integral. So the result need not be real valued. Also the two options being given will be ignored (possibly the Assumptions will have a minor effect, I'm not absolutely certain about that one). $\\endgroup$ \u2013\u00a0Daniel Lichtblau Jan 17 at 19:02\n  \u2022 $\\begingroup$ Hi! First of all thank you for your reply.The indefinite integral of a real function could has a constant imaginary part, right? The problem is that this is not my case:ln[81]:= a = 1/2; l = 2; m = 1; [Theta] = Pi/4; N[rtartaruga[[0.4], 10] N[rtartaruga[[0.7], 10] N[rtartaruga[[5], 10] N[rtartaruga[[10], 10] N[rtartaruga[20], 10] Clear[a, l, m, [Theta]] Out[85]= -0.274199 - 0.47465 I Out[86]= -0.166399 - 0.492226 I Out[87]= 4.822826746 + 3.423249825 I Out[88]= -2.238523542 + 0.*10^-10 I Out[89]= -2.045605814 + 0.*10^-10 I $\\endgroup$ \u2013\u00a0SuperBaba Jan 18 at 10:25\n  \u2022 $\\begingroup$ Due to branch cuts it could be piecewise constant actually. $\\endgroup$ \u2013\u00a0Daniel Lichtblau Jan 18 at 16:50\n  \u2022 $\\begingroup$ Thank you very much, now it's all clear to me! $\\endgroup$ \u2013\u00a0SuperBaba Jan 26 at 13:57\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/98596/check-if-two-items-are-equal-after-replacing\nText:\nLet's say that an item is either a natural number or a list of items. Examples of items are:\n\n  \u2022 1\n  \u2022 [2]\n  \u2022 [4, [3, 1], 3, 4]\n\nA rule states that two items are equal. For example:\n\n  \u2022 1 = 2\n  \u2022 3 = [3, 1]\n  \u2022 [4, 3] = [1, 5]\n\nWhen using these example rules, we can transform [4, [3, 2]] into [4, [3, 1]] into [4, 3] into [1, 5] and we can say that [4, [3, 2]] equals [1, 5].\n\nI want to find an algorithm that, given items $a$ and $b$ and a finite set of rules, determines if $a = b$.\n\nI already thought of an algorithm that works in some cases. But I hope to find an efficient algorithm that works in all cases. It would also be nice if the algorithm can detect $a \\not= b$ instead of infinitely searching for ways to let $a = b$. Is this a known problem? Any help is appreciated.\n\nNote: We can simplify the problem by only allowing the number 1 instead of every natural number. This is equivalent, because we can transform 1 into [1], 2 into [1, 1], 3 into [1, 1, 1], etcetera.\n\n  \u2022 1\n    $\\begingroup$ This looks like the decision problem for the theory of equality with uninterpreted functions, from smt (arrays here being function calls). However, I don't know of any nice explanation of how to solve it quickly, beyond using Union Find. $\\endgroup$ \u2013\u00a0Curtis F Oct 15 '18 at 1:25\n  \u2022 1\n    $\\begingroup$ @CurtisF The underlying problem is about function calls. I thought this would be an easier way to display the problem. $\\endgroup$ \u2013\u00a0Paul Oct 15 '18 at 2:15\n  \u2022 $\\begingroup$ @Paul, if this question comes from a book or a paper, can you add a reference? If it comes back your personal thinking, any background or motivation? It would be great for you to add those information in the question, which should motivate and help people to tackle this question more and better. $\\endgroup$ \u2013\u00a0Apass.Jack Oct 23 '18 at 3:29\n\nI found a solution to my problem. Let's look at the simpler but equivalent problem in which an item is recursively defined as an empty list or a list of items. I'll summarize the algorithm.\n\n\n  \u2022 Int counter starting at 0\n  \u2022 Hash map: list of integers $\\to$ integer. The integers represent equivalence classes.\n\nFunction find(item) $\\to$ int:\n\nFinds the equivalence class of an item. Recursively call find on all the children of item. Now you have a list of ints. If this list of ints is contained in the hash map, return the corresponding value. If not, add the list to the hash map with the counter as value. Increase the counter and return the value.\n\nFunction merge(int a, int b):\n\nMerges two equivalence classes a and b. In the hash map, replace all occurences (both in keys and in values) of a by b. Now it can happen that one key is mapped to multiple values. If that happens, again merge those values. Repeat this until every key maps to a unique value.\n\n\nFor every rule c = d, call merge(find(c), find(d)). Then to see if a = b, check if find(a) = find(b).\n\n  \u2022 2\n    $\\begingroup$ \"Finds the equivalence class of an item\". There are infinitely many elements in an equivalence class. $3 =[3, 1] = [[3,1],1] = [[[3,1],1]]=\\cdots$. Have you handled them all? $\\endgroup$ \u2013\u00a0Apass.Jack Oct 23 '18 at 23:28\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/202755/independent-permutation-symmetry-of-a-tensor-using-tensorsymmetry-command\nText:\nSuppose I have this tensor $A_{ijkl} = \\epsilon_{ik} \\epsilon_{jl}+\\epsilon_{il} \\epsilon_{jk}$. Now I want to find all the independent permutation symmetries of the indices of this tensor. The answer is $(ij)$,$(kl)$,$(ik)(jl)$, where by $(ij)$ I mean the tensor is symmetric under the permutation of $i,j$. Similarly $(ik)(jl)$ represents the multiplication of two disjoint cycles.\n\nI am very new to computation and I want to implement this in Mathematica. Here's what I tried:\n\nss = TensorProduct[LeviCivitaTensor[2], LeviCivitaTensor[2]]; A = ss + TensorTranspose[ss, {Cycles[{{2, 4}}], 1}]; TensorSymmetry[A] \n\nThis yields the result:\n\n{{Cycles[{{2, 4}}], 1}, {Cycles[{{1, 2}, {3, 4}}], 1}, {Cycles[{{1, 2, 3, 4}}], 1}}\n\nWhich when translated back into my notation reads $(kl)$, $ (ik) (jl) $ and $(ikjl)$, but we can see that the results are not simplified. For example we can use $ (ik) (jl) $ to simplify $(ikjl)$ as follows:\n\n$ (ikjl) = (ikj) (jl) = (jik) (jl) = (ji) (ik) (jl)$\n\nSo $(ijkl)$ when used with $(ik)(jl)$ reduces to $(ij) \\equiv (ji)$ as wanted. I want to do this simplification using Mathematica, in other words I want Mathematica to use all the cycles in the list to reduce it to a simplified and independent one. Could someone please help me to implement this? Thanks in advance. On a side note I find manipulating symbolic tensors in Mathematica very difficult. Suggestion for packages that helps this kind of calculation is much appreciated. I know there exists packages like Ricci which are dedicated for GR related calculations, I want something more simple and accessible for tensor analysis.\n\n\nI don't think your TensorProduct expression agrees with your notation. If you correct the definition of A you get your desired symmetries:\n\nA = TensorTranspose[TensorProduct[LeviCivitaTensor[2],LeviCivitaTensor[2]],{1,3,2,4}] + \n\n\n{{Cycles[{{3, 4}}], 1}, {Cycles[{{1, 2}}], 1}, {Cycles[{{1, 3}, {2, 4}}], 1}}\n\n  \u2022 $\\begingroup$ Thank you for your answer, but if we take a more complicated example Mathematica does not simplify as pointed out, for example take 3 epsilon tensor direct product ordered as {1,2,3,4,5,6}. Mathematica gives you as one of the Tensor symmetries this: (135)(246), which using others could be simplified to (15)(26). $\\endgroup$ \u2013\u00a0Sudhakantha Girmohanta Jul 27 at 3:54\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/56323/baire-category-theorem-application\nText:\nIn Antoine Henrot Michel Pierre - Variation et optimisation de formes, Une analyse geometrique, a book I'm studying I found an interesting problem. The problem is listed below. The first 3 points of the problem are pretty easy, and I solved them. The 4-th seems a little harder. The only indication I get is to use point 3) and the Baire theorem for $(\\Sigma,\\delta)$.\n\nDenote by $\\Sigma$ the quotient space of the family of Lebesgue measurable sets of $\\Bbb{R}^N$ by the equivalence relation $E_1 \\sim E_2 \\Leftrightarrow\\chi_{E_1}=\\chi_{E_2} a.e.$. Denote by $|X|$ the Lebesgue measure of the measurable set $X$.\n\n1) Prove that $\\delta(E_1,E_2)=\\arctan( |E_1 \\Delta E_2|)$ is a distance on $\\Sigma$.\n\n2) Prove that given $(E_n)_{n \\geq 1}, E$ measurable sets in $\\Bbb{R}^N$ the following three properties are equivalent.\n\n  \u2022 $\\delta(E_n,E) \\to 0$;\n\n  \u2022 $\\chi_{E_n}-\\chi_E \\xrightarrow{\\sigma(L^1,L^\\infty)} 0$;\n\n  \u2022 $\\chi_{E_n}-\\chi_E \\xrightarrow{L^1} 0$.\n\n3) Prove that $(\\Sigma,\\delta)$ is a complete metric space.\n\n4) Given the sequence $ (f_n)$ of integrable real valued functions on $\\Bbb{R}^N$, such that for any measurable set $E$ of $\\Bbb{R}^N$ there exists $\\displaystyle \\lim_{n\\to \\infty}\\int_E f_n$, prove that if $|E| \\to 0$ then $\\displaystyle\\sup_n\\int_E |f_n| \\to 0$. (Hint: Use the Baire category theorem for $(\\Sigma,\\delta)$)\n\nThe question is: How can I apply Baire theorem to solve the 4-th point in the problem?\n\n\nChoose $\\varepsilon > 0$ and consider sets defined by $$\\Sigma_k = \\{E:\\ \\left|\\int\\limits_{E} (f_n-f_m) \\right| \\leqslant \\varepsilon, \\textrm{ if } n,m \\geqslant k \\}$$ Since for any measurable set a limit of integrals exists, we have $\\Sigma = \\bigcup\\limits_{k} \\Sigma_k$. Note, that given an integrable function $f$, the functional $f(E):= \\int\\limits_{E}f$ is continuous respect to $E$ in metric $\\delta$. Indeed, $f(E)-f(F) = \\int f \\cdot ( 1_E - 1_F )$, hence $|f(E)-f(F)| \\leqslant \\int |f| \\cdot | 1_E - 1_F | = \\int |f| \\cdot 1_{E \\Delta F} = \\int\\limits_{E\\Delta F} |f|$.\n\nThe last expression tends to $0$ if $|E\\Delta F|$ tends to $0$ because of integrability of $f$, equivalently if $d(E,F)\\to 0$. This remark shows that sets $\\Sigma_k$ are closed as an intersection of closed subsets of the space $(\\Sigma,d)$.\n\nFrom Baire theorem we obtain that one of sets $\\Sigma_k$ has an interior point. Therefore, there exists a measurable set $E_0$ and integer $k$ such that the inequality $ |f_n(E)-f_m(E) | \\leqslant \\varepsilon$ holds, whenever $|E\\Delta E_0| \\leqslant \\delta$ and $m,n\\geqslant k$. We will show, that this inequality holds in fact for any set $E$, provided that its measure is sufficiency small.\n\nBy identities $\\mathbf{1}_{E\\cup E_0} - \\mathbf{1}_{E_0} = \\mathbf{1}_{E\\cap E_0^{c}}$ and $\\mathbf{1}_{E_0}-\\mathbf{1}_{E_0\\setminus E} = \\mathbf{1}_{E\\cap E_0}$ we obtain for an arbitrary integrable $f$ $$f(E) = f(E \\cap E_0^{c}) + f(E\\cap E_0) = f(E\\cup E_0) - f(E_0) + f(E_0) - f(E_0\\setminus E)$$ If $|E| < \\delta$, then all of sets $E_0,E_0\\cup E, E_0\\setminus E$, belong to the ball $\\{E:\\ |E\\Delta E_0| < \\delta \\}$. Applying the last inequality to $f_n-f_m$ and $|E| < \\delta$ we get $$ |f_n(E)-f_m(E)| \\leqslant 2\\varepsilon \\quad \\textrm { if } |E|<\\delta, \\ n,m\\geqslant k$$\n\nFinally, observe that the finite family of integrable functions $f_1,\\ldots, f_k$ is obviously locally uniformly integrable, i.e. $\\sup\\limits_{i\\leqslant k} |f_i(E)| \\to 0$ if $|E|\\to 0$. Therefore, for sufficiency small $\\delta'$ we have $$|f_i(E)|\\leqslant \\varepsilon \\quad \\textrm{ if } |E| < \\delta', i\\leqslant k$$\n\nGluing together two estimates that have been derived, we see that for some positive $\\delta$\n\n$$ \\left|\\int\\limits_{E} f_n\\right| \\leqslant 3\\varepsilon, \\quad \\textrm{ if } |E| \\leqslant \\delta$$\n\nWe have estimated integrals for functions $f_n$, instead their modulus. It doesn't matter, however. Namely, applying the last estimate to the set $E\\cap \\{f_n > 0\\}$ and $E\\cap \\{f_n < 0\\}$ respectively (both contained in $E$ hence with a smaller measure), gives finally\n\n$$ \\int\\limits_{E} |f_n| \\leqslant 6\\varepsilon, \\quad \\textrm{ if } |E| \\leqslant \\delta$$\n\nWhat finished the proof.\n\n  \u2022 $\\begingroup$ Very nice! $\\mbox{}$ $\\endgroup$ \u2013\u00a0Nate Eldredge Mar 14 '11 at 15:58\n  \u2022 $\\begingroup$ An interesting exercise :-) However, my professor told me, when I showed him this proof, that it is possible to give a short proof without the Baire theorem, using Schur property of the sequences space $l^{1}$ $\\endgroup$ \u2013\u00a0Maciej S. Mar 14 '11 at 17:03\n  \u2022 $\\begingroup$ Very beautiful proof. $\\endgroup$ \u2013\u00a0Beni Bogosel Mar 15 '11 at 6:04\n\nBy the way, in a posted solution we used only following properties of functionals $f(E)=\\int\\limits_{E} f$:\n\n  1. Continuous respect to $|E|$ (Lebesgue measure)\n  2. Additive (on disjoint sets)\n  3. Finite\n\nTherefore, our problem can be reformulated in a following way:\n\nSuppose, that $\\mu_n$ is a sequence of finite measures, absolutely continuous w.r.t. the Lebesgue measure. Then $\\sup\\limits_{n} \\ |\\mu_n|(E) \\to 0$ if $|E|\\to 0$.\n\nSo we have proved Vitali-Hahn-Saks theorem :-)\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1189169/find-a-branch-of-log-2z-1-that-is-analytic-at-all-points-in-the-plane\nText:\nFind a branch of $\\log (2z - 1)$ that is analytic at all points in the plane except those on the following rays\n\na) {$x + iy : x \\leq \\frac{1}{2}, y = 0$}\n\nDefinition: $F(z)$ is said to be a branch of a multiple valued function $f(z)$ in a domain $D$ if $F(z)$ is single valued and continuous in D and has the property that, for each $ z$ in $D$, the value $F(z)$ is one of the values of $f(z)$\n\nCan someone please help me start this problem? I don't how to start, and there are no examples in the book. I would really appreciate it . Thanks\n\n\nThe best idea is probably to substitute variables, and investigate what happens to the given ray after the substitution:\n\nLet, for example, $w=u+i\\cdot v=2z-1=2(x+i\\cdot y)-1$. Then we get that $z\\in \\mathbb{C}\\setminus(-\\infty,1/2]\\Leftrightarrow w\\in \\mathbb{C}\\setminus(-\\infty,0]$.\n\nNow, by definition, $\\log(w)=\\ln|w|+i\\cdot \\arg(w)$. Thus you should only investigate the argument. Basically, what we want to avoid is to have an argument branch that is continuous when $\\Re(w)=u<0$.\n\nLet us therefore create a branch for $\\arg$, which we will call $\\tilde\\arg$. We define this branch by $\\tilde\\arg(w):=\\theta(w)$, where $\\theta$ is a continuosly varying argument for $w$ on one of the intervals $(-\\pi+2n\\pi,\\pi+2n\\pi)$, $n\\in \\mathbb{Z}$. This means that $\\tilde\\arg(w)$ is continuous for all $w\\notin (-\\infty,0]$.\n\nThus, we define the suitable branch of $\\log$ with $\\tilde\\log(w):=ln|w|+i\\cdot \\tilde\\arg(w)$. As the argument now varies continuously, this branch of the logarithm is now analytic on the desired set.\n\nAn example of a branch that works in this case is the principal branch of $\\log$, which has an argument varying continuosly between $(-\\pi,\\pi)$.\n\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/56324/negative-voltage-level-shifting-to-an-adc\nText:\nI am currently building a project that uses an AD595 analog devices chip to linearize the output of the Thermocouple sensor to 10mv/deg C. This output is to be connected to the ADC input of a Zigbee radio, with a max input of 1.2v. Given that the Zigbee input determines the range, this would achieve a 0-120 degree temperature range. I am now trying to adjust this design to also sense negative temperature.\n\nThe AD595 chip can run as dual-supply by connecting -5v and +5v, to give both positive and negative output, however The zigbee radio will not accept a negative voltage input. I believe i now need to place in the design a Non-Inverting Summing Amplifier to \"level shift\" the range so that \"-1.2v - 0v - 1.2v\" becomes \"0v - 0.6v - 1.2v\" and can be interperated by the ADC. I am fairly new to this and i'm not sure where to start, it being especially difficult using a negative voltage.\n\nSo far i have used a voltage divider on the output to produce a 5mv/deg C output thus increasing the temperature range to 0-240 deg C. I will have a regulated 5V (ad595), 3.3V (for zigbee) and -5V (for dual) supply.\n\nIf anyone could help or point me towards worthwhile resources i would appreciate it a lot.\n\n\n  \u2022 1\n    \\$\\begingroup\\$ try electronics.stackexchange.com/questions/55644/\u2026. Also, all the automatically generated \"related\" links. \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 12:12\n  \u2022 \\$\\begingroup\\$ Thanks... I have already viewed these responses and haven't found a solution - the link you posted differs from what i am asking - hence why i am asking this question. \\$\\endgroup\\$ \u2013\u00a0Nick G Jan 28 '13 at 12:45\n  \u2022 \\$\\begingroup\\$ How do any of those solutions differ other than by shifting by different amounts? Shifting, attenuating, or multiplying a voltage is a very common task. Where exactly are you stuck on understanding the existing solutions? \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 13:08\n  \u2022 \\$\\begingroup\\$ Please take a look at my question. I need to achieve 0V-1.2V from -1.2V to +1.2V. The solution you posted above shifts 0V-5V to a negative-positive 2.5V range. Level shifting may be a common task, however as i stated in the question \"I am fairly new to this...\" If you need me to clariy anything in the question i will gladly do so. \\$\\endgroup\\$ \u2013\u00a0Nick G Jan 28 '13 at 13:14\n  \u2022 \\$\\begingroup\\$ What temperature range do you need to measure, exactly? There are ways to measure negative temperatures with the AD595 without negative voltages, relative to ground. The main limitation is the range of temperatures that can be measured, given the difference between the supply rails. Although nominally starting at 0 degrees, this range can trivially be shifted up and down. \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 13:20\n\nHere's a single supply inverting opamp configuration that will do what you want. You will need an opamp capable of output drive to it's lower rail (You will probably want to include a small capacitor across R2 to limit bandwidth, since you don't need much for thermocouple readings)\nR3/R2 may need to be increased in order not to load thermocouple depending on type - EDIT, just noticed the output is coming from the AD595, so it's probably low impedance (not checked datasheet) and fine as is:\n\nLevel Shift\n\nR3/R2 simply divide the input voltage by 2. R1 and R5 present 400mV to the positive input. Since the opamp tries to keep the two inputs equal, it creates a level shift. For example, when there is -1.2V at the input, to keep the inverting input at 400mV, there needs to be 1.2V at the output. We can now see R3/R2 as a voltage divider with -1.2V at one end and +1.2V at the other, we get 2.4V across R3+R2, so the voltage across R3 is:\n\n2.4V * (R3 / (R2 + R3)) = 2.4V * (10k\u03a9 / 15k\u03a9) = 1.6V and so:\n\n-1.2V + 1.6V = 400mV\n\nYou can run the calculations for the other input voltages and see how it works across the range (remembering there is always 400mV at the inverting input, and effectively no current flows into the input)\n\nAnother way to look at it given the above is, say we have -0.6V at the input. We know there must be +0.4V at the other side of R3, so the current flowing through R3 is:\n\n(0.4V - -0.6V) / 10k\u03a9 = 0.1mA\n\nNow we know none of this current flows into the inverting input, so it must flow through R2:\n\n5k\u03a9 * 0.1mA = 0.5V\n\n0.4V + 0.5V = 0.9V at the output\n\n\nLevel Shift Simulation\n\nIf you need it non-inverting, you can easily do this in firmware or add a simple inverting buffer after this.\n\n\nJust had a look at the Zigbee datasheet and it seems the Vref is fixed at 1.2V (although there is Vref pin, I couldn't find any mention of how to use it in the analog IO section), so you have to work with this unless you use an external (possibly higher resolution) ADC and feed the data to the Zigbee. It's a 10-bit ADC, so 1.2V / 1024 = ~1.17mV LSB, which won't be so bad with with filtering (which use a low cutoff since you have a slowly changing signal from the thermocouple)\nBear in mind the ADC595 has an calibration error of around +-1\u00b0C (or +-3%deg;C depending on which variant you are using) so absolute accuracy will not be excellent, but you could go for a higher resolution as mention if you wanted to.\nSo read the ADC595 datasheet advice thoroughly, pay attention to the PCB layout (if possible a 4-layer with solid ground plane), keep any digital signals away from the analog as best you can and use plenty of decoupling and all should be well.\n\n  \u2022 \\$\\begingroup\\$ Many thanks for that! Could you please explain how you obtained the values for R1-R5? Out of interest - what is the simulation software you are using? Thank you again. \\$\\endgroup\\$ \u2013\u00a0Nick G Jan 28 '13 at 13:40\n  \u2022 \\$\\begingroup\\$ I added a description of how it works. Note that the values are not set in stone, it's the ratios that are important. The higher R2/R3, the higher the input impedance. The higher R1 and R5, the less power consumption (but too high and it's more susceptible to noise) \\$\\endgroup\\$ \u2013\u00a0Oli Glaser Jan 28 '13 at 13:58\n  \u2022 \\$\\begingroup\\$ Input impedance is just R3, since the inverting input is a virtual ground (it is always equal to the non-inverting input). description at wikipedia \\$\\endgroup\\$ \u2013\u00a0Phil Frost Jan 28 '13 at 14:43\n  \u2022 \\$\\begingroup\\$ @PhilFrost - Yes, I know, but the ratio stays the same in this case (e.g. if R2 is increased, R3 must be) so I just put it this way instead. Although note that in this case the inverting input is not at the same value as thermocouple ground. \\$\\endgroup\\$ \u2013\u00a0Oli Glaser Jan 28 '13 at 15:09\n  \u2022 \\$\\begingroup\\$ @PhilFrost - Note that DC input impedance changes with applied voltage for this reason (e.g. if the input voltage is at -1V, it sees an effective impedance of -1V / 140uA = 7.142k) \\$\\endgroup\\$ \u2013\u00a0Oli Glaser Jan 28 '13 at 15:36\n\nThe AD595 can measure negative temperatures without a negative power supply. What it actually needs is a voltage that's more negative than its COM terminal. When the datasheet says \"output is 0V at 0 degrees\", what it means is, \"output is 0V relative to COM at 0 degrees.\" There's no reason COM must be your circuit ground. For example, if you wanted 0 degrees to be the middle of your supply voltage, you could do this:\n\nvoltage divider\n\nFrom the perspective of the ADC595, COM is \"ground\" and it has supply voltages (known as \"ground\" and \\$V_{cc}\\$ elsewhere) of \\$\\pm \\frac{1}{2}V_{cc}\\$. That what the ADC595 conisders \"ground\" is actually half of \\$V_{cc}\\$ to the rest of the circuit doesn't affect its operation at all, except now you don't also need a -5V supply.\n\nThis is a simple resistive voltage divider. R2 exists to calibrate for any differences between R1 and R3. You could use just a pot, or just R1 and R3 also, depending on how carefully you need to calibrate this.\n\nThis potentially introduces two errors: the first is that Vcc may not be a stable voltage. If Vcc isn't regulated well enough to meet your accuracy requirements, then you can construct a more stable voltage source to use instead of Vcc. That's enough of a problem to merit another question. But also maybe your ADC is referenced to Vcc, in which case this is an advantage, not a problem.\n\nThe other is that the current going in or out of COM will change your voltage reference. The current should be small, so this should not be a big error. The smaller you make the resistors, the smaller this error will be, but also the more power you will waste in the voltage divider. To eliminate this error, you can buffer the output of the voltage divider before connecting it to COM.\n\nAlso check out the section in the datasheet, \"RECALIBRATION PRINCIPLES AND LIMITATIONS\". This discusses ways to change the gain and zero point of the internal amplifier.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3188325/in-how-many-ways-can-7-women-10-men-sit-at-table-such-that-no-woman-sits-beside\nText:\nWe have $7$ women and $10$ men; they sit at a table. I've been trying to solve how many ways can they sit excluding the case of women sitting next to each other.\n\nMy reasoning was the following: I will have to alternate woman and men to certain extent so that no woman will sit next to another woman. The possible alternations are the following cases:\n\n$a)$ One of $7$ woman takes the first sit; one of $10$ men take the second; one of $6$ remaining women take the third; one of $9$ remaining men take the fourth, etc. So I have $10*7*9*6*8*5*7*4*6*3*5*2*4*1=10!7!$ possibilties.\n\n$b)$One of $10$ men takes the first place; one of $7$ woman the second; etc. Again, $10!7!$ possibilities, but the order has changed.\n\nIn either case, I have $3$ men remaining. Let's call $A$ and $A'$ the selections of alternated men and woman that I described on points $a)$ and $b)$, and $S$ the selection of the three remaining men. The first man of $S$ is any of the three remaining; the second man of $S$ is any of the two remaining; the last one is the one that's neither of the previous two. So I have for $S$ $3*2*1=3!$ cases.\n\nSo my posibilities are that $A$ is the case or $A'$ is the case, and $P$. Which leaves me with $(10!7!+10!7!)*3!$ posibilities.\n\nIs my reasoning okay? With this type of problems it troubles me how hard it is to actually test or check if one's answer is right. (Excuse any error on my english, it's not my native language.)\n\n  \u2022 1\n    $\\begingroup$ Is the table round? $\\endgroup$ \u2013\u00a0Dbchatto67 Apr 15 '19 at 5:45\n  \u2022 $\\begingroup$ Yes, sorry I forgot to say this. $\\endgroup$ \u2013\u00a0lafinur Apr 15 '19 at 14:06\n\nYour result is correct. More generally, assume that there are $m$ men and $w$ women with $m\\geq w\\geq 1$. Number the $m+n$ chairs around the circular table from $1$ to $m+n$ and let the \"oldest\" woman sit down at the $1$-st chair. In our final arrangement, let $x_i$ be the number of men between the $i$-th woman and the next one. Then $$x_1+x_2+\\dots +x_w=m$$ where each $x_i$ is a positive integer. The number of solutions of this equation is $\\binom{m-1}{w-1}$ (see stars-and-bars). Each solution tells us which chair goes to a man or to a women. Now we have $(w-1)!$ ways to place the remaining $w-1$ women and $m!$ ways to place the $m$ men. Therefore the number of arrangements is $$\\binom{m-1}{w-1}(w-1)!m!=\\frac{(m-1)!m!}{(m-w)!}.$$ For $m=10$ and $w=7$ the above formula gives $$\\frac{9!\\cdot 10!}{3!}=219469824000$$ which coincides with your result $(10!7!+10!7!)3!$.\n\n  \u2022 1\n    $\\begingroup$ I really didn't expect my result to be correct, haha. Well, surprises come in life! Thank you very much, Robert, for your assistance! $\\endgroup$ \u2013\u00a0lafinur Apr 15 '19 at 14:10\n\nRobert Z has provided a nice solution. Here is another approach.\n\nSuppose Edward is one of the men. We will use him as a reference point. Seat Edward first. Once Edward has been seated, there are $9!$ ways to seat the remaining men as we proceed clockwise around the table. This creates ten spaces in which we can place the women, one to the left of each of the ten men. To ensure that the women are separated, we choose seven of these ten spaces in which to place a woman. The women can be arranged in those spaces in $7!$ ways. Hence, the number of admissible arrangements is $$9!\\binom{10}{7}7!$$ For $m$ men and $w$ women, a similar argument yields $$(m - 1)!\\binom{m}{w}w!$$ which is equal to zero when $w > m$, as we would expect.\n\n  \u2022 $\\begingroup$ +1. For OP, the number of ways to arrange $10$ men around the table is a circular permutation: $P_{10}=(10-1)!=9!$. $\\endgroup$ \u2013\u00a0farruhota Apr 15 '19 at 11:33\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/59948/project-to-nearest-point-in-convex-polytope\nText:\nIs there a reasonably efficient algorithm for the following task?\n\nInput: a point $x \\in \\mathbb{R}^d$; a convex polytope $\\mathcal{C} \\subseteq \\mathbb{R}^d$\nFind: a point $y \\in \\mathcal{C}$ that is as close to $x$ as possible\n\nAssume that $\\mathcal{C}$ is specified by a collection of linear inequalities, that the dimension $d$ is fairly high, and \"close\" is measured using $L_2$ distance, i.e., we want to minimize $||x-y||_2$. is there an efficient algorithm for this problem?\n\nI can see how to solve this in polynomial time using linear programming if \"close\" were measured using $L_1$ or $L_\\infty$ distance, but I'm more interested in the $L_2$ distance metric. I keep thinking there might be some algorithm based on identifying the set of inequalities that are violated by $x$ and then doing something, but I can't quite put together a working algorithm.\n\nI found the following paper which describes an algorithm (exponential-time in the worst case but often efficient, like the simplex method):\n\nPhilip Wolfe. Finding the Nearest Point in a Polytope. Mathematical Programming, vol 11, 1976, pp.128--149.\n\nHowever, that paper requires $\\mathcal{C}$ to be presented as a list of vertices rather than a list of inequalities, so it can't be used for my problem. (Converting from inequalities to a set of vertices will cause an exponential blowup; typically the number of vertices is exponential in the number of inequalities.)\n\n\nA quadratic program is an optimization problem where the goal is to minimize $y^T Q y + c^T y$ subject to $A y \\leq b$. If $Q$ is positive definite, then this is a convex quadratic program and we can solve this problem in polynomial time using several methods, one being the ellipsoid method (originally due to Kozlov, Tarasov and Khachiyan\u00a0[1]).\n\nWe can write $\\|y - x\\|_2^2$ as $y^Ty - 2x^Ty + x^Tx$. Thus an equivalent problem is $$ \\min_y\\ (y^Ty - 2x^Ty) \\text{ such that } A y\\leq b. $$ This is a convex quadratic program, since in this case $Q$ is the identity matrix, which is positive definite.\n\n[1] The polynomial solvability of quadratic programming, USSR Computational Mathematics and Mathematical Physics, 20(5):223\u2013228, 1980; Science Direct\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1926519/dead-of-winter-probability-of-avoiding-death\nText:\nIn the board game Dead of Winter, certain actions a player can take result in rolling a 12-sided die. On one face of the die, there's a tooth, representing instant death by zombie. Two faces of the die result in a frostbite wound, and three faces of the die result in a regular wound. Half the time one rolls the die, there is no e ffect. Suppose the game calls for a player to roll the die three times in a row. Assume that if a tooth is rolled, death occurs and no further rolls are made. Assume also that if three wounds of any kind are rolled, death occurs. What is the probability that a player rolling the die three times escapes death?\n\nI tried (11/12)(11/12)(6/12), but I don't think that this accounts for the order of the die. For example, if I rolled a non-wound on the second roll, wouldn't that change my third probability?\n\n  \u2022 1\n    $\\begingroup$ frost bite = regular wound in this exercise ? $\\endgroup$ \u2013\u00a0marmouset Sep 14 '16 at 13:06\n\nFirst of all, you must avoid that tooth three times running. The probability of that is $\\left(\\frac {11}{12}\\right)^3$.\n\nNow, let's suppose that you have dodged the tooth. That means that each of your three rolls is one of the other eleven options. Five of these are wounds, though, and you mustn't get three of those. What is the (conditional) probability of getting three of those? Well, it's $\\left(\\frac {5}{11}\\right)^3$. Therefore the conditional probability that you don't get three wounds is $1-\\left(\\frac {5}{11}\\right)^3$.\n\nAs you need both things to occur the final answer is $$\\left(\\frac {11}{12}\\right)^3\\times\\left(1-\\left(\\frac {5}{11}\\right)^3\\right)=0.697916667$$\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/104514/computing-nash-equilibria-in-discrete-auctions\nText:\nI am trying to compute the (pure strategy) Nash equilibria of some discrete auctions.\n\nMore precisely, let us define the strategy of each player as a function mapping from every valuation that they might have to their bid (i.e. the 'bidding function'). Let us suppose that each player's valuation is drawn from some finite set and that their bid must belong to this same (finite) set. I am interested in finding the set of bidding functions, one for each player, such that each player's bidding function is optimal given the bidding functions of all the other players.\n\nIf it makes things easier, we can assume that valuations are symmetric (i.e. each player's valuation is generated by the same probability distribution) and that there are only two bidders. Ideally, however, we would proceed without these simplifications. I am interested in computing the equilibrium for the first price sealed bid and all pay auctions (in the latter, you pay your bid even if you lose; in the former, you don't.)\n\nI have considered writing down the discrete auction game in normal form and finding the equilibria using software like Gambit. However, this would seem tricky since the strategy space is so large. For example, if a player chooses bids from $ \\{1,...,10\\} $ and draws values from $ \\{1,...,10\\} $, then already they have $10^{10}$ pure strategies.\n\nDoes anyone have any ideas about how to proceed here?\n\n  \u2022 $\\begingroup$ The answer might depend on the parameters. How large is the finite set of possible valuations, in practice? Is it at most about 10? $\\endgroup$ \u2013\u00a0D.W. Feb 18 '19 at 20:20\n  \u2022 $\\begingroup$ No, usually more like 100 - 1000 (unfortunately!) However, we can reduce the dimensionality somewhat by ruling out strategies that require you to bid more than your valuation. $\\endgroup$ \u2013\u00a0afreelunch Feb 20 '19 at 15:04\n  \u2022 $\\begingroup$ OK. What determines whether a player's bidding function is optimal, given the other functions? I'm wondering how one would check that, and how \"simple\" a computation it is. (If it involves reasoning about all other possible choices for that player's bidding function, that sounds pretty complicated. But maybe there's some simpler characterization of when a proposed bidding function is optimal, when given all the other players' functions?) $\\endgroup$ \u2013\u00a0D.W. Feb 20 '19 at 19:33\n  \u2022 $\\begingroup$ Optimal = maximises expected payoff (i.e. assume risk neutrality) $\\endgroup$ \u2013\u00a0afreelunch Feb 23 '19 at 16:00\n  \u2022 $\\begingroup$ OK. How do we calculate expected payoff, given all the players bidding functions? Is it \"highest bidder wins the item, and their payoff for that item is what they bid minus their valuation of the item\"? And where is the randomness (why do you say expected payoff)? $\\endgroup$ \u2013\u00a0D.W. Feb 23 '19 at 19:44\n\nIf there are only two players, you could use integer linear programming.\n\nI'll introduce some zero-or-one integer variables to encode the (unknown) bidding functions (via a one-hot encoding). Let $x_{v,b}=1$ if player $0$'s bid is $b$ when their valuation is $v$, and $0$ otherwise; and $y_{w,c}=1$ if player $1$'s bid is $c$ when their valuation is $w$, and $0$ otherwise. In this way, if there are $n$ possible valuations, we obtain $2n^2$ zero-or-one integer variables. We will write down linear inequalities on these variables that characterize the optimality condition, then use an integer programming solver to find a solution that satisfies all of these inequalities.\n\nNote that if player $0$'s valuation is $v$ and player $1$'s valuation is $w$, then player $0$'s payoff (in a first-price auction) is\n\n$$\\sum_{b>c} x_{v,b} y_{w,c} (v-b).$$\n\nTherefore, if player $0$'s valuation is $v$, player $0$'s expected payoff is\n\n$$\\sum_w p_1(w) \\sum_{b>c} x_{v,b} y_{w,c} (v-b),$$\n\nwhere $p_1(w)$ represents the probability that player $1$ gets valuation $w$. Now, we need this to be at least what it would be if player $0$ used any other bid for valuation $v$, i.e., any other choice of $x_{v,\\cdot}$'s. If there are $n$ possible valuations, there are only $n$ possible bids, so we obtain $n$ inequalities\n\n$$\\sum_w p_1(w) \\sum_{b>c} x_{v,b} y_{w,c} (v-b) \\ge \\sum_w p_1(w) \\sum_{b'>c} y_{w,c} (v-b'),$$\n\nwhere we obtain one such inequality for each possible value of $b'$. (The sum on the left-hand-side is over $w,b,c$ that satisfy the condition $b>c$; the sum on the right-hand-side is over $w,c$ that satisfy the condition $c<b'$.)\n\nThis is a quadratic inequality. We'll turn it into a linear inequality using the techniques of Express boolean logic operations in zero-one integer linear programming (ILP). In particular, introduce new zero-or-one variables $t_{v,w,b,c}$, with the intention that $t_{v,w,b,c}=x_{v,b} y_{w,c}$. This can be enforced using the linear inequalities $t_{v,w,b,c} \\ge x_{v,b} + y_{w,c} - 1$, $t_{v,w,b,c} \\le x_{v,b}$, $t_{v,w,b,c} \\le y_{w,c}$, $0 \\le t_{v,w,b,c} \\le 1$. Now the optimality condition becomes\n\n$$\\sum_w p_1(w) \\sum_{b>c} t_{v,w,b,c} (v-b) \\ge \\sum_w p_1(w) \\sum{b'>c} y_{w,c} (v-b'),$$\n\nfor each $v,b'$. We obtain one such inequality for each $v$ and each $b'$. These $n^2$ inequalities ensure that player $0$'s strategy will be optimal (given player $1$'s strategy).\n\nThen, add similar inequalities to require player $1$'s strategy to be optimal (given player $0$'s strategy).\n\nAlso add the $n^2+n$ constraints that $0 \\le x_{v,b} \\le 1$ and $\\sum_b x_{v,b}=1$ to require the $x$'s to correspond to a bidding function, and similarly for the $y$'s.\n\nFinally, take all of these inequalities and feed them to an off-the-shelf integer linear programming solver. If it finds a solution, then you have found a Nash equilibrium for your game. ILP is NP-hard, so there is no guarantee that it will terminate in a reasonable amount of time, but in my experience often the solvers can handle surprisingly large systems of inequalities.\n\nThe same approach can handle all-pay auctions as well as first-price auctions.\n\nIn practice, you might be able to speed up the solver by adding some extra constraints to help it identify a solution faster. In particular, I have a hunch that without loss of generality the optimal bidding function can be assumed to be monotonic: if we increase my valuation, my bid should never decrease. We can add extra inequalities to the system to characterize this additional assumption, and this might narrow the search space and thus help the ILP solver find a solution more rapidly.\n\nOne big limitation is that this seems limited to two players (or a very small number of players). If there are multiple players, the number of variables and inequalities will explode, and this might not be an effective approach.\n\n\nYour Answer"}
{"text": "Retrieved from http://mathfactor.uark.edu/2009/12/morris-follow-up-trieltruelwhatever/\nText:\nMorris: Follow Up: Triel/Truel/Whatever\n\n\n\n\nJeff suggested that they might all choose not to shoot at each other and it would go on forever. \u00a0This made me think about the logic. \u00a0I\u2019m going to say that someone shoots at someone at some point and everyone knows this. \u00a0So everyone knows that if they shoot to miss then one of the others will shoot to hit at some point.\n\nIf anyone shoots to hit then they will shoot at the best shot. \u00a0If they hit they will be in two-man duel and would prefer to be against the worst shot possible.\u00a0\n\nSo\u00a0Fran\u00e7ois\u00a0knows that no-one will shoot at him. \u00a0Xavier knows that one of the others will shoot at him. \u00a0\n\n\nFran\u00e7ois\u00a0has two options, he can shoot at Xavier or he can shoot to miss.\n\nIf he hits Xavier he will be in a two man dual with JC shooting first, he only has a one in five chance of surviving the first shot so his chance of survival is less than 1/5.\n\nIf\u00a0Fran\u00e7ois\u00a0shoots to miss he knows that the other two will shoot at each other, if they choose to shoot to hit. \u00a0So at some point JC or Xavier will kill the other. \u00a0At this point\u00a0Fran\u00e7ois\u00a0will be in a two man duel with himself shooting first. \u00a0This gives him at least a fifity/fifty chance.\n\nSo\u00a0Fran\u00e7ois\u00a0shoots to miss.\n\n\nXavier and JC know this. \u00a0They know they are effectively in a two man duel with each other. \u00a0They therefore shoot at each other.\n\n\nThat sorts out the strategy, what about the probabilities?\n\n\nLet\u2019s consider JC first. \u00a0There is a fifty/fifty chance that Xavier or JC will shoot first. \u00a0JC\u2019s only chance is to shoot first and hit. \u00a0The chance is 1/2 x 4/5 = 2/5.\n\nSo 2/5 of the time JC will face\u00a0Fran\u00e7ois\u00a0with Francois shooting first. \u00a0\n\nLet\u2019s say that the chance that\u00a0Fran\u00e7ois\u00a0wins is f. \u00a0He has a 1/2 chance of killing JC with his first shot. \u00a0There is a 1/2 x 1/5 = 1/10 chance that both miss with their first shot, we are back to the starting position so the probability of\u00a0Fran\u00e7ois\u00a0surviving is now f again.\n\nThe chance of\u00a0Fran\u00e7ois\u00a0surviving is f = 1/2 + 1/10 f. \u00a0This gives 9/10 f = 1/2 and f = 5/9. \u00a0The chance of\u00a0Fran\u00e7ois\u00a0surviving is 5/9. \u00a0The chance of JC surviving is 4/9.\n\n\nThis gives JC a total survival chance of 2/5 x 4/9 = 8/45.\n\n\nNow consider Xavier. \u00a0He has a 3/5 chance of facing\u00a0Fran\u00e7ois\u00a0with\u00a0Fran\u00e7ois\u00a0shooting first.\n\nHis chance of surviving is 1/2, the chance that\u00a0Fran\u00e7ois\u00a0misses.\n\nHis total survival chance is 3/10.\n\n\nFinally Francois\u2019 chance of surviving is 2/5 x 5/9 + 3/5 x 1/2 = 2/9 + 3/10 = 47/90.\n\n\nSo the probabilities of being the last man standing are: \u00a0Fran\u00e7ois\u00a047/90; Xavier 3/10 and JC 8/45.\n\n\nAmazingly the worst shot has the best chance of survival!\n\n\nRSS feed for comments on this post \u00b7 TrackBack URL\n\nLeave a Comment\n\nYou must be logged in to post a comment.\n\nThe Math Factor Podcast Website\n\n\nA production of the University of Arkansas, Fayetteville, Ark USA\n\nDownload a great math factor poster to print and share!"}
{"text": "Retrieved from https://mathoverflow.net/questions/34719/what-is-the-best-known-upper-bound-for-the-number-of-twin-primes\nText:\nA quantitative form of the twin prime conjecture asserts that the the number of twin primes less than $n$ is asymptotically equal to $2\\, C\\, n/ \\ln^2(n)$ where $C$ is the so-called twin prime constant. A variety of sieve methods (originating with Brun) can be used show that the number of twin primes less than $n$ is at most $A\\, n/ \\ln^2 (n) $ for some constant $A>2C$. My question is: What is the smallest known value of $A$? I'd also be interested in learning what the best known constants are for the prime k-tuple conjecture?\n\n\nJ Wu, Chen's double sieve, Goldbach's conjecture, and the twin prime problem, Acta Arith 114 (2004) 215-273, MR 2005e:11128, bounds the number of twin primes above by $2aCx/\\log^2x$, with $C=\\prod p(p-2)/(p-1)^2$, and $a=3.3996$; I don't know whether there have been any improvements.\n\n  \u2022 2\n    $\\begingroup$ I have checked Math Reviews for papers and reviews that cite Wu's paper. As far as I can tell from the reviews, there is no claim of an improvement on Wu's result. $\\endgroup$ \u2013\u00a0Gerry Myerson Aug 9 '10 at 23:32\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/80860/maximisation-of-graphs-weight/80863\nText:\nI have a graph related problem. Let $G$ be an undirected weighted graph of $N$ nodes. I want to find $p$ independent (they have no edge linking them) sub-graphs of $m$ nodes in a way that the total weight is maximized.\n\nFor example, let $G$ be a graph of $16$ nodes, I want to find $4$ sub-graphs of $4$ nodes with $w_1, w_2, w_3, w_4$ as their weights (sum of the weights on the subgraph's edges) I want to determine the $4$ subgraphs that will maximize $w_1+w_2+w_3+w_4$.\n\nIs this a classic graph problem? Is there already an algorithm for this? I am not very experienced with graphs and my research on the net was only confusing. Any ideas on how to approach this?\n\nThank you for your help\n\n\nIt is definitely not a classic graph problem such as the shortest path, maximum-flow, or graph coloring problem. But your problem, in its general form, seems to solve the Independent set problem, which is $NP$-complete.\n\nAssume that you have a polynomial time algorithm $A(G,m,p)$ solving this problem. Then take $m=1$ and call $A(G,1,p)$ for $p=N,N-1,...,2,1$ (at most $N$ times) until you find a solution. When $m=1$, each subgraph has only one node and so its weight is 0, which is maximum for a single node graph. Furthermore, these nodes are not connected by an edge, and so they are not adjacent, i.e. they are independent.\n\nIf this procedure finds a solution for the maximum $p$ less than $N$, then this means we have a maximal independent set, since we have exactly $n$ nodes (subgraphs) with no edges between them, i.e. independent.\n\nOnce your problem is $NP$-complete, you could try any approximation algorithm including Linear or Integer programming.\n\n  \u2022 $\\begingroup$ Thank you for answering. What if my m is not a variable of the algorithm and it is a fixed value since the beginning. would this affect the NP-completeness of the prob? $\\endgroup$ \u2013\u00a0user76838 Sep 8 '17 at 11:25\n  \u2022 $\\begingroup$ Fixing only $m$ does not affect NP-completeness of the problem. Even when we fix $m$ to $1$, we can solve the Independent set. $\\endgroup$ \u2013\u00a0fade2black Sep 8 '17 at 21:45\n  \u2022 $\\begingroup$ Decision version of problem is trivially in $\\mathsf{NP}$. $\\endgroup$ \u2013\u00a0rus9384 Sep 8 '17 at 22:35\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/138345/geodesic-transformations-of-the-complex-projective-plane\nText:\nAre there non-trivial diffeomorphisms (i.e., different from isometries) of the complex projective plane that map geodesics (for the canonical Riemannian metric) to geodesics?\n\nSame question for all other rank one symmetric spaces different from spheres and real projective spaces.\n\n  \u2022 $\\begingroup$ There is a vast literature on \"projective maps\", going back to Sophus Lie, see e.g. www.minet.uni-jena.de/~matveev/Datei/lichnerowicz.ps and references there. $\\endgroup$ \u2013\u00a0Misha Aug 2 '13 at 5:57\n  \u2022 $\\begingroup$ Misha: thanks for the reference. However, most and probably all (?) of this classic work relies on the existence of \"infinitesimal\" projective transformations. Here I would like to know if there is just one non-isometric transformation that maps geodesics to geodesics. $\\endgroup$ \u2013\u00a0alvarezpaiva Aug 2 '13 at 6:18\n  \u2022 $\\begingroup$ True, but, still, might be worth checking. $\\endgroup$ \u2013\u00a0Misha Aug 2 '13 at 6:24\n  \u2022 $\\begingroup$ @Misha: See section 1.3 in Vladimir\"s paper. $\\endgroup$ \u2013\u00a0alvarezpaiva Aug 2 '13 at 7:39\n  \u2022 2\n    $\\begingroup$ I once wrote a paper called Smooth projective planes, which proved that the continuous maps which preserve orientation and take lines to lines are diffeomorphisms. It turned out that this was already known in the literature of topological projective planes. Using the fact that the geodesics of the complex projective plane lie on the projective lines, you can easily show that the homeomorphisms preserving orientation and geodesics are complex projective transformations. But then preserving geodesics is actually stronger, so they must be isometries as indicated below. $\\endgroup$ \u2013\u00a0Ben McKay Aug 2 '13 at 9:50\n\nThe answer is no. The explanation of Anton is of course correct but there exist stronder statements in the literature: for example by Sinjukov (Dokl. Akad. Nauk SSSR (N.S.) 98, (1954) 21--23) any symmetric space is locally \\emph{geodesically rigid} is the sense that any other metric having the same (unparameterized) geodesics with it is affinely equivalent to if (i.e., the Levi-Civita connections coincide) which in the irreducible case means that the metrics are proportional.\n\nActually, stronger statements hold. For example from the Lichnerowicz-Obata conjecture arXiv:math/0407337 it follows that compact Riemannian homogeneous metrics such that sectional curvature is not constant and positive are also geodesically rigid. Indeed, a Killing vector field for the initial metric is a infinitesimal projective transformation for the second, which must be also Killing by the projective Lichnerowicz-Obata conjecture. Then, the isometry algebras of the metrics are the same and therefore their volume forms are the same and these already implies (short tensor calculations, see for examples eqns. (1), (4), (5) of arXiv:0806.3169) that the metrics are affinely equivalent. I do not know whether homogeneous metrics of nonconstant curvature are geodesically rigid locally but all examples indicate that probably they are.\n\nNow, in the case your metric is K\u00e4hler and not flat,\nthen if it is not geodesically rigid then it is locally a cone over a (sasakian) manifold which in particular implies that the manifold is not compact. This statement is pretty nontrivial and follows from Theorem 4.6. of Mikes (Journal of Mathematical Sciences 78(1996) 311-333) combined with the Splitting Lemma from arXiv:0904.0535 and combined with the following statement which was explained to me by Kiosak and which is probably not published: Warped product K\u00e4hler nonflat metric is a locally a cone over a sasakian manifold.\n\n  \u2022 $\\begingroup$ In the question there is no connected Lie group, no infitesimal projective transformations. Could you please specify how much of what you are saying carries through to this situation? $\\endgroup$ \u2013\u00a0alvarezpaiva Aug 2 '13 at 7:46\n  \u2022 $\\begingroup$ I do not understand your comment. If you are asking whether in my answer I assumed that the projective transformation is actually an infinitesimal projective transformation, I did not do it and spoke about projectively equivalent metrics only. If you would like me to tell you more assuming the existence of an infinitesimal projective transformation, then globally (in the riemannian case) it is in arXiv:math/0407337 and locally in Solodovnikov 1956 in dimensions >2 and in arXiv:0802.2344 + arXiv:0705.3592 in dimension =2. In the case I misunderstood your comment, please explain $\\endgroup$ \u2013\u00a0Vladimir S Matveev Aug 2 '13 at 7:55\n  \u2022 $\\begingroup$ In your paper on the Lichnerowiz-Obata conjecture you explicitly warn that you need the hypothesis of a connected Lie group of projective transformations. Here I'm asking for just the existence of one non-trivial projective transformation that can be very far from the identity. In your comments do you assume that we have a connected Lie group of projective transformations? $\\endgroup$ \u2013\u00a0alvarezpaiva Aug 2 '13 at 8:08\n  \u2022 $\\begingroup$ No, I dont do it in my answer. The result of Sinjukov is local, works in all signatures, and is about projectively equivalent metrics and not about projective transformations or connected groups of projective transformations. The arguments in my asnwer using Lichnerowciz-Obata relies on the existence of a big group of isometries of the metrics in your question. If there exists a (noninfinitesimal) projective transformation, then the pullback of the killing vector fields are projective vector fields and one can use Licherowicz-Obata. The K\u00e4hler result is also about projective equivalence. $\\endgroup$ \u2013\u00a0Vladimir S Matveev Aug 2 '13 at 8:15\n  \u2022 $\\begingroup$ thanks again. I think I need to see this theorem of Sinjukov (is there a proof somewhere? Dokl. is just for announcements, right?). $\\endgroup$ \u2013\u00a0alvarezpaiva Aug 2 '13 at 8:39\n\nFor complex projective plane with the canonical metric you get only isometries.\n\nIndeed, note that such map has to send complex lines to the complex lines. It follows since, any complex line is a union of an infinite family of geodesics passing through two points and the other way arround.\n\nIt remains to check which complex projective maps send geodesics to geodesics.\n\nNote that a M\u00f6bius transformation of a sphere (=complex projective line) sends geodesic to geodesic if and only if it is an isometry. Hence the result follows.\n\n(The same might follow from the projective curvature tensor, but I do not know how one calculates it.)\n\n  \u2022 $\\begingroup$ Anton: You need more work for the 1st part of the proof, since \"and the other way around\" is clearly false. $\\endgroup$ \u2013\u00a0Misha Aug 2 '13 at 4:51\n  \u2022 $\\begingroup$ @Anton: I thought about this line of attack, but I got stuck in proving that complex lines get mapped to complex lines. Oops, never mind: they are the only totally geodesic submanifolds in their homology class. They have to be mapped to each other. Thanks !! $\\endgroup$ \u2013\u00a0alvarezpaiva Aug 2 '13 at 5:07\n  \u2022 2\n    $\\begingroup$ If you take any two points of the complex projective plane, there is either a unique geodesic connecting them, or else the union of the geodesics is a projective line. Therefore geodesic preserving homeomorphisms preserve projective lines, and therefore are smooth projective transformations (from my work, or earlier work on smooth projective planes). Then Anton's argument finishes the proof: all geodesic preserving homeos of the complex projective plane are isometries. $\\endgroup$ \u2013\u00a0Ben McKay Aug 2 '13 at 10:42\n  \u2022 1\n    $\\begingroup$ I keep referring to earlier work that proves smoothness of homeomorphisms preserving projective lines. The proof: B\u00f6di, Richard; Kramer, Linus On homomorphisms between generalized polygons. Geom. Dedicata 58 (1995), no. 1, 1\u201314. $\\endgroup$ \u2013\u00a0Ben McKay Aug 2 '13 at 11:15\n  \u2022 3\n    $\\begingroup$ The same proof then proves that any homeomorphism of the octave projective plane or quaternionic projective plane which preserves geodesics is an isometry. It is nice how the proof breaks for the real projective plane. $\\endgroup$ \u2013\u00a0Ben McKay Aug 2 '13 at 11:21\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/76758/count-of-distinct-substrings-in-string-inside-range\nText:\nHaving string $S$ of length $n$, finding the count of distinct substrings can be done in linear time using LCP array. Instead of asking for unique substrings count in whole string $S$, query $q$ containing indexing $(i,j)$ where $0 \\le i \\le j < n$ is asking for count of distinct substring inside given query range for string $S[i..j]$.\n\nMy approach is just applying linear time construction of LCP array to each query. It gives complexity $O(|q|n)$. Number of queries could raise to order of $n$ so answering all queries makes it $O(n^2)$.\n\nCan it be done better, than linear time for every query?\n\nIn general, if one process substring of string for which we already have suffix array, suffix tree, lcp array, are those structures not relevant anymore, and must be build from scratch again?\n\n  \u2022 $\\begingroup$ The size of input and output seem to be natural lower bounds. $\\endgroup$ \u2013\u00a0Raphael Jun 14 '17 at 5:59\n  \u2022 1\n    $\\begingroup$ I don't have time to think about this, but it's quite standard to build segment trees out of these complex structures (in competitive programming), maybe it's the case for suffix arrays/trees/etc. You just have to be clever in defining a fast \"combine\" operation (which will be used for a father node with his children, or at the end to combine the results of all the leaves covering your interval). $\\endgroup$ \u2013\u00a0md5 Jun 14 '17 at 8:44\n  \u2022 $\\begingroup$ The number of queries is the number of ordered pairs $i, j$ which is $(n*(n+1))/2$, so the complexity should be $O(n^3)$ $\\endgroup$ \u2013\u00a0user11171 Jul 3 '18 at 22:45\n  \u2022 $\\begingroup$ @md5 I don't think a segment tree (or fenwick tree) based solution will work because the number of substrings lacks additive inverse. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 16:27\n\nThe question does not motivate the number of queries being $O(n)$, which seems an arbitrary worst case since the number of unique possible queries is the number of ordered pairs and thus $O(n^2)$.\n\nHere are two different solutions with better time complexity for the $O(n^2)$ case based on (implicit) suffix trees constructed incrementally with Ukkonen's algorithm. Both solutions are based on preprocessing and have complexity $O(n^2 + |Q|)$ where $Q$ is the set of queries. The second solution runs in $O(n + |Q|)$ if all queries have the same width.\n\nSolution 1 - Preprocess all unique queries\n\nIterate over the suffixes of $S$. For each suffix $S_i=S[i..n]$, build the suffix tree of $S_i$ with Ukkonen's algorithm. After update $j$ to the current suffix tree, store the tree size in a matrix at position $(i,i+j-1)$. A query for the range $[x,y]$ is answered by the matrix element at $(x,y)$.\n\nSuffix tree size can be stored along with the suffix tree and updated in constant time at each step by modifying the update procedure in Ukkonen's algorithm. For each update the size increases by the current number of leaves.\n\nSolution 2 - Preprocess unique query widths\n\nThis solution is harder to implement but requires less preprocessing work if there are few query widths. Preprocessing takes $O(n)$ time if there is only one query width.\n\nFor each query width $w$, use a sliding window of width $w$ and incrementally build a suffix tree. Remove the suffix starting one character to the left of the window by remove the longest suffix from the tree. At each step, the current number of substrings within the sliding window is the tree size.\n\nAll queries can then be answered in linear time by using the results of the precomputation.\n\nNote: removing the longest suffix can be done by removing the oldest leaf of the suffix tree. It is not easy to implement correctly.\n\n  \u2022 $\\begingroup$ This seems to be a bit off. The task is not to answer all possible $O(n^2)$ queries, but to answer some $q$ given queries. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 11:17\n  \u2022 $\\begingroup$ I answered the question for the general case, which was the point of the question. In the special case where the number of queries is low, the solution proposed by the question author would run faster in practice. The number of outputs of a valid solution is $q$, which is of size $O(n^2)$ (disregarding duplicate queries), so any possible solution must run in $O(n^2)$ or slower. My proposed solution takes time $O(n^2)$ for preprocessing and then each query can be answered in constant time. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 15:10\n  \u2022 $\\begingroup$ Again, $q$ is a parameter. The question is explicitly interested in the number of queries $q$ being $\\Theta(n)$, not $\\Theta(1)$ nor $\\Theta(n^2)$. The answer for $q$ queries is of size $\\Theta(q)$ which need not be $\\Theta(n^2)$. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 15:39\n  \u2022 $\\begingroup$ Why would the number of queries be of order $n$? It seems like an arbitrary condition, if not an oversight by the author. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 15:46\n  \u2022 $\\begingroup$ The whole problem statement is kind of the same degree of arbitrary. However, this is how a typical data structures problem in competitive programming looks like, so it is unlikely that $n^2$ queries are what the OP looks for. I'd bet $n$ and $q$ are independent parameters from $1$ to $100\\,000$ or so, and the time limit is a couple of seconds, so that an $O(nq)$ solution times out, but something better like $O(n \\sqrt q)$ doesn't. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 15:51\n\nThere is $O(n \\sqrt{n} + |Q| \\sqrt{n})$ offline solution.\n\n  1. Sort elements $(i,j)$ of $Q$ in ascending order of $j$.\n  2. Distribute them into $\\sqrt{n}$ buckets so, that $(i,j)$ goes into bucket number $\\lfloor \\frac{i}{\\sqrt{n}} \\rfloor$.\n  3. For each bucket starting at $b$ and each query $(i,j)$ in it, build a suffix tree for $S[b,j]$.\n  4. For each query in a bucket, remove redundant characters from the left and report the answer.\n\nStep 3 takes $O(n)$ for each bucket, because we use Ukkonen's algorithm and $j$ goes in ascending order.\n\nStep 4 takes $O(\\sqrt{n})$ for each query, because removing $\\sqrt{n}$ longest suffixes from the tree takes $O(\\sqrt{n})$. Note that you can use an indirection layer to avoid modifications to the original suffix tree.\n\n  \u2022 $\\begingroup$ The number of distinct substrings is the number of paths in the suffix tree that start at the root and end at a node with just a single leaf below it, correct? Do you store these path counts explicitly in the notes? If so, then how do you update things when removing the first character in O(1) time? There could be up to $\\sqrt n$ of them (in the case where the first character is unique within the block). If not, how do you compute them on the fly? $\\endgroup$ \u2013\u00a0j_random_hacker Jul 8 '18 at 7:49\n  \u2022 $\\begingroup$ @j_random_hacker Ukkonen's algorithm builds so called implicit suffix tree. Number of distinct substrings is just sum of lengths of its edges (i.e. size of corresponding trie). $\\endgroup$ \u2013\u00a0Dmitri Urbanowicz Jul 8 '18 at 14:14\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/319842/how-many-ways-to-fill-in-a-square-grid-with-certain-restrictions\nText:\nSuppose I have a 5x5 grid of squares. I would like to fill in 15 checkmarks in the squares such that (1) each of the 25 square cells contains at most one checkmark, (2) each row has exactly 3 checkmarks, and (3) each column has exactly 3 checkmarks. How many ways are there to fill in these 15 checkmarks?\n\nMore generally, suppose I have an $n \\times n $ square grid, and I would like to fill in $mn$ checkmarks such that (1) each of the $n^2$ square cells contains at most one checkmark, (2) each row has exactly m checkmarks, and (3) each column has exactly m checkmarks. How many ways are there to do so? If $m=1,$ I think the answer is $n!$. But I am not sure about the general case.\n\nAlso, if I have an additional restriction that no checkmarks on the diagonal, i.e., no checkmark in the (1,1), (2,2),... (n,n) cells. How many ways are there?\n\nThanks very much! Wish all very happy new year!\n\n  \u2022 $\\begingroup$ If you remove the only one checkmark per box requirement then you are looking at the Ehrhart polynomial of the Birkhoff polytope, and get into the Anand-Dumir-Gupta conjecture and related areas. $\\endgroup$ \u2013\u00a0Sam Hopkins Dec 31 '18 at 21:25\n\nWhat you are looking for is the number of matrices in the class $\\mathcal A(n,m)$ of $(0,1)$-matrices that are $n\\times n$ and have each row and column containing exactly $m$ entries equal to $1$. This is a pretty well-studied question, but an exact answer isn't known except in some small cases.\n\nYou are right that for $m=1$, the number is $n!$, as then you are counting the $n\\times n$ permutation matrices. A sort of generalization of this was obtained in\n\nWei, Wan-Di. \"The class $\\mathfrak A(R,S)$ of $(0,1)$-matrices.\" Discrete Mathematics 39, no. 3 (1982): 301\u2013305. Journal link\n\nwhere it is given that the number of such matrices is at least\n\n\nI say it is \u201csort of\u201d a generalization because it is only a lower bound. Again, there is no closed form known for the exact number. I think the most frequently-cited asymptotic results are those of McKay and others, for example see\n\nMcKay, Brendan D., Wang, Xiaoji. \"Asymptotic enumeration of 0-1 matrices with equal row sums and equal column sums.\" Linear Algebra and its Applications. 373 (2003): 273\u2013287. Journal link\n\nand anything that cites it.\n\nThere are other results \u2013 and other asymptotic results \u2013 out there. A good starting point for more details is the book Combinatorial Matrix Classes by Brualdi.\n\nFinally, note that this is the same as counting balanced regular bipartite graphs. For example, your question is the same as this one where the $d_v$ and $d_c$ of that question are taken to be equal. So you may wish to see the answer \u2013 provided by McKay! \u2013 appearing there.\n\n  \u2022 $\\begingroup$ Thanks so much for the very helpful information!! Happy New Year! $\\endgroup$ \u2013\u00a0KPU Jan 1 at 4:25\n\nThe problem amounts to counting binary or $0/1$-matrices with restrictions on row/column sums.\n\nIn general, let the row sums be $r(n)=(r_1,\\dots,r_n)$ and column sums $c(n)=(c_1,\\dots,c_n)$. Obviously, $0\\leq r_i, c_j\\leq n$ for all $i, j$. Further, let $\\mathbf{x}=(x_1,\\dots,x_n)$ and $\\mathbf{y}=(y_1,\\dots,y_n)$ with the multi-exponent notation $\\mathbf{x}^{u}=x_1^{u_1}\\cdots x_n^{u_n}$. Then, there is this generating function $$\\prod_{i,j=1}^n(1+x_iy_j)=\\sum_{r(n),c(n)} N(r(n),c(n))\\mathbf{x}^{r(n)}\\mathbf{y}^{c(n)} \\tag1$$ for the enumeration $N(r(n),c(n))$ of the number of binary matrices with row sums $r(n)$ and $c(n)$.\n\nTo get back to your question, extract the coefficient $N((k,\\dots,k),(k,\\dots,k))$ of $$\\mathbf{x}^{(k,\\dots,k)}\\mathbf{y}^{(k,\\dots,k)}$$ from the above product in (1).\n\n\nYour Answer"}
{"text": "Retrieved from https://blog.flyingcoloursmaths.co.uk/big-lead-can-football-team/\nText:\nA reader asks:\n\nWhat\u2019s the biggest lead a football team can have in the table after $n$ games?\n\nIn a typical football league, teams get three points for a win, one for a draw, and none for getting beat. After, for example, one game, if one team wins and all of the other games are draws, the winners will have three points, while everyone except the team they beat will have one point \u2014 the winners will be two points ahead.\n\nThere\u2019s not a whole lot more to it \u2014 after two games, the biggest possible lead is four points (one team wins both of its games to get six points, and all of the others are draws, leaving everyone else with at most two points). As long as the winning team hasn\u2019t played all of the teams, the biggest lead after $n$ games is $2n$ points.\n\nBut what if they\u2019ve played everyone?\n\nIn a four-team group, it\u2019s possible to have a seven-point lead after three games, rather than just six: if you beat all three of the other teams, you\u2019ll have nine points; if they all draw with each other, they each have two points. Assuming you always win and everyone else always draws, once you\u2019ve played everyone once, you\u2019ll have $3n$ points, and the best of the rest will have $n-1$ points - they\u2019ll have drawn every game except for the one they lost to you - giving you a margin of $3n - (n-1) = 2n+1$.\n\nIn general, if you\u2019ve played everyone at least $m$ times, your biggest possible margin is $2n + m$. So, when Dunfermline beat the other nine teams in Scottish League One four times, and they all draw with each other, they\u2019ll have a lead of $2 \\times 36 + 4 = 76$ points."}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/467287/measuring-output-voltage-single-ended-probe-vs-differential-ended-probe\nText:\nI have a SMPS buck 3.3V output. I am trying to measure the output voltage at the output capcacitor using Oscilloscope.\n\nI am using a single ended probe with spring ground tip to measure the output voltage.\n\nThe oscilloscope ground is connected to the module ground. (The module ground is not the same as board ground)\n\nWhen I measure the output voltage at the output capacitor (with single ended probe with ground tip) , I find the output voltage to be very noisy.\n\nBut when I measure the output voltage using differential probe, I am not able to find the noise?\n\nCan someone tell me where the noise is coming from?\n\nIs this due to different grounds or some common mode current?\n\nCan someone explain me a little clearly with basic terms?\n\n\nThat noise is going to be of the common mode type. Meaning it is on both parts of your scope probe (the tip and the ground pin).\n\nThe differential probes work by subtracting the two signals that it sees on each probe tip. So any noise that is present on both inputs will be subtracted from each other and goes away, leaving only differential signals.\n\n\nOne potential problem with a single-ended 'scope probe is the loop area formed by the probe plus six-inch ground clip. Any high-frequency alternating magnetic field entering this loop area generates a voltage fed back to the 'scope:\nnoise entering probe loop area.\nWhen you're probing a switch-mode power source, this loop area may be very near an inductor whose chopping frequency is not well-contained...noise!\n\nSome good probes include a small springy fixture that attaches to the probe's tip that reduces the loop area greatly...the ground connection is annoyingly short and requires some dexterity to get probe tip and short ground both connected:springy probe tip ground\n\nThere are other ground-loop scenarios too, involving your scope (which is earth-grounded for safety) and the device that you're probing which is also earth-grounded...that's a huge loop that may add much 50/60 Hz noise to your measurement.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2111132/number-of-ways-to-choose-n-objects-from-groups-of-indistinguishable-objects\nText:\nSay I have 5 blue, 6 red, and 7 green balls. How many ways are there to choose 8 balls, without regard to order? My first thought was to just add up all the balls and choose 8 from the collection of 18, but I know that that'll overcount the possibilities, as I can get the same color combination of balls multiple ways by choosing different balls within the same color group. How would I correctly approach this problem?\n\n  \u2022 $\\begingroup$ So all the same color balls are the same? $\\endgroup$\n    \u2013\u00a0S.C.B.\n    Jan 24 '17 at 1:25\n  \u2022 $\\begingroup$ Yep. All balls in the same color group are the same. $\\endgroup$ Jan 24 '17 at 1:29\n\nAny selection can be described as a triple $(b,r,g)$ where $0\u2264b\u22645$, $0\u2264r\u22646$, $0\u2264g\u22647$ and $r+b+g=8$.\n\nAs the numbers involved are small, it's not difficult to work case by case. We'll go through the possible values of $b$.\n\nI. $b=0$. Then $r\u22651$ but any non-zero value of $r$ works so $\\fbox 6$ cases.\n\nII. $b=1$. Now $r$ can be any value from $0$ to $6$ so $\\fbox 7$ cases.\n\nIII. $b=2$ Again we can use any value of $r$ so $\\fbox 7$ cases.\n\nIV. $b=3$. Now $0\u2264r\u22645$ so $\\fbox 6$ cases.\n\nV. $b=4$ Now $0\u2264r\u22644$ so $\\fbox 5$ cases.\n\nVI. $b=5$ Now $0\u2264r\u22643$ so $\\fbox 4$ cases.\n\nFinally the answer is $$6+7+7+6+5+4=\\fbox {35}$$\n\nNote: while the logic is fairly simple, case by case enumeration can be a bit error prone so I suggest checking carefully. As an alternate method you could multiply out the generating functions $$(1+x+x^2+x^3+x^4+x^5)(1+x+\\cdots +x^6)(1+x+\\cdots +x^7)$$ seeking the coefficient of $x^8$.\n\n\nLet's say that we ignore the green balls for now. We have can have between 0 and 5 blue balls and 0 and 6 red balls. So the number of possible pairings of number blue and number red is: $$6 * 7 = 42$$ Now we have to eliminate combinations where we had more than 8 balls so we need to see how far above the target we can get by adding the number of blue (5) and red (6) balls and subtracting the total desired (8). Then we sum the integers from 1 to that answer. This gives us how many of our 42 scenarios are too high. $$5 + 6 - 8 = 3$$ $$\\sum_{n=1}^{3} n = 6$$ $$42 - 6 = 36$$ Then we need to subtract off the bottom where the greens can't get us to 8 which only occurs when we have zero blue and zero red so: $$36 - 1 = 35$$ And thus you have 35 combinations.\n\n\nYour Answer"}
{"text": "Retrieved from http://mathfactor.uark.edu/2009/01/follow-up-differences/\nText:\nFollow Up: Differences\n\nGiven a difference table, as we considered back in EV. What\u2019s the Difference , how do we come up with a polynomial that gives the values on the top row?\n\nFor example, suppose we have\n\n-1     -1     3     35     143     399     899 . . . . .\n      0     4     32    108     256     500  . . . . .\n         4    28    76     148      244  . . . . .\n             24    48     72       96   . . . . .\n                  24     24    24    . . . . .\n\nWhat is the polynomial P(n), of degree four, that gives\n\nP(0) = -1 P(1) = -1 P(2) = 3 P(3) = 35 P(4) = 143 , etc.\n\nCan this be expressed simply in terms of the leading values on the left of the table: -1, 0, 4, 24, 24?\n\nAnd finally, what is the general rule?\n\nWonderfully, beautifully, the answer is, just as tricycle and prunthaban said in the comments:\n\n24 C(n,4) + 24 C(n,3) + 4 C(n,2) + 0 C(n,1) + (-1) C(n,0)\n\nWhere C(n,j) = (n)(n-1)(n-2) \u2026 (total of j terms) / j!\n\nFor example, C(n,4) = n (n-1) (n-2) (n-3) / 4! In the special case when j=0, we set C(n,0)=1.\n\nSo our polynomial here is\n\n(24/4!) (n) (n-1) (n-2) (n-3) + (24/3!) (n) (n-1) (n-2) + (4/2!) (n) (n-1) + (0/1!) (n) + (-1)\n\nThat isn\u2019t very \u201csimplified\u201d, but at least we can see the pattern! If we multiply the whole thing out, we get\n\nP(n) = n4 \u2013 2 n3 + n2 \u2013 1\n\nbut it\u2019s hard to see the connection, in this \u2018simplified\u2019 form, to the original data.\n\nBefore proving that this is correct in general, let\u2019s take a moment to discuss some of the properties of C(n,j), often read \u201cn choose j\u201d. When n is actually a counting number, this really is the number of ways to choose j out of n objects; but we\u2019ve defined things more generally here: n could be a real number, or simply a variable (as in our expression for P).\n\n\n\n\nA key property is that C(n,m) + C(n,m+1) = C(n+1,m+1).\n\nThis is just a matter of algebra:\n\nC(n,m) + C(n,m+1) = (n) \u2026 (n-m+1) / m! + (n) \u2026 (n-m+1)(n-m)/ (m+1)!\n\n= you do this part\n\n= (n+1) (n) \u2026 (n-m+1) / (m+1)! = C(n+1, m+1).\n\n\nThis is precisely why, these are the numbers that fill in Pascal\u2019s triangle: C(n, m) is the mth entry on the nth row.\n\n\n\n\nNow, how hard is our assertion, that our polynomial is the correct one? Not very, really. Suppose we have a difference table with entries on the left ak (on the top row), on down to a0 on the bottom row.\n\nak . . . .\n\n\u00a0ak-1 . . . . .\n\n\u00a0\u00a0\u00a0 . . . . .\n\n\u00a0\u00a0\u00a0\u00a0\u00a0a1 . . . . .\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0a0. . . . .\n\nThen we claim that the jth entry (counting from 0) entries on the ith row (counting up from the bottom 0th row) are given by\n\nPi(j) = a0 C(j,i-0) + a1 C(j,i-1) + . . .\u00a0 + ai C(j,i-i)\n\nTo prove this, we first show it\u2019s true for the bottom row, then the next row up, etc, etc, clicking along like a typewriter from left to right. (This is just induction on i and j)\n\nFor the bottom row, things are pretty easy: all the entries are a0 C(j,0) = a0, so check! Also, on the left of each row, the entry, sure enough is Pi(0) = ai + a1 0 + . . .\u00a0 + ai 0 = ai\n\nsince (C(0,i) = 0, unless i=0 also\u2013 try it!)\n\nSuppose we\u2019ve walked all the way up the spot we care about, on the ith row, jth position. When we get there we will have proven our formula is correct for all the entries below, and for all the entries to the left.\n\nIn particular, when we reach the ith row, jth position, we know that (a) the formula is correct for the entry to the left, and (b) the formula is correct for the entry on the row below, to the left. For (a), the entry is Pi(j-1) and for (b), the entry is Pi-1(j-1)\n\nAll we have to show is that the value we hope is there, namely Pi(j), is what we get when we add (a) to (b), i.e. would be the correct entry in the difference table. So lets try it!\n\nPi(j-1) + Pi-1(j-1) =\n\na0 C(j-1,i-0) + a1 C(j-1,i-1) + . . .\u00a0 + ai-1 C(j-1,1) + ai C(j-1,0) +\n\na0 C(j-1,i-1) + a1 C(j-1,i-2) + . . .\u00a0 + ai-1 C(j-1,0)\n\nGathering our a\u2019s and using our identity, it falls into place, and we get the desired sum:\n\na0 C(j,i-0) + a1 C(j,i-1) + . . .\u00a0 + ai-1 C(j,1) + ai C(j-1,0)\n\nWhat about this last term? C(j-1,0) = 1, as does C(j,0), so we are set. Our total is Pi(j) as promised.\n\n\n\n  1. physicsfreak said,\n\n    January 21, 2009 at 4:27 pm\n\n    Hi, I realize this may be somewhat of an idiotic question, but I cannot for the life of me see /why/ we are using combinations here \u2014 I realize that the method works, but I don\u2019t know how to make it\u2026 intuitive. And what of newton coming up with this? where is it published?\u00a0\n\n    \u2014 Thanks so much for any help.\u00a0\n\n  2. strauss said,\n\n    February 3, 2009 at 7:55 am\n\n    The simplest (quite unsatisfying) answer is just as you say: that it works!\n\n    Let\u2019s see: how to make it intuitive? I am not sure I have a satisfying answer, except to note that the simplest example of this phenomenon is Pascal\u2019s triangle itself: sketch out what happens if the entries on the left of all but the bottom row are 0\u2019s and the entry on the left of the bottom row is 1. Actually draw this out! After a time, a slice of Pascal\u2019s triangle will appear, turned on its side. The entries along the top row will be C(n,k) (where there are k rows); we can think of this as a polynomial in n, or as a combination in n, either way.\n    The more general case is just a linear combination of multiples of this example, for different k\u2019s.\u00a0\n    Don\u2019t know that that is much more satisfying, though!\n    A really terrific reference on closely related topics (particularly, Stirling numbers) is in the beginning of Chapter 1, Vol 1 of Donald Knuth\u2019s The Art of Computer Programming; don\u2019t overlook the exercises!\n    The reference that tipped us off to this, but says less than we have said here, is Martin Gardner\u2019s Colossal Book of Mathematics.\n\nRSS feed for comments on this post \u00b7 TrackBack URL\n\nLeave a Comment\n\nYou must be logged in to post a comment.\n\nThe Math Factor Podcast Website\n\n\nA production of the University of Arkansas, Fayetteville, Ark USA\n\nDownload a great math factor poster to print and share!"}
{"text": "Retrieved from https://www.flyingcoloursmaths.co.uk/common-problem-decimal-division/\nText:\nI\u2019m a big advocate of error logs: notebooks in which students analyse their mistakes. I recommend a three-column approach: in the first, write the question, in the second, what went wrong, and in the last, how to do it correctly. Oddly, that\u2019s the format for this post, too.\n\nThe question\n\nDecimal division: something like 14.4 \u00f7 1.2\n\nWhat went wrong\n\nGot 1.2 instead of 12.\n\nHow to do it right\n\nApproach 1: Estimation. 14 \u00f7 1 is 14, so an answer of 1.2 is way off - 12 seems more reasonable.\n\nApproach 2: Decimal fractions. (A little bit of commentary here: at this point, students normally groan and say \u201cI can\u2019t do fractions\u201d or similar. It would be rude to point out that they clearly can\u2019t yet do decimal division, either.)\n\n  \u2022 Treat the sum as $\\frac{14.4}{1.2}$\n  \u2022 Decide that the bottom is ugly.\n  \u2022 \u201cCancel up\u201d: multiply top and bottom by 10 ((5 works just as well))\n  \u2022 You now have $\\frac{144}{12}$, which is obviously 12.\n\nApproach 3: Fractional fractions. Even a naive approach to dividing fractions is simple here:\n\n$14.4 \\div 1.2 = \\frac{144}{10} \\div \\frac{12}{10}$\n\n$\\frac{144}{10} \\div \\frac{12}{10} = \\frac{1440}{120} = \\frac{144}{12} = 12$.\n\nThere are probably a dozen other ways to approach this. What are your favourites?\n\n* Edited 2017-05-16 to add a category."}
{"text": "Retrieved from http://physics.stackexchange.com/questions/17137/superconductor-levitating-in-earths-magnetic-field/17138\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nCan superconducting magnets fly (or repel the earth's core)?\n\nI've seen superconductors levitating on magnets. But is it possible for superconductors to levitate on Earth from Earth's magnetic field?\n\nshare|improve this question\nAnother duplicate that is arguably better written than the original. Certainly the answer here is superior. Any thoughts from on merging them or leaving them separate? \u2013\u00a0 dmckee Nov 18 '11 at 15:07\nadd comment\n\nmarked as duplicate by Qmechanic, Georg, dmckee Nov 18 '11 at 15:06\n\n\n1 Answer\n\nup vote 4 down vote accepted\n\nThe lift generated by magnetic field B on a superconductor of area S is:\n\n\\begin{equation} F = \\frac{B^2S}{2\\mu_0} \\end{equation}\n\ndisregarding lateral forces and assuming superconducting cylinder (or similar shape) with area S at the top and bottom and height h, we need three forces to remain in the equilibrium: magnetic pressure on top, bottom and gravity force:\n\n\\begin{equation} F_{b} - F_{t} = F_{g} \\end{equation}\n\ndenoting density of the superconductor as \u03c1, Earth' gravity as g and magnetic field at the top and bottom of the object as Bt and Bb, we have\n\n\\begin{equation} \\frac{1}{2\\mu_0}(B_{b}^2-B_{t}^2)=\\rho gh \\end{equation}\n\nassuming the vertical rate of change of magnetic field is nearly constant and denoting the average magnetic field as B, we have\n\n\\begin{equation} -B\\frac{dB}{dz}=\\mu_{0}\\rho g \\end{equation}\n\nCompare with diamagnetic levitation (superconductor's magnetic susceptibility is -1).\n\nNow, Earth magnetic field is between 25 to 65 \u03bcT. For the derivative I have found this survey from British Columbia with upper point on the scale being 2.161 nT/m. Assuming this to be the maximum for vertical derivative we get the required density of 1.1394e-08 kg/m3. For comparison air density at the sea level at 15C is around 1.275 kg/m3, so required density is 8 orders of magnitude smaller.\n\nEven assuming a very high vertical derivative where B goes from its maximum 65 \u03bcT to 0 on 1 m of height results in density required of 0.00034272 kg/m3.\n\nshare|improve this answer\nso it's possible for levitation if the superconductor has maximal area and minimal density? What about metallic hydrogen? I hear that it is the lightest metal in the universe. Though I can't find any numbers.... \u2013\u00a0 mugetsu Nov 17 '11 at 21:33\nWell, you certainly couldn't keep on decreasing the thickness beyond London penetration depth. \u2013\u00a0 Adam Zalcman Nov 17 '11 at 21:51\nthats like in the nm right? Which would be enough in terms of thickness for levitation. \u2013\u00a0 mugetsu Nov 17 '11 at 22:12\nsince a sheet so thin would break easily, it should theoretically work in the same way if instead I had superconductor powder. I'm assuming that each particle is like a very small thin square sheet, so given the right density, these particles can levitate under gravity, even when in close proximity to each other. Is this assumption correct? \u2013\u00a0 mugetsu Nov 17 '11 at 22:22\njust saw your update about the magnetic field obstacle. so in effect, given the perfect material, levitation cannot be achieved practically? quite a shame.... \u2013\u00a0 mugetsu Nov 17 '11 at 22:32\nshow 6 more comments"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214398/the-most-general-meromorphic-function-such-that\nText:\nTake the 2-minute tour \u00d7\n\nSuppose f is meromorphic in a neighborhood of the closed unit disk , that it does not have zeroes nor poles in the open unit disk, and that $|f(z)|=1$ for $|z|=1$. Find the most general such function. Let's denote D = open unit disk\n\nWell, since f has no poles in D, it's holomorphic there, thus by the maximum modulus principle $ |f(z)| < 1$ for $|z|<1$. If f does not have a zero , then we can use the minimum modulus principle, so f attains it's minimum in $\\partial D $ thus $f(z)=1 \\forall z \\in D$ , by analytic continuation $f(z)=1 \\forall$ in where f is defined $ I'm not sure if my solution it's correct :S. I never used the fact that it's analytic in a neighborhood of the closure. I'm missing something?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nActually the conclusion from the minimum modulus principle is $|f(z)| = 1$, not $f(z) = 1$. And the And then you can use the Open Mapping Theorem to say that $f$ is constant.\n\nYou did use the fact that $f$ is continuous on the closed unit disk in applying the maximum and minimum modulus principles.\n\nshare|improve this answer\nYou are completely right, I use the hypothesis that my domain is open , to assert that $f(D)$ is open but contained in $S^1$ Thanks :D! \u2013\u00a0 Daniel Oct 15 '12 at 20:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/72959/metric-for-signal-to-noise-ratio-in-communication-systems?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI'm not quite sure about how to define a good measure of the quality of a communication channel with fading and interference. Let us assume the simplest case, where a node in a network receives the following quantity:\n$$ y = s + w $$\nwhere $s$ is the amplitude (positive real) of the signal and $w$ the noise (gaussian with zero mean and variance $\\sigma^2$). A simple measure of the channel quality is simply given by ${\\rm SNR} = s^2 / \\sigma^2$, i.e., the ratio of the power of the signal vs the power of the noise.\nNow, suppose the received signal is $$ y = h_s s + w$$\nwhere $h_s$ and $w$ are complex gaussian with zero mean and unitary variance. A measure of the SNR that makes sense could be derived by looking at the power of the received signal $$ |y|^2 = y y' = |h_s|^2 s^2 + 2{\\rm Re}(h_ss~w') + |w|^2$$\nnow, since for practical applications the noise process is much faster than the fading (represented by $h_s$) what people normally do is to average over $w$, obtaining\n$$ E[|y|^2]_w = |h_s|^2 s^2 + \\sigma^2 $$\nhence, a measure of the signal strength that makes sense would be $ {\\rm SNR} = |h_s|^2 s^2 / \\sigma^2$.\nWhat I am interested about is the case with interference. Suppose there is an extra term that takes into account for interfering signals\n$$ y = h_s s + h_{\\rm I} s_{\\rm I} + w $$\nwhere $h_I$ is complex with zero mean and unitary variance. How could I possibly define the SNR in this case? By taking $|y|^2$ there are cross terms, i.e., products of $h_s$ and $h_{\\rm I}$ that do not disappear even if I average over the noise $w$. So it seems not obvious to me how to decouple $|y|^2$ into two different pieces, one for the signal and the other for the noise. The final goal would be determining a good measure of the SNR in order to be able to compute probabilities like\n\n$$ P({\\rm SNR} \\geq \\gamma_0).$$\n\nshare|improve this question\nif one can assume that $h_I$ is uncorrelated with $w$ and $h_s$, then you could just average $\u2223y\u2223^2$ over both $h_I$ and $w$; cross terms would still vanish; this is not what you want? \u2013\u00a0 Carlo Beenakker Aug 16 '11 at 13:47\nyes I know, but typically, the $h$ terms vary more slowly than the noise $w$. So averaging over $h$ is not that practical. \u2013\u00a0 Bob Aug 16 '11 at 22:37\n\n1 Answer 1\n\nThe general case is not known. If you find the correct information theoretic metric for the interference channel, you can find the capacity of interference channels (an open problem since the 1960s).\n\nIn your case, it looks like a MAC channel. Decode the stronger signal first and then decode the weaker one. Assuming you have a powerful code underneath, Euclidean distance as metric suffices.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/297594/diophantine-equation-to-characterize-natural-numbers\nText:\nTake the 2-minute tour \u00d7\n\nLet's consider $$\\Bbb N=\\{0,1,2,3,\\ldots\\},$$ and, for each $k\\in\\{1,2,3,\\ldots,\\}$, let $$o_k=2k-1$$ be the sequence of odd natural numbers.\n\nGiven that for each $m\\in\\Bbb N$, if $a$ is odd, the number $$m(m+a)$$ is even, it is easy to see that $$\\begin{align*} (x+y)^2 + y + 3x &= x^2 + 2xy + y^2 + y + 3x\\\\ &= x(x+3) + y(y+1) + 2xy \\end{align*}$$ is even.\n\nAssuming that for arbitrary $x_1,\\ldots, x_k\\in\\Bbb N$, the number $$(x_1+\\cdots + x_k)^2+x_k+3x_{k-1}+\\cdots +o_kx_1$$ is even, we have that $$\\begin{align*} & (x_1+\\cdots + x_{k+1})^2+x_{k+1}+3x_k+\\cdots +o_kx_1\\\\ &\\qquad = (x_1+\\cdots + x_{k})^2 +2(x_1+\\cdots + x_{k})x_{k+1}+ x_{k+1}^2 + x_{k+1} + (x_k+\\cdots + o_kx_{1}) +2(x_1+\\cdots + x_{k}) \\\\ &\\qquad = (x_1+\\cdots + x_{k})^2 + (x_k+\\cdots + o_kx_{1}) + x_{k+1}(x_{k+1}+1) + 2(x_1+\\cdots + x_{k})(x_{k+1}+1) \\end{align*}$$ is even.\n\nTherefore by induction, for each $k\\geq 2$ we have that $$\\frac1{2}\\left[(x_1+\\cdots + x_k)^2+x_k+3x_{k-1}+\\cdots +o_kx_1\\right]$$ is indeed a natural number.\n\nBut, does this describes all natural numbers?\n\nI mean, for a given $n\\in\\Bbb N$, does the equation $$(x_1+\\cdots + x_k)^2+x_k+3x_{k-1}+\\cdots +o_kx_1=2n$$ have exactly one solution $(x_1,\\ldots,x_k)\\in\\Bbb N^k$?\n\nshare|improve this question\nIf that is the case it would be a possible answer to this question. \u2013\u00a0 leo Feb 7 '13 at 23:25\nNotice that your formula fails for $k=1$. \u2013\u00a0 JSchlather Feb 7 '13 at 23:33\nIf $m=2$ and $a=3$ then $a$ is odd, but $m(m+a)=10$ is even. \u2013\u00a0 Joe Johnson 126 Feb 7 '13 at 23:36\n@JacobSchlather that's because the induction starts with $k=2$. \u2013\u00a0 leo Feb 7 '13 at 23:54\nFor $k=3$ the value is $f(x_1,x_2,x_3)=(x_1+x_2+x_3)^2+x_3+3x_2+5x_1$ and we have $f(0,0,2)=f(1,0,0)=6$. Or am I getting the definition wrong somehow? \u2013\u00a0 coffeemath Feb 8 '13 at 7:12\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nThe \"Cantor pairing function\" is $f(x,y)=(1/2)[(x+y)^2+3x+y]$ and is known to give a one-to-one correspondence between $N \\times N$ and $N$. This is the function of the OP for $k=2$.\n\nIt is a conjecture that this $f(x,y)$ and it's flip $f(y,x)$ are the only polynomials with real coefficients that give such a one-to-one correspondence.\n\nThere is a result, the Fueter-Polya Theorem, that says these are the only quadratic polynomials with real coefficients that, when restricted to $N \\times N$, map it one-to-one onto $N$. The proof is quite involved, see for example Craig Smorynski's book \"Logical Number Theory I\", chapter 1, sections 3,4,5.\n\nOf course it is relatively easy to verify these pairing functions do what one wants, the difficulty is showing they are the only ones that work, among polynomials.\n\nAs I noted in a comment, it seems your attempt to extend this doesn't quite work. That is, you seem to be extending the Cantor pairing function, in the specific case of $N \\times N \\times N$, to the function $$f(x,y,z)=(1/2)[(x+y+z)^2+z+3y+5x].$$ However with this $f$ we have $f(1,0,0)=f(0,0,2)=6/2=3$. And also $f(0,0,3)=f(1,1,0)=6,$ and probably a lot of other collisions.\n\nIt would indeed be interesting, in my opinion, if the function could be adjusted even to the three variable case. Of course one can soup one up by defining $g(x,y,z)=f(f(x,y),z)$ (or something like that) but that is the same as one of the usual definitions of ordered triples via a previous definition of ordered pairs.\n\nADDED: There is an \"order of magnitude\" problem with trying to represent $n$-tuples distinctly by a quadratic function. Take for example the case of representing triples. Consider all triples $x,y,z$ with $x,y,z \\le N$. There are $(N+1)^3$ of these triples. No quadratic function can work to distinctly represent these. For example if $x,y,z \\le N$ then the function $f(x,y,z)=(1/2)[(x+y+z)^2+z+3y+5x]$ is bounded above by $(1/2)[(3N)^2+9N]$ and as $N \\to \\infty$ cannot represent distinctly $(N+1)^3$ triples. This order of magnitude problem gets worse for $k$-tuples as $k=4,5,6...$.\n\nI think to represent $k$- tuples one would need the polynomial to be of degree at least $k$ because of order of magnitude issues.\n\nA Stab at triples (and beyond): Let $C(m,k)$ denote the binomial coefficient, where we understand that if $m<k$ then $C(m,k)=0.$ Then the following (I think) maps the triples in $N^3$ one-to-one onto $N$: $$f(x,y,z)=C(x+y+z+2,3)+C(x+y+1,2)+C(x,1).$$ Note that this is in a way a natural extension of the Cantor pairing, since one form of that pairing is $C(x+y+1,2)+C(x,1).$\n\nFor 4-tuples the idea would be $$f(w,x,y,z)=C(w+x+y+z+3,4)+C(w+x+y+2,3)+C(w+x+1,2)+C(w,1),$$ and generally for $k$-tuples the pattern would start with a coefficient $C(s+k-1,k)$ where $s$ is the sum of the tuple, then $C(t+k-2,k-1)$ where $t$ is the sum of the first $k-1$ entries of the $k$-tuple, and so on.\n\nI haven't (yet) come up with a proof that these maps indeed take the $k$-tuples one-to-one onto $N$, but have checked that the $k=3$ case works for an initial segment of triples, by going through the triangular parts $x+y+z=const$ one at a time, enumerating each in turn.\n\nshare|improve this answer\nThanks for your answer and if you got some reasonable way to represent $k$-tuples, please let us know :-) \u2013\u00a0 leo Feb 8 '13 at 13:11\nHave a look at the stuff labelled \"A stab at triples and beyond\" just added at the end. I have a feeling these must be known, since it seems a natural extension. Or maybe they don't work :( \u2013\u00a0 coffeemath Feb 8 '13 at 13:24\n\nSince $f(x,y)=\\frac12[(x+y)^2+3x+y]$ is a bijection $\\Bbb N\\times\\Bbb N\\leftrightarrow\\Bbb N$, we get that $g(u,v,w)=f(f(u,v),w)$ is a bijection $\\Bbb N^3\\leftrightarrow\\Bbb N$. However, $g$ is of degree $4$ for $3$ variables.\n\nStill, notice that for $k=2^r$ we can construct a bijection $h_r:\\Bbb N^{2^r}\\leftrightarrow\\Bbb N$ that is of degree exactly $2^r$ in all variables, by putting:\n\n  1. $h_0(x)=x$\n  2. $h_{r+1}(x_1,\\dots,x_{2^{r+1}})=f(h_r(x_1,\\dots,x_{2^r}), h_r(x_{2^r+1},\\dots,x_{2^{r+1}}))$\nshare|improve this answer\nMaybe studing the behaviour of the coefficients in polynomials $h_r$ it is possible to think out a \"nice\" polynomial for arbitrary number of variables, not just 2-powers. \u2013\u00a0 tohecz Feb 8 '13 at 17:49\nI think for example for $k=3$ we can get by with third degree polynomial, as in my inserted part of answer I gave. However I don't have a proof that it works, only numeric evidence by trying lots of triples. +1 \u2013\u00a0 coffeemath Feb 8 '13 at 18:06\nrelated \u2013\u00a0 leo Feb 9 '13 at 2:53\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/16796/choosing-seats-for-guests\nText:\nTake the 2-minute tour \u00d7\n\nYou have a circular table with $N$ seats.$K$ bellicose guests are going visit your house of-course you don't want them to sit beside each other.As the host, you want to find out how many ways there are to choose $K$ seats such that none of them is adjacent to each other.\n\nI noticed that there is a solution other than $0$ if ($N \\ge 2K $) but I am not sure how to approach for the rest.\n\nEDIT: Only $K$ bellicose guests are visiting,no friendly guest are there the remaining $N-K$ seats will be vacant.\n\nA possible mathematical translation of this problem: Choosing $K$ candidate points from a circle of $N$ indistinguishable points such that there are more than one vacant point between adjacent candidate points.\n\nshare|improve this question\nUp to rotation or not? If not, try fixing K and seeing if you can write down a recurrence in terms of N. \u2013\u00a0 Qiaochu Yuan Jan 8 '11 at 13:46\n@ Qiaochu Yuan: Please rephrase, I don't understand what you meant by \"Up to rotation or not\". \u2013\u00a0 Quixotic Jan 8 '11 at 13:48\nQiaochu is asking (since the table is circular) whether your count of solutions should treat a rotation of a solution as another solution (or just count rotationally equivalent solutions as one). Also notice that you've misstated the inequality: should be $N \\ge 2K$ to get solutions. \u2013\u00a0 hardmath Jan 8 '11 at 14:38\n@hardmath: I am not sure whether the clock-wise or anticlockwise solution are treated different of not. \u2013\u00a0 Quixotic Jan 8 '11 at 14:45\nRight, I'd assume those (reflections) are counted differently, although of course \"who sits next to whom\" will be the same. A reflection is never a rotation except for the trivial case N=2, so there's not really a conflict in saying we want to identify rotationally equivalent solutions but distinguish reflections. \u2013\u00a0 hardmath Jan 8 '11 at 15:13\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nChoose a seat $S$, and a bellicose guest $B$. Sit $B$ in $S$, and tell them not to move, whether they like it or not. That done, there are $(K-1)!$ ways of ordering the remaining bellicose guests clockwise around the table, and $F!$ ways of ordering the friendly guests (here I am using leonbloy's notation $F = N - K$). For each such ordering, we have to choose a pattern of the form $f...b...f...b...f$. This pattern:\n1. starts and ends with $f$ (so that $B$ is isolated);\n2. contains $(K-1)$ $b$'s and $F$ $f$'s; and\n3. contains no two adjacent $b$'s.\n\nBut the number of such patterns is the same as the number of patterns that\n1. start with $f$; and\n2. contain $(K-1)$ $b$'s and $(F-K+1)$ $f$'s.\n\n(To see this, just replace each instance of $bf$ in the original pattern by $b$.) The number of such patterns is the binomial coefficient $\\binom{F-1}{K-1}$. So we end up with:\n\n$(K-1)!F!\\binom{F-1}{K-1} = \\frac{F!(F-1)!}{(F-K)!}$\n\nThis is the number of seating arrangements with guest $B$ in seat $S$. Multiply by $N$ to get the total number.\n\nEdit Reading the question more carefully, it asks for the number of (what I call here) patterns, not the number of seatings. For each pattern, there are $K!F!$ seatings, so the answer is\n\n$N\\frac{F!(F-1)!}{(F-K)!}/(K!F!) = \\frac{N(F-1)!}{(F-K)!K!}$\n\nshare|improve this answer\nSeems right to me. Just to clarify: \"This is the number of seating arrangements with guest B in seat S\" means: with \"a particular B guest (say b1) in seat S\", not \"with some belicose guest in seat S\". \u2013\u00a0 leonbloy Jan 9 '11 at 0:13\n@leonbloy: I suggest that my answer was perfectly clear on that point. I think you must have forgotten the first two sentences by the time you reached the last two. \u2013\u00a0 TonyK Jan 9 '11 at 0:22\nIn TonyK's counting the seats have name tags. If you only distinguish between white and black seats you have a different problem, see my former comment on this question. Maybe the proposer should clarify this point. \u2013\u00a0 Christian Blatter Jan 9 '11 at 11:59\nLet $N = 4$ and $K = 2$ we get $F = 2$ then your formula is giving $2 \\times N = 8$ but given answer is $2$. \u2013\u00a0 Quixotic Jan 9 '11 at 12:28\n@Christian Blatter: My first result is the number of seating arrangements with B in S, which is the same as the number of seating arrangements counting rotations (but not reflections) as identical. Now just multiply this by N to get the number of seating arrangements counting rorations as distinct. No special Polya theory is required. \u2013\u00a0 TonyK Jan 9 '11 at 12:29\n\nLet's call $F=N-K$ number of \"friendly\" guests. And let's call $S(F,K)$ the count of seating ways assuming that seats and guests are distinguible (rotations are distinct solutions).\n\nWe know that $F \\ge K$. For the limit case $F = K$ we have $S(F,K) = 2 K (K-1)! K! = 2 K!^2$.\n\nNow, the recursion: we count the number of ways when adding a friendly guest:\n\n$S(F+1,K) = (F+K+1) S(F,K)$\n\nFrom this (if it's correct!) you can get an explicit solution.\n\nUpdate: this is not correct. See TonyK's answer\n\nshare|improve this answer\nI don't think your recursion is right. Adding a friendly guest between two bellicose guests can transform an invalid seating into a valid one. Also it doesn't agree with the formula in my answer :-) \u2013\u00a0 TonyK Jan 8 '11 at 20:02\n@TonyK: you're right \u2013\u00a0 leonbloy Jan 9 '11 at 0:00\nNo friendly guests are there,please read my question. :-) \u2013\u00a0 Quixotic Jan 9 '11 at 15:04\n\nYour Answer"}
{"text": "Retrieved from http://cstheory.stackexchange.com/questions/14675/is-there-some-mathematical-closed-form-or-somewhat-tight-asymptotic-one-for-g\nText:\nTake the 2-minute tour \u00d7\n\nThe following brief description of the known \"Google Eggs Puzzle\" comes mainly from the web site Google Eggs:\n\nGoogle Eggs Puzzle: Given n floors and m eggs, what is the approach to find the highest floor from which eggs can be thrown safely, while minimizing the throws (not broken eggs).\n\nThe so called \"highest floor\" in the above problem deserves more formal definition:\n\n\"highest:\" there must be a floor f (in any sufficiently tall building) such that an egg dropped from the f th floor breaks, but one dropped from the (f-1)st floor will not. Then, f-1 here is the highest floor.\n\nActually, the description of \"highest\" is an excerpt from the book \"The Algorithm Design Manual (Second Edition)\" by Steven S. Skiena. Being an exercise in Chapter 8 \"Dynamic Programming\", there are plenty of resources in Web devoted to solving the puzzle by the means of dynamic programming, like Google Eggs and The Two Egg Problem.\n\nHowever, there is a question from the above book:\n\nShow that $E(n, m) = \\Theta(n^{\\frac{1}{m}})$, where $E(\\cdot)$ is the minimum number of throws. (Note: I have changed the notations used in book for consistency.)\n\nIt is the question that motivates my problem:\n\nMy Problem: Is there some mathematical closed form for general \"Google Eggs Puzzle\" with n floors and m eggs, instead of dynamic programming recurrence, and of course tighter than the $E(n, m) = \\Theta(n^{\\frac{1}{m}})$ one?\n\nshare|improve this question\nI don't think the asymptotic bound is tight. It works when $m$ is a constant, but if you take $m = \\log n$, your bound gives you a constant, which is false. I think a tight bound is $\\Theta(\\min_{k\\leq m} kn^{1/k})$, which reproduces your bound for constant $m$, but also gives $\\log n$ as the number of throws when $m$ is large enough to support the naive binary search based strategy. \u2013\u00a0 Robin Kothari Dec 9 '12 at 15:40\n@RobinKothari I agree with you. The numerical experiments in the material Joy of Egg-Dropping support your observation. However, I don't catch the meaning of $\\Theta(\\min_{k \\le m} kn^{\\frac{1}{k}})$. As my guess, the parameter $k$ is the actual number of eggs in use. Then, what does it mean as a factor in $kn^{\\frac{1}{k}}$ ? Thanks a lot. \u2013\u00a0 hengxin Dec 12 '12 at 1:23\nI can try to explain the meaning, but it's a bit long so I'll post it as an answer. \u2013\u00a0 Robin Kothari Dec 12 '12 at 3:36\n\n2 Answers 2\n\nup vote 8 down vote accepted\n\nWith m eggs and k measurements the most floors that can be checked is exactly $$n(m,k)={k \\choose 0} + {k \\choose 1} + \\ldots + {k \\choose m},$$ (maybe $\\pm 1$ depending on the exact def). Proof is trivial by induction. This expression has no closed form inverse but gives good asymptotic.\n\nshare|improve this answer\nJust sketching the dropping strategy a little would make the answer more complete. Maybe it's not appropriate, since I guess it's not research-level. Anyway, with 2 eggs, you can skip $k$ floors on your first drop, and if it doesn't break, skip $k - 1$, and if it doesn't break skip $k - 2$, etc. Which gives $k(k+1) / 2$ as the highest floor you could reach using this strategy. \u2013\u00a0 Joe Dec 10 '12 at 23:58\n@domotorp It seems constructive to examine the puzzle from the perspective you have just shown. And the equation about $n(m,k)$ can be proved by induction on $m$ and $k$. Although there is no clear closed form for the right hand side of this equation, can it give the asymptotic expression $k(n,m) = \\Theta(n^{\\frac{1}{m}})$? \u2013\u00a0 hengxin Dec 11 '12 at 13:45\n@hengxin, yesish, because $\\binom{k}{m}$ is a polynomial in $k$ of degree $m$, so this shows that holding $m$ constant gives $n(m, k) = \\Theta(k^m)$. But see Robin's comment on the question. The more interesting question is whether this exact expression allows a more precise bound by approximating the binomial tail e.g. with erf. \u2013\u00a0 Peter Taylor Dec 11 '12 at 13:51\n\nIn my comment above I said perhaps $\\Theta(\\min_{k \\le m} kn^{\\frac{1}{k}})$ is a tight bound. I'm not sure about the lower bound, but since you just want an explanation for what $k$ means, I can explain the intuition using the upper bound.\n\nAs you guessed, $k$ is the number of eggs actually used. That explains the $\\min$ on the outside. Now once we've decided to use $k$ eggs, here's a strategy that works: Think of the number $n$ as being written out in base $n^{1/k}$. So $n$'s representation will have $k$ \"digits\" (the word \"digit\" is usually reserved for base 10, but I'll use it here), and each digit holds a value from 0 to $n^{1/k}-1$. With our $k$ eggs, we're trying to extract the digits of $n$ one by one. First we start with the most significant digit. This can be determined by throwing an egg from the floor numbered $100..00$, $200..00$, and so on. After at most $n^{1/k}-1$ throws, we've learnt what the most significant bit is, and in the worst case we've broken only 1 egg. Now we do this for all the other digits. Since there are $k$ digits, we'll need $O(kn^{1/k})$ throws.\n\nAs a sanity check, observe that when $k=1$, this strategy boils down to dropping eggs from each floor one by one starting from floor 1. When $k = \\log n$, we're just working in base 2. So this yields the binary search algorithm.\n\nshare|improve this answer\nAn interesting feature of domotorp's solution, unlike yours, is that it does not require knowing n in advance! \u2013\u00a0 J\u025b\ufb00E Dec 12 '12 at 4:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55526/example-of-a-variety-with-k-x-mathbb-q-cartier-but-not-cartier?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI know the definition of $K_X$ on a normal, singular variety, but I don't have a good set of examples in my mind. What's an example of a variety where $K_X$ is $\\mathbb Q$-Cartier but not Cartier? Are there any conditions under which an adjunction formula lets me compute the canonical class of a singular divisor?\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 18 down vote accepted\n\nAn easy way to produce a $\\mathbb Q$-Cartier but not Cartier canonical divisor is by a quotient. For instance for the quotient $$X=\\mathbb A^3/(x,y,z)\\sim (-x,-y,-z)$$ $2K_X$ is Cartier, but $K_X$ is not.\n\nI leave it for you to prove that $2K_X$ is Cartier. Here is how to see that $K_X$ is not: Clearly $X={\\rm Spec}k[x^2,y^2,z^2,xy,yz,xz]$ in other words, $X$ is the affine cone over the Veronese surface $\\mathbb P^2\\simeq V\\subset \\mathbb P^5$. Blowing up the cone point gives a resolution of singularities $\\pi: Y\\to X$ with exceptional divisor $E\\simeq V$. In fact $E^2\\sim -2L$ where $L$ is the class of a line. This follows by considering the blow up as a blow up of the ambient $\\mathbb A^6$ (the cone over $\\mathbb P^5$) and noticing that $\\deg V=2$ in $\\mathbb P^5$ so the square of the exceptional divisor of the blow up of $\\mathbb A^6$, which is $-1$-times the hyperplane in $\\mathbb P^5$ restricts to $-2L$ on $Y$. Now write $K_Y\\sim_{\\mathbb Q} \\pi^*K_X + aE$ and use the adjunction formula ($Y$ is smooth!) to get $$ (a+1)E^2\\sim K_E=K_{\\mathbb P^2} \\sim -3L. $$ Solving for $a$ shows that $a=\\dfrac 12$ which shows that $K_X$ cannot be Cartier.\n\nInteresting to note that the same construction does not give a desired example in dimension $2$: The quotient $\\mathbb A^2/(x,y)\\sim(-x,-y)$ is a cone over a conic which is a surface in $\\mathbb P^3$. In particular it is Gorenstein and hence $K_X$ is Cartier.\n\nAs for the adjunction formula, it definitely works as long as $K_X+D$ is Cartier and it works up to torsion if it is $\\mathbb Q$-Cartier. If it is not $\\mathbb Q$-Cartier, it is not clear what the adjunction formula should mean, but even then one can have a sort of adjunction formula involving $\\mathscr Ext$'s but this is almost Grotherndieck Duality then.\n\nshare|improve this answer\nSandor, I'm confused, you still have some sort of adjunction formula (in my answer below). What you might have trouble with is saying things like $n(K_Y + K_X)|_X = n K_X$ (one doesn't have equality in general), but that's a slightly different issue in my mind. \u2013\u00a0 Karl Schwede Feb 15 '11 at 16:36\nKarl, I think we agree in the essence, it's a matter of terminology. My main point was that if it is not $\\mathbb Q$-Cartier, then one has to be careful what the restriction means. \u2013\u00a0 S\u00e1ndor Kov\u00e1cs Feb 15 '11 at 16:42\nAh, or perhaps you intended, $K_X + D$. It's not quite clear what the original questioner meant. \u2013\u00a0 Karl Schwede Feb 15 '11 at 16:55\nYes and yes. I need a personal error-catcher... \u2013\u00a0 S\u00e1ndor Kov\u00e1cs Feb 15 '11 at 16:57\nGreat, thank you for the answer! I think the -2 in the displayed adjunction should read -3, but indeed a=1/2. \u2013\u00a0 Anonymous Feb 15 '11 at 17:21\n\nProbably the easiest example is $X = \\text{Spec} \\; k[x^3, x^2y, xy^2, y^3]$. In this case, $K_X$ is not Cariter, but $3K_X$ is Cartier.\n\nIn what way do you have in mind computing the canonical class of a singular divisor? The adjunction formula basically always works assuming things are sufficiently normal.\n\nIn particular, one always has the following sequence if you assume that $X$ is a divisor in a normal ambient variety $Y$. $$0 \\to \\omega_Y \\to \\omega_Y(X) \\to \\omega_X \\to h^1(\\omega_Y^{\\bullet}) \\to \\dots .$$\n\nIf $Y$ is Cohen-Macaulay, then the $h^1$ vanishes, if $X$ is normal, then $\\omega_X$ can be viewed as a divisor class, and we've obtained some sort of adjunction formula. However, we don't really need those hypotheses.\n\nMore generally if $Y$ is normal but not necessarily Cohen-Macaulay, it is Cohen-Macaulay outside a set of codimension at least 3 (because $Y$ is S2). Thus $h^1(\\omega_Y^{\\bullet})$ (the first cohomology of the dualizing complex of $Y$) is supported at a codimension 3 (or more) subset. In particular, the map $\\omega_Y(X) \\to \\omega_X$ is surjective in codimension 2 on $Y$ and so surjective in codimension 1 on $X$.\n\nThis is enough to compute the canonical class of $X$ because $\\omega_X$ is always S2 (if $X$ is S1, which a reduced scheme is). Thus $\\omega_X$ is determined by its codimension 1 behavior, which we can completely determine by the above short exact sequence.\n\nEDIT: This sort of restriction stuff is certainly contained in chapter 16 of Koll\u00e1r et al's \"Flips and abundance for algebraic threefolds.\" book.\n\nEDIT2: One should be slightly careful about saying $(K_Y + X)|_X = K_X$. It can be a little hard to make sense of the restriction of $K_Y + X$ when $K_Y + X$ isn't Cartier or $\\mathbb{Q}$-Cartier (at least at the codimension 1 points of $X \\subseteq Y$). This is what S\u00e1ndor is talking about. However, you always have the exact sequence above and so one can always in some sense still compute $\\omega_X$.\n\nshare|improve this answer\nThe dot on your dualizing complex is barely visible, but I am not sure what one can do about it. :( I have a macro named \\kdot to produce a better looking dot, but it might be too elaborate for the online LaTeX engine. (\\kdot=\"Karl's dot\" :) \u2013\u00a0 S\u00e1ndor Kov\u00e1cs Feb 15 '11 at 16:47\nSandor, thanks. I made it a \\bullet, I suspect the rendering here would probably die on the circle command I/we usually use for those dots. \u2013\u00a0 Karl Schwede Feb 15 '11 at 16:52\nThanks for the latest edit! \u2013\u00a0 S\u00e1ndor Kov\u00e1cs Feb 15 '11 at 16:58\nAh, thanks for the help! That clears up my adjunction confusion. \u2013\u00a0 Anonymous Feb 15 '11 at 17:22\n\nHere is a more algebraic perspective on your question. If $X=\\text{Spec} (R)$ is affine and $R$ is a Cohen-Macaulay algebra over some field (the following is true in more general setting), then $K_X$ is Cartier is equivalent to $R$ is Gorenstein. On the other hand, $K_X$ is $\\mathbb Q$-Cartier is the same as the class of $K_X$ is torsion in the divisor class group (assuming $R$ is normal).\n\nSo to find a class of examples, you need normal Cohen-Macaulay rings with torsion class group but not Gorenstein. If $R$ is a Veronese $S^{(d)}$ of $S=\\mathbb C[x_1,\\cdots, x_n]$ then $Cl(R)$ is always torsion, but $R$ is Gorenstein if and only if $d|n$ (Sandor's example is indeed the simplest one in this class, with $d=2, n=3$).\n\nshare|improve this answer\nKarl, you are right, I am just about to add Cohen-Macaulay \u2013\u00a0 Hailong Dao Feb 15 '11 at 16:53\nLong, by the way this is just a question of terminology (and I know different people ahve differing opinions on this), when you say $\\mathbb{Q}$-Gorenstein, do you always assume Cohen-Macaulay? \u2013\u00a0 Karl Schwede Feb 15 '11 at 17:04\nKarl, I think generally $\\mathbb Q$-Gorenstein does not mean Cohen-Macaulay, but this is confusing for many. I know that when I first saw it as a graduate student, I did not understand the difference between $1$-Gorenstein and Gorenstein. The main problem is that many people do not realize that this is even an issue. I was once asked after a talk why I kept saying that $K_X$ was Cartier instead \"simply\" saying that $X$ was Gorenstein... As far as \"quasi-Gorenstein\" is concerned I always thought it was only known by commutative algebraists, but apparently it is not even widely known among them. \u2013\u00a0 S\u00e1ndor Kov\u00e1cs Feb 15 '11 at 20:07\nOne more thing about this: Koll\u00e1r very much dislikes the accepted usage of $\\mathbb Q$-Gorenstein. He thinks it should mean $K_X$ is $\\mathbb Q$-Cartier and $X$ is Cohen-Macaulay. I agree with that, but I think it is too late for that. \u2013\u00a0 S\u00e1ndor Kov\u00e1cs Feb 15 '11 at 20:08\n@Sandor: +1 for \"most people do not realize that this is even an issue\". As for quasi-Gorenstein, I think it is a bit unfair to deduce from my ignorance that it is not well-known among commutative algebraists (-: May be they all know it, just didn't tel me! \u2013\u00a0 Hailong Dao Feb 15 '11 at 20:14\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/59212/deriving-torque-from-euler-lagrange-equation\nText:\nTake the 2-minute tour \u00d7\n\nHow could you derive an equation for the torque on a rotating (but not translating) rigid body from the Euler-Lagrange equation? As far as I know from my first class in Classical Mechanics, there is no potential defined for a rotating body, so the only term I see in the Lagrangian is the $\\frac{1}{2}I\\omega^2$. Since there is no $\\theta$, I'm just getting that torque always equals $0$.\n\nshare|improve this question\nIt depends how the body is fixed in space. If it is floating, there's no torque and the angular momentum is conserved. But if the body is supported by a pedestal or something like that, the potential energy $mgh$ where $h$ is the height of the center of mass effectively does depend on the angle $\\phi$ and the derivative of this potential energy with respect to the angle gives you torque. \u2013\u00a0 Lubo\u0161 Motl Mar 27 '13 at 15:26\nComment to the question (v1): It is still possible to define the potential energy $V$ of a torsion spring, so that angular system has a Lagrangian formulation. \u2013\u00a0 Qmechanic Mar 27 '13 at 15:30\nHow does height depend on theta (The angle between the applied force and the radius)? Knowing torque should equal |F||R|sin(theta), the potential should then equal |F||R|cos(theta). If |F||R|cos(theta) = mgh = |F|*h, that would imply that the height is less than the radius. -- What am I missing here? \u2013\u00a0 JLA Mar 27 '13 at 16:16\nYou know you need to refine the rotation with generalized coordinates (like Euler angles) which will yield generalized forces (torques). \u2013\u00a0 ja72 Aug 20 '13 at 14:32\nadd comment\n\n1 Answer\n\nThe question isn't clear to me, the torque is zero if there's not an applied torque, and it's nonzero if it's not zero, but that's just a tautology. Do you mean that you just want to derive something/anything torque-esque given an applied force? If so, here's one way.\n\nThis isn't a job for a potential, it's the job for a generalized force. Consider the 2d case, with a particle at some position $s=(x,y)$, with mass $m$ and a force vector $F$ applied to it.\n\nThe first form of the Euler-Lagrange equations I learned was the form:\n\n$$\\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_i}-\\frac{\\partial T}{\\partial q_i}=Q_i$$ where $T$ is the kinetic energy (NOT the lagrangian), $q_i$ are the parameters describing the system, and $Q_i$ is defined as the generalized force $Q_i=\\sum_j F_j \\frac{\\partial s_j}{\\partial q_i}$. (Goldstein classical mechanics ch 1)\n\nThen, parameterizing in terms of polar coordinates, we can define $s=(q_1 \\cos(q_2),q_1 \\sin(q_2))$.\n\nGoing through the motions of finding the kinetic energy, generalized forces, and partial derivatives:\n\n$\\dot{s}=(\\dot{q_1}\\cos(q_2)-q_1\\sin(q_2) \\dot{q_2},\\dot{q_1}\\sin(q_2)+q_1\\cos(q_2) \\dot{q_2})$\n\n\n\n$Q_1=F\\cdot(\\cos(q_2),\\sin(q_2))\\equiv F_r$ (define $F_r$ this way)\n\n$Q_2=F\\cdot(-q_1\\sin(q_2),q_1\\cos(q_2))\\equiv \\tau$ (define $\\tau$ this way)\n\nEuler-Lagrange equation for $q_1$:\n\n$\\ddot{q_1}m-m\\dot{q_2}^2 q_1=F_r$\n\nfor $q_2$:\n\n$\\frac{d}{dt}(m q_1^2 \\dot{q_2})-0=\\tau =m q_1^2 \\ddot{q_2}+2 m q_1 \\dot{q_1} \\dot{q_2}$\n\nDenoting $q_1=r$, $q_2=\\theta$ for clarity's sake, we wind up with the equations: $$m\\ddot{r}-m r \\dot{\\theta}^2=F_r$$ $$m r^2 \\ddot{\\theta}+2 m r \\dot{r} \\dot{\\theta}=\\tau$$\n\nFrom which we can identify the torque and whatever we want. If $r$ is constant, we have $F_r=-m v^2/r$, and identifying $m r^2 \\dot{\\theta}=L$ with the angular momentum, we see $\\dot{L}=\\tau$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/12949/are-there-as-many-real-closed-fields-of-a-given-cardinality-as-i-think-there-are?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\kappa$ be an infinite cardinal. Then there exists at least one real-closed field of cardinality $\\kappa$ (e.g. Lowenheim-Skolem; or, start with a function field over $\\mathbb{Q}$ in $\\kappa$ indeterminates, choose an ordering and a real-closure).\n\nBut I think there are many more, namely $2^{\\kappa}$ pairwise nonisomorphic real-closed fields of cardinality $\\kappa$. This is equal to the number of binary operations on a set of infinite cardinality $\\kappa$, so is the largest conceivable number.\n\nAs for motivation -- what can I tell you, mathematical curiosity is a powerful thing. One application of this which I find interesting is that there would then be $2^{2^{\\aleph_0}}$ conjugacy classes of order $2$ subgroups of the automorphism group of the field $\\mathbb{C}$.\n\nAddendum: Bonus points (so to speak) if you can give a general model-theoretic criterion for a theory to have the largest possible number of models which yields this result as a special case.\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 14 down vote accepted\n\nHi Pete!\n\nThere's been a lot of study of this and similar problems. I believe that Shelah's theorem, from his 1971 paper \"The number of non-isomorphic models of an unstable first-order theory\" (Israel J. of Math) answers your question about real closed fields in the positive.\n\nThe best big result on such questions that I know of is in the 2000 Annals paper \"The uncountable spectra of countable theories.\" by Hart, Hrushovski, Laskowski.\n\nTo answer the question on real closed fields specifically (and somewhat cautiously since I'm not a model-theorist):\n\nThe theory of real closed fields is a complete first order theory, with countable language. It is an unstable (an easy fact, I think, and explained better on wikipedia than I could explain) theory as well. Hence Shelah's result applies, and the bound $2^\\kappa$ is realized as you surmised.\n\nBonus points should go to Shelah (and perhaps also to Hart, Hrushovski, Laskowski, whose paper mentions the result of Shelah and proves other things) for proving that this bound is realized (for uncountable cardinals), except for theories $T$ which have all of the following properties:\n\n  1. $T$ has infinite models.\n  2. $T$ is superstable.\n  3. $T$ has prime models over pairs.\n  4. $T$ does not have the dimensional order property.\n\nI have no clue what the fourth property means. But there are plenty of non-superstable theories to which Shelah's theorem applies, and hence which realize your bound (for uncountable cardinals).\n\nFor countable cardinality, I think there are still some open problems about how many non-isomorphic models there can be of a given theory, with cardinality $\\aleph_0$.\n\nshare|improve this answer\nHi, Marty. Funny that the guy who introduced me to model theory in the first place answers my question. I think I must have been dimly aware of some result like this, or I wouldn't have asked. Thanks! \u2013\u00a0 Pete L. Clark Jan 26 '10 at 0:47\nHi Pete. Thought that your question was a good way to start my Math Overflow contributions. (Your question about transcendental Galois theory is still on my mind too) \u2013\u00a0 Marty Jan 27 '10 at 1:12\n+1: As a model theorist who is familiar with Shelah's work in this area, I can assure you that this is correct: Shelah's result gives you that this theory has the maximal number of models in any uncountable cardinality. This is simply because the theory is unstable, since any model is infinite and has a definable strict linear ordering on the universe (unstability is actually a somewhat more general condition than this). Shelah's theorem cannot apply to the countable models -- consider the theory of the linear ordering on the rational numbers, which is aleph-0-categorical, yet unstable. \u2013\u00a0 John Goodrick Jan 27 '10 at 2:59\n... also, Shelah's theorem is only about theories in a countable language (which is no problem for this example, of course). Theories in uncountable languages are still mysterious to us. \u2013\u00a0 John Goodrick Jan 27 '10 at 3:00\nAs for the number of countable models, there is really only one open question left (at least for countable theories), which is Vaught's Conjecture: if there are uncountably many countable models, then there are 2^(aleph_0) countable models (i.e. the maximum number). This is still wide open. \u2013\u00a0 John Goodrick Jan 27 '10 at 3:04\nshow 1 more comment\n\nFor real closed fields this is fairly easy.\n\nFirst show that for any infinite cardinal k there are 2^k nonisomorphic linear orders of cardinality k\n\nFor example if X is a subset of k let A_x be Q+2+Q if x is in k and Q+3+Q if x is not in X. Let L_X be the sum of the A_x for x in k. It is easy to see that L_X is isomorphic to L_Y if and only if X=Y.\n\nIf F is a real closed and x and y are infinite element of R we say that x and y are comparable if and only if there are natural numbers m and n such that x is less than y^m and y is less than x^n. The ordering of R induces a linear order L_R of the comparability classes, which we call the ladder of R.\n\nSuppose L is a linear order. Let F be the real algebraic numbers. Let R_L be the real closure of the transcendental extension of the real algebraic numbers F(x_l:l\\in L) ordered such that if i is less than j then x_i^n is less than x_j for all n. It's not hard to show that the ladder of R_L is isomorphic to L.\n\nThus if we start with nonisomorphic orders A and B then the fields R_A and R_B will be nonisomorphic.\n\nshare|improve this answer\nDave, welcome to MO! You can use LaTeX as you normally would. Be careful with '>' and '<', which can get confused with html tags. \u2013\u00a0 Fran\u00e7ois G. Dorais May 5 '10 at 2:08\nWelcome to MO, Dave! \u2013\u00a0 Joel David Hamkins May 5 '10 at 2:16\nBienvenue, Professor Marker. I learned model theory (such as I know it) from your text. \u2013\u00a0 Pete L. Clark May 5 '10 at 2:27\nadd comment\n\nIn the countable case, the bound of 2\u03c9 is realized, since any countable real-closed field will contain the rational numbers and fill at most countably many cuts in the rationals with LUBs. But we can arrange that any given cut is filled by a real closed subfield of R containing that real. So there must be 2\u03c9 many non-isomorphic countaable real closed fields.\n\nIn the general case, because the models have an order, you can easily make this order have different cofinalities, by building elementary chains of different lengths. That is, just use your Lowenheim Skolem construction to add another point on top of the previous model, and continue for \u03b4 steps. This will produce an elementary extension of size \u03ba whose order has cofinality \u03b4, for any regular \u03b4 up to \u03ba. So this gives many more models, but doesn't quite answer your 2\u03ba question. I'm inclined to agree with you and expect that it must be the maximal number for all \u03ba on general grounds.\n\nshare|improve this answer\nAlthough Marty has answered the question in full, I thought I'd remark that Joel's argument generalizes easily to give 2^k for any k <= 2^{aleph_0}. Namely, choose a transcendence basis B for R over Q, and for each subset S of B with |S|=k, let F_S be the set of real numbers that are algebraic over Q(S). This gives you 2^k real closed fields, and they are all different. \u2013\u00a0 Bjorn Poonen Jan 26 '10 at 3:00\nThanks, Bjorn, that's helpful -- in particular, that's enough to derive the statement about Aut(C) in my question. \u2013\u00a0 Pete L. Clark Jan 26 '10 at 3:14\nThanks, Bjorn. I wonder if this kind of argument can work at higher k? Or do we need to use Shelah's (un)stability theory... \u2013\u00a0 Joel David Hamkins Jan 26 '10 at 12:58\n+1: Together with Marty's response, this answers the original question in full (it really is necessary to consider the case of countable models separately). \u2013\u00a0 John Goodrick Jan 27 '10 at 3:08\n@Joel: I'm not sure how Bjorn's argument could work for big k, since if k is bigger than 2^{aleph_0} there are no longer enough types to distinguish all 2^k models. The proof of Shelah's theorem that I've read involves building a big class of Ehrenfeucht-Mosowski models over carefully chosen indiscernible sequences, and then using and extremely clever and indirect argument to show that some subcollection of 2^k of these models must be pairwise nonisomorphic. \u2013\u00a0 John Goodrick Jan 27 '10 at 3:17\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/132743/probability-of-having-linearly-independent-sparse-vectors-over-finite-fields\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that there are $i< N$ linearly independent $N$-dimensional vectors $\\mathbf{v}_1,\\mathbf{v}_2,\\ldots,\\mathbf{v}_i$ over a finite field $\\mathbb{F}_q$, whose elements are denoted as $\\{0,1,2,\\ldots,q-1\\}$. Each vector consists of exactly $m$ nonzero elements uniformly randomly chosen from $\\{1,2,\\ldots,q-1\\}$, $m\\ll N$. The nonzero coordinates of each vector are randomly located.\n\nNow the question is, given a new such random $N$-dimensional vector $\\mathbf{v}_{i+1}$, what is the probability that it is linearly independent with the previous $i$ vectors?\n\nBest Regards.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nThese are some preliminary thoughts that are too long for a comment.\n\nAn equivalent question is: How many vectors with exactly $m$ nonzero entries are in the subspace generated by the first $i$ vectors? Then one just divides by $(q-1)^m\\left(\\begin{array}{c}N \\\\ m \\end{array}\\right)$ to get the probability. A naive guess is $\\frac{(q-1)^m}{q^{N-i}} \\left(\\begin{array}{c}N \\\\ m \\end{array}\\right)$. A trivial lower bound is $i (q-1)$. A trivial upper bound is $q^i-1$.\n\nI would guess that, as long as $m$ is reasonably large, for small $i$ the trivial lower bound is approximately correct, and for larger $i$ the naive guess is correct. All in all, the problem behaves very differently depending on the relative sizes of $i$, $m$, $N$, and, to a lesser extent, $q$. What regimes are you most interested in?\n\nWhen $m$ is very small, we get some interesting behavior. For $m=1$, we can exactly compute the probability of linear independence - it is $(1-1/N)^{i}$. For $m=2$, we can see the $N$ elements as vertices of a graph and the $i$ vectors as edges. Then our new vector can be linearly dependent only if the two nonzero coordinates are connected to each other, or both connected to cycles. I think one can get accurate formulas without too much difficulty this way.\n\nWhen the probability of a linear dependence among the $i$ vectors is sufficiently small, a good upper bound is provided by counting the expected number of ways to write a new vector as the sum of old vectors. One can write this a a sum over different ways to write a new vector as a sum of old ones, and try to find the largest terms. In particular for small $i$ I think only a couple of ways of writing a new vector as a sum of old ones will be dominant - most vectors of length $m$ that are sums of vectors of length $m$ will be sums of only $1$ or $2$ or $3$ vectors of length $m$. Then you would get a sequence of increasingly exact formulas.\n\nThe most important question is really how $i,m,$ and $N$ relate to each other. The problem is really very different for different values of that.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/73958/intersection-of-a-smooth-projective-variety-and-a-plane/83663\nText:\nTake the 2-minute tour \u00d7\n\nLet $X \\subset P^n$ be an irreducible smooth complex projective variety embedded in the $n$-dimensional projective space. Let $k$ be the dimension of $X$ and $d$ its degree. Let $L \\subset P^n$ be a linear subspace of dimension $n-k$ and $Z=L \\cap X$. Assume that\n\n(a) $X$ is not contained in any hyperplane of $P^n$ and\n\n(b) $Z$ is finite of cardinality $d$.\n\nQuestion: Is it true that $Z$ spans $L$?\n\nComment: I was told that this is true if $X$ is ACM (arithmetically Cohen-Macaulay). A reference for this would be appreciated.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nIt is true that $Z$ spans $L$ \u2014 even if $X$ isn't ACM. You can also allow $X$ to be singular (but you do need $X$ irreducible and non-degenerate, of course). To illustrate one of the main ideas it is useful to first look at the case when $X$ is a curve.\n\nIf $X$ is a curve. Let $M$ be the span of $Z$ and suppose that $M\\neq L$. (In the curve case, $L$ will be a hyperplane). Let $p$ be any point of $X$ outside of $Z$ and let $H$ be any hyperplane containing $M$ and $p$. Then $H\\cap X$ contains at least $d+1$ points, so by Bezout's theorem the intersection cannot be zero dimensional. Since $X$ is irreducible and one dimensional, this means that the intersection must be all of $X$, so $X$ is contained in $H$, contrary to hypothesis.\n\nThe general case. The idea when $k\\geqslant 2$ is to show that if $H$ is a general hyperplane containing $L$ then $H \\cap X$ is irreducible and non-degenerate (i.e, the intersection $H\\cap X$ is not contained in a smaller linear space of $H$). But now all dimensions have been reduced by $1$, and so iterating this procedure reduces us to the curve case, which we've already solved.\n\nTo set this up, note that hyperplanes in $\\mathbb{P}^n$ containing $L$ are parameterized by a $\\mathbb{P}^{k-1}$ (If $V$ is the underlying vector space of $\\mathbb{P}^{n}$, $W$ the underlying vector space of $L$, then the hyperplanes are parameterized by the projectivization of $(V/W)^{*}$). We'll use $H$ to refer both to a point of $\\mathbb{P}^{k-1}$ and the corresponding hyperplane in $\\mathbb{P}^n$ containing $L$. Define $\\Gamma\\subset \\mathbb{P}^{k-1}\\times (X\\setminus Z)$ to be the set\n\n$$\\Gamma = \\left\\{(H,p) \\mid p\\in H\\right\\}$$\n\ni.e, the pairs $(H,p)$ so that $H$ is a hyperplane containing $L$, and $p$ a point of $H\\cap X$ not on $Z$.\n\nIf we fix $p$, then the set of possible $H$'s satisfying this condition are simply the hyperplanes $H$ containing the span of $L$ and $p$, and this is parameterized by a $\\mathbb{P}^{k-2}$. In other words, $\\Gamma$ is a $\\mathbb{P}^{k-2}$ bundle over $X\\setminus Z$. (This fibration is where we use $k\\geqslant 2$.) Since $X\\setminus Z$ is irreducible this implies that $\\Gamma$ is irreducible.\n\nLet $\\overline{\\Gamma}$ be the Zariski-closure of $\\Gamma$ in $\\mathbb{P}^{k-1}\\times X$. Then $\\overline{\\Gamma}$ is irreducible since $\\Gamma$ is. For a fixed $H\\in \\mathbb{P}^{k-1}$ the fibre of the projection $\\overline{\\Gamma}\\longrightarrow \\mathbb{P}^{k-1}$ over $H$ is simply the intersection $X\\cap H$, of dimension $k-1$.\n\nNow let $q$ be any point of $Z$. Then $q\\in X\\cap H$ for every $H\\in \\mathbb{P}^{k-1}$ so $q$ gives a section of $\\overline{\\Gamma}\\longrightarrow\\mathbb{P}^{k-1}$. Since $Z$ consists of $d$ distinct points where $d$ is the degree of $X$ we conclude that $q$ is a smooth point of $X$. Finally, since $Z$ is the intersection of all $X\\cap H$ for $H\\in \\mathbb{P}^{k-1}$ this implies that the general intersection $X\\cap H$ is smooth at $q$. Summarizing, we have a section of the map which generically lies in the smooth locus of the fibres. Since $\\overline{\\Gamma}$ is irreducible, this implies that the generic fibre is irreducible, i.e, if $H$ is a generic hyperplane containing $L$, then $H\\cap X$ is irreducible.\n\n(The intuitive reason for this implication is that, generically over $\\mathbb{P}^{k-1}$ the section lets us pick out precisely one irreducible component of the fibre. The union of these components gives us a subset of $\\overline{\\Gamma}$ which has the same dimension as $\\overline{\\Gamma}$, and hence whose closure must be all of $\\overline{\\Gamma}$ by irreducibility. But if there is more than one component in a general fibre, this is a contradiction, thus the general fibre must be irreducible. To make this intuitive construction rigorous requires passing to the normalization of $\\overline{\\Gamma}$ and then looking at the Stein factorization of the map from the normalization to $\\mathbb{P}^{k-1}$. The section gives a generic section of the finite part of the Stein factorization, and that allows one to construct the ``union of the components containing the section''.)\n\nFinally, the same trick as in the curve case also shows us that for any hyperplane $H$, $H\\cap X$ must be non-degenerate. Let $Y=H\\cap X$, so that $Y$ is a variety of degree $d$ and dimension $k-1$. Let $M$ be the span of $Y$. If $M\\neq H$ then pick any point $p\\in X\\setminus Y$ and let $H'$ be any hyperplane containing $M$ and $p$. Then $H'\\cap X$ can't be all of $X$ (since this would contradict the non-degeneracy of $X$), so $Y'=H'\\cap X$ must be a subvariety of dimension $k-1$ (more precisely, all components of $Y'$ have dimension $k-1$) and degree $d$. But $Y$ is therefore a component of $Y'$, and the equality of degrees tells us that $Y'$ can't have any other components so we must have $Y'=Y$. This contradicts the fact that $p\\in Y'$ and $p\\not\\in Y$.\n\nTogether this shows the required inductive step: If $H$ is a general hyperplane containing $L$ then $H\\cap X$ is irreducible and non-degenerate.\n\nOther remarks. I'm guessing from the setup of the question that you want to apply the result for a particular $L$ that you have chosen. If, in the application, you're allowed to pick a general $L$ then you can say something stronger. The classical uniform position principle (where ''classical'' in this case means ''established by Joe Harris in the 80's'') states that for a general subspace $L$ of dimension $n-k$ the finite set of $d$-points in $Z=L\\cap X$ have the property that any subset of $r+1$ of the points (with $r\\leqslant n-k$) span a $\\mathbb{P}^{r}$. Picking $r=n-k$, this means that any subset of $n-k+1$ points of $Z$ spans all of $L$, and so in particular $Z$ spans $L$. (Note that $d\\geqslant n-k+1$; for instance, as a consequence of the argument above: if $d < n-k+1$ then the $d$ points of $Z$ would never span $L$.)\n\nshare|improve this answer\nThanks for the edit. I originally couldn't justify your statement \"Since $\\overline{\\Gamma}$ is irreducible with connected fibers over an irreducible base, its general fiber is irreducible.\" Of course you are right that the section is what helps out here. For other people who may have been confused, a counterexample is given as follows: consider the space of conic plane curves singular at the origin. This is naturally parameterized by a $\\mathbb{P}^2$, and one can check the total space of the universal family is irreducible. \u2013\u00a0 Jack Huizenga Dec 19 '11 at 20:32\nDear Jack - Yes, my previous justification for the irreducibility of the general fibre was completely wrong. I was thinking of the case that $X$ was smooth, and so $\\overline{\\Gamma}$ could be assumed normal. Then the general fibre is normal and so connectedness implies irreducibility. The general case of (possibly) non-normal $\\overline{\\Gamma}$ requires the use of the section to get around this, as your example shows. \u2013\u00a0 Mike Roth Dec 20 '11 at 15:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/galois-theory-morphisms.546932/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nGalois Theory: Morphisms\n\n  1. Nov 3, 2011 #1\n\n    Let K = Q(21/4)\n\n    Determine the automorphism group Aut(K/Q)\n\n    2. Relevant equations\n\n    An automorphism is an isomorphism from a Field to itself\n\n    Aut(K/Q) is the group of Automorphisms from k/Q to K/Q\n\n    Definition: A K-Homomorphism from L/K to L'/K is a homomorphism L---> L' that is the identity on K\n\n    3. The attempt at a solution\n\n    I am completely at a loss really. I have calculated there are four homomorphisms from K to C and think from there if I know how many are K-homomorphisms then that'll be the number of automorphisms, because a homomorphism from a field to itself is an automorphism (Please correct me if I'm wrong on this). Then that'll give me the set of Automorphisms.\n\n    My problem is that I don't know how to go from the number of homomorphisms to the actual homomorphisms. I think it has a relation to the roots of 2(1 /4) in C (which I have calculated to be 2(1 /4), - 2(1 /4), i*2(1 /4), -i2(1 /4) )\n\n    Please help, this lack of understanding is preventing me from moving forward with other questions and my notes from lectures completely gloss over how to do this.\n  2. jcsd\n  3. Nov 3, 2011 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    [itex](2^{1/4}^2= 2^{1/2}[/itex] and [itex](2^{1/4}^3=2^{3/4}[/itex] are irrational but [itex](2^{1/4})^4= 2[/itex] is rational so any number in [/itex]Q(2^{1/4})[/itex] is of the form [itex]a+ b2^{1/4}+ c2^{1/2}+ d2^{3/4}[/itex] for rational numbers a, b, c, d. For any automorphism, f, [itex]f(a+ b2^{1/4}+ c2^{1/2}+ d2^{3/4})= a + bf(2^{1/4})+ cf(2^{1/2})+ df(2^{3/4})[/itex] so the possible values of f depend entirely upon the possible values of [itex]f(2^{1/4})[/itex], [itex]f(2^{1/2})[/itex] and [itex]f(2^{3/4})[/itex].\n\n    Further, [itex](f(2^{1/4})^4= f(2)[/itex] is rational so [itex]f(2^{1/4}[/itex] must be a fourth root of 2. Also, [itex]f(2^{1/2})^2= f(2)[/itex] so [itex]f(2^{1/2}) must be [itex]2^{1/2} (or [itex]-2^{1/2}[/itex] which is just a rational number times [itex]2^{1/2}. Each f permutes the fourth roots of 1 while fixing [itex]2^{1/2}[/itex].\n  4. Nov 3, 2011 #3\n\n\n    User Avatar\n    Science Advisor\n\n    it is somewhat misleading to say the values of f depend on the values of f(21/4), f(21/2) and f(23/4).\n\n    f is a field automorphism, so (for example) f(23/4) = f((21/4)3)= (f(21/4)3,\n\n    so f ONLY depends on the value of f(21/4).\n\n    while it is true that f permutes the roots of x4-2, it is not true that any such permutation yields an \"f\". f takes conjugate pairs to conjugate pairs, as well (the square of a fourth root of 2 must be a square root of 2).\n\n    so if one regards the 4 roots of x4-2 as \u03b11234, where:\n\n    \u03b1j = \u03b1e(j-1)\u03c0i/4\n\n    then (\u03b12 \u03b14) yield a member of Aut(K/Q), but (\u03b12 \u03b13) does not.\n\nHave something to add?\n\nSimilar Discussions: Galois Theory: Morphisms\n  1. Galois theory (Replies: 4)\n\n  2. Galois Theory question (Replies: 0)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-final-velocity-of-the-cart-and-students.53214/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the final velocity of the cart and students\n\n  1. Nov 18, 2004 #1\n    Three Physics 111 AP students, each having a mass of 60kg, climb onto a large flatbed cart that has a mass of 120 kg. Standing at one end and taking turns they run to the opposite end and jump off, one immediately following the other, each with a velocity of 10 m/s with respect to the cart. Calculate the final velocity of the cart and students with respect to the earth.\n\n    I know I need to use [itex]m_1v_1 + m_2v_2 = m_1v_1 + m_2v_2[/itex], and I have done a bunch of simpler problems with no trouble. I'm pretty sure this has to be done in steps but I'm not sure how to incorporate the answer of each step into the next. I have something like this for the first step:\n\n    [tex]60 \\cdot 0 + 120 \\cdot 0 = 60 \\cdot 10 + 120(v + 10)[/tex]\n  2. jcsd\n  3. Nov 18, 2004 #2\n    Read integral's post.\n    Last edited: Nov 18, 2004\n  4. Nov 18, 2004 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    I believe that this problem is a bit more subtle, it is essentially a rocket problem. The mass of the \"cart\" does not remain constant. As each student jumps it becomes less massive, thus each successive student will cause a larger change in velocity.\n    after the first student jumps the carts velocity will change by:\n    [tex] v_c = \\frac {m_1 V_1} {m_2 + m_3 + m_c}[/tex]\n\n    Repeat for each student and sum the changes to get the total change.\n\nHave something to add?\n\nSimilar Discussions: Calculate the final velocity of the cart and students"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55629.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nMonty Hall Strikes Again\n\nSubject: Probability Question from OZ!\nDate: Wed, 2 Nov 1994 17:13:05 +1100 (EST)\nFrom: \"Sean Pryor\"\n\n\nBasically the problem goes like this.  There are three cups, one of which \nswap them?\n\nTo summarise:\n\nThree cups with a coin under one.\nYou pick one, I pick one that DOESN'T have the coin.\nYou then either stay with your choice, or swap it with the remaining cup.\nWhat is the probability of getting the coin, either way?\n\nBTW the answer I get is 50% either way - though it has been suggested \nthat you have a 2/3 chance if you swap cups....  I disagree with this, \nbut I don't think my maths is capable of giving a definitive answer \n(which is why you're reading this!)\n\n(This problem has placed a cool Australian $50 on the line here in a bet - \nso I need an answer proving me right! :-)  My mate would never let me \nforget it if he was right...)\n\n\nSean Pryor\n\nDate: Thu, 3 Nov 1994 08:20:34 -0500\nFrom: Phil Spector\n\n\nThis question is a famous brain teaser that is usually described in terms\nof the game show Let's Make a Deal.  Indeed, you do have a 2/3 chance \nof winning if you swap cups.  The answer is anti-intuitive, and my efforts \nat explaining it usually fall a little flatter than others' explanations, so\nI'm going to let other Dr. Math's try to provide an answer, and I'm going\nto work on a productive explanation.\n\nBasically, the solution is based as follows:\nLet's say it was under cup 1.\nOption 1: You originally choose cup 1.  Then, you get shown one of the\nempty cups (let's say cup 2 or 3) at which point if you CHANGE (to the\nremaining empty cup, either cup 2 or 3), you LOSE, but if you REMAIN \nwith cup one, you WIN.\n\nOption 2: You originally choose cup 2.  Then, you get shown the remaining\nempty cup (cup 3), at which point if you CHANGE (to cup 1), you WIN, \nbut if you REMAIN with cup 2, you LOSE\n\nOption 3: You originally choose cup 3.  Then, you get shown the remaining\nempty cup (cup 2), at which point if you CHANGE (to cup 1), you WIN, \nbut if you REMAIN with cup 3, you LOSE.\n\nEach of the three options has an equal chance of occuring, based upon your\noriginal random pick.  If you change 1/3 of the time, you lose (in the case\nof option 1, which has a 1/3 probability of occuring), while if you change\n2/3 of the time (with options 2 or 3, which have a 2/3 probability of\noccuring), you win.\n\nTherefore, the proper choice is always to change!  Sorry about that 50\ndollars. :(\n\nI think the place where things skew to the anti-intuitive is the fact that\nyou will -always- get shown an EMPTY cup by the game-show host/tricker, \nnot necessarily a random cup.\n\nHope this helped.\n\nPhil, a Dr. Math who knows only statistics revolving around game shows...\n\nSubject: Probability Question from OZ!\nFrom: \"Sean Pryor\"\n\nHey, it wasn't my $50!  It was a mate you was silly enough to bet on a\nmaths problem!! :-)\n\nI think I understand.  My query is that perhaps you have a 2/3 of getting\nthe coin when changing, taking into account the whole process.  If you\nisolate the last choice and say - now it's either in this cup or that and\nI can choose this or that, its 1/2.  Is that a reasonable method of\nexplaining the anti-intuitive bit?  Or have I missed the point here...\n\nX-Sender: pspecto1@cc.swarthmore.edu\nDate: Fri, 4 Nov 1994 18:46:18 -0500\n\nExactly.  Nope, you explained it better than I did...\n\n\n>What better place to start - my favourite was always the Wheel of Fortune\n>- spinning wheels, angular momentum, friction, force, acceleration, sectors,\n>degrees, probability - that show had it all! :-)\n\nTrue, but I always thought Pat Sajak was a dweeb. :)  Glad Dr. Math could\nhelp, and of course, write back with any other problems you have...\n\nAssociated Topics:\nHigh School Logic\nHigh School Probability\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214315/norm-of-integral-operator-in-l1\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the norm of the operator $$ T\\colon L^1[0,1] \\to L^1[0,1]: f\\mapsto \\left(t\\mapsto \\int_0^t f(s)ds\\right) $$ ?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nLet $f\\in L^1([0,1])$. Then\n\n$$\\|Tf\\|_1=\\int_0^1 \\left|\\int^t_0 f(s) ds\\right| dt \\le \\int_0^1 \\int_0^1 |f(s)| ds dt = \\|f\\|_1$$\n\nThis shows $\\|T\\|\\le 1$. Setting $f_n(x)=n\\chi_{[0,1/n]}(x)$, we see $||f_n||_1=1$. Note that\n\n$$\\int^t_0 n\\chi_{[0,1/n]}(s) ds=\\left\\{\\begin{array}\\,1 & \\text{if}\\;t\\ge1/n\\\\ nt & \\text{if}\\;t<1/n\\end{array}\\right.$$ It follows that $$||Tf_n||_1=\\int^1_0\\int_0^t n\\chi_{[0,1/n]}(s)ds dt=\\int_0^{1/n}nt\\,dt+\\int_{1/n}^1 1\\,dt =1-\\frac{1}{2n}\\rightarrow 1\\;\\text{as}\\;n\\rightarrow\\infty. $$ Hence $||T||=1$.\n\nshare|improve this answer\nFor $f \\equiv 1$, I found $||Tf||_1=1/2$ and not $1$. Otherwise, $f(x)=e^x$ works. \u2013\u00a0 Seirios Oct 15 '12 at 16:46\nThanks for the answers! But by the definition of the norm of T as $\\Vert T \\Vert = \\sup_ {f \\in L^1[0,1],\\Vert f\\Vert_1=1} \\Vert Tf \\Vert_1$, I can't really see how $f=2$ works, nor can I see that using $f=e^x$ will work, since $\\Vert f \\Vert _1 \\neq 1$ for both of these cases. Is the definition I'm using wrong? \u2013\u00a0 Maethor Oct 15 '12 at 20:17\nWhat makes you think that your simple-minded estimate is anywhere near sharp? If you do just one step in your computation, you get $$ \\int_{0}^{1}\\left\\lvert\\int_{0}^t f(x)\\,dt\\right\\rvert\\,dx \\leq \\int_{0}^1 \\int_{0}^t \\lvert f(x)\\rvert\\,dx\\,dt $$ which is an integral over a triangular region. If you brutally replace $t$ by $1$ here, you will get an integral over a square, so your estimate will overshoot badly. I would suggest to think about $F(t) = \\int_{0}^t f(x)\\,dx$ and think about what differential equation it solves. You should get $2/\\pi$ as a final solution, unless I'm mistaken. \u2013\u00a0 commenter Oct 16 '12 at 2:27\n@Norbert: geeez, you're right... I was led astray by considering $f(x) = \\frac{\\pi}{2} \\cos{\\frac{\\pi x}{2}}$ as in the $L^2$-case. .@IHaveAStupidQuestion: Try $f_n = n \\chi_{[0,1/n]}$. This sequence will minimize the effect of charging the upper right triangle in your estimate and a computation shows that $\\lVert Tf_n\\rVert_{1} \\nearrow 1$. \u2013\u00a0 commenter Oct 16 '12 at 11:40\n@MattN. The operator $T$ is the Volterra operator. The trick to compute its norm in $L^2$ is to consider $S = T^\\ast T$. Then $\\lVert T\\rVert^2 = \\lVert T^\\ast T\\rVert$. Use that $S$ is compact and self-adjoint, so its norm is equal to its maximal eigenvalue. An eigenfunction $\\lambda f = T^\\ast T f$ is a solution to $f'' = - \\lambda f$ and this yields an ansatz that lets you compute the eigenvalues and eigenvectors of $S$ and thus its norm. \u2013\u00a0 commenter Oct 16 '12 at 13:22\nshow 18 more comments\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/12717/charging-12v-150ah-battery/12718\nText:\nTake the 2-minute tour \u00d7\n\nI want to charge a 12V battery of 150Ah with a solar panel. The solar panel specs is 12V, 25 Watt.\n\nCan anyone please provide me how to calculate that how much time it will take to charge the battery? Please provide the calculations and formulas.\n\nshare|improve this question\nCan someone migrate this to electrical.stackexchange and make sure people don't have to see this question asked here? \u2013\u00a0 Larry Harson Jul 24 '11 at 21:35\n@user2146 - at the level of understand how Ah, V, watts go together and how to model the time - it's physics. If they were askign for a specific charge circuit then it would be eeng \u2013\u00a0 Martin Beckett Jul 24 '11 at 22:49\n@user2146: in addition to agreeing with what Martin said, I'll mention that the best way to signal that you think a question should be migrated is to flag it. Commenting really doesn't help. I'm not sure why you seem to hate this question so much, anyway. \u2013\u00a0 David Z Jul 24 '11 at 22:55\nok, david and martin are right. I'll delete my comments to save clutter and david and martin can do the same \u2013\u00a0 Larry Harson Jul 25 '11 at 2:33\n@user2146 - no need it's a useful discussion to decide the level of questions here. consider it 'case law' ;-) \u2013\u00a0 Martin Beckett Jul 25 '11 at 3:24\nadd comment\n\n5 Answers\n\nup vote 3 down vote accepted\n\nWatts (electrical power) = Volts $\\cdot$ Amps, so 25W = 12V $\\cdot$ 2.1A\n\n150Amp Hour is the total capacity so 150amp $\\cdot$ 1hour, 1amp $\\cdot$ 150hours, or 2.1amp for 72hours.\n\nThat's in an ideal world of course, there are heating losses as you charge the battery, the voltage of the solar panel varies with the load and if you entirely empty a 12V lead acid battery you are likely to damage it. But basically you are looking at 10days of full sunshine\n\nshare|improve this answer\n+1 for remembering that most solar panels do not work at night \u2013\u00a0 Henry Jul 24 '11 at 23:45\nIt depends on the year, of course. One hour on a sunny day in winter is going to be pretty useless compared to one hour in summer. \u2013\u00a0 Larry Harson Jul 25 '11 at 2:36\n@Henry - well I was making the unproven assumption the OP wasn't in orbit! \u2013\u00a0 Martin Beckett Jul 25 '11 at 3:22\nadd comment\n\nThe answers you've got so far from Vladimir and Martin give you a good first-order approximation: power = current x voltage. Energy = power x time. So your 12V battery of 150Ah needs 1800Wh of energy (12 x 150). So a 25W PV panel would need 72 hours at full output (1800Wh/25W).\n\nThe equation is: Peak-hours required = $\\frac{V_{batt} \\times capacity_{batt}}{Power_{PV}} $\n\nThat's an unusual combination of quite a small panel and a very big battery - is the battery designed to be a multi-week store for a low-power system, by any chance?\n\nFor a more accurate answer, you need a lot more information.\n\nThe output of the panel at any moment will depend on:\n\n(1) the voltage, (which will be determined by the battery, and will change as the battery charges)\n\n(2) the ambient temperature, and\n\n(3) the amount light hitting the panel. The amount of light hitting the panel will depend on panel tilt, orientation, overshading, weather, altitude, location, time of year, time of day.\n\nFor (1), you need the panel IV curve, typically presented on the manufacturer's datasheet. That datasheet will also tell you how output varies with panel temperature. You can then estimate the panel's temperature from the ambient temperature - it will (to the first order) be a fairly steady amount above ambient.\n\nHere are some example power curves for a 12V PV (and it looks like it's approx 125W peak) panel, from altestore.com :\n\nPV panel I-V curve\n\nYou also need to know about the battery's characteristics as it charges: the heat losses, and how its voltage changes with temperature and % charged. In a more complex system that involves a controller too, you'd need to know how the controller behaves, how it tracks the maximum power point, and what its internal losses are. A controller is very desirable, not only because it will track the PV panel's maximum power point, but also because it will prevent the battery over-charging.\n\nThere are various online PV calculators that will combine some of this information to give you estimates of output, such as the US NREL PVWATTS calculator. And there are free online GIS insolation resources to give you the raw source information to do detailed calculations yourself, such as the EU PVGIS database.\n\nshare|improve this answer\nI think it's the combination of biggest standard pickup/SUV battery and largest (cheap) battery top-up solar panel \u2013\u00a0 Martin Beckett Aug 3 '11 at 4:23\nadd comment\n\n150 Amper*hour is the battery charge capacity. With power of 25 Watt = 25 A*V at V = 12 V you will supply 25/12 Coulomb each second (Amper*s). So the charge time is equal to 150/(25/12) = 72 hours.\n\nshare|improve this answer\nadd comment\n\nIn the simplest case, and some unmentioned assumptions, the minimum charging time would be given by the formula already mentioned: $$ T = \\frac{V \\times Ah}{W}$$ this gives 12x150/25 = 72 hours.\n\nHowever, this case makes at least two major assumptions, the battery is fully discharged and there are no losses of any kind!\n\nIn the real world, the battery will not be fully discharged and there are energy losses \"everywhere.\" Just to drive the point home, if the battery is already charged, then the time would be zero.\n\nA typical 12V battery is considered \"discharged\" when its voltage is reduced to 9V. This means it has lost only 1/4 of its energy. Everything else remaining the same, it would only need 1/4 of the time (18 hrs) to charge up. If we assume 50% efficiency, this would bring the time up to 36 hours. Assuming 8 hrs per day of sunshine, it would take about 4 days.\n\nshare|improve this answer\nadd comment\n\nYou need to know the implication of using a 25W panel, for me that is pretty small. The idea is 150Ah at 12 V (DC) we need to apply the 10hr charging method, so 10% of 150Ah gives 15A.$$\\frac{150\\,\\text{Ah}}{10\\,\\text h}=15\\,\\text A$$\n\nSo power of needed solar panel is computed as follows, $12\\,\\text V\\cdot15\\,\\text A=180\\,\\text W$. So the power of your panel is 180 W.\n\nshare|improve this answer\nThe 10% of 150ah is 15ah. \u2013\u00a0 jinawee Feb 2 at 12:48\nadd comment\n\nprotected by Qmechanic Apr 11 at 14:32\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/119655/how-many-permutations/119665\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to calculate the number of possible non-repeated permutations of these serial key styles.\n\nI have no mathematical background and cannot read formulas, which is why I'm struggling with other online literature about this.\n\nIf someone could either let me know how many for each, or how I might calculate it, I'd be very grateful.\n\nThe character set is 24 uppercase letters, and 8 numbers. (removing I, O, 0, 1)\n\n1) 7FB-E48-W60\n\n\n\n4) H6EFA-N6H7O-08WW8-0S4SC-4K4S8\n\nThanks very much.\n\n\nshare|improve this question\nYou say \"removing I, O, 0, 1$, but I see 0,1, and O in your examples. Do you mean these are examples without the restrictions? \u2013\u00a0 Thomas Andrews Mar 13 '12 at 12:39\nHi, Thomas. Sorry, these examples don't have those excluded, they're to demonstrate the grouping and length. The finished product would have those excluded. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:02\nHi, dtldarek. I struggle with simple multiplication and division when it involves odd numbers. I don't know what any of that stuff means. I was hoping for pointers on what to type into a calculator, or just the answer for each. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:07\nTo be specific, what do you mean by \"non-repeated\" and what do you mean by \"permutations of styles\"? \u2013\u00a0 dtldarek Mar 13 '12 at 13:08\nHi, Sorry that part was unclear. I'm choosing to adopt one of these, numbered 1, to 4 styles of codes to use as voucher codes to be printed on coupon cards to be sold in stores. I want to know how many of these \"keys\" or \"serials\" I could generate uniquely with the character set of 24 upper case letters and 8 numbers, by \"non-repeated\" I mean unique entire keys, but each key can contain the same character more than once. I'd prefer to use style 1, but if that only gives me 2 million possible serial keys, then I'd have to go for 2, etc... \u2013\u00a0 i-CONICA Mar 13 '12 at 13:15\nadd comment\n\n4 Answers\n\nup vote 2 down vote accepted\n  1. The dashes don't make any difference.\n  2. Your alphabet has 24 + 8 = 32 characters.\n  3. There are 32^n = 32 * 32 * 32 * ... * 32 * 32 (n times) different strings of length n using this alphabet.\n  4. Using your schemes:\n    1. 32^9 = 35184372088832,\n    2. 32^12 = 1152921504606846976,\n    3. 32^16 = 1208925819614629174706176,\n    4. 32^25 = 42535295865117307932921825928971026432.\n\nHave fun ;-)\n\nshare|improve this answer\nadd comment\n\nsince without repetition: (32 because 8+24)\n\n1- 32*31*30*29*28*27*26*25*24 = $\\frac{32!}{(32-9)}!$\n\n2- $\\frac{32!}{(32-12)}!$ \n\n3- $\\frac{32!}{(32-16)}!$ \n\n4- $\\frac{32!}{(32-25)}!$\n\nBut your example above shows repetition and I,O,0, & 1. I hope that is what you want.\n\nshare|improve this answer\nHi, Zeina. Sorry, I written the question a little confusingly. By \"non-repeating\" I mean how many of these keys could I generate uniquely. Each key can contain the same character more than once. I've left some notes on the question. Thank you for your time. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:17\nadd comment\n\nIf, as you say in an earlier comment, characters can occur multiple times in a given serial number, then it's quite straightforward: the total number of serial numbers available for a key of length $k$ is $32^k$, where 32 is the size of your character set (24 letters and 8 digits).\n\nIn practice it's usually more complicated, though, since the serial key is generated in such a way that some information can be extracted from the key (most notably whether or not the key is valid, but also things like an identifier for the product and its version number).\n\nshare|improve this answer\nadd comment\n\nIn that case the probabilities become:\n\n1- $\\32^{9} = 35184372088832\n\n2- $\\32^{12}\n\n3- $\\32^{16}\n\n4- $\\32^{25}\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/516612/probability-of-getting-n-heads-after-cn-tosses\nText:\nTake the 2-minute tour \u00d7\n\nIf $X_n$ is the number of coin tosses to get $n$ heads, then how can one show that there exists a constant $c>1$ such that $P(X_n \\geq cn) \\leq 1/n$? I am looking for a direct elementary proof.\n\nAssume the coin tosses are fair and independent.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nSince $X_n$ is the sum of $n$ i.i.d. geometric random variables with parameter $\\frac12$, $E[X_n]=2n$ and $\\mathrm{var}(X_n)=2n$. Bienaym\u00e9-Chebychev inequality implies that, for every nonnegative $x$, $$ P[X_n\\geqslant E[X_n]+x]\\leqslant\\mathrm{var}(X_n)/x^2. $$ If $x^2=2n^2$, the RHS is $1/n$ and $E[X_n]+x=(2+\\sqrt2)n$ hence $c=2+\\sqrt2$ answers the question. Or, $$ P[X_n\\gt 4n]\\leqslant1/(2n). $$\n\nshare|improve this answer\nThank you. This would be a great answer but I was hoping, perhaps in vain, that there might be a proof that was elementary and entirely self contained. \u2013\u00a0 felix Oct 6 '13 at 16:43\nI suppose I could just incorporate a direct proof of en.wikipedia.org/wiki/\u2026 . \u2013\u00a0 felix Oct 6 '13 at 17:36\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/11778/insidious-exponential-integral/19300\nText:\nTake the 2-minute tour \u00d7\n\nI hope that someone's up for the challenge; I'm attempting to solve this via computer:\n\n\\begin{equation} \\int_{-\\pi}^\\pi{\\displaystyle \\frac{e^{i\\cdot a\\cdot t}(e^{i\\cdot b\\cdot t}-1)(e^{i\\cdot c \\cdot t}-1)}{(e^{i\\cdot t}-1)(e^{i\\cdot d \\cdot t}+1)(e^{i\\cdot f \\cdot t}-1)} \\dots dt} \\end{equation}\n\nI want to know if it's possible to break this up into simpler subproblems. You can use just about anything to do this, but there is one restriction. In computer science terms, I want this to be in $P$.\n\nLet me try to explain. I don't want the work I have to do grow exponentially. For instance, if I break up the integral into two integrals, I don't want to double the amount of work I have to do. I don't want to dramatically increase the amount of work I have to do by breaking things apart, I want to keep things fairly fast.\n\nEDIT I'd prefer to see integration techniques used for this.\n\nshare|improve this question\nHave you tried standard numerical integration methods? \u2013\u00a0 Yuval Filmus Nov 25 '10 at 2:59\n@Yuval:yes. They have potential; I'm not ruling them out if I can use them on subproblems. The main thing is that with these exponentials, everything seems to grow exponentially! Now I'm trying to see if breaking up the problem somehow can be competitive. \u2013\u00a0 Matt Groff Nov 25 '10 at 3:18\nYour integrand has a number of singularities; can you guarantee that the integral is even bounded? \u2013\u00a0 Rahul Nov 25 '10 at 3:32\nYes. It's gauranteed that it will integrate to a positive integer or zero. In fact, I'd be satisfied (really elated!) if I could simply determine if the result is nonzero or not. \u2013\u00a0 Matt Groff Nov 25 '10 at 3:51\nWhat does \"...\" mean? I'm not sure how the pattern would continue. \u2013\u00a0 Hans Lundmark Nov 25 '10 at 5:45\nshow 4 more comments\n\n2 Answers\n\nThis is at least as hard as the Number Partition Problem (or the related Subset Sum) and is probably equivalent. The Number Partition Problem is NP-Complete so the solution to such an integral is, in general, probably not polynomial time solvable.\n\nTo see that it's at least as hard, I will consider a special case of your integral. First notice that:\n\n$$ a_k \\in \\mathbb{N}, \\ \\ k \\in [ 0, 1, \\dots, n-1 ] $$\n\n$$ \\mathbb{I}_{\\sigma, a} = \\frac{1}{2 \\pi} \\int_{-\\pi}^{\\pi} e^{ i \\theta \\sum_{k=0}^{n-1} \\sigma_k a_k } d\\theta $$\n\nfor $ \\sigma_k \\in \\{-1, 1\\}$.\n\nNotice that $\\mathbb{I}_{\\sigma, a}$ will be 1 if the sum $\\sum_{k=0}^{n-1} \\sigma_k a_k = 0$. Otherwise $\\mathbb{I}_{\\sigma, a}$ will be 0. This gives us an indicator function to test whether the configuration is perfect or not.\n\nDefine $Z_a$ as follows:\n\n$$ Z_{ a } = \\int_{-\\pi}^{\\pi} \\prod_{k=0}^{n-1} ( e^{i \\theta a_k} + e^{- i \\theta a_k } ) d\\theta = \\int_{-\\pi}^{\\pi} e^{- i \\theta \\sum_{k=0}^{n-1} a_k } \\prod_{k=0}^{n-1} (e^{ 2 i a_k } + 1 ) d\\theta $$\n\nand notice that $Z_a$ also equals the sum of all indicator functions:\n\n$$ Z_a = \\sum_{ <\\sigma> } \\mathbb{I}_{\\sigma, a} $$\n\nwhere $<\\sigma>$ denotes all possible configurations of $ \\sigma_k \\in \\{ -1, 1\\}$.\n\n$Z_a$ counts the number of solutions and is a special case of the integral you presented above. Were you to produce an algorithm to evaluate your integral in polynomial time, it could be applied to the above integral not just showing that $ P = NP \\ $ but that the related counting problem is also in $P\\ $ ($ \\text{#} P = P $).\n\nWhile this means that you probably cannot produce a polynomial time algorithm (in general) to solve your integral, it also means that you can probably adapt algorithms used to solve the Number Partition Problem (or Subset Sum) to provide a solution to the original integral. For the integral you presented there is a (what appears to me) small hurdle of having the denominators being other than one, but perhaps you could simplify by using continued fractions.\n\nTo my knowledge, the current 'state of the art' algorithm in solving the Number Partition Problem is the Complete Karmarkar Karp algorithm (CKK). See here, here and here for discussions and descriptions.\n\nIf you want further reference on the Number Partition Problem and its integral representation, see Borgs, Chayes and Pittel's paper \"Phase transition and finite-size scaling for the integer partitioning problem\".\n\nshare|improve this answer\nMatt happens to be attempting to use analytic techniques to solve P vs. NP, so I'm not surprised that this is true. \u2013\u00a0 Qiaochu Yuan Jan 28 '11 at 0:04\nadd comment\n\nWhy don't you try complex integration ?. $\\large z \\equiv {\\rm e}^{{\\rm i}t}$. In order to accomplish this task we need to know anything about the constants $\\left(a, b, \\ldots\\right)$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/104751/invariants-of-symmetric-matrices\nText:\nTake the 2-minute tour \u00d7\n\n$\\newcommand{\\eS}{\\mathscr{S}}$ $\\DeclareMathOperator{\\SO}{SO}$ $\\newcommand{\\eP}{\\mathscr{P}}$ $\\newcommand{\\bR}{\\mathbb{R}}$ $\\DeclareMathOperator{\\tr}{tr}$ Let $m>1$ be an integer and denote by $\\eS_m$ the vector space of symmetric $m\\times m$ real matrices. The group $\\SO(m)$ acts by conjugation on $\\eS_m$. The space of $\\SO(m)$-invariant quadratic polynomials on $\\eS_m$ is spanned by the two polynomials\n\n$$ A \\mapsto \\tr A^2,\\;\\;A\\mapsto (\\tr A)^2. $$\n\nLet $\\SO(m-1)$ be the subgroup of $\\SO(m)$ consisting of orthogonal transformations of $\\bR^m$ that fix a unit vector $\\eta$.\n\nWhat is the space of $\\SO(m-1)$-invariant on $\\eS_m$. More precisely, can one explicitly write a basis of this space?\n\nClearly $\\tr A^2$ and $(\\tr A)^2$ are such polynomials, and so are\n\n$$ A\\mapsto (A^2\\eta,\\eta),\\;\\;A\\mapsto (A\\eta,\\eta)^2, $$\n\nwhere $(-,-)$ denotes the natural inner product on $\\bR^m$. Are there any more $\\SO(m-1)$ invariant quadratic polynomials? (I am inclined to believe that the above is the complete list.) Update After Robert Bryant's answer I lost my initial inclination.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 9 down vote accepted\n\nThis is a trick question, right? It's not true when $m=2$ because, then $\\mathrm{SO}(m{-}1)=\\mathrm{SO}(1)$ is trivial, so that all polynomials on $2$-by-$2$ symmetric matrices are invariants, and the four quadratics you mention clearly don't span the the six-dimensional space of all quadratics.\n\nMoreover, for $m>2$, you are missing $\\tr(A)(A\\eta,\\eta)$. When $m>2$, these five do span the space of $\\mathrm{SO}(m{-}1)$-invariant quadratic polynomials, as you can see by realizing that, when $m>2$, the space $\\mathcal{S}_m$ of symmetric $m$-by-$m$ matrices splits under $\\mathrm{SO}(m{-}1)$ into a direct sum $$ \\mathcal{S}_m = \\mathbb{R}\\oplus\\mathbb{R}\\oplus\\mathbb{R}^{m-1}\\oplus \\mathcal{S}^0_{m-1} $$ of $\\mathrm{SO}(m{-}1)$-irreducible modules, where the only equivalences are between the first two (trivial) summands, and where $\\mathcal{S}^0_{m-1}$ means the trace-zero symmetric $(m{-}1)$-by-$(m{-}1)$ matrices. (These two projections to $\\mathbb{R}$ are given by the invariant linear forms $\\tr(A)$ and $(A\\eta,\\eta)$.) [This splitting is valid for $m=2$, of course, but then the third summand is another copy of $\\mathbb{R}$ and the fourth summand has dimension $0$.]\n\nHowever, you switched from quadratic polynomials at the beginning to all polynomials. Was that intentional, or did you just want quadratics?\n\nshare|improve this answer\n@ Robert It was not a trick question. I wrote it early in the morning when my brain hadn't yet absorbed all the caffeine. I meant quadratic polynomials, and I now see that missed one. Thank you for the answer. \u2013\u00a0 Liviu Nicolaescu Aug 15 '12 at 14:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/202630/product-of-3-integers-is-72-find-the-3-integers-that-give-the-smallest-sum\nText:\nTake the 2-minute tour \u00d7\n\nProduct of 3 integers a, b, c equals 72, where every factor is positive integer. Find the integers a, b, c with the smallest sum.\n\nIt's easy to get the factors of 72 manually and see that the 3 smallest factors that give the product as 72 will be the smallest sum.\n\nI checked the factorization like this:\n\n1-1-72: 74\n1-2-36: 39\n1-4-18: 25\n1-8-9:  18\n2-4-9:  15\n3-4-6:  13\n\nIt seems like the smallest possible factors will give the smallest sum.\n\nBut there must be some trick to it or some kind of algorithm to find the smallest integers for any arbitrary product without laborious factoring.\n\nThanks for your help.\n\nshare|improve this question\nThe factors must be close to each other. A heuristic: The AM-GM inequality gives us $(a+b+c)/3 \\geq \\sqrt[3]{abc}$ where equality holds when $a=b=c$ and the difference between the LHS and RHS increases when $a$, $b$ and $c$ are far apart from each other. \u2013\u00a0 user17762 Sep 26 '12 at 5:00\nYes @Marvis is right: And 3-4-6 are the closest number in this case. \u2013\u00a0 Sumit Bhowmick Sep 26 '12 at 6:15\nOne algorithm might be to find the factor of $72$ closest to $\\sqrt[3]{72}$, which is $4$. Then find the factor of $72/4=18$ closest to $\\sqrt[2]{18}$, which is $3$. That leaves $18/3=6$. I don't know if it is always optimal, but it should be close to optimal. \u2013\u00a0 Henry Sep 26 '12 at 7:40\n@Graphth: Lagrange multipliers don't work when you need integer solutions. \u2013\u00a0 TonyK Nov 19 '12 at 15:34\n\n1 Answer 1\n\nYou could try decomposing $72$ into its prime factors. This is:\n\n$$72 = 2^3\\times 3^2 = 2*2*2*3*3.$$\n\nThen pick the smallest combination of factor, which is $2\\times 2$, $2\\times 3$ and $3$, so that $4\\times 6\\times 3 = 72$, and $4 + 6 + 3 = 13$.\n\nHope it helps.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/258204/finding-a-pythagorean-triple-a2-b2-c2-with-abc-40\nText:\nTake the 2-minute tour \u00d7\n\nLet's say you're asked to find a Pythagorean triple $a^2 + b^2 = c^2$ such that $a + b + c = 40$. The catch is that the question is asked at a job interview, and you weren't expecting questions about Pythagorean triples.\n\nIt is trivial to look up the answer. It is also trivial to write a computer program that would find the answer. There is also plenty of material written about the properties of Pythagorean triples and methods for generating them. However, none of this would be of any help during a job interview.\n\nHow would you solve this in an interview situation?\n\nshare|improve this question\nI personally have memorized most of the small Pythagorean triples (this one, for example, is 8, 15, 17). \u2013\u00a0 Joe Z. Dec 13 '12 at 20:36\ntbh, I bet they were testing your ability to admit that you didn't have the tools to solve it right there in the limited amount of time. I highly doubt they wanted you to know the answer. \u2013\u00a0 picakhu Dec 13 '12 at 20:41\nIt certainly helps to know the formula for general relatively prime triples, since you can solve for any triple such that $a+b+c$ divides 40 and then multiply to get a triple with $a+b+c=40$. \u2013\u00a0 Thomas Andrews Dec 13 '12 at 20:41\n\n5 Answers 5\n\nup vote 8 down vote accepted\n\nAssuming you do have a pen and paper, you could substitute $c = 40 - a - b$ into the first equation to get\n\n$$a^2 + b^2 = (40 - a - b)^2 = a^2 + b^2 + 1600 - 80(a + b) + 2ab.$$\n\nRewriting this equation, you get\n\n$$a + b - 20 = \\frac{ab}{40}.$$\n\nFrom this it follows that $ab$ has to be a multiple of $40$, i.e., one of them is a multiple of $5$. That narrows it down to only a few options...\n\nIf that's still too much brute-force, you could also note that $a + b > 20$ from the above equation, and $a + b < 27$, since $c$ has to be the largest of the three. This leaves only the three pairs\n\n\nLooking at the earlier equation, you see the third pair is the right one.\n\nshare|improve this answer\nOr you can rewrite that as $ab=40a+40b-800$ or $(a-40)(b-40)=800$. Given that you know $0<a,b<40$, this shouldn't be too hard to work out. \u2013\u00a0 Thomas Andrews Dec 13 '12 at 20:46\n@thomas, you know better, you know 0<a,b<20 \u2013\u00a0 picakhu Dec 13 '12 at 20:48\n@Thomas: Yes, that should work too. Still, at some point you will have to guess $a$ and $b$ I think. \u2013\u00a0 TMM Dec 13 '12 at 20:55\nThis is exactly the sort of thing I was looking for. Thank you! \u2013\u00a0 NPE Dec 14 '12 at 7:09\n\nThe general pythagorean triple can be written (up to swapping $a$ and $b$) as $$a=2kuv$$ $$b=k(u^2-v^2)$$ $$ c=k(u^2+v^2)$$ where $k,u,v$ are positive integers, $u,v$ are relatively prime with different parity and $u\\geq v$. For $a+b+c=40$, then, you get the condition $2k(u^2+uv)=40$, so you need $u^2+uv=u(u+v)$ to be a factor of $20$. Since $u,v$ have different parity, and they are positive, you know $u+v>1$ is odd, so $u+v=5$.\n\nGiven that $u\\geq v$, that yields $u=4,v=1$ and $u=3,v=2$. But $u=3$ isn't possible, since $3$ is not a factor of $20$. So The only solution is $(u,v)=(4,1)$ and therefore the only solution is $k(15,8,17)$ which you can see must have $k=1$, and you are done - the only solution is $(15,8,17)$. And $(8,15,17)$, if you count that as different.\n\nFor the more general problem, $a+b+c=2n$ (the sum of a Pythagorean triple is always even) this amounts to factoring $n=kuw$ with the following conditions:\n\n  \u2022 $k,u,w$ are positive in\n  \u2022 $w$ is odd\n  \u2022 $u<w<2u$\n\nGiven such a solution, you get a triple (by setting $v=w-u$:) $$a=2ku(w-u)$$ $$b=kw(2u-w)$$ $$c=k(2u^2+w^2-2uw)$$\n\nAnd this gives all such triples (modulo swapping $a$ and $b$.)\n\nListing these amounts to first listing the set of possible values of $w$, which can be any odd factors of $n$ such that $1<w<\\sqrt{2n}$. Then find values of $u$ with $w/2<u<w$ and $uw|n$. Then set $k=n/uw$ and you have your triple $(k,u,w)$ from which you can compute an $(a,b,c)$.\n\n(If you want to allow $ab=0$, the change the above to $u\\leq w < 2u$. Then $u=v=1$ and $k=n$ is always a solution.)\n\nshare|improve this answer\n\nThis is a rect triangle with a length of 40. for example triangle (3,4,5) with a length of 12, you can get the solution: (120/12,160/12,200/12). the point is that you know some patterns in advanced. (5,12,13) etc...\n\nshare|improve this answer\nThe solution you give is not integer. \u2013\u00a0 Martin Argerami Dec 13 '12 at 22:56\nThe term \"Pythagorean triple\" is used only for integer solutions to $a^2+b^2=c^2$ \u2013\u00a0 Thomas Andrews Dec 14 '12 at 14:25\n\n$$a^2=(c-b)(c+b) \\Rightarrow b+c = \\frac{a^2}{c-b}$$\n\n\nFor simplicity let $c-b=\\alpha$.\n\n\n$$a^2+\\alpha a-40\\alpha =0$$ Since this equation has integral solutions,\n\n$$\\Delta=\\alpha^2+160 \\alpha$$\n\nis a perfect square.Thus\n\n$$\\alpha^2+160 \\alpha =\\beta^2$$\n\n\n$$(\\alpha+80)^2=\\beta^2+80^2 \\,.$$\n\nThis way we reduced the problem to finding all pytagorean triples of the type $(80, ??, ??)$. This can be easily done if you know the formula, or by setting\n\n$$80^2=(\\alpha+80-\\beta)(\\alpha+80+\\beta)$$ and solving.\n\nshare|improve this answer\n\nIn practical, I will first solve this problem by assuming a=b. This gives approximately (11.72,11.72,16.56), then I try all possible ways around this solution. I can first assume the largest side is 17, then try (12,11),(13,10),(14,9),(15,8).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/71040/marble-game-theory\nText:\nTake the 2-minute tour \u00d7\n\nIn a game, there exist three piles of marbles, each pile with ,a,b, and c marbles respectively, where a,b,c are natural numbers and all different. At each turn, you can double the number of marbles in one pile by transporting marbles from one other larger pile (relative to the pile that is going to be doubled, before the doubling). The game is won when any two of the piles have an equal number of marbles.\n\nEither show that the game can be won from any starting a,b,c, or prove that this is not the case. (In particular, prove that the game cannot be won from every starting a,b,c.)\n\nAn interesting one, but the solution come does not.\n\n\nshare|improve this question\n\n2 Answers 2\n\nA duplicate of this question, Emptying buckets by moving pebbles around, was asked (and, interestingly, received a lot more upvotes than this one). Before Brian pointed out that it was a duplicate, I came up with a solution different from the shortlist solution. (I treat the problem of emptying one of the piles, which, as discussed in Phira's answer and comments, is equivalent.)\n\nThe idea is to successively produce $0$s in the binary representations of two of the numbers, starting with the least significant bit. So assume that the last $k$ bits of $b$ and $c$ are already zero; then if neither $b$ nor $c$ is zero yet, our aim is to make the last $k+1$ bits of two of the numbers zero.\n\nSo consider the $(k+1)$-th bits of $b$ and $c$. If they're both $0$, we're done. If they're both $1$, we just need one transfer between $b$ and $c$ to make them both $0$. If one is $0$ and one is $1$, we can put the $1$ in the lesser of the two by transferring from the greater to the lesser until it becomes the lesser.\n\nWithout loss of generality, assume $b\\lt c$. Now there are two cases. If $a\\ge b$, we can get rid of the $1$ by a transfer from $a$ to $b$. Otherwise, $a\\lt b\\lt c$, and we transfer first from $b$ to $a$ and then from $c$ to $b$, thus going from $a,b,c$ to $2a,b-a,c$ to $2a,2(b-a),c+a-b$. Now the sum of the first two numbers is $2b$, which has $0$s in the last $k+1$ bits, so we can make the last $k+1$ bits of those two numbers $0$ by making transfers between them, each of which gets rid of their last $1$ bits.\n\nIf we initially assign $a$, $b$ and $c$ such that $a$ has the fewest final zeros, this strategy seems to be slightly more efficient than the shortlist strategy: Compared to the total of $103505$ transfers minimally required to solve all distinct instances with totals less than $100$, this strategy makes $172865$ transfers while the shortlist strategy makes $190994$.\n\nshare|improve this answer\nThe $2b$ trick is nice. ($2b$ or $\\lnot 2b\\dots$) \u2013\u00a0 Brian M. Scott Dec 8 '11 at 21:33\n:-) ${}{}{}{}{}$ \u2013\u00a0 joriki Dec 8 '11 at 21:39\n\nIf you start with 0,1,2 it does not work.\n\nFor strictly positive numbers this is essentially problem C3 of the IMO shortlist 1994 where we want to empty an account in the same situation. (Because you have to have two equal amounts before an amount can get zero.)\n\nThere are several websites that offer shortlist solutions, for example:\n\n\nI don't know if I am supposed to copy a solution here.\n\nshare|improve this answer\nPresumably, \"natural numbers\" here is meant to exclude 0 (pretty common usage). \u2013\u00a0 Alon Amit Oct 9 '11 at 8:54\nFor natural number read positive integer. It\u2019s a regrettably common usage. \u2013\u00a0 Brian M. Scott Oct 9 '11 at 9:02\nPositive is also not always advisable as there are languages/countries where 0 is positive and negative. \u2013\u00a0 Phira Oct 9 '11 at 9:09\n@Brian M.Scott Note that the IMO problem has two parts. The first part is about emptying just one of the three accounts which is exactly equivalent to making two accounts the same size. \u2013\u00a0 Phira Oct 10 '11 at 7:22\nYou\u2019re right. $\\quad$ \u2013\u00a0 Brian M. Scott Oct 10 '11 at 7:42\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/76472/inverted-factorial-and-trailing-zeros-problem\nText:\nTake the 2-minute tour \u00d7\n\nFirst than anything a big Hello for all math fans like me.\n\nI've found a problem that is pretty interesting and I can't find the answer. As all of you must know, to counting the trailing zeros of $n$ factorial goes by this formula:\n\n$$c = (n/5)+(n/25)+(n/125)+(n/5^q)$$\n\nNow the problem is the following:\n\nWhat happen if the problem is in the other side, you have $c$ number of trailing zeros and you want to know the first $n$ that its $n!$ has $q$ trailing zeros, how can it be done?, I've searched a lot and I can't reach a solution. Is there an approach that I'm missing or something?\n\nThanks in advance and sorry about my English and my lack of Latex, but I'm already learning :D\n\nshare|improve this question\nI guess that $q$ is the floor of $\\log_5 (n)$. So it amounts to inverting the above function. There might not be a nice closed form for this, but I'd guess that you can write program to do this quickly. \u2013\u00a0 Tony Huynh Sep 27 '11 at 6:11\nI guess that $(m)$ refers to the floor function $\\lfloor m\\rfloor$, and that some dots are missing between the $125$ term and the $5^q$ term. Use $\\backslash\\text{lfloor}$, $\\backslash\\text{rfloor}$ and $\\backslash\\text{cdots}$. \u2013\u00a0 Did Sep 27 '11 at 6:29\nI looked at this too quickly to check the following but it seems that $\\frac16n-\\log_5n\\le c\\le\\frac16n+\\log_5n$, hence $x\\le n\\le y$ where $x=6c-6\\log_5x$ and $y=6c+6\\log_5y$. \u2013\u00a0 Did Sep 27 '11 at 6:39\nPlease replace every $6$ by $4$ in my previous comment. Sorry. \u2013\u00a0 Did Sep 27 '11 at 7:28\nThe number of trailing zeros in $n!$ is at oeis.org/A027868 -- perhaps some of the facts about the sequence given there can be inverted to give what you want. \u2013\u00a0 Michael Lugo Sep 27 '11 at 16:05\n\n2 Answers 2\n\nConsider the mixed radix representation of a positive integer using the bases 1, 6, 31, 156, 781, ... defined recursively by $b_n = 5b_{n-1}+1$, or in closed form as the sequence $(5^n-1)/4$. For example, the mixed radix representation of 2011 is <22421>, since $2011 = 2\\cdot 781 + 2\\cdot156 + 4\\cdot 31+2\\cdot 6+1\\cdot 1$. All the digits in this representation are 0, 1, 2, 3, or 4, except that a number can have 5 as a digit if all digits after the 5 equal 0; for example, the mixed radix representation of 2028 is <22450>, the mixed radix representation of 2029 is <22500>, and the mixed radix representation of 2030 is <23000>.\n\nThe point of defining this mixed radix representation is as follows: if $n$ is written in base 5 as $n = [d_kd_{k-1}\\cdots d_1d_0]_5$, then the number of trailing zeros in $n!$ is equal to the integer whose mixed radix representation is <$d_kd_{k-1}\\cdots d_1$> (note the omission of $d_0$).\n\nTherefore we can invert the function - that is, given the number $c$, we can find the smallest integer $n$ such that $n!$ has $c$ trailing zeros - as follows. Write $c$ in mixed radix representation; then append a zero to that string of numbers; then convert the string of numbers to a base-5 integer.\n\nFor example, with $c=2011={}$<22421>, the first integer $n$ such that $n!$ has $c$ trailing zeros is $n = [224210]_5 = 8055$. (Of course, the set of such integers $n$ is then precisely {8055,8056,8057,8058,8059}.)\n\nOne must be a little careful if the mixed radix representation of $c$ contains the digit 5: that means that there is no integer $n$ such that $n!$ has exactly $c$ trailing zeros. But we can find the smallest integer $n$ such that $n!$ has at least $c$ trailing zeros by \"carrying\" the 5s to the left.\n\nFor example, with $c=2028={}$<22450>, we rewrite $[224500]_5 = [225000]_5 = [230000]_5$, and so $n=[230000]_5= 8125$ is the smallest integer such that $n!$ contains at least 2028 trailing zeros; in fact, thanks to the 2 carries, $n!$ actually contains <23000>${}={}$2030 trailing zeros.\n\nshare|improve this answer\n\nAn article in GanitCharcha (www.ganitcharcha.com) will help you and have discussed on your question. Look at Problem 2 here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/60510/top-degree-local-cohomology-under-action-by-a-non-zerodivisor\nText:\nTake the 2-minute tour \u00d7\n\nLet $R$ be a noetherian commutative ring of dimension $n$, and let $M$ be a faithful finite $R$-module. Let $I$ be a proper ideal of $R$, and let $x\\in I$ be a non-zerodivisor on $M$.\n\nWhen does multiplication by $x$ induce an injection $H^n_I(M)\\hookrightarrow H^n_I(M)$?\n\nshare|improve this question\nThe local cohomology modules are $I$ torsion, so multiplication by $x$ will actually be the $0$ map. \u2013\u00a0 Hailong Dao Apr 4 '11 at 1:44\nUh-oh! Really? \u2013\u00a0 Harry Gindi Apr 4 '11 at 2:01\nNot necessarily the zero map, but definitely not injective. For example, when $M = R$ is a Gorenstein local ring and $I = m$ is the maximal ideal, the top local cohomology is the injective hull of $R/m$, which is $m$-torsion. \u2013\u00a0 Graham Leuschke Apr 4 '11 at 2:38\n@Harry: The $I$-torsionness follows from the fact that there is an isomorphism ${\\rm H}^i_I(M) = \\varinjlim_d {\\rm Ext}^i_R(R/I^d, M)$ \u2013\u00a0 Steven Sam Apr 4 '11 at 2:41\nGraham was right, let me give a careful answer then. \u2013\u00a0 Hailong Dao Apr 4 '11 at 4:37\n\n1 Answer 1\n\nup vote 6 down vote accepted\n\nGraham was right, the map is not necessarily $0$ as I wrote in the first comment. However, it is true that $H_I^n(M)$ is $I$-torsion, so it will be injective if and only if $H_I^n(M)=0$.\n\nAmusingly, I will observe that the map is actually surjective.\n\nApply $\\Gamma_I(-)$ to the sequence:\n\n$$ M \\stackrel{x}{\\to} M \\to M/xM$$\n\nto get $$ \\to H_I^n(M) \\stackrel{x}{\\to} H_I^n(M) \\to H_I^n(M/xM) \\to $$\n\nNow note that $\\dim M/xM < \\dim M = n$ because $x$ is $M$-regular, so $H_I^n(M/xM) = 0$. (In general, $H_I^n(N) =0 $ for $n>\\dim N$). So the multiplication by $x$ map is surjective, as claimed (may be this is what you had in mind anyway).\n\nFor completeness, the question of when $H_I^n(M) =0$ is rather subtle. It will be true, for example, if $I$ can be generated up to radical by at most $n-1$ elements, because you can calculate local cohomology using the Cech complex on those elements.\n\nAnother instance is when $R$ is a complete local domain, and $\\dim R/I>0$ (this is known as the Hartshorne-Lichtenbaum vanishing theorem). I do not know an easy equivalent condition off the top of my head.\n\nshare|improve this answer\nHeh, for what it's worth, I already knew it was surjective by that exact argument =). \u2013\u00a0 Harry Gindi Apr 4 '11 at 4:57\n@Harry: I am glad you agree! \u2013\u00a0 Hailong Dao Apr 4 '11 at 5:02\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/69490.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nManipulating a Formula Algebraically\n\nDate: 06/15/2006 at 23:45:03\nFrom: Debbie\nSubject: What is this formula used for?  \n\nI have the formula M = C(1 + r) in my algebra text, but it doesn't \ntell me what it is for.  It also asks me to solve for the r variable.  \n\nI know that the formula when solved for the r variable is:\n      M - C\n  r = -------\n\nbut I don't understand how to get all the way there.  This is as far\nas I know:  \n      M = C(1 + r)\n     -C  -C\n  M - C =  (1 + r)\n\nBeyond this I haven't got a clue.  Where did the 1 go?  Where does the\nextra C come from?  How do you get r alone?  Thanks for your help!\n\nDate: 06/16/2006 at 10:17:55\nFrom: Doctor Peterson\nSubject: Re: What is this formula used for?\n\nHi, Debbie.\n\nFirst, you don't need to even ask what a formula is for in this sort \nof problem.  One of the most important things about algebra (or math \nin general, really) is that it is abstract: that is, we can take all \nsorts of real-world problems and turn them into math problems (such \nas equations to solve), and once you've done that, it doesn't matter \nat all where they came from.  The methods you use in algebra ignore \nthe meaning of the problem, and just look at the equation itself.\n\nMany equations you'll work with in class don't come from anywhere at \nall; you are just practicing techniques that you can use on problems \nthat do have some real-world meaning.  It's sort of like a medical \nstudent practicing an operation on a dummy; he doesn't have to ask \nabout the patient's family or insurance!  But when he gets into real \nmedicine, all those things will matter.  In this case, the equation \nMIGHT relate to interest on a bank account, with r being the interest \nrate; but the same equation could come from other sorts of problems, \ntoo--or none at all.\n\nNow, to solve this equation for r, the important thing is to make \nsure that at each step you are making a new equation that is still \ntrue--that is, an equivalent equation.  We know that if we do the \nsame thing to each side, e.g. adding the same thing, the new equation \nwill be equivalent.  But often students don't pay close attention to \nwhat they are doing, and they don't really make an equivalent \n\nLook closely at what you did:\n\n      M = C(1 + r)\n     -C  -C\n  M - C =  (1 + r)\n\nWhat you say you are doing is subtracting C from both sides.  But \nthat's not really what you did.  When you do the subtraction (without \nsimplifying anything), you actually get\n\n  M - C = C(1 + r) - C\n\nNow you have to simplify, and you can't just cross off the C's!  If we \nexpand C(1 + r) using the distributive property, we get\n\n  M - C = C + Cr - C\n\nand then combining like terms gives\n\n  M - C = Cr\n\nThat's not what you got!  Why?  Because you didn't actually subtract C \nfrom the right side, but just crossed something off, thinking it was \nthe right thing to do.  This is a very common mistake!  You must \nalways think of the subtraction as making a change to the equation and \nthen simplifying, not just as canceling something.\n\nWe can continue, now--even though what you did is not the recommended\nmethod, which I will get to in a minute.  Look at the equation we have \n\n  M - C = Cr\n\nWhat is our goal?  To get r by itself.  We're almost there; all that's \n\"wrong\" with this is that r is multiplied by C, and we can get rid of\nthat by dividing by C.  So let's divide BOTH SIDES by C, again making \nsure that's really what we do:\n\n  M - C   Cr\n  ----- = --\n    C     C\n\nNow we can simplify the right side; multiplying r by C and then \ndividing by C undoes the multiplication and just leaves r:\n\n  M - C\n  ----- = r\n\nAnd that's our answer!\n\nNow, there are two other methods that make the first step easier than \nwhat we ended up doing.  One is to always simplify both sides of an \nequation before we start solving:\n\n  M = C(1 + r)\n\n  M = C + Cr\n\n(I distributed on the right side.)\n\nNow we want to get r alone; on the right side it is FIRST being \nmultiplied by C (remember the order of operations?) and THEN we're \nadding C to it.  To get it by itself, we have to undo both operations; \nand we do that in reverse order.  (For example, in the morning I put \non my socks first, then my shoes; to undo that at night, I take off \nmy shoes first, then my socks.)  So we'll first undo the addition of \nC, by subtracting C from both sides:\n\n    M   =   C + Cr\n  - C     - C\n  M - C =       Cr\n\nWhat this really means is that we are subtracting C from both sides \nlike this:\n\n  M - C = C + Cr - C = Cr\n\nwhere I simplified the right side by combining the like terms C and \n\nNow we're right where we were in the first method, and just have to \ndivide by C to finish.\n\nThere's another way we could have done this, without simplifying \nfirst; we'd look at the equation as given and see that in\n\n  M = C(1 + r)\n\nwe are FIRST adding 1 to r, and THEN multiplying by C.  We can undo \nthat by FIRST dividing both sides by C, and THEN subtracting 1 from \nboth sides.  The answer we get would look different, but would mean \nthe same thing.  If you wish, you may try doing that; but the method \nI've shown is what is usually taught.  I mention it because it is \nclose to what you tried to do: you wanted to get rid of the C first; \nbut because it is being MULTIPLIED rather than added, you have to \nDIVIDE by it rather than subtract, in order to eliminate it.  What you \nreally did was to subtract C from the left side and divide by C on \nthe right, which didn't give an equivalent equation.\n\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nMiddle School Equations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/10533/nested-nintegrate/10535\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that we have the given simple integral expression\n\n$$ \\int_{-5}^{5} x \\int_{-\\infty}^{x} e^{\\int_{0}^{z} -y dy} dz dx $$\n\nWriting this out in Mathematica we obtain:\n\nIntegrate[x Integrate[Exp[Integrate[-y, {y, 0, z}]], {z, -\\[Infinity], x}], {x, -5., 5}]\n\n\nIs it possible to do a numerical integration on this expression by using NIntegrate?\n\nA very naive attempt gives us the following errors:\n\nNIntegrate[x NIntegrate[Exp[NIntegrate[-y, {y, 0, z}]], {z, -\\[Infinity], x}], {x, -5, 5}]\n\nNIntegrate::nlim: y = z is not a valid limit of integration\n\nNotice that we want everything to be a numerical integration, this includes the inner integrals.\n\nThe problem is that one of the NIntegrates is an argument to the exponential function and this does not allow us to write the double integral with only one NIntegrate as mentioned in here\n\n\nI'm trying to evaluate an expression that is too complicated for Mathematica to do symbolically and it is composed on integrals of the kind mentioned above.\n\nshare|improve this question\nThank you so much for asking this question, I have a problem exactly like yours where the bounds of the inner integral are dependent on the current value of the outer integral and it was blowing up in my face. This helped a lot. Thanks again. \u2013\u00a0 James Matta Oct 9 '12 at 17:12\nadd comment\n\n2 Answers\n\nup vote 17 down vote accepted\n\nYou can always separate your inner integrals, convert them to functions and use in NIntegrate:\n\ni1[z_?NumericQ] := i1[z] = NIntegrate[-y, {y, 0, z}]\ni2[x_?NumericQ] := i2[x] = NIntegrate[Exp[i1[z]], {z, -\u221e, x}]\nNIntegrate[x i2[x], {x, -5., 5}]\n(* 30.0795 *)\nshare|improve this answer\nThis seems to be working on my actual problem. I'm still waiting on the result. Thank you. \u2013\u00a0 jmlopez Sep 12 '12 at 19:36\nTook a while but it finished. :) \u2013\u00a0 jmlopez Sep 12 '12 at 19:43\n@R.M. Could one use N[Integrate[...]] in case some of the inner integrals have an analytic solution ? If not, N[Integrate[...]]=NIntegrate[...] anyways. \u2013\u00a0 b.gatessucks Sep 13 '12 at 6:46\n@b.gatessucks If the inner ones have an analytic solution that also evaluates quickly, then yes, doing so might be worthwhile. But I've come across some integrals that have a nice analytical solution, but take a long time to compute whereas NIntegrate gives it instantly. Also, N@Integrate will give the same result as NIntegrate only if the function is well behaved within the default options in NIntegrae (e.g., not highly oscillatory, requiring increased precisions/recursions, etc). So N@Integrate only applies N to the result, whereas NIntegrate will use different algorithms \u2013\u00a0 rm -rf Sep 13 '12 at 23:16\nThank you for this answer it has solved my problem perfectly (and saved me the trouble of asking a question to boot :) ) Thanks again. \u2013\u00a0 James Matta Oct 9 '12 at 17:14\nadd comment\n\nIt is possible like so for example:\n\nfn[z_?NumericQ] := Exp[NIntegrate[-y, {y, 0, z}]];\n\nNIntegrate[x fn[z], {x, -5, 5}, {z, -\\[Infinity], x}]\n\n(*  30.0795  *)\n\nbut it takes a while to compute.\n\nI used the ability of NIntegrate to handle non-rectangular domains, which is very powerful but not widely known and / or appreciated, it seems. Note that the answers which numericalize all dimensions separately may not pick the optimal integration grid in multi-dimensional case, in which class of cases (and this includes the case in question) this form may generally work better.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limits-when-determining-area-between-two-graphs.78874/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nLimits When Determining Area between two Graphs\n\n  1. Jun 13, 2005 #1\n    Hi all having a little problem with finding the limits on the area between 2 graphs.\n\n    i can find the easy one such as:\n\n    Find the area between y=x^2 and y = 2x\n    which is:\n    x^2 = 2x\n    x^2 - 2x = 0\n    x(x-2) = 0\n\n    x = 0 & 2\n\n    but when i have a question like:\n    Find the area between y=2-x^2 & y =x\n\n    i cant work it out i got to x(1+x)= 2\n\n    but im sooo lost\n    any help appreciated\n  2. jcsd\n  3. Jun 13, 2005 #2\n    Nvermind, I understand what your saying. To find the points of intersection between those two graphs, set them equal to each other.\n\n    [tex] 2-x^2 = x [/tex]\n\n    [tex] x^2 + x = 2 [/tex]\n\n    An obvious one is x=1.\n\n    Try quadratic formula.\n    Last edited: Jun 13, 2005\n  4. Jun 13, 2005 #3\n    sorry whozum i dont think i explained the question well, i need to work out the points of intersection i have no problems working out the area.\n\n    yeh ive already got 1. so using the quadratic formula i should be able to find the points out?\n  5. Jun 13, 2005 #4\n    so the intersecting points are -2 & 1?\n  6. Jun 13, 2005 #5\n    There you go. Graph it to make sure.\n  7. Jun 13, 2005 #6\n    hello there\n\n    well first of all you need to find where both functions actually intersect this is done by making 2-x^2=x then using the quadratic formulae to find where they intersect, and so you will find that they will intersect at 1 and at -2 now if you want to find the area between these functions its best that you graph it and then split up the area which should correspond to the addition to a couple of integrals\n    [tex]\\int_0^1 2-x-x^2 dx+\\int_{-\\sqrt{2}}^0 2-x^2+x dx-\\int_{-2}^{-\\sqrt 2} x -2+x^2 dx[/tex]\n    by integrating you will be able to find the area between those two functions?\n    by the way y=2-x^2 has roots at +/-sqrt{2}\n    the area is 2.5 units hopefully with out any small errors\n    Last edited: Jun 13, 2005\n  8. Jun 13, 2005 #7\n    thanks guys!\n  9. Jun 13, 2005 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Why in the world should one do such a thing? For all x between -2 and 1, 2- x2 is larger than x so 2-x2- x is positive and is the \"height\" of a thin rectangle between the two. The area is\n    [tex]\\int_{-2}^1 2- x- x^2 dx= \\frac{9}{2}= 4.5[/tex].\n  10. Jun 13, 2005 #9\n    yeh thats tha answer i got 9/2\n\nHave something to add?\n\nSimilar Discussions: Limits When Determining Area between two Graphs"}
{"text": "Retrieved from http://math.stackexchange.com/questions/203491/expected-coverage-after-sampling-with-replacement-k-times\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nprobability distribution of coverage of a set after X independently, randomly selected members of the set\n\nIf I sample with replacement $k$ times from a jar of with a finite population of $N$ unique marbles. What is the probability distribution for the fraction of the unique marbles that I sample?\n\nshare|improve this question\nadd comment\n\nmarked as duplicate by Byron Schmuland, tomasz, Chris Eagle, Norbert, Noah Snyder Oct 7 '12 at 19:09\n\n\n1 Answer\n\nup vote 1 down vote accepted\n\nWe answer only the expectation question in the title, and not the more complicated distribution question asked in the body of the post. Questions like this one have been asked several times on MSE. There is also a large technical literature on related questions.\n\nFor $i=1$ to $N$, let random variable $X_i$ be $1$ if $i$ is chosen at least once, and let $X_i=0$ otherwise.\n\nThe probability that $X_i=1$ is $1$ minus the probability that the number is chosen no times. On any one trial, the probability of not choosing $i$ is $\\frac{N-1}{N}$. Hence $$\\Pr(X_i=1)=1-\\left(\\frac{N-1}{N}\\right)^k.$$ The number $Y$ of $i$ chosen is given by $$Y=\\sum_{i=1}^N X_i,$$ so by the linearity of expectation, $$E(Y)=\\sum_{i=1}^N X_i=N\\left( 1-\\left(\\frac{N-1}{N}\\right)^k \\right).$$ For the expected proportion, divide by $N$.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://mathoverflow.net/questions/4551/a-question-on-function-fields-extending-my-previous-question/4647\nText:\nTake the 2-minute tour \u00d7\n\nConsider the extension Q(a,b) of the field of rationals, where a,b are algebraically independent transcendentals. To Q(a,b) adjoin the roots of the polynomials x^5+a^5=1 and y^5+b^5=1. The resulting field Q(a,b)[x,y] is a radical extension of Q(a,b).\n\nIs it true that the only solutions to the equation X^5+Y^5=1 in the field Q(a,b)[x,y] are {0,1},{a,x}, {b,y}, {1/a,-x/a) and (1/b, -y/b)?\n\nComment: See FC's answer to my previous question.\n\nshare|improve this question\nCan I recommend that you rewrite your title so that it asks a question? \u2013\u00a0 Theo Johnson-Freyd Nov 8 '09 at 1:07\nWhy don't you mimic what FC told you about the 1-dimensional case and see how far it gets and then tell us? \u2013\u00a0 Kevin Buzzard Nov 8 '09 at 7:44\nto FC: i marked your answer as correct. do you think mimicking your answer (to the first question) might work to answer the second question? Let me know what you think...you can email me at bmk@math.cornell.edu, and I will tell you why I am interested in these questions and perhaps this might lead to an interesting work. \u2013\u00a0 Bakh Nov 9 '09 at 17:11\nadd comment\n\n4 Answers\n\nThe complete set of solutions consists of $$(1,0), (0,1),$$ $$(a,x), (x,a), (1/a,-x/a), (-x/a,1/a), (1/x,-a/x), (-a/x,1/x),$$ $$(b,y), (y,b), (1/b,-y/b), (-y/b,1/b), (1/y,-b/y), (-b/y,1/y).$$\n\nLet $C$ be the affine curve $X^5+Y^5=1$ over $\\mathbf{Q}$. Because your field $K:=\\mathbf{Q}(a,b)[x,y]$ is the function field of the $\\mathbf{Q}$-variety $C \\times C$, the set $C(K)$ is in bijection with the set of rational maps $C \\times C \\to C$. So the only fact needed beyond what was in FC's answer to your earlier question is the geometric fact that every non-constant rational map $C \\times C \\to C$ is a composition consisting of the first or second projection $C \\times C \\to C$ followed by a birational automorphism of $C$. More generally,\n\nIf $X,Y,Z$ are curves over a field $k$, and the genus of $Z$ is at least $2$, then every rational map $X \\times Y \\to Z$ factors through the first or second projection.\n\nProof: Extend the rational map to a rational map $X \\times Y \\to Z \\times Y$ by using the projection $X \\times Y \\to Y$ as the second coordinate map. Restrict this to the fibers above the generic point of $Y$ to get a rational map $X_L \\to Z_L$, where $L$ is the function field of $Y$. If this is constant, i.e., factors through the structure map to $\\operatorname{Spec L}$, then the original map factors through the projection to $Y$. On the other hand, the genus hypothesis implies that, up to powers of Frobenius in characteristic $p$, there are only finitely many non-constant rational maps from $X$ to $Z$ over any field, and hence finitely many of bounded degree in any characteristic, so there are no algebraic families of such maps, so the rational map $X_L \\to Z_L$ must be the base extension of a rational map $X \\to Z$, which means that the original rational map factors through the projection to $X$. $\\square$\n\n@Bakh: Both FC and I used the general observation that if $X$ and $Y$ are curves over a field $k$, and $K$ is the function field of $Y$, then $X(K)$ is in bijection with the set of rational maps from $Y$ to $X$. If you have not studied enough algebraic geometry yet to understand this, the following example may be helpful:\n\nConsider the case where $X$ is the plane curve $f(x,y)=0$ and $Y$ is the affine line $\\mathbf{A}^1$, so $K=k(t)$. To give a point in $X(K)$ is to give rational functions $r(t)$ and $s(t)$ such that $f(r(t),s(t))=0$ identically. If we substitute a particular element of $k$ for $t$, then $(r(t),s(t))$ specializes to a point on $X(k)$, and hence we get a map $\\mathbf{A}^1(k) \\to X(k)$ except that we must avoid the finitely many poles of $r(t)$ and $s(t)$. The same holds for points over any field extension of $k$, and in fact we get a rational map $\\mathbf{A}^1 \\to X$.\n\nMore scheme-theoretically, one can say that an element of $X(K)$ is a $k$-morphism from the generic point of $Y$ to $X$, and such a morphism spreads out to a morphism from some Zariski dense open subscheme of $Y$ to $X$, i.e., to a rational map from $Y$ to $X$.\n\nshare|improve this answer\nGiven that Bakh asked this question last Nov 7, and last logged in Nov 15, there's a chance he/she will never see this answer Bjorn. If one of your motivations for doing the exercise I suggested to Bakh was to make their life easier, then you might want to consider emailing them alerting them to the fact you've done it! \u2013\u00a0 Kevin Buzzard Mar 25 '10 at 8:48\nOK, thank you, Kevin; I'll do that. \u2013\u00a0 Bjorn Poonen Mar 25 '10 at 9:25\nadd comment\n\nYou will have more points than just the ones listed. To start, notice that $x$ and $y$ are both invertible. This is because $1 - a^5$ is invertible, and this equals $x^5$. This lets you write $1/x$ as $x^4/(1 - a^5)$. For this reason, you'll at least have extra solutions like $$(1/x, -a/x).$$\n\nAs to whether this amended list is complete, I do not know. I would believe that it is, but cannot say at the moment.\n\nshare|improve this answer\nadd comment\n\nNo. If you adjoin all the roots of $x^5=1-a^5$ to $\\mathbb{Q}(a, b)$, then you obtain a field that contains a primitive 5th root of unity. This will lead to more solutions of $X^5+Y^5=1$ then you have listed here.\n\nshare|improve this answer\nI think the intention was to adjoin exactly one root of each of the two polynomials. \u2013\u00a0 S. Carnahan Nov 8 '09 at 8:16\nadd comment\n\nHere are my comments to some of the suggestions and answers:\n\n(1) I dont quite know some of the facts (theorems, formulas, definitions) mentioned in FC's answer in order to mimic his answer in this case. Those facts might assume certain things not satisfied by the fields I am looking at.\n\n(2) i am adjoining exactly one root of each of the polynomials.\n\n(3) My guess is one might use the fact that a and b are algebraically independent (over Q) and that x and y are algebraic over a and b, respectively. Hence, there might be a reasoning that states that any polynomial equation p=0 that uses both something from {x,a} and something from {y,b} should be a trivial one. Therefore, the case might be reduced to the case of the first question (answered by FC). Cant make this work due to the lack of knowledge in the area at this stage.\n\nCheers, -Bakh.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://newton.dep.anl.gov/askasci/math99/math99144.htm\nText:\nNEWTON, Ask A Scientist!\nName: Norman\nStatus: student\t\nAge:  N/A\nLocation: N/A\nCountry: N/A\nDate: N/A \n\nIf the probability of being struck by lightning is 1 in 600,000, what is the probability of being struck twice?\n\n\nIn general, the probability of some occurrence with known probability happening twice to the same individual would be a product of the independent probabilities.\n\nIn your example, this would mean 1/600,000 times 1/600,000 or 1/360,000,000,000.\n\nJust a comment on this result...such a probability would represent the chance for a random occurrence assuming the original probability was calculated from random occurrences. This probability might be much higher for someone who tends to golf, mountain climb, fish, etc during lightning storms.\n\nIt also presumes that the individual could survive the first strike, which unfortunately might not be very likely.\n\nThanks for using NEWTON!\n\nRic Rupnik\n\n\nLightning does not know whether you have been struck previously. After you are struck, you have a 1 in 600,000 chance of being struck a second time. The probability of being struck twice can be worked out as follows. Consider 600,000 sets of events. In the first 599,999 you are never struck. In the last you are struck at least once. This is the 1 in 600,000 chance of being struck at least once. Make each of these sets 600,000 events. All of the first 599,999 sets of 600,000 events are \"never struck\"(359,999,400,000 events). In the last set of 600,000 events, the first 599,999 are \"only struck once\". The last is \"struck more then once\". This is a total of 360,000,000,000 events. The probabilities are:\n\nnever struck: (599,999 in 600,000),or (359,999,400,000 in 360,000,000,000)\n\nstruck exactly once: (599,999 in 360,000,000,000),or essentially (1 in 600,000)\n\nstruck more than once: 1 in 360,000,000,000 (1 in 360 billion)\n\nDr. Ken Mellendorf\nPhysics Instructor\nIllinois Central College\n\nClick here to return to the Mathematics Archives\n\n\n\nEducational Programs\nBuilding 360\n9700 S. Cass Ave.\nArgonne, Illinois\n60439-4845, USA\nUpdate: June 2012\nWeclome To Newton\n\nArgonne National Laboratory"}
{"text": "Retrieved from https://mathzsolution.com/is-there-an-injective-cubic-polynomial-z2%E2%86%92zmathbb-z2-rightarrow-mathbb-z/\nText:\nIs There An Injective Cubic Polynomial Z2\u2192Z\\mathbb Z^2 \\rightarrow \\mathbb Z?\n\nEarlier, I was curious about whether a polynomial mapping Z2Z could be injective, and if so, what the minimum degree of such a polynomial could be. I\u2019ve managed to construct such a quartic and rule out the existence of such a quadratic, but this leaves open the question of whether a cubic might exist. Equivalently my question is:\n\nCan a cubic polynomial of two variables with integer coefficients be injective?\n\nMy intuition is that there probably is such a function since there is a quadratic bijection N2N so if we allow ourselves an extra \u201cdegree\u201d to compensate for the transition from N to Z, it seems like it ought to be sufficient. However, I have yet to come up with an example that I suspect of being injective nor any general method I might use to try to prove injectivity.\n\nThe Part of This Post That Isn\u2019t A Question, But That Helps Motivate It Or Maybe Inspire Someone:\n\nSo far I have determined that there is an injective quartic and there is not an injective quadratic. To construct the quartic which is injective, note that the map f:N2N defined by f(x,y)=(x+y)2+y is injective and so is the map g:ZN defined by g(n)=2n2n. Then, one can set\nas an injective polynomial (of degree 4) in the two variables.\n\nNo quadratic polynomial may exist because any integer valued polynomial of degree two has a (non-zero) multiple expressible as:\nwhere P1 and P2 are polynomials with integer coefficients. Then, if we choose some y1 and a y2 such that y_1\\equiv y_2 \\pmod{4aP_1(y_1)}, we clearly have that P_1(y_1)\\equiv P_1(y_2)\\pmod a and that P_2(y_1)-P_2(y_2)=4aP_1(y_1)k for integer k. Then, we can choose two integers c_1 and c_2 such that c_1^2-c_2^2=P_2(y_2) \u2013 P_2(y_1)\nc_1\\equiv c_2 \\equiv P_1(y_1)\\equiv P_1(y_2) \\pmod a\nIn particular the values\nsatify the above. Then, choosing x_1=\\frac{c_1-P_1(y_1)}{a} x_2=\\frac{c_2-P_1(y_2)}{a} yields that P(x_1,y_1)=P(x_2,y_2), since their difference is (c_1^2-c_2^2) \u2013 (P_2(y_2)-P_2(y_1)) which we chose the c\u2018s to make 0.\n\nI have no idea how to approach the cubic case.\n\nA Moderately Surprising Computational Result\n\nUsing Mathematica, I determined that there is no polynomial of degree three with integer coefficients with absolute value 2 or less which is injective over the domain (\\mathbb Z \\cap [-2,2])^2. This surprises me, but it such a small set of polynomials that it might not mean anything other than that we might expect large-ish coefficients if a suitable polynomial does exist. (It could also be indicative of the fact that no such polynomial exists). I would have checked a larger range, but my computer crashed.\n\nI also thought the solving the one-dimensional case completely might help, and can see that x\\mapsto ax^3 + bx^2 + cx + d is injective if and only if it cannot be written as a(x-A)(x-B)\\left(x-\\frac{C}a\\right)+k for integer a,A,B,C,k \u2013 but this isn\u2019t super helpful, far as I can tell. However, the statement f(x,y) is injective is equivalent to asserting that t\\mapsto f(m_1t + b_1,m_2t+b_2) is injective for all m_1,b_1,m_2,b_2\\in\\mathbb Z with not both m equalling 0 \u2013 so this could be used to eliminate some cases, if nothing else.\n\n\nDisclaimer: This is merely a too lengthy comment to fit in the comment section.\n\nI still have no idea about the general degree 3 case, but here is another proof that no polynomial of degree 2 will work:\n\nWrite the polynomial P(x,y) of degree 2 as\n\nP(x,y)=\\sum_{i+j\\leq 2}c_{ij} x^i y^j,\\quad c_{ij}\\in\\mathbb Z\n\nConsider a point (a,b)\\in\\mathbb Z^2\\setminus\\{(0,0)\\} and the expression\n\n\nIf the coefficient (c_{10}a+c_{01}b) is zero, then t\\mapsto P(ta,tb) is an even function. Then\n\n\nfor all t\\in\\mathbb Z. If c_{10}=c_{01}=0 we can choose any (a,b)\\in\\mathbb Z^2\\setminus\\{(0,0)\\}. Otherwise (a,b)=(-c_{01},c_{10})\\neq(0,0) works. In any case, we have found an infinitude of pairs (ta,tb),(-ta,-tb) contradicting P being injective.\n\nSource : Link , Question Author : Milo Brandt , Answer Author : String\n\nLeave a Comment"}
{"text": "Retrieved from http://www.math.snu.ac.kr/board/index.php?mid=seminars&page=27&document_srl=796537&sort_index=date&order_type=desc\nText:\nLet $Q$ be a positive definite quadratic form with integral coefficients and let $E(s,Q)$ be the Epstein zeta function associated with $Q$. Assume that the class number of $Q$ is bigger than 1. Then we estimate the number of zeros of $E(s,Q)$ in the region $\\mathfrak{R}s>\\sigma_{T}(\\theta):=1/2 +(\\log T)^{-\\theta}$ and $T<Im s<2T$, to provide its asymptotic formula for fixed $0<\\theta<1$ conditionally. Moreover, it is unconditional if the class number of $Q$ is 2 or 3 and $0<\\theta<1/13.$"}
{"text": "Retrieved from http://www.math.uni-magdeburg.de/institute/imo/teaching/wise19/cao/models/color.mod\nText:\nset V; # nodes param q default card(V); # number of colors to try # we definitely won't need more colors than there are vertices set C = 1..q; # set of potential colors set E within V cross V; # edges var x {V cross C} binary; # x[v,c] = 1 if vertex v is colored using color c, and x[v,c] = 0 otherwise var y {C}; # encodes whether color c is used (1 = used) # x binary => y binary, so we don't need to declare that here # objective function: minimize the number of colors used minimize NumOfUsedCols: sum {c in C} y[c]; # each vertex has exactly one color s.t. AssignColor {v in V}: sum {c in C} x[v,c] = 1; # adjacent vertices must not have the same color s.t. Conflict {(v,w) in E, c in C}: x[v,c] + x[w,c] <= 1; # if vertex v has color c, then color c is used s.t. SetIndicator {v in V, c in C}: x[v,c] <= y[c]; # we allow that y[c] = 1 although c is not used. # However, this will never occur in an optimal solution, so we # don't have to exclude it explicitly"}
{"text": "Retrieved from http://archives.math.utk.edu/visual.calculus/4/int_by_parts.7/index.html\nText:\nEvaluate the following integral:\n\n  1. Let\n    and let\n\n  2. Hence,\n    and let\n\n  3. Using the formula for integration by parts\n\n    we get\n\n  4. Now we can use integration by parts again to compute the following integral\n\n  5. Let\n    and let\n\n  6. Hence,\n    and let\n\n  7. Finally we get\n\n  8. We can now use the above result to finish solving the problem:\n\n  9. It is easy to see that the integral obtained ( marked in red ) is the same as the original integral. Let us combine both integrals on the left hand side:\n\n  10. Acknowledgment: The java applet which is used on this page to display the equations in the discussion above is HotEqn from the Virtual Control Lab.\n\n    This page and the javascript used on this page was written by Marek Szapiel."}
{"text": "Retrieved from https://bioinformatics.stackexchange.com/questions/13627/how-to-design-deseq2-lrt-model-with-individuals-nested-in-2-levels\nText:\nWe have a complicated experimental design that we would like to perform LRT analysis for. Our main goal is to discover significant genes for the \"Injection:Social\" interaction term across the entire dataset by removing it from the LRT reduced model, and as a bonus we are also interested in discovering significant genes for that interaction term for each respective brain region.\n\nSample  Injection   Social  Region  Individual  ind.n\nHY06    L   ISO HY  S06 S1\nNST6    L   ISO NS  S06 S1\nTN06    L   ISO TN  S06 S1\nHY08    L   ISO HY  S08 S2\nNST8    L   ISO NS  S08 S2\nTN08    L   ISO TN  S08 S2\nHY30    L   KF  HY  S30 S1\nNST30   L   KF  NS  S30 S1\nTN30    L   KF  TN  S30 S1\nHY32    L   KF  HY  S32 S2\nNST32   L   KF  NS  S32 S2\nTN32    L   KF  TN  S32 S2\nHY64    L   KFC HY  S64 S1\nNST64   L   KFC NS  S64 S1\nTN64    L   KFC TN  S64 S1\nHY65    L   KFC HY  S65 S2\nNST65   L   KFC NS  S65 S2\nTN65    L   KFC TN  S65 S2\nHY19    L   NF  HY  S19 S1\nNST19   L   NF  NS  S19 S1\nTN19    L   NF  TN  S19 S1\nHY24    L   NF  HY  S24 S2\nNST24   L   NF  NS  S24 S2\nTN24    L   NF  TN  S24 S2\nHY05    S   ISO HY  S05 S1\nNST5    S   ISO NS  S05 S1\nTN05    S   ISO TN  S05 S1\nHY12    S   ISO HY  S12 S2\nNST12   S   ISO NS  S12 S2\nTN12    S   ISO TN  S12 S2\nHY31    S   KF  HY  S31 S1\nNST31   S   KF  NS  S31 S1\nTN31    S   KF  TN  S31 S1\nHY34    S   KF  HY  S34 S2\nNST34   S   KF  NS  S34 S2\nTN34    S   KF  TN  S34 S2\nHY62    S   KFC HY  S62 S1\nNST62   S   KFC NS  S62 S1\nTN62    S   KFC TN  S62 S1\nHY63    S   KFC HY  S63 S2\nNST63   S   KFC NS  S63 S2\nTN63    S   KFC TN  S63 S2\nHY04    S   NF  HY  S04 S1\nNST4    S   NF  NS  S04 S1\nTN04    S   NF  TN  S04 S1\nHY20    S   NF  HY  S20 S2\nNST20   S   NF  NS  S20 S2\nTN20    S   NF  TN  S20 S2\n\nMy first attempt was building simple full (m1) and reduced (m2) models that gets directly at our question of interest but doesn't control for nested individuals.\n\nm1 <- model.matrix(~ Region + Social * Injection, colData_filt)\nm2 <- model.matrix(~ Region + Social + Injection, colData_filt)\n\nWe want to control for individual/batch effects, which is nested within both \"Injection\" and \"Social\" but not region, as we have three brain regions per individual. I followed the example in the DESeq2 manual for creating a term (ind.n) distiguishing individuals nested within groups, but now I'm not sure how to create the full and reduced model given that I have one more level than the example.\n\nI've tried a really elaborate full model (m1) with the interaction term of interest (Injection:Social) removed for the reduced model (m2), but I'm not sure this is correct based on our design.\n\nm1 <- model.matrix(~ Injection + Injection:ind.n + Injection:Social + Injection:Region + Social + Social:ind.n + Social:Region + Region, colData_filt)\nm2 <- model.matrix(~ Injection + Injection:ind.n + Injection:Region + Social + Social:ind.n + Social:Region + Region, colData_filt)\n\nI'm assuming this is wrong, but even if this was by some miracle the correct formulation, would there be a way to extract genes that explain the \"Injection:Social\" interaction term for separate brain regions?\n\nAs a work-around, I subsetted the data by region and ran three separate LRT analyses for each subset and compared the results. While this simplified the model to look like the first example above, I worry that we lose some power by ignoring the fact we have multiple brain region samples from single individuals across the dataset.\n\nAny guidance is much appreciated. Thanks in advance\n\n\nFrom what I can gather, you want to account for the effect of individual, nested within region. That is, you want to see after accounting for these, is there a consistent effect for Injection:Social across all conditions.\n\nSo you set up the model like this:\n\nm1 <- model.matrix(~ ind.n*Region + Injection + Social + Injection:Social,data=..)\n\nThe last term should be Injection:Region and you can just use the waldTest (default) in DESeq2 for this term.\n\nWhat does the terms do? ind.n*Region is the equivalent of ind.n + Region + ind.n:Region , and with this you effectively get an effect for every region in every individual.\n\nWhy don't we need the Injection:ind.n or Social:ind.n or Social:Region. These terms indicate the effect of Injection or Social can vary by individuals or regions. Most likely introducing too many parameters when you are interested in a common effect. Also you do not have the replicates or samples to distinguish this effect from region or other effects.\n\nSince you provided an example we can run DESeq2 and you can see how the results look like:\n\nmat = counts(makeExampleDESeqDataSet(n=1000,m=48))\ndds = DESeqDataSetFromMatrix(mat,df,~ ind.n*Region + Injection + Social + Injection:Social)\n\ndds = DESeq(dds)\n\n [1] \"Intercept\"            \"ind.n_S2_vs_S1\"       \"Region_NS_vs_HY\"     \n [4] \"Region_TN_vs_HY\"      \"Injection_S_vs_L\"     \"Social_KF_vs_ISO\"    \n [7] \"Social_KFC_vs_ISO\"    \"Social_NF_vs_ISO\"     \"ind.nS2.RegionNS\"    \n[10] \"ind.nS2.RegionTN\"     \"InjectionS.SocialKF\"  \"InjectionS.SocialKFC\"\n[13] \"InjectionS.SocialNF\" \n\nThe terms you need are \"InjectionS.SocialKF\",\"InjectionS.SocialKFC\", \"InjectionS.SocialNF\", and you can look at each of them:\n\nlog2 fold change (MLE): InjectionS.SocialNF \nWald test p-value: InjectionS.SocialNF \nDataFrame with 6 rows and 6 columns\n              baseMean     log2FoldChange             lfcSE               stat\n             <numeric>          <numeric>         <numeric>          <numeric>\ngene1  9.9811166787259   1.25304112986447 0.819806376919295   1.52845984752303\ngene2 30.3449455820337 0.0329442893152027 0.705199688255367 0.0467162562092241\ngene3 3.83223545055379    1.0281136369045  1.64095596190233  0.626533350543196\ngene4  11.232305747171  0.595738624408923   0.8243883031544  0.722643227868976\ngene5 6.70950627004097  0.756449993378065   1.0631622863378  0.711509430967263\ngene6 26.1431134888287 -0.854784518963918 0.625714541243558  -1.36609342219393\n                 pvalue              padj\n              <numeric>         <numeric>\ngene1 0.126398405431826 0.978671002658464\ngene2 0.962739373909937 0.999897888026606\ngene3 0.530965168963838 0.978671002658464\ngene4 0.469899103018657 0.978671002658464\ngene5 0.476768608734069 0.978671002658464\ngene6 0.171909642630577 0.978671002658464\n\nAs mentioned, you can do a LRT if you want to test all the Injection:Social term interactions terms at one go, that is, the null hypothesis is that all of them are zero:\n\ndds = nbinomLRT(dds,reduced=~ ind.n*Region + Injection + Social)\n\nUsually the individual terms are more intuitively than testing all of them are zero, but you might have a special need for this.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Thank you, I will try this soon. Just to clarify, an LRT would still be appropriate for the larger question of finding the effect of the \"Injection:Social\" term and you suggest Wald for determining the region-specific impacts? Would it also be valid include a term like \"Injection:Social:Region\" in the suggested Wald model formulation in an attempt to explore the interactive effects of \"Injection:Social\" by region, or would that require more 3-way interaction terms with \"ind.n\"? $\\endgroup$ \u2013\u00a0jfaberha Jun 23 at 17:30\n  \u2022 1\n    $\\begingroup$ @jfaberha, thanks for providing the data, i have updated my answer, hopefully its clearer now. You can include \"Injection:Social:Region\" only if you include Region:Social. My point is this, do you think there is such an effect? $\\endgroup$ \u2013\u00a0StupidWolf Jun 23 at 18:41\n  \u2022 1\n    $\\begingroup$ I would visualize this with a pca or correlation matrix to see where the effects are coming from before applying them onto the model. No need to have a super complicated model... $\\endgroup$ \u2013\u00a0StupidWolf Jun 23 at 18:42\n  \u2022 $\\begingroup$ To answer your question regarding the \"Injection:Social:Region\" term, I will do some more research to see if this has an appreciable effect in the dataset. One question posed by the PI of this study is - what are the genes responsive to the \"Injection:Social\" interaction term in each of the different brain regions and are they different? I was guessing that maybe a 3-way interaction term could address this in the binomial Wald analysis, but I agree that adds excessive complexity to the model. That's said, I'm not sure how to get region-specific interactions without running separate analyses. $\\endgroup$ \u2013\u00a0jfaberha Jun 23 at 19:49\n  \u2022 1\n    $\\begingroup$ The main question is regarding the Injection:Social term across the dataset, with the brain region-specific interactions being less important follow-up. That said, I will move forward with LRT for the primary question and separate analyses for the region-specific analyses. Thank you for all the help! $\\endgroup$ \u2013\u00a0jfaberha Jun 23 at 20:37\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/299434/congruences-ramanujan-style\nText:\nLet $t\\in\\Bbb{N}$ and consider the sequences $p_t(n)$ defined by $$\\sum_{n\\geq0}p_t(n)x^n=\\prod_{i\\geq1}\\frac1{(1-x^i)^t}=(x;x)_{\\infty}^{-t}.$$ The numbers $p_t(n)$ can be regarded as enumerating partitions of $n$ into parts that come with $t$ colors. Furthermore, $p_t(n)=\\sum_{\\lambda\\vdash n}\\prod_{j\\geq1}\\binom{k_j+t-1}{t-1}$ where $\\lambda=1^{k_1}2^{k_2}\\cdots$ and each $k_j\\geq0$. Note also that $p_1(n)=p(n)$ is the usual number of (unrestricted) integer partitions of $n$. Ramanujan's famous congruences state $$\\begin{cases} p(5n+4)\\equiv0\\mod 5, \\\\ p(7n+5)\\equiv0\\mod 7, \\\\ p(11n+6)\\equiv0\\mod 11. \\end{cases}$$\n\nIn the same spirit, the following appear to be true. Are they? $$\\begin{cases} p_t(5n+4)\\equiv0\\mod 5, \\qquad t\\equiv0,1,2,4\\mod 5 \\\\ \\,p_t(7n+5)\\equiv0\\mod 7, \\qquad \\,\\,t\\equiv0,1,4 \\,\\,\\,\\, \\mod 7\\\\ p_t(11n+6)\\equiv0\\mod 11, \\qquad t\\equiv0,1,10\\mod 11. \\end{cases}$$\n\n  \u2022 1\n    $\\begingroup$ Nice. You could add the \"generating-functions\" and the \"ramanujan\" tag. $\\endgroup$ \u2013\u00a0Wolfgang May 4 '18 at 19:00\n  \u2022 2\n    $\\begingroup$ The cases $t=0,1 \\mod p$ ($p=5,7,11$) follow from finite field arithmetic. Indeed, denoting the generating function of $p_1$ by f, we have: $f^{pn_1 + n_0} (x) = f(x^ {p})^{n_1} f(x)^{n_0} \\mod p$ for any prime p and $n_0<p$. By comparing coefficients, $p_{p n_1 + n_0}(p m_1 + m_0) = \\sum_{i=0}^{m_1} p_{n_1}(i)* p_{n_0}(p(m_1 -i)+ m_0) \\mod p$ for $m_0 < p$. In the case of $p=5$ for instance, we may take $n_0=1, m_0=4$ and use Ramamujan's congruences to obtain your result for t=1. For t=0 it is even easier, as it corresponds to $n_0 = 0$, and $p_{0}(j)$ is indicator of 0. $\\endgroup$ \u2013\u00a0Ofir Gorodetsky May 4 '18 at 20:47\n  \u2022 2\n    $\\begingroup$ See also: (Freeman) Dyson's crank. It's a great story. $\\endgroup$ \u2013\u00a0shreevatsa May 5 '18 at 4:49\n\nMore general versions of this have been established: see in particular Theorem 2 of Kiming and Olsson, and for other work see (for example) Locus and Wagner.\n\nTo answer the question fully, as Ofir Gorodetsky observed the problem is trivial when $t$ is $0$ or $1$ modulo the prime modulus. The other cases correspond to $t \\equiv \\ell-1$ or $t\\equiv \\ell-3$ modulo $\\ell$ (with $\\ell$ being $5$, $7$, or $11$). These cases are the \"non-exceptional congruences\" covered by Theorem 2 of the paper by Kiming and Olsson (and the argument there is essentially elementary following easily from Euler's pentagonal number theorem in the case of $\\ell-1$, and an identity of Jacobi in the case of $\\ell-3$). The real interest is in the situation of exceptional congruences, and Theorem 4 of Kiming and Olsson gives some examples of these. For instance, if $t\\equiv 3 \\mod 11$ then $$ p_{t}(11n+7) \\equiv 0 \\pmod{11}. $$\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ I appreciate the details $\\endgroup$ \u2013\u00a0T. Amdeberhan May 5 '18 at 13:47\n\nYour Answer"}
{"text": "Retrieved from https://mathlesstraveled.com/2019/03/30/33-is-the-sum-of-three-cubes/\nText:\n33 is the sum of three\u00a0cubes\n\nI\u2019m a bit late to the party, but I find this fascinating: we now know (thanks to a discovery of Andrew R. Booker) that the number 33 can be written as the sum of three cubes. This may sound unremarkable, but it has been unknown for a long time whether this was possible. Part of the reason this is more difficult than it sounds is that cubes can be both positive and negative.\n\nBy contrast, it is very easy to decide whether it is possible to write 33 as a sum of two squares, 33 = a^2 + b^2. Since squares can only be positive, any values of a and b greater than 5 are not going to work, since they would make the sum too big. So there are only a few pairs of values to check: it\u2019s enough to just check all pairs (a,b) with 1 \\leq a \\leq b \\leq 5 (quick: how many such pairs are there?), which can even be done by hand in a few minutes. None of them work, so this exhaustive search of all the possibilities proves that it is not possible to find a and b such that 33 = a^2 + b^2.\n\nBut a sum of three cubes, 33 = a^3 + b^3 + c^3, is an entirely different matter! We can\u2019t put any a priori bound on the size of the values a, b, and c, because the cube of a negative number is negative\u2014if we choose at least one of them to be positive and at least one of them to be negative, they could in theory be very large but \u201ccancel out\u201d to yield 33. And that\u2019s exactly what Dr.\u00a0Booker found (using approximately 23 years\u2019 worth of computer time spread over one month!):\n\n33 = 8\\,866\\,128\\,975\\,287\\,528^3 + (-8\\,778\\,405\\,442\\,862\\,239)^3 + (-2\\,736\\,111\\,468\\,807\\,040)^3.\n\n\nAbout Brent\n\nThis entry was posted in number theory and tagged , , . Bookmark the permalink."}
{"text": "Retrieved from https://gaurish4math.wordpress.com/tag/infinte-descent/\nText:\nTag Archives: infinte descent\n\nA Curious Investigation\n\n\nAs I always say:\n\nMathematicians are those weird beasts who enjoy being surrounded by problems.\n\nMy current field of interest is Diophantine Equations (DE). Those who ever studied Number theory know about the classic\u00a0Pythagorean Triplets,\u00a0 equivalent to finding possible integer solutions of x^2+y^2 = z^2.\n\nAlso, it is a standard exercise (involving Method of Infinite Descent)\u00a0in DE to prove \u00a0thatx^2+y^2 = 3 z^2 has no integer solutions. But in this blog post I intend \u00a0to discuss following sibling of such degree two DE:\n\nSolve x^2+y^2 = 2z^2 for integers.\n\nClearly, z\\neq 0, I can divide whole equation by z^2 and denote, X=x/z and Y=y/z to get:\n\nSolve\u00a0X^2+Y^2 = 2 for rational numbers.\n\nObserve that (1,1) is a solution of given equation, then any other\u00a0solution (a,b) will lie with (1,1) on a line with rational slope (or\u00a0infinite slope, a vertical line, trivial case).\u00a0Furthermore, every line through (1,1) with rational slope will intersect with the quadratic curve in exactly two points. Because every quadratic equation has either no solutions or two real solutions, and\u00a0we already know that (1,1) is one solution.\n\nTo find all solutions, we first look at the vertical line case by\u00a0substituting X=1 \u00a0and seeing what two solutions you get. \u00a0One will be Y=1,\u00a0and the other gives a solution (which is the same solution in this case). Next, we take a line with rational slope m through (1,1), so that (using slope-intercept form):\n\n\nNow solve this line \u00a0and given curve X^2+Y^2 = 2\u00a0(which is circle of radius\u00a0\\sqrt{2} ). We will get:\n\nX = \\frac{m^2-2m -1}{m^2+1}\n\n\nWhere, m \\in \\mathbb{Q}, thus like x^2+y^2=z^2, x^2+y^2 = 2z^2 has infinite integer solution.\n\nEnding note:\n\nx^2+y^2 = 2 has only 4 integer solutions."}
{"text": "Retrieved from https://economics.stackexchange.com/questions/17208/slutsky-decomposition-of-given-labor-supply-model\nText:\nLet utility curve an individual given as $U(C,R) = C^aR^{1-a}$ where $(0\\lt a \\lt 1)$ and $C$ denotes consumption commodity and $R$ denotes its leisure, and price of $C$ is given as $P$, and the nominal wage for a unit of labor given as $W$. Total amount time available for the individual is $T$.\n\nNow I would like to derive the change of labor supply when nominal wage get increased with two different effect decomposed - income effect/substitution effect.\n\nWhat I have got is $L^s$ only, which is equal to $T-R$, following below process:\n\nfirst, $P\\cdot C = L^s\\cdot W $\n\nsecond, $T-R = L^s$\n\nby, first and second, $P\\cdot C= (T-R)\\cdot W$ (*)\n\nand the from the utility function we can derive the condition of maxmizing its utility, $MU_C = MU_R$, which is eqaul to $\\frac{a}{1-a}=\\frac{C}{R}$(**)\n\nNow, since the (*), (**) must hold at the same time, we can derive equation between $W$ and $R$ without $C$ as below:\n\n$P\\cdot \\frac{a}{1-a}\\cdot R = (T-R)\\cdot W$\n\nThen we get $R = \\frac{TW}{P(\\frac{a}{1-a})+W}$ and $L^s =T\\frac{P(\\frac{a}{1-a})}{P(\\frac{a}{1-a})+W}$\n\nbut my derivation of $L^s$ looks only decreasing while W is increasing.\n\nAny points did I do wrong? I want to did some decomposition of Slutsky, but lack of skills to deal with partial derivatives, it makes me hard to do also.\n\n\nIn this static model with no savings/intertemporal aspect, labor supply does not depend on the wage. Using the equality relations, we can maximize over $L^s$ without constraints\n\n$$\\max_{L^s} U = \\left(\\frac{L^s\\cdot W}{P}\\right)^a\\cdot (T-L^s)^{1-a}$$\n\n$$\\frac {\\partial U}{\\partial L^s} = \\frac a{L^s}\\cdot U - \\frac {1-a}{T-L^s}\\cdot U$$\n\nand setting this equal to zero we get the optimal $L^s$\n\n$$\\frac a{L^s}= \\frac {1-a}{T-L^s} \\implies L^s = aT$$\n\nOne can verify that, at the optimum, the second derivative of the Utility function is negative so we do have a maximum.\n\n| improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/443941/two-server-powersupplies-in-a-row-dangerous\nText:\nI have two server PSUs from HP which can output 12V with 1200W (HP DPS 1200.) My goal is to obtain 24V by chaining the outputs of the two units.\n\nI have modified one of the PSUs so that the negative output is no longer connected to earth by replacing one of the case screws with a nylon one, as recommended by threads in RC forums, where users use those supplies to power their battery chargers.\n\nThe metal case of both supplies is still grounded, so the only concern should be high voltages on the 24V output of the combined unit if something goes wrong inside the PSU.\n\nOne guy in these forums was concerned about the over voltage protection no longer working if this modification is done.\n\nI want to know if such a modification disables safety features in events where the transformer is defective and shorts mains voltage to the low voltage side and if the order in which the supplies get connected changes this behavior.\n\n(negative/earth side of the unmodified unit to 12v of the floating unit)\n\n  \u2022 \\$\\begingroup\\$ There is nothing called voltage. It is always voltage difference. If the PSU never sees a greater voltage difference on its output than it is rated for, you have nothing to worry. You may have to add a diode for reverse voltage though, in case the load shorts. \\$\\endgroup\\$ \u2013\u00a0Indraneel Jun 17 '19 at 2:49\n  \u2022 \\$\\begingroup\\$ Verify that 0V actually is disconnected from mains earth before connecting them in series. Put the multimeter in beep mode and poke the metal chassis right near the heatsinks and such to make sure there are no paths to earth remaining. \\$\\endgroup\\$ \u2013\u00a0Oskar Skog Jun 17 '19 at 3:18\n  \u2022 \\$\\begingroup\\$ @Oscar Skog, I have verified that the resistance between earth and the 0v output is now in the MOhms range... \\$\\endgroup\\$ \u2013\u00a0Beny Benz Jun 17 '19 at 9:02\n\nQuestion: Does this modification disable safety features?\n\nNO. Not if done exactly as stated.\n\nIt enables a status resistor loop to enable the supply and only removes the secondary earth bond and not the primary AC safety ground to enable series DC connection of 12+12=24V @ 75A (850W at 120Vac, 1200W out at 230Vac rating high efficiency) making the two supplies unique with an unmodified one = Earth gnd = V- = 0V and modified one 12Vout to V- to 24V=V+. with AWG 8 or heavier cable. You can choose an external fuse for the charger cables you select if undersized. ( e.g. or use welding cable)\n\nI understand all the safety requirements and fundamentals of this category of designs and none of the safety features are bypassed or disabled in the article link below. However, any modifications are not permitted for resale, but ok for personal use.\n\nI assume this is the one you have read, (because it is written by a professional and popular with hobbyists. )\n\nBut if you make any mistakes with your fingers touching charged HVDC contact points inside, this is your doing. -48V PSU's are normally designed with an earth ground jumper option for V+ or V- earthing. But for Server communication V- is always earth grounded for noise immunity. Short, #8 or bigger solid or stranded welding wire for interconnect cables are necessary to prevent short circuit wire fire. Your application load needs some kind of soft start switch to prevent overcurrent trips then a bypass series load for high current. How you regulate your battery charger with a BMS is outside the scope of this question.\n\nDO NOT attempt anything described herein without ensuring that you have taken all the necessary precautions to safeguard yourself and others from injury.\n\n|improve this answer|||||\n  \u2022 1\n    \\$\\begingroup\\$ Whoever downvoted , please show some courtesy to explain why \\$\\endgroup\\$ \u2013\u00a0Tony Stewart Sunnyskyguy EE75 Jun 17 '19 at 3:04\n\nYour Answer"}
{"text": "Retrieved from https://www.khanacademy.org/math/math-for-fun-and-glory/puzzles/brain-teasers/v/brain-teaser-blue-forehead-room\nText:\nMain content\nCurrent time:0:00Total duration:7:25\n\nBlue forehead room brain\u00a0teaser\n\nVideo transcript\n\nThere's a new reality television program, and it's called the Blue-- I should probably write it in blue-- but it's called the Blue Forehead Room. And what they do in this reality television program-- and you'll have to bear with me, because the show probably wouldn't be that interesting to watch-- but it's interesting to predict what happens. What they do is, they take a room. They'll call it the blue forehead room. And let's see, that's kind of a top view of the room. And let's say there's a door here. None of this is relevant to the actual problem. This is the door, right there. And what they do is they get 100 perfect logicians to sit in this room, in a circle. So they're all sitting in a circle in this room. Now, before the game even starts, before they even enter the room the first time, the logicians are told two things. They're told, One: that at least one of you has your forehead painted blue. At least one of you has your forehead-- And they all get their foreheads painted, so that obviously if you're the only guy who has your forehead painted. But you just don't know what color it is. So all of them have different color foreheads. Or, we don't know. But all they're told is, obviously I've painted your forehead. At least one of the people in the room that you will enter will have their forehead painted blue. And then they're also told that as soon as you deduce that your forehead is blue, you need to leave the room. And what's going to happen is-- and it's very important that I set this up properly. They're all outside of the room. No-one's inside the room. And let's say they're blindfolded. And while they're blindfolded, they essentially have the thing painted onto their forehead. So they can't see the paintbrush or anything. So they really don't know what's on their forehead. And then after that, they all enter the room. And they all sit in a circle like this, so that they can all look at each other. And let's say when they enter, the lights are off. So the lights are off, and then the protocol is that the lights will be turned on, and then they can all look around at each other. There's no reflective surfaces. They can't look into each other's eyes and try to see the reflection. No tricks like that. There are no mirrors in this room. Nothing like that. All they can do is look at each other. So, just as an example, let's say that this is me right here. As soon as the lights get turned on the first time, I'll be able to look at all the other people in the room. And I could see, it'll be pretty obvious to me if anyone has a blue forehead. Maybe that guy has one, that guy doesn't. I don't know, right? And I can see them. I can't see my own forehead. And what happens is, then they will turn off the lights, and the way they're going to do it is you have to leave the room after you have realized that you have a blue forehead. So for example, let's say I enter into the room, and because I'm a perfect logician I see things that allow me to perfectly deduce that I have a blue forehead. Then what they're going to do is they're going to turn off the lights again. And then, if I know that I have a blue forehead while the lights are turned off, I would leave the room. And then when they turn the lights back on, I'd be gone. So there would be no Sal here. So let's say there were 100 before, then there would be 99 guys sitting in the room. Right? As soon as I realize I have a blue forehead, when the lights get turned off, I leave. And just remember these are perfect logicians. So everyone in the room. And not only are they all perfect logicians, but they all know that everyone else is a perfect logician. So, everyone is also told, and this is true, everyone is a perfect logician. Which means they have infallible powers of logic. So my question to you-- Just remember, I have each of these perfect logicians. We set them up outside of the room, paint their foreheads. They're blindfolded. They have no clue. Then we have all of them walk into a dark room, sit in a circle like this. And then what we tell them is, as soon as you realize that you have a blue forehead, as soon as you have a blue forehead, you have to leave the room. Now my question to you is, let's say that we've actually painted everybody's forehead blue. What happens? So remember, this is what we've told each of the people. Right? As soon as you realize your forehead is blue, you leave the room. And now I've just asked you, the producers like to really play with these logicians. They've actually painted everybody's forehead blue. So when everyone goes in the room the first time, what's going to happen? Let's say I'm one of the logicians. This is me right here. As soon as I open my eyes, I'm going to see 99 other fellow logicians with blue foreheads. And then, maybe I can somehow deduce something about my own. I don't think you can. And the lights will go off. And then if I haven't deduced anything about my own blueness of my forehead, then they'll turn the lights back on. And then maybe some other guy will have left. I don't know. Or maybe not. And then I'll see the same 99 guys again. And that'll just keep occurring until something happens. And my question to you is what happens? When? And why? I'm thinking whether I should give you a hint right now. Well let me tell it to you this way. That's the problem. You should be able to solve it. And just so you know where this came from, if I remember correctly I think this was on a computer science exam I had at MIT. So just so you know, this isn't just for fun. I don't want to go into all of the applications that this type of problem can apply to, because that by itself would be a bit of a hint. So if you don't want a hint, turn off the video now or pause it. If you do want a hint, I'm about to give it to you. So my hint is-- and remember turn this off if you don't want to hint-- but the hint is what happens when there are less than 100 people. So I gave the situation where we have 100 logicians. But this problem is actually a lot easier if you try it with a smaller number. Anyway I'll see you in the solution video."}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/32070/auto-delete-parent-window-when-deleting-any-child/32107\nText:\nI understand that when a window is split, the original window and the new window become children under a new \"parent window\".\n\nI would like the option to somehow register these windows such that when either child window is deleted, the other child and the parent are also automatically deleted.\n\nHere's why I want this ...\n\nI'm using a complicated 3rd-party package that has a number of ways to create buffers and windows. Under certain isolated conditions (usually during a conditional operation within a hook function), I split certain windows.\n\nIf I use the standard facilities of this package to delete the original window (which is now one of the two children), the other, newly created child window remains.\n\nI know that I can write code to determine the parent of a window being deleted and to write more code to delete its parent and sibling windows. However, this involves manually modifying functions within this complicated 3rd-party package, and I'd like to avoid this.\n\nIdeally, I'd like to somehow register the children and the parent at the time that the window is initially split, so that whenever one of the three windows is deleted, the other two are also automatically deleted. This way, when the existing 3rd-party code deletes the original window as part of its normal processing, the parent and the other child will also automatically be deleted.\n\nI have not been able to find any such facility in emacs nor in any searches. Does such a thing exist, by any chance?\n\nOne idea which occurs to me is to write wrapper functions for delete-window and split-window and install them via emacs' advice mechanism. But is there perhaps another mechanism for my desired functionality which might already exist?\n\nThank you very much for any suggestions.\n\nNOTE: In digging through the emacs source code, I notice something called an \"atomic window\" or an \"atom window\". I can't find many docs for this, but it seems like it might give me what I want. For example, look at the final paragraph of the doc string for delete-window ...\n\n(delete-window &optional WINDOW)\n\nDelete WINDOW. WINDOW must be a valid window and defaults to the selected one. Return nil.\n\nIf the variable \u2018ignore-window-parameters\u2019 is non-nil or the \u2018delete-window\u2019 parameter of WINDOW equals t, do not process any parameters of WINDOW. Otherwise, if the \u2018delete-window\u2019 parameter of WINDOW specifies a function, call that function with WINDOW as its sole argument and return the value returned by that function.\n\nOtherwise, if WINDOW is part of an atomic window, call \u2018delete-window\u2019 with the root of the atomic window as its argument. Signal an error if WINDOW is either the only window on its frame, the last non-side window, or part of an atomic window that is its frame\u2019s root window.\n\n... and here's the doc string for a function I found called display-buffer-in-atom-window ...\n\n(display-buffer-in-atom-window BUFFER ALIST)\n\nDisplay BUFFER in an atomic window. This function displays BUFFER in a new window that will be combined with an existing window to form an atomic window. If the existing window is already part of an atomic window, add the new window to that atomic window. Operations like \u2018split-window\u2019 or \u2018delete-window\u2019, when applied to a constituent of an atomic window, are applied atomically to the root of that atomic window.\n\nALIST is an association list of symbols and values. The following symbols can be used.\n\n\u2018window\u2019 specifies the existing window the new window shall be\ncombined with. Use \u2018window-atom-root\u2019 to make the new window a\nsibling of an atomic window\u2019s root. If an internal window is\nspecified here, all children of that window become part of the\natomic window too. If no window is specified, the new window\nbecomes a sibling of the selected window. By default, the\n\u2018window-atom\u2019 parameter of the existing window is set to \u2018main\u2019\nprovided it is live and was not set before.\n\n\u2018side\u2019 denotes the side of the existing window where the new window shall be located. Valid values are \u2018below\u2019, \u2018right\u2019, \u2018above\u2019 and \u2018left\u2019. The default is \u2018below\u2019. By default, the \u2018window-atom\u2019 parameter of the new window is set to this value.\n\nThe return value is the new window, nil when creating that window failed.\n\nI'll be investigating this atom(ic) window thing, and I'll report back.\n\n  \u2022 Instead of fiddling with core functions that every library relies upon, I would recommend you run a test when closing the selected-window for other windows containing a particular buffer and then delete those windows using the optional argument in delete-window. For example, you can set up the letter q to call your custom quit window function in the selected-window to handle deleting any other windows matching your specified criteria. You could get fancy and record prior windows in a variable or a window-config -- buffers inside windows can change . . . . \u2013\u00a0lawlist Apr 11 '17 at 16:57\n  \u2022 Thank you. Yes, I can do that, but it would involve re-writing parts of the 3rd-party package that I'm using, and I'm trying to avoid that. I don't delete the window \"manually\"; rather, the 3rd-party software deletes it during its own processing. That's why I'm thinking that I might have to override some core functions. But perhaps there are as-yet-undiscovered hooks within the 3rd-party package that I could use for this purpose. I'm continuing to investigate. \u2013\u00a0HippoMan Apr 12 '17 at 10:59\n  \u2022 I just discovered something in emacs called an \"atom window\" or an \"atomic window\" which might give me what I want. I added text to my question, above, discussing this. \u2013\u00a0HippoMan Apr 12 '17 at 11:23\n  \u2022 ... and atom(-ic) windows indeed do the trick! See my Answer. \u2013\u00a0HippoMan Apr 12 '17 at 13:44\n\nIt turns out that atom(ic) windows are indeed exactly what I want. Consider this code ...\n\n;; Instead of split-window, do this ...\n(let ((subwin (display-buffer-in-atom-window\n               `((window . ,(get-buffer-window (current-buffer)))\n                 (side . below)))))\n  (with-selected-window subwin\n    ;; do whatever you want with subwin\n\nWhen the original window is deleted via a generic call to (delete-window), the subwindow also gets deleted.\n\n| improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from http://www.mathpages.com/home/kmath300.htm\nText:\nTwo In the Shop\n\nSuppose we have 10 units in service, each with an MTBF (Mean Time \nBetween Failure) of 2,000 hours.  Each operates for 2 months per \nyear.  When one fails it is returned to the maintenance shop for \nrepair, and spends 1 week there.  What is the probability that\ntwo units will be in the maintenance shop at the same time for \n\nAssuming the MTBF is quoted in operational hours, the failure\ndistribution is exponential, and the \"2 months per year\" operational\ntime is spread evenly through the year (e.g., 4 hours per day), it\nfollows that the mean calender time between failures of a specific\nunit is 12,000 hours.  Also, a unit spends 168 hours (=1 week) in \nthe shop each time it fails.  Therefore, each unit has a mean duty\ncycle of 12168 hours, of which 12000 are spent in the field and 168\nare spent in the shop.\n\nThe periods in the shop are random and uncorrelated for each of the \n10 units.  The probability of any particular unit being in the shop \nat a randomly chosen instant is just p = 168/12168.  The probability\nof two specific units being in the shop at a random instant is p^2.\nIn general, the probability of exactly k out of 10 units being in the\nshop at a given instant is \n              Pr{k}  =   ----------  p^k (1-p)^(10-k)\n                         (10-k)! k!\n\nso the probability of finding exactly 2 units in the shop is 0.007675,\nwhereas the probability of TWO OR MORE in the shop is 0.007970.\n\nOf course, the above analysis makes several tacit assumptions, and in\nreality the probability could be significantly higher or lower, for \nany of several reasons.  For example, we didn't specify that all the\noperational periods were independent and uniformly distributed over\nthe year, so it's possible that all the units are operational for the \nsame 2-month period each year, which would increase the probability of\nhaving two in the shop at some point during the \"busy season\".  On the \nother hand, the real probability could also be much smaller.  Strictly \nspeaking, within the stated conditions of the original problem, the \nprobability of two or more units in the shop simultaneously could be \nanything from 0 to about 0.3874.  For example, if each unit operates \nfor EXACTLY 2000 hours between failures, we could stagger their repair \ncycles so that one fails every 200 hours, which is greater than the \none week repair time of 168 hours.  Thus, the probability of two in \nthe shop would be 0.  (One could also manipulate the probability by \nassuming the units operate in more or less mutually exclusive 2-month \nperiods during the year.)\n\nOn the other hand, if the units are operated in synchronized pairs\n(hopefully not two engines of a twin-engine airplane), and each fails\nevery 2000 hours exactly, then each pair is in the shop for 168 hours\nout of every 2168 hours, giving a probability of 0.0774.  If the five\npairs of units are staggerred, then the fraction of [active] time with\ntwo units in the shop would be 0.3874.\n\nIt might be interesting to figue out the maximum probability that\nwould be strictly consistent with the stated conditions of the\nproblem.  In many casually-stated probability problems it turns out\nthe answer can be anything on the interval from 0 to 1 (inclusive).\n\nReturn to MathPages Main Menu"}
{"text": "Retrieved from http://mathoverflow.net/questions/34988/maximum-number-of-distinct-diagonals-generated-by-permutations\nText:\nTake the 2-minute tour \u00d7\n\nGiven an n by $n$ matrix with $0$'s and $1$'s only, consider the $n!$ different permutations generated by permuting the rows, what is the maximum number of different diagonals generated?\n\nshare|improve this question\nIs the question for a general upper bound or an upper bound if I know the matrix? \u2013\u00a0 Daniel Krenn Aug 9 '10 at 11:09\nAs in, you can choose any n by n 0-1 matrix you want to maximize this number. \u2013\u00a0 Kamil Aug 9 '10 at 12:12\n\n1 Answer 1\n\nIf I am allowed to choose the matrix, it seems that I can generate all $2^n$ different diagonals.\n\nEdit. Sorry, this approach only generates $2^n -n $ diagonals.\n\nLet $I$ be the $n \\times n$ identity matrix and let $D$ be a diagonal whose non-zero entries are indexed by $S$.\n\nFurther suppose that $D$ does not have exactly one zero entry.\n\nLet $\\pi$ be a perumation of the rows of $I$ whose fixed points are exactly $S$. Then the diagonal of $\\pi(I)$ is $D$, and there are $2^n-n$ such diagonals.\n\nUpdate. Here is a proof that $2^n-n$ is in fact the best one can do.\n\nAn $n \\times n$ bipartite graph is a bipartite graph with bipartition $([n]_r, [n]_c)$, where $[n]_r$ and $[n]_c$ are both copies of $[n]$. Let $G$ be an $n \\times n$ bipartite graph. Define $G'$ to be equivalent to $G$, if $G'$ can be obtained from $G$ by complementing the neighbourhoods of some vertices in $[n_r]$. Note that the equivalence class of $G$, denoted $[G]$, has size $2^n$.\n\nIt is easy to check that the following lemma proves the tightness of the bound.\n\nLemma. For any $n \\times n$ bipartite graph $G$, at most $2^n-n$ members of $[G]$ have a perfect matching.\n\nProof. For each $i \\in [n]_c$ there is a graph $G^i \\in [G]$ such that $i \\in [n_c]$ has degree 0 in $G^i$. Just pick the vertices in $[n]_r$ that are adjacent to $i$ in $G$ and complement their neighbourhoods. If all $G^i$ are distinct, then the lemma clearly follows. Otherwise, $G^i=G^j$ for some $i \\neq j$. Thus, both $i$ and $j$ have degree 0 in $G^i$. But now, the $n$ graphs obtained from $G^i$ by performing a single complementation each do not have a perfect matching.\n\nshare|improve this answer\nThis seems to have a slight problem with the case of the configurations with exactly one zero. \u2013\u00a0 damiano Aug 9 '10 at 12:20\nNot with $n=3$ you can't :-) \u2013\u00a0 Robin Chapman Aug 9 '10 at 12:23\nI suppose that I cannot generate diagonals that have exactly $n-1$ ones in this way, since if I fix $n-1$ rows, then I automatically fix the last one. But it seems that I can still get $2^n-n$ diagonals. \u2013\u00a0 Tony Huynh Aug 9 '10 at 12:24\nA clever argument! One minor comment: I do not think that the current proof of the lemma deals with the case where more than one vertex in [n]_c have exactly the same set of neighbors, but it can be fixed easily. \u2013\u00a0 Tsuyoshi Ito Aug 10 '10 at 1:03\njust a minor remark, the same without graphs: if two rows (say i-th and j-th) are equal to $r$, then each diagonal has at least two coincidences with $r$ (coincidence means coincidence of one of $n$ coordinate functionals). So, there are at least $n$ forbidden diagonals. If all rows are different, then all their complements are forbidden and we again have $n$ forbidden diagonals. \u2013\u00a0 Fedor Petrov Aug 10 '10 at 12:17\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/57266.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nBlending Seed\n\nDate: 09/27/98 at 00:26:11\nFrom: Anonymous\nSubject: Grass seed problem\n\nHi!  Here is a problem that my father and I have been working on for \nhalf an hour:  \n\nA lawn-and-garden dealer wants to make a new blend of grass seed by \nusing 200 pounds of $0.45 per pound seed and some $0.65 per pound \nseed. How much of the $0.65 seed does the dealer need to make a $0.55 \nper pound blend?\n\nThank you so very much for your help. Hope to hear from you soon.\n\nDate: 09/27/98 at 01:22:14\nFrom: Doctor Ken\nSubject: Re: Grass seed problem\n\n\nFirst I'll give you a sort of intuition-based solution, and then I'll \ngo back and be a little more formal, writing things out in algebraic \n\nThe first thing I noticed about this problem was that a pound of one \nkind of seed costs 45 cents, a pound of the other costs 65 cents, and \nwe want to make a mix that costs 55 cents. Well, 55 is halfway between \n45 and 65, so it seems like we should combine equal parts of the two \nkinds of seed. Since we need to use 200 pounds of the first kind, we \nshould use 200 pounds of the other kind, for a total of 400 pounds.  \n\nTo verify this solution, let's see how much the pieces would cost.  \n200 pounds of the first kind of seed would cost 200 * $0.45 = $90, and \n200 pounds of the second kind of seed would cost 200 * $0.65 = $130.  \nWe bought 400 pounds total and paid $220, so we paid on average \n$220/400 = $0.55. Seems to check out.\n\nNow, how can we use algebra to find this same solution? The first \nthing I usually try to do is to find a sentence (an English sentence, \nor whatever language you like best) that says something true and \nuseful about the problem. Then I translate that sentence into an \nalgebraic equation.  \n\nIn this problem, I think I'd make this sentence: \"The cost per pound \nof the combined seed mixture is 55 cents.\" Let's work on translating \nthat into an equation. First it becomes:\n\n   cost per pound = $0.55\n\nWhat is the cost per pound? It's the number you get when you divide \nthe total price by the number of pounds of seed:\n\n     total price\n    pounds of seed\n\nThe total price is the cost of the 45c part and the 65c part. The \nnumber of pounds of seed is the number of pounds of the first kind \nplus the number of pounds of the second kind. The only unknown thing \nhere is the number of pounds of the second kind, so let's call that x.\n\n    200*$0.45 + x*$0.65\n         200 + x\n\nNow we've done the translation. I'll leave it to you to work out the \nsolution from here, and verify that the answer really is 200.\n\n- Doctor Ken, The Math Forum\nAssociated Topics:\nElementary Word Problems\nMiddle School Algebra\nMiddle School Word Problems\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/104426/an-pure-intriguing-counting-problem-of-index-sets\nText:\nTake the 2-minute tour \u00d7\n\nHi Guys. The problem here seems like a homework, but I think that it is not that easy.It comes from a theorem I recently proved.The content of the theorem is not important, the issue is that I have no idea how to counting the number of the index sets that satisfy the constraint the theorem restricted.\n\nTheorem: Suppose a sequence of integers has distinct $n^2+1$ numbers and have exactly t one monotone subsequence of length $n+1$,(Note Erdos Szekeres Theorem guarantees the existence of the unique subsequence.),the index set $C$ of the unique monotone subsequence of length n+1 must satisfy following properties.\n\n(Constraint of index set)\n\nLet $C_i$ denotes the $i$th element of the index set $C$ where $2 \\leq i \\leq n$.Then\n\n(0) $ C_1 < C_2 < \\dots < C_i < C_{n+1}$\n\n(1) $j< C_1 <(j-1)n+1$\n\n(2) $ij < C_i<(j-1)n+i+(i-2)(n-j)$\n\n(3) $ nj+1 < C_{n+1} < (j-1)n + n + 1 + (n-1)(n-j) $\n\nwhere $j$ is any integer for $1$ to $n$ .\n\n(End of the Constraint)\n\nThe meaning of the $j$ is that if the elements of $C$ satisfies the group of constraints above for any $j$, we say that it satisfies the constraints.\n\nEND of the theorem.\n\n\nHow many index sets C satisfy the constraint above are there?\n\nOr could someone provide an approximation of the numbers of qualified index set $C$s. Even the ration of the qualified index sets to the trivial bound $ { n^2 +1 \\choose n+1 }$ would be very desirable.\n\nIF you are reading this, thank you for you patient for at least arriving here. I would also thank for anyone that might suggest some people might know a method to the problem.\n\nshare|improve this question\nYour last constraint expression might be easier to grok if written as n^2+1-(n-j). Also, there have been a few questions asked on related matters recently on specialized combnations, which is what your sets appear to be. You might check those out. (Link to be provided later.) Gerhard \"Search Engines Stole My Memory\" Paseman, 2012.08.10 \u2013\u00a0 Gerhard Paseman Aug 10 '12 at 22:04\nHere is the first in a chain of links that might be of interest. mathoverflow.net/questions/104028/string-possible-combinations/\u2026 . My answer has a comment from me which contains the next link. My guess is that parking functions and Gessel-Viennot (somewhere after the third link) will be relevant to your problem. Gerhard \"Ring Around The Web References\" Paseman, 2012.08.10 \u2013\u00a0 Gerhard Paseman Aug 11 '12 at 2:12\nHi Gerhard. Thanks very much about your links.It seems that I need time to dig it out. \u2013\u00a0 WangYao Aug 11 '12 at 6:31\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/20942/brownian-bridge-under-observational-error?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $Z_t$ follows a simple discrete random walk $Z_t=Z_{t-1}+e_t$ , where $e_t$ are a bunch of uncorrelated normal variables with arbitrary variance sigma^2, and that there are observations of the series at t=a and t=b, with both observations having normal uncorrelated observational error with variance $O_a$ and $O_b$.\n\nHow can I find distribution for intermediate values between a and b?\n\nshare|improve this question\n\n1 Answer 1\n\nif you consider a Gaussian vector $V=(X,Y) \\in \\mathbb{R}^{d=m+n}$, you know how to find the conditional distribution of $X$ knowing the value of $Y=y$, right ? This is exactly the same thing here.\n\nFor example, let us suppose that $a=0, b=N+1$:\n\n  \u2022 you have a noisy observation $Y=(y_1, y_2)=(O_a, O_b)$ with know covariance matrix $\\Sigma_Y$\n  \u2022 the data you are looking for, $X=(z_1, \\ldots, z_N) \\in \\mathbb{R}^N$, have a known covariance matrix $\\Sigma_X$\n  \u2022 the covariance matrix $E[X Y^t] = \\Sigma_{X,Y}$ is also known.\n\nA quick way to find the conditional distribution of $X$ knowing $Y$ is to write $$X = AU + BV$$ $$Y=CU$$ where $U,V$ are independent standard Gaussian random variable of size $2$ and $N$ respectively, while $A \\in M_{N,2}(\\mathbb{R})$ and $B \\in M_{N,N}(\\mathbb{R})$ and $C \\in M_{2,2}(\\mathbb{R})$. Because\n\n  \u2022 $CC^t = \\Sigma_Y$ gives you $C=\\Sigma_y^{\\frac{1}{2}}$,\n  \u2022 $AC^t = \\Sigma_{X,Y}$ then gives you $A=\\Sigma_{X,Y}\\Sigma_y^{-\\frac{1}{2}}$,\n  \u2022 $AA^t + BB^t = \\Sigma_{X}$ then gives you $B=(\\Sigma_{X}-\\Sigma_{X,Y}\\Sigma_y^{-1}\\Sigma_{X,Y})^{\\frac{1}{2}}$,\n\nthe $3$ matrices are easily computable, and $C$ is invertible in the case you are considering. This shows that if you know that $Y=y$, the conditional law of $X | Y=y$ is given by $$X = AC^{-1}y + BV,$$ which is a Gaussian vector with mean $AC^{-1}y = \\Sigma_{X,Y}\\Sigma_y^{-1}y$ and covariance $BB^t = \\Sigma_{X}-\\Sigma_{X,Y}\\Sigma_y^{-1}\\Sigma_{X,Y}$\n\nshare|improve this answer\nI'm having trouble working through the notation, specifically the covariance matrix of Y (The covariance matrix of the sampling error? Or of the observations?). Could you elaborate the calculation for N=2? \u2013\u00a0 David Shor Apr 11 '10 at 11:12\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/32944/how-to-decide-convergence-of-the-ensemble-average-in-a-monte-carlo-process\nText:\nTell me more \u00d7\n\nI am simulating electromagnetic scattering off a rough surface. The usual process is to do a Monte Carlo simulation, which is briefly described as follows.\n\n  \u2022 Generate a randomly rough surface, and compute the scattered far-field intensity in a particular direction of interest.\n  \u2022 Repeat this process for several different instances of rough surfaces, and get an ensemble average of the far-field intensity.\n\nThis ensemble average converges after sufficient instances have been taken. So, my question is that how does one determine in a rigourous manner if convergence has happened? In the electromagnetic scattering community, this question is not addressed, and heuristic estimates are used (e.g. \"we used 100 instances\") instead.\n\nThanks apriori.\n\nshare|improve this question\nIn case you are not aware, there is a scientific computation site now in beta which may have a higher density of experts. I'm sure they would be happy to have this question (and it might be a better fit there than here), but (1) I won't migrate it unless you ask and (2) I don't think it is in any danger of being closed here. Your choice. \u2013\u00a0 dmckee Jul 27 '12 at 0:14\nThanks for the tip @dmckee, I will keep that group in mind for future questions. I've got one good answer here already, and I don't mind if you migrate it to the other group. \u2013\u00a0 UdX Jul 27 '12 at 17:39\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nIn this problem, you have a real valued quantity which has an unknown distribution, and you want to estimate the error on the average from averaging N independent draws. This is an application of the central limit theorem.\n\nIf you choose $N$ independent picks from a distribution $\\rho(x)$ with zero mean and finite second moment, meaning that\n\n$$ \\int x^2 \\rho(x) = \\sigma^2$$\n\nThen add the picks together to get $X$, you get that the sum is distributed as the $N$-fold convolution of $\\rho$ with itself. This eventually converges to a Gaussian of second moment $N\\sigma^2$. This means that the error in taking an average over $N$ steps is the width of the distribution of $X/N$, which is\n\n$$ {\\sqrt{N\\sigma^2}\\over N} = {\\sigma\\over \\sqrt{N}}$$\n\nIn other words, the error is Gaussian distributed with a width that falls off as the square root of the number of trials. Your error is the $\\sigma$ of the distribution divided by the square root of the number of trials.\n\nIf your trials give you $x_1,x_2,...,x_N$ for x, you calculate the mean of these, and call it x:\n\n$$ x = {\\sum_i x_i \\over N}$$\n\nThen calculate the average square of $(x_i-x)$ to get a best-estimator for $\\sigma$\n\n$$ \\sigma^2 = {\\sum_i (x_i - x)^2 \\over N} $$\n\nThen your error is $\\sigma/\\sqrt{N}$. This is the best estimate to make in your circumstances.\n\nThe one thing you have to check is the convergence to a Gaussian. This means that you make sure that the roughness model gives a distribution of intensities where the $sigma$ is not dominated by rare events, so that the estimate from N trials of $\\sigma$ is reliable. In principle, you could have a contrived rough surface model which produces ridiculous things on very rare occasions--- for example, suppose the roughness occasionally conspires over long distances to be a nearly exactly periodic sinusoid. This makes the surface a diffraction grating, with extremely sharp peaks at certain directions. If you are looking at the direction where the diffraction peak occurs, you get a huge outlier in the scattered intensity for a diffraction grating configuration, and this might occur in too few trials, so that the peak might never show up in your limited number of trials.\n\nIn practice, you just make sure your roughness model is not conspiratorial (so as to make periodic gratings) and for this it is usually enough (aside from contrived nonlocal roughness conspiracy) to check that the distribution of intensities doesn't have a power-law tail. You cannot do anything rigorous without a description of the roughness model, so that you can show that diffraction grating conspiracies don't happen with any reasonable probability, so that the second-moment is well described by what you see.\n\nThis is usually true, absent obvious tail phenomenon (for example, you see 2 trials out of 200 that dominate the variance) so doing a central limit theorem error analysis is good enough.\n\nshare|improve this answer\nThanks for the useful answer, @Ron. I do know the statistics of the rough surface, and can therefore be confident that there are no pathological surfaces in my ensemble. Just to be precise, what you mean by error is the standard deviation. PS: A small typo in your answer: the second moment of the sum is N \\sigma^2, not N \\sigma. \u2013\u00a0 UdX Jul 27 '12 at 20:35\nadd comment\n\nDo you have access to the standard deviation? If so, the coefficient of variation is a good measure of convergence: A generalisation is the root mean square deviation. Those wikipedia pages also tell you how to handle, to some extent, situations where the mean is close to zero.\n\nshare|improve this answer\nWell, since I have access to the intensity for each instance of a rough surface, I can generate all statistics, including the standard deviation. will fail for a zero-mean process, though. \u2013\u00a0 UdX Jul 27 '12 at 17:41\n@UdX I just updated the answer with some links that may be useful. Hope that helps. \u2013\u00a0 Gabriel Landi Jul 27 '12 at 23:13\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/64231.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nWhere Do the Parentheses Go?\n\nDate: 09/12/2003 at 00:48:21\nFrom: Lynn\nSubject: order of operations and writing equations\n\nI'm trying to help my daughter with some problems she's been given. \nEach one has a string of numbers and operations on one side, and a\nresult on the other side.  What you're supposed to do is insert\nparentheses around the numbers and operations in order to get the\nresult.  For example:\n\n      2    2    2\n 2 + 7  - 3  / 3  - 1 * 5 = 35\n\nI know how PEMDAS works, but I don't see how to solve these problems\nwithout just doing a lot of guessing.  Argh!\n\nDate: 09/12/2003 at 08:53:18\nFrom: Doctor Peterson\nSubject: Re: order of operations and writing equations\n\nHi, Lynn.\n\nThis sort of problem is just a puzzle -- there is no standard, \nstraighforward way to solve it, you just have to try things out and \nmake intelligent guesses. It may help to read what we have to say \nabout the order of operations\n\n\nbut there is no specific technique we can give you. I'll just try to \nget you started, thinking through the problem until I see where to go.\n\nUsing our e-mail notation, your equation is\n\n\nLooking at this, I notice that 35 = 5*7, and that there is a 7 and a \n5 in the left side. So my first action is to add parentheses so that \nmultiplication by 5 will be the last operation performed; if we can \nmake the rest of the expression equal 7, we'll be in good shape. This \nis just a guess; it may turn out that we won't want to multiply by 5 \nat all. But we can try it:\n\n  (2 + 7^2 - 3^2 / 3^2 - 1) * 5 = 35\n\nNow, it's not obvious that we can get 7 out of that, or that the 7 \nthat is there will in any way show through in the final form (since \nwe can't undo the squaring, and we would have to divide by 7 to leave \nourselves with just one 7). But I do see, at least, that 7^2 is much\ntoo big, so we have to make it smaller, either by subtracting\nsomething big or by dividing. \n\nAs written, the division only affects 3^2; 3^2/3^2 is 1. So we'll want\nto have parentheses around at least part of \n\n  2 + 7^2 - 3^2\n\nand we can decide eventually how much of \n\n  3^2 - 1\n\nto divide by. If we used all of both, we'd have\n\n  (2 + 7^2 - 3^2) / (3^2 - 1) = 42/10\n\nwhich is in the right ballpark but not a whole number, much less \nexactly 7. It doesn't help if we divide 42 by 3^2 or by 3 rather than \n3^2 - 1.\n\nNow we can try either adding more parentheses inside (2 + 7^2 - 3^2) \nto change what we are dividing, or pull the 2 outside of the \n\nAt this point I've finally looked ahead enough to see the solution. \nI'll leave you with just a hint: you'll want to take the first choice \nI mentioned in the last paragraph, and you'll have to change what you \ndivide by as well. See what you can do.\n\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Puzzles\nMiddle School Puzzles\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/206406/what-if-every-function-in-cx-has-finite-spectrum\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $X$ is a compact Hausdorf space, and that every continuous function on $X$ has finite range. How do I conclude that $X$ is a finite set, hence with discrete topology? So far, I have managed to use Urysohn to show that the closed maximal connected component decomposition of $X$ (as opposed to the path component decomposition) is one where every component is a 1 point set.\n\nThis question arose from trying to solve the question that every C* algebra with all normal elements having finite spectra are finite dimensional. A more direct solution to this general question would also suffice, because actually implies the special case I've reduced it to. By taking a unitization, and then a MASA in the unitization, one gets to the case I've gotten to.\n\nAlso, a topological question that is in the same setup but handles a related operator algebras question is this: if a net $u_i$ and $u$ in $X$ has the property that for all continuous $f \\in C(X)$ one has that $f(u_i)$ converges to $f(u)$ then must $u_i$ converge to $u$ in topology? This is for showing that the gelfand representation of a $C(X)$ space is itself. I'd like this fact for $X$ locally compact Hausdorf, actually.\n\nshare|improve this question\nFor 2: Suppose $u_i$ doesn't converge to $u$. Then there is a neighborhood $U$ of $u$ and a subnet such that $u_j \\notin U$ for all $j$ (since $u_j$ is not eventually in $U$, it is frequently in $U^c$). Apply Urysohn's lemma to get a continuous function such that $f(u) = 1$, supported in $U$. Get $f(u_j) = 0$ for all $j$, so $0 = f(u_j) \\nrightarrow f(u) = 1$. \u2013\u00a0 commenter Oct 3 '12 at 8:09\nadd comment\n\n3 Answers\n\nup vote 1 down vote accepted\n\nFor the first question. suppose X has an infinite sequence of point $x_0, ...,x_n,...$.\n\nfor each $i$ considere a function $f$ such that $f_i(x_0)= 0$,...,$f_i(x_{i-1})=0$, $f_i(x_i)=1$, and $\\Vert f_i \\Vert \\leqslant 1$\n\n(Uryshon can do that, just consider the function on {x_0...x_i} which is a discret space and then use the extension properties...)\n\nLet $ g = \\sum \\frac{f_i}{2^i}$.\n\nthen $\\frac{1}{2^{i-1}} \\geqslant g(x_i)\\geqslant \\frac{1}{2^i}$\n\nensure you that $g$ takes an infinite number of value.\n\nshare|improve this answer\nYes, because each f_i can be taken to be nonnegative. \u2013\u00a0 Jeff Oct 3 '12 at 7:56\nYes you are right, in my mind they were positive but i forgot to write it ^^ \u2013\u00a0 Simon Henry Oct 3 '12 at 10:57\nadd comment\n\nFor your first question, let $x\\in X$ be arbitrary, and let $U$ be any open set containing $x$. Let $f:X\\to[0,1]$ be a continuous function such that $f(x)=0$ and $f(y)=1$ for all $y\\in X\\setminus U$, and let $\\alpha$ be the smallest non-zero element of the range of $f$. Then $V=\\left\\{y\\in X:f(y)<\\frac{\\alpha}2\\right\\}$ is a clopen neighborhood of $x$ contained in $U$. Thus, $X$ has a clopen base, i.e., is zero-dimensional. This means that if $p$ is a non-isolated point of $X$, we can construct a sequence $\\langle U_n:n\\in\\Bbb N\\rangle$ of clopen neighborhoods of $p$ such that $U_0=X$, $U_{n+1}\\subseteq U_n$ for each $n\\in\\Bbb N$, and for each $n\\in\\Bbb N$ there are distinct points $x_n,y_n\\in U_n\\setminus U_{n+1}$. Let $K=\\bigcap_{n\\in\\Bbb N}U_n$.\n\nFor each $n\\in\\Bbb N$ there is a continuous function $$f_n:U_n\\setminus U_{n+1}\\to\\left[ \\frac1{2^{n+1}},\\frac1{2^n}\\right]$$ such that $f(x_n)=\\dfrac1{2^n}$ and $f(y_n)=\\dfrac1{2^{n+1}}$. Define\n\n$$f:X\\to[0,1]:x\\mapsto\\begin{cases} f_n(x),&\\text{if }x\\in U_n\\setminus U_{n+1}\\\\ 0,&\\text{if }x\\in K\\;. \\end{cases}$$\n\n(In other words, $f=\\sum_{n\\in N}f_n$ on $X\\setminus K$, and $f[K]=\\{0\\}$.) Clearly $f$ is continuous on $U\\setminus K$, since each part of its definition has clopen domain, and the construction also ensures that $f$ is continuous on $K$. But the range of $f$ includes $2^{-n}$ for every $n\\in\\Bbb N$, so it\u2019s infinite. Thus, $X$ cannot have a non-isolated point and must therefore be finite.\n\nAdded: For the second question, suppose that the net $\\nu=\\langle x_i:i\\in I\\rangle\\not\\to x$, where $\\langle I,\\le\\rangle $ is a directed set. Then $x$ has an open neighborhood $U$ such that $\\nu$ is frequently in $X\\setminus U$. Let $f:X\\to[0,1]$ be a continuous function such that $f(x)=0$ and $f(y)=1$ for $y\\in X\\setminus U$, and suppose that $\\langle f(x_i):i\\in I\\rangle\\to 0=f(x)$. Then there is an $i_0\\in I$ such that $f(x_i)<\\frac12$ for all $i\\ge i_0$. Clearly $\\left\\{y\\in X:f(y)<\\frac12\\right\\}\\subseteq U$, so there is an $i\\ge i_0$ such that $x_i\\notin U$ and hence $f(x_i)=1$; this contradiction shows that $\\langle f(x_i):i\\in I\\rangle\\not\\to f(x)$.\n\nIn other words, if $\\langle f(x_i):i\\in I\\rangle\\to f(x)$ for every $f\\in C(X,\\Bbb R)$, then $\\langle x_i:i\\in I\\rangle\\to x$ in $X$.\n\nshare|improve this answer\nadd comment\n\nFor your second question, if X is compact, you can extract a converging subnet from (u_i) and let u' be its limit... you have f(u)=f(u') for every continuous f, and hence u=u'. If X is just locally compact, then consider its one point 'alexandrov' compactification. (and if he is just regular, then the Stone Cech compactification will do the trick).\n\nshare|improve this answer\nI think this only shows that $u=u'$, not that this common value is the limit of the net. Also, I should note that when I said I wanted this for X locally compact Hausdorf, let me clarify in case there is any misunderstanding that the relevant object then is not $C(X)$ but rather $C_0(X)$ the continuous functions vanishing at infinity. \u2013\u00a0 Jeff Oct 3 '12 at 7:55\nYes, but if $(u_i)$ was not converging to $u$, then you can construct a sub net of $u_i$ which stay away from $u$, and hence extract a \"sub-sub-net\" which converge to something diferent than u, which leads to a contradiction. that a classical fact in topologie : in a compact set, if every convergent extration of a sequence/net converge to the same value, then the sequence/net is convergente. \u2013\u00a0 Simon Henry Oct 3 '12 at 10:55\nand the argument still hold for $C_0(X)$ on a localy compact space as $C_0(X)$ separate the point of the alexandrov compactification of $X$. ($C_0(X)$ is the set of function on the compactification which vanish at infinity... ) \u2013\u00a0 Simon Henry Oct 3 '12 at 10:58\nI have a problem with this fact. In a metric space, one has a convergent sequence whenever he verifies that every subsequence has a convergent subsequence converging to the same value. But with nets, I don't see an analogous result, because for me a subnet is the original net precomposed with an increasing cofinal function. If something like this still goes through, then the construction must be quite strange. I am quite curious about the details of this, but at least for this problem the suggested answer in the comment also works if you just use urysohn w/o subnets. \u2013\u00a0 Jeff Oct 3 '12 at 15:13\nWell, if you have a net $(u_i)$ which does not converge to a value $x$. Then by (the negation of the) definition there exist a neighborhood $V$ of $u$ such that for every $i \\in I$ there exist $j \\in J$ such that $u_j$ is not in $V$. Hence the set of $i$ such that $u_i$ is not in $V$ is cofininal in $I$ and it gives us a sub net (the increasing function you're talking about is just the inclusion) of $u_i$ such that no \"sub-sub-net\" converge to $x$. which leads to a contradiction if the space is compact and if every converging subnet of $(u_i)$ converge to $u$. \u2013\u00a0 Simon Henry Oct 4 '12 at 8:24\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/56315/approximate-analytic-solution-of-schroedinger-equation-with-arbitrary-power-pote?sort=votes\nText:\nTell me more \u00d7\n\nI'm solving the following Schroedinger equation in the domain $r>0$\n\n$\\psi''(r) + \\left(E-\\frac{a}{r^b}\\right)\\psi(r)=0 $,\n\nwhere $0 < b < 2$ and $a, E$ are positive constants. Primarily I'm interested in the asymptotical power behavior of the solution as $r\\to 0$. To be complete in the description of the problem, I fix my boundary conditions at $r\\to +\\infty$ as a plane wave ansatz.\n\nI did a lot of DSolve with Mathematica and found out that $\\psi(r)\\to const$ as $r\\to 0$. It gave me a hint for the power series solution, that one of the terms in the expansion\n\n$\\psi(r) = \\sum\\limits_i a_i r^{\\alpha_i}$\n\nfor some (noninteger) $\\alpha_i>0$ should cancel with $a/r^b$. However, even with this assumption there are a bunch of terms which do not cancel. Power expansion does not seem to work in this case as well as the WKB approximation (double checked numerically). What are the other known methods to find an approximate asymptotic behavior in this case? A good reference would be great too!\n\nshare|improve this question\nProbably a stupid and unhelpful comment, but have you tried letting $r=1/s$ with $s \\to \\infty$? \u2013\u00a0 Zen Harper Feb 23 '11 at 8:01\nWell, it's just changing $r^\\alpha \\to s^{-\\alpha}$, it does not affect power counting... \u2013\u00a0 Peter Feb 23 '11 at 18:44\nI am not an expert on differential equations, so ignore my comments if they sound stupid! Letting $s=1/r$ pushes the singularity out to infinity, but I'm not sure it's of much use. But also, if you let $\\psi = \\exp f$ then you change the second order linear equation into a first order nonlinear one. Maybe this is not simpler, but at least it's different! \u2013\u00a0 Zen Harper Feb 25 '11 at 1:58\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nAs $r$ approaches zero, the coefficient of $\\psi$ becomes dominated by the contribution of $-a/r^b$. This means that in the vicinity of zero your solution is dominated by solution of the following equation $$ \\psi''-\\frac{a}{r^b}\\psi=0. $$ This can be demonstrated more rigorously (and, also, refined to the higher accuracy) by scaling into the vicinity of $r=0$. This equation possesses an explicit solution in terms of the modified Bessel functions: $$ \\psi=C_1\\sqrt{r}K_{\\frac{1}{2-b}}\\left(\\frac{2\\sqrt{a}}{b-2}r^{1-b/2}\\right)+C_2\\sqrt{r}I_{\\frac{1}{2-b}}\\left(\\frac{2\\sqrt{a}}{b-2}r^{1-b/2}\\right). $$ The latest edition of NIST Handbook tells us that for $z\\to 0$ $$ I_{\\nu}(z)\\sim (\\frac{1}{2}z)^{\\nu}/\\Gamma(\\nu+1) \\quad\\mbox{and}\\quad K_{\\nu}(z)\\sim \\frac{1}{2}\\Gamma(\\nu)(\\frac{1}{2}z)^{-\\nu} $$ so the actual constant at $r\\to0$ depends only on $C_1$, unless $C_1$ vanishes. It seems pretty clear that there are no singularities here; typically you should expect that $$ \\psi\\sim \\frac{C_1}{\\Gamma(\\frac{3-b}{2-b})}\\left(\\frac{\\sqrt{a}}{b-2}\\right)^{\\frac{1}{2-b}} \\quad\\mbox{for}\\quad r\\to 0. $$ Specific values of $C_1$ and $C_2$ are less trivial to obtain, but they can be found by matching this limiting solution to another solution that is valid further away from $r=0$.\n\nThe method of matched asymptotic expansions is often used to solve this type of problems asymptotically, see e.g. Kevorkian & Cole (1996) \"Multiple Scale and Singular Perturbation Methods\", Springer. In this method you would need to construct two solutions: \"inner\" solution, valid as $r\\to 0$, (it is the solution derived above) and \"outer\" solution, valid as $r\\to\\infty$ (which you took to be a plane wave). Some ingenuity may be needed to ensure that the ranges of validity of these two solutions overlap, so that they can actually be matched.\n\nshare|improve this answer\nThanks! I was just working with Mathematica, apparently it didn't know about that solution. So yeah, it's a good point to check with thextbooks from time to time. \u2013\u00a0 Peter Mar 2 '11 at 19:08\nI knew this equation from Section 8.4 of Gradshteyn and Ryzhik's \"Table of Integrals, Series and Products\" (this is where they collected various properties of Bessel functions). Maple 7 was also albe to integrate it. However, more generally, you should treat yourself to a copy of Polyanin and Zaitsev's \"Handbook of Exact Solutions for Ordinary Differential Equations\" which, I suspect, still beats any current computer algebra system hands down. \u2013\u00a0 Aleksey Pichugin Mar 2 '11 at 19:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58160.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nGreatest Common Factor (GCF)\n\nDate: 04/13/99 at 10:38:25\nFrom: Eugene\nSubject: Mathematics 6th grade\n\nHere's the question: The GCF of my numerator and denominator is 5. The \nfraction is equivalent to 4/6. \n\nI tried listing all the multiples of 5 and none is divisible by 6 \nexcept 30. But if I divide this by 6 it will be 5 and 5 x 4 is 20. But \n20/30's GCF is not 5, it's 10. HELP!\n\nDate: 04/13/99 at 12:48:27\nFrom: Doctor Peterson\nSubject: Re: Mathematics 6th grade\n\nHi, Eugene.\n\nYes, this is a little tricky; I fell into almost the same trap you \ndid. You're thinking well so far, but now you have to back up and ask \nwhy it didn't work. To let you practice avoiding the trap, I'll work a \nslightly different problem: the GCF will be 7 rather than 5, and the \nfraction will be equivalent to 3/6 rather than 4/6.\n\nWhat you are doing is looking for some number N by which you can \nmultiply the numerator and denominator, so that\n\n    3xN    3\n    --- = ---\n    6xN    6\n\nand the GCD of 3xN and 6xN is 7. It makes sense to try N = 7, as you \ndid with 5; but the GCD of 21 and 42 is 21, not 7. What happened?\n\nLet's factor the numerator and denominator of our new fraction:\n\n    3xN    3xN\n    --- = -----\n    6xN   2x3xN\n\nDo you see that the GCD will not be N, but 3xN, because 3 and 6 \nalready have a common factor, 3? In order to make the GCD be 7, then, \nN must be 7/3. Then\n\n    3xN   7\n    --- = --\n    6xN   14\n\nwhich is equivalent to 3/6, and the GCD of 7 and 14 is 7.\n\nWere you surprised that N was not a whole number? You can multiply the \nnumerator and denominator of a fraction by any fraction and it will \nstill be equivalent; but the result will be two whole numbers only if, \nas in this case, there was a common factor (3).\n\nSo the reason our problem was tricky is that 3/6 is not in lowest \nterms, so equivalent fractions do not have to have whole-number \nmultiples of the numerator and denominator. We can get to the answer \nvery easily by first writing 3/6 in lowest terms as 1/2, then \nmultiplying numerator and denominator by 7.\n\nNow see what you can do with your problem. There are several ways to \nsolve it, once you see what's wrong.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Fractions\nMiddle School Fractions\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/15907/position-function-not-always-retuning-an-answer-even-with-no-apparent-problems?answertab=oldest\nText:\nTell me more \u00d7\n\nI'm having some problems with Position.\n\nSometimes it will give an empty list instead of the actual position of the element I am looking for when that element is specified through some other code but will return the correct position when the element is specified directly as a number as in the minimum working example below.\n\ndata = {{0.1, 0.0001683}, {0.2, 0.00035754}, {0.3, 0.00056711}, {0.4, \n   0.00078986}, {0.5, 0.0010333}, {0.6, 0.0010333}, {0.7, \n   0.0015758}, {0.8, 0.0018738}, {0.9, 0.0022054}, {1., \n   0.0025706}, {1.1, 0.0029788}, {1.2, 0.0034366}, {1.3, \n   0.0039831}, {1.4, 0.0046433}, {1.5, 0.0055203}, {1.6, \n   0.0068061}, {1.7, 0.010939}, {1.8, 0.031246}, {1.9, 0.054948}, {2.,\n    0.076556}, {2.1, 0.098521}, {2.2, 0.12551}, {2.3, 0.1585}, {2.4, \n   0.1921}, {2.5, 0.22544}, {2.6, 0.25798}, {2.7, 0.28992}, {2.8, \n   0.32051}, {2.9, 0.35095}, {3., 0.38104}}\n\ninterpol = Interpolation[data];\n\nq = FindRoot[interpol[x] == 0.159, {x, 2.9}][[1, 2]]\n\nxlow = Floor[q, 0.1]\n\nPosition[data[[All, 1]], xlow]\n\nPosition[data[[All, 1]], 2.3]\n\nWhen running v8 on xP this code gives {} for the first output and {{23}} for the second.\n\nThis type of error is referenced in the Possible Issues section of the documentation for Position in v8 and v9 but no advice is given.\n\nIn[1] := Position[Range[-1, 1, 0.05], 0.1]\nOut[1] = {}\n\nI've tried putting N everywhere I can to solve it as I thought it could just be a precision or representation issue ( i.e. 2.3 vs 23/10 ) but with no success. Does anyone have nifty work around or solution to this that I am missing please?\n\nshare|improve this question\nWould Position[data[[All, 1]], Nearest[data[[All, 1]], xlow][[1]]] be acceptable ? \u2013\u00a0 b.gatessucks Dec 7 '12 at 10:25\nIt works so it most certainly would be acceptable! Thanks for the fast reply. \u2013\u00a0 fizzics Dec 7 '12 at 10:40\nSince I believe the correct answer is to use Chop (see below), it's also worth pointing to this and this. \u2013\u00a0 Jens Dec 8 '12 at 18:26\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nPosition is looking for an exact match (pseudo-SameQ), rather than a numeric one.\nYou will get the result you want with:\n\nPosition[data[[All, 1]], _?(# == xlow &)]\n\n\nPosition[data[[All, 1]], x_ /; x == xlow]\n\nGenerally you should use Equal (short form ==) any time you are trying to mach Real numbers, to allow for small rounding errors.\n\nUsing the pattern 0 | 0. is not sufficient; See this for examples.\n\nFor an excellent treatment of the problems of matching inexact numbers see:\n\nInstability in DeleteDuplicates and Tally\n\nshare|improve this answer\nThanks for the fast reply. Both of those do the job perfectly but I'm a bit confused by the structure you use in the first one. Wouldn't the _? return a True value instead of a numeric? The second structure I don't fully understand either as I don't see how Position knows to loop over x and compared each term. There is obviously more functionality built in than I appreciate \u2013\u00a0 fizzics Dec 7 '12 at 10:37\n@fizzics Both _?(# == xlow &) and x_ /; x == xlow are patterns, which is what Position needs as a second argument. _?testfunction is a pattern for any single expression for which testfunction yields True when applied. x_ /; expr is a pattern for any single expression, which we locally name x, for which expr evaluates to True; if x appears in expr the local definition is used. Read the documentation for Pattern, PatternTest, and Condition, then see this question. Return with any further questions. \u2013\u00a0 Mr.Wizard Dec 7 '12 at 11:27\nadd comment\n\nOne alternative approach that is very powerful when dealing with approximate real numbers hasn't been mentioned yet: use Chop or Threshold.\n\nThese two functions are intended for just the type of situations you describe, so I would always try them first:\n\nIn your example, this simple command works:\n\nPosition[Chop[data[[All, 1]] - xlow], 0]\n\n\nInstead of finding xlow, I reformulated the problem so that you find 0 in the list of differences with xlow.\n\nshare|improve this answer\nExcellent recommendation. Numeric methods are almost always faster. \u2013\u00a0 Mr.Wizard Dec 8 '12 at 22:22\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/90927/shortest-absolute-value-of-path-in-graph?sort=oldest\nText:\nTell me more \u00d7\n\nSuppose we have a weighted, acyclic digraph, with positive and negative edge weights.\n\nIs there an algorithm that determines whether there is a path of weight zero between vertices A and B? The Bellman-Form algorithm finds the path of smallest weight - is there another algorithm that determines the path of smallest absolute value weight?\n\nThanks, Charles\n\nshare|improve this question\nWhat weights are allowable? Integers between -16 and 16? Arbitrary rational or real numbers? Something in between? (If there is a minimum gap between path weights, it might make the problem easier.) \u2013\u00a0 Charles Staats Mar 11 '12 at 20:18\nThe weights are integers in the interval [-c,c] for some integer constant c. \u2013\u00a0 Charles Bailey Mar 11 '12 at 20:23\nIf it's a finite graph, then of course there's an algorithm, exhaustive search. Perhaps your question is whether there is a more efficient algorithm? \u2013\u00a0 Gerry Myerson Mar 11 '12 at 23:03\nYes, it's a finite graph, so exhaustive search would work. I'm looking for something more efficient. Thanks, Charles \u2013\u00a0 Charles Bailey Mar 12 '12 at 2:55\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nIt is NP-complete if $c$ is not specified. For a set of numbers $m_1,\\ldots,m_t$ make a digraph with vertices $v_0,v_1,\\ldots,v_t$. From $v_{i+1}$ to $v_i$ put two edges, of length $m_i$ and $-m_i$, for each $i$. A path of zero length from $v_0$ to $v_t$ corresponds to a partition of $m_1,\\ldots,m_t$ into two sets of equal size, which is a well known NP-complete problem (called PARTITION).\n\nshare|improve this answer\nThat still leaves the question of whether any practical algorithms exist, at least to find \"small\" absolute values. There is the obvious convex relaxation, but it is not clear it works at all... \u2013\u00a0 Igor Rivin Mar 12 '12 at 4:35\nfor weights given in unary, one might suspect that there will be a dynamic programming algorithm... \u2013\u00a0 Dima Pasechnik Mar 13 '12 at 5:06\nIf the weights are integers of magnitude $O(c)$, then there is an $O(cnm)$ dynamic programming algorithm, where $m$ is the number of edges. For each vertex in topological order, determine which path lengths occur from the starting vertex to that vertex. It would be nice to know if faster is possible. \u2013\u00a0 Brendan McKay Mar 13 '12 at 6:58\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/113879/does-strict-order-preservation-of-powerset-curtail-the-candidates-for-violation-o\nText:\nTake the 2-minute tour \u00d7\n\nThus, let $\\mathrm{OPP}$ be the axiom that $|A|\\lt|B| \\Rightarrow |2^A|\\lt|2^B|$ for any sets $A$ and $B$; and, for any ordinal $\\alpha$, let $\\mathrm{CH}_\\alpha$ be the hypothesis that $\\aleph_\\alpha=\\frak c$ (so that $\\mathrm{CH}_1=\\mathrm{CH}$) . Define $S$ to be the set of those ordinals $\\alpha\\in\\frak c$ such that $\\mathrm{CH}_\\alpha$ does not provably (within $\\mathrm{ZFC}$) violate $\\mathrm{ZFC}$ (for example, it is known that $\\omega\\backslash${$0$}$\\subseteq S$ and $\\omega \\notin S$); and let $S'$ be the set of those $\\alpha\\in\\frak c$ such that $\\mathrm{CH}_\\alpha$ does not provably (within $\\mathrm{ZFC}$) violate $\\mathrm{ZFC}$ $\\&$ $\\mathrm{OPP}$. Clearly $S'\\subseteq S$. But is $S'= S$ ? Or are any elements of $S$ known to be not in $S'$ ?\n\nMy guess is that $\\mathrm{OPP}$ can't restrict the possibilities for violations of $\\mathrm{CH}$ because the sets it talks about in the consequent---especially $2^B$--- are too big to be relevant; but I'm not sure of my footing here.\n\nshare|improve this question\nRelated: mathoverflow.net/questions/17152/\u2026 \u2013\u00a0 Asaf Karagila Nov 19 '12 at 23:50\nI am not sure how to define $S$ formally while still capturing what you are trying to ask. Do you restrict to definable ordinals? Then in what theory does your definition take place? (I am not nitpicking, this is also an issue when trying to formalize the way that one usually describes Easton's result, for example.) \u2013\u00a0 Andres Caicedo Nov 20 '12 at 3:07\nI was wondering the same thing as Andres. I think there is a \"semantic\" interpretation where the reference point is some fixed ground model $V$. That's fun to think about too... \u2013\u00a0 Fran\u00e7ois G. Dorais Nov 20 '12 at 3:23\n@Andres: I think that $S$ is well defined, albeit not within $\\mathrm{ZFC}$, as a subset of $\\frak c$ in the following sense. From $\\frak c$ eliminate any $\\alpha$ for which there is a proof in $\\mathrm{ZFC}$ that $\\frak c$ cannot be $\\aleph_\\alpha$. What remains is $S$. This seems to me to be as definite a mathematical object as, say, the set of nonrecursive real numbers. \u2013\u00a0 John Bentin Nov 20 '12 at 12:51\nJohn, the objection is that it doesn't make sense to prove a statement with a parameter in it, since that parameter is not a syntactic object and not part of the formal language and proof system. \u2013\u00a0 Joel David Hamkins Nov 20 '12 at 15:02\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nFirst, let me remark that the particular way that you've posed the question has several problematic issues of formalization. One issue, noted by Fran\u00e7ois, Andres and Andreas, is that it doesn't make sense to speak about proving an assertion with an ordinal parameter (one would instead want to speak of definitions of particular ordinals). Another issue is that for all we know, we may be living in a universe with ZFC + $\\neg\\text{Con}(\\text{ZFC})$, and in this universe everything is provable, so even if we are able to resolve the first issue nevertheless the sets $S$ and $S'$ will be empty, since everything is provable.\n\nSo let me propose a more semantic, alternative version of the question, which to my of thinking gets at the issue in which I believe you are interested.\n\nQuestion. If $\\alpha$ is an ordinal and the continuum $2^{\\aleph_0}$ can be $\\aleph_\\alpha$ in a forcing extension of the universe, then can the continuum be $\\aleph_\\alpha$ in a forcing extension of the universe in which also the OPP holds?\n\nThe answer is yes, and so in this sense the OPP imposes no additional constraints on the value of the continuum. In this question and in the theorem below, I am speaking about possibly proper class forcing, and this is required, since if the OPP fails unboundedly often, it will require proper class forcing to force OPP again.\n\nTheorem. If the universe $V$ satisifes ZFC, then for any ordinal $\\alpha$, the following are equivalent:\n\n  1. There is a forcing extension in which $2^\\omega=\\aleph_\\alpha$.\n  2. There is a forcing extension in which $2^\\omega=\\aleph_\\alpha$ and the OPP holds.\n  3. Either $\\alpha$ is a successor ordinal or $\\alpha$ has uncountable cofinality.\n\nProof. Clearly 2 implies 1, and 1 implies 3. Suppose 3 holds, and I argue for 2. Fix any ordinal $\\alpha$ as in $3$. First, we may simply force the GCH by the canonical forcing of the GCH. This forcing (which may be a proper class), is countably closed and hence preserves the property of having uncountable cofinality. So $3$ still holds about $\\alpha$ in the extension with GCH. We may now simply apply Easton's theorem, using an Easton function $E$ that takes $\\aleph_0$ to the current $\\aleph_\\alpha$, and more generally which takes $\\aleph_\\beta$ to $\\aleph_{\\alpha+\\beta+1}$. (But any strictly increasing Easton function will do, and there are many variations.) Note that $\\alpha+\\beta=\\beta$ once $\\alpha\\cdot\\omega\\leq\\beta$, and so this pattern is eventually the GCH pattern. By Easton's theorem, there is a further forcing extension in which $2^{\\aleph_0}=\\aleph_\\alpha$ and the continuum function is given by $E$, which is strictly increasing, so the OPP holds. QED\n\nIn particular, for any ordinal $\\alpha$ that you care to define, then you can provably force the continuum to become $\\aleph_\\alpha$ if and only if you can do so while also ensuring the OPP.\n\nNotice that in the proof of the theorem, the value of $\\aleph_\\alpha$ may have changed, during the forcing of the GCH, since this will collapse cardinals if the GCH did not already hold. So there is another version of the question, which is about cardinals, rather than about ordinals. If we start with the GCH, then a similar conclusion can be made.\n\nTheorem. If $V$ is a model of ZFC+GCH, then for any cardinal $\\delta$ the following are equivalent:\n\n  1. There is a forcing extension $V[G]$ in which the continuum is $\\delta$.\n  2. There is a forcing extension $V[G]$ in which the continuum is $\\delta$ and the OPP holds.\n  3. The cardinal $\\delta$ has uncountable cofinality.\n\nThe proof is essentially the same as above. The nontrivial part is 3 implies 2, which can be achieved via Easton's theorem by using a strictly increasing Easton function $E$ with the property that $E(\\aleph_0)=\\aleph_\\alpha$. There are many choices of such $E$, such as $E(\\aleph_\\beta)=\\aleph_{\\alpha+\\beta+1}$, as above. Any such $E$ will ensure the right value for $2^{\\aleph_0}$ and, because it is strictly increasing, will also achieve the OPP. In this case, since we started with the GCH, one requires only set-sized forcing.\n\nBy the way, there seems to be alternative terminology to refer to what you call the OPP. For example, in my paper, \"Is the dream solution of the continuum hypothesis attainable?\", I refer to the power set size axiom, denoted, PSA, and this is the same as what you call OPP. This axiom also appears in the MO question on reasonable-sounding statements that are independent of ZFC.\n\nshare|improve this answer\nJoel, if $\\beta>\\alpha$ then $\\alpha+\\beta=\\beta$. Your given $E$ does not satisfy the requirements for Easton forcing. You should change that to include the case where $\\alpha+\\beta=\\beta$, and then just take $\\beta+1$. \u2013\u00a0 Asaf Karagila Nov 20 '12 at 5:42\nI got stuck on the last paragraph... maybe because I'm just too tired today. What if GCH fails badly in $V$? Can we force GCH? Can we force OPP? I think so but, as always, the singular case is bugging me... \u2013\u00a0 Fran\u00e7ois G. Dorais Nov 20 '12 at 6:58\n@Francois, I thought that you can take some sort of an Easton product over collapses and force GCH to hold (for regular cardinals, singulars get that for free). \u2013\u00a0 Asaf Karagila Nov 20 '12 at 8:47\nAsaf, it isn't true that $\\beta\\gt\\alpha\\implies\\alpha+\\beta=\\beta$, since $\\omega+omega+1\\neq\\omega+1$. But you are right, I should be saying $\\alpha+\\beta+1$ here. \u2013\u00a0 Joel David Hamkins Nov 20 '12 at 11:05\nFran\u00e7ois, there is the canonical forcing of the GCH: at stage $\\gamma$, if $\\gamma$ is a cardinal, force GCH at $\\gamma$, and continue with Easton support. This is progressively closed, and so preserves ZFC, and forces GCH. \u2013\u00a0 Joel David Hamkins Nov 20 '12 at 11:06\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59209/hopfian-property\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a group which is Hopfian and given a short exact sequence $1\\to F \\to H \\to G \\to 1$ with $F$ a finite normal subgroup of $H$. Is $H$ Hopfian?\n\nshare|improve this question\nI suspect you will need stronger assumptions on $G$, for example that any quotient of $G$ by one of its finite normal subgroups is Hopfian. \u2013\u00a0 ndkrempel Mar 22 '11 at 19:57\n@ ndkrempel: why the math symbols are not readable here? did you mean the group G or H on which i would need stronger assumptions? sorry for disturbing \u2013\u00a0 Poove Mar 22 '11 at 21:03\n@Poove: Must be a problem at your end. I meant conditions on G. Another possible condition would be to require G to be torsion-free, I think that's enough for the result to hold... It would be helpful if you gave more details about your particular G, if possible. \u2013\u00a0 ndkrempel Mar 22 '11 at 23:07\n@ ndkrempel: G has no normal subgroups isomorphic to a free abelian group of finite rank. (dont want to assume G is torsion free. \u2013\u00a0 Poove Mar 23 '11 at 10:07\n\n2 Answers 2\n\nAn example exists in this paper. In fact they also construct a Hopfian group $H$ with finite (cyclic) normal subgroup $F$ and $H/F$ non-Hopfian.\n\nshare|improve this answer\n@Mark, could you tell on what page the group is constructed? \u2013\u00a0 Igor Belegradek Mar 28 '11 at 19:06\nTake the Abels' group $A_n$ (pages 19,20). Then $A_n/Z$ is not Hopfian while there is a central cyclic subgroup there F such that $(A_n/Z)/F$ is Hopfian. \u2013\u00a0 Mark Sapir Mar 28 '11 at 21:20\nIn fact, as I was told by Yves de Cornulier, the group is not a quotient of Abels' group $A_n$ by its center but the quotient of the analog $B_n$ of group $A_n$ over $\\mathbb{F}_p[t,t^{-1}]$ over a central copy of $\\mathbb{F}_p[t]$ (see 5.10 in the paper). Then the factor-group is not Hopfian, its factor by the (finite) subgroup generated by $t^{-2}$ is Hopfian. If one then kills $t^{-1}$ as well, one get a non-Hopfian group again. I hope he himself will explain here the Hopfian property of these groups. \u2013\u00a0 Mark Sapir Mar 29 '11 at 4:05\nThat is a very nice example. But how does one show that killing $t^{-2}$ gives a Hopfian group? I doubt that this quotient is residually finite. \u2013\u00a0 Andreas Thom Mar 30 '11 at 14:24\n\nEdit: this post refers to a group constructed here (see 5.10), which is Abels' group over the ring $\\mathbf{F}_p[t,1/t]$, and which probably provides a negative answer to the question. Thus the group $G$ below refers to the group of matrices\n\n$$\\left(\\begin{array}{rrrr} 1 & u_{12} & u_{13} & u_{14}\\newline 0 & d_{22} & u_{23} & u_{24}\\newline 0 & 0 & d_{33} & u_{34}\\newline 0 & 0 & 0 & 1\\newline \\end{array}\\right) $$ where $u_{ij}\\in\\mathbf{F}_p[t,1/t]$,\n\nand $d_{ii}\\in\\mathbf{F}_p[t,1/t]^\\times=\\langle t\\rangle\\mathbf{F}_p^\\times$.\n\nActually I restrict to $d_{ii}\\in\\langle t\\rangle$ but it's not important. [end edit]\n\nI haven't checked but here are some guidelines to show the group is Hopfian.\n\nWrite the original group (given by $4\\times 4$ triangular matrices) as $G=D\\ltimes U$ with $D=\\mathbf{Z}^2$ and $U$ its unipotent part. Set $U^2=[U,U]$ and $U^3=[U,U^2]$, which is central and naturally isomorphic to $F_p[t,1/t]$. Our group is $H=G/M$, where $M\\subset U^3$ is generated by $F_p[t]$ and $t^{-2}$. Let $f$ be a surjective endomorphism of $H$.\n\n1) check that the center of $G$ is precisely $U^3$. It follows that $f$ induces a surjective endomorphism of $G/U^3$. Since this group is linear, it is Hopfian so this is an automorphism of $G/U^3$.\n\n2) Describe the group of automorphisms of $G/U^2 = \\mathbf{Z}^2\\ltimes F_p[t,1/t]^3$. (It should be reasonably easy to describe).\n\n3) Deduce a description of the group of automorphisms of $G/U^3$, or at least describe how these automorphisms act on $U^2/U^3$, showing that modulo something, the coefficient $12$ is multiplied by a monomial $w\\cdot t^a$ ($w\\in F_p*$) and the coefficient $24$ is multiplied by $vt^b$. So, taking a commutator (that should kill the \"modulo something\"), we obtain that in the action of $f$ on $H$, the coefficient $14$ should be multiplied by a monomial. This multiplication should stabilize $M$ so this is multiplication by a scalar in $F_p*$, which implies that f is actually an automorphism.\n\nshare|improve this answer\nI just edited tex by inserting dollar signs etc. \u2013\u00a0 Igor Belegradek Apr 2 '11 at 23:11\nSorry if I missed something, but doesn't conjugation by $diag(t^2,1,1,1)$ define an automorphism of $G$ that sends $M$ strictly inside itself (implying $G/M$ non-Hopfian)? \u2013\u00a0 BS. Jul 22 '12 at 16:58\nOn the other hand, a similar idea might work : take $N=F_p[t^2]$ and $M=<N,t^{-1}$. Then $G/N$ is non-Hopfian, but since no non-trivial translation of $\\mathbb{Z}$ sends $E={-1,0,2,4,...,2k,...}$ (strictly) inside itself, the conjugation counterexample breaks down and your argument might work. \u2013\u00a0 BS. Jul 22 '12 at 17:41\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207787/non-principal-ideal-in-boolean-ring?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nDoes anyone know a simple example of a Boolean ring with a non-principal ideal? Every finitely generated ideal in a Boolean ring is principal, hence such an ideal cannot be finitely generated...\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nDepending on what you know, you might consider this is equivalent to another answer, but since it is not spelled out I'll give it a shot.\n\nTake $R=\\prod_{i\\in I} \\mathbb{F}_2$ where $I$ is infinite and $\\mathbb{F}_2$ is the field of two elements.\n\nThis contains lots of ideals that are not finitely generated (for example,$A =\\bigoplus_{i\\in I} \\mathbb{F}_2$).\n\nThis can be shown elementarily, or else if you see that $R$ is not Noetherian, you can recognize it must have non-finitely generated ideals.\n\nshare|improve this answer\n\nThink small. Any reasonable collection of \"small\" sets in a Boolean algebra of sets will do. For example, let the ring be the powerset of the reals, and the ideal the collection of countable (this includes finite) subsets. Or, more boringly, think of the powerset of the natural numbers, with ideal the finite sets. Or else think small in the sense of measure.\n\nshare|improve this answer\n\nConsider the collection of countable and co-countable subsets of the real numbers. The collection of all finite sets is a non-principal ideal; as it the collection of all countable sets.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?t=165712\nText:\nRegister to reply\n\nH2SO4, dissolution\n\nby moleman1985\nTags: dissolution, h2so4\nShare this thread:\nApr14-07, 03:23 PM\nP: 20\nHello, I have the following problem and am unsure how to solve it, although I believe the heat of dissolution to be -71.76kJ/mol, but I can only see how this would help me if my acid was infinetly dissoluted which is not the case so I need to know how the calculate a temperature rise when this is not the case.\n\nMy acid starts off at 98% wt. total wieght 115.985041 kg, (1158.9 moles H2SO4, and 128.8 moles H2O).\nThe acid ends up at 75% wt. total weight 151.55284 kg, (1158.9 moles H2SO4, and 2103.1 moles H20).\n\nBoth the acid and water initial temps can be taken as 30oC,\n\nSo basically 115.98kg of 98% wt. H2SO4 at 30oC, with 35.5kg water at 30oC\nPhys.Org News Partner Engineering news on\nAugmented reality helps in industrial troubleshooting\nHow wireless technology can dramatically improve ship safety\nApr14-07, 03:52 PM\nP: 20\nthe water is also in vapour phase at the beggining, so will I also have to consider the heat of condensation of the water going from the vapour phase to the liquid phase? thankyou.\nApr16-07, 03:43 AM\nP: 116\nI vote no to the second question, but I'm not sure. It's not like it's steam? If the pressure is 1 atm of course... They are little particles of water at 30 \u00b0C.\n\nAnd, the solution of H2SO4 seems 18 M so, I think you may use the formular of:\n\nWhich you posted yourself.\n\nSo if all H2SO4 dissociates it will give: 83170 kJ of energy to the solution.\n\nFor the warmth capacity I'd say approximately:\n\nH2SO4: 3,5 J/gC . 113000 g = 400 kJ/C\nH2O: 4,18 J/gC . 35,3 kg = 150 kJ/C\n\nSo dQ = (cp1m1 + cp2m2) dT\n\ndT = 152 \u00b0 C\n\nOh boy, there must be something wrong with the calculation??? Hey I'm not a professional... yet.\n\nYour reactor is going to explode... do you have some kind of cooling medium?\n\nThe boiling point of H2SO4 was something at 350\u00b0C so maybe, just maybe your solution won't evaporate at 180 \u00b0C. Otherwise, you're in a big trouble. I don't know how your installation looks like, so that info would be interesting too.\n\nI'm curious myself how you're going to handle this calculation! Please post everything you got.\n\nApr16-07, 05:23 AM\nP: 20\nH2SO4, dissolution\n\nHi can I just say first thanks loads for your reply, I will be using a cooling loop in the system, sorry but I gave you all the information I got, but it going to 150oC sounds correct. So do you recon that I would be able to half or maybe even third the heating due to it not beening infinet dilution woukld you be able to hazard a guess with a vague explanation, if not it doesn't matter too much all I need to do is put in my report that I presume that it is infinet dissolution, its just that I dont want to be using more cooling than I sholud as I have to do a detailed costing on the system.\n\nOne other thing I also found the heat of dissolution to be 800kJ/mol, but that was on, or however it's spelt, so it's probaly not reliable.\n\nThanks loads.\nApr16-07, 05:30 AM\nP: 20\nI'm just looking for a basic temperature rise, the whole system is an absorption tower, a wet gas feed at the bottom, and the acid feed at top, so somehow I'm also going to have to come up with a compromise of the two phases increasing with temperature due to the dissolution and the general heat transfere between the two counter flows as both streams will rise in temperature but flow past the inlet streams as they exit which will be at the original lower temperature, but I'm probaly just going to say and presume there is no heat transfer from counter flows but that both the acid and gas are heated together to the same temperature, ha lazy....!\nApr16-07, 01:32 PM\nP: 20\nhi, would you not also have to take into consideration the heating of the gas via the acid (heat transfer), I have a spread sheet set up which considers this and as the gas flow rate is many time the liquid flow rate, and whole system only reaches 55.65oC, and this is good as the column works at optimum absorption at 55-60oC. This is assuming that the heat is shared equally let me know what you think of this if you think its a bad idea then I scrap it, thanks\nApr16-07, 07:06 PM\nP: 116\nSo you spray HS2O4 above and you have some kind of gas at the bottom? Or is it air with water?\nAs for the 800 kJ/mol, that seems much! Meaning the reactor will even blow more up than I predicted. You should know exactly what you are doing here!!!\n\nThe thing is, I calculated that it's 18 M and the internet site also uses 18 M solution as an example. So the heat of reaction they use there should be correct. Maybe I read something wrong there.\n\nI think -800 kJ/mol is the formation of HSO4- from pure H2SO4 (solid) with H2O and -70 kJ/mol takes in account the solution of H2SO4/H2O.\n\nI'm just a student don't take me so seriously! I make mistakes. :)\n\nRegister to reply\n\nRelated Discussions\nH2SO4 preparation Chemistry 6\nCuO dissolution Materials & Chemical Engineering 0\nH2SO4 + Sugar Reaction? Chemistry 1\nQuestions on HCl and H2SO4 reactions Biology, Chemistry & Other Homework 5\nShape of H2SO4 Chemistry 3"}
{"text": "Retrieved from http://math.stackexchange.com/questions/159493/can-there-be-a-function-thats-even-and-odd-at-the-same-time?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI woke up this morning and had this question in mind. Just curious if such function can exist.\n\nshare|improve this question\nIn case anyone has forgotten what \u201ceven\u201d and \u201codd\u201d functions are, $f$ is even if $f(x) = f(-x)$ and odd if $-f(x) = f(-x)$. See also Wikipedia on even and odd functions. \u2013\u00a0 Rory O'Kane Jun 17 '12 at 18:54\nYou might find it interesting that I often used to ask this as an extra credit question on precalculus tests when even/odd function properties were covered, typically worth an extra 3 points on a 100 point scale (so a score of 103/100 was possible). I'd usually get about 2 to 5 students getting the extra points (out of a total of maybe 25-35 students) in a U.S. college precalculus class, and about half the class getting the extra points in U.S. honors level high school classes I used to teach. \u2013\u00a0 Dave L. Renfro Jun 18 '12 at 15:56\n\n6 Answers 6\n\nup vote 38 down vote accepted\n\nOthers have mentioned that $f(x)=0$ is an example. In fact, we can prove that it is the only example of a function from $\\mathbb{R}\\to \\mathbb{R}$ (i.e a function which takes in real values and outputs real values) that is both odd and even. Suppose $f(x)$ is any function which is both odd and even. Then $f(-x) = -f(x)$ by odd-ness, and $f(-x)=f(x)$ by even-ness. Thus $-f(x) = f(x)$, so $f(x)=0.$\n\nshare|improve this answer\nOf course, one could argue that restrictions of the constant $0$ function to different domains symmetric about the origin are different functions, set-theoretically speaking. \u2013\u00a0 Cameron Buie Jun 17 '12 at 15:30\n@CameronBuie That is true, I will make my answer more precise to indicate this. Thank you. \u2013\u00a0 Ragib Zaman Jun 17 '12 at 15:31\nFunny, I never thought of f(x) = 0 as a possibility. Thanks for the answers everyone! \u2013\u00a0 bodacydo Jun 17 '12 at 21:06\n\nIf $K$ is a field of characteristic 2, every function $K\\to K$ is both even and odd.\n\nshare|improve this answer\ni'm sorry, wouldn't that be \"unequal to 2\"? \u2013\u00a0 akkkk Jun 17 '12 at 15:31\n@Auke: No. I won't spoil the joke by spelling it out, sorry. \u2013\u00a0 Harald Hanche-Olsen Jun 17 '12 at 15:40\nActually, you don't even need a field, any ring of characteristic 2 will do. \u2013\u00a0 Ilmari Karonen Jun 17 '12 at 15:42\n@HaraldHanche-Olsen, oh, I am sorry, I misread your answer, you are completely right :) nice one \u2013\u00a0 akkkk Jun 17 '12 at 15:43\nThis is a wonderful answer! \u2013\u00a0 Edward Hughes Jun 17 '12 at 23:52\n\nYes. The constant function $f(x) = 0$ satisfies both conditions.\n\nEven: $$ f(-x) = 0 = f(x) $$\n\nOdd: $$ f(-x) = 0 = -f(x) $$\n\nFurthermore, it's the only real function that satisfies both conditions:\n\n$$ f(-x) = f(x) = -f(x) \\Rightarrow 2f(x) = 0 \\Rightarrow f(x) = 0 $$\n\nshare|improve this answer\n\nHint $\\rm\\ f\\:$ is even and odd $\\rm\\iff f(x) = f(-x) = -f(x)\\:\\Rightarrow\\: 2\\,f(x) = 0.\\:$ This is true if $\\rm\\:f = 0,\\:$ but may also have other solutions, e.g. $\\rm\\:f = n\\:$ in $\\rm\\:\\mathbb Z/2n =\\:$ integers mod $\\rm 2n,$ where $\\rm\\: -n \\equiv n.$\n\nshare|improve this answer\n+1, but note that your last $\\iff$ applies (in the backwards, i.e. 'if' direction) only to $f(x) = -f(x)$, and not to the part where $f(-x)$ equals both of them. \u2013\u00a0 ShreevatsaR Jun 17 '12 at 18:04\nYes, I meant to write $\\:\\Rightarrow\\: $ but it was lost in editing. Now fixed. Thanks. \u2013\u00a0 Bill Dubuque Jun 17 '12 at 18:19\n\nSuppose $f$ odd an even. Let $x \\in D$ ( D is set definition of $f$) then you have : $ f(x)=f(-x)=-f(x)$. What can you conclude about $f$ ?\n\nshare|improve this answer\n\nAs other people have mentioned already, the real function $f(x)$ which maps every real number to zero (i.e.$f(x) = 0 \\space \\forall x \\in \\mathbb{R}$) is both even and odd because $$f(x) - f(-x) = 0 \\space \\space , f(x)+f(-x) = 0\\space \\forall x \\in \\mathbb{R} .$$ Also it is the only function defined over $\\mathbb{R}$ to possess this property.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/11981/building-a-multi-variable-regression-model\nText:\nTake the 2-minute tour \u00d7\n\nI have a large set of data points which have 18 dimensions to them. I know that these data points must follow a strict polynomial formula with no possible variance. Given that I have enough data (I assure you I have), how do I go about building a regression model to find the general formula of the lowest polynomials for the equation which gives these data points?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nThe input dimension being 18 is a little problematic, so I have a few suggestions. I'm putting the statistical approach first due to your choice of tags and terminology..\n\nLinear regression can be made to fit polynomials by simply explicitly creating all the monomial terms; ie for an input with two dimensions $x= (x_1,x_2)$, for a quadratic you'd instead use $x' = (1,x_1,x_2,x_1x_2,x_1^2,x_2^2)$. Notice that this means, to add all $d$th order terms, you would create $O(18^d)$ dimensions! Notice furthermore that your regression model has equivalently many parameters! Therefore, it may be beneficial to try to simplify the model a little with some regularization, maybe use lasso (l1-regularization). Note that, as specified, the degree of the polynomial is not being minimized. The regularization I mentioned only minimizes the l1 length, and even putting a sparsity constraint on the weights alone (which is simpler than minimizing degree) is nonconvex. To find the degree, you could binary search; ie try degrees $1,2,4,8,\\ldots$ until you get zero error, and then binary search within the last interval to find the exact order.\n\nAnother approach is to directly use polynomial interpolation. Simply grow $d$, building an interpolating polynomial at each iteration, and stopping when the one built on the provided points fits all other points. For univariate data, the Lagrange Polynomial[1] is the way to go. I don't know your case offhand but just noticed wikipedia has a \"polynomial interpolation\" page which should be helpful.\n\nanything you try will be slow due to the dimension, your stipulation that you necessarily find the absolute smallest degree, and the vast number of parameters in any such polynomial.\n\n[1] lagrange interpolation\n\nshare|improve this answer\nadd comment\n\nIf there is no possible variation then this isn't really a regression question. It's straight up linear algebra. You have alot of equations of the form. y= ax_1+b x_2+..+q x_18 + aa x_1^2+ab x_1x_2... (all terms taken 2 at a time),+ (stuff taken 3 at a time)+..\n\nNow either you have an idea of where to end this and need to solve a giant matrix, or you aren't sure where to end this and don't really have enough data. By not enough data I mean that you can fit infintely many polynomials if you allow the degree to be unbounded. Just as you can fit infintely many polynomials to a finite set of points in R^2.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/7183/connection-between-bernoulli-polynomials-and-polygamma-function\nText:\nTake the 2-minute tour \u00d7\n\nThere is an intricate connection between Hurwitz Zeta and the (traditional) polygamma function:\n\n\nIf to use a generalization for Bernoulli numbers, this can be considered a formula, connecting polygamma and Bernoulli polynomials of negative order:\n\n$$\\psi_n(z)=(-1)^{n+1}n!\\frac{B_{-n}(x)}n$$ (1)\n\nAs much as this equality is impressing, it is limited as it only holds for natural n.\n\nAfter a couple of unsuccessful attempts to find a more general formula, I encountered a more natural, \"balanced\" generalization of polygamma function explained in this paper. It turned out that while the old formula still holds for natural n (since the old polygamma and balanced polygamma coincide in integer positive orders), a completely new formula connecting this balanced polygamma with Zeta and Bernoulli numbers can be derived which holds for any z:\n\n$$\\zeta(z,q)=\\frac{\\Gamma (1-z) \\left(2^{-z} \\left(\\psi \\left(z-1,\\frac{q}{2}+\\frac{1}{2}\\right)+\\psi \\left(z-1,\\frac{q}{2}\\right)\\right)-\\psi(z-1,q)\\right)}{\\ln(2)}$$\n\n$$B_z(q) = -\\frac{\\Gamma (z+1) \\left(2^{z-1} \\left(\\psi\\left(-z,\\frac{q}{2}+\\frac{1}{2}\\right)+\\psi\\left(-z,\\frac{q}{2}\\right)\\right)-\\psi(-z,q)\\right)}{\\ln (2)}$$\n\nBoth of them can be expressed completely in terms of balanced polygamma and elementary functions if to notice that $\\Gamma(x)=e^{\\psi(-1,x)+\\frac 12 \\ln(2\\pi)}$, which allows to get rid of the Gamma function.\n\nWhile the target was reached, these expressions still leave a bad impression. I cannot simplify it as no CAS system is capable of operations with the balanced polygamma.\n\nHence I am asking for help on how to simplify the expressions so they could be easier to manage and use. It is also not evident how the letter formulas become the former ones at positive real z.\n\nshare|improve this question\nThis appears to be a duplicate of mathoverflow.net/questions/42696 \u2013\u00a0 Robin Chapman Oct 19 '10 at 13:08\nUsually people ask first here and then promote it to MO if it is sufficiently advanced that it stands a better chance of getting answered there. So I'm not entirely sure why you posted here if you couldn't get answers there. \u2013\u00a0 \uff2a. \uff2d. Oct 19 '10 at 14:14\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55169.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPixels in a Triangle\n\nDate: 08/02/99 at 09:14:15\nFrom: Berkant Barla Cambazoglu\nSubject: Triangle pixel intersection\n\nI basically want to find the number of pixels inside a 2D triangle. \nThe triangle may have nodes with floating point coordinate values, but \nthe points returned as answer must have integer-valued coordinates.\n\nThere are some exact solutions: we may scan convert the triangle, or \nperform an inside-outside test over the triangle using the line \nequations of the edges forming the triangle. However, these methods \nare too slow, and they are unnecessary for this particular problem. \nI don't want the coordinates of the pixels; what I seek is just the \ntotal number of pixels inside the triangle.\n\nAn approximation to this problem would be to calculate the area of the \ntriangle and assume that it is the same with the number of pixels \ninside the triangle. However, in this method some triangles can get \nmuch higher values than the actual value. For example, even a triangle \nhas no pixels inside, it is always assigned a positive value instead \nof 0.\n\nI will be glad if you can offer me a smart solution. Thanks for your \n\nDate: 08/02/99 at 13:03:26\nFrom: Doctor Peterson\nSubject: Re: Triangle pixel intersection\n\nHi, Berkant.\n\nThis sounds like it might be a good place to apply Pick's Theorem, \nwhich you can read about here:\n\n\nThis says that the area of a triangle (or any polygon) whose vertices \nare lattice points (in your situation, this is the same as saying they \nare on pixels - integer coordinates) is I+B/2-1, where I is the \nnumber of lattice points (pixels) inside the polygon, and B is the \nnumber of lattice points on the boundary. You want to find I, so \nyou'll need to find the area and B. Of course, your vertices don't \nnecessarily have integer coordinates, but it will probably work if you \nround to find the corner pixel.\n\nSo what's B? The number of lattice points exactly on the line from \n(x1,y1) to (x2,y2), including one of its endpoints, will be the GCD of \n(x1-x2) and (y1-y2). Add these and you'll have B.\n\nSo my formula for I, given three vertices (x1,y1), (x2,y2), and \n(x3,y3) rounded to integers, would be\n\n   I = A + 1 - [gcd(x1-x2, y1-y2) + gcd(x2-x3, y2-y3)\n       + gcd(x3-x1, y3-y1)]/2\n\nIn case you're not familiar with it, you can get the area (again after \nrounding the coordinates) this way:\n\n  A = [(x1-x2)(y1+y2) + (x2-x3)(y2+y3) + (x3-x1)(y3+y1)]/2\n    = [x1 y2 - x2 y1 + x2 y3 - x3 y2 + x3 y1 - x1 y3]/2\n\nwhich is the same as using a determinant, as explained here:\n\n\nLet's test this with a triangle that will contain no pixels:\n\n    (0,0) (15,15) (15,16)\n\nThe area is\n\n    A = [0*15 - 15*0 + 15*16 - 15*15 + 15*0 - 0*16]/2 = 7.5\n\n    gcd(-15,-15) = 15\n    gcd(0,-1)    =  1\n    gcd(15,16)   =  1\n\n    I = 7.5 + 1 - (15+1+1)/2 = 8.5 - 8.5 = 0\n\nwhich is correct.\n\nI'm a little uncertain about how this will work out in practice, \nbecause if you're working with lines drawn on a computer, the \nalgorithm that draws the lines will count many pixels that are \nactually inside as being part of the edge, in order to be able to draw \nit without gaps. On the other hand, if you're looking for exactly the \npixels within the actual triangle defined by non-integer vertices, \nyou'll gain or lose points when you round the coordinates. Whether \nthis is acceptable depends on the details of your application.\n\nPlease let me know whether or not this helps.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nHigh School Geometry\nHigh School Practical Geometry\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/215999/how-many-0s-are-at-the-end-of-20\nText:\nTake the 2-minute tour \u00d7\n\nI'm not exactly sure how to answer this question, any help would be appreciated. After reading this I'm still not sure.\n\n\nshare|improve this question\nDoes this site answer it and walk through enough details? purplemath.com/modules/factzero.htm, using the number of fives method or Wolfram Alpha: wolframalpha.com/input/?i=number+of+trailing+zeros+in+20%21 \u2013\u00a0 Amzoti Oct 18 '12 at 1:09\nThat's funny, I literally just stumbled across this site. \u2013\u00a0 Unknown Oct 18 '12 at 1:10\nEvidently there is only one! (sorry, couldn't resist) \u2013\u00a0 treble Oct 18 '12 at 1:34\nI got asked this in a programming job interview once, but for $100!$ - I didn't get the job :( \u2013\u00a0 Ergwun Oct 18 '12 at 6:50\nadd comment\n\n3 Answers\n\nup vote 10 down vote accepted\n\nThere is a general formula that can be used. But it is good to get one's hands dirty and compute.\n\nIf $20!$ seems dauntingly large, calculate $10!$. You will note it ends with two zeros. Multiplying $10!$ by all the numbers from $11$ to $20$ except $15$ and $20$ will not add to the zeros. Multiplying by $15$ and $20$ will add one zero each.\n\nRemark: Suppose that we want to find the number of terminal zeros in something seriously large, like $2048!$. It is not hard to see that this number is $N$, where $5^N$ is the largest power of $5$ that divides $2048!$. This is because we need a $5$ and a $2$ for every terminal $0$, and the $5$s are the scarcer resource.\n\nTo find $N$, it is helpful to think in terms of money. Every number $n$ between $1$ and $2048$ has to pay a $1$ dollar tax for every $5$ \"in it.\" So $45$ has to pay $1$ dollar, but $75$ has to pay $2$ dollars, because $75=5^2\\cdot 3$. And a $5$-rich person like $1250$ has to pay $4$ dollars.\n\nLet us gather the tax in stages. First, everybody divisible by $5$ pays a dollar. These are $5$, $10$, $15$ and so on up to $2045$, that is, $5\\cdot 1, 5\\cdot 2,\\dots, 5\\cdot 409$. So there are $409$ of them. It is useful to bring in the \"floor\" or \"greatest integer $\\le x$ \" function, and call the number of dollars gathered in the first stage $\\lfloor 2048/5\\rfloor$.\n\nBut many numbers still owe some tax, namely $25,50,75,\\dots,2025$. Get them to pay $1$ dollar each. These are the multiples of $25$, and there are $\\lfloor 2048/25\\rfloor$ of them.\n\nBut $125$, $250$, and so on still owe money. Get them to pay $1$ dollar each. We will gather $\\lfloor 2048/125\\rfloor$ dollars.\n\nBut $625$, $1250$, and $1875$ still owe money. Gather $1$ dollar from each, and we will get $\\lfloor 2048/625\\rfloor$ dollars.\n\nNow everybody has paid up, and we have gathered a total of $$\\lfloor 2048/5\\rfloor + \\lfloor 2048/25\\rfloor +\\lfloor 2048/125\\rfloor +\\lfloor 2048/625\\rfloor$$ dollars. That's the number of terminal zeros in $2048!$.\n\nshare|improve this answer\nI don't always upvote answers that are in \"competition\" with my own...but when I do, it's because it's a damn good answer! (+1) \u2013\u00a0 Cameron Buie Oct 18 '12 at 3:59\nYours is a good answer, now with an additional upvote. I thought that this might be an opportunity to describe in very concrete terms the process that yields the usual formula. \u2013\u00a0 Andr\u00e9 Nicolas Oct 18 '12 at 4:13\nAgreed. You did it much more explicitly and intuitively than I (though, to be fair, I'd never even realized that there was an explicit formula before, and was operating off the cuff). Upvote appreciated. \u2013\u00a0 Cameron Buie Oct 18 '12 at 4:33\nadd comment\n\nCount up the number of factors of $5$ and the number of factors of $2$ in $20!$. Since we get a zero for every pair of factors $5\\cdot 2$, then the minimum of these will answer your question. More simply, $5$ happens less often as a factor (since it's bigger than $2$), so we need only count up the number of $5$'s. In particular, there's one each in $5,10,15,20$, so there are $4$ zeroes at the end.\n\nIf the problem had asked about $25!$, then there'd be $6$ zeroes--not $5$--because there are two factors of $5$ in $25$. Similar idea for other numbers.\n\nshare|improve this answer\nIt gets harder when you try it with bases other than 10. \u2013\u00a0 marty cohen Oct 18 '12 at 1:44\nThat's true, Marty, though not relevant to the context. \u2013\u00a0 Cameron Buie Oct 18 '12 at 1:52\nadd comment\n\nGeneral formula (for the interested) about the number of zeroes in n! in any base (b). First consider all prime factors of b, then consider the biggest one (p). Then use this formula.\n\n$\\lfloor n/p \\rfloor$ + $\\lfloor n/p^2 \\rfloor$ + $\\lfloor n/p^3 \\rfloor$ + ....\n\nThis and using the fact that, the floor becomes zero after some exponent, you can calculate the number of zeroes in any base.\n\n\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathhelpforum.com/advanced-statistics/134307-deriving-event-probability-discrete-time-interval-probability-time-series.html\nText:\nThe probability that I am smiling at any given point during the day is given by a function f(t) [note this is not a pdf but simply the probability of the event at a given time; thus 0<=f(t)<=1 but int_0^24 f(s) ds does not necessarily equal 1].\nWhat is the probability P that I will smile during a specific time interval[t1,t2] during the day?\nI have noted that:\nint_t1^t2 f(s) ds has units time and is not bounded above by 1;\nbreaking the time interval into smaller timesteps and treating the probability in each of these as independent (and then multipliying) gives arbitary results since it is dependent on the choice of time step;\ntaking the mean or maximum etc. of f(t) in the interval would mean that watching me for one minute or twenty four hours could have the same probability of success;\nobviously if f(t)=1 for any t in[t1,t2] then P=1 while if f(t)=0 for all t in[t1,t2] then P=0."}
{"text": "Retrieved from http://math.stackexchange.com/questions/266171/irreducibility-of-polynomial-if-no-root-capelli\nText:\nTake the 2-minute tour \u00d7\n\nThis question already has an answer here:\n\nLet $F$ be a field of arbitrary characteristic, $a\\in F$, and $p$ a prime number. Show that $$f(X)=X^p-a$$ is irreducible in $F[X]$ if it has no root in $F$.\n\nThis answer to a related question mentions the result is due to Capelli.\n\nI can prove the result if $F$ has characteristic $p$ as follows. Suppose $f$ is reducible: $f(X)=g(X)h(X)$ with $g(X)$ an irreducible factor of degree $m$, $1\\le m<p$. Then if $\\alpha$ is a root of $g$ in some extension field $K$ of $F$, we have $$f(X)=X^p-\\alpha^p=(X-\\alpha)^p$$ so its divisor $g(X)$ must be of the form $(X-\\alpha)^m$. Since the coefficient of $X^{m-1}$ in $g$ is in $F$, we have $m\\alpha\\in F$. So $\\alpha\\in F$ because $m$ is invertible modulo $p$.\n\nHow would you show the result in other characteristics?\n\nshare|improve this question\nadd comment\n\nmarked as duplicate by leo, Daniel Robert-Nicoud, Sujaan Kunalan, Davide Giraudo, Old John Nov 27 '13 at 21:53\n\n\n3 Answers\n\nup vote 3 down vote accepted\n\nA proof of this result can be found on page 297 of Lang's Algebra and goes as follows.\n\nLet $F$ be a field of characteristic $q \\neq p$. If $f(x)$ has no root in $F$, then it must be the case that $a$ is not a $p$ - th power in $F$. Suppose that $f(x)$ is reducible. By passing the larger extension $K = F(\\alpha)$ , we see that $\\alpha$ must have degree $d$ where $d < p$. Then $\\alpha^p = a$ and by applying $N_{K/F}(-)$ gives that $N_{K/F}(\\alpha)^p = a^d$ by multiplicativity of the field norm. Since $(d,p) = 1$ this means that $a$ is a power of $p$ in $F$, a contradiction.\n\nshare|improve this answer\nI'm curious though because I don't see where the hypothesis that the characteristic is not equal to $p$ is used. \u2013\u00a0 fpqc Dec 28 '12 at 1:33\nWhat I think: If the field is of characteristic $p$ then for any $a\\in F$ there is $b\\in F$ s.t $b^p=a$ hence $F(b)=b^p-a=a-a=0$ hence the polynomial is reducible \u2013\u00a0 Belgi Dec 28 '12 at 1:39\n@Belgi The Frobenius automorphism is surjective IIRC iff the field is finite. \u2013\u00a0 fpqc Dec 28 '12 at 1:40\nhmm yes, but we are not given that $F$ is not finite \u2013\u00a0 Belgi Dec 28 '12 at 1:41\n@Belgi Nor are we given that $F$ is finite. The point now is that $F$ is an arbitrary field of arbitrary characteristic. \u2013\u00a0 fpqc Dec 28 '12 at 1:42\nshow 11 more comments\n\nSuppose the characteristic of $F$ is not $p$. Let $\\Omega$ be the algebraic closure of $F$. By the assumption on the characteristic of $F$, $\\Omega$ has a primitive $p$-th root of unity $\\zeta$. Let $\\alpha$ be a root of $x^p - a$ in $\\Omega$. Since $\\alpha$ is not contained in $F$, $\\alpha \\neq 0$. Hence $\\alpha, \\alpha\\zeta, \\cdots, \\alpha\\zeta^{p-1}$ are distinct roots of $x^p - a$. Suppose $x^p - a = g(x)h(x)$, where $g(x)$ and $h(x)$ are monic polynomials in $F[x]$ and $1 \\le$ deg $g(x) \\lt p$. Let $k =$ deg $g(x)$. Let $b$ be the constant term of $g(x)$. Then $b = (-1)^k \\alpha^k \\zeta^m$, where $m$ is an integer. Hence $b^p = (-1)^{kp} a^k$ If $(-1)^{kp} = 1$, then let $c = b$. Suppose $(-1)^{kp} = -1$. If $p$ is odd, then let $c = -b$. If $p = 2$, then let $c = b$. In either case, $c^p = a^k$.\n\nLet $\\Gamma$ be the multiplicative group of $F$. Let $\\Gamma^p = \\{x^p |\\ x \\in \\Gamma\\}$. $\\Gamma^p$ is a subgroup of $\\Gamma$. Let $\\pi$ be the canonical homomorophism $\\Gamma \\rightarrow \\Gamma/\\Gamma^p$. Let $\\beta = \\pi(a)$. Since $x^p - a$ does not have a root in $F$, $\\beta \\neq 1$. On the other hand, $\\beta^p = \\pi(a^p) = 1$. Hence the order of $\\beta$ is $p$. However, since $c^p = a^k$, $\\beta^k = 1$. This is a contradiction. Hence $x^p - a$ is irreducible in $F[x]$.\n\nshare|improve this answer\nadd comment\n\n1) I can give you the details of a paper by Chebotarev translated from russian to german in which appears the Capelli Lemma, yet\n\n2) There's also a paper in italian by Capelli, from 1904, which details I can give you, yet\n\n3) The book \"Algebra I\", by R\u00e9dei, has the same lemma with extensions. Alas, the book was written in hungarian, though it seems to be there's a translation to german with, perhaps, the help of Halm\u00f6s.\n\nGoogling around a little there are several references to that lemma but, as far as I could see, none of the first ones, at least, brings the version you want.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/265650/finding-a-harmonic-function\nText:\nTake the 2-minute tour \u00d7\n\nI need to find a harmonic function in the region ${ {z: |z|<1: Imz>0} }$ whose boundary values are in 1 on the interval $(-1,1)$ and $0$ on the half- circle.\n\nI have no clue, where to start!\n\nI do not think I can proceed like as I used to for finding conformal mapping.\n\nI do not mind getting details since this one of the qual question. Any help much appreciated.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nFirst, find a conformal map from the half-disk to the upper half plane, making sure that the half circle is sent to the positive real half-line, and the diameter of the half-disk is sent to the negative real half-line. (Hint: look at the map $z \\mapsto - \\frac{1}{2}(z + z^{-1})$). Let's call this map $\\Phi$.\n\nSecond, consider the Arg function (or, if you like, the imaginary part of the logarithm with a suitable branch cut making it analytic on the upper half plane). Define your Arg so as to assign the value zero to the positive half line and $\\pi$ to the negative half line.\n\nThird, having done all this, you've concocted a harmonic function $u$ on the upper half plane. Now form $u \\circ \\Phi$, which takes on the correct boundary values.\n\nshare|improve this answer\nWould you please prove more rigorously please. I kind of lost in the second and third part. \u2013\u00a0 Deepak Dec 27 '12 at 0:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/78638/why-does-bringing-n-1-orbital-atoms-together-yield-n-levels\nText:\nTake the 2-minute tour \u00d7\n\nA common example of this is that when bringing N hydrogen atoms together into a ring. Far apart, assume each electron exists in the 1s state. As we bring them together, instead of each electron staying at the original 1s level, or all of them changing by the same amount, the 1s level fans out into N.\n\nFor the case of 2 atoms, I can understand this as bonding or anti-bonding of the atoms. i.e., do the wavefunctions add between the protons, meaning each electron can share in the potential of both protons (bonding) or do the wavefunctions destructively interfere between the protons (anti-bonding).\n\nWith 3 atoms, I can't find 3 levels. Assuming Gaussian shaped wavefunctions, note that the sign of each wavefunction between any two atoms defines the wavefunction on the rest of the ring. Since the signs of the wavefunction are independent, there should be 2^3=8 possibilities since each wavefunction can be + or -. Yet, there are really only 2 energetically distinct arrangements that I see: all have the same sign (two cases) or 2 of 3 have the same sign (2*(3 choose 2)), to account for both sign cases). So I get 3 atoms yield 2 levels.\n\nCan somebody shed light on what I've done incorrectly? Or is 3 too small to work correctly? Is there an argument about the shape of the orbitals I've neglected?\n\nThank you.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nIn your 3-orbital example, you are ignoring the fact that you can get degenerate, linearly independent states. Suppose that you have three orbitals $s_1, s_2,$ and $s_3$. Excluding normalization, you can form the following linearly independent combinations $s_1 + s_2 + s_3$, $s_1 - s_2 - s_3$, and $s_1 - s_2 + s_3$. The last two combinations are degenerate in energy if the orbitals are all identical and you bring them together in a $D_{3h}$ symmetry (i.e. perfect equilateral triangle). However, they are clearly distinct and will have different energy if you do not have this symmetry or interact with anything that breaks the symmetry.\n\nIn general, the answer to your question comes from basic linear algebra. Each orbital can be represented as a linearly independent vector; thus, when you bring together $N$ orbitals you can form only $N$ linearly idependent combinations with them, resulting in $N$ energy levels. Some of these levels may be degenerate because of symmetry.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/69412/is-lebesgue-borel-non-measurability-actually-caused-by-non-uniqueness\nText:\nTake the 2-minute tour \u00d7\n\nIn ZFC, every construction of a Lebesgue or Borel non-measurable set uses the axiom of choice. None of them that I've seen use choice to define a unique set, even though it's entirely possible to do so (e.g. under the AoC, if $\\kappa = |A|$ is the cardinality of set $A$, then $\\kappa$ is unique). So I've been wondering lately whether the strength of the AoC is enough by itself to construct a non-measurable set.\n\nHere's an attempt at a specific question. In the language of set theory (first-order logic with equality extended with the ZFC axioms), is there a formula without parameters that identifies a unique, Lebesgue/Borel non-measurable set?\n\nshare|improve this question\nIt seems to me that this would imply the existence of non-measurable sets in the G\u00f6del's L, where AC is true. \u2013\u00a0 Martin Brandenburg Jul 3 '11 at 20:07\nI think it would, but I don't see anything in the construction of, say, the Vitali sets, that excludes it from L. And Googling around, I see that it's known that there are \"non-measurable $\\Delta^1_2$ sets\" (I assume w.r.t. the Lebesgue $\\sigma$-algebra) in L. \u2013\u00a0 Neil Toronto Jul 3 '11 at 20:19\nHow about Lusin's set of continued fractions such that there exists an infinite increasing sequence $i_1 \\lt i_2 \\lt i_3 \\lt \\cdots$ with $a_{i_1} \\mid a_{i_2}, \\; a_{i_2} \\mid a_{i_3}, \\ldots$ which is Lebesgue (in fact analytic) but not Borel (Fund. Math 10, 1927, p. 77), see also planetmath.org/encyclopedia/\u2026 \u2013\u00a0 Theo Buehler Jul 3 '11 at 20:39\nnon-Borel and non-Lebesgue sets: two completely different questions. \u2013\u00a0 Gerald Edgar Jul 3 '11 at 20:54\n@Gerald: Yes. I am sneakily asking two questions by parameterizing one question on two values. \u2013\u00a0 Neil Toronto Jul 4 '11 at 4:59\nadd comment\n\n5 Answers\n\nup vote 9 down vote accepted\n\nThe answer below has been edited in light of other answers and comments.\n\nThere are all sorts of models of $ZFC$ in which every set is definable without parameters, including nonmeasurable sets; indeed a recent paper of Hamkins, Linetsky, and Reitz is devoted to such \"pointwise definable\" models.\n\nAlso, as pointed out in Theo Buehler's comment to the question, there certainly exist definable subsets of reals that are $ZFC$-provably not Borel.\n\nHowever, the situation is completely different for measurability. The classical work of Solovay [using an inacessible] shows that there is a model of $ZFC$ in which every subset of reals in $OD(\\Bbb{R})$ is Lebesgue measurable. Recall that $X$ is in $OD(\\Bbb{R})$ if $X$ is definable with parameters from $Ord \\cup \\Bbb{R}$.\n\nAs pointed out in Demer's answer, Krivine [without an inaccessible] provided a model of $ZFC$ in which every ordinal definable subset of reals is measurable. Moreover, as shown by Harvey Friedman, here, there is a model of $ZFC$ [which is a generic extension of Solovay's model] in which the following property holds:\n\n(*) Every equivalence class of sets of reals modulo null sets that is in $OD(\\Bbb{R})$ consists of Lebesgue measurable sets.\n\nNote that (*) implies that no non-measurable subset of reals in definable, since if $X$ is any definable subset of reals that is not measurable, then the equivalence class $\\[X\\]$ of $X$ modulo null sets satisfies the following two properties:\n\n(1) $\\[X\\]$ definable,\n\n(2) No member of $\\[X\\]$ is measurable.\n\nSo, to sum-up, the answer to the question for Lebesgue measurability is negative, i.e., there is no formula $\\phi(x)$ in the language of set theory for which $ZFC$ proves \"there is a unique nonmeasurable subset of reals satisfying $\\phi$\".\n\nHowever, if $ZFC$ is strengthened to $ZFC+V=L$ then such a formula does exist, as pointed out in Goldstern's answer.\n\nshare|improve this answer\nAli, thank you for mentioning my paper with Linetsky and Reitz. But it should also be mentioned that Ali himself has done important work on exactly the same topic (as we mention in our paper). See, for example, academic2.american.edu/~enayat/DO.pdf, and perhaps Ali can post other suitable links. \u2013\u00a0 Joel David Hamkins Jul 4 '11 at 1:28\nI am a bit confused. I think that already Solovay's theorem provides a negative answer to the original question (if you read \"identifies a unique set\" as \"defines a set\"). \u2013\u00a0 Goldstern Jul 4 '11 at 12:32\n@Martin: you are right, Solovay's result already does the job, and Friedman's extends it further. I will edit to clarify this point. \u2013\u00a0 Ali Enayat Jul 4 '11 at 16:28\nI am in awe at how deep the answer to this question is. Thanks! \u2013\u00a0 Neil Toronto Jul 5 '11 at 1:04\nAli, I think that the result of Krivine that you mention gets only that all OD sets are Lebesgue measurable. For OD$(\\mathbb R)$ sets you really need a Solovay-style argument, using an inaccessible. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:02\nshow 2 more comments\n\nThe other answers are excellent. But since you have adopted such a strong notion of definability, let me augment them with a positive observation.\n\nThe fact is that any particular set can be made definable without parameters in a forcing extension of the universe $V$. Indeed, there is a single definition $\\varphi(x)$, such that for any set $A$ at all, there is a forcing extension $V[G]$ in which $A$ is the unique set such that $\\varphi(A)$. Furthermore, one can arrange that the forcing extension $V[G]$ agrees with $V$ far beyond the reals, so that it has the same reals, the same sets of reals, the same measurable sets and so on for quite a long way.\n\nIn particular, there is a single definition such that for any non-Lebesgue measurable set $A$ that you favor, there is a forcing extension $V[G]$, an alternative set-theoretic universe, in which $A$ is defined by $\\varphi$ and still non-measurable there.\n\nLet me explain the proof. Fix any set $A$. Let $\\kappa$ be the cardinality of the transitive closure $\\text{TC}(\\{A\\})$. Thus, there is binary relation $E$ on $\\kappa$ for which $\\langle\\kappa,E\\rangle\\cong\\langle\\text{TC}(\\{A\\}),{\\in}\\rangle$. This isomorphism is unique, since it is precisely the Mostowski collapse. Let $E_0\\subset\\kappa$ be the set of ordinals coding pairs in $E$. In the style of Easton's theorem, let $\\mathbb{P}$ be the forcing notion coding the GCH pattern on the regular cardinals above $2^{\\aleph_0}$ to first have a block of length exactly $\\kappa$ on which the GCH holds, and then an violation of GCH and then a sequence of length $\\kappa$ on which the GCH pattern on the regular cardinals matches the elements of $E_0$. In the resulting forcing extension $V[G]$, the cardinal $\\kappa$ and the set $E_0$ and hence $E$ and hence $A$ are definable without parameters. Because the forcing is sufficiently closed, it does not adds new reals or sets of reals and it does not affect measurability. So in the extension, the set $A$ is definable by the formula $\\varphi$ that expresses the decoding of the GCH pattern to $E_0$ and hence $E$ and hence $A$. This coding idea is due originally to K. McAloon.\n\nThe conclusion is that there is a kind of universal definition $\\varphi$, which can serve to define any object at all, if only you apply the definition in the correct set-theoretic universe.\n\nshare|improve this answer\nThat is really cool, but it seems like cheating! \"Indeed, there is a single definition $\\phi(x)$, such that <i>for any set $A$ at all</i>...\" So you can invent a universe in which $\\phi$ uniquely identifies any set that you like. But then, in the meta-set-theory in which you build this universe, that set $A$ may be defined in some non-unique way. If you handed me this set-theoretic universe and such a $\\phi$, I couldn't tell precisely which set $\\phi$ defines. It's more like you would have handed me a <i>collection</i> of universes. Is that right? \u2013\u00a0 Neil Toronto Jul 5 '11 at 1:03\nSort of, yes. The forcing method allows us to build extensions of any given set-theoretic universe, and we can build them in such a way that the definition I mentioned succeeds in defining a given desired set $A$, no matter which $A$ we use (each $A$ gets its own forcing extension). The issue here is that the notion of definable-in-the-language-of-set-theory is extremely powerful and general, perhaps much more general than the kind of definitions that you may have intended. It would make sense to restrict to, say, projective definitions, which are addressed by the other answers. \u2013\u00a0 Joel David Hamkins Jul 5 '11 at 1:24\n@Neil: If Joel \"handed me [a] set-theoretic universe and such a $\\phi$,\" then it would be completely determined what set $\\phi$ defines in that universe. That \"I couldn't tell precisely which set $\\phi$ defines\" is just the result of my inability to fully inspect an infinite universe. (The same inability prevents me from telling exactly what the set of prime numbers is, even though that's the same in all models of set theory whose natural numbers are standard.) What's special about Joel's $\\phi$ is how dramatically its extension varies from universe to universe. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:10\n@Neil: Another comment about \"if you handed me this set-theoretic universe and such a $\\phi$\" --- Joel has, in effect, handed us $\\phi$. His argument specifies a particular formula $\\phi$. Handing you a universe is admittedly harder, because each set-theoretic universe is infinite. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:14\nadd comment\n\nThere is no simple formula that invariably describes a set of reals which is not Lebesgue measurable. The reason is that the existence of certain large cardinals imply that all simply definable subsets of $\\mathbb{R}$ are Lebesgue measurable.\n\nFor example, if there are infinitely many Woodin cardinals with a measurable above, then $L(\\mathbb{R})$ satisfies the Axiom of Determinacy and hence all sets in $L(\\mathbb{R})$ are Lebesgue measurable. Here, $L(\\mathbb{R})$ is the smallest transitive model of ZF that contains all the ordinals and all the reals; this universe contains all the projective sets and much more.\n\nIt seems that the situation is hopeless, but this is not quite true. There has been a lot of recent research which shows that the existence of definable wellorderings of $\\mathbb{R}$ is not incompatible with some of the largest cardinals we know. However, the definition of these wellorderings of $\\mathbb{R}$ is necessarily very complex.\n\nshare|improve this answer\nadd comment\n\nConcerning Borel measurability, it was already pointed out that there is an explicit formula s(x) such that ZFC proves \"The set { x in R: s(x) } is not Borel\". (This is not true for ZF, as was pointed out elsewhere.)\n\nConcerning Lebesgue measurability, ZFC neither proves nor refutes the following:\n\nThere is an OD-definition (or: OD(R)-definition) of a subset of the reals which is non-measurable.\n\nThere is a slight fuzziness here, because there are many non-equivalent notions of definability; OD(R)-definability is perhaps the most prominent and useful.\n\nBut an explicit formula can be given: There is a formula phi(x) in the language of set theory (without parameters) such that ZFC neither proves nor refutes\n\n\"The set { x in R : phi(x) } is non-measurable\".\n\nIn fact, phi(x) can be of a rather simple form ($\\Delta^1_2$, as you remarked above). Here is an abbreviated version of phi: For each real number x, let $x_1$ be the number obtained from x by deleting all even decimal places, $x_2$ by deleting all odd decimal places (do what you want for the countably many reals where this is not well-defined). This defines a measure-preserving Borel map from $\\mathbb R$ to $\\mathbb R\\times \\mathbb R$. Now consider the set M of all reals x for which there is some $\\alpha$ such that $x_1\\in L_\\alpha$, but $x_2\\notin L_\\alpha$. ZFC does neither prove nor refute that M is Lebesgue-measurable.\n\n(I think that the fact that ZFC does not prove that M is measurable is already due to G\u00f6del.)\n\nshare|improve this answer\n@Martin: as an example of a $\\Delta^1_2$ non-measurable set in $ZF+V=L$ isn't it easier to look at the well-ordering $W$ of the reals of order-type $\\aleph_1$ in $L$? Sierpinski had already observed, using Fubini's theorem, that no such $W$ can be measurable. \u2013\u00a0 Ali Enayat Jul 4 '11 at 17:29\nMartin's example is very close to the well-ordering suggested by Ali. The former is the pre-well-ordering obtained from the latter by obliterating the distinction between reals that are constructed simultaneously. Since the resulting equivalence classes are countable, Sierpinski's argument seems adequate for handling the pre-well-ordering as well as the well-ordering. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:24\nThank you, Andreas. I prefer the preorder that I gave over the (possibly more usual) well-order for two reasons: It is as canonical as the hierarchy of $L_\\alpha$'s; well-ordering the countable differences $L_{\\alpha+1} \\setminus L_\\alpha$ is less canonical, as you have to introduce some arbitrary order on the formulas (or G\u00f6del operations). The second reason is related: In an exposition of $L$, this preorder can appear right after the definition of $L$, half a page before the well-order on $L$ is introduced. \u2013\u00a0 Goldstern Jul 6 '11 at 12:53\nThanks for pointing out that it was probably Sierpinski, not G\u00f6del, who showed that a well-order of the reals in type omega1 yields a nonmeasurable set. \u2013\u00a0 Goldstern Jul 6 '11 at 12:54\nadd comment\n\n\n\"In particular Krivine (1969) showed there was a model of ZFC\nin which every ordinal-definable set of reals is measurable.\"\n\nIf all subsets of $\\mathbb{R}$ are ordinal-definable then there is such a formula.\n\nshare|improve this answer\nFor the second part, you only need that every real is ordinal definable since that already gives a definable wellordering of $\\mathbb{R}$. \u2013\u00a0 Fran\u00e7ois G. Dorais Jul 3 '11 at 22:04\n(And thanks for pointing out that Krivine paper!) \u2013\u00a0 Fran\u00e7ois G. Dorais Jul 3 '11 at 22:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209842/simple-way-for-solving-generic-work-and-time-problems\nText:\nTake the 2-minute tour \u00d7\n\nI was looking for a general way of formulating solutions for work and time problems.\n\nFor example,\n\n30 soldiers can dig 10 trenches of size 8*3*3 ft in half a day working 8 hours per day. How many hours will 20 soldiers take to dig 18 trenches of size 6*2*2 ft working 10 hours per day?\n\nNow i know that Work = Efficiency * Time, but i get confused sometimes in selecting which factor in the given problem will contribute directly to the work i.e. increase it and which factors will result in the work being done faster.\n\nI've seen the method in which one uses a table to write all the parameters given in the problem e.g. making columns titled work, number of soldiers, volume of trench, number of days required, number of hours per day, efficiency, wages etc and uses the direct and inverse proportionality to write the equation for solving a given unknown. However i face the same problem i.e. finding out which factors are directly related and which are in an inverse relation.\n\nIs there a simple way of solving these general problems?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\n$30$ soldiers can dig $10$ trenches of size $8\\cdot 3\\cdot 3$ cube fit in $4$ hours.\n\n$1$ soldier can dig $10$ trenches of size $8\\cdot 3\\cdot 3$ cube fit in $4\\cdot 30$ hours.\n\n$1$ soldier can dig $1$ trench of size $8\\cdot 3\\cdot 3$ cube fit in $\\frac{4\\cdot 30}{10}$ hours.\n\n$1$ soldier can dig $1$ trench of size $1\\cdot 1\\cdot 1$ cube fit in $\\frac{4\\cdot 30}{10\\cdot 8\\cdot 3\\cdot 3}$ hours.\n\n$20$ soldiers can dig $18$ trenches of size $6\\cdot 2\\cdot 2$ cube fit in $$\\frac{4\\cdot 30\\cdot 18\\cdot 6\\cdot 2\\cdot 2}{10\\cdot 8\\cdot 3\\cdot 3\\cdot 20}=\\frac{36}{10}=3.6$$ hours which is clearly $<10$ hours.\n\nThe number of trenches and the size of trenches are directly proportional to the time, but the number of soldiers is inversely roportional to the time, the more the number of soldiers, the lesser is the time.\n\nshare|improve this answer\n@BrianM.Scott, thanks for your observation. \u2013\u00a0 lab bhattacharjee Oct 10 '12 at 5:00\nadd comment\n\nIdentify the basic assumptions. In this problem it\u2019s clear that soldiers are considered interchangeable: they all work at the same rate. (Recall that in some problems we have different workers working at different rates and have to keep track of the work rate of each worker. And it\u2019s the work rates that are important, because they\u2019re additive: if $A$ and $B$ have work rates of $r$ and $s$ amount of work per unit of time, then $A$ and $B$ working together have a combined work rate of $r+s$.) It\u2019s also clear the amount of work is being measured in cubic feet dug, and that cubic feet are to be considered interchangeable: they\u2019re all equally hard to dig. Finally, the basic unit of time here is the hour, since we\u2019re dealing with working days of two different lengths in hours.\n\nNow convert the initial data to basic units. We have $30$ soldiers doing the work. They dig $10$ trenches of $8\\cdot3\\cdot3$ cubic feet each, for a total of $720$ cubic feet of earth dug, and they do it in half of an $8$-hour day, or $4$ hours.\n\nAt this point we can calculate their combined work rate: $720$ cubic feet in $4$ hours is $\\frac{720}4=180$ cubic feet per hour. But that\u2019s the combined work rate of $30$ interchangeable soldiers, so each soldier is digging only $\\frac1{30}$-th of that, or $\\frac{180}{30}=6$ cubic feet per hour.\n\nNow let\u2019s take a look at the question (which we should have had in the backs of our minds all along as a guide to what\u2019s relevant and what\u2019s likely to be useful). We have $20$ soldiers available. We want to dig $18$ trenches, each $6\\cdot2\\cdot2$ cubic feet in size, so we want to move $18\\cdot6\\cdot2\\cdot2=432$ cubic feet of earth. Finally, we want to know how long this will take. We know that one soldier digs $6$ cubic feet per hour, so $20$ soldiers dig $20\\cdot6=120$ cubic feet per hour. It will therefore take them $\\frac{432}{120}=3.6$ hours, considerably less than one $10$-hour working day.\n\nshare|improve this answer\nThanks for the explanation. \u2013\u00a0 Karan Oct 10 '12 at 14:59\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/41236/deriving-the-poynting-theorem/41240\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to derive the Poynting theorem. So far, I've only been able to narrow down which equations I think I'll need to do so. These are the equations:\n\nMaxwell's Equations: $$ \\nabla\\times{\\bf E} = - {{\\partial{\\bf B}}\\over{\\partial t}} $$ $$ \\nabla\\times{\\bf H} = {\\bf J} + {{\\partial{\\bf D}}\\over{\\partial t}} $$ Equations relating the flux densities and fields: $$ \\bf D = \\epsilon_0\\bf E + \\bf P $$ $$ \\bf B = \\mu_0\\bf H + \\mu_0\\bf M $$ The vector identity: $$ \\nabla\\cdot (\\bf E\\times\\bf H) = (\\nabla\\times\\bf E)\\cdot \\bf H - (\\nabla\\times\\bf H)\\cdot \\bf E $$ Using these equations, I need to obtain Poynting's theorem, which is given as: $$ \\nabla\\cdot\\bf S = -\\frac{\\partial}{\\partial t}(\\frac{1}{2}\\epsilon_0\\bf E^{2}+\\frac{1}{2}\\mu_0\\bf H^{2})+\\bf E\\cdot\\frac{\\partial\\bf P}{\\partial t}+\\mu_0\\bf H\\cdot\\frac{\\partial\\bf M}{\\partial t} $$ Could someone please help me out?\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 1 down vote accepted\n\nFirst of all, I think you're missing a $-\\textbf{J}.\\textbf{E}$ term in the RHS of your final expression. The rest of the expression looks fine.\n\nI present here some general guidelines on how to approach this derivation. As per the homework guidelines of stackexchange I will not provide all the steps. Others are welcome to correct me on this if I have not completely understood the guidelines. I understand that solving coupled equations using vector calculus can be overwhelming and error-prone. Therefore, I will provide \u201canchor points,\u201d which are nothing but validation steps that you are heading in the right direction. My TA used this technique. If you are getting some horrible terms, which I failed to mention, then it is \u201cprobably\u201d time to step back and recheck your calculations. The reason I say \u201cprobably\u201d is because it is possible that you come up with an alternate derivation. I think the one I worked out is the simplest one. Here it is:\n\nYou can observe that the identity is nothing but:\n\n$$\\nabla.\\textbf{S}=(\\nabla \\times \\textbf{E}).\\textbf{H}-(\\nabla \\times \\textbf{H}).\\textbf{E}$$\n\nThe two terms on the RHS of the above equation should give a hint as to which equations you should manipulate first. Where in the above list can you find $\\nabla \\times \\textbf{E}$ or $\\nabla \\times \\textbf{H}$? You\u2019ll need to bring those equations in that form first, i.e. the form $(\\nabla \\times \\textbf{E}).\\textbf{H}$ and $(\\nabla \\times \\textbf{H}).\\textbf{E}$ and then substitute their modified RHS in the identity. After all these manipulations, say you have obtained a form (*). You can observe that the RHS of (*) has time derivatives. You can now start seeing that (*) is closer to the form that you want. You will now need to use $\\textbf{D}= \\epsilon_0 \\textbf{E}+\\textbf{P}$ and $\\textbf{B}= \\mu_0 (\\textbf{H}+\\textbf{M})$ in (*) in the time derivatives. Yes, you are missing the latter in the above list. After a little bit of simplification, you will need to obtain a contracted form. I will show one (of the two):\n\n$$\\textbf{E}.\\frac{\\partial \\textbf{E}}{\\partial t} = \\frac{\\partial}{\\partial t}\\left(\\frac{1}{2}\\textbf{E}^2\\right)$$\n\nAfter performing a similar manipulation for the magnetic field term, you will obtain the desired expression (with the missing $-\\textbf{J}.\\textbf{E}$).\n\nshare|improve this answer\nadd comment\n\nPoynting's theorem is the statement of the conservation of energy and momentum for a system of charged particles and electromagnetic fields.\n\nYou're on the right track. A definition should help you get the theorem into standard from: $u = \\frac{1}{2}(\\mathbf{E}\\cdot\\mathbf{D} + \\mathbf{B}\\cdot\\mathbf{H})$. (Up to some constants like $\\mu_0$, $\\epsilon_0$ and $4\\pi$.)\n\nThe result you're looking for is: \\begin{align} \\frac{\\partial u}{\\partial t} + \\nabla\\cdot\\mathbf{S} = -\\mathbf{J}\\cdot\\mathbf{E}. \\end{align}\n\nBest of luck.\n\nshare|improve this answer\nadd comment\n\nWell, trying to get in the form of what Mark Wayne put down...you can start with the dfinition of the energy density \"u\" and find the partial wrt time. From there you can use Maxwell's Equations to make some substitutions. Finally in the end you will NEED a not so known/popular vector identity to give you the (ExB) term. Good luck...not a bad derivation at all :)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141999/series-solution-near-ordinary-points-for-second-order-differential-equations?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nGiven $(1+x^2)y''+2xy'-2y = 0$\n\nThe above equations obviously has analytic points everywhere except for $x=1$ and $-1$.\n\nFind two linearly independent solutions $y_1$ and $y_2$ to the differential equation valid near $x_0=0$. To make life a little easier, choose the linearly independent equations:\n\n$y_1$ $:$ $a_0$ = $y(x_0)$ = 1 and $a_1$ = $y'(x_0)$ = 0\n\n$y_2$ $:$ $a_0$ = $y(x_0)$ = 0 and $a_1$ = $y'(x_0)$ = 1\n\nAfter a mess of writing, I came up with the following:\n\n$a_{n+2}$ = $[{-(n-1)(n)a_n - 2a_n(n-1)}]/[{(n+1)(n+2)}]$\n\nI don't know if that monster is right, but that's where I need you help. Can somebody give this a sanity check, and then solve the rest?\n\nshare|improve this question\nSome more detail would be nice. What did you get after substituting your power series ansatz into your differential equation? \u2013\u00a0 \uff2a. \uff2d. May 7 '12 at 1:43\nI checked the series solution myself, your expression of $a_{n+2}$ looks correct to me. \u2013\u00a0 Shuhao Cao May 7 '12 at 2:14\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nIf we set up $y = \\displaystyle \\sum^{\\infty}_{n=1} a_n x^n$ like you did, plugging back to the original equation: $$ (-2a_0+2a_2) + 6a_3 x +\\sum^{\\infty}_{n=2}\\Big((n+2)(n+1)a_{n+2} - (n-1)(n+2)a_n\\Big)x^n = 0 $$ simplify the expression for $a_{n+2}$ when $n\\geq 2$: $$ a_{n+2} = -\\frac{n-1}{n+1} a_n \\qquad (*) $$ for the constant and $x$-term we have: $$ a_0 = a_2, \\text{ and } a_3 = 0 $$\n\n  \u2022 Now if the initial condition is $a_0 = 1, a_1 = 0$, then we have: $$ a_2 = 1, \\text{ and } a_{n+2} = (-1)^{n/2}\\frac{n-1}{n+1}\\cdot \\frac{n-3}{n-1}\\cdots\\frac{1}{3} = \\frac{(-1)^{n/2}}{n+1} $$ and $n$ can be even numbers, let $n = 2k$ we have the solution is: $$ y = 1+x^2 + \\sum^{\\infty}_{k=1}\\frac{(-1)^k x^{2k+2}}{2k+1} = 1 + x\\cdot \\sum^{\\infty}_{k=0}\\frac{(-1)^k x^{2k+1}}{2k+1} = 1+ x\\arctan x $$\n\n  \u2022 Now if the initial condition is $a_0 = 0, a_1 = 1$, $a_2 = a_0 = 0$ implies all even powered $x$ coefficients are zero after $n=2$ because of the relation $(*)$, also by $(*)$ and $a_3 = 0$ we know that all odd powered $x$ coefficients are zero too after $n=3$, therefore the solution is just: $$ y = x $$\n\nTo sum up, the two linearly independent solutions are: $$y = x \\;\\text{ or }\\; 1+ x\\arctan(x)$$\n\nshare|improve this answer\nThanks Jon. The only reason why I got stuck was because the simplification threw me off. It was late and I didn't even think to simplify (in fact I thought it was already simplified). Anyway, thanks again. \u2013\u00a0 Nico Bellic May 7 '12 at 14:16\n@NicoBellic Haha, no problem, btw I love GTA4 too! \u2013\u00a0 Shuhao Cao May 7 '12 at 17:01\nHaha, nice few people recognize the reference. \u2013\u00a0 Nico Bellic May 7 '12 at 18:16\nThe power series method works well provided I can solve the recursion relation. All the textbook examples usualy lead to a recursion that involves two coefficients only ( in this case $a_{n+2}$ and $a_n$). However, in most real world examples this is not the case, ie $a_{n+2}$ is usualy a function of $a_n$ and som other values of $a$ with lower indices. How do I solve the recursion relation then? Or in other words how would I go about solving an equation $(1 + x^2)y^{''} + 2 x y^{'} -2 x y =0$ using the power expansion method? \u2013\u00a0 Przemo Feb 12 at 16:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/18268/consecutive-birthdays-probability\nText:\nTake the 2-minute tour \u00d7\n\nLet $n$ be a number of people. At least two of them may be born on the same day of the year with probability: $$1-\\prod_{i=0}^{n-1} \\frac{365-i}{365}$$\n\nBut what is the probability that at least two of them are born on two consecutive days of the year (considering December 31st and January 1st also consecutive)? It seems a good approximation is: $$1-\\prod_{i=0}^{n-1} \\frac{365-2 \\times i}{365}$$\n\nHowever, simulating pseudo-random integers with Python, the 99%-confidence intervals may be slightly different. So do you have any closed formula?\n\nResults of the simulation with Python. Here are 99%-confidence intervals below:\n\nNumber of people:  1    Lower bound: 0.0        Upper bound: 0.0\nNumber of people:  2    Lower bound: 0.00528    Upper bound: 0.00567\nNumber of people:  3    Lower bound: 0.01591    Upper bound: 0.01657\nNumber of people:  4    Lower bound: 0.03185    Upper bound: 0.03277\nNumber of people:  5    Lower bound: 0.0528     Upper bound: 0.05397\nNumber of people:  6    Lower bound: 0.07819    Upper bound: 0.07959\nNumber of people:  7    Lower bound: 0.10844    Upper bound: 0.11006\nNumber of people:  8    Lower bound: 0.14183    Upper bound: 0.14364\nNumber of people:  9    Lower bound: 0.17887    Upper bound: 0.18086\nNumber of people: 10    Lower bound: 0.21816    Upper bound: 0.2203\nNumber of people: 11    Lower bound: 0.25956    Upper bound: 0.26183\nNumber of people: 12    Lower bound: 0.30306    Upper bound: 0.30544\nNumber of people: 13    Lower bound: 0.34678    Upper bound: 0.34925\nNumber of people: 14    Lower bound: 0.39144    Upper bound: 0.39397\nNumber of people: 15    Lower bound: 0.43633    Upper bound: 0.4389\nNumber of people: 16    Lower bound: 0.48072    Upper bound: 0.48331\nNumber of people: 17    Lower bound: 0.52476    Upper bound: 0.52734\n\nI give here some results with a tweaked approximation formula, using Wolfram Alpha: $$\\left( 1 - \\frac{n-1}{2 \\times 365 + n-1} \\right) \\times \\left( 1-\\prod_{i=0}^{n-1} \\frac{365-2 \\times i}{365} \\right)$$\n\nHowever, this is just a tweak, ans is clearly wrong for $n=33$ since:\n\nNumber of people: 33    My guess: 0.91407\nNumber of people: 33    Lower bound: 0.94328    Upper bound: 0.94447\n\nThanks to Jacopo Notarstefano, leonbloy, and Moron, here is the (correct) formula: $$ 1-\\sum_{k=1}^{n}\\frac{1}{365^{n-k}k}\\left(\\prod_{i=1}^{k-1}\\frac{365-\\left(k+i\\right)}{365\\times i}\\right)\\sum_{j=0}^{k-1}\\left(-1\\right)^{j}C_{k}^{j}\\left(k-j\\right)^{n} $$\n\nAnd here are the results of the computations using this formula with Python:\n\nNumber of people:  1    Probability: 0.0\nNumber of people:  2    Probability: 0.005479452\nNumber of people:  3    Probability: 0.016348283\nNumber of people:  4    Probability: 0.032428609\nNumber of people:  5    Probability: 0.053459591\nNumber of people:  6    Probability: 0.079104502\nNumber of people:  7    Probability: 0.108959718\nNumber of people:  8    Probability: 0.14256532\nNumber of people:  9    Probability: 0.179416899\nNumber of people: 10    Probability: 0.218978144\nNumber of people: 11    Probability: 0.260693782\nNumber of people: 12    Probability: 0.304002428\nNumber of people: 13    Probability: 0.34834893\nNumber of people: 14    Probability: 0.393195856\nNumber of people: 15    Probability: 0.438033789\nNumber of people: 16    Probability: 0.482390182\nNumber of people: 17    Probability: 0.525836596\nNumber of people: 18    Probability: 0.567994209\nNumber of people: 19    Probability: 0.608537602\nNumber of people: 20    Probability: 0.647196551\nNumber of people: 21    Probability: 0.683756966\nNumber of people: 22    Probability: 0.718059191\nNumber of people: 23    Probability: 0.749995532\nNumber of people: 24    Probability: 0.779509664\nNumber of people: 25    Probability: 0.806569056\nNumber of people: 26    Probability: 0.831211564\nNumber of people: 27    Probability: 0.853561895\nNumber of people: 28    Probability: 0.873571839\nNumber of people: 29    Probability: 0.892014392\nNumber of people: 30    Probability: 0.906106867\nNumber of people: 31    Probability: 0.919063161\nNumber of people: 32    Probability: 0.928791992\nNumber of people: 33    Probability: 0.944659069\nshare|improve this question\nThe reason your first formula doesn't work is this: if two people have the same birthday, then they only exclude two days between them, not four. I can't see what your second formula is trying to do. \u2013\u00a0 TonyK Jan 20 '11 at 10:09\nThanks. For information, the second formula is just the result of playing with the simulation and the results. It seems okay for small n, but just an approximation of the expected result. \u2013\u00a0 Wok Jan 20 '11 at 10:11\nI wish people didn't ask questions like this. I have work to do! \u2013\u00a0 TonyK Jan 20 '11 at 10:16\nI'll tell my friend to stop asking me intractable problems: he does not know the answer and I am not sure there is a nice formula. Sorry. \u2013\u00a0 Wok Jan 20 '11 at 11:18\nThe second formula is wrong but is a nice try: it corresponds to count all the possible ways of placing the n birthdays, taking into count that each new birthday removes two possibilities. But this is incorrect because it may happen that a new birthday just removes one possibiliy (or none!) It must be a good approximation for small n. \u2013\u00a0 leonbloy Jan 20 '11 at 11:58\n\n3 Answers 3\n\nup vote 9 down vote accepted\n\nI believe we can give a formula, but I would not call it \"closed form\".\n\nWe have $\\displaystyle n$ people, and $\\displaystyle k$ possible birthdays to choose from (i.e. $\\displaystyle k$ days in a year). Let $\\displaystyle M$ be the minimum of the two.\n\nWe will try and count the number of birthday assignments in which no two people have consecutive birthdays.\n\nTo do this, we will try and count the assignments which use exactly $d$ distinct birthdays, for $\\displaystyle d=1, 2 \\dots, k$, and then add them up.\n\nNow suppose we had a set of $\\displaystyle d$ distinct birthdays (don't worry about the consecutive part, just yet). How many ways can we assign these $\\displaystyle d$ birthdays to $\\displaystyle n$ people, so that each birthday is used at least once?\n\nThis is basically the problem of finding the number of ways to partition a set of size $\\displaystyle n$ in exactly $\\displaystyle d$ non-empty parts and assign the $\\displaystyle d$ birthdays to each part in the partition, exactly one to each.\n\nThe number of ways to partition a set of size $\\displaystyle n$ into $\\displaystyle d$ non-empty parts is given by a Stirling Number of Second Kind, $S(n,d)$. The number of ways to assign $\\displaystyle d$ birthdays is $\\displaystyle d!$.\n\nThus the number we are looking for is $\\displaystyle S(n,d) \\times d!$.\n\nNow suppose we managed to count the number of subsets containing $\\displaystyle d$ elements (from the $\\displaystyle k$ birthdays) such that no two elements of the set are consecutive, then we could multiply that number by $\\displaystyle S(n,d) \\times d!$ to give the number of birthday assignments which use exactly $\\displaystyle d$ birthdays such that no two are consecutive.\n\nFor the moment, ignore the fact that Jan 1 and Dec 31 are consecutive.\n\nWe need to select $\\displaystyle d$ numbers from $\\displaystyle 1,2, \\dots, k$ such that no two are consecutive.\n\nNow if $\\displaystyle b_1 \\lt b_2 \\lt \\dots \\lt b_d$ were such numbers, then notice that\n\n$\\displaystyle 1 \\le b_1 \\lt b_2 - 1 \\lt b_3 - 2 \\dots \\lt b_d - (d-1) \\le k-(d-1)$ gives us a way to select numbers from $\\displaystyle 1, 2, \\dots, k-(d-1)$ without having to bother about the consecutive issue.\n\nThis can be done in $\\displaystyle {k-d+1 \\choose d}$ ways.\n\nNow since Jan 1 and Dec 31 are consecutive, we need to subtract from this, the number of sets which contain both $\\displaystyle 1$ and $\\displaystyle k$.\n\nThis number is same as the number of $\\displaystyle d-2$ non-consecutive subsets of $\\displaystyle \\{3, \\dots, k-2\\}$ which is $\\displaystyle {k-d-1 \\choose d-2}$.\n\nThus the number of ways of selecting $\\displaystyle d$ non-consecutive birthdays (assuming $\\displaystyle 1$ and $\\displaystyle k$ are consecutive) is $\\displaystyle {k-d+1 \\choose d} - {k-d-1 \\choose d-2}$, with the understanding that the term being subtracted is $\\displaystyle 0$ for $\\displaystyle d = 1$ and that $\\displaystyle {a \\choose b} = 0$ if $\\displaystyle a \\lt b$\n\nThus, for $\\displaystyle M = \\text{min}\\{n,k\\}$, the total number we are looking for is,\n\n$$ \\sum_{d=1}^{M} S(n,d)\\times d! \\times \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)$$\n\nNote that $\\displaystyle S(n,d) \\ d! = \\sum_{j=0}^{d} (-1)^j {d \\choose j} (d-j)^n$\n\nSo we could also write the formula as\n\n$$ \\sum_{d=1}^{M} \\left(\\sum_{j=0}^{d} (-1)^j {d \\choose j} (d-j)^n\\right) \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)$$\n\nwhich is a bit ugly.\n\nThus the probability you are looking for is\n\n$$1 - \\frac{ \\sum_{d=1}^{M} S(n,d)\\times d! \\times \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)}{k^n}$$\n\nshare|improve this answer\nWhat I don't get is \"We have n people, and k birthdays.\" In my \"experiment\", I have n (fixed) people, each with a random birthday. The set of distict birthdays (which also appeared in my deduction) is a random number, not an input. Perhaps I'm missing something. \u2013\u00a0 leonbloy Jan 20 '11 at 23:37\n@leon: $k = 365$ in our case. Have edited to make it clearer. \u2013\u00a0 Aryabhata Jan 20 '11 at 23:40\n@leon: I see where your confusion might be. We are using similarly named variables, but they mean different things in our answers. For instance, your $k$, is my $d$. Your $M$ is my $k$. btw, I have confirmed that your answer and my answer give the same answer. Also, in your answer, instead of $Q(n,k)$, you perhaps meant $Q(M,k)$. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:31\n+1 for thorough explanations. I believe all three answers are great! Yet yours would be the most pedagogical one. \u2013\u00a0 Wok Jan 21 '11 at 15:44\n@Moron: right, thanks for the correction, fixed. I prefered to expressed it in that way (Q individualized) to emphasize that it's a probability \u2013\u00a0 leonbloy Jan 21 '11 at 18:01\n\nNB: I worked earlier on this problem and came up with the following solution. The first answer that was posted made me think that I got something wrong, and I discarded my work. Since the new answer by Moron agrees (essentially) with my previous work here it is, a slightly different derivation of the same formula.\n\nLet $k$ be the number of days in a year. Let $m$ be the distinct number of birthdays among the $n$ friends. Let's assume that $k$ is big enough to have a non-trivial problem (say, $k > n/2$)\n\nWe're interested in binary strings with these three conditions:\n\n  1. Are of length $k$, with $m$ ones and $k-m$ zeros.\n  2. There's at least one zero between any two ones.\n  3. Condition 2 holds when \"wrapping around\" the string.\n\nLet's count them by constructing them with the following algorithm:\n\n  \u2022 Start with a string of $m$ ones: $11\\dots 1$\n  \u2022 There are now three distinct cases: there's a birthday on the first day of the year, there is a birthday on the last day of the year, there's a birthday on neither.\n  \u2022 In the first case we have to distribute $k-m$ zeros in $m$ non-empty buckets. Those are called compositions, and one can show that there are $\\binom{k-m-1}{m-1}$ such assignments.\n  \u2022 The second case is analogous, giving another $\\binom{k-m-1}{m-1}$ possible strings.\n  \u2022 The third case is similar, giving instead $\\binom{k-m-1}{m}$ strings.\n\nPutting this together we have: $$2\\cdot \\binom{k-m-1}{m-1}+\\binom{k-m-1}{m}$$\n\nSince $n$ friends share $m$ birthdays we have to account for that, giving this expression:\n\n$$p(n,k) =\\frac{\\sum_{m=1}^n{ m! \\cdot S(n,m)\\cdot \\Bigg (2\\cdot \\binom{k-m-1}{m-1}+\\binom{k-m-1}{m}}\\Bigg )}{k^n}$$\n\nwhere $S(n,m)$ is the Stirling number of the second kind.\n\n@Moron: Why do we need to multiply by $m!$ here? Oh right! Stirling numbers of the second kind count the number of coalitions, but we care about their order, too!\n\nshare|improve this answer\nDid you mean $S(n,m)$? We need to multiply by factorial as we also need to assign the birthdays. The Stirling number counts the number of unordered partitions. We could assign the birthdays to each partition in $m!$ ways. For instance for $m=2$ there are $2^{n-1} - 1$ partitions, but you can rearrange the parts of the partition to get different birthdays assigned. \u2013\u00a0 Aryabhata Jan 21 '11 at 4:12\n+1: Apart from the missing $m!$ term. We have that identity $2 \\binom{k-m-1}{m-1} + \\binom{k-m-1}{m} = \\binom{k-m+1}{m} - \\binom{k-m-1}{m-2}$, which matches my answer. So this confirms that this matches Leonbloy's answer too. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:39\nOh right! We do care about their order, too. Fixed the typo in $S(n,m)$. Thank you! \u2013\u00a0 Jacopo Notarstefano Jan 21 '11 at 8:54\n+1 for an explanation using binary strings and compositions. \u2013\u00a0 Wok Jan 21 '11 at 15:21\nUsing weak compositions makes the problem really simple to handle. Bravo! \u2013\u00a0 Wok Jan 21 '11 at 15:32\n\nUPDATE - THIS IS WRONG -- SEE BELOW CORRECT ANSWER --- Let's call N1 the number of configurations that have at least one day in between birthdays (this excludes not only consecutive birthdays, but also coincident birthdays).\n\nI get (counting weak compositions) :\n\n$ \\displaystyle N_1 = 365 \\frac{(365-n-1)!}{(365-2n)!}$\n\nIf you want to include coincident birthdays, we have\n\n$\\displaystyle N_0 = \\frac{365!}{(365-n)!}$\n\nSo the probability asked is\n\n$\\displaystyle P = \\frac{N_0 - N_1}{365^n}$\n\nUpdate: there might be is some error here, I think I'm failing to taking into account the configurations that have both coincident and consecutive birthdays, I'll revise this tonight. I suspect that N1 is correct, and that allows to compute the probability of having consecutive OR coincident birthdays. To count consecutive (exclusively) birthdays seems more difficult.\n\nUPDATE: Here's the correct (I hope) answer.\n\nThe probability of having at least a pair of consecutive birthday for M (=365) days and n persons is\n\n$\\displaystyle P(M,n) = 1 - \\sum_{k=1}^n Q(M,k) {M \\choose k} \\frac{S(n,k) k! }{M^n} = 1 - \\frac{1}{M^{n-1}} \\sum_{k=1}^n \\frac{(M-k-1)!}{(M-2k)!} S(n,k) $\n\nwhere $ \\displaystyle Q(M,k) = \\frac{{M -k - 1 \\choose k -1} }{{M -1 \\choose k -1} } $\n\nand $S(n,k)$ are the Stirling numbers of the second kind\n\nSome computed values follow\n\nM=365 n=1 p=0.00000000\nM=365 n=2 p=0.00547835\nM=365 n=3 p=0.01634745\nM=365 n=4 p=0.03242761\nM=365 n=5 p=0.05345896\nM=365 n=6 p=0.07910314\nM=365 n=7 p=0.10895871\nM=365 n=8 p=0.14256439\nM=365 n=9 p=0.17941667\nM=365 n=10 p=0.21897764\nM=365 n=11 p=0.26069278\nM=365 n=12 p=0.30400167\nM=365 n=13 p=0.34834843\nM=365 n=14 p=0.39319571\nM=365 n=15 p=0.43803357\nM=365 n=16 p=0.48239009\nM=365 n=17 p=0.52583640\n\nM=365 n=30 p=0.90729104\n\nM=365 n=42 p=0.99074145 \n\n\nLet $M$ (=365) number of days, and $n$ = number of persons and $k$ = number of distinct birthdays ($k$ is not fixed, it's a random variable in the range $1..n$). Let $P_{M,n}(S)$ be the probability of NOT having consecutive birthdays (S is the event: \"all birthdays are separated\")\n\nThen $P_{M,n}(S) = \\sum_k P_{M,n}(S \\; k) = \\sum_k P_{M,n}( S | k ) P_{M,n}(k )$\n\nThe following steps compute the two factors inside the summation:\n\n\n$P_{M,n}( S | k )$ is the probability of having the events separated, given that the number of distinct birthdays is $k$. If we think of birthdays as occupied boxes in a circular list, a little reflection shows that all configurations are equiprobable ($n$ does not matter now) and we can assume without altering the result that the first box of the list is occupied. Now, the total number of possible ocurrences are the number of selection of $k-1$ boxes among $M-1$ (combination).\n\nAnd the number of \"succesfull\" arrangements are those that result in non-consecutive occupied boxes. But this is equivalent of specifying a list of $k$ numbers greater than 1 that sum up to M; and this is the same as specifying a list of $k$ numbers greater than 0 than sum up to $M-k$; and this can be counted, by a reasoning similar to this one, as the combination of $k -1$ taken from $M -k - 1$. So,\n\n$\\displaystyle P_{M,n}( S | k ) = \\frac{{M -k - 1 \\choose k -1} }{{M -1 \\choose k -1} } = Q(M,k)$\n\n\n$P_{M,n}(k)$ : if we place $n$ balls at random in $M$ boxes, what is the probability that exactly $k$ boxes will be non-empty?\n\nThe total counting is given by $M^n$. To count the \"successful\" cases, we multiply:\n\n  \u2022 all the possible sets of occupied boxes (combinations of $k$ taken from $M$)\n\n  \u2022 the total numbers of ways of putting $n$ balls in $k$ boxes leaving no empty box: that is given by the Stirling numbers of the second kind.\n\n  \u2022 and we need to multiply by $k!$ (permutations of boxes) because the Stirling numbers consider nondistinct boxes.\n\n    $\\displaystyle P_{M,n}(k ) = {M \\choose k} \\frac{S(n,k) k! }{M^n}$\n\nAnd from there follows the formula above.\n\nshare|improve this answer\nI agree (now!) with all this. I hope you don't have anything else on tonight though :-) \u2013\u00a0 TonyK Jan 20 '11 at 15:39\nThanks for trying, but it does not fit the estimated probabilities with Python. :( \u2013\u00a0 Wok Jan 20 '11 at 19:07\nAlthough my symulations do not give the same probabilities for several n, I wonder whether there is a bias due to the *pseudo-*randomness of generated integers. \u2013\u00a0 Wok Jan 20 '11 at 22:08\nWeird. You made the edit while I was writing my answer. They seem to be a bit different though. \u2013\u00a0 Aryabhata Jan 20 '11 at 23:30\nI have confirmed that the updated formula is same as mine. +1. Basically I have confirmed that $Q(M,k) {M \\choose k} = {M-k+1 \\choose k} - {M-k-1 \\choose k-2}$. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:32\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/263429/four-digit-reversal-numbers\nText:\nTake the 2-minute tour \u00d7\n\nHow to prove without an exhaustive checking that there are only 2 (nontrivial) four digit reversal numbers?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThat depends how exhaustive you are willing to be. The multiplier can only be in the range $2-9$, which is only eight cases. To check $4$ we write $abcd \\times 4=dcba$ where concatenation indicates different digits. $a$ has to be even as the last digit of the product, and has to be $2$ or there would be a carry. Then $d$ has to be $8$ so that it can produce $a$. $b$ has to be $0,1,2$ to avoid a carry and is odd because of the carry from the ones place, so it is $1$. Then $c$ has to be $7$ and we are done-$2178 \\times 4 = 8712$. $5, 6$ and $8$ are out because $a$ would have to be $1$ to avoid a product over $10,000$ but that is odd and not $5$. $7$ is out because again $a$ would have to be $1$, but then $d$ can't be $3$. So we just have to check $2, 3,$ and $9$-not too much work.\n\nshare|improve this answer\n\nLet $A = \\{2,3,4,5,6,7,8,9\\}$.\n\nLet the $4$ digit reversal number be $abcd$ i.e. $1000a + 100b + 10 c + d$, where $a \\in \\{1\\} \\cup A$, $d \\in \\{1,2,3,\\ldots,a-1\\}$ and $b,c \\in \\{0,1\\} \\cup A$. Its reversed number is $$dcba = 1000d + 100c + 10b + a$$ We want $abcd = k \\times (dcba)$ where $k \\in A$. This gives us $$(1000-k)a + (100-10k)b + (10-100k)c + (1-1000k) d = 0$$\n\n$$\\color{red}{\\text{First note that $10 \\vert (ka-d)$. This also means that if $a$ is even, then $d$ also has to be even.}}$$\n\nLet us call the above necessary condition in red as $\\star$. As explained below, this necessary condition filters out almost all the solutions that are not possible.\n\n  \u2022 If $a=2$. Then $d=1$. Violates $\\star$.\n  \u2022 If $a=3$. Then $d=1$. Hence, $k=1$ or $2$. $ka - d = 1 or 5$. Violates $\\star$.\n  \u2022 If $a=4$. Then $d=2$. If $d=2$, then $k=2$, then $ka-d = 6$. Violates $\\star$.\n  \u2022 If $a=5$. Then $d=1$ or $2$. If $d=1$, $k = 3$ or $4$ or $5$. But $10$ doesn't divide $ka - d$ if $d=1$. Violates $\\star$. If $d=2$, $k=2$. Violates $\\star$.\n  \u2022 If $a=6$, then $d=2$. If $d=2$, then $k=3$. Violates $\\star$.\n  \u2022 If $a=7$, then $d=1,2,3$. If $d=1$, $k=4,5,6,7$. Violates $\\star$. If $d=2$, then $k=3$. Violates $\\star$.\n  \u2022 If $a=8$, then $d=2,4$. If $d=4$, $k=2$. Violates $\\star$. If $d=2$, $k=3,4$. $k=3$ violates $\\star$. However, $k=4$ satisfies $\\star$. Hence, $a=8$, $d=2$ and $k=4$ is a possible candidate. Let us return to this candidate later.\n  \u2022 If $a=9$, then $d=1,2,3,4$. If $d=1$, $k=5,6,7,8,9$. Except $k=9$, the rest violate $\\star$. We will return to the case $a=9$, $d = 1$ and $k=9$ later. If $d=2$, then $k=4$. Violates $\\star$. If $d=3$, $k=3$. Violates $\\star$. If $d=4$, $k=2$. Violates $\\star$.\n\nHence, after this elimination using the necessary condition $\\star$, we get only two possibilities.\n\n  1. $a = 8$, $d=2$ and $k=4$. This means $60b - 390c + 996 \\times 8 - 3999 \\times 2 = 0$. Hence, $2b - 13c = 1$. This gives $b=7$ and $c=1$.\n  2. $a = 9$, $d=1$ and $k=9$. This means $10b - 890c + 991 \\times 9 - 8999 \\times 1$. Hence, $b-89c = 8$. This gives us $b=8$ and $c=0$.\n\nHence, the only two numbers are $8712$ and $9801$.\n\nshare|improve this answer\nI like both answers thus far, though. Thank you. \u2013\u00a0 anon Dec 21 '12 at 22:38\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/280837/cdf-of-maxx-1-x-2-maxx-3-x-4-where-all-x-is-are-iid-from-ua-b?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am looking for the cumulative density function of the sum of two variables, which are themselves the result of a rank order process.\n\nThus, if $x_1, x_2, x_3$ and $x_4$ are all independent draws from a uniform distribution with support $[a,b]$, what is the CDF for $\\max(x_1,x_2)+\\max(x_3,x_4)$?\n\n\nshare|improve this question\n\n2 Answers 2\n\nLet $X=\\max\\{x_1,x_2\\}$. We find the density function of $X$. We have that $F_X(x)=\\mathbb{P}\\{X\\leq x\\}=\\mathbb{P}\\{\\max\\{x_1,x_2\\}\\leq x\\}=\\mathbb{P}\\{x_1\\leq x \\cap x_2\\leq x\\}=\\mathbb{P}\\{x_1\\leq x\\}\\mathbb{P}\\{x_2\\leq x\\}$. Because they are uniformly distributed, it follows that the above is just the product of the cdfs of your original uniform distribution. Therefore $F_X(x)=(\\frac{x-a}{b-a})^2$ whenever $x\\in[a.b)$. From this it follows that $f_X(x)=\\frac{2(x-a)}{(b-a)^2}$. Similarly, if $Y=\\max\\{x_3,x_4\\}$, you have that $f_Y(y)=\\frac{2(y-a)}{(b-a)^2}$. Now let $Z=X+Y$. You have that $Z\\leq 2b$ with probability one and $Z\\leq 2a$ with probability 0. For $z\\in[2a,2b)$ you have $F_Z(z)=\\mathbb{P}\\{Z\\leq z\\}=\\mathbb{P}\\{X+Y\\leq z\\}=\\int_A f_{X,Y}(x,y) dA$ Because of independence of $x_1,x_2,x_3$ and $x_4$ you have that $X$ and $Y$ are independent. This means that $f_{X,Y}(x,y)=f_X(x)f_Y(y)$. Therefore, $F_Z(z)=\\int_A f_X(x)f_Y(y) dA=\\int_{-\\infty}^\\infty\\int_{-\\infty}^{z-x}f_X(x)f_Y(y)dydx=\\int_{-\\infty}^\\infty f_X(x)\\int_{-\\infty}^{z-x}f_Y(y)dydx=\\int_a^b f_X(x)\\int_a^{z-x}f_Y(y)dydx=\\int_a^b f_X(x) (\\frac{a+x-z}{b-a})^2dx=\\frac{1}{(b-a)^4}\\int_a^b 2(x-a)(a+x-z)^2 dx=\\frac{1}{12(a-b)^2}(11a^2+10ab-16az +3b^2-8bz+6z^2)$. I hope this is correct.\n\nshare|improve this answer\nThanks. Been working on this and got to the point where I have the PDFs and CDFs of x and y correct as as yours. I follow most of the rest of your derivations, but your result produces a strictly convex to the origin CDFs and therefore negative probabilities over some range. I have tried to take it from the double integrals in Mathematica. I get something close but slightly different but still with implausible results. \u2013\u00a0 user58641 Jan 17 '13 at 21:02\nI could've made a typo, but notice also that you have $z\\in[2a,2b)$. So the cdf is zero for all $z<2a$, whatever that integral turns out to be for $z\\in[2a,2b)$ and 1 for $z\\geq 2b$. \u2013\u00a0 mathemagician Jan 17 '13 at 21:15\nGot that. I am only plotting from 2a to 2b but there appears to be something not quite right in the development of the integrals since trying to go back up and replicating your steps I get similar results. \u2013\u00a0 user58641 Jan 17 '13 at 21:19\nif somebody could point at the mistake that would be highly appreciated \u2013\u00a0 mathemagician Jan 17 '13 at 22:01\n\nSuppose $u,v$ are i.i.d. $U(0,1)$. Then for any $w\\in[0,1]$, $\\operatorname{Pr}(\\max(u,v)\\le w)=w^2$. Hence the density of $W=\\max(u,v)$ is given by $f(w)=2w$. Therefore, if $X=(\\max(x_1,x_2)-a)/(b-a)$ and $Y=(\\max(x_3,x_4)-a)/(b-a)$, the densities of $X$ and $Y$ on $[0,1]$ are $2x$ and $2y$ respectively.\n\nNow let $Z=X+Y=\\left[\\max(x_1,x_2)+\\max(x_1,x_2)-2a\\right]/(b-a)$. Then for any $m\\in[0,\\,2]$, we have $$ \\phantom{=}\\operatorname{Pr}\\left(Z\\le m\\right) =\\begin{cases} \\int_0^m \\int_0^{m-y} 4xy\\, dx dy=\\frac{m^4}{6} &\\text{ if } m\\le1,\\\\ 1-\\int_{m-1}^1 \\int_{m-y}^1 4xy\\, dx dy = 1-\\frac16m(m-2)^2(m+4) &\\text{ otherwise}. \\end{cases} $$\n\nshare|improve this answer\n@D. The density may exceed $1$. Why not? The standard normal density evaluated at $x=0$, for instance, approaches infinity when the standard deviation $\\sigma$ approaches zero. By the way, I've verified the formula using computer simulation. With a million simulation trials, the above formula agrees with the simulation value to three decimal places for $m=0.1,0.2,\\ldots,1.9$. \u2013\u00a0 user1551 Jan 17 '13 at 23:54\nThanks. If you got an email of my last comment, just disregard.. That was silly! Thanks a lot for your help. I think I got it now, although a good reference for these derivations would be useful! \u2013\u00a0 user58641 Jan 18 '13 at 0:25\n@D. I don't have any reference. For $m\\le1$, I just integrated the joint density function over the triangular domain bounded by the $x$-axis, the $y$-axis and the line $x+y=m$. For $m\\ge1$, I integrated the density over the triangular domain bounded by $x=1$, $y=1$ and $x+y=m$, and then subtract the result from $1$. \u2013\u00a0 user1551 Jan 18 '13 at 1:08\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/16565/do-decidable-properties-of-finitely-presented-groups-depend-only-on-the-profinit?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nThis is a just-for-fun question inspired by this one. Let $P$ be a property of finitely presentable groups. Suppose that\n\n  1. The truth of $P(G)$ only depends on the isomorphism class of $G$.\n\n  2. Given a finite presentation of $G$, the truth of $P(G)$ is computable.\n\nLet $\\hat{G}$ denote the profinite completion of $G$. Is it possible to have groups $G$ and $H$, and such a property $P$, so that $\\hat{G} = \\hat{H}$ but $P(G) \\neq P(H)$?\n\nFor example, is there a computable property which separates Higman's group from the trivial group?\n\nshare|improve this question\nI'm glad to see that you've picked up the thread, David. This question is related to understanding the equivalence relation \\equiv at conclusion of my question, to which you link. mathoverflow.net/questions/16532. A related issue: It seems that the relation of having the same profinite completion is likely not decidable. Do we have proof of this? \u2013\u00a0 Joel David Hamkins Feb 27 '10 at 0:53\nDo you know of interesting properties satisfying 1. and 2.? The ones I can think of involve calculating the abelianization of G (or other nilpotent quotients). These certainly won't work. On an unrelated-but-feels-a-bit-related note, Bridson (Paper I <a href=\"people.maths.ox.ac.uk/~bridson/papers/profinite/\u2026) constructs examples of injective homomorphism $i:H \\hookrightarrow G$ so $i$ induces an isomorphism on profinite completions, but you can't decide if $G$ and $H$ are isomorphic. You can take H and G to both be residually finite, or alternatively you can take $H=\\{1\\}$. \u2013\u00a0 Daniel Groves Feb 27 '10 at 0:55\nOh, I just read the linked question, and so I guess you don't know of interesting properties satisfying 1. and 2. ... \u2013\u00a0 Daniel Groves Feb 27 '10 at 0:58\nNot to say that the answers given in that question aren't interesting, just that I know about them. (I realised that my second comment was quite rude, for which I apoligize.) \u2013\u00a0 Daniel Groves Feb 27 '10 at 1:03\nJoel, Regarding whether or not having isomorphic profinite completions is decidable... In the second paper on the webpage that Daniel linked to above, Bridson exhibits pairs of a group and a subgroup such that no algorithm can determine whether or not they have isomorphic profinite completions. Unfortunately, it may be impossible to compute a presentation for the subgroup. I discuss this sort of thing in my answer to this question: mathoverflow.net/questions/15957/\u2026 \u2013\u00a0 HJRW Feb 27 '10 at 2:19\n\n3 Answers 3\n\nOK, I think I have an example of two groups with the same profinitization and a computable property which distinguishes them. The point is that very fine detail about the commutator subgroups can't be seen in the profinitization.\n\nLet $q$ be prime and let $K$ be the $q$-th cyclotomic field. Choose $q$ such that the class group of $K$ is not trivial. Let $I$ be a trivial ideal of $\\mathcal{O}_K$ and $J$ a nontrivial ideal. Our groups $G$ and $H$ will be $(\\mathbb{Z}/q) \\ltimes I$ and $(\\mathbb{Z}/q) \\ltimes J$.\n\nFor any group $B$, let $B' = [B,B]$ and $B'' = [B', B']$. Note that $B/B'$ acts on $B'/B''$ by conjugation. Our computable criterion is the following:\n\n$B/B' \\cong \\mathbb{Z}/q \\times \\mathbb{Z}/q =: A$, the action of the group ring $\\mathbb{Z}[A]$ on $B'/B''$ factors through a map $\\mathbb{Z}[A] \\to \\mathcal{O}_K$ and, as such, $B'/B''$ is a free $\\mathcal{O}_K$ module.\n\nWe leave it as an exercise that $G$ satisfies this condition and $H$ does not.\n\nI believe this condition should be computable. We can go from a finite presentation of $B$ to one of $B'$. (UPDATE I have revised this argument.) Abelianizations are computable, so we can check whether $B/B'$ has the right format. If it does, then $B'$ has finite index in $B$. I think we can use this to get a finite presentation of $B'$: Let $\\Delta$ be a two-dimensional $CW$-complex with one vertex, an edge for each generator of $B$ and a two cell for each relation. Let $\\Delta'$ be the cover of $B$ corresponding to $B'$. Since $B$ has finite index in $B'$, $\\Delta'$ will have finitely many cells, and we get a finite presentation of $B'$.\n\nWe can the compute the abelianization of $B'$ and, I think, the action of the abelianization of $B$ on that of $B'$ should be computable. Note that there are only $q^2$ maps from $\\mathbb{Z}[A]$ to $\\mathcal{O}_K$, so we can just check them each in turn. The class of a finite generated module for a Dedekind domain should be computable by standard number theory methods, although I admit I couldn't describe them.\n\nThe fact that these two groups have the same profinitization is relatively well known. Let $\\hat{I}$ and $\\hat{J}$ denote the profinite completions of $I$ and $J$. The profinite completions of $G$ and $H$ are $\\mathbb{Z}/n \\ltimes \\hat{I}$ and $\\mathbb{Z}/n \\ltimes \\hat{J}$.\n\nWe can identify $\\hat{I}$ and $\\hat{J}$ with submodules of $\\mathbb{A}^0_K$, the integral adeles of $K$. Since $I$ and $J$ are locally principal, these are principal ideals in the ring $\\mathbb{A}^0_K$. They are thus equivalent as $\\mathbb{A}^0_K$ modules, and thus as $\\mathcal{O}_K$ modules.\n\nshare|improve this answer\nThe commutator subgroup of a finitely presented group need not be a finitely presented group. For example, the commutator subgroup of the free group on 2 generators is not even finitely generated. \u2013\u00a0 Bjorn Poonen Feb 27 '10 at 15:17\nDavid, you're correct that a finite-index subgroup of a fp group is fp, so if the abelianization of B is finite and B is fp then B' is also fp. So why is your G fp? \u2013\u00a0 HJRW Feb 27 '10 at 23:50\nTo add a little bit: the first construction of a pair of non-isomorphic, fp, residually finite groups with isomorphic profinite completions was given by Bridson and Grunewald in 2004. Their construction is still essentially the only known one. Your groups seem to be obviously residually finite, so if they're fp then they this is very interesting. \u2013\u00a0 HJRW Feb 28 '10 at 0:05\n@Henry: A semidirect product of finitely presented groups is finitely presented. \u2013\u00a0 Bjorn Poonen Feb 28 '10 at 1:51\n@Henry: I think it was known <=1964 that there exist 2 residually finite fp groups with isomorphic profinite completions. If one starts with a smooth projective variety over a number field k, extends the base via two embeddings k --> C, and takes the fundamental group, then the two resulting groups are fp groups with isomorphic profinite completions (\u00e9tale fundamental group of V_kbar). In 1964 Serre gave an example in which these groups were not isomorphic. And if I remember correctly, they were residually finite. In fact, I think they were exactly the groups David has constructed. \u2013\u00a0 Bjorn Poonen Feb 28 '10 at 2:27\n\nIn this paper, Owen Cotton-Barratt and I construct two finitely presentable groups with isomorphic profinite completions, but such that one is conjugacy separable (implying solvable conjugacy problem) and the other has unsolvable conjugacy problem.\n\n(The construction is very much in the spirit of the paper of Bridson that Daniel Groves mentioned in the comments.)\n\n\nSorry, I only just noticed requirement 2. Since almost no properties are computable from a finite presentation, and yet the class of properties computable from a finite presentation is mysterious (eg does it include having a proper finite-index subgroup?), I don't see how you'll get any interesting answers with condition 2.\n\n\nAs Bjorn explained to me in the comments to David's answer, it's not nearly as hard as I had thought to build two fp groups with the same profinite completion. Indeed, there are virtually abelian examples. As one can solve the isomorphism problem for virtually abelian groups, it follows that there examples of computable properties that are not determined by the profinite completion, as David's answer shows.\n\nshare|improve this answer\n\nIs it decidable from a presentation whether or not a group is large, i.e. admits a homomorphism onto the nonabelian free group on two letters? This seems totally unlikely, and surely either Henry or Daniel would know, but I like the following theorem anyway, so I'll advertise. Lackenby showed (`Detecting large groups', GR/0702571) that largeness is a property of the profinite completion of discrete finitely presented groups.\n\nshare|improve this answer\nHuh, interesting! It's unknown whether this is decidable. It's equivalent to asking whether a group has a proper finite-index subgroup, as G has a proper finite-index subgroup if and only if G*G*G is large. \u2013\u00a0 HJRW Feb 27 '10 at 2:40\nBut how does this answer the question? For a negative answer, what is needed is a decidable property that doesn't respect the profinite completion. (And for a positive answer to the question, you need to grapple with the collection of all decidable properties.) \u2013\u00a0 Joel David Hamkins Feb 27 '10 at 14:36\nJoel, as far as I can tell, there are no genuinely interesting properties that are known to be computable. Indeed, I think 'largeness' is one of the few real candidates. So it's certainly relevant, even if it doesn't answer the question in the strictest sense. \u2013\u00a0 HJRW Feb 27 '10 at 16:42\nActually, what Stover asks is decidable, whether a group has a homomorphism to a free group, by a result of Razborov. The usual definition of large is that there is a finite-index subgroup which maps onto a (non-cyclic) free group, which is actually the condition that Marc shows is determined by the profinite completion. If there is a non-residually finite hyperbolic group, then I suspect the answer to the question is no. ams.org/mathscinet-getitem?mr=755958 \u2013\u00a0 Ian Agol Feb 27 '10 at 23:26\nRight, good point, Ian. In my comment above, I presumed Matt had given the usual definition. Actually, you don't need the full power of Razborov, you just need Makanin. I mentioned this in an answer to this question: mathoverflow.net/questions/16532/\u2026 \u2013\u00a0 HJRW Feb 28 '10 at 0:07\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/125671/ell-1-dense-in-c-0\nText:\nTake the 2-minute tour \u00d7\n\nThis may be a silly question, but here goes. To ensure clarity, $\\ell_1$ is the space of absolutely summable sequences, and $c_0$ the space of bounded sequences with limit 0. So we know that $\\ell_1\\subset c_0$ by basic principles. My question is: is $\\ell_1$ when equipped with the sup-norm dense in $c_0$?\n\nHere is my thought, and I would appreciate a comment on correctness or if something went wrong:\n\nLet $\\xi\\in c_0$ and write $\\xi=\\{\\xi_1,\\xi_2,\\xi_3,\\dots\\}$. Now define $P_n:\\ell_1\\to c_0$ by $$P_n(\\eta)=\\{\\eta_1,\\eta_2,\\dots,\\eta_n\\}$$ So if $\\xi\\in c_0$, we can say $$\\xi=\\underset{n\\to\\infty}{\\lim}P_n\\xi$$\n\nSo does this get us all of $c_0$?\n\nA typical example would be the harmonic sequence $\\{1, 1/2, \\dots, 1/n,\\dots\\}$. This is in $c_0$ but not $\\ell_1$, but taking finite pieces of this sequence at a time guarantees us to remain in $\\ell_1$, and we can approximate the sequence in $c_0$ as the limit of elements of $\\ell_1$.\n\nshare|improve this question\nYour proof for the harmonic sequence generalizes. \u2013\u00a0 dls Mar 28 '12 at 23:41\n$c_{00}$ is dense in $c_0$, so any set containing $c_{00}$ is dense in $c_0$. \u2013\u00a0 user16299 Mar 29 '12 at 2:50\n@Yemon Will the same reasoning always hold for sums of Banach spaces? It seems like the same arguments will work to show that the $\\ell_1$ sum of Banach spaces is dense in the $c_0$ sum of Banach space, and so on. Or is there an example out there where this would break down? \u2013\u00a0 Keaton Mar 29 '12 at 16:04\n@keaton I think it should work, just as you say \u2013\u00a0 user16299 Apr 1 '12 at 0:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nYes. Let $(x_n)\\in c_0$ and take $\\epsilon>0$. Since $x_n\\to 0$, we have some $N$ such that $n\\geq N\\implies |x_n|<\\epsilon$. Define the sequence $(y_n)$ by $y_n=x_n$ for $n<N$ and $y_n=0$ for $n\\geq N$. Clearly $(y_n)\\in \\ell^1$, and for any $n$, $|x_n-y_n|\\leq \\epsilon$, hence $\\sup\\limits_{n}|x_n-y_n|\\leq \\epsilon$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/152414/directional-derivates-and-unique-subgradients\nText:\nTake the 2-minute tour \u00d7\n\nI have a question about the fine structure of convex functions. Convex functions behave very regular in the interior of their domain of definition (e.g. they are locally Lipschitz continuous there) but otherwise some weird things can happen. My question concerns convex functions that possess at most one subgradient at each point. Let's fix notation:\n\nLet $X$ be a Banach space and $J:X\\to\\mathbb{R}\\cup\\{\\infty\\}$ be a convex, extended valued function. Denote by $\\newcommand{\\dom}{\\mathrm{dom}}\\dom J = \\{x\\ :\\ J(x)<\\infty\\}$ and assume that the subdifferential $\\partial J$ of $J$ is at most single valued and denote its unique element by $\\nabla J(x)$ (if it exists). Moreover, denote the G\u00e2teaux directional derivative at $x$ in direction $h$ by $DJ(x;h)$. My question is:\n\nDoes $x,y\\in \\dom J$ imply that $$\\langle \\nabla J(x),y-x\\rangle = DJ(x;y-x)\\ ?$$\n\nSome background: I would like to state that in the above framework for some non-strictly convex $J$ there exist $x,y\\in\\dom J$ such that $\\langle \\nabla J(x),y-x\\rangle = J(y)-J(x)$. It clear that one gets $x$ and $y$ such that for $\\lambda\\in]0,1]$ it holds that $$ \\frac{J(\\lambda y + (1-\\lambda)x) - J(x)}{\\lambda}=J(y) - J(x) $$ which implies $DJ(x,y-x) = J(y) - J(x)$.\n\nHowever, there exists a pathological convex function such that its subdifferential at some point is single values although it is not G\u00e2teaux differentiable there (Example 4.2.6 in Borwein and Vanderwerffs \"Convex Functions: Constructions, Characterizations and Counterexamples\", see here). However, I assume a wee bit more, namely that the subdifferential is at most single valued everywhere (but probably this already rules out some pathological things\u2026).\n\nshare|improve this question\nWhat about $f(x) = -1(1-|x|^2)^{1/2}$ on $|x| \\le 1$ and $f(x)=+\\infty$ elsewhere? This function is in fact differentiable at $x$ for all $|x| < 1$, but $\\partial f(x) = \\emptyset$ for all $|x| \\ge 1$---the badness comes from $1 \\in \\dom f$--- does this break your setup? \u2013\u00a0 Suvrit Dec 20 '13 at 17:26\nWell, I am interested in the case where $\\partial f(x)$ is a singleton for all $x$ in $\\mathrm{dom} f$. In your example, the subdifferential is empty precisely where the directional derivative does not exist. \u2013\u00a0 Dirk Dec 20 '13 at 18:02\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/84634/help-prove-a-maximal-inequality\nText:\nTake the 2-minute tour \u00d7\n\nLet $X_1,\u2026,X_n$ are exchangeable of random variables, and $n$ is an even number. $S_k=X_1+\\dots+X_k$. $M_k=X_{n/2}+\\dots+X_{n/2+k}$.\n\nI want to prove:\n\n$$\\Pr(\\max_{1 \\le k \\le n}{|S_k|>\\epsilon}) \\le \\\\Pr(\\max_{1 \\le k \\le n/2}{|S_k|>\\epsilon/2}) + \\Pr(\\max_{1 \\le k \\le n/2}{|M_k|>\\epsilon/2})$$\n\n[added by YC] for background context to this question, see this MSE question\n\nshare|improve this question\nIf $X_1,\\dots, X_n$ are exchangeable, then doesn't $(S_1,\\dots, S_{n/2})$ have the same distribution as $(M_1,\\dots, M_{n/2})$? \u2013\u00a0 Yemon Choi Dec 31 '11 at 9:04\nWell, it isn't true in general. Take $X_i=1/n$ for all $i$ and $\\epsilon=2/3$. \u2013\u00a0 Brendan McKay Dec 31 '11 at 14:19\n@BrendanMcKay, It is still right, the LHS is $\\Pr(1>2/3)=1$, the RHS is $\\Pr(1/2>1/3)+\\Pr(1/2>1/3)=2$ \u2013\u00a0 Fan Zhang Dec 31 '11 at 15:51\nI think the summation for $M_k$ should start at $n/2 + 1$ so that it is the sum of $k$ terms. With this modification, as Yemon Choi pointed out, $M_k$ has the same distribution as $S_k$ so both probabilities on the right hand side are equal. \u2013\u00a0 Pablo Lessa Dec 31 '11 at 18:00\nThe motivation: math.stackexchange.com/questions/94948/\u2026 \u2013\u00a0 Byron Schmuland Dec 31 '11 at 19:11\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nYou can prove it by using the fact that the following holds always:\n\n$\\max_{1 \\le k \\le n}|S_k| \\le \\max_{1 \\le k \\le n/2}|S_k| + \\max_{1 \\le k \\le n/2}|M_k|$\n\nIf the left hand side is larger than $\\epsilon$ then one of the right hand terms is larger than $\\epsilon/2$.\n\nThis also shows that the inequality is valid under absolutely no assumptions on the joint distribution of the variables $X_1,\\ldots,X_n$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/41933/uniqueness-for-solution-of-a-d-dbar-system-related-to-davey-stewartson-solitons\nText:\nTake the 2-minute tour \u00d7\n\nThis question concerns a system of equations that arise in the study of one-soliton solutions to the Davey-Stewartson equation.\n\nIn what follows, $f(z)$ denotes a function which depends smoothly (but not necessarily analytically!) on $z=x+iy$. Thus $f:\\mathbb{C} \\rightarrow \\mathbb{R}$ or equivalently $f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$. We denote by $\\overline{\\partial}$ and $\\partial$ the usual operators $$ \\overline{\\partial} = \\frac{1}{2} \\left( \\partial_x + i \\partial_y \\right) $$ and $$\\partial = \\frac{1}{2} \\left( \\partial_x - i \\partial_y \\right). $$\n\nThe system is:\n\n$$\\overline{\\partial} n_1(z) = (1+|z|^2)^{-1} n_2(z)$$ $$\\partial n_2(z) = -(1+|z|^2)^{-1} n_1(z)$$\n\nand the question is as follows. Suppose that\n\n$$\\lim_{|z|\\rightarrow \\infty} |z| n_1(z) = \\lim_{\\|z| \\rightarrow \\infty} |z| n_2(z) = 0$$\n\nCan one prove that $n_1(z)=n_2(z)=0$ if one assumes a priori that $n_1$ and $n_2$ belong to $L^p(R^2)$ for all $p>2$ (including $p=\\infty$)? For this purpose one can assume that the limits above exist.\n\nThanks in advance for any help.\n\nPeter Perry, University of Kentucky\n\nshare|improve this question\nDid you try with some Pohozaev-type inequality? e.g. like this: 1) apply $\\partial$ to the first equation so it becomes $\\Delta n_1+(1+|z|^2)^{-1}n_1=g$ where $g$ decays at infinity faster than $z^{-3}$ 2) multiply by $\\overline{z}n_1$ and integrate over an annulus. Typically you obtain quite good information on the behavior of the gradient with this method \u2013\u00a0 Piero D'Ancona Oct 13 '10 at 7:09\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/208696/number-of-roots-of-an-equation/208719\nText:\nTake the 2-minute tour \u00d7\n\nPlotting the equation $x^3-x^2 \\sin(x)+\\cos(x)$ I see that $x^3-x^2 \\sin(x)+\\cos(x)=0$ has only one real solution, is there a simpler way to see that it cannot have 3 real solutions?\n\nshare|improve this question\nOne consideration is the sin and cos are less than $1$ in magnitude, so the function may be compared to $x^3-x^2+1$ which also is close to $x^3 - x^2 = x^2(x-1)$. \u2013\u00a0 adam W Oct 7 '12 at 13:11\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nWe have $f(x) = x^3-x^2\\sin(x) +\\cos(x)$, hence $f'(x)=(3-\\cos(x))x^2-(2x-1)\\sin(x)$, $f''(x)=(x^2-2)\\sin(x) + 6x-(4x-1)\\cos(x) $.\n\nFor $0\\le x$ we have $\\sin x\\le x$, hence $f(x)\\ge x^3-x^3+\\cos(x)\\ge \\cos x$, hence any positive root of $f$ must be $\\ge\\frac\\pi2$. But already for $x\\ge\\frac 3 2$, we have $f(x)\\ge x^3-x^2-1=(x-1)x^2-1\\ge(\\frac32-1)\\frac94-1=\\frac18>0$. Therefore $f$ has no nonnegative root.\n\nIf $-\\frac\\pi2\\le x\\le 0$ then $\\sin(x)\\le \\frac2\\pi x$ and $\\cos(x)\\ge1+\\frac2\\pi x$, hence $f(x)\\ge(1-\\frac2\\pi)x^3+1+\\frac2\\pi x$. The right hand side becomes $=0$ at $x=-1$ and has positive derivative. We conclude that $f(x)>0$ for $x> -1$.\n\nObserve that $A\\sin x+B \\cos x=\\sqrt{A^2+B^2}(\\cos u\\sin x+\\sin u \\cos x)=\\sqrt{A^2+B^2}\\sin(x+u)$ for some $u$, i.e. $$\\tag1 |A\\sin x + B\\cos x|\\le \\sqrt {A^2+B^2}.$$ Therefore we see that $f(x)=x^3-x^2\\sin x+\\cos x$ can be estimated as $$ f(x)\\le x^3+\\sqrt{x^2+1}<x^3+\\sqrt{x^2+1+\\frac1{4x^2}}=x^3+\\left|x+\\frac1{2x}\\right|,$$ i.e. for negative $x$ by $$ f(x)<x^3-x-\\frac1{2x}=\\frac{2x^2(x^2-1)-1}{2x} $$ The numerator is positive for $x^2>\\frac{1+\\sqrt 3}2$, i.e. for $x<-\\sqrt{\\frac{1+\\sqrt 3}2}$, even more so for $x\\le -\\frac65$.\n\nBy the results so far, $f$ can have roots only in $(-\\frac65,-1]$.\n\nBetween any two roots of $f$, there must be a root of $f'$. If $f$ has moe than one root, it must have at least three roots (counting multiplicity) because $f(x)\\to\\pm\\infty$ as $x\\to\\pm\\infty$, hence $f'$ must have two roots in $(-\\frac65,-1]$ (again, counting multipliciites) and finally $f''$ must have at least one root in $(-\\frac65,-1]$. Even a mild estimate for $\\sin$ and $\\cos $ in this interval should suffice to show $f''(x)<0$ here.\n\nshare|improve this answer\n\nLet $f(x) = x^3$ and $g(x) = x^2 \\sin(x) - \\cos(x)$. Clearly $$ |g(x)| \\le x^2 + 1, $$ and hence a necesary condition for $f(x) - g(x) = 0$ is that $$ -\\beta = \\frac{1}{3}\\big(-1 - \\alpha_1^{-1/3} - \\alpha_1^{1/3}\\big) \\le x \\le \\frac{1}{3}\\big(1+\\alpha_1^{1/3}+\\alpha_2^{1/3}\\big) = \\beta $$ where $\\alpha_1 = \\frac{29-3\\sqrt{93}}{2}$ and $\\alpha_2 = \\frac{29+3\\sqrt{93}}{2}$.\n\nNow, $$ g'(x) = x^2\\cos(x) + (2 x + 1)\\sin(x) $$ implies $g'(x) > 0$ from $0 < x \\le \\frac{\\pi}{2}$, meaning that $g(x)$ is strictly increasing in $0 < x \\le \\beta < \\frac{\\pi}{2}$, achieving its maximum at $x = \\beta$ and minimum at $x = 0$.\n\nGiven that $g(0) < f(0)$, $\\,f$ striclty increasing, and $$ g(\\beta) < \\beta^2 \\sin(\\beta) < \\beta^3 = f(\\beta), $$ there is no positive solution to $f(x) - g(x) = 0$ for $x \\in [0,\\infty)$.\n\nThe case $ x < 0$ is a bit more interesting. First, we see that $$ g'(x) = 0 \\quad \\Longleftrightarrow \\quad \\frac{x^2}{2 x +1} = -\\tan(x) $$ meaning that $g(x)$ has a (unique) critical point $x_c$ in $\\big(-\\beta,0\\big)$; moreover, $x_c \\in [-\\frac{1}{2},0)$ and it's a maximum (it's easy to see that $g'(-\\pi/4) > 0$ and $g'(-\\pi/12) < 0$).\n\nIn $x \\in [-\\frac{1}{2},0)$, $g(0) < f(0)$ and $$ g(x) < -\\cos(x) \\le -\\cos(-1/2) < -(1/2)^3 \\le x^3 = f(x) $$ implying that there is no solution for $f(x) - g(x) = 0$ for $x \\in [-\\frac{1}{2},\\infty)$.\n\nFinally, $g'(x) > 0 $ for $x \\in [-\\beta, -\\frac{1}{2}]$, and then there is one (and only one) solution in that interval.\n\nHope I didn't made any mistakes.\n\nshare|improve this answer\n\nIt might be helpful to notice that it has an uneven number of solutions, since $x^3 \\to \\pm\\infty$ for $x \\to \\pm\\infty$. We can furthermore see that the function is not strictly even or odd (as it is composed of both an even function $\\cos(x)$, and uneven functions $x^3, x^2\\cdot\\sin(x)$), this might hint at only one solution.\n\nHowever, since the total function is made up of both polynomials of finite order and sinus/cosinus parts, it could have many more solutions - just compare it to the plot of\n\n$$\\frac{1}{100} x^3 - x^2\\sin(x) + \\cos(x).$$\n\nSo, to answer your question, there is no general way of deciding how many solutions such a function could have.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/328091/every-complete-countable-metric-space-has-a-discrete-dense-subset\nText:\nTake the 2-minute tour \u00d7\n\nGiven a complete, countable metric space, say $X$, I'd like to show it has a discrete, dense subset. This seems like an application of the Baire Category Theorem, but that doesn't seem to go anywhere. Any help would be appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 8 down vote accepted\n\nConsider the collection $I$ of all isolated points of $X$. (By the Baire Category Theorem $I$ is nonempty, but that is somewhat immaterial for the moment.) Note that $I$ is then a discrete subspace of $X$. If $I$ were not dense, then $U = X \\setminus \\overline{I}$ is a nonempty (open) set without isolated points. From here we can construct in the usual manner a Cantor set as a subset of $X$, contradicting that $X$ is countable! (The construction goes as in the linked answer, just ensuring that the $x_\\sigma$ are chosen from $U$.)\n\nshare|improve this answer\nAh, so I was heading in the right direction it seems. Thanks for your help. \u2013\u00a0 Alexander Sibelius Mar 12 '13 at 4:58\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/142809/sampling-value-prediction-and-error-correction?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI am a programmer and I don't have much background in mathematics. I know this question might look much more clear to you if I could articulate it in mathematical terminologies. The problem is this is my first question here and I don't know how to ask it in maths languages! So bare with me...\n\nI am making a car-racing game where multiple players on the Internet can compete with each other. Each player drives a car whose position and rotation changes continuously over time. To let players over the network share the same game I have to quickly deliver each player's position and rotation to all other player. The problem is there is always going to be a network latency between data being sent and being received. In other words, by the time a piece of data reaches another player, it is already dated.\n\nI think the solution to my problem is to make a function that can predict the position and rotation of other cars based on the previous data collected. When newer data arrives, the function should have a feedback so that error could be corrected. Parameters used for prediction should also be modified, maybe.\n\nFor example, I am thinking about sampling the position as well as velocity of my car evenly over time, and sending them to other player one by one. Now before other players receive my new data, they can use their own \"predicted velocity\" to approximate my movement. Once the new data arrives, they can use the new position and velocity to do error correction and make new predictions.\n\nSome additional requirements about the function includes:\n\n  1. Efficiency: the prediction and error correction function must be efficient because it is going to be computed by computer every tens of milliseconds.\n  2. Robust: I will sample evenly but the other players won't receive data at an even speed, due to network uncertainties.\n  3. Error Bound: it would be great if there is a way to confine error within a certain range.\n\nI have been googling papers for such functions but I haven't found much useful information. Maybe it's because I don't have the correct keywords. So any answer/comment that\n\n  1. helps to identify & clarify the problem in the math realm\n  2. points to papers of solutions\n\nis highly appreciated!\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYou might want to consider a Kalman filter with a very low measurement error (since presumably, when a player receives an update about position and rotation through the network, that update is treated as gospel).\n\nIn a little more detail, if you have last known position $x$, velocity $v$, rotation $\\theta$ and angular velocity $\\omega$, then you can compute an updated position and velocity after time $\\delta t$:\n\n$$x \\leftarrow x + v \\delta t$$ $$v \\leftarrow v$$ $$\\theta \\leftarrow \\theta + \\omega\\delta t$$ $$\\omega \\leftarrow \\omega$$\n\nSince this involves two multiplications and two additions, it should be fast. You do this every $\\delta t$ seconds until you receive an update, at which point you set the position, velocity, rotation and angular velocity to their updated values, and continue as before.\n\nIf you additionally have the last known acceleration $a$ and angular acceleration $\\nu$ then your update equations become:\n\n$$x \\leftarrow x + v \\delta t + \\tfrac{1}{2} a \\delta t^2$$ $$v \\leftarrow v + a \\delta t$$ $$\\theta \\leftarrow \\theta + \\omega \\delta t + \\tfrac{1}{2} \\nu \\delta t^2$$ $$\\omega \\leftarrow \\omega + \\nu \\delta t$$\n\nwhich will be more accurate, as they take the time-varying velocity and angular velocity into account (whereas the previous equations assume they are constant).\n\nAs for bounding the error, it will depend somewhat on how the game works and how fast quickly the players can change their accelerations. For a naive estimate, you can say that the error in position from the first set of equations is $O(n v \\delta t^2)$ where $n$ is the number of time steps since you received an update, and in the second case it is $O(na\\delta t^3)$, but if the accelerations have changed significantly since you last received an update, these bounds can be violated.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/163440/will-the-following-expression-be-irrational-rational-or-integer?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWill the following expression be irrational, rational or integer?\n\n$$\\sqrt[3]{\\sqrt a +b} - \\sqrt[3]{\\sqrt a -b}$$\n\nwhere $a$ = $52$ and $b$ = $5$ .\n\nBy intuition, I think this will be an integer.\n\nshare|improve this question\nIt certainly depends on $a,b$. For example, take $a=b=0$, then the expression is $0 \\in \\mathbb{Z}$. Take $a=b=1$ and the expression is $2^{1/3}$ which is irrational. \u2013\u00a0 nullUser Jun 26 '12 at 18:51\n@Bazinga I've added LaTeXed version of your formula. If this is what you meant, you can edit the post ant leave the LaTeX-ed version there. For more about writing math at this site see here or here. \u2013\u00a0 Martin Sleziak Jun 26 '12 at 18:51\nThanks @MartinSleziak \u2013\u00a0 Bazinga Jun 26 '12 at 18:53\nGiven any natural $a,b$, it will be an algebraic integer, therefore either integer or irrational. \u2013\u00a0 sdcvvc Jun 26 '12 at 18:57\nInstead of saying \"irrational, rational or integer\", it may be more useful to say \"irrational, non-integer rational, or integer\". \u2013\u00a0 Dave L. Renfro Jun 26 '12 at 19:02\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nLet's use the identity $(\\alpha + \\beta)^3 = \\alpha^3+\\beta^3+3\\alpha\\beta(\\alpha+\\beta)$\n\nSet $\\alpha =\\sqrt[3]{b+\\sqrt{a}} \\text{ and } \\beta= \\sqrt[3]{b - \\sqrt{a}} \\text { and } \\alpha+\\beta=x$\n\nWe know that $\\alpha\\beta = \\sqrt[3]{b+\\sqrt{a}} \\times \\sqrt[3]{b - \\sqrt{a}} = \\sqrt[3]{b^2-a} = \\sqrt[3]{25-52} = -3$\n\nSo $x^3= b+\\sqrt a + b-\\sqrt a - 9x = 2b-9x = 10-9x$\n\nYou know that you are looking for a real answer, because $a$ is positive and the two cube roots are therefore cube roots of real numbers. Arturo has factorised the cubic, but it is easy to see that 1 is a root (integer roots must be divisors of 10).\n\nshare|improve this answer\n\nThe expression quickly brings to my mind the Cardano formulas for a (depressed) cubic. Which suggested the following:\n\nWe can rewrite as $$\\sqrt[3]{b+\\sqrt{a}} + \\sqrt[3]{b - \\sqrt{a}}.$$ This is a root of the cubic $y^3 + 3py + q=0$, where $b = \\frac{-q}{2}$ and $a=\\frac{q^2+4p^3}{4}$.\n\nWith $b=5$, we have $q=-10$, so $$52 = a = \\frac{100+4p^3}{4}.$$ This gives $4p^3 = 208-100 = 108$, so $p^3 = 27$, or $p=3$.\n\nThus, the expression at hand is a root of the cubic $$y^3 + 9y -10 = 0.$$ This cubic has an obvious integer root $y=1$ (or you could use the rational root test to see if it has any rational roots if this is not obvious), which after factoring gives $$y^3 + 9y - 10 = (y-1)(y^2 + y+10).$$ The quadratic is irreducible over $\\mathbb{R}$, so its roots are complex.\n\nAssuming you mean the real cubic roots of the real numbers, since our number is real, it must equal $1$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234473/sum-of-random-variables-uniformly-distributed-0-1-and-0-2\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to get $P(0.9<Y<=1.8)$ for the sum of 2 random and uniform values x1,x2 (so that y=x1+x2) where $x1$~$u(0,1)$ and $x2$~$(0,2)$ and I'm trying to do the convolution for it. Seems like $\\int\\limits_a^b\\int_0^2 xf(x)\\,\\mathrm{d}x$ where a=0.9, b=1.8 and which seems like a logical way to start. I'm not comfortable with convolution but I'm trying to understand the step-by-step reason that this is the proper equation, and how the problem can be solved. I'd like to understand as much about this as possible so I'd like to also compare that problem to finding the $P(0.9<Y<=1.8)$ for just $x1$~$u(0,1)$ where the values summed are independent but still over the same (0,1) area, and also compare it to $P(0.9<Y<=1.8)$ for $exp(2)$ where lambda is 2, which I'm also not really understanding the summed distribution.\n\nshare|improve this question\nHow is $Y$ related to $x_1$ and $x_2$? It is not clear from your description. \u2013\u00a0 Daryl Nov 10 '12 at 22:37\nsum of two random variables is y. \u2013\u00a0 Seyhmus G\u00fcng\u00f6ren Nov 10 '12 at 22:42\nthat's correct, and also added to the above. y=x1+x2 \u2013\u00a0 stackuser Nov 10 '12 at 22:44\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe answer to your question is $\\frac{179}{400}$. First you need to make the convolution of two $p.d.f.$s. However note that this operation is valid only for the independent random variables $X_1$ and $X_2$. I assume they are independent and continue with the solution.\n\nThe result of the convolution will be on the positive $y$ axis, having non zero values between $0$ and $3$. The density of $Y$ is a linear increasing function from $0$ to $1/2$ for $y\\in [0,1]$, a constant function $p_Y(y)=1/2$ when $y\\in [1,2]$ and a linear decreasing function from $1/2$ to $0$ when $y\\in [2,3]$.\n\nWhat remains to do is to find the area under this $p.d.f.$. If you draw and calculate the area either with integrals or using some simple geometric relations, you will find that the area under the curve w.r.t. the square is $0.4$ and the area with respect to the left triange is $19/400$, which adds up to $\\frac{179}{400}$.\n\nshare|improve this answer\nthank you!! so it sounds like the graph is a triangle from 0 to 2 peaking at 1/2. not sure what the limits of integration are here, sounds like a single integral though. if this can be shown in latex, it would be great for visualizing. sorry it tells me i can't upvote until i get to 15 but i would if i could. \u2013\u00a0 stackuser Nov 11 '12 at 1:36\n@stackuser: There's a very elegant solution to that in this case. If this answer answers your question, you can accept it by checking the little checkmark next to it (see this faq and this one). That gives you $2$ reputation points, exactly what you're missing to be able to upvote :-) \u2013\u00a0 joriki Nov 11 '12 at 8:08\ndone and done. that works! there's so much for a newcomer to learn about the stack-exchange rules. \u2013\u00a0 stackuser Nov 11 '12 at 8:27\nadd comment\n\nHere is a blog post describing something similar to the problem you are attempting to solve. Convolution is the way to go.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/143632/geometric-series-for-fractional-n\nText:\nTake the 2-minute tour \u00d7\n\nI have the following question. Consider the summation\n\n$$ C/(1+r)^i $$\n\nwhich is for i = 1 to n, but n can be FRACTIONAL. Is there a mechanism to do that? Do we proceed like if it was anormal sum?\n\nshare|improve this question\nHow do you even define it? You must give a definition for $$ \\sum_{i=1}^n \\frac{C}{(1+r)^i} $$ for $n \\in \\mathbb Q$ if you want to work with it. In the finite case, the sum is not a construction but just a concise notation. If that is your question, then I'd like to see if you have some motivation for this, if it is not just a wonder you're having. Those kind of things, when useful, are fun to work with. =) \u2013\u00a0 Patrick Da Silva May 10 '12 at 19:34\nOne option would be to take the formula for the sum of the series and extend it to non-integer $n$. \u2013\u00a0 Jim Belk May 10 '12 at 19:34\nHow to do that? That is precisely my question \u2013\u00a0 Bober02 May 10 '12 at 19:35\n@Patrick OK, what you defined is the formula for annuity. it has a solution in the form A/r(1 - 1/(1+r)^n). Could I simply substitute fractional n now? \u2013\u00a0 Bober02 May 10 '12 at 19:38\nAre you asking about your ability to substitute in a fractional $n$? I'm sure you're able to. Whether the result will make any sense cannot be answered without knowing what you're going to use it for. \u2013\u00a0 Henning Makholm May 10 '12 at 19:42\nshow 2 more comments\n\n3 Answers\n\nup vote 3 down vote accepted\n\nYour sum is a geometric sum : $$ \\sum_{i=1}^n \\frac{C}{(1+r)^i} = C \\sum_{i=1}^n \\left( \\frac 1{(1+r)} \\right)^i = C \\frac{(1+r)^{n+1} - 1}{1+r - 1} = C \\frac{(1+r)^{n+1} - 1}r. $$ If you want to substitue fractional $n$ here, you can, the problem is the following ; you have a function that is currently defined over the positive integers (because I believe you said you are in a financial math context, so that you don't want people to give you -2 payments or something weird like that), and you want to extend it over $\\mathbb Q$ (the rationals). There exists wayyy more than one way to do that, and perhaps the easiest way to do it is to plug in the $n$ as a fraction in your formula, but maybe it is not the most natural way : maybe there is a function defined over $\\mathbb Q$ that modelizes your financial context better, but is only equal to your expression above when $n$ is an integer, and is worth something else when $n$ is not an integer.\n\nFormulas are not magical ; it's not because they work that you can play with them and expect them to do everything. The reason why they work is because there is a reason behind it, and you must find a reason behind it before expecting it to work all the time. (You don't need reason to notice that it works very often and then believe that it works all the time, but you need proof to be sure of it.) The whole point of research is to find those remarks/explanations.\n\nA good question for you would be this : could you explain why it would make sense to consider a fractional $n$? Perhaps that with an answer to this question, one could give you a better formula to work with.\n\nHope that helps,\n\nshare|improve this answer\nadd comment\n\nSums by definition cannot have a non-integral number of terms.\n\nHowever, in this case you can find closed form of the sum for integer $n$ using the standard trick for geometric series, and that closed form happens to be defined for fractional $n$. The result is, of course, not a \"sum\" in any principled sense, but it may (or may not) still make some sense to evaluate it, depending on what you're using it for. That depends completely on your application, though.\n\nshare|improve this answer\nadd comment\n\nSee How to add a non-integer number of terms, and how to produce unusual infinite summations Markus Mu\u0308llera, Dierk Schleicherb Journal of Computational and Applied Mathematics 178 (2005) 347 \u2013 360\n\nshare|improve this answer\nI was about to link to this article myself... \u2013\u00a0 \uff2a. \uff2d. May 11 '12 at 15:11\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141792/how-do-you-prove-that-1-is-the-supremum-of-the-set-a-fracmn-m-n-in-m\nText:\nTake the 2-minute tour \u00d7\n\nit might be a simple question.\n\nI need to prove that $1$ is the supremum of the following set: $$A=\\left\\{\\frac{m}{n}\\mathrel{}\\middle|\\mathrel{} m<n\\wedge m,n\\in \\mathbb{N}\\right\\}$$ So, actually I need to prove 2 things:\n\n  1. $\\forall x\\in A .x\\le 1$\n  2. $\\forall \\varepsilon>0 \\ \\exists x\\in A .x>1-\\varepsilon$\n\nSo, the the first requirement is easy to prove, from the defeinition of $A$. but the second is not so simple for me. I've tried to show that this $x$ exists, but I can't show how it looks like.. I guess I should express it with $\\varepsilon$, but I have no success so far.\n\nIf there are other ways to prove it, it'll fine too, and I'll be happy to hear about them.\n\n\nshare|improve this question\nCan you find an integer $N$ with $N>\\frac 1 {\\epsilon}$? (The Axiom of Archimedes, if you have encountered it) \u2013\u00a0 Mark Bennet May 6 '12 at 15:24\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHint: ${n\\over n+1} =1-{1\\over n+1}$.\n\nshare|improve this answer\nI'm not sure how to use it. I guess I should look at $\\frac{1}{n+1}$ as $\\varepsilon$, but still I don't understand how to build $x$ from it :( \u2013\u00a0 RB14 May 6 '12 at 15:41\n@RB14 Given $\\epsilon>0$, select $n$ such that ${1\\over n+1}<\\epsilon$ (why can you do this?). Then show that $1-{1\\over{n+1}} >1-\\epsilon$. \u2013\u00a0 David Mitra May 6 '12 at 15:45\nyeah, apprently I'm a bit idiot :) \u2013\u00a0 RB14 May 6 '12 at 15:48\n@RB14 Not at all; this stuff is hard unless you've been doing it for 15+ years... \u2013\u00a0 David Mitra May 6 '12 at 15:49\nthere supposed to be a continuation to that comment, but I accidently pressed enter, and my chrome browser did not allow me to delete that comment. any way, I get it now, I should select $x$ to be $\\frac{n}{n+1}$ where $n > \\frac{1}{\\epsilon}$. that is possible from the reason Mark mentioned in his comment - the axiom of archimedes. thanks guys! \u2013\u00a0 RB14 May 6 '12 at 15:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/3913/the-right-weigh-to-do-integrals\nText:\nTake the 2-minute tour \u00d7\n\nBack in the day, before approximation methods like splines became vogue in my line of work, one way of computing the area under an empirically drawn curve was to painstakingly sketch it on a piece of graphing paper (usually with the assistance of a French curve) along with the axes, painstakingly cut along the curve, weigh the cut pieces, cut out a square equivalent to one square unit of the graphing paper, weigh that one as well, and reckon the area from the information now available.\n\nOne time, when we were faced with determining the area of a curve that crossed the horizontal axis thrice, I did the careful cutting of the paper, and made sure to separate the pieces above the horizontal axis from the pieces below the horizontal axis. Then, my boss suddenly scooped up all the pieces and weighed them all.\n\nI argued that the grouped pieces should have been weighed separately, and then subtract the weights of the \"below\" group from the \"above\" group, while my boss argued that we were calculating the total area, and thus, not separating the pieces was justifiable.\n\nWhich one of us was correct?\n\nshare|improve this question\n@J. M.: I guess you, in the end, did it like according to your boss? \u2013\u00a0 AD. Sep 3 '10 at 3:48\nWell, I was young and stupid back then, so I let the boss do it his way (I couldn't help but feel I was right, but hey, he's the boss). Now I am no longer so young, but as to whether the other condition still applies is apparently still a matter of contention amongst my peers. \u2013\u00a0 \uff2a. \uff2d. Sep 3 '10 at 5:44\n*sigh* If there were only a way to accept two answers... \u2013\u00a0 \uff2a. \uff2d. Sep 3 '10 at 9:58\nI had to upvote just because of the title :) \u2013\u00a0 anon Sep 3 '10 at 17:18\nThis is really cool! \u2013\u00a0 bobobobo Nov 8 '10 at 1:14\nadd comment\n\n3 Answers\n\nup vote 8 down vote accepted\n\nyou are correct. Actually, the integral is equal to: \"(total above weight) minus (total below weight)\", which I'm sure is what you meant. What your boss is calculating is actually $$ \\int_a^b |f(x)| dx $$\n\nshare|improve this answer\nadd comment\n\nIn my opinion, this is not really a math question. Which procedure is correct depends what you're going to do with your calculation.\n\nAs a matter of definition, the integral indeed measures the signed area (positive area minus negative area), as you suggest. So your approach is computing an approximation to the definite integral $\\int_a^b f$.\n\nBut maybe you want the total (unsigned) area. E.g. if you're going to lay concrete along (some real-world space corresponding to) the region bounded by the curve and the x-axis then surely you want the total area -- there's no such thing as negative concrete.\n\nWithout knowing what you're using the calculation for, it's impossible to say. (Essentially, you're asking us: \"Which of these is mathematically correct: $A-B+C$ or $A+B+C$?\" Of course it depends upon what you're trying to do.) I would like to think that your boss knew what the point of it all was, so without further information I guess I would trust him.\n\nIn fact, your story arouses my curiosity. I suppose you're not putting us on, but weighing paper cutouts is just about the last method I would ever think of for computing area (aren't you going to need a very sensitive scale or an awfully big piece of paper to get anywhere with this?). How long ago are we talking? What was the job? You don't have to answer these questions, but it would be interesting to know...\n\nshare|improve this answer\nMy curiosity is also roused. As soon as I read this question, I started wondering about the points posed in Pete's last paragraph. \u2013\u00a0 Derek Jennings Sep 3 '10 at 9:25\nI wouldn't even dream of putting anyone on on a mathematics Q&A site, Pete. :) As I recall, it had something to do with the integral of the set of empirically-defined measurements, since they're correlated with a certain quantity we were trying to determine from our data. Without a plausible functional form, and none of us knowing about things like splines back then (hey, I only barely learned calculus in school!), it was what was written in the \"manual\". We had, however, an exquisitely sensitive Sartorius analytical balance, which was meant for weighing very light objects. \u2013\u00a0 \uff2a. \uff2d. Sep 3 '10 at 9:43\nApparently it's been done for a long time, too: mathworld.wolfram.com/Cycloid.html says Galileo found areas under the curve by a similar technique, only that he used metal instead of paper. If you look at various engineering handbooks, you'll see this estimation method mentioned, too. I will be the first to admit that it's very crude, and very much dependent on the skill of the operator in drawing and cutting. \u2013\u00a0 \uff2a. \uff2d. Sep 3 '10 at 9:48\n@J.M.: very interesting. As a lifetime academic my ideas about how things might be done in the real world are rather...theoretical. \u2013\u00a0 Pete L. Clark Dec 3 '10 at 5:55\nadd comment\n\nI guess we speak of the area \"under a curve\" when the piece of curve is above the $x$ axis. Sign does matter in the definition of the proper integral, so I would say you were right, and your boss was wrong. Doing integrals by \"weighing\" things should allow for negative weights.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/42685/pro-discrete-locally-compact-and-open-normal-subgroups-have-trivial-intersecti?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nEDIT: After talking to some experts on the subject, I have concluded that a) the answer is not obvious or well-known for locally compact groups in general, b) the answer should be 'no' and I have some idea how to construct examples, but would rather try to write them up properly somewhere. Perhaps this question should be closed? Thanks for the help anyway.\n\nThis is a fairly basic question, but I can't seem to find a clear answer.\n\nLet $G$ be a locally compact group. Suppose that the open normal subgroups of $G$ have trivial intersection. Does it follow that every open subgroup of $G$ contains an open normal subgroup of $G$?\n\nIf so, can the locally compact condition here be weakened?\n\nEdit: some steps towards an answer:\n\n  \u2022 The open subgroups of $G$ have trivial intersection, so $G$ is totally disconnected.\n\n  \u2022 Any compact group satisfying the conditions is profinite and in particular pro-discrete. (Profinite = compact totally disconnected.)\n\n  \u2022 A locally compact totally disconnected group has an open compact (indeed profinite) subgroup by van Dantzig's theorem; this compact subgroup is either finite (in which case $G$ is discrete) or uncountable. So any non-discrete example would need to be uncountable.\n\n  \u2022 To show every open subgroup of $G$ contains an open normal subgroup, I think it would suffice to show there is an open compact normal subgroup $K$ say. For then, given $H$ open, then $H$ contains a finite index subgroup of $K$, and so by intersecting $K$ with finitely many suitably chosen open normal subgroups we can obtain an open normal subgroup contained in $H$.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nLet $K$ be an infinite profinite group and let $K_n < K$ be a decreasing family of open subgroups with trivial intersection. Thus, $K$ acts continuously on the discrete space $X = \\sqcup_n K/K_n$ and this in turn gives rise to a continuous action of $K$ on the free abelian group $\\mathbb Z[X]$. Define $G$ to be the semidirect product $G = K \\ltimes \\mathbb Z[X]$.\n\n$G$ is a locally compact group and if we denote $X_n = \\sqcup_{m \\geq n} K/K_m \\subset X$ then since $K_n$ acts trivially on $X \\setminus X_n$ we have that $K_n \\ltimes \\mathbb Z[X_n]$ is a family of open normal subgroups with trivial intersection in $G$. Also, $K < G$ is an open subgroup but contains no nontrivial normal subgroups since the action of $K$ on $X$ is faithful.\n\nshare|improve this answer\nadd comment\n\nTake a residually finite group $G$ and a subgroup $H$ such that no finite number of conjugates of $H$ intersect trivially, but all conjugates have trivial intersection. Now declare that subgroup and all finite index subgroups of $G$ open. $G$ becomes a locally compact non-discrete group and $H$ is open and does not contain normal non-trivial subgroups.\n\nshare|improve this answer\nYou have to be careful here - when you generate the topology this way, you have to make sure that the induced topology is not discrete, because then the trivial subgroup is an open subgroup. \u2013\u00a0 Ian Agol Oct 19 '10 at 2:42\nI assume that this is the purpose of the condition that no finite number of conjugates of $H$ have trivial intersection. But I do not know if it is enough. \u2013\u00a0 Mark Sapir Oct 19 '10 at 2:54\nDoesn't $\\text{BS}(1,7)$, the semidirect product of $\\mathbb{Z}[\\frac{1}{7}]$ with $\\mathbb{Z}=\\langle t\\rangle$ by $t\\frac{p}{7^k}t^{-1}=\\frac{7p}{7^k}$, provide an example, taking $H=\\mathbb{Z}<\\mathbb{Z}[\\frac{1}{7}]$? \u2013\u00a0 Tom Church Oct 19 '10 at 4:54\n@Tom Church: what topology are you putting on this group? \u2013\u00a0 Kevin Buzzard Oct 19 '10 at 6:59\n@Tom Church, unknown: a countable group is totally disconnected locally compact if and only if it is discrete, so I don't think there are any interesting countable examples for this problem. \u2013\u00a0 Colin Reid Oct 19 '10 at 10:41\nshow 5 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/86250/finding-all-functions-f-satisfying-ft-ft-int-abftdt/86254\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to find all functions f satisfying $f'(t)=f(t)+\\int_a^bf(t)dt$.\n\nThis is a problem from Spivak's Calculus and it is the chapter about Logarithms and Exponential functions. I gave up and read the solution (which I quickly regretted, but at the same time realized that I had not carefully read one very important theorem* in the text) to find that it begins with:\n\nWe know $f''(t)=f'(t)$.\n\nHow do we know this? Also, in general, how would you have approached this problem? Any solution with your thoughts written out would be very appreciated. I am not interested in the solution, but the thought process behind this.\n\n*For the curious, the theorem was that:\n\nIf $f$ is differentiable and $f'(x)=f(x)$ for all $x$ then there is a number $c$ s.t. $f(x)=ce^x$ for all $x$.\n\nshare|improve this question\nUnfortunately, $t$ is used in two different roles here: an ordinary variable and a \"dummy variable\" in the integral. It would be better practice, and less confusing, to use a different letter for the dummy variable, e.g. $f'(t) = f(t) + \\int_a^b f(s)\\ ds$. That makes it more obvious that this term is constant. \u2013\u00a0 Robert Israel Nov 28 '11 at 8:10\nSri, thanks for the edit. I could barely read the question before you intervened :) \u2013\u00a0 The Chaz 2.0 Dec 7 '11 at 0:07\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n  1. How do we know that $f''(x) = f'(x)$? Differentiate both sides of $$f'(x) = f(x) + \\int_a^b f(t)\\,dt.$$ Remember: $\\int_a^bf(t)\\,dt$ is a number (the net signed area between the graph of $y=f(x)$, the $x$-axis, and the lines $x=a$ and $x=b$). So what is its derivative?\n\n    Why would you do this? Because that integral is somewhat annoying: if you just had $f'(x) = f(x)$, then you would be able to solve the differential equation simply enough (e.g., with the theorem you have). But since all that is standing in our way is a constant that is adding, differentiating should spring to mind: that will get rid of the constant, and just \"shift\" the problem \"one derivative down\" (to a relation between $f''(x)$ and $f'(x)$).\n\n  2. Once you know that $f''(x) = f'(x)$, let $g(x) = f'(x)$. Then we have $g'(x)=g(x)$, so the theorem applies to $g(x)$ (exactly what we were hoping for). And you go from there.\n\nAdded. As both Didier Piau and Robert Israel point out, it's probably definitely bad practice to use the same letter as both an actual variable and the variable of integration (sometimes called the 'dummy variable'). Though I see from looking at my copy of Spivak that this originated in the text and not with you.\n\nshare|improve this answer\nSorry but why one would reproduce OP's (mal)practice of using the same unknown in and out of the integral baffles me. Before saying everything else, I would try to explicitly discourage it. \u2013\u00a0 Did Nov 28 '11 at 8:26\n@DidierPiau: A fair point; though Spivak does exactly that, so it's not the OP's practice. Problem 26 in Chapter 17 reads: \"Find all functions $f(t)$ that satify $f'(t) = f(t) + \\int_0^1 f(t)\\,dt$.\" (At least in my Second Edition in Spanish) \u2013\u00a0 Arturo Magidin Nov 28 '11 at 14:13\nYes. But if your edition is faithful to the original in English, you can check that Problem 26 is the one and only (unfortunate) occurrence. Everywhere else, Spivak is correct. Anyway, to me all this has little to do with what we write here and how we choose to write it (and I do not understand the probably in your Addendum). \u2013\u00a0 Did Nov 28 '11 at 18:08\nadd comment\n\nSince $\\int_a^bf(t)dt$ is a constant, we denote it as $C$\uff0c so we get $f'(t)=f(t)+C$. It is $\\frac{df(t)}{dt}=f(t)+C$, i.e. $\\frac{df(t)}{f(t)+C}=dt$. Integrate it, we get $ln(f(t)+C)=t+D$, where D is a constant. Thus, $f(t)=e^{t+D}-C$. Let $e^D=K$, we get $f(t)=K{e^{t}}-C$.\n\nNow plug it into the original eqution, we get $Ke^t=Ke^t-C+\\int_a^b{(Ke^t-C)}dt$. After some manipulation, we have $K=\\frac{b-a+1}{e^b-e^a}C$. Note here we assume that $b \\neq a$.\n\nIf $b=a$,$C$ is obviously $0$, so the equations can be simplified to $f'(t)=f(t)$. In this case, $f(t)=ke^t$, where k is an arbitrary constant and $k \\neq 0$\n\nshare|improve this answer\n@DidierPiau, of course, It my mistake. \u2013\u00a0 Emmad Kareem Nov 28 '11 at 9:14\n+1, clear answer. \u2013\u00a0 Emmad Kareem Nov 28 '11 at 13:03\nadd comment\n\nYou know that $f''(t)=f'(t)$ because you can differentiate the equation you are trying to solve.\n\nSince the second term in the right hand side of the equation you are trying to solve is annoying, it is a good idea to try to get rid of it. Since it is constant, then that can be done by differentiating the equality with respect to $t$.\n\nshare|improve this answer\nadd comment\n\nYes it's a solved problem. Here's a synopsis that may be a little easier to follow. Start with the equation $$ f^\\prime(t) = f(t) + \\int_a^bf(t)dt, $$ for $a<b$ and note that the integral on the RHS is $(b-a)$ times the average value of $f$ on $[a,b]$; call this term M, which is constant for a given $f$. Any solution of $f^\\prime(t)=f(t)+M$ is differentiable, so the RHS is differentiable, implying that $f^{\\prime\\prime}=f^\\prime$ (and, by recursion, that $f$ is actually infinitely differentiable). This has solution $f^\\prime(t)=ce^t$ by a standard argument (the additive constant must be zero) so that $f(t)=ce^t+d$. But then $$ M=\\int_a^bf(t)dt=\\left[ce^t+dt\\right]_a^b=c(e^b-e^a)+d(b-a), $$ giving us a constraint on the constants $c$ and $d$: $$ ce^t=f^\\prime(t)=f(t)+M=ce^t+d+M \\quad\\implies\\quad M=-d \\quad\\implies $$ $$ 0=M+d=c(e^b-e^a)+d(b-a+1)\\quad\\implies\\quad d=-c\\frac{e^b-e^a}{1+b-a} $$ so that the general solution is $$ f(t)=c\\left[e^t-\\frac{e^b-e^a}{1+b-a}\\right]. $$ Finally, the \"standard argument\" referred to above is that if $u^\\prime=u$ for some function $u(t)$, then $$ \\frac{du}{u}=dt \\quad\\implies\\quad \\ln|u|=t+c_1 \\quad\\implies\\quad |u|=e^{t+c_1} \\quad\\implies\\quad u=ce^t $$ where $c=\\pm e^{c_1}$ can be any nonzero constant but in fact also zero (which couldn't be inferred from the derivation because we divided by $u$ along the way, so we recover the solution at the end by inspection).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/53344/sections-of-grassmannian-bundles\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a smooth projective variety of dimension $n$. Take the bundle $TX \\oplus Sym^2(TX)$ over $X$ where $Sym^2(TX)$ is the second symmetric product of the tangent space. The Grassmannian bundle $Gr(n,TX \\oplus Sym^2(TX))$ has a canonical section, namely $TX$.\n\nMy question is: what is the Poincare dual of this section in the cohomology ring of the Grassmannian bundle?\n\nThe cohomology ring is\n\n$H^*(Gr(n,TX \\oplus Sym^2(TX)))=H(X)[c_1,\\ldots, c_n,d_1,\\ldots, d_{{n+1 \\choose 2}}]/$\n\n$(1+c_1+\\ldots +c_n)(1+d_1+\\ldots +d_{{n+1 \\choose 2}})=c(TX \\oplus Sym^2(TX))$\n\nThis is probably a trivial question I am a bit confused about it now.\n\nshare|improve this question\nHi Gergely! This should be not extremely difficult but for sure not completely trivial... I'll think about it later, if no one answers you meanwhile! All the best! \u2013\u00a0 diverietti Jan 26 '11 at 11:57\nMy guess: it is the top Chern class of $Hom(TX,Sym^2(TX))$, that is $\\prod(\\beta_i-\\alpha_j)$ where $\\beta_i$s and $\\alpha_j$s are the Chern roots of the $d$`s and $c$'s respectively, i.e $\\prod(1+\\beta_i)=1+d_1+\\ldots$ \u2013\u00a0 Gergely Berczi Jan 26 '11 at 12:18\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $U$ denote the tautological subbundle. I guess that $c_i = c_i(U^*)$ in your notation. Consider the composition map $$ U \\to p^*(TX + S^2TX) \\to p^*S^2TX, $$ where $p:Gr \\to X$ is the projection. Then your section is the zero locus of this map. In other words, it is the zero locus of a global section of the vector bundle $U^*\\otimes p^* S^2TX$. The section is regular, so the class of the zero locus equals the top Chern class of the bundle. Thus the answer is $$ c_{n^2(n+1)/2}(U^*\\otimes p^*S^2TX). $$ The rest is a straightforward computation.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/7907/how-to-find-all-integer-points-on-an-elliptic-curve/8119\nText:\nTake the 2-minute tour \u00d7\n\nHow can I determine the integer points of a given elliptic curve if I know its rank and its torsion group?\n\nI read same basic books on elliptic curves but as a non-professional I didn't understand everything. Is it true that if rank is 0 and torsion group is isomorphic to a group of order $n$ then the number of integer points is $n-1$? And what is a good reference to learn to determine the integer points if the rank is positive?\n\nI tried to read the book Rational Points on Elliptic Curves but I didn't found an explicit algorithm. I just heard something like take some point and use group law to find the rest. But how can I be sure that I have found every point?\n\nThe curve I had on my mind is $2x^3 + 385x^2 + 256x - 58195 = 3y^2$. I'm not even sure if this is an elliptic curve. I mean why it is projective and why it is isomorphic to a closed subvariety of $\\mathbb{P}_{\\mathbb{Q}}^2$? And why it contain the priviledged rational point $(0,1,0)$?\n\nshare|improve this question\nYour question about curves of rank 0 has positive answer, more or less by definition. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Dec 5 '09 at 22:12\nThanks! I have one curve which is of rank 4 and torsion subgroup isomorphic to trivial abelian group so I would like to know some method to prove the solutions I found are the only one. \u2013\u00a0 amateur algebraist Dec 5 '09 at 22:26\nIn general, you should indicate clearly what is the \"main\" part of your question. \u2013\u00a0 Andrew Critch Dec 6 '09 at 0:32\nIt is a non a trivial fact that the torsion points on an elliptic curve in Weierstrass form have integer coordinates. If the curve is not in the Weierstrass form, it can have rational torsion points that are not integral. I suggest reading Washington's \"Elliptic Curves: Number Theory and Cryptography\". It is very detailed and well written. \u2013\u00a0 Dror Speiser Dec 7 '09 at 17:43\nEssentially the same question was asked earlier on this site: mathoverflow.net/questions/6676/\u2026 \u2013\u00a0 Bjorn Poonen Jan 7 '10 at 17:06\nadd comment\n\n4 Answers\n\nup vote 7 down vote accepted\n\nFinding all the integral points on an elliptic curve is a non-trivial computational problem. You say you are a \"non-professional\" so here is a non-professional answer: get hold of some mathematical software that does it for you (e.g. MAGMA), and then let it run until it either finds the answer or runs out of memory. Alternatively, do what perhaps you should have done at the start if you just have one curve and want to know the answer: post the equation of the curve, and hope that someone else does it for you. Here's another example of an algorithm currently used in these sorts of software (a Thue one was mentioned above but here's a different approach): find generators for the group (already computationally a bit expensive at times, depending on your luck and/or the size of sha), invoke Baker-like theorems saying \"if the coordinates of the point are integral then it must be of the form sum_i n_i P_i with the n_i at most ten to the billion\", and then use clever congruence techniques to massively cut down the search space by giving strong congruences for all the n_i. Then just do a brute force search.\n\nWhether or not this will work for you, I cannot say, because it all depends on how big the coordinates of your curve are. The only clue you give so far is that the conductor is \"bigger than 130000\" [Edit: that was written before the OP edited the question to tell us which curve he was interested in] which of course does not preclude it being bigger than 10^10^10. Also, you need an expert to decide which of the algorithms is best for you. I'd rather do a massive amount of arithmetic in a field of tiny discriminant than a small amount of arithmetic in a field whose discriminant is so large that I can't even factor it, for example.\n\nSo in short the answer is that you're probably not going to be able to do it with pencil and paper, but there are programs around that will do it, if all you want to know is the answer.\n\nEDIT: you posted the equation of the curve. Magma V2.15-10 says the integral points are\n\n[ <-23, -196>, <19, 182>, <61, 784>, <-191, 28>, <103, -1442>, <-19, -144>, <-67, 592>, <23, 242>, <-49, -454>, <-157, -742>, <817, 21196>, <521, 11364>, <3857, 200404>, <10687, -910154>, <276251, -118593646> ]\n\nplus what you get if you change all the y's to -y's.\n\nshare|improve this answer\nOkay. But how can I prove those are the only one? Am I right that the priviledged rational point is not an integer point? \u2013\u00a0 amateur algebraist Dec 6 '09 at 15:32\nMy computer says it has proved those are the only ones. Whether or not you want to believe (a) my computer and (b) the program I used is up to you. If you want to try your own computer and another program (e.g. SAGE, which would also do the job) then feel free. If you want to prove it by hand then I would first buy a lot of pieces of paper, because what takes my computer 30 seconds will take a lot longer to do by hand. As for the \"priviledged rational point\", you can choose whether or not it's an integer point. That's not a maths question, it's a convention question. \u2013\u00a0 Kevin Buzzard Dec 6 '09 at 16:28\nadd comment\n\nThe following Sage code (which I ran with Sage 4.2.1) produces the solutions (and agrees with Magma!):\n\nE = EllipticCurve([0, 1155,0,4608,-6285060])  \nE1 = E.minimal_model()\npts1 = E1.S_integral_points([2,3])\niso = E1.isomorphism_to(E)\npts = [iso(P) for P in pts1]\nsolutions = [(x/6,y/18) for (x,y,z) in pts]\nsolutions = [(x,y) for (x,y) in solutions if x.is_integral() and y.is_integral()]\n\nBefore the first line I used pencil-and-paper to scale the equation to be in Weierstrass form (monic in both X and Y) which involves new variables 6X and 18Y; the solutions a rescaled at the end. In fact we found all S-integral solutions with S={2,3}, i.e. all solutions which are integral except at 2 and 3. (There are 32 of these, of which only 15 are really integral).\n\nJohn Cremona\n\nshare|improve this answer\nadd comment\n\nNo point reinventing the wheel. Use Cremona's table seven on\n\n\nshare|improve this answer\nUnfortunately the curve I had on my mind has larger conductor than 130000 \u2013\u00a0 amateur algebraist Dec 5 '09 at 23:57\nadd comment\n\nThis is handled (with explicit examples) in Nigel Smart's \"The algorithmic resolution of diophantine equations.\" Chapter VII.4, in particular, gives a method for producing finitely many Thue equations whose integer solutions contain the integer solutions to the given elliptic equation.\n\nComputationally, the bottleneck is finding a system of fundamental units for the splitting field.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?t=681376\nText:\nCauchy-Goursat's theorem and singularities\n\nby Verdict\nTags: cauchygoursat, singularities, theorem\nVerdict is offline\nMar27-13, 07:36 PM\nP: 113\nCalculate the closed path integral of [tex]\\frac{z+2 i}{z^3+4 z}[/tex] over a square with vertices (-1-i), (1,i)\nand so forth.\n\n2. Relevant equations\nThe closed line integral over an analytic function is 0\n\n3. The attempt at a solution\nAlright, so first I factored some stuff, leaving me with\n[tex]\\frac{1}{z (z-2 i)}[/tex]\n\nNow, this has a simple pole at 0 and at 2i. However, 2i isn't in the square, so I'm only concerned about the one at 0. Now, I don't know how to continue from here on, formally. I know (do I?) that the answer has to be i*2pi, as that always happens to be the case when doing a closed integral of a function that has 1 singularity (and it is enclosed by the path). But how do I 'calculate' this? I tried writing z = x+iy and the same for dz, and then working it all out and parameterizing the vertices, but that gives horrible expressions to integrate and just doesn't seem right.\n\nIs there something I'm missing?\n\nAlso, there is a follow up question, which concerns the same integral but now over the square with vertices (-1-3i), (1+3i) and so forth. So this encloses both singularities, but they aren't symmetric or anything, so then I can't really go any further. (Is it even true, that when the singularities are distributed symmetrically, that they sort of cancel each others effect and your integral evaluates as 0?)\n\nKind regards\nPhys.Org News Partner Science news on\nNASA data shed new light on changing Greenland ice\nMandelbroth is offline\nMar28-13, 02:36 PM\nMandelbroth's Avatar\nP: 583\nCauchy-Goursat only gets you so far. You have two options:\n\n1. Evaluate it using the typical method of line integrals.\n2. Use the more general theorem.\n\nNot all contour integrals around singularities yield ##2\\pi i##. They do, however, follow the relation $$\\oint_{\\beta}f(z) \\ dz = 2\\pi i \\sum \\mathfrak{R}_{z_i}(f(z))$$\nif ##\\beta## is a Jordan curve, where ##\\mathfrak{R}_{z_i}## denotes the residue of the function at a point ##z=z_i## interior to ##\\beta##.\n\nIf you are unfamiliar with residues, I would suggest using the typical line integral method.\n\nEdit: Didn't see the bottom of your post.\nI see where you would get the idea that they might \"cancel each other out.\" However, it is entirely wrong. Once you get a little further into complex analysis, you'll probably have a kind of epiphany moment where you'll start thinking \"Hey! None of this makes any logical real sense in terms of what I learned from basic calculus. Better start thinking about it differently!\" At that point, everything starts making sense because you'll notice that, in terms of complex numbers, it really doesn't matter what the contour is or where the poles are. As long as the contour contains the same poles and has the same winding number, you get the same answer.\nVerdict is offline\nMar28-13, 02:46 PM\nP: 113\nThank you for your answer!\nI've discussed my issue with the teacher today, and apparently he accidentally gave out exercises that were meant for later in the course. This was only one of them, and I've spent hours thinking about this one and the others, so that is a little frustrating.\n\nEither way, it is still very good to see that what I thought might have been the case is not true at all. I wasn't sure that it was, it just seemed to be so every single time. But its good to know that it is simply not the case. I look forward to getting further into the material though, I really enjoy how elegant everything is in the complex numbers.\n\nRegister to reply\n\nRelated Discussions\nThe Cauchy-Goursat Theorem Topology and Analysis 1\nKln theorem and initial-state singularities High Energy, Nuclear, Particle Physics 0\nContour integral with multiple singularities inside domain without residue theorem?? Calculus & Beyond Homework 14\ngreens theorem and cauchy theorem help Calculus & Beyond Homework 4\nCauchy horizon singularities General Astronomy 2"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/9914/finding-the-height-of-a-d-ary-heap\nText:\nTake the 2-minute tour \u00d7\n\nI would like to find the height of a d-ary heap. Assuming you have an Array that starts indexing at $1$ we have the following:\n\nThe parent of a node $i$ is given by: $\\left\\lfloor\\frac{i+1}{d}\\right\\rfloor$\n\nThe $d$ children of a parent at node $i$ are given by: $di-d+1, di-d+2,\\ldots di+1$\n\nThe height of a heap (which is slightly different than the height of a binary search tree) is a longest path from the root to a leaf. A longest path will always be from the last node in the heap to the root, but how do I calculate this longest path?\n\nMy first Idea is to setup a recurrence relation for the height of the tree:\n\n\\begin{equation} h(1) = 0\\\\ h(i) = h\\left(\\left\\lfloor\\frac{i+1}{d}\\right\\rfloor\\right)+1 \\end{equation}\n\nThis seems overly-complicated and I feel like the answer is much more simple. Is there a better way to find the height of a $d-$ary heap?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nA path from the last node to the leaf would always be a longest path. This is because the last node is always at the lowest level in the heap. Now, assume the root is at level $0$. Then the number of nodes at a completely filled level $i$ would be $d^i$.\n\nLet level $k$ be the last completely filled level in the heap. So the number of nodes upto (and including) level $k$ is: $$\\sum\\limits_{i = 0}^{k}d^i = \\frac{d^{k+1} - 1}{d - 1}$$\n\nNow, the last node - the $n^{th}$ node - can either be the last node at level $k$, or it can be in an incomplete level $k+1$. Taking care of these two cases, it can be seen that: $$\\frac{d^{k+1} - 1}{d - 1} \\le n < \\frac{d^{k+2} - 1}{d - 1}$$ $$\\Rightarrow k\\le \\log_d(n(d-1) + 1) - 1 < k+1$$\n\nNow, equality is only if the last node is the last leaf of level $k$, which also has distance $k$ from the root. If not, that is if there is a level $k+1$, then the $\\log$ term would not be an integer, and applying the ceiling operator would give the right height of $k+1$. Thus, if the last element of the array is at position $n$, the height of the heap is: $$h = \\lceil \\log_d(nd - n + 1) \\rceil - 1$$ You can change the base of the logarithm using the change of base formula. Note that this is the same method that Yuval gives in his answer.\n\nshare|improve this answer\nadd comment\n\nA different approach is to calculate the number of points $n_d(h)$ in a saturated (maximal) $d$-ary heap of height $h$. Given $n_d(h)$, the height of a $d$-ary heap of size $n$ is the minimal $h$ such that $n_d(h) \\geq n$. Given the formula for $n_d(h)$, you should be able to find $h$ explicitly.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/481370/concepts-of-modern-mathematics-ian-stewart-751-7-1072/481373\nText:\nTake the 2-minute tour \u00d7\n\nConcepts of Modern Mathematics by Ian Stewart (1995).\n\nIn Chapter 3 Ian Stewart talks about Short Cuts in the Higher Arithmetics, one section is on modular arithmetics.\n\nWhen talking about the days of the week;\n$0= \\text{Sunday}\\\\ 1= \\text{Monday}\\\\ 2= \\text{Tuesday}\\\\ 3= \\text{Wednesday}\\\\ 4= \\text{Thursday}\\\\ 5= \\text{Friday}\\\\ 6= \\text{Saturday}\\\\ 7= \\text{Sunday}\\\\ \\vdots\\\\ 7n= \\text{Sunday}\\\\ 7n+1= \\text{Monday}\\\\ 7n+2= \\text{Tuesday}\\\\ 7n+3= \\text{Wednesday}\\\\ 7n+4= \\text{Thursday}\\\\ 7n+5= \\text{Friday}\\\\ 7n+6= \\text{Saturday}\\\\ 7n+7= 7(n+1) = 7n = \\text{Sunday}$\n\nIn a simple statement $4+5=2 \\dfrac bc$ the cycle (day $9$ is the same as day $2$).\n\nIn a later statement,\n\n\"What is $751$ days after Thursday\" we rephrase it as $4+751 = ?$ We can observe that $751=7.107+2$\n\nThat is where I am getting lost. What is Ian Stewart doing to make this a true statement? I've attached the three pages on this topic, the statement in question is towards to bottom of page 3.\n\nThank you!!!\n\n1 2 3\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 11 down vote accepted\n\nThat is a typo in the book. It should say:\n\nNow 751 isn't in our table, but we observe that $$751 = 7\\cdot107+2$$ etc.\n\nRather than a decimal point, that should be a multiplication symbol.\n\nEDIT: After some Google-ing, I've found that some cultures use \"$.$\" for multiplication and \"$\\cdot$\" for the decimal point. Thus, the expression could also be written: $$751 = 7\\times 107+2 \\quad \\text{or}\\quad 751 = (7)(107)+2$$\n\nshare|improve this answer\nIs your \"it should say\" not the same as it says originally? Certainly I can't see a difference at a glance so it might be worth clarifying the difference... Though having typed this is it that the . is slightly higher? Either way +1 for the last line which says all that needs saying. :) \u2013\u00a0 Chris Sep 1 '13 at 16:10\n@Chris Perhaps this is a USA convention compared to other countries, but my understanding is that a vertically centered dot is standard for multiplication, and a dot in line with the bottom of the line represents a decimal point (and not multiplication). \u2013\u00a0 anorton Sep 1 '13 at 16:47\nmy comment was mainly because it took me a while to notice the difference between what you'd written and the original so may be worth spelling it more explicitly. As for canonicity, I'm not sure. When writing stuff down by hand I'd tend to put mulitplication dots at the bottom and decimal points in the middle but not sure if there is a different convention for print (there often is) and I'm in thailand at the moment without any maths books to hand to check what they do. :) I suspect the problem though is that the OP had not seen a dot as a multiplication symbol before in any position. :) \u2013\u00a0 Chris Sep 1 '13 at 16:51\n@Chris Good point. I've added some other forms. :) \u2013\u00a0 anorton Sep 1 '13 at 17:00\nadd comment\n\nHe is saying that since $751=7\\times 107+2$, the day is two days after Thursday which is Saturday. The dot means multiplication here.\n\nshare|improve this answer\nadd comment\n\nNote that $7\\times 107=749$ - so $749$ days represents exactly $107$ weeks, and the $750^{th}$ day falls on the same day of the week as the $1^{st}$ day.\n\n$751$ days after Thursday is $107$ weeks and two days. Thursday is the fourth day of the week, so the answer is the sixth day of the week (two days on).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?p=2003624\nText:\nFinding max/min given contraint\n\nby ultra100\nTags: constraint equation, lagrange, maximum, minimum, multivariable\nultra100 is offline\nDec15-08, 09:13 PM\nP: 9\n\nFind the product of the maximum and minimum values of the function f(x, y) = xy\non the ellipse (x^2)(1/9) + y^2 = 2\n\n3. The attempt at a solution\n\nI tried soving using lagrange multiplier and got:\n\nfx = y - (2/9)(x*lambda)\nfy = x - 2y*lambda\nflambda = (x^2)(1/9) + y^2 - 2\n\nthen I set these = 0, but my answer came out wrong.. any suggestions for figuring out the min/max?\n\n2. Relevant equations\n\n3. The attempt at a solution\nPhys.Org News Partner Science news on\nAt tech fest: 3D printers, bitcoin and 'Titanfall'\nLondon launches hi-tech trial for pedestrian safety\nLignin breakthroughs serve as GPS for plant research\nNoMoreExams is offline\nDec15-08, 09:23 PM\nP: 626\nFor y I'm getting, [tex] y = \\pm 1 [/tex]\n\nThe way I set this up was as follows:\n\n\n[tex] f(x,y) = xy; g(x,y) = \\frac{x^{2}}{9} + y^{2} = 2 \\Rightarrow h(x,y,\\lambda) = f(x,y) + \\lambda g(x,y) [/tex]\n\n(Note that the sign in front of [tex] \\lambda [/tex] does not matter)\n\nSo let's take our partials, we get:\n\n[tex] \\frac{dh}{dx} = y + \\frac{2 \\lambda}{9}x, \\frac{dh}{dy} = x + 2 \\lambda y, \\frac{dh}{d\\lambda} = \\frac{x^2}{9} +y^2 - 2 [/tex]\n\nWe know that each of those partials vanish i.e. we can set each to 0.\n\nThe first one gives us\n\n[tex] 9y = -2 \\lambda x [/tex]\n\nand the second one gives us\n\n[tex] \\frac{x}{y} = -2 \\lambda[/tex]\n\nAnd by simple substitution we get:\n\n[tex] 9y^{2} = x^{2} [/tex]\n\nSo let's substitute it into our 3rd equation to get:\n\n[tex] y^{2} + y^{2} = 2 [/tex]\n\nWhich yields our desired result of [tex] y = \\pm 1 [/tex]. Now we can plug this into our g(x,y) to get [tex] x = \\pm 3 [/tex]\n\nNote that it doesn't matter which value for y we pick therefore our solution set will be:\n\n[tex] (1,3), (1,-3), (-1,3), (-1,-3) [/tex]\n\nNow if you don't want to do this using Lagrange Multipliers, we can just realize that we can rewrite our g(x,y) as\n\n[tex] y = \\pm \\sqrt{2 - \\frac{x^2}{9}} [/tex]\n\nand now we can substitute this into our f(x,y) get an equation of one variable i.e.\n\n[tex] \\bar{f}(x) = \\pm x \\cdot \\sqrt{2 - \\frac{x^2}{9}} [/tex]\n\nNow we can proceed using the techniques you learned in Calculus 1 (I'm going to use Maple because I'm lazy)\n\n> a:=x*sqrt(2-x^2/9);\n\na := [tex] \\frac{1}{3} x \\sqrt{18 - x}[/tex]\n\n> solve(diff(a,x)=0,x);\n\n-3, 3\n\nNote that choosing the negative root produces the same results.\nultra100 is offline\nDec15-08, 09:31 PM\nP: 9\nwhat equations are you using to get y = to +/- 1?\n\nNoMoreExams is offline\nDec15-08, 09:50 PM\nP: 626\n\nFinding max/min given contraint\n\nQuote Quote by ultra100 View Post\nRefresh your page :)\nultra100 is offline\nDec15-08, 09:56 PM\nP: 9\nThanks!!! This helps a lot\n\nRegister to reply\n\nRelated Discussions\nFinding the Method of moments estimator? Having trouble finding E(Y^2) Calculus & Beyond Homework 1\nFinding the pH of TSP Biology, Chemistry & Other Homework 5\nFinding pH Biology, Chemistry & Other Homework 11\nfinding the inverse and finding a matrix * A = 0 matrix Introductory Physics Homework 6\nFinding Yourself General Discussion 34"}
{"text": "Retrieved from http://mathoverflow.net/questions/130088/two-variable-recurrence-equation-with-varying-coefficients\nText:\nTake the 2-minute tour \u00d7\n\n\nI have the following two variable recurrence equation for integers $j,k$:\n\n$f(j,k) = (k/j)f(j-1,k-1) - (3 + k/j)f(j-1,k+2)$\n\nwhere $f(j,0) = (3^j - 1)/j + 3jf(j-1,2)$, $f(0,0) = 0$, $f(0,k) = a_k$.\n\nI would like to express $f(n,0)$ in terms of the different $a_k$ values.\n\nI tried a generating function approach, by considering the generating function $\\phi(x,y) = \\sum_j\\sum_k f(j,k)x^jy^k$, but it gives rise to a nasty differential equation.\n\nAny ideas on how to attack this recurrence equation? Maybe by just calculating it for a few $n$ values, observe a pattern and use induction? The latter is also quite tedious. Is there any neat approach to this?\n\nshare|improve this question\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/237280/smallest-imperfect-graph-whos-chromatic-number-equals-clique-number\nText:\nTake the 2-minute tour \u00d7\n\nSo I need to find the smallest imperfect graph, $G$ who's chromatic number equals it's clique number. ie:\n\n$$\\chi(G) = \\omega(G)$$\n\nFinding imperfect graphs isn't hard (since finding perfect graphs is). Even finding imperfect graphs with this property isn't too hard. But how do we find the smallest graph (I assume minimal # vertices). Even if I have an idea what this graph is, how can I prove it is the smallest? I.e if I think sum graph on $n$ vertices is the smallest graph satisfying this, it seems daunting to show every graph of order $<n$ fails to satisfy this (unless $n$ is relatively small).\n\nMethods to approach and tackle this problem?\n\nshare|improve this question\nWhat is the smallest $n$ you can easily find an example for? \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 16:19\n$C_5$ with an added internal vertex connected to 3 vertices of $C_5$, 2 of which neighbours, 1 of which is not a neighbour to either. so $n=6$ \u2013\u00a0 user45814 Nov 14 '12 at 16:53\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nConsider the cyclic graph with five vertices $a,b,c,d,e$ and add a sixth vertex $f$ with edges $af$, $bf$, $df$. Then $\\omega(G)=\\chi(G)=3$ and the graph is not perfect becaus the induced subgraph obtained by removing $f$ has $\\chi=3$ and $\\omega=2$.\n\nWhy is six minimal? For graphs up to four vertices, $\\chi=\\omega$ always holds, hence every graph with at most five vertices having $\\chi=\\omega$ is perfect.\n\nshare|improve this answer\nOh, I see you found that by yourself in a comment meanwhile. \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 17:05\nYes, but couldn't find a way to show it was minimal. Thanks! \u2013\u00a0 user45814 Nov 14 '12 at 17:13\nIs there an easy way to show for graphs up to four verticies that X=w? I can tell it's true, but not sure if I can just state that (Ill post this as a new question, since it seems it may take some thought) \u2013\u00a0 user45814 Nov 14 '12 at 17:44\nIf $\\omega=n$, then trivially $\\omega=\\chi$. If $\\omega=n-1$, then colour a maximal clique with $\\omega$ colours and the remaining vertex with the colour of one of its non-neighbours. If $\\omega\\le n-2$, then $G$ is either $C_4$ or a tree with $\\chi=2$ or disconnected with $\\chi=1$. \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 17:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/16059/can-a-super-extremal-charged-black-hole-be-made-out-of-electrons-only/16061\nText:\nTake the 2-minute tour \u00d7\n\nIn a previous Question it was argued that it would be impossible to add enough charge to a black hole to make it pass the extremal black hole limit since adding charge would increase the mass of the black hole due to the electrostatic field energy (and thus mass) that would be added as the charge is added.\n\nNote that an electron cannot be a black hole but if an electron were a black hole it would be a super-extremal black hole per this wikipedia article: Basically the Schwarzchild radius for the electron's mass is $r_s = 1.35 \\times 10^{-57} m$ whereas the charge radius of the electron is $r_q = 9.15 \\times 10^{-37} m$. So since $$\\frac{r_q}{r_s} \\approx 10^{21} \\gt 1$$ an electron, if it was a black hole, would be a super-extremal black hole by a large margin. In words, the electrons mass is completely negligible compared to its charge.\n\nAn uncharged black hole can be constructed out of matter at any given mass density by simply constructing a big enough sphere of that matter. This is true because a sphere of radius $R$ with a constant (low?) density will have a mass $M$ that is $\\propto R^3$ whereas the Schwartzchild radius is $\\propto M \\propto R^3$. So as $R$ increases the radius of the sphere will eventual be less than the Schwartzchild radius.\n\nSo, can we make a super-extremal charged black hole by using a very large sphere of radius $R$ that is made out of electrons uniformly distributed with (low) charge density $\\rho$?\n\nshare|improve this question\nI was hoping the answer was yes, but as I did the calculations I convinced myself it would not work, so I am documenting my calculations by asking and answering this question. I hope this might be interesting to other people and I hope you will check my calculations. If my answer is wrong, please correct me! \u2013\u00a0 FrankH Oct 23 '11 at 8:13\nIt should be added that there is no reason to suppose that the relation Q=M for extreme black holes is correct for black holes the size of electrons. Electrons are quantum black holes in string theory--- they are strings--- and the lightest black hole excitation in a charged string theory always is on the other side of the extremality bound. Whether you call it a black hole is a matter of convention, but you can't use classical GR to describe something that small. \u2013\u00a0 Ron Maimon Oct 23 '11 at 17:44\nYes, @ron, you are right. The electron cannot be a black hole for lots of reasons. The electrons Schwartzchild radius is many orders of magnitude smaller than the Planck length so classical GR will not apply. I will edit the question to clarify that. Thanks. Any opinion on my answer would be appreciated. \u2013\u00a0 FrankH Oct 23 '11 at 18:17\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe answer is no. As stated, the electrons mass will be ignored. If we assume the mass of the sphere is just due to the electrostatic field energy of the uniformly charged sphere, can we create a black hole and can the charge to mass ratio $\\frac{Q}{M}$ be super-extremal ($\\frac{Q}{M} \\gt 1$ in appropriate units).\n\nNow the charge of the sphere is $$Q \\propto \\rho R^3$$ the electric field strength $E(r)$ as a function of the radius $r$ is $E(r) \\propto \\rho r$ and the mass $M$ due to the electrostatic field energy is $$M \\propto \\int_0^R E^2(r) d^3r \\propto \\rho^2 R^5 $$ Therefore the ratio of charge to electrostatic field energy-mass is $$\\frac{Q}{M} \\propto \\rho^{-1} R^{-2}$$\n\nConsider the case of constant $\\rho$ with $R$ increasing: Since $M \\propto R^5$ increases rapidly, eventually a black hole will form. However the ratio $\\frac{Q}{M}$ will decrease as $R$ increases, so it will not be an extremal black hole.\n\nNow consider the case of constant $R$ with $\\rho$ increasing: Since $M \\propto \\rho^2$ a black hole will eventually form. but again the ratio $\\frac{Q}{M}$ will decrease as $\\rho$ increases, so it will not be an extremal black hole.\n\nTherefore it is impossible to create a super-extremal black hole from a uniform sphere with a constant charge density since the electrostatic energy-mass alone will create a black hole with a charge to mass ratio less than 1. Any additional neutral mass added into the sphere will result in an even lower charge to mass ratio so that will also not be super-extremal.\n\nshare|improve this answer\n+1: nice answer. \u2013\u00a0 Ron Maimon Oct 23 '11 at 18:35\nDue to the fact that no one has found any mistake in my calculations for the past 2 weeks, I am accepting my own answer so this will not stay as an open question forever... \u2013\u00a0 FrankH Nov 5 '11 at 4:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/54866/algorithm-for-graph-with-nodes-grouped-into-sets\nText:\nI have a weighted graph. The nodes of this graph are grouped into sets, and each node has only one corresponding set (no overlapping). Nodes in the same set do not have edges between them. An edge only connects nodes that are in different sets.\n\nI want to select one node from each set, such that the total weight of the edges between these nodes is minimized. Between two sets, I will only be traversing one edge.\n\nOnly some sets are adjacent to each other, they are not all interconnected. But some sets do have multiple neighbours. When one set is adjacent to another, the nodes in these two sets form a complete bipartite graph.\n\nAre there any algorithms to accomplish this? And is there a name for this type of graph?\n\n  \u2022 $\\begingroup$ When you say \"the toatal edge weight is minimized\", you mean the total weight of the edges between the selected vertices? This doesn't look at all like a minimum spanning tree, to me: the structure you're selecting is neither spanning (it doesn't touch every vertex) nor a tree. $\\endgroup$ \u2013\u00a0David Richerby Mar 24 '16 at 2:28\n  \u2022 $\\begingroup$ Yes, the total weight of the edges between the vertices. I said spanning tree because I want to touch all sets, selecting one node from each. It's not really a spanning tree, that may have been a poor analogy. $\\endgroup$ \u2013\u00a0Vermillion Mar 24 '16 at 2:33\n\nThe special case of zero-one weights is already NP-hard. In fact, even determining whether there is a choice such that the total weight is zero is NP-hard. See this question on cstheory.se. (You can arrange that all the weights are, say, $1$ or $2$, and then the condition that two connected parts are fully connected is satisfied.)\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/123951/find-two-contiguous-subarrays-with-the-greatest-difference\nText:\nHere's an interview question I've seen on a few sites. People claim that an O(n) solution is possible, but I've been racking my brain these last 2 days and I couldn't come up with a solution, nor find one anywhere on the web.\n\nGiven an array of integers, find two disjoint, contiguous subarrays such that the absolute difference between the sum of the items in each subarray is as big as possible.\n\nExample input: (2, -1, -2, 1, -4, 2, 8)\n\nExample output: ((1, 4), (5, 6))\n\nThe output above is the indices of these two subarrays: ((-1, -2, 1, -4,), (2, 8))\n\nI've been trying to reduce this problem to the Maximum subarray problem but with no success.\n\n  \u2022 $\\begingroup$ Hint, two contiguous subarrays means the last element of the first subarray is adjacent to the first element of the second subarray. Did you see a parameter here? $\\endgroup$ \u2013\u00a0John L. Apr 11 at 17:35\n  \u2022 $\\begingroup$ I believe OP did not mean that the two subarrays are adjacent. My guess is that they used the word 'contiguous' to just mean that the two disjoint subarrays are independently contiguous themselves, which I think is redundant given the definition of subarray. But it is still used in many places. eg. \"finding a contiguous subarray with the largest sum\" in en.wikipedia.org/wiki/Maximum_subarray_problem $\\endgroup$ \u2013\u00a0CodeChef Apr 11 at 17:45\n  \u2022 1\n    $\\begingroup$ @CodeChef Unfortunately, the example given in the question can be considered the supposed interpretation of \"contiguous subarray.\", although it does not rule out the possibility to treat is as \"redundant\" as well. Treating it as meaningful and not redundant shows, I believe, the most respect to the almost universal convention that \"subarray means contiguous elements\" and, hence, the the author of the original problem. $\\endgroup$ \u2013\u00a0John L. Apr 11 at 17:53\n  \u2022 1\n    $\\begingroup$ Yes, I agree. My guess was also based on having seen this problem (the variant I assumed it to mean) multiple times in relation to interview questions, but you are absolutely right. $\\endgroup$ \u2013\u00a0CodeChef Apr 11 at 17:57\n\nBecause the two subarrays are disjoint, there exists at least one index $m$ such that one entire subarray lies $\\leq m$ and the other subarray lies $\\gt m$.\n\nBut we do not know what this $m$ is, beforehand. So let us iterate over all the $n$ possibilities for $m$. Now if an $m$ is fixed, then the problem reduces to the Maximum subarray problem, and the Minimum subarray problem. This is because for the absolute difference to be the largest, one side of $m$ should have the maximum possible subarray, and the other side should have the minimum possible subarray. So we try both of these options and take the maximum absolute difference among the two.\n\nBut this is still $\\mathcal{O}(n^2)$, because there are $n$ different values of $m$, and for each of those values, we have to spend $\\mathcal{O}(n)$ time to compute the needed minimum and maximum subarrays.\n\nThe next observation is to note that a single $\\mathcal{O}(n)$ run of the Maximum subarray algorithm on the entire array can actually give us one of the needed values for all values of $m$:\n\nGiven: int A[n]\n\nMaxSubarrayTill[0] = A[0]\nMaxSubarrayEndingAt[0] = A[0]\n    MaxSubarrayEndingAt[i] = max{A[i], MaxSubarrayEndingAt[i - 1] + A[i]}\n    MaxSubarrayTill[i] = max{MaxSubarrayTill[i - 1], MaxSubarrayEndingAt[i]}\n\nHere, $\\text{MaxSubarrayTill}[i]$ denotes the maximum sum subarray which ends $\\le i$, and $\\text{MaxSubarrayEndingAt}[i]$ denotes the maximum sum subarray which ends at index $i$.\n\nSimilarly, we can compute the $\\text{MinSubarrayTill}[i]$ array in $\\mathcal{O}(n)$ time. And by repeating the same two algorithms in reverse (ie. from the end of the array to the beginning), we can get $\\text{MaxSubarrayFrom}[i]$ and $\\text{MinSubarrayFrom}[i]$.\n\nSo in $\\mathcal{O}(n)$ time we have precomputed all the values that we needed in the first algorithm, which we can now go back to. Interate over all the values of $m$, and find the largest absolute difference in $\\mathcal{O}(n)$ time.\n\nIf the problem also stipulates that the two subarrays should be adjacent, then we can leave out $\\text{MaxSubarrayTill}[i]$ and its analogous arrays, and instead only consider $\\text{MaxSubarrayEndingAt}[i]$ and its analogous three other arrays. The rest of the algorthm remains the same.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathlair.allfunandgames.ca/missingdollar.php\nText:\n[Math Lair] The Missing Dollar\n\nMath Lair Home > Puzzles & Problems > The Missing Dollar\n\nThree men decide to spend a night in a hotel room. They pay $30 for the room (assume that this took place a long time ago, when hotel rooms might have actually cost $30). They split the cost evenly amongst themselves, with each man paying $10. As they are about to leave, the manager of the hotel, realizing that the three men are frequent patrons of the hotel, decides to give the men $5 back. He gives $5 to the bellhop and asks him to give the money to the three men. The bellhop, not wanting to split $5 among the three men, decides to pocket $2 of the money and gives each of the three guests $1. Each of the guests has now paid $9 for the room, for a total of $27, and the bellhop has $2, for a total of $29. Where is the missing dollar?\n\nMany people find this problem rather frustrating. The key to it is to look at it in a different way. The three men each paid $30. Out of that, $25 is in the hotel's cash register, $2 is in the bellhop's pocket, and each of the three men have $1, for a total of $30. Looking at it this way, there is no missing dollar. So why is there a dollar missing in the analysis above?\n\nThe problem contains a trick. Each of the guests paid $9, for a total of $27. That $27 includes the $2 in the bellhop's pocket. You can't add that $2 to the $27 and expect to get a meaningful result, but that's what the problem does. The sum in the problem is a red herring that doesn't correspond to any real-life amount."}
{"text": "Retrieved from https://math.stackexchange.com/questions/1424818/flip-2-coins-how-to-show-that-each-point-in-sample-space-has-equal-probability\nText:\nYou flip a fair coin twice resulting in the sample space {HH, HT, TH, TT}. How can we show that each point in the sample space has probability 1/4 without invoking independence?\n\nWork so far\n\nIf the coin flips are independent, we get the answer immediately: by fairness, we know p(H) = p(T) = 1/2 and by independence we have p({HT}) = p(H) * p(T) = 1/4 (with the same result for any other point in the sample space).\n\nBut how do we do it without the independence assumption?\n\nHere's the path I've been working on:\n\nLet event A = Heads on first flip = {HH, HT} and let event B = Tails on first flip = {TT, TH}.\n\nBy disjointness and fairness we have p(A) = P({HH}) + p({HT}) = 1/2 and p(B) = P({TT}) + p({TH}) = 1/2\n\nThis gives us 2 equations in 4 unknowns. We can add to this system the fact that p(sample space) = p{HH, HT, TH, TT} = p({HH}) + p({HT}) + P({TT}) + p({TH}) = 1.\n\nThe idea would be to define another event that does not assume independence that would provide a fourth equation and allow us to solve this system for the component point-probabilities.\n\nCan anyone provide guidance?\n\n  \u2022 $\\begingroup$ What do you mean by a \"fair coin\"? The usual thought would include independence (\"each toss comes up H with probability $\\frac 12$ \" or something like that). Or do you have a different notion of \"fair\" in mind? $\\endgroup$ \u2013\u00a0lulu Sep 7 '15 at 2:10\n  \u2022 $\\begingroup$ Here, for example: en.wikipedia.org/wiki/Fair_coin . Independence is built into the definition. $\\endgroup$ \u2013\u00a0lulu Sep 7 '15 at 2:12\n  \u2022 $\\begingroup$ Appreciated. In this context, a fair coin means the probabilities of heads and tails are equal. I'd like to understand how to proceed without independence although I understand that is part of the typical understanding of a 'fair coin.' $\\endgroup$ \u2013\u00a0Chris Sep 7 '15 at 2:24\n  \u2022 $\\begingroup$ You mean, \"on each toss the probabilities are equal\"? That's independence. $\\endgroup$ \u2013\u00a0lulu Sep 7 '15 at 2:25\n  \u2022 $\\begingroup$ I see what you are saying, but assuming independence from the start makes problems like the following trivial: 2 identical and balanced coins are tossed once. Let H(1) be the event the first coin lands heads and H(2) be the event the second coin lands heads. Show that these are independent events. Do you have any idea on how to proceed without assuming what we're supposed to show? $\\endgroup$ \u2013\u00a0Chris Sep 7 '15 at 2:35\n\nIf \"fairness\" is defined to mean \"$P(H)=P(T)=\\frac{1}{2}$,\" then independance follows from fairness logically, so we can avoid saying \"by independance\" by using the word \"fairness\" a bunch. However, if the only property that we know of a coin is that it is fair, then we can't show what you wish without using something at least as strong as independence.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/10089/gravitational-time-dilation-at-the-earths-center\nText:\nI would like to know what happens with time dilation (relative to surface) at earth's center .\n\nThere is a way to calculate it?\n\nIs time going faster at center of earth?\n\nI've made other questions about this matter and the answers refers to:\n\n$\\Delta\\Phi$ (difference in Newtonian gravitational potential between the locations) as directly related, but I think those equation can't be applied to this because were derived for the vecinity of a mass but not inside it.\n\nAny clues? Thanks\n\n  \u2022 $\\begingroup$ May I suggest you spend some time reading about potentials in classical mechanics. Throwing off lines like \"but I think those equation can't be applied to this because were derived for the vecinity of a mass but not inside it\" does nothing to improve you reception here, and these issues are addressed in every textbook on the subject. Or at least ask questions about the subject (potential) you don't understand instead of speculating wildly. Please. $\\endgroup$ \u2013\u00a0dmckee --- ex-moderator kitten May 19 '11 at 15:43\n  \u2022 $\\begingroup$ @dmckee yes, you are right, and I do it whenever I can, I spend the time to go deeper, but there are a lot of interesting topics luckly and althought I am able to have the doubt, and even sometimes to understand an answer, but (life itself) give no so much time to study them all, so thanks to internet and to people like everyone here, one can know things that there is no other way to reach, same sense I help people in other areas I can dedicate more time, thanks $\\endgroup$ \u2013\u00a0HDE May 19 '11 at 15:58\n\nThe rule I mentioned in another question, that the time dilation factor is $1+\\Delta\\Phi/c^2$, applies here. The derivation (found in various textbooks) depends only on the assumptions that fields are weak and matter is nonrelativistic, both of which are true for the Earth.\n\nModeling the Earth as a uniform-density sphere (not true, of course, but I don't care), we find that $g(r)=GMr/R^3$ where $R$ is the radius of the Earth. So $$ \\Delta\\Phi={GM\\over R^3}\\int_0^Rr\\,dr={GM\\over 2R}. $$ That means that $$ {\\Delta\\Phi\\over c^2}={GM\\over 2Rc^2}={1\\over 4}{R_s\\over R}. $$ Here $R_s=2GM/c^2$ is the Schwarzschild radius corresponding to the Earth's mass. Numerically, $R_s$ is about 9 mm, and $R$ is about 6400 km, so $\\Delta\\Phi/c^2=3\\times 10^{-10}$.\n\nThe sign of the effect is that clocks tick slower when they're deeper in the potential well. That is, a clock at the Earth's surface ticks 1.0000000003 times faster than one at the center.\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ This seems a very simple approach, M/R define the ratio, a sort of \"density\", there is \"an order of magnitude\" (simply x10) of difference with Lubo\u0161 Motl answer, but at least both answer said time inside earth would be slower than in the surface $\\endgroup$ \u2013\u00a0HDE May 19 '11 at 15:46\n  \u2022 2\n    $\\begingroup$ Actually, the difference is a factor of 3 ($3\\times 10^{-10}$ vs $10^{-9}$). The difference is because Lubos is calculating the potential difference between the center and infinity, whereas I calculate the difference between center and surface. That's precisely a factor of 3. $\\endgroup$ \u2013\u00a0Ted Bunn May 19 '11 at 17:31\n  \u2022 $\\begingroup$ sorry I'd compared $10^{-10} vs 10^{-9}$, that's why I saw a x10 factor, now I see a 10/3 =3.3333.. factor $\\endgroup$ \u2013\u00a0HDE May 19 '11 at 18:57\n  \u2022 $\\begingroup$ I thought if the Earth is a uniformly dense sphere the gravity at the center is zero. $\\endgroup$ \u2013\u00a0Brandon Enright May 20 '13 at 21:58\n  \u2022 3\n    $\\begingroup$ @BrandonEnright: Time dilation depends on the potential, not the field. $\\endgroup$ \u2013\u00a0user4552 May 20 '13 at 22:01\n\nDear HDE, it's not hard to estimate the gravitational potential at the Earth's center. Of course, it's smooth. Let me assume that the Earth's mass density is uniform which is an OK estimate - up to factors of two or so.\n\nThe gravitational acceleration at distance $R$ from the center is $GM/R^2$ if $R$ is greater than the Earth's radius $R_E$. However, for smaller values of $R$, you have to use Gauss' law $$\\int d\\vec S\\cdot \\vec g \\sim GM_{inside}$$ and determine the total mass inside a smaller sphere. Because $M_{inside}$ goes like $R^3$ for $R<R_E$, and this $R^3$ is still divided by $R^2$ from $\\int d\\vec S$, it follows that the gravitational acceleration inside the Earth is pretty much proportional to $R$: $$ g(R) = g(R_E)\\cdot \\frac{R}{R_E} $$ In particular, the gravitational acceleration at the Earth's center is zero and near the center, a particle would oscillate like in a harmonic oscillator, $\\vec F\\sim -k\\vec x$.\n\nIt's also trivial to calculate the extra decrease of the gravitational potential you get if you go from the surface to the center. On the surface, the gravitational potential is $-GM/R_E$, as you know, because the derivative of $-GM/R$ over $R$ gives the right acceleration. However, the potential is getting even more negative. If you integrate $g(R_E)\\cdot R/R_E$ over $R$ from $0$ to $R_E$, you will get $g(R_E) R_E/2$. This has to be taken with the negative sign.\n\nSo the potential at the center, assuming uniformity, is $$ \\Phi = -\\frac{GM}{R_E} - g(R_E) \\frac{R_E}{2} = -\\frac 32 \\frac{GM}{R_E} = -\\frac 32 g(R_E) R_E $$ This gravitational potential determines the slowing of time, too. In SI units, $g(R_E)=10$ Newtons per meter and $R_E=6,378,000$. The product, with the $3/2$ factor added, is almost exactly $10^{8}$. Divide it by $c^2=10^{17}$ to get about $10^{-9}$ - the relative red shift from the center of the Earth to infinity.\n\nIf you spend 1 billion years at the center of the Earth, your twin brother outside the gravitational field will get 1 billion and one years older. If you wish, you may interpret it by saying that it's healthy to live at the center of the Earth. Good luck.\n\n| cite | improve this answer | |\n  \u2022 4\n    $\\begingroup$ A small note: the question asks about the relative time dilation between the center and surface of the Earth, whereas the $\\Phi$ you calculate is the potential of the center relative to infinity. That accounts for the factor of 3 difference between your answer and mine. $\\endgroup$ \u2013\u00a0Ted Bunn May 19 '11 at 17:32\n\nThe CENTER of the earth will not have more gravity, but less. This is because half the mass will be \"above\" half \"below\" ( Regardless of orientation)...Sort of less g and in different direction/vectors. The thing is mass is not concentrated at a spot in the center with more and more g as one moves closer to the center. As you tunneled down, some of the mass, more and more would be behind you). More time dilation on surface... Where g is stronger. Time would not be slower at center of earth.\n\n| cite | improve this answer | |\n  \u2022 3\n    $\\begingroup$ Time dilation depends on the potential, not the field. $\\endgroup$ \u2013\u00a0user4552 May 20 '13 at 22:00\n  \u2022 $\\begingroup$ While I understand you mean potential as distance from source, and your point that there is no dilation unless this potential is not the same for the two clocks. I do not think this is a point of confusion, and do not see why this comment is particularly relevant. Please explain. $\\endgroup$ \u2013\u00a0Tuesday May 21 '13 at 15:57\n  \u2022 $\\begingroup$ the center of the earth has no gravitational attraction... so according to you, time should not pass there. $\\endgroup$ \u2013\u00a0udiboy1209 Jul 7 '13 at 6:40\n  \u2022 $\\begingroup$ @udiboy: No, that would mean that a Minkowski spacetime is equivalent to a black hole. Weird duality...(!) $\\endgroup$ \u2013\u00a0Abhimanyu Pallavi Sudhir Sep 29 '13 at 8:39"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/58000/maximum-cost-path-in-integer-matrix\nText:\nIn preparation for my design and algorithms exam, I encountered the following problem.\n\nGiven a $2 \\times N$ integer matrix $(a[i][j] \\in [-1000, 1000])$ and an unsigned integer $k$, find the maximum cost path from the top left corner $(a[1][1])$ and the bottom right corner $a[2][N]$, given the following:\n\n$\\bullet$ The path may not go through the same element more than once\n\n$\\bullet$ You can move from one cell to the other vertically or horizontally\n\n$\\bullet$ The path may not contain more than $k$ consecutive elements from the same line\n\n$\\bullet$ The cost of the path is determined by the sum of all the values stored within the cells it passes through\n\nI've been thinking of a simple greedy approach that seems to work for the test cases I've tried, but I'm not sure if it's always optimal. Namely, while traversing the matrix, I select a the maximum cost cell on the vertical or horizontal and then go from there. I've got a counter I only increment if the current cell is on the same line with the previously examined one and reset it otherwise. If at some point the selected element happens to be one that makes the counter go over the given value of $k$, I simply go with the other option that's left.\n\nHowever, I feel that I'm missing out on something terribly important here, but I just can't see what. Is there some known algorithm or approach that may be used here?\n\nAlso, the problem asks for an optimal solution (regarding temporal complexity).\n\n\nThis problem was basically made for dynamic programming (DP). Just review it and follow a couple of examples and solving this problem is straight-forward.\n\nYour simple greedy approach does not always work. Consider:\n\n[ begin ] [  2 ]\n[ 3 ]     [ 10 ]\n[ 1 ]     [ -1000 ]\n[ 1 ]     [ end ]\n\nThe optimal solution would be to go right, down, left, down, down, right.\n\n  \u2022 $\\begingroup$ I meant $2$ lines and $N$ columns, but I guess it doesn't make a difference in this case. $\\endgroup$ \u2013\u00a0user43389 May 29 '16 at 23:28\n\nWe shall approach this using dynamic programming -- the greedy algorithm is 'myopic' in that it only considers immediate neighbors and not the path that follows those neighbors.\n\nLet $C(i, \\ j, \\ m)$ be the cost of the max-cost path starting from $a[i][j]$ going towards $a[2][n]$, where $i$ is either $1$ or $2$, $\\ j \\in [1, n]$ and $m \\in [0, k]$.\n\n  \u2022 $m$ here denotes that we have $m$ remaining consecutive steps that could be taken along row $i$.\n  \u2022 The additional constraint we enforce here is that when we are calculating $a[1][i]$, we have not yet visited $a[2][i]$, and similarly when we're calculating $a[2][i]$, we have not yet visited $a[1][i]$.\n\nWith this constraint in place, what recurrence can we come up with? Well,\n\n  1. $C(1, \\ j, \\ m) = a[1][j] + \\max \\{ M(1, j+1, m-1), \\ a[2][j] + M(2, j+1, k)\\} \\ $ and similarly,\n  2. $C(2, \\ j, \\ m) = a[2][j] + \\max \\{ M(2, j+1, m-1), \\ a[1][j] + M(1, j+1, k)\\} \\ $\n\nNow, what's the rationale here? If we started at $a[1][j]$, we have two choices:\n\n  \u2022 continue along row $1$ : we then go to $a[1][j+1]$ with $m-1$ remaining consecutive steps that we can take along row $1$. (note here that $a[2][j+1]$ is not yet visited, maintaining the invariant).\n\n  \u2022 switch to row $2$ : we go to $a[2][j]$, incurring a cost of $a[2][j]$, and then have only one choice from there - to go to $a[1][j+1]$. Because we have switched rows, we can now refresh our count and take $k$ consecutive steps along row $2$. (note again that we haven't visited $a[1][j+1]$ yet).\n\nNow if we calculate our subproblems starting from $j = n$ towards $j=1$ for every value of $m$, you shall have your answer in $C(1, \\ 1, \\ k)$.\n\nI shall leave the base cases and runtime analysis to you. Note that my solution calculates the cost of the path and not the path itself; can you extend my solution to calculate the path too?\n\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/134451/deformation-of-curves-with-three-nodes\nText:\nLet $X$ be a stable curve consisting of two components meeting at three points. Let $M$ be its versal deformation space. The locus in $M$ parametrizing singular curves is a divisor with three components $D_1, D_2, D_3$, each corresponding to a node on $X$. The question is, which curve does a general point on $D_1\\cap D_2$ correspond to? More precisely, does it correspond to an irreducible nodal curve, or a curve with two components meeting at two points?\n\n\nA general point on $D_1 \\cap D_2$ is given by smoothing the third node, which produces an irreducible curve with two nodes.\n\n  \u2022 $\\begingroup$ Your other possibility would have the wrong arithmetic genus, unless two of the nodes collided, but I guess that's not in the versal deformation space at all. $\\endgroup$ \u2013\u00a0Allen Knutson Jun 22 '13 at 5:24\n  \u2022 $\\begingroup$ Thank you very much. May I ask for some more detail explanation of it? $\\endgroup$ \u2013\u00a0marker Jun 22 '13 at 15:10\n  \u2022 $\\begingroup$ Perhaps you just need to distinguish deformations from resolutions. I.e. a curve with two components meeting at two nodes is obtained by partially resolving the original curve by separating the branches at the third node, but this is a not a \"deformation\". Indeed the only way to deform a node non trivially is to smooth it. A deformation preserves the arithmetic genus, as Allen Knutson referred to, but a resolution reduces it. I always recall the maxim of Brieskorn, something like that analysis of singularities has three key aspects: resolution, deformation, and monodromy. $\\endgroup$ \u2013\u00a0roy smith Jun 23 '13 at 20:19\n\nYour Answer"}
{"text": "Retrieved from https://mathstories4u.com/algebra-smartphoneuse/\nText:\nCan Smart Phone Use Enhance Academic Performance?\n\nsmartphoneuse\u00a0\u00a0(Read the disclaimer at the end of the chapter)\n\n\u00a0Kwong\u2019s Pride and Honor\n\nKwong, a grade 11 student, was sitting alone in the school cafeteria.\u00a0 One could easily tell from his face that he was angry, sad or perhaps both.\u00a0 When his girlfriend Jun saw that he was \u00a0distraught, she joined him and started talking.\u00a0 She was almost sure that Kwong\u2019s grief concerned what happened in Ms. Clementine\u2019s class.\u00a0 Jun also knew about the high expectations of Kwong\u2019s parents and how strict they were with him.\n\nMs. Clementine was a very good Math teacher who would retire in two years. She was also a disciplinarian. She hated it when a student did not respect her, or for that matter if they disrespected any other teacher.\u00a0 Many students were using smart phones in her class when she was talking to the class.\u00a0 She sternly told them to get the ear buds out of their ears, and she threatened to send them to the vice-principal if they used the phones in her class again.\u00a0 She also gave them a long lecture indicating the possibility that a prolonged use of phones decreases the ability of people to think.\u00a0 She went on to tell them that such an action could lower their academic performance. Even though she was talking to the whole class, Kwong thought she was addressing him alone.\n\nJun: Hi Kwong. Are you still thinking of Ms. Clementine?\n\nKwong: How could she?\u00a0 Why did she pick on me?\n\nJun: \u00a0Don\u2019t be so sensitive. \u00a0She was talking to everyone, not just you. Don\u2019t take it personally, Kwong.\n\nKwong: No, she picked on me.\u00a0 She could have easily sent me to the vice-principal\u2019s office.\u00a0 If my mom finds out about it, I would be in trouble and could lose all my privileges.\n\nJun: So don\u2019t tell your mom.\n\nMore students from the class gathered around Kwong and Jun.\n\nA bystander student:\u00a0 Kwong, Ms. Clementine was mad at you today.\n\nJun to the bystander student: Go mind your own business.\u00a0 It\u2019s not like you have the best reputation in the school. Just go.\n\nMoving forward\n\nJohnny: Kwong, I am sorry that we all sat there without challenging \u00a0Ms. Clementine. She didn\u2019t give us any evidence for what she said. We should have asked her for a proof.\u00a0 We all just sat there scared like a herd of dears in front of a lion.\n\nKwong: But why did she have to pick me? At least 15 students in the class were using smart phones with ear buds.\n\nJun: Johnny is right.\u00a0 We should have challenged her.\n\nKwong: She looked so angry.\u00a0 She would have sent me straight to the vice-principal\u2019s office if I had raised any doubts about what she was saying. Yes, for sure (almost sobbing and incoherent due to anger).\n\nJun:\u00a0 So what are you going to do \u2013 moan for the rest of your life?\u00a0 My parents taught me to do whatever it takes to regain my honor.\n\nKwong: What do you mean by whatever it takes?\u00a0 What can I do?\n\nJohnny:\u00a0 I have an idea.\u00a0 I don\u2019t know if you are up to it.\n\nKwong:\u00a0 Johnny, you and your ideas! I don\u2019t know about them (pause).\u00a0 What do you want to say this time?\n\nJohnny: We could challenge Ms. Clementine without actually questioning her. We could say that we want to test the impact of smart phone use on academic performance.\n\nKwong: Johnny, you may have something. What do you have in mind?\n\nThe Science fair proposal\n\nJohnny:\u00a0 We could tell her that we want to enter the Science Fair and we need her to guide us through it.\u00a0 The project would be \u201cThe Relationship Between Smart Phone Use And Academic Performance.\u201d\n\nKwong: How will we do this project?\n\nJohnny: You have many friends in class including Jun and me.\u00a0 We could do a survey.\n\nKwong was a little calmer by now and started playing around with his phone. Suddenly he had a Eureka moment and said: You know I can get my phone history on demand.\u00a0 I can check my total phone use between any two dates.\n\nJohnny:\u00a0 That\u2019s great.\u00a0 Anyone who has a smart phone should be able to find their total phone use in the month of the exams in the last semester.\n\nJun:\u00a0 Why don\u2019t we divide up the class, find out who knows who, and then do the survey.\u00a0 I know a lot of students in the school in grade 11 \u2013 some who take higher math and others who don\u2019t. We all have friends in the class. Can we do the survey?\n\nKwong: First, let me talk to Ms. Clementine.\n\nJohnny:\u00a0 It\u2019s a good idea.\u00a0 Otherwise she might get angry thinking that we are doing this behind her back just to show her up.\n\nDuring his next free period, Kwong approached Ms. Clementine.\n\nKwong: Ms. Clementine.\u00a0 I am sorry for what happened in the class. We have decided to make up for it.\u00a0 Jun, Johnny and I will do a Science Fair Project to show you that we are serious students.\n\nMs. Clementine:\u00a0 The deadline for the registration and school presentation for the Science Fair projects is only a week away.\u00a0 How will you be ready? \u00a0Have you done any experiments?\u00a0 Did you talk to any of your science teachers? \u00a0I am not sure how I can help.\n\nKwong talked to the teacher\n\nKwong: Ms. Clementine. The project is \u201cThe Relationship Between Smart Phone Use And Academic Performance.\u201d We will survey all the students of grade 11 in our school.\u00a0 There are many of us who together can do the survey fairly rapid. After the initial data collection, it will become an analysis problem, and we hope that you will guide us through it as a Math teacher.\n\nMs. Clementine had mixed feelings about it but she couldn\u2019t refuse a student asking for help in Math.\u00a0 So she agreed.\n\nSmart Phone Usage And Academic Performance: The Survey\n\nKwong got back to Jun and Johnny.\u00a0 They found that between them they knew everyone in grade 11. So they divided the work of talking to their friends.\u00a0 The students were told that this was an unofficial survey to help Kwong with the Science Fair, and that it had nothing to do with the school.\u00a0 Nobody\u2019s name or any other identification would appear anywhere even in Kwong\u2019s work.\u00a0 They were also told on how to get their own phone history data.\u00a0 As soon as they got the data, they would send it to Kwong\u2019s phone as a text message along with their grade point average in that semester.\n\nWith the power of having good helpful friends and the smart phone technology, Kwong had the data from all 175 students within 48 hours.\u00a0 He sent the data to his laptop. Now the question was what to do with it.\u00a0 He converted the phone usage data to hours of phone use per day.\u00a0 He arranged the data with the increasing number of hours of phone usage per day.\u00a0 Then he graphed the data, transferred the graph onto his phone and arranged to meet with Jun and Johnny before school.\n\nKwong met Jun and Johnny in the cafeteria. Johnny and his girlfriend Sara used to walk to school together and so she also came. Sara told Kwong that she would go away if they minded her being there.\u00a0 Jun replied that they would be very happy for her to see what they were doing.\u00a0 Kwong also nodded in affirmation.\n\nKwong:\u00a0 I have made two graphs.\u00a0 First, I want to show you the one that I am excited about. See the graph for 35 students on my phone (Fig. 7.1).\u00a0 It shows that the grade point average improved of the students with their phone usage.\u00a0 So, Ms. Clementine was wrong (he said this with an air of smugness).\n\n\nJun:\u00a0 It will be great to do a Science Fair presentation.\u00a0 All the students will be excited.\n\nJohnny: Yes, there is a definite correlation between the grade point average and the extent of phone usage.\n\nKwong:\u00a0 I forgot to tell you that one or two exceptional students, whose marks were very high, are not shown in the graph.\n\nSara:\u00a0 I guess one of them would be me but more interestingly, the graph is only for 35 students. Johnny, didn\u2019t you say that Kwong had the data for all the 175 students?\n\nKwong:\u00a0 Yes, yes.\u00a0 I did tell you that I had two graphs. What if we did the Science Fair using only these 35?\n\nSara:\u00a0 Are these 35 taken at random?\n\nKwong: No. I arranged them according to the increasing phone usage.\u00a0 These are only the first 35 out of the 175.\n\nJohnny:\u00a0 Show us the second graph.\u00a0 A report based only on the first 35 would be dishonest. It could get us kicked out of the competition and even from the school.\n\nJun: Kwong, Show us all the data.\n\nQuadratic relationship\n\nKwong: Okay, here is the graph with all the 175 students \u2013 including the three outliers (Fig.7.2).\u00a0 This graph is not so exciting.\u00a0 It goes up a little bit and then down, down and down.\n\n\nJohnny: Sara, now I see you there with the 98% average in the last semester.\u00a0 You are one of the outliers.\n\nSara was fidgeting with her phone and probably didn\u2019t hear them but then she suddenly blurted: Kwong, you will have to analyze the data if you want to get on Ms. Clementine\u2019s good side or do well in the Science Fair competition.\n\nKwong: What do you suggest?\n\nSara:\u00a0 These data could form some kind of a parabola. I am not sure, but it may fit into a quadratic relationship.\n\nKwong: What\u2019s that?\n\nSara: In general, it is written as y = ax2 + bx + c.\u00a0 We haven\u2019t done this in class as yet but I looked through our book in the holidays.\u00a0 When you showed us the graph, I did an Internet search using my phone.\u00a0 You can analyze the data online at this site.\u00a0 Do you have the raw data on your phone?\n\nKwong: No, but I have it on my laptop. How do we go about the analysis?\n\nSara: Here, let me try. Let\u2019s remove the outliers, feed the data here onto this website and hit execute. Hey, it calculated it in less than a second. The data fit y = -2.4x2 + 9.6x + 76.8.\n\nKwong: Thanks Sara.\u00a0 May be you should be on our team for the Science Fair.\n\nSara: I have a lot work to finish.\u00a0 So, I am not sure.\n\nJun: You can be there as an advisor. We are going to need someone to answer all the tough questions too. So please, join us. Advise us and the three of us can do all the leg work.\n\nSara: I\u2019ll think about it, but for now we have a class.\n\nKwong asked to talk to Ms. Clementine.\n\nKwong: Ms. Clementine, we have completed our survey and I have the data.\n\nClass discussion of the data\n\nMs. Clementine: You said that it would involve analysis. So tell the whole class about your data.\u00a0 Maybe someone can help.\n\nKwong to the class: For a Science Fair project, we did a survey of the whole class.\u00a0 You know about it because all of you participated in it.\u00a0 The overall result is this graph of the relationship between the academic performance of students in the last semester and their smart phone usage in the month of the exams in that semester. You can see, the graph goes up, peaks and then comes down. Sara showed me a website that calculated the relationship. It fits the quadratic function y = -2.4x2 +9.6x + 76.8.\u00a0 Thank you all for your participation.\u00a0 That\u2019s all we have for now.\n\nMs. Clementine: I think you should get Sara to participate in the Science Fair project.\u00a0 Will you do that Sara?\n\nSara: Yes, Ms. Clementine. They had already asked me. I was thinking about it. If you think that it would be good for us, I will be happy to work with the group.\n\nThe Science Fair Presentation\n\nKwong\u00a0and the team prepared a poster for the Science Fair and the school approved it.\u00a0 Kwong showed the graph for the survey of the 175 students, the fit of the data into the equation y = -2.4x2 + 9.6x + 76.8, graph for the equation with the y = 0 points and also the co-ordinates of the vertex.\n\nHere are the title and the abstract of the presentation.\n\n\u201cSmart Phone Use Increases Academic Performance.\u201d\n\nWe surveyed 175 students of grade 11 in our school. We asked them the total time they used the smart phone in the month of the exams in the last semester and their grade point average that semester. The data fit a quadratic relationship y = -2.4x2 + 9.6x + 76.8.\u00a0 This shows that, on average, the academic performance increased when the phone use was up to 2 hours/day.\u00a0 The maximum average increase in the grades was almost 10%.\u00a0 However, excessive time spent on using the phone decreased the grades.\n\nAfter the Science Fair, Kwong had this conversation with Ms. Clementine who asked him how the Science Fair went.\n\nKwong: \u00a0Many students from different schools came to see our poster.\u00a0 The poster was very popular at the Science Fair and we won a prize too. The judges grilled us though. It\u2019s a good thing that Sara was there to answer questions. Otherwise, we would have crumbled.\n\nJudges\u2019 questions\n\nMs. Clementine: I am sure the judges were fair and doing their job. What were some of the questions?\n\nKwong: \u00a0Some of the questions were:\n\nYou get both an increase and a decrease in grades with the cell phone use. Why do you focus only on the increase?\u00a0 Isn\u2019t it misleading?\n\nYour data are only for one month \u2013 the month of the exams.\u00a0 Doesn\u2019t your school also use grades for your assignments and midterm tests throughout the semester?\n\nYou have shown that there is an association between grades and cell phone usage.\u00a0 What is the logical explanation?\n\nYour title is Smart Phone Use Increases Academic Performance. Is an association between the grades and the cell phone use really a proof of causation or is it just a coincidence?\u00a0\u00a0\u00a0 What experiments need to be done to prove that the concept in your title is a valid one?\n\nIf the experiments you want to carry out are not allowed due to ethical reasons, how would you go about testing the validity of your concept?\n\nDo you think that the vertex of 2 hours is applicable to every student individually?\n\nHow did you determine the outliers? \u00a0How do you explain them?\n\nYou indicated that you tried a quadratic fit because the graph looked curved. Did you see if the data would give a better fit using a cubic or a higher power polynomial?\n\nMs. Clementine: That\u2019s good.\u00a0 That means they showed interest in you and prepared you for the future.\n\n\nNo-one should use the data here as a guide for the appropriate time for phone use. This is a fictional story. The data were made up as were all the characters. The data were created solely to explain the concepts of quadratic equations.\u00a0 The values of y were generated using the equation -2.4x2 + 9.6x + 76.8 and then adding random numbers between -5 and 5 to each data point.\n\nTop of the page and site index"}
{"text": "Retrieved from https://www.physicsforums.com/threads/entropy-change-of-a-hot-falling-object.521552/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEntropy change of a hot, falling object\n\n  1. Aug 14, 2011 #1\n\n    A shipyard worker drops a hot steel rivet (mass 125g, temperature 350 degrees C)\n    into a river at temperature 5 degrees C, a distance 30m below. Stating any assumptions\n    you make, calculate the entropy change of the universe as a result of this event.\n    (specific heat capacity of steel ~0.4 J g-1 K-1).\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n\n\n\n\n    If anybody could tell me if I'm on the right lines at all or what the heck to do with the fact that the rivet's being dropped from 30m I'd greatly appreciate it. Thanks!\n    Last edited: Aug 14, 2011\n  2. jcsd\n  3. Aug 14, 2011 #2\n\n\n    User Avatar\n    Homework Helper\n\n    You have traced the change in entropy of the rivet, but I believe there are two more things you need to look at in the \"universe\" (essentially the rivet-Earth system). How much heat has been added to the river by the change in gravitational potential energy in the rivet-Earth system? Also, the river absorbs the heat of the rivet with virtually no temperature change (it's large enough to serve as a \"heat reservoir\"), so what is the change in the entropy of the river from that?\n\n    So there is the entropy change of the cooling rivet plus the entropy change from the change in mechanical energy plus the entropy change from the heat transfer from rivet to river.\n  4. Aug 14, 2011 #3\n    Thanks for the reply.\n\n    So, as I see it, so far I've worked out the decrease in the entropy of the rivet.\n\n    The heat flowing into the reservoir from the rivet cooling will be the same as the heat loss from the rivet:\n\n\n    That gives me 17250 J.\n\n    Then, if we assume the temperature of the reservoir doesn't change, then, using the temperature of the river in Kelvins for T:\n\n\n    That gives me an increase of entropy in the river as 62.1 JK-1\n\n    Finally, the change in gravitational potential energy is:\n\n\n    If we assume that this is all converted to heat in the river we can work out a second component for the increase in entropy. I get S = 0.13 JK-1.\n\n    Overall this gives me a net increase in the entropy of the universe as S = 21.93 JK-1.\n\n    Is this the right track or have I completely messed up?\n  5. Aug 14, 2011 #4\n\n\n    User Avatar\n    Homework Helper\n\n    I agree with those results to the first decimal place (since I rounded off only at the end), so we get a net increase in entropy for the \"universe\" of 21.9 J/K .\n\n    It is a reasonable safe assumption that just about all of the potential energy change is transferred into heating the river. The \"splash\" at impact displaces water and ejects some of it upward (briefly), as well as producing (a minute amount of) acoustical energy. But since practically all the water falls back into the river, that mechanical energy winds up heating the river after all. (We can extend \"the universe\" to include the air over the river, but the tiny amounts of water scattered as microdroplets and vapor and of sound energy probably contribute additions to entropy scarcely worth pursuing...)\n\nSimilar Discussions: Entropy change of a hot, falling object\n  1. Entropy change (Replies: 1)\n\n  2. Change of entropy (Replies: 0)\n\n  3. Change in entropy (Replies: 2)\n\n  4. Entropy changes (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-to-begin-oscillation-in-steady-state.42282/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHow to begin oscillation in steady state?\n\n  1. Sep 8, 2004 #1\n    I need to find the initial conditions such than an underdamped harmonic oscillator will immediately begin steady-state motion under the time dependent force F = m f cos\u03c9t.\n\n    For the underdamped case:\n    [tex]x(t) = ae^{-\\gamma t}cos(\\Omega t+\\alpha)+\\frac{f}{r}cos(\\omega t-\\theta)[/tex]\n\n    and if it matter, [tex]r^2 = (\\omega^2_0-\\omega^2)^2+4\\gamma^2\\omega^2[/tex]\n    and [tex]\\theta = Tan^{-1}\\frac{2\\gamma\\omega}{\\omega^2_0-\\omega^2}\n\n    I thought I would just have to find x0 and v0 such that the transient was 0, but that doesn't seem to be leading down the right track. What direction should my solution be heading?\n    Last edited: Sep 8, 2004\n  2. jcsd\n  3. Sep 8, 2004 #2\n    Why not just let x0=0 and v0=0? This should zero out the transient portion of the solution and leave the driving force intact.\n  4. Sep 8, 2004 #3\n    Makes sense to me, but the back of the book doesn't seem to agree. It has [tex]x_0=\\frac{f (\\omega^2_0-\\omega^2)}{r^2}[/tex] and [tex]v_0=\\frac{2\\gamma\\omega^2f}{r^2}[/tex].\n  5. Sep 8, 2004 #4\n    oh. take x(0) and x'(0) and let a = 0. If a = 0 then the transient solution is immediate null, but you'll see x0 and v0 are not. You'll have to subtitute for theta as well.\n  6. Sep 9, 2004 #5\n\n\n    User Avatar\n    Homework Helper\n\n    It was a good start. Let [tex]a=0[/tex]. Find x(0) and v(0). You have\n    [tex]x(0)=\\frac{f}{r}cos(\\theta ) \\mbox{ and }v(0)=\\frac{f\\omega}{r}\\sin(\\theta ) [/tex], use that\n    [tex] cos(\\theta ) = \\frac{1}{\\sqrt{1+tan^2(\\theta )}}\\mbox{, }sin(\\theta )=\\frac{tan(\\theta )}{\\sqrt{1+tan^2(\\theta )}} \\mbox{ and } tan(tan^{-1}(\\theta))=\\theta [/tex].\n\n\nSimilar Discussions: How to begin oscillation in steady state?\n  1. Steady-state current (Replies: 11)"}
{"text": "Retrieved from https://shitpost.plover.com/m/math.diophantine-equation.html\nText:\nContent-Type: text/shitpost\n\nSubject: A little algebraic thingy\nPath: you\u200b!your-host\u200b!wintermute\u200b!wikipedia\u200b!hardees\u200b!m5\u200b!plovergw\u200b!shitpost\u200b!mjd\nDate: 2018-01-23T19:53:46\nNewsgroup: rec.pets.math.diophantine-equation\nMessage-ID: <>\nContent-Type: text/shitpost\n\nA few days ago I was wondering if there are any (nontrivial) integer solutions of $$a^2 - ab + b^2 = 1\\tag{$\\spadesuit$}$$\n\nbut I couldn't do it in my head. I had the idea it would be pretty easy if I tried on paper, and yes, it was one of those ones where you don't even really have to think, you just push the symbols around.\n\nFrom !!(\\spadesuit)!!, adding or subtracting !!ab!!, we get both $$\\begin{align} a^2 + b^2 & = 1 + ab \\\\ (a-b)^2 & = 1 - ab \\end{align}$$\n\nand since in both cases the left sides are non-negative, we have both !!1+ab\\ge 0!! and !!1-ab \\ge 0!!, so !!-1\\le ab \\le 1!!, and we are done.\n\nI thought about it a little more and decided that perhaps a more elegant way to put it was: Multiplying !!(\\spadesuit)!! by 2, we get $$\\begin{align} 2a^2 - 2ab + 2b^2 &= 2 \\\\ a^2 + b^2 + (a-b)^2 &= 2 \\\\ \\end{align}$$\n\nand then since we have three squares that sum to 2, one must be zero and the rest must be 1.\n\nProbably there is a nice geometric proof also."}
{"text": "Retrieved from https://math.stackexchange.com/questions/1261179/number-of-solutions-of-equations-mod-pn\nText:\nUsing Hensel's lemma, it is easy to prove that if $p$ is a prime with $p\\equiv 1\\mod 3$ then the equation $x^2-x+1=0$ has at least two solutions $\\mod p^n$ for all $n\\geq 1$. Are there more than two solutions?. Of course, the anwer is not when $n=1$ but what happens if $n\\gt 1$?. I have many more equations to analyze so it would be interesting to find an answer for more general equations.\n\nThanks in advance.\n\n\nIt is convenient to note that $x$ is a solution of $x^2-x+1\\equiv 0\\pmod{p^n}$ if and only if $x\\equiv -t\\pmod{p^n}$, where $t$ is a solution of $t^2+t+1\\equiv 0\\pmod{p^n}$.\n\nSince $p$ is an odd prime, there is a primitive root $g$ modulo $p^n$. To show that there are exactly $2$ solutions of $t^2+t+1\\equiv 0\\pmod{p^n}$, it is enough to show that the congruence $t^3-1\\equiv 0\\pmod{p^n}$ has exactly $3$ solutions. We look for solutions of the shape $g^k$.\n\nWe have that $g^k$ is a solution of the congruence $t^3-1\\equiv 0\\pmod{p^n}$ if and only if $g^{3k}\\equiv 1\\pmod{p^n}$.\n\nNote that $\\varphi(p^n)=(p-1)p^{n-1}$. Let $p=1+3m$. If we put $k=mp^{n-1}$, then $g^{3k}\\equiv 1\\pmod{p^n}$. And in general, $g^{3k}\\equiv 1\\pmod{p^n}$ if and only if $\\varphi(p^n)$ divides $3k$. For $0\\le k\\lt \\varphi(p^n)$, this happens if and only if $k=0$, $m$, or $2m$.\n\n  \u2022 $\\begingroup$ @Diego: Thanks for the edit! $\\endgroup$ \u2013\u00a0Andr\u00e9 Nicolas May 1 '15 at 23:29\n  \u2022 $\\begingroup$ question: why did you prefer $t^3-1$ over $t^2+t+1=(t+\\frac{1}{2})^2+\\frac{3}{4}$ and the three solutions must be counted with multiplicity for $p=3$ the solution $t=1$ is a double root $\\endgroup$ \u2013\u00a0Elaqqad May 2 '15 at 1:19\n  \u2022 $\\begingroup$ The problem is about primes of the form $3k+1$. As to $t^3-1$, it looks nicer than $(t+1/2)^2+3/4$, and a basic chapter in elementary number theory has to do with order. Also, the same idea would work with longer sums. But it is true that $(2t+1)^2+3$ would work nicely, and then it comes down to $x^2\\equiv a\\pmod{p^n}$. $\\endgroup$ \u2013\u00a0Andr\u00e9 Nicolas May 2 '15 at 1:42\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/124048/why-is-it-that-det-phi-x-textid-sum-i-0n-1ic-ixi\nText:\nI'm trying to understand a certain formula for the determinant in a more general setting.\n\nSay you have a free module $M$ of rank $n$ over a (commutative) ring $R$. Let $\\phi\\in\\operatorname{End}(M)$, the $R$-module of $M$ endomorphisms, and denote by $c_i$ the trace of $\\phi$ in the exterior algebra $\\Lambda^i M$ (a.k.a alternating algebra, grassman algebra).\n\nHow come $$ \\det(\\phi-x\\text{id})=\\sum_{i=0}^n (-1)^ic_ix^i? $$\n\nThis seems like it would follow easily from induction, but unless I'm missing something obvious, I don't see how the trace fits in. Can someone explain why this polynomial identity is true? Many thanks.\n\n  \u2022 $\\begingroup$ You want to assume that $M$ is free. Then this is a polynomial identity which can be derived by standard methods from the case that $R$ is a field. But then linear algebra comes to the rescue ... $\\endgroup$ \u2013\u00a0Martin Brandenburg Mar 24 '12 at 21:34\n  \u2022 $\\begingroup$ Thanks @MartinBrandenburg. Do you have a reference for this identity when $R$ is a field so I can attempt to adapt it? I couldn't find one. $\\endgroup$ \u2013\u00a0Hailie Mathieson Mar 25 '12 at 18:15\n  \u2022 $\\begingroup$ @hmIII: try to work this out for the $2 \\times 2$ case first. Write out the characteristic polynomial as a function of the matrix entries and you will obtain the trace and the determinant of $\\phi$ as the coefficients. Now, just notice that determinant comes from the action of $\\phi$ on the top exterior power (this holds for any $n$). If this makes sense, you should be able to generalize to other $\\Lambda^i$ without too much trouble. $\\endgroup$ \u2013\u00a0Marek Mar 25 '12 at 19:42\n  \u2022 $\\begingroup$ For the induction step: Laplace expansion on the first column and recall that $\\wedge^i \\phi:\\wedge^i M \\rightarrow \\wedge^i M$ is given by $i\\times i$ minors $\\endgroup$ \u2013\u00a0Blah Mar 25 '12 at 20:50\n\nIf $M$ is a module over $R$, any endomorphism $\\phi:M\\to M$ induces an endomorphism $\\Lambda^r \\phi:\\Lambda^rM\\to \\Lambda^rM$.\nIf $M$ is free with basis $e_1,...,e_n$, then $\\phi $ has a matrix $A=(a_{ij})$ in this basis.\nThe module $ \\Lambda^rM$ is also free, with basis $(e_H)_{H\\in\\mathcal H}$ where $\\mathcal H$ is the set of strictly increasing sequences $H=(1\\leq i_1\\lt ...\\lt i_r\\leq n)$ and $e_H=e_{i_1}\\wedge ...\\wedge e_{i_r}$.\n\nThe key point is that with respect to this basis the linear mapping $\\Lambda^r \\phi$ has a matrix $\\Lambda^r A=B= (b_{H,K})$ and that the entries $b_{H,K}$ can be computed:\nthe result is $b_{H,K}=\\operatorname { det } (A_{H,K})$, the minor obtained by extracting from $A$ the lines numbered by $H$ and the columns numbered by $K$.\nHence we have the formula at the heart of the answer to your question $$\\operatorname { Tr }(\\Lambda^r \\phi) =\\sum_H b_{H,H}=\\sum_H \\operatorname { det }(A_{H,H})$$ From this follows the required formula for the characteristic polynomial of $\\phi$ $$ \\chi_\\phi(X)= \\operatorname { det } ( X\\cdot 1_n-A)=\\sum_{r=0}^n (-1)^r (\\sum_H \\operatorname { det }(A_{H,H}))X^{n-r} =\\sum_{r=0}^n (-1)^r \\operatorname { Tr }(\\Lambda ^r\\phi) X^{n-r} $$\n\nThe formula $b_{H,K}=det (A_{H,K})$ giving the matrix of of the exterior product of an endomorphism is very useful, in the study of Pl\u00fccker embeddings and Grassmannians for example, and is a modern avatar of the venerable Laplace expansion of determinants.\nIt is, in my opinon, underappreciated and the very notion of exterior power $\\Lambda^r A$ of a matrix $ A$ is very rarely mentioned.\n[Amusingly the notion of tensor product of matrices, aka Kronecker product, seems to have made a comeback thanks to quantum computation and quantum information]\n\n  \u2022 $\\begingroup$ Thank you Georges, I appreciate your ever elegant answers! $\\endgroup$ \u2013\u00a0Hailie Mathieson Apr 5 '12 at 19:03\n  \u2022 $\\begingroup$ I really value these kind words, @hmIII: thank you very much. $\\endgroup$ \u2013\u00a0Georges Elencwajg Apr 5 '12 at 19:50\n\nThis business about working over a commutative ring $R$ is a red herring. Ultimately this is a collection of $n$ polynomial identities in $n^2$ variables $x_{ij}$ over the integers; that is, it suffices to prove this identity over $\\mathbb{Z}[x_{ij}]$ as an equality of integer polynomials. But two integer polynomials are equal abstractly if and only if they're equal, say, when the $x_{ij}$ are set to arbitrary complex numbers. So it actually suffices to prove the identity over a specific algebraically closed field of characteristic zero such as $\\mathbb{C}$ to prove it in general.\n\nAt this point you can take any proof you like that works over $\\mathbb{C}$. Here's one:\n\n  \u2022 The identity is obvious for diagonal matrices. Since the identity is conjugation-invariant, it follows for all diagonalizable matrices.\n  \u2022 The diagonalizable matrices are dense and polynomials are continuous (alternately: the diagonalizable matrices are Zariski-dense and polynomials are Zariski-continuous), so the identity is true for all matrices.\n\nYou didn't just ask for a proof, though: you asked for an explanation. I addressed this question in another math.SE answer. Briefly, one can think of the RHS of your identity as the \"trace,\" in an appropriate sense, of the action of a linear transformation on the exterior algebra, and then the result follows for diagonalizable matrices by an observation about how the exterior algebra functor behaves on direct sums.\n\n  \u2022 $\\begingroup$ Many thanks Qiaochu, the linked question is helpful as well. $\\endgroup$ \u2013\u00a0Hailie Mathieson Apr 5 '12 at 19:04\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/11417/are-there-a-lambda-mu-expression-equivalent-to-the-yin-yang-puzzle/11421\nText:\nThe yin yang puzzle was written in Scheme. Since it uses call/cc, it is not possible to express it in a pure lambda expression, unless we do a CPS transform.\n\nHowever, given the fact that $\\lambda \\mu$-calculus have the power to model call/cc, is it possible to write an equivalent $\\lambda \\mu$-expression? I am still learning $\\lambda \\mu$-deductions, so this would be a good example to show how the deduction works.\n\nThere is no need to model the \"display\" command in a pure expression. Ideally only showing how the calculus keep looping and evaluates diffident terms again and again.\n\nUPDATE My translation in $\\lambda$-expression with CPS:\n\n(\u03bbcallcc.callcc (\u03bbyin.callcc (\u03bbyang.yin yang))(\u03bbcc.cc cc)\n\nIn CPS, (\u03bbcc.cc cc) is what \"call with current continuation\" means. So the expression takes it as a parameter. This will result in assign the sub-expression starts \u03bbyin assign its continuation into parameter yin. And then in the body, the second callcc assigns the yang of sub-expression starts \u03bbyang into itself. Finally, apply yin yang.\n\nNote the above translate is not full CPS, only the concept of call/cc has been translated. But it provides the same behavior and it is not hard to do a full CPS translate.\n\n\nYou can get an important hint to solution by thinking how to make the yin-yang puzzle work in a typed language, see this question. OCaml computes the type of yin and yang to be ('a -> 'a) as 'a, which is a recursive type equal to its own function space. Such a type is precisely what it takes to implement the untyped $\\lambda$-calculus in a typed language.\n\nWhat does this have to do with your question? In the untyped $\\lambda$-calculus (or typed calculus with general recursive types) we can define $\\mu$ and other fixed-point combinators. So, since yin and yang cannot be given types, we must use the untyped $\\lambda$-calculus, but then $\\mu$ is not needed as a primitive. In fact, the CPS transform of the puzzle will be just pure $\\lambda$-calculus.\n\nYou can compute the CPS transform in the privacy of your mind. Here is my version, written in Ocaml. To run it, you need to pass -rectypes to Ocaml:\n\nlet callcc f k = f k ;;\nlet yin c = callcc (fun x -> x x) (fun k -> print_char '@'; c k) ;;\nlet yang c = callcc (fun x -> x x) (fun k -> print_char '*'; c k) ;;\nlet _  = yin yang (fun x -> x) ;;\n\nClearly, the let statements are just a convenience. Without them, and with callcc expanded out, we get:\n\n(fun c -> (fun x -> x x) (fun k -> print_char '@'; c k))\n(fun x -> x)\n\nWe could remove the print_char statement and $\\eta$-reduce:\n\n  1. Start with:\n\n    (fun c -> (fun x -> x x) (fun k -> c k))\n    (fun x -> x)\n  2. Reduce fun k -> c k to c:\n\n    (fun c -> (fun x -> x x) c) (fun c -> (fun x -> x x) c) (fun x -> x)\n  3. Reduce fun c -> (fun x -> x x) c to fun x -> x x:\n\n    (fun x -> x x) (fun x -> x x) (fun x -> x)\n\nSo the essence of the yin-yang puzzle is just self-application of self-application. How appropriate! As a last step, we can put in the print_char statements again, to get a one-liner:\n\n(fun x -> x (fun k -> print_char '@'; x k)) (fun x -> x (fun k -> print_char '*'; x k)) (fun x -> x)\n  \u2022 1\n    $\\begingroup$ Is that you mean I don't need a \u03bb\u03bc-expression? Can you please explain how to define \u03bc since \u03bc is not a \"fixed-point combinator\", as what I know so far. $\\endgroup$ \u2013\u00a0Earth Engine Apr 20 '13 at 10:20\n  \u2022 1\n    $\\begingroup$ I may have answered the wrong question because I totally assumed $\\mu$ was a fixed point combinator. Are you referring to Parigot's $\\lambda\\mu$-calculus? In that case the answer ought to be similar, except we're not going to simulate continuations by explicit continuation passing, I suppose. The main point is that it's going to be untyped, no matter what you do. $\\endgroup$ \u2013\u00a0Andrej Bauer Apr 20 '13 at 18:01\n  \u2022 $\\begingroup$ I agreed that it is going to be untyped, and this is not what asking. But yes I am referring to Parigot's \u03bb\u03bc-calculus so \u03bc is not a fixed point combinator. I am learning it so I would like to see what the result looks like. $\\endgroup$ \u2013\u00a0Earth Engine Apr 21 '13 at 10:53\n  \u2022 $\\begingroup$ Well, you don't have to use $\\mu$ because you can do it just with $\\lambda$ (because we're untyped). Let me think what it would look like with $\\mu$. $\\endgroup$ \u2013\u00a0Andrej Bauer Apr 21 '13 at 21:31\n  \u2022 $\\begingroup$ I said I understand that we can do the same thind with \u03bb when using CPS. But CPS changes the semantic of the expression (your - an my - translated expression do not looks like or structured like the origin version any more), this is the reason why I am looking for a direct \u03bb\u03bc translation. $\\endgroup$ \u2013\u00a0Earth Engine Apr 22 '13 at 2:03\n\nYour Answer"}
{"text": "Retrieved from https://robotics.stackexchange.com/questions/19509/ik-3dof-iterative\nText:\nI want to solve for a 3dof planar arm using gradient descent to approximate end position. Now I am a little confused about the formula and was wondering if someone can help me out.\n\nThis is my thought process:\n\n  1. First start about using the forward kinematic solution mapping angles to euclidean space:\n\n    $x = l_1 * cos\\theta_1 + l_2 * \\cos(\\theta_1 + \\theta_2) + l_3 * \\cos(\\theta_1 + \\theta_2 + \\theta_3)$\n\n    $y = l_1 * sin\\theta_1 + l_2 * \\sin(\\theta_1 + \\theta_2) + l_3 * \\sin(\\theta_1 + \\theta_2 + \\theta_3)$\n\n    $\\phi = (\\theta_1 + \\theta_2 + \\theta_3)$\n\n  2. Now to I need to define a cost function ( that is where I get a little stuck), I know from a 2dof example, that I need to minimize the distance from the endpoint of my arm $x_{ep} $ to the target in euclidean space $x_{tg}$. defined as: $|| x_{ep} - x_{tg}||^2$ using gradient descent. Now, for a 3dof arm, obviously I would have an unlimited amount of solutions with this solution, so that I need to add one additional constraint, namely the angle $\\phi$ for my endeffector too. Here I am not quite sure on how to add the angle to the cost function as a parameter.\n\n  3. Then I would find the gradient function $\\nabla f_{cost} $ for each $\\theta$, in respect to my cost function, specified above using partial derivatives. $\\frac{\\partial f_{cost}}{\\partial \\theta_{1}}(|| \\begin{bmatrix} x_{ep} \\\\ y_{ep} \\\\ \\phi_{ep} \\end{bmatrix} - \\begin{bmatrix} x_{tg} \\\\ y_{tg} \\\\ \\phi_{tg} \\end{bmatrix}||^2)$, $\\frac{\\partial f_{cost}}{\\partial \\theta_{2}} ...$ , $\\frac{\\partial f_{cost}}{\\partial \\theta_{3}} ...$\n\nThen we simply try to iteratively minimize the cost function until we are below a tolerance $tol$.\n\nI know there is a missing piece, but I am not quite sure where, I believe it lies the cost function. Maybe I am wrong, thank you for your suggestions!\n\n\nIt can be demonstrated that the Gradient Descent (GD) policy corresponds to the use of the classical Jacobian transposed method for solving IK problems in robotics.\n\nThis strategy does not suffer from singularities but turns out to be slow and can get stuck in particular circumstances. More importantly, GD does not offer a principled way to deal with multiple prioritized objectives as you are looking for, instead.\n\nTo this end, you ought to make use of the Jacobian pseudoinverse $\\mathbf{J}^+$ that allows you to exploit kinematic redundancies to implement a hierarchy of tasks to be attained.\n\nIn particular, this policy can be represented by the following relation:\n\n$$ \\mathbf{\\dot{q}} = \\mathbf{J}^+ \\cdot \\left( \\mathbf{x}_\\text{tg} - \\mathbf{x}_\\text{ep} \\right) + \\left( \\mathbf{I} - \\mathbf{J}^+\\mathbf{J} \\right) \\cdot \\mathbf{\\dot{q}_0}, $$\n\n\n  \u2022 $\\mathbf{\\dot{q}}$ is the direction where to convergence iteratively (or, equivalently, the velocity that you would send to the joints).\n  \u2022 $\\left( \\mathbf{x}_{tg} - \\mathbf{x}_{ep} \\right)$ is the primary task that encodes the reaching in position.\n  \u2022 $\\mathbf{J}^+=\\mathbf{J}^T\\left(\\mathbf{J}\\mathbf{J}^T\\right)^{-1}$ is the pseudoinverse of the Jacobian of the primary task $\\mathbf{J}=\\frac{\\partial \\left( \\mathbf{x}_\\text{tg} - \\mathbf{x}_\\text{ep} \\right)}{\\partial \\mathbf{\\theta}}$ (as $\\mathbf{J}$ is not square).\n  \u2022 $\\mathbf{\\dot{q}_0}$ is the Jacobian of the secondary task \u2212 not yet specified \u2212 that encodes the reaching in orientation.\n  \u2022 $\\left( \\mathbf{I} - \\mathbf{J}^+\\mathbf{J} \\right)$ is the Null Space projection ensuring that the secondary task won't interfere with the primary task. In essence, the algorithm will provide directions that will drive the system toward both the objectives, if possible; otherwise, the primary task will take over the secondary task. Therefore, the primary task acts as a constraint in a typical optimization setting.\n\nIn our context, the simplest secondary objective $q_0$ could be:\n\n$$ q_0 = \\left( \\phi_\\text{tg} - \\phi \\right)^2. $$\n\nHence, it stems that:\n\n$$ \\mathbf{\\dot{q}_0} = \\frac{\\partial q_0}{\\partial \\mathbf{\\theta}}. $$\n\nRemarkably, $\\mathbf{J}^+$ is prone to singularities, thus it can be replaced by the Damped Least-Squares version $\\mathbf{J}_\\text{DLS}^+$ that makes the policy work very similarly to a Jacobian transposed in the neighborhood of singularities:\n\n$$ \\mathbf{J}_\\text{DLS}^+ = \\mathbf{J}^T\\left(\\mathbf{J}\\mathbf{J}^T + \\mu^2\\mathbf{I}\\right)^{-1}, $$\n\nwhere $\\mu$ is a damping factor that can be chosen as a function of the smallest singular value of $\\mathbf{J}$.\n\nInterestingly enough, we challenge students with the same exact problem during our school on robot programming \ud83d\ude09\n\n\n\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/308113/step-subcircuit-in-ltspice\nText:\nI try to simulate different MOSFET's for wich a spice model is provided by the manufacturer as a .lib file containing a subcircuit. In my schematic, the subcircuit is included with a .inc <fname> statement and used by changing the Prefix of a NMOS from M to X and setting to value to the name of the subcircuit.\n\nAll of this works, however, as I want to compare different MOSFETS, I want to step through a list of different models.\n\nI tried to use the same method as found here:\n\n  1. Define numerical models: .model 1 ako:<FET Type>\n  2. Step over the numerical models\n\nHowever, this does not work. A error \"Unknown subcircuit called\" is returned.\n\nIs there another way of stepping over different subcurcuits?\n\n\nIt's not officially supported, since LTspice flattens the schematics prior to simulation. That is, all subcircuits, hierarchies, are expanded and flattened to fit in the matrix solver, so if, for example, a second circuit that is stepped doesn't coincide element by element and node by node with the first one, then LTspice may have problems expanding the circuit \"mid-flight\".\n\nA minor proof is using any stepped subcircuit and looking at the extended netlist format, in the log, after the simulation. You'll see that the expanded subcircuit is the first one, repeated over all the steps.\n\nBut that doesn't mean it's not impossible, only that, if it fails, you shouldn't complain. First, ako only works with models, which are well-defined internally, while subcircuits can have any topology. For this, rename your subcircuits with numerals, 1, 2, 101, etc, so that they can be used with a .step variable. Then you're set, but, again, don't expect miracles. Here's a quick example:\n\n\nAlternatively, you can use switches and/or resistors that connect the subcircuits to the rest of the schematic, and step their values between 1m and 1g, for example, but that will make all the subcircuits count towards the matrix solver, even if they won't be used.\n\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/14239/functional-derivative-of-convolution\nText:\nTake the 2-minute tour \u00d7\n\nHow to carry out the following functional derivative?\n\n$$\\frac{\\delta F}{\\delta n(r)}$$ where $$F=\\int dr n(r) \\int C(|r-r'|) n(r') dr'$$\n\nis it simply: $$2 \\int dr' C(|r-r'|) n(r')$$?\n\nshare|improve this question\nThe answer to the question (v1) is Yes. \u2013\u00a0 Qmechanic Sep 1 '11 at 18:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nNotice that $F$ is essentially a quadratic form; i.e. if it were matrices then you would have (in summation notation): $$F = x_i C_{ij} x_j.$$ Then you would use the fact that $\\frac{\\partial x_i}{\\partial x_j} = \\delta_{ij}$ to get \\begin{align} \\frac{\\partial F}{\\partial x_k} &= \\delta_{ik} A_{ij} x_{j} + x_i A_{ij} \\delta_{jk} \\ &= 2 A_ik x_k \\end{align} if $A_{ij} = A_{ij}$ i.e. it is symmetric.\n\nHere, we use a similar fact: $$\\frac{\\delta n(x)}{\\delta n(y)} = \\delta(x-y)$$ where $\\delta$ this time is the Dirac distribution. Your \"matrix\" in the middle is obviously symmetric, so your proposed answer is correct.\n\nshare|improve this answer\nThanks, that makes sense. Cheers Biosftw \u2013\u00a0 Biosftw Sep 1 '11 at 18:37\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/171807/positive-primes-represented-by-indefinite-binary-quadratic-form?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nNeil Sloane asked me about commands in computer languages to find the (positive) primes represented by indefinite binary quadratic forms. So I wrote something in C++ that works. This is for the OEIS, these primes go into sequences... Note that, within a few hours, another guy had run the tables much higher with a one-line Maple command. Some days it does not pay to get up.\n\nI thought of one I really do not understand. Discriminant $205$ has four classes of forms, $$ \\langle 1, 13, -9 \\rangle, \\; \\langle -1, 13, 9 \\rangle, \\; \\langle 3, 13, -3 \\rangle, \\; \\langle -3, 13, 3 \\rangle. $$\n\nThe third and fourth are opposites so in the same genus, although distinct. The first two are in the principal genus, but they are not opposites, one is $-1$ times the other; in particular, they get diffeent positive primes, although both do residues $\\pmod 5$ and $\\pmod {41}.$ For $\\langle 1, 13, -9 \\rangle$ we get $$ 1,5,59,131,139,241,269,271,359,409, \\ldots, $$ while for $\\langle -1, 13, 9 \\rangle$ we get $$ 31,41,61,251,349,379,389,401,419,431, \\ldots. $$\n\nFor positive forms, low class number, there are polynomials, such as in Cox's book, such that primes represented by the principal form are those for which the polynomial factors a certain way. For a prime $p \\equiv 1 \\pmod 3,$ Gauss showed that $2$ is a cubic residue if an only if $p = u^2 + 27 v^2.$ Jacobi showed that $3$ is a cubic residue if an only if $p = u^2 + uv + 61 v^2.$ All I found in Henri Cohen's tables was the fact that $\\mathbb Q(\\sqrt {205})$ has class number $2$ and $L_K = \\mathbb Q(\\sqrt 5),$ appendix 12C on pages 533 and 534. See related information at IT'S A LINK.\n\nLet's see, $34$ is the smallest number where it is a surprise that there is no solution to $x^2 - 34 y^2 = -1.$ The smallest such odd number is $205,$ as there is no solution to $x^2 - 205 y^2 = -1.$ For prime $p \\equiv 1 \\pmod 4,$ there is always a solution to $x^2 - p y^2 = -1.$ Proof in Mordell's book. Anyway, this is why $\\langle 1, 13, -9 \\rangle, \\; \\langle -1, 13, 9 \\rangle$ are distinct classes.\n\nSo, that is the question, can I distinguish the represented (positive) primes by factoring some polynomial mod these primes?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 13 down vote accepted\n\nClass field theory promises such a polynomial (more properly, such a number field $H$, since a polynomial generating $H$ might have to err on the first few primes, though in our case it turns out there's a polynomial with no exceptional primes). The proof is effective, though the recipe is often hard to carry out. So I attempted an end run by asking this database for number fields of degree $8$ and discriminant $205^4$, and was rewarded with $$ x^8 + 15 x^6 + 48 x^4 + 15 x^2 + 1, $$ which generates an unramified normal extension $H \\, / \\, {\\bf Q}(\\sqrt{205})$ with the right Galois group. This polynomial matches your list exactly: the gp code\n\n   f = factormod(x^8+15*x^6+48*x^4+15*x^2+1, p)[,1];\n\nreturns your 5, 59, 131, 139, 241, 269, 271, 359, 409, and then continues 541, 569, 599, 661, 701, 761, 859, 881, 911, 941, still in exact agreement with the list of primes represented by $u^2 + 13uv - 9v^2$.\n\n[added later] That gp code checks whether all factors of $P_8(x) := x^8 + 15 x^6 + 48 x^4 + 15 x^2 + 1 \\bmod p$ have degree $1$. Since the polynomial is Galois, it would have been sufficient to check that one factor is linear:\n\n   if(poldegree(factormod(x^8+15*x^6+48*x^4+15*x^2+1, p)[1,1])==1, print(p))\n\n(I \"cheated\" a tad by excluding $p=2$, which is a factor of the discriminant of $P_8$ but not of the number field.) The Galois group of $P_8$ is dihedral, so one can find a quartic polynomial $P_4$ with the same Galois closure that factors completely mod $p$ iff $P_8$ does; such a polynomial was exhibited by NAME_IN_CAPS answering the follow-up Question 171846. Alternatively, we know already that $p$ is (either $5$ or) a quadratic residue of both $5$ and $41$, so by Quadratic Reciprocity $5$ and $41$ have square roots mod $p$, which means that $p$ factors completely in ${\\bf Q}(\\sqrt{5},\\sqrt{41})$. And indeed $x^2$ generates that field and equals (some conjugate of) $$ -\\frac14 (15 + 3 \\sqrt{5} + \\sqrt{41} + \\sqrt{205}); $$ so you can also test whether $p$ is represented by $u^2 + 13uv - 9v^2$ by computing $\\sqrt{5} \\bmod p$ and $\\sqrt{41} \\bmod p$ (if they don't exist then there's no representation), and then testing whether $-(15 + 3 \\sqrt{5} + \\sqrt{41} + \\sqrt{205})$ is a square mod $p$.\n\nshare|improve this answer\nFor the very similar discriminant 221 and $x^2 + 13 x y - 13 y^2, $ I was surprised to find that $$ f(x) = x^8 + x^6 - 4 x^5 - 38 x^4 - 2 x^3 + 123 x^2 -34 x + 17, $$ has a repeated root $\\pmod {101},$ although still linear factors, seven of them with one of them squared. Is that allowed? After that it is always 8 roots. This time the primes are $ 17,101,103,127,179,251,263,373,433,$ \u2013\u00a0 Will Jagy Jun 15 at 20:47\nFor 221, the quartic $$ x^4 + x^3 + x^2 + 2 x + 4 $$ behaves well \u2013\u00a0 Will Jagy Jun 15 at 20:57\nThe repeated root mod $101$ is an example of my warning that \"a polynomial generating [the Hilbert class field] $H$ might have to err on the first few primes\" if $H$ has no generator $x$ such that ${\\bf Z}[x]$ is the full ring of integers of $H$. A better choice for this purpose is $x^8 + 34 x^6 + 83 x^4 + 34 x^2 + 1$, which has spurious repeated roots only mod $2$ and $3$ (and as it happens no linear factors modulo either of these primes). Then $x+1/x$ generates a quartic isomorphic with the one you found with coefficients $1,1,1,2,4$. \u2013\u00a0 Noam D. Elkies Jun 15 at 22:14\nCool. Thanks, Noam. That does look much better. I found my degree eight on that website you mentioned, by putting in $221^4.$ Actually, the first time it thought i meant 2214 and complained. i decided it was better to multiply out the number. \u2013\u00a0 Will Jagy Jun 15 at 22:17\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/20622/how-to-compute-drag-coefficient-given-initial-position-initial-velocity-and-fin\nText:\nTake the 2-minute tour \u00d7\n\nThe equations I'm using are:\n\nx = x + (DT * vx)\nvx = vx * C\n\nMy DT is always 0.01 and the coefficient C (related to a linear drag coefficient, as mentioned in the comments) is greater than 0 and less than 1. The above will keep happening until x naturally reaches its limit.\n\nWhat I want is an equation to find C given the other three inputs: initial x, initial velocity x and final resting x(this is where the object has come to a stop and vx = 0). Right now it's tedious because I have to plug in ix, ivx and C and run my simulation to see where the object stops. Then I have to do further tweaking to get exactly what I'm looking for.\n\nHere are some samples:\n\ninitial x = 3.5\nvelocity x = -12.0\nacceleration = 0.92\nfinal resting x = 2.0\n\ninitial x = 3.5\nvelocity x = -14.0\nacceleration = 0.92\nfinal resting x = 1.75\n\nFor example(from the first dataset), we start at 3.5 we want to end at 2.0 and our velocity is -12.0 .. what do we need to use for C?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nBasically what you're doing is calculating a discrete time series: you're finding an discrete series of positions $x_n$ (where $n\\in\\mathbb{Z}_+$) which are paired with times $t_n = t_0 + n\\Delta t$. But there are a couple of ways you could interpret this time series, and the formula you're looking for depends on which one you use.\n\nExact positions\n\nOne option is to say that $x_n$ represents the exact position of the particle at time $t_n$. In order to find the asymptotic position as $n\\to\\infty$ (that is, the position where the particle stops), you need to convert your iterative formulas,\n\n$$\\begin{align}x_n &= x_{n-1} + v_{n-1}\\Delta t \\\\ v_n &= Cv_{n-1}\\end{align}$$\n\ninto direct formulas. Hopefully you can see that, because the speed gets multiplied by $C$ at every step, the speed at the $n$'th step will be given by\n\n$$v_n = C^n v_0$$\n\nThen figuring out the formula for $x_n$ is probably most easily done by finding a pattern:\n\n$$\\begin{align}x_1 &= x_0 + v_0\\Delta t \\\\ x_2 &= x_1 + v_1\\Delta t \\\\ &= x_0 + v_0\\Delta t + Cv_0\\Delta t \\\\ x_3 &= x_2 + v_2\\Delta t \\\\ &= x_0 + v_0\\Delta t + Cv_0\\Delta t + C^2v_0\\Delta t\\end{align}$$\n\nYou wind up with\n\n$$x_n = x_0 + v_0\\Delta t \\sum_{k=0}^{n}C^k$$\n\nIn the limit as $n\\to\\infty$, this simplifies to\n\n$$x_\\infty = x_0 + \\frac{v_0\\Delta t}{1-C}$$\n\nwhich you can solve for $C$. This equation reproduces the sample results you listed.\n\nIt's important to note that the value of $C$ you get from this interpretation depends on your choice of $\\Delta t$. To simulate the same motion using a different time step, you'll need to change the value of $C$. Only the ratio $\\frac{\\Delta t}{1-C}$ is fixed.\n\nDiscrete approximation\n\nThe other way in which one could interpret your time series is as a discrete approximation to some continuous function $x(t)$ that describes the actual motion. If you find it strange that the result depends on the time step $\\Delta t$, this might be worth looking into.\n\nTo motivate this interpretation, you need to know something about finite difference approximations. In a nutshell, when you want to use a computer to numerically solve a differential equation, you can replace the derivative operator with a finite difference operator:\n\n$$\\frac{\\mathrm{d}f}{\\mathrm{d}t} \\to \\frac{f(t + \\Delta t) - f(t)}{\\Delta t}$$\n\nThe thing on the right here is merely the simplest example of a finite difference operator. (It also happens to be quite inaccurate.) This particular one looks a lot like the definition of the derivative, except that $\\Delta t$ is finite, not infinitesimal (hence the name).\n\nYour iteration equations can be written in the form\n\n$$\\begin{align}\\frac{x_n - x_{n-1}}{\\Delta t} &= v_{n-1} \\\\ \\frac{v_n - v_{n-1}}{\\Delta t} &= \\frac{C - 1}{\\Delta t}v_n\\end{align}$$\n\nYou can assume that this is the finite difference approximation to some exact differential equation, and work backwards to find the equation. For example, by replacing the finite difference operator in the position equation with a derivative, you get\n\n$$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = v(t)$$\n\nIf you try to do the same thing with the velocity, well, you can't, because the right side doesn't have a defined limit as $\\Delta t\\to 0$. But there are a couple of little hacks you can use, for example: choose some characteristic time scale $\\tau$ and set $\\Delta t = \\tau$ on the right, while still taking the limit on the left. You wind up with\n\n$$\\frac{\\mathrm{d}v}{\\mathrm{d}t} = \\frac{C - 1}{\\tau}v(t)$$\n\nSolving this differential equation gives you\n\n$$\\begin{align}v(t) &= v(0)e^{-t(1-C)/\\tau} \\\\ x(t) &= x(0) + \\frac{v(0)\\tau}{1-C} \\bigl(1 - e^{-t(1-C)/\\tau}\\bigr)\\end{align}$$\n\nand in the limit as $t\\to\\infty$,\n\n$$x(\\infty) = x(0) + \\frac{v(0)\\tau}{1-C}$$\n\nwhich, again, you can solve for $C$. It turns out to be the same thing as before, only with $\\tau$ instead of $\\Delta t$. This is only the case because this is an exceptionally simple equation, and because of the particular way in which I chose to define the time scale $\\tau$. In general, these two methods won't give identical results, in part because of the inaccuracies of the particular finite difference approximation I used.\n\nshare|improve this answer\nThank you. Is it possible to implement this type of motion without it being dependent on the DT? \u2013\u00a0 Ryan Feb 7 '12 at 6:49\nNo, there's no way to avoid introducing a time scale of some sort if the particle is going to come to rest. \u2013\u00a0 David Z Feb 7 '12 at 7:21\nadd comment\n\nIntegrate with respect to the time. One problem is that if you change DT, you will get a different result, since acceleration does not change with DT, although it should.\n\nYour formulas written as functions:\n\n$$ x(t) = x_0 + \\int_0^t v(t) \\cdot \\mathrm dt $$\n\n$$ v(t) = v_0 \\cdot a^t $$\n\nCombining those yields:\n\n$$ x(t) = x_0 + \\int_0^t v_0 \\cdot a^t \\cdot \\mathrm dt $$ $$ x(t) = x_0 + v_0 \\int_0^t e^{\\log(a)t} \\cdot \\mathrm dt $$ $$ x(t) = x_0 + v_0 \\left[ \\frac{1}{\\log(a)} e^{\\log(a)t} \\right]_0^t $$ $$ x(t) = x_0 + v_0 \\frac{1}{\\log(a)} (a^t - 1)$$\n\n$\\log(a)$ is negative, so for $t \\to \\infty$ you should get:\n\n$$ \\lim_{t \\to \\infty} x(t) = x_{\\mathrm{final}} = x_0 + v_0 \\frac{1}{\\log(a)} (0 - 1)$$ $$ x_{\\mathrm{final}} = x_0 - v_0 \\frac{1}{\\log(a)}$$\n\nThe greater your $a$ is, the less far the particle will have made it. Sounds reasonable.\n\nIf you have a $\\mathrm dt = 0.01$ seconds, you will have a factor of $a^{100}$ per second. So for your $a = 0.92$ I would instead use $a^{100} = 0.000239212$ as $a$.\n\nWhen I put this into my formula, I get:\n\n$$ x_{\\mathrm{final}} = 3.5 - (-12.0) \\frac{1}{\\log(0.000239212)} = 2.0608 $$\n\n$$ x_{\\mathrm{final}} = 3.5 - (-14.0) \\frac{1}{\\log(0.000239212)} = 1.82097 $$\n\nI am not sure whether the formula is wrong or whether your program just makes rounding errors (as usual with numeric calculations).\n\nshare|improve this answer\nThank you for the detailed derivation, but I realize I only need a coefficient of friction. See my comment to my original question up top. \u2013\u00a0 Ryan Feb 6 '12 at 23:54\nThere were some edits made to the question, in case you'd like to update your answer to reflect them. \u2013\u00a0 David Z Feb 7 '12 at 3:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/1283/permutationsrange12-produces-an-error-instead-of-a-list/1362\nText:\nTake the 2-minute tour \u00d7\n\nThis input:\n\n\nResults in this (error) output:\n\n  The result of evaluating Permutations[{1,2,3,4,5,6,7,8,9,10,11,12}] \n  would be a packed array with 5748019200 elements, but the number of elements \n  in a packed array must be a machine integer. >>\n\nThat number (5748019200) is interesting, because it's exactly 12 times 12! (that's factorial, not exclamation point)\n\nPresumably, Mathematica is trying to store all 12! length 12 lists in a single monolithic array. I can imagine this failing.\n\nUsually, Mathematica shields me from these types of problems. For example, I had no trouble calculating 12*12!.\n\nMy intention is to Select some elements from this list, so I don't need to have every permutation in memory at once.\n\nQuestion: Is there a different way to generate the permutations that avoids this problem?\n\nshare|improve this question\nRun the same code on a 64-bit machine ;-) Seriously though, it is possible to iterate over permutations but I'm not sure if the algorithm is implemented directly in Mathematica. \u2013\u00a0 David Z Feb 4 '12 at 3:28\n@David It doesn't work on a 64-bit machine either. Harold: Apparently the maximum size of a packed array is 2^31-1. This is a huge array: a 2^31 - 1-element packed array of machine integers (i.e. assuming the most efficient storage possible) would take up 8 GB of contiguous memory. You need to have a lot of memory in your computer to be able to store such an array (definitely much more than 8 GB because of the contiguous memory block requirement) \u2013\u00a0 Szabolcs Feb 4 '12 at 20:13\nadd comment\n\n3 Answers\n\nup vote 7 down vote accepted\n\nCombinatorica` has the function NextPermutation which allows you to iterate over the permutations. There may be ways of generating a smaller subset if you have more information about what you are looking for.\n\nshare|improve this answer\nOn that note: the algorithms in Combinatorica are based on old FORTRAN routines discussed in this book; OP might want to take a look at the book and see what other strategies might be appropriate for his circumstances. \u2013\u00a0 \uff2a. \uff2d. Feb 4 '12 at 3:48\n@J.M., that book looks to be a tremendous resource. I'm glad I asked this question now. \u2013\u00a0 Harold Feb 4 '12 at 4:52\n@Harold note, the functionality in Combinatorica` is being slowly folded into the kernel functions. So, loading it will give a warning message to that effect, but NextPermutation doesn't (yet?) seem to have been moved over. \u2013\u00a0 rcollyer Feb 4 '12 at 4:55\n@J.M. Thanks a lot for the link to that book. Looks excellent \u2013\u00a0 TomD Feb 4 '12 at 9:34\nadd comment\n\nConsider than the permutations of {1, 2, 3, 4, 5} are each of the permutations of {1, 2, 3, 4} with 5 inserted at each possible place. One can therefore examine the permutations of {1, 2, 3, 4, 5} in blocks like this:\n\np4 = Permutations@Range@4;\n\n  ReplaceList[x, {h___, t___} :> {h, 5, t}],\n  {x, p4}\n\nFor example, making a certain selection:\n\n    # + #2 - #3*#4/#5 > 7 & @@ # &\n  {x, p4}\n\nThe same can be applied to the permutations of Range@12.\n\nshare|improve this answer\nadd comment\n\nWell from computational point of view, if you wanted the whole list or some part of it then the size of output would be the main problem.\n\nAssuming plaintext output is used ... by my rough estimation it would take over 225 GB (gigabytes) to store the whole list on a disk. Furthermore it would take about 4 days to compute them all on this laptop.\n\nYou need data like:\n\nfilename = \"f://out.txt\";\nseed = Range[12];\nsize = 10;\n\nRecursive method call like:\n\nseed = MPermutations[seed, size, filename]\n\nOther useful lines:\n\n\nThis is an example of what MPermutations could look like if flat file output is used. It computes next count number of permutations of list, prints them in filename and returns the last element.\n\nMPermutations[list_, count_Integer, filename_String] := Module[\n  {n = 1, current = list},\n   n < count, current = NextPermutation[current];\n   Write[filename, current]];\n\nReturn result is needed to make recursive method call possible. Recomputing that line will add next size amount of results to file (assuming that data is in a different cell).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/248966/2-connected-planar-graph-and-vertex-degree\nText:\nTake the 2-minute tour \u00d7\n\nIf $G$ is a 2-connected loopless planar graph, and for each vertex $v$ we define: $f(v) = (1/2) - (1/deg(v))$, where $deg(v)$ is the degree of vertex $v$,\n\nShow that for some region $R: \\sum f(v) < 1 $, where the sum is over all vertices $v$ incident with $R$.\n\nI'm confused about how to go about this. Some properties that could be relevant are:\n\n  \u2022 for 2-connected planar graphs, every region is bounded by a cycle\n  \u2022 $12 \\leq \\sum [6 - deg(v)]$ so $\\sum deg(v) \\leq 6|V(G)| - 12$\n  \u2022 $\\sum deg(v) = 2 |E(G)| $\n  \u2022 every region is clearly bounded by at least 3 edges and thus has at least 3 vertices incident to it\n  \u2022 for 2-connected graphs, every vertex has $deg(v) \\geq 2$\n\n    Anyone have ideas?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nLet us denote the sum for a region as $$F(R) = \\sum_{v\\in R}f(v)$$ Consider the sum of $F$ over all regions of the graph. There are $\\deg v$ faces incident with each vertex so each $f(v)$ is counted precisely $\\deg v$ times. $$\\sum_{R\\in G}F(R) = \\sum_{v\\in G} f(v)\\deg v=\\sum_{v\\in G}\\left(\\frac{\\deg v}{2}-1\\right)$$ From the handshaking lemma, this is equal to $$\\sum_{R\\in G}F(R)=|E| - |V|$$ From Euler's formula $$|E|-|V| = |R|-2$$ where $|R|$ is the number of regions. Therefore the average of $F$ over the regions $$\\overline{F(R)} = \\frac{|R|-2}{|R|}<1$$ is less than $1$. Therefore there must exist at least one region for which $F(R)$ itself is less than $1$.\n\nshare|improve this answer\nthank you! the trick here was to see that there are deg(v) faces incident with each vertex. I'm assuming thats because the graph is 2-connected? \u2013\u00a0 DustinH Dec 2 '12 at 15:53\nYes, it's necessary for the graph to be 2-connected. You may want to prove that fact just to be complete. \u2013\u00a0 EuYu Dec 2 '12 at 18:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/4800/choosing-solutions-for-the-intersections-of-n-number-of-circles\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I have an number of distances from an unknown location to a known location. I can use these distances and the known locations to draw a number of circles. The point where all the circles intersect is my unknown location. This is easy to solve. However, if my distance measurements have some error, I will get a cluster of points around my unknown location. The question is, for each pair of intersection points, how can I tell which solution is closer to my unknown point?\n\nEvery solution I have come up with involves many special cases, such as when all the known locations are inside one circle, or all the known locations are co-linear, and so on, buy I am hoping to come up with a more elegant solution.\n\n\nLets make this more simple. I have 2 circles that have at most 2 intersection points. If they don't intersect, I can easily choose the point between them. If they do intersect at 2 points, how can I use a third circle to choose which one of these 2 intersections is the correct one?\n\nMy current plan is to do a comparison between the distance between the radius of the third circle and the intersection points and choose the smaller one. The problem with this is that I don't know how much error this approach can tolerate before you choose the wrong side. If I knew that, I could put a goal on my measurement method to try to reduce the error by X%\n\nshare|improve this question\nThe Wikipedia page for GPS suggests that such a system can be solved using a generalization of Newton's method. \u2013\u00a0 Isaac Sep 16 '10 at 18:27\nadd comment\n\n1 Answer\n\nOne handles error with a probability model. In this case, the typical error in a distance measurement is likely proportional to the distance itself. The errors themselves are often thought of as accumulated small nearly independent errors, allowing one to invoke the Central Limit Theorem and suppose, at least as a reasonable hypothesis, that the errors are normally distributed. We usually assume there's no systematic bias in the errors: they should average out to zero in principle. A simple model is obtained by supposing the errors are independent. (Other suppositions can be treated, depending on how the measurements were made, but it quickly gets complicated.)\n\nThis leaves us with just three unknowns to estimate: the true coordinates $(x,y)$ of your location and the precision of the relative errors, usually expressed as their (common) standard deviation $\\sigma$. Your data consist of $n$ measured distances to the known locations $(x_i, y_i)$, say $d_i, i = 1 \\ldots n$. Mathematically, these assumptions translate to the following. The probability of observing $d_i$ equals\n\n$$\\frac{1}{\\sqrt{2 \\pi} \\sigma \\delta_i} \\exp \\left( -\\frac{(d_i - \\delta_i)^2}{2 \\sigma^2 \\delta_i^2)} \\right)$$\n\nwhere $\\delta_i = \\delta_i(x,y) = \\sqrt{(x - x_i)^2 + (y - y_i)^2}$.\n\nThe probability of your data $(d_1, d_2, \\ldots, d_n)$ is the product of these probabilities. This is the likelihood.\n\nOne reasonably tractable estimator maximizes the likelihood (as a function of the unknown parameters $x$, $y$, and $\\sigma$). This is usually done by maximizing the negative logarithm of the likelihood, which will be a sum of terms, one for each data value. It's nonlinear and a little nasty, but we know geometrically that there will be at least one global optimum and, quite likely, exactly one. Many methods exist to solve this, available in statistical packages, numerical optimization routines, and general-purpose math software like Mathematica.\n\nOf course the optimal arguments $(x,y)$ tell you where your location likely is. The optimal value of $\\sigma$ estimates the typical relative error in the distance measurement: you can check that it's a reasonable value. There are ways to extract confidence intervals for all three parameters (from the Hessian of the log likelihood). A joint confidence interval for $(x,y)$ gives you an ellipse in which the true point is likely to be. Statistical packages will give you this information. If you are doing this by hand, you can analyze any other candidate solution $(x',y')$, such as the intersection of a few circles, by evaluating the likelihood there and comparing it to the optimum likelihood. If the logarithms differ by less than $2$, the candidate solution is consistent with the data.\n\nBTW, as you've seen, you're practically forced to take a statistical approach. With real data you find that some circles don't even intersect and that overall the set of data has little or no internal consistency. You have to model the error somehow.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/97965/solve-drag-equation-for-previous-timestep?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am working on a series of equations to calculate the trajectory of a projectile in reverse. For example, given the ground impact angle and velocity, calculate the flight of the projectile. Here is the equation to calculate the drag on a projectile in normal flight (not reversed yet):\n\n$$ x_2=x(1-k\\sqrt{x^2+y^2}) $$ $$ y_2=y(1-k\\sqrt{x^2+y^2}) $$\n\n$x$ and $y$ are the before-drag velocities, and $k$ is a constant that includes the fluid density, reference area, drag coefficient, and timestep. The result, $x_2$ and $y_2$, are the after-drag velocities. On my graphing calculator, including these functions in a program creates a nice-looking trajectory. However, to reverse the formula, I need to solve the above equations for $x$ and $y$. Given the resulting velocity, find the velocity at the previous timestep. I am at a loss on how to do this.\n\nPut simply, solve the above 2 equations for $x$ and $y$.\n\nAny help will be appreciated.\n\nshare|improve this question\nCould you please explain exactly what you're trying to do? Are the $x,y$'s infinitesmal quantities that are evaluated at each time step and then summed up (integrated) to calculate the trajectory? If so, what integration scheme are you using? \u2013\u00a0 yohBS Jan 10 '12 at 20:47\n@yohBS I don't understand exactly what you are saying (I'm in 10th grade). Every timestep, $x_2$ times the timestep is added to the x position of the projectile, and $y_2$ times the timestep is added to the y position. Then, $x$ and $y$ are set equal to $x_2$ and $y_2$ for the next timestep. Hope this helps. \u2013\u00a0 Joel Jan 10 '12 at 21:11\nYou just do what you would do as if time was running forwards, but change the sign of the drag $k$ (is the opposite of drag shove?) and the two \"after-drag velocities\", so the projectile goes up and backwards with extra shove. \u2013\u00a0 Henry Jan 10 '12 at 22:50\n@Henry Changing the sign of $k$ doesn't work. That is applying negative drag to $x_2$ and $y_2$. For the equations to work, the drag must be applied to $x$ and $y$. \u2013\u00a0 Joel Jan 11 '12 at 16:11\nadd comment\n\n1 Answer\n\nIt helps to write down the equation in vector form: $$\\mathbf v_2=(1-k|\\mathbf v|)\\mathbf v\\tag1$$ This shows that $\\mathbf v_2$ is a scalar multiple of $\\mathbf v$ (no surprise there). Take the magnitude on both sides of(1): $$|\\mathbf v_2|=(1-k|\\mathbf v|)|\\mathbf v|\\tag2$$ Here I assume that $1-k|\\mathbf v|\\ge 0$, that is the velocity does not change direction due to drag. This is physically reasonable. Equation (2) is quadratic for $|\\mathbf v|$, with the solution $$|\\mathbf v|=\\frac{1-\\sqrt{1-4k|\\mathbf v_2|}}{2k} \\tag3$$ Thus, to obtain $\\mathbf v$ from $\\mathbf v_2$, we should divide $\\mathbf v_2$ by its magnitude, and the multiply the result by the right side of (3): $$ \\mathbf v =\\frac{1-\\sqrt{1-4k|\\mathbf v_2|}}{2k |\\mathbf v_2|}\\mathbf v_2 $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166294/condition-to-have-unique-solution\nText:\nTake the 2-minute tour \u00d7\n\nConsider $\\Delta u =f(x) , x \\in \\Omega $ and $\\nabla u\\cdot n +\\alpha u = g(x) , x\\in \\partial\\Omega $, where $n$ is outward normal. Can anyone give me a hind how to find sufficient condition on $\\alpha$ so that the solution is unique. Thanks\n\nshare|improve this question\nwhat do you mean by $\\nabla\\cdot n$? Do you mean $\\nabla u\\cdot n$ instead? \u2013\u00a0 Paul Jul 3 '12 at 21:22\n@Paul : thanks for pointing out. \u2013\u00a0 Theorem Jul 3 '12 at 21:24\nFor future reference, you should write the operators as \\Delta and \\nabla instead of \\triangle and \\triangledown. \u2013\u00a0 Rahul Jul 3 '12 at 21:50\n@RahulNarain : thank you , i didn't know that . \u2013\u00a0 Theorem Jul 3 '12 at 21:51\nadd comment\n\n2 Answers\n\nI think the condition is $\\alpha \\geq 1,$ which you need for coercivity of the bilinear form, which in turn can be got by using the fact that$$\\lVert \\nabla u \\rVert_{L^2(\\Omega)}^2 + \\lVert u \\rVert^2_{L^2(\\partial\\Omega)} \\geq C\\lVert u \\rVert_{H^1(\\Omega)}^2$$ for every $u \\in H^1(\\Omega).$\n\nAdded: If you multiply by a test function $v \\in H^1(\\Omega)$ and IBP, you get $$\\int_\\Omega{\\nabla u \\nabla v} - \\int_{\\partial\\Omega}{v\\nabla u \\cdot \\nu} = \\int_\\Omega{-fv}$$ where $\\nu$ is the normal. Plugging in your boundary condition and moving the term involving $g$ on the other side: $$\\int_\\Omega{\\nabla u \\nabla v} + \\alpha\\int_{\\partial\\Omega}{uv} = \\int_{\\partial\\Omega}{gv} - \\int_\\Omega{fv}$$ So your bilinear form $b(u,v)$ (for Lax-Milgram) is the LHS. For coercivity, we need $$b(v,v) \\geq C_1\\lVert v \\rVert^2_{H^1(\\Omega)}$$ for some $C_1$. We have $$b(v,v) = \\lVert \\nabla v \\rVert^2_{L^2(\\Omega)} + \\alpha \\lVert v \\rVert^2_{L^2(\\partial\\Omega)},$$ which implies coercivity if $\\alpha \\geq 1$ because you can use the statement I gave at the top of this post.\n\nshare|improve this answer\nSir , can you tell me how can i get the condition on $\\alpha$ using the fact that u have given ? \u2013\u00a0 Theorem Jul 4 '12 at 3:19\n@Theorem I updated the answer. \u2013\u00a0 Court Jul 4 '12 at 7:16\n@Court I would like to add to Court's solution. A sharper condition is $\\alpha > 0$. Just note that $$ b(v,v) \\ge \\min \\{1, \\alpha \\} (\\| \\nabla v \\|_{L^2 (\\Omega)} + \\| v \\|_{L^2(\\partial \\Omega)} \\ge \\min \\{1, \\alpha \\} C \\| u \\|_{H^1(\\Omega)}$$ \u2013\u00a0 D... Jan 5 at 16:42\nadd comment\n\nI think that this paper can be very useful and essentially contains the answer.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/273000/is-it-possible-to-reverse-this-sequence-of-permutations\nText:\nTake the 2-minute tour \u00d7\n\nLet $ S = (a_1, a_2, ..., a_N) $ be a finite (arbitrarily long) sequence of elements, and let $p_1, p_2, ..., p_n $ be the first $n$ prime numbers, with $n \\ge 3$.\n\nWe apply a sequence of permutations to $S$ as follows.\n\nFirst, we take every element in $S$ whose index is congruent with 1 modulo 2, and we rotate them within themselves $A^2_1$ positions (where $A^2_1$ is an integer in $[0, N/2)$). For instance, if $S = (a,b,c,d,e,f)$, and $A^2_1=2$, the result would be $(\\mathbf c,b,\\mathbf e,d,\\mathbf a,f)$.\n\nIn the second place, we take every element in the sequence obtained whose index is congruent with $0$ (that is, the rest), and rotate them within themselves $A_0^2$ positions (where $A^2_0$ is an integer in $[0,N/2)$); that will be $S_1$. Following the previous example, rotating with $A^2_0 = 1$ would bear $S_1 = (c,\\mathbf f,e,\\mathbf b,a,\\mathbf d)$.\n\nNow, we take every element in $S_1$ with index congruent with 1 modulo 3, and we rotate them within themselves $A^3_1$ positions; afterwards, every element with index congruent with 2 modulo 3, $A^3_2$ positions, and finally, every element with index congruent with 0 modulo 3, $A^3_0$ positions. $A_i^3$ is an integer in $[0,N/3)$. Continuing the example, assuming $A^3_1 = 1, A^3_2 = 0, A^3_0 = 1$, we would obtain $(b,f,d,c,a,e)$.\n\nThis process is repeated for every prime up to $p_n$, and let $S_n$ be the result.\n\n(Edited: see below) My question is: assuming $n$ and $S_n$ are known, how much additional information would be necessary to calculate the coefficients? (Edited: see below) By additional information I mean, for example, knowing the initial positions (in $S$) of some elements in $S_n$. I have been working for days on this, but my current option, which is straightforward using systems of equations, does not seem t otake me anywhere since I don't know which coefficients are being used in each case. Is there any other approach that I should consider?\n\nApologies for my English, and sorry if this is not the correct stackexchange site for this question.\n\nEDIT: As Alexander pointed, coefficients would not be unique (see his example below), so to state it more accurately: would it be possible to obtain the original $S$ given $n, S_n$, and some additional information?\n\nThis problem is related to a cryptography project, where I intend to cypher a message by rearranging it, using coefficients as a key. This means that, even if the original permutation (or any complete set of coefficients) were impossible to find, any way to determine information on them, or bounding them, would greatly hurt the scheme. I know this is not the place for crypto problems, but maybe explaining the objective would be useful to anyone trying to answer.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nIf I understand correctly, we can take $$(a_1,\\ldots,a_{12})$$ and pick primes $2,3$. Then we can set $A_0^2=A_1^2=3$ and $A_0^3=A_1^3=A_2^3=2$ and the permutation produced by the algorithm is the identity permutation, the same as if we had chosen $A_0^2=A_1^2=A_0^3=A_1^3=A_2^3=0$.\n\nSo even if you have $S_n$, $n$, and the initial position of each $a_i$, you can still in general have multiple solutions. I would say there is no way to determine the coefficients $A_i^j$ uniquely.\n\nI realize that you said $n\\geq 3$, but the above example is illustrative. Note that even for $n\\geq 3$ and even if you insist that $N=\\prod_{i=1}^np_i$ (which is the minimum value of $N$, since $N$ must be divisible by each $p_i$) this does not change. When $n=3$ and $N=30$, we can set $A_0^2=A_1^2=3$ and $A_0^3=A_1^3=A_2^3=8$ and $A_0^5=A_1^5=A_2^5=A_3^5=A_4^5=0$ and obtain the identity permutation, as well as $A_0^2=A_1^2=A_0^3=A_1^3=A_2^3=6$ and $A_0^5=A_1^5=A_2^5=A_3^5=A_4^5=0$.\n\nThe permutations are unique for the case where $n=2$ and $N=6$, in which case the possible permutations correspond to the unique subgroup of $S_6$ of order $72$. But this is the only such case.\n\nshare|improve this answer\nThank you, Alexander! Great point on lack of unicity, I hadn't noticed that. Probably, even if the coefficients are forced to be all different, unicity still won't be possible; I'll look into that! On the other hand, my (admittedly unstated... sorry!) intention with this question was to \"undo\" the permutation. I hurried to assume unicity of the coefficients, which I thought would be equivalent with \"undoing\" the transformations, but I am going to edit the question to further clarify. Thank you for your time! :) \u2013\u00a0 Carlos Jan 9 '13 at 12:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.co.uk/help/optim/ug/minimization-with-gradient-and-hessian.html?nocookie=true\nText:\nDocumentation Center\n\n  \u2022 Trial Software\n  \u2022 Product Updates\n\nMinimization with Gradient and Hessian\n\nThis example involves solving a nonlinear minimization problem with a tridiagonal Hessian matrix H(x) first computed explicitly, and then by providing the Hessian's sparsity structure for the finite-differencing routine.\n\nThe problem is to find x to minimize\n\n\nwhere n = 1000.\n\n\n\ntype brownfgh\n\n\n\nn = 1000;\nxstart = -ones(n,1);\nxstart(2:2:n,1) = 1;\noptions = optimoptions(@fminunc,'GradObj','on','Hessian','on');\n[x,fval,exitflag,output] = fminunc(@brownfgh,xstart,options);\n\nThis 1000 variable problem is solved in about 7 iterations and 7 conjugate gradient iterations with a positive exitflag indicating convergence. The final function value and measure of optimality at the solution x are both close to zero. For fminunc, the first order optimality is the infinity norm of the gradient of the function, which is zero at a local minimum:\n\n\nfval =\n\nexitflag =\n\noutput = \n         iterations: 7\n          funcCount: 8\n       cgiterations: 7\n      firstorderopt: 4.7948e-10\n          algorithm: 'large-scale: trust-region Newton'\n            message: 'Local minimum found.\n\nOptimization completed because the size of the grad...'\n    constrviolation: []\nWas this topic helpful?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/187255/determining-the-value-of-h-that-makes-a-linear-system-consistent/187294\nText:\nTake the 2-minute tour \u00d7\n\nI'm just beginning linear algebra at university and have a teacher who moves very fast and has pre-done slides so i can't actually see the problem worked out, he just talks it out. On top of this, he's also from China and heavily accented, making him hard to understand.\n\nAnyway, i have an augmented matrix, and i want the values of $h$ that make it consistent:\n\n$$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 2 & -8 & 6 \\\\ \\end{array}\\right]$$\n\nand quite frankly, i'm not sure just how to start. I tried eliminating the 1 in the second row, but that made the second line $[0\\;\\;\\; h+4\\;\\; -8]$ and i'm not even sure if that's the right direction or even allowed.\n\nThanks in advance.\n\nshare|improve this question\nIs it clear to you what \"consistent\" means, or even what we mean by an \"augmented matrix\"? \u2013\u00a0 akkkk Aug 26 '12 at 22:13\nI don't see the relevance of the ethnicity of your professor. I would wager he spends time to create those slides so that you read them. \u2013\u00a0 James S. Cook Aug 26 '12 at 23:02\nI don't see the relevance of looking so much into it, I was just stating that I felt behind because he was from another country and heavily accented and I was having a hard time keeping up. The only difference was that I off-handedly mentioned where he was from. \u2013\u00a0 BMEdwards37 Sep 11 '12 at 16:17\nadd comment\n\n3 Answers\n\nA linear system is inconsistent is if it represents a contradiction, for instance the system\n\n$$\\left[\\begin{array}{cc|c} 0 & 0 & -10 \\\\ 3 & -2 & 1 \\\\ \\end{array}\\right]$$\n\nis inconsistent because the first line represents a linear equation $0x+0y=-10$, i.e. $0=-10$, which is a contradiction. Geometrically, when you solve a 2x2 linear system, you are finding the intersection between a pair of lines. If you reach a contradiction, like the system above, then your lines do not intersect, i.e. they must be parallel.\n\nIf you are being asked this question, you have probably already covered Gauss-Jordan ellimination. Inconsistencies in linear systems can be readily identified if the system is brought to reduced row echelon form (can you see why?), so I would start with that. The steps are simple:\n\n$$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 2 & -8 & 6 \\\\ \\end{array}\\right]$$ Multiply the second row by $1/2$: $$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ Subtract the second row from the first: $$\\left[\\begin{array}{cc|c} 0 & h+4 & -8 \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ Without even proceeding further, it is obvious that one way for the system to be inconsistent is if the first line is $0\\, 0\\, |\\, -8$, since this would be equivalent to saying $0x+0y=-8$, that is $0=-8$, a contradiction. The first row would have this form only if $h=-4$, so $h=-4$ makes the system inconsistent.\n\nNow it is pretty clear at this point that no other value of $h$ would make the system inconsistent, and after you are comfortable with Gauss-Jordan elimination this fact would be apparent to you as well, though you should really try to understand why first. So let's say $h\\ne-4$. Then we can multiply the first row by $\\frac 1 {h+4}$: $$\\left[\\begin{array}{cc|c} 0 & 1 & -\\frac 8 {h+4} \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ And now subtract 4 times the first row from the second: $$\\left[\\begin{array}{cc|c} 0 & 1 & -\\frac 8 {h+4} \\\\ 1 & 0 & 3+\\frac {32} {h+4} \\\\ \\end{array}\\right]$$ To really be precise, you can swap the two rows: $$\\left[\\begin{array}{cc|c} 1 & 0 & 3+\\frac {32} {h+4} \\\\ 0 & 1 & -\\frac 8 {h+4} \\\\ \\end{array}\\right]$$\n\nThus for any value of $h$ other than $-4$, we can solve the system - there is no way to make the system displayed above have a row which looks like $0\\,0\\,|\\,c$, for any non-zero number $c$.\n\nshare|improve this answer\nadd comment\n\nA simpler solution is based on a theorem that any system $Ax = b$ is consistent iff rank of $[A \\mid b]$ equal to rank of $A$.\n\nTo compute rank of $A$ perform elimination on $A$ to get: $ \\pmatrix{1 & 0 \\\\ 0 & -8-2h} $ Hence $\\text{rank}(A)=1$ if $h = -4$ and $\\text{rank}(A) = 2$ otherwise.\n\nTo compute rank of $[A \\mid b]$ perform elimination on $[A \\mid b]$ to get: $$ \\pmatrix{1 & 0 & \\frac{3h-20}{h+4} \\\\ 0 & 1 & \\frac{-8}{h+4}} $$ So for values other that $h=-4$ we have $\\text{rank}([A \\mid b]) = 2$.\n\nComparing two ranks, we have a consistent system other than $h=-4$.\n\nshare|improve this answer\nadd comment\n\nSo it is consistent whenever there is at least one solution. That means that the two lines you have cannot be parallel to each other. Multiply the first row by $2$, and you get $[2, 2h, -10]$. The lines will be parallel for the equations $m_1x+n_1y=a$ and $m_2x+n_2y=b$ if $m_1=m_2$ and $n_1=n_2$. In this case, $m_1=2, m_2=2, n_1=2h, n_2=-8$. Since $m_1 = m_2, n_1 \\neq n_2$, so $2h \\neq -8, h\\neq-4$.\n\nNote that there are an infinite number of solutions (aka consistent) if $m_1=m_2, n_1=n_2,$ and $a=b$. Otherwise, you do not have to worry about the $a$ and $b$ values.\n\nshare|improve this answer\nWow, I was going in the complete wrong direction. I'm probably going to have another question here soon, but let me look at it first now after seeing this and i'll see if it helps, these variables are really throwing me off. Thank you though, and keep an eye out for another question here in about 20 minutes :p \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:28\n@BMEdwards37 Sorry I messed up with the negatives, but i fixed my answer. You can think of an augmented matrix as a system of equations, where the each column represents a different dimension, and the last column represents a constant. I was wrong in using \"x\" and \"y\" as dimensions. Usually, people would use $X_1, X_2, X_3...X_n$ \u2013\u00a0 mathguy Aug 26 '12 at 22:30\n@BMEdwards37 Wait, I want to let you know that you are not going in the wrong direction. You ended up with [0 h+4 -8], which is good! The only way to make sure a system is consistent is that ALL of the values cannot equal 0 (nevermind the last column). In your example, since the first column is 0, then the second column CANNOT be 0, so $h+4\\neq0$. If all of the columns except the last equal 0, then there are no solutions. If all columns including the last equal 0, then there are infinite solutions =) \u2013\u00a0 mathguy Aug 26 '12 at 22:35\nI understood your meaning, didn't catch the negatives either. I'm going to post another question because i'm not even sure what it's asking, i appreciate the help. \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:37\nAhh i see, i wasn't so far off. Thanks. \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/26640/free-splittings-of-one-relator-groups/26673\nText:\nTake the 2-minute tour \u00d7\n\nRoughly speaking, I want to know whether one-relator groups only have 'obvious' free splittings.\n\nConsider a one-relator group $G=F/\\langle\\langle r\\rangle\\rangle$, where $F$ is a free group. Is it true that $F$ splits non-trivially as a free product $A * B$ if and only if $r$ is contained in a proper free factor of $F$?\n\n\n  1. One direction is obvious. It is clear that if $r$ is contained in a proper free factor then $G$ splits freely. (We think of $\\mathbb{Z}\\cong\\langle a,b\\rangle/\\langle\\langle b\\rangle\\rangle$ as an HNN extension of the trivial group, so it's not really a counterexample, even though it might look like one.)\n  2. A quick search of the literature suggests that the isomorphism problem for one-relator groups is wide open. (I'd be interested in any details that anyone may have.)\n  3. There is no decision-theoretic obstruction. Magnus famously solved the word problem for one-relator groups. Much more recently, Nicholas Touikan has shown that, for any finitely generated group, if you can solve the word problem then you can compute the Grushko decomposition. So one can algorithmically determine whether a given one-relator group splits. If the answer to my question is 'yes' then one can use Whitehead's Algorithm to find this out comparatively quickly.\n  4. When I first considered this question, it seemed to me that the answer was obviously 'yes' - I don't see how there could possibly be room in a presentation 2-complex for a 'non-obvious' free splitting. But a proof has eluded me, and of course many seemingly obvious facts about one-relator groups are extremely hard to prove.\nshare|improve this question\n\n4 Answers 4\n\nup vote 10 down vote accepted\n\nI think Grushko plus the Freiheitssatz does the trick. Suppose that $G=A\\ast B$ is a 1-relator group which splits as a free product non-trivially. By Grushko, $rank(G)=rank(A)+rank(B)=m+n$, where $rank(A)=m, rank(B)=n$. If $G$ is not free, then by Grushko there is a 1-relator presentation $\\langle x_1,\\ldots, x_m ,y_1,\\ldots, y_n | R\\rangle$, such that $\\langle x_1,\\ldots, x_m \\rangle =A \\leq G, \\langle y_1, \\ldots, y_n \\rangle=B \\leq G$ (for this, one has to use the strong version of Grushko that any 1-relator presentation is Nielsen equivalent to one of this type). Suppose that $R$ is cyclically reduced, and involves a generator $x_1 \\in F_m$. Then $\\langle x_2,\\ldots , x_m, y_1, \\ldots, y_n\\rangle$ generates a free subgroup of $G$ by the Freiheitssatz. But this implies that $B = \\langle y_, \\ldots, y_n\\rangle$ is free. Moreover, if $G$ involves one of the generators $y_i$, then one sees that $A=\\langle x_1,\\ldots,x_m\\rangle$ is also free, and therefore $G=A\\ast B$ is free, a contradiction. So $R \\in F_m$, as required.\n\nshare|improve this answer\nGreat - thanks, Ian! The strengthened version of Grushko's Theorem was the ingredient I was missing. \u2013\u00a0 HJRW Jun 2 '10 at 0:10\n\nI just came across the following, which is Prop. II.5.13 of Lyndon-Schupp.\n\nProposition. Let $G = \\langle x_1, \\ldots , x_n: r\\rangle$ where $r$ is of minimal length under $Aut(\\langle x_1, \\ldots , x_n\\rangle)$ and contains exactly the generators $x_1,\\ldots , x_k$ for some $0 \\leq k \\leq n$. Then $G \\cong G_1*G_2$ where $G_1 = \\langle x_1, \\ldots , x_k:r\\rangle$ is freely indecomposable and $G_2$ is free with basis $x_{k+1}, \\ldots ,x_n$.\n\nUnless I'm missing something, up to isomorphism you can assume that your relator has minimal length. If it is not contained in a free factor of $G$, then $k=n$ in the Proposition, hence $G = G_1$ is freely indecomposable.\n\nshare|improve this answer\nExcellent! I thought it must be in Lyndon and Schupp somewhere, but I didn't manage to find it. Thanks! \u2013\u00a0 HJRW Jun 29 '10 at 21:02\n\nYour question is reminiscent of Jaco's lemma. A special case of Jaco's lemma applies to a 2-handle attached to the boundary of a (3-dimensional) handlebody $H$ (which has free fundamental group). If the boundary curve $J\\subset \\partial H$ along which the handle is attached is \"disk-busting\", that is, $\\partial H-J$ is incompressible (and therefore $\\pi_1$-injective) in $H$, then the manifold obtained has $\\pi_1$-injective boundary (and therefore does not split as a free product). This condition is easily seen to be equivalent to the conjugacy class of $J$ not belonging to any free factor of $\\pi_1(H)$. So this answers your question in this very special case (also note that this works for \"orbifold\" handles attached along $J$). It's not clear whether Jaco's method might apply in your case, but it might be worth having a look (there are other proofs and generalizations of it too which you can find through Mathscinet). In particular, his argument might also apply if the word is only virtually geometric.\n\nshare|improve this answer\n\nI'm not sure whether it helps here, but your question reminds me of the Freiheitssatz. As you probably know, this is the theorem of Magnus that says that if $G=\\langle x_1,\\ldots,x_n|r\\rangle$ and $r$ involves the generator $x_n$, then the elements $x_1,\\ldots,x_{n-1}$ generate a free group of rank $n-1$ inside $G$. Certainly your assumption implies this hypothesis with respect to any basis $x_1,\\ldots,x_n$.\n\nAlso, I feel like we don't want to count HNN extensions as free products -- can't we just exclude the example of $\\mathbb{Z}=\\langle a,b|b\\rangle$ by fiat? There aren't any other such counterexamples, right?\n\nshare|improve this answer\nThanks for the answer Tom. Yes, I know about the Freiheitssatz; I don't see how it helps with this question directly. It's certainly conceivable that the Magnus-rewriting-and-induction proof scheme of the Freiheittsatz could be applied to prove what I want. Unfortunately, I don't have a strong enough feeling for that method to know what's possible and what's not. \u2013\u00a0 HJRW Jun 1 '10 at 15:54\nRegarding your second paragraph: from the Bass--Serre Theory point of view, we're really talking about actions on trees with trivial edge stabilizers; this boils down to free products or HNN extensions over the trivial group. A group G is an HNN extension over the trivial group if and only if it's a non-trivial free product with a $\\mathbb{Z}$ factor or $G\\cong\\mathbb{Z}$. In my remark, I wanted to give a 'natural' reason why $\\mathbb{Z}$ wasn't a counterexample, without mentioning actions on trees. I don't think there's anything natural about excluding something by fiat. \u2013\u00a0 HJRW Jun 1 '10 at 15:59\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/93247/irreducible-elements-in-a-ideal-of-rx-1-x-2\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbf R$ denote the real numbers, let's take a finite number of points in $\\mathbf R^2$ and let's take the ideal $I$ of all the polynomials that vanish on this points. Using the Hilbert basis theorem we know that $I$ is finitely generated. I want to know if there exists an element in this ideal that is an irreducible polynomial.\n\nClearly I can suppose that all the finite generators are not irreducible, otherwise it's done. Using this, how can I find such a polynomial?\n\nshare|improve this question\nTake $F=\\sum_{i+j\\le N} a_{ij}x_1^jx_2^j$. To pass through the points imposes a finite set of conditions on the coefficients $a_{ij}$. Taking $N$ sufficiently large you can find such an $F$ which is also irreducible. \u2013\u00a0 J.C. Ottem Apr 5 '12 at 20:05\nBut how can I prove that it\u00b4s irreducible? \u2013\u00a0 Daniel Apr 5 '12 at 20:09\nLet ${\\cal P}_N$ be the space of degree-$N$ polynomials. The reducible polynomials in ${\\cal P}_N$ form the union of subvarieties each of codimension at least $N-O(1)$ [see e.g. my answer to mathoverflow.net/questions/88895]. The polynomials vanishing on a finite set $S$ of points constitute a subspace of ${\\cal P}_N$ of codimension at most $\\#(S)$. Therefore, once $N > \\#(S) = O(1)$ most polynomials in that subspace are irreducible, QED. \u2013\u00a0 Noam D. Elkies Apr 5 '12 at 21:06\nI don\u00b4t understand your answer, and your link is deleted. \u2013\u00a0 Daniel Apr 5 '12 at 23:59\n@Daniel: Try mathoverflow.net/questions/88895 (I see that if you click on what I wrote the final \"]\" gets appended to the URL). What I wrote has a slight typo: should be $N > \\#(S) + O(1)$, not $\\#(S) = O(1)$. Basically, once $N$ is large enough (bigger than the size of the finite subset plus a bit), there aren't enough reducible polynomials of degree $N$ to fill the space of degree-$N$ polynomials vanishing on $S$. (If $N < \\#(S)$ the claim can fail, because all the points in $S$ might lie on one line $l$, and then a degree-$N$ polynomial vanishing on $N$ would vanish identically on $l$.) \u2013\u00a0 Noam D. Elkies Apr 6 '12 at 0:08\n\n1 Answer 1\n\nTo give an explicit answer, choose a system of coordinates $x,y$ such that no two points have the same $x$ coordinate. This is possible since the slopes of lines that pass through pairs of points in the set are only finitely many of all the slopes. Then use basic algebra or the Chinese remainder theorem to find a polynomial equation $y=f(x)$ that passes through all your points. $y-f(x)$ is irreducible so you're done.\n\n(Proof: its degree in $\\mathbb R[x][y]$ is one so it must be the product of a linear and a constant term, but no nontrivial constant terms divide it.)\n\nEdit: A secondary question might be: what is the worst-case scenario lowest-degree polynomial that accomplishes this goal? This method shows that, with $n$ points, there is always a degree $n-1$ irreducible polynomial. Sometimes, there is no degree $n-2$ polynomial: Take $n-1$ points on a line, and one off it. Then an irreducible polynomial vanishing at all $n$ points cannot vanish identically on the line, but vanishes at $n-1$ points on it, so has degree at least $n-1$.\n\nshare|improve this answer\nAh and I forgot something, not only must cancel on this points, and be irreducible, also has only that roots , and no more! \u2013\u00a0 Daniel Apr 6 '12 at 5:46\nI would never have thought there was such a beautifully elementary solution: congratulations, Will ! \u2013\u00a0 Georges Elencwajg Apr 6 '12 at 7:15\n@Will Sawin Your polynomials has other roots right? ( Not just the finite points, What can I do to find a polynomial that only has that finite points and it\u00b4s also irreducible)? \u2013\u00a0 Daniel Apr 6 '12 at 15:31\n@J.C. Ottem I have a question, how can I put in the coefficients the conditions of being irreducible? \u2013\u00a0 Daniel Apr 6 '12 at 15:32\n@Daniel: Let $y,f(x)$ be as before and $g(x)$ vanish at the $x$ coordinates of the set of points, then $(y-f(x))^2+g(x)^2$ is irreducible in $\\mathbb R[x,y]$, because it splits in $\\mathbb C[x,y]$ into $(y-f(x)+ig(x))(y-f(x)-ig(x))$, neither of which is in $\\mathbb R[x,y]$ \u2013\u00a0 Will Sawin Apr 7 '12 at 0:03\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/37360/complete-estimates-of-the-error-for-a-well-known-asymptotic-expression-of-partiti/37453\nText:\nTake the 2-minute tour \u00d7\n\nLet $p(n,m)$ be the number of partitions of an integer $n$ into integers $\\le m$, we have a well-known asymptotic expression:\n\nFor a fixed $m$ and $n\\to\\infty$, $$p(n,m)=\\frac{n^{m-1}}{m!(m-1)!} (1+O(1/n)) $$\n\nMy question is: why the error $O(1/n)$ is independent of $m$? Or how can it be extended for $m$ growing slowly with $n$? Please help me to find the answer or the references. Thanks.\n\nshare|improve this question\nI think there's a derivation of this in George Andrews' book Theory of Partitions. At the very least you might check there. (This is a comment instead of an answer because I don't actually have the book in front of me to check.) \u2013\u00a0 Michael Lugo Sep 1 '10 at 15:14\n\n3 Answers 3\n\nup vote 3 down vote accepted\n\nI'm not entirely sure of what you are asking, but note that Erdos and Lehner proved here that $$p(n,m)\\sim \\frac{n^{m-1}}{m!(m-1)!}$$ holds for $m=o(n^{1/3})$. In generality for any finite set $A$, with $|A|=m$ and $p(n,A)$ denoting the number of partitions of $n$ with parts from $A$, one has $$p(n,A)=\\frac{1}{\\prod_{a\\in A}a}\\frac{n^{m-1}}{(m-1)!}+O(n^{m-2}).$$\n\nSuch estimations can be deduced from the generating function of $p$ by using methods that are described in many books, for example \"Analytic Combinatorics\" by Flajolet and Sedgewick.\n\nshare|improve this answer\n\nThank Robin Chapman very much for editing.\n\nThere is a nice asymptotic expression for partition $q(n,M)$ that denotes the number of partitions of $n$ with $M$ parts all distinct: As $n\\to\\infty$,\n\n$$ q(n,M)\\approx \\frac{(n-1)!}{M!(M-1)!(n-M)!}\\left( 1+O\\left( \\frac{M^{3}}{n} \\right) \\right)$$\n\nIsn't there no similar asymptotic expression for partition $p(n,m)$?\n\nshare|improve this answer\n\nG. Szekeres, Quart. J. Math. (Oxford) 4(2) (1953), 96-111, obtains an asymptotic formula for $p(n,m)$ valid uniformly for all $n$ and $m$.\n\nshare|improve this answer\nHis formula only seems to be valid for n at most a constant times m<sup>2</sup>. It also involves the solution of a quite nasty looking implicit equation, so I'm not sure how useful it is. \u2013\u00a0 Richard Borcherds Sep 2 '10 at 4:23\nPlease be noted that in G. Szekeres' two papers in 1951 and 1953, the asymptotic formulae for $p(n,m)$ valid only under strong condition that $m$ is related to $n^2$. In physics, no asymptotic formula not useful unless $m \\alpha n$ ($\\alpha >0$ and as $m$ is large). \u2013\u00a0 QHLIU Sep 4 '10 at 8:20\nI am not an expert in this area, but see combinatorics.org/Volume_4/Abstracts/v4i2r06ab.html. Here Szekeres' asymptotic formula is given that is valid in the range $k\\geq n^{1/6}$, and is valid uniformly in the entire range $k\\geq 1$ by adding $1/k$ to the big-oh term. See also the article by Romik in Europ. J. Combinatorics 26 (2005), 1-17. As for whether the formula is useful, Szekeres uses it to prove that for $n$ sufficiently large, the sequence $p(n,1), p(n,2),\\dots, p(n,n)$ is unimodal, the only known proof of this result. \u2013\u00a0 Richard Stanley Sep 7 '10 at 15:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/70125/calculating-n-choose-k-mod-one-million?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI am working on a programming problem where I need to calculate 'n choose k'. I am using the relation formula $$ {n\\choose k} = {n\\choose k-1} \\frac{n-k+1}{k} $$ so I don't have to calculate huge factorials. Is there any way to use this formula and just keep track of the last 6 digits. Could you compute the next k, with only knowing the some of the last digits.\nI understand this is a lot to ask, so all I ask is a point in the right direction. Maths is by far not my strongest subject.\nThanks in advance.\n\nshare|improve this question\nCan you give us an idea of the scale of $n$ or $k$? \u2013\u00a0 Henry Oct 5 '11 at 18:40\n0 <= n, k <= 100. \u2013\u00a0 ricola86 Oct 5 '11 at 18:43\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n\nYou might also want to use $\\binom{n}{k}=\\binom{n}{n-k}$ to reduce the case where $k>n/2$.\n\nUsing $\\binom{n}{k} = \\binom{n}{k-1} \\frac{n-k+1}{k}$ mod one million has a problem when $(k,10)\\not=1$. Such $k$ are zero divisors mod one million, so you cannot divide by $k$ mod one million and get a meaningful result.\n\nHowever, you can count the number of factors of $p$ that are in $\\binom{n}{k}$ for prime $p$. Let $s_p(n)$ be the sum of the base $p$ digits of $n$. Then, the number of factors of $p$ in $\\binom{n}{k}$ is $(s_p(k)+s_p(n-k)-s_p(n))/(p-1)$. Thus, instead of multiplying by $n-k+1$ and dividing by $k$, multiply by $n-k+1$ with all factors of $2$ and $5$ removed and divide by $k$ with all factors of $2$ and $5$ removed. At the end, multiply by the number of factors of $2$ and $5$ computed above.\n\nFor example, let's compute $\\binom{97}{89}=\\binom{97}{8}$.\n\nHere are $97$, $8$, and $89$ in base $2$ and $5$ followed by their sum of digits: $$ 97=1100001_2(3)=342_5(9) $$ $$ 8=1000_2(1)=13_5(4) $$ $$ 89=1011001_2(4)=324_5(9) $$ Therefore, the number of factors of $2$ in $\\binom{97}{89}$ is $(1+4-3)/(2-1)=2$, and the number of factors of $5$ is $(4+9-9)/(5-1)=1$. Therefore, mod one million,\n\n$$ \\begin{align} \\binom{97}{8} &=\\frac{97}{1}\\frac{96/32}{2/2}\\frac{95/5}{3}\\frac{94/2}{4/4}\\frac{93}{5/5}\\frac{92/4}{6/2}\\frac{91}{7}\\frac{90/10}{8/8}\\times2^2\\times5^1\\\\ &=\\frac{97}{1}\\frac{3}{1}\\frac{19}{3}\\frac{47}{1}\\frac{93}{1}\\frac{23}{3}\\frac{91}{7}\\frac{9}{1}\\times4\\times5\\\\ &=010441\\times20\\\\ &=208820 \\end{align} $$ Everything is good above since we can divide by $3$ and $7$ mod one million.\n\nCaveat: Remember that modular division is quite different than standard division of integers, rationals, and reals. It requires solving a Diophantine equation which usually involves the Euclidean algorithm. For example, $1/7=3\\pmod{10}$ because $3\\times7=1\\pmod{10}$.\n\nshare|improve this answer\nI see after finally posting that most of what I say is covered in the links supplied by Sasha. I hope the example gives it some added value. \u2013\u00a0 robjohn Oct 5 '11 at 21:46\nthis is good stuff thanks. It's well explained and I've surprised myself in being able to understand it. +1. \u2013\u00a0 ricola86 Oct 7 '11 at 15:14\n@ricola86: as long as you remember that division $\\pmod{m}$ is quite different than normal division. It requires solving a diophantine equation and usually involves the Euclidean algorithm. E.g. $1/7=3\\pmod{10}$. \u2013\u00a0 robjohn Oct 7 '11 at 15:38\n+1,Nice explanation,you may also like to add the final comment in the actual answer as well. \u2013\u00a0 Quixotic Oct 7 '11 at 18:20\n@FoolForMath: Good idea. I have added a caveat to my answer. \u2013\u00a0 robjohn Oct 7 '11 at 19:40\nshow 1 more comment\n\nIn terms of factorials, probably not.\n\nUse the recurrence ${n \\choose k} = {n \\choose k-1} + {n-1 \\choose k-1}$ and just work mod $10^6$.\n\nAlternatively you can work mod $2^6$ and mod $5^6$ and combine the two results using the Chinese Remainder Theorem. There seem to be interesting patterns in the binomial coefficients mod prime powers but I don't know if there are actually formulas. This is probably more trouble than it's worth, though.\n\nshare|improve this answer\nadd comment\n\nI remember solving SPOJ MARBLES which is actually finding $\\binom{n}{k}$,constraints there are also similar to this problem in hand.\n\nLast January this same problem (with much more difficult constraints) features in Codechef's January cookfoff.You may like to check the editorial which explains the algorithm along with the implementation.\n\nshare|improve this answer\nThis is exactly what I was looking for, thanks alot. Funnily enough, it's a codechef problem I'm working on. \u2013\u00a0 ricola86 Oct 5 '11 at 19:11\n@ricola86:Aha,glad to help!:-)I didn't practise in codechef anymore,but I guess you are not asking help for any current problem-set?! ;-) \u2013\u00a0 Quixotic Oct 5 '11 at 19:16\nerrmm no, I wouldnt dream of it. \u2013\u00a0 ricola86 Oct 5 '11 at 19:24\n@ricola86:Alright! :) \u2013\u00a0 Quixotic Oct 5 '11 at 19:27\nadd comment\n\nYou may find the following page of interest.\n\nMuch of the math behind it is also discussed in this post at math.SE\n\nshare|improve this answer\nNice link thanks, It seems I can't upvote with a low reputation :(. \u2013\u00a0 ricola86 Oct 5 '11 at 19:10\n@ricola86: I upvoted for you. Oops, now I can't upvote for myself! :-) \u2013\u00a0 robjohn Oct 5 '11 at 22:22\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/46936/is-a-map-a-homotopy-equivalence-if-its-suspension-is-so\nText:\nTake the 2-minute tour \u00d7\n\nExist simply connected CW complexes $X$, $Y$ and a mapping $f:X\\to Y$ with the property that the reduced suspension $\\Sigma f:\\Sigma X\\to\\Sigma Y$ is a homotopy equivalence but $f$ is not?\n\nshare|improve this question\nAs said below, the answer is yes. It is interesting to note that this fails if you drop the simply connectedness assumption on $X$ or $Y$. Let's do $X$ not simply connected. Let $X$ be any connected acyclic CW-complexes with non-trivial fundamental group (these exist, see e.g. Hatcher). Then $X \\to pt$ is a homology equivalence, but not a homotopy equivalence. Since suspension raises the connectedness, the induced map $\\Sigma X \\to \\Sigma pt$ is a homology equivalence of simply connected CW-complexes and using Whitehead's theorem from Andreas' answer, this is a homotopy equivalence. \u2013\u00a0 skupers Nov 22 '10 at 23:19\n\n5 Answers 5\n\nup vote 17 down vote accepted\n\nWhitehead's Theorem (it is Corollary 4.33 in Allen Hatcher's book) says that a map between simply connected CW-complexes is a homotopy equivalence if and only if the induced map on homology (with $\\mathbb Z$-coefficients) is an isomorphism. If $\\Sigma f : \\Sigma X \\to \\Sigma Y$ is a homotopy equivalence, then this is clearly the case, since suspension just shifts dimensions and the spaces are connected, so that there is no problem in dimension $0$.\n\nIt would be interesting to have an argument which does not use all the machinery that goes into Whitehead's Theorem, since your assumption is rather strong.\n\nshare|improve this answer\nAndreas, which Whitehead's theorem is that? The only one I can find is the one where \"a weak equivalence between CW complexes (in more generality, fibrant-cofibrant objects) admits a homotopy inverse.\" \u2013\u00a0 Harry Gindi Nov 22 '10 at 12:26\nAlan Hatcher calls it a version of Whitehead's Theorem. It follows from a combination of the relative version of Whitehead's Theorem and a relative version of the Hurewicz Theorem about Isomorphism of homology groups and homotopy groups in the lowest non-vanishing degree. \u2013\u00a0 Andreas Thom Nov 22 '10 at 12:33\nUltimately, what is needed is a way to compare the connectivities of the fiber and cofiber of a map. It can be shown without homology that for simply-connected spaces (you can do slightly better by imposing conditions on $\\pi_1$), the connectivity of the fiber is precisely one more than the connectivity of the cofiber. You can measure the connectivity of a map using cofibers rather than fibers in this case. \u2013\u00a0 Jeff Strom Nov 22 '10 at 12:52\n\nSince adequate answers to the question asked have been given, I will address the relevant underlying theorems. There are two relevant theorems, both called ``Whitehead's theorem''. One says that a weak homotopy equivalence between CW complexes is a homotopy equivalence. The other says that an integral homology isomorphism between suitable spaces, say nilpotent but it actually holds a little more generally, is a weak homotopy equivalence; I say weak because that is what comes naturally out of the proof. I observed in \"The dual Whitehead theorems'', #47 on my web page, that these two theorems are word for word Eckmann-Hilton dual to each other when thought of in the right homotopical way (this was presented at a birthday conference for Hilton). The idea is that you study $[X,Y]$ by decomposing $X$ using cells to get the first theorem and decompose $Y$ using \"cocells'', via (generalized) Postnikov towers, to get the second. This point of view is explained more leisurely in \"More concise algebraic topology\", by Kate Ponto and myself: it dominates our treatment of localizations and completions of spaces. It is an especially precise application of the intuition of model category theory, but it is best understood when worked out directly, without invoking that language.\n\nshare|improve this answer\n\nIf the spaces are simply connected, or somewhat more generally, if they are simple (meaning that $\\pi_1$ is abelian and acts trivially on the higher homotopy groups) then as Andreas points out, there is Whitehead's theorem that a homology isomorphism between simple spaces is a weak equivalence, and also Whitehead's other theorem that a weak equivalence between CW complexes is a homotopy equivalence.\n\nHowever, as rpotrie's example indicates, with non-simple spaces the question is more interesting, and the answer is that there are certainly examples where the suspension is a homotopy equivalence but the map itself is not.\n\nHere's a way to construct such a map. Let $G$ be group containing a nontrivial perfect normal subgroup $H$ (i.e., $H= [H,H]$) let $X=BG$, and let $Y=BG^+$ - Quillen's plus construction. The plus construction attaches 2 cells and 3 cells to a space to produce a new space with the same homology but with fundamental group now the quotient of the original fundamental group by $H$. The inclusion $BG \\subset BG^+$ is a homology isomorphism, but the spaces have different fundamental groups so the inclusion is not a homotopy equivalence. However, if $H$ happens to be the whole commutator subgroup and you suspend the map once then $\\Sigma BG$ and $\\Sigma (BG^+)$ are both simply connected, and so Whitehead's theorems tell you that the map is a homotopy equivalence.\n\nshare|improve this answer\nActually, I think it's enough that the space be nilpotent. If I remember well, a theorem of Drozd generalizing Whitehead's says that if $f\\colon X\\rightarrow Y$ is a map of connected nilpotent CW-complexes inducing isomorphism on $\\pi_1$ and $H_n$, $n\\geq 2$, then it is a homotopy equivalence. \u2013\u00a0 Fernando Muro Feb 19 '13 at 13:04\nSorry, I meant Dror, Emmanuel Dror Farjoun. \u2013\u00a0 Fernando Muro Feb 19 '13 at 17:50\n\nLook at the double suspension theorem, it asserts that the double suspension of the homology $3$-sphere of Poincare is homeomorphic to the 5-sphere.\n\nI believe that there is a map from $S^3$ to this homology sphere, I guess that the double suspension of this map may be a homotopy equivalence, I am not sure about this, but this can help.\n\nshare|improve this answer\nYour homology sphere will not be simply connected. \u2013\u00a0 Andreas Thom Nov 22 '10 at 12:31\nThere is a map from $S^3$ to the Poincare homology sphere $P$ ($S^3$ is its universal covering) and there is a map $P\\rightarrow S^3$ ($P$ can be constructed usin a dodecahedron identifying some faces. Collapsing the whole boundary gives $S^3$ and the map). I guess it is better to consider the latter map (but it is just a feeling). \u2013\u00a0 HenrikR\u00fcping Nov 22 '10 at 12:33\nAlternatively, you can delete a point the homology sphere to get a space with trivial homology and nontrivial fundamental group. \u2013\u00a0 Ben Wieland Nov 22 '10 at 12:38\n@Andreas: You are right, I've missed that hypothesis. I hadn't seen your answer when I wrote mine, it is clear from your answer the need for simple conectedeness. @Henrik: I think you are right, with the first map, the induced map of the one I say will have degree greater than one, yours seems to have degree one (after taking double suspension) which is enough to be homotopic to the identity by Hopf theorem. \u2013\u00a0 rpotrie Nov 22 '10 at 12:47\n\nI liked very much the comment/answer of Jeff Strom. And this result seems to be, indeed, essentialy, a consequence of what he mentioned. At first glance, the result seems to be a consequence of the relative Hurewicz isomorphism (and, obviously, Whitehead theorem). But we can prove the result using homotopy excision without passing to homology.\n\nAssuming $\\Sigma f $ is a weak equivalence between simply connected spaces, we get, by the homotopy excision (pag 81, May's Concise Course), that $\\Sigma C_f\\equiv C_{\\Sigma f} $ is weakly equivalent to a point. Now, we complete by induction. We already know that $f$ is a $1$-equivalence. By induction, we assume that $ f $ is a $n$-equivalence. And, again, by homotopy excision, we know that this hypothesis implies that $(M_f,X)\\to C_f $ is $(n+2)$-equivalence. So $C_f$ is $n$ connected. And, then, by Freudenthal theorem, $\\Sigma :\\pi_q( C_f)\\to \\pi _{q+1}(\\Sigma C_f) $ is an isomorphism for $q< 2n+1 $. In particular, $C_f$ is $2n$-connected. Therefore, by the $(n+2)$-equivalence, we conclude that $f$ is a $(n+2)$-connected space. And this concludes our induction.\n\nConcisely, this proof is about two lemmas: one is that commented by Jeff Strom (which can be proved using excision). The other lemma is a consequence of Freudenthal/excision: If $\\sum X $ is $n$-connected and $X$ is simply connected, then $X$ is $n-1$ connected.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96239/determinant-of-an-updated-covariance-matrix/96240\nText:\nTake the 2-minute tour \u00d7\n\nI am faced with the following problem :\n\nOriginally (at time 0) I have a number of data samples $x^0_{1...n}$ (normalised : $E[x] = 0, Var[x] = 1$) from which I have calculated the covariance matrix $C^0 = X^T X$ (where $X$ is the matrix of data samples), and the corresponding determinant $|C^0|$ (I could also store all and any minors are necessary).\n\nGiven this information I would like to perform the following iterative process incurring the smallest computational cost possible :\n\nAt time $t+1$ I am presented with a new data sample $x^{t+1}_{new}$ (similarly normalised) which can replace any of my existing data samples. Thus if I discard example $x^t_k$ in favour of this new sample, I have a new covariance matrix $C^{t+1}_{k,new}$. I would like to calculate (given $C^0$, its minors and determinant) $\\forall t$ $argmax_k |C^{t+1}_{k,new}|$.\n\nNote that at each time step $t+1$, if I decide to discard $x^t_k$ in favour of $x^{t+1}_{new}$ then $x^{t+1}_k = x^{t+1}_{new}$ .\n\nMy question is, is there a method to calculate the determinants without incurring a cost of $n^3$ per determinant per time step?\n\nThanks for the help.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nFirst compute a Cholesky factorization of the covariance matrix. Now your tentative new covariance matrix is a rank-2 update of the old, $$ M_{new}=M_{old}+\\frac{1}{n}x_{new}x_{new}^T-\\frac{1}{n}x_{old}x_{old}^T. $$ You can use Sylvester's formula here to compute the determinant of the update; for this you'll only need to solve a linear system, which is $O(n^2)$ using your Cholesky factorization.\n\nThen when your \"replacement\" take place for real you just have to update the Cholesky factorization, and there are algorithms to do that (low-rank updates of Cholesky factorization) in $O(n^2)$ as well. Check Matlab's cholupdate for instance.\n\nSo you pay $O(n^3)$ at the first step and then $O(n^2)$ per step.\n\nEDIT: better and clearer algorithm\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/41211/easy-proof-of-the-fact-that-isotropic-spaces-are-euclidean/41224\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a finite-dimensional Banach space whose isometry group acts transitively on the set of lines (or, equivalently, on the unit sphere: for every two unit-norm vectors $x,y\\in X$ there exist a linear isometry from $X$ to itself that sends $x$ to $y$). Then $X$ is a Euclidean space (i.e., the norm comes from a scalar product).\n\nI can prove this along the following lines: the linear isometry group is compact, hence it admits an invariant probability measure, hence (by an averaging argument) there exists a Euclidean structure preserved by this group, and then the transitivity implies that the Banach norm is proportional to that Euclidean norm.\n\nBut this looks too complicated for such a natural and seemingly simple fact. Is there a more elementary proof? I mean something reasonably short and accessible to undegraduates (so that I could use it in a course that I am teaching).\n\nAdded. As Greg Kuperberg pointed out, there are many other ways to associate a canonical Euclidean structure to a norm, e.g. using the John ellipsoid or the inertia ellipsoid. This is much better, but is there something more \"direct\", avoiding any auxiliary ellipsoid/scalar product construction?\n\nFor example, here is a proof that I consider \"more elementary\", under the stronger assumption that the isometry group is transitive on two-dimensional flags (that is, pairs of the form (line,plane containing this line)): prove this in dimension 2 by any means, this implies that the norm is Euclidean on every 2-dimensional subspace, then it satisfies the parallelogram identity, hence it is Euclidean.\n\nLooking at this, I realize that perhaps my internal criterion for being \"elementary\" is independence of the dimension. So, let me try to transform the question into a real mathematical one:\n\n  \u2022 Does the fact hold true in infinite dimensions (say, for separable Banach spaces)?\nshare|improve this question\nWhen I was an undergraduate I read substantial portions of your book (with Burago & Burago) on metric geometry, and I remember encountering this as an exercise and getting hung up on it for about two weeks. I finally asked Ralph Spatzier who suggested more or less the exact argument that you outlined. I could barely understand the argument and went on for years with the problem of simplifying it in the back of my mind. I don't mind the more sophisticated argument anymore, but it would nevertheless be very gratifying for me personally to see this issue resolved. So thanks for the question! \u2013\u00a0 Paul Siegel Oct 6 '10 at 1:10\nNot sure I understand your last question, Sergei. It is a famous problem whether a separable infinite dimensional Banach space which has a transitive isometry group must be isometrically isomorphic to a Hilbert space. Of course, if every two dimensional subspace has a transitive isometry group, then the space is a Hilbert space since then the norm satisfies the parallelogram identity. For counterexamples in the non separable setting, consider $\\ell_p(A)$ with $p$ not $2$ and $A$ uncountable. \u2013\u00a0 Bill Johnson Oct 6 '10 at 1:42\n@Bill Johnson: thanks, you answered it. I was not aware about this being an open problem. \u2013\u00a0 Sergei Ivanov Oct 6 '10 at 7:28\n@Sergei Ivanov: The example I mentioned in the non separable setting is wrong. An example is the $\\ell_p$ sum of uncountably many copies of $L_p(0,1)$, not the $\\ell_p$ sum of uncountably many copies of the real line. \u2013\u00a0 Bill Johnson Oct 6 '10 at 8:04\n@Bill: You should post your remarks as an answer to the revised question. It's an open problem for separable Banach spaces and there are inseparable counterexamples. Sweet! \u2013\u00a0 Greg Kuperberg Oct 6 '10 at 10:45\n\n5 Answers 5\n\nup vote 10 down vote accepted\n\nIt is a famous problem (due to Banach and Mazur) whether a separable infinite dimensional Banach space which has a transitive isometry group must be isometrically isomorphic to a Hilbert space. Of course, if every two dimensional subspace has a transitive isometry group, then the space is a Hilbert space since then the norm satisfies the parallelogram identity. For counterexamples in the non separable setting, consider the $\\ell_p$ sum of uncountably many copies of $L_p(0,1)$ with $p$ not $2$.\n\nFor a recent paper related to the Banach-Mazur rotation problem, which contains some other references related to the problem, see\n\n\nshare|improve this answer\n\nThe heart of the matter is to define a canonical inner product for any norm in finite dimensions. Since it is canonical, an $X$-isometry is also an isometry of the inner product. If the group is transitive on lines, you thus immediately get that norm is Euclidean.\n\nThere are two popular ways to do this. One is John's theorem: The ellipsoid in the unit ball $K$ of $X$ (which is any convex, centrally symmetric body) with the largest volume is unique. Or of course you could use John's theorem dually, taking the smallest ellipsoid that contains $K$. The other popular, canonical ellipsoid is the Legendre ellipsoid of $K$, by definition the ellipsoid $L$ that has the same moment of inertia matrix as $K$, assuming that both $L$ and $K$ have uniformly distributed mass.\n\nOn the other hand, the averaging argument is also \"slick\" in my opinion, and I don't really see anything wrong with it even for undergraduates. Arguably the problem with any slick argument is that it is too adroit for some students.\n\nshare|improve this answer\nYes, thanks, but this is not quite what I am looking for. This is intended for students that probably never heard about Euclidean vs. non-Euclidean norm thing before. I'll try to edit question to make it more clear. \u2013\u00a0 Sergei Ivanov Oct 5 '10 at 22:15\nI'll have to trust Bill Johnson's answer that the new question is an open problem. As for the original question, I learned what John's ellipsoid is before I really knew what a norm is. If you state everything in terms of convex bodies, then I don't see how an undergraduate could object to the John ellipsoid argument. It's a wonderful and elementary fact that there is only one largest ellipsoid, and even only one local maximum of the volume function for ellipsoids. \u2013\u00a0 Greg Kuperberg Oct 6 '10 at 10:47\nI learned about John ellipsoid much later, and did so the hard way (discovering the John representation theorem myself). So it is not a common knowledge to me. But I agree with you - using John ellipsoid is much better from the pedagogical perspective, even if I claim its uniqueness without proof (or leave it as an exercise). After all, I'm not going to use the result in the course, its sole purpose its to impress the students. \u2013\u00a0 Sergei Ivanov Oct 6 '10 at 16:56\n@Sergei I think, uniqueness of the John ellipsoid is quite easy to prove (we are searching for a non-negative quadratic form $Q$ such that $(Qx,x)\\leq \\|x\\|^2$ and $\\det Q$ is maximal possible. If it is not unique, say $Q_1$ and some $Q_2\\ne Q_1$ satisfy, then $(Q_1+Q_2)/2$ has strictly larger determinant), and your students, if they are not freshmen, should know all the necessary linear algebra. \u2013\u00a0 Fedor Petrov Oct 7 '10 at 22:53\n\nThere is a classic paper by Jordan and von Neumann where they prove results that allows this question is settled in an elementary way.\n\nOn Inner Products in Linear, Metric Spaces Author(s): P. Jordan and J. V. Neumann, The Annals of Mathematics, Second Series, Vol. 36, No. 3 (Jul., 1935), pp. 719-723.\n\nThey first prove by elementary arguments (their Theorem I) the so-called Jordan v. Neumann criterion, that a Banach space is Hilbert iff for all $x$ and $y$, $(*) ||x + y||^2 - ||x - y||^2 = 2||x||^2 + 2 ||y||^2$. They then show from this that a Banach space is Hilbert iff every 1 and 2 dimensional subspace is Euclidean. Here is their argument:\n\n4.The condition that every $<= 2$-dimensional subspace $L'$ of $L$ be isometric to a Euclidean space, is obviously necessary for the existence of an inner-product in the generalized linear,metric space L. It is sufficient,too, because if it is fulfilled, one can argue as follows:If $f_o,g_0\\in L$ the space $L'$ of all $\\alpha f_0 + \\beta g_0$ ($\\alpha,\\beta$ arbitrary complex numbers) is $<= 2$ dimensional,thus (*) holds in $L'$ (as in every Euclidean space). Therefore it holds in particular for $f = f_0, g = g_0$,and as $f_0,g_0$ are arbitrary, Theorem I proves the existence of an inner product.\n\n[SEE BELOW: The following sentence does NOT complete the proof !]\nAnd as rpotrie has pointed out in another answer, the two dimensional case follows from the assumed transitivity condition.\n\nERROR NOTICE: I noticed a serious error in the above reasoning! If the isometry group $G$ of a Banach space $V$ is transitive on the unit sphere of $V$, it does NOT follow in any obvious way that the isometry group of a subspace $V'$ of $V$ is transitive on the unit sphere of $V'$. (If $e_1,e_2$ are unit vectors in $V'$, then an element $g$ of $G$ that carries $e_1$ to $e_2$ need not leave $V'$ invariant.)\n\nI did not at first realize how remarkable the conclusion is that transitivity on the unit sphere implies Euclidean. It can be rephrased as saying that transitivity on $S$ implies $2$-transitivity, which to me at least seems even more remarkable. (It was realizing this fact that let me see my silly error.)\n\nshare|improve this answer\nRight, Dick. You could solve the Banach-Mazur problem if you could prove that transitivity implies transitivity of every two dimensional subspace. \u2013\u00a0 Bill Johnson Oct 6 '10 at 18:28\nOwing to fat fingers I accidentally flagged Bill's comment when I meant to +1 it - apologies \u2013\u00a0 Yemon Choi Sep 3 '12 at 23:18\nPerhaps someone may fix the typo in (*). \u2013\u00a0 W\u0142odzimierz Holszty\u0144ski May 16 '13 at 0:02\n\nMaybe this is not good enough, but in dimension two, you can fix a unit vector $v$ and since you must have that $\\langle v, w \\rangle = cos \\alpha$ where $\\alpha$ is the angle between $v$ and $w$ (where $w$ is another unit vector).\n\nNow, you consider $A_w$ the (unique oritentation preserving) isometry that sends $v$ to $w$ and you get that $det(A_w-Id)$ should be $2-2cos(\\alpha)$ so you can have a well defined inner product between unit vectors which you can extend linearly.\n\nIt seems that extending this argument to higher dimensions may involve averaging (between the isometries that send $v$ to $w$) and it may be the same argument you had in mind.\n\nshare|improve this answer\n\nAs Greg says, the heart of the matter is to define a canonical inner product for any norm in finite dimensions; and this can easily be achieved on the dual $X^*$:\n\nIf $B$ is the unit ball of $X$, for any linear functions $\\omega , \\omega' \\in X^*$, define:\n\n$$ \\langle \\omega , \\omega' \\rangle := \\int_B \\omega \\ \\omega' dm $$\n\nwhere $m$ is the Lebesgue measure on $X$, normalized so that $m(B)=1$.\n\n(Observe this inner product is just the one in $L_2(B)$ restricted to $X^* \\subset L_2(B)$, so this construction applies to any borelian set $B \\subset X$, not necessarily a convex, symmetric body)\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70803/shortest-painting-of-the-sphere/70807\nText:\nTake the 2-minute tour \u00d7\n\nLet $S$ be the sphere in $\\mathbb{R}^3$ and $C:[0,1]\\to S$ a continuously differentiable curve on $S$. Let $T:[0,1]\\to\\mathbb{R}^3$ denote the tangent vector of $C$. Let $P(t)$ be the plane containing $C(t)$ and having normal vector $T(t)$.\n\nGiven a size $d$ of the \"paint brush\" we define the \"brush\" $b:[0,1]\\to \\mathcal{P}(S)$ by letting $b(t)$ be the points of $S$ that are at most a distance $d$ (metric on the sphere) from $C(t)$ that are contained in $P(t)$.\n\nWe can think of this as saying the \"brush\" $b(t)$ is an arc on the sphere that is \"orthogonal\" to the motion $C(t)$ of the \"paint brush\".\n\nGiven $d$ what is the arclength of the shortest curves such that $\\cup_{t\\in[0,1]} b(t) = S$. This says that the \"paint brush\" covered the sphere.\n\nshare|improve this question\nDuplicate? mathoverflow.net/questions/26212/\u2026 \u2013\u00a0 Gjergji Zaimi Jul 20 '11 at 9:19\n\n2 Answers 2\n\nThe model is that used by Henryk Gerlach and Heiko von der Mosel in their 2010 paper \"On sphere-filling ropes\" arXiv:1005.4609v1 (math.GT) may be relevant. Their question is different: What is the longest rope of a given thickness on a sphere? But their explicit solutions are packings, and it seems they could be converted to painting paths. Here is a piece of their Fig. 6:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Rope on sphere\n\nshare|improve this answer\nYes indeed -- by as brush width half the width of the rope. This seems to give an optimal painting for countably many widths. Very nice! \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:38\n\nThis question is somewhat related to this recent one. More precisely, the comment by Gjergji Zaimi in the earlier question gives a painting of length $2\\sqrt{2}\\pi$ for $d=\\pi/4$, which, as explained in another comment there, is optimal for a path at constant distance from the sphere. So for $d=\\pi/4$ the optimal length should be $2\\sqrt{2}\\pi$.\n\nshare|improve this answer\nOf course $d=\\pi/4$ is very special, since for this painting each point of the sphere is painted exactly once (except for a curve). It's not clear whether there is another value of $d$ for which this is possible. \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:02\nindeed your comment there was very good too. \u2013\u00a0 Pietro Majer Jul 20 '11 at 10:04\nThanks! But the answer by Joseph O'Rourke above is much more complete. \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:46\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/99959/generators-of-a-2d-lattice/99964\nText:\nTake the 2-minute tour \u00d7\n\nDear MO_World,\n\nI'm hoping someone can point me towards a reference for something. I have an invertible $2\\times 2$ matrix, $A$, with real entries such that for both of the rows, the entries are rationally independent (this ensures that $A\\mathbb Z^2$ only intersects the coordinate axes at the origin).\n\nWhat I want is a pair of generators of the lattice, $u$ and $v$, with $u$ belonging to the first quadrant and $v$ to the fourth quadrant.\n\nI have a proof that I'm not entirely happy with using continued fraction convergents, but as it's going in an already-long paper, I'd love to have a self-contained reference for this.\n\nDoes anyone have any suggestions?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nEDIT: why does a lattice have a shortest vector? To get to the other side? No. Because it is too far to walk around. Also your matrix $A$ is invertible, $A^{-1}$ has an operator norm with respect to the ordinary length, for any vector $w$ we have $|A^{-1} w| \\leq C |w|$ with a constant $C > 0$ that depends on the matrix. So $|A x| \\geq |x| / C. $ All nonzero lattice vectors have length at least 1, so all vectors in your lattice have length at least $1/C.$ Furthermore, the number of lattice vectors with length below any given bound is finite. So there is a shortest vector.\n\nEDITEDIT: For the why is the shortest vector part of a basis? Call it $u.$ It is expressed as $r x + s y,$ for $x,y$ the columns of your matrix. If $\\gcd(r,s) = g > 1,$ then $u/g$ is a strictly shorter vector in the lattice.\n\nORIGINAL: Take a shortest vector $u,$ and a fairly short vector $v,$ with $$ u \\cdot u = a, \\; \\; u \\cdot v = b, \\; \\; v \\cdot v = c. $$ Without loss of generality, $u$ is in the first quadrant. If $v$ is in the second or fourth quadrant we are done. If $v$ is in the third quadrant, replace by $-v.$ So now both are in the first quadrant, the angle $\\theta$ between them is below $\\pi/2$ and we get $$ 1 > \\cos \\theta = \\frac{b}{\\sqrt{ac}} > 0. $$ So $$ 0 \\leq b \\leq a \\leq c $$ and $$ b^2 < a c. $$\n\nSo, take the fairly short vector $v$ and subtract off multiples of $u$. We know that $u$ is shortest so for any integer $k$\n$$ | v - k u|^2 \\geq |u|^2 = a. $$\n\nNow, take the circle of radius $\\sqrt a$ around the origin. For real $t,$ we know that, if the line $v - t u$ passes through the circle at all, the length of the segment of intersection is no longer than $\\sqrt a,$ otherwise there would be an integral value of $t$ giving a lattice point inside the circle, which is forbidden. It follows that the point of closest approach to the origin is not closer than $\\frac{\\sqrt{3a}}{2}.$ In turn, pretending that the line passes through the fourth quadrant next, the length of the line segment between the intersections with the $x$ and $y$ axes is no shorter than $$ \\sqrt {3a} > \\sqrt a.$$ That is, there is an integral value $t = t_0$ for which $v - t_0 u$ lies in the fourth quadrant. The new basis for the lattice is $$u, v-t_0 u.$$\n\nshare|improve this answer\nThanks for this - a nice argument. \u2013\u00a0 Anthony Quas Jun 19 '12 at 4:52\n\nHere is an other proof.\n\nI will construct a hexagon with the vertices $u, v, w, -u, -v, -w$ from your lattice $L$ such that $$\\angle(u,v),\\ \\angle(v,w),\\ \\angle(w,-u)\\le \\tfrac\\pi2$$ and such that each pair $$(u,v),\\ (v,w),\\ (w,-u),\\ (-u,-v),\\ (-v,-w), (-w,u)$$ forms a basis of $L$. Clearly in this case one of these bases will satisfy your condition.\n\n\n  \u2022 Take $u$ in $L$ which minimize the norm.\n  \u2022 Take $v$ in $L\\backslash\\langle u\\rangle$ which minimize the norm.\n\nNote that $u$ and $v$ form a basis of $L$. WLOG we may assume that $\\angle(u,v)\\le\\tfrac\\pi2$. Note that for $w=v-u$ all the above conditions hold.\n\nshare|improve this answer\nAnother very nice creative argument - thank you! \u2013\u00a0 Anthony Quas Jun 19 '12 at 15:38\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/91528/probability-to-be-the-winner-in-a-tournament\nText:\nTake the 2-minute tour \u00d7\n\nIn a project in Game Theory we (Ayala Arad and Ariel Rubinstein) are stuck with the following \"simple\" question. We are sure of the conjecture but we failed to find a (hopefully simple) proof:\n\nLet A and B be two non-empty finite disjoint sets of players. Any two players in A are \"matched\" and $\\$2$ are transferred from one to the other. Any player in A is also matched with any player in B and $\\$1$ is transferred from one to the other. The two possible directions of each transfer are equally likely and independent. No transfers are carried out between players in B. The winner is the player with the highest net transfers. In the case of a tie, the winner is selected randomly from among the highest scoring players. (For example if |A|=1 and |B|=2 the probability of winning for the player in A is 1/4 and the probability for the player in B is 3/8. If |A|=|B|=2 the corresponding numbers are 21/64 and 11/64). Claim: If |AUB|>3 then the probability of winning for any player in A is strictly larger than that of any player in B.\n\nshare|improve this question\nDear Ariel, Welcome to MathOverflow! May the force be with you :) \u2013\u00a0 Gil Kalai Mar 18 '12 at 14:16\nWouldn't any two players in A have the same number of transfers, and the same for B? I guess I don't understand the game. \u2013\u00a0 Patrick Reardon Mar 18 '12 at 18:15\nTo Patrick: Note, that the direction of transfer between any two players is indepedent from the directions in other \"matches\". \u2013\u00a0 Ariel Rubinstein Mar 18 '12 at 22:00\nThanks, it's clearer now. So we could say that every pair of players in $A$ flip a fair coin and the winner gets $\\$2$. Every pair of players with one from $A$ and one from $B$ flip a fair coin and the winner gets $\\$1$. Interesting problem! \u2013\u00a0 Patrick Reardon Mar 19 '12 at 8:33\n\n3 Answers 3\n\nHere's a partial answer, I believe that the technique can be generalized to include more cases.\n\nSuppose that $|A|=|B|=n$ and $n$ is large enough. As $n\\to \\infty$, the distribution of what an $A$-player gets is roughly $N(0,3n-2)$ and what $B$=player gets is roughly $N(0,n)$. Hence, we can choose some threshold $t_n$ (about $\\sqrt{\\log n}$ or so) such that the expected number of $A$-players getting more than $t_n$ is large (tends to infinity) and the expected number of $B$-players getting more then $t_n$ is small (tends to zero). The probability that a $B$-player will get more then $t_n$ therefore also goes to 0.\n\nFurthermore, the amounts different players get are almost pairwise independent (they are independent up to the amount one of them pays the other). Thus, a second moment argument easily show that the probability of some $A$-player gets more then $t_n$ goes to 1. So the probability that an $A$-player will win goes to 1. Since the players are symmetric and there are equal number of $A$ and $B$ players, we get that the probability of an $A$-player to win is strictly larger then that of a $B$-player.\n\nThis can be extended to other regimes by analyzing what $t_n$ and the probabilities actually are and perhaps using the binomial distribution instead of Normal (actually, I now notice that the argument is not precise as it is since I use Normal approximation in a regime where it is not formally valid, but it's easy to correct). Perhaps all cases where either $|A|$ or $|B|$ are large enough can be covered that way and perhaps \"large enough\" turns out to be pretty small after all. Perhaps I'll try to give a more complete answer later.\n\nOne final remark: it seems that (at least asymptotically) it is not important that $2>1$, but only that $2>0$.\n\nshare|improve this answer\nThanks. We do need the result for small values as well (and not just for large numbers). Note that for general |A| and |B| (not for the case that |A|=|B|) we need the condition that $2>$1: Consider the case that the transfer between a member of A and a member of B (which is now $1) is very very high then if |A|>|B|, the probability of a member of B to win will be larger (the transfers inside B will be negligible). \u2013\u00a0 Ariel Rubinstein Mar 18 '12 at 21:58\n\nThis was intended to be a comment to Ori's post but it is too long, so I'm posting it as an answer. First of all, let us modify the game a bit by initially giving each player a random score between $0$ and $\\varepsilon$. That will break the ties just as needed but will allow us to talk about the winner.\n\nNow the case $|A|=|B|$ is trivial. Let's do all transactions between $A$ and $B$ first and look at the resulting configurations. They split into natural pairs (swapping $A$ and $B$). Now let $a$ be the top score in $A$ and $b$ be the top score in $B$. Arrange the pair so that $a>b$. Then we need to show that for every configuration the probability that the top score in $A$ will become less than $b$ after transactions in $A$ is less than that the probability that the top score in $B$ will become larger than $a$ if we do the transactions in $B$. Identify $A$ with $B$ in some way so that the top scorers are identified. Any way to do the transactions in $A$ that moves the winner to $B$ should bring the score $a$ of the top scorer in $A$ below $b$ at the very least and that may be insufficient in some configurations. On the other hand, if have one such way and do the inverse transactions in $B$ instead, they'll bring the top scorer in $B$ above $a$ and it is not necessary to move the winner to $B$. That's all one needs to say about the equal cardinalities case.\n\nNow, like Ori, I have to say that I'll try to give a more complete answer later.\n\nshare|improve this answer\n\nFor the little it might be worth, here are the results of some simulations:\n\nThe columns correspond to values of $|A|$ and the rows to values of $|B|$. The four-tuple in each cell is (Probability winner is in $A$, Probability winner is in $B$, Probability a given member of $A$ is the winner, Probability a given member of $B$ is the winner).\n\nI simulated each of these 10,000 times, rounded results to the nearest percent, and retyped them (which has a small chance of having introduced additional errors).\n\nI was struck by the non-monotonicity in the third entry as you go down the third column, so I repeated these trials and got the same result.\n\nshare|improve this answer\nThanks. We conducted here similar simulation for all |A|,|B|<11 In case you are interested: arielrubinstein.tau.ac.il/simulation.pdf \u2013\u00a0 Ariel Rubinstein Mar 19 '12 at 5:43\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/48298/how-to-calculate-the-effect-of-the-earths-magnetic-field-on-a-hze-particle?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to calculate the protection provided by the earth's magnetic field from HZE particles to astronauts in low earth orbit, such as those on the ISS.\n\nHZE particles are often quoted as a danger of travel in deep space. But given their high energies I am skeptical that the Earth's magnetic field provides significant protection to humans outside the atmosphere (the ISS orbits ~370km above the Earth).\n\nI have been able to find data on the energy of the particles expressed in MeV or GeV and the strength of the magnetic field expressed in microteslas.\n\nWhat formulas would be applicable in calculating whether 1) the particle is deflected, and 2) if it's not deflected the energy reduction by the time it reaches a given altitude?\n\nshare|improve this question\nAnd? What is the question here? Are you unsure of the meaning of the units; unsure of the physics or what? I mean, the radius of curvature goes by $p_{\\perp}/qB$ (you can look up the full derivation in any E&M text). \u2013\u00a0 dmckee Jan 3 '13 at 22:13\nI'm trying to calculate the protection provided by the earth's magnetic field from HZE particles to astronauts in LEO, eg: the ISS. \u2013\u00a0 Patrick Ritchie Jan 4 '13 at 0:00\n\n1 Answer 1\n\nThe basic physcs here is the Lorentz force on a moving charge, $q$, with velocity, $\\vec{v}$ due to a magnetic field $\\vec{B}$. $$ F = q \\left( \\vec{E} + \\vec{v} \\times \\vec{B} \\right) \\quad ,$$ where we ignore the electrical field so we get $$ \\vec{F}_B = q \\vec{v} \\times \\vec{B}\\quad .$$\n\nThe cross-product implies that the force acts perpendicularly to both field and velocity which means that the general path is (locally) helix with it's axis along the direction of the magnetic field.\n\nThe accelration is $\\vec{a}_B = \\frac{\\vec{F}_B}{m} = \\frac{q v_\\perp B}{m}$ which implies a radius of curvature of in the plane normal to the magnetic field. Noting that this is a centripital force we use $a = \\frac{v^2_{\\perp}}{r}$ to find the radius of curvature as $$r_\\perp = \\frac{v^2_{\\perp}}{a} = \\frac{m v_\\perp}{qB} = \\frac{p_\\perp}{qB} \\quad .$$\n\nDespite the classical derivation the final form involving momentum, charge and field is relativisitcally correct.\n\nMomentum parallel to the field is unaffected.\n\nNow, saying that the path is a helix is only correct for uniform fields which is not true over scales a significant fraction of the Earth's radius, but it is a good approximation of scales of a hundred kilometers or less, which suggests a reasonable step size for a low precision simulation.\n\nMoving beyond the physics you are asking about the the desired result, these particles never lose any energy due to the effects of magnetic fields and are just pointed in different direction. The result is to first order no change in the flux ariving at objects in orbit.\n\nThere are some places where that first order result is insuffient (the flux can actually get amplified near the magnetic poles where particles are revesed and could pass the target twice), but it is a place to start.\n\nNote that I put the charge in the wrong place in the comment I dashed off earlier and have used moderator superpower to fix it post facto.\n\nshare|improve this answer\nMaybe you should emphasize the conclusion that no protection is provided by the earth's magnetic field because the flux does not change locally. Probably the OP is confused by the deviations by the sun's magnetic field, which happen because of the much larger volume that magnetic field affects (c.f.cosmic rays and climate) \u2013\u00a0 anna v Jan 4 '13 at 5:30\nthat should be \"than the one the earth's magnetic field affects\" \u2013\u00a0 anna v Jan 4 '13 at 9:42\nThanks, i'll dig into these and see if I can get some results. \u2013\u00a0 Patrick Ritchie Jan 4 '13 at 15:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/146187/probability-of-picking-a-specific-card-from-a-deck\nText:\nTake the 2-minute tour \u00d7\n\nQuestion: Assume you have a deck with with $52$ cards ($4$ suites of $13$ cards: numbers $1\\ldots 9$, and faces J,Q,K). What is the probability you draw jack of hearts in a hand of $5$?\n\nMy way of thinking is the following:\n\n$$\\frac{\\left(\\dfrac{1\\cdot51\\cdot50\\cdot49\\cdot48}{4!}\\right)}{ \\left(\\dfrac{52\\cdot51\\cdot50\\cdot49\\cdot48}{5!}\\right)}$$\n\n$1$ is for the jack of hearts being drawn, and then $51\\ldots48$ for the rest of the $4$ cards\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 4 down vote accepted\n\nYour thinking is correct, though let me provide another way of looking at the problem that might make its structure clearer:\n\n  \u2022 There are ${51\\choose 4}$ ways to pick a hand that include the Jack of Hearts (because once we've picked the Jack, we can choose 4 other cards from the remaining 51)\n  \u2022 There are ${52\\choose 5}$ ways to pick a hand, with no restrictions.\n\nTherefore the probability of getting a hand with the Jack of Hearts is\n\n$$\\frac{51\\choose 4}{52\\choose 5} = \\frac{51!5!47!}{4!47!52!} = \\frac{5}{52}$$\n\nYou can check that the obvious generalization is, in fact, true: the probability of drawing a particular card in a hand of $m$ cards with a deck of size $n$ is $m/n$.\n\nshare|improve this answer\nadd comment\n\nThe probability you draw the jack of hearts is the same as the probability of drawing any other particular card. Since you draw 5 cards, the 52 individual probabilities have to add up to 5, so each probability is 5/52. In particular, the probability of drawing the jack of hearts is 5/52.\n\nshare|improve this answer\nadd comment\n\nAlternatively, there are $\\binom{51}{5}$ ways of picking a hand that does not have the Jack of Hearts. There are a total of $\\binom{52}{5}$ ways of picking $5$ cards, so the probability of choosing a hand with the Jack of Hearts is: $$1 - \\frac{\\binom{51}{5}}{\\binom{52}{5}} = 1-\\frac{47}{52} = \\frac{5}{52}$$\n\nshare|improve this answer\nAlthough a bit more complicated, this is valid (+1) \u2013\u00a0 robjohn Mar 5 at 23:42\nadd comment\n5/52 seems wrong to me.  \n\nI suggest the slightly higher probability of:\n                          n = (1/52 + 1/51 + 1/50 + 1/49 + 1/48)\n\nWhich approximates to:\n                          n = 5/50\n\nEach time a cards is picked the deck gets smaller, and the probability of \npicking the \"good\" card the next round increases.\n\n5/52 would be the probability ONLY if after each time you drew one card, \nyou replaced it into the deck before the next draw.\nshare|improve this answer\nWith replacement, the probability would be $1-\\left(\\frac{51}{52}\\right)^5$ \u2013\u00a0 robjohn Mar 5 at 23:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/138944/questions-on-symmetric-matrices\nText:\nTake the 2-minute tour \u00d7\n\nDescribe a basis for the vector space of symmetric n x n matrices. What is the dimension of this space?\n\nshare|improve this question\nIs this homework? If it is, it is customary to label it so, and to mention any attempts you have made. \u2013\u00a0 Martin Argerami Apr 30 '12 at 16:08\n@Jim_CS : My guess is that whoever down-voted this question did so because it's written as if you copied a question written by someone other than yourself. \u2013\u00a0 Michael Hardy Apr 30 '12 at 16:16\nIt was in an exam i had today and i never came across it during the course or pre exam study so i had no answer for it. well i said the dimension was n as that seemed obvious. \u2013\u00a0 Jim_CS Apr 30 '12 at 16:20\nReading the comments, I feel you could first try to answer the following questions: (i) Describe a basis for the vector space of all the $n\\times n$ matrices? (ii) What is its dimension? \u2013\u00a0 Did Apr 30 '12 at 18:13\nI dont know what all the downvotes are for...what else am I supposed to put in the post when I wasnt even able to make an attempt at this question in the exam? (apart from putting dim = n, which seems wrong in any case) \u2013\u00a0 Jim_CS Apr 30 '12 at 22:19\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nHINT: If you know all of the elements on and above the diagonal of a symmetric matrix, you know the whole matrix. How many elements are there on or above the diagonal of an $n\\times n$ matrix?\n\nAdded: I can see that you're having trouble getting a handle on the vector space in question; perhaps this will help. Let $S_n$ be the space of $n\\times n$ symmetric matrices. In the simplest case that isn't completely trivial, $n=2$, the elements of $S_2$ are matrices of the form $$\\pmatrix{a&b\\\\b&c}\\;.$$ Vector addition in $S_2$ is just ordinary matrix addition: $$\\pmatrix{a_1&b_1\\\\b_1&c_1}+\\pmatrix{a_2&b_2\\\\b_2&c_2}=\\pmatrix{a_1+a_2&b_1+b_2\\\\b_1+b_2&c_1+c_2}\\;.$$ Note that the result of this addition is still symmetric, so it really is in $S_2$. If it weren't, $S_2$ wouldn't be closed under addition and therefore wouldn't be a vector space after all.\n\nScalar multiplication in $S_2$ is ordinary multiplication of a matrix by a scalar: $$\\alpha\\pmatrix{a&b\\\\b&c}=\\pmatrix{\\alpha a&\\alpha b\\\\\\alpha b&\\alpha c}\\;,$$ and again all's well, since the result is still in $S_2$.\n\nHere's a simple exercise to help you get more accustomed to working with this vector space.\n\nLet $V=\\{\\langle a,b,c,d\\rangle\\in\\Bbb R^4:b=c\\}$.\n\n  1. Prove that $V$ is a subspace of $\\Bbb R^4$.\n  2. Prove that $V$ is isomorphic to $S_2$. That is, find a linear transformation $T:V\\to S_2$ that is one-to-one and maps $V$ onto $S_2$.\nshare|improve this answer\nWell there are n elements on the diagonal so the dimension is n, yes? \u2013\u00a0 Jim_CS Apr 30 '12 at 17:01\n@Jim_CS: There are $n$ elements on the diagonal, but specifying them isn't enough to specify the whole matrix, so the dimension of the space is more than $n$. You also have to specify the elements above the diagonal. How many of those are there? As for your other question, it means exactly what it says: the space of $n\\times n$ symmetric matrices, i.e., the space whose elements are these matrices. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 17:03\n@Jim_CS : it seems to me that you're making a confusion between the dimension of the space spanned by the column of a single matrix (i.e. its rank) and the dimension of the space of all (symmetric) matrices, which is a vector space itself (the \"vectors\" are the matrices) \u2013\u00a0 Andrea Mori Apr 30 '12 at 17:13\n@Jim_CS: The $3\\times 3$ identity matrix isn't a vector space, so it doesn't even have a dimension. Its rank is $3$. That aside, you're not thinking about what the question actually asks. You have a vector space $V$ whose elements $-$ the actual vectors in $V$ $-$ are $n\\times n$ symmetric matrices. Each matrix is one vector in $V$. You could write it out as a single row of $n^2$ numbers instead of as a square array, except that it would be much harder to tell that it was symmetric. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 17:15\n@Jim_CS: I'll expand my answer a bit to try to give you a better idea of what the space itself is like. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 22:24\nshow 4 more comments\n\nIf $A$ is a symmetric $n\\times n$ matrix, then $A$ has the form $$ \\begin{bmatrix} * \\ & a_1 & a_2 & \\cdots & a_k \\\\ a_1 & * \\ & a_3 \\\\ a_2 & a_3 & * \\ \\\\ \\vdots & & & \\ddots & \\\\ \\\\ a_k & & & & * \\ \\end{bmatrix} $$ where the $*$ entries are whatever you like them to be. You can see that we have $a_{ij}=a_{ji}$.\n\nFrom this form you can see that we need $n$ elements in the basis to span the diagonal entries. For the remaining $n(n-1)$ entries, we need exactly $\\frac{1}{2}n(n-1)$ elements in the basis to in order to span those entries (due to the fact that $a_{ij}=a_{ji}$). This gives a basis with $\\frac{1}{2}n(n+1)$ elements.\n\nDefine $T_{ij}$ to be the matrix with $(T_{ij})_{ij}=1$ and all other entries equal to $0$. Then define $$ M_{ij} = T_{ij}+T_{ij}^\\text t $$ where $i$ and $j$ range over $1,2,\\dots, n$. Then for a given $n\\times n$ symmetric matrix $A$, we can write it as $$ A = \\sum_{i=1}^n\\sum_{j=1}^n \\frac{1+\\delta_{ij}}{2}(A)_{ij}M_{ij} $$ where $(A)_{ij}$ denotes the $(i,j)^\\text{th}$ entry of the given matrix $A$. The $\\frac{1+\\delta_{ij}}{2}$ in the sum is to correct for the fact that $M_{ij}=M_{ji}$.\n\nThe collection of the distinct $M_{ij}$ will form a basis for the space of $n\\times n$ symmetric matrices. Of course, this is not proof, but provides a way that you might express the basis.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/20529/fast-method-for-nth-squarefree-number-using-mathematica/20541\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to compute Nth Squarefree numbers using Mathematica. What I am trying to utilize is the SquareFreeQ[i] function.\n\nHere is my solution :\n\nNSqFree[N_] := For[n = 1; i = 1, n <= N + 1, If[SquareFreeQ[i], If[n == N, Print[i] ] n++] i++]\n\nBut I am supposed to compute NSqFree[1000000000] but seems like my approach is taking for ever. Any faster method ?\n\n\n\nHere an exactly identical topcoder question and the corresponding editorial for the same.\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n\nYou have to us the Inclusion-Exclusion principle: suppose you want to find the number of square free numbers up to $N$, then from $N$ you have to substract the number of integers divisible by the square of a prime, but then you have to add any multiple of the square of the product of two discinct primes and so on, in formulas the number looked for is $$ N - \\sum_{p^2 \\le N} \\left\\lfloor\\frac{N}{p^2}\\right\\rfloor + \\sum_{p^2q^2 \\le N} \\left\\lfloor\\frac{N}{p^2q^2}\\right\\rfloor - \\sum_{p^2q^2r^2 \\le N} \\left\\lfloor\\frac{N}{p^2q^2r^2}\\right\\rfloor + \\cdots -\\cdots $$ using the moebius $\\mu$ function you can write this last formula as $$ \\sum_{n \\le \\sqrt{N}} \\mu(n) \\left\\lfloor\\frac{N}{n^2}\\right\\rfloor $$ I don't know how to write this in mathematica but it should take a negligible fraction of the time it takes your current method.\n\nshare|improve this answer\nBut my problem is to find the exact Nth Square free number not the number of square free numbers up to N,I have used your idea in here and here but I am not getting how to use the same formula to get the exactly Nth square free number. \u2013\u00a0 Quixotic Feb 5 '11 at 18:42\nOkay I guess I got my answer and here is the explanation. \u2013\u00a0 Quixotic Feb 5 '11 at 18:50\nI'm sorry, I had misunderstood the question. But you can use the same formula combined with a binary search. It will take only a few applications of the formula. \u2013\u00a0 Esteban Crespi Feb 5 '11 at 18:52\nadd comment\n\nYou won't do a billion (if I counted the zeros right) loops any time soon, so you need a better approach. Wikipedia has an approximation under the section Distribution of square-free numbers. So you could start with $10^9 \\pi^2/6$ and calculate how many below that are square-free, then correct from there. You will need to use inclusion/exclusion, but there are only about 40,000 to consider.\n\nshare|improve this answer\nadd comment\n\nI'm not an expert of number-theoretic algorithms, but it seems to me that you can employing the Chinese Remainder Theorem to obtain a decent first stab at a \"sieving\" algorithm.\n\n  \u2022 Use several registers r[p], each storing a residue modulo p2 for some prime p. Define such a register for various small primes p\u00a0\u2208\u00a0{2,\u20093,\u20095,\u2009...\u2009,\u2009P} for some suitably large prime P. You will use these to represent an integer R, such that R\u00a0\u2261\u00a0r[p] (mod p2). You shouldn't need too many such registers to faithfully represent even reasonably large non-negative numbers (the registers can uniquely determine any integer from 1 to 22\u00a0\u00d7\u00a032\u00a0\u00d7\u00a052\u00a0\u00d7\u00a0...\u00a0\u00d7\u00a0P2).\n\n  \u2022 Whenever you wish to increment R, increment each of the registers r[p] as well. If R is square-free, none of these registers will be zero modulo the square of the appropriate prime. For sufficiently small integers N, you can even characterize N as being square-free if none of these residues are zero. Put another way, the more registers r[p] you maintain, the larger the range of square-free numbers you can automatically detect using these registers.\n\nSuppose that you want to test for square-freeness up to some upper limit N. What do you need to test square-freeness using nothing but registers such as I've described? What you need is for any composite number less than N to have a prime factor from the list of registers that you maintain; that is, you need registers for each of the primes up to \u221aN.\n\nIf you're going to iterate through all integers anyway, you can discover the list of primes that you need to characterize square-freeness at the same time by the Sieve of Erasthotenes, and construct the list of residues modulo squares-of-primes as you go. Any time you find a new prime P, so long as P2\u00a0<\u00a0N, add P to the list of primes for which you maintain registers and initialize a register for residues modulo P2.\n\nAs Ross suggests in his answer, you can use results on the distribution of square-free numbers to obtain an upper bound for the Nth square-free number (it should grow more slowly than N\u00a0ln(N) or so, in any case). This gives you an upper bound on the number of registers that you have to maintain as you search for square-free integers.\n\nFrom this, you should actually be able to show a polynomial-time asymptotic upper bound on the runtime of your procedure.\n\nshare|improve this answer\nadd comment\n\nI think that your method can be improved by sieving: if $n$ is not squarefree you don't need to check any of its multiples. Start with a reasonable estimate (like the one Ross Millikan gave) and sieve like you would do in a prime sieve.\n\nIs this viable? I don't know! I can't program in Mathematica, but later today I'll try to implement this in Python.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/68966/mean-value-of-arithmetic-function?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we define a mean value of arithmetic function $G(f)$ as $$ G(f)=\\lim_{x \\rightarrow \\infty} \\frac{1}{x \\log{x}} \\sum_{n \\leq x} f(n) \\log{n},$$ and suppose now for an arithmetic function $f$, $G(f)$ exist and is equal to $A$, how to use this result to show that the ordinary mean value of arithmetic function $M(f)=\\lim_{x \\rightarrow \\infty} \\frac{1}{x} \\sum_{n \\leq x} f(n)$ also exists?\n\nshare|improve this question\nPunctution should go inside double dollar signs (ideally separated by \"\\;\"), otherwise it appears on the next line. \u2013\u00a0 joriki Oct 1 '11 at 8:46\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nVia Abel's summation formula: $$\\sum_{n\\le x} (f(n)\\log n)\\frac{1}{\\log n}=\\left(\\sum_{n\\le x}f(n)\\log n\\right)\\frac{1}{\\log x}+\\int_2^x \\left(\\sum_{m\\le u} f(m)\\log m\\right)\\frac{du}{u\\log^2 u}.$$ Divide by $x$ and subtract, obtain: $$M_x(f)-G_x(f)=\\frac{1}{x}\\int_2^xG_u(f)\\frac{du}{\\log u}=\\frac{\\mathrm{Li}(x)}{x}\\left(A+O(1)\\right)\\to0.$$\n\nshare|improve this answer\nadd comment\n\nYou'll want to use \"partial summation\", also called \"summation by parts\". Define $G(f;x) = \\sum_{n\\le x} f(n)\\log n$ and $M(f;x) = \\sum_{n\\le x} f(n)$. Then you can write $M(f;x)$ as a Riemann-Stieltjes integral $$ M(f;x) = \\int_1^x \\frac1{\\log t} \\, dG(f;t). $$ (Technically the lower endpoint should be $1-\\epsilon$.) Then integrating by parts gives $$ M(f;x) = \\frac{G(f;x)}{\\log x} + \\int_1^x \\frac{G(f;t)}{t(\\log t)^2} \\,dt. \\tag1 $$ (Even if you don't know Riemann-Stieltjes integrals, you can still verify this last identity by hand - just split the integral up into intervals of length 1, on which $G$ is constant.)\n\nWhen you divide both sides of equation (1) by $x$ and take the limit as $x\\to\\infty$, all that remains to show is that the term with the integral tends to $0$. (Note that $G(f;t)=0$ for $t<2$, so there's no problem with the integral at the lower endpoint.)\n\nshare|improve this answer\n(+1) I just realized my answer is essentially the same thing, I didn't see it at first because I'm not used to RS integration. The integrand in $\\mathrm{(1)}$ is $(A+o(1))/t$ so its integral divided by $x$ is $\\frac{\\log x}{x}(A+O(1))$ which is $o(1)$. Thus the arithmetic mean exists and equals $A$. \u2013\u00a0 anon Oct 1 '11 at 9:40\nTrue ... the integrand is in fact $(A+o(1))/\\log t$, but the integral still turns out to be $o(1)$. \u2013\u00a0 Greg Martin Oct 2 '11 at 3:29\nOh yes, you're correct. \u2013\u00a0 anon Oct 2 '11 at 3:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96338/integration-under-functional-sign/96348\nText:\nTake the 2-minute tour \u00d7\n\nLet $f(x,y)$ be some bounded with its derivatives continuous function on $\\Omega \\times \\overline{\\Omega}$, where $\\Omega$ is a domain in $\\mathbb{R}^n$. Let $f(\\,\\,\\cdot\\,,\\,y) \\in \\mathcal{E}(\\Omega)$ for any fixed $y$. Let $L_{x} \\in \\mathcal{E}'(\\Omega)$. Is it true that\n\n$$\\int\\limits_{\\overline{\\Omega}} L_{x}f(x,y) \\, \\mu(dy) = L_{x}\\int\\limits_{\\overline{\\Omega}} f(x,y) \\, \\mu(dy)$$\n\nholds for any probability measure $\\mu$ in $\\overline{\\Omega}$? If it is true, how to show it?\n\nIf $f(x,y) \\in \\mathcal{E}(\\Omega \\times \\Omega')$ where domain $\\Omega'$ is such that $\\overline{\\Omega} \\subseteq \\Omega'$ then the equality holds by virtue of the tensor product of distributions theorem.\n\nshare|improve this question\nDo you need that the derivatives of $f(\\cdot,y)$ to be bounded, in other to ensure us that $x\\mapsto \\int_{\\overline \\Omega}f(x,y)\\mu(dy)$ is infinitely many times differentiable? \u2013\u00a0 Davide Giraudo May 8 '12 at 15:08\nThanks, I've corrected the question. \u2013\u00a0 Nimza May 8 '12 at 17:46\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nSuppose first that $L_x\\in C^\\infty_0(\\Omega)$. Then the equality you ask about is Fubini's theorem.\n\nSuppose now that $L_x$ is not necessarily smooth. Choose a sequence $\\newcommand{\\ve}{\\varepsilon}$ $L_{\\ve,x}\\in \\mathscr{E}'(\\Omega)$ that converges to $L_x$ in the weak sense. Then one needs to prove that\n\n$$ \\lim_{\\ve\\to 0} L_{\\ve,x}\\int_\\Omega f(x,y)d\\mu(y)=L_x\\int_\\Omega f(x,y)d\\mu(y), \\tag{A} $$\n\n$$ \\lim_{\\ve\\to 0}\\int_\\Omega (L_{\\ve,x}-L_x)f(x,y)d\\mu(y)=0. \\tag{B} $$\n\nThe equality (A) is an immediate consequence of the weak convergence. The equality (B) requires an additional assumption on $f$.\n\nDenote by $K$ a compact set containing the support of $L_x$ and $L_{\\ve, x}$, $\\ve$ sufficiently small. If we assume that for any multi-index $\\alpha$ we have\n\n$$ \\sup_{x\\in K, y\\in \\Omega} \\partial^\\alpha_x f(x,y) <\\infty, \\tag{C} $$\n\nthen (B) follows by invoking the uniform boundedness principle for $\\mathscr{E}'(\\Omega)$ which states that if a sequence $u_n \\in \\mathscr{E}'(\\Omega)$ converges weakly to $0$, then $ u_n(\\phi)\\to 0$ uniformly for $\\phi$ in a bounded subset of $\\mathscr{E}(\\Omega)$.\n\nI recall that a subset $\\Phi\\subset \\mathscr{E}(\\Omega)$ is bounded if for any compact $K\\subset \\Omega$ and any multi-index $\\alpha$ we have\n\n$$ \\sup_{x\\in K, \\phi\\in \\Phi} \\partial^\\alpha_x\\phi(x) <\\infty. $$\n\nUpdate. Let me set $\\phi_y:=f(x,y)$. To insure the integrability of $y\\mapsto L(\\phi_y)$ for any $L\\in\\mathscr{E}'(\\Omega)$ it suffices to assume that the map $\\Omega\\ni y\\mapsto \\phi_y\\in\\mathscr{E}(\\Omega)$ is continuous, i.e., for any $y_0\\in \\Omega$, any $\\ve>0$, any compact $K\\subset \\Omega$ and any multi-index $\\alpha$ there exists $\\delta>0$ such that\n\n$$|y-y_0|<\\delta \\Rightarrow \\sup_{x\\in K}\\left|\\partial^\\alpha_x\\bigl(\\; \\phi_y(x)-\\phi_{y_0}(x)\\;\\bigr )\\right| <\\ve. $$\n\nshare|improve this answer\nGreat thanks! Can you give me please some reference on such version of uniform boundness principle? \u2013\u00a0 Nimza May 8 '12 at 15:34\nThe most complete reference would be Francois Treve, Topological Vector Sapeces, Distributions and Kernels, now in Dover. However this is a bit harder to digest given its generality. A more readable and helpful source would be vol. 2 of Gelfand and Shilov's treatise on generalized functions. There they investigate complete countably normed spaces, or Frechet spaces and they prove among other things the uniform boundedness principle. The space $\\mathscr{E}(\\Omega)$ is such a space. \u2013\u00a0 Liviu Nicolaescu May 8 '12 at 16:00\nThanks for update and for references. \u2013\u00a0 Nimza May 8 '12 at 17:49\n\nDavide's right. Neither integral makes sense because the function was only continuous. If you assume $f$ is a smooth test function, then a priori it's only clear when $\\mu$ is a finite linear combination of point masses. Thus, you cannot avoid using a Riemann sums trick: approximate the more general measure with a sequence of finitely supported measures $\\mu_n$. My impression is that the general theory of distributions cannot start without taking Riemann-type sums at some point and that any argument probably has this maneuver underlying it somewhere.\n\nFor the right hand side, you need to prove that $\\int f(x,y) d\\mu_n \\to \\int f(x,y) d\\mu(y)$ in some $C^k$ topology as functions of $x$ over the support of $L_x$. For the left hand side, check that $\\mu_n \\rightharpoonup \\mu$ weakly and $L_x f(x,y)$ is continuous in $y$. This step again uses that $L_x$ is continuous with respect to $C^k$ convergence for some $k$.\n\nNote, if you establish this identity when $\\mu$ is, say, an absolutely continuous measure with a smooth density function, then you can pass to the limit for a general finite measure by using a mollifying kernel (analogous to taking $L_{\\epsilon, x}$ in Liviu's argument, but this is a mollification in the $y$ variable, and is just measure theoretic).\n\nshare|improve this answer\n@ Phil The collection of functions $\\Phi:=(\\; f(-,y)\\;)_{y\\in \\Omega}$ is bounded in $\\mathscr{E}(\\Omega)$ due to (C). Set $$s(\\varepsilon):=\\sup_{y\\in \\Omega} |(L_{\\varepsilon, x}-L_x)f(x,y)|$$ The uniform boundedness principle implies $s(\\varepsilon)\\to 0$. Hence $$\\left|\\;\\int_\\Omega(L_{\\varepsilon, x}-L_x)f(x,y)d\\mu(y)\\;\\right| \\leq \\int_Omega s(\\varepsilon) d\\mu(y)=s(\\varepsilon)\\to 0. $$ \u2013\u00a0 Liviu Nicolaescu May 8 '12 at 16:23\n(It looks like there is a coding error in the comment.) I think I'm starting to see the relationship between these two arguments. On the one hand, your argument appeals to Fubini to get started; the argument that I suggested actually avoids Fubini's theorem by taking Riemann sums. I actually thought that you couldn't get away without this move (for the reason in my post), but it looks like you can just get by with the continuity in the $y$ variable? Thoughts? \u2013\u00a0 Phil Isett May 8 '12 at 20:35\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55633/diophantine-problem?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nI have reduced a knotty research problem to the following reasonable looking form:\n\nGiven any two integers $a$ and $b$, show that there are natural numbers $x_1,x_2,x_3$ and a (probaby negative) integer $n$, where $-3n < x_1+x_2+x_3$, satisfying:\n\n$x_1x_2x_3=-n^3-an-b,$ and\n\n\nI am not expecting a solution to this (although that would of course be the ideal outcome)! However, I don't really know where to start. How might one go about solving something like this? Are there any tried and tested methods I should know about?\n\nAnd finally, given the unsolvability of Hilbert's tenth problem, is it possible that there is no way to know whether or not this is true?\n\n(edit: equations corrected. Sorry for time-wasting!)\n\nshare|improve this question\nThanks! To everyone. Your observations have made me realise I've made a stupid mistake. I have corrected the equations in my question...they now look a lot more probable. \u2013\u00a0 Adam Feb 16 '11 at 22:54\nIf $a$ is positive you still get bounded $n,$ after your changes. \u2013\u00a0 Will Jagy Feb 16 '11 at 23:06\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nFollowing up Charles Matthews' idea, Maclaurin's inequality gives\n\n$$\\frac{x_1 + x_2 + x_3}{3} \\ge \\sqrt{ \\frac{3n^2 - 2n + a}{3} } \\ge \\sqrt[3]{ n^3 + an - b}.$$\n\nThe second inequality in particular expands out to an inequality of the form $-54n^5 + \\text{lower order terms} \\ge 0$, so does in fact provide an upper bound for $n$ in terms of $a$ and $b$. If you don't expect the statement to be true, from here it is possible to search for counterexamples.\n\nIf I'm not mistaken, the above inequality never holds when $a = b = 1$, so no such $n$ exists in this case. In general in order to get a reasonable number of possibilities for $n$, $a$ needs to be large compared to $b$. Are you sure you meant to ask the question about any possible $a, b$?\n\nshare|improve this answer\n\nMy guess is that it doesn't work. But I think elementary methods are your friend here. For example the two equations seem set up to apply the AM-GM inequality here, which apparently yields a comparison of two sextic polynomials in n. I think this comes out bounding n in terms of a and b. And unless the x-values are similar in size, there should be more. But most n don't factor like that, so I would expect this to fail.\n\nshare|improve this answer\n\nYou are asking whether the cubic polynomial\n\n$$ X^3 - c X^2 + (a + 3 n^2 -2n) X - (n^3 +a n - b) = 0$$ has positive integer solutions under the assumption that $c < 3 n.$ While I don't know the answer, this presumably reduces to standard arithmetic geometry, bypassing Hilbert's tenth problem.\n\nshare|improve this answer\nI think you mean c > 3n. \u2013\u00a0 Qiaochu Yuan Feb 16 '11 at 17:52\nwith the correction it should be possible with a=2 and b=1 to find the local maximum of the cubic and verify that it is below the x axis \u2013\u00a0 Aaron Meyerowitz Feb 16 '11 at 23:17\n\nHere is an alternative formulation (possibly your original one) where $x_m$ is replaced by $n +$ something which yields $0 < i+j+k$ with each of $i,j,k \\ge -n$ . Then (I've already fixed one mistake, so check my work)\n\n$2(i+j+k+1)n + (ij+jk +ki) = a$\n\n$(i+j+k)n^2 + (ij+jk+ki)n +ijk = an - b$\n\n$(i+j+k+2)n^2 - ijk = b$\n\nSince $(ij +jk +ki)$ can be negative, we don't have $a > n$ or even $b> 0$.\n\nHowever there are inequalities mentioned in other posts which apply to the terms $(s-1) = (i+j+k)$ and $t =(ij +jk +ki)$. Further, one has $an/2 - b = ijk $. So it might be useful to rewrite the system using $s$ and $t$ and solve it given $n$, and then see if $i,j,k$ can be found after that.\n\nGerhard \"Ask Me About System Design\" Paseman, 2011.02.16\n\nshare|improve this answer\nIn the new version (using s and t), we have s > 0, 2sn +t =a, and ijk -sn^2 = b. With n given, one can get s and t in terms of a and b nicely. (I'll let you do that.) The same general advice holds. Good Luck. Gerhard \"Ask Me About System Design\" Paseman, 2011.02.16 \u2013\u00a0 Gerhard Paseman Feb 16 '11 at 23:13\nOops: In the comment above, I mean s = (i+j+k) now, not s=(i+j+k+1). Perhaps you should do it yourself. Gerhard \"Ask Me About System Design\" Paseman, 2011.02.16 \u2013\u00a0 Gerhard Paseman Feb 16 '11 at 23:18\nInstead of keeping up with the changes, I'll just suggest the idea above: use n+i for x_1, n+j for x_2, n+k for x_3, or something similar, and see where that takes you. If you develop it and want more suggestions, you can respond here. Again, good luck. Gerhard \"Going To Play Elsewhere Now\" Paseman, 2016.02.16 \u2013\u00a0 Gerhard Paseman Feb 16 '11 at 23:23\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55065/maximizing-the-smallest-eigenvalue-of-a-diagonally-dominant-matrix/55072\nText:\nTake the 2-minute tour \u00d7\n\nAssume that we have a full-rank diagonally dominant matrix $A$, all the diagonal elements of which are positive, all the non-diagonal elements are negative, and the sum of the absolute values of the non-diagonal elements is equal to the diagonal element. More precisely: \\begin{equation} A=[a_{i,j}] \\qquad a_{i,i}>0 \\qquad a_{i,j} \\leq 0 \\textrm{ for $i \\neq j$} \\quad \\textrm{and } \\quad a_{i,i}=\\sum _{j\\neq i}|a_i,_j | \\end{equation}\n\nWe also have a positive diagonal matrix $D$ whose trace is constant and equal to $K$: \\begin{equation} d_{ij}=0 \\textrm{ for } i \\neq j \\qquad d_{ii} \\geq 0 \\quad \\textrm{and } \\quad K=\\sum_{i}d_{i,i} \\end{equation}\n\nWhat is the matrix $D$ such that the smallest eigenvalue of the matrix sum $T=A+D$ is as large as possible? In other words, how can we find the $d_{ii}$ 's such that we maximize the smallest eigenvalue of $T=A+D$? Thank you all in advance! :-)\n\nshare|improve this question\nThe existence of such matrix is easy to prove, do you want to find it's coefficients? \u2013\u00a0 Kate Juschenko Feb 10 '11 at 22:05\nWe need to find the elements of the diagonal matrix $D$, such that the real part of the eigenvalue with the smallest real part is as large as possible. If finding this matrix is easy, could you please give me some pointers on where to look? Thanks! :-) \u2013\u00a0 Maria Kinget Feb 10 '11 at 23:18\nBecause everything acts on a finite-dimensional Hilbert space such matrix always exists. I don't know how to find it's coefficients. \u2013\u00a0 Kate Juschenko Feb 10 '11 at 23:58\nThe smallest eigenvalue (or the real part of the eigenvalue with smallest real value) of a matrix is a nonconvex function of the matrix. Thus I would expect this to be a hard nonconvex optimization problem unless something special about the additional structure of your problem simplifies things. \u2013\u00a0 Brian Borchers Feb 11 '11 at 0:53\nYou say the matrix $A$ has full rank, but all the row sums are zero, so that the all-ones vector is an eigenvector with eigenvalue $0$. So $A$ can't be full rank. \u2013\u00a0 alex Feb 24 '11 at 21:55\n\n2 Answers 2\n\nIf the A matrix were symmetric (so the eigenvalues are real), then you could just solve a semidefinite programming problem (SDP) to find the matrix D (and 'lambda'). In particular, maximizing the smallest eigenvalue ('lambda') of the matrix A + D in your case would be equivalent to the SDP (over variables D and lambda):\n\nmax lambda such that: A + D >= lambda I Trace(D) = K D_{ii} >= 0\n\nwhere the first '>=' denotes 'greater-or-equal in the cone of positive semidefinite matrices', and I is the identity matrix.\n\nThere are several MATLAB-based packages in which you can formulate and solve problems like this (for instance, Yalmip and CVX). You'll probably also need a solver for SDPs (e.g., sedumi or sdpt3). Good luck, -Dan\n\nshare|improve this answer\n\nMaximize what? The smallest eigenvalue is complex... Do you want to maximize the absolute value of the smallest eigenvalue?\n\nshare|improve this answer\nThe question states that the entries of A and D are real (and even states what their signs should be). So, if A is symmetric, then the eigenvalues will be real. (The nonsymmetric case seems less natural, although you could study it as well.) \u2013\u00a0 David Speyer Feb 10 '11 at 20:35\nWrong on three counts: The smallest eigenvalue is real, by Perron-Frobenius. The convention chosen in the question has row sum zero, so actually the all-ones vector is a right eigenvector. Choosing equal diagonal entries is not always the best you can do, as you can see by the example $A = \\left[\\begin{array}{rr}1 & -1\\\\\\\\ 0 & 0 \\end{array}\\right]$ and $K=1$. \u2013\u00a0 Tracy Hall Feb 10 '11 at 20:36\n@Tracy: How does P-F tell you that the smallest eigenvalue is real? \u2013\u00a0 Igor Rivin Feb 10 '11 at 20:39\n@Igor: Apply it to $tI -A-D$ for large enough positive $t$, such as $t=\\mathrm{tr}(A)+K$. \u2013\u00a0 Tracy Hall Feb 10 '11 at 20:55\nWe need to maximize the real part of the eigenvalue with the smallest real part. Thanks for pointing this out! :-) \u2013\u00a0 Maria Kinget Feb 10 '11 at 21:28\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/78145/exponentially-different-running-times-random-access-machine-ram-vs-turing-mach?noredirect=1\nText:\nI propose a simple polynomial algorithm for the following problem. Given $m$ integers each one stored on $n$ bits, output the integer that appears the most often.\n\n  1. Reserve a memory area with $2^n$ slots/registers/locations/cells, each cell being long enough to store the number $m$. This requires constant time because we do not initialize/touch the cells. If you agree with this, skip to step 2. Otherwise, check the following four points.\n    \u2022 One could easily be tempted to read \"reserve a memory area\" as \"allocate a memory area\". Actually, the memory allocation operation is an invention/complication of real multi-tasking machines where programs can \"fight\" for memory. If I consider some (Random Access Machine) RAM machine that only knows running my algorithm, I can state that the algorithm can simply use the whole memory. Thus, it is enough to reserve (read \"put aside\" not \"allocate\") the first $2^n$ cells for a an array with $2^n$ elements. The next memory cells are simply used for other variables.\n    \u2022 To be more precise, I consider running my algorithm on a RAM-TM (Random Access Memory-Turing Machine) that is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to move the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics. The RAM-TM has no notion of memory allocation. This seems to be a simplification of the various (Transdichotomous or word) RAM machines out there.\n    \u2022 Even if I must confess I do not really know the exact technical details of all theoretical machines RAM (or RASP), it is possible to work with an exponentially-large memory area and yet use only a polynomially large number of cells and my algorithm is not the first doing this. This also happens in the binary search algorithm over a sorted array: $n$ cells but only $O(log(n))$ time complexity. This scientific paper introduced a data structure that uses a large memory area but has constant time access, see also the answer of zotachidil to this question. My algorithm could work with this data structure instead of explicitly reserving space.\n    \u2022 see Ps 1.\n  2. Go through the $m$ numbers in the input and for each one of them $x$ assign $[x]=0$, where $[x]$ is the memory slot/location number $x$ in the above reserved memory area.\n  3. Go through the $m$ numbers in the input and for each one of them $x$ assign $[x]=[x]+1$.\n  4. Take the first number $x$ in the input and assign $outVal=x$ and $maxFreq=[x]$.\n  5. Scan again the $m$ numbers and for each number $x$ perform: if $[x]>maxFreq$, set $outVal=x$ and $maxFreq=[x]$.\n  6. Output $outVal$.\n\nThe algorithm has time complexity $O(mn)$ assuming $n\\hskip 0.7mm \\not \\hskip -0.7mm \\ll m$ at least on the RAM-TM (see ps 2.), i.e., linear. It is certainly not the only algorithm to solve the problem, but I do not know any other linear algorithm using polynomial memory.\n\nHowever, the big problem is that the algorithm would require exponential time in a Turing machine, no? Does this contradict one of the Extended/Complexity-Theoretic Church\u2013Turing Theses? The section \"Variations\" of the Wikipedia article on the Church\u2013Turing thesis states that \"polynomial-time overhead and constant-space overhead could be simultaneously achieved for a simulation of a Random Access Machine on a Turing machine [55]\", where [55] is \"C. Slot, P. van Emde Boas, On tape versus core: an application of space efficient perfect hash functions to the invariance of space, STOC, December 1984\". Something seems inconsistent. Any help would be greatly appreciated.\n\nps 1. A real-machine argument for the fact one can allocate $O(2^n)$ bits in constant time. Notice I did not say the $2^n$ cells are initialized to some zero values. In a programming language like C this should be achieved by an instruction malloc instead of calloc. In my comment to D.W.'s answer, I provide a reference for a real-life memory allocator that \"performs the allocation/deallocation in constant time\". However, D.W. seem to reject this argument, claiming the above \"constant time\" is calculated by ignoring the fact that we can have $n\\to \\infty$ since in practice $n$ does no go to $\\infty$, if I understood the response. As for me, it is hard to believe this \"constant time\" is actually $O(2^n)$, constant time is really far from $O(2^n)$. I would be surprised to see such large approximations in a paper published by Real-Time Systems.\n\nps 2. Not really essential, but a technical edit: because of Step 5, the complexity of the algorithm should be $O(nm+m\\cdot log(m))$ on a RAM-TM and not $O(nm)$, which is relevant only if $n$ is very very small compared to $m$.\n\n  \u2022 $\\begingroup$ You claim that there is no polynomial time algorithm for a TM machine solving that problem, or you say there is no LINEAR time algorithm for that problem? Time complexity may change depending on what model you choose. But I think your problem is solvable in polynomial time on a deterministic TM. $\\endgroup$ \u2013\u00a0fade2black Jul 20 '17 at 21:28\n  \u2022 $\\begingroup$ Thanks for this reply. I do not really claim there is no Linear algorithm, not essential (by the way, I think the TM needs $O(n^2)$ to compare two numbers on n digits). I agree the deterministic TM can solve it in polynomial time. But the algorithm itself, is it really polynomial on a RAM machine? If yes, how could a TM simulate it with only a polynomial time overhead as stated by the citation from [55]? There are some extended Church-Turing theses claiming the TM can simulate any realistic computation model up to polynomial-time reductions (sec \"Variations\" in the Church-Turing wiki article). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 20 '17 at 21:42\n  \u2022 1\n    $\\begingroup$ You say that \"[...] Turing machine should be able to simulate my algorithm in polynomial time\" but at the same time you demand that you should be able to create a $2^k$ size \"array\" in the RAM model, whereas this must take $2^k$ time in a Turing Machine model. Well, then, of course the TM will be exponentially slower than the RAM machine, but only because you demand it. $\\endgroup$ \u2013\u00a0P\u00e5l GD Jul 21 '17 at 18:11\n  \u2022 $\\begingroup$ Two more things. You need to reserve $2^{n \\log m}$ cells to hold your information, second, in your question regarding binary search, you are given the \"array\" an an input to the algorithm, i.e., the array is already allocated and populated. Nobody claims you're able to construct and populate an array of $n$ elements in $\\log n$ time. $\\endgroup$ \u2013\u00a0P\u00e5l GD Jul 22 '17 at 8:06\n  \u2022 $\\begingroup$ @P\u00e5l GD, thanks for your replies, I agree. If you think I need to edit my question to take these remarks into account, please specify the information I need to update. I said we need $2^n$ cells, each one large enough to store $m$, which is perfectly equivalent to using $2^{n~\\text{log}(m)}$ bits as you said (incidentally, you actually said \"$2^{n~\\text{log}(m)}$ cells\", but I assume you thought about bits). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 11:24\n\nYour algorithm involves an array of length $2^n$. Allocating an array of length $2^n$ takes $\\Theta(2^n)$ time. Consequently, the running time will be $O(m+2^n)$.\n\nAlternatively, you can represent the array in a sparse way using a self-balancing binary tree data structure. Then each access to the array takes $O(\\log m)$ time, so the total running time of your algorithm is $O(m \\log m)$ (assuming we can treat $n$ as a constant).\n\nAlternatively, you could use a hash table to replace the array. Then the expected time per access is $O(1)$ if you use a suitable hash function, so your algorithm will have expected running time $O(m)$ (again, treating $n$ as a small constant). However, this is the expected running time, not the worst-case running time; the worst case could be as bad as $O(m^2)$.\n\nYou seem to have the idea that you can allocate and work with an array of exponential in constant time. I don't think that's correct. What is true is that you can simulate such an array, at the cost of a logarithmic increase in the running time (using the methods I described above). If you care only about whether the algorithm is polynomial-time or not, you can ignore the logarithmic increase, but if you care about the concrete running time, you can't ignore it.\n\nAnd if you really care about the precise running time, you should probably specify the model of computation (e.g., transdichotomous model, etc.). For instance, in the transdichotomous model, if $n$ is guaranteed to be at most the word size (i.e., all of your integers fit within a word), then yes, your algorithm works and runs in linear time -- you can allocate/reserve memory for $2^n$ cells without difficulties. However if $n$ is larger than the word size, you can't. So, giving a precise answer to your question requires specifying a particular model of computation.\n\nRelated: Saving on array initialization.\n\n  \u2022 $\\begingroup$ Could you please expand on why allocating $O(2^n)$ bits requires $O(2^n)$ time? I do not fully agree on this. You think this holds on which RAM machine(s)? Regarding the real-life machines, there is at least a memory allocator that \"performs the allocation/deallocation in constant time maintaining a very low memory fragmentation.\", citing page 150 of [M. Masmano, I. Ripoll, P. Balbastre, and A. Crespo. A constant-time dynamic storage allocator for real-time systems. Real-Time Systems, 40(2):149-179, 2008]. My algorithm should be polynomial when using with this allocator, no? $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:24\n  \u2022 $\\begingroup$ @DanielPorumbel, I haven't read that paper, but my guess would be that it is constant-time in a particular model. Ultimately, memory allocators tend to rely on virtual memory, which tend to rely on a page table datastructure, which are based on a tree data structure, and in the end, as $n \\to \\infty$, the cost of accessing a page you've never accessed before is $O(\\log n)$. (We treat it as $O(1)$ in real machines because in real life $n$ doesn't get very large, but if you want to do asymptotic analysis, arguably it really should be considered $O(\\log n)$ time.) $\\endgroup$ \u2013\u00a0D.W. Jul 21 '17 at 16:44\n  \u2022 $\\begingroup$ So if you're using virtual memory to support memory allocation of extremely large memory regions, of which you write to only a small amount of... you're basically using the \"simulate the array using a tree data structure\" without realizing it. The hardware is doing the tree for you, so it's not visible to you, but it's there. Anyway, if we want to make really precise statements about running time, we have to fix a specific model of computation, and that requires deeper analysis than what's in my answer. $\\endgroup$ \u2013\u00a0D.W. Jul 21 '17 at 16:45\n  \u2022 $\\begingroup$ @ D.W. If you don't trust the memory allocator is really constant-time as claimed (by the way, you seem to accept a complexity of $O(log n)$ which is not $O(2^n)$ and would keep my algo polynomial), please check my first argument below point 1 on the edited question. I can simply consider a RAM machine only for my algorithm. My algorithm would not need memory allocation on this machine, because it can have the whole available memory at its disposal. It can simply put aside the first $O(2^n)$ bits and access them in constant time using the formalization of the RAM machine. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 16:57\n  \u2022 $\\begingroup$ @DanielPorumbel, it's simple since changing $f(n)$ bits requires $\\Omega(f(n))$ time. Because changing a bit in $0$ time is impossible. We consider that machine memory is not essentially bounded by constant unlike computer. $\\endgroup$ \u2013\u00a0rus9384 Jul 21 '17 at 20:50\n\nI would argue that this is not an exponential algorithm on either Random Access Memory or a Turing Machine. On a Turing Machine you could compute as follows (assuming you have a symbol set and state set large enough to cover all of the integers. If not, you are going to have to do a more complex comparison, but that will only be a linear slowdown): Along the tape, alternate cells are the integers, and then counters next to them.\n\nFor each integer in the list:\n    Iterate along the tape, and compare each cell with the current integer\n    If it is the same, increment the relevant counter, otherwise move along the tape.\nOnce you have completed this for all of the integers, iterate along the tape again, and look for the highest counter. Output the integer next to the highest counter\n\nThis algorithm will take $4m$ steps per integer (two out and two back for each integer currently on the tape), multiplied by $m$ integers. It will then take $2m$ time to compare all of the counters, and $2m$ to return to the start to output the answer. This is a total of $4m^2+4m$, which is $O(n^2)$ By using RAM, either a hashtable or an exponential amount of memory can be used. For a hashtable, it is a worst case $O(n^2)$ algorithm, and best case $O(n)$, and with exponential memory it is $O(n)$.\n\nTherefore, in answer to your question, no, it does not have to take exponential time on a Deterministic Turing Machine. Your implementation does, but only because you opted to use an exponential amount of memory. By using RAM, the algorithm can be reduced to $O(n)$ given sufficient memory, or $O(n^2)$ with reasonable limits.\n\nEdited to answer both the comments and the edited question:\n\nWhile the algorithm you use allocates an exponential amount of memory, as you correctly point out it does not write to it. Because of this, the TM can simulate the algorithm without needing the same number of memory locations. Where I have above written the integer to the tape, that is effectively a pointer to your exponential amount of memory. In the interests of simplicity I did not have my array in order, however had I inserted into the middle of the array, rather than appending new values. (at a cost of $O(n)$), then my algorithm would exactly simulate yours.\n\nTo demonstrate this difference, consider the following algorithm:\n\nFor an input of length n:\n    write a 1 to the 2^nth cell\n\nBy your definition, this algorithm is exponential, because the TM would have to move out $2^n$ cells to write. When running this in RAM, it would take constant time. Crucially however, ONLY the $2^n$th cell has been written to, and the rest are undefined. For this reason, the TM could simulate it by writing a 1 to the first cell and ending. I would argue therefore, that this algorithm is constant time.\n\nBased on the above logic, although your algorithm reserves an exponential amount of memory, it only ever uses a linear amount of it (the total amount required to transcribe the input). For this reason, it is not required for the TM to allocate an exponential amount of memory, it can also use a linear amount. This will take either $O(n^2)$ or $O(n^3)$ depending on whether or not you want the array in order.\n\nIn answer to your second point, yes, I sidestepped the issue of the amount of time taken to compare integers. I did this by assuming that the symbol and state set was large enough to accomodate the integers. If you ignore this assumption, there is a further $n^2$ slowdown. (I would note however that it's $n^2$ on the length of a single integer, not on the length of the input as a whole.)\n\nIn conclusion, depending on precisely how you simulate the algorithm, and what you define to be part of the machine vs variable with the input, the TM algorithm can range from $O(n^2)$ to $O(n^5)$, but is definitely polynomial.\n\n  \u2022 $\\begingroup$ Thanks, I agree to what you said. But you actually only prove that the Turing machine solves the problem in polynomial time, using a different algorithm. But the extended Church-Turing theses mentioned at the end of my question seem to say that the Turing machine can simulate RAM machines with polynomial overhead. This would mean that the Turing machine should be able to simulate my algorithm in polynomial time. I don't know how this could happen? $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:30\n  \u2022 $\\begingroup$ A second comment, less important. In the complexity of you Turing Machine (TM) algorithm, do you think the TM can compare two integers on $n$ bits in less than $O(n^2)$? Did you take this into account in the TM complexity calculation? I think this is one of the reasons why multi-tape TMs are useful: they can recognize language $xx$ in linear time, while the TM needs $n^2$ moves, where $n$ is the binary size of $x$. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:40\n  \u2022 $\\begingroup$ @DanielPorumbel, \"simulate the algorithm\" doesn't mean it works exactly identically. The simulation might do all sorts of clever things... including replacing a giant array with a small sorted list, as this answer suggests. $\\endgroup$ \u2013\u00a0D.W. Jul 22 '17 at 1:40\n  \u2022 $\\begingroup$ @C Baish, thanks for the response. As far as I can see, you still use an additional assumption that the input comes alternating the integers and the counters. It is simple to avoid this by using a second tape for the counters. A TM with two tapes can be simulated in quadratic time by a TM with one tape. The second tape could well represent the contents of my utilized memory cells. Less importantly, your $m$ and $n$ notations are a bit confusing, because your $n$ is not my $n$ but it is the input size which is also $m$, assuming \"my $n$\" (size of each integer) is a bounded constant (?). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 10:42\n  \u2022 $\\begingroup$ @C Baish,@D.W. maybe you both found the key: simulate the huge memory with a polynomial size list. This list can work somehow as a virtual memory with polynomial access time. It is enough to use a lame list, no need for a faster red black tree. I will try to answer the question myself by adapting this ideas to bring the resulting Turing machine closer to what I understand by \"simulation\". As it stands the algorithm of C. Baish is not (yet) a simulation for my taste, because it requires a particular input structure. This can however be easily avoided with a second tape as in my above comment. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 10:52\n\nSo this is what I consider as the pitfalls of abstracting physical computation into a purely mathematical theory. First, to answer your question, by extended Church-Turing, when you implement your algorithm on a physical RAM machine, it will run in exponential time.\n\nThere are some subtle points here.\n\n  1. To access a uniformly random memory cell among all $2^n$ cells (of constant size, say, of bits), assuming general relativity and quantum mechanics, there is no way you can do this in $o(2^{n/3})$ time (proof left as exercise, hint: use concentration of volume).\n  2. There are no contradictions because when you reduce a RAM program with time $T$ and space $S$ into a Turing machine, the running time of the Turing machine will be ${\\sf poly}(S, T)$. So extended Church-Turing thesis is robust as long as you don't use superpolynomial space. See also: Strongly polynomial time v.s. weakly polynomial time, although this particular example is not a typical example of weakly polynomial time.\n\nTo conclude, extended Church-Turing thesis really considers reasonable computational models, and the seeming contradiction really stems from the fact that you are making an unreasonable assumption that RAM access only costs constant time.\n\nP.S. You can also consider similar \"speed-ups\" in the circuit model, in fact, you can prove that circuits can decide everything (including undecidable problems) in as much time as one needs to read the input.\n\n  \u2022 $\\begingroup$ Welcome to CS.SE! $\\endgroup$ \u2013\u00a0D.W. Apr 3 at 22:48\n\nThanking everybody for the responses, I come myself with a solution that satisfies me at 99.99%, using arguments from your replies. The main idea is that the Turing Machine (TM) can simulate my RAM machine in polynomial time, provided an initialization axiom.\n\nTo be very clear, I can run my algorithm in $O(nm+m\\log(m))$ time on a RAM-TM (Random Access Memory-Turing Machine). The RAM-TM is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to jump the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics, and an input tape. We consider an additional program tape that represent instructions. For instance, scan, $+1$ could mean ''scan the input tape and for each number increment the memory content pointed by the number''. Incidentally, my algorithm also runs in polynomial time on a Transdichotomous RAM machine with word size $w=n+1$. I think D.W. agrees on this (last paragraph of the response).\n\nA Turing Machine (TM) can simulate my RAM-TM in polynomial time, circumventing the fact that my RAM-TM has infinite memory, since the memory tape is infinite. Consider a whole execution of the RAM-TM consisting of running algorithms/programs $A_1$, $A_2$, $\\dots$, $A_p$, where $A_p$ is my algorithm. If the total time complexity of all these runs is polynomial in $p$ and in the total input size of $A_1$, $A_2$, $\\dots$, $A_p$, then the TM can simulate the whole execution in polynomial time.\n\nWe simulate the whole RAM-TM execution using a 2-tape TM, knowing that a 2-tape TM can be simulated in quadratic (hence polynomial) time by a TM. We use the second tape to store the accessed memory cells of the infinite RAM-TM memory. Since the RAM-TM execution is polynomial, the number of accessed cells is polynomial. We can simply use the second tape of the TM to store all accessed memory locations, each location together with its content. Whenever any of the algorithms accesses memory content $[x]$ on the RAM-TM, the 2-tape TM can scan the second tape in polynomial time and search for index $x$ and retrieve the associated content $[x]$.\n\nI said I am satisfied at 99.9%, because I think we still need an initialization axiom. It is not clear what the 2-tape TM should do when it finds no content associated to some index $x$, i.e., if the RAM-TM asks to retrieve an uninitialized memory cell. We use the following axiom: when the RAM-TM is first turned on, the memory tape contains only zeros. This does not mean that my algorithm $A_p$ can rely on the fact that all uninitialized cells are 0. From the viewpoint of $A_p$, uninitialized cells have an undetermined value, due to the previous programs $A_1$, $A_2$, $\\dots$, $A_{p-1}$.\n\nWithout this axiom, the RAM-TM can not be simulated as far as I can see. Imagine a RAM-TM that has the following memory state when first turned on: the infinitely many bits of the memory tape contain the binary digits of $\\pi$. It can solve the following problem: given an integer $n$ as input, return the $n^\\text{th}$ digit of $\\pi$. It can do this by simply returning $[n]$ in $O(\\log(n))$ time, where it needs $O(\\log(n))$ to write $n$ on the index tape. If we try to simulate this using some multi-tape TM with $\\pi$ on one of the tapes, it would need $O(n)$ time to go to the $n^\\text{th}$ location on that tape. $O(n)$ is exponential compared to the input size $log(n)$.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/water-pressure-in-conical-tank-question.9850/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nWater Pressure in Conical Tank Question\n\n  1. Nov 28, 2003 #1\n\n    Another God\n\n    User Avatar\n    Staff Emeritus\n    Gold Member\n\n    I was wondering if anyon could help me out.\n\n    You have a conical tank with a top diameter of 1m, going down to an outlet of 150mm diameter, height of the tank = 3m, and it's full of water. Assuming an air pressure of 15psi, what is the pressure at the 150mm opening? (the bottom)?\n\n    Does the air pressure make a difference due to the nozzle shape of the tank?\n\n  2. jcsd\n  3. Nov 28, 2003 #2\n\n    Are you trying to say something about a pipeline with a wider beginning and a narow end. The water is flowing from the wider end to the narrower end.\n\n    If this is the problem, then u can use bernoulli's theorem,\n    The total energies at both the ends are the same.\n\n    i.e the sum of pressure energy, kinetic energy and potential energy is constant throughout the flow.\n\n    in other words:\n\n    [tex](p^2)/w + gh + (v^2)/2g [/tex] is always a constant. Assuming that flow is downwards in the problem, the height of the 1m openong is 3 m and that of the 150mm end is 0. So using this find the total energy on each side and equate them. Since the same fluid is flowing w-the sp.density is the same. p is the pressure. At the opening the pressure = air pressure.\n    v is the velocity. To find the value of v at both the ends (or atleast cancel out the v term in the equation) u need to use the continuity equation A1*v1 = A2*v2. Using this find, v1/v2, substitute the other values and then find the value of the pressure at the other end.\n\n    Got it???\n\n  4. Nov 29, 2003 #3\n\n    Another God\n\n    User Avatar\n    Staff Emeritus\n    Gold Member\n\n    Yep, that exactly what we meant.\n\n    Thanks for the reply, we'll run some numbers, and get back to you with what conclusions we reach.\n\n    Thanks again.\n  5. Nov 29, 2003 #4\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Nope. Thats one of the trick questions in fluids. Remember - pressure is pressure. The pressure (static and velocity are the same for the various cases you could do here, conveniently) at the bottom is simply the weight density of water times the height. Technically, thats the static pressure, but if the water is flowing, the static pressure at the bottom of the tank is equal to the velocity pressure. So from that you can caluclate the velocity of the water and the flowrate."}
{"text": "Retrieved from https://www.physicsforums.com/threads/conservation-of-energy-inclined-plane-w-spring.539899/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nConservation of energy/inclined plane w/ spring\n\n  1. Oct 13, 2011 #1\n    Problem: A 2 kg mass is held at the top of a ramp 6m above a spring which has a spring constant of 40 N/m (the 6 m distance is measured along the ramp surface). The ramp is at 30 degrees relative to the horizon. Find the speed of the mass as it just strikes the spring 6 meters below the point it was released from. Find how much the spring is compressed. Ignore friction.\n\n    Formulae: PEspring=1/2kx2, KE=1/2mv2, GPE=mgh (we use 10 m/s2 for acceleration due to gravity), and conservation of energy\n\n    The professor said this problem was tricky, but the solution I found seems like it may be too easy. I calculated the gravitational potential energy to be 60J at the top of the incline. At the end of the ramp, where theoretically all of the GPE would be kinetic energy now because \u03bc=0, I calculated the velocity to be 7.75 m/s. Would this be the correct way to go, given that the incline is at an angle?\n  2. jcsd\n  3. Oct 13, 2011 #2\n    The dimensions of the incline are 6m on the hypotenuse, 3m on vertical leg, 5.2m on horizontal leg by trigonometry.\n  4. Oct 13, 2011 #3\n    And also, k=40N/m.\n  5. Oct 13, 2011 #4\n    The solution will become fairly easy if you apply the work energy theorem.\n\n    Initial configuration - ke is 0\n\n    Final configuration (when spring is completely compressed) - ke is again 0\n\n    So between these to configurations, the work done by all the forces should cancel out to be zero.\n\n    W(gravity) {for 6m + compression} + W(spring){For Cmpression ONLY} = 0\n  6. Oct 13, 2011 #5\n    Thanks for the help! I looked in the textbook (there was an example problem that was exactly the same but done backwards and with different values) and they all lined up with your explanation of using the work-energy theorem, and it basically seemed to be the way I worked it at first. I guess the tricky part that he was talking about was figuring out that you need to find the vertical leg of the inclined plane in order to use that value to plug in to find the potential energy.\n\n    Thanks again!"}
{"text": "Retrieved from https://www.physicsforums.com/threads/vector-differentiation-of-velocity-polar-coord.363484/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Vector differentiation of velocity (polar coord.)\n\n  1. Dec 15, 2009 #1\n    The velocity of a particle moving in a plane in polar coordinates is\n\n    [tex]{\\bf{v}} = v_r {\\bf{\\hat r}} + r\\omega \\hat \\theta[/tex]\n\n    where [tex]v_r = \\frac{{dr}}{{dt}}[/tex] and [tex]\\omega = \\frac{{d\\theta }}{{dt}}[/tex].\n\n    By differentiating w.r.t. time, show that the acceleration of the particle is\n\n    [tex]{\\bf{a}} = \\left( {\\frac{{dv_r }}{{dt}} - \\omega ^2 r} \\right){\\bf{\\hat r}} + \\left( {2\\omega v_r + r\\frac{{d\\omega }}{{dt}}} \\right)\\hat \\theta[/tex]\n\n    (The no-subscript v should be bold, as should the a and the r's with hats.)\n\n    Okay, I'm confident I can work this one out, except for one thing: how does that [tex]\\omega ^2 r[/tex] get into the derivative? I assume the [tex]\\bf{\\hat r}[/tex] is a unit vector, so the derivative of [tex]v_r[/tex] should just be [tex]{\\frac{{dv_r }}{{dt}}[/tex] right? Anyway, if anyone could just explain that detail to me, I'll be on my way.\n\n  2. jcsd\n  3. Dec 15, 2009 #2\n    I like writing in the dot notation because it helps me to remember the dependencies of each variable.\n\n\n    So r depends on time and theta depends on time, what are all the variables that now have r in them and theta in them? (Hint: unit vectors might count!)\n    Last edited: Dec 15, 2009"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-about-simple-harmonic-motion.93241/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Question about simple harmonic motion\n\n  1. Oct 9, 2005 #1\n    A square block, with a mass of 3.40 kg and edge lengths d = 6.00 cm, is mounted on an axle through its center. A spring of spring constant k = 1190 N/m connects the block's upper corner with a rigid wall. Initially the spring is at its rest length. If the block is rotated by 3\u00b0 and then released, what is the period of the resulting SHM?\n\n    What type of problem should this be treated as?\n  2. jcsd\n  3. Oct 9, 2005 #2\n\n\n    User Avatar\n    Homework Helper\n\n    It oscillates by rotation ... it's called a torsional oscillator.\n    You look at \"restoring torque\" which returns the object\n    (which responds slowly due to its rotational Inertia) to\n    the equilibrium orientation angle.\n\n    set torque = I alpha , get torque as function of theta.\n    Now it should operationally look like an oscillator eq'n.\n\n    Be careful to keep the omega_(orientation_change_rate)\n    distinct from the omega_(forward trig function argument)\n    omega_ocr has amplitude 3 degrees, while\n    omega_tfa is multiplied by time.\n\n    Enjoy it, this one is fun!\n  4. Oct 9, 2005 #3\n    there are two different omegas? I'm slightly confused. I know for a torsion oscillator, period is usually found using T = (2*pi)*(I/kappa)^(1/2)\n    Inertia can be calculated...but how should I go about getting kappa, setting the net torque = -k*theta?\n  5. Oct 10, 2005 #4\n\n\n    User Avatar\n    Homework Helper\n\n    Torque is force multiplied by perpendicular distance from axis of rotation.\n\n    Tau = -K(d/2)^2 @ sin@ =@ approx"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/415801/better-transistor-inverter-using-ground-signal\nText:\nI'm getting close to finishing my brand spanking new gate control design. I sincerely appreciate all the help I've received out here.\n\nMy latest challenge is to extinguish an LED when a circuit is grounded. To do so, I require a simple transistor inverter. However, I could not find anything that uses a ground signal. So I had to come up with one.\n\nThe parameters of the circuit are that the input signal has to be a ground, the circuit power has to be 12V, and I am trying to stick to transistors (I could probably use CMOS, but I'm trying to design the entire thing using transistor logic - it's been a great learning experience). This inverter is also powered by solar/battery, so current draw (particularly when active and LED is out) is important. The best I can do is 213.26 uA. Here is my design:\n\n\n(Simulation link)\n\nAll 3 transistors seem to go into saturation mode when they are forward biased, and go into cutoff mode when they are not. I'd like to reduce the current draw, but I don't think it's possible and still maintain exactly 10 mA on the LED when it is lit. Is there a simpler design that I am missing? Am I overlooking the obvious (yet again)?\n\nAs always, any help is sincerely appreciated. I can't wait to finish this design and start building it.\n\n  \u2022 \\$\\begingroup\\$ tinyurl.com/y9lkrcnh \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 2:25\n  \u2022 \\$\\begingroup\\$ There's probably a reason you didn't do this, but tinyurl.com/yc8tavfo ? \\$\\endgroup\\$ \u2013\u00a0user253751 Jan 8 '19 at 2:40\n  \u2022 \\$\\begingroup\\$ Pulling 11.75 mA in off state. \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 2:48\n  \u2022 \\$\\begingroup\\$ Although, thinking about it, seems like a lot of work to save the equivalent power consumed by a single LED. You have a point, and that's why I posted. \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 2:56\n\nI think there are two transistors too many. Most people will say that 70K is a bit high for the base resistor in this application, but we can leave that alone for now. Here is a more simple solution.\n\n\nsimulate this circuit \u2013 Schematic created using CircuitLab\n\nIs there a reason you are not using a saturated switch to drive the LED? Also, why is exactly 10 mA LED current important?\n\n  \u2022 \\$\\begingroup\\$ Sorry, I don't know what a saturated switch is. I'll have to look it up. But in the meantime, you once again came up with an elegant (and INFINITELY better) solution. This is precisely what I was looking for. I tend to over complicate things. Your circuit is perfect (and uses less current). \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 3:39\n  \u2022 \\$\\begingroup\\$ Oh sorry, forget to add.......I've seen circuits where the current used by different LED's is slightly different, and it drives me nuts because I notice it. I'm shooting for 10mA, and if I can just make sure I get close enough to not notice the difference, I will be happy. Right now I'm just simulating. -smiles- \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 3:41\n  \u2022 \\$\\begingroup\\$ @Rikki \"Saturated\" means the transistor is \"completely on\", so that adding more base current won't turn it on any more. \\$\\endgroup\\$ \u2013\u00a0user253751 Jan 8 '19 at 4:16\n  \u2022 \\$\\begingroup\\$ You mention \"saturation\" in your question. Same thing. When the intent of a transistor circuit is to go from full on to full off without operation in the linear active region between, the application is called a saturated switch. \\$\\endgroup\\$ \u2013\u00a0AnalogKid Jan 8 '19 at 14:23\n  \u2022 \\$\\begingroup\\$ Got it. The circuit I provided went from cutoff to 30% of the way into the saturation region of operation when forward biased. I was confused by the term \"saturation switch\" since this is what my circuit was doing (and yours too). This is fun and I sincerely appreciate all your help. \\$\\endgroup\\$ \u2013\u00a0Rikki Jan 8 '19 at 19:04\n\nYou are correct (and I was in error), your Q3 and my Q1 are operating in the saturation region, but barely. The rule of thumb (from the 1950's) is that the base current should be no less than 10% of the collector current for hard saturation. I think 5% (20:1) is a more reasonable number for today's parts. The problem with this is that your off-state circuit current is now higher.\n\nTo fix that, change Q1 to a small MOSFET such as the 2N7000 or 2N7002. Now the gate pullup resistor can be 100K or even 1 M, reducing the off-state current through the circuit. For the high resistor values I would add a small noise filter cap such as 100 nF or 1 uF from the gate to GND.\n\n  \u2022 \\$\\begingroup\\$ I see it as a different answer to the same question, albeit one that is very similar to the first answer. The FET can make for a significantly lower off-state current. \\$\\endgroup\\$ \u2013\u00a0AnalogKid Jan 9 '19 at 4:10\n\nYour Answer"}
{"text": "Retrieved from https://economics.stackexchange.com/questions/34206/unit-elasticity-calculation-question\nText:\nI'm struggling with a math concept dealing with unit elasticity at an undergraduate textbook level. In most problems, we are given a starting price and an ending price as well as corresponding quantities demanded. For example:\n\nWhen bread was ${$2.00}$ a loaf Bobby wanted ${4}$ loaves, when bread prices raised to ${$2.50}$ Bobby wanted just ${2}$ loaves. What is bobby's price elasticity of demand?\n\nTo calculate these we say the percent change in price is ${\\% \\Delta P = \\frac{$2.50-$2.00}{$2.00}=25\\%}$. The percent change is measured relative to the starting price. Meanwhile ${\\% \\Delta Q = \\frac{2-4}{4}=-50\\%}$. Making elasticity ${-2.0}$.\n\nHowever, I came across a problem where essentially it asked what is the elasticity for someone who wants to spend exactly ${$10}$ on gasoline. I first tried to think about this intuitively, \"If price doubles, she'll be able to get half as much quantity no matter the starting price,\" which seems like elasticity of ${1}$. However, I set it up algebraically I get the following: $${Q*P=10 \\implies Q = 10/P}$$\n\nSo I put in some random values of ${P}$, for example ${P_1=$2.00}$ and ${P_2=$2.50}$ for ${\\% \\Delta P = \\frac{$2.50-$2.00}{$2.00}=25\\%}$. Meanwhile, For quantity we have ${Q_1 = \\frac{10}{2}=5}$ and ${Q_2 = \\frac{10}{2.5}=4}$. So that ${\\% \\Delta Q = \\frac{4-5}{5}=-20\\%}$.... Which isn't unit elastic.\n\nSo I turned to calculus and did the following:\n\n$${Q(P)=\\frac{10}{P} \\implies \\frac{dQ}{Q}*\\frac{P}{dP}=\\frac{dQ}{dP}*\\frac{P}{\\frac{10}{P}}=-\\frac{10}{P^2}*\\frac{P^2}{10}=-1.}$$\n\nWhich is unit elasticity. Clearly the discrepancy here is caused by the fact that the derivative has the \"starting quantity\" = \"ending quantity\" since it's the same point. But should we be measuring percent change relative to starting price and quantity? Or relative to starting price, but ending quantity? Or does it depend? And why?\n\n\nYou have to use the midpoint method to resolve this (if I recall correctly).\n\n\nThe reason I may not recall correctly is because the second you introduce calculus into the study of economics, you discard these formulae entirely and (try to) forget they ever existed. You seem to already know calculus, which is probably causing you to be even more confused rather than less, and understandably so.\n\nThe primary purpose of these non-calculus formulations of elasticity is to teach you the intuition around what elasticity is as a concept - I definitely have strong opinions about how well it accomplishes that. :)\n\nEDIT: Just wanted to add that, if indeed the problem is as you're saying it (come hell or high water, Billy is going to spend \\$10 and only \\$10 on gas) then your intuition is right - Billy has unit price elasticity of demand for gas, although in a kludgy sort of way. This is supported by your calculus-based analysis.\n\n  \u2022 $\\begingroup$ Thank you! The material doesn't mention the midpoint method, at all. I think the complication I was having was the disconnect between my intuition about what unit elasticity means and trying to plug in numbers to prove what I was thinking. In some ways it makes sense that it shouldn't be based on the \"starting\" or \"ending\" value since those are relative to our perception of time while it seems elasticity should not depend on such a notion. $\\endgroup$ \u2013\u00a0James Bender Feb 27 '20 at 21:48\n  \u2022 $\\begingroup$ Yeah, the formulas you first encounter are various approximations of the \"correct\" calculus method. In addition to the linear method and midpoint method, there's also an arc-length method, all of which are clearly flawed to the observant student in a way that can't be addressed in class because at the first and second year level, calculus is verboten. Heck, you'll be lucky if you see an integral in undergraduate at all, unless you're studying at a top-tier school. $\\endgroup$ \u2013\u00a0heh Feb 27 '20 at 22:57\n  \u2022 $\\begingroup$ By the way the reason the calculus method is \"correct\" is because it produces expressions that you'll see pop out of solutions to more advanced optimization problems. This allows you to talk about things like the optimal Ramsey price in terms of the price elasticities of the products in question, which helps make intuitive sense of some highly abstract concepts. $\\endgroup$ \u2013\u00a0heh Feb 27 '20 at 22:59\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/264156/prove-that-pqm-leq-pmqm\nText:\nIf $p,q$ are positive quantities and $0 \\leq m\\leq 1$ then Prove that $$(p+q)^m \\leq p^m+q^m$$\n\nTrial: For $m=0$, $(p+q)^0=1 < 2= p^0+q^0$\n\nand for $m=1$, $(p+q)^1=p+q =p^1+q^1$.\n\nSo, For $m=0,1$ the inequality is true.How I show that the inequality is also true for $0 < m < 1$.\n\nPlease help.\n\n\nLet $m=1-n$, where $n \\in [0,1]$. Then\n\n$(p+q)^m = (p+q)^{1-n} = p (p+q)^{-n} + q (p+q)^{-n} \\leq p p^{-n} + q q^{-n} = p^m + q^m$.\n\n  \u2022 $\\begingroup$ (Conversely, if $m \\geq 1$ then $(p+q)^m \\geq p^m + q^m$ with the same method.) $\\endgroup$ \u2013\u00a0sdcvvc Dec 23 '12 at 15:32\n  \u2022 2\n    $\\begingroup$ Does this theorem has a name? Is it a type of Jensen's Inequality? $\\endgroup$ \u2013\u00a0luchonacho Mar 9 '17 at 11:45\n  \u2022 $\\begingroup$ @luchonacho I don't know of a name, and it doesn't seem to be Jensen because it relies only on monotonicity not convexity. $\\endgroup$ \u2013\u00a0sdcvvc Mar 12 '17 at 15:06\n\nYour Answer"}
{"text": "Retrieved from https://flyingcoloursmaths.co.uk/ask-uncle-colin-elastic-speed-limit/\nText:\nDear Uncle Colin,\n\nI clumsily dropped a particle of mass $m$! Luckily, it\u2019s attached to a light elastic string with a modulus of elasticity of $3mg$ and natural length $a$. The other end of the string is attached to the point where I dropped the weight from.\n\nWhen I say \u2018dropped\u2019, I mean \u2018propelled downwards with a speed of $\\sqrt{3ga}$\u2019, of course. I\u2019m worried it\u2019s going to go too fast! What\u2019s the fastest it goes?\n\n-- Hands Off Our Kinetic Energy!\n\nHello HOOKE! There are a few ways to approach this. You hint at one of them in your name: you can work with the conservation of energy to find out when the velocity stops changing.\n\nThe total energy throughout the travel is made up of (potential) + (kinetic) + (elastic). I\u2019ll take the zero level for height as the point where the particle is dropped.\n\nInitially, then, the energy is $E_0 = (0) + \\left( \\frac 12 m v_0^2 \\right) + 0$, which comes to $E_0 = \\frac 32 mga$.\n\nOnce the elastic becomes taut, let\u2019s write \u2018height\u2019 as $(a+x)$, where $x$ is the extension of the string; the velocity is unknown.\n\n$E_t = -\\left( mg(x+a) \\right) + \\left( \\frac 12 mv^2 \\right) + \\left( \\frac 12 \\lambda \\frac{x^2 }{a} \\right)$. That needs some tidying up: $E_t = mgx + mga + \\frac 12 mv^2 + \\frac 32 mg \\frac{x^2}{a}$\n\nBy conservation of energy, we have $E_0 = E_t$, so $\\frac 32 mga = -mgx - mga + \\frac 12 mv^2 + \\frac 32 mg \\frac{x^2}{a}$.\n\nIt\u2019s still a mess. Everything has a factor of $m$ we can get rid of, and it\u2019s probably good to multiply by 2 as well: $3ga = - 2gx - 2ga + v^2 + 3g \\frac{x^2}{a}$\n\nNow rearrange to get $v^2$ on its own: $v^2 = g\\left( 5a + 2x - 3\\frac{x^2}{a} \\right)$\n\nDifferentiate with respect to $x$ and you get $v \\diff vx = g\\left( 2 - 6\\frac{x}{a} \\right)$, which has its extremum when $2 - 6\\frac xa = 0$, or when $x = \\frac 13 a$.\n\nPutting this back into the $v^2$ equation, we get: $v^2 = g\\left( 5a + \\frac 23 a - \\frac{a}{3} \\right)$, or $v^2 = \\frac {16}{3} ga$. The maximum speed is $\\frac 43 \\sqrt {3ga}$.\n\nAs I say, there are alternative approaches: you can find the maximum speed by looking for the point where the net force is zero; you can model the freefall part of the travel with SUVAT and then use either energy or a differential equation; I\u2019m sure there are other approaches that didn\u2019t spring to my mind.\n\nI hope your particle is all right after its trauma!\n\n-- Uncle Colin"}
{"text": "Retrieved from https://mathoverflow.net/questions/360632/bounds-on-operatornamesgnau-operatornamesgnav-when-u-v-1-leq/360722\nText:\n$\\DeclareMathOperator\\sgn{sgn}$Suppose A is a $N \\times N$ Hermitian and unitary matrix, i.e., $A^{\\dagger}=A$ and $A^{\\dagger}A=I =AA^{\\dagger}$. (Assume all entries are real.)\n\nAnd let $u \\in \\{-1,1\\}^N$, $v \\in \\{-1,1\\}^N$.\n\nSuppose $\\|u- v\\|_1 \\leq \\epsilon N$ (i.e., $u$ and $v$ differ on $\\frac{\\epsilon}{2} N$ coordinates) .\n\nand $\\sgn: \\mathbb{R} \\rightarrow \\{-1,0,1\\}$ be the sign function, i.e., maps all negative numbers to $-1$, and positive numbers to $1$, and $0$ to $0$.\n\nI want a non-trivial upper bound on $$\\|\\sgn(Au)-\\sgn(Av)\\|_1$$ in terms of $\\epsilon$. For example, is it upper bounded by $4\\epsilon N$?\n\n  \u2022 1\n    $\\begingroup$ Since each place where $u$ and $v$ differ contributes 2 to their $\\operatorname L^1$-distance, I guess you want $\\|u - v\\| \\le 2\\epsilon N$, or that $u$ and $v$ differ in at most $\\frac1 2\\epsilon N$ places? $\\endgroup$ \u2013\u00a0LSpice May 18 '20 at 23:12\n  \u2022 $\\begingroup$ @Omnomnomnom, thanks for fixing my bone-headed error of including \\sgn in the subject. $\\endgroup$ \u2013\u00a0LSpice May 19 '20 at 1:24\n  \u2022 1\n    $\\begingroup$ @LSpice No problem. Anyway, Mathjax doesn't behave in an intuitive way. For instance, despite the fact that your command is only defined in the question body, it used to be the case that the command \\sgn would work in any answer-posts below your definition. $\\endgroup$ \u2013\u00a0Ben Grossmann May 19 '20 at 1:26\n\nThere is a straightforward bound.\n\nConsider A to be the $\\log(N)$-fold tensor product of $H= \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$.\n\nA is Unitary and Hermitian. In fact A is just the Fourier transform.\n\nSet $u$ to be all one vector, i.e. $u=(1, 1, 1, \\ldots , 1)^T$.\n\nAnd $v$ is all one vector with the first coordinate set to $-1$, i.e. $v=(-1, 1, 1, \\ldots , 1)^T$\n\nSee $Au =(1, 0 , 0 , \\ldots 0)^T$\n\nand $Av$ has non zero entries in all coordinates.\n\nThus, $\\|\\operatorname{sgn}(Au)-\\operatorname{sgn}(Av)\\|_1 \\geq N-1$.\n\nConclusion. No non-trivial bound.\n\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/103468/a-problem-on-lagrange-interpolation-polynomials/103520\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nBased on a previous question, I had the following conjecture and was wondering if anyone knew how to prove it or find a counterexample.\n\nConsider the polynomial $$ p(t)=c\\frac{(t-x_0)(t-x_1)\\cdots(t-x_n)}{(x-x_0)(x-x_1)\\cdots(x-x_n)}$$\n\nwhere $x_0,x_1,\\ldots,x_n$, and $x$ are distinct and all lie in the interval $[a,b]$, and $c\\neq 0$. The polynomial $p(t)$ is the lagrange interpolation polynomial of degree $n+1$ satisfying $p(x_i) = 0$ for $i=0,\\ldots,n$ and $p(x)=c$. Its $(n+1)$-th derivative is the constant $$p^{(n+1)}(t)=\\frac{c(n+1)!}{(x-x_0)(x-x_1)\\cdots(x-x_n)}$$\n\nConjecture: suppose $f(t)\\in C^{(n+1)}[a,b]$ and satisfies $f(x_i) = 0$ for $i=0,\\ldots,n$ and $f^{(n+1)}(t)>p^{(n+1)}(t)$ for all $t\\in [a,b]$ or $f^{(n+1)}(t)<p^{(n+1)}(t)$ for all $t\\in [a,b]$. Prove that $f(x) \\neq p(x)=c$.\n\nOr find a counter example to the conjecture\n\nshare|cite|improve this question\nup vote 0 down vote accepted\n\nThis is true. If $f(x)=p(x)$, then $f-p$ has $n+2$ distinct zeros, between which lie $n+1$ distinct zeros of $(f-p)'$, between which lie $n$ distinct zeros of $(f-p)''$, and so on, leading to a zero of $(f-p)^{(n+1)}$, contradicting the fact that $f^{(n+1)}\\lessgtr p^{(n+1)}$.\n\nNote that the proof uses neither the fact that $p$ is a polynomial, nor the fact that the function values are zero; it proves the more general fact that if two $C^n$ functions coincide at $n+1$ distinct points, their $n$-th derivatives must coincide at some point in between.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/61042/bijection-between-sets-p-groups-and-conjugacy-classes\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $G$ be a finite group. We let $T_{G}$ denote the set of conjugacy classes of subgroups of $G$ and let $T$ denote a set of representatives of $T_{G}$.\n\nHow to establish a bijection between the following sets:\n\n$\\{H \\in T: O^{p}(H)=H\\}$ and $\\{S \\in T: [N_{G}(S): S] \\textrm{is not divisible by p} \\}$.\n\nHere $N_{G}(S)$ means the normalizer of $S$ in $G$ and $O^{p}(H)$ the smallest normal subgroup of $H$ such that $H/O^{p}(H)$ is a $p$-group.\n\nshare|cite|improve this question\nWhat's $O^p(O^p(S))$ ? \u2013\u00a0user641 Aug 31 '11 at 23:35\nNotice that for the set on the right hand side, $N_G(O^p(S))$ contains $N_G(S)$; what does $S$ map to in $N_G(O^p(S))/O^p(S)$? \u2013\u00a0user641 Aug 31 '11 at 23:38\n@Steve D: I don't understand your last line. Can you please explain? \u2013\u00a0user6495 Sep 1 '11 at 0:16\nAbout what $S$ maps to? Have you thought about it? What do we know about $S/O^p(S)$? \u2013\u00a0user641 Sep 1 '11 at 0:34\nIf you'd prefer, I could also post a full answer - but where's the fun in that? \u2013\u00a0user641 Sep 1 '11 at 0:36\nup vote 1 down vote accepted\n\nLet $A=\\{H\\in T\\ |\\ O^p(H)=H\\}$ and $B=\\{S\\in T\\ |\\ p\\nmid [N_G(S):S]\\ \\}$. We need to define two maps $\\phi:A\\rightarrow B$ and $\\psi:B\\rightarrow A$, which are both well-defined up to conjugacy, and are inverses of one another.\n\nThe map from $B$ to $A$ is easier to describe: $\\psi(S)=O^p(S)$. Note that $O^p(O^p(S))=O^p(S)$, so $\\psi(S)\\in A$. Since $O^p(S)^g=O^p(S^g)$, this map is well-defined.\n\nTo define $\\phi(H)$, choose a subgroup $K$, with $H\\le K\\le N_G(H)$, such that $K/H$ is a Sylow p-subgroup of $N_G(H)/H$. Let $\\phi(H)=K$. Since $N_G(H)^g=N_G(H^g)$, and Sylows are conjugate, this map is well-defined. Moreover, since $K/H$ is a p-group, $O^p(K)\\subset H$, and thus $O^p(K)=H$ since $H\\in A$. Thus $N_G(K)\\subset N_G(H)$, and since $p\\nmid [N_G(H):K]$, certainly $p\\nmid [N_G(K):K]$. Thus $\\phi(H)\\in B$.\n\nFrom what was said above, we see that $O^p(\\phi(H))=H$, so that $\\psi\\phi(H)=H$.\n\nIn the other direction, since $O^p(S)$ is characteristic in $S$, we have $N_G(S)\\subset N_G(O^p(S))$. Now $S/O^p(S)$ is a p-subgroup of $N_G(O^p(S))/O^p(S)$, and since \"normalizers grow\" in p-groups, yet $S\\in B$, $S/O^p(S)$ must be a Sylow p-subgroup of $N_G(O^p(S))/O^p(S)$. Thus $\\phi(\\psi(S))=\\phi(O^p(S))=S$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162794/maximum-likelihood-estimation-of-an-ornstein-uhlenbeck-process/163220\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI am wondering whether an analytical expression of the maximum likelihood estimates of an Ornstein-Uhlenbeck process is available. The setup is the following: Consider a one-dimensional Ornstein-Uhlenbeck process $(X_t)_{t\\geq 0}$ with $X_0=x$ for some $x\\in\\mathbb{R}$, i.e. $(X_t)_{t\\geq 0}$ solves the SDE $$ \\mathrm{d} X_t=\\theta(\\mu-X_t)\\,\\mathrm{d} t + \\eta\\,\\mathrm{d} W_t,\\quad X_0=x $$ where $(W_t)_{t\\geq 0}$ is a standard Wiener process and $\\eta,\\theta>0$, $\\mu\\in\\mathbb{R}$. If $\\lambda=(\\eta,\\theta,\\mu)$ is the vector of parameters, then the transition densities are known and if $p_{\\lambda}(t,x,\\cdot)$ denotes the density of $X_t$ (remember $X_0=x$) with respect to the Lebesgue-measure, then $$ p_{\\lambda}(t,x,y)=(2\\pi\\beta)^{-1/2}\\exp\\left(-\\frac{(y-\\alpha)^2}{2\\beta}\\right),\\quad y\\in\\mathbb{R}, $$ where $\\alpha=\\mu+(x-\\mu)e^{-\\theta t}$ and $\\beta=\\frac{\\eta^2}{2\\theta}(1-e^{-2\\theta t})$.\n\nSuppose we have observed an Ornstein-Uhlenbeck process in equidistant time-instances (where the parameter $\\lambda$ is unknown), i.e. the vector of observations is given by $$ \\mathbf{x}=\\{x_0,x_{\\Delta},\\ldots,x_{N\\Delta}\\}, $$ where $x_0=x$ and $\\Delta>0$ and $N+1$ is the number of observations. Then by the Markov property of $(X_t)_{t\\geq 0}$ we have that the log-likelihood function is given by $$ l(\\lambda)=l(\\theta,\\eta,\\mu;\\mathbf{x})=\\sum_{i=1}^N \\log\\left(p_{\\lambda} (\\Delta,x_{(i-1)\\Delta},x_{i\\Delta})\\right). $$ Now i am asking if it is possible to maximize this expression with respect to $\\lambda=(\\eta,\\theta,\\mu)$ simultaneously and if so, how would one go about doing this. If anyone can point me in the direction of a paper/book where this is shown, it would be much appreciated. Thanks in advance!\n\nshare|cite|improve this question\ni think that when you discretize the ou process you get a genuine AR(1) process. There is 1 issue with 'exact' mle, but it is perfectly reasonable use OLS type estimates. See Brockwell & Davis or any other time series book. \u2013\u00a0mike Jun 25 '12 at 12:00\nAha, that's a good point! I will surely look into that. Thanks. \u2013\u00a0Stefan Hansen Jun 25 '12 at 12:04\nup vote 3 down vote accepted\n\nIn the paper \"Parameter estimation and bias correction for diffusion processes\" by Tang and Chen explicit formulas for the MLE are given. Their formulas ignore $X_0$, but this makes little difference if the number of observations is reasonably large. I am puzzled how they managed to come up with this formulas, though. Solving $l'(\\lambda)=0$ seem to be a difficult task.\n\nshare|cite|improve this answer\nThat was exactly what I was looking for. Thanks. \u2013\u00a0Stefan Hansen Jun 27 '12 at 7:06\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/69813/residency-time-of-a-spherical-brownian-particle-in-a-cylindrical-container-with\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI place two spherical particles, $P_1$ and $P_2$ (with radii $r_1$ & $r_2$), into a cylindrical container of radius $r_c$ ($r_1$ & $r_2$ $\\leq \\frac{1}{2}r_c$) and height $h$. While $P_1$ is immobilized at the centerpoint of the cylindrical container, $P_2$ has a coefficient of diffusion $D$, and can freely diffuse throughout the container and across its walls (i.e. the boundaries of the cylindrical container are non-reflecting).\n\nWe randomly position $P_1$ and $P_2$ somewhere inside the cylindrical container. Can we derive an expression for the mean residency time of $P_2$ as a function of the relative sizes of the particles and the cylindrical container? Is it a fair approximation to simply estimate the residency time of $P_2$ in a cylindrical container resized to subtract the volume of $P_1$?\n\nUpdate - $P_1$ is now fixed at the centerpoint of the cylindrical container, and $r_1$ & $r_2$ are defined to be $\\leq \\frac{1}{2}r_c$, s.t. $P_1$ cannot block access, say, to half the cylindrical container.\n\nUpdate 2 - In practice, $r_1$, $r_2$, and $r_c$ will be within one or two orders of magnitude of one another, i.e. it is not the case that $r_1$ & $r_2$ $<< \\frac{1}{2}r_c$). Also, all collisions between particles, like the walls of the container, are fully reflecting.\n\nUpdate 3 - I'd be perfectly happy calling the cylindrical container a \"spherical container\" with the same radius, $r_c$. Similarly, I'd be happy to not pin $P_1$ at any particular point, and instead to simply make the walls of the sphere reflecting specifically for this particle.\n\nshare|cite|improve this question\nYou haven't said anything about the relative sizes of the particles and the cylindrical container. Clearly, in one extreme case (P1's radius is as large as the radius of the cylinder so it completely blocks access to part of the cylinder) P1 matters. Just as clearly, P1 doesn't matter in the other extreme case (e.g. the cylinder has a diameter measured in light years and P1 and P2 are the size of small molecules.) You need to tell us something more about what you're actually trying to model... \u2013\u00a0Brian Borchers Jul 8 '11 at 18:21\n@Brian, you're absolutely right. Hopefully the added clarifications will better address your concerns. \u2013\u00a0Rob Grey Jul 8 '11 at 19:56\nNot really. If r_1 and r_2 are far smaller than r_c, then the additional particle shouldn't have any significant effect on the escape time. The problem only becomes interesting if r_1 is big enough. You also haven't told us what happens if particle 1 and particle 2 interact with each other. Does particle 2 just bounce off particle 1? \u2013\u00a0Brian Borchers Jul 8 '11 at 23:28\nRob, there's an hour to go on this bounty, and one answer which is very reasonable. Is there a problem with the answer? \u2013\u00a0Nilima Nigam Jul 20 '11 at 1:23\nup vote 3 down vote accepted\n\nYou can use the Feynman-Kac formula to get the Moment Generating Function of the time it takes the particle to leave.\n\nI will consider the case where you fix $P_1$ and let $P_2$ move. Whatever the geometry of your problem, you can get an equivalent problem with a point particle diffusing in some region in space, where there is one wall that it reflects off (let's call it $\\Gamma_0$) and another where it is absorbed (let's call it $\\Gamma_1$.) Let $X(t)$ be the position of the particle at time $t$. Let $T$ be the time at which the process first hits $\\Gamma_1$. Let $f(x,\\lambda) =E [ e^{\\lambda T} | X(0)=x]$. Then Feynman-Kac gives you that $f$ satisfies $\\nabla^2 f/2 + \\lambda f =0$ with $\\frac{\\partial f}{\\partial n} = 0$ on $\\Gamma_0$ and $f=1$ on $\\Gamma_1$. This is the Helmholtz equation on your domain with mixed boundary conditions. $f(x,\\lambda)$ is the moment generating function of $T$ with $X(t)=x$, evaluated at $\\lambda$. So now you can compute the mean of $T$, etc.\n\nOne geometry for your problem for which you can get an exact solution for each $\\lambda$ is if you have one sphere fixed at the middle of the big sphere and you are tracking a point particle that diffuses, bounces off the small sphere and is absorbed by the big sphere. In that case the solutions to the PDE are spherical Bessel functions.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inertial-problem-is-the-helicopter-still-moving-with-the-speed-of-the-rotating-earth.50285/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nInertial problem:is the helicopter still moving with the speed of the rotating earth?\n\n  1. Oct 29, 2004 #1\n    a helicopter flies up straightly perpendicular to an \"X\" marked on a floor. then, the helicopter keep static in the air when it has reached 10m from the floor. after 5 hours, will the \"X\" still remain right on the floor below the helicopter?\n  2. jcsd\n  3. Oct 29, 2004 #2\n\n\n    User Avatar\n    Science Advisor\n\n    What could make it otherwise?\n    Reilly Atkinson\n  4. Oct 29, 2004 #3\n    actually, my point is that will the X \"moves\" away as the earth is rotating after 5 hours?\n    for example, the earth is rotating with the speed 1km/s(just an example coz i dunno what's the actual speed). will the helicopter remain the speed of 1km/s in the direction of the rotation of the earth while it's floating staticly on the sky. it's because newton's nertial law tells us that the objects inside the same reference frame will have the same speed with the reference frame if no other force is applied to the objects inside. in my question before, the earth is the reference frame and it's moving in the speed of 1km/s and the helicopter is the object inside the reference frame. so, is the helicopter still have the same speed with the earth, which is 1km/s, after 5 hours? if yes, the X will remain 90 degree below of the helicopter.\n  5. Oct 29, 2004 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    that's funny...\n\n    If Newton's law would not apply,it would be a great problem (actaully a fatal one) for those athletes in the high jump discipline.They would definitely be crushed by the stadium approaching them at 465 m/s (at the equator)... :rofl: That's the first example that crossed my mind.Other even more sadistic could be imagined.\n  6. Oct 29, 2004 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I think it was Isaac Asimov that wrote a short story about a scientist, who was very smart but very poor, that found a way to bring any object to a complete stop instantaneously. A rival scientist, less smart, but more famous and rich, publicly ridiculed the poor scientist's theory. The two scientists often challenged each other to billiards, so the poor scientist invited the famous scientist to a demonstration of the first operational 'anti-momentum machine'. The poor scientist demonstrated how his anti-momentum machine worked by shooting a pool ball into the anti-momentum field.\n\n    If you add the rotation of the Earth, the Earth's motion around the Sun, the Solar System's motion about the center of the Milky Way, the Milky Way's motion, etc., etc., it's amazing how fast all those velocities add up.\n\n    I liked that story almost as much his story about the poor soccer referee who made a bad game deciding call against the home team. 100,000 mirror weilding fans focusing their ire into one united effort can really make a referee's blood boil. I referee soccer and always use that story to comfort comrades who've just endured the fury of a critical blown call.\n  7. Oct 29, 2004 #6\n    Let's examine two cases :\n\n    1. As the helicopter gains in altitude, it keeps its inertia in the horizontal direction, as does the air which supports it, so if he is above the equator, would stay right a top the x. (Of course, the pilot has to have the x as a reference over which to fly, but what I mean is that he will not have to make corrections if he is near the equator. I believe \"near the equator\" includes most of the industrial world : up to 60 or 70 degrees in latitude.)\n\n    2. If he is flying above the north pole, he will have to yaw, because the earth and atmosphere will tend to spin under and around him.\n\n    So if he is \"near\" the north pole, then yes, the pilot will have to make corrections to stay over the x. The perceived force is exactly what is called the Coriolis effect and is entirely compatible with all that Newton has to say. The amount of corrections depends on the helicopter's horizontal speed and latitude (+ distance and time of travel), and it does have to be accounted for in self-guided systems or by visual pilots (perhaps unkowingly when flying visual). Even some advanced training simulators (for helicopters and planes) take it into account.\n    Last edited by a moderator: Oct 29, 2004\n  8. Oct 29, 2004 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The helicopter did not maintain a constant speed. It accelerated in order to raise it's height. Even if it is only pushing in a radial direction (directly away from the center of the Earth), the atmosphere is pushing in the direction of the Earth's rotation and giving the helicopter some tangential acceleration.\n\n    However, if the Earth were a vacuum, a push strictly in the radial direction with no tangential component would cause the object to fall behind the Earth's rotation. You add energy, you increase the size of an object's orbit, regardless of how you add the energy - in other words, if a geosysnchronous satellite is accelerated in the same direction of the Earth's rotation instead of radially, it will still increase the size of the orbit and its angular velocity will still fall behind the Earth's angular velocity.\n  9. Oct 29, 2004 #8\n    There is however an initial tangential component of speed, whether atmosphere or vacuum. It is the reason for 2D-directionnal symmetry in our daily lives (high jump, golf etc.).\n  10. Oct 30, 2004 #9\n    if the helicopter is not flying in the vacuum, the air or the wind will become the friction forces to the helicopter. then, the inertial tangential component of the helicopter would be effected by these frictions. with this reason, i suppose that the pilot would see the X \"moving\" away slowly from the below of his helicopter.\n\nHave something to add?\n\nSimilar Discussions: Inertial problem:is the helicopter still moving with the speed of the rotating earth?\n  1. Helicopter's rotation (Replies: 6)\n\n  2. Rotation of earth (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inverse-of-upper-triangular-matrix.206915/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nInverse of Upper Triangular Matrix\n\n  1. Jan 2, 2008 #1\n    Does anyone know a formula to find the inverse of an upper triangular matrix of dimension n (with a reference preferred)?\n  2. jcsd\n  3. Jan 2, 2008 #2\n    isn't row reduction how you find inverses? as in augment the matrix with the correspondent identity matrix and row reduce\n  4. Jan 2, 2008 #3\n    Yes, I understand. However, I am trying to find a general formula for upper triangular matrices. Something along the lines of the inverse formula for 2x2 matrices. I remember my linear algebra teacher telling us that formulas like that exist for higher dimension matrices.\n  5. Jan 2, 2008 #4\n    Do you remember the analytic formula for the inverse of a matrix from that linear algebra class? Note that the determinant of an upper triangular matrix is just the product of the diagonal components (which are the eigenvalues of the matrix). The cofactors are either 0 or signed determinants of smaller upper triangular matrices.\n  6. Jun 18, 2009 #5\n    For those of you, like me, that just want the answer... here it is (Slider142, please read the item at the bottom re: cofactors and why that doesn't work in this case, sorry):\n\n    My full problem was as follows:\n\n    Given a set of observations and a fixed start-point - in this case acoustic ranges, magnetic and true bearings and some angles, from a ship at sea to towed cables behind it - solve the position in x and y of all other nodes in a network down the length of those cables. For those familiar with surveying, it's a classic triangulation network, using the variation of co-ordinates method of least squares.\n\n    Underlying this is the fact that this network is VERY large, needs to be solved millions of times during a survey and at a minimum, once every few seconds as a boat moves forward acquiring data in real time. There are more than 10,000 observations and more than 1500 nodes to solve.\n\n    I firstly designed a Normal Matrix, A (for those interested 'A' is actually C'WC where C is a design matrix of observations).\n\n    Then, having obtained 'A' I formed 'b' - a simple vector (again, for those interested, 'b' is actually A'Wb where this 2nd 'b' is just the observed minus computed observations for the current estimate of node positions)\n\n    What I need is x, in Ax=b, where x is a vector of the corrections I need to make to positions of the nodes from their currently estimated position.\n\n    Having found x, I will then correct the node positions by this amount, go back to the beginning and re-iterate until such time as the node positions are not changing.\n\n    Now, and here's the rub - no observation is ever perfect, and eliminating 'bad' or unacceptaby bad observations requires a solution to the inverse of A to be found and used.\n\n\n    (again, for those interested, I need a solution of C.A^-1.C', to work out the normalised residuals, or w statistic, and eliminate the worst offender from the network and re-solve)\n\n    In summary:\n\n    I needed the least squares solution of a system Ax=b AND the inverse of the Sparse, positive Definite, symmetric Matrix, A, to enable data snooping using the w-test, which can only be done by multiplying items by the inverse of A. I then need to eliminate bad data and re-compute the network from the beginning. That's the problem. Within the solution I'll need to compute the inverse of a triangular matrix.\n\n    My solution\n    Start with an initial approximation of the node positions, and set x to zero.\n\n    1. Firstly, compute A - which is sparse, positive definite and symmetric - and store it. Computing and storing it is most efficiently achieved by using CSR (Compressed Sparse Row) format - essentially only storing non-zero values and indexes instead of the whole matrix.\n\n    2. Compute b - store this as a vector.\n\n    3. Apply a matrix row re-ordering algorithm to minimise the work required in the next step, Cholesky decomposition. I used Banker's algorithm for this - generally recognised as being better than Reverse Cuthill-McKee (RCM)\n\n    4. Decompose A, using Cholesky decomposition - but store the result as a simple vector of values of a triangular matrix, including zeros. This is because in computing the Cholesky decomposition the same structure as the original matrix is not preserved and so a large amount of manipulation and data 'insertion' (which is time consuming) can be avoided simply by storing it as a simple vector.\n\n    5. Take the matrix stored as a vector in 4 and put it into CSR format for the next step.\n\n    6. Use Forward and Backward Substitution to solve for x, using CSR format thoughout and storing the result, x, as a simple vector. It is important to use CSR format for this, otherwise it becomes very time consuming.\n\n    7. Having solved for x, apply the corrections to node positions and go back to the beginning, using these updated positions for all nodes as the new estimate of position and put x back to zero.\n\n    8. When no further useful changes in position are occurring - or the solution has converged - then the work starts... we now need to assess an estimate of the error from each observation. the w-statistic needs to be computed.\n\n    this is where The inverse is needed - we compute it using the latest value of the Cholesky factor, determined above - let's call it L - which is Triangular.\n\n    The inverse of A is the inverse of L (call it Li) multiplied by it's own transpose, Li.Li'\n\n    Here's where the inverse of a triangular matrix comes in, as L is triangular - but I simply don't have the time to do a naive solution - I need the fastest available because my L is over 1500 rows and may be up to 3000 rows long.\n\n    So, store L as CSR format and use the fact that ONE VECTOR (one column) of the inverse can be computed from FORWARD SUBSTITUTION as follows:\n\n    Let L.Li = I where I is one vector of the identity matrix...\n\n    (Any Matrix, times it's own inverse, is the identity matrix...)\n\n    For One vector of Li, use forward substitution to solve L x Li = [1,0,0,0,0...0] - Store the resulting vector as the 1st column of Li...\n\n    Then use the next vector, [0,1,0,0,0,0....0], and the next [0,0,1,0,0,0,0....0] and so on, building up a solution to Li column by column.\n\n    The use of CSR format in this is vital to keep the computation time to a minimum.\n\n    This works because forward substitution, when using CSR format on a sparse matrix, is very fast.\n\n    et voila, we have the Inverse of a triangular matrix using the minimum possible flops (or at least I believe it to be the minimum possible... ANYONE who knows a faster way, PLEASE, PLEASE, PLEASE let me know!!\n\n    The next problem, for me, is to compute Li.Li' - ie. a Triangular x it's own transpose in the minimum possible time, ie. the minimum number of flops.\n\n    This seemingly trivial, final operation, actually takes more time than the entire of the solution above when the matrix is large (which it always is.)\n\n    One final thing, for those interested - if you are wondering why I didn't use Conjugate Gradients for the least squares solution... it's because although that IS faster than cholesky decomposition, it is numerically unstable when computing the inverse as a sum of it's components - rounding error really kills it. Otherwise it would be beautiful, and quick. if anyone knows a way of stabilising CG, please let me know!\n\n    Well, that's it - I genuinely hope to have been of use to someone out there... it's taken me quite a while to hammer out the method above. Unlike many of you, I'm not a student or professor - just a guy trying to do a job in the real world. So please, if it is useful or if you see something I missed, or a way of improving it, please DO let me know.\n\n\n    Mike Li, from New Zealand.\n\n  7. Jun 18, 2009 #6\n    Sorry Slider142 - got carried away and forgot to say why cofactors don't work quite as simply as you suggest here...\n\n    When you form the cofactor by eliminating a row/column, some of the resulting matricies are not triangular any more - which means the determinant needs to be found of a full matrix, not a simple triangular one. For the others you're right, they're either 0 or the product of the diagonals.\n\n    That makes the solution a whole lot more complex... consequently it's quicker and easier to use forward substitution to find the inverse of a matrix, one vector at a time from L.Li = I where L is a triangular matrix and Li is 1 vector of it's inverse and I is one vector from the identity matrix.\n\n\n    Mike Li.\n\nHave something to add?\n\nSimilar Discussions: Inverse of Upper Triangular Matrix"}
{"text": "Retrieved from https://www.physicsforums.com/threads/multiple-percentages-probability.134225/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nMultiple Percentages Probability\n\n  1. Sep 30, 2006 #1\n    Hi, I seem to be having problems calculating this out. My friends were asking me how to caculate multiple precentages and I thought it would be easy but I got a little stuck. Here is the problem.\n\n    Lets say there is a program that spits out the words yes and no. 60% chance it says yes and 40% chance it says no. If I hit it once, there is a 60% chance it says yes and a 40% chance it says no. If I click it 7 times and it says yes 6 times, what are the odds? I put .6^6 to calculate it, but it seems that I don't include the fact that it says no once. Also, what would the odds be if it said yes all 7 times or no all 7 times? How would you calculate these percentages?\n\n    Thanks alot, seems like a great forum so far.\n  2. jcsd\n  3. Sep 30, 2006 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You're looking for what's called the binomial distribution.\n\n    The odds of exactly 6 out 7 \"yes\" is (7 choose 6) * 0.6^6 * 0.4 ^ 1. Let me explain. You are getting 6 \"yes\" and 1 \"no\"; the chances of getting those answers []in that order[/i] is 0.6^6 * 0.4 ^ 1. Since you don't care about the order, you need to multiply this by the number of ways to choose 6 elements out of 7. In general, (x choose y) is\n\n\n    For (7 choose 6), that's 7!/(6! * 1!) = 7, giving a total probability of [itex]7\\cdot0.6^6\\cdot0.4^1[/itex].\n  4. Sep 30, 2006 #3\n    Thanks so much\n    I cant believe someone actually solved this for me in such a clear manner.\n    This forum is great!\n  5. Sep 30, 2006 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'm glad to have helped. o:)\n\nHave something to add?\n\nSimilar Discussions: Multiple Percentages Probability\n  1. Percentage help (Replies: 7)\n\n  2. Multiple Percentages (Replies: 2)\n\n  3. Percentage reduction (Replies: 10)"}
{"text": "Retrieved from http://mathinsight.org/penicillin_clearance_model\nText:\nMath Insight\n\nConstructing a mathematical model for penicillin clearance\n\nIn developing a model of bacteria growth, we detailed every step of building the model from the data. Since we assumed the change in the population size in one time step was a linear function of the population size, the model was so simple that we could even solve it. We ended up with a fairly simple expression showing the exponential growth of the population size.\n\nHere we'll examine a situation that seems completely different. We'll look at what happens when we give a patient a bolus injection (a one-time injection) of penicillin. In this case, of course, the penicillin won't start multiplying like bacteria in the patient. Instead, the body (i.e., the kidneys) will start removing the penicillin from the body. However, if we make a model where the amount of penicillin removed is a linear function of the amount penicillin in the blood, the model is starting to look a lot like the bacteria growth model. In fact, we'll get exponential decay of the amount of penicillin in the blood.\n\nThere's one more big difference between the bacteria growth example and this page. Here, we'll just get you started on the process, giving you background information about the drug clearance. We then let you go make the model on your own.\n\n\nWhen penicillin was first discovered, its usefulness was limited by the efficiency with which the kidney eliminates penicillin from the blood plasma (blood minus blood cells) passing through it. The modifications that have been made to penicillin (leading to amphicillin, moxicillin, mezlocillin, etc.) have enhanced its ability to cross membranes and reach targeted infections and reduced the rate at which the kidney clears the plasma of penicillin.\n\nEven with these improvements in penicillin, the kidneys can still remove penicillin fairly rapidly. In this project, you will build a mathematical model of penicillin clearance based on an assumption of how the kidneys operate. The secret to your success will be to build into the model a key parameter that captures the speed of the penicillin clearance. Then, you can estimate the model parameter by fitting predictions of the model to data. Lastly, you will compare your model predictions to the data to see how well the model matches the data.\n\nThe assumption behind the model is that the amount of penicillin removed by the kidneys in a five minute interval is proportional to the total amount of penicillin. We can formulate this assumption as a word model for the renal (i.e., kidney) clearance of penicillin.\n\nRenal clearance of penicillin\n\nIn each five minute interval following penicillin injection, the kidneys remove a fixed fraction of the penicillin that was in the plasma at the beginning of the five minute interval.\n\nYour goal is to translate this word model into a mathematical model that has a parameter that determines how much penicillin the kidneys remove in each interval. You can then use the below data to determine this parameter.\n\nThe following table and graph contain data for serum penicillin concentrations at 5 minute intervals for the 20 minutes following a bolus injection (a one-time injection) of 2 g into the serum of \u201cfive healthy young volunteers\u201d (read \u201cmedical students\u201d) taken from T. Bergans, Penicillins, in Antibiotics and Chemotherapy, Vol 25, H. Sch\u00f8onfeld, Ed., S. Karger, Basel, New York, 1978. We are interpreting serum in this case to be plasma.\n\nTime (min)Penicillin Concentration (\u03bcg/ml)\nPenicillin concentration versus time\n\nYour turn\n\nNow its your turn to develop a mathematical model of penicillin clearance. You can use a procedure similar to the one we used to developed the model of bacteria growth. Your model should be based on\n\n  \u2022 the above data, and\n  \u2022 the assumption that the drop in penicillin concentration each 5 minutes will depend linearly on the concentration.\n\nIf all goes well, you should be able to create a model that has an unknown parameter, fit the model to determine that parameter from the data, and then compare your model prediction to the data to see how well you did.\n\nWhen you are all finished, you can compare your results to some findings from the research literature. Analysis of some numbers from the research literature seems to indicate that the all of the blood plasma of a human passes through the kidneys every 5 minutes and that the kidneys remove about 20% of the penicillin in the blood that passes through them.1 You can determine if your analysis of the above data yields a result close to that rate of clearance.\n\nInstructions from writing up the penicillin project are here.\n\nFor more practice on building dynamical system models, try out the exercises."}
{"text": "Retrieved from http://mathoverflow.net/questions/19747/the-symmetry-of-a-soccer-ball/19758\nText:\nTake the 2-minute tour \u00d7\n\nLet $P$ be a polyhedron which satisfies the following three conditions:\n\n  1. $P$ is built out of regular hexagons and regular pentagons.\n  2. Three faces meet at each vertex.\n  3. $P$ is topologically a sphere.\n\nAn easy Euler characteristic argument tells you that $P$ has exactly twelve pentagonal faces.\n\nAn example of a polyhedron like this is a truncated icosahedron (soccer ball for those of us in the States, football for everyone else). In this case, the pentagonal faces are arranged with some nice symmetry, and the polyhedron has icosahedral symmetry.\n\nAnother (trivial) example is the regular dodecahedron, which again has icosahedral symmetry.\n\nHere's my question: Is this symmetry forced? What, if anything, can be said in general about the symmetry of a polyhedron which satisfies the above three conditions?\n\nEdit: Since the discussion below points out that there are precisely two polyhedra which satisfy the above conditions, a suitable evolution of the question, which has already begun to be discussed below, is this: What symmetry groups can a polyhedron have if one or more of the above conditions are relaxed?\n\nshare|improve this question\nIn case you're curious, the mathematical name for a soccer ball is a truncated icosahedron: en.wikipedia.org/wiki/Truncated_icosahedron \u2013\u00a0 Qiaochu Yuan Mar 29 '10 at 18:18\nIf you drop the condition of regularity, you can have other combinatorial types. For example, you can join 2 copies of 6 pentagons around a hexagon. See fullerenes for more examples. However, I would guess that these can't be made from regular polygons. I recommend using Polydron models to check. \u2013\u00a0 Douglas Zare Mar 29 '10 at 18:23\nIndeed the soccer ball and the dodecahedron both have rotational symmetry group $A_5$: see en.wikipedia.org/wiki/Icosahedral_symmetry. Are you asking whether any other polyhedron meeting your requirements has symmetry group $A_5$, or nontrivial symmetry group, or what? \"Very nice symmetry\" is not very precise. \u2013\u00a0 Pete L. Clark Mar 29 '10 at 18:49\nSince the question as stated turned out to have a not very interesting answer, would any of the geometers out there like to address what happens when the regularity conditions in 1) are dropped? \u2013\u00a0 Pete L. Clark Mar 29 '10 at 18:54\n\n8 Answers 8\n\nup vote 12 down vote accepted\n\nOnly soccer ball or dodecahedron.\n\nClearly 3 hexagons can not meet at one vertex. Thus we have only 3 choices for one vertex:\n\n  \u2022 3 pentagons\n  \u2022 2 pentagons + 1 hexagon\n  \u2022 1 pentagons + 2 hexagon\n\nNote that if $[pq]$ is an edge then $p$ has the same type as $q$ (the type is determined by angle at $[pq]$). Thus the polyhedron is completely determined by one vertex. Further:\n\n  \u2022 Once you have a vertex of the first type you have a regular dodecahedron.\n  \u2022 If you have a vertex of the second type then you will get one hexagon surrounded by pentagons. Then it is easy to see that you can not continue.\n  \u2022 For the third type you will get a soccer ball or \"truncated icosahedron\" as some people call it :)\nshare|improve this answer\nThat's assuming all vertices look the same, but it's also possible to have polyhedra in which all faces are hexagons or pentagons and all vertices have degree three but e.g. some vertices have three hexagons while others have one pentagon and two hexagons. \u2013\u00a0 David Eppstein Mar 29 '10 at 18:53\nAnton, you are too brief. I'm afraid that those who can understand this proof do not need it. \u2013\u00a0 Sergei Ivanov Mar 29 '10 at 19:01\nWhat is missing in Anton's answer is the fact that all vertices must have the same type. This can be proved as follows: let $[pq]$ be a common edge of faces $A$ and $B$. Since $A$ and $B$ are regular polygons, the angle between their remaining edges at $p$ is the same as at $q$. Hence the face meeting $A$ and $B$ at $p$ has the same angles as the one meeting $A$ and $B$ at $q$. Therefore $p$ and $q$ are of the same type. This is so for every pair of adjacent vertices and hence for all vertices. \u2013\u00a0 Sergei Ivanov Mar 29 '10 at 19:10\nI added something, hope it is better now. \u2013\u00a0 Anton Petrunin Mar 29 '10 at 20:17\nI do not see where the conditions (2) and (3) are used in the proof. If you relax the conditions of the problem, an infinite hexagonal lattice would be the third solution. Are there any other solutionos possible, if (2a) more than three polygons may meet at a surface, (3a) P is topologically a closed surface (4) P may self-intersect? \u2013\u00a0 Toma\u017e Pisanski Mar 29 '10 at 20:56\n\nIf one gives up on regularity of the hexagonal and pentagonal faces then these graphs (usually called \"Fullerene graphs\") don't have to have much symmetry. See e.g. this 26-vertex graph with 12 pentagonal faces, 2 hexagonal faces, and only order-four symmetry.\n\nshare|improve this answer\nAn easy not-so-symmetric Fullerene to imagine: fit six pentagons around a regular hexagon, and then fit two of these caps together to get what looks like a squashed dodecahedron. Though now that I think about it, I don't think the pentagons end up flat when you do this. \u2013\u00a0 Anton Geraschenko Mar 29 '10 at 19:14\nThat's the example I described in the comments on the question. To see that you can make the pentagons flat, start with a nonplanar 12-gon which projects to a regular 12-gon and has alternating vertices in parallel planes. Attach quadrilaterals to each 3 adjacent vertices so that the final vertex is on the line perpendicular to the projected 12-gon through its center. Six of these quadrilaterals meet above at P, and six meet below at Q. Then truncate P and Q. To make this easier to visualize, remember the 10-sided dice from Dungeons and Dragons, \u2013\u00a0 Douglas Zare Mar 29 '10 at 19:32\nwhich are squashed versions of regular dodecahedra with pentagonal pyramids attached to two opposite faces. \u2013\u00a0 Douglas Zare Mar 29 '10 at 19:32\nAnything that looks combinatorially like a polyhedron can be made with faces that are flat polygons: see Steinitz' theorem, en.wikipedia.org/wiki/Steinitz%27s_theorem \u2013\u00a0 David Eppstein Mar 29 '10 at 20:43\nThanks, I had forgotten that. \u2013\u00a0 Douglas Zare Mar 29 '10 at 20:51\n\nPerhaps you will also find the following interesting:\n\nV. Braungardt und D. Kotschick: \u201cThe classification of football patterns\u201d, 2006.\n\n(for a popular Summary see: D. Kotschick: \u201eThe Topology and Combinatorics of Soccer Balls\u201d, The American Scientist, Juli-August 2006)\n\nABSTRACT. We prove that every spherical football is a branched cover, branched only in the vertices, of the standard football made up of 12 pentagons and 20 hexagons. We also give examples showing that the corresponding result is not true for footballs of higher genera. Moreover, we classify the possible pairs (k; l) for which football patterns on the sphere exist satisfying a natural generalisation of the usual incidence relation between pentagons and hexagons to k-gons and l-gons.\n\nHere a football (AE: soccer ball) pattern is a map on the two-sphere satisfying the following conditions:\n\n  1. at least three edges meet at every vertex\n  2. all faces are pentagons and hexagons\n  3. the edges of each pentagon meet only edges of hexagons\n  4. the edges of each hexagon alternately meet edges of pentagons and of hexagons\nshare|improve this answer\nThanks for the link to the paper. This is a very interesting result. \u2013\u00a0 Bill Kronholm Mar 30 '10 at 19:43\n\nFrom a combinatorial point of view one can define a fullerene to be a 3-valent 3-connected graph with exactly 12 faces which are 5-gons (pentagons) and h 6-gons (hexagons). By Steinitz's Theorem fullerenes which exist as graphs can be realized by convex polyhedra. Branko Grunbaum and Theodore Motzkin showed, The number of hexagons and the simplicity of geodesics on certain polyhedra, Canadian J. Math., 15 (1963) 744-751, that the admissible values of h for such graphs are all non-negative integers h except h = 1. Other proofs of this, given by construction, show other features than what Grunbaum and Motzkin did. (For references see article listed below.)\n\nWhat are the symmetry groups which can arise as the automorphism groups of fullerene graphs? There are only 28 such groups and they are listed on page 36 of the book: Geometry of Chemical Graphs: Polycylces and Two-Faced Maps, by Michel Deza, and Mathieu Dutour Sikiric, Cambridge U. Press, 2008. By a theorem of Peter Mani, these fullerene graphs can be realized by 3-dimensional polyhedra with the full automorphisms group of the graph as the group of isometries of the realizing polyhedron.\n\nFor further discussion of fullerenes and some open problems about fullerene graphs see:\n\nMalkevitch, J., Geometrical and Combinatorial Questions about Fullerenes, in Discrete Mathematical Chemistry, (P. Hansen, P. Fowler, M. Zheng, eds.), Volume 51, DIMACS Series in Discrete Mathematics and Computer Science, AMS, Providence, 2000, pp. 261-266.\n\nshare|improve this answer\n\nIf you are willing to relax the trivalency requirement (and not require convexity, which was not one of the stated constraints), you can make all sorts of polyhedra, using only regular pentagons and hexagons, which have all sorts of symmetry.\n\nFor example, start with two truncated icosahedra, and remove one hexagon from each of them. Now you can glue them together along the removed hexagons (matching up pentagonal and hexagonal faces), forming a new polyhedron with 3 and 4-valent vertices and considerably less symmetry than what you started with. Continuing, you could make long rod-shaped polyhedra, or you could make some spiky polyhedron by replacing multiple hexagons with other truncated icosahedra.\n\nshare|improve this answer\nThese are cool molecules! \u2013\u00a0 Victor Protsak Jun 23 '10 at 8:23\n\nLemma: In a polyhedron of this type with polygons $A$ and $B$ sharing an edge $e$, the two other polygons meeting $e$ must have the same number of sides.\n\nProof: By local symmetry reflecting through the perpendicular bisector of $e$, the angles are equal.\n\nSergei Ivanov proved the same lemma in the comments.\n\nSince 5 is odd, all of the polygons around a pentagon must have the same number of sides, since you can't have a nonconstant alternating sequence. So, the only possibilities are that all polygons are pentagons, or that each pentagon is surrounded by hexagons, and each of these hexagons is surrounded by 3 pentagons and 3 hexagons. In the latter case, attaching pentagonal pyramids to each pentagon extends each hexagon into an equilateral triangle, producing a polyhedron whose faces are equilateral triangles with 5 meeting at a vertex, an icosahedron, so the original was a truncated icosahedron.\n\nNote that if you have equilateral triangles and squares meeting 4 to a vertex, then there are two possibilities for 3 squares and 1 triangle at a vertex, one with cubic symmetry and one with only dihedral symmetry with a belt which is an octagonal prism.\n\nBy contrast, if you require that there are 3 congruent triangles meeting at a vertex, but drop the regularity assumption, you get a family of disphenoids, which generically have the Klein 4-group as symmetries and no reflective symmetry. These are related to ideal hyperbolic tetrahedra.\n\nshare|improve this answer\n\nA follow up to Tomaz Pisanski's question: What if we allow skew regular hexagons, i.e., non-planar regular hexagons? An example of this sort of thing is the Petrie polygon of the cube.\n\nNote that we can't have non-planar skew regular pentagons because of parity.\n\n(This should be a comment on the question at top, but the site rules don't let me do that yet.)\n\nshare|improve this answer\n\nAn interesting example involving self-intersection, but the valence is 4 is given on page 158 of Wenninger's Polyhedron Models (Model #102), this is Great Dodecahemicosahedron, with 10 hexagons and 12 pentagons. You can check it out as well on wikipedia. A similar example is the small demidecahemicosahedron. This provides a partial answer to Pisanski's follow up question.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/101659/what-is-the-value-of-x-with-exponential-growth-but-decreases-as-it-reaches-its-m\nText:\nTake the 2-minute tour \u00d7\n\nI am building a financial model. I am looking for the value of Y:number of subscribers over X:month.\n\nThe model calls for the following.\n\n  \u2022 Competing of a market with 500,000 exclusive subscribers.\n  \u2022 Growth in year one will be exponential month over month with the total at the end of the year being 2500 subscribers.\n  \u2022 Growth in following years is expected to be 250% but will decrease as the product saturates the market.\n  \u2022 20,000 new subscribers will be introduced into the market each year with a total of 2,000 leaving the market each year.\nshare|improve this question\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nI can't give you an equation for $y(x)$ but I can give you a differential equation that it must satisfy...I'm not sure if an exact (closed form) equation exists.\n\nTo derive the equation, note that if the total-subscriber population was unlimited rather than 500,000, an exponential growth model would be: $$ y'(x) = ry(x),\\quad y(0) = y_0 $$ where $r>0$ is the growth factor and $y_0$ is the initial number of people subscribing to your service. The term $y'(x)$ is the change in $y$ with respect to $x$...the derivative from calculus. If you forgot your calculus, then think of it as how much $y$ changes when $x$ increases by one month (this is almost true). In this case the solution is $y(x) = y_0 e^{rx}$, which is exponential. Note that the growth is zero if you start with no one subscribing to your service! Let's assume therefore that you're able to get a small number of initial subscribers and call this number $y_0$. In fact, your assumption of 2500 year 1 subscribers and 250% growth means that $$ y_0 = 1000. $$\nYour assumption of 250% yearly growth means that $$ r = \\frac{\\ln 2.5}{12}. $$ This model is insufficient since it doesn't take saturation into account. To add that in (still ignoring the 20,000 new - 2,000 dropped yearly subscribers) we try the model $$ y'(x) = r y(x)(1 - \\frac{y}{250000}), \\quad y(0) = 1000 $$ Now, when $y(x) < 250,000$ growth will be positive, and when $y>250,000$ growth with be negative. Of course $y>250,000$ is impossible, but the effect will be saturation at 250,000 (the solution will never grow beyond 250,000 unless it starts there...). One can show that the solution to this is $$ y(x) = 250000 \\frac{1000 e^{rx}}{1 + 1000 e^{rx}}. $$ This is the logistic sigmoid, and this model is logistic growth, most often used in modeling populations.\n\nWe now have to take into account that the general subscriber population grows by 20,000 each year, but 2,000 people are lost. The general population growth can be modeled by replacing 250,000 with $$250,000 + 20,000\\frac{x}{12}$$ Now, to deal with the lost subscribers, we note that some of those 2,000 will be our subscribers, and some will not. This complicates things significantly. We can take the approximation that the total population gains 18,000 people per year. This is approximately true when you have much less than 250,000 subscribers. While it is possible to take this complicating factor into account, I'd argue, \"what's the point?\" There will always be some error with your model...also, there is no way your model will simultaneously work well at this stage in time (when you have a small market share), and further down the road when you are close to monopoly...so I think you should just attempt a model that works well when you have a small to medium market share...to do otherwise would be to confuse mathematical models with reality. If your investors require a model that \"works\" everywhere, then that can be done. In any case, our simplification means that we replace 250,000 with $$c(x) = 250,000 + 18,000\\frac{x}{12}.$$ $y(x)$ then satisfies the equation $$ y' = ry(1-\\frac{y}{c(x)}),\\quad y(0) = 1000. $$ You can solve for $y(x)$ using e.g. MATLAB or Python or whatever. It will look like a logistic sigmoid, but the right side will slowly grow without bound.\n\nIf I wanted to complicate the model I would add some uncertainty in the growth rates using some random variables.\n\nshare|improve this answer\n\nThis is a type of sigmoid function maybe more specifically a logistic function.\n\nUnless you are a transhumanist, in which case the growth will obviously never stop and will instead reach a singularity like 1/0.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/591784/if-two-sequences-converge-in-a-metric-space-the-sequence-of-the-distances-conve\nText:\nTake the 2-minute tour \u00d7\n\nLet $(p_n)$ and $(q_n)$ be sequences in the metric space $(X, d)$ and assume that $p_n \\rightarrow p \\in X$ and $q_n \\rightarrow q \\in X$. Prove that $d(p_n, q_n)$ converges to $d(p, q)$.\n\nOk, so using the triangle inequality (and assuming the sequences are Cauchy - but can I do that?), I can prove that the distance does converge, but how do I say it converges to $d(p,q)$ exactly?\n\nshare|improve this question\nWhy don't you look at the sequence d(p, $q_n$) -- what does that converge to? \u2013\u00a0 Betty Mock Dec 4 '13 at 0:48\nAssume it converges to $d'\\neq d(p,q)$, where $|d'-d(p,q)|=\\varepsilon > 0$. Go far enough in the sequences that $d(p_n,p)$, $d(q_n,q)$, and $|d'-d(p_n,q_n)|$ are all less than $\\varepsilon/3$. Show a contradiction. \u2013\u00a0 mjqxxxx Dec 4 '13 at 0:49\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe key is to use the reverse triangle inequality. Since $d$ is a distance, you have $d(x,y)\\leq d(x,z)+d(z,y)$ for any $x,y,z\\in X$. This you can write as $$ d(x,y)-d(z,y)\\leq d(x,z). $$ As the roles of $x$ and $z$ can be reversed, you get the reverse triangle inequality $$ |d(x,y)-d(z,y)|\\leq d(x,z). $$\n\nNow we get directly that $$ |d(p_n,q)-d(p,q)|\\leq d(p_n,p),\\ \\ \\ |d(p_n,q_n)-d(p_n,q)|\\leq d(q_n,q). $$ Now (using the triangle inequality) $$ |d(p_n,q_n)-d(p,q)|\\leq |d(p_n,q_n)-d(p_n,q)|+|d(p_n,q)-d(p,q)|\\leq d(q_n,q)+d(p_n,p). $$ So $\\lim_{n\\to\\infty}d(p_n,q_n)=d(p,q)$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://stackoverflow.com/questions/8580113/using-all-in-mapat-in-mathematica\nText:\nTake the 2-minute tour \u00d7\n\nI often have a list of pairs, as\n\ndata = {{0,0.0},{1,12.4},{2,14.6},{3,25.1}}\n\nand I want to do something, for instance Rescale, to all of the second elements without touching the first elements. The neatest way I know is:\n\nTranspose[MapAt[Rescale, Transpose[data], 2]]\n\nThere must be a way to do this without so much Transposeing. My wish is for something like this to work:\n\nMapAt[Rescale, data, {All, 2}]\n\nBut my understanding is that MapAt takes Position-style specifications instead of Part-style specifications. What's the proper solution?\n\nTo clarify,\n\nI'm seeking a solution where I don't have to repeat myself, so lacking double Transpose or double [[All,2]], because I consider repetition a signal I'm not doing something the easiest way. However, if eliminating the repetition requires the introduction of intermediate variables or a named function or other additional complexity, maybe the transpose/untranspose solution is already correct.\n\nshare|improve this question\nNote that [[All,2]] has the same number of characters as Transpose. So far the solutions are interesting, but I think none is shorter than the double-transpose one, especially if you permit the esc-tr-esc shortcut. Perhaps I should have posed the question as a code golf challenge? \u2013\u00a0 ArgentoSapiens Dec 20 '11 at 19:15\nif you want a shorter solution you probably should specifically ask for it. different people will consider different things to be the (proper OR most elegant OR easiest to understand) solution. \u2013\u00a0 acl Dec 20 '11 at 19:21\nWell if you simply don't want a double Transpose or double [[All,2]], both answers I gave seem suitable :) (I'd go for Mr.W's though, it's easier to read if not to write) \u2013\u00a0 acl Dec 20 '11 at 19:34\nWhy is you data that form on the first place, {{_Integer,_Real},..} performance wise {{__Integer},{__Real}} where better and then you would not have the problem to begin with. \u2013\u00a0 user1054186 Dec 20 '11 at 19:44\nThanks, all, for your answers. There is not always a super-compact way to do these things; these solutions have shown the variety that is possible when seeking a balance between compactness and versatility. \u2013\u00a0 ArgentoSapiens Dec 20 '11 at 21:35\n\n5 Answers 5\n\nup vote 10 down vote accepted\n\nUse Part:\n\ndata = {{0, 0.0}, {1, 12.4}, {2, 14.6}, {3, 25.1}}\n\ndata[[All, 2]] = Rescale @ data[[All, 2]];\n\n\nCreate a copy first if you need to. (data2 = data then data2[[All, 2]] etc.)\n\nAmending my answer to keep up with ruebenko's, this can be made into a function also:\n\npartReplace[dat_, func_, spec__] :=\n  Module[{a = dat},\n    a[[spec]] = func @ a[[spec]];\n\npartReplace[data, Rescale, All, 2]\n\nThis is quite general is design.\n\nshare|improve this answer\nPutting it in your own words, +1 for doing it exactly the way I'd do it (but see my answer below for a few minor differences) \u2013\u00a0 Leonid Shifrin Dec 20 '11 at 20:49\n\nI am coming late to the party, and what I will describe will differ very little with what @Mr. Wizard has, so it is best to consider this answer as a complementary to his solution. My partial excuses are that first, the function below packages things a bit differently and closer to the syntax of MapAt itself, second, it is a bit more general and has an option to use with Listable function, and third, I am reproducing my solution from the past Mathgroup thread for exactly this question, which is more than 2 years old, so I am not plagiarizing :)\n\nSo, here is the function:\n\nOptions[mapAt] = {MappedListable -> False}; \nmapAt[f_, expr_, {pseq : (All | _Integer) ..}, OptionsPattern[]] := \n  Module[{copy = expr}, \n    copy[[pseq]] = \n      If[TrueQ[OptionValue[MappedListable]] && Head[expr] === List, \n        f /@ copy[[pseq]] \nmapAt[f_, expr_, poslist_List] := MapAt[f, expr, poslist]; \n\nThis is the same idea as what @Mr. Wizard used, with these differences: 1. In case when the spec is not of the prescribed form, regular MapAt will be used automatically 2. Not all functions are Listable. The solution of @Mr.Wizard assumes that either a function is Listable or we want to apply it to the entire list. In the above code, you can specify this by the MappedListable option.\n\nI will also borrow a few examples from my answer in the above-mentioned thread:\n\nIn[18]:= mat=ConstantArray[1,{5,3}];\n\nIn[19]:= mapAt[#/10&,mat,{All,3}]\nOut[19]= {{1,1,1/10},{1,1,1/10},{1,1,1/10},{1,1,1/10},{1,1,1/10}}\n\nIn[20]:= mapAt[#/10&,mat,{3,All}]\nOut[20]= {{1,1,1},{1,1,1},{1/10,1/10,1/10},{1,1,1},{1,1,1}}\n\nTesting on large lists shows that using Listability improves the performance, although not so dramatically here:\n\nIn[28]:= largemat=ConstantArray[1,{150000,15}];\n\nIn[29]:= mapAt[#/10&,largemat,{All,3}];//Timing\nOut[29]= {0.203,Null}\n\nIn[30]:= mapAt[#/10&,largemat,{All,3},MappedListable->True];//Timing\nOut[30]= {0.094,Null}\n\nThis is likely because for the above function (#/10&), Map (which is used internally in mapAt for the MappedListable->False (default) setting, was able to auto-compile. In the example below, the difference is more substantial:\n\nf[x_] := 2 x - 1;\n\nIn[54]:= mapAt[f,largemat,{All,3}];//Timing\nOut[54]= {0.219,Null}\n\nIn[55]:= mapAt[f,largemat,{All,3},MappedListable->True];//Timing\nOut[55]= {0.031,Null}\n\nThe point is that, while f was not declared Listable, we know that its body is built out of Listable functions, and thus it can be applied to the entire list - but OTOH it can not be auto-compiled by Map. Note that adding Listable attribute to f would have been completely wrong here and would destroy the purpose, leading to mapAt being slow in both cases.\n\nshare|improve this answer\nHow can I not vote for this? You always bring a deeper analysis to the table. By the way, \"The solution of @Mr.Wizard assumes that either a function is Listable or we want to apply it to the entire list.\" I thought that was the point of this question based on the example. Yours in certainly an interesting take on it. Your last paragraph highlights something I have wondered about before: is there, or does it make sense to have, some way to assert that a function as \"inherently listable\"? This could help with misuse case 4 here.. \u2013\u00a0 Mr.Wizard Dec 21 '11 at 0:35\n@Mr.Wizard I think one can implement something like the type-inference for Listability, to address this problem. This does not even sound as a very hard problem. \u2013\u00a0 Leonid Shifrin Dec 21 '11 at 18:55\nWhat do you have in mind? It is a very loosely formed idea for me at this time. \u2013\u00a0 Mr.Wizard Dec 21 '11 at 19:07\n@Mr.Wizard The question can be formulated as follows: given a piece of code representing a function call, determine whether or not the result will be internally parallelized by appropriate Listable kernel functions which are called during the evaluation of this piece of code. But I start to see that this is not such a simple problem as I initially thought, so I withdraw my previous statement. \u2013\u00a0 Leonid Shifrin Dec 21 '11 at 19:13\n\nHow about\n\nTranspose[{#[[All, 1]], Rescale[#[[All, 2]]]} &@data]\n\nwhich returns what you want (ie, it does not alter data)\n\nIf no Transpose is allowed,\n\nThread[Join[{#[[All, 1]], Rescale[#[[All, 2]]]} &@data]]\n\n\nEDIT: As \"shortest\" is now the goal, best from me so far is:\n\ndata\\[LeftDoubleBracket]All, 2\\[RightDoubleBracket] = Rescale[data[[All, 2]]]\n\nat 80 characters, which is identical to Mr.Wizard's... So vote for his answer.\n\nshare|improve this answer\nIs that any cleaner than what he uses now? \u2013\u00a0 Mr.Wizard Dec 20 '11 at 18:37\n@Mr.W well, obviously I think it is (it uses indexing rather than MapAt, transposing and indexing to locate the elements to be acted upon, don't you think this is cleaner?), but of course different people think in different ways. \u2013\u00a0 acl Dec 20 '11 at 18:39\nPardon me, I didn't mean to be rude. I guess I fixated on the OP's request to \"do this without so much Transposeing.\" \u2013\u00a0 Mr.Wizard Dec 20 '11 at 18:43\n@Mr.W no rudeness perceived. I agree that yours looks cleaner; less @&# going on, which is bizarre :) \u2013\u00a0 acl Dec 20 '11 at 18:44\nLook, @Mr.W, no Transpose! \u2013\u00a0 acl Dec 20 '11 at 19:07\n\nHere is another approach:\n\nop[data_List, fun_] := \n Join[data[[All, {1}]], fun[data[[All, {2}]]], 2]\n\nop[data, Rescale]\n\nEdit 1:\n\nAn extension from Mr.Wizard, that does not copy it's data.\n\nSetAttributes[partReplace, HoldFirst]\npartReplace[dat_, func_, spec__] := dat[[spec]] = func[dat[[spec]]];\n\nused like this\n\npartReplace[data, Rescale, All, 2]\n\nEdit 2: Or like this\n\nReplacePart[data, {All, 2} -> Rescale[data[[All, 2]]]]\nshare|improve this answer\nReplacePart was the first thing I thought of, but I used {_, 2} and it failed. EDIT: Oh darn, it still doesn't work. :-(( Is this a v8 change? \u2013\u00a0 Mr.Wizard Dec 21 '11 at 0:37\nThis works in 801 and 804. I don't have V7 handy anymore. It could be that this was fixed, but I don't know. \u2013\u00a0 user1054186 Dec 21 '11 at 8:36\n\nThis worked for me and a friend\n\nIn[128]:= m = {{x, sss, x}, {y, sss, y}}\nOut[128]= {{2, sss, 2}, {y, sss, y}}\n\nIn[129]:= function[ins1_] := ToUpperCase[ins1];\nfatmap[ins2_] := MapAt[function, ins2, 2];\n\nIn[131]:= Map[fatmap, m]\nOut[131]= {{2, ToUpperCase[sss], 2}, {y, ToUpperCase[sss], y}}\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/123355/maximum-number-of-edges-fn-k-in-a-graph-on-n-vertices-with-no-k-core\nText:\nTake the 2-minute tour \u00d7\n\nThe $k$-core of a finite graph is defined as follows. Delete all vertices of degree $< k$ and repeat until there are no such vertices left. If there is a nonempty subgraph remaining, necessarily of minimum degree $\\ge k$, we call this graph the $k$-core. If the deletion process results in removing all vertices, we say that the graph has no $k$-core.\n\nLet $f(n,k)$ denote the maximum number of edges in a simple graph on $n$ vertices with no $k$-core. For example, if $f(n,2)=n-1$ for every $n$, since $n$ edges are sufficient (and necessary) to guarantee the existence of a cycle.\n\nWhat about $k \\ge 3$? Maybe a formula is too much to hope for, so for fixed $k$ what are the asymptotics of $f(n,k)$ as $n \\to \\infty$?\n\nI suspect this kind of question has been studied, so any references would be appreciated. It is very similar in flavor to questions in \"classical\" extremal graph theory, where one tries to maximize the number of edges in a graph on $n$ vertices with no $H$-subgraph, where $H$ is a fixed graph. This question fits in a more general setting where $H$ ranges over an infinite family of possible subgraphs.\n\nshare|improve this question\nI think you want \"of minimum degree >= k\". Also, the literature on triangle free graphs may hint at an answer for f(n,3), even though it will only give an upper bound, and possibly a very weak bound. If you specialize to bipartite graphs, (I am guessing) you might also find some literature. Gerhard \"Ask Me About System Design\" Paseman, 2013.03.01 \u2013\u00a0 Gerhard Paseman Mar 1 '13 at 17:17\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\n$$f(n,k)= (n-k)(k-1)+\\frac{k(k-1)}{2}, \\; \\mathrm{for} \\; n \\geq k, $$ $$f(n,k) = \\frac{n(n-1)}{2}, \\; \\mathrm{for} \\; n \\leq k. $$\n\nProof: Every graph with no $k$-core on $n$ vertices contains a vertex of degree $\\leq k-1$ which one can delete, obtaining a graph with no $k$-core. Thus $$f(n,k) \\leq f(n-1,k) + k-1.$$\n\nThe formula now follows by induction. In the base case $n \\leq k$ the formula gives the number of edges in the complete graph.\n\nFor an example that the bound can be achieved, let $G$ be a graph with $V(G) = \\{1,2, \\ldots, n \\}$ and let the vertices $i$ and $j$ be adjacent if and only if $|i-j| < k$. It is easy to check that $G$ has no $k$-core and has the right number of edges.\n\nshare|improve this answer\n\nIf I'm not confused, I believe the graphs you are searching for (with a $k-1$ core but no $k$-core, and adding any edge creates a $k$-core) are also called \"maximal $(k-1)$-degenerate graphs,\" see e.g. the wikipedia article on degeneracy.\n\nThe paper \"k-degenerate graphs\" of Lick and White proves the following:\n\nCorollary 1: Let $G$ be a maximal $k$-degenerate graph with $p$ points, $p\\geq k$. Then $G$ has $kp-\\binom{k+1}{2}$ [edges].\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/22722/why-are-finitely-generated-modules-over-principal-artin-local-rings-direct-sums\nText:\nTake the 2-minute tour \u00d7\n\nI am looking for a proof of the following fact:\n\nIf $R$ is a principal artin local ring and $M$ a finitely generated $R$-module, then $R$ is a direct sum of cyclic $R$-modules.\n\n(Apparently such rings $R$ are called, e.g. in Zariski-Samuel, special principal ideal rings.)\n\nI almost didn't ask this question for fear that I might just be missing something obvious, but I've been unable to come up with a proof myself and I can't find one anywhere (if I am just being stupid I certainly don't mind being told). Zariski-Samuel proves a structure theorem for principal ideal rings (they are products of PID's and special PIR's), as well as the fact that a submodule of a principal ideal ring generated by n elements is generated by $\\leq n$ elements. I thought perhaps the statement above could be deduced from this last fact, in a similar manner to the way one proves the corresponding result for finite modules over PID's, but the obstruction to this (as I see it) is that submodules of free $R$-modules will not in general be free (for instance, the maximal ideal of $R$ is not free, assuming $R$ is not a field, i.e., has length $\\geq 2$). Essentially the naive induction on the number of generators doesn't seem to work because I can't be sure that the relevant exact sequence splits...again, maybe I'm just being foolish. I think a proof might be found in chapter VIII of Bourbaki's Algebra text, but this chapter isn't in my copy (I think maybe it's only available in French).\n\nIncidentally, it's straightforward to show that, if such a decomposition exists, the number of times a factor of the form $R/(\\pi^i)$, where $(\\pi)$ is the maximal ideal of $R$ and $1\\leq i\\leq k$ ($k$ being the length of $R$, i.e., the index of nilpotency of $(\\pi)$) is uniquely determined as the length of a quotient of $M$, for instance.\n\nThe reason I'm interested in this is because I want to know that the isomorphism type of $M$ is completely determined by the function sending $i$, $1\\leq i\\leq k$, to the length of $M[\\pi^i]$ (the kernel of multiplication by $\\pi^i$), which, assuming such a decomposition exists, is definitely the case.\n\nEdit: I realized that my module M can (being artinian) be written as a finite direct sum of indecomposable submodules, so I guess this reduces my question to: must an indecomposable submodule of $M$ be a cyclic?\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nLet $I$ be the annihilator of $M$, by assumption $I=(\\pi^i)$ for some $i$. One can view $M$ as an $R/I$ module and furthermore, embed $0 \\to R/I \\to M$. But $R/I$ is also principal artin local, so it is a quotient of a DVR by an element (by Hungerford's paper, in particular it is 0-dim Gorenstein. So $R/I$ is an injective module over itself, and the embedding splits. You are done.\n\nshare|improve this answer\nThank you Hailong, for the answer and the reference. \u2013\u00a0 Keenan Kidwell Apr 27 '10 at 17:38\nYou are very welcome, I hope that helps. \u2013\u00a0 Hailong Dao Apr 27 '10 at 18:44\n\nFirst, all ideals are of the form $(\\pi^i)$. Say $(\\pi^n)$ is the annihilator of $M$. We can replace $A$ by $A/(\\pi^n)$ wlog. Then $M$ has $A$ as submodule, since there's an element that isn't killed by $(\\pi^{n-1})$. Now show that $A$ is injective over itself by Baer's criterion. Say $f : \\pi^i A \\to A$, we need to extend it to $A$. It suffices to show that $f(\\pi^i) \\in \\pi^i A$. But it follows by induction that if an element of $A$ is $\\pi^{n-i}$-torsion, it is a multiple of $\\pi^{i}$.\n\nEdit: the idea is the same as in Hailong's answer, but you don't need the result of Hungerford.\n\nshare|improve this answer\n@fherzig: That's a nice proof! \u2013\u00a0 Hailong Dao Apr 27 '10 at 20:04\n+1 Very nice proof! \u2013\u00a0 Keenan Kidwell Apr 27 '10 at 20:56\nThanks!-------- \u2013\u00a0 fherzig Apr 27 '10 at 21:59\nThis is very slick. I had to think for a while to see why this works, even though a localization of a PID is not self-injective (unless it's a field). \u2013\u00a0 Victor Protsak May 13 '10 at 0:46\n\nIn fact, every special principal ring is a quotient of a principal ideal domain. For an explanation of this, see e.g. the very fine wikipedia article\n\n\n[Disclosure: I wrote it.]\n\nThis is not the easiest way around, but it gives a nice conceptual answer to your question, since it reduces it to the well known structure theory of finitely generated modules over a PID.\n\nAddendum: After reading Hailong Dao's answer, I see that mine is essentially a variant of it: in the end we are both referring to Hungerford's paper. But maybe some will appreciate the variation (e.g. I didn't say the G-word), so I will leave it up for now.\n\nshare|improve this answer\n(Presumably, you weren't writing Hailong Dao's answer.) \u2013\u00a0 Jay Apr 27 '10 at 15:48\nThanks, Pete! Nice Wikipedia article ;) \u2013\u00a0 Keenan Kidwell Apr 27 '10 at 17:42\n(And presumably he didn't write Hungerford's paper either.) \u2013\u00a0 KConrad Apr 27 '10 at 21:17\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/32098/positivity-of-sequences-via-generating-series?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThere are different ways of showing that a given sequence $a_0,a_1,a_2,\\dots$ of integers, say, is nonnegative. For example, one can show that $a_n$ count something, or express $a_n$ as a (multiple) sum of obviously positive numbers. Another recipe is manipulating with the corresponding generating series $A(x)=\\sum_{n=0}^\\infty a_nx^n$ and showing that $A(x)\\ge0$ (this is the notation for a series which has all coefficients nonnegative, and this extends to formal power series in as many variables as needed).\n\nAn example of criterion in this direction is $$ (*) \\qquad A(xy)\\ge0 \\iff \\frac1{(1-x)(1-y)}A\\biggl(\\frac{xy}{(1-x)(1-y)}\\biggr)\\ge0 $$ (the multiple $1/(1-x)(1-y)$ is introduced for cosmetic purposes only and, of course, both $A(x)\\ge0$ and $A(xy)\\ge0$ are by definition equivalent to the nonnegativity of the sequence $a_n$). The latter can be verified by comparing the corresponding coefficients in the power series expansion $$ \\frac1{(1-x)(1-y)}A\\biggl(\\frac{xy}{(1-x)(1-y)}\\biggr) =\\sum_{n=0}^\\infty a_n\\sum_{k,m=0}^\\infty\\binom{n+k}n\\binom{n+m}nx^{n+k}y^{n+m}. $$\n\nOn the other hand, the one-dimensional version of $( * )$, $$ A(x)\\ge0 \\iff \\frac1{1-x}A\\biggl(\\frac{x}{1-x}\\biggr)\\ge0, $$ is simply false.\n\nMy question is whether it is possible to find two nontrivial rational functions $p(x)\\in\\mathbb Q[[x]]$ and $r(x)\\in x\\mathbb Q[[x]]$ in one variable $x$ such that $$ A(x)\\ge0 \\iff p(x)A\\bigl(r(x)\\bigr)\\ge0. $$ Although I am not supposed to put several problems in one question, I would also ask about a more direct proof of $( * )$ and about general ways of constructing such $p$ and $r$ in more than one variable.\n\nMotivation. Basically I am interested in proving nonnegativity of certain $q$-series sequences $a_0(q),a_1(q),a_2(q),\\dots$ by manipulating with the corresponding generating series $A_q(x)=\\sum_{n=0}^\\infty a_n(q)x^n$. Some of them can be \"guessed\" from non-$q$-versions, for example there is a neat $q$-analogue of the criterion $( * )$.\n\nshare|improve this question\nHi, Wadim. So you sometimes do \"positivity\" of series, same as the article I sent you. Let me be sure: (*) is true and really does follow from the expansion with the binomial coefficients? Then the next one with just $$ \\left( \\frac{x}{1-x} \\right) $$ is false, so I suggest you switch to (But it is not!) Do you have an example of falsity for this one? \u2013\u00a0 Will Jagy Jul 16 '10 at 1:16\nHi Will, yes I do (sometimes) positivity. :-) $( * )$ does follow by comparing the coefficients of $x^Ny^M$ when you fix successively $N=0,1,\\dots$ and choose the corresponding $M$ sufficiently large. As for a 1-variable counterexample, take $A(x)=1+x-x^2+x^3$; then $A(x/(1-x))/(1-x)\\ge0$. \u2013\u00a0 Wadim Zudilin Jul 16 '10 at 1:37\nI agree with Will that the sentence \"but it does not\" is confusing and should be changed to \"but it is not.\" \u2013\u00a0 Charles Staats Jul 16 '10 at 2:05\nDone! $ $ \u2013\u00a0 Wadim Zudilin Jul 16 '10 at 2:25\nI am having trouble seeing how (*) follows from the double iteration of the false statement. Could you elaborate? \u2013\u00a0 Qiaochu Yuan Jul 16 '10 at 17:37\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nIt is impossible, and not just for rational functions. To see this, let's consider the coefficients $b_n$ of $p(x) A(r(x))$ as functions of the $a_n$, the coefficients of $A(x)$. Since $r(0) = 0$ (as it must be) we see that:\n\n  \u2022 Each $b_n$ is a linear combination of $a_0, \\dots, a_n$; i.e. we have an upper-triangular infinite matrix $F$, not depending on $a_n$, such that (writing $\\vec{a} = (a_n), \\vec{b} = (b_n)$) $\\vec{b} = F \\vec{a}$. Suppose for now that $p(0), r'(0) \\neq 0$; then $F$ has a nonzero diagonal, and so is invertible.\n\n  \u2022 If $\\vec{b} \\geq 0$ for all $\\vec{a} \\geq 0$, then in particular this is true of the columns of $F$, taking $\\vec{a}$ to be infinite \"basis\" vectors. Conversely, we have equivalently that $\\vec{a} = F^{-1} \\vec{b}$, so if $\\vec{a} \\geq 0$ for all $\\vec{b} \\geq 0$ this must be true of the columns of $F^{-1}$. We conclude that both $F$ and $F^{-1}$ have nonnegative entries.\n\n  \u2022 Lemma in linear algebra: if $F$ is upper-triangular and both it and $F^{-1}$ have nonnegative real entries, then $F$ is diagonal. Proof by induction: true for $1 \\times 1$ matrices vacuously. In general, by induction we may assume that the upper-left and lower-right $(n - 1) \\times (n - 1)$ blocks of $F$ are diagonal, so only the $(1,n)$ entry of $F$ is nonzero off the diagonal. Then we have $(F^{-1})_{1n} = -F_{1n} F_{nn}/F_{11}$. Since $F_{11}$ and $F_{nn}$ are both positive, $F_{1n}, (F^{-1})_{1n} \\geq 0$ implies $F_{1n} = 0$.\n\n  \u2022 This is also true of infinite matrices, since we can compute the finite upper-left blocks independently of the rest of the matrix.\n\n  \u2022 However, if $F$ is diagonal then we see that $p(x)A(r(x)) = \\sum a_n p(x) r(x)^n = \\sum F_{nn} a_n x^n$ for all choices of $a_n$, so (for example, taking $a_n = t^n$ for a new variable $t$ and rewriting both sides as power series in $t$) we have $p(x) r(x)^n = F_{nn} x^n$ for all $n$ (and some $F_{nn} > 0$). That is, $(r(x)/x)^n = F_{nn} p(x)^{-1}$ for all $n$, so in fact $r(x)/x = F_{11}/F_{00}$ is constant, and finally, $p(x)$ is constant as well.\n\n  \u2022 Now we remove the assumptions that $p(0), r'(0) \\neq 0$. If $x^k$ divides $p(x)$, then replacing $p(x)$ by $p(x)/x^k$ does not change positivity of the coefficients. Now suppose the bottom exponent of $r(x)$ is $x^m$ with positive coefficient; then in $\\mathbb{R}[[x]]$ we can write $r(x) = s(x)^m$, and if we denote $A_m(x) = A(x^m)$, we have $A(r(x)) = A_m(s(x))$. Clearly, $A_m$ has nonnegative coefficients if and only if $A$ does, and $s'(0) \\neq 0$, so the previous proof applies and $s(x)$ is a multiple of $x$, i.e. $r(x)$ is a multiple of $x^m$, and $p(x)$ is a multiple of $x^k$.\n\nshare|improve this answer\nRyan, thank you very much for your computation (it will take time for me to follow it in details). I took $p_0=r_1=q(x)=1$, so that $p(x)=1+x$, $r(x)=x-x^2$, and computed $p(x)A(r(x))$ for $A=\\sum_{j=0}^4a_jx^j$. The coefficient of $x^8$ in the resulting polynomial is $-3a_4<0$. \u2013\u00a0 Wadim Zudilin Jul 22 '10 at 6:04\nHmmm. Looking back over the argument I realize that it is not possible for $F$ to be diagonal, since that would necessitate $p(x) r(x)^n \\in \\mathbb{Q}$ for all $n$, an impossibility. I will think on this and replace the above answer with something correct tomorrow, when I am more awake. \u2013\u00a0 Ryan Reich Jul 22 '10 at 6:38\nNo hurry, Ryan, and thanks again. I was thinking of the problem hard before posting it. The expectation is \"no\" which is probably harder than giving at least one (nontrivial) example. \u2013\u00a0 Wadim Zudilin Jul 22 '10 at 6:43\nIt is definitely \"no\". My mistake (which betrays the fact that I am NOT a combinatorialist) is that I forgot all the binomial coefficients :) \u2013\u00a0 Ryan Reich Jul 22 '10 at 13:08\nI haven't gone through your solution yet, but I'm wondering where do you lose answers like $p(x)=x^3$ and $r(x)=x^2$? \u2013\u00a0 Gjergji Zaimi Jul 22 '10 at 17:34\n\nJust a quick observation. It is not hard to see that this is impossible if there exists some $i$ such that for all $j \\ge i$, the coefficients of $p(x) r(x)^j$ are all positive after the first positive coefficient. (This occurs, for example, whenever $p, r$ themselves have this property.) This is because by induction one can take $A(x) = a_i x^i - x^{i+1} + a_{i+2} x^{i+2} + ...$ where $a_i, a_{i+2}, ... $ can be chosen to be large enough so that $p(x) A(r(x)) \\ge 0$. In general some weird things happen that you might be able to fix with the Skolem-Mahler-Lech theorem, and I suspect that when $r$ is a polynomial it should always be possible to find a counterexample.\n\nshare|improve this answer\nThanks a lot, Qiaochu! I didn't have your argument to exclude the \"eventually\" positive ($j\\ge i$) case of $p(x)r(x)^j$, but of course I suspect that only \"trivial\" pairs $p(x),r(x)$ do the job. I am just wondering whether the problem was studied... Can you provide some details on what do you mean by the SML theorem? \u2013\u00a0 Wadim Zudilin Jul 18 '10 at 2:44\nIf r is not a polynomial, the coefficients of p(x) r(x)^j will be nonzero infinitely often for sufficiently large j. Unfortunately, they can also be zero infinitely often, so changing the coefficients of A isn't necessarily enough to give you control over the coefficients of p(x) A(r(x)). The SML theorem tells you what kind of control you have and I think one could argue as above, but more carefully. \u2013\u00a0 Qiaochu Yuan Jul 18 '10 at 2:55\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/183259/collatz-ish-olympiad-problem\nText:\nTake the 2-minute tour \u00d7\n\nThe following is an Olympiad Competition question, so I expect it to have a pretty solution:\n\nFor a positive integer $d$, define the sequence: \\begin{align} a_0 &= 1\\\\ a_n &= \\begin{cases} \\frac{a_{n-1}}{2}&\\quad\\text{if }a_{n-1}\\text{ is even}, \\\\ a_{n-1}+d &\\quad\\text{if }a_{n-1}\\text{ is odd.} \\end{cases} \\end{align} Find all values of $d$ such that $a_n=1$ for some $n>0$.\n\nIt is obvious that $d$ must be odd, or else the sequence is monotone increasing. Also, I have numerically observed that all odd values of $d$ seem to work. Can anyone provide a hint as to how to even begin to prove this? Thank you!\n\nshare|improve this question\nDid you intend \"... if $a_n$ is even, .... if $n$ is odd.\" Should $n$, or $a_n$ be used in both predicates? \u2013\u00a0 Sasha Aug 16 '12 at 16:05\nThanks for pointing that out. I edited the question \u2013\u00a0 Raj Raina Aug 16 '12 at 16:25\nYes I have tried induction, but I see no way of relating previous values of $d$ with bigger values of $d$ (i.e. the induction step) \u2013\u00a0 Raj Raina Aug 16 '12 at 16:40\n@RajRaina There still seems be to a typo. Did you mean to say $a_{n+1} = \\frac{a_n}{2}$ if $a_n$ is even, and $a_{n+1} = a_n + d$ if $a_n$ is odd? \u2013\u00a0 Sasha Aug 16 '12 at 16:41\nAHH sorry for not proofreading more carefully! I edited :) \u2013\u00a0 Raj Raina Aug 16 '12 at 16:43\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere is an outline of an argument. Our guess was that the sequence goes back to $1$ for any $d = 2m-1$.\n\nFirst, it seems preferable to work with the sequence\n\n$$b_0 = 1, \\quad b_n = \\begin{cases} \\dfrac{b_{n-1}}2 & (b_{n-1}\\text{ even}) \\\\ \\frac{b_{n-1}+d}2 & (b_{n-1} \\text{ odd})\\end{cases}$$\n\ninstead of $a_n$ (the statement to be proven remains the same).\n\nHint: Show that it is enough to show $b_n\\equiv 1 \\pmod d$ for some $n$. What does the sequence $b_n$ look like mod $d$?\n\nI have included a more detailed outline below (but I fear it is giving away way too much!)\n\nClaim 1: We have $0<b_n<d$ for all $n$.\n\n\nThis allows us to work mod $d$ from now on, i.e. we have $b_n = 1$ if and only if $b_n\\equiv 1 \\pmod d$.\n\n\nClaim 2: $\\frac12 \\equiv m \\pmod d$, where $d=2m-1$ as above.\n\n\nNow notice that the sequence is really simple when considered $\\pmod d$! Use this to show\n\n\nClaim 3: $b_n \\equiv m^n \\pmod d$\n\n\nClaim 3 implies that $b_k \\equiv 1 \\pmod d$ for some $k$ (why?), so by Claim 1 it follows that $b_k=1$ for this $k$. $\\square$\n\nshare|improve this answer\nSince you tagged the question (homework) I assume you wanted a hint rather than a full solution. Please let me know whether you think the above format is helpful in this/how it could be improved... \u2013\u00a0 Sam Aug 16 '12 at 17:59\nA nice argument. You actually show what the return time is, not just that it does return as I do. \u2013\u00a0 Ross Millikan Aug 16 '12 at 18:09\n@RossMillikan: Thank you. Yes, at least for the $b_n$, the return time is given by $\\mathrm{ord}(m)$, where $m\\in \\mathbb Z_{2m-1}^\\times$ and $d = 2m-1$. But it doesn't seem easy to get a return time for the $a_n$ from this (although it does give an upper bound of $2\\varphi(d)$). \u2013\u00a0 Sam Aug 16 '12 at 18:20\n@SamL. I posed a related question before seeing your response. Your response answers the question completely though. You might want to respond to it, to claim the credit. Thanks! \u2013\u00a0 Sasha Aug 16 '12 at 18:59\nThank you Sam L. If I am understanding correctly, we can now say that $b_{n}\\equiv 2^{\u2212n}\\pmod d$ (Claim 3), and so we need $2^n \\equiv 1 \\pmod d$, which has the trivial solution $n = \\phi (d)-1$ since $2$ and $d$ are relatively prime, and so we will always have $b_{\\phi(d)-1} =1$. What a simple solution! But what was Claim 2 necessary for? \u2013\u00a0 Raj Raina Aug 16 '12 at 23:12\n\nIt is true that you return to $1$ for all odd $d$, and the power of $2$ that you get to for the return is the next power of $2$ above $d$.\n\nAll odd numbers in the series are less than $d$, which means it must cycle. If $a_n$ is odd and less than $d$, $a_{n+1}$ is less than $2d$ and even, so the next odd is again less than $d$.\n\nTo have a cycle that does not include $1$ you must have a number that can be reached from two different numbers-one to enter the cycle and one to continue it. But this is impossible-odd numbers have to be reached by division by $2$, even numbers greater than $d$ have to be reached by addition, and even numbers less than $d$ have to be reached by division.\n\nshare|improve this answer\nThank you for your help! \u2013\u00a0 Raj Raina Aug 16 '12 at 23:04\n\nThe question has already an \"accepted\" answer - but the following scheme may be useful for some later reader anyway.\nThe iterative dividing and adding can be expressed as a whole operation.\nWe formulate one transformation as $$ a_{k+1}={a_k+d \\over 2^A }$$ and work on odd $a_k$ only. The value for A is determined by the requirement, that it is the highest A such that the result of the transformation is an odd integer.\nThe second transformation is then $$ a_{k+2}={{a_k+d \\over 2^A }+d \\over 2^B} = {a_k \\over 2^{A+B} } + d \\cdot ({1 \\over 2^{A+B} } + {1 \\over 2^B} )$$ and so on.\n\nLet the h subsequent exponents of such transformations $a_0 \\to a_h = 1$ be denoted as $A,B,C,\\ldots,G,H$ and their sum as $S$. Then the full transformation can be written as\n$$ 1 (=a_h) = {a_0 \\over 2^S} + d \\cdot {(1+2^A + 2^{A+B} + \\ldots + 2^{A+B+\\ldots + G})\\over 2^S} $$ and we must have an integer solution for\n$$ 2^S = a_0 + d \\cdot (1+2^A + 2^{A+B} + \\ldots + 2^{A+B+\\ldots +G})= a_0 + d \\cdot x $$\nwhere S is to be found (if there is a solution in $A,B,C,\\ldots,H$ at all!).\n\nThus we solve for S such that $ 2^S = a_0 \\pmod d$ which must in general be done by searching (see \"discrete-logarithm-problem\").\nNow here seems to be the critical problem of the original question: we need to know such combinations of $d$ and $a_0$ that this equation has a solution at all. Possibly this is also meant to be the core problem in your homework-assignment, so I won't proceed here ( #1 see below)\n\nIf in fact there is a solution for some S then we compute\n$$ x = { 2^S - a_0 \\over d} $$. Then the bits in the binary representation of x correspond to the \"division by 2's\" of the original formulation of the problem.\n\nFor instance, with $a_0 = 605, d=13$ I found $2^S = a_0 + d \\cdot x $ with $ S=11, x=111$ and $2048 = 605 + 13 \\cdot 111 $\n\n(#1): Referring to another answer we might reformulate this as $ 2 = a_0^{1 \\over S} \\pmod d$ which hints to the concept of \"primitive roots (mod p)\".\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/305026/enumerating-rooted-labeled-trees-without-langrange-inversion-formula\nText:\nTake the 2-minute tour \u00d7\n\nI am wondering how to enumerate rooted labeled trees without the Langrange inversion formula. Because each tree is a collection of other trees, the recursive generating function becomes $$C(x) = x + xC(x) + xC(x)^2 ... = \\sum_n x[C(x)]^n/{n!} = xe^{C(x)}$$\n\nFrom my notes, I am told that we may be able to utilize the function $G(x)$ which counts the number of forests on n vertices => $xG(x) = C(x)$ I can been trying to fiddle around with these functions as well as taking derivatives/log of both, but I can't seem to isolate $C(x)$ to get a functional equation to extract coefficients. Any help would be appreciated!\n\nshare|improve this question\nThe solution to $C(x) = x \\exp(C(x))$ is a new transcendental function, you won't find a \"nice\" formula for it, it is related to Lambert's W function <en.wikipedia.org/wiki/Lambert_W_function>; \u2013\u00a0 vonbrand Feb 15 '13 at 20:21\nBTW, why restrict yourself from using one of the most useful tools to handle this type of equations? \u2013\u00a0 vonbrand Feb 15 '13 at 20:22\nWell based on the notes, we're not suppose to have covered the LIF so the problems should be doable without. I actually asked this problem to give me some intuition for other problems and the counting proofs are great! \u2013\u00a0 Azhuang Feb 17 '13 at 7:07\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere's another proof, I believe due to Jim Pitman.\n\nA rooted forest is a disjoint union of rooted trees, which we will think of as a digraph with edges always directed toward the roots. Given a rooted forest $F$ on $n$ vertices with $k$ components, we would like to add an edge while still having a forest. To do this, choose any vertex $x$ and any of the $k-1$ roots $y$ not in the same component as $x$ and add the edge $y \\rightarrow x$. There are thus $n(k-1)$ ways of doing this, and the resulting forest now has $k-1$ components. If we start from forest with $n$ isolated vertices, we see that we can add $n-1$ edges in\n\n$$n(n-1)\\cdot n(n-2) \\cdot \\ldots \\cdot n(1) = (n-1)! \\cdot n^{n-1}$$ ways. In this expression each tree has been counted $(n-1)!$ ways since the order in which we added edges does not matter, so dividing this out gives the desired formula.\n\nshare|improve this answer\n\nUsually, you would use the Lagrange inversion formula together with the functional equation $C(x)=x e^{C(x)}$ to extract the coefficients from $C(x)$. But if you don't want to do that, here is a combinatorial argument to count labeled rooted trees, from Joyal (1981), p. 16:\n\nCall a vertebrate an unrooted labeled tree with two (possibly coincident) distinguished points, a red one and a black one. By following a path from the red point to the black point, rooting each subtree you come to at that point, and removing all edges along the path, you can change the vertebrate into a nonempty sequence of rooted labeled trees. This is a bijective correspondence, so the number $V_n$ of vertebrates on $n$ vertices which are labeled $\\{1,\\ldots,n\\}$ is the same as the number of nonempty sequences of rooted trees on vertices labeled $\\{1,\\ldots,n\\}$.\n\nLet $n\\ge 1$. The number of ways of arranging the roots of $k$ rooted trees into a sequence is $k!$, which is the same as the number of ways of arranging the roots of $k$ rooted trees into a permutation. So, $V_n$ is also the number of sets of rooted trees on vertices labeled $\\{1,\\ldots,n\\}$ together with a permutation acting on their roots. But every self-map on $\\{1,\\ldots,n\\}$ gives such a structure (composed of trees of elements which coalesce under the action of the self-map and eventually fall into cycles), and conversely. This is a bijective correspondence, so $V_n$ equals the number of self-maps on $\\{1,\\ldots,n\\}$, which is $n^n$.\n\nEach rooted tree on labeled vertices $\\{1,\\ldots,n\\}$ gives $n$ different vertebrates, by coloring the root black and any of $\\{1,\\ldots,n\\}$ red. This is an $n$-to-$1$ correspondence, so, if $n\\ge 1$, the number of rooted trees on $n$ vertices is $n^n/n=n^{n-1}$.\n\nJoyal also uses similar reasoning to give a combinatorial proof of the Lagrange inversion formula (pp. 21-24.)\n\nshare|improve this answer\nThere is a detailed presentation of this argument in Mikl\u00f3s B\u00f3na, Introduction to Enumerative Combinatorics, McGraw-Hill, 2007, pp. 266-8. \u2013\u00a0 Brian M. Scott Feb 16 '13 at 0:27\n\nPitman gave a wonderful solution.\n\nTalking about \"Joyal point of view\" one could give up those vertebrates and talking only about functions and labeled trees. And in case we haven't rooted trees there'll be $n^2$ functions for each tree. Otherwise, if the problem concerns labeled rooted trees, then we'll have $n$ functions associated to every such tree.\n\n(So there are $n^{n-2}$ labeled trees and $n^{n-1}$ labeled rooted trees)\n\nTalking on the base set $[n]={1,2,...,n}$\n\nIt's not that obvious how you build the function(s) starting from a labeled tree (rooted or not). But it's similar. For example, in the case of \"unrooted\" labeled trees we'll have \"n X n\" = $n^2$ unique paths, from each vertex to each vertex (including from a vertex to itself). Such a path, with the vertices M = {$v_1, ..., v_k$} like this $v_1$ -> $v_2$ ->...-> $v_k$ will build partially a function $f(v_i)=v_{i+1}$, where $v_{k+1}$ is $v_1$. For the \"subtrees\" (having the ROOT in the paths' vertices it's simple).\n\nConversely, having a function, you must build a tree ... There is a unique (nonempty) set $M$ with maximum elements such as $f$ is bijective on $M$ ... If we write the elements of $M$ increasingly $M = \\{i_1, i_2,...,i_2\\}$ then $f(i_1)$ -> $f(i_2)$ -> ... -> $f(i_k)$ will be the path .. for the rest is much more simple... (and we'll have finally $n^2$ functions giving the same tree). The operations are inverse to one another...\n\nIn the case of rooted labeled trees we'll have $n$ unique paths joining the root with every other vertex (including the root itself). The rest is just the same.\n\nAnyway, here are only the main STEPS. A rigorous demonstration it's much more longer than this, because you must justify all, major or minor \"tricks\" or statements.\n\nWhat is interesting in my case (what I'm looking for) is the possibility to follow similar steps (in the \"Joyal style\", using functions) to prove the Moon theorem, I mean enumerating labeled trees having given (fixed) degrees, so $d(x_i)= d_i$ for $i \\in [n]$, of course with $\\sum d_i = 2(n-1)$...\n\n... and find the well known multinomial coefficient $\\binom{n-2}{d_1 -1 \\; d_2 -1 \\; ... \\; d_n -1}$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192981/proving-1-0-using-only-the-field-axioms-and-order-axioms?answertab=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nHow do I prove $1 > 0$ using only field axioms and order axioms? I have tried using the cancellation law, with the identities in a field and I cannot get anywhere. Does anybody have any suggestions?\n\nshare|cite|improve this question\nI think $1 = 1^2$ is helpful. \u2013\u00a0Dylan Moreland Sep 9 '12 at 2:02\n@GerryMyerson I assume the OP means \"ordered field axioms\". \u2013\u00a0Alex Becker Sep 9 '12 at 2:28\nYou need not only the axioms of fields and the axioms of linearly ordered sets, but also the axioms that say the linear order is compatible with the algebraic operations, i.e. if $a,b>0$ then $ab>0$, etc..... \u2013\u00a0Michael Hardy Sep 9 '12 at 2:53\nIn general assume the most minimal set of axioms. I think a lot of textbooks and people might have different terminology. \u2013\u00a0CodeKingPlusPlus Sep 10 '12 at 1:52\nup vote 6 down vote accepted\n\nSuppose $1 < 0$. Adding $(-1)$ to both sides we'd also have $0 < -1$ (addition axiom). But if $0 < a$ then it must also hold that $0 < a^2$ (multiplication axiom). For $a = -1$ this means $0 < (-1)^2 = 1$, a contradiction.\n\nshare|cite|improve this answer\nCan't you do the same with $0$ < $1$? Subtract 1 from each side then we have $-1$ < $0$. Now square both sides. We have $1$ < $0$ another contradiction. Thus, this method does not work. \u2013\u00a0CodeKingPlusPlus Sep 10 '12 at 1:51\n@CodeKingPlusPlus There is some missing detail that I believe Marek meant for you to fill in. Of course it is incorrect to say that if $a, b$ are elements of an ordered field then $a < b$ implies $a^2 < b^2$ \u2014 one remembers the graph of $ y = x^2$ over $\\mathbb R$. But what is true is that if $0 < a < b$ then $0 < a^2 < b^2$. \u2013\u00a0Dylan Moreland Sep 10 '12 at 3:34\n@CodeKingPlusPlus: I was not squaring. I was multiplying by (a > 0) -- a positive number by assumption (since 0 < -1). In your argument (-1 < 0) is a negative number, so the multiplication axiom cannot be applied. \u2013\u00a0Marek Sep 10 '12 at 6:29\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/40816/fibonacci-series-mod-a-number/40818\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm trying to write a program with an input of numbers $n$ and $k$ (where $n<10^{1000}$ and $k<10^9$), where I compute fib[n] % k. What is a good FAST way of computing this?\n\nI realize that the resulting series is periodic, just not sure how to find it efficiently.\n\nshare|cite|improve this question\nIf k has no large prime or large prime power factors, then brute force combined with the Chinese Remainder Theorem will get you somewhere quickly. Otherwise use recursions to do the Fibonacci series mod k, to compute e.g. F(2j) and F(2j+1) mod k from F(j) and f(j+1) mod k. If n and k satisfy the bounds you say, a reasonably coded laptop can give you the answer in seconds or less. Gerhard \"Ask Me About System Design\" Paseman, 2010.10.01 \u2013\u00a0Gerhard Paseman Oct 2 '10 at 6:11\nThe Fibonacci entry in wikipedia has this identity : $F_{lk+c} = \\sum_{i=0}^l {l\\choose i} F_{c-i} F_k^i F_{k+1}^{l-i}$. It definitely seems to be relevant in your case, where write $n=lk+c$ and then you have to know $F_j$ mod $k$ for $j=1,\\ldots,k+1$ as well as ${l\\choose i}$ mod $k$. I don't know if this is efficient enough. \u2013\u00a0Somnath Basu Oct 2 '10 at 6:19\nModulo a prime $>5$ the Fibonacci sequence has a period that is either a factor of $p-1$ or $2(p+1)$. This follows from Binet's formula. If $5$ is a quadratic residue modulo $p$, then $$x^2=x+1$$ has two roots in the field $F_p$, and thus both roots have multiplicative orders that are factors of $p-1$. OTOH if $5$ is a quadratic non-residue, then the roots $\\tau_1,\\tau_2$ of that polynomial are in the finite field $K=F_{p^2}$. But by known Galois theory of $K$ we then have $$\\tau_1^p=\\tau_2=-1\\frac1{\\tau_1},$$ so $\\tau_^{p+1}=\\tau_2^{p+1}=-1.$$ See \u2013\u00a0Jyrki Lahtonen May 26 '12 at 15:56\nup vote 12 down vote accepted\n\nThis is really just an expansion of Gerhard's comment. One has the matrix formula $$\\begin{pmatrix} 1&1\\\\\\ 1&0 \\end{pmatrix}^n= \\begin{pmatrix} F_{n+1}&F_n\\\\\\ F_n&F_{n-1} \\end{pmatrix} $$ so the problem reduces to computing $A^n$ modulo $k$ where $$A=\\begin{pmatrix} 1&1\\\\\\ 1&0 \\end{pmatrix}.$$ This can be done by the repeated squaring method often used in modular exponentiation. The idea is to compute $A^n$ recursively either as $(A^m)^2$ or $A(A^m)^2$ according to whether $n=2m$ or $n=2m+1$.\n\nshare|cite|improve this answer\nSorry for the late accept, I have been busy lately. Thank you all for the help! \u2013\u00a0user9734 Oct 4 '10 at 12:28\nAlso note that the order of $GL_2(\\Z_k)$ is much smaller than $n$, and the order of the matrix divides this order. If $l$ is the reminder of $n$ divided by this order, then $A^n=A^l \\mod p$. Last but not least it is enough to consider the subgroup of matrices of $det =\\pm1$. \u2013\u00a0Nick S Nov 7 '10 at 19:52\n\nPerhaps Elsenhans, Jahnel, \"The Fibonacci sequence modulo $p^2$ \u2013 An investigation by computer for $p < 10^{14}$\" will be interesting for you. There are sections about the algorithm.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/50770/open-parent-cell-groups-of-selected-cell\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI wrote a small script for a palette, which allows me to highlight a specific cell in a notebook by using SelectionMove[mycell, All, Cell]. The cell is selected as expected, but sometimes this cell is part of a cell group (section, subsection etc.) which is currently closed, so the cell itself is hidden, and SelectionMove does not reveal it. So far, I didn't find a way to open all parent groups of this cell programatically so that this cell will be shown... Is this possible?\n\nshare|improve this question\nYou can use pattern matching like there: 33416 \u2013\u00a0Kuba Jun 14 '14 at 9:11\nup vote 1 down vote accepted\n\nYou can select parent cell group of currently selected object in notebook nb with SelectionMove[nb, All, CellGroup] and then open it using FrontEndTokenExecute[nb, \"SelectionOpenAllGroups\"]. To open all groups containing currently selected cell you can use something like this:\n\n       SelectionMove[nb, All, CellGroup];\n       If[MatchQ[NotebookRead[nb], Cell[CellGroupData[_, Closed], ___]],\n           FrontEndTokenExecute[nb, \"OpenCloseGroup\"]\n\nIt will select parent group, open it (if it's closed), return selected cell expression and repeat until returned expression is unchanged (i.e. when there's no parent CellGroup).\n\n\nIt seems that NotebookLocate automatically opens all groups containing located cell.\n\nSo you could just add CellTags to selected cell and then locate it:\n\nSetOptions[NotebookSelection[nb], CellTags -> \"MyFavoriteCell\"]\nSetSelectedNotebook[nb]; NotebookLocate[\"MyFavoriteCell\"]\n\nIt should be much faster (and cleaner) than my previous, overcomplicated method.\n\nshare|improve this answer\nThanks - does what I want, but the use of NotebookRead makes this slightly slow when using this function in a large notebook. I didn't find a workaround, because this seems to be the only way to find out whether or not the cell group is open... \u2013\u00a0mjayvizzle Jun 15 '14 at 10:51\n@mjayvizzle Please look at edited version. \u2013\u00a0jkuczm Jun 15 '14 at 11:33\nThanks - that's much faster! Didn't think about the option to assign a cell tag... \u2013\u00a0mjayvizzle Jun 15 '14 at 14:58\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18268/discrete-stochastic-process-exponentially-correlated-bernoulli/23441\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nThere is a question that was asked on stackoverflow that at first sounds simple but I think it's a lot harder than it sounds.\n\nSuppose we have a stationary random process that generates a sequence of random variables x[i] where each individual random variable has a Bernoulli distribution with probability p, but the correlation between any two of the random variables x[m] and x[n] is \u03b1|m-n|.\n\nHow is it possible to generate such a process? The textbook examples of a Bernoulli process (right distribution, but independent variables) and a discrete-time IID Gaussian process passed through a low-pass filter (right correlation, but wrong distribution) are very simple by themselves, but cannot be combined in this way... can they? Or am I missing something obvious? If you take a Bernoulli process and pass it through a low-pass filter, you no longer have a discrete-valued process.\n\n(I can't create tags, so please retag as appropriate... stochastic-process?)\n\nshare|cite|improve this question\nyou could try to take a process $x(t)$ like an Ornstein-Uhlenbeck, that has a correlation structure that decreases exponentially, and then define $B_n = 1_{x(n) > \\alpha}$ where $\\alpha$ is a well-chosen threshold - I have not done the computations, but I have the feeling that the correlation between these Bernoulli random variables also decreases exponentially. Do you really need the correlation to be equal to $\\alpha^{|m-n|}$ ? Would an exponentially decreasing correlation be enough for your particular purpose ? \u2013\u00a0Alekk Mar 15 '10 at 14:59\nthx for the suggestion... I'm posting this on behalf of someone else (see the link in the 1st sentence) so I do not know the stringency of their requirements. The problem seemed simple enough to state that I felt I could translate into a \"proper\" problem statement for mathoverflow. \u2013\u00a0Jason S Mar 15 '10 at 15:20\n...and I had kind of the same hunch (make a continuous-value process, then use a threshold to produce a binary-value output) but don't quite know how to go about characterizing the output process w/r/t correlation, other than an empirical calculation on the computer. \u2013\u00a0Jason S Mar 15 '10 at 15:56\nBy the way, the SO problem is not $\\alpha^{|m-n|}$, but $c|m-n|^{-\\alpha}$. \u2013\u00a0Douglas Zare Mar 15 '10 at 18:09\nYes, that was pointed out to me... but I am suspicious + wondering if the OP meant alpha ^ |m-n|. Using the c |m-n| ^ (-alpha) formula, correlation is undefined for m=n. \u2013\u00a0Jason S Mar 15 '10 at 19:15\nup vote 6 down vote accepted\n\nHere is a construction.\n\n  \u2022 Let $\\{Y_i\\}$ be independent Bernouilli random variables with probability $p$.\n  \u2022 Let $N(t)$ be a Poisson process chosen so that $P(N(1)=0)=\\alpha$.\n  \u2022 Let $X_i = Y_{N(i)}$.\n\nIn words, we have some radioactive decay which tells us when to flip a new (biased) coin. $X_n$ is the last coin flipped at time $n$. The correlation between $X_m$ and $X_n$ comes from the possibility that there are no decays between time $m$ and time $n$, which happens with probability $\\alpha^{|m-n|}$.\n\nThe conditional correlation between $X_m$ and $x_n$ is $1$ if $N(m) = N(n)$, and $0$ if $N(m)\\ne N(n)$, so $\\text{Cor}(X_n,X_m) = P(N(m)=N(n)) = \\alpha^{|m-n|}.$\n\nYou can simplify this by saying that $N(i) = \\sum_{t=1}^i B_i$ where $\\{B_i\\}$ are independent Bernoulli random variables which are $0$ with probability $\\alpha$.\n\nshare|cite|improve this answer\nfascinating! I think I understand... thanks! \u2013\u00a0Jason S Mar 15 '10 at 19:13\nBrilliant answer \u2013\u00a0David Bar Moshe Mar 16 '10 at 9:44\nPhrasing it in terms of a Poisson process seems overly complicated; the properties of Poisson processes aren't actually used. Couldn't one just phrase it as follows? Let $$X_{i+1} = \\begin{cases} X_i & \\text{with probability }\\alpha; \\\\ \\text{a new Bernoulli trial independent of }X_i & \\text{with probability }1-\\alpha. \\end{cases} $$ \u2013\u00a0Michael Hardy Jun 2 '10 at 20:36\n\nIn other words:\n\nStart with a random variable $X_0$ Bernoulli with parameter $p$, random variables $Y_n$ Bernoulli with parameter $\\alpha$, random variables $Z_n$ Bernoulli with parameter $p$, and assume that all these are independent. Define recursively the sequence $(X_n)_{n\\ge0}$ by setting $X_{n+1}=Y_nX_n+(1-Y_n)Z_n$ for every $n\\ge0$.\n\nThen $X_n$ and $X_{n+k}$ are conditionally correlated if and only if $Y_i=1$ for every $i$ from $n$ to $n+k-1$. This happens with probability $\\alpha^k$, hence you are done.\n\nThis is Douglas Zare's idea, but with no Poisson process.\n\nshare|cite|improve this answer\nInteresting variation, thanks! \u2013\u00a0Jason S Mar 16 '10 at 14:06\nThe last line of my answer gave the same construction. My $B_i$ is your $1-Y_i$. \u2013\u00a0Douglas Zare Mar 16 '10 at 14:33\n\nI suggest also to look a the paper: Generating spike-trains with specified correlations. By Jakob Macke, Philipp Berens, et al. (Max Planck Institute for Biological Cybernetics.).\n\nGenerating spike-trains with specified correlations\n\nThey also offer a Matlab Package for 'Sampling from multivariate correlated binary and poisson random variables' ... also available at Matlab central:\n\nSampling from multivariate correlated binary and poisson random variables\n\nAlso look at the page link\n\nshare|cite|improve this answer\n\nThe above solution is very nice, but relies on the very special structure of the desired process. In a much more general framework, I think that one could use a perfect simulation algorithm as described in:\n\nProcesses with long memory: Regenerative construction and perfect simulation, Francis Comets, Roberto Fern\u00e1ndez, and Pablo A. Ferrari, Ann. Appl. Probab. 12, Number 3 (2002), 921-943.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/48009/inequality-on-probability-distributions?sort=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI would like to know if the following inequality is satisfied by all probability distributions (or at least some class of probability distributions) for all integer $n \\geq 2$.\n\n$\\int_0^{\\infty} F(z)^{n-1}(1-\\frac{F(z)}{n})\\left[zF(z)^{n-2} - \\int_0^z F(t)^{n-2}dt\\right]f(z)dz$ $\\leq \\int_0^{\\infty} F(z)^{n-1}\\left[zF(z)^{n-1} - \\int_0^z F(t)^{n-1}dt\\right]f(z)dz $\n\nSome comments follow:\n\n1) F(z) is the cumulative distribution function of any probability distribution over positive real numbers. The outer integral runs over the entire support of the distribution, thus, in general, from zero to infinity. f(z) is the probability density function.\n\n2) I will be happy even if this is proved for bounded support distributions, in which case, the outer integral runs from 0 to some upper limit H.\n\n3) Note that both the LHS and the RHS are always non-negative. This is because of the special form of what is inside the square brackets. For both the LHS and the RHS, the second term in the square bracket (i.e. the negative integral from 0 to z), when replaced by its value at the upper limit throughout the region of integration from 0 to z, gives precisely the first term in the square bracket. Thus the term in the square bracket is always non-negative, for both the LHS and the RHS.\n\n4) Also note the obvious similarity in the structure between the LHS and the RHS. The only differences are the difference in exponent for what is inside the square brackets, and the LHS having an extra factor of $1 - \\frac{F(z)}{n}$.\n\n5) Note that for $n=2$, this inequality is definitely true since the LHS evaluates to zero owing to the term in the square bracket in the LHS becoming zero, and the RHS is always non-negative, as mentioned in point 3 above.\n\n6) It is easy to work out that for all $n \\geq 2$, this inequality is true for uniform [0,1] distributions, i.e., the distribution with support [0,1] and $F(z) = z$.\n\n7) I tried evaluating this integral for small values of $n$ (till 50) using Maple for exponential distribution, and the positive half of the normal distribution and found it to be true. I am guessing that this inequality is true for at least some large class of probability distributions if not all distributions.\n\n8) For instance, would a monotone hazard rate condition help? Monotone hazard rate means that $\\frac{f(z)}{1-F(z)}$ is non-decreasing.\n\nshare|cite|improve this question\nCould you give some background of this inequality? \u2013\u00a0zhoraster Dec 2 '10 at 11:21\nThis inequality pops up in my research in algorithmic game theory. The actual context itself yields little intuition, except for the fact that if the above inequality held, the result we get would be a natural one. Briefly, the problem has to do with comparing two kinds of auctions with each other and analyzing bidding strategies in the two auctions. One auction rewards the highest bidder more than the other, so we would expect the expected highest bid to be larger in the first auction. That is what this inequality would imply. \u2013\u00a0Balu Dec 2 '10 at 18:21\nIs $n$ the number of bidders and this inequality derived from expected order statistics? \u2013\u00a0R Hahn Jan 1 '11 at 7:48\nHahn, the answer to both of your questions is yes. \u2013\u00a0Balu Jan 2 '11 at 11:37\nup vote 7 down vote accepted\n\nThe inequality holds for every $n\\ge2$ (integer or not) and every probability distribution. Here is a proof. We begin with two easy facts.\n\nFact 1: For every $z\\ge0$ and every $k\\ge1$, $$ zF(z)^k-\\int_0^zF(t)^k\\mathrm{d}t=k\\int_0^ztF(t)^{k-1}f(t)\\mathrm{d}t. $$ Fact 2: For every $t$ and every $k\\ge0$, $$ (k+1)\\int_t^{+\\infty}F(z)^kf(z)\\mathrm{d}z=1-F(t)^{k+1}. $$ (Fact 1 is an integration by parts. Fact 2 is trivial.)\n\nNow to the proof.\n\nReplace the brackets on the LHS and on the RHS by integrals over $t$ in $(0,z)$ thanks to Fact 1. This yields expressions of the LHS and of the RHS as double integrals. Interchange the order of integration. The inner integrals over $z$ in $(t,+\\infty)$ can both be evaluated thanks to Fact 2. One gets that the difference between the RHS and the LHS is $$ A_n=n^{-1}\\int_0^{+\\infty}tf(t)F(t)^{n-3}P_n(F(t))\\mathrm{d}t, $$ where $$ P_n(x)=(n-1)x(1-x^n)-(n-2)(1-x^n)+(n-2)(1-x^{n+1})/(n+1). $$ Hence $$ A_n=n^{-1}\\int_0^{+\\infty}Q_n(F(t))\\mathrm{d}t,\\qquad\\mbox{with}\\quad Q_n(x)=\\int_x^1u^{n-3}P_n(u)\\mathrm{d}u. $$ The proof that $A_n\\ge0$ for every probability distribution is complete if $Q_n\\ge0$ over $(0,1)$. Some easy calculus of variation will do the job.\n\nNamely, over $(0,1)$, the second derivative $P''_n$ is positive then negative, hence the first derivative $P'_n$ is increasing then decreasing. Since $P'_n(0)>0$ and $P'_n(1)<0$ (expressions omitted), $P'_n$ is positive then negative, hence $P_n$ is increasing then decreasing. Since $P_n(0)<0$ and $P_n(1)=0$, $P_n$ is negative then positive.\n\nThis shows that $Q_n$ is increasing then decreasing over $(0,1)$. Since $Q_n(1)=0$, it remains to prove that $Q_n(0)\\ge0$. This last fact follows from the explicit computation of the integral over $(0,1)$ defining $Q_n(0)$, which yields, unless I am mistaken, that $Q_n(0)=(n-2)/(2(n-1)(2n-1))$. Since this quantity is nonnegative for every $n\\ge2$, we are done.\n\nshare|cite|improve this answer\nThanks Didier! Perfect. \u2013\u00a0Balu Jan 2 '11 at 11:36\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/25312/number-of-spanning-trees-of-a-quotient-graph?sort=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $G$ be a finite connected graph on a $2m$-element vertex set $V$. For any graph with vertices $u,v$, let $\\mu(u,v)$ denote the number of edges between $u$ and $v$. Suppose that $G$ has an automorphism $f$ that is a fixed-point free involution on the vertices. We can define a quotient graph $G/f$ by letting the vertices of $G/f$ be the orbits $[u]=\\left\\lbrace u,f(u)\\right\\rbrace$ of $f$, and setting $$ \\mu([u],[v]) = \\mu(u,v) + \\mu(f(u),v). $$ Let $\\kappa(H)$ denote the number of spanning trees of a graph $H$. By the Matrix-Tree Theorem and some simple linear algebra, one can show that $2\\kappa(G)$ is divisible by $\\kappa(G/f)$. My question is whether the factor of 2 is necessary, i.e., is it always true that $\\kappa(G)$ is divisible by $\\kappa(G/f)$? Similar questions can be asked for more complicated automorphism groups of $G$.\n\nshare|cite|improve this question\nI think this works in the general case too if we define a quotient according to $\\mu([u],[v])=\\mu(u,v)+\\mu(u,f(v))+\\cdots+\\mu(u,f^{n-1}(v))$, where $f$ is an automorphism of degree $n$, but I havent checked the details. I wonder if there are any other graph related quantities that behave this way under taking quotients. \u2013\u00a0Gjergji Zaimi Jun 4 '10 at 14:40\n\nLet us group the vertices as $U=\\{u_1,u_2,\\dots,u_n\\}$ and $V=\\{v_1,v_2,\\dots, v_n\\}$ where $f(u_i)=v_i$. Let $L_0$ be the laplacian of the graph with vertex set $U$ and edges as restricted from $G$, let $L _1 = \\operatorname{diag}\\left( \\sum _{j=1}^n \\mu(u _i, v _j)\\right)$ and $L=L _0+L _1$, also let $A$ be the symmetric matrix whose $a _{ij}$ is $-\\mu(u _i,v _j)$. Clearly the Laplacian of $G$ is $M=\\left( \\begin {array} {cc} L & A \\\\\\ A & L \\end {array} \\right)$. Let $M^*$ stand for the matrix $M$ with deleted first row and column. We have $$\\kappa(G)=\\det \\left( \\begin {array} {cc} L & A \\\\\\ A & L \\end {array} \\right) ^ *=\\det \\left( \\begin {array} {cc} B & C \\\\\\ D & (L+A)^ * \\end {array} \\right)$$ for some block matrices $B,C,D$ of size $n\\times n,n\\times (n-1),$ and $(n-1)\\times n$ where this second matrix was obtained by adding the $i$th row of $M^{\\*}$ to it's $n+i$th row for $1\\le i\\le n-1$ and then adding the first (or last) $n-1$ columns to the $n$th column. So $D$ is the matrix $(L+A)*$ together with a last column of zeros, making $(L+A)^{\\*-1}D$ with integer entries. Next we factor it using one of these identities $$\\kappa(G)=\\det(L+A)^ * \\det(B-C(L+A)^{*-1}D)$$ and observe that $L+A$ is the Laplacian of $G/f$ so $\\det(L+A)^ *=\\kappa(G/f)$, and since the second factor is an integer we get the desired divisibility.\n\nshare|cite|improve this answer\nIt seems to me that the statement \"Clearly the Laplacian of G is M = [[L,A],[A,L]]\" is false. Can the proof be fixed? \u2013\u00a0Richard Stanley May 29 '10 at 21:33\nFortunately it was just a typo, I think it's fixed now. \u2013\u00a0Gjergji Zaimi May 31 '10 at 5:55\nThe proof looks o.k. now. Getting the last column of zeros was a key step. Thanks for your answer! \u2013\u00a0Richard Stanley Jun 21 '10 at 1:12\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/16851/set-x-increases-by-1-set-y-increases-by-3-need-help-with-a-function-that-will\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nTwo sets\n\nx = 1,2,3,4,5...\ny = 1,4,7,10,13...\n\nI need to write a function\n\n$f(x_n) = y_n$\n\nI found that if I\n\n  1. take a number from x\n  2. double it\n  3. subtract 2\n  4. add the result to the original number\n  5. I get the corresponding number from y\n\nHere's what I have so far (it's in ruby code), it works but is there a better way of doing it.\n\ndef f(x)\n  if x > 1\n    return x + ((2 * x) - 2)\n    return 1\n\ny = f(x)\nshare|cite|improve this question\nNot sure what better way you are looking for. What you have seems fine, expect we can multiply by 3 instead of doubling and then adding itself. I guess Ruby does not have overflow issues. \u2013\u00a0Aryabhata Jan 9 '11 at 1:12\nup vote 3 down vote accepted\n\nYour values y form what is called an arithmetic progression, namely a sequence where each element is obtained from the previous one just by adding always the same constant. In your case the constant is 3, namely: 1, 4=1+3, 7=4+3, 10=7+3 and so on.\n\nSince the FIRST time you add 3 corresponds to x=2, the formula is just\n\n\nor (equivalently)\n\n\nshare|cite|improve this answer\nWow thanks, I can't believe I didn't think about 3x instead of 2x + x lol. \u2013\u00a0Seth Archer Brown Jan 9 '11 at 3:32\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/355934/hamming-code-error-correction\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm currently learning how Hamming codes work and so far I am understanding it!\n\nI have worked through several examples, and it seems to work well following the below table:Hamming Code Table\n\nWhere I get stuck however is when I have an example which its length means it ends on a parity bit. For example:\n\n\nIgnore the meaning of obviously random binary string above, but the fact that it is 16 bits long, when you are error checking it, you start with p1 and then do p2, p4, p8 and finally p16. What I don't understand however, is that as there are no digits after position 16, how am I meant to work out if p16 is correct or not. If the string was 20 bits long, I know you just count 16 and skip 16, starting at p16. However as there are no bits after p16 I am a bit stuck.\n\nIf anyone has any idea, that would be awesome!\n\n\nshare|cite|improve this question\nThis code has 15 bits of data, plus 5 of redundacy (parity), giving a total of 20 bits per encoded symbol. To decode each symbol you need 20 bits. I don't understand why you are given 16 bits to decode, and what are you supposed to do with that. \u2013\u00a0leonbloy Apr 9 '13 at 14:17\nThe table above shows how to error correct up to 20 bits, but the symbol doesn't have to be 20 bits. For example the code word 110110001010 without the parity bits would be 01001010. The original code word can be error corrected using p1, p2, p4 and p8. My problem is not knowing how to error correct a symbol of 16 bits. \u2013\u00a0Luke Presland Apr 9 '13 at 14:36\nNo. The table above is general, in the sense that it can be used to generate a coding scheme for different sizes. But you must fix that size (raw data size and encoded size) beforehand, and the decoder must know it. \u2013\u00a0leonbloy Apr 9 '13 at 14:41\nIndeed. The example I am stuck on is a fixed length of 16 bits. I'm not sure if I'm just not explaining this correctly, but I have worked through examples of 12 bits, which I understand. But 16 bits is just confusing. \u2013\u00a0Luke Presland Apr 9 '13 at 14:46\nup vote 3 down vote accepted\n\nIf the encoded size is 16, this means that the raw size was 11, and the last bit is a useless parity bit, with value zero, that only checks itself. If it's zero, then it's ok, if it's 1 its an error. Of course, to chose this Hamming code of length 16 would be a stupid thing to do, because we are sending a bit with no useful information or error detection capability.\n\nshare|cite|improve this answer\nThanks for your answer! When you say 1 means it is an error. Is this effecting the data stream or does it have no effect? \u2013\u00a0Luke Presland Apr 9 '13 at 15:05\nThe error affected only the parity bit, so \"the correction\" for the data is trivial: do nothing. \u2013\u00a0leonbloy Apr 9 '13 at 15:09\nAh thank you. I hope my question wasn't too trivial. \u2013\u00a0Luke Presland Apr 9 '13 at 15:14\nNot, it wasn't. \u2013\u00a0leonbloy Apr 9 '13 at 15:16\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/161707/is-there-an-efficient-algorithm-to-compute-a-minimal-polynomial-for-the-root-of\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nAn algebraic number is defined as a root of a polynomial with rational coefficients.\n\nIt is known that every algebraic number $\\alpha$ has a unique minimal polynomial, the monic polynomial with rational coefficients of smallest degree of which $\\alpha$ is a root.\n\nIt is also known that the algebraic numbers are algebraically closed, meaning that any polynomial with algebraic numbers as coefficients has algebraic roots.\n\nMy question is:\n\nGiven the root of a degree $d$ uni-variate polynomial with $n$ terms with algebraic coefficients, is there an efficient (i.e. polynomial time in $d$ and $n$) algorithm to generate its minimal polynomial?\n\nI have searched the literature, but found very little work on algebraic number theory concerned with computational complexity. The closest result I found is:\n\nTheorem 1.4.7 in Lovasz's book:\n\nbut I don't think this (quite) answers my question.\n\nshare|cite|improve this question\nIf there is no algorithm for computing the minimal polynomial, an efficient algorithm for finding any polynomial with rational coefficients for which this number is a root, will suffice. \u2013\u00a0dan8394 Jun 22 '12 at 16:32\nOne generally finds the minimal polynomial of an algebraic number, not of a polynomial. Could you please clarify your question? \u2013\u00a0Ragib Zaman Jun 22 '12 at 16:33\nI have done so. Thanks for your careful reading! \u2013\u00a0dan8394 Jun 22 '12 at 16:35\nThanks, and no problem. \u2013\u00a0Ragib Zaman Jun 22 '12 at 16:35\n\nSuppose you have a finite field extension $\\mathbb Q \\subset K$ and an irreducible polynomial $P \\in K[X]$.\n\nLet $L$ be the Galois closure of $K$, $G$ be the Galois group of $\\mathbb Q \\subset L$, and $H$ be the subgroup of $G$ fixing $K$. Then $G$ acts on $L[X]$ by $\\sigma(\\sum a_i X^i) = \\sum \\sigma(a_i)X^i$, and $H$ is still the subgroup of $G$ fixing $K[X]$.\n\nThen define $\\tilde{P} = \\prod_{\\sigma \\in G/H} \\sigma(P)$. For any $\\sigma$ in $G$, $\\sigma(\\tilde{P}) = \\tilde P$, thus $\\tilde P \\in \\mathbb Q[X]$, and I think it should be irreducible over $\\mathbb Q$ if $K$ is the extension generated by the coefficients of $P$. And so far, the computation is polynomial in the degree of the extension $\\mathbb Q \\subset L$ (which may be exponential in the degree of $K$) and in the degree of $P$.\n\nIf you don't know exactly what $L$ and $G$ are but you know the set of conjugates $C_i$ of each coefficient $a_i$ of $P$, define $$\\tilde P = \\prod_{(b_0, \\ldots, b_n) \\in C_0 \\times \\ldots \\times C_n} (b_0 + b_1 X + \\ldots b_n X^n)$$ This will produce a polynomial in $\\mathbb Q[X]$, but can be extremely larger than the minimal polynomial.\n\nHere you pick one conjugate for each coefficient, and you do the product for all possible simultaneous choices of those conjugates. If you have one coefficient with 2 conjugates and another one with 3, and all the other coefficients are rationals, then you have 6 polynomials to multiply.\n\nFinally, if you don't know the conjugates of the coefficients but you know some annihilating polynomial for each coefficient, let $C_i$ be a set of formal roots of those polynomials, and formally expand that product. You will get an expression involving the formal roots symmetrically so you can write it using the elementary symmetric polynomials of those roots, and then use the Viete relations and replace those with the corresponding coefficients of your annihilating polynomials.\n\nHowever, these two methods can be exponential in the degree of $P$, so you should avoid them if possible.\n\nIn the worst case scenario, the Galois group of $\\mathbb Q \\subset K$ will be $S_n$, meaning that we have to do calculations in a very big field extension.\n\nsuppose $K$ is of degree $n$ and $P$ is of degree $d$. We can estimate of the generic formula you need to use to transform $P$ into a polynomial with rational coefficients.\n\nPick $L = \\mathbb Q(Y_1, \\ldots, Y_n)$, let $Z_1, \\ldots, Z_n$ be the elementary symmetric polynomials in $Y_i$, pick $K_0 = L^{S_n} = \\mathbb Q(Z_1, \\ldots, Z_n)$, and $K = K_0(Y_1)$ So the extension $K_0 \\subset K$ is the \"generic\" extension of degree $n$ over $\\mathbb Q$. Then say $P = \\sum a_i X^i$, where $a_i \\in K = K_0[Y_1]$ and are of degree $ < n$. So you can write $P = \\sum b_{i,j} X^i Y_1^j$ where $b_{i,j} \\in K_0$, and $(i,j) \\in \\{0 \\ldots d \\} \\times \\{0 \\ldots n \\}$. Add indeterminates $B_{i,j}$, so that now $P$ is an element of $K[B_{i,j},X]$. We can compute the product $\\prod_{k=1}^n P(Y_k,B_{i,j},X)$ in $L[B_{i,j},X]$, then since it is symmetric, write it as an element of $K_0[B_{i,j},X]$. In fact since the coefficients of $P$ are polynomials in $Y_1$ with integer coefficients, this will be a polynomial in $\\mathbb Z[Z_i, B_{i,j},X]$ of degree $dn$ in $X$, homogeneous of degree $n$ in the $B_{i,j}$.\n\nFor any choice of $n$ indeterminates among the $B_{i,j}$, $B_{i(1),j(1)} \\ldots B_{i(n),j(n)}$ will appear accompanied with $X^{i(1)+\\ldots i(n)}$ and a polynomial in $Z_k$ of degree $j(1)+\\ldots j(n) \\le n^2$ in $Y_k$. So we obtain less than about $(n+d)!/n!d! * n^{2n}/n!$ terms in the final polynomial. Though there may be a better bound on the complexity of polynomials in $Z_k$ that are of a given degree less than $n^2$ than $n^{2n}/n!$ (in particular, not all of them should be able to appear).\n\nWell the good thing it that this is polynomial in $d$ when $n$ is fixed, and is probably exponential in $n$ when $d$ is fixed. And when both of them vary, it's exponential in $d$ and $n$.\n\nshare|cite|improve this answer\nThank you. These are some promising ideas. Can you clarify your notation in the equation? Is $\\times$ a Cartesian product? What fixes the order of conjugates in that expression? \u2013\u00a0dan8394 Jun 23 '12 at 8:04\nTo clarify, I am interested in worst case complexity. Your answer seems to imply that the best-known algorithms are exponential in run time. Is there a rigorous way to prove this? My investigations in Mathematica also support this conclusion. \u2013\u00a0dan8394 Jun 23 '12 at 8:58\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/15055/finding-distribution-parameters-of-a-gaussian-mixture-distribution\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nShort version: how to estimate the parameters of a mixture of multivariate normal distributions (i.e.: Gaussian mixture model)?\n\nLong version.\n\nI am trying to estimate the parameters of a mixture of multivariate Gaussian distribution.\n\nI know how to do it for a single multivariate normal distribution:\n\ndataSet = RandomVariate[dist, 300];\nestDist = EstimatedDistribution[dataSet, MultinormalDistribution[{m1, m2}, {s11, s12}, {s12, s22]}}]]\n\nPlot[{PDF[dist, {x, 0}], PDF[estDist, {x, 0}]}, {x, -4, 4}, Filling -> Axis]\nPlot3D[PDF[estDist, {x, y}], {x, -2, 2}, {y, -2, 2}]\n\nSimilarity of PDF at y=0, density of dataset and estimated density.\n\nAll fine and dandy. However, the same approach does not work for me with mixture distributions. In particular, I am interested in mixtures of Gaussian distribution (Gaussian Mixture Model).\n\nI generate a sample dataset:\n\ntargetDist = MixtureDistribution[{1/3, 2/3}, {MultinormalDistribution[{0, 0}, {{1, 0}, {0, 1}}], MultinormalDistribution[{3, 3}, {{1, 0}, {0, 1}}]}];\ndataSet = RandomVariate[targetDist, 500];\n\nMixture of Gaussians\n\nI try to find the estimated distribution with:\n\nestimatedDist = EstimatedDistribution[dataSet,\n    MixtureDistribution[{w1, w2}, {\n        MultinormalDistribution[{m11, m12}, {{s111, s112}, {s112, s122}}],\n        MultinormalDistribution[{m21, m22}, {{s211, s212}, {s212, s222}}]\n\nBut the evaluation always fails with:\n\nNMaximize::cvdiv: Failed to converge to a solution. The function may be unbounded. >>\n\nFor some reason, it works if, instead of using MultinormalDistribution I use BinormalDistribution with $\\rho$=0.\n\nI know how to estimate these parameters using the Expectation Maximization algorithm, but I was wondering if there is a Mathematica-friendly way to do it.\n\n\nGiving initial estimates of the parameters does not really improve much. Even when giving the exact parameters like this:\n\nestimatedDist = EstimatedDistribution[dataSet, \n        {w1, w2},\n        {MultinormalDistribution[{m11, m12}, {{s111, s112}, {s121, s122}}],\n         MultinormalDistribution[{m21, m22}, {{s211, s212}, {s221, s222}}]}],\n        {{w1, 1/3}, {w2, 2/3}, {m11, 0}, {m12, 0}, {s111, 1}, {s112, 0}, {s121, 0}, {s122, 1}, {m21, 3}, {m22, 3}, {s211, 1}, {s212, 0}, {s221, 0}, {s222, 1}}]\n\nEstimatedDistribution seems to take much more time than what it would be reasonable (and, since the estimates are exact, \"reasonable\" means 0.1 sec).\n\nAfter about 15 minutes of processing on a 3.3GHz Xeon, I got this error:\n\nFindMaximum::eit: The algorithm does not converge to the tolerance of\n4.806217383937354`*^-6 in 500 iterations. The best estimated solution,\nwith feasibility residual, KKT residual, or complementary residual of\n{2.1536*10^-12,0.00200273,5.6281*10^-13}, is returned. >>\n\nThen a popup message:\n\nClick here to find out if this problem is known, and to help improve\nMathematica by reporting it to Wolfram Research.\nshare|improve this question\nYou are aware that you can supply EstimatedDistribution[] with initial estimates of parameters? \u2013\u00a0J. M. Nov 22 '12 at 14:19\n@J.M. Please see my edit. Using the exact parameters as estimation seems just to avoid divergence, but EstimatedDistribution still fails to return a meaningful result. \u2013\u00a0Giuseppe Cardone Nov 22 '12 at 15:15\nup vote 9 down vote accepted\n\nYou need to make sure that the constraints on the parameters are satisfied. In this case, these are\n\n1) The mixture weights sum to one. 2) The covariance matrices of the two bivariate normals need to be positive definite.\n\nThe first constraint can be guaranteed by specifying the weights as follows:\n\nw1 = Exp[w]/(1 + Exp[w]);\n\nwhere w is unconstrained.\n\nThe second constraint can be enforced by using the Cholesky Decomposition of the covariance matrices as below.\n\nc1 = {{c111, 0}, {c112, c122}};\n\nwhere c1 is a lower triangular matrix of unrestricted elements. The resulting covariance matrix is given by s1 below.\n\ns1 = c1.Transpose[c1]\n\nOut[9]= {{c111^2, c111 c112}, {c111 c112, c112^2 + c122^2}}\n\nSimilarly, we have for the other covariance,\n\ns2 = c2.Transpose[c2];\n\nLet the two mean vectors be\n\nm1 = {m11, m12};\n\nm2 = {m21, m22};\n\nThe mixture pdf can be written as\n\nIn[15]:= mixPDF = MixtureDistribution[{w1, 1 - w1}, \n  {MultinormalDistribution[m1, s1], \n   MultinormalDistribution[m2, s2]\n\nOut[15]= MixtureDistribution[{E^w/(1 + E^w), \n  1 - E^w/(1 + E^w)}, {MultinormalDistribution[{m11, \n    m12}, {{c111^2, c111 c112}, {c111 c112, c112^2 + c122^2}}], \n    m22}, {{c211^2, c211 c212}, {c211 c212, c212^2 + c222^2}}]}]\n\nThen one may get what you are looking for, depending upon starting values.. The first try here does not give the correct answer.\n\nIn[16]:= est1 = EstimatedDistribution[dataSet, mixPDF]\n\nOut[16]= MixtureDistribution[{0.0172133, \n  0.982787}, {MultinormalDistribution[{1.37871, \n    0.821044}, {{4.88591, 1.35155}, {1.35155, 0.373881}}], \n    1.88312}, {{3.0206, 2.01692}, {2.01692, 3.08025}}]}]\n\nSpecifying starting values helps.\n\nIn[17]:= est2 = \n  mixPDF, {{m11, - 0.5}, {m12, 0.8}, {m21, 1.5}, {m22, 2.0}, {c111, \n    1.5}, {c112, 0.0}, {c122, 1.0}, {c211, 1.5}, {c212, 0.0}, {c222, \n    1.0}, {w, 0.2}}]\n\nOut[17]= MixtureDistribution[{0.39772, \n  0.60228}, {MultinormalDistribution[{0.110727, \n    0.110757}, {{1.05393, 0.060291}, {0.060291, 1.07923}}], \n    3.02315}, {{0.84418, -0.148054}, {-0.148054, 0.982491}}]}]\n\nAn alternative approach can use FindDistributionParameters as follows\n\nest3 = FindDistributionParameters[dataSet, \n  mixPDF, {{m11, 0.0}, {m12, 0.0}, {m21, 2.5}, {m22, 3.0}, {c111, \n    1.0}, {w, 0.5}}]\n\nOut[18]= {m11 -> 0.110727, m12 -> 0.110757, m21 -> 3.0927, \n m22 -> 3.02315, c111 -> 1.02661, c112 -> 0.0587281, c122 -> 1.0372, \n c211 -> 0.918792, c212 -> -0.16114, c222 -> 0.978021, w -> -0.414975}\n\nThe original parameters can be obtained as\n\nIn[19]:= {w1, 1 - w1, m1, s1, m2, s2} /. est3\n\nOut[19]= {0.39772, 0.60228, {0.110727, \n  0.110757}, {{1.05393, 0.060291}, {0.060291, 1.07923}}, {3.0927, \nshare|improve this answer\nThis is a great answer. I hadn't realized that EstimatedDistribution doesn't take sensible constraints on the parameters into account. So, I assume that we have to use similar tactics for other distributions, right? Like n>=0 for the binomial distribution and sigma >=0 for normal distribution. \u2013\u00a0Sjoerd C. de Vries Jul 3 '13 at 21:03\n\nYou may have more success creating your own custom mixture distribution.\n\nOleksandr Pavlyk created a presentation about creating distributions in Mathematica for the Wolfram Technology Conference 2011 workshop:\n\n'Create Your Own Distribution'.\n\nYou can download it here.\n\nThe downloads include the notebook,\n\n\nthat seems to lay out all the pieces required to create a distribution that one can use like the distributions that come with Mathematica.\n\nIt takes some time and thought to set up all of the pieces, but once done your custom distribution can work like a charm.\n\nshare|improve this answer\nI think that defining a new distribution would be much more difficult that implementing the EM algorithm, which is relatively simple. \u2013\u00a0Giuseppe Cardone Nov 23 '12 at 20:13\nI cant seem to find the .nb file? \u2013\u00a0Chen Stats Yu Dec 19 '14 at 1:04\n@ChenStatsYu -- Send me an email and I can send you the notebook. You can find my address in my profile. \u2013\u00a0Jagra Dec 19 '14 at 14:04\n@Jagra Sorry about the confusion. I finally got the notebook. I will give it a go. I am having some trouble optimizing a likelihood from a mixture distribution. I wonder define an implicit PDF will have a better way to find mle. \u2013\u00a0Chen Stats Yu Dec 19 '14 at 14:17\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-total-current.82840/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the total current\n\n  1. Jul 21, 2005 #1\n    A coil of self-inductance 0.7H is joined in parallel with a non-inductive resistance of 50 ohm. Calculate the total current, the current throught the wattless and power components when connected to a supply of 200V at a frequency of 50Hz.\n\n    Here is my steps:\n    Impedance Z= root [ 50^2 + (2pi*50*0.7)^2 ] = 225.5 ohm\n    Total current = 200/ Z = 0.9756A\n\n    Am I right? as for the other two questions, i really don't know how to solve them. :confused: Please help me with it. Thank you!\n\n  2. jcsd\n  3. Jul 21, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have treated the resistor and coil as a series combination. The problem says they are in parallel.\n\n\n    When you do the first part correctly, you will be able to find the total current. You can find the current in each branch, and therefore in each device using the individual impedences and the applied voltage.\n    Last edited: Jul 21, 2005\n  4. Jul 21, 2005 #3\n    the equation for total impedance Z you used above would apply to a series circuit with coil inductance 0.7H and resistor resistance 50 ohms.\n    however, in this case, these 2 components are in parallel, and you would first need to compute Ztotal using (complex impedances):\n\n    [tex] \\frac{1}{Z_{total}} \\ = \\ \\frac{1}{Z_{coil}} \\, + \\, \\frac{1}{Z_{resistor}} [/tex]\n\n    and then use:\n\n    [tex] Total \\ Current \\ Magnitude \\ = \\ \\frac{200 \\ Volts}{|Z_{total}|} [/tex]\n\n    an easier method for this parallel circuit is to sum the currents thru each branch of the parallel circuit:\n\n    [tex] \\mbox{Current Thru Coil} \\ = \\ \\frac{200}{2 \\pi (50)(0.7)\\mathbf{j}} [/tex]\n\n    [tex] \\left ( \\ \\ \\mbox{Current Magnitude Thru Coil} \\ = \\ \\left | \\, \\frac{200}{2 \\pi (50)(0.7)\\mathbf{j}} \\, \\right | \\ = \\ \\frac{200}{2 \\pi (50)(0.7)} \\ \\ \\right ) [/tex]\n\n    [tex] \\mbox{Current Thru Resistor} \\ = \\ \\frac{200}{(50)} [/tex]\n\n    [tex] \\mbox{Total Current Magnitude} \\ = \\ \\, \\left \\Large | \\, \\mbox{Current Thru Coil} \\ + \\ \\mbox{Current Thru Resistor} \\, \\right | [/tex]\n\n    this also answers the last 2 questions of your problem.\n    (*** Clarifications/corrections added from suggestions by OlderDan ***)\n    Last edited: Jul 21, 2005\n  5. Jul 21, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The currents are not in phase. You cannot simply add them. Your first equation is valid only if complex impedences are used. I fixed the link in my earlier post. Check it out.\n  6. Jul 21, 2005 #5\n    Hello olderdan and geosonel, thank you for your help. I realise I have treated the problem wrongly. However, when I follow your method, i get the total current to be 4.9095 ohm; and the answer given is 0.8865A. Yet, the other two answers are 0.8642A and 0.1964A respectively, which do not add up to 0.8865A...What do you think? :)\n  7. Jul 21, 2005 #6\n    OlderDan -- your comments are, of course, correct.\n    the entire Msg #3 was originally intended to incorporate COMPLEX impedances and use complex representations. clarifications/corrections have been added based on your suggestions.\n\n    Clari --\n    changes were made to Msg #3 to better indicate the COMPLEX representations of the various quatities. do you know how to use these complex representations? specifically, the total current would be equal to:\n    total current = (complex current thru coil) + (complex current thru resistor)\n    = (-0.9095j) + (4)\n\n    total current MAGNITUDE = | (-0.9095j) + (4) |\n\n    [tex] \\ = \\ \\sqrt{(0.9095)^{2} + (4)^{2}} \\ = \\ 4.102 \\ amps [/tex]\n\n    the individual current magnitudes must be combined like shown above because the current thru the coil and current thru the resistor are out of phase (which is why they are represented by complex quantities).\n\n    apparently the book is wrong about the answer. either that or you may have made a careless error in copying the problem. you might double check the problem.\n  8. Jul 21, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I think you have not treated the impedence as complex when calculating the equivalent impedence, and the unit of \"ohm\" in your result should be \"amp\". I see no way of getting the answers you have been given. A 50 ohm resistor by itself connected to a 200 volt supply would give a 4 amp current. A parallel path through the 0.7H inductor would give a current of 0.9095 amp at 50 hz that is 90 degrees out of phase with the resistor current. You cannot simply add these two (which is effectively what you did by not calculating the equivalent impedence correctly) because they are out of phase, but even when added correctly they still add up to about 4.10 amps, which is a lot more than the answers you are given.\n\n    EDIT: Late to the party again :smile: See geosonel's reply for more detail on the calculations\n\n    Please check the problem and make sure you are stating it correctly. The ratio of the currents given for the separate currents is about right. Is there something else in series with the parallel combination? Do you have the voltage right?\n    Last edited: Jul 21, 2005\n  9. Jul 23, 2005 #8\n    I think your answers are right, while those given by my teacher are wrong, so i believe i know how to sort it out now. ^^ Thank you very much!! :smile:\n\n    To geosonel, i haven't learned anything about the RLC circuit in parallel in fact, so i know nothing about complex representations. What is j in:\n    To olderdan, i have stated out the problems clearly, and there's certainly nothing in series with the parallel combination.\n  10. Jul 23, 2005 #9\n    Clari -\n    we didn't know your mathematical background when suggesting the \"complex representation\" method for AC circuits. unfortunately, it's difficult to provide a complete tutorial on AC circuit methods in this forum.\n\n    if you're interested in learning what the \"j\" signifies in the previous msgs and how the \"complex representation\" method works, try the tutorial given in the URL link below. (this tutorial takes 8 pages, including the introduction). this link also provides good info on many other electronic circuit topics.\n    Last edited: Jul 23, 2005\n  11. Jul 23, 2005 #10\n\n\n    User Avatar\n    Homework Helper\n\n    I have done the problem with very basic method by taking voltage V = v(max)sin(wt)\n    taking the total instantaneous current then finding the rms value of it using integration method and got the same answer 4.102 A as by geosonel\n    Last edited: Jul 23, 2005\n\nHave something to add?\n\nSimilar Discussions: Calculate the total current\n  1. Calculating current (Replies: 2)\n\n  2. Calculating current (Replies: 3)\n\n  3. Calculating Current (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/volume-of-a-solid.3590/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nVolume of a solid\n\n  1. Jul 4, 2003 #1\n    I need help on this problem which is giving me a few headaches...!!!!\n\n    here goes..\n\n    Show that the volume of the solid bounded by the coordinate planes and the plane tangent to the portion of the surface xyz = k, k>0, in the first octant does not depend on the point of tangency.\n\n    Your help will be much appreciated.\n  2. jcsd\n  3. Jul 4, 2003 #2\n    OK, i think i have the answer. i make it 9k/2. how much help do you want?\n\n    my first hint: the normal to that surface can be found by taking the gradient.\n  4. Jul 4, 2003 #3\n    Hi lethe,\n\n    I am totally lost on this question to be honest and I can't seem to work out what to do here to solve it. I would really appreciate it if you could explain step by step what you are doing so I can understand how you came to your conclusion and your answer.\n\n    eg. how you came to your answer of 9k/2.\n\n    and also your hint: the normal to that surface can be found by taking the gradient.\n\n    How would you go about solving this?\n\n    Your help will be greatly appreciated.\n  5. Jul 4, 2003 #4\n\n    step 1: the gradient of xyz - k gives you the normal vector to the surface.\n\n    the gradient is (yz,xz,xy)\n\n    step 2: the equation for a plane with normal vector n is n*(x-x0)=0\n\n    so the equation for the tangent plane at x0 is y0z0(x-x0)+x0z0(y-y0)+x0y0(z-z0)=0\n\n\n    x/x0 + y/y0 + z/z0 = 3\n\n    step 3: find the three coordinate intercepts of this plane by plugging in x=y=0 and get z=30, then x=z=0 and get y=3y0, and x=3x0\n\n    step 4: calculate the volume. it is a right pyramid, the base has legs 3x0 and 3y0, so the area of the base is 9x0y0/2. the area for a pyramid is 1/3*Base*height, so this is 9x0y0z0/2, but since x0 is on the surface, x0y0z0 = k, and we get 9k/2 for the volume\n  6. Jul 5, 2003 #5\n    Hey thanks for your help lethe!\n\n\nHave something to add?\n\nSimilar Discussions: Volume of a solid\n  1. Volume of a solid (Replies: 1)\n\n  2. Solid angle (Replies: 7)\n\n  3. Imaginary volume (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/intersection-of-two-functions.265279/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntersection of two functions\n\n  1. Oct 17, 2008 #1\n    (Problem from practice math subject GRE exam:) At how many points in the xy-plane do the graphs of [tex]y=x^{12}[/tex] and [tex]y=2^x[/tex] intersect?\n\n    The answer I got was 2, but the answer key says 3.\n\n    Intuitively, by the shape of their graphs, I would say two. I tried to calculate actual values for x:\n\n\n    [tex]x\\ln2=12\\ln x[/tex]\n\n    [tex]\\frac{\\ln2}{12}=\\frac{\\ln x}{x}[/tex]\n\n\n    I don't know what to do with that last equation.\n\n    I'm really confused though, because I can't even imagine how they would get a third intersection. Any help would be appreciated. :)\n  2. jcsd\n  3. Oct 18, 2008 #2\n    It's pointless to try to solve a transcendental equation analytically. Remember that x^12 is an even function, and note that 2^x approaches 0 as x approaches -infinity, but also remember that when x=0 that x^12 = 0, so you know that the two plots cross once for x < 0. You might guess they cross once for x>=0, but think about when x is > say 1000 and when x is say 2. Which function is larger in each case? Which is larger at x=0? Which is larger for x = -1000?\n  4. Oct 18, 2008 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Clearly the graph of y= 2x crosses the graph of y= x12 for x somewhere between -1 and 0: 2-1= 1/2 and (-1)12= 1 so the graph of x12 is higher for x= -1 while, at x= 0, 20= 1 and 012= 0 so the graph of 2x is higher for x= 0.\n\n    Also 212= 4096 while 22= 4: the graph of x12 is higher again so the graph must intersect again between x= 0 and x= 2.\n\n    The question, then, is whether the graphs intersect a third time for x> 2; whether 2x is larger than x12 for \"sufficiently large x\".\n\n    One way to answer that is to look at the limit of 2x/x12 as x goes to infinity. Since that fraction itself becomes \"infinity over infinity\" we can apply L'Hopital's rule. Repeatedly differentiating, the numerator just stays 2x (times a power of ln(2)) while the denominator has lower and lower powers eventually becoming a constant (after 12 differentiations, we get 12!) and then 0. What does that tell you about the limit? And what does that tell you about whether 2x or x12 is larger for very large x?\n  5. Oct 18, 2008 #4\n    Thanks! This makes sense. So...\n\n\n    Which means that for very large x, 2^x does eventually exceed x^12, which gives us the third intersection point.\n\n    So, one last question -\n\n    Is this a good general strategy for this type of problem (if I were to get a similar one on the actual exam): First sketch the graph and see what obvious/immediate intersection points I can find. Then use the limit idea for [tex]x\\rightarrow\\infty[/tex] and [tex]x\\rightarrow-\\infty[/tex].\n\n    Will this ensure that I find all of my intersection points?\n\n    Thanks so much! :)\n  6. Oct 18, 2008 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Not necessarily. For example, it there were 3 more intersections between x= 2 and infinity, the same changes in which is smaller and which is larger would be true. You might try looking at the derivative of f- g. If that is always positive, then that can't happen.\n\nHave something to add?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/99421/cosets-of-a-subgroup-do-not-overlap?answertab=votes\nText:\nSign up \u00d7\n\nThis is a question from the free Harvard online abstract algebra lectures. I'm posting my solutions here to get some feedback on them. For a fuller explanation, see this post.\n\nThis problem is from assignment $5$.\n\nProve directly that distinct cosets do not overlap.\n\nLet $H$ be a subgroup of $G$ and let $a$, $b$, and $c$ be elements of $G$ such that $b\\not\\in aH$ and $c$ is in both $aH$ and $bH$. Then there are elements $h$ and $h^\\prime$ in $H$ such that $c=ah$ and $c=bh^\\prime$. So $ah=bh^\\prime$ and $b=ahh^{\\prime -1}$. But $hh^{\\prime -1}\\in H$ so $b\\in aH$. This contradicts our original assumption. Therefore, there can be no element in more than one distinct coset.\n\nAgain, I welcome any critique of my reasoning and/or my style as well as alternative solutions to the problem.\n\n\nshare|cite|improve this question\nThat's the proof. I don't think you'll find an alternative solution, because it's immediate by appealing to the definitions. \u2013\u00a0Isaac Solomon Jan 16 '12 at 0:33\nLooks just fine to me. \u2013\u00a0Alex Becker Jan 16 '12 at 0:34\nIt looks fine. Another way of viewing this is to place an equivalence relation on $G$: $x \\sim y$ if there exists an $h \\in H$ such that $x = yh$. The equivalence classes are exactly the left cosets of $H$. You could also view this through group actions, but it doesn't seem like you're there yet. [I'm not claiming that these are essentially different.] \u2013\u00a0Dylan Moreland Jan 16 '12 at 0:37\nAlso, maybe it's good to be clearer as to why $b \\notin aH$ implies that $aH$ and $bH$ are different. If you worry about that sort of thing then it seems cleaner to prove that $aH \\cap bH \\neq \\varnothing$ implies $aH = bH$. \u2013\u00a0Dylan Moreland Jan 16 '12 at 0:43\nI retract my (worthless) seal of approval from earlier. A lot of the right equations are there, but I'm concerned about this $b \\notin aH$ thing. Perhaps the argument is: if the cosets are different then without loss of generality assume that $bH \\not\\subset aH$. So there exists an $h \\in H$ such that $bh \\notin aH$ and hence $b \\notin aH$. \u2013\u00a0Dylan Moreland Jan 16 '12 at 1:37\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nTo prove the result at hand, you need to start with two distinct cosets sharing a common element, and prove that the cosets coincide. In saying that, \"let $a$, $b$, and $c$ be elements of $G$ such that $b \\not\\in aH$ and $c$ is in both $aH$ and $bH$\", you are assuming that $aH$ and $bH$ are distinct cosets with non-empty intersection and that doesn't mean that $b \\not \\in aH$ [as of now]. Also, $b \\not \\in aH$ does not also mean that, $bH \\neq aH$ [as of now].\n\nSo, I think your proof is faulty here.\n\nI'd fix it this way.\n\nSuppose $c$ belongs to distinct cosets, $aH$ and to $bH$, say $$c = ah_1 = bh_2$$ where $h_1$, $h_2 \\in H$. Then $a = bh_2h_1^{-1}$. Any element of $bH$ has the form $bh$ for some $h \\in H$ and, $$ah = b(h_2h_1^{-1}h) \\in bH$$\n\nSince $h$ was arbitrary in $H$, we see $aH\\subseteq bH$ .\n\nThe reverse inclusion, $bH \\subseteq aH$, follows by a similar argument (using the equation $b = ah_1h_2^{-1}$ instead and arguing similarly).\n\nThis proves the claim.\n\nThere is a round about way of doing this, which I'll nevertheless mention here: The approach through equivalence relations.\n\nLet $H \\subseteq G$ be a subgroup of $G$. Define $\\sim$ on $G$ by, $a\\sim b$ iff there exists $h \\in H$ such that, $a=bh$ for $a,b \\in G$. Prove that your notion of cosets coincide with the equivalent classes of $\\sim$. Now, you know that distinct equivalence classes are disjoint and hence your result.\n\nNote that this leads you into Lagrange's Theorem in finite groups and in fact, the following is also true.\n\nLet $H \\subset G$ such that for all $a,b \\in G$, $aH \\cap bH=\\emptyset$ or $aH=bH$ holds. Then $\\exists g \\in G$ such that $gH$ is a subgroup of $G$.\n\nIn case you have difficulty proving the above result, please let me know.\n\nHope this helps.\n\nEdited to add @Dylan's viewpoint of this problem from group actions: Note that the equivalence relation we have defined can be viewed as a group action by looking at the definition of orbits. (i.e.) search for the action whose orbits are the equivalence classes of $\\sim$. You'll identify that this action is the left multiplication action.\n\nshare|cite|improve this answer\nIn the comments to the question itself I've started to wonder what \"distinct cosets\" means if you have to admit the possibility that they might overlap. When I first read Dylan's and your comments, I agreed with you but I think I've come full circle. The only way I can make sense of distinct is to have the element that \"defines\", for lack of a better word, the coset assumed to be outside the coset it's supposed to be distinct from. And I thought this was such a simple problem... \u2013\u00a0jobrien929 Jan 16 '12 at 2:39\n@jobrien929 \"Distinct\" here should mean that you have two sets $aH$ and $bH$ and they are not equal. \u2013\u00a0Dylan Moreland Jan 17 '12 at 5:59\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/823601/divergent-complex-sequence-with-distinct-points-and-without-accumulation-point-t\nText:\nSign up \u00d7\n\nIs it true that any Divergent complex sequence with distinct points and without accumulation point tends to $\\infty$ ? (One can also replace distinctness condition by condition finitely repeating terms)\n\nI think it's true as my intuition, but tried to prove this as follows :\n\nBy contradiction, suppose $\\{z_i\\}$ are bounded, that is: $\\forall n\\,:\\,|z_n|\\in D_M$. Now as sequence doesn't have accumulation point and $D_M$ is open, all points of the sequence (which their cardinality is infinite) and for each $i$, there exists $r_i$ such that : $$\\forall i\\neq j\\,:\\,D_{r_i}(z_i)\\cap\\{z_j\\}=\\emptyset\\quad\\wedge\\quad \\bigcup_{i=1}^\\infty D_{r_i}(z_i)\\subset D_M$$ From distintness, we know that the set of all these neighborhoods are infinitely countable.\n\nAny help is appreciate for the rest.\n\n\nDivergence is necessary to be determined which I have not used it yet !\n\nshare|cite|improve this question\nYou need to prove more than the fact the $z_i$ are not bounded. Try to show that any disk with centre the origin has only finitely many points of the sequence. That will basically get you there. \u2013\u00a0Andr\u00e9 Nicolas Jun 7 '14 at 6:12\nYes you're right. Thanks \u2013\u00a0Fardad Pouran Jun 7 '14 at 6:24\nYou are welcome. You added a question about divergence. That is not needed, a convergent sequence will have an accumulation point. \u2013\u00a0Andr\u00e9 Nicolas Jun 7 '14 at 6:27\nOk I meant I had not considerd this fact and i wanted to emphasize on it. \u2013\u00a0Fardad Pouran Jun 7 '14 at 6:33\n@Andr\u00e9Nicolas, Could you please give another hint ? \u2013\u00a0Fardad Pouran Jun 7 '14 at 17:58\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nHint: Take a large number $B$. If the sequence $(z_n)$ has an infinite number of terms in the disk with radius $B$, then the sequence has an accumulation point (Bolzano-Weierstrass).\n\nIt follows that for any $B$, there are only finitely many $n$ such that $|z_n|\\le B$. Therefore there is an $N=N_B$ such that if $n\\gt N$ then $|z_n|\\gt B$. This is precisely what it means for $z_n$ to go to infinity.\n\nshare|cite|improve this answer\nIndeed it was suffices for my idea to discuss on $\\bar{D}_M$ instead of $D_M$, which compactness is perfect property for sequences :) \u2013\u00a0Fardad Pouran Jun 8 '14 at 5:19\nHappy to be of help. \u2013\u00a0Andr\u00e9 Nicolas Jun 8 '14 at 5:26\nthank you . My sight over problem was limited \u2013\u00a0Fardad Pouran Jun 8 '14 at 5:42\n\nYour Answer"}
{"text": "Retrieved from http://www.pedagonet.com/mathgenius/answer257.html\nText:\nAnswer :\n\nThe correct answer is 1,992 different ways.\u00a0\nEvery F is either a corner F or a side F\u2014standing next to a corner in its own square of F's.\u00a0\nNow, FIED may be read from a corner F in 16 ways; therefore DEIF may be read into a corner F also in 16 ways; hence DEIFIED may be read through a corner F in 16\u00a0\u00d7\u00a016\u00a0=\u00a0256 ways.\u00a0\nConsequently, the four corner F's give 4\u00a0\u00d7\u00a0256\u00a0=\u00a01,024 ways.\u00a0\nThen FIED may be read from a side F in 11 ways, and DEIFIED therefore in 121 ways.\u00a0\nBut there are eight side F's; consequently these give together 8\u00a0\u00d7\u00a0121\u00a0=\u00a0968 ways.\u00a0\nAdd 968 to 1,024 and we get the answer, 1,992.\n\nIn this form the solution will depend on whether the number of letters in the palindrome be odd or even.\u00a0\nFor example, if you apply the word NUN in precisely the same manner, you will get 64 different readings; but if you use the word NOON, you will only get 56, because you cannot use the same letter twice in immediate succession (since you must \"always pass from one letter to another\") or diagonal readings, and every reading must involve the use of the central N.\n\nThe reader may like to find for himself the general formula in this case, which is complex and difficult. I will merely add that for such a case as MADAM, dealt with in the same way as DEIFIED, the number of readings is 400.\n\nMath Genius"}
{"text": "Retrieved from http://math.stackexchange.com/questions/2356/is-it-possible-to-split-coin-flipping-3-ways/620526\nText:\nSign up \u00d7\n\nWhen flipping a coin to make important decisions in life you can flip once to choose between 2 possible outcomes. (Heads I eat cake, Tails I eat chocolate!)\n\nYou can also flip twice to choose between 4 outcomes. (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads)\n\nCan you use a coin to choose evenly between three possible choices? If so how?\n\n(Ignoring slight abnormalities in weight)\n\nshare|cite|improve this question\nSee also:\u2026 \u2013\u00a0Isaac Aug 13 '10 at 15:55\n@Isaac: Your link is an exact duplicate. Why wasn't this question closed? \u2013\u00a0Casebash Aug 13 '10 at 23:39\nMeta discussion here:\u2026 \u2013\u00a0Tom Boardman Aug 14 '10 at 0:08\nfind a coin with a large edge, so that the probability it falls on the edge is 1/3. now you only need one toss :) \u2013\u00a0user20963 Dec 10 '11 at 6:05\n@Nico: Or just flip a coin in a world where 2 = 3... not very useful answer. \u2013\u00a0The Chaz 2.0 Dec 10 '11 at 10:11\n\n8 Answers 8\n\nup vote 17 down vote accepted\n\nIf you throw your coin $n$ times you have $2^n$ outcomes, the probability of each of which is $\\frac{1}{2^n}$. The larger $n$ is, the better you can divide $2^n$ into three approximately equal parts:\n\nJust define $a_n=[2^n/3]$ and $b_n=[2\\cdot 2^n/3]$, where $[\\cdot]$ denotes rounding off (or on). Since $\\frac{a_n}{2^n}\\to\\frac{1}{3}$ and $\\frac{b_n}{2^n}\\to\\frac{2}{3}$ as $n\\to\\infty$, each of the three outcomes\n\n\"the number of Heads is between $0$ and $a_n$\",\n\n\"the number of Heads is between $a_n$ and $b_n$\", and\n\n\"the number of Heads is between $b_n$ and $2^n$\"\n\nhas approximately the probability $\\frac{1}{3}$.\n\nAlternatively, you could apply your procedure to get four outcomes with the same probability (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads) to your problem in the following way:\n\nAssociate the three outcomes Heads-Heads, Tails-Tails, Heads-Tails with your three possible choices. In the case that Tails-Heads occurs, just repeat the experiment.\n\nSooner or later you will find an outcome different from Tails-Heads.\n\nIndeed, by symmetry, the probability for first Heads-Heads, first Tails-Tails, or first Heads-Tails is $\\frac{1}{3}$, respectively.\n\n(Alternatively, you could of course throw a die and select your first choice if the outcome is 1 or 2, select your second choice if the outcome is 3 or 4, and select your third choice if the outcome is 5 or 6.)\n\nshare|cite|improve this answer\nCan't you count tails-heads as the same as heads-tails? \u2013\u00a0Tyler Hilton Aug 13 '10 at 15:26\n@Affan, it would not be fair as that possibility would occur with the same probability as the other two combined. \u2013\u00a0Joshua Shane Liberman Aug 13 '10 at 15:35\nOh I get ya, thanks! \u2013\u00a0Tyler Hilton Aug 13 '10 at 17:15\nI think what Rasmus meant (in the second part) is that you would always toss in pairs and take into account the order of the two tosses: only if the first toss (of a pair) is tails and the second toss is heads toss the coin another two times. \u2013\u00a0Andre Holzner Aug 19 '10 at 18:58\n\nA simple (practical, low-computation) approach to choosing among three options with equal probability exploits the fact that in a run of independent flips of an unbiased coin, the chance of encountering THT before TTH occurs is 1/3. So:\n\nFlip a coin repeatedly, keeping track of the last three outcomes. (Save time, if you like, by assuming the first flip was T and proceeding from there.)\n\nStop whenever the last three are THT or TTH.\n\nIf the last three were THT, select option 1. Otherwise flip the coin one more time, choosing option 2 upon seeing T and option 3 otherwise.\n\nshare|cite|improve this answer\n\nEDIT Oh dear, Rasmus has extended his answer and rendered this one obsolete! In fact, stop reading this right now and go see what he has done.\n\nI interpret what you are asking as trying to find a way to decide without introducing bias (as would be introduced by counting tails-heads as the same as heads-tails). Rasmus's suggestion of repeating the experiment for a certain configuration seems the best choice.\n\nI drew a little tree and tried to group outcomes into three \"equally-likely\" sets and then realized this is impossible because $3$ does not divide $2^n$ for any $n$. (The quantity $2^n$ being the number of unique outcomes after $n$ \"flips\".)\n\nshare|cite|improve this answer\n\nHere's another method: consider H to be 0 and T to be 1. Consider the results that you get from your coins as successive bits (after the binary point) in a binary number. Assign numbers in the interval [0, 1/3) to the first choice; [1/3, 2/3) to the second choice; [2/3, 1) to the third choice. Flip coins until you know, no matter what happens on the remaining flips, in which of these intervals the resulting real number in [0, 1) will lie.\n\nMore concretely, this means that if you flip two coins and observe HH, make the first choice; no matter what happens the result will be between .0000... = 0 and .001111... = 1/4. Similarly if you observe TT, make the third choice; the result will be between 3/4 and 1. If you observe HT, you can't commit to a choice yet; the result will be between 1/4 and 1/2, which overlaps two of the intervals. Something similar is true for TH.\n\nIn either case flip a third time. HTT corresponds to the interval [3/8, 1/2) which lies entirely in [1/3, 2/3), so HTT corresponds to the second choice; similarly for THH. If you see HTH you're still undecided between the first and second choices; THT is still undecided between the second and third.\n\nContinuing in this way, HTHH corresponds to the first choice, HTHT and THTH are still undecided, THTT corresponds to the third choice.\n\nIn general, for the cut-points 1/3 and 2/3, you flip coins until you get either two heads or two tails in a row. If you first get two heads in a row, this corresponds to the first choice if the initial flip was a head, the second if the initial flip was a tail. If you first get two tails in a row, this corresponds to the second choice if the initial flip was a head, the third choice if the initial flip was a tail.\n\nYou might wonder how many flips this takes, on average, to give a result. With probability 1/2 you get a result on the second flip; with probability 1/4, on the third flip; with probability 1/8, on the fourth flip, and in general with probability $1/2^{n-1}$ for $n \\ge 2$. The sum $\\sum_{n \\ge 2} n/2^{n-1}$ has value 3, so on average this method takes three flips.\n\nThis is a bit slower on average than the method Rasmus suggested, which takes on average 8/3 flips. However, the same method works even if the three choices are not equally likely! (It won't have such a clean way of being expressed as \"flip until you get two in a row\", though.)\n\nshare|cite|improve this answer\n\nIf you are at a crossroads in life requiring you to choose one of three options, then coin tossing is not the correct thing to do.\n\nRather, pick up a dice and roll it. Go for first option if the diece turns up 1 or 2. Go for second option if the dice turns up 3 or 4. Go for the third option if the dice turns up 5 or 6.\n\nEdit: Oops, I saw that Rasmus already gave this option. Anyway I strongly suggest that you prefer this one to the other two methods given by him.\n\nshare|cite|improve this answer\nWell, from the philosophically view-point, I think it's inadvisable to use random experiments for decision making anyway. \u2013\u00a0Rasmus Aug 13 '10 at 15:57\nTrue, true. But if at all someone does a random experiment for decision making, better do one that will get done in the shortest time! So your third method is more time-saving compared to the other two. \u2013\u00a0user1119 Aug 13 '10 at 16:02\n@Rasmus: From a game-theory viewpoint, it often is advisable to use a random method to make decisions. :) \u2013\u00a0Larry Wang Aug 13 '10 at 16:40\n@Kaestur Hakarl: Well... Touch\u00e9! :) \u2013\u00a0Rasmus Aug 13 '10 at 16:53\nOne of Piet Hein's grooks comes to mind: A PSYCHOLOGICAL TIP Whenever you're called on to make up your mind, and you're hampered by not having any, the best way to solve the dilemma, you'll find, is simply by spinning a penny. No -- not so that chance shall decide the affair while you're passively standing there moping; but the moment the penny is up in the air, you suddenly know what you're hoping. \u2013\u00a0Bob Durrant Sep 15 '10 at 20:49\n\nI think I have a pretty good idea where you don't have to redo at all.\n\nflip the coin to decide a side for the first two possibilities. if heads come up, its heads for option 1 and tails for option 2 or vice versa flip again to decide a side for option 3. hence, we have 3 outcomes of a coin for 3 possibilities, and all three are not the same. example: H for 1, T for 2 and T for 3, but not H or T for all 3 options.\n\nnow flip again. if the coin lands on heads, and heads is only on say, option 1, then option 1 wins. if H is on 2 options, select those 2, keep heads for 1 and tails for the other, flip again and decide. the same is applicable if it lands on tails.\n\nI hope you understand how it works and how each option has an equal chance of getting selected.\n\nyou don't have to redo your flips anywhere here. (there is a definite answer).\n\nshare|cite|improve this answer\nAn interesting idea, but I don't think it works. Option 3 is guaranteed to match one of the first two options. It will never be the lone-H or lone-T, and thus will never be selected by the first flip. Option 1 or Option 2 are thus more likely to be selected. \u2013\u00a0Nathan Kurz Mar 22 '14 at 17:46\n\nI prefer a method based on a simple unbalanced game: the first person to throw heads wins. In this game, the person who throws first has a $\\frac 23$ chance of winning, the other has a $\\frac 13$ chance of winning.\n\nTo decide fairly between three outcomes, simply put two outcomes on one team in this game, so they have a $\\frac 23$ chance of getting picked. If this team of outcomes wins, simply toss another coin to decide between them. If the other team wins, there is only one outcome on that team and so no further tosses are needed.\n\nThis method is equivalent to Rasmus's \"alternatively\" answer, and will take $2{\\frac 23}$ coin tosses on average. I don't think there exists a method with fewer average coin tosses, but I have no proof of this.\n\nshare|cite|improve this answer\n\nConsider a similar problem and answer first that happens for our gaming group: If you have a die and need a choice from 1-5, how do you do it? One way is to roll the die and re-roll if you get a six. The advantage of this method is that in a noisy group of drunken people you won't get an objection that one outcome is favored over another.\n\nIn the same vein, people are apt to readily acknowledge there are 4 possibilities for a coin flipped twice (or flip two different coins such as a sickle and a knut at once). In the case that both sickle and knut come up tails, flip both again until you have one of the other three outcomes.\n\nshare|cite|improve this answer\n\nprotected by Zev Chonoles Jul 14 at 0:46\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/22002/travelling-salesman-with-start-and-end-points-for-30-points/22015\nText:\nSign up \u00d7\n\nI am doing a route optimisation for delivery vehicles and failing dismally. Please see problem statement below. My current solution uses FindShortestTour, but this does not have defined start and end points.\n\nData is received from the calling application in the following format: {\"Unique Identifier used by server\", Original order, Task locked, Latitude, Longitude}\n\nThe first point will always have the unique identifier \"00000000-0000-0000-0000-000000000000\" and represents the depot. This point will always have an order of 1 and always be locked.\n\nA number of tasks may be locked in their given order at the beginning of the list. The Task locked is a boolean represented by 1 - locked, 0 - unlocked. These locked tasks are not included in the optimisation as they are fixed in their given order at the beginning of the scheduled.\n\nThe route is to be optimised finding the shortest path starting at the last locked point and ending back at the depot, traversing all other unlocked points. Depot is always locked and will be used if there are no other locked tasks.\n\nThe output is to be in the following format: {\"Unique Identifier used by server\", Original order, Distance to Next Task in km} and is to be arranged in the optimal order. The order will always start with the depot the traverse locked Tasks in their given order. This will be followed by unlocked tasks optimised from the last locked to the depot. This list will not contain the final depot point as the distance returned is the distance to next task. i.e. The last ordered task distance will be the distance from itself to the depot.\n\nThe calculation needs to be able to handle the optimisation of 30 points in under a minute as accurately as possible.\n\ninput = {{\"00000000-0000-0000-0000-000000000000\", 1., \n    1., -26.17132739, \n    28.21375807}, {\"817463b3-e330-4405-9008-e21821e6c121\", 2., \n    1., -26.2055333333333, \n    28.420565}, {\"36418378-a9ef-49d7-be5a-3a54264a8479\", 3., \n    0., -25.99202013, \n    27.53309061}, {\"49595197-11e5-463a-8f7b-6cd294c33f43\", 4., \n    0., -26.14895194, \n    27.92271447}, {\"83fd029b-0313-4519-a785-ff7b9843c85c\", 5., \n    0., -26.169355, \n    28.2079083333333}, {\"612bf08a-1679-4feb-8fee-d12deb49803a\", 6., \n    0., -25.6755766666667, \n    28.0820533333333}, {\"382f1997-5efe-42c1-99f5-bcb8da30e1c8\", 7., \n    0., -26.8742866666667, \n    28.25047}, {\"883d68f2-b50f-48ca-b065-febfc6ea9546\", 8., \n    0., -26.0938733333333, \n    28.1937966666667}, {\"1bf089bf-acae-4a41-8c4b-e120cef8a148\", 9., \n    0., -25.9877716666667, \n    28.0691433333333}, {\"6958e90b-d42a-4c13-b6ec-78bbdd301aba\", 10., \n    0., -25.7661166666667, \n    28.2811033333333}, {\"2f2c5d25-c1de-449e-b779-dd95699d83ed\", 11., \n    0., -26.0474216666667, \n    28.0060766666667}, {\"a11feb01-f067-49aa-b99d-50879229c423\", 12., \n    0., -25.7949916666667, \n    28.29928}, {\"729b8bfb-029a-483a-814a-1575a6fe47bc\", 13., \n    0., -26.0258616666667, \n    28.0692033333333}, {\"732771dd-55fd-4074-a097-2665686f67d8\", 14., \n    0., -26.772045, \n    28.49977}, {\"0690914d-ba34-4086-b5ae-feda7ed6d22b\", 15., \n    0., -26.044905, \n    28.0346666666667}, {\"5de23f0e-9a05-40af-8e1e-f887d5a06452\", 16., \n    0., -26.4070083333333, \n    28.138515}, {\"3e95a2ac-9985-4753-a4cc-5372ca44ed12\", 17., \n    0., -25.64392423, \n    28.13148167}, {\"d2e0bce2-8061-4b57-b983-aa409c1532fe\", 18., \n    0., -26.42138814, \n    28.1074221}, {\"0259d54a-0782-4ac8-a5f6-42af6e3edbc3\", 19., \n    0., -25.78637, 28.28066}, {\"f686b23a-de85-4004-ae70-8d2703336b5d\",\n     20., 0., -26.043795, \n    28.1197816666667}, {\"e8bca7d4-69ad-4477-8791-9daedbc563c9\", 21., \n    0., -26.2624883333333, 28.17859}};\n\n   27.24}, ..., {\"83fd029b-0313-4519-a785-ff7b9843c85c\", 5., 0.62}}\n\nCurrent poor solution here:\n\nEdit The requirement boils down to a traveling salesman path problem.\n\nI have a fixed start and end point with a list of intermediate points which need to be visited exactly once in an optimal order.\n\nI have a working solution here\n\nshare|improve this question\nHello, and welcome to Mathematica.SE! Please edit your question to contain a minimal example, say, with a small collection of cities for your problem. So we can most directly address the Mathematica question at hand, and not the logistics one. \u2013\u00a0VF1 Mar 24 '13 at 19:59\n@TheGwa: is this a typo in the headline? I'm only counting 20 or 21 points (depending on how you see this, it can be considered a 20 or 21 point problem). But where does the 30 in the title come from? \u2013\u00a0Andreas Lauschke Mar 25 '13 at 18:24\n@VF1 I am new to Mathematica and was hoping that giving the most possible information about my problem at hand would get me the most directed help. I have clarified the question and added my working solution to it too. Many thanks. \u2013\u00a0TheGwa Mar 25 '13 at 22:21\n@Andreas: Sorry I have edited the question. 30 points is what I need. \u2013\u00a0TheGwa Mar 25 '13 at 22:22\nTry with an intelligent goo:\u2026 \u2013\u00a0faysou Mar 26 '13 at 9:42\n\n3 Answers 3\n\nup vote 7 down vote accepted\n\nCould make the end point have distance zero from the depot. Say pt 2is your start point and pty 1 is the finish (depot). Then your example could have a route computed thusly.\n\npt2 = input[[All, 4 ;; -1]];\nlen = Length[pt2];\n\ndists = Table[Norm[pt2[[j]] - pt2[[k]]], {j, 1, len}, {k, 1, len}];\ndists[[1, 2]] = dists[[2, 1]] = 0.;\n\n DistanceFunction -> (dists[[#1, #2]] &)]\n\n(* Out[123]= {3.808066795204197, {1, 5, 8, 20, 13, 15, 11, 9, 12, 19, 10,\n   17, 6, 3, 4, 21, 16, 18, 7, 14, 2}} *)\n\nNow just reverse it to start at point 2 and end at the depot.\n\nshare|improve this answer\nBut that's exactly my point. It's cheating if you can pick and choose your start and end nodes. The optimal tour is {{-25.6756,28.0821},{-25.6439,28.1315},{-25.7661,28.2811},{-25.7864,28.2807},{-2\u200c\u200b5.795,28.2993},{-26.2055,28.4206},{-26.772,28.4998},{-26.8743,28.2505},{-26.4214,\u200c\u200b28.1074},{-26.407,28.1385},{-26.2625,28.1786},{-26.1713,28.2138},{-26.1694,28.207\u200c\u200b9},{-26.0939,28.1938},{-26.0438,28.1198},{-25.9878,28.0691},{-26.0259,28.0692},{-\u200c\u200b26.0449,28.0347},{-26.0474,28.0061},{-26.149,27.9227},{-25.992,27.5331}}, verified optimal, and the longest edge is between start and end, the length is 3.22458 \u2013\u00a0Andreas Lauschke Mar 25 '13 at 5:27\n@Andreas The query stated that it was necessary to fix a start and end (and gave a straightforward justification for that). I made no claim to the effect that the tour I found was optimal in the TSP sense, only that it seemed fine for the stated purpose of the original post. As for \"cheating\", I have no idea how meeting (or trying to meet) a stated requirement falls into that category. \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 17:10\nthe o/p does not mention a specific start point -- unless I'm missing something (in that case please correct me). You pick the start point purely arbitrary, which gives you room to make your solution almost arbitrarily \"good\". As for you having no idea how meeting a stated requirement falls into the cheating category, I can only concur, but you merely CLAIM you are meeting a stated requirement. As I said, you pick your start node arbitrarily, giving you the option to pick and choose, thus making your tour (almost) arbitrarily \"good\" (or bad). \u2013\u00a0Andreas Lauschke Mar 25 '13 at 17:17\n@Andreas The statement has the route beginning at the last locked point, and ending at the depot (which I assumed to be the initial point, also categorized as locked). I simply reversed this, found a tour starting at the depot and ending at the last locked point which, in this example, was the second point. Then said to simply reverse that. I now notice that another point, #14, is also locked, so the basic idea seems about right but not the actual result. On a separate note, I'm not sure how preselecting a starting point leads to a better (let alone arbitrarily good) solution for a TSP. \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 17:24\n@Andreas You are certainly correct. I confess I was oblivious to the possibility that our discussion had a point... \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 18:04\n\nNote that FindShortestTour will not allow for start and end points because it is a tour, and thus you can cycle your staring and ending point by simply removing an edge in your Hamiltonian circuit. To find the shortest path for a given start and end point, I would recommend searching for \"find shortest path\" in the Documentation Center, which would lead one to the function of interest, FindShortestPath.\n\nAs speed seems to be an issue, consider changing the Method used by the function or implementing your own approximate algorithm. However, I don't think it would be necessary to go this far as you stated your problem is for 30 points.\n\nEDIT: As requested, here is an approximate algorithm for the traveling salesman problem. If a significant speed/optimization is required, feel free to implement your own. In the method, start refers to the starting vertex, and adj refers to the adjacency matrix of the graph (you will have to create your own).\n\nHere is a nearest-neighbor algorithm:\n\nNearestNeighbor[start_Integer?Positive, adj_?MatrixQ]:=\n    With[{len = Length[adj]},\n        Module[{visited=ConstantArray[1, len], nearest, neighbors, mult, total = 0},\n                visited[[#]] = Infinity;\n                neighbors = adj[[#]];\n                mult=neighbors visited;\n                First@First[Position[mult, nearest]]\n\nYou can easily create an adjacency matrix by telling Mathematica to do so after you have created a Graph object from your coordinates. Look up WeightedAdjacencyMatrix and Graph in the documentation. If you have a set of points pts, then it is fairly easy to do:\n\npts = RandomReal[1, {20, 2}];\nwam[pts_, dist_: EuclideanDistance] := \n  Array[If[Equal[##], Infinity, \n     dist[pts[[#1]], pts[[#2]]]] &, {Length@pts, Length@pts}];\nshare|improve this answer\nThanks VF1. I have tried to implement the shortest path algorithm from here:\u2026 it is too slow for anything over 17 points however. I have tried the FindShortestPath function, but I can't work out how to create a graph from my list of coordinates. Could you please point me to an approximate algorithm for the shortest path problem. \u2013\u00a0TheGwa Mar 24 '13 at 21:50\nI have supplied the Nearest-Neighbor approximate algorithm. This takes in a weighted adjacency matrix. In order to convert a set of coordinates into a Mathematica Graph object, I recommend you take a look at the documentation for Graph, please read the rest of my answer. \u2013\u00a0VF1 Mar 24 '13 at 23:31\nThank you for your input. It has helped me significantly in understanding a number of key concepts in Mathematica. It was not the solution I used in the end, but it helped greatly. \u2013\u00a0TheGwa Mar 25 '13 at 22:25\n\nJVMTools has very powerful TSP functions, using initial and post-opt methods and exploiting concurrency by submitting competing algorithms in parallel, and chaining post-opt methods (also in parallel):\n\nTSP Intro and TSP Power Examples\n\nIf you want specific start and end points, you could use the option \"All\", which will return all tours for the subdivision of the list of nodes, and then pick the first one. That is guaranteed to use the start and end points the user has provided. However, note that with fixed start and end points you may not necessarily get the shortest tour through all nodes. The author of JVMTools has specifically implemented it in a manner so that node list subdivision is used in parallel with the start-end edge as a viable candidate, so that it's not possible to \"cheat\" to create particularly good or bad solutions by specifying fixed start and end points. But, you can discard n-1 solutions and take only the first, that will use your start and end nodes.\n\nFindShortestTour[] uses very simple algorithms. 20 points is small enough, but even with 20 points you are most likely not getting an optimal tour with any of the FST methods. They have a free trial version for JVMTools that is not feature-capped (only time-limited). Some of the algorithms available through JVMTools solve TSP problems with a few thousand nodes to optimality with amazing speed (like less than a minute).\n\nAddition Mar 25:\n\nDue to Lou's request, here is my code. I'm a bit hesitant to say/show too much about JVMTools, because it's my own commercial product, and I don't want to do \"cheap plugs\" in this venerable community, but due to Lou's request, here it comes. Geez, this is gonna get long, but I like the \"Leonid method\" :).\n\nThere's a few ways to do it. If all distances are Euclidean lengths and you want one of the best TSP algorithms in the world (MAOS, \"multi-agent optimization system\", similar to an ant-colony optimization system), you could simply submit\n\nJTravellingSalesmanMAOS[Round[1000 input[[All,{4,5}]]],200,200,100,1,\"EUC_2D\"]//AbsoluteTiming\n\n\nThis uses 200 agents, 200 as the size of the maximum learning cycle as termination condition, 100 as the number of cycles for the best cycle that no longer changes, 1 as the number of trials, and EUC_2D to specify the 2-dimensional Euclidean norm as distance function. Don't worry, if you understand a bit about multi-agent / ant colony optimization, these terms will not be intimidating. With JVMTools you can use that powerful algorithm without understanding too much about multi-agent optimization / ant colony optimization. MAOS is used by JVMTools with permission of the owners.\n\nThe tour is verified optimal, and the only reason it takes 1.4 seconds total time is because the data is encrypted with asymmetric 2048 cipher strength encryption on the client side and sent to the JVMTools server, where the MAOS algorithm runs (like a webservice) on a high-performance Fedora 18 system, and then the result is sent back. 1.4 seconds for 20 nodes is a prohibitively long run time, but the encryption takes constant time for long as well as short data lists, and JVMTools wasn't written for such toy problems. When choosing the MAOS algorithm in JVMTools there is some 1.4 second overhead for everything you send, due to the encryption. This is to ensure that the client data remains confidential when travelling over the public internet with proven unbreakable encryption (active attacks, passive attacks, eavesdropping attacks, chosen-plaintext attacks, chosen ciphertext attacks, man-in-the-middle attacks, padding attacks, ...), and for large problems this constant 1.4 second encryption overhead amortizes away.\n\nBut you can also model things in a more flexible way, by specifying the node pairs you want to consider (or drop) and explicitly setting the edge lengths. This may be more appropriate here, as the o/p has \"non-standard\" edge lengths.\n\n\n\nIt looks a bit more complicated than how you specify it when using the MAOS algorithm in JVMTools or FST in M, but in the end it gives you more flexibility, because a) you can specify the distances for each and every one of the n(n-1)/2=Binomial[n,2] theoretically feasible edges individually (assuming complete graph to start with), setting it to any (positive) number, including MaxDouble or 0, b) you can leave out index pairs, which means there is no edge (taken as infinity) -- which means it is no longer a complete graph. With FST you can only specify a distance function, not what I would call edge data. In addition, pairs then provides a \"data overview\" in a concise form of what you are about to submit as edge-by-edge data. You could literally edit that manually in a spreadsheet program and read in as a M symbol, if you want to model a complicated non-Eudlidean, highly non-convex structure. And although these lists can get long (generated or edited manually), there is no time delay when sending it over to the JVM, because both indices as well as costs are rectangular arrays of compatible type, thus internally they are packed arrays (auto-packed), and JLink/MathLink uses native array methods for primitives, giving you native speed.\n\nUnless I miss something, the o/p did not specify the start node, only the end node (the first), so I can't address that specific case. All TSP functions in JVMTools assume that you want an optimal solution for the FULL cycle, this is by design and not an omission. But you can leave out edges and set arbitrary positive edge lengths, giving you full control over how to model it very individually.\n\nThe option ConcurrentPostOpt shown above did the following in 41 milliseconds:\n\n  \u2022 in thread 1, FarthestInsert is used as initial method, then 6NodeSwap is applied as post-opt, this is candidate 1. Next CheapestInsert is used as initial method, then 6NodeSwap is applied as post-opt, this is candidate 2.\n  \u2022 in thread 2 NearestNeighbor is used as initial method, then 6NodeSwapSingle is applied as post-opt, this is candidate 3.\n  \u2022 in thread 3 NearestNeighbor is used as initial method, then 6NodeSwapDouble is applied as post-opt, this is candidate 4.\n\nThe output is the best solution of candidates 1 through 4. As 6NodeSwap is extremely fast (yet effective), I have put two initial/post-opt pairs in one thread, as even both strategies one after the other is faster than the other two, meaning I can get 4 candidates by using only 3 threads.\n\nThe tour is verified optimal.\n\nBut with 20 nodes you can't really show any meaningful comparison. 20 nodes is a toy problem, a \"micro-benchmark\", which is not a meaningful comparison. The TSP functions in JVMTools were written for a few thousand nodes (a practical runtime/memory limitation is probably around 20 thousand nodes), where M can do nothing but throw in the towel.\n\nshare|improve this answer\nWhy don't you post the anser by using your environment. It seems that we now have two different answers to one question :). Your website looks great. \u2013\u00a0Lou Mar 25 '13 at 10:31\n@Lou: done, see my addition above. \u2013\u00a0Andreas Lauschke Mar 25 '13 at 17:06\nLauske Thanks for the edit. I learned alot and it seems more and more that Java and Mathematica form a very great couple indeed. Impressive. \u2013\u00a0Lou Mar 25 '13 at 20:24\n@Lou: indeed, M and the JVM are a match made in heaven. The M/.Net combination (qua NETLink) is also quite powerful, it's very, very similar. I mull writing a blog post here about using JLink. I think JLink is totally under-appreciated. \u2013\u00a0Andreas Lauschke Mar 25 '13 at 20:33\n@Andreas: This looks like a really amazing technology. Unfortunately I cannot install Java on the server due to security concerns, but I appreciate the input. I am sure it will help others greatly. \u2013\u00a0TheGwa Mar 25 '13 at 22:27\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/226253/what-statistical-hypothesis-test-to-use-for-comparing-results-of-two-equations\nText:\nSign up \u00d7\n\nGiven a function $f\\left(x\\right)$, I have two formulas to compute the coefficients of the same harmonic series approximation to $f\\left(x\\right)$. Call the results of each formula $^1c_k$ and $^2c_k$ for formula 1 and 2 respectively.\n\nI want to test whether the two formulas give the same result for all $k$. Assuming there is no analytical way to test for equivalence, I wanted to perform some kind of statistical hypothesis test.\n\nSo far I have computed $^1c_k$ and $^2c_k$ for hundreds of different functions: $f_1\\left(x\\right), f_2\\left(x\\right),\\ldots,f_n\\left(x\\right)$. So that for each $k$ I have a set of paired values for $^1c_k$ and $^2c_k$:\n\n\n\n\nMy original hypothesis to test was that the error between the results of either formula should be normally distributed about zero. My first inclination was to use a paired t-test, but the paired errors fail normality tests (to varying degrees depending on which normality test you use). I've tried rank-sum tests that didn't give great results. So it looks like the errors are not always normally distributed about zero. But they are generally close to zero.\n\nOne reason that they might not be normally distributed is that one of the formulas might give a result that approaches the result of the other formula asymptotically (i.e. one is always or usually below the other), this would fail my original hypothesis, and yet suggest that the results are the same in the limit of increasing accuracy.\n\nI am now considering using convergence acceleration (e.g. Wynn's epsilon algorithm) to compare the asymptotic values of each formula for each $k$, but this doesn't really give any measurement of the statistical significance of any difference that I might find, nor provide any error bars on the conclusions I arrive at. So I'm still at a loss for how to test statistically whether the two formulas produce equivalent results, any ideas?\n\nshare|cite|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/164928/find-the-number-of-common-normals-to-both-these-curves\nText:\nSign up \u00d7\n\nFind the number of common normals to the curves $ x^2 + (y-1)^2 =1 $ and $y^2=4x$.\n\nMy take :\n\nI formed a cubic in $m$ i.e. slope, so there'll be 3 normals. Please help.\n\nshare|cite|improve this question\nPlease explain how you formed a cubic in slope $m$. \u2013\u00a0hardmath Jun 30 '12 at 15:13\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYour first curve is a circle of radius 1, centered at $(0,1)$. Its normals are the lines through its center, that is, the lines $$y=mx+1$$ for arbitrary $m$ (this leaves out the vertical normal, but that's obviously not normal to the other curve). So now you just have to work out the values of $m$ for which the graph of $y=mx+1$ is normal to the graph of $y^2=4x$. Can you do that?\n\nI guess not, so here goes.\n\nFrom $y^2=4x$ we get $2yy'=4$, so $y'=2/y$. If $(a,b)$ is a point on the graph of $y^2=4x$, then\n1. the slope of the normal to the curve at that point is $-b/2$, and\n2. $b^2=4a$.\nSo the equation of the normal is $$y-b=-(b/2)(x-a)$$ which we can write as $$y=-(b/2)x+(1/2)ab+b$$ But we want the normal to be $y=mx+1$, so $$(1/2)ab+b=1$$ Now combining that with $b^2=4a$, we get, after a little algebra, $$b^3+8b-8=0$$ and it's easy to show that equation has exactly one real zero, so there is exactly one common normal.\n\nshare|cite|improve this answer\nso, no real values of m. Thus no common normals. \u2013\u00a0Bazinga Jul 1 '12 at 7:46\nIf you sketch the two curves, I think it's clear that there is at least one common normal. \u2013\u00a0Gerry Myerson Jul 1 '12 at 9:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/210543/is-this-inequality-proof-correct/210555\nText:\nSign up \u00d7\n\n$a$ and $b$ are fixed real numbers.\n\nClaim: $a < b$ implies $a < b - \\varepsilon$ for some $\\varepsilon > 0$.\n\nProof: Utilise the fact that $a \\implies b$ is equivalent to $b' \\implies a'$.\n\nSo this is equivalent to proving $a \\ge b - \\varepsilon\\,$ for all $\\varepsilon > 0 \\implies a \\ge b$.\n\nNow, as $a \\ge b - \\varepsilon$, take the infimum of both sides.\n\n$$\\inf (a) \\ge \\inf \\{b - \\varepsilon \\mid \\varepsilon > 0\\}$$\n\n$\\inf (a) = a$ and the right-hand side $= b$, hence:\n\n$$a \\ge b.$$\n\nThus, $a \\ge b - \\varepsilon$ for all $\\varepsilon > 0$ implies $a \\ge b$. Which then proves our original claim.\n\nshare|cite|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nSoo... looks good, but!:\n\n  1. Rather use different letters for propositions in your 3rd line, at least capitals ($A\\implies B$ equivalent to $\\lnot B\\implies \\lnot A$)\n  2. Instead of $\\inf$ you are considering $\\sup$\n  3. You are implicitly using $\\sup\\{b-\\varepsilon \\mid \\varepsilon >0\\} = b$, which is true, but... it is equivalent to the given problem. that's why it's not really working.\n\nAnd the solution is (straight ahead):\n\nIf $a<b$, then $b-a>0$, and let $\\varepsilon:=\\displaystyle\\frac{b-a}2$.\n\nshare|cite|improve this answer\nAbout point 3... Any two true statements are equivalent. \u2013\u00a0Arthur Oct 10 '12 at 16:41\nAh ok. Yes the infimum was a slip on my part. Ok so I see that epsilon works, thank you! \u2013\u00a0user64219 Oct 10 '12 at 16:46\nAny $\\varepsilon\\in (0,b-a)$ works. \u2013\u00a0Berci Oct 10 '12 at 20:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/58161/simulate-a-double-chance-bet-with-two-single-bets/58184\nText:\nSign up \u00d7\n\nIf you bet on the result of a soccer match, you usually have three possibilities. You bet\n\n  \u2022 1 - if you think the home team will win\n  \u2022 X - if you think the match ends in a draw\n  \u2022 2 - if you think the away team will win\n\nLets say we have the following soccer match with the following betting quotes:\n\nKansas City vs. Portland - 1 = 1.92, X = 3.57, 2 = 5.00\n\nThis means: If you think Portland (In the opinion of the bookie, the underdog) will win the match, you bet on 2\n\nExample (I bet \\$100): In case Portland wins I win \\$400 $$100*5.00-100 = 400$$ $$stake*quote-stake = net win$$ (When Portland loses the match, or it ends in a draw, I'll lose my stake)\n\nNow, some bookies offer a so-called double chance bet. This kind of bet takes one possibility out. That leaves you to following bets. You bet\n\n  \u2022 1/X - if you think the home team will win or the match ends in a draw\n  \u2022 X/2 - if you think the away team will win or the match ends in a draw\n\nThis variant is perfect if you think Portland will win the match, or at least it will end up in a draw. To calculate this quotes I use the following formula: (Q1 = 1st quote 1, Q2 = 2nd quote)\n\n$$ 1/(1/Q1+1/Q2) $$\n\nFor the 1/X bet $$ 1/(1/1.92+1/3.57) = 1.25 $$\n\nFor the X/2 bet $$ 1/(1/3.57+1/5) = 2.08 $$\n\nNow comes my math problem: When the bookie does not offer a double chance bet, I want to create it my self: With two single bets. For the Kansas City vs. Portland bet I'd like to place a X/2 bet. The quote for the bet is as I showed before 2.08. I want to place \\$100 on it. When I win the bet, I'll get \\$108 net win:\n\n$$100*2.08-100 = 108$$\n\nHow do I have to split the money on two (X and 2) single bets, to win \\$108, when Portland wins or the match ends in a draw?\n\nI got to the solution for this case by trying out. But with the result in my hand, I still don't get the formula to calculate it.\n\nI bet \\$58.35 on X and \\$41.65 on 2\n\n$$ 58.35*3.57-58.53-41.65 \u2248 108$$ and $$ 41.65*5.00-41.65-58.53 \u2248 108$$\n\nNotice the last subtraction. You have to subtract the stake of the other bet. Because when Portland wins, I win only the 2 bet and lose the stake for the X bet.\n\nshare|cite|improve this question\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nLet's examine the X/2 case. Denote by $Q_X=3.57$ the bookie's quote for X and $Q_2=5.00$ for 2. Denote by $Q=1/(1/Q_X+1/Q_2)=(Q_X Q_2)/(Q_X+Q_2)\\approx 2.0828$ the quote you have calculated for the X/2 bet. You want to split the total bet $B=\\$100$ into two bets $B_X$ (for X) and $B_2$ (for 2) so that $B_X Q_X=BQ=B_2 Q_2$. From the first equation you get $B_X=B(Q/Q_X)$. Similarly from the second equation you get $B_2=B(Q/Q_2)$, or alternatively $B_2=B-B_X$ (as the value of $B_1$ is already known). Let's substitute the values: $$B_X=100(2.0828/3.57)\\approx 58.34\\quad\\text{and}\\quad B_2=100-58.34=41.66.$$ In fact, you can do this more easily without calculating $Q$ at all, since $$B_X=B\\frac{Q}{Q_X}=B\\frac{Q_2}{Q_X+Q_2}.$$\n\nshare|cite|improve this answer\n\nThe defining feature of a double chance bet is that, if either of the events you bet on happens, you win the same amount regardless of which event it was.\n\nTo simulate a double chance bet with single bets, you need to divide the stake so that the same will happen.\n\nSo, let $Q_1$ and $Q_2$ be the quotes offered for the two events. We seek a value $0 \\le \\alpha \\le 1$ such that, if we bet a fraction $\\alpha$ of our total stake on event 1 and the rest on event 2, the payout in either case will be the same, i.e.\n\n$$\\alpha Q_1 = (1 - \\alpha) Q_2.$$\n\nTo solve this, expand the right hand side, collect the $\\alpha$ terms together on one side and divide to get\n\n$$\\alpha = \\frac{Q_2}{Q_1 + Q_2}.$$\n\nThen, to ensure equal payout in either case, you should bet $\\alpha$ times you total stake on event 1, and the rest on event 2.\n\nshare|cite|improve this answer\n\nPlanning on betting that either team wins?\n\n\n$S_1=S_2*\\frac{Q_2}{Q_1}, S_2=S_1*\\frac{Q_1}{Q_2}$\n\n$S_1+S_2=1$ (to find $S_1$ and $S_2$ as percentages)\n\n$S_1+S_1\\frac{Q_1}{Q_2}=1, S_2+S_2\\frac{Q_2}{Q_1}$\n\n$S_1=\\frac1{Q_2/Q_1+1}, S_2=\\frac1{Q_1/Q_2+1}$\n\nFor X/2, S_1 = 58.3% just as above.\n\nshare|cite|improve this answer\nIf you think it isn't a tie with these odds, put 72.2% on 1 and 27.7% on 2 for +38.7% on a win. Remember that you never win a double-chance if $\\frac1{1/Q_1+1/Q_2}<=1$. \u2013\u00a0user474632 Aug 17 '11 at 23:50\n\nYou bet $\\$100$ $Q2 / (Q1 + Q2)$ on X and $\\$100$ $Q1 / (Q1 + Q2)$ on 2. To the nearest cent, these work out at $\\$58.34$ and $\\$41.66$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/518186/eulerian-paths-in-non-traversable-graphs\nText:\nSign up \u00d7\n\nSuppose I have a weighted connected graph which is traversable (each vertex has even degree) and I wish to walk over all edges. Clearly any Eulerian path minimizes the total weight. What can be said about the case of non-traversable (weighted connected) graphs? Can a minimum-weight path still be found in polynomial time?\n\nshare|cite|improve this question\nYou want a path that traverses every edge at least once, I suppose? \u2013\u00a0Henning Makholm Oct 7 '13 at 22:57\n@HenningMakholm: Yes. Sorry, I had typed that but it must have been deleted as I edited the post before submitting. \u2013\u00a0Charles Oct 8 '13 at 3:46\nI would be surprised if it had an efficient solution. It is a variant of the travelling purchaser problem (on the line graph) but with some simplifications (like travel cost zero) and only one product. \u2013\u00a0Leen Droogendijk Oct 8 '13 at 5:58\nThis is the Route inspection problem a.k.a. Chinese Postman Problem. This has a polynomial time algorithm for undirected graphs and polynomial for directed graphs, but it is NP-complete for mixed graphs. \u2013\u00a0N. S. Oct 8 '13 at 17:10\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nYes, this can be done in polynomial time.\n\nWhat we need to is find a minimum-weight set of edges to traverse twice, such that the graph with some edges doubled is traversable. Once we have that, finding an actual Eulerian path is of course easy.\n\nThe edges we need to double will form a set of paths each connecting two odd-degree nodes, such that each odd-degree node is the endpoint of exactly one of the path.\n\nTo find out which odd-degree nodes to connect, temporarily disregard the even-degree nodes and instead consider a graph with one edge between each pair of odd-degree nodes, its weight being the length of the shortest path between those nodes in the original graph.\n\nWhat we need to find is then a minimal perfect matching in the reduced graph, which is known to have a polynomial-time algorithm.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/233666/linear-operator-on-a-vector-space-v-such-that-t2-t-i-0/233673\nText:\nTake the 2-minute tour \u00d7\n\nlet T be a linear operator on a vector space V such that $T^2 -T +I=0$.Then\n\n  1. T is oneone but not onto.\n  2. T is onto but not one one.\n  3. T is invertible.\n  4. no such T exists.\n\ncould any one give me just hint?\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 1 down vote accepted\n\nI was looking at a problem similar to this, and these answers are great but I needed a bit more to make it click. Here is a step by step with the rules used.\n\n$T^2 \u2212 T + I = 0$\n\n$TT = T - I$\n\n$TT = T - TT^{-1}$ , because $I = TT^{-1}$\n\n$TT = IT - TT^{-1}$ , because $IT = T$\n\n$TT = T(I-T^{-1})$ , factor out the T\n\n$T = I - T^{-1}$ , remove T from both sides\n\nIn my case we had to prove $T^{-1} = 2I - T$ given almost the same equation (that 2 being the difference). I know this break down is probably too basic for most, but this what helped me understand how to apply those rules.\n\nI was lead here by this duplicate.\n\nshare|improve this answer\n\n$$ T^2-T+I=0 \\iff T(I-T)=I=(I-T)T, $$ i.e. $T$ is invertible and $T^{-1}=I-T$. In particular $T$ is injective and surjective.\n\nshare|improve this answer\n\nLet $\\mathbb{x}$ be any vector in the nullspace. Then $T\\mathbb{x} = \\mathbb{0}$. Using your equation $T^2 - T + I = 0$, what can you conclude about $\\mathbb{x}$?\n\nAlternatively if you know about minimal polynomials: How does your polynomial split?\n\nshare|improve this answer\n$T^2(x)-T(x)=0$ and so $I(x)=0$ so $x=0$ so $T$ is injective. am I right? \u2013\u00a0 La Belle Noiseuse Nov 9 '12 at 16:38\nI know about minimal polynomial, it has distinct roots over the field $\\mathbb{C}$ \u2013\u00a0 La Belle Noiseuse Nov 9 '12 at 16:40\nYour mapping is injective. It is not necessarily surjective unless $V$ is finite-dimensional. \u2013\u00a0 EuYu Nov 9 '12 at 16:52\nIt is surjective: $T(-Tx + x) = x$ \u2013\u00a0 Robert Israel Nov 9 '12 at 16:54\nOh, well that's that. Thank you for catching my mistake @RobertIsrael \u2013\u00a0 EuYu Nov 9 '12 at 16:54\n\n$T(T-1)= -I$ then $\\det T\\cdot \\det (T-I) = (-1)^n$ which implies $\\det (T) \\neq0 \\,\\,.$ hence $T$ invertible\n\nshare|improve this answer\nIs it true for a vector space with not a finit dimension ? \u2013\u00a0 Ricky Bobby Nov 9 '12 at 16:40\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/275856/the-roots-in-a-finite-field?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbb F$ be a finite field of order $q=p^k$, where $p$ is an odd prime number. For an element $a\\in\\mathbb F$ how can we count the m-th roots of $a$? That is, the number of solutions of the equation $$x^m=a$$\n\nSuppose that $a\\neq 0$.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nThe multiplicative group of $\\mathbb F$ is cyclic of order $q-1$, and as already pointed out by DonAntonio, all solutions of $x^m=a$ can be obtained from any fixed solution by multiplying it by all $m$th roots of unity in $\\mathbb F$. This implies:\n\n  \u2022 If there is at least one solution, the total number of solutions is the number of $m$th roots of unity in $\\mathbb F$, which is $$\\gcd(m,q-1).$$\n  \u2022 In order to determine whether the equation has a solution, let $r$ be the multiplicative order of $a$ (i.e., the least $r$ such that $a^r=1$). Then $x^m=a$ is solvable iff $$\\gcd(m,q-1)\\mid\\frac{q-1}r.$$\nshare|improve this answer\nThe criterion for solvability can be written more consisely as $a^{(q-1)/\\gcd(m,q-1)}=1$. \u2013\u00a0 Emil Je\u0159\u00e1bek Jan 14 '13 at 16:40\n\nAs in any other field, if $\\,\\alpha\\,$ is a root, i.e. $\\,\\alpha^m=a\\,$ ,then all the roots are $\\,\\alpha\\, w^k\\,,\\,k=0,1,...,m-1\\,$ , where $\\,w\\,$ is a primitive $\\,m-$th root of unity: $\\,w^m=1\\,\\,\\,,\\,\\,w^t\\neq 1\\,\\,,\\,\\forall\\,0\\leq t<m\\,$ .\n\nI don't think something in general can be said: it'll depend on $\\,a\\,\\,,\\,\\operatorname{char}\\Bbb F$\\, and on $\\,m\\,$ , though it can be divided in cases.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/135540/question-concerning-a-possible-constant-sum-of-squares-in-a-circle\nText:\nTake the 2-minute tour \u00d7\n\nAssume a circle, of some radius $r$ say $r=1$. Consider a fixed $n$, say $n=30$, of points on the circumference of the circle. That $n$ points $(x_k,y_k)_{k=1,\\ldots, n}$ define a mean in the interior of the circle, call this point m $(x_m,y_m) $. Now we compute the \"circular variance\" , just the mean-of-squares of the distances $$ \\mathrm{msq}=\\frac1n\\sum_{k=1}^n ((x_k-x_m)^2+(y_k-y_m)^2) $$\nNow we assume another set of $n$ points $(x'_k,y'_k)_{k=1,\\ldots, n}$, which are selected such that they have the same mean. Is the circular variance the same $\\mathrm{msq}'=\\mathrm{msq} $ ?\nI've seen, that the two extreme situations where the $n$ points are accumulated at the green positions in the graph and where they are accumulated at the magenta positions in the graph( (where the fat red point indicates the mean)) graph, the msq-values are identical. I could try to program a routine to test the question approximately by brute force, but perhaps there is an analytic argument?\n\n[update]: Michael Hardy's anwer solves this neatly. I find it a very nice observation, that that \"circular variance\" depends only on the mean of the points and is thus constant for all resulting means which lie on the same circle inside the original circle.\nSo with the mean laying on the inner circle with radius $\\small r_m$ we get $$\\small \\operatorname{msq}=1-r_m^2$$ Possibly worth an entry in the wikipedia? (in some \"special points/geometric relations of a circle\" - section , don't know the actual name for the existing collection) Btw, does this allow also a generalization to a continuous formulation instead of \"n discrete points\", say via integrals?\n\nshare|improve this question\nRegarding your edit, this might run afoul of Wikipedia's \"no original research\" policy, unless you can find a reference to it in a textbook somewhere... \u2013\u00a0 Rahul Apr 23 '12 at 5:59\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nLetting $\\bar x$, $\\bar y$ be the average $x$- and $y$-coordinates, this \"variance\" is $$ \\sum_{k=1}^n ((x_k-\\bar x)^2+(y_k-\\bar y)^2)= \\left(\\sum_k (x_k^2+y_k^2)\\right) - 2n(\\bar x^2 + \\bar y^2) + n(\\bar x^2 + \\bar y^2)$$ $$ = n - n(\\bar x^2 + \\bar y^2), $$ and this clearly depends on the $x$s and $y$s only through the averages.\n\nLater edit: The usual 2-dimensional counterpart of the variance is the nonnegative-definite matrix $$ \\mathbb{E}\\sum_{k=1}^n \\begin{bmatrix} x_k^2 & x_k y_k \\\\ x_k y_k & y_k^2 \\end{bmatrix}. $$ The \"variance\" in this question is the trace of that matrix. In many applications, it makes no sense to speak of this matrix as having a trace at all, because, for example, $x_i$ may be measure in dollars and $y_i$ in centimeters, and it is not at all unusual for that sort of thing to happen. What if one changes the units in which $y_i$ is measured from centimeters to meters? However, since in this problem we have the constraint $x_k^2+y_k^2=1$, that problem doesn't seem to arise.\n\nNow notice that although the trace of this matrix depends on the $(x,y)$s only through their average, nonetheless the off-diagonal entries of the matrix depend on more than that; they depend on the correlation.\n\nStill later edit: Suppose $F$ is a probability distribution supported on the circle of unit radius centered at $(0,0)$, and $X$ is a random variable with that distribution. Then we have $$\\mathbb{E}(X)=\\mu=\\text{some point in the disk}.$$ Then $$ \\mathbb{E}(\\|X-\\mu\\|^2) = \\mathbb{E}(\\|X\\|^2) - 2\\mu\\cdot \\mathbb{E}(X) + \\|\\mu\\|^2 = 1-2\\|\\mu\\|^2+\\|\\mu\\|^2 = 1 - \\|\\mu\\|^2.\\tag{1} $$ A theorem of elementary geometry that I remember learning in school when I was about 16 says that for two chords $AB$ and $CD$ of a circle intersecting at $P$, the products of lengths $AP\\cdot PB$ and $CP\\cdot PD$ are equal. That is seen to be simply a special case of (1), when we remember that the variance of a probability distribution supported on a set of two points is just the product of the distances from those two points to their suitably weighted mean.\n\nSo we have a novel proof, and a generalization, of that theorem of elementary geometry.\n\nshare|improve this answer\nVery nice idea; the reformulation using the sum in the parentheses which are then all units is really amazing! \u2013\u00a0 Gottfried Helms Apr 22 '12 at 23:20\nHmm, isn't there an error in the formula? I think the mean-coordinates should occur only in their squares. I think we should have $ n- n(\\bar x^2 + \\bar y^2)$ , correct? \u2013\u00a0 Gottfried Helms Apr 22 '12 at 23:28\nFixed.${{{{{{}}}}}}$ \u2013\u00a0 Michael Hardy Apr 22 '12 at 23:33\nThat's again a nice refinement of the answer. Well, I needed this only for a question which resulted (and is a detail for the possible answer) from math.stackexchange.com/questions/132775 (see my partial answer), so I deal with numbers from the complex plane only. Then the question concerns a \"correlation\" with another set of points, but which also are allowed to be on the interior. But I've not yet formulated the problem precise enough for the final attack... \u2013\u00a0 Gottfried Helms Apr 23 '12 at 5:40\nJust for a nitpick... the use of the term \"variance\" should imply the averaging, which means the division by the number n of points in the first formula. \u2013\u00a0 Gottfried Helms Apr 23 '12 at 15:14\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/447098/why-peirces-law-implies-law-of-excluded-middle?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nWhy if in a formal system the Peirce's law $((P\\rightarrow Q)\\rightarrow P) \\rightarrow P$ is true, the law of excluded middle $P \\lor \\neg P$ is true too?\n\nshare|improve this question\nYou can prove this by using uniform substitution, modus ponens, and the law of simplification, given that Peirce's law and the law of the excluded middle are axioms. \u2013\u00a0 Doug Spoonwood Jul 19 '13 at 12:59\nlaw of the excluded middle is not an axiom, I want to prove that if the Peirce's law is true implies that the law of excluded middle is true \u2013\u00a0 Robbo Jul 19 '13 at 13:10\nYou need to know what system you're talking about before you can answer your question, before you can prove that Peirce's law implies the law of excluded middle. In the implicational calculus, Peirce's law holds, but (P\u2228\u00acP) does not, because there does not exist any \u00ac connective, nor any \u2228 connective. In classical logic and some non-classical logics you can prove (P\u2228\u00acP) without it coming as an axiom, also prove (((P\u2192Q)\u2192P)\u2192P) and then use ((P\u2192Q)\u2192P)\u2192P to prove (P\u2228\u00acP) again (within the system). \u2013\u00a0 Doug Spoonwood Jul 19 '13 at 19:49\nWhat formal system do you have in mind? From my understanding of definitions of a formal system, you can consider Peirce's law under just modus ponens, and uniform substitution as a formal system. It still has a potential infinity of theorems (all less general than Peirce's law). You certainly can't derive the law of the excluded middle in that system. See the end of my answer. \u2013\u00a0 Doug Spoonwood Jul 20 '13 at 0:22\n\n3 Answers 3\n\nThis is probably what you're looking for: Peirce's Law Equivalent to Law of Excluded Middle. Note, however, that this proof depends on a few assumptions which are not embodied in every logic. For instance, in relevance logic, the move from $\\neg p$ to $p \\rightarrow q$ is invalid, since $p$ may not be relevant to $q$.\n\nshare|improve this answer\nIn line 3 it assumes that the negation of excluded middle is false, is not this equivalent to assuming that the excluded middle is true? \u2013\u00a0 Robbo Jul 19 '13 at 11:51\nGood point. You're right that that line seems to assume what's trying to be proven, but (if you click on the link to that \"rule\") you'll notice that they derive it by deriving that $\\neg(p \\vee \\neg p)$ implies $\\neg p \\wedge \\neg \\neg p$, using one of De Morgan's Laws. And it turns out that this particular De Morgan law is valid for most standard logics with negation, though indeed it is still an implicit assumption in the proof. \u2013\u00a0 Alex Kocurek Jul 19 '13 at 16:53\n\n\nPeirce's law is of the form $$\\big((A \\to B) \\to A\\big) \\quad \\to \\quad A,$$ that is, given $(A \\to B) \\to A$ we could deduce $A$. Therefore, we will try to construct $$((P \\lor \\neg P) \\to \\bot) \\to (P \\lor \\neg P).$$ The trick is that for any $A \\to B$ we can strengthen $A$ or relax $B$, for example:\n\n\\begin{align} P\\lor \\neg P &\\to \\bot &\\text{implies}&& P &\\to \\bot,\\\\ P &\\to P &\\text{implies}&& P &\\to P \\lor \\neg P. \\end{align} So we could start with a tautology (I assume that negation is just a shorthand for $\\to \\bot$) \\begin{align} \\neg P &\\to \\neg P \\\\ (P \\to \\bot) &\\to \\neg P \\end{align} strengthen left side $$(P \\lor \\neg P \\to \\bot) \\to \\neg P$$ and relax right side $$(P \\lor \\neg P \\to \\bot) \\to P \\lor \\neg P.$$\n\nNow we apply Peirce's law, and we are done ;-)\n\nThings used:\n\n  \u2022 negation $\\neg P$ is a shorthand for $P \\to \\bot$,\n  \u2022 identity: $\\dfrac{\\quad}{\\Gamma, A \\vdash A}[\\alpha]$\n  \u2022 application: $\\dfrac{\\Gamma \\vdash A, A \\to B}{\\Gamma \\vdash B}[\\beta]$\n  \u2022 finite composition $\\dfrac{\\Gamma \\vdash A_1 \\to A_2, A_2 \\to A_3, \\ldots, A_{n-1} \\to A_n}{ \\Gamma \\vdash A_1 \\to A_n}[\\gamma]$,\n  \u2022 disjunction introduction: $\\dfrac{}{\\Gamma, A \\vdash A \\lor B}[\\delta]$,\n  \u2022 implication: $\\dfrac{\\Gamma, A \\vdash B}{\\Gamma \\vdash A \\to B}[\\iota]$,\n  \u2022 Peirce's law $\\dfrac{}{\\Gamma \\vdash ((A\\to B) \\to A) \\to A}[\\pi]$.\n\nThe proof:\n\nThe premise\n\n$$ \\dfrac{ \\dfrac{ \\dfrac{ \\frac{}{P \\to P \\lor \\neg P}{[\\delta,\\iota]}, \\quad \\frac{}{P \\lor \\neg P \\to \\bot \\vdash P \\lor \\neg P \\to \\bot}[\\alpha] }{P\\lor\\neg P \\to \\bot \\vdash P \\to \\bot}[\\gamma] }{(P\\lor\\neg P\\to \\bot) \\to \\neg P}[\\iota], \\quad \\dfrac{\\quad}{\\neg P \\to P \\lor \\neg P}[\\delta, \\iota] }{(P \\lor \\neg P \\to \\bot) \\to P \\lor \\neg P}[\\gamma] $$\n\nand final derivation\n\n$$ \\dfrac{ \\dfrac{\\text{from above} }{(P \\lor \\neg P \\to \\bot) \\to P \\lor \\neg P}, \\ \\dfrac{}{((P \\lor \\neg P \\to \\bot) \\to P \\lor \\neg P) \\to P \\lor \\neg P}[\\pi] }{P \\lor \\neg P}[\\beta] $$\n\nThere are various shortcuts, and implicit assumptions, most notably negation $\\neg P$ is a shorthand for $P \\to \\bot$, be careful! Nevertheless, I hope it still helps $\\ddot\\smile$\n\nshare|improve this answer\nI think you've confused a rule of inference with a logical theorem. You've also assumed that \"\u2228\" (as well as \u00ac) comes as a meaningful connective in a system. In some logical systems, it just abbreviates other formulas. \u2013\u00a0 Doug Spoonwood Jul 19 '13 at 12:53\n@DougSpoonwood Indeed, I mixed rules and theorems (the proof would be painful otherwise), and I do assume nontrivial things about $\\neg$ and $\\lor$. In various systems this proof would look different, I picked intuitionistic logic (with $\\lor$) and that's it. In fact this proof is a rewritten $\\lambda$-term: $$\\mathrm{with\\_return}\\ (\\lambda k.\\ \\mathrm{Right}\\ \\lambda p.\\ k\\ (\\mathrm{Left}\\ p)),$$ where $\\mathrm{with\\_return}$ has the Peirce's law type and Left/Right are constructors of sum type (there are the $\\lor$-related assumptions). \u2013\u00a0 dtldarek Jul 19 '13 at 13:13\nIgnoring the problem that this answer assumes a lot more than we know that the question asker allows, the original question states Peirce's law. This answer applies Peirce's rule of inference. It is not at all difficult to start with Perice's law and derive Peirce's rule of inference. Why did this not get done? \u2013\u00a0 Doug Spoonwood Aug 5 '13 at 23:08\n@DougSpoonwood Because the answer was already lengthy, and I didn't want to complicate it anymore. \u2013\u00a0 dtldarek Aug 6 '13 at 7:10\n@DougSpoonwood Edited, I hope it's more to you liking now. \u2013\u00a0 dtldarek Aug 6 '13 at 7:36\n\nWhy? Because you can prove it. A formal system has no (or minimal) reference to meaning, and consequently any logical theorem holds, because you can prove it given the axiom set and the rules of inference of the system. I'll outline a formal system where you can prove the law of the excluded middle ApNp and Peirce's law CCCpqpp. First formation rules:\n\n  1. All lower case letters of the Latin alphabet qualify as formulas.\n  2. If $\\alpha$ qualifies as a formula, so dose N$\\alpha$\n  3. If $\\alpha$ and $\\beta$ qualify as a formulas, so does C$\\alpha$$\\beta$, and A$\\alpha$$\\beta$.\n  4. The above rules come as sufficient for what follows.\n\nThe system (and almost all of the proofs below can get credited to the work of Jan Lukasiewicz and the publishers and translators of Lukasiewicz's Elements of Mathematical Logic) has three axioms:\n\n1 CCpqCCqrCpr (hypothetical syllogism)\n\n2 CCNppp\n\n3 CpCNpq\n\nIn words you can translate the first axiom as saying \"if the first (proposition) implies the second, if the second implies the third, then the first implies the third\". The second axiom can get translated into English as saying \"if the negation of the first implies the first, then the first.\" The third axiom can get translated as saying \"if the first, then, if not the first, then the second.\" The system has one definition\n\n4' Apq:=CNpq\n\nIt has three inference rules\n\nS: For any lower case letter $\\lambda$ within any axiom we may uniformly substitute it with any other formula, provided that such substitution happens for all lower case letters equiform with $\\lambda$ in that formula. For instance, were it the case that CpCqp came as an axiom of our system, we could substitute p with Cpp in CpCqp (substitutions will get abbreviated by the notation p/Cpp hereafter) and obtain C Cpp Cq Cpp, but not C Cpp C qp. We can also apply such uniform substitution to any theorem we have derived already.\n\nR: For any formula where Xpq, or some substitution instance of Xpq, we may replace Xpq with Yrs, where we have a definition such that we have definition Yrs:=Xpq, where the variables of Yrs contain only equiform variables with Xpq. Such replacement does not have to happen uniformly for the formula. It can happen only in one place within a formula. In particular here this means that if we have some theorem like CCNpqCqCNpq, we may replace either instance of CNpq in CCNpqCqCNpq with Apq, to yield CApqCqCNpq.\n\nD: If we have a theorem C$\\alpha$$\\beta$ and $\\alpha$ qualifies as a theorem also, we may detach $\\beta$ as a theorem also.\n\nSo, first we'll prove the law of the excluded middle, in symbols ApNp. The notation \"1, p/q\" indicates that we will uniformly substitute formula p in the formula reference by the numeral 1 with q. The \"=\" sign gets used to indicated that the formula on the left of the \"=\" sign comes as equiform with the formula on the right side of the \"=\" sign. The notation C1-2 indicates that formula 1 comes as the antecedent or first formula which the C on the leftmost of the formula connects, 2 comes as the consequently or second formula which the C on the leftmost of the formula connects, and the \"-\" indicates that we will detach formula 2 as a theorem. The notation 3 R = 4 indicates that we will replace formula 3, which comes as a substitution instance of CNpq, with the formula Apq (p and q remain equiform throught CNpq and Apq) and obtain theorem 4.\n\n1 CCpqCCqrCpr axiom\n\n2 CCNppp axiom\n\n3 CpCNpq axiom\n\n 1 q/CNpq = 4\n\n4 C CpCNpq CCCNpqrCpr\n\n 4 = C 3 - 5\n\n5 CCCNpqrCpr\n\n 5 q/p, r/p = 6\n\n6 C CCNppp Cpp\n\n 6 = C 3 - 7\n\n7 Cpp\n\n 7 p/Np = 8\n\n8 CNpNp\n\n 8 R = 9\n\n9 ApNp\n\nNext we'll prove prove CqCpq so that we can prove any two theorems from another theorem within this system.\n\n  1 p/Cpq, q/CCqrCpr, r/s = 10\n\n10 C CCpqCCqrCpr CCCCqrCprsCCpqs\n\n  10 = C 1 - 11\n\n11 CCCCqrCprsCCpqs\n\n  11 q/Cqr, r/Csr, s/CCsqCpCsr = 12\n\n12 C CCCCqrCsrCpCsrCCsqCpCsr CCpCqrCCsqCpCsr\n\n  11 p/s, s/CpCsr = 13\n\n13 CCCCqrCsrCpCsrCCsqCpCsr\n\n  12 = C 13 - 14\n\n14 CCpCqrCCsqCpCsr\n\n  11 s/CCCprsCCqrs = 15    \n\n15 C CCCqrCprCCCprsCCqrs CCpqCCCprsCCqrs\n\n  1 p/Cqr, q/Cpr, r/s = 16\n\n16 CCCqrCprCCCprsCCqrs\n\n  15 = C 16 - 17\n\n17 CCpqCCCprsCCqrs\n\n  14 p/Cpq, q/CCprs, r/CCqrs, s/t = 18\n\n18 C CCpqCCCprsCCqrs CCtCCprsCCpqCtCCqrs\n\n  18 = C17 - 19\n\n19 CCtCCprsCCpqCtCCqrs\n\n  5 r/CCCNpppCCqpp = 20\n\n20 C CCNpqCCCNpppCCqpp CpCCCNpppCCqpp\n\n  17 p/Np, r/p, s/p = 21\n\n21 CCNpqCCCNpppCCqpp\n\n  20 = C 21 - 22\n\n22 CpCCCNpppCCqpp\n\n  22 p/CCNppp = 23\n\n\n  23 = C 2 -24\n\n24 C CCNCCNpppCCNpppCCNppp CCqCCNpppCCNppp\n\n  2 p/CCNppp = 25\n\n25 CCNCCNpppCCNpppCCNppp\n\n  24 = C 25 - 26\n\n26 CCqCCNpppCCNppp\n\n  5 p/t, q/CCNppp, r/CCNppp = 27\n\n27 C CCNtCCNpppCCNppp CtCCNppp\n\n  26 q/Nt = 28\n\n28 CCNtCCNpppCCNppp\n\n  27 = C 28 - 29\n\n29 CtCCNppp\n\n  19 p/Np, r/p, s/p = 30 \n\n30 C CtCCNppp CCNpqCtCCqpp\n\n  30 = C 29 - 31\n\n31 CCNpqCtCCqpp\n\n  1 p/CNpq, q/CtCCqpp = 32\n\n32 C CCNpqCtCCqpp CCCtCCqpprCCNpqr\n\n  32 = C 31 - 33\n\n33 CCCtCCqpprCCNpqr\n\n  33 t/NCCqpp, r/CCqpp = 34\n\n34 C CCNCCqppCCqppCCqpp CCNpqCCqpp\n\n  2 p/CCNqpp = 35\n\n35 CCNCCNqppCCNqppCCNqpp\n\n  35 = C 34 - 36\n\n36 CCNpqCCqpp\n\n  5 r/CCqpp = 37\n\n37 C CCNpqCCqpp CpCCqpp\n\n  37 = C 36 - 38\n\n38 CpCCqpp\n\n  38 p/q, q/Np = 39\n\n39 CqCCNpqq\n\n  14 p/q, q/CNpq, r/q, s/p = 40\n\n40 C CqCCNpqq CCpCNpqCqCpq\n\n  40 = C 39 - 41\n\n41 C CpCNpq CqCpq\n\n  41 = C 3 - 42\n\n42 CqCpq\n\nIn words theorem 42 can get translated as \"The first proposition implies that the second proposition implies the first proposition.\" Or equivalently, \"The first proposition implies that if the second proposition, then the first proposition.\" On the strength of that you can show any proposition on the basis of any other proposition within this system (you might want to note exactly what the rule of substitution S says and what it does not say). Now we'll prove Peirce's law CCCpqpp.\n\n  1 p/q, q/Cpq = 43\n\n43 C CqCpq CCCpqrCqr\n\n  43 = C 42 - 44 \n\n44 CCCpqrCqr\n\n  44 p/Nq, q/p, r/CCpqq = 45\n\n45 C CCNqpCCpqq CpCCpqq\n\n  36 p/q, q/p = 46\n\n46 CCNqpCCpqq\n\n  45 = C 45 - 47\n\n47 CpCCpqq\n\n  14 p/q, q/Cqr, s/p = 48\n\n48 C CqCCqrr CCpCqrCqCpr\n\n  47 p/q, q/r = 49\n\n49 CqCCqrr\n\n  48 = C 49 - 50\n\n50 CCpCqrCqCpr\n\n  1 p/CpCqr, q/CqCpr, r/s = 51\n\n51 C CCpCqrCqCpr CCCqCprsCCpCqrs\n\n  51 = C 50 - 52\n\n52 CCCqCprsCCpCqrs\n\n  52 q/Np, r/q, s/CCCpqpp = 53\n\n53 C CCNpCpqCCCpqpp CCpCNpqCCCpqpp\n\n  36 q/Cpq = 54 \n\n54 CCNpCpqCCCpqpp\n\n  53 = C 54 - 55\n\n55 CCpCNpqCCCpqpp\n\n  55 = C 3 - 56\n\n56 CCCpqpp\n\nSo, now we'll prove the law of the excluded middle ApNp from Peirce's law CCCpqpp in this system.\n\n  42 q/ApNp, p/CCCpqpp\n\n57 C ApNp CCCCpqppApNp\n\n  57 = C 9 - 58\n\n58 CCCCpqppApNp\n\n  58 = C 56 - 59\n\n59 ApNp\n\nBut, even here, there exists a catch...\n\nWhat what if we only had Perice's law with the rules of inference S, D, and R above? Could we prove the law of the excluded middle? Prover9 gave me the following matrix (with condensed detachment as a rule of inference, but that won't end up mattering here):\n\n A|  0  1|C| 0 1|N \n 0*| 1  0|0| 0 1|0\n 1|| 0  0|1| 0 0|0\n\nI've starred 0 to indicate it as the designated element here. If you write out the truth tables for CCCpqpp and ApNp here, you can see that CCCpqpp always evaluates to the designated element 0. However, when p=0, ApNp=A0N0=A00=1. Also, and it does come as important to check this also, if Cpq=0, and p=0, then q=0, so rule D comes as valid for this system. Rules R and D hold for this system, since the matrix above implies A, C, and N as truth-functional. Thus, from Peirce's law \"alone\" (the rules mentioned above preferably will get understood as implicit in this statement), you simply cannot derive the law of the excluded middle.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/242087/eigen-value-minimization-proof\nText:\nTake the 2-minute tour \u00d7\n\nThe two minimization problems below are equivalent:\n\n$\\min\\{\\mathrm{trace}(AX^TBX): XX^T=I_n\\}=\\min\\{\\mathrm{trace}(AQ^T\\tilde{B}Q): QQ^T=I_m\\}$, where $A,\\tilde{B}$ and $Q$ are square matrices of the same size, $A,B$ are also p.s.d and $X$ is a $m \\times n, (m >n) $ rectangular matrix.\n\nThe solution to this latter minimization problem is well known: the extrema of the trace are the extrema of $\\{\\sum_{i=1}^m\\lambda_i(A)\\lambda_{\\sigma(i)}(\\tilde{B}): \\sigma\\in S_m\\}$, where $\\lambda_i(M)$ denotes the $i$-th eigenvalue of a real symmetric matrix $M$ and $S_m$ is the symmetric group of order $m$.\n\nSuppose $A$ and $\\tilde{B}$ are orthogonally diagonalized as $A=U\\Lambda U^T$ and $\\tilde{B}=V\\Sigma V^T$, where $\\Lambda = \\mathrm{diag}(\\lambda_1(A), \\lambda_2(A), \\ldots, \\lambda_m(A))$ contains the eigenvalues of $A$ arranged in ascending order and $\\Sigma$ is analogously defined, but the eigenvalues are arranged in descending order. That is, if $\\lambda_1(B),\\ldots,\\lambda_n(B)$ are arranged in ascending order, and for $\\Sigma=\\mathrm{diag}\\left(\\lambda_n(B),\\ldots,\\lambda_1(B),0,\\ldots,0\\right)$\n\nThen am looking for a 'detailed proof' that the minima is reached at an $X^*$ given by:\n\n\\begin{align} X^* &= VU^T \\begin{bmatrix}I_n\\\\ 0_{(m-n)\\times n}\\end{bmatrix}. \\end{align}\n\nfor my better understanding.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nIt is a bit easy to show for the square case. For the rectangular case, it becomes cumbersome due to heavy notational stuff. You need to have the following inequality for the positive (semi) definite matrices\n\n\\begin{align}trace(AB)\\geq\\sum_{i=1}^{N}\\alpha_i \\beta_{N-i+1}\\end{align}\n\nwhere $\\alpha_ 1\\geq\\alpha_ 2...\\geq\\alpha_ N$ are the eigenvalues of $A$ and $\\beta_ 1\\geq\\beta_ 2...\\geq\\beta_ N$ are eigenvalues of $B$. The lower bound is achieved when $A$ and $B$ commute and the corresponding eigenvalues are in order (ie ascending for $A$ and descending for $B$).\n\nNow $X$ is orthogonal, Define $\\hat{B}=X^{H}BX$. Note that $B$ and $\\hat{B}$ will have same eigenvalues. This implies $trace(A\\hat{B})\\geq \\sum_{i=1}^{N}\\alpha_i \\beta_{N-i+1}$. Thus it is enough to design $X$ such that we can attain the (universal) lower bound for every $X$. This is possible only if $X=VU^{H}P$. Here $U$ and $V$ comes from eigen decomposition of $A$ and $B$. $P$ is a suitable permutation (which is orthogonal) matrix which rearranges the eigenvalues. Since you have already assumed the required order, it should be identity.\n\nshare|improve this answer\nalso- any views on if the objective function considered in this question is Convex-as in is this solution a point where a global minima is reached? \u2013\u00a0 qlinck Nov 21 '12 at 18:25\nNote that $trace(AX^{T}BX)=vec(X)^{T}(A\\otimes B)vec(X)$. Since $A$ and $B$ are positive (semi)definite, this implies the objective function is a convex quadratic. But note that this doesn't imply the optimization is itself convex as the orthogonality constraint is not convex. But in this case, due to the constraint, whatever $X$ you come up with (which obeys the constraint), the inequality always holds. For any other $X$ (which obeys the constraint), you can't reduce the objective value than the lower bound. Hence, it should be the solution \u2013\u00a0 dineshdileep Nov 22 '12 at 3:01\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/255885/constructing-idempotent-generator-of-idempotent-ideal/258657\nText:\nTake the 2-minute tour \u00d7\n\nExercise 2.1 in Matsumura's Commutative Ring Theory reads as follows: \"Let $A$ be a commutative ring and $I$ an ideal that is finitely generated and $I=I^2$. Then $I$ is generated by an idempotent.\"\n\nIn trying to solve it, i first followed a constructive approach, where e.g. for the case of two generators i tried to construct an idempotent generator. However, it seemed difficult. Then i realized that i could apply Nakayama's lemma to the $A$-module $I$ and the existence of the idempotent generator follows.\n\nMy question is: How could one go about finding this idempotent generator? Is there a systematic way?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nOne can reconstruct a method by considering the usual proof of Nakayama's lemma.\n\nSuppose you know that the ideal is generated by $n$ elements, $(x_1, ..., x_n)$. By assumption, we may write $x_i = \\sum a_{ij} x_j$, where the $a_{ij} \\in I$. The element we're looking for is $p(1) -1$, where $p$ is the characteristic polynomial of the matrix $(a_{ij})$.\n\nTo see this, consult the proof of NAK in, say, Matsumura or Atiyah-Macdonald.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56476.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nEllipse Geometry\n\nDate: 08/09/98 at 03:03:00\nFrom: Simon Crosbie\nSubject: Ellipse geometry\n\nan ellipse and bisecting the perimeter of the ellipse at right angles \nto the tangent at that point. How do I determine the distance along \nthe long axis of an ellipse that this line must start from? \n\nI am a joiner who specializes in constructing special-shaped plantation \nshutters. A formula showing this relation would help me work out the \nprecise timbers required to construct an ellipse. I have already worked \nout a formula which I use to draw an ellipse of a given width and \nheight using two centers and a piece of string. The distance between \nthe two centers is found with the expression:\n\n   Center spacing = 2*Sqrt((Height/2)*(Height/2)*(Width/2))\n   Length of string = Height + Center spacing\n\nwhere Height is the length of the long axis of the ellipse and Width \nis the length of the short axis.\n\nDate: 08/09/98 at 09:16:33\nFrom: Doctor Jerry\nSubject: Re: Ellipse geometry\n\nHi Simon,\n\nLet's see if I understand your problem. You have an ellipse:\n\n\nThe numbers 2a and 2b are the lengths of the major and minor axes. The \nfoci of the ellipse are at (-c,0) and (c,0), where c = sqrt(a^2-b^2). \nThe length of the string is 2a.\n\nI think 2a is what you have called width and 2b is what you have called \nheight. I don't understand your formula for center spacing. I'd say \nthat the center spacing (the distance between centers) is: \n\n   2c = 2*sqrt(a^2-b^2)\n\nI'll use what I understand, as outlined in my first paragraph. You are \nseeking a point (X,0), where -a < X < a, on the major axis, from which \na line at a specified angle d (I'll assume 0 < d < 90) will intercept \nthe ellipse at right angles to the tangent.\n\nThere is a well-known formula for the equation of the tangent line to \nthe ellipse at any point (x0,y0) of the ellipse. It is:\n\n   a^2*y0*y + b^2*x*x0 = a^2*b^2\n\nAssuming (x0,y0) is in the first quadrant, the slope of this line is\n-b^2*x0/(a^2*y0). The slope of the line K perpendicular to this line is \nthe negative reciprocal of this, namely, a^2*y0/(b^2*x0). This is the \ntangent of the angle d.\n\nThe equation of K is y-y0 = a^2*y0/(b^2*x0)(x-x0). Its x-intercept, \nwhich you want, is (set y=0):\n\n   X = x0(1-b^2/a^2) = x0(a^2-b^2)/a^2 = x0*c^2/a^2\n\nSince tan(d) = a^2*y0/(b^2*x0) and x0^2/a^2+y0^2/b^2 = 1, we can \neliminate y0:\n\n   1/x0^2 = (b^2/a^4)tan^2(d) + 1/a^2  \n\nWe now know x0 in terms of d. Put this into the equation for X and \nyou're done.\n\nPlease check this out. Write back if I've made mistakes or been \n\n- Doctor Jerry, The Math Forum\nAssociated Topics:\nHigh School Conic Sections/Circles\nHigh School Coordinate Plane Geometry\nHigh School Geometry\nHigh School Practical Geometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56132.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPossible Combinations on a Push Lock\n\nDate: 4/17/96 at 15:53:5\nFrom: Anonymous\nSubject: lock problem\n\nThe digits available are 1 thru 5.  Furthermore, in each \ncombination a digit can occur only once.  You need at least two \npushes to open the lock. How many different combinations are \n\nThis is as far as I got......\n\n\t5! = 120 combinations\n\nThis seem to be the right answer but I feel that there is more to \nit. I am not sure I understand the problem fully.  Any help to the \nsolution of this problem would be most appreciated.\n\nDate: 4/18/96 at 20:2:40\nFrom: Doctor Ken\nSubject: Re: lock problem\n\nHey there -\n\nIf I understand this problem correctly, you can't use any number \ntwice in a combination, even if they are in different pushes.  So \nthe following would be okay:\n\n4, then \n5 and 2, \nthen 3 and 1.  \n\nBut this wouldn't:\n\n4, then\n5 and 4, then\n3 and 4, because you re-use 4.\n\nNotice that this limits us to at most 5 pushes, because after that \nyou're going to have to start repeating.  Anyway, let's get some \nnotation: if a push consists of 5 and 4, for example, let's write \nthat as (5,4).  And let's use the + sign to seperate consecutive \npushes, so that the first combination we had would be written as \n(4) + (5,2) + (3,1).\n\nAnyway, I think this is a harder problem than one that will be \nable to be solved with just one case: we're going to have to break \nit down.\n\nSo let's break it down according to how many digits we use in each \ncombination.  We know we need to use at least 2, because we need \nto have at least 2 pushes.  So how many different combinations can \nwe have that use exactly 2 digits?  Well, we'll have 5 choices for \nthe first one and 4 choices for the second (order does matter in \nthis case).  So that's 20 ways of choosing our digits.  Then how \nmany different combinations can we get with these 2 digits?  It \nseems pretty obvious, in this case, that all we can do is push one \nbutton, then the other (i.e. we can't push 2 at the same time).  \nSo we'll just get 20 different combinations that use 2 digits.\n\nNow let's look at 3 digits, which is a little more interesting.  \nHow many ways can we choose which 3 digits to use?  Well, again, \nit's 5*4*3 = 60.  \n\nBut now we have several choices for whether these buttons are \npushed one at a time, or together with others.  For instance, if \nwe chose the digits 1, 2, and 3, in that order, we could have \n(1) + (2) + (3), or we could have (1,2) + (3), or (1) + (2,3).  \nIt looks like these are the only possible combinations that use \nonly 1, 2, and 3 in that order.  So since every selection of 3 \ndigits will have these 3 different combination orders, there will \nbe a total of 60 * 3 = 180 combinations that use 3 digits.\n\nCan you do the cases where we use 4, and then 5 digits yourself?  \nThey get tougher the more digits you have, but try to get it \nyourself before you write back for more help.  This is a neat \nproblem, and it will be worth it if you solve it yourself.\n\n-Doctor Ken,  The Math Forum\n\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/121682/does-negative-semidefinite-intersection-matrix-of-bunch-of-curves-implies-zero-in/121696\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIf we have the result as the title, then I can solve my real question. The original question was stated as follows.\n\nIn a paper I found the following lemma\uff1a\n\nLet $S$ be a nonsingular projective surface, $R\\in PicS$ a divisor with $R^2>0$ . Let\n\n$(E_{i})$ be the family of distinct curves such that $R\\cdot E_{i}=0$.\n\nThen the $E_{i}$ are numerically independent.\n\nThe proof just says that the result follows from Hodge Index Theorem. But I cant see how. HIT just assert that the intersection matrix $(E_i.E_j)$ is negative semidefinite. Why $E_i$ can't be numerically dependent?\n\nAny hint is welcome. Thanks a lot.\n\nshare|cite|improve this question\nup vote 6 down vote accepted\n\nThe answer already given here seems to assume the E_i are pairwise disjoint, which I didn't take to be the case from your question.\n\nTo get the result in general, I think you need to use the additional fact that an effective divisor can never be numerically trivial (since it will have positive intersection with an ample divisor.) Then take a hypothetical numerical relation among the E_i. By the above, it must have both positive and negative coefficients. Group them to get a relation like\n\n$\\sum a_i E_i = \\sum b_j E_j $ (modulo numerical equivalence)\n\nwith the a's and b's positive and all of the E_i and E_j distinct from each other. If you call the left and right hand sides of this equation A and B, then you have that $A^2<0$ since it's a nonzero element and the intersection pairing is negative definite, but $A \\cdot B \\geq 0$ since all the curves intersect properly. This contradicts $A\\equiv B$.\n\nshare|cite|improve this answer\nThank you very much. \u2013\u00a0MZWang Feb 15 '13 at 2:16\n\nHodge index tehorem for surfaces asserts that in the intersection quadratic form on $\\mathrm{Num}(X)$, ther eis exactly one positive square. Hence, the restriction of this form to the orthogonal complement of $R$ must be negative definite. The classes of $E_i$ are pairwise orthogonal, and the quadratic form on the space defined by them in negative definite. Hence, these clacces are linearly independent.\n\nshare|cite|improve this answer\nWhy are the classes of $E_i$ orthogonal\uff1f \u2013\u00a0MZWang Feb 15 '13 at 2:19\nThey don't need to be , of course. My fault: I read disjoint' instead of distinct'. \u2013\u00a0Serge Lvovski Feb 15 '13 at 7:32\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/143252/system-of-odes-and-lyapunov-function\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI've tried to solve a little problem that goes as follows:\n\nConsider a system of ODEs: $$x'=y-x^3\\text{ and } y'=-x^3-y^3$$ And the function $$L(x,y)=\\frac{1}{2}y^2+\\frac{1}{4}x^4.$$\n\nNow I shall show that $(0,0)$ is not linearly stable, and that $L$ is a Lyapunov function.\n\nI tried to investigate $\\frac{dL}{dy}$ and $\\frac{dL}{dx}$ and check if this is smaller or greater than $0$ at (0,0). However, these two terms are just $\\frac{dL}{dy}=y,\\frac{dL}{dx}=x^3$, so it seems we have to solve for $x,y$ explicitly? I'm confused because this looks like one of those exercise where brute-force can be avoided (And we did not deal with non-linear ODEs yet)?\n\nyours, Marie\n\nshare|cite|improve this question\nYou can investigate \"the derivative of L with respect to your system\", $\\nabla L \\cdot f(y)$, where $f(y)$ is your system. See the example here. The system is guaranteed to be stable if this derivative is negative definite. \u2013\u00a0tentaclenorm May 9 '12 at 22:37\nup vote 2 down vote accepted\n\nFor $L(x,y)$ to be a Lyapunov function, what you want to do is consider $$\\dfrac{dL}{dt} = y \\dfrac{dy}{dt} + x^3 \\dfrac{dx}{dt} = y (-x^3 - y^3) + x^3 (y - x^3)$$ Do you see why $\\dfrac{dL}{dt} \\le 0$, with equality only at $(0,0)$? And why $L(x,y) \\ge 0$, with equality only at $(0,0)$?\n\nshare|cite|improve this answer\nAwesome! So for the linear stability, we also have to differentiate w.r.t. $t$, not $x,y$ and hence the two exercises were connected! :) \u2013\u00a0Marie. P. May 9 '12 at 23:06\nWait - I see how $\\frac{dL}{dt}<0$ and $L(x,y)>0$ except equalities at $0$, but if the derivative is negative, then how can the function start at $0$ and then be always greater than zero? \u2013\u00a0Marie. P. May 9 '12 at 23:16\nIf you start at $(0,0)$, then obviously you stay there. If you start somewhere else, then as time goes on $L(x,y)$ decreases so you must approach $(0,0)$. \u2013\u00a0Robert Israel May 10 '12 at 0:34\n@Marie.P.: Also, that second equality there is the reason we say that the derivative ${dL\\over dt}$ is computed along a solution since we substitute back in the dynamics from the ODE there. \u2013\u00a0JohnD Dec 14 '12 at 3:22\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207208/cutting-a-n-dimensional-cubic-cake\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nGiven a cubic cake, defined as $\\{(x,y,z)|0\\leq x,y,z\\leq 1\\}$.\n\nWe cut it by the planes\n\n$p_1\\leftrightarrow x=y$\n\n$p_2\\leftrightarrow y=z$\n\n$p_3\\leftrightarrow x=z$.\n\nHow many pieces will we have after cutting?\n\nAnd the 4-dimensional case: $\\{(x,y,z,u)|0\\leq x,y,z,u\\leq 1\\}$\n\nHow many pieces will we have after having cut by the spaces\n\n$x=y$, $x=z$, $x=u$, $y=z$, $y=u$, $z=u$?\n\nAnd the $n$-dimensional case...\n\nshare|cite|improve this question\nHint: What are the conditions on the two subsets after cutting along $x=y$? That is, how do you determine if $(x,y,z)$ is in one subset or the other? \u2013\u00a0Thomas Andrews Oct 4 '12 at 15:30\nI have a solution, but i wanted to share this with others. Because i find it a beautiful problem. \u2013\u00a0barto Oct 4 '12 at 15:37\nThis is not a puzzle site, it is a site for answering questions so that later people with the same question can find the answer. So if you have an answer, then post it. @barto \u2013\u00a0Thomas Andrews Oct 4 '12 at 15:41\nup vote 1 down vote accepted\n\nWhen cutting by the space $x=y$, we divide the cake in two parts:\n\nOne part with $x>y$ and one part with $x<y$.\n\nThe same holds for spaces like $y=z$, $z=u$, ...\n\nThat means, that every ordering of the variables $x$, $y$, $z$, ... defines a part. And since there are $n!$ orderings, there are $n!$ pieces after cutting.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://galwaymathsgrinds.wordpress.com/maths-topics/binomial-theorem/\nText:\nBinomial Theorem\n\nFormulae and Tables page 20\n\nI think that on first seeing the Binomial theorem many students think it very complicated and straight away tell themselves that this is too difficult to deal with. But like many other things in maths if we just identify a few patterns in how things are ordered it suddenly appears much simpler.\n\nIt is binomial because we are working with the sum or difference of two algebraic terms, (x+y). It tells us the result of raising this to any whole number power. Lets take a few examples that we know already or can easily work out by multiplying out the (x+y) the required number of times. Remember from the rules of indices that anything to the power of zero is 1.\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)0 = 1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1 term\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)1 = x+y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2 terms\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)2 = x2 +2xy + y2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0 3 terms\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)3 = x3 + 3x2y + 3xy2 + y3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\u00a0 4 terms\n\nIf we raise it to the power of n, then the number of terms in the expansion will be n + 1, and these are all added together.\n\nLook at the powers of x. They start at the same power as the binomial is being raised to and then decrease by 1 in each succeeding term until we reach x0. Remember x0 is 1. And since multiplying by 1 makes no difference we do not need to write it in.\n\nThe powers of y follow the reverse pattern starting at y0 in the first term. Again since this is 1 and it is multiplied by xn it is just ignored. They increase by 1 in each succeeding term until we reach yn.\n\nWe then have to find the coefficients of the different terms. These are given by calculating nCr where n is the power we are raising the binomial to, and r starts at 0 for the first term and increments by 1 in each succeeding term until it reaches n.\n\nThe booklet gives the definition of nCr in terms of factorials but it is much simpler to just use the nCr button on your calculator.\n\nIn general then a binomial expansion raised to the power of n will consist of the sum of n+1 terms of the form nCr . xn-r .yr where r starts at zero and increases by 1 in succeeding terms.\n\nThis results in\n\nGeneral term of binomial expansion\n\n= Tr+1 = nCr . xn-r .yr\n\nFind the term independent of x in (x2 \u2013 1/x)15\n\nThe term independent of x is the term with no x, in other words the index (power) on x is zero.\n\nTr+1 = 15Cr . (x2)15-r .(-1/x)r\n\n= 15Cr . (x)30-2r .(-1/x)r\n\n= 15Cr . x30-2r .(-x)-r\n\n= 15Cr . -x30-3r\n\n30-3r = 0 for independent term. r = 10\n\nTr+1 = 15Cr . (x2)15-r .(-1/x)r = 3003 . x10 . 1/(-x10) = 3003"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/116566/is-there-a-olog-n-time-algorithm-to-find-the-maximum-element-of-a-circular-shi\nText:\nConsider this problem: You are given an array $A$ (of distinct integers) of one out of the following four types:\n\n  \u2022 Ascending (e.g., 1,2,4,6);\n  \u2022 Descending (e.g., 6,4,2,1);\n  \u2022 Ascending rotated (a non-trivial circular shift of an ascending array, e.g., 4,6,1,2);\n  \u2022 Descending rotated (a non-trivial circular shift of an descending array, e.g., 4,2,1,6).\n\nThe task is to determine the type and the maximum element of $A$.\n\nSince $A$ is \"sorted\", is there a $O(\\log n)$-time approach or is the best possible time complexity $O(n)$, as suggested in the link?\n\n  \u2022 3\n    $\\begingroup$ Please include the question as part of your post. The link could rot in the future. $\\endgroup$ Nov 1 '19 at 16:45\n  \u2022 $\\begingroup$ The question has been put on hold seconds before I could post my answer. Am I allowed to edit the question even if I'm not the original poster? $\\endgroup$\n    \u2013\u00a0Steven\n    Nov 1 '19 at 18:31\n  \u2022 $\\begingroup$ @Steven yes, and edit was very good. $\\endgroup$\n    \u2013\u00a0Evil\n    Nov 2 '19 at 4:20\n  \u2022 1\n    $\\begingroup$ Let N>= 3 be the array size, n = N/3, m=2N/3, x=position of last element. Read a, b, c from index 0, n and m. a, b, c can be sorted in six different ways, and each corresponds to one of the six cases array sorted in ascending/descending order, and x<n, n<=x<m, and x>= m. The rest is binary search in a sub array of size N/3, so O(log N). $\\endgroup$\n    \u2013\u00a0gnasher729\n    Nov 2 '19 at 10:36\n  \u2022 $\\begingroup$ What did you try? Where did you get stuck? Can you recognize any of the four cases? We're happy to help you understand the concepts but just solving exercises for you is unlikely to achieve that. You might find this page helpful in improving your question. $\\endgroup$\n    \u2013\u00a0D.W.\n    Nov 3 '19 at 7:31\n\nLet $A = \\langle a_1, \\dots, a_n \\rangle$ be the input array. I will only consider the case $n \\ge 3$, otherwise the problem is trivial.\n\nThe key property is that the order relation between all but one pair of consecutive elements modulo $n$ in $A$ will be \"greater than\" if $A$ is some circular shift of an increasing array (possibly the trivial shift by $0$), and \"less than\" if $A$ is some circular shift of a decreasing array. Examining the first and last elements suffices to determine if the shift is trivial or not.\n\nIn practice you can determine the type of $A$ in constant time, as follows:\n\n  \u2022 Look the majority value $x$ among $\\textrm{sign}(a_1-a_n)$, $\\textrm{sign}(a_2-a_1)$, and $\\textrm{sign}(a_3-a_2)$.\n\n  \u2022 If $x = +1$ then $A$ is some circular shift of an increasing array. If $\\textrm{sign}(a_1-a_n)=-1$, $A$ is of type \"ascending\", otherwise it is of type \"ascending rotated\".\n\n  \u2022 If $x = -1$ then $A$ is some circular shift of a decreasing array. If $\\textrm{sign}(a_1-a_n)=1$, $A$ is of type \"descending\", otherwise it is of type \"descending rotated\".\n\nAs for returning the maximum, I will only discuss the case in which $A$ is a circular shift of an increasing array (the complementary case is handled similarly). Notice that, if the maximum element is in some position $a_j$, then all $a_1, \\dots, a_j$ are larger than or equal to $a_1$, while all ements $a_{j+1}, \\dots, a_n$ are smaller than $a_1$. This allows you to binary search for the last element that is larger than or equal to $a_1$, i.e., $a_j$.\n\n  \u2022 1\n    $\\begingroup$ No doubt this is a great answer as per me. But, I think we should consider $x$ as majority of $sign(a_1-a_n), sign(a_2-a_1)$ and $sign(a_3 - a_2)$. Because I'm getting wrong answer if I follow above approach with sequence $6,3,4,5$. $\\endgroup$ Nov 2 '19 at 11:07\n  \u2022 $\\begingroup$ Ughh. You are right! Thanks for spotting that. $\\endgroup$\n    \u2013\u00a0Steven\n    Nov 2 '19 at 11:13\n\nif we are given with first two cases i.e Ascending sorted array and descending sorted arrays we can simply find the difference b/w last element of array and first element of array i.e (last element of array - first element of arrays)if difference is positive then it is ascending order and maximum element is the element at last index of array (in ascending sorted arrays ) and vice versa. it takes just 0(1) in that case.\n\n  \u2022 1\n    $\\begingroup$ We don\u2019t know which of the four cases it is, finding which case is part of the problem. $\\endgroup$\n    \u2013\u00a0gnasher729\n    Nov 3 '19 at 13:35\n\nYour Answer"}
{"text": "Retrieved from https://linguistics.stackexchange.com/questions/25564/sami-loanwords-in-swedish-language\nText:\nAre there any words in Swedish borrowed directly from Sami languages? Excluding proper nouns. One example would be enough for \"yes\" answer. A link to some research on related subject is required for \"no\" answer.\n\n\nThe set of candidates is small. The word \"tundra\" is from Saami (Proto-Sami *tuonder), though I don't know if it went direct to Swedish, or via Russian. There are some Saami words used in Norwegian (at least northern Norwegian) which therefore might also be used in Swedish, namely \"duotji\" (handicrafts, not sure how it's spelled in Norwegian), and \"joik\", but one might decide that they aren't yet words 'in Scandinavian'. A rather old word is Swedish lunnef\u00e5gel, Norwegian lunde \"puffin\", from Proto-Sami *londe and Finno-Urgic *lunta \"bird\". Another (possibly not in Swedish) is the northern Norwegian semi-dried cod boknefisk, from Saami boahk- \"dry\". I would be remiss if I didn't mention samisk \"Saami\", which is from Saami.\n\nAddendum: I have to somewhat retract the example duodji (N. Saami spelling), related to the verb duddjot \"to do work by hand\". Sammallahti indicates this comes from Germanic to\u0304wja and Old Notse t\u00f8\u0304ja \"to accomplish\". I was unaware of sarv, vaja, h\u00e4rk in Scandinavian, but you'd expect there to be more influence of Saami in the realm of reindeer terminology. In contrast to the words duodji and joik which are Saami words pretty transparently used in Scandinavian, sarv would most likely be from N. Saami sarvva where it means \"moose\", suggesting that it is an older loan. The example h\u00e4rk also seems to have undergone a semantic shift pointing to it being an older word, since the closest N. Saami noun is heargi \"draft reindeer\", with a number of related derivatives. Interestingly, there is one verb heargut \"to be castrated (of reindeer)\" with the missing semantic element. So while h\u00e4rk surely derives from Saami, it's not just a Saami word that happens to be used in Scandinavian (as duodji is).\n\nFinally there is a Norwegian product name, Boazo, a brand of reindeer meat, transparently derived from N. Saami boazu \u2013 I don't know if that can called a loanword (analogous to Sriracha now being an English word).\n\n  \u2022 I think I have seen the spelling \"duodji\" in Norwegian.\n    \u2013\u00a0OmarL\n    Aug 7 '17 at 10:44\n  \u2022 I've found a couple more examples now: sarv - male reindeer, vaja - female reindeer with calf, h\u00e4rk - castrated male reindeer.\n    \u2013\u00a0Ondska\n    Aug 8 '17 at 13:48"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/162105/why-do-the-einstein-field-equations-efe-involve-the-ricci-curvature-tensor-ins/162540#162540\nText:\nI am just starting to learn general relativity. I don't understand why we use the Ricci curvature tensor. I thought the Riemann curvature tensor contains \"more information\" about the curvature. Why is that extra information so to speak irrelevant?\n\n  \u2022 $\\begingroup$ In a sense it does involve the Riemann tensor since the Ricci tensor is the trace of the Riemann tensor. $\\endgroup$\n    \u2013\u00a0Prahar\n    Jan 28 '15 at 20:45\n  \u2022 1\n    $\\begingroup$ Answer to v1:More seriously though, the traceless part of the Riemann tensor (i.e. Riemann - Ricci) known as the Weyl tensor encodes partial information about gravitational waves which is not sourced by matter. For this reason, one cannot expect an equation relating the Weyl tensor to a matter density (i.e. stress-energy tensor). BTW, the Weyl tensor is NOT irrelevant. It plays a crucial role in the quantization of gravity. $\\endgroup$\n    \u2013\u00a0Prahar\n    Jan 28 '15 at 20:48\n  \u2022 $\\begingroup$ Answer to v2: As eluded to in the previous comment, we introduce the Ricci curvature tensor to separate out the part of the Riemann tensor that is affected by presence of matter vs that part (namely the Weyl tensor) that gives us the gravitational fluctuations (which is eventually quantized). $\\endgroup$\n    \u2013\u00a0Prahar\n    Jan 28 '15 at 20:50\n  \u2022 $\\begingroup$ Ohhh....okay. I still don't think I understand what Ricci tells us but now I slightly better understand why other parts of Riemann might not be relevant for the particular purpose of the EFEs $\\endgroup$ Jan 28 '15 at 20:50\n  \u2022 2\n    $\\begingroup$ Basically, the Riemann tensor contains \"a lot\" of information, not all of which may be relevant to what we want to study. Thus, we break it up into two pieces, the Ricci tensor and the Weyl tensor each of which contains more specific kinds of information and allows to consider one in some cases over the other. People who study gravity waves are more interested in the Weyl tensor. On the other hand, if you are interested in the background metric in the presence of a matter source, you should look at the Ricci tensor. $\\endgroup$\n    \u2013\u00a0Prahar\n    Jan 28 '15 at 20:53\n\nI think this question is more trivial than you think.\n\nYou should ask yourself why should the full Riemann tensor appear. I'll sketch a heuristic derivation of the field equations.\n\nWe know that with small velocities and a static field, the Poisson equation $$\\Delta\\phi=4\\pi G\\rho$$ is approximately satisfied. From special relativity we know that the mass/energy density $\\rho$ must change with two Lorentz factors under a Lorentz transformation. Thus it is the time-time component of a rank two tensor $T_{\\mu\\nu}$. Using the equivalence principle, we promote this to a curved spacetime tensor. When we look for field equations, we demand that they be tensor equations. For one thing, this means we must have the same number of indices on both sides. We posit $$D_{\\mu\\nu}=\\kappa T_{\\mu\\nu}$$ with $\\kappa$ some constant. We don't know what $D_{\\mu\\nu}$ is, but the principle of covariant conservation fixes it to be the Einstein tensor. Note that the general form is the natural generalization of the Poisson equation.\n\nYou might propose an equation with more indices, such as $$R_{\\mu\\nu\\rho\\sigma}=\\kappa'T_{\\mu\\nu}T_{\\rho\\sigma}$$ with some appropriate antisymmetrization scheme. What are the vacuum equations? They would be $$R_{\\mu\\nu\\rho\\sigma}=0$$ But this just says spacetime is flat! We know this is incorrect. Black holes are certainly vacuum solutions but are also certainly not flat spacetime solutions.\n\nIn summary, the Ricci tensor has the ability to vanish without the full Riemann tensor vanishing. The general form of the equations is determined by the Poisson equation to be a rank two equation. In my mind, these two facts are the most effective argument.\n\n  \u2022 1\n    $\\begingroup$ Let me see if I follow. When looking for a general form of the Poisson equations, it becomes clear that the right form of the EFEs must be a rank two equation. Already, that suggests Riemann alone wouldn't work without doing some additional tricks to make it a rank two equation. $\\endgroup$ Jan 28 '15 at 21:47\n  \u2022 1\n    $\\begingroup$ Point 2. we want the equations on the left to be able to yield zero for the vacuum equations. So it makes no sense to use the Riemann tensor because to do so would require components to be zero that we wouldn't want to vanish. The Ricci tensor allows us to have the correct components to vanish and not vanish in the vacuum equations without giving us nonphysical results by having all of them vanish. In short, for the purposes of the EFEs and what they are intended to describe, the Ricci tensor allows us to establish equations that make sense. $\\endgroup$ Jan 28 '15 at 21:48\n  \u2022 1\n    $\\begingroup$ @StanShunpike: Exactly. In an ironic sense, the Riemann tensor contains too much information. If it vanishes, then spacetime is flat. If the Ricci tensor is flat, however, this only says spacetime is Ricci flat, not totally flat. $\\endgroup$\n    \u2013\u00a0Ryan Unger\n    Jan 28 '15 at 21:50\n  \u2022 $\\begingroup$ @StanShunpike: If you were really hell-bent on making life difficult, you could ask why $\\kappa''(R_{\\mu\\rho\\nu\\sigma}R^{\\rho\\sigma}+\\text{other terms})$ where $\\kappa''$ is some new constant does not work. (The \"other terms\" are terms that make the covariant divergence of the whole thing vanish.) Here the answer is not very satisfying: scale. Experimentally, see good agreement between reality and the EFEs. We thus conclude $\\kappa''$ must be very small compared to the other constants in the theory. $\\endgroup$\n    \u2013\u00a0Ryan Unger\n    Jan 28 '15 at 21:57\n  \u2022 $\\begingroup$ @StanShunpike: Thus this new term does not matter in the grand scheme of things. HOWEVER, if we are in four dimensions, which we are in GR, then there exists a theorem called Lovelock's theorem. It states that in four dimensions only a tensor $D_{\\mu\\nu}$ satisfying $\\nabla^\\mu D_{\\mu\\nu}=0$ and constructed with at most two derivatives of the metric tensor is a linear combination of the Einstein tensor and the metric tensor (cosmological term). $\\endgroup$\n    \u2013\u00a0Ryan Unger\n    Jan 28 '15 at 22:02\n\nRegarding why the Ricci tensor, not the Riemann, appears in the EFEs the answer is in the Newtonian theory.Very heuristically consider Newton's law\n\n$\\ddot{r}=-\\frac{GM}{r\u00b2} $.\n\nNow let's try to make this a more local statement. In order to do so I'll divide both sides by $r$ and some numerical factors in order for the volume $V=\\frac{4\\pi r\u00b3}{3}$ of some hypothetical sphere enclosing the mass to appear in the denominator\n\n$\\frac{\\ddot{r}}{r}= -\\frac{4\\pi G}{3} \\left(\\frac{M}{\\frac{4\\pi r\u00b3}{3}}\\right)=-\\frac{8\\pi G}{3}\\left(\\frac{1}{2}\\rho\\right)$,\n\nwhere $\\rho$ is the matter density. Now use the fact that\n\n\nto write Newton's law, in a first approximation, as\n\n$\\frac{\\ddot{V}}{V}=-8\\pi G\\left(\\frac{1}{2}\\rho\\right)$,\n\nso that Newton's law can be interpreted as relating the fractional volume change with the matter distribution. Now from the point of view of General Relativity gravity is curvature, which is described by the Riemann tensor. In order to obtain Newton's law you could ask for the part of the Riemann curvature that describes volume changes, and will not be surprised to find that it is the Ricci tensor (wikipedia has a section on this interpretation of Ricci curvature). The other part, the Weyl tensor, describes shape deforming, volume preserving curvature, and therefore cannot be directly related to Newton's law.\n\nWhen writing the EFEs as\n\n$R_{\\mu\\nu}=8\\pi G (T_{\\mu\\nu}-1/2g_{\\mu\\nu}T^\\mu_{\\;\\mu})$,\n\nand taking the time-time component you get on the left hand side the fractional change in volume (plus the $O(V^{-2})$ term that I neglected), and the right hand side provides the one-half density (plus terms of pressure divided by $c\u00b2$ which don't appear in the newtonian limit).\n\nRegarding the Riemann tensor, it is true that it contains more information than the Ricci tensor, but this is not irrelevant. In fact the Riemann curvature satisfies the second Bianchi identity $R_{\\alpha\\beta[\\mu\\nu;\\lambda]}=0$, and if you're masochistic enough to decompose the Riemann tensor in Ricci and Weyl parts (here in wikipedia for the expression) you'll see that one can write the derivatives of the Weyl part in terms of the Ricci tensor and its derivative. Now use the EFEs to substitute the Ricci tensor for the energy-momentum and the second Bianchi indentity will give you a system of partial differential equations relating the Weyl components and the energy-momentum (and it's derivatives). So, in a certain sense, the curvature equations of general relativity are the Einstein Equations plus the Bianchi indentity, that determines the whole curvature. In the absence of matter the manifold will be Ricci flat (by EFEs) but the Weyl part need not be null, the solution to the system of PDEs will be determined by the boundary conditions. In relativity this boundary conditions are things like the spacetime being asymptotically flat, symmetries, etc.\n\nThis situation is analogous to electromagnetism. One can write Maxwell's equations covariantly as $\\partial_\\alpha F^{\\alpha\\beta}=J^\\beta$ and $\\partial_{[\\gamma}F_{\\alpha\\beta]}=0$. But you could write only the first equation (the one with the sources) and just define the Faraday tensor to be a closed form, which gives you the second equation, Gauss' law and Faraday's law. Since the Bianchi identity is, well, an identity, the equations for the Weyl part are already determined by the definition of Riemann curvature.\n\nI hope this clarifies the presence of the Ricci tensor in the EFEs and how the rest of the Riemann curvature is obtained.\n\nEDIT: Per Rod Vance's suggestion I'll put the Bianchi identities explicitly in terms of Weyl and Ricci parts. Straight out of the wikipedia link he furnished below, the Bianchi identities read (for our four dimensional case):\n\n$\\nabla_\\mu C^\\mu_{\\; \\nu\\lambda\\sigma}=\\nabla_{[\\lambda}( R_{\\sigma]\\mu}-\\frac{R}{3}g_{\\sigma]\\mu})$,\n\nwhere brackets denote antisymmetrization as usual, and one should note that although the derivative of the metric is zero, one must apply Leibniz rule here to take in account derivatives of the scalar curvature as well. Therefore in the presence of matter the Weyl tensor will describe the tidal forces (differential gravity) sourced by this objects, but even in the absence of matter one will still have to solve a PDE to find $C^\\mu_{\\;\\nu\\lambda\\sigma}$, the solution of which is subject to the aforementioned boundary conditions. Gravitational waves in particular are vacuum solutions where there are gravitational tidal forces in a given region of the spacetime even in the absence of matter.\n\n  \u2022 $\\begingroup$ What a great answer. I really like this one too. Particularly the simple move to divide by $r$ was an ingenious and intuitive way to connect to the idea that the Ricci tensor measures deviation from a Euclidean geodesic ball. $\\endgroup$ Jan 31 '15 at 3:10\n  \u2022 $\\begingroup$ Thanks, this argument is kind of an adaption of the paper by John Baez called \"The Meaning of Einstein's Equation\", take a look for more info math.ucr.edu/home/baez/einstein, all credits belong to him. Also I added some remarks on the Riemann tensor that disappeared when I first posted the answer, so sorry for the incomplete look at first $\\endgroup$ Jan 31 '15 at 15:00\n  \u2022 $\\begingroup$ Fantastically clear summary of relationship between Ricci, Weyl and Riemann. Wonderful technical writing here. $\\endgroup$ Feb 11 '15 at 12:21\n  \u2022 1\n    $\\begingroup$ \"one can write the derivatives of the Weyl part in terms of the Ricci tensor and its derivative\" you're talking about this I presume. It might help to add a footnote with these equations explicit, as this really is the crux of one aspect of the question: one sees a \"signal flow\" through the equations to see how boundary conditions together with the Ricci fix the Weyl. $\\endgroup$ Sep 29 '15 at 12:54\n  \u2022 1\n    $\\begingroup$ Thanks for that. It was an awesome answer anyway, but a friend was asking me about this stuff and I referred them to your answer: I found that we still had to dig a bit to find the explicit relationships. My friend said that once she did, it was like the removal of a thorn that had been bothering her for years - she's not in GR but certainly has the werewithall to understand this stuff - \"I've never been too clear on the Weyl and how it's set up in GR, and this is exactly what I wanted to see\" was her comment (well almost: can't be sure it's verbatim). $\\endgroup$ Sep 30 '15 at 3:01\n\nThe Einstein equations are equivalent to an relation on the Riemann tensor. Given $a, b$ that are linearly independent vectors,\n\n$$R(a \\wedge b) = C(a \\wedge b) + 4\\pi [a \\wedge T(b) - b \\wedge T(a) - \\frac{2}{3} T a \\wedge b]$$\n\nwhere $T(a)$ is the stress energy tensor acting on $a$ and $T$ is its trace, and $C$ is the Weyl (\"conformal\") tensor.\n\nThis equation subsumes the Einstein equations, and it forms part of the basis for numerical tetrad approaches to gravity.\n\nI say this equation subsumes the Einstein equations because it requires strictly more information than the stress-energy tensor to characterize the Riemann this way. The Weyl tensor describes the state of gravitational radiation in the system, and so you can see the Riemann has two distinct contributions: one from stress-energy, and one from gravitational radiation.\n\nThe symmetries of the Weyl tensor mean that you can contract both sides and eliminate it, yielding the familiar Einstein equations in terms of the Ricci tensor. This can be convenient, as often we might treat different systems with the same distribution of stress energy--but different distributions of gravitational radiation--as \"equivalent\" in some sense.\n\nCompare with common electrodynamics problems: e.g. solving for the electric field from a spherical charge density. Technically, you could add any divergence- and curl-free electric field and still satisfy the Maxwell equations, but everybody knows that and it's tacitly not considered except when that's really relevant.\n\n\nThe other answers to this question focus on the analogies of the EFE with Poisson's equation. I prefer to focus on the stress energy-tensor. Stating that its divergence is zero expresses a generalization of f=ma.\n\nA blob of stuff in a reference frame falling toward a gravitational center experiences tidal forces, and the naive divergence of the stress-energy tensor is not zero. However, a judicious choice of pseudo-metric can result in the covariant divergence being zero. This is a way of invoking the Einstein Equivalence Principle.\n\nThe Einstein Tensor is guaranteed to have a zero covarient divergence, and gives a recipe for finding a pseudo-metric compatible with the stress-energy tensor.\n\nI believe Einstein found his tensor by trial and error together with intuition of what the Ricci tensor says about a cone of geodesics, and the changing shape of a falling blob. Hillbert arrived at the same tensor via a least action principle. It turns out that the Einstein tensor is essentially the only tensor with zero covariant divergence that results from only a few derivatives of the pseudo-metric.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/499031/minimum-number-of-weighings-necessary\nText:\n8 boxes each having different weights are numbered from 1 to 8 (the lightest 1, the heaviest 8). The total weight of 4 boxes are equal to the other 4\u2019s total, and your task is to identify these two groups. You have a balance scale with two pans on which you can compare the weight of two groups each having exactly 4 boxes. What is the minimum number of weighings necessary to guarantee to accomplish this task?\n\n  \u2022 $\\begingroup$ As there are $\\frac 12 {8 \\choose 4}=35 \\gt 2^5$ (barely) ways to split the eight boxes into fours, one would guess $6$. $\\endgroup$ Sep 19 '13 at 22:05\n  \u2022 $\\begingroup$ Thank you very much. I was trying to solve it by choosing the most useful 4's every time. But it's hard to be sure that way=) thanks again. $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 19 '13 at 22:15\n  \u2022 $\\begingroup$ I didn't post that as an answer, as I am not convinced. But it gives an idea where to look. In puzzles like this, there may be a trick that gets you down to $5$. $\\endgroup$ Sep 19 '13 at 22:20\n  \u2022 $\\begingroup$ But you're saying it shouldn't be more than 6 right? Because I could guarantee it with 7 weighings, which should be wrong if that's what you mean. $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 19 '13 at 22:32\n  \u2022 1\n    $\\begingroup$ Some of the valid combinations are 1238, 1248,1258,1268, 1278. If you weigh 1258 first you can eliminate two of the others by noting which way the balance tilts. I believe this is the kind of thinking needed. $\\endgroup$ Sep 20 '13 at 18:46\n\nKnowing that the weights increase monotonically from box $1$ to box $8$ allows several options to be discarded out of hand. In particular, if the groups are $A=\\{a_1,a_2,a_3,a_4\\}$ and $B=\\{b_1,b_2,b_3,b_4\\}$, with $a_1<a_2<a_3<a_4$ and $b_1<b_2<b_3<b_4$ and $a_1<b_1$, then we already know the $A$'s are lighter if $a_i<b_i$ for each $i$. These ignorable configurations correspond to walks by $\\pm 1$ from $0$ to $0$ that are always non-negative: $$ 010101010 \\\\ 010101210 \\\\ 010121010 \\\\ 012101010 \\\\ 012121010 \\\\ 012101210 \\\\ 010121210 \\\\ 012321010 \\\\ 012121210 \\\\ 010123210 \\\\ 012123210 \\\\ 012321210 \\\\ 012323210 \\\\ 012343210 $$ (fourteen, or the Catalan number $C_4$) where the $A$'s are definitely lighter. (The last in this list corresponds to $A=\\{1,2,3,4\\}$ and $B=\\{5,6,7,8\\}$, for instance.) This leaves only $\\frac{1}{2}{{8}\\choose{4}}-14=21$ partitions to choose from. So it's quite possible that $5$ weightings are enough.\n\nIndeed, even $4$ may be enough, since a weighing may be balanced (that is, there are three possible outcomes, one of which consists of only one possibility). So ideally the first weighing would either balance or reduce us to $10$ possibilities; the second would either balance or reduce us to $5$ possibilities; the third would either balance or reduce us to $2$ possibilities; and the fourth would determine the answer.\n\n\nI would start with $1278$. If heavy, it allows you to knot that $7$ and $8$ are in different groups, if light, you know $1$ and $2$ are in different groups. Let us assume it is heavy, otherwise subtract all numbers below from $9$.\n\nThe remaining combinations that are possible are $$\\begin {array} \\\\1268&1368&1468&1568\\\\ 1258&1358&1458\\\\1248&1348\\\\1238\\\\ \\\\2368\\\\2358&2458\\\\2348\\\\ \\\\3458\\end{array}$$ where combinations above, north or east are known to be heavier. The line breaks represent layers in a 3D matrix. If we try $1358$ next, then either $1468$ or $2358$, we might need as many as four more. This gives $7$ weighings. I haven't proven that you can't do it in $6$.\n\n  \u2022 $\\begingroup$ There is something I dont understand. There are 6 combinations(considering 21 valid) which has 7 and 8 on the same side. There should be 15 left. How did you narrow it down to ten? What happened to 2368, 3458, 2458, 2358 and 2348 ? $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 21 '13 at 22:23\n  \u2022 $\\begingroup$ @Taner: oversight. Updated and it cost me one. Now I think one can do better. $\\endgroup$ Sep 21 '13 at 23:01\n  \u2022 $\\begingroup$ Maybe I'm asking too many questions, but I also couldnt entirely understand why did we assume 1278 would be heavier and not lighter? How does 1278 being lighter be an easier way to find the equality? $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 22 '13 at 2:46\n  \u2022 $\\begingroup$ @Taner: there is a symmetry in the problem that is broken when we get that result. Any strategy that applies if 1278 is heavy is mirrored by one where 1278 is light, with all the numbers subtracted from 9. So instead of trying 1358 next, we would try 1468, then 1358 or 1467. $\\endgroup$ Sep 22 '13 at 5:16\n\nYour Answer"}
{"text": "Retrieved from https://ww2.mathworks.cn/help/stats/improve-an-engine-cooling-fan-using-design-for-six-sigma-techniques.html\nText:\nMain Content\n\nImprove an Engine Cooling Fan Using Design for Six Sigma Techniques\n\nThis example shows how to improve the performance of an engine cooling fan through a Design for Six Sigma approach using Define, Measure, Analyze, Improve, and Control (DMAIC). The initial fan does not circulate enough air through the radiator to keep the engine cool during difficult conditions. First the example shows how to design an experiment to investigate the effect of three performance factors: fan distance from the radiator, blade-tip clearance, and blade pitch angle. It then shows how to estimate optimum values for each factor, resulting in a design that produces airflows beyond the goal of 875 ft3 per minute using test data. Finally it shows how to use simulations to verify that the new design produces airflow according to the specifications in more than 99.999% of the fans manufactured. This example uses MATLAB\u00ae, Statistics and Machine Learning Toolbox\u2122, and Optimization Toolbox\u2122.\n\nDefine the Problem\n\nThis example addresses an engine cooling fan design that is unable to pull enough air through the radiator to keep the engine cool during difficult conditions, such as stop-and-go traffic or hot weather). Suppose you estimate that you need airflow of at least 875 ft3/min to keep the engine cool during difficult conditions. You need to evaluate the current design and develop an alternative design that can achieve the target airflow.\n\nAssess Cooling Fan Performance\n\nLoad the sample data.\n\n\nThe data consists of 10,000 measurements (historical production data) of the existing cooling fan performance.\n\nPlot the data to analyze the current fan's performance.\n\nylabel('Max Airflow (ft^3/min)')\ntitle('Historical Production Data')\n\nThe data is centered around 842 ft3/min and most values fall within the range of about 8 ft3/min. The plot does not tell much about the underlying distribution of data, however. Plot the histogram and fit a normal distribution to the data.\n\nhistfit(originalfan) % Plot histogram with normal distribution fit\nformat shortg\nxlabel('Airflow (ft^3/min)')\nylabel('Frequency (counts)')\ntitle('Airflow Histogram')\n\npd = fitdist(originalfan,'normal') % Fit normal distribution to data\npd = \n\n\n  Normal distribution\n       mu = 841.652   [841.616, 841.689]\n    sigma =  1.8768   [1.85114, 1.90318]\n\nfitdist\u00a0fits a normal distribution to data and estimates the parameters from data. The estimate for the mean airflow speed is 841.652 ft3/min, and the 95% confidence interval for the mean airflow speed is (841.616, 841.689). This estimate makes it clear that the current fan is not close to the required 875 ft3/min. There is need to improve the fan design to achieve the target airflow.\n\nDetermine Factors That Affect Fan Performance\n\nEvaluate the factors that affect cooling fan performance using design of experiments (DOE). The response is the cooling fan airflow rate (ft3/min). Suppose that the factors that you can modify and control are:\n\n  \u2022 Distance from radiator\n\n  \u2022 Pitch angle\n\n  \u2022 Blade tip clearance\n\nIn general, fluid systems have nonlinear behavior. Therefore, use a response surface design to estimate any nonlinear interactions among the factors. Generate the experimental runs for a Box-Behnken design in coded (normalized) variables [-1, 0, +1].\n\nCodedValue = bbdesign(3)\nCodedValue =\n\n    -1    -1     0\n    -1     1     0\n     1    -1     0\n     1     1     0\n    -1     0    -1\n    -1     0     1\n     1     0    -1\n     1     0     1\n     0    -1    -1\n     0    -1     1\n     0     1    -1\n     0     1     1\n     0     0     0\n     0     0     0\n     0     0     0\n\nThe first column is for the distance from radiator, the second column is for the pitch angle, and the third column is for the blade tip clearance. Suppose you want to test the effects of the variables at the following minimum and maximum values.\n\nDistance from radiator: 1 to 1.5 inches\nPitch angle: 15 to 35 degrees\nBlade tip clearance: 1 to 2 inches\n\nRandomize the order of the runs, convert the coded design values to real-world units, and perform the experiment in the order specified.\n\nrunorder = randperm(15);     % Random permutation of the runs\nbounds = [1 1.5;15 35;1 2];  % Min and max values for each factor\n\nRealValue = zeros(size(CodedValue));\nfor i = 1:size(CodedValue,2) % Convert coded values to real-world units\n    zmax = max(CodedValue(:,i));\n    zmin = min(CodedValue(:,i));\n    RealValue(:,i) = interp1([zmin zmax],bounds(i,:),CodedValue(:,i));\n\nSuppose that at the end of the experiments, you collect the following response values in the variable TestResult.\n\nTestResult = [837 864 829 856 880 879 872 874 834 833 860 859 874 876 875]';\n\nDisplay the design values and the response.\n\ndisp({'Run Number','Distance','Pitch','Clearance','Airflow'})\ndisp(sortrows([runorder' RealValue TestResult]))\n'Run Number'    'Distance'    'Pitch'    'Clearance'    'Airflow'\n\n            1          1.5           35          1.5          856\n            2         1.25           25          1.5          876\n            3          1.5           25            1          872\n            4         1.25           25          1.5          875\n            5            1           35          1.5          864\n            6         1.25           25          1.5          874\n            7         1.25           15            2          833\n            8          1.5           15          1.5          829\n            9         1.25           15            1          834\n           10            1           15          1.5          837\n           11          1.5           25            2          874\n           12            1           25            1          880\n           13         1.25           35            1          860\n           14            1           25            2          879\n           15         1.25           35            2          859\n\nSave the design values and the response in a table.\n\nExpmt = table(runorder', CodedValue(:,1), CodedValue(:,2), CodedValue(:,3), ...\n\nD stands for Distance, P stands for Pitch, and C stands for Clearance. Based on the experimental test results, the airflow rate is sensitive to the changing factors values. Also, four experimental runs meet or exceed the target airflow rate of 875 ft3/min (runs 2, 4,12, and 14). However, it is not clear which, if any, of these runs is the optimal one. In addition, it is not obvious how robust the design is to variation in the factors. Create a model based on the current experimental data and use the model to estimate the optimal factor settings.\n\nImprove the Cooling Fan Performance\n\nThe Box-Behnken design enables you to test for nonlinear (quadratic) effects. The form of the quadratic model is:\n\nAF\u00a0=\u00a0\u03b20+\u03b21*Distance+\u03b22*Pitch+\u03b23*Clearance+\u03b24*Distance*Pitch+\u03b25*Distance*Clearance+\u03b26*Pitch*Clearance+\u03b27*Distance2+\u03b28*Pitch2+\u03b29*Clearance2,\n\nwhere AF is the airflow rate and Bi is the coefficient for the term i. Estimate the coefficients of this model using the fitlm function from Statistics and Machine Learning Toolbox.\n\nmdl = fitlm(Expmt,'Airflow~D*P*C-D:P:C+D^2+P^2+C^2');\n\nDisplay the magnitudes of the coefficients (for normalized values) in a bar chart.\n\nh = bar(mdl.Coefficients.Estimate(2:10));\nset(h,'facecolor',[0.8 0.8 0.9])\nset(gcf,'units','normalized','position',[0.05 0.4 0.35 0.4])\nylabel('Airflow (ft^3/min)')\nxlabel('Normalized Coefficient')\ntitle('Quadratic Model Coefficients')\n\nThe bar chart shows that Pitch and Pitch2 are dominant factors. You can look at the relationship between multiple input variables and one output variable by generating a response surface plot. Use plotSlice to generate response surface plots for the model mdl interactively.\n\n\nThe plot shows the nonlinear relationship of airflow with pitch. Move the blue dashed lines around and see the effect the different factors have on airflow. Although you can use\u00a0plotSlice\u00a0to determine the optimum factor settings, you can also use Optimization Toolbox to automate the task.\n\nFind the optimal factor settings using the constrained optimization function fmincon.\n\nWrite the objective function.\n\nf = @(x) -x2fx(x,'quadratic')*mdl.Coefficients.Estimate;\n\nThe objective function is a quadratic response surface fit to the data. Minimizing the negative airflow using\u00a0fmincon\u00a0is the same as maximizing the original objective function. The constraints are the upper and lower limits tested (in coded values). Set the initial starting point to be the center of the design of the experimental test matrix.\n\nlb = [-1 -1 -1]; % Lower bound\t\t\t\t\t\nub = [1 1 1];    % Upper bound                       \nx0 = [0 0 0];    % Starting point\n[optfactors,fval] = fmincon(f,x0,[],[],[],[],lb,ub,[]); % Invoke the solver\nLocal minimum found that satisfies the constraints.\n\nOptimization completed because the objective function is non-decreasing in \nfeasible directions, to within the default value of the function tolerance,\nand constraints are satisfied to within the default value of the constraint tolerance.\n\nConvert the results to a maximization problem and real-world units.\n\nmaxval = -fval;\nmaxloc = (optfactors + 1)';\nbounds = [1 1.5;15 35;1 2];\nmaxloc=bounds(:,1)+maxloc .* ((bounds(:,2) - bounds(:,1))/2);\ndisp('Optimal Values:')\ndisp([maxloc' maxval])\nOptimal Values:\n    'Distance'    'Pitch'    'Clearance'    'Airflow'\n\n            1       27.275            1       882.26\n\nThe optimization result suggests placing the new fan one inch from the radiator, with a one-inch clearance between the tips of the fan blades and the shroud.\n\nBecause pitch angle has such a significant effect on airflow, perform additional analysis to verify that a 27.3 degree pitch angle is optimal.\n\ntbl = table(pitch,airflow);\nmdl2 = fitlm(tbl,'airflow~pitch^2');\nans =\n\n\nThe results show that a quadratic model explains the effect of pitch on the airflow well.\n\nPlot the pitch angle against airflow and impose the fitted model.\n\nhold on\nylim([840 885])\ntitle('Fitted Model and Data')\nxlabel('Pitch angle (degrees)') \nlegend('Test data','Quadratic model','Location','se')\nhold off\n\nFind the pitch value that corresponds to the maximum airflow.\n\nans =\n\n\nThe additional analysis confirms that a 27.3 degree pitch angle is optimal.\n\nThe improved cooling fan design meets the airflow requirements. You also have a model that approximates the fan performance well based on the factors you can modify in the design. Ensure that the fan performance is robust to variability in manufacturing and installation by performing a sensitivity analysis.\n\nSensitivity Analysis\n\nSuppose that, based on historical experience, the manufacturing uncertainty is as follows.\n\nFactorReal ValuesCoded Values\nDistance from radiator1.00 +/- 0.05 inch1.00 +/- 0.20 inch\nBlade pitch angle27.3 +/- 0.25 degrees0.227 +/- 0.028 degrees\nBlade tip clearance1.00 +/- 0.125 inch-1.00 +/- 0.25 inch\n\nVerify that these variations in factors will enable to maintain a robust design around the target airflow. The philosophy of Six Sigma targets a defect rate of no more than 3.4 per 1,000,000 fans. That is, the fans must hit the 875 ft3/min target 99.999% of the time.\n\nYou can verify the design using Monte Carlo simulation. Generate 10,000 random numbers for three factors with the specified tolerance. First, set the state of the random number generators so results are consistent across different runs.\n\n\nPerform the Monte Carlo simulation. Include a noise variable that is proportional to the noise in the fitted model, mdl (that is, the RMS error of the model). Because the model coefficients are in coded variables, you must generate dist, pitch, and clearance using the coded definition.\n\ndist = random('normal',optfactors(1),0.20,[10000 1]);\npitch = random('normal',optfactors(2),0.028,[10000 1]);\nclearance = random('normal',optfactors(3),0.25,[10000 1]);\nnoise = random('normal',0,mdl2.RMSE,[10000 1]);\n\nCalculate airflow for 10,000 random factor combinations using the model.\n\nsimfactor = [dist pitch clearance];\nX = x2fx(simfactor,'quadratic');\n\nAdd noise to the model (the variation in the data that the model did not account for).\n\nsimflow = X*mdl.Coefficients.Estimate+noise;\n\nEvaluate the variation in the model's predicted airflow using a histogram. To estimate the mean and standard deviation, fit a normal distribution to data.\n\npd = fitdist(simflow,'normal');\nhold on\ntext(,300,['Mean: ' num2str(round(])\ntext(,280,['Standard deviation: ' num2str(round(pd.sigma))])\nhold off\ntitle('Monte Carlo Simulation Results')\n\nThe results look promising. The average airflow is 882 ft3/min and appears to be better than 875 ft3/min for most of the data.\n\nDetermine the probability that the airflow is at 875 ft3/min or below.\n\nformat long\npfail = cdf(pd,875)\npass = (1-pfail)*100\npfail =\n\n\npass =\n\n\nThe design appears to achieve at least 875 ft3/min of airflow 99.999% of the time.\n\nUse the simulation results to estimate the process capability.\n\nS = capability(simflow,[875.0 890])\npass = (1-S.Pl)*100\nS = \n\n       mu: 8.822982645666709e+02\n    sigma: 1.424806876923940\n        P: 0.999999816749816\n       Pl: 1.509289008603141e-07\n       Pu: 3.232128339675335e-08\n       Cp: 1.754623760237126\n      Cpl: 1.707427788957002\n      Cpu: 1.801819731517250\n      Cpk: 1.707427788957002\n\npass =\n\n\nThe Cp value is 1.75. A process is considered high quality when Cp is greater than or equal to 1.6. The Cpk is similar to the Cp value, which indicates that the process is centered. Now implement this design. Monitor it to verify the design process and to ensure that the cooling fan delivers high-quality performance.\n\nControl Manufacturing of the Improved Cooling Fan\n\nYou can monitor and evaluate the manufacturing and installation process of the new fan using control charts. Evaluate the first 30 days of production of the new cooling fan. Initially, five cooling fans per day were produced. First, load the sample data from the new process.\n\n\nPlot the X-bar and S charts.\n\ncontrolchart(spcflow,'chart',{'xbar','s'}) % Reshape the data into daily sets\n\nAccording to the results, the manufacturing process is in statistical control, as indicated by the absence of violations of control limits or nonrandom patterns in the data over time. You can also run a capability analysis on the data to evaluate the process.\n\n[row,col] = size(spcflow);\nS2 = capability(reshape(spcflow,row*col,1),[875.0 890])\npass = (1-S.Pl)*100\nS2 = \n\n       mu: 8.821061141685465e+02\n    sigma: 1.423887508874697\n        P: 0.999999684316149\n       Pl: 3.008932155898586e-07\n       Pu: 1.479063578225176e-08\n       Cp: 1.755756676295137\n      Cpl: 1.663547652525458\n      Cpu: 1.847965700064817\n      Cpk: 1.663547652525458\n\npass =\n\n\nThe Cp value of 1.755 is very similar to the estimated value of 1.73. The Cpk value of 1.66 is smaller than the Cp value. However, only a Cpk value less than 1.33, which indicates that the process shifted significantly toward one of the process limits, is a concern. The process is well within the limits and it achieves the target airflow (875 ft3/min) more than 99.999% of the time."}
{"text": "Retrieved from https://physics.stackexchange.com/questions/375612/parameters-for-custom-lens-design\nText:\nFirst, problem background: I'm attempting to source lenses for use in eyeglasses to deal with extreme sensitivity to chromatic aberration, and likely need either achromatic doublets or single lenses in very low dispersion material (e.g. various fluorite crown glasses with Abbe numbers up to 90 or so).\n\nI've found several optical manufacturers/labs that advertise single-item custom optics and seem to have the capabilities to produce what I want, but I don't have any background in lens design to know what kind of design parameters I'd need to provide to make a meaningful inquiry, much less an order.\n\nMy prescription is moderately high negative, -6.25 and -7 diopters, with cylinder components (yes, let's make it harder) of -1 and -2, respectively. Most of the non-ophthalmic optics sources I've found list their regular stock (non-custom) items in just focal length and diameter. Obviously pure spherical diopters can be converted to a focal length if needed, but I'm not sure how the cylinder components come into play and possibly complicate or preclude certain designs (for doublets?), and what other parameters might be relevant/important (for example, outer curvature which seems to be something of a free parameter but maybe there are reasons it should correspond in some way to the eyes).\n\nWhat do I need to learn to go about translating my prescription into something I might be able to actually get made?\n\n  \u2022 $\\begingroup$ Cylinder components imply a different focal length in different planes. For example, a +4 sphere with an additional +1 vertical axis cylinder means a 25-cm focal length in the vertical plane while a 20-cm focal length in the horizontal plane. In a doublet, obviously the inner curvature of the outer lens must match the outer curvature of the inner lens. This is probably achieved by default by these curvatures being spherical, which conceptually may introduce chromatic aberrations. The idea of the overall outer curvature probably is to have its center in the center of the eye rotation. $\\endgroup$\n    \u2013\u00a0safesphere\n    Dec 21 '17 at 4:53\n  \u2022 $\\begingroup$ There is also a relation among the prescription, lens thickness, refractive index, and reflections. Stronger prescriptions, like yours, make the glass thick (along the edge for negative). For this reason often manufacturing of specialty glasses is limited by a certain optical power, especially of the cylinder part. You can reduce the thickness by increasing the refractive index, but this in turn increases the amount of light reflected. So an anti-reflective coating is a must, but it is not 100% effective. $\\endgroup$\n    \u2013\u00a0safesphere\n    Dec 21 '17 at 5:10\n  \u2022 $\\begingroup$ @safesphere: Are you talking about single lenses or doublets? As a general rule (not always true; the big exception which I'm actually considering and have some potential sources for is sapphire) higher index has increasingly bad dispersion/low Abbe and wouldn't be a potential solution for single lenses anyway. $\\endgroup$ Dec 21 '17 at 5:20\n  \u2022 $\\begingroup$ Sorry, which part of my comments are you asking about? I think most of what I mentioned would apply to both types, except for stronger reflection that applies mostly to the inner lens of the doublet, because the anti-reflective coating is not applied on the outer lens. Do you know what it would cost to make a pair of sapphire lenses? They would outlast any frame with no scratches, except for the anti-reflective coating that would eventually wear off. How would you shape them to the frame? Only diamond can sand them, I assume, no regular lab would agree or have the skills? $\\endgroup$\n    \u2013\u00a0safesphere\n    Dec 21 '17 at 5:37\n  \u2022 $\\begingroup$ @safesphere: I meant the second comment where you mentioned thickness and reducing it. I'm content with all options (except of course sapphire if I consider that a real option) being very thick - the single lenses because low-index, and the doublets because they're doublets. $\\endgroup$ Dec 21 '17 at 5:47\n\nYou will need to learn about the generalized Coddington Equations, which are simply Snell's law applied to an interface between two mediums and relate the Hessian matrix (called the \"curvature matrix\" in the jargon that people who use the Coddington equations speak) of a general quadric refracting surface and the direction cosines of the rays refracted by that surface. See, for example,\n\nCharles E. Campbell, \"Generalized Coddington equations found via an operator method\", JOSA-A, 23, #7, p1691\n\nYou're going to have to apply them to several wavelengths at once to come up with the design of doublet lens with the correct powers in each direction and whose powers are set equal at two target wavelengths.\n\nYou will probably benefit from a commercial raytracer software such as Zemax; unfortunately these are all grotesquely overpriced given that they are merely glorified Snell law calculators, with an optimized attached.\n\nYou'll also need to be fluent in the language of the ophthalmologist's prescription, although it sounds as though you may be more advanced along this road than I; for what it's worth, my answer here is a primer.\n\n\nYour Answer"}
{"text": "Retrieved from https://web2.0calc.com/questions/math-question_88\nText:\nwhat is 6^2/2(3)+4\n\nGuest\u00a0Aug 3, 2017\n\n4+0 Answers\n\n\nwhat is 6^2/2(3)+4\n\n\nPower calculation before point calculation before line calculation,\nthen from left to right.\n\n\n\\(\\frac{6^2}{2\\times 3}+4=\\frac{36}{6}+4=6+4\\color{blue}=10\\)\n\n\nWhoever wants can also shorten de Bruch by 6. \u00a0\u00a0 (\\(\\frac{36}{6}=\\frac{6}{1}\\) )\n\n\nlaugh\u00a0 !\n\nasinus \u00a0Aug 3, 2017\n\nThis is a rare example in mathematics where, I believe,\u00a0parentheses is necessary in order to evaluate the expression without ambiguity. I will demonstrate why.\n\n\nStrictly speaking, asinus's interpretation is incorrect. If you were to evaluate this with a calculator inputted like as is, the calculator would evaluate it as\u00a0\\(\\frac{6^2}{2}*3+4\\). This is because the 2(3) is really multiplication, so division takes precedence since it is\u00a0comes first in the expression. First it does 6^2, then it divides 6^2 by 2 because division is first from left to right, and then it multiplies that quantity by 3. Here is another example with a variable\u00a0\n\n\n\n\nUsing the same logic as above, this equation, in fraction form is strictly\u00a0\\(\\frac{8}{2}y\\)--not\u00a0\\(\\frac{8}{2y}\\). Some would argue, however, that 2y is a term, so it shouldn't be separated.\u00a0\u00a0\n\n\nHow do we eliminate this ambiguity if there is no fraction button to speak of? Use parentheses!\u00a0\n\n\nAsinus's interpretation of \\(\\frac{6^2}{2*3}+4\\)\u00a0will be unambiguous once you add 1 set of parentheses with\u00a0\\(6^2/(2(3))+4\\). Now, the only correct interpretation is\u00a0\\(\\frac{6^2}{2*3}+4\\)\u00a0because the parentheses indicate that we are dividing by the quantity of the product of 2 and 3.\n\n\nThe strict interpretation is\u00a0\\(\\frac{6^2}{2}*3+4\\)\u00a0should be written like\u00a0\\((6^2/2)(3)+4\\). In this case, the quantity of six squared divided by two is all multiplied by three. No more ambiguity.\n\n\nOkay, after all of this ranting, now I will evaluate what I believe to be, under the current rules of the order of operations, the way to evaluate the expression 6^2/2(3)+4 as\u00a0\\(\\frac{6^2}{2}*3+4\\):\n\n\n\\(\\frac{6^2}{2}*3+4\\) Evaluate the numerator.\u00a0\\(6^2=36\\)\n\\(\\frac{36}{2}*3+4\\) Simplify the fraction\u00a0by recognizing that the 36 is divisible by 2 because 36 is even.\n\\(18*3+4\\) Do multiplication before addition.\n\n\n\n\n\nTheXSquaredFactor \u00a0Aug 3, 2017\n\nHello\u00a0 \\(X^2\\)\n\nNeither of us is wrong.\nRight, who puts brackets to represent the meaning of his term.\ngreetings :)\n\nasinus \u00a0Aug 4, 2017\n\nGreetings to you, too :)\n\nTheXSquaredFactor \u00a0Aug 5, 2017\n\n23 Online Users"}
{"text": "Retrieved from https://www.physicsforums.com/threads/minimize-a-certain-function-involving-sine-and-cosine.662968/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMinimize a certain function involving sine and cosine\n\n  1. Jan 7, 2013 #1\n    It isn't a homework problem per se, but a curiosity a stumbled upon when trying to solve a physics problem (I was trying to calculate the angle I would need to do less work possible, while moving the box). The equation I found is:\n    [itex]f(\\theta)=\\cos(\\theta)+ 0.4sen(\\theta)[/itex]\n\n    2. Relevant equations\n\n    Just the one stated above, and trig identities, probably.\n\n    3. The attempt at a solution\n\n    I tried a few things (including deriving and finding the roots of the function without success, since I couldn't found the roots), I also tried to rewrite (Using cos\u00b2 + sin\u00b2 = 1) and got:\n    [itex]f(\\theta)=\\sqrt{1-\\sin^2(\\theta)}+ 0.4sin(\\theta)[/itex]\n    But I also don't know how to find the minimum in this equation.\n\n    How could I go about solving that?\n\n    Thanks in advance!\n    Last edited: Jan 7, 2013\n  2. jcsd\n  3. Jan 7, 2013 #2\n    What problems did you run into? Did you do anything with tangent?\n  4. Jan 7, 2013 #3\n\n\n    User Avatar\n    Science Advisor\n\n    Interesting that you use both \"sen\" and \"sin\"! Can't decide between French and English?\n\n    You have [itex]f(\\theta)= cos(\\theta)+ 0.4sin(\\theta)[/itex] (only English for me, I'm afraid.). I don't see any reason to introduce a square root just to have only sine. Taking the derivative, [itex]f'(\\theta)= -sin(\\theta)+ 0.4cos(\\theta)= 0[/itex] at a max or min. That is the same as [itex]sin(\\theta)= 0.4 cos(\\theta)[/itex] or, since sine and cosine are not 0 for the same [itex]\\theta[/itex], we must have [itex]sin(\\theta)/cos(\\theta)= tan(\\theta)= 0.4[/itex]. You can use a calculator to solve that.\n    Last edited by a moderator: Jan 7, 2013\n  5. Jan 7, 2013 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Reposting HallsofIvy's post to fix up the LaTex:\n  6. Jan 7, 2013 #5\n    Oh god, I can't believe I ignored sin(x)/cos(x) = tan(x). I'm terribly sorry, thanks a lot! That solves my problem.\n\n    About the whole sen and sin thing, it's because I'm actually Brazilian, and here we write \"Sen\", so I sometimes get both of them confused :P\n  7. Jan 7, 2013 #6\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You also need to worry about whether the point you find is a maximizer or a minimizer of f.\n  8. Jan 7, 2013 #7\n    Yes indeed, but that was easily done by deriving again and finding if the result in this particular point would be positive or negative, since I found a negative value I concluded that it was a maximum, the value I wanted(In OP I miswrote, I actually wanted a maximum initially).\n\n    [itex]tan(\\theta)= 0.4;\\theta = 21.8^o\\\\f''(21.8^o)= -1.077[/itex]\n\n    However, since you mentioned that, I just realized that I have no idea on how to find the minimum. Shouldn't [itex]tan(\\theta) = 0.4[\\itex] yield two values, one of which is a maximum and another which is a minimum?\n  9. Jan 7, 2013 #8\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n  10. Jan 7, 2013 #9\n    Hmm. I found by trial and error that the angles should be: 21.8\u00b0 and 201.8\u00b0, but how am I supposed to get the 201.8\u00b0? My calculator only gave me 21.8\u00b0.\n  11. Jan 7, 2013 #10\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    tan(x)=tan(x+180). The values of tan repeat every 180 degrees (pi in radians). It's periodic with period pi.\n  12. Jan 7, 2013 #11\n    Ohhh, I see, thanks!\n    I really need to get better in trigonometry. I have several wrong concepts :S\n  13. Jan 7, 2013 #12\n\n\n    User Avatar\n    Homework Helper\n\n    This is usually done with the identity\n\n    [tex]\\cos (x)+\\frac{2}{5} \\sin (x)=\\sqrt {1+\\left( \\frac{2}{5} \\right) ^2 } \\sin \\left( x+\\arctan \\left( \\frac{5}{2} \\right) \\right)[/tex]\n\n    Which is quite easy to optimize.\n\nSimilar Discussions: Minimize a certain function involving sine and cosine"}
{"text": "Retrieved from https://www.physicsforums.com/threads/elliptical-orbit.10486/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nElliptical orbit\n\n  1. Dec 7, 2003 #1\n    i was wondering, is there a particular formula to calculate the velocity of a object in an elliptical orbit. Lets say a satellite orbiting around the earth, and the orbit is elliptical, so how do u calculate the velocity at a certain distance from earth. I tried using the v^2=GM/r, but thats only for circular orbits.\n    thx for ur time\n  2. jcsd\n  3. Dec 7, 2003 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    Welcome to the forums!\n\n    The generalized form is called the Vis-Viva equation:\n\n\n    Where [itex]\\mu[/itex] is G*M or 398600.4 km^3/sec^2 for Earth,\n    r is the distance from the center of the Earth and\n    a is the semimajor axis of the ellipse.\n\n    You'll see that for a circular orbit, a = r for all points on the \"ellipse\" and you get the expected [tex]\\sqrt{\\frac{\\mu}{r}}[/tex]. You can also get the escape velocity by plugging in infinity for a.\n  4. Dec 8, 2003 #3\n    There are two things that must be remembered\n\n    1. Conservation of Angular Momentum\n    2. Conservation of Energy at any moment\n\n    Writing the above equations as function of r,v\n    and calulate r or v whatever required\n  5. Dec 8, 2003 #4\n    THanx alot for the help, even though in high school we haven't learned that formula yet, but it was really helpfull.\n  6. Dec 9, 2003 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    Do you understand it? The way you worded that, it sounds like you didn't.\n\n    It really isn't any more difficult than sqrt(mu/r). a is half the distance of the longest line in the ellipse, r is the current position. Plug and chug.\n  7. Dec 9, 2003 #6\n    i also found it using the conservation of energy, except with the formula i was a little confused but somehow i got the answer, with it, so i guess that's an alternate way of doing it as well. but the idea of conservation energy was good because thats how much we are taught so far. and i did understood too, n e ways. thnx again\n  8. Dec 10, 2003 #7\n    Yes those two equations are basic foundation for deriving formula\n  9. Mar 24, 2004 #8\n    General Math or Physics\n\n    Each planet moves around the sun in an elliptical orbit. the orbital period, T,of a planet is the timeit takes the planet to go once around the sun. the orbital period of a planet is proportional to the 3/2 power of the length of its semi-major axis. what is the orbial period (in days) of Mercury whose semi-major axis is 58 million km? what is the period (in years) of Pluto whose semi-major axis is 6,000 million km? the semi-major axis of the Eart is 150 million km.\n    how do you solve this\n\nSimilar Discussions: Elliptical orbit\n  1. Elliptical orbits (Replies: 1)\n\n  2. Elliptical Orbits (Replies: 6)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/questions-on-weinberg-cosmology-book.697215/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestions on Weinberg Cosmology Book\n\n  1. Jun 15, 2013 #1\n    I am following up Weinberg Cosmology book, but I have one question.\n\n    In chapter 3.1, we have Eq (3.1.3) and (3.1.4)\n\n    [itex] s(T) = \\frac{\\rho(T) + p(T)}{T} [/itex]\n    [itex] T\\frac{dp(T)}{dT} = \\rho(T) + p(T) [/itex]\n\n    In Eq (3.1.5), we have the Fermi-Dirac or Bose-Einstein distributions.\n\n    [itex] n(p, T) = \\frac{4 \\pi g p^2}{(2 \\pi \\hbar)^3} \\frac{1}{exp(\\sqrt{p^2 + m^2} / k_B T) \\pm 1} [/itex].\n\n    From using this number distribution, the author said we have the energy density and pressure of a particle mass m are given by Eq (3.1.6) and (3.1.7).\n\n    [itex] \\rho(T) = \\int n(p, T) dp \\sqrt{p^2 + m^2} [/itex]\n    [itex] p(T) = \\int n(p, T) dp \\frac{p^2}{3\\sqrt{p^2 + m^2}} [/itex]\n\n    Here, energy density is straightforward by the definition of number density.\n    But, for pressure, the author said it can be derived from Eq(3.1.4), the second equation on this post.\n\n    However, I cannot derive this pressure equation using Eq(3.1.4). Can somebody help me do this?\n\n    Thank you.\n  2. jcsd\n  3. Jun 22, 2013 #2\n\n\n    User Avatar\n    Science Advisor\n\n    My Weinberg seems a lot different from your Weinberg! But tracing through it, here's where the p(T) equation comes from. For a particle (using c = 1), the energy is E = \u03b3m and the momentum is p = \u03b3mv. Thus p/E = v (Eq.1)\n\n    For a system of particles, the energy-momentum tensor is T\u03bc\u03bd = \u2211n pn\u03bc dxn\u03bd/dt \u03b43(x-xn), or using Eq.1, T\u03bc\u03bd = \u2211n pn\u03bc pn\u03bd/En \u03b43(x-xn\n\n    For a perfect fluid, the spatial components of T\u03bc\u03bd are related to the pressure p by Tij = p \u03b4ij.\n\n    Thus p = (1/3) \u01a9j Tjj = (1/3) \u01a9n pn2/En \u03b43(x-xn).\n\n    This gets you the p2 in the numerator, the E in the denominator, and the 1/3 out front."}
{"text": "Retrieved from https://brainmass.com/physics/velocity/finding-overall-speed-and-velocity-540821\nText:\nExplore BrainMass\n\nFinding Overall Speed and Velocity\n\nEach of parts (b), (c) and (d) requires you to use numerical answers found in earlier parts of the question.\n\nA dragonfly has a flight speed in still air of 4.5ms-1. It is pointed in the direction N - 29 degree - E, but flies in a wind of speed 7.5ms-1 from the direction S- 42 degree - E. Take i to be 1ms-1 due east and j to be 1ms-1 due north. Also, take\n\nvd to be the velocity of the dragonfly in still air,\nvw to be the velocity of the wind,\nv to be the resultant velocity of the dragonfly.\n\nExpress each of the vectors vd and vw in component form, giving the components correct to four decimal places.\n\nHence show that the resultant velocity v of the dragonfly is given in component form approximately by\nv = -2.8368 i + 9.5094 j\n\nBy putting v into geometric form, find the overall speed |v| of the dragonfly (in ms-1 correct to one decimal place) and its direction of travel, as a bearing (with the angle in degrees correct to one decimal place).\n\nUsing your answers to parts (b) and (c), find the time taken by the dragonfly to travel one kilometre (in seconds, correct to one decimal place), and the distance west that it travels in this time (correct to the nearest metre)\n\nSolution Preview\n\nvd = 4.5 m/s N 29 degree E == 4.5 m/s, at 29 degree towards East from North\n=> vd = 4.5(i sin(29) + j cos(29)) = 4.5*( 0.4848i+ 0.8746j)\n\n=> vd = 2.1816i + 3.9358j --Answer\n\nvw = 7.5 m/s from S 42 degree E ...\n\nSolution Summary\n\nHere we solve a problem related to motion of an object (here dragonfly) influenced by the medium (here wind velocity). We estimate wind velocity of dragonfly and displacement in a given time duration."}
{"text": "Retrieved from https://www.physicsforums.com/threads/air-resistance-and-drag-coefficien.260206/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Air Resistance and drag coefficien\n\n  1. Sep 29, 2008 #1\n\n    An object of mass 10kg is projected upwards (from ground level) with initial velocity 60m/s. It hits the ground 8.4 seconds later.\n\n    Find the drag coefficient, k.\n\n    2. Relevant equations\n\n    dv/dt + rv = -g, where r = k/m\n\n    3. The attempt at a solution\n\n    I have used the integrating factor of e^rt to give me the final equation:\n\n    v = -g/r + C/e^rt\n\n    I then plug in the initial values to get:\n\n    60 = -98/k + C\n\n    I am not sure what to do next. We are given an impact time of 8.4 seconds. Do I assume that at this instant the velocity is -60 m/s (i.e. the exact opposite of the initial)? Or can I assume that at time 4.2 seconds the velocity is equal to 0? In either case, I am not sure how to solve the equation so that I only have one variable (e.g. just k or just C).\n\n  2. jcsd\n  3. Sep 29, 2008 #2\n    I don't follow your logic, why would you do this? I would start by making a FBD of the object. Your drag force will obviously be a function of velocity but you should come up with a fairly simple integral based off of the golden kinematics equations.\n  4. Sep 29, 2008 #3\n    Solved it.\n\n    I had to use e^-rt, use the initial velocity to give me a value for C, substitute that back in and then integrate with respect to t to give me height. From there you know that at t=0 and t=8.4, the height is 0. You can then calculate r and because you know the mass, k.\n\n    Use that r value for the velocity and you can then solve the velocity at t=8.4. The maximum height will be when the velocity equation is equal to 0.\n\n\n    Took me 2 hours, but I worked it out."}
{"text": "Retrieved from https://www.physicsforums.com/threads/eccentricity-of-orbit.244403/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Eccentricity of Orbit\n\n  1. Jul 10, 2008 #1\n    A particle moves in an elliptical orbit in an inverse-square law central force \ufb01eld. If the\n    ratio of the maximum angular velocity to the minimum angular velocity of the particle\n    in its orbit is n, then show that the eccentricity of the orbit is\n\n    \\epsilon = \\frac{\\sqrt{n}-1}{\\sqrt{n}+1}[/tex]\n\n    Not sure where to go with this. I tried finding total energy and angular momentum in terms of max/min angular velocity and radius but can't get anywhere\n  2. jcsd\n  3. Jul 10, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n\n    At what points in the orbit are the maximal and minimum angular (or, for that matter, linear) velocities attained? At what distances from the \"massive body\" (what the particle is orbiting around -- assumed to be \"infinitely massive\" here) is the particle at those moments? (You don't need values here -- just identify those places on the orbit and label them appropriately.)\n\n    Now for the critical part. Angular momentum is conserved. What angle does the velocity makes to the radial vector from the massive body at those moments (and no others)? Express the angular momentum in terms of radial distance and velocities for those two moments and set them equal. What is the relationship between these two angular (or linear) velocities and the two distances from the massive body?\n\n    Having found how the ratio of angular velocities, called n here, relates to those distances, how do those distances fit into the expression for the eccentricity of an ellipse?\n\n    That would be the full derivation of the answer. If you already know how n relates to the ratio of distances, it's a short step to getting to the eccentricity expression...\n  4. Jul 10, 2008 #3\n    Thanks, got it. Silly of me for starting with eccentricity in terms of energy and angular momentum instead of geometry.\n  5. Jul 10, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    \u2026 geometry \u2026\n\n    Hi cscott! :smile:\n\n    Consider it geometrically \u2026\n\n    Hint: if F is a focus of the ellipse, and P and Q are the ends of the major axis, what is PF/QF as a function of e?\n\n    And then what is n as a function of PF/QF? :smile:"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54873.html\nText:\nThe Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nDistance Between 2 Lines: Vectors\n\nDate: 8/19/96 at 23:29:28\nFrom: Anonymous\nSubject: Shortest Distance...\n\nWhat is the shortest distance between 2 lines?\n\nDate: 8/20/96 at 8:16:26\nFrom: Doctor Anthony\nSubject: Re: Shortest Distance...\n\nI am not sure how much vector work you have done, but I will assume a \nknowledge of scalar products of vectors, and the vector equation of \nstraight lines.  \n\nIn 3D space the shortest distance between two skew lines is in the \ndirection of the common perpendicular. (There is one and only one such \ndirection, as can be seen if you move one line parallel to itself \nuntil it intersects the other line. These two lines would now define a \nplane, and the perpendicular to this plane is the direction of the \ncommon perpendicular).  \n\nYou now take any point on one line, and any point on the other line, \nand write down the vector joining these two points.  Finally you find \nthe component of this vector in the direction of the common \nperpendicular.  This is done by finding the scalar product of the \nvector with the UNIT vector in the direction of the common \nperpendicular.  The result of the scalar product is the shortest \ndistance you require.  \n\nI will illustrate the method by means of an example. \n\nFind the shortest distance between the lines:\n\nx/1 = (y-3)/1 = z/(-1)\n\n(x-5)/3 = (y-8)/7 = (z-2)/(-1)\n\nFirst we require the vector perpendicular to both (1,1,-1) and \n\nLet the common perpendicular be (p,q,r). The scalar product of this \nwith both (1,1.-1) and (3,7,-1) will be zero, so:\n\n   p+q-r = 0 and 3p+7q-r = 0\n\nNote that although there are apparently 3 unknowns and only two \nequations, these are homogeneous equations (having 0 on the right hand \nside), so we could find values of p/r and q/r and hence the ratios \np:q:r which is all that we require.  Using the determinant method for \nsolving, we have:\n\n    p       -q          r\n|1  -1|   |1  -1|     |1   1|\n|7  -1|   |3  -1|     |3   7|\n\n   p/6  =  -q/2    =   r/4\n\n   p/3  =  q/-1    =   r/2   and so  p:q:r = 3:-1:2\n\nSo the common perpendicular is the vector (3,-1,2)\n\nAs a UNIT vector this is (1/sqrt(14)){3,-1,2}\n\nNext we have point (0,3,0) on line (1) and (5,8,2) on line (2).  \nThe vector joining these points is (5,5,2)  and now scalar product \nthis with the unit vector of the common perpendicular.\n\nScalar product = (1/(sqrt(14)){5*3 + 5*(-1) + 2*2}\n               = (1/sqrt(14)){15 - 5 + 4}\n               = 14/sqrt(14)\n               = sqrt(14)    \n\n   and this is the shortest distance required.\n\n-Doctor Anthony,  The Math Forum\n Check out our web site!   \nAssociated Topics:\nHigh School Geometry\nHigh School Higher-Dimensional Geometry\nHigh School Linear Algebra\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM"}
{"text": "Retrieved from https://www.physicsforums.com/threads/probability-expected-value-of-z-where-z-x-1-y-2.530580/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Probability- expected value of Z, where z= X/(1+y)^2\n\n  1. Sep 15, 2011 #1\n\n    X & Y are independent r.v.s with uniform distribution between 0 and 1.\n\n    Z= X/(1+Y)^2\n\n    find E[Z].\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    Here is what I did.\n\n    E[Z]= E[X]*E[1/(1+Y)^2]\n    I think that once I know the distribution of (1+Y)^(-2), I'll be able to find the answer. Is it 1/(1+Y)^2~ U(1,2) ?\n  2. jcsd\n  3. Sep 15, 2011 #2\n    You can also use this theorem:\n\n\n    So, in your case, this comes down to\n\n  4. Sep 15, 2011 #3\n\n\n    thanks for the answer.\n\n    Is 1+y^2 a typo in your answer?\n    so adding a constant to a uniform r.v. doesn't change it's distribution?\n  5. Sep 15, 2011 #4\n\n    Obviously it does change the distribution. But I don't see how that is important here.\n  6. Sep 15, 2011 #5\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If W = 1/(1+Y)^2, then for any w > 0 we have P{W <= w} = P{1/(1+Y)^2 <= w} = P{-sqrt(w) <= 1/(1+Y) <= sqrt(w)}. The left-hand inequality -sqrt(w) <= 1/(1+Y) holds automatically because Y >= 0, so P{W <= w} = P{1/(1+Y) <= sqrt(w)} = P{Y >= -1 + 1/sqrt(w)}. Since Y ~ U(0,1), we can easily get P{W <= w} and hence can get the density function of W. Alternatively: just apply the standard formula for the density of a transformed random variable.\n\n  7. Sep 15, 2011 #6\n\n    Well I was thinking that now its uniformly distributed from 1 to 2... isn't it?\n\n    Oh right its still uniform from 0 to 1...\n    omg... I'm so rusty :\\\n\n    Last edited: Sep 15, 2011\n  8. Sep 15, 2011 #7\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have all the information you need to work out the answer for yourself."}
{"text": "Retrieved from https://www.physicsforums.com/threads/extended-power-derivative.763884/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Extended power derivative\n\n  1. Jul 29, 2014 #1\n    I am having difficulty calculating the following derivative [tex]{ \\frac{2x^2-1}{(3x^4+2)^2}}[/tex]\n\n    Could someone demonstrate the first step algebraically? Assuming c is the exponent on the variable expression, n is the numerator and d is the denominator, I tried:\n\n\n    Which gives me\n\n    Which simplifies to\n    [tex]\\frac{-48 x^7+72 x^5+8 x^3-16 x}{(3x^4+2)^3}[/tex]\n\n    However, the book lists the answer as being [tex]\\frac{-36x^5+24x^3+8x}{(3x^4+2)^2}[/tex]\n  2. jcsd\n  3. Jul 29, 2014 #2\n\n    Char. Limit\n\n    User Avatar\n    Gold Member\n\n    I'm not quite sure what rule you're trying to use, but if it's the quotient rule, then you've got it written down wrong. The correct way is:\n\n    [tex]\\frac{d}{dx} \\frac{n(x)}{d(x)} = \\frac{n'(x) d(x) - d'(x) n(x)}{d(x)^2}[/tex]\n\n    Since you've already worked the latter expression out, it should be easy to finish for you.\n  4. Jul 29, 2014 #3\n    Are you sure that : [tex]\\frac{d}{dx} (3x^4+2)^2=12x^3[/tex] ?\n  5. Jul 29, 2014 #4\n    My book lists a rule called the \"extended power rule,\" which goes as follows:\n\n    \"Suppose g(x) is a differentiable function of x. Then, for any real number k,\n\n    [tex]\\frac {d}{dx}[g(x)]^k=k[g(x)]^{k-1}*\\frac{d}{dx}[g(x)][/tex]\n\n    Here's a link to the text:\n\n\n    I could easily solve the problem by expanding the binomial expression (3x^4+2)^2 and then using the standard product rule, but I need to know how to use the extended product rule as one of the sample question is raised to the power of 7, and there is no way that I am going to expand that. If you can offer me an alternative method to dealing with the derivatives of high order expressions, I would accept that as well.\n  6. Jul 29, 2014 #5\n\n    Char. Limit\n\n    User Avatar\n    Gold Member\n\n    The extended power rule isn't exactly relevant here. And you got that particular part correct. The problem was that the quotient rule, for whatever reason, was done incorrectly. I'm not sure where you got a c or the first part of that product.\n  7. Jul 29, 2014 #6\n    The book says to use the extended power rule in addition to the quotient rule to solve this particular problem, so it has to be relevant >_>\n\n    According to the extended power rule, I take the exponent off the expression, k (i accidentally put c), and multiply it by g(x). The text has a step-by-step example of how to use the extended power rule in conjunction with another quotient problem, [tex]\\sqrt[4]{\\frac{x+3}{x-2}}[/tex] in which they use the setup [tex]k\\frac{n(x)}{d(x)}\\frac{n'(x)*d(x)-d'(x)*n(x)}{d(x)^2}[/tex], but that form doesn't appear to work here.\n  8. Jul 29, 2014 #7\n    You don't need to expend these high order derivatives, just use the chain rule. As a reminder [tex](3x^4+2)^2[/tex] can be seen as a function of this type : [tex]f(g(x))\\ \\mbox{where}\\ g(x)=3x^4+2\\ \\mbox{and}\\ f(x) = x^2\\\\ \\mbox {Now consider that the x in}\\ x^2\\ \\mbox{actually is your function g(x), that is, f(x) is applied to g(x), the x in brackets become g(x).}\\\\ \\mbox{You then have your function h(x) = f(g(x)), which is} (3x^4+2)^2\\\\ \\mbox{You can now differentiate h(x), and as you can see, it's simply the derivative of f(g(x)).}\\\\ \\mbox{Use the chain rule:} \\frac{d}{dx}f(g(x)) = f'(g(x)) * g'(x)\\ \\mbox{and you've got the derivative.}\\\\ \\mbox{You can now differentiate polynomials, for instance :} \\frac{d}{dx}(4x^5+3)^9 = 9*(4x^5+3)^8 * 20x^4\\\\ \\mbox{In general :}\\ \\frac{d}{dx}(P(x))^n = n(P(x))^{n-1} * P'(x)[/tex]\n\n    Hope this helps!\n  9. Jul 29, 2014 #8\n    thank you!\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/mis-using-bernoullis-equation.836002/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Mis-using Bernoulli's equation\n\n  1. Oct 4, 2015 #1\n\n    An incompressible heated gas of constant temperature and pressure flows along an infinitely long tube at an unspecified velocity v1; a pressure of P1; and a density of p1 into an unheated open area of infinite volume containing the same gas at a lower pressure of P2; a density of p2,; and an effective velocity v2 of 0 m/s. The pipe is horizontal. Find the velocity of the gas inside the tube, ignoring friction and head losses.\n\n    2. Relevant equations\n    Bernoulli's equation, maybe\n\n    3. The attempt at a solution\n    Since the pipe is horizontal, h1 and h2 are treated as 0, cancelling out the pgh terms on each side of the equation. Since v2 is also 0, the .5p2v22 is eliminated. That leaves us with:\n\n    P1 + .5p1v12 = P2\n\n    Since P1 > P2 in this situation, the answer is always going to be the square root of a negative number.\n\n    Common sense tells me that the gas will flow from a region of high pressure to a region of low pressure, so it should flow out of the tube; sadly, it seems that I am applying Bernoulli's equation incorrectly in attempting to form a basic model of that effect. That, or something else is terribly wrong with the way the scenario is laid out (this is my own thought experiment; it is not homework, and no teacher is to blame for this problem).\n\n    Just looking at the reduced equation, it's all wrong. There's no way the high pressure value plus PLUS the squared velocity is going to equal the low pressure value. But the flow velocity in the tube is going to be non-zero since gas will be constantly leaving the tube ad infinitum, while the velocity outside of the tube is going to be zero since it is effectively a section of tube with a cross-sectional area approaching infinity.\n  2. jcsd\n  3. Oct 5, 2015 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    2017 Award\n\n    Bernoulli equation is conservation of energy. At tube inlet you have pressure energy and kinetic energy. At tube outlet you have lower pressure energy, so if all else can be ignored, you should have higher kinetic energy. I.e. v2 > v1, in contradiction with your assumption that v2 = 0.\n    The change from v2 > v1, to v'2 = 0 must occur somewhere in or around the tube outlet area, apparently.\n\n    Look at Bernoulli examples for flow through a small orifice (most have \u0394p > 0 from tank to jet) and compare with your case (\u0394p > 0 from pipe to 'tank')\n  4. Oct 5, 2015 #3\n    Your answer makes sense. I have erred in assuming that the equation covers the quiescent gas in the open area rather than the gas ejected from the tube in the immediate vicinity of the tube's outlet.\n  5. Oct 6, 2015 #4\n    Followup question: Given that the above-mentioned gas in the tube assumes a velocity of v2 immediately after exiting the tube where v2 > v1, is it safe to assume that the pressure P2 and density p2 of said gas will be the same as that of the quiescent gas in the open area? Or will that only pertain once the velocity of the exiting gas settles out after some arbitrary amount of time and effectively equals 0?\n  6. Oct 6, 2015 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    2017 Award\n\n    Bernoulli to the rescue again: when the gas is slowing down, the pressure must necessarily increase ! So I would say no. There will be some contraction effects and a volume where p is even lower than P2. I think I saw them described in one of the orifice flow examples.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/rate-of-change-of-x-wrt-sin-x.747893/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nRate of change of x wrt sin(x)\n\n  1. Apr 9, 2014 #1\n    Is possible to compute the rate of change of x wrt sin(x)? ##\\frac{dx}{d \\sin(x)}##\n  2. jcsd\n  3. Apr 9, 2014 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Have you tried just plotting it in Excel? You will get some 1/0 inflection points that you will need to deal with...\n  4. Apr 9, 2014 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Compare with ##\\frac{dsin^{-1}(x)}{dx}##\n\n    Or, turn the graph of sin(x) on its side.\n  5. Apr 9, 2014 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Compare to reciprocal dsin(x)/dx. Sin-1(x) is not relevant.\n  6. Apr 9, 2014 #5\n    Why isn't it relevant?\n\n    If we have dx/d(sinx), why is it not reasonable for me to let sinx = y and therefore have that x = arcsin(y)?\n\n    Then I have d(arcsin(y))/y = 1 / sqrt(1-y\u00b2)\n\n    And thus dx/d(sinx) = 1/sqrt(1-sin\u00b2(x)) = 1/sqrt(cos\u00b2(x)) = 1/|cos(x)|\n\n    Just curious, so where does this break down? This is a very unique question so I'm sure there is an error in my logic. One may note that this comes out to be only slightly different than the reciprocal method (no absolute value). I suspect this is because in assigning these variables in the way I did, I restricted/changed domain?\n    Last edited: Apr 9, 2014\n  7. Apr 9, 2014 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n\n    Due to the inverse function theorem, it is very relevant.\n  8. Apr 10, 2014 #7\n    After a quick Google, it looks like I followed this theorem with f(a) = sin(x). So why does f'(b) evaluate to 1/|cos(x)| according to my work rather than 1/cos(x) as the inverse function theorem claims it should?\n\n    I mean, hopefully we can agree that the answer to the OP's question is actually 1/cos(x) and not 1/|cos(x)|.\n  9. Apr 10, 2014 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    There are two ways to \"differentiate x with respect to sin(x)\". The first is to use the fact that\n    [tex]\\frac{dx}{dy}= \\frac{1}{\\frac{dy}{dx}}[/tex].\n    Here y= sin(x) so dy/dx= cos(x). Then dx/dy= 1/cos(x) is a perfectly good answer.\n\n    The other way is to say that if y= sin(x) then [itex]x= sin^{-1}(y)[/itex] so that the derivative of \"x with respect to sin(x)\" is [itex]dx/dy= d(sin^{-1}(y))/dy= 1/\\sqrt{1- y^2}[/itex].\n\n    It's not at all difficult to prove that those are the same. If y= sin(x) then [itex]1- y^2= 1- sin^2(x)= cos^2(x)[/itex] so [itex]1/\\sqrt{1- y^2}= 1/cos(x)[/itex].\n  10. Apr 10, 2014 #9\n    So, I can differentiate any function f(x) wrt another any function g(x).\n\n    If df = f'(x) dx and dg = g'(x) dx, thus df/dg = f'/g' ...\n  11. Apr 10, 2014 #10\n    Our work is the same, but I don't understand how you conclude that sqrt(cos\u00b2(x)) = cos(x). This is |cos(x)|, don't you agree?\n  12. Apr 10, 2014 #11\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n\n    Well, the sine function is not invertible, since it's not injective and not surjective. This is of course no problem for the inverse function theorem, since it will take a \"local inverse\".\n    You worked with the arcsine, which is indeed a local inverse. But not all local inverses are like the arcsine. That is, if we restrict the sine to ##(-\\pi/2,\\pi/2)## then the arcsine is an inverse. But guess what? The cosine function is actually positive on that said, so the absolute values drop.\n\n    If you apply the inverse function theorem on some other domain, then you can't use the arcsine anymore in that form.\n\n    Does that make sense?\n  13. Apr 10, 2014 #12\n    Yes, thank you.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Rate of change of x wrt sin(x)\n  1. Integration of sin(x) (Replies: 14)\n\n  2. Sin x =cosh x (Replies: 12)\n\n  3. Inverse of sin(x)+x (Replies: 10)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/y-x-2-y-2-xy-ode.86514/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\n\n  1. Aug 27, 2005 #1\n    for this O.D.E. :\n    y`= (x^2 + y^2)/xy\n    it's unseparable, so what other methods can there be taken?\n  2. jcsd\n  3. Aug 27, 2005 #2\n    It's a change of variables case (actually excercise #1 in my book on this topic), the way you do this is check to see whether f(x,y) = f(tx,ty), where f(x,y) = dy/dx.\n    So if you substitute tx and ty for x and y respectively, you'll see that equality holds. Then do following substitution: y = x V(x) into the DE and see what you get with applying dy/dx and some simplifications. It should reduce to separable equation.\n  4. Aug 27, 2005 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    This is just like the post about the other ODE. You can write it as:\n\n\n    Again, with the substitution z=y/x it becomes:\n\n    which is separable.\n  5. Aug 28, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    it's homogenous, separable, use v=y/x\n  6. Aug 30, 2005 #5\n    ok, thanks!\n  7. Sep 3, 2005 #6\n    here's my work:\n    y`=x/y +x/y\n    suppose y=vx\n    => y`=v+xv`\n    so v+xv`=1/v+v\n    => vdv=dx/x\n    => v^2=ln[absolute value(x)]+c`\n    => (y^2)/(x^2)=ln[absolute value(x)]+c\n    => y^2=2(x^2)ln[absolute value(x)]+cx^2\n    now if i take the square root on both sides, there should be a positive and negative sign on the right~\n    the correct answer should only have the positive sign, but how can you be sure that it should be positive?\n  8. Sep 3, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Whoopsie, you've forgot a factor 1/2 on the left side.\n\n    You can use either sign, both will be valid solutions to the ODE. This becomes clear when you plug y back into the ODE to check if it works out. Then, with the benefit of hindsight, you could foresee this, since if y is one solution, then the other is -y and it's derivative is -y'. If you write the ODE as xyy'=x^2+y^2 you can see that if y is a solution, then -y is too.\n\n    Ofcourse, if you're given a boundary value or initial value/condition then there will be only one solution. (otherwise the problem is ill-stated).\n  9. Sep 4, 2005 #8\n    thank you very much! :)\n\nHave something to add?"}
{"text": "Retrieved from http://mathoverflow.net/questions/131066/in-cell-decomposed-manifolds-how-easy-is-it-to-arrange-for-the-tubular-neighbor\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that you have decomposed a manifold $M$ into cells (I care most, if it matters, about compact oriented smooth manifolds; but if my question can be solved in the PL category, all the better). By this, I have in mind some sort of combinatorial description, so there probably should be various words like \"regular\" or whatnot. For various reasons, I cannot restrict my attention to simplicial decompositions \u2014 I must allow cubes, for example. In any case, if you have done so, then on the set of cells in $M$ there is a metric, generated by declaring that $\\operatorname{distance}(a,b) = 1$ if $a$ is a facet of $b$ (i.e. if the cell $a$ lies in the closure of the cell $b$). Then given any collection $Y$ of cells and any $\\ell \\in \\mathbb N = \\lbrace 0,1,2,\\dots\\rbrace$, I can define the set $\\mathrm{B}_\\ell(Y)$ to consist of the closure of the union of all cells at distance at most $\\ell$ from some element of $Y$. It is a sub-cell-complex of $M$. Suppose that the cell decomposition is very fine compared to the topologies of $Y$ and $M$: then one should expect that $\\mathrm{B}_\\ell(Y)$ contracts onto the closure of $Y$. Note that the closure of $Y$ is precisely $\\mathrm{B}_0(Y)$.\n\nMy specific situation is as follows. I have a manifold (compact, oriented, etc., if it matters) $X$. If I choose a cell decomposition of $X$, then I can induce a cell decomposition of $M = X^n$ by declaring that a cell of $M$ is an $n$-tuple of cells in $X$. (Certainly, if my cells were simplices with ordered vertices, then I could make other choices, but for my application this is most natural.) The diagonal map $X \\hookrightarrow X^n$ is not a map of cell complexes, but still for each cell in $X$, there is a corresponding diagonal cell of $M$, and I will define $Y$ to be this \"diagonal\" copy of $X$.\n\nMy question is the following:\n\nFor fixed $\\ell$, but letting $n$ vary, how can one find a cell decomposition of $X$ such that, with the notation above, $\\mathrm B_\\ell(Y)$ has the homotopy type of $X$? Or at least the same rational homology?\n\nAlmost surely, the $\\ell$-fold barycentric subdivision of any cell decomposition of $X$ will do the trick \u2014 probably the $\\lceil \\log_2\\ell \\rceil$-fold barycentric subdivision would work \u2014 but I find myself unable to prove this, even after talking to various friends who know more topology than I do. Or perhaps I'm supposed to find a Riemannian metric for which I would have the appropriate result, and then choose a cell decomposition in which all vertices are at distance roughly $1$ from each other. Or something. In any case, I know that my intuition for high-dimensional manifolds is poor.\n\nI do know how to prove that after one barycentric subdivision, $\\mathrm{B}_0(Y)$ has the rational homology of $X$.\n\nshare|improve this question\nYour question is very close in spirit to Abrams and Ghrist's work on discretized configuration spaces. It's not quite the same but it's close. \u2013\u00a0 Ryan Budney May 18 '13 at 20:28\n@Ryan: Thanks for the comment! I was unaware of their work, but I'll look it up. \u2013\u00a0 Theo Johnson-Freyd May 18 '13 at 21:57\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/597134/deformations-of-a-cuspidal-plane-cubic\nText:\nTake the 2-minute tour \u00d7\n\nTo practice with deformations, I am trying to compute the space of first order deformations of the cuspidal curve $X=\\textrm{Spec }B$, where $B=P/I$, $P=k[x,y]$ and $I=(f)=(y^2-x^3)$.\n\nThe conormal sequence $$I/I^2\\overset{d}{\\longrightarrow}\\Omega_{P/k}\\otimes_PB\\cong B\\,dx\\oplus B\\,dy\\longrightarrow \\Omega_{B/k}\\longrightarrow 0$$ induces a $B$-linear map (the \"dual\" of $d$) $$\\alpha:\\hom_B(\\Omega_{P/k}\\otimes_PB,B)\\to\\hom_B(I/I^2,B).$$ Just to be as clear as possible with those who read this question, I give a list of \"synonyms\" of the space of first order deformations of $X$ (hoping not to confuse anyone, nor to state something wrong!):\n\n  \u2022 $\\textrm{coker } \\alpha$,\n  \u2022 $T^1(B/k,B)$,\n  \u2022 $\\textrm{Ex}_k(B,B)$,\n  \u2022 $\\textrm{Ext}^1_B(\\Omega_{B/k},B)$.\n\nI attempted to determine $\\textrm{coker }\\alpha$, but now I'm stuck.\n\nWhat I did was just to translate the maps explicitly. So for instance $I/I^2$ is a principal module generated by $\\overline f=f+I^2$, so $$d:\\overline f\\mapsto 2y\\,dy-3x^2\\,dx.$$ This is useful to determine $\\alpha$. The source is generated by two vector fields $\\partial/\\partial x$ and $\\partial/\\partial y$, so: \\begin{align} \\alpha: &\\partial/\\partial x\\mapsto (\\overline f\\mapsto \\partial f/\\partial x=-3x^2),\\\\ \\alpha: &\\partial/\\partial y\\mapsto (\\overline f\\mapsto \\partial f/\\partial y=2y). \\end{align}\n\nNow, as $I/I^2$ is a principal module, we get an identification $(\\star)$ $$\\textrm{coker }\\alpha=\\hom_B(I/I^2,B)/\\textrm{Im }\\alpha\\overset{(\\star)}{\\cong} B/(-3x^2,2y)\\cong k[t^2,t^3]/(t^4,t^6).$$\n\nI cannot go further, and I remember having read on Moduli of Curves that this space should be $2$-dimensional. Can anyone help me to conclude?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe quotient $B/(-3x^2,2y) \\cong B/(x^2,y) = k\\langle 1, x \\rangle$.\n\nA mini-versal deformation is given by $x^3 + y^2 + ax + b$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/65202/how-to-prove-log-n-n?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nSorry if this is a silly question but most books claim $\\log n < n$ for $n \\geq 1$ without providing any proof, saying it's too obvious. Could someone give me a rigorous proof? Is there some trick or method I forgot about?\n\nshare|improve this question\nIn fact, $\\log x \\leq x-1$ for any $x \\geq 0$. This is equivalent to the inequality $1+t \\leq e^t$ for all $t \\in \\mathbb R$. \u2013\u00a0 Srivatsan Sep 17 '11 at 3:06\nHint: $e^x = 1 + x + x^2/2 + x^3/6 ... > 1 + x$ when $x>0$. \u2013\u00a0 Thomas Andrews Sep 17 '11 at 4:19\nSee this question for proofs that for all $t\\gt 0$, $\\log t\\leq t-1$, which implies the question you have. So this looks like a duplicate. \u2013\u00a0 Arturo Magidin Sep 17 '11 at 4:57\n\n6 Answers 6\n\nup vote 14 down vote accepted\n\nIf we let $f(n) = \\log n$ and $g(n) = n$, then $f'(n) = \\frac{1}{n}$ and $g'(n)=1$. Since $f(1) < g(1)$ and $f'(n) \\leq g'(n)$ for $n \\geq 1$, we must have $f(n) < g(n)$ for all $n \\geq 1$.\n\nThe idea in the last sentence is sometimes called the racetrack principle: If $f(n)$ and $g(n)$ denote the positions of horses $f$ and $g$ at time $n$, horse $f$ starts behind horse $g$ (i.e, $f(1) < g(1)$), and at any given time horse $f$ is never faster than horse $g$ (i.e, $f'(n) \\leq g'(n)$) then horse $f$ will always be behind horse $g$ (i.e, $f(n) < g(n)$ for $n \\geq 1$).\n\nOP asks for a proof of the racetrack principle.\n\nThe racetrack principle: If $f(a) < g(a)$ and $f'(n) \\leq g'(n)$ for $n \\geq a$, then $f(n) < g(n)$ for $n \\geq a$.\n\nProof: Let $h(n) = f(n) - g(n)$. Then $h'(n) = f'(n) - g'(n) \\leq 0$. The mean value theorem tells us that there exists some point $x \\in [a,n]$ such that $$h'(x) = \\frac{h(n) - h(a)}{n-a}.$$ Since we know the claim is true for $n=a$, take $n > a$. We already know $h'(x) \\leq 0$, so we get $h(n) - h(a) \\leq 0$, which means $f(n) - g(n) \\leq f(a) - g(a) < 0$, and so $f(n) < g(n)$ for $n \\geq 1$.\n\nshare|improve this answer\nOops - cross-posted the same thing. Sorry! \u2013\u00a0 Billy Sep 17 '11 at 3:06\nHow do I prove this general theorem? Is it possible to do using the Big-O definition? \u2013\u00a0 Mark Sep 17 '11 at 3:08\n@Mark: I'll add a proof. \u2013\u00a0 Mike Spivey Sep 17 '11 at 3:12\nOn the account of your proof,I guess we can call it a variation of racetrack principle :-) \u2013\u00a0 VelvetThunder Sep 17 '11 at 3:35\n\nHow rigorous do you need? If it's rigorous enough in your context, prove that log(1) < 1 (shouldn't be hard!), and then show that the derivative of log(x) is less than or equal to the derivative of x for all $x \\geq 1$.\n\nshare|improve this answer\nCould you prove this using Big-O definition? \u2013\u00a0 Mark Sep 17 '11 at 3:16\n@Mark: No, this isn't what big O notation is about. Big O describes limiting behaviour (e.g. as two functions go to infinity), and says nothing about what they do elsewhere. \u2013\u00a0 Billy Sep 17 '11 at 3:18\nYou are right, but I wonder how one should prove this without using calculus. Are there more primitive tools? \u2013\u00a0 Mark Sep 17 '11 at 3:21\n@Mark: That depends on how you define the natural logarithm in the first place. The most direct definitions I am aware of, either as $\\log x = \\int_1^x dt/t$, or as the inverse of the exponential function defined as $d/dx \\exp x = \\exp x$ and $\\exp 0 = 1$, are definitions which themselves require calculus. \u2013\u00a0 Rahul Sep 17 '11 at 3:57\n\njust simply look at the function $f(t)=t-log(t)$. You can show that this function is always increasing and that $f(n)\\ge f(1)=1$ for every $n$.\n\nshare|improve this answer\n\nI will assume that by $\\log n$ we mean the natural logarithm of $n$.\n\nIf $b > 1$, then $\\log b$ is the area under the curve $y=1/x$, above the $x$-axis, from $x=1$ to $x=b$.\n\nThis area is clearly less than the area of the rectangle with base $b-1$ and height $1$, so $\\log b <b-1$.\n\nComment: It is not uncommon in calculus courses to define $\\log b$ as above, and then introduce the exponential function. If we want to make the argument rigorous, we would probably introduce the definite integral before introducing the derivative, and define $\\log b$ as $\\int_1^b \\frac{1}{t} dt$. The inequality we need is an easy consequence of the definition of Riemann integral.\n\nshare|improve this answer\n\nFor $n\\geq 1$, $\\log n < n$ iff $n < e^n = 1 + n + n^2/2! + n^3/3! + \\cdots$\n\nshare|improve this answer\n\nIn your comments you seem ask about this in the context of the big O notation -- e.g., the concept frequently used in computer science that when analyzing an algorithm for time (or resource consumption like RAM). In big O notation, the following order appears (with constant time as best, and exponential time being worst):\n\n  \u2022 $O(1)$ - constant time\n  \u2022 $O(\\log N)$ - logarithmic\n  \u2022 $O(N)$ - linear\n  \u2022 $O(N \\log N)$ - loglinear\n  \u2022 $O(N^2)$ - quadratic (followed by other polynomial times e.g., $O(N^3)$ - cubic, etc.)\n  \u2022 $O(2^N)$ - exponential time\n\nYou aren't going to come up with a mathematical proof for this ordering that shows for every $N$ that a $O(\\log N)$ function will be smaller than every $O(N)$ function, because it simply isn't true. To demonstrate with a counterexample, let $f(N) = 10^{100} \\log N$ (an $O(\\log N)$ algorithm; you ignore the constant multiplier), and let $g(N) = N$ ($O(N)$ algorithm). While $N \\lt 10^{98}$, $f$ the logarithmic function will be larger (and hence slower; less optimal) than $g$ the linear-time function, opposite to what you usually expect.\n\nThe point of big O notation is that the scaling what usually matters most is how the functional will scale for large N. Comparing any logarithmic and linear function, the logarithmic function will always be smaller than the linear function for all values of $N$ larger than some finite number. You would say that a $O(\\log N)$ function grows asymptotically slower than a $O(N)$ function.\n\nNote in many cases like comparing $f(N) = N$ and $g(N) = \\log N$ it will be true over the entire domain of $N$ (equivalent to $N \\gt 0$).\n\nThe power of big-O notation is that is if you know you have an $O(N)$ and an $O(\\log N)$ function and both take 2 seconds to do when $N = 100$, when you need to process $N = 100000$ cases, the O(N) function will worst-case take roughly 2000 seconds, but the $O(\\log N)$ function will take only about 5 seconds.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/131648/even-more-generalized-catalan-numbers/131656\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the number of ways to parenthesize $n$ elements using applications of operators of arbitrary arities larger than or equal to $2$? For example, for $n=3$, there are $3$ ways: $$ abc, a(bc),(ab)c $$ and for $n=4$ there are 11 ways: $$ abcd,\\ ab(cd),\\ a(bc)d,\\ (ab)cd ,\\ a(bcd), (abc)d,$$ $$ a(b(cd)),\\ a((bc)d),\\ (ab)(cd),\\ (a(bc))d,\\ ((ab)c)d $$ Note that, if we restrict the operators to have arity $2$ (i.e. binary operators), then the answer would be given by the Catalan number $C_{n-1}$. (More generally, if we restrict the operators to have arity $p$, the answer would be given by generalized Catalan numbers. So the point here is that the arity is arbitrary, corresponding to a situation where I can select between operators of arities 2,3,4,...\n\nAn aymptotic formula for $n\\to\\infty$ would also be highly appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nA little bit of programming and a look up in the OEIS tells me that this is the sequence A001003, the solution to Schroeder's second problem, see also Wikipedia.\n\nAccording to the page in OEIS, the asymptotic form is $$ \\frac{n^{-3/2}}{4}\\sqrt{\\frac{\\sqrt{18}-4}{\\pi}}(3+\\sqrt{8})^n. $$\n\nshare|improve this answer\nThe wikipedia is clickable in this notation: en.wikipedia.org/wiki/Schr%C3%B6der%E2%80%93Hipparchus_number \u2013\u00a0 Gottfried Helms May 24 '13 at 1:10\nJust was I was looking for. Thank you! \u2013\u00a0 Esben May 24 '13 at 7:03\nBy the way, if you take just the first four terms in the sequence (1,1,3,11) and put them into OEIS, the first suggestion (out of 191) that comes up is in fact the right answer. OEIS is incredibly useful for these types of questions. \u2013\u00a0 Kirill May 24 '13 at 17:50\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/41784/roots-of-permutations/41866\nText:\nTake the 2-minute tour \u00d7\n\nConsider equation $x^2=x_0$ in symmetric group $S_n$, where $x_0\\in S_n$ is fixed. Is it true that for each integer $n\\geq 1$, the maximal number of solutions (square roots) has identity permutation? How far may it be generalized?\n\nshare|improve this question\nI assume x_0 and x_o are the same? Also \"identical permutation\" means \"identity permutation\"? \u2013\u00a0 JBL Oct 11 '10 at 13:52\nof course, thank you \u2013\u00a0 Fedor Petrov Oct 11 '10 at 14:19\nThe number of $k$-th roots of a permutation is the number of ways to collect its cycles into tuples according to certain rules. At least for prime $k$, I think it follows immediately that the maximum is achieved at the identity permutation. \u2013\u00a0 JBL Oct 11 '10 at 14:34\n\n2 Answers 2\n\nup vote 32 down vote accepted\n\nThe maximum of the function counting square roots is attained at $x_0=1$ and this statement generalises quite well.\n\nLet $s(\\chi)$ denote the Frobenius-Schur indicator of the irreducible character $\\chi$. Thus, $s(\\chi)=1$ if the representation of $\\chi$ can be realised over $\\mathbb{R}$, $s(\\chi)=-1$ if $\\chi$ is real-valued but the corresponding representation is not realisable over $\\mathbb{R}$ and $s(\\chi)=0$ if $\\chi$ is not real-valued. Then, the number of square roots of an element $g$ in any group is equal to $$\\sum_\\chi s(\\chi)\\chi(g),$$ where the sum runs over all irreducible characters of the group. See below for a quick proof of this identity.\n\nOf course, in $S_n$, all Frobenius-Schur indicators are 1, so the number of square roots of $x_0$ is just $\\sum_\\chi \\chi(x_0)$. This proves that the maximal number of solutions is indeed attained by $x_0 = 1$, since each character value attains its maximum there. This generalises immediately to any group, for which any representation is either realisable over $\\mathbb{R}$ or has non-real character, e.g. all abelian groups. Other cases would require more thought, but this is likely the right way to go about it.\n\nEdit: One reference I have found for the identity expressing the number of square roots in terms of Frobenius-Schur indicators is Eugene Wigner, American Journal of Mathematics Vol. 63, No. 1 (Jan., 1941), pp. 57-63, \"On representations of certain finite groups\". Once you get used to the notation, you will recognise it in displayed formula (11). Since the notation is really heavy going, I will supply a quick proof here:\n\nClaim: If $n(g)$ is the number of square roots of an element $g$ of a finite group $G$, then we have $$n(g) = \\sum_\\chi s(\\chi)\\chi(g),$$ where the sum runs over all characters of $G$ and the Frobenius-Schur indicator of $\\chi$ is defined as $s(\\chi)=\\frac{1}{|G|}\\sum_{h\\in G}\\chi(h^2)$.\n\nProof: It is clear that $n(g)$ is a class function. So let's just take inner products with all characters of $G$ to find their coefficients, noting that we can write $n(g) = \\sum_h \\delta_{g,h^2}$ (here $\\delta$ is the usual Kronecker delta): $$ \\begin{align*} \\left< n,\\chi \\right> &= \\frac{1}{|G|}\\sum_{g\\in G}n(g)\\chi(g) = \\frac{1}{|G|}\\sum_{g\\in G}\\sum_{h\\in G}\\delta_{g,h^2}\\chi(g)=\\\\\\\\ &=\\frac{1}{|G|}\\sum_{h\\in G}\\sum_{g\\in G}\\delta_{g,h^2}\\chi(g) = \\frac{1}{|G|}\\sum_{h\\in G}\\chi(h^2) \\end{align*}$$ as required.\n\nEdit 2: I got curious and ran a little experiment. The proof above applies to all finite groups that have no symplectic representations. So the natural question is: what happens for those that do? Among the groups of size $\\leq 150$, there are 1911 groups that have a symplectic representation, and for 1675 of them, the square root counting function does not attain its maximum at the identity! There are several curious questions that impose themselves: is there a similar (representation-theoretic?) 2-line criterion that singles out those 300-odd groups that satisfy the conclusion but not the assumptions of the above proof? What happens for the others? Can we find an if and only if characterisation that provides more insight into the structure of the groups, whose square root counting functions is maximised by the identity? Following Pete's suggestion, I have started two follow-up questions on this business: one on square roots and one on $n$-th roots.\n\nshare|improve this answer\nWow, neat: I didn't see that coming at all. Do you have a reference for your identity? \u2013\u00a0 Pete L. Clark Oct 11 '10 at 14:55\nSee also Exercise 7.69 of my book Enumerative Combinatorics, vol. 2. In particular, part (c) asserts that if $k$ is a positive integer and $r_k(w)$ is the number of $k$th roots of $w\\in S_n$, then $r_k$ is a character of $S_n$. It follows that $r_k$ takes its maximum value at the identity permutation. \u2013\u00a0 Richard Stanley Oct 11 '10 at 15:26\n@Alex: Your Edit 2 seems very interesting. I doubt it is getting optimal exposure here: please consider asking it as as a separate question. \u2013\u00a0 Pete L. Clark Oct 13 '10 at 16:48\nPete, thank you for your encouragement! I might do that, but not now, since posting questions at 3 in the morning is asking for embarrassing situations. \u2013\u00a0 Alex B. Oct 13 '10 at 17:48\n\nTwo your last question - \"how far may it be generalized\" - Richard Stanley answered when you fix the equation ($X^2=c$) and vary the group. You may also wonder about other equations. The situation is interesting: There are equations and groups with the property that the identity is not the RHS yielding the most solutions. This is so even though the LHS has no constants, just variables.\n\nOne may rephrase the question as follows: given a word $w=w(X_1,X_2,\\ldots,X_r)$ in the free group $F_r$ with variables $X_1,\\ldots,X_r$, and given any finite group $G$, one may naturally consider $w$ as inducing a function $G^r \\to G$ by plugging elements of $G$ as variables. This in turn defines a probability distribution on $G$: if you plug uniform random elements, what do you get? The most likely outcome is often, but not always, the identity.\n\nIn fact, the probability of getting the identity can be made arbitrarily small iff the group is non-solvable. I circulated this as a conjecture some years ago and it was proven by Miklos Abert (for the non-solvable case) and Nikolov and Segal (for the solvable one).\n\nshare|improve this answer\nIn fact, Richard Stanley didn't fix the equation. He is talking about equations of the form $x^k = c$ in $S_n$. \u2013\u00a0 Alex B. Oct 12 '10 at 8:39\nTrue. My answer attempts to generalize further into equations in several variables. \u2013\u00a0 Alon Amit Oct 12 '10 at 18:44\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/58972/probability-of-preserving-connectivity-between-pair-of-vertices-in-weighted-grap\nText:\nTake the 2-minute tour \u00d7\n\nLet $G=(V,E)$ be an undirected graph and $p \\colon E \\mapsto (0,1]$ defines weights of its edges.\n\nLet's fix two connected vertices $v_1, v_2 \\in V$.\n\nRandom graph $G'=(V,E')$ is obtained from $G$ by removing each edge $e \\in E$ with probability $1-p(e)$.\n\nWhat is the probability that connectivity between $v_1$ and $v_2$ is preserved in $G'$?\n\nshare|improve this question\nThis looks hopeless to have a nice formula isn't it ? \u2013\u00a0 camomille Mar 20 '11 at 14:39\nYou definitely must tell more about the graph (and about the weight function) to get any answer at all. Compare the case of the line graph with $v_1$ and $v_2$ far apart to the case of the complete graph on $n$ vertices with $n$ large. \u2013\u00a0 Did Mar 20 '11 at 14:52\n@Didier well, you right, that's implied part of the question -- if there are no nice results for arbitrary graph, maybe there are any non-trivial classes of graphs, where this problem is trackable? In my context it would be randomly generated scale-free network with number of edges that makes the brute force method unfeasible. \u2013\u00a0 alyst Mar 20 '11 at 17:33\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet L be the set of all simple paths in G from $v_1$ to $v_2$. By inclusion-exclusion, the probability that $v_1$ and $v_2$ are connected is\n\n$\\sum_{A \\subseteq L} (-1)^{|A|-1} P(\\cup A \\subseteq E')$\n\nwhere for any set S of edges, $P(S \\subseteq E') = \\prod_{e \\in S} p(e)$.\n\nAlthough explicit computation won't be feasible for large graphs, under appropriate conditions this might be used to get asymptotics.\n\nshare|improve this answer\nThanks, Robert. That gives an idea for an alternative formula: if $M$ is a collection of all minimal sets of edges, which removal disrupts connectivity between $v_1$ and $v_2$, then $1 - \\sum_{B \\subseteq M} (-1)^{|B|-1} P(\\cup B \\not\\subseteq E')$ should also be the sought probability, where $P(S \\not\\subseteq E') = \\prod_{e \\in S} (1-p(e))$. \u2013\u00a0 alyst Mar 20 '11 at 21:28\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/trigonometric-substitution.264934/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nTrigonometric substitution\n\n  1. Oct 16, 2008 #1\n    Hello, I have been wokring on this problem for some hours now, and I get the wrong answer, but I can't understand why, could you guys please look at it?\n  2. jcsd\n  3. Oct 16, 2008 #2\n    I should probably mention that the answer is supposed to be:\n\n    2*arctan(2x)+4x/(4x^2+1) +C\n  4. Oct 16, 2008 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    I didn't go through that in detail but it looks like a very strange way to attack the problem! You have a square of a square and you write it as a fourth power of a square root of a square so you can apply a trig substitution!\n    You don't need the square root to apply a trig substitution. Let 2x= tan t and 4x2+ 1= tan2 t+ 1= sec2. (4x2+ 1)2= sec4 t and 2dx= sec2 t dt. Your integral becomes\n    [tex]\\int\\frac{8dx}{(4x^2+ 1)^2}= \\int \\frac{4dt}{sec^2 t}= 4\\int cos^2 t dt[/itex]\n    That should be easy.\n\nHave something to add?\n\nSimilar Discussions: Trigonometric substitution"}
{"text": "Retrieved from http://math.stackexchange.com/questions/370862/find-a-best-fit-line-through-a-point-cloud-that-goes-through-a-specific-point\nText:\nTake the 2-minute tour \u00d7\n\nI'm not a mathematician so I hope I ask this question properly; I apologize for anyone who is annoyed with how I ask it (I will try my best to be precise).\n\nSay I have a point cloud in $\\Re^3$. I wish to fit a line through to this point cloud. However - and this is the kicker - I wish to force the line through a specified point in the point cloud; that is, I wish to find a vector through a point I specify which minimizes the distance squared from all the points in the cloud to the line spanned by the vector. Does this make sense?\n\nIf I were explaining this to a non-mathematician (like me), I would say I want to \"anchor\" a line on one of the points and then best fit the line from there.\n\nI understand the notion of ordinary least squares, but this particular spin on the problem doesn't make sense to me.\n\nThanks in advance, Ben\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nThis notion makes sense. You still have two degrees of freedom for the line, which can be two angles we will call elevation $(E)$ and azimuth $(A)$. It is easiest if you move the origin to the anchor point by subtracting the coordinates of the anchor points from each of the points in the cloud. Then your line has parameterization $t(\\sin E \\cos A, \\sin E \\sin A, \\cos E)$ if you measure $E$ up from the $xy$ plane and $A$ counterclockwise from the $X$ axis. Now you can find the distances from each other point in the cloud to the line using this formula where the vector I gave is $\\bf n$, square them, and add them up. Now use a 2D function minimizer on $A,E$. Depending on the points, there may be local minima to fool you.\n\nshare|improve this answer\nThanks! I will try this out and post the results here for the sake of posterity. \u2013\u00a0 user74039 Apr 23 '13 at 22:52\nLike ordinary least squares, there are no \"local\" minima distinct from the global minimum (though in degenerate cases the location of the global minimum may not be unique). Differentiating the sum of squares \"errors\" with respective to the unknown parameters gives a (homogeneous) linear system to solve. \u2013\u00a0 hardmath Apr 26 '13 at 0:27\nadd comment\n\nRoss Millikan's solution will work. To get the exact answer, probably faster, you can modify a solution for finding the 3D line of best fit (without an anchor point). The way that works is you compute the covariance matrix of the point cloud and the line of best fit is the line through the centroid in the direction of the eigenvector associated with the largest eigenvalue.\n\nTo modify this solution for the current problem, you can do the same thing, only when you're computing the covariance matrix, you subtract the anchor point from each point in the point cloud, rather than subtracting the centroid.\n\nshare|improve this answer\nadd comment\n\nThe least squares fit of a line/plane/etc. with an additional constraint of passing through a specified point is usually reduced to the case where that point is the origin (subtract the specified point from all data and fit a linear homogenous function). In this connection such model fitting is called \"regression through the origin\" (RTO) to quickly distinguish it from ordinary least squares (OLS).\n\nSome references and discussions are given in Answers to this previous Question.\n\nNote that the number of parameters for a line and a plane surface in 3D are equal, but there is a difference in what the nearest distance to the line or the plane is. Passing through the origin makes the fitted model a subspace, so the nearest distance is given by (subtracting) the orthogonal projection of each data point onto the subspace.\n\nLike ordinary least squares one gets a system of linear equations to solve for the unknown parameters, but the system is homogeneous. One is therefore solving for a nontrivial solution to a problem like $Au = 0$, and since there are only three unknowns speed of solution is not an issue.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/54723/commutator-formulas-in-a-universal-enveloping-algebra\nText:\nTake the 2-minute tour \u00d7\n\nI am interested in finding formulas for commutators of symmetrized monomials in a universal enveloping algebra. Let $C(x_1,\\ldots, x_n)= (1/n!)\\sum x_{\\sigma(1)}\\cdots x_{\\sigma(n)}$ where the sum runs over all permutations, and $x_i \\in L$ for some LIe algebra $L$. This is an element of $UL$.\n\nNow, reasonable combinatorics shows that, in $UL$, we have,\n\n$ [C(x_1,\\ldots, x_n), l] = \\sum_{i=1}^n C(\\ldots,[x_i,l],\\ldots) $\n\nfor $l\\in L$.\n\nI am looking for formulas for $[C(x_1,\\ldots, x_n), C(y_1,\\ldots, y_m)]$ in terms of symmetrized monomials and brackets. Even for $n=m=2$ the number of terms gets fairly large. If anyone knows where I can find such things I would be very grateful.\n\nshare|improve this question\nWhat is exact formulas for the case $n=m=2$? \u2013\u00a0 Melania Feb 8 '11 at 6:54\nPresumably you are working over an arbitrary field of characteristic 0 here. As Melania comments, one should try to answer the question first for products of length 2. Anyway I can't visualize an illuminating general answer, since the symmetrization process already depends so heavily on the specific nature of the bracket in the Lie algebra. Maybe in very special cases a good formula could be written down? \u2013\u00a0 Jim Humphreys Feb 8 '11 at 14:09\nadd comment\n\n1 Answer\n\nThis is probably not yet a final answer but may shine some additional light on the problem: For simplicity, I assume that $L$ is finite-dimensional and defined over the reals (for some other field of char $0$, the following should still work).\n\nThe symmetrization map can be viewed as a linear map \\begin{equation} \\sigma\\colon \\mathrm{S}(L) \\longrightarrow \\mathrm{U}(L) \\end{equation} from the symmetric algebra over $L$ into the universal envelopping algebra. It is now possible (essentially via PBW) to show that this is a fitration compatible linear bijection. Thus it allows to pull-back the product of $\\mathrm{U}(L)$ to $\\mathrm{S}(L)$. The result is the star product of Gutt / Drinfel'd (both in 1983, I guess). A further canonical isomorphism yields that the symmetric algebra is nothing else than the poylnomials on the dual $L^*$ (suppose $L$ is finite-dimensional for convenience) Thus your question is equivalent to the following task:\n\nWhat is the Gutt star product commutator of two (homogeneous) polynomials on $L^*$?\n\nGutt has computed many properties of this star product and fan almost explicit formula. However, it essentially involved the full BCH series of $L$, so my guess is that a complete answer might be as complicated as computing BCH.\n\nThe Gutt star product can be characterized nicely as follows: take $x, y \\in L$ and view them as linear polynomials on $L^*$ as usual. Then form the formal exponential functions $e_{\\hbar x} (\\alpha) = \\exp(\\hbar \\alpha(x))$ and similarly for $e_{\\hbar y}$ where $\\hbar$ is your formal parameter. Then $\\star_{\\mathrm{Gutt}}$ is uniquely determined by \\begin{equation} e_{\\hbar x} \\star_{\\mathrm{Gutt}} e_{\\hbar y} = e_{\\mathrm{BHC}(\\hbar x, \\hbar y)} \\end{equation} I hope I got the signs right :) You can find this formulas also in Section 8 of q-alg/9707030 (published in Commun. Math. Phys.). There are many more papers on the Gutt star product, so a little MRsearch will probably give some addition info.\n\nThe solution of your problem is now obtained by differentiating the above equation with respect to $\\hbar$ sufficiently often and use polarization afterwarts. But as I sad, you need to know BCH quite well to efficiently do that. In the end you take commutators\\ldots\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/269478/non-constant-bounded-holomorphic-function-on-some-open-set\nText:\nTake the 2-minute tour \u00d7\n\nthis is an exercise I came across in Rudin's \"Real and complex analysis\" Chapter 16.\n\nSuppose $\\Omega$ is the complement set of $E$ in $\\mathbb{C}$, where $E$ is a compact set with positive Lebesgue measure in the real line.\n\nDoes there exist a non-constant bounded holomorphic function on $\\Omega$?\n\nEspecially, do this for $\\Omega=[-1,1]$.\n\nSome observations:\n\nSuppose there exists such function $f$, then WLOG, we may assume $f$ has no zeros points in $\\Omega$ by adding a large enough positive constant, then, $\\Omega$ is simply-connected implies $\\int_{\\gamma}fdz=0$, for any closed curve $\\gamma\\subset \\Omega$, how to deduce any contradiction?\n\nshare|improve this question\nWhy do you say that $\\Omega$ is simply connected? // You are going in the wrong direction: such a function exists on any domain with complement of positive measure on the line. Think of the Cauchy integral formula. // In the case of $E=[-1,1]$ (you have a typo there in the question) it's possible to find it explicitly using conformal maps. \u2013\u00a0 user53153 Jan 3 '13 at 0:16\n@Pavel M, the function constructed using Cauchy integral formula is not bounded on $\\Omega$, this is the first several questions before this one on the book, you can check it. That is why Rudin post this question on the book. \u2013\u00a0 ougao Jan 3 '13 at 0:23\nMaybe it depends on how you use the Cauchy integral. Anyway, here's an example for $E=[-1,1]$: the conformal map $g(z)=\\frac12(z+z^{-1})$ sends the unit disk onto the complement of $E$. Therefore, its inverse $f=g^{-1}$ is bounded by $1$ on the complement of $E$. // At least this shows that your attempt to find a contradiction could not work. \u2013\u00a0 user53153 Jan 3 '13 at 0:37\nYou are correct, I double checked the problem, and found I have made a silly typo, in fact, I want to know whether there exists a non-constant bounded holomorphic(not just analytic) function, sorry for the confusion. \u2013\u00a0 ougao Jan 3 '13 at 1:06\nDoes not change anything in my replies. I assumed you wanted a holomorphic function from the beginning. \u2013\u00a0 user53153 Jan 3 '13 at 1:34\nshow 2 more comments\n\n1 Answer\n\nup vote 6 down vote accepted\n\nReading Exercise 8 of Chapter 16, I imagine Rudin interrogating the reader.\n\nLet $E\\subset\\mathbb R$ be a compact set of positive measure, let $\\Omega=\\mathbb C\\setminus E$, and define $f(z)=\\int_E \\frac{dt}{t-z}$. Now answer me!\na) Is $f$ constant?\nb) Can $f$ be extended to an entire function?\nc) Does $zf(z)$ have a limit at $\\infty$, and if so, what is it?\nd) Is $\\sqrt{f}$ holomorphic in $\\Omega$?\ne) Is $\\operatorname{Re}f$ bounded in $\\Omega$? (If yes, give a bound)\nf) Is $\\operatorname{Im}f$ bounded in $\\Omega$? (If yes, give a bound)\ng) What is $\\int_\\gamma f(z)\\,dz$ if $\\gamma$ is a positively oriented loop around $E$?\nh) Does there exist a nonconstant bounded holomorphic function on $\\Omega$?\n\nPart h) appears to come out of the blue, especially since $f$ is not bounded: we found that in part (e). But it is part (f) that's relevant here: $\\operatorname{Im}f$ is indeed bounded in $\\Omega$ (Hint: write it as a real integral, notice that the integrand has constant sign, extend the region of integration to $\\mathbb R$, and evaluate directly). Therefore, $f$ maps $\\Omega$ to a horizontal strip. It's a standard exercise to map this strip onto a disk by some conformal map $g$, thus obtaining a bounded function $g\\circ f$.\n\nshare|improve this answer\nthanks, I should be more careful to deal with part (f). \u2013\u00a0 ougao Jan 3 '13 at 14:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/1660/direct-proof-of-gelfand-zetlin-identity/2823\nText:\nTake the 2-minute tour \u00d7\n\nDenote by $D(a_1,\\dots,a_n)$ the product $\\prod_{j>i}(a_j-a_i)$. Assuming that $a_i$ are integers s.t. $a_1\\le a_2\\le\\dots\\le a_n$, proove that $D(a_1,...,a_n)/D(1,...,n)$ is the number of Gelfand-Zetlin triangles (that is, triangles consisting of $\\frac{n(n+1)}2$ integers, s.t. each number is greater it's lower-left neighbor but not greater than lower-right neighbor) with the base $a_i$.\n\nFor example, for n=3 one needs to prove that number of b1, b2, b' s.t. $a_1\\le b_1<a_2\\le b_2<a_3$, $b_1\\le b'<b_2$ is exactly $\\frac{(a_3-a_2)(a_3-a_1)(a_2-a_1)}{3}$.\n\nAs one can guess from the name \u201cGelfand-Zetlin\u201d, this fact is well-known in representation theory (namely, in LHS we count dimension of a $gl_n$-representation by Weyl formula, and in RHS we count elements in Gelfand-Zetlin basis of the same representation). But maybe someone can come with more or less direct proof? (Some kind of bijective proof, maybe.)\n\nInformal probabilistic argument\n\nFor simplicity, consider the case $n=3$: D(a_1,a_2,a_3) counts the number of triangles s.t. $a_1\\le b_1<a_2\\le b_2<a_3$, $a_1\\le b'<a_3$ \u2014 and we're interested only in G-Z triangles, i.e. in triangles s.t. $b_1\\le b'< b_2$. Now, mathematical expectation of the length of the interval $(b_1,b_2)$ is exactly one half of the length of the interval from which $b'$ is chosen. So one may expect that the probability that random triangle is G-Z is $1/2$ \u2014 and the answer is indeed $D(a_1,a_2,a_3)/D(1,2,3)$.\n\n(The main problem with this computation is that we're multiplying probabilities for events that are clearly not independent. And although for n=3 it's not hard to transform this heuristic argument into a formal proof, even for n=4 I failed to do such thing.)\n\nshare|improve this question\nThere is a beautiful identity I learned from Gjergji Zaimi (artofproblemsolving.com/Forum/viewtopic.php?f=590&t=290405) which is probably relevant here, but I haven't thought about how to complete the argument; I am guessing an inclusion-exclusion argument, possibly using the Lindstrom-Gessel-Viennot lemma. \u2013\u00a0 Qiaochu Yuan Aug 5 '10 at 22:06\nadd comment\n\n3 Answers\n\nup vote 3 down vote accepted\n\nAs Qiaochu points out the formula given by Gjergji Zaimi is certainly relevant. It realizes $D(a_1,\\ldots,a_n)/D(1,\\ldots,n)$ as the determinant of the $n$-by-$n$ matrix $M$ with $(i,j)$-entry $${a_i\\choose j-1}.$$ By row operations this equals the determinant of the $(n-1)$-by-$(n-1)$ matrix $N$ with $(i,j)$-entry $${a_{i+1}\\choose j}-{a_i\\choose j}.$$ The $i$-th row of $n$ is the sum of vectors $v_{a_i},v_{a_i+1},\\ldots,v_{a_{i+1}-1}$ where the $j$-th entry of $v_c$ is $${c\\choose j-1}.$$ By the multilinearity of the determinant as a function of its rows, $N$ is the sum the determinants with rows $v_{b_1},\\ldots,v_{b_{n-1}}$ where $a_1\\le b_i < a_2\\le b_2 < a_3\\le\\cdots$. These tuples $(b_1,\\ldots,b_{n-1})$ are precisely the admissible penultimate rows in GZ triangles with bottom row $(a_1,\\ldots,a_n)$. Hence both sides of the sought equality satisfy the same recurrence.\n\nshare|improve this answer\nCombinatorial interpretation (from a friend of mine): the determinant = the number of non-intersecting paths from points $0,1,\\dots,n-1$ on Y-axis to points $a_1,\\dots,a_n$ on X-axis = number of Gelfand-Zetlin triangles. \u2013\u00a0 Grigory M Aug 6 '10 at 15:06\nSee also: I. Gessel. Binomial determinants, paths, and hook length formulae in Adv. Math. (from non-intersecting paths to binomial determinant and computation of binomial determinant). \u2013\u00a0 Grigory M Aug 21 '12 at 17:42\nadd comment\n\nSchur polynomials proof\n\nObserve that $D(a_1,\\ldots,a_n)/D(1,\\ldots,n)=s_\\lambda(1,\\ldots,1)$ (for $a_i=\\lambda_i+i$). But by Giambelli (aka Jacobi-Trudi) formula $s_\\lambda=\\det h_{\\lambda_i+j-1}$, so $s_\\lambda(1,\\ldots,1)=\\det\\binom{a_i}{j-1}$. Now by Lindstrom-Gessel-Viennot lemma last determinant counts non-intersecting lattice paths from the set $0,1,\\ldots,n$ on Y-axis to the set $a_1,\\ldots,a_n$ on X-axis. Finally, observe that any such path is characterized by x-coordinates of \"steps down\" \u2014 which are subject to conditions from the definition of GZ triangle.\n\n/* Well, it's not that direct and it's more or less the proof from Robin Chapman's answer. Nevertheless, it explains something, I hope. */\n\nshare|improve this answer\nadd comment\n\nJust to make sure: you know that what you are asking for is actually Weyl's dimension formula for the highest weight representation in the case of SL(n,C) resp. SU(n)? I suppose there is no direct combinatorial proof that does not make use of this fact.\n\nshare|improve this answer\nWhy not? Many similar results about e.g. Young tableaux have purely combinatorial proofs. \u2013\u00a0 Qiaochu Yuan Aug 5 '10 at 22:31\nYes, LHS is the Weyl dimension formula for a representation of gl_n, and RHS is the number of elements in Gelfand-Zetlin basis in the same representation. \u2013\u00a0 Grigory M Aug 6 '10 at 7:47\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/26771/what-is-the-expected-number-of-steps-in-the-following-process\nText:\nTake the 2-minute tour \u00d7\n\nWe have $n$ boxes. And initially there are $x_1, x_2, x_3, \\ldots, x_n$ marbles in each box. We randomly (with equal probabilities) select one of the boxes. We take one marble from it and we put it into another (different from the origin) box chosen randomly (with equal probabilities). We continue this process until one of the boxes become empty. How many operations we do on average?\n\nIt is not a homework. I don't know whether a closed form solution exists. My current results are:\n\n\\begin{align}{} x_1 x_2 & \\text{ for } n=2\\\\ \\frac{3x_1 x_2 x_3}{x_1 + x_2 + x_3} & \\text{ for } n=3 \\end{align}\n\nI have crossposted in artofproblemsolving. This problem is related and maybe (or not) useful.\n\nUpdate2: As i learned: this problem has been studied before. As usual :) It seems very hard even for $n=4$. No explicit solution is known, only asymptotics for the case $f(x,x,x,x)$. Nevertheless the solution is much much more easier if we change slightly the problem. For example.\n\nBig thanks to Viktor for pointing the reference!\n\nshare|improve this question\nLooking at what you have for $n=2$ and $n=3$, my guess would be $\\frac{\\binom{n}{2}}{\\displaystyle \\sum_{i,j,i \\neq j}\\frac{1}{x_i x_j}}$ \u2013\u00a0 user17762 Mar 13 '11 at 20:33\nIt's beautiful but it seems that it does not pass the following test for $n=4$: $f(x,x,x,x)=f(x-1,x+1,x,x)+1$. \u2013\u00a0 Roah Mar 13 '11 at 21:21\n@Tomek The case $n=2$ is the usual one dimensional gambler's ruin problem. It is true, but not intuitively obvious, that for a symmetric random walk the expected number of steps needed to hit 0 is infinite, even starting at 1. Unless we hit 0 very soon, the random walk wanders far into the positives and then takes a long (but finite!) number of steps to reach 0. \u2013\u00a0 Byron Schmuland Mar 15 '11 at 0:22\nThat is N-player ruin problem. See: Y.Swan - A Matrix-Analytic Approach to the N-Player Ruin Problem \u2013\u00a0 Viktor Mar 15 '11 at 23:23\nThere is a paper arguing for why this is unlikely to have any closed form solution for N>3. projecteuclid.org/\u2026 \u2013\u00a0 user1708 Mar 18 '11 at 7:42\n\n1 Answer 1\n\nHere are some results for very small numbers, when there are $n$ variables: $$ \\begin{align*} f(1,1,1,\\ldots,1) &= 1, \\\\ f(2,1,1,\\ldots,1) &= \\frac{n}{n-1}, \\\\ f(3,1,1,\\ldots,1) &= \\frac{n^3-2n^2+3n}{n^3-3n^2+4n-2} = \\frac{n}{n-1} \\cdot \\frac{n^2-2n+3}{n^2-2n+2}, \\\\ f(2,2,1,\\ldots,1) &= \\frac{n^3-n^2+2n}{n^3-3n^2+4n-2} = \\frac{n}{n-1} \\cdot \\frac{n^2-n+2}{n^2-2n+2}. \\end{align*} $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/18613/handling-error-in-database-connection-timeconstrained?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI have a lot of scripts that use a database connection, and I have realized that my code should be protected against errors in my connection. For example, when my database is out for some technical reason.\n\nI tried to use this in a fake broke connection:\n\nsqlConn:=OpenSQLConnection[JDBC[\"Microsoft SQL Server(jTDS)\",\"\"],\"Username\"->\"myUser\",\"Password\"->\"myPass\"];\n(conn = TimeConstrained[sqlConn, 1]) // AbsoluteTiming\n\nBut without success as you can see. The 1 second argument is not respected. I get this:\n\n\"JDBC::error: Network error IOException: Operation timed out >>\"\n{76.518145, $Aborted}\n\nWolfram technical support asked me to try changing $SQLTimeout, but that did not work either.\n\nI tried before the last code:\n\n\nand the time restriction is also not respected.\n\nThey then told me:\n\n\"Most of the timeout functions in Mathematica takes into account only the CPU time spent inside the main Mathematica kernel process; it does not include additional threads or processes. And the time OpenSQLConnection spend is mostly on it's own thread.\"\n\nSome clue on how to deal with this?\n\nshare|improve this question\nWhat about throwing in a mention of TimeConstrained in the question title? \u2013\u00a0 Yves Klett Jan 28 '13 at 13:11\nAFAIK the $SQLTimeout variable is there exactly for that purpose. Can you explain what you have tried and why you think it does not work? \u2013\u00a0 Albert Retey Jan 28 '13 at 13:46\n@AlbertRetey Hi. Tks, I have made some changes to make it clearer in this topic. \u2013\u00a0 Murta Jan 28 '13 at 14:31\n@YvesKlett tks. Done! \u2013\u00a0 Murta Jan 28 '13 at 14:33\ndocumentation of $SQLTimeout is vague, but could be understand as if $SQLTimeout doesn't work for initiating the connection but only for queries. Have you tried that? Maybe this question is also of interest. As mentioned there you might need to change some settings for the network connection on the client or for the connection settings on the sql server. Another possibility would be to build something with the v9 asynchronouse tasks, but I haven't tried that... \u2013\u00a0 Albert Retey Jan 28 '13 at 15:00\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nI was able to reproduce your behaviour on Mathematica V9 64-bit under Windows 7. Neither TimeConstrained nor $SQLTimeout would work. However, an explicit \"Timeout\" option worked for me:\n\n, \"Username\" -> \"myUser\"\n, \"Password\" -> \"myPass\"\n, \"Timeout\" -> 1\n\nThe evaluation stopped with the message JDBC::error: Login timed out. after one second. Interestingly, this expression apparently made a persistent change to the DatabaseLink state because thereafter any attempt to open the database would time out after one second -- even if I did not specify the \"Timeout\" option! If I subsequently tried a longer explicit timeout setting, that longer value would then \"stick\" and be applied to all future connection attempts. It would seem that we are looking at a bug here. I cannot say that I am surprised however. The handling of timeouts and early cancellation of SQL transactions is notoriously unreliable in many, if not most, SQL software stacks. In our context here, we are doubly removed from SQL Server by both JDBC and DatabaseLink.\n\nIncidentally, it also does not surprise me that TimeConstrained fails here. In practice, I find that TimeConstrained sometimes has difficulty interrupting a process that engages in a blocking I/O operation (and the front-end does too).\n\n\nFurther investigation reveals that DatabaseLink is using the Java class java.sql.DriverManager to allocate non-pooled SQL connections. Furthermore, it is setting the loginTimeout property of this class in a persistent fashion. Therefore, we can adjust that property ourselves without actually attempting to open a connection thus:\n\n\n\nWe can query the current setting like this:\n\n\nThe same investigation also revealed that OpenSQLConnection only uses the $SQLTimeout global variable if we pass an invalid value for the \"Timeout\" option:\n\nBlock[{$SQLTimeout = 1}\n, OpenSQLConnection[\n    , \"Username\" -> \"myUser\"\n    , \"Password\" -> \"myPass\"\n    , \"Timeout\" -> \"invalid\"\n\nWe are even informed that the default will be used:\n\nOpenSQLConnection::timeout: Illegal value for Timeout option: invalid (continuing with default value)\n\nAll this, and more, can be found if one studies the files found in:\n\nFileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"Links\", \"DatabaseLink\"}] //\nshare|improve this answer\nTks a lot, nice answer! You beat Wolfram Suport. +1. Do you know how can I set back this parameter without make a new call? What is the default value? This persistent state is really annoying. \u2013\u00a0 Murta Jan 28 '13 at 16:59\n@Murta Yes, we can reset the parameter without opening a new connection -- see my update. \u2013\u00a0 WReach Jan 28 '13 at 17:36\n@WReach Thank you for this quite descent investigative reverse engineering. Thank you! \u2013\u00a0 Stefan Jan 28 '13 at 17:53\n\nIn Mathematica V10, the jtds driver was updated to version 1.3.1.\n\nNow the command:\n\n    , \"Username\" -> \"myUser\"\n    , \"Password\" -> \"myPass\"\n    , \"Timeout\" -> 3\n\nWill respect the 3 seconds limit.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/25505/what-is-int-0-12-dx-dy-mathcalp-frac-logxx-y?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the value of $$\\int_{[0,1]^2} \\!\\!\\!dx\\,dy\\,\\mathcal{P} \\frac{\\log(x)}{x-y},$$ where $\\mathcal{P}$ denotes Cauchy's principal value. I solved this once for a homework, but I can neither remember the answer nor reproduce it right now... (bad memory)\n\nAny help or comment is highly welcome.\n\nshare|improve this question\nwhat do you mean by principal value? you have infinite values along $y=x$ and $\\{0\\}\\times[0,1]$. how are you approaching those? \u2013\u00a0 yoyo Mar 7 '11 at 17:16\nThe logarithmic singularity at ${0}\\times [0,1]$ seems to be integrable. So only the pole at $x=y$ poses problems. Cauchy's princial value (en.wikipedia.org/wiki/Cauchy_principal_value) denotes the limit when this singularity is approached symetrically... \u2013\u00a0 Fabian Mar 7 '11 at 17:32\nMathematica tells me that the result is $\\pi^2/6$ [looks like $\\zeta(2)$]. Any thoughts why (or if) this is correct? \u2013\u00a0 Fabian Mar 7 '11 at 17:34\nCan you not take the Hilbert transform of $1_{[0,1]}$ and then compute the (principal value) integral of $\\log(x)$ times the result of that? \u2013\u00a0 Jonas Teuwen Mar 7 '11 at 21:30\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $f(x,y)=\\frac{\\log x}{x-y}$. Since the principal value does not seem well-defined here, let's integrate $f(x,y)+f(y,x)= \\frac{\\log (x/y)}{x-y}$ (which is positive) on the triangle defined by $0<y<x<1$. Now $\\int_0^x \\frac{\\log (x/y)}{x-y} dy = -\\int_0^1 \\frac{\\log u}{1-u} du$ (change of variable $y=xu$), which does not depend on $x$, and so this is equal to the first integral (integrating for $x$ between $0$ and $1$).\n\nNow $-\\int_0^{1-\\epsilon} \\frac{\\log u}{1-u} du = \\int_0^{1-\\epsilon} \\sum_{ n \\geq 1} \\frac{u^{n-1}}{n} du = \\sum_{n \\geq 1} \\frac{(1-\\epsilon)^n}{n^2}$ and letting $\\epsilon$ go to $0$ gives $\\zeta(2)=\\frac{\\pi^2}{6}$.\n\nshare|improve this answer\nWhy you think the principal value is not well defined? \u2013\u00a0 Fabian Mar 9 '11 at 18:22\nThe examples at the end of the Wikipedia page illustrate this fact, for a given integral you can get different values if you choose your epsilons differently. But most of the time if you make \"reasonable\" choices the result is the same: for example in your case if we integrate on a closed symetric (with respect to the diagonal) domain not containing the diagonal and if this domain \"converges\" to the whole of $[0,1]^2$. If we integrate wrt $y$ first, excluding $[x-\\epsilon,x+\\epsilon]$ (then $\\epsilon \\rightarrow 0$) we still find $\\zeta(2)$. But other choices would give different values. \u2013\u00a0 Plop Mar 9 '11 at 19:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/88728/factorizing-a-block-symmetric-matrix\nText:\nTake the 2-minute tour \u00d7\n\nLet $X,Y\\in\\mathbb{R}^{n\\times n}$ be symmetric matrices. You may assume that $X$ is positive semidefinite and $Y$ negative semidefinite, if needed, but not that they are invertible.\n\nI would like to find a way to factor the $2n\\times 2n$ block matrix $$ \\begin{bmatrix} X & I\\\\\\\\ I & Y \\end{bmatrix} $$ into some form of the kind $MDM^T$, where:\n\n  \u2022 $D$ should be a \"simple\" matrix, ideally diagonal or of the form $D=\\begin{bmatrix}0 & I\\\\\\\\I & 0\\end{bmatrix}$, or something similar;\n  \u2022 The factorization should take explicit advantage of the identities being there, without treating them as general matrices and thus depending on too many parameters, so the Cholesky factorization is ruled out.\n\nIs there some nice identity that I am missing?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAssuming that $X$ and $Y$ are invertible (if not, probably a perturbation argument will yield the generalization). Then, the following choice of $M$ works, i.e., $MDM^T$ equals your original matrix with $D$ being the anti-diagonal identity matrix as desired.\n\n(Also, note slightly different notation, I write $-Y$ instead of $Y$ as in the original question, so that both $X$ and $Y$ are positive).\n\nA solution is given by: \\begin{equation*} M = \\begin{bmatrix} a & b\\\\\\\\ c & d \\end{bmatrix}, \\end{equation*}\n\n\n\\begin{equation*} a = X^{1/2},\\quad b=\\frac{X^{1/2}}{2},\\quad c = X^{-1/2} - (X^{-1}+Y)^{1/2},\\quad d = \\frac{X^{-1/2} + (X^{-1}+Y)^{1/2}}{2}. \\end{equation*}\n\nEdit. Typo in $d$ fixed now.\n\nTo see that the above matrix provides a solution, simply verify\n\n\\begin{equation*} \\begin{bmatrix} a & b\\\\\\\\ c & d \\end{bmatrix}\\begin{bmatrix} 0 & I\\\\\\\\ I & 0\\end{bmatrix}\\begin{bmatrix} a^T & c^T\\\\\\\\ b^T & d^T\\end{bmatrix} = \\begin{bmatrix} X & I\\\\\\\\ I & -Y\\end{bmatrix}, \\end{equation*} which boils down to checking the following four equations: \\begin{eqnarray*} ad^T + bc^T &=& I\\\\\\\\ cb^T + da^T &=& I\\\\\\\\ ab^T + ba^T &=& X\\\\\\\\ cd^T + dc^T &=& -Y. \\end{eqnarray*}\n\nshare|improve this answer\nNice. I arrived at something similar using the Schur complement formula, but what I really would like to get rid of is the requirement of nonsingularity of X$... \u2013\u00a0 Federico Poloni Feb 17 '12 at 22:04\n@Federico: roughly speaking, won't using $X \\gets X + \\epsilon I$, doing the math with that, and then letting $\\epsilon \\to 0$ yield the desired answer? (I say that because originally, I had derived the answer in terms of matrix geometric means, which can be extended using the $\\epsilon$ trick). \u2013\u00a0 Suvrit Feb 18 '12 at 3:06\nYou're right, it does. \u2013\u00a0 Federico Poloni Feb 18 '12 at 20:38\nHmm, can you double-check that identity? Numerically it does not hold, and what is fishier is that $b=a/2$ and $d=c/2$, so your factor matrix $M$ has rank at most $n/2$. \u2013\u00a0 Federico Poloni Feb 20 '12 at 8:49\nI obtained another solution (the matlab code seems to require invertible $Y$) via Riccati equations: $d=I$, $c=-Y/2$, $BYB+2B=X$, and $A=I+BY/2$. I tested this solution in Matlab---works fine. Using similar ideas, I think one could overcome the dependence on $Y$ being invertible---by appropriately defining solutions to $BYB+2B=X$ for rank deficient $X$ and $Y$ (extreme case $X=0$ gives $B=0$, and $Y=0$ forces $B=X/2$, so maybe the method can be extended). \u2013\u00a0 Suvrit Feb 20 '12 at 22:45\n\nSuvrit's answer can be interpreted sort of as an application of the Cholesky factorization on the 2x2 block structure. I will add an answer that may help if $X$ and $Y$ share a similar sparsity structure. You can apply an interlacing permutation $P$ such that if your matrix is $A$, then $PAP^T$ interlaces the rows and columns from each of the two halves. You would have diagonal blocks like $$ \\begin{bmatrix} x_{ii} & 1 \\\\\\\\ 1 & y_{ii} \\end{bmatrix} $$ and off diagonal blocks like $$ \\begin{bmatrix} x_{ij} & 0 \\\\\\\\ 0 & y_{ij} \\end{bmatrix} $$ Now if $X$ and $Y$ are both sparse, the $LDL^T$ factorization likely exists since each diagonal 2x2 block is more likely full rank, so you can apply the factorization in 2x2 blocks.\n\nshare|improve this answer\nThose diagonal blocks being nonsingular is not a problem, since $x_{ii}\\geq 0$ and $y_{ii}\\leq 0$ under the semidefiniteness assumption. However, if I am not mistaken, after the first $LDL^T$ step, you need to take a Schur complement that spoils the $1$'s in your structure. \u2013\u00a0 Federico Poloni Feb 20 '12 at 10:19\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-about-ellipse.62405/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestion about Ellipse\n\n  1. Feb 3, 2005 #1\n\n    Here is a problem in coordinate geometry, in particular about the ellipse.\n\n    A point moves such that the sum of the squares of its distances from two intersecting straight lines is constant. Prove that its locus is an ellipse and find the eccentricity in terms of the angle between the straight lines.\n\n    My solution:\n\n    Without loss of generality we may assume the two straight lines to be [itex]y = 0[/itex] and [itex]y = mx[/itex] where [itex]m = \\tan\\phi[/itex] ([itex]\\phi[/itex] is the angle between the lines). Their point of intersection is thus the origin O(0,0).\n\n    Let the point whose locus is to be found be [itex]P(\\alpha,\\beta)[/itex]. The constraint on P is then,\n\n    [tex]\\beta^2 + \\frac{(m\\alpha - \\beta)^2}{m^2+1} = k^2 [/tex]\n\n    where k is some constant ([itex]k\\epsilonR[/itex])\n\n    This after some rearranging and replacing [itex](\\alpha,\\beta)[/itex] with with general coordinates [itex](x,y)[/itex] yields\n    [itex]m^2x^2 - 2mxy + y^2(m^2+2) - k^2(1+m^2) = 0[/itex]\n    which when compared with the general second degree equation,\n    [itex]Ax^2 + 2Hxy + By^2 + 2gx + 2fy + c = 0 [/itex]\n    does turn out to be an ellipse.\n\n    However it is not in the standard form, so finding its eccentricity is not as easy. Now I understand that by rotating the coordinate axes we can bring the equation into such a form by a suitable choice of the rotation angle which causes the cross term (H) to disappear. However, I want to know if there is some other way out to find the eccentricity (or more generally to do this problem).\n\n    I would be grateful if someone could offer some ideas.\n\n    Thanks and cheers\n  2. jcsd\n  3. Feb 3, 2005 #2\n    After posting this, I realized this probably isn't the right place for this post. For the moderator(s): if you think, could you please shift it to the right place. Sorry for the inconvenience...\n  4. Feb 5, 2005 #3\n    Someone please help!!\n  5. Feb 5, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    Dearly Missed\n\n    What's wrong with writing it in standard form?? :confused:\n  6. Feb 5, 2005 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I don't see any other way to extract the excentricity,other than knowing the semiaxes...You can do that simply applying the theory of conics and the set of linear transformations which bring the conic to a known form,in this case an ellipse.\n\n  7. Feb 6, 2005 #6\n    Okay thanks for your replies. Suppose that I live in a very weird world and I'm supposed to show that I can do this \"smartly\" but not in a lengthy way. How would I do it? :biggrin:\n\n    I know I can rotate the axes and do what I've said I can in the first post to get it in the standard form. But I was wondering if there's some other way out. Anyway thanks...\n\n  8. Feb 7, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    How about if i told you that the equation:\n    [tex] m^{2}x^{2}-2mxy+y^{2}(m^{2}+2)-k^{2}(m^{2}+1) [/tex](1)\n\n    is the EQUATION OF A CIRCLE...\n\n    The equation (1) can be written:\n    [tex](mx-y)^{2}+[y\\sqrt{m^{2}+1}]^{2} =[k\\sqrt{m^{2}+1}]^{2} [/tex] (2)\n\n    and making the rotation & the notation:\n    [tex] x'=:mx-y [/tex] (3)\n    [tex] y'=y\\sqrt{m^{2}+1} [/tex] (4)\n    [tex] R=:k\\sqrt{m^{2}+1} [/tex] (5)\n\n    is exactly the equation of a circle:\n    [tex] x'^{2}+y'^{2}=R^{2} [/tex] (6)\n\n    If this outcome is not correct,then it's your fault for providing an incorrect quadratic form... :wink:\n\n  9. Feb 8, 2005 #8\n    I do not know what you are trying to imply. The question and my working are before you. Do you believe the question is wrong?\n    Last edited: Feb 8, 2005\n  10. Feb 8, 2005 #9\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I don't know that.I've just shown you that the equation u came up with when substituting alpha & beta wiht x & y is the equation of a circle,and not of an ellipse.\n\n  11. Feb 8, 2005 #10\n    You could try assuming [itex]y = mx[/itex] and [itex]y = -mx[/itex] where [itex]m = \\tan\\phi/2[/itex]\n\n    This is squashing the coordinates, and so will transform a circle into an ellipse\n  12. Feb 8, 2005 #11\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Ups,you made me realize that what i had was not a genuine rotation and indeed i squashed \"y\" and so the initial ellipse became a circle... :frown:\n\n    I would have to stick to the initial advice,namely applying the theory of conics...\n\n  13. Feb 10, 2005 #12\n    Yes but the problem is to extract the eccentricity from the equation without reducing it to a standard form via rotation. However, as the problem stands now, I do not think there is any other method than to do it the brute force way. Thanks for your help though.\n\n\nHave something to add?\n\nSimilar Discussions: Question about Ellipse"}
{"text": "Retrieved from http://mathoverflow.net/questions/129879/filling-in-a-rational-orthogonal-matrix-given-one-row?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nQuick version: given natural $n$ and a row of $n$ integers such that the sum of the squares is another square, call it $m^2.$ For $n=5,6,7$ is it always possible to fill in the rest of an $n$ by $n$ matrix of integers, call it $M,$ so that $M M^T = m^2 I? $ If so, $M/m$ is rational orthogonal.\n\nNotes: this is true for $n=1,2,3,4,8.$ 1 is trivial 2 uses complex numbers, 4 uses quaternions, 8 uses octonions. 3 uses quaternion stuff applied to ternary quadratic forms, papers of Jones and Pall mostly, the main one 1939. The naive adaptation of the Jones-Pall formalism to our $n=7$ does not work very well, see Octonions and the dance of the seven veils\n\nThis is false for $n = 9,17,25,33,\\ldots.$ Indeed, take any odd $n = k^2,$ let the first row have all entries $1,$ no second row is possible that is orthogonal to the given first row, consists of integers, and has the same length. Problem mod 2, insofar as the dot product of the two rows is odd, therefore nonzero. Actually, for any $n >1, \\; \\; \\; n \\equiv 1 \\pmod 8,$ one may specify any $n-3$ odd numbers, then find the final three (also odd) by Gauss three square theorem to get an odd square sum, no luck.\n\nAnyway, I did some computer checks, entirely successful for small entries for $n=5,6,7,$ and instinct tells me that it only gets easier with larger entries.\n\nSo, that is the short version, does this work for any first row of integral length (sum of squares is another square) in dimension $n=5,6,7?$\n\nshare|improve this question\nThat's nice, if you do a large number of edits, but they are all in a few minutes, it clumps them together and counts only one edit. \u2013\u00a0 Will Jagy May 6 '13 at 19:42\nIndeed. However, note that after a certain number of edits (maybe 8) the question automatically becomes CW, so be careful despite the clumping. \u2013\u00a0 Tony Huynh May 6 '13 at 19:51\n@Tony, yes, I pay attention to that. If I click in the middle, where it currently says \"edited 13 mins ago\" it shows me the revision list and the official edit count. So that is how I know when to start an answer of my own, for example. \u2013\u00a0 Will Jagy May 6 '13 at 19:54\nYou might be interested in weighing matrices. (I think that's the term.) I know Robert Craigen and others in combinatorial matrix theory have studied matrices with MM^T = wI. Also Will Orrick might know some people who can help. Gerhard \"Ask Me About Indirect References\" Paseman, 2013.05.06 \u2013\u00a0 Gerhard Paseman May 6 '13 at 20:03\n@Gerhard, I used to have a very nice bathroom scale, based on strain gauge. Later I dripped a bunch of water on it and it died. en.wikipedia.org/wiki/Weighing_matrix Will Orrick is an MO regular, not sure about the other name. It appears the important case for most people has entries $0,1,-1.$ \u2013\u00a0 Will Jagy May 6 '13 at 20:37\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYes, it is possible to fill in. Your problem is a particular case of a completion problem and is treated in the following paper:\n\nHsia, J.S. Two theorems on integral matrices. Linear Multilinear Algebra 5, 257-264 (1978).\n\nshare|improve this answer\nThank you. I had that article at one point. \u2013\u00a0 Will Jagy May 8 '13 at 20:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/15162/hitting-times-for-an-n-dimensional-random-walk-on-a-lattice-with-strictly-posit?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nPlease consider a random walk on a finite N-dimensional lattice with vectors $(x_1, ..., x_N)$. We define the origin to be $(0, ..., 0)$ and the target to be at the point in the lattice furthest away from the origin - i.e. $(||x_1||, ..., ||x_N||)$ where $||x_k||$ is the integer length of the lattice in the $x_{k}$ dimension. Here, each step of the random walk is a uniformly distributed, strictly positive random integer in each of the N-dimensions with an upper-bound value defined by the requirement that one cannot exceed the dimensions of the lattice.\n\nIs there a nice method, aside from explicit path-counting, to derive the probability density for hitting times provided an arbitrary lattice as defined above?\n\nSome computational results: For the $N=1$ case I expected the target hitting time (defined as the number of steps to reach the target) to fit well with a logarithmic growth function of the form $A*ln(S)$ where A is a positive real number and $\"S\"$ is the number of integer steps one takes to reach the target from the origin. Running simulations (averaging 10,000 times) this yielded a decent fit with the value of $A$ ~ 1.146 for $||x|| = 100$, but $A$ decreases to ~1.095 for $||x|| = 1,000$ and decreased further ~1.069 for $||x||=10,000$.\n\nshare|improve this question\nThis sounds a lot like directed percolation. ;) \u2013\u00a0 Gjergji Zaimi Feb 13 '10 at 3:08\nHow are you choosing your random step sizes? \u2013\u00a0 Qiaochu Yuan Feb 13 '10 at 3:08\nLeonid, yes, that's exactly what I mean. One would generate a uniformly distributed random integer between '1' and the largest integer value that won't take you out of the lattice for each of the 'N' dimensions. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:24\nLeonid, I apologize, I misspoke. The overall step size must be non-zero, but movement in any subset of the dimensions may be zero for a step. I.e. one of the randomly generated integers must be at least one, but the remainder may be zero-valued. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:35\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAssuming you mean Leonid Kovalev's interpretation, the distribution of the hitting time in the $N = 1$ case is the same as the distribution of the number of cycles of a random permutation of $[n]$.\n\nTo be more specific, I'll change coordinates. Let $X_0 = (x_0^1, \\ldots, x_0^N) = (S, S, \\ldots, S)$. Let $X_1 = (x_1^1, \\ldots, x_1^N)$, where $x_1^j$ is chosen uniformly at random from $0, 1, \\ldots, x_0^j-1$. Define $X_2$ similarly in terms of $X_1$, and so on.\n\nThen the sequence $(x_0^1, x_1^1, x_2^1, x_3^1, \\ldots)$ are as follows:\n\n  \u2022 $x_0^1 = L$, of course.\n  \u2022 $x_1^1$ is uniformly distributed on $\\{ 0, \\ldots, S-1 \\}$.\n  \u2022 $x_2^1$ is uniformly distributed on $\\{ 0, \\ldots, x_1^1-1 \\}$.\n\nand so on... In particular the distribution of $x_1^1$ is the distribution of number of elements in a random permutation on $S$ elements which are {\\it not} in the cycle containing 1; In particular the distribution of $x_1^1$ is the distribution of number of elements in a random permutation on $S$ elements which are {\\it not} in any of the $k$ cycles with the smallest minima.\n\nSo the distribution of the smallest $k$ for which $x_k^1 = 0$ is exactly the distribution of the number of cycles of a random permutation of $\\{ 1, \\ldots, S \\}$; this is $1 + 1/2 + \\cdots + 1/S \\sim \\log S + \\gamma$, where $\\gamma = 0.577\\ldots$ is the Euler-Mascheroni constant.\n\nIn the higher-dimensional cases, the time to reach $(0, \\ldots, 0)$ is just the {\\it maximum} of the number of cycles of $N$ permutations chosen uniformly at random; this should still have expectation $\\log S$ plus a constant depending on $N$.\n\nshare|improve this answer\nThanks for your answer Michael. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:39\nYou're welcome! It just happens that I spend way too much time thinking about random permutations. That being said, the original problem was a little underspecified, and I happened to make the interpretations that led to me being able to solve it. In your second comment I see you actually had a different interpretation in mind. I suspect the overall behavior is the same -- still logarithmic -- but it would be harder to prove because the $N$ dimensions are no longer independent. \u2013\u00a0 Michael Lugo Feb 13 '10 at 3:50\n\nWhile I like Michael Lugo's answer better, I thought I might as well put up the solution I sketched out for myself for the one-dimensional case:\n\nThe probability that the walker visits a particular point on the one-dimensional lattice can be expressed as $\\frac{1}{||x_k||-p}$ where $p$ is the distance between the lattice point and the origin. Therefore, we can express the probability that, during a given step, the walker visits the target lattice point (i.e. the lattice point furthest from the origin) as - $P(target)$ = $\\frac{(\\frac{1}{||x_k||-(||x_k||-1)})}{\\sum_{i=0}^{\\||x_k||-1}\\frac{1}{||x_k||-i}}$. $\\frac{1}{P(target)}$ should therefore provide the average hitting time for the one-dimensional walkers under the imposed conditions. Computationally this value approximates Michael Lugo's answer of $ln(||x_k||)+\\gamma$ within ~0.1 by $||x_k||$ = 5.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/266604/uniqueness-of-for-integration-functional\nText:\nTake the 2-minute tour \u00d7\n\nLet $f\\in C([0,1])$ and assume that there exists a positive constant C such that $\\left| \\int_0^1p'(t)f(t) dt \\right| \\leq C\\|p\\|_2 $ for all polynomials $p$, where $\\|p\\|^2_2 = \\int_0^1 |p(t)|^2 dt$. Show that there exists a unique $g\\in L^2([0,1])$ such that \\begin{equation} f(x) = \\int_0^x g(t) dt, \\\\ \\int_0^1 g(t)dt =0 \\end{equation} My try: let $\\ell(p) = \\int_0^1 p'(t) f(t) ds$ then $$\\ell(p) = \\int_0^1 p'(t) \\left(\\int_0^tg(x) dx\\right) dt$$ Integrate by parts: $$\\ell(p) = - \\int_0^1 p(t)g(t) dt$$ and this unique by Riesz theorem. Im pretty sure I need some kind of extension here but I cannot see where, please correct me and fill in some blanks.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nTo define $\\ell(p) = \\int_0^1 p'(t) f(t)\\, ds$ was the right move. I don't understand what happens after that line, though: the second formula for $\\ell(p)$ does not seem to agree with the first.\n\nUniqueness of $g$ is not so hard: If both $g_1$ and $g_2$ serve the purpose, then $\\int_0^x (g_1-g_2)=f(x)-f(x)=0$ for all $x$, which implies [why?] that $g_1$ and $g_2$ are the same element of $L^2$.\n\nFor existence, we certainly need the Riesz representation theorem. But the first step should probably be to extend $\\ell$ to a bounded linear functional on all of $L^2$, by Hahn-Banach. Then the Riesz representation theorem gives us $g\\in L^2$ such that $\\ell(p)=\\langle p,g\\rangle $ for all $g$.\n\nYou are also correct in that we need integration by parts. On which side of\n$$\\int_0^1 p'(t)f(t)\\,dt = \\int_0^1 p(t)g(t)\\,dt$$ can we do it? Only on the right, because $f$ is not known to be differentiable. So, introduce $G(x)=\\int_0^x g(t)\\,dt$ and perform the magic: $$\\int_0^1 p(t)g(t)\\,dt = p(1)G(1) - \\int_0^1 p'(t)G(t)\\,dt$$ This is what we have so far: $$\\int_0^1 p'(t)f(t)\\,dt = p(1)G(1) - \\int_0^1 p'(t)G(t)\\,dt$$\n\nI leave it for you to finish the proof. To-do items:\n\n  \u2022 show that $G(1)=0$\n  \u2022 show that $f\\equiv -G$\nshare|improve this answer\nThanks alot I see I had a typo in my try. And shouldnt it be -$\\int_0^1p(t)G'(t)dt = \\int_0^1p(t)g(t) dt $ and $G(1) = 0$ is given from the beginning. \u2013\u00a0 Johan Dec 29 '12 at 8:34\n@Johan No, $G(1)=0$ is not given. This is something you are told to prove in the sentence that begins with \"Show that..\". (note that the formula $\\int_0^1 g=0$ is a part of that sentence). When you are asked \"show that there exists a unicorn with five legs\", it does not mean you can assume that unicorns have five legs. It means your duty is to not only to produce a unicorn, but one that has five legs. No four-legged unicorns will be accepted. \u2013\u00a0 user53153 Dec 29 '12 at 8:44\nSorry, I can not read what I'm typing, u are correct! \u2013\u00a0 Johan Dec 29 '12 at 8:54\nSo the last things following by putting $p(t) =1 $? \u2013\u00a0 Johan Dec 29 '12 at 9:49\n@Johan Yes, that's right. \u2013\u00a0 user53153 Dec 29 '12 at 15:55\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/152021/solutions-of-an-integral-equation\nText:\nTake the 2-minute tour \u00d7\n\nGiven the integral equation: $$\\sqrt{f(x)}\\int_{0}^{x}f(\\tau)d\\tau=g(x)$$ with g(x) known function, in what cases and how is it possible to solve it?\n\n\nshare|improve this question\nIf $g(x)=k_1x^\\beta$ then the solution has a simple form $f(x)=\\sqrt{(\\alpha+1)k_1} x^\\alpha$ being $\\alpha=\\frac{2}{3}(\\beta-1)$ with $\\beta\\ne 1$. \u2013\u00a0 Jon May 31 '12 at 14:08\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nSquare both sides of the equation : $$F^'(x) \\ (F(x))^2=(g(x))^2$$ with $F(x) = \\int_{0}^{x}f(\\tau)d\\tau $.\nNow by integration between 0 and t : $$\\frac{(F(t))^3}{3} = \\int_{0}^{t} (g(x))^2 dx$$ F(t) can now be expressed : $$F(t) =\\sqrt[3]{3} \\ \\left( \\int_{0}^{t} (g(x))^2 dx \\right)^{1/3}$$ since $F'(t)=f(t)$, by derivation we obtain : $$f(t) = \\sqrt[3]{3} \\ (g(t))^2 \\left(\\int_{0}^{t} (g(x))^2 dx \\right)^{-2/3}$$\n\nshare|improve this answer\n\nLet us assume that $g(x)$ is differentiable (in fact $g(x)$ should be also positive and monotonously increasing $f(x)$ has to be positive such that the square root is properly defined).\n\nTake a derivative of your equation and you obtain $$ f(x)^{3/2} + \\frac{g(x)\\, f'(x)}{2 f(x)} =g'(x). $$ Thus, you have reduced your equation to a differential equation with the initial condition $f(0) = g(0)$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56926.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSumming Triangle Numbers\n\nDate: 04/21/98 at 15:05:43\nFrom: Karen Hooton\nSubject: Sum of triangle numbers\n\nDear Dr. Math,\n\nI am trying to find the formula for the sum of triangle numbers, such \nas: 1 + 3 + 6 + 10 + 15. \n\nI've gone through my school library and checked out the Internet with \nno luck. Is it at all possible that you can help me out?\n\nYours sincerely,\nKaren Hooton\n\nDate: 04/22/98 at 10:51:30\nFrom: Doctor Nick\nSubject: Re: Sum of triangle numbers\n\nHi Karen -\n\nThis is a nice question and it has a nice answer.\n\nLet g(n) be the n-th triangular number. So:\n\n     g(1) = 1\n     g(2) = 3\n     g(3) = 6\n\nand so on. You probably know that:\n\n     g(n) = n(n+1)/2\n\nLet f(n) be the sum of the triangular numbers 1 through n.\n\n     f(n) = g(1) + g(2) + ... + g(n)\n\n     f(n) = n(n+1)(n+2)/6\n\nHow can we prove this? We can prove it by induction. That is, we'll \nprove two things:\n   1) It's true for some n (n=1, in this case).\n   2) If it's true for n, then it's true for n+1.\n\nThis will allow us to conclude that it's true for all n >= 1.\n\nNow 1) is easy. We know that f(1) = g(1) = 1. So it's true for n = 1.\n\nNow for 2). Suppose it's true for n. Consider f(n+1). We have:\n\n     f(n+1) = g(1) + g(2) + ... + g(n) + g(n+1) \n            = f(n) + g(n+1)\n\nUsing our assumption that f(n) = n(n+1)(n+2)/6 and that \ng(n+1) = (n+1)(n+2)/2, we have:\n\n     f(n+1) = n(n+1)(n+2)/6 + (n+1)(n+2)/2\n            = n(n+1)(n+2)/6 + 3(n+1)(n+2)/6\n            = (n+1)(n+2)(n+3)/6\n\nwhich is exactly what the formula says it should be. Thus we have \nshown that if it's true for n, it's true for n + 1. Since we showed it \nwas true for n = 1, we now know it's also true for n = 1 + 1 = 2, and \nthen for n = 2 + 1 = 3, and so on, for all n >= 1.\n\nBy the way, these numbers (1,4,10,20,35,56,...) are known as \ntetrahedral numbers. If you imagine piling triangles of dots on top of \none another first 1, then 3, then 6, then 10 you'll get a tetrahedron \nof dots at each stage with 1,4,10,20 dots total. Take a look at:\n\nfor some high level information about them and related fun things.\n\nHave fun,\n\n-Doctor Nick,  The Math Forum\nAssociated Topics:\nHigh School Sequences, Series\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/283740/finding-the-first-odd-abundant-number-less-than-1000/291555\nText:\nTake the 2-minute tour \u00d7\n\nWe say about number $n $ abundant if the sum of the divisors except $n$ is bigger than the number $n$.For example : $12$ is abundant because the sum of divisors except $12$ is bigger than $12$ : $1+2+3+4+6=16>12$ .How to find the first odd abundant number less than $1000$\n\nshare|improve this question\n\"the first odd abundant number less than 1000\": that's a strange way of putting it! If the smallest abundant number is less than 1000, then that's your answer right there; and if it's not, then your question is like \"who is the present king of France?\" \u2013\u00a0 TonyK Jan 21 '13 at 20:54\n@TonyK The smallest abundant number. \u2013\u00a0 sen Jan 21 '13 at 20:57\n\n3 Answers 3\n\nWe will take the problem to be finding the smallest abundant number, then will confirm that it is less than $1000.$ For a prime power $p^e$, the sum of divisors is $\\sum_{i=1}^e p^i=\\frac{p^{e+1}-1}{p-1}$. The sum of divisors function is multiplicative, so if $n=\\prod_i p_i^{e_i}$, the sum of divisors of $n, \\sigma(n) = \\prod_i \\frac{p_i^{e_i+1}-1}{p_i-1}$. We need $\\frac {\\sigma(n)}n =\\prod_i \\frac{p_i^{e_i+1}-1}{p_i^{e_i}(p_i-1)}=\\prod_i 1+\\frac {p_i^{e_i}-1}{p_i^{e_i}(p_i-1)}\\gt 2$\n\nIf we make a table of $\\frac{p_i^{e_i+1}-1}{p_i^{e_i}(p_i-1)}$ we get\n\n$$\\begin {array}&&3&5&7&11\\\\0&1&1&1&1\\\\ 1&1.333333&1.2&1.142857&1.090909\\\\ 2&1.444444&1.24&1.163265&1.099174\\\\ 3&1.481481&1.248&1.166181&1.099925\\\\ 4&1.493827&1.2496&1.166597&1.099993\\\\ 5&1.497942&1.24992&1.166657&1.099999\\\\ 6&1.499314&1.249984&1.166665&1.1\\\\ \\end{array}$$\n\nwhere the column is the prime and the row is the exponent. We want to find the set of entries that multiply to more than $2$ with the smallest product of prime powers. This makes us think that what as we increase the power of each prime, what we get is the difference of the log of the next entry and the current entry and what we pay is the log of the prime. So we make a new table that way\n\n$$\\begin{array} &&3&5&7&11\\\\ 1&0.26186&0.113283&0.068622&0.036287\\\\ 2&0.072858&0.020373&0.009096&0.003147\\\\ 3&0.023045&0.003996&0.001286&0.000285\\\\ 4&0.007554&0.000796&0.000184&2.59E-05\\\\ 5&0.002504&0.000159&2.62E-05&2.35E-06\\\\ 6&0.000833&3.18E-05&3.74E-06&2.14E-07\\\\ \\end{array}$$\n\nUsing the greedy algorithm, the priority order of factors is $3,5,3,7,11,3,5\\ldots$ leading to a series of candidates $3,15,45,315,3465$, but we see we can sneak another factor of $3$ onto $315$ giving $945$. The way the candidates stack up:\n\n$$\\begin{array} n&\\sigma(n)&\\frac {\\sigma(n)}n\\\\ 3&4&1.333333\\\\ 15&24&1.6\\\\ 45&78&1.733333\\\\ 315&624&1.980952\\\\ 945&1920&2.031746\\\\ 3465&7488&2.161039 \\end {array}$$\n\nand $945$ is the first to exceed $2$. We get more \"bang for the buck\" with $3465$, but $945$ is good enough.\n\nshare|improve this answer\n\nThe oeis is a good source for sequences like these.\n\nFor example, your answer can be found here as linked from here.\n\nIn particular, the answer is $945$.\n\nIf you want to check this particular example, you could do it as so in Wolfram|Alpha.\n\nshare|improve this answer\n\nIf you're familiar with a bit of R-programming, then you could try this script:\n\nn <- 1000\no <- sapply(seq(3, n, by=2), function(x) {\n    t <- sapply(1:x-1, function(y) {\n        ifelse(x %% y == 0, y, 0)\n    t <- sum(t, na.rm = TRUE)\ndf <- data.frame(num = seq(3, n, by = 2), sum_div = o)\n> df[with(df, sum_div > num), ]\n\n#     num sum_div\n# 472 945     975\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/11818/probability-of-random-number-repeating\nText:\nTake the 2-minute tour \u00d7\n\nIn the situation of having a high entropy random number generator, that generates numbers in the range of 0 and 2,147,000,000.\n\nIf i have a list of 1,000,000 integer values, what are the chances that a random number will already be on my list?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nOne minus the probability that they are all different: $$1 - \\left( 1- \\frac{1}{n} \\right) \\left( 1- \\frac{2}{n} \\right) \\cdots \\left( 1- \\frac{k-1}{n} \\right),$$ where $n=2,147,000,001$ (since you include $0$) and $k=1,000,000.$\n\nSee the birthday problem for more information.\n\nshare|improve this answer\n\nIf the list is drawn with replacement, the chance that a given number (the new draw) is not in it is $$(1-\\frac{1}{2147000001})^{1000000}$$ The birthday problem only comes up if you ask for the chance of a collision anywhere in the 1000001 numbers.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/31047/optimization-problem-with-two-step-discontinuous-function\nText:\nTake the 2-minute tour \u00d7\n\nimagine my function as a staircase with two steps. This function is to be fitted to some empirical data and I'm searching for an algorithm which minimizes the Root Mean Squared Error between this function and the data. The decision variables are L1 and L2 (for the level of the steps on the y-axis) and C (for the cut-off-point between the steps on the x-axis). The possible values for C on the x-axis are discreete and finite. Can you point me to algorithms or even possible solutions in Excel (VBA), Matlab or C++? The standard Excel solver is unable to solve this problem, because it requires a smooth function, but the (expensive) Premium solver seems able to do it.\n\nMy suggestion for an algorithm would be following 2-step method: Given the finite set of values for C, for each C, optimize L1 and L2. Then, optimum C* would the C with the lowest RMSE given L1* and L2*. Would that be correct? Or is there a more elegant way to it?\n\nAny helpful comments are appreciated. Steve\n\nshare|improve this question\nWhen you say \"imagine my function as a staircase with two steps\", I imagine a function with three different values and two steps between them, but then you only have two variables for the \"level of the steps\" and only once position on the $x$ axis. So it seems you actually mean just a function that changes from one value to another just once? This would usually be referred to as a \"step function\", not a \"two-step function\". \u2013\u00a0 joriki Apr 5 '11 at 7:07\nNote that your problem has a discrete aspect and a continuous aspect. The decision for $C$ is discrete, since it doesn't matter where between two consecutive data points you put it. The decision for $L_1$ and $L_2$ is continuous. The continuous part is easy: Once you know where the step is, $L_1$ and $L_2$ are just the averages of the data on each side of the step. So your problem is basically to find the best split point. \u2013\u00a0 joriki Apr 5 '11 at 7:16\nIt helps if you mark edits as edits in the text; then people who have already read the question know that they need to reread parts of it to be up to date. My comments above referred to the original question. \u2013\u00a0 joriki Apr 5 '11 at 7:27\nYour algorithm is correct. I was hoping one might be able to show that the RMSE is convex in $C$, which would have meant you don't have to try all values for $C$, but there are counterexamples for that, with several local minima for $C$, so I think you do have to try them all. When you say \"optimize $L_1$ and $L_2$\", note that in this case that just means \"take the average of the data on each side of $C$\". \u2013\u00a0 joriki Apr 5 '11 at 7:47\nwith respect to your 1st comment: You are right, only one change of value, sorry for the confusion. 2nd comment: correct. 3d comment: sorry again. 4th comment: I realize that for a given C, I can evaluate L1* and L2* independently from one another. That's what I meant. \u2013\u00a0 Steve06 Apr 5 '11 at 17:34\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe example $\\{(-1,-1),(-\\epsilon,-\\epsilon),(\\epsilon,\\epsilon),(1,1)\\}$ shows that there can be more than one local minimum with respect to $C$: Splitting 1 & 3 either way is better than splitting 2 & 2. So it seems you can't avoid trying out every position for the step.\n\nTo find the optimal $C$ efficiently, note that the optimal $L_1$ and $L_2$ given $C$ will be the average of the data on each side of $C$, so that what you're trying to minimize is\n\n$$ \\begin{eqnarray} && \\sum_{x_i<C}\\left(f_i-\\frac{\\sum_{x_i<C}f_i}{N_<}\\right)^2 + \\sum_{x_i\\ge C}\\left(f_i-\\frac{\\sum_{x_i\\ge C}f_i}{N_\\ge}\\right)^2 \\\\ &=& \\sum_{x_i<C}f_i^2 - \\frac{\\left(\\sum_{x_i<C}f_i\\right)^2}{N_<} + \\sum_{x_i\\ge C}f_i^2 - \\frac{\\left(\\sum_{x_i\\ge C}f_i\\right)^2}{N_\\ge} \\\\ &=& \\sum f_i^2 - \\left( \\frac{\\left(\\sum_{x_i<C}f_i\\right)^2}{N_<} + \\frac{\\left(\\sum_{x_i\\ge C}f_i\\right)^2}{N_\\ge} \\right)\\;, \\end{eqnarray} $$\n\nwhere $N_<$ and $N_\\ge$ are the numbers of points to the left and right of $C$, respectively. The first term is constant, so you can ignore it, so all you need to do is sweep through from left to right, in each step adding one function value to the left-hand sum and subtracting it from the right-hand sum and evaluating the expression in parentheses.\n\nshare|improve this answer\ni implemented an algorithm that checks every possible split point, but due to the no. of possibilities (around 1000) it's a bit slow. I consider starting with a large net of inspecting first every 100th possible split point, then, within the range of the 2 nearby solutions with the lowest average error, I would tighten the net to every 20th possible split point, and finally loop through every possibility of the best 20-point range. Would that make sense? \u2013\u00a0 Steve06 Apr 6 '11 at 14:58\n@Steve: I'm not sure how good your chances to get close to the optimal solution would be with such an approach. I think it would depend on the clustering of the values and might differ quite a bit from the optimal result in some cases. If you have 1000 split points, you should be able to try them in almost no time, so I suspect you might be doing it inefficiently -- did you use the approach in my answer to avoid having to sum function values for each possible split? \u2013\u00a0 joriki Apr 6 '11 at 15:57\nit takes long because (a) because L1, L2 are each fitted to the data iteratively, (b) I use Excel VBA which as a scripting language is of course a lot slower than some C code and (c) the whole procedure has to be repeated for 500 different companies in my sample. At the moment, one company takes about half an hour on average to be optimized. \u2013\u00a0 Steve06 Apr 6 '11 at 17:51\n@Steve: Your last comment makes we wonder whether you've understood my answer. This should be a matter of milliseconds, not hours. Most importantly, $L1$ and $L2$ should not be fitted to the data iteratively -- as I wrote in the answer, they are simply the averages of the function values to the left and to the right of the split point, respectively, and even these averages don't have to be recalculated for each potential split point. I recommend that you try to implement my answer; I'll be happy to help if you have questions about it. \u2013\u00a0 joriki Apr 6 '11 at 17:59\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/45829/programming-paradigm-change/45958\nText:\nTake the 2-minute tour \u00d7\n\nI'm new to Mathematica, I've been learning by myself, and, being a Java developer for some time, it makes it hard to adapt.\n\nI've tried to solve a Reddit challenge, and I came up with this solution:\n\nstr = \"[can {and it(it (mix) up)} look silly]\"\ntotal = \"\"\nstr = StringTake[str, {2, -2}]\ninix[strn_] := \n  Min[StringPosition[strn, \"[\"], StringPosition[strn, \"{\"], \n  StringPosition[strn, \"(\"]];\nfinix[strn_] := \n  Max[StringPosition[strn, \"]\"], StringPosition[strn, \"}\"], \n  StringPosition[strn, \")\"]];    \nhowmany[strn_] := \n  Length[StringPosition[strn, \"[\"]] + \n  Length[StringPosition[strn, \"{\"]] + \n  Length[StringPosition[strn, \"(\"]];\nbrackets[x_, y_] := \n  If[x != \\[Infinity], (total = \n     StringTake[str, {1, x - 1}] <> \" \" <> \n     StringTake[str, {y + 1, -1}] <> \" \" <> total; \n     str = StringTake[str, {x + 1, y - 1}]) , \n     (total = str <> \" \" <> total; str = \"\")];\n\nDo[brackets[inix[str], finix[str]], {i, howmany[str] + 1}];\nStringSplit[total, Whitespace]\nStringJoin[Riffle[%, \" \"]]\n\nIs there a better solution? From seeing some Mathematica code, this looks to be terribly big code. I would want just some pointers on how to improve.\n\nshare|improve this question\nFolks, these are all great solutions, but I do think beginning users would benefit from a bit of explanation of how your code works and why you chose to write it that way. \u2013\u00a0 Verbeia Apr 11 '14 at 10:52\nWhen I go to that link you posted, using firefox, I see empty boxes there for the code. Only when I move the mouse over the box, will the code show up there. Same with IE and Chrom. Very strange and confusing web site this reddit is. \u2013\u00a0 Nasser Apr 11 '14 at 19:18\n@Nasser this is spoiler markup, and it exists here on StackExchange as well. The idea is that people might like to try the problem for themselves before they see someone else's solution. \u2013\u00a0 Oleksandr R. Apr 13 '14 at 4:04\n\n9 Answers 9\n\nup vote 55 down vote accepted\n\nIn this response, I will focus upon the programming paradigm change when moving from Java to Mathematica. I will emphasize two differences between the languages. The first concerns the \"feel\" of writing Mathematica code. The second is about how iteration is expressed.\n\nThe \"Feel\" of Mathematica\n\nJava is a reasonably conventional programming language, designed to conform to the principle of \"least surprise\" for programmers who are coming to it from other mainstream languages. The boundary between the language proper and the runtime libraries is well-defined. Learning Java is often just a matter of trying to find where a preconceived piece of functionality resides in the standard library.\n\nBy contrast, the symbolic nature of Mathematica blurs the line between language and library. From a strict computer science perspective, one could argue that the core language is very tiny indeed. It consists of a few data types, some term-rewriting machinery, and little else. However, it does not feel this way to use it. Instead, I would suggest that learning Mathematica is more akin to learning a natural language. There is endless vocabulary, obscure idioms, weird exceptions, and countless ways to express any given concept. For me, the act of writing Mathematica code sometimes feels more like writing prose (or perhaps even poetry). This is simultaneously Mathematica's greatest strength and its greatest weakness. On the one hand, it is flexible enough to express an algorithm in many differents styles, e.g. procedural, functional, query-based, language-based, etc. On the other hand, the computer sometimes acts like you've just read it a piece of poetry or prose :)\n\nMy advice is to learn Mathematica as if you were learning a new natural language. Slowly, patiently. Ability grows with use. Tackle lots of small problems (like this question -- you've come to the right place in Mathematica StackExchange!). Practice expressing the same concept many different ways. Read lots of code. Read random pages from the voluminous documentation -- there are many, many gems hiding in there. Don't try to bite off the whole thing at once.\n\n\nOkay, enough of the warm and fuzzy stuff. Let's talk about code. If I had to pick just one difference between Java and Mathematica to talk about, it would be iteration. Whenever we want to operate on a collection of items in Java, our first thought is to operate upon each item individually within an explicit loop (ignoring Java 8 for the moment). Mathematica takes a different approach. The first choice in Mathematica is to operate upon the collection as a single unit using implicit iteration. For example, the Java loops:\n\nfor (int i = 0; i < array.length; ++i) { result[i] = array[i] + 1; }\nfor (int i = 0; i < array.length; ++i) { result2[i] = someFunction(array[i]); }\n\nwould have the following Mathematica equivalents:\n\nresult = array + 1;\nresult2 = Map[someFunction, array];\n\nThe iteration is implicit. A big part of the study of Mathematica is about learning these higher-level functions that perform implicit iteration. Explicit iteration still happens in Mathematica, but it is not the first tool to reach for. It is almost always fruitful to seek an operator that will transform a collection in one fell swoop.\n\nYou can get a feel for iteration in Mathematica from the Functional Operations tutorial in the documentation, but you'd be hard-pressed to find a better investment of your time than to read Mathematica Programming - an advanced introduction.\n\nOne final point before we move on to the specific problem from the question. Mathematica has very few facilities to destructively alter large data structures. Any modification of, say, a list results in a copy of that list being generated. This is the Mathematica way, and one just has to embrace it. It is possible to write (often convoluted) code to minimize memory usage, but the first tool in the toolbox almost always involves lots of data structure copying. A common theme that you will find in the answers here on the Mathematica StackExchange is that the fastest algorithms frequently use the most memory. Don't fight it, unless there is no alternative. Memory is cheap. (ohh, the fading memory of C/C++ in my mind stirs restlessly :)\n\nThe Problem, At Last\n\nAs you can see from the many responses to this question, there are many ways to approach this problem. I dare say that they hardly scratch the surface of possible solutions. I will add another, but make no claim as to how it stacks up against other answers. This response is more concerned with the process of creating the solution.\n\nMathematica is first and foremost an exploratory programming environment. Let's explore.\n\nThe first thing we know for sure is that we will need to divide the string into pieces. Let's play:\n\n$string = \"[can {and it(it (mix) up)} look silly]\";\n\n(* {[,c,a,n, ,{,a,n,d, ,i,t,(,i,t, ,(,m,i,x,), ,u,p,),}, ,l,o,o,k, ,s,i,l,l,y,]} *)\n\nStringSplit[$string, Characters[\"{[()]}\"]]\n(* {can ,and it,it ,mix, up,, look silly} *)\n\n$split = StringSplit[$string, RegularExpression[\"(?<=[(){}[\\\\]])|(?=[(){}[\\\\]])\"]]\n(* {[,can ,{,and it,(,it ,(,mix,), up,),}, look silly,]} *)\n\nThat last one looks promising. Take no notice of the fact that I pulled that regex out of a hat -- this post is long enough! What we need to do is to scan for brackets and drop down a level when we see an opening one and pop back up when we see a closing one:\n\n$changes = Replace[$split, {\"[\"|\"{\"|\"(\"->-1, \"]\"|\"}\"|\")\"->1, _->0}, {1}]\n(* {-1,0,-1,0,-1,0,-1,0,1,0,1,1,0,1} *)\n\nThose represent the level changes, but we are really more interested in the levels themselves. We need to keep a running total of the changes. It so happens that there is an operation for that:\n\n$levels = Accumulate @ $changes\n(* {-1,-1,-2,-2,-3,-3,-4,-4,-3,-3,-2,-1,-1,0} *)\n\nNow we have the individual strings and their levels. We need to sort them by level. Here are a couple ways to do that. First, we could pair up each string with its level and then use SortBy:\n\n$pairs = Transpose[{$split, $levels}]\n(* {{[,-1},{can ,-1},{{,-2},{and it,-2},{(,-3},{it ,-3},{(,-4},{mix,-4},{),-3},\n   { up,-3},{),-2},{},-1},{ look silly,-1},{],0}} *)\n\n$sorted = SortBy[$pairs, {Last}]\n(* {{(,-4},{mix,-4},{(,-3},{it ,-3},{),-3},{ up,-3},{{,-2},{and it,-2},{),-2},\n   {[,-1},{can ,-1},{},-1},{ look silly,-1},{],0}} *)\n\nHere, the \"natural language\" behaviour of Mathematica crops up. We need the sort to be stable, that is, elements at the same level must stay in the original order. The way to achieve that is to say SortBy[$pairs, {Last}]instead of SortBy[$pairs, Last]. There is a logical explanation for this (see the documentation), but it is far from obvious. This is an example of something one just picks up by experience and hard knocks.\n\nThere is another way to perform this sort that is even less obvious, but is actually a fairly common idiom:\n\n$sorted = $split[[Ordering@$levels]]\n(* {(,mix,(,it ,), up,{,and it,),[,can ,}, look silly,]} *)\n\nOrdering does not sort the list, but rather tells you the index of each element as it would appear in a sorted list. This is useful to sort one list based upon the contents of another. It eliminates the need to assemble an intermediate list of pairs first. (Although we are still assembling an intermediate list of indices. Memory. Cheap. Remember?).\n\nThe list still contains all of the brackets. We need to remove those:\n\n$result = DeleteCases[$sorted, \"{\"|\"[\"|\"(\"|\")\"|\"]\"|\"}\"]\n(* {mix,it , up,and it,can , look silly} *)\n\nWe need to join the strings together:\n\nStringJoin @@ $result\n(* mixit  upand itcan  look silly *)\n\nHmm, we need to something about those spaces. Let's delete the excess:\n\nStringJoin @@ StringTrim @ $result\n(* mixitupand itcanlook silly *)\n\nOops, we need spaces between the strings.\n\nStringJoin @@ Riffle[StringTrim @ $result, \" \"]\n(* mix it up and it can look silly *)\n\nRiffle? Where did that come from? Alas, it is simply vocabulary that must be memorized.\n\nAt last, we have the result. Let's pull it all together, keeping our favourites from the variations:\n\ndecode[string_] :=\n  Module[{split, changes, levels, sorted, result}\n  ; levels = Accumulate @ changes\n  ; sorted = split[[Ordering@levels]]\n  ; result = DeleteCases[sorted, \"{\"|\"[\"|\"(\"|\")\"|\"]\"|\"}\"]\n  ; StringJoin @@ Riffle[StringTrim @ result, \" \"]\n\ndecode[\"[can {and it(it (mix) up)} look silly]\"]\n(* mix it up and it can look silly *)\n\nIf we are performing a one-off task, there is little need to search for alternative approaches as we have done above. The first approach we find is just fine, provided if gives us our result. But sometimes it takes a while to find an approach that performs well and/or is comprehensible enough to convince ourselves that it is correct. That is where the need to write, rewrite and rewrite again surfaces, just as when writing natural-language prose.\n\nParting Tip\n\nThe widespread mathematical ethic of terseness has taken hold in the Mathematica community. So we are just as likely to see the preceding function expressed without making the intermediate expressions explicit:\n\ndecode2[string_] :=\n  StringJoin @@ Riffle[\n    StringTrim @ DeleteCases[\n      #[[Ordering @ Accumulate @ Replace[#, {\"[\"|\"{\"|\"(\"->-1, \"]\"|\"}\"|\")\"->1, _->0}, {1}]]]\n  , \" \"\n  ] &\n\n(* mix it up and it can look silly *)\n\nThere it is, fully-grown, armed and armoured as if sprung directly from Zeus' head. Time to post to StackExchange! We might consider such an approach to show little mercy to the reader, who must reverse-engineer what is happening. This is a common problem in expressive high-level languages. Terse expression can sometimes give few cues for understanding.\n\nWith experience, it becomes easier to read such expressions. In the meantime (and beyond), a little helper function can help wade through code like this:\n\nP[x___, l_] := (Print[Row[{x, l}, \" \"]]; l)\n\nThis function prints out its arguments, returning the last unchanged. It can be quickly inserted at various places in a pipeline to see what they return. For example:\n\nModule[{level = 0}\n, P@StringCases[\"[can {and it(it (mix) up)} look silly]\"\n  , { s:Characters[\"[{(\"] :> (--level; ##&[])\n    , s:Characters[\"]})\"] :> (++level; ##&[])\n    , s:Except@Characters[\"[{()}] \"].. :> {s, level}\n] //\nP@SortBy[#, {Last}]& //\n#[[All, 1]]&\n\n\n\n\nNote the use of P before the StringCases and the Sort, causing their results to be shown. This technique is far more \"low tech\" than the debuggers in the Front-End and Workbench, but in the notebook interface it is quick and easy and often all that one needs. (And the attentive reader will have noticed that the code block was yet another approach to the problem, using a semi-imperative style. Assuming said attentive reader was not put to sleep half-way through this TL;DR :)\n\nshare|improve this answer\nIt took me 15 minutes to read, but it's all good. If this doesn't earn an Accept I don't know what does. +1 \u2013\u00a0 Mr.Wizard Apr 12 '14 at 18:47\nNice read. I'll buy a copy when it's in paperback ;-). +1 \u2013\u00a0 ciao Apr 13 '14 at 2:37\n@rasher Naaahhh, wait for the movie. We are hoping to get Steven Seagal to play Java, and Christopher Lloyd for Mathematica. I'm not too sure about the love triangle added to the shooting script involving Julia (Amanda Seyfried), but the climactic battle royale ought to make up for it... if we can secure the production funding for the CGI. \u2013\u00a0 WReach Apr 13 '14 at 3:39\n@Mr.Wizard I do indeed love your new method. I rest my case comparing writing Mathematica to writing poetry. \u2013\u00a0 WReach Apr 13 '14 at 13:51\nWonderful insight into the mind of a Mma programmer :). A big (and late) +1 \u2013\u00a0 belisarius Sep 22 '14 at 18:21\n\nStringReplace method\n\nAfter reading other answers I was inspired to write a new method. I place it first because it is almost as concise as the method below yet it is more robust (and safe) because it preserves strings as strings.\n\n\nStringReplace[str, {\"[\"|\"{\"|\"(\" -> -1, \"]\"|\"}\"|\")\" -> 1, \" \" -> 0}] //\n  #[[ Ordering @ Accumulate[# /. _String :> 0] ]] ~Cases~ _String ~Row~ \" \" &\nmix it up and it can look silly\n\nThis method is certainly not basic, but instead illustrates some interesting functionality in Mathematica.\n\nAdditionally this code is several times faster than WReach's decode and decode2 upon which it was based. It appears to be the fastest method posted so far.\n\nDo[str = StringReplace[str, \"mix\" -> str], {15}];  (* nest the original string *)\n\n    Timing // First\n\ndecode[str]  // Timing // First\ndecode2[str] // Timing // First\n\n\n\nNote: using List @@ # to change the head before Accumulate is a bit faster still, presumably because it eliminates a useless StringExpression evaluation. It however isn't as didactic regarding Mathematica's capabilities.\n\nNative-parser methods\n\nHere is a method using Mathematica's parsing to assist in the process:\n\n\nhe = ToHeldExpression @ StringReplace[str, {\"[\"|\"(\" -> \"{\", \"]\"|\")\" -> \"}\"}]\n\nRow[Join @@ Array[Cases[he, _Symbol, {99 - #}] &, 99], \" \"]\nHold[{can {and it {it {mix} up}} look silly}]\n\nmix it up and it can look silly\n\nThis has one clear flaw: words such as \"can\" are converted to Symbols. Since all of the words in the example are lower case this works without error, but to make it robust additional holding would be required, e.g. s_Symbol :> ToString @ Unevaluated[s] or use of heldCases. I also hard-coded a maximum depth of 98 just to make the code a bit cleaner.\n\nWith the same start but using ReplaceRepeated to order and condense the expression:\n\nFirst[he //. Except[Hold][a___, {x__}, b___] :> {x, a, b}] ~Row~ \" \"\nmix it up and it can look silly\n\nAn example of how holding may be added:\n\nsilly = \"Stop that! It's silly!\";  (* if this appears in the output I failed *)\n\nhe //. Except[Hold][a___, {x__}, b___] :> {x, a, b} /. _[x_] :> HoldForm @ Row[x, \" \"]\nmix it up and it can look silly\nshare|improve this answer\n+1 for the patternmeister \u2013\u00a0 ciao Apr 13 '14 at 2:39\n@rasher Thank you. I think you might like the new one I just put at the top. :-) \u2013\u00a0 Mr.Wizard Apr 13 '14 at 9:08\nI giggled at that. Very cool, and Ordering to the rescue to boot. \u2013\u00a0 ciao Apr 13 '14 at 9:16\nThe new one is very clever. I don't think I've ever seen non-strings on the rhs of StringReplace rules. Nice... \u2013\u00a0 Simon Woods Apr 13 '14 at 10:50\n@Simon In that case please see: (1), (2) \u2013\u00a0 Mr.Wizard Apr 13 '14 at 16:37\n\ni = 10;\nStringJoin @@ Last[Replace[Characters@str,\n    {\"[\" | \"(\" | \"{\" :> Sow[\" \", --i], \"]\" | \")\" | \"}\" :> Sow[\"\", ++i], c_ :> Sow[c, i]}\n    , 1] ~Reap~ Range@10]\n\n(* \" mix it  up and it can  look silly\" *)\n\nThis just scans through the characters one at a time and Sows them with an integer tag. The tag starts with a high value (i=10) and is decremented if an open bracket is encountered, and incremented when a closing bracket is encountered. The Reap collects the results in order, starting with the smallest integer tag (i.e. the most deeply nested characters).\n\nshare|improve this answer\nNice and clean, but can you get rid of the extra spaces without adding too much? \u2013\u00a0 Mr.Wizard Apr 11 '14 at 17:47\n@Mr.Wizard, I decided the use of spaces was inconsistent in the original string so didn't worry about it ;-) \u2013\u00a0 Simon Woods Apr 11 '14 at 19:37\nThat sounds reasonable. :-) \u2013\u00a0 Mr.Wizard Apr 11 '14 at 19:38\nClever as usual...+1 \u2013\u00a0 ciao Apr 13 '14 at 2:40\n\nThis is a straightforward attempt at a recursive descent parser, favoring readability over brevity.\n\nFirst, the tokenizer:\n\ntokenize[str_] := DeleteCases[StringCases[str,\n    \"(\" -> open[1],\n    \"[\" -> open[2],\n    \"{\" -> open[3],\n    \")\" -> close[1],\n    \"]\" -> close[2],\n    \"}\" -> close[3],\n    x : (Except[Characters[\"()[]{}\"]] ..) :> token[StringTrim[x]]\n    }], token[\"\"]]\n\nAnd the \"parser\":\n\nparse[{open[i_], rest : ___}, backetStack_: {}] := \n parse[{rest}, Prepend[backetStack, i]]\n\nparse[{close[i_], rest : ___}, backetStack_: {}] := (\n  If[Length[backetStack] == 0, Throw[\"No matching open bracket\"]];\n  If[backetStack[[1]] != i, Throw[\"Closing bracket doesn't match\"]];\n  parse[{rest}, Rest[backetStack]])\n\nparse[{token[t_], rest : ___}, backetStack_: {}] := \n Prepend[parse[{rest}, backetStack], \n  tokenDepth[Length[backetStack], t]]\n\nparse[{}, {}] := {}\nparse[{}, _] := (Throw[\"Brackets not closed\"]; {})\n\nThis returns a flat list of tokens, in the same order as the input string, with the depth attached, so:\n\n\nreturns something like:\n\n{tokenDepth[1, \"racket for\"], tokenDepth[2, \"brackets\"], \n tokenDepth[3, \"matching\"], tokenDepth[2, \"is a\"], \n tokenDepth[1, \"computers\"]}\n\nAll that's left is sorting the tokens by depth, and reuniting them to a string:\n\n Riffle[Last /@ Sort[parse[tokenize[str]], #1[[1]] >= #2[[1]] &], \n  \" \"]]\nshare|improve this answer\n\nAs no one gave a FixedPoint answer, here is one:\n\npreparedStr =\n                  \"((your[drink {remember to}]) ovaltine)\",\n                   RegularExpression[\"[{[(]\"] -> \"{\",\n                   RegularExpression[\"[)\\]}]\"] -> \"}\"\n\"{{your{drink {remember to}}} ovaltine}\"\nlst = {};\n                RegularExpression[\"{([^{}]*)}\"] :> (AppendTo[lst, \"$1\"]; \"\")\n               ] &,\nlst // Riffle[#, \" \"] & // StringJoin // StringReplace[#, Whitespace -> \" \"] &\n\"remember to drink your ovaltine\"\n\nHere the StringReplace[ ] will look for the innermost substring matching the pattern \"{...}\", where there is no other \"{\" or \"}\" inside it, and store it to lst, then replace the matched one with \"\". FixedPoint will do this iteratively until the result doesn't change any more.\n\nshare|improve this answer\n\nReset the kernel first.\n\n\nnew = StringReplace[\n        StringReplace[str, {\"(\" | \"[\" -> \"{\", \")\" | \"]\" -> \"}\"}],\n        {(a : WordCharacter ~~ \" \" | \"\" ~~ \"{\") :> a <> \",{\",\n         (a : WordCharacter ~~ \" \" ~~ b : WordCharacter) :> a <> \",\" <> b,\n         (\"}\" ~~ \" \" | \"\" ~~ b : WordCharacter) :> \"},\" <> b\n\n    }] // ToExpression\n{can, {and, it, {it, {mix}, up}}, look, silly}\n  ToString /@ \n   Flatten[DeleteCases[Level[new, {#}], _List] & /@ \n  \" \"]\n\"mix it up and it can look silly\"\nshare|improve this answer\n\nThis will give you an idea to start with I think:\n\ntarget = \"[racket for {brackets (matching) is a} computers]\"\n\n  Nest[With[{s = StringPosition[#, {\"{\", \"(\", \"[\"}][[-1, 1]], \n      e = StringPosition[#, {\"}\", \")\", \"]\"}][[1, 1]]},\n     Sow[StringTake[#, {s + 1, e - 1}]];\n     StringDrop[#, {s, e}]] &, target, \n   Length@StringPosition[target, {\"{\", \"(\", \"[\"}]]]\n\n(* {{{matching,brackets  is a,racket for  computers}}} *)\n\nThe remaining braces are Mathematica's, use the result list to StringJoin or whatever else you need.\n\nshare|improve this answer\nstr = \"[to {quite similar(answer (My) is)} Kuba's answer]\";\nmid = StringReplace[\n        \"Hold@\" <> str, {\"[\" | \"(\" -> \"{\", \"]\" | \")\" -> \"}\"}] // \n       ToExpression // InputForm // ToString, \"*\" -> \",\"] // \n   ToExpression // ReleaseHold\n{to, {quite, similar, {answer, {My}, is}}, Derivative[1][Kuba], s, answer}\n Riffle[ToString /@ \n        Flatten[Sow@DeleteCases[#, a_List]; Cases[#, a_List], 1] &, \n        new, Depth@# > 2 &], 1], -1], \" \"]\n\"My answer is quite similar to Kuba' s answer\"\nshare|improve this answer\n paren = {{\"\\\\(\", \"\\\\)\"}, {\"\\\\[\", \"\\\\]\"}, {\"{\", \"}\"}};\n allparen = StringJoin@Flatten[paren];\n re = RegularExpression[\n      StringJoin[#[[1]] <> \"[^\" <> allparen <> \"]*\" <> #[[2]] <> \"|\" & /@paren] , \n       {1, -2}]];\n sr := Function[strl,\n      Fold[ (Sow[\" \" <> StringTake[strl, #2 + {1, -1}] <> \" \"];\n          StringReplacePart[#1, \"\", #2]) &, strl,\n            StringPosition[strl, re, Overlaps -> False] ]];\n StringReplace[ StringJoin@First@Last@Reap[\n       NestWhile[sr, \"(\" <> str <> \")\", # != \"\" &] ] ,\n       {RegularExpression[\"^ *\"] -> \"\",\n        RegularExpression[\" *$\"] -> \"\",\n        RegularExpression[\"  *\"] -> \" \"}]\n\n\"mix it up and it can look silly\"\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://plus.maths.org/content/comment/reply/2957\nText:\nReply to comment\n\nColoured hat exam solution\n\nMarch 2009\n\nThis puzzle and its solution were kindly provided by Christopher Dowden.\n\nThe coloured hat exam\n\n\n\n\nOf course, normal exam regulations will apply, so the students won't be allowed to communicate with each other in any way once they are in the hall. They only know that the colours will be red and yellow, and that all 8 possible combinations (RRR, RRY, RYR, YRR, RYY, YRY, YYR and YYY) are equally likely.\n\n\n\n\nA problem like this has recently been circulating around universities all over the world. At first sight, it appears that 50% is the best the students can possibly achieve. For example, if they decide that Alice will write \"pass\" and that Ben and Chris will both write \"red\", then they will only have a 25% chance of winning (since they will only succeed if Ben and Chris are both given red hats). The situation is exactly the same if they decide instead that Ben and Chris will both guess yellow, or that Ben will guess yellow and Chris will guess red, or vice versa. If they decide that all three will guess red (or any other particular combination), then this is even worse as they will only have a 1/8 chance.\n\nThere are other more complicated strategies. For example, one possible tactic would be for Alice and Ben to both write \"pass\", and for Chris to write \"red\" if he sees that Alice and Ben are both wearing red hats and \"yellow\" otherwise. However, this will only be successful if the configuration of Alice, Ben and Chris's hats are RRR, RYY, YRY or YYY, which is again only a 50% chance. There is no way that Chris can use the information he has about Alice and Ben's hats to predict the colour of his own.\n\nIt seems that the knowledge the students have about each other's hats is useless, but in fact this information turns out to be a crucial part of the optimal strategy. With the right plan, the pupils will actually get a 75% chance of winning.\n\nAn optimal strategy is as follows: if a student sees that the other two are both wearing red hats, then he should answer \"yellow\"; if he sees that the others are both wearing yellow, he should answer \"red\"; otherwise (if the others have different coloured hats), he should write \"pass\". The possible permutations of hat colours and guesses are:\n\nHat colours of Alice,\nBen and Chris resp.\nGuesses of Alice,\nBen and Chris resp.\nWin or lose\nR R Y - - Y W\nR Y R - Y - W\nY R R Y - - W\nR Y Y R - - W\nY R Y - R - W\nY Y R - - R W\nWith this strategy, the pupils will only lose if the hats are all red or all yellow, giving them a 75% chance of winning! Notice that this is despite the fact that each individual student is just as likely to guess the wrong colour as the right one.\n\nIt turns out that 75% is the best that three pupils can possibly do, but what if there were more than three of them? One possible strategy would be for all the additional students to always write \"pass\" and for Alice, Ben and Chris to ignore the hats of these extra people and answer in exactly the same way as before. Again, the students would only lose if Alice, Ben and Chris all had the same colour hat, so they would still have a 75% chance of winning.\n\nIs there any way that the students can ever do better than 75%? In fact, by using techniques from the world of coding theory it can actually be shown that if the number of people is equal to $2^ k - 1$ for some $k$ (1, 3, 7 and 15 are all numbers like this), then an optimal strategy will give the pupils a $\\frac{2^ k-1}{2^ k}$ probability of winning, giving the probabilities\n\nNumber of students Probability of winning\n1 1/2\n3 3/4\n7 7/8\n15 15/16\n31 31/32\n63 63/64\n\nand so on.\n\nIn general, if the number of students is not equal to $2^ k - 1$, the optimal strategy and chance of winning are not known!\n\nFortunately, Alice, Ben and Chris were all extremely clever (and lucky), and they passed the test successfully. Mr Chalk was very pleased to discover that he had such bright students, and so they all lived happily ever after \u2014 until the next lesson.\n\nThis puzzle is treated in more detail in the book Impossible?, which has been reviewed in Plus.\n\nAbout the author\n\n\nBack to main puzzle page\n\n\n  \u2022 Lines and paragraphs break automatically.\n\nMore information about formatting options\n\nTo prevent automated spam submissions leave this field empty.\nBy submitting this form, you accept the Mollom privacy policy."}
{"text": "Retrieved from http://mathoverflow.net/questions/27234/elogz-t2-proof-of-convergence-with-law-of-large-numbers\nText:\nTake the 2-minute tour \u00d7\n\nHi all, question: Let $Z_t$ be an iid sequence with $$\\mathbb{E}\\log(Z_t^2)<0 $$ Show that $$\\sum_{j=0}^\\infty Z_t^2 Z_{t-1}^2 ... Z_{t-j}^2 < \\infty$$ almost surely\n\nI am supposed to use LLN to solve this... but i can't make ends meet (this is exam preparation sheet question)\n\nshare|improve this question\nThis is just a straightforward exercise. Don't think it is really the kind of question this site is intended for. To answer, take the log of the product, divide by n and use LLN to deduce that the product is less than one (almost surely) for all large n. \u2013\u00a0 George Lowther Jun 6 '10 at 17:13\nActually I misread it. The formula doesn't seem to make sense. Shouldn't the product be $Z_1\\cdots Z_j$, in which case the LLN shows that the terms are almost surely bounded by a geometric series with ratio less than 1, so absoluty convergent. \u2013\u00a0 George Lowther Jun 6 '10 at 17:22\n\n2 Answers 2\n\nIf the term $Z_i^2$ of the independent and identically distributed random sequence is less than 1, then you can find a $q$ with $Z_i^2 \\leq q < 1$ for almost all $i$ (acording to the law of large numbers). Then the $k$-fold product is less than $q^k$ such that the geometric series limits your sum by $\\frac{1}{1-q}$.\n\nI presume that you meant $Z_{t+j}^2$ instead of $Z_{t-j}^2$. Otherwise you'd get negative indices.\n\nshare|improve this answer\n\nFor every $t$, let $Y_t=\\log(Z_t^2)$. Fix some $t$. The sequence $(Y_{t-k})_{k\\geqslant0}$ is i.i.d. with $E[Y_t]\\lt0$ hence the usual law of large numbers yields $\\frac1j\\sum\\limits_{k=0}^{j-1}Y_{t-k}\\to E[Y_1]$. Fix some negative $m\\gt E[Y_1]$.\n\nThen $\\frac1j\\sum\\limits_{k=0}^{j-1}Y_{t-k}\\leqslant m$ for every $j$ large enough, that is, for every $j\\geqslant J$ where $J$ is random and almost surely finite. In particular, for every $j\\geqslant0$, $\\sum\\limits_{k=0}^{j}Y_{t-k}\\leqslant mj+X$, for some almost surely finite random $X$. This implies the pointwise convergence of the series since $$ \\sum_{j\\geqslant0}\\exp\\left(\\sum\\limits_{k=0}^{j}Y_{t-k}\\right)\\leqslant\\sum_{j\\geqslant0}\\mathrm e^X\\mathrm e^{mj}=\\mathrm e^X(1-\\mathrm e^m)^{-1}. $$ Note that the RHS above is almost surely finite since $m\\lt0$ but is not (a priori) uniformly bounded since $X$ may be unbounded.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/29469/spontaneous-time-reversal-symmetry-breaking?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nIt is known that you can break P spontaneously--- look at any chiral molecule for an example. Spontaneous T breaking is harder for me to visualize. Is there a well known condensed matter system which is uncontroversial example where T is broken spontaneously?\n\nI remember vaguely articles of Wen, Wilczek, and Zee from 1989 or so on standard High Tc hopping models, electrons which singly-occupy lattice sites, double-occupation repulsion, small amount of p-doping (holes running around), where they made the claim that T is spontaneously broken. Unfortunately I didn't understand how this happened or if it actually happened. If somebody understands the Zee example, that's good, but I would be happy with any example.\n\nI am not looking for explicit T breaking, only spontaneous T breaking. I would also like an example where the breaking is thermodynamically significant in the large system limit, so mesoscopic rings with permanent currents caused by electron discreteness is not a good example.\n\nshare|improve this question\nI guess you are thinking about the papers by Wen, Wilczek and Zee. I remember this is explained in Xiao-Gang Wens book (chapter 9), under chiral spin liquids. Sadly I don't remember the details or have the book to look in right now. \u2013\u00a0 Heidar Jun 4 '12 at 9:04\nBetter fix it quickly before Wen reads it! (I apologize, I was citing from memory) \u2013\u00a0 Ron Maimon Jun 4 '12 at 9:09\nAnd I suppose that you're not talking about spontaneous CP breaking that then implies spontaneous T breaking via CPT, right? \u2013\u00a0 Jerry Schirmer Jun 4 '12 at 11:35\nThe simplest example in condensed matter physics that spontaneously breaks time reversal symmetry is a ferromagnet. Because spins (angular momentum) change sign under time reversal, the spontaneous magnetization in the ferromagnet breaks the symmetry. This is a macroscopic example. \u2013\u00a0 Everett You Jun 4 '12 at 14:28\nI was about to mention the same example as Everett You. So let me just add that the same applies roughly speaking to any many-body system T-invariant on the microscopic (Hamiltonian) level where some continuous symmetry is spontaneously broken and the associated Nambu-Goldstone boson has a dispersion relation quadratic in momentum. The reason is that the effective Lagrangian for the NG boson then contains a term with a single time derivative. \u2013\u00a0 Tom\u00e1\u0161 Brauner Jun 4 '12 at 14:54\n\n2 Answers 2\n\nup vote 15 down vote accepted\n\n\nThe chiral spin liquid (Wen-Wilczek-Zee) mentioned in the question is a non-trivial example that breaks time reversal but with out any spontaneous magnetization. Its order parameter is the spin chirality $E_{123}=\\mathbf{S}_1\\cdot(\\mathbf{S}_2\\times\\mathbf{S}_3)$, which measures the Berry curvature (effective magnetic field) in the spin texture. Because $E_{123}$ also changes sign under time reversal, so the T symmetry is broken by spontaneous development of the spin chirality. Chiral spin liquid can be consider as a condensation of the skyrmion which carries the quantum of spin chirality but is spin neutral as a whole.\n\nIn fact, within the spin system, one can cook up any order parameter consisting of odd number of spin operators ($\\mathbf{S}_1$ for ferromagnets and $E_{123}$ for chiral spin liquid are both examples of such constructions). Then by ordering such order parameter, the time reversal symmetry can be broken spontaneously.\n\nBeyond the spin system, it is still possible to break time reversal symmetry by the development of orbital angular momentum (loop current) ordering. Just think of spins and loop currents are both angular momenta, what can be done with spins can also be done with loop currents. Indeed, the spinless fermion system can break the time reversal symmetry using the loop current (Note the word \"spinless\", so there is no spin SU(2) nor spin-orbit coupling involved in the following discussion). Simply consider the spinless fermion $c_i$ on a square lattice coupling to a U(1) gauge field $a_{ij}$, the Hamiltonian reads $$H=-t\\sum_{\\langle ij\\rangle}e^{ia_{ij}}c_i^\\dagger c_j+g\\sum_\\square \\prod_{\\langle ij\\rangle\\in\\partial\\square}e^{ia_{ij}}+h.c.$$ With zero flux per plaquette and with the filling of 1/2 fermion per site, the system has a fermi surface and the fermi level rest on a Van Hove singularity, which is very unstable energetically. The fermions wish to develop any kind of order as long as a it helps to open a gap at the fermi level, such that the fermi energy can be reduced. It is found that the stagger flux is a solution, in which the U(1) flux $\\pm\\phi$ goes through the plaquette alternately following the checkboard pattern. The corresponding gauge connection is $a_{i,i+x}=0, a_{i,i+y}=(\\phi/2)(-)^{i_x+i_y}$. One can show that the energy dispersion for the fermion is given by $$E=\\pm\\sqrt{\\cos^2k_x+\\cos^2k_y+2\\cos\\frac{\\phi}{2}\\cos k_x\\cos k_y},$$ which removes the Van Hove singularity and opens up a pseudo gap (like Dirac cones) as long as $\\phi\\neq 0$. Therefore driven by the fermi energy, $\\phi$ wishes to grow toward the maximum flux $\\pi$. However due to the $g$ term in the Hamiltonian, the development of stagger flux consumes magnetic energy (the energy of orbital angular momentum), which grows as $\\phi^2$ for small $\\phi$. The competition between the fermi energy $t$ and the magnetic energy $g$ will eventually agree on a saddle point value for $\\phi$ which is between 0 and $\\pi$ and its specific value can be tuned by the $t/g$ ratio. In terms of fermions, the stagger flux $\\phi$ is interpreted as loop currents alternating between clockwise and counterclockwise around each plaquette following the check board pattern. Such a state is also call the orbital antiferromagnet (an antiferromagnetic arrangement of orbital angular momentum) or d-wave density wave (DDW) in high-Tc context.\n\nHere $\\phi$ serves as the order parameter of the stagger flux state. Because $\\phi$ changes sign under time reversal symmetry (like any other magnetic flux), the spontaneous development of the stagger flux pattern in the spinless fermion system will break the time reversal symmetry. In solid-state materials, such phenomenon has not been observed due to the too small $t/g$ ratio which is unable to drive $\\phi$ away from 0. However considering the fast development of cold atom physics, the spontaneous time reversal symmetry broken in spinless fermion system may be realized in the future in the optical lattice.\n\nshare|improve this answer\n+1, accepted, and thanks. \u2013\u00a0 Ron Maimon Jun 16 '12 at 16:52\n@RonMaimon Welcome. I have learnt much from you in your other posts. \u2013\u00a0 Everett You Jun 16 '12 at 19:47\n\nPerhaps chiral superfluids and superconductors are also good examples. The A-phase of liquid 3-He, for instance, is known to be a TRSB superfluid with pairing $p_x + i p_y$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207303/throwing-coins-probability\nText:\nTake the 2-minute tour \u00d7\n\nX and Y are throwing coins. X throws $n$ times and Y throws $n+1$ times. What's the probability that Y got more heads than Y?\n\nI was trying to consider all the situations that X got $i$ heads and Y got $j>i$ heads but it didn't lead me to any sensible conclusion.\n\nshare|improve this question\n\n2 Answers 2\n\nLet $H_X, H_Y,T_X,T_Y$ denote the heads and tails counts of $X$ and $Y$. Assume that the heads of $X$'s coin is red, tails green, whereas the heads of $Y$'s coin is green, tails red. We ask for the probability of $$H_Y>H_X$$ $$\\iff T_X+H_Y=n-H_X+H_Y>n+H_X-H_Y=H_X+T_Y-1\\\\\\iff T_X+H_Y\\ge T_Y+H_X$$ But the latter expression is just that the number of grean outcomes is at least as large as the number of red ones. For this, the answer (by symmetry and since ties cannot occur) $\\frac12$.\n\nAlternatively, let $Y$ delay her last throw. With both players making $n$ throws, there is a certein probability $p$ that $X$ has more heads, the same probaility that $Y$ has more heads, and the probability $1-2p$ for a tie. With the last coin, $Y$ can only make a change in case of a tie and does so half the time for a win. That is: The probability of more heads for $Y$ is $p+\\frac{1-2p}2=\\frac12$.\n\nshare|improve this answer\n\nLet $X_n$ and $Y_n$ be the number of head in the first $n$ tosses. What is asked for is the probability of $$P(X_n < Y_{n+1}) = P(X_n < Y_n) + P(X_n = Y_n)P(\\text{last toss of }Y \\text{is a head})$$ Apparently, $P(X_n<Y_n)+P(X_n>Y_n)+P(X_n=Y_n)=1$ and because of symmetry, $P(X_n<Y_n)=P(X_n>Y_n)$ so that $P(X_n<Y_n)=\\frac{1-P(X_n=Y_n)}{2}$. Moreover, $P(\\text{last toss of }Y \\text{is a head})=1/2$. Plug them into the above equation, you will find out that $$P(X_n<Y_{n+1})=\\frac{1}{2}$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/72555/generating-coordinates-for-n-points-on-the-circumference-of-an-ellipse-with-fi/442308\nText:\nTake the 2-minute tour \u00d7\n\nI have an ellipse with semimajor axis $A$ and semiminor axis $B$. I would like to pick $N$ points along the circumference of the ellipse such that the Euclidean distance between any two nearest-neighbor points, $d$, is fixed. How would I generate the coordinates for these points? For what range of $A$ and $B$ is this possible?\n\nAs a clarification, all nearest-neighbor pairs should be of fixed distance $d$. If one populates the ellipse by sequentially adding nearest neighbors in, say, a clockwise fashion, the first and last point added should have a final distance $d$.\n\nshare|improve this question\nadd comment\n\n5 Answers 5\n\nup vote 3 down vote accepted\n\nAs long as $d$ is sufficiently small (where \"sufficiently small\" depends on the eccentricity of the ellipse), you can proceed as follows:\n\nStart at point $P_0$, and set off around the ellipse in steps of (Euclidean) length $d$, leaving point $P_i$ at the $i$th step. When you reach or pass the original point $P_0$, leave a point $P_n$ there, and stop.\n\nIf $P_n$ and $P_0$ coincide, we are done, Otherwise, decrease $d$ continuously until they do. Now we have $n$ equally spaced points on the ellipse. And we can repreat this procedure to find $n+1$ equally spaced points, and so on.\n\nThere are two things that can go wrong:\n\n  1. This procedure works, but the ellipse is so eccentric that $P_{i-1}$ and $P_{i+1}$ are not the nearest neighbours of $P_i$ (because there is a closer point across the semi-minor axis).\n  2. For some $i$, the position of $P_i$ is not a continuous function of $d$. This can happen if $P_{i-1}$ is near the 'sharp end' of the ellipse, and the line $P_{i-1} P_i$ is normal to the ellipse at $P_i$. This can happen if, roughly, the curvature of the ellipse exceeds $\\frac{1}{2d}$ at some point.\nshare|improve this answer\nadd comment\n\nPerhaps I am misinterpreting your question, as I think there is a very simple way to do this. Given the ellipse, and given $N$, take $d$ very small compared to $A/N$, pick a point on the ellipse, then going around the ellipse clockwise (say) pick points such that each is at distance $d$ from the preceding one. Locating each point is a simple matter of finding the intersection with the ellipse of a circle of radius $d$ centered at the previous point.\n\nIf this is not what you want, please clarify your question.\n\nshare|improve this answer\nIf I take $d$ very small to $\\frac{A}{N}$ then won't the two terminal points won't have a nearest-neighbor distance of $<<d$? \u2013\u00a0 Ness Oct 14 '11 at 8:54\n@Ness: it may, it may not. It's hard to tell unless you actually do it... \u2013\u00a0 \uff2a. \uff2d. Oct 14 '11 at 8:59\nI think the OP wants the distance between the first and last points to be $d$ too. So the question is not trivial. \u2013\u00a0 TonyK Oct 14 '11 at 9:03\n@TonyK, right, that's what I was trying to say. If I don't care about this nearest-neighbor pair, the problem is trivial. \u2013\u00a0 Ness Oct 14 '11 at 9:13\nI just adding a (hopefully) appropriate clarification to the problem description. \u2013\u00a0 Ness Oct 14 '11 at 9:18\nshow 2 more comments\n\nTo find such points exactly amounts to solving a system of $2N$ or so quadratic equations. A practical way could be the following: Choose the points $$z_k:=\\bigl(A\\cos{2\\pi k\\over N}, B\\sin{2\\pi k\\over N}\\bigr)\\quad(0\\leq k\\leq N)$$ $(z_0=z_N)$ as starting set and update the $z_k$, $0<k<N$, recursively in the following way: Each $z_k$ is replaced by the point $z_k'$ on the arc $(z_{k-1},z_{k+1})$ which is at equal distance from $z_{k-1}$ and $z_{k+1}$. This point can be found by solving a single quadratic equation. I conjecture that this procedure converges \"linearly\" to the unique solution of the problem with $z_0=(A,0)$.\n\nshare|improve this answer\nadd comment\n\nI will assume that $A$, $B$ and $N$ are given, and that $d$ is unknown.\n\nThere is always a solution. Let $L$ be the perimeter of the ellipse. An obvious constraint is $N\\,d<L$. Take $d\\in(0,L/N)$. As explained in Gerry Myerson's answer, pick a point $P_1$ on the ellipse, and then pick points $P_2,\\dots,P_N$ such that $P_{i+1}$ is clockwise from $P_i$ and the euclidean distance between $P_i$ and $P_{i+1}$ is $d$. If $d$ is small, $P_N$ will be short of $P_1$, while if $d$ is large, it will \"overpass\" $P_1$. In any case, the position of $P_N$ is a continuous function of $d$. By continuity, there will be a value of $d$ such that $P_1=P_N$. It is also clear that this value is unique.\n\nTo find $P_N$ for a given $d$ you need to solve $N-1$ quadratic equations. To compute the value of $d$, you can use the bisection method.\n\nEdit: TonyK's objections can be taken care of if $N=2\\,M$ is even. Take $P_1=(A,0)$ and follow the procedure to find points $P_2,\\dots,P_{M+1}$ in the upper semiellipse such that $P_{i+1}$ is clockwise of $P_i$ and at distance $d$, and $P_{M+1}=(-A,0)$. The the sought solution is $P_1,\\dots,P_{M+1},\\sigma(P_M),\\dots,\\sigma(P_2)$, where $\\sigma(P)$ is the point symmetric of $P$ with respect to the axis $y=0$.\n\nIf $N=2\\,M+1$ is odd, I believe that there is also a symmetric solution, but I have to think about it.\n\nshare|improve this answer\nSee my answer for objections to this argument! \u2013\u00a0 TonyK Oct 14 '11 at 10:03\n@TonyK I have edited my answer. \u2013\u00a0 Juli\u00e1n Aguirre Oct 14 '11 at 11:37\nYour solution for even $M$ doesn't answer my first point. If the ellipse is flat enough, it may be that $P_{M+1}$ is closer to $P_{M-1}$ than it is to $P_M$. \u2013\u00a0 TonyK Oct 14 '11 at 11:42\nSo by symmetry we could also have $P_3$ closer to $P_1$ than $P_2$? \u2013\u00a0 Juli\u00e1n Aguirre Oct 14 '11 at 13:14\nSorry, I meant $P_{M+2}$ is closer to $P_M$ than to $P_{M+1}$. So by symmetry $P_2$ is closer to $P_{N-1}$ than to $P_1$. Draw yourself an ellipse with $A=5, B=1$, and take $N=8$. Then you'll see what I mean. \u2013\u00a0 TonyK Oct 14 '11 at 14:44\nshow 3 more comments\n\nAssuming you have a starting point along the ellipse, position P, generate the next candidate points by intersecting the ellipse with a circle of radius d, where d is the desired distance between adjacent points\n\nThen choose the candidate which is of the desired winding. Winding can be calculated by considering the vector from the origin of the ellipse to position P and the vector from position P to the candidate position.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141377/ranking-probability-problem\nText:\nTake the 2-minute tour \u00d7\n\n$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$.\n\nWe know $P(A > B) = 0.7, P(B > C) = 0.6$, what is $P(A > C)$?\n\nIs this a well defined problem? Does it have a sensible answer?\n\nEDIT: Suppose we have two careless observers. An observer observes $A > B$ and there are 70% probability that she is right. Another observer observes $B > C$ and there are 60% probability that she is right. So what is the probability of $A > C$ in the underlying event?\n\nshare|improve this question\nWait, if they are all sampled from the same uniform distribution on $[0,1]$, how can we have $P(A > B) \\neq 0.5$? \u2013\u00a0 TMM May 5 '12 at 13:37\n@TMM I edited the question. Is it well defined now? \u2013\u00a0 lqhl May 5 '12 at 14:05\nThere is a potentially interesting Bayesian problem here, struggling to get out. \u2013\u00a0 Andr\u00e9 Nicolas May 5 '12 at 14:29\nadd comment\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nI wrote following MATLAB code. Simulation results show the probability is around 0.602. I hope someone could confirm this with an analytic answer.\n\nN = 1000000;\n\nA = rand(N, 1);\nB = rand(N, 1);\nC = rand(N, 1);\n\np1 = 0.7;\np2 = 0.6;\n\nc1 = rand(N, 1);\nc2 = rand(N, 1);\n\nob1 = ((A > B) & (c1 < p1)) | ((A < B) & (c1 > p1));\nob2 = ((B > C) & (c2 < p2)) | ((B < C) & (c2 > p2));\n\nob = ob1 & ob2;\n\npos = ob & (A > C);\n\nsum(pos) / sum(ob)\n\n\nI enumerate all the 6 possibilities of relative order of $A, B, C$. They all appear with probability 1/6.\n\nThe following lists shows with how much probability each case passes the two observers\n\n  \u2022 $A>B>C$, $0.7\\times 0.6$\n\n  \u2022 $A>C>B$, $0.7\\times 0.4$\n\n  \u2022 $B>A>C$, $0.3\\times 0.6$\n\n  \u2022 $B>C>A$, $0.3\\times 0.6$\n\n  \u2022 $C>A>B$, $0.7\\times 0.4$\n\n  \u2022 $C>B>A$, $0.3\\times 0.4$\n\nAmong them, $A>B>C$, $A>C>B$, $B>A>C$ are the valid cases. So\n\n$\\frac {0.7\\times 0.6+0.7\\times 0.4+0.3\\times 0.6} {0.7\\times 0.6+0.7\\times 0.4+0.3\\times 0.6+0.3\\times 0.6+0.7\\times 0.4+0.3\\times 0.4} = 0.6027$\n\nshare|improve this answer\nWhat does \"$A > C > B, 0.7 \\times 0.4$\" mean? Certainly it cannot mean $P(A > C > B) = 0.7 \\cdot 0.4$. \u2013\u00a0 TMM May 5 '12 at 15:35\n@TMM It means the probability that $A>C>B$ passes the two observers. Since $A>C$, it passes the first observer probability with $70\\%$ (she makes a correct observation) probability. Since $C>B$, it passes the second observer with $40\\%$ probability (she makes a mistake). And the two events are independent. Hope this solves your problem :) \u2013\u00a0 chtlp May 5 '12 at 15:41\nNope, it doesn't. The two observations are fixed, while the values of $A,B,C$ are not. So what does \"the probability that [it] passes the two observers\" mean? \u2013\u00a0 TMM May 5 '12 at 15:45\n@TMM Imagine we repeat sampling $\\langle A, B, C\\rangle$ many times, some of them fit the description $P(A>B)=0.7$, $P(B>C)>0.6$ (``pass the observers''). And we want to know in these events, how many of them have $A>C$. \u2013\u00a0 chtlp May 5 '12 at 16:16\n+1: Despite the downvoting, the simulated answer and the maths is absolutely correct, under the assumption that the values of A,B and C are independent of the observed probabilities. Nice job. \u2013\u00a0 Ronald May 5 '12 at 23:27\nadd comment\n\nAh. It depends strongly on the method for making those probabilistic observations.\n\nFor example: If we observe that A=0.7, then we should note P(A>B)=0.7.\n\nIf we observe that C=0.4, then we should note P(B>C)=0.6.\n\n(This is perhaps the most obvious, natural way of accessing those probabilities. An observation of B would affect both probabilities)\n\nAnd, if those were our observations, then it's absolutely guaranteed that A>C. P(A>C) = 1.\n\nshare|improve this answer\nYou are assuming $A$ is fixed in $P(A > B) = 0.7$, but it could also be that $B$ is fixed, e.g. $B = 0$ and $A = B + U(-0.3, 0.7)$ and $C = B + U(-0.4, 0.6)$ with $U(a,b)$ a uniformly distributed random variable on $[a,b]$. In that case $P(A > C) > 0.5$ but $P(A > C) \\neq 1$. \u2013\u00a0 TMM May 5 '12 at 17:24\nAs I said, it depends on the method of making the probabilistic observations. What I said is consistent with the observations, and I would argue is the most natural way for those observations to occur, but there are other possible cases. \u2013\u00a0 Ronald May 5 '12 at 23:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/86695/existence-of-polynomial-equation-system-solution\nText:\nTake the 2-minute tour \u00d7\n\nFor $1 \\leq i \\leq n$, let $A=\\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{n1} & \\cdots & a_{nn} \\\\ \\end{bmatrix}$\n\n$B_i=\\begin{bmatrix} b_{i1} \\\\ \\vdots \\\\ b_{in} \\end{bmatrix}$ and $C_i=\\begin{bmatrix} c_{i1} \\\\ \\vdots \\\\ c_{in} \\end{bmatrix}^*$\n\nLet $D=A+\\sum_{1 \\leq i \\leq n}B_i k_i C_i$. Then, for almost all $a_{ij},b_{ij},c_{ij}$, there exists $k_i \\in \\mathbb{C}$ such that all eigenvalues of $D$ are zeros.\n\nshare|improve this question\nWhy do you think this is true? Does the $2\\times 2$ case work? \u2013\u00a0 Yemon Choi Jan 26 '12 at 7:52\nConsider the characteristic polynomial $P(k_1,\\ldots,k_n,\\lambda) = \\det(D - \\lambda)$. For all eigenvalues of $D$ to be $0$, the coefficients of $\\lambda^0$ to $\\lambda^{n-1}$ must be $0$. That makes $n$ polynomial equations in the $n$ variables $k_1, \\ldots, k_n$. I would expect that for almost every choice of the $a_{ij}, b_{ij}, c_{ij}$ this system of equations will have at least one solution in ${\\mathbb C}^n$. \u2013\u00a0 Robert Israel Jan 26 '12 at 8:33\nConsider the matrix $C$ made by stacking the $C_i$ together, the matrix $K$ with $k_i$ on the diagonal and $0$ elsewhere, and the matrix $B$ by lining up the $b_i$ against each other. We can then write: $D=A+BKC$. In general position, $C$ is invertible, so we can conjugate by it and change $D$ and $B$ as appropriate, and we are left with $D=A+BK$, with $A$ and $B$ generic and $K$ chosen from among diagonal matrices. I think we want the eigenvalues of $D$ to all be different. If those are different and $B$ and $C$ are invertible, I think it should work. \u2013\u00a0 Will Sawin Jan 26 '12 at 21:46\nDoes anyone know what the tangent space of the variety of nilpotent matrices looks like? If it did not contain any invertible matrices, or matrices in any other \"generic\" class, that would solve the problem by a dimension argument. \u2013\u00a0 Will Sawin Jan 26 '12 at 22:00\nadd comment\n\n1 Answer 1\n\n[update] By an example of 4x4-matrices the ansatz below could not be used to solve the problem. The matrix $\\small Q_K $ cannot in general be made lower triangular by choices of the $\\small k_i $. I'll delete this answer soon if I cannot improve the ansatz.\n\nI do not yet have a full answer but possibly a first step into one. I think that this can be answered unsing two facts:\n\na) There is a similarity transformation with a rotation T such that $\\small P = T^{-1}\\cdot A \\cdot T = T' \\cdot A \\cdot T $ where P is triangular and has the eigenvalues of A on its diagonal.\n\nb) Your sum-expression of vector outer products, let it be called matrix $\\small E_K = \\sum_{i=1}^n B_i k_i C_i = \\sum_{i=1}^n k_i (B_i C_i)= \\sum_{i=1}^n k_i E_i $ is a weighted (by the $\\small k_i $ weights) sum of rank-1-matrices $\\small E_i $\n\nFrom the \"similarity rotated version\" of all matrices\n\n$\\qquad \\small Q_K = T' E_K T = \\sum_{i=1}^n k_i (T' E_i T) = \\sum_{i=1}^n k_i Q_i $ (which should be made triangular by choices of $\\small k_i $ ) and\n$\\qquad \\small R = T' D T $ which is then also triangular\n\nwe get your final equation in its form with triangular matrices\n\n$\\qquad \\small R = P + Q_K $\n\nWe'll have a solution if the weights $\\small k_i $ for the non-triangular, generic but rank-1-matrices $\\small Q_i $ can be chosen such that their sum $\\small Q_K$ becomes triangular and its diagonal equals the negative diagonal in $\\small P $.\n\nI've a vague speculation that the equation with this triangular matrices can easier be shown to be \"almost always\" possible, but have not yet a further concrete approach. At least this construction exhibits that the rank-1-matrices $\\small E_i $ (and thus $\\small Q_i$ ) cannot be simple scalar multiples of each other if A has full rank and thus the restriction to \"for almost all\" is unavoidable and possibly mainly consists of this property.\n\nshare|improve this answer\nI think this method doesn't work. You can't find the common $T$ such that $T^{-1} A T$ is triangular and $T^{-1} Q_K T$ is also triangular. \u2013\u00a0 Seyong Jan 27 '12 at 3:41\n@Seyong: seems to be true. I tried with a 4x4-example and the $\\small k_i $ could not be chosen such that the strict upper triangle of $\\small Q_K$ is zero: I need one of the $\\small k_i$-parameters to get one entry in $\\small Q_K$ zero but we have $\\small n (n-1)/2 $ such entries to be made zero simultaneously according to my ansatz. I hoped, that the rank-1-property of the $\\small Q_i $-matrices could be exploited, but that seems not be sufficient this way. \u2013\u00a0 Gottfried Helms Jan 27 '12 at 7:12\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192090/what-is-wrong-with-this-idft-trick/192439\nText:\nTake the 2-minute tour \u00d7\n\nIn this section from Wikipedia about IDFT, three methods are given for expressing the Inverse Discrete Fourier Transform in terms of the direct transform.\n\nBeing curious, I implemented the three methods in Octave:\n\n% define TD signal\nN = 1024; n = [1:N]-1; f = [4 8];\nx0 = sin(2*pi*n'*f/N);\nx0 = sum(x0');\n\n% calculate FD spectrum\ny0 = fft(x0);\n\n% trick #1\ny1 = fliplr(y0);\nx1 = fft(y1) / N;\n\n% trick #2\ny2 = conj(y0);\nx2 = conj(fft(y2)) / N;\n\n% trick #3\ny3 = imag(y0) + i*real(y0);\nx3 = fft(y3) / N;\nx3 = imag(x3) + i*real(x3);\n\n% plot results\nplot(n,x0,'m-o', n,x1,'r-*', n,x2,'g-^', n,x3,'bxo');\naxis tight\n\nIf happens that tricks #2 and #3 work well, while trick #1 fails to generate the correct result.\n\nAm I missing something in the explanation, or is there an error in Wikipedia?\n\nUPDATE: It seems like the magnitude of the y1 result is actually OK, it is just that the angle is doing funny things. Replacing the plot line with:\n\nplot(n,abs(x0),'m-o', n,abs(x1),'r-*', n,abs(x2),'g-^', n,abs(x3),'bxo');\n\nshows the overlap.\n\nshare|improve this question\nIn your definition of $n$, you create a row vector. x0 would then be a row vector, except that you take the sin of n': n-transposed. So x0 would, I believe, be a column vector. Which means that y0 would be a column vector, and so fliplr would be operating on a column vector and hence do nothing (at least, this would be the case if Octave works as MATLAB does). Did you check that y0 is a row vector, as expected? \u2013\u00a0 Arkamis Sep 6 '12 at 21:12\n@EdGorcenski - x0 is being transposed in the sum() as well, so I end up with a row vector. Typing whos shows all vectors have a 1 in their 1st dimension. \u2013\u00a0 ysap Sep 6 '12 at 21:33\nAh, so it is; I missed that! \u2013\u00a0 Arkamis Sep 6 '12 at 21:49\n@EdGorcenski - I just posted an update to the question. \u2013\u00a0 ysap Sep 6 '12 at 21:49\nadd comment\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nI found my mistake. According to Wikipedia, using the 1st method, the indices of the reversed series are modulo N. So the correct code is:\n\n% trick #1\ny1 = [y0(1) fliplr(y0(2:N))];\nx1 = fft(y1) / N;\n\nand not as posted in the question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232576/questions-about-convergence-in-lp\nText:\nTake the 2-minute tour \u00d7\n\nIf $X_n$ converges to $X$ in $L^p$, do we have $X_n^p$ converges to $X^p$ in $L^1$?\n\nWe can prove that it is true when p=1,2 easily. I am curious whether this is true for all $p>0$.\n\nshare|improve this question\nYou should consider $|X|^p$ and so on, as $X^p$ does not make sense for all $X$ and all $p>0$. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Nov 8 '12 at 3:05\nThanks for your comment. When I consider Lp convergence, I will take modulus. I don't think we need to add modulus in the beginning. \u2013\u00a0 XXX11235 Nov 8 '12 at 23:53\nadd comment\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nNote that $$|x^p - y^p| = \\left|\\int_y^x p t^{p-1}\\ dt \\right| \\le p (|x|+|y|)^{p-1} |x - y|$$ Thus if $1/p + 1/q = 1$ (where $1 < p,q < \\infty$) $$\\eqalign{\\|X^p - Y^p\\|_1 &\\le \\int p (|X| + |Y|)^{p-1} |X - Y| \\cr &\\le p \\|(|X| + |Y|)^{p-1}\\|_q \\|X - Y\\|_p \\cr &= p \\left(\\int (|X| + |Y|)^p\\right)^{1/q} \\|X - Y\\|_p \\cr &= p \\||X|+|Y|\\|_p^{p/q} \\|X - Y\\|_p \\cr &\\le p (\\|X\\|_p + \\|Y\\|_p)^{p/q} \\|X - Y\\|_p\\cr}$$ If $X_n \\to X$ in $L^p$, $\\|X_n\\|_p$ is bounded, and so we get $\\|X_n^p - X^p\\|_1 \\to 0$.\n\nshare|improve this answer\nGet it. Thank you very much!! \u2013\u00a0 XXX11235 Nov 8 '12 at 23:48\n@Robert Israel: Dear Sir. I have an interesting question in the following math.stackexchange.com/questions/346937/\u2026 I would like to ask your comments? \u2013\u00a0 blindman Apr 12 '13 at 2:18\nadd comment\n\nIt's not correct for $0 < p < 1$. Take $X_n: [0,1] \\to \\mathbb{R}$ as $X_n(x) = n \\cdot I_{[0,1/n)}(x)$, where $I_A$ = indicator function of a set $A$. Then $\\|X_n\\|_p = n^{1-1/p}$ and therefore $X_n \\to 0$ in $L^p$ for $p < 1$, but $X_n$ does not converge in $L^1$.\n\nshare|improve this answer\nI don't understand you solution. But many thanks anyway. \u2013\u00a0 XXX11235 Nov 8 '12 at 23:53\nadd comment\n\nIt is solved by Robert Israel.\n\nshare|improve this answer\nIf you cite an author, give book, edition and page number. Be complete. \u2013\u00a0 ncmathsadist Nov 9 '12 at 2:38\nIt is actually the first answer of this page. I should have said \"It is answered by Robert\" \u2013\u00a0 XXX11235 Nov 10 '12 at 3:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/39088/how-do-i-do-error-calculus-right-using-gnuplot-as-an-example\nText:\nTake the 2-minute tour \u00d7\n\nGiven is a set of measurements with their respective errors for example an energy spectrum. In gnuplot one is to fit a function $ f(x;\\{p_i\\})$ depending on a variable $x$ and on fit parameters $p_i$. When the fit is done one gets values for the $p_i$ with errors and a correlation matrix with values $ c_{ij}$. Now one has to calculate a value $v(\\{\\text{some of the }p_i\\})$ that depends on some of the the $p_i$ and find its error $\\Delta p_i$.\n\nHow will a calculate the error $e$? Do I have to take correlations into account? Can I do it the way I attempted it in my solution attempt.\n\nSolution Attempt: $e^2=\\sum_{i}\\left(\\frac{\\partial v}{\\partial p_i}\\cdot \\Delta p_i\\right)^2+\\sum_{ij}\\frac{\\partial v}{\\partial p_i}\\frac{\\partial v}{\\partial p_j}c_{ij}\\Delta p_i \\Delta p_j$\n\nIf this is right what happens if one of the $c_{ij}$ is negative?\n\nshare|improve this question\nDoes this really have anything to do with gnuplot? It seems like you're just asking how to interpret the results of a regression with uncertainties given on the coefficients. \u2013\u00a0 David Z Oct 5 '12 at 0:46\n@David I agree this is more general than gnuplot, and people here (myself included) can probably give some feedback. But I'm wondering if there's a stackexchange more appropriate for error analysis. \u2013\u00a0 Chris White Oct 5 '12 at 7:26\nI think questions on error analysis in general are fine here, and in fact this is probably the best site on the network to put them on. If not here, I could see them perhaps going on Mathematics. However, questions about gnuplot usage would go on Super User or Computational Science. I suspect this question is basically fine, it just needs to be retitled/edited to show that it is asking about error analysis in general, not the usage of gnuplot to do error analysis, and I wanted to confirm that suspicion with the OP. \u2013\u00a0 David Z Oct 5 '12 at 8:00\nI changed the title. Is this title maybe more ok? Please is there anybody who can answer it? \u2013\u00a0 A badbad student Oct 5 '12 at 10:05\nQuestions about the meaning of sums of residuals in a regression would be fine on Stats.SE, as well. \u2013\u00a0 dmckee Oct 5 '12 at 14:50\nadd comment\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/51570.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nFermat's Little Theorem\n\nDate: 09/02/2000 at 10:49:15\nFrom: Isac Heden\nSubject: Why is (n^p-n)/p always an integer?\n\nHello Dr. Math,\n\nCan you help me prove that the expression n^p-n, where p is an \n\nI can prove it for p = 3 (and p = 2):\n\n     n^3-n = (n-1)n(n+1) \n\nOne of three factors must be divisible by three. And for p = 5:\n\n     n^5-n = n(n^2-1)(n^2+1) = (n-1)n(n+1)(n^2+1)\n\nFor a positive integer a; one of (n-1), n or (n+1) is divisible by 5 \nwhen n = 4+5a, n = 5+5a or n = 1+5a. The last factor (n^2+1) is \ndivisible by 5 when n = 3+5a and when n = 2+5a since the last digit is \nalways 2, 3, 7 or 8 and the last digit of n^2 always is 4 or 9. If you \nadd 1 to 4 or 9 you always obtain a number, whose last digit is either \n5 or 0, and those numbers are divisible by 5.\n\nHence n^5-n can be divided by 5, for any integer n.\n\nBut I can't extend this proof, to apply for any prime, p, and that is \nmy problem.\n\n\nDate: 09/05/2000 at 05:35:03\nFrom: Doctor Floor\nSubject: Re: Why is (n^p-n)/p always an integer?\n\nHi Isac,\n\nThanks for writing.\n\nThe theorem you mention is known as Fermat's Little Theorem.\n\nFor a proof we will do some modular arithmetic. Instead of (n^p-n)/p \nbeing an integer, or n^p-n divisible by p, we will write:\n\n     n^p == n (mod p)\n\nwhich is read as \"n^p is congruent to n modulo p.\" It means that n^p \nand n differ by a multiple of p. So, for example, 2 == 27 (mod 5) and \n275 == 0 (mod 5).\n\nThere are some interesting properties of this modular arithmetic:\n\nIf a == b (mod m) and c == d (mod m), then also\n\n     a + c == b + d (mod m)\n     a - c == b - d (mod m)\n     a * c == b * d (mod m)\n\nDivision is a bit more difficult:\n\nIf the GCD of t and m is 1, and if ta == tb (mod m), then \na == b (mod m).\n\nNow on to prove Fermat's Little Theorem:\n\n     n^p == n (mod p)\n\nIf n is divisible by p, then it is clearly true.\n\nIf n is not divisible by p, then the GCD of n and p is 1.\n\nWe note that for such n there are the following possibilities:\n\n     n == 1 (mod p)\n     n == 2 (mod p)\n     n == p-1 (mod p)\n\nAll numbers == 1 (mod p) are said to be in the \"residue class of 1 \nmodulo p.\"\n\nSo the numbers 1, 2, ... , p-1 represent all but one (the == 0 residue \nclass) residue classes modulo p. These p-1 residue classes are exactly \nthe residue classes representing numbers with a GCD of 1 with p.\n\nNow if we multiply all these representatives of these p-1 residue \nclasses by n, we get n*1, n*2, ... , n*(p-1). No two of these numbers \ncan be in the same residue class modulo p, because if n*x == n*y (mod \np) then x == y (mod p) (see above). But then these numbers n*1, n*2, \n..., n*(p-1) again represent all p-1 residue classes. Multiplying, we \n\n     n*1 * n*2 * ... * n*(p-1) == 1 * 2 * ... * (p-1) (mod p)\n\nDivide by 1*2*...*(p-1), which has a GCD of 1 with p, to get:\n\n     n^(p-1) == 1 (mod p)\n\nand then multiply both sides by n and we have:\n\n     n^p == n (mod p)\n\nas desired.\n\nIf you need more help, just write back.\n\nBest regards,\n- Doctor Floor, The Math Forum\nAssociated Topics:\nCollege Number Theory\nHigh School Number Theory\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM"}
{"text": "Retrieved from https://www.physicsforums.com/threads/bad-mosfet-detection-circuit.332886/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nBad MOSFET detection circuit\n\n  1. Aug 27, 2009 #1\n    Hey Everyone,\n\n    The title of this thread may be a bit ambiguous but what I am wondering is if there is a way to determine if a MOSFET in an output stage has shorted. The scenario I want to catch is the case where the FET drain is exposed to too much voltage (from a collapsing spike or some other unpredictable transient) and the drain blows and shorts out. At the moment, my protection circuit is simply a small mechanical circuit breaker which cuts the supply (12V in my case) to stop the circuit from roasting, but I'm trying to determine if there is another way to detect that the MOSFET is blown (so the uC will know) other than testing for a lack of supply voltage on the output stage?\n\n    Jason O\n  2. jcsd\n  3. Aug 27, 2009 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Is the output stage push-pull, or open-drain?\n\n    In either case, can you sense the quiescent output voltage (no output drive), and determine if it is correct? If you have a shorted output FET, the expected output voltage should change...\n  4. Aug 28, 2009 #3\n    Hi berkeman,\n\n    In my setup, the FET is essentially being used as a low-side flyback driver (open drain). It is driving a flyback transformer primary with a 12V input but when the switch closes, the flyback voltage can rise as high as 400V. the FETs I'm using will handle this with no problem but I'm wondering what happens in the case where something goes wrong. When the FET shorts, that would simply blow the breaker on the circuit. But even without the input voltage to the output stage, is there any way to safely determine weather the fet is good or bad (to differentiate between a case where there is simple some kind of current fault vs. the fault being caused because the MOSFET failed).\n\n    Sorry in advance for the confusing explanation, I'm still trying to get it straight in my mind even now.\n\n    - Jason O\n  5. Aug 28, 2009 #4\n\n\n    User Avatar\n    Science Advisor\n\n    TV sets have a similar arrangement and when the line output transistor breaks down, it also destroys an expensive line output transformer in series with it.\n\n    Rather than develop a sensor for detecting a failure, it would be better to improve the circuit so that it is less likely to happen.\n\n    If the FET was not normally in saturation (ie with near zero volts on it) you could detect this, but that 400 volts would be a problem with logic circuitry.\n\n    If the FET failed by shorting to the Gate from the Drain, then the Gate would be at zero volts, too, so you could detect that. Mosfets normally have a forward bias on them.\n\n    If the circuit normally generated high voltage pulses at a constant frequency, you could detect that these were not there any more by using a 567 tone decoder and a small pickup probe near the circuitry.\n\n    The transformers normally generate smoke when they fail, so you could use a smoke detector.\n  6. Aug 29, 2009 #5\n    If a transistor begins to fail it will behave more non-linearly and cause a greater harmonic distortion. You could detect the rise of a 2nd or 3rd harmonic with some sort of filter and detector or if the micro-controller had an ADC on board, code an FFT program to monitor the spectrum.\n\n    But that's all too much work for a switcher. Good components and protection should ensure it will work fine.\n  7. Aug 30, 2009 #6\n    Yeah, that definitely makes sense. I'm going to rely primarily on the input circuit breaker to stop any major damage from happening to the board. The loss of the supply voltage to the fet would be the best way, in my situation, to determine if something went wrong with the output stage. Thank you everyone for the suggestions. I especially like the \"smoke detector\" one, that was great, lol. I have another question about temperature sensors related to the same situation but I'll make a new thread about that.\n\n    Jason O\n\nHave something to add?\n\nSimilar Discussions: Bad MOSFET detection circuit\n  1. MOSFET circuit problem (Replies: 5)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/113477/what-is-expected-number-of-turns-to-play-this-childrens-game/113483\nText:\nTake the 2-minute tour \u00d7\n\nI'm playing this game with children am I'm ready to stab my eyes with an ice pick. It seems like it never ends, but I know I expect it to end. What is my expected number of spins to remove all the fruit from the tree?\n\nGoal: To remove 14 cherries from tree by executing one of following seven directions at random per turn.\n\n 1. Remove 1 cherry.\n 2. Remove 2 cherries.\n 3. Remove 3 cherries.\n 4. Remove 4 cherries.\n 5. Return 1 cherry to tree.\n 6. Return 2 cherries to tree.\n 7. Return all your cherries to tree.\n\nOnce I realized I have a 1/7 chance each turn of playing this game in perpetuity, I started reaching for the kitchen drawer.\n\nshare|improve this question\nSuppose there are 2 cherries on the tree. Does the game end if you roll a 3 or a 4? (ie, if you're asked to remove more cherries than there are left.) \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:32\nYes, if there are two cherries, picking 2,3, or 4 cherries will end the game. \u2013\u00a0 zundarz Feb 26 '12 at 3:35\nAlso, if all 14 cherries are on the tree and you roll a 5, does the tree now have 15 cherries or does nothing happen? \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:36\nIn my solution below, I assume that nothing happens in this case. \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:46\nUm, if there are children threatening you with ice picks, then the statistical properties of some game probably shouldn't be on top of your priority list. \u2013\u00a0 Henning Makholm Feb 26 '12 at 3:48\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nI actually spent some time about a year ago doing some computations for a variant of this game, sold as Hi-Ho Cherry-O. It's identical to your game, except with 10 cherries instead of 14. (I learned about it from a colleague with a 4-year-old daughter.)\n\nThe computation is a nice example of some simple Markov chain techniques, which produce linear equations of the sort in Brett Frankel's answer. I considered the cases of 1 to 4 players, which are amenable to computer solution.\n\nAnother interesting feature is that since the players take turns, the first player has a slight advantage.\n\nHere are the results I got for 10 cherries. If you are really interested, I can try and reconstruct my code and run the 14 cherry case.\n\n1 player game:\n\nExpected length: 15.8019792994073 rounds\n\n2 player game:\n\nExpected number of rounds: 9.58554137805221\nP(player 1 wins) = 0.518720469382215\nP(player 2 wins) = 0.481279530617784\nExpected number of turns = 18.6523622867222\n\n3 player game:\n\nExpected number of rounds: 7.49668096168849\nP(player 1 wins) =  0.357756582790784\nP(player 2 wins) =  0.332728455615310\nP(player 3 wins) =  0.309514961593905\nExpected number of turns: 21.4418012638686\n\n4 player game:\n\nExpected number of rounds: 6.44149249272987\nP(player 1 wins) =  0.276928283784381\nP(player 2 wins) =  0.258099951775544\nP(player 3 wins) =  0.240610168544412\nP(player 4 wins) =  0.224361595895655\nExpected number of turns: 24.1783750474708\n\nEdit: I should also mention some previous work by Jeffrey Humpherys.\n\nshare|improve this answer\nI get $1179248/80915\\approx14.573910894148181$ for $10$ cherries, yet the same as DSM for $14$ cherries. Are you sure you used exactly the same rules (especially when there aren't enough cherries to remove or to return)? \u2013\u00a0 joriki Feb 26 '12 at 5:22\n@joriki: DSM's answer is now deleted, but I believe the rule I used is that when there aren't enough cherries, you add or remove as many as possible. E.g. if you have only one cherry in your bucket and spin a 6, you return that one cherry to your tree. Again, I unfortunately only saved pieces of my code, so I can't check it, but perhaps if I have some time in the near future I'll reconstruct it. \u2013\u00a0 Nate Eldredge Feb 26 '12 at 14:16\nNate E.: The game is Hi-Ho-Cherry-Oh. It seems like 14 cherries!! After I removed the ice-picks from my eyes, I recounted and there are just 10 cherries. \u2013\u00a0 zundarz Feb 26 '12 at 14:26\nI've resolved the discrepancy between our results; see my answer. \u2013\u00a0 joriki Feb 27 '12 at 12:35\n\nYou can solve via a series of 14 linear equations: Let $E_n$ be the expected number of turns remaining until the game is over when there are currently $n$ cherries on the tree. For example, $$E_1=\\frac{4}{7}1+\\frac{1}{7}(1+E_2)+\\frac{1}{7}(1+E_3)+\\frac{1}{7}(1+E_{14})$$\n\n\nBy the time you finish writing down all 14 equations and solving, the game may well be over. (Then again, I expect the answer will be quite large).\n\nshare|improve this answer\n\nI've found the reason for the discrepancy between Nate's answer and my results (which agree with DSM's). In the version of the game that Nate linked to, the dog and the bird both require you to return $2$ cherries to the tree, whereas in the present version 5. says one cherry and only 6. says two cherries. If I change my code to the linked version my result for the expected number of turns is in agreement with Nate's. For the present version, I get\n\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/12139/number-of-relations-that-are-both-symmetric-and-reflexive\nText:\nTake the 2-minute tour \u00d7\n\nConsider a non-empty set A containing n objects. How many relations on A are both symmetric and reflexive?\n\nThe answer to this is $2^p$ where $p=$ $n \\choose 2$. However, I dont understand why this is so. Can anyone explain this?\n\nshare|improve this question\nthis is not (number-theory); just because it numbers does not make it number theory. It's about counting, so it's combinatorics. \u2013\u00a0 Arturo Magidin Nov 27 '10 at 23:40\n\n5 Answers 5\n\nup vote 12 down vote accepted\n\nTo be reflexive, it must include all pairs $(a,a)$ with $a\\in A$. To be symmetric, whenever it includes a pair $(a,b)$, it must include the pair $(b,a)$. So it amounts to choosing which $2$-element subsets from $A$ will correspond to associated pairs. If you pick a subset $\\{a,b\\}$ with two elements, it corresponds to adding both $(a,b)$ and $(b,a)$ to your relation.\n\nHow many $2$-element subsets does $A$ have? Since $A$ has $n$ elements, it has exactly $\\binom{n}{2}$ subsets of size $2$.\n\nSo now you want to pick a collection of subsets of $2$-elements. There are $\\binom{n}{2}$ of them, and you can either pick or not pick each of them. So you have $2^{\\binom{n}{2}}$ ways of picking the pairs of distinct elements that will be related.\n\nshare|improve this answer\n\nBeing reflexive means that $(x,x)\\in R$ for all $x\\in A$. Being symmetric means that $(x,y)\\in R$ implies that $(y,x)\\in R$ as well.\n\nBegin by listing $A$ as $A=\\{a_1,\\dots,a_n\\}$. Then let $B$ be the set $$\\{(a_i,a_j)\\mid 1\\le i<j\\le n\\}.$$ Note that if $x\\ne y$ are elements of $A$, then either $(x,y)\\in B$ or $(y,x)\\in B$ but not both.\n\nLet $S$ be any subset of $B$. Let $$R_S=S\\cup\\{(y,x)\\mid (x,y)\\in S\\}\\cup\\{(x,x)\\mid x\\in A\\}.$$ Then $R_S$ is a symmetric and reflexive relation on $A$.\n\nNote that there are $2^{|B|}$ subsets of $B$, and that if $S\\ne S'$ are subsets of $B$, then $R_S\\ne R_{S'}$. Also, note that $|B|=\\binom{n}2$. (If the last equality is not clear, note that $$B=\\{(a_1,a_j)\\mid j>1\\}\\cup\\{(a_2,a_j)\\mid j>2\\}\\cup\\dots$$ so $|B|=(n-1)+(n-2)+\\dots+1$, and it is well-known that the last sum equals $n(n-1)/2=\\binom n2$.\n\nThis shows that the number of symmetric, reflexive relations on $A$ is at least $2^p$ with $p=\\binom n2$.\n\nTo see the equality, it is enough to check that any such relation $R$ is $R_S$ for some $S\\subseteq B$. But, given $R$, let $S=\\{(a_i,a_j)\\in R\\mid i<j\\}$. This is a subset of $B$, and it is easy to check that $R=R_S$.\n\nshare|improve this answer\n\nMaybe you can see it like this: a relation $R$ on $A$ is a subset of $A\\times A$, and it is symmetric if and only if $(x,y)\\in R \\implies (y,x)\\in R$, moreover, if the relation is reflexive, then $(x,x)\\in R$ for all $x\\in A$. Then you can determine uniquely such a relation by saying which subsets of two distinct elements of $A$ \"belong\" to $R$, in the sense that $\\{x,y\\}\\in R \\iff (x,y),(y,x)\\in R$. Now, you know that the number of subsets with two distinct elements of $A$ is $\\binom{n}{2}$, and the number of subset of a set with $p$ elements is $2^p$. I'm sorry if i was too obscure.\n\nshare|improve this answer\nI had not seen that Arturo Magidin had already answered, so that i gave almost an equal explanation. Sorry again (for my bad english too!). \u2013\u00a0 Daniele A Nov 27 '10 at 23:55\n\nYou can also think of it as a matrix of $nxn$, with the elements of the matrix being $(a_i,a_j)$ with $ a_i,a_j \\in A$. The elements of the main diagonal have to be included in R because R is reflexive. For the remaining $n^2-n$, picking a pair from the upper triangle say $(a_2,a_1)$ implies that you are also picking $(a_1,a_2)$. So in reality you only have $\\frac{n^2-n}{2}$ elements to pick from. This can be done in $2^{\\frac{n^2-n}{2}}$ ways.\n\nshare|improve this answer\n\nThere is only one way to make the relation reflexive -- all ordered pairs $(x,x), x\\in A$ must be in the relation. So the number of reflexive symmetric relations on $A$ is the same as the number of ways of adding symmetric pairs $(a,b),(b,a)$, where $a\\neq b$ into the relation.\n\nLet $S$ be a subset of $2^A$ consisting of subsets of 2 elements. Then $S$ gives rise to exactly one reflexive symmetric relation on $A$. For example, if $A=\\lbrace 1,2,3,4\\rbrace$, then an example of $S$ is $\\lbrace \\lbrace 1,2\\rbrace, \\lbrace 1,4\\rbrace, \\lbrace 3,2\\rbrace\\rbrace$. The relation induced by $S$ is $$\\lbrace (1,2), (2,1), (1,4), (4,1), (2,3), (3,2)\\rbrace$$ plus all $(x,x), x\\in A$. Conversely, every reflexive symmetric relation on $A$ arises in this way.\n\nSince there are $p={n\\choose 2}$ subsets of 2 elements, there are $2^p$ such $S$'s. The answer to your question is therefore $2^p$.\n\nshare|improve this answer\nI think this is not quite right. If the number of reflexive symmetric relations on $A$ were the same as the number of symmetric relations on $A$, then every symmetric relation would have to be reflexive. \u2013\u00a0 Rahul Nov 28 '10 at 2:00\n@Rahul. I have edited my post. \u2013\u00a0 TCL Nov 28 '10 at 3:42\nI just noticed that I had a $-1$ on my reputation. In checking it out, I found out that apparently I downvoted this two days ago. I don't remember this question/answer at all, and I certainly wouldn't have marked this (correct, well written) answer down intentionally. So, I apologize. If this is important to you, edit the answer (so I can revote), and then ping me. Sorry! \u2013\u00a0 Jason DeVito Apr 19 '14 at 19:51\n@DeVito.I have just edited it. \u2013\u00a0 TCL Apr 21 '14 at 14:54\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/95626/prove-that-lr-is-context-free-without-alphabet/95630\nText:\nI'm stuck with this problem:\n\nGiven $L$ a CFL on the alphabet $\\Sigma$. Prove that $L^r=\\{x^r|x\\in L\\}$, where for each $a\\in\\Sigma$ and $y\\in\\Sigma^*$, $$\\epsilon^r=\\epsilon,$$ $$(ay)^r=y^ra,$$ is context free or not.\n\nSince I don't have the alphabet I cannot think of a grammar that generates this language, so I decided to prove that it's not context free by applying the pumping lemma for CFL. So I started with the hypothesis that $L^r$ is context free, thus if $x\\in L^r$ that $x^r\\in L$.\n\nThen I tried to find different possible strings that once pumped didn't belong anymore to $L^r$, but I'm not able to find such string.\n\nIs this a bad aproach? Where am I wrong?\n\n\nInformally, by construction $L^r$ consists of the strings in $L$ reversed. Since $L$ is context-free, it has a Grammar in Chomsky normal form. All production rules in this grammar will fall in one of three classes:\n\n  1. $A \\rightarrow BC$\n  2. $A \\rightarrow a$\n  3. $S \\rightarrow \u03b5$\n\nThus by reversing the order of non-terminals in the RHS of all rules of category 1., a new grammar can be derived that produces $L^r$.\n\nThis new grammar is also in Chomsky normal form, thus $L^r$ is context-free.\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Oh! I was so wrong... Anyway, thank you very much now I understand. $\\endgroup$ \u2013\u00a0tokenizer Jul 26 '18 at 10:18\n  \u2022 $\\begingroup$ There is absolutely no need to use CNF here. Any context-free grammar would do. $\\endgroup$ \u2013\u00a0Yuval Filmus Jul 26 '18 at 18:24\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/2554/is-the-2nd-parity-bit-in-raid-6-a-simple-calculation/2568\nText:\nI'm trying to understand how the 2nd parity bit or byte is set in RAID 6. I'm reading a paper by H. Peter Anvin, and it goes into Galois field algebra, which is somewhat new to me. Anyway, a rep from HP was trying to explain RAID 6 to me and she thought it was merely two XOR operations, one for the 1st parity bit and one for the 2nd. This doesn't make sense to me, but since I'm still working through the paper I don't know if it reduces to something simple for RAID 6 as opposed to RAID n. It looks to me like the 2nd parity bit is quite a bit more complicated than the XOR based 1st parity bit. Is that true?\n\n\nThe general case is indeed a bit complicated.\n\nHowever, in the case of 4 disks you can simplify it a lot; you do not really need to know any fancy math. You only need to know how to store 4 bits redundantly, and then you already know everything; just repeat the same scheme for each group of 4 bits that you need to store.\n\nWe can represent the scheme as 4 x 4 tables. The first 2 bits of our data determine the row and the last 2 bits of our data determine the column.\n\nDisk 1: Just store the first 2 bits. That is:\n\n00 00 00 00\n01 01 01 01\n10 10 10 10\n11 11 11 11\n\nDisk 2: Just store the last 2 bits. That is:\n\n00 01 10 11\n00 01 10 11\n00 01 10 11\n00 01 10 11\n\nSo far so good. Given disk 1 + disk 2, we can recover our original data: disk 1 tells us the row (the first 2 bits of the original data) and disk 2 tells us the column (the last 2 bits of the original data).\n\nDisk 3: This is what we do on RAID5, just XOR the bits:\n\n00 01 10 11\n01 00 11 10\n10 11 00 01\n11 10 01 00\n\nAgain, everything is still fine. You can recover the original data using disk 1 + disk 3 or disk 2 + disk 3. A key observation is that the lookup table for disk 3 forms a Latin square: all elements of each row are distinct, and all elements of each column are distinct. For example, if you know the data on disk 1, you know the right row, and then you can use the data on disk 3 to recover the column. Conversely, if you know the data on disk 2, you know the right column, and then you can use the data on disk 3 to recover the row.\n\nDisk 4: Here we can use the following lookup table:\n\n00 01 10 11\n10 11 00 01\n11 10 01 00\n01 00 11 10\n\nDon't worry how it is constructed; we do not really care about that. The crucial properties are:\n\n  \u2022 The lookup tables of both disk 3 and disk 4 are Latin squares. Therefore if you know 1 + 3 or 1 + 4 or 2 + 3 or 2 + 4, you can recover both row and column (i.e., the original data).\n\n  \u2022 The lookup tables of disk 3 and disk 4 form orthogonal Latin squares, which makes it possible to recover the data if we only have disks 3 + 4.\n\nLet's elaborate on the second point. By concatenating the lookup tables of disk 3 and disk 4, we get this matrix:\n\n0000 0101 1010 1111\n0110 0011 1100 1001\n1011 1110 0001 0100\n1101 1000 0111 0010\n\nNow note that each 4-bit string occurs in this table exactly once. That is, if we know what is stored on disks 3 + 4, we know where we are on this table. We know both the row and the column, and hence we can recover the original data.\n\nIf you insist on seeing the connection to Galois fields, consider the field $F = GF(2^2)$. Label the elements of the field with $F = \\{0,1,x,x+1\\}$; these correspond to 2-bit strings ($0$ \u2248 00, $1$ \u2248 01, $x$ \u2248 10, $x+1$ \u2248 11). Now any 4-bit string can be encode as a pair $(a,b)$, where $a,b \\in F$.\n\nA pair $(a,b)$ is now stored as follows:\n\n  \u2022 Disk 1 stores $a$.\n  \u2022 Disk 2 stores $b$.\n  \u2022 Disk 3 stores $a+b$.\n  \u2022 Disk 4 stores $xa+b$.\n\nNow given, for example, just $p = a+b$ and $q = xa+b$, you can solve $a$ and $b$. Using the rule $2 \\equiv 0$, you can find\n\n  \u2022 $p + q = (xa+b) + (a+b) = (x+1)a + 2b \\equiv (x+1)a$,\n  \u2022 $p + xq = (xa+b) + x(a+b) = 2xa + (x+1)b \\equiv (x+1)b$.\n\nThen divide by $x+1$ to get $a$ and $b$, etc. But in the end, this approach gives you precisely the same lookup tables as what was presented above.\n\n| cite | improve this answer | |\n  \u2022 1\n    $\\begingroup$ And this is just a special case of the general method of Reed-Solomon codes as noted in the document cited by the OP, and the details as described in my answer: $P = D_0 \\oplus D_1$ and $Q = D_0 \\oplus D_1\\alpha$ is not different from $a+b$ and $xa+b$. It is just that with $n=2$ it is possible to use a smaller field. On the other hand, you need 2 redundant disks for 2 data disks whereas RAID-n allows for more than 2 data disks. $\\endgroup$ \u2013\u00a0Dilip Sarwate Jul 1 '12 at 13:44\n\nThe computation for $Q$ is definitely more difficult than the XOR computation needed for $P$ though it is in one sense the same kind of calculation: a polynomial evaluation.\n\nStripped of the detailed computational techniques described in the link, the idea is to regard the $n$ data bytes/drives $D_0$, $D_1, \\ldots, D_{n-1}$ as the coefficients of a polynomial $D(x) = D_0 + D_1x + \\cdots + D_{n-1}x^{n-1}$. Then,\n\n$\\qquad \\begin{align*} P &= D(1) = D_0 \\oplus D_1 \\oplus \\cdots \\oplus D_{n-1}\\\\ Q &= D(\\alpha) = D_0 \\oplus D_1\\cdot\\alpha \\oplus \\cdots \\oplus D_{n-1}\\cdot\\alpha^{n-1}\\\\ &= ((\\cdots(D_{n-1}\\cdot\\alpha \\oplus D_{n-2})\\cdot\\alpha \\oplus \\cdots \\oplus D_1\\cdot\\alpha) \\oplus D_0 \\end{align*}$\n\nwhere $\\alpha$ is an element (denoted by $\\{02\\} = (00000010)$ in the paper cited by the OP) of the Galois field GF$(2^8)$ (also denoted $\\mathbb F_{2^8}$) whose $256$ elements are the $256$ $8$-bit bytes, and the second line of the equation for $Q$ can be recognized as Horner's rule. Of course, the computation for $P = D(1)$ can also be thought of as using Horner's rule except that we are ignoring the multiplications by $1$ as NOPs and eliding all the parentheses in Horner's rule since they are unnecessary.\n\nAfter the drives have been written,\n\n  \u2022 If either or both of $P$ and $Q$ fail, there is no problem; $P$ and $Q$ can be recomputed and stored on replacement drives.\n\n  \u2022 If the only failure is one data drive, say the $i$-th drive, then its contents can be recomputed since $$D_i = D_0 \\oplus D_1 \\oplus \\cdots \\oplus D_{i-1} \\oplus D_{i+1} \\oplus \\cdots \\oplus D_{n-1} \\oplus P.$$\n\n  \u2022 If one data drive and $Q$ fails, the data drive can be recomputed as described above, and then $Q$ can be recomputed.\n\n  \u2022 What to do in the other cases: one data drive and $P$ failing or two data drives failing are more complicated to describe, but the methods can be understood more easily using the polynomial perspective described here. For example, if the $i$-th and $j$-th drives have failed, reconstruction is effectively the solution of the simultaneous equations: $$\\begin{align*} D_i \\oplus D_j &= P \\oplus \\sum_{k: k \\neq i, j} D_k\\\\ \\alpha^i\\cdot D_i \\oplus \\alpha^j \\cdot D_j &= Q \\oplus \\sum_{k: k \\neq i, j} D_k\\cdot\\alpha^k. \\end{align*}$$ where the right hand sides can be computed from the contents of the non-failed drives.\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ This looks like the same type of calculations as done in Reed-Solomon forward-error-correction. $\\endgroup$ \u2013\u00a0edA-qa mort-ora-y Jul 1 '12 at 13:13\n  \u2022 2\n    $\\begingroup$ Yes indeed, the method uses a shortened Reed-Solomon code (as mentioned in the link in the OP's question) but the data recovery does not invoke the full-blown RS decoding algorithm methodology that allows for multiple error correction/disk failures but a much simpler method predicated on there being at most two disk failures and we know which disks have failed. In other words, if there are undetected read errors on two disks, the method will not work (nor will the general RS decoding method): detected read errors (a.k.a. disk failures) are OK. $\\endgroup$ \u2013\u00a0Dilip Sarwate Jul 1 '12 at 13:27\n\nIt looks pretty damned complicated to me.\n\nThus, in the formula above, the calculation of P is just the XOR of each stripe. This is because addition in any characteristic two finite field reduces to the XOR operation. The computation of Q is the XOR of a shifted version of each stripe.\n\n(P being the first parity bit and Q being the second.)\n\nSo it sounds like the explanation you got is a valid high level description of the calculation, without getting into the mathematical theory and details that neither you or her (or me, or most anyone else) actually understand.\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Not sure how (or even if I should) put that formula from Wikipedia in my reply... :/ $\\endgroup$ \u2013\u00a0HopelessN00b Jun 30 '12 at 0:04\n  \u2022 $\\begingroup$ Now that the question has been migrated to Computer Science, you can use LaTeX formatting. $\\endgroup$ \u2013\u00a0Gilles 'SO- stop being evil' Jun 30 '12 at 1:04\n\nThe three disk raid-6 is trivial: Just store the same information on disk 1, disk 2 and disk 3. Any two disks may fail and you can still recover the data. So a three disk raid-6 is basically just a three disk raid-1.\n\nIn the four disk case, there are two data \"disks\" (let's call them $A$ and $B$) and two parity \"disks\" (let's call them $P$ and $Q$). Furthermore, we have to operate on two bits from each disk at a time, so the minimum data item (whose parity generation is shown here) is four bits: Two bits on disk $A$ and two bits on disk $B$. This will generate two bits of parity $P$ and two more bits of parity $Q$. If we have more bits, we just repeat this scheme as needed.\n\nThe first parity $P$ is calculated normally, using a standard XOR ($\u2295$) scheme:\n\n$P = A \u2295 B$\n\nFor the second parity $Q$, we have to mangle one of the data items before we do the XOR, so that it becomes different from $P$:\n\n$Q = A \u2295 B^*$\n\nThe mangled $B^*$ is calculated from $B$ as follows: The first bit of $B^*$ is the XOR of both bits from $B$, and the second bit of $B^*$ is a copy of the first bit of $B$:\n\n$B^* = (B^*_1, B^*_2) = (B_1 \u2295 B_2, B_1)$\n\nThe above formula leads to the following table for the calculation of $B^*$ from $B$:\n\n$00 \\rightarrow 00$\n$01 \\rightarrow 10$\n$10 \\rightarrow 11$\n$11 \\rightarrow 01$\n\nNote, that the value $00$ remains unchanged, when mangled, while the other values go through a cycle of three: $01 \\rightarrow 10 \\rightarrow 11 \\rightarrow 01$.\n\nUnmangling is rather straightforward: Because of the cyclic property, just repeat the mangling twice to do an unmangle. Or invert above formula for $B^*$, which leads to:\n\n$B = (B^*_2, B^*_1 \u2295 B^*_2)$\n\nSo, unmangling is somewhat symmetrical to mangling.\n\nNow comes the magic, that will later enable us recovery in the scenario, that the two data disks fail and only the parity disks survive: What happens, if $B$ and $B^*$ get XORed? Now, let's have a look:\n\n$B \u2295 B^* = (B_1, B_2) \u2295 (B_1 \u2295 B_2, B_1) = (B_1 \u2295 B_1 \u2295 B_2, B_1 \u2295 B_2) = (B_2, B_1 \u2295 B_2)$\n\nThe nice result: XORing $B$ and $B^*$ is identical to performing an unmangle step on $B$. Thus $B$ can be recovered from $B \u2295 B^*$ by applying a mangle to it: $B = (B \u2295 B^*)^*$. And as $(B \u2295 B^*)$ is the result of XORing the two parity values $P$ and $Q$, recovery from the parity disks alone becomes possible.\n\nNow, we have everything together: To store $A$ and $B$ on a RAID-6, we calculate first the mangled datum $B^*$, and then the standard parity $P$ from $A$ and $B$ and the mangled parity $Q$ from $A$ and $B^*$:\n\n$B^* = (B_1 \u2295 B_2, B_1)$\n$P = A \u2295 B$\n$Q = A \u2295 B^*$\n\nRecovery after failure of two disks is as follows:\n\n  \u2022 If $A$ and $B$ survive, just recompute $P$ and $Q$.\n  \u2022 If $A$ and $P$ survive, recover $B = P \u2295 A$, then recompute $Q$.\n  \u2022 If $B$ and $P$ survice, recover $A = P \u2295 B$, then recompute $Q$.\n  \u2022 If $A$ and $Q$ survive, recover $B^* = Q \u2295 A$, then recover $B$ from $B^*$ via an unmangle operation (or a double mangle), then recompute $P$.\n  \u2022 If $B$ and $Q$ survive, calculate the mangled $B^*$ from $B$, then recover $A = Q \u2295 B^*$, then recompute $P$.\n  \u2022 If $P$ and $Q$ survive, use the formula explained above $B = (P \u2295 Q)^*$, then recover $A = P \u2295 B$.\n\nIn the five disk case, there are three data disks $A$, $B$ and $C$ and again two parity disks $P$ and $Q$. The most notable difference is, that the mangle is performed twice on $C$, when calculating $Q$:\n\n$P = A \u2295 B \u2295 C$\n$Q = A \u2295 B^* \u2295 C^{**}$\n\nRecovery in the five disk case follows the same principles as for the four disk case. In those cases, that two data disks and either $P$ or $Q$ survives, one has to take out two values from the parity instead of just one, and follow with the correct unmangle function in case of $Q$. For example, $C$ is recovered from $A$, $B$ and $Q$ as follows: $C = (Q \u2295 A \u2295 B^*)^*$.\n\nThe most tricky case is, if disks $A$, $P$ and $Q$ survive. Then $A$ is first XORed out of $P$ and $Q$, and then $(P \u2295 A)$ is mangled before XORing with $(Q \u2295 A)$. That maps out $B$ and leaves plain $C$:\n\n$(P \u2295 A)^* \u2295 (Q \u2295 A) = (A \u2295 B \u2295 C \u2295 A)^* \u2295 (A \u2295 B^* \u2295 C^{**} \u2295 A) =$\n$= (B \u2295 C)^* \u2295 (B^* \u2295 C^{**}) = (B^* \u2295 C^*) \u2295 (B^* \u2295 C^{**}) =$\n$= B^* \u2295 C^* \u2295 B^* \u2295 C^{**} = B^* \u2295 B^* \u2295 C^* \u2295 C^{**} = (C \u2295 C^*)^* =$\n$= (C^{**})^* = C^{***} = C$\n\nFor six or more disks, the principle remains the same, but the mangle operation needs to be replaced with one that has a longer cycle. This also requires the use of more bits. With four bits, a possible mangle op is:\n\n$M^* = (M_1 \u2295 M_4, M_1, M_2, M_3)$\n\n$0000$ is again mapped on $0000$, while all other values go through a 15-stage cycle: $0001 \\rightarrow 1000 \\rightarrow 1100 \\rightarrow 1110 \\rightarrow 1111 \\rightarrow 0111 \\rightarrow 1011 \\rightarrow 0101 \\rightarrow 1010 \\rightarrow 1101 \\rightarrow 0110 \\rightarrow 0011 \\rightarrow 1001 \\rightarrow 0100 \\rightarrow 0010 \\rightarrow 0001$\n\nWith its 15-stage cycle, this mangle op can be used for up to 15 data disks and two parity disks. For the $P$ parity, all values are XORed together as is, and for $Q$, the first disks datum is not mangled, the second disks datum is mangled once, the third disks datum is mangled twice, and so on.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://matheducators.stackexchange.com/questions/7927/algebraic-solving-and-uniqueness-proofs/7929\nText:\nThe following issue came up in my Intro to Proofs course and I wasn't sure how to explain my distaste of the student proof.\n\nProve that the solution for $x$ in $ax+b=c$ is unique ($a \\neq 0$).\n\nStudent Proof: Solving gives \\begin{align*} ax+b &= c\\\\ ax &=c-b\\\\ x &= \\frac{c-b}{a}. \\end{align*} Hence the solution must be $x=\\frac{c-b}{a}.$\n\nThe Proof I Wanted: Suppose both $x$ and $y$ solve the equation, then \\begin{align*} ax+b &= ay+b\\\\ ax&=ay\\\\ x&=y. \\end{align*} Thus the solution is unique.\n\nIs the student solution acceptable?\n\nI feel like finding an algebraic solution is not a proof of uniqueness. My gut says that there should be a good example where algebraically solving implies a unique solution when really there isn't one. (But I can only think of simple cases where you forget a $\\pm$ on a square root.)\n\nAnother way of explaining my distaste for this is that when solving choices are made to arrive at $x$. Maybe other choices would've gotten you to a different solution. Whereas in the desired proof since we assumed two solutions from the start, it's okay to make algebraic choices to show the two solutions are the same. But maybe I'm being too pedantic.\n\nAm I justified in disliking the student solution?\n\n  \u2022 5\n    $\\begingroup$ I'd say the student's proof is valid in this case but not a good one for generalising. $\\endgroup$ \u2013\u00a0Jessica B Apr 20 '15 at 13:54\n  \u2022 15\n    $\\begingroup$ The student's proof is correct. $\\endgroup$ \u2013\u00a0NiloCK Apr 20 '15 at 13:54\n  \u2022 10\n    $\\begingroup$ Arguably, the student's solution is better since it doesn't just show uniqueness but also finds the value. $\\endgroup$ \u2013\u00a0Adam Apr 20 '15 at 15:15\n  \u2022 9\n    $\\begingroup$ Another sense in which the student's proof is arguably better is that the OP's desired proof doesn't even show existence of solutions. $\\endgroup$ \u2013\u00a0Dag Oskar Madsen Apr 20 '15 at 21:53\n  \u2022 4\n    $\\begingroup$ In the future it would be wise not to base any judgement of proofs on gut feelings (intuition, experience, preference, popularity, ...). If one cannot find any mistake in a proof, one is not justified in finding it distasteful! That said, as Dirk said both presentations do not make the logical structure clear, but the student's solution gives a stronger result than your expected solution as Dag said and hence I would prefer it. Furthermore, the question itself is totally flawed. What in the world are $a,b,x$? quid gives an excellent counter-example. $\\endgroup$ \u2013\u00a0user21820 Apr 21 '15 at 8:07\n\nBoth are valid ways to prove the uniqueness of solutions, i.e. that the set $\\,S\\,$ of solutions contains at most one element. Indeed, one easily proves that the following are equivalent for any set $\\,S.$\n\n$(1)\\ \\ \\ |S| \\le 1,\\ $ i.e. $S\\,$ contains at most one element.\n\n$(2)\\ \\ \\ s\\in S\\,\\Rightarrow\\, s = t,\\ $ for some fixed $\\,t$\n\n$(3)\\ \\ \\ s,t\\in S\\,\\Rightarrow\\, s = t$\n\nThe student's solution uses method $(2)$ whereas your solution uses method $(3)$.\n\nIn my experience, such doubts about the method used in $(2)$ are not unusual. One can find many such questions in any general-level math forum such as sci.math, e.g. see this thread about such a proof in Max Rosenlicht's Introduction to Analysis.\n\nRemark $\\ $ It would be interesting to better understand the source of this apparent bias against the method $(2).\\,$ It may be related to the fact that the general method(s) of proving uniqueness seem to be rarely explicitly taught. Rather, the method(s) are typically learned en passant while working on specific problems. As a result, some students never master such method(s) and often miss opportunities for employing these powerful tools. To help rectify this, I often emphasize such applications, e.g. over 30 answers on math.SE, e.g. this interesting simple example occurred only a few days ago: $\\,4ab\\!-\\!1\\mid 4a^2\\!-\\!1\\,\\Rightarrow\\, a=b\\,$ for integers $\\,a,b > 0.\\,$ As I explain there, it is just a special case of the uniqueness of (multiplicative) inverses (in $\\,\\Bbb Z/m = $ integers modulo $\\,m).$\n\n| improve this answer | |\n  \u2022 3\n    $\\begingroup$ I think you forgot to define $t$ in method (2). $\\endgroup$ \u2013\u00a0David Z Apr 21 '15 at 6:57\n  \u2022 $\\begingroup$ @DavidZ $ $ In $(2),$ $\\ t$ denotes any (fixed) element of the ambient universe (probably a field such as $\\,\\Bbb Q,\\Bbb R\\,$ or $\\,\\Bbb C\\,$ in the OP). $\\endgroup$ \u2013\u00a0Gone Apr 21 '15 at 14:37\n  \u2022 $\\begingroup$ OK, I see what you mean. It would make the answer clearer, I think, if you mentioned that - perhaps saying there exists some $t$ such that $s\\in S\\implies s=t$ (if I've thought through it correctly). $\\endgroup$ \u2013\u00a0David Z Apr 21 '15 at 14:40\n  \u2022 $\\begingroup$ @BillDubuque: You're right. I'm biased against (2). I feel like somewhere in grad school I was sternly steered away from (2). So my rational mind recognizes it's valid, but my gut hates it (similar to proofs by exhaustion that could've been done in two lines). $\\endgroup$ \u2013\u00a0Aeryk Apr 21 '15 at 16:00\n  \u2022 $\\begingroup$ @BillDubuque: Interesting side note: the text I'm using for the course is Solow's \"How to Read and Do Proofs\" and he only gives methods, strategies, and examples of (3). He seems to also disfavor (2). $\\endgroup$ \u2013\u00a0Aeryk Apr 21 '15 at 16:02\n\nBe careful here. You're teetering close to the edge of checking whether the student has guessed your solution to the problem rather than whether the student has solved the problem.\n\nThis is easy to do, especially in cases like this where a problem is constructed with the specific purpose of exercising a particular technique (eg, your solution).\n\nThis purposeful construction inflicts the problem setter with a bit of blindness for other potential solution paths - when we solve a problem, we stop looking for different angles on it. And being presented with an alternate solution path can also be a little blow to the ego - because of the implicit suggestion that the problem doesn't serve its purpose perfectly, eg, the desired technique was not required.\n\nMy suggestion would be to congratulate the student on their straightforward approach, and explain that you had tripped yourself up with the expectation of a different line of thought.\n\nMoving forward, there's nothing wrong with prescribing a technique for problems when you want a particular technique to be used. (Excepting that one can get into a bit of a taxonomical nightmare when trying to put names on individual techniques for things. May be better to treat the technique names as disposable: eg, Tuesday's Method can be a labelled technique from the class notes).\n\n| improve this answer | |\n\nI do not see any issue $\\iff$ it is clear what the sequence of equations means. (Sorry for the pun.)\n\nThe following is true (for $a \\neq 0$, in the real numbers, say)\n\n$$ax+b = c \\iff ax =c-b \\iff x = \\frac{c-b}{a}$$ Hence the solution $x$ must be $x=\\frac{c-b}{a}.$\n\nEach transformation is an equivalence. The problem is that sometimes some do not pay enough attention and write sequences of equations like this that in fact are not equivalences. (Or perhaps they pay attention but just mean to express something different.)\n\nFor example the following might be written but does not give uniqueness: \\begin{align*} x^2 +5 & = 9 \\\\ x^2 & = 4 \\\\ x & = 2 \\end{align*} The issue is that the last equation is not an equivalence; it is false that $x^2 = 4 \\iff x = 2$ (again in the reals, that is; in the positive reals it would be true).\n\nThe main issue I see, but this is the same for the students and your solution, is that it is not completely made clear (at least in what is written) what the sequence of equation means.\n\nFor example, would we work over the $\\mathbb{Z}/4\\mathbb{Z}$ your solution would not show uniqueness either as even for $a\\neq 0$ the equation $ax=ay$ is not equivalent to $x= y$.\n\nAdded: The discussion above uses equivalence ($\\iff$) that is \"if and only if\" throughout. Such transformations will preserve the set of solutions exactly. It can sometimes be more desirable to use implications only in one way. Then one also has a relation among the solutions, namely:\n\n$$f(x)= a \\implies g(x)=b$$ will yield that every solution to $f(x)=a$ is also a solution to $g(x)=b$. That is if the concern is only to show uniqueness it is even sufficient to have sequence of equations linked by $\\implies$ and a unique solution for the final one.\n\nConversely, if one wants existence of a solution one needs a sequence of equations linked by $\\Leftarrow$ and a solution for the last.\n\nThus (in the reals),\n\\begin{align*} x^2 +5 & = 9 \\\\ x^2 & = 4 \\\\ x & = 2 \\end{align*} can be taken to show the existence of a solution of the first equation as $$x^2 +5 = 9 \\Leftarrow x^2 = 4 \\Leftarrow x = 2 $$ is true, yet not uniqueness as $$x^2 +5 = 9 \\implies x^2 = 4 \\not \\Rightarrow x = 2 $$\n\nSummary: To me the key point is to make clear how the different equations are logically linked, and to know what this means for the respective solutions.\n\n| improve this answer | |\n  \u2022 4\n    $\\begingroup$ I like your comment about $Z/4Z$, which makes very clear that the instructor's answer is no better than the student's. $\\endgroup$ \u2013\u00a0Tom Church Apr 20 '15 at 20:04\n  \u2022 3\n    $\\begingroup$ Indeed, as a quick example, $2x + 2 = 0$ does not have a unique solution over $\\mathbb{Z}/4\\mathbb{Z}$: Both $x = 1$ and $x = 3$ are solutions. $\\endgroup$ \u2013\u00a0Benjamin Dickman Apr 20 '15 at 20:59\n\nI suspect your discomfort with the student's proof is carryover from high school algebra where the logical underpinnings of what you are actually doing isn't often made clear.\n\nThe student's work is essentially a rigorous proof of the theorem\n\nTheorem: If $a \\neq 0$ and $a x + b=c$, then $x = (c-b)/a$.\n\nand this sort of thing is the typical result of the work involved in solving a problem.\n\nUniqueness is an easy corollary:\n\nCorollary: If $a \\neq 0$ and $ax+b = c$ and $ay+b=c$, then $x=y$\n\nProof: $x = (c-b)/a$ and $y = (c-b)/a$, therefore $x=y$.\n\nYou should also note that any skepticism about the student's approach showing the solution for $x$ is unique should also apply to your approach of showing that $x=y$ is the unique solution for $x$. e.g. after all you made choices too; maybe if you made other choices you wouldn't have arrived at $x=y$?\n\nAll of the work demonstrated in your post can be thought of as simply applying transformations to a problem to derive simpler problems that are implied by it.\n\nThe student opted to simplify first, and produced a simpler problem for which it was trivial to prove uniqueness.\n\nYou opted to invoke a proof technique for showing uniqueness first, and then proceeded to simplify the ensuing system of equations.\n\nMaybe all of your concerns would be obviated if you did as I did above and explicitly tacked on the remaining, trivial argument needed to arrive at that the conclusion that the solution (if it exists) is unique.\n\n| improve this answer | |\n\nThere are two typical ways for uniqueness proofs: showing that all answers have the same form or that any two potential answers must be the same. What your student did was if $x$ is a solution to $ax +b = c$ ($a \\neq 0$), then $x= \\frac{c-b}{a}$ implying that if $y$ is another solution, then $y = \\frac{c-b}{a} = x$.\n\nBoth ways should be explained as valid forms of proving uniqueness. While supposing if $x$ and $y$ are solutions, then $ax +b = c = ay+b$, the leap to setting both equations equal might be a leap for some. For instance, I personally would show that all solutions have the same form to get uniqueness. You could add that, since this is a proof class, that linear functions are one-to-one or injective to get the desired result as well. This allows for quite a bit of generalization for linear systems of equations.\n\nIn the end, if the student uses a valid proof for something that is not what you were considering, congratulate them and, perhaps, point out the method you were intending.\n\n| improve this answer | |\n\nActually, I get a bit confused about this, each step he took was reversable. But I don't think that by itself is enough. The important thing seems to be that each step he took preserved the solution set. In which case he proved that the solution set is a singleton.\n\n| improve this answer | |\n  \u2022 1\n    $\\begingroup$ What do you mean by \"reversible\"? That there exists an inverse operation to recover the prior step? In the case of such a linear system, yes as these correspond with row operations. $\\endgroup$ \u2013\u00a0Chris C Apr 20 '15 at 19:06\n  \u2022 $\\begingroup$ I'm also not quite sure what you mean, but certainly if you have a sequence of propositions each separated (correctly) by $\\iff$ then you can follow the sequence from beginning to end or end to beginning. See quid's answer for one approach using iff in the given problem. $\\endgroup$ \u2013\u00a0Benjamin Dickman Apr 20 '15 at 21:02\n  \u2022 $\\begingroup$ I tried to expand my answer a bit in the hope to address your concern. $\\endgroup$ \u2013\u00a0quid Apr 20 '15 at 21:36\n  \u2022 1\n    $\\begingroup$ There is a sequence of operations performed on each equation to produce the next equation. The final equation being $x = \\frac{c - b}{a}$. There is also a sequence of operations by which you can start at the bottom and produce $ax + b = c$. It can be shown that each of these operations does not altar the solution set. $\\endgroup$ \u2013\u00a0Steven Gregory Apr 27 '15 at 16:49\n\nYour Answer"}
{"text": "Retrieved from http://www.riddlesandanswers.com/v/229407/once-upon-a-time-there-lived-a-king-who-wished-to-find-the-wisest-man-in-the-realm-to-be-his-assista/\nText:\nTrending Tags\n\nPopular Searches\n\nTerms \u00b7 Privacy \u00b7 Contact\nRiddles and Answers \u00a9 2020\n\nThe Red Hat\n\nOnce upon a time there lived a king who wished to find the wisest man in the realm to be his assistant. He summons the 3 known wisest men to his court and he administers the following test.\n\nHe sits them in a circle, facing each other and he says Im going to put either a red hat or a white hat on each of your heads. He proceeds to place a red hat on each of their heads. Obviously they can see each other but there are no mirrors in the room so they cant see whats on their heads. He says If you can see a red hat, raise your hand. They all raise their hands. Then he says If you can tell what color hat you have on, stand up.\n\nTime goes on, one guy looks at another guy, he looks at the other guy. The other guy looks at him. Finally one guy stands up. The question is how did he know he was wearing a red hat?\nHint: For a moment or two, nobody moved. Nobody knew for certain what color his hat was, and thats what told the wisest guy that all of the hats were red.\nStep 1:\nWiseguy #1 knows he can see two red hats.\n\nStep 2:\nWiseguy #1 thinks, \"Hey, if I were wearing a white hat, Wiseguy #2 would see one red hat and one white.\"\n\nStep 3:\nWiseguy #1 then thinks, \"If I were wearing a white hat, and Wiseguy #2 saw one red hat and one white (and if he were wearing a white hat himself), then Wiseguy #3 would have seen two white hats. So, Wiseguy #3 wouldnt have raised his hand to the first question.\n\nWiseguy #1 thinks, \"If that were true, Wiseguy #2 would be sure that he had a red hat. But since Wiseguy #2 was actually unsure about his hat color, it can only mean one thing, my hat is red.\"\nDid you answer this riddle correctly?\n\nAdd Your Riddle Here"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/45438/can-a-red-black-tree-be-constructed-of-only-black-nodes-using-rb-insert-only\nText:\nI am trying to construct a red black tree out of only black nodes. I know it is possible getting it after some deletions but I am trying to construct one only via insertion orders. Is it possible? I couldn't find a way to do so , so far even after trying to use the simulator.\n\n*** exept of a root node being added to an empty tree.\n\n  \u2022 1\n    $\\begingroup$ What have you tried? Have you tried working through some very small examples (say, exhaustively enumerating all possible insertion orders for trees of size 1, 2, and 3)? Have you tried to find a proof that it is impossible? Have you tried looking for suitable invariants that would imply it is impossible? $\\endgroup$ \u2013\u00a0D.W. Aug 20 '15 at 17:01\n  \u2022 $\\begingroup$ Hello and thank you for your comment. I have tried to do so. I couldn't find any invariants though. Can I assume it is impossible since we always insert a red node and thus an only black nodes tree is impossible to construst without a deletion after an insertion? The balancing menipulations taken on the nodes ( rotations and recoloring) don't allow that \"only black\" situtaion ( not reffering a single node tree). $\\endgroup$ \u2013\u00a0user118972 Aug 20 '15 at 17:09\n  \u2022 $\\begingroup$ I am quite convinced after trying a lot of diferent insertions that it isn't possible but I can't find the invariant. $\\endgroup$ \u2013\u00a0user118972 Aug 20 '15 at 17:19\n  \u2022 $\\begingroup$ Hints: 1) Can you quickly name a tree shape that allows you to color everything black? 2) Given any (balanced) target shape, what is a simple insertion order to obtain exactly that shape? $\\endgroup$ \u2013\u00a0Raphael Aug 20 '15 at 17:57\n  \u2022 $\\begingroup$ RBT have properties you must obey. Which of those could be violated? When? $\\endgroup$ \u2013\u00a0Evil Aug 20 '15 at 18:12\n\nProperties of Red Black Tree:\n\n0) Every node is black or red. Ok, no problem.\n\n1) Root is black. Ok, no problem.\n\n2) All leaves (empty nodes) are black. Ok, no problem.\n\n3) Every red node must have two black childs. Ok, no problem.\n\n4) Every path from any node to leaf has equal number of black nodes. It seems problematic.\n\nSo now comes problems: When you insert element it's color is red. (In fact this not comes from properties but observation that adding red node does not violate $4$th rule, so it is easier to implement).\n\nSo for start you add one element, let me say 10. It is black root. Ok.\n\nNow You add 13. It must be red, otherwise it violates rule 4.\n\nRed Black Tree elements 10; 13\n\nNow you add 19. Depending on implementation you can leave all black, or recolor.\n\nRed Black Tree elements 10; 13; 19\n\nNow adding 12 gives recoloring and comes red.\n\nRed Black Tree elements 10; 13; 19; 12\n\nAnd after several numbers\n\nRed Black Tree elements 10; 13; 19; 12; 41; 43; 26; 10; 82\n\nAnd now it starts nightmare, as you should propagate changes from one side of tree to another convincing somehow that you will change everything to black after insertion.\n\nBasically I asked you about rules to obey, as it comes to mind that with $4$th can be fulfilled only in perfectly balanced trees.\n\nSo to answer your questions:\n\nNo you cannot with common implementations of RBT, but extending balance operation to recolor when it is possible - it does not violate rules, so it is possible. Also with extension that whenever there is $n = 2^k - 1$ nodes, restructure it to perfectly balanced tree and recolor everything to black, it would be also possible.\n\nI did firstly answer \"no\" as purpose of balancing operation is to guarantee bound on worst case search / insert, and such extensions comes at price of time complexity. It does not violate rules, but is not implicitly implemented in standard RBT.\n\nGiven only root, you have it. Given three nodes inserted in order with implementation changing all to black (rather rare case and counterproductive), you can. But this is last one that is without deletions possible.\n\nWhen you are about to insert element and want all tree to be black that would mean there is violated rule $4$ (so not possible) or you have to rebalance tree, which would recolor nodes, so it is not pure black anymore.\n\nWith deletions on the other hand ;)\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Well, for $n=2^k$ you can. :) $\\endgroup$ \u2013\u00a0Raphael Aug 21 '15 at 16:34\n  \u2022 $\\begingroup$ Well, not by only insertions ;) And recoloring is possible, but it needs traversing whole tree. Otherwise, if we implement such feature that perfectly balanced tree we switch all colors to black, then yes. But not for $n = 2^k$ as it must have one red node, but $n = 2^k -1$ $\\endgroup$ \u2013\u00a0Evil Aug 21 '15 at 16:37\n  \u2022 $\\begingroup$ Right, wrong $n$. :D I understand the question to ask for the final tree being all black. Inserting the values in breadth-first order definitely gets the right shape; whether all nodes are black probably depends on the implementation (they all can be). $\\endgroup$ \u2013\u00a0Raphael Aug 21 '15 at 16:40\n  \u2022 $\\begingroup$ BFS is just level ordering, ok I am mixing two things one is impementation dependence - and one is recoloring. $n = 2^k - 1$ nodes and then it can be all black, but none existing implementation has it. $\\endgroup$ \u2013\u00a0Evil Aug 21 '15 at 16:57\n\nYour Answer"}
{"text": "Retrieved from https://iterativepath.wordpress.com/2010/11/17/let-us-do-expected-value-math-on-0-price/?like_comment=982&_wpnonce=2fa3e5f834\nText:\nLet Us Do Expected Value Math on $0\u00a0Price\n\nOnce again the power of $0 price is in the news. This time in The Wall Street Journal, featuring research published in Journal of Consumer Research. It is the previously famous Hershey\u2019s experiment from Dan Ariely\u2019s work,\n\n\u201cIn one of their experiments, participants were offered a choice between a cheaper lower quality chocolate (Hershey\u2019s) and a more expensive higher quality one (Ferrero Rocher). The price of the chocolates was manipulated between subjects in the following manner: two cents & 27 cents, one cent & 26 cents, and zero & 25 cents. Results showed that whereas there was roughly an even split between the two chocolates in the first two conditions, 90% chose Hershey\u2019s when it was free, indicating a discontinuity in the cost-benefit evaluations. In other words, consumers over-reacted to the free chocolate.\u201d\n\nAs it had been said before, \u201csomething magical happens at $0 price\u201d. \u00a0 So a strong case is made for giving your product away for free regardless of the experimental conditions and its applicability to your particular scenario. You are told that Free is Free marketing. But no one bothered to do the math for you on what is the expected value of free. Let us do just that here.\n\nLet us assume the costs are all sunk since you already bought the chocolates. From the text in bold above you can see that:\n\n  1. When the price was 1 cent for Hershey\u2019s and 26 cents for Rocher, \u00a0the choice was even, that is 50%. So the expected value of the customer is \u00a0(0.5 * 1 + 0.5 * 26) = \u00a013.5 cents\n  2. When the price was 0 cent for Hershey\u2019s and 25 cents for Rocher, the choice was 90% Hershey\u2019s and 10% Rocher. So the expected value is (0.9*0+0.1*25) = 2.5 cent\n\nSo which option would you choose? One that has an expected value per customer of 13.5 cents or 2.5 cents.\n\nIf you believe the free customers generate other revenue, then each one has to make up additional 12.2 cents from whatever means it is.\n\nJust by giving up the 1 cent\u00a0on the price you could lose much more than 1 cent. In this case, you lost \u00a011 cents and left with the hope that you will somehow make up for it.\n\nWhat does this say about the wildly famous Freemium model? The Freemium model is about having a free version to get users and hope that they will convert over to paid premium version. Simple calculation from Hershey experiment shows presenting a free version is much worse than presenting a low priced version alongside premium version.\n\nIsn\u2019t it time you do some hard math and reject fads and pseudo economics of social media gurus?\n\nSee also:\n\n1.\u00a0Opportunity cost of $0 price.\n\n2. Dan Ariely cautioning on the dangers of $0 price.\n\n16 thoughts on \u201cLet Us Do Expected Value Math on $0\u00a0Price\n\n  1. Yes, people measure what is convenient and available. That is is why you see metrics like HHI and RMS.\n    Apple has less than 5% of market share in mobile phone market but has more than 30% of profit.\n\n\n  2. Christian\n    You are correct. I am not selling my articles but using them as part of my Marcom tactic, like BCG Perspectives.\n\n    If the option to give away free does generate incremental profit over not having free option, by all means one should do it but not before doing the math.\n\n\n  3. Another one of my favourite quotes is \u201cthere is no bank in the world that will accept a deposit of market share\u201d \u2026which is what free will give you.\n\n    I have another comment \u2013 Behavioural Economics. Great stuff. Been around for 30 years now. But those of us involved in pricing have been doing behavioural economics since Joseph (with his coat of many colours) was sold into slavery by his brothers!\n\n    But these chocolate experiments (etc) are always done with undergrad and grad students. When is Dan Ariely at al going to get out and do some experiments on other (real) people. Who here is going to base their pricing strategy on the behavior of some Duke University students?\n\n\n  4. Great point. But I would say you also have to consider how similar the product offer is. In this case the product is a chocolate bar \u2013 and then I 100% agree with you calculation.\n\n    But one could also argue that you yourself are using a freemium model; free blogposts on effective pricing, and then pricing consulting as a premium.\n    For me the breaking point is how similar the \u201cfree\u201d and \u201cpremium\u201d product offer are..\n\n\n  5. Free is intoxicating. The idea of releasing a free version of something can be hard to fight against because the upside is that user growth can be truly phenomenal.\n\n    I\u2019ll mention to someone how many customers we have and 20-30% of the time the response will be \u201cYeah, but how many of those are paying customers.\u201d It\u2019s a funny interaction that\u2019s reinforced by glorifying users #\u2019s instead of glorifying customer and revenue growth.\n\n\n  6. Joseph\n    Thanks for the comment.\n    Pricing is not all art. The known unknowns of pricing is science and only the unknown unknowns is art. You will see that from my many articles on Effective Pricing.\n\n\n  7. Jon\n    Thanks for participating.\n    You are correct, it s not a pricing strategy and yes if they are not paying they are freeloaders and not customers.\n    Free is not a marketing strategy but a clueless tactic.\n\n\n  8. Lets not forget that free is not a pricing strategy! Its a marketing strategy. Its an advertising strategy, its a \u2018free-rider\u2019 acquisition strategy (can\u2019t call them customers if they\u2019re not paying\u2026can we?)\n\n\n  9. Thanks a lot for this write up. It\u2019s definitely interesting how 1 cent can change behavior. Pricing is such an art. Finding the perfect price sweet spot is a journey in itself.\n\n\nComments are closed."}
{"text": "Retrieved from https://mathoverflow.net/questions/137077/spreading-out-integers-via-multiplication\nText:\nLet $a_1,...,a_n\\in [0,m]$ be a set of $n$ positive integers, where $n<<m$, $m=poly(n)$. One can assume $m$ is prime. Is there an efficient, possibly randomized, way to find an integer $N=poly(n)$, such that $(a_i \\cdot N) (mod \\ m)$ is approximately uniform on $[0,m]$. The value of $N$ may also depend on the approximation parameter.\n\n  \u2022 $\\begingroup$ Should there be some additional hypothesis to prevent, for example, the situation where all the $a_i$ are equal? $\\endgroup$ \u2013\u00a0Andreas Blass Jul 18 '13 at 14:52\n  \u2022 $\\begingroup$ Yes, let's assume they are all different. $\\endgroup$ \u2013\u00a0Lior Eldar Jul 18 '13 at 15:04\n  \u2022 $\\begingroup$ \"All different\" won't work because there are $n$ of the integers $a_i$'s, all in $[0,m]$ with $m < n$ $\\endgroup$ \u2013\u00a0Andreas Blass Jul 18 '13 at 15:08\n  \u2022 $\\begingroup$ Of corse! - fixed the mistake above. $\\endgroup$ \u2013\u00a0Lior Eldar Jul 18 '13 at 15:49\n\nChoosing $N$ at random and checking should work. Put $e(t)=e^{2\\pi i t/m}$. Then we have \\begin{eqnarray*} \\sum_{N=1}^m\\sum_{k=1}^K\\left|\\sum_{i=1}^ne(k N a_i)\\right|^2 & = & \\sum_{N=1}^m\\sum_{k=1}^K\\sum_1\\leq i,j\\leq n e(kN(a_i-a_j))\\\\ & = & m\\sum_{k\\leq K} \\#\\{(i,j)|a_i\\equiv a_j\\pmod{\\frac{m}{(m, k)}}\\}. \\end{eqnarray*} Since the $a_i$ are all different and in $[0, m]$, for fixed $a_i$ the number of $a_j$ satisfying the last congruence is $(m,k)$ at most, and the last sum is bounded above by $mn\\sum_{k\\leq K}(k,m)\\leq mnK^2$.\n\nDenote by $D_N$ the discrepancy of $a_iN\\bmod m$. Then we have $$ D_N\\ll \\frac{n}{K}+\\sum_{k\\leq K}\\frac{1}{k}\\left|\\sum_{i=1}^n e(kNa_i)\\right|, $$ thus $$ \\frac{1}{m}\\sum_{N=1}^m D_N \\ll \\frac{n}{K} + \\sqrt{nK}\\log K. $$ Hence for most $N$ we have $D_N\\ll n^{2/3}\\log n$, which is reasonable good equidistribution.\n\nChecking whether for a random $N$ we have that $D_N<n$ is small requires between $n^{1+\\epsilon}$ and $n^{3/2}$ steps, depending on how small $D_N$ has to be.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3593751/geometric-intuition-of-systems-of-parameters\nText:\nI'm currently reading Eisenbud's Commutative Algebra with a View Toward Algebraic Geometry, and he defines a system of parameters in Section 10.1.\n\nHe says that, geometrically, if $x_1,\\ldots,x_d$ form a system of parameters for the local ring of a point $p$ on an algebraic variety, then the values of the functions $x_i$ determine points near $p$ up to a \"finite ambiguity\".\n\nThe example given is that $y$ and $y-x^2$ form a system of parameters for $k[x,y]_{(x,y)}$, and he points out that only finitely many points lie in the intersections of $y-x^2=\\delta$ and $y=\\varepsilon$ for small $\\delta$ and $\\varepsilon$.\n\nIs the \"finite ambiguity\" in this sense that each point near $(0,0)$ is determined by its values on these functions up to the sign of the $x$-coordinate? For example the point $(1,0)$ isn't quite defined uniquely by these values, but there are only finitely many other points which share the same values, namely just $(-1,0)$.\n\nIf that is the case, then I'm wondering if this characterisation is necessary and sufficient, but don't really know how to begin proving it. I've taken the notion of points \"near\" each other to mean they lie in some Zariski open neighbourhood.\n\nLet $V$ be an affine variety, and let $R$ be the local ring of a point $p$ on $V$. Say that $\\dim R=d$, and let $x_1,\\ldots,x_d$ be functions on our variety. Suppose that there exists some Zariski open neighbourhood $U\\subseteq V$ with $p\\in U$ such that, for every point $q\\in U$, we have that the set $$\\{r\\in U:x_i(r)=x_i(q)\\text{ for }1\\leq i\\leq d\\}$$ is finite. Then is this criteria necessary and sufficient for $x_1,\\ldots,x_d$ to be a system of parameters for $R$?\n\n\nIt seems like there are trivial counterexamples to my criteria as written. For example, if we localise at the point $(1,1)$ instead of $(0,0)$ as in his example, then clearly no power of $(x-1,y-1)$ lies in $(y,y-x^2)$. Then $y,y-x^2$ cannot be a system of parameters for this new ring, despite satisfying my conditions.\n\nHowever if we specify additionally that $p$ lies in the subvariety $V(x_1,\\ldots,x_d)$, then this rules out such counterexamples. This is also consistent with his example.\n\n\nI've added a potential answer based on another reading of his example. If anybody has any thoughts, or thinks that the argument is faulty, then please let me know.\n\n\nI now think that what he means when he says that the intersection is finite near $p$ is that on some Zariski open neighbourhood we have that $V(\\mathfrak{q})$ is finite, where $\\mathfrak{q}=(x_1,\\ldots,x_d)$. If this is the case, then I believe the following gives an answer:\n\nSince any affine open set is a union of open sets of the form $D(f)$, we may assume that $U$ is of this form since $p$ must belong to one of them. Furthermore, the intersection of an affine variety with $D(f)$ is also an affine variety, and so we may assume that our property holds for every point on our variety $V$.\n\nSince $x_i(p)=0$ for all $i$, there can be only finitely many other points in $V(\\mathfrak{q})$, and so $V(\\mathfrak{q})$ is a finite subvariety of $V$.\n\nHe says in Section 10.1 that $x_1,\\ldots,x_d$ being a system of parameters is equivalent to $R/\\mathfrak{q}$ being of finite length. Since $V(\\mathfrak{q})$ is finite, it has only finitely many subvarieties, and so $R/\\mathfrak{q}$ must be of finite length. Then the property is sufficient.\n\nConversely, if there doesn't exist a neighbourhood containing $p$ where $V(\\mathfrak{q})$ is finite, then we can always construct a chain of subvarieties of $V(\\mathfrak{q})$ of arbitrary length, and so $R/\\mathfrak{q}$ is not of finite length. Then the property is necessary.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/261812/vectors-that-are-almost-orthogonal-on-average-lower-bounds-on-dimension/261821\nText:\nLet $v_1,\\dotsc,v_k \\in \\mathbb{R}^d$ be unit-length vectors such that $$\\sum_{1\\leq i,j\\leq k} |\\langle v_i,v_j\\rangle|^2 \\leq \\epsilon k^2.$$ What sort of lower bound can we give on $d$ in terms of $k$ and $\\epsilon$?\n\nMust it be the case that $d\\gg \\min(\\log k,\\epsilon^{-1})$, say, or anything of the sort? Is that tight?\n\n  \u2022 $\\begingroup$ I guess a more flexible reformulation is to let $v_1,\\ldots,v_k$ be unit-length vectors in some vector space of large (infinite?) dimension, and ask for a lower bound on the dimension of their span given the almost-orthogonal condition. $\\endgroup$ \u2013\u00a0Peter Humphries Feb 9 '17 at 22:05\n  \u2022 1\n    $\\begingroup$ Isn't this equivalent? $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 22:12\n  \u2022 $\\begingroup$ Yes of course.. $\\endgroup$ \u2013\u00a0Peter Humphries Feb 9 '17 at 22:13\n\nThe Johnson Lindenstrauss Lemma states that there are $k$ vectors achieving $\\epsilon$ provided $d\\geq C \\epsilon^{-2} \\log k.$\n\nIf you actually want to bound the maximum absolute value of the inner product for distinct vectors, instead of the average as you stated which is of course stronger, then tighter bounds apply.\n\nRelevant results for this case are due to Welch, Kabatianski, Levenshtein, Sidelnikov. Welch's applies to arbitrary vectors, real or complex. The others apply to vectors constructed from complex roots of unity of some finite order. Welch's bound states\n\nLet $e\\geq 1$ be an integer and let $a_1,\\ldots,a_k$ be distinct vectors in $\\mathbb{C}^d.$ Then the following inequalities hold $$ \\sum_{i=1}^k \\sum_{j=1}^k \\left| \\langle a_i, a_j \\rangle \\right|^{2e} \\geq \\frac{\\left(\\sum_{i=1}^k \\lVert a_i \\rVert^{2e}\\right)^2}{\\binom{d+e-1}{e}}, $$ If the set of vectors you are interested in is of size roughly $d^u,$ the tightest lower bound is obtained by choosing $e=\\lfloor u\\rfloor.$\n\n\nSince you required $\\langle a_i,a_i\\rangle=1,1\\leq i\\leq k,$ if I subtract the diagonal inner products, I obtain $$ \\sum_{1\\leq i\\neq j\\leq k} \\left| \\langle a_i, a_j \\rangle \\right|^{2} \\geq \\frac{k^2-kd}{d}, $$ recovering the dependence on $k.$\n\nEdit 2:\n\nThe Johnson Lindenstrauss Lemma is tight up to a constant factor. The Welch bound is tight for some cases, when so-called Welch Bound with Equality sets of vectors exist, which correspond to all unequal innner products being the same in absolute value.\n\n\nV.M. Sidelnikov, On mutual correlation of sequences, Soviet Math Dokl. 12:197-201, 1971.\n\nV.M. Sidelnikov, Cross correlation of sequences, Problemy Kybernitiki, 24:15-42, 1971 (in Russian)\n\nWelch, L.R. Lower Bounds on the Maximum Cross Correlation of Signals. IEEE Transactions on Information Theory. 20 (3): 397\u2013399, 1974.\n\nKabatianskii, G. A.; Levenshtein, V. I. Bounds for packings on the sphere and in space. (Russian) Problemy Pereda\u010di Informacii 14 (1978), no. 1, 3\u201325. (A version of this might be available in English translation, in Problems of Information Transmission)\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Wait. Doesn't the inequality you cite as Welch's imply that $d\\geq \\epsilon^{-1}$, with no dependence on $k$? This seems a little too strong. $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 23:13\n  \u2022 $\\begingroup$ @HAHelfgott, please see edit. $\\endgroup$ \u2013\u00a0kodlu Feb 9 '17 at 23:31\n  \u2022 $\\begingroup$ Thanks. That answers the question, then. But how far is it from being tight? Is the Johnson Lindenstrauss Lemma tight? $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 23:52\n  \u2022 1\n    $\\begingroup$ As I pointed out earlier in a now deleted comment, we can (trivially) achieve the bound for a given $\\epsilon$ without any real size restrictions on $k$ if $d\\ge\\epsilon^{-1}$ by just repeating an ONB of $\\mathbb R^d$. (I guess it would be more honest to say that if $d$ is very close to $\\epsilon^{-1}$, then $k$ should be a multiple of $d$ to be safe.) $\\endgroup$ \u2013\u00a0Christian Remling Feb 10 '17 at 1:51\n  \u2022 $\\begingroup$ May you give references to \"Welch, Kabatianski, Levenshtein, Sidelnikov\", please. $\\endgroup$ \u2013\u00a0Sergei Feb 11 '17 at 5:37\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/295300/recurrence-finding-asymptotic-bounds-for-tn-tn-2-n2\nText:\nTake the 2-minute tour \u00d7\n\nI've been working on a problem set for a bit now and I seem to have gotten the master method down for recurrence examples. However, I find myself having difficulties with other methods (recurrence trees, substitution). here is the question I am stuck on: $$T(n) = T(n-2) + n^2$$ Is there a pattern as follows? $$n^2 + T(n-2) + T(n-4) +...$$ where it goes until there is no more n left. so around n/2 times and would that mean that $$n^2 + (n-2)^2 + (n-i) ^2$$ so the asymptotic bound would be $\\theta(n^2)$?\n\nI am honestly taking a shot in the dark here, so I was hoping someone could help guide me in how to approach these questions.\n\nThank you,\n\n\nshare|improve this question\nperhaps an indirect answer would even do, something to show how to solve questions of form t(n-i) + f(n) \u2013\u00a0 Tyler Feb 5 '13 at 9:31\n\n2 Answers 2\n\n$$T(n) = T(n-2) + n^2 = T(n-4) + (n-2)^2 + n^2 = T(n-2k) + \\sum\\limits_{i = 0}^{k - 1}(n - 2i)^2$$\n\nThis goes down till $n - 2k \\ge 0$. Assuming even $n$ (for asymptotic complexity, it does not really matter, and you can do similar calculations for odd $n$ also, with the same asymptotic results), we have $k = \\frac{n}{2}$ at the end.\n\n$$T(n) = T(0) + \\sum\\limits_{i = 0}^{\\frac{n}{2} - 1}(n - 2i)^2 = \\sum\\limits_{i = 0}^{\\frac{n}{2} - 1}(n^2 - 4ni + 4i^2) + C$$ $$T(n) = n^2\\cdot\\left(\\frac{n}{2}-1\\right) - 4n\\cdot\\frac{1}{2}\\cdot\\frac{n}{2}\\cdot\\left(\\frac{n}{2} - 1\\right) + 4\\cdot\\frac{1}{6}\\cdot\\left(\\frac{n}{2} - 1\\right)\\cdot\\frac{n}{2}\\cdot n + C$$ $$\\therefore \\ T(n) = \\Theta(n^3)$$\n\nshare|improve this answer\n\nNote that if $n=2k$ is even, then $$ T(n)+T(n-1) = n^2+(n-1)^2+ \\cdots+4^2+3^2 + T(2)+T(1) =\\frac{n(n+1)(2n+1)}{6} + C. $$ Here $C=T(2)+T(1) -2^2-1^2$ and we used the formula $\\sum_{i=0}^n i^2 = \\frac{n(n+1)(2n+1)}{6}$. We also note that $T(n) \\sim T(n-1)$, so we may conclude that $$ T(n) \\sim n^3/12. $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://magic.aladdin.cs.cmu.edu/category/mathematics/combinatorics/\nText:\nCategory Archives: Combinatorics\n\nAn Annoying Combinatorial Problem\n\nHere is an \u201cinnocent\u201d combinatorial problem, with the best known bounds being very simple (but nobody managed to improve them since 1978). Disclaimer: the problem is very catchy (I struggled with it for quite a while), so do not read any further if, for example, you are writing a PhD thesis :-)\n\nMaker and Breaker alternatively select 1 and q edges of K_n (the complete graph on n vertices) until all edges have been claimed. Maker wins if his graph has a triangle. What is the smallest q=q(n) such that Breaker has a winning strategy?\n\nThe best known strategy for Maker is to claim edges incident to some vertex x (and never miss a one-step win). If Breaker managed to block x completely, say after m rounds, then Breaker made n-1-m + {m\\choose 2}\\le m q(n) moves. This implies that q(n) is approximately at least \\sqrt{2n}.\n\nOn the other hand, Breaker can win if q> 2\\sqrt{n}: for each edge xy claimed by Maker, Breaker selects \\sqrt{n} edges at x and \\sqrt{n} edges at y. Thus Maker\u2019s graph has maximum degree at most (n-1)/\\sqrt{n}+1 and Breaker can always block all immediate threats.\n\nReference: V.Chvatal and P.Erdos, Biased positional games, Ann. Discrete Math. 2 (1978), 221-229.\n\nI would bet on the \\sqrt{2n} bound :-)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/229370/solve-2a-5b-20/229379\nText:\nTake the 2-minute tour \u00d7\n\nIs this equation solvable? It seems like you should be able to get a right number! If this is solvable can you tell me step by step on how you solved it. $$\\begin{align} {2a + 5b} & = {20} \\end{align}$$\n\nMy thinking process: $$\\begin{align} {2a + 5b} & = {20} & {2a + 5b} & = {20} \\\\ {0a + 5b} & = {20} & {a + 0b} & = {20} \\\\ {0a + b} & = {4} & {a + 0b} & = {10} \\\\ {0a + b} & = {4/2} & {a + 0b} & = {10/2} \\\\ {0a + b} & = {2} & {a + 0b} & = {5} \\\\ \\end{align}$$\n\nThe problem comes out to equal: $$\\begin{align} {2(5) + 5(2)} & = {20} \\\\ {10 + 10} & = {20} \\\\ {20} & = {20} \\end{align}$$\n\nsince the there are two different variables could it not be solved with the right answer , but only \"a answer?\" What do you guys think?\n\nshare|improve this question\nAre $a$ and $b$ supposed to be integers or real numbers? I don't really know a lot about number theory, but I know that if they're real numbers then there are infinite solutions. \u2013\u00a0 Javier Badia Nov 5 '12 at 2:05\nThere are infinite solutions either way (for this one anyways). See here. \u2013\u00a0 EuYu Nov 5 '12 at 2:07\nAnyway, I don't understand the thinking process. How do you get from $2a+5b =20$ to $0a+5b=20$? That's certainly not a valid step. \u2013\u00a0 Javier Badia Nov 5 '12 at 2:09\nI have no vaild reason why I put 2a to 0a. My thinking process was that if i had just magicly put it to 0 that i could get \"a answer.\" but that I look at it makes me feel dumb! \u2013\u00a0 Hobbs Nov 5 '12 at 13:57\n\n5 Answers 5\n\nup vote 2 down vote accepted\n\nYou have what is known as a linear diophantine equation. An equation of the form $$ax + by = c$$ is solvable in $x$ and $y$ if and only if $\\gcd(a,\\ b)\\mid c$. In your particular case the equation is solvable.\n\nYou've generated one solution already, the pair $(x,\\ y)=(5,\\ 2)$. All the other solutions are then given by $$(x,\\ y)=\\left(5 + 5k,\\ 2-2k\\right)$$ for $k\\in \\mathbb{Z}$.\n\nshare|improve this answer\n\nAlso, this equation has solutions in the integers in the greatest common divisor of 2 and 5 is 1, which divides 20.\n\nTo get an explicit solution, use the Euclidean algorithm. (BTW these are called Diophantine equations if you want to do further reading on them)\n\nshare|improve this answer\n\nNote that $2a$ must have as its unit digit $0, 2, 4, 6,$ or $8$ (because it's even!).\n\nSimilarly, note that $5b$ must have as its unit digit $0$ or $5$.\n\nWith a bit of thinking, you can see that for $2a + 5b$ to be $20$, we need to ensure that $2a$ has a unit digit of $0$ (hence $a$ is a multiple of $5$).\n\nSo let $a$ be a multiple of $5$. That is, let $a = 5k$, for some integer $k$.\n\nThen $2a + 5b = 20$ becomes $10k + 5b = 20$, so that $5b = 20 - 10k$.\n\nDividing both sides of our last equation by $5$, we have $b = 4 - 2k$.\n\nThis gives you all the possible answers for $(a, b)$, namely, $(5k, 4-2k)$.\n\nFor example, when $k = 1$ you get $(5 \\cdot 1, 4 - 2 \\cdot 1) = (5, 2)$, which is the answer you came to.\n\nshare|improve this answer\n\nGenerally one can use the Extended Euclidean algorithm, but that's overkill here. First note that since $\\rm\\,2a+5b = 20\\:$ we see $\\rm\\,b\\,$ is even, say $\\rm\\:b = 2n,\\:$ hence dividing by $\\,2\\,$ yields $\\rm\\:a = 10-5n.$\n\nRemark $\\ $ The solution $\\rm\\:(a,b) = (10-5n,2n) = (10,0) + (-5,2)\\,n\\:$ is the (obvious) particular solution $(10,0)\\,$ summed with the general solution $\\rm\\,(-5,2)\\,n\\,$ of the associated homogeneous equation $\\rm\\,2a+5b = 0,\\:$ i.e. the general form of a solution of a nonhomogeneous linear equation.\n\nshare|improve this answer\n\nThere are infinite solutions to this problem. Why? Fix a value of a. say that you wanted a to be 1. Then you get the equation 2+5b=20. 5b=18 so b=17/5. lets do it more generally. 2a+5b=20 so then 5b=20-2a and b=4-2a/5. If b=4-2a/5. Simply plug it into the original equation to get 2a+5(2-a/5)=20 which then gets to 20=20. so then for any a: (a,4-2a/5) will be an answer, you need both a and b to be integers. just take an a that is a multiple of 5 and you will have two integer solutions.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/30614/path-traced-out-by-a-point\nText:\nTake the 2-minute tour \u00d7\n\nWhile studying uniform circular motion at school, one of my friends asked a question:\n\n\"How do I prove that the path traced out by a particle such that an applied force of constant magnitude acts on it perpendicular to its velocity is a circle?\" Our physics teacher said it was not exactly a very simple thing to prove.\n\nI really wish to know how one can prove it.Thank you!\n\nshare|improve this question\nHow easy this can prove depends on your level of mathematics. Do you understand analytic geometry or even calculus? \u2013\u00a0 C.R. Jun 22 '12 at 13:35\nYou'll come away with so much more if spend the time to think more deeply about the problem and earn the knowledge of how to prove it. \u2013\u00a0 Alfred Centauri Jun 22 '12 at 13:40\nIt is an extremely simple thing to prove! You should not listen to your teacher. \u2013\u00a0 Ron Maimon Jun 23 '12 at 8:37\nThank you.I did prove it eventually,I was doing something extremely stupid. :) I am least bothered about how tough something is as long as I have the background to attack it. \u2013\u00a0 user10060 Jun 23 '12 at 8:49\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nOne can prove it in a more-or-less elementary way by solving a pair of simultaneous differential equations. In two dimensions, a vector that is perpendicular to a velocity $$\\left(\\begin{matrix}u(t)\\cr v(t)\\end{matrix}\\right)\\quad\\mathrm{is}\\quad\\left(\\begin{matrix}-v(t)\\cr u(t)\\end{matrix}\\right).$$ The acceleration, the time derivative of the velocity, is proportional to this vector, so we have the two differential equations $$\\left(\\begin{matrix}\\dot u(t)\\cr \\dot v(t)\\end{matrix}\\right)=\\lambda\\left(\\begin{matrix}-v(t)\\cr u(t)\\end{matrix}\\right).$$ If $\\lambda$ is negative, the circle goes \"the opposite way\". If $\\lambda$ is zero, the circle is a straight line. If you know differentiation and how to solve differential equations, you should be able to solve this pair of equations, and then integrate it to obtain the way in which the position changes over time. If you don't, then it may be better to be patient and wait until you come across it in the course of your studies. Learning calculus on your own to the level needed to solve this differential equation is possible, however.\n\nshare|improve this answer\n\nTry looking for uniform circular motion in google. It is not hard to prove it if you know something about vectors and what taking a derivative of vector function means. Force is a vector it is proportional to acceleration. Acceleration is change in velocity(remember a vector) divided by time(really shot period of time). Try to draw a circle yourself and some velocity, acceleration and position vectors\n\nshare|improve this answer\n\nIf you don't want or know how to solve a pair of simultaneous differential equations, try this more elementary approach using complex numbers and ordinary time derivatives.\n\nConsider the arbitrary path, with parameter t, in the complex plane:\n\n\nThe \"velocity\" is the time derivative:\n\n$[\\frac{dr}{dt} + ir(t)\\frac{d\\theta}{dt}] e^{i\\theta(t)}$\n\nThe \"acceleration\" is the 2nd time derivative:\n\n$\\{[\\frac{d^2r}{dt^2} - r(t)(\\frac{d\\theta}{dt})^2] + i[2(\\frac{dr}{dt}\\frac{d\\theta}{dt}) + r(t)\\frac{d^2\\theta}{dt^2}]\\}e^{i\\theta(t)}$\n\nWe require that the \"acceleration\" be orthogonal to the \"velocity\". In polar representation, this just means that the ratio of the two complex numbers is an imaginary number (multiplication by $i$ is a rotation of 90 degrees in the complex plane).\n\nIf you stare at the two derivatives a bit, you see that this condition only holds if $r$ and $\\frac{d\\theta}{dt}$ are constants:\n\n$r(t) = R$\n\n$\\frac{d\\theta}{dt} = \\omega$\n\nThen the \"velocity\" is just:\n\n$iR\\omega e^{i\\omega t}$\n\nand the \"acceleration\" is just:\n\n$-R\\omega^2e^{i\\omega t}$\n\nSo, the \"velocity\" and \"acceleration\" are indeed orthogonal. The path then is just:\n\n$Re^{i\\omega t}$\n\nThis is just a circle in the complex plane.\n\nOf course, you could have done this with polar coordinates in the x-y plane but polar complex numbers make the derivatives so much easier!\n\nshare|improve this answer\n\nI think you can prove it you can prove that the acceleration vector $\\vec{a}$ is decomposed into two components $$\\vec{a} = \\dot{v}\\, \\hat{e} + \\frac{v^2}{r} \\hat{n}$$ one tangential to motion along the unit direction vector $\\hat{e}$ and one perpendicular to along the unit direction $\\hat{n}$, with tangential speed $v$, change in speed $\\dot v$ and path radius of curvature $r$.\n\nSo if the path was not a circle, there would be a component of $\\vec{a}=\\frac{\\vec{F}}{m}$ along the tangential vector $\\hat{e}$ changing the speed $v$ as to moves along. The hole thing hinges on the fact that speed does not change in uniform circular motion.\n\nThe above comes from math called Differential Geometry along a curve, and it is related to accelerations here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/352570/martingale-not-uniformly-integrable?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI've come across a statement that implies that non-negative martingales for which $\\{M_{\\tau}\\mid \\tau \\ \\rm{stopping} \\ \\rm{time}\\}$ is not uniformly integrable exist. I personally can't think of an example tho.\n\nI've considered gambling strategies and Brownian Motions but none seem to work.\n\nIs there anyone who can think of an example and help me understand the concept a bit more?\n\nBeen looking into this for a while now so help is much appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nLet $\\xi_j$ be i.i.d. with $\\mathbb{P}(\\xi=0)=\\mathbb{P}(\\xi=2)=1/2$, and define $M_n=\\prod_{j=1}^n \\xi_j$ for $n\\geq 0$. Then $(M_n)$ is a non-negative martingale with $\\mathbb{E}(M_n)=1$ for all $n$. But $M_n\\to 0$ almost surely, so $(M_n)$ cannot be uniformly integrable.\n\nshare|improve this answer\nI've considered this before but I came to the conclusion that the stopped proces $\\{M_{\\tau}\\mid \\tau \\ \\rm{stopping} \\ \\rm{time}\\}$ was UI. \u2013\u00a0 user70267 Apr 6 '13 at 7:16\n@user70267 Already the sequence $(M_n)_n$ is not UI, and the family $(M_\\tau)_\\tau$ contains it, hence... \u2013\u00a0 Did Apr 6 '13 at 10:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/356623/counting-the-number-of-graphs-with-a-certain-property\nText:\nTake the 2-minute tour \u00d7\n\nHow many simple graphs exist with the property that such a graph $G$ has chromatic number 3, but given any edge $e$ in $G$, $G - e$ has chromatic number 2?\n\nIs there some sort of standard criteria to automatically make such a simple graph follow this behaviour? (i.e. an \"easy\" way to tell, given any graph $G$?)\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThink about cycles (specifically, odd cycles).\n\nshare|improve this answer\nI found something in the text that says if a graph has an odd cycle, then $\\chi (G) \\geq 3$. But how do I check all simple graphs with odd cycles to see which follow the property above? \u2013\u00a0 user41419 Apr 10 '13 at 2:34\nIf you remove all the edges but those of the odd cycle the chromatic number will still be greater or equal than $3$... \u2013\u00a0 Quimey Apr 10 '13 at 2:35\nEach odd cycle has chromatic number $3$. Remove any edge and the cycle turns into a path with chromatic number $2$. There are infinitely many odd length cycles $\\dots$ \u2013\u00a0 Michael Biro Apr 10 '13 at 4:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262115/why-are-hyperbolic-toral-automorphisms-e-g-arnolds-cat-map-ergodic\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\varphi : \\mathbb{T}^2 \\to \\mathbb{T}^2$ be a hyperbolic automorphism of the torus, induced by a linear map $A : \\mathbb{R}^2 \\to \\mathbb{R}^2$ of determinant $\\pm 1$ with no eigenvalues of modulus 1. What is an easy way to prove that $\\varphi$ is ergodic?\n\nIt's true that the stable and unstable manifolds at $(0,0) \\in \\mathbb{T}^2$ (projections of the eigenspaces of $A$ to the torus) are dense in the torus, which can be used to prove that such maps are topologically mixing. An example is Arnold's cat map.\n\nArnold and Avez show in Ergodic Problems in Classical Mechanics that Arnold's cat map is ergodic by proving that it has \"Lebesgue spectrum\", which implies that it is strong mixing, which implies that it is ergodic. Is there a more direct way to prove this?\n\nshare|improve this question\nA few weeks ago, someone here asked for a proof that these maps are chaotic. I found one in a textbook by Elaydi on discrete dynamical systems. The hardest part was proving the map transitive. \u2013\u00a0 Gerry Myerson Dec 20 '12 at 4:57\n@GerryMyerson I saw that thread. I found a simpler proof of a stronger statement (topologically mixing) in the book by Broer and Takens (proposition 2.15, page 111). But I don't see how topological transitivity or mixing can help me prove that these maps are ergodic. \u2013\u00a0 Ricardo Buring Dec 20 '12 at 11:25\nadd comment\n\n1 Answer\n\nI suggest using the following characterization of ergodicity:\n\n$\\varphi$ is ergodic if and only if every $f\\in L^2(\\mathbb{T}^2)$ such that $f\\circ \\varphi = \\varphi$ is constant function.\n\nNow let's use this criterion to prove $\\varphi$ is ergodic. Suppose $f\\in L^2$ with $f\\circ \\varphi = \\varphi$. Decompose $f$ into its Fourier series $$f = \\sum_{m,n\\in \\mathbb{Z}} = \\alpha_{(m\\,n)}e^{2\\pi imx}e^{2\\pi iny},$$ with coefficients $\\alpha_{(m\\,n)}\\in \\mathbb{C}$. Then, if $\\varphi$ is given by the matrix $$A = \\left(\\begin{matrix} a & b\\\\c & d\\end{matrix}\\right),$$ it is easy to compute that $$f\\circ \\varphi = \\sum_{m,n}\\alpha_{(m\\,n)}e^{2\\pi i(ma+nc)x}e^{2\\pi i(mb+nd)y}.$$ Since $f$ is invariant, the Fourier series for $f$ and $f\\circ \\varphi$ must agree, so $\\alpha_{(m\\,n)} = \\alpha_{(ma+nc\\,mb+nd)}$ for all $m,n\\in \\mathbb{Z}$. We can express this more simply as follows. If $v = (m\\,\\,n)\\in \\mathbb{Z}^2$, then $\\alpha_v = \\alpha_{vA}$. By iterating, $\\alpha_v = \\alpha_{vA^k}$ for each $k\\in \\mathbb{Z}$.\n\nSuppose that $v\\in \\mathbb{Z}^2$. Either the sequence $vA^k$ of vectors with integer coordinates is periodic, or else $\\|vA^k\\|\\to \\infty$ as $k\\to \\infty$. Note that the first case cannot happen unless $v = 0$, since if $v = vA^k$ for some $k$, then $A^k$ would have $1$ as an eigenvalue, which contradicts the assumption of hyperbolicity. Thus either $v = 0$, or $\\|vA^k\\|\\to \\infty$. Suppose $v\\neq 0$. Since $f\\in L^2$, the coefficients $\\alpha_{(m\\,n)}\\to 0$ as $\\|(m\\,\\,n)\\|\\to \\infty$, and thus $\\alpha_v = \\alpha_{vA^k}\\to 0$, i.e., $\\alpha_v = 0$. We have therefore shown that the only way $\\alpha_v$ can be nonzero is if $v = 0$. The Fourier series for $f$ is then $f = \\alpha_0$, so $f$ is a constant function.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.com/matlabcentral/answers/68186\nText:\nDiscover MakerZone\n\nMATLAB and Simulink resources for Arduino, LEGO, and Raspberry Pi\n\nLearn more\n\nDiscover what MATLAB\u00ae can do for your career.\n\nOpportunities for recent engineering grads.\n\nApply Today\n\nCan I solve this with Matlab Optimization Toolbox?\n\nAsked by GFX on 22 Mar 2013\n\nDear all,\n\nHi, I'm new to Matlab and also to optimization problems. I need help on an optimization problem. The problem is as follows:\n\nfind x=(est_pos_1, ... est_pos_n)\nminimizing the sum of squared difference between elements in matrix A and B\na_ij = 1 if Euclidean distance between est_pos_i and est_pos_j is less than constant R and 0 otherwise, 0 < i, j < m + n, m is number of points with known position, n of points with unknown positions to be estimated, b_ij = 1 if Euclidean distance between actual_pos_i and actual_pos_j is less than R and 0 otherwise. Matrix B is given.\n\nI tried solving it using Particle Swarm Optimization with poor success, i.e. the error between the estimated and actual positions is high.\n\n\nWalter Roberson on 22 Mar 2013\n\nThe two matrices A and B appear to be different sizes, as B only goes as far as the known positions but A extends to estimated positions. I am not sure what the sum of the squared difference would mean for different sized matrices?\n\nIf the values are all 0's and 1's, then squared difference would be the same as absolute difference, right? And in turn would be the same as \"not equal\" ?\n\nWhat does it mean to estimate position (i,j) for points whose actual position is known?\n\nGFX on 29 Mar 2013\n\nHi, the size of A an B are of the same size. However, instead of determine all m+n points, we are to decide only on the position of n unknown points, since the m points we already known their position from prior knowledge. We are to determine positions of est_pos_i (estimated positions of unknown points i, n of these) given some connectivity constrains, given by B. So, we are trying to recreate the position of all points based on connectivity readings. In actual, B can be obtained for e.g. say the points know who their neighboring points are. However, for simulation, B can simply be calculated by determining if the distances between the actual positions between any pair of points. In simulation, we also have the exact positions of all points. I hope I am clear. Thank you.\n\nGFX on 29 Mar 2013\n\nAnd the objective here is to recreate the configuration (positioning) of points that resembles the exact configuration. Hence the sum of square difference objective.\n\nThank you.\n\n\n\nNo products are associated with this question.\n\n1 Answer\n\nAnswer by Matt J on 29 Mar 2013\nEdited by Matt J on 29 Mar 2013\nAccepted answer\n\nNo, you can't use the Optimization Toolbox. The solvers in the Toolbox are smooth algorithms (except for bintprog) and therefore apply to differentiable functions.\n\nHowever, your matrix A, and therefore the objective function overall, is a piecewise constant, non-differentiable, function of x. The piecewise constant behavior will also mean that the objective function is flat almost everywhere, making almost every point a local minimum where the optimization can get stuck.\n\n\nGFX on 29 Mar 2013\n\nFor example, how do I easily and quickly determine if such a problem is say linear, convex, or non linear? I know about the standard forms of LP, convex programs and such, but for eg. in my original question, how do you determine them?\n\nMatt J on 29 Mar 2013\n\nWell, I don't think there's always an easy way. Certainly optimization textbooks will always give examples of functions that are convex etc... and you build your analysis skills from that.\n\nHowever, in your case, the A matrix can only take on values 0 or 1. Discrete-valued functions like that have to be piecewise constant.\n\nGFX on 31 Mar 2013\n\nThanks Matt J, thanks all. :-)\n\nMatt J\n\nContact us"}
{"text": "Retrieved from http://math.stackexchange.com/questions/239697/huffman-code-with-probabilities-p-1-p-2-ldots-p-n?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have solved the first two subsections of an assignment, but I can't solve the last subsection.\n\nWe have a Huffman code with probabilities $p_1,p_2,\\ldots, p_n$ and we know that $p_1>p_2>\\cdots>p_n>0$.\n\n$y_1$ - the code for the character whose probability is $p_1$? And $|y1|$ is the length of $y_1$.\n\nI proved that:\n\n  \u2022 if $|y_1| = 1$ then $p_1 \\geq 1/3$.\n  \u2022 if $p_1 < 1/3$ then $|y_1| \\geq 2$ (it is not the same as above).\n\nI can't prove:\n\n  \u2022 if $p_1 > 2/5$ then $|y_1| = 1$.\n\nThanks for all kind of help.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nSince you say it's an assignment I won't give you the full answer, but here's an orientation. You can build a proof by contradiction from two components: Dirichlet's principle and the construction of the Huffman tree.\n\nFirst prove that given that $p_1 = 2/5 + \\epsilon$ and $|y_1| > 1$ there must be a merge step where the words are partitioned into three disjoint sets: $\\{y_1\\}$, $A$, and $B$ such that the total probability of the words in $A$ is more than $p_1$ (and hence the total probability of the words in B is less than $1/5 - 2\\epsilon$).\n\nThen prove that the step which generated $A$ by merging the two smallest sets was performed incorrectly because $B$ was actually smaller than one of them.\n\nshare|improve this answer\nthank you, I solved this assignment an another way. \u2013\u00a0 Tatar Elem\u00e9r Nov 18 '12 at 22:30\nadd comment\n\nI use this:\n\nif p1 > 2/5 then at least one symbol is encoded by a codeword of length 1. (Hint: Suppose not and consider the vertices of the Hu\ufb00man tree which are distance 2 from the root.) Solution: Suppose not. This immediately implies that at distance 2 from the root of the encoding tree there are exactly 4 vertices, say a1, a2, a3, a4 with probabilities p1, p2, p3, p4 . One of these, say a1 corresponds to a1 or was obtained by merging it. It follows that p1 > p1 > 2/5. Suppose a3 and a4 are merged at the next step to form a new symbol a with probability p. Since a1 must be merged before the \ufb01nal step, we must have that p > p1 (otherwise we would merge a2 with a). Since also 2p2 > p3 + p4 = p > p1 and p1 + p2 + p = 1, we obtain that 1 > p1 + p1/2 + p1 = 5p1/2 > 5p1/2, a contradiction.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/298191/lower-bound-for-matrix-sorting\nText:\nTake the 2-minute tour \u00d7\n\nConsider the problem of sorting a $n$ by $n$ matrix i.e. the rows and columns are in ascending order. I want to find the lower and upper bound of this problem.\n\nI found that it is $O(n^2logn)$ by just sorting the elements and then outputting the first $n$ elements as the first row, the next $n$ elements as the second row, and so on. However, I want to prove that it is also $\\Omega(n^2logn)$.\n\nAfter trying smaller examples, I think I should prove that if I can solve this problem using less than $n^2log(\\frac{n}{e})$ comparisons, it would violates the $log(m!)$ lower bound for comparisons needed to sort $m$ elements. Any ideas on how to prove that?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nHere is the argument I alluded to in my earliest comment. I claim that a sorted $n\\times n$ matrix $A$ can be linearly sorted in $n^2 \\log_2 n + O(n^2)$ comparisons. To do this, we maintain a vector $v$ which records up to $n$ values of $A$ in increasing order (and their corresponding locations $i,j$). Initially, take $v$ to be the first row of $A$.\n\nWe then iterate the following procedure $n^2$ times: output the least value of $v$, delete it from $v$, and insert into $v$ the entry directly underneath it in $A$ (if there is one). Since $v$ is sorted, finding the lowest value takes $0$ comparisons, but insertion of the new value requires a binary search on $v$, which is $\\lceil \\log_2 m \\rceil \\le \\log_2 m + 1$ comparisons, where $m \\le n$ is the length of $v$.\n\nIt should be clear that we never insert any value into $v$ before exhausting all smaller values, so if we iterate $n^2$ times this gives a linearly sorted list. The number of comparisons is at most $n^2 (\\log_2 n + 1) = n^2 \\log_2 n + O(n^2)$, proving the claim.\n\nHowever, to sort an arbitrary matrix of $n^2$ elements requires at least $\\log_2(n^2!)$ comparisons in the worst case, and this is equal to $n^2 \\log_2 n^2 - O(n^2) = 2n^2 \\log_2 n - O(n^2)$ . Therefore, getting from an arbitrary matrix to a sorted matrix must consume at least the difference of these two amounts of comparisons in the worst case, namely $n^2 \\log_2 n - O(n^2)$.\n\nshare|improve this answer\nI don't understand your conclusion (Therfore, ... ). How do you go from the problem of sorting the elements of a sorted matrix to the problem of sorting the matrix itself. Please, can you explain it to me? \u2013\u00a0 J Mint Feb 9 '13 at 9:41\n@jiji777 Do you understand what the lower bound for sorting means? There is no comparison-based way to sort $n^2$ numbers without spending about $2n^2 \\log n$ comparisons. Yet if we could matrix-sort cheaply it would only cost about half that many. \u2013\u00a0 Erick Wong Feb 9 '13 at 15:00\nNo, I understand that. But if T(n) is the time spent to get from an arbitrary matrix to a sorted matrix and S(n) is the time spent to get from a sorted matrix to a sorted array. Shouldn't you prove that $S(n)$ cannot be done in less than $n^2logn$ to prove that $T(n) \\geq n^2logn+log(n^2!)$. Is giving one algorithm that runs in $n^2logn$ sufficient or do we have to prove it for all algorithms? \u2013\u00a0 J Mint Feb 9 '13 at 20:21\n@jiji777 You have it backwards. We know that $T(n) + S(n) \\ge 2n^2 \\log n$, because the RHS is how long it takes to go from arbitrary matrix to sorted list, and the LHS is one possible way of doing so. A lower bound for $S(n)$ wouldn't help at all to control $T(n)$. \u2013\u00a0 Erick Wong Feb 9 '13 at 20:23\nright. Ok, thanks. \u2013\u00a0 J Mint Feb 9 '13 at 20:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/118626/real-symmetric-matrix-has-real-eigenvalues-elementary-proof/118640\nText:\nTake the 2-minute tour \u00d7\n\nEvery real symmetric matrix has at least one real eigenvalue. Does anyone know how to prove this elementary, that is without the notion of complex numbers?\n\nshare|improve this question\nThis is a very weird notion of \"elementary\", isn't it? Defining the complex numbers using the reals takes hardly more than 1 page. There is a real-analysis proof of the spectral theorem which never uses complex numbers; instead, it uses induction and Lagrange multipliers to find the maximum of $\\left|\\left|Ax\\right|\\right|$ over $x\\in S\\left(0,1\\right)$ (the sphere with center $0$ and radius $1$). This maximum is then shown to be an eigenvalue of $A$, and the vector $x$ for which the maximum is achieved is an eigenvector. ... \u2013\u00a0 darij grinberg Jan 11 '13 at 13:28\nWhat does \"has real eigenvalues\" mean? Apparently it is not to be understood as \"has no nonreal eigenvalues\", since mention of complex numbers is forbidden. Does it mean \"has at least one real eigenvalue\"? Does it mean: (where the size is $n \\times n$) \"has $n$ linearly independent eigenvectors with real eigenvalues\"? \u2013\u00a0 Gerald Edgar Jan 11 '13 at 14:16\nI'm with Gerald in not being sure exactly what the question's asking. By definition, the eigenvalues of a matrix over a field $k$ are elements of $k$. So strictly speaking, the question is trivial; looking for a nontrivial interpretation, I guess it must be one of the two possibilities that Gerald mentions. @Z254R: yes, I think Gerald is helping to formulate the problem. \u2013\u00a0 Tom Leinster Jan 11 '13 at 17:08\n@Z254R: As Gerald points out, it is still unclear whether by \"has real eigenvalues\" the OP means \"has at least one real eigenvalue\" or \"has $n$ real eigenvalues\". \u2013\u00a0 Mark Meckes Jan 11 '13 at 20:54\n@marjeta: the point is that we shouldn't have to spend time guessing exactly what your question means, which is what many of these comments are trying to do. You should make it clear what your question means. \u2013\u00a0 Tom Leinster Jan 12 '13 at 22:23\nshow 9 more comments\n\n9 Answers\n\nup vote 27 down vote accepted\n\nIf \"elementary\" means not using complex numbers, consider this.\n\n  1. First minimize the Rayleigh ratio $R(x)=(x^TAx)/(x^Tx).$ The minimum exists and is real. This is your first eigenvalue.\n\n  2. Then you repeat the usual proof by induction in dimension of the space.\n\n  3. Alternatively you can consider the minimax or maximin problem with the same Rayleigh ratio, (find the minimum of a restriction on a subspace, then maximum over all subspaces) and it will give you all eigenvalues.\n\nBut of course any proof requires some topology. The standard proof requires Fundamental theorem of Algebra, this proof requires existence of a minimum.\n\nshare|improve this answer\nAlexander, when you said that the minimum is an eigenvalue, did you mean to prove it by applying the Lagrange multiplier equation to the function $f(x)=x^tAx$ restricted to a level set of $g(x)=x^tx$, or did you have a different idea in mind? \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 23:56\nMarcos. In that case, you can prove the Lagrange multiplier relation hand: if $\\lambda$ is the minimum, then for every $y$, $(x+y)^TA(x+y)\\geq \\lambda (x+y)^T(x+y)$, that is, $2((y^T (Ax-\\lambda x)\\geq \\lambda y^Ty - y^TAy$. The LHS is homoegeneous of degree $1$, the RHS of degree $2$. So the LHS has to be zero for every $y$. This implies $Ax=\\lambda x$. \u2013\u00a0 ACL Jan 14 '13 at 0:15\nMarcos: yes. ACL's explanation is one way to do it. \u2013\u00a0 Alexandre Eremenko Jan 14 '13 at 21:31\nadd comment\n\nHow about Jacobi's proof?\n\nSee, e.g., Folkmar Bornemann, ``Teacher's Corner - kurze Beweise mit langer Wirkung,'' DMV-Mitteilungen 3-2002, Seite 55 (in German, sory). I don't have the original reference, sorry.\n\nThe idea is simple, define $\\Sigma(A)=\\sum_{i=1}^n\\sum_{j=i+1}^n a_{ij}^2$ for $A=(a_{ij})$ a symmetric real matrix. Then minimize the function $O(n)\\ni J \\mapsto \\Sigma(J^TAJ)$ over the orthogonal group $O(n)$. The function is continuous and bounded below by zero, and $O(n)$ is compact, so the minimum is attained. But it can not be strictly positive, because if there is an $a_{ij}\\not=0$, $i\\not=j$, then you can make it zero by a rotation that acts only on the $i$th and $j$th row and column, so that it decreases $\\Sigma$ (this is a simple little calculation with $2\\times 2$ matrices). Therefore the minimum is zero and it is attained in a matrix $J$ for which $J^TAJ$ is diagonal.\n\nThe eigenvalues of $A$ are now the (diagonal) entries of $J^TAJ$. No complex numbers are used, but you have to know that the minimum exists. We get the existence of an orthonormal basis consisting of eigenvectors with real eigenvalues.\n\nshare|improve this answer\nTo add a little more detail: The total energy $\\frac 12\\sum a_{ij}$, which is the sum of the energy on the diagonal and $\\Sigma$, is invariant by orthogonal conjugation, so we want to move it to the diagonal. When you apply a rotation $J$ in the plane spanned by the canonic vectors $e_i$ and $e_j$, which only affects the $i$th and $j$th rows and columns, the resulting coefficients $ii$, $ij$, $ji$, $jj$ of $J^tAJ$ depend only on the same coefficients of $A$, so the problem is reduced to increasing the energy on the diagonal of a $2\\times 2$ matrix. \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 2:00\nI meant $\\frac 12\\sum a_{ij}^2$. \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 14:21\nThis feels so wrong! :-) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 14 '13 at 4:29\nadd comment\n\nLet me give it a try. This one only uses the existence of a maximum in a compact set, and the Cauchy-Schwarz inequality.\n\nLet $T$ be a selfadjoint operator in a finite dimensional inner product space.\n\nClaim: $T$ has an eigenvalue $\\pm\\|T\\|$.\n\nProof: Let $v$ in the unit sphere be such that $\\|Tv\\|$ attains its maximum value $M=\\|T\\|$. Let $w$ also in the unit sphere be such that $Mw=Tv$ (which is like saying that $w=\\frac{Tv}M$, except in the trivial case $T=0$).\n\nThis implies that $\\langle w,Tv\\rangle=M$. In fact, the only way that to unit vectors $v$ and $w$ can satisfy this equation is to have $Mw=Tv$. (Since we know that $\\|w\\|=1$ and $\\|Tv\\|\\leq M$, the Cauchy-Schwarz inequality tells us that $|\\langle w,Tv\\rangle\\|\\leq M$, and the equality case is only attainable when $Tv$ is a scalar multiple of $w$, being $M$ the only possible value of the scalar.)\n\nBut by selfadjointness of $T$, we also know that $\\langle v,Tw\\rangle=M$, so that $Mv=Tw$.\n\nNow, one of the two vectors $v\\pm w$ is nonzero, and we can compute\n\n$T(v\\pm w)=Tv\\pm Tw=Mw\\pm Mv=M(w\\pm v)=\\pm M(v\\pm w)$.\n\nThis concludes the proof that $\\pm\\|T\\|$ is eigenvalue with eigenvector $v\\pm w$. The reality of the other eigenvalues can be proved by induction, restricting to $(v\\pm w)^\\bot$ as in the usual proof of the spectral theorem.\n\nRemark: The proof above works with real or complex spaces, and also for compact operators in Hilbert spaces.\n\nComment: I would like to know if this proof can be found in the literature. I obtained it while trying to simplify a proof of the fact that if $T$ is a bounded selfadjoint operator, then $\\|T\\|=\\sup_{\\|v\\|\\leq 1} \\langle Tv,v\\rangle$ (as found, for example, on p.32 of Conway J.B., \"An Introduction to Functional Analysis\"). In the case of non-compact operators, one can only prove that $T$ has as an approximate eigenvalue one of the numbers $\\pm\\|T\\|$. The argument is similar to the one above, but knowledge of the equality case of Cauchy-Schwarz is not enough. One has to know that near-equality implies near-dependence. More precisely, let $v$ be a fixed unit vector, $M\\geq 0$ and $\\varepsilon\\in[0,M]$. If $z$ is a vector with $\\|z\\|\\leq M$ such that $|\\langle v,z\\rangle|\\geq \\sqrt{M^2-\\epsilon^2}$, then it can be proved that $z$ is within distance $\\varepsilon$ of $\\langle v,z\\rangle v$.\n\nshare|improve this answer\nI don't see why this is different from Alexander Eremenko's answer. \u2013\u00a0 Deane Yang Jan 13 '13 at 22:10\nI don't understand Alexander's answer. How do you prove that if $R(x)=\\frac{x^tAx}{x^tx}$ is maximum, then $x$ is an eigenvector? I got nowhere by derivating $R$, and the only easy way that I see to complete his proof is to normalize $x$ to get a maximum of $x^tAx$ in the unit sphere, and then write the Lagrange multipliers equation that tells you that $x$ is an eigenvector. \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 23:35\nBut Lagrange multipliers is, in my opinion, different from the argument above, which in fact was originally designed to deal with bounded operators, as explained in the comment. Can Lagrange multiplier be used to prove that $\\pm\\|T\\|$ is an approximate eigenvalue of a bounded operator T? If not, is this enough to conclude that the proofs are different? \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 23:45\nI think that the main difference is that Alexander extremises $x^tAx$ and I extremise $y^tAx$. That the two situations are not trivially equal is the subject of p.32 of Conway. \u2013\u00a0 Marcos Cossarini Jan 14 '13 at 0:33\nadd comment\n\nWe can do it in two steps.\n\nStep 1: show that if $A$ is a real symmetric matrix, there is an orthogonal matrix $L$ such that $A=LHL^T$, where $H$ is tridiagonal and its off-diagonal entries are non-negative. (Apply Gram-Schmidt to sets of vectors of the form $\\{x,Ax,\\ldots,A^mx\\}$, or use Householder transformations, which is the same thing.)\n\nStep 2. We need to show that the eigenvalues of tridiagonal matrices with non-negative off-diagonal entries are real. We can reduce to the case where $H$ is indecomposable. Assume it is $n\\times n$ and let $\\phi_{n-r}$ the the characteristic polynomial of the matrix we get by deleting the first $r$ rows and columns of $H$. Then $$ \\phi_{n-r+1} = (t-a_r)\\phi_{n-r} -b_r \\phi_{n-r-1}, $$ where $b>0$. Now prove by induction on $n$ that the zeros of $\\phi_{n-r}$ are real and are interlaced by the zeros of $\\phi_{n-r-1}$. The key here is to observe that this induction hypothesis is equivalent to the claim that all poles and zeroes of $\\phi_{n-r-1}/\\phi_{n-r}$ are real, and in its partial fraction expansion all numerators are positive. From this it follows that the derivative of this rational function is negative everywhere it is defined and hence, between each consecutive pair of zeros of $\\phi_{n-r-1}$ there must be a real zero of $\\phi_{n-r}$.\n\nshare|improve this answer\nMight it be done using eigenvalue interlacing on the original matrix rather than reducing to tridiagonal form first? \u2013\u00a0 Brendan McKay Jan 13 '13 at 5:54\nI can do it if I am allowed to use spectral decomposition. Write $A$ as $A_1 + bb^T$, where the first row and column of $A_1$ are both zero. (If needed replace $A$ by $-A$.) Then $$ \\det(tI-A) = \\det(tI-A_1-bb^T) = \\det(tI-A_1)\\det(I-(tI-A)^{-1}bb^T) $$ and since $\\det(I-uv^T)=1-v^Tu$, we get that $\\det(tI-A)/\\det(tI-A_1)$ is equal to $1-b^T(tI-A_1)^{-1}b$. Now use spectral decomposition to deduce that the numerators in $b^T(tI-A_1)^{-1}b$ are real. (This argument is logical, but it might not be a lot of fun in a classroom.) \u2013\u00a0 Chris Godsil Jan 13 '13 at 15:38\nadd comment\n\nThis is just the details of the first step of Alexander Eremenko's answer (so upvote his answer if you like mine), which I think is by far the most elementary. You only need two facts: A continuous function on a compact set in $R^n$ achieves its maximum (or minimum), and the derivative of a smooth function vanishes at a local maximum. And there's no need for Lagrange multipliers at all.\n\nLet $C$ be any closed annulus centered at $0$. The function $$ R(x) = \\frac{x\\cdot Ax}{x\\cdot x}, $$ is continuous on $R^n\\backslash\\{0\\}$ and therefore achieves a maximum on $C$. Since $R$ is homogeneous of degree $0$, any maximum point $x \\in C$ is a maximum point on all of $R^n\\backslash\\{0\\}$. Therefore, for any $v \\in R^n$, $t = 0$ is a local maximum for the function $$ f(t) = R(x + tv). $$ Differentiating this, we get $$ 0 = f'(0) = \\frac{2}{x\\cdot x}[Ax - R(x) x]\\cdot v $$ This holds for any $v$ and therefore $x$ is an eigenvector of $A$ with eigenvalue $R(x)$.\n\nshare|improve this answer\n(You could add this to his answer, probably) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 14 '13 at 4:26\nadd comment\n\nAnother elementary proof, based on the order structure of symmetric matrices. Let me first recall the basic definitions and facts to avoid misunderstandings: we define $A\\ge B$ iff $(A-B)x\\cdot x\\ge0$ for all $x\\in\\mathbb{R}^n$). Also, a lemma:\n\nA symmetric matrix $A$, which is positive and invertible, is also definite positive (that is, $A\\ge\\epsilon I$ for some $\\epsilon > 0\\, > $).\n\nWe may say, equivalently: if $A$ is positive but, for any $\\epsilon >0$, the matrix $A-\\epsilon I$ is not, then $A$ is not invertible. (A quick proof passes through the square root of $A$: $(Ax\\cdot x)=\\|A^{1/2} x\\|^2 \\ge \\|A^{-1/2}\\|^{-2} \\| x\\|^2$; one has to construct $A^{1/2}$ before, without diagonalization, of course).\n\nAs a consequence, $\\alpha^*:=\\sup_{|x|=1}(Ax \\cdot x)$ is an eigenvalue of $A$, because $ \\alpha^*I-A$ is positive and $\\alpha^*I-A-\\epsilon I$ is not (and $\\alpha _ *:=\\inf _ {|x|=1}(Ax \\cdot x)$ too, for analogous reasons).\n\nThe complete diagonalization is then performed inductively, as in other proofs.\n\nshare|improve this answer\nadd comment\n\nThis is quite an interesting question, perhaps a research problem. I think an elementary answer should be a high school algebra answer in the sense of Abhyankar and it would have to be in the spirit of what follows. But first a little story.\n\nI was teaching linear algebra and had just covered eigenvalues and characteristic polynomials but was not yet at the chapter on the spectral theorem for real symmetric matrices. I was looking for problems to assign for my students as homework in the textbook we were using. One of the exercises was to show that a real matrix $$ A=\\left[ \\begin{array}{cc} \\alpha & \\beta \\\\\\ \\beta & \\gamma \\end{array} \\right] $$ only had real eigenvalues. Not too hard. Write the characteristic polynomial $$ \\chi(\\lambda)=det(\\lambda I-A)=\\lambda^2-(\\alpha+\\gamma)\\lambda+\\alpha\\gamma-\\beta^2 $$ then its discriminant is $$ \\Delta=(\\alpha+\\gamma)^2-4(\\alpha\\gamma-\\beta^2)=(\\alpha+\\gamma)^2+4\\beta^2\\ge 0\\ . $$ Hence two real roots.\n\nThe next problem in the book was to do the same for $$ A=\\left[ \\begin{array}{ccc} \\alpha & \\beta & \\gamma\\\\\\ \\beta & \\delta & \\varepsilon \\\\\\ \\gamma & \\varepsilon & \\zeta \\end{array} \\right] $$ and (silly me) I also assigned it...\n\nHere is the solution in the 3X3 case. All roots are real if the discriminant (for a binary cubic) is nonnegative. The discriminant of the characteristic polynomial is $$ \\Delta = (\\delta \\varepsilon ^{2} + \\delta \\zeta ^{2} - \\zeta \\delta ^{2} - \\zeta \\varepsilon ^{2} + \\zeta \\alpha ^{2} + \\zeta \\gamma ^{2} - \\alpha \\gamma ^{2} - \\alpha \\zeta ^{2} + \\alpha \\beta ^{2} + \\alpha \\delta ^{2} - \\delta \\alpha ^{2} - \\delta \\beta ^{2})^{2} \\\\\\ \\mbox{} + 14(\\delta \\gamma \\varepsilon - \\beta \\varepsilon ^{2} + \\beta \\gamma ^{2} - \\alpha \\gamma \\varepsilon )^{2} \\\\\\ \\mbox{} + 2(\\delta \\alpha \\gamma + \\delta \\beta \\varepsilon + \\delta \\gamma \\zeta - \\gamma \\delta ^{2} - \\gamma \\varepsilon ^{2} + \\gamma ^{3} - \\alpha \\beta \\varepsilon - \\alpha \\gamma \\zeta )^{2} \\\\\\ \\mbox{} + 2(\\delta \\beta \\gamma + \\delta \\varepsilon \\zeta - \\varepsilon ^{3} + \\varepsilon \\alpha ^{2} + \\varepsilon \\gamma ^{2} - \\alpha \\beta \\gamma - \\alpha \\delta \\varepsilon - \\alpha \\varepsilon \\zeta )^{2} \\\\\\ \\mbox{} + 2(\\zeta \\alpha \\beta + \\zeta \\beta \\delta + \\zeta \\gamma \\varepsilon - \\beta \\varepsilon ^{2} - \\beta \\zeta ^{2} + \\beta ^{3} - \\delta \\alpha \\beta - \\alpha \\gamma \\varepsilon )^{2} \\\\\\ \\mbox{} + 14(\\zeta \\beta \\varepsilon - \\gamma \\varepsilon ^{2} + \\gamma \\beta ^{2} - \\alpha \\beta \\varepsilon )^{2} \\\\\\ \\mbox{} + 2(\\zeta \\beta \\gamma + \\delta \\varepsilon \\zeta - \\varepsilon ^{3} + \\varepsilon \\alpha ^{2} + \\varepsilon \\beta ^{2} - \\alpha \\beta \\gamma - \\alpha \\delta \\varepsilon - \\alpha \\varepsilon \\zeta )^{2} \\\\\\ \\mbox{} + 14(\\varepsilon \\beta ^{2} + \\zeta \\beta \\gamma - \\delta \\beta \\gamma - \\varepsilon \\gamma ^{2})^{2} \\\\\\ \\mbox{} + 2(\\zeta \\alpha \\beta + \\zeta \\beta \\delta + \\zeta \\gamma \\varepsilon - \\beta \\gamma ^{2} - \\beta \\zeta ^{2} + \\beta ^{3} - \\delta \\alpha \\beta - \\delta \\gamma \\varepsilon )^{2} \\\\\\ \\mbox{} + 2(\\alpha \\gamma \\zeta + \\zeta \\beta \\varepsilon - \\gamma ^{3} + \\gamma \\beta ^{2} + \\gamma \\delta ^{2} - \\delta \\alpha \\gamma - \\delta \\beta \\varepsilon - \\delta \\gamma \\zeta )^{2}\\ . $$\n\nThis formula comes from a paper by Ilyushechkin in Mat. Zametki, 51, 16-23, 1992.\n\nI suspect the elementary answer should be as follows. First find a list of invariants or covariants of binary forms $C_1,C_2,\\ldots$ such that a form with real coefficients has only real roots iff these covariants are nonnegative. Apply this to the characteristic polynomial of a general real symmetric matrix and show that you get sums of squares. I suppose these covariants, via Sturm's sequence type arguments, should correspond to subresultants or rather subdiscriminants. This seems also related to Part 2) of Godsil's answer.\n\nEdit: Another recent research reference which relates to the above sum-of-squares formula is the article The entropic discriminant by Sanyal, Sturmfels and Vinzant.\n\nEdit 2: I just found out that the problem I mentioned above has been completely solved! See Proposition 4.50 page 127 in the book by Basu, Pollack and Roy on real algebraic geometry. The connection with classical invariants/covariants of binary forms is not apparent but it is there: their proof is based on subresultants and subdiscriminants which are leading terms of $SL_2$ covariants.\n\nshare|improve this answer\nadd comment\n\nThe fact that real symmetric matrix is ortogonally diagonalizable can be proved by induction. The crucial part is the start. Namely, the observation that such a matrix has at least one (real) eigenvalue. But this can be done in three steps.\n\n(1) An easy observation (using direct matrix multiplication) shows that all columns of a matrix $\\mathbf{A}\\in\\mathbb{R}_{m\\times n}$ are orthogonal to any vector $z\\in\\mathbb{R}_{m\\times 1}$ iff $z$ belongs to the null space of the transpose $\\mathbf{A}^{\\sf T}$, i.e. $\\mathcal{N}(\\mathbf{A}^{\\sf T})=\\mathcal{R}(\\mathbf{A})^{\\perp}$.\n\n(2) If $\\mathbf{S}^{\\sf T}=\\mathbf{S}$ and $\\mathbf{S}x \\neq 0$ for every $x\\neq 0$, then the dot product $\\langle\\mathbf{S}x,x\\rangle\\neq 0$ for any $x\\neq 0$ as well. Otherwise, if $\\langle \\mathbf{S}z,z\\rangle=0$ for some $z\\neq 0$, then we have, using (1), $z\\in\\mathcal{R}(\\mathbf{S})^{\\perp}=\\mathcal{N}(\\mathbf{S}^{\\sf T})= \\mathcal{N}(\\mathbf{S})$, i.e. a contradiction $z\\ne0$ and $\\mathbf{S}z=0$.\n\n(3) If matrix $\\mathbf{A}=\\mathbf{A}^{\\sf T}\\in\\mathbb{R}_{n\\times n}$ has no (real) eigenvalue, then $(t\\mathbf{I}-\\mathbf{A})x\\neq 0$ for any $x\\neq 0$ and every $t\\in\\mathbb{R}$. Consequently, according to (2), we have $\\langle(t\\mathbf{I}-\\mathbf{A})y,y\\rangle\\neq 0$ for fixed $y\\neq 0$ and $t\\in\\mathbb{R}$. Therefore $t\\|y\\|^2 -\\langle\\mathbf{A}y,y\\rangle \\neq 0$ for every $t\\in\\mathbb{R}$, which is impossible.\n\nshare|improve this answer\nI'm confused by your (2)...doesn't putting $S=\\left(\\begin{array}{cc} 0 & 1 \\\\ 1 & 0\\end{array}\\right)$ and $z=\\left(\\begin{array}{c} 1 \\\\ 0\\end{array}\\right)$ give a counterexample? The statement that $\\langle Sz,z\\rangle=0$ isn't enough to imply that $z$ is orthogonal to the range. \u2013\u00a0 Mike Usher Jan 12 '13 at 18:40\nThank you for the comment. Unfortunately, the relation $z\\perp\\mathbf{S}z$ does not imply $z\\perp y$ for \\underline{every} $y\\in\\mathcal{R}(\\mathbf{S})$. I apologize for the false proof. Vito Lampret \u2013\u00a0 Vito Jan 13 '13 at 13:48\nadd comment\n\nJust found in Godsil-Royle's Algebraic graph theory: One first proves that two eigenvectors associated with two different eigenvalues are necessarily orthogonal to each other (pretty standard), then observes that if $u$ is eigenvector associated with eigenvalue $\\lambda$, then $\\bar u$ is eigenvector associated with eigenvalue $\\bar\\lambda$. Now the eigenvalues $\\lambda,\\bar\\lambda$ cannot be different, for otherwise by the above observation $0=u^T u=\\|u\\|^2$ although $u\\not=0$.\n\n(It does contain complex numbers, but is still amazingly straightforward).\n\nshare|improve this answer\nThis is what I would call the standard approach (going through operators on ${\\mathbb C}^n$) and as such I don't think it really fulfils the requirements of the original question. \u2013\u00a0 Yemon Choi Feb 26 '13 at 23:45\nYes, this is how an operator theorist would do it. But the question was also the existence of an eigenvalue (possibly without the fundamental theorem of algebra). Is there an argument for it too? \u2013\u00a0 Andr\u00e1s B\u00e1tkai Feb 27 '13 at 7:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/227794/in-field-f-cdot-how-can-i-prove-x2-1-implies-x-1-1/227796\nText:\nTake the 2-minute tour \u00d7\n\nI'm a really confused about fields.\n\nI know that it means $x$ is the reciprocal element of itself, and I can easily show that $1^2=1$ (not as trivial for $(-1)^2$ though), but I'm not sure how it helps me.\n\nedit: oh... I can only approve one answer. Well Rankeya was first (by a very short time) so I guess I'll approve his though, I don't really have any idea what it means. Thanks to both Brian M. Scott and Rankeya for the help.\n\nshare|improve this question\nDear @Nescio: You accept an answer that you feel is most helpful to you. It does not have to be the first answer that is posted. (But, make sure that you always accept answers if you feel you are satisfied with them. It encourages people to answer your questions, and also brings a sense of completeness/closure.) \u2013\u00a0 Rankeya Nov 3 '12 at 1:19\nadd comment\n\n2 Answers\n\nup vote 15 down vote accepted\n\nA field is a domain, which in particular means that $ab = 0 \\Rightarrow a = 0$ or $b = 0$. Write $x^2 = 1$ as $x^2 - 1 = 0$, and try to proceed from there.\n\nAlso, welcome to MSE!\n\nshare|improve this answer\nwow, that was so simple I feel stupid now... Thanks \u2013\u00a0 Nescio Nov 2 '12 at 20:26\nIt happens to the best of mathematicians. So, don't worry too much about it. \u2013\u00a0 Rankeya Nov 2 '12 at 20:27\nActually, I have been told by other mathematicians that it happens to the best of mathematicians. I often disbelieve them when they say this, and continue to feel stupid :) \u2013\u00a0 Rankeya Nov 2 '12 at 20:30\n@Rankeya: The best way to believe it is to see enough people who are more experienced and smarter than you do the same. Then again, even if you do believe it, it doesn't mean it won't make you feel stupid when you it happens to you. \u2013\u00a0 tomasz Nov 2 '12 at 20:42\nadd comment\n\nHINT: $x^2=1$ if and only if $x^2-1=0$. In any field $x^2-1=(x-1)(x+1)$, so $x^2=1$ if and only if $(x-1)(x+1)=0$. Now prove that for any $a,b\\in F$, $ab=0$ if and only if at least one of $a$ and $b$ is $0$.\n\nshare|improve this answer\n+1 But you solved the problem for him. :) \u2013\u00a0 B. S. Nov 2 '12 at 20:24\n@Babak: He may not agree. :-) \u2013\u00a0 Brian M. Scott Nov 2 '12 at 20:25\nstill feeling stupid... Thanks for the quick response both of you. \u2013\u00a0 Nescio Nov 2 '12 at 20:27\n@Andrey: You\u2019re welcome. And don\u2019t worry about it: it\u2019s happened to all of us. \u2013\u00a0 Brian M. Scott Nov 2 '12 at 20:28\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/127546/is-the-solution-to-a-driftless-sde-with-lipschitz-variation-a-martingale\nText:\nTake the 2-minute tour \u00d7\n\nIf $\\sigma$ is Lipschitz, with Lipschitz constant $K$, and $(X_t)_{t\\geq 0}$ solves\n\n$$dX_t=\\sigma(X_t)dB_t,$$ where $B$ is a Brownian motion, then is $X$ a martingale? I'm having difficulty getting past the self-reference here. I tried showing that, for $t\\geq 0$, $\\mathbb{E}[X]_t$ is finite. Perhaps Gronwall's lemma is needed?\n\nThank you.\n\nshare|improve this question\nYou could try and have a look at Theorem 4.40 (b) (and the above definition 4.39) in Jacod and Shiryaev's Limit Theorems for Stochastic Processes. If we are in the scope of that Theorem then $(X_t)$ is in fact a square integrable martingale. \u2013\u00a0 Stefan Hansen Apr 3 '12 at 10:57\n@StefanHansen I'm away from a library at the moment. If this works, put it as an answer, and I'll find the book later. :) \u2013\u00a0 Ben Derrett Apr 3 '12 at 12:32\nadd comment\n\n2 Answers\n\nUnfortunately, it didn't work in general (not saying that your claim is false though). Here is what I was trying to do. Maybe it can help you come up with ideas, otherwise just nevermind it.\n\nLet $L^2(X)$ be the set of all predictable processes $H$ such that the process $(\\int_0^t H^2_s d\\langle X\\rangle_s)_{t\\geq 0}$ is integrable, where $(\\langle X \\rangle_t)_{t\\geq 0}$ denotes the predictable quadratic variation process.\n\nIn the following $\\mathcal{H}^2$ (resp. $\\mathcal{H}_{\\text{loc}}^2$) denotes the set of all square integrable martingales (resp. locally square integrable martingales). Then we have the following theorem from Jacod & Shiryaev:\n\nTheorem 4.40(b). Let $(X_t)_{t\\geq 0}\\in \\mathcal{H}_{\\text{loc}}^2$. Then $(\\int_0^t H_s d X_s)_{t\\geq 0} \\in \\mathcal{H}^2$ if and only if $H\\in L^2(X)$.\n\nObviously we are in the scope of this theorem as $(B_t)_{t\\geq 0}\\in\\mathcal{H}^2$ with predictable quadratic variation $\\langle B_t\\rangle = t$, $t\\geq 0$. Furthermore if $(X_t)_{t\\geq 0}$ is the solution to the SDE of the original post, i.e. $$ X_t=\\int_0^t \\sigma(X_s) dB_s,\\quad t\\geq 0, $$ then $(X_t)$ is adapted and continuous and hence it is a predictable process. The theorem now yields that $(X_t)_{t\\geq 0}\\in \\mathcal{H}^2$ if and only if $$ E\\left[\\int_0^t \\sigma(X_s)^2 d \\langle B\\rangle_s\\right]=E\\left[\\int_0^t \\sigma(X_s)^2 ds\\right]=\\int_0^t E\\left[\\sigma(X_s)^2\\right] ds<\\infty $$ holds for all $t\\geq 0$. Using the Lipschitz assumption we get a sufficient condition for $(X_t)$ being a square integrable martingale: $$ \\int_0^t E[|X_s|]ds<\\infty, \\quad t\\geq 0. $$\n\nshare|improve this answer\nadd comment\nup vote 0 down vote accepted\n\n\n$$[X]_t = \\int_0^t\\sigma(X_u)^2du,$$\n\n\n$$\\begin{align} \\mathbb{E}([X]_t) \\le \\int_0^t \\mathbb{E}\\left[(x_0 + K|X_u-x_0|)^2\\right]du.\\\\ \\end{align} $$\n\n$X$ is locally bounded in $L^2$. See, for example, Karatzas and Shreve equation 5.2.15 (p. 289). So it follows easily that $\\mathbb{E}([X]_t)<\\infty$, for each $t$. Hence $X$ is a martingale.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232634/a-question-about-fourier-transform/232707\nText:\nTake the 2-minute tour \u00d7\n\nI just don't know how to calculate the the fourier transform of $1/(1+x^2)$.Can you help me guys? Thx\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nYou need to use the duality property of the Fourier transform:\n\nTheorem: Let $\\hat{f}(w) = $$\\mathcal{F}[f(t)]$, then the following duality property holds:\n\n$$\\mathcal{F} \\, \\big [\\hat{f}(t) \\big ] = 2 \\pi f(-w).$$\n\nSo, look at your table and see this convenient identity:\n\n$$\\mathcal{F} \\, \\Big [\\frac{1}{2a}e^{-a|t|} \\Big ] = \\frac{1}{a^2 + w^2}.$$\n\nNow apply the duality property:\n\n$$\\mathcal{F} \\, \\Big [ \\frac{1}{a^2 + t^2} \\Big ] = \\frac{\\pi}{a} e^{-a|w|}$$\n\nThen, the answer to your question is:\n\n$$\\mathcal{F} \\, \\Big [ \\frac{1}{1 + t^2} \\Big ] = \\pi e^{-|w|}.$$\n\nshare|improve this answer\nI got , THANK YOU VERY MUCH \u2013\u00a0 dbzhu Nov 8 '12 at 8:12\nIf my answer was helpful, then please upvote/accept it. Thanks. \u2013\u00a0 Charles Boyd Nov 8 '12 at 9:13\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/112411/solving-the-system-sum-sin-sum-cos-0/113612\nText:\nTake the 2-minute tour \u00d7\n\nCan we solve the system of equations:\n\n$$\\sin \\alpha + \\sin \\beta + \\sin \\gamma = 0$$\n\n$$\\cos \\alpha + \\cos \\beta + \\cos \\gamma = 0$$\n\n\n(i.e. find the possible values of $\\alpha, \\beta, \\gamma$)\n\nshare|improve this question\nadd comment\n\n5 Answers\n\nup vote 11 down vote accepted\n\nTry something similar to what has been posted yet. Take one variable to the other side, then square and add the equations. What you get is $\\alpha-\\beta=120\u00b0$ and same for cyclic permutations (or negating all angles). The solutions is the three angles $\\delta$, $\\delta+120\u00b0$, $\\delta-120\u00b0$ (arbitrary $\\delta$) in any order.\n\nEDIT: Or simply realize that the equations are equivalent to $\\exp(i\\alpha)+\\exp(i\\beta)+\\exp(i\\gamma)=0$ which make the answer immediately obvious.\n\nshare|improve this answer\nadd comment\n\nDeveloping on Gerenuk's answer, you could consider the complex numbers\n\n$$ z_1=\\cos \\alpha+i\\sin \\alpha,\\ z_2=\\cos \\beta+i\\sin\\beta,\\ z_3=\\cos \\gamma+i\\sin \\gamma$$\n\nThen you know that $z_1,z_2,z_3$ are on the unit circle, and the centroid of the triangle formed by the points of afixes $z_i$ is of afix $\\frac{z_1+z_2+z_3}{3}=0$. From classical geometry, we can see that if the centroid of a triangle is the same as the center of the circumscribed circle, then the triangle is equilateral. This proves that $\\alpha,\\beta,\\gamma$ are of the form $\\theta,\\theta+\\frac{2\\pi}{3},\\theta+\\frac{4\\pi}{3}$.\n\nshare|improve this answer\nadd comment\n\nTry writing $$ \\sin^2(\\alpha)=(\\sin(\\beta)+\\sin(\\gamma))^2=\\sin^2(\\beta)+\\sin^2(\\gamma)+2\\sin(\\beta)\\sin(\\gamma)\\tag{1} $$ and $$ \\cos^2(\\alpha)=(\\cos(\\beta)+\\cos(\\gamma))^2=\\cos^2(\\beta)+\\cos^2(\\gamma)+2\\cos(\\beta)\\cos(\\gamma)\\tag{2} $$ then add $(1)$ and $(2)$ to get $$ 1=1+1+2\\cos(\\beta-\\gamma)\\tag{3} $$ which means $\\cos(\\beta-\\gamma)=-\\frac12$. The same is true for the other pairs, so we get that each of $\\alpha$, $\\beta$, and $\\gamma$ differ from each other by $\\frac{2\\pi}{3}$, which is the same answer that was achieved using complex means already.\n\nshare|improve this answer\nNice Answer without complex numbers. \u2013\u00a0 user21436 Feb 26 '12 at 15:25\nadd comment\n\nHere's an algebraic proof : Write $z_k = e^{i \\alpha_k}$. Then your equations are equivalent to $z_1 + z_2 + z_3 = 0$. Write $\\theta = \\frac{\\alpha_1 + \\alpha_2 + \\alpha_3}{3}$ and $z = e^{i \\theta}$\n\nExpand the polynomial $P = (X-z_1)(X-z_2)(X-z_3)$. The $X^2$ term is $0$ by hypothetis, and the $X$ term can be written as $z_1 z_2 z_3 (z_1^* + z_2^* + z_3^*) = 0$. So $P = X^3 - z_1 z_2 z_3 = X^3 - z^3$. So the roots are $z . e^{2i k \\pi /3}$.\n\nshare|improve this answer\nadd comment\n\nMore of a comment and less of an answer!\n\nWell, your information seems to tell us that,\n\n\n(To see this, square both equalities and add.)\n\nI don't see any other obvious thing, you can do with these equations. If any thought plops up, I will type it in here.\n\nshare|improve this answer\nYour relation should be with $\\alpha-\\beta,\\beta-\\gamma$ and $\\gamma-\\alpha$ \u2013\u00a0 Beni Bogosel Feb 23 '12 at 17:58\n@BeniBogosel I am sorry for having made that blunder. Thanks for the pointer. That the answer has posted, I'll flag it for the moderator to make it CW. \u2013\u00a0 user21436 Feb 24 '12 at 8:01\nYour result follows from my answer which shows that $$\\cos(\\alpha-\\beta)=\\cos(\\beta-\\gamma)=\\cos(\\gamma-\\alpha)=-\\frac12$$ \u2013\u00a0 robjohn Feb 26 '12 at 23:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/208851/need-a-tip-hint-evaluating-a-limit?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have the following limit:\n\n\nwhere $0<b<a$.\n\nI care for the case where $\\epsilon>-1/2$. I suspect that for $\\epsilon>0$ this limit evaluates to 1, and for $-1/2<\\epsilon\\leq0$ it evaluates to 0. However, I am having hard time evaluating this. I have tried taking the log of the expression (moving the $x$ in the exponent down), substituting $y=1/x$ and then Taylor-expanding the log, but didn't get anywhere.\n\nDoes anyone have any tips/hints that might help me evaluate this?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nSince $c=1/2+\\varepsilon\\gt0$, one knows that $1-\\exp(-bx^{-c})\\sim bx^{-c}$ and $\\log(ax^{-c})\\sim-c\\log(x)$ when $x\\to+\\infty$. Thus, the function to be evaluated is $$ f(x)=(1-kg(x))^x,\\quad k=abc\\gt0,\\quad g(x)\\sim x^{-2c}\\log x. $$ Since $g(x)\\to0$ and $\\log(1+u)\\sim u$ when $u\\to0$, $$ f(x)=\\exp\\left[x\\log(1-kg(x))\\right]=\\exp\\left[-kxg(x)\\cdot(1+o(1))\\right]. $$ Note that $xg(x)\\sim x^{-2\\varepsilon}\\log x$ and recall that $k\\gt0$. This yields:\n\n  \u2022 If $-1/2\\lt\\varepsilon\\leqslant0$, then $xg(x)\\to+\\infty$ hence $f(x)\\to0$ when $x\\to+\\infty$.\n  \u2022 If $\\varepsilon\\gt0$, then $xg(x)\\to0$ hence $f(x)\\to1$ when $x\\to+\\infty$.\nshare|improve this answer\nSo it turns out I made a mistake in the original definition of the problem: I flipped the plus sign after the first 1 to a minus sign when I was typing this up (I've edited the question since I saw your answer and my mistake). However, you solved the problem that I originally had in mind (otherwise the minus in $-c\\log(x)$ would've flipped the minus in your re-definition of $f(x)=(1-kg(x))^x$ to a plus). Thank you, this confirms my intuition (which was backed up by numerical evaluations)! \u2013\u00a0 M.B.M. Oct 8 '12 at 5:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/342001/combinatorics-riddle-keys-and-a-safe\nText:\nTake the 2-minute tour \u00d7\n\nThere are 8 crew members, The leading member wants that only a crew of 5 people or more could open a safe he bought, To each member he gave equal amount of keys, and locked the safe with several locks.\n\nWhat's the minimal number of locks he should put:\n\n  1. at least 5 crew members would be required to open the safe?\n  2. Any team of 5 crew members could open the safe, but none of the 4 team crew members.\n\n1,2 stands individually of course.\n\nshare|improve this question\nCan any key open any lock? Can each lock have multiple keys? Can a key open different types of locks? \u2013\u00a0 Ian Coley Mar 26 '13 at 19:11\nI suspect each person can open some subset of the locks, essentially. It's not clear if the \"leading member\" is counted in the crew, but I'm assuming he is. \u2013\u00a0 Thomas Andrews Mar 26 '13 at 19:13\nWhat's the common source of this kind of problems? math.stackexchange.com/questions/323694/how-many-keys-and-locks \u2013\u00a0 Andreas Caranti Mar 26 '13 at 19:19\nI think we may not be able to give a 'minimal number'. For instance, if we give each crew member one key and put 5 locks on the door, then we're done. But that's not gonna be the best way to think about it. \u2013\u00a0 Ian Coley Mar 26 '13 at 19:20\nWell, key is suited into an individual lock. Thing is, You can copy a key and send it to different key members. \u2013\u00a0 StationaryTraveller Mar 26 '13 at 19:24\nshow 3 more comments\n\n2 Answers\n\nup vote 2 down vote accepted\n\nConsider the general case that $n$ people know certain secrets such that no subset of $k$ of them know all secrets, but any subset of $k+1$ of them do know all secrets. (Here $n=8$, $k=4$, secrets are locks, and knowing a secret is having a key.)\n\nThis can be done using $\\binom nk$ secrets, each labelled by a different subset of $k$ among the $n$ people, which is the set of people that does not get to know that secret (everyone else does). Then for any subset of $k$ people the corresponding secret will not be known by them, but for any set of $k+1$ people and any secret there is at least one of them who knowns the secret.\n\nTo show one cannot do with less secrets, consider any solution to this problem, and the relation between on one hand the $\\binom nk$ subsets of $k$ people and on the other hand the secrets, defined by none of those people knowing the secret. This relation is \"one to at least one\": it is required that any set of $k$ people not know at least one secret, and if two different subsets of $k$ people do not know the same secret, then the union of those subsets, which contains at least $k+1$ people would not know that secret, and hence not all secrets, which is against the requirement. The relation is in fact a surjective map from secrets to $k$-subsets, so there are al least $\\binom nk$ secrets.\n\nshare|improve this answer\nThanks, Nice clarification . \u2013\u00a0 StationaryTraveller Mar 27 '13 at 10:24\nadd comment\n\nThis can easily be generalized, replacing 8 and 4 with a variable each.\n\nLet the set of keys (and locks) be denoted by $K$. Let the set of keys that crew member $i$ doesn't receive be $K_i$.\n\nFor distinct indices, Condition 1 states that $K_{ijkl} = K_i \\cap K_j \\cap K_k \\cap K_l \\neq \\emptyset$ (no 4 crew can open the safe), and condition 2 states that $K_i \\cap K_j \\cap K_k \\cap K_l \\cap K_m = \\emptyset$ (any 5 crew can open the safe).\n\nClaim: $ K_{ijkl} \\cap K_{i'j'k'l'} = \\emptyset$ for distinct quadruple sets.\n\nProof: Suppose not. Then $\\{i, j, k, l, i', j', k', l'\\}$ is a set with at least 5 distinct elements, contradicting condition 2. $_\\square$\n\nHence, there must be at least $8 \\choose 4$ locks.\n\nClaim. $8 \\choose 4$ is sufficient.\n\nProof: Label each of the locks with a distinct quadruple from 1 to 8. To each crew member, give him the key to the lock, if it doesn't have his number on it. Then, any 4 crew members $i, j, k, l$ will not be able to open lock $\\{i, j, k, l\\}$. Any 5 crew members will be able to open all locks.\n\nshare|improve this answer\nThank you, Nice answer. \u2013\u00a0 StationaryTraveller Mar 27 '13 at 10:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122257/finding-the-formula-for-bezier-curve-ratios-hull-point-point-baseline\nText:\nTake the 2-minute tour \u00d7\n\nGiven a cubic Bezier curve defined by points p\u2081, p\u2082, p\u2083, and p\u2084, a point B on that curve at some t value (where 0 \u2264 t \u2264 1), a point A on the line (p\u2082p\u2083) at distance ratio t from p\u2082, and a point C that is the intersection of the line (p\u2081p\u2084) and the line that goes through A and B, the ratio between distance d1 = (AB) and d2 = (BC) is a fixed value, regardless of the values for coordinates p\u2081, p\u2082, p\u2083, and p\u2084\n\nI'd like to find the formula that expresses this ratio as a function of t (all interactive graphing experiments suggest that this function is an identity function for cubic Bezier curves, not actually being dependent on the coordinates used for the curve) but I'm having little success coming up with something satisfactory. My math skills are not sufficient...\n\nI initially wrote up a quick data-generator using the \"Processing\" programming language to see if I could use that data for polynomial regression (based on the fact that the function is symmetrical around t = 0.5, finding the expression for the interval t=0.5 to t=1), but the fact that the ratio is actually asymptotic at t = 0 and t = 1 (towards positive infinity) means that it's not a straight-forward power function.\n\ncurve parameter -> ratio plot.\n\n(note: the jsfiddle link doesn't actually log all 5000 step values; normal Processing does)\n\nWould anyone know how to express this ratio function as a proper formula? I don't quite know how to approach this symbolically, as I'm using de Casteljau's algorithm to determine my red and green lines; since I don't know how to symbolically express the values d1 and d2, expressing the ratio d1/d2 as a function is quite hard.\n\nN.B.: Apologies if the tags don't fit the question. I'll take suggestions on using the right ones instead; first question on MathOverflow.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nA cubic bezier defined by $p_1, p_2, p_3, p_4$ has parametric equation $$B(t) = (1-t)^3p_1 + 3(1-t)^2tp_2 + 3(1-t)t^2p_3 + t^3p_4.$$\n\nThe setup here also defines $A(t) = (1-t) p_2 + tp_3$.\n\nThe way $C$ is defined, there are some real $s(t)$ and $u(t)$, both possibly depending on $p_1,\\ldots,p_4$ such that $C = sA + (1-s)B = up_1 + (1-u)p_4$.\n\nSo $B - C = B - sA - (1-s)B = s(B-A)$. Hence $\\frac{|B - C|}{|A - B|} = |s|$.\n\nOn the other hand, we want $sA + (1-s)B - up_1 - (1-u)p_4 = 0$. That comes out to\n\n$$((1-s)(1-t)^3 - u)p_1 + (s(1-t) + 3(1-s)t(1-t)^2)p_2 + (st + 3(1-s)t^2(1-t))p_3 + ((1-s)t^3 - (1-u))p_4 = 0.$$\n\nSet $$s = \\frac{t^3+(1-t)^3-1}{t^3 + (1-t)^3}$$ and $$u = \\frac{(1-t)^3}{t^3 + (1-t)^3}.$$\n\nThen the coefficents of $p_1,\\ldots,p_4$ in the above expression become identically 0. Note that the denominators of these expressions are never 0 for $t \\in [0,1]$, so the divisions are ok.\n\nSo your ratio is given by the $|s|$ above (or its reciprocal, depending on how you're taking the ratio).\n\nshare|improve this answer\nyou are a hero, thanks! \u2013\u00a0 Mike 'Pomax' Kamermans Feb 19 '13 at 18:34\nadd comment\n\nJust in case someone finds this question using google at some point, and is also curious about the solution for the quadratic case, its solution is similar:\n\n$A(t) = p_2$\n\n$B(t) = (1-t)^2p_1 + 2t(1-t)p_2 + t^2p_3$\n\n$C(t) = sA(t) + (1-s)B(t) = up_1 + (1-u)p_2$\n\nThis requires solving:\n\n$$sp_2 + (1-s)((1-t)^2p_1 + 2t(1-t)p_2 + t^2p_3) - up_1 + (1-u)p_2 = 0$$\n\nwhich, expressed in terms of the control points, is:\n\n$$((1-s)(1-t)^2 - u)p_1 + (s+2t(1-s)(1-t))p_2 + ((1-s)t^2 + u - 1)p_3 = 0$$\n\nIf we want these coefficients to become identically zero, we can determine s(t):\n\n$$(1-s)(1-t)^2 = u = -((1-s)t^2 - 1)$$\n\nwhich means solving:\n\n$$(1-s)(1-t)^2 + ((1-s)t^2 - 1) = 0$$\n\nwhich gives us the following expressions for s and u (after substituting s into either of the identities for u and solving):\n\n$$s(t) = \\frac{2t^2 - 2t}{2t^2 - 2t + 1}$$\n\n$$u(t) = \\frac{(t-1)^2}{2t^2 - 2t + 1}$$\n\n(Also note that there are no solutions for curves of order 4 and higher; unlike for quadratic and cubic curves, the ratio between the two distances is not a fixed value for higher order curves, unfortunately)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/351623/does-an-mid-bn-imply-a-mid-b\nText:\nTell me more \u00d7\n\nDoes $a^n \\mid b^n$ imply $a\\mid b$? I think it does but haven't been able to prove it. I don't know much number theory so an elementary answer would be great.\n\nshare|improve this question\nHint: Look at prime factors. \u2013\u00a0 Brett Frankel Apr 5 at 0:29\nYou can start with the fundamental theorem of arithmetic. \u2013\u00a0 julien Apr 5 at 0:30\nConsider this. Might I call yhis a duplicate? Since they end up in asking the same question. \u2013\u00a0 awllower Apr 5 at 13:32\n@awllower: you're right that it's a duplicate, but I think this one has better answers. \u2013\u00a0 Javier Badia Apr 5 at 14:16\n@JavierBadia Probably because the previous one prohibited the use of GCD and UFD. \u2013\u00a0 awllower Apr 5 at 15:01\nadd comment\n\n3 Answers\n\nup vote 6 down vote accepted\n\nIf you can assume the fundamental theorem of arithmetic (that each integer has a unique factorization in prime numbers), you can write: $$ \\begin{align*} a &= p_1^{e_1} p_2^{e_2} \\ldots p_r^{e_r} \\\\ b &= q_1^{d_1} q_2^{d_2} \\ldots q_s^{d_s} \\end{align*} $$ Here the $p_i$, $q_i$ are primes, and $e_i$ and $d_i$ are all greater than 0. If $a^n \\mid b^n$, then $p_i^{n e_i}$ must have a counterpart in a $q_j^{n d_j}$, in that $p_i = q_j$ and $n e_i \\le n d_j$, so it must then also be that $e_i \\le d_j$; and this means $a \\mid b$.\n\nshare|improve this answer\nadd comment\n\nHint $\\ $ Either examine exponents in unique prime factorizations, or, by the Rational Root Test, the reduced rational root $\\rm\\:x = b/a\\:$ of $\\rm\\:x^n = c\\in\\Bbb Z\\:$ must be integral, so $\\rm\\:b/a\\in\\Bbb Z\\:\\Rightarrow\\:a\\mid b.$\n\nshare|improve this answer\n@Peter For that, after cancelling any common factor, one needs only $\\rm\\:(a,b)=1\\:\\Rightarrow\\:(a,b^n)=1,\\:$ true by iterating Euclid's Lemma. Thus $\\rm\\:1 < a\\nmid b^n,\\:$ so $\\rm\\:a^n\\nmid b^n.\\ \\ $ \u2013\u00a0 Math Gems Apr 5 at 0:41\nYes, that was my idea. I was awfully unclear, sorry. \u2013\u00a0 Pedro Tamaroff Apr 5 at 0:44\nadd comment\n\nHint: $p$ is a prime factor of $k$ if and only if $p^n$ is a factor of $k^n$. This holds for any prime $p$, integer $k$, and positive integer $n$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/63491.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nMean Latitude/Longitude\n\nDate: 07/10/2003 at 14:21:30\nFrom: Peter Richard\nSubject: Spherical Trigonometry\n\nIf we have three points on the earth measured in latitude/longitude, \nsuch as 'A'= 33S54;151E12 / 'B'= 37S49;144E58 / 'C'= 51N30;0W10 \nwhat is the formula to calculate a mean latitude/longitude for this \ngroup of 3?\n\nWhen I say 'mean latitude/longitude' I am referring to a 'midpoint in \nspace' between the three. So perhaps if I used the term 'equidistant' \nrather than 'mean' it might make it clearer.\n\nDate: 07/15/2003 at 14:47:57\nFrom: Doctor Rick\nSubject: Re: Spherical Trigonometry\n\nHi, Peter.\n\nI might approach this as follows: \n\nConvert the lat-long positions into x,y,z coordinates, find the mean \nposition in 3-dimensional space, and project this point back onto the \nsphere, and convert back to latitude and longitude. (I am assuming - \nand hoping - that a spherical approximation to the earth's surface \nis sufficient.)\n\nThis method will give the correct result in the \"flat-earth \napproximation\" in which the points are close enough together that the \ncurvature of the earth can be ignored. It seems like a reasonable \noperational definition of an average position on the earth, but I'm \nbeing rather intuitive at this point.\n\nTo convert each location to (x,y,z) coordinates, use the formulas\n\n  x_n = cos(lat_n)*cos(lon_n)\n  y_n = cos(lat_n)*sin(lon_n)\n  z_n = sin(lat_n)\n\nwhere location n has latitude lat_n and longitude lon_n. I have set \nthe radius of the earth equal to 1 since we aren't interested in \nactual distances; the radius would cancel out eventually anyway.\n\nAverage the coordinates independently:\n\n  x = (x_1 + x_2 + x_3)/3\n  y = (y_1 + y_2 + y_3)/3\n  z = (z_1 + z_2 + z_3)/3\n\nNow convert to latitude and longitude using the inverse transformation\n\n  lat = arcsin(z/r)\n  lon = arctan(y/x)\n\nI haven't tested this, so let me know if you have any trouble with \nit. If you're programming, you should use the atan2() function found \nin many programming languages, spreadsheets etc. Otherwise you'll \nhave to do some extra stuff if x = 0 or if the longitude is more than \n90 degrees from the Prime Meridian.\n\nThe \"mean\" in any ordinary sense can be quite different from the \npoint that is equidistant from three points. To demonstrate, draw a \ncircle and pick three points on the circle, all on the right side. \nThe point that is equidistant from the three points is the center of \nthe circle. I doubt that this is what you mean by \"mean\"! (However, \nit could be what you want: If you expect a structure to be circular \nand you have found three points on the edge of the structure, you \ncould use such a method to find the center of the structure.)\n\n- Doctor Rick, The Math Forum\nAssociated Topics:\nHigh School Higher-Dimensional Geometry\nHigh School Trigonometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/36851/how-many-permutations-of-a-word-do-not-contain-consecutive-vowels/36854\nText:\nTake the 2-minute tour \u00d7\n\nThe word is \"ENGINEERING\".\n\nThe number of ways that the consonants can be ordered is 6! / 3!2!\n\nThe number of ways that the vowels can be ordered is 5! / 3!2!\n\nBut how would I determine how many ways vowels can be ordered so that they are not next to each other?\n\nshare|improve this question\nThink of using the vowels as separators, and thus you'll have 6 bins to place 6 consonants. Then you need to place a consonant between each spacer, and you'll be left with 2 consonants to place in any of the 6 bins. And of course take into account the double letters. \u2013\u00a0 Nicolas Villanueva May 4 '11 at 3:19\nI slightly edited as the capital letters were really offensive on the front page. \u2013\u00a0 Asaf Karagila May 4 '11 at 7:02\nIf your question has been answered satisfactorily, you should upvote and accept the answer so that it doesn't keep popping up in the frontpage unnecessarily. \u2013\u00a0 svenkatr May 5 '11 at 16:29\nadd comment\n\n2 Answers\n\nup vote 7 down vote accepted\n\nImagine that you arrange the consonants first. There are six consonants which you can arrange in $6!/(3!2!)$ ways.\n\nNow there are 7 spaces for the 5 vowels to go into but only one vowel can go into each space. So you choose 5 of the 7 available spaces and put a permutation of the vowels into these spaces.\n\nTotal number of arrangements with no consectutive vowels $= 6!/(3!2!) \\times 5!/(3!2!) \\times \\binom{7}{5}$.\n\nshare|improve this answer\nHow do you know that there are 7 spaces for the 5 vowels to go in? \u2013\u00a0 Krysten May 4 '11 at 3:38\n@krysten - You know that the consonants have to separate the vowels. Counting one space in front of the consonants, one at the end and the five in the middle gives us 7 seven spaces. For example, look at .N.G.N.R.N.G. which is an arrangement of consonants with the dots representing places where vowels can go. There are seven dots, which are the seven places where a vowel can go into. \u2013\u00a0 svenkatr May 4 '11 at 3:42\nalright thanks. \u2013\u00a0 Krysten May 4 '11 at 3:53\nadd comment\n\n(edit: Answer has been updated to include four missed combinations and the fact that permutations are not considered unique if their spelling matches that of another permutation.)\n\n12345678901  (11 letters in ENGINEERING)\nC.C.C.C.C.C (alternating sequence, bounded on both sides by C)\n.C.C.C.C.CC  (start single consecutive C pair, one end bounded by C)\nC.C.C.C.CC. (count: 10)\n.CC.CC.C.C. (start double consecutive C pair)\n.C.C.CC.CC. (count: 6)\n.CCC.C.C.C. (start triple C string)\n.C.C.C.CCC. (count: 4)\n\nIn all of these formats, there are 6!/(3!2!) ways to order the C's (i.e. consonants) and 5!/(3!2!) ways to order the .'s (i.e. vowels,) so there should be (21)(6!/3!2!)(5!/3!2!), or 12,600, permutations in which there are no adjacent vowels.\n\nshare|improve this answer\nI forgot one possible combination: C1 C2 V1 C3 V2 C4 V3 C5 V4 C6 V5. I went back and edited the post, bringing the total up to (17)6!5!. \u2013\u00a0 Michael May 4 '11 at 3:48\n@Michael - your starting count of $6!5!$ is wrong because there are repeating vowels and consonants. Also, I don't see how you can get a factor of 17. I suspect you have made a mistake when you manually count the possible arrangements. \u2013\u00a0 svenkatr May 4 '11 at 3:53\n@Michael - That's a very interesting way to look at it. I guess if all else fails you can just look at all the different possibilities. However, I believe the answer is 12,600. \u2013\u00a0 Krysten May 4 '11 at 3:55\n@svenkar I made a prettier version of it, showing all 17 formats that the vowels and consonants can follow. If you can find anything wrong with the formats, please explain! \u2013\u00a0 Michael May 4 '11 at 4:07\n@Krysten I've noticed a problem! The subject/title of this question is \"How many permutations of ENGINEERING do not contain consecutive vowels,\" which is the question that I answered. This, however, does not match up with the question that you ask in the body of your post, which asks, \"how would I determine how many ways vowels can be ordered so that they are not next to each other?,\" which I find to be both ambiguous and quite different than the subject/title. \u2013\u00a0 Michael May 4 '11 at 4:08\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/41318/probability-of-achieving-a-given-density-of-iid-random-variables\nText:\nTake the 2-minute tour \u00d7\n\nI have a sequence of IID random variables $X_1, X_2, \\dots, X_n$. In this particular case, each of the variables is L\u00e9vy distributed with PDF\n\n$f(x) = (\\lambda / 2 \\pi x^3)^{-1/2} \\exp(-\\lambda/2x)$\n\nfor $x > 0$, and $f(x) = 0$ otherwise.\n\nI'm trying to find the probability, given constants $\\tau > 0$ and $b < n$, that there exists an interval of length $\\tau$ which contains at least $b$ of the $n$ random variables.\n\nMy first approach was to use order statistics; for example, if $X_{(1)}, X_{(2)}, \\dots, X_{(n)}$ are the order statistics, the probability that the $b$ smallest fall in an interval of length $\\tau$ could be found using the joint distribution of $X_{(1)}$ and $X_{(b)}$. From the Wikipedia article,\n\n\nThis could then be integrated over the simplex $0 \\leq x \\leq y \\leq x + \\tau$, and the result could be repeated for each group of $b$ random variables and summed. However, I feel that this approach leads to double counting (for example, both $X_{(1)} \\dots X_{(b)}$ and $X_{(n-b+1)} \\dots X_{(n)}$ could fall in disjoint intervals of length $\\tau$) and also seems to be difficult to obtain in closed form.\n\nThe other approach I considered was to use the joint density of all order statistics:\n\n$f_{X_{(1)},\\ldots,X_{(n)}}(x_1,\\ldots,x_n)\\,dx_1\\cdots dx_n=n!f_X(x_1)\\cdots f_X(x_n)\\,dx_1\\cdots dx_n$\n\nHowever, I can't determine how to express the region of integration in any meaningful way. Any thoughts or pointers would be appreciated!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe nonexistence of such interval is equivalent to $X_{(i+b-1)} > X_{(i)}+r$ for $i=1\\ldots n-b+1$. So for the probability of the complement of your event, integrate $n! f(x_1) \\ldots f(x_n)$ over the region defined by $$ x_{b-1} > x_{b-2}> \\ldots >x_2 > x_1>0 $$ and $$ x_b > \\max(x_{b-1}, x_1 + r), \\ldots, x_n > \\max(x_{n-1}, x_{n-b+1} + r). $$\n\nshare|improve this answer\nThanks, that makes a lot of sense. This helps when using numerical approximations, but the bounds don't seem to lead to a closed form solution - I suppose this is unlikely anyways. \u2013\u00a0 sciyoshi May 25 '11 at 18:19\nadd comment\n\nAs said before, there is no simple closed form solution. But one can prove some upper and lower bounds, which yield a precise value in a semi-explicit range of values of $b$, $n$ and $\\tau$.\n\nWe start with some notations. For $x\\le y$, call $g(x,y)=P(x\\le X_1\\le y)$ the integral of the density function $f$ of $X_1$ from $x$ to $y$. For any subset $I$ of $\\{1,2,\\ldots,n\\}$ of size $b$, call $A_I=[R_I\\le\\tau]$ where $R_I$ is the range of the sample $(X_k)$ over $I$, that is, $$ A_I=[R_I\\le\\tau],\\qquad R_I=\\max\\{X_k;k\\in I\\}-\\min\\{X_k;k\\in I\\}. $$ Using the fact that the event $[x\\le\\min\\{X_k;k\\in I\\},\\max\\{X_k;k\\in I\\}\\le y]$ has probability $g(x,y)^b$, one sees that $P(A_I)=\\alpha_b$ for every $I$ of size $b$, with\n\n$$ \\alpha_b=\\int bf(x)g(x,x+\\tau)^{b-1}\\mathrm{d}x. $$\n\nThe event $A$ that there exists an interval of length (at most) $\\tau$ which contains (at least) $b$ values from the sample of size $n$ is $$ A=\\bigcup_IA_I,\\quad A_I=[R_I\\le\\tau], $$ where the union is over the subsets $I$ of $\\{1,2,\\ldots,n\\}$ of size $b$. By the inclusion-exclusion principle, $$ S-S'\\le P(A)\\le S,\\quad S=\\sum_{I}P(A_I),\\ S'=\\sum_{I\\ne J}P(A_I\\cap A_J). $$ For every $I$ of size $b$, $P(A_I)=\\alpha_b$. For every $I\\ne J$ of size $b$, $A_I$ and $A_J$ are independent if $I\\cap J=\\emptyset$ and positively correlated otherwise, hence $P(A_I\\cap A_J)\\ge \\alpha_b^2$. Finally,\n\n$$ {n\\choose b}\\alpha_b-\\frac12\\left({n\\choose b}^2-{n\\choose b}\\right)\\alpha_b^2\\le P(A)\\le{n\\choose b}\\alpha_b. $$\n\nThis reads approximately as $p-\\frac12p^2\\le P(A)\\le p$ with $p=\\displaystyle{n\\choose b}\\alpha_b$ hence this estimation of $P(A)$ is as precise as the upper bound $p$ is small.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/25874/what-is-the-minimal-size-of-a-partial-order-that-is-universal-for-all-partial-or\nText:\nTake the tour \u00d7\n\nA partial order $\\mathbb{B}$ is universal for a class $\\cal{P}$ of partial orders if every order in $\\cal{P}$ embeds order-preservingly into $\\mathbb{B}$.\n\nFor example, every partial order $\\langle\\mathbb{P},\\lt\\rangle$ maps order-preservingly into its power set by the map $$p\\mapsto\\{q\\in\\mathbb{P}\\mid q\\leq p\\}$$ that sends each element $p$ to its lower cone.\n\nThus, the power set order $\\langle P(\\{1,2,\\ldots,n\\}),{\\subseteq}\\rangle$ is universal for the class of partial orders of size $n$. This provides an order of size $2^n$ that is universal for orders of size $n$.\n\nQuestion. What is the minimal size of a partial order that is universal for orders of size $n$?\n\nIn particular, is there a polynomial upper bound?\n\nOne can make at least slight improvements to the $2^n$ upper bound, by observing that the emptyset was not needed, as it never arises as a lower cone, and we don't need all the atoms, since if they are needed, then one can use the co-atoms instead. I suspect that there is a lot of waste in the power set order, but the best upper bound I know is still exponential.\n\nFor a lower bound, my current knowledge is weak and far from exponential. Any order that is universal for orders of size $n$ will contain a chain and an antichain, making it have size at least $2n-1$. (That bound is exact for $n\\leq 3$.) A student in my intro logic course extended this to $n\\log(n)$ by considering $k$ chains (and antichains) of size $n/k$.\n\nCan one find better lower bounds?\n\nInterestingly, the same student observed that we cannot in general expect to find unique smallest universal orders, since he found several orders of size 5 that are universal for orders of size 3 and which are minimal with that property. So in general, we cannot expect a unique optimal universal order. Does this phenomenon occur for every $n$? (He also found minimal universal orders of size larger than the minimal size universal order.)\n\nshare|improve this question\nNeat question. I guess the logic tag is because it came up in your logic class? \u2013\u00a0 Pete L. Clark May 25 '10 at 13:58\nThe concept of universal structures is important in model theory and used in set theory (although usually for infinite structures). Also, the easiest way to show that every countable partial order embeds into the Turing degrees is to consider orders that are universal for countable orders (and there are countable such orders). For the warm-up to that theorem, we first embedded the finite powersets into the Turing degrees, and then concluded that all finite orders embed by universality. \u2013\u00a0 Joel David Hamkins May 25 '10 at 14:09\nCorrection: my student's lower bound is $n\\log(n)-n$. \u2013\u00a0 Joel David Hamkins May 25 '10 at 14:41\nadd comment\n\n2 Answers\n\nDenote by $F(n)$ the number of different partial orders on the set of cardinality $n$. Then the minimal size $N$ of a partial order that is universal for orders of size $n$ satisfies $\\binom{N}{n}\\geq F(n)$ (that's captain obvious advice, yes). Since $\\log F(n)$ behaves like $cn^2$ (the lower estimate, which we need, is proved as follows: take $n/2$ blue elements and $n/2$ red elements, then decide for each pair of red and blue elements $r_i$, $b_j$, whether $r_i > b_j$ or not. We get $2^{n^2/4}$ patial orders, each isomorphism class is counted at most $n!$ times). So, $N^n> \\binom{N}{n}\\geq F(n)$, taking logarithms we get $n\\log N > cn^2$, so $N$ should grow at least exponentially.\n\nshare|improve this answer\nThanks very much for this excellent answer! I appreciate it very much. Could I ask kindly whether you might carry your argument through to the conclusion of an explicit lower bound? \u2013\u00a0 Joel David Hamkins May 25 '10 at 17:46\nOf course, but if you carry on the sharp constant in the exponent, I have to think bit more:) Now the lower estimate is $2^{n/4+o(n)}$ . But I suppose that calculating the best constant is very hard, similar to Ramsey numbers precise asymptotics. \u2013\u00a0 Fedor Petrov May 25 '10 at 20:13\nadd comment\n\nThere does not exist a polynomial upper bound.\n\nLet $P_n$ be the number of partial orders on $n$ elements. It is know that $P_n \\geq 2^{n^2/4}$. Thus, any method of uniquely representing the partial orders on $n$ elements, say in binary, will require at least $log_2(2^{n^2/4}) = O(n^2)$ bits.\n\nNow assume that for every $n$ there is a partial order on $n^k$, or fewer, elements, where $k$ is a constant, that is universal for the class of partial orders on $n$ elements. Fix some canonical ordering of the partial orders and let $U(n)$ be the first universal partial orders on $n^k$, or fewer elements.\n\nLabel each of the elements in $U(n)$ with a unique number from $1$ up to $log_2(f(n)) = O(log(n))$ in some fixed canonical way. Now each partial order on $n$ elements can be uniquely described by writing down for each element that elements corresponding label in $U(n)$. This takes $O(nlog(n))$ bits. However; this representation is not quite complete, as it seems to require the description of $U(n)$ to actually reconstruct a partial order given its representation in this form.\n\nHowever, since $U(n)$ is the first universal partial order on $n^k$ or fewer elements, rather than appending an encoding of $U(n)$ to each partial order directly we can instead append an encoding of the following Turing machine $M$. $M$ takes in three arguments $n$, $i$ and $j$ and accepts if element $i$ is less than element $j$ in $U(n)$ and rejects otherwise. Given such a Turing machine we can clearly reconstruct the partial order. $M$ simply enumerates all partial orders of size between $n$ and $n^k$ and stops at the first partial order that is universal for all partial orders on $n$ elements. It then labels the elements of $U(n)$ in the canonical manner and accepts if the element labeled $i$ in $U(n)$ is less than the element labeled $j$ in $U(n)$. This TM has constant size.\n\nWe can thus uniquely and completely represent all partial orders on $n$ elements by $O(nlog(n)) + O(1) = O(nlog(n))$ bits, which is a contradiction as there are too many partial orders on $n$ elements to be represented in only $O(nlog(n))$ bits.\n\nshare|improve this answer\nIt is not true that $P_n \\geq 2^{n^2/4}$. Also, LaTeX knows \\log. \u2013\u00a0 JBL May 25 '10 at 17:19\nIf you consider distinguishable elements then it is true that $P_n \\geq 2^{n^2/4}$. If you consider indistinguishable elements then the there are still at least $\\frac{2^{n^2/4}}{n!} \\geq 2^{n^2/4 - n\\log{n}} = 2^{\\Theta(n^2)}$ partial orders on $n$ elements and the proof still holds. \u2013\u00a0 Travis Service May 25 '10 at 18:19\n+1. Travis, thanks very much for the argument--your information-theoretic way of analyzing it appeals to me very much. \u2013\u00a0 Joel David Hamkins May 25 '10 at 18:49\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/276865/verify-a-given-svd-of-an-operator\nText:\nTake the tour \u00d7\n\nShow that the Singular Value Decomposition of the operator\n\n$$ A\\colon L^2([0,1])\\to L^2([0,1]), x\\mapsto\\int\\limits_0^t x(s)\\, ds $$\n\nis given by\n\n$$ \\sigma_j=\\frac{1}{(j-1/2)\\pi},~~~~~v_j(x)=\\sqrt{2}\\cos((j-1/2)\\pi x),~~~~~u_j(x)=\\sqrt{2}\\sin((j-1/2)\\pi x). $$\n\nMy first question is: Is this operator compact at all so that it makes sense to talk of a SVD?\n\nThen: What do I have to do to solve the task?\n\nFirst, I determined the adjoint operator $A^*$; it is given by $x\\mapsto\\int\\limits_t^1 x(s)\\, ds$. Then I attested that $Av_j=\\sigma_ju_j$ and $A^*u_j=\\sigma_jv_j$.\n\nMoreover, I showed with substitution $\\omega=(j-1/2)\\pi x$ that\n\n$\\langle v_j,v_j\\rangle_{L^2([0,1])}=\\frac{2}{(j-1/2)\\pi}\\int\\limits_0^{(j-1/2)\\pi}\\lvert\\cos(\\omega)\\rvert^2\\, d\\omega=1$ and similarly $\\langle u_j,u_j\\rangle_{L^2([0,1])}=1$.\n\nFurthermore, I calculated for $k\\neq j$ that\n\n$\\langle v_j,v_k\\rangle_{L^2([0,1])}=\\int\\limits_0^1 v_j(x)\\overline{v_k(x)}\\, dx=\\int\\limits_0^1 v_j(x)v_k(\\overline{x})\\, dx=\\int\\limits_0^1 v_j(x)v_k(x)\\, dx$ because $x\\in [0,1]$. This integral is 0.\n\nSimilarly $\\langle u_j,u_k\\rangle_{L^2([0,1])}=0$.\n\nSo far so good. But is this the whole task? Is there something i have to show additionally?\n\nshare|improve this question\nConcerning compactness, write $(Ax)(t) = \\int_0^1 a(t,s)x(s)\\,ds$ with $a(t,s) := \\chi_{[0,t]}(s)$. Then $\\int_0^1 \\int_0^1 |a(t,s)|^2 \\,ds\\,dt < \\infty$, hence $A$ defines a Hilbert-Schmidt operator which is compact (see en.wikipedia.org/wiki/Hilbert-Schmidt_integral_operator) \u2013\u00a0 fbg Jan 13 at 13:29\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/124270/bh-as-a-direct-sum-of-a-closed-two-sided-ideal-and-a-subalgebra/124272\nText:\nTake the tour \u00d7\n\nLet $B(H)$ is the C*-algebra of all bounded linear operators on Hilbert space $H$. Are there a closed two-sided ideal $I$ and a subalgebra $A$ of $B(H)$ such that $B(H)=I \\oplus A$ (direct sum I and A)?\n\nshare|improve this question\nThe tag is inappropriate; I changed it. \u2013\u00a0 Captain Oates Mar 12 at 0:33\nadd comment\n\n2 Answers\n\n$K(H)$, the compact operators on $H$, is the only proper closed ideal in $B(H)$ when $H$ is a separable infinite dimensional Hilbert space, and $K(H)$ is not complemented in $B(H)$ (because if it were the diagonal compact operators would be complemented in the diagonal bounded operators, which is to say that $c_0$ would be complemented in $\\ell_\\infty$).\n\nshare|improve this answer\nDo you know anything about general case of H? Would you please let me know. \u2013\u00a0 Ali Mar 11 at 23:17\nFor general $H$ the ideals are $K(H)$ and, for each cardinal '$\\aleph' \\le$' the dimension $\\aleph$ of $H$, the set of operators whose ranges have dimension less than $\\aleph$. If such an ideal were complemented in $B(H)$ you argue that you would have the functions in '$\\ell_\\infty(\\aleph')$' whose support has cardinality less than $\\aleph$ is complemented in '$\\ell_\\infty(\\aleph')$', which it is not. But I don't recall an easy argument that it is not complemented. In the separable case, it is basically Phillips' lemma that $c_0$ is not complemented in $\\ell_\\infty$ and the result is in \u2013\u00a0 Bill Johnson Mar 12 at 0:44\n...text books (e.g., Albiac-Kalton). \u2013\u00a0 Bill Johnson Mar 12 at 0:46\nadd comment\n\nLet me complement Bill's answer. It is basically the same idea.\n\nGramsch and Luft described the lattice of closed ideals of $B(H)$ where is $H$ a non-separable Hilbert space.\n\nB. Gramsch, Eine Idealstruktur Banachscher Operatoralgebren, J. Reine Angew. Math. 225 (1967), 97\u2013115.\n\nE. Luft, The two-sided closed ideals of the algebra of bounded linear operators of a Hilbert space, Czechoslovak Math J. 18 (1968), 595\u2013605.\n\nThey proved that for a non-separable Hilbert space $H$ with density character ${\\rm dens}\\; H$ (this is the minimal cardinality of a dense subset) all the closed ideals of $B(H)$ are of the form $\\{0\\}$, $K(H)$ (the compact operators) and\n\n$$K_\\lambda(H) = \\{T\\in B(H)\\colon \\mbox{dens }T[H]< \\lambda\\}$$\n\nwhere $\\lambda\\leqslant\\kappa^+$. Certainly, $$B(H) = K_{({\\rm dens}\\; H)^+}(H).$$ Hence, we are interested in the case only where $\\lambda\\leqslant {\\rm dens}\\; H$.\n\nFix an orthonormal basis for $H$ and identify operators on $H$ with matrices with respect to this basis. Consider the Banach space $\\ell_\\infty^\\lambda({\\rm dens}\\; H)$ of all bounded complex-valued functions on the cardinal ${\\rm dens}\\; H$ with at most $<\\lambda$ non-zero entries, endowed with the sup-norm.\n\nIf you intersect the ideal $K_\\lambda(H)$ with the diagonal masa (that is, $\\ell_\\infty({\\rm dens}\\; H)$) then you'll get precisely $\\ell_\\infty^\\lambda({\\rm dens}\\; H)$. The diagonal masa is complemented because $\\ell_\\infty({\\rm dens}\\; H)$ is an injective Banach space. Consequently, if $K_\\lambda(H)$ was complemented in $B(H)$ then $\\ell_\\infty^\\lambda({\\rm dens}\\; H)$ would be complemented in $\\ell_\\infty({\\rm dens}\\; H)$. This is however a contradiction because $\\ell_\\infty^\\lambda({\\rm dens}\\; H)$ is not injective (see this paper for a discussion of this space and its injectivity-like properties).\n\nProof of non-injectivity of $\\ell_\\infty^\\lambda(\\kappa)$: Assume $\\ell_\\infty^\\lambda(\\kappa)$ is injective. Manifestly, it contains $c_0(\\kappa)$. Then by Rosenthal's theorem\n\nH.P. Rosenthal, On relatively disjoint families of measures, with some applications to Banach space theory, Studia Math., 37 (1970), 13\u201336.\n\nit would contain a copy of $\\ell_\\infty(\\kappa)$ and by Pe\u0142czy\u0144ski's decomposition method, it would be isomorphic to $\\ell_\\infty(\\kappa)$; a contradiction.\n\nEDIT: As Bill pointed out we have to be careful why this is indeed impossible. Under GCH this is evident but life would be too easy with GCH. Actually, to see this is a result in ZFC, one has to tweak the argument in Paragraph d) on page 12 of the hyperlinked paper by replacing $\\mathbb{N}$ with $\\lambda$ and $\\aleph_1$ with $\\lambda$. Then the whole proof carries over. (Frankly, I learnt it from one of the authors of this paper some time ago and presumed that it is well-known. My apologies for that.)\n\nshare|improve this answer\n@Tomek: The argument you suggest at the end only shows that $\\ell_\\infty^\\lambda({\\rm dens}\\; H)$ is not $1$-injective. \u2013\u00a0 Bill Johnson Mar 12 at 1:03\nThank you, Bill. I hope my answer is now fairly complete. \u2013\u00a0 Tomek Kania Mar 12 at 1:18\n@Tomek: Yes, I saw that argument, too, but why is $\\ell_\\infty^\\lambda(\\kappa)$ not isomorphic to $\\ell_\\infty(\\kappa)$? The latter space has density character $2^\\kappa$ and the former density character sup $\\{ 2^\\alpha: \\alpha < \\lambda\\}$, so non isomorphism is easy under the generalized continuum hypothesis. Absent GCH, I did not at first see a simple reason. Now I do, but I'll wait a bit before posting in case you want to think about it some more. \u2013\u00a0 Bill Johnson Mar 12 at 16:15\nNice answer, Tomek. For the sake of completeness$^\\ast$, I mention that, with the definitions given in your answer, $K_\\lambda(H)$ is not closed in $B(H)$ when $\\lambda< dens(H)$ is of cofinality $\\omega$; similarly, $\\ell_\\infty^\\lambda (dens(H))$ is not closed in $\\ell_\\infty(dens(H))$ when $\\lambda< dens(H)$ is of cofinality $\\omega$ (these spaces are otherwise closed in their respective overspaces). The definition of $\\ell_\\infty^\\lambda (dens(H))$ should presumably be those $f\\in \\ell_\\infty(dens(H))$ with $\\vert\\{ \\alpha\\in dens(H)\\mid\\vert f(\\alpha)\\vert>\\epsilon\\}\\vert <\\lambda$. \u2013\u00a0 Philip Brooker Mar 13 at 12:05\nFor my \"simple\" argument that $\\ell_1(2^\\kappa)$ does not embed into (the closure of) $\\ell_\\infty^\\lambda(\\kappa)$ I implicitly used $\\lambda < \\gamma$ implies $2^\\lambda < 2^\\gamma$. (Correcting typo in earlier comment.) \u2013\u00a0 Bill Johnson Mar 14 at 15:24\nshow 7 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/112594/least-prime-primitive-root\nText:\nTake the tour \u00d7\n\nFor $p$ a prime number, let $G(p)$ be the least prime $q$ such that $q$ is a primitive root mod $p$, that is $q$ generates the multiplicative group $(\\mathbb Z/p\\mathbb Z$)* .\n\nIs it known that $G(p)=O(p)$ ? I don't mind if the answer assumes GRH or any other standard conjecture.\n\nI am interested in results true for all $p$, much less (though a little bit) on results which exclude a density $0$ or other smallish set of $p$. I note that it is easier to find bounds in the literature for $g(p)$, the least integer $n$ such that $n$ is a primitive root mod $p$. For example $g(p)=O(p^{1/2+\\epsilon})$ was known unconditionally to Vonogradov in the 1930's (we have better unconditional results since), and with GRH we have result of type $g(p)=O(log^A p)$ with $A$ is some small constant. But what are the best results we have for $G(p)$? What are the best expected results ?\n\nI am interested by $G(p)$ and not $g(p)$ because I use this problem as a testing ground of various effective forms of Chebotarev's there, and Chebotarev provides prime numbers. The best result I can prove this way is, under GRH, is $G(p)=O(p \\log^{6+\\epsilon} p)$ (edited: I made a mistake on the exponent of the $\\log$), using Proposition 8.3 of the book of Ram Murty and Kumar Murty \"Non-vanishing of $L$-functions and applications\". With the GRH version of Lagarias-Odlyzko I get only $O(p^2 \\log^2 p)$.\n\nEDIT: Here is the proof of the estimate using Murty and Murty, as GH asked. Proposition 8.3 of Murty and Murty states that if $G$ is the Galois group of an extension $L$ of $\\mathbb Q$, $D$ a union of conjugacy classes in $G$, and $M=\\sum \\log p$, the sum being on the primes ramified in $L$, then $$| \\pi_D(x) - \\frac{|D|}{|G|} Li\\, x | < C |D|^{1/2} x^{1/2} \\log(Mx),$$ where $C$ is an absolute constant, $\\pi_D(x)$ the numbers of primes $p \\leq x$ such that $Frob_p \\in D$.\n\nLet us apply this to $L=\\mathbb Q(\\mu_p)$, $D=$ set of primitive roots in $G=(\\mathbb Z/p\\mathbb Z)^\\ast$. If for some real $x$, the principal term $\\frac{|D|}{|G|} Li x = Li(x)/2$ is bigger than the error term $C |D|^{1/2} x^{1/2} \\log(p x)$, then $\\pi_D(x) > 0$ which means that $G(p)< x$.\n\nSo we write that inequality, and solve it for $x$, using $|D|=\\phi(p-1)$, and replacing $Li(x)$ by $x/\\log x$ which just changes the constant $C$. So we want: $$ x/(\\log(x) x^{1/2}) > C \\phi(p-1)^{1/2} (\\log p + \\log x).$$ Since $\\log p \\log x > \\log p + \\log x$ except for $x$ ridiculously small, it is enough to have $$ x/(\\log(x) x^{1/2}) > C \\phi(p-1)^{1/2} \\log p \\log x,$$ or, taking the square, $$x / \\log^4(x) > C^2 \\phi(p-1) \\log^2 p$$ which is implied by $$x > C' \\phi(p-1) \\log^2 p \\log^4(\\phi(p-1) \\log^2 p),$$ Hence $G(p)=O(\\phi(p-1) \\log^2 p \\log^4(\\phi(p-1) \\log^2 p)) = O(p \\log^{6+\\epsilon} p)$.\n\nshare|improve this question\nAccording to mathoverflow.net/questions/834/\u2026 , a conjecture of Montgomery implies that, for EVERY residue class $a$ in $\\mathbb{Z}/p^{\\ast}$, there is a prime $q$ which is $O(p^{1+\\epsilon})$ and represents $a$. I'm afraid I don't know more about this. \u2013\u00a0 David Speyer Nov 16 '12 at 17:28\nYou may want to exclude successors of ( primorials and small multiples of primorials), as they may produce the hardest p to determine G(p). Or tackle them head on, as small values of phi(p-1) suggest potentially large values for G(p). Gerhard \"But I May Be Wrong\" Paseman, 2012.11.16 \u2013\u00a0 Gerhard Paseman Nov 16 '12 at 17:34\n@Gerhard: $\\phi(p-1)$ is never too small, it is at least $C (p-1)/\\log \\log (p-1))$. A $\\log \\log$ term is not really important in those estimations. So I don't think it is \"morally\" necessary to excludes those primes. \u2013\u00a0 Jo\u00ebl Nov 16 '12 at 17:50\n@David: Yes. Actually a stronger form of this conjecture says that there is a prime $q$ that represents $a$ wiih $q=O(p \\log(p)^2)$. And since (beware ! very bad heuristic follows...) it is much easier to find a prime which modulo $p$ falls in a set of $\\phi(p-1)/2$ elements rather than on just one specific element, one could expect that $G(p) = O(p \\log(p)^2 / (phi(p-1)/2)) = O(\\log(p)^2 \\log \\log p)$ ! But very likely it's too naive... \u2013\u00a0 Jo\u00ebl Nov 16 '12 at 17:54\n@GH: I have wrote the answer -- and realized I made a mistake on my back of the envelope computation: the exponent of \\log must be $6+\\epsilon$, not $4$. Hope I haven't made an other mistake... \u2013\u00a0 Jo\u00ebl Nov 16 '12 at 18:32\nshow 6 more comments\n\n1 Answer\n\nup vote 10 down vote accepted\n\nFor the expected behavior, see Paszkiewicz and Schinzel's paper \"On the least prime primitive root modulo a prime\" in Math. Comp. 71 (2002), no. 239, 1307\u20131321. There they examine a conjecture of Bach that $\\limsup \\frac{G(p)}{(\\log p)(\\log\\log p)^2}=e^{\\gamma}$.\n\nIt is known that almost always $G(p)$ is bounded by a fixed power of $\\log{p}$, and the word `almost' can be removed if we assume GRH. (Under GRH, we in fact have $G(p) \\ll (\\log{p})^6$, and one can do better as long as $p-1$ doesn't have atypically many prime factors.) The best results I know in this direction are due to Greg Martin; see\n\n\nUnconditionally, I believe it's not even known that $G(p)$ is less than $p$ for all large $p$.\n\nshare|improve this answer\nGreg Martin says $G(p) \\ll (\\log{p})^6$ under GRH is due to Shoup (1992). He says \"Although both authors state their bounds only for primitive roots, the bounds actually hold for prime primitive roots as well.\" Can you explain why? \u2013\u00a0 GH from MO Nov 16 '12 at 18:13\nIt looks from Wang's paper (which can be found by searching Google books for his collected works) that he actually shows the partial sums of $\\Lambda(n) e^{-n/x}$, taken over primitive roots $n$ up to about $(log p)^{C}$, is positive. So this gives a prime small power $n$ which is a primitive root mod $p$. But then the prime which $n$ is a power of must also be a primitive root mod $p$. \u2013\u00a0 Anonymous Nov 16 '12 at 18:43\nThank you very much! \u2013\u00a0 GH from MO Nov 16 '12 at 18:51\nWell, many thanks. I find striking how bad the effective chebotarev theorems (even those proved under GRH) are when we try to apply them in special situations, compared to what we can get directly in those situations. Here we have under GRH $O(\\log^6 p)$ instead of $O(p \\log^{6+\\epsilon} p)$. Similarly, for the problem of the least prime in an arithmetic sequence, we expect $O(p \\log^2 p)$ but with effective Chebotarev under GRH, we only get $O(p^2 \\log^2 p)$. \u2013\u00a0 Jo\u00ebl Nov 16 '12 at 18:57\nJust wanted to confirm that Anonymous has said correctly almost everything I could say about unconditional results. Note that Linnik's theorem (with Xylouris's constant), applied to any one primitive-root residue class mod $p$, shows unconditionally that there exists a prime primitive root mod $p$ that is $\\ll p^{5.2}$. As far as I know, this is the best unconditional, uniform result for prime primitive roots! \u2013\u00a0 Greg Martin Nov 16 '12 at 20:04\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/180520/sqrtx-y-4-x-sqrty-6-find-the-solution-x-y\nText:\nTake the 2-minute tour \u00d7\n\n$\\sqrt{x} +y = 4$, $\\sqrt{y} +x= 6$, find the solution (x,y). $NOTE$ : $\\sqrt{4}+1= 4-1$, $\\sqrt{1} +4 =1+4$\n\nshare|improve this question\n$(\\sqrt{2}+1) \\lt (2+\\sqrt{1})$, $(\\sqrt{4}+1) \\lt (4+\\sqrt{1})$ \u2013\u00a0 Rajesh K Singh Aug 9 '12 at 5:09\n$\\sqrt x=4-y$, $x=y^2-8y+16=6-\\sqrt y$, $y=(y^2-8y+10)^2$ gives you an equation of degree 4 in $y$. If you can solve it, you win. \u2013\u00a0 Gerry Myerson Aug 9 '12 at 6:00\nAnother approach is $y=4-\\sqrt x$, $\\sqrt y = 6-x$ implies $y=(6-x)^2$. Since $y=y$, we can set the right side of both equations equal to each other. Then we get an 4th degree equation in $\\sqrt x$. \u2013\u00a0 Matt Groff Aug 9 '12 at 6:07\nlet $u=\\sqrt{x}, v=\\sqrt{y}$. Then $u^2+v=4, u+v^2=6$ Hence $v=4-u^2$. Hence $u+16-8u^2+u^4=6 \\iff u^4-8u^2+u+10=0$. Wolframalpha gives some disgusting solutions to this quartic equation: wolframalpha.com/input/?i=u%5E4-8u%5E2%2Bu%2B10%3D0 \u2013\u00a0 progressiveforest Aug 9 '12 at 6:07\nBeautiful question with ugly answer... \u2013\u00a0 \u1d0a \u1d00 s \u1d0f \u0274 Aug 9 '12 at 6:13\nshow 1 more comment\n\n2 Answers\n\nThis is basically the method which was suggested in the comments above - turning this into a quartic equation. We will see whether someone suggest a substantially more elegant solution.\n\n$$\\sqrt{x}+y=4\\\\ x+\\sqrt{y}=6$$\n\nUsing the substitution $\\sqrt{x}=s$ and $\\sqrt{y}=t$ we get: $$s+t^2=4\\\\ t+s^2=6$$\n\nWhich gives $$s=4-t^2=4-(6-s^2)^2\\\\ (s^2-6)^2+s-4=0\\\\ s^4-12s^2+s+32=0$$\n\nIt should be possible to solve this as a quartic equation, although it would be quite laborious. You can check what WolframAlpha is able to find out here and here\n\nshare|improve this answer\ngreat attempt indeed \u2013\u00a0 Rajesh K Singh Aug 9 '12 at 6:20\nadd comment\n\nLet, $\\sqrt{x}=s$, $\\sqrt{y}=t$\n\nwe have, $s^4 -12s^2+s+32=0$, which is a 'biquadratic' equation of the form,\n\n\ni.e. $$s^4 -12s^2+s+32=(s^2+ks+l)(s^2-ks+m)$$\n\nnow by equating coefficients, we have\n\n$$l+m-k^2 = -12, k(m-l) = 1, lm = 32$$\n\nfrom the first two of these equations, we obtain\n\n$$2m=k^2-12+(1/k), 2l=k^2-12-(1/k)$$\n\nhence substituting in the third equation, the values of l,m,\n\n\n\n\n\nthis is a cubic in $k^2$ which always has one real positive solution and we can find $k^{2}$,$l$,$m$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/31077/inverse-of-1x-ln1x-x\nText:\nTake the 2-minute tour \u00d7\n\nDefine g(x) = (1+x) ln(1+x) - x. One can check that g is strictly monotonically increasing for x>=0 by checking its derivative is ln(1+x). So g is invertible and its inverse is also strictly monotically increasing.\n\nIs there an explicit closed form for its inverse?\n\nWith a page of calculations I can prove that (1/2) x/ln(1+sqrt(x)) <= g^{-1}(x) <= 2 x/ln(1+sqrt(x)) for all x>=0. Is this obvious? Can estimates like this be found in the literature?\n\nshare|improve this question\nI don't think there's any reason to expect one. You could try writing it in terms of the Lambert W-function, although I don't see how this could possibly help anybody. You might also try Lagrange inversion: en.wikipedia.org/wiki/Lagrange_inversion_theorem \u2013\u00a0 Qiaochu Yuan Jul 8 '10 at 16:52\nWhy do you say that writing it in terms of Lambert-W couldn't help anyone? Lambert-W hasn't made it into the high school curriculum yet, but it's incorporated in the major symbolic math engines, which know how to evaluate it, manipulate it, etc. In particular, if what OP wants is estimates, well, it shouldn't be too hard to find useful info on Lambert-W on the web. \u2013\u00a0 Gerry Myerson Jul 9 '10 at 7:14\nadd comment\n\n1 Answer\n\nup vote 6 down vote accepted\n\nJust to expand on Qiaochu's comment: let $W$ stand for the Lambert W-function, then if $g(x)=z$, we readily find that $$ x=\\exp\\big(W((z-1)/e)+1\\big)-1. $$\n\nshare|improve this answer\nThanks very much for this information, I was not familiar with Lambert-W. \u2013\u00a0 Nick Harvey Jul 9 '10 at 13:31\nConversely, my estimates to g^{-1} imply estimates for W. Specifically, for all z>-1/e, I can prove W(z) <= ln( 2*(e*z+1)/ln(1+sqrt(e*z+1)) + 1)-1 and W(z) >= ln( 0.5*(e*z+1)/ln(1+sqrt(e*z+1)) + 1)-1 Is this obvious or well-known? The Taylor's series for W(z) around z=0 given at Wikipedia is only useful for z close to 0. My estimates are best for z close to -1/e, and have a constant additive error for z -> infinity. \u2013\u00a0 Nick Harvey Jul 9 '10 at 19:57\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/3239/is-no-proof-based-on-tertium-non-datur-sufficient-any-more-after-godel/3243\nText:\nTake the 2-minute tour \u00d7\n\nThere are many proofs based on a \"tertium non datur\"-approach (e.g. prove that there exist two irrational numbers a and b such that a^b is rational).\n\nBut according to G\u00f6del's First Incompleteness Theorem, where he provides a constructive example of a contingent proposition, which is neither deductively (syntactically) true nor false, we know that there can be a tertium.\n\nMy question: Are all proofs that are based on that principle useless since now we know that a tertium can exist?\n\nshare|improve this question\nI think it's a bit unfair to downvote this question. Logic can have many confusing aspects, and most people I know take some time to appreciate its subtleties. \u2013\u00a0 aorq Oct 29 '09 at 15:42\nI agree. This is a common error, and it is one that I think is not so naive that it is not of interest to mathematicians to know how to correct it. \u2013\u00a0 David Speyer Oct 29 '09 at 16:06\nThis is somewhat addressed in some answers below, but this point is important enough that it warrants stressing here: questioning the validity of using the law of excluded middle is a legitimate (albeit minority) position, and it has a distinguished history. It just does not have much to do with G\u00f6del's First Incompleteness Theorem, and indeed, pre-dates it by at least a couple of decades. \u2013\u00a0 Thierry Zell Aug 13 '10 at 13:14\nadd comment\n\n7 Answers\n\nup vote 40 down vote accepted\n\nYou are confused.\n\nThe best way out of your confusion is to maintain a very careful distinction between strings of formal symbols and their mathematical meanings. Godel's theorem is, on its most primitive level, a theorem about which strings of formal symbols can be obtained from other strings by certain formal manipulations. These formal manipulations are called proofs, and the strings which are obtainable in this way are called theorems. For clarity, I'll call them formal proofs and formal theorems.\n\nIn particular, let G be a string such that G is not a formal theorem and neither is NOT(G). It is still true that G OR NOT(G) is a formal theorem. Moreover, if G IMPLIES H and NOT(G) IMPLIES H are both formal theorems, then H will be a formal theorem; because there are rules of formal manipulation that allow you to take the first two strings and produce the third. I believe that Douglass Hofstader discusses this in a fair bit of detail when he goes over Godel's theorem.\n\nThe above is mathematics. Next, some philosophy. I don't find it helpful to say that G is neither true nor false. It find it more helpful to say that our systems of formal symbols and formal manipulation rules can describe more than one system. For example, Euclid's first four axioms can describe both Euclidean and non-Euclidean geometries. This doesn't mean that Euclid's fifth postulate has some bizarre third state between truth and falsehood. It means that there are many different universes (the technical term is models) described by the first four axioms, and the fifth postulate is true in some and false in others.\n\nHowever, in any particular one of those universes, either the fifth postulate is true or it is false. Thus, if we prove some theorem on the hypothesis that the fifth postulate holds, and also that the fifth postulate does not hold, then we have shown that this theorem holds in every one of those universes.\n\nThere are fields of mathematical logic, called constructivist, where the law of the excluded middle does not hold. As far as I understand, that issue is not related to Godel's theorem.\n\nshare|improve this answer\nThis is a side comment, not a criticism of your answer: I find it quite helpful to think of a statement containing variables as neither true nor false. For example, for a real variable x, \"(x+1)^3 > 0\" is neither true nor false, but \"(x+1)^2 > 0\" is true. I have written about this in several places and talked to people about it. I get two reactions: One, like yours, is that that is a bizarre way to think. The other is \"well of course -- that's the normal way to describe such assertions\". Perhaps there is a Deep Divide among mathematicians... \u2013\u00a0 SixWingedSeraph Oct 29 '09 at 15:20\nMy perspective is that both your examples are not full sentences. A full sentence should not have bound variables, so it should say: \"For all x in R, (x+1)^3 > 0.\" or \"For the x defined in Section 2, (x+1)^3>0.\". Of course, we often drop the preceding phrase, but only because it is clear from context. But I've run into a lot of people who think the way you do, and I don't want to claim that I am more right in any absolute sense. I think one of the reasons that I have a hard time understanding the notation of predicate calculus was that it was invented by people who take your perspective. \u2013\u00a0 David Speyer Oct 29 '09 at 15:48\nOf course, when I wrote \"bound\", I meant \"unbound\". \u2013\u00a0 David Speyer Oct 29 '09 at 15:51\nFor what it's worth, many standard presentations of predicate calculus call the things SixWingedSeraph is talking about \"well-formed formulas\" (or \"wffs\"), and then reserves the term \"sentence\" for wffs with no free (unbound) variables. Then the terms \"true\" and \"false\" are applied only to sentences, and not to wffs in general. There are some proof systems that allow non-sentence wffs in intermediate steps in proofs, while others only allow sentences as steps in proofs. \u2013\u00a0 Kenny Easwaran Nov 6 '09 at 6:42\n-1: The argument in the question is sketchy, but it is not confused. Your \"answer\" comes down to assertions involving \"I don't find it useful\" and existence of \"different universes\": I find it hard to see why anyone attracted by the argument in the question would find this response cogent. \u2013\u00a0 Charles Stewart Jan 15 '10 at 12:37\nshow 2 more comments\n\nI accidentally ran into this old question and thought to give an example whose (humble!) intention is to permanently deconfuse anyone who knows just a little bit of undergraduate mathematics.\n\nConsider group theory. In a typical introductory course, you will learn the simple axioms and immediately encounter sentences like\n\n$$\\forall y \\forall x \\forall z( (xy=e) \\wedge (zy=e ) \\Rightarrow x=z);$$\n\nor slightly more complicated ones like\n\n$$(\\forall x(x^2=e ))\\Rightarrow (\\forall x\\forall y(xy=yx)).$$\n\nYou also learn how to deduce them rather easily from the axioms of the theory.\n\nHow about the sentence\n\n$$S:\\ \\ \\ \\ \\ \\ \\ \\forall x \\forall y( xy=yx)$$\n\n\nCan it be deduced from the axioms? Obviously not, but it requires at least a bit of thoughtfulness to prove that it can't. You see, we can just write down a structure like $S_3$ that satisfies the axioms of group theory, a model of group theory, and produce two elements in it for which the sentence is not true. Obviously we couldn't produce such a model if the sentence was a logical consequence of the axioms.\n\nHow then about $\\neg S$? Can it be deduced from the axioms? Again obviously not. Consider the integers $Z$.\n\nSo we see that group theory is incomplete: We've written down a sentence $S$ such that neither $S$ nor $\\neg S$ can be deduced from the axioms.\n\nBut here is an important point: If the context of the discussion was the group $Z$, is the sentence $S$ true? Yes, of course, and I can prove it for you. (Using more than the axioms of group theory, of course.)\n\nFor a complete theory, every true assertion $S$ (in the language of the theory) about a given model $G$ can be deduced from the axioms. This is because $S$ or $\\neg S$ can be deduced, but if $\\neg S$ could be deduced, then it would have to be true in any model of the theory, in particular, $G$. So $S$ would be false in $G$. But $S$ is true. Therefore, it must be the one that can be deduced. The upshot is that whenever you have a theory (like group theory) with a model that admits a true sentence that can't be deduced from the axioms, then the theory is incomplete. The point of boring you with this discussion is to illustrate that an incomplete theory is a very mundane object.\n\nIn case this suggests (as it should) that a complete theory, on the other hand, is bound to be very exotic, you might like this simple list of a few complete theories. For example, the theory of algebraically closed fields of characteristic zero is complete. This implies, in particular, a logical incarnation of the 'Lefschetz principle': A field-theoretic sentence true in $C $ is true in every algebraically closed field of characteristic zero. In fact, as noted above, a sentence true in any given model, since it can be deduced from the axioms, is true in any other model. I found this fact quite mind-boggling when I first encountered it. A good exercise is to see why a sentence like 'every element of $\\bar{Q}$ is algebraic' doesn't cause a problem. (You need to get a bit more precise to do this, especially about the language of the theory.)\n\nThere is a complete theory of the natural numbers, by the way. Add to your favorite axioms of arithmetic all the sentences that are true in the natural numbers. This is a perfectly respectable complete theory, sometimes referred to as the theory of natural numbers. Goedel's first incompleteness theorem can be interpreted as saying this theory doesn't admit a recursively enumerable set of axioms. (Which should be at least intuitively plausible if you consider difficult unresolved problems like, say, Goldbach's conjecture.)\n\n\nIn my opinion, it's not such a good idea to emphasize the 'string of formal symbols and rules' point of view when explaining the incompleteness theorem. It's true that to prove the theorem, you need to set up such background formalities. But the statement itself can plausibly be interpreted as something about everyday reasoning in mathematics. We are usually interested in some structure, a rather specific one like $Z/2$, a somewhat more general one like 2-groups, or more general yet like all groups. The question concerns which properties (or axioms satisfied by the structure, if you prefer) we use to prove certain assertions. The everyday nature of this question was the reason for bringing up the commutativity of $Z$, which I can certainly prove in the course of a normal discussion on the chalkboard, but anyone can see requires more than group theory.\n\nThis question also comes up rather frequently as one of great interest to practicing mathematicians. An advanced example that I can remember off the top of my head is 'Can one prove the Kodaira vanishing theorem using only algebraic geometry?,' which was resolved first by Faltings (although there is room for interpretation of the phrase 'only algebraic geometry').\n\nIn some sense, the rationale for the abstract formalism surrounding the incompleteness theorem is also pretty commonsensical. To prove that something can be done, you just need to do it. For example, I think it is uncontroversial that the proof of the Kodaira vanishing theorem by Deligne and Illusie uses 'only algebraic geometry.' And then, there are the famous elementary proofs of the prime number theorem. To prove that something can't be done, on the other hand, often requires more careful foundations.\n\nAdded again:\n\nAfter some conversations, I decided to put in a few final words of clarification. I hope I didn't slight anyone with the joke about 'permanent deconfusion.' I don't claim to have any serious understanding of philosophical ramifications, for example. However, I tried to articulate what seems to me a sensible view of the matter for practicing mathematicians. Starting from the one given, you can yourself quickly make up examples illustrating the (uninteresting) incompleteness of a large majority of the theories we usually work with, rings, fields, topological spaces, etc. After that process, and thinking through just the few implications of completeness already mentioned, if someone came up to you and claimed that Peano Arithmetic was complete, I suspect your eyes would pop out.\n\nSomeone once told me that a good way to sound sophisticated as an amateur logician is to proclaim that the completeness theorem* is much more important than the incompleteness theorem. That's perhaps too sweeping a statement, but it seems to be the one that's useful for usual mathematics. For people interested in pursuing this line of thought, I recommend the nice lectures delivered by Angus Macintyre at the Arizona Winter School in 2003:\n\n\nOne intriguing observation there I sometimes think about is how number-theoretic completions (reals and $p$-adics) correlate to logically complete theories.\n\n*The completeness theorem essentially says that a sentence is a logical consequence of the axioms if and only if it's true in all models of the axioms. The idea for the non-trivial direction is to show how to construct, given any sentence that can't be deduced, a model for the axioms in which it is false.\n\nshare|improve this answer\nI'm afraid you're far too sophisticated for me. But I'll leave it to a professional to write down the absolutely correct version of group theory and its language in a way that my assertions make good sense. \u2013\u00a0 Minhyong Kim Apr 14 '10 at 22:01\nIsn't it pretty clear that \"xy=yx\" refers to multiplying group elements together? \u2013\u00a0 Peter Samuelson Apr 14 '10 at 22:25\nSo these comments make sense, I'll explain the comments I deleted: I made a comment regarding some set-theoretic nonsense because I misread the post and didn't see that Minhyong was assuming the axioms of group theory instead of set theory. \u2013\u00a0 Harry Gindi Apr 15 '10 at 18:23\nJust found and not yet read, <a href=\"rsta.royalsocietypublishing.org/content/363/1835/\u2026; title=\"abstract\">here</a> an article on Skolem's thoughts on the meaning of that incompleteness. BTW, I found that incompleteness theorem (after I had learned it's precise formulation) not very surprising, but would have been shocked about a completeness theorem, as the later would show that elementary number theory were \"trivial\" and just like some chess game. \u2013\u00a0 Thomas Riepe Apr 21 '10 at 14:13\nadd comment\n\nYou're missing the distinction between truth and proof. Godel's Theorem says there are statements which are neither provable nor disprovable (from a given set of axioms). Those statements are still either true or false in a given universe. Godel just says your axioms aren't good enough to tell which one.\n\nshare|improve this answer\nadd comment\n\nIf you believe in classical logic, such proofs are still fine. Godel incompleteness just states that in first order logic, any system capable of expressing arithmetic must contain an undecidable formula P. You can still prove (P or ~P) - that's an axiom actually. In every model of the axioms either one or the other is true. So a classical mathematician (who is a platonist), says Godel's incompleteness theorem just shows that FOL is insufficient for expressing everything about the \"real\" mathematical universe, but that doesn't mean that the law of the excluded middle (LEM) fails. If you have a philosophical problem with this, you have some constructivist leanings. I have strong formalist tendencies, and would say that LEM is cool if you think its cool, and not if you don't like it. We should be free to change our foundations to suit our whims!\n\nshare|improve this answer\nadd comment\n\nIn classical logic, for any proposition $A$, either $A$, or $\\lnot A$.\n\nWhat Godel showed was that under certain conditions (which hold for the formal system most of us use) there are propositions $A$ such that neither $A$ nor $\\lnot A$ are provable.\n\nNote the difference between these statements. In one case it's about the assertions $A$ and $\\lnot A$. In the other case it's about the provability of the assertions $A$ and $\\lnot A$. The former is about whatever $A$ is about. The latter is about whether or not you can produce a string of symbols by following certain rules.\n\nFor example, if you assert \"for all real $a>1, a^2>1$\" you're saying something about real numbers. But if you assert \"for all real $a>1, a^2>1$ is provable\", you're saying something about how you can produce the string of symbols \"for all real $a>1, a^2>1$\" by following a bunch of rules. These two things are entirely different kinds of assertion.\n\nIn particular, if you know $A \\lor \\lnot A$, you can conclude that either $A$ is true, or that $\\lnot A$ is true. But if you know that $A \\lor \\lnot A$ is provable, you can't deduce (in a classical context) that either $A$ is provable or that $\\lnot A$ is provable.\n\nAs long as you make clear the distinction between asserting $A$ and asserting that $A$ is provable, you're fine.\n\nshare|improve this answer\nYour fourth paragraph is slightly confusing. If you say \"for all real $a>1$, $a^2>1$ is provable\", you should really say \"provable from a given collection of axioms\". \u2013\u00a0 Stefan Geschke Aug 30 '10 at 12:02\nadd comment\n\nThere are reputable mathematicians who assert that \"tertium non datur\" arguments are at best incomplete and at worst meaningless. I recommend \"A Constructivist Manifesto\", Chapter 1 of Errett Bishop's \"Foundations of Constructive analysis\".\n\nThe idea is not to assert some \"bizzare state\" between truth and falsity, but rather to take seriously the possibility that there may be simple and natural propositions that (a) Are independent of ZFC and (b) Will not or can not ever yield to any compelling new intuition or axiom. The idea that in some magical timeless world such assertions are forever true or false in themselves is at least questionable, and Godel was the first to expose this difficulty.\n\nshare|improve this answer\nOf course, G&ouml;del himself seems to have been a Platonist --- he thought that his result showed the poverty of formalism, and motivated the necessity of a direct cognitive link to the Platonic realm, for discovering mathematical truth! \u2013\u00a0 Niel de Beaudrap Apr 15 '10 at 8:07\n@Niel: Yes, and Cohn, it seems, was a passionate formalist..... Which goes to show how questionable it is to draw philosophical conclusions from mathematical results. \u2013\u00a0 SJR Apr 15 '10 at 10:09\nI don't think it is accurate to say that \"Godel was the first to expose this difficulty\". Brouwer was on record a constructivist some 20+ years before Godel's incompleteness theorem was published. It's the crisis in the foundations itself that sent mathematicians scrambling for fixes, one of which being the restricted use of excluded middle. \u2013\u00a0 Thierry Zell Aug 13 '10 at 13:06\nadd comment\n\nI think that many of the responses here are overlooking the key part of your question, \"Are all proofs that are based on that principle useless?\". The question of whether LEM is not merely formally consistent but actually useful, i.e., pertaining to reality, is a deep question that has been debated for at least a century (since Brouwer). One partial answer to your question is that no, not all such proofs are useless, because often they involve LEM on propositions which are indeed decidable. In constructive mathematics, $\\varphi \\vee \\neg \\varphi$ is precisely what it means for a proposition $\\varphi$ to be decidable, and making use of this fact in a proof amounts to calling a decision procedure.\n\nshare|improve this answer\nEven LEM on propositions that will never or can never be decided is not useless -- An LEM proof of a proposition indicates that attempts to prove the negation of the proposition are futile. A wise old logician once told me that the attempt to make proofs constructive is not so much a logical imperative as it is a crucial method of discovery. For example, the project of making constructive the fact that the rationals are dense in the reals gives rise to the discipline of diophantine approximation. \u2013\u00a0 SJR Apr 17 '10 at 11:17\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/4768/every-permutation-is-either-even-or-odd-but-not-both?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nHow we can show every permutation is either even or odd,but not both......I can't arrive at a proof for this ..... Can anybody give me the proof...\n\nThanks in advance...\n\nshare|improve this question\nThere are three well explained answers to this question on en.wikipedia.org/wiki/Parity_of_a_permutation \u2013\u00a0 alext87 Sep 16 '10 at 10:44\nUnless I'm having a particularly daft day... I question the validity of the first two proofs on wikipedia: they don't seem to eliminate the possibility that every permutation is both even and odd. \u2013\u00a0 Douglas S. Stones Sep 16 '10 at 10:56\nThe identity permuation is even. \u2013\u00a0 alext87 Sep 16 '10 at 11:19\nDepends on your definition of parity of the permutation. If you simply define it as the parity of number of inversion pairs, this is a no-brainer. \u2013\u00a0 Aryabhata Sep 16 '10 at 18:26\nSee my answer here: math.stackexchange.com/questions/46403/\u2026 \u2013\u00a0 Grumpy Parsnip Feb 18 '12 at 23:51\nadd comment\n\n4 Answers\n\nThere is a proof given here: An Historical Note on the Parity of Permutations, T. L. Bartlow, American Mathematical Monthly Vol. 79, No. 7 (Aug. - Sep., 1972), pp. 766-769.\n\nHere's an outline of Bartlow's proof (it matches the proof given in Ted's answer).\n\n  \u2022 Divide $S_n$ (the symmetric group on $n$ letters) into two classes according to the parity of the number of cycles (fixed points counted as 1-cycles) in their unique decomposition into disjoint cycles. [E.g. in $S_5$ the permutation $(1,2,3)(4)(5)$ has 3 disjoint cycles.]\n\n  \u2022 These classes are thus well-defined and disjoint, and the identity permutation belongs to exactly one class (since it decomposes into $n$ disjoint cycles, and $n$ is either even or odd).\n\n  \u2022 He showed that by multiplying a permutation in one class by a transposition, will result in a permutation in the other class.\n\n  \u2022 He concludes that the two classes are, in fact, the sets of even and odd permutations in $S_n$.\n\n(NB. In earlier versions of this answer I incorrectly labelled this proof as faulty. In fact, this is an excellent proof, and doesn't rely on any auxiliary functions or unrelated concepts.)\n\nI claim all three \"proofs\" of this result (currently) on wikipedia are incomplete. Let's begin with the observation that, assuming that identity permutation is not an odd permutation, then the result follows fairly easily.\n\nTheorem: Assuming the identity permutation is not an odd permutation, then all permutations are either even xor odd.\n\nProof: Let $\\sigma$ be both an even and an odd permutation. Then there exists transpositions $t_i$ and $s_j$ such that \\[\\sigma=t_1 \\circ t_2 \\circ \\cdots \\circ t_k=s_1 \\circ s_2 \\circ \\cdots \\circ s_m\\] where $k$ is even and $m$ is odd. Note that \\[\\sigma^{-1}=s_m \\circ s_{m-1} \\circ \\cdots \\circ s_1.\\]\n\nThen the identity permutation $\\sigma \\circ \\sigma^{-1}$ is the odd permutation \\[t_1 \\circ t_2 \\circ \\cdots \\circ t_k \\circ s_m \\circ s_{m-1} \\circ \\cdots \\circ s_1,\\] giving a contradiction. Thus completing the proof of the theorem.\n\nThe problem is that we cannot just assume that the identity permutation not an odd permutation (yes, it's an even permutation, but what's to stop it being an odd permutation also?), it does not follow from the definition and it is the base case of the \"induction\". To prove it, we need to show that the identity permutation cannot be decomposed into an odd number of transpositions (without using the theorem itself).\n\nHowever, we can deduce from the above theorem that either (a) all permutations are both even and odd or (b) all permutations are either even xor odd.\n\nOn wikipedia: Proof 1 states that the identity permutation is an even permutation (which it is) then assumes that the identity permutation is not also an odd permutation (this is analogous to assuming that a closed set is not an open set). Proof 2 essentially says that we can switch signs by multiplying by a transposition (which is fine, if you know a priori that there exists some permutation that is not even or not odd). Proof 3 neglects the possibility that an even-length word might be equal to an odd-length word.\n\nKeith Conrad also gave a proof that the identity permutation is not an odd permutation here. It is almost a page long (and is the majority of the proof of the result in question).\n\nshare|improve this answer\nI think that the Wikipedia article is technically correct, because it is explicit that the well-definedness of the transposition-based definition is assumed (with a reference). However, I cannot see the point of stating a proof of the equivalence of the inversion-based definition and the transposition-based definition in the article without stating a proof of the well-definedness of the latter. As is often the case with Wikipedia, I do not know whom the article is intended for. \u2013\u00a0 Tsuyoshi Ito Sep 16 '10 at 12:32\n@Douglas: The wiki page has this definition: \"Parity of permutation is the parity of the number of inversion pairs\". This trivially implies that a permutation cannot be both even and odd. \u2013\u00a0 Aryabhata Sep 16 '10 at 18:26\nA permutation can be written as the composition of transpositions in an infinite number of ways... how do you check all infinity of them? [besides, the alarm bells should be going off: you're claiming that the OP's theorem is trivial from the definition] \u2013\u00a0 Douglas S. Stones Sep 17 '10 at 1:37\n@Douglas: What I am claiming is that it depends on the definition. OP never provided one. The wiki page provided one in terms of inversion pairs (transpositions was proven equivalent) and so is probably correct (I didn't go through the whole thing) in assuming it is either even or odd, but not both. The question asked by OP is trivial under the definition in terms of inversion pairs. I do agree, if we go via transpositions, we have work to do. \u2013\u00a0 Aryabhata Sep 17 '10 at 5:01\nHmm... I equated \"inversion pairs\" with \"transpositions\" in the earlier comment (which is incorrect). But there's still an infinite number of ways to write a permutation as the composition of inversion pairs. I'm might be missing something obvious here, but why is this now a no-brainer? \u2013\u00a0 Douglas S. Stones Sep 17 '10 at 5:39\nshow 3 more comments\n\nOne way is to define the sign of a permutation $\\sigma$ using the polynomial $\\Delta = \\Pi (x_i-x_j)$ with $1\\le i < j \\le n$.\n\nIt is easy to see that $\\sigma(\\Delta) = \\Pi (x_{\\sigma(i)}-x_{\\sigma(j)})$ satisfies $\\sigma(\\Delta)=\\pm\\Delta$. Now define the sign by $sign(\\sigma)=\\frac{\\Delta}{\\sigma(\\Delta)}$\n\nWith a little more work you can show that this function is a homomorphism of groups, and that on transpositions it return -1. Therefore, if $\\sigma=\\tau_1\\cdots\\tau_k$ is a way to write $\\sigma$ as a product of transpositions, we have $sign(\\sigma)=(-1)^k$ and so for even permutations (permutations whose sign is 1) k must always be even, and for odd permutations (whose sign is -1) it must always be odd.\n\nshare|improve this answer\nI've often wondered why people use that polynomial instead of simply the integer $\\prod_{1\\le i<j\\le n} (i-j)$, which seems to me more elementary than using a polynomial in several variables. \u2013\u00a0 lhf Sep 16 '10 at 13:56\nI can't see a reason myself. It might be because algebraists are used to working with symmetric polynomials, and this is a private case. \u2013\u00a0 Gadi A Sep 16 '10 at 14:08\n@lhf: The symmetric group cannot act on that integer per se; it acts on the form in which you have expressed it! Thus you are computing with it as if it were a polynomial in which the indexes are names for the variables. \u2013\u00a0 whuber Sep 16 '10 at 15:14\nI think this is proof is really interesting because it's not very difficult and provides an easy way to see that the definition with inversion pairs is equivalent to the one with transpositions. \u2013\u00a0 Joel Cohen Oct 14 '11 at 12:03\n@JoelCohen- good point! You have totally demystified the inversion-pairs definition for me. \u2013\u00a0 Ben Blum-Smith Feb 19 '12 at 0:15\nadd comment\n\nThis is overkill, but it follows from general facts about Coxeter groups as outlined here. In particular, it follows from the fact that $S_n$ has presentation $s_i^2 = 1, (s_i s_{i+1})^3 = 1, s_i s_j = s_j s_i, |i - j| \\ge 2$ (which follows from the faithfulness of the geometric representation) that the homomorphism $s_i \\to -1$ is well-defined.\n\nshare|improve this answer\nAnother general fact about Coxeter groups (the first proposition at qchu.wordpress.com/2010/07/08/the-strong-exchange-condition) also implies that this definition agrees with the definition by inversion number. \u2013\u00a0 Qiaochu Yuan Sep 16 '10 at 19:49\nadd comment\n\nIt is enough to show that the product of an odd number of transpositions cannot be the identity.\n\nEvery permutation of a finite set $S$ is a unique product of disjoint cycles in which every element of $S$ occurs exactly once (where we include fixed points as 1-cycles). Let $p$ be any permutation of $S$, let $(ij)$ be a transposition ($i,j \\in S$), and let $q=p \\cdot (ij)$. It is easy to check that if $i$ and $j$ are in the same cycle in $p$, then that cycle splits into two in $q$; if $i$ and $j$ are in different cycles in $p$, then those cycles merge into one in $q$. Cycles of $p$ not containing either $i$ or $j$ remain the same in $q$. Therefore, $q$ has either one more or one less cycle than $p$ does.\n\nNow let $t$ be any product of an odd number of transpositions. Then by the above, multiplying any permutation by $t$ changes the parity of the number of cycles in the permutation. Therefore $t$ cannot be the identity.\n\nshare|improve this answer\nExcellent answer. Gallian uses this argument. \u2013\u00a0 Stefan Smith Jan 9 '13 at 14:42\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55736/a-problem-in-finite-group-theory?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThis is a problem I encountered in Martin Isaacs' 'Finite Group Theory'. It's located at the end of Chapter II which deals with subnormality, and the particular paragraph is concerned with a couple of not so well-known results which I quote for reference:\n\n(In what follows $F$ is the Fitting subgroup)\n\nTheorem (Zenkov)\nLet $A$ and $B$ be abelian subgroups of the finite group G, and let $M$ be a minimal (in the sense of containment) member of the set {$A \\cap B^g : g \\in G$}. Then $M\\subseteq F(G)$.\n\nAn easy corollary follows which establishes the existence of a subnormal subgroup:\n\nIf $A$ is an abelian subgroup of the finite group $G$ and $|A|\\geq|G:A|$, then $A \\cap F(G)>1$.\n\nIn fact, if $A$ is cyclic, then a normal subgroup is guaranteed:\n\nTheorem (Lucchini)\nLet A be a cyclic proper subgroup of a finite group G, and let $K=core_G(A)$. Then $|A:K|<|G:A|$, and in particular, if $|A|\\geq|G:A|$, then $K>1$.\n\nLet G be a finite group such that $G=AN$, where $A$ is abelian, $N \\unlhd G$, $C_A(N)=1$ and $F(N)=1$. Show that $|A|<|N|$.\n\nNote that, since $N \\unlhd G$, it follows that $F(N)= N \\cap F(G)$. So, if $|A|\\geq|N|$ in the problem, then $|A|\\geq|N:N \\cap A|=|NA:A|=|G:A|$ and the corollary applies to give $A \\cap F(G)>1$.\n\nHow does one proceed from here to obtain a contradiction? In particular, how can the condition on the centralizer be utilized effectively?\n\nshare|improve this question\nI'm not sure this is the right site to visit for this kind of question, which is somewhat advanced but based on a textbook problem. I hope it's not a homework problem. (The issue would be different if you thought you found a serious gap or error in a published proof. Anyway, Isaacs himself is still active in mathematics and could be consulted in that case.) \u2013\u00a0 Jim Humphreys Feb 17 '11 at 18:17\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou were almost there: Since $N$ and $F(G)$ are two normal subgroups intersecting trivially, they commute. But now take a non-trivial element $a \\in A \\cap F(G)$; then by the previous observation, $a$ commutes with every element of $N$. But this contradicts the fact that $C_A(N) = 1$.\n\nshare|improve this answer\nIndeed. What if we replace the condition on the Fitting subgroup with the requirement that A and N have relatively prime orders. Is it still true that |A|<|N|? \u2013\u00a0 user13040 Feb 20 '11 at 23:15\nYes: if $A$ is a $\\pi$-group (where $\\pi$ is a set of primes), then the fact that $A \\cap F(G) > 1$ gives $A \\cap O_\\pi(G) > 1$. Now proceed as in the previous problem with $F(G)$ replaced by $O_\\pi(G)$. \u2013\u00a0 Tom De Medts Feb 21 '11 at 13:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/33834/calculating-impact-force-for-a-falling-object?answertab=oldest\nText:\nTake the tour \u00d7\n\nGood evening, I'm trying to calculate what kind of impact force a falling object would have once it hit something. This is my attempt so far:\n\nBecause $x= \\frac{1}{2} at^2$, $t=\\sqrt{2x/a}$\n$v=at$, therefore $v=a \\sqrt{2x/a}$\n$E_k=\\frac{1}{2} mv^2$, so $E_k=\\frac{1}{2} m(2ax)=m \\cdot a \\cdot x$\nSince $W=E_k=F_i s$, $F_i=E_k/s=(m \\cdot a \\cdot x)/s$\n\nFor an object weighing about as much as an apple, $0.182$ kg, falling $2.00$ m straight down and creating a dent of $0.00500$ m, this would result in:\n\n$$F_i=(m \\cdot a \\cdot x)/s$$\n\n$$F_i=(0.182 \\cdot 9.81 \\cdot 2.00)/0.00500=706 \\, \\text{N}$$\n\nDoes this make any sense? I wouldn't be surprised at all to find out I'm missing something here.\n\nAny input would be appreciated,\n\nthanks in advance!\n\nshare|improve this question\nYou forget air resistance. \u2013\u00a0 sidht Aug 9 '12 at 19:38\nRegarding Qmechanic's edit: While I know this is high-school level physics, please note that this is not, in fact, homework, as the tag would suggest. I do not have any assignment to go from nor any way to look up the answer. \u2013\u00a0 Chris Aug 9 '12 at 20:06\nYour calculations are ok and the model you used (constant hitting force) is reasonable. Though remember that's just a model, real apples hit the ground in a more complicated way, but I think for what you might use your calculations, your model is accurate enough. Unless, of course, you are not allow for the apple to bounce. \u2013\u00a0 Yrogirg Aug 10 '12 at 8:20\nRead all replies and marked an answer, thanks all for your help! \u2013\u00a0 Chris Aug 10 '12 at 9:29\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nIf your apple falls $2m$ it's velocity is calculated using the equation you give:\n\n$$ v^2 = 2as $$\n\nand you get $v^2 = 39.24 \\space m^2s^{-2}$ (I've haven't taken the square root for reasons that will become obvious). You know the apple is slowed to rest in $0.005m$, so you just need to work out what acceleration is needed when $v^2 = 39.24$ and $s = 0.005$. A quick rearrangement of your equation gives:\n\n$$ a = \\frac{v^2}{2s} $$\n\nand plugging in $v^2 = 39.24$ and $s = 0.005$ gives $a = 3925 \\space ms^{-2}$. To get the force just use Newton's equation:\n\n$$ F = ma $$\n\nwhere $m$ is the mass of the apple, $0.18 kg$, and you get $F = 706.32N$. So you got the correct answer (my answer differs from yours only because I used $g = 9.81 \\space ms^{-2}$).\n\nTo get a more general result substitute for $v^2$ in the second equation to get:\n\n$$ F = ma = m\\frac{2gs_1}{2s_2} = mg\\frac{s_1}{s_2}$$\n\nwhere $s_1$ is the distance the apple falls and $s_2$ is the distance it takes to stop.\n\nshare|improve this answer\nExactly what I was looking for, explanation and confirmation. Thank you very much! \u2013\u00a0 Chris Aug 10 '12 at 9:26\nadd comment\n\nI would have done this calculus if there was a uniform constant breaking force applied all all along the trajectory and if at impact, the ball had a zero velocity. The work done by such a force must exactly balance the initial mechanical energy of the ball. For a shock, I would rather use something like: d(mV)/dt=mg-F and use for instance a contact time dt=0.001s\n\nBefore impact: v=sqrt(2*g*x) After impact: v=0 Duration of the impact: dt=0.001s\n\n\nF=1140 N\n\nshare|improve this answer\nadd comment\n\nI'm not sure where you're going with the .0050 being treated as time, unless you meant to say it's in contact with the ground for .005 seconds. In that case, what you have would work algebraically.\n\nshare|improve this answer\nadd comment\n\nCalculate Potential energy using the following formula $PE = mgh = 0.182 \\cdot 9.81 \\cdot 2\\: \\mathrm{Joules}$\n\nAverage Impact Force = $0.182 \\cdot 9.81 \\cdot 2 \\cdot 0.005\\: \\mathrm{Newtons}$ (that is the answer)\n\nshare|improve this answer\nadd comment\n\nprotected by Qmechanic May 12 at 0:00"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234782/cyclotomic-polynomials\nText:\nTake the tour \u00d7\n\nLet $E(n)$ denote an nth root of unity. (For convenience, we may take $E(n) = \\exp(\\frac{2\u03c0i}{n})$.)\n\nProve that for any prime $p$ and any natural number $r$, we have $$ \\prod_{\\substack{j\\\\ \\gcd(p^r, j) = 1}} \\left(1 \u2013 E(p^r)^j\\right) = p,$$ without using the formula to get the cyclotomic polynomial of $p^r$.\n\nshare|improve this question\nWithout using what formula? And why without using it? \u2013\u00a0 Phira Nov 11 '12 at 10:49\n@Phira, because with using the formula it would be really direct. I wanted to see a proof without using the formula. The formula is Phi(x) = sum i= 1 to p-1 ( x^(i*p^(k-1))) \u2013\u00a0 John Chang Nov 11 '12 at 13:20\nIt should be $\\displaystyle{\\prod_{\\left(p^r,j\\right)=1} \\left(1 \u2013 E\\left(p^r\\right)^j\\right) = p^r}$. \u2013\u00a0 P.. Nov 12 '12 at 11:57\n@Pambos, the cyclotomic polynomial of p^r, Phi(x) = sum i= 1 to p-1 ( x^(i*p^(k-1))) gives us that it is indeed p. I think. But I wanted to see a more detailed proof without using this formula. \u2013\u00a0 John Chang Nov 12 '12 at 12:00\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nLet $n$ be a natural number and let $E_n=e^{2\\pi i/n}$. Then the polynomial $x^n - 1$ splits in $\\mathbb{Q}(E_n)$ as\n\n$x^n - 1 = (x - 1)(x - E_n)\\cdots(x-E_n^{n-1})$, which yields:\n\n$1+x+\\cdots+x^{n-1} = \\frac{x^n-1}{x-1} = (x - E_n)(x - E_n^2)\\cdots(x-E_n^{n-1})$\n\nand so we get the following result.\n\n$\\prod_{j=1}^{n-1}(1-E_n^j) = n$\n\nNow let $n = p^m$, for some natural number $m$. Thus,\n\n$p^m = \\prod_{j=1}^{p^m-1}(1-E_{p^m}^j) = \\prod_{(j, p^m)=1}(1-E_{p^m}^j)\\prod_{(j, p^{m-1})=1}(1-E_{p^{m-1}}^j)\\cdots\\prod_{(j, p)=1}(1-E_p^j)$\n\nNow look at the right side of the last equation. Each product $\\prod_{(j, p^r)=1}(1-E_{p}^j)$ is greater than 1, and there are a total of $m$ factors of this form. Since the product of these $m$ factors is $p^m$, then each factor must be equal to $p$.\n\nTherefore, $\\prod_{(j, p^r)=1}(1-E_{p^r}^j) = p$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/240175/computing-lim-n-rightarrow-infty-sqrtn1-sqrtn2-cdots-sqrtn2\nText:\nTake the tour \u00d7\n\nI'm trying to find:\n\n$$ \\lim_{n\\rightarrow\\infty} (\\sqrt[n]{1}+\\sqrt[n]{2}+\\cdots+\\sqrt[n]{2007}-2006)^n $$\n\n(Problem from CMJ)\n\nWe have:\n\n$$ k^{1/n}=1+\\frac{\\ln k}{n}+O(1/n^2) $$\n\n$$ \\left( \\sum_{k=1}^{2007}k^{1/n}-2006 \\right)^n= \\left(1+\\frac{1}{n}\\sum_{k=1}^{2007}\\ln k+O(1/n^2) \\right)^n \\sim_{n\\rightarrow\\infty} \\exp \\left( \\sum_{k=1}^{2007} \\ln k \\right)(=2007!)$$\n\nI'm quite sure of my result but I could not check it numerically.\n\nDo you agree with this limit?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nYes. Your limit looks fine. You can simplify it further into $$\\exp \\left( \\sum_{k=1}^{2007} \\log (k) \\right) = \\exp \\left( \\log \\left(\\prod_{k=1}^{2007} k \\right) \\right) = \\exp \\left( \\log (2007!) \\right) = 2007!$$\n\nshare|improve this answer\nOK, thank you Marvis! \u2013\u00a0 Chon Nov 18 '12 at 22:24\nadd comment\n\nTake the log of your expression and replace $x=\\frac{1}{n}$, you get the expression:\n\n$$\\frac{\\log\\left((\\sum_{k=1}^{2007} k^x) - 2006\\right)}{x}$$\n\nFirst, show the numerator approaches zero as $x\\to 0$. Then apply L'Hopital's rule, yielding a limit:\n\n$$ \\sum_{k=1}^{2007} \\log k = \\log 2007!$$\n\nThat is the log of your limit, so your limit is $e^{\\log 2007!}=2007!$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/79373/some-questions-concerning-a-random-number-process/79387\nText:\nTake the tour \u00d7\n\nConsider the following Markov process: Start with an integer $N = N_0$. Now repeatedly choose an $N_i$ uniformly at random in the range $[1...N_{i-1}]$ until $N_i = 1$ at which point one terminates the process. This produces a nonincreasing integer sequence $\\{N_0,N_1,\\ldots,N_{k-1},N_k = 1\\}$.\n\nExperimental evidence shows that as $N_0$ grows large, the expected length $E(N_0)$ of such a sequence seems to approach $ln(N_0)$. Equivalently, one expects that the average over many steps of $N_i/N_{i+1}$ is approximately $e$. Convergence to this expectation is slow however; for example if $N_0$ is a 1000-bit integer one finds that $E(N_0)$ satisfies roughly $2.71^{E(N_0)} = N_0$ and in particular the base agrees with $e$ to only around 2 decimal places.\n\nBecause the $N_i$ were chosen uniformly at random, for any given $i$ the expectation of $N_i/N_{i+1}$ is 2, so this seems to contradict the above observation that the average of $N_i/N_{i+1}$ is approximately $e$. To understand this discrepancy, consider a toy example where $N_1 = qN_0$ and $N_2 = (1-q)N_1$ for some $0\\leq q\\leq 1$. One sees that $N_2 \\leq \\frac{1}{4}N_0$ with equality iff $q=\\frac{1}{2}$; clearly the average of the step ratios $q$ and $1-q$ is equal to the expected single step ratio $\\frac{1}{2}$, but the composition of the steps has led to an overall decrease in the sequence at a rate faster than division by 2. Hence the above observation that the overall step decrease rate is approximately division by $e$ is plausible.\n\nMain Question: How does one understand the appearance of $e$ in the expected step down rate (as opposed to some other constant)? Presumably it should appear as a result of some averaging of all possible step ratios, but I can't seem to see what the correct average to be considering is.\n\nSecondary question: At the risk of being vague, does anyone know what an inverse to this process looks like? That is, a process where $M_0 = 1$ and at each step one chooses an $M_i\\geq M_{i-1}$ at random such that the expected growth rate is roughly multiplication by $e$ but such that the expected growth at any step should be multiplication by 2. Clearly one cannot choose the next number uniformly at random since this would lead to infinite step and expected growth, so what probability distribution (if any) can be put on the integers greater than $N_i$ so that choosing a next element will lead to a process which looks roughly like the original process in reverse?\n\nshare|improve this question\nAbout the main question: $e^{-1}=\\lim_{n\\to \\infty}(1-1/n)^n$: if $N_i$ is close to $N_{i-1}$ then the process takes longer. \u2013\u00a0 Mark Sapir Oct 28 '11 at 12:09\nWhen I answered this question I didn't realize I knew its author. Hi! \u2013\u00a0 Michael Lugo Oct 28 '11 at 13:50\nThanks for the various explanations everyone... the $e$ appearing as the result of geometric means is obvious in retrospect. \u2013\u00a0 ARupinski Oct 28 '11 at 23:02\nadd comment\n\n5 Answers\n\nup vote 9 down vote accepted\n\nFor the main question, your process is \"roughly\" the same as the one starting at $N_0=N$, and defined by $N_{i+1} = U_{i+1} N_{i}$, where $U_i$ are iid uniform in $[0,1]$. I guess that the \"roughly\" can be easily made more precise.\n\nFor this modified process, your question becomes: what is $k(N)$, the smallest $k$ such that $U_1\\dots U_k < 1/N$, or equivalently $\\ln U_1 + \\dots + \\ln U_k < -\\ln N$?\n\nBut the expected value of $\\ln U$ is $-1$, so that by the law of large numbers $\\ln U_1 + \\dots + \\ln U_k$ is equivalent to $-k$, which give that $k(N) \\sim \\ln N$.\n\nEdit: the following coupling argument makes the \"roughly\" more precise, as requested in the comments.\n\nGiven $(U_i)_{i \\geq 1}$ an iid sequence of uniform variables in $[0,1]$ and an integer $N$, consider the two processes $N_i$ and $\\widetilde N_i$ defined by $N_0 = \\widetilde N_0 = N$, and $N_{i+1} = U_{i+1} N_i$, and $\\widetilde N_{i+1} = 1+E(U_{i+1} \\widetilde N_i)$, where $E(\\cdot)$ is the integer part. The inequalities $N_i \\leq \\widetilde N_i \\leq N_i+i$ are obvious, and the process $\\widetilde N$ has the same law as the process described in the question.\n\nshare|improve this answer\nMikael: If the roughly can easily be made more precise, why do you omit the proof? This reminds of the old warning that when a mathermatician declares something is trivial but does not prove it, something is amiss... :-) (Nice post, by the way.) \u2013\u00a0 Did Oct 29 '11 at 16:47\nDidier: I did not have time to expand my answer (and check the details) when I first wrote it. But this is now done. \u2013\u00a0 Mikael de la Salle Oct 30 '11 at 20:26\nI agree with you that sentences containing \"can easily be made more precise\" can look suspicious... but I believe that my answer was enough for MO, which is meant for research-level questions (and I am sure that any researcher with some interest in the question could have made the roughly more precise). :-) \u2013\u00a0 Mikael de la Salle Oct 30 '11 at 20:34\nOn $[k(N)=i]=[N_i<1\\leqslant N_{i-1}]$, $\\widetilde{N}_i<i+1$ and $1\\leqslant \\widetilde{N}_{i-1}$, hence $\\widetilde{k}(N)\\geqslant i$ is all one can be sure of. It seems $\\widetilde{k}(N)$ may be quite larger than $k(N)$ when $N$ is large hence this comparison is not enough to characterize the asymptotic behaviour of $\\widetilde{k}(N)$. Or maybe you know how to bound the difference between $k(N)$ and $\\widetilde{k}(N)$, using arguments not in the post... \u2013\u00a0 Did Nov 2 '11 at 20:58\nI agree with you. If one wants to prove with this method that $a_N := E(\\widetilde k(N))\\sim\\ln N$, there is some more work: what follows from the coupling argument is that $a_N \\leq E(k(N)+a_{k(N)})$. One then uses some a priori bound on $a_N$ (as $a_N\\leq 2N$). But I think that the shortest way to prove that $a_N \\sim \\ln N$ is using Markov's property to express $a_N$ in term of the $a_n$'s for $n < N$ as Byron Schmuland explains. My answer was more meant as an informal explanation for the $1/e = \\exp(E(ln U))$ appearing instead of $1/2 = E(U)$. \u2013\u00a0 Mikael de la Salle Nov 3 '11 at 0:33\nadd comment\n\nRegarding the secondary question: If we start the process from a large $N$, it will always reach 1 sooner or later. The probability that it passes through the number 2 is $1/2$, since as long as the numbers are larger than 2, going in the next step to 2 is as likely as going to 1, and when the process reaches 1 or 2 for the first time, where it went decides whether it ever passes through 2. Similarly the probability that the process ever visits a number $n$ is $1/n$, since this happens precisely when the first visit to any of $1,\\dots,n$ is to $n$.\n\nNow it's easy in principle to see what the inverse is: For each pair of numbers $m < n$, the probability that a process starting at a larger $N$ will include a step from $n$ to $m$ is $$\\frac1{n(n-1)},$$ since it will reach $n$ with probability $1/n$, and the next number distinct from $n$ is uniform on $1,\\dots,n-1$. In particular, for \"infinite $N$\", the last number visited before reaching 1 is $n$ with this probability.\n\nFor $m>1$, the probability that $m$ was reached from $n$ given that the process reached $m$ is $m/(n(n-1))$, since we get a factor $m$ from conditioning on the process ever reaching $m$. It might be easier to sort out the details if we assume that the process never repeats the same number.\n\nADDED: The inverse process constructed this way has the property that at any $m$, the expectation of the next (previous in the original process) step is infinite. But it does have the nice property that the probability of going from $m$ to a number $\\leq 2m$ is $1/2$, so the median growth factor over one step is 2.\n\nNEW UPDATE: If we discard repetitions, then one way to understand the inverse is that from a number $m$, the next step is $$m\\mapsto \\left\\lceil\\frac{m}{U}\\right\\rceil,$$ where $U$ is uniform on the interval $[0,1]$. When $m$ is large, the growth factor is therefore asymptotically the reciprocal of a uniform $[0,1]$, which is the same thing as an \"exponential of an exponential\" ($e$ to an exponential variable). The median growth factor over one step is 2, but over a large number of steps approaches $e$.\n\nshare|improve this answer\nThe first paragraph also shows that the expected number of steps is exactly $1 + (1/2) + (1/3) + \\cdots + (1/N) = H_N = \\log(N) + C + O(1/N)$ where $C = 0.5772157\\ldots$ is the Euler(-Mascheroni) constant. This explains the OP's observation that $E(N)$ looks like $\\log N$ but the convergence in $N^{1/E(N)} \\rightarrow e$ is slow. \u2013\u00a0 Noam D. Elkies Oct 30 '11 at 1:33\nadd comment\n\nUsing Markov chain theory, it is not hard to show that the expected time until the process hits state \"1\" starting at $N_0$ is $1+1+1/2+\\cdots+1/(N_0-1)$.\n\n\nIn my previous answer, I mistakenly chose a new state uniformly from $[1,\\dots, N_i]$ instead of $[1,\\dots, N_{i-1}]$. The expected hitting time of state \"1\" for the OP's model starting at $N_0$ is $1+1/2+\\cdots+1/(N_0-1)$. This is one less than my first answer.\n\nshare|improve this answer\nadd comment\n\nThe average you want in the main question is the geometric mean, as Mikael de la Salle has already alluded to.\n\nAbout the secondary question: I'd start by looking for a random variable $X$, which always takes value at least 1, which has expectation 2 and geometric mean $e$. Let $X_1, X_2, \\ldots$ be independent, and let each have the distribution of $X$. Then take $M_i$ to be $M_{i-1} X_i$ rounded to the nearest integer. Unfortunately there is no such random variable, by the arithmetic-geometric mean inequality. So it seems very likely to me that there is no such process.\n\nshare|improve this answer\nExpectation is actually supposed to be the harmonic mean of [0,1], not the arithmetic mean. The harmonic mean is, of course, infinite. Such a random variable exists, and can, in fact, be derived from the above solution by Johan. \u2013\u00a0 Will Sawin Oct 28 '11 at 17:35\nYou're right! My proof of nonexistence didn't feel right to me, but I think I hadn't had coffee yet. \u2013\u00a0 Michael Lugo Oct 28 '11 at 18:41\nadd comment\n\nThe process described is also known as the stick-breaking process for sampling the cycle type of a uniformly chosen permutation in $S_n$. So we have the set $[n]$ and we want to choose a uniformly random permutation $\\sigma$ in $S_n$, viewed as an automorphism of $[n]$. So we can choose $n$ target values for $\\sigma(1)$ and $n-1$ values for $\\sigma(\\sigma(1))$ etc. This process stops when $\\sigma^k(1) = 1$ for some least $k > 0$. It's an easy computation to show that the chance that the process stops at step $k$ is always $1/n$ regardless of what $k$ is: for instance, if $k = 1$, then that means $1$ has to map to itself, which if done uniformly has chance $1/n$, and if $k=2$, then there are $n-1$ out of $n$ choices for $\\sigma(1)$ (because we have to exclude $1$), and $1$ out of $n-1$ choices for $\\sigma(\\sigma(1))$, namely it has to be $1$. So the probability in that case is $\\frac{n-1}{n} \\frac{1}{n-1} = 1/n$ again! This corresponds to a uniform \"cut\" in $[n]$ such that everything to the left of that cut gives the length of the cycle containing $1$. Now we continue by picking a number not in the first cycle, and the process is indeed self-similar by inspection.\n\nThe number of cycles of a ramdom permutation is concentrated at $\\log n$ with variance $\\log n$ and satisfies a Central limit theorem. Therefore we expect $\\log n$ on average for the finishing time of the original problem.\n\nshare|improve this answer\n+1, but you should explain your answer. \u2013\u00a0 Ori Gurel-Gurevich Oct 31 '11 at 1:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96292/a-hard-diophantine-equation\nText:\nTake the tour \u00d7\n\nHello !\n\nI would like prove that the following diophantine equation is unsolvable: $m!+27=n^3$.\n\nThanks in advance.\n\nshare|improve this question\nWhe does this question arise? \u2013\u00a0 Captain Oates May 8 '12 at 5:28\nStrictly speaking, I don't think that's a Diophantine equation. . . \u2013\u00a0 Noah S May 8 '12 at 7:43\nBut the more interesting so... \u2013\u00a0 Felix Goldberg May 8 '12 at 8:28\nI think the question is interesting especially in view of GH's answer, and should stay open. \u2013\u00a0 Mark Sapir May 9 '12 at 2:14\nThere's an excellent paper of Berend and Harmse [Trans. AMS 358 (2005)] which treats equations of the shape $m!=p(x)$ for various polynomials $p(x)$ (generalizing an old problem of Brocard). The (very nice) argument of GH is evident in section 4, applied to, for example, to $p(x)=x (x^2+1)$. \u2013\u00a0 Mike Bennett May 10 '12 at 3:53\nshow 5 more comments\n\n1 Answer\n\nup vote 28 down vote accepted\n\nI am happy to report that the equation has no solution. I kept my original response, and put the remaining arguments in the \"EDIT\" section below.\n\nHere is a quick proof that there are only finitely many solutions.\n\nWe use $m!=(n-3)(n^2+3n+9)$. Here $n$ is divisible by $3$, hence $n^2+3n+9$ is not divisible by any prime $p\\equiv 2\\pmod{3}$. In other words, all the prime divisors $p\\equiv 2\\pmod{3}$ of $m!$ are contained in $n-3$ with multiplicity. It follows, with the usual notations, that\n\n$$ \\frac{\\log m!}{3}>\\log(n-3)\\geq\\sum_{p\\equiv 2 \\ (3), \\ p\\leq m}v_p(m!)\\log p> \\sum_{p\\equiv 2\\ (3), \\ p\\leq m} \\left(\\frac{m}{p}-1\\right)\\log p.$$\n\nThe left hand side is $\\sim (m\\log m)/3$, while the right hand side is $\\sim (m\\log m)/2$ by Dirichlet's theorem. Hence for large $m$ the inequality must fail.\n\nEDIT. Assume that $m\\geq 1000$, and denote by $\\chi$ the nontrivial character modulo $3$. Then $$ \\sum_{p\\leq m}\\frac{\\chi(p)\\log p}{p}<\\sum_{n\\leq m}\\frac{\\chi(n)\\Lambda(n)}{n}-\\sum_{p\\leq m,\\ p\\neq 3}\\frac{\\log p}{p^2+p}. $$ This implies, in combination with some ideas of Bordelles (cf. the proof of (4.2) here), that $$ \\sum_{p\\leq m}\\frac{\\chi(p)\\log p}{p}<3\\left|\\frac{L'(1,\\chi)}{L(1,\\chi)}\\right|+1.53<2.64\\ .$$ By including the contribution of the prime $p=3$ to $n-3$ in the original inequality, and using also some classical bounds by Rosser and Schoenfeld (cf. (3.15) and (3.21) here), it follows that $$\\frac{m(\\log m-0.9)}{3}>\\frac{m(\\log m-6.1)}{2}\\quad\\text{for}\\quad m>e^{16.5}.$$ Hence $m < e^{16.5}$. I checked with SAGE that in fact $$\\sum_{p\\leq m}\\frac{\\chi(p)\\log p}{p}<-0.63\\quad\\text{for}\\quad e^{16.5}>m>e^{7}.$$ This can be used to improve the previous bound to $$\\frac{m(\\log m-0.99)}{3}>\\frac{m(\\log m-2.92)}{2}\\quad\\text{for}\\quad e^{16.5}>m>e^{7},$$ which in turn forces $m < 1000$. The above shows that all solutions of the original equation satisfy $m < 1000$. However, I checked with SAGE that in this range the equation has no solution.\n\nshare|improve this answer\nThank you so much GH, now it is interesting find an upper bound for $m$ such that we can begin a computer search. \u2013\u00a0 Roberto Bosch Cabrera May 8 '12 at 14:51\nThis problem arise (it is the hard part) when we try to solve the equation: $x!+y!+3=Z^3$ which was proposed as $J198$ in Mathematical Reflections. I think that the solution can be found in (1) renyi.hu/~p_erdos/1937-09.pdf (2) ams.org/journals/tran/2006-358-04/S0002-9947-05-03780-3/\u2026 but I'm not sure. I'm trying to find an \"elementary\" solution. \u2013\u00a0 Roberto Bosch Cabrera May 8 '12 at 15:14\nIt seems that Erd\u0151s's paper contains everything needed for a solution. Namely, we are dealing with (8), where $p=3$ and $y=3$. Hence (10) needs to be adjusted slightly: $B_2\\leq 27 T(n,6)$. From here it should be easy to finish the solution. At the heart of the argument is (Va), which is a clever explicit substitute of Dirichlet's theorem. \u2013\u00a0 GH from MO May 8 '12 at 16:06\n@GH: Thank you for your new Edit proving that $m<10^{12}$. \u2013\u00a0 Roberto Bosch Cabrera May 8 '12 at 23:24\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/114945/mutually-tangent-ellipsoids-in-3-space/115059\nText:\nTake the tour \u00d7\n\nI recently heard a claim that for any n, it is possible to arrange n ellipsoids in 3 space such that each pair of ellipsoids is kissing. Is this true, and if so, how?\n\nEdit: By kissing, I mean that I would like the interiors of the ellipsoids to be disjoint, but each pair of ellipsoids should intersect at a point.\n\nshare|improve this question\n\"kissing\" might mean different things... \u2013\u00a0 Anton Petrunin Nov 30 '12 at 0:11\nThere was a MathOverflow post some months back mentioning work of Jeff Erickson on n convex bodies that were cotangent. (Some kind of voronoi cells of points on a helix.) Perhaps someone can guide you and extend it to ellipsoids. Gerhard \"Ask em About System Design\" Paseman, 2012.11.29 \u2013\u00a0 Gerhard Paseman Nov 30 '12 at 1:03\nI think she means that the solid ellipsoids have disjoint interiors, but nevertheless all their pairwise intersections are non-empty. Kissing, yes, but nothing more! \u2013\u00a0 alvarezpaiva Nov 30 '12 at 14:26\nThanks for the comments and ideas. I added in what I mean by kissing, which, as many guessed, includes disjoint interiors. If I should have used another word, please let me know! \u2013\u00a0 Linda Brown Westrick Dec 1 '12 at 1:33\nadd comment\n\n3 Answers\n\nHere is the paper that Gerhard remembered, which doesn't answer the question as posed, but does answer a related question:\n\nJeff Erickson and Scott Kim, \"Arbitrarily large neighborly families of congruent symmetric convex 3-polytopes,\" 2003. (link)\n\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Erickson Fig\nThat their paper does not mention ellipsoids might be taken as indirect evidence that the posed question may not yet have been answered a decade ago.\n\nshare|improve this answer\nadd comment\n\nI've never heard of this before, and it sounds quite counterintuitive. If one is granted that this is true, then one can try to work backwards and apply a bit of dimensional analysis to understand how this can be.\n\nFirst, note that ellipsoids are quadrics, and there are a $9$ dimensional space of quadrics. Also, note that ellipsoids are invariant under affine (or more generally projective) transformations, so if we have one such configuration, we will expect to get at least a $15$-dimensional family of kissing ellipsoids.\n\nOn the other hand, there are degenerate quadrics for which this is true. Consider $n$ mutually non-parallel lines in the plane. We can consider these as degenerate ellipsoids, with two axes $0$ radius and one axis $\\infty$ radius. They the are each mutually tangent, since they each meet in a point. There is an $2n+3$-parameter family of these. One could hope to \"regenerate\" families of $n$ tangent ellipsoids from these, but there might be restrictions on when this is possible.\n\nFor $n=1$, there is a $9$ dimensional family.\n\nFor $n=2$, there is a $17=9+8$ dimensional family. We have $9$ dimensions for the first ellipsoid. Choosing any other ellipsoid with center disjoint from the first, we may rescale it uniquely to be tangent to the first ellipsoid. So this gives us $8$ dimensions for the second ellipsoid.\n\nFor $n=3$, let's assume that one of the ellipsoids is a sphere. Then its center is equidistant from the other two ellipsoids. The space of points equidistant from two kissing ellipsoids is $2$-dimensional. So we get a $17+2=19$-dimensional space of 3 tangent ellipsoids, with one round. We may change the round sphere by an affine transformation based at its center to get any ellipsoid with the same center, and we have a $6$-parameter family of such affine maps (we have $3$ dimensions for the major axis, $2$ for the minor axis, and $1$ for the third axis). However, this over-counts, since a similarity (all $3$ axes equal) will take the sphere to a sphere, so this gives us $19+6-1=24$ dimensions (or we may take a $5$-parameter family of volume-preserving affine transformations to eliminate repetitions).\n\nFor $n=4$, let's again assume that one of the ellipsoids is a sphere. The space of points equidistant from $3$ ellipsoids is $1$-dimensional. As above, we may modify the sphere by a $5$-parameter family of volume-preserving affine transformations to get $24+1+5=30$ dimensions of 4 mutually tangent ellipsoids.\n\nFor $n=5$, we expect finitely many points which are equidistant from $4$ mutually tangent ellipsoids, so the computation gives $35$ dimensions.\n\nAt this point, one expects adding the next sphere will cut down on the dimension of the space of 5 tangent ellipsoids which have an equidistant point. If we continue the sequence $9,17,24,30,35$, then the next term ought to be $39$ dimensions ($42, 44, 45, ?$). Of course, this trend couldn't possibly continue if one expects to have $n$ tangent ellipsoids for all $n$, so there must be some non-generic phenomenon creating the incidence.\n\nshare|improve this answer\nadd comment\n\nI'm assuming \"kissing\" means osculating, i.e. the ellipsoids intersect at a point where they have second-order contact, i.e. in a coordinate system where the point of contact is the origin and the tangent plane is the $xy$ plane, near the origin we have $z = a x^2 + b x y + c y^2 + O((|x|+|y|)^3)$ for the same $a,b,c$. Well, e.g. this is true for the ellipsoids $$ x^2 + y^2 + b (z - 1/b)^2 = 1/b,\\ b > 0$$ which are all mutually osculating at the origin.\n\nOr did you want each pair to be osculating at a different point?\n\nshare|improve this answer\nI suspect the asker wanted the interiors of the ellipsoids to be disjoint. \u2013\u00a0 Graham Leuschke Nov 30 '12 at 3:02\nMe too. Otherwise why not just use ellipses in two dimensions rather than ellipsoids in three? \u2013\u00a0 Noam D. Elkies Nov 30 '12 at 3:24\nThey couldn't be osculating if the interiors are disjoint. \u2013\u00a0 Robert Israel Nov 30 '12 at 3:42\nKissing usually means disjoint interior plus tangent; one does not ask for osculation. \u2013\u00a0 Beno\u00eet Kloeckner Nov 30 '12 at 17:07\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/65424/determinant-of-sum-of-positive-definite-matrices/65430\nText:\nTake the 2-minute tour \u00d7\n\nSay $A$ and $B$ are symmetric, positive definite matrices.\n\nI've proved that $\\det(A+B) \\ge \\det(A) + \\det(B)$ in the case that $A$ and $B$ are two dimensional.\n\nIs this true in general for $n$-dimensional matrices?\n\nIs it even true that $\\det(A+B) \\ge \\det(A)$ [as this would also be enough..]\n\n\nshare|improve this question\n\n6 Answers 6\n\nup vote 32 down vote accepted\n\nThe inequality $$\\det(A+B)\\geq \\det A +\\det B$$ is implied by the Minkowski determinant theorem $$(\\det(A+B))^{1/n}\\geq (\\det A)^{1/n}+(\\det B)^{1/n}$$ which holds true for any non-negative $n\\times n$ Hermitian matrices $A$ and $B$. The latter inequality is equivalent to the fact that the function $A\\mapsto(\\det A )^{1/n}$ is concave on the set of $n\\times n$ non-negative Hermitian matrices (see e.g., A Survey of Matrix Theory and Matrix Inequalities by Marcus and Minc, Dover, 1992, P. 115 and also the previous MO thread).\n\nshare|improve this answer\nlooks nice, but isn't it somewhat overkill to invoke the Minkowski theorem here? \u2013\u00a0 Suvrit May 19 '11 at 17:05\nThanks very much! \u2013\u00a0 user15221 May 19 '11 at 17:44\nThis is really misleading since it makes the question look like complicated, while is almost obvious that $\\det(A+B) = \\det(A) \\det(1+A^{-1/2}BA^{-1/2}) \\geq \\det(A) (1+\\det(A^{-1/2}BA^{-1/2})) = \\det(A) + \\det(B)$. In the second step, it is just used that $\\prod_i (1+ \\mu_i) \\geq 1 + \\prod_i \\mu_i$, where $\\mu_i$ are the eigenvalues of $A^{-1/2}BA^{-1/2}$. \u2013\u00a0 Andreas Thom Jun 28 at 20:02\n\nYet another way to see this is to note that $A = \\overline{Q}^{t}Q$ for some invertible matrix $Q$. Then ${\\rm det}(A+B) = |{\\rm det}(Q)|^{2}{\\rm det}{( I + (\\overline{Q}^{-1}})^{t}BQ^{-1})$.` Now $(\\overline{Q}^{-1})^{t}BQ^{-1}$ is Hermitian, and positive definite. It suffices to prove that if $X$ is positive definite and Hermitian, then ${\\rm det}(I+X) \\geq (1 + {\\rm det}X)$. We may conjugate $X$ by a unitary matrix $U$ and assume that $X$ is diagonal. Let the eigenvalues of $X$ be $\\lambda_{1},\\ldots, \\lambda_{n}$, (allowing repetitions). Then ${\\rm det}(I+X) = \\prod_{i=1}^{n}(1 + \\lambda_{i}) \\geq 1 + \\prod_{i=1}^{n} \\lambda_{i} = 1 + {\\rm det}X.$ Such an argument appears in some proofs by R. Brauer, though I do not know whether it originates with him.\n\nLater edit: Incidentally, I think that with the arithemetic-geometric mean inequality and a slightly more careful analysis, you can see by this approach that for $X$ as above, you do have ${\\rm det}(I+X) \\geq (1 +({\\rm det}X)^{1/n})^{n}$ (a special case of the inequality of Minkowski mentioned in the accepted answer, but enough to prove the general case by an argument similar to that above). For set $d = {\\rm det}X$. Let $s_{m}(\\lambda_{1},\\ldots ,\\lambda_{n})$ denote the $m$-th elementary symmetric function evaluated at the eigenvalues. Using the arithmetic-geometric mean inequality yields that $s_{m}(\\lambda_{1},\\ldots ,\\lambda_{n}) \\geq \\left( \\begin{array}{clcr} n\\\\m \\end{array} \\right)d^{m/n}$, so we obtain ${\\rm det}(I+X) \\geq (1+d^{1/n})^{n}.$\n\nshare|improve this answer\n\nWe have $((A+B)x,x)\\ge (Ax,x)$. It then follows from the variational characterization of eigenvalues (min-max theorem) that the eigenvalues of $A+B$ are greater than or equal to those of $A$. This implies $det(A+B)\\ge det(A)$.\n\nshare|improve this answer\n\nHere is yet another overkill, but hopefully not too bad a way to prove this inequality.\n\nWe have the following proof sketch.\n\n$$\\begin{eqnarray} x^T(A+B)x &\\ge& x^TAx\\quad\\forall x\\\\\\\\ -x^T(A+B)x &\\le& -x^TAx\\\\\\\\ \\exp(-x^T(A+B)x) &\\le& \\exp(-x^TAx)\\\\\\\\ \\int\\exp(-x^T(A+B)x)dx &\\le& \\int\\exp(-x^TAx)dx\\\\\\\\ \\frac{1}{\\sqrt{\\det(A+B)}} &\\le& \\frac{1}{\\sqrt{\\det(A)}}\\\\\\\\ \\det(A+B) &\\ge& \\det(A) \\end{eqnarray} $$\n\nThe only fancy thing that happened is in the second last line, where I used the formula for the Gaussian integral (see multivariate section)\n\nshare|improve this answer\n\nThe determinant of a positive definite matrix $G$ is proportional to $(1/\\hbox{Volume}(\\mathcal B(G)))^2$ where $\\mathcal B(G)$ denotes the unit ball with respect to the metric defined by $G$. If $A$ and $B$ are positive definite then the volume of $\\mathcal B(A+B)$ is smaller than the volume of $\\mathcal B(A)$ or $\\mathcal B(B)$.\n\nshare|improve this answer\nIt's worth noting that this is secretly the same as Suvrit's answer. \u2013\u00a0 Mark Meckes May 20 '11 at 14:20\nNot really: You don't need exponentials for proving that $\\det(G)$ is proportional to $1/\\hbox{Volume}(G)^2$ : It is enough to stare at an orthogonal basis formed of eigenvectors for $G$. In this sense this proof is more elementary. \u2013\u00a0 Roland Bacher May 25 '11 at 7:18\nFair enough.$ $ \u2013\u00a0 Mark Meckes May 29 '11 at 0:49\n\nLet me add some more. If $A, B, C$ are positive semidefinite, then $$\\det (A+B+C)+\\det C\\ge \\det (A+C)+\\det (B+C). \\quad (\\star)$$\n\nWhen $C=0$, this reduces to OP's question.\n\nA remarkable extension of ($\\star$) were recently obtained by V. Paksoy, R. Turkmen, F. Zhang [ Electron. J. Linear Algebra 27 (2014) 332-341], which says that the determinant functional can be replaced by any generalized matrix function.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/322851/on-the-precise-asymptotic-scaling-of-n-n-k-as-n-k-to-infty\nText:\nTake the 2-minute tour \u00d7\n\nOn page 23 of [Erd\u0151s+R\u00e9nyi 1960, \"On the evolution of random graphs\"], the following asymptotic formula is stated without proof: $$ \\binom{n}{k} \\sim \\frac{n^k \\mathrm e^{-\\frac{k^2}{2n} - \\frac{k^3}{6n^2}}}{k!} $$ valid for $k \\in o(n^{\\text{[some illegible fraction]}})$. That is, we have $$ \\frac{n!}{(n-k)!} \\;=\\; n^k \\exp\\left(-\\tfrac{k^2}{2n} - \\tfrac{k^3}{6n^2}\\right) \\cdot \\Bigl[1 \\pm o(1)\\Bigr].$$ I was curious about what the limitations of the illegible upper bound on $k$ were for this approximation, and hoped that I could use at least some useful scaling for $k \\in \\Theta(n^{2/3})$, so I tried to rederive it. However, using Stirling's approximation for the factorial, $$ n! = n^{n+\\frac{1}{2}} \\mathrm e^{-n}\\cdot \\Bigl[\\sqrt{2\\pi} + o(1)\\Bigr], $$ the best that I could rederive was the following: $$\\begin{align} \\frac{n!}{(n-k)!} \\;&=\\; \\frac{n^{n-k+\\frac{1}{2}} n^k \\mathrm e^{n-k}}{(n-k)^{n - k + \\frac{1}{2}} \\mathrm e^n} \\cdot \\Bigl[1 \\pm o(1)\\Bigr] \\\\&=\\; n^k \\left(1 - \\frac{k}{n}\\right)^{-n+k-\\frac{1}{2}} \\mathrm{e}^{-k} \\cdot \\Bigl[1 \\pm o(1)\\Bigr]\\end{align}$$ which looks as though it should scale like $$ \\frac{n!}{(n-k)!} \\;\\;\\stackrel{\\;?\\,}\\sim\\;\\; n^k \\exp\\Bigl( - \\tfrac{k^2}{n} + \\tfrac{k}{2n} \\Bigr),$$ for all $k \\in o(n)$. This is close, but no cigar. Is there anything that I'm missing?\n\nshare|improve this question\nA comment on the \"illegible fraction\": the denominator seems to be a $4$. The numerator looks like a $2$, which doesn't make sense. It might also be a $3$. \u2013\u00a0 Andrew Uzzell Mar 6 '13 at 19:18\n@AndrewUzzell: that's more or less what I thought, too. Mind you, if it's as trivial a formula as they imply (and it doesn't seem as though it should be too hard to prove in principle if correct, right?) then it shouldn't be too hard to show it, and possibly discover that the value of the exponent plays a particular role. \u2013\u00a0 Niel de Beaudrap Mar 6 '13 at 19:19\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nAs you say, if $n$ approaches infinity so that $k/n\\to 0$, by Stirling's approximation $$ k! n^{-k} \\binom{n}{k} = (1 + o(1)) (1-\\frac{k}{n})^{-(n-k)} e^{-k}. \\qquad\\ \\ \\ (*) $$ Then, taking logarithms and expanding in a Taylor series with remainder gives \\begin{eqnarray*} \\log\\left((1-\\frac kn)^{-(n-k)} e^{-k}\\right)&=&-k-(n-k)\\log(1-\\frac kn)\\\\ &=& -k + (n-k) \\left(\\sum_{1\\le i\\le j} \\frac 1i (\\frac kn)^i + O((\\frac kn)^{j+1})\\right)\\\\ &=& -\\sum_{1\\le i\\le j-1} \\frac 1 {i(i+1)} \\frac{k^{i+1}}{n^i}+ O(\\frac{k^{j+1}}{n^j}) \\end{eqnarray*} for any fixed $j\\ge 1$. Exponentiating and substituting this back into $(*)$ gives, as $n\\to\\infty$, $$ \\binom{n}{k} = (1 + o(1)) \\frac{n^k}{k!} \\exp\\left(-\\sum_{1\\le i\\le j-1}\\frac{1}{i(i+1)} \\frac{k^{i+1}}{n^i} \\right),\\ \\ \\ \\text{where } k=o(n^{j/(j+1)}). $$ The formula in the Erd\u0151s-R\u00e9nyi paper is obtained by setting $j:=3$. The illegible exponent should then be $3/4$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/206854/whats-the-probability-that-abe-will-win\nText:\nTake the 2-minute tour \u00d7\n\nAbe and Bill are playing a fun game. Each of them roll a dice every turn. Abe succeeds if he rolls either a 1 or 2. Bill succeeds is he rolls either a 3, 4, or 5.\n\nIf they both succeed on a turn, then they tie the game. If exactly 1 player succeeds on a turn, then the succeeding player wins. If neither player succeeds on a turn, another turn occurs.\n\nWhat's the probability that Abe will win? I originally thought that the answer was $\\frac{2}{5}$, but I realized that the players could tie as well.\n\nshare|improve this question\nDoes Bill succeed if Abe rolls a $3$, $4$, or $5$? Or do they need to roll \"their\" number? \u2013\u00a0 Andr\u00e9 Nicolas Oct 4 '12 at 0:12\nThey both need to roll one of their numbers on their own dice. Good point. \u2013\u00a0 David Faux Oct 4 '12 at 0:13\nA non-mathematical comment: dice is plural, the singular being die. \u2013\u00a0 Brian M. Scott Oct 4 '12 at 0:28\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nOut of 36 (6x6) combinations of die rolls:\n\nAbe will win in 6 of them: (Abe rolls 1 or 2) AND (Bill rolls 1 or 2 or 6)\n\nBill will win in 12 of them: (Abe rolls 3 or 4 or 5 or 6) AND (Bill rolls 3 or 4 or 5)\n\nThe remaining lead to another roll, so they became irrelevant as only one of the 18 situation above finishes up the game.\n\nOut of 18 possible, and equally likely, game ends, Abe wins 6 times, thus:\n\nP{Abe wins} = 6/18 = 1/3\n\nshare|improve this answer\n\nLet $p$ be the probability that Abe eventually wins the game. This can happen in three ways:\n\n(i) (Immediately) Abe succeeds and Bill fails.\n\n(ii) Abe succeeds, and Bill does. Then they are tied. Given this, Abe's probability of ultimately winning is $p$.\n\n(iii) Abe and Bill both fail. Then we are in a situation similar to (ii).\n\nSo $$p=\\frac{2}{6}\\cdot\\frac{3}{6}+\\left(\\frac{2}{6}\\cdot\\frac{3}{6}\\right)p+\\left(\\frac{4}{6}\\cdot\\frac{3}{6}\\right)p.$$\n\nSolve. We get $p=\\dfrac{1}{3}$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/1956/is-there-an-integral-that-proves-pi-333-106\nText:\nTake the 2-minute tour \u00d7\n\nThe following integral,\n\n$$ \\int_0^1 \\frac{x^4(1-x)^4}{x^2 + 1} \\mathrm{d}x = \\frac{22}{7} - \\pi $$\n\nis clearly positive, which proves that $\\pi < 22/7$.\n\nIs there a similar integral which proves $\\pi > 333/106$?\n\nshare|improve this question\nHey, how do you know that it is clearly positive? is there something about the integral that makes it positive? \u2013\u00a0 Tyler Hilton Aug 10 '10 at 20:01\nIf $f(x)>0$ then $$\\int\\limits_{a}^{0} f(x)>0$$ \u2013\u00a0 anonymous Aug 10 '10 at 20:06\n@Affan, you're integrating a fraction of even powers: it can't be negative. \u2013\u00a0 Andrea Ambu Aug 11 '10 at 7:13\nYou can use $\\pi = \\int_0^1 \\frac{4}{1+x^2}$. Now the power series of $\\frac{4}{1+x^2}$ is alternating, thus stopping after odd/even numbers of terms gives under and overevaluations. Thus, for all $a< \\pi <b$ you can find $m, n$ so that $a< \\int_0^1 P_m(x) dx < \\pi < \\int_0^1 P_n(x) < b$, where $P_n$ denotes a Taylor Polynomial. \u2013\u00a0 N. S. Aug 3 '12 at 13:25\nadd comment\n\n3 Answers\n\nup vote 57 down vote accepted\n\nThis integral would do the job:\n\n$$\\int_0^1 \\frac{x^5(1-x)^6(197+462x^2)}{530(1+x^2)}= \\pi -\\frac{333}{106}$$\n\n  \u2022 Also you can refer to S.K. Lucas Integral proofs that $355/113 > \\pi$, Gazette, Aust. Math. Soc. 32 (2005), 263-266.\n\n  \u2022 This is the link. (Thanks to lhf for pointing out.)\n\nshare|improve this answer\nGreat! I had not expected anyone to answer this so quickly! \u2013\u00a0 anon Aug 9 '10 at 21:10\nHow does one come up with that integral, may I ask? \u2013\u00a0 ShreevatsaR Aug 9 '10 at 21:33\nmath.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf Please read this article \u2013\u00a0 anonymous Aug 9 '10 at 21:38\nThe link above is broken. The current one is educ.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf \u2013\u00a0 lhf Jun 10 '11 at 19:05\n@lhf: Thanks for the link. \u2013\u00a0 user9413 Jun 10 '11 at 19:09\nadd comment\n\nAlthough this is not exactly an answer to the question, it seems sufficiently related to mention: there are some direct generalizations, given on the Wikipedia page about this integral. For instance, $$0 < \\frac14\\int_0^1\\frac{x^8(1-x)^8}{1+x^2}\\ dx=\\pi -\\frac{47171}{15015}$$\n\nIn general, $$\\frac1{2^{2n-1}}\\int_0^1 x^{4n}(1-x)^{4n}\\ dx <\\frac1{2^{2n-2}}\\int_0^1\\frac{x^{4n}(1-x)^{4n}}{1+x^2}\\ dx <\\frac1{2^{2n-2}}\\int_0^1 x^{4n}(1-x)^{4n}\\ dx$$\n\nwhich for $n=1$ (the integral in the question) gives slightly better bounds than just $\\pi < 22/7$: $$ \\frac{1}{1260} < \\frac{22}{7} - \\pi < \\frac{1}{630}$$\n\nshare|improve this answer\nThank you! Doesn't that imply that pi is irrational? \u2013\u00a0 anon Aug 9 '10 at 21:17\n@muad: Without checking the asymptotics of the respective numerators and denominators, I'm not sure. It doesn't follow simply from the fact that the left and right expressions go to 0: for instance 1 is rational, but you could still find sequences of rational numbers $x_n, y_n, z_n$ such that $x_n$ and $y_n$ go to 0, but $x_n < 1 - z_n < y_n$ for all $n$. \u2013\u00a0 ShreevatsaR Aug 9 '10 at 21:31\n@anon For this to work, you'd have to show that the rational approximants converged suitably fast. See Dirichlet's irrationality test. \u2013\u00a0 A Walker Oct 19 '11 at 6:23\nadd comment\n\nIn the beginning of 2009 I was posting re similar issue at several sites, namely, at sci.math.symbolic, www.math.utexas.edu, etc.\n\nTo repeat: In Paper 1 Lucas found, by brute-force search using Maple programming, several different variants of integral identities which relate each of several first Pi convergents (described in terms of OEIS sequences as A002485(n)/A002486(n)) to Pi.\n\nFurther, in my above-mentioned postings, I conjectured the following identity below, which represents a generalization of Stephen Lucas' experimentally obtained identities between Pi and its convergents:\n\n$$(-1)^n\\cdot(\\pi - \\text{A002485}(n)/\\text{A002486}(n))$$\n\n$$=(|i|\\cdot2^j)^{-1} \\int_0^1 \\big(x^l(1-x)^m(k+(i+k)x^2)\\big)/(1+x^2)\\; dx$$\n\nwhere integer n = 0,1,2,3,... serves as index for terms in OEIS A002485(n) and A002486(n), and {i, j, k, l, m} are some integers (to be found experimentally or otherwise), which are probably some functions of n.\n\nThe \"interesting\" (I think) part of my generalization conjecture is that \"i\" is present in both:\n\ndenominator of the coefficient in front of the integral and in the body of the integral itself\n\nFor example, in cited by Lucas old known formula for 22/7\n\n22/7 - Pi = Int(x^4*(1-x)^4*/(1+x^2),x = 0 .. 1)\n\nn=3, i=-1, j=0, k=1, l=4, m=4\n\nIn Lucas's formula for 333/106 (mentioned above in the comment by Chandrasekhar)\n\nPi - 333/106 = 1/530*Int(x^5*(1-x)^6*(197+462*x^2)/(1+x^2),x = 0 .. 1)\n\nn=4, i=265, j=1, k=197, l=5, m=6\n\nIn Lucas's formula for 355/113\n\n355/113 - Pi = 1/3164*Int(x^8*(1-x)^8*(25+816*x^2)/(1+x^2),x = 0 .. 1)\n\nn=5, i=791, j=2, k=25, l=8, m=8\n\nIn Lucas's formula for 103993/33102\n\nPi - 103993/33102 = 1/75521*Int(x^14*(1-x)^12*(124360-77159*x^2)/(1+x^2),x = 0 .. 1)\n\nn=6, i= 47201, j=4, k=77159, l=14, m=12\n\nIn Lucas's formula for 104348/33215\n\n104348/33215 - Pi = 1/38544*Int(x^12*(1-x)^12*(1349-1060*x^2)/(1+x^2),x = 0 .. 1)\n\nn=7, i= -2409, j=4, k=1349, l=12, m=12\n\nI do not have computer math resources (Mathematica, Maple, etc.) to experimentally prove or disprove it for all larger n (but see my comment below).\n\nBest Regards, Alexander R. Povolotsky\n\nshare|improve this answer\nOne also could check and see that my above generalization formula also applies to identities obtained by Jaume Oliver Lafont, described in the \"Following Lucas (2009)\" section in oeis.org/wiki/User:Jaume_Oliver_Lafont/\u2026 \u2013\u00a0 Alex Apr 8 '12 at 21:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/372638/100-sided-die-probability/372644\nText:\nTake the 2-minute tour \u00d7\n\nThe question is as follows: You are given a 100-sided die. After you roll once, you can choose to either get paid the dollar amount of that roll OR pay one dollar for one more roll. What is the expected value of the game? There is no limit on number of rolls.\n\nThe EV for a 100-sided die roll is 50.5, but the fact that you can pay a dollar for an extra roll complicates things. Not quite sure how to proceed.\n\nshare|improve this question\nUnless I'm misreading the question, the EV should be infinite. The WORST you can do is an infinite string of {1}s, with probability 0, in which case you end up with $0. However, EVERY other roll you get nets you money. \u2013\u00a0 Foo Barrigno Apr 25 '13 at 17:07\n@FooBarrigno No, the payout is the last value you rolled, not the sum. \u2013\u00a0 gt6989b Apr 25 '13 at 17:10\nwouldn't it just be 50? Your EV of the first roll is 50.5 and your EV of the second roll is 49.5 since you've paid a dollar. This problem also has the constraint that you can choose to roll again or keep your money, so doesn't that play in to calculating this stuff? \u2013\u00a0 Eleven-Eleven Apr 25 '13 at 17:23\n@gr6968b Ah, that clears it up then. I'm not sure how I missed the words \"that roll\" in the problem statement. \u2013\u00a0 Foo Barrigno Apr 26 '13 at 18:00\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nIf the expected value of this game is $a$, then at a die roll of $X$ you have the choice of either collecting $X$ or paying a dollar and restart, which gives you an expected value of $a-1$. To maximize the expected value, you should take $X$ if $X> a-1$ and start over if $X\\le a-1$ (it does not really matter what we do when $X=a-1$). We obtain therefore $$ a = \\frac1{100}\\left(\\lfloor a-1\\rfloor\\cdot a+\\sum_{k=\\lfloor a-1\\rfloor+1}^{100}k\\right) =\\frac1{100}\\left(\\lfloor a-1\\rfloor\\cdot a+\\frac{100\\cdot101}{2}-\\frac{\\lfloor a-1\\rfloor \\cdot\\lfloor a\\rfloor}{2}\\right). $$ I find numerically (didn't do much code checking, but the results are somewhat plausible) $$a\\approx87.3571 $$ which seems to be exactly (and of course the true result must be rational) $$a=87\\frac{5}{14}.$$ But I'm sure you can do the justification after the fact, i.e. show that the strategy that consists in continuing until you roll at least $87$ gives you $87\\frac{5}{14}$ as expected value.\n\nFor your convenience, here is the PARI one-liner:\n\n\nIf an extra roll costs two dollars instead of one, the result would be $$a=82\\frac12$$ instead, and with a cost of only $0.1$ dollars it would be $$a=96\\frac1{10}.$$\n\nshare|improve this answer\nI get an expected value of 1135/13 = 87.30... for the strategy \"Roll until you get higher than 87\" and an expected value of 1223/14 = 87.35... for the strategy \"Roll until you get higher than 86\". This seems to be the best strategy. \u2013\u00a0 Charles Apr 25 '13 at 17:55\nadd comment\n\n\nIf your value now is $X_t$, what is the marginal value of the roll? If you roll $R \\sim \\mathcal{U}[1,100]$, then if $R > X_t+1$ you gained and if $R \\leq X_t+1$, you either lost or became indifferent. So what is the marginal value?\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/106571/a-space-in-which-sequences-have-unique-limits-but-compact-sets-need-not-be-close?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nA topological space is KC if every compact subspace is closed. A topological space is US if every convergent sequences has exactly one limit. Does someone know an easy example of a US space which is not KC? Thanks.\n\nshare|improve this question\nThese terms happen to both 1) be terrible search terms and 2) have unguessable meanings if you're not familiar with them, so you might want to include definitions. \u2013\u00a0 Qiaochu Yuan Sep 7 '12 at 5:28\nSorry, I edit to include definitions. \u2013\u00a0 Pedro Perez Sep 7 '12 at 6:15\nTake the finite complement topology on any infinite set. \u2013\u00a0 Evan Jenkins Sep 7 '12 at 6:39\nThat space is not US. \u2013\u00a0 Pedro Perez Sep 7 '12 at 7:53\nBy the way, what do KC and US stand for? I imagine KC means \"kompact closed\", but US is puzzling me. (\"unique sequence\"?) \u2013\u00a0 Henry Cohn Sep 7 '12 at 12:32\nshow 1 more comment\n\n3 Answers\n\nTo create a counterexample X, start with the closed interval [0,1] (with the usual topology) and attach a new point z whose neighborhoods are open dense subsets of [0,1].\n\nObserve [0,1] is a compact nonclosed subspace of X and thus X is not a KC space. However no sequence in [0,1] converges to z and in particular all convergent sequences in X have unique limits.\n\nThe finite complement topology on an infinite set does not yield a counterexample since every infinite sequence converges to every point of the space.\n\nIn general no counterexample Y can be a sequential space since if Y is a sequential space then Y is a KC space iff Y is a US space. ( Recall Y is a sequential space if every nonclosed set B contains a convergent sequence whose limit lies outside B).\n\nshare|improve this answer\nadd comment\n\nStart with the one point compactification of the minimal uncountable well ordered space and then split the maximum point into two points.\n\nshare|improve this answer\nadd comment\n\nI refer to COROLLARY 1 of This Article.\n\nIn COROLLARY 1 of it, $X^+$ denotes the one point compactification of the topological space $X$:\n\nCOROLLARY: Let $X$ be a Hausdorff space.Then:\n\n(a) $X^+$ is always $US$.\n\n(b) $X^+$ is $KC$ if and only if $X$ is a $\\kappa$ space.\n\nSo it suffices to choose a Hausdorff space $X$, which is not $\\kappa$ space. then $X^+$ is $US$ but is not $KC$.\n\nPS: The topological space $X$ is called $\\kappa$ space, if A subspace $A$ is closed in $X$ if and only if $A \\cap K$ is closed in $K$, for all compact subset $K \\subset X$.\n\nshare|improve this answer\n+1 for the link. Theorem 1 says: $T_2 \\implies KC \\implies US \\implies T_1$ and none of the implications reverses even for compact spaces. \u2013\u00a0 Ramiro de la Vega Sep 7 '12 at 14:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204645/why-directly-does-every-number-divide-9-99-999-or-10-100-1000?answertab=votes\nText:\nTell me more \u00d7\n\nA curiosity that's been bugging me. More precisely:\n\nGiven any integers $b\\geq 1$ and $n\\geq 2$, there exist integers $0\\leq k, l\\leq b-1$ such that $b$ divides $n^l(n^k - 1)$ exactly.\n\nThe question in the title is obviously the case when n = 10. This serves as a motivating example: if we take b = 7 and n = 10, then k = 6, l = 0 works (uniquely), and if we calculate $\\dfrac{n^k - 1}{b}$, we see that it turns out to be 142857 - the repeating part of the decimal expansion of 1/7. A (very sketchy, but correct!) sketch proof, which I've included for completeness:\n\n  \u2022 Notice that $\\dfrac{1}{99\\dots 9} = 0.00\\dots 01\\; 00\\dots 01\\; 00\\dots 01\\dots$.\n  \u2022 Notice that $1/7$ must have either a repeating or a terminating decimal expansion: just perform the long division, and at each stage you will get remainders of 0 (so it terminates) or 1, 2, ..., 6 (so some of these will cycle in some order). It turns out the decimal expansion is repeating, and the 'repeating part' is 142857. This has length (k=)6.\n  \u2022 $\\dfrac{1}{10^6 - 1} = 0.000001\\;000001\\dots$, so $\\dfrac{142857}{10^6 - 1} = 0.142857\\;142857\\dots = 1/7$, and so $7\\times 142857 = 10^6 - 1$.\n  \u2022 And we can do the same thing with $\\dfrac{1}{10\\dots 0} = 0.00\\dots 01$ and terminating decimals. And the same proof of course holds in my more general setting.\n\nBut this (using the long division algorithm after spotting an unwieldy decimal expansion) feels a little artificial to me, and the statement is sufficiently general that I'm sure there must be a direct proof that I'm missing. Of course, the $n^k$ part is easy, but the $n^k-1$ part has me a little stumped. My question is: is there a direct proof of the latter part?\n\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 6 down vote accepted\n\nThe statement as you've given it isn't quite true. For example, $6$ doesn't divide $10^k$ or $10^k-1$ for any $n$. What is true, however, is that every integer divides $10^a(10^b-1)$ for some $a,b$ (and similarly if you replace $10$ by any other $n$).\n\nThe \"$10^k-1$\" part of this (which you've correctly noticed is the more interesting half) is basically a version of Euler's totient theorem, so any proof of that would be a proof of your statement. On the other hand, if you squint at the standard proofs of Euler's theorem in the right light, they start looking an awful lot like your long division argument, so I personally wouldn't worry too much about finding a more direct proof...\n\nshare|improve this answer\nThe \"correct\" proof of Euler's theorem uses elementary group theory, and no calculations at all! (unless you're interested in the value of $\\phi(n)$) \u2013\u00a0 Yuval Filmus Sep 30 '12 at 0:39\n@YuvalFilmus: But the \"proof by long division\" doesn't really involve any calculations either, just the facts that 1) the set of remainders mod $n$ is finite and 2) long division to find the decimal representation of $1/n$ is deterministic and requires only a remainder as input at each step. They're really not all that far apart; both of them boil down to some basic facts about permutations of a finite set... \u2013\u00a0 Micah Sep 30 '12 at 0:44\nSo it is. I'm rather embarrassed that I didn't spot that - it's been a while. Thank you! \u2013\u00a0 Billy Sep 30 '12 at 0:53\nadd comment\n\nHint $\\ $ By the pigeonhole (box) principle, the map $\\rm\\:k\\mapsto n^k\\ (mod\\ b)\\:$ from $\\,\\Bbb N\\,$ to $\\rm\\,\\Bbb Z/b\\Bbb Z\\:$ is not $1$-$1,$ therefore there exist naturals $\\rm\\:j\\!+\\!k > j\\:$ such that $\\rm\\: n^{\\,j+k}\\equiv\\,n^{\\,j}\\ (mod\\ b),\\ $ i.e. $\\rm\\ b\\:|\\:n^j(n^k-1).$\n\nshare|improve this answer\nYep. Unfortunately I misstated the conditions when I posted this last night, so I had no chance of proving it, but now that I've stopped being silly, it's easy. Thank you! \u2013\u00a0 Billy Sep 30 '12 at 14:11\nadd comment\n\nThe claim is false as stated. Take $n = 2$, then the claim states that every number $b$ divides either $2$ or $1$. Perhaps you meant not to limit $k$. But then it's still false. Take for example $b = 6$ and $n = 2$. Certainly $6$ divides no power of $2$ (since $3$ divides no power of $2$), and also no power of $2$ minus one (since they are all odd).\n\nHowever, suppose $(n,b)=1$, that is $n$ and $b$ are relatively prime. Then $b|n^{\\phi(b)-1}-1$, where $\\phi(b)$ is Euler's totient function. This is because $n^{\\phi(b)-1} \\equiv 1 \\pmod{b}$. For example, if $(7,n)=1$ then $7$ divides $n^6-1$. This generalizes your example. Note $\\phi(b)-1$ need not be the minimal exponent; if it is, then we say that $n$ is a primitive root modulo $b$. As an example, $7$ divides $11^3-1$. The minimal exponent always divides $\\phi(b)$.\n\nshare|improve this answer\nOf course, I meant to bound k above by b-1, not n-1. And thanks for pointing out that this is just Euler's totient function - I'm embarrassed not to have spotted it! \u2013\u00a0 Billy Sep 30 '12 at 0:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/65472/official-name-and-complexity-of-k-way-balanced-set-partitioning-what-is-the-be?sort=newest\nText:\nTell me more \u00d7\n\nAs a lot of people know, graph partitioning is NP-Complete. In graph partitioning, you try to create k balanced (within some pre-specified epsilon) disjoint subsets of (possibly weighted) vertices such that the edgecut is minimized. (See\n\nBut what about the simpler problem of partitioning a set of arbitrarily weighted objects into k balanced disjoint subsets, seeking to minimize not some edgecut (only applicable to graph) but the imbalance itself?\n\nIt seems this simpler problem is itself still either NP-Complete or at least NP-Hard, based on similarity to problems such as Graph Partitioning, Bin Packing, Subset Sum, Multiprocessor Scheduling, Set Cover, etc.\n\nIs there a real name for this problem (other than the one I made up in the title)?\n\nAnd does anyone know of a formal paper or some other official, citable source proving its complexity?\n\nLast but not least, and this is the primary reason why I am looking for the name/complexity, what is the best known heuristic for this problem?\n\n(I am currently doing a greedy approach-- iteratively placing the next heaviest object in the total set on the currently lightest partition. But is it possible to do better?)\n\n\nshare|improve this question\nExcuse my density: what about putting vertex I in part J, where J = I mod k? I assume conseuctively numbered v ertices and parts. Gerhard \"Ask Me About System Design\" Paseman, 2011.05.19 \u2013\u00a0 Gerhard Paseman May 19 '11 at 20:27\nBut what about the case in which vertices are weighted? (Or general objects, not necessarily vertices, for the simplified version.) I am working with case where objects can have arbitrary weights. \u2013\u00a0 user15230 May 19 '11 at 21:53\nI have edited my question to clarify that the objects/vertices can have arbitrary weights, thanks Gerhard. \u2013\u00a0 user15230 May 19 '11 at 22:00\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe problem is NP-complete, because it contains the problems Partition and 3-Partition (problems 41 and 46 in If your instances are not extremely huge, I would give an integer programming formulation a try. The heuristics build into modern solvers will probably be competitive (and come without any implementation work on your side).\n\nFor a heuristic, local search seems to be a natural approach. After greedily generating a start solution you can repeat the following steps.\n\n  \u2022 pick blocks $A$ and $B$ with maximal weight difference $w(A)-w(B)$\n  \u2022 find subsets $A'\\subseteq A$ and $B'\\subseteq B$ such that $|w((A\\setminus A')\\cup B')-w((B\\setminus B')\\cup A')|<w(A)-w(B)$\n  \u2022 replace $A$ by $(A\\setminus A')\\cup B'$ and $B$ by $(B\\setminus B')\\cup A'$\n\nTo spice it up a bit one could GRASP it (see ). That just means that the greedy generation of the start solution is randomized: instead of adding the heaviest object to the lightest block, an object, randomly chosen from the $k_1$ heaviest is added to a block randomly chosen from the $k_2$ lightest. Then you start the local search, and when that becomes boring, you just generate a new randomized greedy start solution. This procedure is iterated very often with varying $(k_1,k_2)$, and one can keep track of which parameters $(k_1,k_2)$ tend to lead to good solutions.\n\nshare|improve this answer\nUnfortunately I typically have several million arbitrarily weighted objects, sometimes much more, and am guessing this may qualify as huge. My guess is that heuristics that are tailored to the characteristics of this problem instead of the IP formulation may perform better. \u2013\u00a0 user15230 May 20 '11 at 0:06\nI noticed the connection to Partition/3-Partition but they're not exactly instances of the problem I mention. Aren't partition/3-partition decision problems (vs the optimization problem in my question)? It's a relatively small difference I'll admit but... If possible, I'd really like to know if there is a name/proof for this k-partition optimization generalization of Partition/3-Partition. If no one can find a name/proof for the generalization after a few days, I'll assume neither exist and I'll mark your answer correct. :) (I've already googled for a few hours with no success.) \u2013\u00a0 user15230 May 20 '11 at 0:10\nBy definition, NP-completeness always refers to decision problems. A decision problem corresponding to your optimization problem would be: Given $n$ objects, an integer $k$ and a bound $L$, can they be partitioned in $k$ blocks such that the weights of two blocks differ by at most $L$. Partition: $k=2$, $L=0$ 3-partition: $k=m$, $L=0$ (the $m$ from the fromulation of 3-partition in my link) \u2013\u00a0 Thomas Kalinowski May 20 '11 at 0:43\nAccording to the abstract, the paper has a heuristic for minimizing the maximum weight difference, but subject to the additional constraint that the blocks contain roughly the same number of objects. \u2013\u00a0 Thomas Kalinowski May 20 '11 at 1:32\nI didn't find the Zhang et al paper you link to-- that's a good catch. Even though the paper requires an additional cardinality balance (not what I'm looking for), the paper itself cites other papers that are indeed about my problem (no cardinality constraint) and seem to hint there is no commonly agreed upon name, eg \"set partitioning\", \"multiway number partitioning\", etc. I knew such papers had to exist, but couldn't find them. Thanks! :) \u2013\u00a0 user15230 May 21 '11 at 7:12\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/27524/fair-value-of-a-hat-drawing-game\nText:\nTell me more \u00d7\n\nI've been going through a problem solving book, and I'm a little stumped on the following question:\n\nAt each round, draw a number 1-100 out of a hat (and replace the number after you draw). You can play as many rounds as you want, and the last number you draw is the number of dollars you win, but each round costs an extra $1. What is a fair value to charge for entering this game?\n\nOne thought I had was to suppose I only have N rounds, instead of an unlimited number. (I'd then let N approach infinity.) Then my expected payoff at the Nth round is (Expected number I draw - N) = 50.5 - N. So if I draw a number d at the (N-1)th round, my current payoff would be d - (N-1), so I should redraw if d - (N-1) < 50.5 - N, i.e., if d < 49.5. So my expected payoff at the (N-1)th round is 49(50.5-N) + 1/100*[(50 - (N-1)) + (51 - (N-1)) + ... + (100 - (N-1))] = 62.995 - N (if I did my calculations correctly), and so on.\n\nThe problem is that this gets messy, so I think I'm doing something wrong. Any hints/suggestions to the right approach?\n\nshare|improve this question\ncan you share which book you found this problem? thanks. \u2013\u00a0 Qiang Li Mar 17 '11 at 21:18\nadd comment\n\n3 Answers\n\nConsider what happens in the first stage. You get a number out of the hat, and either stop or go on. And you do it in some \"optimal\" way (maximizes expectation). If you do go on, the rule that will ensure you the maximal expectation is the same rule you used before - your original optimal rule.\n\nThis shows that your stopping rule can be characterized by some threshold $X$, which is the minimal number for which you'd stop (alternatively we could have chosen $X-1$, which is the maximal number for which you'd go on). Denote the expected gain by $E$. We have $$ E = -1 + \\frac{X-1}{100}E + \\frac{\\sum_{t=X}^{100} t}{100} = -1 + \\frac{X-1}{100} + \\frac{(100-X+1)(100+X)}{200}. $$ Multiplying by $200$ and rearranging, we get $$ 2(101-X)E = (101-X)(100+X) - 200. $$ Therefore $$ E = \\frac{(101-X)(100+X) - 200}{2(101-X)}. $$ This is maximized by $101 - 10\\sqrt{2} \\approx 86.86$. Thus the best value for $X$ is either $86$ or $87$. These values give $E \\approx 86.33$ and $E \\approx 86.37$, so $X = 87$ is better, and the value of the game is $1209/14$.\n\nMy calculations don't agree with Ross's, so there's probably a mistake somewhere; this doesn't invalidate the method.\n\nshare|improve this answer\nOur philosophies are the same. I think the difference is the factor $\\frac{100\u2212\u230aR\u230b}{100}$ in my first term, which is the chance that the next draw will be accepted. I think that should multiply your third term, which is the $\\frac{100+\u230aR\u230b}{2}$ part. I just edited my subtraction of the cost of another play, which decreased the expected value by 1. It appears it \"wants\" the expected value to be just below a natural. \u2013\u00a0 Ross Millikan Mar 17 '11 at 6:12\nadd comment\n\nYour expected return if you draw a number on the last round is 49.5 (because it costs a dollar to make the draw). On round N-1, you should keep what you have if it is greater than 49.5, or take your chances if it is less. The expected value if N=2 is then $\\frac {51}{100}\\frac {100+50}{2} -1 + \\frac {49}{100}49.5=61.505$ where the first term is the chance that you keep the first draw times the expectation of that draw (assuming you will keep it), the second is the cost of the first draw, and the third is the chance that you will decline the first draw and take your chances on the second times the expectation of the second draw.\n\nAdded: As Yuval makes more explicit, your strategy will be to quit when you get a number at least $X$. The gain then is $\\frac{100+X}{2}-\\frac{100}{101-X}$ where the first is the payoff and the second is the cost of the expected number of plays. As he says, this is maximized at X=87 with value $\\frac{1209}{14}=86.3571$. I'll have to think where I was a bit off.\n\nshare|improve this answer\nadd comment\n\nEdit: I've added some information about the game with a restricted number $N$ of rounds, since the OP mentioned this.\n\nJust a comment to complement the nice answers we have already.\n\nThere is an algorithm that calculates the optimal strategy and the value of each state for such an optimal stopping problem.\n\nLet $f(x)$ be the payout at each state $x\\in {\\cal S}$ for the underlying Markov chain $(X_n)$, and let $g(x)$ be the cost of leaving state $x$.\n\nSet $u_0=f$ and for $N\\geq 1$ put $u_N=\\max(Pu_{N-1}-g,f)$. Here $P$ is the transition matrix of the Markov chain. Then $u_N$ is the value function for the restricted game with at most $N$ rounds; that is, $$u_N(x)=\\sup_{T\\leq N}\\ \\mathbb{E}\\left[ f(X_T)\\, | \\, X_0=x\\right],$$ where the supremum is over all stopping times $T$ that satisfy $T\\leq N$.\n\nAs $N\\to\\infty$, we get $u_N\\uparrow v$ where $v$ is the value function for the unrestricted game. The optimal strategy is to stop when the chain hits the set $\\lbrace x: f(x)=v(x)\\rbrace$. Here $v(x)$ means the value of state $x$, i.e., $v(x)$ is the maximum expected payout starting in state $x$ and using any finite stopping time $T$ as a strategy:\n\n$$v(x)=\\sup_T\\ \\mathbb{E}\\left[ f(X_T)\\, | \\, X_0=x\\right].$$\n\nThis is all nicely explained in the section on Optimal Stopping in Gregory Lawler's book \"Introduction to Stochastic Processes\".\n\nIn your problem we have $f(x)=x$ for $1\\leq x\\leq 100$, and $g(x)\\equiv 1$. Your Markov chain $(X_n)$ is a sequence of independent, uniform $\\lbrace 1,2,\\dots, 100\\rbrace $ random variables. Thus the $P$ operator applied to $h$ gives the constant function whose value is the average value of $h$, that is, $Ph(x)\\equiv \\sum_{i=1}^{100} h(i)/100$. So we calculate $$u_0(x)=x,\\quad u_1(x)=\\max\\left(x,{99\\over 2}\\right), \\quad u_2(x)=\\max\\left(x,{12301\\over 200}\\right). $$\n\nTaking very large $N$ gives $$v(x)\\approx \\max\\left(x,{86.35714}\\right),$$ which shows that the optimal strategy (over all finite stopping times!) is to quit as soon as we get $87$ or higher, and the value of the game is $86.35714$ dollars.\n\nIn your problem it is pretty straightforward to calculate the exact answer, but this algorithm also gives the answer for more complicated games where exact calculations are not so easy.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/62426/generating-bernoulli-correlated-random-variables-with-space-decaying-correlation\nText:\nTell me more \u00d7\n\n\nI have a set of N objects randomly distributed in a 2D physical space. Each object (i) generates a bernoulli random number (0 or 1) based on a marginal probability Pr(xi = 1) = p. These objects a correlated by physical distance. The closer the objects are, the larger their correlation is.\n\nE.g. If objects i and j are co-located, they are expected to generate correlated results. For Example, if P(Xi=1)= 0.6 and P(Xj=1)=0.3 they would produce something like:\n\nXi= 0 1 0 1 1 1 0 1 0 1\n\nXj= 0 1 0 0 0 1 0 1 0 0\n\nSuch that Pr(Xi|Xj)=1\n\nOn the other hand if i and j are distant they would produce uncorrelated results such that Pr(Xi|Xj)=Pr(Xi)\n\nI have tried to use some of the packages in Matlab (Sampling from multivariate correlated binary and poisson random variables) and R (bindata) but I could not produce an acceptable correlation matrix.\n\nAny ideas how I can produce an acceptable correlation matrix?\n\nBTW, I have checked the following earlier posts discrete stochastic process: exponentially correlated Bernoulli?\n\n\nConstructing Bernoulli random variables with prescribed correlation\n\nBut I am not sure how I can relate to them.\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHere's a suggestion:\n\nDefine a non-negative decreasing function $w(r)$ measuring interaction strength. Given each object its own independent $N(0,1)$ random variable $N_i$. Now set $$ Y_i=\\frac{\\sum_{j}w(\\|x_i-x_j\\|)N_j}{\\sqrt{\\sum_j w(\\|x_i-x_j\\|)^2}}, $$ where $x_i$ denotes the location of the $i$th object.\n\nThen the $Y_i$ are correlated $N(0,1)$ random variables. If two objects are co-located the normal random variables agree.\n\nFinally set $t_i=\\Phi^{-1}(p_i)$ (i.e. $\\mathbb P(N < t_i)=p_i$) and set $X_i=1$ if $Y_i < p_i$ and 0 otherwise.\n\nWith this setup you can write down the covariance of $Y_i$ and $Y_k$ explicitly: it's just $$ \\text{Cov}(Y_i,Y_k)=\\frac{\\sum_j w(\\|x_i-x_j\\|)w(\\|x_k-x_j\\|)} {\\sqrt{\\sum_j w(\\|x_i-x_j\\|)^2\\sum_j w(\\|x_k-x_j\\|)^2}}. $$\n\nIf you write this as $\\cos\\theta_{ik}$ then you can write the covariance of $X_i$ and $X_k$ as an integral: $$ 1/(2\\pi)\\int_{ x < t_1\\;,\\; cos\\theta_{ik}x+\\sin\\theta_{ik}y < t_2} e^{-(x^2+y^2)/2}\\,dxdy-p_ip_k. $$\n\nshare|improve this answer\nIf i understood you correctly, what you are saying is to simply use the Cov(Yi,Yk) above as the covariance matrix and plug it in the bernoulli generator. If so, then Unfortunately, I tried that but I keep getting an Unacceptable correlation matrix, which seams to be not positive definite. \u2013\u00a0 alandalusi Apr 26 '11 at 21:44\nNo you didn't understand me correctly. Here is my concrete suggestion. (1) Compute $t_i=\\Phi^{-1}(p_i)$; (2) Compute the matrix $Cov(Y_i,Y_k)$ as above (3) Use a multivariate normal generator to build some $Y_i$'s. (4) Set $X_i=1$ if $Y_i<t_i$ and 0 otherwise. You could compute the covariance of the Bernoulli's (using the nasty integral formula I wrote down), but if your purpose is to just generate the random #s, then the procedure I described will work just as well. \u2013\u00a0 Anthony Quas Apr 26 '11 at 22:59\nAcually, It is positive definite, but does not have a dichotomized Gaussian distribution for the correlation matrix. \u2013\u00a0 alandalusi Apr 26 '11 at 23:03\nOK, I think I understand your suggestion now. I will test it right away. \u2013\u00a0 alandalusi Apr 26 '11 at 23:32\nIt works!, but I noticed that the Correlation (or Conditional Probabilities) $Pr(X{_i}=1|X{_k}=1)$ between any fixed pair (i and k) slightly change as we add more objects into the physical space. So, I changed $Cov(Y{_i},Y{_k})$ to be $w(||x{_i}-x{_k}||)$ and it worked with fixed conditional probabilities, even if I add more objects. I am still testing it, but does this make sense to you? For your information, my distance functions is $e^{(-\\frac{eucaliandistance}{dcorr})}$ \u2013\u00a0 alandalusi Apr 27 '11 at 16:33\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/346134/packing-radios-into-cartons-why-is-my-solution-wrong/346141\nText:\nTake the 2-minute tour \u00d7\n\nA manufacturer of car radios ships them to retailers in cartons of $n$ radios. The profit per radio is $\\$59.50$, minus shipping cost of $\\$25$ per carton, so the profit is $59.5n-25$ dollars per carton. To promote sales by assuring high quality, the manufacturer promises to pay the retailer $\\$200X^2$ if $X$ radios in the carton are defective. Suppose radios are produced independently and that $5\\%$ of radios are defective. How many radios should be packed per carton to maximize expected net profit per carton?\n\nMy solution:\n\nSuppose that $n$ radios are packed into a carton. Then, the expected profit is clearly $$\\mu = 59.5n-25-200(0.05n)^2$$ Simplifying we get $$\\mu = 59.5n-25-0.5n^2$$\n\nWe want to find a maximum, so we find a derivative:\n\n\nClearly there is just one maximum, so set $\\mu'=0$ we find that $$n^2=59.5$$ and thus $$n\\approx 7.7136\\dots$$This however seems to be wrong. The textbook gives an answer of exactly $50$ in the solution without any explanation of the steps.\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\n$X$ is binomially distributed with $n$ trials and success probability $0.05$. For any random variable $X$ whose mean and variance exist, \\begin{eqnarray*} {\\Bbb E}X^2&=&({\\Bbb E}X)^2+\\text{Var } X, \\end{eqnarray*} and since the mean and variance of a binomial distribution with $n$ trials and success probability $p$ are $np$ and $np(1-p)$, in this case this equals \\begin{eqnarray*} &&(0.05 n)^2+n\\cdot 0.05 \\cdot (1-0.05)\\\\ &=& 0.0025 n^2+0.0475 n \\end{eqnarray*} and the expected profit is \\begin{eqnarray*} &\\ &59.5n-25-200{\\Bbb E}X^2\\\\ &=&59.5n-25-0.5n^2-9.5n\\\\ &=&1225-\\frac 12 (n-50)^2, \\end{eqnarray*} which is maximized at $n=50$.\n\nshare|improve this answer\nadd comment\n\nThe expected loss isn't just $(0.05n)^2$, you must compute its average the hard way ($\\mathbb{E}(x^2) \\ne (\\mathbb{E}(x))^2$ in general!). If the probability of $n$ ones broken is $p_n$, your expected loss due to breakage is $$ \\sum_{n \\ge 0} p_n \\cdot 200 n^2 = 200 \\sum_{n \\ge 0} p_n n^2 $$ Presumably you can start assuming that the number of radios in each box isn't limited, that should give a starting point. Once you have an approximate number of radios per box, refine.\n\nshare|improve this answer\nadd comment\n\nThe profit $Y$ is given by $$Y=59.5n -25-200 X^2,$$ where $X$ is the number of defectives.\n\nThe number of defectives has binomial distribution, with $p=0.05$.\n\nWe want to find $E(X^2)$. There are various ways to do this. One way is to recall that the relevant binomial has mean $np$ and variance $np(1-p)$. But the variance of $X$ is $E(X^2)-(E(X))^2. So E(X^2)=np(1-p) +n^2p^2$.\n\nThere are various other ways to find $E(X^2)$.\n\nSo we are maximizing $59.5n-25-200np(1-p)-200n^2p^2$, which in this case is $-(0.5n^2 -50n +25)$.\n\nFor the maximization, complete the square, or use calculus.\n\nThe answer does turn out to be exactly $50$.\n\nRemark: You asked why your answer was wrong. One way was uninteresting. You differentiated $59.5n-0.5n^2$ and got $59.5-n^2$ instead of the correct $59.5-n$.\n\nThat would have given an answer of $59.5$, say $60$-ish.\n\nThe actual answer is less, and for an interesting reason. The penalty for bad radios is $200X^2$. This is quite sensitive to large values of $X$. Roughly speaking that explains why the optimal number of radios is smaller than the $59.5$ given by your method.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/103787/generalized-tic-tac-toe/103829\nText:\nTake the 2-minute tour \u00d7\n\nWe begin with $2n+1$ cards, each with a distinct number from $-n$ to $+n$ on it, face up in between the two players of the game. The players take turns selecting a card and keeping it. The first player to collect three cards that sum to zero wins the game. If the cards are exhausted and neither player has won, a draw is declared.\n\nTic-tac-toe, or noughts and crosses, is of course the special case $n=4$, by using the essentially unique $3\\times3$ magic square:\n\n$$\\begin{matrix} 3 & -4 & 1 \\\\\\ -2 & 0 & 2 \\\\\\ -1 & 4& -3\\end{matrix}$$\n\nHas the case of general $n$ been studied?\n\nshare|improve this question\nI'm unfamiliar with this generalization! How does the case $n=7$ reduce to ordinary tic-tac-toe? \u2013\u00a0 Owen Biesel Aug 2 '12 at 14:47\nTic-tac-toe actually seems to be the case $n=4$. (I'd also suggest to drop \"of course\", to avoid the reader developing the inferiority complex.) \u2013\u00a0 Seva Aug 2 '12 at 14:51\nAh, now I see. The correspondence is via a magic square (subtracting 5 from each number in a standard $3\\times 3$ square containing 1 through 9), and you can check manually that there are no extra relations of three numbers summing to 0. \u2013\u00a0 Owen Biesel Aug 2 '12 at 14:56\nI would have thought that the \"general case\" would define the winner as the first player to collect $n\u22121$ cards that sum to zero. Also, I'm wondering if your original phrasing was: each with a distinct number from $1$ to $2n + 1$, where the first player to collect three cards that sum to $2n + 1$ wins the game. Then tic-tac-toe is the special case $n = 7$, where we construct a $3x3$ magic square and let that determine the optimal strategy. \u2013\u00a0 Benjamin Dickman Aug 2 '12 at 15:38\n@Patricia: The correspondence starts with a magic square, where the rows, columns and diagonals all sum to 15, not with the numbers 1-9 in a standard array (that's a Muggle square). \u2013\u00a0 Zack Wolske Aug 2 '12 at 20:53\nshow 3 more comments\n\n3 Answers\n\nup vote 9 down vote accepted\n\nFirst player wins for $n$ at least five. First turn, name $0$. They name a number, say $-a$. Choose two numbers $b$ and $c$ such that neither $b$, $c$, nor $b+c=a$. Then name $b$, forcing them to name $-b$, then $c$, forcing them to name $-c$, then $-b-c$, winning. You can always choose two such numbers, since each positive number is missed by one of the following triples: $1+2=3, 1+3=4, 1+4=5, 2+3=5$.\n\nAs quid points out, this is more complicated than I originally made it seem. If $c\\neq a+b$ but $a+b$ is in the interval, then the second player can name $a+b$ in response to $c$ and win.\n\nTo avoid this, if $1 <a\\leq n-2$, choose $b=1$ and $c=a+1$. Neither $1$, $a+1$, nor $a+2=a$ so this works.\n\nIf $a\\geq n-1$, choose $b=2$ and $c=1$. Since $n\\geq 5$, neither $1$, $2$, nor $3=a$ so this works, and $a+b=a+2>n$.\n\nIf $a=1$, choose $b=2$ and $c=3$, so $c=a+b$ and neither $2$, $3$, nor $5=a$.\n\nshare|improve this answer\nClever! Wish I'd seen it. \u2013\u00a0 Timothy Chow Aug 2 '12 at 21:48\nEither I do not understand this description or it is incomplete/wrong. Let me illustrate my problem with an example. Say let n=5, so we choose 0 (according to startegy) and they choose say -4. Now (according to strategy) we choose b=1 and c=2 so neither 1, 2, nor 1+2 is 4. Then we name b=1 so they need to name -1. And now we name c=2. Yet now we lost if they choose 5 (instead of -2)! [We could still win if instead of 2 we defend at 5, forcing them to take -5 and then choose 2, but this is not the point.] \u2013\u00a0 quid Aug 2 '12 at 23:47\nYou are correct. This is incomplete or wrong. \u2013\u00a0 Will Sawin Aug 3 '12 at 1:44\nNice catch, quid. I have \"unaccepted\" the answer. \u2013\u00a0 Timothy Chow Aug 3 '12 at 1:52\nI fixed my answer. \u2013\u00a0 Will Sawin Aug 3 '12 at 2:05\nshow 1 more comment\n\nSince I still do not understand the argument for the accepted answer, but agree with its conclusion (win for $n \\ge 5$), here is an alternate strategy (albeit not very elegant):\n\nLet $n \\ge 5$. We start with $0$. And assume without restriction they choose a negative number.\n\nFour cases (but one could somewhat merge 1,3,4):\n\n  1. They choose $-a$, for $a$ neither $1$, $n-1$, nor $n$. Then, we choose $1$. They have to choose $-1$. We choose $a+1$ defending against their (only) winning move. And then win, since they cannot both 'defend' against $a+1$ and $a+2$ (both being legit due to the condition on $a$).\n\n  2. They choose $-1$. Then we choose $2$. They need to choose $-2$. We choose $3$ defending against their (only) winning move and creating again two potential wins (at $-3$ and $-4$), and thus winning.\n\n  3. They choose $-(n-1)$. Then we choose $1$. They have to choose $-1$. We choose $n$ defending their winning move. They need to choose $-n$, which does not create any winning move for them, so we can choose $2$, creating two winning options ($-2$ and $-3$) [note due to $n \\ge 5$ there is no interference with the earlier moves], and thus win.\n\n  4. They chooose $-n$. We choose $1$. They need to choose $-1$. This does not create any threat. So we can choose $2$ and then win with $-2$ or $-3$.\n\nshare|improve this answer\nThe introductory sentence is now not correct anymore, as I do understand the modified version, not sure it is worth editing it (or keeping at all) my answer, though. For the time being I will leave it as is, in case anybody has some opinion on this matter, please kindly let me know. \u2013\u00a0 quid Aug 3 '12 at 10:37\nadd comment\n\nI am not sure about this particular game, but the general and well-studied framework is as follows: given a hypergraph $H$, two players take turns choosing vertices from $H$, the first player collecting a whole edge being the winner. (In your case, the vertex set is $[-n,n]$, and the edges are triples $(a,b,c)\\in[-n,n]^3$ which add up to $0$.) Two references you may check: Combinatorial Games: Tic-Tac-Toe Theory and Foundations of Positional Games, both by J. Beck.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/114879/an-optimization-problem-non-complete-bipartite-graph-and-hungarian-algorithm/114954\nText:\nTake the 2-minute tour \u00d7\n\nI have two tables at my disposal, one work dataset and one reference dataset. Each dataset has got two columns, lets say these are fields A and B. I would like the rows in reference dataset with the rows in work dataset that are 'closest' w.r.t. some distance. I have more rows in work dataset than in reference dataset, and i will match all rows in reference dataset to some rows in work dataset.\n\nI can define distance between two rows in reference and wrk dataset like this:\n\n$ d_{i,j} = (A_{w}(i) - A_{r}(j))^{2} + (B_{w}(i) - B_{r}(j))^{2} $\n\nwith $A_{w}, A_{r}, B_{w}, B_{r} $ the A and B columns work and reference datasets with obvious notation.\n\nIn other word, i want to minimize over all permutations of rows from the work dataset (with the same number of rows as in reference dataset) the sum of distances between one row in reference dataset and one row in wrk dataset.\n\nI do not know how to proceed if not examining all permutations.\n\nThis is combinatorial problem. What about stochastic methods: genetic algorithm, swarm...\n\nCould you hint at some idea for a start ?\n\nI had a look at linear assignment problem. However, my problem is not a complete bipartatite graph representation, it is not complete since there can be more peaks in work signal than there are in reference signal.\n\nThanks !\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's a standard trick to convert the min cost matching problem on a balanced bipartite graph to one on an unbalanced bipartite graph. Let $G = (X \\cup Y, E, w)$ be the bipartite graph where $E \\subset X \\times Y$ and $|X| \\le |Y|$.\n\nNow create a copy of $G$ and add it \"reversed\", so that in the new graph both sides have exactly $|X| + |Y|$ vertices. All old edges have their same weight: edges between vertices in $X$ and their copies have weight $\\infty$, and edges between vertices in $Y$ and their copies have weight zero.\n\nNow run the usual algorithm, and the solution will have cost exactly twice the unbalanced cost.\n\np.s the fact that the graph is not complete is irrelevant - you can always pretend that there are dummy edges with infinite weight.\n\nWhile the above method works, it's inefficient. there's a recent (2012) paper by Ramshaw and Tarjan on exactly this problem.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/149325/finding-extremas-of-a-three-variable-function\nText:\nTake the 2-minute tour \u00d7\n\nFind all points on he portion of the plane $x+y+z=5$ in the first octant at which $f(x,y,z)=xy^2z^2$ has a maximum value.\n\nAttempt; Since $x+y+z=5$; $x=5-y-z$. I plug this into the $f(x,y,z)$: $$f(5-y-z,y,z)=u(y,z)=y^2 z^2 (5-y-z)=\\text{5 }y^2 z^2-y^3 z^2-y^2 z^3$$\n\nNow I find critical points: $$u_y=10 yz^2-3y^2z^2-2yz^3=0$$ $$u_z=10 y^2 z-2 y^3 z-3 y^2 z^2=0$$\n\nThe solution for this system of equations is $y=z=0$.Therefore, $x=5$. So thats the only critical point $(0,0,5)$ I get and $f(0,0,5)=0$. The answer should be a max at $(1,1,2)$ according to the answer key. How do I get it? Any hints please.\n\nshare|improve this question\nit's $(1,2,2)$. Typing sol \u2013\u00a0 Simon Markett May 24 '12 at 19:03\nYou missed a solution of the system of two equations. Not surprising, they are messy equations. \u2013\u00a0 Andr\u00e9 Nicolas May 24 '12 at 19:05\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe maximum is at $(1,2,2)$ (I assume there is a typo, either in your question or in the answer key.)\n\nYou did everything correctly up to the point where you determine the critical points. We have\n\n$$10yz^2-3y^2z^2-2yz^3=0$$ and $$10y^2z-2y^3z-3y^2z^2=0$$\n\nThe solution is not only $z=y=0$, but it is a sufficient condition if either $y$ or $z$ is $0$. You also get a solution where $z,y\\neq 0$.\n\nFirst look at the original function. In the first octant the values are non-negative. If $y=0$ or $z=0$ the value is also $0$. So let us assume both are positive. Then the equations simplify to\n\n$$10-3y-2z=0$$ and $$10-2y-3z=0$$\n\nWe see easily that the only solution is $y=z=2$ which yields $x=1$.\n\nshare|improve this answer\nI see. But, how do you come to a conclusion that if $y$ and $z$ are positive then the equations simplify in that way? \u2013\u00a0 Koba May 24 '12 at 19:32\n@Dostre :The kicker is that we can write them in factored form as $(10-3y-2z)yz^2=0$ and $(10-2y-3z)y^2z=0$, so if we take $y,z$ to be non-$0$ (we don't actually need to assume positive), then we may divide the two equations by $yz^2,y^2z$ (respectively) to get the simplified equations given by Simon. Now, of course, we are looking for a solution in the first octant, so if the solution to that system of equations didn't have $y,z$ positive, then it wouldn't actually be the solution we wanted, at all. \u2013\u00a0 Cameron Buie May 24 '12 at 20:40\nYeah. Now I understand it completely. Thanks. \u2013\u00a0 Koba May 25 '12 at 4:58\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/270578/laplace-boundary-problem\nText:\nTake the 2-minute tour \u00d7\n\nConsider a boundary given by vertices $(0,a)$, $(0,0)$ and $(1,0)$ (an 'L' shaped boundary).\n\nThe problem is to find the equation that passes between the endpoints $(0,a)$ $(1,0)$ of minimum length that encloses a specified area $A$.\n\nA trivial case would be $A=a/2$ in which case the solution would be a line.\n\nThis is one dimensional Laplace problem with two boundaries (area and lenth) but how do I try to get a series solution for $A < a/2$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nThe formulation is as follows: Maximize $$L[y]=\\int_{x_1}^{x_2}\\sqrt{1+y'\\ ^2}\\ dx$$ subject to $$A=\\int_{x_1}^{x_2}y\\ dx$$ We can use Lagrange multipliers for a new formulation such as $$G=\\sqrt{1+y'\\ ^2}+\\lambda \\ y$$ and the Euler equation is $$\\frac{\\partial G}{\\partial y}-\\frac{d}{dx}\\frac{\\partial G}{\\partial y'}=\\lambda-\\frac{d}{dx}\\bigg(\\frac{y'}{\\sqrt{1+y'\\ ^2}}\\bigg)=0$$ where the open formulation is $$\\lambda-\\frac{1}{\\big(1+y'\\ ^2\\big)^{3/2}}=0$$ and can be solved for y such as $$y[x]=\\alpha \\ x^2+\\beta \\ x +\\gamma\\qquad \\alpha=\\frac{1}{2}\\sqrt{\\frac{1}{\\lambda^{2/3}}-1}$$ To satisfy the conditions to pass through points $(0,a)$ and $(1,0)$; and $A=\\int_{x_1}^{x_2}y\\ dx$ $$y[x]=(3a-6A)\\ x^2+(6A-4a)\\ x +a$$\n\nshare|improve this answer\nadd comment\n\nWelcome to Math.SE! This is an interesting question which would be approached in different ways depending on the context in which it arrives (e.g., level of a course). For example, the curves could be assumed to be smooth or merely rectifiable. They could be assumed to be graphs, or not. The attainment of minimal length could be taken for granted, or require a proof. All this makes it hard to pitch the answer at the right level, and I'm most likely going to fail at that. Indeed, I do not see how one would get a solution in the form of a series, because in general the minimizer is not analytic. If this problem comes from a textbook, it would be helpful to have a reference so that an answer can be given within the context of that book.\n\nIf the existence and differentiability of a minimizing curve can be granted, then there is a variational argument to show it must have the same curvature at all points where it does not meet the constraint (i.e, does not lie on the vertical or horizontal axis). Indeed, write the curve in vector form $\\gamma(t)$, parametrized by arclength, and consider the perturbation $$\\Gamma(t)=\\gamma(t)+\\epsilon \\eta(t) R\\gamma'(t)$$ where $\\epsilon$ is a parameter, $\\eta$ is a smooth function with compact support, and $R$ denotes rotation by $\\pi/2$ clockwise. Note that $(Ru)\\times v =u\\cdot v$ and $u\\times Rv=-u\\cdot v$. The area bounded by $\\Gamma$ is expressed as an integral of $\\Gamma\\times \\Gamma'$, in which the linear term in $\\epsilon $ simplifies to $$2\\epsilon \\eta \\gamma'\\cdot \\gamma' - \\epsilon (\\eta \\gamma\\cdot \\gamma')' $$ Here the first term yields $2\\epsilon \\int \\eta$ and the second integrates to zero. Thus, we should have $\\int \\eta=0$ to preserve the area up to $O(\\epsilon^2)$.\n\nThe length of $\\Gamma$ is given by the integral of $|\\Gamma'(t)| = (\\Gamma'(t)\\cdot \\Gamma'(t))^{1/2}$ in which the linear term simplifies to\n$$ \\epsilon \\eta (\\gamma' \\cdot R\\gamma'') = \\epsilon \\eta \\kappa $$ where $\\kappa$ is the curvature of $\\gamma$. The conclusion is that $\\int \\eta \\kappa =0$ for any $\\eta$ such that $\\int \\eta =0$. Equivalently, $\\kappa$ is constant.\n\nThus, the minimizing curve will be a circular arc as long as it is free to move; i.e., as long as it does not hit the obstacle (vertical or horizontal axes). And the obstacle does get involved when $A$ is so small that no circular arc through $(0,a)$ and $(1,0)$ can bound area $A$ and stay within the first quadrant. When the obstacle takes effect, the minimizing curve consists of parts of the vertical and/or horizontal axes joined by a circular arc that is tangent to them. An obstacle must always be met tangentially: otherwise the point of contact could slide along the obstacle, decreasing length. This takes a separate perturbation argument, into which I will not go.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mechanics.stackexchange.com/questions/5627/2006-nissan-titan-makes-odd-sound-but-only-at-certain-speeds?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nMy 2006 Nissan Titan makes an odd sound, like a grinder, mostly when travelling steady at 35, 40 or 45 miles per hour. Even 1-2 mile per hour difference will cause the noise to stop.\n\nThe noise will go away if I accelerate slightly or slow down by letting off the gas. I've noticed that it will also make the same sound around 20 miles an hour, sometimes when turning, sometimes not. It will not make the sounds during steady acceleration passing through 45 miles an hour.\n\nCould this be a wheel bearing, or possibly the fuel pump? It's a difficult sound to locate whether I'm a passenger or driving, as I have a custom exhaust that's rather loud.\n\nThanks for the ideas!\n\nshare|improve this question\nIf it is only at those speeds then there is a resonance somewhere. Do those speeds correspond to a specific RPM? If so then there is something related to engine speed - perhaps mounts. If it is not related to RPM then check wheels, shocks, bearings etc \u2013\u00a0 Rory Alsop Mar 16 '13 at 18:09\nI'll definitely check and see if it corresponds to a specific RPM. \u2013\u00a0 Brandon Mar 16 '13 at 18:12\nadd comment\n\n2 Answers\n\nWheel bearing was my first thought but it should get louder at higher speeds and remain during accel and decel.\n\npossibly some issue with the torque converter not locking or slipping at certain speeds? Does it only happen in the highest gear of the transmission?\n\nthe turning at low speed leads me to think power steering pump. The sound should change with engine rpm. Try revving the engine at different speeds in neutral.\n\nshare|improve this answer\nThe sound stays constant in volume, no matter which speed, and only happens at the specific speeds. I'll check to see which gear I'm in when it makes the noise and also check in neutral. \u2013\u00a0 Brandon Mar 16 '13 at 18:16\nAn issue with the converter lock-out clutch would give a feel similar to a failed Mass Air Flow Sensor. The steady jerking or bucking at a constant cruise speed on the highway, or a slight load when going uphill at highway speeds. \u2013\u00a0 cinelli Mar 22 '13 at 14:03\nadd comment\n\nI would imagine that something is just rattling.. I say this because if it was an issue of possibly a pulley or a wheel bearing or anything at all for that matter. Then the noise would be more consistent. It isn't too often where you have a vehicle that only has an issue in that tight of a situation.\n\nmostly when traveling steady at 35, 40 or 45 miles per hour. Even 1-2 mile per hour difference will cause the noise to stop. The noise will go away if I accelerate slightly or slow down by letting off the gas. I've noticed that it will also make the same sound around 20 miles an hour,\n\nThis leads me to believe that it's an issue of something vibrating. At a stead 35 to 45 miles per hour the engine should be I'd say about 2500rpm on the highway. Around the same rpm that it would be at when coasting 20 miles per hour. A slight increase in speed also is directly related to a slight increase in RPM, and the noise is gone. Turning, (lets build a scenario of you turning right at a read light) you touch the gas slightly and turn. Most likely hitting right around that 2300-2500rpm mark to get the noise to occur.\n\nNext time you're in the vehicle and you hear the noise take note to where in the RPM range the motor is at at the given time. Then when you get back to your parking spot try to replicate the noise while stopped. If you cannot get it to happen while stopped then perform the following test.\n\nFully engage the parking brake, place the vehicle in drive, and place your left food on the brake pedal. Then with your right foot start to bring the RPM level up (use common sense here, don't just put a brick on the gas pedal because you'll end up slamming into whatever it is in front of you).\n\nUsing the second method if the first one fails will ensure that all the components are engaged and being torqued as if you were driving the vehicle down the road. You'll feel the entire car lurch up (resembling a cat ready to pounce).\n\nIf you can get the noise to reoccur at will then you can have someone assist you in pinpointing it's location.\n\nshare|improve this answer\nThanks for the ideas. I'll try the parking brake/brake/gas method - with a lot of room in front of me - this truck has 313 HP :) \u2013\u00a0 Brandon Mar 17 '13 at 12:06\nIf you get a chance, slide under the truck and make sure that the the heat-shields around the exhaust aren't touching on the exhaust. This usually happens from going through a nice puddle. They're made of a rather thin aluminum so you can just push them back with a long flat-head screwdriver or if you can reach them safely then just use your hand. \u2013\u00a0 cinelli Mar 17 '13 at 21:58\nI wouldn't describe a vibration as a \"grinding\" sound. Usually you would hear a rattle or ping. Grinding makes me think something that is rotating. I guess it is possible that something is intermittently touching the driveshaft? \u2013\u00a0 Mike Saull Mar 20 '13 at 16:17\nIt's also possible the noise wasn't explained correctly. When giving my answer, tried to think of the symptoms given and forget about the description of the noise. I can see see how a low pitched heat-shield could be processed as a \"grinding\" noise to a customer. Do you agree? \u2013\u00a0 cinelli Mar 22 '13 at 14:01\n@cinelli Yeah I agree its possible. Just if you are looking for \"grinding\" specifically that isn't where I would start looking. If you disregard the description of \"grinding\" then you have to start looking at suspension springs, bushings, shocks etc the list of possibilities goes up like crazy. \u2013\u00a0 Mike Saull Mar 22 '13 at 15:32\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://tcsmath.wordpress.com/tag/expander-graphs/\nText:\ntcs math \u2013 some mathematics of theoretical computer science\n\nFebruary 7, 2013\n\nA bit more on expanders\u2026\n\nFiled under: Math \u2014 Tags: , , \u2014 James Lee @ 11:56 am\n\nSo the lecture notes I posted a year ago giving a \u201csimpler proof\u201d of expansion for the Margulis-Gabber-Galil graphs turns out to be very similar to arguments of M. Berger (1991) and Y. Shalom (1999) for proving that SL_2(\\mathbb Z) \\ltimes \\mathbb Z^2  has property (T). See Section 4.2 of the book of Bekka, de la Harpe, and Valette.\n\nAnyone interested in expander graphs should take a look at Amir Yehudayo\ufb00\u2019s recent article in the SIGACT newsletter: Proving expansion in three steps. Amir uses a ping-pong lemma argument (which is essentially the same as the \u201ccombinatorial lemma\u201d in the preceding post) to exemplify the \u201copening\u201d of the three part strategy of Bourgain and Gamburd to proving expansion in Cayley graphs.\n\nApril 18, 2012\n\nGabber-Galil analysis of Margulis\u2019\u00a0expanders\n\nFiled under: Math \u2014 Tags: , , \u2014 James Lee @ 8:11 pm\n\nI\u2019m currently teaching a course on spectral graph theory, and I decided to lecture on Margulis\u2019 expander construction and the analysis of its spectral gap by Gabber and Galil. I had never realized how intuitive the analysis could be; the lectures notes I had seen didn\u2019t quite reflect this. In particular, we won\u2019t do any unsightly calculations. Everything I\u2019m about to say is probably well-known, but I thought I would write it down anyway.\n\nThe idea is to first start with an initial \u201cexpanding object,\u201d and then try to construct a family of graphs out of it. First, consider the infinite graph {G} with vertex set {\\mathbb Z^2} . The edges are given by two maps {S} and {T} , where {S(x,y) = (x,x+y)} and {T(x,y) = (x+y,y)} . So the edges are {\\{(x,y), S(x,y)\\}} and {\\{(x,y), T(x,y)\\}} . Clearly {(0,0)} is not adjacent to anything. Except for the origin, this graph is an expander in the following sense.\n\nLemma 1 For any subset {A \\subseteq \\mathbb Z^2 \\setminus \\{0\\}} , we have\n\n\\displaystyle  |E(A)| \\geq \\frac{1}{3} |A|\\,,\n\nwhere {E(A)} denotes the edges leaving {A} .\n\nThe following simple proof is inspired by a paper of Linial and London.\n\nProof: First consider a subset {A} that does not intersect the coordinate axes. Let {Q_1, Q_2, Q_3, Q_4} represent the four quadrants of {\\mathbb Z^2} , and let {A_i = A \\cap Q_i} . Consider that {S(A_1), T(A_1) \\subseteq Q_1} and {S(A_1) \\cap T(A_1) = \\emptyset} . The latter fact follows because if {(x,x+y)=(x'+y',y')} then {x'=-y} . Similarly, {S^{-1}(A_2), T^{-1}(A_2) \\subseteq Q_2} and {S(A_3), T(A_3) \\subseteq Q_3} and {S^{-1}(A_4), T^{-1}(A_4) \\subseteq Q_4} , while all the respective pairs {S^{-1}(A_2), T^{-1}(A_2)} and {S(A_3), T(A_3)} and {S^{-1}(A_4), T^{-1}(A_4)} are disjoint.\n\nCombining this with the fact that {S} and {T} are bijections on {\\mathbb Z^2} immediately shows that {|S(A) \\cup S^{-1}(A) \\cup T(A) \\cup T^{-1}(A)|} is at least\n\n\\displaystyle  |S(A_1)| + |T(A_1)| + |S^{-1}(A_2)| + |T^{-1}(A_2)|\n\n\\displaystyle  + |S(A_3)| + |T(A_3)| + |S^{-1}(A_4)| + |T^{-1}(A_4)|\n\n\\displaystyle  = 2(|A_1| + |A_2| + |A_3| + |A_4|)\n\n\\displaystyle  = 2 |A|\\,.\n\nDealing with the coordinate axes is not too hard. Suppose now that {A \\subseteq \\mathbb Z^2 \\setminus \\{0\\}} is arbitrary. Let {A_{+} = A \\cap \\{ (x,0), (0,x) : x \\in \\mathbb Z \\}} . The preceding argument shows {|E(A)| \\geq |A\\setminus A_+|-|A_+| = |A|-2|A_+|} . We will show that {|E(A)| \\geq |A_+|} . Averaging these two inequalities with weights {1/3} and {2/3} completes the proof.\n\nLet {A_\\times = A \\cap \\{ (x,x), (x,-x) : x \\in \\mathbb Z \\}} , and {A_\\circ = A \\setminus (A_1 \\cup A_2)} . Then we have the bounds:\n\n\\displaystyle |E(A_+, \\bar A)| \\geq |A_+| - |A_\\times|\n\n\\displaystyle |E(A_\\times, \\bar A)| \\geq 2|A_\\times| - |A_\\circ|\n\n\\displaystyle |E(A_\\circ, \\bar A)| \\geq |A_\\circ| - |A_\\times|\\,.\n\nThe first equation follows since each element of {A_+} is connected to exactly two elements of {A_{\\times}} , and each element of {A_{\\times}} is connected to exactly two elements of {A_+} . For instance, {(x,0)} is connected to {(x,x)} and {(x,-x)} , while {(x,x)} is connected to {(x,0)} and {(0,x)} .\n\nThe second follows because every point of {A_\\times} is connected to two unique points of {A_\\circ} , e.g. {(x,x)} is connected to {(x,2x)} and {(2x,x)} . The final inequality follows from the fact that {|E(A_\\circ)| \\geq |A_\\circ|} from our first argument (since {A_{\\circ}} does not touch the axes), and because {A_\\circ} has no edges to {A_+} . Summing these three inequalities yields {|E(A)| \\geq |A_+|} . \\Box\n\nOf course, {\\mathbb Z^2} is not a finite graph, so for a parameter {n} , we define the graph {G_n=(V_n,E_n)} with vertex set {V_n = \\mathbb Z_n \\oplus \\mathbb Z_n} , where {\\mathbb Z_n = \\mathbb Z/(n \\mathbb Z)} . There are four types of edges in {E_n} : A vertex {(x,y)} is connected to the vertices\n\n\\displaystyle \\{(x,y+1), (x+1, y), (x,x+y), (x+y,y)\\}\\,.\n\nThis yields a graph of degree at most 8.\n\nTheorem 2 There is a constant {c > 0} such that for every {n \\in \\mathbb N} ,\n\n\\displaystyle  \\lambda_2(G_n) \\geq c\\,,\n\nwhere {\\lambda_2} is the second-smallest eigenvalue of the Laplacian on {G_n} .\n\nOf course, the graphs {\\{G_n\\}} now have torsion, and thus our expansion result for {\\mathbb Z^2} is not, a priori, very useful. The non-trivial idea of the proof is that the torsion doesn\u2019t matter, making Lemma 1 applicable. This is not difficult to show using some Fourier analysis. It turns out to be better though, if we first move to the continuous torus.\n\nRecall that,\n\n\\displaystyle  \\lambda_2(G_n) = \\min_{f : V_n \\rightarrow \\mathbb R} \\left\\{\\frac{\\sum_{uv \\in E_n} (f(u)-f(v))^2}{\\sum_{u \\in V_n} f(u)^2} : \\sum_{u \\in V_n} f(u) = 0\\right\\}\\,,\n\nLet {\\mathbb T^2 = \\mathbb R^2/\\mathbb Z^2} be the 2-dimensional torus equipped with the Lebesgue measure, and consider the complex Hilbert space\n\n\\displaystyle  L^2(\\mathbb T^2) = \\left\\{ f : \\mathbb T^2 \\rightarrow \\mathbb C : \\int_{\\mathbb T^2} |f|^2 < \\infty \\right\\}\\,.\n\nequipped with the inner product {\\langle f,g\\rangle_{L^2} = \\int_{\\mathbb T^2} f \\bar g} .\n\nWe might also define a related value,\n\n\\displaystyle   \\lambda_2(\\mathbb T^2) = \\min_{f \\in L^2(\\mathbb T^2)} \\left\\{\\frac{\\|f-f\\circ S\\|_{L^2}^2 + \\|f-f \\circ T\\|_{L^2}^2}{\\|f\\|_{L^2}^2} : \\int_{\\mathbb T^2} f = 0\\right\\}\\,. \\ \\ \\ \\ \\ (1)\n\nNote that this is just defined as a number; the eigenvalue notation is merely suggestive, but we have not introduced an operator on the torus.\n\nClaim 1 There is some {\\varepsilon > 0} such that for any {n \\in \\mathbb N} , we have {\\lambda_2(G_n) \\geq \\varepsilon \\lambda_2(\\mathbb T^2)} \\\n\nProof: We simply sketch a proof, which is rather intuitive. Suppose we are given some map {f : V_n \\rightarrow \\mathbb R} such that {\\sum_{u \\in V_n} f(u)=0} . Define its continuous extension {\\tilde f : \\mathbb T^2 \\rightarrow \\mathbb R} as follows: Under the natural embedding of {\\mathbb Z_n \\oplus \\mathbb Z_n} into {\\mathbb T^2} , every point {z \\in \\mathbb T^2} sits inside a grid square with four corners {u_1,u_2,u_3,u_4 \\in \\mathbb Z_n \\oplus \\mathbb Z_n} . Writing a local convex combination {z = \\lambda_1 u_1 + \\lambda_2 u_2 + \\lambda_3 u_3 + \\lambda_4 u_4} , we define\n\n\\displaystyle  \\tilde f(z) = \\lambda_1 f(u_1) + \\lambda_2 f(u_2) + \\lambda_3 f(u_3) + \\lambda_4 f(u_4)\\,.\n\nNow it is elementary to verify that {\\int_{\\mathbb T^2} \\tilde f = 0} . It is also easy to verify that {\\|\\tilde f\\|^2_{L^2} \\geq c\\frac{1}{n} \\sum_{v \\in V} f(v)^2} for some {c > 0} . (Even if {f(u_1)+f(u_2)+f(u_3)+f(u_4)=0} , we still get a contribution from {f(u_1)^2 + f(u_2)^2 + f(u_3)^2 + f(u_4)^2} to {\\|\\tilde f\\|_{L^2}} on this square because we are taking a weighted average.)\n\nFinally, for any {z \\in \\mathbb T^2} , there is a path of length {O(1)} in {G_n} connecting each of the corners of {z} \u2018s square to the corners of {S(z)} \u2018s square. A similar fact holds for {T(z)} . In fact, this is the only place where we need to use the fact that edges of the form {(x,y) \\leftrightarrow (x,y+1)} and {(x,y) \\leftrightarrow (x+1,y)} are present in {G_n} . Thus any contribution {|\\tilde f(z)-\\tilde f(S(z))|^2} to {\\|\\tilde f-\\tilde f\\circ S\\|_{L^2}^2} can be charged against a term in {\\sum_{uv \\in E_n} (f(u)-f(v))^2} , and similarly for {T} . \\Box\n\nNow our goal is to show that {\\lambda_2(\\mathbb T^2) > 0} . We will use the Fourier transform to \u201cremove the torsion.\u201d The point is that {S} and {T} , being shift operators, will act rather nicely on the Fourier basis.\n\nWe recall that if {m,n \\in \\mathbb N} and we define {\\chi_{m,n} \\in L^2(\\mathbb T^2)} by {\\chi_{m,n}(x,y) = \\exp(2\\pi i(mx+ny))} , then {\\{\\chi_{m,n}\\}} forms an orthonormal Hilbert basis for {L^2(\\mathbb T^2)} . In particular, every {f \\in L^2(\\mathbb T^2)} can be written uniquely as\n\n\\displaystyle  f = \\sum_{m,n \\in \\mathbb Z} \\hat f_{m,n} \\chi_{m,n}\\,,\n\nwhere {\\hat f_{m,n} = \\langle f, \\chi_{m,n}\\rangle_{L^2}} . The Fourier transform is defined as a map {\\mathcal F~:~L^2(\\mathbb T^2) \\rightarrow \\ell^2(\\mathbb Z^2)} , where {\\mathcal F f(m,n) = \\hat f_{m,n}} . In particular, {\\mathcal F} is a linear isometry.\n\nDefine {S^*(f) = f \\circ S} and {T^*(f) = f \\circ T} . Then for any {m,n \\in \\mathbb Z} , we have\n\n\\displaystyle  S^*(\\chi_{m,n}) = \\chi_{m+n,n} \\quad\\textrm{ and }\\quad T^*(\\chi_{m,n}) = \\chi_{m,n+m}.\n\nIn particular, for any {f \\in L^2(\\mathbb T^2)} , we have {\\widehat{S^*(f)} = \\sum_{m,n} \\hat f_{m-n,n} \\chi_{m,n}} and {\\widehat{T^*(f)} = \\sum_{m,n} \\hat f_{m,n-m} \\chi_{m,n}} . The final thing to note is that {\\hat f(0,0) = \\langle f, \\chi_{0,0} \\rangle = \\int_{\\mathbb T^2} f} . So now if we simply apply the Fourier transform (a linear isometry) to the expression in (1), we get a reformulation that {\\lambda_2(\\mathbb T^2)} is precisely\n\n\\displaystyle  \\min_{g \\in \\ell^2(\\mathbb Z^2)} \\left\\{ \\frac{\\sum_{z \\in \\mathbb Z^2} |g(z)-g(S(z))|^2 + |g(z)-g(T(z))|^2}{\\|g\\|^2_{\\ell^2}}: g(0,0)=0 \\right\\}\\,.\n\nHere we have simply replaced {f} by {\\mathcal F f} in (1), and then written {g = \\mathcal F f} .\n\nBut now recall our initial infinite graph {G} on {\\mathbb Z^2} . If we denote by {L_G} the Laplacian on {G} , then we can rewrite this as,\n\n\\displaystyle  \\lambda_2(\\mathbb T^2) = \\min_{g \\in \\ell^2(\\mathbb Z^2)} \\left\\{ \\frac{\\langle g, L_G g\\rangle_{\\ell^2}}{\\|g\\|^2_{\\ell^2}}: g(0,0)=0 \\right\\}\\,.\n\nIn other words, it is precisely the first Dirichlet eigenvalue on {G} , subject to the boundary condition {g(0,0)=0} .\n\nBut now the discrete Cheeger inequality tells us that\n\n\\displaystyle  \\lambda_2(\\mathbb T^2) \\geq \\frac1{2 d_{\\max}} h^2,\n\nwhere {h} is the minimal expansion of any set not containing the origin. Thus we have indeed unwrapped the torsion and returned to our initial question. Lemma 1 shows that {h \\geq 1/3} , yielding the desired lower bound on {\\lambda_2(\\mathbb T^2)} .\n\nMay 4, 2008\n\nThe pseudorandom subspace\u00a0problem\n\nFiled under: Math \u2014 Tags: , , , \u2014 James Lee @ 7:31 pm\n\nIn this post, I will talk about the existence and construction of subspaces of \\ell_1^N which are \u201calmost Euclidean.\u201d In the next few, I\u2019ll discuss the relationship between such subspaces, compressed sensing, and error-correcting codes over the reals.\n\nA good starting point is Dvoretzky\u2019s theorem:\n\nFor every N \\in \\mathbb N and \\varepsilon > 0, the following holds. Let |\\cdot| be the Euclidean norm on \\mathbb R^N, and let \\|\\cdot\\| be an arbitrary norm. Then there exists a subspace X \\subseteq \\mathbb R^N with \\mathrm{dim}(X) \\geq c(\\varepsilon) \\log N, and a number A > 0 so that for every x\\in X,\n\n\\displaystyle A|x| \\leq \\|x\\| \\leq (1+\\varepsilon) A |x|.\n\nHere, c(\\varepsilon) > 0 is a constant that depends only on \\varepsilon.\n\nThe theorem as stated is due to Vitali Milman, who gave the (optimal) dependence of \\log N on the dimension of X, and proved that the above fact actually holds with high probability when X is chosen uniformly at random from all subspaces of this dimension. In other words, for d \\approx \\log N, a random d-dimensional subspace of an arbitrary N-dimensional normed space is almost Euclidean. Milman\u2019s proof was one of the starting points for the \u201clocal theory\u201d of Banach spaces, which views Banach spaces through the lens of sequences of finite-dimensional subspaces whose dimension goes to infinity. It\u2019s a very TCS-like philosophy; see the book of Milman and Schechtman.\n\nOne can associate to any norm its unit ball B = \\left\\{ x \\in \\mathbb R^N : \\|x\\| \\leq 1 \\right\\}, which will be a centrally symmetric convex body. Thus we can restate Milman\u2019s proof of Dvoretzky\u2019s theorem geometrically: If B is an arbitrary convex body, and H is a random c(\\varepsilon) \\log N-dimensional hyperplane through the origin, then with high probability, B \\cap H will almost be a Euclidean ball. This is quite surprising if one starts, for instance, with a polytope like the unit cube or the cross polytope. The intersection B \\cap H is again a polytope, but which is approximated closely by a smooth ball. Here\u2019s a pictorial representation lifted from a talk I once gave:\n\n(Note: Strictly speaking, the intersection will only be an ellipsoid, and one might have to pass to a subsection to actually get a Euclidean sphere.)\n\nEuclidean subspaces of \\ell_1^N and Error-Correcting Codes.\n\nIt is not too difficult to see that the dependence \\mathrm{dim}(X) \\approx \\log N is tight when we consider \\mathbb R^N equipped with the \\ell_\\infty norm (see e.g. Claim 3.10 in these notes), but rather remarkably, results of Kasin and Figiel, Lindenstrauss, and Milman show that if we consider the \\ell_1 norm, we can find Euclidean subspaces of proportional dimension, i.e. \\mathrm{dim}(X) \\approx N.\n\nFor any x \\in \\mathbb R^N, Cauchy-Schwarz gives us\n\n\\|x\\|_2 \\leq \\|x\\|_1 \\leq \\sqrt{N} \\|x\\|_2.\n\nTo this end, for a subspace X \\subseteq \\mathbb R^N, let\u2019s define\n\n\\displaystyle \\Delta(X) = \\max_{0 \\neq x \\in \\mathbb R^N} \\frac{\\sqrt{N} \\|x\\|_2}{\\|x\\|_1},\n\nwhich measures how well-spread the \\ell_2-mass is among the coordinates of vectors x \\in X. For instance, if \\Delta(X) = O(1), then every non-zero x \\in \\mathbb X has at least \\Omega(N) non-zero coordinates (because \\|x\\|_1 \\leq \\sqrt{|\\mathrm{supp}(x)|} \\|x\\|_2). This has an obvious analogy with the setting of linear error-correcting codes, where one would like the same property from the kernel of the check matrix. Over the next few posts, I\u2019ll show how such subspaces actually give rise to error-correcting codes over \\mathbb R that always have efficient decoding algorithms.\n\nThe Kasin and Figiel-Lindenstrauss-Milman results actually describe two different regimes. Kasin shows that for every \\eta > 0, there exists a subspace X \\subseteq \\mathbb R^N with \\dim(X) \\geq (1-\\eta) N, and \\Delta(X) = O_{\\eta}(1). The FLM result shows that for every \\varepsilon > 0, one can get \\Delta(X) \\leq 1 + \\varepsilon and \\dim(X) \\geq \\Omega_{\\varepsilon}(N). In coding terminology, the former approach maximizes the rate of the code, while the latter maximizes the minimum distance. In this post, we will be more interested in Kasin\u2019s \u201cnearly full dimensional\u201d setting, since this has the most relevance to sensing and coding. Work of Indyk (see also this) shows that the \u201cnearly isometric\u201d setting is useful for applications in high-dimensional nearest-neighbor search.\n\nThe search for explicit constructions\n\nBoth approaches show that the bounds hold for a random subspace of the proper dimension (where \u201crandom\u201d can mean different things;we\u2019ll see one example below). In light of this, many authors have asked whether there are explicit constructions of such subspaces exist, see e.g. Johnson and Schechtman (Section 2.2), Milman (Problem 8), and Szarek (Section 4). As I\u2019ll discuss in future posts, this would also yield explicit constructions of codes over the reals, and of compressed sensing matrices.\n\nDepending on the circles you run in, \u201cexplicit\u201d can mean different things. Let\u2019s fix a TCS-style definition: An explicit construction means a deterministic algorithm which, give N as input, outputs a description of a subspace X (e.g. in the form of a set of basis vectors), and runs in time \\mathrm{poly}(N). Fortunately, the constructions I\u2019ll discuss later will satisfy just about everyone\u2019s sense of explicitness.\n\nIn light of the difficulty of obtaining explicit constructions, people have started looking at weaker results and partial derandomizations. One starting point is Kasin\u2019s method of proof: He shows, for instance, that if one chooses a uniformly random N/2 \\times N sign matrix A (i.e. one whose entries are chosen independently and uniformly from \\{-1,1\\}), then with high probability, one has \\Delta(\\mathrm{ker}(A)) = O(1). Of course this bears a strong resemblance to random parity check codes. Clearly we also get \\dim(\\mathrm{ker}(A)) \\geq N/2.\n\nIn work of Guruswami, myself, and Razborov, we show that there exist explicit N/2 \\times N sign matrices A for which \\Delta(\\mathrm{ker}(A)) \\leq (\\log N)^{O(\\log \\log \\log N)} (recall that the trivial bound is \\Delta(\\cdot) \\leq \\sqrt{N}). Our approach is inspired by the construction and analysis of expander codes. Preceding our work, Artstein-Avidan and Milman pursued a different direction, by asking whether one can reduce the dependence on the number of random bits from the trivial O(N^2) bound (and still achieve \\Delta(\\mathrm{ker}(A)) = O(1)). Using random walks on expander graphs, they showed that one only needs O(N \\log N) random bits to construct such a subspace. Lovett and Sodin later reduced this dependency to O(N). (Indyk\u2019s approach based on Nisan\u2019s pseudorandom generator can also be used to get O(N \\log^2 N).) In upcoming work with Guruswami and Wigderson, we show that the dependence can be reduced to O(N^{\\delta}) for any \\delta > 0.\n\nKernels of random sign matrices\n\nIt makes sense to end this discussion with an analysis of the random case. We will prove that if A is a random N/2 \\times N sign matrix (assume for simplicity that N is even), then with high probability \\Delta(\\mathrm{ker}(A)) = O(1). It might help first to recall why a uniformly random N/2 \\times N matrix B with \\{0,1\\} entries is almost surely the check matrix of a good linear code.\n\nLet \\mathbb F_2 = \\{0,1\\} be the finite field of order 2. We would like to show that, with high probability, there does not exist a non-zero vector x \\in \\mathbb F_2^N with hamming weight o(N), and which satisfies Bx=0 (this equation is considered over \\mathbb F_2). The proof is simple: Let B_1, B_2, \\ldots, B_{N/2} be the rows of B. If x \\neq 0, then \\Pr[\\langle B_i, x \\rangle = 0] \\leq \\frac12. Therefore, for any non-zero x, we have\n\n\\Pr[Bx = 0] \\leq 2^{-N/2}. (**)\n\nOn the other hand, for \\delta > 0 small enough, there are fewer than 2^{N/2} non-zero vectors of hamming weight at most \\delta N, so a union bound finishes the argument.\n\nThe proof that \\Delta(\\mathrm{ker}(A)) = O(1) proceeds along similar lines, except that we can no longer take a naive union bound since there are now infinitely many \u201cbad\u201d vectors. Of course the solution is to take a sufficiently fine discretization of the set of bad vectors. This proceeds in three steps:\n\n  1. If x is far from \\mathrm{ker}(A), then any x' with \\|x-x'\\|_2 small is also far from \\mathrm{ker}(A).\n  2. Any fixed vector x \\in \\mathbb R^N with \\|x\\|_2 = 1 is far from \\mathrm{ker}(A) with very high probability. This is the analog of (**) in the coding setting.\n  3. There exists a small set of vectors that well-approximates the set of bad vectors.\n\nCombining (1), (2), and (3) we will conclude that every bad vector is far from the kernel of A (and, in particular, not contained in the kernel).\n\nTo verify (1), we need to show that almost surely the operator norm \\|A\\| = \\max \\left\\{ \\|Ax\\|_2 : \\|x\\|_2 = 1\\right\\} is small, because if we define\n\n\\mathrm{dist}(x, \\mathrm{ker}(A)) = \\min_{y \\in \\mathrm{ker}(A)} \\|x-y\\|_2,\n\n\n\\mathrm{dist}(x', \\mathrm{ker}(A)) \\geq \\mathrm{dist}(x,\\mathrm{ker}(A)) - \\|A\\| \\cdot \\|x-x'\\|_2\n\nIn order to proceed, we first need a tail bound on random Bernoulli sums, which follows immediately from Hoeffding\u2019s inequality.\n\nLemma 1: If v \\in \\mathbb R^k and X \\in \\{-1,1\\}^k is chosen uniformly at random, then\n\n\\displaystyle \\Pr\\left[|\\langle v, X \\rangle| \\geq t\\right] \\leq 2 \\exp\\left(\\frac{-t^2}{2 \\|v\\|_2^2}\\right)\n\nIn particular, for y \\in \\mathbb R^{N/2} and x \\in \\mathbb R^N, we have \\langle y, Ax \\rangle = \\sum_{i=1}^{N/2} \\sum_{j=1}^N A_{ij} y_i x_j. We conclude that if we take \\|x\\|_2 = 1 and \\|y\\|_2 = 1, then\n\n\\Pr\\left[ |\\langle y, Ax \\rangle| \\geq t \\sqrt{2N}\\right] \\leq 2 \\exp\\left(-t^2 N\\right), (4)\n\nobserving that \\sum_{i,j} y_i^2 x_j^2 = 1, and applying Lemma 1. Now we can prove that \\|A\\| is usually not too big.\n\nTheorem 1: If A is a random N/2 \\times N sign matrix, then\n\n\\Pr[\\|A\\| \\geq 10 \\sqrt{N}] \\leq 2 e^{-6N}.\n\n\nFor convenience, let m = N/2, and let \\Gamma_m and \\Gamma_N be (1/3)-nets on the unit spheres of \\mathbb R^m and \\mathbb R^N, respectively. In other words, for every x \\in \\mathbb R^m with \\|x\\|_2 = 1, there should exist a point x' \\in \\Gamma_m for which \\|x-x'\\|_2 \\leq 1/3, and similarly for \\Gamma_N. It is well-known that one can choose such nets with |\\Gamma_m| \\leq 7^m and |\\Gamma_N| \\leq 7^N (see, e.g. the book of Milman and Schechtman mentioned earlier).\n\nSo applying (4) and a union bound, we have\n\n\\displaystyle \\Pr\\left[\\exists y \\in \\Gamma_m, x \\in \\Gamma_N\\,\\, |\\langle y, Ax \\rangle| \\geq 3\\sqrt{2N}\\right] \\leq 2 |\\Gamma_m| |\\Gamma_N| \\exp(-9N) \\leq 2 \\exp(-6N).\n\nSo let\u2019s assume that no such x \\in \\Gamma_N and y \\in \\Gamma_m exist. Let u \\in \\mathbb R^N and v \\in \\mathbb R^m be arbitrary vectors with \\|u\\|_2=1,\\|v\\|_2=1, and write u = \\sum_{i \\geq 0} \\alpha_i x_i and v = \\sum_{i \\geq 0} \\beta_i y_i, where \\{x_i\\} \\subseteq \\Gamma_N and \\{y_i\\} \\subseteq \\Gamma_m, where |\\alpha_i|, |\\beta_i| \\leq 3^{-i} (by choosing successive approximations). Then we have,\n\n|\\langle v, A u\\rangle| \\leq \\sum_{i,j \\geq 0} 3^{-i-j} |\\langle y_i, A x_i\\rangle| \\leq (3/2)^2 3\\sqrt{2N} \\leq 10 \\sqrt{N}.\n\nWe conclude by nothing that \\|A\\| = \\max \\left\\{ |\\langle u, Av \\rangle| : \\|u\\|_2 = 1, \\|v\\|_2=1 \\right\\}.\n\nThis concludes the verification of (1). In the next post, we\u2019ll see how (2) and (3) are proved.\n\nThe Shocking Blue Green Theme Blog at\n\n\nGet every new post delivered to your Inbox.\n\nJoin 57 other followers"}
{"text": "Retrieved from http://www.math.niu.edu/~rusin/known-math/95/volume.polyh\nText:\nFrom: (Boyan I. Boyanov) Newsgroups: sci.math Subject: Volume of a tetrahedron Date: 27 Mar 1995 00:30:42 GMT Hi, I have a stupid question that I cannot solve myself and cannot find the answer to in any of the math handbooks I've looked at. Is there a general formula for the volume of an ARBITRARY polyhedron? I know everything there is to know about the polyhedron - the coordinates of the vertices, the equations of the planes that form the walls, the number of walls, the number of sides, the number of vertices, etc. About the only restriction that is put on the polyherdon is that it is \"convex\", i.e. all vertices lie in a single \"half-space\" relative to any wall. I was trying to do it by breaking up the polyhedron into a collection of tetrahedra and summing up the volumes of the tetrahedra, but I can't seem to come up with an algorithm that allows me to determine which vertices form the tetrahedra that make up the polyhedron. Any ideas? Is there a better nad easier way to do this? Please Cc: me if you post a followup, if at all possible. Thanks! Boyan -- Boyan I. Boyanov ============================================================================== From: (Dave Rusin) Newsgroups: sci.math Subject: Re: Volume of a tetrahedron Date: 27 Mar 1995 22:52:56 GMT In article <3l50vi$>, Boyan I. Boyanov wrote: >Is there a general formula for the volume of an ARBITRARY polyhedron? Well, I suppose I ought to answer this since I just advertised Green's theorem for a similar purpose. In this question, the author wants a space integral integral_P 1 dxdydz where P is the polyhedron. The corresponding technique is to use Stokes' Theorem, whose general form _ _ _/ w = _/ dw boundary(S) S (for w any differential form on S) specializes for 2-forms to _ _ _/ P dxdy + Q dydz + R dzdx = _/ (dP/dz + dQ/dx + dR/dy) dxdydz so we can get the space integral of 1, for example, by integrating the 2-form z dxdy over the surface of the polyhedron. We can compute the surface integrals face-by-face. The quick answer here is that the individual surface integrals, when divided by the area of the face, would compute the average value of the z coordinate on the face. Therefore, we can compute the surface integrals easily by averaging the z coordinates of the vertices of the face, and multiplying by an area: the surface integral int( zdxdy ) over a face spanned by (x0 y0 z0), (x1 y1 z1), and (x2 y2 z2) is (z0+z1+z2)/3 . | (1/2)( y1.(x0-x2) + y2.(x1-x0) + y0.(x2-x1) ) | This surface integral is added to the total if the three points are in counterclockwise order as seen from the outside of the polyhedron, subtracted otherwise. A proof is appended as a postscript to this post; it may perhaps reinforce an understanding of surface integrals. It perhaps bears mentioning that this procedure does not assume the polyhedron is convex, nor indeed homeomorphic to a sphere. It does assume that the polyhedron is closed (no boundary) and a triangularization of a manifold (which will then be compact and orientable, conditions which I would otherwise have to add). It is not necessary that all the faces be triangles, really, although any other polygons may be so divided. The method may also be extended to other surface integrals besides volume, and so for example may be used to compute the center of mass. One can remove the absolute values and simply add in the polynomial expression if an orientation is chosen consistent with the \"right-hand-rule\" for outward pointing normals. As in the previous post I will concede that there is some redundant calculation here, so that if it is important that the computation be done quickly it pays to watch for repeated line integrals and so on. dave __Derivation of formula for surface integral over one face__ Assuming that the face is not vertical, we can write z = Ax+By+C for some constants A, B and C (easily computed from any three non-collinear vertices on the face). Then that face contributes to the surface integral the sum A integral(x) + B integral(y) + C integral(1) where the integral may be taken over the projection of the face to the xy-plane (translation: ignore the z coordinates on the face). There is an orientation problem: the integral over the projection to the xy-plane will be off by a sign if the polyhedron faces \"in\" rather than \"out\", so you will need to know whether the interior of the polyhedron contains those points whose z coordinates are just larger than Ax+By+C or just smaller. In a previous post, I discussed integrating these very three surface integrals around a polygon. (These were done with Green's theorem.) The upshot is that these integrals may be computed as simple sums around the perimeter of the polygon. The segment from (x0, y0) to (x1, y1) contributes (x0 + x1)/2 . (y1-y0) to the integral of 1 over the polygon, (x0^2 + x0 x1 + x1^2)/6 . (y1-y0) to the integral of x, and ( (y0 x1 + x0 y1) + 2(x1 y1 + x0 y0) )/6 . (y1 - y0) to the integral of y. So, for example, if one face of your polyhedron is a triangle with vertices (x0,y0,z0), (x1,y1,z1), and (x2,y2,z2), then the equation for the plane is z = Ax + By + C where A, B, and C are determined by ( A ) ( x0 y0 1 )^{-1} ( z0 ) ( B ) = ( x1 y1 1 ) ( z1 ) ( C ) ( x2 y2 1 ) ( z2 ) We compute the line integrals around the triangle in the xy-plane: the integral of 1 is I1 = (1/2)( y1.(x0-x2) + y2.(x1-x0) + y0.(x2-x1) ) as in a followup I made to the previous post; the integral of x is this times (x0+x1+x2)/3, and the integral of y is the same factor I1 times (y0+y1+y2)/3. (All these should have their sign adjusted in case the points (x0,y0), (x1,y1), (x2,y2) do not wrap counterclockwise around the triangle. The correction is easy: since integral(1)=Area > 0, the sign correction to multiply by is just the sign S1 of I1. Thus, the surface integral over this face is the linear combination [ A(x0+x1+x2)/3 + B(y0+y1+y2)/3 + C ] . (S1 I1) As it happens, I1 is precisely the determinant of the matrix to be inverted above, so multiplyng thru we see that A B and C may be replaced by the cofactors, making division unnecessary. Apart from the sign correction, the previous surface integral may thus be written (z0.(y1-y2)+z1.(y2-y0)+z2.(y0-y1)) . (x0+x1+x2)/3 + (z0.(x2-x1)+z1.(x0-x2)+z2.(x1-x0)) . (y0+y1+y2)/3 + (z0.(x1y2-x2y1)+z1.(x2y0-x0y2)+z2.(x0y1-x1y0)) This, in turn, simplifies to just (z0+z1+z2)/3 . (I1) (again, times the sign correction so that S1 I1 > 0 ) This is the formula given above."}
{"text": "Retrieved from http://math.stackexchange.com/questions/334375/conditional-probability-uniform-distributions\nText:\nTake the 2-minute tour \u00d7\n\nProblem: Suppose that the random variable X is uniformly distributed symmetrically around zero, but in such a way that the parameter is uniform on (0, 1); that is, suppose that $X\\mid (A=a) \\sim U(-a,a)$ with $A \\sim U(0,1)$. Find the distribution of X.\n\nMy attemt: $f_{A,X}(a,x)=f_{X\\mid A=a}(x) \\cdot f_{A} (a)$.\n\n$f_{A}(a)=1$ for $0<a<1$ and $f_{X,A=a}(x)=\\frac{1}{2a}$ for $-a<x<a$ which means that $f_{A,X}(a,x)=\\frac{1}{2a}$ for $0<a<1$ and $-a<x<a$. Next I integrate the joint distribution over a to find $f_{X}(x)$.\n\n$f_{X}(x)=\\int_0^1 f_{A,X}(a,x) da=\\int_0^1 \\frac{1}{2a}da$, but this integral is not convergent. Where do I go wrong?\n\n\nshare|improve this question\nI think the standard symbol where you use $\\in$ would be $\\sim$. \u2013\u00a0 joriki Mar 19 '13 at 2:04\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou were correct up until setting up the integral for the marginal density: $$ f_X(x) = \\int_0^1 f_{A,X}(a,x) \\mathrm{d}a = \\int_0^1 \\frac{1}{2a} [-a<x<a] \\mathrm{d}x $$ For a given $-1<x<1$, the indicator function $[-a<x<a]$ is non-zero for $|x|<a<1$, therefore $$ f_X(x) = \\int_{|x|}^a \\frac{\\mathrm{d}a}{2a} = \\frac{1}{2} \\ln \\frac{1}{|x|} $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/35964/how-can-i-get-buffer-local-environment-variables-via-dir-locals/35965\nText:\nI'm using emacs for many different projects. For some of them, I need, for example, different entries in $PATH, or different $MAKEFLAGS, whatever, you name it...\n\nI thought this would be possible somehow like this in .dir-locals:\n\n  (c-basic-offset . 4)\n  (tab-width . 4)\n  (eval progn\n          (make-local-variable 'process-environment)\n          (setenv \"gna\" \"gnagna3\")))\n  (c-basic-offset . 4)\n  (tab-width . 4)))\n\nBit with this approach, \"gna\" is set in all buffers.\n\nWhat am I missing?\n\n\nBoth the buffer-local and the global variable are initially pointing to the same cons cell / list. If setenv pushes a new value to the front of the list, that would only be reflected in the local list value (the global value would effectively point to the cdr of the local value) in which case your code should work as desired; however if setenv is modifying an existing element further down the list, that change will be reflected in both values.\n\nYou can avoid this by making a copy of the list.\n\n(eval . (progn\n          (make-local-variable 'process-environment)\n          (setq process-environment (copy-sequence process-environment))\n          (setenv \"gna\" \"gnagna3\")))\n\nYou could also shorten that by using setq-local\n\n  \u2022 Of course, if you do this, it will cause problems, at least it did for me. If you start a shell from a buffer that has a buffer-local process-environment the sell will not inherit your changes to the process-environment. See emacs.stackexchange.com/questions/45563/\u2026. \u2013\u00a0Ben Key Nov 14 '18 at 5:17\n  \u2022 2\n    That is because in general non-file-visiting buffers do not see directory-local variables. So it's not that this approach is \"causing problems\", but rather that it's not having any effect in the shell buffer. I've added an answer to the linked question. \u2013\u00a0phils Nov 14 '18 at 6:01\n\nYour Answer"}
{"text": "Retrieved from https://www.jiskha.com/questions/360191/n2h4-g-h2-g-2-nh3-g-h1-1876kj-3-h2-g-n2-g-2-nh3-g-h2-922-kj-the\nText:\nEnthalpy of Formation\n\nN2H4(g) + H2(g)--> 2 NH3(g) H1 = \u20131876kJ\n\n3 H2(g) + N2(g)--> 2 NH3(g) H2 = \u2013922 kJ\n\nThe H.f for the formation of hydrazine: 2 H2(g) + N2(g)--> N2H4(g) will be______kj/mol\n\nI am very confused here. I thought I would just add H1 and H2 and divide by the molar mass of N2H4, but that is not correct. Please Help. Thank You!\n\n  1. \ud83d\udc4d\n  2. \ud83d\udc4e\n  3. \ud83d\udc41\n  1. I got the answer to be 95.4 kj/mol\n    I reversed the 1st equation to get an overall 187.6 kj = h1\n    then I just added that to H2 and I got the answer.\n    But I still don't really understand the processes. If someone could explain that to me I would truly appreciate it.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n  2. You have to reverse the direction of one reaction and change the sign of H.\n\n    3 H2+ N2--> 2 NH3 H2 = -922 kJ/mole\n    2NH3 -> N2H4 + H2 H = +1876 kJ/mole\n\n    NOW add, and cancel out terms that appear on both sides.\n\n    N2 + 2H2 -> N2H4 H = -954 kJ\n\n    There is another problem. Your heat of formation of NH3 does not agree with accepted data. It should be -10.97 kJ/per mole of NH3, or twice that much for the reaction as written (which forms two moles). Also, the standard form of N2H4 at room temperature is a liquid, and your reaction involves the gas.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n  3. For what it is worth, the correct heat of formation of N2H4 (liq.) is +12.10 kcal/mole and for N2H4(g) it is +22.79 kcal/mole. Those values are at 298 K. They are a few kcal/mole different at 0 K. Multiply by 4.18 for kJ/mole. That gives +95.3 kJ/mole for the N2H4(g) heat of formation, which agrees well with your second answer. You seem to have misplaced decimal points in your first version of the question.\n\n    Those values come from the JANAF Thermochemcial Tables of the U.S National Bureau of Standards, 2nd edition.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n\nRespond to this Question\n\nFirst Name\n\nYour Response\n\nSimilar Questions\n\n  1. Honors Chemistry\n\n\n  2. Chemistry\n\n    Calculate the molarity and the molality of an NH3 solution made up of 30 g of NH3 in 70 g of water. The density of the solution is 0.982 g/ml. Molar Mass of NH3 = 17.04 g\n\n  3. chemistry\n\n    Nitrogen (N2) and hydrogen (H2) react to form ammonia (NH3). Consider a mixture of six nitrogen molecules and six hydrogen molecules in a closed container. Assuming the reaction goes to completion, what will the final product\n\n  4. Chemistry\n\n    If 2.50 g of CuSO4 are dissolved in 9.4 102 mL of 0.34 M NH3, what are the concentrations of Cu(NH3)42+, NH3 and Cu2+ at equilibrium? i tried doing Cu2+ first and i did Kf=5e13= salt/cu2+ nh3+^4 and i did molesCuSO4/.94 L = .01666\n\n  1. chemistry\n\n    How many moles are in 1.50 x 1023 molecules NH3? A. 2.49 x 10 -1 mol NH3 B. 2.49 x 101 mol NH3 C. 2.65 x 10 -1 mol NH3 D. 2.78 x 10 1 mol NH3 maybe B\n\n  2. Chem help\n\n    Which reaction of ammonia does not involve the non-bonding pair of electrons on the nitrogen atom? A NH3(g) + CH3I(g) \u2192 CH3NH 3+ I \u2013(s) B NH3(g) + HCl (g) \u2192 NH4Cl (s) C 2NH3(l) + 2Na(s) \u2192 2NaNH2(s) + H2(g) D 2NH3(aq) +\n\n  3. Chemistry\n\n    Consider this equilibrium N2(g) + H2(g) NH3(g) +94 kJ The equilibrium law exoression for the balanced chemical equationwould be A. [N2][H2]/[NH3] B. [NH3]/[H2][N2] C. [NH3]2/[H2][N2] D. [NH3]2/[H2]3[N2] E. 2[NH3]2/3[H2]3[N2]\n\n  4. science\n\n    Calculate the solubility of silver chloride in 10.0 M ammonia given the following information: Ksp (AgCl) = 1.6 x 10^\u201310 Ag+ + NH3--->AgNH3+ K=2.1x10^3 AgNH3+ + NH3-----> Ag(NH3)2+ K=8.2x10^3 Answer : 0.48 M Calculate the\n\n  1. Chemistry\n\n\n  2. AP Chem\n\n    At a certain temperature, 4.0 mol NH3 is introduced into a 2.0 L container, and the NH3 partially dissociates by the reaction. 2 NH3(g) N2(g) + 3 H2(g) At equilibrium, 2.0 mol NH3 remains. What is the value of K for this reaction?\n\n  3. chemistry\n\n    from the balanced equation 4NH3 +7O2 - 4NO2 + 6H2O How many molecules of water are produced when 2.25 moles of ammonia are completely reacted? The equation tells us that 4 mol NH3 will produce 6 mols water. That means 2 mols NH3\n\n  4. Chemistry\n\n    Calculate the molar concentration of uncomplexed Zn2+ (aq) in a solution that contains 0.22 mol of Zn(NH3)4 2+ per liter and 0.3109 M NH3 at equilibrium. Kf for Zn(NH3)4 2+ is 2.9 X 10^9 I started this way... (0.3109 +\n\nYou can view more similar questions or ask a new question."}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/6917/measuring-output-impedance/6920\nText:\nGiven I have designed and produced an RF circuit with an output for connecting an antenna. I know this antenna has an input impedance of 50\u03a9. I now wish to measure the actual output impedance of my circuit, before connecting the antenna, to ensure that the impedance matches.\n\nHow do I actually measure the output impedance of my circuit?\n\nAnd additionally, can I do this with hobby friendly priced equipment?\n\nUpdate: I know the basic theory of impedance matching, but I have never understood how to actually do it. So I am really asking for input on the specific hardware and equipment to use, and how to perform actual tests.\n\nThe RF circuit is operating in the UHF range, and transmits about 10dBm, if this helps.\n\n  \u2022 1\n    \\$\\begingroup\\$ Does \"Hobby Friendly\" include an oscilloscope? Also, do you wish to know the physical output impedance, or calculate the theoretical output impedance? \\$\\endgroup\\$ \u2013\u00a0Kevin Vermeer Nov 18 '10 at 19:09\n  \u2022 \\$\\begingroup\\$ Well, yes, I consider oscilloscopes in the hobby friendly zone. However I don't think a spectrum analyzer is in the hobby friendly zone, and I know any oscilloscope which has a high enough bandwidth to measure UHF and above (directly). \\$\\endgroup\\$ \u2013\u00a0bjarkef Nov 18 '10 at 19:20\n  \u2022 \\$\\begingroup\\$ I asked a similar question about trace impedance: electronics.stackexchange.com/questions/5778/\u2026. I think the answer is to design in the 50 ohms impedance, not to calibrate it after manufacture. \\$\\endgroup\\$ \u2013\u00a0Thomas O Nov 18 '10 at 19:21\n  \u2022 \\$\\begingroup\\$ Hi Thomas. I looked at your question, but I still do not understand how to actually measure what output impedance I have achieved, or how to design that in for that matter. Your question concerns the characteristic impedance for a transmission line. I am interested in the output impedance of a RF generator circuit (+ possibly the transmission line), and I don't understand how this relates. Please enlighten me? :) \\$\\endgroup\\$ \u2013\u00a0bjarkef Nov 18 '10 at 19:34\n  \u2022 \\$\\begingroup\\$ @bjarkef, Thomas is incorrect here, although they are both RF related, your applications are fundamentally different. I have done both, designing a trace to be 50 ohms is very easy, getting an RF generator to match can be quite challenging. \\$\\endgroup\\$ \u2013\u00a0Kortuk Nov 18 '10 at 21:51\n\nYou really need one of a number of options, none of them are hobby friendly if you are above a few MHz. I would guess you are at 2.4GHz, or at 900MHz.\n\nProfessional Options\n\nIf you might know someone whom has access to equipment that would help you have a few options.\n\n  1. VNA- Vector Network Analyzer. This can give you a smith chart over a frequency range and make sure it shows you at 50 ohms. You can also measure S11 which should be less than -20dB\n  2. Spectrum Analyzer- This should allow you to determine your power received at your frequency. This is not ideal, but it should get more output power as you get closer to a proper match.\n  3. SWR Meter-As Is noted in another answer and I always forget about, you can use an Standing Wave Ratio meter, but I would still suggest a VNA. They have significantly more features, and can do anything a spectrum analyzer or SWR meter can do.\n\nHacker style ways to approach it\n\nThere is another funny way to approach this, the problem being you will need to build one of a few microwave components.\n\nYou could use an isolator and measure its temperature, hotter isolator is equivalent to a worse mismatch. this is not even close to good method as at 10dBm it will be very hard to detect a temperature failure.\n\nYou could build your own mixer and feedback your output signal and mix it with your signal returning from the connection. To take away your signal from the feedback you need to use what is called a circulator. This is not fun, but it is doable.\n\nIf you would like to try either method, which is similar to creating your own VNA, I can get you more information on how to build these devices.\n\n  \u2022 \\$\\begingroup\\$ I'm interested in the mixer method... got any more links? Thanks. \\$\\endgroup\\$ \u2013\u00a0cksa361 Dec 4 '10 at 7:56\n  \u2022 \\$\\begingroup\\$ @cksa361, There are a number of options here. I would suggest you look into a \"gilbert cell\" to design this yourself, but there are many different approaches. Here google.com/\u2026 they have someone trying to analyze one. You will probably need a signal generator, like a Phased-locked-loop to generate your signal. This will not be any easy task. \\$\\endgroup\\$ \u2013\u00a0Kortuk Dec 4 '10 at 20:53\n  \u2022 \\$\\begingroup\\$ What is your budget like? I think I can find you some hobbyist projects that actually make most of what you need, then you only need to do a tiny bit of design. \\$\\endgroup\\$ \u2013\u00a0Kortuk Dec 4 '10 at 20:55\n\nIn general, to measure an output impedance, you just connect a known impedance across it and measure the drop in voltage level. You can then calculate the source impedance using the voltage divider rule.\n\nvoltage divider\n\nVout = Z2/(Z1+Z2)*Vin\n\nYou know these:\n\n  \u2022 Z2 (known load)\n  \u2022 Vout (voltage with load)\n  \u2022 Vin (unloaded voltage)\n\nSo you can calculate the output impedance:\n\nZ1 = ((Vin - Vout)*Z2)/Vout\n\nIn other words, Vin and Z1 are inside your device that you're measuring, and Z2 is the test load you connect across its output.\n\nalt text\n\nIf the impedance varies with frequency, you can do the same measurement multiple times with sine waves of different frequencies. If you need to know the reactance, you'll have to measure the phase change with and without the load connected.\n\nAt low frequencies, this can all be done with a single channel scope and hobbyist equipment. At UHF I'm not sure how much effect the test equipment, scope's impedance, probe capacitance and line length, etc. will have on the measurements.\n\n  \u2022 \\$\\begingroup\\$ Thanks for the answer. However this is where I get lost when I try to put theory into practice: I don't really have a Vin, this is not some passive circuit with an input and an output. It is a circuit with a microcontroller, and a radio IC, and some RF low-pass filters, and some sensors, and maybe other things. Sure the input is a battery with around 2.7v, but that may vary with time, and I don't really think that is meant by Vin. \\$\\endgroup\\$ \u2013\u00a0bjarkef Nov 18 '10 at 20:23\n  \u2022 \\$\\begingroup\\$ Vin is the voltage at the output with no load attached. If you measure with a high enough input impedance, the effect of the source's impedance should be negligible. Vout is the voltage with a load attached. In other words, Vin and Z1 are inside your source that you're measuring, and Z2 is the test load you connect across its output. \\$\\endgroup\\$ \u2013\u00a0endolith Nov 18 '10 at 20:27\n  \u2022 \\$\\begingroup\\$ This is great information, but as I note, this is applicable at RF frequencies, I note that you say this, I am just adding and extra note. \\$\\endgroup\\$ \u2013\u00a0Kortuk Nov 18 '10 at 21:17\n  \u2022 \\$\\begingroup\\$ Good information for low frequencies but you would have a really hard time taking this approach to design a matching circuit for RF frequencies. At least without some really expensive equipment. \\$\\endgroup\\$ \u2013\u00a0Mark Nov 18 '10 at 23:55\n\nAnother approach would be to use what is known as a \"dummy\" load. It basically a large resistor with the same impedance as your antenna. This will simulate your antenna.\n\nFor \"tuning\" most people use a SWR meter. If the impedance does not match a standing wave is reflected back to the transmitter from the antenna. With a prefect match the SWR ratio should be 1 to 1. There are several ways to adjust the impedance including shortening the antenna.\n\n\nYou can measure the source resistance of a transmitter by recording the RF output voltage with a 50 ohm load and paralleling a high value resistor (should be above 1000 ohms) and recording the new RF voltage and recording the calculated new value of the load resistance due to the added resistor.\n\nCall the voltage ratio (first rf meas./second rf meas.) = N\nCall the parallel load resistor = Rn\nCall the source resistance = Rs\n\nRs = 50 x Rn x (N-1)/(50 - (N x Rn))\n\nUsing a high value resistor minimizes the Rs measurement error due to the transmitter source resistance being a dependent generator (value depending on the load resistance)."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/51738/algorithm-to-find-the-shortest-walk-with-k-leaf-nodes-on-a-tree\nText:\nLet's say I have a general tree. What algorithm can I use to find a shortest walk that starts at the root, passes through exactly $k$ different leaves, and ends at the root? Passing through a node/edge more than once is allowed.\n\nFor example, consider this graph:\n\n\nFor $k = 1$, the shortest walk would have the node 4. For $k = 2$, the leaf nodes would be 4 and 12. For $k = 3$, the leaves would be 4, 16 and 17.\n\nWhat I actually need is the length of the shortest walk (if this simplifies anything).\n\nI could not find an algorithm for this, but maybe I searched with the wrong terms.\n\n  \u2022 $\\begingroup$ What have you tried? Where did you get stuck? We do not want to just do your exercise for you; we want you to gain understanding. However, as it is we do not know what your underlying problem is, so we can not begin to help. See here for a relevant discussion. $\\endgroup$ \u2013\u00a0D.W. Jan 12 '16 at 0:21\n\nThis can be solved by a fairly standard dynamic programming algorithm. For a given node $v$, let $C(v,k)$ be the minimum length of a (closed) walk through the subtree rooted at $v$ passing through exactly $k$ leaf nodes ($C(v,k)=\\infty$ if there is no such walk).\n\nIf a node $v$ has children $c_1,\\ldots c_m$, then $C(v,k) = min_{k=a_1 + \\ldots + a_m} \\Sigma_{\\{i:a_i\\not = 0\\}} 2 + C(c_i, a_i)$ (i.e. taking the minimum over all ways to split up $k$ over the children of the node).\n\nWith some modification, this can be made to run in $O(n^3)$.\n\n  \u2022 $\\begingroup$ $O(n^2)$? Interesting. $\\endgroup$ \u2013\u00a0Hendrik Jan Jan 12 '16 at 17:40\n  \u2022 $\\begingroup$ Whoops, now that I think about it I can only do $O(n^3)$, but you definitely don't need to iterate over the exponentially many ways to split up $k$. $\\endgroup$ \u2013\u00a0Tom van der Zanden Jan 12 '16 at 17:47\n  \u2022 $\\begingroup$ How to achieve $O(n^3)$? $\\endgroup$ \u2013\u00a0hengxin May 26 '16 at 12:39\n\nYour Answer"}
{"text": "Retrieved from https://in.mathworks.com/matlabcentral/answers/636780-how-can-i-obtain-the-mean-and-standard-deviation-of-a-gaussian-pdf\nText:\nMATLAB Answers\n\nHow can I obtain the mean and standard deviation of a gaussian PDF\n\n3 views (last 30 days)\nThis might be a trivial question but i calculated 3 gaussian pdf's on the domain\nx = [0 : 0.1 : 200],\nand computed the pdf's as:\ny1 = normpdf(x,mu1,sigma1)\ny2 = normpdf(x,mu2,sigma2)\ny3 = normpdf(x,mu3,sigma3)\nI averaged them together such that:\ny_final = (y1+y2+y3)./3\nMy question is how can I obtain the the mean and standard deviation of the y_final?\n\n\nSign in to comment.\n\nAccepted Answer\n\nDavid Goodmanson\nDavid Goodmanson on 5 Nov 2020\nHi Matthew,\nhere is an example, where mu and sigma are calculated by numerical integration. Also shown are analytical results for those, which agree with the numerical results. For the mean of y = (y1 +y2 +y3)/3,\nmu = (mu1 + mu2 + mu3)/3\nwhich is not a big surprise. The variance of y is\nvar = Integral (x-mu)^2*(y1 +y2 +y3)/3 dx\nIf y1 has mean mu1 and standard deviation sigma1 then the integral involving y1 above is\nsigma1^2 + (mu-mu1)^2\nand similarly for y2 and y3. The analytic expression for the variance and standard deviation is shown below.\nNote that none of these results has anything to do with whether or not the pdfs are normal distributions. The pdfs could be anything, not even of the same type (as long as each is normalized to 1), and the result is the same.\nxplot = -20:.001:38; % use plenty of points\ngrid on\nN = integral(@(x) y(x), -inf,inf) % should be 1\nmu = integral(@(x) x.*y(x), -inf,inf) % mean\nvar = integral(@(x) (x-mu).^2.*y(x),-inf,inf) % variance\nsig = sqrt(var) % standard deviation\n% analytical calculations of mu, variance, std deviation\nmus = [16 3 9];\nsigs = [ 2 1 3];\nmuA = (1/3)*sum(mus)\nvarA = (1/3)*(sigs(1)^2 + (mu-mus(1))^2 ...\n+ sigs(2)^2 + (mu-mus(2))^2 ...\n+ sigs(3)^2 + (mu-mus(3))^2)\nsigA = sqrt(varA)\nfunction a = y(x)\n% sum of three pdfs\nmus = [16 3 9];\nsigs = [ 2 1 3];\ny1 = normpdf(x,mus(1),sigs(1));\ny2 = normpdf(x,mus(2),sigs(2));\ny3 = normpdf(x,mus(3),sigs(3));\na = (1/3)*(y1+y2+y3);\n\n\nSign in to comment.\n\nMore Answers (0)\n\n\n\n\n\nCommunity Treasure Hunt\n\n\nStart Hunting!"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/176554/evaluate-arguments-in-a-curried-function-left-to-right\nText:\nI have an inner pattern\n\nf[g, n_] := inner\n\nand I want to define an outer curried pattern\n\nf[h, m_][f[g, n_]] := ...\n\nwhich has unrelated behaviour to f[g,n] and so should receive expression f[g,n] rather than inner. Alas, f[h,m][f[g,n]] is undesiredly first evaluated as f[h,m][inner]. How can I prevent Mathematica from evaluating the inner f[g,n] whilst still recognising a pattern for f[h,m_][..] without having to explicitly insert Hold into the outermost expression?\n\nOf course SetAttribute[f, HoldAll] doesn't work, and I can't exactly set an attribute for the experssion f[h].\n\nMy motivation: I'm creating inner \"functions\" with subscript \"arguments\", and I want to define an outer \"functional\" which also has subscript \"arguments\" which should start evaluating before the passed inner functions are evaluated.\n\n\nSubscript[g1, n_] := bad[n]\nSubscript[g2, n_] := bad[n] \n\nSubscript[h, m_][ Subscript[g_,n_] ] := good[g,m,n]\n\nI want the behaviourwhere $g1_n$ gives bad[n], but $h_m[g1_n]$ gives good[g1,m,n]. The above code instead gives $h_m[bad[n]]$.\n\nI notice that the last line of the above code doesn't affect the DownValues of Subscript:\n\n\n    {HoldPattern[Subscript[g1, n_]] :> bad[n], \n    HoldPattern[Subscript[g2, n_]] :> bad[n]}\n\nIs this at all possible?\n\n  \u2022 $\\begingroup$ @kglr Actually the \"inner\" arguments aren't declared verbatim (see my motivation) $\\endgroup$ \u2013\u00a0Anti Earth Jul 3 '18 at 14:24\n  \u2022 $\\begingroup$ @kglr Pardon the over-simplicity in the original statement of my problem - please see 'my motivation' $\\endgroup$ \u2013\u00a0Anti Earth Jul 3 '18 at 14:35\n  \u2022 $\\begingroup$ Some of us here think that using Subscript while defining symbols (variables) should be avoided. Subscript[x, 1] is not a symbol, but a composite expression where Subscript is an operator without built-in meaning. You expect to do $x_1=2$ but you are actually doing Set[Subscript[x, 1], 2] which is to assign a DownValues to the operator Subscript and not an OwnValues to an indexed x as you may intend. Read how to properly define indexed variables here $\\endgroup$ \u2013\u00a0rhermans Jul 4 '18 at 8:18\n  \u2022 $\\begingroup$ I agree, but I'm still looking to do it :) I can use /: to attach an OwnValues to x if that was really a problem $\\endgroup$ \u2013\u00a0Anti Earth Jul 4 '18 at 13:19\n\nWhen I run into problems like this, I workaround it by using ReplaceAll like so:\n\nrules = {\n  f[g, n_] :> inner,\n  f[h, m_][f[g, n_]] :> outer\n\nf[h, m][f[g, n]] //. rules\n\n(* outer *)\n\nThat's because while the standard evaluation procedure looks at elements before moving up, ReplaceAll works by first trying to match the whole expression before going deeper.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Works fantastic. I'll hopelessly wait a little longer for I accept this answer :) $\\endgroup$ \u2013\u00a0Anti Earth Jul 4 '18 at 16:30\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1486538/proving-an-asymptotic-relation/1486566\nText:\nI want to show that $$ \\sum_{k=1}^{n} k^{\\alpha} \\sim \\frac{n^{\\alpha+1}}{\\alpha+1} \\ \\ \\ \\ \\ \\ n\\to \\infty$$\n\nfor $\\alpha > -1$ . So I need to show that the following limit exists and is equal to $1$ : $$ \\displaystyle \\lim_{n \\to \\infty} \\frac{\\sum_{k=1}^{n} k^{\\alpha}}{\\frac{n^{\\alpha+1}}{\\alpha+1}} $$\n\nBecause $\\alpha > -1$, it is clear that the above limit is of the type $\\frac{\\infty}{\\infty}$. Here I have doubts about using the L'Hospital's rule, because that means differentiating with respect to the upper bound of the sum which is a discrete variable, then how shoud I proceed with the computation of this limit?\n\n\n  \u2022 $\\begingroup$ use euler mac-laurin summation formula $\\endgroup$ \u2013\u00a0tired Oct 18 '15 at 21:50\n  \u2022 1\n    $\\begingroup$ Or simply look at $$\\frac{1}{n^{\\alpha+1}}\\sum_{k = 1}^n k^\\alpha$$ and think Riemann sum. $\\endgroup$ \u2013\u00a0Daniel Fischer Oct 18 '15 at 21:54\n\nUse the inequality\n\n\nwhich holds because the middle term is an upper sum for the left integral and a lower sum for the right integral. Equality holds if and only if $\\alpha=0$. Now compute both integrals, divide throughout by ${n^{\\alpha+1}}$ and let $n\\to\\infty$.\n\nAs pointed out by the8thone, the above holds for $\\alpha\\geq 0$, and for $-1<\\alpha<0$ both inequalities are reversed, but the limits are still the same.\n\n  \u2022 $\\begingroup$ Thank you, however , the inequality you wrote is true for $\\alpha \\geq 0$, for $\\alpha < 0$ we have the reverse inequalty, which finally gives the desired answer. $\\endgroup$ \u2013\u00a0the8thone Oct 18 '15 at 22:16\n  \u2022 $\\begingroup$ You are absolutely correct. I'll fix it. $\\endgroup$ \u2013\u00a0uniquesolution Oct 18 '15 at 22:16\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/297250/how-many-naked-eye-stars-have-died-since-they-emitted-the-light-we-are-seeing\nText:\nThis question is sort of in the spirit of this xkcd:\n\nThe light we get from stars was emitted many years in the past, but the distances to stars which are bright enough to be visible to the naked eye are not that great, so the light we received likely wasn't emitted long enough ago that the stars would have undertaken significant changes.\n\nOn the other hand, some bright stars are red giants, which are very bright, very far away, and pretty close to the end of their lives, so there is a higher chance that they have collapsed in the meantime.\n\nSo: what numerical fraction of stars which are visible by naked eye are likely to have undertaken significant steps in their stellar evolution? Here I'm interested both in main-sequence stars evolving into red giants, giants undergoing collapse, and similar events. Similarly, how does this answer change if you increase the range to stars that are visible using a reasonable pair of binoculars?\n\nIn case special relativistic effects are important, for the purposes of this thread, both the current frame of reference of the solar system and the rest frame of the galaxy are interesting.\n\n  \u2022 $\\begingroup$ I'd say about 0% for stars going SNe. The few in our galaxy we think we'll go SNe 'soon' are $\\lesssim1000$ ly away and not expected to go off for a few hundred thousand years. $\\endgroup$ \u2013\u00a0Kyle Kanos Dec 7 '16 at 21:03\n  \u2022 $\\begingroup$ @KyleKanos Interesting. Null results are still answers, btw ;-). $\\endgroup$ \u2013\u00a0Emilio Pisanty Dec 7 '16 at 21:08\n  \u2022 $\\begingroup$ Probably, but I'm at work (using mobile) and that comment is half an answer b/c it doesn't address evolution (there could be some candidates for helium flash, not sure) $\\endgroup$ \u2013\u00a0Kyle Kanos Dec 7 '16 at 21:11\n  \u2022 $\\begingroup$ Oh, no pressure. Astronomy is a waiting game after all ;-). $\\endgroup$ \u2013\u00a0Emilio Pisanty Dec 7 '16 at 21:12\n  \u2022 $\\begingroup$ Just a comment, I suspect the fraction decreases with a reasonable pair of binoculars, and even more with a reasonable backyard telescope. You'll be able to see a few red dwarfs with binoculars, and quite a few more with a telescope. (Plus a bunch more G and K class stars.) Nothing's go to happen to those low mass stars (which represent ~95% of all stars) in a long, long time. $\\endgroup$ \u2013\u00a0David Hammen Dec 7 '16 at 21:23\n\nThere are about 10,000 naked-eye stars (likely optimistic). Typical distances are less than a kiloparsec (3000 light-years, see for example post by @RobJeffries). Red-Giants (RG) still have a lifetime of about 10 Million years*, so only something like $10^{-4}$ would have already \"died\"... which means even if every single naked-eye star were a RG, only about 1 of those 10,000 would likely have already died. So the answer is probably 0-1 stars.\n\nSince the list of naked-eye (ish) stars is compiled, it wouldn't be too hard to just go through and see which (if any) have a non-negligible probability of having died... would be a good class project for someone! This, of course, completely neglects binarity... which is hard to model, even in detail. Naively, I think binaries are more likely to extend lifetimes than shorten them, however - so that probably makes this estimate even more optimistic.\n\nIn regards to the change from using Binoculars instead: again this could be explored using the above-linked catalog but I suspect @DavidHammen is right (in the comments above) - that the bulk of stars that become visible with Binoculars are low-mass dwarfs, decreasing the fraction of likely-to-have-died-visible-stars, and negligibly increasing the total expected number of dead stars.\n\n*Regarding RG lifetime, I'm not finding any great sources for lifetimes, but 10 Myr is the number of remember offhand. It looks like that might be on the lower end---again making this estimate more optimistic.\n\n  \u2022 $\\begingroup$ I think 1 Myr is more realistic for red giant evolution. Main sequence lifetimes for the most massive visible stars eg. Gamma Vel, are already less than 10 Myr. $\\endgroup$ \u2013\u00a0ProfRob Dec 8 '16 at 0:05\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1664140/4-married-couples-and-2-single-men-will-sit-at-a-circular-table\nText:\n$4$ married couples and $2$ single men sit at a circular table. In how many ways can they sit so that a man can't sit next to a woman who is not his wife?\n\nI have tried but I am not sure to the following answer :\n\nFirst, the husbands sit in the circular table of which the possible ways is $3!$.\n\nThe wives should sit next to her husband which is only $1$ way.\n\nThe two men can only be put between two husbands in only $2$ ways and they then can be permuted in $2$ ways. So the number of ways is $4$.\n\nBy applying the multiplication principle, the total number of ways for this possibility is $3! \\times 4$ = $24$.\n\nThe second possibility is similar which is making the wives sit first and put each husband next to his own wife and then put the single men. The total number of ways is also $24$.\n\nSo the answer is $24 + 24 = 48$.\n\n\nAs each woman has two neighbors, one way to have a woman not sit next to a man who is not her husband is to line up husband$_1$ wife$_1$ wife$_2$ husband$_2$ twice. Then we have three ways to pair up the couples and two ways to flip each pair left/right. We might as well put the leftmost of the pair including husband A at seat $1$ to break the rotational symmetry. Then there are three groups of seats for the other married couple and a factor two for placing the single men. Total is $$3 \\cdot 2^2 \\cdot 3 \\cdot 2=72$$\nThe other way to deal with the women is to place all four together in some order, $4!$ ways and seat the husbands of the end ones next to them. Again break the symmetry by seating the leftmost woman in seat $1$. Now you can arrange the other four men any way you want, another $4!$ ways, giving $$4!^2=576$$ The total is then $$72+576=648$$\n\n  \u2022 $\\begingroup$ Do you think OP wants to consider rotational overcounts? $\\endgroup$ \u2013\u00a0K. Jiang Feb 20 '16 at 13:42\n  \u2022 $\\begingroup$ +1 for rechecking an earlier answer that had been wrong. $\\endgroup$ \u2013\u00a0Oscar Lanzi Feb 21 '16 at 3:38\n\nI get 648.\n\nThe women must sit in two pairs of adjacent seats, and if the pairs are separated there must be at least two intervening positions (for different husbands) in each direction.\n\nThis leads to three distinct arrangements for the women: 1-2-3-4, 1-2-5-6, 1-2-6-7. In the first case two men must sit next to their respecive wives in positions 5 and 10, while the other four men sit in any fashion that choose in positions 6-7-8-9. Thus 24\u00d724 = 576 permutations. For the second arrangement of the women, all four husbands must sit next to their wives leaving only the two single men with any free choice. Thus 24\u00d72 = 48 permutations.\n\nThe third female arrangement is tricky, in fact I had to edit my answer because I got it wrong the first time. If we count 24 permjtations for the women and two for the single men we seem to get 48. But because the women (and their husbands) are in a twofold rotationally symmetric arrangemet only half of these 48 are actually distinct. So we can really count only 24 additional permutations to go with the 576+48 from the other cases. Total: 648.\n\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/121141/nonhyperbolic-groups-that-contain-no-free-abelian-groups-or-baumslag-solitar-gro\nText:\nI've heard it conjectured that a finitely presentable group $G$ is hyperbolic if it satisfies the following two conditions.\n\n  1. $G$ contains no subgroup isomorphic to a Baumslag-Solitar group $BS(n,m)$ (including $BS(1,1) \\cong \\mathbb{Z}^2$).\n  2. $G$ is rationally of finite type in the sense that all the groups $H_k(G;\\mathbb{Q})$ are finite-dimensional and $H_k(G;\\mathbb{Q})=0$ for $k \\gg 0$.\n\nQuestion : Can someone tell me an example of a finitely presentable group that satisfies $1$ but but not $2$? All the examples of finitely presentable groups I know of that don't satisfy $2$ actually have plenty of copies of $\\mathbb{Z}^2$ in them.\n\n  \u2022 $\\begingroup$ You probably know this, but if you relax f.p. to f.g. then I believe the first Grigorchuk group is an example (right?). $\\endgroup$ \u2013\u00a0Khalid Bou-Rabee Feb 8 '13 at 2:58\n  \u2022 1\n    $\\begingroup$ @Khalid Bou-Rabee : That's right; it has infinite $\\mathbb{Q}$-cohomological dimension (and it might have infinite rank $H_2$, though I don't know off the top of my head). $\\endgroup$ \u2013\u00a0Steven Feb 8 '13 at 3:05\n  \u2022 $\\begingroup$ Steven: Your finiteness conditions are not quite right, in the conjecture you should assume instead that your finitely-presentable group $G$ has type $FP$ over ${\\mathbb Q}$, i.e., ${\\mathbb Q}$ admits a finite resolution by finitely-generated projective $G[{\\mathbb Q}]$-modules, see Brown's book \"Cohomology of groups\". This is a much stronger assumption than your assumption on homology groups with trivial coefficients. If $G$ is torsion-free, you can simply say that $G$ admits a finite $K(G,1)$. Even then, this conjecture is widely expected to fail. $\\endgroup$ \u2013\u00a0Misha Feb 8 '13 at 7:21\n  \u2022 $\\begingroup$ If you're interested in this problem, you may also want to take a look at the idea to find a counterexample in this paper: Benson Farb and Lee Mosher, Convex cocompact subgroups of mapping class groups, Geom. Topol. 6 (2002), 91\u2013152 (electronic). MR MR1914566. $\\endgroup$ \u2013\u00a0Autumn Kent Feb 8 '13 at 14:40\n\nNoel Brady's finitely presented non-hyperbolic group embeds in a hyperbolic group (and hence satisfies (1)), but has infinitely generated third integral homology.\n\nI'm guessing, but don't remember with certainty, that the rational third homology is infinitely generated.\n\nNoel Brady, Branched coverings of cubical complexes and subgroups of hyperbolic groups, J. London Math. Soc. (2) 60 (1999), no. 2, 461\u2013480. MR MR1724853\n\n  \u2022 $\\begingroup$ I'm fairly certain that this is the only known example of a group with this property. I don't know a reference for this fact (though asking Noel would be a good start) - I thought this was stated explicitly in Bridson's problem list on the AIM 'Open Problems in Geometric Group Theory' wiki, but the wiki seems to have vanished! $\\endgroup$ \u2013\u00a0HJRW Feb 8 '13 at 10:24\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/307752/2d-elastic-collision-in-the-center-of-mass-frame-of-reference/307799\nText:\nIn a collision between two spheres $A$ and $B$, their velocities are symmetric ($v$ and $-v$, respectively) in the center-of-mass frame of reference. The final speed of $A$ does a $45\u00b0$ angle with its initial velocity.\n\nDetermine the final speed of the spheres if the collision is elastic, in the frame of reference where the sphere B is initially at rest.\n\nHow do I solve this? I am not used to solve these problems with the center-of-mass frame of reference.\n\n\nThe centre of mass frame information is there to give you some information about the relative masses of the two spheres and the initial speed of sphere $A$ in terms of speed $v$.\nThe rest of the problem can then be done in the reference frame of sphere $B$ which you would have done many times before.\n\nIf you decide correctly about the relative masses the problem can be solved fairly easily by writing the conservation of kinetic energy equation from which the shape of the momentum vector addition triangle can be inferred.\n\n\nFinish the calculation in the CoM frame of reference. That is the frame in which the problem is set.\n\nThen transform from the CoM frame to the frame of reference in which B is initially at rest by adding the reverse of the initial velocity vector of B (ie $-\\vec{u_B}=+\\vec{v}$) to each of the final velocities in the CoM frame.\n\nThe wording of the question does not make clear whether the collision is elastic in the CoM frame or in the frame in which B is initially at rest. Does this matter? No. The amount of KE each sphere has depends on which frame you are measuring it in, but the fact that total (kinetic) energy is conserved in the collision does not depend on which frame of reference you are using. If the collision is elastic in the CoM frame, it is elastic in the rest frame of B also.\n\n  \u2022 $\\begingroup$ Why do we transform in the COM frame tho.....is it because of it being momentum conserved frame and elastic collision is known to have its momentum conserved so why do we have to change back then $\\endgroup$ \u2013\u00a0user195235 Aug 15 '18 at 11:25\n  \u2022 $\\begingroup$ @user195235 The COM frame is specified in the question, so we have to use it to solve the problem. And we have to change to another frame because that is what the question asks for. However, generally there is no requirement to use one frame or another if the question does not require it. You can use whatever frame you find convenient. The COM frame sometimes makes the problem easier. In other cases the solution might be obvious or more intuitive in a non-inertial frame of reference. $\\endgroup$ \u2013\u00a0sammy gerbil Aug 19 '18 at 17:35"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/69910/how-to-solve-this-partial-order-reduction-in-on2/69934\nText:\nThere are two orderings of numbers from the same set. Number $a$ is \"immediately before\" $b$ iff $a$ appears before $b$ in both sequences and there is no other number that appears between them in both sequences.\n\nSo in this example:\n\nSeq 1: 1 2 3 4 5 6\nSeq 2: 6 2 1 3 5 4\n  \u2022 1 is not immediately before 2 because they appear in opposite orders.\n  \u2022 1 is not immediately before 4 because 3 appears between them in both sequences.\n  \u2022 2 is immediately before 3 and 3 is immediately before 4.\n\nThe problem is to find all pairs $a$, $b$ such that $a$ is immediately before $b$ in $O(n^2)$ time. How can this be done?\n\nI understand that the naive solution can work in $O(n^3)$: For each pair in the first sequence ($n^2$ pairs) verify it using the second sequence ($O(n)$ time).\n\n\nYour solution looks good to me, except that your lookup arrays are a bit handwavy: What happens if the set contains negative numbers? Or what if it contains an extremely large number ($\\gg n^2$), so that the arrays would need to be massive?\n\nTo address this, I'd suggest creating just a single lookup table, that instead of mapping from values to indices, maps from indices in one sequence to indices in the other. Thus seq2[i] = seq1[translator[i]]. You can build that table in $\\mathcal{O}\\left(n^2\\right)$ time using nested loops. You can then ignore seq1 and seq2 in all of your logic: the problem becomes, \"find all pairs of indices (i, j) such that i < j, that translator[i] < translator[j], and that i < k < j precludes translator[i] < translator[k] < translator[j]\" (which you can solve using basically the same approach as what you've written). The only time you'd refer to seq1 or seq2 again is when you're adding an entry to the result (since for that you want the actual values rather than the indices).\n\n\nI think I am able to solve it.\n\nFirst, have a lookup array for each sequence where array[element] = element's position in sequence [O(1)].\n\nPhrased another way, this algorithm will find all \"successors\" for each of the elements in the first sequence. Finding successors for each element will take O(n) time.\n\nFor i in range(0,n):\n    initialize most_recent_successor to None\n    For j in range(i+1, n):\n        if pos. of seq_1[j] > pos. of most_recent_successor in both sequences:\n            advance j\n            most_recent_successor = seq_1[j]\n            add (seq_1[i], seq_1[j]) to result\n\nEssentially, if a valid pair (seq_1[i], seq_1[j]) exists, then any pair (seq_1[i], seq_1[k]) will not be valid if the position of seq_1[k] in comes after the position of seq_1[j] in both sequences.\n\nSo, for the example in the question, (1, 3) is a valid pair. Therefore, (1,4) and (1, 5) are not valid pairs since 4 and 5 come after 3 in both sequences.\n\nEdit: Please look at ruakh's insightful answer on lookup arrays I used here.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/double-integral.349791/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nDouble Integral\n\n  1. Oct 28, 2009 #1\n    I need to find the area of the hyperbolic paraboloid z=xy contained within the cylinder x^2+y^2=1. I know I need to take a double integral but am having real difficulty finding the correct limits, so far I've got that;\n\n    [tex]\\int dx[/tex][tex]\\int dy[/tex]\n\n    With the x limits being 1 and -1 and the upper y limit to be sqrt(1-x^2) I'm having trouble finding the lower y limit. Although to be honest I'm not completely sure about the other three limits! Sorry about my awful attempt at Latex-ing I don't know how to do it so couldn't write the limits of the integrals on the integral. Any help would be great! Thanks.\n  2. jcsd\n  3. Oct 29, 2009 #2\n    the problem is symmetric by pi/2 so I'd just stick to the (+,+) quadrant and your lower limit is y=0. Then your x limits would be 1 and 0.\n\n    The area in the entire domain is then four times the area in a single quadrant.\n  4. Oct 29, 2009 #3\n\n\n    User Avatar\n    Science Advisor\n\n    I have no idea what you mean by\n    Shouldn't there be some function to be integrated in that? And it probably is NOT\n    [tex]\\int dx\\int dy[/tex]\n    but rather\n    [tex]\\int f(x,y) dxdy[/tex]\n    Even ignoring the \"f(x,y)\" the two separate integrals implies that the two coordinates can be separated- which is not the case here- at least not in Cartesian coordinates.\n\n    The surface area of z= f(x,y) is given by\n    [tex]\\int\\int \\sqrt{1+ \\left(\\frac{\\partial f}{\\partial x}\\right)^2+ \\left(\\frac{\\partial f}{\\partial y}\\right)^2} dA[/tex]\n    where dA is the differential of area in whatever coordinate system you are using, in the xy-plane. Because of the circular symmetry I would recommend changing to polar coordinates- where the two coordinate variables can be separated."}
{"text": "Retrieved from https://www.physicsforums.com/threads/orbital-mechanics.839274/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nOrbital mechanics\n\n  1. Oct 23, 2015 #1\n    I'm having trouble with orbItal mechanics, I'm trying to determine the total potential energy of an orbiting satellite, what I've done so far is this:\n    I know m*g*h is potential energy, but I also know that gravity deceases with distance avoiding to the inverse square law. I know I Just can't use the satellites current Ag because that will increase as it falls towards the earth, and I'm having trouble determining exactly what that is.\n    This is giving me serious trouble because I want to calculate periapsis or apoapsis given just one of those two, and the velocity at that point.\n  2. jcsd\n  3. Oct 23, 2015 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    The gravitational potential energy of an orbiting body is different from mgh, which applies only to something located close to the surface of a planet, like earth.\n\n\n    U = -GMm / r\n\n\n    M - Mass of the planet, kg\n    m - mass of the orbiting body, kg\n    G - Universal Gravitational Constant = 6.67408 \u00d7 10-11 m3/kg-s2\n    r - distance between the centers of mass of M and m, in meters\n    U - gravitational potential energy (= 0 when r \u2192 \u221e)\n  4. Oct 23, 2015 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'd make one adjustment to SteamKing's equation. Use specific energy per unit of mass.\n\n    F= -GMm/r^2\n    therefore, a=GM/r^2\n\n    All objects accelerate at the same rate (due to gravity).\n\n    Since it's the motion you're interested in, you can do the same with the energy (divide out the mass). And, if you do need to know the energy (to determine how much fuel to do a delta V, for example), you just multiply the specific energy (or the change in specific energy) by the mass when you need that info.\n\n    Likewise, your specific kinetic energy would be (v^2)/2. And your total specific energy would be (GM)/(-2a), where a is the semi-major axis of your orbit.\n\n    Given that you mentioned Earth, I assume you're talking about a satellite orbiting Earth? The universal gravitational constant and the mass of the Earth are constant. Once you've multiplied them together once, you can just remember the answer. You can even look up the answer in a book. It's your geocentric gravitational constant (3.986 x 10^5 km^3/sec^2).\n  5. Oct 28, 2015 #4\n    Is it really that simple? It makes sense but It seems too simple. I came up with that about two weeks ago but I didn't believe myself when I did it. I guess I'll just have to launch a scientific mission in KSP to verify it.\n  6. Oct 28, 2015 #5\n    Wait, that doesn't make sense, by getting higher your potential energy decreases? And in a higher orbit you move slower so your kinetic energy decreases too, that can't be right.\n    I'm looking for \u03a3 specific potential energy, our the whole of all the specific kinetic energy that would be gained from a fall of such altitude.\n  7. Oct 28, 2015 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    First, you were looking for orbital elements; now, you're looking for the K.E. a satellite gains by falling out of orbit.\n\n    This article discusses orbital mechanics in some detail:\n\n\n    This article talks about the relationship between gravitational P.E. into K.E. for an orbiting body:\n\n  8. Oct 28, 2015 #7\n    No. Notice the minus sign in front of the expression fro PE.\n    The PE increase as you go higher, the maximum value being zero. This is so because the reference is chosen to be at infinite distance.\n  9. Oct 28, 2015 #8\n    I don't see how my request has changed. if an object has 25,000,000 Joules of kinetic energy when it impacts, then it must have had 25,000,000 Joules of potential energy when it began to fall. I am just looking for the potential energy of an object in freefall beginning at a distance where the gravitational inverse-square law becomes relevant, as I always have been. maybe I was sloppy with my wording before, but I truly do not see a difference between what I was originally asking for and the description you gave here.\n  10. Oct 28, 2015 #9\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    The gravitational inverse square law is always relevant, regardless of distance. After all, this law still works between Pluto and the Sun, even though these two bodies are separated by a distance of some 4.5 billion kilometers.\n\n    If you want to calculate the periapsis or apoapsis of an orbiting body, then application of Newton's laws of motion can tell you this.\n\n    If you want to calculate the impact energy of a body falling out of orbit, a different application of the same laws is required.\n\n    Depending on the problem you want to solve, you have to tailor the analysis to obtain the solution. It is not immediately obvious how knowing the periapsis of an orbiting body will necessarily convert into the K.E. of that body hitting the ground.\n  11. Oct 28, 2015 #10\n\n\n    User Avatar\n    Science Advisor\n\n    No, it must have had 25,000,000 more Joules of potential energy when it began to fall than when it impacts. Zero is 25,000,000 more than -25,000,000.\n  12. Oct 28, 2015 #11\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    The total orbital energy of your satellite is the sum of it's kinetic and potential energies.\n    KE = mv2/2\n    GPE = - GMm/r\n    (note since r is measured from the center of M, working out the potential energy difference between the satellite in orbit vs on the ground means solving the following\n    [tex]\\Delta GPE = \\frac{GMm}{r_E}- \\frac{GMm}{r_o}[/tex]\n\n    Where rE and ro are the Earth's radius and orbit radial distance\n\n    Now, to get to your orbital question:\n\n    We start with:\n\n    (1)[tex]E= \\frac{mv^2}{2}- \\frac{GMm}{r}[/tex]\n\n    If we assume a circular orbit, we know that [itex]v= sqrt{\\frac{GM}{r}}[/itex]\n\n    subbing for v, and reducing the equation gives\n\n    (2)[tex]E=- \\frac{GMm}{2r}[/tex]\n\n    It also turns out that this equation holds for elliptical orbits if we use a, the semi-major axis for r:\n\n    (3)[tex]E=- \\frac{GMm}{2a}[/tex]\n\n    If we equate equation 1 and 3 and solve for a, we get\n\n    [tex]a =\\frac{1}{\\frac{2}{r}-\\frac{v^2}{GM}}[/tex]\n\n    which gives us the semi-major axis if we know the velocity at r\n    (This last equation is a re-arrangement of the vis viva equation)\n\n    Now its just a simple case of knowing that\n\n    [tex]a= \\frac{r_{per}+r_{app}}{2}[/tex]\n\n    to find either apogee or perigee if you know the other and the velocity at it."}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-harmonic-motion-inside-earth.164142/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Harmonic Motion Inside earth\n\n  1. Apr 4, 2007 #1\n    A particle is dropped into a hole drilled straight through the center of the Earth. Neglecting rotational effects, show that the particle's motion is simple harmonic if you assume Earth has uniform density. Show that the period of the oscillation is about 84 min.\n\n    2. Relevant equations\n    [tex]F = -G m \\int_V \\frac{\\rho(r') e_r}{r^2}dv'[/tex]\n\n    3. The attempt at a solution\n\n    I was going to use Newton's second law to show that\n    [tex] m \\frac{d^2 r}{dt^2} = -G m \\int_V \\frac{\\rho(r') e_r}{r^2}dv'[/tex]\n\n    Where the volume integral should produce some function of r. So, I started off the integration by choosing an arbitrary point in the sphere a distance r' away, and using R as the distance from the origin to the point mass, r as the distance between the arbitrary distance and the distance of the point mass, theta as the asimuthal angle, and phi as the rotational angle I got.\n\n    [tex]m \\frac{d^2 r}{dt^2} = -G m \\int_0^{R} \\int_0^\\pi \\int_0^{2\\pi} \\frac{\\rho r'^2 sin\\theta}{r^2}dr' d\\theta d\\phi[/tex]\n\n    integrating with respect to phi brings in a factor of 2\u03c0, and now I used law of cosines\n\n    [tex]r^2 = r'^2 + R^2 - 2r'Rcos\\theta[/tex]\n\n    [tex] 2r dr = 2r'Rsin\\theta d\\theta[/tex]\n\n    [tex]\\frac{sin\\theta}{r}d\\theta = \\frac{dr}{r'R}[/tex]\n\n    so the substitute the law of cosines stuff into the force equation\n\n    [tex]F = \\frac{-2 \\pi G m \\rho}{R} \\int_0^R r'^2 dr \\int_{r'-R}^{r'+R} \\frac{1}{r}dr[/tex]\n\n    doing the r' integral I can see that this ultimately won't give a linear function of R\n\n    [tex]\\frac{2 \\pi}{3} \\frac{G m \\rho}{R} R^3 \\int_{r'-R}^{r'+R} \\frac{1}{r}dr [/tex]\n\n    Can someone help me out, point out what I did wrong, put me on the right track?\n\n    I think that once I find the right equation for force, which I actually know from experience should be [tex]F(r) = -\\frac{4 \\pi}{3}G m r \\rho[/tex], that I can do the differential equation stuff.\n  2. jcsd\n  3. Apr 5, 2007 #2\n    You're making it too complicated. Assume that the density of the earth is a constant function, and realize that because of the character of the 1/r^2 force law, you can turn this into a surface integral. Once you do that, you're golden.\n  4. Apr 5, 2007 #3\n\n\n    User Avatar\n    Gold Member\n\n    At any point in the fall, the only mass exerting a nett force on the test body is that contained inside the current radius because the shell of matter outside the radius has no effect. So the force at point x is\n\n    [tex]F(x) = -\\frac{4}{3}\\pi Gm\\rho x^3/x^2[/tex]\n\n    which gives\n\n    [tex]F(x) = -Kx[/tex]\n\n    QED I think. Assuming uniform density.\n    Last edited: Apr 5, 2007"}
{"text": "Retrieved from https://www.physicsforums.com/threads/coupled-oscillator.330209/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCoupled Oscillator\n\n  1. Aug 11, 2009 #1\n\n\n    User Avatar\n\n\n    One mass [itex]m[/itex] constrained to the x-axis, another mass [itex]m[/itex] constrained to the y-axis. Each mass has a spring connecting it to the origin with elastic constant [itex]k[/itex] and they are connected together by elastic constant [itex]c[/itex]. I.e. we have a right-angle triangle made from the springs with lengths [itex]b[/itex], [itex]b[/itex], and [itex]\\sqrt{2} b[/itex].\n\n    Write the Lagrangian, find the normal mode frequencies.\n\n    3. The attempt at a solution\n\n    Again having trouble with the coupling. For the two springs connected to the origin the potentials are straightforward:\n\n    [tex]V = \\frac{1}{2} k x^2 + \\frac{1}{2} k y^2[/tex]\n\n    Given the geometry wouldn't the coupling spring add the potential,\n\n    [tex]V = \\frac{1}{2} c \\left [ \\sqrt{x^2 + y^2} - \\sqrt{2} b \\right ]^2 = \\frac{1}{2} c \\left [ x^2 + y^2 - 2 \\sqrt{2 x^2 + 2 y^2} + 2 b^2 \\right ][/tex]\n\n    But I don't know how to put this in matrix form...\n    Last edited: Aug 11, 2009\n  2. jcsd\n  3. Aug 11, 2009 #2\n    I reworked the problem and got the same potential as you, so it looks like you do indeed have the spring interaction potential correct. It looks a bit pesky because of the presence of the square root. This would make a closed form solution a bit difficult.\n\n    I did think of a potential trick you could use (I don't remember if I read this in a textbook or came up with it myself...hopefully the former). You could try converting to polar coordinates with,\n\n    [tex]x = r cos(\\theta)[/tex]\n    [tex]y = r sin(\\theta)[/tex]\n\n    Be careful here, because in this context [tex]r[/tex] and [tex]\\theta[/tex] don't have any physical meaning; it's merely a math trick. You can then rewrite the Lagrangian with these new generalized coordinates. If my algebra/calculus are right, you should get the following set of differential equations:\n\n    [tex]m\\ddot{r} = -(k + c)r + cb[/tex]\n    [tex]\\ddot{\\theta} = 0[/tex]\n\n    This seems comparatively a lot easier than what you would likely get by writing the Lagrangian using the generalized coordinates that you were working with. And the first differential equation looks like it will give you the oscillatory motion (without damping) that you would expect. After you solve for the two coordinates, you can transform back into the coordinates given in the problem.\n\n    Disclaimer: I don't know if this method will work, and indeed I see one potential pitfall. When you transform into polar coordinates, you get the weird effect of [tex]\\theta = \\theta + 2\\pi[/tex]. I normally leave it to the mathematicians to prove that physics math tricks actually work, but in this case I could see this as possibly being the cause of an incorrect solution. But hey, try it out and see what happens\n  4. Aug 11, 2009 #3\n\n\n    User Avatar\n\n    Thanks for your insight. I may have misled you into thinking I needed to the differential equations because I asked for the Lagrangian. I'm trying to get the normal mode frequencies by solving the eigenvalue problem.\n\n    I was thinking your trick might help still but it seems [itex]\\theta[/itex] drops out of the expression for V.\n\n    [tex]T = \\frac{1}{2} m \\dot{r}^2[/tex]\n\n    [tex]V = \\frac{1}{2} c (r^2 - 2 \\sqrt{2} r)[/tex]\n\n    (constant term dropped in V)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/2-dielectrics-in-a-parallel-plate-capacitor.419835/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\n2 Dielectrics in a Parallel Plate Capacitor\n\n  1. Aug 2, 2010 #1\n    So, I know what happens with the first two cases, but what if the dielectrics are on a diagonal?\n\n  2. jcsd\n  3. Aug 2, 2010 #2\n    Nice drawing :)\n\n    You could try to split this capacitor into pieces. So you make horizontal cuts and for each strip you cut at the boundaries of dielectrics.\n    Now you use the equation\n    [tex]C=\\frac{\\varepsilon A}{d}[/tex]\n    for each little piece and add up these partial capacitance according to your equation to yield the overall capacitance.\n    What you get in the end is\n    The only problem is that now its ill-defined what C1 and C2 were. I mean in you first two examples you just remove one colour and stick the plates to whatever is left to get C1 and C2. But if you do that for your diagonal case, then the plates touch and thus are not a capacitor anymore.\n\n    Is that clear?\n  4. Aug 2, 2010 #3\n    Thanks. The logic / ideas make sense but I am having trouble getting your formula. Could you show an extra step or two?\n  5. Aug 2, 2010 #4\n    One strip has capacitance\n    [tex]\\frac{1}{dC}=\\frac{1}{\\frac{dx\\cdot dy \\varepsilon_1}{h}}+\\frac{1}{\\frac{dx\\cdot dy \\varepsilon_2}{d-h}}[/tex]\n    where x is the distance of one strip from the top, y the distance into the plane, so dx dy is an area element, epsilons are the dielectric constants, d the total separation between plates and [itex]h=\\alpha x[/itex] (giving a diagonal) the width of one strip from a single dielectric. Also alpha is adjusted to give [itex]d=\\alpha x_\\text{end}[/itex]. You plug in h and integrate\n    [tex]C=\\int_0^{x_\\text{end}}dx\\int_0^{y_\\text{end}}dy dC[/tex].\n  6. Aug 2, 2010 #5\n    Btw, it should be\n    1/C=1/C1+1/C2 ;)\n    in your second example."}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-reliable-are-logarithm-tables.903910/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nB How reliable are logarithm tables?\n\n  1. Feb 14, 2017 #1\n    Today I came across a high school math book which has a particular problem in the logarithms chapter. It has\n    $$ \\log_{10}{0.2913} = -1.4643 $$\n    Trying to verify it with a calculator, I get -0.53566. There's a log table attached at the end which agrees with the calculation made in the book. To make sure there wasn't a typo, I looked up online for the common logarithm table and found tables that agree with it. Trying to verify the book's calculation, I got (with a calculator)\n    $$ 10^{-1.4643} = 0.034332 $$\n    Now am I missing something or is it something wrong with the logarithm tables I have? Admittedly, it has been a very long time since I last calculated logarithms using a table.\n    Last edited: Feb 14, 2017\n  2. jcsd\n  3. Feb 14, 2017 #2\n\n\n    User Avatar\n    2017 Award\n\n    Staff: Mentor\n\n    That is a very odd error, as it is off by nearly (but not exactly) 1. Are the logarithm values next to it wrong in a similar way?\n    Does your logarithm table really have exactly this entry?\n  4. Feb 14, 2017 #3\n    It is off for the next value in the same problem too. It calculates $$ \\log_{10}{0.004236} $$ as -3.6269 while with a calculator I get -2.373044.\n    Even weirder is that it proceeds to add the two logarithms (which it calculated as -1.4643 and -3.6269) to get -3.0912. Then it proceeds to take the anti-log of -3.0912 and gets 0.001234 (while with a calculator I get $$ 10^{-3.0912} = 0.0008106 $$). At this point I stopped taking the book seriously but thought I'd make sure whether it's a problem with me or the book before I explain it to my friend. o0)\n  5. Feb 14, 2017 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    It's written in what we called 'bar' notation in school .\n\n    Roughly : number of decade shifts + basic log of number in range 1 to 10\n\n    0.4643 is the log of 2.913\n\n    log of 0.2913 = -1 + 0.4643 = - 0.5357\n\n    You can see why this works :\n\n    log 0.2913 = log 2.913 - log 10\n  6. Feb 14, 2017 #5\n    Oh. So the bar isn't actually a negative? Why would they decide to write it this way? o_O\n    Last edited: Feb 14, 2017\n  7. Feb 14, 2017 #6\n    Are there cases where the bar notation is useful other than confusing poor unsuspecting readers?\n  8. Feb 14, 2017 #7\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    It greatly reduces the number of log values that are needed in tables . All you need are logs for numbers in range 1 to 10 .\n\n    There are also some small advantages in making calculations more systematic and in reducing chance of order of magnitude errors in final answers .\n  9. Feb 14, 2017 #8\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Conventionally written down like this :\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/probability-choice-of-boxes.303637/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nProbability: choice of boxes\n\n  1. Mar 30, 2009 #1\n    hi, I am writing a computer algorithm which descibes the change of choice.\n\n    1.your friend puts $10 in a box among three (there are three boxes) but you don't know which.\n    2.you choose one of them but do not open it.\n    3.your friend opens (eliminates) one of empty boxes\n    i.e. if you choose the lucky box, he eliminate either one of two empty boxes at equal probability\n    and if you choose an unlucky one, he eliminates the empty remainder.\n    4.then you decide, whether or not you change your choice between two remainings.\n    5.repeat 1~4 many times and expect the maximum result(in $).\n\n    Question: you'd better change your choice? or should not change? for the maximum outcome.\n\n    I expected that the change of choice should not matter: the equal probabilities.\n\n    but my computer algorithm tells that \"if you change the choice, better\"\n\n    Can someone tell me whether I am wrong or my algorithm is wrong?\n  2. jcsd\n  3. Mar 30, 2009 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The algorithm is right. Search for Monty Hall problem (here or on the search engine of your choice). It's a popular topic. In short: picking the remaining box is really as good as picking both remaining boxes, and there's a better chance it's in one of the two remaining boxes than in your original 1.\n  4. Mar 30, 2009 #3\n    Thank you for such a quick reply!\n    I will check it out. but your explanation helped a lot, CRGreathouse!"}
{"text": "Retrieved from http://mathforum.org/blogs/pows/mentoring-the-cherokee-creek-checkers-club-algpow-with-the-noyce-scholars/\nText:\nLast Friday, I was invited to speak about the Problems of the Week to the Northeast region Noyce Scholars (early career and future STEM educators, and a really fun group to do math with!).\n\nSince I\u2019d been thinking a lot about the AlgPoW that just wrapped up, Cherokee Creek Checkers Club, we looked at that problem and some students\u2019 work on the problem.\n\nWe began with this scenario:\n\nCherokee Creek Middle School has a checkers club with an enthusiastic group of players. Unfortunately, they started this semester in a bit of a slump, winning only 40 of their first 90 games in various inter-school competitions. That gave them a winning percentage of only about 44%.\n\nThen they found a new coach, who inspired them and significantly improved their overall level of play. This month they went on a hot streak, winning 3 out of every 5 games they played.\n\nWe used a scenario to loosen our thinking up and try to focus on three big preparation themes: prerequisite knowledge, big math ideas, and multiple approaches.\n\nLooking at the scenario, the Noyce Scholars noticed and wondered about cool math like:\n\n  \u2022 Quantities are represented as percentages, fractions, and ratios in this problem.\n  \u2022 How could you determine which coach was better? How do you know for sure?\n  \u2022 What\u2019s the overall winning percentage, based on the number of games played, before and after the new coach.\n  \u2022 If they won 40 out of 90 games at first, how many games might they play over a year? A week?\n  \u2022 How come winning 3 out of 5 is an improvement over winning 40 out of 90?\n  \u2022 They increased their winning percentage by 16 percent\n\nAll of these noticings and wonderings gave us insight into two of our three foci.\n\n  1. What do students need to know/understand to work on a problem about this story?\n    \u2022 Fractions, ratios, and percents and how they are related\n    \u2022 How winning percentages are calculated\n    \u2022 That two coaches are being compared and one might be better than the other; the team improved over time\n  2. What big math ideas are at work here?\n    \u2022 Comparing two quantities using fractions, ratios, and percentages\n    \u2022 Change in one quantity as a function of another e.g. overall winning percentage as a function of games played with the new coach\n\nOur third focus is multiple approaches, and for that we needed a problem to solve. I revealed that after playing some more games, the team\u2019s overall winning percentage climbed to exactly 52% and we wondered, \u201chow many games did they play? How many did they win?\u201d Recalling that they won 3 out of every 5 games, we set to work.\n\nThe multiple methods that we used were Make a Table, Guess and Check, and Make a Mathematical Model (an algebraic model, in this case).\n\nThen we took a look at the work of an Algebra I student, M.:\n\n\nThey played 85 games that month\n\n\nFor this problem I did guess and check. First I tried 40/90 and 30/50 because it says they won 3/5 games so 70/140 was 50% which was too little so I tried 33+40/55+90 and got 50.3% so I realized I needed to go up a lot more. Then I tried 60/100 + 40/90 and 100/190 and got 52.6% so I went down a bit and did 94/180 and got 52.22222% so I went down more and did 91/175 and 52% evenly. so they had played 90 games and now they played a total of 175, so they played 85 games that month\n\nCheck- 40/90 + 51/90 is 91/175 which is 52%\n\nHere are some of the initial things we noticed and wondered about M\u2019s work:\n\n  \u2022 She checks her work at the bottom\n  \u2022 In the check, she adds 40/90 + 51/90 = 91/175 and we wondered how she was using that calculation to check her work\n  \u2022 We also wondered in the check if she meant 51/85 instead of 51/90 because 51/85 was used earlier in the problem and would represent winning 3 out of every 5 games (17 sets of 5 games)\n  \u2022 We wondered how she thought of her first guess, 30/50\n  \u2022 We noticed that sometimes she used \u201cand\u201d and sometimes she used the \u201c+\u201d sign\n  \u2022 We noticed she used fraction notation and wondered if she was using it informally, using \u201c+\u201d to mean \u201cand\u201d and using \u201c/\u201d to mean \u201cout of\u201d\n  \u2022 We noticed that she got the correct answer, and it didn\u2019t take her very many guesses at all!\n\nAnd finally, we thought of some questions we could ask M. to help her revise her work and keep reflecting on the problem such as:\n\n  \u2022 This time, it took you 5 guesses to get the answer. What are some ways you could find an answer with fewer guesses next time you solve a similar problem?\n  \u2022 How did you decide what guess to start at? What did you notice in the problem that led to your first guess?\n  \u2022 How would you explain your steps and calculations to another student who is stuck and doesn\u2019t understand how to make a guess and check it?\n  \u2022 Each time you did a calculation you wrote it a different way. If you pick one of the ways (e.g. 33+40/55+90) and translate all the other calculations into that format, what patterns do you notice in the calculations?\n\nThe final step, which we ran out of time for, is to get feedback on the questions we generated. Which of them are engaging? Which inspire reflection and meta-cognition? What do you think of the tone of each question?\n\nBy the way, if you\u2019re interested in the process of looking at student work and finding the right question to ask, we are focusing a new set of Professional Development courses on it this year. We\u2019d love to have you join us!\n\nIf you teach with the PoWs, or work with pre-service teachers, you might also be interested in our free mentoring, which pairs volunteer pre-service teachers with students working on the PoWs. The mentors learn to ask good questions and the students get feedback on their mathematical thinking.\n\nSome \u201cCherokee Creek Checkers Club\u201d links in case you are interested:"}
{"text": "Retrieved from http://mathoverflow.net/questions/74293/non-trivial-isotrivial-family-of-elliptic-curves-over-c-times/74343\nText:\nTake the 2-minute tour \u00d7\n\nSo How does one prove (rigorously) that $$ Frac(\\mathbb{C}[x,y,t]/(y^2-x^3-t)) \\not\\simeq Frac(\\mathbb{C}[t][x,y]/(y^2-x^3-1))? $$ So here $Frac$ denotes the fraction field of an integral domain.\n\nNote that this gives an example of (a non-trivial) isotrivial family over $\\mathbf{C}^{\\times}$.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nThere is a slightly different proof which works over any field $k$ (of characteristic different from 2 and 3). The first field is just $k(x,y)$. As Rita indicated, if it is isomorphic to the second field as $k$-extension, than there exists a birational map $f: \\mathbb P^2\\to \\mathbb P^1\\times E$. This birational map induces a birational map over the algebraic closure of $k$, so we can suppose $k$ is algebraically closed. Composing with the projection to $E$, we get a dominant rational map $g: \\mathbb P^2\\to E$. By two arbitrary points where $g$ is defined, it passes a line $L$. As $E$ is not rational, by L\u00fcroth $g|_L$ is constant. So $g$ is constant, contradiction. More quickly, one can say that the existence of $g$ implies that $E$ is unirational and this is impossible.\n\nEDIT: the rational map $\\mathbb P^2\\to E$ is not birational ! but dominant.\n\nshare|improve this answer\nThis is not so much different as it looks from the proof I gave. $h^1({\\mathcal O})$ is the dimension of the Albanese variety, that for the non rational surface is precisely $E$. Now your argument shows precisely that the Albanese variety of a unirational variety is $0$. \u2013\u00a0 rita Sep 2 '11 at 12:42\nThanks a lot Qing for the very slick argument! It is completely self contained and the key result that you use is that there is no non-constant rational map going form $\\mathbb{P}^1\\rightarrow E$ which as you pointed is a consequence of Luroth's theorem. Cool! \u2013\u00a0 Hugo Chapdelaine Sep 2 '11 at 14:12\nStill, you need to know that $E$ is not rational... The only way I know to show that is by computing the genus. \u2013\u00a0 rita Sep 4 '11 at 16:24\nTo show that $E$ is not rational, one can aslo compute directly $H^0(E, O_E(\\infty))$ which is equal to $k$, and would be of dimension $2$ over $k$ if $E$ was rational. \u2013\u00a0 Qing Liu Sep 5 '11 at 11:51\nTo prove that $\\mathbb P^1\\times E$ is not rational, one can also use the fact that its $\\pi_1$ is obviously non-trivial. \u2013\u00a0 Qing Liu Sep 5 '11 at 11:58\nshow 1 more comment\n\nThe second field is the function field of $X_2:=E\\times {\\mathbb P}^1$, where $E$ is a smooth elliptic curve; the first one is the function field of $X_1:=\\{zy^2-x^3-tz^2=0\\}\\subset {\\mathbb P}^3$. The surface $X_1$ is rational, as one can see by projecting onto ${\\mathbb P}^2$ from the point $P$ given by $x=y=z=0$, which is a double point of $X_1$. The surface $X_2$ is not rational, since it has $h^1({\\mathcal O}_{X_2})=1$. So $X_1$ and $X_2$ are not birational, and the two fields are not isomorphic (as extensions of $\\mathbb C$).\n\nshare|improve this answer\nSo I guess the first $X_2$ should read as $X_1$. Is it completely obvious that $h^1(\\mathcal{O}_X)$ is a birational invariant? After all $\\mathcal{O}_X$ is the sheaf of regular functions on $X$ which a priori could change under birational maps. \u2013\u00a0 Hugo Chapdelaine Sep 2 '11 at 1:18\n@Georges: I've edited and fixed the typos (I hope). Thanks! @Hugo: $h^1({\\mathcal O})$ is a birational invariant because by Hodge theory it is equal to $h^0(\\Omega^1) \u2013\u00a0 rita Sep 2 '11 at 6:27\n@Hugo (continued): there is also a famous rationality criterion by Castelnuovo, that says that a surface $S$ is rational iff $h^1({\\mathcal O})=h^0(2K_S)=0$. \u2013\u00a0 rita Sep 2 '11 at 8:36\nI'm quite happy with your proof but I think there should be a more elementary proof which is self contained. You see the whole point of this question is to come up with a birational invariant and if we assume from the outset that $h^1(\\mathcal{O})$ is a birational invariant then it (almost) kills the problem. \u2013\u00a0 Hugo Chapdelaine Sep 2 '11 at 12:10\nThe last statement is a well known fact, have a look at Beauville's book on surfaces, the chapter on birational maps of surfaces. \u2013\u00a0 rita Sep 2 '11 at 12:37\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18482/find-the-subset-of-a-line-on-a-sphere-far-from-a-set-of-points-on-the-sphere/18521\nText:\nTake the 2-minute tour \u00d7\n\nI have some code where the \"hot part\" relies on an inefficient solution to this problem.\n\nProblem: I have 3 inputs: a. A collection of N points on the surface of a sphere.\nb. A line segment on the sphere.\nc. A distance X (distance can be on the surface or in 3D as it's trivial to map between them)\n\nOutput: Find the subset of the line segment which is more than distance X from the collection of points.\n\n(My problem actually involves a curve on the sphere, but I can reduce it to a line segment by chopping it up into smaller pieces.)\n\nAt present, I parametrize the line and created a distance function, subtract X then slam it into a method that finds the times when a function is positive. VERY slow.\n\nAlso, precomputations count in this algorithm. That is, the set does change over time, but it changes less frequently than I need this result for different line segments. Maybe 5 queries to every set change? That's worst case.\n\nX is fixed over time.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nBy a line on the sphere, I assume you mean a part of a great circle spanning less than 180\u00b0.\n\nFor each of the N points, find what part of the line is closer than X to that point. This is at most a single segment. Find their union C as a disjoint union of segments. This is probably easier if you sort them by their starting point, and the obvious algorithm gives you the union as a sorted list as well \u2013 which makes the last part trivial: Find the complement of C.\n\nOh, and the first part can be done with some simple linear algebra.\n\nshare|improve this answer\nadd comment\n\nIf the querying aspect is important for you (i.e the lines keep appearing), then you should really build a data structure on the disks. Here's what you need to do. You need to build the arrangement on disks of radius X centered at each point (the arrangement being the way in which the sphere is decomposed into patches by the boundaries of the disks). Then, a point location query for each endpoint locates the start and end cells, and walking through the arrangement along the line gives you the subset of the line not covered by the disks.\n\nWhile this is overkill for a single line (and Harald's solution is fine), it'll be more efficient if the lines are short and there are many of them (since the point location queries will run in time logarithmic in the number of points, and you hopefully won't have to walk through too many cells). To implement this is a little tricky though: luckily, CGAL has packages that you can use for this purpose. A source paper on this topic is here.\n\nshare|improve this answer\nVery nice paper. That is kind of what I had in mind, but Harald's answer looks to be a lot easier to code, and probably is going to be good enough for me as long as X is large enough. (The exact final values of X are TBD.) THANKS! \u2013\u00a0 John Mar 17 '10 at 22:16\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/135478/using-linear-algebra-how-is-the-binet-formula-for-finding-the-nth-fibonacci-nu?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nIf possible, please refrain from any type of proof besides linear algebra. So, using the recursion formula $F_{n+1} = F_{n-1} + F_n$, for $n\\gt 1$, and where $F_0 = 0$ and $F_1 = 1$, and the Fibonacci matrix, derive the golden ratio and ultimately the Binet formula.\n\nshare|improve this question\nI haven't done eigenvectors yet (I do that in about a week in my L.A. course). Is there a way to derive all that without using those concepts? \u2013\u00a0 Nico Bellic Apr 22 '12 at 20:08\nYou could use the shift operator $S$ in the space of sequences. Then $F$ satisfies $S^2 F=SF+F$ and so $(S^2-S-I)F=0$. You now factor $S^2-S-I$ to find its kernel. @BillDubuque has proposed this approach several times here but I can't find a good link right now. \u2013\u00a0 lhf Apr 22 '12 at 20:10\nI'm truly, really sorry, but I'm not sure if I'm able to follow you. \u2013\u00a0 Nico Bellic Apr 22 '12 at 20:15\nSee for instance cs-netlab-01.lynchburg.edu/courses/algorithms/recurenc.htm (Example - solving the Fibonacci numbers) This is a random link found by Google. I could not find anything in Wikipedia. \u2013\u00a0 lhf Apr 22 '12 at 20:20\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI am not sure to which extent this will be helpful for OP, but I'll post this anyway. This is basically the same solution as the one posted by Zhen Lin, but without any explicit reference to eigenvalues or eigenvectors.\n\nSo the sequence given by $F_{n+2}=F_{n+1}+F_n$ seems to be complicated. But there is a wide class of sequences we understand very good - geometric progressions.\n\nLet us ask the question whether we can modify the sequence $F_n$ to get a geometric progression. E.g. we can ask whether there is an $x$ such that the sequcence $G_n=xF_n+F_{n-1}$ is a geometric progression.\n\nFrom $$\\begin{align} F_{n+1}&=F_n+F_{n-1}\\\\ F_{n}&=F_{n-1}+F_{n-2} \\end{align} $$ we get $$G_{n+1}=xF_{n+1}+F_n=xF_n+(x+1)F_{n-1}+F_{n-2}= xF_n+(x+1)F_{n-1}+F_n-F_{n-1}=(x+1)F_n+xF_{n-1}.$$ If we want the RHS to be a multiple of $G_n$, then we must have $$\\frac{x+1}x=x,$$ i.e. $x+1=x^2$ or $x^2-x-1=0$, which has the two solutions $\\lambda_{1,2}=\\frac{1\\pm\\sqrt5}2$.\n\nNotice that $\\lambda_1+\\lambda_2=1$, $\\lambda_1\\lambda_2=-1$.\n\nFor any of the above values we have $$G_{n+1}=(\\lambda+1)F_n+\\lambda F_{n-1}=\\lambda\\left(\\frac{\\lambda+1}\\lambda F_n+F_{n-1}\\right)=\\lambda G_n.$$ We also have $G_1=\\lambda$, $G_0=1$.\n\nSo we get $$ \\begin{align} \\lambda_1F_{n}+F_{n-1}&=\\lambda_1^n\\\\ \\lambda_2F_{n}+F_{n-1}&=\\lambda_2^n \\end{align} $$ If we subtract the above two equations, we get $$(\\lambda_1-\\lambda_2)F_{n}=\\lambda_1^n-\\lambda_2^n$$ which gives $$F_n=\\frac{\\lambda_1^n-\\lambda_2^n}{\\lambda_1-\\lambda_2}.$$\n\nIn the solution, which used the diagonal form and eigenvalues, we did not have to guess, that it is possible to obtain geometric progressions combining Fibonacci sequence and shifted Fibonacci sequence - we get this fact from that diagonal matrix.\n\nOr we can look at this the other way round - many applications of diagonal matrices similar to given matrix (e.g. in linear recurrences, ordinary differential equations) can be viewed as an effort to transform the original problem to a simpler form; in this case the simpler form was a geometric progression.\n\nshare|improve this answer\nadd comment\n\nThe Fibonacci numbers are defined by a second-order linear recurrence equation: $$F_{n+2} = F_{n+1} + F_n$$ This means we can treat the solution of $F_n$ in terms of $n$ as a problem in linear algebra involving only $2$-dimensional vectors. In some sense, what we are doing is modelling this as a dynamical process on a $2$-dimensional state space.\n\nLet $V = \\mathbb{R}^2$. We define a linear operator $T : V \\to V$ by $$T(x, y) = (y, x + y)$$ Notice that $T(F_{n}, F_{n+1}) = (F_{n+1}, F_{n+2})$, so you can think of $V$ as being a sliding $2$-entry window on the Fibonacci sequence and $T$ as the operator which advances the window along the Fibonacci sequence. The initial conditions $F_0 = 0, F_1 = 1$ then imply that $$T^n(0, 1) = (F_n, F_{n+1})$$ so all we need to do to find $F_n$ in terms of $n$ is to find an effective way to compute iterates of the operator $T$!\n\nNow, we get our hands dirty and represent $T$ as a matrix: $$T = \\begin{pmatrix} 0 & 1 \\\\ 1 & 1 \\end{pmatrix}$$ Imagine if we could somehow find an invertible matrix $P$ and a diagonal matrix $D$ such that $T = P D P^{-1}$; then, by matrix algebra, we would have $T^n = P D^n P^{-1}$, and it is easy to compute powers of diagonal matrices. The theory of eigenvectors and eigenvalues gives us one way to find such a factorisation of $T$. Notice that $$\\det (T - x I) = \\det (P(D - x I)P^{-1}) = (\\det P)(\\det (D - x I))(\\det P^{-1}) = \\det (D - x I)$$ but a simple calculation shows $$\\det (D - x I) = \\det \\begin{pmatrix} \\lambda_1 - x & 0 \\\\ 0 & \\lambda_2 - x \\end{pmatrix} = (\\lambda_1 - x)(\\lambda_2 - x)$$ so whatever $\\lambda_1$ and $\\lambda_2$ are, they must be the zeros of the polynomial $$\\det (T - x I) = \\det \\begin{pmatrix} -x & 1 \\\\ 1 & 1 - x \\end{pmatrix} = x^2 - x - 1$$ which, surprise surprise, is the minimal polynomial of the golden ratio. So let $\\lambda_1 = \\frac{1}{2} (1 + \\sqrt{5})$ and $\\lambda_2 = \\frac{1}{2} (1 - \\sqrt{5})$. These are the eigenvalues of $T$. By construction, $\\det (T - \\lambda_1 I) = \\det (T - \\lambda_2 I) = 0$, so there must be non-zero vectors $\\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix}$ and $\\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix}$ such that $$ T \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} = \\lambda_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} $$ $$ T \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = \\lambda_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} $$ These vectors are called the eigenvectors of $T$. I leave you to verify that $x_1 = \\lambda_1 - 1$, $y_1 = 1$, $x_2 = \\lambda_2 - 1$, $y_2 = 1$ works, but there are other solutions.\n\nDefine the matrix $P$ by $$P = \\begin{pmatrix} x_1 & x_2 \\\\ y_1 & y_2 \\end{pmatrix}$$ Notice that $$\\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\alpha_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} + \\alpha_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = P \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$$ so by linearity we have $$T \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\lambda_1 \\alpha_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} + \\lambda_2 \\alpha_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = P \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix} \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$$ but we can invert $P$ to find $\\alpha_1$ and $\\alpha_2$ in terms of $x$ and $y$, so we have obtained the desired factorisation of $T$ as $P D P^{-1}$ with $D$ diagonal. Putting everything together, we get the formula $$T^n = P \\begin{pmatrix} {\\lambda_1}^n & 0 \\\\ 0 & {\\lambda_2}^n \\end{pmatrix} P^{-1}$$ and applying this to the vector $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ gives Binet's formula.\n\nshare|improve this answer\nThe OP seems to want to avoid eigenvalue decompositions. \u2013\u00a0 lhf Apr 23 '12 at 1:09\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/205260/solutions-of-diophantine-equations-xy-yx/205264\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\n$x^y = y^x$ for integers $x$ and $y$\n\nHow to prove that $(2,4)$ and $(4,2)$ are the only solutions of Diophantine equations ${x^y} = {y^x}$ for $x \\ne y$?\n\nshare|improve this question\n@DavidWallace For $x \\ne y$. \u2013\u00a0 glebovg Oct 1 '12 at 5:02\nHah! Sorry, I can't read. \u2013\u00a0 user22805 Oct 1 '12 at 5:04\nadd comment\n\nmarked as duplicate by Cameron Buie, Thomas, Noah Snyder, Chris Eagle, \uff2a. \uff2d. Oct 5 '12 at 13:00\n\n\n1 Answer\n\nup vote 3 down vote accepted\n\nTaking logarithms:\n\n$$x\\ln y=y\\ln x$$ $$\\frac{\\ln y}y=\\frac{\\ln x}x$$\n\nFor this to be true, the function has to take the same value at two different locations. Take the function\n\n$$f(x)=\\frac{\\ln x}x$$ $$f'(x)=\\frac{1-\\ln x}{x^2}$$\n\nIt has a maximum at $x=e$, is decreasing for $x>e$ and increasing for $x<e$. So if two values are equal, one has to be greater than $e$ and the other must be less. So for the lower value we only have $x=1,2$ as options. Our problem amounts to proving that there is no other number that gives the same value as $x=1$. Since $f(1)=0$, and $\\ln(x)$ only has a single root at $1$, we know this can't happen, so we're done.\n\nshare|improve this answer\nKeep in mind that logarithms assume the numbers are positive. $x=-4, y=-2$ works as well. Cases of negative integers either reduce to the positive case in disguise (when both are negative) or are trivial (when only one is). \u2013\u00a0 Robert Mastragostino Oct 1 '12 at 5:29\nI used a very similar argument, but I was not convinced. Thanks. \u2013\u00a0 glebovg Oct 1 '12 at 5:30\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/103588/expression-that-hits-integer-multiples-of-two-variables/103777\nText:\nTake the 2-minute tour \u00d7\n\nIs there a way to generate am expression that will get all integer multiples of an arbitrary pair of integers?\n\nI.e. Some function that will spit out ${0,2,3,4,6,8,9,10, ... }$ and all of the other multiples of 2 and 3 given integer arguments. It should not generate results for integer arguments that are not multiples of 2 and 3.\n\nBy function I mean using elementary mathematical operations.\n\nI would prefer a single variable expression.\n\nshare|improve this question\nI'm confused. Your $f(x,y)$ outputs many more integers than the multiples of a and b. But if that's allowed, then just take your single-variable function to be $f(x)=x$, and then you get all your multiples out. \u2013\u00a0 Cam McLeman Jan 29 '12 at 15:25\nDoes $$f(n)=\\text{the }n\\text{th natural number that is a multiple of either }a\\text{ or }b\\text{ (or both)}$$ count for you? If not, then you'll have to specify more precisely what you mean by \"function\". \u2013\u00a0 Henning Makholm Jan 29 '12 at 15:25\n@CamMcLeman, Henning, edited, you are correct. \u2013\u00a0 soandos Jan 29 '12 at 15:30\nSo what you want is not just a function (which in mathematics can be just about anything you are able to define unambiguously), but an expression with one or more free variables. But then you need to specify what is an \"elementary mathematical operation\" to you. \u2013\u00a0 Henning Makholm Jan 29 '12 at 15:32\nStandard definition, composition of constants, logarithms, exponentiation, extractions of nth roots by using $(+,-,*,/)$. \u2013\u00a0 soandos Jan 29 '12 at 15:34\nshow 6 more comments\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThe function $$f(n)={3\\over2}n+{i^n-i^{-n}\\over4i}$$ (where $i$ is a square root of minus one) gives the outputs $0,2,3,4,6,8,9,10,\\dots$ on being given the inputs $0,1,2,3,4,5,6,7,\\dots$.\n\nEDIT: In general, suppose you're given positive intgers $a,b$, and want the output to be all $n$ divisible by one or the other. First find the least common multiple $L$ of $a$ and $b$ (in the example, $L=6$). Then find the number $N$ of multiples of $a$ and/or $b$ in $0,1,2,\\dots,L-1$ (in our example, $N=4$; in general, this is a simple exercise). The main term of $f(n)$ will be $(L/N)n$. The difference, $f(n)-(L/N)n$, will be periodic with period $N$, so it will be a linear combination of the functions $g_j(n)=e^{2\\pi ijn/N}$, $j=0,1,\\dots,N-1$. You find the coefficients in this linear combination by the standard techniques of intro linear algebra - it's just solving $N$ linear equations in $N$ unknowns.\n\nshare|improve this answer\nHow could I generalize this for arbitrary multiples? \u2013\u00a0 soandos Jan 29 '12 at 23:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/9075/nl-definition-and-a-problem\nText:\nTake the 2-minute tour \u00d7\n\nThe question is: What is the smallest complexity class in which the following problem is contained: Given a graph with $n$ nodes, Is there independent set of size of at least $n-10$?\n\nI have a little difficulty to understand the meaning of being in ${\\sf L}$ and examine problems in a correct way for deciding if they are in ${\\sf NL}$ or ${\\sf L}$\n\nFirst I know that for being in ${\\sf NL}$ I need to provide a verifier for a Turing machine which uses only $O(\\log n)$ space on its working tape- So I wonder- I can give as a verifier this set of nodes to be independent set as requested, but how does the checking work? Can it go to all the lists of the pointers to the neighbors of each node , and for every node to check whether all the other nodes in the set given as independent set is not on that list- Is this considered of not using any space and I only need to count the nodes in the list that fulfill the requirement and therefore use only $O(\\log n)$ space? Is this correct? Is there a way to prove that the problem is in ${\\sf L}$?\n\nshare|improve this question\nHaving an independent set of size $n-10$ means that the graph has a vertex cover of size $10$, no? There is an exact algorithm solving this problem in $O(1.3^{10} \\cdot n^2)$ time, hence in $O(n^2)$ time. I don't know any lower complexity class than $\\mbox{P}$ for which constant-sized vertex cover is a member. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 20:26\n@P\u00e5lGD, I think you're wrong. Consider a graph of $n$ vertices and no edges. Any subset of it's vertices is independent, but only all $n$ form a cover. \u2013\u00a0 Karolis Juodel\u0117 Jan 21 '13 at 20:35\n@KarolisJuodel\u0117 A vertex cover is a set of vertices \"covering\" all the edges. In an edgeless graph the empty set is a vertex cover. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 20:59\n@P\u00e5l The idea is to go over all sets of $10$ vertices. That requires only logarithmic space. \u2013\u00a0 Yuval Filmus Jan 21 '13 at 21:35\n@YuvalFilmus Yes, I see now. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 21:45\nadd comment\n\n1 Answer\n\nHint: How much space do you need to store a set of $10$ vertices? How much space does it take to go over all pairs of nodes in a graph?\n\nAnother hint: How much space does it take to implement the following algorithm? (I replaced 10 with 3 to make it easier to follow)\n\n int algorithm(int n, int G[n][n]) {\n   int x, y, flag;\n   int v1, v2, v3;\n\n   for (v1 = 0; v1 < n; v1++)\n     for (v2 = 0; v2 < n; v2++)\n       for (v3 = 0; v3 < n; v3++) {\n         flag = 0;\n         for (x = 0; x < n; x++)\n           for (y = 0; y < n; y++)\n             if ((x != v1) && (x != v2) && (x != v3) &&\n                 (y != v1) && (y != v2) && (y != v3))\n               flag |= G[x][y];\n         if (flag == 0)\n           return 1;\n   return 0;\nshare|improve this answer\nI'm not really sure, as you can read I don't understand the meaning of storing vertices, in which representation I keep them? Your questions is exactly what I dont know and I wondered in my question. \u2013\u00a0 Ben Benli Jan 21 '13 at 21:20\nThis is not homework if you are concerned. \u2013\u00a0 Ben Benli Jan 21 '13 at 22:14\nLet's say your Turing machine gets as input $n$ (assuming the vertices are labeled from 1 to $n$) and then a list of which vertices are connected. You are looking for a vertex cover of, in Yuval's example, size 3. First you need to iterate through all combinations $(v_1,v_2,v_3)$ for $v_i \\leq n$. Then you go through the edges an confirm that all of them has at least one endpoint in $(v_1,v_2,v_3)$. You store $3 \\log n$ bits plus some constant for spacings. \u2013\u00a0 P\u00e5l GD Jan 21 '13 at 22:47\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/291956/if-p-is-prime-and-p-5-show-that-when-p-is-divided-by-10-the-remainder\nText:\nTake the 2-minute tour \u00d7\n\nIf $p$ is prime and $p > 5$, show that when $p$ is divided by 10, the remainder is 1, 3, 7, or 9.\n\nThis is a problem from Hungerford's Abstract Algebra: An Introduction. I would like some help on it, it was an example in class. Thanks.\n\nshare|improve this question\nConsider the case when the remainder is 2. Then $p = 10 q + 2$ for some integer $q$, so that $p = 2 (5 q + 1)$ is even, but cannot be 2 by the assumption $p > 5$. The other cases are entirely similar, it is useful for you to work them out yourself. \u2013\u00a0 Andreas Caranti Feb 1 '13 at 7:27\nSince you are new, I want to give some advice about the site: To get the best possible answers, you should explain what your thoughts on the problem are so far. That way, people won't tell you things you already know, and they can write answers at an appropriate level; also, people are much more willing to help you if you show that you've tried the problem yourself. If this is homework, please add the [homework] tag; people will still help, so don't worry. Also, many would consider your post rude because it simply states the problem, and is not a request for help, so consider rewriting it. \u2013\u00a0 Zev Chonoles Feb 1 '13 at 7:34\n$p > 5$ prime means $p$ not divisible by $2$ or $5$. \u2013\u00a0 Benjamin Dickman Feb 1 '13 at 8:26\nadd comment\n\n6 Answers\n\nup vote 5 down vote accepted\n\nBy the division algorithm, we can write each $p$ as $$p = 10q + r$$ for some quotient $q$ and remainder $0\\le r < 10$. As $p$ is prime, clearly $r\\neq 0$. $r$ also cannot be even, otherwise $p$ is even. Finally, note that $r \\neq 5$ or $5 \\mid p$.\n\nFor a more brief and algebraic solution, note that $(p,\\ 10) = 1$ implies that $p$ is a unit in $\\mathbb{Z}/10\\mathbb{Z}$. The units of the ring are precisely $1,\\ 3,\\ 7$ and $9$.\n\nFor completeness, you should probably show that there exists primes for each of the remaining congruence classes.\n\nshare|improve this answer\nadd comment\n\nYou already have a couple of nice \u2018mathematical-looking\u2019 answers. In attacking a question like this, though, you might want to start with simple, familiar facts.\n\nThe remainder when $p$ is divided by $10$ is simply the last digit of $p$. If the last digit of a number $n$ is $0,2,4,6$, or $8$, what kind of number is $n$? Can it be prime if it\u2019s greater than $2$? If the last digit is $0$ or $5$, what can you say about $n$? Can it be prime and greater than $5$?\n\nThese are enough to tell you, at least informally, why the prime $p>5$ must end in $1,3,7$, or $9$, and now you can worry about explaining the reasoning in the previous paragraph a bit more formally.\n\nshare|improve this answer\nThank you for the tip, I was not sure how to best ask questions here but I'm learning and will remember that. \u2013\u00a0 grayQuant Feb 1 '13 at 14:36\nadd comment\n\nTo say that a prime $p > 5$ gives a remainder of $1, 3, 7$ or $9$ when divided by $10$ is merely remarking that the prime is odd (and not $5$, since all integers ending in five are multiples thereof).\n\nAfter all, the remainder when divided by $10$ is simply the unit of the number itself, and if that unit was any of $0, 2, 4, 6, 8$ we'd plainly see that it was an even number, and therefore not prime. Likewise with the five.\n\nThat said, we could come to the conclusion of your statement by, say, basing an argument on how all primes above $3$ are of the form $6n \\pm 1$ (mind you, this follows from an argument akin to the above): the multiples of $6$ begin as follows: $$6, 12, 18, 24, 30\\ldots$$ From which we father that the units of such multiples are either $0, 2, 4, 6$ or $8$. Now take the '$\\pm 1$' bit into consideration and we find that we have the following units possible: $$1, 3, 5, 7, 9$$ (Remember, a remainder of $-1$ when divided by $10$ is equivalent to a remainder of $9$.)\n\nSo, much like the above, we disregard the $5$ since that certainly isn't prime, and we have $1, 3, 7, 9$ leftover, as desired.\n\nshare|improve this answer\nadd comment\n\nAny natural number $n$ can be expressed as $$n=a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$$\n\nfor some natural numbers (including $0$) $k,a_k,\\dots , a_1, a_0$. This representation is unique (up to commutation of the products and sums).\n\nSuppose $p\\in \\mathbb{P}$. Then $p=a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$.\n\nClearly the remainder of $a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$ when divided by $10$ is $a_0$.\n\nCan you conclude?\n\nshare|improve this answer\nThis helped me think about the problem. I think using the division algorithm is what the author of the book had in mind, just because it was in the previous section. \u2013\u00a0 grayQuant Feb 1 '13 at 22:03\nadd comment\n\nyou are looking for the unit digit of the prime.For prime $p\\neq 2$, unit digit is odd which means $p\\pmod {10}\\in\\{1,3,5,7,9\\}$\n\nNow, for any prime $p\\gt 5$, unit git can't be $5$ otherwise it would be divisible by $5$ and hence won't be a prime.\n\nThus only possible candidates for unit digit of a prime $p\\gt 5$ are $\\{1,3,7,9\\}$\n\nshare|improve this answer\nadd comment\n\nThis is clear from the Euclidean algorithm. Write the remainder $\\rm\\: r = (p\\ mod\\ 10).\\:$ By Euclid\n\n$$\\rm p\\equiv r\\,\\ (mod\\ 10)\\ \\Rightarrow\\ gcd(p,10) = gcd(r,10)$$\n\nIn particular, $ $ when the $ $ gcd $= 1,\\, $ then: $\\rm\\,\\ p\\,$ is coprime to $10$ $\\iff$ $\\rm\\,r\\,$ is coprime to $10$\n\nNow, by hypothesis, $\\rm\\, p\\,$ is prime $ > 5,\\,$ so $\\rm\\, p\\,$ is coprime to $10,\\ $ thus $\\rm\\ r\\,$ is coprime to $10,\\:$ so we infer that $\\rm\\,r\\,$ is odd and coprime to $\\,5,\\:$ hence $\\rm\\:r\\in \\{1,3,7,9\\},\\,$ since the remainder $\\rm\\,r\\in [0,9].$\n\nRemark $\\ $ Ditto if we generalize $\\rm\\,10\\,$ to any modulus $\\rm\\,m\\!:\\ $ if prime $\\rm\\,p\\nmid m\\:$ then its remainder $\\rm\\, p\\ mod\\ m\\,$ is one of the $\\,\\varphi(m)\\,$ remainders coprime to $\\rm\\,m.\\:$ Or, expressed in radix language:\n\n$\\quad$ in radix $\\rm\\,m\\!:\\ $ if $\\rm\\,n\\,$ has units digits $\\rm\\,r,\\ $ then $\\rm\\ n\\,$ is coprime to $\\rm\\, m\\iff r\\,$ is coprime to $\\rm\\,m$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/31554/is-the-feedback-vertex-number-bounded-by-the-maximum-number-of-leaves-in-a-spann\nText:\nTake the 2-minute tour \u00d7\n\nI have a graph-theoretical conjecture which I think would have been studied before, but for which I cannot find anything in the literature.\n\nLet G be a finite, simple, connected graph. Let the feedback vertex number $FVS(G)$ be the minimum number of vertices that have to be deleted from $G$ to break all cycles, so the minimum number of deletions needed to turn $G$ into a forest. Let the max leaf number $MaxLeaf(G)$ be the maximum number of leaves in any spanning tree for $G$.\n\nMy conjecture is that $FVS(G) \\leq MaxLeaf(G)$.\n\nThe two numbers come close for complete graphs: a $K_t$ has a spanning tree with $(t-1)$ leaves, and $(t-2)$ deletions are needed to turn $K_t$ into a forest. Since a forest can have an arbitrary number of leaves and has FVS number 0, the MaxLeaf number cannot be bounded by a function of the FVS number.\n\nI can prove that $FVS(G) \\leq 6 \\cdot MaxLeaf(G)$ through a lemma on spanning trees which says that for every connected graph G containing m vertices of degree $\\neq 2$, there is a spanning tree for G with at least $m/6$ leaves. Since the deletion of the set of vertices of degree $\\neq 2$ turns a graph into a forest if the graph is not a simple cycle, this shows that $FVS(G) \\leq 6 \\cdot MaxLeaf(G)$ when $G$ is not a simple cycle; and it is easy to see that the claim also holds when $G$ is a simple cycle since $MaxLeaf(C_n) = 2$ and $FVS(C_n) = 1$ for $n \\geq 3$.\n\nSince the complement of the leaves in a spanning tree form a connected dominating set, and since the complement of a feedback vertex set is a maximum induced forest, an alternative way to state the conjecture is: For any connected graph $G$ the number of vertices in the largest induced subforest of $G$ is at least as large as the minimum size of a connected dominating set in $G$.\n\nSo my question is: is this conjecture true, and does anyone know of any research related to it?\n\nshare|improve this question\nYou might consider looking at this circle of ideas for planar graphs. David Barnette showed that for a planar 3-connected graph there is always a spanning tree of maximum valence 3. However, if I remember properly, he also showed that for d-polytopal graphs (d more than 3) that there is no uniform upper bound for the valence of a spanning tree. d-polytopal graphs are known to be d-connected. This paper might also be of interest: citeseerx.ist.psu.edu/viewdoc/\u2026 \u2013\u00a0 Joseph Malkevitch Jul 13 '10 at 12:39\nadd comment\n\n2 Answers\n\nup vote 6 down vote accepted\n\nBill Waller and I proved the stronger statement that for G a graph on n(G) > 1 vertices, the order of a largest induced linear forest is at least one plus the connected domination number. See our preprint. A linear forest is a forest in which each connected component is a path, and clearly a lower bound for the order of a largest forest.\n\nshare|improve this answer\nExcellente, thanks a lot! I actually looked at the preprint briefly during my web search, but missed the theorem. Nice work. \u2013\u00a0 Bart Jansen Jul 13 '10 at 21:43\nadd comment\n\nThis isn't a complete answer, but at least it's a step. I think it should be possible to prove that FVS(G) < 2 MaxLeaf(G).\n\nMore specifically, if NonTwo(T) is the number of nodes in spanning tree T that do not have degree two, and MaxNonTwo(G) is the maximum value of NonTwo(T) over all spanning trees of G, then I think that\n\n  \u2022 MaxNonTwo(G) < 2 MaxLeaf(G). This is obvious: in any tree, the number of leaves in T is greater than half of NonTwo(T), so the tree T that maximizes NonTwo(T) has greater than NonTwo(T)/2 leaves, and the max leaf spanning tree can only have even more leaves.\n\n  \u2022 FVS(G) \u2264 MaxNonTwo(G). More specifically, in every tree T maximizing NonTwo(T), the set of vertices of degree \u2260 2 form a feedback vertex set. For, if there's a cycle induced by the degree-2 vertices of T, then some edge e of the cycle does not belong to T. If the path in T connecting the endpoints of e passes through a vertex v that does not have degree three, then adding e and removing an edge incident to v produces a tree with a larger value of NonTwo(T). If this situation does not occur, then all edges in the induced cycle are non-tree edges; adding two consecutive edges from the cycle to T and removing two of the edges from T (two of the three edges at the median in T of the endpoints of the added cycle edges) produces a new tree with greater NonTwo again (the three endpoints of the added edges get their degree increased above two, the median goes from degree three to degree one, and two other vertices get their degrees decreased from three to two).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64940/zeros-of-a-sequence-related-to-roots-of-unity\nText:\nTake the 2-minute tour \u00d7\n\nConsider the sequence\n\n$$ a(n) = \\prod_{u^n=1,u \\neq 1}( (1+u)^n+1) $$\n\nSome terms are: $$ 1,1,0,9,121,2704,118336, 4092529,0,97734390625, \\ldots $$\n\nAlonso del Arte asks:\n\nQuestion: What are the multiples of $3$ such that\n\n$$ a(3k) =0 $$\n\nI tried some factorization of cyclotomic polynomials without success. May be true for all odd $k$ ???\n\nEDIT: Another simple property of the sequence is\n\n(hope this may please the negative voter (???))\n\n$$ a(p) \\equiv 1 \\pmod{p} $$\n\nfor any prime $p>3$\n\n\n$$ a(n) (2^n+1) $$ is the determinant of a circulant matrix with first line $$ 3,\\binom{n}{1}, \\ldots,\\binom{n-1}{n} $$\n\nshare|improve this question\nWhy does this question deserve negative feedback? \u2013\u00a0 Daniel Parry May 14 '11 at 22:38\n@Daniel: faq, first line, first paragraph \u2013\u00a0 Franz Lemmermeyer May 15 '11 at 18:37\n\n2 Answers 2\n\nup vote 9 down vote accepted\n\nSuppose that $n=3m$, where $m$ is odd, and $u=e^{2\\pi i/3}$. Then $$ (1+u)^n+1 = ((1+u)^3)^m+1 = (-1)^m+1=0, $$ so $a(n)=0$.\n\nshare|improve this answer\nnice ! I do not see that... \u2013\u00a0 Luis H Gallardo May 13 '11 at 23:03\nReminds me of the old joke about how to simplify the expression $(x-a) (x-b) \\ldots (x-z)$. \u2013\u00a0 Terry Tao May 15 '11 at 18:37\n\nThe complex number $a(n)$ is the resultant of the polynomials $P=(X^n-1)/(X-1)$ and $Q=(X+1)^n+1$; similarly, $(2^n+1)a(n)$ is the resultant of $X^n-1$ and $(X+1)^n+1$. Since these polynomials have integer coefficients, their resultant is a rational integer.\n\nThe resultant of two polynomials vanishes whenever they have a common root. So $a(n)=0$ if and only if there exists a $n$th root of unity $u$ such that $(u+1)^n+1=0$. This implies that $u$ and $u+1$ are both roots of unity, in particular they belong to the unit circle, so that necessarily $u=e^{2\\pi i/3}$ or $u=e^{-2\\pi i/3}$, and $u+1=e^{\\pm i\\pi/3}$. If $u$ is a $n$th root of unity, one gets $3|n$; if $(u+1)^n=-1$, one obtains that $n/3$ is odd. Conversely, if $n=3m$ with $m$ odd, $u=e^{2\\pi i/3}$ satisfies $u^n=1$, $u\\neq 1$, and $(u+1)^n=-1$, hence $a(n)=0$.\n\nSince the two polynomials $P$ and $Q$ above are monic, their resultant vanishes mod $p$ if and only if they have a common root when considered as polynomials modulo $p$. If $n=p$ is prime, then $X^n-1=(X-1)^p$, so $1$ is the only root of $P$, with multiplicity $p-1$; it follows that $$\u00a0a(n)\\equiv ((1+1)^p+1)^{p-1}\\equiv (2^p+1)^{p-1}\\equiv 3^{p-1} \\pmod p.$$ If, moreover, $p\\neq 3$, then $a(n)\\equiv 1\\pmod p$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/68604/can-we-write-the-electromagnetic-potential-covariantly-in-terms-of-the-four-curr\nText:\nTake the 2-minute tour \u00d7\n\nIn the Lorenz gauge, we have a beautiful relation between the four-current and the four-potential:\n\n$$\\Box A^{\\alpha} = \\mu_0 J^{\\alpha}$$\n\nTo get $A$ in terms of $J$, however, we have to use a considerably uglier formula; or, at least, this is the formula presented in textbooks:\n\n$$A^{\\alpha}(t, \\mathbf{r}) = \\frac{\\mu_0}{4\\pi} \\int \\frac{J^{\\alpha}\\left(t - \\frac{1}{c}\\|\\mathbf{r} - \\mathbf{r}'\\|, \\mathbf{r}' \\right)}{\\|\\mathbf{r} - \\mathbf{r}'\\|} d^3\\mathbf{r}'$$\n\nThe first equation is evidently Lorentz covariant. The second one, on the other hand, doesn't look covariant at all. The integrand has some messy dependence on $(t, \\mathbf{r})$ and the integration goes over only the spatial dimensions.\n\nCan we rewrite the second equation in a covariant form? If not, then why not?\n\nshare|improve this question\nMore on retarded $4$-potential: physics.stackexchange.com/q/67533/2451 \u2013\u00a0 Qmechanic Jun 20 '13 at 6:47\nLorentz covariance of the solution is provided with the Lorentz covariance of the four-current and the Lorentz invariance of the retarded Green's function given in Lubosh's answer. \u2013\u00a0 Vladimir Kalitvianski Jun 20 '13 at 11:19\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nThe integral expression is Lorentz-covariant, too, and it may be made manifestly Lorentz-covariant, too.\n\nThe integral measure $\\int d^3 r' / ||\\vec r - \\vec r'||$ is equal to and may be rewritten as the four-dimensional integral with a delta-function (and step function) added: $$2\\int {d^4 x'} \\cdot \\delta[(x-x')^2]\\cdot \\theta(t-t') $$ It's understood that $J$ is substituted at the point $J(x')$.\n\nNote that the step function $\\theta$ (equal to one for positive arguments and zero otherwise) is Lorentz-covariant assuming that the points $x,x'$ aren't spacelike-separated (because the ordering of a cause and its effect is frame-independent), and they're not spacelike-separated as guaranteed by the delta-function that is only non-vanishing near/at the null separation of $x,x'$\n\nThe step function guarantees that the cause precedes its effect.\n\nThe argument of the delta-function is a Lorentz invariant, $(x-x')^2$ which means $(x-x')^\\mu(x-x')_\\mu$. The sign convention for the metric doesn't matter becase this invariant is the argument of an even function (delta-function).\n\nFinally, the equivalence of the two integrals may be shown by performing the integral over $t'$. The theta-function implies that we only integrate over the semi-infinite line $t'\\lt t$. The delta-function implies that the integral is only sensitive on the value of $J(t')$ where $c|t-t'| = |r-r'|$ where the delta-function vanishes.\n\nFinally, the delta-function also automatically generates the $1/|\\vec r - \\vec r'|$ factor because $$\\delta(y^2) = \\delta (y_0^2-|\\vec y|^2) = \\delta[(y_0+|\\vec y|)(y_0-|\\vec y|)]=\\dots $$ which is equal, because $\\delta(kX) = \\delta (X)/ |k|$, to $$\\dots = \\frac{\\delta(y_0-|\\vec y|)}{y_0+|\\vec y|}=\\frac{\\delta(y_0-|\\vec y|)}{2|\\vec y'|}$$ You see that the factor of two was needed, too.\n\nshare|improve this answer\nI think we also need an extra factor of $c$ in order to make the units work out. \u2013\u00a0 Brian Bi Jun 20 '13 at 7:20\nRight. I just wasn't sure which powers of $c$ I wanted to add to the definition of the 4-vector because this depends on some conventions, too. Adult physicists work in the $c=1$ units, anyway. \u2013\u00a0 Lubo\u0161 Motl Jun 20 '13 at 8:33\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/111066/is-there-any-techniques-for-solving-a-differential-equation-including-iterated-f/111073\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to solve this differential equation but I have no idea how.\n\n$f ' (x) = f( f( x ) ) $\n\nAlthough I don't think this differential equation is solvable, I'd like to know if there is any interesting approach on solving a differential equation of this kind, or at least a non-trivial solution of the equation.\n\nP.S. I don't think chain rule is useful for this\n\nshare|improve this question\nI think this is more suitable for math.stackexchange.com \u2013\u00a0 Beni Bogosel Oct 30 '12 at 10:49\nBeni, why do you say that? \u2013\u00a0 Vidit Nanda Oct 30 '12 at 11:57\n@Vel Nias I think math analysis questions are not welcome here. \u2013\u00a0 Anixx Nov 1 '12 at 11:03\n@Anixx. For the best of my knowledge, this claim is plain wrong. However, I agree that the remarks like \"this is homework\" or \"ask that on MSE\" that are not supported by any evidence that the person making them can solve the problem himself can be somewhat irritating... As to Beni's recommendation itself, MSE is not a bad site per se but it is just DROWNED in \"homeworks\" nowadays. MO and AoPS are much better choices for something nontrivial IMHO. \u2013\u00a0 fedja Nov 1 '12 at 12:33\nIs that a delay differential equation? \u2013\u00a0 Zsb\u00e1n Ambrus Nov 1 '12 at 14:03\nshow 2 more comments\n\n5 Answers\n\nup vote 14 down vote accepted\n\nNothing is new under the Moon...\n\n\nshare|improve this answer\nwow! Thank you very much! Did you solve it by yourself? You're amazing! \u2013\u00a0 frigen Nov 1 '12 at 3:17\nI see no solution following the link. \u2013\u00a0 Anixx Nov 1 '12 at 3:27\nMeaning you haven't scrolled down or you failed to understand what is written there? In the latter case you are welcome to ask questions. \u2013\u00a0 fedja Nov 1 '12 at 3:32\n@fedja I only see the supposed proofs of existence. Regarding the solution, you yourself wrote \"I have no hope for an explicit elementary formula for it.\" \u2013\u00a0 Anixx Nov 1 '12 at 3:34\nExistence and uniqueness of a one-parameter family of solutions, to be exact ;). Do you believe one can come with a formula? We can, probably, give it a shot and try to prove that the functions in question are not elementary but that is quite another story (and, most likely, quite a non-trivial one given that there exist formal elementary pseudo-solutions like the ones you mentioned). If you are interested in such a project, I can think of what might be the right approach here (but a bit later :)). \u2013\u00a0 fedja Nov 1 '12 at 3:46\nshow 3 more comments\n\nThere are two closed form solutions:\n\n$$\\displaystyle f_1(x) = e^{\\frac{\\pi}{3} (-1)^{1/6}} x^{\\frac{1}{2}+\\frac{i \\sqrt{3}}{2}}$$ $$\\displaystyle f_2(x) = e^{\\frac{\\pi}{3} (-1)^{11/6}} x^{\\frac{1}{2}+\\frac{i \\sqrt{3}}{2}}$$\n\nThe solution technique can be found in this paper.\n\nFor a general case, solution of the equation\n\n\nhas the form\n\n$$f(z)=\\beta z^\\gamma$$\n\nwhere $\\beta$ and $\\gamma$ should be obtained from the system\n\n$$\\gamma^m=\\gamma-1$$ $$\\beta^{\\gamma^{m-1}+...+\\gamma}=\\gamma$$\n\nIn your case $m=2$.\n\nshare|improve this answer\nSee also my answer regarding real solutions below. \u2013\u00a0 Anixx Nov 2 '12 at 10:36\nadd comment\n\nI don't know, but one answer is $f(x)=ax^c$ where $a=\\frac12(\\sqrt {3}+i){ e^{\\frac16\\pi\\sqrt {3}}}$ and $c=\\frac12+\\frac12i\\sqrt{3}$. Another is obtained by taking the complex conjugate of both $a$ and $b$.\n\nshare|improve this answer\nThe only unclear thing is where this function is defined. Note that complex powers of real numbers are complex and complex powers of complex numbers are branching like crazy... \u2013\u00a0 fedja Nov 1 '12 at 2:41\nadd comment\n\nFor what I know, the standard method is the Taylor series expansion at a fixed point, i.e. at a point $x=a$ such that $f(a)=a$.\n\nshare|improve this answer\nYes. +1 And I will give the expansion in another answer. \u2013\u00a0 Anixx Nov 1 '12 at 11:04\nadd comment\n\nAnd regarding real solutions to the question, Alex Gavrilov is completely correct. A Taylor expansion at fixed point $p$ gives us the real solution. Existence of this solution is proven in the paper which I already referenced from my another answer.\n\n$$f(z)=\\sum_{n=0}^\\infty \\frac{d_n (z-p)^n}{n!}$$\n\nwhere $d_n$ is defined as follows:\n\n$$d_0=p$$ $$d_{n+1}=\\sum _{k=0}^n d_k \\operatorname{B}_{n,k}(d_1,...,d_{n-k+1})$$\n\nwhere $B_{n,k}$ are the Bell polynomials\n\nThis gives the following starting coefficients:\n\n$$d_1=p^2$$ $$d_2=p^3+p^4$$ $$d_3=p^4 + 4 p^5 + p^6 + p^7$$ $$d_4=p^5 + 11 p^6 + 11 p^7 + 8 p^8 + 4 p^9 + p^{10} + p^{11}$$\n\n\nThe fixed point $p$ here serves as a parameter, which determines the family of solutions. According the linked theorem, the expansion should converge in the neighborhood of $p$ for $0 < |p| < 1 $ or $p$ being a Siegel number.\n\nshare|improve this answer\nAnixx, this becomes boring. Yeah, if $p$ is small enough, this has a chance to work (though I wonder how you prove that there are no other solutions). However, for large $p$, you have a polynomial with the leading term $p^N$ with $N\\approx k^2$ for the $k$'th coefficient. The miraculous cancellations can shave only something like $8^{N}$ off it for a typical $p$ (Remez). So, you are left with $(p/8)^{ck^2}$ which eats up the factorial and the geometrical progression for breakfast and happily flies to infinity by the lunchtime if $p$ is like $-20$. \u2013\u00a0 fedja Nov 2 '12 at 2:50\n@fedja yes, the proof in the linked paper requires p<1 or a Siegel number. I wiil add this to the answer. \u2013\u00a0 Anixx Nov 2 '12 at 10:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/236687/finding-the-volume-of-a-cylinder-without-using-pi?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nGiven a cylinder's radius and height, $a$ and $z$, and given that $z\\ll a$, what is it's volume without using $\\pi$?\n\nI was thinking that I could integrate to get the cylinder's circumference, and then divide this by the diameter to get $\\pi$, but I haven't tried it yet. Is this correct?\n\nshare|improve this question\nJust out of curiosity, why do you want to avoid $\\pi$? \u2013\u00a0 EuYu Nov 13 '12 at 20:50\nYou need $\\pi$ to get the cylinder's circumference. \u2013\u00a0 timvermeulen Nov 13 '12 at 20:52\nIt is simply a mind-bender, a challenging question designed to make me think. However, every solution I've tried so far has not worked. \u2013\u00a0 Stan Harvey Nov 13 '12 at 20:53\nIf the area of the base is $A$, the volume is $zA$. Or if the circumference is $C$ the volume is $aCz/2$ \u2013\u00a0 Ross Millikan Nov 13 '12 at 21:29\nYou could always take the Archimedes route: place it in a bowl full of water (or a measuring jug) and measure the volume of liquid displaced. \u2013\u00a0 Mark Bennet Nov 13 '12 at 21:51\nshow 1 more comment\n\n4 Answers\n\nIn order to exactly find the volume, you must use $\\pi$, as volume of a cylinder is given by\n\n$$V = \\pi a^2 z$$\n\nshare|improve this answer\nOver 6k now ${}$ :D \u2013\u00a0 amWhy Nov 27 '12 at 2:07\n@amWhy Haha, thank you! \u2013\u00a0 Argon Nov 27 '12 at 2:50\nadd comment\n\nThe area of the base is $\\dfrac{\\tau a^2}{2}$, so the volume is $\\dfrac{\\tau a^2 z}{2}$.\n\nshare|improve this answer\nHaha, I know about $\\tau$! It does seem like the easy way out, though... \u2013\u00a0 Stan Harvey Nov 13 '12 at 20:55\nI think $\\tau$ is cheating a bit, because $\\tau = 2\\pi$! \u2013\u00a0 Argon Nov 13 '12 at 20:56\nIt reminds me of a cure for hiccups that I was told about as a child: Run three times around the house without thinking of wolves. It is very important not to think of wolves. If you do, the hiccups will continue. Anyway, to get more mathematical, just use the first positive zero of the sine function. No \u03c0 needed. \u2013\u00a0 Harald Hanche-Olsen Nov 13 '12 at 21:16\nadd comment\n\nWhy don't you inscribe the cylinder into a prism whose base is a regular polygon and has $h=z$, and then compute its volume as a function of $n$? The resulting expression does not involve $\\pi$ and if you take the limit when $n$ goes to $\\infty$ you get the volume of the cylinder. The tricky part is to express the apothema in terms of $n$, so you can check that the limit is actually finite, but it can be done.\n\nTo me, this sounds like a typical application of the density of $\\mathbb{Q}$ in $\\mathbb{R}$.\n\nshare|improve this answer\nadd comment\n\nSure you can without pi. Remove the top of the cylinder. Fill it with fine-grained sand. Then pour the sand into a rectangular box, and measure how far it comes up. Of course, it will be an estimate, but not a bad one. (Get an even finer grade sand.) You can do the same by unscrewing the top of a sphere.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/35054/help-on-unit-conversion-problem/35061\nText:\nTake the 2-minute tour \u00d7\n\nThis is a problem from school. I will show my attempt.\n\nThe question:\n\n\"The gas constant for dry air R is 287 $\\frac{m^2}{s^2*K}$. Assuming the temperature is 330 K and the pressure is 1050 hPa, what is the atmospheric density.\"\n\nThe professor said DO NOT produce an answer by finding a formula, but to use the magic of unit conversion to try to solve things.\n\nI know density is measured in kg/m^3 or thereabouts so I tried the following:\n\n1050 hPA = 105, 000 Pa\n\n1 Pa = 1 kg/m*s^2\n\n105,000 $\\frac{kg}{m*s^2}$ * 330 K * 287 $\\frac{m^2}{s^2*K}$.\n\nThis cancels some units... but not enough...in fact it cancels just K, so far as I understand, far from what I need for my density unit.\n\nAny ideas on what Im doing foolishly here?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nthe line you wrote\n\n\nhas to read in fact\n\n$\\frac{105,000 \\frac{kg}{m*s^2} }{ 330 K * 287 \\frac{m^2}{s^2*K}} = 1.11 \\frac{kg}{m^3}$.\n\nThis comes from the gas law\n\n$p=\\rho \\ R \\ T $\n\nwhere $p$ is the air pressure and $\\rho$ is the air density. Solving for $\\rho$ you get\n\n$\\rho =\\frac{p}{R T} $\n\nfrom which the numerical solution follows.\n\nshare|improve this answer\nThank you - this is excellent and uses what I already did to show me how to arrive to a solution for problems like these! \u2013\u00a0 Anne Aug 28 '12 at 0:28\nWelcome! You started well but you have to write more carefully the units. Now and then write also the formulas you are going to use, even if they look very simple. This helps to cross-check the numerical calculation in each step. Longer multiplications with unit conversions come very quickly out of control (you are not the only one!) \u2013\u00a0 Lupercus Aug 28 '12 at 0:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/87914/linear-mmse-estimate-of-mmse-estimator\nText:\nTake the 2-minute tour \u00d7\n\nThis question is prompted by a recent discussion about the relationship between conditional expectation and covariance.\n\nSuppose that $X$ and $Y$ are zero-mean unit-variance random variables with covariance (and correlation coefficient) $\\rho$. The minimum-mean-square error (MMSE) estimator of $Y$ given $X$ is the random variable $g(X)$ that minimizes $E[(Y-g(X))^2]$, and as is well known, $$g(X) = E[Y \\mid X] ~\\text{minimizes}~E[(Y-g(X))^2]$$ It is also well known that $E[g(X)] = E[E[Y\\mid X]] = E[Y] = 0$. In general, $g(X)$ is a nonlinear function. On the other hand, if the estimator is restricted to being of the form $\\hat{Y} = aX + b$ where $a$ and $b$ are real numbers, then the linear MMSE estimator of $Y$ given $X$ is $\\hat{Y} = \\rho X$, that is, $$a = \\rho, ~ b = 0, ~\\text{minimizes}~E[(Y-aX-b)^2].$$ The linear MMSE estimator $\\rho X$ has a mean-square-error $E[(Y-\\rho X)^2] = 1 - \\rho^2$ and so the mean-square-error of the MMSE estimator $g(X)$ can be no larger:\n$$E[(Y-g(X))^2] \\leq 1 - \\rho^2.$$\n\nA simplified version of the question in the previous discussion is: if $g(\\cdot)$ is a decreasing function of its argument, show that $\\rho$ is nonpositive.\n\nMy question is: what is the linear MMSE estimate of $g(X) = E[Y \\mid X]$ given $X$? That is, what choice of real numbers $c$ and $d$ minimizes $E[(g(X) - cX - d)^2]$? Since $g(X)$ and $X$ both have zero mean and $X$ has unit variance, standard linear MMSE estimator theory gives that $d = 0$ and $$c = \\frac{\\text{cov}(g(X),X)}{\\text{var}(X)} = \\text{cov}(g(X),X) = E[Xg(X)]$$ which I think might work out to be $\\rho$, but I am not sure about this. Any suggestions on how to proceed further would be appreciated.\n\nshare|improve this question\nYour final result is correct: for simple least-squares regression of $Y$ on $X$, the line passes through the point $(\\mu_X,\\mu_Y)$ with gradient $\\rho \\dfrac{\\sigma_Y}{\\sigma_X} = \\dfrac{\\text{cov}(X,Y)}{\\sigma_X^2}$. So here it is just $\\rho$. \u2013\u00a0 Henry Dec 3 '11 at 3:36\nI am somewhat uncomfortable with your language, since I fear that this way of using the word \"linear\" might feed into the popular misunderstanding that the reason why linear regression in called linear regression is that one is fitting a line. People who think that then find it confusing when a statistician insists that one is doing linear regression when one fits a parabola or a sine wave, etc. \u2013\u00a0 Michael Hardy Dec 3 '11 at 5:38\n@MichaelHardy I thought about editing the question to say something like \"straight-line MMSE estimation\" instead of \"linear MMSE estimation\" but decided against it because linear MMSE estimation is reasonably well-established, at least in the engineering literature: Google provides over $900,000$ hits. But, thanks for your answer which I am accepting. I was able to show $E[Xg(X)] = \\rho$ for discrete and for jointly continuous random variables but wanted a proof that did not rely on special cases, and your answer gave me exactly what I wanted. \u2013\u00a0 Dilip Sarwate Dec 4 '11 at 3:56\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nYour conjecture is correct. By the law of total expectation we have $$ \\begin{align} E(X(Y-g(X)) & = E(\\;E(X(Y-g(X))\\mid X)\\;) \\\\ \\\\ & = E(\\; E(XY\\mid X) - E(Xg(X)\\mid X)\\;) \\\\ \\\\ & = E(\\; XE(Y\\mid X) - Xg(X) \\;) \\\\ \\\\ & = E( Xg(X) - Xg(X)) = 0. \\end{align} $$ Therefore $$ E(XY) = E(Xg(X)). $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54889.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nLines Intersecting within a Polygon\n\nDate: 10/24/96 at 18:12:24\nFrom: Keith Loveland\nSubject: geometry\n\nA fellow math teacher asked me this the other day:\n\nGiven an n-sided regular polygon with each vertex connected to each \nother vertex by a straight line segment, how do you determine the \nnumber of intersection points within the polygon? I tried n = 3 \nthrough n = 8, looked for a pattern, and noticed some things but \nnothing definitive. I plotted these points with the intersection \npoints as a function of n and tried curve fitting, but couldn't get an \nexact fit. Do you know a rule for this? Is there an odd and even set \nof rules?\n\nThanks for any help you're able to give me,\nKeith Loveland \n\nDate: 10/24/96 at 20:48:14\nFrom: Doctor Tom\nSubject: Re: geometry\n\nHi Keith,\n\nWell, this isn't a complete answer, but it may help some. I can solve \nthe problem if the points are \"unevenly\" spaced around the polygon, \nbut not if they're evenly spaced.\n\nWhat I mean is this - I can count the number of times pairs of lines \ncross each other, but the simplest case where this goes bad is the \nperfect hexagon. Three lines go through the center, and if those are \ncalled lines A, B, and C, then my method counts AB, BC, and CA as \nthree points when it probably should be counted as one. Notice that \nif the vertices are moved just a little, instead of hitting at a \nsingle point, there would be a tiny triangle with 3 intersections.\n\nAs the number of lines goes up, the number of these multiple\nintersections increases, and in a funny way that has to do with the \nprime factorization of the numbers.  My formula should work exactly \nfor all prime-sided polygons, for example.\n\nHere's how I did it:\n\nFor a triangle, there are no intersections.\n\nFor a square connecting points 1,2,3,4, break it into two parts: those \ninvolving a line from 1, and those not involving a line from 1.\n\nThose not involving a line from 1 include all the crossings made by \nthe triangle 234: zero to be exact.\n\nThose involving a line from 1 include 13 crossing 24, or one \nintersection.  So for a square, there is 1 total.\n\nI'll jump up a bit so you can see more easily, I think, what's going\non.  Consider a 7-sided polygon 1,2,3,4,5,6,7.\n\nSuppose you've got the crossing number for the 6 sided 2,3,4,5,6,7,\nand you just need to count the number of lines involving point 1.\n\nIf 1 connects to 4, those crossing it must connect 2 or 3 with 5, 6, \nor 7.  If 1 connects to 3, those crossing it must connect 2 with 4, 5, \n6, or 7, and so on.  If 1 connects to 2, nothing crosses it.  So \nconsider all the lines starting from 1:\n\n   1-2:  nothing               0   ways\n   1-3:  {2} to {4,5,6,7}      1x4 ways\n   1-4:  {2,3} to {5,6,7}      2x3 ways\n   1-5:  {2,3,4} to {6,7}      3x2 ways\n   1-6:  {2,3,4,5} to {7}      4x1 ways\n   1-7:  nothing               0   ways\n\nSo the answer is whatever your answer for 6 was plus 1x4+2x3+3x2+4x1.\n\nSo here's the full method, where f(n) is the number of ways to do this \nwith n points:\n\n   f(3) = 0\n   f(4) = f(3) + 1x1 = 0 + 1 = 1\n   f(5) = f(4) + 1x2 + 2x1 = 1 + 2 + 2 = 5\n   f(6) = f(5) + 1x3 + 2x2 + 3x1 = 5 + 3 + 4 + 3 = 15\n   f(7) = f(6) + 1x4 + 2x3 + 3x2 + 4x1 = 15 + 4 + 6 + 6 + 4 = 35\n\net cetera.\n\nMy intuition tells me that these numbers will satisfy a fourth-power \nequation (I am 99% sure of this for reasons that I can't explain).\n\nSo if you work out a few more terms for f(8), f(9), and so on, and \nthen imagine that the solution must look like this:\n\n   f(n) = A*n^4 + B*n^3 + C*n^2 + D*n + E\n\nPlug in n = 3, 4, 5, 6, 7, and consider A, B, C, D, and E to be \nunknowns, you'll get 5 equations in 5 unknowns, and you can work out \nA, B, C, D, and E.\n\nBut as I said, I have no idea how to take into account the multiple \n\nGood luck.\n\n-Doctor Tom,  The Math Forum\nAssociated Topics:\nHigh School Geometry\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/101140/a-question-about-collections-of-sets\nText:\nTake the tour \u00d7\n\nIs there anything known about the following problem? Which (sub)field to look into for questions of this flavor?\n\nConsider a collection $F$ of subsets of $[n]$, excluding the empty set, with the property that every element of $[n]$ is contained in exactly $n$ sets. The same set might appear more than once in $F$ (The number of sets in $F$ is thus between $n$ and $n^2$ and the sum of cardinalities is $n^2$).\n\nIs there a sequence (possibly with repetitions) of the numbers $1 \\dots n$, of length at most $n^\\alpha$, such that each set appears somewhere in the sequence in at most $n^\\beta$ contiguous blocks.\n\nHere's a small example: F = { {1,2}, {1,3}, {2,3}, {1,2,3} }. In the sequence (1,2,3) the set {1,3} can be mapped to two blocks only. In the sequence (1,2,3,1) all sets can be mapped to a single block.\n\n$\\alpha = 1, \\beta=1$ works if we use any permutation of the numbers.\n\n$\\alpha = 2, \\beta =0$ works if we concatenate all sets of F.\n\nCan we get something \"in between\" ?\n\nEDIT: as an important special case, F could consist of n \"partitions\" of [n].\n\nshare|improve this question\nUnfortunately, I do not understand the important special case when $F$ consists of $n$ partitions of $[n] := \\{ 1,2,\\dots,n \\}$. If $F$ is to have size $n$, then necessarily $F$ must consist of $n$-many copies of $\\{ 1,2,\\dots,n \\}$. Right? \u2013\u00a0 Asher M. Kach Jul 2 '12 at 23:08\nYes, if $F$ has size $n$, then $F$ just contains $n$ copies of $[n]$, in other words, $F$ contains $n$ copies of the partition, which is just the whole set itself. In this sense, it contains $n$ partitions of $[n]$ in this case too. For example, for n=3, $F$ could be {{1,2,3},{1,2,3},{1,2,3}} or {{1},{2,3},{1,2},{3},{1,2,3}} or {{1},{2},{3},{1},{2},{3},{1},{2},{3}}, etc. \u2013\u00a0 Laszlo Kozma Jul 3 '12 at 8:59\nBut $F$ is not necessarily of size $n$, it is just $\\geq n$ and $\\leq n^2$. \u2013\u00a0 Laszlo Kozma Jul 3 '12 at 9:01\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/34814/how-to-release-mathematica-from-the-pre-holdallcomplete-lock/34815\nText:\nTake the tour \u00d7\n\nNot sure if posted before, but I'm asking this question from a Mathematica fellow user who tried to load expressions, whose problem soon turned into a prison break game featuring the following code.\n\nSetAttributes[hold, HoldAllComplete];\nGetOut /: hold[GetOut] := Unset[$Pre];\n\n$Pre = hold;\n\nAfter executing this code, all subsequent evaluations are hold, including the GetOut \"key\" and the reset expression.\n\n$Pre = .\n\nAre there any ways to unhold subsequent evaluations, in addition to rebooting Mathematica?\n\nshare|improve this question\nAre you looking for a good solution, or the user's physical integrity should be preserved? \u2013\u00a0 belisarius Oct 26 at 2:36\n@belisarius Definitely both, if possible. I don't feel like hurting executed evaluations preceeding the lock. \u2013\u00a0 FrenzY DT. Oct 26 at 2:39\nGood question. I've always just restarted my kernel when I bungle up $Pre or $PreRead, since I didn't think there was any other way around. Would be interesting if there was... \u2013\u00a0 rm -rf Oct 26 at 2:46\n@rm-rf It's interesting that once we change HoldAllComplete to Hold, both the original attempts work. \u2013\u00a0 FrenzY DT. Oct 26 at 2:49\nOoh... I have a way out. Writing an answer. \u2013\u00a0 rm -rf Oct 26 at 2:52\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's nothing that can break out of a HoldAllComplete as long as it has to pass through the kernel. But what if we had a way to bypass the kernel? Hmmm... buttons!\n\nI suggest using the following button as an escape mechanism instead of your GetOut:\n\nButton[\"Clear $Pre\", Unset[$Pre]]\n\nWith this, you can clear $Pre by simply clicking it \u2014 even with the HoldAllComplete. It works because the evaluation is done via the Front End and not the kernel, thus bypassing $Pre.\n\nshare|improve this answer\nHow does the Button function get evaluated? Is it through the Front End? \u2013\u00a0 FrenzY DT. Oct 26 at 4:34\n@FrenzYDT. Read the last paragraph? \u2013\u00a0 Sjoerd C. de Vries Oct 26 at 6:45\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/77063/sequences-of-linear-combinations-of-measures/77347\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a Polish space. Let $J\\in\\mathbb{N}$.\n\nLet $\\lbrace a^n_1\\rbrace_n,\\dots,\\lbrace a^n_J\\rbrace_n$ be $J$ sequences of reals.\n\nLet $\\lbrace \\mu^n_1\\rbrace_n,\\dots,\\lbrace \\mu^n_J\\rbrace_n$ be $J$ sequences of probability measures in $\\Delta(X)$.\n\nFor each $j\\leq J$, let $\\mu^n_j$ weakly converge to $\\mu_j \\in \\Delta(X)$.\n\nLet $\\sum_{j\\leq J} a^n_j \\mu^n_j \\in \\Delta(X)$ weakly converge to $\\mu^* \\in \\Delta(X)$.\n\nConjecture: Does there exist a vector $(\\beta_1,\\dots,\\beta_J)$ of reals such that $\\mu^* = \\sum_{j\\leq J} \\beta_j\\mu_j$? It need not be unique.\n\nProof for when $J=2$:\n\n$a^n_1\\mu^n_1+a^n_2\\mu^n_2$ is a probability measure. Therefore $a^n_2 = 1-a^n_1$.\n\n$a^n_1\\mu^n_1+(1-a^n_1)\\mu^n_2 = a^n_1 (\\mu^n_1-\\mu^n_2)+\\mu^n_2 \\to \\mu^*$. Since $\\mu^n_2 \\to \\mu_2$, it follows that $a^n_1 (\\mu^n_1-\\mu^n_2)$ converges.\n\nIf $\\mu_2 = \\mu_1$, then $\\mu^* = \\mu_2$.\n\nIf $\\mu_2 \\neq \\mu_1$, then $a^n_1$ must converge since $a_1^n\\int g\\ d(\\mu^n_1-\\mu^n_2)$ must converge for all continuous bounded functions $g: X \\to \\mathbb{R}$.\n\nSome comments The proof above does not seem to generalize to $J>2$. We can also view the problem more generally as an infinite dimensional vector space problem.\n\nThat is, we can look at $\\lbrace \\mu^n_1,\\dots,\\mu^n_J \\rbrace$ as the vector subspace defined by the linear span of its elements. If $\\mu^n$ is a convergent sequence ($\\mu^n \\to \\mu^*$) such that $\\mu^n \\in span(\\mu^n_1,\\dots,\\mu^n_J)$ and $\\mu^n_j \\to \\mu_j$, is it the case that $\\mu^* \\in span(\\mu_1,\\dots,\\mu_J)$?\n\nI think the original problem places additional constraints on the problem by requiring that certain objects are probability measures (as opposed to any vector in the space of finite signed measures), but these two problems seem reasonable close.\n\nAny hints? Could the original conjecture be wrong? Strange things happen in infinite dimensional spaces...\n\nshare|improve this question\nAs it is, the generalization is false, even in $\\mathbb{R}$ (as a TVS) and $J=1$. Take $\\mu^n_1:=1/n\\to\\mu_1:=0$, and $\\mu^n=\\mu^*=1$, for all $n$. \u2013\u00a0 Pietro Majer Oct 3 '11 at 19:27\nThanks Pietro. You are right about the generalization. About your comment regarding linear independence: What if $\\lbrace\\mu_1^n,\\dots,\\mu_J^n\\rbrace$ was always a linearly independent set for each given $n\\in\\mathbb{N}$? It happens that the particular research problem I am working on does have that restriction \u2013\u00a0 BSL Oct 3 '11 at 19:52\nActually I think what is needed is the linear independence of the limit family; see below. \u2013\u00a0 Pietro Majer Oct 3 '11 at 21:39\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe generalization you suggest is true in any real topological vector space $X$ (Hausdorff or not), under the further assumption that the limit family $(\\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$ be linearly independent. The natural generalization to net convergence is also true (with essentially the same proof) .\n\nFact. The set $D _ J$ of all linearly dependent $J$-uples of elements of $X$ is a closed subset of $X^J$. Indeed, let $\\mathbb{S}$ be the unit sphere of $\\mathbb{R}^J$. Then $D _ J$ is the projection on the second factor of the closed subset of $\\mathbb{S}\\times X^J$ $$F_J:=\\Big\\{ (\\lambda,\\mu) \\in \\mathbb{S}\\times X^J\\ : \\ \\sum_{j=1}^J\\ \\lambda_ j \\mu _ j=0 \\Big\\} , $$ and the projection $\\mathbb{S}\\times X^J\\to X^J$ is a closed map because $\\mathbb{S}$ is compact.\n\nConsequence. Let $\\mu ^ n _ 0 \\in \\operatorname{span} (\\mu ^ n _ 1,\\dots,\\mu ^ n _ J)$ for all $n \\in \\mathbb{N}$ and assume that $\\mu ^ n _ j \\to \\mu ^ \\infty _ j$ as $n\\to\\infty$, for $j=0,1,\\dots, J$. Then the $(J + 1)$-uple $(\\mu ^n _ 0, \\mu ^ n _ 1,\\dots,\\mu ^ n _ J)$ is linearly dependent, so by the above fact the limit $(J +1)$-uple $(\\mu ^\\infty _ 0, \\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$ is linearly dependent too. However, by assumption $(\\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$ is linearly independent, which implies that $\\mu ^ \\infty _ 0 \\in \\operatorname{span} (\\mu^\\infty _ 1,\\dots,\\mu^\\infty _ J)$.\n\nRmk. Assuming the linear independence of the limit $J$-uple is necessary, otherwise the statement is false even for $J=1$ and $X=\\mathbb{R}$ as shown in my comment above. Also, assuming that the limit $J$-uple are probability measures as in your first conjecture, is still not sufficient already for $J=2$, and in fact there's a problem in your proof. In your notation, if $\\mu_2=\\mu_1$, it is not guaranteed that $\\mu^*=\\mu_2$. Take e.g. $X=\\{0,1\\}$, a discrete two\u2212points space. Take $\\mu^n_1:=\\delta_1$ and $\\mu^n_2:=\\big(1-\\frac{1}{n}\\big)\\delta_1+\\frac{1}{n}\\delta_0$.They both converge to $\\mu_1=\\mu_2=\\delta_1$, but a linear combination of them, namely $n\\mu^n_2 - (n-1) \\mu^n_1=\\delta_0$ converges to $\\mu^*:=\\delta_0$, which is not in the span of $\\delta_1$.\n\nshare|improve this answer\nI've rewritten the whole answer. \u2013\u00a0 Pietro Majer Oct 6 '11 at 9:53\nThanks! Even though this wasn't my original problem, it will be helpful. I was interested in the original problem as an intermediate result for something else, and I can see that your solution of the modified problem might help me in other ways. It also helps that my original conjecture was proven wrong in your answer. \u2013\u00a0 BSL Oct 6 '11 at 20:34\nadd comment\n\nHere's a preliminary answer.\n\nIf you consider convex combinations, so that in particular we have $a^n_j \\in [0,1]$, then this is true. By the compactness of $[0,1]^J$, we can assume (passing to a subsequence) that $a^n_j$ converges for each $j$. If we call $\\beta_j$ the limit, then weak continuity of addition and scalar multiplication shows that $\\sum_j a^n_j \\mu^n_j \\to \\sum \\beta_j \\mu_j$, so uniqueness of weak limits gives $\\mu^* = \\sum_j \\beta_j \\mu_j$.\n\nReally, all we're using is that the space of measures with the weak topology is a Hausdorff topological vector space.\n\nI have a suspicion that any probability measure $\\mu$ that can be written as a linear combination of probability measures can also be written as a convex combination of those same probability measures, which would settle the general case. This may be a basic fact about cones in vector spaces. I'll think about it a little more.\n\nshare|improve this answer\nThanks for the preliminary reply. I will wait for your full reply. Your ideas seem promising at least. However, one note about linear combinations of probability measures: If $X=\\lbrace a, b, c\\rbrace$, $p = (1/3,1/3,1/3), q = (1/4,1/4,1/2), r = (0,0,1) \\in \\Delta(X)$. $r = -3p + 4q$. There cannot exist an $a \\in [0,1]$ such that $r= ap +(1-a)q$. \u2013\u00a0 BSL Oct 3 '11 at 19:51\nOk, good counterexample. \u2013\u00a0 Nate Eldredge Oct 3 '11 at 21:01\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/40808/velocity-of-electron-in-electrostatic-field-does-radiation-matter\nText:\nTake the 2-minute tour \u00d7\n\nThere's a voltage difference of 1000 Volts between two points 2 meters apart. An electron starts at the point of lower potential and is left to travel alone in a straight line until it reaches the other point. Question: What speed does the electron have when it reaches the second point?\n\nMy concern is whether the retardation effects of the radiation of the electron are important here. I tried doing it using the relativistic formulae for the kinetic energy and got\n\n\nwhere $m_e$ is the electron mass, $c$ the speed of light, $V$ the voltage difference between the two points, and $v$ the final speed of the electron.\n\nThis is not a homework exercise. I am just curious as to the effects of radiation.\n\nEdit: What if the potential difference was 10 000 Volts in 2 meters? What if it was 1 000 000 Volts in 2 meters?\n\nshare|improve this question\nIn principle yes, there is some loss to Bremsstrahlung, but...half a kilovolt per meter over two meters is chump change. The electron is still mostly non-relativistic (around 2% of c) and the acceleration is quite modest (by accelerator physics standards). For comparison, high gradients are measured in MV/m. \u2013\u00a0 dmckee Oct 15 '12 at 2:44\nBy the way, you'll find the math easier if you work in $c = 1$ units. Then $m_e \\approx 511\\text{ keV}$, and the above claim about the velocity becomes reasonably clear. \u2013\u00a0 dmckee Oct 15 '12 at 2:47\n@dmckee I added two additional cases. So at about a million Volts per meter is that the retardation effects of radiation start to be felt? \u2013\u00a0 becko Oct 15 '12 at 3:36\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou need to distinguish between retardation and radiation.\n\nRetardation usual refers to the effect of limited propogation seeds on interactions. That is we replace $$a_g = G\\frac{M}{r^2}$$ with $$a_{g,\\mathrm{ret}} = G\\frac{M}{r(t - \\frac{r}{c})^2} .$$\n\nThis only matters if\n\n  1. The ration of velocities in the system to propogation speeds are significant, or\n  2. The effect is constantly in one direction\n\nin other cases (as in retarded Newtonian gravity in the solar system) it simply results in a constant correction to some effective parameter of the system (reduced mass in our example).\n\nIn your case, you have a static field which means that $\\mathcal{E}(t) = \\mathcal{E}$ and the problem reduced to original case. There is no effect due to retardation.\n\nI'm taking \"radiation\" to mean the loss of energy by accelerating charges known as Bremsstrahlung.\n\nEverything you really want to know is in the Wikipedia link. You propose a linear acceleration case, so we can use $$ P_{a\\parallel v} = \\frac{q^2 a^2 E^6}{6 \\pi^2 \\epsilon_0 m^6 c^{15}}$$ for the power lost to radiation. Here I have used $E = \\gamma m c^2$ for the total energy of the electron (including it's mass).\n\nAs I noted above, the energies involved are such that the electron remains largely non-relativistic, so we'll stick to the Physics 101 for of the kinematic equations. The average velocity is about 1% of the speed of light, so the time to cover the distance is about 600 ns, and the acceleration is $a = \\frac{0.02 * 3\\times10^8\\text{ m/s}}{6\\times10^{-7}\\text{ s}} = 10^{13}\\text{ m/s}^2$.\n\nBecause the electron's energy only changes by about 2% over the whole range I'm not going to bother with a proper integration of the power, and instead just multiply (I make an error on order of 6% by doing so). The energy lost to radiation is about $$E_l = P_{a \\parallel v} t = \\frac{q^2 a^2 \\left(1.01*mc^2\\right)^6}{6 \\pi^2 \\epsilon_0 m^6 c^{15}} t = \\left(1.01\\right)^6 \\frac{q^2 a^2}{6 \\pi^2 \\epsilon_0 c^3} t$$ and (after furiously checking the units) I just start plugging in\n\n  \u2022 $q = 1.6 \\times 10^{-16}\\text{ C}$\n  \u2022 $\\epsilon_0 = 8.8 \\times 10^{-12} \\text{ m}^{-3} \\text{ kg}^{-1} \\text{ s}^2 \\text{ C}^2$\n  \u2022 $c = 3\\times10^8\\text{ m/s}$\n  \u2022 $t = 6\\times10^{-6}\\text{ s}$\n\n$$E_l \\approx 1.2\\times 10^{-28}\\text{ J} = 7 \\times 10^{-10}\\text{ eV}$$.\n\nSo the losses are trivial.\n\nThis isn't surprising since a typical CRT runs at 10+ keV over a few centimeters and doesn't spew lots of x-rays around the room.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64233/could-this-be-a-np-complete?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\n Given a undirected and unweighted graph G(V,E). M is a subset of vertices of V. \n s is a vertex in V - M.\n Find an optimal tree T of G defined as:\n (1) M and s are in V(T)\n (2) Distance (which is length of the shortest path) from s to any vertex in M in tree T is equal to distance from s to these vertices in G\n (3) No other tree T' satisfying condition (1) and (2) can have fewer nodes than T  \nMy idea was to use Dijkstra's algorithm to find shortest path from s to all vertices in M. However, there could be many shortest paths from vertex s to a vertex v. So, I will pick the shortest path that has the most number of vertices in M.\n Merge all these paths together to get tree T.  \nThis seems to solve the problem in polynomial time. However, my concern is the number of shortest path from vertex s to a vertex v could be very large that can make this algorithm be exponential. I don't know if there is any upper bound for the number of shortest path between 2 vertex in a graph.  \nAlso, does any one know if this problem is NP problem or it could be solved in polynomial time?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nThe problem is NP-complete.\n\nI think that the following algorithm describes a polynomial reduction of SAT to your problem.\n\nLet S be an instance of SAT. So you have a finite set of clauses $C_1$, $C_2$, ...,$C_n$.\nand a finite set of variables $p_1$, $p_2$, ..., $p_k$. Each clause contains some literals, i.e., variables $p_i$ and/or negated variable $\\lnot p_i$. (in 3sat we assume that each clause contains at most 3 literals.) We may assume that for each variable $p$ there is a clause $C_p$ containing only $p$ and $\\lnot p$, so $n\\ge k$.\n\nMake S into a graph as follows: There is a special vertex $ s$. For each variable $p$ there are two vertices $p$ and $\\lnot p$, both connected to $s$ (EDITED to simplify) by an edge. There is a vertex for every clause. Each literal $L$ is connected by an edge to each clause $C$ in which $L$ appears.\n\nThe set $M$ will be the set of all clauses.\n\nIf the original problem S was satisfiable, say with an assignment $A$, then then there is an optimal tree with $n+k$ edges: Connect $s$ with all literals which are true under $A$, and connect each clause $C$ with a literal $L$ in $C$ that is true under $A$.\n\n(EDITED to clarify and to close a gap:) Conversely, if there is an optimal graph with at most $n +k$ edges, then:\n\n  1. Each clause has to be on the tree, so it has to be connected to some literal. This costs $n$ edges.\n\n  2. For each variable $p$, either $p$ or $\\lnot p$ has to be on the tree (because of $C_p$), so either $p$ or $\\lnot p$ has to be connected (by an edge) to $s$ (because the distance has to be $1$). These connections cost $k$ edges.\n\n  3. So from each such pair EXACTLY one is connected with $s$. Those literals which are connected to $s$ now define a satisfying truth assignment.\n\nHence the instance $G,M$ of your problem that I constructed from the SAT problem $S$ has a solution of size at most $n+k$ iff $S$ is satisfiable. So any algorithm to solve your problem also solves SAT. Hence your problem is NP-complete.\n\nshare|improve this answer\nThanks a lot goldstern. I thinks this transformation is correct. I just wonder why we don't connect s directly to each variable instead of going through path o length n. That way we can have a tree of n + k edges, can't we? \u2013\u00a0 chepukha May 8 '11 at 1:18\nanother problem with this transformation is that you're trying to limit the number of edges while the optimal tree must have minimum number of vertices. With the way you select the tree, the number of vertices is not minimum. \u2013\u00a0 chepukha May 8 '11 at 5:02\nYou are right, the paths are not necessary. I edited my answer to simplify it (and also to clarify some points). \u2013\u00a0 Goldstern May 8 '11 at 8:19\nI do not understand your question about edges vs vertices. A tree with v vertices has v-1 edges. So you minimize the number of edges iff you minimize the number of vertices. \u2013\u00a0 Goldstern May 8 '11 at 8:20\nMaybe I didn't quite understand your proof. So let me give an example. Let say I have a 3SAT (x+y+z)(x+\u00acy+z). We can assign x=y=z=T. So, if we follow the proof, then we will get a tree with 6 vertices and n+k=2+3=5 edges. However, I can have another smaller tree that can have the same shortest paths to vertices in M={C1, C2}. That tree has 3 edges connecting the vertex representing x with s, C1, and C2. It also has only 4 vertices. Am I missing something here? \u2013\u00a0 chepukha May 8 '11 at 8:48\n\nJust a rough idea: (I am not really an expert on graph theory, so there may be a much better upper bound.)\n\nYou can group the vertices according to their distance to $s$, say\n\n$L_i=\\{v\\in V|dist(s,v)=i\\}$\n\nThen of course the $L_i$ are pairwise disjoint. Any shortest path from $s$ to a given vertex $v$ has to pass the $L_i$ ascending (you can easily proof this fact), so first a vertex from $L_1$, then one from $L_2$, and so on. That means there are at most $\\prod_{i=1}^{dist(s,v)-1}|L_i|$ shortest paths. As $|L_i|\\leq |V|$, you have a polynomial upper bound.\n\nWhile thinking about it: There might be a way to press this bound much lower, as $|L_i|=|V|$ only happens when all vertices have distance 1, which means the shortest path is the direct connection between $s$ and $v$. For decreasing amount of vertices in the $L_i$, the possible length of the path grows. You probably could use this to get a better bound.\n\nI do not see why the rest of your algorithm should not work.\n\nshare|improve this answer\nThank you. I didn't have time to verify your proof here but I think the above transformation is correct. \u2013\u00a0 chepukha May 8 '11 at 1:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/339218/probability-problem-about-calls-to-a-fire-department/339288\nText:\nTake the 2-minute tour \u00d7\n\nIn a particular city, the probability a call to a fire department concerns various situations is as given below:\n\n  1. fire in a detached home: $p_1=0.10$\n  2. fire in a semi-detached home: $p_2=0.05$\n  3. fire in an apartment or multiple unit residence: $p_3=0.05$\n  4. fire in a non-residential building: $p_4=0.15$\n  5. non-fire-related emergency: $p_5=0.15$\n  6. false alarm: $p_6=0.50$\n\n(a) Give the joint probability function for $X_1,\\dots,X_6$ (I know how to do this one...)\n\n(b) What is the probability that there is at least one apartment fire, given that there are 4 fire-related calls? (cannot come up with a formula for this one)\n\nshare|improve this question\nTry this: in 100 calls, how many are fire-related, and how many of those are apartment fire calls? So what is the probability of non-apartment fire call? Of four of them? And what's the complement of \"none\"? \u2013\u00a0 User58220 Mar 24 '13 at 1:26\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nOn average, in 100 calls there will be 50 false alarms and 15 non-fire-related calls.\n\nSo there will be only 35 fire related calls, of which 5 will be apartment calls. So the probability that a fire call will be an apartment call is $\\frac{1}{7}$\n\nThe probability that a fire call will not be apartment related is $\\frac{6}{7}$\n\nThe probability of four non-apartment fire calls is $(\\frac{6}{7})^4$\n\nSo the probability of at least one apartment call in four fire calls is:$$1-(\\frac{6}{7})^4$$ or $ 0.460225$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/58635/bounding-the-number-of-character-degrees-of-a-finite-group-in-terms-of-the-order?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $cd(G)$ be the set of degrees of irreducible complex characters of the finite group $G$ (so $cd(G) = \\{\\chi(1) | \\chi\\in Irr(G)\\}$).\n\nWhat bounds are known of the form $|cd(G)|\\leq f(|G|)$ (ie, what functions $f$ are known which satisfies such an inequality)?\n\nI can show that $|cd(G)|\\leq \\sqrt[3]{3|G|-7}$ and if $|G|$ is odd that $|cd(G)|\\leq \\sqrt[3]{\\frac{12}{15}|G|}$. On the other hand, one clearly has $|cd(G)|\\leq d(|G|)-1$ (where $d(n)$ is the number of divisors of $n$), and this is better asymptotically. There are two reasons for this question. One is that I am looking at certain inequalities which guarantee that a group will be solvable, and having a good bound on $|cd(G)|$ in terms of the order of the group would help. Also, the question is interesting when compared to the Taketa-inequality ($dl(G)\\leq |cd(G)|$ which is conjectured to hold for all solvable groups), since clearly the derived length of a solvable group only grows logarithmically in the order of the group (being bounded by the sum of the exponents in the prime factorization of the order of the group).\n\nshare|improve this question\nI've taken the liberty of making the question more visible. I hope you don't mind. \u2013\u00a0 S. Carnahan Mar 16 '11 at 14:11\nNot at all, thank you. I just realized that instead of $d(|G|)-1$ one can actually use $d(|G|)/2$ (and I have a feeling that equality is rare except when $G$ has prime order) \u2013\u00a0 Tobias Kildetoft Mar 17 '11 at 9:47\n\n1 Answer 1\n\nThe number of divisors at least roughly resembles the best achievable lower bound. For each prime $p$, there is a group $G_p$ with $p^3$ elements which has an irreducible representation of dimension 1 (the trivial representation) and an irreducible representation of dimension $p$ (because it's non-abelian). Now let $p_n$ be the $n$th prime. The number $$P_n = p_1p_2\\cdots p_n$$ is a type of number with a lot of divisors. If you likewise let $$H_n = G_{p_1} \\times G_{p_2} \\times \\cdots \\times G_{p_n},$$ then $H_n$ has an irreducible representation for every $d$ that divides $P_n$, and it has $P^3_n$ elements.\n\nNow, it is not quite true that $P_n$ has more divisors than any $N < P_n$. It is a good strategy for making a number with many divisors, but soon enough it is better to add more factors of $p_1$, then eventually more factors of $p_2$, etc., than to keep adding new prime factors. To understand this situation better, we can make many numbers (but not all numbers) that have more divisors than their predecessors with the \"threshold method\". The idea is to optimize the ratio $\\log(d(N))/\\log(N)$ globally by optimizing it locally (with respect to prime factorization). Pick a constant $t > 0$, the threshold, and say that $N$ should have at least $k > 0$ factors of a prime $p$ if and only if $$\\frac{\\log(k+1) - \\log(k)}{\\log(p)} \\ge t.$$ Then I think that $d(M) < d(N)$ when $M < N$.\n\nIn fact, finding large values of $cd(G)$ (which I will use to mean the cardinality of the character degrees rather than the set) is a very similar problem when $G$ is nilpotent. A finite group is nilpotent if and only if it is the product of its Sylow subgroups. The main idea of the construction above is that in this case $cd(G)$ is multiplicative, i.e., the product of its values for $p$-groups. Following the comment by Frieder Ladisch, $cd(G)$ is maximized for $p$-groups by $C_{p^m} \\ltimes C_{p^{m+1}}$. (In the first version of the answer I used other $p$-groups that aren't as good.) I.e., this group has character degrees $1,p,\\ldots,p^m$, and no $p$ group with $p^{2m}$ or fewer elements can have an irrep with $p^m$ elements. So you can find many record values of $cd(G)$ for nilpotent groups using instead the threshold formula $$\\frac{\\log(k+1) - \\log(k)}{\\min(4-k,2)\\log(p)} \\ge t.$$\n\nLet's incorporate the concept of a \"record value\" by defining $d'(N)$ to be the maximum of $d(M)$ with $M \\le N$. Likewise define $cd'(N)$ to be the maximum of $cd(G)$ with $|G| \\le N$. Then I think that the above constructions show that $d'(N)$ and $cd'(N)$ are at least similar functions, and that $$d'(N) > cd'(N) > \\sqrt[3]{d'(N)}$$ when $N$ is large enough. In fact I think that the exponent of the second inequality climbs from $1/3$ to some higher value, although for nilpotent groups one also has $$\\sqrt{d'(N)} > cd'_{\\text{nil}}(N).$$\n\nLet me also mention that the bound $O(\\sqrt[3]{|G|})$ follows immediately from the fact that $|G|$ is the sum of the squares of the dimensions of the irreducible representations --- maybe that's what you have in mind with your bound.\n\nshare|improve this answer\nThe order of your group $H_n$ has $4^n$ divisors, and there are $2^n$ different character degrees. In general, a nilpotent group of order $N=p_1^{e_1}\\cdot \\dotsm\\cdot p_n^{e_n}$ has at most $d(N)2^{-n}$ character degrees. I guess that non-nilpotent groups of the same order might have more character degrees. \u2013\u00a0 Frieder Ladisch Mar 17 '11 at 20:20\nBy the way, the group $C_{p^{m}}\\ltimes C_{p^{m+1}}$ has character degrees $1$, $p$, $\\dotsc $, $p^m$. \u2013\u00a0 Frieder Ladisch Mar 17 '11 at 20:22\n@F. Ladisch Thanks for these remarks. That makes the second part of the construction rather simpler. Clearly, then, the lower bound is at least the cube root of the upper bound asymptotically, if one regularizes to make the bounds monotonic. If you can find non-nilpotent examples that do better, cool. \u2013\u00a0 Greg Kuperberg Mar 17 '11 at 21:18\nI don't have a series of non-nilpotent groups that do better, but I've made the observation that if there are non-nilpotent groups of some fixed order, then the maximum of $|cd(G)|$ for all groups of that order is usually obtained for a non-nilpotent group. I'm not sure however, if this makes any difference asymptotically. \u2013\u00a0 Frieder Ladisch Mar 18 '11 at 11:58\n\nYour Answer"}
{"text": "Retrieved from http://www.chegg.com/homework-help/questions-and-answers/satellite-moves-circular-orbit-around-earth-speed-64-km-s-determine-satellite-s-altitude-s-q1065421\nText:\nA satellite moves in a circular orbit around the Earth at a speed of 6.4 km/s.\nDetermine the satellite\u2019s altitude above the surface of the Earth. Assume the\nEarth is a homogeneous sphere of radius 6370 km and mass 5.98 \u00d7 1024 kg. The\nvalue of the universal gravitational constant is 6.67259 \u00d7 10-11 N \u00b7 m2/k2\nAnswer in units of km.\n\n\nDetailed answers to tough\nhomework problems"}
{"text": "Retrieved from http://mathoverflow.net/questions/35351/minimum-differences-in-vectors-of-naturals?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI have run into this problem (or something similar to it) a few times now and I am wondering if the answer is known.\n\nGiven an vector $s$ of integers let $d(s)$ be the minimum difference between any two integers in $s$, that is $$d(s) = \\min_{i,j \\in s} |i - j|.$$ For $s$ a vector of length $m$ from $\\lbrace 1,2,\\dots,n\\rbrace^m$ we must have $0 \\leq d(s) < n$.\n\nGiven $0 \\leq k < n$, how may such vectors have $d(s) = k$ ?\n\nI'm more interested in the case where $n$ is much larger than $m$.\n\nNote: If $N_k$ is the answer for $k$. Then you should have $n^m = \\sum_{k=0}^{n-1}N_k$\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nThe number of $m$-subsets of {$1,2,\\ldots,n$} with distance at least $k$ between any pair is $n - (k-1)(m-1) \\choose m$.\n\nProof: for any subset of size $m$ of the first $n-(k-1)(m-1)$ integers, you can get a subset $S$ of the first $n$ with $d(S)\\geq k$ by just adding $k-1$ consecutive integers after each of the first $m-1$ elements of $S$.\n\nSo your answer is ${ n - (k-1)(m-1) \\choose m } -{ n - k(m-1) \\choose m }$ .\n\nUPDATE The intended question was about vectors and not sets. Essentially the same proof works; see the comments.\n\nshare|improve this answer\nHi Peter, I don't think this is correct. With ''m-subsets of $\\{1,2,\\cdots,n\\}$'' you are not allowing repetition, but I mean for the question to allow repetition. This is wholly my fault, I should never have called $S$ a set! \u2013\u00a0 Robby McKilliam Aug 12 '10 at 21:57\nMy comment makes no sense! Repetition implies that $d(S) = 0$. I'm going to have to stop and think about what I am asking. \u2013\u00a0 Robby McKilliam Aug 12 '10 at 22:14\nThat is the answer for sets since one gets just those sets, and once each. Then $\\binom {n}{m} = \\sum_{k=1}^{n-1}N_k$. If you want to have an $N_0$ and $n^m = \\sum_{k=0}^{n-1}N_k$ then you really are talking about vectors. Then, for $k \\gt 0$, multiply the answer above by $m!$. And then $N_0$ is what it would have to be, $n^m-\\frac{n!}{(n-m)!}$ \u2013\u00a0 Aaron Meyerowitz Aug 12 '10 at 23:18\nIt seems that you really do mean vectors and not multisets as in your amended title. But the answer for multisets is cute. Then $N_k$ is as Peter said for $k \\gt 0$ and $N_0=\\binom{n+m-1}{m}-\\binom{n}{m}$ which is the $k=0$ case of the formula. \u2013\u00a0 Aaron Meyerowitz Aug 12 '10 at 23:44\nIndeed, I mean vectors. I have fixed the title. I have made a bit of a mess of this question! And multiplying Peters answer by $m!$ as you have said give the desired result. \u2013\u00a0 Robby McKilliam Aug 13 '10 at 0:28\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/210352/boolean-simplification?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm having some trouble getting a handle with this course. We are starting Boolean algebra and my professor wants us simplify the following:\n\n\n\nI am assuming the \"()\" with \"'\" means the over-score above the variables.\n\nForgive my ignorance but my professor does not explain anything. He just says \"Do!\" in a Russian accent. I just want to understand.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nBy de Morgan\u2019s law $(AB)'=A'+B\\,'$, and it\u2019s always true that $X+X'=1$, so $$(AB)'+(A'+B\\,')'=(A'+B\\,')+(A'+B\\,')'=1\\;.$$\n\nSimilarly, we can start simplifying $(AB)'+BC+A'B\\,'C\\,'$ by using de Morgan\u2019s law to expand the first term, getting $A'+B\\,'+BC+A'B\\,'C'$. Now use one of the distributive laws to get $$A'+A'B\\,'C\\,'=A'1+A'B\\,'C\\,'=A'(1+B\\,'C\\,')$$ and then an absorption law to get $$A'+A'B\\,'C\\,'=A'(1+B\\,'C\\,')=A'1=A'\\;.$$ Thus, $$A'+B\\,'+BC+A'B\\,'C'=A'+B\\,'+BC\\;.$$\n\nNote that I could have reached the same final result by simplifying $B\\,'+A'B\\,'C\\,'$ to $B\\,'$, using exactly the same approach.\n\nAdded: As StainlessSteelRat notes in the comments, the simplification can be taken a step further. Specifically,\n\n\nso $A'+B\\,'+BC=A'+B\\,'+C$.\n\nshare|improve this answer\nAlright that makes sense. My question is now do we always follow those same steps? i.e. de Morgans, distribute laws, absorption laws. Or does each equation go through a different approach, depending how it is presented? \u2013\u00a0 Leo Oct 10 '12 at 9:29\n@Leo: In general it\u2019ll be a different approach each time, just as it was back in eighth- or ninth-grade algebra when you were asked to simplify an expression. In fact it is just algebra, though the rules are a little different from the ones for the familiar algebra of real numbers. \u2013\u00a0 Brian M. Scott Oct 10 '12 at 9:35\nThanks Brain for help. \u2013\u00a0 Leo Oct 10 '12 at 9:48\n@Leo: You\u2019re welcome. \u2013\u00a0 Brian M. Scott Oct 10 '12 at 10:03\n@Brian Since B' is there the B in BC is not required, so it reduces to A' + B' + C. \u2013\u00a0 StainlessSteelRat Apr 8 at 15:56\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/46418/relation-between-toric-geometry-and-log-geometry/46454\nText:\nTake the 2-minute tour \u00d7\n\n\nI'm trying to understand the relation between the points of view of log geometry (monoids) and toric geometry (fans).\n\nSuppose that $k$ is a field and $P$ is a finitely generated monoid. Then $k[P]$ has a natural log structure and furthermore, any choice of generators $\\mathbf N^r\\to P$ induces a closed embedding $Spec(k[P])\\subset\\mathbf A^r$.\n\nOn the other hand, starting from a cone $\\sigma$ satisfying some properties in a lattice $N\\otimes\\mathbf R$, where $N = \\mathbf Z^r$, we obtain a monoid $P' = \\sigma^\\vee\\cap M$, where $M = Hom(N,\\mathbf Z)$ and $\\sigma^\\vee$ is the set of all $x\\in M\\otimes\\mathbf R$ such that $x(\\sigma) \\geq 0$.\n\nQuestion: if we start with $P$ (and a choice of generators as above), can one write a corresponding cone so as to recover $P$ by the construction in the previous paragraph?\n\n\nshare|improve this question\nJust to clarify about generators: you don't want to use the same $r$ for the number of generators of $P$ and the rank of $N$. For example, take the monoid generated by $2$ and $3$ inside $M={\\Bbb Z}$. Then $N={\\Bbb Z}$ also, but you need two generators for $P$. \u2013\u00a0 Dave Anderson Nov 18 '10 at 5:05\nYou have to assume that $P$ is saturated, cancellative and with the group completion torsion free in order to be able to recover it from the cone. \"Saturated\" means that if $p$ belongs to the group completion and $np\\in P$ for some $n>0$ then $p\\in P$. \u2013\u00a0 Torsten Ekedahl Nov 18 '10 at 5:56\n\n3 Answers 3\n\nup vote 4 down vote accepted\n\nNot all finitely generated monoids $P$ will come from the cone construction. You need to assume that:\n\n  1. $P^{gp}$ is torsion-free: If $x \\in P^{gp}$ and $n\\cdot x = 0$ then $x = 0$.\n  2. $P$ is cancellative: If $x + y = x + y'$, then $y = y'$. This is equivalent to saying that the map $P \\rightarrow P^{gp}$ is injective.\n  3. $P$ is saturated: If $x \\in P^{gp}$ and $x^n \\in P$, then $x \\in P$. Assuming the previous two proporties, this is equivalent to $k[P]$ being normal.\n\nHere, $P^{gp}$ refers to the group formed by inverting all the elements of $P$.\n\nIf $P$ is finitely generated and satisfies 1, then $P^{gp}$ is a lattice, i.e. isomorphic to $\\mathbb Z^r$ for some $r$, and this is the lattice $M$ from the cone construction. The dual lattice $N$ is $\\textrm{Hom}(M, \\mathbb Z)$, and $\\sigma$ can be taken to be those $\\lambda$ in $N \\otimes_{\\mathbb Z} \\mathbb R = \\textrm{Hom}(M, \\mathbb R)$ such that $\\lambda(x) \\geq 0$ for all $x \\in P$.\n\nshare|improve this answer\nIn Condition (3), I think you mean to say $k[P]$ is a normal (i.e., integrally closed) domain. To me, at least, \"integral domain\" just means no zerodivisors, which is implied by (1) and (2). \u2013\u00a0 Dave Anderson Nov 18 '10 at 6:31\n@Dave, yes, (1) and (2) are exactly what you need for k[P] to be an integral domain, and then having (3) in addition says that it is a normal domain. \u2013\u00a0 Dustin Cartwright Nov 18 '10 at 16:18\n\nSloppy stab at a reformulation:\n\nI think we are assuming P is commutative? (\\sigma^\\vee \\cap M certainly is.) If so, then isn't P spanned by all linear combinations of the generators? But then there are relations, too, etc. So the question might be, does P embed as a submonoid of a free abelian group over Z? (I don't know.) If so, convexity of the corresponding domain is clear, and finite generatedness means it's cut out by a finite number of conditions. Your lattice is the Z-span of P and your cone is then the (dual of the) R-convex hull.\n\nshare|improve this answer\n\nPicking up some of Eric Zaslow's reformulation: Assume $P$ is commutative, saturated, and cancellative, as well as finitely generated. The answer to your question is affirmative if and only if the \"groupification\" $P^{gp}$ of $P$ is torsion-free. (As mentioned in Dustin's answer, saturated means that for all $p$ in $P^{gp}$, $np \\in P$ implies $p\\in P$. Cancellative means $p_1+q=p_2+q$ implies $p_1=p_2$.)\n\nAll this amounts to $P$ being embeddable as a sub-monoid of ${\\Bbb Z}^n$ for some $n$. Then take the subgroup of ${\\Bbb Z}^n$ spanned by $P$. This is isomorphic to some ${\\Bbb Z}^m$; take the dual of the convex hull of $P$ in ${\\Bbb R}^m$ and you've got your cone $\\sigma$, just as Eric says. When $P$ is saturated, it is equal to $\\sigma^\\vee \\cap M$; otherwise, this gives the saturation of $P$, corresponding to the integral closure of $k[P]$.\n\nDepending on what references you use, when $P^{gp}$ is torsion-free, $P$ is called either integral or toric. (See, e.g., the toric variety notes on M. Mustata's webpage versus the log geometry notes on Danny Gillam's webpage; both sources are worth looking at.) It seems the latter terminology is more standard in the log geometry world, where \"integral\" sometimes just means \"cancellative\".\n\nshare|improve this answer\nThere is an extension of toric geometry which starts with a fan in an abelian group which is not assumed to be torsion free. Then one obtains a toric stack. \u2013\u00a0 Sasha Nov 18 '10 at 5:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/38539/are-there-other-algebra-structures-on-the-regular-representation-of-a-group\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a (discrete, say) group and $\\mathbb K$ a field. The regular representation $G^{\\mathbb K}$ is the vector space of all functions $G \\to \\mathbb K$. It is a (left, say) $G$-module: given $g\\in G$ and $f: G \\to \\mathbb K$, the action is $g\\cdot f: x \\mapsto f(xg)$. Then $G^{\\mathbb K}$ is a commutative algebra object in $G\\text{-rep}_{\\mathbb K}$, the symmetric monoidal category of $\\mathbb K$-valued $G$-representations, under pointwise multiplication $f_1f_2: x \\to f_1(x)f_2(x)$.\n\nBut the pointwise product is not necessarily the only commutative algebra (in $G\\text{-rep}$) structure that can be put on $G^{\\mathbb K}$. For example, when $\\mathbb K = \\mathbb R$ and $G = \\mathbb Z/2$, as an algebra $G^{\\mathbb K} \\cong \\mathbb R[\\epsilon]/(\\epsilon^2 = 1)$, with the $G$-action corresponding to conjugation $\\epsilon \\mapsto -\\epsilon$. The same $G$-module supports the algebra structure $\\mathbb R[\\epsilon]/(\\epsilon^2 = -1) = \\mathbb C$, which is patently a different algebra.\n\nMy question is whether there are any examples with $\\mathbb K = \\mathbb C$? I.e.:\n\nDoes there exist a group $G$ so that there is a commutative algebra object in $G\\text{-rep}_{\\mathbb C}$ that is isomorphic to $G^{\\mathbb C}$ as a representation but not as an algebra?\n\nI believe that any such group must be rather large: in particular, I'm sure that it cannot be finite.\n\nshare|improve this question\nI will mention an idea in the comments, since I'm very unsure of its correctness. Take G=PGL(2,C) and forget its algebraic structure: think of it just as a discrete group. It acts on the field C(x) as automorphisms, and the invariant subspace of C(x) is just C. So G^C and C(x) have the same dimension and the same invariant subspace, and that's almost a proof that they're the same representation. Unfortunately, math isn't that easy, and I don't see how to really get my hands on either representation. \u2013\u00a0 Theo Johnson-Freyd Sep 13 '10 at 6:13\nSilly/stupid question: when you say ``${\\mathbb K}$-valued representation of $G$'', do you mean a repn of G as endomorphisms of some ${\\mathbb K}$-vector space? I also don't follow what it means for $G^{\\mathbb K}$ to be an algebra object in the category $G-{\\rm rep}_{\\mathbb K}$. \u2013\u00a0 Yemon Choi Sep 13 '10 at 6:36\nYemon, yes to the first question; \"algebra object etc\" simply means that the multiplication map on functions is $G$-equivariant (well, the same for scalar multiplication, but that is automatic). You can also call it a \"commutative $G$-algebra\", which is fairly standard. However, the correct notion of isomorphism should take both structures into account (in particular, $A$ and $B$ may two $G$-algebras that are isomorphic as algebras and as $G$-modules, but not as $G$-algebras); this question is about a stronger property of being non-isomorphic as algebras only. \u2013\u00a0 Victor Protsak Sep 13 '10 at 7:18\nAren't $A=\\mathbb{C}[x]/(x^n)$ and $B=\\mathbb{C}[x]/(x^n-1)\\cong\\mathbb{C}^G$ two commutative $G$-algebras isomorphic to the regular representation of $G=\\mathbb{Z}_n$ but non-isomorphic as algebras (e.g. because $A$ is not semisimple)? In both cases, the standard generator of $G$ acts on $x$ as the multiplication by the fixed primitive $n$th root of unity. \u2013\u00a0 Victor Protsak Sep 13 '10 at 7:28\nI think your exponential notation is at odds with standard convention: $G^{\\mathbb{K}}$ usually means maps from $\\mathbb{K}$ to $G$, and you want the opposite. \u2013\u00a0 S. Carnahan Sep 13 '10 at 7:56\nshow 2 more comments\n\n1 Answer\n\nup vote 6 down vote accepted\n\nSummary Yes, there are many such examples, even for finite groups.\n\nConstruction Let $W<GL(V)$ be a complex reflection group, $A=\\mathbb{C}[V]$ be the algebra of polynomial functions on $V$ and $A^W$ be the subalgebra of $W$-invariants. Then by the Chevalley\u2013Shephard\u2013Todd theorem, $A^W$ is a polynomial algebra and $A$ is a free $A^W$-module. This may be viewed as a deformation of $\\mathbb{C}^W$ as follows. For any $z\\in\\text{Spec}A^W,$ consider the fiber $A_z=A/zA.$ By the freeness property, each $A_z$ carries the regular representation of $W.$ For a regular $z,$ corresponding to a $W$-orbit of a regular point in $V,$ the algebra $A_z$ may be identified with the algebra of functions on the orbit, which consists of $|W|$ points; in particular, $A_z\\cong \\mathbb{C}^W$ as a $W$-algebra. But for values of $z$ corresponding to singular orbits, algebras $A_z$ are not reduced. The most singular fiber is $A_0=\\mathbb{C}[V]/(\\mathbb{C}[V]^W_{+})$ and is a graded nilpotent Frobenius algebra, with one-dimensional socle and radical, called the covariant algebra of $W.$\n\nExample Let $W=\\mathbb{Z}_n$ acting on the one-dimensional vector space with coordinate $x$ by the $n$th roots of unity. Then regular fibers $\\mathbb{C}[x]/(x^n-a)$ with $a\\ne 0$ are semisimple and isomorphic to $\\mathbb{C}^{\\mathbb{Z}_n}$ (explicitly, $x$ is mapped to $b\\sum_k \\zeta^{-k}\\delta_k,$ where $b^n=a$), whereas the singular fiber $\\mathbb{C}[x]/(x^n)$ is a graded nilpotent algebra.\n\nshare|improve this answer\nThe case $n=2$ is by itself rather instructive. One only has the choice of specifying multiplication on the sign representation summand, and asking whether the map $sign \\otimes sign \\to triv$ is the zero map or an isomorphism. \u2013\u00a0 S. Carnahan Sep 13 '10 at 9:32\nI'm slightly ashamed of myself for not thinking of this when I first read the question. \u2013\u00a0 Ben Webster Sep 13 '10 at 22:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96268/square-roots-of-the-laplace-operator/96355\nText:\nTake the 2-minute tour \u00d7\n\nIn several places in the literature (e.g. this paper of Caffarelli and Silvestre), I've seen an integral formula for fractional Laplacians. I'd like to understand it. In this question, I'll stick to the case of the square root.\n\nThe formula I've seen is this: $$((-\\triangle)^{1/2}f)(x)= C_n \\int_{\\mathbb{R}^n}\\frac{f(x) - f(y)}{\\|x - y\\|^{n + 1}}\\ dy. $$ Here $x \\in \\mathbb{R}^n$ and $C_n$ is a constant. Also, $f$ is a function $\\mathbb{R}^n \\to \\mathbb{R}$, but I'm not sure what regularity assumptions it's supposed to satisfy.\n\nFor this notation to be justified, it must surely be the case that $$ (-\\triangle)^{1/2} \\bigl((-\\triangle)^{1/2} f\\bigr) = -\\triangle f $$ for all nice enough $f$. My question is: why? I haven't been able to prove this identity even in the case $n = 1$.\n\n\n  1. It's clearly the case that the Laplace operator has a square root defined by $$ \\widehat{((-\\triangle)^{1/2}f)}(\\xi) = \\|\\xi\\| \\hat{f}(\\xi). $$ The paper linked to says that this operator $(-\\triangle)^{1/2}$ is the same as the operator $E$ defined by the integral formula. If I'm understanding correctly, proving this is equivalent to proving (i) that $E$ really is a square root of the Laplacian, and (ii) that $E$ is a positive operator on functions of compact support.\n\n  2. I've seen a couple of references to Landkof's 1972 book Foundations of Modern Potential Theory. Unfortunately, those citing Landkof's book don't say which part of the book they're referring to, and I've been unable to find the relevant part myself. I'd be happy for someone to simply tell me where in that book to look.\n\n  3. I can see that the integral formula has something to do with Laplacians. Switching to spherical coordinates, the formula is $$ ((-\\triangle)^{1/2}f)(x) = \\text{const}\\cdot\\int_0^\\infty \\frac{\\int_{S^{n-1}} f(x + ru)\\ du - f(x)}{r^2}\\ dr $$ where $du$ is surface area measure on $S^{n-1}$ normalized to a probability measure. The integrand converges to $(\\triangle f)(x)$ as $r \\to 0$ (up to a constant factor). Also, the integrand is identically zero if $f$ is harmonic, which is promising.\n\nshare|improve this question\nHi Tom, A basic reference for this sort of things is the classic paper of Seeley \"Complex powers of an elliptic operator\". Since this is one of the early papers on pseudo-differential operators, I'm sure you can find something about this in a book (H\u00f4rmander or Taylor are good bets). \u2013\u00a0 alvarezpaiva May 9 '12 at 6:13\nThanks; that's very helpful. \u2013\u00a0 Tom Leinster May 11 '12 at 0:29\nadd comment\n\n6 Answers\n\nThe Fourier transform of a radially symmetric function is a radially symmetric function. Basic scaling shows that the Fourier transform of $\\|\\xi\\|$ must be $\\|x\\|^{-n-1}$ in some sense. Some care must be taken in interpreting this, since this function is not integrable. A good reference for this is Gelfand and Shilov, Generalized Functions.\n\nEdit by Tom Leinster Here I'll try to flesh out Michael's answer. Michael: please feel free to edit.\n\nWe begin by finding the Fourier transform of $\\|\\xi\\|$. A priori this doesn't make sense as $\\|\\xi\\|$ isn't integrable, but I'll proceed formally anyway, hoping that there's a world in which this is all kosher. Write $g(\\xi) = \\|\\xi\\|$ and $g_a(\\xi) = g(a\\xi)$ (for $a > 0$). For completely general reasons, $$ \\widehat{g_a}(x) = a^{-n} \\hat{g}(x/a). $$ Also, for this particular $g$ we have $g_a = a g$, so $\\widehat{g_a} = a\\hat{g}$. Hence $\\hat{g}(x) = a^{-(n+1)} \\hat{g}(x/a)$, giving $$ \\hat{g}(x) = \\|x\\|^{-(n+1)} g(x/\\|x\\|). $$ On the other hand, $g$ is spherically symmetric, so $\\hat{g}$ is too; hence $\\hat{g}$ has constant value $C$ on the unit sphere. So the Fourier transform of $\\|\\xi\\|$ is $C\\|x\\|^{-(n+1)}$.\n\nNow we take the Fourier transform of each side of the equation $(\\widehat{(-\\Delta)^{1/2}}f)(\\xi) = \\|\\xi\\|\\hat{f}(\\xi)$. This gives $$ ((-\\Delta)^{1/2}f)(x) = C\\|x\\|^{-(n+1)} * f = C\\int_{\\mathbb{R}^n} \\frac{f(y)}{\\|x-y\\|^{n+1}} \\ dy. $$ That seems good, but now I have three problems. First, this isn't the integral formula I was looking for. (Maybe I'm missing a simple trick.) Second, I don't know the value of $C$. Third, I don't know how to make this all rigorous: what are some sufficient conditions on $f$ guaranteeing that $(-\\Delta)^{1/2}\\bigl((-\\Delta)^{1/2}f\\bigr)$ is defined (in the sense of the integrals existing) and equal to $f$?\n\nEdit by Michael Renardy:\n\nThe problem is that $\\|x\\|^{-n-1}$ is not integrable at zero. Therefore it needs to be replaced by a regularization. The theory of such regularizations is developed in detail in Section 3 of Chapter I in Gelfand and Shilov.\n\nshare|improve this answer\nThanks for the answer, Michael. I'd been slightly frustrated at people citing Landkof's book of 400+ pages without saying which part of it they were referring to. But you've gone one better, by citing a three-volume collection without saying which part of it you're referring to :-) \u2013\u00a0 Tom Leinster May 7 '12 at 23:19\nMore seriously, could you elaborate? I think I see what you mean and can guess what strategy you have in mind, but when I carry it out, it leads me to an integral formula different from the one above. \u2013\u00a0 Tom Leinster May 7 '12 at 23:46\nI'll provide chapter numbers after I get to my office where I can look it up. But it will be the morning before that happens. If you can look at the table of contents before that, good for you! \u2013\u00a0 Michael Renardy May 7 '12 at 23:53\nGreat, thanks. I have it on my shelf, but I don't really know what I'm looking for. \u2013\u00a0 Tom Leinster May 7 '12 at 23:55\nThe relevant sections are Chapter I, Section 3.9 and Chapter II, Section 3.3 in Volume I. \u2013\u00a0 Michael Renardy May 8 '12 at 13:03\nshow 1 more comment\n\nA very nice way to see all of this is to look start with the Poisson semi-group $f \\mapsto e^{-t\\sqrt{-\\Delta}}f$ for $t>0$. These operators are defined by Fourier Transform as $$\\widehat{e^{-t\\sqrt{-\\Delta}}f}(p)=e^{-t|p|}\\widehat{f}(p),$$ for any function $f$ so that the right hand side makes sense. Then for $f$, say in $ L^1$, we have $$e^{-t\\sqrt{-\\Delta}}f(x)=\\int_{\\mathbb{R}^n} P_t(x-y)f(y) dy$$ where $P_t(x)$ is the Poisson kernel $$P_t(x)=\\frac{1}{(2\\pi)^n} \\int_{\\mathbb{R}^n} e^{ix\\cdot p} e^{-t|p|} dp = C_n \\frac{t}{(t^2 +|x|^2)^\\frac{n+1}{2}}. $$ (The computation of $P_t(x)$ is carried out in the first chapter of Stein and Weiss, Fourier Analysis on Euclidean Spaces.) The formula for $\\sqrt{-\\Delta}$ follows by taking the limit $$\\sqrt{-\\Delta}f = \\lim_{t\\downarrow 0} \\frac{f- e^{-t\\sqrt{-\\Delta}}f}{t}$$ whenever this limit exists in a suitable sense. Because $\\int P_t(x)dx=1$ we have $$\\frac{1}{t} \\left (f(x)-e^{-t\\sqrt{-\\Delta}}f(x) \\right ) = C_n \\int_{\\mathbb{R}^n} \\frac{f(x)-f(y)}{(t^2 +|x-y|^2)^{\\frac{n+1}{2}}}dy.$$ Your identity now follows whenever $f$ is smooth enough and decays fast enough for the integral to make sense.\n\nshare|improve this answer\nThanks; that's very helpful. \u2013\u00a0 Tom Leinster May 11 '12 at 0:27\nadd comment\n\nSo you believe expression (1)? Have you tried taking the inverse Fourier transform of the right side of this expression? This will give you the convolution of f with the inverse Fourier transform of $|\\xi|$, at least morally speaking. The inverse Fourier transform of $|\\xi|^{\\alpha}$ can be made sense of.\n\nWhen $n=1$, for example, and $-1<\\alpha<0$, this is relatively easy to compute directly, and is something like $C_\\alpha |x|^{-\\alpha-1}$. This kind of computation would probably be done in a textbook in a section like 'tempered distributions'. You can see that that $\\alpha=1$ doesn't fit into this range, which is clear since the formulas wouldn't match up in such a case. But if one naively input this value, we'd get a convolution with $|x|^{-2}$, which is nice. So you clearly should be guessing that the inverse Fourier transform of $|\\xi|$ is convolution with $|x|^{-2}$ plus a delta function, modulo constants.\n\nThis can be made rigorous, but the computation involves knowing some stuff about distributions. Try looking up 'homogeneous distribution'. I think actually with the information on the wikipedia pages for Fourier transform and homogeneous distribution, you should be able to do the computation. This older mathoverflow question might also be helpful: The fourier transform of homogeneous distribution and related topics\n\nshare|improve this answer\nThanks, Peter. My edit to Michael's answer shows my attempt to do what you're suggesting in your first paragraph. I'll go and look up homogeneous distributions. I learned about tempered distributions and their Fourier transforms from Friedlander and Joshi's text, but the treatment there is quite concise. \u2013\u00a0 Tom Leinster May 8 '12 at 14:42\nYes, much of this stuff is fairly disjointed, as I recall, which is unfortunate. Many of the basic computations are not terribly difficult (just tricky), so I think they are not written down in many places. The issue you are having in the computation in your comment comes from having to use some analytic continuation technique to extend the range of possible $\\alpha$s in the inverse transform of $|\\xi|^\\alpha$. $|x|^{-n-1}$ is not locally integrable, as Tom pointed out, so its a bit more delicate. \u2013\u00a0 Peter Luthy May 8 '12 at 15:05\nNow that I think about it, the analytic continuation might need some additional work... there might be some poles at certain integers $\\alpha$, so you would need to add an additional term to balance things out. This computation has to be written down someplace. Sorry that I don't know of a good place. \u2013\u00a0 Peter Luthy May 8 '12 at 16:12\nadd comment\n\nDenote integral operator as follows:$$Lu=P.V.\\int_{\\mathbb{R}^n}\\frac{u(x) - u(y)}{\\|x - y\\|^{n + 1}}\\ dy$$.when $u\\in \\varphi$.It can also been writen as(after changing variable y to -y and then taking average)a more symmetric form $$Lu=\\int_{\\mathbb{R}^n}\\frac{u(x+y) +u(x-y)- 2u(x)}{\\|y\\|^{n + 1}}\\ dy$$.Thus the sigularity can be cancelled. We are looking for its symbol (or multipler),that is $$\\mathcal {F}(Lu)(\\xi)=m(\\xi)\\mathcal {F}u$$and we want to prove that m(\\xi) is exactly $c_{n}|\\xi|$,where $c_{n}$ is a constant determinated later which is the answer of the second question of Tom Leinster. First for $u\\in \\varphi$,we have $\\frac{u(x+y) +u(x-y)- 2u(x)}{\\|x - y\\|^{n + 1}}\\in L^{1}{\\mathbb{R}^n}$.By fubini theorem(we exchange the integral in y with fourier transform in x),we obtain $$\\mathcal {F}(Lu)=\\int_{\\mathbb{R}^n}\\frac{\\mathcal {F}(u(x+y) +u(x-y)- 2u(x))}{\\| y\\|^{n + 1}}\\ dy.= \\int_{\\mathbb{R}^n}\\frac{e^{i\\xi\\cdot y}+e^{-i\\xi \\cdot y}-2}{\\|y\\|^{n + 1}}\\ dy \\mathcal {F}(u)$$ hence,in order to get the desired result,it suffices to show that $\\int_{\\mathbb{R}^n}\\frac{e^{i\\xi y}+e^{-i\\xi y}-2}{\\|y\\|^{n + 1}}\\ dy=c_{n}|\\xi|$. Define $$I(\\xi)=\\int_{\\mathbb{R}^n}\\frac{1-cos(y \\xi)}{\\|y\\|^{n + 1}}\\ dy$$.Since $I(\\xi)$ is rotatonally invariant.so $I(\\xi)=I(|\\xi|e_{1})$ where $e_{1}$ denotes the first direction vector.So $$I(\\xi)=I(|\\xi|e_{1})=|\\xi|\\int\\frac{1-cos(z_{1})}{\\|z\\|^{n + 1}}dz$$.so we take $c_{n}=\\int\\frac{1-cos(z_{1})}{\\|z\\|^{n + 1}}\\ dz$.And we have $(-\\triangle)^{1/2}=\\frac{1}{c_{n}}L$ as desired.\n\nshare|improve this answer\nit's really nice to start from the poisson semigroup,but the mathod pressented here is applied for any $0<\\alpha<1$ with $(-\\triangle)^{\\alpha}$ \u2013\u00a0 user23078 May 8 '12 at 23:17\nGood job. Your answer also clarifies the meaning of the original integral, which of course does not converge as a Lebesgue integral but only if interpreted as a singular integral or a principal value. \u2013\u00a0 Piero D'Ancona May 9 '12 at 8:17\nThanks very much! \u2013\u00a0 Tom Leinster May 11 '12 at 0:26\nadd comment\n\nThis answer is a modified version of Tom's edit on Michael's answer just to make it a bit more rigorous.\n\nTake $b(\\xi)$ to be a smooth non negative radially symmetric function supported in $1< |\\xi| <2$. Then we see that $|\\xi|^\\alpha = c \\int_0^\\infty t^{\\alpha-1} b(\\xi/t) dt$.\n\nNow, let us say $b$ is the fourier transform of some kernel $k$, which will also be smooth, radially symmetric, and its integral is zero because $b(0)=0$. Then $b \\cdot \\hat u = \\widehat{k \\ast u}$. Moreoever, since k has integral zero and is symmetric $$ b \\cdot \\hat u = \\left(\\int k(y) (u(x+y)-u(x)) dy\\right)^\\wedge. $$\n\nLet us assume that $\\alpha \\in (0,2)$.\n\nI want to use the identity above for $|\\xi|^\\alpha$ as an integral of scaled versions of $b$. For that recall that $b(\\cdot/t)^\\\\wedge = t k(t\\cdot)$. So, we have $$ |\\xi|^\\alpha \\cdot \\hat u = \\left( c \\int_0^\\infty t^{\\alpha-1} \\int t k(ty) (u(x+y)-u(x)) \\ dy dt \\right)^\\wedge$$ Exchanging the order of integration we have that $$ |\\xi|^\\alpha \\cdot \\hat u = \\left( \\int (u(x+y)-u(x)) K(y) dy \\right)^\\wedge$$ for $$ K(y) = c \\int_0^\\infty t^{\\alpha} k(ty) dt = c_0 |y|^{-n-\\alpha}.$$ The last identity is obtained from the change of variables $s = t|y|$.\n\nThere are still a few things that should be clarified, like the application of Fubini, and that the integrals may be principal values when $\\alpha \\geq 1$. But everything should be fine if $u$ is smooth enough.\n\nshare|improve this answer\nadd comment\n\nPerhaps you could see what the right-hand-side evaluates to for the eigen-functions of the Laplacian (I don't know what they are offhand but I would guess that the eigenbasis for the Laplacian on L^2(R) is well known). You should get that the eigen-functions are still eigen-functions of the right-hand-side but with each of the eigen-values raised to the 1/2 power.\n\nAlso, your question leads me to a question of my own: From the probabilistic perspective, the right-hand-side integral operator is associated to a Markov jump process. So this statement seems to imply that in some way \"The square of a jump process gives a true diffusion\" or maybe \"if you jump and jump again you get a true diffusion\". I am wondering if anyone knows anymore on this line of thought or a reference where it is made precise?\n\nshare|improve this answer\nThat is it: there are no eigenfunctions here unfortunately. And you should ask your question separately, it will not be noticed here. \u2013\u00a0 Andr\u00e1s B\u00e1tkai May 8 '12 at 20:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232989/finding-radius-of-convergence-for-power-series\nText:\nTake the 2-minute tour \u00d7\n\nFind the radius of convergence of the given power series:\n\n$$\\sum _{n=0}^{ \\infty} \\frac{8n!x^n}{2^n}$$\n\nAfter taking the limits as n-> $\\infty$, I get $\\frac{8x}{2}$, and Radius of convergence is R = 2. Is this correct?\n\nshare|improve this question\nThis is a very standard, very straightforward problem; what have you tried? \u2013\u00a0 Brian M. Scott Nov 8 '12 at 16:59\nUse the Ratio Test. Informally, the problem is that $n!$ grows hugely fast. \u2013\u00a0 Andr\u00e9 Nicolas Nov 8 '12 at 17:01\nTry by using the ratio test \u2013\u00a0 M. Strochyk Nov 8 '12 at 17:02\n@everyone except the OP: meta.math.stackexchange.com/a/2179/7850 \u2013\u00a0 The Chaz 2.0 Nov 8 '12 at 17:40\nshow 1 more comment\n\n2 Answers\n\nup vote 0 down vote accepted\n\nUsing the Ratio Test, it looks like we get $R=0$.\n\n$$\\left|a_{n+1}\\over a_{n}\\right| = \\left| \\frac{8(n+1)! \\cdot x^{n+1} \\cdot 2^n}{2^{n+1} \\cdot 8n! \\cdot x^n} \\right| = \\left| \\frac{8(n+1)n! \\cdot x \\cdot x^n \\cdot 2^n}{2\\cdot 2^n \\cdot 8n! \\cdot x^n} \\right|$$\n\n$$=\\frac{\\left|x\\right|} {2} \\lim_{n\\to\\infty} (n+1) \\to \\infty \\ \\ \\forall x \\ne 0\\implies R=0$$\n\nThus, the power series only converges when $x=c$, which is at $x=0$ here.\n\nshare|improve this answer\nadd comment\n\nThis can help you solve this problem.\n\nThe answer is:\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/133781/finite-generation-and-henselization\nText:\nTake the 2-minute tour \u00d7\n\nNow I understand the answers.\n\nI am trying to understand Henselian Weierstrass Theorem in Hironaka's Idealistic exponents of singularity, page 76 - 77. A glance at the paper.\n\nAt some point there is a ring $R$, which is Noetherian, Henselian, and local, with maximal ideal $m$. A module $A$ such that\n\n  1. $\\frac{A}{mA}$ is finitely generated over $\\frac{R}{m}$.\n\n  2. $A$ is finitely generated over the Henselization $S$ of $R[z]$ with respect to $(m,z)$.\n\nAnd then he concludes, 'thanks to Hensel's lemma', that\n\n(3). $A$ is finitely generated over $R$.\n\nI don't understand how that works. It should be something standard/simple since it is stated just like that, but I don't see it. Could you explain how the argument goes?\n\nPS: If you are looking at the paper, the notation used is:\n\n  \u2022 $R$ is what in the paper is called $R_{j+1}$,\n  \u2022 $A$ is what in the paper is $G_j$,\n  \u2022 $m$ is $M_{j+1}$,\n  \u2022 $z$ is $z_{j+1}$,\n  \u2022 and $S$ is what in the paper is called $R_{j}$.\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\n(Note: There is no new content in this answer; it is simply an explanation of parts of user's excellent response. I'm writing it as an answer, because that seems less perverse than splitting it across many comments.)\n\nThe key result that is being used here is the following consequence of Zariski's Main Theorem + Hensel's lemma: Suppose that $f:A\\to B$ is a map of finite type (between noetherian rings), with $A$ local henselian. Suppose that $\\mathfrak{n}\\subset B$ is a prime above $\\mathfrak{m}$ such that the localization $B_{\\mathfrak{n}}$ is quasi-finite over $A$ at the closed point (i.e. $B_{\\mathfrak{n}}/\\mathfrak{m}B_{\\mathfrak{n}}$ is finite over the field $A/\\mathfrak{m}$). Then $B_{\\mathfrak{n}}$ is finite over $A$, and is in particular itself henselian local.\n\nHere, Zariski's Main Theorem is (or can be) used in the following incarnation (see Raynaud, 'Anneaux locaux henseliens', p. 42): Let $f:A\\to B$ be as in our hypotheses in the first paragraph (but don't assume that $A$ is henselian). Let $B'$ be the integral closure of $A$ in $B$ (note that $B'$ is automatically finite over $A$); then there exists $f\\in B'$, $f\\notin \\mathfrak{n}$ such that $B'_f=B_f$. In other words, $\\text{Spec }B\\to\\text{Spec }B'$ is an open immersion in a neighborhood of $\\mathfrak{n}$. Therefore, there exists a prime $\\mathfrak{n}'\\subset B'$ such that $B'_{\\mathfrak{n}'}=B_{\\mathfrak{n}}$. So, replacing $B,\\mathfrak{n}$ by $B',\\mathfrak{n}'$, we can assume that $B$ is finite over $A$.\n\nIf we now assume that $A$ is in addition henselian, then Hensel's lemma implies that $B$ is a product $B=\\prod_{i=1}^rB_{\\mathfrak{n}_i}$, where $\\mathfrak{n}_i$ ranges over all the primes of $B$ that lie over $\\mathfrak{m}$; see for example p. 2 of Raynaud's book. This immediately implies that $B_{\\mathfrak{n}}$ is finite over $A$.\n\nLet's see why this implies Hironaka's claim. As in user's answer, let $S/I$ be the quotient of $S$ that acts faithfully on the $R$-module $A$. As observed already in the answer, the map $R\\to S/I$ is quasi-finite at the closed point; also, $S/I$ is the henselization of the localization of an $R$-algebra $B$ of finite type at a prime $\\mathfrak{n}\\subset B$ (this is the point where you use the fact that $I$ is finitely generated; $B$ is what user denotes as $S'/I'$). Now, we can apply the result from the first paragraph to conclude that $B_{\\mathfrak{n}}$ is finite over $R$ and is therefore itself henselian. This implies that $S/I=B_{\\mathfrak{n}}$, which shows that $S/I$ (and hence $A$) is finite over $R$.\n\nshare|improve this answer\nMaybe no new content, but less names that are defined in terms of names, defined in terms of other names, some of which I couldn't find their translation (definition). I think I will be able to understand now. I recognize the language here. Thank you. \u2013\u00a0 ABC Jul 17 '13 at 23:07\nUnfortunately I got stuck in the part before your explanation. When they say that the support of $A/mA$ over $S/mS$ is $k$-finite because $A/mA$ is finitely generated over $R/m$. Why is that? This support is $\\text{Spec}(\\frac{S}{mS+I})$. I am assuming being $k$-finite means $\\frac{S}{mS+I}$ is finitely generated over $R/m$. So, why $A/mA$ finitely generated over $R/m$ implies $\\frac{S}{mS+I}$ finitely generated over $R/m$? \u2013\u00a0 ABC Jul 18 '13 at 19:48\nThis follows from: Let $A\\to B$ be a map of commutative Noetherian rings and let $M$ be a faithful, finitely generated $B$-module. Then $B$ is a finitely generated as an $A$-module if and only it $M$ is. For the non-trivial direction, note that $B$ embeds in the $A$-module $End_A(M)$, and use Noetherianness. \u2013\u00a0 Keerthi Madapusi Pera Jul 18 '13 at 22:07\nadd comment\n\nYou probably meant to assume $R$ is noetherian. And Hironaka seems to have suppressed his appeal to Zariski's Main Theorem, as we'll see below (or maybe someone else sees a more elementary procedure, which is certainly possible).\n\nConsider the schematic support ${\\rm{Spec}}(S/I)$ of the $S$-finite $A$ in ${\\rm{Spec}}(S)$ (here, $I$ is the annihilator ideal of $A$ in $S$). Its special fiber over ${\\rm{Spec}}(R)$ has underlying reduced scheme that coincides with that of the schematic support of $A/mA$ over $S/mS$, and this latter schematic support is $k$-finite (with $k := R/m$) since $A/mA$ is $k$-finite. Thus, $S/I$ has $k$-finite special fiber over $R$ since such finiteness is insensitive to killing nilpotents.\n\nSince $R$ is noetherian, so $I$ is finitely generated, there is a residually trivial etale neighborhood $({\\rm{Spec}}(R'),\\xi)$ of $(m,z) \\in {\\rm{Spec}}(R[z])$ such that $I$ has a finite set of generators coming from $R'$ (via the unique map $R'_{\\xi}\\rightarrow S$ over $R[z]_{(m,z)}$). Letting $I'\\subset R'$ be the ideal generated by those elements of $R'$, we see that $R'/I'$ has henselization $S/I$ at $\\xi$ with $k$-finite special fiber over $R$. But henselization is compatible with quotients, so the special fiber of $R'_{\\xi}/I'$ over $R$ is an essentially finite type local $k$-algebra with $k$-finite henselization, so $R'_{\\xi}/I'$ has $k$-finite special fiber over $R$. In other words, ${\\rm{Spec}}(R'/I') \\rightarrow {\\rm{Spec}}(R)$ is quasi-finite at $\\xi$.\n\nBy openness of the quasi-finite locus of a finite type map between noetherian schemes, we can localize $R'$ around $\\xi$ so that $R'/I'$ is a quasi-finite $R$-algebra. Hence, by Zariski's Main Theorem, ${\\rm{Spec}}(R'/I')$ is Zariski-open in a finite $R$-algebra. But $R$ is henselian, so by Hensel's Lemma (in the EGA form) applied to lifting idempotents from the special fiber we know that every finite $R$-algebra is a direct product of finite local $R$-algebras. Consequently, by shrinking some more around the point $\\xi$ in the special fiber we can arrange that ${\\rm{Spec}}(R'/I')$ is Zariski-open in a finite local $R$-scheme with closed point $\\xi$, so this Zariski-open locus is the entire space. In other words, we get to the case that $R'/I'$ is $R$-finite and local. Thus, it is equal to its own henselization, which is $S/I$ by design.\n\nWe have proved that $S/I$ is $R$-finite, yet $A$ is an $S/I$-module, so $A$ s $R$-finite. QED\n\nshare|improve this answer\nYes, $R$ is Noetherian. I will add it now. Thank you for the explanation. \u2013\u00a0 ABC Jun 18 '13 at 17:52\nLet me momentarily unselect this as the answer since it is not true that I understand everything in it to be able to say by myself if it is correct or not. Now I need to unravel all the definitions of the concepts in this explanation. \u2013\u00a0 ABC Jun 18 '13 at 19:56\nAll user36938 is saying is this: Let $M$ be a finitely generated $R$-module, and let $Supp(M)\\subset\\text{Spec }R$ be the sub-set of primes such that $M_P$ (localization at $P$) is non-zero. By Nakayama's lemma, this is the same as saying that $M_P/PM_P\\neq 0$. Claim: This set is compatible with base-change in the obvious sense. That is, if $f:R\\to S$ is any map of Noetherian rings, then $Supp(S\\otimes_RM)\\subset\\text{Spec }S$ consists precisely of those primes that lie above primes in $Supp(M)$. \u2013\u00a0 Keerthi Madapusi Pera Jul 17 '13 at 1:15\nIndeed, given a prime $Q\\subset S$, we have $(S\\otimes_RM)_Q/Q(S\\otimes_RM)_Q=k(Q)\\otimes_RM=k(Q)\\otimes_{k(P)}M_P/PM_P$, where $P=f^{-1}(Q)$. Therefore, $Q\\in Supp(S\\otimes_RM)$, if and only if $P\\in Supp(M)$. The geometric interpretation is that you have a coherent sheaf over $\\text{Spec }R$ attached to $M$, and $Supp(M)$ is precisely the locus where this sheaf has non-zero fibers. If you think about the behavior of fibers under pull-back for a moment, you'll find that this assertion is not at all surprising, if not obvious. \u2013\u00a0 Keerthi Madapusi Pera Jul 17 '13 at 1:21\n@Franklin: I am glad that Keerthi came up with a formulation which is agreeable to you. But since you tell us basically nothing about your background (except that you have some difficulty translating between algebraic and geometric descriptions of certain things), it is to be expected that some may offer an answer which inadvertently does not fit with your background. I recommend learning the \"geometric\" way of thinking about these things (smoothness, henselization, Zariski's Main Theorem, etc.); it is incredibly illuminating even for purely algebraic results. Look at \"Neron Models\", Ch. 2. \u2013\u00a0 user36938 Jul 21 '13 at 15:44\nshow 6 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54364.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSum of Unit Fractions\n\nDate: 07/17/2001 at 20:28:27\nFrom: Candyce\nSubject: Java programing class\n\nSuppose that p/q is a fraction in lowest terms such that \n1/(n+1) < p/q < 1/n for some positive integer n. Show that \n(p/q) - (1/(n+1)) is a fraction which in its lowest terms has \nnumerator less than p. Hence by induction, prove that every proper \nfraction p/q with p < q can be written as a finite sum of distinct \nreciprocals of positive integers. \n\nFor example, 19/15 = 1/2 + 1/3 + 1/4 + 1/6 + 1/60. \n\nUse this technique to express 5/7 as a sum of reciprocals.\n\nThe example given here is correct, though it's not true that all \nfractions greater than 1 can be expressed finitely in this way \n(e.g. 2) - you've been asked to prove the statement only when the \nfraction is less than 1 (which is always true). If you want an \nexample for this case, then 14/17 = 1/2 + 1/4 + 1/14 + 1/476. \n\nThe problem is the PROFF part. I can understand that it works.\n\nDate: 07/18/2001 at 10:53:15\nFrom: Doctor Paul\nSubject: Re: Java programing class\n\nHere's how to do it for fractions less than one (assumed to be in \nlowest terms):\n\nI'll show you how it works for 14/17 and you should be able to \nit for any p/q.\n\nGiven 14/17, find the largest unit fraction less than 14/17. I think \nthe easiest way to do this is to systematically increment the \ndenominator by one until the fraction reduces to a unit fraction. The \nreduced unit fraction will be the largest unit fraction less than the \ngiven number. In the case of 14/17, we first consider: 14/18 = 7/9, \nwhich is not a unit fraction, so we next consider 14/19, 14/20 = 7/10, \n14/21 = 2/3, which is not a unit fraction, so we next consider 14/22, \n.... , 14/28 = 1/2.\n\nSo we know that 1/2 is a unit fraction and we know that it is less \nthan 14/17.\n\nThus we can write:\n\n  14/17 = 1/2 + a/b where a/b is to be determined.\n\nsubtract 1/2 from both sides to obtain:\n\n  a/b = 14/17 - 1/2 = 11/34\n\nThus we have:\n\n  14/17 = 1/2 + 11/34\n\nIf a/b had turned out to be a unit fraction, we would be done. But \nsince it isn't a unit fraction, we do the process again. We now want \nto convert 11/34 into a sum of unit fractions:\n\nIncrease the denominator until you get a unit fraction:\n\n  11/35, 11/36, ... , 11/44 = 1/4\n\n  so 11/34 = 1/4 + c/d\n\n\n  c/d = 11/34 - 1/4 = 5/68\n\nSo we have:\n\n  14/17 = 1/2 + 1/4 + 5/68\n\nIf c/d had been a unit fraction, we would be done. But since c/d was \nequal to 5/68, we now need to repeat the process and convert 5/68 into \na unit fraction.\n\nincrease denominators:\n\n  5/68, ..., 5/70 = 1/14\n\nso we have:\n\n  5/68 = 1/14 + e/f\n\n  e/f = 1/476\n\nSince e/f is a unit fraction, we're done.\n\nWe can now write the final result:\n\n\nwhich is exactly the answer you gave above.\n\nThis method is attributed to the British mathematician J.J. Sylvester \n\nIn general, the decomposition of a fraction into a sum of unit \nfractions is not unique. For example, 3/8 = 1/4 + 1/8 = 1/3 + 1/24.\n\nSince your subject is \"Java programming class\" I'm guessing that you \nhave to implement this algorithm in Java. Obviously, you're going to \nneed to run some sort of 'for' or 'until' loop to get this thing to \nrun properly. I've never programmed in Java, but I think it's a great \nassignment in any programming language! Good luck.\n\n- Doctor Paul, The Math Forum\nAssociated Topics:\nHigh School Calculators, Computers\nHigh School Number Theory\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/49141/galois-theory-splitting-field-of-cubic-as-a-vector-space?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to express the splitting field of a cubic equation as a vector space over the rationals. Specifically I am looking for a set of six independent vectors that span the space. If the roots are a,b, and c then I know I need to be able to express all expressions in a,b and c up to second degree: namely,\n\na, a^2\n\nb, b^2\n\nc, c^2\n\nab, bc, ca\n\na^2b, b^2c, c^2a, ab^2, bc^2, ca^2\n\nObviously there are 15 of these and they are not all independent. Given a and b, I easily get c as a linear term in a, b, and (a+b+c). Likewise c^2 is not independent of a^2 and b^2. And I find that I can generate ab etc as linear combinations of c, c^2, and abc.\n\nSo what are my six vectors? I have allowed myself 1, a, b, a^2, and b^2 ....this gives me five and I think they are all linearly independent. I'm only allowed one more and I can't get it to work. I'm inclined to try (a^2b + b^2c + c^2a) because I'm pretty sure I need it, but having done so I can't see how I generate terms like a^2b on their own.\n\nAny ideas? I'd be especially interesteds if there is a basis which is more symmetric in some sense than the arbitrary collection of terms which I'm cobbling together.\n\nshare|improve this question\nA cubic extension has degree $3$, not degree $6$. Or do you mean the splitting field of a cubic? In that case, it depends on the Galois group of the cubic. \u2013\u00a0 Qiaochu Yuan Jul 3 '11 at 5:01\nHave you tried a Gr\u00f6bner basis algorithm (Buchberger?) on the obvious set of generators? Also, is it immediately clear that you don't need to worry about monomials like $a^2b^2$? \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 5:25\n@qiaochu Although English is my first language, I am very weak on the terminology in this subject. Yes, I think I meant the splitting field of the cubic; and I know that some cubics have a different Galois group, but I meant the most general case of S3. \u2013\u00a0 Marty Green Jul 3 '11 at 5:45\n@Jyrki I don't know anything about the methods you refered to; but yes, I forgot about terms like a^2b^2 when I posted my question. In fact, I get them the same way I got terms like ab; since a^2b^2c^2 is an integer, I divide by c^2 which is the same as multiplying by a linear term in c. I think. \u2013\u00a0 Marty Green Jul 3 '11 at 5:48\n@Marty: Sorry about bringing up Gr\u00f6bner here. Too heavy a tool for this job. \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 8:17\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nThe simplest basis I can think of consists of monomials $\\mathcal{B}=\\{1,a,a^2,b,ab,a^2b\\}$. One way to see this goes as follows. Let's first write $$ P(x)=(x-a)(x-b)(x-c)=x^3-s_1x^2+s_2x-s_3, $$ with the elementary symmetric polynomials $s_1=a+b+c$, $s_2=ab+bc+ac$ and $s_3=abc$. If $K$ is your base field, I claim that all the monomials $a^ib^jc^k$ can be written as linear combinations of monomials from the set $\\mathcal{B}$ with coefficients from the field $L=K(s_1,s_2,s_3)$ (in your case surely $s_1,s_2,s_3\\in K$, so the combinations are really $K$-linear).\n\nThe first and most obvious thing is to replace everywhere $c$ with $s_1-a-b$. After that we only need to take care of monomials $a^ib^j$. The quantities $a$ and $b$ are zeros of $P(x)$, so we know how to replace $a^i, i\\ge 3$ and $b^j, j\\ge3$ with lower powers. So we are left with the 9 monomials $\\mathcal{B}\\cup\\{b^2,ab^2,a^2b^2\\}$. Substituting $c=s_1-a-b$ to the equation $ab+ac+bc-s_2=0$ gives us a relation $$ b^2=ab+a(s_1-a-b)+b(s_1-a)-s_2 $$ that allows us to write $b^2$ as an $L$-linear combination of $a^2,ab,a,b$ and $1$. When we do this substitution to a monomial like $ab^2$ or $a^2b^2$ we introduce higher powers of $a$. But we can reduce these to lower powers of $a$ as before. It may feel like $s_3$ wasn't really used, but it did make an appearance, when we reduced the higher powers of $a$ and $b$.\n\nshare|improve this answer\nNicely done, and very well explained. Thanks. \u2013\u00a0 Marty Green Jul 3 '11 at 12:23\nIn retrospect the basis is obvious given that this is the usual way of getting a basis for a tower of field extensions. $L(a)/L$ has a basis $\\{1,a,a^2\\}$ and $L(a,b)/L(a)$ a basis $\\{1,b\\}$. A basis for $L(a,b)/L$ is gotten by including all the products of elements of the two bases. \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 18:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/124556/signing-a-strongly-regular-graph/124705\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be the adjacency matrix of a strongly regular graph. When is it possible to sign $A$ (i.e. replace some of the +1 entries by -1) so that the resulting matrix has exactly two eigenvalues?\n\nI know of one interesting case where this is possible. Namely, define a graph $G$ where $V(G)$ is the set of 120 lines in ${\\mathbb R}^8$ given by the $E_8$ root system, and two vertices are adjacent if these lines make an angle of $\\pi/3$. This graph is strongly regular with parameters $(120, 56, 28, 24)$. To sign it, choose one vector in $E_8$ from each of these lines, and let $B$ be the associated Gram matrix. Then $C = B - 2I$ is a signing of the adjacency matrix of $G$ with just two eigenvalues ($-2$ and $28$).\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nSuppose we have a set of unit vectors $x_1,\\ldots,x_m$ in $\\mathbb{R}^d$ such that (for $i=j$) either $x_i^Tx_j=0$ or $|x_i^Tx_j|=a$. The Gram matrix of these vectors can be written as $I+aS$, where $S$ is symmetric, has zero diagonal, and entries in $\\{0,\\pm\\}$. So we have a signed graph. (Hi Tom.) Replacing $x_i$ by $-x_i$ for some $i$'s does not change anything of interest, we're really dealing with sets of lines.\n\nBy results of Delsarte, Goethals and Seidel \"Spherical Codes and designs\" we know that $m\\le \\binom{n+2}3$. They mention two examples where this bound is tight: $d=8$ as in your question and 2300 lines when $d=23$. It's likely that these are the only known examples where the bound is tight. I think DGS supply enough theory to show that the underlying graph will be strongly regular in this case.\n\nDGS also derive a bound $$ m \\le \\frac{d(d+2)(1-a^2)}{3-(d+2)a^2}. $$ I'd expect that sets of lines meeting these bounds will give strongly regular graphs (but I could not see exactly what I needed in a quick skim and my coffee break is coming to an end).\n\nForgive me if you knew all this and were really fishing for more examples.\n\nEdit: Let $H$ be an $n\\times n$ Hadamard matrix and let $A$ be given by $$ A =\\begin{pmatrix}0&H^T\\\\\\ H&0\\end{pmatrix} $$ Then $A^2=nI$ and $A$ is a signing of the complete bipartite graph. These examples may appear a bit trivial, but there are a lot of them. More generally any antipodal distance-regular graph with diameter four (and antipodal fibres of size two) will give rise to examples. Unfortunately this will only produce three further examples, and the margin is too small to deal with these.\n\nEdit2: The fact equality in the given bound implies that the graph on the lines is strongly regular appears as (part of) Proposition 3.12 in the paper by Calderbank, Cameron, Kantor and Seidel on Kerdock codes over $\\mathbb{Z}_4$. They also prove that equality in the bound imples that the signed adjacency matrix has exactly to eigenvalues.\n\nshare|improve this answer\nI am aware of the construction using lines which are all either pairwise orthogonal or at a given angle. If you have n lines spanning a d dimensional space with n > d, then the resulting matrix you construct will have smallest eigenvalue of multiplicity n-d. However, I don't understand anything about the interaction between the geometry of these lines and the behaviour of any other eigenvalues. I didn't have any secret agenda here, but I am certainly delighted to learn of this result from Delsarte Goethals and Seidel, and of another magic configuration. Thanks!! \u2013\u00a0 mdevos Mar 20 '13 at 4:38\nadd comment\n\nHere are a few ideas on places to look for examples. You may not find (m)any this way.\n\nFirst to eliminate a trivial case: For some people a complete graph or disjoint union of isomorphic complete graphs is a SRG. These only have two eigenvalues even without making any changes.\n\nA SRG need not have any automorphisms but many do. This allows an easier complete search of very small cases. In a very modest search I found one legit example and a few questionable ones. Then it seems reasonable to look for ways to sign the matrix and preserve a large subgroup of the automorphism group (but I did not get anything from that.)\n\nEssentially we are taking a graph with $e$ edges, viewing it as having $2e$ directed edges, and then giving some of them a weight of $-1$.\n\nA 4-cycle has 4 edges or $8$ directed edges (aka $+1$ entries of the Adjacency matrix $A$)\n\n  \u2022 Changing a single $1$ to $-1$ does not work.\n  \u2022 There are $28$ ways to choose two entries, but only $6$ up to action of the Dihedral group. Changing two entries , both from the same edge, gives eigenvalues $\\pm\\sqrt{2}$ twice each. (That is my sole good example so enjoy it). There are also three ways to change two entries to $-1$ and get all eigenvalues $0$: the two edges leaving a vertex, the two going into a vertex, and two parallel directed edges.\n  \u2022 there are no successful ways to change three entries.\n  \u2022 There are $\\binom84=70$ ways to choose $4$ entries to change but only $13$ up to isomorphism (maybe less but at worst I looked at some cases twice.) Four of them give all eigenvalues $0.$\n\nNote that with two eigenvalues $\\theta_1,\\theta_2$ taken $k$ and $n-k$ times we need $\\frac{\\theta_1}{\\theta2}=-\\frac{n-k}{k}$ unless it is actually a single eigenvalue of $0$.\n\n  \u2022 A pentagon amounts to $10$ directed edges, There is no way to change some of the entries of $A$ to $-1$ and get only two eigenvalues. There are $\\binom{10}{5}=252$ ways to change $5$ of them but only $26$ up to isomorphism.\n\n  \u2022 The complete bipartite graph has $18$ directed edges. Nothing works there. There would be $\\binom{18}{9}=24310$ ways to change half the edges but only $681$ up to isomorphism.\n\nI'd hoped to find an example which generalized. I did not give up after two tries but did after three. Maybe someone else will find something by looking a bit harder. Perhaps $K_{2,2,2}$ , $K_{4,4}$, or some other small case.\n\nI also looked, without results at a few ways to weight the $2 \\cdot 15=30$ directed edges from a Peterson Graph.\n\n  \u2022 The obvious order $5$ rotation gives $3$ pairs of $5$ edge orbits so $64$ (or $32$ or $16$ depending how hard you wish to think) ways to sign some orbits $-1$. None worked ( assuming I programmed correctly).\n  \u2022 Fixing a point gives orbits of sizes $3,3,6,6$ and $12$ (Probably the $12$ could be split $6,6$ but I did not try that variation. ) That does not yield anything.\n  \u2022 I did not look at fixing a pair of vertices (setwise). This would give orbits of sizes $1,1,4,4,8,8,2?,2?.$\n\nA similar attempt could be made for other graphs.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/32281/inverse-of-baker-campbell-hausdorff\nText:\nTake the 2-minute tour \u00d7\n\nThis should be quite simple to answer. I have a situation in which I must have an explicit expression for the inverse of Baker-Campbell-Hausdorff. More precisely:\n\nI have two power series $P_1(X,Y)$, $P_2(X,Y)$ in noncommuting variables $X,Y$. I want an expression for\n\n$$exp\\left(log(1+P_1) + \\ log(1 +P_2) \\right) .$$\n\nI searched some books and google; but beyond the fact that it exists, I am unable to find an explicit expression. If it already exists in print, it would save me some work of trying to derive it myself.\n\nThank you very much.\n\nshare|improve this question\nI assume that should be $\\log(1+P_1)+\\log(1+P_2)$? \u2013\u00a0 David Speyer Jul 17 '10 at 13:01\nYes, thanks. I fixed it. Sorry for the mistake. \u2013\u00a0 Anweshi Jul 17 '10 at 13:02\nDeriving it yourself is fun! By the way, what is the significance of $P_1$ and $P_2$ as opposed to $X$ and $Y$? Even if one or both $P_i$s have a non-zero constant term, it can be absorbed into the constant 1 inside the $\\log.$ \u2013\u00a0 Victor Protsak Jul 17 '10 at 19:17\nThere is no significance, except that when I needed to work it out, it came up as two arbitrary power series, rather than just X and Y. \u2013\u00a0 Anweshi Jul 17 '10 at 21:06\nI don't remember if you are automatically updated when I edit an answer. If not, this note is to mention that I have added some content, answering a question I asked in the comments. \u2013\u00a0 Theo Johnson-Freyd Jul 19 '10 at 5:37\nshow 1 more comment\n\n2 Answers\n\nThe following recursion formula for the homogeneous factors of $A(P,Q)$ exists:\n\n\n$A(tP,tQ) = 1 + t \\frac{B_1}{1!}+t^2 \\frac{B_2}{2!}+t^3 \\frac{B_3}{3!}+...$\n\n$C_n = P^n+Q^n$\n\n$\\Delta C_n = -n C_{n+1}$\n\n\n$B_1 = C_1$\n\n$n! B_n = [(\\Delta+C_1) B_{n-1}] _{symm}$\n\nWhere the symmetrization is of all words of the type $C_{i1} C_{i2} C_{i3} ... $\n\nThis formula can be obtained by differentiation with respect to t. I compared the results up to the cubic term to Theo's expression with a full agreement.\n\nThe coefficient of the string $\\[(C_{i1} C_{i2} C_{i3} ...]_{symm}$ in $B_n$ is equal to the coefficient of $tr(M^{i1}) tr(M^{i2}) tr(M^{i3})...$ in the coefficient of $t^n$ in $det(I-tM)$. These coefficients are the charcters of $\\{{{1^n\\}}}$ of $S_n$.\n\nshare|improve this answer\nadd comment\n\nGiving your series a name, I'll set $$A(P,Q) \\overset{\\rm def}= \\exp\\bigl( \\log(1 + P) + \\log(1 + Q) \\bigr) $$ to be your power series, where $P,Q$ are free (noncommuting) variables. I'm not sure what you want to know about this series: it exists, I don't think it has a name, the first few terms are $$ A(P,Q) = 1 + P + Q + \\frac12(PQ + QP) + \\frac1{3! \\cdot 2}\\left(-P^2 Q + 2PQP - Q^2 P-PQ^2 + 2QPQ - Q P^2\\right) + $$ $$ + \\frac1{4!}\\left( P^3 Q - P^2QP -PQP^2 + QP^3 - PQ^2P + PQPQ + \\{P\\leftrightarrow Q\\} \\right) + \\dots.$$ I don't see much of a pattern in the coefficients, and I haven't worked out the next term. If the cubic term didn't have that $\\frac12$, or if the quartic terms had more fractions, I would be happier. As it should, when $[P,Q] = 0$, the series truncates to $A(P,Q) = 1 + P + Q + PQ$. It is left-right symmetric and symmetric in $P\\leftrightarrow Q$.\n\nHere's one remark that might be useful for your intended application. Let $K = k\\langle\\langle X,Y\\rangle\\rangle$ be the ring of power series in two noncommuting variables. Then there is an algebra homomorphism $\\Delta: K \\to K \\hat\\otimes K$, where $\\hat\\otimes$ denotes that you should complete the tensor product w.r.t. the adic topology, given on generators by $\\Delta(X) = 1 \\otimes X + X\\otimes 1$ and $\\Delta(Y) = 1 \\otimes Y + Y \\otimes 1$. Recall that an element $P \\in K$ is primitive if $\\Delta(P) = 1 \\otimes P + P\\otimes 1$. Then the primitive elements form a Lie subalgebra of $K$, and consist precisely of the Lie series: the power series that can be expressed without ever referring to multiplication in $K$, only to the Lie bracket $[x,y] = xy - yx$ (and that begin in degree $1$). Recall also that an element $P\\in K$ is grouplike if $\\Delta(P) = P\\otimes P$. Then the grouplike elements if $K$ form a group under multiplication; in particular, they are all units.\n\nIf $P,Q$ are primitive, then there's no particular reason for $A(P,Q)$ to be primitive, and actually I think it never will be. However, by construction $\\Delta$ is continuous w.r.t. the adic topology, and it is a homomorphism, and so $\\Delta(f(P)) = f(\\Delta(P))$ for any power series $f$ in one variable. Also, an element $P\\in K$ is primitive iff $\\exp(P)$ is grouplike. So it follows that if $1+P$ and $1+Q$ are both grouplike, then so is $A(P,Q)$.\n\nI'll close by saying that, to me anyway, you already have an \"explicit expression\" for the power series, and even a \"geometric interpretation\", which is that it moves the additive structure of the Lie algebra to the (formal) group (whereas the BCH series moves the group multiplication to the Lie algebra). You shouldn't strongly hope for a simple description of the coefficients in terms of combinatorics, because similar descriptions for BCH, although they do exist, can be rather complicated.\n\n\nAbove I observed that $A(P,Q)$ is not a Lie series in $P,Q$. This can be seen directly: any Lie series truncates to its linear and constant terms when $[P,Q] = 0$, whereas $A(P,Q) = (1+P)(1+Q) = 1 + P + Q + PQ$ in commuting land.\n\nSo the next best thing, as I asked in the comments, is whether $$A(P,Q) - (1+P)(1+Q) = -\\frac12[P,Q] - \\frac1{12} \\bigl( [P,[P,Q]] + [Q,[Q,P]] \\bigr) + \\dots $$ is a Lie series. Alas, this also fails, as can be seen at the quartic part. Indeed, by Jacobi and antisymmetry, $$ [P,[Q,[P,Q]]] = [[P,Q],[P,Q]] + [Q,[P,[P,Q]] = [Q,[P,[P,Q]] = -[Q,[P,[Q,P]] $$ is the unique Lie monomial (up to scalar) of degree $P^2Q^2$. But it is antisymmetric under $P\\leftrightarrow Q$, whereas $A(P,Q)$ is symmetric under the same transposition. Thus if $A(P,Q) - (1+P)(1+Q)$ were a Lie series, then it could not have any terms of degree $P^2Q^2$, whereas by direct calculation: $$ A(P,Q) \\ni \\frac1{4!} \\bigl( PQPQ - PQ^2P - QP^2Q + QPQP \\bigr) = \\frac1{24} [P,Q] ^2 $$\n\nshare|improve this answer\nThanks. This was helpful. The application was the following. I wanted to define a sort of \"geometric mean\" for some finite number of noncommutative power series and see how badly it behaves, and how much can be salvaged. That is why I asked for an explicit expression, and I was imagining that something may exist using nested Lie brackets, like in BCH. I was hoping that such an expression was already worked out in the literature. Thanks for your effort. I will wait for some time and if no better answer comes, I will accept yours. \u2013\u00a0 Anweshi Jul 17 '10 at 21:10\n@Anweshi: well, I hope you get something closer to what you're looking for. But you can see explicitly, and also from the abstract nonsense about primitive versus grouplike elements, that there will not be a formula with nested brackets. OTOH, I don't see immediately whether $A(P,Q) - (1+P)(1+Q)$ is a Lie series. It does vanish when $[P,Q] = 0$, which is promising, but not sufficient. \u2013\u00a0 Theo Johnson-Freyd Jul 18 '10 at 1:48\nSince this is in the group (as opposed to the Lie algebra), the right kind of \"bracket\" is a group commutator. Anweshi: the \"geometric mean\" that you allude to is probably related to non-commutative exponential function (given by the multiplicative integral). You may find some general theory in books by Maslov and coauthors. \u2013\u00a0 Victor Protsak Jul 18 '10 at 2:24\n@Victor: Yes, this (use the group commutator) occurred to me. But with only multiplication and inverses, I'm dubious that I'd be able to write down an infinite product that converges to the operation in question. OTOH, the series $A(x,y)$, when $x,y$ are the generators of the noncommutative power series ring, is the limit of $\\bigl((1+x)^{1/n}(1+y)^{1/n}\\bigr)^n$ --- note that $(1+x)^{1/n}$ converges in the power series ring. There is certainly an infinite product whose $n$th partial product is $\\bigl((1+x)^{1/n}(1+y)^{1/n}\\bigr)^n$, but I don't find that enlightening. \u2013\u00a0 Theo Johnson-Freyd Jul 18 '10 at 3:25\nWell, I was not saying that group commutator $\\textit{would}$ work (cf Hall's identity, which is a nontrivial group-like analogue of the Jacobi identity), merely stating an obvious reason why the Lie bracket wouldn't. \u2013\u00a0 Victor Protsak Jul 18 '10 at 9:11\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/36743/solving-series-of-linear-systems-with-diagonal-perturbations/36754\nText:\nTake the 2-minute tour \u00d7\n\nI would like to solve a series of linear systems Ax=b as quickly as quickly as possible. However, the systems are related. Specifically, each matrix A is given by:\n\ncI + E\n\nwhere E is a fixed sparse, symmetric positive definite real matrix (unchanged in all the linear systems), I is the identity matrix, and c is a varying complex number.\n\nIn other words, I am wondering how to quickly solve a series of complex linear systems which are all identical except for complex perturbations along the diagonal. I should say that the resulting matrices are not necessarily Hermitian, so currently I compute the LU decomposition. This works, but given the large number of rather closely related systems to be solved, I wonder if there is a better way to solve the problem, perhaps by using a more expensive (e.g. QR) decomposition up front.\n\n(Edit for Jiahao: Yes, the bs are all the same.) (Edit for J. Mangaldan: The matrices are of order n=10^5 ~ 10^6, with about 10 times that many nonzeros.)\n\n\nI'd like to thank everyone here for their suggestions. My implementation is ugly, but in the end interpolation was the key to a reasonable (10x) speedup. Since the c are quite close (imagine a small region of the complex plane, small in the sense that the spectrum of the matrix E is much larger) I could get away with computing solutions for a subset of the values of c and interpolating a solution for a given value of c using the precomputed values. It isn't elegant at all but it's something.\n\nshare|improve this question\nI assume the bs are all the same then? \u2013\u00a0 Jiahao Chen Aug 26 '10 at 11:55\nExactly how big are your matrices anyway? This can crucially affect the practicality of proposed solutions. \u2013\u00a0 J. M. Aug 26 '10 at 12:33\n$10^6$... you've essentially said none of the proposals thus far are practical. ;) So what you in fact want is the vector $(E+cI)^{-1}b$ with varying c; I'll check my notes on special methods for sparse matrices and report back. Only one thing: definitely QR decomposition will not be a practical solution to your problem either! \u2013\u00a0 J. M. Aug 26 '10 at 12:51\nadd comment\n\n3 Answers\n\nup vote 1 down vote accepted\n\nYou want the resolvent of $E$ (at $z:=-c$). Recall it's an analytic function of $z$ defined on the resolvent set, $\\mathbb{C}\\setminus\\operatorname{spec}(E)$. According to the complexity of the matrix $E$, and with the number and the location of the $c$ you need to consider, it may be worth computing a power series expansion at various centers so as to cover the set $\\{c\\}$ of the data. For $|z|$ larger than the spectral radius you have of course the Laurent expansion $(z-E)^{-1}=1/z+ E/z^2+ E^2/z^3+\\dots$\n\nshare|improve this answer\nWell, (E+cI)x=b can indeed be turned into something like (E/c+I)x=b/c, and thus you can use the geometric series technique. Of course, if the spectral radius of E/c is bigger than 1, this idea is shot. \u2013\u00a0 J. M. Aug 26 '10 at 12:29\nIs there a method to use the resolvent without computing it explicitly? It seems to use the resolvent would have to be recalculated for all cs, and explicit computation could result in massive fill-in (loss of sparsity) as @J. Mangaldan pointed out above once products like E^2 are computed. \u2013\u00a0 Jiahao Chen Aug 26 '10 at 12:50\nWell, one can do it Krylov-style, assuming there is a nice black box for matrix-vector multiplications. Maintain a vector v initialized to the right-hand side, and at every iteration multiply this by E. But again, this is only feasible if it can be assured that the spectral radius of E/c never exceeds unity. \u2013\u00a0 J. M. Aug 26 '10 at 13:00\nYes, as I wrote. Nevertheless, finitely many expansions suffice to cover the set of {c}; whether this approach is efficient depends on the details. \u2013\u00a0 Pietro Majer Aug 26 '10 at 14:22\nadd comment\n\na) There are formulae such as the Woodbury identity that allow for rank k updates to a previously solved problem, which I think fits your problem nicely.\n\nb) In addition, using a reasonably smart iterative algorithm such as conjugate gradients (or whatever is appropriate for your problem) will also be helpful since you can feed it the solution from your previous problem, and for small perturbations the new solution can be computed very quickly.\n\nIn practice I have found it sufficient to use just (b), but it might be worth trying both separately or together.\n\nshare|improve this answer\n(a) does not look useful since the updates are full-rank (b) seems useful only if the $c$s are close. Or am I missing something? \u2013\u00a0 Federico Poloni Aug 26 '10 at 12:14\nSherman-Morrison-Woodbury, as already stated, is of no help since it is intended for low-rank corrections; e.g., corrections expressible in the form $UV^T$, where $U$ and $V$ are rectangular. CG is of no use since he said in the problem statement \"I should say that the resulting matrices are not necessarily Hermitian\", and computing $(E+cI)^T(E+cI)$ so that you can apply CG can result in a much denser matrix. \u2013\u00a0 J. M. Aug 26 '10 at 12:24\n@Frederico: That's true, I forgot about fill-in, since using Woodbury would require the computation of E^-1 . E^-1. I am assuming that the c's are small since the OP did say diagonal perturbations. \u2013\u00a0 Jiahao Chen Aug 26 '10 at 12:54\n@J. Mangaldan: that is true, CG is not guaranteed to work. Sometimes it does anyway though! But really without knowing more about the problem it is difficult to recommend any particular iterative solver. Tricks like level shifting (regularizing the matrix A to make it always posdef) can sometimes be useful in using CG. BCG certainly doesn't seem feasible due to fillin. My first thought was regularized CG or GMRES. \u2013\u00a0 Jiahao Chen Aug 26 '10 at 12:54\nA method that sometimes works and sometimes doesn't, IMHO, cannot be recommended in good conscience to somebody whose problem's properties still have to be explored fully. Besides, he said c can be complex, and that can play havoc with regularization. \u2013\u00a0 J. M. Aug 26 '10 at 12:57\nshow 1 more comment\n\nIf you're doing a full LU decomposition and ignoring sparsity, then you could switch to a Schur decomposition (costs $25n^3$ instead of $2/3n^3$, but allows you to solve any of the resulting systems within $O(n^2)$). If you're using sparsity, as far as I know it is an open research problem how to exploit fully this property (see e.g. the rational Krylov method).\n\nshare|improve this answer\nE might be sparse, the Schur decomposition is definitely dense, and computational time and storage can be prohibitive. I'm assuming that E is a large enough matrix that the \"LU decomposition\" alluded to in the original post is in fact set to do something like the Cuthill-McKee ordering to maintain sparsity in the triangular factors. \u2013\u00a0 J. M. Aug 26 '10 at 12:32\nUnfortunately, I do need to maintain sparsity or the problem becomes too big to handle. (I am using the KLU package, but I expect that most LU solvers would be able to handle the linear systems I have.) \u2013\u00a0 Fumiyo Eda Aug 26 '10 at 12:47\nAs I said, the reason why those LU solvers can manage your large matrices is that they do a preliminary analysis of sparsity pattern before performing the LU decomposition. Blindly triangularizing or pivoting can result in disastrous fill-in, and thus pattern analysis is a crucial step for these LU solvers. \u2013\u00a0 J. M. Aug 26 '10 at 12:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/81944/whats-the-expected-matched-pair-of-shoes-when-10-pairs-mixed-up\nText:\nTake the 2-minute tour \u00d7\n\nWe've got $10$ different pairs of shoes. Now we mix them up and randomly regroup them into $10$ \"pairs\". Of course some \"pairs\" are not matched and maybe some of them are. So what's the expect number of pairs that are matched?\n\nBy \"randomly group\", I mean you can randomly pick one from the $20$, then choose one from the remaining $19$ to pair it up, and so on.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nLet $X$ be the number of pairs of shoes that are matched. It is somewhat complicated to work with $X$ directly, so we think of $X$ as a sum of simpler variables:\n\nFor $i=1,2,\\ldots10$, let $X_i=\\cases{1 & \\text{if the }i\\text{th pair is matched},\\\\ 0 & \\text{otherwise}.}$\n\nThen each $X_i$ is a Bernoulli variable and $X=\\sum_{i=1}^{10}X_i$.\n\nExpectation is linear, so $$ \\Bbb E(X)=\\sum_{i=1}^{10}\\,\\Bbb E(X_i). $$\n\nNow we fix $i$ and find $\\Bbb E(X_i) $:\n\nSince $X_i$ is a Bernoulli variable, $\\Bbb E(X_i)=P[X_i=1]$. But the probability that $X_i=1$ is the probability that the $i$th pair was matched. Since it is equally likely that any one of the other 19 shoes is paired with the left shoe of the $i$th pair, $P[X_i=1]={1\\over19}$.\n\nSo $\\Bbb E(X_i)={1\\over19}$.\n\nFinally, we have:\n\n$$\\Bbb E(X)=\\sum_{i=1}^{10}\\Bbb E(X_i)=\\sum_{i=1}^{10}{1\\over19}=10/19.$$\n\nshare|improve this answer\nI should mention why $P[X_i=1]={1\\over19}$ without \"hand waving\": there are ${20!\\over2^{10}}\\cdot{1\\over10!}$ ways to divide the 20 shoes into pairs and there are ${18!\\over2^9}\\cdot{1\\over9!}$ ways to divide them into pairs with the $i$th pair matched. $P[X_i=1]$ is the ratio of these quantities, which is $1/19$. \u2013\u00a0 David Mitra Nov 14 '11 at 10:15\nInteresting that you're allowed to pair a right shoe with another right shoe. I might have stated the problem differently---maybe using socks, since with those you can't tell left from right. \u2013\u00a0 Michael Hardy Nov 14 '11 at 11:45\nI'm thinking of the problem as the same as \"10 married couples are split into 10 groups, each of size 2\". Find the expected number of groups consisting of a married couple. (That is, a pair of shoes consists of two distinct objects.) \u2013\u00a0 David Mitra Nov 14 '11 at 11:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/83958/combinatorial-geometry-covering-a-square?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm stuck with this problem. can anyone help me?\n\nA finite collection of squares has total area 4. show that they can be arranged to cover a square of side 1.\n\nshare|improve this question\nSquare overlapping is allowed, right ? If, for exemple, you have 21 small squares with areas $a_1,a_2, \\ldots ,a_{21}$ given by $a_k=\\frac{19}{105}+\\frac{k-1}{1050}$, then all the $a_k$'s are different and smaller than $a_{21}=\\frac{1}{5}$, so if we cover a unit square with those small squares, some small squares will necessarily overlap. \u2013\u00a0 Ewan Delanoy Nov 20 '11 at 17:16\nyes, overlapping is allowed. \u2013\u00a0 Goodarz Mehr Nov 20 '11 at 17:37\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nHere's a proof using the following simple combinatorial\n\nLemma. Let a positive integer $k$ and a nonempty finite multiset $P$ of powers $k^i$ with $i\\in\\mathbf{Z}$ be given. Put $s=\\sum P$, the sum of all the powers, and $k^m$ the greatest power occurring in $P$; let the integer $q>0$ be such that $s\\geq qk^m$. Then there exists a partition of a sub-multiset of $P$ into $q$ parts each of sum exactly $k^m$.\n\n(Finding a decent formulation is more difficult here than finding a proof.) One can obviously take $q$ the quotient of the Euclidean division of $s$ by $k^m$, but for the proof it will be convenient to have a bit more freedom. The condition for a collection of multisets of being a partition of a sub-multiset of $P$ is what the terminology suggests: it just means that for any element, the sum of its multiplicities of occurrence in members of the collection is no more than its multiplicity of occurrence in $P$.\n\nProof. By induction on the number $n\\geq1$ of elements in $P$. Split off from $P$ the singleton $\\{k^m\\}$ of its greatest element, which will be one part of the partition sought, leaving a remainder $P'$. If $q=1$, then the one-part partition $\\{k^m\\}$ is a solution. In the remaining case one certainly has $n>1$, so $P'$ is non-empty; let $k^{m'}$ be the greatest element of $P'$, with obviously $m'\\leq m$. Applying the induction hypothesis to $P'$ and $q'=(q-1)\\,k^{m-m'}$, one obtains a partition of a sub-multiset of $P'$ into $q'$ parts each of sum $k^{m'}$. Grouping them together $k^{m-m'}$ at a time (in an arbitrary way) provides a partition of the same sub-multiset of $P'$ into $q-1$ parts, which together with $\\{k^m\\}$ give a solution. QED\n\nNow for the problem of the squares, round the lengths of their sides down, each to a (probably negative) integer power of $2$. Each square will certainly cover a square of the rounded-down size, and replacing the collection by the so rounded-down squares gives a multiset of squares whose total area is greater than a quarter of the original area, that is greater than 1. Excluding the trivial case of a single square of area $4$, the largest square has size $2^{-l}$ with $l\\in\\mathbf{N}$. Apply the lemma with $k=4$, the multiset of the areas of the rounded-down squares, and $q=4^l\\in\\mathbf{N}$. This provides a partition of a sub-multiset of the squares into $q$ parts, each of which parts will cover one of the $q$ squares of the $2^l\\times2^l$ subdivision of the unit square. (One needs to check that the regrouping of $4^{m-m'}$ multisets done in the proof of the lemma can be realised geometrically, but this is obvious by a similar $2^{m-m'}\\times2^{m-m'}$ subdivision.)\n\nshare|improve this answer\n\"...the greatest power occurring in S\" - what is S? Did you mean P? \u2013\u00a0 Erel Segal Halevi May 19 '13 at 10:30\n@ErelSegalHalevi Yes, thank you. Corrected now. \u2013\u00a0 Marc van Leeuwen May 19 '13 at 10:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/90189/checking-consistency-of-a-system-of-linear-equations-and-inequalities/90199\nText:\nTake the 2-minute tour \u00d7\n\nI have a lot of systems of equations and inequalities of the following form:\n\n$$ a_{1,1}x+a_{1,2}y+a_{1,3}z+a_{1,4}w = 2 $$ $$ \\ldots $$ $$ 0 < x < 2 $$ $$ 0 < y < 2 $$ $$ 0 < z < 2 $$ $$ 0 < w < 2 $$\n\nThere are always at least two equations, and I probably won't consider cases with more than twenty equations. All coefficients $a_{i,j}$ are positive integers and some can be zero. We also have the property that $\\sum_{j=1}^4a_{i,j}\\geq3$ for all $i$. The solutions are real numbers.\n\nI don't need to solve these systems, but I need to be able to tell whether there exists a solutions. If it isn't possible to tell for each system whether it is consistent or not, any method which identifies as many inconsistent systems as possible is greatly appreciated.\n\nI have a few hundred millions of these systems, so I'm specifically looking for things that can easily be turned into a program. (I know the basic techniques to do this by hand, and am looking for some handy tricks that can be done by a computer. I have some programming experience, but not really with programming this kind of problems.)\n\nshare|improve this question\nIts difficult to give an appropriate answer here but a very simple approach would be to use view this as a convex feasibility problem: You try to decide if the intersection of the solution space of the linear equation with the cube defined by the inequalities is not empty. Since your linear systems seem to be small and it looks like projecting a point onto the polytope formed by the linear constraints is also easy, alternating projections should be easy and fast. \u2013\u00a0 Dirk Mar 4 '12 at 10:43\nHave a look at constraint-logic programming (in particular, over the reals -- CLP(R)) which is designed for just such problems. Typically these are implemented as Prolog libraries (Sicstus, SWI), but I believe that stand-alone versions are available too. \u2013\u00a0 J.J. Green Mar 4 '12 at 11:21\nFor these systems solving them is no harder than detecting feasibility. So just add an objective function, e.g., x+y+w+z, and now you have a linear program. Stuff this into an LP solver and it will tell if your feasible region is empty. If you read the manual, there may a flag you can set to avoid dding the objective function. This question would be just as well answered at math.stackexchange, and is not appropriate for this site. \u2013\u00a0 Chris Godsil Mar 4 '12 at 15:10\nChris, the inequalities there are strict, and these need a bit of work. A solution to your LP would likely violate the feasibility of these strict inequalities. \u2013\u00a0 Dima Pasechnik Mar 4 '12 at 15:28\nDima: you're right, of course. \u2013\u00a0 Chris Godsil Mar 4 '12 at 17:02\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nThere is a criterion for solvability of a system of strict inequalities $Mt\\lt b$ due to Carver (cf. A.Schrijver \"Theory of linear and integer programming\", Sect. 3.7.8). It says that $Mt\\lt b$ is solvable if and only if $v=0$ is the only solution of the system \\begin{equation}\\label{eee} v\\geq 0,\\ M^\\top v=0,\\ v^\\top b\\leq 0.\\qquad \\qquad (*)\\end{equation}\n\nLet us see how to get $Mt\\lt b$. To do this, let $\\zeta=\\frac{1}{2}(x,y,z,w)$, and write your linear equations as $A\\zeta=e$, where $e$ denotes all-1 vector. If this system has no solution, done. If it has only one solution, you can check it with your inequalities directly. If there are several solutions, linear algebra software will be able to rewrite your system in the form $(I\\ B)\\zeta'=d$, where $I$ is the identity matrix of size 1, 2, or 3, $B$ is a matrix of the appropriate size, and $\\zeta'$ is a permutation of the original variables $\\zeta$. In other words it gives you expressions $\\zeta'_k=d_k-\\sum_{j\\neq k} B_{kj}\\zeta'_j$, for $1\\leq k\\leq m$, and $m$ being 1, 2, or 3, depending upon $A$.\n\nThis reduces your original system to the system of strict inequalities in the remaining unexpressed $\\zeta'$. (i.e. in $4-m$ variables).\n\nFinally, apply Carver's criterion by solving a linear programming problem: $\\max\\sum_{i} v_i$ subject to $(*)$. If this maximum is strictly bigger than 0 then the original system $Mt\\lt b$ has no solution, otherwise it does have one.\n\nshare|improve this answer\nadd comment\n\nTo simplify the notation, let $A$ be the coefficient matrix in a given instance of your problem, let $\\xi = ((x,y,z,w)^T)/2$, and let $O = (0,0,0,0)^T$, $e = (1,1,1,1,...)^T$, $e_4 = (1,1,1,1)^T$. The problem then can be written in shorthand as $$ A \\xi = e, O < \\xi < e_4 $$ where $O < \\xi < e_4$ is understood component wise.\n\nTo check if there is a feasible solution, proceed in two steps:\n\n  1. Check if there is a feasible solution of the linear system $A \\xi = e$. If there is one, it can be found as $\\xi = (A^TA)A^Te$ and therefore $A(A^TA)^{-1}A^Te = e$ must hold. In practice, compute the $QR$ decomposition of $A$, $A = QR$ where $R$ is square and upper triangular and $Q$ has the same dimensions as $A$ and satisfies $Q^TQ = I$ (identity matrix) and look at the system $R \\xi = Q^T e$. If $R$ has full rank, you can find $\\xi$ and compare $A \\xi $ to $e$. If $R$ does not have full rank (i.e. there are zero rows at the bottom), this also tells you if there is a solution.\n\n  2. Suppose now there is a nontrivial solution of $A \\xi = e$. Then choose a small number $\\epsilon$, e.g. $\\epsilon = 10^{-8}$, and solve the linear program $$ A \\xi = e, \\epsilon e_4 \\le \\xi \\le (1 - \\epsilon) e_4, c^T \\xi \\to \\max $$ with any vector $c$. If there is a feasible solution to the full problem, it will show up as the optimum (and some of its components may be equal to $\\epsilon$ or $1 - \\epsilon$). By varying $\\epsilon$ for these problems, you may be able to find solutions which are further in the interior of the four-dimensional cube in which your solution is supposed to be.\n\nThe entire method should be easily implementable in e.g. R (package lpSolve) and it is obvious how to parallelize it.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262199/relating-the-genus-of-a-curve-to-its-degree-via-n-canonical-embedding\nText:\nTake the 2-minute tour \u00d7\n\nLet $n\\geq 3$ be an integer. If we embed a connected curve $C$ (e.g. a stable curve) of genus $g$ in $\\mathbb P^N$ by an $n$-canonical embedding, i.e. using the very ample linear system $|nK_C|$, we have that $N=(2n-1)(g-1)-1$. This is clear. But I do not see how to deduce that the degree of $C$ is $2n(g-1)$. This is equivalent to the assertion \\begin{equation} g+\\deg C=N, \\end{equation} which I am not able to justify. Does anyone have any hint? Is it possible to use some adjunction formula argument even if we are not in the plane case?\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nThe degree of $C$ in $\\mathbb P^N$ is the intersection number of a hyperplane with $C$, or equivalently, the degree (as divisor on $C$) of the restriction of a hyperplane to $C$. In terms of invertible sheaf, a hyperplane corresponds to $O_{\\mathbb P^N}(1)$ and its restriction to $C$ is, by construction, $nK_C$. So the degree of $C$ in $\\mathbb P^N$ is just the degree on $C$ of $nK_C$, which is $n(2g-2)=2n(g-1)$ by Riemann-Roch.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/570088/prove-that-if-f-is-continuous-at-0-it-is-continuous-on-mathbbr\nText:\nTake the 2-minute tour \u00d7\n\nLong story short, the question I'm stuck on is as follows:\n\nLet $f$ be a positive-definite function. Prove that if $f$ is continuous at $0$, then it is continuous everywhere.\n\nHere's the long version:\n\nWe say that a function $f:\\mathbb{R}\\to \\mathbb{C}$ is positive definite if the matrix $A_f[\\{t_1,t_2,\\dots,t_n\\}]$, whose entries are given by $$ A_f[\\{t_1,t_2,\\dots,t_n\\}]=[f(t_i-t_j)]_{i,j=1}^n $$ Is positive semidefinite for all choices of $t_1,\\dots,t_n \\in \\mathbb{R}$. In the whole problem, we are meant to show that $f$ has the following properties:\n\n  \u2022 $f(-t) = \\overline{f(t)}$\n  \u2022 $f(0) \\in \\mathbb{R}$ and $f(0) \\geq 0$\n  \u2022 $|f(t)|\\leq f(0)$ for all $t \\in \\mathbb{R}$\n  \u2022 if $f$ is continuous at $0$, then it is continuous everywhere\n\nThe first three parts may all be solved by considering the $2\\times 2$ matrix $A_f[0,t]$ where $t\\in \\mathbb{R}$ is arbitrary. Because $A_f[0,t]$ is Hermitian, the first statement holds. Because $A_f[0,t]$ must have non-negative trace, we conclude that the second statement holds. Becuase $A_f[0,t]$ has a non-negative determinant, we conclude that the third statement holds. That fourth statement, however, has me stumped.\n\nAs far as I can tell, there is no more insight to be gleaned from $2\\times 2$ matrices. Presumably, I need to find an upper bound for $|f(t) - f(t+\\delta)|$ given that $|f(\\delta) - f(0)|$ can be made arbitrarily small. I've noticed that $\\det A_f[0,t,t+\\delta]$ can be finagled into something like $f(0)|f(t) - f(t+\\delta)|^2$. However, it's not clear to me how I would use this to the desired ends.\n\nThere's also a good chance that I've managed to think myself into a hole, given that this one small part of one problem has given me more trouble than the rest of the assignment. The question claims that this problem can be solved using the fact that a semi-definite matrix has a non-negative trace and determinant, and that all principal submatrices have a non-negative determinant.\n\nI think that just about covers it. If you've made it this far, thank you for your time; I tried not to make this a wall of text. Any helpful nudges in the right direction would be very much appreciated; an attempt at an answer doubly so.\n\nshare|improve this question\nHaving finally typed out this question, I wondered if there was a hint for this problem in the back of the book. There was. It turns out I'm on the right track now that I am (finally) considering $3\\times 3$ matrices (the hint is simply \"consider the $n=3$ case.\"). Things are looking much more hopeful now, but I don't feel like the solution is quite at hand. At any rate, I plan to sleep on it. All input is, however, still (and always) welcome. \u2013\u00a0 Omnomnomnom Nov 17 '13 at 6:38\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nHint: The matrix $$ A=\\pmatrix{ f(0) &f(-t) &f(-t-h)\\\\ f(t) &f(0) &f(-h)\\\\ f(t+h) &f(h) &f(0)} $$ is congruent to $$ B=\\pmatrix{ f(0) &f(-t) &f(-t-h)-f(-t)\\\\ f(t) &f(0) &f(-h)-f(0)\\\\ f(t+h)-f(t) &f(h)-f(0) &2f(0)-f(h)-f(-h)}. $$ Now consider the $2\\times2$ submatrix taken from the entries at the four corners of $B$.\n\nshare|improve this answer\nBrilliant idea to use a congruent matrix! I know it's an elegant solution because I can't help but feeling stupid for not having thought of it myself (I had considered matrix similarity, which can be used to the same effect, but had only considered it in the $2\\times 2$ case, and not quite with this end in mind). This will definitely go into my bag of tricks. Thank you. \u2013\u00a0 Omnomnomnom Nov 17 '13 at 14:56\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56582.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nProbability Distribution\n\nDate: 12/22/97 at 19:15:33\nFrom: Smith, Cassandra\nSubject: Probability distribution\n\nI have written to you before with much success. I am once again\nstumped. I have tried several times to answer this question and even\nthough the answers are available to me, I am unable to solve it.\n\nA county containing a large number of rural homes is thought to have \n60% of those homes insured against fire. Four homeowners are chosen \nat random and x are found to be insured against fire. Find the\nprobability distribution for x. What is the probability that at least \n3 of the 4 are insured?\n\nI am able to find p(0) = 0.0256  and the p(4) = 0.1296\nThe answers to p(1) = 0.1536   p(2) = 0.3456  p(3) = 0.3456\nProbability of 3 out of 4 = 0.4572\n\nI have tried to work towards these answers without any success.  \nPlease show me how to solve this problem.  \n\nThank you.\n\nDate: 01/28/98 at 13:54:14\nFrom: Doctor Sonya\nSubject: Re: Probability distribution\n\nWhat you have described is known as a Bernoulli trial.  \n\nYou use a Bernoulli trial when you want to know the number of \nsuccesses in n trials. For example, if I have a probablity of 0.34 of \nwinning a game, I could use Bernoulli trials to tell me my probability \nof winning three out of five.\n\n\"What does this have to do with insurance?\" you may ask. Well, if my \ngame is picking a house, and I win that game if the house is insured, \nwe can use Bernoulli trials to find the probability of \"winning\" 0, 1, \n2, 3, or 4 times. This is also the probability that 0, 1, 2, 3, or 4 \nof the houses are insured.\nOne thing that has to be true about our game before we can use \nBernoulli trials is that each play must be independent. This means \nthat one house having insurance has nothing to do with its neighbor \nalso having insurance.\n\nI'm sure there's a chapter about Bernoulli trials in your textbook if \nyou want more information. \n\nLet's say I have n trials (or n plays of a game), with a probability p \nfor success. Then the probability that I will win EXACTLY k of these \nn trials is given by\n\n  P(X = k) = (n choose k) * (p^k) * (1 - p)^(n-k)\n\nSo for our problem, if n = 4, and k = 3, and p = .6 we have\n\n  P(X = 3) = (4 choose 3) * (.6^3) * (.4)^1\n           = (4) * (.6^3) * .4\n           = (4) * (.216) * .4\n           = .3456\n\nHowever, this isn't all.  Your problem asked for the probability of \n\"at least 3\" being insured. So if 4 of the 4 get insurance, then the \nproblem is also solved. \n\nI'll let you use the Bernoulli trials for P(X=4). (Remember that k=4.)\n\nThus the probability that at least 3 of the four houses are insured \n\n  P(X=4) + P(X=3) \n\nand you'll see that these are the answers you're looking for.\n\nGood luck, and don't hesitate to write back with more questions.\n\n-Doctor Sonya,  The Math Forum\nAssociated Topics:\nHigh School Probability\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/309536/quaternions-torque-and-impulse\nText:\nTake the 2-minute tour \u00d7\n\nIn a physics simulation I have a solid ball of mass $m$ and moment of interia $M$ (which is a diagonal matrix with all entries equal to ${2\\over5}mr^2=i$). Its instantaneous rotation is given by a quaternion $q$.\n\nThis body is touching another rotating body which applys a force $f$ at a point $p$ measured from the centre of the ball. $f$ resolves into a push into the radius (which we can disregard here) and a tangential torque $f^T$.\n\nThe simulation advances in a time step of $t$ seconds. How should I update $q$?\n\nI have a basic understanding of quaternions but not enough familiarity to approach this. Computational efficiency matters so I'd like to avoid converting $q$ into a matrix and back again. I imagine that $f^T$ and $p$ combine to some kind of \"impulse\" rotation $r_t$ so I can just do $q \\to qr_t$. Is this at all the right way to do it?\n\nshare|improve this question\n\n1 Answer 1\n\nI don't know the term \"instantaneous rotation\", so I don't know whether you mean the instantaneous orientation or the instantaneous angular momentum or angular velocity; whichever one you mean, the other one seems to be missing from your state description. I also don't know what to make of a force resolving into a push and a torque, since a torque doesn't have the same dimensions as a force. Further it's unclear to me what you mean by \"$f^T$ and $p$ combine\", since $f^T$ is a force or a torque and $p$ is a point. I'll restate the problem in a form and notation that I understand, and I hope you'll be able to map that onto what you're doing.\n\nThe orientation of the body at time $t$ can be described by a quaternion $s(t)$ corresponding to the rotation required to get to that orientation from some reference orientation. Its rotational state can be described by either its angular momentum $L$ or its angular velocity $\\omega$; since the body is symmetric and its moment of inertia $I=\\frac25mr^2$ is a scalar, these two are proportional to each other, $L=I\\omega$. The angular velocity can be regarded as an element of the Lie algebra of the quaternions, specified by a three-dimensional vector whose direction is the instantaneous axis of rotation and whose magnitude is the instantaneous angular speed. The body's orientation evolves according to $\\dot s(t)=\\Omega(t)s(t)$, where the dot denotes differentiation with respect to the time $t$ and $\\Omega(t)=(0,\\omega(t))$ is the purely imaginary quaternion corresponding to the angular velocity $\\omega(t)$. In the absence of torques, the angular velocity is constant and the motion can be integrated to $s(t)=\\exp(\\omega t)s(0)$, where $\\exp$ is the exponential map from the Lie algebra to the quaternions,\n\n$$\\exp(x)=\\left(\\cos|x|,\\sin|x|\\frac x{|x|}\\right)\\;.$$\n\nA torque is by definition a rate of change of the angular momentum. A force $F$ acting at a point $p$ exerts a torque $\\tau=r\\times F$ on the ball, where $r$ is the vector from the ball's centre to $p$. This causes the angular momentum to change according to $\\dot L=\\tau$, so the angular velocity changes according to $\\dot\\omega=\\tau/I$. Section $3$ of this paper gives what might be called a closed form for the resulting motion, but it's rather complicated and I gather you want to approximate the motion in finite time steps $\\Delta t$. Since $\\omega$ changes linearly, its update is exactly given by $\\omega(t+\\Delta t)=\\omega(t)+\\Delta t\\tau/I$. To update the orientation $s$, you could take the average angular velocity $\\bar\\omega=\\omega(t+\\Delta t/2)=\\omega(t)+\\Delta t\\tau/(2I)$ during the time step and update $s$ according to $s(t+\\Delta t)\\approx\\exp(\\bar\\omega\\Delta t)s(t)$. If you want, you can also approximate the exponential map by\n\n$$ \\exp(x)\\approx\\left(\\sqrt{1-|x|^2},x\\right) $$\n\nfor small time steps.\n\nI hope you can translate that into how you're thinking about the problem; if not, feel free to ask.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://yetanothermathprogrammingconsultant.blogspot.com/2011/05/optimal-spread.html\nText:\nSaturday, May 14, 2011\n\nOptimal spread\n\nIn a multi-objective MIP model I am working I have a binary variable x(t). This variable is mostly zero but now and then it is one. One of the goals is to achieve an even spread of the ones. I.e.\n\n\nThe first row has the ones clustered in the middle. The second one looks pretty good.\n\nThe following idea is based on how Q-Q plots are used to find distributions in statistical data (\n\nFirst we form a running sum:\n\n\nThe \u201cpredicted\u2019 running sum for an evenly distributed x(t) can be expressed as tn/T where n is the total number of ones, t is the current index and T is the last t:\n\n\nNow we try to keep the values s(t) as close as possible to the predicted values tn/T. I.e.:\n\n\nNote that n is a variable in my model: I don\u2019t know in advance how many x(t)\u2019s are turned on. Indeed when I run this (with n=3) I see:\n\n----\u00a0\u00a0\u00a0\u00a0 42 VARIABLE x.L\u00a0\n\nt3\u00a0 1.000,\u00a0\u00a0\u00a0 t7\u00a0 1.000,\u00a0\u00a0\u00a0 t10 1.000\n\nHere are the results when we compare the two solutions (click to enlarge):\n\n\nIndeed this seems to confirm this approach could work, and we can add d(max)-d(min) as an extra objective to minimize.\n\n\n  1. Dear Erwin,\n\n    A very nice solution indeed. Especially since this solution works in case you do not know the number of ones in advance.\n\n    I noticed that shifting all ones a single position to the left, leads to the same \"irregularity penalty\". Is this what happens for any shift, iow Is your solution \"translation invariant\"?\n\n    Adriaan Hoogendoorn\n\n  2. It almost looks like that. We can subtract or add a constant from dmin and dmax without affecting the difference. Let's see if this can be fixed.\n\n    I probably should have added dmax \u2265 0, dmin \u2264 0. That will limit how far you can move the pattern around. (Think of dmax,dmin forming a \"band-width\"; with this constraint the predicted values are inside the band.)\n\n  3. I guess the beauty of this method lies in the fact that you can use whatever distribution. In this case a uniform distribution, which is translation invariant, or a triangular distribution, giving focus to the start or the end of the period, or any other distribution.\n\n    Maarten Schuerhoff\n\n  4. Hi\n    I have a problem that is similar in spirit to this one. It involves maintaining a distribution of decision variable outcomes in a MP model. That is, I wish the standard deviation of milk production from goats to be equal to a given number, where milk production is determined endogenously. Are you familiar of any way to do this?\n\n  5. Without knowing more about the model it is not very wise to give advice. Many formulation issues are heavily dependent on the situation. So the best answer is \"It depends\"."}
{"text": "Retrieved from https://www.hackmath.net/en/math-problem/1271?tag_id=124_9\nText:\nDiagonals in the diamond\n\nThe length of one diagonal in diamond is 24 cm greater than the length of the second diagonal and diamond area is 50 m2. Determine the sizes of the diagonals.\n\nCorrect result:\n\nu1 = \u00a01012.07 cm\nu2 = \u00a0988.07 cm\n\n\nu2=u124\u00a0S=u1u22=u1(u124)2=50\u00a0m2=500000\u00a0cm2\u00a02S=u1224u1\u00a0u224u1000000=0\u00a0\u00a0a=1;b=24;c=1000000\u00a0D=b24ac=24241(1000000)=4000576\u00a0D>0\u00a0\u00a0u1,2=b\u00b1D2a=24\u00b140005762=24\u00b18625092\u00a0u1,2=12\u00b11000.0719974082\u00a0u1=1012.0719974082\u00a0u2=988.07199740819\u00a0\u00a0\u00a0Factored\u00a0form\u00a0of\u00a0the\u00a0equation:\u00a0\u00a0(u1012.0719974082)(u+988.07199740819)=0\u00a0\u00a0u>0\u00a0u1=1012.07\u00a0cmu_2 = u_1 - 24 \\ \\\\ S = \\dfrac{u_1 \\cdot u_2}{2 } = \\dfrac{u_1 \\cdot (u_1-24)}{2 } = 50 \\ m^2 = 500000 \\ cm^2 \\ \\\\ 2S = u_1^2-24 u_1 \\ \\\\ u^2 -24u -1000000 =0 \\ \\\\ \\ \\\\ a=1; b=-24; c=-1000000 \\ \\\\ D = b^2 - 4ac = 24^2 - 4\\cdot 1 \\cdot (-1000000) = 4000576 \\ \\\\ D>0 \\ \\\\ \\ \\\\ u_{1,2} = \\dfrac{ -b \\pm \\sqrt{ D } }{ 2a } = \\dfrac{ 24 \\pm \\sqrt{ 4000576 } }{ 2 } = \\dfrac{ 24 \\pm 8 \\sqrt{ 62509 } }{ 2 } \\ \\\\ u_{1,2} = 12 \\pm 1000.0719974082 \\ \\\\ u_{1} = 1012.0719974082 \\ \\\\ u_{2} = -988.07199740819 \\ \\\\ \\ \\\\ \\text{ Factored form of the equation: } \\ \\\\ (u -1012.0719974082) (u +988.07199740819) = 0 \\ \\\\ \\ \\\\ u>0 \\ \\\\ u_1 = 1012.07 \\ \\text{cm}\nu2=u124=988.07\u00a0cmu_2 = u_1 - 24 = 988.07 \\ \\text{cm}\n\n\nShowing 2 comments:\nMath student\nHow comes about U1 and U2\n\nDr Math\nu1, u2 = unknown diagonals.\n\n\nTips to related online calculators\nLooking for help with calculating roots of a quadratic equation?\nDo you want to convert area units?\nDo you want to convert length units?\n\n\nNext similar math problems:\n\n  \u2022 Alopecia\n    alopecia Medical literature indicates that 45% of men suffer from alopecia. For random sample of 8 men, calculate the probability that: (a) exactly four men suffer from alopecia. (b) at most two men suffer from alopecia.\n  \u2022 Assembly time\n    mean_normal The assembly time for the toy follows a normal distribution with a mean of 75 minutes and a standard deviation of 9 minutes. The company closes at 5 pm every day. If one starts assembling at 4 pm what is the probability that he will finish before the comp\n  \u2022 Pascal's law\n    lis Please calculate according to Pascal's law. Krupp's machines were known for their large size. In 1861, a blacksmith's steam hydraulic press was put into operation in Essen. What was the cross-sectional area of the larger piston if a compressive force of 1\n  \u2022 RC time constant\n    capacitor You introduced 1 Coulomb worth of electrons into the inner volume of a dielectric material with \u03f5r=6. 30 minutes later, you found that only 36.79% of the electrons were in the inner volume. Determine the conductivity \u03c3 of the dielectric material.\n  \u2022 Decibel\n    tv_1 By what percentage does the sound intensity increase if the sound intensity level increases by 1 dB?\n  \u2022 Natural fertilizer\n    garden_1 The rectangular garden measuring 120m and 60m was fertilized with 16kg of natural fertilizer. Natural fertilizer contains 45% organic matter. How much organic matter falls on 1 m2 of garden?\n  \u2022 Sphere in cone\n  \u2022 Hiking trip\n    walker Rosie went on a hiking trip. The first day she walked 18kilometers. Each day since she walked 90 percent of what she walked the day before. What is the total distance Rosie has traveled by the end of the 10th day? Round your final answer to the nearest ki\n  \u2022 2 cyclists and car\n    cyclist_1 One cyclist rides at a constant speed over a bridge. It is 100 meters long. When he is 40 meters behind him, he meets an oncoming cyclist who is riding at the same speed. The car travels along the bridge in the same direction as the first cyclist at a spe\n  \u2022 Water mixing\n    watermixing We have 520 ml of hot water and 640 ml of water at 48\u00b0C. What is the temperature of approximately hot water when the resulting mixture has a temperature of 65\u00b0C?\n  \u2022 Closed circuit\n  \u2022 Energy consumption\n    elektromer The device is connected to 230V and draws 3.5A current. Power consumption is 1932kJ. How many minutes has this device been in operation?\n  \u2022 Permille of alcohol\n    heart I have 2 per mille of alcohol in my blood. How many milliliters is it when I have 5 liters of blood?\n  \u2022 Wall thickness\n    sphere_Nickel The hollow metal ball has an outside diameter of 40 cm. Determine the wall thickness if the weight is 25 kg and the metal density is 8.45 g/cm3.\n  \u2022 What percentage\n    astronaut What percentage of the Earth\u2019s surface is seen by an astronaut from a height of h = 350 km. Take the Earth as a sphere with the radius R = 6370 km\n  \u2022 Self-oscillation period\n    lambda The water in the vessel carried by the boy has a self-oscillation period of 0.8 s. What is the size of the boy's movement speed when the length of the boy's step is 60 cm? Give the result in m/s.\n  \u2022 Power line pole\n    pole From point A, the power line pole is seen at an angle of 18 degrees. From point B to which we get when going from point A 30m away from the column at an angle of 10 degrees. Find the height of the power pole."}
{"text": "Retrieved from https://robotics.stackexchange.com/questions/16759/jacobian-of-a-6dof-arm\nText:\nI have a robot with 6 DOF. I read a lot of tutorial on how to compute the Jacobian, but usually all examples are for planar robots with 2DOF.\n\nI don't understand how can I get the Jacobian of a 6 DOF robot.\n\nI know that Torque = J_transpose * Force.\n\nI want to compute the force of my end effector when I apply some torque. For this reason I need the Jacobian.\n\nThank you very much\n\n\nWrite the forward kinematic equations $$\\vec(x) = F\\vec(\\theta)$$\n\nTaking the partial derivatives of each $\\vec (x)$ term with respect to each joint variable $\\vec(\\theta)$ will give you $J$.\n\n  \u2022 $\\begingroup$ Typically F(.) has a value in SE(3) so there are 12 partial derivatives (actually 16 but the bottom row are all zero since the elements are constant). Nine of those partial derivatives, the rotation part $\\dot{R}$ are related to the angular velocity, 3 elements, via Rdot = [omega]_x R. [Pity no math notation allowed in comments] $\\endgroup$ \u2013\u00a0Peter Corke Dec 30 '18 at 2:45\n\nBy taking the time derivative of the forward kinematics equation, you get a Jacobian equation, as @steveo said in his answer. What is interesting is that by using some properties of rotation matrices, we can derive a rather impressive formula for computing a Jacobian.\n\nIn short, a Jacobian can be computed as\n\n$$J = \\begin{bmatrix}J_1 & J_2 & \\cdots J_n\\end{bmatrix},$$\n\n\n$$J_i = \\begin{cases} \\begin{bmatrix}z_{i - 1}\\\\0_{3\\times1}\\end{bmatrix} & \\text{the $i^\\text{th}$ joint is revolute}\\\\ \\begin{bmatrix}z_{i - 1} \\times (o_n - o_{i - 1})\\\\z_{i - 1}\\end{bmatrix} & \\text{the $i^\\text{th}$ joint is prismatic (linear)} \\end{cases},$$ $z_i$ is the axis of the $i^\\text{th}$ joint and $o_i$ is the origin of the $i^\\text{th}$ frame.\n\nNote that a Jacobian matrix $J$ is actually a function of a joint value $q$. (We can also see this from the above equation as the joint position $o_i$ and the joint orientation $z_i$ change when the robot changes joint values.) For 6-DOF robots, although it is very unlikely that you will be able to obtain a closed form formula for $J(q)$, computing $J$ for a given $q$ is pretty straightforward.\n\nFor more details, see Chapter 5 of Robots Dynamics and Control (Spong et al.).\n\n  \u2022 $\\begingroup$ Please note that, in contrary to @SteveO `s answer this method only works if the DH Convention was used to for defining the coordinate systems. Also, if it is a serial manipulator the Jacobi will have a closed form expression. $\\endgroup$ \u2013\u00a050k4 Nov 28 '18 at 15:06\n  \u2022 $\\begingroup$ @50k4 Interesting points. Thanks a lot. $\\endgroup$ \u2013\u00a0Petch Puttichai Nov 28 '18 at 15:11\n  \u2022 $\\begingroup$ @50k4 By the way, could you help elaborate a bit more why the above formulation breaks when a convention other than DH convention is used? $\\endgroup$ \u2013\u00a0Petch Puttichai Nov 28 '18 at 15:25\n  \u2022 2\n    $\\begingroup$ you are using z-axis coordinates. if the motor axis is not the z axis, multiplying it with the axis velocity returns nonsence. The motor axis is z-axis only because DH says so... $\\endgroup$ \u2013\u00a050k4 Nov 28 '18 at 15:28\n  \u2022 $\\begingroup$ Thank you for your clarifications. I am using DH convention. I found libraries to compute the Jacobian but I want to understand and do it by myself. $\\endgroup$ \u2013\u00a0user3018940 Nov 29 '18 at 4:19\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/88180/how-to-determine-the-maximum-valued-play-in-rummikub/128553\nText:\nThis question is meant as a follow-up this question and my answer here.\n\nThe question asked multiple questions about algorithms for playing Rummikub and my answer provided an algorithm that, given a set of Rummikub pieces $S$, determines whether they can be arranged as a set of valid plays (called an arrangement).\n\nHowever, when we actually play Rummikub, the situation is slightly different: there is a given board state $B$ and a hand $H$. We want to empty our hand by adding pieces to the board. We assume the board $B$ has a valid arrangement.\n\nSo, the problem now becomes:\n\n  1. Does there exists a subcollection $S\\subseteq H$ such that there exists a valid arrangement for $S \\cup B$; and\n  2. What is the largest such subcollection $S$ ?\n\nObviously, we can iterate over every subcollection $S$ of $H$ and test validity for each of them, but that is inefficient. To make precise what I mean by 'efficient' here, consider the game to be played with $3,4$ or $5$ colours and the numbers $1\\ldots n$ for each color.\n\nDoes there exist an polynomial (in $n$) time algorithm that solves problem 1 or 2? Or this 1 or 2 intractable (e.g. NP-hard)? Feel free ignore complications such as jokers or assume all tiles are distinct.\n\n\nI will describe a polynomial time algorithm that solves both problem 1 and problem 2. I learned of the algorithm from this paper.\n\nI am going to make the following assumptions:\n\n  1. No jokers (adding them is a small change).\n  2. There are only four colors.\n  3. There are at most two copies of each tile.\n  4. The face values range from 1 to 13.\n\nTo find the maximum value play, complete these steps:\n\n  1. Recursively enumerate every valid configuration that can be built from tiles in $hand \\cup board$\n  2. Ignore any configuration where not all tiles from board are used (the board constraint).\n  3. Of the visited configurations, choose one with maximal score. Where score is the sum of values of tiles played or number of tiles played (whichever you prefer to maximize).\n\nStep 1\n\nHow do we build a configuration from a given set of tiles? We proceed by playing tiles in order of their face value. First play all tiles of value 1. Then play all tiles of value 2, and so on. We can visit every configuration by recursing for each way to play tiles of the current value.\n\nLet's look at the different ways to form runs. Assume we are playing tiles of value 5, that we have a red 5, and that we will use it in a run. Our tile can be used to start a new run or it can be used to extend any existing run (or partial run) that contains a red 4. If we extend an existing run then there is at most two choices for where to put it since there is at most two runs that contain a red 4 (there are at most two red 4's). If we have two copies of our tile then we can extend or start two runs.\n\nIn forming runs there is an optimization that can be made. We should not start a new run if we know in advance that there is no way we could finish the run. This can be implemented by counting the number of tiles of greater value.\n\nNow on to forming groups. For a given way to play runs we should recurse for every way to play groups using the remaining tiles since we want to enumerate all possible valid configurations. However this would be very slow and in the end we really only care about finding the best configuration. So instead we recurse for only the best way to play groups. Notice, for a given choice of how to form runs, how we form groups does not effect what choices we have in forming groups and runs using tiles of greater value. So given a choice of how to form runs, we should use as many of the remaining tiles in groups as possible. To do this enumerate all ways to pick groups and choose the one containing the most tiles.\n\nFinally after choosing how to play all tiles, discard any tile not used in a valid set.\n\nStep 2\n\nHow do we ensure every valid configuration we visit uses all tiles from board? After choosing how to play all tiles and discarding invalid sets, do not accept the configuration as valid if not all tiles from board are contained in it. This is correct but it would be inefficient. Instead we check at each step, after choosing how to form runs and groups, whether we have used enough tiles of the current value. For example, if the current value is 5 and we have chosen a way to play the red 5's, then we need to check if we have played at least as many red 5's as are contained in board. If we have not, then we choose another way to play red 5's before moving to the next value. Note if we have played $n+m$ red 5's where $n$ is the number of red 5's in board, then we have played $m$ red 5's from our hand. If there is no way to play red 5's (including not playing red 5's) then this branch of the recursion tree does not lead to a valid configuration and we should return.\n\nHowever, these checks are not sufficient to guarantee we never violate the board constraint. Why? Because when forming runs using tiles of value 6 we can choose to not extend a run that has length one or two. The tiles in that run would have to be discarded which could violate the board constraint due to not having enough 4's or 5's. In this case we would not be able to catch this error because so far we only know how to check the board constraint for the current value. The way to fix this is to keep count of how many tiles we have played of the previous two values (for each color separately). Then when forming runs with red 6's we can check if not extending a red run (of length one or two) puts us in a state where not enough red 4's or 5's have been played. Note that if a run has length at least three then not extending it does not force us to discard any tiles and so can not violate the board constraint (so we do not have to check in this case).\n\nWe do not have to do anything special for choosing groups. In the following proof of this fact I will use 'configuration' to mean a set of groups. Also, I will use 'maximal configuration' to mean a configuration containing the most tiles possible among all configurations where tiles come from some set $S$. Note that if we have $n$ tiles of color $c$ in a configuration then there are at least $n$ groups in the configuration. Also if a subset of the available tiles can be arranged into a configuration of $n$ groups then a maximal configuration contains at least $n$ groups (there are at most three groups, if using two jokers, and at most two groups of four in any configuration). Now assume a subset $S$ of the available tiles can be arranged into a configuration with $n$ tiles of color $c$ and that we have arranged some maximal configuration $M$. If $M$ contains $k < n$ tiles of color $c$ then $M$ contains at least $n - k$ groups which do not contain a tile of color $c$ (groups of size three). In this case we can add $n-k$ tiles of color $c$ from $S$ to $n-k$ groups of three in $M$ which contradicts that $M$ is a maximal configuration. Thus $k\\geq n$. This shows that if there are $n$ tiles of color $c$ in the set of tiles of current value that remain after playing runs and if those $n$ tiles can be played in some configuration then every maximal configuration contains those $n$ tiles. So choosing a maximal group guarantees that we satisfy the board constraint if it is possible to satisfy the board constraint by playing groups.\n\nStep 3\n\nA simple way to do step 3 would be to compute the score of a configuration when you accept it as valid then update some global variable with the configuration of max score ('configuration' meaning set of runs & groups). But this solves the same subproblem many times (compute score for sets common to more than one valid configuration). Instead make use of the fact that we know at each step how many tiles of the current value we will play. Multiply this number of tiles by the current value to find how much these choices contribute to the score. Sum the contribution with the return value of the recursive call and then update the max if necessary. Instead of updating a global max variable, we will update a local (available only in scope of recursive call) max variable which will hold the score of the best way to play tiles of the current value. The recursive function should return the value of this max variable. After attempting to play tiles of current value in all ways, if no play leads to a valid configuration (every play violates the board constraint), then return $-\\infty$. Returning $-\\infty$ is useful because even if we have a high contribution (from runs & groups), adding that contribution to $-\\infty$ is still $-\\infty$.\n\nNote that we cannot know the contribution of extending a length zero or length one run. This is because, when playing tiles of the next greater value, we may choose to not extend a run of length one or two and so the tiles in those runs would be discarded. Instead we say the contribution of extending a length zero run (starting a run) or length one run is 0. When a run is extended from length two to length three then we say it's contribution is the sum of the values of the three tiles in the run. When extending a run that has length at least three then the contribution is just the value of the tile played into the run.\n\nThere are other things you can do here too. For example, It may be desireable to find a configuration that is maximally similar to the previous configuration of the board. This can be done by maximizing score and then maximizing some similarity function. This would inflate the dp table size by two.\n\nState, Memoization, & Time Complexity\n\nThe only state we need to know is the current value and the length of the runs that we could possibly extend. The length of runs can be recorded in a list of pairs, for example [(0,0), (0,0), (0,1), (0,3)], where the $i^{th}$ pair is the length of the two possible runs of color $i$. The order of the numbers in the pairs does not matter so the above state is the same as [(0,0), (0,0), (1,0), (0,3)]. A particular extension (i.e. child state) of those runs could be [(1,1), (0,1), (0,0), (1,3)]. Also, we never need to know if a run is longer than three tiles (so an extension of (3,3) is (3,3)). We will only need to distinguish between when a run is of length 0, 1, 2, or 3. A benefit of this is the size of the state space is reduced which makes memoization much more effective.\n\nThis algorithm is exponential in the number of distinct values in $hand \\cup board$. However it can be made linear by memoization.\n\nTo memoize, store in a dictionary the key-value pair key=(currentTileValue, runLengthsList) and value=localMaxValue. Other inputs like the board, $hand\\cup board$, number of jokers available, number of tiles played per color on the last two turns, etc, are just used to bound the search and so we do not need to memoize them.\n\nHopefully I have been able to effectively communicate most of the ideas of this algorithm. For more details see the paper and my implementation. Note, the paper claims that the dynamic programming state space (number of unique inputs, max size of dp table needed, i think) is of size $n * k * f(m)$. Where $n$ is the number of possible tiles, $k$ is the number of colors, $m$ is the max number of copies of a tile, and $f(x)$ computes 4 choose $x$ with replacement. This might be a typo, I do not know. In any case the state space of the algorithm I've described is $n * f(m)^k$.\n\nNote both the paper and my implementation refer to what you call the board as the table.\n\nBy the way, before learning of this algorithm, I tried to understand the algorithm you gave here. I could not understand how to deal with duplicates. I can see how breaking into sublists, ordering those sublists, and then combining them into a single list again would allow your recursive formula to handle duplicates for some inputs. But you did not describe how exactly to break the original list into sublists nor how to combine them into a single list again. For some inputs, your recursive formula will give different answers depending on how sublists are split/recombined. Unfortunately, I do not have enough stackoverflow reputation to comment on your answer to ask for clarification. Thanks for giving the answer though, your recursive formula is nice.\n\n\nI did not read your long answer at the linked thread. However, you did mention proceeding in order of number and using a recursive relation. You can do the same here. Define $Q(x,k,m)$ to be true iff there is a valid grouping $G$ of $B\u222aS$ for some $S\u2286H$ such that exactly $k$ pieces in $S$ have numbers at most $m$ and $x$ is the multiset of colours of runs in $G$ that include the number $m$. Since there are a fixed number $c$ of colours, $x$ is encoded as a $c$-tuple of naturals with sum $O(n)$. Each state transition either stops or extends each of these runs (by adding an $m{+}1$), and may also form groups of $m{+}1$, such that all $m{+}1$-tiles from $B$ with number are used (either in extending runs or in forming groups), and the number of $m{+}1$-tiles used from $H$ are reflected in the change in $k$. I will leave the details as an exercise for you.\n\nAlso, there seems to be an incorrect assumption in your question, because the actual games rules do not allow arbitrary rearrangement of the played tiles. For instance, if the played tiles are the three sets 1a 1b 1c + 2a 2b 2c + 3a 3b 3c, then you cannot play 4a by rearranging the tiles to form 1a 2a 3a 4a + 1b 2b 3b + 1c 2c 3c. In other words, a solution to your question does not provide a solution to finding the maximal number of tiles that can be played given an actual game position. I did not check but I do think there is an algorithm along the same lines as above to solve that actual game-based problem.\n\n  \u2022 $\\begingroup$ This does not assume all tiles are distinct, and furthermore a slight modification can also handle any number of jokers. $\\endgroup$ \u2013\u00a0user21820 Jul 20 '20 at 16:33\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/567929/heat-absorbed-from-a-reservoir-by-a-moving-object\nText:\nImagine two bodies, say a body A with an infinite heat capacity(reservoir) and the another body B with some finite heat capacity($C = \\alpha \\ T_{B}(t) $).\n\nThey come into direct contact with each other for a limited time, as B moves along the surface of A with a constant velocity v.\n\nGiven the thermal conductivity $\\kappa$ of the moving object B, the temperatures of the reservoir $T_{A}$ and the moving object $T_{B}(t)$.\n\nHow to calculate the amount of heat transferred in the process as a function of time?\n\n  \u2022 $\\begingroup$ What does $C \\propto \\alpha \\ T_{B}(t)$ mean precisely? What is $\\alpha$? $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 17:27\n  \u2022 $\\begingroup$ actually $\\alpha $ is just a constant that depends on the type of the material of B $\\endgroup$ \u2013\u00a0EverydayFoolish Jul 24 '20 at 20:01\n  \u2022 $\\begingroup$ In thermodynamics we normally write: $\\Delta Q=mc_p\\Delta T$: the heat absorbed (or shed) by a change of temperature of an object of mass $m$ and specific heat capacity $c_p$. $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 20:06\n  \u2022 $\\begingroup$ I made another edit. $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 22:14\n\n\nThe calculation will first of all depend on the Biot Number:\n\n\nwhere $h$ is the convective heat transfer coefficient, $\\kappa$ the thermal conductivity and $L$ a characteristic length of the object (a length or diameter, typically)\n\n  1. Low Biot Number:\n\nThe interior of the object may be considered of uniform temperature distribution (no or low temperature gradient inside the object $B$)\n\nHere lumped thermal analysis can be used by means of Newton's Law of Cooling. It states:\n\n$$\\dot{Q}=hA[T(t)-T_A]=hA\\Delta T(t)\\tag{1}$$ where:\n\n  \u2022 $\\dot{Q}$ is the rate of heat transfer out of the body ($B$)\n  \u2022 $A$ is the surface area shared by $A$ and $B$\n  \u2022 $T(t)$ the temperature of body $B$ and $T_A$ the (constant) temperature of $A$\n\nNote that due to cooling (or heating) of $B$, $\\Delta T(t)\\neq \\text{constant}$. To calculate the heat transfer in a given amount of time, the evolution of $T(t)$ has to be (and can be) calculated.\n\n$\\text{NLC}$ is mathematically simple to use.\n\nEq. $(1)$ is a separable differential equation that solves to:\n\n$$\\Delta T(t)=(T_0-T_A)e^{-kt}\\text{ where }k=\\frac{hA}{mc_p}$$\n\n($T_0$ is the initial temperature of $B$)\n\nSo with $(1)$ we get:\n\n\nThe heat transferred in a time-interval $\\Delta t$ is:\n\n$$Q=\\int_0^{\\Delta t}hA(T_0-T_A)e^{-kt}\\text{d}t$$\n\n\n$$Q=-mc_p(T_0-T_A) e^{-k\\Delta t}$$\n\n  1. High Biot Number:\n\nHere significant temperature gradients in the body $B$ must be assumed and heat conduction will play a significant part in the heat transfer process.\n\nThe 'go to' equation here is Fourier's Heat Equation:\n\n$$\\frac{\\partial T}{\\partial t}=\\alpha \\nabla^2T\\text{ with }\\alpha=\\frac{\\kappa}{c_p\\rho}$$\n\nwhich is a partial differential equation (PDE) and will require boundary conditions and an initial condition. From the obtained spatial distribution of temperature can then be calculated the heat transferred in a given time-interval.\n\nIn many cases solving Fourier's equation is mathematically very demanding, requiring higher calculus. Analytical solutions are really only possible for simple geometries (rod, plate, sphere for instance)\n\nAn example for an internally heated sphere can be found here."}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/133361/get-the-name-of-a-time-series-while-using-table\nText:\nI saw a number of related questions to the one I'm about to post; they helped, but none of them solved my problem entirely.\n\nGet the name of a symbol passed to a function\n\nObtaining the name of a variable as a string\n\nThe general question is how to get the name of something (a function, a list...). From the previous questions, I learned that you could use a function with the HoldFirst attribute:\n\nSetAttributes[f, HoldFirst]\nf[x_] := SymbolName[Unevaluated@x]\n\nThis function works well when it's input is directly the element of which you want to get the name. However, in my case, I have to use Table[] and I want to get the name of multiple time series. For example, I have three time series, ts1, ts2 ts3. I then want to produce two list plots, both with ts1 on the x axis and then respectively one that has ts2 on the y axis and another that has ts3 on the y axis. Here is the code I used:\n\n\nListPlot[\u00a0Transpose[{ts1[\"Values\"],i[\"Values\"]}]\n\n\u00a0,{i,{ts2,ts3}}\u00a0]\n\nBut the y axis labels, on both plots, are the time series objects, not their names. If I use the function f[_x] that I linked above, I get:\n\n\n\n\u00a0,{i,{ts2,ts3}}\u00a0]\n\nThen the y axis label is just \"i\"... So what I need is a function that evaluates i \"just enough\" (forget the imprecise formulation) so that it is replaced by, let's say, ts2, but then holds the form and convert it to a symbol. I do not know how to do that.\n\nHere are three time series if you want to try and mess around with them:\n\n\n\n\nProposed alternatives\n\nThis is a matter of controlling evaluation. You can do this with varying degrees of difficulty using things like HoldFirst, Unevaluated, etc., or you can simply avoid the problem in the first place which is what I greatly prefer.\n\nTo do this you can separate the names from the data using indexed objects, Rules, or Associations. Instead of defining ts1 = TimeSeries[. . .] you would write one of the following:\n\nts[1] = TimeSeries[. . .]\n\ndata[\"ts1\"] = TimeSeries[. . .]\n\nts1[] = TimeSeries[. . .]\n\nrules = {\"ts1\" -> TimeSeries[. . .], \"ts2\" -> TimeSeries[. . .]}\n\nasc = <|\"ts1\" -> TimeSeries[. . .], \"ts2\" -> TimeSeries[. . .]|>\n\nIn each case you can freely pass around a reference (name) for the TimeSeries expression without it automatically evaluating to anything.\n\nYou would reference each of these in the respective manner:\n\nTable[Labeled[ts[i], Row[{\"ts\", i}]], {i, 1, 3}]\n\nTable[Labeled[data[name], name], {name, {\"ts1\", \"ts2\", \"ts3\"}}]\n\nTable[Labeled[ts[], ts], {ts, {ts1, ts2, ts3}}]\n\nTable[Labeled[name /. rules, name], {name, {\"ts1\", \"ts2\", \"ts3\"}}]\n\nTable[Labeled[asc[name], name], {name, {\"ts1\", \"ts2\", \"ts3\"}}]\n\nSelf-contained examples\n\nLet me see if I can provide a concrete example using your data.\n\nt = {3686428800, 3686515200, 3686601600, 3686688000, 3686774400, 3686860800, \\\n3687033600, 3687120000, 3687206400, 3687379200, 3687465600, 3687552000, 3687638400, \\\n3687724800, 3687897600, 3687984000, 3688243200, 3688329600, 3688502400, 3688588800, \\\n3688675200, 3688761600, 3688848000, 3689020800, 3689107200, 3689193600, 3689366400, \\\n3689452800, 3689539200, 3689625600, 3689712000, 3689798400, 3689884800, 3689971200, \\\n3690057600, 3690144000, 3690230400, 3690316800};\n\nvaleurs = {{2,2,1,1.4,1.9,1.8,1.7,1.5,2,2,2,2.2,1.7,1.7,1.7,1.7,2,2,1.7,2.3,1.7,1.7,1.7,1.7,2,1.7,2.4,1.7,0.5,2,1.7,1.7,1.7,1.7,2.1,1.7,2.1,3.4},\n\nnomsVariables = {ts1, ts2, ts3};\n\n\nMapThread[(#1[] = TimeSeries[#2, {t}]) &, {nomsVariables, valeurs}];\n\nAccess and labeling of various time series as an illusration:\n\nLabeled[#[], #] & /@ nomsVariables\n\nIf nomsVariables is a list of Strings rather than Symbols I recommend that you use the second, fourth or fifth forms shown earlier so as to avoid the need to convert to Symbols:\n\nnomsVariables = {\"ts1\", \"ts2\", \"ts3\"};\n\nMapThread[(data[#1] = TimeSeries[#2, {t}]) &, {nomsVariables, valeurs}]\n\nLabeled[data[#], #] & /@ nomsVariables\n\nThe question at face value\n\nTo leave no stone unturned I should address the actual question as asked rather than only proposing an alternative. You can HoldForm the individual Symbols in the Table and then ReleaseHold that expression when you need it to resolve to the TimeSeries:\n\nTable[ListPlot[Transpose[{ts1[\"Values\"], ReleaseHold[i][\"Values\"]}], Frame -> True, \n  FrameLabel -> {\"ts1\", i}], {i, {HoldForm[ts2], HoldForm[ts3]}}]\n\nThis works for the example given but it introduces other question like how to create the list {HoldForm[ts2], HoldForm[ts3]} apart from typing it in. Typically you would start with an expression of held Symbols before they (ts2, ts3, etc.) are assigned values. Another question exists that addresses the use of this form to some degree: Elegant manipulation of the variables list Nevertheless IMHO this should not be used commonly but rather as a special purpose tool.\n\n  \u2022 $\\begingroup$ Thank you for your answer. I'm trying out what you proposed by using the indexed objects ts1[]. It is indeed much simpler than messing around with the evaluation. However, I do have another question related to these indexed objects. As I dont have 3, but around 50 times series to define, I'm trying to define them as a bunch, but I get the error message Set::write: Tag Map in (#1[]&)/@{liquide,travail} is Protected.. Here is what I tried: Map[#[] &, Symbol /@ nomsVariables[[;; 2]]] = Map[TimeSeries[#, {t}] &, valeurs[[;; 2]], {1}]. $\\endgroup$ \u2013\u00a0EBassal Dec 12 '16 at 19:42\n  \u2022 $\\begingroup$ Where nomsVariables contains the names of all the variables, t contains the different dates and where valeurs contains the different variables (one sublist per variable). $\\endgroup$ \u2013\u00a0EBassal Dec 12 '16 at 19:43\n  \u2022 $\\begingroup$ Never mind, I just added an Evaluate...: Evaluate[Map[#[] &, Symbol /@ nomsVariables[[;; 2]]]] = Map[TimeSeries[#, {t}] &, valeurs[[;; 2]], {1}]. $\\endgroup$ \u2013\u00a0EBassal Dec 12 '16 at 19:55\n  \u2022 $\\begingroup$ @EBassal give me a minute; I am looking at your example. If you've found a solution in the mean time that's fine. $\\endgroup$ \u2013\u00a0Mr.Wizard Dec 12 '16 at 19:55\n  \u2022 1\n    $\\begingroup$ @EBassal Please see my update. I hope you find the examples useful, but if not it seems you found what you need. Thanks for the Accept. $\\endgroup$ \u2013\u00a0Mr.Wizard Dec 12 '16 at 20:04\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/47101/maximum-independent-nodes-subset-algorithm-with-strong-constraint\nText:\nI've a tree with weighed nodes, the problem is to flag a subset of nodes with the following constraints:\n\n  \u2022 The selected nodes must be the optimal solution (maximal sum of weight).\n  \u2022 If one node is flagged no adjacent nodes can be flagged.\n  \u2022 If a node is flagged it will be called: \"directly controlled\", the adjacent nodes instead will be called: \"indirectly controlled\", all nodes must be directly or indirectly controlled.\n\nI think is a dynamic programming problem (a greedy approach didn't find always a optimal solution), the first two constraints are a typical maximum independent subset problems, but i cannot find a solution with the third constraint included. Any idea? Thanks\n\n\nA set satisfying condition (3) is known as a dominating set. The exercise asks for a maximum weight dominating independent set.\n\nIf all node weights are positive, then every optimal solution is automatically a dominating set (why?), regardless of whether the graph is a tree or not. In the more general case in which negative weights are allowed, you can use a standard dynamic programming approach. Root the tree at an arbitrary node, and for every subtree rooted at some internal node $v$, compute the maximum weight independent set in the following three cases:\n\n  \u2022 The independent set is dominating and includes $v$.\n  \u2022 The independent set is dominating and doesn't include $v$.\n  \u2022 The independent set is dominating if $v$ is removed (it is allowed to dominate $v$ as well), and doesn't include $v$.\n\nI'll let you complete the details.\n\n  \u2022 $\\begingroup$ Thanks for your help. My tree have all positive weights, i've tried the independent set algorithm with some particular tree and, as you said, is always a dominating set, so intuitively i've understood that it's true, now i'm trying to find a better formal demonstration. $\\endgroup$ \u2013\u00a0FabioL Sep 12 '15 at 14:39\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/104570/algorithm-calculate-every-number-in-a-given-list-using-addition-and-numbers-you\nText:\nI'm creating an algorithm to calculate every number in an array using only addition and numbers we've created - in the shortest amount of steps. That's confusing so here is an example:\n\ninput: [5, 11], used numbers (start with 1): [1]\n1+1=2, used: [1, 2]\n2+2=4, used: [1, 2, 4]\n1+4=5, [1, 2, 4, 5]\n5+5=10, [1, 2, 4, 5, 10]\n10+1=11, [1, 2, 4, 5, 10, 11]\n\nWe have hit 5 and 11 so we are done in 5 steps. There are other ways to get [5, 11], eg. [1, 2, 3, 5, 6, 11]. They are the same amount of steps. Imagine we have input [5, 11, 20]. Now it matters which we choose above because [1, 2, 4, 5, 10, 11] only requires one more step, 10+10.\n\nThe input can be hundreds of numbers. Certainly I can't attempt every possibility. I was thinking about an \"elegant\" solution using prime factors. If my input is [16, 30, 36, 40], does it help me to think about this as [2*2*2*2, 2*3*5, 2*2*3*3, 2*2*2*5]? I'm not sure. I've also thought about using the differences of each input, eg. [16, 30, 36, 40] would give me [14, 6, 4, 20, 24, 10], but I'm not sure how to use that either.\n\nAny thoughts?\n\n\nIt's NP complete, but you may have a chance in many practical cases, especially if you need to produce a lot of numbers in a not very large range. I'll call the numbers you want to produce \"desired numbers\", and assume that 1 is not one of the \"desired numbers\".\n\nAn important observation is that in any chain, performing an addition that produces one of the desired numbers is optimal. Therefore, we need only count the additions that don't produce one of the desired numbers (and if you want to produce 100 numbers from 1 to 200 those additions might be very few).\n\nSo instead of the initial set { 1 }, we add { 2 } if it is one of the desired numbers, then add 3 or 4 if they are among the desired numbers, and so on. If you wanted { 2, 3, 5, 6, 10, 19, 20, 21, 50 } then you start with the initial set { 1, 2 = 1+1, 3 = 2+1, 5 = 3+2, 6 = 5+1, 10 = 5+5, 20 = 10+10, 21 = 20+1 } and you only need to find 19 and 50.\n\nThen each move consists of adding the sum of two numbers, and then adding all of the desired numbers that can now be produced. In the example, one move would be adding 16 and 19, another move adding 40 and 50. All this really cuts down on the number of possibilities you need to try out.\n\nSome more ways to cut down on the possibilities: We can require that the non-desired numbers are produced in increasing order. So if you produced 2 and 4, you cannot produce the number 3 anymore. Or if you produced 2, 3, 5, you cannot produce the number 4 anymore - if you wanted it, you should have produced it earlier.\n\nObviously you don't ever produce a number larger than the highest desired number. Or higher than the highest desired number that wasn't produced yet. And all numbers greater than the highest desired number that wasn't produced yet must have been used producing one of the higher desired numbers.\n\nAnd you cannot ever produce a number larger than the smallest desired number not found yet.\n\nApart from that, I cannot think of any \"elegant\" algorithm. I'd try all the possibilities, producing large numbers first, and of course stopping when you can prove you are not going to find a solution than the best so far.\n\nYour example: [16, 30, 36, 40].\n\nFirst attempt, always adding the largest number possible according to the rules: 2, 4, 8+16, 24, 28+30, 34+36+40. That's six moves, so you can try to find a better solution using five or fewer moves using backtracking. (Note that in move 4 and 5 we couldn't produce a number > 30 according to the rules).\n\nProducing 26 or 25 in step 5 doesn't help. In step 4, we could produce 20+36+40, 18+36+40, 17, 12, 10, 9. 20+36+40 can be followed by 28+30, so we found a better solution using five moves only (2, 4, 8+16, 20+36+40, 28+30). Now the goal is to find a chain with four or fewer extra additions.\n\n2, 4, 8+16 doesn't give success with four extra additions. We can try 2, 4, 6 or 2, 4, 5 or 2, 3, 6 or 2, 3, 5 or 2, 3, 4 which all don't solve the problem in four moves. So (2, 4, 8+16, 20+36+40, 28+30) with five moves plus four moves adding the four desired numbers is an optimal solution.\n\n\nYou're looking for an algorithm to generate an addition chain that includes each of the specified numbers. As Wikipedia explains, the problem is NP-complete in general. However, there are approximation algorithms and heuristics. Searching for algorithms for computing addition chains should give you some candidate methods.\n\n\nThis is the addition sequence problem. You can transform the addition sequence problem into the vector addition chain problem as well. The best known algorithm for computing these is:\n\nD. Bleichenbacher and A. Flammenkamp \"An Efficient Algorithm for Computing Shortest Addition Chains\"\n\nThis is unpublished but you can find it on the addition chain website:\n\n\nYou essentially need to write a function what will approximate (find a lower bound) the size of an addition sequence. For this I use the bounding sequences in this paper:\n\nE. G. Thurber \"Efficient Generation of Minimal Length Addition Chains\", SIAM Journal of Computing, V. 28(4) 1999 pp 1247-1263.\n\nMyself and Ed have an update to this paper with better bounds. Now you work in reverse with the algorithm of Flammenkamp etc by removing the largest element in the set and splitting it as per the paper. You then prune with known l(n) values that I have already calculated as well as using your lower bound for the addition sequence that is updated with the split values. You will need to understand the graph representation of addition chains to understand this algorithm. I have numerous unpublished updates to this algorithm in the code that I use. This is quite old work of mine as there are better approaches for the single number addition chain problem I study.\n\n  \u2022 $\\begingroup$ I don't see how this would work. For example, given just two numbers x and y, it is quite possible that the best way to produce two numbers doesn't involve a shortest addition chain for either number, but two non-optimal chains with common elements. $\\endgroup$ \u2013\u00a0gnasher729 Mar 31 '19 at 0:14\n  \u2022 $\\begingroup$ The algorithm described by Flammenkamp works on a set of numbers. It transforms a set say {a,b} with b > a by enumerating on the largest reduced vertex that is an input to b. Lets call that i. So you actually them process the set {a,i,b-i}. If i > b it actually skips a step working on {a,i,b-2i}. Nothing in this algorithm means we are using an optimal chain for a or b. We can clearly pune using l(a) and l(b) since l({a,b}) >= max(l(a),l(b)). You can do much better though with Thurber bounds though since you can calculate the min distance between a and b. So l({a,b}) >= l(a) + dist(a,b). $\\endgroup$ \u2013\u00a0Neill Clift Mar 31 '19 at 5:12\n  \u2022 $\\begingroup$ Need i > a above sorry. $\\endgroup$ \u2013\u00a0Neill Clift Mar 31 '19 at 5:20\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/162712/an-inequality-involving-the-spectral-norm-of-a-complex-matrix\nText:\nLet $A,B \\in {M_n}(R)$ be real $n \\times n$ matrices and let matrices $|A|$ and $|B|$ contain the absolute values of the elements of $A$ and $B$ respectively. Construct the complex matrices $C = A + j \\cdot B$ and $D = |A| + j \\cdot |B|$, where $j$ is the imaginary unit.\n\nFor a square complex matrix $M \\in {M_n}(C)$ its spectral norm is given by\n\n$||M|{|_2} = \\mathop {\\max }\\limits_{z \\ne 0} \\frac{{||Mz|{|_2}}}{{||M|{|_2}}} = \\sqrt {{\\lambda _{\\max }}({M^*}M)} = {\\sigma _{\\max }}(M)$\n\nThrough random generation in MATLAB of 100000 matrices of different orders I obtain that the following inequality holds\n\n$||C|{|_2} \\le ||D|{|_2}$.\n\nI have tried to prove it but I cannot succeed.\n\nHave you encountered this inequality somewhere or can you prove it?\n\n  \u2022 $\\begingroup$ If we replace every complex number $a+bi$ an $M$ with the real block matrix $\\begin{pmatrix} a & -b \\\\ b & a\\end{pmatrix}$ then we get a real matrix $M'$ with the same spectral norm as $M$. We need to show that $\\left|M'\\right|$ has larger spectral norm than $M$, but that's true for all real matrices, since $\\left|M\\right| \\left|v\\right|$ has larger norm than $M v$. $\\endgroup$ \u2013\u00a0Anton Malyshev Apr 7 '14 at 16:57\n  \u2022 $\\begingroup$ @Anton Malyshev: Thanks, but it is not exactly as you said. Using the principle indicated by you, from the $n \\times n$ complex matrices $C = A + jB$ and $D = |A| + j|B|$ we construct the $2n \\times 2n$ real matrices $C' = \\left[ {\\begin{array}{*{20}{c}} A & { - B}\\\\ B&A \\end{array}} \\right]$ and $D' = \\left[ {\\begin{array}{*{20}{c}} {|A|}&{ - |B|}\\\\ {|B|}&{|A|} \\end{array}} \\right]$. Now the problems comes to proving that $||C'|{|_2} \\le ||D'|{|_2}$. Note that $D'$ is not $|C'|$. Any other idea? $\\endgroup$ \u2013\u00a0Hanah Apr 7 '14 at 19:37\n  \u2022 $\\begingroup$ It is clear that $\\| A +jB\\|_{2}^{2} \\leq \\sqrt{\\|A\\|_{2}^{2} + \\|B \\|_{2}^{2}}.$ $\\endgroup$ \u2013\u00a0Geoff Robinson Apr 10 '14 at 20:06\n\nThank you all for your interest. On ResearchGate Prof. Leonid Gurvits just pointed out an excellent 2 x 2 counterexample to the inequality I intended to prove. I was tricked by the fact that the inequality was numerically satisfied for a huge number of 5 x 5, 7 x 7, 10 x 10 randomly generated matrices. I went straight to big dimensions, overlooking the test of 2 x 2 matrices. Running again the MATLAB program for 2 x 2 matrices I noticed that it cannot be true.\n\nThe 2 x 2 counterexample is: $C(1,1) = C(2,2) = 1$ and $C(1,2) = a + j b$, $C(2,1) = a - jb$, where $a^2 + b^2 = 1$; $a,b > 0$. Therefore $D(1,1) = D(2,2) = 1$ and $D(1,2) = D(2,1) = a + jb$.\n\nWe get $||C|{|_2} = 2$ and $||D|{|_2} = \\sqrt{2 + 2 a}$; since $0 < a < 1$, $||D|{|_2} < ||C|{|_2}$.\n\nSorry for bothering you all.\n\n  \u2022 $\\begingroup$ Oops! Clearly I was misled too, $\\endgroup$ \u2013\u00a0Geoff Robinson Apr 10 '14 at 21:20\n  \u2022 $\\begingroup$ Generally, for a complex matrix $C$, when we write $C=A+jB$, it refers to the Cartesian decomposition of $C$. That is $A, B$ are Hermitian. Then the answer to your question is yes, if $|A|$ is defined as $(A^*A)^{1/2}$. $\\endgroup$ \u2013\u00a0Russel Apr 10 '14 at 23:59\n\nYour Answer"}
{"text": "Retrieved from https://www.flyingcoloursmaths.co.uk/minecraft-circles/\nText:\nMinecraft circles\n\n\nSorry, buddy. I've tried it. I love that you love it -- honestly, creative games are awesome for your problem-solving skills and breaking down the barriers between art and science, so I'm all for it in principle -- it's just not my cup of tea.\n\nAll the same, I'm happy to help you solve problems! Of course I am. That's what uncles are for.\n\nSo, you want to make a circle? Awesome. One tiny problem: the Minecraft world is made of squares, and you can't make a perfect circle out of squares. You can, however, make something that looks pretty much like a circle -- that's what happens when your computer draws a circle; using lots of tiny dots means you can get close enough!\n\nSo, how would you draw a circle that was, say, 21 squares wide? That would be a circle with a radius of 10 units.\n\nIt's easy to find a few places blocks need to go: ten squares north of the centre of the circle, you'll have a block. Same thing 10 squares east, south and west of the centre -- four points making a sort of cross with the centre.\n\nAfter that, it gets trickier -- how about a square to the north-east of the centre? It needs to be 10 units away from the centre, so you'd think you'd go ten squares diagonally -- but unfortunately, that's too far! That would make a big square. Why is it too far? It's because a diagonal step is bigger than a north/south/east/west step. It's not twice as far, though: if you go five squares to the northeast of the centre, you end up midway between your compass points, which isn't right, either. The right answer is somewhere in between five and ten.\n\nIt turns out to be seven squares1, because of Pythagoras's Theorem. You might have come across this, you might not: in a Minecraft context, it says, if you go east one number of squares and north another number, you can work out how far from the centre of the circle you are by using the recipe:\n\n  \u2022 multiply the east/west number by itself\n  \u2022 multiply the north/south number by itself\n  \u2022 add the two numbers together\n  \u2022 find the square root, probably using a calculator\n\nHow does it help? Well, if you go seven squares across and seven squares up, following those steps gives you 49 and 49, which add up to 98. The calculator says the square root of 98 is about 9.9, which rounds up to 10 -- the square seven east and seven north of the centre is pretty close to 10 units away from it, which is what we want from a circle with radius 10!\n\nWe can change the recipe slightly to work out how far north we need to go if we go any distance to the east. Here's how it looks:\n\n  \u2022 multiply the east/west number by itself\n  \u2022 multiply the radius by itself\n  \u2022 find the difference between them\n  \u2022 find the square root, probably using a calculator\n\nIf you go one to the east, the steps give you 1, 100, a difference of 99, and the square root is 9.95 or so -- which rounds up to 10, so the square one to the east and 10 north is on the circle. You can write this efficiently as (1, 10).\n\nWorking the same way for the next few numbers gives (2, 10), (3, 10), (4, 9), (5, 9), (6, 8) and (7,7) -- and surprisingly, that's all the hard work we need to do! We can now use the idea of symmetry to find all of the other coordinates.\n\nOne kind of symmetry means you can swap the numbers in a pair of coordinates: because (1, 10) is on the circle, so is (10, 1). In the same way, you know (10, 2), (10, 3), (9, 4), (9, 5) and (8, 6) are also on the circle.\n\nNow you've got a quarter-circle! (I believe, in Minecraft, that's enough; you can set it up to build the whole circle using symmetry. But let's keep going!)\n\nHow do you get the rest of the circle? Simple. The coordinates count how far east and how far north you need to go -- but you can switch the directions around! Instead of going east and north, you could go west and north, or east and south, or west and south -- making up the four quarters of the circle! (The important thing to remember is that you always need one sideways direction and one up/down direction for it to work.)\n\nI hope that's enough for you to get going -- and that it's practical enough for you to draw your circle!\n\n\n\n  1. roughly []\n\n\n4 comments on \u201cMinecraft circles\n\nLeave a Reply\n\n\n\n\nNo spam ever, obviously.\n\nWhere do you teach?\n\nI teach in my home in Abbotsbury Road, Weymouth.\n\n\nOn twitter"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/119227/undecidability-of-two-turing-machines-acting-the-same-way-on-an-input\nText:\nSo I need to find a reduction to the (undecidable) problem of deciding if two Turing machines $M_1$ and $M_2$ behave the same way on an input $x$. \"Behaving the same way\" is defined like this:\n\n$M_1$ and $M_2$ behave the same way on an input $x$, when they both don't halt, or when they both accept $x$ or when they both halt and reject $x$.\n\nI found a reduction from the halting problem which uses the fact that if the Turing machines behave in the same way, than they must have the same language. But this all breaks down in the case that $M_1$ rejects $x$ and $M_2$ doesn't halt, obviously they could have the same language, but they don't act in the same way.\n\nI do think the best way to approach this is by reducing from the halting problem, but I just can't find a valid reduction. Any help would be appreciated.\n\n\nYou were very close to the answer. The special case you mentioned can be handled by hand. Modify the machines resulting from the reduction such that, for each transition, where the machine halts and rejects, let the resulting machine go into an endless loop instead.\n\nNow each machine either accepts or goes into an endless loop. That means, checking if both machines are equivalent on an input $x$ is checking whether both accept the input $x$.\n\n  \u2022 1\n    $\\begingroup$ \"each time the machine halts and rejects\" We don't have this information. The halting problem: $H = \\left\\{ \\left \\langle M \\rangle, x \\: \\right| x \\in L(M) \\right\\} $. Either $M$ accepts $x$ or it doesn't. If $x \\notin L(M)$, $M$ either doesn't halt or it halts and rejects, but we can't tell which. $\\endgroup$ \u2013\u00a0Karla Jan 5 '20 at 20:44\n  \u2022 $\\begingroup$ I probably did not formulate the idea correctly, I meant to look into the transitions function, and instead of transition to the state \"no\", go into an endless loop. I updated the answer correspondingly $\\endgroup$ \u2013\u00a0narek Bojikian Jan 5 '20 at 21:00\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/is-this-the-right-working-out-for-integral-x-3sin-x-dx-x-2-1-x-2-9.171431/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIs this the right working out for integral x^3sin(x)dx/[(x^2+1)(x^2+9)]\n\n  1. May 23, 2007 #1\n    [tex] int^{infty}_{0} \\frac{x^3sinx}{(x^2+1)(x^2+9)} dx [/tex]\n\n    2. Relevant equations\n\n    I understand the value of the integral will be 2 * pi * [sum of residues]\n    and I am also aware of the formula\n\n    Res_{z=z_0} f(z) = [tex] \\frac{g^{m-1} (z_0)}{(m-1)!} [/tex]\n\n    3. The attempt at a solution\n\n    I know the poles exsit and are x= + / - i and x = +/- 3i\n\n    only 2 in the countour and that is x=i and x=3i\n\n    so I get stuck here because all the examples have a bit of working out with a less than or equal to sign and an absolule value, which shows as it goes to zero R goes to inifity... I just don't understand how to set that bit up and why it is necessary, if you know what i'm talking about, can you please explain it to me?\n\n\n  2. jcsd\n  3. May 23, 2007 #2\n\n\n    User Avatar\n    Homework Helper\n\n    ok, to cut a long story short...\n    you wish to apply Cauchy integral theorem to help you doing this integral...because it seems \"hard\" to do if we stay on the real line. Therefore the idea is to analytically continue the function onto the complex plane and treat it as a contour integration. Here you have nice theorems like Cauchy integral theorems, Jordan lemma...etc. to help you do things.\n\n    ok, so you are looking for a \"closed\" contour such that you can apply your theorems. now, however, your initial integral is only from 0 to infty, so you need to make sure that the \"extra piece\" used to close the contour actually vanishes in the desire limit. (that's where the R->infty bit comes from) let me list the procedure:\n\n    1. goto complex plane x->z\n    2. close contour (from a straight line 0->infty, you add an arc of radius R, then return to zero vertically from iR ->0)\n    3. wish to make sure the arc bit disappear in the limit of R->infty, the vertical bit may require more work such as change of variables and other tricks (can't remember off top of my head for this specific case)\n    4. now to see whether the arc really disappear, you do a \"test\" on what happen to the integral\n    [tex]\\int_{\\text{arc}}\\ldots = \\int_{0}^{\\pi/2}\\ldots d\\theta [/tex]\n    where [tex]\\ldots[/tex] means the integral in polar form (with R and theta instead of z)\n    5. you would really want to just look at absolute value because, phases don't matter, only R matters since R->infty eventually\n    6. now, if the function/integrand is bounded from above by some function that goes to zero when R becomes large, then you can say this integral involving the \"arc\" really vanishes (that's where those less than or equal to sign comes from .... i presume)\n    7. once, all auxiliary stuffs are proved to be \"OK\" you can then proceed to solve the problem using those theorems\n  4. May 23, 2007 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Split sin(x) up as (exp(ix)-exp(-ix))/(2i) and split the integral into two parts. For the part with exp(ix) in it you can argue the contribution from the extra part of the contour can be ignored if you close it in the upper half plane. For the exp(-ix) part you will want to close in the lower half plane (use the other set of poles and reverse the overall sign since the contour is going in the opposite direction)."}
{"text": "Retrieved from https://www.physicsforums.com/threads/molar-volume-of-gas-in-function-of-temperature-and-pressure.672926/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMolar volume of gas in function of temperature and pressure\n\n  1. Feb 19, 2013 #1\n\n    Given are two relations for the molar volume. Are they possible? If so, give the formula for v in function of P and T.\n    a) dv =R/P dT - RT/P\u00b2 dP\n    b) dv = 2R/P dT - RT/2P\u00b2 dP\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    If I integrate dv I get \u222bR/P dT - \u222bRT/P\u00b2 dP= RT/P + RT/P (in case a) and 5/4 * RT/P (in case b).\n    does this mean they are both 'possible'?\n\n    intuitively I would say only a is possible\n\n    another thing that struck me - probably resulting from some kind of error I made- was the following discrepancy:\n    say v=RT/P then dv=dv/dT dT + dv/dP dP = R/P dT - RT/P\u00b2 dP.\n    So according to this v=RT/P might well be the solution to the integral \u222bdv (in the case of a).\n  2. jcsd\n  3. Feb 20, 2013 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    The molar volume v is function of P and T: v(T,P). If its first and second partial derivatives exist and continuous its differential is\n\n    dv=\u2202v/\u2202T dT + \u2202v/\u2202P dp.\n\n    an the mixed second partial derivatives are equal:\n\n\n    The integral of dv is independent of he path taken, v is a \"potential\", only if that condition holds.\n\n    In case of the first example, \u2202v/\u2202T=R/P and \u2202v/\u2202P=-RT/P2. The mixed derivatives are equal.\n\n    Now you have \u2202v/\u2202T=R/P, and integrate with respect to T: V=RT/P + integration constant. But that constant can depend on P, so v(T,P)=R/P+f(P). You can find f(P) from the condition that the derivative of v with respect to P has to be -RT/P2:\n    \u2202v/\u2202P= -RT/P2+df/dP=-R/P2, so f=constant.\n\n    Check if the other dv can be the perfect differential of a potential function."}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculating-battery-usage.581732/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculating battery usage?\n\n  1. Feb 26, 2012 #1\n    I have a phone. Since it was last charged, I used it for 8 hours and it was on standby for 16. Now my battery's down to 50%. How much battery did I use when I used the phone?\n\n    I'm thinking it's as simple as x + 2x = 50%.\n  2. jcsd\n  3. Feb 27, 2012 #2\n\n\n    Staff: Mentor\n\n    Maybe or maybe not. You're assuming that the battery draw is the same when the phone is in use versus when it's in standby mode. It's possible and maybe likely that the phone uses less power when it's in standby mode, since it might not need to use power to drive the screen. If so, your equation doesn't take this reduced current draw into account.\n  4. Feb 27, 2012 #3\n    Yes, the screen shuts off in standby mode.\n  5. Feb 27, 2012 #4\n\n\n    User Avatar\n    Science Advisor\n\n    So the phone uses less energy in standby mode. Unfortunately, you do not know how much less. If you knew, for example, that in standby mode you phone uses fraction m of the amount of energy it uses when in use, you could argue that, since it was in standby twice as long as in use, the total energy uses is E+ 2mE= 0.5. That gives (1+ 2m)E=0.5 so the amount of energy used while in use would be E= (0.5)/(1+ 2m).\n\nSimilar Discussions: Calculating battery usage?\n  1. Calculate the variance (Replies: 3)\n\n  2. Log calculation (Replies: 16)"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/64569.html\nText:\nThe Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\n\nDate: 01/14/2004 at 20:44:47\nFrom: Colin\nSubject: proof of the \"quick form\" of derivitives of A*X^N\n\nI've been wondering if there is a proof for the \"quick form\" of the\nderivative in the ax^n case?  We just learned it after using limits to\ncalculate the derivatives.  I like the quick method, but I'm the kind\nof person who likes to know why and how things work.\n\nDate: 01/15/2004 at 09:09:15\nFrom: Doctor Peterson\nSubject: Re: proof of the \"quick form\" of derivitives of A*X^N\n\nHi, Colin.\n\nWe first define derivatives using limits, then we apply that\ndefinition to find simple rules for the derivatives of common\nfunctions, and then rarely go back to the definition again.  The main\nvalue of the definition is to allow us to prove the rules and other\ntheorems about derivatives.\n\nLet's look at the function f(x) = ax^n. The derivative is\n\n       f(x+h) - f(x)        a(x+h)^n - ax^n\n  h->0       h         h->0        h\n\nAt this point you need the binomial expansion; among other places, you\ncan find this discussed in our FAQ on Pascal's triangle.  Or see\n\n  Binomial Expansions and Pascal's Triangle \n\nAll that matters to us is the first two terms:\n\n  (a+b)^n = a^n + n a^(n-1) b + n(n-1)/2 a^(n-2) b^2 + ...\n\nwhere the rest of the terms have whole coefficients with decreasing \npowers of a and increasing powers of b.  Setting a = x and b = h, and \nputting this into the derivative, we get\n\n       a[x^n + nx^(n-1)h + n(n-1)/2 x^(n-2) h^2 + ...] - ax^n\n  h->0                          h\n\nNote that the first term of the expansion will cancel with the -ax^n\nat the end, leaving\n\n       anx^(n-1)h + an(n-1)/2 x^(n-2) h^2 + ...\n  h->0                   h\n\nUp to this point we still have the form 0/0, which means there's more \nto do.  But now we can divide by h.  The unshown terms above all have\na factor of at least h^2, so we get\n\n   = lim [anx^(n-1) + h(an(n-1)/2 x^n-2 + ...) ]\n\n   = anx^(n-1)\n\nsince the term with a factor of h goes to zero.\n\nThe main idea of limits is that when we simplify a function, as by \ndividing by h here, we get a continuous function that is equivalent to\nthe original everywhere except where the latter was not defined;\ntherefore the new function's VALUE at that point is the same as the \nLIMIT of the original function.  In effect, we are \"filling in the \nhole\".  Not all limits can be solved that easily, but when it can be \ndone, it makes the work very easy.  And now that we've done it, we \ndon't need to bother with limits when we need to find the derivative \nof a polynomial.\n\n\n- Doctor Peterson, The Math Forum \n\nDate: 01/20/2004 at 15:54:01\nFrom: Colin\nSubject: Thank you (proof of the \"quick form\" of derivitives of A*X^N)\n\nThank you very much!  This is very cool, and now I understand why the\n'quick method' actually works.  Thanks for taking the time to answer\nmy question.\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM"}
{"text": "Retrieved from https://www.physicsforums.com/threads/f-ma-2009-14-momentum-quick-conceptual-question.667948/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nF = MA 2009 # 14 (Momentum Quick Conceptual Question)\n\n  1. Jan 29, 2013 #1\n    See # 14\n\n    2. Relevant equations\n    None really, perhaps keep in mind that\n    1) p is conserved in the absence of external forces\n    2) L is conserved in the absence of external torque\n    3) Mech E is conserved if no energy is lost due to external forces\n\n    3. The attempt at a solution\n    I'm not sure how to attack this problem. My reasoning was that the bullet, as it is embedded into the block, has most of its velocity absorbed by the interior of the block (not rigorous at all). This means that the block does not move at the velocity it should and thus all A, B, C, D are false.\n\n    How can I do this rigorously?\n  2. jcsd\n  3. Jan 29, 2013 #2\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    14. A wooden block (mass M) is hung from a peg by a massless rope. A speeding bullet (with mass m and initial speed v0) collides with the block at time t = 0 and embeds in it. Let S be the system consisting of the block and bullet. Which quantities are conserved between t = \u221210 s and t = +10 s?\n\n    (A) The total linear momentum of S.\n    (B) The horizontal component of the linear momentum of S.\n    (C) The mechanical energy of S.\n    (D) The angular momentum of S as measured about a perpendicular axis through the peg.\n    (E) None of the above are conserved.\n\n    ... and then what happens?\n\n    Usually it is quicker to take each option one at a time.\n    But you have a nice list ...\n    ... \"external\" to what? Anyway - rephrase your list as questions:\n\n    1. are their any external forces to the system being brought to bear?\n    2. are their any external torques to the rotating part?\n    3. is their any energy loss (note: does not have to be due to \"external forces\")?\n    ... from those answers you have characterized the system so the options will make sense.\n\n    Science is not about knowing answers, it is about asking uncomfortable questions.\n    Learning how to ask hard questions is basically the main point of science education.\n  4. Jan 29, 2013 #3\n    I thought\n    1) no external forces\n    2) no external torque\n    3) energy loss due to heat/friction inside the block\n\n    So the fact that there's an energy loss due to thermal energy negates everything?\n  5. Jan 30, 2013 #4\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    Well... no: that's not what your list is telling you. You can conserve momentum and not (mech) energy ...\n\n    You want to take another look at #2, at t<0 what is the angular momentum? What is it at t>0? Are these numbers the same?\n\n    Now compare your answers to the three questions with each option provided.\n    Last edited: Jan 30, 2013\n  6. Jan 30, 2013 #5\n\n\n    User Avatar\n\n    UPDATE: I had misread the problem, nevermind what I said before :P\n\n    UPDATE2: I read it right, I erased my comment for nothing \u00ac\u00ac Will re-write. Sorry.\n\n    Something like that: In these \"simple\" problems, forces essentially come from gravity or contact. An external force will come from contact to the external world (or existance of gravity with an external object), and an external torque will have to be produced by that external force.\n\n    Is any part of the system (bullet + block) in contact to the external world (rope, Earth, etc.)? Does if feel a force from those parts? Does this force produce a torque about an axis through the peg? :)\n\n    Also, notice that the problem considers a \"long\" time interval before and after the collision. Try to visualize how the system will behave when the block is hit by the bullet, it really helps!\n    Last edited: Jan 30, 2013\n  7. Jan 30, 2013 #6\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    Case in point - let the bullet be mass m and speed v\n    block is mass M, initial speed 0\n    if the final speed of m+M is u, then:\n\n    conserving momentum: ##mv = (m+M)u##\n\n    this means that ##u=mv/(m+M)##\n    ... so the final speed is slower than the initial speed like you intuited - but the overall momentum still stays the same.\n\n    now look at the kinetic energy:\n\n    initially: ##K_i = \\frac{1}{2}mv^2##\n    finally: ##K_f = \\frac{1}{2}(m+M)u^2 = \\frac{1}{2}(m+M)[mv/(m+M)]^2 =\\frac{1}{2}(mv)^2/(m+M)##\n\n    comparing them: $$\\frac{K_f}{K_i} = \\frac{m}{m+M}$$ i.e. ##K_i > K_f## and kinetic energy is not conserved even though momentum is.\n\n    What happened to it?\n    Well it got lost in heat, sound and so on... which was your original thought.\n\n    Note: fgb has a valid point about how gravity (etc) applies here though - modifying the above.\n  8. Jan 30, 2013 #7\n\n\n    User Avatar\n\n    At first I had thought that the correct answer was D. Since as the block moves it feels a force due to the rope (which has a horizontal component after the rope tilts a little) there are external forces and no conservation of linear momentum. Tricky question since you are told to consider a fairly large time interval - momentum is still conserved during and short after the collision, but not a little later as the block moves.\n\n    Mechanical energy is lost in the collision due to deformation, as the bullet sticks inside the block.\n\n    The force due to the rope (the external force), also, always passes through the axis, so it does not produce an external torque and at first I thought angular momentum is conserved. However, taking gravity into account, gravity indeed produces an external torque and therefore no quantity is conserved, so I would say the correct answer is E.\n  9. Jan 30, 2013 #8\n\n    Simon Bridge\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    Actually the question kinda defines \"before\" as at the instant t=-10s, and \"after\" as the instant t=+10s. Anyhow: if we include gravity - then there is an external force messing with the system. Anything with momentum being conserved will get messed up. That leaves energy - but the collision is inelastic - and \"none of the above\".\n\n    I had misread the question - I thought it referred to the collision at t=0, which is where it usually appears.\n\n    To be super-rigorous, you'd have to construct the equations for each case.\n    However, most of the questions in this paper can be tackled by just going through each of the alternatives one at a time after stopping to think of the processes involved. There's usually two options that look likely, which is where you look harder.\n\nSimilar Discussions: F = MA 2009 # 14 (Momentum Quick Conceptual Question)\n  1. 2009 f=ma #24 (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inequalities-with-two-different-fractions-which-include-x-in-the-denominator.664277/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nInequalities with two different fractions which include x in the denominator.\n\n  1. Jan 14, 2013 #1\n\n    (x-2)/(x+3) less than (x+1)/(x)\n\n    3. The attempt at a solution\n\n    I broke it up into cases.\n\n    When x+3 less than 0 and x less than 0\n\n    and then when both are positive, when one is positive and the other is negative and then the other way around.\n\n    I'm not sure if that's the right way though. I was thinking that maybe you can say:\n\n    (x+3)(x) less than 0\n\n    and a second case\n\n    (x+3)(x) greater than 0\n  2. jcsd\n  3. Jan 14, 2013 #2\n    (x+3) and x are not independent. You have to consider the value ranges of x.\n\n    Perhaps a good place to start is to consider the value of each expression as they pass the \"difficult\" value of x in each case, and how those behave as x is large-negative and large-positive in each case again.\n\n    There are three relevant ranges of x, one of which is a little trickier than the other two.\n  4. Jan 14, 2013 #3\n    So you mean to say x\u2260-3 and x\u22600 and x\u2260 some other number?\n  5. Jan 14, 2013 #4\n    One of the ranges is x < -3\n  6. Jan 14, 2013 #5\n    You mean x < -3 is not in the 'solution set' right? x is -4 makes it not a true statement.\n\n    After trying the first method again (the textbook's method except they didn't show any examples with two fractions both with x in the denominator) I found that x > -3 , x cannot equal -1/2 , 0\n  7. Jan 14, 2013 #6\n    x can equal anything. Of the two expressions being considered in the question, each one is undefined at one value of x (which you already have indicated you know).\n\n    {x<-3} is a range of values where both expressions are well-defined. You might like to explore this range with some values of x (like -4, -5, -10) to see how the functions are behaving.\n  8. Jan 14, 2013 #7\n    When you input -4 for x, you get 6 < 0.75 which means that x < -3 is not a part of the solution right?\n\n    When you input -1/2 for x, you get -1 < -1 which again is not true.\n\n    Although plugging values is good to check answers, I wanted to know if my method was correct. I don't have the answer to this question though.\n\n    What I did was solve for x under all circumstances. When x+3 > 0 and x > 0 and then when x+3 < 0 and x < 0 and then when x+3 > 0 but x < 0 then when x+3 < 0 and x > 0\n\n    The idea behind this is that when solving for x, multiplying by -(x+3) or -(x) would switch the inequality sign. So the possibility that one or the other or both are positive or negative becomes an issue. Is this a correct way to solve this inequality?\n  9. Jan 14, 2013 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    It seems a lot easier to write [itex]\\displaystyle \\ \\ \\frac{x-2}{x+3}<\\frac{x+1}{x}[/itex]\n\n    as the equivalent inequality: [itex]\\displaystyle \\ \\ \\frac{x-2}{x+3}-\\frac{x+1}{x}<0\\ .[/itex]\n\n    Then use a common denominator to combine the two fractions into one fraction.\n  10. Jan 14, 2013 #9\n    Don't you still have to consider that x + 3 and x could be negative?\n  11. Jan 14, 2013 #10\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, it is really the same thing.\n\n    Well, x+3< 0 is the same as x< -3 and, then, of course, x< 0.\n    The three cases you want to consider are\n    x< -3 when x+3< 0 and x< 0 are BOTH true.\n\n    [itex]-3\\le x< 0[/itex] when [itex]x+ 3\\le 0[/itex] and x< 0.\n\n    [itex]0\\le x[/itex] when both x+3> 0 and [itex]x\\ge 0[/itex].\n  12. Jan 14, 2013 #11\n    Yes, I quickly found out that when both are negative and when x+3<0 and x>0 there are no solutions. Maybe in the future I will have the instinct to realize that from the start. But for now I am just trying to get the medthod down.\n\n    I got the same answer by putting both terms together and finding the commoj denomintor. Surely the answer must be correct.\n\n    I thank you all for your help in rehabilitating my mathematics.\n  13. Jan 15, 2013 #12\n    You're not done yet.\n\n    It's possible to establish the answer for the ranges {x<-3} and {x>0} just by considering function values relative to 1 (= x/x).\n\n    However, the intermediate range {-3<x<0} is more complicated. Look at both function values at -2.9 and at -0.1 which should tell you there is more to discover.\n    Last edited: Jan 15, 2013\n  14. Jan 15, 2013 #13\n    Are you supposed to state that there are asymptotes at -3 and 0 ?\n\n    x cannot be -1/2 is that what you're referring to?\n  15. Jan 15, 2013 #14\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    The resulting inequality is: [itex]\\displaystyle \\ \\ \\frac{-6x-3}{x(x+3)}<0\\ .[/itex]\n\n    This simplifies to: [itex]\\displaystyle \\ \\ \\frac{2x+1}{x(x+3)}>0\\ .[/itex]\n\n    You have three factors, one in the numerator and two in the denominator. Either all three must be positive, or one must be positive and two of them negative.\n  16. Jan 15, 2013 #15\n    There is another range for x which satisfies the condition.\n\n    Both original expressions - and the combined expression too - are valid for ##x = -\\frac 12##\n\n    SammyS's simplified expression can also be expressed as $$ \\frac{x+\\frac 12}{x(x+3)}>0 $$\n  17. Jan 15, 2013 #16\n    It seems like I kept making careless errors. Thank you all for being patient with me.\n\n    -3 < x < -1/2 , x > 0\n\n    That should be the right answer.\n  18. Jan 16, 2013 #17\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    You want to determine when [itex](x-2)/(x+3)< (x+1)/(x)[/itex].\n\n    As I said before, since we clearly want to multiply both sides by x+ 3 and x, to clear the fractions, we need to consider when they are positive of negative. So consider 3 cases:\n    1) x< -3. Then both x+ 3 and x are negative. Multiplying the above inequality by x(x+ 3) is multiplying by a positive number (the product of two negatives) so the direction of inequality does not change. [itex](x- 2)(x)< (x+ 3)(x+ 1)[/itex]. [itex]x^2- 2x< x^2+ 4x+ 3[/itex]. Subtract [itex]x^2[/itex] from both sides to get [itex]-2x< 4x+ 3[/itex] so that [itex]0< 6x+ 3= 3(x+ 1)[/itex]. Dividing both sides by the positive number 3, we have [itex]0< x+ 1[/itex] or [itex]x< -1[/itex] which can't happen when x< -3.\n\n    2) -3< x< 0. Now x+ 3 is positive but x is still negative. Multiplying both sides by x(x+ 3) is now multiplying by a negative number and changes the direction of the inequality: [itex](x- 2)(x)> (x+ 3)(x+ 1)[/itex]. The same calculations as before go through with the changed inequality sign: [itex]x< -2[/itex]. That tells us that the orignal inequality is true for [itex]-3< x< -2[/itex].\n\n    3) x> 0. Now both x+ 3 and x are positive so j=multiplying both sides of the inequality by x(x+ 3) does not change the sign: [itex](x- 2)(x)< (x+ 3)(x+ 1)[/itex] and again we get [itex]x> -1[/itex]. Of course that is true for all x> 0 so we have the inequality true for all x> 0.\n\n    We have, so far, that the inequality is true for -3< x< -2 and x> 0. You should also check to see if it is true at x= -3, x= -2, and x= 0.\n    Last edited: Jan 17, 2013\n  19. Jan 16, 2013 #18\n    I think you made a mistake in the firsf case where you ended up with 3(x+2)\n\n    Also the question didn't include any inequality symbols with equal signs. (No line under the inequality is what I mean.\n  20. Jan 17, 2013 #19\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Oh, bother! Thanks. I have gone back and edited my post.\n  21. Jan 17, 2013 #20\n    ## (x\u22122)(x) > (x+3)(x+1) ##\n\n    ## x^2-2x > x^2 +4x +3 ##\n\n    ## -2x > 4x +3 ##\n\n    ## 0 > 6x +3 ##\n\n    ## x < -\\frac 36 = -\\frac 12 ##"}
{"text": "Retrieved from https://www.physicsforums.com/threads/unitarily-equivalent.591586/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nUnitarily equivalent\n\n  1. Mar 29, 2012 #1\n    I've had the flu all week.\n\n    Of course, the book defines unitary equivalent, but it doesn't talk about an efficient method of determining if two matrices are unitarily equivalent.\n\n    Is there an efficient way to determine if these matrices are unitarily equivalent?\n\n    0 & 1 & 0\\\\\n    -1 & 0 &0 \\\\\n    0 &0 &1\n\n    1 & 0 & 0\\\\\n    0 & i &0 \\\\\n    0 &0 &-i\n  2. jcsd\n  3. Mar 29, 2012 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n    2016 Award\n\n    You can easily find the eigenvalues, no?\n  4. Mar 29, 2012 #3\n    How does that relate to unitary equivalence?\n  5. Mar 29, 2012 #4\n    I found that A and B are unitarily equivalent if they have the same sets of eigenvalues, counting multiplicity.\n\n    A = P*BP (unitarily equivalent)\n\n    det(A) = det(P*BP) = det(P*)det(B)det(P) = det(P*)det(P)det(B) = det(B)\n    det(A) = det(B)\n\n    Their characteristic polynomials must be equal.\n  6. Mar 29, 2012 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    No, that is not true. The matrices\n    [tex]A= \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}[/tex]\n    [tex]B= \\begin{bmatrix}1 & 1 \\\\ 0 & 1\\end{bmatrix}[/tex]\n    have the same eigenvalues (1 with multiplicity two) but are not unitarily equivalent because they do not have the same eigenvectors. A has every vector as eigenvector while B has only multiples of <1, 0> as eigenvectors.\n\n    Two matrices are \"unitarily equivalent\" if and only if they have the same eigenvalues and the same corresponding eigenvectors.\n\n  7. Mar 29, 2012 #6\n    Okay, so I found the eigenvalues of each of the matrices: 1, -i, +i. Now I have the tedious job of finding the eigenvectors. -_-\n  8. Mar 29, 2012 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Halls is definitely wrong to say that they have to have the same eigenvectors. You just have to have the same number of linearly independent eigenvectors for every eigenvalue. You have three distinct eigenvalues. That means you don't have to compute the eigenvectors. Why?\n    Last edited: Mar 29, 2012\n  9. Mar 29, 2012 #8\n    Ah, you're right. The dimensions of the eigenspaces are equal - 3."}
{"text": "Retrieved from https://www.physicsforums.com/threads/differential-form-of-gauss-theorem-with-dielectrics.754928/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nDifferential form of Gauss' theorem with dielectrics\n\n  1. May 23, 2014 #1\n    Hi all,\n    I'm stuck on this incompatibility within the differential form of Gauss' thearem (or Maxwell's first equation) with dielectrics.\n\n\n\n    But with a linear, homogeneous, isotropic dielectric we have\n\n\n    And therefore we get\n\n    [itex]\\vec{\\nabla}\\cdot\\vec{E}=\\frac{\\rho_{free}}{\\epsilon_{0}}[/itex] (1)\n\n    But using the general formula we have\n\n    [itex]\\vec{\\nabla}\\cdot\\epsilon_{0}\\vec{E} + \\vec{\\nabla}\\cdot\\vec{P}=\\rho_{free}[/itex]\n\n\n    So ([itex]1+\\chi_e=\\epsilon_r[/itex], [itex]\\epsilon_0\\cdot\\epsilon_r=\\epsilon[/itex])\n\n\n    which means\n\n\n    and is incompatible with (1).\n\n    Where is the mistake?\n\n    Thank you in advance,\n  2. jcsd\n  3. May 23, 2014 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Hi, Ocirne94. Welcome to PF!\n\n    I don't think there is any mistake. But you did assume that ##\\rho_{bound} = 0##. You have essentially proven an interesting fact about linear, homogeneous, and isotropic dielectrics whenever ##\\rho_{bound} = 0##. There is only one way for your two equations for ##\\vec{\\nabla} \\cdot \\vec{E}## to be compatible. What is it?\n  4. May 23, 2014 #3\n    where did [itex]-\\vec{\\nabla}\\cdot\\vec{P}=0=\\rho_{bound}[/itex] come from?\n  5. May 23, 2014 #4\n    thank you for your answers.\n\n    There are two ways for those two equations to be compatible inside the dielectric: the first is that\n    [itex]\\epsilon = \\epsilon_0[/itex]\n    which I would interpret as saying that the dielectric isn't there.\n\n    The other one is that the divergence is zero in both cases, which implies\n    inside any linear, homogenous and isotropic dielectric.\n    In other words, no LIH dielectric can have free electrons inside its volume.\n    Now this is somewhat disturbing (so much that in three hours of messing around the problem I have never considered this possibility), but eventually consistent with the fact that\n    and I have started from\n\n    Thank you very much for your illuminating answer! :smile:\n  6. May 23, 2014 #5\n    You still haven't explained why you think the divergent of P is zero.\n  7. May 23, 2014 #6\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Keep in mind that you assumed ##\\rho_{bound} = 0## in your analysis. So, what you showed is that if ##\\rho_{bound} = 0## then ##\\rho_{free} = 0## also.\n\n    You should be able to show the converse.\n\n    So, in a \"Class A\" dielectric (i.e., linear, homogeneous, and isotropic), ##\\rho_{free} = 0## \u21d4 ##\\rho_{bound} = 0##.\n\n    But, as dauto is suggesting, it is not necessarily true that these charge densities are both zero. But if one is zero, the other is zero. If one is nonzero, then the other is nonzero. You could certainly imagine that some free charge density is embedded inside a dielectric, so that ## \\rho_{free} \\neq 0##. Then you would also have ##\\rho_{bound} \\neq 0##.\n\n    You might try to show ##\\rho_{bound} = - \\frac{\\epsilon_r-1}{\\epsilon_r} \\rho_{free}##.\n  8. May 24, 2014 #7\n    I was taught that (as a rough model with some approximations) within a LIH dielectric the dipoles get a uniform orientation: this implies that no net bound charge can be found inside the dielectric's volume, and only surface charge is present.\n\n    I definitely agree that the maths allows nonzero charge densities, but in this case I face a problem with definitions: (quoting from my and many other textbooks), \"in dielectrics all the charges are bound to specific atoms and molecules\".\n    So considering a free charge density within a dielectric, hence a bound charge density, looks like violating the definition: this likely enters the domain of the microscopic structure of matter and of the particles' interaction, but I would say that the volume taken by a free charge density within a dielectric cannot be considered dielectric.\n  9. May 24, 2014 #8\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Free charge in a dielectric is just additional charge added into the material. For example, you could imagine an electron beam that sends electrons into a dielectric material and that these electrons become entrapped in the material with some volume charge density \u03c1f that might vary with position inside the material. These electrons would be considered \"free charge\" that is not due to polarization of the molecules of the dielectric. Admittedly, this is not a typical situation for dielectric materials. But in such a situation I think you would consider the free charge and dielectric as occupying the same region.\n\n    If you embed small, but macroscopic-sized charged particles into a dielectric, then I think your are right that you could consider these particles as not occupying the same region as the dielectric but, rather, as particles that are surrounded by the dielectric material.\n\n    Anyway, you will see problems in standard textbooks where you have dielectrics that contain some specified free volume charge density.\n  10. May 24, 2014 #9\n    That's only true if the electric field is uniform. If the electric field varies from spot to spot in the dielectric - that is it is a function of the coordinates - than there will be non-zero net bound charges in the dielectric. if there are embedded \"free\" charges in the dielectric those free charges produce no uniform electric field that induce a net bound charge in the dielectric that partially shields the free charge.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Differential form of Gauss' theorem with dielectrics"}
{"text": "Retrieved from https://www.physicsforums.com/threads/integration-by-parts.68260/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntegration by parts\n\n  1. Mar 22, 2005 #1\n    ok i`m really struggling with the concept.\n    I've been asked to find the indefinite integral of;\n\n    [tex] \\int \\frac{x^2}{(2+ x^3)} dx [/tex]\n\n    so before i beg for the answer could someone confirm that i`ve got the right rule to solve this;\n\n    [tex] \\int u(x) v'(x) = [ u(x) v(x)] - \\int v(x) u'(x) [/tex]\n\n    if this is right would you mind giving a suggestion to what u(x) to use?\n\n    p.s. i may have to edit this if latex doesn`t come out right I've been having trouble with it and only jointed the forum a few day's ago!\n    Last edited: Mar 22, 2005\n  2. jcsd\n  3. Mar 22, 2005 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, that is the correct formula (it's surely in your text book), but I don't see any good reason for using integration by parts. That's a fairly standard anti-derivative: look up \"arctangent\".\n  4. Mar 22, 2005 #3\n    I`ve just edited it. Now it`s integration by parts! see I`m getting all flustered\n  5. Mar 22, 2005 #4\n    Actually, you still don't need integration by parts. Substituting [itex]u = x^3[/itex] will simplify it to a standard form.\n\n    Anyways, since differentiation is in some sense the inverse operation to integration, every differentiation rule yields an integration rule. I'm sure you remember the product rule:\n\n    [tex] \\frac{d}{dx}(f(x) g(x)) = f^\\prime (x) g(x) + g^\\prime (x) f(x)[/tex]\n\n    Rearraging the equation above gives\n\n    [tex] f(x) g^\\prime (x) = \\left[f(x) g(x)\\right]^\\prime - f^\\prime(x)g(x)[/tex]\n\n    And integrating both sides with respect to x gives\n\n    [tex] \\int f(x) g^\\prime (x) \\ dx = \\int \\left(\\frac{d}{dx} (f(x) g(x)) - f^\\prime(x)g(x)\\right) \\ dx[/tex]\n\n    but certainly, [tex] \\int \\frac{d}{dx}(f(x)g(x)) \\ dx = f(x)g(x)[/tex], so this just reduces to\n\n    [tex] \\int f(x)g^\\prime (x) \\ dx = f(x)g(x) - \\int g(x) f^\\prime (x) \\ dx[/tex]\n\n    which is what your teacher probably called the formula for integration by parts.\n    Last edited: Mar 22, 2005\n  6. Mar 22, 2005 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    [tex] x^{2}dx=\\frac{1}{3}d(2+x^{3}) [/tex] so the integration is simple...\n\n  7. Mar 22, 2005 #6\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    As others have said, you don't have to use integration by parts to solve this, but .....\n\n    Pick the term whose derivative will eventually go to zero (the soonest). In this case, it's x^2. First derivative is 2x. Second derivative is 2. Third derivative is 0.\n\nSimilar Discussions: Integration by parts"}
{"text": "Retrieved from https://www.physicsforums.com/threads/composition-of-infinite-deformation-retracts.620651/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nComposition of infinite deformation retracts\n\n  1. Jul 13, 2012 #1\n    I'm trying to give an answer to the following problem, I hope someone could come in help! Consider a smooth [itex]n[/itex]-dimensional manifold [itex]M[/itex] with smooth (nonempty) boundary [itex]\\partial M[/itex], and suppose given a function [itex]f: M\\setminus \\partial M \\to \\mathbb{R}[/itex] (which one can assume to be differentiable) satisfying the property that there exists [itex]A > 0[/itex] such that for any [itex]A \\le \\alpha \\le \\beta[/itex], one has that the sublevel [itex]\\left\\{F\\le -\\beta\\right\\}[/itex] is a deformation retract of [itex]\\left\\{F\\le -\\alpha \\right\\}[/itex]. The question is: is it true that [itex]\\partial M[/itex] is a deformation retract of [itex]\\left\\{F\\le -A\\right\\}\\cup \\partial M[/itex] (i.e., is it true that a composition of infinitely many of such deformation retracts is a deformation retract)?\n  2. jcsd\n  3. Jul 14, 2012 #2\n    I don't have a full answer for you, but as a rule of thumb, infinite compositions of maps don't necessarily retain the properties of the individual maps. I think in this case a compactness argument might work, although I think either I'm missing something from your statement, or it's incomplete. Do we know what [itex]f\\big|_{\\partial M}[/itex] is? I was assuming it's identically zero, but I realize the problem doesn't say, nor does it say anything about what happens on the levels between zero and A.\n  4. Jul 15, 2012 #3\n    First of all, thank you for your reply. Next, you're right, I forgot an hypothesis that could be crucial: [itex]f(p)\\to -\\infty[/itex] as [itex]p[/itex] approaches the boundary [itex]\\partial M[/itex]. Could this do any difference?\n    Maybe, (but I don't know if this makes any sense...) an idea could be to work with the extended function [itex]\\hat{f}: M \\to \\mathbb{R}^*[/itex], where [itex]\\mathbb{R}^*:=\\mathbb{R}\\cup \\left\\{\\infty\\right\\}[/itex] (the Alexandroff compactification of [itex]\\mathbb{R}[/itex]), [itex]\\hat{f}(p):=f(p)[/itex] if [itex]p \\in M\\setminus \\partial M[/itex] and [itex]\\hat{f}:=\\infty[/itex] if [itex]f \\in \\partial M[/itex] (hoping that this [itex]\\hat{f}[/itex] inherits some regularity from [itex]f[/itex]...). In this way, [itex]\\partial M[/itex] would become the level [itex]\\left\\{f=\\infty\\right\\}[/itex]...\n  5. Jul 15, 2012 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Slice the north polar ice cap off of a sphere to get a manifold with boundary. Then remove the South pole. Let f be the reciprocal of the minimum of the distances along a great circles to the South pole and to the edge of the removed polar cap. This function is continuous and f(p) -> -\u221e as p approaches the edge of the removed ice cap.\n\n    But but the set,\n\n    f < - the distance of the meridian where both distances are the same\n\n    does not deform onto the edge circle of the ice cap.\n\n    it seems that you need to assume that f(p) -> -\u221e if and only if p approaches the boundary.\n    Last edited: Jul 15, 2012\n  6. Jul 15, 2012 #5\n    I really apologize with all of you for the incompleteness of the provided hypothesis. Actually, the manifold [itex]M[/itex] is simply connected as well as its boundary [itex]\\partial M[/itex], and these restrictions seems to exclude the latter counterexample (if I'm not wrong).\n    And (finally) these are all the hypothesis I have...\n\nSimilar Discussions: Composition of infinite deformation retracts\n  1. Deformation retract (Replies: 9)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/equations-of-speed-and-position-under-a-constant-force.86698/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEquations of speed and position under a constant force\n\n  1. Aug 28, 2005 #1\n    there's a question in my book that says \"If you jump upward with a speed of 2 m/s, how long will it take before you stop rising?\" anyone have a hint as to how i would go about answering this?\n  2. jcsd\n  3. Aug 28, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Use the equations of speed and position under a constant force (in this case the gravitational force).\n\n    v(t) = v_0 + a*t\n    x(t) = x_0 + v_0*t + 0.5at\u00b2\n  4. Aug 29, 2005 #3\n    Assuming no air resistance, right?\n    Since you're jumping [itex] vertically [/itex],\n    *Set your initial position at y=0, then apply that equation\n    [tex] y\\left( t \\right) = t\\left( {2\\frac{m}{s}} \\right) - \\frac{{t^2 }}{2}\\left( {9.8\\frac{m}{{s^2 }}} \\right) [/tex].\n    Simply then, set [itex] y\\left( t \\right) = 0s [/tex] to find your jump duration (*Note: [itex] t \\ne 0s [/itex] :smile: )\n\n    The answer is 0.41 seconds :biggrin:\n  5. Aug 29, 2005 #4\n\n\n    User Avatar\n    Homework Helper\n\n    1) Bomba's \"jump duration\" is 2x as long as the\n    duration of upward travel. No big deal ...\n\n\n    2) It is important to find out how to READ the WORDS of a question!\n    Otherwise it's going to be a long, hard, confusing, frustrating year.\n    The key is knowing what event-condition tells you to stop timing...\n    here, \"stop rising\" is translated into \"upward speed = 0\".\n\n    So Quasar's first equation is all you need to answer this question.\n    Bomba's approach will get you the right answer\n    (if you divide by 2, and if there's no air resistance)\n    but can't be generalized to, say, when does a police car catch up.\n    Quasar's APPROACH even works (slight mod of eq'n) if there IS drag."}
{"text": "Retrieved from https://www.physicsforums.com/threads/y-x-2-1-and-y-x-2-tangent.67554/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nY=(x^2) +1 and y = - (x^2)? tangent\n\n  1. Mar 16, 2005 #1\n    Find the equations of the lines that are tangent to both curves simultaneously:y=(x^2) +1 and y = - (x^2)? :eek:\n  2. jcsd\n  3. Mar 16, 2005 #2\n    Find the equations for the tangent lines to both curves and set them equal to each other. You will find when the slope of the tangents are equal and then can make an equation(s) of of it.\n  4. Mar 17, 2005 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Jameson is correct but it's a bit more complicated than he implies.\n\n    Suppose a line is tangent to y= x2+ 1 at (x0,x02+ 1) and tangent to y= -x2 at (x1,-x12).\n    Any (non-vertical) line can be written as y= mx+ b. m is equal to the derivative of the functions at the given points: m= 2x0= -2x1 so x1= -x0. We must have x02+1= (2x0)x0+ 1 or b= 1- x02. We must also have -x12= (-2x1)x1+ b or b= x12. That is, b= x12= 1- x02. But since x1= -x0, x12= x02 so 1- x02= x02.\n\n    Solve that for x0 and then you can find m and b.\n\n    Because of the squares, there are, of course, two symmetric solutions,.\n    Last edited: Mar 17, 2005\n\nSimilar Discussions: Y=(x^2) +1 and y = - (x^2)? tangent\n  1. Integral of 2/(y+1)? (Replies: 4)\n\n  2. Integrate ln(4+y^2)dy? (Replies: 8)\n\n  3. D/dx y^2 help (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/investigating-max-and-min-value-of-a-function.222944/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nInvestigating max and min value of a function\n\n  1. Mar 19, 2008 #1\n\n    [tex] f(x) = (1/2)sin2x + cosx [/tex]\n\n\n    [tex] f^2 min +f^2 max = ? [/tex]\n\n    2. Relevant equations\n\n    Differentiation not allowed... only by transformations and analysis.\n\n    3. The attempt at a solution\n\n    I am confused by what it means by f^2 min +f^2 max... does it imply we have to find max and min values seperately, square them and add them? Or does this formulation imply we can directly get the required value?\n\n    Do we have to square the function before investigating it?\n  2. jcsd\n  3. Mar 20, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n\n    I think what they're asking you to do is find the sum of the squares of the maximum and minimum values of this function.\n\n    I'd suggest first writing out what sin(2x) is: you'll find that f(x) can be expressed as a product of two factors. It should be reasonably straightforward to see what the greatest and least values of that product are. Can f(x) be zero?\n  4. Mar 20, 2008 #3\n    you need to take the derivative of that..\n\n\n    after that you solve f'(x)=0\n    find the extreme points and put the y values in the asked equation\n\n  5. Mar 20, 2008 #4\n\n\n    User Avatar\n    Homework Helper\n\n    The problem statement says no differentiation allowed...\n\n    (If it were, the derivative would be f'(x)=1*cos2x - sinx .)\n    Last edited: Mar 20, 2008\n  6. Mar 21, 2008 #5\n    i'm getting\n\n    [tex]f(x) = cosx(1+sinx)[/tex]\n\n    ok i got min value = 0 (the problem says 0 <= x <= pi/2)\n    how do we get the max value of the product?\n  7. Mar 21, 2008 #6\n    you have a point in x=pi/2 +pi*k\n    and for x=3/4*pi +2pi*k\n\n    substitute them in the fuction and find their y values\n    Last edited: Mar 21, 2008\n  8. Mar 21, 2008 #7\n    how does that work?\n  9. Mar 21, 2008 #8\n\n\n    User Avatar\n    Homework Helper\n\n    If the interval is [0, pi/2], then you don't have to worry about the other periodic values of sine and cosine. (You didn't mention the interval earlier...)\n\n    The minimum is zero at pi/2 because of the cosine term. For the maximum, you could either look at the terms in f(x) or square your result for f(x) first. In any case, using x = 0 would give you\n    f(0) = 1, but there's a place where we can do better. The problem with the endpoints is that sine is high when cosine is low and vice versa. What value of x gives both fairly high values for sine and cosine? (Consider graphs of those functions.)\n  10. Mar 22, 2008 #9\n    pi/4 gives equal values for sine and cosine... however, how do we know there isn't a value thats higher? i think there may be a more rigorous proof...\n\n    e.g. on another similar problem i could obtain a quadratic equation containing f(x) in a constant term (by squaring function) and getting something like:\n\n    [tex] ax^2 +bx + c = f^2(x) [/tex]\n\n    [tex] ax^2 +bx + (c - f^2(x)) = 0 [/tex]\n\n    [tex] b^2 - 4a(c - f^2(x)) >or= 0 [/tex] (for real f(x))\n\n    thus obtaining min and max values simultaneously...\n\n    on this example, on squaring i get a quartic equation on sin(x)... i'm unable to bring it to a simpler (quadratic) form or otherwise...\n    Last edited: Mar 22, 2008\n  11. Mar 22, 2008 #10\n\n\n    User Avatar\n    Homework Helper\n\n    Maybe we shouldn't look at the quartic polynomial, but rather the factored form. The function squared is\n\n    [tex] (cos x)^{2} (1+sin x)^{2} = (1 - [sin x]^{2})(1+sin x)^{2} = (1 - sin x)(1+sin x)^{3}\n\n    So we make the substitution t = sin x and ask for the maximum on the interval [0,1] of\n\n    [tex] (1 - t)(1+ t)^{3}\n\n    [I'm still thinking about how to solve this without calculus. (The maximum turns out to occur at sin x = 1/2 , BTW, not {sqrt(2)}/2 , as I'd earlier thought.) The instruction \"use transformations and analysis\" isn't very descriptive, so I'm still trying out ideas...]\n    Last edited: Mar 22, 2008\n\nHave something to add?\n\nSimilar Discussions: Investigating max and min value of a function"}
{"text": "Retrieved from http://math.stackexchange.com/questions/23228/which-is-bigger-9999999999-or-9/23235\nText:\nTake the 2-minute tour \u00d7\n\nIn my classes I sometimes have a contest concerning who can write the largest number in ten symbols. It almost never comes up, but I'm torn between two \"best\" answers: a stack of ten 9's (exponents) or a 9 followed by nine factorial symbols. Both are undoubtedly huge, but I haven't been able to produce an argument that one is larger (surely they aren't equal). Any insight into which of these two numbers is bigger would be greatly appreciated.\n\nshare|improve this question\nYou can always define new symbols which give you higher number than before. You want perhaps to limit your alphabet to digits, addition, multiplication, exponentiation, factorial. \u2013\u00a0 Asaf Karagila Feb 22 '11 at 15:20\nTry taking the logarithm several times, estimating the results using Stirling's formula: en.wikipedia.org/wiki/Stirling's_approximation \u2013\u00a0 Qiaochu Yuan Feb 22 '11 at 15:30\n@Fdart17: $9^{999999999}$ is enormously smaller than the exponential tower of ten 9s, which is the number being considered here. \u2013\u00a0 Chris Eagle Feb 22 '11 at 15:35\nDepending on what you're willing to allow without bracketing, neither of these is the best you can do with these symbols. $9!!!!!!!!!$ is smaller than $9^9!!!!!!!!$, while (tower of ten 9s) is smaller than (tower of nine 9s)!. \u2013\u00a0 Chris Eagle Feb 22 '11 at 15:38\n\"(surely they aren't equal)\": One way to see that the exponential tower is not equal to 9!!!!!!!!! is to note that the first is odd and the second is even. \u2013\u00a0 Jonas Meyer Feb 22 '11 at 18:58\n\n3 Answers 3\n\nup vote 33 down vote accepted\n\n$n!$ grows more rapidly than $9^n$ (it grows approximately with $n^n$), so eventually it wins out; in fact, a few moments with Wolfram Alpha suggests that for all $n\\gt 21$, $n! \\gt 9^n$. This means that the best solution is mixed: after the first exponentiation (since $9^9$ is greater than $9!$), you're better off using factorials, giving the answer $9^9!!!!!!!!$. (Also, note that we're all assuming that the correct parentheses here are implicit, since there's a big difference between $\\left(9^9\\right)^9$ and $9^{\\left(9^9\\right)}$.)\n\nOn the other hand, if you're allowed to use more-or-less stock mathematical notation, you may want to have a look at Knuth's arrow notation; $9\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow9$ is bigger by far than the rest of these. (And numbers even larger than this have come up in mathematics - have a look, for instance, at Graham's Number, which most conveniently uses the arrow notation in its definition.)\n\nEDIT: In fact it's pretty straightforward to prove that the answer in the first paragraph, $9^9!!!!!!!!$, is the best that can be done (with these operations). First, as long as $a$ is at least two symbols (for this group of symbols), then $a^9 \\lt 9^a\\lt a!$, so adding a factorial symbol is always going to be better than adding a $9$ onto your tower. But what about structures like $9!^{9!}$? Well, if both $a$ and $b$ are at least two symbols long, then $a^b\\lt \\mathrm{max}(a,b)!!$; assuming for the moment that $b$ is larger (because if $a$ were larger, then $b^a\\gt a^b$), then $b! \\approx b^b$, and while this isn't enough to ensure that it's greater than $a^b$ (consider the case where $a$ = $b$ = $9!$), it's close enough that we can be certain taking a second factorial will be larger - so those extra symbols you spent on exponentiation should retroactively have just gone into more exclamation points, and this is enough to guarantee that $9^9!!!!!!!!$ is the largest possible combination of these particular operations.\n\nshare|improve this answer\nWhat do you mean by \"so eventually it wins out\" ? Of course I agree that $9^9!!!!...$ is best possible, but what about the original structures the OP is asking about? I think you can you prove that for any number of characters $n$, the power tower of nines will be larger than the iterated factorials. \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:38\n+1 for mentioning Grahams Number. I always have little chuckle when I see it's definition. \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:50\nSorry - by 'eventually it wins out' I just meant that for some n, n! will be greater than 9^n - but as Jonas points out, that doesn't imply that the iterated-factorial will be larger than the iterated-exponential with one additional iteration. \u2013\u00a0 Steven Stadnicki Feb 22 '11 at 18:14\n\nWolfram Alpha shows $$9^{9^9}\\approx 10^{10^{8.56}}$$ while $$(9!)! \\approx 10^{10^{6.26}}$$ Adding another character adds another 10 to the bottom of the stack without changing the upper exponent much at all. It will even do the full stack of 10. The exponents have 8.5678 atop the tower of 10's, while the factorials have 6.26949. So the exponents win.\n\nAdded: In Douglas Hofstadter's May, 1982 column \"On Number Numbness\" he declares these essentially equal. For numbers of this size, the first thing you should look at is how many times you have to take a log to make it reasonable, which is 9 for both of them. Then look at the number on top of the stack, which is the only one that matters. So it is like 9.85678 compared with 9.626949, which are very close.\n\nshare|improve this answer\n+1 for being the only one to answer the OP's original question, namely that the tower of nines is larger than the factorials. In fact, I think you can you prove it is true no matter how many times we iterate. That is for any number of characters, say $n$, the power tower of nines will be larger than the iterated factorials. (I find that shocking since factorials is basically $n^n$) \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:32\nI have to admit, I find this really surprising too, but no less impressive for it! \u2013\u00a0 Steven Stadnicki Feb 22 '11 at 18:26\nFor comparison $(9^9)! \\approx 10^{10^9.5}$ \u2013\u00a0 Henry Feb 22 '11 at 18:27\n@Eric: thanks for noticing. Sometimes these questions take on a life of their own, but there was an original question that prompted it. \u2013\u00a0 Ross Millikan Feb 23 '11 at 3:25\n$9!!!$ is roughly $(10^{10^{6.26}})^{10^{10^{6.26}}}$, much greater than $9^{10^{10^{8.56}}}$ (most likely), so adding a character (a factorial in one case and an exponent to the tower in the other), seems to favor factorials here by quite a bit. \u2013\u00a0 Mitch May 14 '11 at 17:51\n\nA thorough study of this question is given in the article \"Exponential vs. Factorial\" by Velleman (American Mathematical Monthly Vol. 113, No. 8, Oct. 2006, pp. 689-704). In the motivating example there are 5 characters instead of 10. Of course, the conclusion is the same as in Steven Stadnicki's answer, that $9^9!!!!!!!!$ (or $9^9!!!$ in the case of 5 characters) is the largest possible.\n\nThe article also addresses your original question, proving that the exponential tower of $n$ $9$s is always larger than a $9$ with $n-1$ factorials applied (and many more general statements).\n\nshare|improve this answer\nExcellent answer! +1! No need to say more. \u2013\u00a0 Eric Naslund Feb 22 '11 at 18:00\n@Eric: Thanks. I just knew where to look because I remembered skimming the article when that Monthly was new. \u2013\u00a0 Jonas Meyer Feb 22 '11 at 18:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/67129/groups-of-order-pq-without-using-sylow-theorems\nText:\nTake the 2-minute tour \u00d7\n\nIf $|G| = pq$, $p,q$ primes, $p \\gt q, q \\nmid p-1 $, then how do I prove $G$ is cyclic without using Sylow's theorems?\n\nshare|improve this question\nTry counting elements of order $p$ and elements of order $q$ - there can't be any elements of order $pq$ (why?) and the subgroups of prime order are disjoint apart from the identity (why?) so the identity plus elements of order $p$ plus elements of order $q$ form the whole group. \u2013\u00a0 Mark Bennet Sep 24 '11 at 8:10\njust curious but, why would you not want to use the sylow theorems? \u2013\u00a0 user12205 Sep 24 '11 at 11:32\n\n5 Answers 5\n\nup vote 4 down vote accepted\n\nOnce again, Burnside's book (Theory of Groups of Finite Order) contains the classification of groups of order $pq$ before it tackles Sylow's Theorems. In the Dover print of the Second Edition this is contained in Page 48 (Section 36), with Sylow Theorems not occurring until section 120 (pages 149-151).\n\nThe argument relies on Cauchy's Theorem; here's the quote. I put in brackets the modern terms for some of the ones used by Burnside.\n\nA group of order $pq$ must contain a subgroup of order $p$ and a subgroup of order $q$. If the latter is not self-conjugate [normal] it must be one of $p$ conjugate sub-groups, which contain $p(q-1)$ distinct operations [elements] of order $q$. The remaining $p$ operations [elements] must constitute a subgroup of order $p$, which is therefore self-conjugate [normal]. A group of order $pq$ has therefore either a self-conjugate subgroup [normal subgroup] of order $p$, or one of order $q$. Take $p\\lt q$, and suppose first that there is a self-conjugate [normal] subgroup $\\{P\\}$ [$\\langle P\\rangle$] of order $p$. Let $Q$ be an operation [element] of order $q$. Then:\n\n$$\\begin{align*} Q^{-1}PQ &= P^{\\alpha}\\\\ Q^{-q}PQ^q &= P^{\\alpha^q},\\\\ \\alpha^q\\equiv 1&\\pmod{p},\\\\ \\text{and therefore }\\alpha\\equiv 1&\\pmod{p}. \\end{align*}$$\n\nIn this case, $P$ and $Q$ are permutable [commute] and the group is cyclical. Suppose secondly that there is no self-conjugate [normal] subgroup of order $p$. There is then necessarily a self-conjugate [normal] subgruop $\\{Q\\}$ of order $q$; and if $P$ is an operation of order $p$, $$\\begin{align*} P^{-1}QP &= Q^{\\beta}\\\\ P^{-p}QP^{p} &= Q^{\\beta^p}\\\\ \\beta^p\\equiv 1 &\\pmod{q}. \\end{align*}$$ If $q\\not\\equiv 1\\pmod{p}$ this would involve $\\beta=1$, and $\\{P\\}$ would be self-conjugate, contrary to supposition. Hence if the group is non-cyclical, $q\\equiv 1 \\pmod{p}$ and $P^{-1}QP=Q^{\\beta}$, where $\\beta$ is a root, other than unity, of the congruence $\\beta^p\\equiv 1\\pmod{p}$. Between the groups defined by [$E$ is the identity] $$\\begin{align*} P^p&=E, &\\qquad Q^q&=E,&\\qquad P^{-1}QP &= Q^{\\beta},\\\\ \\text{and }P'^p&=E, & Q'^q&=E, & P'^{-1}Q'P'&=Q^{\\beta^a}, \\end{align*}$$ a simple isomorphism is established by taking $P'$ and $P^a$, $Q'$ and $Q$, as corresponding operations [elements]. Hence when $q\\equiv 1\\pmod{p}$ there is a single type of non-cyclical group of order $pq$.\n\nshare|improve this answer\nIf $Q_1, Q_2$ are two subgroups of order q, then $<Q_1, Q_2> \\supseteq Q_1Q_2$, and so $|<Q_1, Q_2>|\\geq |Q_1Q_2|=q.q/1=q^2 >qp=|G|$, contradiction; so there is unique subgroup of order $q$, hence normal. \u2013\u00a0 Marshal Kurosh Sep 29 '11 at 5:30\n@MarshalKurosh: Perhaps you can contact your local medium and let Burnside know, instead of letting me know? \u2013\u00a0 Arturo Magidin Sep 29 '11 at 13:20\n\nThis solution will mostly use Lagrange and the fact that |G| has so few divisors. This is mostly an example of how looking at cosets and permutations is useful. Sylow's theorem is just an example of doing that in a more general situation. Like Sylow's theorem, we gain a lot by finding fixed points of permutations.\n\nBy Lagrange's theorem, an element of G has order 1, p, q, or pq. There is only one element of order 1. If there is an element of order pq, then G is the cyclic group generated by it. Otherwise, every non-identity element of G has order p or q, and there is at least one such element, x. Let H be the subgroup generated by x.\n\nCase I: If x has order q, then Lagrange says that there are p cosets of H in G and x acts as a permutation on them. The order of that permutation is either 1 or q (by Lagrange again), but q > p is impossibly big, and so x leaves all the cosets gH alone. That means H is normal in G, because xgH = gH and so g\u22121xg in H for all g in G, and H is generated by x. Let y be any element of G not contained in H. Then y normalizes H, and so conjugation by y is an automorphism of H. The automorphism group of H has order q\u22121, and so the order of that automorphism is a divisor of gcd(q\u22121,\u00a0pq) = 1 by Lagrange, so conjugation by y is the identity automorphism on H. In other words, y\u22121xy = x and xy = yx. In particular, x and y commute and xy has order pq, so G is cyclic.\n\nCase II: If x has order p, then there are q cosets of H in G, by Lagrange. Note that xH = H, so x does not move the coset 1H. We examine two subcases based on whether it leaves any other cosets alone:\n\nCase IIa: Suppose x moves all the other cosets. By Lagrange, those other cosets are collected into p-tuples (the \"orbits\" of x), and so we get that q = 1 + kp, where k is the number of orbits. This explicitly contradicts the non-divisibility hypothesis.\n\nCase IIb: Suppose x leaves at least one more coset alone, say yH for some y not contained in H. In other words, xyH = yH, or y\u22121xy is in H. This means that y acts by conjugation on the elements of H. However, the automorphism group of H has order p\u22121, and so the automorphism by y is a divisor or p\u22121 and a divisor of pq, but gcd(p\u22121,\u00a0pq) = 1. Hence conjugation by y is the identity automorphism: y\u22121xy = x and xy = yx. In particular, x and y commute and xy has order pq, so G is cyclic.\n\nshare|improve this answer\nIn Case 1, Why can you claim that $x$ acts as a permutation on the set of left cosets of $H$ ? i.e. suppose $\\{g_1H, \\ldots g_pH\\}$ are left cosets of H, what goes wrong if $xg_iH=xg_jH$ for $1 \\leq i < j \\leq p$ ? \u2013\u00a0 the8thone Oct 14 '14 at 20:31\n\nFor any group $G$ and a normal subgroup $H$, $G$ acts on $H$ by conjugation as automorphisms of $H$. This gives a map from $G \\to \\text{Aut}(H)$ via the permutation representation with kernel $C_G(H)$. So by the First Isomorphism Theorem we have $G/C_G(H) \\hookrightarrow \\text{Aut}(H)$.\n\nNow let $G$ be a group of order $pq$ as above. Clearly if $Z(G)$ is nontrivial then $G/Z(G)$ is cyclic, and thus $G$ is abelian. So we may assume that $Z(G) = \\{e\\}$. If every element of $G$ besides the identity has order $q$, then the size of each conjugacy class must be $p$ for every nontrivial element. Then we would have the class equation $pq = 1 + kp$ for some $k \\in \\mathbb{Z}$. But clearly this is impossible as $p$ divides $pq$ but not $1 + kp$. So $G$ must have an element of order $p$, say $g$. Define $H = \\langle x \\rangle$. Then $|G:H| = q$, and since $q$ is the smallest prime dividing $|G|$, we have that $H$ must be normal. So $N_G(H) = G$ and since $Z(G) = \\{e\\}$, we must have that $C_G(H) = H$. Then by the above work, $G/C_G(H) \\hookrightarrow \\text{Aut}(H)$. But since $H$ is cyclic, we have that $\\text{Aut}(H) \\simeq (\\mathbb{Z}/p\\mathbb{Z})^\\times$ by a standard result in group theory. Since $C_G(H) = H$, $|G/C_G(H)| = q$. But $|\\text{Aut}(H)|=p-1$. Since $G/C_G(H) \\hookrightarrow \\text{Aut}(H)$, this implies that $\\text{Aut}(H)$ has a subgroup of order $q$, but this would imply that $q \\mid p-1$, which is a contradiction. Hence $G$ must be abelian. From here you just need a single element of order $p$ and one of order $q$. Their product has order $pq$ and thus generates $G$.\n\nshare|improve this answer\nIn your argument you have not used the fact that $p \\neq q$, in fact if $p=q$, A group of order $p^2$ is not necessarily cyclic , i.e. it can be isomorphic to $\\mathbb{Z}_p \\times \\mathbb{Z}_p$ \u2013\u00a0 the8thone Oct 14 '14 at 20:18\n@the8thone That fact is used in the last line. The product of two elements of order $p$ need not be of order $p^2$. \u2013\u00a0 Brandon Carter Oct 14 '14 at 20:53\n\nLet $G$ be a group of order $pq$. Then order of element should be $1,p,q,pq$.\n\nIt is sufficient to show existance of subgroups of order $p$ and $q$.\n\n  \u2022 If all elements of $G$ are of order $p$ (except identity), then consider a subgroup $H$ of order $p$ and take $y\\in G\\backslash H$, let $K=\\langle y\\rangle$.\n\n    Now $H$ can not be normalised by $y$ in $G$, otherwise $HK$ will be an abelian subgroup of $G$ of order $p^2$, contradiction. Therefore, $yHy^{-1}$ is another conjugate subgroup of order $p$. Now number of conjugates of $H$ will be the index $[G\\colon N(H)]$ of normalizer of $H$ in $G$; since there are at least two conjugates, ($H,yHy^{-1}$) so $[G\\colon N(H)]>1$, we deduce that $N(H)=H$. Therefore there are exactly $q$ conjugates of $H$. The non-trivial elements in collection of conjugates of $H$ will be $(p-1)q$. Then take element $z$ of $G$ outside these counted elements, proceed further for $\\langle z\\rangle$. We will get $(p-1)q$ non-trivial elements in the collection of all conjuagtes of $\\langle z\\rangle$. After some finite steps, say $m\\geq 1$, we will get all non-trivial elements of $G$ (of order $p$); they will be $m(p-1)q$ in number.\n\n    Therefore, $m(p-1)q+1=pq$, which is not valid, since $pq-m(p-1)q$ is divisible by $q$ (here all terms are non-zero).\n\n    Therefore, we conclude that all non-trivial elements of $G$ can-not be of same order $p$.\n\n    Similarly, we can conclude that all non-trivial elements can not have same order $q$.\n\n    \u2022 If $G$ has element of order $pq$ then it will be cyclic.\n\n    \u2022 Otherwise, now we must have atleast one element of order $q$, hence a subgroup $Q$ of order $q$. This subgroup must be be unique (hence normal): if $Q_1$ is another subgroup of order $q$, then $\\langle Q, Q_1\\rangle \\supseteq QQ_1$, so $|\\langle Q,Q_1\\rangle | \\geq |QQ_1|=q.q/1=q^2>qp = |G|$, contradiction.\n\n    Take a subgroup $P$ of order $p$. Now $Q \\triangleleft G$, $P\\leq G$, hence $PQ\\leq G$; in fact this is equality - $PQ=G$ (computing orders). So $G=Q\\rtimes P$. Using two basic theorems on semi-direct product of groups ( Ref. Alperin-Bell - Groups and Representations), we can conclude that $G=Q\\times P$, hence it is cyclic.\n\n    (The crucial step stated in proof is existance of subgroups of order $p$ and $q$. Using theorems on semi-direct products doesn't uses Sylow's theorems.)\n\nshare|improve this answer\n\n(We only consider the complex representation) Suppose that $G$ is non-Abelian. Then there is an irred repr. $\\rho$ s.t. it is $d$-dim'l, $d>1$. By dimension theorem, we get $d=p,q$, or $pq$, but we know that $d$ must be $p$; otherwise by the property that $\\sum_{\\chi'\\in\\text{Irr}(G)}d_\\chi^2=|G|$, we will get $d^2>pq$ because of the condition $p<q$. So the dimension of the irred repr's can only be $1$ or $p$, and hence we get $$ mp^2+n=pq, $$ where $m,n$ stand for the number of $p$-dim'l and $1$-dim'l irred repr's, respectively. Furthermore, let $\\mathcal{L}(G)$ be the set of all $1$-dim'l characters of $G$. Then we have $$ n=|\\mathcal{L}(G)|=|\\text{Irr}(G/[G,G])|=\\frac{|G|}{|[G,G]|}, $$ where $[G,G]$ is the commutator subgroup of $G$. Since $G$ is non-Abelian, $[G,G]$ is nontrivial. So $n=1,p$, or $q$.\n\n[Case 1]: If $n=1$, then $mp^2=pq-1$. So we get $pq\\equiv1\\;(\\text{mod}\\,p^2)$. However, since $q\\equiv 1\\;(\\text{mod}\\,p^2)$, we get $$ pq\\equiv p\\equiv 1 (\\text{mod}\\,p^2), $$ which is a contradiction.\n\n[Case 2]: If $n=p$, then $\\displaystyle m=\\frac{q-1}{p}\\notin\\Bbb N$ because $p\\nmid(q-1)$. Contradiction.\n\n[Case 3]: If $n=q$, then $\\displaystyle m=\\frac{(p-1)q}{p^2}\\notin\\Bbb N$, still a contradiction.\n\nTherefore, in conclusion, we find $G$ must be Abelian, and hence, by the fundamental theorem of Abelian groups, $G\\cong \\Bbb Z_{pq}$ or $\\Bbb Z_p\\times \\Bbb Z_q$. So in any case $G$ is a cyclic group.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/95995/there-is-no-simple-group-of-order-448-26-cdot-7?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nHow can I prove that there is no simple group of order $448=2^6\\cdot 7$? I tried with Sylow's theorems, I proved that (if $G$ is simple) the number of 2-Sylows is 7 and that the number of 7-Sylows is 8 or 64, but I don't know how to continue, could you help me please?\n\nshare|improve this question\n(There is a monthly maximum for questions... :D ) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 3 '12 at 5:36\nHint: If there are 64 Sylow 7-subgroups, consider how may elements of order 7 there are. \u2013\u00a0 Geoff Robinson Jan 3 '12 at 5:45\n@Alex: Well, if there are 384 elements of order $7,$ how many Sylow $2$-subgroups can there be? (Actually, I see a more direct approach to the question than this anyway). \u2013\u00a0 Geoff Robinson Jan 3 '12 at 5:53\nonly 1, right thank you \u2013\u00a0 Alex M Jan 3 '12 at 5:59\n@Jack, Jyrki: I do not believe the statement about groups of order $q^{n}p.$ For example, the symmetric group $S_4$ has order $2{3}.3,$ and a Sylow $3$-subgroup normalizes the normal Klein $4$-group, but not a whole Sylow $2$-subgroup (there is noting special about these primes for this question). \u2013\u00a0 Geoff Robinson Jan 3 '12 at 9:12\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nLet $n_2$ be the number of $2$-Sylow subgroups of $G.$ Then, $n_2$ is odd and divides $7.$ If $n_2=1$ we're done, but if $n_2=7$, by Sylow theorem, conjugation of these seven $2$-Sylow subgroups defines a homomorphism $G \\to S_7.$ The kernel of this homomorphism cannot be trivial so we're done.\n\nshare|improve this answer\nwhy the kernel cannot be trivial? \u2013\u00a0 Alex M Jan 3 '12 at 7:42\n+1: This works for groups of size $2^6\\cdot 7$, because that number does not divide $7!$. But curiously it wouldn't work for $2^4\\cdot 7$ :-) \u2013\u00a0 Jyrki Lahtonen Jan 3 '12 at 7:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164264/do-elliptic-operators-on-riemannian-manifolds-have-a-regularizing-effect?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm working on my master thesis and need to handle some spectral theory of the Laplace operator on compact Riemannian manifolds and especially on the sphere. While investigating essential self-adjointness I stumbled on the following problem.\n\n*Problem*$\\quad$ In a compact Riemannian manifold $M$ let $$\\Delta=\\operatorname{div}\\operatorname{grad}$$ and let $f\\in L^2(M)$ be such that $(f, u-\\Delta u)=0$ for every $u \\in C^{\\infty}(M)$. Prove that $f=0$.\n\nI believe that the claim is true, because the condition $(f, u-\\Delta u)=0$ means exactly that $f$ is a distributional solution of the elliptic equation $-\\Delta f + f=0$, and so I expect it to be a $H^2_{\\text{loc}}$ function (see Theorem 2.1 of Berezin - Shubin's book). Since $M$ is compact this must imply that $f\\in H^1(M)$ so that integrating by parts we get $\\lVert f \\rVert_{H^1}^2=(f, f)+(\\operatorname{grad}f, \\operatorname{grad}f)=0$.\n\nUnfortunately Theorem 2.1 above is set in an open subset of the Euclidean space and I don't know if it is applicable verbatim in a Riemannian manifold. Can you point me to some reference on this?\n\nThank you.\n\nshare|improve this question\nI don't know the answer to this but would first try to look in Chavel's book 'Eigenvalues in Riemannian Geometry'. \u2013\u00a0 user20266 Jun 28 '12 at 18:07\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nYes. Write your equation in local coordinates and then use the usual elliptic theory there.\n\nHere is an example. The equation $$\\Delta_g u = h$$ in local coordinates is $$g^{ij}\\frac{\\partial^2u}{\\partial x^i\\partial x^j} - \\frac{1}{\\sqrt g} \\frac{\\partial}{\\partial x^i}(\\sqrt g g^{ij})\\frac{\\partial u}{\\partial x^j} = h$$\n\nNotice that the operator on the LHS is still an elliptic operator on $\\mathbb R^n$ in the given local coordinates, due to the fact that the Riemannian metric is positive definite. Therefore all of the standard elliptic regularity theorems you know for operators on $\\mathbb R^n$ still apply.\n\nThere isn't really a standard reference for this, although it probably appears as a remark buried in most PDE books.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296931/find-x-such-that-1213x-be-a-perfect-square/297410\nText:\nTake the 2-minute tour \u00d7\n\nFind $x \\in N$ such that $12+13^x$ be a perfect square\n\nI am going to limit $k < 12 + 13^x < k+i$ so that I can have $t<x<t+u$, I don't know how to do it, if $x=2k$, it pretty easy but x can also equal $2k +1$ too. So... Stuck here\n\nUpdate 2: I can prove that $x$ can't be $2k$, if so, x = 2k $(k \\in \\mathbb{N})$ then $13^{2k}<12+13^x = 12 + 13^{2k}<(13^k+1)^2$ => $12+13^x$ can't be a perfect square.\n\n~# if $x=2k+1$\n\n=> $12+13^x = 12+13^{2k+1}$. Now we need prove that $k$ can not greater than $1$ (how to do that ?, stuck again)\n\nshare|improve this question\n$x=1$ works, but you probably knew that. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 5:03\nWhere is this question from? \u2013\u00a0 Will Jagy Feb 7 '13 at 5:40\nRamanujan and Nagell are associated with the similar equation $-7+2^x=y^2$, which has several solutions. The methods used for finding all the solutions would probably be a good starting point for the current problem. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 6:00\nHow were you led to this question? \u2013\u00a0 Will Jagy Feb 7 '13 at 6:01\nA couple of papers that might be relevant: MR0856715 (87m:11027a) Peth\u00f6, A.; de Weger, B. M. M., Products of prime powers in binary recurrence sequences, I, The hyperbolic case, with an application to the generalized Ramanujan-Nagell equation, Math. Comp. 47 (1986), no. 176, 713\u2013727 and MR0856716 (87m:11027b) de Weger, B. M. M., Products of prime powers in binary recurrence sequences, II, The elliptic case, with an application to a mixed quadratic-exponential equation, Math. Comp. 47 (1986), no. 176, 729\u2013739. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 6:09\n\n5 Answers 5\n\nThere are many ways to solve such problems -- I'm not sure that any of them are particularly easy. One way, since you've observed that your exponent $x$ is necessarily odd, would be to find all the integral points on the elliptic curves given by the equations $$ y^2 = 13^\\delta u^4+12 \\; \\mbox{ for } \\; \\delta \\in \\{ 1, 3 \\}. $$ One can do this in, for example, magma by typing : IntegralQuarticPoints([13,0,0,0,12]); and IntegralQuarticPoints([13^3,0,0,0,12]); which lead to the two known solutions (with $|u|=1$ and $|y| =5$ and $47$). These routines are using lower bounds for linear forms in logarithms (elliptic, I believe).\n\nAnother approach (which has some similarities) would be to use an argument of de Weger (from his thesis, again based on linear forms in logarithms). This would enable you, for example, to tackle the more general equation $$ 13^x + 2^y 3^z = w^2. $$ I haven't worked out the details, but one should be able to show that the only solutions are with $$ \\begin{array}{r} (x,y,z) = (0,0,1), (0,3,0), (0,3,1), (0,4,1), (0,5,2), (1,0,1), (1,0,5), \\\\ (1,2,1), (1,2,2), (1,2,3), (2,0,3), (2,6,1), (2,10,5), (3,2,1). \\\\ \\end{array} $$\n\nYet another way to solve such problems is to use the hypergeometric method of Thue and Siegel. In this context, it enables one to prove an inequality of the shape $$ \\left| y^2 - 13^x \\right| > |y|^{0.4}, $$ valid for all integers $y$ and odd $x$. Such an approach is also useful for bounding the number of solutions to equations like the one under consideration here. One can, for example, show that given any odd prime $p$ and integer $D$, there are at most $3$ positive integers $x$ such that $$ p^x+D = y^2 $$ for integer $y$. This is, of course, not quite sharp when $p=13$ and $D=12$, but it's close.\n\nshare|improve this answer\nI may be two weeks late, but welcome to Math Stack Exchange professor Bennett! \u2013\u00a0 Eric Naslund Feb 7 '13 at 18:59\nThank you, Eric. \u2013\u00a0 Mike Bennett Feb 8 '13 at 1:57\n\n$x=3 \\implies 13^x+12=2209=47^2$.\n\nshare|improve this answer\n\nI don't think there's a nice way to do this. You can, however, use a calculator or a computer to find solutions. I used the following line in Mathematica:\n\n      Intersection[12+13^(2#-1) & /@Range[100000],#^2&/@Range[300000]]\n\nAnd it returned\n\n{25, 2209}\n\nImplying the only answers less than $100000$ are $1$ and $3$.\n\nEDIT: changed code and results\n\nshare|improve this answer\n\nWe want: $$13^x + 12 = a^2$$ Not an answer just compiling results:\n$$ x=1,3 $$ Are the first two solutions.\nThere are no solutions for $$ 3<x<100000 $$ Note that $$ 12+13^x \\equiv 1 \\mod 8, \\;\\; \\forall x>1, \\mbox{ such that $x$ is odd}\\\\ 12+13^x \\equiv 5 \\mod 8, \\;\\; \\forall x>1, \\mbox{ such that $x$ is even}\\\\ $$ Hence $$ a^2 \\equiv 1 \\ $$ So we have that: $$ a \\equiv 1,3,5 \\text{ or } 7 \\mod 8 $$\nand $x$ is odd since $5$ is a non-residue $\\mod 8$\n\nA similar result yields that: $$ a \\equiv 2 \\text{ or } 5 \\mod 7 $$\n\nshare|improve this answer\n\nI think algebraic approach is appropriate to this problem. With some calculation, we get $$(y+2\\sqrt{3})(y-2\\sqrt{3})=(4+\\sqrt{3})^x (4-\\sqrt{3})^x.$$ and $4\\pm\\sqrt{3}$ is prime on $\\mathbb{Z}[\\sqrt{3}]$. And $$\\frac{5-2\\sqrt{3}}{4+\\sqrt{3}}=2-\\sqrt{3}$$ $$\\frac{47+2\\sqrt{3}}{(4+\\sqrt{3})^3}=2-\\sqrt{3}$$\n\nSo I conjectured following propositions:\n\n  1. If $(x,y)$ is solution of this equation, then $y+2\\sqrt{3}$ associates $(4+\\sqrt{3})^x$ or $(4-\\sqrt{3})^x$.\n\n  2. And each case ($(4+\\sqrt{3})^x$ associates $y+2\\sqrt{3}$ or $(4-\\sqrt{3})^x$ associates $y+2\\sqrt{3}$) gives only one solution.\n\nBut I can't get more.\n\nshare|improve this answer\nBy working out the unit group, you have $$y \\pm 2 \\sqrt{3} = (4 + \\sqrt{3})^x (2 - \\sqrt{3})^a$$ for some integer $a$ and positive integer $y$. A quick exhaust shows $a > 0$ too. Subtracting the conjugates on both sides, you get what is essentially a quadratic equation in $(2 - \\sqrt{3})^a$, so there is effectively one solution for each choice of $(4 \\pm \\sqrt{3})^x$. But there isn't always a solution where $a$ is an integer. \u2013\u00a0 Hurkyl Feb 7 '13 at 8:54\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/334585/use-fund-thm-to-evaluate-the-integral-of-zex2-dydz-3ys-dydz-2-yz7dx\nText:\nTake the 2-minute tour \u00d7\n\nUse the Fundamental Theorem to evaluate the integral of $ ze^{x^2} dydz + 3ys dydz + (2-yz^7)dxdy $ over the surface of the unit cube, except the bottom face.\n\nshare|improve this question\nWhat is $s$, a constant? \u2013\u00a0 Ron Gordon Mar 19 '13 at 9:05\nI assumed so. It is not a typo on my part. \u2013\u00a0 GaMbiT Mar 19 '13 at 9:14\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nBy \"unit cube,\" I assume you mean $[0,1]^3$. In any case, use the divergence theorem to get the net surface integral, i.e., the net outward flow across all faces of the cube. Then subtract the specific surface contribution from the bottom face to get the quantity you seek.\n\nThe vector field described above is\n\n$$\\vec{F} = (z\\, e^{x^2}, 3 s y, 2-y z^7)$$\n\nThen its divergence is\n\n$$\\vec{\\nabla}\\cdot \\vec{F} = 2 x z e^{x^2} + 3 s - 7 y z^6 $$\n\nThe net surface integral is then the integral of the divergence over the unit cube. I assume you can do this relatively simple integral; I get\n\n$$\\iiint_{[0,1]^3} dx\\,dy\\,dz\\: \\vec{\\nabla}\\cdot \\vec{F} = \\frac{1}{2} (e-3) + 3 s$$\n\nThen you must subtract out the contribution from the bottom face, i.e. $z=0$. Since the flow is outward, i.e., down in the negative $z$ direction, you add back in the integral\n\n$$2 \\iint_{[0,1]^2} dx \\,dy 2 = 2$$\n\nso the quantity you seek is\n\n$$\\frac{1}{2} (e+1) + 3 s$$\n\nshare|improve this answer\n*(e - 1), instead of (e + 1)? Thank you very much for the help, by the way. \u2013\u00a0 GaMbiT Apr 19 '13 at 14:18\n@XxGaMbiT: No, because of the factor of $1/2$. \u2013\u00a0 Ron Gordon Apr 19 '13 at 14:19\nOh, right. Careless mistake. Sorry. \u2013\u00a0 GaMbiT Apr 19 '13 at 14:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/445123/how-to-solve-the-advection-equation-with-spiral-motion\nText:\nTake the 2-minute tour \u00d7\n\nThe advection equation is :\n\n$$\\frac{\\partial f(x,y,t)}{\\partial t} + \\nabla_{(x,y)} \\cdot (A f)= 0$$\n\nWith initial condition $f(x,y,0) = f_0(x,y)$.\n\nIf the vector $A$ is constant, ie. $A = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix}$ we have a linear advection. Using the characteristic method we found\n\n$$\\frac{dX}{dt} = a_1\\implies X(t) = x_0 + a_1t \\\\ \\frac{dY}{dt} = a_2\\implies Y(t) = y_0 + a_2t$$\n\nIf $A = \\begin{pmatrix} -x \\\\ y \\end{pmatrix}$ the motion of the advection is a circle :\n\n$$\\frac{dX}{dt} = y \\implies X(t) = c_0\\sin(t+c_1) \\\\ \\frac{dY}{dt} = -x\\implies Y(t) = c_0 \\cos(t+c_1)$$\n\nSo I was wondering what can I do to have a spiral advection ? Let's say I want to found :\n\n$$X(t) = t\\cos(t+\\theta_0) \\\\ Y(t) = t\\sin(t+\\theta_0)$$\n\nif we derivate this system :\n\n$$\\frac {dX(t)}{dt} = -t\\sin(t+\\theta_0) + \\cos(t+\\theta_0) = x/t - y = a_1(t,x,y)$$\n\n$$\\frac {dY(t)}{dt} = t\\cos(t+\\theta_0) + \\sin(t+\\theta_0) = y/t + x = a_2(t,x,y)$$\n\nWe can notice then that $\\nabla \\cdot A = \\dfrac{2}{t}$\n\nThen the equation is :\n\n$$\\frac{\\partial f(x,y,t)}{\\partial t} + A \\cdot \\nabla_{(x,y)} f = - \\dfrac{2}{t} f$$\n\nBut I don't manage to solve it. Using the characteristic method we found the spiral equation for X and Y but for the last element I have :\n\n$$\\dfrac{dF(x,y,t)}{dt} = - \\dfrac{2}{t}f \\implies f = C_0 / t^2$$\n\nwhich is not defined when $t=0$ so I don't know how to apply the initial condition.\n\nHow can I solve this equation ?\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/193944/closed-form-for-a-sum-of-values-of-a-quadratic\nText:\nTake the 2-minute tour \u00d7\n\nToday in class we were analyzing the number of half-spaces created by $n$ number of planes. For two planes there are 4 spaces, 3 there are 8, 4 there are 15, etc. our teacher challenged us to find the formula for $n$ planes. Me and my friend came up with $$ 1+\\sum^n_{x=1} \\left(\\frac{x(x+1)}{2}+1\\right) $$ Because based on that when a line cuts a plane in half, the formula for the number of half-planes it creates is $$ \\frac{n(n+1)}{2} + 1 $$ and the difference in the number of half-spaces between each $n$ plane is equal to adding on the same number of half-planes.\n\n+--#of planes--+--1--+--2--+--3--+--4--+--5--+--50--+\n|separates into|  2  |  4  |  8  |  15 | 26  |20,876|\n| _ half-spaces|     |     |     |     |     |      |\n\nMy teacher said that this was correct, but it would be better if it was a formula/function, where you plug in the variables rather than have to evaluate the summation. I know that the final answer is $$ \\frac{n^3+5n+6}{6} $$ but I need to show my work, and am unsure of how to get from a sum to that formula. Am I approaching this incorrectly? How was the original formula derived?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe reasoning is basically right, with slight glitches in the details. The desired number is $$2+\\sum_{x=1}^{n-1} \\left(\\frac{x(x+1)}{2}+1\\right).\\tag{$1$}$$ Or else, if you want to sum from $1$ to $n$, the desired number is $$1+\\sum_{x=1}^{n} \\left(\\frac{x(x-1)}{2}+1\\right).\\tag{$2$}$$\n\nNote that $(x+1)^3-x^3=3x^2+3x+1$. So $$\\frac{x^2+x}{2}=\\frac{1}{6}\\left((x+1)^3-x^3-1\\right).$$ Adding $1$, we get $$\\frac{x^2+x}{2}+1=\\frac{1}{6}\\left((x+1)^3-x^3+5\\right).$$\nWe will add up $(x+1)^3-x^3+4$ from $x=1$ to $x=n-1$, and divide by $6$ at the end. We have $n-1$ $5$'s, which add up to $5n-5$. Now add up the $(x+1)^3-x^3$ from $x=1$ to $x=n-1$. The sum is $$(2^3-1^3)+(3^3-2^3)+(4^3-3^3)+\\cdots +(n^3-(n-1)^3).$$ Note the beautiful cancellations! Almost everything disappears, and we end up with $n^3-1^3$. Add the $5n-5$. We get $n^3+5n-6$.\n\nSo our answer is $2+\\dfrac{n^3+5n-6}{6}$, which simplifies to $\\dfrac{n^3+5n+6}{6}$.\n\nRemarks: $1$. If you want to work with expression $(2)$ instead of $(1)$, you may want to use the identity $x^3-(x-1)^3=3x^2-3x+1$, though the one we used works fine.\n\n$2$. The kind of collapsing that we saw comes up surprisingly often. You may want to look into telescoping sums.\n\n$3$. There are many many other ways to find a closed form for the sm. Here is another idea. It is known that for any quadratic $q(k)$, $\\sum_{k=1}^{n-1}$ is a cubic. (And for any cubic $c(k)$, $\\sum_{1}^{n-1}c(k)$ is a quartic, and so on.). So our answer must have shape $p(n)=an^3+bn^2+cn+d$. If we know the values of our function at $4$ different $n$, we get $4$ linear equations in the coefficients $a$, $b$, $c$, $d$. Solve.\n\nshare|improve this answer\nWhere does the $(x+1)^6-x^6+4$ come from? Shouldn't it be $(x+1)^3-x^3+4$? \u2013\u00a0 SomekidwithHTML Sep 12 '12 at 1:55\n@SomekidwithHTML: It comes from a typo. Thanks! \u2013\u00a0 Andr\u00e9 Nicolas Sep 12 '12 at 2:47\n\nYour question amounts to evaluating\n\n$$\\sum_{x=1}^n x^2\\,\\,\\,\\text{and}\\;\\;\\sum_{x=1}^n x$$\n\n(upon expanding your original sum). Specifically,\n\n\n$$\\sum_{x=1}^n x^2=\\frac{x(x+1)(2x+1)}{6}$$\n\nwhich can be shown by induction.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/x-a-b-x-ab.87503/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\n\n  1. Sep 5, 2005 #1\n    Can anyone show me the reason [itex](x^a)^b = x^{ab}[/itex]? Is this something that always works or is it just a general rule.\n  2. jcsd\n  3. Sep 5, 2005 #2\n    where a and b are what? Natural numbers? Reals?\n  4. Sep 5, 2005 #3\n    Well, if it depends then when does it depend? Specifically I want to know for when a and b are reals, but does it change the answer if a and b can be complex?\n  5. Sep 5, 2005 #4\n    In any situation where you have the commuative law of multiplication, you probably (certainly?) will have the \"power of a power\" rule.\n\n    To get a proof, you will have to start with natural numbers, then rational, then real, and finally complex. In each subsequent case, I think you boil it down to the previous case.\n\n    Going from rational to real will be the hardest case, I think.\n\n    In Natural numbers, seems like you can use induction.\n  6. Sep 5, 2005 #5\n    i think that this is defined when x>0, or at least when we are dealing with real numbers, in complex number i havent dealt yet (there is for example the (e^-1)=1/e, in the reals, but if we look at it as (e^i)^i, we can use euler identity but then i think we get a different answer).\n  7. Sep 5, 2005 #6\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    I am interested in this also. And specifically, what is a number raised to an irrational number? Wiki says \"Exponentiation to an arbitrary real exponent can then be defined by continuity.\" What is meant by 'continuity' exactly? Is it that even though it is impossible to give a clear meaning to a^b (where b is irrationnal), we define a^b as having the same properties as exponentiation to a rational number?\n  8. Sep 5, 2005 #7\n\n\n    User Avatar\n    Homework Helper\n\n    By continuity means that the exponential f:Q->R from rationals to reals is a continuous function. The rationals are dense in the reals, so only one continuous map f:R->R exist that agrees with the rational exponetnial. To put things more simply, and assuming additonally that for a positive real a\n    a^x<a^y <-> x<y\n    we have for p and q rational x real\n    p<x<q <-> a^p<a^x<a^q\n    thus for any real number (having defined a rational exponential) we can trap a^x in as small an interval as we like by traping x between two rationals that are sufficiently close. Thus it is not impossible to give a clear meaning to exponentiation of a real number, but it is convient to give that meaning in terms of exponentiation of a rational number.\n    [tex]a^x:=\\lim_{r\\rightarrow x}a^r[/tex]\n    where the limit is taken with r constrained to rational numbers\n\n    This can be avoided by defining exponential and log functions then (for a>0)\n    for this to work log and exp much be defined, my perfered definition being\n    exp is the function (which exist and is unique) having\n    exp(x+y)=exp(x)*exp(y) for all real x and y\n    [tex]\\lim_{x\\rightarrow 0}\\frac{\\exp(x)-1}{x}=1[/tex]\n    log is the function (which exist and is unique) having\n    log(x*y)=log(x)+log(y) for all real x and y\n    [tex]\\lim_{x\\rightarrow 0}\\frac{\\log(1+x)}{x}=1[/tex]\n    This method has the problem of making exp and log appear a bit mysterious.\n  9. Sep 5, 2005 #8\n    Well here's what has me confused.\n\n\n    So either the powers can't be multiplied in this case, or I'm mistaken and [itex]1^\\frac{1}{2}={\\pm}1[/itex]. I've been told the latter is false, so I was wondering where the multiplication of powers came from. I was assuming it would be easy to show, but maybe not.\n  10. Sep 5, 2005 #9\n\n\n    User Avatar\n    Homework Helper\n\n    The reason it breaks down is exp is many to one.\n    exp(x)=exp(y) <-> 2pi*i|(x-y)\n    We chose a principle value for log, but the rule\n    cannot hold for all values\n    in principle value\n    which is true when\n    which is true when\n    other wise the rule fails\n    the given example\n  11. Sep 5, 2005 #10\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Suppose n and m are positive integers. Then [itex](a^n)^m[/itex] means (an) multiplied by itself m times. Think of that as m \"copies\" of an. But an means a multiplied by itself n times: think of that as n \"copies\" of a. So, in each of the m \"copies\" of an, you have n copies of \"a\". How many copies of \"a\" do you have altogether? If you had m boxes with n apples in each box, how many apples do you have? n*m of course. The total number of \"a\"s being multiplied in [itex](a^n)^m[/itex] is mn so that is exactly the same as amn.\n\n    That is for m,n positive integers. The two laws: an*am= an+m and (an)m= amn are so useful that, as quasar987 said, we effectively define ar, for r anything other than a positive integer, so as to make those two laws true.\n  12. Sep 5, 2005 #11\n\n\n    User Avatar\n    Gold Member\n\n    It is true that [itex]1^{\\frac{1}{2}}=\\pm 1[/itex], but not true that [itex]\\sqrt{1}=\\pm 1[/itex]. This is because of the definition of the square root symbol. The definition of fractional, irrational and complex powers is as follows: In general, [itex]x^a[/itex] is defined as [itex]e^{a\\log{x}}[/itex]. log is a multiple-valued function: [itex]\\log{z}=\\ln{|z|}+i arg(z)[/itex], where arg z is the argument of z and can take on any value of the form [itex] arg z = Arg z +2\\pi k, k \\in \\mathbb{Z}[/itex] This means that\n    [tex]x^a=e^{a\\log{x}}=e^{a(\\ln{|x|} + i arg x)}=e^{a\\ln{|x|}}e^{ia Arg x +2ia\\pi} = e^{a\\ln{|x|}}e^{ia Arg x}e^{2iak\\pi}[/tex]\n    If x is positive real, then Arg x=0, if negative then Arg x= [itex]\\pi[/itex]. [itex]e^{2k\\pi}[/itex] is 1 for any integer k. This means that if a is also an integer, the function will be single-valued. If a is a fraction then ka will only be an integer for some values of k. If a=1/2, then there will be two possible values of [itex]e^{2aik\\pi}[/itex], hence two values of [itex]x^a[/itex].\n\n    This definition also provides an easy answer to \u03b5llipse's question:\n    For convenience, let [itex]w = e^{a\\log{x}}[/itex]\n    Now, since log(e^(z))=z+2kpi,\n    [tex](x^a)^b=\\exp{[b\\log{e^{(a\\log{x})}]}=e^{b(a\\log{x}+2k\\pi)} = e^{ba\\log{x}}e^{2kb\\pi}[/tex]\n    On the other hand,\n    So, if b is an integer:\n    [tex](x^a)^b=e^{ba\\log{x}}e^{2kb\\pi}=e^{ba\\log{x}}= e^{ab\\log{x}} \\rightarrow (x^a)^b=x^{ab}[/tex]\n    As was to be shown. Note that if b is not an integer, then the function is multiple-valued and the relation need not hold if the wrong branch cut is chosen, as in the example \u03b5llipse gave. The fact that k can be chosen to be zero, though, guarantees the existance of a branch cut that will cause the relation to hold.\n    Last edited: Sep 5, 2005\n  13. Sep 5, 2005 #12\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    What is the definition of the square root symbol if not \"raised to the power 1/2\" ?!\n  14. Sep 6, 2005 #13\n\n    James R\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Consider [itex](a^4)^3[/itex], for example.\n\n    This means:\n\n    [tex](a^4)^3 = a^4 a^4 a^4 = a^{12} = a^{(4 \\times 3)}[/tex]\n\n    So, it seems sensible that, in general\n\n    [tex](x^a)^b = x^{ab}[/tex]\n\n    This is, of course, nowhere near a proof, but it's at least an intuitive argument for the natural numbers.\n  15. Sep 6, 2005 #14\n\n\n    User Avatar\n    Gold Member\n\n    The definition is the positive root. That's why it is often written as [itex]\\pm \\sqrt{x}[/itex] when you want to indicate either possibility. It is convenient because if you write [itex]\\sqrt{16}[/itex] everyone will know you mean 4, while if you write [itex]-\\sqrt{16}[/itex] everyone knows you mean -4.\n  16. Sep 6, 2005 #15\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Cleraluy the expoent noation orginated as a shorthand for mulplication of strings of the same number/variable:\n\n\n    a^2 = a*a\n\n    a^3 = a*a*a\n\n    a^n = a*a*....*a (where n is a ntural number)\n\n    are just definitions\n\n    From the basic properties of multplication, we can obtain a^n*a^m = a^(n+m) which allows us to dfeine integer powers and (a^n)^m which allows us to define rational powers.\n\n    So the relationship (a^n)^m comes from the basic properties of multplication and is used to extend our defitnion into rational powers.\n\n    The defitnion of expoentaion can be extended to real and complex powers as has already been discussed above.\n  17. Feb 7, 2011 #16\n    so whats the answer to that question\n  18. Feb 7, 2011 #17\n    or to write it another way, (a^4)^3 = (a*a*a*a)(a*a*a*a)(a*a*a*a)\n\n    Since everything is multiplication where a(bc)=(ab)c and ab=ba you can ignore the brackets.... so a is multiplied by itself 12 times or a^12\n\n    .. or 3 groups of (a*a*a*a), 3 x 4 = 12\n\n    Edit:.... wow, this was a really old thread!\n    Last edited: Feb 7, 2011\n  19. Feb 9, 2011 #18\n    what about (-1)^ [tex]\\frac{1}{\\sqrt{2}}[/tex] ?\n    is it a real number ?\n  20. Feb 9, 2011 #19\n\n\n    User Avatar\n    Science Advisor\n\n    Yes, that is the definition of the square root symbol.\n\n    We can define a^r for any positive real a and real r in the following naive way (it can be done more effectively by starting out with the log and exp-functions as power series):\n\n    For natural n we define a^n as multiplication n times (recursively, if you insist). That (a^n)^m=a^(nm) is trivially proved. To prove the order-preserving properties of a^n as a function in n is also trivial. (that is, a^n<=a^m <--> n<=m for a>=1, and oppositely for a<1). Extending to all negative integers is easy, and order will still be preserved.\n\n    a^(1/n) is defined as the positive zero of the polynomial x^n-a (which exists by the intermediate theorem and is unique as seen by factoring). We define a^(p/q) as (a^(1/q))^p which is well-defined by the previous definitions. This definition obviously coincide on the common domain of the previous definition. Again, that (a^(p/q))^(n/m)=a^(pn/qm) is trivially proved. That a^(p/q) is order-preserving is also easy to prove.\n\n    Now, for real r, let r_n be a increasing sequence of rational numbers converging to r. We define a^r as the limit the sequence a^(r_n). For a>1, this is an increasing sequence bounded above by a^k for some rational k>r, which can be shown using the order-preserving properties we arrived at previously. For a<1 it is a decreasing sequence similarly bounded below. For a = 1 it is constant, so the limit exists for any real r, and can trivially be shown unique for any such converging sequence. Similarly this definition coincide with the previous ones.\n\n    It remains to prove that (a^r)^s=a^(rs), but this is now trivial by using converging sequences for s and r.\n\n    For negative a you immediately run into trouble in the second step, when you want to define a^(1/n) by x^n-a which has no roots for even n.\n    Last edited: Feb 9, 2011\n\nHave something to add?\n\nSimilar Discussions: (x^a)^b = x^(ab)?\n  1. Combinations ab=x? (Replies: 9)\n\n  2. Abs(x-y) dydx (Replies: 6)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/properly-divergent-sequences.268043/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProperly Divergent Sequences\n\n  1. Oct 29, 2008 #1\n    Suppose that (x_n) is a properly divergent sequence, and suppose that (x_n) is unbounded above. Suppose that there exists a sequence (y_n) such that limit (x_n * y_n) exists. Prove that (y_n) ===> 0.\n\n    2. Relevant equations\n    (x_n) ===> 0 <====> (1/x_n) ===> 0\n\n    3. The attempt at a solution\n    One can say with certanty that (y_n) must be bounded, as if it weren't, for all K in Naturals, there exists a b_1 in (x_n) > |K| and b_2 > |K|, and there product is unbounded.\n\n    If (y_n) is bounded, and does not converge to 0, then... what?\n\n    That's where I'm stuck. How do I finish this?\n\n  2. jcsd\n  3. Oct 29, 2008 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If y_n does not converge to zero then there is an e>0 such that for all N there is an n>N such that |y_n|>e. If x_n is unbounded, what does this tell about y_n*x_n?\n  4. Oct 30, 2008 #3\n    When I was trying to prove it directly (for fun), I met some problems.\n    What is a *properly* divergent sequence?( I cannot find its definition in books)\n    If x_n is defined as follows:\n    x_n = 0 when n is even, x_n = n when n is odd\n    is it of such kind?\n    If so, define y_n as:\n    y_n = 1 when n is even, y_n = 0 when n is odd\n\n    does this gives x_n*y_n = 0, as a counter??\n    Last edited: Oct 30, 2008\n  5. Oct 30, 2008 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The crucial part of the problem is \"suppose that (x_n) is unbounded above\". Your example does not satisfy that.\n  6. Oct 30, 2008 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    A properly divergent series is one such that\n\n    (mathematics) A series whose partial sums become either arbitrarily large or arbitrarily small (algebraically).\n\n    So turning each partial sum into an element of the sequence, I believe a properly divergent sequence is one in which for all M there exists k s.t. j>k => |xj|>M\n  7. Oct 30, 2008 #6\n    Thanks..I forgot to search the web.... That would make sense. So a direct proof is also not hard.\n\n    BTW, to HallsofIvy, my x_n do satisfy the unboundedness, IMO.\n\nHave something to add?\n\nSimilar Discussions: Properly Divergent Sequences\n  1. Diverging sequence (Replies: 11)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/elastic-collision-is-outer-space.116432/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nElastic Collision is outer space\n\n  1. Apr 3, 2006 #1\n    I think I'm getting lost in the numbers somewhere here.\n\n    Two astronauts, one of mass 60 kg and the other 84 kg, are initially at rest in outer space. They then push each other apart. How far apart are they when the lighter astronaut has moved 10 m?\n\n    m1= 60 kg\n    m2=84 kg\n    X initial = 0\n    X1 final= 10 m\n    V1 inital = 0\n    V2 initial= 0\n    V 1 final= 10m/s\n    T=1 S\n\n    .5*60*0^2 + .5*84*0^2 = .5*60*10^2 +.5*84*V2Final^2\n    0=3000 + 42* V2Final^2\n    V2Final = -8.5 m/s\n\n    8.5+10=18.5 m\n  2. jcsd\n  3. Apr 3, 2006 #2\n\n    Physics Monkey\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Why did you say the final velocity for astronaut one is 10 m/s? This isn't right. You need to determine the velocity of each astronaut after they push off each other. Since the collision is elastic, you can use conservation of energy and momentum to find the two velocities. Notice that as it stands now, your astronauts have not conserved momentum!\n\n    Edit: Yikes, I knew there was some reason this question was bothering me. Redburns, I'm sorry, but I didn't read the question or your response very carefully. The square root of a negative number is imaginary, not another negative number. Clearly the \"collision\" or push can't be elastic since they start out with no kinetic energy. My apologies for posting too quickly without reading things carefully. You do need to use conservation of momentum.\n    Last edited: Apr 4, 2006\n  4. Apr 4, 2006 #3\n\n\n    User Avatar\n    Homework Helper\n\n    Their combined centre of mass will stay at the initial point and will not move after the interaction since they are experiencing only internal forces.\n  5. Apr 4, 2006 #4\n    In the question you posted no information is given about the strength of the push given and so finding the *numerical* velocity of either person A or B is gonna be a bit tricky (did one push very gently with his little finger or give him a mighty big shove!)...knowing these facts are not necessary!\n\n    What is important is that the impulse that A exerts on B is the same impulse that B imparts on A\n\n    Whether the lighter dudes velocity was 5m/s or 0.0001m/s he is always going to have travelled a distance of 10 meters at precisely the same point when the heavy dude has travelled 'a' meters (where 'a' is constant) (assuming no other forces are acting)\n    Last edited: Apr 4, 2006\n  6. Apr 4, 2006 #5\n    Thanks! I though I might be making this one harder than it should be.\n\nHave something to add?\n\nSimilar Discussions: Elastic Collision is outer space"}
{"text": "Retrieved from https://www.physicsforums.com/threads/plotting-the-position-of-a-pendulum.277475/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nPlotting the position of a pendulum\n\n  1. Dec 6, 2008 #1\n    Does anyone know where I could find some information about solving a pendulum position. What I mean is a swinging pendulum and the position. The position would be the spot on the ground that a sun directly above would cast. I don't really know where to start other then the pythagorean theorum, Ke and Pe equations. Any help would be great. thanks\n  2. jcsd\n  3. Dec 6, 2008 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The simple pendulum satisfies the differential equation [itex]d^2\\theta/dt^2[/itex]= -(g/l) sin(\\theta)[/itex] where g is the acceleration due to gravity, l is the length of the pendulum, t is the time, and [itex]\\theta[/itex] is the angle the pendulum makes with the vertical. Assuming the sun is directly overhead the shadow of the pendulm bob will be the horizontal coordinate, [itex]l cos(\\theta)[/itex].\n\n    That is an extremely difficult equation to solve but for small angles, [itex]sin(\\theta)[/itex] is approximately equal to [itex]\\theta[/itex] so the equation can be approximated by [itex]d^2\\theta/dt^2= -(g/l)\\theta[/itex] which has general solution\n    [tex]\\theta(t)= C cos(\\sqrt{g/l} t)+ D sin(\\sqrt{g/l} t)[/tex].\n\n    Determine C and D by the intitial value of [itex]\\theta[/itex] and the angular velocity.\n  4. Dec 6, 2008 #3\n    thanks a lot!\n\nHave something to add?\n\nSimilar Discussions: Plotting the position of a pendulum\n  1. Box plot (Replies: 1)\n\n  2. Researching plots (Replies: 7)\n\n  3. Plots in Mathematica (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/keplers-third-law.75968/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nKepler's third law\n\n  1. May 17, 2005 #1\n    not sure what to do here..\n\n    Im being asked to compare the periods of 2 different satellites in orbit around a planet.\n\n    the first one is a circular orbit of radius = r\n\n    the second one orbits 1r to the left and 3r to the right around the planet.\n\n    I'll attempt to draw it here :tongue:\n\n    0 is the planet\n\n\n    I understand how the period works in the first circular orbit.. but not the second one. any ideas?\n  2. jcsd\n  3. May 17, 2005 #2\n\n    Doc Al\n\n    User Avatar\n\n    Staff: Mentor\n\n    Start by reviewing what Kepler's 3rd law says.\n  4. May 17, 2005 #3\n    it states that r^3/T^2 = K\n\n    is it just the average radius of the second satellite? (in this case 2r ?)\n  5. May 17, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Yes, the mean distance, average radius, or, more commonly, the semi-major axis.\n\n    The shape of the orbit doesn't matter (your second orbit has an eccentricity of .5)\n  6. May 17, 2005 #5\n\n\n    User Avatar\n    Gold Member\n\n    So, a satellite in an eccentric orbit will have a period that is equivalent to a circular orbit whose radius is equal to (aphelion minus perihelion) of the eccentric orbit?\n\n    So, if an asteroid happened to be on an orbit that went out as far as Jupiter, and in as far as Mercury, its orbital period would be equivalent to a circular orbit whose radius is (Jupiter's - Mercury's) orbit?\n\n    I'd always wondered that.\n  7. May 17, 2005 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    A circular orbit whose radius is equal to the semimajor axis of the ellipse. Perihelion is\n\n\n    where a is the semimajor axis and e is the eccentricity. Aphelion is\n\n\n    So, the semimajor axis is given not by r_ap - r_peri, but rather:\n\n\n    This is what scales with period in Kepler's 3rd law:\n\n    [tex]P^2 \\propto a^3[/tex]\n  8. May 17, 2005 #7\n\n    James R\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n\nHave something to add?\n\nSimilar Discussions: Kepler's third law\n  1. Kepler's Third Law (Replies: 7)\n\n  2. Kepler's Third Law (Replies: 11)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/279860/probability-of-rolling-the-same-number-twice/279862\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nMath novice here. With a 10-sided die, the probably of rolling '1' is 10%. I'm tempted to think the probability of rolling '1' with two consecutive rolls is 20%. Would I be correct?\n\nNot sure if I need to factor in the first roll i.e. 10% + (10% - probability of NOT rolling 1 in the first roll). Or am I overthinking this?\n\nCLARIFICATION: I mean the probability of rolling a 1, then another 1.\n\nshare|cite|improve this question\nYou need to clarify your question. Do you mean the probability of rolling a $1$ at least once, exactly once, or both times? \u2013\u00a0Isaac Solomon Jan 16 '13 at 5:38\nGetting two $1$'s in a row must be less probable than getting the first one. You have to start with the first one, then can fail on the second roll. B.D has the correct answer, but this might help with intuition. \u2013\u00a0Ross Millikan Jan 16 '13 at 5:45\n@RossMillikan makes an excellent point. If you are trying to sync this intuition up with the array visualization I posted below, the single $1$ probability corresponds to the top-left square among just the squares in the top row; the two consecutive $1$s probability corresponds to that same square among all $100$ squares. \u2013\u00a0Benjamin Dickman Jan 16 '13 at 6:03\nup vote 3 down vote accepted\n\nThink of a $10 \\times 10$ array of squares, where each square represents a possible roll. For example, we could say the square in row $a$ column $b$ corresponds to rolling an $a$ first, and then rolling a $b$.\n\nWith these $100$ different possibilities, only one of them - the one in the top left hand corner - corresponds to rolling two consecutive $1$s.\n\nTherefore, the probability is $1/100 = 1\\%$.\n\n(More generally, you want to be multiplying the probabilities of independent events rather than adding them. This sometimes goes by the name of the \"multiplication rule.\")\n\nshare|cite|improve this answer\nWhat a wonderful way of visualizing it. Thank you very much. \u2013\u00a0hoipolloi Jan 16 '13 at 5:46\nYou could also visualize it by drawing a tree: 10 different points for each of the possible rolls, then each of those points gets 10 possible points for the subsequent roll. Again, you will end up with 100 possible two roll scenarios, of which only one is 1 followed by 1. This \"tree approach\" might make it clearer why you are multiplying probabilities instead of adding them. \u2013\u00a0Benjamin Dickman Jan 16 '13 at 5:48\n\nThe probability of rolling the same number twice on a $10$-sided die is $1\\over 10^2$, which is $1\\over 100$. This means that the probability is $1$%, so it's extremely unlikely that you'll make it.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/160329/measure-zero-in-r-but-not-in-r2\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI want to find some subset of R^2 which its intersection with every vertical line is measure zero if we see it as a subset of R and it is not measure zero in R^2?\n\nshare|cite|improve this question\nWhy?${}{}{}{}{}$ \u2013\u00a0Asaf Karagila Mar 14 '14 at 11:27\nbecause of some reasons in integrability of multivariable functions \u2013\u00a0alich Mar 14 '14 at 11:29\nWouldn't this contradict Fubini's theorem? Of course, assuming that the set is measurable in the first place. \u2013\u00a0Alex Degtyarev Mar 14 '14 at 11:31\nWhy does It contradict Fubini theorem? \u2013\u00a0alich Mar 14 '14 at 11:35\n@alich: Because such a set $A\\subseteq\\mathbb{R}^2$ would satisfy $0\\neq \\lambda^2(A) = \\int_{\\mathbb{R}^2} \\chi_A(x,y) d\\lambda^2(x,y) = \\int_\\mathbb{R} \\int_\\mathbb{R} \\chi_A(x,y) d\\lambda^1(x) d\\lambda^1(y) = \\int_\\mathbb{R} 0 d\\lambda^1(y) = 0$. (where $\\lambda^{1,2}$ denotes the 1-dimensional and 2-dimensional lebesgue meausure respectively) \u2013\u00a0Johannes Hahn Mar 14 '14 at 11:59\nup vote 9 down vote accepted\n\nIt is a well known result of Sierpinski that there exists non-measurable subsets of $\\mathbb{R}^{2}$ which intersect each line in at most two points. Furthermore, there exists a real-valued function whose graph is a non-measurable subset of $\\mathbb{R}^{2}$.\n\n  1. W. Sierpi\u00b4nski: Sur un probl`eme concernant les ensembles mesurables superficiellement. Fund. Math. 1 (1920), 112\u2013115.\n\n  2. Gelbaum, Bernard R., and John M. H. Olmsted. Counterexamples in Analysis. San Francisco: Holden-Day, 1964. (p. 142-145)\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/178841/leibniz-rule-of-a-product/179394\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWhy can't I apply Leibniz' rule in the following way?\n\n$$\\frac{d}{ds} g(s)\\int_0^\\infty f(s,x,u) \\, du = \\int_0^\\infty \\frac{d}{ds}g(s)f(s,x,u)\\,du,$$\n\nassuming $gf$ and $(gf)'$ are continuous on $[0,+\\infty]\\times [s_0,s_1]$ for some $s_0<s_1\\in\\mathbb{R}$.\n\nshare|cite|improve this question\nIt is unclear if there is any relationship between $s$, $x$ and $u$. Are $x$ and $u$ functions of $s$? \u2013\u00a0Siminore Aug 4 '12 at 16:51\n@Siminore, well, the $u$ is a dummy variable, so... \u2013\u00a0J. M. Aug 4 '12 at 16:57\nAs written, the domain of $f$ seems to be a subset of $\\mathbf R^2$, so the expression you've written doesn't make sense (saying that it is continuous in something two-dimensional). Unless you mean that for all $x$, $f(s,x,u)$ is continuous as a function of $s,u$ in the specified range. But in this case the usage of $x$ as a bound of the range is very confusing. \u2013\u00a0tomasz Aug 4 '12 at 20:13\nup vote 0 down vote accepted\n\nThe problem I was originally having was in thinking that $g(s)$ was a constant coefficient of the definite integral. However, since we wish to differentiate w.r.t. $s$ it seems we can not think of $g$ as a constant, which seems obvious now. Instead, we must treat $g\\int$ as a product and apply the product rule of differentiation, e.g.\n\n$$\\frac{\\partial}{\\partial s}g(s)\\int_0^\\infty f(s,x,u)du = g(s)\\frac{\\partial}{\\partial s}\\int_0^\\infty f(s,x,u)du + \\left(\\frac{d}{d s}g(s)\\right)\\int_0^\\infty f(s,x,u)du.$$\n\nWe can then take the $\\partial/\\partial s$ inside the integral as required.\n\nshare|cite|improve this answer\nIndeed, as long as you take a partial derivative, the other variables are as good as constants. I recommend using the standard notation \\partial for partial derivatives. \u2013\u00a0user31373 Aug 8 '12 at 3:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/193739/intersection-of-a-cone-and-sphere\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nShow that a the cone $xy + yz + xz = 0$ cuts the sphere $x^2 + y^2 + z^2 = r^2$ into two equal circles and find their area.\n\nI have been trying to substitute one of the variables, say $z$, from the equation of the cone and putting that into the sphere; this looks like the wrong approach though. Could someone please help me with this?\n\nshare|cite|improve this question\n\nI would start with a change of variables (orthogonal transformation) to diagonalize the quadratic form $xy + yz + xz$. Try $u = (x+y+z)/\\sqrt{3}$, $v = (x - y)/\\sqrt{2}$, $w = (x + y - 2 z)/\\sqrt{6}$.\n\nshare|cite|improve this answer\nAmazing! That's exactly the new choice of coordinates that I was about to recommend. \u2013\u00a0Lubin Sep 10 '12 at 20:07\nHi, Thanks a lot for your comment, I will try this approach too. \u2013\u00a0coolbootgeek Sep 10 '12 at 20:26\n\nThe cone's apex is at the origin, so it definitely intersects the origin-centered sphere in equal circles.\n\nNote that the cone contains the coordinate axes. (Simply set any two variables to zero, and see that the last can be arbitrary.) Consequently, it meets the sphere at the points $(\\pm r, 0, 0)$, $(0, \\pm r, 0)$, $(0,0,\\pm r)$, so that the circles of intersection must be circumcircles of equilateral triangles with side-length $r\\sqrt{2}$. So ...\n\nshare|cite|improve this answer\nGreat, thanks for the answer \u2013\u00a0coolbootgeek Sep 10 '12 at 20:25\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56764.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPerilous Ping-Pong\n\nDate: 11/14/97 at 10:16:11\nFrom: Amanda Stone\nSubject: Perilous ping-pong\n\nThe President is going to a ping-pong match in Tokyo. He is taking\n8 balls with him. A terrorist has implanted one of the balls with \nexplosives, but they add such a small amount that no one can tell the \ndifference. The CIA has only enough time for TWO weighings before the \n\nI know that you must weigh more than one ball on each scale and that \nyou can get information from the good batch of balls. Can you help?\n\n\nDate: 11/14/97 at 13:34:37\nFrom: Doctor Tom\nSubject: Re: Perilous ping-pong\n\nHi Amanda,\n\nI assume the explosive (bad) ball is heavier and the others all weigh \nthe same, or the problem is totally hopeless.\n\nThis isn't possible to solve if all you can do is weigh them. It can \nbe done in 3 weighings, assuming you already know what a normal ball \nweighs. In 3 weighings, here's how to do it:\n\n  Weigh 4 balls. If it is exactly 4 times as heavy as\n  one ball, the explosive ball is in the other batch, and\n  in any case, you've now got it down to 4.\n\n  Take the set of four with the bad ball and weigh 2 of them.\n  You now know which set of 2 is bad.\n\n  Weigh one of the 2 bad balls. If it's normal, the other is bad.\n\nI can prove that the problem, as stated, can't be solved in two\nweighings. Each weighing will give only one bit of information, and \nthere are 8 balls, so 8 possible solutions, which is 3 bits of \ninformation. With only 2 bits in two weighings, you can't possibly \nwork the problem.\n\nThe other possibility is that maybe the question means to use a\nbalance (where you can compare 2 weights). In this case, the problem \ncan be solved, even without knowing what a good ball weighs. In fact, \nyou could do it with up to 9 balls.\n\n  First, balance 3 against 3. If they balance, the heavy ball must\n  be among the other two, and a single comparison of those two on\n  the balance shows which one is heavy.\n\n  If not, the set of 3 that's heavier contains the bad one. Put\n  one of those on each side of the balance, and if one is heavier,\n  it's the bad one.  If they match, the other ball is bad.\n\n-Doctor Tom,  The Math Forum\n\nAssociated Topics:\nHigh School Puzzles\nMiddle School Puzzles\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/148897/determining-position-at-some-point-in-time\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI try to solve the following problem.\n\nOn $n$ parallel railway tracks $n$ trains are going with constant speeds $v_1$, $v_2$, . . . , $v_n$. At time $t$ = 0 the trains are at positions $k_1$, $k_2$, . . . , $k_n$. Give an $O(n\\log n)$ time algorithm that detects all trains that at some moment in time are leading.\n\nThe problem is I don't know how to approach the above problem. I assume it's should very popular problem in computational geometry. I saw it few times before, but never considered to solve it.\n\nIt looks like that the problem assumes preprocessing the data before giving input the moment of time.\n\nComplexity $O(n\\log n)$ points out to process similar to sorting.\n\nshare|cite|improve this question\nForgive my ignorance, but if you have the current time can't you just do $d=v*t+k$, loop through the trains one by one, and keep track of the farthest? That would be $O(n)$ if I understand the problem correctly. Or do they specifically want $O(n\\log n)$? It seems that fundamentally you're sorting an array of tuples $(train_n, v_nt+k_n)$ by their second element. \u2013\u00a0Robert Mastragostino May 24 '12 at 4:39\n@Robert: For the question to be interesting it probably means that the desired output is a list of indices $i$ such that train $\\#i$ was leading at some instant of time $t_i\\in[0,\\infty)$. \u2013\u00a0Jyrki Lahtonen May 24 '12 at 5:44\nHint: This should have the computational-geometry tag. \u2013\u00a0JeffE May 24 '12 at 8:08\nIf you view the train positions as lines in $t-v$ space, the region to the right of all lines is convex. You are looking for all trains that contribute a segment to the boundary. Maybe you can adapt one of the convex hull algorithms. \u2013\u00a0Ross Millikan May 24 '12 at 8:17\n@RossMillikan, Thank you for the comment. Let's say I almost get the idea. But could you please elaborate a little more please, I don't understand how to represent a position. \u2013\u00a0fog May 24 '12 at 18:20\nup vote 2 down vote accepted\n\nFollow-up on my comment, long for another: For any given train, the position at time $t$ is $v_it+x_{i0}$ where $v_i$ is the velocity of train $i$ and $x_i0$ is its position at $t=0$. This defines a line in the plane. The set of all lines defines a region to the left where at a given time there is at least one train to the right and a region to the right were there is no train to the right. The rightward region is convex. A train is rightmost precisely when its line is the boundary. For example, if train 1 starts at 0 with speed 1 and train 2 starts at -1 with speed 2, they meet at (1,1). Train $1$ is rightmost before $t=1$, and train $2$ is after $t=1$. If train 3 starts at -2 with speed $3/2$, it is never rightmost. If you plot the three lines you can see that. This forms the basis of my statement that you want a convex hull of the right region.\n\nshare|cite|improve this answer\nAnother term occasionally used for this concept is the upper envelope of the set of lines (for instance, in the generalization of this question to arbitrary convex curves instead of just lines, which leads to the study of Davenport-Schinzel sequences). \u2013\u00a0Steven Stadnicki May 24 '12 at 22:53\nThank you Ross Millikan, so $x$ it's a positions of the train, on $y$ it's a time. Therefore the task is to find the rightmost train on the given time, which can be done by sorting in $O(nlogn)$. \u2013\u00a0fog May 25 '12 at 4:40\n@fog: In you original post, it seemed you were to find a list of trains that were rightmost at any time, a different problem. You are right that at a given time you can calculate each train position in $O(n)$, then sort in $O(n\\log n)$ \u2013\u00a0Ross Millikan May 25 '12 at 11:00\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/91685/5-8-bound-in-group-theory/91686\nText:\nTake the 2-minute tour \u00d7\n\nThe odds of two random elements of a group commuting is the number of conjugacy classes of the group\n\n$$ \\frac{ \\{ (g,h): ghg^{-1}h^{-1} = 1 \\} }{ |G|^2} = \\frac{c(G)}{|G|}$$\n\nIf this number exceeds 5/8, the group is Abelian (I forget which groups realize this bound).\n\nIs there a character-theoretic proof of this fact? What is a generalization of this result... maybe it's a result about semisimple-algebras rather than groups?\n\nshare|improve this question\nThat formula can't be quite right, since the term on the left is $<1$ and the term on the right is $>1$. Presumably you're off by a factor of $|G|$? The quaternions and $D4$ realize that bound. \u2013\u00a0 Will Sawin Mar 20 '12 at 4:40\nA nice version would be to ask this for finite loops or quasigroups. Gerhard \"Ask Me About System Design\" Paseman, 2012.03.19 \u2013\u00a0 Gerhard Paseman Mar 20 '12 at 5:00\nYeah, I dug up the article by Gustafson. This question appears as an exercise. Both groups you mention have order 8. \u2013\u00a0 john mangual Mar 20 '12 at 5:03\nAny group with center of index 4 realizes this bound. (This is an iff). \u2013\u00a0 Steve D Mar 20 '12 at 5:21\nRobert Guralnick and I have a Journal of Algebra Article called \"On the Commuting Probability in Finite Groups\" (~2006) where we discuss at some length links between the commuting probability and character theory among other things. Much of the paper is reasonably elementary, including a proof that that the commuting probabilty tends to $0$ as $[G:F(G) \\to \\infty,$ where $F(G)$ is the largest nilpotent nomal subgroup of the finite group $G.$ I am not sure whether this paper would help for other algebraic systems though. \u2013\u00a0 Geoff Robinson Mar 20 '12 at 7:27\n\n3 Answers 3\n\nup vote 78 down vote accepted\n\nIf $c(G)> 5|G|/8$, then the average character has a dimension-squared of less than $8/5$, so at least $4/5$ of the characters are dimension $1$ (since the next-smallest dimension-squared is $4$), so the abelianization, which has one element for each 1-dimensional character, is more than half the size of the group, so the commutator subgroup has size smaller than $2$ and so is trivial.\n\nshare|improve this answer\nNeat! Small correction: the average dimension-squared is less than $8/5$. \u2013\u00a0 Noam D. Elkies Mar 20 '12 at 5:28\nThe fact that more than 4/5 of the characters have degree 1 does NOT imply that the group is abelian. Look, for example, at an extraspecial group of order 2^{2n+1}. This nonabelian group has 2^n degree 1 characters, but only one of larger degree. The argument in this answer is thus, at best, incomplete. \u2013\u00a0 Marty Isaacs Feb 14 '14 at 21:33\n@MartyIsaacs Recall that $(4/5) \\times (5/8)=(1/2)$, and so the number of $1$-dimensional characters is more than half the number of elements of the group, as desired. The implication you suggest is not stated in the argument. \u2013\u00a0 Will Sawin Feb 14 '14 at 23:36\n@WillSawin Right. Sorry, I misunderstood your argument. \u2013\u00a0 Marty Isaacs Feb 16 '14 at 17:42\n\nThere is a beautiful generalization due to Guralnick and Wilson, The Probability of Generating a Finite Soluble Group. Their results:\n\n1) if the probability that two randomly chosen elements of $G$ generate a solvable group is greater than $\\frac{11}{30}$ then $G$ itself is solvable,\n\n2) If the probability that two randomly chosen elements of $G$ generate a nilpotent group is greater than $\\frac{1}{2}$, then $G$ is nilpotent,\n\n3) if the probability that two randomly chosen elements of $G$ generate a group of odd order is greater than $\\frac{11}{30}$ then $G$ itself has odd order.\n\nInterestingly, these probabilities are best possible. Note also the elementary McHale article on probability of commutativity again.\n\nshare|improve this answer\n\nOne elementary result using character theory, but going in the other direction, which is proved in the paper of R. Guralnick and myself mentioned in my comment above is that if $\\{\\chi_1, \\chi_2, \\ldots, \\chi_c \\}$ are the complex irreducible characters of $G$, where $c = c(G)$ is the numberof conjugacy classes of $G,$ then by Cauchy-Schwarz, we have $\\sum_{i=1}^{c} \\chi_i(1) \\leq \\sqrt{c}\\sqrt{|G|}$, so that $\\frac{c(G)}{|G|} \\geq \\left( \\frac{\\sum_{i=1}^{c} \\chi_i(1)}{|G|} \\right)^{2}.$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/157792/is-there-a-nice-minimum-of-two-symmetric-operators?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ and $B$ be two bounded symmetric positive operators in Hilbert space, such that $A-B$ is trace class. If needed, $A$ and $B$ may be assumed reasonably \"small\", let's say, Hilbert-Schmidt.\n\nDoes there exist another symmetric operator $C$, $0 \\le C \\le A$, $0 \\le C \\le B$, such that both $A-C$ and $B-C$ are trace class?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 9 down vote accepted\n\nLet $P=\\left[\\begin{matrix} 1 & 0 \\\\ 0 & 0 \\end{matrix}\\right]$ and $Q(\\phi)=\\left[\\begin{matrix} \\cos^2(\\phi) & \\cos(\\phi)\\sin(\\phi) \\\\ \\cos(\\phi)\\sin(\\phi) & \\sin^2(\\phi) \\end{matrix}\\right]$. Then $P$ and $Q$ are orthogonal projections and if $\\phi\\neq 0$, then the only operator $T$ which satisfies $0 \\leq T \\leq P$ and $0 \\leq T \\leq Q(\\phi)$ is zero.\n\nNow, set $A := \\oplus_{n \\in \\mathbb N} n^{-1} P$ and $B:= \\oplus_{n \\in \\mathbb N} n^{-1} Q(\\pi/n)$.\n\nThen, $A,B$ are Hilbert-Schmidt (and not trace-class), $A-B$ is trace-class and the $2$-dimensional phenomenon from above shows that every operator $C$ with $0 \\leq C \\leq A$ and $0 \\leq C \\leq B$ must be zero. In particular, $A-C$ and $B-C$ are not trace-class. Thus, the answer to your question is no.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathcentral.uregina.ca/QQ/database/QQ.09.06/jay1.html\nText:\nSubject: Calculus\nName: Jay\nWho are you: Student\n\nA snowball melts at a rate proportional to its surface area. Show that its radius shrinks at a constant rate. If it melts to 8/27 of its original volume in 20 minutes, how long will it take to melt completely? Please I need your help.\n\n\nHi Jay.\n\nLet's take this question step by step: first, the \"snowball melts at a rate...\" is clearly referring to the change in volume of the snowball with respect to time. If V = volume,\nA = surface area and R = radius, then dV/dt is what this phrase means.\n\nNow \"...proportional to its surface area.\" means that the dV/dt (the first part of the sentence) varies directly with the surface area A. Varies directly just means that the two terms are equal, but there is a constant of proportionality (usually called k) as a factor (usually attached to the second term). That means:\n\ndV/dt = kA.\n\nSo that's all the first sentence says.\n\nThe question is \"show that the radius shrinks at a constant rate\". That means the change in radius with respect to time is constant (let's call this constant q). So that means you are asked to show dr/dt is some constant.\n\nThe way to do this is to know the formulas for the volume and surface area of a sphere:\n\nV = (4/3) \u03c0 r3 and A = 4 \u03c0 r2\n\nand take derivatives.\n\ndV/dt is the derivative of volume with respect to time, but remember that r is also changing, so you have to use the chain rule:\n\ndV/dt = d/dt((4/3) \u03c0 r3) = (4/3) \u03c0 3 r2 (dr/dt)\n\nNow let's plug that into the first equation:\n\n(4/3) \u03c0 3 r2 (dr/dt) = k A = k(4 \u03c0 r2) = 4 \u03c0 k r2\n\nSo when we simplify by dividing left and right sides by 4 \u03c0 r2, we get:\n\ndr/dt = k\n\nwhich is saying exactly what we wanted to prove: that dr/dt is constant.\n\nFor the second (numerical) part of the question, you don't know the\noriginal volume (call it V again), but hopefully it will cancel out\nlater, so just start with what you know. Call the original radius R,\nthe radius after 20 minutes r, and the volume after 20 minutes v,.\n\nV = 4/3 \u03c0 R3\nv = 4/3 \u03c0 r3\nv = (8/27)V\n\nNow use this last equation to tie together the two volume equations:\n\n4/3 \u03c0 r3 = (8/27) (4/3 \u03c0 R3)\n\nso when you simplify and take the cube root,\n\nr = 2/3 R\n\nThat's very useful, because it is saying that the new radius is 2/3 the initial radius. But since the change in radius with respect to time is constant, the radius is shrinking at a constant rate. So if the radius lost 1/3 its length in 20 minutes, it will take another 40 minutes to melt away completely.\n\nStephen La Rocque.>"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/96642/block-on-cart-equation-of-motion\nText:\nTake the 2-minute tour \u00d7\n\nConsider a rigid block of $b \\times h$ having mass $m$ on cart (as depicted below). The cart is given an acceleration $a$, this leads to overturning of the block. The angle of rotation is indicated by $\\theta$.\n\nThis is how far I got (not considering the movement of the cart): The Lagrangian $L=T-V$ is calculated using $$T = \\frac12 J \\dot{\\theta}^2$$ $$V = m g \\Delta_y = m g \\bigg(r \\cos(\\alpha - \\theta) - \\frac{h}{2}\\bigg) $$ so that $$\\frac{\\mathrm{d}}{\\mathrm{d} t} \\bigg( \\frac{\\mathrm{d} L}{\\mathrm{d} \\dot{\\theta}} \\bigg) - \\frac{\\mathrm{d} L}{\\mathrm{d} \\theta} = 0$$ yields the EOM $$J\\ddot{\\theta} + m g r \\sin(\\alpha-\\theta) = 0$$ Now, my question is: how do I add the acceleration of the cart to the RHS? My initial guess would be $$J\\ddot{\\theta} + m g r \\sin(\\alpha-\\theta) = m a r \\cos(\\alpha - \\theta) $$ where $ma$ is the force and $r \\cos(\\alpha - \\theta)$ the lever arm. But I don't believe this is true since the block does not experience the acceleration $a$ over its full body. Can anyone help or provide some literature? Thanks.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nVerified it with FEA, it is correct.\n\nAlso, taking into account the \"rocking\" effect requires the piece-wise description: $$ J\\ddot{\\theta} + \\bigg\\lbrace\\begin{matrix} -m g r \\sin(\\alpha + \\theta) & \\theta < 0 \\\\ m g r \\sin(\\alpha - \\theta) & \\theta \\geq 0 \\end{matrix} = m a r \\cos(\\alpha - \\theta) $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/102358/is-the-following-curve-a-circle?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\gamma(\\theta)=(\\sin(\\theta+\\alpha)\\cos\\theta,\\sin(\\theta+\\alpha)\\sin\\theta),\\theta\\in[0,2\\pi]$. Is $\\gamma(\\theta)$ a circle? What is the radius of it?\n\nshare|improve this question\nHint en.wikipedia.org/wiki/\u2026 \u2013\u00a0 David Speyer Jan 25 '12 at 17:13\nPlot it (for some suitably chosen values of $\\alpha$, such as $0$ and $\\pi/2$). Does is look like a circle? If so, what does its center and radius appear to be? If you write down the naive parameterization of a circle with that center and radius, can you prove that it equals your $\\gamma$? \u2013\u00a0 Henning Makholm Jan 25 '12 at 17:15\nPedantic note: $\\gamma$ might or might not be (the equation of) a circle (here, it is) but $\\gamma(\\theta)$ is a point in the plane. \u2013\u00a0 Did Jan 25 '12 at 17:20\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nLet's recall two trigonometric identities: $$ \\begin{align} \\sin\\gamma\\cos\\delta & = \\frac{\\sin(\\gamma+\\delta)+\\sin(\\gamma-\\delta)}{2} \\\\ \\\\ \\sin\\gamma\\sin\\delta & = \\frac{\\cos(\\gamma-\\delta)-\\cos(\\gamma+\\delta)}{2} \\end{align} $$ So put $\\theta+\\alpha$ in the role of $\\gamma$ and $\\theta$ in the role of $\\delta$. Then we have $$ \\begin{align} \\sin(\\theta+\\alpha)\\cos\\theta & = \\frac{\\sin\\alpha+\\sin(2\\theta+\\alpha)}{2} \\\\ \\\\ \\sin(\\theta+\\alpha)\\sin\\theta & = \\frac{\\cos\\alpha-\\cos(2\\theta+\\alpha)}{2} \\end{align} $$ As $\\theta$ goes from $0$ to $2\\pi$, this point goes twice around a circle centered at $(\\sin\\alpha,\\cos\\alpha)/2$, with radius $1/2$ (and diameter $1$).\n\nshare|improve this answer\n\nUsing polar coordinates $(r,\\theta)$, the equation of this curve is $$ r=\\sin(\\theta+\\alpha)=\\sin(\\theta)\\cos(\\alpha)+\\cos(\\theta)\\sin(\\alpha). $$ One sees that $r^2=r\\sin(\\theta)\\cos(\\alpha)+r\\cos(\\theta)\\sin(\\alpha)=y\\cos(\\alpha)+x\\sin(\\alpha)$, hence $$ x^2+y^2-x\\sin(\\alpha)-y\\cos(\\alpha)=0. $$ This is indeed the equation of a circle. Let me indicate its radius is $ \\frac12$ and leave you the joy to find its center.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/536810/number-of-fibonacci-numbers-in-a-range?answertab=active\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nThe definition of the Fibonacci numbers is given by:\n\n$$\\begin{align}f_1 &= 1;\\\\ f_2 &= 2;\\\\ f_n &= f_{n-1} + f_{n-2},\\qquad (n >= 3); \\end{align}$$\n\nnow we are given two numbers $a$ and $b$, and we have to calculate how many Fibonacci numbers are in the range $[a,b]$. How can we calculate it?\n\nshare|cite|improve this question\nNaively just compute all Fibonacci numbers smaller or equal to $b$ and count. Maybe you should clarify what you mean by 'calculate'. A closed form dependent on $a$ and $b$ will probably not exist. \u2013\u00a0Simon Markett Oct 23 '13 at 10:22\nYour definition of Fibonacci numbers is off by one from the standard indexing. Normally $f_2=1, f_3=2$. My answer uses the standard indexing. The final answer doesn't change as we are subtracting two indices. \u2013\u00a0Ross Millikan Oct 23 '13 at 10:43\n'calculate'means total fibonacci numbers between the range... \u2013\u00a0rock321987 Oct 23 '13 at 11:05 it \u2013\u00a0rock321987 Oct 23 '13 at 11:06\nup vote 1 down vote accepted\n\nThis question is asked in Skiena's programming challenges. Now, to find the $ n^{\\text{th}} $ fibonacci number, we have the following closed form expression.\n\n$$ \\Large F(n) = \\dfrac{1}{\\sqrt{5}} \\left( \\left( \\dfrac{1 + \\sqrt{5}}{2}\\right)^n - \\left( \\dfrac{1 - \\sqrt{5}}{2} \\right)^n\\right) $$\n\nNow, given $ F(n) $, we can find approximately the index of the closest fibonacci number to it. Therefore, we find one $ n_1 $ such that $ F(n_1) = a $ and another $n_2 $ such that $ F(n_2) = b $. Then our answer is $\\mathsf{round(n_2)} - \\mathsf{round(n_1)}$ where $ \\mathsf{round(x)} $ find the nearest integer to $ x $.\n\nshare|cite|improve this answer\nIs the PDF in the link really freely available or is it a copyright violation? \u2013\u00a0lhf Apr 29 '14 at 12:13\nI'll change the link, since I am not sure. \u2013\u00a0adijo Apr 29 '14 at 12:20\n\nWe know that $F_n\\approx \\frac {\\phi^n}{\\sqrt 5}$, so given $a$, the next larger Fibonacci number is $F_k$, where $k= \\left \\lceil\\frac {\\log (a\\sqrt 5)}{\\log \\phi }\\right \\rceil$. Similarly the $F_m$ below $b$ is $m= \\left \\lfloor\\frac {\\log (b\\sqrt 5)}{\\log \\phi }\\right \\rfloor$, then there are $m-k+1$ between $a$ and $b$. You have to think about what you want if $a$ or $b$ are themselves Fibonacci numbers.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/182375/relationship-of-a-point-to-a-rotating-plane\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI have three points in space, which cannot move relative to one another, and create a reference plane.\n\nThere is a forth point, that lays off/on the plane (off will be more general solution, on will be a private case I guess).\n\nHow can I use the information I just described to predict where the point off/on the plane will lie when the plane moves? The point is constrained by the original relationship.\n\nFor example: $P_1$, $P_2$, $P_3$ define a plane and they are respectively $(1,1,5) , (0,1,5) , (-1,0,5)$.\nThe fourth point $P$ is $(-5,2,5)$ on the plane defined by $P_{1,2,3}$. What would be the coordinates of $P$ when the plane moves (arbitrary rotation in space) and $P_{1,2,3}$ have new values. In the example all points are on the same $z$ plane $(5)$ in the initial reference state.\n\n\nshare|cite|improve this question\nAre only rotations allowed? When you say 'rotation' you mean rotations around any axis, right? Are the old values of $P_i$ mapped onto the new ones (meaning that the angles of the triangle $P_1P_2P_3$ are preserved)? \u2013\u00a0Karolis Juodel\u0117 Aug 14 '12 at 9:11\nrotation could be any rotation, not just around specific axis. the old values are mapped. imagine a tool with 4 significant points that travels freely in the 3d space. \u2013\u00a0ButterFly Aug 14 '12 at 14:32\n\nConstruct the transformation matrix used on the plane and multiply $P$ by it. The matrix is $BA^{-1}$ where matrices $A$ and $B$ move the $xOy$ plane to the one defined by old and new values of $P_i$ respectively.\n\nHere's a way to construct $A$ and $B$. It makes sense to use $4 \\times 4$ matrices. Otherwise you couldn't map $(0, 0, 0)$ to anything else. The columns of the matrices could be as follows. $(P_2-P_1, 0)$, $(P_3-P_1, 0)$, $((P_2-P_1) \\times (P_3-P_1), 0)$ and $(P_1, 1)$. The first $3$ rows are filled with the values of the vectors I wrote and the last row is $(0, 0, 0, 1)$. Note that the third column could be anything. A perpendicular vector is probably what you are looking for, though. Notice that, for example, $A*(1, 0, 0, 1) = (P_2, 1)$. Finally, $BA^{-1}*(P, 1)$ is the new value of $P$.\n\nshare|cite|improve this answer\nA is perpendicular to the old or new plane ? is it a norm vector ? \u2013\u00a0ButterFly Aug 14 '12 at 14:36\nA and B are matrices. The upper left $3 \\times 3$ part of either is supposed to have orthonormal vectors for columns. Since we are combining two matrices, these vectors can be 'wrong', as long as they are 'wrong' the same way in A and B. The third vector is the normal of the plane - the old plane in A and the new plane in B. \u2013\u00a0Karolis Juodel\u0117 Aug 14 '12 at 15:04\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/77218/two-polynomials?sort=votes\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIf $p,q:\\mathbb R^3\\rightarrow\\mathbb R$ are two polynomials, such that $\\{p=0\\}\\cap\\{q=0\\}$ is two-dimensional, does it follow that $p$ and $q$ have a common factor? (I believe it does.) How to prove that?\n\nshare|cite|improve this question\nWe consider the rimg $A = R[x,y,z]$, $dim A = 3$. We have $V((p)) \\cap V((q)) = V((p,q))$. If $gcd(p,q) = 1$, then $ht(p,q) = 2$. So $V((p)) \\cap V((q))$ is not 2-dimension \u2013\u00a0Pham Hung Quy Oct 5 '11 at 10:47\n@Pham Hung Quy: Why don't you make this an answer? Otherwise this question may linger around until someone else comes in and gives your comment as an answer just to stop the Mathoverflow-bot from bumping the question \u2013\u00a0David White Oct 5 '11 at 12:19\nI am sorry David White. I am not good at algebraic geometry. So I posed it as a comment, and I hope to see a better anwser. Now I pose it as an anwser. \u2013\u00a0Pham Hung Quy Oct 5 '11 at 15:53\n\nHere is my answer. We consider the rimg $A=R[x,y,z]$ , $dimA=3$. We have $V((p))\u2229V((q))=V((p,q))$. If $gcd(p,q)=1$, then $ht(p,q)=2$. So $V((p))\u2229V((q))))=V((p,q))$ is not 2-dimension.\n\nshare|cite|improve this answer\nunfortunately, i don't understand the proof. what is ht(p,q)? \u2013\u00a0filipm Oct 6 '11 at 8:26\n$ht(I)$ is the height of $I$, (see, Notice that $\\mathbb{R}[x,y,z]$ is a Gassian ring, hence a prime ideal of height 1 is a principal ideal $(f)$ with $f$ is a irreducible polynomial. If $ht(p,q) = 1$, then $(p,q) \\subset (f)$ for some $f$, so $f$ is a common factor of $p$ and $q$, a contradiction. Thus $ht((p,q))>1$ (= 2), so $\\dim A/(p,q) < 2$. So $V((p,q))$ is not dimension two (see, Atiyah-Macdonald: Introduction to Commutative algebra, chapter 11 as example). \u2013\u00a0Pham Hung Quy Oct 6 '11 at 17:01\nthx Pham Hung Quy, now it's much clearer, I'll try to digest it. \u2013\u00a0filipm Oct 7 '11 at 15:39\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/157784/can-we-always-find-a-primitive-element-that-is-a-square\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $L/\\mathbb Q$ be a galois extension. The Primitive element theorem says, that there is an element $\\alpha \\in L$, so that $L=\\mathbb Q(\\alpha)$.\n\nCan I always find an element $\\beta \\in L$, so that $L=\\mathbb Q(\\beta^2)$ ?\n\nshare|cite|improve this question\nGreat question! Just a small point: the primitive element theorem only applies to finite extensions. \u2013\u00a0Zev Chonoles Jun 13 '12 at 14:04\nAlso, the extension doesn't need to be Galois, just separable. [And over $\\mathbf Q$ everything is separable.] \u2013\u00a0Dylan Moreland Jun 13 '12 at 14:05\nThis is certainly true if $L$ has odd degree over $\\mathbf Q$. Do you see why? \u2013\u00a0Dylan Moreland Jun 13 '12 at 14:08\nup vote 7 down vote accepted\n\n$\\newcommand{\\Q}{\\mathbb Q}$\n\nI think this works. Let $K/\\Q$ be a finite field extension. Note that $K$ has finitely many subfields, call them $F_1,\\dots,F_t$ and let $W$ be their union. Then any element in $K \\setminus W$ is necessarily a primitive element. So it suffices to show their exists some $\\alpha \\in K \\setminus W$ that has a squareroot. Pick $\\alpha \\in K \\setminus W$, note that for $k \\in \\Q$ we still have $\\alpha_k=\\alpha + k \\in K \\setminus W$ otherwise $\\alpha \\in W$. Consider $\\alpha_k^2=(\\alpha+k)^2=\\alpha^2+2k\\alpha+k^2$ suppose that for every $k \\in \\Q \\setminus {0}$ we have $\\alpha_k^2 \\in W$. Then by the pigeonhole principle we must have some $j$ and $k_1 \\neq k_2$ such that $\\alpha_{k_1}^2,\\alpha_{k_2}^2 \\in F_j$. So we have\n\n$$\\frac{\\alpha_{k_1}^2-\\alpha_{k_2}^2-(k_1^2+k_2^2)}{2(k_1-k_2)} \\in F_j$$\n\n\n$$ \\frac{\\alpha_{k_1}^2-\\alpha_{k_2}^2-(k_1^2+k_2^2)}{2(k_1-k_2)} =\\frac{2\\alpha(k_1-k_2)}{2(k_1-k_2)}=\\alpha. $$\n\nWhich would imply that $\\alpha \\in F_j \\subset W$ so we have some $k \\in \\Q\\setminus \\{0\\}$ such that $(\\alpha+k)^2 \\in K \\setminus W$ and thereby $\\Q((\\alpha+k)^2)=K$.\n\nI think this could be turned into a constructive argument fairly easy. Take one of the primitive elements given to you by the primitive element theorem then add $t+1$ non-zero rational numbers to it and the square of one of those will be the desired element.\n\nAmmendum: This could also extend to a proof that there always exists an element $\\alpha \\in K$ such that $\\Q(\\alpha^n)=K$. Essentially use the same argument except find $t$ such distinct $c_i$ so that $\\alpha_{c_i}^n \\in F_t$ then notice that the matrix given by $A_{ij}=\\binom{m}{j}c_i^j$ has determinant a constant multiple of the vandermode matrix $A_{ij}=c_i^j$. Thereby the determinant is nonzero and so we can find a linear combination of the $\\alpha_{c_i}^n$ that gives us $\\alpha$.\n\nshare|cite|improve this answer\nThank you very much. It is a nice proof. \u2013\u00a0Lisa Mainhard Jun 14 '12 at 13:18\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/67041/how-many-elements-with-a-hamming-distance-of-3-or-less/67104\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\n[This is a complete rewrite which makes some of the comments redundant or irrelevant.]\n\nTake a set of $50$ elements. How many subsets of size $5$ are needed so that every subset of size $5$ will intersect at least one of these in at least $2$ points?\n\nThis collection of subsets is known as a lottery wheel or a lotto design. $L(v,k,p,t)$ is the minimum number of subsets of a $v$ element set so that each subset has size $k$ with the property that every $p$ element subset intersects at least one $k$-subset in at least $t$ points. If you select $5$ out of $50$ numbers in a lottery which pays a prize for getting at least $2$ numbers right, then you can ensure getting a prize if you buy a particular collection of $L(50,5,5,2)$ tickets. The question is to find $L(50,5,5,2)$.\n\nshare|cite|improve this question\nCould you explain your definition of $d_h$ a bit more? (By the way, that formula defining $S$ is horrendous! Words really are better for these things.) \u2013\u00a0James Cranch Jun 6 '11 at 13:58\nThis sounds like lottery wheels or lottery designs. I suggest a web search. Gerhard \"Ask Me About System Design\" Paseman, 2011.06.06 \u2013\u00a0Gerhard Paseman Jun 6 '11 at 18:53\n@chous: you have not really defined $S_3$ uniquely. I think what you're really saying is that you want some set $T$ such that for every $s \\in S$ there is some $t \\in T$ with $d_h(s,t) \\le 3$. There are lots of such sets, for example $S$ itself. But perhaps what you want is one with minimum cardinality: you're talking about a \"minimal cover problem\" in a graph $G$ consisting of the elements of $S$, with edges corresponding to pairs with Hamming distance $\\le 3$. \u2013\u00a0Robert Israel Jun 7 '11 at 0:54\nHamming distance works better on sequences than on sets. Although we could phrase your distance in terms of the symmetric distance of two sets, I think it easier to say \"For any 5-set t, I want there to be at least one of my 5-sets s in S such that s intersect t has at least two elements. Further, I want S chosen so that S has as few 5-sets in it as can be managed.\" The La Jolla Covering Repository answers this sort of question (if I read it right). Do a web search and check it out if you agree. Gerhard \"Donates Regularly To Mega Millions\" Paseman, 2011.06.06 \u2013\u00a0Gerhard Paseman Jun 7 '11 at 1:44\nYou are asking for a wheel with parameters $(50,5,2)$. A covering design is different, which is unfortunate because there is a nice searchable database of covering designs, the La Jolla Covering Repository which Gerhard Paseman mentions. Most of the web hits when you search for lottery wheels are trying to sell junk to lottery players. \u2013\u00a0Douglas Zare Jun 7 '11 at 8:29\nup vote 7 down vote accepted\n\nYou are not using the positions at all. You have 50 points. $S$ is the set of all $\\binom{50}{5}=2118760$ selections of 5 points. You want a subset $B \\subset S$ such that any $s \\in S$ intersects at least one $b \\in B$ in at least 2 points. That is an interesting problem and does not immediately strike me as familiar. Call a member of $B$ a block. A given block intersects $152026$ members of $S$ in 2 or more points. This gives a lower bound of $14$ for the possible size of $B$. Of course this a weak bound since two disjoint blocks determine $200$ members of $S$ intersecting one in 2 points and the other in 3 and another $4000$ intersecting each in 2 points. If my calculations are correct, that raises the lower bound to at least $19$ blocks. I doubt that $20$ would suffice.\n\nSo far my record is 44 blocks.\n\nLet me digress for some terminology (which I'll try to keep fairly standard). a design is a pair $D=(V,B)$ where $V$ is a set of $v$ vertices and a $B$ is a collection of subsets called blocks There are various names for designs which satisfy additional conditions. Two are\n\nEvery pair of points is in exactly one common block. (Then $D$ is called a linear space)\n\nEvery pair of points is in at least one common block and every block has the same number $k$ of points. (Then $D$ is called a $(v,k,2)$-covering design and the La Jolla Repository has information about these.)\n\nWhen both conditions hold, $D$ is called a Steiner System $S(2,k,v).$ Many that one encounters arise from algebraic constructions. This is perhaps due to the Streetlight effect.\n\nI'll coin the term super-linear space for a design such that every pair of points from $V$ occur in at least one common block but the blocks may have various sizes (since I don't know a standard name. It turns out that this might be called a lottery wheel although that term is not very specific)\n\nYou have $50$ points and do not require that every pair of points is in a block but do wish that from every 5 points (element of $S$), at least one pair is in at least one block. You also want all blocks to have $5$ points. I'll find it convenient to only require that each block have at most 5 points, then one can arbitrarily enlarge blocks to size 5.\n\nAll my constructions have this form: Split the points into 4 groups (or 2 or 3) and for each group take a super-linear space with no block having more than 6 points. Then any element of $S$ has two points in the same group and those two points are in a common block. Perhaps one can do better without this restriction. I include a few other possibilities in case it inspires anyone to get a better result.\n\n44* blocks. Split into 4 groups of size 21,21,4 and 4. For each of the large groups take the 21 lines of a projective plane of order 4 and let the two small groups be 4 point blocks. Now any set in $S$ has at least two points in a common group and those two pints determine a unique block.\n\n60 blocks: split the points into two sets of 25 and use the 30 lines of an affine plane of order 5 on each. This is overkill because any 3 element set has two points in some block. Perhaps there is a way to cull out some of the lines.\n\nUnder 52 blocks If the points are partitioned into 3 groups of 13 and one of 11 (with two fake points added in) then (for each group) the lines of a projective plane of order 3 were taken as blocks this would give a solution with 52 blocks of size 4. Delete $X,Y$ to improve this to 45 of size 4 and 6 of size 3 and one of size two. Now tack the block of size 2 onto a block of size 3 to get $51$ blocks (one of size 5). (If $X,Y$ are in different groups it might be better, I haven't checked.) One can also get rid of at least 3 more blocks as follows: take a block abcd, delete it and add b as a fifth point to a block containing c and another containing c, add c as a fifth point to two blocks containing d and a and add d as a fifth point to two blocks containing a and b.\n\nshare|cite|improve this answer\nThanks a lot! How would you recommend to build the projective 3 space of order 4? I think I'm currently not ready for this task :(. \u2013\u00a0chous Jun 7 '11 at 12:18\nAaron Meyerowitz's construction for $42$ blocks used $F_3$ rather than $F_4$, which should make it easier. The construction is just like that of $\\mathbb{RP}^3$ so that the points are lines passing through the origin in $\\mathbb{R}^4$ and the lines of $\\mathbb{P}^3$ correspond to (two-dimensional) planes passing through the origin. $\\mathbb{P}^3(F_4)$ has $(4^4-1)/(4-1)=85$ points, though. \u2013\u00a0Douglas Zare Jun 7 '11 at 17:53\n$\\mathbb{P}^3(F_3)$ has ${40 \\choose 2}/{4 \\choose 2} = 130$ lines, not $40$, so the construction for $42$ blocks actually uses $132$ blocks. It was a little too good to be true since it would mean any quadruple would intersect a block in $2$ points, and it would be easy to use the $5$th points to make a line redundant. \u2013\u00a0Douglas Zare Jun 7 '11 at 18:40\n\nHere is a construction of size $38$. Call the points cards and divide the deck into $4$ suits, so that $2$ suits have ranks $1,...,13$ and $2$ suits have ranks $1,...,12$. Every hand of $5$ cards must have at least $2$ cards in some suit. So, if we cover all possible pairs in each suit, the result will be a wheel.\n\nThe La Jolla Covering Repository says that $C(12,5,2)=9$ so we can cover all pairs within the short suits with $9$ hands each:\n\n1  2  4  7  9 \n1  3  4  6 12 \n1  3  7 10 11 \n1  5  6  8 12 \n2  3  5  7  8 \n2  6 10 11 12 \n3  6  7  9 12 \n4  5  8 10 11 \n5  8  9 10 11 \n\nSimilarly, it says $C(13,5,2) \\le 10$ so we can cover all pairs within the long suits with $10$ hands each:\n\n1  2  3  4  5\n1  6  7  8  9\n1 10 11 12 13\n2  3  6  7 10\n2  3  8  9 11\n4  5  6  7 11\n4  5  8  9 10\n2  3  4 12 13\n5  6  7 12 13\n1  8  9 12 13\n\nThe total is $38$ hands which intersect each hand of $5$ cards in at least $2$ cards. So, $L(50,5,5,2) \\le 38$.\n\nEdit: The best this method can do with the coverings known in the La Jolla Repository is $37$. That can be done by splitting a $50$ card deck into suits of sizes $(17, 11, 11, 11),$ $(13,13,13,11)$, or $(15, 13, 11, 11)$.\n\n$C(17,5,2) \\le 16$.\n\n$C(15,5,2) \\le 13$.\n\n$C(13,5,2) \\le 10$ as shown above.\n\n$C(11,5,2) \\le 7$.\n\nshare|cite|improve this answer\nThanks (truly!) for clarifying the question and making my LJCR comment less useful (since a covering design was not wanted) and also more useful (by showing how two covering designs could help). Gerhard \"Likes To Feel Really Useful\" Paseman, 2011.06.07 \u2013\u00a0Gerhard Paseman Jun 7 '11 at 23:47\nThanks! I wish I could mark more than one answers. Searching in the Internet I found a solution with 36 tuples, and I'll try to find more using your suggestions, but I'm not discarding using a \"branch and bound\" algorithm. \u2013\u00a0chous Jun 8 '11 at 19:45\n@Douglas Zare: Thanks for rewriting the question. It's much clearer now. \u2013\u00a0chous Jun 8 '11 at 19:50\nPlease post at least a link to the wheel of size $36$, since it must have been constructed using a different method. It's ok to answer your own question. \u2013\u00a0Douglas Zare Jun 8 '11 at 20:01\nThis 36 block solution is nice. It is actually close to one of the 37 block solutions by @Douglas. In the solution with suits of size 11,11,11,17 and covering designs of sizes 7,7,7,16, each covering design has a block which can be reduced to 3 cards. Take the 3 card blocks abc def ghi jkl and replace them by abcjk defjl ghikl. In fact one of the pairs from jkl ( in the 17 card suit) has a pair already covered so one could leave one of the hands with three cards. \u2013\u00a0Aaron Meyerowitz Jun 10 '11 at 5:38\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/690866/triangle-geometric-problem\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn triangle ABC, AB=BC=12. Side AC extended through C a length equal to itself to a point D. Point E is on AB; DE intersects BC at F and BF equal to 8. Find AE ?\n\nshare|cite|improve this question\n\nThe answer is $AE=BE=6$ because in the triangle ABD, BC is a median and F is the intersection point of medians, therefore DE is also median. Since, $BF=8$ then $CF=4$, but we know that the intersection point of medians splits them into two segments which lenghts have quatient 2:1 from the vertex.\n\nshare|cite|improve this answer\n+1 Nice way of seeing it, in this special setup. You could fill in a bit more details about why F is the centroid (of what triangle). \u2013\u00a0Calvin Lin Feb 26 '14 at 6:56\n\nBC divides AD in half. So in triangle ABD, BC is the median. BF:FC = 2:1, so F is the centroid. Since ED passes through centroid, it is also a median. Hence AE = BE = 6.\n\nshare|cite|improve this answer\n\nHint: Apply Menelaus' theorem to triangle $ABC$ and transversal $DEF$.\n\nshare|cite|improve this answer\nYes, more \"classical\" theorems that don't get much \"air play\" nowadays... \u2013\u00a0RecklessReckoner Feb 26 '14 at 7:16\n@RecklessReckoner If you are a student training for olympiads, they are important. But once you are out of that phrase of your life, very few people care about Euclidean Geometry anymore. \u2013\u00a0Calvin Lin Feb 26 '14 at 8:05\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-expected-frequencies-of-3-4-5-and-6-eggs.105383/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the expected frequencies of 3,4,5 and 6 eggs\n\n  1. Dec 30, 2005 #1\n    Hello, i found one question really difficult and I cant solve it. Please help.\n\n    Six hens are observed over a period of 20 days and the number of eggs laid each day is summarised in the following table:\n\n    No. of eggs: 3 4 5 6\n    No. of days: 2 2 10 6\n\n    This can be considered as a binomial model, with n=6, for the total number of eggs laid in a day. State the probability that a randomly chosen hen lays an egg on a given day. Calculate the expected frequencies of 3,4,5 and 6 eggs.\n\n    I know the probability required is 5/6. but i dont know how to find the expected frequencies.\n  2. jcsd\n  3. Dec 30, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You said it is a binomial distribution so the frequencies (probabilities) are\n\n    [tex]p_j = \\binom {6}{j} \\left( \\frac {5}{6} \\right)^j \\left( \\frac {1}{6} \\right)^{6-j}[/tex]\n  4. Dec 30, 2005 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Tide, that's assuming the base probability is 5/6 which is one of the things Clari needs to determine.\n\n    Clari, you should know that the expected value for a binomial distribution with base probability p is np. The 6 chickens laid a total of 100 eggs in 20 days or an average of 5 eggs per day. Assuming that the sample does reflect the actual expected value, np= 6p= 5 so p= 5/6.\n\n    Now use Tides's suggestion to answer the rest of the problem.\n  5. Dec 30, 2005 #4\n    Thanks for your help,Tide and HallsofIvy ^-^\n\nHave something to add?\n\nSimilar Discussions: Calculate the expected frequencies of 3,4,5 and 6 eggs"}
{"text": "Retrieved from http://mathoverflow.net/questions/128993/on-solution-of-a-discrete-time-equation\nText:\nTake the 2-minute tour \u00d7\n\nHello, members. I have a problem for the following problem when I derive an optimization algorithm for stochastic singular systems $$S(k+1)=A(k)S(k)A^{T}(k)+R(k)+F(k)S(k+1)F^{T}(k)$$ where $R(k)>=0$ So, how to calculate $S$, is there analytic solution or numerical solution to $S$?\n\nThis problem is different from the following one On solution of a recursion with rectangular matrices\n\nThanks for your help\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nyou'll want to solve this equation iteratively, considering $S(k)$ as known and $S(k+1)$ as unknown; for $F(k)$ invertible you then have a Sylvester equation, of the form $F^{-1}(k)S(k+1)-S(k+1)F^{T}(k)=C(k)$, which has a unique solution iff $F^{-1}(k)$ and $F(k)$ have no common eigenvalue. The Wikipedia page gives algorithms to solve this equation, implemented in several software packages.\n\nshare|improve this answer\nThere are numerical methods dealing directly with the equation $X-FXF^T=C$, known as discrete-time Lyapunov equation, or Stein equation. There is no need to invert $F$ and convert it to a Sylvester; sometimes algorithms even go the other way round and convert a continuous-time Lyapunov equation to a discrete-time one to solve it. \u2013\u00a0 Federico Poloni Apr 28 '13 at 18:37\nThanks for your kind help, Dr. Carlo and Dr. Federico. When $F$ is singular, The Sylvester method may fail to work. So, would you please give me some links or references on the equation $X-FXF^{T}=C$. It seems we can solve it using LMI techniques for obtaining numerical solutions. \u2013\u00a0 eolithr Apr 29 '13 at 1:07\nNo, I made the problem too complex. By using 'dlyap' in Matlab can solve this equation. \u2013\u00a0 eolithr Apr 29 '13 at 3:04\nYep. dlyap will be fine for a small-scale problem; it should use a variant of the same Bartels-Stewart method that is used for continous-time lyapunov eqs; essentially, take a Schur form of $F$ and solve directly via back-substitution for each entry of $X$ \"in the right order\". For large-scale problems, you can truncate the series $X=\\sum_{i=0}^{\\infty} F^{i}CF^{Ti}$, or obtain the partial sum truncated at the term $2^{k}$ directly from the one truncated at $2^{k-1}$ with some manipulations (Smith methods). You can apply some M\u00f6bius transforms to $F$ without changing the solution to make... \u2013\u00a0 Federico Poloni Apr 29 '13 at 7:09\nit more stable, and ultimately obtain a discrete-time version of the ADI method for Lyapunov equations. In short, with some algebraic manipulations everything that works in the continuous-time case rates to work in the discrete-time case as well. \u2013\u00a0 Federico Poloni Apr 29 '13 at 7:10\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/42479/alternative-algebras-in-characteristic-2-especially-scalar-extension/42487\nText:\nTake the 2-minute tour \u00d7\n\nRecently my work has led me to consider octonion algebras. Not having much of a background with non-associative anything, I decided to check out a basic text on the subject, R.D. Schafer's Introduction to Nonassociative Algebras.\n\nI was reading it happily for a good while, until I got to the discussion of alternative algebras. A little background: let $A$ be an arbitrary $F$-algebra: i.e., just endowed with an $F$-bilinear product $A \\times A \\rightarrow A$, no further assumptions. In analogy to the more familiar commutator, it is also useful to define for any $x,y,z \\in A$ the associator\n\n$[x,y,z] = (xy)z - x(yz)$,\n\nthe obvious point being that an algebra is associative iff all of its associators identically vanish. But there is a more subtle merit to this: the associator is an $F$-trilinear map from $A^3$ to $A$. From this it follows that it is entirely determined by its values on any $F$-basis $\\{e_i\\}_{i \\in I}$ of $A$. And from that it follows that associativity can be checked on basis elements and moreover that associativity is faithfully preserved by scalar extension: clearly any trilinear map on an $F$-vector space is identically zero iff its extension to some field extension $K/F$ is identically zero.\n\nOn to alternativity: an $F$-algebra $A$ is said to be alternating if for all $x,y \\in A$,\n\n$[x,x,y] = [x,y,y] = 0$.\n\n(These two identities are easily seen to imply the flexible law $[x,y,x] = 0$.)\n\nNote however that these identities are not multilinear any more: e.g. the left alternator $[x,x,y]$ is quadratic in $x$ and linear in $y$. Thus both of the above consequences of multilinearity are in question: is it sufficient to check left alternativity on basis elements, and is a scalar extension of an alternative algebra necessarily alternative?\n\nPresumably the first question has a negative answer. Compare for instance the quadratic form $q(x,y) = xy$: it vanishes on the two standard basis elements of $F^2$ yet is nondegenerate. What we need to do is linearize, i.e., replace the quadratic form with the associated bilinear form. In the present context, this amounts to replacing the alternating condition with the skew-symmetric condition, i.e.,: for all $x,y,z \\in A$,\n\n$[x,y,z] = -[y,x,z] = [y,z,x]$.\n\nThe skew-symmetry condition looks much better: as a pair of equalities among trilinear maps, again it suffices to check it on basis elements and again it is faithfully preserved by scalar extension.\n\nAs is well-known, alternation implies skew-symmetry and the converse holds when $\\frac{1}{2} \\in F$.\n\nBut what about when $F$ has characteristic $2$?\n\nIn this case, unfortunately (and somewhat embarrassingly) I am not even seeing why if $A$ is an alternating $F$-algebra and $K/F$ is a field extension, then $A_K = A \\otimes_F K$ is an alternating $K$-algebra. Schafer does address this in his book: for $x \\in A$, we have the left and right multiplication operators $L_x, R_x$ as elements of $\\operatorname{End}_K(A)$.\nThen equation (3.1) asserts that left and right alternating laws are equivalent to\n\n$L_{x^2} = (L_x)^2$ and $R_{x^2} = (R_x)^2$.\n\nHe also says that the skew-symmetry of the associator is equivalent to (3.2), which is:\n\n$R_x R_y - R_{xy} = L_{xy} - L_y L_x = L_y R_x - R_x L_y = L_x L_y - L_{yx} = R_y L_x - L_x R_y = R_{yx} - R_y R_x$.\n\n(I have no problem with these identities.)\n\nThen he says (on the top of p. 28) that \"It follows from (3.1) and (3.2) that any scalar extension of an alternative algebra is alternative.\"\n\nUnfortunately I don't follow. Can someone help me out?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nA good samaritan has delivered an answer directly to my email account. It is indeed almost obvious, as long as one ignores the bit about the multiplication operators!\n\nTake for instance the left alternative property: for all $x,y \\in A$, $[x,x,y] = 0$. As I said above, this condition is linear in $y$, so it is enough to check that for each element $e$ of a fixed $F$-basis of $A$, the bilinear form $B_e(x,y) = [x,y,e]$ is alternating. Thus, the left alternation property itself will be preserved by base extension iff the alternating property of a bilinear map is preserved by base extension. I must have had a little mental block about this, but of course it is true: let $\\{e_i\\}$ be an $F$-basis for $A$ hence a $K$-basis for $A_K = A \\otimes_F K$. Then any $x \\in A_K$ may be uniquely written as $x = \\sum_i x_i e_i$ with $x_i \\in K$, and thus\n\n$[x,x] = \\sum_{i=1}^n x_i^2 [e_i,e_i] + \\sum_{i \\neq j} x_i x_j [e_i,e_j]$\n\n$= 0 + \\sum_{i < j} x_i x_j ([e_i,e_j] + [e_j,e_i]) = 0$,\n\nsince alternation implies skew-symmetry always.\n\nshare|improve this answer\nTwo remarks about this argument: (1) This proof doesn't require $F$ and $K$ to be fields. We could just as well have $F$ be any commutative ring and $K$ be any commutative $F$-algebra. The proof would need only a minor modification: The $F$-module $A$ would not necessarily have an $F$-basis anymore; but this doesn't hurt the argument, since all we need is that any $x\\in A_K$ may be written (not necessarily uniquely) in the form $x=\\sum_i x_i e_i$ for some $x_i \\in K$ and some $e_i\\in A$; and this is a trivial consequence of the definition of $A_K$ as the tensor product $A\\otimes_F K$. \u2013\u00a0 darij grinberg Jan 17 '12 at 18:59\n(2) The same argument can be used to prove another fact in algebra, which is very often swept under the rug (it looks as if it would follow from abstract nonsense, functoriality, linearity, etc., but it does not): If $F$ is a commutative ring, $K$ is a commutative $F$-algebra, $A$ is an $F$-module, and $n$ is a nonnegative integer, then $\\wedge^n_K \\left(A\\otimes_F K\\right)$ is canonically isomorphic to $\\left(\\wedge^n_F A\\right)\\otimes_F K$ (where, for every $F$-algebra $T$, the notation $\\wedge^n_T$ means the $n$-th exterior power of a $T$-module). \u2013\u00a0 darij grinberg Jan 17 '12 at 19:02\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/58111/analogue-of-gue-and-ginibre-in-higher-dimensions\nText:\nTake the 2-minute tour \u00d7\n\nThis is a completely unmotivated question, but what happens to the 1-point marginal distribution for the following $N$-point joint distribution: $$\\displaystyle p(z_1,\\ldots, z_N) = C_N \\exp\\left(-\\sum_{j=1}^N \\|z_j\\|^2\\right) \\prod_{j < k} \\|z_j - z_k\\|^2$$ Here $z_j$'s are points in $\\mathbb{R}^3$ or higher. Presumably one can no longer write the Vandermonde as a determinant so orthogonal polynomial theory breaks down. But I am interested in the distribution of $\\|z_1\\|$ as $N$ goes to infinity in this case, which shouldn't need the full machinery of orthogonal polynomials and determinantal point processes (but maybe it is still determinantal?).\n\nshare|improve this question\n\n2 Answers 2\n\nUsing the normalization $\\mathrm{e}^{-\\|z\\|^2/2}$ instead of your $\\mathrm{e}^{-\\|z\\|^2}$ for points $z$ in $\\mathbb{R}^d$, the probability distribution of the one-dimensional marginal $z$ you are interested in is $$ \\kappa_N\\mathrm{e}^{-\\|z\\|^2/2}q_{N}(\\|z\\|^2)\\mathrm{d}z, $$ where $\\kappa_N$ is a positive constant and $q_N$ is a unitary polynomial of degree $N-1$. Small $N$ values of $q_N$ are $$ q_1(x)=1,\\qquad q_2(x)=x+d,\\qquad q_3(x)=x^2+d(d+2). $$\n\nshare|improve this answer\nHi Didier, Could you give a reference to the unitary polynomials you mentioned? I have never encountered them before. Also do you think the point process defined in my question is actually determinantal? Thanks. \u2013\u00a0 John Jiang Apr 7 '11 at 19:31\nHello John. Unfortunately I cannot suggest a reference, I did it myself. Determinantal or not? I do not know. Sorry (twice). \u2013\u00a0 Did Apr 7 '11 at 23:35\n\nBy $\\|z_1\\|$, I understand you mean the maximal modulus of the $z_i$'s.\n\nIf you are interested in the process of the $\\|z_i\\|$'s, you have no chance for a determinantal structure since you may have two different $z_i$'s with same modulus with non zero probability.\n\nConcerning the process of the $z_i$'s, note that even if the Ginibre Ensemble (that is the case $\\mathbb{R}^2$) is indeed determinantal, its kernel is related to the polynomials orthogonal with $\\exp(-\\|x\\|^2/2)$, that is the $(z^k)_{k\\geq 0}$ ... which have trivial zeros ! My point is that except on $\\mathbb{R}$ you won't get so much information concerning $\\|z_1\\|$ from a determinantal structure.\n\nI don't know how prove the convergence of $\\|z_1\\|$, but note that from your density expression, once renormalized $z_i\\rightarrow z_i/\\sqrt{N}$, you still can use the Coulomb-gaz approach to characterize the global distribution of the $z_i$'s (for example by proving a large deviation principle for the empirical measure) : It is given by the unique minimizer $\\mu^*$ of the functional $$ \\iint\\log\\frac{1}{\\| x-y\\|}d\\mu(x)d\\mu(y) +\\frac{1}{2}\\int \\|x\\|^2d\\mu(x) $$ over probability measures $\\mu$ on $\\mathbb{R}^3$ (or higher). I guess that $\\|z_1\\|$ should converge towards $\\max \\big(Supp(\\mu^*)\\cap \\mathbb{R}\\big)$...\n\nshare|improve this answer\nHi Adrien, I guess if you have a closed form for the determinantal structure, then you can compute the marginal distribution directly right? \u2013\u00a0 John Jiang Jan 25 '12 at 21:36\nHi John, I don't see what you mean exactly. Could you elaborate ? \u2013\u00a0 Adrien Hardy Jan 26 '12 at 11:02\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/45759/find-the-limit-lim-limits-n-to-infty-cos-left-pi-sqrtn2-n-right/45760\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'd love your help with finding the following limit: $$\\lim_{n\\to \\infty }\\cos (\\pi\\sqrt{n^{2}-n}).$$\n\nI was asked to find this limit, but honestly I believe that it doesn't exist.\n\nAccording to Heine Theorem of limit of functions, I can choose two sequences:\n\n$x_{k}=2\\pi k$ and $y_{k}=2\\pi k+\\pi$ and notice that when I apply the function on both of them, I'll get -1 and 1, respectively.\n\nAm I right?\n\nThank you again.\n\nshare|cite|improve this question\nDo you mean to have that $\\pi$ in your sequences? There's already multiplication by $\\pi$ inside the cosine. Or did you plan to start with, say, $x_k$, and work backwards to a sequence of $n_k$ such that $\\cos\\pi\\sqrt{n_k^2-n_k} = \\cos{x_k}$? \u2013\u00a0MartianInvader Jun 16 '11 at 17:12\nYes, my mistake. without the $\\pi$'s. thanks. \u2013\u00a0user6163 Jun 17 '11 at 7:05\nYou kinda started the wrong way, by asking what tool to use. Your first question should have been \"what's happening here?\" It is then natural to calculate, for largish but not too large $n$. (Not too large because if you take $n=10^9$, roundoff error kills you.) So look at $n=100, 101, 102$. Calculate. You will get answers near $0$. And while you are taking $\\sqrt{n^2-n}$, you may notice it is almost exactly halfway between consecutive integers. Now an idea for a proof may come. \u2013\u00a0Andr\u00e9 Nicolas Jun 18 '11 at 3:39\nup vote 56 down vote accepted\n\nWe have \\begin{align*} \\cos (\\pi\\sqrt{n^2-n})&= (-1)^n\\cos(\\pi(\\sqrt{n^2-n}-n))\\\\ &= (-1)^n \\cos\\pi\\frac{-n}{\\sqrt{n^2-n}+n}\\\\ &=(-1)^n\\cos \\pi\\frac 1{\\sqrt{1-\\frac 1n }+1}, \\end{align*} hence $|\\cos(\\pi\\sqrt{n^2-n})| = \\left|\\cos \\left(\\pi\\frac 1{\\sqrt{1-\\frac 1n }+1}\\right)\\right|$. Since $\\lim \\limits_{n\\to +\\infty}\\pi\\frac 1{\\sqrt{1-\\frac 1n }+1} =\\frac{\\pi}2$, the $\\cos$ is continuous and $\\cos \\frac{\\pi}2 =0$ we conclude that the limit is $0$.\n\nshare|cite|improve this answer\nIt is intresting that when you go by intuition and write the limit as $\\cos \\pi n\\sqrt{1-\\frac{1}{n}}$ you sincerely might think that the limit does not exist. \u2013\u00a0user6163 Jun 18 '11 at 10:14\n@Nir Yes, I agree. The idea comes from an exercise that I've done some years ago. I had to look at the convergence of the series $\\sum_{n\\geq 0}\\sin(\\pi\\sqrt{n^2+1})$. \u2013\u00a0Davide Giraudo Jun 18 '11 at 10:25\nAre you sure of this answer?*sqrt+%28n^2-n%29%29 \u2013\u00a0user6163 Jun 18 '11 at 10:37\n@Nir: it is very important that $n$ here is integer. \u2013\u00a0Marek Jun 18 '11 at 12:18\n\nSince a nice formal argument has been supplied by Davide Giraudo, I will allow myself the luxury of informality.\n\nLet $n$ be a large positive integer. Complete the square. We have $$n^2-n=\\left(n-\\frac{1}{2}\\right)^2 -\\frac{1}{4}$$\n\nTake the square root. When $n$ is very large, the term $-1/4$ makes a vanishingly small contribution to the square root.\n\nSo our square root is nearly equal to $n-1/2$. And the cosine of $\\pi n -\\pi/2$ is $0$.\n\nshare|cite|improve this answer\n\nConsidering the form $\\cos(\\pi n \\sqrt{1-\\frac{1}{n}})$ and using Taylor's expansion for $\\sqrt{1-\\frac{1}{x}}$ $\\to$ see here, we get that when n is large $\\cos (\\pi\\sqrt{n^{2}-n}) \\approx \\cos( \\pi n -\\frac{\\pi}{2})$. Therefore, $L=0$.\n\n\nshare|cite|improve this answer\nNice answer Chris's sis........ \u2013\u00a0juantheron Nov 3 '13 at 13:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/609700/in-how-many-ways-can-we-select-n-objects-from-a-collection-of-size-2n-that-consi\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn how many ways can we select $n$ objects from a collection of size $2n$ that consists of $n$ distinct and $n$ identical objects?\n\nThe answer is $2^n$ and I really don't see how they get this. Selecting $n$ distinct from $2n$ is $\\binom{2n}{n}$.\n\nshare|cite|improve this question\nTry working a small example: one white sock, one red sock, two black socks. Hint: sort the 12 possibilities in order by number of black socks. \u2013\u00a0Eric Lippert Dec 17 '13 at 0:31\n\nLet $A=\\{a_1,\\ldots,a_n\\}$, where the $a_k$ are mutually distinguishable, and let $S$ be $A$ together with $n$ indistinguishable objects. An $n$-element subset $X$ of $S$ is completely determined when you know $X\\cap A$: if $|X\\cap A|=k$, the remainder of $X$ is just $n-k$ of the indistinguishable objects. $A$ has $2^n$ subsets, so there are exactly $2^n$ different possibilities for $X\\cap A$ and therefore for distinguishable sets $X\\subseteq S$ of cardinality $n$.\n\nshare|cite|improve this answer\n\nHint. If you choose $k$ elements from the $n$ distinct, and $n-k$ from the $n$ identical, there are:\n\n$$\\binom{n}{k}\\cdot 1$$\n\nways to do this. Now sum from $k=0$ to $k=n$.\n\nshare|cite|improve this answer\n\nNote that the set of objects chosen is determined by which of the distinct objects are chosen and how many of the identical objects are chosen. For each of the $2^n$ subsets of the $n$ distinct objects, the number of identical objects we need to take in order to fill our quota of $n$ total objects is uniquely determined. Hence there are $2^n$ total ways to take $n$ total objects from $n$ distinct and $n$ identical objects.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-can-one-find-the-area-between-the-curves.90727/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHow can one find the area between the curves\n\n  1. Sep 25, 2005 #1\n    when three curves intersect,i mean like the intersection of three straight lines to give a triangle,how can one find the area between the curves\n  2. jcsd\n  3. Sep 25, 2005 #2\n    area of a triangle is given by 1/2 * b * h\n  4. Sep 25, 2005 #3\n    I think mathelord means any three curves. You can use a double integral. Do you know calculus?\n  5. Sep 25, 2005 #4\n    If you don't know calculus you calculate the height. The factor of two perpendicular slopes is -1.\n  6. Sep 26, 2005 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The man said curves! Assuming he is asking about the area of the region formed by three general curves, he will need to use caluculus.\n\n    Exactly how that is done depends on the curves themselves. In the very common situation, a sort of \"curvy\" triangle, where you have one curve under the other two (between the points where the other two intersect it), then you don't need a double integral. You will need to break the integral into two parts. I'm going to call the curve on the bottom C1, the graph of y= f1(x), and the other two C1 and C2, graphs of y=f2(x), y= f3(x) respectively. Let's say that C2 intersect C1 at x=a, C3 intersects C1 at x= c, and that C2 is below C3 until they intersect at x= b after which C3 is below C2.\n\n    Then the area is given by two separate integrals:\n    [tex]\\int_a^b(f2(x)-f1(x))dx+ \\int_b^c(f3(x)-f1(x)dx[/tex]\n\nHave something to add?\n\nSimilar Discussions: How can one find the area between the curves\n  1. How do i find the area (Replies: 1)\n\n  2. How can one prove (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limit-of-a-long-trig-function.268716/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLimit of a long trig function.\n\n  1. Nov 2, 2008 #1\n    x->0 ((sin5x)/(sin2x) - (sin3x)/(4x))\n\n    2. Relevant equations\n    i guess sinx/x as x approaches zero is 1.\n\n    3. The attempt at a solution\n    lets be honest, this is a simple question. i am getting a final answer of 4, but it is wrong apperently according to the book's solution. i want to see if anyone else got this answer\n\n    I separated the limit into two limits, divided by 5x's and 2x's on the left limit and divided by 3x's on the right limit. this shouldnt be a problem (and yes i divided top and bottom by the same amounts so they would cancel out; thats not my mistake). please someone help\n  2. jcsd\n  3. Nov 2, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    You've obviously made an algebra error somewhere, If you show your work, we can tell you where your error is.\n  4. Nov 2, 2008 #3\n\n\n    Staff: Mentor\n\n    Are you sure you have given us the problem as it appears in your book or assignment? Could it be lim sin(5x)/(2x) - sin(3x)/(4x)? If so, that's a much simpler problem, whose limit is 1.75, as x approaches 0.\n  5. Nov 2, 2008 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    [tex]\\frac{sin(3x)}{4x}= \\frac{3}{4}\\frac{sin(3x)}{3x}[/tex]\n\n    [tex]\\frac{sin(5x)}{sin(2x)}= \\frac{5}{2}\\frac{sin(5x)}{5x}\\frac{sin(2x)}{2x}[/tex]\n  6. Nov 2, 2008 #5\n    HOW IS IT 1.75!!!!!!!!!!!!!!!!!!!! wheres the flaw in my logic.\n\n    (sin5x)/sin2x = [((sin5x)/(5x*2x)]/[(sin2x)/(5x*2x)]\n    = (5/2x)/(2/5x))\n    = 25/4\n\n    (sin3x)/4x = [(sin3x/3x)]/[(4x/3x)]\n    = 3/(4x/3x)\n    = 3/(4/3)\n    = 9/4\n\n    25/4 - 9/4 = 16/4 = 4 where is my flaw!!!???\n  7. Nov 2, 2008 #6\n\n\n    Staff: Mentor\n\n    Halls, are you missing a division symbol in your second equation?\n  8. Nov 2, 2008 #7\n\n\n    Staff: Mentor\n\n    How did you get (5/2x)/(2/5x)) from the expression above it? lim (as x [tex]\\rightarrow[/tex] 0) of sin(5x) / (5x) is 1, not 5, if that's what you did.\n\n    The expression on the right side of your first line is equal to\n    [tex]\\frac{sin(5x)}{5x} * \\frac{5x}{2x} * \\frac{2x}{sin(2x)}[/tex]\n    As x [tex]\\rightarrow[/tex] 0, this expression approaches 1 * 5/2 * 1 = 5/2. Similarly sin(3x)/(4x) approaches 3/4, so the difference approaches 7/4 = 1.75.\n\n    Regarding my earlier question about whether the denominator of the first fraction should have been 2x rather than sin(2x), it doesn't matter. For x close to 0, sin(x) [tex]\\approx[/tex] x, and sin(2x) [tex]\\approx[/tex] 2x.\n\n\nHave something to add?\n\nSimilar Discussions: Limit of a long trig function.\n  1. Limit of trig function (Replies: 23)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/148444/how-to-solve-the-limit-of-a-succession-on-this-particular-circumstances\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nGiven this limit $\\displaystyle\\lim_{n \\to{+}\\infty}{\\frac{\\sqrt{16n^2+3}}{(1+a_n)n+5cos n}=\\frac{7}{6}}$ I need to calculate this one : $\\displaystyle\\lim_{n \\to{+}\\infty}{a_n}$\n\nAny ideas of how to solve it. Thanks!!!\n\nshare|cite|improve this question\nHint: Divide top and bottom by $n$, let $n$ get big. Top approaches $4$. Term $(5\\cos n)/n$ at the bottom dies. So for large $n$, $4/[(1+a_n)]$ is very close to $7/6$, and therefore $\\dots$ \u2013\u00a0Andr\u00e9 Nicolas May 22 '12 at 22:40\nup vote 1 down vote accepted\n\nHint: write $$ {\\sqrt{16n^2+3}\\over (1+a_n) n +5\\cos n} = {n\\cdot\\sqrt{16+{3\\over n^2} }\\over n\\cdot\\bigl( (1+a_n)+{5\\cos n\\over n}\\bigr)} = {\\sqrt{16+{3\\over n^2} }\\over (1+a_n)+{5\\cos n\\over n}}. $$ Then note $$ \\lim_{n\\rightarrow\\infty} {\\sqrt{16+{3\\over n^2} }\\over (1+a_n)+{5\\cos n\\over n}} ={4\\over 1+\\lim\\limits_{n\\rightarrow\\infty}a_n}. $$\n\nshare|cite|improve this answer\nPerfect. Thank you so much. I have a test tomorrow, and this exercise was killing me! \u2013\u00a0limoragni May 22 '12 at 23:12\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/27479/calculating-correlation-functions-of-exponentials-of-fields\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn their book Condensed Matter Field Theory, Altland and Simons often use the following formula for calculating thermal expectation values of exponentials of a real field $\\theta$:\n\n$$ \\langle e^{i(\\theta(x,\\tau)-\\theta(0,0))} \\rangle = e^{-\\frac12 \\langle (\\theta(x,\\tau)-\\theta(0,0))^2 \\rangle} $$\n\nAn example can be found in chapter 4.5, problem \"Boson-fermion duality\", part c). (This refers to the second edition of the book, page 185.)\n\nIn other words, expectation values of exponentials can be cast as exponentials of expectation values under certain conditions. Unfortunately, I seem to be unable to find an explanation of why this can be done and what the conditions on the Lagrangian of $\\theta$ are.\n\nHence, my question is:\n\nHow to derive the above formula? What do we need to know about $\\theta$ for it to be valid in the first place?\n\nIdeally, I am looking for a derivation using the path integral formalism. (I managed to rederive a very special case in terms of operators and the Baker-Campbell-Hausdorff formula, but I'd like to gain a more thorough understanding.)\n\nshare|cite|improve this question\nup vote 17 down vote accepted\n\nThis is just a property of Gaussian averaging analogous to the finite dimensional case:\n\n$\\langle e^{ix} \\rangle=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty} e^{ix}e^{-\\frac{x^2}{2\\sigma^2}}=e^{-\\frac{\\sigma^2}{2}}= e^{-\\frac{\\langle x^2 \\rangle}{2}}$\n\nThe field can be decomposed into its independent Gaussian modes and integrated for each mode separately.\n\nshare|cite|improve this answer\nThe simplest answers are simply the best. \u2013\u00a0Greg Graviton Oct 7 '11 at 7:50\nSo this formula only holds in the noninteracting case. \u2013\u00a0Arnold Neumaier May 2 '12 at 18:48\n\nDavid Bar Moshe's derivation is of course right. Let me offer you a Taylor-expansion-based alternative proof: $$ \\left\\langle e^{ix} \\right \\rangle = \\left\\langle \\sum_{n=1}^\\infty \\frac{(ix)^n}{n!} \\right \\rangle = \\left\\langle \\sum_{k=1}^\\infty \\frac{(ix)^{2k}}{(2k)!} \\right \\rangle $$ Here, I just used that by some odd-ness, the odd powers have a vanishing expectation value. In the formula above, $x$ is whatever linear function of the elementary fields you want, including your coefficient. But the expectation value of $x^{2k}$ is $$ \\left\\langle x^{2k} \\right \\rangle = \\frac{ \\int_{-\\infty}^\\infty {\\rm d}x \\,x^{2k}\\exp(-x^2/2x_0^2)}{ \\int_{-\\infty}^\\infty {\\rm d}x \\,\\exp(-x^2/2x_0^2)} = 1\\times 3\\times \\cdots \\times (2k-1) \\times x_0^{2k} $$ which may be computed by integrating by parts or by converting it to the Euler integral (which is also evaluated by parts) so when you combine it with the $1/(2k)!$ factor, the odd integers cancel, only the product of the even integers which is equal to $2^k k!$ is left, and the original sum from the first line is $$\\sum_{k=1}^\\infty \\frac{(-x_0^2)^k}{2^k k!} = \\exp(-x_0^2/2) $$ where $x_0^2$ is the expectation value of $\\langle x^2\\rangle$ because I used it in the probabilistic distribution. Again, you may set $x=\\theta(x_1,t_1)-\\theta(x_2,t_2)$ or whatever linear function of variables and my derivation still holds.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/133065/a-curious-binomial-coefficient-sum\nText:\nTell me more \u00d7\n\nLet $k, l \\leq n$ be non-negative integers. Does the following identity simplify? \\begin{align} \\sum_{j = 0}^{k} \\binom{k}{j} \\binom{j + n -l + 1}{n} = \\binom{n - l + 1}{n} \\phantom1_{2}\\mathsf{F}_{1}(-k,n - l + 2, 2- l; -1) \\end{align} where $\\!\\!\\! \\phantom1_{2}\\mathsf{F}_{1}$ is a hypergeometric function. That is, does the right side have another representation in terms of simple functions given that $k,l$ and $n$ are non-negative integers?\n\nshare|improve this question\n$\\binom{n-l+1}{n}=0$ if $l > 1$ I guess \u2013\u00a0 GEdgar Apr 17 '12 at 19:27\nSuperficially it appears that the right side vanishes, but you must also consider the hypergeometric function. The sum is equal to $2^{k-1} k$ if $l = 2$ and $n = 1$. \u2013\u00a0 user02138 Apr 17 '12 at 19:46\nWhat do you consider to be a \"simple function\"? The theory behind Gosper's algorithm will tell you that if the sum exists as a hypergeometric then it's a rational polynomial times the summand. \u2013\u00a0 Peter Taylor Apr 17 '12 at 20:44\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://pari.math.u-bordeaux.fr/archives/pari-users-0903/msg00004.html\nText:\nKurt Foster on Sat, 14 Mar 2009 17:10:41 +0100\n\n\nAvoiding a znlog() computation\n\nSuppose that a and b are given, and for some prime p you know that\n\nn1 = znorder(Mod(a,p),p-1)\n\n\nMod(b,p)^n1 == Mod(1,p).\n\nThen the multiplicative order n2 of b (mod p) is automatically a divisor of n1, so we can compute it using n2 = znorder(Mod(b.p),n1).\n\nThen alpha = Mod(a,p)^(n1/n2) has multiplicative order n2, so\n\nMod(b,p) = alpha^k\n\nfor a unique k in (0, n2) with gcd(k, n2) ==1.\n\nThe problem is, how to determine k.  One way is to let\n\ng = znprimroot(p); l1 = znlog(alpha,g);l2 =znlog(b,p);k=lift(Mod(l2/ l1,n2))\n\nbut this entails finding a primitive root and TWO znlog()s. Given that Mod(k,n2) is already known to be well defined, is there a more direct/faster way to compute it?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/193542/behavior-of-sum-n-1-infty-n-1zn-on-the-circle-of-convergence\nText:\nSign up \u00d7\n\nConsider the following complex power series :$$\\sum_{n=1}^\\infty\\frac{z^n}{n}$$ The radius of convergence of this series is $1$ and the series is divergent for $z=1$. I want to know what are the values of $z\\in C:=\\lbrace z\\in\\mathbb{C}: |z|=1\\rbrace$, the circle of convergence, for which the given series converges.\n\nshare|cite|improve this question\nTo find any value you may rewrite it as $\\ -\\ln(1-z)\\ $ (for $z\\not =1$) \u2013\u00a0 Raymond Manzoni Sep 10 '12 at 11:41\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nHINT: Look at Dirichlet test. In your case, choose $a_n = \\dfrac1n$ and $b_n = z^n$.\n\nFrom the Dirichlet test, you will get that the series converges everywhere on the boundary of the unit disc except at $z=1$.\n\nshare|cite|improve this answer\nAlthough it ultimately amounts to the same, I'd suggest to consider $(1-z)f(z)$ where $f(z)$ is the given series. \u2013\u00a0 t.b. Sep 10 '12 at 10:20\n\nHint: This is a classical example for Abel's Test.\n\nshare|cite|improve this answer\nAccording to this statement of Abel's Test, it doesn't apply, since $\\sum\\limits_{n=1}^\\infty z^n$ doesn't converge. Would you explain what you mean by Abel's Test? \u2013\u00a0 robjohn Sep 14 '12 at 6:03\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/24609/are-there-primes-p-q-such-that-p41-2q2?answertab=active\nText:\nSign up \u00d7\n\n$\\exists p, q \\in \\mathbb{P}: p^4+1 = 2q^2$? I suspect there is some simple proof that no such p, q can exist, but I haven't been able to find one.\n\nSolving the Pell equation gives candidates for p^2=x and q=y, with x=y=1 as the first candidate solution and subsequent ones given by x'=3x+4y, y'=2x+3y; chances of a prime square seem vanishingly unlikely as x increases, but I don't have a proof.\n\nMeta: how do you search for a question like this? I looked for a searching HOWTO here and on meta, and couldn't find one. That the search appears to strip '^' and '=' makes it all the harder.\n\nshare|cite|improve this question\nIf you're looking for a simple proof, you probably have to a) factor the left hand side over Z[i]; b) subtract 1 and factor the right hand side over Z[sqrt{2}], or c) multiply by 2 and use the classification of Pythagorean triples (or subtract a square and factor the right hand side, which is a difference of squares). \u2013\u00a0 Franz Lemmermeyer May 14 '10 at 12:31\nYes, $\\mathbb{P}$ is the primes. That is standard isn't it? \u2013\u00a0 Hugo van der Sanden May 14 '10 at 12:32\n@Franz: This is a variation of Pell's equation, so $p^2+q\\sqrt2=(1+\\sqrt2)^{2k+1}$ (it can be shown by modular argument that $k$ is multiple of 4). Thus (a) can't work, (b) is used in derivation of the above formula (there are useless recursions mentioned by the author), and for (c) I have no idea of what do you mean (how to relate the equation with Pythagorean triples?) \u2013\u00a0 Wadim Zudilin May 14 '10 at 13:45\nInterestingly enough, the similar equation p^2 + 1 = 2q^4 DOES have an interesting solution, namely (p,q) = (239,13). This is related to Machin's identity pi/4 = 4 arctan(1/5) - arctan(1/239). (See Ribenboim's book on Catalan Conjecture for this.) See p.7-8 of for an \"explanation\" of this solution via a congruence mod 5 between a weight-2 cuspform in conductor 1024 and an Eisenstein series. \u2013\u00a0 JSE May 14 '10 at 20:45\n@Wadim: I can't see why a) cannot work. As for c), 2p^4 + 2 = (p^2+1)^2 + (p^2-1)^2 = (2q)^2. \u2013\u00a0 Franz Lemmermeyer May 16 '10 at 16:10\n\n3 Answers 3\n\nup vote 20 down vote accepted\n\nThis is not my solution, but I don't remember where I learned it.\n\nSquare both sides, subtract $4p^4$, and divide by 4 to obtain $({p^4-1\\over 2})^2=q^4-p^4$.\n\nHowever, $z^2=x^4-y^4$ has no solutions in non-zero integers. This is Exercise 1.6 in Edwards's book on Fermat's Last Theorem. The proof uses the representation of Pythagorean triples and infinite descent.\n\nSo you must have $p=\\pm 1$.\n\nshare|cite|improve this answer\nThanks, this does solve it. I also found the infinite descent proof of the lemma at\u2026 \u2013\u00a0 Hugo van der Sanden May 14 '10 at 15:42\n\nI think -- correct me if I am wrong -- that it is known that the equation $x^4+1=Dy^2$ with given squarefree $D$ has at most one solution in integers, primes or no primes. See for example J. H. E. Cohn., Math. Comp. 66 (1997), 1347-1351. ( The article cites an original proof by Ljunggren in 1942, which I can't find online.\n\nshare|cite|improve this answer\nAh, excellent. That suggests x=y=1 is the only solution; I'll take a look at the paper to see if it constitues a proof. \u2013\u00a0 Hugo van der Sanden May 14 '10 at 14:07\nOh, it is the Ljunggren paper I'd need. \u2013\u00a0 Hugo van der Sanden May 14 '10 at 15:40\n\nI don't know if there is a simple proof, but I know one which is easy to do because it lets a computer do all the work (but the work is perhaps complicated): you simply ask a computer to solve Y^2=2X^4+2 in integers for you, like this (in MAGMA, but other packages will do it too):\n\n> IntegralQuarticPoints([2,0,0,0,2]);\n    [ 1, 2 ],\n    [ -1, 2 ]\n\nso the only solution with p,q integers is p,q=+-1 and that's it.\n\nshare|cite|improve this answer\nHow can Magma be used with confidence, their code is not open. \u2013\u00a0 teil May 14 '10 at 13:39\nNegative's point is a valid one, but I think Kevin's answer points to the fact that there is a standard algorithm to solve these kinds of problems. Maybe it is also implemented in other packages. \u2013\u00a0 Felipe Voloch May 14 '10 at 14:59\nThis is only semi-true. The outer code of SIntegralPoints in Magma can be viewed easily. As Felipe Voloch says in part, this lists the algorithm. Low-level functions (eg. Height) cannot be seen, though \"open\" is technically true as you can decompile. From the philosophy of science, no system is used with confidence, and only independent verification can be partially satisfactory. We still have at least two chip manufacturers, so hardware independence is possible. For using software, too many packages throw eggs into a large basket (like GMP), and so I see a scarcity of true independence often. \u2013\u00a0 Junkie May 15 '10 at 6:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/46590/whats-the-minimum-of-int-01-fx2-dx-subject-to-int-01-fx-dx/46603\nText:\nSign up \u00d7\n\nThe question is as in the title: what's the minimum of $\\int_0^1 f(x)^2 \\: dx$, subject to $\\int_0^1 f(x) \\: dx = 0, \\int_0^1 x f(x) \\: dx = 1$? (Assume suitable smoothness conditions.)\n\nA problem in the textbook for the course I am TEACHING (not taking) reduces to minimizing $w_1^2 + w_2^2 + w_3^2$ subject to $w_1 + w_2 + w_3 = 0, w_1 + 2w_2 + 3w_3 = 1$. Of course there's nothing special about the number $3$ here, and so one can ask for the minimum of $\\sum_{i=1}^n w_i^2$ subject to $\\sum_{i=1}^n w_i = 0, \\sum_{i=1}^n iw_i = 1$. At least when $n = 3, 4, 5$, we get $w_i = c_n(i-(n+1)/2)$, for some constant $c_n$ which depends on $n$. So for fixed $n$, $w_i$ is a linear function of $i$. (This is a bit of an annoying computation, so I won't reproduce it here.)\n\nSo it seems like there should be a continuous analogue of this. If we have $$ \\int_0^1 f(x) \\: dx = 0, \\int_0^1 x f(x) \\: dx = 1 $$ and $f(x)$ is linear, then we get $f(x) = 12(x-1/2)$, and $\\int_0^1 f(x)^2 \\: dx = 12$. Is this the function satisfying these integral conditions with smallest $\\int_0^1 f(x)^2 \\: dx$? That is, is it the case that $$ \\int_0^1 f(x)^2 \\: dx \\ge 12 $$ for every $f(x)$ satisfying the two conditions above and whatever smoothness conditions are necessary?\n\nI've tagged this calculus-of-variations because that's what it looks like to me. But I don't know the calculus of variations, which is why I can't just solve the problem myself.\n\nshare|cite|improve this question\nIn my answer here I proved that if $f \\in C^1$, $\\int_{0}^{1} f = 0$ and $m \\leq f' \\leq M$ then $$\\frac{m}{12} \\leq \\int_{0}^{1} x f(x) \\leq \\frac{M}{12}.$$ I'm not sure if that helps immediately but it seems related and I'd try a few integrations by parts. It's getting late here, so I'm not sure that I could succeed now. \u2013\u00a0 t.b. Jun 20 '11 at 23:33\nWell, there is the same mysterious constant of 12. I may give it a shot. \u2013\u00a0 Michael Lugo Jun 20 '11 at 23:36\n\n3 Answers 3\n\nup vote 24 down vote accepted\n\nThe integrals above can be interpreted using the $L^2$ inner product $$ \\langle f,g\\rangle \\;=\\; \\int_0^1 f(x)\\,g(x)\\,dx. $$ Specifically, we are given that $\\langle 1,f\\rangle = 0$ and $\\langle x,f\\rangle =1 $, and we are asked to find the minimum possible value of $\\langle f,f\\rangle$.\n\nSince components of $f$ orthogonal to both $1$ and $x$ will only increase the norm of $f$, the minimizing function must lie in the subspace spanned by $1$ and $x$. A simple calculation shows that the minimum is obtained when $f(x) = 12x - 6$, in which case $\\langle f,f\\rangle = 12$.\n\nshare|cite|improve this answer\nIndeed, there are nice exercises at the end of chapter 4 of Walter Rudin's Real and Complex Analysis that provide practice with this technique. \u2013\u00a0 Amitesh Datta Jun 21 '11 at 0:24\n\nYes, it is true.\n\nConsider the Hilbert space $L^2([0,1])$ of square integrable functions $f\\colon[0,1]\\to\\mathbb{R}$ with inner product $\\langle f,g\\rangle = \\int_0^1 f(x)g(x)\\,dx$. Letting $V$ be two dimensional subspace generated by $u(x)=1$ and $v(x)=x$, then the function $g(x)=12(x-1/2)$ is in $V$ and satisfies $\\langle g,u\\rangle=0$ and $\\langle g,v\\rangle=1$. So, your question is equivalent to choosing $f$ to minimize $\\langle f,f\\rangle$ subject to $\\langle f,h\\rangle=\\langle g,h\\rangle$ for all $h\\in V$. This condition is just saying that $g$ is the orthogonal projection of $f$ onto $V$.\n\nSo, any $f\\in L^2$ satisfying the condition can be written as $$ f = g + h $$ where $h$ is in the orthogonal complement of $V$ and, therefore, $$ \\langle f,f\\rangle = \\langle g,g\\rangle+\\langle h,h\\rangle\\ge \\langle g,g\\rangle=12 $$ with equality if and only if $f=g$ almost everywhere.\n\nshare|cite|improve this answer\nThis solution is so beautiful and simple that it's almost disappointing. \u2013\u00a0 t.b. Jun 21 '11 at 0:23\nNote that you could alternatively try varying $f$ by an (infinitesimal) amount $\\delta f$, giving $0=\\delta\\int_0^1f^2\\,dx=\\int_0^1f\\delta f\\,dx$ for the optimal $f$. In order that the conditions remain satisfied, you must choose $\\int u\\delta f\\,dx=0$ for $u=1$ and $u=x$. This means that $f$ is orthogonal to any $\\delta f$ orthogonal to both $1$ and $x$. As the orthogonal complement of the orthogonal complement of a closed subspace gets you back to the original space, this means that $f$ is in the linear span of $1,x$. Making this a bit cleaner and more rigorous gives the argument above. \u2013\u00a0 George Lowther Jun 21 '11 at 0:28\n\nSeeing the very nice solutions using linear algebra that have been posted, I am again reminded that the calculus of variations is a bigger and less elegant hammer than is necessary for most nails. For what it's worth, here is how you could solve this problem with the calculus of variations. Jos\u00e9 Figueroa-O'Farrill has some nice notes which cover this:\n\nAs we have two constraints, we introduce two Lagrange multipliers $\\lambda$ and $\\mu$, and attempt to extremize the functional $$S[f] = \\int_0^1 \\big( f(x)^2 + \\lambda f(x) + \\mu x f(x) \\big) dx.$$ Let us denote the integrand by $$L\\big(x,f(x),f'(x)\\big) = f(x)^2 + \\lambda f(x) + \\mu x f(x).$$\n\nThe function $f$ which is a stationary point of the functional $S[f]$ satisfies the corresponding Euler-Lagrange equation, $$\\frac{\\partial L}{\\partial f} = \\frac{d}{dx} \\frac{\\partial L}{\\partial f'}$$ which in this case reduces to $$2f(x) + \\lambda + \\mu x = 0.$$ So we see that the extremal $f(x)$ is indeed linear, and the values of $\\lambda$ and $\\mu$ can be obtained from the constraints $\\int_0^1 f(x) dx = 0$ and $\\int_0^1 xf(x) dx = 1$.\n\nshare|cite|improve this answer\nOut of curiosity what was your air in jee? i might be your junior... \u2013\u00a0 kuch nahi Jun 21 '11 at 5:05\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/157866/derivative-for-matrix-function?answertab=active\nText:\nSign up \u00d7\n\nI have a matrix kernel function which I am trying to find the derivative to. Function is K = c * exp[-1/2 * (P(X1 - X2))' * P(X1 -X2)] where uppercase are matrices and lower case are scalars (and ' denotes transpose). I'm trying to find dK/dP. I'm pretty rusty on matrix calculus, can anyone give me a hand here?\n\n\nshare|cite|improve this question\nYour notation is not very clear. Is $P$ a matrix? then did you mean something like $K(P) = c \\exp[-\\frac12 \\| P(X_1 - X_2) \\|^2]$? In that case you should probably write (P(X1-X2))', the transpose should be around everything and maybe a trace before it? Is P symmetric or not? \u2013\u00a0 passerby51 Jun 13 '12 at 17:43\nI was assuming this is a matrix valued function. If that's true I'd undelete my (by now corrected) answer. If @passerby51 assumption is correct, the derivative is just $$ D_V K = -1/2K \\langle V(X_1-X_2), P(X_1-X_2)\\rangle$$ with $\\langle.,.\\rangle$ the scalar product on the vector space of matrices. \u2013\u00a0 user20266 Jun 13 '12 at 17:50\nSorry yeah the transpose is around the whole thing. P is not symmetric. \u2013\u00a0 tomas Jun 13 '12 at 17:50\nYeah it is a matrix valued function. I didn't quite get a chance to see your deleted answer Thomas. What was it? Thanks for the response guys. \u2013\u00a0 tomas Jun 13 '12 at 17:53\nundeleted my reply. \u2013\u00a0 user20266 Jun 13 '12 at 17:53\n\n1 Answer 1\n\nLet $$Z(P)=(P(X_1-X_2))^TP(X_1-X_2)$$ If $K$ is viewed as depending only on $P$ and if you differentiate in direction $V$ you get $$ D_V K = K*\\frac{-1}{2} \\left\\{\\frac{I-e^{-ad_{Z(P)}}}{ad_{Z(p)}} \\left[ (V(X_1-X_2))^TP(X_1-X_2) + P(X_1-X_2)^TV(X_1-X_2) \\right] \\right\\}$$\n\nThe term on the right hand side in curly parenthesis needs explanation. It is the matrix valued function $\\frac{I-e^{-ad_{Z(P)}}}{ad_{Z(P))}}$ applied to the term in square brackets. This in turn means\n\n$$\\frac{I-e^{-ad_{Z}}}{ad_{Z}}[Y] = Y-\\frac{[Z,Y]}{2!} + \\frac{[Z,[Z,Y]]}{3!} - \\ldots$$\n\nSee, e.g., Chapter 3.3 in Brian C. Halls Book 'Lie Groups, Lie Algebras and Representations for a derivation of the derivative of the exponential.\n\n(Sorry for posting a too simple and wrong answer first, which is true only if $Z$ and $D_VZ $ commute). (I don't like the $\\frac{d}{dP}$ notation).\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/99948/is-there-a-polynomial-upper-bound-for-number-of-holes-over-following-class-of-gr\nText:\nSign up \u00d7\n\nA hole is chordless cycle that length of the cycle is four or more.\n\nIn this post I asked: What is the maximum number of holes that a simple graph on n vertices can have?\n\nGil Kalai answered that there is no polynomial upper bound.\n\nI need a polynomial upper bound for number of holes over following class of graphs: Graphs constructed from triangles such that no two triangles have more than one vertex in common. this graphs are not necessarily chordal, and may have holes.\n\nMay I hope for a polynomial upper bound for number of holes of such graphs?\n\nshare|cite|improve this question\nNo. Subdivide each edge. This leaves a triangle-free graph with Poly($n$) vertices, and at least as many holes. \u2013\u00a0 Andrew D. King Jun 18 '12 at 22:08\nDear Andrew, we are not allowed subdivide edges. with triangles I mean $K_3$s. \u2013\u00a0 b.a Jun 18 '12 at 22:18\nIf your graph be planar, your answer is easy by Euler formula. So you can think about the number of induced planar subgraphs of a graph. But, I didn't see any discussion about this Idea. \u2013\u00a0 Shahrooz Janbaz Jun 19 '12 at 10:08\nDear Shahrooz, I don't want number of faces. I want number of holes. After all, mentioned class of graphs contains some non-planar graphs. \u2013\u00a0 b.a Jun 19 '12 at 15:23\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nGil Kalai's example has no triangles - the smallest cycle has length 4. So glue a triangle to each edge of his graph. (Add a vertex, and connect it to both vertices of the edge). This graph is then constructed of triangles, but no two triangles share an edge. (and it's simple, so no two triangles share two points) None of the holes have gained chords.\n\nThus, it is still a counterexample.\n\nshare|cite|improve this answer\nA Genius Answer. thanks. \u2013\u00a0 b.a Jun 18 '12 at 22:36\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/45061/linear-ordering-of-color-balls\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $n+m$ balls of which $n$ are red and $m$ are blue, are arranged in a linear order, we know there are $(n+m)!$ possible orderings. If all red balls are alike and all blue ball are alike, we know there are $\\frac{(n+m)!}{n!m!}$ possible orderings.\n\nFor example, 2 red and 3 blue balls:\n\nR1 R2 B1 B2 B3\n\nR2 R1 B2 B3 B1\n\nThe above two orderings are equivalent and can be denoted as:\n\n\nNow here is the problem: what if we further concentrate on the color, and record consecutive balls of the same color with the just ONE color code?\n\nFor example the color code for the afore-mentioned example would be:\n\n\nHow many possible color code orderings are there?\n\nshare|improve this question\nShould be tagged co.combinatorics instead of pr.probability? \u2013\u00a0 Emil Nov 6 '10 at 12:27\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nSuch a color-code ordering starts with either R or B and continues with strictly alternating R and B. The string can be of any length up to the smaller of $n$ or $m$, meaning it can be twice that smaller value, but that can be followed by one more character if there are enough of the other color. Moreover, every such string is a color-code ordering for some linear ordering of balls. There are a couple of special cases, namely that if either $n$ or $m$ is zero then there is exactly one color-code ordering and there aren't any if both are zero. Also, if neither is zero, we must have at least one instance of each letter.\n\n\nIf $n = m = 0$, the answer is 0.\n\nIf exactly one of $n$ and $m$ is zero, the answer is 1.\n\nIf $n = m > 0$, the answer is $4n - 2$.\n\nOtherwise, let $p$ be the minimum of $n$ and $m$. The answer is $4p-1$.\n\nshare|improve this answer\nadd comment\n\nWithout loss of generality, assume $n \\leq m$. Such a colour code ordering is just a sequence of alternating $R$ and $B$ letters. There are four types of such sequences, depending which letter they start and end with. Say a sequence is of type $(X,Y)$ if it begins with $X$ and ends with $Y$.\n\nSo, there are\n\n  1. $n$ sequences of type $(R,B)$\n  2. $n$ sequences of type $(B,R)$\n  3. $n-1$ sequences of type $(R,R)$\n  4. $n$ sequences of type $(B,B)$ (and only $n-1$ of them if $n=m$).\n\nThus, the answer is $4n-1$ if $n < m$, and $4n-2$ if $n=m$.\n\nEdit. As Larry Denenberg mentions, in the degenerate case of $n=0$, the answer is always 1 (I count the empty string if $n=m=0$).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/106008/how-does-expxy-expx-expy-imply-expx-exp1x/106038\nText:\nTake the 2-minute tour \u00d7\n\nIn Calculus by Spivak (1994), the author states in Chapter 18 p. 341 that $$\\exp(x+y) = \\exp(x)\\exp(y)$$ implies $$\\exp(x) = [\\exp(1)]^x$$ He refers to the discussion in the beginning of the chapter where we define a function $f(x + y) = f(x)f(y)$; with $f(1) = 10$, it follows that $f(x) = [f(1)]^x$. But I don't get this either. Can anyone please explain this? Many thanks!\n\nshare|improve this question\nAs a first step: try writing out the argument Spivak gave in your question, and try writing it in your own words. \u2013\u00a0 \uff2a. \uff2d. Feb 5 '12 at 16:08\nEither $f(x+y)=f(x)+f(y)$ or $f(x)=[f(1)]^x$ is incorrect. One of the two should be changed to $f(x+y)=f(x)f(y)$ or $f(x)=[f(1)]x$ respectively. \u2013\u00a0 Adam Feb 5 '12 at 16:40\nadd comment\n\n4 Answers\n\nup vote 7 down vote accepted\n\nI think you should assume $x$ is an integer (since $a^x$ is defined using $\\exp$ if $x$ is a positive real). You can write $\\exp(x) = \\exp(1+1+1+1+\\cdots+1)$ (there is $x$ times \u00ab 1 \u00bb\u00a0in the last term).\n\nUsing the property of $\\exp$, you find now $\\exp(x) = \\exp(1)\\exp(1)\\cdots\\exp(1) = (\\exp(1))^n$\n\nshare|improve this answer\nNote that $a^x = \\exp( x \\log(a))$ and is defined for all complex $x$ and $a$, s.t. $a \\not= 0$, where the principal branch of $\\log$ is taken. \u2013\u00a0 Sasha Feb 5 '12 at 16:50\nadd comment\n\nAs Paul Pichaureau has mentioned, it is easy to see that the formula holds for $n$\u00a0natural. You can also easily go further: what should $\\exp(-n)$\u00a0be? Well, $\\exp(0) = 1 = \\exp(-n+n) = \\exp(-n) \\exp(n)$, so $\\exp(-n) = 1/\\exp(n)$. Furthermore, it is easily seen that $\\exp(nx) = \\exp(x)^{n}$, so that $$\\exp(1) = \\exp(n\\cdot 1/n) = \\exp(1/n)^n,$$ and hence $$\\exp(1/n) = \\exp(1)^{1/n}$$ by the usual rules for powers. Combining these, we see that $$\\exp(p/q) = \\exp(1)^{p/q},$$ so the formula holds for any rational number $x$. I think this is about as far as you can get using only that formula (in addition to the requirement that $\\exp(0) = 1$). If we, in addition, assume that $\\exp$ is continuous on $\\mathbb{R}$, then we can choose a sequence $(r_{i})_{i =1}^{\\infty}$\u00a0of rational numbers such that $\\lim_{n \\to \\infty} r_{i} = x$, and compute $$\u00a0\\lim_{n\\to \\infty} \\exp(1)^{r_n} = \\lim_{n \\to \\infty} \\exp(r_{n}) = \\exp(\\lim_{n \\to \\infty} r_{n}) = \\exp(x).$$ The problem now is what $\\exp(1)^x$\u00a0is supposed to be. If we already know that the power function $x \\mapsto \\exp(1)^x$\u00a0is continuous, then certainly the right hand side is equal to $\\exp(1)^x$, but as Paul mentions, the power functions are often defined in terms of the exponential function. However, I don't think you have to do it that way (you could define rational powers as usual, and prove that a continuous extension to the reals exists), so it all depends on what Spivak has done prior to that chapter (you also didn't specify what $x$\u00a0is, so it conceivable that he assumes it is rational, in which case it doesn't matter much).\n\nshare|improve this answer\nInstead of continuity, you could get by with monotonicity. \u2013\u00a0 Michael Hardy Feb 6 '12 at 2:41\n@michaelhardy: interesting! \u2013\u00a0 Martin Wanvik Feb 6 '12 at 2:54\nexcellent answer Martin, thorough and comprehensive without abstruosity \u2013\u00a0 David Holden Dec 23 '13 at 16:22\nadd comment\n\nThe $n$-th $\\ (n\\in{\\mathbb N}_{\\geq1}$) power of a real number $a>0$ is defined in elementary terms as product of $n$ factors equal to $a$. It is only reasonable to define $a^0:=1$ and $a^n:=1/a^{-n}$ when $n<0$. One then has $$a^{m+n}=a^m\\cdot a^n\\ ,\\qquad a^{m\\ n}=\\bigl(a^m\\bigr)^n \\qquad(*)$$ for all $m$, $n\\in{\\mathbb Z}$. The aim now is to extend the definition of an $x$-th power of $a$ from $x\\in{\\mathbb Z}$ to $x\\in{\\mathbb Q}$ and $x\\in{\\mathbb R}$ such that the law $(*)$ is preserved.\n\nThe first step is easy: For $p\\in{\\mathbb Z}$ and $q\\in{\\mathbb N}_{\\geq1}$ put $$a^{p/q}\\ :=\\ \\root q \\of {a^p}\\ .$$ Using the \"rules of algebra\" one then can verify that $(*)$ is true for arbitrary $x$, $y\\in{\\mathbb Q}$ instead of $m$, $n\\in{\\mathbb Z}$. That is as far as one can get using the algebraic notions of $n$-th power and $q$-th root.\n\nNow analysis provides a wonderful (in particular, continuous) function $x\\mapsto\\exp (x)$ with the property that $\\exp(x+y)=\\exp(x)\\cdot\\exp(y)$ for all $x$, $y\\in{\\mathbb C}$. Put $\\exp(1)=:e\\doteq 2.718$. Then it follows by an easy induction that in fact $$\\exp\\Bigl({p\\over q}\\Bigr)\\ =\\ e^{p/q}$$ for all ${p\\over q} \\in{\\mathbb Q}$. As $\\exp$ is continuous it is only natural to define arbitrary real powers of the number $e$ by $$e^x\\ :=\\ \\exp(x)\\qquad(x\\in{\\mathbb R})\\ .$$ Via the logarithm function (which I won't explain here) we can define arbitrary real powers not only of $e$, but of an arbitrary number $a>0$: $$a^x\\ :=\\ \\exp\\bigl(x\\log(a)\\bigr)\\qquad (x\\in{\\mathbb R})\\ .$$ Using the functional equations of $\\exp$ and $\\log$ one then easily proves that the rule $(*)$ remains true for arbitrary $x$, $y\\in{\\mathbb R}$ instead of $m$, $n\\in{\\mathbb Z}$.\n\nshare|improve this answer\nadd comment\n\nI like (as I have done here before) to start with a functional equation and derive properties of the function.\n\nIf $f(x+y) = f(x) f(y)$ and $f$ is differentiable (and non-zero somewhere), $f(0) = 1$ and $f(x+h)-f(x) = f(x)f(h)-f(x) =f(x)(f(h)-1) =f(x)(f(h)-f(0)) $ so $$(f(x+h)-f(x))/h = f(x)(f(h)-f(0))/h.$$ Letting $h \\to 0$, $f'(x) = f'(0) f(x)$. From this, $f(x) = \\exp(f'(0)x)$.\n\nThis also works for $\\ln$, $\\arctan$, and $\\sin$ and $\\cos$.\n\nFunctional equations are fun!\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/63055/bridging-uniform-and-mass-distributions\nText:\nTake the 2-minute tour \u00d7\n\nForeword. The original formulation of this problem was inaccurate; chamomille and Didier Piau came up with a simple example which would not solve the problem in its accurate formulation. Sorry for my inaccuracy. Below is an edited version.\n\nMy goal is to find a family X(a, b) of random variables (continuously) depending on two non-negative parameters a and b . The family should have the following properties:\n\n(1) X(a, b) take values in the unit interval [0, 1] for all a, b;\n\n(2) For dependent random variables Y(a, b) defined as 1/(a+b*X(a, b)) the expected values E[Y(a, b)] exist;\n\n(3) When b/a is close to 0, the distribution of X(a, b) is close to uniform on [0, 1];\n\n(4) When a/b is close 0, the distribution of X(a, b) is close to \u201cmass\u201c distribution (that is, X(a, b) equals 1 with probability 1).\n\nSo my goal is to find a family of random variables parameterized by a and b to \u201cbridge\u201d the uniform and \u201cmass\u201d distributions.\n\nI tried different parameterizations but was not able to find a parameterization satisfying all conditions (1)-(4).\n\nshare|improve this question\nI do not understand why you are not happy with the choice $X(a,b)=1$ for all $a,b>0$. \u2013\u00a0 camomille Apr 26 '11 at 16:39\nThank you, camomille. I agree. In my original post I missed an additional condition (required for the purpose of my investigation) that would not permit this obvious choice. My fault. Sorry and thank you again. \u2013\u00a0 Max1 Apr 26 '11 at 18:14\nadd comment\n\n1 Answer\n\nThese conditions are met if $X(a,b)\\in[0,1]$ almost surely for every $a$ and $b$ and if $X(a,b)\\to1$ in probability when $a\\to0$. Hence $X(a,b)=1$ almost surely solves the problem. If one wants to avoid Dirac masses, $X(a,b)$ uniform on $[1/(1+a),1]$ (or on any interval $[c(a),1]$ with $c(a)$ in $[0,1)$ and $c(a)\\to1$ when $a\\to0$) will do.\n\nEdit This is to answer the edited version of the question. A solution is to consider $X(a,b)$ uniform on $[b/(a+b),1]$ or on any interval $[k(a/b),1]$ where the function $k(\\ )$ is such that $k(r)$ in $[0,1]$ for every $r\\ge0$, $k(r)\\to1$ when $r\\to0$ and $k(r)\\to0$ when $r\\to+\\infty$, for example $k(r)=1/(1+r)$ or $k(r)=\\mathrm{e}^{-r}$.\n\nSecond edit Still another solution, such that the support of $X(a,b)$ is the full interval $(0,1)$ for every $(a,b)$, is to assume that $X(a,b)$ has density $c(b/a)x^{c(b/a)-1}$ for $x$ in $(0,1)$, where the function $c(\\ )$ is such that $c(r)\\to1$ when $r\\to0$ and $c(r)\\to0$ when $r\\to+\\infty$. A realization is $X(a,b)=U^{1/c(b/a)}$ with $U$ uniform on $(0,1)$, for example $$ X(a,b)=U^{a/(b+a)}. $$\n\nshare|improve this answer\nThank you, Didier. I should have formulated my goal more accurately to avoid this example. \u2013\u00a0 Max1 Apr 26 '11 at 18:18\nThank you again, Didier! \u2013\u00a0 Max1 Apr 27 '11 at 14:11\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/8782/multidimensional-array-reduction-through-summation-over-one-of-its-dimensions/8785\nText:\nTake the 2-minute tour \u00d7\n\n1. Introduction\n\nI am using an array of dimension 3 (might become more) to store some values. I would like to implement a function that takes as argument the array and a couple of numbers smaller than the array dimension and returns a standard matrix (dim=2) which is obtained by reduction or \"projection\" (I don't really know how to call it) of the array along all the \"other\" dimensions. First a quick example with an array of dimension/depth 3\n\ndata=Table[10 (i - 1) + 3 (j - 1) + k, {i, 2}, {j, 3}, {k, 4}]\n--> data = {{{1, 2, 3, 4}, {4, 5, 6, 7}, {7, 8, 9, 10}},\n           {{11, 12, 13, 14}, {14, 15, 16, 17}, {17, 18, 19, 20}}}\n\nMy desired function would do, for example, the following\n\nMyfunction[data,{1,2}] = {{10,22,34},{50,62,74}}\n\nAfter this brief introduction, let me explain where I've arrived. First let's generalize a little bit, as it is my goal, eventually.\n\n2. Definitions\n\nLet $M \\in \\mathbb{R}^{\\Pi d_i}$ be an array of dimension $N \\in \\mathbb{N}$.\n\nLet $d_i \\in \\mathbb{N}, \\quad i=1,\\dots,N\\quad$ be the sublengths of each of the dimensions.\n\nWhat I will call in the following the projection of the array along the dimension $q$ is the following surjective function : $$ \\textrm{For } q\\leq N \\in \\mathbb{N}_0,\\quad P(M,q) : \\mathbb{R}^{\\Pi d_i} \\rightarrow\\mathbb{R}^{\\frac{\\Pi d_i}{d_q}} : M(n_1,\\dots,n_N) \\mapsto \\sum_{j=1}^{n_q}M(n_1,\\dots,n_{q-1},j,n_{q+1},\\dots,n_N) $$\n\n3. Goal\n\nThe goal is to write a function that takes any multidimensional array as well as a list of all the dimensions that will be \"kept\" in the final array. For the sake of any representation, the obtained array should be of dimension $\\leq$ 2 but I would like to stay as general as I (we) could.\n\nThe dimensions ordering should simply be the one used to implement the array, and the code should be consistent in order to keep the dimensions in the same order at any time.\n\n4. Implementation\n\nProjectedColumns[len_,cols_]:= Complement[Range[len],cols]\n\nProjectedColumns is a function that returns a list of the dimensions to project, where cols is the list of dimensions to be kept and len is the dimension of the array.\n\nCompoundProjection[data_, cols_] :=\nModule[{len, vect},\n    len = Depth[data] - 1;\n    vect = ProjectedColumns[len, cols];\n        SingleProjection[data, vect[[i]]],\n        {i, Length[vect]}\n\nCompoundProjection is a function that will project all the dimensions sequentially in order to arrive to the final result (The projection is commutative).\n\nSingleProjection[data_, dimnumber_] := ???\n\nNow what I need and I don't manage to get is the function that will actually perfom a one-dimensional projection. In my mind, I would need to have a number of Do loops which equals the dimension of the array.\n\nIn that case, I simply parse through the array and do the summation over the one I'm interested in. Is it possible to set up such a structure with all the commands that Mathematica offers and that I probably don't know ?\n\n5. In summary\n\n  1. Has anyone followed this nonsense ?\n  2. Is there a Mathematica command that makes what I want directly ?\n\n(If Yes then No to the previous questions, then I'm happy)\n\n  1. Is there a way to improve the correctness or elegance of what I did ?\n  2. Is there a way to intricate a dynamic number of Do loops ?\n  3. Or, in general, is there another way to achieve the goal described in 3.\nshare|improve this question\nMaybe you can start from this : Map[Total , data, {2}], which will do what you seek with Myfunction \u2013\u00a0 b.gatessucks Jul 27 '12 at 18:07\nSeems that @b.gatessucks is right. But I would like to see a few more examples for the {1,2} parameter in your first code snippet \u2013\u00a0 belisarius Jul 27 '12 at 18:10\nadd comment\n\n3 Answers\n\nup vote 10 down vote accepted\n\nDid you know about the second argument of Total, which lets you sum up element at a certain level, which in practice means along a certain dimensions?\n\nFor example, if you want to keep levels 1 and 2, and sum up along level 3, you can use\n\nTotal[data, {3}]\n\n(* ==> {{10, 22, 34}, {50, 62, 74}} *)\n\nOr sum up along dimension 1:\n\nTotal[data, {1}]\n\n(* ==> {{12, 14, 16, 18}, {18, 20, 22, 24}, {24, 26, 28, 30}} *) \n\nThis is the same as removeDimensions[data, {3, 1}].\n\nshare|improve this answer\nReading this I though initially that you could actually get all the desired functionality out of just Total and complement, however you run into trouble with it if you want to remove for example dimension 1 and 4 in a 6 dimensional structure, and then you need to reorder the arguments, or call Total continually while recalculating the dimensions on each pass. \u2013\u00a0 jVincent Jul 27 '12 at 18:27\n@jVincent Yes, for that it's necessary to call Total two times. \u2013\u00a0 Szabolcs Jul 27 '12 at 19:03\nTotal seems to be a good tool indeed. I've come up with a way of using it recursively. You don't need to relaculate anything in the process. You just apply the reduction beginning by the deepest dimensions and then it works fine. \u2013\u00a0 Pschoofs Jul 30 '12 at 9:08\nadd comment\n\nI may be misunderstanding what you need, however consider this. If you have an structure of nested lists such as your data, then summing across the deepest list is easily accomplished using Map[Total,data,{-2}]. So, as long as you want to remove dimensions from \"the back\" you are good to go. And if we need to remove for example the second dimension, then you can just transpose it to the back, and then remove it:\n\n\nSumming out more then one dimension would then just be pushing them all to the back, and applying Total at a higher level and summing all the way down. Which can be done as:\n\n transposeOrder[data_, dimensions_] := \n    Join[dimensions, Complement[Range[Depth[data] - 1], dimensions]]\n\n removeDimensions[data_, dimensions_] /; (Length[dimensions] < Depth[data] - 1) := \n    Map[Total[#, Infinity] &, \n    Transpose[data, transposeOrder[data, dimensions]],\n    {-1 + Length[dimensions] - (Depth[data] - 1)}]\n\nAnd for the case where you aren't removing any dimensions, I suppose it should just fall back to reordering them:\n\n sumOutDimensions[data_, def_] /; Length[def] == Depth[data] - 1 := Transpose[data, def]\n\nNow these functions output the results with dimensions in the order given by the input, if you want to retain the order of the data structure, you could just sort the arguments to it.\n\n removeDimensions[data, {1, 2}]\nshare|improve this answer\nadd comment\n\nHere's a version using Flatten to push all the \"unwanted\" dimensions down to the innermost level before applying the desired function.\n\nkeepDimensions[data_, dims_List, func_:Total]:=\n\nExamples :\n\nkeepDimensions[data, {1,2}]\n\nAny combination of dimensions can be kept\n\nkeepDimensions[data, {1,3}]\n\nKept dimensions can be re-ordered\n\nkeepDimensions[data, {3,1}]\n\nAn optional third argument can be supplied to do something other than summation:\n\nkeepDimensions[data, {1,3}, Max]\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/432652/confusion-regarding-change-of-variables-in-odes\nText:\nTake the 2-minute tour \u00d7\n\nConsider the following exercise:\n\nUsing the Laplace transform, find a solution $y(x)$ of the following initial value problem:\n\n$$\\begin{cases} y'' +y = x + 1, \\quad x > \\pi \\\\ y(\\pi) = \\pi^2 \\\\ y'(\\pi) = 2\\pi \\end{cases}$$\n\nSuggestion: Make the change of variables $t = x - \\pi$.\n\nOf course, this equation is pretty easy to solve without the Laplace transform, but the whole point of the exercise is to use it. That's not the problem, though. I'm having some trouble with the change of variables.\n\nI know that for the derivatives you have to use the chain rule; in this case, since $dt = dx$ there's no difference. My main issue is with the initial conditions. I'm not very sure how to restate them in terms of $t$, and I think that's because I don't really know a precise definition of change of variables. How is it done? Do we define a new function, something like $g(t) = y(x-\\pi)$, if that even makes sense? What would be a general method to make sure one does things like this carefully?\n\nI apologize if the question is rather vague. Just to be clear, I'm not asking how to solve this particular differential equation; I've realized I get confused in general when using change of variables in an ODE.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nTry to use Laplace transform to solve: $$\\begin{cases} g'' +g = t+ \\pi + 1, \\quad t > 0 ,\\\\ g(0) = \\pi^2, \\\\ g'(0) = 2\\pi. \\end{cases}$$\n\nLike you said, but it is not letting $g(t) = y(x-\\pi)$, rather it is letting $g(t) := y(t+\\pi) = y(x)$. Basically the equation is translated by $\\pi$ in the independent variable, so when originally the initial condition is at $x = \\pi$, now it is at $t = x-\\pi = 0$.\n\nshare|improve this answer\nThat works. But what's the point then ofusing two different \u2013\u00a0 Javier Badia Jun 30 '13 at 13:09\n@JavierBadia Because Laplace transform's formula for derivatives involve the initial value at 0: $\\mathcal{L}\\{f'\\} = s\\mathcal{L}\\{f \\}-f(0)$. You can use the initial value at $\\pi$ as well, but whenever you perform the integration by parts using the definition of Laplace transform, you will find it essentially you are translating the coordinates as well, so it is easier to do it before going into the Laplace transform stage. \u2013\u00a0 Shuhao Cao Jun 30 '13 at 16:03\n@Shuhaho: I'm sorry, I accidentally submitted that comment early and was going to fix it but I forgot. I understand that. What I was going to say is, what's the point of using a different variable name? Like you said; isn't it clearer to say \"use $g(x) = g(x+\\pi)$\" instead of \"use $t = x - \\pi$\"? \u2013\u00a0 Javier Badia Jun 30 '13 at 16:43\n@JavierBadia Using the same letter would cause confusion, for $g(x) = g(x+\\pi)$ means periodicity for the same function $g$, using a different letter just avoid this: say $y(x) = x^2$, then letting $g(t) := y(t+\\pi) = t^2 + 2\\pi t + \\pi^2$, this can be also written as $g(x) := y(x+\\pi) = x^2 + 2\\pi x + \\pi^2$, $g$ and $y$ are simply different functions, one of which is a translation in $x$ of the other. \u2013\u00a0 Shuhao Cao Jun 30 '13 at 16:58\nIt seems I just can't write comments today. I meant $g(x) = y(x+\\pi)$. \u2013\u00a0 Javier Badia Jun 30 '13 at 17:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/permutation-groups.52613/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nPermutation groups\n\n  1. Nov 14, 2004 #1\n    what is the number of elements of order 5 in the permutaion group S7??\n    so what we're concerned with here is, after decompositon into disjoint cycles the l.c.m of the lengths must be 5. since 5 is a prime, the only possible way we could get 5 as l.c.m would be to fix ANY 2 elements amongst the 7 to themselves....so we end up getting 2 cycles of length 1 each. the remaining five elements can be arranged in 4! ways...\n    so, the answer is 7C2 * 4! = 21*24 = 504.\n    :smile: but unfortunately, this answer is WRONG!!\n  2. jcsd\n  3. Nov 14, 2004 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Since 5 is prime, you MUST have cycle of length 5.\n    Then there could be a 2-cycle in addition.\n  4. Nov 15, 2004 #3\n\n    well....yes, it's possible to have a cycle of length 2 in addition to the 5 cycle...but then the l.c.m becomes 10. so that rules out such a consideration!\n  5. Nov 15, 2004 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Yes, so the only permutations in S7 of order 5 are the 5-cycles.\n  6. Nov 15, 2004 #5\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Your answer is wrong because you've counted, for example:\n\n    12345, 23451, 34512, 45123, and 51234 as different elements.\n  7. Nov 15, 2004 #6\n    ya....so what further? that's a valid point you've raised...\n    so do you divide by 4?\n  8. Nov 15, 2004 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have [itex]{7 \\choose 5}[/itex] ways to pick 5 elements from a set of 7.\n    There are 5! ways you can order 5 elements in a cycle.\n    For a given cycle of length 5, 5 orderings are give the same permutation.\n  9. Nov 16, 2004 #8\n    hey galileo\n\n    please read stuff carefully...\n    we left this a long while ago, right astronut?! :smile:\n  10. Nov 21, 2004 #9\n    i think the solution 504 is correct....\n    i don't see any fallacy in it.\n  11. Nov 21, 2004 #10\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The general solution is:\n\n    suppose t is a permutation of type\n\n\n    then the order of the centralizer is\n\n    [tex]\\prod_i i^{m_i}m_i![/tex]\n\n    in this case it is 1^2.5\n\n    so the centralizer's order is\n\n\n    hence the conjugacy class has order\n\n\n    which is indeed 504\n\nHave something to add?\n\nSimilar Discussions: Permutation groups\n  1. Permutation Group (Replies: 2)\n\n  2. Permutation Group (Replies: 29)"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53536.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nRate of Change of Angle\n\nDate: 8/12/96 at 0:31:2\nFrom: da bellm\nSubject: Rate of Change of Angle\n\nDear Dr. Math,\n\nI'm an engineering student at the University of Adelaide in South \nAustralia.  This is a problem that I was given about 4 years ago,  \nback in high school.  No one I've asked has been able to give me a \nsatisfactory answer to it.\n\nTwo roads, BA and CA, meet at an angle of 60 degrees. A landmark \nsituated at B, 500 metres from A, is visible to drivers approaching \nA along CA. A vehicle at X is moving along CA towards A at \n72 kilometres per hour.\n           /  o\n         /  60\n      A                   X           C\n\na)  Find the rate at which BX is changing when the vehicle is 500m \nfrom A. (This bit is easy,  but leads on to part b.)\n\nb)  Find the rate at which angle BXA is changing in radians per second \nwhen the distance BX is least,  and give a physical explanation of why \nit is whatever it is. (This is the hard bit!)\n\nHave a nice day, \n\nDate: 8/24/96 at 19:30:46\nFrom: Doctor Mike\nSubject: Re: Rate of Change of Angle\n\nHi  Dave, \nSince you already understand part (a) I'll skip that one. \nPart (b) is a fantastic calculus problem! The straightforward way\nis incredibly long and messy, but there's a quick way if you look\nat it right.  The key is the Chain Rule for derivatives.\nDrop a perpendicular from B to the road CA and let that be the\norigin of a coordinate system with +x toward C and +y toward B.\nThis origin is 250 metres from A and 250*sqrt(3) metres from B.\nThe only *physical explanation* I see is the observation that\nBX is least exactly when the vehicle location X is at the origin.\nTo keep consistent units, use 20 metres per second rather than \n72kph.  With respect to some arbitrary reference time t=0 let p(t)\nbe the x-coordinate of the vehicle location on road CA at time \nt seconds.  If the reference time is when the vehicle is M metres\nfrom the origin, then p(t) = M-20t and p'(t) = -20 is constant.\nLet d(t) be the distance BX at time t seconds, and a(t) be the\nangle BXA at time t seconds.  Then cos(a(t)) = p(t)/d(t).  \nTake derivatives of both sides to get : \n                             d(t)*p'(t) - p(t)*d'(t)  \n       -sin(a(t)) * a'(t) = ------------------------- \nYou want to solve for a'(t) when BX is least, which is when X is\nat the origin, a(t) = pi/2, and d'(t) = 0 for a d(t) minimum.\nAnswer: (2/75)*sqrt(3) or about 0.046188 radians per second.\nI hope this is what you were looking for. \n\n-Doctor Mike,  The Math Forum\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/22937/a-simple-pendulum-moving-at-a-relativistic-speed-how-does-the-period-change\nText:\nTake the 2-minute tour \u00d7\n\nI've been pondering the precise mechanism of time dilation for the example of a simple pendulum in two different situations:\n\n  1. The observer and ground are at rest in one frame of reference; the pendulum is moving at high speed with respect to that frame.\n\n  2. The observer is at rest in one frame of reference; the pendulum and the ground together move at high speed with respect to that frame.\n\nuser8260 has pointed out that in situation 1, in the pendulum's frame $g$ is greater by $\\gamma^2$ compared to $g$ in the observer's frame. Thus in the pendulum's frame the period is less than it is in the observer's frame by a factor of $1/\\gamma$, just as one would expect from time dilation.\n\nBut what about situation 2? Here, compared to the pendulum frame, the observer sees the pendulum with the same length in a stronger gravitational field, yet observes a longer period. Does the inertial mass of the pendulum change differently than its gravitational mass? Also, does the analysis depend on whether the plane of swing is perpendicular or parallel the direction of motion?\n\nshare|improve this question\nUser8260 is not right. The first case does not require time dilation changes because the Earth define a ret frame. Only in the second case do you see pure time dilation. \u2013\u00a0 Ron Maimon Apr 5 '12 at 3:14\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nAs in physics in general, a suitable choice of coordinates makes our life so much better. Time dilation in this problem is somewhat a more trivial effect, and the transformation of gravitational field is somewhat a more complicated phenomenon. With this in mind, let me reformulate slightly the two situations:\n\nCase 2. Pendulum is at rest with respect to the Earth (and some observer moves with respect to them, observes time dilation etc etc)\n\nCase 1. Pendulum is set above the Earth, which moves relativistically below it (and some observer moves with the Earth, observes time dilation etc)\n\nSo, let us settle the physics first, and the observer effects last.\n\nCase 2: Classical physics problem, nothing to settle.\n\nCase 1: From the pendulum's point of view, the gravitational field is generated by a moving body (=>the field is unknown). From the Earth frame, a relativistic body moves in a gravity field (=>the equations of motion are unknown).\n\nOne might transform the energy-momentum tensor of the Earth from the Earth rest frame to the pendulum frame, but special care should be taken about the fact that the Earth ceases to be spherical in the new frame (though its density does increase as $\\gamma^2$). Additionally, it is not clear appriori that the motion of the Earth doesn't cause any additional forces.\n\nI propose to use a straightforward yet more secure method of transforming the metric tensor from the Earth frame to the pendulum frame, and hence obtain the gravity, acting on the pendulum.\n\nIn the Earth rest frame the metric tensor is known to be $$g_{\\mu\\nu}=\\left(\\begin{array}{cccc} &1-2U & 0 & 0 & 0 &\\\\ &0 & 1-2U & 0 & 0 &\\\\ &0 & 0 & 1-2U & 0 &\\\\ &0 & 0 & 0 & -1-2U &\\\\ \\end{array} \\right),$$\n\nwhere $U$ is the Newtonian potential of the Earth. This expression corresponds to the so called weak field limit, when the metric tensor is nearly flat. We use the standard notation of MTW ($c=1$, signature $(+++ -)$, Einstein's summation rule etc) and refer to this book for further details on linearized gravity.\n\nTransformation of the field to the pendulum frame:\n\nLorentz tranformation matrix is given by:\n\n$$ \\Lambda_{\\mu'}^{~\\mu}=\\left(\\begin{array}{cccc} &\\gamma & 0 & 0 & \\beta \\gamma &\\\\ &0 & 1 & 0 & 0 &\\\\ &0 & 0 & 1 & 0 &\\\\ &\\beta\\gamma & 0 & 0 & \\gamma &\\\\ \\end{array} \\right), $$ with $\\beta=\\dfrac{v}{c}, \\gamma=(1-\\beta^2)^{-1/2}$ and $v$ being the relative velocity of the pendulum with respect to the Earth rest frame.\n\nThe transformed metric tensor is obtained by: $$g_{\\mu'\\nu'}=\\Lambda_{\\mu'}^{~\\mu}\\Lambda_{\\nu'}^{~\\nu} g_{\\mu\\nu}=\\left(\\begin{array}{cccc} &1-2U\\dfrac{1+\\beta^2}{1-\\beta^2} & 0 & 0 & -\\dfrac{4 U \\beta}{1-\\beta^2} &\\\\ &0 & 1-2U & 0 & 0 &\\\\ &0 & 0 & 1-2U & 0 &\\\\ &-\\dfrac{4 U \\beta}{1-\\beta^2} & 0 & 0 & -1-2U\\dfrac{1+\\beta^2}{1-\\beta^2} &\\\\ \\end{array} \\right)$$\n\nIn the pendulum frame (further primes in the indices are omitted!):\n\nIt is known that only the term $g_{44}$ determines the newtonian potential. One can see that by writing out the lagrangian for the pendulum:\n\n$$ \\mathcal{L}=\\dfrac{1}{2}g_{\\mu\\nu} u^\\mu u^\\nu=\\\\ =\\dfrac{1}{2}((u^1)^2+(u^2)^2+(u^3)^2-(u^4)^2)-\\\\ -U((u^2)^2+(u^3)^2+4 u^1 u^4 \\beta \\gamma^2+((u^1)^2+(u^4)^2)\\dfrac{1+\\beta^2}{1-\\beta^2}) $$\n\nHere $u^\\mu$ is the 4-velocity of the pendulum. As the latter moves non-relativistically (in its own frame), we may consider $u^4\\gg u^1,u^2,u^3$ and $u^4\\approx \\mathrm{const}$, which leaves:\n\n$$ \\mathcal{L}=\\dfrac{1}{2}((u^1)^2+(u^2)^2+(u^3)^2)-U(u^4)^2\\dfrac{1+\\beta^2}{1-\\beta^2} $$\n\nIf the pendulum as a whole didn't move with respect to the Earth, we would have $\\beta = 0$ and\n\n$$ \\mathcal{L}_0=\\dfrac{1}{2}((u^1)^2+(u^2)^2+(u^3)^2)-U(u^4)^2 $$\n\nEffectively, therefore, the pendulum in its rest frame experiences the gravitational field magnified by the factor of $\\dfrac{1+\\beta^2}{1-\\beta^2}$. The pendulum frequency is thus magnified by $\\dfrac{(1+\\beta^2)^{1/2}}{(1-\\beta^2)^{1/2}}$.\n\nRemarks: the neglected terms in the lagrangian are either $\\dfrac{v}{c}$ or $(\\dfrac{v}{c})^2$ smaller than the kept leading terms. Hence, up to $\\dfrac{v}{c}$ accuracy the direction of motion doesn't affect the pendulum frequency.\n\nFinally, lets add time dilations to get the final answers. Let the period of the pendulum in the case when observer, the Earth, and the pendulum do not move with respect to each other be $T_0$. Then:\n\nCase 1: In the pendulum frame, as we have seen it has the period of $\\dfrac{(1-\\beta^2)^{1/2}}{(1+\\beta^2)^{1/2}} T_0$. Then in the observer frame, due to time dilation, the period is $\\dfrac{1}{(1+\\beta^2)^{1/2}}T_0$.\n\nCase 2: In the pendulum frame the period is $T_0$. In the observer frame the period is $\\dfrac{T_0}{(1-\\beta^2)^{1/2}}$.\n\nTo conclude, the two cases are quite different due to the different physics happening. In one case the observed period changes due to the change of the reference frame, whereas in the other there is an additional factor due to the fact that the gravity of a moving source is not the same as that of a still source.\n\nshare|improve this answer\nThe question for case 2 in the observer frame isn't \"can it be solved with the time dilation formula?\" That must be true. The question is \"can the observer attribute this time dilation to some physical mechanism?\" In his frame there's a pendulum in a gravitational field that is stronger than it would be in the pendulum frame, yet it swings more slowly. \u2013\u00a0 Noah Apr 5 '12 at 13:49\nThe answer is yes. In the lagrangian $u^4\\gg u^1$ stops being true if the pendulum is flying relativistically over the ground (which also moves). Then one has to consider all the terms in the lagrangian, which will lead to the same result as given by the dilation formula. \u2013\u00a0 Alexey Bobrick Apr 5 '12 at 15:39\nAs a follow-up, the gravitational field, which acts on a relativistically moving source is not a newtonian-like potential, it is more complicated (other components of the metric tensor start producing significant effects). Then it is somewhat unsafe to compare the newtonian-like potential acting on a moving body and on a body at rest. In other words the reasoning \"the field is stronger, the effect is different\" cannot apply. Strictly, one should also consider the so-called post-newtonian corrections to the forces (which are represented as the terms in the lagrangian), which change the field. \u2013\u00a0 Alexey Bobrick Apr 5 '12 at 15:45\n\nWhen g increases in the moving frame the period should decrease, not increase. Recall, the period goes like $\\sqrt\\frac{l}{g}$, so a large gravitational acceleration translates to fast oscillations, or a short period. In any case, the stationary reference frame should always measure a period that is larger by a factor of $\\gamma$ than what the moving frame sees. This time dilation shouldn't be correlated with the changing of the effective density in the moving frame - that is something of a red herring. Really, this isn't a lorentz invariant system (because of the large stationary mass defining the gravitational field) so this might cause some of the confusion. Yes, the gravitational field looks different in a moving frame, and yes, this should cause a change in the period, but this isn't the same thing as the usual time dilation effect one expects in special relativity. Both effects are at play here. Finally, the density of the earth that the moving observer sees will change by $\\gamma^2$, not simply $\\gamma$. However, as detailed in the answer above, one cannot simply deduce the the moving pendulum's frequency from the density alone because this is a non-inertial frame and one should do a full calculation.\n\nThe situation in question 2 is analogous, but now, from the moving frame's perspective, we have a moving pendulum in an altered gravitational field. We should really formulate this problem properly in the language of tensors. From the moving frame's viewpoint the equation of motion of the mass at the end of the pendulum is (very roughly)$(dv/dt+v\\Gamma'v)=F'$, where $\\gamma'$ is the christoffel symbol in the moving frame and F' is the force. F' transforms as a vector, while $\\gamma$ almost transforms as a vector, but with an extra additive piece. In any case, it is the christoffel symbol built from the metric g'_uv in the moving frame, which does transform as a tensor. We may thus obtain g'_uv by acting on g_uv with the usual transformation matrix, and we know g_uv since it's zero-zero component is simply related to the usual Newtonian potential.\n\nNow, one could do all the algebra here, but the main point is that since both sides are tensors that transform the same way, the end result is guaranteed to be invariant. Thus, if we just wanted to get some answer we would naturally use the stationary frame where the calculation is easier. Thus, we may conclude that the stationary frame gets $\\sqrt(l/g)$ and the moving frame sees $\\gamma$ times this.\n\nOne further note. This question is somewhat analogous to the following problem. Let observer A be stationary and let B be moving. Observer A measures the time, $t_a$, between two events and observer B likewise measures $t_b$. Now, observer A thinks $t_a < t_b$, while observer B thinks $t_b < t_a$. These are just real numbers, so $t_a=t_b$! Obviously something went wrong and this is a standard \"paradox\" in special relativity. The answer is the same: we have to consider the transformation of the non-time components of the four-vector connecting the two events in order to see how one observer interprets the measurements of another. As an exercise, try to calculate B's coordinates for the events and t_b given A's coordinates, and then use this to go back and get A's coordinates from B's coordinates. I.e., transform from A to B to A. One might think that the time is getting \"slower\" with each boost but the two transforms cancel each other (obviously). I think that this is essentially a simplified version of the problem here.\n\nshare|improve this answer\nWhy would the density of the earth in the pendulum support's frame change by gamma squared instead of gamma? \u2013\u00a0 Noah Mar 29 '12 at 0:04\nThe density changes as gamma squared because it is the zero-zero component of the stress energy tensor. Tensors change by acting with the transformation matrix twice, one for each index. For the zero-zero component this is simply gamma squared. \u2013\u00a0 user8260 Mar 30 '12 at 0:57\nThanks. I had hoped there would be a more straightforward dynamical explanation for how an observer moving with respect to the pendulum would describe the difference in period, similar to how an observed watching an object accelerate to high speed might explain the length contraction as an electromagnetic effect - moving atomic nucleic producing distorted fields that reduce bond lengths. \u2013\u00a0 Noah Apr 4 '12 at 20:03\nOkay, I concur with Alexey's answer below. You really can't get the pendulum's period just by considering the change in the density, this was just laziness. A full calculation seems necessary, verbal hand waving won't suffice. \u2013\u00a0 user8260 Apr 4 '12 at 22:39\n-1: this is totally wrong. The Earth defines a rest frame, and only if you move both the Earth and the pendulum do you see time dilation. \u2013\u00a0 Ron Maimon Apr 5 '12 at 3:13\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204036/simplify-sum-i-0n-1-2n-choosei-cdot-xi/204049\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to simplify an expression involving summation as follows:\n\n$$\\sum_{i=0}^{n-1} { {2n}\\choose{i}}\\cdot x^i$$\n\nwhere $n$ is an integer, and $x$ is a positive real number.\n\nAt a first glance, I can see that\n\n$$\\sum_{i=0}^{2n} { {2n}\\choose{i}}\\cdot x^i = {(1+x)}^{2n}.$$\n\nBut what if in the case when $i$ goes from 0 to $n-1$?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nIf you sum from $0$ to $n-1$, then no longer you get an easy espression. Instead, you can get the sum in terms of the hypergeometric function\n\n$$ \\left( x+1 \\right) ^{2\\,n}-{2\\,n\\choose n}{x}^{n} {F (1,-n;\\,n+1;\\,-x)}\\,.$$\n\nshare|improve this answer\n\nIt's just a partial answer.\n\nLet $S_1(x):=\\sum_{i=0}^{n-1}\\binom{2n}ix^i$, and $S_2(x):=\\sum_{i=n+1}^{2n}\\binom{2n}ix^i$. Then writing $j=2n-i$, we get $$S_2(x)=\\sum_{j=0}^{n-1}\\binom{2n}jx^{2n-j}=S_1(x^{-1})x^{2n}.$$ So $$(1+x)^{2n}=S_1(x)+\\binom{2n}nx^n+S_2(x)=S_1(x)+\\binom{2n}nx^n+S_1(x^{-1})x^{2n}.$$ Writing $f(x):=\\frac{S_1(x)}{x^n}$, we get that $f$ satisfies the functional equation $$f(x)+f(x^{-1})=\\left(1+\\frac 1x\\right)^n(1+x)^n-\\binom{2n}n.$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/257875/a-difficult-symmetric-inequality\nText:\nTake the 2-minute tour \u00d7\n\nIn my studies of various geometric inequalities I reached an inequality which seems true (numerically) but I cannot prove it. Let $p$, $q$, and $r$ be real numbers from the interval $(0,1)$. Let's also define the following function $$f({p})=\\frac{\\sqrt{1-p}}{(2-p)^2}$$ Prove (or disprove) that: $$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq \\frac{f(p)}{p\\sqrt{p}}+\\frac{f(q)}{q\\sqrt{q}}+\\frac{f(r)}{r\\sqrt{r}} $$\n\nI've tried Lagrange multipliers but the resulting equations do not seem tractable.\n\nEDIT: The original question had the condition $p+q+r=2$ which apparently is not necessary, so I dropped it. I can prove that the inequality holds for $p=q$. A possible strategy is to try to establish monotonicity in one of the parameters under certain conditions. Unfortunately I can't manage the calculations.\n\nshare|improve this question\nI've noticed that this inequality seems to be true for other functions $f(x)$. Which suggests an additional question - what conditions are needed for $f(x)$ so that the inequality holds given the initial conditions. \u2013\u00a0 ivan Dec 14 '12 at 7:28\nHi ivan, the inequality would not be contrary? \u2013\u00a0 Elias Dec 15 '12 at 15:04\nNo, it is like this. \u2013\u00a0 ivan Dec 15 '12 at 16:57\n@ivan : of course, it is no coincidence that you treated the $p=q$ case. For a fixed $r$, and when we let $p$ and $q$ vary, numerically it seems that the minimum of the difference is attained when $p=q$. This is a familiar pattern in symmetrical inequalities : optimality is reached when the variables are equal. \u2013\u00a0 Ewan Delanoy Dec 17 '12 at 8:51\nI would be tempted to study $$g(p,q,r)= \\frac{f(p)}{p\\sqrt{p}}+\\frac{f(q)}{q\\sqrt{q}}+\\frac{f(r)}{r\\sqrt{r}}-\\frac{f(p)+\u200c\u200bf(q)+f(r)}{\\sqrt{p q r}}\\,.$$ It is clear that $g(1,1,1)=0$ (and even $g(p,1,1)\\geq0$). If one could prove that $\\frac{\\partial}{\\partial p} g(p,q,r)\\leq 0$ on $(0,1]^3$, it would be sufficient (using the symmetry in $p$, $q$, $r$) to conclude on $(0,1]^3$, and then I guess the case with one or several of the other variables equal to $0$ could be handled separately. But the partial derivative does not seem to be very nice, as a maple computation indicates. \u2013\u00a0 Sebastien B Dec 17 '12 at 13:39\n\n2 Answers 2\n\nThis is a comment too long to fit in the usual format. Put $g(x)=\\frac{f(x)}{x\\sqrt{x}}$. Then the inequality to be shown is\n\n$$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq g( p ) +g( q ) +g( r ) \\tag{1} $$\n\nI can show this inequality in a special case, when $r=\\frac{1}{10}$. Indeed, a stronger inequality holds in this case :\n\n$$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq g( r ) \\tag{2} $$\n\nTo show (2), it will suffice to show the following four inequalities :\n\n$$ \\begin{array}{lc} \\frac{f(p)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (3) \\\\ \\frac{f(q)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (4) \\\\ \\frac{f(r)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (5) \\\\ 6 \\leq g(r) & (6) \\\\ \\end{array} $$\n\nConsider the term $$T_1=\\bigg(\\frac{9}{10} (2-p)^2\\bigg)^2pqr - (1-p) $$ Using the fact that $r=\\frac{1}{10}$ and $q=(19/10)-p$, $T_1$ can be rewritten $$ T_1=\\frac{673289}{10^8}+\\frac{62373961}{10^8}(1-q)+\\frac{29403}{80000}(1-q)^2+ (1-q)^3\\Bigg(\\frac{81}{1000}(1-p)^3 + \\frac{1701}{5000}(1-p)^2 + \\frac{48033}{100000}(1-p) + \\frac{58887}{500000}\\Bigg) $$ So $T_1$ is nonnegative, which yields (3). Interchanging $p$ and $q$, we obtain (4). We have $$ f ( r )=\\frac{1}{(2-\\frac{1}{10})^2} \\sqrt{1-\\frac{1}{10}}=\\frac{300}{361\\sqrt{10}} \\tag{7} $$ and hence $$ \\frac{f ( r )}{\\sqrt{pqr}} = \\frac{300}{361\\sqrt{pq}} $$ The identity $$ pq-(\\frac{10}{9} \\times \\frac{300}{361})^2=\\frac{556001}{11728890}+(1-p)(1-q) $$ shows that $pq \\geq (\\frac{10}{9} \\times \\frac{300}{361})^2$, which yields (5). Finally, we deduce from (7) that $$ g ( r )=\\frac{f ( r ) }{r\\sqrt{r}}=\\frac{300}{361\\sqrt{10}} \\times 10\\sqrt{10}=\\frac{3000}{361} $$ and this is indeed larger than $6$, which proves (6) and settles the $r=\\frac{1}{10}$case.\n\nshare|improve this answer\nNice. I tried to generalize this without using $p+q+r=2$ (which seems not to be necessary) but couldn't do it. \u2013\u00a0 ivan Dec 17 '12 at 7:42\nup vote 2 down vote accepted\n\nI was able to prove this, finally. Here is a brief sketch of the proof. I will use the following simple fact:\n\nLemma. For positive numbers, if $a\\geq b\\geq c$ and $(x_1,x_2,x_3)\\succ(y_1,y_2,y_3)$ then $ax_1+bx_2+cx_3\\geq ay_1+by_2+cy_3\\geq ay_i+by_j+cy_k$ where $(i,j,k)$ is an arbitrary permutation of $(1,2,3)$\n\nNow notice that the function : $g(p)=f(p)/\\sqrt{p}$ is decreasing in $(0,1)$. Assume $p\\leq q\\leq r$. Our inequality is equivalent to:$$\\frac{g(p)}{p}+\\frac{g(q)}{q}+\\frac{g(r)}{r}\\geq\\frac{g(p)}{\\sqrt{q r}}+\\frac{g(q)}{\\sqrt{p r}}+\\frac{g(r)}{\\sqrt{p q}}$$ Let's put $x_1=1/p, x_2=1/q$, $x_3=1/r$ and $y_1=(x_1+x_2)/2, y_2=(x_1+x_3)/2, y_3=(x_2+x_3)/2$. Notice that $x_1\\geq x_2\\geq x_3$, $y_1\\geq y_2\\geq y_3$ and $(x_1,x_2,x_3)\\succ(y_1,y_2,y_3)$. Applying the lemma for $a=g(p), b=g(q)$ and $c=g(r)$ ($a\\geq b\\geq c$ because $g(x)$ is decreasing) we get: $$ ax_1+bx_2+cx_3\\geq ay_3+by_2+cy_1=a\\frac{x_2+x_3}{2}+b\\frac{x_1+x_3}{2}+c\\frac{x_1+x_2}{2}\\geq a\\sqrt{x_2 x_3}+b\\sqrt{x_1 x_3} + c\\sqrt{x_1 x_2} $$\n\nand this is exactly what we are trying to prove.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/156218/covering-points-on-a-sphere-with-a-disk?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $m$ points (\"sites\") are selected on the unit sphere $S^2$. For a given radius $r < \\pi$, we can define a disk around any point on the sphere as the set of points at geodesic distance at most $r$ from it. Let $k$ be the maximum number of sites contained in any such disk. Is there a nice lower bound on $k$ in terms of $r$? In other words, what should the function $k(r)$ be so that, no matter where the $m$ sites are placed, we can always find a disk of radius $r$ containing $k(r)$ of them?\n\nI would hope it is simply $m$ times the fraction of the surface area of the sphere covered by a disk. After all, if the average density of sites on the sphere is $m/A$, there must be some disk whose density is at least the average, right? This would be easily proved if you could tile the sphere with disks with no overlap, but you can't, so I'm not sure. If it turns out to depend on the packing density of disks on a sphere, I'll be happy with a reasonable lower bound.\n\nIf you replace the unit sphere and the disks with unit ball and smaller balls of radius $r < 1$ in $\\mathbb R^3$, and the area ratio with the volume ratio, then the naive guess doesn't work. You can have $m/2$ sites clustered around one point near the surface of the unit ball and the other $m/2$ sites around the antipodal point, so that for $\\sqrt[3]{\\frac1{2}} < r < 1$, the volume of a ball of radius $r$ is more half that of the unit ball, but you can't get more than $m/2$ sites inside it. Perhaps it still works in some asymptotic sense; I'm curious about anything rigorous that can be said in this case too.\n\nFinally, although I've stated the above question for the 2-sphere and ball in $\\mathbb R^3$, I'm also interested in the generalization to higher dimensions.\n\nshare|improve this question\n\n1 Answer 1\n\nIt turns out that the answer to my first question is really very simple.\n\nSuppose you pick the center of the disk randomly from a uniform distribution on the sphere. Appealing to symmetry, we may infer that the probability that a given site lies within the disk is precisely the fraction of the surface area of the sphere covered by the disk; if the areas of the disk and the sphere are $a$ and $A$ respectively, this probability is $a/A$. By linearity of expectation, the expected number of sites contained in a randomly chosen disk is $ma/A$. Therefore, there must exist some disk which contains at least this many points.\n\nThe second question remains open, namely the problem of covering as many as possible of $m$ sites in a unit ball with a smaller ball of radius $r < 1$.\n\nEdit: I hate to edit merely to bump this to the front page, but I wanted to use this solution to answer another question on math.SE, and I'd rather not do that if it has a negative score. For all I know, it might have an error that I haven't noticed. The one person who downvoted did not leave a reason; can anyone else let me know if this solution is incorrect?\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49532/partitioning-a-matrix-with-bounded-row-sums?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be a $n \\times n$ matrix with non-negative entries $a_{ij}$, where $a_{ij}$ is the entry in the $i^{th}$ row and $j^{th}$ column. Assume $\\sum_{1 \\leq j \\leq n} a_{ij} \\leq 1$ for all $1 \\leq i \\leq n$. Also assume $a_{ii} = 0$ for all $1 \\leq i \\leq n$.\n\nI want to partition the index set $I = \\{1, 2 \\ldots n\\}$ into minimum number of sets $I_1, I_2, \\ldots I_t$ so that the column sum is bounded by $1$ in each sub-matrix defined by the sets, or more formally:\n\n  1. $\\cup_{1 \\leq k \\leq t} I_k = I$\n  2. For all $1 \\leq k \\leq t$, $\\sum_{i \\in I_k}a_{ij} \\leq 1$ for all $j \\in I_k$\n  3. The number $t$ is minimized\n\nI can construct examples where $t$ has to be at least $2$, on the other hand, $t = \\Theta(\\log n)$ would suffice for all such matrices. I am wondering if a tighter bound exists.\n\nMotivation: this is a sort of generalization of the coloring problem in bounded out-degree digraphs. If a di-graph has out-degree upper bounded by $k$ it can be colored with $k + 1$ colors.\n\nshare|improve this question\nSo to rephrase the question, you take an edge-weighted digraph with maximum in-degree $k$, and you want to $t$-colour the vertices such that the maximum out-degree to any colour is $k$, right? (I guess you know about the Alon-Tarsi list colouring theorem.) \u2013\u00a0 Andrew D. King Dec 15 '10 at 15:08\nLook at A remark on finite-dimensional $P\\sb{\\lambda }$-spaces by J. Bourgain Studia Mathematica [0039-3223] Bourgain yr: 1982 vol: 72 iss: 3 pg: 285 -289. \u2013\u00a0 Bill Johnson Dec 15 '10 at 16:08\nWell, when you say \"the maximum out-degree to any colour\" if you mean, the maximum weighted out-degree from any node to nodes of the same color, they yes. I actually didn\u2019t know about the theorem you mention :) \u2013\u00a0 Pradipta Dec 15 '10 at 16:09\nYes, that's what I mean. Here is the link for the original Alon-Tarsi paper springerlink.com/content/u627qn50r7013363 , but you might get more out of it by looking at the papers which cite it, for example onlinelibrary.wiley.com/doi/10.1002/jgt.20500/abstract . The proof of their result, which relates to list colourings, uses combinatorial nullstellensatz, which is useful but intimidating. Better to look at what you can do using their theorem as a black box, first. \u2013\u00a0 Andrew D. King Dec 15 '10 at 16:21\nThanks to both Andrew and Bill. I\u2019ll take a look at both papers. \u2013\u00a0 Pradipta Dec 15 '10 at 16:24\n\n2 Answers 2\n\nWhy the qualification \"bounded row-sums\" for a matrix of finite dimension?\n\nshare|improve this answer\nJust emphasizing the upper bound of 1. I guess one could rephrase in the terms the maximum row sum as well. \u2013\u00a0 Pradipta Dec 15 '10 at 19:42\nup vote 0 down vote accepted\n\nOk, I think there are examples where $\\Omega(\\log n)$ colors are needed.\n\nHere\u2019s an example, let $a_{ij} = \\frac{1}{i}$ for $j < i$ and $a_{ij} = \\frac{1}{j^2}$ for $j > i$. Then $\\sum_{j} a_{ij} = \\frac{i-1}{i} + \\sum_{j > i} \\frac{1}{j^2} = O(1)$. Of course, the bound is $O(1)$ instead of $1$, but that can be normalized and all that.\n\nHowever, note that $\\sum_j a_{j1} = \\Omega(\\log n)$ and if we only have $o(\\log n)$ partitions, this sum cannot be \"distributed\" into small enough parts.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/151921/a-hard-proof-of-two-matrixs-elements\nText:\nTake the 2-minute tour \u00d7\n\nThis is not duplicate of A matrix's element proof, but it is harder than that one.\n\nGiven an constant $\\alpha \\in (0,1)$, and an $n \\times n$ matrix $X$ whose all entries are between 0 and 1, and each row sum of $X$ is 1, and ${\\|X\\|}_{\\infty} \\le 1$. Suppose $$A=\\sum_{i=0}^{\\infty} {\\alpha}^i X^i ,$$ $$B=\\sum_{i=0}^{\\infty} \\frac {{\\alpha}^i}{i!} X^i ,$$\n\nI've done some experiments and found that :\n\nFor every two entries $(a,b)$ and $(c,d)$ ,\n\n  \u2022 if $[A]_{a,b} \\ge [A]_{c,d}$, then $[B]_{a,b} \\ge [B]_{c,d}.$\n\n(Note that I use $[A]_{i,j}$ to denote the $(i,j)$-entry of the matrix $A$)\n\nHow can I prove this result mathmetrically? Any suggestions are warmly welcome.\n\n\n** I leak out one condition that each row sum of $X$ is 1.\n\n** The subscript of sum should be starting from 0 (rather than 1) that is, $$A=\\sum_{i=0}^{\\infty} {\\alpha}^i X^i $$\n\nshare|improve this question\nI edited your other question and corrected the typos, perhaps you would do the same for this version of your question! \u2013\u00a0 Gigili May 31 '12 at 7:58\nThe assumption seems to be the same, but the conclusion is much harder for me to prove. \u2013\u00a0 John Smith May 31 '12 at 8:03\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nIt's not true. Note that $A = (I-\\alpha X)^{-1} - I$ and $B = \\exp(\\alpha X) - I$. A consequence of your claim would be that if $A_{ab} = A_{cd}$ then $B_{ab} = B_{cd}$. Try $X = \\pmatrix{1/10 & 29/40\\cr 1/5 & 1/5\\cr}$ and $\\alpha = 4/5$. I get $A = \\pmatrix{4/17 & 29/34\\cr 4/17 & 6/17\\cr}$ so $A_{11} = A_{21}$. But $B \\approx \\pmatrix{.135321868 & .6642856308 \\cr .1832512085 & .226947472\\cr}$ so $B_{11} \\ne B_{21}$.\n\nEDIT: If the sum starts at $0$, then $A = (I-\\alpha X)^{-1}$ and $B = \\exp(\\alpha X)$. Let's try for a $3 \\times 3$ matrix where $A_{12} = A_{23}$ with $\\alpha = 1/2$. $$ X = \\left( \\begin {array}{ccc} \\frac15&\\frac15&\\frac35\\\\ {\\frac {23}{60}}&\\frac25&{\\frac {13}{60}}\\\\ \\frac{1}{10}&\\frac{1}{2}&\\frac25 \\end {array} \\right),\\ A = \\left( \\begin {array}{ccc} {\\frac {2942}{2445}}&{\\frac {248}{815}}&{\\frac {1204}{2445}}\\\\ {\\frac {254}{815}}&{\\frac { 1128}{815}}&{\\frac {248}{815}}\\\\ {\\frac {422}{2445}} &{\\frac {368}{815}}&{\\frac {3364}{2445}}\\end {array} \\right)$$ $$ \\ B \\approx \\left( \\begin {array}{ccc} 1.127701142& 0.1620598118& 0.3589603173\\\\ 0.2284419794& 1.252387244& 0.1678920478 \\\\ 0.0872176063& 0.3115915010& 1.249912163 \\end {array} \\right)$$\n\nshare|improve this answer\nSorry, I leak out that each row sum of $X$ is 1. \u2013\u00a0 John Smith May 31 '12 at 8:33\nI also corrected one mistake that the index of summations in $A$ and $B$ should go from 0 (rather than 1). This would ensure that $A$ and $B$ are diagonally dominant. I think in this case, your counterexample won't apply. \u2013\u00a0 John Smith May 31 '12 at 9:07\n@Robert: I copied your TeX for your matrices to write mine, and it's different from how I usually make matrices. Does \\pmatrix just know how big to make the matrix, and then put parentheses around it? And what is \\cr? \u2013\u00a0 mixedmath May 31 '12 at 10:08\n\\pmatrix is plain TeX rather than LaTeX. It just happens to be what I'm used to. It makes a matrix delimited by parentheses. \\cr goes to the next row. \u2013\u00a0 Robert Israel May 31 '12 at 16:21\n\nThe result is still not true.\n\nSuppose $X = \\pmatrix{1/10 & 9/10 \\cr 1/2 & 1/2 \\cr}$ and $\\alpha = 4/5$.\n\nThen I get\n\n$$A \\approx \\pmatrix{2.272 & 2.727 \\cr 1.515 & 3.484 \\cr} \\qquad B \\approx \\pmatrix{1.261 & 0.963 \\cr .535 & 1.690 \\cr}$$\n\nAnd $[A]_{(1,2)} > [A]_{(1,1)}$ but $[B]_{(1,2)} <[B]_{(1,1)}$\n\nshare|improve this answer\nI corrected the index $i$ goes from 0, not start from 1. So $A$ and $B$ should be diagonally dominant. \u2013\u00a0 John Smith May 31 '12 at 9:53\n@John: These are the sums from $0$. I'll note that in this case, even $\\sum_0^8 \\alpha^i X^i$ has that $[A]_{(1,2)} > [A]_{(1,1)}$ \u2013\u00a0 mixedmath May 31 '12 at 10:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/682420/find-the-mle-of-bivariate-normal\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $X = (x_{ij})n*2$ follows a bivariate normal distribution $\\mathcal{N}(\\mu, \\sigma^2I)$, where I is the $2\\times 2$ identity matrix. How to find the maximum likelihood estimates of $\\mu$ and $\\sigma^2$? Specifically, how to deal with the determinant part in the density formula of bivariate normal distribution? Thanks!\n\nshare|improve this question\nCan you please explain what you want to mean by $(x_{ij})n*2$? Does it mean a $n\\times 2$ matrix $X$? \u2013\u00a0 Samrat Mukhopadhyay Feb 19 at 18:28\nit's a n*2 matrix, has n rows and 2 columns \u2013\u00a0 user2350622 Feb 19 at 18:37\n\n1 Answer 1\n\nIf $X$ is a $m\\times n$ matrix with $n$ random vectors distributed identically as $\\mathcal{N}(\\mu,\\sigma^2 I_{m\\times m})$, and if the random vectors are independent then you can write the joint distribution of the vectors as $$p(x_1,x_2,\\cdots,\\ x_n)=\\prod_{i=1}^np(x_i)\\\\=\\frac{1}{(2\\pi)^{mn/2} \\sigma^{mn}}\\exp\\left(-\\frac{\\sum_{i=1}^n\\sum_{j=1}^m(x_{ji}-\\mu_{j})^2}{2\\sigma^2}\\right)$$ So, to find the MLE of $\\mu$ and $\\sigma^2$ find the simultaneous solutions of $$\\nabla_{\\mu}p(x_1,x_2,\\cdots,x_n)=0\\\\ \\frac{\\partial p(x_1,x_2,\\cdots,x_n)}{\\partial \\sigma^2}=0$$\n\nshare|improve this answer\nI solved the equations but I ended up getting a strange MLE for sigma^2. I got 1/2*variance of X. \u2013\u00a0 user2350622 Feb 19 at 19:07\nIf by variance you mean the sample variance of $X$, then it is fine. \u2013\u00a0 Samrat Mukhopadhyay Feb 19 at 19:16\nokay! It just seemed to be wired to me because usually MLE variance does not have a 1/2 in front of it \u2013\u00a0 user2350622 Feb 20 at 0:04\nIf you do the math, then you'll see that for the case where you have $m$ samples, a factor of $1/m$ is coming in front of the sample variance. \u2013\u00a0 Samrat Mukhopadhyay Feb 20 at 6:47\nyes but I tried in R and the variance of the samples should be really close to the true sigma. \u2013\u00a0 user2350622 Feb 24 at 1:57\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/99007/rate-of-convergence-of-series-of-squared-prime-reciprocals\nText:\nTake the 2-minute tour \u00d7\n\nIt is well known that $\\sum_{p \\text{ prime}} \\frac{1}{p}$ diverges, and in fact - it behaves like log of the harmonic series: $$ \\sum_{p \\le x} \\frac{1}{p} = \\log \\log x + O(1). $$ It is also well known that $\\sum\\limits_{p \\text{ prime}} \\frac{1}{p^2}$ converges. What is known about the rate? Letting $C = \\sum\\limits_{p \\text{ prime}} \\frac{1}{p^2}$, what can be said about $C - \\sum\\limits_{p \\le x} \\frac{1}{p^2}$?\n\nI am reading an article (a survey of Artin's Primitive Root Conjecture - which follows from the GRH). I am trying to understand what are the condition on functions $f_1\\le f_2$ tending to infinity in order that $$ \\sum_{f_1(x) \\le p \\le f_2(x)} \\frac{1}{p^2} = O\\left(\\frac{1}{\\log x}\\right). $$ Of course I can take $f_1(x) = \\log\\log\\log x$, $f_2(x) = \\log\\log x$, but I want the general conditions.\n\nshare|improve this question\nThe sum from $x$ to infinity of $1/p^2$ is bounded by the sum from $x$ to infinity of $1/n^2$ which, by comparison with the integral, is on the order of $1/x$. 29% accept rate - do you understand the value of accepting answers to your questions here? \u2013\u00a0 Gerry Myerson Jan 14 '12 at 23:20\n\n1 Answer 1\n\nup vote 6 down vote accepted\n\nLets rearrange the sum $C-\\sum_{p\\leq x}\\frac{1}{p^{2}}=\\sum_{p>x}\\frac{1}{p^{2}}$. Using integration by parts this is $$\\sum_{p>x}\\frac{1}{p^{2}}=\\int_{x}^{\\infty}\\frac{1}{t^{2}}d\\left(\\pi(t)\\right)=\\frac{\\pi(t)}{t^{2}}\\biggr|_x^\\infty+2\\int_{x}^{\\infty}\\frac{\\pi(t)}{t^{3}}dt.$$ Using the prime number theorem, that is the asymptotic for $\\pi(x),$ you can deduce that the quantity on the right hand side is $\\sim\\frac{1}{x\\log x},$ which is your rate of convergence.\n\nJust worth noting, this is exactly what we would expect. The tail of the sum over all integers has size $\\frac{1}{x}$, that is $\\sum_{n>x} \\frac{1}{n^2}\\sim \\frac{1}{x}$ and the primes occur with density $\\frac{1}{\\log n}$ around $n$, so we would expect the tail of the sum to be of size $\\frac{1}{x\\log x}$. Partial summation/integration allows to prove this.\n\nEdit: Replaced $\\asymp$ with $\\sim$, since as pointed out by Greg Martin in the comments, the Prime Number Theorem is strong enough to yield this/\n\nshare|improve this answer\nUsing the prime number theorem actually gives an asymptotic formula for the tail of the series, not just the order of magnitude, right? \u2013\u00a0 Greg Martin Jan 22 '12 at 10:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/136831/factorial-number-of-digits\nText:\nTake the 2-minute tour \u00d7\n\nIs there any neat way to solve how many digits the number $20!$ have? I'm looking a solution which does not use computers, calculators nor log tables, just pen and paper.\n\nshare|improve this question\nI suspect Stirling's approximation will help. \u2013\u00a0 David Mitra Apr 25 '12 at 15:43\nThe simplest way is just to compute $20!$. $20$ is small enough that this shouldn't take too much time (or paper). \u2013\u00a0 Chris Eagle Apr 25 '12 at 15:45\nSee \"D. FACTORIALS OF LARGE NUMBERS\" in groups.google.com/group/sci.math/msg/d12962e3af2c74b7 \u2013\u00a0 Dave L. Renfro Apr 25 '12 at 15:45\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAs a rough approximation, multiplying an $n$-digit number by an $m$-digit number yields a result with about $n+m$ digits. So the numbers from 2 to 9 are all 1-digit numbers. From 10 to 20 are all 2-digit numbers. That suggests we should have about 18 digits or so.\n\nWolfram|Alpha claims that $20! = 2.4 \\times 10^{18}$. Not far off! :-D\n\nshare|improve this answer\n(Exponents of more than one character require {} to render properly) \u2013\u00a0 The Chaz 2.0 Apr 25 '12 at 16:00\nApparently I fail basic math. If you actually count 2 for all of the 2-digit numbers, you come up with 28, which is quite a way out. sigh \u2013\u00a0 MathematicalOrchid Apr 25 '12 at 20:34\n@TheChaz Thanks for that... \u2013\u00a0 MathematicalOrchid Apr 25 '12 at 20:35\n\nI come from a background in computers, so here's my two cents. Taking the logarithm to the base 10 of n!. If the log comes out to be x, it is not hard to see that the number of digits must be the lowest integer greater than or equal to x, i.e, $floor(x)+1$. Now the question comes down to approximating the $log(n!)$ It is possible to prove by induction that n! lies between $(\\frac{n}{2})^n$ and $(\\frac{n}{3})^n$. Thus the log(n!) lies between $nlog(\\frac{n}{2})$ and $nlog(\\frac{n}{3})$. We can get a pretty tight bound if we used log tables for log(20/3), but as you have disallowed that, using the upper limit(which becomes log(10) = 1) will do quite nicely too. The answer comes to 20*log(10) = 20, which should tell you that the expected number of digit is about 19 or 20.(Since 20 is only the upper bound). And 19 happens to be the answer.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/105586/equality-of-integrals-of-differential-forms\nText:\nTake the 2-minute tour \u00d7\n\nI have two $(n-1)$-forms $\\omega_{1}$ and $\\omega_{2}$ on $\\mathbb{R}^n$ and a smooth function $g(x) \\colon \\mathbb{R}^n \\to \\mathbb{R}$ ($dg$ doesn't vanish anywhere) such that $dg \\wedge \\omega_1 = dg \\wedge \\omega_2$ holds. Let $M = \\{x \\in \\mathbb{R}^n \\mid g(x) = 0 \\}$. Is it true that $$ \\int\\limits_{M} \\omega_1 = \\int\\limits_{M} \\omega_2 $$\n\nshare|improve this question\nDid you try to show the result when $g(x)=x_n$? \u2013\u00a0 Davide Giraudo Feb 4 '12 at 11:02\nNo, but I considered difference $dg \\wedge (\\omega_1 - \\omega_2)$ so it is sufficient to show for $\\omega_2 = 0$. I have $dg(X) = 0$ for any $X$ that is tangent to $g(x) = 0$. Then I take $X_1,...,X_n$ such that $X_1,...,X_{n-1}$ are tangent to $g(x) = 0$ and so $dg \\wedge \\omega_1 (X_1,...,X_n) = \\pm dg(X_n) \\omega_1(X_1,...,X_n)$, but $dg(X_n) \\neq 0$ so $\\omega_1$ is zero on tangent bundle of $M$. \u2013\u00a0 Nimza Feb 4 '12 at 11:12\n$\\omega_1$ and $\\omega_2$ are closed? \u2013\u00a0 Paul Feb 4 '12 at 12:26\n$\\omega_1$ and $\\omega_2$ are arbitrary $(n-1)$-forms such that $dg \\wedge (\\omega_1 - \\omega_2) = 0$ \u2013\u00a0 Nimza Feb 4 '12 at 13:49\nTo the question is reduced to the next: why if the form $\\omega$ vanishes on tangent spaces of $M$ then $\\int_{M} \\omega = 0$? \u2013\u00a0 Nimza Feb 4 '12 at 17:24\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nConsidering $\\omega = \\omega_1 - \\omega_2$ we have to show that if $dg \\wedge \\omega = 0$ then $\\int_{M} \\omega = 0$.\n\n  1. $dg(X_p) = 0$ iff $X \\in T_{p}M$ because $dg(X_p) = \\langle \\nabla g(p), X \\rangle$.\n  2. Let $X^1,...,X^n$ be such that $X^1,...,X^{n-1}$ are from $T_pM$ and $X^n$ is transversal to $T_pM$. Then $$ 0 = dg \\wedge \\omega (X^1_p,...,X^n_p) = \\pm dg(X^n_p) \\omega(X^1_p,...,X^{n-1}_p) $$ but $dg(X^n_p) \\neq 0$ then $\\omega$ vanishes on tangent spaces to $M$, hence $\\int_{M} \\omega = 0$.\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/22243/what-is-the-smallest-cardinal-number-of-a-set-that-requires-the-axiom-of-choice/22250\nText:\nTake the 2-minute tour \u00d7\n\nLet C(x) be a formula belonging to the language of ZFC in which the variable \"x\" and no other variable occurs free. Suppose that (a sentence of this language equivalent to) the following statement, is provable in ZFC but not in ZF.\n\n\"There exists a non-empty set Q such that every element x of Q satisfies the formula C(x)\"\n\nQUESTION: What is the smallest cardinal number that such a set Q can (be proved in ZFC) to have?\n\nI know of no examples of such a set Q having a cardinal number less than 2^(2^k) where k is the cardinal number of the contnuum. Examples of such sets Q are the set of all uncountable sets of real numbers that are non-measurable in the sense of Lebesgue or that contain no perfect subset.\n\nshare|improve this question\nWhat about a set Q containing just one element which is a non-measurable subset of the reals? Do you mean the set of all x satisfying C(x)? \u2013\u00a0 Sergei Ivanov Apr 22 '10 at 20:14\nSergei, even if he does mean all x, then my answer still gives a one-element set. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:29\nBut your answer isn't sporting! \u2013\u00a0 Simon Thomas Apr 22 '10 at 20:42\nBut it is optimal...But seriously, I am interested in the projective version. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:54\n\n2 Answers 2\n\nYou probably won't like this, but the answer is cardinality 1.\n\nLet C(x) be the statement, \"x=0 and the Axiom of Choice holds\".\n\nZF doesn't prove that any x satisifes C(x), since it doesn't prove AC. If AC fails, then no x can have C(x). Thus, ZF+\u00acAC proves that no x has C(x).\n\nBut ZFC proves that C(0) holds, and so it proves that Q={0} is the desired set.\n\n\nThe set { x | C(x) } is an indicator set for AC, in the sense that it is either 0 or 1, depending exactly on whether AC holds. A similar trick works to construct indicator sets for any assertion.\n\nI have suggested that the question be focused on the possibility of projective statements C(x). A projective statement is one expressible in the language of second order number theory, with quantifiers over real numbers and natural numbers. Thus, the question would be whether there is a specific projective statement C(x) such that ZFC proves that Q = { x | C(x) } is nonempty, but ZF does not.\n\nThis version of the question is exactly equivalent to the question of whether ZFC is not conservative over ZF for projective sentences, since if there is a counterexample C(X), then the assertion $\\exists x C(x)$ is provable in ZFC but not ZF, and if $\\sigma$ is provable in ZFC but not in ZF, then the set {x | $\\sigma$} is ZFC provably all of the reals, but ZF is consistent with this set being empty.\n\nTherefore, the question amounts to: Is ZFC not conservative over ZF for projective statements?\n\nI think it is not, but I don't have a counterexample.\n\nMeanwhile, I can say that if one replaces ZF here with ZF+DC, looking at the difference between the full Axiom of Choice and the Axiom of Dependent Choices, rather than at the difference between full AC and no AC at all, then the answer is that it IS conservative. In this MO answer, I explained that ZFC is conservative over ZF+DC for projective sentences, and so if one replaces ZF with ZF+DC in the question, the answer would be no. But without DC, weird things can happen in the reals, and I'm not yet quite sure about it.\n\nshare|improve this answer\nIn this case, the formula asserting that there is such a nonempty Q is exactly equivalent to AC. You could replace AC in this argument with any statement whatsoever; what you get is a kind of indicator set for the truth of that statement. It is empty when the statement fails, and it is 1 when the statement holds. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:05\nI take this answer to show that you will want to revise your question. Probably it is natural to restrict the complexity of the statement C(x). For example, can there be a projective such C(x)? \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:22\nThis is a really cool answer. \u2013\u00a0 Harry Gindi Apr 22 '10 at 20:27\nThanks, Harry. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:33\n@Joel: I'm thinking about C(x) = \"x is a minimal uncountable ordinal\". Is it projective? \u2013\u00a0 Sergei Ivanov Apr 22 '10 at 20:55\n\nWilfrid Hodges has shown that it is consistent with ZF that there is an algebraic closure $L$ of the rational field $\\mathbb{Q}$ with no nontrivial automorphisms. Obviously $|Aut(L)\\smallsetminus \\{1\\}| = 2^{\\aleph_{0}}$.\n\nSee: W. Hodges, L\u00e4uchli's algebraic closure of $\\mathbb{Q}$. Math. Proc. Cambridge Philos. Soc. 79 (1976), no. 2, 289--297\n\nshare|improve this answer\nIs that rigidity due to the fact that there are less functions in his model than in the usual one? I imagine there is a bijection between his $L$ and the usual algebraic closure, if there is any sense one can talk about such a bijection... \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Apr 22 '10 at 20:10\nSimon, does this example lead to a projective C(x)? I guess not, since I think your L cannot be countable, as weird as that sounds, since if it were then the assertion that L is rigid would be Pi^1_1, and hence absolute to forcing extensions with AC for reals. Could you clarify this? \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:26\nI find this shocking and disturbing...so much so that I dug up the paper. It is available at math.uga.edu/~pete/Hodges76.pdf \u2013\u00a0 Pete L. Clark Apr 22 '10 at 21:50\n\u00abThe reader may well feel he could have bought Corollary 10 cheaper in another bazaar\u00bb Best comment in a paper EVAR. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Apr 22 '10 at 22:04\nYes, this is shocking! Joel is right: L is not countable in that model of ZF. The basic idea goes back to Plotkin who showed that given any countably categorical theory T you can find a model of ZF with an model M of T such that the only subsets of M that exist are the T-definable subsets of M. This doesn't directly apply to the algebraic closure of Q since ACF_0 is not countably categorical, but Hodges showed that ACF_0 is still nice enough for the basic idea to work... \u2013\u00a0 Fran\u00e7ois G. Dorais Apr 22 '10 at 22:14\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/133636/proof-of-the-area-of-a-right-triangle\nText:\nTake the 2-minute tour \u00d7\n\nProve that every right triangular region is measurable because it can be obtained as the intersection of two rectangles. Prove that every triangular region is measurable and its area is one half the product of its base and altitude.\n\nI'm supposed to prove the above statement from the following area axioms:\n\nWe assume that there exists a class of measurable sets in the plane and a set function $a$ whose domain is $M$ with the following properties:\n\n1) $a(S) \\geq 0$ for each set $S$ in $M$.\n\n2) If $S$ and $T$ are two sets in $M$ their intersection and union is also in $M$ and we have: $a(S \\cup T) = a(S) + a(T) - a(S \\cap T)$\n\n3)If $S$ and $T$ are in $M$ with $S \\subseteq T$ then $T \u2212 S$ is in $M$ and $a(T \u2212 S) = a(T) \u2212 a(S)$.\n\n4) If a set $S$ is in $M$ and $S$ is congruent to $T$ then $T$ is also in $M$ and $a(S) = a(T)$.\n\n5) Every rectangle $R$ is in $M$. If the rectangle has length $h$ and breadth $k$ then $a(R) = hk$.\n\n6) Let $Q$ be a set enclosed between two step regions $S$ and $T$ so that $S \\subseteq Q \\subseteq T$. If there is a unique number $c$ such that $a(S) \\leq c \\leq a(T)$ for all such step regions $S$ and $T$, then $a(Q) = c$.\n\nI can see from axiom 2 that the intersection of 2 rectangles is measurable, but I can't think of how to use that to get that the area of the intersection is $bh \\over 2$.\n\nshare|improve this question\nHint: the rectangles will not have parallel sides. Once you show that half of a rectangle is measurable, the other half will be too, and as both regions are congruent, the formula for the area will follow from 4 and 5 \u2013\u00a0 Barry Smith Apr 18 '12 at 21:39\n\n2 Answers 2\n\nLet $ABC$ be a right triangle, with right angle at $C$. Form two rectangles $R$ and $S$ as follows.\n\nRectangle $R$ is the natural one with $AB$ as a diagonal that splits $R$ into two halves, with $\\triangle ABC$ as one of the halves.\n\nRectangle $S$ has $AB$ as one side, and the side parallel to $AB$ passes through $C$.\n\nThe intersection of $R$ and $S$ is $\\triangle ABC$.\n\nTo decompose any triangle into two right triangles with uninteresting intersection, there is a natural construction. Be a little careful in describing the construction.\n\nshare|improve this answer\nWell, that's the first piece of the problem nicely done. \u2013\u00a0 Gerry Myerson Apr 19 '12 at 0:13\n\nFor the second piece of the problem, can you see that every triangle is the union of two right triangles?\n\nEDIT: For the last part of the problem, a right triangle is half a rectangle, so properties 2) and 5) should get you the formula for right triangles. Then as noted every triangle is a union of two right triangles, so property 2 and the result for right triangles should get you the result for all triangles.\n\nshare|improve this answer\nIf a base angle is obtuse, the triangle is also the difference of two right triangle. \u2013\u00a0 marty cohen Apr 19 '12 at 2:27\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/213374/group-homomorphisms-between-two-abelian-groups-with-different-kernel\nText:\nTake the 2-minute tour \u00d7\n\nDoes there exist two abelian groups $A,B$ with an epimorphism $f: A\\to B$, and two other abelian groups $A', B'$ along with an epimorphism $g: A'\\to B'$ such that $A\\cong A'$, $B\\cong B'$ and $ker\\,f \\not\\cong ker\\,g$? It seems to me that the groups must be infinite, since we have $B\\cong A/ker\\,f$ and $B'\\cong A'/ker\\,g$.\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet me reformulate the question: you want an abelian group $G$ with two subgroups $H, H'$ which are not isomorphic but such that the quotients $G/H, G/H'$ are isomorphic.\n\nThe smallest example is $G = C_2 \\times C_4, H = C_2 \\times C_2, H' = 1 \\times C_4$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/303939/planar-graph-number-of-faces\nText:\nTake the 2-minute tour \u00d7\n\nI need to determine the number of faces of a planar graph with $n$ vertices, $m$ edges and $k$ connected components. I was thinking of using Euler's formula $f=m-n+2$ but that is for a connected graph. Because I have $k$ components I was thinking $k$ times Euler formula, for each connected component.\n\nAny advice or help is welcome.\n\nshare|improve this question\nMy advice would be to draw a bunch of examples with, say, three connected components, and calculate $f-m+n$ for each of them, and make a conjecture, and prove it. If you get stuck along the way, come back, tell us what you've done, and someone will help. \u2013\u00a0 Gerry Myerson Feb 14 '13 at 12:34\nIn the Euler's formula for a connected planar graph $f-m+n=2$, one of the face is the exterior face. If you only count the inner face, it is $f_{inner}-m+n=1$. If you have $k$ connected component, you get $f_{inner}-m+n=k$. Add back the exterior face, you get $f-m+n=k+1$. \u2013\u00a0 achille hui Feb 14 '13 at 13:01\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nEuler's formula can be extended $$ V+F = E +C+\\chi, $$ where $C$ is the number of components and $\\chi$ is Euler's characteristic of the surface where the graph lives on. If you deal with $k$-regular planar graphs the mean face degree obeys: $$ \\frac{\\sum f_k}{F}=\\frac {2k}{k -2} \\left( 1-\\frac{1+\\chi}{F}\\right) $$ (see here)\n\nshare|improve this answer\n\nWe will count the outer face as its own face. So a cycle has two faces, for example.\n\nThe idea is to take each connected component $C_1$, $C_2$, etc., and connect them by drawing a bridge between $C_1$ and $C_2$, $C_2$ and $C_3$, etc. We will thus add $n-1$ edges (the restriction is if you contract the connected components we had previously, you must form a tree).\n\n  \u2022 $F = f$ remains the same.\n  \u2022 $V = n$ since no vertices were added.\n  \u2022 $E = m + k - 1$ since $k-1$ edges were added.\n\nNow apply Euler's formula.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/92306/partitions-in-which-no-part-is-a-square?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI asked a similar question earlier about partitions, and have a suspicion about another way to count partitions.\n\nIs it true that the number of partitions of $n$ in which each part $d$ is repeated fewer than $d$ times is equal to the number of partitions of $n$ where no part is a square?\n\nI tried this out for $n=2,3,4$, and so far it checks out. Is there a way to prove it more generally?\n\nshare|improve this question\nThe natural thing to do in such a case is to write generating functions for the two cases and see if they look similar. Even if you can't decide, computing a number of terms of the series is much faster than testing cases by hand. Did you try? \u2013\u00a0 Marc van Leeuwen Dec 17 '11 at 19:04\n\n2 Answers 2\n\nup vote 7 down vote accepted\n\nAs mentioned in the comment above, generating functions are the standard tool for proving such statements. If you can write down the proper generating functions, proofs sometimes just fall right out.\n\nLet $S = \\{ \\ell^2 \\;|\\; \\ell \\in \\mathbb{N} \\}$ be the set of perfect squares.\n\nIn the following generating function: the coefficient of $x^k$ is the number of partitions of $k$ which do not involve $d$ or more copies of $d$ for each $d$.\n\n$$ \\prod\\limits_{d=1}^\\infty \\left(\\sum\\limits_{j=0}^{d-1} x^{jd}\\right) =$$\n\n$$(1+x^2)(1+x^3+x^6)(1+x^4+x^8+x^{12})\\cdots (1+x^d+x^{2d}+\\cdots+x^{d(d-1)}) \\cdots $$\n\n$$=((1-x^2)^{-1}-x^{2^2}(1-x^2)^{-1})((1-x^3)^{-1}-x^{3^2}(1-x^3)^{-1})\\cdots ((1-x^k)^{-1}-x^{k^2}(1-x^k)^{-1}) \\cdots $$\n\n$$=\\left(\\frac{1-x^{1^2}}{1-x^1}\\right)\\left(\\frac{1-x^{2^2}}{1-x^2}\\right)\\left(\\frac{1-x^{3^2}}{1-x^3}\\right)\\cdots \\left(\\frac{1-x^{k^2}}{1-x^k}\\right) \\cdots $$\n\n$$=\\prod\\limits_{k = 1}^\\infty \\frac{1-x^{k^2}}{1-x^k} = \\prod\\limits_{k = 1}^\\infty \\frac{\\frac{1}{1-x^k}}{\\frac{1}{1-x^{k^2}}} =\\frac{\\prod\\limits_{k = 1}^\\infty \\frac{1}{1-x^k}}{\\prod\\limits_{k=1}^\\infty\\frac{1}{1-x^{k^2}}} = \\prod\\limits_{k\\in\\mathbb{N}-S} \\frac{1}{1-x^k}$$\n\nIn the final generating function: the coefficient of $x^k$ counts the number of partitions not involving perfect squares.\n\nEdit For a bit more about generating functions here is a link to another question I answered: partitions and generating functions\n\nshare|improve this answer\nThank you Bill, this is a great answer. \u2013\u00a0 Noel Dec 18 '11 at 6:18\n@Bill: In the last line, wouldn't you prefer just cancelling the terms $1-x^{k^2}$ against their counterparts in the denominator right away? \u2013\u00a0 Marc van Leeuwen Dec 18 '11 at 17:13\n@MarcvanLeeuwen I guess that would have been a bit more efficient. Oh well. :) Since it doesn't make a big difference, I'll just leave it alone. \u2013\u00a0 Bill Cook Dec 18 '11 at 18:46\n\nNow that you have a generating function proof (so you know the result is true), you may wonder if you can actually map partitions of one kind bijectively to those of the other kind. Motivated by this other question, the following idea comes to mind: starting with a partition in which no part $d$ is repeated $d$ times or more, in order to get rid of square parts, break any part $x^2$ into $x$ parts equal to $x$, and repeat. Since there were no parts equal to $1$ this terminates, producing a partition without square parts.\n\nWe must show that every partition of without square parts is produced exactly once from a partition in which no part $d$ is repeated more $d$ times or more. We can treat non-squares separately: if $k>1$ is a non-square, then the parts in the original partition that would have been broken up eventually into parts of size $k$ are those of size $k$, $k^2$, $k^4$, $k^8$, ..., $k^{2^i}$,... Supposing the multiplicity of $k$ in the final partition is $m$, we must decompose $$ mk=c_0k+c_1k^2+c_2k^4+\\cdots+c_ik^{2^i}+\\cdots \\quad\\text{with $c_i<k^{2^i}$ for all $i\\in\\mathbf N$} $$ But this is uniquely possibly by the expression of $mk$ in the mixed radix number system with place values $1,k,k^2,k^4,k^8,\\ldots$ (the initial $1$ is only there to have a number system capable of expressing all natural numbers; $mk$ being a multiple of $k$ has digit $0$ on this least significant position.) Concretely one can find the $c_i$ either in order of increasing $i$ by taking remainders modulo the next $k^{2^{i+1}}$, or by decreasing $i$ by allocating the largest chunks first and then using smaller chunks for what is left of $mk$.\n\nshare|improve this answer\nThanks for this other argument, Marc van Leeuwen. \u2013\u00a0 Noel Dec 19 '11 at 7:05\nSee Wilf's Lectures on Integer Partitions for more on bijections like this. \u2013\u00a0 David Bevan Dec 19 '11 at 8:56\n@David Bevan: Thank you for the reference. So apparently this bijection, as well as the one in the question I linked to, are special cases of a general construction of partition maps proved to be bijective by Kathleen O'Hara. \u2013\u00a0 Marc van Leeuwen Dec 21 '11 at 14:26\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/115544/integration-involving-partial-fractions\nText:\nTake the 2-minute tour \u00d7\n\nI have to integrate the following and I was having trouble with it because I am pretty new to the concept of using partial fractions. I did as much as I could and I need help in moving forward:\n\n\nI did some long division and got:\n\n\nFactored the denominator:\n\n\nand got the following:\n\n\nNow I think that I should have something like this, but I'm not sure:\n\n\nWould appreciate any help. Thanks.\n\nshare|improve this question\nYour error is only in the set-up. Because of the quadratic denominator in the first partial fraction, you need a linear numerator, $\\frac{A+Dx}{x^2}$. Alternatively, use the set-up given by Pete Clark. \u2013\u00a0 Arturo Magidin Mar 2 '12 at 3:59\nI think the above comment is most helpful. In general, should the numerator be a polynomial of one degree lower than the denominator? Should we have Ax+B/(x^2) + C/(x+1) + Dx+E/(x^2-x+1)? \u2013\u00a0 Ziggy Jul 16 '12 at 18:54\n\n2 Answers 2\n\nThe polynomial $x^2 - x + 1$ has discriminant $(-1)^2 - 4(1)(1) = -3 < 0$, so it has no real roots. According to the partial fractions recipe, there are unique real constants $A,B,C,D,E$ such that\n\n$$\\frac{2x^2+1}{x^5+x^2} = \\frac{A}{x} + \\frac{B}{x^2} + \\frac{C}{x+1} + \\frac{Dx+E}{x^2-x+1}$$\n\nfor all $x \\in \\mathbb{R}$. In other words, you did not postulate a sufficiently general expression for the partial fractions decomposition, so -- except in the unlikely event that $A = D = 0$ -- you will not be able to achieve a decomposition in the form you have given.\n\nI happened to cover partial fractions quite recently in a class I am teaching this semester. A student asked me why you need a term like $\\frac{A}{x}$. My answer at the time was to think of taking a sum which did have a $\\frac{A}{x}$ term, put it over a common denominator, and then apply a partial fractions decomposition: we would then be saying that there are some real constants $\\alpha,\\beta,\\gamma,\\delta$ such that\n\n$$\\frac{A}{x} + \\frac{B}{x^2} + \\frac{C}{x+1} + \\frac{Dx+E}{x^2-x+1} = \\frac{\\alpha}{x^2} + \\frac{\\beta}{x+1} + \\frac{\\gamma x + \\delta}{x^2-x+1},$$\n\nwhich seems unlikely. Actually I think I could say it a bit better: a general proper rational function with denominator $x^5+x^2$ is of the form\n\n$$\\frac{ax^4 + bx^3 + cx^2 + dx + e}{x^5+x^2},$$\n\nthus there is in a sense a five parameter family of such things. Therefore whatever your partial fractions decomposition should be, it should also have five parameters $A,B,C,D,E$. That's a more convincing answer as to why your proposed expansion is (very probably) not achievable -- isn't it? -- you are trying to express a five parameter family of functions using only three parameters: no good.\n\nThis business with \"parameters\" can be made rigorous using the language of linear algebra, and in fact dimension-counting can be used to give a proof of the existence and uniqueness of the partial fraction decomposition. See this note which I wrote just a few days ago.\n\nshare|improve this answer\nPete, my understanding of mathematics is very elementary compared to yours so please bear with me on this; I used this expression $\\frac{A}{x} + \\frac{B}{x^2} + \\frac{C}{x+1} + \\frac{Dx + E}{x^2 -x +1}$ and got the following $x^5(A+C+D)+x^4(B-C+D+E)+x^3(C+E)+Ax^2-Bx$ Am I on the right path? If so, how do I equate these 5 expressions to $2x^2+1$ \u2013\u00a0 user754950 Mar 2 '12 at 4:47\n@user754950: (i) You have an $x$ too many; you can factor out one $x$ and cancel it with the $x^3$ that you undoubtedly have in your denominator. The least common denominator is $x^2(x+1)(x^2-x+1)$, not $xx^2(x+1)(x^2-x+1)$. It's easier if you leave the products indicated and then you use Heaviside's cover-up method. You have $Ax(x+1)(x^2-x+1) + B(x+1)(x^2-x+1) + Cx^2(x^2-x+1)+(Dx+e)x^2(x+1) = 2x^2+1$. Plug in $x=0$ to get the value of $B$; plug in $x=-1$ to get $C$; etc. \u2013\u00a0 Arturo Magidin Mar 2 '12 at 5:06\nYou have an extra factor of $x$ - you want to have $x^4(A+C+D)+$ etc. Then you compare coefficients to those in $2x^2+1$, giving you five equations for the five unknowns $A,B,C,D,E$. \u2013\u00a0 Gerry Myerson Mar 2 '12 at 5:08\nThis is a good answer, but I had to read it two or three times before I was convinced of its merit. I'm glad I did though! :) \u2013\u00a0 Ziggy Jul 16 '12 at 19:03\n\nAs a rule of thumb, you should remember that the number of partial fractions that you need is the same as the degree of the polynomial appearing in the denominator. Therefore consider an expression like\n\n\nThus repeated roots need extra terms (the presence of the $\\dfrac{1}{x}$ and the $\\dfrac{1}{x^2}$) and if the denominator of the partial fraction is an irreducible degree $2$ polynomial then you will need a linear factor on top.\n\nWhy should you need $5$ partial fractions for a degree $5$ denominator? Intuitively, the reason is that you want to get a system that has the same number of equations as unknowns. When you set up the equations to solve for the coefficients, a degree $5$ polynomial gives you $5$ equations, so you want enough coefficients to ensure that there is one and only one solution.\n\nEdit: to answer the question in the comment, let me give you an example of why the extra partial fractions are necessary:\n\nConsider the function\n\n\nLet's try to do a partial fractions decomposition. If I tried to write\n\n$$\\frac{3x+2}{x^2(x+1)} = \\frac{A}{x^2} + \\frac{B}{x+1}$$\n\nThen this gives me the equation $$\\frac{3x+2}{x^2(x+1)} = \\frac{Bx^2 + Ax + A}{x^2(x+1)}$$\n\nWhich would imply that $B= 0$, $A= 2$ and $A=3$ (Notice that I have three equations and only two constants $A$ and $B$). This is, of course, impossible. This means that I need to add in another term when I write down the partial fraction decomposition in the first place. I can get around this by adding in an extra term for each repeated root. The correct equation is:\n\n\nNow in this case it is possible to determine $A$, $B$, $C$.\n\nSee also Pete's more general answer- I was writing this as he finished his edit.\n\nshare|improve this answer\nHow did you get this: $\\frac{A}{x} + \\frac{B}{x^2}$? I only had 3 denominators. \u2013\u00a0 user754950 Mar 2 '12 at 3:40\nIn each fraction, the degree of the numerator can be up to one less than the degree of the denominator. So the factor with $x^2$ in the denominator can be of the form $$\\frac{Ax+B}{x^2} = \\frac{Ax}{x^2}+\\frac{B}{x^2} = \\frac{A}{x}+\\frac{B}{x^2}.$$ You need to allow the possibility of a degree 1 numerator. \u2013\u00a0 Arturo Magidin Mar 2 '12 at 4:01\n\"can\" be up to one less? Why not just leave it in the form Ax+B/(x^2)? \u2013\u00a0 Ziggy Jul 16 '12 at 19:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204659/finding-the-winning-probability-of-the-game\nText:\nTake the 2-minute tour \u00d7\n\nSuppose in an independent game which has 2 players, player 1 and player 2, the probability of player 1 to win each game is $r$. To be the overall winner of the game, one of the players needs to win 2 more games than the other. What is the probability that player 1 will be the overall winner?\n\nMy sketch to solve the question: Note that to be the overall winner, one player should have won 2 games consecutively. So if player 1 is the winner, the outcome should either a draw, i.e. each player wins a game consecutively or player one won 2 games consecutively. But I am not sure how to start calculating.\n\nshare|improve this question\nJust to clarify, they play a game, say head or tail, until one of them has a $2$ games lead onto the other? \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 0:54\nI am not sure as in a head tail game, it is possible to have 2 winner at the same time, i think may be consider a simplier case first, i.e.each game always have one winner \u2013\u00a0 abc Sep 30 '12 at 1:01\nWhat is the tie probability? \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:07\n\n2 Answers 2\n\nLet $a$ be the probability that the first player (ultimately) wins if the two players are tied in wins. Let $b$ be the probability that she wins if she is $1$ ahead. And let $c$ be the probability she wins if she is $1$ behind. We have the equations $$\\begin{align}a&=rb+(1-r)c,\\\\ b&=r+(1-r)a, \\\\ c&=ra.\\end{align}$$\n\nSolve the system of linear equations.\n\nshare|improve this answer\nWould you mind briefly explain how you get the equations \u2013\u00a0 Mathematics Oct 9 '12 at 14:45\nWe justify the first equation. Suppose the two are tied. Player $1$ can ultimately win if (i) she wins next game and ultimately wins or (ii) she loses next game but ultimately wins. For (i), the probability she wins next game is $r$, and given that, she will be $1$ ahead, and the probability she ultimately wins is by definition $b$. So the probability of (i) is $rb$. For (ii), the probability she loses the next game is $1-r$, and given that, she will be $1$ behind, so by definition the probability she ultimately wins is $c$. So the probability of (ii) is $(1-r)c$. (Continued $\\dots$) \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 14:56\nNow we add the probabilities of (i) and (ii). We get $a=rb+(1-r)c$. The other two equations are obtained the same way, except that for the third, if Player $1$ is $1$ behind and wins (probability $r$, they are tied, but if she loses the game, then it's all over, Player $1$ has lost. So probability Player $1$ ultimately wins if she is $1$ behind is $ra$. \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 15:01\nI did the problem this way because it is a general approach to similar problems. A system can be in any one of several states. In our case there are $3$ states (tied, $1$ ahead, $1$ behind). There are various transition probabilities between states. We form a matrix with these transition probabilities, and multiplying by that matrix lets us trace out the evolution of the system. If you are familiar with Linear Algebra, you will note we found an eigenvector of the matrix with eigenvalue $1$. \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 15:12\nWhat a gorgeous solution, Thank you very much. \u2013\u00a0 Mathematics Oct 9 '12 at 15:23\n\nThe probability player 1 wins the first two games is $r^2$ while the probability player 2 wins the first two is $(1-r)^2$; otherwise they start again.\n\nSo the probability player 1 wins the first two games given that either of the players does is $\\dfrac{r^2}{r^2 + (1-r)^2}$ and this is therefore the probability overall that player 1 wins overall.\n\nshare|improve this answer\nSituation is not that clear, as mentionned in a comment, the games can tie... \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:04\n@Jean-S\u00e9bastien: if that was a possibility then the question could not be answered without knowing the probability of player 2 winning an individual game. abc's comment says \"each game always has one winner\" \u2013\u00a0 Henry Sep 30 '12 at 1:08\nyes right, he said that he could consider a simpler case. I asked him to specify what is the Tie probability, or player 2's \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:11\n@Jean-S\u00e9bastien: The probability of an overall tie is $0$. \u2013\u00a0 Brian M. Scott Sep 30 '12 at 1:11\nhow do you get that form? \u2013\u00a0 abc Sep 30 '12 at 1:23\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/45618/probability-of-market-movement-trends\nText:\nTake the 2-minute tour \u00d7\n\nIf you imagine a scale from -100 to 100, if the market has moved up from 0 to 40, what is the probability is will continue to 100?\n\nThere is a 50-50 chance to move up or down from 0, but what is the probability of moving to 100 when it has already moved to 40?\n\nThis may be a simple question, but I am struggling! Can someone share the the algorithm that solves this problem?\n\nIs the answer 70%, ie. if at 0 it is 50-50 to go up or down, if it moves to 40 there is 70% chance it will rise to 100 and a 30% chance it will not?\n\nshare|improve this question\nIt depends on which model you choose for the stockmarket. For example the simplest model would be the binomial model ( en.wikipedia.org/wiki/Binomial_options_pricing_model ) \u2013\u00a0 Listing Jun 15 '11 at 22:03\nWow... that is complicated! Thank you though. Is there some simplier answer? Maybe the mention of the stockmarket made it more complex than it need to be. \u2013\u00a0 user12170 Jun 15 '11 at 22:20\nDo a search on \"stochastic calculus\" to see how truly bad things can get when transitioning from discrete models, such as the binomial model, to continous models. \u2013\u00a0 ItsNotObvious Jun 15 '11 at 22:41\nThank you. What if this was a straight case of up or down movement, not stock market movement.... this is complicating things... lets just imagine a straight up or down. \u2013\u00a0 user12170 Jun 15 '11 at 22:42\n\n2 Answers 2\n\nIt's a well established 'empirical fact' that there is no significant autocorrelation in market returns. That is, knowing that the market moved up in the last period provides no information about what it will do in the next period.\n\nSo the answer to your question (as backed up by a lot of data) is that it is still 50/50 whether the market goes up or down next, no matter what just happened.\n\nYou haven't really asked a mathematical question, which is why I haven't give you a mathematical answer.\n\nshare|improve this answer\nThank you Chris... your logic makes sense to me. \u2013\u00a0 user12170 Jun 16 '11 at 5:15\n\nIf (and this is a big if) you are considering a symmetric $\\pm1$ random walk or a driftless Brownian motion starting from $x=40$ and you are wondering about the probability $u(x)$ that it hits $x_1=100$ before hitting $x_0=-100$, then indeed the answer is $$ u(x)=\\frac{x-x_0}{x_1-x_0}=70\\%. $$ Briefly, an elementary method in the random walk case is to compute $u(x)$ for every integer starting point $x$ between $x_0$ and $x_1$. For every such $x$, one has $50\\%$ chances that the first step is to $x+1$ and $50\\%$ chances that the first step is to $x-1$, and from there, one looks for the probability $u(x\\pm1)$ to hit $x_1$ before $x_0$. Hence, $u(x)=\\frac12(u(x+1)+u(x-1))$.\n\nThis means that $x\\mapsto u(x)$ is a straight line on the integer interval $[x_0,x_1]$. Obviously, $u(x_0)=0$ and $u(x_1)=1$ hence $u(x)$ is as written above.\n\nA slightly more advanced method is to consider the position $X_n$ of the random walk at time $n\\wedge\\tau_0\\wedge\\tau_1$ where $\\tau_0$ is the first hitting time of $x_0$ and $\\tau_1$ is the first hitting time of $x_1$. This means that the random walk performs equiprobable independent $\\pm1$ steps and that one stops it as soon as it hits $x_0$ or $x_1$. Then $(X_n)$ is a bounded martingale hence its expectation does not depend on $n$. Now $X_0=x$, $X_n\\to x_1$ on $S=[\\tau_1<\\tau_0]$, $X_n\\to x_0$ on $[\\tau_0<\\tau_1]=S^c$, and one gets $$ x=X_0=\\lim\\limits_{n\\to\\infty}E(X_n)=E(\\lim\\limits_{n\\to\\infty}X_n)=x_0P(S^c)+x_1P(S). $$ Since $P(S)+P(S^c)=1$, this yields the result.\n\nIn the Brownian motion case, one can still use the idea of the second method, replacing finite differences by a differential operator: one gets that $u(x_0)=0$, $u(x_1)=1$ and $u''(x)=0$ for every real number $x$ in the interval $(x_0,x_1)$. This means that $u$ is affine in this case as well hence $u(x)$ is given by our first displayed formula, where now the argument $x$ is a real number.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/297513/proof-of-the-pumping-lemma-for-context-free-languages\nText:\nTake the 2-minute tour \u00d7\n\nI have a doubt concerning the proof of the pumping lemma for context-free languages. The pumping lemma for context-free languages is stated as follows:\n\nIf $A$ is a context-free language, then there exists a number $p$ (the pumping length) where, if $s$ is any string in $A$ whose length is at least $p$, then $s$ can be divided into five parts $s = uvxyz$ satisfying the conditions:\n\n  1. for every $i\\geq 0$, $uv^ixy^iz \\in A$,\n  2. $|vy|>0$, and\n  3. $|vxy| \\leq p$\n\nThe proof is as follows:\n\nLet $G$ be a context-free grammar for the context-free language $A$. Let $b$ be the maximum number of symbols on the right side of a rule. Thus, in any syntactic tree using this grammar, a node can have at most $b$ children. Therefore, if the height of the syntactic tree is at most $h$, the pumping length of the generated string is at most $b^h$. Reciprocally, if a generated string has length at least $b^h+1$, each of its syntactic trees must have a height of at least $h+1$.\n\nLet $|V|$ be the number of variables (non-terminal symbols) of $G$. Let $p$, the pumping length, be $b^{|V|} + 1$. Now, if $s$ is a string in $A$ and its length is $p$ or more, its syntactic tree must have a height of at least $|V|+1$.\n\nTo see how to pump any of these strings $s$, let $\\tau$ be one of its syntactic trees which has the least number of nodes. We know that $\\tau$ has height, at least, $|V|+1$, therefore it must contain a path from the root to a leaf of length at least $|V|+1$. This path has at least $|V|+2$ nodes, one in a terminal symbol and the other ones in variables. So, this path has at least $|V|+1$ variables. By the pigeonhole principle, some variable $R$ appears more than once in this path. Let $R$ be a variable that repeats among the $|V|+1$ lowest variables in this path.\n\nThen, the proofs for conditions 1, 2 and 3 are shown. I won't transcribe the proofs for condition 1 and 2, because I understood them. My problem is with condition 3:\n\nTo obtain condition 3, we have to be sure that $vxy$ has length at most $p$. In the syntactic tree for $s$, the upper occurrence of $R$ generates $vxy$. We chose $R$ such that both occurrences are among the $|V|+1$ lower variables in the path, and we chose the longest path in the tree, so the subtree where $R$ generates $vxy$ has height at most $|V|+1$. A tree with this height can generate a string of length at most $b^{|V|+1} = p$.\n\nI'm confused about the last paragraph. Initially, it chooses the pumping length to be $b^{|V|} + 1$, and it concludes that the height of every syntatic tree of $s$ with $|s| \\geq p$ is at most $|V|+1$. However, afterwards, it concludes that, since the subtree where $R$ generates $vxy$ has height at most $|V| + 1$, the string generated by this subtree has length at most $b^{|V|+1} = p$. But isn't $p = b^{|V|}+1$?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThere does appear to be an error in the argument. It can be fixed by taking $p$ initially to be $b^{|V|+1}$: we may assume that $b>1$ (as otherwise the language is finite and therefore regular), so $b^{|V|+1}\\ge 2b^{|V|}\\ge b^{|V|}+1$, and we can still argue that a syntactic tree for $s$ must have height at least $|V|+1$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/39331/how-to-replace-multiple-variables-at-once/39337\nText:\nTake the 2-minute tour \u00d7\n\nI would like to make a replacement \"c1 C1 -> F1, c2 C2-> F2....\" such that the expression like this \"c1 C1 c2 C2 c3 C3 c4 C4\" becomes \"F1 F2 F3 F4\".\n\nI used the standard replacement method: c1 C1 c2 C2 c3 C3 c4 C4 /. {c1 C1 ->F1, c2 C2 -> F2, c3 C3-> F3, c4 C4-> F4}. But mathematica only gives \"F1 c2 C2 c3 C3 c4 C4\", it only replace the first product.\n\nWhat is the reason this replacement does not work? How could I make such a replacement at once?\n\nThanks a lot.\n\nshare|improve this question\nuse //. instead of /. \u2013\u00a0 belisarius Dec 24 '13 at 3:08\nIt works! Thanks a lot! In fact, I used /. for the multiple variables replacement before but never have problems. May I ask why this does not work this time? \u2013\u00a0 skippyho Dec 24 '13 at 3:12\nCheck out the help files for ReplaceAll and ReplaceRepeated \u2013\u00a0 bill s Dec 24 '13 at 4:49\nSome of the discussion here is related. There are probably other questions where issues related to matching subexpressions of Plus and Times are discussed. \u2013\u00a0 Michael E2 Dec 24 '13 at 5:16\nadd comment\n\n1 Answer\n\nWhen it's not more complicated than your example, I do the replacement in the form\n\nc1 C1 c2 C2 c3 C3 c4 C4 /. {C1 -> F1 / c1, C2 -> F2 / c2, C3 -> F3 / c3, C4 -> F4 / c4}\n\nwith simplified patterns that avoid tricky issues of pattern-matching.\n\nThe trouble is that the FullForm of c1 C1 is Times[c1, C1] which on the face of it doesn't exactly match the FullForm of c1 C1 c2 C2 c3 C3 c4 C4, which is\n\nTimes[c1, C1, c2, C2, c3, C3, c4, C4]\n\nBut the pattern-matcher does match them and replaces only a subsequence of the arguments of Times. But since the Times expression has matched already, further rules are not applied. We're lucky (as users) that it matches once, but unlucky that it doesn't match repeatedly. That's why ReplaceRepeated (//.) works: it keeps applying the rules until there are no more matches. First rule will be applied the first time but not on subsequent tries since it will no longer match; and second on the second try, etc.\n\nshare|improve this answer\nNice explanation and recommendations! \u2013\u00a0 belisarius Dec 24 '13 at 13:31\nThanks a lot for such a nice explanation!! \u2013\u00a0 skippyho Dec 25 '13 at 6:01\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/336429/in-this-cumulative-distribution-function-am-i-finding-the-wrong-term\nText:\nTake the 2-minute tour \u00d7\n\nQuestion I was given: Let V be a uniform random variable distributed over the interval (0,1). Let $\\ X = \\frac{1}{\\sqrt(U)}$. What is the cumulative distribution function and probability density function of X?\n\nI understand the basic concept here behind cumulative distribution functions and probability density functions. What's throwing me off here is the additional parameter saying that V is a uniform random variable.\n\nIs the cumulative distance function just: $\\ \\int\\limits_0^1 \\frac{1}{\\sqrt(V)}dV $ which would then just equal 2?\n\nThen the prob dens function would be: $$ \\frac{1}{\\sqrt(V)}-----0<V<1 $$ $$ 0------otherwise $$ This seems too simple to me to be the correct answer though. Am I missing something? Am I finding the cumulative distance function of V rather than of X?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nWe find the cumulative distribution function $F_X(x)$ of $X$. So we want to find $\\Pr(X\\le x)$.\n\nIf $x\\le 1$, then $F_X(x)=0$. For since $0\\lt U\\lt 1$, it is impossible for $\\dfrac{1}{\\sqrt{U}}$ to be $\\le 1$.\n\nNow we find $F_X(x)$ for $x\\gt 1$.\n\nWe have $X\\le x$ if and only if $\\dfrac{1}{\\sqrt{U}}\\le x$. Flip it over. So $X\\le x$ if and omly if $\\sqrt{U}\\ge \\dfrac{1}{x}$, that is, if and only if $U\\ge \\dfrac{1}{x^2}$.\n\nBut $\\Pr\\left(U\\ge \\dfrac{1}{x^2}\\right)=1-\\Pr\\left(U\\le \\dfrac{1}{x^2}\\right)$. Since $U$ is uniform, this is simply $1-\\dfrac{1}{x^2}$. Thus for $X\\gt 1$, $$F_X(x)= 1-\\frac{1}{x^2}.$$\n\nFor the density function $f_X(x)$, differentiate the cdf.\n\nshare|improve this answer\nWhich would just yield 2/X^3 for X>1 and 0 otherwise? \u2013\u00a0 chrisbster Mar 21 '13 at 2:24\nAnd thank you - that clarification was fantastic! \u2013\u00a0 chrisbster Mar 21 '13 at 2:24\nYou are welcome. Yes, the density function (for $x\\gt 1$) is $\\frac{2}{x^3}$. \u2013\u00a0 Andr\u00e9 Nicolas Mar 21 '13 at 2:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/17255/counting-colored-rook-configurations-in-the-cube-when-is-it-even?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nInformal Statement\n\nIn the $n\\times n \\times n$ grid, we can places rooks (those from chess) such that no two rooks can attack each other. One way to achieve this is to place a rook in position $(i,j,k)$ if and only if $i+j+k=0\\mod n$. In general, there are \"many\" ways to do this.\n\nEach such \"attack-free\" rook position can be colored with $c$ colors. When we fix an $i$, we can then count the colors in the matrix $(i,.,.)$, and can do similarly for each $j$ and $k$. Call this set of tuples of colors-counts the \"color profile\". For each color profile, there is either an even or odd number of colored rook positions that achieve it. I want to know the largest $c$ such that all color profiles have an even number of colored rook positions achieving it. In particular, I want to say that $c=\\omega(n)$. This question came up in some complexity theory research, but the question seems interesting in its own right.\n\nFormal Statement\n\nDefine $[n]$ to be the set ${1,\\ldots, n}$, and define $[n]^3=[n]\\times[n]\\times[n]$. Define a $c$-coloring of a set $S\\subseteq[n]^3$ to be a function $C:S\\to[c]$. We can say that this is a $c$-coloring of $[n]^3$ with the convention that $C(i,j,k)=0$ for $(i,j,k)\\notin S$. A $c$-coloring $C$ induces a color profile $P$, which is a function from $P:[n]\\times[3]\\times[c]\\to[n]$, via the rules\n\n  \u2022 $P(i,1,c)$ is the number of $(j,k)\\in[n]^2$ such that $C(i,j,k)=c$.\n\n  \u2022 $P(j,2,c)$ is the number of $(i,k)\\in[n]^2$ such that $C(i,j,k)=c$.\n\n  \u2022 $P(k,3,c)$ is the number of $(i,j)\\in[n]^2$ such that $C(i,j,k)=c$.\n\nwhere we keep in mind the convention above on $(i,j,k)\\notin S$.\n\nCall a set $S\\subseteq [n]^3$ to be a rook set, if\n\n  \u2022 for all $i,j\\in[n]$, there is exactly one $k\\in[n]$ such that $(i,j,k)\\in S$\n\n  \u2022 for all $j,k\\in[n]$, there is exactly one $i\\in[n]$ such that $(i,j,k)\\in S$\n\n  \u2022 for all $i,k\\in[n]$, there is exactly one $j\\in[n]$ such that $(i,j,k)\\in S$\n\nLet a colored rook set $C_S$ correspond the coloring $C$ of a rook set $S$.\n\nDefine $N(P)$ to be the number of colored rook sets $C_S$ that induce the color profile $P$.\n\nThe question is:\n\nFor each fixed $n$, what is the largest $c$ such that for all color profiles $P$, $N(P)\\equiv 0\\mod 2$? In particular, is the largest $c$ asymptotically $\\omega(n)$?\n\nWhat I know\n\nIt should be clear that this problem can be defined analogously in any dimension, and I'm interested in this more general question. I state it with $d\\ge3$ because I can solve the $d=2$ case exactly. In particular\n\nFor each $n$, for any $c\\le n-1$, and any color profile $P$ on grid $[n]^2$, $N(P)\\equiv 0 \\mod 2$. For $c\\ge n$, there are profiles $P$ where $N(P)\\equiv 1\\mod 2$.\n\nThis can be proven by exhibiting a bijection between colored rook sets (which in d=2 are just permutation matrices). Specifically, using the pigeonhole principle $c\\le n-1$ implies that there are two rooks with the same color. If they were at positions $(i,j)$ and $(i',j')$, then we replace them with the rooks of the same color at positions $(i,j')$ and $(i',j)$. (Of course, one needs to make this well-defined to ensure a bijection.)\n\nPossible Methods\n\nI see two possible methods of proof\n\n  \u2022 generalize the above bijection proof to the 3-dimensional case\n\n    \u2022 I don't know how to use the pigeonhole principle to get such an extension, but it seems possible that there is a method to show that some motif exists in any colored rook set, and then argue that we can alter this motif to get the bijection\n  \u2022 define a system of polynomials (over $\\mathbb{F}_2$) such that the solution set corresponds to exactly the colored rook sets inducing a color profile $P$. Then try to apply the Chevalley-Warning theorem.\n\n    \u2022 I've tried this, but can't seem to get systems of polynomials where the sum of the total degrees is strictly less than the number of variables, so the C-W theorem does not apply.\n    \u2022 One can observe the the C-W theorem is an \"iff\" here: if $N(P)$ is even then there is a multilinear polynomial with degree strictly less than the number of variables, such that the solution set encodes those $C_S$'s that induce $P$.\n  \u2022 Instead of using \"rook sets\", one can ask the question for other classes of subsets of $[n]^3$. I'd be happy with establishing $c=\\omega(n)$ for any class of subsets (although I'd like to be able to compute at least one example of such a subset efficiently).\n\nAre there other methods for counting modulo two that I missed?\n\nshare|improve this question\nBy the way, the codomain of P should include 0. \u2013\u00a0 Douglas S. Stones Mar 6 '10 at 10:38\nadd comment\n\n1 Answer\n\nup vote 10 down vote accepted\n\nThis can be phrased as a problem concerning Latin squares. Eg. a \"rook set\" is equivalent to a Latin square. For example:\n\n123       100 010 001\n231  <->  001 100 010\n312       010 001 100\n\nA colouring of the Latin square is a partition of its entries (corresponding to a coloured rook set).\n\nWe can therefore readily construct colour profiles P with c=n2 such that N(P)=1 (that is, by partitioning some Latin square into n2 parts). But we can do much better...\n\nA defining set is a partial Latin square with a unique completion. A critical set is a minimal defining set. Let scs(n) be the size of a smallest critical set for Latin squares of order n. From a Latin square L containing a critical set of size scs(n), we can choose a partition (i.e. a c-colouring) such that the entries in the critical set are in parts of size 1 and the remaining entries of L are in a single part. This also will give rise to a colour profile P in which N(P)=1. It has been shown that scs(n)\u2264n2/4 for all n. (see J. Cooper, D. Donovan and J. Seberry, Latin squares and critical sets of minimal size, Australasian J. Combin 4 (1991), 113\u2013120.) Hence we can deduce that for some c<=n2/4+1 we have N(P)\u22611 (mod 2). But with a more intelligent choice of the partition, we can do better...\n\nIn fact, we can use the constructions in Cooper et al. to construct a colour profile P with c=n for which N(P)=1. I will only be able to prove this by example here (but it should be clear it can be readily generalised): Partition the \"back circulant\" Latin square of order 6 as follows.\n\n123456     100000   020000   003000   000000   000000   000456\n234561     000000   200000   030000   000000   000000   004561\n345612 <-> 000000 + 000000 + 300000 + 000000 + 000000 + 045612\n456123     000000   000000   000000   000000   000000   456123\n561234     000000   000000   000000   000004   000000   561230\n612345     000000   000000   000000   000040   000005   612300\n\nNow observe that the three colour profiles are:\n\n100005  111003  111003\n020004  011004  011004\n003003  001005  001005\n000204  000006  000006\n000015  000105  000105\n000006  000114  000114\n\nTogether these form P. Given P, we can observe that any Latin square of order 6 with colour profile P must contain the following partial Latin square:\n\n\nWhich is a critical set -- and therefore admits a unique completion (that is, to the \"back circulant\" Latin square of order 6). Therefore, if c=n there exists a color profile P for which N(P)=1, not just N(P)\u22611 (mod 2).\n\nEDIT: I presented this problem to our research group at Monash and we improved the upper bound to c=1 (which was a bit surprising!). The idea came from the following critical set (call it C) of the back-circulant Latin square, which is related to the one above, but contains more entries than the one above (but this doesn't matter for this problem).\n\n\nWe observed that if every entry in the critical set above is assigned one colour, and the remaining entries another colour, then there is a unique Latin square with that colour profile. That is, we derive the colour profile from in the following way.\n\n123456     12345.   .....6\n234561     2345..   ....61\n345612 <-> 345... + ...612\n456123     45....   ..6123\n561234     5.....   .61234\n612345     ......   612345\n\nwhich gives rise to the following colour profile P:\n\n15   51   51\n24   42   42\n33   33   33\n42   24   24\n51   15   15\n06   06   06\n\nWe can deduce that any Latin square with the colour profile P will, in fact, contain the critical set C. Hence, N(P)=1.\n\nTo see how we deduce the critical set from the colour profile, we note that for the first colour, it contains 5 entries in the first row and column, 4 entries in the second row and column, and so on (and the same for columns). This selection of cells can take only one shape -- that is, it is unique. Then placing the symbols 1..5 in it can only be achieved in one way (to preserve the Latin property).\n\nSince this can be generalised for all n\u22652, the answer to your question \"what is the largest c such that for all colour profiles P, N(P)\u22610 (mod 2)\" is c=1.\n\nEDIT 2: We also discussed at our research meeting the complexity side of the problem.\n\nInstance: colour profile P\n\nQuestion: is N(P)\u22651?\n\nIn fact, there is an easy way to see that this problem is NP-complete, since (a) we can embed instances of the problem of partial Latin square completion in the above problem and (b) a Latin square together with its colouring can be used as a certificate.\n\nThe problem of partial Latin square completion was shown to be NP-complete in: C. J., Colbourn, The complexity of completing partial Latin squares, Discrete Appl. Math. 8 (1984), no. 1, 25--30.\n\nshare|improve this answer\nAh, this seems to answer the most well-defined aspect of my question, though I'll have to take some more time later to fully digest this. I'm not sure if I should mark my question as \"answered\" as I'll comment more on the broader question I have. \u2013\u00a0 miforbes Mar 6 '10 at 21:01\nI suppose the remains of the question are too open-ended, so I'll mark this answer as the one I'm happy with. As for the c=n-1 case, I would imagine that for all $P$, $N(P)\\equiv 0\\mod 2$, but don't have any good reason to think this. However, I'm really looking for $c=\\omega(n)$, (see my expanded section on the original motivation), so the $c=n-1$ case is slightly less interesting to me. \u2013\u00a0 miforbes Mar 6 '10 at 21:18\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.newton.dep.anl.gov/newton/askasci/1993/math/MATH029.HTM\nText:\nNEWTON, Ask A Scientist!\nNEWTON Home Page NEWTON Teachers Visit Our Archives Ask A Question How To Ask A Question Question of the Week Our Expert Scientists Volunteer at NEWTON! Frequently Asked Questions Referencing NEWTON About NEWTON About Ask A Scientist Education At Argonne Spirals... Circles... Radius\nName: Name\nStatus: N/A\nAge: N/A\nLocation: N/A\nCountry: N/A\nDate: Around 1993\n\nQuestion: Is there any mathematical formula for determining the un-rolled length of a spiral? For instance, if I had a roll of ribbon that had a radius of two inches, and the ribbon was one sixteenth of an inch thick, how long would the ribbon be? If there is not a formula for it, what would be the best way to determine this?\n\nA very close approximation for this kind of spiral is to pretend that the roll of ribbon is a series of concentric circular loops of ribbon. Then, the length of each loop is 2 * pi * r, where r = the loop's radius and pi = 3.1415926...so the answer for your example would be: 2 * pi * (1/16 + 2/16 + 3/16 + ... + 32/16) = 2 * pi * 528/16. If the ribbon was on a spindle of radius, say, 1 inch, the sum would be (16/16 + 17/16 + ... + 32/16). An interesting related problem is find (and prove) a formula for ( 1 + 2 + 3 + ... + N ) John Hawley\n\nHere is another approach. If we assume that the ribbon is tightly wound up (i.e., no gaps between the layers of ribbon), then the volume occupied by the 'disk' of wound-up ribbon equals the volume of the unwound strip (a very flat and long 'box'). Let R denote the radius of the 'disk', T the thickness of the ribbon, L its unwound length (the quantity we want to compute), and W its width. The wound-up volume is pi*R^2*W (\"R^2 means \"R squared\"), and the unwound volume is L*W*T. Setting these equal and solving for L, we get L = pi*R^2/T. For the values given (R=2 in., T=1/16 in.), we get L = 64*pi (about 201) inches. By the way, your idea of using a spiral would work. One could write an equation (polar coordinates would be the easiest choice) for a curve that would lie within the ribbon-say, at mid- interior. There is a formula for length of a curve, using integral calculus. As it happens, the answer you get is the same as that obtained above. If you would like more details on this calculus approach, please ask (here or via e- mail).\n\nRon Winther\n\nClick here to return to the Mathematics Archives\n\n\n\nEducational Programs\nBuilding 360\n9700 S. Cass Ave.\nArgonne, Illinois\n60439-4845, USA\nUpdate: June 2012\nWeclome To Newton\n\nArgonne National Laboratory"}
{"text": "Retrieved from http://math.stackexchange.com/questions/26167/expectation-of-the-maximum-of-iid-geometric-random-variables/26214\nText:\nTake the 2-minute tour \u00d7\n\nGiven $n$ independent geometric random variables $X_n$, each with probability parameter $p$ (and thus expectation $E\\left(X_n\\right) = \\frac{1}{p}$), what is $$E_n = E\\left(\\max_{i \\in 1 .. n}X_n\\right)$$\n\nIf we instead look at a continuous-time analogue, e.g. exponential random variables $Y_n$ with rate parameter $\\lambda$, this is simple: $$E\\left(\\max_{i \\in 1 .. n}Y_n\\right) = \\sum_{i=1}^n\\frac{1}{i\\lambda}$$\n\n(I think this is right... that's the time for the first plus the time for the second plus ... plus the time for the last.)\n\nHowever, I can't find something similarly nice for the discrete-time case.\n\nWhat I have done is to construct a Markov chain modelling the number of the $X_n$ that haven't yet \"hit\". (i.e. at each time interval, perform a binomial trial on the number of $X_n$ remaining to see which \"hit\", and then move to the number that didn't \"hit\".) This gives $$E_n = 1 + \\sum_{i=0}^n \\left(\\begin{matrix}n\\\\i\\end{matrix}\\right)p^{n-i}(1-p)^iE_i$$ which gives the correct answer, but is a nightmare of recursion to calculate. I'm hoping for something in a shorter form.\n\nshare|improve this question\nIs there are typo there? How did $32$ get into it? \u2013\u00a0 joriki Mar 10 '11 at 8:58\nOh yes, whoops. This question arises from a concrete example, where n was 32. \u2013\u00a0 Rawling Mar 10 '11 at 9:04\nIs there a reason for the \"RV\" abbreviation? The main page has plenty of space for two lines... \u2013\u00a0 Uticensis Mar 10 '11 at 9:15\nForce of habit. I can now see all the other questions in \"Related\" with \"random variable\" in their titles :) \u2013\u00a0 Rawling Mar 10 '11 at 9:17\n\n3 Answers 3\n\nup vote 14 down vote accepted\n\nFirst principle:\n\nTo deal with maxima $M$ of independent random variables, use as much as possible events of the form $[M\\leqslant x]$.\n\nSecond principle:\n\nTo compute the expectation of a nonnegative random variable $Z$, use as much as possible the complementary cumulative distribution function $\\mathrm P(Z\\geqslant z)$.\n\nIn the discrete case, $\\mathrm E(M)=\\displaystyle\\sum_{k\\ge0}\\mathrm P(M>k)$, the event $[M>k]$ is the complement of $[M\\leqslant k]$, and the event $[M\\leqslant k]$ is the intersection of the independent events $[X_i\\leqslant k]$, each of probability $F_X(k)$. Hence, $$ \\mathrm E(M)=\\sum_{k\\geqslant0}(1-\\mathrm P(M\\leqslant k))=\\sum_{k\\geqslant0}(1-\\mathrm P(X\\leqslant k)^n)=\\sum_{k\\geqslant0}(1-F_X(k)^n). $$ The continuous case is even simpler. For i.i.d. nonnegative $X_1$, $X_2$, ..., $X_n$, $$ \\mathrm E(M)=\\int_0^{+\\infty}(1-F_X(t)^n)\\mathrm{d}t. $$\n\nshare|improve this answer\nThese are very nice principles. I'd just add that what Didier has called \"repartition function\" is called \"cumulative distribution function\" in English. \u2013\u00a0 Michael Lugo Mar 10 '11 at 19:27\n@Michael Thanks, post modified. \u2013\u00a0 Did Mar 10 '11 at 21:01\n@Did sorry to bother you over such an old answer but I am unclear on what F_X(k) is. For a geometric distribution of parameter p, I think it is the c.d.f. or (1-(1-p)^{k+1}). Is this correct? \u2013\u00a0 Dale M Apr 2 '13 at 1:52\n@DaleM If $P(X=k)=p(1-p)^k$ for every $k\\geqslant0$, yes. \u2013\u00a0 Did Apr 2 '13 at 5:08\n\nThere is no nice, closed-form expression for the expected maximum of IID geometric random variables. However, the expected maximum of the corresponding IID exponential random variables turns out to be a very good approximation. More specifically, we have the hard bounds\n\n$$\\frac{1}{\\lambda} H_n \\leq E_n \\leq 1 + \\frac{1}{\\lambda} H_n,$$ and the close approximation $$E_n \\approx \\frac{1}{2} + \\frac{1}{\\lambda} H_n,$$ where $H_n$ is the $n$th harmonic number $H_n = \\sum_{k=1}^n \\frac{1}{k}$, and $\\lambda = -\\log (1-p)$, the parameter for the corresponding exponential distribution.\n\nHere's the derivation. Let $q = 1-p$. Use Did's expression with the fact that if $X$ is geometric with parameter $p$ then $P(X \\leq k) = 1-q^k$ to get\n\n$$E_n = \\sum_{k=0}^{\\infty} (1 - (1-q^k)^n).$$\n\nBy viewing this infinite sum as right- and left-hand Riemann sum approximations of the corresponding integral we obtain\n\n$$\\int_0^{\\infty} (1 - (1 - q^x)^n) dx \\leq E_n \\leq 1 + \\int_0^{\\infty} (1 - (1 - q^x)^n) dx.$$\n\nThe analysis now comes down to understanding the behavior of the integral. With the variable switch $u = 1 - q^x$ we have\n\n$$\\int_0^{\\infty} (1 - (1 - q^x)^n) dx = -\\frac{1}{\\log q} \\int_0^1 \\frac{1 - u^n}{1-u} du = -\\frac{1}{\\log q} \\int_0^1 \\left(1 + u + \\cdots + u^{n-1}\\right) du $$ $$= -\\frac{1}{\\log q} \\left(1 + \\frac{1}{2} + \\cdots + \\frac{1}{n}\\right) = -\\frac{1}{\\log q} H_n,$$ which is exactly the expression the OP has above for the expected maximum of $n$ corresponding IID exponential random variables, with $\\lambda = - \\log q$.\n\nThis proves the hard bounds, but what about the more precise approximation? The easiest way to see that is probably to use the Euler-Maclaurin summation formula for approximating a sum by an integral. Up to a first-order error term, it says exactly that\n\n$$E_n = \\sum_{k=0}^{\\infty} (1 - (1-q^k)^n) \\approx \\int_0^{\\infty} (1 - (1 - q^x)^n) dx + \\frac{1}{2},$$ yielding the approximation $$E_n \\approx -\\frac{1}{\\log q} H_n + \\frac{1}{2},$$ with error term given by $$\\int_0^{\\infty} n (\\log q) q^x (1 - q^x)^{n-1} \\left(x - \\lfloor x \\rfloor - \\frac{1}{2}\\right) dx.$$ One can verify that this is quite small unless $n$ is also small or $q$ is extreme.\n\nAll of these results, including a more rigorous justification of the approximation, the OP's recursive formula, and the additional expression $$E_n = \\sum_{i=1}^n \\binom{n}{i} (-1)^{i+1} \\frac{1}{1-q^i},$$ are in Bennett Eisenberg's paper \"On the expectation of the maximum of IID geometric random variables\" (Statistics and Probability Letters 78 (2008) 135-143).\n\nshare|improve this answer\nIs the log here based 2 or mathematical constant? \u2013\u00a0 Fan Zhang Apr 2 '12 at 4:35\n@FanZhang: It's log base $e$. \u2013\u00a0 Mike Spivey Apr 2 '12 at 13:59\n\n$$\\begin{align} P(\\max Y_i=k)&=P(\\max Y_i\\leq k)-P(\\max Y_i<k)\\\\\\\\&=F(k)^n-(F(k)-f(k))^n. \\end{align}$$ Thus $$\\begin{align} E(\\max Y_i) &= \\sum_{k=0}^{\\infty} k\\left[F(k)^n-(F(k)-f(k))^n\\right] \\\\\\\\ &=\\sum_{k=1}^{\\infty}k\\left[\\left(1-(1-p)^k\\right)^n-\\left(1-(1-p)^{k-1}\\right)^n\\right]. \\end{align}$$\n\nNot a closed form though.\n\nSee also Order statistic for both continuous and discrete case. The formula for the continuous case appears in Shai Covo's post here.\n\nshare|improve this answer\nVery nice. No recursion required to calculate, works with any distribution, and gives me a whole new concept to look into. I'll have to try with the continuous case to see if it gives me the same answer as I have above. \u2013\u00a0 Rawling Mar 10 '11 at 9:48\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/20200/distribution-of-degree-of-minimum-polynomial-for-eigenvalues-of-random-matrix-wi?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThis is an attempt to extend the current full fledged random matrix theory to fields of positive characteristics. So here is a possible setup for the problem: Let $A_{n,p}$ be an $n \\times n$ matrix with entries iid taking values uniformly in $F_p$. Then one should be able to find its eigenvalues together with multiplicities, which might lie in some finite extension of the field $F_p$. To ensure diagonalizability, one might even take $A_{n,p}$ to be symmetric or antisymmetric (I am not so sure if that guarantees diagonalizability in $F_p$ but I have no counterexamples either). Now the question is if we associate to each eigenvalue $\\lambda$ the degree of its minimal polynomial $d(\\lambda)$, then does the distribution of $d(\\lambda)$ as $n$ goes to infinite converge to some law upon normalization (say maybe Gaussian)? I am very curious whether others have studied this problem before. Maybe it's completely trivial.\n\nshare|improve this question\nBeing symmetric isn't enough; for example, if p is congruent to 1 mod 4, let i denote a square root of -1. Then [[i 1][1 -i]] squares to zero. \u2013\u00a0 Qiaochu Yuan Apr 3 '10 at 2:21\nAnyway, section 1.10 of the second edition of Stanley's EC Chapter might be relevant: math.mit.edu/~rstan/ec/ch1.pdf \u2013\u00a0 Qiaochu Yuan Apr 3 '10 at 2:28\nNice example! I guess one could still ask the question in the nonsymmetric case, as an analogy of the ginibre Ensemble in the complex case. \u2013\u00a0 John Jiang Apr 3 '10 at 4:05\n\n1 Answer 1\n\nup vote 12 down vote accepted\n\nThe survey article\n\nJason Fulman, Random matrix theory over finite fields, Bulletin of the AMS 39 (2002), 51-85\n\nand the references therein should answer your questions to the extent that the answers are currently known. See in particular Example 3 in Section 2.2. Roughly, the distribution of the degrees of the factors of the characteristic polynomial of a random matrix over a finite field is close to the distribution of the degrees of the factors of a random polynomial over the same finite field, which is close to the distribution of the cycle lengths of a random element of a symmetric group.\n\nshare|improve this answer\nThank you for the reference and pointer to the example. This is very helpful. \u2013\u00a0 John Jiang Apr 3 '10 at 20:56\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/104946/poisson-process-courts?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nIITK sports facility has $4$ tennis courts. Players arrive at the courts at a Poisson rate of one pair per $10$ min and use a court for an exponentially distributed time with mean $40$ min. Suppose that a pair of players arrives and finds all courts busy and $k$ other pairs waiting in queue. How long will they have to wait to get a court on the average?\n\nshare|improve this question\n\n1 Answer 1\n\nThey need to wait for $k+1$ pairs to finish before they can start.\n\nSince the exponential distribution is memoryless, the expected time for a given pair to finish once started is $40$ minutes, and there are four courts, the expected time for any of the four courts to finish is $\\frac{40}{4}=10$ minutes, and so their expected waiting time is $10(k+1)$ minutes.\n\nSlightly more worryingly, since the service rate of the courts is equal to the arrival rate, the expected waiting time (in effect summing over $k$ weighted by the probability that there are $k$ queuing at any one time) is infinite.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/292315/offline-flyback-dc-dc-converter-using-ne555-works-in-ltspice-will-it-work-in-a\nText:\nI'm currently a novice and am learning EE. I've been experimenting with low voltage DC-DC converters. Now I want to build an offline DC-DC converter that operates directly from AC mains.\n\nThe schematic works very well in simulation, but being this converter draws its power directly from AC mains, I'd like some input from experienced users/professionals before I build this thing and test it in a real world scenario.\n\nThis NE555 circuit is only a learning tool. The objective was to take on a project way beyond the scope of my knowledge and I decided to build a SMPS using basic oscillators and designing all of the auxiliary circuitry around them.\n\nI'm aware of the existence of and have many different SMPS control ICs.\n\n\nI took the entire circuit apart and rearranged it a bit. I realized in order for PFC to really work the transformer has to be wound for the max voltage, so I'm operating the boost converter from a pre-regulator then once the boosted output hits 360VDC it starts up the flyback circuit. Once the flyback's regulated output reaches 14.8V it shuts the pre regulator off. All occurring within a half a second or so.\n\nWill the pre-regulator blow up? I know I'll survive up to 170VDC I've tried these (get very hot after a few minutes, but will power an NE555 and a few transistors), but at 340VDC? I know the jump from 340 to 360 won't take more than 60ms, could be safe, but What do you guys think?\n\nHere's are the latest revisions The output results are with PFC output @ 360VDC carrying a 129\u03a9 load (>1KW)\n\nSchematic More Organized First is both the boost converter and transformer waveforms without current traces. Second is Boost converter only with current trace. Third is transformer only with current trace OutPuts\n\n  \u2022 1\n    \\$\\begingroup\\$ I'm an experienced EE, I design circuits for a living. Low voltage circuits, including DCDC converters. Could I design a mains powered DCDC converter ? Probably. Would I do it ? Nope. Why not ? Because it will not bring anything compared to an off-the-shelf module. Also there are lots of practical issues, like electrocution risk being one of them. Also your circuit looks overcomplicated. Why use the 555 ? There are special purpose ICs for this. \\$\\endgroup\\$ Mar 14 '17 at 14:47\n  \u2022 1\n    \\$\\begingroup\\$ There is a difference between making something working in a simulator and the real world. For example, in the simulator things do not blow up. I see a transformer there but it's not for isolation ? Oh, you're switching the high voltage directly to low voltage. Hmm, everyone else uses a transformer for this (flyback converter). Can you guess why. There are 2 important reasons. Why have you chosen a different topology ? Even if it worked I would not use your converter to charge my phone, can you guess why ? \\$\\endgroup\\$ Mar 14 '17 at 14:50\n  \u2022 1\n    \\$\\begingroup\\$ I suggest that you study how mains supplies are build up because yours uses the same ground everywhere and your ground is mains referenced via the bridge rectifier. So your design is not isolated. If it was you'd be able to draw a line between input and output without crossing any connections. Usually this line will go through the transformer, opto coupler (for feedback) and a Y-rated capacitor. Despite what you say this circuit is not isolated. \\$\\endgroup\\$ Mar 14 '17 at 15:11\n  \u2022 4\n    \\$\\begingroup\\$ In case you are planning to make youtube videos about your circuits: do it as a live show. Dead people can't upload stuff. \\$\\endgroup\\$\n    \u2013\u00a0PlasmaHH\n    Mar 14 '17 at 15:14\n  \u2022 1\n    \\$\\begingroup\\$ the control chips were grounded to the main rectifier and they are. But note that that \"ground\" is just the ground reference of the primary side, it is not connected to mains earth (mains must remain isolated from earth !) but it is also not (directly) connected to the output ground. The output ground can be connected to mains earth, if possible I'd even recommend that as it makes the output safe to touch. There is more than one ground and they should not be connected ! \\$\\endgroup\\$ Mar 14 '17 at 15:32\n\nThe NE555 is IMO totally unsuitable for such a design as the pulse width of the first pulse is invariably much longer than any subsequent pulses. This is due to the fact that the timing capacitor is charged and discharged between 1/3 and 2/3 of the supply ...except for the first time you charge it, and you always start from zero charge on the capacitor. So the first pulse is from 0 - 2/3.\nThis makes soft start almost impossible to engineer, and can result in large initial currents since you don't know when in the AC cycle you will first make contact.\n\nI see no attempt here to make the supply zero crossing startup and your (I assume an attempt) at soft start looks quite flawed. Particularly the drive for Q1, Q7 and the fact that the C8 charge dump is not AC synchronized.\nThe first pulse from U1 will be much longer because of the ramp on C5 continuously raising the C6 aiming voltage and the complications with exactly what voltage it will get to. When your charge dump (Q1/Q2) turns on there is uncontrolled discharge of C8 through Q1/Q2 which I don't think you intended.\n\nIf I were to test this I'd be using a transformer as isolation and start with perhaps a 50 V RMS output.\n\nAdditional Comments 4/22 circuit:\n\n  1. Pre-Reg shutdown. Overcurrent base drive from Q31 driving Q30. Need a base resistor.\n  2. Pre-Regulator. Do you really need 9900 uF capacitance?\n    Need a 270 Ohm resistor between C9 and Q3 Collector pulldown to lower Q3 current discharging C9.\n  3. Zero-Crossing. Do you really need Pre_Charge since it's derived from Pre_Supply?\n  4. PFC-Startup Controller and Flyback Startup-Controller. Need base resistor in Q2/4. Consider when latch turns on the base current is limited only by Q18/20 Beta.\n  5. PFC Softstart and Transformer Softstart. Clamping U2_out and U4_out appears faulty. You are trying to hold the amplitude of the signal low, but with insufficient current limiting.\n  6. Positive voltage regulator. If I read correctly Pre_Charge will be about 17-18 V, so Positive_Voltage will not turn on. The voltage for the two BE's, 3 diodes and a zener come to about 20 V, but if Supply goes over 20 V then there is an uncontrolled current path. Perhaps you could remove a diode and replace with a resistor and still get the correct operation.\n  \u2022 \\$\\begingroup\\$ Okay, I'm glad you mentioned the charge dump because the control chip's aren't really my issue. I have SG3225s, FAN4800s, Hi/Low side MOSFET drivers, etc., that I would use in the design of a power supply that had a purpose other than experimentation. The purpose for this experiment is the charge dump. I've been trying to make a low voltage regulated supply for the primary side of an offline DC-DC converter. It made sense to me to feed C8 through R2 then once C8's charge exceeds 12V it will cause D7 to conduct in the opposite direction, applying current to the base of Q2, pulling down the \\$\\endgroup\\$\n    \u2013\u00a0user14828\n    Mar 15 '17 at 8:09\n  \u2022 \\$\\begingroup\\$ ..base of Q1, dumping C8's entire charge into the NE555 driver circuit (D16 prevents feedback into D7) which starts switching M1, charging L3, inducing current in L1, feeding the driver circuit. There was no attempt at a soft start (didn't know I needed that in a flyback, if I do then I stand corrected). I really didn't think the first pulse being longer was going to be an issue because I've read that actual control chips vary duty cycle and if you look at the values of R14 and R15, the NE555 is switching at a pretty low duty cycle. I'm very new to EE so I'm sure there are mistakes. \\$\\endgroup\\$\n    \u2013\u00a0user14828\n    Mar 15 '17 at 8:31\n  \u2022 \\$\\begingroup\\$ The waveforms look good though. The peak voltage between L3 and M1 are >200V over supply which at peak is 595V (I have 800V MOSFETS). But correct me where I'm wrong I've only done this particular one simulation. \\$\\endgroup\\$\n    \u2013\u00a0user14828\n    Mar 15 '17 at 8:37\n  \u2022 1\n    \\$\\begingroup\\$ You've made significant changes, and certainly improved your design overall. Glad I could help in some way. I do still think that using the 555 has resulted in some odd design elements, especially with low current base protections for example. I'm surprised that zero crossing alignment didn't help control startup currents more. I'm stunned how good the waveform simulations turned out. \\$\\endgroup\\$ Apr 8 '17 at 14:38\n  \u2022 1\n    \\$\\begingroup\\$ You were correct again! I sharpened the startup by adding a smaller cap at SUPPLY then start switching at the FETs threshold voltage (4.5v) and BINGO! current spikes dropped by 6A,(21A). I also removed the second push pull amp as it was unnecessary, and added a small resistor in parallel with a diode. I'm getting much better performance, I'll post an update as soon as I'm done improving the soft start. \\$\\endgroup\\$\n    \u2013\u00a0user14828\n    Apr 13 '17 at 6:37\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/2298/how-do-i-force-re-evaluation-of-a-defvar?noredirect=1\nText:\nSuppose I have an Emacs lisp buffer that contains:\n\n(defvar foo 1)\n\nIf I call eval-last-sexp or eval-buffer, foo is bound to 1. If I then edit this buffer to:\n\n(defvar foo 2)\n\neval-last-sexp and eval-buffer do not re-execute this line, so foo is still 1.\n\nThis is particularly challenging when there are multiple such statements and I have to track down which lines are not being re-evaluated.\n\nI looked at just restarting Emacs and then (require 'foo), but then I have to be careful to avoid loading any older .elc files.\n\nHow can I be absolutely, positively sure that the variables and functions defined in the current file are in the same state as loading code afresh in a new Emacs instance?\n\n  \u2022 You cannot be \"absolutely, positively sure that Emacs is in a state that is the same as loading the code afresh in a new Emacs instance\" without doing just that. If you want to be sure only wrt this and other global variables, then you can remove their values using makunbound and then re-evaluate the code in the buffer.\n    \u2013\u00a0Drew\n    Oct 17 '14 at 21:30\n  \u2022 Sure, side effects like (silly code) (incf emacs-major-version) I can live with happening repeatedly. I'm interested in hacking on code with lots of defvar forms. Oct 17 '14 at 21:36\n\nAs explained in other answers, evaluating a defvar form using eval-last-sexp does not reset the default value.\n\nInstead, you can use eval-defun (bound to C-M-x in emacs-lisp-mode by default), which implements the behaviour you want as a special exception:\n\nIf the current defun is actually a call to defvar or defcustom, evaluating it this way resets the variable using its initial value expression even if the variable already has some other value. (Normally defvar and defcustom do not alter the value if there already is one.)\n\nIf you need to evaluate the full contents of a buffer, you can write a function that walks the top-level forms in turn and calls eval-defun on each. Something like this should work:\n\n(defun my/eval-buffer ()\n  \"Execute the current buffer as Lisp code.\nTop-level forms are evaluated with `eval-defun' so that `defvar'\nand `defcustom' forms reset their default values.\"\n    (goto-char (point-min))\n    (while (not (eobp))\n      (eval-defun nil))))\n  \u2022 6\n    This is the answer. No need for fake defvars or extra setqs. Just use eval-defun instead of eval-last-sexp . You can even write a function that calls eval-defun on every form in the buffer, and use it instead of eval-buffer.\n    \u2013\u00a0Malabarba\n    Oct 17 '14 at 19:06\n  \u2022 1\n    @Malabarba This post falls far short of answering the question. Use eval-defun instead of eval-last-sexp, sure, but the difficulty is for eval-buffer. Oct 17 '14 at 21:17\n  \u2022 @Gilles yes, you're right. I added a tentative implementation of @Malabara's idea of calling eval-defun on every top-level form in the buffer. Oct 17 '14 at 21:41\n  \u2022 1\n    This approach does not seem to work if the defvar is not inside a defun. Example: (progn (defvar foo \"bar\")). Mar 13 '15 at 15:01\n  \u2022 2\n    @kaushalmodi The latter examples that you cite (variables storing regular expressions) look a lot like candidates for defconst (which is always re-evaluated). There's recently been a very enlightening post on this topic in endless parentheses Mar 13 '15 at 21:07\n\nLike the other answers say, this is just the way defvar works, but you can get around it, this is elisp after all.\n\nYou can temporarily redefine how defvar works if you'd like and during that time, reload the packages you'd like to reset.\n\nI wrote a macro where during the evaluation of the body, defvars values will always be reevaluated.\n\n(defmacro my-fake-defvar (name value &rest _)\n  \"defvar impersonator that forces reeval.\"\n  `(progn (setq ,name ,value)\n\n(defmacro with-forced-defvar-eval (&rest body)\n  \"While evaluating, any defvars encountered are reevaluated\"\n  (declare (indent defun))\n  (let ((dv-sym (make-symbol \"old-defvar\")))\n    `(let ((,dv-sym (symbol-function 'defvar)))\n             (fset 'defvar (symbol-function 'my-fake-defvar))\n         (fset 'defvar ,dv-sym)))))\n\nExample Usage:\n\n\n(defvar my-var 10)\n\n\n  (load-file \"file_a.el\")\n  (assert (= my-var 10))\n  (setq my-var 11)\n  (assert (= my-var 11)\n  (load-file \"file_a.el\")\n  (assert (= my-var 10))\n\nNote: This this should only be used for the purpose of reevaluating defvars, as it just ignores docstrings when reevaluating. You can modify the macro to support re-evaluating that applies docstrings as well, but I will leave that up to you.\n\nIn your case you could do\n\n(with-forced-defvar-eval (require 'some-package))\n\nBut know what those who write elisp do so expecting defvar to work as specified, it could be they use defvar to define and setq in some init function to specify the value, so you may end up nil'ing variables you don't intend but this is probably rare.\n\nAlternative Implementation\n\nUsing this you can just redefine defvar globally and control whether or not it will set the symbol's value to the INIT-VALUE arg even if the symbol is defined by changing the value of the new defvar-always-reeval-values symbol.\n\n;; save the original defvar definition\n(fset 'original-defvar (symbol-function 'defvar))\n\n(defvar defvar-always-reeval-values nil\n  \"When non-nil, defvar will reevaluate the init-val arg even if the symbol is defined.\")\n\n(defmacro my-new-defvar (name &optional init-value docstring)\n  \"Like defvar, but when `defvar-always-reeval-values' is non-nil, it will set the symbol's value to INIT-VALUE even if the symbol is defined.\"\n     (when defvar-always-reeval-values (condition-case nil\n         (makunbound ',name)\n       (error nil)))\n     (original-defvar ,name ,init-value ,docstring)))\n\n;; globally redefine defvar to the new form\n(fset 'defvar (symbol-function 'my-new-defvar))\n  \u2022 1\n    I'm not sure redefining the behaviour of defvar is a good idea: there are several different possible uses of defvar, with slightly different semantics. For example, one use your macro doesn't account for is the (defvar SYMBOL) form, which is used to tell the byte-compiler about the existence of a variable without setting a value. Oct 17 '14 at 19:07\n  \u2022 If you absolutely need to redefine defvar with a macro, you would probably be better off prefixing the original defvar form with a makunbound, rather than replacing it by setq. Oct 17 '14 at 19:11\n  \u2022 Yes, it is a terrible idea, and should only be used for things like reevaluting the defvars of a loaded package in your scratch buffer, you should never ship something like this. Oct 17 '14 at 19:12\n  \u2022 @Francesco also you are right about the makunbound version, I had implemented that but strayed away from the idea, I have put that code on my answer as an alternative. Oct 17 '14 at 19:15\n  \u2022 In case anyone runs across this answer and wonders why my-new-defvar might crash your Emacs, it's because if the symbol being passed is already void (like from a fresh Emacs restart) and makunbound gets involved, it throws an error (and coincidentally crashed Emacs for me). Wrap the makunbound call in a condition-case to catch that error.\n    \u2013\u00a0David\n    Nov 29 '21 at 1:29\n\nThe defvar is being evaluated and doing exactly what you've specified. However, defvar only sets an initial value:\n\nThe optional argument INITVALUE is evaluated, and used to set SYMBOL, only if SYMBOL's value is void.\n\nSo to achieve what you want you would either need to unbind the variable before re-evaluating, e.g.\n\n(makunbound 'foo)\n\nor use setq to set the value, e.g.\n\n(defvar foo nil \"My foo variable.\")\n(setq foo 1)\n\nIf you don't need to specify a docstring here you can skip the defvar altogether.\n\nIf you really want to use defvar and automatically unbind this, you will need to write a function to find defvar calls in the current buffer (or region, or last sexp, etc); call makunbound for each one; and then do the actual eval.\n\n  \u2022 I was off playing with an eval-buffer wrapper that would unbind everything first, but @Francesco's answer about eval-defun is really what you want.\n    \u2013\u00a0glucas\n    Oct 17 '14 at 19:22\n\nThe following macro was created by tracing eval-defun to its supporting functions and modifying it so that it is no longer necessary to evaluate a region of a particular buffer. I needed help in the related thread Converting an expression to a string, and @Tobias came to the rescue -- teaching me how to convert the imperfect function into a macro. I don't think we need eval-sexp-add-defvars to precede elisp--eval-defun-1, but if someone thinks that is important, please let me know.\n\n;;;   (defvar-reevaluate\n;;;     (defvar undo-auto--this-command-amalgamating \"hello-world\"\n;;;     \"My new doc-string.\"))\n\n(defmacro defvar-reevaluate (input)\n\"Force reevaluation of defvar.\"\n  (let* ((string (prin1-to-string input))\n        (form (read string))\n        (form (elisp--eval-defun-1 (macroexpand form))))\n\nThe problem is not that the line is not getting re-evaluated. The problem is that defvar defines a variable and its default value. If a variable already exists, then changing its default value does not modify the current value. Unfortunately, I think you will need to run a setq for every variable whose value you wish to update.\n\nThis may be overkill, but you could update your file like this if you want to be able to easily update foo to its new default value.\n\n(defvar foo 2)\n(setq foo 2)\n\nbut that requires that you maintain the default value in two places in your code. You could also do this:\n\n(makunbound 'foo)\n(defvar foo 2)\n\nbut if there is a chance that foo is declared elsewhere you may have some side effects to deal with.\n\n  \u2022 That's difficult when trying to test changes to a complex mode. I'd rather not change the code. eval-defun treats defvar specially, so surely there's something similar for whole buffers? Oct 17 '14 at 18:49\n  \u2022 @WilfredHughes I'm not sure what you mean by \"something for whole buffers.\" You want a single function that will makunbound any variables declared in the current buffer, and then re-evaluate it? You could write your own, but I don't think that there is an out-of-the-box function for this. EDIT: Never mind, I get what you are saying. An eval-defun that works on the whole buffer. It looks like @JordonBiondo has your solution for that.\n    \u2013\u00a0nispio\n    Oct 17 '14 at 18:53\n  \u2022 No. The problem is lack of re-evaluation: defvar does nothing if the variable already has a value (as its doc says: The optional argument INITVALUE is evaluated, and used to set SYMBOL, only if SYMBOL's value is void.). The problem is not that defvar changes the default value and not the current value. (defvar a 4) (default-value 'a) (setq a 2) (default-value 'a); then C-x C-e after the defvar sexp; then (default-value 'a). C-x C-e, eval-region, and the like on a defvar sexp do not change the default value.\n    \u2013\u00a0Drew\n    Oct 17 '14 at 20:40\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/45405/highlight-current-line-in-gud-disassembler-window/45410\nText:\nI am using GUD for debugging C code. Because many of the lines and variables have been optimized away, it is necessary to follow the C source and the corresponding disassembly simultaneously. I want the current line in the disassembler window to be highlighted each time I \"step instruction.\" Right now the cursor moves automatically, in the disassembler window, but hl-line-mode does not highlight the line that the cursor moved to. If I switch to that window, the new line gets highlighted, and remains highlighted when I move away from that window again. But each time I step, the highlighting from hl-line-mode disappears in the inactive window.\n\nHow can I get a good visual indication of the \"current line\" in the disassembler window? The tiny triangle in the fringe is not enough, because the lines are quite long, and it is difficult to tell at a glance which instruction will be executed next.\n\n  \u2022 Wherever you see gud-overlay-arrow-position (make-marker) ... set-marker, you can put something after that location using (marker-position gud-overlay-arrow-position) as the point at which to update hl-line-mode or other gizmo that suits your needs. I see two (2) locations in the version I am using: gud-display-line and gdb-frame-handler. However, I have limited experience using gdb and am unfamiliar with terms such as disassembler and step instruction ... Therefore, I am unable to write up an answer because I cannot test it myself.\n    \u2013\u00a0lawlist\n    Oct 16 '18 at 18:33\n  \u2022 Thanks, @lawlist. I tried this and found out that the gud-overlay-arrow-position is different from the gdb-disassembly-position overlay. Interestingly the gud-display-line function already has special handling for hl-line-mode, so regular source buffers already work as expected with hl-line-mode, even when the source buffer is not the active window. (re-reading this comment right after typing it, I realize that it might be more confusing than anything.)\n    \u2013\u00a0nispio\n    Oct 16 '18 at 21:57\n\nThanks to @lawlist nudging me into the source code, I found out that gdb mode will highlight the line for me, but only on the condition that the window containing the disassembly does not have fringes. The following was enough to make that happen:\n\n;; Enable automatic highlighting of the active line in disassembly window\n(defun nispio/disable-window-fringes () (set-window-fringes nil 0 0))\n(add-hook 'gdb-disassembly-mode-hook #'nispio/disable-window-fringes)\n\nBecause I usually pop the disassembly window out into a separate frame, this is okay. Otherwise, it would disable the fringes on some semi-arbitrary window.\n\n\nThis is the solution I came up with using hl-line. I needed to advise the function that updates the disassembly buffer and invoke hl-line-highlight directly to make it work.\n\n(defadvice gdb-disassembly-handler-custom\n    (after nispio/ad-after-disas-handler-hl-line activate)\n  \"Make sure that `hl-line' gets updated after updating disassembly buffer\"\n  (let* ((buffer (gdb-get-buffer 'gdb-disassembly-buffer))\n         (window (get-buffer-window buffer 0)))\n    (when (and window (featurep 'hl-line))\n      (with-current-buffer buffer\n          (goto-char gdb-disassembly-position)\n         ((and hl-line-mode hl-line-sticky-flag)\n          (goto-char gdb-disassembly-position)\n\n(add-hook 'gdb-disassembly-mode-hook #'hl-line-mode)\n\nYour Answer"}
{"text": "Retrieved from http://polymathprogrammer.com/2012/11/30/modulo-26-and-column-names/\nText:\nModulo 26 and column names\n\nI was sitting in the lecture theatre valiantly trying to keep awake. The professor was speaking on the rigorous application and proving of the modulus function. It\u2019s basically the remainder, but I\u2019ve never been introduced to it in such, uh, rigor.\n\nHe brought up an example using modulo 26. And demonstrated the wrapping around of values. And the use of it in cryptology (a class I took later on, and I got tasked by the cryptography professor to write a program to do simple encryption. But another story perhaps\u2026).\n\nModulo 26 is similar to finding the remainder. The difference is that the remainder is unique. This is important to our discussion.\n\n\u201cAbout what?\u201d you may ask.\n\nExcel column names.\n\nThere are 2 types of cell references used in spreadsheets, the R1C1 format and the A1 format. The R1C1 is simple. If the row index is 5 and the column index is 7, the result is R5C7.\n\nThe A1 format takes on a column name and the row index. Using our example again, the result is G5, because \u201cG\u201d is the 7th alphabet. Yes, that list of 26 alphabets.\n\nThe version of Excel currently (Excel 2007 and 2010) has up to 3 letters, with XFD as the last column name (that\u2019s the 16384th column). What happens is you have column names A, B, and then up to Z. Then the next column name is AA, then AB and then up AZ. Then BA, BB and so on.\n\nBasically, it\u2019s base 26 arithmetic.\n\nAs far as I know, the typical method of getting the column name given the column index, is to run a loop. You add 1 until it hits 26, then you move to the next \u201cposition\u201d, and then start from 1 again.\n\nThere\u2019s nothing wrong with this method. It\u2019s just that you have to iterate as many times as the given column index. If you\u2019re given 16384, the loop runs 16384 times. This is regardless of the fact that the result is always the same. Given the range of values, the result can only be one of 16384 values.\n\nSo it was with this in mind, and my dabbling in game development (which said \u201cPrecalculate everything!\u201d), that I precalculated an array of strings that are the column names. The array has 16384 items. The context is a spreadsheet software library.\n\nNow to recoup that precalculation cost, I\u2019d have to access my array at least 16384 times. This is where the context of the spreadsheet library comes in. Everybody (and their dog) wants to know if my library can handle millions of cells. This means if the column name calculation is in a method, that method is called millions of times. Given the iteration loop in it, that means the method with the iteration loop thing isn\u2019t efficient (it\u2019s O(n^2)).\n\nHowever, due to technical issues, I can\u2019t keep the array of strings. The column name array needs to be static to be available throughout the library. This causes issues if multi-threads or multi-processors or multi-whatevers comes in.\n\nSo I can\u2019t use my static array anymore. Bummer. The O(n) of simple array access was working so well.\n\nBut I still want to have an efficient way of getting column names. So instead of iterating, I used simple division and modulus operations.\n\nConsider 587. How do you know there\u2019s 5 hundred? 587 / 100 equals 5 (truncating remainders). How do you know there\u2019s 8 tens? 87 / 10 equals 8 (truncating remainders).\n\nYes, it\u2019s elementary arithmetic, but it works great. So we can do the same for column names. There\u2019s a problem though.\n\nIn the case above, we divided by 100. Why 100? Because it\u2019s 10^2, and we\u2019re concerned with the 2nd position after the ones position. The ones position is 10^0 by the way, which is 1.\n\nSo for our case, for the \u201chundreds\u201d position, we divide by 676, which is 26^2. And for the \u201ctens\u201d position, we divide by 26.\n\nNow 587 is 100*5 + 10*8 + 7. I\u2019m going to use the notation (5,8,7) to denote this.\n\nNow consider a column index of 3380. 3380 is equal to 676*5 + 26*0 + 0. This is (5,0,0).\n\nHowever, in our case, our acceptable range of values is 1 through 26. It doesn\u2019t contain zero. So (5,0,0) is not valid.\n\nIn the case of 587, we\u2019re working in base 10, with the acceptable range of values being 0 to 9. This is \u201cproper\u201d remainder. Given any number in base 10, there\u2019s a unique number within [0, 9] that\u2019s the remainder.\n\nHowever, for our purposes, there\u2019s no unique number. Because we\u2019re working in modulo 26, not just \u201cremainder 26\u201d.\n\nThe correct column name corresponding to column index 3380 is \u201cDYZ\u201d. This corresponds to (4,25,26). Or\n3380 = 676*4 +26*25 + 26.\n\nNote that 3380 is also 676*5 + 26*0 + 0.\n\nMy solution is to start from the \u201cones\u201d position. If it\u2019s greater than zero, fine. If it\u2019s less than or equal to zero, borrow from the next larger position. Then we move to the next larger position, and check again. Continue to borrow until there are no zero values (or negatives) on the \u201cright\u201d side of the resulting notation (we can have \u201cleading\u201d zeroes).\n\nSo (5,0,0) becomes (5, -1, 0 + 26), or just (5,-1,26), borrowing 1 from the \u201ctens\u201d position. We cannot have -1, so that becomes (4, -1 + 26, 26), which becomes (4, 25, 26).\n\nAn interesting effect is that we typically assign 0 to A, 1 to B, and 25 to Z. In this case, 1 is assigned to A, 2 is to B, and most interestingly, both 0 and 26 map to Z. In fact, any multiple of 26 will map to Z.\n\nDon\u2019t think Z is special. Any multiple of 26 plus 1 also maps to A. So 1, 27, 53 and so on map to A. This is a property of the modulo thing.\n\nDo you have a better way of converting (5,0,0) to (4,25,26)? Let me know in the comments."}
{"text": "Retrieved from https://mathoverflow.net/questions/311084/additive-discrepancy-under-a-multiplicative-constraint\nText:\nConsider four sequences of numbers, $0 \\le a_i, b_i, c_i, d_i \\le 1$, suppose they satisfy the following constraints:\n\n(1). $\\sum_{i=1}^K a_i, \\sum_{i=1}^K b_i, \\sum_{i=1}^K c_i \\ge 1/2 + \\epsilon$;\n\n(2). $\\sum_{i=1}^K d_i \\le 1/2 - \\epsilon$;\n\n(3). $a_i d_i = b_i c_i$ for all $i=1, \\ldots, K$.\n\nIs it true that \\begin{equation} \\sum_{i=1}^K (|a_i - b_i| + |a_i - c_i|) = \\Omega(\\epsilon) ? \\end{equation}\n\nThe following example shows that the absolute value and the sum is necessary: \\begin{align*} a_1 = 1/2 + \\epsilon, \\quad &a_2 = \\epsilon^2, \\\\ b_1 = 1/2 + \\epsilon + \\epsilon^2, \\quad &b_2 = 0, \\\\ c_1 = 0, \\quad &c_2 = 1/2 + \\epsilon + \\epsilon^2, \\\\ d_1 = 0, \\quad &d_2 = 0. \\end{align*}\n\nNote that the following case is easy: if we have an explicit lower bound $b_i \\ge c > 0$ for all $i$, then let $j$ be the index that maximizes $c_i/d_i$, then \\begin{equation} a_j / b_j = c_j/d_j \\ge (\\sum_i c_i)/(\\sum_i d_i) \\ge 1 + \\epsilon. \\end{equation} Hence \\begin{equation} a_i - b_i \\ge c\\epsilon. \\end{equation} Similarly if we have a lower bound for $c_i$. Note that in these cases we don't even need the assumption that $\\sum_i a_i \\ge 1/2 + \\epsilon$.\n\n  \u2022 $\\begingroup$ There is no $d_i$ in that sum: did you mean that, or is it a mistake? Also, are the various conditions understood to hold for all $K \\in \\mathbb N$ (and the sequences to be infinite), or is $K$ fixed? $\\endgroup$ \u2013\u00a0Alex M. Sep 21 '18 at 15:47\n  \u2022 $\\begingroup$ Even though this problem has a pretty simple solution, I think it is nontrivial and somewhat intriguing. So, I don't understand the down vote. $\\endgroup$ \u2013\u00a0Iosif Pinelis Sep 21 '18 at 17:38\n\n\nIt is not hard to show (see the proof at the end of this answer) that for any real $a,b,c,d\\ge0$ such that $ad=bc$ we have \\begin{equation}\\tag{1} |a-b|+|a-c|\\ge a-d. \\end{equation} Replacing here $a,b,c,d$ by $a_i,b_i,c_i,d_i$ and summing in $i$, we have \\begin{equation} \\sum_i (|a_i - b_i| + |a_i - c_i|)\\ge\\sum_i a_i-\\sum_i d_i\\ge2\\ep, \\end{equation} as desired. (The conditions that $\\sum_i b_i, \\sum_i c_i \\ge 1/2 + \\ep$ were not needed or used here.)\n\nProof of (1). If $a=0$, then $a-d\\le0$, so that (1) holds. So, without loss of generality (wlog), $a>0$, whence $d=bc/a$ and $a-d=(a^2-bc)/a$. So, wlog $a^2>bc$ and hence $a\\ge b\\wedge c$. Also, wlog $c\\le b$. So, one of the following two cases takes place.\n\nCase 1: $0\\le c\\le b\\le a$. Here (1) can be rewritten as $$f(a,b,c):=a-b-c+bc/a\\ge0,$$ which follows because $f(a,b,c)$ is nonincreasing in $b$ (given that $c/a\\le1$) and hence $f(a,b,c)\\ge f(a,a,c)=0$. So, (1) holds in Case 1.\n\nCase 2: $0\\le c\\le a\\le b$. Here (1) can be rewritten as $$g(a,b,c):=b-c+bc/a-a\\ge0,$$ which follows because $g(a,b,c)$ is nondecreasing in $b$ and hence $g(a,b,c)\\ge g(a,a,c)=0$. So, (1) holds in Case 2 as well.\n\nInequality (1) is completely proved.\n\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/53971/example-of-sequences-with-different-limits-for-two-norms/53978\nText:\nI was explaining to my students that if there is an inequality between two norms, then there is an inclusion between their spaces of convergent sequences, with matching limits. I then proceeded to show examples of such inequalities on the normed spaces they knew, and counterexamples of sequences which converge for a norm and not for another, stating the equivalence of norms in finite dimension, etc.\n\nIt is then that I wondered about the following : does there exist a vector space, two norms on that vector space and a single sequence which converges for both norms, but with different limits?\n\nThe first remark is that such a counter-example cannot exist in finite dimension ; and one first has to find \"really inequivalent norms\", which do exist : consider the space of polynomials in one variable, and define norms on it by summing the absolute values of the coefficients :\n\n  \u2022 first with a weight $1$ for every coefficient ;\n  \u2022 second with $2^n$ or $2^{-n}$ depending on the parity of the degree $n$.\n\nIt's now easy to find a sequence going to zero for the first and not for the second, and a sequence going to zero for the second and not for the first - so there can't be an inequality between those.\n\nNotice this is all over the real or complex numbers, though the question could be amusing in a more general setting.\n\n  \u2022 2\n    $\\begingroup$ In Koblitz's book on p-adic analysis, in the chapter on power series, he gives an example of an infinite series of rational numbers which converges in both R and some Q_p (maybe p = 2?) and the limits are different rational numbers. Using Zorn's lemma, Q_p can be embedded into C and the p-adic abs. value on Q_p can be extended to an absolute value on C. Therefore C, as a vector space over Q, equipped with its usual absolute value and a (non-constructive) extension of the p-adic absolute value, admits a sequence which converges for both norms, but with different limits. $\\endgroup$ \u2013\u00a0KConrad Feb 2 '11 at 4:27\n  \u2022 $\\begingroup$ That's another interesting example ; even higher level than Bill Johnson's, but good. $\\endgroup$ \u2013\u00a0Julien Puydt Feb 2 '11 at 11:30\n  \u2022 $\\begingroup$ Dear Julien Puydt, As you said:\" consider the space of polynomials in one variable, and define norms on it by summing the absolute values of the coefficients : first with a weight 1 for every coefficient ; second with 2n or 2\u2212n depending on the parity of the degree n.\" Could define the sequence so that the two limit in these two different norms are different ? Thanks a lot! $\\endgroup$ \u2013\u00a0zhongjie Sep 11 '15 at 8:53\n  \u2022 $\\begingroup$ @zhongjie: defining a single sequence with two different limits for two different norms is precisely what the question is about! $\\endgroup$ \u2013\u00a0Julien Puydt Sep 11 '15 at 14:55\n\nConsider the space $X$ of trigonometric polynomials (with period $1$, say). Choose the norms $$\\|f\\|_1=\\sup\\{|f(x)|;\\frac16\\le x\\le\\frac13\\},\\qquad \\|f\\|_2=\\sup\\{|f(x)|;\\frac23\\le x\\le\\frac56\\}.$$ Now consider the partial sums $f_N$ of the Fourier series of the periodic function $F$ defined by $F(x)=0$ if $x\\in(0,1/2)$ and $F(x)=1$ if $x\\in(1/2,1)$. In the first norm, $f_N$ converges to $g\\equiv0$, whereas in the second one, $f_N$ converges to $h\\equiv1$.\n\nRemark that $F$ does not belong to $X$, but this has no importance at all. Perhaps it is even natural in order to construct practical examples.\n\n  \u2022 $\\begingroup$ A remark: I do get the feeling (with your last paragraph in mind), this example is showing more that for a fixed vector space $X$ and two different norms w.r.t. which $X$ is not complete, the completion of $X$ by the two norms are not necessarily the same. $\\endgroup$ \u2013\u00a0Willie Wong Feb 1 '11 at 13:55\n  \u2022 $\\begingroup$ @Willie. Of course they aren't. If a sequence has two distinct limits for two norms, then these norms are not comparable. Not only the completions are distinct, but there is not natural embedding from one to the other. Here the completions are $C([1/6,1/3])$ and $C[2/3,5/6])$ thanks to Stone-Weierstrass. $\\endgroup$ \u2013\u00a0Denis Serre Feb 1 '11 at 14:05\n  \u2022 $\\begingroup$ @Denis: I don't think I phrased my remark quite the way I meant to. Let me try again (hope you don't mind). I guess what I am trying to say is similar to the point you just made in the comments. What I think I want to say is that I think there is a conceptual difference (which may just be something that is in my head only) between a set $E$ and two topologies $T,S$, and a sequence such that $x_k \\to x$ in $(E,S)$ and $x_k \\to y$ in $(E,T)$ with $x\\neq y$, $x,y\\in E$; and the case of two sets $X,Y$ such that $X\\cap Y = E$, a topology $S$ on $X$, a topology $T$ on $Y$, and a sequence $(x_k)$ $\\endgroup$ \u2013\u00a0Willie Wong Feb 1 '11 at 14:28\n  \u2022 1\n    $\\begingroup$ Instead of $X$ (in the answer), it seems that you could easily take a much more general space---for example, the space of bounded real functions. Then you don't need the remark in the last paragraph. $\\endgroup$ \u2013\u00a0John Bentin Feb 3 '11 at 22:25\n  \u2022 1\n    $\\begingroup$ In a late response to John Bentin's comment, if $X$ were replaced by the space of bounded real functions, then the norms would only be seminorms, and would not satisfy $\\|x\\|=0\\implies x=0$. Limits would not be unique. $\\endgroup$ \u2013\u00a0Jonas Meyer Dec 5 '12 at 14:50\n\nNote first that your example spaces cannot give what you want because in both spaces the coordinate evaluation functionals are continuous and separate points.\n\nExamples are easy. Take in $\\ell_2$ a linearly independent sequence that converges to a non zero vector, such as $x_n := e_1 + n^{-1}e_n$, $n=2,3,...$. Map $x_n$ to $n^{-1}e_n$ in $\\ell_2$ and extend to a linear isomorphism from $\\ell_2$ onto $\\ell_2$.\n\n  \u2022 $\\begingroup$ The moral of this is \"Any independent sequence can be made to converge to zero\". $\\endgroup$ \u2013\u00a0Ewan Delanoy Feb 1 '11 at 13:04\n  \u2022 $\\begingroup$ The first note is nice -- my norms weren't smelling good and I didn't know why ; now I know! I should have thought about it. For your example, I'm not sure I got everything ; I assume $e_n$ is the sequence which takes the value $1$ in rank $n-1$ (where $n\\geq1$) and zero elsewhere. The family $(e_n)_{n\\geq1}$ is orthonormal and generates a dense subspace. The family $(x_n)_{n\\geq1}$ generates the same subspace, and is free. Good. $\\endgroup$ \u2013\u00a0Julien Puydt Feb 1 '11 at 20:44\n  \u2022 $\\begingroup$ I can then define a linear operator on that subspace like you explain. If I can extend it to the whole space and keep it injective, I guess I'll be able to skew the usual norm with that. But it's not clear how I'll extend it... $\\endgroup$ \u2013\u00a0Julien Puydt Feb 1 '11 at 20:45\n  \u2022 1\n    $\\begingroup$ You just take $A$ and $B$ so that $A\\cup (x_n)$ and $B \\cup (e_n)$ are Hamel bases for $\\ell_2$, map $A$ one to one onto $B$, and extend linearly. $\\endgroup$ \u2013\u00a0Bill Johnson Feb 1 '11 at 21:14\n  \u2022 $\\begingroup$ Ah, so you were thinking about an algebraic extension - I was wondering if you hadn't something like the density in mind, in which case it was more problematic. Good! $\\endgroup$ \u2013\u00a0Julien Puydt Feb 1 '11 at 21:28\n\nI was given IRL another beautiful answer to that question, and thought it would be nice to share.\n\nConsider the space $\\mathbb{K}[X]$ and a polynom $Q\\neq0$ of degree $m$ ; define a new basis for the space by considering $\\mathcal{B}_Q=1,X,\\dots,X^m,X^{m+1}-Q,X^{m+2}-Q,\\dots$, then a norm by $N_Q(P)=\\sup_{n\\in\\mathbb N}\\frac1{2^n}|a_n|$ where $(a_n)_{n\\in\\mathbb{N}}$ are the coefficients of $P$ in $\\mathcal{B}_Q$.\n\nThe same sequence $(X^n)_{n\\in\\mathbb{N}}$ now converges to $Q$ for $N_Q$ for each $Q\\neq0$.\n\n\nJust thinking out loud - this could be totally irrelevant - you can find a sequence of integers $b_0,b_1,\\dots$ such that $0\\le b_i\\le4$ and $(b_0+5b_1/7+25b_2/49+\\dots+5^nb_n/7^n)^2\\equiv-1\\pmod{5^{n+1}}$. That makes the series $b_0+5b_1/7+25b_2/49+\\dots$ converge, in the 5-adic norm, to a number whose square is minus one. In the usual norm on the rationals, the series converges to some real number, most assuredly not a square root of minus one.\n\n  \u2022 $\\begingroup$ Well, it's not 100% irrelevant, but close. ;-) The original question is over the real or complex numbers. Even the generalization I had in mind in my last sentence didn't involve touching the valuation of the base field to find a (counter)example, but merely going over to other base fields. $\\endgroup$ \u2013\u00a0Julien Puydt Feb 1 '11 at 11:50\n  \u2022 $\\begingroup$ Similarly irrelevant examples can be found by considering ${\\mathbb Q}(\\sqrt{2})$, with two inequivalent topologies defined by the induced topology on either ${\\mathbb R}$ or ${\\mathbb R}^2$. $\\endgroup$ \u2013\u00a0B R Feb 1 '11 at 18:17\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/272850/equipartition-theorem-missing-energy\nText:\nI seem to be unsure about a discrepancy in energy conservation utilizing the equipartition theorem. Let's say I have a molecule within a thermal reservoir. For example, I will use a molecule of $NH_3$. I will assume that the temperature of reservoir is sufficiently high enough that the high temperature limit can be assumed for the thermodynamical ensembles and molecule's internal energy will be share equally among its degrees of freedom. Specifically, I will focus on its translational, vibrational, and rotational motions.\n\nAccording to the equipartition theorem, $NH_3$ should have three translational degrees of freedom (each of which gives $\\displaystyle \\frac{1}{2} k_B T$\n\n$$U_{tr}=\\frac{3}{2} k_B T$$\n\nSimilarly for rotational energy\n\n$$U_{rot}=\\frac{3}{2} k_B T$$\n\nAnd for a polyatomic molecule such as $NH_3$, there are $3N-6$ vibrational degrees of freedom each of which give energy $k_B T$ which gives\n\n$$U_{vib}=6 k_B T$$\n\nTherefore the total energy of the $NH_3$ molecule is\n\n$$U_{tot}=9 k_B T$$\n\nNow what if the $NH_3$ molecule completely dissociates so that\n\n$$NH_3 \\rightarrow N + 3H$$\n\nNow we only have 3 translational degrees of freedom for each of the 4 atoms. This gives a total internal energy of the system to be\n\n$$U_{tot}=6 k_B T$$\n\nOf course due to energy conservation this energy must have gone somewhere. My question therefore is, where did the extra $3 k_B T$ worth of energy go? My best guess would be that it either was lost as heat to the surroundings when the bonds were broken or it went into the actual dissociation of the molecule. Would I be correct in any of these assumptions?\n\n\nConsider the simpler case of a diatomic molecule where there is just one degree of freedom. The potential energy as a function of bond length will look something like this:\n\n\nNear the minimum the potential is approximately quadratic, that is:\n\n$$ V(x) = kx^2 $$\n\nfor some effective force constant $x$. So if we want to make our molecule vibrate we have to (1) give the atoms some kinetic energy and (2) give them some extra potential energy. For any potential $V(r)=ar^n$ the kinetic energy $T$ and potential energy $V$ are related by the virial theorem:\n\n$$ 2T = nV $$\n\nso for a quadratic potential where $n=2$ we end up with $T=V$. And this is why the energy associated with a vibrational mode is $kT$ not $\\tfrac{1}{2}kT$, because for every $\\tfrac{1}{2}kT$ we add as kinetic energy we have to add another $\\tfrac{1}{2}kT$ as potential energy.\n\nHowever as we climb out of the potential well to large interatomic distances the potential flattens out and eventual becomes independent of distance, i.e. $n=0$ in our equation above, so now we just need to add kinetic energy without needing to add any potential energy at the same time, and the energy becomes just $\\tfrac{1}{2}kT$ i.e. the same as a free particle.\n\nSo that extra $\\tfrac{1}{2}kT$ of energy went into climbing out of the potential well.\n\n  \u2022 $\\begingroup$ I'm not convinced by the last sentence. What does $kT/2$ have to do with the height of the potential well? Can't it be arbitrarily higher or lower? $\\endgroup$ \u2013\u00a0knzhou Aug 6 '16 at 15:53\n\nThe 6$k_BT$ for the whole body (NH$_3$) and for the separated atoms is the same. In calculating this value for ammonia (translation + rotation) one considers only that the atoms move as a group. Only when using 3N-6 does the internal dynamics of a molecule come in, i.e. vibrating bonds. Thus the difference in energy (3k$_B$T) is that needed to break the bonds, i.e. to take the molecule from its potential well to separate atoms. Each of the three normal vibrational modes account for k$_B$T, (1/2)k$_B$T each for potential & kinetic energy, which make up the difference. (Each squared term in the energy (potential & kinetic) equates to (1/2)k$_B$T via the Virial Theorem)\n\n(Even if the potential energy is not harmonic and thus a different relationship between kinetic and potential energy is given by the virial theorem, when the energy from 3N-6 modes was calculated a harmonic potential was assumed, because the energy is (1/2)k$_B$T, thus it is ok to assume this when bonds are broken. Clearly if a different potential was used the energy would be different, but must still cancel when the bond is broken as the potential has to be the same.)\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/314063/conservation-of-angular-momentum-exercise?noredirect=1\nText:\nA disk of radius $R$ and moment of inertia $I_1$ rotates with angular velocity $\\omega_0$. The axis of a second disk, of radius $r$ and moment of inertia $I_2$ is at rest. The axes of the two disks are parallel. The disks are moved together so that they touch. After some initial slipping the two disks rotate together. Find the final rate of rotation of the smaller disk.\n\n\n\n$L_{1_0} = L_1 + L_2 \\rightarrow I_1\\omega_0 = I_1\\omega_1 + I_2\\omega_2$\n\n$\\omega = \\frac{v}{r} \\rightarrow v = \\omega r$\n\n$\\omega_1 R = \\omega_2 r \\rightarrow \\omega_1 = \\frac{r}{R}\\omega_2$\n\n$I_1\\omega_0 = I_1\\frac{r}{R}\\omega_2 + I_2\\omega_2 \\rightarrow \\omega_2 = \\frac{I_1\\omega_0}{\\frac{r}{R}I_1 + I_2}$\n\n$$\\omega_2 = \\frac{I_1\\omega_0}{\\frac{r}{R}I_1 + I_2}$$\n\n\nIs my solution correct? If not, where and why?\n\n  \u2022 $\\begingroup$ Angular momentum cannot be conserved as is assumed in your solution. The system starts with the clockwise angular momentum of disc 1. After contact with disc 1, disc 2 has to have an anti-clockwise angular momentum. To conserve angular momentum disc 1 would need to rotate faster in the clockwise direction which is impossible as then the kinetic energy of the system of two discs would increase with no input of energy. $\\endgroup$ \u2013\u00a0Farcher Feb 23 '17 at 8:14\n\nFront view of two disks\n\nLooking at the system above, you can write for the left disk $$I_2 \\dot{\\omega_2}=Fr$$ and for the second one $$I_1 \\dot{\\omega_1}=FR$$ where $F$ is the (unknown) friction force. Getting $F$ from the second equation $$F=\\frac{I_1}{R} \\dot{\\omega}_1$$and putting in the first we get $$\\frac{I_2}{r} \\dot{\\omega}_2-\\frac{I_1}{R}\\dot{\\omega}_1=0$$ This means that tha quantity $$\\frac{I_2}{r} \\omega_2-\\frac{I_1}{R}\\omega_1$$ is conserved. Setting it equal to the initial value we obtain $$\\frac{I_2}{r} \\omega_2-\\frac{I_1}{R}\\omega_1=-\\frac{I_1}{R}\\omega_0$$\n\nIn the final situation there is no slipping, so $\\omega_2 r=-\\omega_1 R$ and substituting $\\omega_1$ in the previous equation we get $$\\frac{R I_2}{r} \\omega_2+\\frac{r I_1}{R}\\omega_2=-I_1\\omega_0$$ which gives the final solution $$\\omega_2=-\\frac{I_1 r R }{R^2 I_2+r^2 I_1}\\omega_0$$ The angular momentum of the system is not conserved because there are external forces applied on the axes of the disks, and they apply a torque on the system.\n\n  \u2022 $\\begingroup$ In think this derivation using the friction force between the wheels and assuming that the axes of the disks are fixed and don't start to rotate around each other is correct. When the whole experiment is done in free space with a device for the pivots of the axes of known (or negligible) moment of inertia the conservation of angular momentum can probably still be used leading to an additional rotation of the axes of the disks around each other. $\\endgroup$ \u2013\u00a0freecharly Feb 23 '17 at 5:00\n  \u2022 1\n    $\\begingroup$ How is the angular momentum not conserved .....The disks was rotating and it sets the other in rotation. A angular momentum should be conserved about the center of mass. $\\endgroup$ \u2013\u00a0Shashaank Feb 23 '17 at 12:08\n  \u2022 $\\begingroup$ This is not an isolated system, there are external torques acting on it. $\\endgroup$ \u2013\u00a0GCLL Feb 23 '17 at 16:48\n  \u2022 $\\begingroup$ @Shashaank There are forces acting on the axles equal in magnitude to the frictional forces. $\\endgroup$ \u2013\u00a0Farcher Feb 23 '17 at 22:45\n  \u2022 $\\begingroup$ @GCLL Sorry , I couldn't understand . Could you tell which force in particular is giving the torque $\\endgroup$ \u2013\u00a0Shashaank Feb 24 '17 at 5:31\n\nThe solution is not correct because the angular velocities must have opposite signs after contact. Thus $$\\omega_1 = -\\frac{r}{R}\\omega_2$$ which yields the correct angular velocity of the smaller disk $$\\omega_2 = \\frac{I_1\\omega_0}{I_2-\\frac{r}{R}I_1}$$\n\n  \u2022 $\\begingroup$ Good point. I totally missed that. However, could there be more errors? The answer in the book is $\\omega_2 = \\frac{rRI_1}{r^2I_1+R^2I_2}$ (the book's answer could be wrong; it's had mistakes before). $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:30\n  \u2022 $\\begingroup$ @Sir Jony - There seems to be a problem with the use of conservation of angular momentum. When you assume equal disks, there can be no solution because then both disks rotate in opposite sense which always should result in total angular momentum zero. The formula in you comment is dimensionally incorrect, probably a factor $\\omega_0$ is missing. $\\endgroup$ \u2013\u00a0freecharly Feb 22 '17 at 20:46\n  \u2022 $\\begingroup$ Right, I forgot to multiply the RHS by $\\omega_0$. Thanks for catching that. $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:55\n  \u2022 $\\begingroup$ @Sir Jony - In order to get the correct answer you have probably to consider that the contact of the disks in the described manner will also produce a rotation of the disk axes around each other. Otherwise the paradox mentioned above likely cannot be resolved. $\\endgroup$ \u2013\u00a0freecharly Feb 22 '17 at 20:58\n  \u2022 $\\begingroup$ I assume that the axes simply represent pivot points. Other than that, I think they're meant to be ignored. $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:59"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/258765/how-to-determine-if-a-signal-path-needs-to-be-treated-as-a-transmission-line\nText:\nI remember reading this somewhere but cannot find the ratio of the rise time vs. the propagation time (i.e. the trace length?) of a signal when transmission line effects come into effect?\n\nFor example - if I have a SPI bus running at 12.5MHz. If it runs a few inches through the PCB trace, it is not a transmission line - but at what length goes it become a transmission line (at least in theory). How to calculate that?\n\n  \u2022 \\$\\begingroup\\$ It is somewhat arbitrary and may depend on what you are trying to accomplish. \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 2:50\n  \u2022 \\$\\begingroup\\$ I am trying to determine what reflections I might get. I have a SPI master and I want to run it at 12.5MHz over about 5\" of FR4 PCB trace and about 6 feet of 26awg wire. I dont know if that is even possible and how to do it. \\$\\endgroup\\$ \u2013\u00a0user1406716 Sep 20 '16 at 2:52\n  \u2022 \\$\\begingroup\\$ It will probably work. Use a dedicated GND wire for each signal wire and twist the signal with the GND. Add a series resistor on the source board (start with 0 Ohms, and change it if needed) and an AC termination on the receive board. AC termination is a cap and resistor in series. For MOSI, add the series resistor on the master, and AC termination on the slave. For MISO add series resistor on the slave board, and AC termination on the master. Don't install any AC termination to start. You might not need it. Clock is same as MOSI. \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 2:59\n  \u2022 \\$\\begingroup\\$ pericom.com/assets/App-Note-Files/AB023.pdf \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 3:00\n  \u2022 \\$\\begingroup\\$ In theory, it is a transmission line at any length. Termination always works, but sometimes you can leave it out and ignore the resulting overshoot/ringing. \\$\\endgroup\\$ \u2013\u00a0Whit3rd Sep 20 '16 at 4:37\n\nThe boundary between lumped and distributed systems is not clear-cut but there are some commonly used values. For distributed systems transmission line theory is required.\n\nThe distinction is usually made based on the effective length of a signal or the feature of a signal like an edge. So it's important to consider the rise- and fall time of a signal and not the frequency. Nevertheless the frequency imposes an upper limit on the risetime.\n\nIn air a signal travels with about 85ps/in (~ 33ps/cm). The propagation delay depends on the dielectric constant, it is proportional to the square root of it. For a PCB with a dielectric constant of 4 (like FR4 which is in the range of 3 to 5) the propagation delay doubles.\n\nA rising edge with a risetime of 1ns would occupy a trace length of 1ns/(2*85ps) ~ 6in (~ 15cm). At the driving side the signal is already high when at a 6in distance it just starts to rise.\n\nSo a 6in (15cm) track clearly is too long, since the potential varies from low to high along the track.\n\nIf the length of the track is between 1/6 or 1/4 of the effective length of a feature like an edge a system can be regarded as lumped.\n\nSo the upper limit for the example given above is between 6in / 6 (= 1 in, ~2.5cm) and 6in /4 (= 1.5in, ~4cm) for a trace on a PCB with a dielectric constant of 4.\n\n\nFor analog signals (sine waves, let's say), the rule of thumb I was taught is when the line length is 1/8 of the wavelength, you should treat it as a transmission line. Practically speaking, the propagation speed of an electromagnetic wave is determined by the dielectric the wave is traveling in. For PCB's it is typically around C/2, where C is the speed of light in space. Your wavelength will be shorter by the same scale factor (wavelength in free space / 2). So a 100 MHz signal would be 3 meters in free space. 1.5 meters in a PCB. And 1/8 of that is 18.75 cm.\n\nFor digital signals, there are several alternative ways to look at it. One way is rise time and bandwidth. The basic idea is, you use the rise time to estimate the bandwidth, then use the analog signal rule above, but with the bandwidth as the frequency. The justification for this is that the wave can be somewhat accurately reproduced provided that you have the majority of the BW. So the highest significant frequency in the signal is given by the BW.\n\nThe rule of thumb I have seen is that BW = 0.35/TR. BW is bandwidth in GHz, and TR is rise-time in nanoseconds. This formula uses the 10/90 rise time. So if your rise time is 10 ns, then your BW is 0.35/10 = 0.035 GHz = 35 MHz.\n\nAnother way to look at it is that you want the round trip flight time of your signal to be substantially less than your rise time. This means that the reflections will return to the source while the signal is still rising or falling. Reflections like this will not cause the rising and falling edges to be jagged or have \"shelves\" on them. They will still be smooth.\n\nHope this helps.\n\n  \u2022 \\$\\begingroup\\$ Thank you. This is the kind of 'rule of thumb' i was looking for. \\$\\endgroup\\$ \u2013\u00a0user1406716 Sep 22 '16 at 4:29\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1750532/alpha-exists-so-that-for-any-points-x-n-there-is-a-point-at-average-distanc\nText:\nLet $X$ be a connected and compact metric space. Prove a real number $\\alpha$ exists so that for every finite set of points $x_1,x_2,\\dots, x_n\\in X$ (not necessarily distinct) there exists $x\\in X$ such that:\n\n$\\dfrac{d(x_1,x)+d(x_2,x)+\\dots + d(x_n,x)}{n}=\\alpha$\n\n  \u2022 $\\begingroup$ Seems like something to do with the intermediate value theorem applied to a finite sum of metrics. $\\endgroup$ \u2013\u00a0Rick Sanchez Apr 20 '16 at 2:22\n  1. Let us prove the statement for a fixed $n$. Denote$$f_n(x_1,x_2,\\ldots,x_n,x) = \\frac{d(x_1, x) + d(x_2, x) + \\ldots + d(x_n, x)}{n},$$$$M(x_1,x_2,\\ldots,x_n)=\\max_{x\\in X}f_n(x_1,x_2,\\ldots,x_n, x),$$$$m(x_1,x_2,\\ldots,x_n)=\\min_{x\\in X}f_n(x_1,x_2,\\ldots,x_n,x),$$and let $I(x_1, x_2, \\ldots, x_n)$ be the closed interval $[m(x_1, x_2, \\ldots, x_n), M(x_1, x_2, \\ldots, x_n)]$. If we prove all the intervals $I(x_1, x_2, \\ldots, x_n)$, $x_i \\in X$ have a common point, we are done. To prove it, it is enough to establish any two of them have a common point, by Helly's theorem combined with the finite intersection property of a family of compact sets. Arguing by contradiction suppose $I(x_1, x_2, \\ldots, x_n)$ and $I(y_1, y_2, \\ldots, y_n)$ do not intersect and let $a$ be a real number that separates them. Suppose without loss of generality that$$f_n(x_1, x_2, \\ldots, x_n, x) < a < f_n(y_1, y_2, \\ldots, y_n, y) \\text{ for all }x,y \\in X.$$Now, in the first inequality substitute consecutively $x = y_1$, $x = y_2$, $\\ldots$ , $x = y_n$ and sum the terms. Then do the same with the second one substituting $y = x_1$, $y = x_2$, $\\ldots$ , $y = x_n$. We get that one and the same sum is both less and greater than $a$, a contradiction. Thus all the intervals have a common intersection, which is a nonempty interval $I_n$.\n  2. We prove all $I_n$, $n \\in \\mathbb{N}$ have a common point. Again, it is enough to prove it for any two of them. Let us first observe that$$m \\mid n \\implies I_n \\subset I_m.$$Indeed let $c \\in I_n$ and let $x_i \\in X$, $i = 1, 2, \\ldots, m$. Then we get $k$ copies of each $x_i$, $i = 1, 2, \\ldots, m$, where $k \\cdot m = n$ and apply what $c \\in I_n$ means for the new $n$ points in $X$. Using that observation, for any $m$, $n$ we have$$I_{mn} \\subset I_m, \\quad I_{mn} \\subset I_n,$$which means $I_n$, $I_m$ have nonempty intersection. Thus, all $I_n$ have nonempty intersection and any $\\alpha$ inside that intersection will do the job.\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/3776/how-to-view-diff-when-emacs-suggests-to-recover-this-file\nText:\nSometimes it happens: emacs prompts you about recovering unsaved changes to a file, but you cannot remember if you want those changes or not.\n\nStarting at the recover-this-file buffer, is there a way to view a diff or otherwise directly see the changes?\n\nFor example, something like what magit-mode gives when tabbing on a edited file in the status buffer.\n\n\nAfter running recover-this-file and accepting the autosave version, you'll have a modified buffer containing the autosave contents. At this point you can use M-x diff-buffer-with-file RET to see the differences between the modified buffer and the saved file.\n\nThe key I've bound for this actually runs a custom function, in order to produce a unified diff, and to skip the prompt for the buffer (it assumes the current buffer).\n\n(defun my-diff-buffer-with-file ()\n  \"Compare the current modified buffer with the saved version.\"\n  (let ((diff-switches \"-u\")) ;; unified diff\n    (diff-buffer-with-file (current-buffer))))\n\nThere's also an ediff equivalent (which I generally prefer, although I do use both) which is available at M-x ediff-current-file RET\n\nIf you wish to reject the modifications after checking the diff, you should be able to simply undo the recovery. (Failing that you can always use revert-buffer or find-alternate-file.)\n\nAs keybindings for diff commands often involve =, I find the following convenient (n.b. I've unbound the default C-z binding, and moved it instead to C-z C-z, which opens up C-z as a prefix for custom bindings):\n\n(global-set-key (kbd \"C-z =\") 'my-diff-buffer-with-file)\n(global-set-key (kbd \"C-z C-=\") 'ediff-current-file)\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/35571/3-2-approximation-probabilistic-algorithm-for-max-3-color\nText:\nI have a textbook question here regarding Max-3-Coloring and need some assistance with it. I have searched for any type of information regarding it but haven't found anything substantial. Here is the question:\n\nIn MAX-3-COLOR you are given a graph $G=(V,E)$ and your goal is to find a coloring of the vertices with only 3 colors $c: V \\rightarrow [3]$ that maximizes the quality function $q(c)$ - The number of edges whose endpoint vertices are colored with different colors:\n\n$\\sum_{(i,j)\\in E} (1_{c(i) \\neq c(j)})$\n\nGive a probabilistic $3/2$-approximation algorithm. (i.e $q(c)\\geq 2/3 \\cdot OPT$ with probability at least $1-\\frac{1}{e^{k}}$ for any $k \\in \\mathbb{N}$\n\nOK so up until now the textbook only talks about one probabilistic algorithm which fits the requirements - MAX-3-SAT. The textbook gives a probabilistic $8/7$ - approximation algorithm for it (for every literal, toss a fair coin and decide whether to set it to $True$ or $False$).\n\nI also found several other sources which prove that the 3-COLOR is NP-Complete by reducing it to the 3-SAT problem. Thus I am pretty confident that MAX-3-SAT is the way to go.\n\nAccording to this thread: 3 Colorability reduction to SAT I thought about doing the same thing:\n\nFor every $x \\in V$ create three literals: $x_1, x_2, x_3 \\in \\{{True, False}\\}$ where each literal denotes if said vertex $x$ is colored with color $i$.\n\nThen for every edge $e =(x,y)\\in E$ create the following 3-CNF formula $\\varphi$:\n\n$ \\varphi_e = (\\urcorner x_1 \\vee \\urcorner y_1 \\vee \\urcorner y_1) \\wedge (\\urcorner x_2 \\vee \\urcorner y_2 \\vee \\urcorner y_2) \\wedge (\\urcorner x_3 \\vee \\urcorner y_3 \\vee \\urcorner y_3) \\wedge (x_1 \\vee x_2 \\vee x_3)$\n\nAnd the final formula $\\phi$ is:\n\n$\\phi = \\bigwedge_{e \\in E} \\varphi_e$\n\nEvery 3-CNF formula for an edge makes sure that the two endpoints are not of the same color and that one of them is either color 1, 2 or 3.\n\nThe thing is I don't see how this would help me. This gives me a MAX-3-SAT problem since I have a 3-CNF formula for every edge and one big 3-CNF formula for the whole graph. So technically I could use the same algorithm that was given in the textbook before\n\nBut wouldn't using the same probabilistic probabilistic $8/7$ - approximation algorithm for the MAX-3-SAT give the exact same approximation? whereas I wish to achieve a $3/2$- approximation\n\nThanks to anyone who helps!\n\n\nIf you simply uniformly at random (i.i.d) color each of the vertices of $V$ by each of the three possible colors, then for every edge $e\\in E$, it's endpoint will be colored by different colors w.p. $\\frac{2}{3}$, hence the expected quality of the random coloring is exactly $\\frac{2|E|}{3}$. We know that the optimal quality is at most $q^*\\leq |E|$, hence this is a $\\frac{3}{2}$ approximation.\n\n  \u2022 $\\begingroup$ This is a $3/2$-approximation in expectation. To get the high probability result required by the original question, you need to run this algorithm several times and return the best of the resulting colorings. $\\endgroup$ \u2013\u00a0JeffE May 28 '17 at 20:36\n\nConsider the greedy algorithm that loops through the vertices in arbitrary order and assigns each vertex $v$ the least popular color among its previously-colored neighbors. Each vertex $v$ gets a different color than at least $2/3$ of its neighbors, so the quality of the greedy coloring is at least $2|E|/3$. The optimal quality is trivially at most $|E|$, so the greedy coloring is always a $3/2$-approximation. (In particular, the greedy coloring is a $3/2$-approximation with probability at least $1-e^{-k}$ for any integer $k\\in \\mathbb{N}$.)\n\n(You might object that this is not a probabilistic algorithm. Okay, whatever. In a preprocessing phase, generate a random permutation of the colors, and use this permutation to break ties in the greedy algorithm. Alternatively, flip 42 independent fair coins, and if they all come up heads, do ten jumping jacks and a lap around the football field before running the greedy algorithm.)\n\n  \u2022 $\\begingroup$ This is just the derandomization of the algorithm in the other answer, using the method of conditional expectations. $\\endgroup$ \u2013\u00a0Yuval Filmus May 28 '17 at 21:32\n  \u2022 $\\begingroup$ @YuvalFilmus In retrospect, sure. But that's not the easiest way to think about it. $\\endgroup$ \u2013\u00a0JeffE May 28 '17 at 21:35\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/143087/is-mcgees-counterexample-to-modus-ponens-accepted-by-the-mathematical-community/143093\nText:\nIn the mid 1980's Vann McGee proposed a counterexample to Modus Ponens:\n\n(a) If a Republicans will win the election, then if Reagan will not win, Anderson will win. (b) A Republican will win the election. (c) So, if Reagan will not win, Anderson will win.\n\nChristian Piller describes it here: \"[McGee's] attempt to show that modus ponens is not a valid form of inference - and to show this by the help of a counterexample and not by envisaging an evil demon confusing us - is proof of the ingenuity of a philosopher's ability to doubt.\"\n\nJohn MacFarlane here lists two additional statements of the same type:\n\n(a) If that creature is a \ufb01sh, then if it has lungs, it is a lung\ufb01sh. (b) That creature is a \ufb01sh. (c) So, if it has lungs, it is a lung\ufb01sh.\n\n(a) If Uncle Otto doesn\u2019t \ufb01nd gold, then if he strikes it rich, he will strike it rich by \ufb01nding silver. (b) Uncle Otto won\u2019t \ufb01nd gold. (c) So, if Uncle Otto strikes it rich, he will strike it rich by \ufb01nding silver.\n\nModus Ponens permeates all of mathematics yet the counterexample seems primarily discussed in the philosophical literature. Is it accepted in the mathematical community? Is there a precise, mathematical restatement (eg, in terms of set theory or categorical) - free of subject-matter - that everyone can agree on? Or does it lead to a no-mans land of disputed interpretations?\n\nRecall, proof of the conditional A --> B doesn't require A to be true. But the detachment of B as a true consequence the only follows via Modus Ponens, which requires the antecedent of a conditional to be true.\n\nLawvere & Rosebrugh write in Sets for Mathematics that substitution, correctly objectified, is composition.\n\nIf McGee's counterexample is valid, it would seem that substitutions of the form A --> (B --> C) are a \"transitivity trap\" so to speak.\n\n  \u2022 49\n    $\\begingroup$ I honestly don't see the problem with any of these statements. What is the contradiction/paradox presented here? $\\endgroup$ \u2013\u00a0Thomas Andrews May 9 '12 at 14:56\n  \u2022 5\n    $\\begingroup$ Yes, all these examples are perfectly logically sound, and are consistent Modus Ponens as far as I can tell. In Piller's discussion of the first example he seems to be suggesting that people don't fully believe (b). In other words, while it's true that people believed that if Reagan didn't win, then Carter would (rather than Anderson), if they also believe that a Republican will inevitably win then (c) is fine. It just happens that the case that Reagan doesn't win is (considered) impossible, so the statement is vacuous. $\\endgroup$ \u2013\u00a0mdp May 9 '12 at 15:01\n  \u2022 9\n    $\\begingroup$ Ah, after some search, the point is that the statement \"if Reagan will not win, Anderson will win\" is not obviously true. But modus ponens exists in a universe of facts, and it isn't false in a universe where you know (a) and (b) already. If you don't have the additional facts (a) and (b), then (c) isn't true, but that's the nature of deduction. (c) isn't true absent context, it is dedicble from (a) and (b). $\\endgroup$ \u2013\u00a0Thomas Andrews May 9 '12 at 15:02\n  \u2022 40\n    $\\begingroup$ I am thoroughly baffled by how on earth that is supposed to be even mildly convincing 'counterexample'. $\\endgroup$ \u2013\u00a0Tara B May 9 '12 at 16:01\n  \u2022 13\n    $\\begingroup$ @AsafKaragila To be fair, I don't think that is what MacFarlane (and, by inference, McGee) were doing. They were showing that attempting to carry out modus ponens (as understood mathematically) on certain natural seeming statements leads to counterintuitive results. The lesson is not that philosophers cannot do logic; it's that philosophers care about questions where naive attempts to formalize the reasoning seem problematic. $\\endgroup$ \u2013\u00a0user16299 May 9 '12 at 22:09\n\nIn the first example, it seems like the problem is with an intuition of truth being \"high likelihood.\" You can't start from\n\n(a') If a Republican wins, then if Ronald Reagan doesn't win, Anderson will win\n(b') It is highly likely that a Republican will win\n\nand deduce:\n\n(c') If Reagan doesn't win it is highly likely that Anderson will win\n\nThat certainly is not a valid statement, even if (a') and (b') are true. But it also isn't an application of Modus Ponens.\n\n(For those not old enough to remember, in 1980, the US presidential election was between Reagan, a Republican, Carter, a Democrat, and Anderson, a Republican running as an independent. Anderson was not very likely to win - if Reagan did not win, then it was highly likely that Carter would be the winner. But, given that a Republican was going to win, if Reagan did not win, it was most likely that Anderson would have won.)\n\nVann McGee, then, appears to be unaware of the fact (or just playing qwith it) that the truths used in logic are absolute. Modus Ponens only works if you are careful about your language. If you are lazy about your language, as in all things, logical deduction is useless.\n\nIf you want to deal with degrees of likelihood, you want probability. If you want degrees of truth other than pure \"true\" and pure \"false,\" you want fuzzy logic. Modus Ponens fails in these variants of logic, and it is worth exploring how it fails and what sorts of deductions you can do in these spaces, but it is hardly a failure of modus ponens - it is more a failure of imprecise colloquial language.\n\nThe lungfish example is actually a different sort of error, fundamentally related to the difference between Propositional Logic, in which the only types are propositions, and First Order Logic, in which you can make propositions about \"all\" things. In first order logic, you would write:\n\n(a) For any thing, if the thing is a fish, then if the thing has lungs, then the thing is a lungfish.\n(b) This thing is a fish\n(c) Therefore, if this thing has lungs, then this thing is a lungfish.\n\n(c) Is not the same as saying, \"For any thing, if the thing has lungs, then the thing is a lungfish,\" but rather, a statement about a specific thing about which we have some (possibly incomplete) information.\n\nIf you start with the statements:\n\n(u) For all X, If X won the election, then X is a Republican.\n(v) Y won the election\n\nYou can conclude:\n\n(w) Y is a Republican\n\nBut that doesn't mean that (w) is true for all Y, it only means it is true given the statement (v).\n\nOne of the frequent flaws in elementary logic is that people think \"implication\" actually implicitly means \"for all cases.\" (Often it also is taken to imply causality.) It doesn't. Implication is always about individual instances. The only way you get a \"for all\" added to implication is by explicitly adding that phrase to the sentence. In common language, it often doesn't need to be there. But the meaning in hard logic of the \"P implies Q\" is always about an individual instance, and the only way to make it general is by adding a \"for all\" explicitly to the sentence and adding a variable to the expression.\n\nModus ponens is a purely Propositional Logic statement.\n\nThe symbol $\\forall$ is used to represent \"For all\" in First Order Logic. What you are trying to do is start with the statements:\n\n(a) $\\forall X: P(X)\\implies Q(X)$\n(b) $P(Y)$\n\nand conclude:\n\n(c) $\\forall Y: Q(Y)$\n\nBut that is not how modus ponens of First Order Logic works. You cannot add back the $\\forall$ part of the sentence. What you can do, from (a), and (b) is conclude:\n\n(a') $P(Y)\\implies Q(Y)$ (by the substitution rule for $\\forall$)\n(d) $Q(Y)$ (By modus ponens)\n\n$Q(Y)$ is not the same statement as $\\forall Y: Q(Y)$. $Q(Y)$ is a conclusion given that you've already stated that you know $P(Y)$ is true.\n\n  \u2022 10\n    $\\begingroup$ The lungfish example is pure language error, having nothing to do with grades of truth. The reason (c) appears false in the first example is that it implicitly seems untrue, but that's only if you treat the premise (b) as a high likelihood, rather than as an actual hard truth. If (a) and (b) are absolutely true, then (c) is clearly absolutely true. @alancalvitti $\\endgroup$ \u2013\u00a0Thomas Andrews May 9 '12 at 16:24\n  \u2022 5\n    $\\begingroup$ @alancalvitti You've lost me, and comments aren't a good place to chat. Modus ponens applies to absolutely truths in logic. If your computer system represents individual facts in an absolute sense, you can apply modus ponens to those facts, as long as they mean what you think they mean. If you are not talking about absolute truths, but mere likely truths or fuzzy truths, then you cannot simply apply modus ponens to your set of facts. $\\endgroup$ \u2013\u00a0Thomas Andrews May 9 '12 at 16:46\n  \u2022 2\n    $\\begingroup$ @alancalvitti: Modus ponens is unequivocally valid in Heyting algebras, and in the intuitionistic logic that they algebraise. Intuitionistic logic is not fuzzy logic either. If you want to formalise the lungfish example, look up \"conditional proof\". $\\endgroup$ \u2013\u00a0Zhen Lin May 9 '12 at 17:10\n  \u2022 3\n    $\\begingroup$ @alancalvitti: It does not fail MP, so it is not a counterexample. I can formalise it, but in order to appreciate it, you have to learn some formal logic first. $\\endgroup$ \u2013\u00a0Zhen Lin May 9 '12 at 17:28\n  \u2022 2\n    $\\begingroup$ Since this is a mathematics site, and not philosophy, I'll take your comment as a compliment. @6005 If philosophers use lazy logical term usage, then they'll be pretty shoddy in their reasoning, too. $\\endgroup$ \u2013\u00a0Thomas Andrews Jan 26 '16 at 0:25\n\nTo put it briefly, McGee's \"counterexample\" is not accepted by the mathematical community because it is not, per se, a statement about mathematics. Modus ponens certainly holds in the context of logic, with its absolute interpretations of \"true\" and \"false\", and the references you give acknowledge that. But those authors (who are philosophers, not mathematicians) appear to be considering other possible notions of truth, different from those of logic, which they believe may better describe the way humans routinely think, and noting that modus ponens can fail to hold for those.\n\nSome of those models make sense to describe mathematically, but mathematicians would not confuse those models with plain logical truth, and indeed would probably avoid using the words \"true\" and \"false\" to describe anything else.\n\n  \u2022 $\\begingroup$ Can natural language can be factored out of McGee's counterexample? Thomas's lungfish in particular seems to consist of binary-valued, \"plain logical truth\" statements amenable to conditional proof (thanks to Zhen Lin for the ref). Can you help formalize the lungfish using categories, objects, subobjects and part-of and is-a relations to see if the conditional proof holds? $\\endgroup$ \u2013\u00a0alancalvitti May 9 '12 at 17:26\n  \u2022 5\n    $\\begingroup$ @alancalvitti: The proof obviously holds, and the statement (c) is obviously true (given the assumptions (a) and (b)). What is the contradiction/paradox/problem here? $\\endgroup$ \u2013\u00a0ShreevatsaR May 9 '12 at 17:28\n  \u2022 $\\begingroup$ @ShreevatsaR: I'm confused about what the issue is, too. I think it's that they believe Modus Ponens implies that statement c is true in all cases, not just the cases where b is true. I get the impression that this is the result of philosophers trying to reason about mathematical logic, without first building up the underlying mathematical intuition that we all take for granted. $\\endgroup$ \u2013\u00a0BlueRaja - Danny Pflughoeft May 9 '12 at 19:59\n  \u2022 8\n    $\\begingroup$ I respectfully disagree that philosophers are somehow deficient in logic. Skimming the link to Macfarlane's note, it seems more that they are discussing rules of inference in settings to which mathematical logic cannot always be applied consistently $\\endgroup$ \u2013\u00a0user16299 May 9 '12 at 20:21\n  \u2022 5\n    $\\begingroup$ @BlueRaja-DannyPflughoeft: My opinion is the same as that of Yemon. These philosophers are not trying to reason about mathematical logic. They are reasoning about some other system which looks superficially similar to mathematical logic and uses similar terminology, but is actually very different. (Disclaimer: I know little of philosophy and do not claim to actually understand what they are doing, but this is my understanding so far.) $\\endgroup$ \u2013\u00a0Nate Eldredge May 9 '12 at 21:19\n\nMc Gee's counterexample points one problematic application of classical propositionnal logic to natural language. In general mathematicians are not interested with it because they are happy with classical logic and consider that it gives a correct model of their way to reason. As far as I know, it is not possible to produce the same counterexample applied to mathematical objects. Perhaps it is due to the necessary relations between objects in mathematical sentences.\n\nFor those who do not see any interest in this kind of counterexample, I just want to point that the problematic application of classical logic to reasoning in natural language does not interest only philosophers but also computer scientists and many other researchers. This question concerns non-classical logics, a field perhaps not useful for mathematics but important to other areas as Artificial Intelligence.\n\n\nIt looks to me like McGee is making the following error.\n\nSuppose, for a moment, that $A \\to (B \\to C)$ is a tautology.\n\nBecause of this, we know\n\n$$ A \\vdash B \\to C$$\n\nwhich means, among other things, that\n\n$$\\mathcal{M} \\models A \\quad \\text{implies} \\quad \\mathcal{M} \\models B \\to C$$\n\nHowever, McGee seems to have fallen into a trap of some sort, and is concluding\n\n$$ \\vdash B \\to C$$\n\nwhich is incorrect.\n\n(the other answer does say this too, but in a more verbose language)\n\n\nYour Answer"}
{"text": "Retrieved from https://gamestoday.info/pc/heroes-of-the-storm/can-someone-help-me-with-a-bit-of-ability-damage-math/\nText:\nHeroes of the Storm\n\nCan someone help me with a bit of ability damage math?\n\nHeroesoftheStorm 7 - Can someone help me with a bit of ability damage math?\n\nRight now, I'm working on a big spreadsheet involving damage values and scaling and I want to make sure I'm correctly applying modifiers and scaling (and not screwing up the rounding). The issue I'm running into is with Hanzo's Target Practice and Flawless Technique talents. Storm Bow's level 0 damage is 291, its scaling is the standard 1.04, Target Practice's quest completion provides 100 bonus damage (non-scaling), and Flawless Technique grants a modifier of .3 to Storm Bow. Here's some of the XML pertaining to this:\n\n <CEffectDamage id=\"HanzoStormBowDamage\" parent=\"StormSpell\"> <Amount value=\"291\" /> <MultiplicativeModifierArray index=\"FlawlessTechniqueTalentDamageBonus\" Validator=\"HanzoFlawlessTechniqueIsEmpoweredStormBowMissile\" Modifier=\"0.3\" Crit=\"1\" /> <FlatModifierArray index=\"TargetPracticeTalentFlatDamage\" Validator=\"HanzoTargetPracticeCasterHasDamageIncreaseBehavior\" Modifier=\"100\" /> <SourceButtonFace value=\"HanzoStormBow\" /> </CEffectDamage> \n\nFuther down is the scaling\u2026\n\n <LevelScalingArray Ability=\"HanzoStormBowFireTargetPoint\"> <Modifications> <Catalog value=\"Effect\" /> <Entry value=\"HanzoStormBowDamage\" /> <Field value=\"Amount\" /> <Value value=\"0.040000\" /> <AffectedByAbilityPower value=\"1\" /> <AffectedByOverdrive value=\"1\" /> </Modifications> \n\nI'm trying to calculate the value of a level 20 Storm Bow with both of these bonuses (and no spell power or armor shred from other talents). If we scale the base 291 up to level 20, we get the following:\n\n\n291 * 1.04^20 = 637.616834623\n\nNow we add the Target Practice Bonus:\n\n637.616834623 + 100 = 737.616834623\n\nAnd finally our .3 multiplier from Flawless Technique:\n\n737.616834623 * 1.3 = 958.90188501\n\nSo I end up at a value of ~958.9, which I assume the UI would normally round up to 959. However! When I take these talents, go into Try Mode, set the level to 20, and do this in practice, I get a crit hit of 960 on a Target Dummy. While this seems to confirm that my math was pretty close, it wasn't exact. I'm not sure where this extra bit of damage is coming from and I want to make sure this isn't because I'm missing something in my calculations. At the very least, I think I'm misunderstanding something about the way HotS does rounding.\n\nIt's not a big deal for me to be off by one on this spell, but I have a formula going down an entire column in Google Sheets and I don't want to mess up 500 calculations by a tiny bit.\n\nRead:\u00a0 (Inven) [Interview] Farewell from the best HotS Esports player: Jaewon 'Rich' Lee\n\nAny help is appreciated!\n\nEdit: One clue is that the UI seems to be giving me 638.1 for a level 20 Storm Bow cast on a Target Dummy with no talents. Starting from 638.1, you get:\n\n(638.1 + 100) * 1.3 = 959.53\n\nThis value rounds up to 960 quite nicely and makes perfect sense to me. But it begs the question: why is an untalented level 20 Storm Bow dealing ~638.1 damage?\n\nSource: Original link\n\n\u00a9 Post \"Can someone help me with a bit of ability damage math?\" for game Heroes of the Storm.\n\nTop 10 Most Anticipated Video Games of 2020\n\n\nTop 15 NEW Games of 2020 [FIRST HALF]\n\n\nYou Might Also Like\n\nLeave a Reply"}
{"text": "Retrieved from https://math.stackexchange.com/questions/661801/infinite-matrix-leading-eigenvalue-problem\nText:\nI'm trying to find the leading eigenvalue and corresponding left and right eigenvectors of the following infinite matrix, for $\\lambda>0$:\n\n$$ \\mathrm{A}=\\left( \\begin{array}{cccccc} 1 &e^{-\\lambda} & 0 &0 &0 & \\dots\\\\ 1 &e^{-\\lambda} & e^{-2\\lambda} &0 &0 & \\dots\\\\ 1 &e^{-\\lambda} & e^{-2\\lambda} &e^{-3\\lambda} &0 & \\dots\\\\ \\vdots & \\vdots & \\vdots & & \\ddots \\end{array} \\right) $$\n\nNote that there are terms above the main diagonal.\n\nI know that in general infinite matrices aren't really a self-consistent idea, but from doing it numerically with $n\\times n$ matrices using power iteration it looks like the problem converges in the limit of infinite $n$. The convergence is slower for smaller values of $\\lambda$, but it looks like it probably converges for all $\\lambda>0$.\n\nNote that I only care about the leading eigenvalue, i.e. the one with the largest magnitude, which should be real and positive. Its corresponding eigenvectors should have only positive entries, due to the Perron-Frobenius theorem.\n\nAlternatively, if it's easier, a solution for the following matrix will be just as useful to me: $$ \\mathrm{B}=\\left( \\begin{array}{cccccc} 1 & 1& 0 &0 &0 & \\dots\\\\ e^{-\\lambda} &e^{-\\lambda} & e^{-\\lambda} &0 &0 & \\dots\\\\ e^{-2\\lambda} & e^{-2\\lambda} &e^{-2\\lambda} &e^{-2\\lambda} &0 & \\dots\\\\ \\vdots & \\vdots & \\vdots & & \\ddots \\end{array} \\right) $$\n\nAgain note the terms above the diagonal. (The two problems are not equivalent, it's just that either one of them will help me solve a larger problem.)\n\nThe problem is, I just don't have much of an idea how to do this. I've tried a variety of naive methods, along the lines of writing the eigenvalue equation $\\mathrm{A}\\mathbf{x} = \\eta \\mathbf{x}$ as a system of equations involving infinite sums and then trying to find $\\{x_i >0\\}$ and $\\eta>0$ to satisfy them, but this doesn't seem to lead anywhere nice.\n\nIt could be that there is no analytical solution. Or even worse it could be that these matrices have unbounded spectra after all (in which case I'd really like to know!), but if anyone has any insight into how to solve one of these two problems I'd really appreciate it.\n\n  \u2022 $\\begingroup$ Does this come about from discretizing some continuous operator? I ask because that might give some insight or inspiration for how to approach this problem, or solve it by analogy to the continuous problem. $\\endgroup$ \u2013\u00a0rajb245 Feb 10 '14 at 19:00\n  \u2022 $\\begingroup$ @rajb245 no it doesn't unfortunately. (It comes from maximising the entropy of a discrete probability distribution subject to a complex series of constraints - the full explanation is a paper's worth.) $\\endgroup$ \u2013\u00a0Nathaniel Feb 11 '14 at 0:38\n  \u2022 $\\begingroup$ I have a gut feeling that this does have a good closed form answer anyway. I have done some numerical investigations myself and agree that the dominant eigenvalue converges. I made some progress on a solution...I might post what I've got tomorrow if I can get it better shape. $\\endgroup$ \u2013\u00a0rajb245 Feb 11 '14 at 2:40\n  \u2022 $\\begingroup$ @rajb245 that's great! I look forward to it. $\\endgroup$ \u2013\u00a0Nathaniel Feb 11 '14 at 2:44\n  \u2022 $\\begingroup$ In which sequence space are you considering this operator, by the way? It may be a difference if the eigenvectors are bounded, convergent, or square-summable, for example. $\\endgroup$ \u2013\u00a0Roland Feb 11 '14 at 2:55\n\n(No promises here, because I haven't worked the algebra all the way through, but...)\n\nTry writing the matrix equation $A\\mathbf{x}= \\mu \\mathbf{x}$, and then looking at the individual equations it gives;\n\n$$ x_1 + e^{-\\lambda}x_2 = \\mu x_1 \\\\ x_1 + e^{-\\lambda}x_2 + e^{-2 \\lambda}x_3 = \\mu x_2 \\\\x_1 + e^{-\\lambda}x_2 + e^{-2 \\lambda}x_3 + e^{-3 \\lambda}x_4 = \\mu x_3 $$ etcetera.\n\nNotice that you can substitute previous equations in to each one to get that for each $i \\geq 1$, $$\\mu x_i + e^{-(i+1)\\lambda}x_{i+2} = \\mu x_{i+1} \\\\ \\Rightarrow \\mu (x_{i+1} - x_i) = e^{-(i+1)\\lambda}x_{i+2} $$\n\nYou can then solve the recurrence relation similarly to a differential equation, by finding two distinct (neither a constant multiple of the other) solutions, which gives the general solution of any linear combination of these.\n\nThen substitute the general solution into the first equation and see if you can make it consistent with that.\n\nFinding the general solution to the recurrence could still be difficult though - the $e^{-(i+1)\\lambda}$ means that the $x_i = k^i$ trick will fail to work. I'm not actually sure if there is a solution of a different form, or if actually you can show that there is no solution - in which case, it would follow that $A$ did not have eigenvalues.\n\nSorry if this is what you've tried, but you mentioned infinite sums, and this at least doesn't involve them.\n\n  \u2022 $\\begingroup$ This is pretty much what I'd tried. The problem is that solving the recurrence relation gets pretty gnarly pretty quickly. The infinite sums appear when trying to do the same thing for the left eigenvector - I tried that when I couldn't get this to work. $\\endgroup$ \u2013\u00a0Nathaniel Feb 12 '14 at 7:40\n  \u2022 $\\begingroup$ Aaah, I meant to award you the bounty for your effort, but I was really busy today and it timed out. I'm very sorry about that, maybe another time. $\\endgroup$ \u2013\u00a0Nathaniel Feb 13 '14 at 11:58\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/214878/additivity-of-upper-densities-with-respect-to-arithmetic-progressions-of-integer\nText:\nLet $\\mathsf{d}^\\star$ be the asymptotic upper density, defined on the power set of positive integers $\\mathbf{N}^+$, so that $$ \\mathsf{d}^\\star\\colon \\mathcal{P}(\\mathbf{N}^+) \\to\\mathbf{R}\\colon X\\mapsto \\limsup_{n\\to \\infty} \\frac{|X\\cap [1,n]|}{n}. $$ It is easy to verify that if $k\\cdot \\mathbf{N}^++h:=\\{kx+h\\colon x \\in \\mathbf{N}^+\\}$ is an arithmetic progression of $\\mathbf{N}^+$, and $X$ is a set of positive integers having no elements in common with $k\\cdot \\mathbf{N}^++h$, then $$ \\mathsf{d}^\\star(X\\cup (k\\cdot \\mathbf{N}^++h))=\\mathsf{d}^\\star(X)+\\frac{1}{k}. $$ The same reasoning can be extended to the upper analytic, upper logarithmic, upper Banach and upper Buck densities, at least. That's why one may ask if this property holds in general:\n\nWe say that a set function $\\mu^\\star\\colon \\mathcal{P}(\\mathbf{N}^+)\\to \\mathbf{R}$ is an \"upper density\" whenever it satisfies the following axioms:\n\n(F1) $\\mu^\\star(\\mathbf{N}^+)=1$\n\n(F2) $\\mu^\\star(X) \\le \\mu^\\star(Y)$ if $X\\subseteq Y$\n\n(F3) $\\mu^\\star(X\\cup Y) \\le \\mu^\\star(X)+\\mu^\\star(Y)$\n\n(F4) $\\mu^\\star(k\\cdot X+h)=\\mu^\\star(X)/k$\n\nfor all positive integers $k,h$ and sets $X,Y \\subseteq \\mathbf{N}^+$. Then, is it true that if $X \\cap (k\\cdot \\mathbf{N}^++h)=\\emptyset$ then $$ \\mu^\\star(X \\cup (k\\cdot \\mathbf{N}^++h))=\\mu^\\star(X)+\\frac{1}{k}\\,\\,? $$\n\n  \u2022 $\\begingroup$ Do you have any counterexample to the stronger (and more natural?) statement that $\\mu^\\ast(X \\cup Y) = \\mu^\\ast(X) + \\mu^\\ast(Y)$ whenever $X,Y \\subseteq \\mathbf N^+$, $X \\cap Y = \\emptyset$, and $\\mu^\\ast(Y) + \\mu^\\ast(Y^c) = 1$, i.e. $Y$ belongs to the domain of the density induced by $\\mu^\\ast$? $\\endgroup$ \u2013\u00a0Salvo Tringali Aug 18 '15 at 12:01\n  \u2022 $\\begingroup$ I agree that your question would be natural (and obviously stronger); the reason why I asked in this form is that, on the one hand, I guess this is not simpler from the general case, and, on the other hand, this would be enough to prove that also its associated lower density $\\mu_\\star \\colon \\mathcal{P}(\\mathbf{N}^+)\\to \\mathbf{R}\\colon X\\mapsto 1-\\mu^\\star(X^c)$ satisfies (F4) too.. $\\endgroup$ \u2013\u00a0Paolo Leonetti Aug 20 '15 at 8:38\n  \u2022 $\\begingroup$ I didn't ask you to agree with me (on something); I asked if you have a counterexample (to something). Anyway, here is an idea: Let $\\mathcal A^\\sharp$ be the collection of all subsets of $\\mathbf N^+$ that can be expressed as a finite union of sets of arithmetic progressions of ${\\bf N}^+$, or which differ from these by finitely many integers. Given $X\\subseteq{\\bf N}^+$, can you show that there exists a nonincreasing (resp., nondecreasing) sequence $(U_n)_{n \\ge 1}$ of $\\mathcal A^\\sharp$ such that $X\\subseteq U_n$ (resp., $U_n\\subseteq X$) for each $n$ and $\\lim_n\\mu^\\ast(U_n)=\\mu^\\ast(X)$? $\\endgroup$ \u2013\u00a0Salvo Tringali Aug 21 '15 at 9:43\n  \u2022 $\\begingroup$ I am almost sure that what you are asking holds if and only if $X$ belongs to the domain of the Buck's density, which holds if and only if $X$ belongs to the topology generated by the set of arithmetic progressions $\\mathscr{A}$, or differ by these by a finite set of elements. Anyway, for a negative answer to your question, it sufficient to provide a counterexample (which holds for all $\\mu^\\star)$. Set $X=\\cup_{n\\ge 1}\\{(2n)!,\\ldots,(2n+1)!\\}$, then it contains no AP, and the smallest AP containing $X$ is $\\mathbf{N}^+$ itself. $\\endgroup$ \u2013\u00a0Paolo Leonetti Aug 21 '15 at 9:56\n  \u2022 $\\begingroup$ I've just realized that the answer to my previous question is negative: Looking at the case of the upper asymptotic density, ${\\sf d}^\\ast$, on $\\mathbf N^+$, fix $\\alpha \\in {]0,1[}$ and consider as $X$ the set $\\bigcup_{n \\ge 1} [\\![\\alpha(2n-1)! + (1-\\alpha)(2n)!+1, (2n)!]\\!]$; then recall from mathoverflow.net/questions/207522 that ${\\sf d}^\\ast(X) = \\alpha$. Edit: I see we added a comment almost at the same time. $\\endgroup$ \u2013\u00a0Salvo Tringali Aug 21 '15 at 9:56\n\nThe answer is in the negative.\n\nLet $f$ and $g$ be two upper densities (in the sense of the OP), and let $\\alpha \\in [0,1]$ and $q \\in [1,\\infty[$. Then the function $$h := (\\alpha f^q + (1-\\alpha) g^q)^{\\frac{1}{q}}$$ is an upper density too (in particular, condition (F3) follows from Minkowski's inequality, which is why we need $q \\ge 1$).\n\nNext, fix a set $X \\subseteq 2\\cdot\\mathbf N^+$, let $x := 2f(X)$, $y := 2g(X)$ and $Y := 2 \\cdot \\mathbf N^+ + 1$, and suppose to a contradiction that $h$ is ``weakly additive'' (that is, $h(A \\cup B) = h(A) + h(B)$ for all disjoint $A, B \\subseteq \\mathbf N^+$ such that $B$ is an (infinite) arithmetic progression), regardless of the actual values of the parameters $\\alpha$ and $q$. Then, also $f$ and $g$ are weakly additive, and using that $f(Y) = g(Y)=\\frac{1}{2}$, we obtain $$ \\begin{split} 2h(X \\cup Y) & = 2(\\alpha (f(X \\cup Y))^q + (1-\\alpha) (g(X \\cup Y))^q)^{\\frac{1}{q}} \\\\ & = 2(\\alpha (f(X) + f(Y))^q + (1-\\alpha) (g(X) + g(Y))^q)^{\\frac{1}{q}} \\\\ & = (\\alpha (x+1)^q + (1-\\alpha)(y+1)^q)^{\\frac{1}{q}} \\end{split} $$ and $$ \\begin{split} h(X) + h(Y) & = (\\alpha (f(X))^q + (1-\\alpha) (g(X))^q)^{\\frac{1}{q}} + \\frac{1}{2} \\\\ & = (\\alpha x^q + (1-\\alpha)y^q)^{\\frac{1}{q}}+ \\frac{1}{2} \\end{split} $$ which, together with $h(X \\cup Y) = h(X) + h(Y)$, yields $$ (\\alpha (x+1)^q + (1-\\alpha)(y+1)^q)^{\\frac{1}{q}} = (\\alpha x^q + (1-\\alpha)y^q)^{\\frac{1}{q}} + 1. $$ On the other hand, an appropriate choice of $f$, $g$ and $X$ makes it possible to have $x$ equal to zero while $y$ takes any prescribed value in the interval $[0,1]$: This can be achieved, for instance, by letting $f$ be the upper asymptotic density (on $\\mathbf N^+$), $g$ the upper Banach density, and $X$ a suitable subset of the intersection, $S$, of $\\bigcup_{n \\ge 1} [\\![2^n, 2^n + n]\\!]$ and $2 \\cdot\\mathbf N^+$, and by considering that (i) the upper asymptotic density of $S$ is $0$, (ii) the upper Banach density of $S$ is $\\frac{1}{2}$, (iii) the upper asymptotic and upper Banach densities are upper densities, and (iv) upper densities have the strong, and hence the weak, Darboux property (by the main theorem here).\n\nAccordingly, we should have $$(\\alpha + (1-\\alpha)(y+1)^q)^{\\frac{1}{q}} = (1-\\alpha)^{\\frac{1}{q}}y + 1$$ for all $\\alpha, y \\in [0,1]$ and $q \\in [1,\\infty[$, which, however, is blatantly false. []\n\nAdded later. If you assume $\\alpha = \\frac{1}{2}$ and $q = 2$ in the last displayed equation, you don't even need to know that the upper Banach density has the weak Darboux property, since then you end up with the equation $$\\sqrt{1 + (y+1)^2} = y + \\sqrt{2},$$ which has a unique solution for $y \\in \\bf R$ (namely, $y = 0$).\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/143594/are-non-degenerate-critical-points-always-isolated\nText:\nI have a question regarding the isolation of critical points of a function:\n\nSuppose $f : \\mathbb{R}^n \\to \\mathbb{R}$ is a $C^\\infty$ function such that $f$ has a non - degenerate critical point at $0 \\in \\mathbb{R}^n$. That is, we have $\\triangledown f (0) = 0$, and the Hessian $\\left((\\partial^2 f/ \\partial x_i \\partial x_j ) (0) \\right)$ is invertible.\n\nCan I deduce from this that the critical point at $0$ is an isolated critical point ? My guess is to say yes, because the fact that the Hessian is non-degenerate forces $f$ to change its value in the vicinity, and in all directions. But I am unsure, in particular with regards to the last statements (\"in all directions\") - though that should be encoded by the fact all eigenvalues of the Hessian are non - zero.\n\nIs this the right way to think about the question of whether the critical point is isolated ? Thanks for your thoughts !\n\n\nYes, this is a right way of thinking about the question. You can see this in several ways.\n\n1: The Morse lemma: The Morse lemma declares that about any nondegenerate critical point $p$ of a smooth function $f$ there is a coordinate neighborhood $x_i$ so that in those coordinates, $f(x_i) = x_1^2 + \\cdots + x_i^2 - x_{i+1}^2 - \\cdots - x_n^2 + f(p)$. It's an easy exercise to compute the gradient in these coordinates, and you can immediately see that the only zero of the gradient in the neighborhood is at $p$. (In this case, $p = 0$ and the claim is that you can precompose $f$ with a diffeomorphism $\\varphi$ of $\\mathbb{R}^n$ so that $f\\circ\\varphi = \\sum x_i^2 - \\sum x_j^2$.)\n\n2: Directly: Take a curve (easiest, a straight line) $\\gamma$ through $0$, and for simplicity's sake, parametrize the curve so that $\\gamma(0)=0$. Consider $f|_\\gamma$. Then $f'(t) = (\\nabla f\\cdot \\gamma')(t)$ and $f''(t) = (\\gamma'^THess_f\\gamma')(t)$. Leaving out some details you should verify as an exercise, the Hessian is invertible, so in a neighborhood of $0$, $f$ has a local extremum, hence the zero of $f'$ is isolated. This is true for any curve, thus, every direction, so $0$ is an isolated critical point. This formalizes your intuition about \"every direction.\"\n\n  \u2022 1\n    $\\begingroup$ it's an extremum, not an extremeum :-) $\\endgroup$ \u2013\u00a0user20266 May 10 '12 at 18:35\n  \u2022 $\\begingroup$ It's an extremuseum! Thanks :) $\\endgroup$ \u2013\u00a0Neal May 10 '12 at 20:15\n  \u2022 1\n    $\\begingroup$ Yes. But the Morse Lemma is a nice and worthy exhibit. $\\endgroup$ \u2013\u00a0user20266 May 11 '12 at 16:01\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3001136/0-sqrt-a-sqrt3b-epsilon-for-a-b-in-bbb-z\nText:\nI'm trying to solve the following problem:\n\nGiven $\\epsilon>0$, are there positive integers $a,b$ such that $0<|\\sqrt a-\\sqrt[3]b|<\\epsilon$ ?\n\nMy solution: given $n\\in\\Bbb N$, $$|\\sqrt{n^2}-\\sqrt[3]{n^3+1}|=\\sqrt[3]{n^3+1}-n=\\frac1{\\sqrt[3]{(n^3+1)^2}+n\\sqrt[3]{n^3+1}+n^2}<\\frac1{3n}\\to 0$$ Thus, the answer is yes.\n\nBut I was trying to find an \"optimal\" solution. That is, now the problem becomes\n\nGiven $\\epsilon>0$, find the least $b\\in \\Bbb Z_+$ such that there exists $a\\in\\Bbb Z_+$ such that $0<|\\sqrt a-\\sqrt[3]b|<\\epsilon$\n\nand now I'm totally lost. Is there some theory about this? Perhaps has it to do with the diophantine equation $a^3-b^2=\\pm1$, and hence, to Catalan's conjecture?\n\nRemark: Please note the '$0<$' in the inequality. I'm aware that $\\sqrt 1=\\sqrt[3]1$.\n\n\nListing some easy observations to get the ball rolling.\n\nMy guess is that the variable $b$ and the error $\\epsilon$ are, asymptotically, related by estimates of the form $$\\epsilon\\approx \\frac C{b^\\alpha},$$ where $C$ and $\\alpha>0$ are positive constants.\n\nThe true relation may be very complicated, but at least we can derive upper and lower bounds of the prescribed form. Your example with $b=n^3+1$, $\\root3\\of b-\\sqrt a\\le 1/(3n^2)$, shows that $$ \\epsilon\\le \\frac{1/3}{b^{2/3}} $$ is possible for infinitely many values of $b$.\n\nOn the other hand, let $\\zeta=(1+i\\sqrt3)/2$ be a primitive sixth root of unity. We have the polynomial factorization $$ x^6-y^6=(x-y)\\prod_{j=1}^5(x-\\zeta^j y).\\qquad(*) $$ Assume that integers $b, a$ are chosen in such a way that $\\root3\\of b-\\sqrt a$ is very small (but non-zero). Plug $x=\\root3\\of b, y=\\sqrt a$ into $(*)$. The left hand side $b^2-a^3$ has absolute value $\\ge1$ because it is an integer. Predalescu/Catalan says that actually it is $\\ge2$ when $b>3$ but that's insignificant, at least for now. Because $x\\approx y$, the other factors on the right hand side of $(*)$ have absolute values $\\approx x, \\sqrt{3}x,2x,\\sqrt3 x,x$ for $j=1,2,3,4,5$ respectively. Their product is thus $\\approx 6x^5$. The factorization $(*)$ thus gives the estimate $$ |\\root3\\of b-\\sqrt a|\\ge\\frac{K}{b^{5/3}} $$ with a constant $K\\approx 1/6$.\n\nI would summarize this by stating that\n\n$$2/3\\le \\alpha\\le 5/3.$$\n\nWaiting for the experts to show up with something more precise.\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/29872/how-many-bytes-are-in-the-region/29877\nText:\nAfter far too many years of counting the number of characters in the region by doing M-: (- (point) (mark)), I just discovered M-= (count-words-region). Much better! But now I'm looking for a way to obtain the number of bytes that the characters in the region occupy in the buffer's coding system--typically, or always really, UTF-8. Is there an easy way to do this?\n\nFor context, I've been doing some code golfing on codegolf.stackexchange.com in a language that supports various Unicode operators, and I need to know how many bytes my submission occupies. So far I've been saving the region to a file, doing ls -l on it, then deleting it. I could easily whip up a function to do this automatically, but it seems rather inelegant.\n\n  \u2022 You could also probably open the file in hexl mode, you could then use the regular Emacs commands to count bytes. \u2013\u00a0wvxvw Jan 8 '17 at 5:56\n  \u2022 I'm typically in a shell buffer when I want to know the byte count, so hexl-mode isn't really practical. A nice thought though. \u2013\u00a0Sean Jan 8 '17 at 20:19\n\nSounds like you are asking for something like this:\n\n(defun region-bytes ()\n  (let ((strg  (if (use-region-p)\n    (message \"Region has %d bytes\" (string-bytes strg))))\n\nYou might also be interested in showing the region size in the mode line. You can do that with library modeline-posn.el -- see Mode Line Position. One of the style choice is to show the number of bytes in the active region -- just what you are asking for here. The difference is that it would always be shown (when the region is active), instead of being reported as a message only on demand (as per the command above).\n\n\nWhile Drew's answer will work correctly in many cases (where utf-8 is pervasive and if you don't use DOS-style EOLs), if you want to make it work reliably for \"all\" buffers, you could do something like the following:\n\n(defun region-bytes (start end)\n  \"Return the number of bytes used by the region.\"\n  (interactive \"r\")\n  (message \"Region has %d bytes\"\n           (- (bufferpos-to-filepos end 'exact)\n              (bufferpos-to-filepos start 'exact))))\n\nand for cases where efficiency is more important than precision, you could pass approximate instead of exact, in which case bufferpos-to-filepos will always be very fast tho it will not handle correctly cases like GBK or utf-2022 encodings.\n\n  \u2022 +1. Good to know about bufferpos-to-file-pos. It is apparently available only in Emacs 25 and later. And it apparently presumes that the buffer is associated with a file (?). You speak of \"all\" buffers, but I imagine the quotes mean (at least) that it is limited to file buffers. \u2013\u00a0Drew Jan 27 '17 at 3:17\n  \u2022 The notion of \"bytes\" here only makes sense with respect to some encoding. bufferpos-to-file-pos uses the encoding specified by buffer-file-coding-system, but other than that it should also work in a non-file buffer (e.g. if you let-bind buffer-file-coding-system around the call). \u2013\u00a0Stefan Jan 27 '17 at 3:29\n  \u2022 I see; thanks. I did not bother to look at the code - looked at only the doc. The doc mentions only \"the file\". It might be more useful if what you say in your comment, or similar, were added. \u2013\u00a0Drew Jan 27 '17 at 3:31\n  \u2022 I see also that the doc says that bufferpos-to-file-pos with type exact \"may end up re-(en/de)coding a large part of the file/buffer\", which might not be desirable in some contexts, for performance reasons. That text seems misleading, BTW, since it suggests that the buffer can be modified, with some of its text changing coding system. If I read the code right, when b-t-f-p re-(en/de)codes the text it puts the result in a different, temporary buffer, and returns the size - the original text does not have its encoding changed. \u2013\u00a0Drew Feb 5 '17 at 17:07\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/1749/dijsktras-algorithm-applied-to-travelling-salesman-problem/1805\nText:\nI am a novice(total newbie to computational complexity theory) and I have a question.\n\nLets say we have 'Traveling Salesman Problem' ,will the following application of Dijkstra's Algorithms solve it?\n\nFrom a start point we compute the shortest distance between two points. We go to the point. We delete the source point. Then we compute the next shortest distance point from the current point and so on...\n\nEvery step we make the graph smaller while we move the next available shortest distance point. Until we visit all the points.\n\nWill this solve the traveling salesman problem.\n\n\nmigrated from cstheory.stackexchange.com May 9 '12 at 8:48\n\n\n  \u2022 3\n    $\\begingroup$ Note that TSP is NP-complete and Dijkstra's algorithm has polynomial runtime. What you propose would be next-to-trivial solution of the P=NP? question, so it is unlikely that your approach works. This kind of reasoning is only a heuristic, mind! $\\endgroup$ \u2013\u00a0Raphael May 14 '12 at 14:19\n\nDijkstra's algorithm returns a shortest path tree, containing the shortest path from a starting vertex to each other vertex, but not necessarily the shortest paths between the other vertices, or a shortest route that visits all the vertices.\n\nHere's a counter example where the greedy algorithm you describe will not work:\n\n\nStarting from $a$, the greedy algorithm will choose the route $[a,b,c,d,a]$, but the shortest route starting and ending at $a$ is $[a,b,d,c,a]$. Since the TSP route is not allowed to repeat vertices, once the greedy algorithm chooses $a,b,c,d$, it is forced to take the longest edge $d,a$ to return to the starting city.\n\n\nAs it already turned out in the other replies, your suggestion does not effectively solve the Travelling Salesman Problem, let me please indicate the best way known in the field of heuristic search (since I see Dijkstra's algorithm somewhat related to this field of Artificial Intelligence).\n\nA heuristic algorithm can return optimal solutions (though the sizes it can manage are relatively small as a matter of fact) and the following method was suggested by Richard Korf in the 90s. While it works perfectly for the symmetric travelling salesman problem (where the cost of the edge $(u,v)$ equals the cost of the same edge when traversed in the opposite direction $(v,u)$), it can be easily adapted to the alternative case of the asymmetric version.\n\nThe best approach (I am aware of) consists of running a Depth-First Branch-and-Bound heuristic search algorithm where the heuristic is the cost of the Minimum Spanning Tree (MST). Since the MST can be computed in polynomial time with either the Prim's algorithm or the Kruskal's algorithm, then it can be expected to return solutions in a reasonable amount of time. For a wonderful discussion of these two algorithms I do strongly suggest you to have a look at The Algorithm Design Manual\n\nAs a matter of fact, let me highlight that since this approach was suggested not much progress have been seen in the field for deriving optimal bounds of this problem so that I do consider it to be a hot question in the field of combinatorial search.\n\nHope this helps,\n\n\nI have no idea how anyone here didn't notice that the application of Dijkstra's algorithm would be entirely unnecessary in this case? You could implement this greedy algorithm by simply selecting the closest node, which is known apriori. Dijkstra's algorithm is used for discovering paths, but you are only taking a single step each time. This obviously does not find the optimal solution to the TSP, but many very good approaches do not find it either. All optimal solution finders for TSP are very computationally demanding.\n\n\nThe answer is no, that's not a good way of solving the TSP problem. A good counter example is where all the points are on a line, like the following:\n\n\nusing Dijsktra's algorithm, would make the poor salesman starting at point 0, first go to 1 then to 2 then to 3 ect. which is not the optimal.\n\nHope that helps. Have a look at the first chapter in Steven S. Skiena excellent book called \"The Algorithm Design\" it explains this example in more detail.\n\nThe TSP problem is not finding the shortest way between two points, but in making a route between all the points which are optimal. When you have the optimal route you can use Dijsktra to find the shortest path between each points in the route.\n\n  \u2022 2\n    $\\begingroup$ Dijkstra is a single source shortest path algorithm, but it wouldn't \"make\" the salesman start at 0, nor would it return a route. It just returns the shortest path tree, containing the shortest path to each vertex from the given source vertex. $\\endgroup$ \u2013\u00a0Joe May 9 '12 at 18:25\n  \u2022 $\\begingroup$ Traditionally, the TSP problem [en.wikipedia.org/wiki/\u2026 ] is \"Given a list of cities and their pairwise distances, the task is to find the shortest possible route that visits each city exactly once and returns to the origin city.\" Technically it's not possible to satisfy those requirements on a path-- you must either not return to the starting city, or repeat cities. $\\endgroup$ \u2013\u00a0Joe May 9 '12 at 18:27\n  \u2022 $\\begingroup$ However, on a path, if we relax either of those constraints, then the problem is trivial. $\\endgroup$ \u2013\u00a0Joe May 9 '12 at 18:28\n  \u2022 $\\begingroup$ Of course, Dijkstra wouldn't make the salesman start at 0. But the algorithm proposed in the original question did not specify a start vertex; therefore, the proposed algorithm could force the poor salesman to start at 0. So this answer is correct. $\\endgroup$ \u2013\u00a0JeffE May 14 '12 at 17:33\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1736959/filled-suit-vs-triple-quads-which-is-more-likely-to-happen-first-on-average/1738504\nText:\nSuppose we have a standard well shuffled $52$ card deck and deal cards from it without replacement (for each hand). Which is likely to happen first on average, we deal out an entire suit (all $13$ cards of any one suit) or get $3$ quads?\n\nNone of the cards have to be in any special order, just that they show up. For example, the quads could show up with other \"irrelevant\" cards in between.\n\nNote that both of these are stopping conditions for a trial, whether you first get the full suit or the triple quads.\n\nAlso note that each case could be poised, waiting for $1$ card to \"win\" but a single card drawn could satisfy both conditions simultaneously and thus will be considered a tie or no decision and we would then reshuffle and retry a new hand. For example, if you needed the K of hearts to complete all $13$ hearts but you also have seen $5,5,5,5,3,3,3,3,K,K,K$ so far with no other quads seen yet that hand. The K of hearts would satisfy both conditions simultaneously and thus create a \"tie\" (no decision) situation, prompting a reshuffle and retrial.\n\n  \u2022 $\\begingroup$ What is a \"quad\"? $\\endgroup$ \u2013\u00a0K. Jiang Apr 11 '16 at 3:48\n  \u2022 $\\begingroup$ I gave examples. A quad in this context is $4$ cards all of the same rank such as K,K,K,K. There are $13$ different ranks in a standard $52$ card deck. $\\endgroup$ \u2013\u00a0David Apr 11 '16 at 4:00\n\nAs I said in my other answer, it is feasible to explicitly calculate all the probabilities. We generate all the distributions of cards into ranks, ${13+4\\choose4}=2380$ except the distributions that lack $3$ cards of any rank, ${13+3\\choose3}=560$. Then for each distribution we can compute the probability of having that distribution given a hand of that many cards, $$P_{dist}=\\frac{\\frac{13!}{n_0!n_1!n_2!n_3!n_4!}{4\\choose0}^{n_0}{4\\choose1}^{n_1}{4\\choose2}^{n_2}{4\\choose3}^{n_3}{4\\choose4}^{n_4}}{{52\\choose0\\cdot n_0+1\\cdot n_1+2\\cdot n_2+3\\cdot n_3+4\\cdot n_4}}$$ Where $n_i$ is the number of ranks that have $i$ cards in the distribution. Then we multiply that by the probability of ending a game requiring $n_4+1$ quads on the next card, $$P_{over}=\\frac{n_3}{52-(0\\cdot n_0+1\\cdot n_1+2\\cdot n_2+3\\cdot n_3+4\\cdot n_4)}$$ Now we have to find the probabilities of winning on that next card, drawing, or already having lost. $$\\begin{align}P_{win}&=P(0)\\\\ P_{tie}&=\\frac14P(1)\\\\ P_{lose}&=\\frac34P(1)+P(2)+P(3)+P(4)\\end{align}$$ Where $P(i)$ is the probability of having completed $i$ suits after the next card has been drawn. Then by inclusion-exclusion, we can find that $$\\begin{align}P(0)&=1-4P(\\spadesuit)+6P(\\heartsuit\\spadesuit)-4P(\\diamondsuit\\heartsuit\\spadesuit)+P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(1)&=4P(\\spadesuit)-12P(\\heartsuit\\spadesuit)+12P(\\diamondsuit\\heartsuit\\spadesuit)-4P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(2)&=6P(\\heartsuit\\spadesuit)-12P(\\diamondsuit\\heartsuit\\spadesuit)+6P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(3)&=4P(\\diamondsuit\\heartsuit\\spadesuit)-4P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(4)&=P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\end{align}$$ Where, for example $P(\\heartsuit\\spadesuit)=P_2$ is the probability of having completed both the hearts and spades suits by the time the next card is drawn. Having picked $K$ specific suits, the probability of all of those suits being present in a rank where $N$ cards has been drawn is $$P_{NK}=\\frac{{4-K\\choose N-K}}{{4\\choose N}}$$ Where ${N\\choose k}=0$ if $k<0$. So the probability of success over all ranks is $$P_K=P_{0K}^{n_0}P_{1K}^{n_1}P_{2K}^{n_2}P_{3K}^{n_3-1}P_{4K}^{n_4+1}$$ Where conventionally $0^0=1$. Putting all that stuff together we can write a program (not posted) to calculate the probabilities of winning, losing, or drawing for games requiring all numbers of quads to win.\n\n$$\\begin{array}{r|rrr} \\text{Quads}&\\text{Win}&\\text{Lose}&\\text{Tie}\\\\ \\hline 1&0.998563&0.001078&0.000359\\\\ 2&0.992344&0.005746&0.001910\\\\ 3&0.975825&0.018161&0.006013\\\\ 4&0.941256&0.044220&0.014525\\\\ 5&0.879013&0.091425&0.029562\\\\ 6&0.778897&0.168285&0.052818\\\\ 7&0.633332&0.282725&0.083944\\\\ 8&0.444088&0.438620&0.117292\\\\ 9&0.234020&0.629219&0.136761\\\\ 10&0.060783&0.826763&0.112455\\\\ 11&0.004689&0.972954&0.022357\\\\ 12&0.000048&0.999376&0.000576\\\\ 13&0.000000&1.000000&0.000000\\\\ \\end{array}$$\n\n\nWhile I can't tell you the exact likelihood of either option coming first, I can prove that getting three quads first is far more likely.\n\nConsider that after 42 cards, you are guaranteed to have at least three quads since there are only 10 cards remaining. After 42 cards, the likelihood of having a full suit would be the likelihood that the remaining 10 cards contain 3 suits or fewer. This probability is $${4*{39 \\choose 10}-6*{26 \\choose 10}+{13 \\choose 10}\\over {52 \\choose 10}}=.1587 $$\n\nThis means that at a point when you are certain you have three quads, there is still a more than 84% chance that you do not have a full suit. Hence, the three quads are more likely to come first.\n\n  \u2022 $\\begingroup$ Can anyone run a Monte Carlo simulation to help confirm this? I'd be interested to know things like the percentages of each, % of ties, average number of cards for a winner.... $\\endgroup$ \u2013\u00a0David Apr 11 '16 at 14:28\n  \u2022 $\\begingroup$ @David Thanks for the suggested edit. I changed it to 84%. $\\endgroup$ \u2013\u00a0browngreen Apr 11 '16 at 15:45\n  \u2022 $\\begingroup$ @Browngren, can you redo your calculation to see what happens when checking for $8$ quads instead of only $3$? According to the simulation by user5713492, those outcomes (one full suit vs. $8$ quads) are almost \"even steven\" (equiprobable). Thanks. $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 4:12\n  \u2022 $\\begingroup$ You are guaranteed at least 8 quads after 47 cards. At that point, the likelihood of having a full suit is $${4*{39 \\choose 5}-6*{26 \\choose 5}+{13 \\choose 5}\\over {52 \\choose 5}}=.7348$$ Based on this alone, we see that the probability of 8 quads coming first is at least .2652, but you couldn't conclude which is more likely to come first. $\\endgroup$ \u2013\u00a0browngreen Apr 12 '16 at 16:00\n\nI tried a simulation. Ran a total of $1.0\\times10^{10}$ times. Program was:\n\nprogram shuffle\n   implicit none\n   integer(INT64) deck(52)\n   integer i, j\n! The deal has 4 4-bit counters for suits and 13 2-bit counters\n! for ranks. Like this:\n! xxxx0SSSS0HHHH0DDDD0CCCC0AA0KK0QQ0JJ0TT099088077066055044033022\n! Each card has a bit set for its suit and for its rank.\n! When added to the deal it updates the appropriate suit and rank\n! counters. When a counter overflows, we know that all 4 of a\n! rank or all 13 of a suit have been dealt (the suit counters\n! were initialized to 3 so that 13 more overflowed them.)\n   integer(INT64), parameter :: initial(52) = &\n   integer(INT64), parameter :: suits = &\n   integer(INT64), parameter :: ranks = &\n   integer(INT64), parameter :: first = &\n   integer(INT64) Nsim, k, deal\n   integer(INT64) :: win = 0, tie = 0, lose = 0\n   real harvest(51)\n   integer quads\n   logical won, lost\n\n   Nsim = 1000000000\n   call random_seed()\n   do k = 1, Nsim\n      deck = initial\n      deal = first\n      call random_number(harvest)\n      do i = 1, 51\n         j = harvest(i)*(53-i)\n         if(j /= 0) deck([i,j+i]) = deck([j+i,i])\n      end do\n      do i = 1, 52\n         deal = deal+deck(i)\n         won = popcnt(iand(deal,ranks)) >= 3\n         lost = iand(deal,suits) /= 0\n         if(won .OR. lost) exit\n      end do\n      if(won) then\n         if(lost) then\n            tie = tie+1\n            win = win+1\n         end if\n         lose = lose+1\n      end if\n   end do\n   write(*,'(a,i12,1x,f12.8)') ' win = ', win, win*1.0d2/Nsim\n   write(*,'(a,i12,1x,f12.8)') 'lose = ', lose, lose*1.0d2/Nsim\n   write(*,'(a,i12,1x,f12.8)') ' tie = ', tie, tie*1.0d2/Nsim\nend program shuffle\n\nResults were as follows: $$\\begin{array}{rrr} \\text{win} & 9758240072 & 97.5824\\% \\\\ \\text{lose} & 181632175 & 1.8163\\% \\\\ \\text{tie} & 60127753 & 0.6013\\% \\end{array}$$ So it can be seen that a loss (all of a suit before 4 quads) was rare, and ties even less frequent.\n\n  \u2022 $\\begingroup$ Just curious. How many quads are needed to make it \"neck and neck\" with filling a full suit? 6? 7?...? Can you mod your program to check when the percentages approach 50% each please? $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 2:19\n  \u2022 1\n    $\\begingroup$ When I cranked it up to 8 quads, it was 44.39% win, 43.87% lose, 11.74% tie. $\\endgroup$ \u2013\u00a0user5713492 Apr 12 '16 at 2:51\n  \u2022 $\\begingroup$ Wow that tie seems very high maybe someone else should also do a Monte Carlo simulation to check. How can it be that just as you get the $8$th quad you are also finishing the first complete suit on that same exact card about $1$ out of $9$ trials? What is the average number of cards of the win, loss, and tie \"buckets\"? $8$ quads is at least $32$ cards and likely more. $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 3:52\n  \u2022 $\\begingroup$ If you think about it, the 8th quad is very likely to come in the 45th-47th card range, which is also a very reasonable range to complete the first full suit. $\\endgroup$ \u2013\u00a0browngreen Apr 12 '16 at 8:06\n  \u2022 1\n    $\\begingroup$ Another $6.0\\times10^9$ simulations, tracking mean game length: $$\\begin{array}{rr}\\text{Quads}&\\text{Length}\\\\3&35.11\\\\4&37.96\\\\5&40.19\\\\6&41.96\\\\7&43.33\\\\8&44.33\\end{array}$$ Come to think of it, it may be feasible to calculate exact probabilities -- in terms of distributions there aren't really that many possibilities. $\\endgroup$ \u2013\u00a0user5713492 Apr 12 '16 at 17:18\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1535997/prove-piecewise-function-integrable\nText:\n$$ f(x) = \\begin{cases} -2, & \\text{if }x < 0 \\\\ 1, & \\text{if }x > 0\\\\ 0, & \\text{if }x = 0 \\end{cases} $$\n\nHey guys I need some help showing that this function is integrable on the closed interval $[-1,2]$.\n\nSo far my idea has been to show $$U(f,P)-L(f,P) < \\epsilon$$ for some $\\epsilon>0$.\n\nThe only problem is the point $(0,0)$ on the function.\n\nI don't understand how to handle that.\n\nCan I just say that $U(f,P)$ for some partition will equal to $3$ and then find a partition $P$ for which $$3-L(f,P)<\\epsilon?$$\n\n  \u2022 $\\begingroup$ If you make the interval(s) containing 0 sufficiently narrow, you can make the difference between upper an lower sums as small as you want, namely at most $|1-(-2)|=3$ times this interval width. $\\endgroup$ \u2013\u00a0Henning Makholm Nov 18 '15 at 23:28\n  \u2022 $\\begingroup$ Hint: look at partitions like $\\{[-1,-\\epsilon],[-\\epsilon,\\epsilon],[\\epsilon,2]\\}$ for smaller and smaller (positive) $\\epsilon$. $\\endgroup$ \u2013\u00a0Arthur Nov 18 '15 at 23:29\n\nLet $\\sigma$ be a partition of $[-1,2]$. Taking Arthur's hint, have the partition be of the form, $$[-1,-\\delta],[-\\delta,\\delta],[\\delta,2]$$ for appropriately small $\\delta >0$.\n\nThe supremum of $f(x)$ is -2 on the first subinterval, $1$ on the second subinterval, and $1$ on the third subinterval (verify it!). Thus the upper sum is given by $$U_{f,\\sigma}=(1-\\delta)\\cdot -2 + 2\\delta \\cdot 1 + (2-\\delta)\\cdot 1=3\\delta$$ The infimum of $f$ on the first interval is $-2$, as well as $-2$ on the second subinterval, and $1$ on the last (verify). Thus the lowers sum is given by $$L_{f,\\sigma}=(1-\\delta)(-2)+2\\delta \\cdot (-2) +(2-\\delta)\\cdot 1=-3\\delta$$ Thus, $U_{f,\\sigma}-L_{f,\\sigma}=6\\delta$ and it should be clear how small to make $\\delta$.\n\n  \u2022 $\\begingroup$ So after you get 2$\\delta$ we need a $\\delta$ < $\\epsilon$ /2. We could choose $\\epsilon$ /3 and get Uf-Lf=$\\epsilon$ - $\\epsilon$ /3 which finishes the proof of 2/3 $\\epsilon$ < $\\epsilon$. Would that be correct? $\\endgroup$ \u2013\u00a0jeff Nov 19 '15 at 0:54\n  \u2022 $\\begingroup$ Yes, you got it. $\\endgroup$ \u2013\u00a0Nap D. Lover Nov 19 '15 at 1:03\n  \u2022 $\\begingroup$ Just one question though. Why isn't the infimum on the interval [-$\\delta$,$\\delta$] set as -2? $\\endgroup$ \u2013\u00a0jeff Nov 19 '15 at 1:07\n  \u2022 $\\begingroup$ Because i messed up haha. This will affect the bound $\\endgroup$ \u2013\u00a0Nap D. Lover Nov 19 '15 at 1:48\n  \u2022 $\\begingroup$ @jeff I have edited my answer with this fixed now. $\\endgroup$ \u2013\u00a0Nap D. Lover Nov 19 '15 at 1:53\n\nNotice that for any $x$ at which $f$ is discontinuous, $x$ can be contained in an interval as small as you please. Make sure to include this small interval in your partition.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/479892/problem-in-the-continuum-limit-of-a-kronecker-delta\nText:\nI am having troubles in understanding how to correctly perform the continuum limit of a double sum containing a Kronecker delta.\n\nImagine to integrate a function depending on $t$ and $t'$, both ranging from $0$ (initial time) to $T$ (final time):\n\n$$I:=\\int_0^Tdt_1\\int_0^Tdt_2 f(t_1,t_2).\\tag{1}$$\n\nThe corresponding Riemann sums, dividing the time intervals in slices of width $\\epsilon=T/N$ is:\n\n$$I_{disc}:=\\sum_{j,j'=1}^N \\epsilon^2 f(j\\epsilon,j'\\epsilon).\\tag{2}$$\n\nObviosly lim$_{N\\rightarrow\\infty}I_{disc}=I$. Now consider the case when only the diagonal elements of the double integral are different from zero i.e.\n\n$$J_{disc}:=\\sum_{j,j'=1}^N \\delta_{j,j'}\\epsilon^2 f(j\\epsilon,j'\\epsilon).\\tag{3}$$\n\nI would expect that, in the continuum limit $N\\rightarrow \\infty$ ($\\epsilon\\rightarrow 0$) it becomes\n\n$$J:=\\int_0^Tdt\\int_0^Tdt'\\delta(t-t') f(t,t'),\\tag{4}$$\n\nwhere $\\delta(t-t')$ is a Dirac delta.\n\nHere is the problem: the Kronecker delta is adimensional, while the Dirac Delta has the dimensions of seconds$^{-1}$. This implies that $J_{disc}$ and $J$ have different dimensions, which does not make any sense. Therefore, there must be some mistake I am doing in going from the discrete to the continuum version of $J$. Could you help me spotting it and, more important, suggest the way to do this limit correctly?\n\n  \u2022 $\\begingroup$ Maybe $\\delta\\left(\\frac{t-t'}{T}\\right)$? $\\endgroup$ \u2013\u00a0Cryo May 14 at 0:06\n\nThe translation between the Kronecker delta function and the Dirac delta distribution is\n\n$$ \\frac{1}{\\epsilon}\\delta_{j,j^{\\prime}}\\qquad\\longrightarrow\\qquad\\delta(t-t^{\\prime}),\\tag{A}$$\n\nwhere $\\epsilon$ is the \"volume\" of a unit-cell in the discretization. See e.g. this related Phys.SE post.\n\nIn particular, the rhs. of OP's eq. (3) should be divided with $\\epsilon$ to have a finite continuum limit.\n\n  \u2022 $\\begingroup$ Thank you very much, I think this clarifies! To summarize, if I just take (3) as it is and perform the limit I get zero, which is also consistent of doing an integral of a finite quantity (the function f) on a set with null measure (the line s=s'). $\\endgroup$ \u2013\u00a0Sandro May 15 at 14:01\n  \u2022 $\\begingroup$ $\\uparrow$ Yes. $\\endgroup$ \u2013\u00a0Qmechanic May 15 at 16:49\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/706243/alternating-series-error-bound\nText:\nThe taylor series for $ln(x)$, centered at $x=1$, is $$\\sum_{n=1}^{\\infty}(-1)^{n+1}\\frac{(x-1)^n}{n} $$ Let $f$ be the function given by the sum of the first three nonzero terms of this series. The maximum value of $|\\ln(x)-f(x)|$ for $0.3\\le\\ x \\le\\ 1.7$ is?\n\nWhen I look at this question, I instinctively think of alternating series error bound. Therefore the maximum error should be equal to the first omitted term $$= (-1)^{4+1}\\frac{(x-1)^4}{4}$$ when we substitute in the endpoints of x, the results are the same $ =0.060025$\n\nThis solution is incorrect, but I do not understand why. The correct solution is the tedious way of actually calculating $$|\\ln(0.3)-(\\frac{x-1}{1}-\\frac{(x-1)^2}{2}+\\frac{(x-1)^3}{3})|$$ $=0.145$ (assuming $\\ln(0.3)$ gives the largest answer). Why is this so? Why does using error bound give an incorrect answer?\n\n\nDoes your series really alternate?\n\nEach term you add is negative for $x = 0.3$.\n\nAddendum: When $n$ is an even number you multiply an even term by $(-1)^{(n+1)}$ to reach a negative number.\n\n  \u2022 $\\begingroup$ not when $n$ is an even number $\\endgroup$ \u2013\u00a0Harrison Mar 10 '14 at 3:53\n  \u2022 $\\begingroup$ @Harrison: user1789954 is pointing out that for $x \\lt 1$, your series is not alternating. All terms are negative. Your alternating series error bound will work for $x \\gt 1$, but not for $x$ below that \"center of the expansion\". $\\endgroup$ \u2013\u00a0hardmath Mar 10 '14 at 3:57\n  \u2022 $\\begingroup$ Ahhh..I see. Thank you! $\\endgroup$ \u2013\u00a0Harrison Mar 10 '14 at 4:01\n  \u2022 $\\begingroup$ Here are the first few terms of the series: $-.7, -.245, -.114333, -.060025...$ $\\endgroup$ \u2013\u00a0Brad Mar 10 '14 at 4:01\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/76556/gravitational-force-exerted-by-a-rod-on-a-point-mass\nText:\nI have doubts with the solution of a certain problem. I will give the entire solution below and will lay out my doubts as well.\n\nA point mass $m_1$ is separated by a distance $r$ from a long rod of mass $m_2$ and length $L$.The objective is to find the total gravitational force exerted by the rod on the point mass.\n\nThis is how a particular author solved this question in a book.\n\nThe total mass of the rod was differentiated with respect to the total length of the rod, and each mass piece was called $dm$ and each length piece was called $dx$. Hence this equation was formulated:\n\n$\\large \\frac{m_2}{L}\\ =\\ \\frac{dm}{dx}$\n\nAlso, the distance between the point mass and each individual $dm$ piece was taken as $x$. Then the gravitational force between the point mass and each mass piece is given by:\n\n$F\\ =\\ \\large \\frac{Gm_1dm}{x^2}$\n\n$dm$ was substituted using the first equation, now the new equation becomes:\n\n$F\\ =\\ \\large \\frac{Gm_1m_2}{Lx^2}\\small dx$\n\nThis is then integrated from $x\\ =\\ r$ to $x\\ =\\ r + L$.\n\nMy question is this: how can we integrate $x$ with respect to $dx$?\n$dx$ represents the tiny length pieces of the rod, and $x$ represents the distance from the centre of the point mass to any point along the rod. How can we integrate $x$ with respect to $dx$, it does not make any physical sense to me? I am new to differentiation and integration, but I understand the basics well enough. If there is something wrong with this solution please tell me the right way to solve this problem, otherwise tell me how this solution makes sense.\n\n  \u2022 $\\begingroup$ You are right. One cannot integrate $x$ wit respect to $dx$. Maybe you are misinterpreting the author. A link to that solution would help. $\\endgroup$ \u2013\u00a0udiboy1209 Sep 7 '13 at 14:54\n  \u2022 $\\begingroup$ @udiboy. It is not on a site, it is from one of the coaching center study materials. The final answer comes out to be $F\\ =\\ \\frac{Gm_1m_2}{r(L + r)}$. Is this what you would get if you solved the problem the right way? $\\endgroup$ \u2013\u00a0Ram Sidharth Sep 7 '13 at 17:21\n\nI don't think that you really understand integration. Let me clear this up for you. In that question there is a rod of length l. You know how to calculate gravitational force between two point masses but not in continuous mass bodies.\n\nIf you apply the formula to find the gravitational force you don't know what to take the distance as because it is continuous body. Let us apply the formula $F\\ =\\ \\large \\frac{Gm_1m_2}{r^2}$ by taking r as the distance between the two bodies. Obviously we get a wrong answer. Now let us consider the rod to be made up of two bodies each of mass $m_2/2$ an length $l/2$ . Now we can define the force as $F\\ =\\ \\large \\frac{Gm_1m_2/2}{r^2} + \\frac{Gm_1m_2/2}{(r+l/2)^2}$ . Again we get a wrong answer. Now let us divide it into $N$ parts. Now the force can be represented as $F\\ =\\ \\large \\frac{Gm_1m_2/N}{r^2} + \\frac{Gm_1m_2/N}{(r+l/N)^2} +\\frac{Gm_1m_2/N}{(r+2l/N)^2}+...... \\frac{Gm_1m_2/N}{(r+(N-1)l/N)^2}+\\frac{Gm_1m_2/N}{(r+l)^2}$ Or $F\\ =\\ \\large \\frac{Gm_1m_2}{N}[\\frac{1}{(r)^2} +\\frac{1}{(r+l/N)^2} + \\frac{1}{(r+2l/N)^2} + .....\\frac{1}{(r+(N-1)l/N)^2}+\\frac{1}{(r+l)^2}]$ Now if we increase the value of $N$ we get a more accurate answer as the divisions become more smaller and more like point masses. Now if we make the value of $N$ very very high then we would get an accurate answer. This is where differentiation ad integration comes in. $\\large \\frac{m_2}{N}$ represents $dm$ and $\\large \\frac{l}{N}$ represents $dx$. Now you know why $dm\\ =\\large \\frac{m_2dx}{l}$\n\nLet us now apply this in the above expression. So now we have .. $F\\ =\\ \\large \\frac{Gm_1m_2dx}{l}[\\frac{1}{(r)^2} +\\frac{1}{(r+dx)^2} + \\frac{1}{(r+2dx)^2} + \\frac{1}{(r+3dx)^2} + .....+\\frac{1}{(r+l)^2}]$ This is same as integrating $\\ \\large \\frac{Gm_1m_2dx}{lx}$ from $x=r$ to $x=r+l$\n$Note:$ Every dm mass is not at the same distance from the point mass. We can integrate $x$ with respect to $dx$ as $dx$ is a small change in $x$ . You add all the values and you add $dx$ to $x$ in every next value. Hope this helps\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/504936/existence-of-a-lagrange-multiplier-euler-lagrange-equations-holonomic-constra\nText:\nLet $I=[a,b]\\subset \\mathbb{R}, G:\\mathbb{R}^n\\to \\mathbb{R}^k$ smooth, $0<k<n, M=G^{-1}(0)$. Assume that $DG(x)$ has full rank for all $x\\in M$. Fix $p_1,p_2\\in M$ and assume $u\\in W^{1,\\infty}(I,\\mathbb{R}^n)$ minimizes the functional given by\n\n$$J(u)=\\int_a^bF(t,u(t),\\dot{u}(t))dt $$\n\non the set $$S := \\{u\\in W^{1,\\infty}(I,\\mathbb{R}^n): u(a)=p_1,u(b)=p_2, u(t)\\in M\\}.$$\n\nShow there exists a function $\\lambda \\in W^{1,\\infty}(I,\\mathbb{R}^k)$ such that\n\n$$\\frac{d}{dt}F_p(t,u(t),\\dot{u}(t)) -F_u(t,u(t),\\dot{u}(t))= DG(u(t))^T\\lambda(t).$$\n\nI got as $\\textbf{hint}$:\n\nNear $p\\in M$, there are parameterizations $\\psi:V\\to U\\subset M$ where $V\\subset \\mathbb{R}^{n-k}$ and $U\\subset M$ contains $p$. Assume first $\\bigcup_t\\{u(t)\\}\\subset U$. Define $w:I\\to\\mathbb{R}^{n-k}$ by\n\n$$w(t) = (\\psi^{-1}\\circ u)(t) $$ and find a suitable functional $\\tilde{J}$ (on a suitable space) which corresponds to $J$ and is minimized by $w$. Use the Euler-Lagrange equations for $\\tilde{J}$ and the fact that $DG(\\psi(z))D_z\\psi(z)=0.$\n\n(for the general case, cover $\\bigcup_t\\{u(t)\\}$ with coordinate patches and localize by subdividing the set into pieces that lie within thise patches).\n\nI'm simply trying to prove the simpler case, but I have hard time finding such $\\tilde{J}$. I appreciate all the help and suggestions.\n\n  \u2022 $\\begingroup$ Well, $\\tilde J$ is very similar to $J$, just use $\\psi$ to pull $F$ to $V$ and use that $\\psi^* F(w(t)) = F(u(t))$. Similarly the analogue of the set $S$ will be the set of all $W^{1,\\infty}$ paths in $V$ between $w(a)$ and $w(b)$. Does this help a little? $\\endgroup$ \u2013\u00a0Marek Sep 25 '13 at 17:02\n  \u2022 $\\begingroup$ what do you mean with $\\psi^*$? $\\endgroup$ \u2013\u00a0DinkyDoe Sep 25 '13 at 18:10\n  \u2022 $\\begingroup$ A pullback: $f^*g(x) = g(f(x))$. You can use it to \"pull\" the function from $U$ to $V$. $\\endgroup$ \u2013\u00a0Marek Sep 25 '13 at 18:18\n  \u2022 $\\begingroup$ Right so the idea is to use $\\tilde{F}(w(t)) = (F\\circ \\psi) (w(t)) = F(u(t))$ where the $w(t)$ now live in $\\tilde{S}$ (like you said.) But why are we allowed to use Euler's equations on $\\tilde{J}(w(t))$? Also, I dont quite see how this helps... $\\endgroup$ \u2013\u00a0DinkyDoe Sep 25 '13 at 23:59\n  \u2022 $\\begingroup$ The difference is that $V$ is not a curved subspace whereas $M$ is. $S$ was defined by means of a constraint that the paths land in $M$. But we got rid of this by explicit parametrization of $M$. Therefore $\\tilde S$ now only contains unconstrained paths which is where the standard calculus of variations applies. As for why you can use Euler's equation: again, standard variational argument. And Lagrange multipliers arise the same they do in fin. dim. vector calculus with constraints. Please clarify how much of this you are familiar with so that the answerers can provide a suitable answer. $\\endgroup$ \u2013\u00a0Marek Sep 26 '13 at 7:59\n\nIt might be useful for you to see how to derive Lagrange multipliers in the finite dimensional setting and then generalize it to the variational setting.\n\nLet's work with a curve in $\\mathbb R^3$ for concreteness. Assume the curve is given implicitly by the constraint $G(\\vec x) = 0$ where $G: \\mathbb R^3 \\to \\mathbb R^2$ (and the rank of $G$ is 2 along the curve). Let's assume now that the curve can be parametrized as $\\psi: \\mathbb R \\to \\mathbb R^3, \\psi: x \\mapsto (x, g(x), h(x))$ in these coordinates (such coordinates can always be found because of the maximal rank assumption by the implicit function theorem). Then we have that $G(\\psi(x)) = G(x, g(x), h(x)) = 0$ for all $x$ and therefore $D(G \\circ \\psi)^i = G^i_x + G^i_y g' + G^i_z h' = 0$ for $i = 1,2$ (the argument of $G^i$ is $\\psi(x)$ but I suppress it for notational convenience).\n\nNow let's get back to finding extremes of the function $F : \\mathbb R^3 \\to \\mathbb R$ along this curve. This is equivalent to finding extremes of $F(\\psi(x))$ on $\\mathbb R$. But the condition for the extremes is $D(F\\circ \\psi) = F_x + F_y g' + G_z h' = 0$. We note that this is very similar for the equation of constraints given by the implicit function theorem and therefore it's enough to solve $\\nabla F = \\lambda_1 \\nabla G^1 + \\lambda_2 \\nabla G^2$ for two unknown constants $\\lambda_1, \\lambda_2$. We can suggestively rewrite this equation as $DF = DG ^T \\lambda$ with $\\lambda = (\\lambda_1, \\lambda_2) \\in \\mathbb R^2$.\n\nNow, returning to the variational setting, everything works out very similarly except that you replace $D$s above with $\\delta$s. Applying standard variational arguments you can then reduce integral equations to time-local equation for every $t$ and deduce the existence of a constant $\\lambda(t)$. The function $\\lambda$ will be in $W^{1,\\infty}(I, \\mathbb R^k)$ precisely because it must satisfy the Euler-Lagrange equation and all the other functions figuring there ($F\\circ u$, $G\\circ u$ and their derivatives) belong to $W^{1,\\infty}$ spaces.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/598787/any-other-prime-numbers-that-satisfy-this-condition-2\nText:\nAny other prime numbers that satisfy this condition?\n\nI asked if $a=2$ and $b=3$, then $a^2-1$ is an integer multiple of $b$. Is there any other pair of primes $a$ and $b$ that satisfy this relationship? The answer is yes, there are infinite pairs: set $a= \\text{any prime} =p$ and $b$ to any prime divisor of $p^2-1$. If we add the condition that $a<b$, are there any other pairs?\n\nMore Clearly,\n\nAre there primes $a,b$ where $a<b$ such that $a^2 -1$ is an integer multiple of $b$, aside from $a=2,b=3$?\n\n\nNo. $a^2-1=(a+1)(a-1)$ certainly has no prime divisors $>a+1$.\n\n\nHagen von Eitzen gave a very good succinct explanation, but I had some doubts and tried to attack it differently.\n\nI noted that $a^2-1$ is necessarily even, so if $kb=a^2-1$, we must have $2pb=a^2-1$, where $p,k \\in \\mathbb{N}$. I tried to show this implies $b\\leq a$, but didn't get very far.\n\nStill having doubts, I wrote a Python script to computationally check the proposition. I know this isn't a proof at all, I'm just sharing this hoping that it might be somehow helpful.\n\nThe primes.txt file is just a copy-paste of this list of the first 1000 primes, though you could of course do it with a larger list of primes if you wanted to. The code for my script is available here.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/69875/maximization-over-vectors-seen-as-column-matrices\nText:\nI am trying to solve the following question: $$\\text{Maximize } f(x_1,x_2,\\ldots, x_n)=2\\sum\\limits_{i=1}^n x_i^t A x_i+\\sum\\limits_{i=1}^{n-1}\\sum\\limits_{j>i}^n (x_i^tAx_j+x_j^tAx_i)$$ subject to\n$$x_i^t x_j=\\left\\{\\begin{array}{cc} 1&~i=j \\\\ -\\frac{1}{n}&~i\\ne j \\end{array}\\right.$$ where $x_i$'s are column vectors ($m\\times1$ matrices) with real entries and A is an $m\\times m$ $(n<m)$ real symmetric matrix.\n\nFrom some source, I know the answer as $$f_\\max=\\frac{n+1}n \\sum\\limits_{i=1}^n\\lambda_i^\\downarrow,$$ $\\lambda_i^\\downarrow$ being the eigenvalues of $A$ sorted in non-increasing order (counting multiplicity). But I am unable to prove it. I will appreciate any help (preferably with established matrix inequality, or Lagrange's multiplier method).\n\n  \u2022 $\\begingroup$ Just checking; does $$f(x_1,x_2,\\dots,x_n)=\\sum_{i=1}^nx_i^tAx_i+u^tAu$$ where $u=x_1+x_2+\\dots+x_n$? $\\endgroup$ \u2013\u00a0robjohn Oct 4 '11 at 21:15\n  \u2022 $\\begingroup$ yes, it is. Actually, I have expanded the sum... $\\endgroup$ \u2013\u00a0Tapu Oct 4 '11 at 21:26\n  \u2022 $\\begingroup$ This looks a lot like an equation I got when I was doing a least squares regression for a rigid rotation. If that is what you are doing, you might want to take a look at something I wrote up for sci.math. $\\endgroup$ \u2013\u00a0robjohn Oct 4 '11 at 22:55\n\nWhy Lagrange multipliers? Your maximization problem can be solved in a rather straightforward manner using some standard tricks in matrix theory. Let $e=\\frac1{\\sqrt{n}}(1,\\ldots,1)^T\\in\\mathbb{R}^n$ and $X=(x_1,\\ldots,x_n)\\in M_{m,n}(\\mathbb{R})$ (hence $X$ is \"tall\" and $X^T$ is \"wide\"). The problem can be formulated as maximizing $$ f(X)=\\textrm{tr}(X^TAX)+ne^TX^TAXe=\\textrm{tr}\\left((I+nee^T)X^TAX\\right) $$ subject to the constraint $X^TX=\\frac{n+1}{n}I-ee^T$.\n\nThe eigenvalues of $X^TX$ are $\\frac{n+1}{n}$ (with multiplicities $n-1$) and $\\frac{1}{n}$ (with $e$ being an eigenvector). Pick any orthogonal matrix $V$ whose last column is $e$. Then every $X$ that satisfies $X^TX=\\frac{n+1}{n}I-ee^T$ can be written as $X=U\\Sigma V^T$, where $U$ is some $m\\times m$ orthogonal matrix, $\\Sigma$ is the $m\\times n$ (tall) diagonal matrix with diagonal $\\left(\\sqrt{\\frac{n+1}{n}},\\ldots,\\sqrt{\\frac{n+1}{n}},\\sqrt{\\frac{1}{n}}\\right)$, and $V$ is an $n\\times n$ orthogonal matrix. Now let $e_n=(0,\\ldots,0,1)^T\\in\\mathbb{R}^n$. Then $$ \\begin{align} \\Sigma V^T(I+nee^T)V\\Sigma^T &= \\Sigma\\left[I+n(V^Te)(e^TV)\\right]\\Sigma^T \\\\ &= \\Sigma(I+ne_ne_n^T)\\Sigma^T \\\\ &=\\textrm{diag}\\left(\\underbrace{\\frac{n+1}{n},\\ldots,\\frac{n+1}{n}}_{n \\textrm{ entries}},\\ \\underbrace{0,\\ldots,0}_{m-n \\textrm{ entries}}\\right) = D\\quad\\textrm{(say)}. \\end{align} $$ Hence $$ \\begin{align} f(X)&=\\textrm{tr}\\left((I+nee^T)X^TAX\\right)\\\\ &=\\textrm{tr}\\left((I+nee^T)V\\Sigma^T U^TAU\\Sigma V^T\\right)\\\\ &=\\textrm{tr}\\left(\\Sigma V^T(I+nee^T)V\\Sigma^T U^TAU\\right)\\\\ &=\\textrm{tr}\\left(DU^TAU\\right) \\end{align} $$ and the maximum of $f$ occurs when $U^TAU$ is a diagonal matrix whose diagonal entries are in descending order. Thus the answer follows.\n\n  \u2022 $\\begingroup$ Please let me verify (and how it matches with my original problem)...and I'll then accept your answer. Thanks in advance! $\\endgroup$ \u2013\u00a0Tapu Oct 10 '11 at 17:38\n\nThis is not an answer but a reformulation of the question. As robjohn stated, the question becomes: Maximize $f:\\mathbb{M}^{m\\times n}\\mapsto \\mathbb{R}$ such that\n\n$$ f(X) = \\operatorname{tr}(X^TAX) + \\underbrace{u^TAu}_{\\in\\mathbb{R}} $$ This can be combined into $$ \\operatorname{tr}(X^TAX) + \\operatorname{tr}(u^TAu) = \\operatorname{tr}\\left(\\begin{bmatrix}X&u\\end{bmatrix}^T A \\begin{bmatrix} X &u\\end{bmatrix} \\right) = \\operatorname{tr}\\left(\\pmatrix{I &\\mathbf{1}}^TX^TAX\\pmatrix{I &\\mathbf{1}}\\right) $$ where $I$ is the identity matrix and $\\mathbf{1}$ is the all-ones vector. You might want to check these lecture notes page 123. I would try something similar by myself but I am burned out and I need to rest. I will edit later if I can come with anything.\n\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/201299/wrong-output-in-self-defined-quaternionic-multiplication\nText:\nI tried to define quaternionic multiplication in terms of pairs of complex numbers where I identify $\\mathbb{C}^2$ with $\\mathbb{H}$ via $(z,w)\\mapsto z+jw$. Consequently, I used the multiplication rule\n\nQ /: Q[a_, b_]*Q[c_, d_] := \n Q[a*c - Conjugate[b]*d, Conjugate[a]*d + b*c]\n\nStrangely enough, the input\n\nQ[0, 1]*Q[0, I]\n\nGives the incorrect output\n\nQ[I, 0]\n\nHowever, typing\n\nQ[0, 1]*Q[a, I]\n\nGives the correct output\n\nQ[-I, a]\n\nDoes anyone have an idea why this is happening?\n\n\nMultiplication with * is commutative (technically, Orderless), whereas quaternionic multiplication is not. Because * automatically puts its terms in normal order before multiplying, you sometimes end up with a commuted result. In your case this happens because I comes before 1 in the alphabet, and 0 comes before a, so the two terms are commuted (exchanged) automatically (try Sort[{Q[0, 1], Q[0, I]}] and Sort[{Q[0, 1], Q[a, I]}]).\n\nThe solution is to use NonCommutativeMultiply to prevent term reordering:\n\nQ /: Q[a_, b_] ** Q[c_, d_] := Q[a*c - Conjugate[b]*d, Conjugate[a]*d + b*c]\n\nQ[0, 1] ** Q[0, I]\n(*    Q[-I, 0]    *)\n\nQ[0, 1] ** Q[a, I]\n(*    Q[-I, a]    *)\n  \u2022 $\\begingroup$ Thank you so much!:) $\\endgroup$ \u2013\u00a0deepfloe Jul 1 at 11:55\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-practical-gas-law.735502/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple practical gas law\n\n  1. Jan 29, 2014 #1\n    Hi all...!\n\n    Gas laws.\n\n    Sorry about the simplicity of the question, but that should make it easy :)\n\n    I have two rigid containers open to air. One is 10 times the volume of the other.\n\n    I cap each.\n\n    I increase the temperature of each, 50 degrees.\n\n    What can I say about the pressure inside the containers, compared to each other?\n\n    A brief explanation?\n\n    Thanks ever so much.\n    Last edited: Jan 29, 2014\n  2. jcsd\n  3. Jan 29, 2014 #2\n    The pressure will be the same.\n\n    Just look at the ideal gas law:\n\n    PV = nRT, here P is pressure, V is volume, n is the number of molecules and T is the temperature. R is just a constant.\n\n    Solving for P you get:\n\n    P = nRT / V\n\n    Now, right after you close the lid on each container, notice that the number of molecules in each container is directly proportional to the volume of the container. Therefore the pressure will be the same. When you increase the temperature, it is proportional to the pressure in both cases, so when you increase the temperature equally much in both containers, you increase the pressure equally much. So the end pressure is the same.\n  4. Jan 29, 2014 #3\n    Thanks... this is how I see it as well... but I'm in disagreement with a PhD about it... (I'm not one, so I have less cred), so I appreciate the sanity check.\n\n    I just think of a (very tough) soap bubble in a pressure cooker.\n\n    If you add or subtract heat... he would have to believe that the bubble would change size one way or the other as you changed temperature.\n\n    Intuitively, I just couldn't see that happening. The gas would become equally more active on both sides of the bubble, so the bubble would retain its size. The only way to change the bubble size would be to add or remove gas.... so even if the bubble was slowly permeable... there would be no net exchange (discounting surface tension of the bubble, of course :)\n    Last edited: Jan 29, 2014\n  5. Jan 29, 2014 #4\n    It's not quite the same problem.\n    The gas inside the bubble has a higher pressure than the environment, to start with.\n    In your OP both containers have the same initial pressure.\n  6. Jan 29, 2014 #5\n\n\n    User Avatar\n\n    I would tend to think a bubble would be pretty close to zero gauge pressure - in other words, the same pressure as the environment.\n  7. Jan 29, 2014 #6\n    That's why I said:\n\n    \"discounting surface tension of the bubble, of course :)\"\n\n    So there you go.\n\n    Thanks to all!"}
{"text": "Retrieved from http://www.learn-math.top/calculating-the-reciprocal-distance-matrix-without-inflicting-complexinfinity/\nText:\nCalculating the reciprocal distance matrix without inflicting `ComplexInfinity`\n\nGiven a list of coordinates r (r[[i]]!=r[[j]]), I\u2019d like to know the reciprocals of distances of all pairs in the list, and for the convenience subsequent operations, the trace of the resulting matrix should be all zero. I feel that this should be a frequent need, but I can\u2019t do it optimally.\n\nMy code:\n\nR = Outer[Norm, r, r, 1];\nrR = Quiet[1/R] /. {ComplexInfinity -> 0.}\n\nBut this is not such a good idea as ReplaceAll is significantly slower than the other calculations in this code. Is it a good idea to use For or Table and loop over all indices, or is there a better way to do this?\n\n\n\n\nIf you know all of the r values are different, why not just set the diagonal to 0 afterward? Do UpperTriangularize[#, 1] + LowerTriangularize[#, -1] &@Quiet[1/R]. See here.\n\u2013\u00a0march\nSep 6 at 5:41\n\n\n\nOr what\u2019s your definition of distances of all pairs?\n\u2013\u00a0goodbye_M.SE\nSep 6 at 14:07\n\n\n\nI think Outer[Norm, r, r, 1] should be Outer[EuclideanDistance, r, r, 1]?\n\u2013\u00a0xzczd\nSep 6 at 14:41\n\n\n3 Answers\n\n\nIf the coordinates are machine reals and speed is an issue, I would Compile a function:\n\nreciprocalDist = Compile[{{r, _Real, 2}},\nR = Outer[Subtract, r, r, 1]; (* Outer[Norm,..] is not supported in Compile *)\nMap[If[# == 0, 0, 1/#] &@Norm[#] &, R, {2}]\n\nSeedRandom[0]; (* for reproducibility *)\nreciprocalDist[RandomReal[{-1, 1}, {4, 3}]] // MatrixForm\n\nTheoretically one could cut the speed in half by calculating the upper triangular part. One could preallocate a zero matrix and fill the distances two at a time with a Do loop, for instance.\n\n\n\nWhy DV? I can\u2019t see what\u2019s wrong, other than the stated limitations. Since no comment, obviously a cowardly troll not sincerely interested in improving the site.\n\u2013\u00a0Michael E2\nSep 15 at 23:46\n\nSince DistanceMatrix[] is built-in, it seems natural to use it for this problem. Using Michael\u2019s example, let me present two approaches:\n\nBlockRandom[SeedRandom[0]; (*for reproducibility*)\npts = RandomReal[{-1, 1}, {4, 3}]];\n\n(* method 1 *)\nWith[{id = IdentityMatrix[Length[pts]]}, 1/(DistanceMatrix[pts] + id) \u2013 id]\n\n(* method 2 *)\nDistanceMatrix[pts, DistanceFunction -> (With[{d = EuclideanDistance[##]},\nIf[d == 0, 0, 1/d]] &)]\n\nBoth should return\n\nreci[R_] :=\nWith[{l = Length@R}, {m = SparseArray[Band[{1, 1}] -> 1, {l, l}]}, (1 \u2013 m)/(R + m)]\n\nIf you\u2019re before v10.4:\n\nreci[R_] :=\nWith[{l = Length@R},\n\n\n\nTo the downvoter, I am interested in what was missing from my answer. Did I give too little detail? Or, was it considered incorrect in some way? Either way, would you please elaborate? I\u2019m not trying to complain here, I\u2019m just curious about what I could have done instead.\n\u2013\u00a0xzczd\nOct 6 at 11:09"}
{"text": "Retrieved from https://www.physicsforums.com/threads/de-of-the-form-y-by-a.243575/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nDE of the form y'' + by' = a\n\n  1. Jul 5, 2008 #1\n    Hi, I'm trying to solve the following equation\n\n    y'' + by' = a\n\n    But my answer doesn't make sense:\n\n    The question:\n    an object is flying through space, with velocity could be approximated as:\n    v_next = v_current + a*dt - damp*v*dt\n\n    dt - time increment taken repetitively\n    a - acceleration\n    damp - a constant\n\n    For large dt the approximation is inappropriate, find an equation that will do for large dt.\n\n    My go:\n\n    it looks like the above equation is \"similar\" to\n    x'' = a - damp*x'\n    x'' + damp*x' = a\n\n    part 1: x_c\n    [tex]x'' + damp*x = 0 => r*r + damp*r = 0; r = 0, r = \\frac{-1}{damp}[/tex]\n    [tex]x_c = c_1 + c_2e^{\\frac{-t}{damp}}[/tex]\n\n    part 2: x_p\n    x(t) = k*t\n    x'' + damp*k = a\n    (k*t)'' = 0\n    [tex]k = \\frac{a}{damp}[/tex]\n    [tex]x_p = \\frac{a*t}{damp}[/tex]\n\n    part 3:\n    [tex]x = x_c + x_p = c_1 + c_2e^{\\frac{-t}{damp}} + \\frac{a*t}{damp}[/tex]\n    we want x' approximation so\n    [tex]x' = \\frac{-c_2}{damp}e^{\\frac{-t}{damp}} + \\frac{a}{damp}[/tex]\n\n    what doesn't make sense is lets say damp -> 0 then x' should be a streight line but it doesn't look like it?\n\n    Where may I have gone wrong?\n\n    Thank you\n    Last edited: Jul 5, 2008\n  2. jcsd\n  3. Jul 5, 2008 #2\n    Your solution for nonzero damp looks fine to me: the system starts with some initial speed and then approaches asymptotically the so called \"terminal speed\", v(terminal) = a/damp, at which the pulling force balances the friction exactly: m*a = m*damp*v(terminal).\n\n    Your solution doesn't apply to damp=0 case because you assumed you got two distinct roots of the characteristic equation and hence the full general solution of the homogeneous equation in part 1. That assumption breaks down when damp =0.\n\n    When damp=0, the homogeneous diff. equation in part 1 is x\" = 0.\n    You get a double zero root of the characteristic equation hence only one exponent which can't capture the full general solution required to depend on two arbitrary constants not one. In such cases the general prescription tells you to look for solution of other types not exp(kt). In this case the solution is a linear function xc = c1 + c2*t. The double zero root in the exponent produces only the c1 term.\n    Last edited: Jul 5, 2008"}
{"text": "Retrieved from https://www.physicsforums.com/threads/linear-stuff-i-never-get-the-awnser.89423/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLinear stuff: I never get the awnser\n\n  1. Sep 17, 2005 #1\n    Linear stuff: I never get the awnser...!!!\n\n    [3 1 1 1 0]\n    [5 -1 1 -1 0]\n\n    Where the variables are X1 X2 X3 X4.\n\n    I always get somethignt that is far away from the answer.\n    The answer should be x1= -s x2=-t-s x3=4s x4 = t\n\n    Help please!\n  2. jcsd\n  3. Sep 17, 2005 #2\n    What did you do to begin?\n  4. Sep 17, 2005 #3\n    At first, i putted the first number in the frist row as 1.\n\n    so i get [1 1/3 1/3 1/3 0]\n    than i eliminate the 5 to make it a 0.\n    But its after that i got ****ed!\n\n  5. Sep 17, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n\n    What was the question?? I think you have two equations in 4 unknowns and both equations are equal to 0. (It is mildly confusing that you tell us the variables are X1, X2, X3, X4 but then write x1, x2, x3, and x4!)\n\n    Do you understand that there are many different ways to write the answer depending on exactly how you do this? It might be that your answers that are \"far away from the answer\" are, in fact, exactly on the answer!\n\n    You could do this by \"row reducing\" but with a simple problem like this I think just \"substitution\" is best.\n\n    The equations are 3x1+ x2+ x3+ x4= 0 and 5x1- x2+ x3- x4= 0. I might do something like add the two equations and get 8x1+ 2x3= 0 so that x3= -4x1.\n    Now, I choose (arbitrarily) to make x1= s. Then x3= -4s. Putting those into the two equations I get 3s+ x2- 4x+ x4= 0 or x2+ x4= s and\n    5s- x2- 4s- x4= 0 or x2+ x4= s. Since those two equations are exactly the same, I choose (again arbitrarily) to let x2= t and solve for x4= s-t.\n    My solution is x1= s, x2= t, x3= -4s, x4= s-t.\n\n    Is that \"far away from the answer\", which was x1= -s x2=-t-s x3=4s x4 = t? No, not at all. It might make a little more sense if I don't use the same letters as in your given answer: In my answer use \"u\" instead of \"s\" and \"v\" instead of \"t\". Then my answer is x1= u, x2=v, x3=-4u, x4= u- v. Looking at the \"given\" answer, I see that x1=u= -s. If I just replace u by -s, I will have both x1= -s and x3= -4u= 4s as in the \"given\" answer. MY x2 was v while the \"given\" x2 is -t-s. That would be the same if v= -t-s. In that case, my x4= u- t would become x4= (-s)-(-t-s)= -s+ t+ s= t, exactly as given.\n\n    That means that the set of points from my answer and the \"given\" answer are exactly the same! For example, If you take s= 1, t= 1 in the \"given\" answer you get x1= -1, x2= -2, x3= 4, x4= 1.\n    If you take s= -1, v= -2 (in my original form. In terms of u, v, I am taking u= -s= -1, v= -t-s= -2.) so that x= s= -1, x2= t= -2, x3=-4s= 4, x4= s-t= 1, just as before.\n\n    Because there are 2 (independent) equations in 4 unknowns, we have 4-2= 2 \"degrees of freedom\". We are free to choose any two parameters, arbitrarily, and write x1, x2, x3, x4 in terms of those two parameters. Of course, the equations you get will depend upon those arbitrary choices.\n    Last edited by a moderator: Sep 17, 2005\n  6. Sep 17, 2005 #5\n    Thanks bud, i'll look at it later on. If i have any problem, i'll post.\n\nSimilar Discussions: Linear stuff: I never get the awnser"}
{"text": "Retrieved from https://www.physicsforums.com/threads/frequency-addition.226941/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nFrequency Addition\n\n  1. Apr 6, 2008 #1\n    Hi everyone, first post so go easy :)\n\n    What I want to do is design a circuit to add two square wave frequencies into one output.\n\n    The use is for a vehicle fitted with a Karman Vortex mass airflow sensor.\n    The MAF sensor has a 5V square wave output of 0~150Hz.\n    The vehicle has been modified with twin throttle bodies currently plumbed back to a single MAF.\n    The idea is to run two MAF sensors, one for each throttle body.\n\n    So how do I combine the two signals into one output to the ECU?\n    The problem that I see is that even if the two signals are 180 degrees out of phase, they must still add. Ie. 50Hz + 50Hz input, regardless of phase, must = 100Hz output.\n\n    All feedback appreciated,\n\n  2. jcsd\n  3. Apr 7, 2008 #2\n    I think I get the idea. You don't care about phase and amplitudes. If one signal has a frequency of F1 and the other F2, you want the output to have a frequency of F1+F2, correct?\n\n    This would be new to me. The first thing I would do is look at a PPL VCO (phase lock loop, voltage controled oscillator).\n  4. Apr 7, 2008 #3\n    You got it, that's exactly what I'm looking for.\n\n    Ok then. Time to hit Google and look that up. Forgive me but I'm an electronics noob.\n  5. Apr 7, 2008 #4\n    the CD4046 is a CMOS PLL-VCO---of course there's always an easier way to do something.\n  6. Apr 7, 2008 #5\n    would a mixer work?\n    it will return F1-F2 and F1+F2\n    put a high pass filter to get rid of the lower frequency\n  7. Apr 7, 2008 #6\n    I really don't know edmondng. Care to elaborate?\n    EDIT: Actually given the low frequency's I'm dealing with (30~150Hz) would it even be possible to filter out the original input frequencies?\n\n    What about a half adder? Would that work?\n    Last edited: Apr 7, 2008\n  8. Apr 7, 2008 #7\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    The biggest problems are the 0 Hz thing and the \"square wave\" thing. You will need to understand what the ECU expects out of the MAF signal, before you can pick the best way (if one exists) of combining the two MAF signals into one for the ECU.\n\n    For example, if the ECU divides the MAF square wave down by two right away (like, it is only rising edge sensitive), then it is easier to combine the two signals with an adder or some such thing, since you wouldn't care about the duty cycle, only getting the right number of rising edges. You should also find out about the response time and stability criteria for the ECU, since you could confuse it if the two MAF sensors rolled through phase and gave the ECU some jittery edges.\n\n    If the ECU expects a 50% duty cycle input signal from the MAF, then you have to do more work. And the 0 Hz part is still a problem for this. What is the minimum frequency really, that is, what is it at idle. Probably not 0 Hz, right? If it is something reasonable, then you can take the two MAF signals, add them, and phase lock a 50% duty cycle signal to them as suggested already. Your comparison in the PLL will be between the added signal divided by 2, versus the PLL output signal divided by 2. That gets rid of jitter in the comparison, and as long as your PLL output is reasonably square, the ECU should be okay with it.\n\n    But even with a PLL, you are going to have to trade off PLL lock delay and jitter numbers, versus how fast and accurate you want your ECU to be able to respond.\n\n    You might be best off just to stay with the single MAF sensor to the ECU, and maybe make a simple comparison circuit for now that measures the difference in MAF from the two sensors, and just displays that for you to see. If the two MAFs are giving about the same readings anyway, then there is no reason to go to the pretty big trouble of combining the signals, IMO.\n  9. Apr 7, 2008 #8\n    Ok, the MAF sensor outputs a 5V square wave signal of ~30Hz at idle rising to ~150Hz at WOT.\n    The MAF sensors output is 50% duty cycle.\n\n    Your example above makes the most sense to me and eliminates problems introduced by phase shift.\n\n    But your right, I need to find out if the ECU is rising edge sensitive or requires a 50% duty cycle square wave.\n    So how much delay are we talking about here?\n\n    Obviously I've got a lot to learn, I'm going to reserch about PLL's and how they work.\n\n    Thanks for the great reply even if I didn't understand half of it :)\n  10. Apr 7, 2008 #9\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    So when you go to two MAF sensors, the output frequency range of each will now be about 15Hz-75Hz, right?\n\n    I'd suggest drawing a few representative waveforms (with different phases, etc.), to start to get an idea for how you might want to combine them. You can also do a full-digital PLL without an analog VCO for this low-frequency project. You would run a higher-freq digital clock (say, 32kHz like with a watch crystal, or 10MHz with a regular crystal oscillator), and oversample the MAF digital signals, and compute what the sum waveform would be, and output that to the ECU. That would be a fun all-digital project for you.\n  11. Apr 7, 2008 #10\n    You got it.\n    Hahah, sounds way over my head but if you point me in the right direction I'll give it a go.\n  12. Apr 7, 2008 #11\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    I'm not sure I can point you to a good design reference... maybe others reading this thread will know of a good reference for you to read up on this.\n\n    If a brief description would help, I'll try that. Basically you would have two high-frequency counters running, counting the half periods of each of the MAF sensor outputs. Each time a counter finished counting a half period, that information would go toward adjusting the half period of your final output counter.\n\n    So if you used a 32kHz watch crystal as your time base, you would get to a half period count of about 425/2 for a 75Hz input square wave from a MAF, and a half period count of about 2100/2 for a 15Hz input. Each time you got an update from either MAF's counter (each rising or falling edge of the MAF output waveform), you would use that number plus the most recent number from the other MAF channel to pre-set the next terminal count for the output counter. There's a little bit of arbitration and synchronization stuff that has to happen also, but that's a bit complicated to get into in this simple explanation.\n\n    So I think you see the concept of how it would work. I still think as a practical matter, it's best to just stick with a single MAF sensor output. Well, except it just occurred to me that the MAF output will now be too low in frequency, since you have divided the airflow in half. Yikes. Any chance the ECU can be re-mapped to handle the 1/2 MAF output frequency?\n  13. Apr 8, 2008 #12\n    You could be making more work for yourself than necessary.\n\n    If you expect the two MAF to output about the same frequency, you many only need to take the signal from one, and double it.\n\n    By the way, I really like the half-adder idea. Ultimately simple, if not a bit chaotic. Of course you may never know what the ECU expects to see. But if the ECU samples the MAV infrequently, instead of every wave, or doesn't do any sort of averaging, then it wouldn't work at all.\n    Last edited: Apr 8, 2008\n  14. Apr 8, 2008 #13\n    Well this is the problem, there is no guarantee that both MAF sensors would have the same airflow. Also if one filter was to become more restricted then the other, then that would throw it out of balance. Unfortunatly this won't work reliably.\n\n    I'll do some asking around and find out what the ECU needs\n  15. Apr 8, 2008 #14\n    How about using a frequency to Voltage Converter and Voltage to frequency converter to achieve this??\n    Use F to V converter for two inputs F1 and F2 to get V1 and V2 respectively, then add those two analog voltage and again use V to F converter to get a frequency output. Dont have idea on pros and cons.... just an idea to achieve frequency addition.\n\nSimilar Discussions: Frequency Addition\n  1. Addition of decibels (Replies: 21)\n\n  2. Addition of vectors (Replies: 12)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/significant-digits-ruler-to-what-decimal-point.687574/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSignificant Digits Ruler -To what decimal point\n\n  1. Apr 23, 2013 #1\n    Significant Digits Ruler -To what decimal point\n    To what decimal point do I write the number 30 if the uncertainty is 0.0625?\n    The ruler has 1/8 marks.\n\n    Thank you :)\n  2. jcsd\n  3. Apr 23, 2013 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Welcome to the PF.\n\n    You are required to show your Attempt at a Solution before we can offer any tutorial help. How would *you* approach this problem?\n  4. Apr 23, 2013 #3\n    I thought it would be 30.000 +- 0.0625 bc there are 3 sig figs in the uncertainty, but I'm not sure. :/\n    Also, should the uncertainty be rounded since it looks very precise? I'm so sonfused\n  5. Apr 23, 2013 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    There are three sources of error here. One is that you are rounding to the nearest mark. That introduces an uncertainty of exactly \u00b10.0625. Next is any error in the placing of the marks on the ruler. You could handle that by rounding the first uncertainty up a little, \u00b10.064, say. Third is any error in your decision of which is the nearest mark. That's the same in nature as the second error, but statistically independent.\n    Now, suppose you decide the error is \u00b10.07 and you measured the value as 30.375. It would be quite appropriate to write the answer as, say, 30.375\u00b10.070, strange though that may seem. But it would also be reasonable to compromise there, e.g. with 30.37\u00b10.08.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Significant Digits Ruler -To what decimal point\n  1. Significant digits (Replies: 2)\n\n  2. Significant Digits (Replies: 3)\n\n  3. Significant Digits (Replies: 2)\n\n  4. Significant digits (Replies: 1)\n\n  5. Significant digits (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/magnitude-of-current-induced.805827/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMagnitude of current induced\n\n  1. Mar 30, 2015 #1\n    . A circular coil of radius 5.0 cm and resistance 0.20 \u03a9 is placed in a uniform magnetic field perpendicular to the plane of the coil. The magnitude of the field changes with time according to B = 0.50e-20t T. What is the magnitude of the current induced in the coil at the time t = 2.0 s?\n\n    2. Relevant equations\n\n    \u03a6 = BAcos(0) = BA\n    emf = -d\u03a6B /dt = -d(BA)/dt = -A * d(B)/dt\n\n    3. The attempt at a solution\n\n    I differentiated that magnetic field and got -10e-20t, then multiplied that times pi*(.052), and ultimately divided by .2 \u03a9. My answer is 1.66*1018, which is nowhere near any of the answers. I feel like I'm following a logical path but obviously this isn't working, so I don't know what else to do.\n  2. jcsd\n  3. Mar 30, 2015 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Your mistake is that you dont take into account the self inductance L of the coil. It will be [itex] E+L\\frac{dI}{dt}+IR=0[/itex] where E(t) exactly as you calculated and R=0.2Ohm. You still have to calculate L from the geometrical data of the coil and then solve the differential equation. In doing that becareful that E is not constant but varies with time as of course the current I(t) do so also.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-integration.209566/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Integration\n\n  1. Jan 18, 2008 #1\n    [SOLVED] Simple Integration\n\n    1. Integrate the following\n\n    f(x) = sin x/(cos x )^2\n\n    3. Well i dont really want to use subsititution or anything since im pretty sure this can be done very simply but i dont know why i cannot get it...\n\n    sin x /cos ^2 x = sinx / 1- sin^2x\n\n    i know ln (cos x)^2 will give me (-2(cosx)*sinx)(1/cos^2x)\n\n    so thats not good...\n  2. jcsd\n  3. Jan 18, 2008 #2\n    How about u-substitution?\n  4. Jan 18, 2008 #3\n    You must use substitution. Using trig identities will only make it messier.\n\n    Hint: get f(x) into the form du / u ^2 .\n  5. Jan 18, 2008 #4\n    yea i just did it with u as well but that weird, cause this question was in my first section for integral calc (where we basically onyl went through basic rules like power rule, and integrals of other trig functions)\n\n    but anyways\n\n    let u = cosx\n\n    du/dx = -sinx\n\n    now i integrate - 1/(u)^2 * du\n    = integral of -u^-2 *du\n\n    = u^-1\n\n    = cos^-1 x\n\n    = 1/cos x\n\n    = sec x\n\n  6. Jan 18, 2008 #5\n\n\n    User Avatar\n    Homework Helper\n\n    Yup, that seems perfectly correct. Except for a small error, you forgot the Constant of Integration \"+ C\" at the end of the final result. :)\n  7. Jan 18, 2008 #6\n\n\n    User Avatar\n    Homework Helper\n\n    It happens in this case that there is another way to go about this, although it's not something you'd generally spot at first (you notice it after doing the u-substitution). You can also write\n    (sin x)/[(cos x)^2] as (1/cos x)\u00b7(sin x / cos x) = sec x tan x , which is the derivative of sec x . (This at least serves as a check on your result...)\n  8. Jan 20, 2008 #7\n    [tex]\\int\\frac{\\sin x}{\\cos^2 x}dx=-\\int\\frac{1}{\\cos^2 x}d(\\cos x)=-\\int (\\cos x)^{-2}d(\\cos x)=-\\frac{(\\cos x)^{-2+1}}{-2+1}+C=\\frac{1}{\\cos x} +C[/tex]\n    [tex]d(\\cos x)=-\\sin x dx[/tex]\n    [tex]dx=\\frac{d(\\cos x)}{-\\sin x}[/tex]\n    Last edited: Jan 20, 2008\n\nSimilar Discussions: Simple Integration\n  1. Simple integration (Replies: 2)\n\n  2. Simple Integral (Replies: 3)\n\n  3. Simple Integral (Replies: 10)\n\n  4. Simple integral (Replies: 7)\n\n  5. Simple Integral (Replies: 8)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/conductivity-of-organic-compund.229530/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nConductivity of organic compund\n\n  1. Apr 17, 2008 #1\n\n    Why doesn't CH3CH2OH (alcohol) conduct electricity but CH3COOH does?\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    I did some research on the website( answers.yahoo.com/question/index?qid=20080411203909AAqYaN1). It mentions about the difference of bonding between ionic coumpounds and covelant compund will result the difference in conductivity.\n\n    And in the end, the article mentions about\n    \"Sucrose and any form of alcohol are molecular, covalent compounds (organic molecules. covalent = non-metal/non-metal bond).\"\n\n    But isn't CH3COOH organic molecule?\n\n    I still don't really understand why CH3COOH will seperate into two ions, CH3COO- and H+ while alcohol won't.\n  2. jcsd\n  3. Apr 17, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n    Education Advisor\n    Gold Member\n\n    The compound you express as CH3COOH, ethanoic acid (commonly called acetic acid) is a weak organic acid and will dissociate into ions, therefore the ions can conduct electricity.\n  4. Apr 17, 2008 #3\n    Another way to think about it is to ask which molecule is more acidic, and why. In order to do this you have to consider the stability of the conjugate base that is formed when the two molecules lose a proton. Whichever molecule has a more stable conjugate base will be more acidic. What is it that makes CH3COO- more stable than CH3CH2O-?\n\nSimilar Discussions: Conductivity of organic compund\n  1. Inorganic Compunds (Replies: 9)"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3146359/pdf-of-the-product-of-two-independent-uniformly-distributed-random-variables/3146380\nText:\nSuppose that X and Y are independent U[0,1]-random variables. Find the probability density function of the product V = XY.\n\nI have seen that \ud835\udc53(\ud835\udc67)=(\u22121)^(\ud835\udc5b\u22121)log(\ud835\udc5b\u22121)(\ud835\udc67)/(\ud835\udc5b\u22121)! for the product of n independent random variables from 0 < z < 1 but I am not sure how to derive this.\n\n\n$P(XY\\leq t)=EP(XY \\leq t |Y)=E(\\frac t Y I_{Y >t}+I_{Y \\leq t})$ so $P(XY\\leq t)=t\\log (\\frac 1 t)+t$ for $0<t<1$. The density is $\\log (\\frac 1 t)$ for $0<t<1$.\n\n  \u2022 $\\begingroup$ Where did you get the -tlogt +t after the indicator functions? $\\endgroup$ \u2013\u00a0gigglegirl6 Mar 13 at 10:36\n  \u2022 $\\begingroup$ @gigglegirl6 $\\int_t^{1} \\frac t y \\, dy=t\\log\\, y|_t^{1}=-t\\log\\, t$ $\\endgroup$ \u2013\u00a0Kavi Rama Murthy Mar 13 at 11:37\n\nYour Answer"}
{"text": "Retrieved from https://politics.stackexchange.com/questions/1200/are-clergy-required-to-perform-interracial-and-or-same-sex-marriages-in-the-unit\nText:\nIn Loving v. Virginia, the United States Supreme Court invalidated laws against interracial marriages. This, along with laws around equal protection and non-discrimination made for a compelling argument that the right of marriage could not be denied on account of race. In 2009, a Louisiana Justice of the Peace who personally felt that interracial marriages were morally wrong was forced to resign because of his refusal to actually perform an interracial marriage. This, despite the fact that he was not prohibiting it - he just referred the ceremony to another JP who was willing to perform the ceremony.\n\nWhat I am trying to ascertain is if pastors and other ordained clergy are subject to the same compulsory mandate - that as an officer of the state (which technically pastors are when performing cermeonies) churches and pastors are subject to public accomodation provisions that are used to stop discrimination.\n\nMore generally, of course, is the precedent that would be set if the Supreme Court finds a constitutional right for individuals of the same gender to marry. Would a pastor, who personally holds that same sex marital relations is a sin, be compelled to provide \"equal access\" to gay and straight couples alike?\n\nWhat protections are afforded to religious personnel that would allow a pastor not to violate his or her conscience on the matter, but still be compliant with equal access provisions?\n\n  \u2022 2\n    The Judge could have choosen to fight for his rights to refuse he chose not to. But Clergy are not officers of the state. In fact they are barred from being officers of the state, by the seperation clause. Pat Roberson had to give up his ordination in 88(or 92) when he ran for president \u2013\u00a0SoylentGray Mar 28 '13 at 1:45\n  \u2022 1\n    When I became authorized to perform weddings in Virginia, I was informed that I was being deputized as an officer of the state to perform weddings. \u2013\u00a0Affable Geek Mar 28 '13 at 2:00\n  \u2022 4\n    This question could probably be rewritten a bit more succinctly: Are clergy allowed to refuse marriages that would be allowed under law? (My assumption is, yes, of course they can, as, for example, a Priest is under no obligation to marry two Jewish people--even though a justice of the peace may be.) \u2013\u00a0user1530 Mar 28 '13 at 4:50\n  \u2022 Difficult to say, if the church is operated out of a public space that offers non-religious services, there is precedence. \"The power to tax involves the power to destroy\" \u2013\u00a0user1873 Mar 28 '13 at 13:29\n  \u2022 1\n    I would imagine forcing a religious person to perform a religious ceremony contrary to his religion is direct violation of the First Amendment. Doesn't mean that may not happen, but I would be surprised if such order survived SCOTUS scrutiny. \u2013\u00a0StasM Mar 29 '13 at 23:33\n\nIn \"Capitalism and Freedom,\" Milton Friedman drew a distinction between \"positive harm\" and \"negative harm.\" \"Positive harm\" consists of e.g. pushing someone into the river so s/he drowns. \"Negative harm\" would be passing by the river, seeing someone drowning and not offering to help. The first is illegal, the second is not.\n\nThe civil rights laws are written so that no one can actively or \"positively\" interfere with the e.g. interracial marriage. That might consist of the preacher standing outside the church and turning away guests so that the couple couldn't have a proper wedding ceremony.\n\nBut American law is not written to force people to \"do the right thing\" (that is, to prevent negative harm). A preacher doesn't have to perform a marriage ceremony for an interracial couple, as long as s/he doesn't block or INTERFERE with another preacher's doing so. The clergyman may even (verbally) \"protest\" the marriage.\n\n  \u2022 3\n    I'm not convinced this answer is correct at all. In fact, 1st Amendment freedom of speech and freedom of assembly allow people to protest outside any event, including same-sex weddings. \u2013\u00a0BradC Aug 30 '17 at 15:30\n  \u2022 2\n    @BradC: Poeple are allowed to \"protest,\" as long as they don't block or otherwise \"interfere.\" Once it goes beyond a certain point, it becomes a crime. Abortion clinics are an example. \u2013\u00a0Tom Au Aug 30 '17 at 15:34\n  \u2022 Yes, some states have put boundaries and limits on protestors, but just as many of those laws have been struck down by the courts because of the First Amendment. And that has nothing to do with civil rights laws, per se. \u2013\u00a0BradC Aug 30 '17 at 15:36\n  \u2022 2\n    @TomAu Negative harm is not permitted by Title II of the civil rights act of 1964, which says \"All persons shall be entitled to the full and equal enjoyment of the goods, services, facilities, privileges, advantages, and accommodations of any place of public accommodation, as defined in this section, without discrimination on the ground of race, color, religion, or national origin\". justice.gov/crt/title-ii-civil-rights-act-public-accommodations \u2013\u00a0DavePhD Jun 5 '18 at 11:07\n  \u2022 1\n    @Evargalo Generally speaking, in the US there is no \"duty to assist\" or \"duty to rescue\" for bystanders, although a few states have exceptions. \u2013\u00a0BradC Jun 5 '18 at 14:15\n\nAs stated by the US Supreme Court in MASTERPIECE CAKESHOP, LTD., ET AL. v. COLORADO CIVIL RIGHTS COMMISSION ET AL. (emphasis added):\n\n\n  \u2022 Extra point for timeliness. \u2013\u00a0K Dog Jun 4 '18 at 18:31\n  \u2022 1\n    @KDog sadly, the person asking the question passed away in 2015 though \u2013\u00a0DavePhD Jun 4 '18 at 19:19\n  \u2022 The edited answer is much better; I've voted it up. \u2013\u00a0phoog Jun 4 '18 at 19:22\n\nNo, a pastor in the US cannot be forced to perform interracial or same-sex weddings against his or her religious convictions.\n\nWe need to carefully distinguish between similar sounding scenarios, because different laws and principles apply:\n\n1. A pastor exercising his freedom of religion in his own church walls or with his own congregation.\n\nFreedom of Religion wins here.\n\nThis is a private religious ceremony and can be subject to any restrictions the pastor and the church want to put on it. There is no \"public accommodation\" in a church.\n\nA church can require a couple be church members, or be baptized into the faith, or attend pre-marital counseling. The church can refuse to marry someone previously divorced, or a same-sex couple, or even an interracial couple.\n\nThey could certainly face social blowback for those decisions, but it's not against the law, and the government can't force them to perform a religious wedding for someone they don't approve.\n\nThis wouldn't apply to a government employee (a justice of the peace), see #3 below.\n\n2. A company offering a service to the public.\n\nThis is a \"public accommodation\", so federal anti-discrimination laws win here.\n\nIf you offer your reception hall to the public to be rented out for events (wedding receptions, etc), Federal civil rights laws say that you can't discriminate against someone based on their race, religion, or gender.\n\nThis is the \"wedding cake\" scenario: a bakery that offers their services to the public can't refuse to make a wedding cake for a same-sex couple. (They can, interestingly, refuse to write something on the cake they object to, since that is overruled by 1st Amendment \"freedom of speech\" considerations.)\n\n3. A government employee is asking for religious accommodation.\n\nThis is the Kim Davis scenario, and is a little more complicated.\n\nSo on one hand, the US Supreme Court found that the government itself cannot discriminate against same-sex marriage applicants, but at the same time, a government employee is within their rights to request a \"religious accommodation\" based on their sincere religious beliefs.\n\nThe key, though, is that the employer (the government in this case) only has to allow for \"reasonable\" accommodations of that employee's religious objections. (And yes, the definition of \"reasonable\" is the basis for many a lawsuit.)\n\nLet's take a simpler example of a religious accommodation: a US Marine objects to working in the kitchen on days when pork is served, because of her faith. It is entirely reasonable to only assign her mess duty on other days, or to reassign her to other grunt duties.\n\nKim Davis, on the other hand, refused any offer of reasonable compromise. If she objected to personally issuing marriage certificates for same-sex couples, it would have been \"reasonable\" to simply allow someone else in her office to issue them instead. She refused this option. She was ordered to do so by the court, and jailed for contempt when she refused. She lost all appeals.\n\n4. A private company employee asking for religious accommodation.\n\nThis is also potentially complicated, since the ideas of a \"public accommodation\" and an employee's religious freedom can come into conflict.\n\nTake a pharmacy that sells Plan B (\"morning after\") pills. The store sells them and has no restrictions on who can buy them, but what happens if one particular pharmacist has a religious objection to selling them?\n\n\"Public accommodation\" means that the store (as a whole) can't refuse to sell them, but a \"reasonable accommodation\" would be having someone else on duty handle the transaction. If there is no one else on duty, state laws differ: some states disallow religious objections in this case, other states handle it differently.\n\nIn Conclusion\n\nIt can be difficult at times to distinguish between these scenarios, and which principles might apply. But the pastor's freedom of religion definitely wins out in your original scenario, public accommodation isn't a factor for private religious organizations.\n\n  \u2022 Nice answer! The one additional thing I'd suggest would be directly addressing the case of the JoP linked in the question. I presume this would fall under #3 (he provided reasonable accommodation) with a side of #1 (pressured to resign for it, even if no crime was committed)? \u2013\u00a0Bobson Sep 1 '17 at 0:04\n  \u2022 1\n    @Bobson My read on the linked story is that the Justice of the Peace didn't request (from his superiors) a formal accommodation because of religious objection, he simply told interracial couples to go away and get it done somewhere else (neighboring wards). And even if he had, no \"reasonable\" remedy may have been available anyway if he was the only JoP in that specific ward. So similar to Kim Davis in #3, except he was pressured to resign, instead of being sued in court (which he likely would have lost). \u2013\u00a0BradC Sep 1 '17 at 2:26\n  \u2022 > If she objected to personally issuing marriage certificates for same-sex couples, it would have been \"reasonable\" to simply allow someone else in her office to issue them instead. Although, as I recall because of her position, all licenses were legally issued in her name even if physically someone else filled out the paperwork, etc. \u2013\u00a0eques Sep 13 '18 at 20:42\n\nThe problem is that the term \"marriage\" has a couple of very different contexts, which also muddies the waters when people try to discuss things like government recognition of gay marriage.\n\nQuite simply, the First Amendment holds sway in this case. The government may not pass any law regarding the establishment of a religion, or restricting a religion to practice its religion. So, forcing a religion to perform ceremonies that run contrary to their beliefs would absolutely violate this core principle. Now, where \"beliefs\" actually cause harm and violate the rights of others, the government can rule that religions can't do that, but that's not from the perspective of dictating religious beliefs as much as not allowing religion to claim beliefs to violate rights.\n\nI can't, for instance, form my own church and religion and claim I can have multiple grade-school girls as my wives, or claim that my religion demands I go out and beat Hispanics. Well, I can claim that, but it affords me no legal protections for those actions.\n\nI can, however, say that my religion does not recognize gay or interracial marriages as legitimate. While there is a right for people to worship as they please, that does not mean they can force a religion to change to suit their own preferences - they are free to find a religion that best suits them, and worship as they see fit.\n\nLoving vs Virginia invalidated government laws restricting marriages. This is where the dual context comes into play. When government is, generally, talking about \"marriage,\" they are talking about state-sanctioned and recognized civil unions. When a religion talks about marriage, they are talking about the religious sacrament of marriage as recognized by their religion. For example, the Catholic Church does not recognize divorces and subsequent marriages. Government does. That government recognition does not force the Catholic church in the US or other countries to change their stance, nor does the Catholic church's stance alter the status in the eyes of the government of even Catholics in regards to whether they can get divorced or re-married.\n\nIf I want to be \"officially\" married in the eyes of the government, I must get a marriage license, from the government, to be recognized and sanctioned by the government. People can be married in civil ceremonies without any religious context, and they are \"officially\" married. What the government does, to make it easier, is to also recognize marriage ceremonies performed by religions as government-recognized ceremonies, but a church wedding without also having an official non-secular government license is not \"married\" according to US law and government.\n\nThe Church of Me not performing a marriage ceremony does not prevent interracial couples or gay couples from getting an license and being officially recognized by the government as a married couple, so the government is not going to force any specific religion to perform ceremonies against their will.\n\nThat is why it was a big deal when individuals, in their capacity as government officials, tried to not issue the standard documents for marriage (Kim Davis, County Clerk in Rowan, KY, is the highest profile example).\n\nNY Times: Clerk in Kentucky Chooses Jail Over Deal on Same-Sex Marriage\n\nThe government can force other government officials and bodies to follow the secular, civic laws, but that \"marriage\" is not the religious sacrament.\n\n\nFirst sentence of the Bill of Rights reads\n\n\nWhile this only restricts actions that Congress may take, the SCOTUS has long ruled that the 14th Amendment's Due Process clause forces the Bill of Rights to apply to the states as well.\n\nSo no state legislature can make any law \"respecting an establishment of religion, or prohibiting the free exercise thereof.\"\n\nAny government mandate requiring clergymen to perform any religious ceremony contrary to their expressed wishes (however arbitrary those wishes may be) would be a prohibition on free exercise of religion. It would force clergymen to make utterances which they would find contrary to their consciousness.\n\nSince neither Congress nor any state legislature can pass a law with such a requirement, the clergy are not required to perform weddings which they do not find in keeping with their faith.\n\nYour Answer"}
{"text": "Retrieved from http://alphapowertrading.com/index.php/12-research-papers/95-portfolio-math-i\nText:\nJanuary 30, 2015\n\nWhen designing stock trading systems it is a good idea to view the problem, not only with a vision of what a trading program could or should do but also with an understanding of the environment in which this program will have to operate.\n\nIn a software trading program, which we can make it do whatever we want it to do, we only have logical decisions, calculations and statements in code to execute.\n\nNo feelings, no moods, no hunches and no trader psychology even if these in some way could also be programmed in. But this won't stop anyone from just gambling, be it in a discretionary manner or by using a partially or totally automated solution.\n\nA trading program will just do what it is programmed to do. It does not know the difference between good or bad code. It is up to the strategy designer to put in his program whatever he thinks is appropriate or required to make that program profitable over the long term. This may include technical and fundamental data that it be used or not; sentiment indicators, or outside input such as long-term prognosis on individual companies, minor or major world economic trends. Every strategy designer carries his own information set, to be used or not, in the making of trading decisions.\n\nThe not executed trade makes absolutely no profit and evidently no loss either.\n\nThe \"I told you so\", \"I knew\", or \"you could or should have\" also do not generate profits. It's the set of executed trading decisions, on whatever basis they were made, or will be made, that matters. It's the sum of all these trading/investment decisions that will determine if in the end you win or lose. This does not imply that you can avoid drawdowns; they are an inherent part of the investment/trading process.\n\nThe primary objective is not just to make money, the primary objective is first to survive the game, and then also prosper. Capital preservation should be the cornerstone of any stock trading/investment strategy. Be it investing or speculating; be it discretionarily, partially or totally automated: no capital means no trade, no game, no return.\n\nWhy Automate?\n\nYou design an automated trading strategy because you view the problem as amenable to logical trading rules, and the task too considerable to do it all by hand. You also want to know if the trading strategy you have in mind could have at least survived its past; because if it didn't, this would not be a good omen that it could outperform going forward.\n\nWhat should transpire in your trading script is your expertise, your knowledge, and understanding of what a stock trading strategy should do. But whatever the code's simplicity or complexity for that matter, the final outcome will entirely depend on the applied decision process that determined when and how much to buy, sell or hold.\n\nYou are, technically, designing an expert system. No wonder some use quite sophisticated tools to get there. It's not an easy task as evidenced by all the academic literature available and the huge number of people pushing their particular brand of trading methodology, philosophy or other.\n\nYou do automation because you can not type fast enough or handle more than just a few trades and stocks at a time. As a portfolio grows, it becomes more and more difficult to follow everything. Automation is an answer to a more systematic trading methodology. What you can do by hand can be done by machines at a much faster pace and grander scale.\n\nAs an individual or organization, your interest should be for the long term. And here long term means 20+ years. The idea is simple as to why: if your trading strategy blows up at any time before the 20+ years are up, you lose. Period. It's not just that you lost the game, you also lost the capital. All that time wasted, all those resources wasted. Maybe most important of all, it was your time wasted with absolutely nothing to show for it except your vaporized account.\n\nPerforming a task that might have been doomed from the start because your strategy design was inadequate to properly handle its future long-term trading environment is not a desirable outcome. It's something that should have been corrected before you started to \"play\" this stock market \"game\".\n\nAny trading strategy, be it discretionarily driven up to totally automated, needs to be based on something that is there. This from a single phenomenon to any combination of notions that can serve to describe what is happening in the market. A trade needs to be executable, if not, even if it is hardcoded in your trading strategy, it might have absolutely no economic value.\n\nThat is why you do long-term back tests. To see how your trading strategy would have behaved in general terms over long-term historical data. It is not enough to simulate on a single stock or instrument, the strategy must work at the portfolio level. This means multiple stocks over a long trading interval. These tests will also give you added knowledge as to general trading behavior, order placements and maybe help uncover new avenues to explore as you see more potential in some of your trading procedures.\n\nIf you do not do these back tests, on what grounds could you claim that your particular brand of trading strategy has some value going forward. If you want to sell me that your short-term trading strategy operating on breakouts is worthwhile, bring me a 20+ year test, at the portfolio level (say 30 stocks or more), showing that it was at least feasible in the past. If not, I pass. And there are many reasons why.\n\nThe Math\n\nThe most concise form of expressing the evolution of a portfolio of stocks of any size over any duration can be given using a payoff matrix equation of the form: A(t) = A(0) + \u03a3(H.*\u0394P). The symbol .* represents element-wise matrix multiplication. Easily done in Excel. The expression:\u00a0H.*\u0394P\u00a0resumes all the trading activity of any trading strategy over the life of a portfolio.\n\nI remember seeing this equation for the first time. It took me about 15 minutes to convert all my stuff to adhere to it, most of it was already in that general form, only a few minor modifications were required. It is what is implied by this equation that can be revealing. The output of the payoff matrix \u03a3(H.*\u0394P) is a vector of the cumulated profits and losses generated by each of the stocks in the portfolio over its entire history. What an easy way to express such a complex problem.\n\nAn equation representing a price series can be given by P(t) = P(0) + \u03a3 \u0394P, an initial price to which is added the cumulative sum of all price variations up to time t. It's not the only representation available, one could consider a stock price as if composed of a series of n consecutive numbers: P(t) = P(0), P(1), ..., P(n) spanning the trading or investment interval.\n\nThe holding inventory of about anything could also be written as: H(t) = H(0) + \u03a3 \u0394H, also saying an initial inventory to which is added the sum of all inventory changes. All the terms used in the payoff matrix could be view as starting with an initial value to which is added the sum of all variations over any duration. These series could be fragmented into as many segments as desired or required for whatever reason.\n\nIf there is no variation, there is no change. And if the sum of all variations over any duration is zero (\u03a3\u0394P = 0), you are left with the same thing: the initial value. It should be evident that the object of the \"game\" is to achieve: \u03a3(H.*\u0394P) > 0, meaning making an overall profit, no matter the size of the portfolio payoff matrix over whatever the duration.\n\nBoth the price series and the inventory series can be chopped in any which way one thinks appropriate. It's only when one decides to play the stock market game live that the manner in which one will chop, slice and dice these two particular data series that it will become critical. This requires a decision process: how much of this or that, when and at what price?\n\nThat is the problem to be solved, with a profitable outcome: \u03a3(H.*\u0394P) > 0. A portfolio payoff matrix ending in the red (no profit): \u03a3(H.*\u0394P) < 0, should not be part of acceptable solutions, neither should one design the output of a trading strategy to tend to zero: \u03a3(H.*\u0394P) \u2192 0 and this from either side of zero.\n\nOne needs to introduce a decision process in order to play the game. But there, there is no perfect equation for that. Yet, it's what will bring a change in inventory! I can write: D(t) = D(0) + \u03a3 \u0394D. The equation is right, but it has absolutely no monetary value, it is totally disembodied. However, if you play the game live, it is of the utmost importance. It will be this decision process that will determine what you will trade at what time and in what quantity. Therefore, this decision process needs to be divided into its components; you have time, prices, and quantity of shares bought or sold.\n\nAll this to come back full circle to A(t) = A(0) + \u03a3(H.*\u0394P) which resumes it all! The equation could have been written as: A(t) = A(0) + \u03a3(D.*(B.-S).*\u0394P) where the decision process is involved in the buying and selling,\u00a0of part\u00a0or all, of the outstanding inventory in each of the selected stocks in the portfolio. The holding inventory matrix\u00a0H\u00a0varies according to the result of the trading decision process in action:\u00a0H\u00a0=\u00a0D.*(B.-S).\n\nAny trading strategy that needs to survive over long periods of time (read 20+ years) need the following properties: feasibility, executability, marketability, and maintainability for the entire duration of the investment period. It's imperative that it be feasible, just as it needs to be logical and respond to just basic common sense.\n\nThings you can't do in real life, even if they are programmed and backtested using your trading software are not executable and therefore worthless. Things like trading a million shares a day when the average daily volume is less than 100k shares are not feasible in real life, but your backtest program could still process price data as if it was. This would result in a doomed and worthless trading strategy, and this from the start and by design.\n\nThe Payoff Matrix\n\nThe construction of a price matrix\u00a0P\u00a0can be the closing price of every stock in the DOW 30 over the last 25 years (making this a representative sample of the market as a whole). Every price element in the matrix p(i,j) would be the close of that day (i) for a particular stock (j). Since we are looking at the past, all p(i,j) would be recorded historical data and easily accessible. The Dow 30 price matrix\u00a0P\u00a0would grow in size, day by day, by j = 30 new closing prices, and for i = 0 to about 6,500 trading days (195,000 prices in all). The 195,000 entries in the\u00a0P\u00a0matrix would be the same closing prices for everyone.\n\nLooking at the\u00a0P\u00a0matrix, each column (j) is the actual closing price of a single stock. But the payoff matrix needs the difference in price from entry to exit with all price changes in between \u0394P. This difference matrix is easily constructed: \u0394p(i,j) = p(i,j) \u2013 p(i-1,j), subtract the previous price from current price for all the stocks in the\u00a0P\u00a0matrix and you get \u0394P. Since all the data in\u00a0P\u00a0was historical data, their daily change or price variations are also part of recorded history. Again, whatever the composition of the historical price matrix\u00a0P, its price variation matrix \u0394P\u00a0is also the same for everyone. One could view\u00a0P\u00a0and \u0394P\u00a0as a portfolio's stock selection to which can be applied any trading strategy\u00a0H.\n\nSo if I want to design an EOD (end-of-day) trading strategy from the above matrix, the price universe would be composed in the above case of 195,000 data points. Both\u00a0P\u00a0and \u0394P, are totally determined with no option to modify the price data since being taken as it is from historical records. If I design two different EOD trading strategies, they both will have to contend with the same closing price data.\n\nIf I want to extract some other information from the price series, it will be of my doing. Say I want a moving average, well the data is there, so I can do it. Will it be useful, this depends on what I want to do with it. It opens the door to a multitude of data interpretations. From the original data series, which was the same for everyone, I can now transform it into any suitable form in order to feed my trading decision surrogate.\n\nThe main course of a trading strategy is\u00a0H\u00a0the holding inventory matrix. Evidently, it will have the same size as\u00a0P\u00a0and \u0394P: 195,000 data elements. Each h(i,j) gives the state of the inventory level, the quantity held in each of the stocks on that particular day. It is with the decision matrix that we can slice and dice the price series at will and for whatever reasons we see fit:\u00a0H\u00a0=\u00a0D.*(B.-S).\n\nThe Buy & Hold is the easiest payoff matrix to build:\u00a0H.*\u0394P\u00a0where\u00a0H\u00a0is a matrix having its first row h(0,j) equal to the number of initial shares bought in each of the stocks, and all other rows, all 6,499 of them are identical to the first, since the initial inventory is held constant for the entire duration.\n\nI prefer writing the Buy & Hold strategy using scalar multiplication as: A(t) = A(0) + \u03a3(hoI.*\u0394P) where ho is the initial scalar vector the same size as j, while\u00a0I\u00a0is a matrix the same size as \u0394P\u00a0but entirely composed of ones. This produces a matrix where each column has for data element: h(i,j) = h(hoj,j). Using the 30 Dow stocks case, it can be considered as a Buy & Hold benchmark where the quantities held are constant, and \u0394P\u00a0the difference in the closing prices of the stocks in DJIA index. The same principles could be applied to the S&P100 or S&P500, and respectively generate matrices of 650,000 or 3,125,000 data elements over a 25 year period.\n\nBecoming a benchmark, all the characteristics of the index would equally apply to a Buy & Hold strategy. The historical Sharpe ratio, as well as any other ratios you might want to choose, long-term CAGR, drawdowns, including other statistics and metrics.\n\nAnother useful tidbit is that you can now compare other trading strategies to this basic benchmark, just as you can compare one trading strategy to another over the same stock selection and duration: is \u03a3(H(S#n).*\u0394P) >? \u03a3(H(S1).*\u0394P) >? \u03a3(H(B&H).*\u0394P) > 0 ? Is your latest trading strategy better than your previous ones and better than a Buy & Hold?\n\nWhere is the Money or Where is the Strategy\n\nDesigning a trading strategy should have for primary purpose to do better than a Buy & Hold benchmark. Otherwise, why bother? Do a Buy & Hold instead. Simply buy some index funds and be done with it. At least an index fund is designed to generate a long-term average performance that will tend to about the same performance level as a Buy & Hold strategy. Why strive and put the effort to in the end underperform an index?\n\nDoing less than the Buy & Hold over the same period of time is surely less than optimum, if not downright useless considering the small effort required in executing a Buy & Hold. Consider all the time saved not constantly monitoring the market, all that effort just to underperform.\n\nA strategy S1 playing EOD Dow stocks can be written as: A(t) = A(0) + \u03a3(H(S1).*\u0394P(Dow)). From its equation, one can surmise what is required: \u03a3(H(S1).*\u0394P(Dow)) > \u03a3(hoI.*\u0394P(Dow)). Whatever you design as a trading strategy, it must at least beat the Buy & Hold as its\u00a0final outcome. The closer your trading strategy is to the Buy & Hold, the closer your performance level will tend to the Buy & Hold. If\u00a0H(S1) \u2192 hoI, then the output of the payoff matrix will be about the same or close to it: \u03a3(H(S1).*\u0394P(Dow)) \u2192 \u03a3(hoI.*\u0394P(Dow)). Should S1 be the strategy of an index fund, then one should not be surprised if its payoff is about the same as the index.\n\nOne could compare multiple trading strategies by ordering them from most to least productive. The differences would be the result of how the trading strategy changed the inventory over time. How they would have sliced and diced the price series for all their trades. Not just one in and there, but all of them, since all trades will be accounted for over the trading interval. The question becomes: is\u00a0H(S#n) >?\u00a0H(S3) >?\u00a0H(S2) >?\u00a0H(B&H)? Is a particular trading strategy better than the others including better than the Buy & Hold or an index fund?\n\nFrom the holding matrix equation:\u00a0H\u00a0=\u00a0D.*(B.-S), the decision surrogate\u00a0D\u00a0determines if you buy or sell. It will slice the time series and thereby determine how long you will hold onto bought shares. But there is one ingredient still undefined: q(i,j), the quantity to be bought or sold for each stock over the entire trading interval.\n\nThe price of a transaction in an EOD system has already been determined, it is p(i+1,j), which is the next day at the open using a market order as demonstrated in the\u00a0DEVX V6\u00a0strategy. Market orders at the open for the next day is not the most efficient way to set entry prices. But all you want in the initial stage of designing a trading strategy is to find out if it is worthwhile even if it trades under adverse conditions.\n\nWhat is left to determine is:\u00a0B.*P\u00a0and\u00a0S.*P. I opted to use a buying trade unit (u) as a fix amount: u = q(i+1,j)p(i+1,j), with u having position sizes like $5k, $10k, $50k or more. This way I can scale the trading functions using this trade unit, and as a result, the payoff matrix would be scalable to any value I might want, need or consider feasible.\n\nThis would result in: u/p(i+1,j) = b(i+1,j), the quantity that will be bought on the next day at the opening price and that will be added to the then current inventory: h(i+1,j) = h(i,j) + b(i+1,j). The same would hold when selling shares: h(i+1,j) = h(i,j) - s(i+1,j). A strategy\u00a0H(S?) can be applied to a portfolio of selected stocks over the entire trading interval. For the Dow 30 stocks this would give: A(t) = A(0) + \u03a3(H(S?).*\u0394P(Dow)), and for the S&P100 100 stocks, one would get: A(t) = A(0) + \u03a3(H(S?).*\u0394P(SP100)).\n\nHaving set a buying trade unit (u), I can already answer some investment questions. If I double the trade unit by doubling the initial capital, what will happen? Easy: 2A(t) = 2A(0) + \u03a3(2H.*\u0394P). The position size, the trade unit, would be twice as big producing twice as much profits or losses as before. It's the same as if I traded 200 shares at a time compared to only 100 each trade; I would get twice as much profit or loss. I could scale the portfolio to any size I want as long as the trading strategy remains feasible, executable, marketable and sustainable.\n\nBy analyzing the whole trading strategy as a block, not in the Markowitz sense from period to period, but from start to finish, I can extract a different view of the portfolio management process. It is not anymore the determination of what can come next from period to period, from trade to trade, but more what is the combined and final output of all those trading decisions (all 195,000 or 650,000 decisions depending on the Dow 30 or S&P100 case). A global view of the problem is now required and it is all resumed in its payoff matrix: \u03a3(H.*\u0394P).\n\nStrategy Design\n\nThis provides a framework to develop trading strategies. Using a single price series as an example of a time-ordered sequence of prices, one could take from it a number n of time slices. At the limit, on an EOD strategy, one could buy at the open of the next day and sell the next. Thereby having n = 6,499 one day trades. The result would not be difficult to guess. It's equivalent to a Buy & Hold minus the trading expenses. Only slightly under-performing due to frictional costs. I could express such a strategy: \u03a3(H(S1).*\u0394P(Dow)) \u2192 \u03a3(hoI.*\u0394P(Dow)), as tending to the Buy & Hold.\n\nIf I took a trade every other week and sold the next, I would be in the market about \u00bd the time, or about 3,250 trading days. I could opt to be in the market only one day a week (1,300 days) set a fixed day or select at random one day a week. However, I should not expect to perform at the same level as if at a full market participation.\n\nThis raises basic and simple considerations to take care of. One of which is market exposure. A strategy might try splicing price series in such a way as to extract the best parts, those generating a profit. In reality, one might find that averaging out participating in the market half the time might also result in having one's equity working half the time as well. The equation: A(t) = A(0) + 1/2*\u03a3(H.*\u0394P) can express that the equity is only participating over half the trading interval, thereby generating half of the profit or loss even if this splicing is randomly generated.\n\nAnother consideration is the position size. Trading smaller positions of say half the usual trade size unit (u/2) will also have for equation: A(t) = A(0) + 1/2*\u03a3(H.*\u0394P) showing that reducing the bet size also reduces average generated profits. Understandably, Q is a profit/loss scaling factor as in q\u0394p.\n\nThe Buy & Hold is a full exposure and full participation trading strategy. And as such, historically it has managed to generate, on average, and including reinvested dividends, a little less than a 10% CAGR over long holding periods. As a matter of fact, holding for 20+ years will have a probability of generating a portfolio profit asymptotically approaching 1: E[\u03a3(hoI.*\u0394P(Dow)) > 0] \u2192 1. As Mr. Buffett has said many times before: \"... an almost guarantee to win in the long run\" simply due to market participation.\n\nIf you reduce exposure and participation, then you are operating with some drawbacks. It means that a trading strategy will have to compensate for these shortcomings. Say you use only half your capital and reduce your trade unit by half as well, this would result, on average, in A(t) = A(0) + 1/2*1/2*\u03a3(H.*\u0394P), the equivalent of putting only \u00bc of your capital at work. Should you want to beat the Buy & Hold with that, you better have an outstanding trading strategy since it might require something around a 16.27% compounded rate of return just to compensate and reach the same level as the Buy & Hold over a 25 year investment period: (1+r)t\u00a0= 1/4*(1+g)t, or in numbers: (1+0.10)25\u00a0= 1/4*(1+0.1627)25. Much more if you shorten the investment interval. Over a ten year period, it would require a CAGR of about 26.35% to be equivalent to its Buy & Hold counterpart: (1+0.10)10\u00a0= 1/4*(1+0.2635)10. This is a major drawback entirely related to the actual trading strategy\u00a0H\u00a0being used.\n\nNot only that but depending on your strategy design you might find yourself with an added problem: gradual performance degradation. This one is hidden and kind of insidious. It is aimed at the sequential and linear trader that is trying to average out his/her performance level over the year.\n\nSay you have a trading strategy designed to generate, on average, $300k/year from a starting capital of $1M, thereby an expected 30% return on your first year. Even though each year you make $300k, each year it would represent less and less as a percentage of the accumulating account. After just 9 years, your $300k gain would represent less than a 10% increase for the year. After 25 years, your original 30% return on the account is now less than a 4% increase.\n\nPortfolio Return Degradation\n\nPortfolio Return Degradation\n\n(click to enlarge)\u00a0\n\nIt is not the only source of long-term portfolio degradation. For instance, take a look at\u00a0Fixed Fraction\u00a0as a trading technique where one sets the same percentage gain or loss by setting a percent profit target and equal percent stop loss. The\u00a0paper\u00a0covers the subject and provides easy solutions to this problem as this one relates to the number of trades taken over the life of a portfolio. And since my trading strategies go for a large number of trades, it becomes wise to compensate for the fixed fraction shortcomings by simply over-compensating.\n\nI would say that it is imperative to address all these potential problems (and others) when designing a trading strategy in order to deliberately compensate for these deteriorating performance agents before or as they arise. And it is the responsibility of the strategy designer to do these things.\n\nNot compensating for these problems will not make them go away.\n\nIt is not after, that you need to compensate for these problems, it is before; right from the start. And that is by designing trading strategies that will take care of these problems or at least account for them and compensate where you can. Otherwise, you will have designed a trading strategy with inherent flaws that will inevitably show up as you spend more and more time in the pursuit of your alpha generation.\n\nAnother consideration is the need, not only to keep up with the Buy & Hold, but to outperform, not just once in awhile but over the long term where it really counts. If your end game is less than what could have been achieved by a simple Buy & Hold, then your efforts were kind of useless. And here again, the objective remains: \u03a3(H(S#n).*\u0394P(Dow)) > \u03a3(hoI.*\u0394P(Dow)) > 0. You definitely must outperform the Buy & Hold, otherwise... the Buy & Hold was the solution.\n\nAll that is being said is: if you deal with the same price series as everybody else, then the differences in payoff matrices, the outcome of the game, will have to come from the trading methodology itself.\n\n... to be continued ...\n\nCreated...\u00a0January 30, 2015,\u00a0 \u00a0 \u00a9 Guy R. Fleury. All rights reserved."}
{"text": "Retrieved from https://physics.stackexchange.com/questions/389276/rindler-coordinate-changes-in-relativity-leading-t0-a-conceptual-misunderstandin\nText:\nI have a conceptual problem relating to non-Lorentzian changes of coordinates in flat spacetime. I would be grateful is someone could point out my error.\n\nLet's change to Rindler coordinates in $1+1$-dimensional special relativity, \\begin{equation} x^\\mu = \\begin{pmatrix} t \\\\ x \\end{pmatrix} = \\begin{pmatrix} X\\sinh[\\alpha \\tau] \\\\ X \\cosh[\\alpha \\tau]\\end{pmatrix}. \\end{equation} Now, let's consider the four velocity, \\begin{equation} v^\\mu = \\frac{dx^{\\mu}}{d\\tau} = \\begin{pmatrix} \\frac{dt}{d\\tau} \\\\ \\frac{dx}{d\\tau} \\end{pmatrix} = \\begin{pmatrix} \\alpha X\\cosh[\\alpha \\tau] \\\\ \\alpha X\\sinh[\\alpha \\tau] \\end{pmatrix}. \\end{equation} Now let's calculate the magnitude of the four-velocity using the Minkowski metric, \\begin{equation} |v| = g_{\\mu\\nu}v^\\mu v^\\nu = g_{\\mu\\nu} \\frac{dx^\\mu}{d\\tau} \\frac{dx^\\nu}{d\\tau} = -\\left(\\frac{dt}{d\\tau}\\right)^2 + \\left(\\frac{dx}{d\\tau}\\right)^2 = -(\\alpha X)^2. \\end{equation} I've always been taught to set \\begin{equation} \\frac{dt}{d\\tau} = \\gamma, \\quad \\frac{dx}{d\\tau} = \\gamma \\mathbf{v}, \\end{equation} where $\\mathbf{v}$ is the three-velocity and $\\gamma = (1-\\mathbf{v})^{-1/2}$. This makes the magnitude of the four-velocity always equal to $-1$ in the original coordinates. This is a Lorentz scalar in that it is invariant under Lorentz coordinate transformation. However, now I am left with the situation that \\begin{equation} -1 = -(\\alpha X)^2. \\end{equation}\n\nQuestion: By changing coordinates I have gone from a constant function on spacetime to one that varies in coordinates. To me, this seems wrong. A constant function in one set of coordinates should be constant in all coordinates. Was I wrong in the inclusion of $\\gamma$? Or am I wrong in this final assertion? Should I set $X = \\pm 1/\\alpha$? But surely I can change $X$ as I like? Should this not be considered a function on spacetime?\n\n  \u2022 1\n    $\\begingroup$ If you are on a specific trajectory, $X$ is a function of $\\tau$ and you need to differentiate it. $\\endgroup$ \u2013\u00a0Javier Mar 1 '18 at 17:06\n  \u2022 $\\begingroup$ Thanks. The answer below gives me the situation when $X$ is constant, which is the constantly accelerated trajectory. However, your answer tells me that I don't have to make this choice, but in that case $X$ is a function of $\\tau$ in general. Hopefully I've understood. Thanks to all. $\\endgroup$ \u2013\u00a0Matta Mar 1 '18 at 17:49\n  \u2022 $\\begingroup$ Wait, that's right, $X$ is constant for this trajectory. What you just found out is that Rindler coordinates with parameter $\\alpha$ are adapted to the trajectory with $X=1/\\alpha$. $\\endgroup$ \u2013\u00a0Javier Mar 1 '18 at 17:57\n\nIn Minkowski spacetime coordinates $(t, x)$ the worldline of a body in hyperbolic motion, with a constant proper acceleration $\\alpha$ in the $+x$ direction, as function of proper time $\\tau$ is described by\n$t = 1/\\alpha \\sinh (\\alpha \\tau)$\n$x = 1/\\alpha \\cosh (\\alpha \\tau)$\nThe path in Minkowski is an hyperbola of equation\n$x^2 -t^2 = 1 / \\alpha^2$\n\nThe velocity is\n$v = (\\cosh (\\alpha \\tau), \\sinh (\\alpha \\tau))$\nThe acceleration is\n$a = \\alpha (\\sinh (\\alpha \\tau), \\cosh (\\alpha \\tau))$\n\nWith $\\eta_{\\mu \\nu} = diag(-1, 1)$ metric tensor in 1+1-dimensional Minkowski, we have\n$v^2 = -1$ time-like vector\n$a^2 = \\alpha^2$ space-like vector\n$a \\cdot v = 0$ velocity and acceleration are orthogonal\n\nThe worldline refers to a body with a specific acceleration, however a Rindler reference frame is made up of a continuous set of worldlines each with a constant acceleration, so that the Rindler coordinates are $(\\tau, \\alpha)$ with $-\\infty \\lt \\tau \\lt \\infty$ and $\\alpha \\gt 0$. A constant $\\alpha$ in Rindler coordinates picks up a stationary observer in that reference frame.\nThe $X$ coordinate in the question is equal to $1 / \\alpha$ as per definition of Rindler coordinates, so there is no contradiction in your calculation of the squared velocity.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3021467/left-continuous-adapted-process-x-is-optional\nText:\nI was reading through \"Limit Theorems for Stochastic Processes\" by Jacod and Shiryaev and came across\n\n1.24 Proposition: Every process $(X_t)_{t \\geq 0}$ that is left continuous and adapted is optional.\n\nThe setup is the follwoning: Let $(\\Omega,\\mathcal{F},(F_t)_{t \\geq 0}, P)$ be a filtered probability space with right continuous filtration.\n\nIn the proof, they define a new sequence of process $$X^n := \\sum_{k \\in \\mathbb{N}}X_{k/2^n} 1_{[[k/2^n,(k+1)/2^n[[}$$ and claim that for every $(t,\\omega) \\in [0,\\infty) \\times \\Omega$, we have $X^n_t(\\omega) \\rightarrow X_t(\\omega)$ for $n \\rightarrow \\infty$. Why does $X^n$ converge pointwise to $X$ ? I do not see why this has to hold.\n\nThanks a lot in advance!\n\n\nIt's pretty simple: For $t \\geq 0$, we have $$ X_t^n = X_{2^{-n}\\lfloor t2^n \\rfloor}. $$ Now notice that $2^{-n}\\lfloor t2^n \\rfloor \\leq t$ and $2^{-n}\\lfloor t2^n \\rfloor \\to t$ ($n \\to \\infty$) and use the left continuity of $X$.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1100198/expected-value-and-variance-of-a-stochastic-process\nText:\nHaving trouble finding expected value and variance of a stochastic process defined by SDE:\n\n$dX_{t} = a X_{t} dt + b dB_{t}$\n\n$X_0 = x$, $a$ and $b$ are constant values, $B_t$~$N(0,t)$\n\nThank you for any help or pointers. I will now post my progresses:\n\n1) Considering an auxiliary process $Z_t=X_te^{-at}$\n\n2) Using Ito's formula to derive $dZ_t$ omitting quadratic covariance term due to it being between a stochastic and a determinist process (=0):\n\n$dZ_t = e^{-at} dX_t+X_t(-ae^{-at}) dt$\n\n3) Plugging in $dX_t$:\n\n\n\n\n4) Applying the integral on both sides ( change of variable from t to s inside the integral)\n\n$\\int_{0}^{t}dZ_s = b \\int_{0}^{t}e^{-as}dB_s $\n\n$Z_t-Z_0 = b \\int_{0}^{t}e^{-as}dB_s $\n\n5) Plugging back in $Z_t=X_te^{-at}$ and isolating $X_t$\n\n\n$X_t=X_0e^{at} + be^{at}\\int_{0}^{t}e^{-as}dB_s$\n\n6) Applying expectations\n\n$\\mathbb{E}(X_t)=xe^{at} + be^{at}\\,\\mathbb{E}(\\int_{0}^{t}e^{-as}dB_s)$\n\nI end up with this expression, now I know that I should use the Dol\u00e9ans exponential to prove that the stochastic integral is 0. But how can I proceed further to recover both expected value and variance?\n\n  \u2022 $\\begingroup$ So what happens if you plug in $dX_t$? (And I suppose $(B_t)_{t \\geq 0}$ is a Brownian motion. If so, the statement \"$B_t \\sim N(0,1)$\" is not correct.) $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:01\n  \u2022 $\\begingroup$ You plugged in $dX_t$, so there should be no \"$dX_t$\" in the last 3 lines. (Note that the expression $dB_t dX_t$ doesn't even make sense...) Consequently, you end up with $$dZ_t = b dB_t.$$ Solve it! $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:07\n  \u2022 $\\begingroup$ yes, thank you I'll fix the mistakes you pointed out and try to solve it, kinda new to Latex and stoch calculus, please bear with me $\\endgroup$ \u2013\u00a0Clemente Cortile Jan 11 '15 at 17:09\n  \u2022 $\\begingroup$ You are welcome. (There is a typo in my previous comment, it should read $dZ_t = b e^{-a t} \\, dB_t$.) $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:24\n  \u2022 $\\begingroup$ So far your calculations are correct. What does this tell you about $X_t$? $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:43\n\nHint: The stochastic integral\n\n$$M_t := \\int_0^t e^{-as} \\, dB_s$$\n\nis a martingale. Hence, $\\mathbb{E}M_t = \\mathbb{E}M_0=0$. In order to calculate the variance of $X_t$ use It\u00f4's isometry.\n\nAlternative approach: Since stochastic integrals are martingales, we have\n\n$$\\mathbb{E}X_t- \\mathbb{E}X_0 = \\int_0^t a \\cdot \\mathbb{E}X_s \\, ds,$$\n\ni.e. $m(t) := \\mathbb{E}X_t$ solves the ordinary differential equation (ODE)\n\n$$m'(t) = a \\cdot m(t) \\qquad m(0) = \\mathbb{E}X_0.$$\n\nThe (unique) solution is $m(t) =e^{at} \\mathbb{E}X_0$. Similarly, using It\u00f4's formla, one can show that\n\n$$\\mathbb{E}(X_t^2)-\\mathbb{E}(X_0^2) = \\int_0^t \\left( 2a \\mathbb{E}(X_s^2) + b^2 \\right) \\, ds.$$\n\nConsequently, $\\sigma(t) := \\mathbb{E}(X_t^2)$ solves\n\n$$\\sigma'(t) = 2a \\sigma(t)+b, \\qquad \\sigma(0) = \\mathbb{E}(X_0^2).$$\n\nSolving this (linear) ODE yields $\\mathbb{E}(X_t^2)$.\n\nRemark: The process $(X_t)_{t \\geq 0}$ is called Ornstein-Uhlenbeck process.\n\n  \u2022 $\\begingroup$ How is the expected value of a process defined? Does it depend on $t$? $\\endgroup$ \u2013\u00a0user415535 Sep 13 '17 at 10:03\n  \u2022 1\n    $\\begingroup$ @user21312 Yes, it does depend on $t$; the expected value is the mapping $m(t) := \\mathbb{E}(X_t)$. $\\endgroup$ \u2013\u00a0saz Sep 13 '17 at 12:51\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/346384/how-to-turn-this-into-an-equation-and-then-sum-the-series\nText:\nI'm reading \"How would you move Mount Fuji?\", and one of the puzzzles/questions is:\n\nA train leaves Los Angeles for New York at a constant speed of 15 miles an hour. At the same moment, a train leaves New York for Los Angeles on the same track. It travels at a constant 20 miles an hour. At still the same moment, a bird leaves the Los Angeles train station and flies toward New York, following the track, at a speed of 25 miles an hour. When it reaches the train from New York, it instantly reverses direction. It travels at the same speed until it reaches the train from Los Angeles, when it reverses again, and so forth. The bird flies back and forth between the two trains until the very moment they collide. How far will the bird have travelled?\n\nIn the answer, they mention that it could be solved by using an infinite series (and that most people will probably have forgotten how to do it when asked in an interview, and that John von Neumann did so almost instantly when asked this type of question), but they do it another way. First, they note that the time until the trains crash is given by h, and d = 15h + 20h, where d is the distance (they use 3500). Thus, h = 100 hours. The distance that the bird travels is 25d. Thus, the answer is 2500 miles.\n\nI'm curious though, how does one solve this using an (infinite) series? How does one write this problem as a series in the first place? The only thing that I can get is that the series (of the hours that the bird spends flying) starts like this: (77.77, 9.73, ...)\n\n\nI will take a general tack; yes, you use an infinite series, as follows. We begin with the trains being a distance $d_0$ apart. After the bird goes up and back, the trains will be a distance $d_1$ apart. Once we find this distance, we will be able to sort out a geometric series because the bird repeats the same behavior ad infinitum.\n\nThe bird initially flies a distance $d_u$ (distance up) that is equal to $v_b t_u$, where $v_b$ is the bird's speed. This is equal to $d_0 - v_2 t_u$, where $v_2$ is the speed of the NY-to-LA train. Then $t_u = d_0/(v_b+v_2)$, and\n\n$$d_u = \\frac{v_b}{v_b+v_2} d_0$$\n\nNow the bird flies back to the other train and intercepts it at time $t_d$ later. The LA-to-NY train has traveled a distance $v_1 (t_u+t_d)$ by this time. The bird's position is at $d_u-v_b t_d$, and we solve for $t_d$. By then, the bird will have traveled at distance $v_b (t_u+t_d)$. The result is that, on the first pass, the bird travels a distance of\n\n$$v_b (t_u+t_d) = \\frac{2 v_b^2}{(v_b+v_1)(v_b+v_2)} d_0$$\n\nMeanwhile, the trains at this time are a distance apart of\n\n$$d_1 = [d_0-v_2(t_u+t_d)] - v_1 (t_u+t_d) = \\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}d_0$$\n\nBy now, we can see how to construct the series that will lead to the result. When the trains are a distance $d_k$, the bird travels a distance\n\n$$\\frac{2 v_b^2}{(v_b+v_1)(v_b+v_2)} d_k$$\n\n\n$$d_k = \\left [\\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}\\right ]^k d_0$$\n\nTherefore, the total distance the bird travels is\n\n$$\\begin{align}d &= \\frac{2 v_b^2 d_0}{(v_b+v_1)(v_b+v_2)} \\sum_{k=0}^{\\infty} \\left [\\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}\\right ]^k \\\\ &= \\frac{\\frac{2 v_b^2}{(v_b+v_1)(v_b+v_2)} d_0}{1-\\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}}\\end{align}$$\n\nI will leave the rest of the algebra to the reader. The final result is\n\n$$d = \\frac{v_b}{v_1+v_2} d_0$$\n\nFor the stated problem, the answer is $[25/(15+20)] 3500 \\text{miles} = 2500 \\text{miles}$.\n\n\nSuch a simple result from a relatively complicated analysis screams for a simple explanation. I guess you can look at it this way. Imagine the NY train is held fixed while the LA train moves at $v_1+v_2$ toward NY. The bird flies out at the same time at its speed $v_b$ and simply flies on. The LA train gets to NY in time $t=d_0/(v_1+v_2)$; in that time, the bird flies a distance $v_b d_0/(v_1+v_2)$.\n\n\nLet $v_a$, $v_b$ and $v$ be the speeds of the two trains and of the bird respectively (the first being the one from which the bird leaves), $d$ the distance between the cities. Let $t$ denote the time variable, and $t_k$ ($k\\in\\mathbb N$) the time starting from $t_0=$ in which the bird reverses direction for the $k$-th time. We may refer to Los Angeles and New York as $A$ and $B$ respectively.\n\nBy the time the bird has flown $t_1$, the trains have moved by $v_at_1$ and $v_bt_1$ respectively. Since the bird has to reach the second train we have $vt_1=d-v_bt_1$, so that $$ t_1=\\frac{d}{v+v_b} $$ Now the bird, which is $t_1v_a$ far from $B$, reverses direction and flies a distance $t_2v$ meeting the first train which now is $(t_1+t_2)v_a$ far from $A$. So $t_2v=d-(t_1+t_2)v_a-t_1v_b$ which gives $$ t_2 = \\frac{d - t_1(v_a+v_b)}{v+v_a} = d\\frac{v - v_a}{(v+v_a)(v+v_b)} $$ Now suppose you are at time $t_{2n}$, i.e. the bird touches the first train which is now $\\sum_{i=1}^{2n}t_iv_a$; by that time, the second train is far $\\sum_{i=1}^{2n}t_iv_b$ from $B$. The bird will meet the second train after $t_{2n+1}$, so $t_{2n+1}v=d-\\sum_{i=1}^{2n}t_iv_a-\\sum_{i=1}^{2n}t_iv_b-t_{2n+1}v_b$ which gives $$ t_{2n+1} = \\frac{d-\\sum_{i=1}^{2n}t_i(v_a+v_b)}{v+v_b} $$ The same reasoning shows that $$ t_{2n} = \\frac{d-\\sum_{i=1}^{2n-1}t_i(v_a+v_b)}{v+v_a} $$\n\nUsing induction you can show that $$ \\begin{cases} t_{2n} = & d\\frac{(v-v_a)^n(v-v_b)^{n-1}}{(v+v_a)^n(v+v_b)^n} \\\\[6pt] t_{2n+1} = & d\\frac{(v-v_a)^n(v-v_b)^n~~}{~(v+v_a)^n(v+v_b)^{n+1}} \\end{cases} $$ So altogether the bird will fly a distance of \\begin{align} v\\sum_{n=1}^\\infty t_n = & v\\left( \\sum_{n=1}^\\infty t_{2n} + \\sum_{n=0}^\\infty t_{2n+1} \\right) \\\\ = & dv\\left(\\frac{1}{v-v_b}+\\frac{1}{v+v_b}\\right) \\sum_{n=0}^\\infty \\left[ \\frac{(v-v_a)(v-v_b)}{(v+v_a)(v+v_b)} \\right]^n - \\frac{dv}{v-v_b} \\end{align} The term $\\frac{dv}{v-v_b}$ has been taken out since the first sum starts from $n=1$ and not $n=0$.\n\nSince $\\sum_{n=0}^\\infty x^n=\\frac{1}{1-x}$ for $x\\in(0,1)$, you have a total distance of $$ dv\\left(\\frac{1}{v-v_b}+\\frac{1}{v+v_b}\\right) \\frac{1}{1- \\frac{(v-v_a)(v-v_b)}{(v+v_a)(v+v_b)} } - \\frac{dv}{v-v_b} = \\frac{vd}{(v_a+v_b)} $$\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1966062/how-do-you-find-the-area-of-a-parallelogram-with-the-vertices/1966509\nText:\nHow do you find the area of a parallelogram with the following vertices; $A(4,2)$, $B(8,4)$, $C(9,6)$ and $D(13,8)$.\n\n\nclosed as off-topic by user21820, Xander Henderson, Jos\u00e9 Carlos Santos, YuiTo Cheng, RRL May 18 at 2:36\n\n\n\n  \u2022 $\\begingroup$ Use the determinant. $\\endgroup$ \u2013\u00a0Steven Gubkin Oct 13 '16 at 13:05\n\nFor this, we plan to use the Shoelace formula.\n\nShoelace Formula: Given the coordinates of vertices of a polygon, its area is found by $$A=\\frac 12\\left|\\sum_{i=1}^{n-1}x_iy_{i+1}+x_ny_1-\\sum_{i=1}^{n-1}x_{i+1}y_i-x_1y_n\\right|$$ Or, in other words, we have $$A=\\frac 12|x_1y_2+x_2y_3+\\ldots x_{n-1}y_n+x_ny_1-x_2y_1-x_3y_2-\\ldots -x_ny_{n-1}-x_1y_n|$$ Where $A$ is the area of the polygon, and $(x_i,y_i)$ with $i=1,2,3\\dots$ are the vertices of the polyon\n\nSo with your case, the vertices are $A(4,2), B(8,4), C(9,6)$ and $D(13,8)$. We let $x_1=13,y_1=8,x_2=9,y_2=6,x_3=4,y_3=2,x_4=8,y_4=4$ and the area is given by $$A=\\frac 12|13\\cdot 6+9\\cdot 2+4\\cdot 4+8\\cdot 8-9\\cdot 8-4\\cdot 6-8\\cdot 2-13\\cdot 4|\\\\=\\frac 12\\cdot 12=6$$\n\n  \u2022 $\\begingroup$ You answered with another person's answer? xD $\\endgroup$ \u2013\u00a0Billy Rubina Oct 13 '16 at 8:15\n  \u2022 4\n    $\\begingroup$ This is hitting a nail with a sledge hammer. There aren't many polygons that are as simple to handle as parallelograms. Or to be more specific, it is very probably the computation for parallelograms (and derived from that, triangles) that serves as basis for deriving the shoelace formula. $\\endgroup$ \u2013\u00a0Marc van Leeuwen Oct 13 '16 at 9:14\n\nThe absolute value of the cross product of two vectors $\\vec{a}, \\vec{b} \\in \\mathbb{R}^3$ spanning the parallelogram is its area:\n\n$$A_\\text{parallelogram}= \\left|\\vec{a}\\times\\vec{b}\\right|$$\n\nSo in your case we have to write the points in $\\mathbb{R}^2$ as vectors in $\\mathbb{R}^3$ and apply the formula:\n\n$\\vec{AB}\u00a0= \\begin{pmatrix}8\\\\4\\\\0\\end{pmatrix} -\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} =\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix}$\n\n$\\vec{AD}\u00a0= \\begin{pmatrix}13\\\\8\\\\0\\end{pmatrix} -\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} =\\begin{pmatrix}9\\\\6\\\\0\\end{pmatrix}$\n\n$A_\\text{parallelogram}= \\left|\\vec{AB}\\times\\vec{AD}\\right| = \\left| \\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} \\times \\begin{pmatrix}9\\\\6\\\\0\\end{pmatrix} \\right| = \\left|\\begin{pmatrix}0\\\\0\\\\6\\end{pmatrix} \\right| = 6$\n\nYou might have noticed that this simplifies to\n\n$$A_\\text{parallelogram}= (b_1 - a_1)(d_2-a_2)-(b_2-a_2)(d_1-a_1)$$ $$= (8 - 4)(8-2)-(4-2)(13-4)=-24-(-18)=6$$\n\n\nThere are plenty of ways, such as the Shoelace Theorem and Pick's Theorem.\n\nIf you have a graph, you can also simply draw a rectangle around the shape and subtract the parts you don't want.\n\n\nI think this is a special case of shoelace theorem. A quad is made up of two triangle and area of a triangle is\n\n$${1\\over 2}{|x_1(y_2 - y_3) + x_2(y_3 - y_1) + x_3(y_1 - y_2)|}$$\n\nOr you can use distance formula\n\n$$distance = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$\n\nand then heron's formula\n\n$$A = {1\\over 2}\\sqrt{s(s-a)(s-b)(s-c))}$$ Where s is the semi-perimeter of the triangle and, a,b,c are the length of its sides.\n\n\nFor any quadrilateral the area is one-half the magnitude of the cross product of the two diagonal vectors.\n\n\nI am just providing you with the simplest shortcut to doing this\n\nPick the first three points A(4,2), B(8, 4) and C(9, 6)\n\nNegate point A to get (-4, -2) and add to the other two points B and C. Add x's and y's so you have a new point\n\n(4, 2) (5, 4) Now use determinant to find the area.\n\n16-10 = 6sq unit\n\nNeglect any negative sign that arises\n\n  \u2022 $\\begingroup$ I don't understand so much. What is 6sq unit? $\\endgroup$ \u2013\u00a0El borito Jan 25 at 4:47\n  \u2022 $\\begingroup$ square unit as in square meter or any unit of length measurement...mm, cm, m..etc $\\endgroup$ \u2013\u00a0Daniel Wasty Jan 25 at 4:49"}
{"text": "Retrieved from https://math.stackexchange.com/questions/631576/probability-of-x-heads-before-y-consecutive-tails-in-n-biased-coin-tosses\nText:\nI have another coin toss question:\n\nAssume I am tossing a biased coin n times with probability p of coming up heads. What is the probability that x heads come up, before y consecutive tails?\n\nA code example would be preferable.\n\n  \u2022 $\\begingroup$ Just to be clear about what you mean, is HTHTT a case where $x=2$ heads come up before $y=2$ consecutive tails? Or did you mean to say \"$x$ consecutive heads\"? $\\endgroup$ \u2013\u00a0Barry Cipra Jan 8 '14 at 17:42\n  \u2022 $\\begingroup$ @BarryCipra, Yes, the heads do not need to be consecutive. $\\endgroup$ \u2013\u00a0user27 Jan 8 '14 at 17:46\n\nConsider the following events:\n\n$A_{x,y}$: You observe $x$ heads before $y$ consecutive tails.\n\n$B_{x,y}$: You observe $y$ consecutive tails before $x$ heads.\n\nLet $X_{i}$ follow a Geometric(p). This means that $X_{i}$ denotes the number of tail counts until you observe the first head with a biased coin. Observe that, in particular, $P(A_{1,y}) = P(X_{1} < y)$.\n\nIn order to solve for the general case, consider $X_{1},\\ldots,X_{x}$ i.i.d. Geometric(p). I claim that:\n\n\\begin{align*} P(A_{x,y}) = P(X_{1} < y, \\ldots,X_{x} < y) = P(X_{1} < y)^{x} \\end{align*}\n\nIn order to understand the claim, you can think of $X_{i}$ as the number of observed tails it takes until you observe a head after having already observed $i-1$ heads in the past. Hence, we only need to find $P(X_{1} < y)$. This is well known and equals $1-(1-p)^{y}$.\n\nHence, in general $P(A_{x,y}) = (1-(1-p)^{y})^{x}$\n\n  \u2022 $\\begingroup$ Thank you! Though this does not answer my question exactly, since I was asking for a specific maximum number of tosses. On second thought, I don't actually need to know this, so I marked your answer as accepted. $\\endgroup$ \u2013\u00a0user27 Jan 9 '14 at 16:09\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/164/what-are-the-possible-sets-of-word-lengths-in-a-regular-language/175\nText:\nGiven a language $L$, define the length set of $L$ as the set of lengths of words in $L$: $$\\mathrm{LS}(L) = \\{|u| \\mid u \\in L \\}$$\n\nWhich sets of integers can be the length set of a regular language?\n\n\nFirst, an observation which is not crucial but convenient: the set $\\mathscr{S}$ of sets of integers that are $LS(L)$ for some regular language $L$ on a non-empty alphabet $\\mathscr{A}$ does not depend on the choice of alphabet. To see that, consider a finite automaton that recognizes $L$; the lengths of the words that are in $L$ are the lengths of the paths on the automaton seen as an unlabeled graph from the start state to any accept state. In particular, you can relabel every arrow to $a$ and get a regular language with the same length set over the alphabet $\\{a\\}$. Conversely, if $L$ is a regular language over a one-element alphabet, it can be trivially injected into a larger alphabet, and the result is still a regular language.\n\nTherefore we are looking for the possible length sets for words over a singleton alphabet. On a singleton alphabet, the language is the length set written out in unary: $\\mathrm{LS}(L) = \\{n\\in\\mathbb{N} \\mid a^n \\in L\\}$. Such languages are called unary languages.\n\nLet $L$ be a regular language, and consider a deterministic finite automaton (DFA) that recognizes $L$. The set of lengths of words of $L$ is the set of lengths of paths in the DFA seen as a directed graph that start on the start state and end in one of the accept states. A DFA on a one-element alphabet is pretty tame (NFAs would be wilder): it's either a finite list or a circular list. If the list is finite, number the states from $0$ to $h$ following the list order; if it's circular, number the states from $0$ to $h$ following the head of the list, and $h$ to $h+r$ along the loop.\n\nlist-shaped automata\n\nLet $F$ be the set of indices of accept states up to $h$, and $G$ be the set of indices of accept states from $h$ to $h+r$. Then\n\n$$\\mathrm{LS}(L) = F \\cup \\{ k \\, r + x \\mid x \\in G, k\\in\\mathbb{N} \\}$$\n\nConversely, let $h$ and $r$ be two integers and $F$ and $G$ be two finite sets of integers such that $\\forall x \\in F, x \\le h$ and $\\forall x \\in G, h \\le x \\le h+r$. Then the set $L_{F,G,r} = \\{ a^{k\\,r+x} \\mid x\\in G, k\\in\\mathbb{N} \\}$ is a regular language: it is the language recognized by the DFA described above. A regular expression that describes this language is $a^F \\mid a^{G} (a^r)^*$.\n\nTo summarize in English, the length sets of regular languages are the sets of integers that are periodic\u00b9 above a certain value.\n\n\u00b9 To hang on to a well-established notion, periodic means the characteristic function of the set (which is a function $\\mathbb{N}\\to\\{\\mathtt{false},\\mathtt{true}\\}$ which we lift to a function $\\mathbb{Z}\\to\\{\\mathtt{false},\\mathtt{true}\\}$) is periodic. Periodic above a certain value means that the function restricted to $[h,+\\infty[$ can be prolonged into a periodic function.\n\n  \u2022 $\\begingroup$ Your observation about the irrelevance of the alphabet suggests that Parikh's theorem can be applied. Specifically, you show that LS(L) = LS(L') where in L' all letters are collapsed to a single alphabet. But LS(L') is the Parikh mapping of the language L, which is known to be semilinear for any regular language. $\\endgroup$ \u2013\u00a0Suresh Mar 10 '12 at 6:46\n  \u2022 $\\begingroup$ Nice approach! 1) I think the first paragraph can be replaced with noting that regular languages are closed against string homomorphisms. 2) For clarity, you should consider giving the second part of $\\mathrm{LS(L)}$ as $\\{h + kr + (x - h) \\mid \\dots \\}$, modulo off-by-one-errors. 3) What is a \"periodic\" set of integers? $\\endgroup$ \u2013\u00a0Raphael Mar 10 '12 at 10:31\n  \u2022 1\n    $\\begingroup$ @Suresh, Raphael (1): I prefer to state the proof in an elementary way, neither homomorphisms nor Parikh mappings were mentioned in my CS 102 class. $\\endgroup$ \u2013\u00a0Gilles Mar 10 '12 at 14:15\n  \u2022 $\\begingroup$ @Raphael (2) Where you start in indexing $G$ doesn't matter, I could remove the condition $h \\le G$, as $F$ can absorb as many small elements as we want. (3) A set that is periodic above a certain value is one that can be put in the displayed form above. $\\endgroup$ \u2013\u00a0Gilles Mar 10 '12 at 14:18\n\nAny finite subset $\\{\\ell_1,\\ldots,\\ell_n\\}\\subset\\mathbb{N}$ can be the lenght-set of a regular language $L$, since you can take a unary alphabet $\\{0\\}$ and define $L$ as $\\{0^{\\ell_1},\\ldots,0^{\\ell_n}\\}$ (this includes the empty language and $\\{\\varepsilon\\}$).\n\nNow for the infinite sets. I'll give a short analysis, though the final answer might not be explicit enough. I won't elaborate unless you ask me to, because I think it's intuitive and because I don't have much time now.\n\nLet $r_1,r_2$ be regular expressions generating languages $L_1$ and $L_2$, respectively. It is (sort of) easy to see that\n\n  \u2022 $\\mathsf{LS}(L(r_1+r_2))=\\mathsf{LS}(L_1\\cup L_2)=\\mathsf{LS}(L_1)\\cup\\mathsf{LS}(L_2)$.\n  \u2022 $\\mathsf{LS}(L(r_1r_2))=\\mathsf{LS}(L_1L_2)=\\{\\ell_1+\\ell_2:\\ell_1\\in\\mathsf{LS}(L_1),\\ell_2\\in\\mathsf{LS}(L_2)\\}$. This is denoted $\\mathsf{LS}(L_1)+\\mathsf{LS}(L_2)$.\n  \u2022 $$\\mathsf{LS}(L(r_1^*))=\\{0\\}\\cup\\bigcup_{n\\geq 1}\\Big\\{\\sum_{i=1}^n\\ell_i:(\\ell_1,\\ldots,\\ell_n)\\in\\big(\\mathsf{LS}(L_1)\\big)^n\\Big\\}.$$\n\nThus, the possible sets of integers that can be the length-set of a regular language are the ones that are finite subsets of $\\mathbb{N}$ or that can be built by taking finite subsets $S_1,S_2$ of $\\mathbb{N}$ and using the previous formulas a finite number of times.\n\nHere, we are using that regular languages are built, by definition, by applying the rules for constructing a regular expression a finite number of times. Note that we can start with any finite subset of $\\mathbb{N}$, even though in regular expressions we start with words of length 0 and 1 only as the base case. This is easily justified by the fact that all (finite) words are (finite) concatenations of the symbols of the alphabet.\n\n  \u2022 $\\begingroup$ I don't see any final answer. (Were you intending to finish your answer later?) I was hoping for a simple description of the possible sets, and a connection with automata. $\\endgroup$ \u2013\u00a0Gilles Mar 9 '12 at 17:47\n  \u2022 $\\begingroup$ The final answer is there: \"Thus, the possible sets of integers...\". That is indeed a simple description, though connected with regular expressions, not automata. $\\endgroup$ \u2013\u00a0Janoma Mar 9 '12 at 18:01\n  \u2022 $\\begingroup$ There's a simpler description that doesn't involve taking a fixpoint. Maybe this question isn't as elementary as I thought! $\\endgroup$ \u2013\u00a0Gilles Mar 9 '12 at 18:06\n  \u2022 $\\begingroup$ I don't think you can avoid the last rule, since it is the star operator the one which can produce infinite length-sets, just as it produces infinite languages. $\\endgroup$ \u2013\u00a0Janoma Mar 9 '12 at 18:17\n  \u2022 $\\begingroup$ @Gilles So you want a closed form of the smallest fixpoint of the inductive solution Janoma provides? $\\endgroup$ \u2013\u00a0Raphael Mar 10 '12 at 10:25\n\nAccording to the pumping lemma for regular languages, there exists an $n$ such that a string $x$ of length at least equal to $n$ can be written in the following form: $$x = uvw$$ Where the following three conditions hold: $$|uv| < n$$ $$|v| > 0$$ $$uv^{k}w \\in L$$\n\nThis gives us one test for sets: a set cannot be the length set of a regular language unless all its elements can be expressed as some arbitrary set of integers no greater than a fixed $n$, plus some multiple of an undetermined value $m$ (the length of $v$), plus some arbitrary finite value.\n\nIn other words, it looks like the possible sets of language lengths for regular languages is the closure with respect to set union (as discussed under EDIT and EDIT2, thanks to commenters) of sets described as follows: $$\\{a + bn | n \\in \\mathbb{N}\\} \\cup S$$ For fixed $a, b \\in \\mathbb{N}$ and all finite sets $S$, by the pumping lemma for regular languages (thanks to Gilles for pointing out a silly mistake in my original version, whereby I was defining the set $\\mathbb{N}$).\n\nEDIT: A little more discussion. Certainly all finite sets of integers are length sets. Also, the union of two length sets must also be a length set, as must be the complement of any length set (hence intersection, hence difference). The reason for this is that the regular languages are closed under these operations. Therefore, the answer I give above is (possibly) incomplete; in reality, any union of such sets is also the length set of some regular language (note that I have abandoned requiring intersection, complement, difference, etc., since these are covered by the fact that regular languages are closed under these properties, as discussed in EDIT3; I think that only union is actually necessary, even if the others are right, which might not be the case).\n\nEDIT2: Even more discussion. The answer I give is basically where you'd end up if you took Janoma's answer a little further; the $bn$ part comes from the Kleene star, the $a$ comes from concatenation, and the discussion of union, intersection, difference and complement come from the + of regular expressions (as well as other closure properties of regular languages) provable starting from automata).\n\nEDIT3: In light of Janoma's comment, let's forget closure properties of language length sets that I discuss in the first EDIT. Since the regular languages have these closure properties, and since every regular language has a DFA, it follows that the pumping lemma for regular languages applies to all unions, intersections, complements, and differences of regular languages, and we'll leave it at that; no need to even consider any of these, except union, which I still think might be necessary to make my original (modified, thanks to input from Gilles) correct. So, my final answer is this: what I say in the original version, plus the closure of language length sets with respect to set union.\n\n  \u2022 1\n    $\\begingroup$ $\\{a+bn \\mid a,b,n\\in\\mathbb{N}\\} \\cup S$ is on the right track, but you got a quantifier wrong somewhere, you're generating $\\mathbb{N}$. $\\endgroup$ \u2013\u00a0Gilles Mar 9 '12 at 18:08\n  \u2022 1\n    $\\begingroup$ The analysis for the complement of a length set may be a bit delicate. If $L=L(a^*)$ over the alphabet $\\Sigma=\\{a,b\\}$, then the length set of $L$ is $\\mathbb{N}$ and the length set of $\\overline{L}$ is $\\mathbb{N}^+$, and these are not complement of each other. $\\endgroup$ \u2013\u00a0Janoma Mar 9 '12 at 18:10\n  \u2022 $\\begingroup$ @Gilles But the set of all natural numbers is a valid length set, right? I'm not generating all subsets of natural numbers, right? I agree that would be problematic. Edit: oh wait, I see what you're saying. Yes, you're right. Will fix when back at computer. $\\endgroup$ \u2013\u00a0Patrick87 Mar 9 '12 at 18:19\n  \u2022 $\\begingroup$ @Janoma Excellent point, will need to consider how that might change the set of things I'm defining... $\\endgroup$ \u2013\u00a0Patrick87 Mar 9 '12 at 18:21\n\nYour Answer"}
