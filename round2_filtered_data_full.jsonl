{"text": "Retrieved from http://mathforum.org/library/drmath/view/53260.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSubtracting Different Types of Units\n\nDate: 05/26/2001 at 16:41:16\nFrom: Bruce Herman\nSubject: Subtracting units of different types\n\nI have a question about the following proposed solution for this \n\nTommy bought 20 pieces of candy for 20 cents. A piece of fudge costs 4 \ncents, gumdrops are 4 for a penny, and chocolate drops are 2 for a \npenny. If he bought all these varieties, how many of each did he buy? \nHere is the solution one of my students came up with:\n\n1)  4f + g/4 + c/2 = 20     multiply everything by 4\n\n2) 16f + g   + 2c  = 80\n3)   f + g   +  c  =  2     subtract line 3 from line 2\n4) 15f       +  c  = 60\n\n5) Since 15f is a multiple of 15, 15f can only be 15, 30, or 45, from \n   f = 1, 2, or 3 respectively.\n\n6) If f = 1, then there are 45 chocolate drops; that's too many\n7) If f = 2, then there are 30 chocolate drops; that's too many\n8) If f = 3, then there are 15 chocolate drops; that's good\n\n9) So we have 3 fudge and 15 chocolate drops, so we have 2 gumdrops, \n   which works out to 3 fudge = 12 cents; 15 chocolate drops = \n   7.5 cents; and 2 gumdrops = .5 cents; that does work.\n\nThe question the class has, which I can't explain, is that when we \nsubtract line 3 from line 2, it looks as if we are subtracting the \nnumber of items from the cost of the items. How can we subtract when \nwe are looking at different units?\n\nDate: 05/26/2001 at 23:31:08\nFrom: Doctor Peterson\nSubject: Re: Subtracting units of different types\n\nHi, Bruce (and class!)\n\nInteresting question. I have two ways to look at it.\n\nFirst, in my mind when I write an equation it is abstract, and doesn't \ninvolve units. I hide the units in the definitions of the variables \n(for example, by saying \"x is the length in meters,\" so that x itself \nis merely a number); in this case, \"f is the number of pieces of \nfudge,\" and f is just a number, which becomes a number of pieces of \nfudge only when I apply my solution back to the actual problem. When \nyou write the equation for cost, you are initially thinking of units,\n\n     4 cents/piece * f pieces + 1/4 cent/piece * g pieces\n     + 1/2 cent per piece * c pieces = 20 cents\n\nbut then you drop the units (dividing the whole equation by \"cents\") \nto get merely:\n\n     4f + g/4 + c/2 = 20\n\nNow when you do the algebra, you can ignore units; the algebra doesn't \n\nSecond, I have to admit there are times when I do like to think of an \nequation as having units, so that I can check, for instance, that \nevery term represents an area, and I am not trying to add areas and \nlengths, which would indicate I made an error. If I want to do that \nhere, I will have to say that equation (2) is in cents, while \nequation (3) is in pieces, and in order to subtract the latter I have \nto multiply it by the unit fraction \"cents/piece\" (just as I might \nhave had to multiply it by 2 before subtracting) so that the units as \nwell as the numbers match and I can really subtract like terms. I \nwouldn't bother with that sort of thinking here, but it might be worth \n\nMaybe there's a third way to think this out. Often equations like \nthese can be solved concretely, as I have to do in solving this sort \nof problem with a student who hasn't had any algebra. That is, rather \nthan work with variables, I would manipulate the actual objects, \nexchanging them, moving them to the other side of a scale, and so on. \nWe would say in this case, first suppose Tommy bought four times as \nmuch of everything; then he would have spent 80 cents. (This gives \nequation 2.) Now suppose I pay him a penny for each item, regardless \nof its type (subtracting equation 3 from equation 2)... I'm not sure \nhow I would finish this, but you might like to try it and see what \nconcrete explanation you could give for that step. That would explain \nwhere the units go, and I suspect you will find it matches one of my \nanswers above.\n\n- Doctor Peterson, The Math Forum\n\nDate: 05/27/2001 at 11:16:36\nFrom: (Anonymous)\nSubject: Re: Subtracting units of different types\n\nHow would that last work?  \n\n        16f + g + 2c = 80\n     -     f + g + c = 20\n\nIf each variable in the latter equation, as you suggest, is a penny, \nthen how can you take away 20? Shouldn't you be taking away 3?\n\nDate: 05/28/2001 at 22:56:53\nFrom: Doctor Peterson\nSubject: Re: Subtracting units of different types\n\nHi, Bruce.\n\nActually, this part doesn't make any sense to me either; it was late, \nI just had this idea that _some_ concrete solution might help explain \nwhat's going on, but I couldn't come up with a good solution along \nthose lines, so I just left you with a suggestion of the kind of thing \nI had in mind, hoping you might be able to finish it, or that I would \ndream up such a solution. Let's think it through now.\n\nThe closest thing I can think of would be a concrete solution to \nsomething simpler, like:\n\n    I bought 8 items, some for 5 cents and some for 2 cents, and\n    they cost a total of 25 cents. What did I buy?\n\nAlgebraically, this becomes\n\n      x + y = 8    (items)\n    5x + 2y = 25   (cents)\n\nand we subtract twice the first from the second to get\n\n    3x = 9\n     x = 3\n\n     y = 8 - x = 5\n\nTo solve this without algebra, I would probably use an exchange \nmethod, like this:\n\n    If all 8 items cost 2 cents, the total would be only 16 cents. I\n    have to add 9 cents to that. If I replace one 2-cent item with a\n    5-cent item, I have the same number of items but add 3 cents to\n    the cost. In order to add 9 cents, I have to do this 3 times; so\n    I will have 3 5-cent items and 5 2-cent items.\n\nAlgebraically, this is equivalent to substitution:\n\n              y = 8 - x\n  5x + 2(8 - x) = 25\n        16 + 3x = 25\n             3x = 9\n              x = 3\n\nThe step that is equivalent to your addition of \"counts and costs\" is \nthe substitution; but doing it this way, there's no unit conflict; I'm \nsimply multiplying 2 cents/item by 8-x items. I think this suggests \nthat what we're really doing when we subtract equations is multiplying \nthe first equation not just by 2, but by 2 cents/item. That agrees \nwith my second suggestion last time; but I don't think it really makes \nanything any clearer.\n\nThe fact is, combining two equations is an inherently abstract \noperation, and we're not really dealing with units at all, just \nnumbers. The substitution method is more basic and intuitive, and fits \nbetter with the use of units.\n\nI'll be interested to hear whether any of these ideas help your \nstudents at all!\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nHigh School Basic Algebra\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/352352/integral-extension-implies-that-the-induced-map-on-prime-spectra-is-closed\nText:\nSign up \u00d7\n\nSay we have an integral extension $f:R \\hookrightarrow S$ of rings. I want to show that the induced map $f^*:Spec(S) \\twoheadrightarrow Spec(R)$ is closed. In other words, let $V(I) = \\{\\mathfrak{P} \\in Spec(S) | \\mathfrak{P} \\supset I\\}$, for some ideal $I \\in S$, be a closed subset in $Spec(S)$. I want to find an ideal $J \\in R$ such that $f^*(V(I)) = V(J)$.\n\nI thought about using $J = I^{c} = I \\cap R$ (contraction), but one direction is unclear to me. To be more precise, let $\\mathfrak{p}$ be a prime ideal of $R$ containing $I^c$. By the lying over property of the extension, we know that there exists a $\\mathfrak{P} \\in Spec(S)$ such that $\\mathfrak{p} = \\mathfrak{P}^c$. But is it even true then that $I$ is contained in $\\mathfrak{P}$?\n\nThanks for your time.\n\nshare|cite|improve this question\nYes, your candidate for $J$ is the right one. \u2013\u00a0 Georges Elencwajg Apr 5 '13 at 17:48\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nApply lying over to $R/I^c \\hookrightarrow S/I$.\n\nshare|cite|improve this answer\nAh, yes! Because passing to quotients preserves integrity (integrality?), and prime ideals $\\mathfrak{p}$ containing $I^c$ correspond to prime ideals $\\mathfrak{p}/I^c$in the quotient... Thus there exists a prime ideal $\\mathfrak{P}/I$ such that $(\\mathfrak{P}/I)^c = p/I^c$, and from there we can easily conclude that $\\mathfrak{P}^c = \\mathfrak{p}$. \u2013\u00a0 A.P. Apr 5 '13 at 20:34\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/441764/when-does-a-solution-to-linear-equations-satisfy-x-1-sum-i-2nx-i\nText:\nSign up \u00d7\n\nLet $A\\overline{X}=0$, where $A=(a_{i,j})\\in M_{L, n}(\\mathbb{C})$ is a given non-zero $L\\times n$ matrix over the complex numbers $\\mathbb{C}$, and $\\overline{X}=(x_1, x_2, \\cdots, x_n)^T $ is an $n$-column vector.\n\nSuppose $L< n$, then we know that the above equations have non-zero solutions. My question is:\n\nWhat are the sufficient (and necessary) conditions on $A$ such that we can find one solution $\\overline{X}$ satisfying:\n\n$$(P)\\ \\ \\ \\ \\ \\ \\ \\ |x_1|>\\sum_{i=2}^n|x_i|$$\n\nHere are some observations and remarks:\n\n  1. We may assume $L>1$, since for $L=1$, $|a_{1,1}|<|a_{1,i}|$ for some $i>1$ is a sufficient condition.\n\n  2. For $a_{i,1}\\neq 0$, since $x_1=-\\sum_{j=2}^n\\frac{a_{i,j}x_j}{a_{i,1}}$, we know that a necessary condition for the property $(P)$ to be hold is that $\\exists j>1$, s.t., $|a_{i,j}|>|a_{i,1}|$.\n\n  3. My primary motivation to ask this question is that I want to consider equations in the general group algebras $\\mathbb{Z}G$ for some countable discrete group $G$; see this problem: Find a special element in group algebra\n\nshare|cite|improve this question\n\n1 Answer 1\n\nThis is not really a full answer.\n\nSplit the matrix into the first column and the rest, so that $A=(A_1,A_2)$. We can set $x_1=-1$ by scaling, so that the problem is to find a solution to $$ A_2 x = A_1, \\quad \\|x\\|_1<1. $$ A necessary condition is clearly that $$ \\|A_1\\|_1 = \\|A_2x\\|_1 < \\|A_2\\|_1. $$\n\nThe problem of finding a solution to $A_2x=A_1$ that minimizes $\\|x\\|_1$ instead of bounding it above is $\\ell_1$-regularized least squares, but I don't know a good bound.\n\nIf we minimize $\\|x\\|_2$ instead, then this is an underdetermined least squares problem, so in the case that $A_2$ has full rank, the solution with the smallest 2-norm gives the sufficient condition that $$ \\|A_2^t(A_2A_2^t)^{-1}A_1\\|_1 < 1. $$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/64035/can-a-nonzero-polynomial-evaluate-to-the-zero-function-in-a-suitable-infinite-ri?answertab=votes\nText:\nSign up \u00d7\n\nI shall assume all rings to be commutative in this question. The impatient can scroll down to the \"blockquote\" to read the actual question.\n\nWhenever we have a polynomial over a ring, it defines a function from the ring to itself by evaluation. It's reasonable to ask when two different polynomials define the same function.\n\nFrom the factor theorem it follows that an $n^\\text{th}$ degree polynomial over an integral domain has at most $n$ roots. Then it's easy to show this:\n\nTheorem. Let $R$ be an infinite integral domain and let $f \\in R[X]$ such that $f(a)=0$ for all $a \\in R$, then $f = 0$.\nProof. $f$ has infinitely many roots, so it must be the zero polynomial. $\\quad\\square$\n\nFor finite rings a kind of opposite situation occurs:\n\nTheorem. For any finite ring $R$ there are polynomials over $R$ that are different but agree on all elements.\nProof. There are only finitely many functions from $R$ to itself, but $R[X]$ is infinite. $\\quad\\square$\n\nIf we make further assumptions it's of course possible to prove more, as Pete L. Clark wrote in this post: [1]\n\nThen there is the question of infinite rings that are not integral domains. It's relatively easy to come up with examples of a ring $R$ with positive characteristic and a nonzero polynomial that evaluates to the zero function, e.g.: $$ R := \\bigoplus_{n=1}^\\infty \\mathbb{Z}/6\\mathbb{Z} \\quad\\text{and}\\quad f(X) := X^3-X.$$\n\nThe Question:\n\nThis leaves open the case alluded to in this post's title: Is there a commutative ring of characteristic $0$ (hence infinite) such that a nonzero polynomial evaluates to the zero function?\n\nshare|cite|improve this question\n+1 for the hint for the impatient. \u2013\u00a0 lhf Sep 13 '11 at 0:34\n\n2 Answers 2\n\nup vote 15 down vote accepted\n\nYes. I'll give my example first. Below is the TeXing I did while thinking that I was proving the answer to be \"no\". Trying to prove the answer was \"no\" led me to this example:\n\nLet $R=\\mathbb{Z}[y]/\\langle 6y,y^2\\rangle$. This commutative ring has characteristic zero, since no integer is in the ideal $\\langle 6y,y^2\\rangle$. And now you can just slide over your polynomial example so that it always evaluates to zero: $$f(X) = y\\;X^3-y\\;X=y\\;(X^3-X)$$\n\nJust as in your example, $X^3-X$ always evaluates to a multiple of $6$ when $X$ is an integer. More generally if $X=a+b\\;y$, then since $y^2$ is modded out, we only need consider the constant term $a$.\n\nIf you changed the question to be about integral domains rather than characteristic zero rings, then the answer would be \"no\" by completing the argument below.\n\nSuppose that $f$ is such a polynomial in $R[x]$ of degree $n$: $$f(x)=\\sum_{j=0}^n\\;c_j\\;x^j$$ The equations $$f(i)=0$$ for $i=0\\ldots n$ form a system of $n+1$ linear equations in the unknowns $\\{c_j\\}$. There is one clear solution to this system, where each $c_j=0$. But can there be other solutions with $c_j\\in R$?\n\nThe system can be written as $$\\begin{bmatrix}1 & 0 & 0 & \\cdots & 0\\\\ 1 & 1 & 1 &\\cdots & 1\\\\ 1 & 2 & 4 &\\cdots & 2^n\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\ 1 & n & n^2 & \\cdots & n^n\\end{bmatrix} \\begin{bmatrix}c_0\\\\c_1\\\\c_2\\\\\\vdots\\\\ c_n\\end{bmatrix} =\\begin{bmatrix}0\\\\0\\\\0\\\\\\vdots\\\\0\\end{bmatrix}$$\n\nThe matrix on the left (which I will call $V$) is an example of a Vandermonde matrix which is invertible in $M(\\mathbb{Q})$. Now, $V$ might not have an inverse in $M(R)$, but that's not a big problem. It's still the case that in $M(R)$ there is a matrix $W$ such that $W\\;V$ is a scalar matrix $D$ with an integer $d$ running down the diagonal. You just need to rescale $V^{-1}$ by the least common multiple of the divisors that appear in $V^{-1}$. After applying $W$ to both sides, $$D \\begin{bmatrix}c_0\\\\c_1\\\\c_2\\\\\\vdots\\\\ c_n\\end{bmatrix} =\\begin{bmatrix}0\\\\0\\\\0\\\\\\vdots\\\\0\\end{bmatrix}$$\n\nSo there is some nonzero integer $d$, such that for each $j$, we have that $d\\cdot c_j=0$.\n\nHere I realized the answer is actually \"yes\".\n\nshare|cite|improve this answer\nI just came back to this again, and I realised that we can take $R := \\mathbb{Z} \\times \\mathbb{Z}/6\\mathbb{Z}$ and $f(X) := (0,1)X^3 - (0,1)X$. It's not exactly isomorphic to your example ($(0,1)^2 \\neq (0,0)$) but yours helped a lot with finding it \u2013\u00a0 kahen Sep 15 '11 at 9:17\n\nConsider the ring generated by $a$ with $a^2 = 0$, and take $p(x) = a x$.\n\nshare|cite|improve this answer\nRobert: Come on: Kahen said a ring, not a rng. Let's stay serious here... \u2013\u00a0 Pete L. Clark Sep 13 '11 at 1:26\n@Pete: thnk t was a serous and constructve answer. \u2013\u00a0 zyx Sep 13 '11 at 2:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/200599/subspace-spanned-by-the-vectors\nText:\nSign up \u00d7\n\nI am having difficulty understanding this question:\n\nGraph the subspace spanned by the vectors $i = (3,-2,-1)^T$, $j = (-2,0,-1)^T$.\n\nYou don't have to graph it, but the answer for this problem is $z = (-3/5)x - (6/5)y$. I don't understand how to come up with that answer. I tried setting $i=-j$ but to no avail. Also, sorry for writing $i,j$ with $^T$, I do not know how to format it to make it look like a column vector.\n\nshare|cite|improve this question\nAre you sure that's the right answer? The points $(3,-2,-1)$ and $(-2,0,-1)$ don't seem to be on that plane. \u2013\u00a0 yunone Sep 22 '12 at 7:27\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nI think something is not quite right here.\n\nSince we are in $\\mathbb{R}^3$ we can find the normal to the plane spanned by $i, j$ by $i \\times j = (2,5,-4)^T$, hence the equation of the plane is $\\langle (x,y,z)^T, i \\times j \\rangle = 2x+5y-4z =0$, which gives $z = \\frac{1}{2} x + \\frac{5}{4} y$.\n\nHere is another approach that does not use the cross product:\n\nSuppose $(x,y,z) = a i + b j = (3a-2b, -2a, -(a+b))$. Then, from $y$ we have $a = -\\frac{y}{2}$, and from $x$ we have $b = -\\frac{3}{4} y -\\frac{1}{2} x$. Then $z = -(a+b) = \\frac{1}{2} x + \\frac{5}{4} y$.\n\nshare|cite|improve this answer\nHow did you get z=1/2x + 5/4y and (2,5,-4)^T ? We haven't been taught the cross product yet. \u2013\u00a0 diimension Sep 22 '12 at 21:53\nI added another approach. \u2013\u00a0 copper.hat Sep 22 '12 at 22:00\nI understand now because of your help, thank you very much copper!! \u2013\u00a0 diimension Sep 22 '12 at 23:15\nYou are very welcome, glad to be of help. \u2013\u00a0 copper.hat Sep 23 '12 at 0:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162332/g-12-and-no-elements-of-order-2-in-zg\nText:\nTake the 2-minute tour \u00d7\n\nI am thinking on the following problem:\n\nIf $|G|=12$ and there is no element of order $2$ in its center then $3$-Sylow subgroup of $G$ cannot be normal in $G$.\n\nI was told that to assume the $3$-Sylow subgroup of $G$, say $P$, is normal in the group and go to reach a contradiction.\n\nMy attept: $|P|=3$ so it is cyclic, $P=\\langle x\\rangle=\\{1,x,x^2\\}$. As above hint, I would have for all $g\\in G$ two possibilities: $gxg^{-1}=x$ or $gxg^{-1}=x^2$. Cannot to go any further. I am in doubt if the hint leads me to a contradiction properly and if so, it does with a long proof. Any help or any other way are welcome to me. Thanks for your time.\n\nshare|improve this question\nThis is a followup to math.stackexchange.com/questions/158339/\u2026 \u2013\u00a0 Jack Schmidt Jun 24 '12 at 19:10\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nHint #1: Show that all Sylow 2-subgroups are abelian. So if an element of a Sylow 2-subgroup commutes with the elements of $P$, then it belongs to the center.\n\nHint #2: At this point the questions you should ask from yourself are: 1) What possibilities (up to isomorphism) are there for the Sylow 2-subgroup H? 2) Given that $P$ was assumed to be normal, what possibilities are there for the conjugation action for the non-trivial elements of $H$. Remember that conjugation action is a homomorphism from $H$ to $Aut(P)$.\n\nshare|improve this answer\n:About you first hint: That the Sylow 2-subgroups is abelian is obvious cause they are of order 4. So I should show that an element of one of these subgroups COMMUTE with $x$. Thanks. As you said me later, you put a loop in my mind finding the result. :-) \u2013\u00a0 Babak S. Jun 24 '12 at 10:14\nCorrect (re: the 1st hint). Be a bit careful in that the element of $H$ that commutes with $P$ should be of order two. It doesn't really matter much in this case, but for full credit... :-) \u2013\u00a0 Jyrki Lahtonen Jun 24 '12 at 10:29\nI am on the way you paved. Yes, with that element say $y$, I can see that $G$ is being generated by $x$ and $y$. Thanks. Thanks. \u2013\u00a0 Babak S. Jun 24 '12 at 10:38\n\nTo follow your attempt:\n\nFor every $g \\in G$, we have $gxg^{-1} = x$ or $gxg^{-1} = x^2$. Thus $x$ has $1$ or $2$ conjugates, in other words, $[G : C_G(x)] = 1$ or $[G : C_G(x)] = 2$. In both cases, $2$ divides the order of $C_G(x)$, and thus $C_G(x)$ contains an element $y$ of order $2$. This gives us the desired contradiction. Can you see why $y$ must belong to the center of $G$?\n\nshare|improve this answer\nThanks for your answer. It solves my problem in detail. :) \u2013\u00a0 Babak S. Jun 25 '12 at 5:39\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/114814/does-n2nk2n2k2-ldots-nmk2-have-a-general-equation\nText:\nTake the 2-minute tour \u00d7\n\nDoes $n^2+(n+k)^2+(n+2k)^2+\\ldots+(n+mk)^2$ have a general formula?\n\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 9 down vote accepted\n\nThe sum can we written as $\\sum_{j=0}^m(n+jk)^2=\\sum_{j=0}^mn^2+2jkn+j^2k^2$ and using the formulas $\\sum_{j=0}^mj=\\frac{m(m+1)}2$, $\\sum_{j=0}^mj^2=\\frac{m(m+1)(2m+1)}6$, we get \\begin{align*}\\sum_{j=0}^m(n+jk)^2&=(m+1)n^2+knm(m+1)+k^2\\frac{m(m+1)(2m+1)}6\\\\ &=(m+1)\\left(n^2+knm+\\frac{k^2m(2m+1)}6\\right). \\end{align*}\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164179/induced-sigma-algebra-vs-product-sigma-algebra\nText:\nTake the 2-minute tour \u00d7\n\nLet $(E,\\mathscr E)$ be a measurable space and $(S,2^S)$ be a finite set. Let $$ \\xi:(E,\\mathscr E)\\to(S,2^S) $$ be a mesaurable function, i.e. $\\xi^{-1}(s)\\in \\mathscr E$ for any $s\\in S$. Now, let us denote by $\\Omega = E^{\\mathbb N_0}$ and by $\\mathscr F$ its product $\\sigma$-algebra. Also, let $\\Sigma = S^{\\mathbb N_0}$ and let $\\mathscr S$ be the correspondent product $\\sigma$-algebra.\n\nLet $\\eta:\\Omega\\to\\Sigma$ be the element-wise extension of $\\xi$, i.e. $$ \\eta(\\omega_0,\\omega_1,\\dots) = (\\xi(\\omega_0),\\xi(\\omega_1),\\dots). $$\n\nI wonder if $\\mathscr S$ is different from $$ \\mathscr C = \\{A\\subseteq \\Sigma:\\eta^{-1}(A)\\in \\mathscr F\\}. $$ It is clear that $\\mathscr S\\subseteq \\mathscr C$ - but can the strict inclusion actually happen?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYes, strict inclusion can happen. If $S$ has more than one element, $(\\Sigma,\\mathscr{S})$ will be an uncountable compact metric space with the Borel $\\sigma$-algebra. By standard arguments, there will be $\\mathfrak{c}$ many measurable sets, there are as many measurable sets as real numbers. Also, $|\\Sigma|=\\mathfrak{c}$.\n\nNow let $S=\\{0,1,2\\}$ and let $\\xi$ be the constant function that maps everything to $2$. There are $2^\\mathfrak{c}$ subsets of $\\{0,1\\}^\\mathbb{N}$. Take any subset $A$ of $\\{0,1\\}^\\mathbb{N}$ and let $A'=A\\cup\\{(2,2,2,\\ldots)\\}$. There are $2^\\mathfrak{c}$ sets of this form and since $\\eta^{-1}(A')=\\Omega$ for all of them, they are all in $\\mathscr{C}$.\n\nSo for cardinality reasons, the inclusion will be strict. Note that $\\mathscr{C}$ is the largest $\\sigma$-algebra on $\\Sigma$ that is compatible with $\\eta$ being measurable. It shouldn't be surprising that it is quite large.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/686/combinations-of-selecting-n-objects-with-k-different-types/690\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that I am buying cakes for a party. There are k different types and I intend to buy a total of n cakes. How many different combinations of cakes could I possibly bring to the party?\n\nshare|improve this question\nSeeded question \u2013\u00a0 Casebash Jul 25 '10 at 10:54\nPS. This problem has a really nice proof. I'm pretty hopeful that someone else has seen it posts it \u2013\u00a0 Casebash Jul 25 '10 at 11:23\nWhenever I do this sort of thing, the shop runs out of the cakes I want. \u2013\u00a0 walkytalky Jul 25 '10 at 15:20\nvoting to close--because I'd do so if I saw it as a real question--no indication the asker has thought about the problem first. \u2013\u00a0 Jamie Banks Jul 25 '10 at 19:24\n@Katie: Its a perfectly valid question and I haven't seen a hasn't thought about it close reason on any of the other SO websites (maybe mathoverflow is different though). If you want someone to think about a problem, the best solution is to just not give them the whole solution. For example, show them how you go about proving it and leave out the actual formula \u2013\u00a0 Casebash Jul 25 '10 at 20:54\nshow 3 more comments\n\n3 Answers\n\nup vote 12 down vote accepted\n\nUsing a method that's often called \"stars and bars\":\n\nWe draw $n$ stars in a row to represent the cakes, and $k-1$ bars to divide them up. All of the stars to the left of the first bar are cakes of the first type; stars between the first two bars are of the second type; .\u00a0. .\u00a0.\n\n\nHere's an example with $n=6$ and $k=5$. We're getting 2 of the first type, 3 of the second type, 0 of the third type, 1 of the fourth type, and 0 of the fifth type.\n\nIn order to solve the problem, we just need to reorder the stars and bars by choosing the $k-1$ spots for the bars out of the $n+k-1$ total spots, so our answer is:\n\n$$ \\binom{n+k-1}{k-1}. $$\n\nshare|improve this answer\nExactly what I was looking for \u2013\u00a0 Casebash Jul 25 '10 at 20:51\nNote that $\\binom {n+k-1}{k-1} = \\binom {n+k-1}{n}$ - here the description picks the $k-1$ spots for the bars - equivalently we could pick the $n$ spots for the cakes. \u2013\u00a0 Mark Bennet May 28 '13 at 17:20\nHere is a derivation of your formula using the Polya Enumeration Theorem. \u2013\u00a0 Marko Riedel Oct 28 '13 at 0:42\nadd comment\n\nLet g(n,k) = # combinations of cakes.\n\nNotice that:\n\n  \u2022 g(n,1) = 1. (all the cakes are the same)\n  \u2022 g(n,2) = n+1. (e.g. for 5 cakes, the # of cakes of type 1 can be 0, 1, 2, 3, 4, 5)\n  \u2022 g(1,k) = k.\n  \u2022 g(2,k) = k*(k-1)/2 + k (the first term is two different cakes; the second term is when both cakes are the same), as long as k > 1. (otherwise g(2,1) = 1)\n  \u2022 g(3,k) = k * (k-1) * (k-2)/6 + k*(k-1)/2 * 2 + k (the first term is 3 different cakes; the second term is 2 different cakes, with a *2 since there are two choices for which one to duplicate, the third term is when all 3 cakes are the same), as long as k > 2.\n\nIf we think of k as a radix rather than the # of cakes, then this problem is equivalent to expressing the # of distinct n-digit numbers in base k whose digits are in sorted order. (e.g. 1122399 is equivalent to 9921231)\n\nI think I can express it as a nonrecursive sum:\n\ng(n,k) = sum from j=1 to max(n,k) of { (k choose j) * h(n,j) }\n\nwhere h(n,j) is the # of ways to partition N cakes using j different types. (the term in the sum is when there are j distinct cakes actually chosen.)\n\nBut that's about as far as I can get... :/\n\nedit: looks like it's combinations with repetitions = ((k+n-1) choose n). (same as the wikipedia article with n and k swapped)\n\nshare|improve this answer\nnice solution Jason S............... \u2013\u00a0 juantheron Dec 13 '13 at 3:34\nadd comment\n\nLet's assume you have $n$ items and $k$ bins. You need $k-1$ separators to get the $n$ items into the $k$ bins. There are $(n + k - 1)!$ permutations of ordering $n$ items and $(k-1)$ separators. The permutations of the $n$ items don't matter, and the permutations of the $(k-1)$ separators don't matter, so you'll need to divide by $n!$ and $(k-1)!$\n\nThus you have $$\\frac{(n + k - 1)!}{n!(k-1)!} = \\binom{n+k-1}{k-1}$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/116802/number-of-elements-in-a-ring-with-identity-s-t-x2-1-r-for-all-0-r-neq-x\nText:\nTake the 2-minute tour \u00d7\n\nI'm not sure how to go about finding the solution to this question.\n\nLet R be a ring with identity such that $x^2 = 1_R$ for all $0_R \\neq x\\in R$. How many elements are in $R$?\n\nI've just been playing around with squaring elements, like $$(x+1_R)^2 = x^2+2.x+1_R =2.x+2.1_R = 1_R.$$\n\nBut I'm not sure where to go with this. Any help?\n\nshare|improve this question\nEither $1_R+1_R=0$ or $(1_R+1_R)^2=1_R$ so $3\\cdot 1_R=0$. \u2013\u00a0 Davide Giraudo Mar 5 '12 at 20:15\nadd comment\n\n2 Answers\n\nOne possibility, of course, is $R=\\{0\\}$. Assume $1_R\\neq 0$.\n\n$R$ has no zero divisors: if $xy=0$ and $x\\neq 0$, then $y = 1_Ry = xxy = x(0)=0$.\n\n$R$ is commutative: if $x$ and $y$ are nonzero, then so is $xy$ by the above; hence $(xy)^2 = x^2y^2$; canceling from $xyxy=xxyy$ we get $yx=xy$.\n\n(Of course, the ring satisfies $x^3=x$ for all $x$, so by a famous theorem of Jacobson, the ring is necessarily commutative; but we don't need to call in that heavy cannon to the fray).\n\nSince every nonzero element is invertible, $R$ is a field. Since $x^2-1_R$ has $|R-\\{0\\}|$ solutions, we have $|R-\\{0\\}|\\leq 2$, so $|R|\\leq 3$.\n\nIf $1_R+1_R=0$, then $R$ is of characteristic $2$, so $R\\cong \\mathbb{F}_2$ and $|R|=2$. And, indeed, in this case the hypothesis holds.\n\nIf $1_R+1_R\\neq 0$, then we get $4\\cdot 1_R = 1_R$, hence $3\\cdot 1_R=0$, so $R$ is of characteristic $3$, and therefore $R\\cong\\mathbb{F}_3$ and $|R|=3$. Again, the hypothesis holds for this ring.\n\nIn summary, $R$ has either $1$, $2$, or $3$ elements, and is either the trivial ring, $\\mathbb{F}_2$, or $\\mathbb{F}_3$.\n\nshare|improve this answer\nThanks, this is very helpful, but why does $x^3=x$ imply that $R$ is commutative? \u2013\u00a0 098765 Mar 5 '12 at 20:28\n@098765: It is a common exercise in Ring Theory, and also a consequence of a famous Theorem of Jacobson, which states that a ring for which there exists $n\\gt 0$ such that $x^n=x$ for all $x$ is always commutative. But I gave a simpler derivation that does not call upon such heavy artillery in an edit. \u2013\u00a0 Arturo Magidin Mar 5 '12 at 20:33\n@ArturoMagidin am pleased you revised your answer, because the proof that $x^3 = x$ implies R is commutative isn't trivial, and is probably beyond the stage at which the asker of this question is at. \u2013\u00a0 David Wheeler Mar 5 '12 at 20:53\nDoes your proof actually depend on commutativity? (mine does not). If not, then you can omit the proof of comutativity, since it's a trivial consequence of the final result. \u2013\u00a0 Bill Dubuque Mar 5 '12 at 22:42\n@Bill: I use commutativity only to conclude that I have a field rather than a simply division ring; I believe it is equivalent to your \"$x^{-1}=x\\Rightarrow R$ field\". \u2013\u00a0 Arturo Magidin Mar 6 '12 at 3:54\nadd comment\n\n$\\rm R=0\\:$ works. Else $\\rm\\ x\\ne 0$ $\\Rightarrow$ $\\rm x^2 =1$ $\\Rightarrow$ $\\rm x^{-1} = x $ $\\Rightarrow$ $\\rm R$ field, so $\\rm\\: x\\ne 0\\!\\iff\\!\\! (x-1)(x+1) = 0$ $\\iff$ $\\rm x=\\pm 1.\\:$ But $\\rm\\: R\\backslash0 = \\{\\pm1\\}$ $\\!\\iff\\!$ $\\rm R\\:\\! \\cong\\:\\! \\mathbb Z/2\\:$ or $\\:\\mathbb Z/3$.\n\nMore generally, the finite fields $\\:\\rm\\mathbb F_p,\\: \\mathbb F_q,\\ p,q\\:$ prime, are axiomatized by the ring axioms plus $$\\rm x^n =\\: x,\\quad n\\: =\\: 1 + lcm(p\\!-\\!1,q\\!-\\!1)$$ $$\\rm q\\:(x^p-x)\\: =\\: 0\\: =\\: p\\:(x^q-x)$$ $$\\rm pq\\: =\\: 0$$\n\nThus any identity true in both of these fields has a purely equational proof from the above axioms. This theorem extends similarly to any finite set of finite fields, for example see Stanley Burris and John Lawrence, Term rewrite rules for finite fields (1991). This result is very closely related to Jacobson's model-theoretic proof of commutativity of rings satisfying the identity $\\rm\\: x^{n_x} =\\: x$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/314978/row-and-column-algorithm\nText:\nTake the 2-minute tour \u00d7\n\nLooking for help in revising my algorithm. I need to find one that will give me the row and column of a cell on a grid.\n\nThe grid is $t \\times t$. For example, this is a grid for $t=5$. Now given $n$, find the row and column. $$\\begin{array}{|c|c|c|c|c|} 1& 2& 3& 4& 5\\\\ 6& 7& 8& 9& 10\\\\ 11& 12& 13& 14& 15\\\\ 16& 17& 18& 19& 20\\\\ 21& 22& 23& 24& 25 \\end{array}$$\n\nMy attempt:\n\nrow: $n / t + 1$ column: $n \\bmod t$\n\nSecond attempt:\n\n$\\operatorname{row}(x, t) = ((x-x \\bmod t)/t)+1$\n\n$\\operatorname{column}(x,t) = (x-1) \\bmod t+1$\n\nDoesn't work for $n = t^2$\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe row is :$$r = \\lfloor \\frac{n-1}{t} \\rfloor + 1$$\n\nThe column is:$$c = n - t(r-1)$$\n\nshare|improve this answer\nIf zero indexing were to be used ($0,1,2,\\ldots$ instead of $1,2,\\ldots$) then the answer would look cleaner. $c$ could also be (n-1)%t+1. \u2013\u00a0 adam W Feb 26 '13 at 16:23\nI understand, thank you! \u2013\u00a0 \u041c\u0438\u043a\u0440\u043e\u041f\u0438\u043d\u0433\u0432\u0438\u043d Feb 26 '13 at 16:26\nGlad to hear it, your welcome! \u2013\u00a0 adam W Feb 26 '13 at 16:35\nHi, I have another question. This was just borne out of curiosity. Is there an equation for reflections over diagonals? My attempt only works for the first column down when reflected over the topleft-bottomright diagonal. n - (row - 1)(t - 1) \u2013\u00a0 \u041c\u0438\u043a\u0440\u043e\u041f\u0438\u043d\u0433\u0432\u0438\u043d Feb 26 '13 at 23:14\nThis is a common operation using matrices called the transpose, it is simply the swap of the indices $r\\leftrightarrow c$. If by reflection over diagonals you mean other than the main (top left down to the bottom right), then maybe do some sort of shifting... though that sounds inexact, since any sort of \"reflecting\" would give indices out of bounds... \u2013\u00a0 adam W Feb 26 '13 at 23:36\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/99421/computational-complexity-of-calculating-the-nth-root-of-a-real-number?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nSeveral sources state that the computational or time complexity of square rooting is the same as that of multiplication (or division). See for example:\n\n  \u2022 Jean-Michel Muller, \"Elementary Functions: Algorithms and Implementation\" (Birkh\u00e4user, Boston, USA, 2006, 2nd edn.) on p.93 where the Newton-Raphson method is considered. It is stated that \"...the complexity of square root evaluation or division is the same as that of multiplication...\"\n\n  \u2022 H. Alt, \"Square rooting is as difficult as multiplication\", Computing, 1979, 21, (3), pp.221-232. It is stated on p.231 \"...that we have shown that square rooting is of the same complexity as the other arithmetical operations mentioned. The proof can be extended to higher roots, as well.\"\n\nAlthough there are several different approaches to implement computation of the elementary operations (+,-,x,/) it is therefore possible to implement square rooting such that the complexity is equivalent to an implementation of multiplication (a single multiplication of 2 real numbers).\n\nWhat does \"the proof can be extended to higher roots\" mean? Is it possible to implement the calculation of the nth root with complexity equivalent to a single multiplication or to the multiplication of $n$ real numbers? If not, what is the complexity of calculating the nth root of a real number?\n\nshare|improve this question\nHow are your real numbers represented? Without specifying this, it's rather unclear... \u2013\u00a0 Dima Pasechnik Jun 13 '12 at 10:04\nSay single precision floating point real numbers \u2013\u00a0 aslan Jun 13 '12 at 10:09\nIn the paper of H. Alt, big O notation is used, which is only an asymptotic complexity bound, and it does not mean that the operations are equivalent. In the analysis of high-level algorithms (the book of Jean-Michel Muller), the complexity of multiplication and square root evaluation is assumed the same for simplicity. In real computation, a square root evaluation is about 5 times more expensive than a multiplication. \u2013\u00a0 Stanislav Jun 13 '12 at 10:17\nIf you are interested in the floating point instruction latencies in real processors, see \"Intel 64 and IA-32 Architectures Optimization Reference Manual\" (Appendix C) \u2013\u00a0 Stanislav Jun 13 '12 at 10:20\n\n2 Answers 2\n\nup vote 10 down vote accepted\n\nFirst, note that the asymptotic complexity of arithmetic operations stated in the common literature concerns operations on numbers with arbitrary precision, and the running time is expressed as a function of the desired number of digits. From the standpoint of asymptotic complexity it makes no sense to ask for operations with constant precision (e.g., single floats, as you mentioned in the comments): there are only $O(1)$ such numbers, hence the operation can be evaluated in time $O(1)$ (e.g., by a look-up table).\n\nLet me thus denote the desired precision as $m$ (since you use the customary $n$ for something else). The result you quote is that $\\sqrt a$ can be computed in time $O(M(m))$, where $M(m)$ is any function (satisfying some mild regularity conditions) such that multiplication of two $m$-bit integers can be performed in time $M(m)$. (The currently known asymptotically fastest multiplication algorithm has $M(m)=m\\log m\\,2^{O(\\log^*m)}$.) The algorithm uses Newton iteration $x\\mapsto x-\\frac{x^2-a}{2x}$. This iteration has a quadratic rate of convergence, hence $O(\\log m)$ iterations suffice, and each step takes $O(1)$ multiplications and divisions, leading to the estimate $O(M(m)\\log m)$ on the total running time. The extra factor of $\\log m$ can be removed by the following observation: since the number of correct digits is roughly doubled by each iteration, we do not have to perform all operations with precision $m$, it suffices to use precision sufficient to accomodate the correct digits. Thus only the last iteration is performed with precision $m$, the last but one has precision $m/2$, the one before that $m/4$, and so on. Then the running time is $O(M(m)+M(m/2)+M(m/4)+\\cdots)$. Since $M$ is essentially linear, this is can be bounded by a geometric series, whose sum is $O(M(m))$. (Note by the way that the fact that division can be done in time $O(M(m))$ also uses a similar Newton iteration argument.)\n\nNow, what about $n$th roots in general? You can use Newton iteration again, as Denis suggests. The analysis is similar to the square root case, but since each step takes $O(\\log n)$ multiplications, you get a bound $O(M(m)\\log n)$. Note that if $n$ is given in binary, $\\log n$ is the length of the input, hence this is an algorithm with worse than a quadratic running time. Another approach is to compute $\\sqrt[n]a$ as $\\exp((\\log a)/n)$. Using binary splitting, the Taylor series for $\\exp$ and $\\log$ can be evaluated in time $O(M(m)(\\log m)^2)$; using algorithms based on the arithmetic-geometric mean this can be reduced to $O(M(m)\\log m)$, leading to $n$th root computation with the same time bound. This also has an extra $\\log$ factor, but it is independent of $n$. I don\u2019t know how to compute $\\sqrt[n]a$ in time $O(M(m))$, and I am somewhat skeptical that such a thing is known. It might well be that the comment in Alt\u2019s paper is only intended to cover the case of constant $n$.\n\nshare|improve this answer\n+1.but the $m$ in $M(m)$ is very annoying,could we get it's upper bound by the polynomial or the function to solve? \u2013\u00a0 XL _at_China Jul 31 at 22:06\nI can't make heads or tails of your comment. Any bound has to involve $m$, as it is the length of the output, and the bound is already polynomial (almost linear) as given. \u2013\u00a0 Emil Je\u0159\u00e1bek Aug 1 at 9:41\nokay,let me try to get it \u2013\u00a0 XL _at_China Aug 1 at 11:34\n\nThe Newton-Raphson algorithm uses, for computation of $A^{1/p}$, the sequence $u_0=A$, $u_{n+1}=u_n-\\frac {u_n^p-A}{pu_n^{p-1}}$, whose speed of convergence , always quadratic, is essentially independent of $p$ (and $A$). So, mostly, it asks for $\\ln p$ multiplications and 1 division at each step.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/66866/maximum-angular-velocity-to-stop-in-one-rotation-with-a-known-torque\nText:\nTake the 2-minute tour \u00d7\n\nI have an object I can rotate with a given torque. I would like to stop applying torque once I've reached a defined maximum rotational speed. The maximum rotational speed should be defined so that applying maximum torque will stop the rotation of the object within one rotation. If I know my torque and moment of inertia, how can I find the maximum rotational velocity to allow me to stop the object in one rotation?\n\nTime is whatever is needed.\n\nI've tried finding the angular acceleration required to stop the object, but that leaves me with the time variable. Of the equations I've tried, I'm left with a time variable as well as the maximum angular velocity.\n\nshare|improve this question\nWhat approaches have you tried? Where are you hung up with this question? \u2013\u00a0 Jerry Schirmer Jun 2 '13 at 22:04\nI edited the question to give a little details about what I've tried. And it's not homework. More like hobby work. \u2013\u00a0 Byte56 Jun 2 '13 at 22:09\nFor people with similar homework questions: try the equivalent exercise in linear motion. E.g. the direct equivalent here is, given a stopping length L and a force F, what is the maximum velocity v ? You'll quickly spot that you need the second derivative a which you get from F=m*a. \u2013\u00a0 MSalters Jun 3 '13 at 0:00\n\n3 Answers 3\n\nup vote 2 down vote accepted\n\nTo stop the object you must do work. For a constant torque perpendicular to the moment arm, the work it does is equal to $\\tau\\cdot\\Delta\\theta$, and you want $\\Delta\\theta\\leq2\\pi$.\n\nIt should be obvious that the greatest angular velocity that a torque $\\tau$ can stop will take it the full $2\\pi$ radians to stop. In a rotating system, the rotational kinetic energy is given by $E_r=\\frac12I\\omega^2$ (a direct analogue of $E_K=\\frac12mv^2$ ). Now consider work-energy equivalence.\n\nshare|improve this answer\nGreat, I should have taken the energy approach. Been too long since physics. Thanks. \u2013\u00a0 Byte56 Jun 2 '13 at 22:29\nNo problem. J. Lowney has a full-detail solution above - you should check your algebra. A word of advice: on a problem like this, omit your direction signs and only consider magnitudes. Signs will only confuse you and freak you out when you end up with an imaginary angular velocity. \u2013\u00a0 Zen Jun 2 '13 at 22:31\n\nBuilding off of Zen's response, the energy will be $E_r = \\frac{1}{2}I\\omega^2$. The work done in one rotation is $\\tau\\Delta\\theta$. These two terms are equivalent in your case. I.e. you will have the following expression\n\n$$ E_r = \\frac{1}{2}I\\omega^2 = \\tau_\\text{max} \\Delta\\theta$$ $$ \\omega_\\text{max} = \\sqrt{\\frac{2\\tau_\\text{max}\\Delta\\theta}{I}}$$\n\nYou're treating your $\\Delta\\theta$ as $2\\pi$, for one full rotation, hence:\n\n$$\\omega_\\text{max} = \\sqrt{\\frac{4\\pi\\tau_\\text{max}}{I}}$$\n\nWhere $I$ is the moment of inertia of your object. $\\omega$ is the angular velocity. $\\tau$ is your torque.\n\nshare|improve this answer\nThanks for furthering the equation J. \u2013\u00a0 Byte56 Jun 2 '13 at 22:30\nHow would I go about expanding this to use multiple torque values at different positions around the object? \u2013\u00a0 Byte56 Jun 2 '13 at 22:43\nIf you have a function $\\tau(\\theta)$ that gives you torque at every position around the object then simply replace the naive expression for work $W=\\tau\\Delta\\theta$ by $$W=\\int_0^{2\\pi}\\tau(\\theta)d\\theta$$ \u2013\u00a0 Zen Jun 2 '13 at 22:56\n\nAlternative solution:\n\nI see you tried to do it by first finding angular acceleration $\\alpha=\\frac\\tau I$ (where tau is your applied torque). This also works! However I suspect you got stuck at $$\\alpha t=-\\omega_{max}$$ This is perfectly understandable because t is somewhere between 0 and a full period (under the original angular velocity $\\omega$ that is), but you don't know what t is.\n\nYou could try to set up some equations to solve simultaneously for $t$, but that's not necessary because you don't care about $t$, you only care about $\\omega_{max}$ There is another equation you can use, the so-called \"timeless equation\": $$\\omega_f^2=\\omega_o^2+2\\alpha\\Delta\\theta$$ where $\\omega_f$ is final angular velocity, $\\omega_o$ is initial angular velocity, $\\alpha$ is angular acceleration, and $\\Delta\\theta$ is angular displacement (this again is a direct analogue of the linear kinematic equation $v^2=v_0^2+2a\\Delta x$).\n\nLet $\\omega_f=0$ and $\\omega_0=\\omega_{max}$ (i.e., you start out at maximum velocity). By the same reasoning as above $\\Delta\\theta=2\\pi$ and if you know $\\tau$ and $I$ you can find $\\alpha$. Then you have: $$0=\\omega_{max}^2+2\\alpha\\cdot2\\pi$$ $$\\omega_{max}^2=2\\alpha\\cdot2\\pi$$ (again, ignore signs) $$\\omega_{max}=\\sqrt{4\\alpha\\pi}$$ which is the same as above, since $\\alpha=\\frac \\tau I$\n\nshare|improve this answer\nGreat, thanks Zen. \u2013\u00a0 Byte56 Jun 2 '13 at 23:39\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/11737/get-rid-of-tr-in-svm-kernel-trick/11740\nText:\nTake the 2-minute tour \u00d7\n\nI designed a kernel function (to be used within SVM) which has the expression $tr(AB)$ in it. For efficient implementation of this, I was wondering if I could write $tr(AB)$ as an inner product: $\\phi(A)^T \\phi(B)$? What is the function $\\phi()$?\n\nshare|improve this question\nI'm not sure I understand your question (it would help if you eliminated or explained your jargon), but the obvious optimization is that you don't explicitly need to compute AB: tr(AB) is the sum of A_{ij}*B_{ji} over all pairs i,j. You can do this with a single pass over your matrices. \u2013\u00a0 Darsh Ranjan Jan 14 '10 at 9:25\n@darsh you beat me by 3 minutes! I can explain some of the terminology. Imagine you have data in $\\mathbb{R}^d$ (here it seems to be in $\\mathbb{R}^{d\\times d}$??) but want to work with it in $\\mathbb{R}^D$, which you can accomplish by passing everything through a mapping $\\Phi$. If $D \\gg d$, this can be expensive. But in some cases your algorithm need only compute inner products $\\langle \\Phi(a), \\Phi(b)\\rangle$, in which case there may be a functin $k(\\cdot,\\cdot)$ which computes the same thing but with much less work than the explicit mapping. this is called the 'kernel trick'. \u2013\u00a0 Matus Telgarsky Jan 14 '10 at 9:34\nNote that you don't really need the explicit mapping $\\phi$. What you want is a kernel $k(A, B)$ which has the property that $k(A, B) = \\phi(A)^T \\phi(B)$. Generally, you compute the kernel directly, instead of calculating the mapping and computing the dot product -- that's why it's called kernel `trick'. In your case, it seems you want the kernel to be $k(A, B) = tr(AB)$. So it seems you want to know how to compute the trace efficiently, rather than what the mapping is. \u2013\u00a0 user3035 Jan 14 '10 at 10:02\nThe non-efficiency-related part of this question is basic linear algebra: tr(AB) is an inner product on the space of nxn matrices and so you can find isometric isomorphisms from M_{nxn} to R^{n^2}. Any of these will do for the map phi. I do not know whether or not any of these will improve the efficiency in calculating the trace, but I doubt it. \u2013\u00a0 Andrew Stacey Jan 14 '10 at 10:20\nSorry for being ambiguous. I know that I can implement $k(A,B)$ directly and avoid needing $\\phi()$. But it would be nice if I have $\\phi()$ because then, I can use a regular linear SVM on my $\\phi()$ mapped vectors. This is much simpler and faster compared to implementing $k(A,B)$ and plugging it into SVM. \u2013\u00a0 andinos Jan 14 '10 at 21:39\nadd comment\n\n2 Answers\n\nup vote 0 down vote accepted\n\nMatus is right. But if the matrices $A$, and $B$ have certain properties like being symmetric, or diagonal, then simply just vectorizing the matrices and taking their inner product would be equal to the $tr(AB)$.\n\nshare|improve this answer\nadd comment\n\nIf $A,B$ are arbitrary $n\\times n$ matrices, by definition of trace, $\\textrm{tr}(AB) = \\sum_{i,j} A_{ij}B_{ji}$. This is $O(n^2)$, but just reading the entries of $A$ is $\\Omega(n^2)$. Without any special structure on $A,B$, you probably can't do better.\n\nIf $A,B$ are (column) vectors, you probably mean the outer product $\\textrm{tr}(AB^T) = \\sum_i A_i B_i$.\n\nEdit: andinos clarified to say he wants to know about the implicit mapping of the kernel function. Well I have bad news: It does not exist!! The proof works by showing there exist matrices $A,B$ such that the corresponding kernel matrix is not positive semi-definite. To finish, apply Mercer's theorem.\n\nIn particular, set $A = \\left(\\begin{array}{cc}1 & 1 \\\\\\\\ -1 & 1\\end{array}\\right)$ and $B = A^T = \\left(\\begin{array}{cc}1 & -1 \\\\\\\\ 1 & 1\\end{array}\\right)$. Therefore $\\textrm{tr}(AB) = \\textrm{tr}(AA^T) = 4$, and $\\textrm{tr}(BA)$ is identical. On the other hand, $\\textrm{tr}(AA) = \\textrm{tr}(BB) = 0$. therefore, the kernel matrix $K$ is $\\left(\\begin{array}{cc}0 & 4 \\\\\\\\ 4 & 0\\end{array}\\right)$. Set $x = \\left(\\begin{array}{c} 1 \\\\\\\\ -1\\end{array}\\right)$, and observe that $x^T K x = -8 < 0$, and therefore $K$ is not PSD, so the kernel $k(A,B) = \\textrm{tr}(AB)$ is not PSD.\n\nOn the other hand! If you had instead defined your kernel to be $k'(A,B) = \\textrm{tr}(AB^T)$, notice that $k'(A,B) = \\sum_{i,j}A_{ij}B_{ij} = \\Phi(A)^T\\Phi(B)$ where $\\Phi$ simply takes its input matrix and outputs it as a column vector.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.it/it/help/dsp/examples/adaptive-noise-canceling-anc-applied-to-fetal-electrocardiography.html?nocookie=true\nText:\nDocumentation Center\n\n  \u2022 Trials\n  \u2022 Product Updates\n\nAdaptive Noise Canceling (ANC) Applied to Fetal Electrocardiography\n\nThis example shows how to apply adaptive filters to noise removal using adaptive noise canceling. The example uses a user interface (UI) which can be launched by typing the command HelperAdaptiveNoiseCancellation. For more details, see 'Example Architecture' below.\n\n\nIn adaptive noise canceling, a measured signal d(n) contains two signals: - an unknown signal of interest v(n) - an interference signal u(n) The goal is to remove the interference signal from the measured signal by using a reference signal x(n) that is highly correlated with the interference signal. The example considered here is an application of adaptive filters to fetal electrocardiography, in which a maternal heartbeat signal is adaptively removed from a fetal heartbeat sensor signal. This example is adapted from Widrow, et al, \"Adaptive noise canceling: Principles and applications,\" Proc. IEEE\u00ae, vol. 63, no. 12, pp. 1692-1716, December 1975.\n\nCreating the Maternal Heartbeat Signal\n\nIn this example, we shall simulate the shapes of the electrocardiogram for both the mother and fetus. We use a 4000 Hz sampling rate. The heart rate for this signal is approximately 89 beats per minute, and the peak voltage of the signal is 3.5 millivolts.\n\nCreating the Fetal Heartbeat Signal\n\nThe heart of a fetus beats noticeably faster than that of its mother, with rates ranging from 120 to 160 beats per minute. The amplitude of the fetal electrocardiogram is also much weaker than that of the maternal electrocardiogram. The following series of commands creates an electrocardiogram signal corresponding to a heart rate of 139 beats per minute and a peak voltage of 0.25 millivolts.\n\nThe Measured Maternal Electrocardiogram\n\nThe maternal electrocardiogram signal is obtained from the chest of the mother. The goal of the adaptive noise canceller in this task is to adaptively remove the maternal heartbeat signal from the fetal electrocardiogram signal. The canceller needs a reference signal generated from a maternal electrocardiogram to perform this task. Just like the fetal electrocardiogram signal, the maternal electrocardiogram signal will contain some additive broadband noise.\n\nThe Measured Fetal Electrocardiogram\n\nThe measured fetal electrocardiogram signal from the abdomen of the mother is usually dominated by the maternal heartbeat signal that propagates from the chest cavity to the abdomen. We shall describe this propagation path as a linear FIR filter with 10 randomized coefficients. In addition, we shall add a small amount of uncorrelated Gaussian noise to simulate any broadband noise sources within the measurement.\n\nApplying the Adaptive Noise Canceller\n\nThe adaptive noise canceller can use most any adaptive procedure to perform its task. For simplicity, we shall use the least-mean-square (LMS) adaptive filter with 15 coefficients and a step size of 0.00007. With these settings, the adaptive noise canceller converges reasonably well after a few seconds of adaptation--certainly a reasonable period to wait given this particular diagnostic application.\n\nRecovering the Fetal Heartbeat Signal\n\nThe output signal y(n) of the adaptive filter contains the estimated maternal heartbeat signal, which is not the ultimate signal of interest. What remains in the error signal e(n) after the system has converged is an estimate of the fetal heartbeat signal along with residual measurement noise. Using the error signal, can you estimate the heart rate of the fetus?\n\nExample Architecture\n\nThe command HelperAdaptiveNoiseCancellationHelperAdaptiveNoiseCancellation launches a user interface designed to interact with the simulation. It also launches a time scope to view the the measured fetal hearbeat as well as the measured maternal heartbeat and the extracted fetal heartbeat.\n\nUsing a Generated MEX File\n\nUsing MATLAB Coder, you can generate a MEX file for the main processing algorithm by executing the command HelperANCCodeGenerationHelperANCCodeGeneration. You can use the generated MEX file by executing the command HelperAdaptiveNoiseCancellation(true).\n\nWas this topic helpful?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/52053/deforming-a-truncated-icosahedron-into-its-circumscribing-sphere\nText:\nTake the 2-minute tour \u00d7\n\nImagine that I have a truncated icosahedron consisted of 60 vertices, each of degree $deg(v) = 3$, and fixed edge length $L$. I'd like to assign some constant curvature or bending angle $\\theta$ to each edge s.t. I can deform the icosahedron into its circumscribing sphere.\n\nAs a function of the edge length $L$, what value of $\\theta$ allows me to properly perform this deformation?\n\nshare|improve this question\nI don't understand how you're using the \"bending angle\" to deform the icosahedron. Are you looking for the angle $\\theta$ that each edge makes with the circumscribing sphere? \u2013\u00a0 anon Jul 17 '11 at 23:49\n@anon, sorry for the confusion! No I'm looking for the bending angle that places each edge on the surface of the sphere. \u2013\u00a0 R.H. Jul 18 '11 at 3:04\nOh, you mean the angle formed by the arc which results from a radial projection of an edge onto the circumscribing sphere. \u2013\u00a0 anon Jul 19 '11 at 12:15\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nFix $L=1$. Then the radius of the circumscribed sphere is $r=\\frac{1}{4} \\sqrt{58+18 \\sqrt{5}} \\approx 2.478$. Now look at the isosceles triangle formed by the center of the sphere and one edge. It has sides of length $r$ and base length 1. So the angles at either end of the base are $\\cos^{-1} (1/(2r)) \\approx 78.3593^\\circ$. The angle between the tangent to the sphere at one endpoint and the edge is then about $11.6407^\\circ$.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Soccer Ball\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192928/optimize-function-lagrange-multipliers/193013\nText:\nTake the 2-minute tour \u00d7\n\nI have a function of 4 variables: (distance function)\n$d(x,x_1,y,y_1 )=(x-x_1 )^2+(y-y_1 )^2$\n\nsubject to 2 constraints:\n1. $g(x,x_1,y,y_1 )=ax^2+2hxy+2gx+by^2+2fy+c=0$\n2. $h(x,x_1,y,y_1 )= a_1 x_1^2+2h_1 x_1 y_1+2g_1 x_1+b_1 y_1^2+2f_1 y_1+c_1=0$\n\nUsing lagrange multipliers, and partial differentiation, what should be the values of $x,x_1,y,y_1$ in terms of $a,b,c,a_1,b_1,c_1,f,g,h,f_1,g_1,h_1$, with aforementioned constraints?\n\nshare|improve this question\nHave you tried writing down the gradients of all functions involved and coming up with an equation for the Lagrange multipliers? \u2013\u00a0 Alex R. Sep 9 '12 at 1:01\nYes I have tried and I have come up with equations. That was the easy part actually, the hard part is to find values of x,x1,y,y1, with which I'm struggling up to now. \u2013\u00a0 David Hoffman Sep 9 '12 at 20:49\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $\\nabla F= \\langle \\partial_x F, \\partial_{x_1} F, \\partial_y F, \\partial_{y_1} F \\rangle$. The method of Lagrange in this case requires the introduction of two multipliers. We should solve:\n\n$$ \\nabla d = \\lambda_1\\nabla g+ \\lambda_2\\nabla h $$\n\nsubject to constraints 1 and 2 as listed in your post.\n\nThe reason for this is as follows: if an extrema exists then curves $t \\mapsto \\alpha(t) $ which pass through the extremal point must make $\\eta=d \\circ \\alpha$ extreme at the corresponding point in the domain. Suppose $t=0$ gives $\\alpha(0)$ the extremal point (we can shift the parameter to make this happen, nothing is lost in this convenience).\n\nThe curve $\\alpha$ lies on the intersection of the level sets given by 1 and 2. We have\n\n$$ g (\\alpha(t)) =0 \\qquad h( \\alpha(t))=0 $$\n\nThe chain-rule yields\n\n$$ \\nabla g (\\alpha(t)) \\cdot \\alpha'(t)=0 \\qquad \\nabla h (\\alpha(t)) \\cdot \\alpha'(t)=0 $$\n\nLikewise, since $\\eta$ is extremal at $t=0$ the chain rule gives\n\n$$ \\nabla d (\\alpha(0)) \\cdot \\alpha'(0)=0 $$\n\nSummarizing, the tangent vector field $\\alpha'$ is orthogonal to the gradient fields of $g$ and $h$ where they can be compared and at $\\alpha(0)$ the tangent $\\alpha'(0)$ is orthogonal to $\\nabla d$. The point $\\alpha(0)$ is special in that we obtain orthogonality with respect to $\\nabla d, \\nabla g$ and $\\nabla h$.\n\nAt first glance this would not appear to connect $\\nabla d, \\nabla g$ and $\\nabla h$ in any particular way. However, there is not just one curve on the constraint surface. Provided the constraints 1. and 2. are nondegenerate the level set they define is two-dimensional and there will be a two-dimensional plane of tangent vectors which are found orthogonal to $\\nabla d, \\nabla g$ and $\\nabla h$. But, this means that $\\nabla d, \\nabla g$ and $\\nabla h$ are linearly dependent since $\\mathbb{R}^4$ should be the direct sum of the tangent and normal space. For these reasons we introduce multipliers to ascertain the location of the max/min solution.\n\nNotice the method is based on the existence of extreme solutions. For the continuous function $d$ these are known to exist if the constraint is a compact surface. Sometimes the method still \"works\" for non-compact constraints, but beware the limit of the method.\n\nshare|improve this answer\nI'm sorry but I can't really understand what you wrote, this math is too advanced for me. Would it be possible to explain this at a high-school level? If not, I will be absolutely ok with it. I just need to know whether a high school student is able to solve this. Thanks. \u2013\u00a0 David Hoffman Sep 9 '12 at 20:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/447604/law-of-iterated-expectation-in-an-algebraic-axiomatization-of-probability-theory\nText:\nTake the 2-minute tour \u00d7\n\nIn the second chapter of Radically Elementary Probability Theory [PDF], Edward Nelson gives an axiomatization of probability theory based on algebras of random variables, briefly discusses a couple of properties, and points out in passing that the law of iterated expectation holds.\n\nHow can we show this? That is, how do we get from the definition of an algebra of r.v.'s to the consequence that $ E_{\\cal{B}}E_{\\cal{A}} = E_{\\cal{B}} $ for algebras $\\cal{B} \\subseteq \\cal{A}$? Nelson's definition of an algebra is the usual:\n\nBy an algebra $\\cal{A}$ of random variables we will always mean a subalgebra of $\\cal{R}^\\Omega$ containing the constants; that is, $\\cal{A}$ is a set of random variables containing the constants such that whenever $x$ and $y$ are in $\\cal{A}$, then $x + y$ and $xy$ are in $\\cal{A}$.\n\nThe structure of an algebra $\\cal{A}$ is very simple. By an atom of $\\cal{A}$ we mean a maximal event [i.e., subset of $\\Omega$] $A$ such that each random variable in $\\cal{A}$ is constant on $A$. ...\n\nHe defines the conditional expectation $E_{\\cal{A}}x(\\omega)$ to be the r.v. in $\\cal{A}$ that for each $\\omega \\in \\Omega$ is the expectation of $x$ with respect to the probability relative to the atom $A_\\omega$ that contains $\\omega$:\n\n$$E_{\\cal{A}}x(\\omega) = \\frac{1}{pr(A_\\omega)}\\sum_{\\eta \\in A_\\omega}{x(\\eta) pr(\\eta)} .$$\n\nI imagine the law of iterated expectation follows somehow from the fact that for algebras $\\cal{B} \\subseteq \\cal{A}$, each atom of $\\cal{B}$ is the union of some number of (disjoint) atoms of $\\cal{A}$, but I haven't been able to work out a complete proof. I feel like I'm missing something obvious.\n\n(Note also that if $x \\in \\cal{A}$, the proof is trivial, since it is easy to show that $E_{\\cal{A}}x = x $ whenever $x \\in \\cal{A}$. My difficulty is in showing $E_{\\cal{B}}E_{\\cal{A}}x = E_{\\cal{B}}x$ for a r.v. $x \\notin \\cal{A}$.)\n\nshare|improve this question\nThis is restricted to discrete probability spaces $\\Omega$, right? \u2013\u00a0 Did Jul 20 '13 at 8:31\n@Did, yes, everything's discrete. (The text proceeds to use non-standard analysis to extend discrete techniques to spaces that we would not be able to think of as discrete in a standard setting.) \u2013\u00a0 pash Jul 20 '13 at 14:30\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/297881/find-two-closest-points-on-two-functions\nText:\nTake the 2-minute tour \u00d7\n\nWe have two functions:\n\n$$\\begin{align*} y &= x^4-5x^3+2x^2-5 \\\\ y &= -11x-20 \\end{align*}$$\n\nMy task is to find two closest points that can be found on these two functions.\n\nCan somebody give any hints on how to solve these type of exercises?\n\nThank you!\n\nshare|improve this question\nDo you mean the closest points of the curves, or the minimum difference between the two functions? \u2013\u00a0 copper.hat Feb 8 '13 at 8:17\nThe minimum difference between the two functions. :) \u2013\u00a0 Trom Feb 8 '13 at 8:23\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nYou want to minimize $x^4-5 x^3+2 x^2+11 x+15$. Take the derivative, set that to $0$, and solve. Unfortunately this is an irreducible cubic, so the solutions are not very nice. There are three real roots: approximately $-.6828742578$, $1.275428188$, $3.157446070$. I'll leave it to you to find which of these gives the minimum.\n\nshare|improve this answer\nadd comment\n\nSince you want the minimum difference between $$\\begin{align*} y_1(x) &= x^4-5x^3+2x^2-5 \\text{ and }\\\\ y_2(x) &= -11x-20 \\end{align*}$$ you are looking for the minimum of $$ \\left| y_1(x) - y_2(x) \\right|$$ which will be a max / min of $$ z(x) = y_1(x) - y_2(x).$$ So write down the equation for $z$ as Robert Israel has done for you, differentiate $z$ and find its turning points.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247312/what-are-the-solutions-to-z41-0/247387\nText:\nSign up \u00d7\n\nI can't seem to find the solutions to $z^4+1=0 $. $z$ is in the complex plane.\n\nThe solutions show four roots; however, how do I find them once $z^4 = -1$?\n\nshare|cite|improve this question\nCan you find one? Do you know geometrically (in polar coordinates) what happens to a complex number $z$ when raised to power $n$? In the solution, basically you will draw a square in the unit circle. \u2013\u00a0 Berci Nov 29 '12 at 15:31\nDo you know the magic factorization $z^4+4=(z^2-2z+2)(z^2+2z+2)$? From this you can get what you\u2019re seeking. \u2013\u00a0 Lubin Nov 29 '12 at 17:10\nAfter answering, I realized I had already answered the same question, not too long ago. Duplicate of:\u2026 \u2013\u00a0 mrf Nov 29 '12 at 22:53\nNote: I think it is more appropriate to say \"find the solutions to $X$\" when $X$ is an equation; and \"find the roots of $X$\" when $X$ is a polynomial. \u2013\u00a0 Pedro Tamaroff Nov 29 '12 at 23:39\n\n5 Answers 5\n\nYou can write $z^4=-1$ as $(z^2)^2=-1$. The two square roots of $-1$ are $i$ and $-i$, so we get the two equations $z^2=\\pm i$.\n\nSince $i$ corresponds to $\\pi/2$ on the unit circle, its square root will have to correspond to $\\pi/4$ (or use De Moivre if you don't see this). So $$ z=\\pm\\frac{1+i}{\\sqrt 2},\\ \\ z=\\pm\\frac{1-i}{\\sqrt 2} $$ are the roots.\n\nshare|cite|improve this answer\n\nYou can write $-i$ in polar form: $$-i = e^{i \\cdot 3 \\pi /2} $$\n\nThen to find a fourth root...\n\nshare|cite|improve this answer\n\n$$z^4=-1=e^{\\pi i+2k\\pi i}=e^{\\pi i(1+2k)}\\Longrightarrow z=e^{\\frac{\\pi i}{4}(1+2k)}\\,\\,,\\,k=0,1,2,3$$\n\nshare|cite|improve this answer\n\nSince we have $i^2=-1$ $$z^4+1=(z^2)^2-(i)^2$$ $a^2-b^2=(a-b)(a+b)$, so we can factor to have $$z^4+1=(z^2)^2-(i)^2=(z^2-i)(z^2+i)$$ It's easy to solve from here on. $$z^4+1=0 \\implies \\left \\{ \\begin{align}&z^2-i=0\\implies z=\\pm\\sqrt i \\\\&z^2+i=0 \\implies z=\\pm\\sqrt{-i}\\end{align}\\right.$$\n\nUsing the properties\n\n  \u2022 $i=e^{i(\\pi/ 2)}$\n  \u2022 $-i=e^{i(3\\pi/ 2)}$\n  \u2022 $e^{i\\theta}=\\cos \\theta + i\\cdot \\sin \\theta$\n\nyou can express the result in much more interesting forms.\n\nshare|cite|improve this answer\n\n$$z^4+1 = (z^2+1)^2-2z^2 = (z^2+1-z\\sqrt2)(z^2+1+z\\sqrt2)$$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/16664/how-do-i-rearrange-de-dt-to-find-an-electrons-half-life-due-to-synchrotron-ra\nText:\nSign up \u00d7\n\nI know that $-\\frac{\\mathrm{d}E}{\\mathrm{d}t} \\propto E^2$ for an electron losing energy to synchrotron radiation, but I can't find how to arrange this to give the time it would take for the electron to lose half of its original energy. How would I go about working that out?\n\nshare|cite|improve this question\nThe half-life description only works for exponential decay. As others have shown, this leads to a power-law decay, as 1/t. So you can ask for the asymptotic half-life in log-t variable, but not in t. \u2013\u00a0 Ron Maimon Nov 8 '11 at 6:48\nBut the OP does not speak of half-life! His problem has meaning per se. \u2013\u00a0 Vladimir Kalitvianski Nov 9 '11 at 15:21\n\n2 Answers 2\n\nNot to worry, it's fairly easy: right now you have a differential equation which can be written\n\n$$\\frac{\\mathrm{d}E}{\\mathrm{d}t} = -CE^2$$\n\nfor some constant $C$. You need to solve that differential equation for $E(t)$. (If you're wondering how to do that, you can find more information at the math site.) Then you can determine the electron's energy at the initial time $t_0$ as $E(t_0)$, and find the time at which its energy becomes half of that:\n\n$$E(t) = \\frac{E(t_0)}{2}$$\n\nand solve for $t$.\n\nshare|cite|improve this answer\n\n$$\\frac{dE}{dt} = -CE^2$$\n\n$$d\\left (\\frac{1}{E}\\right ) = Cdt$$\n\n$$\\frac{1}{E_2}-\\frac{1}{E_1}= C(t_2-t_1)$$\n\n\n$$\\frac{1}{E_1} = C\\Delta t$$ $$\\Delta t = \\frac{1}{CE_1}$$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/30720/ned-velocity-to-redshift-conversion\nText:\nSign up \u00d7\n\nI've done some search with the Nasa Extragalactic Database (NED) and I have a very basic question about the velocity/redshift conversion. For example, for the first object of this page, we have $v=19791km/s$ and $z=0.066016$.\n\nIf we use the simple formula $z=v/c$, we find the result of the database : $19791/299792=0.0660157709345$. But now if we use the formula : $z = \\sqrt{\\frac{c+v}{c-v}}-1$ we find $0.0683461749892$\n\nWhich is the correct one and why ?\n\nThank you very much.\n\nshare|cite|improve this question\nI suspect that the velocity formula must incorporate the expansion of the Universe. I'm not sure though: I wouldn't expect it to be a ~3% effect at that redshift. \u2013\u00a0 Warrick Jun 25 '12 at 11:29\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe simple formula is just the first-order expansion of the more complicated one about $v = 0$, the latter being exact for the Doppler effect of motion purely along the line of sight. The $v$ here refers to the peculiar motion of the galaxy.\n\nBe aware that for all but the very nearest galaxies, the observed redshift comes almost entirely from the expansion of the universe, not from relative motion in the special-relativistic sense. Thus converting from redshift to velocity using either of the formulas mentioned, though a very common practice, can be misleading. For a thorough albeit technical discussion of subtleties related to this point, there is a paper by Davis and Lineweaver.\n\nEdit: Since I have lately been using NED a lot, I came across this page in their documentation. Point 1 in particular notes that \"no relativistic correction is applied\" and so you may see \"velocities in excess of the speed of light.\" (It also says $v = z/c$, but I hope that's just a typo.) There are two important points here. The first is that you can safely assume the values reported are redshift times the speed of light, possibly with a correction to a certain reference frame. The second is that even NASA is under the misconception that redshift of distant galaxies has something to do with Doppler shift, when this is just fundamentally false. The quantity $zc$ is really just a way of putting units to redshift, nothing more.\n\nshare|cite|improve this answer\nActually, now that you mention Davis & Lineweaver - there's another article (popular one) where Davis explains how Doppler and expansion redshifts are perfectly equivalent, it is really just a matter of one's choice of descriptive language. The real misconception is that superluminal speeds are not possible. Special Relativity only applies locally, and over the distances covered by a redshift of 1.4 (which, IIRC, is where expansion goes superluminal), this is no longer a good approximation. \u2013\u00a0 Thriveth Mar 24 '14 at 14:08\n\nThere are different formulas that give better approximations depending on the velocity distribution, and overall velocity magnitude. Suggest looking at :\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247855/strictly-convex-inequality-in-lp\nText:\nSign up \u00d7\n\nLet $1<p<\\infty$. Let $x,y\\in l^p$ such that $||x||_p=1$, $||y||_p=1$ and $x\\neq y$. Would you help me to show that for any $0<t<1$, $||tx+(1-t)y||_p<1$.\n\nMy answer : By using Minkowski inequality, we get $||tx+(1-t)y||_p\\leq t||x||_p+(1-t)||y||_p=t+(1-t)=1$. But I don't get the strict inequality.\n\nBut, For $p=2$: \\begin{eqnarray} ||tx+(1-t)y||_2^2&=&t^2||x||_2^2+(1-t)^2||y||_2^2+2t(1-t)\\Re(<x,y>)\\\\&=&1+2t(1-t)(\\Re(<x,y>)-1)) \\end{eqnarray}\n\nSince $x\\neq y$ and $||x||_2=||y||_2$, we conclude that $x\\neq ky$ for every scalar hence we get $\\Re(<x,y>)\\leq|<x,y>|<||x||_2||y||_2=1$. So, $||tx+(1-t)y||_2<1$.\n\nThanks everyone.\n\nshare|cite|improve this question\n\n1 Answer 1\n\nFor $1 < p < \\infty$, Minkowski's inequality is an equality if and only if one of the vectors is a multiple of the other by a nonnegative scalar.\n\nshare|cite|improve this answer\nIf the vectors is multiple of the other by scalar implies the equality is trivial. How about the converse? \u2013\u00a0 beginner Nov 30 '12 at 6:43\nYou can go back over the proof of Minkowski's inequality, and H\u00f6lder's which is usually used in that proof. At some point you may use something like the fact that the minimum of the function $f(x) = x^p/p - x$ for $x \\ge 0$ is at $x=1$. Now note that this is a unique minimum ($f$ is strictly convex)... \u2013\u00a0 Robert Israel Nov 30 '12 at 8:20\n\nYour Answer"}
{"text": "Retrieved from http://stackoverflow.com/questions/784533/reverse-that-math-function\nText:\nTake the 2-minute tour \u00d7\n\nI need to reverse a function with hard Math operations, I'm asking here to check if it's even possible, eventually for help.\n\n    public static UInt32 Func_4(UInt32 P, UInt32 X, UInt32 G)\n        UInt64 result = 1;\n        UInt64 mult = G;\n        if (X == 0)\n            return 1;\n        while (X != 0)\n            if ((X & 1) != 0)\n                result = (mult * result) % P;\n            X = X >> 1;\n            mult = (mult * mult) % P;\n        return (UInt32)result;\n\nBy \"Reversing\" I mean this: I know G, I know P, I know the result. I need X.\n\nI tried to translate it again this morning while my mind was clear, but I failed. Is it even possible?\n\nThank you in advance.\n\nshare|improve this question\nWhat are your expected inputs to the inverse? Which of P, X, and G are you looking to get back? \u2013\u00a0 Ben Alpert Apr 24 '09 at 4:34\nIt would help if you show the algorithm you hope to do. Also, if you know the result and don't know X, then why pass in X? Pass in the result as a parameter. \u2013\u00a0 James Black Apr 24 '09 at 4:38\nJames: I think he has r = f(p, x, g) and wants a function x = h(p, r, g). \u2013\u00a0 Ben Alpert Apr 24 '09 at 4:40\n@Ben,I need X. @James,X by default is random everytime you use the whole algoritm.I need to get that random number always.I know the other two,they are static.I also know the result.I have to reverse that function and then put the result and the other two parameters I know to get X. \u2013\u00a0 Ivan Prodanov Apr 24 '09 at 4:41\nWhat does the function compute? Let's start there. :) \u2013\u00a0 JP Alioto Apr 24 '09 at 4:45\n\n6 Answers 6\n\nup vote 20 down vote accepted\n\nIt looks like your Func_4() function calculates GX mod P. What you're asking for is a solution to the discrete logarithm problem, but no efficient algorithm is known.\n\nshare|improve this answer\nHowever, if the poster does solve this problem, I've got this RSA system I'm trying to break... \u2013\u00a0 Stefan Kendall Apr 24 '09 at 5:05\nthe \"mod\" is the problem. You won't break this ever. 5 mod 2 has the same result as 7 mod 2 and 9 mod 4 and so on. You can't determine the input based on the output. There is an infinity of input combinations that result in the desired output. Go to sleep. \u2013\u00a0 Andrei R\u00eenea Apr 24 '09 at 21:09\nExactly. You're not supposed to get X. You're supposed to check whether the client knew the correct x by sending it different G and P, and check if their results agree with yours. But at no point is x supposed to be transmitted. \u2013\u00a0 Tim Lin Apr 29 '09 at 15:20\n\n\nworking through this by hand for:\n\nP=5, X=0b0000 1110, G=7\n\nP=5, X=0b0001 1110, G=7\n\nP=5, X=0b0011 1110, G=7\n\nP=5, X=0b0111 1110, G=7\n\netc, i think you see the pattern\n\nall have the same return value for result (4)...\n\ntherefore any attempt to reverse this to get a value for X would have multiple possible values for X..\n\ndepending what you actually need out of this thing, this may not really matter...\n\nwhats the context of this thing?\n\nshare|improve this answer\n\nSince the modulo operator is in play, you can tell immediately that the function is not bijective: for a fixed P and G, different x's may return the same result.\n\nBut the function is bijective for a limited domain of x. Just like atan, asin, sqrt, .... produce a whole set of values, when you limit the domain, you can pick the correct one.\n\nAt first sight, what the function does, for a very large P, is,\n\nThe product of G(2i*x[i]), where x[i] is the i'th bit of x (starting with bit 0 as least significant).\n\nThis means that given a large P (larger than Prod(G2i), for x=0x1111...111), you can reverse the function. It also seems that the function was designed not to be reversible for smaller P's.\n\nshare|improve this answer\n\nIt looks like i = (g**x) mod p. That means there may be more than one x\n\nshare|improve this answer\nYeah,X = X << 1 ,everytime you step the loop. Does that mean its impossible? \u2013\u00a0 Ivan Prodanov Apr 24 '09 at 4:45\nNot impossible, just that there are multiple answers (and not due to the << but due to the %). Is this fast enough for you?... x=0; do { if (Func_4(P,x,G)==I) then return x; x++; } while (x!=0); \u2013\u00a0 Doug Currie Apr 24 '09 at 14:54\n\npseduo algorithm\n\nR = pow(G,X) mod P\n\nie) there exists one Q which is R + P * Q = pow (G,X)\n\nIn reverse, Check Y for all Q from 0 to UINT32((MAXUINT32-R)/P),\n\nY = log ( R + P * Q ) / log (G)\n\nand if the value Y does not have fractions, then they are the Set of multiple \"X\" answers to your problem.\n\nAssume X1 is the first X value which does not have fractions and X2 is the second X Value which does not have fractions. Then Set of all X can be given in the equation X(S) = X1 + (X2-X1) * S where S=0 to UINT32( (MAXUINT32-X1) / (X2-X1) ).\n\nThat is due to if 1= Pow(G,T) mod P and then Pow(G,X+T) mod P = Pow(G,X) mod P * Pow(G,T) mod P which is also Pow(G,X) mod P. Hence X, X+T, X+2T, X+3T... all will have same values..\n\nshare|improve this answer\n\nI seriously think you're abusing this algorithm. From your description, and from looking at the algorithm, it's pretty clear that this is designed to go forward only. Think of it as computing a checksum of X using keys P and G.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/79469/will-the-eigenvalue-of-the-dirac-operater-tend-to-negative-infinity/79471\nText:\nTake the 2-minute tour \u00d7\n\nQuestion: If M is a spin manifold. Condider the dirac operator on a spinor bundle. Can the eigenvalue of this operater tend to negative infinity? If it can, can we choose a riemann matrix such that under this matrix, the eigenvalue of dirac operator does not tend to negative infinity??\n\nshare|improve this question\n\n2 Answers 2\n\nGiven any first order, graded, self-adjoint, elliptic operator on a manifold the spectrum is unbounded in both the positive and negative directions. There are probably elementary ways to see this, but I'll give an argument which is overly sophisticated but a bit more quantitative.\n\nGiven $D$ as above, consider the eta function associated to $D$:\n\n$$\\eta(s) = \\sum_{\\lambda} sign(\\lambda) |\\lambda|^{-s}$$\n\n(the sum ranges over the eigenvalues of $D$)\n\nBy a variation on Weyl's asymptotic formula for the eigenvalues of the Laplacian together with some basic complex analysis, this function extends to a meromorphic function on the complex plane. It is a very deep topological fact that the eta function is actually bounded at $0$; in the case of Dirac-type operators this follows from the sort of heat kernel analysis used in the local proof of the Atiyah-Singer index theorem, and for general elliptic operators this follows from the Dirac case together with some cobordism theory.\n\nIn any event, $\\eta(0)$ can be regarded as a sort of \"renormalized difference\" between the number of positive eigenvalues and the number of negative eigenvalues, and the fact that it is bounded means that there are infinitely many positive and negative eigenvalues.\n\nAs I said above this machinery is probably overkill as far as your actual question is concerned, but it proves something stronger: it makes precise the assertion that the cardinality of the positive part of the spectrum agrees with the cardinality of the negative part \"up to a finite error\".\n\nshare|improve this answer\n\"There are probably elementary ways\". I think the following should work: It suffices to show that the Rayleigh quotient $\\langle \\phi, D\\phi\\rangle/|\\phi|^2$ is doubly unbounded. Take $\\phi$ to be supported in a ball where $D$ is well approximated by a constant coefficient operator. In a much smaller domain, take $\\phi$ to be an eigenvector $\\psi$ for the latter operator thought of as an operator with periodic boundary condition (i.e. an operator on a torus). \u2013\u00a0 Tim Perutz Oct 29 '11 at 22:56\nIn the larger ball, define $\\phi$ by cutting off $\\psi$, but slowly, so that the behaviour of $\\psi$ dominates. This reduces the problem to the case of constant coefficient operators over the torus, for which Fourier series are available. \u2013\u00a0 Tim Perutz Oct 29 '11 at 22:57\nBTW, a good account of these facts about the eta function is given by Ken Richardson in his note \"Introduction to the eta invariant\" ncatlab.org/nlab/show/eta+invariant#Richardson \u2013\u00a0 Urs Schreiber Aug 27 at 18:52\n\nCan the eigenvalue of this operater tend to negative infinity?\n\nYes -- actually this question is closely tied to the physical origins of the Dirac operator. Very roughly speaking negative eigenvalues correspond to negative-energy eigenstates; the Dirac equation predicts that particles with positive energy (e.g. electrons, which can have arbitrarily large positive energy) there is an antiparticle \"twin\" with negative energy (positrons in this case).\n\nFor instance, if $M$ is the unit sphere in $\\mathbb{R}^3$ then Dirac eigenfunctions give you the angular part of the electron wave function; the corresponding eigenvalues are simply all the integers $n \\in \\mathbb{Z}$ which show up with multiplicity $n+1$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/99918/riemann-roch-and-dim-of-deformation-space\nText:\nTake the 2-minute tour \u00d7\n\nLet's consider curve $C\\subset \\mathbb P^n$ of degree $d$ and genus $g$. We want to calculate dimension of deformation space of $C$, i.e. $h^0(C,L)$ where $L$ is the normal bundle.\n\nWe can decompose $L$ as $L_1\\subset L_2\\dots \\subset L$, such as $dim L_{i+1}/L_i =1 \\ $ and apply Riemann-Roch to each $L_{i+1}/L_i$.\n\nI heard that this gives us $(n-1)(d-g+1)+2g-2 + 2d\\ $ (as expected to be dimension of deformation space of $C$ or the number of points need to fix to count curves degree $d$ and genus $g$ passing through them).\n\nBut I can't calculate it ! Could you help me with this or give me a reference ?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nLet's start by stating Riemmann-Roch for vector bundles: If $C$ is a smooth projective curve of genus $g$, and $E$ is a vector bundle of rank $r$ and degree $\\delta$, then $h^0(C,E) - h^1(C,E) = \\delta - r(g-1)$. If $E$ has a filtration such as you describe, you can prove this by using Riemann-Roch on each quotient line bundle, and then adding up the contributions in the long exact sequence of cohomology.\n\nNow, we want to consider the case where $E$ is the normal bundle $N$ to $C \\subset \\mathbb{P}^n$. The rank of $E$ is $n-1$. We have the short exact sequence $0 \\to T_C \\to T_{\\mathbb{P}^n}|_C \\to N \\to 0$. The tangent bundle to $C$ has degree $-(2g-2)$. The tangent bundle to $\\mathbb{P}^n$ has first chern class $(n+1)$ times the hyperplane class; the hyperclane class restricts to $d$ times the fundamental class of $C$. So the degree of $N$ is $d(n+1) + (2g-2)$ and Riemann-Roch gives $$d(n+1)+(2g-2)-(n-1)(g-1)$$ which matches your formula.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/122396/is-this-set-corresponding-to-a-bounded-linear-operator-necessarily-open\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\Lambda : X \\to X$ be a bounded linear operator on a Banach space $X$. My question is whether the set $$ \\{\\lambda \\in \\mathbb C: \\lambda I - \\Lambda \\quad\\text{is surjective} \\} $$ is necessarily open. The above set is similar to the resolvent set of $\\Lambda$, which is defined to be the set of all $\\lambda \\in \\mathbb C$ such that $\\lambda I - \\Lambda$ is invertible; I know that the resolvent set is always open. However, what about the set above?\n\nFor reference, it was a problem on a past qualifying exam (see problem 6) to prove that the set is in fact open. I'm not sure if they meant to indicate the resolvent set, or if the problem is correct as stated.\n\nshare|improve this question\nA related thread proving the stronger result that the space of surjective operators is open. \u2013\u00a0 t.b. Mar 20 '12 at 10:20\n@t.b. Thanks for pointing that out, the argument is very nice. \u2013\u00a0 Nick Strehlke Mar 20 '12 at 14:17\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nLet $\\lambda$ such that $T := \\lambda - \\Lambda$ is surjective. Then $\\bar T: X/\\ker T \\to X/\\ker T$, $\\bar T(x + \\ker T) = Tx + \\ker T$ is invertible, hence there is some $\\varepsilon > 0$ such that $\\bar T + \\mu$ is invertible for $|\\mu| < \\varepsilon$.\n\nLet $0 < |\\mu| < \\varepsilon$ and $y \\in X$. Then there is some $x \\in X$ such that $(\\bar T + \\mu)(x + \\ker T) = y + \\ker T$, which means that $Tx + \\mu x + \\ker T = y + \\ker T$. So there is some $z \\in X$ with $Tz = 0$ and $Tx + \\mu x + z = y$. Then \\begin{align*} (T + \\mu)\\left(x + \\frac 1\\mu z\\right) &= Tx + \\mu x + z\\\\ &= y. \\end{align*} As $y$ was arbitrary, $T + \\mu$ is surjective and the set in question is open.\n\n\nshare|improve this answer\nThanks martini, this is very helpful. \u2013\u00a0 Nick Strehlke Mar 20 '12 at 14:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166010/messenger-riddle?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nA column of troops one km long is moving along a straight road at a uniform pace. A messenger is sent from the head of the column, delivers a message at the rear of the column and returns. He also moves at a uniform pace and arrives back at the head of the column when it has just covered its own length. How far did the messenger travel?\n\nI can't get any ideas on how to start.\n\nThanks for any help.\n\nshare|improve this question\nHow far did the messenger travel means the distance traveled or the displacement? If its displacement then the answer should be 1km. \u2013\u00a0 Saurabh Jul 3 '12 at 6:10\nIt means distance. \u2013\u00a0 Matt Jul 3 '12 at 6:12\nYou just need to organise the information carefully and use distance = speed x time. Write down what you know about the movement of the column - say speed $u$ and the messenger say speed $v$ taking total time $t$. Split the movement of the messenger into two obvious parts. Then identify the total distance $d$ you want to find, and use the information you have to find an equation for $d$. \u2013\u00a0 Mark Bennet Jul 3 '12 at 6:19\nA trivial answer to the question would be $1$km, the length of the column. After all, the messenger starts out at the head of the column, and ends up again at the end of the column, at the point in time when it has covered its own length, and she then has advanced as much as the column has. This is probably not what the question intends, but it could be made clearer. \u2013\u00a0 Marc van Leeuwen Jul 3 '12 at 6:50\nadd comment\n\n3 Answers\n\nup vote 7 down vote accepted\n\nLet us assume that the speed of the column is $1$ km per unit of time. For convenience, call that unit an hour. The column took $1$ hour to cover its own length.\n\nLet $v$ be the speed of the messenger. When she is travelling to the back, the combined speed of approach of the messenger and the column rear is $v+1$, so the time it takes is $\\frac{1}{v+1}$. Going the other way, the speed at which the messenger gains on the head is $v-1$, so the time it takes to gain the whole $1$ km is $\\frac{1}{v-1}$. The whole task took $1$ hour, and therefore $$\\frac{1}{v+1}+\\frac{1}{v-1}=1.$$ This gives $v=1+\\sqrt{2}$. The time taken is an hour, so the distance travelled is $1+\\sqrt{2}$.\n\nshare|improve this answer\nadd comment\n\nLet the speed of troop is $u$ kmph and that of messenger is $v$ kmph.\nSo the relative speed when messenger is going backward is $v+u$ kmph.\nAnd relative speed while going forward is $v-u$ kmph $(v>u)$.\nSo the total time taken is $$t=\\frac{1}{v+u}+\\frac{1}{v-u}$$ but in this time troop had moved $1$km so the $t=\\frac{1}{u}$\n$$\\frac{1}{u}=\\frac{1}{v+u}+\\frac{1}{v-u}$$ $$v^2-2uv-u^2=0$$ which give us the following relation $$v=u(1+\\sqrt2)$$\n\nso the distance traveled is $$\\begin{align*} d= &\\underbrace{\\frac{v}{v+u}}_{backward}+\\underbrace{\\frac{v}{v-u}}_{forward}\\\\ &=\\frac{2v^2}{v^2-u^2}\\\\ &=\\frac{2v^2}{2uv}\\\\ &=\\frac{v}{u}=1+\\sqrt{2}\\text{ km}\\end{align*}$$\n\nshare|improve this answer\nMostly ok, but why did you give the answer using units of speed? Mind you, I've never seen it abbreviated \"kmph\". At least locally \"km/h\" is the only way to write it. This is different from, e.g. U.S.A., where \"mph\" is always used. I guess there are local variations :-) \u2013\u00a0 Jyrki Lahtonen Jul 3 '12 at 7:27\n@JyrkiLahtonen Oh that was a mistake .I have corrected it.Thanks \u2013\u00a0 Saurabh Jul 3 '12 at 7:32\nadd comment\n\nLet $x$ be the troops' speed and $y$ be the messenger's speed.\n\nTotal messenger travelling time is $1/x$ (as the troops moved 1km forward).\n\nIn the troops frame of reference, the messenger first moved backwards with the speed of $y+x$, and then moved forward with the speed of $y-x$ so that in the $1/x$ total time he returned to the initial position.\n\nLet $z$ be the time messenger spent to reach the rear of the column. Obviously, $z = 1/(y+x)$ (as messenger moves with the speed of $y+x$ relative to the column and has to travel $1$ km relative to the column to reach its rear).\n\nFrom the other side, we have $z \\times (y+x) + (1/x - z) \\times (y-x) = 0$, from which follows $2zx + y/x - 1 = 2/(y/x+1) + y/x - 1 = 0$.\n\nNote that the total messenger travelling distance is $d = y/x$. From the previous equation we get $2/(d+1) + d - 1 = 0$, $d^2-3 = 0$, and thus $d = \\sqrt{3}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262615/a-logic-puzzle-from-tes-arena/262653\nText:\nTake the 2-minute tour \u00d7\n\nIts nice when games have riddles hidden in them. While playing TES:Arena, I came across an unusual logical puzzle: There are 3 cells.\n\nIf Cell 3 holds worthless brass, Cell 2 holds the gold key.\n\nIf Cell 1 holds the gold key, Cell 3 holds worthless brass.\n\nIf Cell 2 holds worthless brass, Cell 1 holds the gold key.\n\nKnowing this brave fool, and knowing that all that is said cannot be true, which cell contains the gold key?\n\nThe correct answer is Cell 2 as suggested by the game. I wanted to know how one could logically arrive at the result. Could anyone help me with this?\n\nWhat I tried: I negated all the above statements. The first implication became Cell 3 holds worthless brass AND Cell 2 does not have gold key. But if this is true, then cell 2 does not have the gold key and the result is incorrect. Hence I had this doubt.\n\nPS: Choosing the wrong door causes man eating spiders to be released.\n\nshare|improve this question\nDoes each cell necessarily contain either worthless brass or a gold key? \u2013\u00a0 Sp3000 Dec 20 '12 at 12:55\nAlthough not stated in game, there is only ONE cell with a gold key. The other cells may/may not have brass. \u2013\u00a0 Gautam Shenoy Dec 20 '12 at 12:57\nadd comment\n\n4 Answers\n\nIf you label the conditions a-c, and if the gold key exists and is unique, it is enough to show that not in 2 leads to a contradiction. But 'key not in 2' leads to 'key in 2' (so a contradiction), as follows:\n\nBy (c), not in 2 implies in 1. By (b) then, not in 3. By (a) then, key is in 2. Contradiction.\n\nTo be safe, you can check if the game makers messed up:\n\nAs 'key in 1' is a sub chain of the above, it also leads to 'key in 2'. Contradiction.\n\nSimilarly, 'key in 3' means by uniqueness that 2 holds brass, which, by (c), implies 1 holds the key. Contradiction.\n\nFinally note that if the key is in 2, it doesn't lead to any contradictions. So game is correct.\n\nshare|improve this answer\nadd comment\n\nCell 2 cannot hold worthless brass, and cell 1 cannot have the gold key.\n\nIf a cell can have neither brass nor key, then that is the limit of what you can conclude. For example, your conditions are consistent with cell 3 having the key and there being nothing in the other cells.\n\nBut if every cell contains either brass or key, then you know cell 2 has the key. You can prove that by assuming cell 2 did not have the key, and hence had worthless brass. That implies that cell 1 has the key, which implies cell 3 has worthless brass which implies that cell 2 has the key. Contradiction.\n\nHowever, if that additional condition were part of the problem, then your middle condition would be redundant.\n\nshare|improve this answer\nadd comment\n\nSorry to be contrary, but I believe you need 2 assumptions for there to be a unique solution. First, that all 3 statements are indeed true. If we allow that one or more of those statements doesn't hold, the whole thing falls apart.\n\nSecond, that each cell contains either brass or the key. No empty cells. If you disagree, try looking at these 2 solutions:\n\nCell 1 = Empty, Cell 2 = Key, Cell 3 = Empty\n\nCell 1 = Empty, Cell 2 = Empty, Cell 3 = Key\n\nNone of the 3 statements apply to either of these, so they're both possible valid solutions and you're left to guess and hope the spiders don't eat your face.\n\nNow, you can brute force your way through by listing all possible solutions and checking which are valid under the given statements. In this case there aren't many possible choices, so that approach is not too bad. However, I'm assuming you're looking for a bit deeper insight, so I'll walk through a technique that can sometimes provide a quicker route to the answer, especially in more complex puzzles.\n\nSince all the implications are one way (they are \"if\", not \"if and only if\"), one approach is to start by assuming a condition from the left side of a statement and trace the implications through all the statements to look for inconsistencies.\n\nJust going in order, let's assume first that Cell 3 holds brass. Then by statement 1, Cell 2 holds the key. Since we're assuming key or brass in each and only one key, then Cell 1 would have to be brass. Given that, neither of the last 2 statements apply, so this solution is possible with no contradictions. Let's continue and check the others to be sure we have the only possible valid solution.\n\nLooking at statement 2, let's assume now that Cell 1 holds the key. By statement 2, Cell 3 holds brass. By statement 1, Cell 2 holds the key. Since only 1 cell can hold the key, this is a contradiction. Therefore our original assumption is false, so Cell 1 does not hold the key.\n\nLastly, look at the third statement. If we assume Cell 2 holds brass, then Cell 1 holds the key. But we already know by our last reasoning that if Cell 1 holds the key we end up with a contradiction. So our assumption here is false, and Cell 2 does not hold brass.\n\nSince Cell 2 cannot hold brass, it must hold the key.\n\nshare|improve this answer\nadd comment\n\nIf you take \"not all that is said is true\" to mean that at least one statement is false, you can go through negating them and see where it leads. If the first statement is false, you have 3 holds brass and 2 does not hold the gold key. Given that there is a gold key, it must be behind door 1. Then the second and third statements would be true, but we still don't know whether cell 2 holds brass.\n\nIf the second statement is false, cell 1 has gold and 3 does not have brass (so is empty). The first and third sentences are then true and we again know nothing about cell 2.\n\nIf the third statement is false, 2 holds brass and 1 does not have gold, so it must be cell 3 that has gold. The other two are then true and we don't know what 1 holds.\n\nSince we didn't reach a contradiction from any of these, we can't choose between them. I would downvote the puzzle creator. However, if you ignore the \"not all that is said is true\" and believe them all, gnometorule has shown how to get there.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/297008/expected-value-of-largest-integer-in-a-draw/297074\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I pick $k$ integers without replacement from $\\{1, \\ldots, n\\}$. Let $I$ be the value of the highest integer. A calculation with binomials reveals $$E[I] = \\frac{k}{k+1}(n+1)$$ This is a very simple formula - does it have a simple calculation-free proof?\n\nshare|improve this question\nDo you know some instance of calculation-free proof for the expected value of some non-constant random variable? I would like to see it. \u2013\u00a0 Matem\u00e1ticos Chibchas Feb 7 '13 at 8:22\nIn many cases, you can use symmetry or some clever conditioning to avoid heavy calculations. \u2013\u00a0 pierre Feb 7 '13 at 8:33\nYou just said it: \"heavy\" calculations. This is OK, but no calculations at all? Besides, I agree that conditioning is clever, but it is based on the nontrivial subject of conditional expectation. \u2013\u00a0 Matem\u00e1ticos Chibchas Feb 7 '13 at 9:04\n@Matem\u00e1ticosChibchas - the answer by Henry below is what I would call calculation-free. \u2013\u00a0 pierre Feb 8 '13 at 23:42\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nPicking $k$ integers without replacement from $\\{1, \\ldots ,n\\}$ involves breaking the interval $[0,n+1]$ into $k+1$ pieces where the length of each piece has the same distribution.\n\nSo the expected length of each piece (including the piece from the highest sampled integer to $n+1$) is $\\dfrac{n+1}{k+1}$ and so the expected value of the highest sampled integer is $n+1 - \\dfrac{n+1}{k+1}$.\n\nSimple calculation will give your result.\n\nSo in general, the expected value of the $j$th sampled integer (counting from the bottom) is $j \\dfrac{n+1}{k+1} $.\n\nshare|improve this answer\nSorry by my ignorance, but I don't get it: what is the \"same distribution\" of each piece? (I don't understand the expected length stuff either, but hopefully this will be cleared when I get illuminated about the \"same distribution\" issue) Thanks. \u2013\u00a0 Matem\u00e1ticos Chibchas Feb 7 '13 at 20:08\nVery nice! But how do you show that are no \"edge effects,\" i.e., that the length of the first piece has the same as the length of the second? \u2013\u00a0 pierre Feb 7 '13 at 22:04\n@Matem\u00e1ticos Chibchas: Each length is a random variable with a distribution. Each of these distributions is the same and has the same mean. \u2013\u00a0 Henry Feb 8 '13 at 7:35\n@pierre: Imagine seating $k+1$ people round a table with $n+1$ seats: there are no edge effects in the gaps between people. Then cut the table where the first person sits and straighten it into a bench of length $n+1$. \u2013\u00a0 Henry Feb 8 '13 at 7:39\nLovely. Thank you for this fantastic answer. \u2013\u00a0 pierre Feb 8 '13 at 23:41\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/9558/the-shortest-path-in-first-passage-percolation\nText:\nTake the 2-minute tour \u00d7\n\nConsider a square planar grid. (The vertices are pair of points in the plane with integer coordinates and two vertices are adjacent if they agree in one coordinate and differ by one in the other.)\n\nGive every edge a length one with probability a half and length two with probability a half.\n\nConsider a shortest path between the origin and the vertex $(n,0)$.\n\nShow that with probability that tends to one as $n$ tends to infinity the shortest path will not contain the \"middle edge\" on the x-axis inbetween the orgin and $(n,0)$. (Namely, the edge between the vertices $(\\lfloor\\frac{n}{2}\\rfloor,0)$ and $(\\lfloor\\frac{n}{2}\\rfloor+1,0)$.)\n\nThis question is in the category of \"a missing lemma\". It is not really a full fledged open problem but rather a statement which looks correct that was needed in some paper and resisted proof. Of course, some such \"lemmas\" turn out to be very difficult, but sometimes maybe a simple argument was simply missed. The relevant paper is with Itai Benjamini and Oded Schramm: First Passage Percolation Has Sublinear Distance Variance\n\nWhile MO have chosen to accept one answer, and there were some nice suggestions, the problem is still wide open.\n\nshare|improve this question\nThanks Alon, I myself cannot see the latex (it leaves the formulas uncompiled) so I prefer the plain text. \u2013\u00a0 Gil Kalai Dec 23 '09 at 10:34\nNitpicking: is it \"a shortest path\" or \"the shortest path\"? Do you want to show there is a shortest path avoiding the given edge, or that all shortest paths avoid the given edge. \u2013\u00a0 Boris Bukh Dec 23 '09 at 11:26\nThat's really a shame, Gil. Have you tried installing jsMath along with the fonts? It's not supposed to be necessary but perhaps it'll help. \u2013\u00a0 Alon Amit Dec 23 '09 at 18:00\nBoris, I suppose I just want to show that there is a shortest path avoiding this middle edge. Alon, jsMath? where \u2013\u00a0 Gil Kalai Dec 23 '09 at 18:50\nBoris: That's not nitpicky, it's actually an important point. If the distribution of passage times is continuous, then with probability one, there is a unique minimizing path between any two points. Here, since the distribution has atoms, with positive probability, there are multiple shortest paths. \u2013\u00a0 Tom LaGatta Dec 26 '09 at 2:02\nshow 1 more comment\n\n7 Answers\n\nGil: This is a type of problem that I know little about so here I am thinking out loud about problems that seem natural to ask about this situation. It is hard to believe that people have not already thought about these questions and perhaps answered them. Where would I look to find out more?\n\nYou write you are interested in a \"square planar grid.\" So I took this to mean that you were thinking about the points of a \"square grid graph\" with lx1 squares as the cells that goes from (0,0) to (n,n) and where weights were going to be assigned to the edges of size 1 or 2.\n\nThe paths that you are talking about need not be constrained to move up and to the right but it might be interesting to contrast the behavior of general shortest paths with those that move up and to the right. It would also seem to be of interest to see what happens if one selects half of the edges at random and makes them all length 1 edges and makes all the others of length 2. Since there are 4n edges this means 2n are 1's and 2n are 2's. Furthermore, If we insist that paths move up and to the right, such paths all have length 2n, so \"very shortest\" paths would consist only on 1's.\n\nIn both settings:\n\na. What is the probability there is a shortest path to (n,n) consisting of all 1's?\n\nb. What can be said about the expected value of the length of a shortest path to (n, n)? What can be said about the expected number of paths of this value?\n\nc. When one insists that each of the two lengths appear equally often how many different ways can this happen? (One can also ask how many of these are different up to symmetry of the \"colored\" graph, treating the lengths as two colors.) One could count in the general case too but the up and to the right case seems more interesting here.\n\nshare|improve this answer\nTo whomever gave this post a negative vote: Shame on you. This post does not answer the question Gil asked, but so what? It is exploratory and raises some interesting ideas; perhaps one of those could lead to a correct answer. Posts like this are exactly what MathOverflow needs. \u2013\u00a0 Tom LaGatta Dec 26 '09 at 1:57\nJoe, it is a very good idea to consider paths from (0,0) to (n,n) and to consider also the case where you only go north and east. This restricted model is called \"directed percolation\". As far as I know the lemma is not known for directed percolation. There is one version where the distribution of edge length is exponential and you want the path of MAXIMUM length where this model is understood very well and is strongly connected to maximum eigenvalues of random symmetric matrices, largest monotone subsequences etc. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:27\nIt may be possible that for this version (directed percolation; exponential lengths, maximum path), the detailed understanding of the model may lead to a proof of the lemma; but I am not sure even about it. (There are hopes, but no proofs for universality: that various models will behave in some sense the same way.) Strangely, I dont know the answer for a) off-hand. Nice question. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:34\n@Tom. I think you are wrong --- if someone read it and find it not helpful then it is right thing to vote down. (BTW, it was not me) \u2013\u00a0 Anton Petrunin Jan 27 '10 at 19:37\nadd comment\n\nGil, as you said, this is one of those typical FPP problems which seems obvious but is hard to prove. What have you tried already? It'd be helpful to know of some na\u00efve attempts which didn't work.\n\nHere are my thoughts:\n\nClaim: There exists non-random $\\lambda$ such that, with probability one, for large n, all shortest paths between $0$ and $(n,0)$ meet $\\lambda n + o(n)$ edges. (this is a LLN-type theorem so it shouldn't be hard to prove; e.g., via energy-entropy methods, since your passage time distributions are bounded)\n\nThus one can consider the probability space $\\Omega_n$ consisting of all paths between $0$ and $(n,0)$ which meet $\\lambda n + o(n)$ edges. A shortest path is a random variable $X_n$ on this space with a certain probability distribution.\n\nClaim: There exists $\\sigma$ such that $|\\Omega_n| \\approx \\sigma^n$. (should be easy: $\\log|\\Omega_n|$ is probably subadditive)\n\nLet $\\Omega_n'$ be the subspace of paths which meet the middle edge, so that $|\\Omega_n'| \\approx \\sigma^{n/2} + \\sigma^{n/2}$.\n\nSuppose that there exists $p > 0$ such that the shortest path between $0$ and $(n,0)$ meets the middle edge with probability at least $p$. (*)\n\nHere is the part which I'm struggling to quantify. Intuitively, the distribution of $X_n$ should be smeared smoothly over $\\Omega_n$. Certainly the mean is a horizontal line segment, but even paths which veer quite far away aren't unreasonable. However, if (*) holds, with probability at least $p$, $X_n$ concentrates on the much smaller subspace $\\Omega_n'$. This seems wrong.\n\nPerhaps all I've done is to translate one \"obvious\" statement into another. Hopefully this helps a bit. Good luck!\n\nshare|improve this answer\nTom, Interseting suggestion. I dont remember so much what we tried. At the end we managed to go around this lemma. \u2013\u00a0 Gil Kalai Dec 26 '09 at 19:38\nadd comment\n\nGil, thanks for bumping this post. I think I've got a new idea for you, but it's not a proof yet. Let $\\gamma_n$ be a minimizing geodesic between $(-n,0)$ and $(n,0)$, and let $\\gamma^{\\pm}_n$ be a minimizing geodesic betwen $(\\pm n, 0)$ and the origin.\n\nDenote by $d(\\gamma_n)$ the maximal Euclidean distance from the geodesic $\\gamma_n$ to the straight line path between $(-n,0)$ and $(n,0)$, and define $d(\\gamma^\\pm_n)$ similarly for $\\gamma^\\pm_n$. By the definition of the transversal fluctuation exponent $\\xi$, $d(\\gamma^\\pm_n)$ scales like $n^\\xi$ and $d(\\gamma_n)$ scales like $(2n)^\\xi$.\n\nSince $\\tfrac 1 2$ is less than the critical probability for oriented bond percolation in two dimensions $\\approx .633$, a theorem of Licea-Newman-Piza applies and there is a rigorous lower bound $$\\xi \\ge 1/3$$ for your model. (cf. Theorem 4.3 in Howard - Models of First-Passage Percolation)\n\nSuppose that $\\gamma_n = \\gamma^-_n \\cup \\gamma^+_n$ (i.e. the geodesic $\\gamma_n$ meets the origin), so that $$2^\\xi n^\\xi \\approx d(\\gamma_n) = \\max\\{d(\\gamma^-_n), d(\\gamma^+_n)\\} \\approx n^\\xi, $$ which suggests a contradiction since $2^\\xi > 1$ by the lower bound $\\xi \\ge 1/3$.\n\nHere's why it doesn't work. The exponent $\\xi$ is precisely defined as the minimal power of $n$ such that the following hold: $$\\lim_{n\\to\\infty} \\mathbb P\\left[d(\\gamma^\\pm_n) \\le n^\\xi \\right] = 1 \\qquad \\mathrm{and} \\qquad \\lim_{n\\to\\infty} \\mathbb P\\left[d(\\gamma_n) \\le (2n)^\\xi \\right] = 1.$$ Since the $\\approx$ signs above are really inequalities, there is no contradiction above.\n\nshare|improve this answer\nThat's very interesting. I did not know that there is a (provable) lower bound for xsi and this certainly looks very relevant. (In fact stronger than my question...) \u2013\u00a0 Gil Kalai Apr 28 '10 at 6:08\nadd comment\n\nHere is a sketch of a germ of an idea that might work. But don't take it too seriously.\n\nConsider the space $E_k$ of grid paths from $(0,0)$ to $(2k+1,0)$ with nonnegative $x_2$-coordinate and Euclidean length $2k+3$. Associate such paths with functions in the obvious way. Now there are $\\binom{2k+2}{2}$ such paths, $2\\binom{k+1}{2}$ (i.e., proportionally just less than one half) of which contain the middle edge. Now there exists an assignment of edge lengths and corresponding coefficients $\\{a_j\\}_{j=1}^k \\in \\{0,1\\}^k$ s.t. the sum $\\gamma = \\sum_{j=1}^k a_j \\gamma_j$ is a shortest path (provided we require a nonnegative $x_2$-coordinate).\n\nIf the $a_j$ and $\\gamma_j$ are selected uniformly at random, then the probability that the middle edge will be contained in $\\gamma$ is asymptotically $2^{-k/2}$.\n\nshare|improve this answer\nadd comment\n\nTalking about naive attempts, I thought maybe a simple solution along these lines could be found, but I couldn't:\n\nI denote by $p_k(n,2r)$ the probability that a shortest path from the origin to $(n,2r)$ contains the segment $(\\lfloor \\frac{n}{2}\\rfloor,k)$ to $(\\lfloor \\frac{n}{2}\\rfloor +1,k)$. A simple observation is that $p_k(n,2k)=p_k(n,0)$ (consider reflecting the path on the line $y=k$ in the region $x > \\lfloor \\frac{n}{2}\\rfloor$). The idea is to show that $p_k(n,2k)$ is close to $p_0(n,0)$ for small $k$. One can do this maybe by considering a new rectangular grid spanned by $(1,\\frac{2k}{n})$ and $(-\\frac{2k}{n},1)$ (with suitable edge weight distribution) and trying to find the new $p_0'(n,0)$ which should be a good approximation of $p_k(n,2k)$.\n\nNow if one can find a slowly decreasing function $f$ so that $p_k(n,2k)\\approx f(p_0(n,0))$ in the range, say $|k|\\le \\sqrt{n}$ then $$1=\\sum_{k=-\\infty}^{\\infty}p_k(n,0)=\\sum_{k=-\\infty}^{\\infty}p_k(n,2k)\\approx \\int_{-\\sqrt{n}}^{\\sqrt{n}}f(p)dp \\geq c\\sqrt{n}p_0(n,0)$$ for some constant $c$. If $\\lim_{n\\to \\infty}p_0(n,0)>0$ then the above inequality is obviously false for large enough $n$.\n\nETA: I realize this approach works if we were able to prove $$\\liminf_{n\\to \\infty} p_{0}(n,0)=\\liminf_{n\\to \\infty} p_k(n,0)$$ for any fixed $k$.\n\nshare|improve this answer\nadd comment\n\nUPDATE: Fixed typing error in 2nd paragraph (greater than -> less than or equal to)\n\nUPDATE2: Fixed typing errors pointed out by Gil Kalai\n\nUPDATE3: I put off the detailed version from my webpage\n\nUPDATE4: The solution is wrong, as pointed out to me by Nathana\u00ebl Berestycki. It is of course not enough to consider only the path that goes directly from the origin to (n,0). I didn't read the problem properly. Sorry.\n\nI don't know whether this problem is still open, but I think I have found an elementary proof for the original question. It is almost too simple to be true, but I don't see any mistake. Here's the sketch:\n\nAll numbers here are natural numbers between $0$ and $n$, and $n$ is sufficiently large. Fix a (large) $K$. Let $x_l$ be the smallest $x < n/3$, such that for all $1\\le j \\le K$, the length of the path $(x,0)\\rightarrow (x,j) \\rightarrow (x+K,j)$ is less than or equal to the length of the path $(x,0)\\rightarrow (x+K,0)$. The arrow indicates that we take the direct path. For definiteness, set $x_l = \\lfloor n/3 \\rfloor + 1$ if such a number does not exist, but note that it exists with probability going to one as $n\\rightarrow \\infty$. Note further that since we took the smallest $x$ with the above property, conditioned on $x_l$, the lengths of the edges to the right of the vertical line $x=x_l+K$ are still independent, of the same law as before, and independent of the configuration to the left of this vertical line.\n\nNow define $x_r$ by mirroring the above definition at the line $x=n/2$ (the largest $x>2n/3$, such that ....)\n\nThen, the paths $(x_l+K,j)\\rightarrow(x_r-K,j)$ are independent for $0\\le j\\le K$, hence, with probability going to $K/(K+1)$, there exists $1\\le j \\le K$, such that the path $(x_l+K,j)\\rightarrow(x_r-K,j)$ is shorter than $(x_l+K,0)\\rightarrow(x_r-K,0)$.\n\nCombining the above observations, with probability $K/(K+1) + o(1)$, there exist $x_l < n/3$, $x_r>2n/3$ and $1\\le j \\le K$ such that the path $(0,0) \\rightarrow (x_l,0)\\rightarrow (x_l,j)\\rightarrow (x_r,j) \\rightarrow (x_r,0) \\rightarrow (n,0)$ is shorter than the path $(0,0) \\rightarrow (n,0)$. Letting first $n\\rightarrow \\infty$, then $K\\rightarrow\\infty$ finishes the proof.\n\nshare|improve this answer\nDear Pascal, it is a bit too sketchy for me to follow but it looks promising! (Also I supppose the vertical line is x=x_l+K). \u2013\u00a0 Gil Kalai Sep 25 '11 at 13:26\n@Gil: Thanks for having a look at the proof and pointing out the typos. I'd be glad to write down a detailed version, if the problem still interests you. \u2013\u00a0 Pascal Maillard Sep 25 '11 at 17:22\nDear Pascal, yes definitely it is an interesting problem on its own, several people tried to prove it (including us) and it has some applications regarding geodesics in the random metric described by FPP. \u2013\u00a0 Gil Kalai Sep 25 '11 at 19:51\nDear Pascal, the conjecture is from 2002 by Benjamini, Schramm and myself in the paper cited in the question itself .front.math.ucdavis.edu/0203.5262 . It is mentioned at the bottom of page 2 and the top of page 5. Actually on page 5 a slightly stronger version that we needed is mentioned and maybe your method apply there too. \u2013\u00a0 Gil Kalai Sep 26 '11 at 12:10\nOK, I'll have a look at it and see if the method can be applied to the stronger statement. \u2013\u00a0 Pascal Maillard Sep 26 '11 at 12:59\nshow 1 more comment\n\nMidway Problem (a reformulation only)\n\nThis is not an Answer. Start with a 2n x2n grid graph. all edges length one, all even pairs linked.\n\nThe \"both even\" numbered vertices are \"the original graph\". Add (x odd, y even) vertices half the time. Add (x even, y odd) vertices the time. The (odd, odd) vertices are always out. Seems a decent starting point. Point Midway is now (n+1, 0), and in the graph half of the time.\n\nThe two questions may then be:\n\nStrongest question, as n grows: Show with probability approaching one that the set of all shortest paths between (0,0) and (2n,0) almost never contains Midway.\n\nWeaker question, as n grows: Show with probability approaching one that there is a shortest path\nbetween (0,0) and (2n,0) that does not contain Midway.\n\nThey may even have different answers, unless the shortest path has \"uniqueness\" properties. So again, this is not an answer.\n\nBut, the fractions are gone, and the edge lengths are all one!\n\nApologies for the initial typo. Is this variation more accessible?\nThe Far Corner variant of Midway, with an exclusion somewhere, may be easier for purists; but again, I do not know the answer (Nor even close). Propertys of shortest path sets from (0,0) to (2n,2n) may shed light on the axial case. Some small variety of forbidden minor, behaving as Midway, may be worthy of considering. I would try constant sized cycles.\n\nshare|improve this answer\nThat's an interesting variation of the problem that might be easier. When you say add (x odd y even) hald the time do you mean with probability 1/2? I suppose also the (x even y odd) vertices are also added half the time. that's interesting. \u2013\u00a0 Gil Kalai Jan 31 '10 at 16:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/20583/how-to-simplify-frac-sqrt4h-2h\nText:\nTake the tour \u00d7\n\nThe following expression:\n\n\nshould be simplified to:\n\n\n(even if I don't agree that this second is more simple than the first).\n\nThe problem is that I have no idea of the first step to simplify that.. any help?\n\nshare|improve this question\nThe magic words are \"multiply by the conjugate\". For what it is worth, I would actually prefer the former form to the latter. I find it is easier to keep radicals out of denominators, so I would call the former the simplification, not the latter. \u2013\u00a0 Arturo Magidin Feb 5 '11 at 21:25\nI prefer the latter because the removable singularity is removed. But I also am prone to say $\\sin\\frac{\\pi}{4}=\\frac{1}{\\sqrt 2}$ rather than $\\frac{\\sqrt 2}{2}$. @Tom: An important use of such \"simplification\" is that the latter expression indicates how the original expression can be continuously extended to $h=0$. This allows you to determine that the slope of the tangent line to the curve $y=\\sqrt x$ at the point $(4,2)$ is $\\frac{1}{4}$. If you haven't already learned derivatives, these ideas are explained in the following article: en.wikipedia.org/wiki/Derivative \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:59\nadd comment\n\n4 Answers\n\nup vote 13 down vote accepted\n\nIf you multiply both the top and the bottom by $\\sqrt{4+h}+2$, you get $\\frac{(\\sqrt{4+h}-2)(\\sqrt{4+h}+2)}{h(\\sqrt{4+h}+2)}$, which simplifies to $\\frac{h}{h(\\sqrt{4+h}+2)}$. Then, divide both by $h$ (assuming $h\\neq 0$), and you get $\\frac{1}{\\sqrt{4+h}+2}$.\n\nshare|improve this answer\nadd comment\n\nIt is really simple. Let us just do what is most intuitive, multiply numerator and denominator with what you want to have in denominator. You get: $$ \\frac{(\\sqrt{4+h} - 2)(\\sqrt{4+h} + 2)}{h(\\sqrt{4+h}+2)} $$ Then observe the numerator has a difference of squares. Multiply the numerator easily using that and then your left with $$\\frac{h}{h(\\sqrt{4+h}+2)}$$ Just assume $ h \\neq 0 $ and get \"rid\" of it.\n\nshare|improve this answer\nadd comment\n\nHINT $\\rm\\displaystyle\\quad\\quad g^2 = 4+h\\ \\ \\Rightarrow\\ \\ \\frac{g-2}h\\ =\\ \\frac{g-2}{g^2-4}\\ =\\ \\frac{1}{g+2}$\n\nUsually the \"simplification\" is the opposite inference - known as rationalizing the denominator.\n\nshare|improve this answer\nIs that step $\\frac{g-2}{g\u00b2-4}$ correct? If you multiply g+2 up and down, you get $\\frac{g\u00b2-4}{h(g+2)}$, and you can't go on from here.. \u2013\u00a0 Tom Brito Feb 20 '11 at 19:27\n@Tom: $\\rm\\ g^2 = 4 + h\\ \\Rightarrow\\ h = g^2-4\\:.\\:$ That step results from substituting this value for $\\rm\\:h\\:$ into the denominator. \u2013\u00a0 Bill Dubuque Feb 20 '11 at 19:42\nadd comment\n\nSo its not about simplification. You just want to show they are equal. What you do is put an equal sign between them, and cancel everything you can, if you get 1=1 or similar you are done.\n\nshare|improve this answer\nI have downvoted, because I think this answer is misleading. You have to be very careful when trying to prove an identity not to start with the equation you want to prove and arrive at another equation via potentially irreversible steps. It is best to work with just one side of the alleged identity at a time. \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:04\n@Jonas What is an irreversible step ? Do you not have to be equally careful when when working with one side? \u2013\u00a0 user5904 Feb 5 '11 at 21:07\nLet us prove that $-1$ can be simplified to $1$. So I'll put an equal sign between them, $-1=1$. Now if I square both sides, $1=1$. This is true, so $-1=1$. Don't get me wrong, I'm not saying that you are advocating such an illogical step, but starting by assuming (at least in appearance) what you are supposed to prove has the potential to lead to errors. \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:11\nYou have a good point about being careful with one side, but there the rule is that you never even change what the expression is. You can multiply by $1$, add $0$, factor, cancel, etc., but you typically don't do anything that actually changes the value. (Of course, this warning is only for beginners, not those who have enough experience to recognize that there are many valid ways to prove an identity.) \u2013\u00a0 Jonas Meyer Feb 5 '11 at 21:14\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/281206/partition-minimizing-maximum-of-eulers-totient-function-across-terms\nText:\nTake the tour \u00d7\n\nGiven natural numbers $M$ and $N$, I'd like to find a partition of $2^N$ with $M$ or fewer terms, $t_1 + t_2 + ... + t_M$, such that $\\max(\\phi(t_1), \\phi(t_2), ..., \\phi(t_M))$ is minimized, where $\\phi$ is Euler's totient function.\n\nWhat might a smart algorithm for this look like? I can approach this with raw CPU power and metaheuristic search, but maybe the partition can be found analytically? I am mostly interested in $N$ = 8, 16, 32, 64, 128 in case that somehow simplifies the problem.\n\nshare|improve this question\nHere's a suggestion, I don't know how good it is. Precompute a list of \"sparsely totient numbers,\" see oeis.org/A036913. Given $N$, find the largest sparsely totient number $x$ not exceeding $2^N$, let $t_M=x$, then apply recursively to $2^N-x$ to get $t_{M-1},\\dots,t_2$, then let $t_1$ be whatever's left over. Maybe instead of largest s.t.n not exceeding $2^N$, use largest s.t.n not exceeding $2^N/M$. \u2013\u00a0 Gerry Myerson Jan 18 at 4:46\nIt maybe a great idea. I read that the ith primorial multiplied by the ith prime is sparsely totient, and used that to quickly build a list (not all sparse totients, but for rough minimization may be OK). I tried building the partition for $2^{64}$ in the style of Euclid's algorithm for GCD -- I took the biggest number in the list < $2^{64}$ and took the remainder of dividing by it, then took the biggest sparse totient in the list under the remainder and took the remainder of dividing by it, etc. etc. Turns out a linear combination of those sparse totients exactly partitioned it. Coincidence? \u2013\u00a0 Joseph Garvin Jan 22 at 15:36\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/73142/estimating-lattice-sums-of-concave-functions/73154\nText:\nTake the tour \u00d7\n\nSuppose that $f$ is a twice-differentiable concave function from $R^2$ to $R$ that's negative outside of some bounded set (e.g. $f(x,y)=1-x^2-y^2$) and let $F=$max$(f,0)$. Let $S_n$ be the Riemann sum for the integral of $F$ over $R^2$ obtained by summing the values of $F$ at all points in the lattice $(Z/n)^2$ and dividing by $n^2$. What sort of bounds can be given for the difference between $S_n$ and the integral of $F$ over $R^2$? Is it $O(1/n)$ or $O(1/n^2)$ or what? This is a more focussed version of the question error estimates for multi-dimensional Riemann sums .\n\nshare|improve this question\nOy! Mr. Propp, are you going to accept or comment at mathoverflow.net/questions/71432/\u2026? (Also, I answered your comment at (mathoverflow.net/questions/71344/\u2026) \u2013\u00a0 Ricky Demer Aug 18 '11 at 19:04\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nIt looks like the error is in $O(1/n^2)$, with a precise and optimal bound $C/n^2$ if you have a fixed bound on (1) the second derivative of the function (2) the radius of the region where it is non-negative.\n\nAs the question is stated there are two sources for the error term:\n\n  \u2022 the error in each square, centered at a point of the lattice, on which the function is strictly positive. This terms is controled by the second derivative of the function (it clearly vanishes for a linear function) at it is bounded by $O(1/n^4)$, since the number of squares is $O(n^2)$ the estimate on this whole term is $O(1/n^2)$,\n\n  \u2022 the error term in the boundary squares, those on which the function takes both a $>0$ and a zero value. On those squares the error is $O(1/n^3)$ and the number or such boundary squares is $O(n)$ so we get again a bound $O(1/n^2)$.\n\n(Note that a complete argument has to be more precise because the function $f$ could have zero derivative at the points where it vanishes, then the number of boundary squares is $O(n^2)$ but I think the result does not change).\n\nTo check that this estimate is optimal you can think of a function which is invariant under a rotation of angle $\\pi/2$ and equal to say $N-x$ on $y>0, -y+u\\leq x\\leq y-u$ for some small $u>0$. Then the first error term can be made smaller than the second, while the second \"boundary\" error term is indeed of the order of $1/n^2$ (the boundary errors all sum up).\n\nshare|improve this answer\nThe errors in each cell tend to compensate. If instead of having a compactly supported function with limited regularity, we have a functin $F$ in the Schwartz class, then the total error is $O(n^{-k})$ for every $k>0$. This is a consequence of the Poisson summation formula and the fact that the Fourier transform of $F$ is of Schwartz class too. Therefore the question is really about the effect of the limited regularity of $F$, and whether the concavity helps. \u2013\u00a0 Denis Serre Aug 18 '11 at 16:14\nI agree but as stated the main error term comes from the boundary squares. In some cases at least no compensation occurs, as in the example I tried to described, where all centers of boundary squares are at points where $f=0$ so that all those boundary terms are positive. \u2013\u00a0 Jean-Marc Schlenker Aug 18 '11 at 17:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122818/nth-root-of-a-matrix-as-an-analytic-function\nText:\nTake the tour \u00d7\n\nLet $A$ be a $k \\times k$ invertible matrix over complex numbers.\n\nIf it possible to write its nth root as an analytic function (i.e. power series in $A$)?\n\nEDIT: Complex coefficients can be functions of $A$.\n\n\nIf a matrix $A$ has only one eigenvalue $\\lambda$, then it is simple. We take\n\n$$B = \\exp\\left[\\tfrac{1}{n} \\log (A ) \\right]$$\n\nwhere we have $B^n = A$. Using Jordan decomposition, we can simplify the logarithm to a polynomial in that matrix (as $(A - \\lambda \\mathbb{I})$ is nilpotent)\n\n$$\\log(A) = \\log(\\lambda) - \\sum_{i=1}^{k} \\frac{\\left(- \\tfrac{A}{\\lambda} + \\mathbb{I}_k \\right)^{i}}{i}.$$\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nIf I am reading this correctly, you are fine with a power series whose (scalar) coefficients depend on the matrix $A$. In this case, it suffices to take a polynomial $p$ that interpolates $\\sqrt[n]{x}$, such that for each eigenvalue $\\lambda$ with multiplicity $k_\\lambda$, the first $k_\\lambda-1$ derivatives of $p$ coincide with those of $\\sqrt[n]{x}$ (Hermite interpolant). A degree-$k$ polynomial will always do the job.\n\nshare|improve this answer\nYes, I'm fine with coefficients depending on the matrix. I don't know why I overlooked this solution. \u2013\u00a0 Piotr Migdal Feb 24 at 20:19\nHowever, it is not as simple - I cannot assume that the matrix is diagonalizable; so any function which just maps eigenvalues to their roots won't work. Take as a counterexample $A = [[1, 1], [0, 1]]$ and $f(z)=z$ (sure, another polynomial works for this $A$). \u2013\u00a0 Piotr Migdal Feb 24 at 20:30\nThe multiplicity of the eigenvalue $1$ is $2$, so you need a polynomial that matches $g(z)$ and $g'(z)$ in $z=1$, where $g(x)=\\sqrt[n]{x}$. For some more detail on this approach, you can check Higham's Functions of matrices, SIAM Press 2008. \u2013\u00a0 Federico Poloni Feb 24 at 21:08\nSorry - I meant to add Chapter 1, but I pressed \"enter\" too quickly. \u2013\u00a0 Federico Poloni Feb 24 at 21:11\n@Federico So, you have my thanks in arxiv.org/abs/1305.1506. \u2013\u00a0 Piotr Migdal May 8 at 8:54\nadd comment\n\nLet $A$ be a $k\\times k$ invertible matrix, i.e. in $Gl(k)$. Assume that the segment $[I,A]$ lies in $Gl(k)$. Let us define $$ \\text{Log}A=\\int_{[1,A]} \\frac{d\\xi}{\\xi}=\\int_0^1(I-tI+tA)^{-1}(A-I)dt. $$ It makes sense since $A$ commutes with the denominator inside the integral. The assumption is satisfied in particular whenever $A$ is symmetric invertible with a nonnegative real part. Analytic continuation arguments entail $$ \\exp(\\text{Log}A)=A\\quad \\bigl(\\exp(\\frac{1}{n}\\text{Log}A)\\bigr)^n=A. $$ Looking at the Jordan canonical form of $A$, it is not difficult to see that the only thing to be avoided for the above method to work is that eigenvalues should not be negative real numbers. Let $z=a+ib$ be an eigenvalue not in $\\mathbb R_-$ in a Jordan block $J_N$ of size $N$, with 1 above the diagonal. Considering the segment $[I_N,J_N]$, we find on the diagonal $$ (1-t)+tz\\notin \\mathbb R_-\\text{ since $z\\notin \\mathbb R_-$}, $$ and above the diagonal $ (1-t)0+t=t. $ The logarithm formula above works.\n\nshare|improve this answer\nadd comment\n\nIf all eigenvalues of $A$ are in the right half plane, there is $\\alpha > 0$ such that the circle $|z - \\alpha| < \\alpha$ contains all the eigenvalues, and the principal branch of $f(z) = z^{1/n}$ is analytic in that circle. We then have a convergent binomial series $$ A^{1/n} = \\alpha^{1/n} \\sum_{k=0}^\\infty {{1/n} \\choose k} (\\alpha^{-1} A - I)^k $$\n\nshare|improve this answer\nIt was my initial thought, but in my case I cannot make such an assumption. \u2013\u00a0 Piotr Migdal Feb 25 at 0:40\nadd comment\n\nIt easy to apply a series to a diagonalizable matrix, and diagonalizable matrices are dense. This should answer your question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/125870/counting-k-cliques-not-also-k1-on-random-graphs\nText:\nTake the tour \u00d7\n\nconsider the set of graphs with $n$ vertices and exactly half of all $\\binom n 2$ possible edges.\n\nlooking for a formula that counts the number of these graphs that have a $k$-clique but not a $(k+1)$-clique.\n\nlooked at some of the Erdos-Renyi random graph theory and related formulas but did not see this case covered so far. an estimate may be ok. also if this is used in a paper somewhere, that would be useful to know.\n\nedit as Erdos-Renyi theory & a comment points out the critical point for detection of a $k$-clique is at $k=\\log(n)$ where the probability goes from $P<0.5$ to $P>0.5$. it would be very interesting if there was a formula that could be derived independent of these regions (once called \"subcritical, critical, supercritical\"), but am seeking the answer for $k \\approx \\log(n)$ in particular.\n\nbackground/motivation: question inspired by similar constructions in theoretical computer science circuit theory proofs/theorems.\n\nshare|improve this question\nAsymptotically, for fixed $k\\ge 2$, almost all $K_{k+1}$-free graphs have $K_k$. But except for $k=2$, which is obvious, I'm not even sure that has been proved. \u2013\u00a0 Brendan McKay Mar 29 at 3:36\nParallel to Brendan's comment, if $k$ is larger than order $\\log(n)$, the probability of $\\omega(G)$ being $k+1$ is vanishingly small compared to the probability of $\\omega(G)$ being $k$. I recommend looking at Chapter 7 of Random Graphs by Janson, Luczak and Rucinski. Note that since you have half the edges, looking at the size of a maximum stable set is equivalent to looking at the size of a maximum clique. You should also look at Section 1.4 if you are unfamiliar with the asymptotic equivalence of $G(n,p)$ and $G(n,m)$. \u2013\u00a0 Andrew D. King Mar 29 at 16:31\n@andrew thanks. yes from Erdos-Renyi theory, $\\log(n)$ is the so-called \"critical point\" where existence of k-cliques switches from low (P<0.5) to high (P>0.5) probability, and am looking for the answer in exactly that region where P=0.5. should have mentioned that in the question. will edit \u2013\u00a0 vzn Mar 29 at 16:58\nDo you really expect someone can tell you a formula for the number? If you want asymptotics you should ask for asymptotics. \u2013\u00a0 Douglas Zare Mar 30 at 1:31\n@douglas are you saying a closed form formula is unlikely to exist, or hard to find, etc? \u2013\u00a0 vzn Apr 12 at 18:06\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53595.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nApplied Problems in Maxima and Minima\n\nDate: 08/30/97 at 23:40:40\nFrom: Anonymous\nSubject: Applied problems in maxima and minima\n\ntangent together with the coordinate axes determine a triangle of \nminimum area.\n\nAnswer: (2 (3)^(1/2) / 3, 8 / 3)\n\nPlease show me how to get the answer.\n\nDate: 08/31/97 at 12:38:45\nFrom: Doctor Anthony\nSubject: Re: Applied problems in maxima and minima\n\nWe can simplify the working a little by considering the curve y = x^2, \nand consider the triangle of minimum area formed by a tangent to the \ncurve, the y axis, and the line y = 4.  This allows us to use very \nsimple parametric coordinates (t,t^2) to represent the curve.\n\n  dy/dx = (dy/dt)/(dx/dt) = 2t/1  =  2t\n\nThe equation of the tangent is  \n\n                    y-t^2 = 2t(x-t)\n\nThis meets the y axis where x = 0, so \n\n                    y-t^2 = -2t^2\n\n                        y = -t^2\n\nas expected this is a distance t^2 below the x axis. The vertical side \nof the required triangle will therefore be of length 4+t^2.\n\nThe tangent meets y = 4 where  4-t^2 = 2tx-2t^2\n                             4 + t^2 = 2tx\n\n                                   x = (4+t^2)/2t\n\nArea of triangle  = (1/2)(4+t^2)(4+t^2)/2t\n\n                A = (1/4t)(16 + 8t^2 + t^4)\n\n                  = (1/4)(16/t + 8t + t^3)\n\n            dA/dt = (1/4)(-16/t^2 + 8 + 3t^2)  = 0 for max or min.\n\nSo       3t^2 + 8 = 16/t^2\n\n 3t^4 + 8t^2 - 16 = 0\n\n  (3t^2-4)(t^2+4) = 0    and so  t^2 = 4/3  \n\n                                   t = 2/sqrt(3)\n\nThus the x coordinate is 2/sqrt(3).  This is the same x value as \nfor the equation y = 4 - x^2, and therefore we can substitute \nx = 2/sqrt(3) in this equation to find the y coordinate.\n\n  y = 4 - 4/3 = 8/3\n\nCoordinates of required point   [2/sqrt(3), 8/3]\n-Doctor Anthony,  The Math Forum\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38424/how-do-you-do-an-integral-involving-the-derivative-of-a-delta-function/38450\nText:\nTake the tour \u00d7\n\nI got an integral in solving Schrodinger equation with delta function potential. It looks like\n\n$$\\int \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x}$$\n\nI'm trying to solve this by splitting it into two integrals\n\n$$\\int_{-\\infty}^{x_0 - \\epsilon} \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x} + \\int_{x_0 + \\epsilon}^{\\infty} \\frac{y(x)}{x} \\frac{\\mathrm{d}\\delta(x-x_0)}{\\mathrm{d}x}$$\n\nand then do the limit $\\epsilon\\to 0$. Could you tell me how to solve this integral please? I used Mathematica, it gave out a weird result.\n\nshare|improve this question\nAre you trying to evaluate $\\int \\left(\\frac{y(x)}{x}\\frac{d\\delta(x-x_{0})}{dx}\\right)dx$ for an arbitrary $y(x)$? I don't understand your statement about the limits, either, are you evaluating two separate integrals with limits $\\int_{-\\infty}^{x_{0}-\\epsilon}$ and $\\int_{x_{0}+\\epsilon}^{\\infty}$? \u2013\u00a0 Jerry Schirmer Sep 26 '12 at 23:16\nThanks Jerry. Yes it is. Basically it is a part of the radial part of my Schrodinger equation and y[x] is radial component and delta function is my potential function. There is a derivative of the potential function. I am trying to solve the equation for the delta function barrier about xo.Finally I can take the limit of e->0. \u2013\u00a0 nagendra Sep 26 '12 at 23:21\nI wonder if perhaps this would be better off at Mathematics? (I'll migrate it if that is the case) \u2013\u00a0 David Z Sep 26 '12 at 23:30\n@DavidZaslavsky: it is primarily a mathematics question, but of the type that physicists will care about more than mathematicians. I'll answer this soon. \u2013\u00a0 Jerry Schirmer Sep 26 '12 at 23:41\n@Jerry yes, but I still think those sorts of questions should be sent to math.SE. \u2013\u00a0 David Z Sep 27 '12 at 3:29\nadd comment\n\n4 Answers\n\nup vote 9 down vote accepted\n\nThe $\\delta$ function is not continuous, so it's a priori not differentiable. In fact, it's not even well-defined as an ordinary real-valued function, but can be made so in terms of distributions - linear maps on a space of test functions given by $f\\mapsto\\int\\delta f=f(a)$.\n\nIt's possible to sensibly define derivatives of distributions by looking at representations as limits of functions:\n\nIf $\\delta_i$ is a family of functions so that $\\lim_{i\\rightarrow\\infty}\\int\\delta_i(x) f(x)\\mathrm dx=f(a)$ for any test function $f$, then it can be considered a representation of the Dirac delta. Now, if we take the family of derivatives $\\frac{\\mathrm d}{\\mathrm dx}\\delta_i$ we arrive at $$ \\int\\left[\\frac{\\mathrm d}{\\mathrm dx}\\delta_i(x)\\right]f(x)\\mathrm dx=-\\int\\delta_i(x)\\left[\\frac{\\mathrm d}{\\mathrm dx}f(x)\\right]\\mathrm dx $$ through integration by parts and using the fact that $f$ has by definition compact support (which makes the boundary term vanish).\n\nAs the derivative is linear as well, this defines another linear map $f\\mapsto-\\int\\delta f'$ on the space of test functions, which we call the derivative of our distribution.\n\nSymbolically, $$ \\left[\\frac{\\mathrm d}{\\mathrm dx}\\delta(x-a)\\right]f(x)=-\\delta(x-a)f'(x) $$ which you can just plug in into your formula above without any need for actual computation as it holds true by definition.\n\nshare|improve this answer\nDear Christoph. Just to clarify that the derivatives is only for the DiracDelta function. What about in that case? \u2013\u00a0 nagendra Sep 27 '12 at 13:03\n@Nagendra: added some parens to clarify - I believe this is the case you're interested in \u2013\u00a0 Christoph Sep 27 '12 at 13:48\nadd comment\n\nSo, the properties of the derivative of the delta function can be shown relatively quickly though the following ansatz: Consider a function $\\delta(x)$ such that $\\delta(x) = \\frac{1}{a^{2}}(x+a)$ if $-a<x<0$ and $\\delta(x) = \\frac{1}{a^{2}}(a-x)$ if $0<x<a$, and $\\delta(x) = 0$ elsewhere. It is easy to see that $\\delta(x)$ has area 1 irrespective of the value of $a$, so we can consider $\\delta(x)$ to be the dirac delta function in the limit $a\\rightarrow0$.\n\nNow, consider the derivative of our putative delta function. It will be $\\frac{1}{a^{2}}$ for $-a<x<0$ and $-\\frac{1}{a^{2}}$ for $0<x<a$. Let's integrate a function $f(x)$ against $\\delta^{\\prime}(x)$:\n\n$\\begin{align} \\int \\delta^{\\prime}(x)f(x)dx &= \\int_{-a}^{0}\\frac{f(x)}{a^{2}}dx - \\int_{0}^{a}\\frac{f(x)}{a^{2}}dx\\\\ &=\\int_{0}^{a}\\frac{f(-x)}{a^{2}}dx-\\int_{0}^{a}\\frac{f(x)}{a^{2}}dx\\\\ \\end{align}$\n\nExtracting the $a^{2}$ out of the integral, and taking the limit $a\\rightarrow0$, we find, after applying L'Hopital's rule once, and then using the definition of the derivative:\n\n$\\int \\delta^{\\prime}(x)f(x) = -f'(0)$\n\nshare|improve this answer\nThanks Jerry. Hope it would work for the limiting point xo. Let me check it with my problem. \u2013\u00a0 nagendra Sep 27 '12 at 2:04\nadd comment\n\nThe Dirac delta function is often defined as the following distribution:\n\n$$\\int_a^b \\delta(x - x_0) F(x)\\mathrm{d}x = \\begin{cases}F(x_0), & a < x_0 < b \\\\ 0, & \\text{otherwise}\\end{cases}$$\n\nwhere $F$ is a suitable test function. Its derivative is then defined as\n\n$$\\int_a^b \\delta'(x - x_0) F(x)\\mathrm{d}x = -\\int_a^b \\delta(x - x_0) F'(x)\\mathrm{d}x$$\n\nwhich is also the result one would get from naively applying integration by parts. You can use this result directly to calculate your integral by setting $F(x) = \\frac{y(x)}{x}$ - no need to split the integral or take any limits.\n\nshare|improve this answer\nadd comment\n\nAs noted above, if $x_0$ a regular point of the integrand one calculates the value of the desired integral simply by substituting this point in the derivative with appropriate choice of sign. The interesting part is when the singularities of the integrand and the delta derivative coincide, i.e., where $x_0=0$. In order to compute the integral in this case we use the fact that $$\\delta_0'=\\lim_{\\epsilon \\to 0^+}\\frac{\\delta_\\epsilon-\\delta_{-\\epsilon}}{2 \\epsilon},$$ the limit being in the distributional sense. A back-of-an-envelope calculation suggests that this is only defined if $y(0)=0$ and that the integral is then $\\dfrac{y''(0)}2$. (Note that since the integrand is not a smooth function, the integral is not a priori defined).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/37877/finding-psix-t-for-a-free-particle-starting-from-a-gaussian-wave-profile?answertab=active\nText:\nTake the tour \u00d7\n\nConsider a free-particle with a Gaussian wavefunction,\n\n$$\\psi(x)~=~\\left(\\frac{a}{\\pi}\\right)^{1/4}e^{-\\frac12a x^2},$$ find $\\psi(x,t)$.\n\nThe wavefunction is already normalized, so the next thing to find is coefficient expansion function ($\\theta(k)$), where:\n\n$$\\theta(k)=\\int_{-\\infty}^{\\infty} \\psi(x)e^{-ikx} \\,dx.$$ But this equation seems to be impossible to solve without error function (as maple 16 tells me).\n\nIs there any trick to solve this?\n\nshare|improve this question\nI am a bit confused, why are you trying to find $\\psi (k)$ ? Or as you write it, $\\theta (k)$ ? \u2013\u00a0 DJBunk Sep 20 '12 at 23:06\nCan you put what you ran through maple 16? \u2013\u00a0 Magpie Apr 8 at 1:38\nadd comment\n\n1 Answer\n\nYour question seems rather confused,\n\n  \u2022 First you ask for the time evolution of the wavefunction. For this you will need to use the Schr\u00f6dinger equation $i \\partial \\psi/\\partial t= \\hat H \\psi $ and thus will need to know the Hamiltonian ($\\hat H$).\n  \u2022 Second you seem to want to work out the Fourier transform of the wavefunction. This will not give you the wavefunction as a function of time but will give you the wavefunction in momentum space. The integral you want to calculate is the Fourier transform of a Gaussian which is itself a Gaussian: $$\\int_{-\\infty}^{\\infty} e^{-ax^2/2}e^{-i k x} \\, dx \\\\ = \\int_{-\\infty}^{\\infty} e^{-ax^2/2}\\left(\\cos{kx} - i \\sin{kx} \\right) \\, dx .$$ The second term in the above integral is odd so will give zero. The first term is a known integral and gives $$=\\sqrt{\\frac{2\\pi}{a}} e^{-k^2/2 a} , $$ a Gaussian as promised with width inversey proportional to the original.\n\nI am pretty certain Maple should also be able to calculate the integral for you as it is written in my fist line (Mathematica can), so I imagine you are just not entering it correctly.\n\nEdit: Apologies for the first comment above. I had not seen that you had written this was for a free particle, so indeed you know the Hamiltonian, the potential is $V(x,t)=0$, and so from Schr\u00f6dinger's equation we know the time evolution of the energy Eigenstates is $\\psi(x,t)=e^{-i \\omega t}\\psi(x)$. For the free particle we have $\\omega=k^2/2m$ and so you know the time evolution of the Fourier transform.\n\nSo taking the Fourier transform given above, applying the time evolution, and transforming back to position space we have $$\\psi(x,t)=\\int_{-\\infty}^{\\infty} e^{-k^2/2 a}e^{-i\\omega t}e^{ikx} \\, dk \\\\ =\\int_{-\\infty}^{\\infty} e^{-\\frac{k^2}{2 a}(1+iat/m)}e^{ikx}\\, dk \\\\ \\sim e^{\\frac12 \\frac{x^2}{1/a+imt}}$$ as #Ron pointed out in his comment. This shows how the wavepacket spreads out with time.\n\nshare|improve this answer\nThe fourier trasnform evolves by simple phases, and a reverse fourier transform gives the time evolution, which is a spreading Gaussian, so that the a gets replaced everywhere by ${1\\over {(1/a)+it}}$ \u2013\u00a0 Ron Maimon Sep 21 '12 at 6:48\nOh yeah, hadn't seen the part saying this was for a free particle (doh!). Have added an edit to the answer to complete it. Thanks for pointing that out. \u2013\u00a0 Mistake Ink Sep 21 '12 at 13:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/68908/is-the-f-t-of-operatornamespan-mathscr-s-mathbb-r2-otimes-mathscr-dd/69105\nText:\nTake the tour \u00d7\n\nLet $K$ be the real vector space generated by elements $f$ in $\\mathscr S(\\mathbb R^2,\\mathbb R)\\otimes\\mathscr D(D, \\mathbb R)$, where $D$ is any bounded subset of $\\mathbb R^2$. Let $\\hat K$ be the vector space generated by the Fourier transform of each $f\\in K$, i.e. $\\hat K = \\{\\hat f\\ |\\ f\\in K\\}$. Is $\\hat K+i\\hat K$ dense in $L^2(\\mathbb R^4)$?\n\nshare|improve this question\nCould you please clarify the notation? One of the spaces is Schwartz space, I presume; what's the other one? \u2013\u00a0 Captain Oates Jun 27 '11 at 9:18\nI think the second factor is test functions with support in D. I am not sure if D is supposed to be fixed or arbitrary. Either way, this question has the flavor of homework. \u2013\u00a0 Michael Renardy Jun 27 '11 at 10:01\nI guess $\\mathscr D$ are smooth functions with compact support. If $L^2(\\RR^4)$ is the complex space i guess this is not true, because the Furiertransform of some real function has some symmetry, and otherwise the Fourier transform does not make sense to me. \u2013\u00a0 Marcel Bischoff Jun 27 '11 at 20:11\nProbably this question is not approriate for here. But if I know understand your notation correctly, if you take a function that has support outside of D then the Fourier transform is orthogonal to your space, or not? So it would not be dense. The situation is different if you restrict the fourier transform to something lying in some \"cone\". Then you end up to some situation similar to the Reeh-Schlieder Theorem in Quantum Field Theory. I recommened you to look into the books of Reed and Simon. \u2013\u00a0 Marcel Bischoff Jun 28 '11 at 10:56\n\"Probably this question is not appropriate for here\"... actually I don't see why. At most, one may ask the OP to provide some motivation and details, as explained in the section \"how to ask\". \u2013\u00a0 Pietro Majer Jul 27 '11 at 11:30\nshow 1 more comment\n\n1 Answer\n\nI'm sorry if this is not the appropriate place to ask such questions. I'll be more careful next time. By the way my question is strongly related to an actual problem in QFT (actually QFT on QST). I'm not sure about M. Bischoff conclusion on orthogonality pointed out in one of the comments to the question.\n\nThere is a result from Araki that state that the real Hilbert subspace of the one-particle Hilbert space $K(O)=\\{\\hat f\\big\\vert_{\\Omega_m^+}\\ |\\ f\\in\\mathscr D(O,\\mathbb R)\\}$, where $\\Omega_m^+$ is the hyperboloid of mass $m$ in the future light-cone and $O\\subset\\mathbb R^4$ is a non-empty simply connected bounded open subset of $\\mathbb R^4$, is standard, i.e. $\\overline{K(O)+iK(O)}$ is dense and $K\\cap iK=\\{0\\}$. The vector space $\\hat K$ I defined in the question ought to contain such a vector space $K(O)$ associated with a region $O\\subset\\mathbb R^2\\times D$, where $D$ satisfies some suitable regularity condition (e.g. regular boudary, simply connectedness,...) and therefore $K(O)\\subset \\hat K$, that would imply $\\hat K$ standard, according to the result from Araki.\n\nshare|improve this answer\nBut the important fact is the restriction to the mass shell, because then the \"two-point function\" (which is essentially the scalar product written is tempered distribution) is an analytic function in some tube region, because the Fourier transform has support in some cone. Then using the Edge of the Wedge theorem one can show that a vector orthogonal to your set is already the zero vector. This can be found eg. in Streater-Wightmann etc under Reeh-Schlieder theorem (the original article is german). If you do not restrict I think my argument says it will be not dense anymore. \u2013\u00a0 Marcel Bischoff Jul 4 '11 at 19:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/269953/show-that-m-t-int-0-t-expb-2s2-db-1s-is-not-a-continuous-square\nText:\nTake the tour \u00d7\n\nConsider the following $\\mathcal F_t$- (continouous) local martingale $$M_t = \\int_0 ^t \\exp{((B_2(s)^2)} dB_1(s)$$ where $\\left(B_t\\right)_{t\\geq0} =\\left(B_1(t),B_2(t)\\right)_{t\\geq0}$ is $\\mathcal F_t$-Brownian motion in $\\mathbb R^2$, null at $t=0$.\n\nHow to show that $\\left(M_t \\right)_{t\\geq 0}\\notin \\mathcal{M }^2_c=\\{\\mathcal {F}_t - $real continuous martingale square integrable, with $ M_0 =0 \\}$ ?\n\nshare|improve this question\nDo you intend to show that it is not continuous or that it is not square-integrable? Or that it is not a martingale? \u2013\u00a0 GEdgar Jan 3 at 22:08\nBy definition $M$ is a (continuous) local martingale (i.e, $M \\in \\mathcal M_{c,loc}$) as you can see, so the problem is primordially the square-integrability because we know it's continous. Nonetheless, there is also an acessorie problem concerning localization. \u2013\u00a0 Paul Jan 3 at 22:20\nThaks for your remark GEdgar. I edited the text to make it clear. I expect I was successefull. \u2013\u00a0 Paul Jan 3 at 22:24\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nLet $\\mathcal G_t=\\sigma(B_2(s),s\\leqslant t)$. Since $(B_1(s))_{s\\leqslant t}$ is independent of $\\mathcal G_t$ and $(B_2(s))_{s\\leqslant t}$ is measurable with respect to $\\mathcal G_t$, It\u00f4's isometry indicates that $$ \\mathbb E(M_t^2\\mid\\mathcal G_t)=\\int_0^t\\mathrm e^{2B_2(s)^2}\\,\\mathrm ds. $$ Everything is nonnegative, hence $$ \\mathbb E(M_t^2)=\\int_0^t\\mathbb E(\\mathrm e^{2B_2(s)^2})\\,\\mathrm ds. $$ Since $B(s)$ is centered normal with variance $s$, $\\mathbb E(\\mathrm e^{2B_2(s)^2})$ is infinite for every $s\\geqslant\\frac14$. Thus, $\\mathbb E(M_t^2)$ is infinite for every $t\\gt\\frac14$ and in particular, $(M_t)_{t\\geqslant0}$ is not a square integrable martingale.\n\n(Note that $\\mathbb E(M_t^2)=\\frac12(1-\\sqrt{1-4t})$ for every $t\\leqslant\\frac14$, hence $(M_t)_{t\\leqslant1/4}$ is a square integrable martingale.)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/74055/the-cantor-function-is-surjective-and-continuous\nText:\nTake the tour \u00d7\n\nHow can I prove that the Cantor function is surjective and continuous?\n\nThe part, I think that the cantor function is monotonic and surjective, if I prove this, it is easy to prove that this implies continuity. The way to prove that is surjective, it's only via an algorithm, I don't know if this can be proved in a different way, more elegant. And the monotonicity I have no idea, I think that it's also via an algorithm.\n\n\nshare|improve this question\nSee Problems in real and complex analysis By Bernard R. Gelbaum, pages 17 and 155. \u2013\u00a0 Martin Sleziak Oct 19 '11 at 18:20\nComment (I don't have enough points to post a comment, sorry): A delta-epsilon proof is not too hard. \u2013\u00a0 gary Oct 19 '11 at 20:49\nadd comment\n\n1 Answer\n\nLet $f$ be the Cantor function. Let $y\\in[0,1]$. Let $0.d_1d_2d_3\\ldots$ be the binary expansion of $y$. Let $x$ be the number whose ternary expansion is $0.(2d_1)(2d_2)(2d_3)\\ldots\\ {}$. Then $f(x)=y$. For numbers with non-unique binary expansions, one gets two ternary expansions that do not represent the same number; call them $x_1 < x_2$. Then for all $x\\in [x_1,x_2]$, $f(x)=y$.\n\nAs for continuity, if a weakly monotone function has a discontinuity, it is a jump, so then the function cannot be surjective.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/143046/counting-number-of-linear-transformations\nText:\nTake the tour \u00d7\n\nLet $v_{1} = (1, 0)$, $v_{2} = (1, -1)$ and $v_{3} = (0, 1)$. How many linear transformations $T :\\mathbb {R^2}\\rightarrow \\mathbb {R^2} $ are there such that $T(v_{1} ) = v_{2}$, $T(v_{2} ) = v_{3}$, $T(v_{3} ) = v_{1}$. I am finding difficulty in tackling to this problem. I tried to identify corresponding linear transformation. But didn't come to any conclusion.It should be either 0, 1, 3 or $3!$\n\nshare|improve this question\nCan you find even one such transformation? \u2013\u00a0 Chris Eagle May 9 '12 at 12:46\nThat's what i am asking. i think answer should be zero. But how to show? \u2013\u00a0 srijan May 9 '12 at 12:48\nRemember that once you have defined a linear map on a basis, you can work out what its value has to be on any other vector. \u2013\u00a0 Matt Pressland May 9 '12 at 12:49\nIf you have some ideas about the problem (like that the answer is zero), then put them in your question. \u2013\u00a0 Chris Eagle May 9 '12 at 12:49\ni have added sir..it should be either 0 , 1 , 3 or 3! \u2013\u00a0 srijan May 9 '12 at 12:51\nshow 3 more comments\n\n1 Answer\n\nup vote 3 down vote accepted\n\n$v_2 = v_1-v_3$, so you'd need: $$ v_3 = T(v_2) = T(v_1-v_3)=T(v_1)-T(v_3) = v_2-v_1$$ which is not true.\n\nshare|improve this answer\nI think a hint would probably have been more helpful than a complete answer. (I'm just bothering to say this because I upvoted your answer, and then realised that I don't like the fact that complete answers to easy questions get disproportionately many upvotes, so upvoting it perhaps didn't make sense.) \u2013\u00a0 Tara B May 9 '12 at 13:12\n@Tara B: Unless the OP merely copies the above answer, there is work for the OP to do in order to see that the above does answer the question. \u2013\u00a0 Andr\u00e9 Nicolas May 9 '12 at 13:31\n@TaraB Actually, I agree with you, I probably should have just given a hint. Sometimes, my eagerness to answer overrides the filter that asks, \"What kind of answer is best for this user?\" I'll leave it as is, since I'll guess the OP has already read it, but will keep trying to improve my instincts for future answers. \u2013\u00a0 Thomas Andrews May 9 '12 at 13:39\n@Andr\u00e9Nicolas: That's true, but I think there's still more benefit to be gained from working out the rest from a hint than from figuring out why an answer works. \u2013\u00a0 Tara B May 9 '12 at 13:46\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/116608/clifford-algebra-is-graded-separable\nText:\nTake the 2-minute tour \u00d7\n\nLet $D$ be an algebra of odd differential operators on a free module $V$, this algebra is isomorphic to the Clifford algebra $Cl(V^* \\oplus V)$. Let $m$ denote multiplication map $$m : D\\otimes D \\to D.$$ I need an explicit formula for a bimodule splitting of this map or equivalently an element $z \\in D\\otimes D$ s.t. $az=za$ for any $a \\in D$ and $m(z)=1$.\n\nIt is possible to use isomorphism of algebras $Cl(V^* \\oplus V) \\cong End(\\wedge V)$ and for $End(\\wedge V)$ such splitting is given (up to sign) by the same formula as for matrix algebra. So, I know that such splitting exists and I want a nice formula in term of differential operators (or standard generators of Clifford algebra).\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/144190/factoring-a-number-pa-qb-knowing-its-totient/144197\nText:\nTake the 2-minute tour \u00d7\n\nWe are given: $n=p^aq^b$ and $\\phi(n)$, where $p,q$ are prime numbers. I have to calculate the $a,b,p,q$, possibly using computer for some calculations, but the method is supposed to be symbolically valid and proper. I know that $\\phi(n)=p^{a-1}q^{b-1}(p-1)(q-1)$, but I dont know what can I deduct from this.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nWithout loss of generality we can assume that $p<q$. I would first compute the greatest common divisor of $n$ and $\\phi(n)$, $m=\\gcd(n,\\phi(n))$. There are two possibilities.\n\n1) $m=p^{a-1}q^{b-1}$. This happens, if $p$ is not a factor of $q-1$. In this case we can calculate $$ \\frac{n}{m}=pq,\\qquad\\text{and}\\qquad \\frac{\\phi(n)}{m}=(p-1)(q-1)=pq-(p+q)+1. $$ In this case we know $r=p+q$ and $s=pq$, and can solve the primes $p$ and $q$ as the roots of the quadratic equation $$ 0=(x-p)(x-q)=x^2-(p+q)x+pq=x^2-rx+s. $$\n\n2) $m=p^aq^{b-1}$. This happens, if $p$ is a factor of $q-1$. This time $$ \\frac{n}{m}=q,\\qquad\\text{and}\\qquad\\frac{\\phi(n)}{m}=\\frac{(p-1)(q-1)}p. $$\n\nI think that is possible to build a method from these bits alone. I would assume that we have the first case, and then check that it works in a separate verification step. The roots of the quadratic need to be integers, and we can keep on dividing $n$ with the roots to verify that the number $n$ is, indeed, of the form $p^aq^b$. If something goes wrong, then we must have case 2. This time we know $q$ directly, and can solve for $p$ from the equation $$ \\frac1{q-1}\\cdot\\frac{\\phi(n)}{m}=\\frac1{q-1}\\cdot\\frac{(p-1)(q-1)}p=\\frac{p-1}p=1-\\frac1p, $$ because the LHS is known.\n\nUndoubtedly there are alternative ways of exploiting these bits. The key is to compute $m$ first.\n\nshare|improve this answer\nThank you, I was hoping there's some way to avoid the initial case guesswork but I suppose this will have to do. \u2013\u00a0 poe123 May 12 '12 at 12:21\n@poe123, if you knew about this method, you could have said so. And waited for somebody to suggest a clever trick avoiding the verification step :-) No harm done, though! \u2013\u00a0 Jyrki Lahtonen May 12 '12 at 12:25\nOnce you have $t=n/m$ you can repeatedly divide it out of $n$ to get a power of $p$ or $q$ alone. Write $n=t^ku$, then if $u=1$ it's case 1) with $a=b$, otherwise in case 1) $\\gcd(t,u)$ is $p$ or $q$, in case 2) $\\gcd(t,u)$ is 1 and $t=q$. \u2013\u00a0 Zander May 14 '12 at 17:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/85418/expectation-of-log1x-if-x-is-a-gamma-random-variable\nText:\nTake the tour \u00d7\n\nI would like to know if there is a closed form expression for the expectation of log(1+x) when x is a gamma random variable.\n\nThank you.\n\nshare|improve this question\nYes, you may need Digamma function. See en.wikipedia.org/wiki/Polygamma_function \u2013\u00a0 Anand Jan 11 '12 at 15:58\nadd comment\n\n2 Answers\n\nIf $X$ has the gamma distribution with rate $\\lambda$ and shape parameter $n$, you're asking for $$ J(\\lambda, n) = \\frac{\\lambda^n}{\\Gamma(n)} \\int_0^\\infty t^{n-1} e^{-\\lambda t} \\log(1+t)\\ dt = \\frac{1}{\\Gamma(n)} \\int_0^\\infty s^{n-1} e^{-s} \\log(1+s/\\lambda) \\ ds$$\n\nUsing Maple, I get\n\n$$\\Psi \\left( n \\right) -\\ln \\left( \\lambda \\right) +{\\frac { {\\mbox{$_2$F$_2$}(1,1;\\,2,2-n;\\lambda)}\\lambda}{n-1}}+{\\frac { \\left( -1 \\right) ^{-n}\\pi }{\\sin \\left( \\pi n \\right) }}-{\\frac { \\left( -1 \\right) ^{-n}\\pi \\Gamma \\left( n,-\\lambda \\right) }{\\sin \\left( \\pi n \\right) \\Gamma \\left( n \\right) }} $$\n\nwhich seems to be correct when $n$ is a non-integer. For integer values of $n$, the result seems to be $\\frac{\\Gamma(n,-\\lambda)}{\\Gamma(n)} Ei(1,\\lambda)$ plus a polynomial in $\\lambda$ of degree $n-2$.\n\nshare|improve this answer\nadd comment\n\nI may be mistaken, but if you are making the change of variable $s = \\lambda t$, shouldn't there be an extra factor of $\\lambda$ outside the integral?\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/280708/a-question-on-a-sequence?answertab=votes\nText:\nTake the tour \u00d7\n\nLet $X$ be Hausdorff. If $S=\\{x_n: n\\in \\mathbb N \\}\\subset X$, then does there exist a subsequence $D$ of the sequence $S$ such that $D$ is a discrete subset of $X$?\n\nThanks ahead:)\n\nshare|improve this question\nHave you tried working this out for some concrete examples of $X$ and $S$? \u2013\u00a0 Brad Jan 17 at 12:40\nI think you mean \"$D$ is a discrete subspace of $X$. (That is, every point of $D$ is open in the subspace topology of $D$). This may be of interest then. \u2013\u00a0 David Mitra Jan 17 at 13:06\n@DavidMitra: You are RIGHT. \u2013\u00a0 Paul Jan 17 at 13:11\nAlso: mathoverflow.net/questions/42117 \u2013\u00a0 Martin Jan 17 at 13:20\nSo use the fact that if $A_1\\subset A_2\\subset X$, then the relative topology induced on $A_1$ by the relative topology of $A_2$ in $X$ is precisely the relative topology of $A_1$ in $X$, and fact that every infinite Hausdorff space contains a countably infinite discrete subspace. The latter fact is proven in this post. \u2013\u00a0 David Mitra Jan 17 at 13:20\nshow 4 more comments\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHere is the copy of the answer to the question:Exercises about Hausdorff spaces .\n\nIf $x \\in X$ has a finite open nbhd, then $\\{x\\}$ is open (i.e., $x$ is an isolated point). (Why?) Let $I$ be the set of isolated points of $X$; clearly $I$ is discrete, so if $I$ is infinite, just pick any countably infinite subset of it. That's the easy case; you have to work harder when $I$ is finite.\n\nIn that case let $Y = X \\setminus I$. Note that if $y \\in Y$, every open nbhd $V$ of $y$ is infinite. Now build the desired discrete set recursively. Start by choosing distinct points $y_0,y_1 \\in Y$, and let $W_0,V_1$ be disjoint open sets with $y_0 \\in W_0$ and $y_1 \\in V_1$. (Here there's a reason for using different letters: the $V_n$'s are needed temporarily for the construction, but it's the $W_n$'s that we really want.) $V_1 \\cap Y$ is infinite (why?), so we can pick a point $y_2 \\in V_1 \\setminus \\{y_1\\}$. Now let $W_1$ and $V_2$ be disjoint open subsets of $V_1$ such that $y_1 \\in W_1$ and $y_2 \\in V_2$. Now $V_2 \\cap Y$ is infinite, so we can pick a point $y_3 \\in V_2 \\setminus \\{y_2\\}$ and let $W_2$ and $V_3$ be disjoint open subsets of $V_2$ such that $y_2 \\in W_2$ and $y_3 \\in V_3$. Continue in this fashion to get points $y_n$ and open sets $W_n$ for each $n \\in \\omega$. Clearly $y_n \\in W_n$ for each $n$, and with a little thought you should be able to see that if $m \\ne n$, $y_m \\notin W_n$. (It's probably best to consider the cases $m<n$ and $m>n$ separately. It may also help to make a sketch of the first few steps of the construction.)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49365/does-every-symmetric-group-s-n-have-a-single-element-of-maximal-word-norm\nText:\nTake the tour \u00d7\n\nGenerate $S_n$ by transpositions $s_i$ of (i) and (i+1). Both $S_3$ and $S_4$ have single elements of maximal word norm associated with this presentation. In fact, the Cayley graph of $S_3$ can be seen as a tiling of $S^1$, and the Cayley graph of $S_4$ a tiling of $S^2$. The element of maximal length is then antipodal to e.\n\nDoes every symmetric group $S_n$ have a single element of maximal word norm? If so, is there a formula for its length l(n)?\n\nshare|improve this question\nThanks for the answers. All are helpful - both the basic proof and bigger theory. \u2013\u00a0 ian Dec 14 '10 at 14:57\nadd comment\n\n5 Answers\n\nup vote 23 down vote accepted\n\nIt is amazing how a fact that I was taught in a middle school can be proved using big theories where I don't understand half of the words. Let me add a straightforward proof (for $S_n$ and only $S_n$).\n\nFor a permutation $\\sigma:\\{1,\\dots,n\\}\\to\\{1,\\dots,n\\}$, let $\\lambda(\\sigma)$ denote the number of inversions in $\\sigma$, that is the number of pairs $(i,j)$ such that $i<j$ and $\\sigma(i)>\\sigma(j)$. Then $\\lambda(\\sigma)$ equals the length of $\\sigma$ with respect to the generating set $\\{s_i\\}$.\n\nIndeed, left-multiplying $\\sigma$ by $s_i$ only interchanges $\\sigma(i)$ and $\\sigma(i+1)$, and hence changes $\\lambda(\\sigma)$ by at most 1. Therefore the length is bounded below by $\\lambda$. On the other hand, if $\\sigma$ is not the identity, there exists $i$ such that $\\sigma(i+1)<\\sigma(i)$, then left-multiplying by $s_i$ decreases $\\lambda(\\sigma)$ by 1. Repeating this procedure, one reaches the identity from $\\sigma$ by exactly $\\lambda(\\sigma)$ multiplications by generators.\n\nNow it is clear that the maximum length equals $n(n-1)/2$ and is attained only at the order reversing permutation (the one given by $\\sigma(i)=n+1-i$ for all $i$).\n\nshare|improve this answer\n+1 for the first sentence :) \u2013\u00a0 JBL Dec 14 '10 at 12:40\nTo combine with Qiaochu's answer: inversions $\\sigma(i)>\\sigma(j)$ correspond to flipped roots $e_i-e_j$. So the proof here extends easily to other root systems with their own notion of inversions, e.g. for the group of signed permutations. \u2013\u00a0 Allen Knutson Dec 14 '10 at 19:06\nadd comment\n\nYes; this is known as the longest element, and it exists and is unique for every finite Coxeter group (including the ones which do not arise as Weyl groups). The length of the longest element is the number of positive roots in the corresponding root system; here that number is ${n \\choose 2}$. A standard reference here is Humphreys' Reflection groups and Coxeter groups; Proposition 5.6b is relevant, and this is the content of Exercise 2 in that section.\n\nTo be more explicit (and to explain Tobias' answer), specialized to symmetric groups Proposition 5.6b says the following: let $S_n$ act on the orthogonal complement of the all-ones vector in $\\mathbb{R}^n$ in the obvious way. This complement is spanned by elements of the form $e_i - e_j, 1 \\le i \\neq j \\le n$; a choice of positive roots for the corresponding root system can be obtained by considering the elements with $i > j$, of which there are ${n \\choose 2}$. Then the length of $w \\in S_n$ is the number of positive roots $e_i - e_j$ sent to their negatives $e_j - e_i$ (which, one readily verifies, is the number of inversions in $w$). And there is a unique permutation that does this to every positive root: just send $k$ to $n + 1 - k$.\n\nOne way to interpret this result is that the length of an element $w \\in S_n$ (with its usual Coxeter system) is the least number of steps required to sort the word $w_1 w_2 ... w_n$ using bubblesort, and of course the word $n (n-1) (n-2) ... 3 2 1$ takes ${n \\choose 2}$ steps to sort and is maximal (since $n$ is moved $n-1$ times, $n-1$ is moved $n-2$ times, etc.)\n\nshare|improve this answer\nThe bit \"...their negatives $e_j - e_i$...\" is wrong above. It should just be \"negative roots,\" but this seems like too minor an edit to bump for. \u2013\u00a0 Qiaochu Yuan Nov 20 at 7:31\nadd comment\n\nThe Cayley graph of $S_n$ is the skeleton of the Permutahedron of order $n$. This polytope is the Minkowski sum of the $\\frac{n(n-1)}{2}$ segments connecting pairs of the standard basis vectors. You can now visualize that the element of maximal length is antipodal to the identity vertex and has length exactly $\\frac{n(n-1)}{2}$.\n\nshare|improve this answer\nNote that this is just a response to the observation that the Cayley graph of $S_n$ looks like $S^n$, the simplest proof is given by Sergei Ivanov in the other answer. \u2013\u00a0 Gjergji Zaimi Dec 14 '10 at 9:51\nadd comment\n\nYes, all $S_n$ have a unique longest element. One way to see this is that $S_n$ is the Weyl-group of the simple Lie algebra of type $A_{l-1}$, and here the length can be characterized by fixing a set of simple roots (and thus of positive roots). The length is then the number of positive roots that are sent to negative roots. The unique longest element is then the one that sends each simple root to its negative (the product of the simple reflections corresponding to each simple root)\n\nshare|improve this answer\nadd comment\n\nA more explicit version of Qiaochu's answer : $S_n$ can be viewed as a Coxeter group of type $A_{n-1}$. The maximal length is $\\frac{n(n-1)}{2}$, achieved by the element $$s_1(s_2s_1)(s_3s_2s_1) \\ldots (s_{n-1}s_{n-2} \\ldots s_2s_1)$$.\n\nThis is a classical result in Coxeter groups theory. Sketch of the proof : for each $i \\in [1,n-1]$ let $G_i$ be the so-called parabolic subgroup generated by $T_i=\\lbrace s_1,s_2, \\ldots ,s_n \\rbrace $. For any $w\\in G_k (1 \\leq k \\leq n-1)$ we can write $w=w_1w_2w_3 \\ldots w_r$ where each $w_i \\in T_k$ and $r$ is minimal. Among all those decompositions, we choose the one with as many generators in $T_{k-1}$ on the left as possible. This shows that $w$ can be written $w=w'x$, with $w'\\in G_{k-1}$, and $x\\in X_k$ where $X_k$ consists of the element $x\\in G_k$ all of whose minimal decompositions start with $s_k$.\n\nIt is not hard to show that the pair $(w',x)$ is unique (this is because $G_{k-1}$ and $X_k$ are disjoint) and trivially we have $l(w)=l(w')+l(x)$. By induction, any $w\\in S_n$ can be written uniquely $w=x_1x_2 \\ldots x_n$, where each $x_i$ is in $X_i$, and furthermore $l(w)=l(x_1)+l(x_2)+ \\ldots +l(x_n)$.\n\nNow, when the group is $S_n$ it is a straightforward exercise to show that $$X_k=\\lbrace s_{k},s_{k}s_{k-1}, \\ldots, s_{k}s_{k-1} \\ldots s_{2}s_{1} \\rbrace$$ for any $k$. Therefore $X_k$ has a unique element of maximal length, $\\xi_k=s_{k}s_{k-1} \\ldots s_{2}s_{1}$, and we deduce that $S_n$ has a unique element of maximal length which is the product $\\xi_1\\xi_2 \\ldots \\xi_{n-1}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/48721/calculate-temperature-of-the-earth-through-blackbody-radiation/49739\nText:\nTake the tour \u00d7\n\nI don't understand the solutions to a problem about blackbody radiation and was wondering if anybody could help me out.\n\nHere is the question:\n\nThe sun can be considered as a blackbody radiation source at temperature T = 5778 K. Radiation from the sun which is incident on the earth is reflected by the atmosphere such that the intensity hitting the earth's surface is reduced by a factor R. Some of the radiation emitted from the earth's surface is reflected by the atmosphere such that only a fraction A leaves the atmosphere. If A = R = 0:1, what temperature would the earth be?\n\nThen in the solutions they state: This is obtained by first trying to find the power from the sun which passes through unit area at the earth's radial distance. This is given by:\n\n$\\frac{4 \\pi r_s^2}{4 \\pi d_e^2}\\sigma T_s^4$\n\nwhere $r_s$ is the radius of the sun, $d_e$ is the distance between the earth and sun and $T_s^4 = 5778K$ is the temperature of the sun.\n\nI know that $\\sigma T_s^4$ is from the Stefan-Boltzmann law, and that $4 \\pi r_s^2$ is the surface of the sun. What I don't understand is why the distance to the earth is important. Thanks in advance!\n\nshare|improve this question\nIf the Earth is farther from the sun it receives less radiation from the sun! Try sketching the geometry. (Hints: conservation of energy (flux); inverse square law) \u2013\u00a0 Michael Brown Jan 9 at 13:15\n@MichaelBrown So the $\\frac{1}{d_e^2}$ comes from the inverse square law? The thing that confuses me is that the earth's radius isn't needed anywhere. \u2013\u00a0 Longeyes Jan 9 at 13:35\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe standard procedure (or at least how I think about it) for getting the temperature of a planet from that of the star consists of alternating between power and power per unit area.\n\n  \u2022 You start with $\\sigma T^4$, the total power per unit area of the star.\n  \u2022 To get the total power, multiply by the area of the star.\n  \u2022 To get the power per unit area at the distance of the planet, you have to divide by the area of the sphere over which this energy is (by assumption evenly) distributed. This gets you to the quantity you have.\n  \u2022 Now you can find the total power absorbed by the planet, given the power per unit area it gets and an area1.\n  \u2022 Then you can divide by an area1 to get the power per unit area given off by the planet, which is a quantity you can set equal to $\\sigma T_\\text{planet}^4$ to find its temperature.\n\nSo there is a lot of multiplying and dividing by areas, and lots of factors of $\\pi$ will cancel when you string it all together. Note one can modify these steps to take additional complexities into account (the $R$ and $A$ of your problem, for example).\n\nFurther, note that I used the planet's radius - twice in fact. And if you go through the arithmetic, you should find that it cancels itself. Intuitively, you might expect that an object's temperature (an average thermal energy) only depends on the strength of the heat source and its distance, but not on the object's size. Both you and your pet hamster2 get to about the same temperature sitting at equal distances from the fireplace.\n\n1 Be careful about these two areas. You have to think about what area is appropriate where.\n\n2 I have no idea how I came up with this example.\n\nshare|improve this answer\nThanks! I think I understand how they got their results now :) By the first area...do you mean the \"receiving\" planet's surface? \u2013\u00a0 Longeyes Jan 11 at 10:40\n@Longeyes Yes, but there's a difference between the cross-sectional area $\\pi r^2$ and the total surface area $4 \\pi r^2$. \u2013\u00a0 Chris White Jan 11 at 15:57\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/109483/maximal-order-of-elements-in-gln-p?answertab=active\nText:\nTake the tour \u00d7\n\nI am looking for a formula for the maximal order of an element in GL(n,p), where p is prime.\n\nI recall seeing such a formula in a paper from the mid- or early 20th century, but could not find again this reference. I will be grateful for any hint.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nWell, by Hamilton--Cayley, each matrix $A\\in {\\rm GL}(n,p)$ generates an at most $n$-dimensional subalgebra ${\\mathbb F}_p[A]\\subseteq M(n,p)$ thus containing at most $p^n-1$ nonzero elements. Hence the order of $A$ cannot exceed $p^n-1$.\n\nOn the other hand, consider a degree $n$ monic polynomial $P_n$ whose root is a generator $\\xi$ of ${\\mathbb F}_{p^n}^*$. Then a matrix with $P_n$ as its characteristic polynomial has order at least $p^n-1$ since $\\xi$ is its eigenvalue.\n\nADDENDUM. if you wish the order to be the power of $p$, then the answer is $d=p^{\\lceil \\log_p n\\rceil}$. Since the order of $A$ is divisible by the multiplicative orders of its eigenvalues, all the eigenvalues should be $1$. Hence the characteristic polynomial is $(x-1)^n$, so $A^d-I=(A-I)^d=0$.\n\nOn the other hand, if $A=I+J$ is the Jordan cell of size $n$ (with eigenvalue 1), then $A^{d/p}=I^{d/p}+J^{d/p}\\neq I$, but $A^d=I+J^d=I$.\n\nNB. The subgroup of all (upper-)unitriangular matrices is a Sylow $p$-subgroup in ${\\rm GL}(n,p)$. So you may concentrate on it when looking at the elements of this kind.\n\nshare|improve this answer\nThank you very much for the elegant answer! A related question: what is the maximal p-power which is the order of an element of GL(n,p)? \u2013\u00a0 user27196 Oct 13 '12 at 6:41\nI've added an answer to this question, too. \u2013\u00a0 Ilya Bogdanov Oct 13 '12 at 7:20\nThank you very much again - this was very helpful. \u2013\u00a0 user27196 Oct 13 '12 at 8:31\nBeautiful trick to use Cayley-Hamilton here! \u2013\u00a0 Peter Mueller Oct 13 '12 at 9:35\nI have meanwhile found the paper: Ivan Niven, Fermat theorem for matrices, Duke Math. J. 15 (1948), 823-826, which gives an elementary and explicit description of the possible orders of elements in GL(n,q), where q is a prime power. Thanks again. \u2013\u00a0 user27196 Oct 14 '12 at 7:26\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/393071/divide-by-a-number-without-dividing?answertab=active\nText:\nTake the tour \u00d7\n\nCan anyone come up with a way to divide any given x by any given y without actually dividing?\n\nFor example to add any given x to any given y without adding you would just do:\n\nAnd to subtract any given x from any given y (that is, y-x) you could do:\n*edit: well since (i) is ($\\sqrt{-1}$) and that is technically subtracting this one might not work perfectly but for the sake of the riddle and for the sake of example, I'm using that equation :)\n\nHow can you divide without dividing? Can anyone come up with equations that work for all $x$ and $y$ values? (For all intents and purposes we will leave out dividing by zero issues and what-not... don't worry about that...\n\nshare|improve this question\nI don't really see the point of this post. Divide without dividing? Sure you can do it for simple things, like solving: $2x = 6$. You could guess rational numbers until you get it right but that's pretty silly. What about something more complicated like $2x = \\pi$? How could you solve for $x$ without doing division? \u2013\u00a0 Cameron Williams May 16 at 2:20\n@CameronWilliams Exactly! How would you? That's what I want to know! I think it's a fun question! \u2013\u00a0 Albert Renshaw May 16 at 2:21\n$x/y=x\\times y^{-1}$ \u2013\u00a0 vadim123 May 16 at 2:22\n@CameronWilliams: Come now, Albert mentions $y+xe^{\\pi i}$ as a work-around for subtraction. You could not compute this without actually doing subtraction. The question is clearly about equivalent expressions with no immediate regard to practicality. We all have to learn these things at some point :) \u2013\u00a0 Eric Stucky May 16 at 2:27\nLet me just add that while the question may seem a little facetious, Paul Dirac spent some time trying to join special relativity and quantum mechanics before he discovered he could take a square root without taking a square root and revolutionise physics! (Slide 13) \u2013\u00a0 Nicolau Saker Neto May 16 at 3:32\nshow 9 more comments\n\n4 Answers\n\nup vote 7 down vote accepted\n\nLook at the equation $\\frac{1}{x}=a$. We use Newton's Method to approximate the solution.\n\nLet $f(x)=\\frac{1}{x}-a$. The standard Newton iteration gives $$x_{n+1}=x_n -\\frac{f(x_n)}{f'(x_n)}=x_n -\\frac{\\frac{1}{x_n}-a}{-\\frac{1}{x_n^2}}.$$ This simplifies to $$x_{n+1}=x_n(2-ax_n).$$\n\nRemark: Note that only subtraction and multiplication are used. If we start with $x_0$ close enough to $\\frac{1}{a}$, the method converges rapidly. It was once used to implement reciprocal in software.\n\nshare|improve this answer\n@AlbertRenshaw: You mentioned in the comments that your original idea was to try and \"guess high, guess low\" until you got to the right answer. This is a formally rigorous way of implementing a strategy similar to that one. The downside is that you'll never actually reach the number, but the upside is that for integer divisions you'll be able to see pretty quickly what you're \"headed towards,\" for example if your first guess is 0.8, this method tells you after four steps that $\\frac12\\approx 0.49999996$; it's not too much of a stretch to say, \"Oh, that's 0.5\". \u2013\u00a0 Eric Stucky May 16 at 2:49\nadd comment\n\nTake the logarithm that maps multiplication/division into addition/subtraction:\n\n$$\\frac{x}{y}=e^{\\log{x/y}}=e^{\\log x- \\log y}.$$\n\n$x,y >0$.\n\nAlso, see my answer for multiplying natural numbers here: Advocating base 12 number system\n\nshare|improve this answer\nadd comment\n\nFor $y \\neq 0$ $$\\large x\\div y = \\dfrac 1y\\times x = y^{-1}\\times x = \\large y^{\\left(e^{i\\pi}\\right)}\\times x = y^{\\left(i^2\\right)}\\times x$$\n\nshare|improve this answer\nVery nice!!! For now I will accept this, I am curious what others come up with!!! (I will accept it in 7 minutes when SE lets me) \u2013\u00a0 Albert Renshaw May 16 at 2:23\nMultiplying by the reciprocal could be thought of as the definition of division. This is analogous to saying that $x-y = x+(-y)$ is subtracting without subtracting, whereas an alternative would be to note that that is the definition of subtraction. \u2013\u00a0 Jonas Meyer May 16 at 2:30\n@JonasMeyer I'm eager to see if other's come up with solutions that don't use that... since the only way to \"really\" solve mathematically for (x^-y) is to use division. But this was more of a riddle question, in which case this is a valid answer :o) \u2013\u00a0 Albert Renshaw May 16 at 2:31\n@amWhy: I have seen all of the OP's comments. I'm not sure what part you want me to see. \u2013\u00a0 Jonas Meyer May 16 at 2:36\n@Jonas see below the answer...he simply wants to avoid using the symbol for division. \"I just meant without using the symbols in the actual equation! Haha :o) \" \u2013\u00a0 amWhy May 16 at 2:37\nshow 1 more comment\n\nLogs turn reciprocals into minus signs: $\\ln(1/y)=-\\ln(y)$. Thus, $$x/y=xe^{-\\ln y}.$$\n\n(This is assuming that $y$ is positive. If $y$ is negative, then $x/y=-xe^{-\\ln(-y)}$.)\n\nshare|improve this answer\nI like this one even better!!! :) \u2013\u00a0 Albert Renshaw May 16 at 2:33\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214234/tiling-a-minimal-perimeter-region-with-n-unit-squares?answertab=oldest\nText:\nTake the tour \u00d7\n\nSuppose I have $n$ identical unit squares and I want to use them all to tile a region with minimal perimeter $p(n)$. For instance I guess $p(n^2)=4n$, by arranging them im a $n\\times n$ square.\n\nIs there an explicit formula for $p(n)$? Or sharp bounds? How do one prove equalities or bounds for this type of quantities?\n\nI would be happy also with a recursive formula for $p(n)$, like $p(n\\cdot m) = f(p(m),p(n))$, but the factorization is not unique and I don't see how to get it easily.\n\nMy intuition is that given a certain number $n$, the minimal perimeter region is a rectangle with sides of integer lengths $l$ and $m$, where $l\\cdot m=n$ and $(l,m)$ is the pair of integer numbers \"closest\" (in some sense) to $(\\sqrt{n},\\sqrt{n})$, that's where number theory could play a role.\n\nI have no clue where to start proving something along these lines, so any hint, comment or reference is welcome!\n\nshare|improve this question\nI think it should be $p(n) \\sim 2\\sqrt{\\pi n}$ as $n\\to\\infty$ \u2013\u00a0 nikita2 Oct 15 '12 at 13:30\n@nikita2: That would be the asymptotic form for the minimal length of the convex hull; but if you measure the perimeter exactly following the sides of the squares a circular arrangement is actually worse than a square. \u2013\u00a0 joriki Oct 15 '12 at 15:03\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nFor every x in the range $n^2 \\le x < (n+1)^2$ you have $4n \\le p(x) \\le 4n+4$, so $p(x) = \\sqrt{x} + \\operatorname{O}(1)$. If you want a closed formula I would try with (putting $t=n^2-x$) $$ p(n^2+t) = \\begin{cases} 4n \\quad&\\text{if }t=0\\\\4n+2 &\\text{if }0 < t \\le n\\\\ 4n+4 &\\text{if }n < t \\le 2n\\end{cases}$$ which is the perimeter you obtain if you go from the square $n\\times n$ to the square $(n+1)\\times(n+1)$ tile by tile.\n\nEDIT (Proof sketch) We can assume that the shape with least perimeter is connected (if the shape has two pieces, connecting them by a suitable edge gives a shape with strictly less perimeter than the original).\n\nNow given $x = n^2+t$ with $0\\le t \\le 2n$ fix a shape that gives the least perimeter $p(x)$. Pick a rectangle with minimal dimensions $a\\times b$ containing the shape. The perimeter is at least $2a+2b$, (as it goes all the way from left to right and from top to bottom and back by the other side).\n\nOn the other hand $ab \\ge x$ because there are at least $x$ tiles inside the rectangle so $$ p(x) \\ge 2a + 2b \\ge 2a + 2x/a $$ the right hand side has a single minimum at $a = \\sqrt{x}$ but $a$ is an integer so we have $$ p(x) \\ge 2n + 2x/n = \\frac{ 4n^2 + 2t}{n} $$ (it is easy to see that $a=n+1$ gives a larger value). If $t = 0$ this gives $p(x) \\ge 4n$, if $t \\le n$ we have $p(x) > 4n$ but as $p(x)$ is even we have $p(x) \\ge 4n+2$ and if $t > n$ we have $p(x) > 4n+2$ so again $p(x) \\ge 4n+4$. As we have examples obtaining this bounds we are finished.\n\nshare|improve this answer\nthat was my guess as well, but does one prove it formally? \u2013\u00a0 Ale Zok Oct 15 '12 at 16:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/57964/from-lagrangian-to-hamiltonian-in-fermionic-model?answertab=active\nText:\nTake the tour \u00d7\n\nWhile going from a given Lagrangian to Hamiltonian for a fermionic field, we use the following formula. $$ H = \\Sigma_{i} \\pi_i \\dot{\\phi_i} - L$$ where $\\pi_i = \\dfrac{\\partial L}{\\partial \\dot{\\phi_i}} $ In a Lagrangian involving fermionic fields given by, $$ L = \\dfrac{1}{2}(\\bar{\\psi_i} \\dot{\\psi_j} - \\dot{\\bar{\\psi_i}} \\psi_j)$$ a direct computation gives $\\pi_{\\psi_j} = -\\dfrac{1}{2}\\bar{\\psi_i}$ and $\\pi_{\\bar{\\psi_i}} = -\\dfrac{1}{2}\\psi_j$. But on adding a total derivative $\\dfrac{1}{2} \\dfrac{d}{dt} (\\bar{\\psi_i} \\psi_j)$ to the Lagrangian (which can always be done as the action won't change) but $\\pi$'s become different. So the Hamiltonian as well changes. How do we resolve the issue ?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nThe canonical momenta don't change if you add a total derivative to the Lagrangian.\n\nThe particular total derivative you wanted to add to the Lagrangian as well as the Lagrangian itself has free $i,j$ indices. You surely meant something else because the Lagrangian should have no free indices like that. Let me assume that you meant both expressions to be summed with the sum and prefactor $\\sum_{ij} c_{ij}$. Of maybe you really meant the Lagrangian to be a monomial for fixed values of $i,j$.\n\nBut that's not the issue here. The error relevant for your question is that you considered a phase space that has coordinates $\\psi_j$, $\\bar\\psi_i$, $\\pi_{\\psi_i}$, and $\\pi_{\\bar\\psi_j}$, and you think they're independent coordinates on the phase space. That would be too many phase space coordinates for such a limited system.\n\nWell, they're not independent. The right derivation, using any form of the Lagrangian you want, will give you $\\pi_{\\psi_i}=-\\bar \\psi_i$ (without one-half; and equations that may be obtained by simple conjugations from this one!) so it means that the \"same\" non-differentiated $\\psi$'s are their own momenta, too.\n\nIf you rewrite the Lagrangian in such a way that the redundant notation is eliminated, i.e. you don't think that coordinates that are dependent are actually independent (this is the error that made you end up with the canonical momenta being 1/2 of their right value; for example, you incorrectly used $\\partial\\dot{\\bar\\psi_i} / \\partial \\psi_j = 0$, which is not true, in the first momentum you mentioned), you will see that $$\\frac{\\partial L}{\\partial \\dot\\psi_j }=-\\bar\\psi_i$$ if I use your confusing non-summation over $i,j$. There's no factor of 1/2. Indeed, to derive this thing without problems, it's helpful to first rewrite the Lagrangian as $\\bar\\psi_i\\dot\\psi_j$ by adding the appropriate total derivative. This form is unique because it contains no $\\dot{\\bar\\psi_i}$ and no $\\psi_j$, so it's only expressed as a function of the independent 1/2 of the degrees of freedom.\n\nNeedless to say, the Hamiltonian is zero if the fermionic Lagrangian only contains the kinetic term with the time derivative.\n\nshare|improve this answer\n+1 Nice answer, What is the correct value of the partial derivative that the OP made a mistake with? \u2013\u00a0 Prathyush Mar 26 at 14:33\nSorry for the sloppy way of posting the question. I think I was in a haste while doing so, actually Lagrangian does have a summation over all the indices. \u2013\u00a0 Jaswin Mar 27 at 16:42\nDear @Prathyush, I don't know how to answer this question. The Lagrangian must first be rewritten to a form in which only the predecided independent coordinates and velocities appear... \u2013\u00a0 Lubo\u0161 Motl Mar 28 at 5:55\nadd comment\n\nIt is not completely clear what Lagrangian OP has in mind. Here we will assume that the Lagrangian reads\n\n$$\\tag{1} L~=~\\frac{i}{2} g_{IJ} \\left(\\overline{\\psi}^I \\dot{\\psi}^J-\\dot{\\overline{\\psi}}^I \\psi^J \\right) + \\frac{1}{2} h_{IJ} \\left(\\overline{\\psi}^I \\dot{\\psi}^J+\\dot{\\overline{\\psi}}^I \\psi^J \\right), $$\n\nwhere $\\psi^{I}$ is a complex Grassmann-odd scalar field, and $\\overline{\\psi}^I$ is the complex conjugate field. (This choice is partly inspired by one of OP's other Phys.SE questions.) The metrics are constant\n\n$$\\tag{2} g_{JI}~=~g_{IJ}~=~\\overline{g}_{JI}, \\qquad h_{JI}~=~h_{IJ}~=~\\overline{h}_{JI}. $$\n\nThe second term in the Lagrangian (1) is a total derivative term. This is just included for fun to see how this does not affect the quantization procedure. To derive the Hamiltonian formalism, we will use a Grassmann-odd version of this Phys.SE answer. (We recommend that the reader familiarize himself with the Grassmann-even model in that answer before trying to understand the Grassmann-odd model in this answer.)\n\nThe canonical anticommutation relations (CAR) read\n\n$$\\tag{3} \\{\\psi^I, \\pi_J \\}_{PB}~=~\\delta^I_J~=~\\{\\overline{\\psi}^I, \\overline{\\pi}_J \\}_{PB} ,$$\n\n$$\\tag{4} \\{\\overline{\\psi}^I, \\pi_J \\}_{PB}~=~0~=~\\{\\psi^I, \\overline{\\pi}_J \\}_{PB} ,$$\n\nThe Grassmann-odd momenta are given by right derivatives of the Lagrangian\n\n$$\\tag{5} \\pi_I~:=~L\\frac{\\stackrel{\\leftarrow}{\\partial^r}}{\\partial \\dot{\\psi}^I}~=~\\frac{1}{2}\\overline{\\psi}^J(i g_{JI}+h_{JI}), $$\n\n$$\\tag{6} \\overline{\\pi}_I~:=~L\\frac{\\stackrel{\\leftarrow}{\\partial^r}}{\\partial \\dot{\\overline{\\psi}}^I} ~=~\\frac{1}{2}(i g_{IJ}-h_{IJ})\\psi^J.$$\n\nThe Hamiltonian is identically zero,\n\n$$\\tag{7} H~:= ~ \\pi_I\\dot{\\psi}^I+\\overline{\\pi}_I\\dot{\\overline{\\psi}}^I - L~=~0. $$\n\nEquations (5) and (6) yield two primary constraints\n\n$$\\tag{8} 0~\\approx~\\chi_I~:=~\\pi_I-\\frac{1}{2}\\overline{\\psi}^J(i g_{JI}+h_{JI}), $$\n\n$$\\tag{9} 0~\\approx~\\overline{\\chi}_I~:=~\\overline{\\pi}_I-\\frac{1}{2}(i g_{IJ}-h_{IJ})\\psi^J.$$\n\nThey are, in turn, second-class constraints,\n\n$$\\tag{10} \\{\\chi_I, \\overline{\\chi}_J \\}_{PB}~=~-ig_{IJ}~=~\\{\\overline{\\chi}_I, \\chi_J \\}_{PB} ,$$\n\n$$\\tag{11} \\{\\chi_I, \\chi_J \\}_{PB}~=~0~=~\\{\\overline{\\chi}_I, \\overline{\\chi}_J \\}_{PB} ,$$\n\nindependent of the $h_{IJ}$ metric.\n\nThe Dirac bracket becomes\n\n$$\\tag{12}\\{f, g \\}_{DB}~:=~ \\{f, g \\}_{PB}- i\\{f, \\chi_I\\}_{PB}g^{IJ}\\{ \\overline{\\chi}_J,g\\}_{PB}- i\\{f, \\overline{\\chi}_I\\}_{PB}g^{IJ}\\{ \\chi_J,g\\}_{PB}.\\qquad$$\n\nIn other words, the Dirac anticommutation relations become\n\n$$\\tag{13} \\{\\psi^I, \\overline{\\psi}^J \\}_{DB}~=~-ig^{IJ}~=~\\{\\overline{\\psi}^I, \\psi^J \\}_{DB} ,$$\n\n$$\\tag{14} \\{\\psi^I, \\psi^J \\}_{DB}~=~0~=~\\{\\overline{\\psi}^I, \\overline{\\psi}^J \\}_{DB} ,$$\n\nin agree with the Faddeev-Jackiw method. The corresponding operator anticommutation relations read\n\n$$\\tag{15} \\{\\hat{\\psi}^I, \\hat{\\overline{\\psi}}^J \\}_{+}~=~\\hbar g^{IJ}~=~\\{\\hat{\\overline{\\psi}}^I, \\hat{\\psi}^J \\}_{+} ,$$\n\n$$\\tag{16} \\{\\hat{\\psi}^I, \\hat{\\psi}^J \\}_{+}~=~0~=~\\{\\hat{\\overline{\\psi}}^I, \\hat{\\overline{\\psi}}^J \\}_{+} .$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/128525/expectation-of-the-trace-of-an-inverse-of-a-random-matrix\nText:\nTake the tour \u00d7\n\nGiven a $N \\times M$ matrix $X$ comprised of standard normal entries ($M > N$), I'm interested in approximating $E[trace((XX^T\\frac{\\gamma}{M} + I)^{-1}]$ in terms of $N, M$ and $\\gamma$. Unfortunately, I can't necessarily assume $\\gamma$ is small. I've had no luck in coming up with any kind of approximation. Thanks!\n\nFor context, this problem relates to the effective degrees of freedom for ridge regression.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nlet $\\lambda_{1},\\lambda_2,\\ldots\\lambda_N$ be the eigenvalues of $M^{-1}XX^{T}$; including for convenience a factor $1/N$, the quantity you seek is\n\n$$N^{-1}E[{\\rm Tr}(XX^{T}\\gamma/M)+I)^{-1}]=\\int d\\lambda \\rho(\\lambda)(\\lambda\\gamma+1)^{-1}$$\n\nwhere $\\rho(\\lambda)=E[N^{-1}\\sum_n\\delta(\\lambda-\\lambda_n)]$ is the eigenvalue density of Wishart matrices; this quantity is known in closed form for $N,M\\rightarrow\\infty$ at finite ratio $N/M=r\\in(0,1]$ (Marchenko-Pastur distribution). I find in this way the answer\n\n$$\\lim_{N,M\\rightarrow\\infty}N^{-1}E[{\\rm Tr}(XX^{T}\\gamma/M)+I)^{-1}]=(2r\\gamma)^{-1}\\left(-1-\\gamma\\sqrt{ab}+\\sqrt{(1+a\\gamma)(1+b\\gamma)}\\right)$$\n\nwith $a=(1+\\sqrt r)^2$ and $b=(1-\\sqrt r)^2$. As a check, you can take the limit $\\gamma\\rightarrow 0$ of this expression and obtain $1$, as it should.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/140310/a-limit-with-integral?answertab=active\nText:\nTake the tour \u00d7\n\nWe are given a continuous function $f \\colon [0,1] \\to \\mathbb{R}$. What is the value, if it exists, of the limit $$\\lim_{t \\to +\\infty} \\frac{1}{t} \\log \\int_0^1 \\cosh (t f(x))\\, \\mathrm{d}x \\ ?$$\n\nPS: this is not homework. It's a question contained in a Ph.D test, and I am unable to make progress toward the solution :-(\n\nshare|improve this question\nmay be try L'H\u00f4pital's rule \u2013\u00a0 Babgen May 3 '12 at 9:45\nMy first guess: consider $f(x)=mx+q$ and compute the limit in this particular case. Then remark that any continuous $f$ on $[0,1]$ can be uniformly approximated by affine functions. But also the affine case is not really easy... \u2013\u00a0 Siminore May 3 '12 at 9:55\nadd comment\n\n1 Answer\n\nup vote 9 down vote accepted\n\nWithout loss of generality, assume $f(x)\\geq 0$ (as $\\cosh$ is even). Let $m = \\max f(x)$ and let $\\delta$, $\\epsilon$ be such that $|x-x_0|<\\delta$ impies $m\\geq f(x)>m-\\epsilon$.\n\nFirst, $$ I_t = \\frac1t \\log\\int_0^1 \\cosh(tf(x))\\,dx \\leq \\frac1t \\log \\cosh(tm), $$ and since $\\log\\cosh(tm)\\sim \\log\\frac12 + tm$ ($t\\to\\infty$), this implies that $$ \\limsup_{t\\to\\infty} I_t \\leq m. $$\n\nSecond, $$I_t \\geq \\frac1t \\log \\int_{x_0-\\delta}^{x_0+\\delta} \\cosh(tf(x))\\,dx \\geq \\frac1t \\log \\big(2\\delta \\cosh(t(m-\\epsilon)),$$ which implies that $$ \\liminf_{t\\to\\infty} I_t \\geq m-\\epsilon. $$\n\nTaking the limit as $\\epsilon\\to0$, it follows that $\\lim_{t\\to\\infty}I_t$ exists and equals $\\max_x |f(x)|$.\n\nshare|improve this answer\nVery nice! Just a correction: $\\cosh (tm) \\sim \\frac{1}{2}\\mathrm{e}^{tm}$, so that $\\log \\cosh (tm) \\sim \\log \\frac{1}{2}+tm$ as $t \\to +\\infty$. \u2013\u00a0 Siminore May 3 '12 at 11:31\nThanks. Fixed that. \u2013\u00a0 Kirill May 3 '12 at 11:34\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/252638/bounds-on-a-sum-involving-the-mobius-function\nText:\nTake the tour \u00d7\n\nIn Apostol's Analytic Number Theory, Apostol defines $$A(x):= \\sum_{n \\leq x} \\frac{\\mu(n)}{n}$$ and proves that $A(x)=o(1)$ implies the Prime Number Theorem, by showing that $$\\frac{M(x)}{x}=A(x)-\\frac{1}{x}\\int_1^x A(t)dt,$$ in which $M(x):=\\sum_{n \\leq x} \\mu(n)$ is the summatory function for the M\u00f6bius function (Theorem 4.16). What are some known error bounds for the function $A(x)$? In particular, do we have $A(x)= o(1/\\log x)$ as $x \\to \\infty$?\n\nshare|improve this question\nTerence Tao has a rather interesting paper about this : 'A remark on partial sums involving the Mobius function'. See too his blog. \u2013\u00a0 Raymond Manzoni Dec 7 '12 at 1:20\nSchoenfeld's paper, Marraki's one and Cohen's paper seem interesting too (summatory function is much more studied than the $\\zeta(1)$ formula). \u2013\u00a0 Raymond Manzoni Dec 7 '12 at 1:25\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nI'll answer my own question:\n\nThe Abel Summation formula gives\n\n$$A(x)=\\frac{M(x)}{x}+ \\int_1^x \\frac{M(u)}{u^2} du = \\frac{M(x)}{x}+\\int_1^\\infty \\frac{M(u)}{u^2} du-\\int_x^\\infty \\frac{M(u)}{u^2} du.$$ As $A(x)=o(1)$, the right-hand side of the above must tend to $0$. We have $M(x)/x \\to 0$, and the estimate $$\\left\\vert \\int_x^\\infty \\frac{M(u)}{u^2} du \\right\\vert \\leq \\int_x^\\infty \\frac{\\vert M(u)\\vert}{x^2} du =\\frac{1}{x^2}O(xM(x))=O(M(x)/x)$$ implies that the rightmost integral of our first line tends to $0$ as well. Thus $$\\int_1^\\infty \\frac{M(u)}{u^2} du=0,$$ and $A(x)=O(M(x)/x)$. In particular, we can answer our question by simply bounding the growth of Mertens' function $M(x)$. We have $$M(x)=O\\left(xe^{-c\\sqrt{\\log x}}\\right)$$ for some positive constant $c$. (I believe this follows from the classical bounds in the PNT but am unable to find a proper reference. Edit: I found a mention of the process here.) Then $A(x) =O(e^{-c \\sqrt{\\log x}})$, and since $$\\lim_{x \\to \\infty} \\frac{(\\log x)^n}{e^{c \\sqrt{\\log x}}}=0$$ for all $n$, we find $A(x)=o((\\log x)^{-n})$ for all $n >0$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/325141/probability-that-n-points-on-a-circle-are-in-one-semicircle\nText:\nTake the tour \u00d7\n\nChoose n points randomly from a circle, how to calculate the probability that all the points are in one semicircle? Any hint is appreciated.\n\nshare|improve this question\nHave I taken too much of a simplistic view on the problem by thinking the probability is $\\left\\(\\dfrac{1}{2}\\right\\)^n$? \u2013\u00a0 Noble. Mar 9 at 1:10\n@Noble: Yes, you have -- that's the probability that the points are all in one particular semicircle. \u2013\u00a0 joriki Mar 9 at 1:10\n@joriki I thought as much, it's a much more interesting problem then! \u2013\u00a0 Noble. Mar 9 at 1:11\nHint: Start with a point randomly on the circle and draw a diameter from that point. All you got to do now is ensure that rest of the $n-1$ points lie on the same side of the diameter (i.e., on a semi-circle). You can place the $n-1$ points using a coin toss. \u2013\u00a0 jay-sun Mar 9 at 1:12\n@jay-sun I dont think this is the correct way, three points could still be in one semicircle even if the last two are on two different sides of the diameter joining the first point and the center. \u2013\u00a0 Shu Xiao Li Mar 9 at 1:14\nadd comment\n\n4 Answers\n\nup vote 5 down vote accepted\n\nA variation on @joriki's answer (and edited with help from @joriki):\n\nSuppose that point $i$ has angle $0$ (angle is arbitrary in this problem) -- essentially this is the event that point $i$ is the \"first\" or \"leading\" point in the semicircle. Then we want the event that all of the points are in the same semicircle -- i.e., that the remaining points end up all in the upper halfplane.\n\nThat's a coin-flip for each remaining point, so you end up with $1/2^{n-1}$. There's $n$ points, and the event that any point $i$ is the \"leading\" point is disjoint from the event that any other point $j$ is, so the final probability is $n/2^{n-1}$ (i.e. we can just add them up).\n\nA sanity check for this answer is to notice that if you have either one or two points, then the probability must be 1, which is true in both cases.\n\nshare|improve this answer\nI don't understand this answer. (Strange, since you think it's a variation on mine. :-) I presume the \"if\" in \"if the remaining points end up all in the upper halfplane\" is intended to mean \"if and only if\"? If so, why is that? And why is the final probability simply the number of points times this one probability you calculated? \u2013\u00a0 joriki Mar 9 at 1:46\n@joriki Basically I'm breaking this down into conditional probabilities. The angle around the circle is just an arbitrary assignment, so conditionally pick $i$. All of these conditional probabilities are going to be identical, and there's $n$ of them, so whatever that probability is, multiply it by $n$. That's the easy part. (cont'd...) \u2013\u00a0 John Moeller Mar 9 at 1:48\n@joriki Since you've conditionally picked $i$, then you can arbitrarily choose the upper or lower halfplane as your \"in the same semicircle\" event. That's a coin-flip for each point, and they all have to be true, so it's $1/2^{n-1}$. (cont'd...) \u2013\u00a0 John Moeller Mar 9 at 1:51\nI think I see now -- I find it rather confusingly formulated, but if I understand correctly, you mean something like this: The probability of the remaining $n-1$ points being in the semicircle clockwise of a given point is $1/2^{n-1}$. These $n$ events (one for each given point) are disjoint, and exactly one of them has to occur for the points to lie in a semicircle; thus the desired probability is their sum. That's a nice argument :-) \u2013\u00a0 joriki Mar 9 at 2:02\nThere's a slight variation of this answer that uses the inherent symmetry: instead of picking $n$ points at random, pick $n$ random diameters of the circle and pick the $n$ points by randomly picking one of the 2 poles of each diameter. By essentially the same argument, you have the probability given by $(2n)/2^n=n/2^{n-1}$. \u2013\u00a0 sai Mar 9 at 2:16\nshow 4 more comments\n\nFind the largest angle gap, and number the points, say, clockwise such that that gap is between the last and first point. Then the probability density for the angle from the first to the last point to be $\\phi\\lt\\pi$ is\n\n$$ n\\frac1{2\\pi}\\left(\\frac\\phi{2\\pi}\\right)^{n-2}\\;, $$\n\nwhere the factor $n$ arises because we mapped $n$ numberings to one, $1/2\\pi$ is the density for the angle between the first and last point, and $(\\phi/2\\pi)^{n-2}$ is the probability that the remaining $n-2$ points are between them. The integral\n\n$$ \\int_0^\\pi n\\frac1{2\\pi}\\left(\\frac\\phi{2\\pi}\\right)^{n-2}=\\frac n{(2\\pi)^{n-1}}\\pi^{n-1}=\\frac n{2^{n-1}} $$\n\nis the desired probability.\n\nP.S.: Here's code that tests this result by simulations.\n\nshare|improve this answer\nadd comment\n\n\n\nfor the general problem (when the points have any distribution that is invariant w.r.t. rotation about the origin) and\n\n\nfor a nice application.\n\nAs a curiosity, this answer can be expressed as a product of sines:\n\n\nshare|improve this answer\nadd comment\n\nHere's another way to do this:\n\nDivide the circle into $2k$ equal sectors. There are $2k$ contiguous stretches of $k$ sectors each that form a semicircle, and $2k$ slightly shorter contiguous stretches of $k-1$ sectors that almost form a semicircle. The number of the semicircles containing all the points minus the number of slightly shorter stretches containing all the points is $1$ if the points are contained in at least one of the semicircles and $0$ otherwise; that is, it's the indicator variable for the points all being contained in at least one of the semicircles. The probability of an event is the expected value of its indicator variable, which in this case is\n\n$$k\\left(\\frac k{2k}\\right)^n-k\\left(\\frac{k-1}{2k}\\right)^n=k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)\\;.$$\n\nThe limit $k\\to\\infty$ yields the desired probability:\n\n$$ \\lim_{k\\to\\infty}k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)=\\lim_{k\\to\\infty}k2^{-n}\\left(\\frac{2n}k\\right)=\\frac n{2^{n-1}}\\;. $$\n\nshare|improve this answer\nWhy is $ \\lim_{k\\to\\infty}k2^{-n}\\left(1-\\left(1-\\frac2k\\right)^n\\right)=\\lim_{k\\to\\infty\u200c\u200b}k2^{-n}\\left(\\frac{2n}k\\right)$ true? \u2013\u00a0 sai Mar 9 at 5:09\n@sai: Apply the binomial theorem to the $n$-th power -- the first term cancels the $1$, the second term yields $2n/k$ and the remaining terms have more than one inverse power of $k$ and thus go to zero as $k\\to\\infty$. Note that $n$ is fixed; it's not a question of taking $n$ and $k$ to infinity simultaneously; we're just adding a finite number of terms, so the standard rules for adding convergent sequences apply. \u2013\u00a0 joriki Mar 9 at 8:23\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/90495/example-of-a-discontinuous-function\nText:\nTake the tour \u00d7\n\nIs there an example of a discontinuous function, $F$, defined on some complete subset $X\\subset R^n$ such that under some metric $d$, $\\sum\\limits_{n=1}^\\infty \\|F^n(x)-F^n(y)\\|<\\infty$ and\u00a0\n\nEither for multiple $x_i\\in X$ where $i\\in I$ and $I$ is any arbitrary indexing set, we have $F(x_i)=x_i$.\n\nOr For all $x\\in X, F(x)\\neq x$?\n\nshare|improve this question\nusually the notation $||.||$ is used for a norm, do you mean norm or metric? What do you assume about $x$ and $y$ in the inequality you stated? Is this supposed to hold for any $x, y$? \u2013\u00a0 user20266 Dec 11 '11 at 17:10\nThe parts \"multiple $x_i$\" and \"any arbitrary indexing set\" seem to contradict each other -- is $I$ really completely arbitrary, or does \"multiple $x_i$\" imply that $I$ has at least two elements? \u2013\u00a0 joriki Dec 11 '11 at 17:40\nAlso the sentence seems to be missing a verb -- do you mean \"Is there an example of a discontinuous function ...\"? \u2013\u00a0 joriki Dec 11 '11 at 17:58\n@Thomas: I meant a metric. Yes, for any x,y. Thanks. \u2013\u00a0 Will Dec 11 '11 at 19:18\n@joriki: Sorry for the ambiguities. I has to bhave at least 2 elements for the \"either\" option. Yes, I should probably use of instead. Edited. :) \u2013\u00a0 Will Dec 11 '11 at 19:20\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nYes. Take $X=[0,1]$ and\n\n$$F(x)=\\begin{cases}\\frac12&x=0\\;,\\\\\\frac x2&x\\ne0\\;.\\end{cases}$$\n\n$F$ is discontinuous at $0$. The sum is a geometric series and thus convergent. And $\\forall_{ x\\in X}F(x)\\ne x$.\n\nNote that the discontinuity at $0$ isn't required to make this work; we could introduce arbitrary discontinuities within the interval, as long as the iteration eventually moves beyond them towards $0$.\n\nClearly we can't have the other case, $F(x_i)=x_i$ for multiple $x_i\\in X$, since in that case the sum would diverge for $x=x_1$, $y=x_2$, being the sum over a non-zero constant.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/175448/cubic-polynomial-discriminant/175522\nText:\nTake the 2-minute tour \u00d7\n\nI am stuck on a cryptography problem that pertains to Elliptic Curves.\n\nThe problem is stated as follows:\n\nAssume the cubic polynomial $X^3+AX+B = (X-a)(X-b)(X-c)$\n\nIf $4A^3 + 27B^2 = 0$, then show two or all of $a,b,c$ are the same.\n\nSo far, I expanded the right side, so I get the following equations:\n\n$0 = a + b + c$\n\n$A = ab + ac + bc$\n\n$B = -abc$\n\nI can't seem to use the hypothesis in the correct way. I tried to compute $A^3$ but the expansion of it looks horrible. If any one has any tips how to approach this problem, that would be great.\n\nshare|improve this question\nDo you recognise that $4A^3+27B^2$ is the discriminant of the cubic? \u2013\u00a0 Andrew Jul 26 '12 at 13:44\nAlso, you might want to change the title and possibly the tags, as the question, though it will be related to elliptic curves and cryptography at some point, is really just about polynomials as stated. \u2013\u00a0 Tobias Kildetoft Jul 26 '12 at 13:54\n@Andrew: Yes I do now. But I guess I'm missing some key fact about that that allows me to conclude what I'm trying to show. \u2013\u00a0 MathNewbie Jul 26 '12 at 14:05\n@Tobias: Hopefully this will be much better of a tag. \u2013\u00a0 MathNewbie Jul 26 '12 at 14:07\nIn general, the discriminant of a polynomial is the product of the square of the differences of the roots. Hence, it is zero if and only if there is a multiple root. \u2013\u00a0 M Turgeon Jul 26 '12 at 14:09\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nThe case $A=0$ must be treated separately: In this case, $X^3+B$ has a double root if and only if $27B^2=0$, i.e. if and only if $B=0$. That is obvious, so let us assume $A\\ne 0$.\n\nLets set $f(X):=X^3+AX+B$ and consider $f'(X)=3X^2 + A$. A polynomial has a double root if and only if it shares this root with its derivative. Hence, let us check when that is the case. $f'(x)=0$ means $x^2 = -\\frac 13 A$ and $f(x)=0$ means $0=x^3+Ax+B=-\\frac{1}{3}Ax+Ax+B$, so $\\frac{2}{3}Ax = -B$, i.e. $x=\\frac{-3B}{2A}$. Plugging this back into $f'$, we get that $$0=f'(x)=3\\cdot\\frac{9B^2}{4A^2} + A,$$ which yields $27B^2 = -4A^3$. Hence, $f$ has a double root if and only if $27B^2+4A^3=0$.\n\nshare|improve this answer\nThanks, rattle. \u2013\u00a0 MathNewbie Jul 26 '12 at 17:50\n\nLet $X^3+Ax+B=(X-p)(X-q)^2$\n\nComparing the coefficients of the different powers of X,\n\n\n\n\nEliminating q, $4A^3+27B^2=0$ as $A^3=-27q^6$ and $B^2=4q^6$\n\nConversely, the parametric values of (A,B) can be written as $(-3s^2,2s^3)$\n\nThen, the equation becomes $X^3-3s^2X+2s^3=0$\n\nClearly, s is one of the solutions.\n\nOn the division by (X-s), we get $X^2+sX-2s^2=0 =>X=s,-2s$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59317/amenable-equivalence-relation-generated-by-an-action-of-a-non-amenable-group/59698\nText:\nTake the 2-minute tour \u00d7\n\nQuestion. Give a (possibly elementary) example of a probability measure preserving action $\\rho\\colon G \\curvearrowright X$ of a finitely-generated discrete group $G$ on a standard borel space $X$ with a probability measure, such that\n\n  1. the equivalence relation generated by $\\rho$ is ergodic and amenable,\n  2. the action $\\rho$ is faithful,\n  3. the group $G$ is non-amenable.\n\nA friend of mine asked me this question couple of days ago, which led us to another question, but perhaps there is an easier way to provide an example.\n\nshare|improve this question\nThis question is discussed in: Alexander S. Kechris \"Global Aspects of Ergodic Group Actions and Equivalence Relations\", pp. 31-34. It is available on line here: citeseerx.ist.psu.edu/viewdoc/summary?doi= \u2013\u00a0 Jesse Peterson Mar 27 '11 at 7:18\nYou can use the construction known as Mackey range: take a cocycle of an amenable equivalence relation with values in a non-amenable group G. Then G induces an amenable action on the space of skew product orbits. See Zimmer's paper for details. \u2013\u00a0 SIB Mar 27 '11 at 12:21\n@Jesse Peterson - Could you be a bit more specific? \u2013\u00a0 R W Mar 27 '11 at 12:31\nThe discussion is in Chapter 1, section 4, subsection (E). In the on line version I've linked to this actually begins on page 27 (page 37 of the pdf file). Thanks RW. \u2013\u00a0 Jesse Peterson Mar 27 '11 at 13:30\n@SIB - Yes, but the problem is still to find such a cocycle for which the resulting action is faithful - which is more or less equivalent to the original question. \u2013\u00a0 R W Mar 27 '11 at 13:40\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nThe answer is yes, such an action exists.\n\nWhat is needed for the construction is the following very nice example of an action of a non-amenable group on $\\mathbb Z$, which I just learned from Gabor Elek.\n\nConsider a graph with vertices given by $\\mathbb Z$ and unoriented edges between $n$ and $n+1$.\n\nPick a random labelling of the edges by the letters $a,b$ and $c$ with no $a$, $b$ or $c$ adjacent to the same letter. This defines an action of the group $G=\\mathbb Z/2 \\mathbb Z \\ast \\mathbb Z/2 \\mathbb Z \\ast \\mathbb Z/2 \\mathbb Z$. Indeed, just act according to existing labels or fix the element.\n\nThis action has the nice feature that it keeps invariant all counting measures on $\\mathbb Z$, i.e. all $\\mathbb Z$-Folner sequences sets are also Folner sequences for the $G$-action.\n\nNow, the space of labellings (as above) of the graph is itself a probability measure space (a Bernoulli space), which carries an ergodic p.m.p. $\\mathbb Z$-action by shifting. It is easy to see that $G$ acts on this space by measure preserving transformations (just by the method described above, done orbit by orbit) and induces an action as required. Indeed, the orbits are just the $\\mathbb Z$-orbits, so its ergodic and amenable. Faithfulness follows the fact that you considered all labellings, so that with positive probability (on the space of labellings), an element will act non-trivially. Note also that $G$ is not amenable.\n\nEDIT: As requested, more details on the action. The elements of the shift space are maps $f: \\mathbb Z \\to \\lbrace a,b,c \\rbrace$ with $f(n) \\neq f(n+1)$. A letter shifts $f$ to the right if $f(1)$ equals that letter, it shifts to the left, if $f(0)$ is equal to the letter; otherwise you fix $f$. It is obvious that the orbits are just the orbits of the shift-action of $\\mathbb Z$. Hence, the induced equivalence relation is just the one induced by the action of $\\mathbb Z$.\n\nshare|improve this answer\nI may miss something, but I don't see how it becomes an action. Take the sake of example the following labelling: $a$ on the edge $(0,1)$, and $b$ on all other edges $(n,n+1)$. Then, according to what you say, $a$ maps 0 to 1 and preserves all other vertices, whereas $a^{-1}$ maps 1 to 0 and preserves all other ones (I presume you meant that if you reverse orientation of an edge, then the label changes to its inverse). But then their composition is not the identity map. \u2013\u00a0 R W Mar 27 '11 at 13:37\nThanks, I corrected the construction. \u2013\u00a0 Andreas Thom Mar 27 '11 at 21:04\nI agree that now there is an action of the free product on $\\mathbb Z$. However, I still don't see how you define an action of this free product on your space of symbol sequences (your description \"just by the method described above, done orbit by orbit\" is not clear to me at all), and why this hypothetical action should be orbit equivalent to the shift. \u2013\u00a0 R W Mar 27 '11 at 22:27\nIt is really easy; I added more details above. \u2013\u00a0 Andreas Thom Mar 28 '11 at 0:15\nThat's nice - thank you. \u2013\u00a0 R W Mar 28 '11 at 3:48\n\nI believe in this paper there is an example of such group:\n\n  \u2022 Rostyslav Grigorchuk, Volodia Nekrashevych, \"Amenable actions of nonamenable groups\" (which can be downloaded from Volodia's webpage)\n\nalso, this is related (but not quite clear if one can built examples that you ask from it):\n\n  \u2022 Yair Glasner, Nicolas Monod, \"Amenable actions, free products and a fixed point property\"\nshare|improve this answer\nLet me also mention that by taking ``generic'' (think Baire category) generators one can show that the free groups have such an action. Also, by a result of Kirchberg (ams.org/mathscinet-getitem?mr=1282231), if $\\Gamma$ has property (T) and also has such an action then it must be residually finite. \u2013\u00a0 Jesse Peterson Mar 24 '11 at 12:53\n\nLet me join the discussion. Nicolas rightly says that amenability of an action is equivalent to amenability of the orbit equivalence relation and of a.e. stabilizer. It is also true that for a finite invariant measure amenability of the action is equivalent to amenability of the acting group. However, there is no contradiction here as (at least a priori) it might be possible that the orbit equivalence relation of an action of a non-amenable group is still amenable - due to the presence of huge stabilizers (which in this case must necessarily be non-amenable).\n\nI think that the paper by Grigorchuk and Nekrashevych quoted by Kate does provide a requested example. Indeed, they construct (Sections 3 and 4) a non-amenable group which has a faithful self-similar action on a homogeneous rooted tree. This action preserves the uniform measure on the boundary of the tree. Moreover, the orbit equivalence relation is a subrelation (mod 0) of the tail (or co-final in authors' terminology) equivalence relation. Since the latter one is hyperfinite ($\\equiv$ amenable), the orbit equivalence relation is also amenable.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/153564/is-it-true-that-for-matrices-where-all-entry-are-lower-than-1-determinant-is-lo\nText:\nTake the 2-minute tour \u00d7\n\nGeneric square matrix with positive 1 bounded entries\n\nConsidering a matrix $A=(a_{i.j})$ where $0 \\leq a_{i,j} < 1 \\forall i,j$. It is important to consider that all entries are strictly lower than 1 and positive.\n\nRows sum to a number lower than 1\n\nLet us consider that the sum of all entries of matrix $A$'s rows is lower than 1: $\\sum_{j=1}^{n}a_{i,j} < 1$. Sorry, maybe I did not specify it, only wrote in the formula, I talk about rows. Rows sum to a number lower than 1.\n\n\nLet us consider $\\det(A)$ (determinant).\n\nIs it true that $\\det(A)<1$???\n\nOr maybe $|\\det(A)| < 1$???\n\nshare|improve this question\nPerhaps you want to put absolute value signs around everything? Otherwise, consider $\\begin{bmatrix}-100 & 0 \\\\ 0 & -100\\end{bmatrix}$. \u2013\u00a0 Rahul Jun 4 '12 at 2:09\nYeah, all entries are positive. Please forgive me... \u2013\u00a0 Andry Jun 4 '12 at 2:13\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nEDIT: Taking into account the condition that the sum of the entries be less than one, the determinant is a sum of $n!$ terms, each of which is at most $n^{-n}$, so the determinant is bounded by $n!/n^n$, which is certainly less than 1 (for $n\\gt1$). Each term is les than $n^{-n}$ because it's a product of $n$ numbers that add up to less than 1, and you maximize the product by taking all the number to equal $1/n$.\n\n(Never mind --- I just saw the part about the sum of all the entries, or maybe it's the sum of all the entries in each row, being less than 1.)\n\nAre we only talking about $2\\times2$ matrices? If not, then $$\\pmatrix{a&b&0\\cr0&c&d\\cr e&0&f\\cr}$$ will have determinant $acf+bde$ which can certainly exceed 1 even if all the variables stand for numbers between zero and one.\n\nshare|improve this answer\nI am talking about sum of row entries... In your case, did you take into account this in your explaination? Sorry I am still reading, wanna be sure we are talking about the same. In my case I consider sum of row entries, not all elements in the matrix \u2013\u00a0 Andry Jun 4 '12 at 2:52\nI edited my questino because I specified the condition on rowas only in the frmula and not using words... It could be misleading. Very sorry for my carelessness \u2013\u00a0 Andry Jun 4 '12 at 2:54\nWhy don't you go away and think about your question for a couple of days and come back when you're able to put into writing the actual question you want to ask instead of something with lots of conditions missing or incorrectly stated? While you're at it, look up the Hadamard bound on determinants, it might answer your question, depending, of course, on what the heck your question might really be. \u2013\u00a0 Gerry Myerson Jun 4 '12 at 3:07\nI can understand that due to my carelessness you had to go through some troubles in understanding what I was looking for. Actually the question is the one here now, no more edits. I simply had in my mind the matrix structure but failed in explaining it and providing good details. I apologized. This being said, I do not think to deserve your bad words as there are many other members in this community behaving really bad towards those who answer their questions. You could simply say to pay more attention, it would have been \"more professional\". \u2013\u00a0 Andry Jun 4 '12 at 3:37\nEach term in the sum isn't necessarily bounded by $n^{-n}$, take a constant multiple of the identity matrix for example.. making all terms ${1 \\over n}$ actually minimizes things as the determinant becomes zero. \u2013\u00a0 Zarrax Jun 4 '12 at 4:59\nshow 1 more comment\n\nNote that $\\sum_j a_{ij}^2 < \\sum_j a_{ij} < 1$. So the magnitude of each row, viewed as a vector in ${\\mathbb R}^n$, is less than one. The absolute value of the determinant of $A$ is the volume of the parallelopiped spanned by the rows, which is at most the product of the magnitudes of the row vectors, and therefore is less than one in this case.\n\nIf you want to do it algebraically, you can prove it by induction on the dimension, the $1$ by $1$ case being trivial. Then you can do a cofactor expansion along any $i$th row, getting that $$det(A) = \\sum_j (-1)^{i + j} a_{ij} \\,det(A_{ij})$$ Note that each matrix $A_{ij}$ also satisfies the conditions of the problems, so each $|det(A_{ij})| < 1$ by induction hypothesis. You then get $$|det(A)| < \\sum_j |a_{ij}||det(A_{ij})|$$ $$< \\sum_j |a_{ij}|$$ $$< 1$$\n\nshare|improve this answer\nI think you'll find that what you are using in the first paragraph is what's commonly referred to as the Hadamard bound. \u2013\u00a0 Gerry Myerson Jun 4 '12 at 6:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/107694/constructing-numbers-from-basic-arithmetic-on-digits?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI was tooling around over on stackoverflow and happened upon this question. To summarise, given the set of digits $\\{1,2,3,4,5,6,7,8,9\\}$ and a set of basic arithmetic (binary) operators $\\{+,-,\\times,/\\}$, what is the least number of operations you need to construct a given integer? For example $239 = 8\\times6\\times5-1$, requires 3 operations.\n\nMy conjecture is that division doesn't help you. There is no number that can be constructed using division, that can't be constructed without division using the same number operations (or fewer). Can anyone prove or disprove this?\n\nshare|improve this question\nI have a feeling that you do need division sometimes. For instance, take numbers like 1+9+81+729+...+9^k. These are easy to make with division: (9*9*9*...*9-1)/8. But I'm not sure how to prove this works; that is, that at least some of these numbers are \"rough\" enough that there's no more efficient way to make them. \u2013\u00a0 Lopsy Feb 10 '12 at 2:48\nLopsy: You can calculate with a computer the smallest number of operations required with or without division. That wouldn't constitute a proof for general $n$, but will at least answer the OP's question. \u2013\u00a0 Yuval Filmus Feb 10 '12 at 5:46\nCould you be more precise of what to do if a division is not exact? Either you simply forbid this, or you consider the rational result as a valid intermediate value, or you take the quotient ignoring the remainder. I think your conjecture is false even if you simply forbid inexact divisions, but it helps to have carity about this first. \u2013\u00a0 Marc van Leeuwen Feb 10 '12 at 12:34\n@Marc: I used only exact division for my answer. \u2013\u00a0 joriki Feb 10 '12 at 13:02\nDo you allow parenthesis? eg. (1+9)*9 \u2013\u00a0 user1708 Feb 10 '12 at 13:19\nshow 1 more comment\n\n1 Answer\n\nup vote 12 down vote accepted\n\nDivision does help, but you have to use seven operations (eight operands) to find a case where it does. Here's a list of all expressions with seven operations with values that can't be obtained with seven operations without division:\n\n$$ \\begin{eqnarray} (5\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9-1)/2&=&89302\\\\ (5\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9+1)/2&=&89303\\\\ (7\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9-5)/2&=&125021\\\\ (7\\cdot7\\cdot7\\cdot9\\cdot9\\cdot9+5)/2&=&125026\\\\ (7\\cdot7\\cdot9\\cdot9\\cdot9\\cdot9-3)/2&=&160743\\\\ (7\\cdot7\\cdot9\\cdot9\\cdot9\\cdot9+5)/2&=&160747\\\\ (7\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-1)/2&=&206671\\\\ (7\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9+3)/2&=&206673\\\\ (7\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9+5)/2&=&206674\\\\ (9\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-7)/2&=&265717\\\\ (9\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-5)/2&=&265718 \\end{eqnarray} $$\n\nHere's the code I used to find them.\n\nSo Lopsy's idea turns out to be a good one. In fact I found the penultimate example, $(9\\cdot9\\cdot9\\cdot9\\cdot9\\cdot9-7)/2=265717$ with a lot less computational effort than the others by factorizing the numbers of the form $(9^6\\pm d)/2$, where $d$ is a single-digit number, finding that $(9^6-7)/2=265717$ is a prime and thus can't be the result of a multiplication, noting that a number this large requires a product with at least six factors and could thus only be formed as $p_7\\pm p_1$, $p_6\\pm p_1\\pm p_1$ or $p_6\\pm p_2$ (where $p_k$ is a product of $k$ factors), and checking that no such expression yields $265717$.\n\nHere's an attempt at explaining that all the counterexamples involve division by $2$. The number should be large, in order to require most of the operations to be multiplications and to leave as little room as possible for additions, subtractions and small factors. The divisor cannot divide any of the other numbers, since then it would have to divide both terms and thus could be canceled. Thus, if the divisor were $3$, there could be no factors of $9$, which lowers the attainable maximum to $(8^6+8)/3=87384$, which is below the smallest counterexample. The higher the divisor $d$, the fewer potential candidates there are, since only every $d$-th number is divisible by $d$, and also the lower the attainable maximum. For $d=4$, the value of $(9^6+7)/4=132862$ is still within the lower range of the actual counterexamples, but with only half as many candidates for counterexamples, it may be just a coincidence that there aren't any. For $d=5$, the maximum $(9^6+9)/5=106290$ is already at the lower end of the range, and with only $2/5$ as many candidates, counterexamples aren't to be expected. Since $d=6$ is excluded for the same reason as $d=3$, the next possibility is $7$. For $d=7$, the maximum $(9^6+6)/7=75921$ is already below the smallest counterexample.\n\nHere's a table showing the number $a_n$ of values expressible with $n$ operations (excluding division) and, as requested in a comment, the least value $b_n$ not expressible with $n$ operations:\n\n$$ \\begin{array}{c|c} n&0&1&2&3&4&5&6&7\\\\ \\hline a_n&9&39&155&739&3667&16947&77860&379072\\\\ b_n&10&19&92&417&851&4237&14771&73237 \\end{array} $$\n\nThe growth rate appears to be well below $9$. That shows that it would be quite wrong to model the expressions as having random values uniformly distributed over the accessible interval $[1,9^{n+1}]$ (where $n$ is the number of operations). The generating function for the number of expressions with $n$ operations (excluding division) approximately satisfies\n\n\n(approximately because the symmetry factor $\\frac12$ shouldn't be applied when combining two identical expressions), and the solution is\n\n\nwith a singularity at $x=1/54$, so the growth rate of the number of expressions is $54$. If their values were uniformly distributed, the probability for a value not to be represented by an expression would be roughly of the order\n\n$$\\left(1-\\frac1{9^n}\\right)^{54^n}\\approx\\mathrm e^{-6^n}\\;,$$\n\nso we would expect almost complete coverage, i.e. a growth rate of $9$.\n\nshare|improve this answer\nWow really a nice answer, which reflects your hard-work sir. Fantastic answer. \u2013\u00a0 Iyengar Feb 10 '12 at 13:03\n@Iyengar: Thank you! \u2013\u00a0 joriki Feb 10 '12 at 13:06\n+1. Could you add a table with the smallest number not expressible in n operations? \u2013\u00a0 user1708 Feb 10 '12 at 13:19\n@Holowitz: Done. \u2013\u00a0 joriki Feb 10 '12 at 13:48\nExcellent stuff. If you're still keen you could see what happens for negative numbers. \u2013\u00a0 wxffles Feb 10 '12 at 19:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/111161/nonhomeomorphic-cw-complexes-that-are-stably-homeomorphic?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nDo there exist CW-complexes $X$ and $Y$ that are not homeomorphic, but $X \\times I$ and $Y \\times I$ are homeomorphic? Here $I$ denotes the unit interval $[0, 1]$.\n\nshare|improve this question\nSee mathoverflow.net/questions/26385/\u2026 \u2013\u00a0 j.c. Nov 1 '12 at 15:26\n\n1 Answer 1\n\nYes. Take $X$ a punctured torus ($T^2\\setminus$open disk) and $Y$ a three-punctured $S^2$. Then $X\\times I=Y\\times I$ is a genus 2 handlebody.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/92233/projection-onto-a-quadratic-cone\nText:\nTake the 2-minute tour \u00d7\n\nConsider a constraint of the form\n\n$$ f(x) := x^T A x = 0 $$\n\nwhere $A \\in \\mathbb{R}^n$ is symmetric but may be singular and indefinite. The constraint set $C$ is a (nonconvex) cone, since for any $x \\in C$ we also have $ux \\in C$ for all $u \\in \\mathbb{R}$.\n\nGiven a point $x_0$ not necessarily in $C$, I am seeking a cheap computational procedure for finding a nearby (in the Euclidean sense) point $x \\in C$. \"Nearby\" means something like the distance between $x$ and the closest point $x^* \\in C$ can be bounded in terms of the distance between $x_0$ and $C$. \"Cheap\" means something like $O(n \\log n)$ or some (very) small polynomial at worst.\n\nPerforming exact line search along the constraint gradient $-2Ax$ is one idea, yielding a single scalar quadratic equation for the shortest time t: $\\min_t f(x_0 - 2tAx_0)$. Unfortunately, the roots of this equation are not always real.\n\n\nshare|improve this question\nDo I correctly understand that the computational time shouldn't depend on point $x_0$ itself? \u2013\u00a0 Kirill Shmakov Mar 26 '12 at 18:42\nI suppose it could. \u2013\u00a0 TerronaBell Mar 27 '12 at 5:33\n\n1 Answer 1\n\nIf you write the problem of finding the closest point to $x_0$ on the cone with a Lagrange multiplier, the solution must have the form $x = (\\lambda A + I )^{-1}x_0$.\n\nIf you start by diagonalizing $A$, the inverse can be computed efficiently and you can search for $\\lambda$ by dichotomy. The algorithm will run in $O(n^2 \\log{1/\\epsilon})$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://www.chegg.com/homework-help/questions-and-answers/wedge-shaped-block-mass-m-rests-smooth-horizontal-table-small-block-mass-m-placed-upper-su-q180605\nText:\nClassical Mechanics\n\n0 pts pending\nA wedge-shaped block of mass M rests on a smooth horizontal table.A small block of mass m is placed on its upper surface, which isalso smooth and inclined at an angle \u03b1 to the horizontal. Thesystem is released from rest. Write down the horizontal componentof momentum, and the kinetic energy of the system, in terms of thevelocity v of the wedge and the velocity u of the small blockrelative to it. Using conservation of momentum and the equation forthe rate of change of kinetic energy, find the accelerations of theblocks.\n\ndu/dt = (M + m)gsin\u03b1/(M + msin2x)\ndv/dt = mgsin\u03b1cos\u03b1/(M + msin2x)\n\nAnswers (0)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/202821/gambler-with-infinite-bankroll-reaching-his-target\nText:\nTake the 2-minute tour \u00d7\n\nSuppose a gambler with infinite bankroll has a target of winning 10 dollars. He wins/loses $\\$1$ with probabilities $0.48=p$ and $0.52=q$ respectively. What is the probability that he meets the target?\n\nThe answer using the usual methods is $(p/q)^n = (12/13)^{10}.$\n\nBy a rather devious process, I have arrived at a combinatorial formula, $$ \\sum_{k=n}^{\\infty}\\frac{n}{k}{2k-n-1\\choose k-n}p^kq^{(k-n)}, $$ I get the same results, but can it be proved that the results will be identical?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHere's a probabilistic argument. Let $T$ be the hitting time of the state $n$. Then a simple application of the hitting time theorem shows that, for $k\\geq n$, $$\\frac{n}{k}{2k-n-1\\choose k-n}p^kq^{(k-n)}=\\mathbb{P}(T=2k-n).\\tag1$$ Therefore $$\\sum_{k=n}^{\\infty}\\frac{n}{k}{2k-n-1\\choose k-n}p^kq^{(k-n)}=\\mathbb{P}(T<\\infty).\\tag2$$\n\nAs for an analytic argument, use a change of variables and simple properties of binomial coefficients to rewrite the sum on the left hand side of (2) as $$\\sum_{x=0}^{\\infty}\\frac{n}{2x+n}{2x+n\\choose x}p^{x+n}q^x.\\tag3$$ Using formula (5.70) on page 203 of Concrete Mathematics by Graham, Knuth, and Patashnik, the sum in (3) can be written as $$(p\\,{\\cal B}_2(pq))^n=\\left(1-\\sqrt{1-4pq}\\over 2q\\right)^n.$$ For $0\\leq p\\leq 1/2$ and $q=1-p$, this reduces to $(p/q)^n$.\n\nshare|improve this answer\nThanks a bunch ! \u2013\u00a0 true blue anil Sep 27 '12 at 4:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/75131/how-to-detect-frequency\nText:\nTake the 2-minute tour \u00d7\n\nLet $J$ be an arc in $\\mathbb{S}^{1}\\subset\\mathbb{C}$ (no matter open or closed) and $\\alpha\\in(0,2\\pi)$ be an angle such that $\\alpha/\\pi$ is irrational. Consider in $\\mathbb{S}^{1}$ the sequence $z_{n}=e^{in\\alpha}$. Then this sequence is dense in $\\mathbb{S}^{1}$ by Kronecker's Theorem or by ergodicity. Let's associate with the arc $J$ its \"indicator sequence\" $s(J)={s_{n}\\}$ of zeroes and ones defined as follows:\n\n$s_{n}=1$ if $z_{n}\\in J$ and $s_{n}=0$ if $z_{n}\\notin J$.\n\nSo, we get something like 0 0 1 1 1 0 0 0 1 1 0 0 1. . . Suppose that we are given such a sequence $s(J)$ for some $J$ and some $\\alpha$. By the Ergodic Theorem one gets the measure of arc $J$ as the limit\n\n$\\mathtt{meas}(J)=2\\pi\\underset{n\\rightarrow\\infty}{\\lim}\\frac{\\sigma_{n}}{n}$ where $\\sigma_{n}$ is the number of 1's in ${s_{1},s_{2},...,s_{n}}$.\n\nOK, but is it possible to detect the \"frequency\" $\\alpha$ only by the 0-1 data contained in the sequence $s_{n}$? More precisely, my question is:\n\nLet $\\{s_{n}\\}$ be a sequence of 0's and 1's and we know that it is an \"indicator sequence\" for some arc $J\\subset\\mathbb{S}^{1}$ and some angle $\\alpha$. Is it then possible to get $\\alpha$ by some formula similar to the above one for the measure of $J$? This would be something like a \"rotation number\" of sequence $\\{s_{n}\\}$.\n\nSimilar question may be posed for the torus $\\mathbb{T}^{n\\text{ }}$and an open set $J\\subset\\mathbb{T}^{n\\text{ }}$. Then we should detect not only the frequencies $\\alpha_{1},\\alpha_{2},...$ but also the \"dimension\" $n$ of the sequence. Here $\\alpha_{1},...,\\alpha_{n},\\pi$ have to be independent over $\\mathbb{Z}$.\n\n[I know that the \"indicator sequence\" is a standard construction in symbolic dynamics, but I am not very involved in the topic, so references are welcome.]\n\nP.S. Curly brackets {} are not displayed in math mode. How to fix the problem?\n\nshare|improve this question\nCurly brackets can be obtained via \\lbrace and \\rbrace. \u2013\u00a0 Andrew Sep 11 '11 at 10:20\n@Andrew @Symbo'leon Or via \\{ and \\}. \u2013\u00a0 Quinn Culver Sep 11 '11 at 15:27\n$S((0,\\alpha))$ forms what is called a Sturmian sequence, a special case of a subshift of finite type. If $J$ is a general interval, than one gets a more general subshift. I still believe, one always has uniqueness. \u2013\u00a0 Helge Sep 11 '11 at 17:23\n@Helge: Sturmian sequences - or, strictly speaking, their orbit closures - are subshifts of infinite type. Subshifts of finite type are those subshifts which can be obtained from the full shift by \"forbidding\" finitely many words, and have special properties not enjoyed by Sturmian shifts. (These days it is usually assumed that the forbidden words are all of length two, which can be achieved by re-coding the alphabet.) \u2013\u00a0 Ian Morris Sep 11 '11 at 21:00\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nIt seems likely to me that $\\alpha$ can be computed by calculating the frequencies of subwords of the coding sequence, but in a manner which depends on certain parameters. For example, if $\\alpha<\\min\\{|J|,2\\pi-|J|\\}$ then the interval $J \\setminus J +\\alpha$ has length precisely $\\alpha$, and it follows easily that $\\alpha$ equals the frequency of the subword 01. On the other hand if $|J|$ is very small and $\\alpha, 2\\pi-\\alpha$ are both larger than $|J|$, then the frequency of the subwords 01 and 10 are both $|J|$, while the subword 00 has frequency $1-2|J|$, and we cannot gain anything by considering words of length 1 or 2. So the frequencies of words of arbitrary length probably need to be considered.\n\nThe articles \"Coding rotations on intervals\" by Berstel and Vuillon, and \"Three-distance theorems and combinatorics on words\" by Alessandri and Berth\u00e9 appear to be relevant (especially Lemma 1 in the latter) but do not seem to yield a complete answer.\n\nshare|improve this answer\nadd comment\n\nUnless I am missing something you can just compute $\\lim_{N\\rightarrow \\infty} \\frac{1}{N}\\sum a_k \\exp(2 \\pi i k s)$ to find the Fourier transform of the characteristic function of the interval J, and then do an inverse transform to find J. This is more-or-less what you suggest about computing a rotation number.\n\nshare|improve this answer\nWhat I said above was not quite what you asked - let me try again. The above should give you the Fourier transform with argument $\\frac{s}{\\alpha}$. From this and knowledge of the Fourier transform of an interval you can recover $\\alpha$. \u2013\u00a0 Jared Bronski Sep 11 '11 at 23:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/543131/probability-of-a-result-from-3d6-lowest-to-highest\nText:\nTake the 2-minute tour \u00d7\n\nI have a fascination with tabletop sports games, and through that, I've developed an interest in probability. That said, it's not my strong suit, so I wanted to pose this question because I think involves a few different probability principles to solve it.\n\nHere's the premise...the game uses a roll of 3d6 to determine the result of a play. The dice are read from lowest to highest, as in:\n\na roll of 3, 6, 2 would be 2-3-6 a roll of 1, 4, 1 would be 1-1-4 etc.\n\nThat roll is then looked up on a chart to determine the result.\n\nI was curious about the probability of different results coming up so that if I wanted to make a house rule, I would know which result would be the best place to modify.\n\nSo, what I do know is that for probability, you multiply chances together, correct? So without the low to high rule I discussed above, any number would have a 1/6 * 1/6 * 1/6 chance of occurring, correct?\n\nHow would I apply this principle to any result? My guess is something like:\n\n1-1-4 = 1/6 * 1/6 * 5/6\n\nonly one chance for the first 2 die, and the last can be anything but 1, so 5 remaining numbers\n\n2-3-6 = 1/6 * 4/6 * 4/6\n\nfirst number can be 2 only = 1/6\n\nsecond number can be any number but 2 or 6 = 4/6\n\nsecond number can be any number but 2 or 3 = 4/6\n\nAm I understanding this correctly?\n\nshare|improve this question\nThis is the kind of thing that's really easy to get the computer to do. Complete results are here. \u2013\u00a0 MJD Oct 28 '13 at 18:32\nWouldn't $3,6,2$ be $2-3-6?$ \u2013\u00a0 Ross Millikan Oct 28 '13 at 18:37\nRoss, you're correct, I swear I had that typed correctly when I first posted it incorrectly on the main stack overflow page. I'll fix it... \u2013\u00a0 tjans Oct 29 '13 at 12:53\nadd comment\n\n1 Answer\n\nYour answer's not correct. For 1-1-4, you have multiplied by $\\frac56$, but it's not clear to me why. The correct calculation goes like this: there is a $\\frac16$ probability of getting a 1 on the first die, a $\\frac16$ probability of getting a 1 on the second die, and a $\\frac16$ (not $\\frac56$) probability of getting a 4 on the third die. This multiplies out to $\\frac1{216}$. But there are three different orders in which the rolls could occur to give a result of 1-1-4, since 1-4-1 or 4-1-1 give the same result. So you must multiply the $\\frac1{216}$ by 3, for a final result of $\\frac1{72}$.\n\nSimilarly, the result for 2-3-6 is again $\\frac1{216}$, but this time multiplied by 6 because there are 6 different orders in which the 2, 6, and 3 can appear; the final result is $6\\cdot\\frac1{216}=\\frac1{36}$.\n\nIn general, the answer is as follows: if the pattern you're looking up is XXX, with all three dice the same, the probability is $\\frac1{216}$. If the pattern is XXY or XYY, the probability is $\\frac1{72}$. And if the pattern is XYZ, the probability is $\\frac1{36}$.\n\nshare|improve this answer\nThe 5/6 was me overthinking things. I'll save me the embarrassment by not explaining why I thought it'd be 5/6 :) \u2013\u00a0 tjans Oct 29 '13 at 12:56\nfor 1-1-4, how are there 3 possibilities? Wouldn't there be 6 different ways for that as well, as each die is independent of the other? 1a-1b-4, 1a-4-1b, 1b-1a-4, 1b-4-1a, 4-1a-1b, 4-1b-1a \u2013\u00a0 tjans Oct 29 '13 at 13:03\nSuppose the three dice were red, blue, and green. The 4 can be on the red die, the blue die, or the green die; that's 3 ways. Saying that a green 4, a red 1 and a blue 1 is somehow different from a green 4, a blue 1 and a red 1 makes no sense at all. \u2013\u00a0 MJD Oct 29 '13 at 14:35\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/59009/no-complexity-class-contains-all-recursive-languages\nText:\nTake the 2-minute tour \u00d7\n\nI want to prove that there does not exist some complexity class that contains all recursive languages.\n\nAny complexity class C is defined by a complexity measure $\\Phi$ (according to Blum axioms) and a total recursive function f:N $\\rightarrow$ N. So there does not exists C that contains all languages L for which there exists a Turing Machine M that decides L and for all x $\\Phi$(M,x)<=f(|x|).\n\nAny ideas?\n\nshare|improve this question\nI don't get it; doesn't the class R contains all the recursive languages? en.wikipedia.org/wiki/R_(complexity) \u2013\u00a0 Hsien-Chih Chang \u5f35\u986f\u4e4b Mar 21 '11 at 10:06\nThe author means a complexity class in the sense of Blum - en.wikipedia.org/wiki/Blum_axioms \u2013\u00a0 Fran\u00e7ois G. Dorais Mar 21 '11 at 10:38\nThank you Fran\u00e7ois! \u2013\u00a0 Hsien-Chih Chang \u5f35\u986f\u4e4b Mar 21 '11 at 11:02\nHave you looked at en.wikipedia.org/wiki/Blum%27s_speedup_theorem ? \u2013\u00a0 Andr\u00e1s Salamon Mar 21 '11 at 22:49\nThanks for your answer Andr\u00e1s but I really can't see how the speed up theorem implies that C can't exist. \u2013\u00a0 user13788 Mar 22 '11 at 15:34\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nLet $\\langle M_i\\rangle$ be an enumeration of all Turing Machines (TM) and $\\langle f_i\\rangle$ the corresponding ($f_i=f_{M_i}$) enumeration of the functions in $RE$. Suppose there is an $f\\in REC$ such that all the recursive languages are in the complexity class $\\mathcal{C}(f)=${$f_i\\in RE:\\forall x\\ \\Phi(i,x)\\leq f(x)$}.\n\nHere are two ways you can prove this is not possible:\n\n1) $\\Phi(i,x)=y$ is $REC$, thus let $N$ be the TM which computes it. We can use $N$ to construct a new TM $N'$ which takes as input $i$, then calculates $\\Phi(i,x)=y$ for every $x$ and all $y\\leq f(x)$ and it halts iff for some $x$, $\\Phi(i,x)=y$ is false for all $y\\leq f(x)$ or $rng(f_i(x))\\nsubseteq${$0,1$}.\n\nHaving a closer look on $N'$, we see that it recognizes exactly the language\n\n$TOT'=${$i\\in\\mathbb{N}:f_i\\mbox{ not total}\\vee f\\mbox{ is not a relation}$}.\n\nThus $TOT'\\in RE$ which can not be true because it is $\\Sigma_2$-complete. ($\\Sigma_2$ contains the relations which are $RE$ given a $co-RE$ oracle).\n\n2) We use the Recursive Relatedness Theorem, i.e.\n\nSuppose $\\Phi,\\Psi$ be complexity measures. Then there exists an $r(x,y)\\in REC$ s.t.:\n\n(i) $\\forall x,y\\ r(x,y)< r(x,y+1)$;\n\n(ii) $\\forall i\\ \\forall^* x\\ \\Phi(i,x)\\leq r(x,\\Psi(i,x))$; ($\\forall^*$ means for all but finitely many)\n\n(iii) $\\forall i\\ \\forall^* x\\ \\Psi(i,x)\\leq r(x,\\Phi(i,x))$.\n\n(This says roughly that the one measure is bounded by the other using a REC function.)\n\nLet $\\Phi$ be the measure under consideration and $T$ the usual masure of time complexity. By (iii), $T(i,x)\\leq r(x,\\Phi(i,x))$ and since $r$ is increasing for $y$ and $\\Phi(i,x)\\leq f(x)$, we get that $T(i,x)\\leq r(x,f(x))$ for all $i$ s.t. $f_i\\in \\mathcal{C}(f)$.\n\n$r(x,f(x))$ is recursive hence we can get a TM $M_{i_0}$ which given an input $x$ moves $r(x,f(x))+1$ times and halts with output $0$. $f_{i_0}$ realizes a recursive language so it is in $\\mathcal{C}(f)$, which means that $\\forall^* x\\ r(x,f(x))+1=T(i_0,x)\\leq r(x,f(x))$. But this is a contradiction.\n\nIf you want to see the proof that $TOT'$ is $\\Sigma_2$-complete (actually that $TOT=\\mathbb{N}\\setminus TOT'$ is $\\Pi_2$-complete. $TOT$ contains functions instead of relations but you can easily reduce the one to the other) you can check it in p.224 of Computability, complexity and languages of Martin Davis.\n\nInside the same book, you can find the proof of the recursive relatedness theorem in p.422. Actually the whole chapter (14) contains some useful results on abstract complexity.\n\nshare|improve this answer\nThank you Marios! \u2013\u00a0 user13788 Apr 1 '11 at 0:14\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/165625/restoring-a-point-after-transformation\nText:\nTake the 2-minute tour \u00d7\n\nI am given a point $ \\begin{bmatrix} u & v \\end{bmatrix}^T $ which I know is in form $\\begin{bmatrix} \\frac{x}{f(r)} & \\frac{y}{f(r)} \\end{bmatrix}^T$ where $f(r)$ is polynomial function, $f(r)=a_nr^n + \\cdots + a_1r + a_0$ and $r=\\sqrt{x^2+y^2}$.\n\nI want to restore $x$ and $y$ given $u$ and $v$. What I have done so far is below.\n\n$$ u = \\frac{x}{f(r)}\\\\ v = \\frac{y}{f(r)}\\\\ $$\n\nIf we square both equations and sum them we get:\n\n$$ \\tag{1} f(r) = \\frac1{\\sqrt{u^2+v^2}}r $$\n\nWhich is:\n\n$$ a_nr^n + \\cdots + \\left(a_1 - \\frac1{\\sqrt{u^2+v^2}}\\right) r + a_0 = 0 $$\n\nI can find the roots of a polynomial using roots() in MATLAB. Then using Equation 1 I can find the value of $f$ and then $u$ and $v$.\n\nWhen I try this with a numerical example with known polynomial coefficients I cannot restore $x$ and $y$ given $u$ and $v$, the results I am getting do not match. Am I missing something here?\n\nI can provide the coefficients and the numbers I am using if needed.\n\nUpdate: Here are my values which are not working. First polynomial coefficients $a_0, a_1, a_2$ are $-174.4486, 0, 0.0026$ respectively. Lets start with an original point $p = \\begin{bmatrix} \\frac{50}{-161.4486} & \\frac{50}{-161.4486}\\end{bmatrix}^T$. Observe that $p$ is in form described above where $f(r) = -161.4486$, you can calculate if you don't believe me :). Now my given point becomes $\\begin{bmatrix}-0.3097 & -0.3097\\end{bmatrix}^T$, using only this I want to find $x=50$ and $y=50$. Lets start. We calculate:\n\n$$\\frac1{\\sqrt{u^2+v^2}} = 2.2832$$\n\nWe put it into the polynomial and find the roots which are $r_1= 948.875$ and $r_2=-70.7107$. Since we know $r$ is non negative we choose $r_1$, plug it into the Equation 1 and we get $f(r)=2166.5$ put it into the equations we get $-671$ for $x$ and $y$. Before calculating those values we can understand something is wrong just looking at $r$, it is not the correct value which is $70.7107$.\n\nshare|improve this question\nAs Christian Blatter's answer shows, this procedure ought to work to get you the right solution. I think you should go ahead and provide the numbers you're working with; maybe then we can pinpoint the error. \u2013\u00a0 Rahul Jul 2 '12 at 21:24\n@RahulNarain I provided the actual values. \u2013\u00a0 nimcap Jul 3 '12 at 15:23\n@nimcap: The mistake is in your equation $(1)$. The correct version is equation $(4)$ in my edited answer. \u2013\u00a0 Christian Blatter Jul 3 '12 at 18:06\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\n\nThe values of $u$ and $v$, and therefore $u^2+v^2$, are given to you, and you want to find $x$, $y$ such that $$(u,v)=\\Bigl({x\\over f(r)}, {y\\over f(r)}\\Bigr)\\ ,\\qquad r:=\\sqrt{x^2+y^2}\\ .\\qquad(2)$$\n\nIt follows that we necessarily have $$x=f(r)u\\ , \\quad y=f(r)v\\qquad(3)$$ and therefore $$r^2=(u^2+v^2)f^2(r)\\ .\\qquad(4)$$\n\nThis equation only involves given data and the unknown $r$. Solving it produces a list of values $r_k>0$ (and maybe some other solutions), and to each of these $r_k$ by $(3)$ correspond values $$x_k= u f(r_k)\\ ,\\quad y_k=v f(r_k)\\ .\\qquad(5)$$ Now $(5)$ is just a necessary condition that solutions of the original equation $(2)$ would have to fulfill, and we have to prove that such pairs $(x_k,y_k)$ are in fact solutions of $(2)$, i.e., satisfy $$(u,v)=\\Bigl({x_k\\over f\\bigl(\\sqrt{x_k^2+y_k^2}\\bigr)},{y_k\\over f\\bigl(\\sqrt{x_k^2+y_k^2}\\bigr)}\\Bigr)\\ .$$ To this end we argue as follows: If $x_k$ and $y_k$ are given by $(5)$, where $r_k>0$ is a solution of $(4)$, then $$x_k^2+y_k^2=(u^2+v^2)f^2(r_k)=r_k^2\\ .$$ As $r_k>0$ it follows that $\\sqrt{x_k^2+y_k^2}=r_k$ and therefore $${x_k\\over f\\bigl(\\sqrt{x_k^2+y_k^2}\\bigr)}={x_k\\over f(r_k)}=u\\ ,$$ and similarly for $y$ resp. $v$.\n\nshare|improve this answer\nI believe that my problem has something to do with squaring and square rooting. I lose or introduce solutions that are not true by doing that, but I can't explain. \u2013\u00a0 nimcap Jul 2 '12 at 19:05\nthank you, it seems I had problem with extraneous solutions, which I forgot about the whole thing by not practicing algebra regularly. \u2013\u00a0 nimcap Jul 3 '12 at 20:28\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/85008/changing-divergent-series-to-convergent-by-re-ordering-denominators\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $a_n$ is strictly decreasing and positive and $\\sum_{n>1}a_n/n=\\infty$, let $g:\\mathbb N\\to\\mathbb N$ be a bijection between the positive integers, can we have $\\sum_{n>1}a_n/g(n)<\\infty$?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nIf $a_n$ goes to zero, choose a subsequence whose $n$th term is smaller than $1/n$.\n\nNow, for any index that is not a power of two, pair up $1/n$ with the term of the subsequence that is smaller than $1/n$.\n\nThe sum of these terms is smaller than $\\sum \\frac 1 {n^2}=\\pi^2/6$.\n\nPair up the remaining $a_n$ with the remaining $1/2^k$. This gives a series that is smaller than $\\sum a_1 \\frac 1 {2^n}=a_1$. (The $a_n$ are decreasing and bounded by $a_1$.)\n\nSince everything is positive, this implies that the series converges.\n\nshare|improve this answer\nThe idea is to form one subsequence that uses \"few\" $a_n$ and \"many\" $1/n$ so that $a_n$ is small and makes the product small, and another subsequence that uses \"many\" $a_n$ and \"few\" $1/n$ so that $1/n$ is small and makes the product small. This is the same idea as in David's answer, of course. \u2013\u00a0 Phira Nov 23 '11 at 19:10\n\nWe may assume, $a_n\\searrow 0$ (otherwise, you can't do it).\n\nChoose a subsequence $\\{a_{n_k}\\}$ with $a_{n_k}\\le {1\\over 2^k}$.\n\nWe write our new sequence: $a_1/2, a_2/4, \\ldots, a_{n_1-1}/2^{n_1-1}$\n\nThe next term is $a_{n_1}/1$.\n\nFor terms after $a_{n_1}$ and before $a_{n_2}$ we continue dividing by powers of 2.\n\nThe next term is $a_{n_2}/ 3$.\n\nIn general:\n\nTerms $a_i$ that are not a term of the subsequence are divided by $2^i$. The series formed by these terms will converge since the $a_i$ are decreasing and $\\sum{1\\over 2^n}$ converges\n\nA term $a_{n_k}$ is divided by the first integer that hasn't been used to that point. The series form by these terms clearly converges, since $a_{n_k}\\le 2^{-k}$ and we made the terms smaller.\n\nThus, the resulting series of nonnegative terms converges.\n\nI think this works. I'd try to formalize it; but I'm sure I would just make a mess of things...\n\nshare|improve this answer\nhum, but isn't the whole problem that the terms that are not terms of the subsequence may be very, very numerous ? it doesn't matter that you divide them by powers of 2 (say less than 2^n_k) if there are way more than 2^n_k of them... For this reason I actually think it is false (but definitely not trivial !) \u2013\u00a0 Glougloubarbaki Nov 23 '11 at 19:09\nThose terms are bounded, and the series formed by those terms would converge since $\\sum 2^{-n}$ converges. \u2013\u00a0 David Mitra Nov 23 '11 at 19:14\nit's hard to say it precisely, but if you take $a_n = 1/(\\ln(1+ \\ln(1+ \\ln(1+ n))))$ the number of terms before $a_n < 1/4$ is monstruous, and you'll end up with a sum of an enourmous number of terms of the size $1/4 /(\\ln(1+ \\ln(1+ \\ln(1+ n))))$ which is not so small, and so on at every stage, so that the sum will not converge. \u2013\u00a0 Glougloubarbaki Nov 23 '11 at 19:15\nI am also led to a similar conclusion. If it needs to formalize, one may do like this: Suppose $a_n \\downarrow 0$. Let $(x_{n})$ be an increasing sequence so that both $a_{x(k)} \\leq 2^{-k}$ and $x(k) \\geq 2^{k}$. Also let $(y_{n})$ be the enumeration of the set $\\mathbb{N} - \\{ x_n : n \\in \\mathbb{N} \\}$ in increasing order. Then define $$g(n) = \\begin{cases} x(k) & \\text{if} \\ n = y(k) \\\\ y(k) & \\text{if} \\ n = x(k) \\end{cases}.$$ Then $$\\sum_{n \\geq 1} \\frac{a_n}{g(n)} = \\sum_{k \\geq 1} \\frac{a_{x(k)}}{y(k)} + \\sum_{k \\geq 1} \\frac{a_{y(k)}}{x(k)},$$ which clearly converges. \u2013\u00a0 sos440 Nov 23 '11 at 19:18\nok, you're right \u2013\u00a0 Glougloubarbaki Nov 23 '11 at 19:25\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/56874/equation-for-the-family-of-lines-that-passes-through-3y-5x-10-0-and-3y-frac/56938\nText:\nTake the 2-minute tour \u00d7\n\nFind an equation for the family of lines that passes through the intersection of $3y-5x-10=0$ and $3y-\\frac{x}{3}-\\frac{5}{3}=0$\n\nshare|improve this question\n\n3 Answers 3\n\nI think it's $$\\displaystyle k \\left(3y-5x-10 \\right)+m \\left(3y-\\frac{x}{3}-\\frac{5}{3} \\right)=0$$ where $k$ and $m$ are not all zero.\n\nshare|improve this answer\n\nLet us denote by $L = L(a, b, c)$ the line $ax + by + c = 0$. $(a, b, c)$ can be considered a 3-dimensional vector $v$ and all lines can be represented by the 3-dimensinal vector space $R^3$. The bundle of lines $L(a, b, c)$ passing through the intersection $(i, j)$ of the given lines $L_1 = L(a_1, b_1, c_1)$ and $L_2 = L(a_2, b_2, c_2)$ satisfy\n\n$$a i + b j + c = 0$$\n\nSo, the vectors $v$ corresponding to this bundle lie in a 2-dimensional subspace $R^2$. $v_1 = (a_1, b_1, c_1)$ and $v_2 = (a_2, b_2, c_2)$ are also in this subspace because they satisfy the above restriction. Moreover, they are linearly independent (because the 2 lines cross) and hence they span this subspace. Therefore $v$ must be a linear combination of $v_1$ and $v_2$: $$v = \\lambda_1 v_1 + \\lambda_2 v_2$$. So, the bundle lines are given by $$L(\\lambda_1 a_1 + \\lambda_2 a_1, \\lambda_1 b_1 + \\lambda_2 a_2, \\lambda_1 c_1 + \\lambda_2 c_2)$$ $$ = \\lambda_1 L_1 + \\lambda_2 L_2$$ because $L$ is a linear form. The line equation of these lines is $$\\lambda_1 L_1 + \\lambda_2 L_2 = 0$$ (as used without proof in another answer). Now, we should divide by $\\lambda_1$ to get the family of bundle lines parametrized by one parameter $\\lambda$: $$L_1 + \\lambda L_2 = 0$$\n\nshare|improve this answer\n\nFind the intersection of $3x - 5y - 10 = 3x - \\frac{x}{3} - \\frac{5}{3}$, it should be a point in the plane $(a,b)$, then shift the origin to $(a,b)$.\n\nFor example, $x=y$ becomes $(x-a)=(y-b)$, to make it have an arbitrary slope $m$, just scale the left hand side of the equation to get $(x-a)m=(y-b)$, so the family of all lines that go through the point $(a,b)$ (except the vertical one) is given by $\\{(x,y) \\text{ } | \\text{ } (x-a)m=(y-b), m\\in\\mathbb{R} \\}$.\n\nIn your example, $(a,b) = \\left(\\frac{5}{14},-\\frac{25}{14}\\right)$, here are some of the lines in that family, sampled by selecting $m$ values from $[-5,5]$.\n\nLines passing through the point $\\left(\\frac{5}{14},-\\frac{25}{14}\\right)$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/23053/constructing-the-most-general-two-particle-spin-interaction-with-su2-symme\nText:\nTake the tour \u00d7\n\nSuppose I want to write down an interaction term for an action for spin 1/2 fermions that is $SU(2)$-symmetric.\n\nI start from the most naive general form of such an action: $$S_{int} ~=~ \\int_{4321} \\sum_{\\alpha \\beta \\gamma \\delta} \\bar \\psi(4)_\\alpha \\bar \\psi(3)_\\beta \\psi(2)_\\gamma \\psi(1)_\\delta V(4,3,2,1)_{\\alpha \\beta \\gamma \\delta}$$\n\nwhere the indices $1$ to $4$ stand for momenta and frequencies of my fermions.\n\nNow I want to find the form $V$ must have in order to be $SU(2)$ symmetric. By transforming the fermion fields and demanding that the action must stay invariant under that, I can show that $V$ must transform as $$V_{\\alpha' \\beta' \\gamma' \\delta'} ~=~ \\sum_{\\alpha\\beta\\gamma\\delta} R^\\dagger_{\\alpha \\alpha'} R^\\dagger_{\\beta \\beta'} R_{\\gamma \\gamma'} R_{\\delta \\delta} V_{\\alpha \\beta \\gamma \\delta}$$ where $R \\in SU(2)$.\n\nWell, and now I'm stuck continuing from here. Using some handwaving I think I could argue that $V$ must preserve total spin and also total spin in $z$-direction I could probably argue that $V$ can only scatter triplets to triplets, singlets to singlets, and also can't change the $z$-component of the triplet, but I would rather use a more rigorous approach.\n\nWhich will probably involve irreducible representations? I could probably get to the singlet/triplet statement above by noting that $SU(2)$ will transform multiplets into the same multiplet, so the singlet would be invariant under $SU(2)$ and the triplets would somehow mix. But why is it appropriate then to look at an \"ingoing\" singlet or \"ingoing\" triplet formed by indices $\\gamma$ and $\\delta$ as opposed to forming such states with, e.g., indices $\\alpha$ and $\\gamma$?\n\nADDENDUM: Well, I guess I can also start with the spins in a different basis: Assuming that I can put the two \"ingoing\" and the two \"outgoing\" spins into either a singlet or one of three triplets, I guess I can write the action as $$S \\sim \\int_{1234} \\sum_{jm j'm'} (\\bar \\psi(4) \\bar \\psi(3))_{jm} (\\psi(2) \\psi(1))_{j'm'} V(4,3,2,1)_{jm;j'm'}$$ Then I can first argue that due to conservation of total spin we require $j = j'$. And then for $V$ I can look at singlet-singlet scattering and triplet-triplet scattering separately: For $j = j' = 0$, $m$ must be $0$ and so $V$ is a scalar, invariant under $SU(2)$, But for $j = j' = 1$, the states with $m = 0, \\pm 1$ transform into each other in some way, and thus I must work a bit harder to get the symmetry right. I'll think about this, but in the meantime I'm open for more suggestions.\n\nshare|improve this question\nIs your action going to be renormalizable? In how many dimensions? It's worth noting that in 3+1D renormalizability limits you to no more than two fermion fields in a single term (because each has dimension 3/2, and you need to have dimension 4 total). \u2013\u00a0 David Z Mar 30 '12 at 21:31\nIt's for a condensed matter system so I don't worry about renormalizability; I'll always assume that there is a \"natural\" cut-off \u2013\u00a0 Lagerbaer Mar 30 '12 at 22:10\nOh, OK. Ignore me then :-) \u2013\u00a0 David Z Mar 30 '12 at 23:21\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThis is very much a quick and dirty answer, I havn't though too much about it. I might update my answer if I find time in the weekend, otherwise I hope others will give more precise answers.\n\n$V_{\\alpha\\beta\\gamma\\delta}$ transforms reducibly under $SU(2)$, as tensor products of four spin $\\frac 12$ representations. Using $\\bf\\frac 12\\otimes\\frac 12 = 0 \\oplus 1$ and $\\bf 1\\otimes 1 = 0 \\oplus 1 \\oplus 2$, we find that $V_{\\alpha\\beta\\gamma\\delta}$ decomposes into these irreducible representations $$\\mathbf{\\frac 12\\otimes\\frac 12\\otimes\\frac 12\\otimes\\frac 12} = (2\\times\\mathbf{0})\\oplus (3\\times \\mathbf{1}) \\oplus \\mathbf{2},$$ two singlets, three triplets and a spin 2 (5-dimensional representation). There is an action of the permutation group $S_4$ on the indices of $V_{\\alpha\\beta\\gamma\\delta}$, for $SU(N)$ it turns out that decomposing this tensor into irreducible representations of the permutation group also corresponds to irreducible representations of $SU(N)$. This can be done rather quickly using Young Tableau, you can find the details in most representation theory books for physicists (I don't have a relevant book here and don't remember the details. I might add the answer in the weekend). In the case of a tensor product $\\bf 1\\otimes 1 = 0\\oplus 1\\oplus 2$, we get the following decomposition\n\n$$ T_{ij} = \\delta_{ij}\\frac{tr(T)}3 + \\left(\\frac{T_{ij}-T_{ji}}2\\right) + \\left(\\frac{T_{ij}+T_{ji}}2 - \\delta_{ij}\\frac{tr(T)}3\\right).$$ These three terms transform irreducibly as spin $0$, spin $1$ and spin $2$ representations of $SU(2)$, respectively. In terms for the permutation group, these are the trivial, anti-symmetric and trace less symmetric representations, respectively.\n\nSomething similar can be done for $V_{\\alpha\\beta\\gamma\\delta}$, by using Young Tableau or just by playing around with it.\n\nshare|improve this answer\nHm, when you decompose $V$ into irreducible representations you combine all four spins into total spins of $0$, $1$ or $2$. But should I, given that two of the spins transform in one direction and the other two into the \"opposite\" direction, keep the spins whose operators have a \"bar\" on top separate from those without the bar, i.e. $(0 \\oplus 1) \\otimes (0 \\oplus 1)$? \u2013\u00a0 Lagerbaer Mar 30 '12 at 22:48\nMh, I think I'm just a bit confused. Maybe for clarification: When my general operator $V_{\\alpha\\beta\\gamma\\delta}$ is decomposed as you describe, are then the two singlets the only parts that are invariant under rotation as they transform like scalars? Or am I getting things completely wrong? \u2013\u00a0 Lagerbaer Mar 31 '12 at 5:01\nYou were right; the fact that I get two terms in the action that transform like singlets is related to the irreducible representations: One singlet is obtained by combining two singlets, the other is obtained by combining two triplets. \u2013\u00a0 Lagerbaer Apr 4 '12 at 18:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/12899/charged-particle-close-to-a-charged-black-hole-what-happens\nText:\nTake the tour \u00d7\n\nLet's assume the Reissner\u2013Nordstr\u00f6m metric (charged black hole, non-rotating), for simplicity. The black hole is charged with a powerful electric charge. There's a particle nearby, of non-zero mass, let's say an electron, its charge being the same sign like the black hole's charge. The particle's initial speed, relative to the BH, is zero. The particle is close to the event horizon, but still outside of it.\n\nThe question is - what happens? Are there any combinations of parameters where the particle starts falling in, but stops before being swallowed? Or even repulsed outright? If so, any quantitative, intuitive examples?\n\nI'm asking because I know how easily intuition can get deceived by General Relativity, and doing the math involving the R-N metric is probably not feasible for me now. :)\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet's say the black hole has mass and charge $Q$ and $M$, and the electron has $m$ and $q$. An extremal black hole has $|Q|=2M$ (in the appropriate units). An electron has $|q| \\gg 2m$ in the same units. If the electron fell into a negatively charged extremal R-N black hole, then the black hole would have $|Q| > 2M$, which would make it more than extremal. This would cause it to be a naked singularity, which would be exciting, since it would be a counterexample to the cosmic censorship hypothesis; but I'm pretty sure there is no such trivial counterexample, since cosmic censorship is still alive and kicking, decades after being conjectured. Another way of seeing that it will be repelled is that extremal R-N black holes with like charges do not interact; their gravitational attraction exactly cancels their electrostatic repulsion. Since the electron has a greater $|q|/m$, it will definitely be repelled.\n\nOne thing to watch out for in this kind of situation is that different observers can disagree on the direction of the forces. For example, a light ray that falls radially into a black hole experiences a repulsion at certain points as measured in Schwarzschild coordinates. This is the famous \"Hilbert repulsion\" beloved of kooks like Angelo Loinger. The light ray nevertheless passes through the horizon, and local observers never see a repulsion -- McGruder, Gravitational repulsion in the Schwarzschild field, Phys. Rev. D 25, 3191\u20133194 (1982).\n\nshare|improve this answer\nIs it really the case that CCH is alive? I think I recall reading multiple times that there's no problem constructing non-pathological solutions that violate it. Moreover, there doesn't seem any reason to require it to be true (except in the wonderland where people assume GR is all there is to physics and singularity is in any sense physical). \u2013\u00a0 Marek Jul 28 '11 at 19:16\n@Marek: I don't know any more about its current status than what the WP article en.wikipedia.org/wiki/Cosmic_censorship_hypothesis says. There's a weak version and a strong version, and each can be true or false independent of the other. There are issues with how to define the hypothesis correctly. If it does hold, then it has to depend on some energy condition, but we know that basically all energy conditions fail under some circumstances. Re assuming \"GR is all there is to physics,\" I disagree philosophically. If we can prove existence or nonexistence of singularities,[...] \u2013\u00a0 Ben Crowell Jul 28 '11 at 19:27\n[...continued...] that really does mean something. For instance, the Hawking singularity theorem doesn't guarantee that the big bang singularity was a physical singularity, but it does suggest that the universe got to somewhere around the Planck density, which is a nontrivial inference. In any case, I strongly doubt that there is such a trivial counterexample as dropping an electron into an extremal R-N black hole. \u2013\u00a0 Ben Crowell Jul 28 '11 at 19:28\nI don't quite follow. To get at BB singularity all you need is right FLRW solutions (which follow from the parameters obtained from observations), no need to invoke Hawking. Moreover, BB is one and only special event in this universe completely unrelated to any other BH out there. By the way, I agree that showing existence of singularities is very important -- it shows the theory is breaking down which implies new exciting physics is lurking close by. But there's no need to prevent them from happening. FWIW, I agree with your last sentence though. \u2013\u00a0 Marek Jul 28 '11 at 19:39\nFRW assumes perfect homogeneity and isotropy. The Hawking singularity theorem applies when there is not perfect homogeneity and isotropy. \u2013\u00a0 Ben Crowell Jul 28 '11 at 23:02\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/109420/is-this-a-known-solvable-problem-system-of-algebraic-equations?answertab=active\nText:\nTell me more \u00d7\n\nHi there,\n\nI am trying to find complex solutions with positive real part $\\{t_j \\;|\\;{\\rm Re}\\;t_j>0, j = 1, 2, 3, \\dots, n\\}$ of the system of equations $$0 = 1 + \\sum_j \\left(t_j^{2l+1} + {t_j^*}^{2l+1}\\right),\\; l = 1,2,3,\\dots m.$$ Where for a given $n$ I would like to make $m$ as large as possible. Since, this system is non-analytic and thus for $n=m$ most likely under-constrained, I had the idea to just fix the magnitude of all solutions to 1: $t_j = e^{i\\phi_j}$ with $-{\\pi\\over 2} < \\phi_1 \\le \\phi_2 \\le \\dots \\le \\phi_n <{\\pi\\over 2}$. In terms of these the system becomes: $$0 = 1 + 2\\sum_j \\cos{\\left[\\phi_j(2l+1)\\right]},\\; l = 1,2,3,\\dots n.$$ This definitely has solutions up to $n=m=2$, but already for $n=3$, my naive attempt at numerically solving this (Mathematica's NSolve) is taking quite long. Is there some better way to find or at least confirm the existence of such solutions?\n\nThanks, Nik\n\nshare|improve this question\nWhat is $t_j^*$? Is that the complex conjugate? \u2013\u00a0 Gerry Myerson Oct 11 '12 at 22:34\nSo letting $\\phi_0=1$ and $\\phi_{-i}=-\\phi_i$ you want that for $0 \\le \\ell \\le m$ the values $(e^{i\\phi_k})^{2\\ell+1}$ for $-n \\le k \\le n$ to have average real part $0$. If they were, in each case, equally distributed around the unit circle, that would suffice. \u2013\u00a0 Aaron Meyerowitz Oct 12 '12 at 0:42\nGerry, yes that is correct, I should have said that! \u2013\u00a0 nik Oct 12 '12 at 15:15\nAaron, yes, but is it possible to use those considerations to construct solutions with ${-\\pi\\over2} < \\phi_j < {\\pi\\over 2}$? I.e. they must lie in the positive half-plane. \u2013\u00a0 nik Oct 12 '12 at 15:22\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nI would try to get rid of the trigonometric functions, and rather rewrite the system as a polynomial system. If $x_j=\\cos(\\phi_j)$, then $\\cos(\\phi_j(2\\ell+1))=T_{2\\ell+1}(x_j)$, where $T_k$ is the $k$-th Chebychev polynomial of degree $k$. So your system of equations is \\begin{equation} 0=1+2\\sum_j T_{2\\ell+1}(x_j),\\;\\;l=1,2,\\dots,m, \\end{equation} with the requirement that $0<x_j\\le 1$. Such a system can be discussed via Groebner bases, see here how to do that with Sage. For $m=n\\le4$ there are only finitely many solutions. Among them pick those which fit your inequalities. For instance, for $m=n=4$, an approximation of a solution seems to be \\begin{align*} x_1 &= 0.963494595276259\\\\ x_2 &= 0.852773246361416\\\\ x_3 &= 0.600336170417163\\\\ x_4 &= 0.058262327046178 \\end{align*} Of course, you can use this technique also to handle the original case, where $t_j$ need not have length $1$. For instance, for $n=2$ one can show that $m\\le4$, and and approximate solution for $m=4$ is $t_1=0.466916296430820 + 0.717248344919154i$, $t_2=0.856453001234213 + 0.445264622297009i$.\n\nOne cannot expect simple expressions for the $t_j$. For instance, the absolute values of the $t_j$ are roots of an irreducible (over the rationals) polynomial of degree $60$.\n\nshare|improve this answer\nThanks! That is very helpful! \u2013\u00a0 nik Oct 12 '12 at 15:25\nSo what does the final solution for $m=n=4$ come out to be? \u2013\u00a0 Aaron Meyerowitz Oct 13 '12 at 4:57\n@Aaron: Not sure what you mean. We have $t_j=e^{i\\phi_j}=\\cos(\\phi_j)+i\\sin(\\phi_j)=x_j\\pm i\\sqrt{1-x_j^2}$. Since nik adds $t_j^{2\\ell+1}$ and its complex conjugate, it does not matter which sign you choose in $\\pm i\\sqrt{1-x_j^2}$ for each $j$. \u2013\u00a0 Peter Mueller Oct 13 '12 at 9:10\nadd comment\n\nConsider the case $m=n=4.$ If we take $t_j=\\cos(\\frac{2j\\pi}{9})+I\\sin(\\frac{2j\\pi}{9})$ then $\\sum_{j=0}^{8}t_j^q= 1 + \\sum_{j=1}^{4} \\left(t_j^{q} + {t_j^*}^{q}\\right)=0$ for $1 \\le q \\le 8.$ This is because the set of values $t_j^q$ is just the nine $9$th roots of unity (or in two cases, the third roots of unity taken three times). Admittedly, this is not exactly what you wanted.\n\nIf you take just the real parts for $j=1,2,3,4$ you get\n\n  \u2022 $t_1=t_1^*=.766044443118979$\n  \u2022 $t_2=t_2^*=.173648177666934$\n  \u2022 $t_3=t_3^*=-.500000000000$\n  \u2022 $t_4=t_4^*=-0.939692620785905$\n\nIt can be seen that this makes $1 + \\sum_{j=1}^4 \\left(t_j^{q} + {t_j^*}^{q}\\right)=0$ correct for $q=1,3,5,7.$\n\nshare|improve this answer\nHmm, maybe I am missing something, but please see my response to your comment above. \u2013\u00a0 nik Oct 12 '12 at 15:24\nadd comment\n\nYour problem may be understood as solving a system of equations and inequalities over $\\mathbb{R}$. It is solvable in the sense that there exists an algorithm to find solutions (e.g. to find a point in every connected component specified by the system just mentioned).\n\nSuch algorithms are desribed, e.g., in this book: \"Algorithms in Real Algebraic Geometry\" by Saugata Basu, Richard Pollack, Marie-Fran\u00e7oise Roy.\n\nHow practical they are at present, is another question.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://michaelnielsen.org/polymath1/index.php?title=Finding_narrow_admissible_tuples&diff=7961&oldid=prev\nText:\nFinding narrow admissible tuples\n\nFrom Polymath1Wiki\n\n(Difference between revisions)\nJump to: navigation, search\nm (Benchmarks)\nm (added asymmetric HR entry for 5453 due to Sun)\nLine 182: Line 182:\n| [ 112,562]\n| [ 112,562]\n| [ 53,774]\n| [ 48,484]\n| [ 48,484]\n\nRevision as of 11:54, 19 June 2013\n\nFor any natural number k0, an admissible k0-tuple is a finite set {\\mathcal H} of integers of cardinality k0 which avoids at least one residue class modulo p for each prime p. (Note that one only needs to check those primes p of size at most k0, so this is a finitely checkable condition.) Let H(k0) denote the minimal diameter \\max {\\mathcal H} - \\min {\\mathcal H} of an admissible k0-tuple. As part of the Polymath8 project, we would like to find as good an upper bound on H(k0) as possible for given values of k0. To a lesser extent, we would also be interested in lower bounds on this quantity. There is some scattered numerical evidence that the optimal value of H is roughly of size k0logk0 + k0 for k0 in the range of interest.\n\n\nUpper bounds\n\nUpper bounds are primarily constructed through various \"sieves\" that delete one residue class modulo p from an interval for a lot of primes p. Examples of sieves, in roughly increasing order of efficiency, are listed below.\n\nZhang sieve\n\nThe Zhang sieve uses the tuple\n\n{\\mathcal H} = \\{p_{m+1}, \\ldots, p_{m+k_0}\\}\n\nwhere m is taken to optimize the diameter p_{m+k_0}-p_{m+1} while staying admissible (in practice, this basically means making m as small as possible). Certainly any m with pm + 1 > k0 works; in particular, one can just take {\\mathcal H} to be the first k0 primes past k0, but this is not optimal. Applying the prime number theorem then gives the upper bound H \\leq (1+o(1)) k_0\\log k_0.\n\nHensley-Richards sieve\n\nThe Hensley-Richards sieve [HR1973], [HR1973b], [R1974] uses the tuple\n\n{\\mathcal H} = \\{-p_{m+\\lfloor k_0/2\\rfloor - 1}, \\ldots, -p_{m+1}, -1, +1, p_{m+1},\\ldots, p_{m+\\lfloor k_0/2+1/2\\rfloor-1}\\}\n\nwhere m is again optimised to minimize the diameter while staying admissible.\n\nAsymmetric Hensley-Richards sieve\n\nThe asymmetric Hensley-Richard sieve uses the tuple\n\n{\\mathcal H} = \\{-p_{m+\\lfloor k_0/2\\rfloor - 1-i}, \\ldots, -p_{m+1}, -1, +1, p_{m+1},\\ldots, p_{m+\\lfloor k_0/2+1/2\\rfloor-1+i}\\}\n\nwhere i is an integer and i,m are optimised to minimize the diameter while staying admissible.\n\nSchinzel sieve\n\nGiven 0 < y < z < x, the Schinzel sieve (discussed in [S1961], [HR1973], [GR1998], [CJ2001]) sieves the interval [1,x] by 1mod p for primes p \\le y and by 0mod p for primes y < p \\le z. Provided that z is large enough (z = k0 clearly suffices), the first k0 survivors form an admissible k0-tuple (but not necessarily the narrowest one in the interval). The case y = 1 corresponds to a sieve of Eratosthenes; if one minimizes z and takes the first k0 survivors greater than 1, this yields the same admissible k0 tuple as Zhang, with the minimal possible value of m.\n\nShifted Schinzel sieve\n\nAs a generalization of the Schinzel sieve, one may instead sieve shifted intervals [s,s + x]. This is effectively equivalent to sieving the interval [0,x] of the residue classes -s\\ \\bmod\\ p for primes p\\le y and  1-s\\ \\bmod\\ p for primes y<p\\le z.\n\nGreedy sieve\n\nWithin a given interval, one sieves a single residue class amod p for increasing primes p=2,3,5,\\ldots, with a chosen to maximize the number of survivors. Ties can be broken in a number of ways: minimize a\\in[0,p-1], maximize a\\in [0,p-1], minimize |a-\\lfloor p/2\\rfloor|, or randomly. If not all residue classes modulo p are occupied by survivors, then a will be chosen so that no survivors are sieved. This necessarily occurs once p exceeds the number of survivors but typically happens much sooner. One then chooses the narrowest k0-tuple {\\mathcal H} among the survivors (if there are fewer than k0 survivors, retry with a wider interval).\n\nGreedy-greedy sieve\n\nHeuristically, the performance of the greedy sieve is significantly improved by starting with a shifted Schinzel sieve on [s,\\ s+x] using y = 2 and z = \\sqrt{x} and then continuing in a greedy fashion, as proposed by Sutherland. One first optimizes the shift value s over some larger interval (e.g. [-k_0\\log\\ k_0,\\ k_0\\log\\ k_0]) and then continues the sieving over primes p > z greedily choosing the best residue class for each prime according to a chosen tie-breaking rule (in Sutherland's original implementation, ties are broken downward in [0,\\ p-1]).\n\nSeeded greedy sieve\n\nGiven an initial sequence {\\mathcal S} that is known to contain an admissible k0-tuple, one can apply greedy sieving to the minimal interval containing {\\mathcal S} until an admissible sequence of survivors remains, and then choose the narrowest k0=tuple it contains. The sieving methods above can be viewed as the special case where {\\mathcal S} is the set of integers in some interval. The main difference is that the choice of {\\mathcal S} affects when ties occur and how they are broken with greedy sieving. One approach is to take {\\mathcal S} to be the union of two k0-tuples that lie in roughly the same interval (see Iterated merging) below.\n\nIterated merging\n\nGiven an admissible k0-tuple \\mathcal{H}_1, one can attempt to improve it using an iterated merging approach suggested by Castryck. One first uses a greedy (or greedy-Schinzel) sieve to construct an admissible k0-tuple \\mathcal{H}_2 in roughly the same interval as \\mathcal{H}_1, then performs a randomized greedy sieve using the seed set \\mathcal{S} = \\mathcal{H}_1 \\cup \\mathcal{H}_2 to obtain an admissible k0-tuple \\mathcal{H}_3. If \\mathcal{H}_3 is narrower than \\mathcal{H}_2, replace \\mathcal{H}_2 with \\mathcal{H}_3, otherwise try again with a new \\mathcal{H}_3. Eventually the diameter of \\mathcal{H}_2 will become less than or equal to that of \\mathcal{H}_1. As long as \\mathcal{H}_1\\ne \\mathcal{H}_2, one can continue to attempt to improve \\mathcal{H}_2, but in practice one stops after some number of retries.\n\nAs described by Sutherland, one can then replace \\mathcal{H}_1 with \\mathcal{H}_2 and begin the process anew, yielding a randomized algorithm that can be run indefinitely. Key parameters to this algorithm are the choice of the interval used when constructing \\mathcal{H}_2, which is typically made wider than the minimal interval containing \\mathcal{H}_1 by a small factor \u03b4 on each side (Sutherland suggests \u03b4 = 0.0025), and the number of failed attempts allowed while attempting to impove \\mathcal{H}_2.\n\nEventually this process will tend to converge to particular \\mathcal{H}_1 that it cannot improve (or more generally, a set of similar \\mathcal{H}_1's with the same diameter). Interleaving iterated merging with the local optimizations described below often allows the algorithm to make further progress.\n\nIterated merging can be viewed as a form of simulated annealing. The set \\mathcal{S} initially contains at least two admissible k0-tuples (typically many more), and as the algorithm proceeds the set \\mathcal{S} converges toward \\mathcal{H}_1 and the number of admissible k0-tuples it contains declines. One can regard the cardinality of the difference between \\mathcal{S} and \\mathcal{H}_1 as a measure of the \"temperature\" of a gradually cooling system, since the number of choices available to the algorithm declines as this cardinality is reduced (more precisely, one may consider the entropy of the possible sequence of tie-breaking choices available for a given \\mathcal{S}).\n\nLocal optimizations\n\nLet \\mathcal H = \\{h_1,\\ldots, h_{k_0}\\} be an admissible k0-tuple with endpoints h1 and h_{k_0}, and let \\mathcal I be the interval [h_1,h_{k_0}]. If there exists an integer h\\in\\mathcal I such that removing one of \\mathcal H's endpoints and inserting h yields an admissible k0-tuple \\mathcal H', then call \\mathcal H contractible, and if not, say that \\mathcal H non-contractible. Note that \\mathcal H' necessarily has smaller diameter than \\mathcal H. Any of the sieving methods described above may produce admissible k0-tuples that are contractible, so it is worth testing for contractibility as a post-processing step after sieving and replacing \\mathcal H by \\mathcal H' if this test succeeds.\n\nWe can also shift \\mathcal H to the left by removing its right end point h_{k_0} and replacing it with the greatest integer h0 < h1 that yields an admissible k0-tuple \\mathcal H', and we can similarly shift \\mathcal H to the right. The diameter of \\mathcal H' need not be less than \\mathcal H, but if it is, it provides a useful replacement. More generally, by shifting \\mathcal H repeatedly we can produce a sequence of admissible k0-tuples that lie successively further to the left or right. In general the diameter of these tuples may grow as we do so, but it will also occasionally decline, and we may be able to find a shifted \\mathcal H' with smaller diameter than \\mathcal H.\n\nA more sophisticated local optimization involves a process of ``adjustment\" proposed by Savitt. Let \\mathcal H be an admissible k0-tuple. For a prime p and an integer a, let [a;p] denote the residue class amod p, i.e. the set of integers {x:x = amod p}. Call [a;p] occupied if it contains an element of \\mathcal H .\n\nSuppose that [a;p] and [b;q] are occupied residue classes, for some distinct primes p and q, and that [a';p] and [b';q] are unoccupied. Let \\mathcal U be the intersection of \\mathcal H with [a;p] \\cup [b;q], and let \\mathcal V be a subset of the integers that lie in the intersection of the interval I containing H and the set [a';p] \\cup [b';q] such that the set \\mathcal H' formed by removing the elements of \\mathcal U from \\mathcal H and adding the elements of \\mathcal V is admissible. A necessary (and often sufficient) condition for and integer v to lie in \\mathcal V is that v must not lie in a residue class [c;r] that is the unique unoccupied residue class modulo r for any prime r other than p or q.\n\nThe admissible set \\mathcal H' lies in the interval \\mathcal I containing \\mathcal H, so its diameter is no greater than that of \\mathcal H, however its cardinality may differ. If it happens that \\mathcal H' contains more elements than \\mathcal H , then by eliminating points at either end of \\mathcal H' we obtain an admissible k0-tuple that is narrower than \\mathcal H and may ``adjust\" \\mathcal H by replacing it with \\mathcal H' . The process of adjustment can often be applied repeatedly, yielding a sequence of successively narrower admissible k0-tuples.\n\nFurther refinements\n\nLower bounds\n\nThere is a substantial amount of literature on bounding the quantity \u03c0(x + y) \u2212 \u03c0(x), the number of primes in a shifted interval [x + 1,x + y], where x,y are natural numbers. As a general rule, whenever a bound of the form\n\n \\pi(x+y) - \\pi(x) \\leq F(y) (*)\n\nis established for some function F(y) of y, the method of proof also gives a bound of the form\n\n k_0 \\leq F( H(k_0)+1 ). (**)\n\nIndeed, if one assumes the prime tuples conjecture, any admissible k0-tuple of diameter H can be translated into an interval of the form [x + 1,x + H + 1] for some x. In the opposite direction, all known bounds of the form (*) proceed by using the fact that for x > y, the set of primes between x + 1 and x + y is admissible, so the method of proof of (*) invariably also gives (**) as well.\n\nExamples of lower bounds are as follows;\n\nBrun-Titchmarsh inequality\n\nThe Brun-Titchmarsh theorem gives\n\n \\pi(x+y) - \\pi(x) \\leq (1 + o(1)) \\frac{2y}{\\log y}\n\nwhich then gives the lower bound\n\n H(k_0) \\geq (\\frac{1}{2}-o(1)) k_0 \\log k_0.\n\nMontgomery and Vaughan deleted the o(1) error from the Brun-Titchmarsh theorem [MV1973, Corollary 2], giving the more precise inequality\n\n k_0 \\leq 2 \\frac{H(k_0)+1}{\\log (H(k_0)+1)}.\n\nFirst Montgomery-Vaughan large sieve inequality\n\nThe first Montgomery-Vaughan large sieve inequality [MV1973, Theorem 1] gives\n\n k_0 (\\sum_{q \\leq Q} \\frac{\\mu^2(q)}{\\phi(q)}) \\leq H(k_0)+1 + Q^2\n\nfor any Q > 1, which is a parameter that one can optimise over (the optimal value is comparable to H(k0)1 / 2).\n\nSecond Montgomery-Vaughan large sieve inequality\n\nThe second Montgomery-Vaughan large sieve inequality [MV1973, Corollary 1] gives\n\n k_0 \\leq (\\sum_{q \\leq z} (H(k_0)+1+cqz)^{-1} \\mu(q)^2 \\prod_{p|q} \\frac{1}{p-1})^{-1}\n\nfor any z > 1, which is a parameter similar to Q in the previous inequality, and c is an absolute constant. In the original paper of Montgomery and Vaughan, c was taken to be 3 / 2; this was then reduced to \\sqrt{22}/\\pi [B1995, p.162] and then to 3.2 / \u03c0 [M1978]. It is conjectured that c can be taken to in fact be 1.\n\n\nEfforts to fill in the blank fields in this table are very welcome.\n\nk03,500,000 181,000 34,429 26,024 23,283 22,949 10,719 6,329 5,453 5,000\nUpper bounds\nFirst k0 primes past k0 59,874,594 2,530,338 420,878 310,134 275,082 270,698 117,714 65,924 55,892 50,840\nZhang sieve 59,093,364 2,486,370 411,932 303,558 268,536 264,414 114,806 64,176 54,488 49,578\nHensley-Richards sieve 57,554,086 2,422,558 402,790 297,454 262,794 258,780 112,868 63,708 48,634\nAsymmetric Hensley-Richards 2,418,054 401,700 296,154 262,286 258,302 112,562 53,774 48,484\nShifted Schinzel sieve 2,413,228 400,512 295,162 262,206 258,000 112,440 48,726\nGreedy-greedy sieve 2,326,476 388,076 286,308 253,968 249,992 108,694 46,968\nBest known tuple 57,554,086 2,326,476 386,382 285,210 252,804 248,898 108,450 60,726 51,526 46,810\nk0logk0 + k0 56,238,957 2,372,232 394,096 290,604 257,405 253,381 110,119 61,727 52,371 47,586\nLower bounds\nInclusion-exclusion 29,508,018 1,513,556 193,420 85,878 49,464 38,048\nPartitioning 156,614 73,094 43,130 34,068\nMV with c = 1 (conjectural) 32,503,908 1,395,694 234,872 173,420 153,691 151,298 66,314 37,274 28,781\nMV with c = 3.2 / \u03c0 32,469,985 1,393,869 234,529 173,140 153,447 151,056 66,211 37,207 28,737\nMV with c=\\sqrt{22}/\\pi 31,765,216 1,357,096 227,078 167,860 148,719 146,393 63,917 35,903 27,708\nSecond Montgomery-Vaughan 31,756,667 1,356,644 226,987 167,793 148,656 146,338 63,886 35,887 27,696\nBrun-Titchmarsh 30,137,225 1,272,083 211,046 155,555 137,756 135,599 58,863 32,916 25,351\nFirst Montgomery-Vaughan 28,080,007 1,184,954 196,729\n\n\n\n\n\n128,971 126,931 55,149\n\n\n30,982 24,012\n\n\nk0 4,000 3,405 3,000 2,000 1,000 672 342\nUpper bounds\nFirst k0 primes past k0 39,660 33,222 28,972 18,386 8,424 5,406 2,472\nZhang sieve 38,596 32,296 28,008 17,766 8,212 5,216 2,414\nHensley-Richards sieve 38,498 31,820 27,806 17,726 8,258 5,314\nAsymmetric Hensley-Richards 37,932 27,638 17,676 8,168 5,220\nShifted Schinzel sieve 38,168 27,632 17,616 8,160 5,196\nGreedy-greedy sieve 36,756 26,754 17,054 7,854 5,030\nBest known tuple 36,612 30,600 26,606 16,978 7,802 5,010* 2,328\nEngelsma data 36,622 30,606 26,622 16,978 7,802 4,998 2,328\nk0logk0 + k0 37,176 31,098 27,019 17,202 7,907 5,046 2,338\nLower bounds\nInclusion-exclusion 29,746 21,884 14,082\nPartitioning 27,248 20,434 13,620 6,802 4,574 342\nMV with c = 1 (conjectural) 22,564 18,898 16,456 10,500 4,858 3,124\nMV with c = 3.2 / \u03c0 22,523 18,866 16,428 10,480 4,847 3,118\nMV with c=\\sqrt{22}/\\pi 21,701 18,153 15,758 10,061 4,648 2,979\nSecond Montgomery-Vaughan 21,690 18,143 15,751 10,056 4,645 2,977\nBrun-Titchmarsh 19,785 16,536 14,358 9,118 4,167 2,648\nFirst Montgomery-Vaughan 18,768\n\n\n15,783 13,696 8,448\n\n\n3,959 2,558\n\nThe bold number indicates the best currently known result for a twin-prime-like theorem.\n\n* indicates that the widths listed are the best known tuples that have been found by the methods that gave the entries for larger values of k0, but are not as narrow as the literally best known tuples (due to Engelsma). For k0=342 and below the exact values of H(k0) have been determined by Engelsma (each is one less than the corresponding value of w listed in his tables).\n\nFor the Zhang tuples the optimal m < \u03c0(1010) that produced an admissible k0-tuple was used. This is not always the least m that produces an admissible k0-tuple; for k0 = 22,949, for example, the minimal m = 586 yields an admissible k0-tuple of diameter of 264,460, but m = 599 yields a narrower admissible k0-tuple with the listed diameter of 264,414. A list of table entries for which this occurs can be found here (and also for k0=6,329).\n\nThe shifted Schinzel tuples were generated with y = 2 using an optimally chosen interval contained in [ \u2212 k0logk0,k0logk0] (the interval is not in every case guaranteed to be optimal, particularly for larger values of k0, but it is believed to be so).\n\nThe greedy-greedy tuples were generated using Sutherland's original algorithm, breaking ties downward in every case (and the optimal interval in [ \u2212 k0logk0,k0logk0] was selected on this basis). As noted by Castryck, breaking ties upward may produce better results in some cases.\n\nThe lower bounds listed under in the inclusion-exclusion and partitioning rows due to Avishay and computed as described in this document (the case k0=342 corresponds to the trivial partition).\n\nPersonal tools"}
{"text": "Retrieved from http://math.stackexchange.com/questions/140583/compute-the-period-of-a-decimal-number-a-priori\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nUpper bound/exact length of decimal expansion of simple fraction\n\nI noticed that WolframAlpha given an operation like $\\frac{n}{m},\\;n,m \\in N$ that result in a periodic decimal number, computes really fast the length of the period.\n\nE.g. $\\frac{3923}{6173}$ has a period of 3086: here.\n\nI was wondering how this computation is done: is there some method to do this (except the trivial one of executing the division and looking for a sequence repetition) ?\n\nshare|improve this question\nNote: i'm not a mathematician, I apologize if I have done some mistake with names, tags, etc.. \u2013\u00a0 Aslan986 May 3 '12 at 20:54\nadd comment\n\nmarked as duplicate by Ross Millikan, sdcvvc, William, t.b., rschwieb Sep 14 '12 at 16:39\n\n\n3 Answers\n\nup vote 3 down vote accepted\n\nThe period is always a factor of the totient of the denominator. In your example, 6173 is prime, so its totient is 6172 and half of that is 3086. I suspect Alpha is just doing the long division. When the remainder at any step matches the remainder at a previous step you have found the repeat. You can also find the repeat by finding the $k$ such that $10^k \\equiv 1 \\pmod {denominator}$\n\nshare|improve this answer\nadd comment\n\nconsider for example $10/3=0.333333333333333 $ which has period 3,or 33 or as you like,it happens when one number can't be divided by another exactly and during this division,some sequence of numbers is repeating\n\nshare|improve this answer\nYes, sure :).The period length here is 1. In the example above the period length is 3086. I mean, 3086 is not the period, but it is its length. I Wonder how to compute this length a priori. \u2013\u00a0 Aslan986 May 3 '12 at 21:11\nadd comment\n\nSuppose that the fraction $\\rm\\:r\\in (0,1)$ has a decimal expansion purely periodic of length $\\rm\\:k.\\:$ Then $\\rm\\:10^k r - r\\:\\! =\\:\\! (10^k-1)\\:\\! r = n\\:$ is an integer, since $\\rm\\:10^k r\\:$ is simply $\\rm\\:r\\:$ left-shifted by $\\rm\\:k\\:$ places, so its digits after the decimal point are the same as those of $\\rm\\:r,\\:$ so they cancel out in the subtraction, leaving an integer. Conversely, if $\\rm\\: r = n/(10^k-1)$ then $\\rm\\:10^k\\:\\! r = n + r\\:$ so $\\rm\\:r\\:$ has period $\\rm\\:k\\:$ (or a divisor of $\\rm\\:k\\:$ if the cycle is not minimal).\n\nTherefore, to find the minimal period of $\\rm\\:r = n/m\\:$ we need to find the minimal $\\rm\\:k\\:$ such that $\\rm\\:(10^k-1) n/m\\:$ is an integer, i.e. such that $\\rm\\:m\\:|\\:n\\:\\!(10^k-1)\\:$ (here $\\rm\\:a\\:|\\:b\\:$ denotes $\\rm\\:a\\:$ divides $\\rm\\:b).\\:$ We may assume that $\\rm\\:n/m\\:$ is in lowest terms, i.e. $\\rm\\:gcd(m,n) = 1.\\:$ Hence, by Euclid's lemma, from $\\rm\\:m\\:|\\:n\\:\\!(10^k-1)\\:$ we deduce $\\rm\\:m\\:|\\:10^k-1.\\:$ Thus to find the least period we need to find the least $\\rm\\:k\\:$ such that $\\rm\\:10^k \\equiv 1\\pmod{m},\\:$ i.e. the order of $10,\\:$ modulo $\\rm\\:m.\\:$ There are various algorithms known for computing such orders, e.g. see the references in this post.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/96625/question-on-the-standard-normal-distribution?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a random variable having standard normal distribution. Let $\\Phi$ denote its distribution function. Find\n\n$$ \\int_0^\\infty \\operatorname{Prob} (\\Phi(X) \\geq u) \\; du $$\n\nshare|improve this question\ninteresting question \u2013\u00a0 dato datuashvili Jan 5 '12 at 11:18\ndistribution function as in cdf right? \u2013\u00a0 Nikhil Bellarykar Jan 5 '12 at 11:19\nUm. $\\Phi(x)=P(X\\leq x)$ \u2013\u00a0 kodyv Jan 5 '12 at 11:28\n\n2 Answers 2\n\nSince $\\Phi$ is a strictly increasing function whose range is $(0,1)$, we have for $0<u<1$, $$ \\Pr(\\Phi(X)\\ge u) = \\Pr(X\\ge \\Phi^{-1}(u)) = 1 - \\Phi(\\Phi^{-1}(u)) = 1-u. $$ Here we've used the fact that $\\Pr(X\\ge a) = 1-\\Phi(a)$, for all $a\\in\\mathbb{R}$.\n\nBut if $u>1$ then $\\Pr(\\Phi(X)\\ge u)$ is $0$ since that event is impossible.\n\nThat tells you what to integrate.\n\nshare|improve this answer\n\nHINT: If $X$ is standard normally distributed, then $\\Phi(X)$ is uniformly distributed.\n\nshare|improve this answer\nSub-hint: for every continuous random variable $Z$ with CDF $F$, the random variable $F(Z)$ is uniformly distributed on $(0,1)$. \u2013\u00a0 Did Jan 5 '12 at 12:55\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/74173/how-do-we-describe-standard-matrix-multiplication-using-tensor-products?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $V$ be a finite dimensional vector space over a field $F$. Consider the bilinear map $End(V) \\times End(V) \\rightarrow End(V)$ given by $(u,v) \\rightarrow u \\circ v$ and the map associated linear map of tensor productsw $m : End(V) \\otimes End(V) \\rightarrow End(V)$.\n\nI am interested in how we can identify an element of the tensor product $End(V)^* \\otimes End(V)^* \\otimes End(V)$ with the map $m$ which apperently is just another way to describe standard multiplication of matrices. In any case the question can be formulated as follows:\n\nHow do we identify $m$ with an element $u^* \\otimes v^* \\otimes w \\in End(V)^* \\otimes End(V)^* \\otimes End(V)$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI believe it will be a sum of tensors, not a simple tensor. Choosing a basis of $V$, there is an element $u^* = a_{ij}$ that takes a matrix $A$ and gives you its $i,j$th entry. Set $b_{ij} = a_{ij}$ to be a nicer name for $v^*$, and $e_{ij}$ to be the matrix unit with a 1 in the $i,j$th spot, and 0 elsewhere. Then the matrix multiplication element is: $$ \\mu = \\sum_{i=1}^n \\sum_{j=1}^n \\sum_{k=1}^n a_{ij} \\otimes b_{jk} \\otimes e_{ik}$$ In other words, it is just the formula for matrix multiplication with some tensor products instead of multiplication signs.\n\nshare|improve this answer\nadd comment\n\nDepending on taste, one might also have the \"motion\" go in the opposite direction: with $v\\otimes \\lambda$ an endomorphism given by $(v\\otimes \\lambda)(w)=\\lambda(w)\\cdot v$, for $v,w\\in V$ and $\\lambda\\in V^*$, the multiplication/composition of endomorphisms is $$ (v\\otimes \\lambda)\\circ (w\\otimes \\mu) \\;=\\; \\lambda(w)\\cdot v\\otimes \\mu $$ for $v,w\\in V$ and $\\lambda,\\mu\\in V^*$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/414023/probability-of-winning-the-game-1-2-3\nText:\nTake the 2-minute tour \u00d7\n\nOk, game is as follow, with spanish cards (you can do it with poker cards using the As as a 1)\n\nYou shuffle, put the deck face bottom, and start turning the cards one by one, saying a number each time you turn a card around ---> 1, 2, 3; 1, 2, 3; etc. If when you say 1 a 1 comes out, you lose, same with 2 and 3. If you finish the deck without losing, you win.\n\nI know some basics of probabilities, but is there a way to calculate the probability of winning the game, given a random shuffled deck?\n\nshare|improve this question\nCan you name any number $1 \\to 13$ while turning the cards? I.e. whats the range of the numbers you may name? \u2013\u00a0 JohnWO Jun 7 '13 at 17:28\nIs the player allowed to say 1, 2, or 3 at random or does he/she always have to follow the sequence 1,2,3,1,2,3,...? \u2013\u00a0 iX3 Jun 7 '13 at 17:52\nIf one wants something more general; If one could name any numerical value of a card in the deck, i.e.: If there are 52 cards in the deck, divided over 4 suits, which range from $1 \\to 13$, counting $\\text{Ace's}$ as $1$, you would have $13$ different choices. So the chances of loss are approx.: $\\frac{d}{r^2\\;s}$, where $d$ denotes the number of cards left in the deck, and $r$ denotes the numberical range of the cards in the deck, and $s$ denotes the number of suits. \u2013\u00a0 JohnWO Jun 7 '13 at 17:54\nMonte Carlo method shows the probability of $\\approx 0.008$, so the approximation with $\\left(\\frac 2 3\\right)^{12}$ is for this deck size already good enough. \u2013\u00a0 Harold Jun 7 '13 at 18:32\nYes, i am sorry, you can't say any number, you have to say JUST 1, 2, 3, 1, 2, 3, 1, 2, 3, repeat. \u2013\u00a0 Pphax Jun 7 '13 at 22:17\nadd comment\n\n3 Answers\n\nup vote 3 down vote accepted\n\nFor $i,j\\in\\{1,2,3\\}$, let $a_{i,j}$ denote the number of $i$ cards being dealt with number $j$ spoken. We have $\\sum_j a_{i,j}=4$ and for a winning game $a_{i,i}=0$. The number of winning positions for a given $(a_{i,j})$ is $$\\frac{18!}{a_{2,1}!a_{3,1}!(18-a_{2,1}-a_{3,1})!}\\cdot\\frac{17!}{a_{1,2}!a_{3,2}!(17-a_{1,2}-a_{3,2})!}\\cdot\\frac{17!}{a_{1,3}!a_{2,3}!(17-a_{1,3}-a_{2,3})!}. $$ We need to sum this over all $(a_{i,j})$ and divide by the total count $$ \\frac{52!}{4!4!4!40!}.$$ (Actually, we need just let $a_{1,2}, a_{2,3}, a_{3,1}$ run from $0$ to $4$ and this determines $a_{1,3}=4-a_{1,2}$ etc.) The final result is $$p=\\frac{58388462678560}{7151046448045500}=\\frac{24532967512}{3004641364725}\\approx 0.008165 $$ (I just noted that Harold has performed a Monte Carlo simulation with matching result)\n\nshare|improve this answer\nI did calculate the precise probability too, also using combinatorics, but this formula looks so terrifying for me :) I like the approximation explained by Byron Schmuland more. But it would be intresting to find some simplier way for a common case, it should defenitely exist. \u2013\u00a0 Harold Jun 7 '13 at 19:16\nadd comment\n\nAnother update:\n\nAs explained in the paper below, you can use rook polynomials to solve such problems. Playing with a full deck of 52 cards we will call \"one\" 18 times, we will call \"two\" 17 times, and we will call \"three\" 17 times. The forbidden positions in the 52 by 52 board consist of three \"independent\" complete rectangles; one $18\\times 4$ and the other two $17\\times 4$.\n\nThe rook polynomial for a full $m\\times n$ rectangle with $m\\geq n$ is $$\\sum_{k=0}^n{m\\choose k}\\, {n!\\over (n-k)!}\\, x^k. $$\n\nMultiply the polynomials for these three rectangles to give us the rook polynomial for our problem\n\nThe number of winning deck orders is $$\\int_0^\\infty x^N R(-1/x) \\exp(-x)\\,dx $$ so the probability is this divided by $N!$, i.e. $$\\mathbb{P}(\\text{win})= 24532967512/3004641364725= 0.008165023553.$$\n\n\nUpdate: The solution below is for a simplified version of the problem where you work with a deck of size 12: four each of ace, deuce, and trey.\n\nThis is a problem in generalized derangements and joriki's answer here tells you what to do. In general, the number of deck orders that lead to a win is $$\\int_0^\\infty L_{n_1}(x)\\cdots L_{n_r}(x)\\,\\mathrm e^{-x}\\mathrm dx.$$\n\nIn this problem, we have $r=3$ and $n_1=n_2=n_3=4$. The fourth Laguerre polynomial is $L_4(x)=(x^4-16x^3+72x^2-96x+24)/24$. Raising this to the third power and integrating against $\\exp(-x)$ gives $346$. That is, there are $346$ ways to order the deck that give a win.\n\nDivide this by the total number of orders $12!/(4!)^3$, to give $$\\mathbb{P}(\\text{win})=173/17325=0.00998.$$\n\nshare|improve this answer\nWhy does your answer differ significantly from Harold's Monte Carlo result? \u2013\u00a0 Hagen von Eitzen Jun 7 '13 at 19:05\nI am playing with a deck of size 12: four each of ace, deuce, trey. \u2013\u00a0 Byron Schmuland Jun 7 '13 at 19:07\nNow I'm playing with a full deck! \u2013\u00a0 Byron Schmuland Jun 7 '13 at 20:04\nThank you Byron, i chose Hagen's answer because he answered first, but yours is very clear too. \u2013\u00a0 Pphax Jun 7 '13 at 22:44\nadd comment\n\nThis is a hard question, if the player is using optimal strategy rather than just cycling through numbers.\n\nFor example, once the deck is down to 2 cards the player is guaranteed a win, because those two cards are known and (even if they're different) the player can name the third number. If the deck is down to 3 cards the player is guaranteed a win unless those last three cards are all different, in which case the player can't do better than guessing at random (2/3 chance) of winning.\n\nFull analysis for a deck of size 6: 2 each of $1,2,3$.\nCard 1: random, 1/3 chance of loss\nCard 2: guess whatever card 1 was, 1/5 chance of loss (if top two cards are the same)\nCard 3: guess either of the first two cards, 1/4 chance of loss\nWe now have two situations. If the first three cards are all different, there is a further 1/3 chance of loss, based on the analysis in the paragraph above, otherwise a win is assured. Each case happens half the time; two each of the four cards lead to the two cases.\n\nAltogether, the probability of loss is: $$\\frac{1}{3}+\\frac{2}{3}\\frac{1}{5} + \\frac{2}{3}\\frac{4}{5}\\frac{1}{4} + \\frac{2}{3}\\frac{4}{5}\\frac{3}{4}\\frac{1}{2}\\frac{1}{3}=\\frac{2}{3}$$\n\nThis seems too good to be true, but there it is.\n\nshare|improve this answer\nI may be misunderstanding, but I thought the player is required to call $1,2,3,1,2,3,1,\\ldots$ in that order with no scope for strategy. \u2013\u00a0 MJD Jun 7 '13 at 19:02\n@iX3 asked this question but received no answer. \u2013\u00a0 vadim123 Jun 7 '13 at 19:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/225972/bounds-for-the-size-of-a-circle-with-a-fixed-number-of-integer-points\nText:\nTake the 2-minute tour \u00d7\n\nI know that there are infinitely many rational points on the (unit) circle. I am interested in the following question:\n\nHow large has the radius of a circle to be, such that there are at least $n$ integer (lattice) points on it?\n\nActually, I am not interested in the precise number, but in some reasonable good upper bound $f(n)$. Something like, there is a circle of radius $\\leq f(n)$ that has least $n$ integer points.\n\nshare|improve this question\nThe radius must be at least about $\\sqrt{\\frac{n}{\\pi}}$. Also see: en.wikipedia.org/wiki/Gauss_circle_problem \u2013\u00a0 Dan Brumleve Oct 31 '12 at 10:13\n@DanBrumleve: Sorry, but my question was ambiguous. I meant integer points on the circle and not inside the circle. I made the question more precise. \u2013\u00a0 A.Schulz Oct 31 '12 at 10:26\nHere is a lousy bound. There are $4(e+1)$ representations of $5^e$ as a sum of two squares of integers. \u2013\u00a0 Andr\u00e9 Nicolas Oct 31 '12 at 11:10\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nEdit: In the following I suppose that the center of the circle is $(0,0)$ and this extent easily to the case where the center is a lattice point.\n\nIf the radius of a circle is $r$ and we have $n$ lattice points on it (of cource $4|n$) then $r^2 \\in \\mathbb{N}$ and $r^2$ can be written as sum of two squares in $n$ different ways (assuming of course that $(a,b) \\neq (-a,b)$ and $(a,b) \\neq (b,a)$ for $a \\neq b$).\n\nSo if you are asking if there is a function $f$ s.t. if $k \\leq f(n)$ then $k$ can be written as sum of two squares in at least $n$ different ways then according to this paper the answer is no.\n\nIn theorem 4.3 is shown that for a prime $p$ there at most $8$ different ways to write $p$ as a sum of two squares.\n\nHowever, there is a function $g$ s.t. for all $n \\in \\mathbb{N}, \\ g(n)$ can be written as sum of two squares in $n$ different ways, so if this is what you are asking the answer is yes. This is a consequence of Theorem 4.4.\n\nTheorem 4.4. says that if the prime numbers of the form $1 \\pmod4$ in $m$ appear with exponents $a_1,a_2,\\ldots , a_s$ and the prime numbers of the form $3 \\pmod4$ in $m$ appear with even exponents then $m$ can be written as sum of two squares in $4(a_1+1)(a_2+1)\\ldots(a_s+1)$ different ways.\n\nLets say that you want to find a circle with $4k$ lattice points. Then you can take the radius to be $5^{\\frac{k-1}{2}}$.\n\ne.g to find $8$ lattice points take the radius to be $\\sqrt{5}$. The lattice points are $(1,2),(1,-2),(-1,2),(-1,-2),(2,1),(2,-1),(-2,1),(-2,-1)$.\n\nThe best bound (assuming the circle is centered at zero) is the following:\n\nDenote the primes of the form $1 \\pmod 4$ as $p_1<p_2<\\ldots$. Lets say that you want to find the smallest $m$ s.t. the circle with radius $m$ has $4n$ lattice points. Factor $n$ as $n=4a_1a_2\\ldots a_s$ where $a_i$ are primes with $a_1\\leq a_2\\leq a_3 \\leq \\ldots \\leq a_s$. Then the smallest $m$ is given by $m^2=p_1^{a_s-1}p_2^{a_{s-1}-1}p_3^{a_{s-2}-1}\\ldots p_s^{a_1-1}$. This can be deduced from Theorem 4.4, the fact that for $a<b, \\ r_1,r_2 \\in \\mathbb{N}, \\ \\text{ with } a^2>b \\text{ and } r_1\\geq 2 \\Rightarrow a^{r_1r_2-1}>a^{r_1-1}b^{r_2-1}$ and the fact that $p_{i+1}<p_i^2, \\ \\forall i \\in \\mathbb{N}.$\n\nFor example the smallest radius $m$ witch give $48$ lattice points is $m=5\\cdot \\sqrt{13 \\cdot 17}$.\n\nshare|improve this answer\nI think you'll find that last circle has radius $\\sqrt5$. But in fact you can get it down to $\\sqrt5/\\sqrt2$ with center $(1/2,1/2)$. No one said the center had to be a lattice point. \u2013\u00a0 Gerry Myerson Oct 31 '12 at 12:01\nCorrect, thanks. I will edit. \u2013\u00a0 P.. Oct 31 '12 at 12:06\n@Pambos: Interesting! This is the bound that was mentioned by Andr\u00e9 Nicolas at the question's comment. Thanks for your longer answer. I am curious if one can find a better bound or if this is the best you can get. \u2013\u00a0 A.Schulz Oct 31 '12 at 13:23\nIn the same direction of @Andr\u00e9 Nicolas's bound, we can take the radius as the square root of the product of the first $m$ primes $\\equiv 1\\pmod{4}$, in order to have $4\\cdot 2^m$ integer points on a circle having a radius that grows like $m^m$. \u2013\u00a0 Jack D'Aurizio Oct 31 '12 at 14:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/88430/restrictions-of-modules-and-dimensions/89015\nText:\nTake the 2-minute tour \u00d7\n\nLet K be a finite field and let R,P be groups (with R a subgroup of P). I know that the irreducible KP-modules have dimensions 1,4 and 16 over K. I have a KP-module M, and I know that M has dimension at most 5 over K. I also know that M does not have a quotient of dimension 1 over K. Moreover, if I consider M as a module over KR, it has a 2-dimensional irreducible module. Is it necessarily the case that M is a 4-dimensional irreducible module over KP? (my initial reasoning can be found in a comment below)\n\nshare|improve this question\nThe answer is no if and only if $\\operatorname{Ext}^1(4,1)\\neq 0$ in the obvious notation. If you said what P and R are maybe someone could work it out, but a priori it is not even obvious groups with these properties exist. \u2013\u00a0 m_t Feb 14 '12 at 14:02\nSorry, P and R are parabolic subgroups of the McLaughlin Group in a minimal parabolic system. \u2013\u00a0 dward1996 Feb 14 '12 at 15:10\nI think your answer has also proved that irrespective of the answer to the question in my specific case, there is a flaw in my reasoning. Thanks for the help. \u2013\u00a0 dward1996 Feb 14 '12 at 15:24\nHaving looked at this again, I'm not sure that I follow the comment by mt. My initial reasoning was as follows. Suppose M were a 5-dimensional module. If M has a 4-dimensional submodule, then it must have a 1-dimensional quotient over K, which we know is not the case. Thus it must be the case that every irreducible submodule of M is 1-dimensional over K. However, the restriction of M to KR has a 2-dimensional irreducible submodule. A similar argument shows that M must have a 4-dimensional irreducible submodule, and thus as M has dimension at most 4, it is an irreducible 4-dimensional module \u2013\u00a0 dward1996 Feb 20 '12 at 11:07\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nI see no reason in general if $\\operatorname{Ext}_P^1(4,1) \\neq 0$ that, on restriction to R the four dimensional simple can't drop down and have a 2-dimensional submodule. I.e. On restriction to R it looks like:\n\n\\begin{equation}\\begin{array}{c} 2\\\\ 2 \\end{array} \\oplus 1 \\end{equation}\n\nIf you knew on restriction to KR the only irreducible submodule was two dimensional then this would be ruled out.\n\nshare|improve this answer\nThanks for that. I'm not sure why I thought that my justification was correct! (Sorry!) \u2013\u00a0 dward1996 Feb 21 '12 at 12:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/108593/how-to-prove-that-the-normalizer-of-diagonal-matrices-in-gl-n-is-the-subgroup\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to prove that de normalizer $N(T)$ of the subgroup $T\\subset GL_n$ of diagonal matrices is the subgroup $P\\in GL_n$ of generalized permutation matrices. I guess my biggest problem is that I don't really know how diagonal and permutation matrices (don't) commute. Because it is not true that $DM=MD$ when $D\\in T$ and $M\\in P$ since the permutation is either horizontal or vertical, but sometimes it seems like you can do something like it.\n\nSo far, I have proved that $P\\subset N(T)$, in the following way. Let $M_\\sigma\\in P$. Then $M_\\sigma=VS_\\sigma$, with $V\\in T$ and $S_\\sigma$ a permutation matrix. So $M_\\sigma DM^{-1}=VS_\\sigma D S_\\sigma^T V^{-1}$. Thus if we prove that $S_\\sigma D S_\\sigma^T$ is diagonal we are done. This is true since $S_\\sigma D S_\\sigma^T=(x_1 e_{\\sigma(1)} \\dots x_n e_{\\sigma(n)}) (e_{\\sigma^{-1}(1)} \\dots e_{\\sigma^{-1}(n)})=(x_{\\sigma^{-1}(1)}e_1 \\dots x_{\\sigma^{-1}(n)}e_n)$, where $e_i$ are the standard basis vectors. Even this is hopelessly written out. I'm trying to find a way to see what the product $S_\\sigma D S_\\sigma^T$ is without writing it in vectors.\n\nFor the other way around I don't really know what to do. I'm having a hard time rewriting matrix products in a useful way. Perhaps there is a way of proving this using something completely different? Maybe you can prove it using $N(T)/T\\simeq S_n$, but this actually what I want to use my question for. When I just write what I know about a matrix $M\\in N(T)$ I just get a big system of equations that isn't really handy.\n\nshare|improve this question\nTry taking a matrix in $N(T)$, testing it on the diagonal matrices with zeros in all but one diagonal entry, and forcing it to be a generalized permutation matrix. Recall that the group $GL_{n}$ lives inside a ring of matrices (i.e. use addition and distributivity). \u2013\u00a0 Isaac Solomon Feb 12 '12 at 19:33\n@IsaacSolomon Thanks, but I don't really understand it. When I take $D_1$ for instance (with zeroes everwhere but $D_{1,1}$), and I look at $MD_1=SM$ for some diagonal matrix $S$, I can see that it follows that the first column only has one non-zero entry. But now how do I put that together. I can write $M(x_1D_1 + \\dots + x_nD_n)=SM$, but then I get confused. \u2013\u00a0 dropfruitduo Feb 12 '12 at 20:09\nadd comment\n\n4 Answers\n\nup vote 2 down vote accepted\n\nLet $S\\in N(T)$. Then $SDS^{-1}$ is diagonal for each diagonal matrix $D$. Now, conjugation preserves the spectrum, which is exactly the diagonal in the case of diagonal matrices. So the diagonal of $SDS^{-1}$ has to be the same as the diagonal of $D$ up to a permutation. From this it's not hard to setup the equations to see that $S$ has to have a unique nonzero entry per row and column, i.e. $S$ is a generalized permutation matrix.\n\nConcretely, let us write $\\{E_{kj}\\}$ for the set of canonical matrix units (i.e. $E_{kj}$ is the matrix with a $1$ in the $k,j$ position and zeroes elsewhere). Let $D=E_{11}+2E_{22}+\\cdots+n E_{nn}$ (i.e. a diagonal matrix with all different entries). From the first paragraph, we know that $SDS^{-1}$ is $W=\\sigma(1)E_{11}+\\cdots+\\sigma(n)E_{nn}$ for some permutation $\\sigma$. Since $SD=WS$, we get that $$ S_{kj}(j-\\sigma(k))=0. $$ For each $j\\ne\\sigma(k)$, we have $S_{kj}=0$; so the only nonzero entry in the $k^{\\rm th}$ row of $S$ is $S_{k,\\sigma(k)}$. In other words, each row of $S$ contains a single nonzero entry, so $S$ is a generalized permutation matrix.\n\nshare|improve this answer\nRight that makes sense! It's mostly the writing down the equation part I'm having trouble with. So can I say: $SDS^{-1}=W$ for some diagonal $W$ with the same diagonal as $D$ up to a permutation for every $D$, so also for one with all unique diagonal entries. Then when I calculate $SD$ and $WS$ I get equations $(x_j-x_{\\sigma(i)})s_{i,j}=0$ for all $i,j$. Then since $x_1-x_{\\sigma(i)}$ is only zero for one $i$, the rest of the $s_{i,1}$ must be zero, and so for all j? Or am I making it too complicated? \u2013\u00a0 dropfruitduo Feb 12 '12 at 20:59\nMostly yes, you need to play a little with the choices of different diagonals. I'll add it to the solution in a few minutes. \u2013\u00a0 Martin Argerami Feb 12 '12 at 23:45\nHow about those diagonal matrices with some identical diagonal entries? \u2013\u00a0 Eric Apr 27 '12 at 14:47\nWhat about them? \u2013\u00a0 Martin Argerami Apr 28 '12 at 11:44\nadd comment\n\nIf $P$ is the permutation matrix corresponding to permutation $\\pi$, i.e. $P_{i,\\pi(i)} = 1$ for each $i$, and $D$ is a diagonal matrix, then $(PDP^{-1})_{ij} = \\sum_k \\sum_\\ell P_{ik} D_{k\\ell} P^{-1}_{\\ell j}$. For a term to be nonzero, you need $k = \\pi(i)$, $k=\\ell$ and $\\ell = \\pi(j)$, so $\\ldots$\n\nshare|improve this answer\nadd comment\n\nLet $S \\in N(T)$. Now, $\\forall D \\in T$ we have $SDS^{-1} \\in T$. As noted, conjugation preserves the spectrum, and so $D$ and $SDS^{-1}$ have the same diagonal entries up to permutation. This allows us to write $SDS^{-1} = \\prod_kP_kDP_k'$, where $P_k, P_k' \\in P_{S_n} \\leq GL(n)$, the group of permutation matrices. This shows that $N(T) \\leq \\langle T , P_{S_n}\\rangle$. Finally, a simple calculation shows that $\\langle T , P_{S_n}\\rangle \\leq N(T)$.\n\nshare|improve this answer\nadd comment\n\nThe set of eigenvectors common to all elements of $T$ is that of the nonzero multiples of the standard basis vectors. Any element of $N(T)$ must permute these common basis vectors among each other (if $P\\in N(T)$ and $v$ is a common eigenvector of $T$, then so is $P\\cdot v$). This means all columns of $P$ must have a single nonzero entry, and of course these entries have to be in distinct rows as well. Hence $N(T)$ is contained in the set of generalised permutation matrices. The reverse inclusion follows from a simple computation to show that permutation matrices normalise $T$ (as of course do elements of $T$ itself). Or show this using the fact that $t\\in T$ whenever all standard basis vectors are eigenvectors of $t$ (nearly the converse of the property used at the beginning).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70300/algorithm-to-determine-a-discrete-function\nText:\nTake the 2-minute tour \u00d7\n\n\nI'm not quite sure what title to give to this question or what tags to use, because this isn't really my area of expertise and I'm unfamiliar with the terminology. It is a problem that came up while trying to write a program to enumerate some graphs, however there is no graph theory left in this problem.\n\nLet me first start by giving definitions for the different components. I have a set $C$ and two functions: $s:C\\rightarrow \\mathbb{N}$ and $r:C\\rightarrow \\mathbb{N}$. The values for these functions are completely known. It is also true that $\\forall c \\in C: r(c)=s(c) \\vee r(c)=\\frac{s(c)}{2}$. I don't know whether this will make a difference for the solution of my problem, but it might be relevant information.\n\nI am now interested in finding all possible functions $m:C\\rightarrow \\mathbb{N}$ that satisfy the following conditions:\n\n  \u2022 $\\sum_{c\\in C}\\frac{s(c)}{m(c)}=\\sum_{c \\in C}\\frac{s(c)}{4}$\n  \u2022 $\\forall c \\in C: r(c) \\mid m(c)$\n\nI really need an algorithm to find all possible solution, but of course I'm also interested in any theoretical results that could help me find such an algorithm. As I said, I'm not really at home in this type of problems, so I have no idea what to look for and where to start. The first conditions makes it impossible to have an infinite number of solutions, but in some cases I have some better upper bounds and lower bounds available for the value of the function $m$ in certain points. It would be nice if this could be taken into account, but I think it would not be the bottle-neck if I just filtered the solutions to take these bounds into account.\n\nAny help is greatly appreciated. And of course I will try my best to clarify anything in my explanation that isn't clear.\n\nEdit: Let me first say that $C$ will always be finite.\n\nA small example might also be more clarifying. Suppose we have $C=\\{1,2\\}$, the function $s:C\\rightarrow\\mathbb{N};c\\mapsto 2$ and the function $r:C\\rightarrow\\mathbb{N};c\\mapsto 1$.\n\nWe then have three possible solutions for $m$:\n\n  \u2022 $m(1)=3$, $m(2)=6$\n  \u2022 $m(1)=4$, $m(2)=4$\n  \u2022 $m(1)=6$, $m(2)=3$\nshare|improve this question\nIs $C$ a finite set? I.e., can one loop over all elements of $C$ in an algorithm? \u2013\u00a0 Jesko H\u00fcttenhain Jul 14 '11 at 8:35\nYes, $C$ is most definitely finite and in most cases really small (at least size 2 but only in rare cases larger than 30). I'll have a look at your answer, Thanks already for answering. \u2013\u00a0 nvcleemp Jul 14 '11 at 9:25\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nI will assume that $C$ is finite for my answer.\n\nLet $n,d:C\\to\\mathbb{N}$ such that $n\\equiv\\left.m/r\\right.$ and $r\\equiv\\left.s/d\\right.$. In other words, $\\mathrm{im}(d)\\subseteq\\{1,2\\}$. Let $C_1:=d^{-1}(1)$ and $C_2:=C\\setminus C_1 = d^{-1}(2)$. Now, we want to find a function $n$ such that\n\n$R := \\displaystyle \\sum_{c\\in C} \\frac{d(c)}{n(c)} = \\sum_{c\\in C} \\frac{s(c)\\cdot d(c)}{s(c)\\cdot n(c)} = \\sum_{c\\in C} \\frac{s(c)}{r(c)\\cdot n(c)}= \\sum_{c\\in C} \\frac{s(c)}{m(c)} = \\sum_{c\\in C} \\frac{s(c)}{4} =: S$\n\nClaim. This problem has a solution if and only if $2\\le S\\le|C_1|+2|C_2|$.\nProof. We consider $S\\in\\mathbb{Q}$ and perform induction on $r$, where $C=\\{c_1,\\ldots,c_r\\}$. In the case $r=1$, the statement is clear. Assume now that $S>|C_1|+2|C_2|$. Then, no matter how we choose $n(c_r)$, by induction we can not find a valid solution for $S'=S-d(c_r)/n(c_r)$ on $C'=\\{c_1,\\ldots,c_{r-1}\\}$.\n\nIn the case where $S\\le|C_1|+2|C_2|$ however, a solution can be calculated by setting $n\\equiv 1$, so $R=|C_1|+2|C_2|$. We then have to decrease $R$ until it achieves the desired value.\n\nFor $d=1,2$ we can decrease $R$ by $dr-1$ in the following way: Pick $\\{c_1,\\ldots,c_r\\}\\subseteq C_d$ and set $n(c_i):=dr$ for all $i$. The following python code\n\ndef n(c):\n    D = 2*c[2] + c[1] - c[0]\n    for d in (1,2):\n        j,r = 0,c[d]\n        ctr = c[d]\n        while r > 0 and D != 0:\n            if d*r-1 <= D:\n                D -= d*r-1\n                n[d-1][j:j+r] = [d*r]*r\n                j += r\n                ctr -= r\n                r = ctr\n                r -= 1\n    print n[0]+n[1]\n\nexpects input of the form $(S,|C_1|,|C_2|)$ and returns the function $n$, with my notation. In your example above, $S=1$, $|C_1|=0$ and $|C_2|=2$, the output is\n\n>>> n((1,0,2))\n[4, 4]\n\nwhich is the second of your solutions. I think this should work.\n\nshare|improve this answer\nI might be missing something obvious, but what exactly do you mean by $|S|$? It is not the absolute value of the rational number $S$, right? \u2013\u00a0 nvcleemp Jul 14 '11 at 9:50\nErr, those are really not supposed to be there. It should be just $S$, I will edit it. \u2013\u00a0 Jesko H\u00fcttenhain Jul 14 '11 at 11:53\nThen there seems to be a problem with the condition that $|C|\\leq S$. As can be seen in the example I added in my original question this is not a necessary condition. But it doesn't seem like you really need this. \u2013\u00a0 nvcleemp Jul 14 '11 at 12:22\nIndeed, let me fix that up. \u2013\u00a0 Jesko H\u00fcttenhain Jul 14 '11 at 13:56\nI was working under the assumption that $S\\in\\mathbb{N}\\setminus\\{1\\}$. You allow $S\\in\\mathbb{N}\\cup\\left\\{\\frac{1}{2},\\frac{1}{4}\\right\\}$, but these additional three special cases can be easily handled by multiplying $n$ with $2$, $4$ or $8$. \u2013\u00a0 Jesko H\u00fcttenhain Jul 16 '11 at 22:19\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/38624/determining-the-center-of-mass-of-a-cone?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm having some trouble with a simple classical mechanics problem, where I need to calculate the center of mass of a cone whose base radius is $a$ and height $h$..!\n\nI know the required equation. But, I think that I may be making a mistake either with my integral bounds or that $r$ at the last..! $$z_{cm} = \\frac{1}{M}\\int_0^h \\int_0^{2\\pi} \\int_0^{a(1-z/h)} r \\cdot r \\:dr d\\phi dz$$\n\n'Cause, once I work this out, I obtain $a \\over 2$ instead of $h \\over 4$...!\n\nCould someone help me?\n\nshare|improve this question\nHello there Coolcrab and please keep an eye on our Homework policy before asking about homework questions, 'cause they're discouraged here..! Sorry :) \u2013\u00a0 Waffle's Crazy Peanut Sep 29 '12 at 10:16\nThey are not homework, and I did do the sum just making a mistake somewhere. And asking for help with that.. \u2013\u00a0 Coolcrab Sep 29 '12 at 10:55\nWhat!? $a/2 := h/4$!? I don't think so... Increasing $a$ has no effect on $h$, this assertation is plane false. \u2013\u00a0 Killercam Sep 29 '12 at 11:14\nOfc its not, and thats my problem. It's either my bounds or the r should be a z. I'm not sure. \u2013\u00a0 Coolcrab Sep 29 '12 at 11:16\n@Killercam: Hi guys, I understood it. But, I just assumed that the center of mass would be somewhere along the axis of the cone...! Isn't that right? \u2013\u00a0 Waffle's Crazy Peanut Sep 29 '12 at 11:36\nshow 2 more comments\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI am not sure about this formula. Lets start by taking the vertex of the solid cone to be $O(0, 0, 0)$ in cylindrical coordinates ($r$, $\\theta$, $z$). Then take the height of the cone to be $h$ and the base of the cone to have radius $a$. In this case the we know that\n\n$r = \\frac{a}{h} z$.\n\nThe formula for the center of mass of this cone can be written as\n\n$Mz_{M} = \\int^{h}_{0} z \\mathrm{d}m$,\n\nwhere $M$ is the total mass of the (solid) cone and $z_{M}$ is the location of the center of mass. We can write $\\mathrm{d}m$ as\n\n$\\mathrm{d}m = \\pi \\rho \\frac{a^{2}}{h^{2}}z^{2}\\mathrm{d}z$,\n\nwhere we have considered $\\mathrm{d}m$ to be the mass of a thin disk at height $z$ and of radius $r$, with thickenss $\\mathrm{d}z$. Now we can write the full equation for the center of mass as\n\n$Mz_{M} = \\pi\\rho\\int^{h}_{0}\\frac{a^{2}}{h^{2}}z^{3}\\mathrm{d}z$,\n\nthis becomes\n\n$Mz_{M} = \\rho Vz_{M} = \\frac{1}{4}\\pi\\rho a^{2}h^{2}$.\n\nWe know that the volume of a cone $V = \\frac{1}{3}\\pi a^{2} h$, so we find\n\n$z_{M} \\rho \\frac{1}{3}\\pi a^{2} h = \\frac{1}{4}\\pi\\rho a^{2}h^{2}$,\n\n\n$z_{M} = \\frac{3}{4} h$.\n\nWhich is the distance from the vertex of the cone.\n\nI hope this helps.\n\nshare|improve this answer\nadd comment\n\nI see the problem you have here, change the r*r drd\u03d5dz there to z*r drd\u03d5dz, then you should get the correct answer\n\nshare|improve this answer\nHi Mengyu, welcome to Physics.SE. Can you please use MathJax with dollar signs and markup to make your answer more readable? See meta.math.stackexchange.com/questions/5020/\u2026 \u2013\u00a0 Brandon Enright Feb 20 at 18:37\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/311043/determining-complex-differentiability-using-cauchy-riemann-equations\nText:\nTake the 2-minute tour \u00d7\n\nI need to find where $f(x+iy)=-6(\\cos x+i\\sin x)+(2-2i)y^3+15(y^2+2y)$ is complex differentiable.\n\nI first rearranged the function into its real and imaginary parts: $f(x+iy)=(-6\\cos x+2y^3+15y^2+30y)+i(-6\\sin x-6y^2)$\n\nThat means $u(x,y)=-6\\cos x+2y^3+15y^2+30y$ and $v(x,y)=-6\\sin x-6y^3$.\n\nThen, if we take the partial derivative of u and v in terms of x and y:\n\n$u_x=6\\sin x$\n\n\n$v_x=-6\\cos x$\n\n\nThen, by the Cauchy-Riemann equations, $u_x=v_y$ and $u_y=-v_x$.\n\nThis means that: $6\\sin x=-18y^2$ and $6y^2+30y+30=6\\cos x$.\n\nThis is where I am stuck. How do I solve for x and y? I was thinking that I could proceed in this way:\n\n$\\sin^2 x + \\cos^2 x=1 \\Rightarrow (-3y^2)^2+(y^2+5y+5)^2=1 \\Rightarrow 10y^4+10y^3+35y^2+50y+24=0$\n\nHowever, from here, how do I solve for y and then solve for x? I'd appreciate any tips. Thanks for your help in advance!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nYou can see from wolfram alpha that the solutions for the pair of equations never overlap.\n\nBut using your chain of logic: $10y^4+10y^3+35y^2+50y+24=0$ has no real solutions. Therefore the function is complex-differentiable nowhere.\n\nshare|improve this answer\nadd comment\n\nWe can simplify these equations into $$ \\sin{x} = -3 y^2, \\quad y^2 + 5y + 5 = \\cos{x} $$ Now, $x$ and $y$ are real, so the only way that the first equation can be satisfied is if $y \\in [-1/\\sqrt{3}, 1/\\sqrt{3}]$, since otherwise $-3y^2$ will not be in the range of sine.\n\nNow we turn to the second equation. The graph of $y^2 + 5y + 5$ achieves its minimum at $y = -5/2$; therefore it is monotone on the interval $[-1/\\sqrt{3}, 1/\\sqrt{3}]$. So we can simply check the endpoints to verify that $y^2 + 5y + 5 > 1$ when $y \\in [-1/\\sqrt{3}, 1/\\sqrt{3}]$, and hence it can never equal $\\cos{x}$ if the first equation is satisfied.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/134011/scalar-product-of-gaussian-process/134048\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $n(t)$ is a White Gaussian Noise (WGN) process with $E[n(t)]=0$, $E[n(t)^2]=\\sigma^2$ and $x(t)$ a deterministic function defined in $[0,T]$. How can I compute from first principles the variance of $g(T)$ defined as\n\n\nAny references to elementary textbooks on stochastic processes are also welcome.\n\nshare|improve this question\nis the e(t) in the definition of g(T) the n(t) you introduced before? \u2013\u00a0 tibL Apr 19 '12 at 17:20\nYou need the autocorrelation function of the process, not just the variance. \u2013\u00a0 Dilip Sarwate Apr 19 '12 at 17:25\nYes, the noise is white and e(t)=n(t). The text is now correct. \u2013\u00a0 Arrigo Benedetti Apr 19 '12 at 21:57\nIf the autocorrelation function is $$E[n(t)n(s)] = R_n(t-s)=\\begin{cases}\\sigma^2,&t=s,\\\\0,&t\\neq s,\\end{cases}$$ then the integral expression in Nate Eldredge's answer gives $\\operatorname{var}(g(T))=0$. If the autocorrelation function is $\\sigma^2\\delta(t-s)$ (note the difference) then see my comment on that answer as well as this question. \u2013\u00a0 Dilip Sarwate Apr 20 '12 at 11:06\nadd comment\n\n1 Answer\n\nAssuming that $e(t)$ is supposed to be $n(t)$ and that you know the covariances $E[n(s) n(t)]$, then note that $$g(T)^2 = \\int_0^T \\int_0^T x(s) x(t) n(s) n(t)\\,ds\\,dt$$ and so by Fubini's theorem $$E[g(T)^2] = \\int_0^T \\int_0^T x(s) x(t) E[n(s) n(t)]\\,ds\\,dt.$$\n\nshare|improve this answer\n@ArrigoBenedetti This calculation occurs in engineering applications very often where $n(t)$ is assumed to be a white Gaussian noise process with autocorrelation function $\\sigma^2\\delta(t-s)$ and so $E[g(T)] = 0$ while the variance becomes $$\\text{var}(g(T)=\\sigma^2\\int_0^T x^2(t) \\mathrm dt.$$ See for example Appendix A of this document. \u2013\u00a0 Dilip Sarwate Apr 19 '12 at 19:11\nThese heuristics are nice, but it may be important to mention that they're not too much more than this. In particular, the integrals, as shown, don't exist. \u2013\u00a0 cardinal Apr 20 '12 at 4:20\n@cardinal Would you please comment on or respond to this question of mine on this issue? Thanks. \u2013\u00a0 Dilip Sarwate Apr 20 '12 at 11:10\nThe application of Fubini's theorem is illegal here, as mentioned by @cardinal. \u2013\u00a0 Did Jan 15 '13 at 6:55\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/260182/solving-an-equation-with-an-integral/260190\nText:\nTake the 2-minute tour \u00d7\n\nI need to solve the following equation for $v(x)$: $$\\int_0^tv(x)(x+1)dx=f(t)$$ I am given the function $f(t)$. I've done this so far:\n\nIf we derive both sides by $t$, we get $v(t)(t+1)=f'(t)$ and $\\bar{v}(t)=\\frac{f'(t)}{t+1}$. The problem is that I am still off by a constant, i.e., the above only guarantees that : $\\int_0^t\\bar{v}(x)(x+1)dx+c=f(t)$ which is not enough for me.\n\nshare|improve this question\nHint: consider taking the Fourier or Laplace transform from both sides, solve algebraic equation and making the inverse transform. \u2013\u00a0 m0nhawk Dec 16 '12 at 19:38\n@monhawk: how should that help? \u2013\u00a0 Fabian Dec 16 '12 at 19:38\nIf your $f(0)=0$, then $c\\equiv0$ for any $\\nu(x)$. Isn't it? \u2013\u00a0 0x2207 Dec 16 '12 at 19:38\n@0x2207: yes, the constant is in fact $f(0)$. \u2013\u00a0 Fabian Dec 16 '12 at 19:39\n@Fabian, from definition $\\int_{0}^{0} g(x) dx \\equiv 0$ \u2013\u00a0 0x2207 Dec 16 '12 at 19:40\nshow 7 more comments\n\n2 Answers\n\nup vote 2 down vote accepted\n\nIt is easy to see that the constant $c$ in your post is in fact $f(0)$. Furthermore, a little thought shows that your equations cannot be solved unless $f(0)=0$ (just plug in $t=0$ in your equation and you find $0=f(0)$).\n\nshare|improve this answer\nadd comment\n\nI don't see what is the problem here. Obsviously $f(0)=0$ (for the equation to have a solution) and by deriving as you said, we get $$v(t)=\\frac{f^{\\prime}(t)}{t+1}$$ If we substitue this back in the orginal equation we have $$f(t)=\\int_{0}^{t}f^{\\prime}(x)dx=f(t)-f(0)=f(t)$$ which is true\n\nshare|improve this answer\nThe problem is the given $f(0)\\neq 0$. \u2013\u00a0 Hasanhasan Hasan Dec 16 '12 at 20:27\nThen the problem has no solutions \u2013\u00a0 Nameless Dec 16 '12 at 20:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/36609/what-is-the-nature-of-this-sequence?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\n$3, 4, 10, 33, 136$\n\nwhat will be next most appropriate value? I tried finding any relation in the sequence but i couldn't.\n\n$a.276 $\n\n$b.539 $\n\n$c.612 $\n\n\nshare|improve this question\nIs this just a puzzle or do you have some context you can provide? \u2013\u00a0 Aryabhata May 3 '11 at 6:15\nI have got options with me. $a.276$ $b.539$ $c.612$ $d.685$ \u2013\u00a0 amul28 May 3 '11 at 6:18\nOne option is $685$. $3, 3*1+1 = 4, 4*2 + 2 = 10, 10*3+3 = 33, 33*4+4 = 136, 136*5 + 5 = 685$... But such questions are nonsense as Qwirk's answer shows. I am voting to close a NARQ. \u2013\u00a0 Aryabhata May 3 '11 at 6:21\n@amul: I really don't know. There is no systematic method. Really, such questions are nonsense and solving this one likely won't help you solve other nonsense questions like this. It is unfortunate, but you have to guess what the idiot who wrote the question on the entrance test was thinking of... \u2013\u00a0 Aryabhata May 3 '11 at 6:41\nI agree that questions like this can be frustrating, especially when multiple answers might fit, but I don't agree that they're completely worthless. I think the ability to look at arbitrary data, see patterns, find possible relationships, and then identify the most likely relationship is a critical skill for a mathematician to have. The question isn't \"what was the exam writer thinking when he wrote this?\", it's \"what's the simplest relationship you can find between these numbers?\" \u2013\u00a0 Kevin May 3 '11 at 15:15\nshow 10 more comments\n\n2 Answers\n\nup vote 7 down vote accepted\n\nI agree with all the complaints about this sort of problem, but still.... There are some techniques which work from time to time.\n\nTry taking differences: $4-3=1$, $10-4=6$, $33-10=23$, $136-33=103$, so now we have to explain the sequence $1,6,23,103,\\dots$. Hmm, that doesn't seem very helpful.\n\nOK, subtraction didn't work, try division: $4\\div3=1r1$, $10\\div4=2r2$, $33\\div10=3r3$, $136\\div33=4r4$ - hey, that looks much better! (When I write $arb$, I mean quotient $a$, remainder $b$.)\n\nshare|improve this answer\nseems very clear for me. \u2013\u00a0 amul28 May 3 '11 at 7:09\nWow! I never knew division could be applied. I always used subtraction. +1 for arb notation. Its really helpful. \u2013\u00a0 Shiplu Dec 21 '11 at 7:44\nadd comment\n\nI must say, I have always disliked 'find the next term in the series question'. For any sequence, it is easy to produce any number next (e.g. for a sequence of $n$ terms, pick the $n+1$ number and then fit a polynomial to those $n+1$ terms).\n\nOEIS does not give anything useful for your sequence - how has it arisen?\n\nEdit: For this question, as Moron has shown, the likely answer is 685, based on the sequence $3,3\\times 1 + 1 = 4, 4 \\times 2 + 2 = 10, 10 \\times 3 + 3 = 33, 33 \\times 4 + 4 = 136,$$136 \\times 5 + 5 = 685$ . But in general knowing how to find the pattern in this sequence, will not help (much) in finding patterns in similar sequences.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/325208/the-boundary-of-a-region-for-complex-valued-functions\nText:\nTake the 2-minute tour \u00d7\n\nFrom Chapter $3$ of Stein and Shakarchi's complex analysis book, we have the following problem ($15$):\n\nShow that if $f$ is holomorphic in the unit disc (open), bounded, and converges uniformly to zero in the sector $\\theta<\\arg z<\\varphi$ as $|z|\\to1$, then $f=0$.\n\nWe're supposed to use either the Cauchy inequalities or maximum modulus principle (per the instructions at the beginning, since this is a $4$-part problem), but I don't quite see how to do it using either of those, though the structure of the problem seems to lend itself to the maximum modulus principle. The problem with this is that we know that in the interior of the sector, the function cannot attain a maximum modulus, however, we don't know anything about the boundary of the sector that is in the interior of the circle. This is one obstacle I couldn't quite overcome.\n\nMy approach was to extend the function past the boundary of the circle, which we can do since $f$ is bounded (I think, though even this part is a little bit 'hand-wavy'), and then, since it has a cluster of zeros, the function will be identically zero.\n\nHow should I approach the problem with the intention of using the maximum modulus principle or Cauchy inequalities? Any suggestions would be appreciated. Thanks!\n\nEDIT: I've been thinking about this problem, and I've come up with the following solution:\n\nLet $f$ be an analytic function on $\\mathbb{D}$ (take note that I'm not assuming $f$ is bounded), with the property that for $\\theta<\\arg z<\\varphi$, $|f(z)|$ converges to zero uniformly as $|z|\\to1$ in this sector. Then we can make a 'bump' on the disc in this sector so that it extends in this outside of $\\mathbb{D}$, call this set $\\Omega'$. Define $$g(z)=\\begin{cases}f(z)&:\\,z\\in\\Bbb D\\\\0 &:z\\notin\\Bbb D\\end{cases}.$$ Now, clearly in $\\Bbb D$ $g(z)$ is holomorphic and outside of $\\Bbb D$, it's holomorphic as it's constant, so the only questionable part would be on the boundary of the disc in this sector. At this point, we can take a small disc around each point entirely contained in $\\Omega'$, since it's open, and apply Morera's theorem to show that $g(z)$ is holomorphic here. Therefore, on all of $\\Omega'$, $g$ is holomorphic and has a cluster of zeros, hence is identically equal to zero, therefore $f(z)=0$.\n\nIs this proof correct? Or did I miss something and there is a counterexample when $f$ is not bounded? If it is correct, it's nice in that the proof didn't rely on the shape of the region at all, only on the fact that there was a nondegenerate connected subset of the boundary with the property. Therefore, we see the exercise as a very special case of the generalized problem.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nA particular case that should help you think of a solution is when the sector is of the form $0\\leq \\text{arg}z \\leq \\pi$. In this case consider $g(z)=f(z)f(-z)$. Since $f$ is bounded, $g$ admits a continuous extension to the boundary of the circle that is $0$ on said boundary. The maximum modulus principle gives the result.\n\nshare|improve this answer\nYour argument may be fixed, but note that it's not true that any bounded analytic function admits a continuous extension to the boundary. (The assumption on $f$ in the statement of the problem is important.) \u2013\u00a0 mrf Mar 9 '13 at 16:33\n@mrf: That's why I said that $g$, not $f$, admits a continous extension (the boundedness of $f$ is used to ensure that $g$ tends to zero at the boundary, not as automatic extension). \u2013\u00a0 Jose27 Mar 9 '13 at 18:33\n@Jose27: I've updated an argument of my own; would you take a look and let me know your thoughts? \u2013\u00a0 Clayton Mar 12 '13 at 2:01\n@mrf: I've added an argument of my own; would you take a look and let me know your thoughts? Thanks! \u2013\u00a0 Clayton Mar 12 '13 at 2:01\nHow do you generalize this to arbitrary $\\theta,\\varphi$? I don't quite see it. \u2013\u00a0 Clayton Mar 12 '13 at 12:15\n\nFirst of all, I think you should upvote (if you haven't already) and accept Jos\u00e9's answer, which seems like the canonical answer.\n\nTo address the follow up questions and remarks:\n\nI think your argument is correct, but it took me a little while to see why the integral of $g$ over a curve that crosses $\\partial\\mathbb{D}$ should be zero. You should provide some more details here.\n\nThe result is certainly true without assuming that $f$ is bounded. Here is another way to see this: Instead of bumping $\\partial\\mathbb{D}$ outward, we can create an inward bump. More precisely, let $U$ be an open subset of $\\mathbb{D}$ whose closure contains a (non-empty) arc on which $f$ extends to $0$. By shrinking $U$ a little, we can assume that $f$ is bounded on $U$, that $U$ is simply connected and that the boundary of $U$ is reasonably smooth. Map $U$ biholomorphically onto the unit disc (Carath\u00e9odory's theorem assures that the Riemann map extends continuously up to the boundary, so the arc maps onto another non-empty arc). This construction reduces the problem the the case where $f$ is bounded, and we can apply Jos\u00e9's solution and pull it back. Hence $f = 0$ on an open set, and by the identity theorem, $f = 0$ everywhere.\n\nshare|improve this answer\nI've upvoted Jose's answer. I understand about half of your answer, though. It sounds legitimate, but I'm unfamiliar with what it means to map something biholomorphically, conformal mappings for Caratheodory's theorem, Riemann maps, etcetera. When I get time, I'll read into these topics as much as I can and inform myself about your answer. \u2013\u00a0 Clayton Mar 12 '13 at 13:40\n@Clayton Ok, I thought you were aware of Riemann's mapping theorem. \u2013\u00a0 mrf Mar 12 '13 at 13:56\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/151885/zeroing-out-lower-order-terms-in-generating-function/151888\nText:\nTake the 2-minute tour \u00d7\n\nGiven a generating function $F(x)=a+bx+cx^2+dx^3+\\dotsb$, how do I truncate the $n$ lower order terms to get, for example if $n=2$: $cx^2+dx^3+\\dotsb$?\n\nFor example, if I wanted to find $0a+1b+2c+\\dotsb$, I would evaluate $$\\left.\\frac{dF(x)}{dx}\\right|_{x=1}$$\n\nThis procedure can be used to find the expected value of a probability distribution given its generating function.\n\nI want something similar for truncation of lower-order terms. This would give a cdf for a probability distribution. Since the cdf has a nice form for a binomial generating function, this suggests that there might be a nice way to arrive at it using generating function operators.\n\nI vaguely remember learning this once, but flipping through the book generatingfunctionology didn't yield it.\n\nshare|improve this question\nBy what available means? Obviously subtracting $a+bx$ from $F(x)$ works for your example, and is easily generalized... \u2013\u00a0 anon May 31 '12 at 4:09\n@anon: I've added to my question to make it more clear. \u2013\u00a0 Neil G May 31 '12 at 4:12\nIf differentiation and evaluation are all you have at hand, you can truncate by subtracting a partial Taylor expansion - however, without convergence (e.g. $\\sum n!x^n$) I'm unsure if truncation is obtainable with these two operations alone. \u2013\u00a0 anon May 31 '12 at 4:16\n@anon: There are other operations available, but I don't know what they are. \u2013\u00a0 Neil G May 31 '12 at 4:23\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nIf $f(x) = \\sum\\limits_{n=0}^\\infty a_n x^n$, then $f''(x) = \\sum\\limits_{n=2}^\\infty a_n n (n-1) x^{n-2}$, and $$ \\int_0^x (x-t) f''(t)\\ dt = \\sum_{n=2}^\\infty a_n x^n. $$ EDIT: More generally, $$ \\int_0^x \\dfrac{(x-t)^{k-1}}{(k-1)!} f^{(k)}(t)\\ dt = \\sum_{n=k}^\\infty a_n x^n. $$\n\nshare|improve this answer\nAwesome! Generating functions are the first time in my adult life that math felt like magic. \u2013\u00a0 Neil G May 31 '12 at 4:32\nWould you mind adding a line or two to make it clear why the antiderivative works here? \u2013\u00a0 Neil G May 31 '12 at 4:38\n$\\int_0^t f''(s)\\ ds = \\sum_{n=2}^\\infty a_n \\int_0^t n(n-1) s^{n-2}\\ ds = \\sum_{n=2}^\\infty a_n n t^{n-1}$, and so $\\int_0^x \\int_0^t f''(s)\\ ds\\ dt = \\sum_{n=2}^\\infty a_n x^n$. Now interchange the order of integration. \u2013\u00a0 Robert Israel May 31 '12 at 4:45\nPerfect, thank you very much. \u2013\u00a0 Neil G May 31 '12 at 5:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/137592/example-of-a-functor-which-preserves-all-small-limits-but-has-no-left-adjoint?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThe General Adjoint Functor Theorem (Category Theory) states that for a locally small and complete category $D$, a functor $G\\colon D \\to C$ has a left adjoint if and only if $G$ preserves all small limits and for each object $A$ in $C$, $A \\downarrow G$) has a weakly initial set.\n\nCould someone help by giving an example of a functor $G$ that preserves all small limits but has no left adjoint?\n\nshare|improve this question\nLet $\\emptyset$ be the empty category. Then $G : \\emptyset \\to \\mathcal{C}$ preserves all limits (vacuously), but $G$ has no left adjoint if $\\mathcal{C}$ is non-empty. \u2013\u00a0 Zhen Lin Apr 27 '12 at 7:39\n\n2 Answers 2\n\nup vote 9 down vote accepted\n\nA nontrivial example is mentioned in MacLane's Categories for the Working Mathematician , on page 123: consider the category $\\mathbf{CompBool}$ of complete boolean algebras. The forgetful functor $\\mathbf{CompBool} \\to \\mathbf{Set}$ has no left adjoint, but preserves all limits ($\\mathbf{CompBool}$\u00a0is also small-complete). The reason is that, given a denumerable set $D$, one can construct an arbitrarily large complete Boolean algebra generated by $D$ (a fact that was apparently proved by Solvay in 1966), and so the solution set condition in the General AFT fails.\n\nshare|improve this answer\nThank you Martin - really helpful. \u2013\u00a0 Conan Wong May 4 '12 at 10:44\n\nMartin's answer is probably the one you want, but here's another marginally trivial example.\n\nLet $\\mathcal{C}$ be a category and let $\\mathbf{1}$ be the terminal category with only one object and one morphism. The unique functor $G : \\mathcal{C} \\to \\mathbf{1}$ obviously preserves all limits, but $G$ has a left adjoint if and only if $\\mathcal{C}$ has an initial object. Dually, $G$ preserves all colimits and has a right adjoint if and only if $\\mathcal{C}$ has a terminal object.\n\nshare|improve this answer\nThanks Zhen Lin - your example(s) are very helpful too. \u2013\u00a0 Conan Wong May 4 '12 at 10:44\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/148636/how-to-check-whether-a-positive-integer-can-be-written-as-linear-combination-of/148666\nText:\nTake the 2-minute tour \u00d7\n\nLet $n$, $k$ and $m_1, \\dots, m_k$ be positive integers. Which is the most efficient algorithm to find out whether there are positive integers $a_1, \\dots, a_k$ such that $n = \\sum_{i=1}^k a_i m_i$?\n\nTo make things nontrivial, think of $k$ being in the hundreds, and of $n$ and the $m_i$ having hundreds of decimal digits, each. -- Clearly if we would remove the requirement that the $a_i$ are positive, the Chinese Remainder Theorem would tell us the answer -- but we do require them to be positive.\n\nshare|improve this question\nMO is intended for topics at the graduate-school level and above. \u2013\u00a0 Andy Putman Nov 12 '13 at 4:10\nI don\u2019t see how this is not at the graduate-school level or above, nevertheless the problem seems to be equivalent to the unbounded subset-sum problem, whose NP-completeness is mentioned in mathoverflow.net/a/144983/12705 . \u2013\u00a0 Emil Je\u0159\u00e1bek Nov 12 '13 at 12:39\nThe question sounds perfectly legitimate to me (and Emil Je\u0159\u00e1bek provided an answer to it -- maybe he wants to post it as an actual answer as opposed to a comment, now that the question is reopened). \u2013\u00a0 Andr\u00e9 Henriques Nov 12 '13 at 12:47\nAndy, this is an important question related to the works of Sylvester and Frobenius where much was discovered in recent decades. \u2013\u00a0 Gil Kalai Nov 12 '13 at 13:58\nadd comment\n\n1 Answer\n\nThe problem can be thought of as a coin problem. There are $k$ coins with denominations $m_1,\\dots,m_k$ and you want to express an amount $n$ with these coins. As states, the problem is an integer programming question which is NP-complete when $k$ is part of the input. It is in P (with exponential dependence on $k$) when $k$ is fixed by an algorithm by Lenstra.\n\nThe problem is closely related the Frobenius/Sylvester coin problem - to find the minimum $n$ so that every larger integer has such a representation. See here and here. A polynomial algorithm when $k$ is bounded was achieved by Ravi Kannan. (The dependence on $k$ is double-exponential.)\n\nThese two problems (finding a representation for fixed $n$ and finding the value of $n$ above which a representation always exists) represent the first two levels in Presburger Hierarchy. An important open problem here is to find a P-algorithm for higher order problems in the Presburger Hierarchy.\n\nOf course, another important question is how to solve such questions in practice. I suppose other people can answer that better than me. One method that certainly comes to mind is to consider the linear programming relaxation (i.e. to allow rational $a_i$s) and then apply some rounding and \"local\" improvement.\n\nThe range proposed by the OP where $k$ - (the number of coins) is in the hunderds is interesting. I don't know if current algorithms can scratch this value.\n\nshare|improve this answer\nthe coin problem is to find the least integer which is not in the submonoid generated by some natural numbers (assuming the gcd is 1). The problem of the OP is the unbounded subset problem, as mentioned by Emil in his comment, and is NP complete. \u2013\u00a0 Benjamin Steinberg Nov 12 '13 at 14:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/236124/multinomial-distributions/236133\nText:\nTell me more \u00d7\n\nI'm a little bit confused about what the meaning of multinomial distributions, at least from what i've gleaned from the wikipedia page on Multinomial Distribution. In essence, a multinomial distribution is the generalized form of a binomial distribution. That is, outcomes are independent, however there are k possible outcomes, each with k success, which gives the probability mass function:\n\n$Mult(n, p_1, p_2, p_3, ..., p_n) = {n \\choose x_1, x_2, ... x_n} p_1^{x_1} ...p_n^{x_n} $\n\nHowever, shouldn't evaluating only $X_1$ give a binomial distribution since the multinomial is just a generalization of it? But throwing that in, we get: $Mult(n, p_1) = {n \\choose x_1} p_1^{x_1}$ which can't possibly turn into $Bin(n, p) = {n \\choose x} p^x(1-p)^{n-x}$\n\nAm I missing something in my understanding of a multinomial distribution? And if so, how do we get the binomial from the multinomial equation then?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nYour formula for the multinomial distribution is a little off: there should be $k$ different $p$s and $x$s with $\\sum_{i=1}^k x_i=n$, so that the key coefficient is ${n}\\choose{x_1,x_2,\\ldots,x_k}$. (You can confirm this with Wikipedia.)\n\nTo get the binomial distribution, take $k=2$, $x_1=x$, $p_1=p$ and $p_2=1-p$. Then you have ${n}\\choose{x_1,x_2}$$p_1^{x_1}p_2^{x_2}=$$n\\choose x_1$$p^{x_1}(1-p)^{n-x_1}$, as desired.\n\nshare|improve this answer\noh, i think i see what i was missing now... since we only have $p_1$ and $p_2$, $p_2 = 1 - p_1$ by definition. Thanks! \u2013\u00a0 Jaynathan Leung Nov 13 '12 at 2:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mainstreetplaza.com/2012/09/24/mitt-romneys-funny-math/\nText:\nMitt Romney\u2019s Funny Math\n\nSo, Mitt Romney released his 2011 tax return. The newspapers report that Mitt and Ann Romney engineered their tax return to show that he paid 14.1% of his income in taxes. The primary mechanism employed to engineer their tax return, according to the press reports, was to not claim all the charitable deductions Mitt and Ann could have claimed. Reportedly, the Romneys donated $4 million to various charities (I wonder which charities?) in 2011. Although they could have claimed a $4 million charitable contribution, the Romneys only claimed $2.5 million in charitable deductions on their return. By doing so, they increased their tax rate to 14.1%. A press release was then issued reporting their effective tax rate.\n\nMy prediction: the first item on Romneys to-do list, whether he wins the election or not, is to file an amended tax return the day after the election, claiming the entire $4 million of charitable contributions, and getting a big fat refund from the IRS that will reduce his effective tax rate to about 10.5%.\n\nBut thats not all . . . the Romneys released a summary of their taxes for the past 20 years, showing that their average tax rate over that time period had never fallen below 13.66%. I love math problems involving average rates. Average rates can mean anything.\n\nFor example, Billy the Hillbilly wants to go to school. The school is 3 miles away. The first mile involves climbing over a mountain with lots of boulders, etc. Over this mile, Billy can only walk 2 miles per hour. After the first mile, Billy comes to a river. There is a path along the river for another mile. While walking along the river, Billy can walk 3 miles per hour. Finally, Billy comes to a road. Billy walks the final mile to school over the road, and can walk 4 miles per hour. What is Billys average speed while walking to school? If you answer 3 miles per hour, Mitt Romney may have tricked you into voting for him (the correct answer is approximately 2.769 miles per hour).\n\nHeres the thing: Romneys summary doesnt tell us much at all. For the first several years of that average rate, Mitt Romney may have been climbing over a number of tax boulders. Paying 18% on $10,000 of income one year, and 10% on $1 million of income the next year, does not mean Romney paid an average tax rate of around 14%. The truth can only be ascertained by examining the details of every tax return for all 20 years. My guess is hell never let us do that.\n\nAny more than hell let us see his underwear.\n\nViews: 1281\n\n\n  1. 1\n    Dan says:\n\n    Interesting idea! But I think you have this all wrong, this is politics! There is not room for FACTS and MATH here!\n\n\n  2. 2\n    Robert says:\n\n    Part of what\u2019s funny about this latest move, the under-reporting of charitable payments in order to keep his reported tax rate higher, is that he is one record at least twice as having said that paying more taxes than required would disqualify him as a presidential candidate.\n\n\n  3. 3\n    mark banta says:\n\n    I\u2019m reminded of Bill Clinton\u2019s recent convention speech in which he derided Romney for his lack of \u201carithmetic.\u201d Yeah, Robert, Romney is all over the map, isn\u2019t he?\n\n\n  4. 4\n    Chris F. says:\n\n    Your math is confusing me there. Simple averages are done by adding the values given and then dividing by the number of values: 2+3+4=9; 9/3=3\n\n    There is the matter of a weighted average, but that doesn\u2019t matter either, because the distances of the legs were all the same.\n\n    You could argue that you need to break the speed up into verticle and horizontal components and only count the horizontal part, but you didn\u2019t supply values for the steepness of the path legs, so that can\u2019t be calculated either.\n\n    How did you come up with 2.769 miles per hour?\n\n\n  5. 5\n    chanson says:\n\n    @4 It depends on whether you\u2019re averaging over time or over distance. Over time:\n\n    He walks 30 min @ 2 mph, then 20 min @ 3 mph, then 15 min @ 4 mph.\n\n    ((30 x 2) + (20 x 3) + (15 x 4))/(30+20+15)\n\n    = (60 + 60 + 60)/65\n\n    approximately 2.769\n\n\n  6. 6\n    kuri says:\n\n    IOW, he walked 3 miles, but it took him 65 minutes, so his speed must be less than 3 miles per hour.\n\n\n  7. 7\n    mark banta says:\n\n    I believe in the Church of Mathematics. It explains so much more than religion!\n\n    Thanks for doing the work, Carol!\n\n\n  8. 8\n    chanson says:\n\n    @6 Ah, yes, that\u2019s a very clear way of seeing it.\n\n\n  9. 9\n    chanson says:\n\n    @7 No problem! :D\n\n\n  10. 10\n    Chris F. says:\n\n    Thanks chanson. I don\u2019t know why I didn\u2019t get that, but it seems obvious now!\n\n\nLeave a Reply\n\n\n\n\n  \u2022 Recent Comments\n\n  \u2022 MSP TV\n\n    Early Mormon sermons deciphered!\n  \u2022 EXMO Radio\n\n    How do you explain The Problem of Good?\n  \u2022 Categories\n\n  \u2022 Archives\n\n  \u2022 Meta\n\n  \u2022 Awards\n\n    Lists of Brodie award winners:\n\n    X-Mormon of the Year 2012: David Twede\n\n    X-Mormon of the Year 2011: Joanna Brooks\n\n    X-Mormon of the Year 2010: Monica Bielanko\n\n    X-Mormon of the Year 2009: Walter Kirn"}
{"text": "Retrieved from http://math.stackexchange.com/questions/184154/prove-the-function-fz-sin-z-frac1z-a-has-infinitely-many-zeros-in-th\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\epsilon $ be a positive real number and $a$ a complex number.\n\nProve the function $f(z)= \\sin z +\\frac{1}{z-a}$ has infinitely many zeros in the strip $|\\mathrm{Im}z| < \\epsilon.$\n\nThanks in advance!\n\nshare|improve this question\nThis is an old qualifying exam problem from Rice: Question 6 on page 6. \u2013\u00a0 yunone Aug 19 '12 at 2:33\nadd comment\n\n1 Answer\n\n  1. I don't understand your argument. Consider the function $e^z$. It takes values $w$ with $Re(w) > 0$ and $Re(w) < 0$ in the strip $\\{z: |\\operatorname{Im}(z)| < \\varepsilon\\}$ but nevertheless it is never equal to $0$.\n\n  2. Hint: let $k$ be large enough and $\\varepsilon$ small enough. Consider the circle of radius $\\varepsilon/2$ around point $2\\pi k$. Specifically, consider the contour $\\phi(t) = 2\\pi k + \\frac{\\varepsilon}{2} e^{it}$ for $t\\in [0, 2\\pi)$.\n\n    a. Prove that $\\sin(\\phi(t))$ makes one revolution around 0.\n\n    b. Prove that $\\sin(\\phi(t)) > \\varepsilon / 4$ (if $\\varepsilon$ is small enough). Thus $f(\\phi(t))$ makes one revolution around $0$ (if $k$ is large enough).\n\n    c. Conclude that $f(z)$ has a zero in the $\\varepsilon/2$ neighborhood of point $2\\pi k$.\n\nshare|improve this answer\nYes I just proved it cuts through $x=0$ I will remove that from my question \u2013\u00a0 clark Aug 19 '12 at 2:29\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58571.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nHow Many Pads of Paper?\n\nDate: 10/30/2001 at 02:23:05\nFrom: Jessica\nSubject: Number Theory\n\npads did he sell?\n\nI don't understand how to solve this without knowing at least one more \nvariable, like how much or what percent they were marked down to.\n\nDate: 10/30/2001 at 08:46:16\nFrom: Doctor Paul\nSubject: Re: Number Theory\n\nThe integer 60377 has only four factors: 1, 173, 349, 60377\n\nSo 60377 = 1 * 60377 or 173 * 349\n\nIt follows then that \n\n   603.77 =  .01 * 60377   or \n            1.73 * 349     or \n             173 * 3.49    or \n               1 * 603.77\n\nBut since we know the merchant charged less than $2.00, we can assume \nhe sold them for either $1.73 each or $.01 each.\n\nIn the former case he sold 349 pads, and in the latter case he sold \n60377 pads.\n\nNotice that 1.73 * 349 = 603.7699999999999999999999999...  and \n.01 * 60377 = 603.77\n\nI'm guessing that the correct answer here is probably 349 since the \nother case is obvious and wouldn't require you to do much work. But if \nthe problem is stated exactly as you have it written above, 60377 \nwould be a legitimate answer as well.\n\nFeel free to write back if you want to talk about this some more.\n\n- Doctor Paul, The Math Forum\nAssociated Topics:\nMiddle School Factoring Numbers\nMiddle School Word Problems\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/32798/partition-function-for-the-jaynes-cummings-hamiltonian?answertab=votes\nText:\nTell me more \u00d7\n\nI was wondering if anyone here has calculated before the partition function for the Jaynes-Cummings Hamiltonian: $H_{JC}=\\omega_0 (a^\\dagger a + \\sigma^+ \\sigma^-)+g (a \\sigma^+ +a^\\dagger \\sigma^-)$ (Here I have assumed resonance and $a,a^\\dagger$ are bosonic operators and $\\sigma^-,\\sigma^+$ are ladder operators for a spin one half particle) For the Hamiltonian above the energy of the ground state is zero and corresponds to 0 excitations in the harmonic oscillator and the spin being down. The excited eigenenergies come in pairs and are given by: $\\omega_{n\\pm}=n \\omega_0 \\pm \\sqrt{n}g$. I am interested in knowing the partition function: $\\mathcal{Z}=\\text{tr}( \\exp(-\\beta H_{JC} ))=1+2\\sum_{n=1}^\\infty\\exp(-\\beta \\omega_0 n )\\cosh(\\beta g \\sqrt{n}) $ I tried Mathematica to get an analytic expression for the above sum and it did not work. Any thoughts on whether the summation can be expressed in terms of some special function or how to calculate it numerically in an efficient and reliable way?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nit is not exact and is impossible to compute exactly i recommend to use the Euler method to approximate your series by an integral plus some extra corrections , this Euler-Maclaurin summation converges fast to the exact solution with only a few terms.\n\nshare|improve this answer\nThanks a lot Jose Javier, I will just use what you just wrote :) \u2013\u00a0 Nicol\u00e1s Quesada Jul 26 '12 at 1:53\nAlso do you know any reference related to this specific problem? \u2013\u00a0 Nicol\u00e1s Quesada Jul 26 '12 at 2:32\nno, unfortunately i know no reference to this problem :/ or how the partition funciton is obtained. \u2013\u00a0 Jose Javier Garcia Jul 26 '12 at 8:42\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/239798/how-to-calculate-frac-partialnf-lnx-partial-xn?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nIs there any sophisticated way to find n-th derivative of $f(\\ln(x))$. Function $f \\in C^{\\infty}(\\mathbb R)$. I tried 2nd and 3rd but I can not see any pattern.\n\nshare|improve this question\nYou know the Fa\u00e0 di Bruno formula, I presume? \u2013\u00a0 \uff2a. \uff2d. Nov 18 '12 at 13:10\n@J.M. Yes, I know but this particular problem for Calculus-I and I hope one can do it without this formula. \u2013\u00a0 nikita2 Nov 18 '12 at 13:13\nOkay then, would Stirling cycle numbers fall under the purview of this \"Calculus I\" that you speak of? \u2013\u00a0 \uff2a. \uff2d. Nov 18 '12 at 13:19\n$$\\frac{\\mathrm d^n}{\\mathrm dz^n}f(\\log\\,z)=z^{-n}\\sum_{k=1}^n (-1)^{n-k} \\left[{n}\\atop{k}\\right]f^{(k)}(\\log\\,z)$$ \u2013\u00a0 \uff2a. \uff2d. Nov 18 '12 at 13:22\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nSet $x=e^t$. Then $t=\\log x, f(\\log x)=f(t)$ and: $$\\frac{d}{dx}=\\frac{d}{dt}\\cdot\\frac{dt}{dx}=\\frac{1}{x}\\cdot\\frac{d}{dt}=e^{-t}\\frac{d}{dt},$$ so: $$\\frac{d^n}{dx^n}f(\\log x)=\\left(e^{-t}\\frac{d}{dt}\\right)^n f(t).$$ Now, if you define a sequence of polynomials $\\{p_n(x)\\}_{n\\in\\mathbb{N}}$ such that: $$ p_1(x)=x,\\qquad p_{n+1}(x)= (x-n)\\cdot p_n(x),$$ you clearly have: $$ \\frac{d^n}{dx^n}f(\\log x) = e^{-nt}\\cdot \\left(p_n\\left(\\frac{d}{dt}\\right)f(t)\\right), $$ so: $$ \\frac{d^n}{dx^n}f(\\log x) = \\frac{1}{x^n}\\sum_{j=0}^{n-1}(-1)^{j}\\cdot e_j(1,\\ldots,n-1)\\cdot f^{(n-j)}(\\log x),$$ where $e_j$ is the $j$-th elementary symmetric polynomial.\n\nshare|improve this answer\n\nA pretty easy induction shows:\n\n$$\\frac{d^k}{dx^k}\\{f(\\log(x)\\}=\\left(\\left(P_k\\left(\\frac{d}{dx}\\right)f\\right)\\circ\\log\\right)(x)\\cdot x^{-k} $$\n\nwhere the polynomial $P_k$ is given by\n\n$$P_k(x):=\\prod_{j=0}^{k-1}(x-j) $$\n\nHopefully this formula is something like what you are after.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70851/free-product-of-boolean-algebras?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nGiven a family of Boolean algebras $\\mathcal{B}=\\{B_i\\colon i\\in I\\}$ with respective Stone spaces $S_i$. Recall that the algebra of clopen (both closed and open) subsets of the product space\n\n$$\\prod_{i\\in I}S_i$$\n\nis said to be the free product of $\\mathcal B$. This algebra is typically denoted by\n\n$$\\bigotimes_{i\\in I}B_i$$\n\n(and I will use the standard \"tensor\" notation for finite free products in the obvious manner).\n\nI am interested in the (possible) Boolean algebras which admit only very particular decomposition in terms of the free product:\n\nIs there an uncountable Boolean algebra $B$ such that if $B$ is isomorphic to $A\\otimes C$ then either $A$ or $C$ is countable?\n\nshare|improve this question\nRemark: This tensor product is just the usual tensor product of algebras over $\\mathbb{F}_2$. \u2013\u00a0 Martin Brandenburg Jul 21 '11 at 10:26\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nTranslating this to Boolean spaces, you are looking for a Boolean space X which is not second countable, but cannot be written as a product of two factors of the same type (i.e., not second countable).\n\nHave you considered the compact space $[0,\\omega_1]$? It is certainly not the product of two uncountable spaces, as such a product would contain two almost disjoint closed uncountable sets. On the other hand, a countable Boolean space cannot have uncountably many clopen sets.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://coxmath.blogspot.com/2011/03/to-lcd-or-not-to-lcd.html\nText:\nMonday, March 28, 2011\n\nTo LCD or Not To LCD\n\n\n\n\n\n\nWith LCD and without LCD.\n\nIf you want the original GeoGebra files: \u00a0LCD, NO LCD\n\n\nCarlberg said...\n\nI think this is a very interesting point, but I wonder if students could develop intuition for the non-LCD method without already knowing the LCD method.\n\nmartinandersongraham said...\n\nI feel good about what we do with LCD because it really drills down into understanding factored form and common multiples, even if students don't express it that way. That is, I find harping on LCD helps them connect algebraic fraction to numerical ones.\n\nHowever, my students know that finding a CD is more important than finding the LCD - we talk instead of efficiency.\n\nmisscalcul8 said...\n\nI think Not To LCD because after the initial presentation of the concept, we basically skip to CD instead of LCD anyway.\n\nPaul Hawking said...\n\nI think fractions are such a beast for most students that they won't make the conceptual leap from using CD for numerical fractions to using CD for algebraic fractions. Meaning if you teach CD for numerical fractions, I don't think it will make it any easier when you teach CD for algebraic fractions. So I'd say do what works best for teaching numerical fractions--I like LCD because it avoids the calculator dependency issue of student's trying to simplify 56/98th and the like without a calculator--and expect the normal amount of challenge that comes when you get to teaching adding algebraic fractions.\n\nPaul Hawking\nThe Challenge of Teaching Math\nLatest post:\nHow do you get students to practice without their notes?\n\nhillby said...\n\nWhen I review fractions with Algebra II, I don't mess around with the LCD. It's such a lame step when I just want them to not flip out about fractions.\n\nOf course, I also tell kids that if you can't pull out a 2 or 3, I don't really care if it gets reduced.\n\ngasstationwithoutpumps said...\n\nI think that too much time on LCD detracts from understanding. The crucial concept is that a common denominator is needed\u2014LCD is an efficiency hack. I would teach the general form of fraction addition first, since it is universally useful, and LCD only as a cool thing to do to save effort.\n\nIncidentally, I mis-parsed the title when I saw it in my feed reader. If you can't find the Liquid Crystal Display, how can you read the blog post?"}
{"text": "Retrieved from http://mathoverflow.net/questions/15853/disintegrations-are-measurable-measures-when-are-they-continuous?sort=oldest\nText:\nTell me more \u00d7\n\nThis is a sequel to another question I have asked.\n\nThe notion of disintegration is a refinement of conditional probability to spaces which have more structure than abstract probability spaces; sometimes this is called regular conditional probability. Let $Y$ and $X$ be two nice metric spaces, let $\\mathbb P$ be a probability measure on $Y$, and let $\\pi : Y \\to X$ be a measurable function. Let $\\mathbb P_X(B) = \\mathbb P(\\pi^{-1} B)$ denote the push-forward measure of $\\mathbb P$ on $X$. The disintegration theorem says that for $\\mathbb P_X$-almost every $x \\in X$, there exists a nice measure $\\mathbb P^x$ on $Y$ such that $\\mathbb P$ \"disintegrates\":$$\\int_Y f(y) ~d\\mathbb P(y) = \\int_X \\int_{\\pi^{-1}(x)} f(y) ~d\\mathbb P^x(y) d\\mathbb P_X(x)$$ for every measurable $f$ on $Y$.\n\nThis is a beautiful theorem, but it's not strong enough for my needs. Fix a Borel set $B \\subseteq X$, and let $p(x) = \\mathbb P^x(B)$. Part of the theorem is that $p$ is a measurable function of $x$. Suppose that the map $\\pi : Y \\to X$ is continuous instead of simply measurable. My question: What is a general sufficient condition for $p(x)$ to be continuous?\n\nTo me, this is an obvious question to ask, since if $x$ and $x'$ are two close realizations of a random $x \\in X$, then the measures $\\mathbb P^x$ and $\\mathbb P^{x'}$ should be close too, at least in many natural situations. However, in my combing through the literature, I haven't been able to find an answer to this question. My guess is that most people are content to integrate over $x$ when they use the theorem. For my purposes, I need some estimates which I get by continuity.\n\nAt this point, I've managed to prove and write down a pretty good sufficient condition for the case I care about (Banach spaces), using an abstract Wiener space-type construction. However, I am hoping that an expert can point me toward a good reference that does this in wider generality.\n\nshare|improve this question\nB must be a subset of Y? \u2013\u00a0 Andrey Gogolev Feb 20 '10 at 1:09\nAlso, sufficient condition on what, on B, on pi, both? \u2013\u00a0 Andrey Gogolev Feb 20 '10 at 1:24\nAndrey: B above is a Borel set in Y. The function pi need only be measurable for the general disintegration theorem to apply. However, in my case, pi is continuous function. \u2013\u00a0 Tom LaGatta Feb 20 '10 at 15:21\nadd comment\n\n3 Answers\n\nTue Tjur studied the existence of continuous disintegrations in a 1975 preprint \"A Constructive Definition of Conditional Distributions,\" Issue 13, Copenhagen Universitet. He gives necessary and sufficient conditions for their existence, at least in the setting of Radon measures.\n\nHe also discusses sufficient structure, and there considers a basic probability space that is an open subset of a finite-dimensional Euclidean space and the problem of conditioning on a random variable taking values in an open subsets of a Euclidean space $\\mathbb R^k$ such that, when the random variable is considered as a (measurable) function, it is surjective and continuously differentiable with differential of maximal rank. This particular special case may be too narrow for you, but perhaps the general case can give you some guidance.\n\nThe article is a bit hard to track down, so let me know if you need help finding it. The existence of continuous disintegrations arises also in the study of the computability of conditional probability, which is my interest.\n\nshare|improve this answer\nadd comment\n\nProbably is not general as you want, but if you don't think before about that can be a begining...\n\nProposition: If $\\pi:Y\\to X$ is bijective function such that $\\pi^{-1}$ is continuous then $\\mathbb{P}^{x_n}\\to\\mathbb{P}^{x}$ (weak topology) whenever $x_n\\to x$.\n\nProof: it follows from the Disintegration Theorem that for all $B\\in\\mathcal{B}(Y)$ we have\n\n$$ \\begin{array}{rcl} \\mathbb{P}(B)&=&\\displaystyle\\int_X\\int_{\\pi^{-1}(x)}\\chi_B(y)\\ d\\mathbb{P}^x(y)\\ d\\mathbb{P}_X(x) &=&\\displaystyle\\int_X \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) \\end{array} $$ For the other hand we have that $$ \\mathbb{P}(B)=\\displaystyle\\int_X \\chi_B(\\pi^{-1}(x))\\ d\\mathbb{P}_X(x) =\\displaystyle\\int_X \\chi_B(\\pi^{-1}(x))\\delta_{\\pi^{-1}(x)}(\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) $$ so $$ \\displaystyle\\int_X \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x)=\\mathbb{P}(B)=\\displaystyle\\int_X \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x)) \\ d\\mathbb{P}_X(x) $$\n\nSince $\\mathbb{P}^x$ is a probability measure and $B\\cap\\pi^{-1}(x)$ is a singleton or empty set, we have $$ \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x))\\geq \\mathbb{P}^x(B\\cap\\pi^{-1}(x)) $$ and from previous integral equality almost surely we have $$ \\delta_{\\pi^{-1}(x)}(B\\cap\\pi^{-1}(x))=\\mathbb{P}^x(B\\cap\\pi^{-1}(x)). $$ Fix $x$ and take $B=\\pi^{-1}(x)$, then from the above equality, follows that $\\mathbb{P}^x=\\delta_{\\pi^{-1}(x)}$.\n\nIf $x_n\\to x$ then $p(x_n)=\\mathbb{P}^{x_n}$ converge to $p(x)$ in the weak topology. In fact, by the continuity of $\\pi^{-1}$ we get that $\\int f\\ p(x_n) \\to\\int f\\ p(x)$ for all bounded uniformly continuous functions $f$.\n\nshare|improve this answer\nadd comment\n\nI think you need some hypothesis on the measure to be pushed, at least in the very common case where $\\pi$ is the projection to a factor in a product.\n\nTake any family $\\mathbb{P}^x$ of measures in a space $X'$, where $x$ runs over $X$, and let $Y=X'\\times X$, $\\pi$ be the projection on $X$, and $\\mathbb{P}=\\int_X \\mathbb{P}^x dx$ where $dx$ is any measure on $X$. Then $\\pi$ is very regular (smooth if $X'$ and $X$ are smooth manifolds for example) but yet, any kind of lack of regularity can appear in $\\mathbb{P}^x$ (which are by construction the disintegration measures, since they are unique up to a negligible set).\n\nI guess that in this setting, assuming $\\mathbb{P}$ to be absolutly continuous with continuous density would be sufficient.\n\nEdit: My guess seems wrong, as is shown by the restriction of Lebesgue measure to a L shaped polygon. You will probably need strong restrictions on $\\mathbb{P}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/2988/how-fast-can-we-find-all-four-square-combinations-that-sum-to-n\nText:\nTell me more \u00d7\n\nA question was asked at Stack Overflow (here):\n\nGiven an integer $N$, print out all possible combinations of integer values of $A,B,C$ and $D$ which solve the equation $A^2+B^2+C^2+D^2 = N$.\n\nThis question is of course related to Bachet's Conjecture in number theory (sometimes called Lagrange's Four Square Theorem because of his proof). There are some papers that discuss how to find a single solution, but I have been unable to find anything that talks about how fast we can find all solutions for a particular $N$ (that is, all combinations, not all permutations).\n\nI have been thinking about it quite a bit and it seems to me that it can be solved in $O(N)$ time and space, where $N$ is the desired sum. However, lacking any prior information on the subject, I am not sure if that is a significant claim on my part or just a trivial, obvious or already known result.\n\nSo, the question then is, how fast can we find all of the Four-Square Sums for a given $N$?\n\nOK, here's the (nearly) O(N) algorithm that I was thinking of. First two supporting functions, a nearest integer square root function:\n\n    // the nearest integer whose square is less than or equal to N\n    public int SquRt(int N)\n        return (int)Math.Sqrt((double)N);\n\nAnd a function to return all TwoSquare pairs summing from 0 to N:\n\n    // Returns a list of all sums of two squares less than or equal to N, in order.\n    public List<List<int[]>> TwoSquareSumsLessThan(int N)\n        //Make the index array\n        List<int[]>[] Sum2Sqs = new List<int[]>[N + 1];\n\n        //get the base square root, which is the maximum possible root value\n        int baseRt = SquRt(N);\n\n        for (int i = baseRt; i >= 0; i--)\n                int sum = (i * i) + (j * j);\n                if (sum > N)\n                    //make the new pair\n                    int[] sumPair = { i, j };\n                    //get the sumList entry\n                    List<int[]> sumLst;\n                    if (Sum2Sqs[sum] == null)\n                        // make it if we need to\n                        sumLst = new List<int[]>();\n                        Sum2Sqs[sum] = sumLst;\n                        sumLst = Sum2Sqs[sum];\n                    // add the pair to the correct list\n\n        //collapse the index array down to a sequential list\n        List<List<int[]>> result = new List<List<int[]>>();\n        for (int nn = 0; nn <= N; nn++)\n            if (Sum2Sqs[nn] != null) result.Add(Sum2Sqs[nn]);\n\n        return result;\n\nFinally, the algorithm itself:\n\n    // Return a list of all integer quads (a,b,c,d), where:\n    //      a^2 + b^2 + c^2 + d^2 = N,\n    // and  a >= b >= c >= d,\n    // and  a,b,c,d >= 0\n    public List<int[]> FindAllFourSquares(int N)\n        // get all two-square sums <= N, in descending order\n        List<List<int[]>> Sqr2s = TwoSquareSumsLessThan(N);\n\n        // Cross the descending list of two-square sums <= N with\n        // the same list in ascending order, using a Merge-Match\n        // algorithm to find all combinations of pairs of two-square\n        // sums that add up to N\n        List<int[]> hiList, loList;\n        int[] hp, lp;\n        int hiSum, loSum;\n        List<int[]> results = new List<int[]>();\n        int prevHi = -1;\n        int prevLo = -1;\n\n        //  Set the Merge sources to the highest and lowest entries in the list\n        int hi = Sqr2s.Count - 1;\n        int lo = 0;\n\n        //  Merge until done ..\n        while (hi >= lo)\n            // check to see if the points have moved\n            if (hi != prevHi)\n                hiList = Sqr2s[hi];\n                hp = hiList[0];     // these lists cannot be empty\n                hiSum = hp[0] * hp[0] + hp[1] * hp[1];\n                prevHi = hi;\n            if (lo != prevLo)\n                loList = Sqr2s[lo];\n                lp = loList[0];     // these lists cannot be empty\n                loSum = lp[0] * lp[0] + lp[1] * lp[1];\n                prevLo = lo;\n\n            // do the two entries' sums together add up to N?\n            if (hiSum + loSum == N)\n                // they add up, so cross the two sum-lists over each other\n                foreach (int[] hiPair in hiList)\n                    foreach (int[] loPair in loList)\n                        // make a new 4-tuple and fill it\n                        int[] quad = new int[4];\n                        quad[0] = hiPair[0];\n                        quad[1] = hiPair[1];\n                        quad[2] = loPair[0];\n                        quad[3] = loPair[1];\n\n                        // only keep those cases where the tuple is already sorted\n                        //(otherwise it's a duplicate entry)\n                        if (quad[1] >= quad[2]) //(only need to check this one case, the others are implicit)\n                        //(there's a special case where all values of the 4-tuple are equal\n                        // that should be handled to prevent duplicate entries, but I'm\n                        // skipping it for now)\n                // both the HI and LO points must be moved after a Match\n            else if (hiSum + loSum < N)\n                lo++;   // too low, so must increase the LO point\n            else    // must be > N\n                hi--;   // too high, so must decrease the HI point\n        return results;\n\nAs I said before, it should be pretty close to O(N), however, as Yuval Filmus points out, as the number of Four Square solutions to N can be of order (N ln ln N), then this algorithim could not be less than that.\n\nshare|improve this question\nI can think of a $O(N^2)$ time algorithm. If you want to, I can post the details. How can you do it in linear time? \u2013\u00a0 Juho Aug 1 '12 at 20:57\nYes, please post it. I'm still developing the linear algorithm details, but I'm pretty sure it's valid. \u2013\u00a0 RBarryYoung Aug 1 '12 at 21:04\nFor the record, it appears that sometimes there are as many as $\\Omega(N\\log\\log N)$ solutions, so we can't really have an $O(N)$ algorithm. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 14:37\nFrom here, it looks like the catch (and the extra non-linear factor) comes from the two foreach() loops within your main while loop; your total time is basically $\\displaystyle\\sum_{i=0}^{N/2} |hiList_{N-i}|*|loList_i|$, and the problem is that the sizes of hiList and loList aren't necessarily bounded by any constant. \u2013\u00a0 Steven Stadnicki Aug 2 '12 at 18:30\nYes, that's correct, however your formula's a little bit off because first i ranges from 0 to apprx. N*PI/8, and second only a fraction of the values of i satisfy hiList(N-i)+loList(i) = N, so they are not all added in. In any event, there's no way to fix this and I am pretty sure that this gives the minimum possible complexity of O(N*log(log(N))). \u2013\u00a0 RBarryYoung Aug 2 '12 at 21:11\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nJuho's algorithm can be improved to an $O(N)$ algorithm using meet-in-the-middle. Go over all pairs $A,B \\leq \\sqrt{N}$; for each pair such that $M=A^2+B^2 \\leq N$, store $(A,B)$ in some array $T$ of length $N$ (each position $M$ could contain several pairs, which might be stored in a linked list). Now go over pairs $M,N-M$ such that the corresponding cells in $T$ are non-empty.\n\nThis way we get an implicit representation of all quadruples. If we want to list all of them, then we can't do any better than $\\Omega(N\\log\\log N)$, since Jacobi's four square theorem shows that (for odd $N$) the number of representations is $8\\sigma(N)$, and there are infinitely many integers such that $\\sigma(N) \\geq (e^\\gamma - \\epsilon) N\\log\\log N$ (see Gr\u00f6nwall's theorem).\n\nIn order to get less trivial algorithms, one can try to factor $N$ over the appropriate quaternion ring, since we know that the representations as sums of two squares correspond (in some sense) to these factorizations, through Lagrange's four-square identity. We would still need to find all representations of any relevant prime.\n\nshare|improve this answer\nHmm, the meet-in-the-middle thing sounds very similar to what I am working on (almost done) which is an ascending/descending Merge-Match algorithm over the TwoSquare pairs. Does that sound the same? \u2013\u00a0 RBarryYoung Aug 2 '12 at 14:35\nIt's probably the same, meet-in-the-middle is such a common heuristic that it must have many different names. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 14:36\nUmm, I've been out of academia for thirty years, what's the $\\sigma(N)$ thing mean? (or can you point me to a reference?) thnx. \u2013\u00a0 RBarryYoung Aug 2 '12 at 14:40\nOr is that $\\sigma(N)$ really a $\\omicron(N)$? \u2013\u00a0 RBarryYoung Aug 2 '12 at 15:01\nSum of divisors function indeed. \u2013\u00a0 Yuval Filmus Aug 2 '12 at 15:48\nshow 1 more comment\n\nI think a $o(N^2)$ time algorithm is not a trivial one and requires some insight if one exists. The obvious algorithm that runs in quadratic time enumerates all tuples $A,B,C,D \\leq \\sqrt[]{N}$. This can be done in four loops, so the total time complexity becomes $O(N^2)$. It also clearly enumerates all solutions.\n\nAs relating algorithms, Rabin and Shallit [1] present two randomized algorithms for decomposing integers as sum of squares. For two squares, they give a $O(\\log^2 n)$ expected time algorithm. For four squares, they give a $O(\\log^2 n \\log \\log n)$ expected time algorithm. Note that the algorithms don't give you all the solutions, but merely just one.\n\n[1] M. O. Rabin, J. O. Shallit, Randomized Algorithms in Number Theory, Communications on Pure and Applied Mathematics 39 (1986), no. S1, pp. S239\u2013S256.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/2166/bertrands-postulate/2173\nText:\nTake the 2-minute tour \u00d7\n\nStatement For every $n > 1$ there is always at least one prime $p$ such that $n < p < 2n$.\n\nI am curious to know that if I replace that $2n$ by $2n-\\epsilon$, ($\\epsilon>0$) then what is the $\\inf (\\epsilon)$ so that the inequality still holds, meaning there is always a prime between $n$ and $2n-\\epsilon$\n\nshare|improve this question\n\n4 Answers 4\n\nup vote 2 down vote accepted\n\nThree related points are worthy of mention, showing that epsilon can be close to n.\n\nThere is a result of Finsler that approximates how many primes lie between n and 2n, which is of order o(n/log(n)) as is to be expected by the Prime Number Theorem.\n\nLiterature on prime gaps will tell you the exponent delta such that there is (for sufficiently large n) at least one prime in the interval (n , n + n^delta). I think delta is less than 11/20.\n\nObserved data suggests that n^delta can be replaced by something much smaller: for n between something like 3 and 10^14 , some function like 2(log(n))^2 works.\n\nshare|improve this answer\n\nBertrand's postulate is\n\nif n > 3 is an integer, then there always exists at least one prime number p with n < p < 2n \u2212 2.\n\nThus \u03b5 < 2 for n > 3. What if n \u2264 3?\n\n  \u2022 For n = 3, 3 < 5 < 6 - \u03b5 \u21d2 \u03b5 < 1\n  \u2022 For n = 2, 2 < 3 < 4 - \u03b5 \u21d2 \u03b5 < 1\n\nHence we have 0 < \u03b5 < 1, if \u03b5 is a constant.\n\nshare|improve this answer\nnow the question may be more interesting. I actually wanted to find the least postive $\\epsilon$ such that the condition remains true. \u2013\u00a0 anonymous Aug 11 '10 at 16:21\n@Chandru1: Any \u03b5 between 0 and 1 will do, so the infimum of all possible positive \u03b5 is 0. This is not surprising. Did you want the supremum instead? (The supremum is 1 of you want it to hold for n=2 or 3, and infinity if you only want sufficiently large n.) \u2013\u00a0 ShreevatsaR Aug 11 '10 at 16:44\n@ShreevatsaR : Hi i got it. \u2013\u00a0 anonymous Aug 11 '10 at 16:50\n\nThe answer depends if you want an answer that is true \"for all n\" or an answer that is true \"for all sufficiently large n.\" For instance, there is not always a prime in an interval of the form (n, 3n/2). Take n=7, for instance. There is always a prime in such an interval \"for sufficiently large n,\" however.\n\nshare|improve this answer\n\nThis was there in the proof of Bertrand's theorem.\n\nif $n>60$, then $\\varepsilon=\\frac{2n}{3}$.\n\nshare|improve this answer\nHi! Welcome to math.SE. This solution would be more helpful if you cited readers to the proof you are referring to. Might you be able to add that? \u2013\u00a0 rschwieb Dec 28 '12 at 14:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/95049/f-nx-p-converge-uniformly-to-nice-fx-p-do-zeros-of-f-n-p-converge-unifor?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nFix compact intervals $X, P \\subseteq \\mathbb{R}$.\n\nLet $f_n : X \\times P \\to \\mathbb{R}$ be a sequence of $C^2$ functions converging uniformly to a $C^2$ function $f$. The first and second derivatives of $f_n$ also converge uniformly to those of $f$.\n\nFor any $p \\in P$, the function $f(\\cdot,p) : X \\to \\mathbb{R}$ has a unique zero $x^*(p)$, and $f_1(x^*(p),p) \\neq 0$. Therefore there is a sequence $x_n^* (p) \\to x^*(p)$ such that $f_n(x_n^*(p),p)=0$ for large $n$.\n\nWhen can we also say that $x_n^*(p) \\to x(p)$ uniformly in $p$? Is there a standard reference for such results?\n\nshare|improve this question\nHow about $f_n(x,p)=(x-p)^2+1/n$? This converges to $f(x,p)=(x-p)^2$, but $f_n(x,p)\\neq 0$ for all $x,p$ and $n$. Therefore, your therefore does not seem right, unless I am misinterpreting something. \u2013\u00a0 Per Alexandersson Apr 24 '12 at 21:01\nI think \" $f_1(x,p)$ \" denotes the partial derivative wrto the first variable, x. In other words, he's in the hypotheses of the implicit function thm. \u2013\u00a0 Pietro Majer Apr 24 '12 at 22:04\n\n1 Answer 1\n\nIt's a quick proof by contradiction.\n\nAssume that $ x _ n ^ * $ does not converge uniformly to $x^*$. Then, there exists $\\epsilon > 0$ and, for all $n\\in \\mathbb{N}$, a point $p_n\\in P$ such that $|x_n ^ *(p _ n)-x ^ *(p _ n)|\\ge\\epsilon$.\n\nA subsequence $\\big( p_{n_k}\\, ,\\, x_ {n_k} ^ *(p _{n_k})\\big)$ converges to some $( p, y ^ * ) \\in P \\times X$, a zero of $f$ different from $(p,x^*(p))$, contradiction.\n\nshare|improve this answer\nNote that this requires nothing about the derivatives, just uniform convergence of $f_n$ to $f$ on $X \\times P$, continuity of $f$ on $X \\times P$, and the fact that $f(\\cdot,p)$ has a unique zero in $X$ for each $p \\in P$. \u2013\u00a0 Robert Israel Apr 26 '12 at 7:36\n(and compactness of $X$ and $P$) \u2013\u00a0 Robert Israel Apr 26 '12 at 7:37\nIndeed. We may say it's an instance of a kind of general situation: \"uniqueness plus compactness gives continuous dependence\". \u2013\u00a0 Pietro Majer Apr 26 '12 at 7:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/289375/bound-for-the-product-of-numbers/289771\nText:\nTake the 2-minute tour \u00d7\n\nLet $n \\in N$. Fix $m \\in [-n,n]$. I am curious, how to bound from above the following expression $$ (n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}}\\leq \\quad ? $$\n\nThank you.\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\n$$ (n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}} = n^{n+3/2}\\exp\\left(\\frac{n-m+2}{2}\\log(1+m/n)+\\frac{n+m+1}{2}\\log(1-m/n))\\right) \\leq n^{n+3/2}\\exp\\left(\\frac{m(n-m+2)}{2n}-\\frac{m(n+m+1)}{2n}\\right) = n^{n+3/2} \\exp\\left(\\frac{m-2m^2}{2n}\\right) \\leq n^{n+3/2} \\exp\\left(\\frac{1}{16n}\\right),$$\n\nand from the Taylor series of $\\log(1+x)$ and $\\log(1-x)$ in a neighbourhood of zero it is not difficult to derive lower bounds, too.\n\nshare|improve this answer\n\n$(n-m)^{\\frac{n-m}{2}+1}(n+m)^{\\frac{n+m+1}{2}}\\leq (2n)^{n+1}(2n)^{n+1/2}=(2n)^{2n+3/2}$\n\nshare|improve this answer\nThank you, but I would like to get more accurate bound. I was trying to maximize this expression, but it turns out that there is no global maximum... Also, I've realized I did not mentioned that $m$ is fixed. Sorry. \u2013\u00a0 Alex Jan 29 '13 at 0:06\n\nI have had good luck tightening bounds by finding the form $(a-b)(a+b)$ which you already have. $$a^2 - b^2 \\le a^2 - b^2 \\le a^2$$ is a much better bound than the naive $$(a-b)^2 \\le (a-b)(a+b) \\le (a+b)^2$$ (with $b \\lt a$)\n\nSo for your problem, I would take as many factors of $n^2 - m^2$ as I can. Which exponent is larger switches at $m=\\frac12$ so treat each interval separately.\n\nFor $m \\ge \\frac 12$ we can break your expression as follows: $$ (n-m)^{\\frac{n-m+2}2} (n+m)^{\\frac{n-m+2}2} (n+m)^{m-\\frac12} $$ which is $$ (n^2-m^2)^{\\frac{n-m+2}2} (n+m)^{m-\\frac12} $$ To simplify the powers I will only eliminate $m$ from the quantities in parentheses. The previous expression is less than: $$ (n^2)^{\\frac{n-m+2}2} (2n)^{m-\\frac12} $$ which equals $$ n^{n-m+2} 2^{m-\\frac12} n^{m-\\frac12} $$ and $$ 2^{m-\\frac12} n^{n+\\frac32} $$\n\nYou can complete the same steps for $m \\le \\frac12$ to obtain a similar expression, then combine these for the overall upper bound.\n\nEdit: with the correction I just made it appears that both cases produce the same expression, so the result above should be the overall upper bound.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://brainmass.com/math/calculus-and-analysis/establish-non-existence-multivariable-limit-245416\nText:\nExplore BrainMass\n\nTo establish non-existence of multivariable limit\n\nWe examine the above function and consider its limit as (x,y)-> (0,0).We take two different paths in the x-y plane for approaching the point (0,0),and find that f(x,y) approaches two different values .This enables us to conclude that the given limit does not exist.For a detailed discussion see the solution given.\n\n\nSolution Preview\n\nFind limit of the function x^2y^2/[x^2y^2 + (x - y)^2] as (x,y) -> (0,0).\n\nTo explain the procedure, first let us consider the case of a single variable function by examining the limit of the function f(x) = |x|/x as x->0. If we are able to show that the left hand limit and right hand limits are unequal then the limit does not exist.\n\nWhen we consider the left hand limit then x->0 by taking values less than zero that is by taking negative values. When x < 0,then |x| = -x and accordingly |x|/x has value -1; this means that ...\n\nSolution Summary\n\nWe consider the limit of a given function f(x,y) of two variables x and y as the point (x,y) approaches a given point (a,b). By taking two different paths for approaching (a,b) ,we show that f(x,y) approaches two different values.This allows us to conclude that the limit in question does not exist."}
{"text": "Retrieved from https://www.physicsforums.com/threads/integration-by-substitution-its-been-a-while.289116/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntegration By Substitution It's Been A While\n\n  1. Feb 1, 2009 #1\n\n    It's been god knows how long since I've had to use integration by substitution. I've totally forgotten it. I am trying to integrate to solve for the value of an electric field at a given point. The integral I am trying to solve is:\n\n    (2kz/4(pi)(epsilon_0)*1/(z^2+x^2)^(3/2) dx.\n\n    I know the answer is (2kz/4(pi)(epsilon_0)*(x/[z^2(z^2+x^2)^(1/2)]\n\n    2. Relevant equations\n\n    I'm sure I have to set u=(z^2+x^2). This makes du = 2x.\n\n    3. The attempt at a solution\n\n    I'm confused as to what to do now. The equation I'm integrating doesn't have an x in it anywhere. I don't think I can say du/2x=dx because I will have x's and u's in the integral, which is no good. However, I can't just ignore it.\n\n    Also, how did that z^2 get in there on the bottom? z is a constant in this integration and since u = z^2+x^2, the z-term drops right out. I feel terribly lost.\n  2. jcsd\n  3. Feb 1, 2009 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    That's really confusing. Why don't you just post the actual problem you are working on and how you tried to solve it?\n  4. Feb 1, 2009 #3\n    Sure thing.\n\n    I'm trying to find the electric field at an arbitrary distance z above a straight line segment, where the arbitrary distance z is measured above one of the endpoints of the line segment.\n\n    Relevant Equations:\n\n    We are given that the electric field of a line charge is [tex]\\frac{1}{4 \\pi \\epsilon_0} \\int_P \\frac{\\lambda (R)}{r^2}dl[/tex].\n\n    Attempt At Solution.\n\n    A little element of the electric field is going to be pointed in two directions. One will be in the z-direction. The other will be in the direction parallel to the line. Using the geometry of the problem, I found that\n\n    [tex] dE=\\frac{1}{4 \\pi \\epsilon_0}\\frac{\\lambda dx}{r^2}(cos(\\theta) \\textbf{z}+sin(\\theta)\\textbf{x})=\\frac{\\lambda}{4 \\pi \\epsilon_0}\\frac{\\lamda dx}{r^3}(z\\textbf{z}+x\\textbf{x})[/tex], where the bold indicates unit vectors.\n\n    I split this up into two integrals. This is where I have to integrate by parts, and where I get stuck. I have for instance, one integral which is [tex]\\frac{1}{4 \\pi \\epsilon_0} \\int_0^L \\frac{2 \\lambda z}{(z^2+x^2)^{3/2}}}dx[/tex].\n\n    I set my u = (z^2+x^2) and my du is then 2xdx. I am confused because there is no x in my numerator, and I can't just say du/2x=dx because then I am going to have both x's and u's in my equation when I integrate it.\n  5. Feb 2, 2009 #4\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Well, if [itex]u = (z^2+x^2)[/itex], then [itex]2x=2\\sqrt{u-z^2}[/itex] right?....but I don't think that makes the integral any easier!\n\n    Try the substitution [tex]u=\\frac{x}{\\sqrt{x^2+z^2}}[/tex] instead :wink:\n  6. Feb 2, 2009 #5\n    Ah, I got it, I think.\n\n    If I use the u-substitution you suggest, I get [tex]du=\\frac{1}{\\sqrt{x^2+z^2}}-\\frac{x^2}{(x^2+z^2)^{3/2}}dx[/tex], which, getting a common denominator yields:\n\n\n    So [tex]\\frac{du}{z^2}=\\frac{dx}{(x^2+z^2}dx[/tex]\n\n    My integral is then just [tex]\\frac{\\lambda z}{4 \\pi \\epsilon_0}\\int_a^b \\frac{du}{z^2}[/tex] which, after re-substituting for u back into x's, and plugging in the bounds 0 and L, I get\n\n    [tex] \\frac{1}{4 \\pi \\epsilon_0} \\frac{\\lambda z L}{z^2(z^2+x^2)^{3/2}}[/tex].\n\n    Thanks, though I still wonder how I would have thought of that particular u-substitution on my own!\n\nHave something to add?\n\nSimilar Discussions: Integration By Substitution It's Been A While\n  1. Integral substitution? (Replies: 3)\n\n  2. Integral substituting (Replies: 4)"}
{"text": "Retrieved from http://mathoverflow.net/questions/82332/seeking-a-solution-algorithm-to-the-3-partition-problem\nText:\nTell me more \u00d7\n\nI need to divide 48 pieces of jewelry between 3 inheritors so as to give equal, or nearly equal value, to each. I have learned that this is called the 3-partition problem. I solved it for 9 pieces of jewely by exhaustive enumeration (some 19,000 possibilities) in a spreadsheet (LibreOffice Calc). No big deal. But all 48 pieces becomes a big deal.\n\nI don't actually need a perfect solution. A heuristic algorithm would suffice if it were acknowledged as an acceptable solution scheme by some set of professionals; programmers, estate settling lawyers, etc. In other words using a technique recognized as \"good enough\" will be good enough for my purpose.\n\nThis question is also posted on StackOverflow. They suggested I post here.\n\nThank you, David\n\nshare|improve this question\nThe problem is NP-complete to find an exact 3-partition; see the short Wikipedia description: So you have two choices: An exhaustive search of all possibilities, or approximation algorithms. \u2013\u00a0 Joseph O'Rourke Dec 1 '11 at 1:58\nTo: Joseph O'Rourke: it is the approximation algorithms that I seek. Where is one described? I've been on mathisfun and codingthewheel and don't find it there. \u2013\u00a0 Grabs At Strawberries Dec 1 '11 at 3:54\nThe first thing I'd do is to take a brief look at how the appraised values are distributed. You may find that it is obviously problematic (for example, if there are just a handful of exceptionally valuable pieces, which can't themselves be divided evenly into thirds, and the remaining pieces can't make up the difference). If you are lucky, there will be many pieces with roughly comparable values. In that case, simple randomized heuristics probably get you close enough for practical purposes (since, unless you actually have an offer on the table, the appraisals will have some error anyway). \u2013\u00a0 Henry Cohn Dec 1 '11 at 4:34\nOne difficulty in giving an abstract answer is that it's not clear how to model this. For example, one could try to bound the worst-case approximation ratio; this is an interesting theoretical question, but I'm not convinced it would shed much light on what you can do in practice. It really depends on the numbers. \u2013\u00a0 Henry Cohn Dec 1 '11 at 4:40\nI suggest you hire a mathematical consultant. Mathematicians have put in the hard yards to get to where they can solve this kind of problem; they deserve to be paid for their specialist skills. \u2013\u00a0 Gerry Myerson Dec 1 '11 at 5:03\nshow 5 more comments\n\n2 Answers\n\nThere exists a pseudo-polynomial time dynamic programming solution to this problem, for which running time and storage complexity depend on the sum of costs of the pieces of jewelry, denoted $S$. If the sum of costs, $S$, is small then the algorithm would be practical as its storage is $O(S^2)$ and its running time is $O(S^2N)$, $N$ being the number of pieces (48 here).\n\nTo get a sense of the algorithm take a look at the Subset sum problem Wikipedia page--dynamic programming solution. This concerns finding a subset of items which sums to a particular cost. Clearly you can solve the 2-partition problem by using the subset sum solutions, i.e., by enumerating over all the potential subset sums, and choosing the one that you prefer for any reason.\n\nNow generalizing to 3-partition is straightforward. You basically solve the double-subset sum problem. You store $Q(i,s, t)$ to be the value (true or false) of \"whether there are two disjoint subsets of $x_1, \\ldots, x_i$ which respectively sum to $s$ and $t$\". You can easily update $Q(i, s, t)$ by adding new items. Again one can enumerate over the potential $Q(N, s, t)$'s and choose the one that is considered best.\n\nObviously even if $S$ is large, the costs can be quantized using larger cost units, which results in a measurable upper bound on the error. This also can be used combined with the solution of Brendan McKay to guide a local search algorithm.\n\nshare|improve this answer\nAs a (perhaps useless) supplement to this description, Exercise 6.25 in the Dynamic Programming chapter of Vazirani's algorithms textbook (PDF: asks to devise \"a dynamic programming algorithm for 3- PARTITION that runs in time polynomial in $n$ and in\" $S$. [p.197] \u2013\u00a0 Joseph O'Rourke Dec 1 '11 at 20:50\nadd comment\n\nTo get a good approximation, I suggest a local refinement algorithm. Define some success measure (like the maximum value of a share minus the minimum value). Start with any distribution into three shares.\n\nNow move a small number of pieces into different shares if they improve the success measure. Keep doing that until no such improvement is possible. With 48 items, you should be able to find a partition where no movement of 4 or fewer items improves the success measure, and this will be a fairly good solution.\n\nStart with different random partitions to see if you get the same final result. If so, there is a fair chance (in practice, not in theory!) that you have the best solution. If you get multiple final results, you can at least choose the best one.\n\nA variation is to allow movement of a small number of pieces with low probability even if the success gets worse. Maybe the probability can depend on how much worse the success gets. This can get you out of local minima but you will never find the global minimum if you set the probabilities too high.\n\nMore sophisticated algorithms like simulated annealing, genetic search, and tabu search are out there and can be adapted to this problem.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/10854/subvalue-and-level/10868\nText:\nTell me more \u00d7\n\nI'm interested in the arguments of f in expressions like\n\n\nBy argument I mean what is here a, b and c. I would like to know the arguments and in what order they appear. For example, the order of the arguments in\n\n f[d]@(2 x f[b])@f[c]@f[q]\n\n\n {d, b, c, q}\n\nHow can I find this from the above expression? I tried to use Level[], but the Subvalue construction is hindering me.\n\nshare|improve this question\nWhat would be an appropriate title for this question? \u2013\u00a0 sjdh Sep 20 '12 at 12:01\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nHere is another way:\n\nCases[f[d]@(2 x f[b])@f[c]@f[q], f[x_] :> x, {-2}, Heads -> True]\nshare|improve this answer\nadd comment\n\nThis works:\n\nexpr = f[d]@(2 x f[b])@f[c]@f[q];\nExtract[expr, Position[expr, f[_]], First]\n   {d, b, c, q}\n\nNote that Extract[] and Position[] are able to handle expressions with any head, not just lists.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/42818/stable-orthogonalization-procedure?sort=newest\nText:\nTell me more \u00d7\n\nAt a high level, my question is the following: given a set of $k$ vectors in Euclidean space which are pairwise \"almost orthogonal\", can one find a set of $k$ orthogonal vectors which are pairwise close to the original ones? This could be seen as a stable version of Gram-Schmidt orthogonalization, in which, under the promise that the original set of vectors is not too far from being orthogonal, one has the guarantee that they do not need to be moved too much in order to become orthogonal.\n\nMore precisely, assume given vectors $v_i$, $i=1,\\ldots,k$ in a real (or complex) $k$-dimensional space, such that $\\sum_{i\\neq j} \\langle v_i,v_j\\rangle \\leq \\epsilon k$ ($\\epsilon$ should be understood as an arbitrarily small constant, or it could even be $o(k)$ if needed -- the weaker the assumption the better). Then, does there exist a set of orthogonal vectors $w_i$ such that $\\sum_i \\|w_i - v_i\\|^2 \\leq \\epsilon' k$? (The norm is the usual Euclidean norm.) The interesting question is whether one can get an $\\epsilon'$ which depends on $\\epsilon$ only, not on $k$.\n\nA related question (the one I am originally most interested in), is that of orthogonalizing $d$-dimensional projector matrices $P_1,\\ldots,P_k$: assume $\\frac{1}{d} \\sum_{i\\neq j} \\langle P_i,P_j \\rangle \\leq \\epsilon$ (where now the inner product is the trace inner product), can you find orthogonal projectors $Q_i$ such that $\\frac{1}{d}\\sum_i \\|P_i-Q_i\\|_F^2 \\leq \\epsilon'$? (Here the norm is the Frobenius norm, the sum of squares of the coefficients.) So far using various iterative procedures I can only get a bound where $\\epsilon' = poly(\\log k) \\epsilon$, but I would like to know if the dependence on $k$ can be removed.\n\nshare|improve this question\nSo in a way Graham-Schmidt may be seen as the greedy approach to this question: Pick the \"new\" n-th vector as the vector on the orthogonal complement of the span of the already picked n-1 vectors closest to the given n-th vector. \u2013\u00a0 HenrikR\u00fcping Oct 19 '10 at 19:22\nYes. Unfortunately it is not \"stable\", in the sense that as the first t vectors get orthogonalized, the overlap of the remaining vectors on the span of the t orthogonal vectors will grow with t, so that it \"costs\" more and more (in terms of distance moved) to make each subsequent vector orthogonal to the previous ones. In my calculations this typically leads to a linear or quadratic dependence of $\\epsilon'$ on k. \u2013\u00a0 Thomas Oct 19 '10 at 19:29\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nUse a Procrustes rotation of the standard basis vectors onto your vectors. This gives the set of orthogonal vectors with the smallest sum of squares of distances to your vectors.\n\n\"The orthogonal Procrustes problem is a matrix approximation problem in linear algebra. In its classical form, one is given two matrices A and B and asked to find an orthogonal matrix R which most closely maps A to B.\"\n\nIn your case you want to find the orthogonal matrix R which most closely maps the standard basis to your matrix. Something like the columns of R should then be the set of orthogonal vectors which are nearest to your vectors, where 'nearest' is in the sense of sum of squares.\n\nshare|improve this answer\nSorry, I should have mentioned all vectors are unit. I am not familiar with Procrustes rotations; is there a good reference to start learning about them (in relation to my original problem)? \u2013\u00a0 Thomas Oct 19 '10 at 19:45\nThat turned out to work pretty well also for the case of the projectors I was mentioning, thanks! \u2013\u00a0 Thomas Oct 21 '10 at 4:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/106828/define-lim-x-rightarrow-0-frac1x-int-0x-et2-dt-what-is-the/135274\nText:\nTake the 2-minute tour \u00d7\n\nThis question is in the section about definite integrals and the task is to calculate the limit. My first idea was division-by-zero but I am very unsure about this. What is the goal here? I then thought that should I investigate things by different limits?\n\nI have simplified this question but similar questions on the page 548 6* here.\n\nshare|improve this question\nThe goal is to see if you have understood the material covered till the fundamental theorem of calculus. \u2013\u00a0 Aryabhata Feb 7 '12 at 22:15\nWhich book did you get this from? \u2013\u00a0 Aryabhata Feb 7 '12 at 22:22\nSure you've seen this theorem if you've gotten that far? The limit is the derivative of $\\int_0^x \\exp t^2 dt$ at $x=0$. \u2013\u00a0 anon Feb 7 '12 at 22:29\n\n3 Answers 3\n\nup vote 8 down vote accepted\n\nYou may re-write what you have as\n\n$$ \\lim_{x\\to 0}\\frac{1}{x-0}\\int_0^x e^{t^2}\\,dt. $$\n\nIf you haven't seen it before,\n\n$$ \\frac{1}{x-0}\\int_0^x e^{t^2}\\,dt $$\n\nis the average value of the function $e^{t^2}$ over the interval $[0,x]$. Now, imagine that $F'(t)=e^{t^2}$. Then by the Fundamental Theorem of Calculus we have\n\n$$ \\int_0^x e^{t^2}\\,dt=F(x)-F(0). $$\n\nThus, your limit becomes\n\n$$ \\lim_{x\\to 0}\\frac{F(x)-F(0)}{x-0}. $$\n\nThis is just the definition of the derivative of $F$ evaluated at $x=0$. But, we know what the derivative of $F(x)$ is, namely $e^{x^2}$.\n\nshare|improve this answer\nWhat about if the other limit is of different form such as $x^{7}$, $ln(x)$ --? Then, it is not exactly the theorem (or the average -analogy). I think I need to do some adjusting or investigation of the limit then somehow? \u2013\u00a0 hhh Feb 7 '12 at 22:53\nFor example, this is not for the def. of derivative so do I need to somehow adjust it? $$\\lim_{x\\rightarrow 3} \\frac{x^{2}-F(9)}{x-3}$$ \u2013\u00a0 hhh Feb 7 '12 at 22:59\n@hhh: Do you mean that to be $F(x^2)$? In that instance, you've got some chain rule stuff going on. \u2013\u00a0 Joe Johnson 126 Feb 8 '12 at 14:17\n\nHINT: Let $$f(x)=\\int_0^x e^{t^2}dt\\;.$$\n\n  1. What is $\\lim\\limits_{x\\to 0}f(x)$?\n  2. What is $f\\,'(x)$?\n  3. L\u2019Hospital\u2019s rule.\nshare|improve this answer\nPerhaps the downvoter would care to explain? The suggested argument is in fact both correct and easy, and the answer has the virtue of not completely doing the homework problem for the OP. \u2013\u00a0 Brian M. Scott Feb 7 '12 at 22:59\nI don't see the point of #3 but I don't get the downvote either. This is basically what I would have said. \u2013\u00a0 anon Feb 7 '12 at 23:03\n@anon: The point of (3) is that you don\u2019t have to recognize this as the limit of a difference quotient: you can also see it simply as a $0/0$ indeterminate form. \u2013\u00a0 Brian M. Scott Feb 7 '12 at 23:07\nIn my opinion, that would defeat the point of the exercise. \u2013\u00a0 anon Feb 7 '12 at 23:10\n@anon: I take a different view of the point of the exercise: I think that the point is the fundamental theorem, as in my point (2). \u2013\u00a0 Brian M. Scott Feb 7 '12 at 23:13\n\ni think that our integral should be understood as the mean value of the exponential on the interval $ (0,x)$ since $ x \\rightarrow 0 $ the mean value on the interval $ (0,0) $ is just $ exp(0)=1$ to $1$ is the answer\n\nshare|improve this answer\nDid you ask the author of the question about his intended method of solution/interpretation? \u2013\u00a0 The Chaz 2.0 Apr 22 '12 at 13:33\n+1 good observation, indeed that is the straightforward interpretation. \u2013\u00a0 hhh Apr 22 '12 at 14:06\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/121561/pigeonhole-principle-question?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThere is a row of 35 chairs. Find the minimum number of chairs that must be occupied such that there are some consecutive set of 4 chairs or more occupied.\n\nI would like to have some hints as to approach this problem. This isn't for homework or anything, I'm just curious as to what would be the best strategy for this problem.\n\nshare|improve this question\nI'd say worst case is groups of $3$ occupied with $1$ open seat between them. So that's $9 \\times 3$ occupied seats and $8 \\times 1$ open seats, i.e. $27$ occupied seats. So I think you need $28$ occupied seats. \u2013\u00a0 TMM Mar 18 '12 at 1:55\nSounds like the answer. Please add it! \u2013\u00a0 user21436 Mar 18 '12 at 2:09\nUhm the best strategy is to try and use the pigeonhole principle? i.e. the title you gave the post. So are you asking how to use pigeonhole? \u2013\u00a0 john w. Mar 18 '12 at 2:50\nSomehow everybody understands that the second sentence contains a negation (the word \"not\"), but unless my eyesight is really betraying me, there is no such negation. For me the answer is obviously $4$. \u2013\u00a0 Marc van Leeuwen Mar 27 '13 at 14:17\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nFor every $4$ seats you need to keep at least $1$ open to not have $4$ consecutive chairs occupied. So divide the row in sets $S_k = \\{4k + 1, 4k + 2, 4k + 3, 4k + 4\\}$ for $k = 0, \\ldots, 7$ and $S_8 = \\{33, 34, 35\\}$. For each set $S_0, \\ldots, S_7$ you need to keep one seat open, so you need at least $8$ open seats to not have a sequence of $4$ occupied seats. This maximum can also be achieved, by leaving seats open at positions $4k$, for $k = 1, \\ldots, 8$.\n\nWith respect to applying the pigeonhole principle: If you do have more than $35 - 8 = 27$ seats filled, then you have at least $25$ seats filled for $S_0, \\ldots, S_7$. Since $25 / 8 > 3$, by the pigeonhole principle one of them must have at least $4$ seats occupied. But then you get a sequence of $4$ occupied seats. So if $28$ or more seats are occupied, you always have $4$ or more consecutive occupied seats.\n\nshare|improve this answer\nThere are 8 pigeonholes.We need to find the minimum pigeons so that at least one pigeon hole contains 4 pigeons.In generalized pigeon hole principle if there are n pigeons and k holes at least one pigeonhole should have $\\lceil n/k \\rceil$ pigeons.Therefore if we have $\\lceil 25/4 \\rceil$=4.So why isn't the answer=25 but 28? \u2013\u00a0 sam_rox Nov 18 '14 at 3:55\n:typo not $\\lceil 25/4 \\rceil$ but $\\lceil 25/8 \\rceil$ \u2013\u00a0 sam_rox Nov 18 '14 at 4:02\nHi Sam. The reason is that there are 35 = 4\u00d78+3 seats. You can apply the pigeonhole to the first 32 seats like you did, so you know that out of those 32 seats, it is possible to fill 24 seats. Add to that the other 3 seats, and you see it is possible to fill 27 seats. (But not 28.) \u2013\u00a0 TMM Nov 19 '14 at 17:26\n\nThis is not really an answer ........Fill the pigeonholes in blocks of 3 with 1 separator (shown as ~) 123~456~789~101112~131415~161718~192021~222324~252627 You can see that 27 is the max that can be occupied with 4 in a row. So if 28 or more seats are occupied, you always have 4 or more consecutive occupied seats. I just made many people's explanation into that...........What is The GENERALISING statement for this type of pigeonhole questions?\n\nshare|improve this answer\nAs you mention, this \"is not really an answer\". Perhaps you have the germ of an idea for asking a generalized version of the question, although it isn't quite polished yet. However the Answer box is only for answers. \u2013\u00a0 hardmath Mar 27 '13 at 13:38\nThis really is an answer, but needs a bit of spit and polish. Wellcome! But consider that this site looks for complete, closed (and we also wish for brilliant, no harm in wishing so near Easter ;) answers to questions. Please try for a more complete answer next time. \u2013\u00a0 vonbrand Mar 27 '13 at 13:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/129195/problem-in-valuation-theory\nText:\nTake the 2-minute tour \u00d7\n\nFind $\\alpha\\in \\mathbb{Q}$, such that $v_2(\\alpha-1/3)\\ge 2$, $v_3(\\alpha-1/2)\\ge 3$ and $|\\alpha-1|_\\infty<1/2$, where $v_p$ is the $p$-adic exponential valuation and $|\\cdot|_\\infty$ is the usual absolute value.\n\nThanks in advance!\n\nshare|improve this question\nIs this homework? What have you tried? \u2013\u00a0 Alon Amit Apr 8 '12 at 6:45\n@Alon Amit, thanks for the comment. I have tried to do some 3-adic and 2-adic expansion for 1/2 and 1/3, respctively, then I may find \u03b1 by the Chinese Remainder Theorem. But I am confused with the expansions, since what I have got is quite different from what I need. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 7:38\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe first two conditions are equivalent to $v_2(3\\alpha-1)\\ge2$ and $v_3(2\\alpha-1)\\ge3$. That is,\n\n$$3\\alpha-1\\equiv 0 \\mod 2^2\\Bbb Z \\qquad and \\qquad 2\\alpha-1 \\equiv 0 \\mod 3^3\\Bbb Z.$$\n\nRewriting each side (note $2^{-1}\\equiv 14\\mod 27$), we obtain\n\n$$\\begin{cases} \\alpha\\equiv -1 \\mod 4 \\\\ \\alpha \\equiv 14 \\mod 27. \\end{cases}$$\n\nBy CRT we have $\\alpha=95 \\mod 108$. We need $|p/q-1|_\\infty <1/2$ while $pq^{-1} \\equiv 95 ~(108)$. The two nontrivial factors of $95$ are $5$ and $19$; we have $5^{-1}\\equiv 65$ and $19^{-1}\\equiv 91 \\mod 108$. The latter is close to $5+108=113$ in the $|\\cdot|_\\infty$ metric, so we check that $|113/91-1|_\\infty<1/2$ indeed holds.\n\nThis gives $\\alpha=113/91$ as one solution.\n\nshare|improve this answer\n@Qiang: If you want to do it by hand it'd be the extendend Euclidean algorithm. Otherwise cheat and consult google for an online applet. :) \u2013\u00a0 anon Apr 8 '12 at 16:22\nAnon, a thousand thanks for your answer! I want to know if there some tricks in solving the equation such as $19x\\equiv1 \\mod 108$? P.S. I thought about the weak approximation theorem later on today, feeling the problem would be solved by the constructive proof. But I didn't really do it after I read your answer. It's a really great answer! \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:25\nAnon, I got it. Thanks. It seems that your solution is actually $\\alpha=113/91$. I'm sorry I cannot @you on this computer. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:37\n@Qiang: Oops, typo. Fixed, thanks. Don't worry, comments on a person's answer always ping that person, so @anon would be redundant here. \u2013\u00a0 anon Apr 8 '12 at 16:50\n\nHint: If $\\alpha = \\frac{a}{b}$ then\n\n$\\alpha-\\frac{1}{2} = \\frac{2a-b}{2b}$\n\n$\\alpha-\\frac{1}{3} = \\frac{3a-b}{3b}$\n\nYou need to make the first fraction divisible by a high power of 3, and the second divisible by a high power of 2. It's easiest to make $b$ relatively prime to 6 so you don't have to worry about the denominators. Pick such a $b$. Can you find an $a$ such that $2a-b$ is divisible by 27? Can you find an $a$ that makes $3a-b$ divisible by 4? Can you find an $a$ that does both? Finally, can you make $a$ close enough to $b$ so that $\\frac{a}{b}$ is not too far from 1?\n\nshare|improve this answer\nAlon, thanks for your hint! I will try that. Later on today, I found that the weak approximation theorem will be useful here. \u2013\u00a0 Qiang Zhang Apr 8 '12 at 16:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/198129/perfect-squares\nText:\nTake the 2-minute tour \u00d7\n\nWonder whether anybody here can provide me with a hint for this one.\n\nIs $c=1$ the only case in which the expression $(c^2+c-1)(c^2-3(c-1))$\n\nreturns a perfect square?\n\nshare|improve this question\n@Ben, so, what's the cutoff? and, why? \u2013\u00a0 Gerry Myerson Sep 18 '12 at 6:43\n@Ben, my experience with people at zero percent is that they are unaware of the accept mechanism and are grateful when it is pointed out to them. If they are aware of the mechanism and truly don't like any of the answers they've had on any of the questions they have asked, why would they keep asking questions here? \u2013\u00a0 Gerry Myerson Sep 18 '12 at 12:51\n@GerryMyerson: well, fair enough, but do you really think that Don Antonio's original comment was helpful in that regard? \u2013\u00a0 Ben Millwood Sep 18 '12 at 13:27\n@Ben, I'm not convinced that anything in this discussion has been helpful, especially as it really belongs elsewhere. Maybe you want to begin a thread on meta, or contribute to one of the already-existing meta threads on accepting answers. \u2013\u00a0 Gerry Myerson Sep 18 '12 at 23:10\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nYes, $c=0$ is the only such value. For the proof, it is useful to let $c=x+1$. Then our expression becomes $$(x^2+3x+1)(x^2-x+1).$$ Note that $x^2-x+1$ is always odd. Any common divisor of $x^2+3x+1$ and $x^2-x+1$ must divide the difference $4x$. But such a common divisor must be odd, so any common divisor must divide $x$. But then it must divide $1$.\n\nThus $x^2+3x+1$ and $x^2-x+1$ are relatively prime. Since $x^2-x+1$ is always positive, it follows that if their product is a perfect square, each must be a perfect square.\n\nBut that can only happen when $x=0$. To prove this, use the fact that for any integer $u$, there is no perfect square strictly between $u^2$ and $(u+1)^2$. Since you asked for a hint, I will, unless you request otherwise, leave out the rest of the argument. It is short.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/213974/norm-of-power-of-matrix-recursive-formula?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI have a question concerning matrix analysis.\n\nlet $A$ be the following $n \\times n$-matrix with non-negative integer entries.\n\n$$\\begin{pmatrix}0&k_2&k_3&\\dots&k_n\\\\ k_1&0&k_3&\\dots&k_n\\\\ k_1&k_2&0&\\dots&k_n\\\\ \\vdots&\\vdots&\\vdots&\\vdots&\\vdots\\\\ k_1&k_2&k_3&\\dots&0\\end{pmatrix}$$\n\ni.e. the $j$-th row of $A$ is $(k_1,k_2,\\dots k_n)-(0,0,...,k_j,0,0)$\n\nHow to express the norm of $A^n$ in terms of $k_1, k_2,\\dots, k_n$ and the entries of $A^{(n-1)}$???\n\nshare|improve this question\nWhich norm?${}$ \u2013\u00a0 Gerry Myerson Oct 15 '12 at 0:41\neither the induced norm or the frobenius norm, \u2013\u00a0 noot Oct 15 '12 at 1:53\nI am asking the growth rate of the norm \u2013\u00a0 noot Oct 15 '12 at 1:53\nInduced --- from what? \u2013\u00a0 Gerry Myerson Oct 15 '12 at 2:53\n\n1 Answer 1\n\nDeriving a relation for the frobenius norm should be easy.\n\nDefine $x_n=[k_1,k_2,\\dots,k_n]^{T}$, then it is straight forward to see that $||A_n||_{F}^{2}=(n-1)||x_n||^2_{2}$. Using this recursive formula, one can derive that $||A_{n+1}||_{F}^{2}=||A_{n}||_{F}^{2}+||x_{n+1}||^2_{2}+(n-1)|k_{n+1}|^{2}$.\n\nDeriving the induced norm case is slightly more involved. But may be this direction can help.\n\nDefine the matrix $T_n=ones(N,N)-I$ where $ones(N,N)$ is a $N \\times N$ matrix with all entries as one and $I$ is the identity matrix. To get a feel of it, for $N=4$, \\begin{align} T_4=\\left[ \\begin{array}{cccc} 0 & 1 & 1 & 1 \\\\ 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 \\\\ 1 & 1 & 1 & 0 \\end{array} \\right] \\end{align} Define $D_n=diag(x_n)$ where $x_n$ is defined as earlier and $D_n$ is the diagonal matrix with $x_n$ as its diagonal entries. Note that now your matrix $A_n$ is\n\n\nNote the observation that the singular values of $T_n$ are $(n-1,1,\\dots,1)$. Consider the problem. \\begin{align} \\max_{||D_{n}^{-1}y||=1} ||T_ny||_{2} \\end{align} I am not sure how exactly you can solve this. Once you can solve that deriving a relation between successive induced norms should be a easy matter.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/173636/putnam-problem-partitioning-integers-with-generating-functions/173675\nText:\nTake the 2-minute tour \u00d7\n\nWe were given the following A-1 problem from the 2003 Putnam Competition:\n\nLet $n$ be a fixed positive integer. How many ways are there to write $n$ as a sum of positive integers, $$ n= a_1+a_2+ \\cdots + a_k$$ With $k$ an arbitrary positive integer, and $a_1 \\le a_2 \\le \\cdots \\le a_k \\le a_1+1$. For example, with $n=4$ there are 4 ways: 2, 2+2, 1+1+2, 1+1+1+1.\n\nI managed to do this by induction, showing that there are always $n$ ways to partition an integer in such a way. In my combinatorics class however, we always solved integer partitioning problems with generating functions and I have been unable to construct one for this problem. I was wondering if the math.stackexchange community could help me out with this and at least give me a nudge in the right direction.\n\n\nshare|improve this question\nfixed, thank you \u2013\u00a0 Jeremy Jul 21 '12 at 15:58\nI assume that first way should be a 4. \u2013\u00a0 Mike Jul 21 '12 at 19:29\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nRecall exponential notation for partitions: $a^b$ signifies $b$ occurrences of $a$ in the partition. (Exponential notation can be useful for seeing the generating functions.) In exponential notation, every partition satisfying your constraints are of the form $m^k (m+1)^l$. In your $n = 4$ example, the partitions are $4^1 5^0$, $2^2 3^0$, $1^2 2^1$, and $1^4 2^0$. Notice that the smaller number, $a_1$, must have exponent at least $1$, while successor can have exponent $0$.\n\nFor a fixed $m$, the contributions from partitions of the form $m^k (m+1)^l$ are given by the following generating function:\n\n$$(x^m + x^{2m} + x^{3m} + \\cdots)(1 + x^{m+1} + x^{2(m+1)} + \\cdots)$$\n\nThis simplifies to:\n\n$$\\frac{x^m}{1-x^m} \\frac{1}{1-x^{m+1}}$$\n\nSuch contributions come from any $m \\geq 1$, and of course, the contributions are disjoint. Thus the full generating function is:\n\n$$\\sum_{m \\geq 1} \\frac{x^m}{1-x^m} \\frac{1}{1-x^{m+1}}$$\n\nThis might already be too great a nudge, but the point is that you now obtain something you can manipulate. After some obvious $1 - x$ factorings and some telescoping, I get $\\frac{x}{(1 - x)^2}$, a generating function for $n$, as desired. Let me know if you get similar results or not.\n\nshare|improve this answer\n\nThis does not really answer the question in the sense that it uses no generating functions. But think of the problem of partitioning any positive number $n$ into a given number $k$ of parts, with $1\\leq k\\leq n$, as equitably as possible, in the sense that no two parts differ by more than $1$ (for if they did, one could make it more equitable by moving a unit from the larger to the smaller part). One solution is to first make $k$ equal parts of size $\\lfloor n/k\\rfloor$, and then if $k$ does not evenly divide $n$ distribute the remaining $n\\bmod k$ units by assigning them randomly to distinct parts, making those $\\lceil n/k\\rceil$ (since the order of parts are not taken into account, it makes no difference which). Can you see why there are no other such equitable partitions of $n$ into $k$ parts? Once this is established, these are clearly the $n$ possible solutions of your problem, one for every $k$.\n\nPersonally, with such a complete description of the solution available, I'm mentally blocked to think how generating functions could be used to find an alternative solution. In fact, I think that the requirement that relates the sizes of different parts (limiting their difference to at most $1$) does not easily translate into the world of generating functions (as one can do for independent conditions on the size of parts, or on multiplicities of a given size).\n\nshare|improve this answer\nThis is a very pleasing solution, one that I prefer to a generating function based solution. As noted in the answer I gave, these partitions are uniquely realizable in exponential form as $m^k (m+1)^l$, where $k \\geq 1$ and $l \\geq 0$. So, there is a generating function approach, and as far as I can tell, the answer can be obtained solely using generating functions. \u2013\u00a0 Hugh Denoncourt Jul 22 '12 at 17:16\nYes I prefer this as well and is essentially the reasoning I used in my original solution, but I was looking for a different way, really to brush up on generating functions. \u2013\u00a0 Jeremy Jul 22 '12 at 20:14\n\nConsider the integer $n$. How are it's partitions related to the partitions of those of integers $k$ where $1 \\le k < n$? Can you find a recursive function that relates these?\n\n(FYI, Project Euler, Problem 76 is a variation of this question.)\n\nshare|improve this answer\nBut the Euler problem doesn't have the restriction that $a_k \\le a_1+1$ \u2013\u00a0 Ross Millikan Jul 22 '12 at 15:40\n@RossMillikan Thus I qualified my statment with the word \"variation.\" \u2013\u00a0 Code-Guru Jul 22 '12 at 17:37\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/130902/counting-the-number-of-squares-on-an-n-times-n-board\nText:\nTake the 2-minute tour \u00d7\n\nYesterday I was asked by a friend how many squares are in a chess board of $8\\times 8$. I thought about 64 immediately, but of course this is not the solution, there are much more.\n\nSo the number of squares is: $$8\\times 8 + 7\\times 7 + 6\\times 6 + 5\\times 5 + 4\\times 4 + 3\\times 3 + 2\\times 2 + 1\\times 1=1^2 + 2^2 + 3^2 + 4^2...+ 8^2$$\n\nI came across this formula: $$\\frac{n(n + 1)(2n + 1)} 6$$\n\nIt produces the sum of squares in $n\\times n$ board.\n\nMy question is, how did he reached this formula? Did he just guessed patterns until he reached a match, or there is a mathematical process behind?\n\nIf there is a mathematical process, can you please explain line by line?\n\nThanks very much.\n\nBtw: Couldn't find matching tags for this question, says I can't create.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe first step is to recognize that there are $8^2$ squares of size $1$ by $1$, $7^2$ squares of size $2$ by $2$ and so on. That justifies the total number being, as you say, $1^2+2^2+3^2+\\ldots 8^2$. Sums of powers are calculated by Faulhaber's formula. There are several ways to derive them. One way is to know or suspect that $\\sum_{k=1}^n k^p$ should be of degree $p+1$. So for squares, we want $\\sum_{k=1}^n k^2=an^3+bn^2+cn+d$. Then if we evaluate it at $n+1$, we get $\\sum_{k=1}^{n+1} k^2=a(n+1)^3+b(n+1)^2+c(n+1)+d$. Subtracting, we get $(n+1)^2=a((n+1)^3-n^3)+b((n+1)^2-n^2)+c((n+1)^1-n^1)$ and equating the coefficients gets the desired formula. You can prove the formula rigorously by induction\n\nshare|improve this answer\nYou should say, \"So for squares, $p=2$, ...\" and then later you have $k^{n+1} = ...$ when you mean $k^2 = ...$ \u2013\u00a0 Thomas Andrews Apr 12 '12 at 15:30\n@ThomasAndrews: Thanks. Fixed. For the second it should have been $(n+1)^2$ as that is the term added to the sum. \u2013\u00a0 Ross Millikan Apr 12 '12 at 15:55\nOops my bad, had a mistake, ignore please. Thanks for the help Ross! \u2013\u00a0 Novak Apr 12 '12 at 21:09\nI accidently marked this as solved, even though I believe your answer is correct. I'm in the stage of the substracting. Can you please write the stages after? All of these techniques are new to me, as I'm only in the 10th grade. What am I supposed to do with the coefficients? Thanks \u2013\u00a0 Novak Apr 13 '12 at 16:11\n@GuyDavid: If you take the last equation and expand the powers of $n+1$ you get $n^2+2n+1=3an^2+3an+a+2bn+b+c$ We need this to be true for all $n$, so $1=3a, 2=3a+2b, 1=a+b+c$ by equating the coefficients of each power of $n$. Solving gives $a=1/3, b=1/2, c=1/6$ Then if you check you can find $d=0$ \u2013\u00a0 Ross Millikan Apr 13 '12 at 16:27\n\nformula to calculate the square in $m \\cdot n$ order: $[n(n+1)x(3m-n+1)]/6$\n\nshare|improve this answer\nWhat does \"mxn order\" mean? A board of size $m\\times n$ perhaps? A brief sentence fragment of this kind is almost never a good answer. \u2013\u00a0 hardmath Jan 12 '14 at 18:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/58666/is-there-any-matrix-2-times-2-such-that-a-neq-i-but-a3-i?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI want to ask you this question: Is there any matrix $2\\times 2$ such that $A\\neq I$ but $A^3=I$. In my opinion: No. Thank you very much\n\nshare|improve this question\nI don't think it is a matter of opinions... \u2013\u00a0 \u00c1lvaro Lozano-Robledo Aug 20 '11 at 15:42\n\n2 Answers 2\n\nup vote 25 down vote accepted\n\nRotation by $2\\pi/3$ in the plane. Find the $2 \\times 2$ matrix that gives you this linear transformation.\n\nshare|improve this answer\nHi! How did you get that? \u2013\u00a0 Jozef Aug 20 '11 at 15:08\nImagine something when applied 3 times is the identity. How do you think? \u2013\u00a0 GEdgar Aug 20 '11 at 15:12\nOk, I'll think. thanks \u2013\u00a0 Jozef Aug 20 '11 at 15:20\n\nSince you don't specify what field the entries of this matrix have to come from, I could just take a diagonal matrix whose entries are $1$ and $\\omega$ where $\\omega=e^{2\\pi i /3}$ is a primitive cube root of 1 in the complex numbers.\n\nI guess you want real or integer entries though. If $A^3=I$ then the eigenvalues of $A$, that is, the roots of the characteristic polynomial, have to be third roots of unity. A primitive third root of unity satisfies $x^2+x+1=0$, so you could look for a matrix over the integers with that as a characteristic polynomial....\n\nshare|improve this answer\n+1. Nice! Your argument shows that this holds for any (nonzero) commutative ring. \u2013\u00a0 Pierre-Yves Gaillard Aug 20 '11 at 16:17\nAnother way to get an integral matrix that does the job it to take the automorphism of order $3$ of the torus, then the induced map on homology. In fact, there's an automorphism of order $6$ coming from the symmetry of the hexagonal tiling. \u2013\u00a0 Ryan Budney Aug 20 '11 at 16:35\n@Ryan: over $\\mathbb Z$, you have reduced to the problem to the (equivalent, I'm pretty sure---given enough technology) one of finding an automorphism of order $3$ of the torus :) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Aug 20 '11 at 22:07\nYes, $2\\times 2$ matrices of the integers of finite order all come from symmetries of the torus. This is a special case of what's called the Nielsen Realization problem -- which is solved, by-the-way. en.wikipedia.org/wiki/Nielsen_realization_problem Among other things, this gives you a fairly intuitive way to enumerate all the finite-order elements of $GL_2 \\mathbb Z$ (up to conjugacy). \u2013\u00a0 Ryan Budney Aug 20 '11 at 22:20\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/70777/a-ring-element-with-a-left-inverse-but-no-right-inverse\nText:\nTake the 2-minute tour \u00d7\n\nCan I have a hint on how to construct a ring $A$ such that there are $a, b \\in A$ for which $ab = 1$ but $ba \\neq 1$, please? It seems that square matrices over a field are out of question because of the determinants, and that implies that no faithful finite-dimensional representation must exist, and my imagination seems to have given up on me :)\n\nshare|improve this question\nThe two hints you have been given have a common thread: you need to lose information in one direction and cannot recover it in the other. \u2013\u00a0 Ross Millikan Oct 8 '11 at 4:03\n\n2 Answers 2\n\nup vote 15 down vote accepted\n\nTake the ring of linear operators on the space of polynomials. Then consider (formal) integration and differentiation. Integration is injective but not surjective. Differentiation is surjective but not injective.\n\nshare|improve this answer\nI am slightly confusing. Let $D$ denotes differentiation, and $I$ integration. I want to clarify whether $(D\\circ I)(p(x))$ is not necessarily $p(x)$ or $I\\circ D(p(x))$ is not necessarily $p(x)$. Should we take $I(0)=0$? \u2013\u00a0 Groups Dec 25 '14 at 9:53\n@Groups $I(f) = \\int_0^x f(t)dt$ works. \u2013\u00a0 Bib Apr 26 at 15:47\n\nConsider the ring of infinite matrices which have finitely many non-zero elements both in each row and in each column and the matrix $$a=\\begin{pmatrix}0&0&0&\\cdots\\\\1&0&0&\\cdots\\\\0&1&0&\\cdots\\\\\\ddots&\\ddots&\\ddots&\\ddots\\end{pmatrix}.$$\n\nA canonical example is the quotient $A$ of the free algebra $k\\langle x,y\\rangle$ by the two-sided ideal generated by $yx-1$.\n\nshare|improve this answer\nIn my example, this is the matrix of integration with respect to a suitable basis. \u2013\u00a0 lhf Oct 8 '11 at 3:37\nA very good and nontrival example! \u2013\u00a0 Mathemagician1234 Oct 8 '11 at 4:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/257873/why-isnt-the-inverse-of-the-function-x-mapsto-x-sinx-expressible-in-terms/275100\nText:\nTake the 2-minute tour \u00d7\n\nThe function\n\n\nis easily checked to be a bijection from the reals to itself, and so it has a unique inverse $y\\mapsto g(y)$ such that $f\\circ g=g\\circ f$ are both the identity map.\n\nNow $g$ will almost certainly be a function which is not expressible using \"the functions in a high-schooler's toolkit\" (by which I guess I mean $\\exp$, $\\log$, and, if you like, the usual trigonometric functions and their friends like $\\sinh$, although of course these can all be of course built from exponentials anyway). For purely recreational reasons (stemming from conversations I've had whilst teaching undergraduates) I'm interested in how one proves this sort of thing.\n\nA few years ago I was interested in a related question, and took the trouble to learn some differential Galois theory. My motivation at the time was learning how to prove things like why $h(t):=\\int_0^t e^{x^2} dx$ is not expressible in terms of these calculator-button functions (I'm sure there's a better name for them but I'm afraid I don't know it). I've realised that since then I've forgotten most of what I knew, but furthermore I am also unclear about whether this is the way one is supposed to proceed. Is the idea that I come up with some linear differential equation satisfied by $g$ and then apply some differential Galois theory technique? In fact, one of the many things that I have forgotten is the following: if $F$ is a field equipped with a differential operator $D$, and $E/F$ is the field extension obtained by adding a non-zero root of $Dh=ch$, with $c\\in F$, then the Galois group of $E/F$ is solvable, whereas the equation itself might not be, in terms of calculator-button functions, if I can't integrate $c$.\n\nCan a more enlightened soul explain to me how one is supposed to proceed? I wonder whether I am somehow conflating two ideas and the differential Galois theory business is a red herring, but it seemed simpler to ask rather than continuing to flounder around.\n\nshare|improve this question\nThe term I am familiar with is \"integration in finite terms\". \u2013\u00a0 marty cohen Dec 16 '12 at 5:10\nI think the term you are looking for (calculator button) is elementary function. \u2013\u00a0 Marc van Leeuwen Dec 16 '12 at 10:37\nYes, I'm looking for a proof that the inverse function is not an elementary function. Thanks. \u2013\u00a0 Kevin Buzzard Jan 4 '13 at 16:23\n\n3 Answers 3\n\nThis paper, titled \"Elementary functions and their inverses\" by J.F. Ritt addresses your question.\n\nSome time ago, in searching for why some functions don't have elementary integrals, I was led to the work of Liouville, as digested by Ritt in his book \"Integration in finite terms; Liouville's theory of elementary methods\". It was written in 1948 so I think the copyright has expired, and you can find a download link via a Google search.\n\nLiouville's results on elementary integrals were derived using quite basic tools (it is hard to be precise here on what I mean by \"basic tools\", best you see for yourself). The latter portions of Ritt's book explore elementary solutions of differential equations, which is based on the work of mathematicians after Liouville, and it is only from then that some differential Galois theory is used.\n\nRitt's paper uses methods somewhat similar to Liouville and in particular, does not seem to use differential Galois theory. However, it is possible there may be a more modern approach to your question that does use differential Galois theory, since the generalization of Liouville's original work develops it.\n\nAlternatively, if you can express your inverse function in terms of the Lambert W function as Nicholas suggests, then you can answer your question via the more specific methods of this paper.\n\nshare|improve this answer\nThanks for your answer and sorry it's taken so long to follow this up. I think that you're right that Ritt's paper addresses my question, but I don't think it answers it. It reduces my question to proving that $x+sin(x)$ is not expressible in some quite explicit way using $\\exp$ and $\\log$, but leaves me none the wiser about how to actually check this. \u2013\u00a0 Kevin Buzzard Jan 4 '13 at 16:22\nHere is one last comment. A theorem of Liouville gives a necessary and sufficient criterion for a function to be integrable in elementary terms. However the criterion is, in my mind, tough to verify in practice. But a paper by Brian Conrad called \"impossibility theorems for elementary integration\" states Liouville's result (Theorem 4.1) but then also deduces Theorem 4.4, which is a practical test for impossibility. Conrad uses Theorem 4.4 to prove that $Li(x)$ and $erf(x)$ aren't expressible in elementary terms. I guess I need a practical consequence of Ritt's work but don't know one. \u2013\u00a0 Kevin Buzzard Jan 4 '13 at 16:26\n\nTo answer this, let's express $\\sin(x)$ as $\\frac i 2(e^{-ix}-e^{ix})$ so we now have $x+\\frac i2(e^{-ix}-e^{ix})$. And you said that you are trying to find the inverse. From what I can see, this is relatable to $x+e^x = y$, the inverse of which is $x-W(e^x)$ where $W(x)$ is the product log function or Lambert $W$ function which cannot be expressed in terms of quote \"the functions one finds on a calulator\". Unfortunately, I am only in high school and therefore my answer may not be correct and I apologize if it is. This is only what I have gathered from my knowledge.\n\nshare|improve this answer\nI think the weak point in your answer is \"this is relatable to $x+e^x=y$\". If one could express my function in terms of Lambert $W$ this would be a step forward, but there's a world of difference between \"this looks similar\" and \"I can actually relate your function to Lambert $W$\". However, thanks for your contribution and, to be honest, you're raising another question in my mind -- how might one prove whether or not there's a way of expressing the function I'm interested in in terms of Lambert $W$? I guess you're also pointing out that perhaps the methods used to prove... \u2013\u00a0 Kevin Buzzard Dec 17 '12 at 12:27\n...that Lambert $W$ isn't expressible in terms of elementary functions can perhaps also be used to deal with the inverse of $x+\\sin(x)$... \u2013\u00a0 Kevin Buzzard Dec 17 '12 at 12:28\nup vote 4 down vote accepted\n\nI have finally found an answer to my own question, so I'll answer it myself and make the answer community wiki so I don't profit from it.\n\nLet me first explain why the other answers given here did not completely resolve the problem. Let me use standard notation -- an elementary function is a funtion you can build using the buttons on your calculator. If you allow complex coefficients then basically you only need exp and log, as you can build everything else from this.\n\nRagib Zaman's answer points us to a paper of Ritt where he proves a theorem of the form \"an elementary function whose inverse is also an elementary function must be of a very special form\", but this very special form is quite hard to work with: it is basically of the form exp(rational function(log(rational function(log(rational function(exp(...))))))) where at each stage you can choose whether to use exp or log. The problem with this is that it's very hard (for me) to prove that the function $x+\\sin(x)$ can provably not be expressed in this form.\n\nRitt's work relies on ideas of Liouville, and Liouville had a lot of ideas about this sort of question. Liouville proved a criterion for when an elementary function had an elementary integral (in fact he proved several results of this form, best phrased nowadays in the language of differential fields). One can hence use calculus as a tool: one can use strategies such as \"the inverse function of this function satisfies a certain differential equation, which implies it can't be elementary\". But here you have to be skillful to actually get your equation into the right form. This is why I can't use Nicholas' answer to answer my question. Nicholas observes that Lambert's $W$ function isn't elementary, and I know a proof of this which uses calculus and Liouville's criterion -- the trick being to write down a differential equation which (a simple function of) $W$ satisfies and then using Liouville to prove that this differential equation has no elementary solutions -- but the moment you change the problem a little, the differential equation changes, and the methods may not (and in this case don't) apply. An analogue might be this: if I can integrate $1/\\sqrt{1-x^2}$, then even though it looks quite similar, I might well not be able to integrate $1/\\sqrt{1-x^2+x^{-2}}$. This is an area where even quite a small change might derail things substantially.\n\nOn the other hand, these answers helped me immensely, because they provided me with references which enabled me to start a literature search. And today the search came to an end, because I got my hands on a copy of \"Integration in finite terms: Liouville's theory of elementary methods\" by J. F. Ritt (written in 1948), and on p56 Ritt shows how to deal with $x+\\sin(x)$ explicitly! Apparently the equation $y=x+a\\sin(x)$ ($a$ a constant) is called \"Kepler's equation\".\n\nSo the answer to the question is \"this has nothing really to do with differential Galois theory; you need Liouville's theory, and a proof is in p56 of Ritt's 1948 book mentioned above\".\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/83732/number-of-ways-to-divide-a-stick-of-integer-length-n/83751\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have a stick of integer length $N$. I'm looking for (preferably closed-form) formula that gives the numbers of ways in which we can divide the stick into 3 parts with distinct integral lengths.\n\nEDIT: Also, every part in any division has unique length which does not appear in any other division of $N$.\n\nEDIT2: Based on coffeemath's answer, just to clarify, I'm interested in maximal number of sums $F(n)$. Given some $N$, count the number of all possible ways to divide stick $N$ into 3 parts such that the length of any part in any valid division is unique number between $1$ an $N$.\n\nshare|improve this question\nUnless your three parts must have integral length the answer is obviously $\\infty$ ;) \u2013\u00a0 N. S. Nov 19 '11 at 20:23\nYes the three parts have integral length :) \u2013\u00a0 Mohammad Al-Turkistany Nov 19 '11 at 20:26\nis $0$ a valid length? \u2013\u00a0 robjohn Nov 19 '11 at 20:34\nNo, $0$ is invalid length. \u2013\u00a0 Mohammad Al-Turkistany Nov 19 '11 at 20:38\nOrder does not matter. Here you can not count both triples. \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 10:06\n\n5 Answers 5\n\nup vote 6 down vote accepted\n\nThe array $$\\matrix{1&30&16&4&24&31&7&18&13&15&28\\cr17&2&32&20&5&14&23&8&29&22&11\\cr33&19&3&27&22&6&21&25&9&10&12\\cr}$$ uses each integer $1,2,\\dots,33$ exactly once; each column sums to $51$ (so we have $11$ ways to divide a stick of length $51$ into three parts); and, as a bonus, each row sums to $187$. There's a calculator that finds such things.\n\nIt has been proved that an $m\\times n$ magic rectangle exists provided $m$ and $n$ have the same parity and exceed $1$, with the sole exception of $m=n=2$. Taking $m=3$, this gives a way of dividing a stick of length $(9n+3)/2$ into three parts in $n$ ways, where $n$ is an arbitrary odd number exceeding $1$. It's pretty clear that stick can't be divided into three parts in more than $n$ ways; if you can do it in $k$ ways, then the numbers used must add up to $k(9n+3)/2$, but they must also add up to at least $3k(3k+1)/2$, and this is easily seen to imply $k\\le n$.\n\nIn short, if $N$ is of the form $(9n+3)/2$, $n$ odd, then the number of ways is $(2N-3)/9$.\n\nThe magic rectangles theorem has been proven, and constructions given, in many papers. One, which gives references to others, is Thomas R Hagedorn, Magic rectangles revisited, Discrete Mathematics 207 (1999) 65-72. Of course, the construction is a bit of overkill for this problem, as we don't really need a magic rectangle, we just need the columns sums to be equal and don't care about the row sums. Here's a simple construction which just solves the original construction, without giving a magic rectangle: $$\\matrix{1&2&3&4&5&6&7&8&9&10&11\\cr17&18&19&20&21&22&12&13&14&15&16\\cr33&31&29&27&25&23&32&30&28&26&24\\cr}$$ The pattern should be clear.\n\nEDIT: Now, suppose $N$ is not of the form $(9n+3)/2$ with $n$ odd. Let's write $n'=n+1$ and $n''=n+2$, and $${9n+3\\over2}\\lt N\\lt{9n''+3\\over2}$$ for some odd $n$. First, we note that $F(N)\\ge n$; if $N-(1/2)(9n+3)=k$, then just add $k$ to each entry in the bottom row in the construction above. and you have $n$ ways to divide $N$ into three parts. Second, note that $F(N)\\le(2N-3)/9$, by the argument a few paragraphs up about the sum of the numbers involved. So we get\n\n  1. If $(1/2)(9n+3)\\lt N\\lt (1/2)(9n'+3)$, then $f(N)=n$;\n\n  2. If $(1/2)(9n'+3)\\le N\\lt(1/2)(9n''+3)$, then $f(N)$ is either $n$ or $n+1$.\n\nIn summary, for every $N$, we have a formula for $f(N)$ which is exact in some ranges, and off by at most $1$ in other ranges. I suspect that the $n+1$ is generally correct in the situation where we haven't pinned things down. For example, for $N=20$, we have $$((9)(4)+3)/2\\lt N\\lt((9)(5)+3)/2$$ with the left inequality barely holding, and we get $f(20)=4$ from $$\\matrix{1&2&3&4\\cr5&7&8&6\\cr14&11&9&10\\cr}$$\n\nshare|improve this answer\nThanks for your answer. May be I'm missing something but does it work for any $N$ since I'm looking for $F(N)$ for any $N$. \u2013\u00a0 Mohammad Al-Turkistany Feb 6 '13 at 0:35\nNow that you've answered it, I feel like I understand the problem for the first time!! \u2013\u00a0 hardmath Feb 6 '13 at 2:16\n\nThis is an example of achieving $a$ distinct sums for a stick of length $6a$. No specific integer occurs twice in any particular sum, or twice in two different sums, or more succinctly all the numbers involved in the sums are distinct. I think that is what the OP means in the statement of the \"EDIT\".\n\nThe triples are $T_k=[k,3a-2k+1,3a+k-1]$ for $1 \\le k \\le a.$ Each triple then has sum $6a$ as desired, and the numbers used are all distinct. The middle numbers are going down by 2 as $k$ runs through $\\{1,2,...,a\\}$ with the last one being $3a-2a-1=a+1$, just after the highest number $a$ of the first term in any triple, and the first middle number is the largest of the middle numbers namely $3a-2\\cdot 1+1=3a-1,$ which is just before the lowest of the third elements of the triples, i.e. $3a+1-1=3a$. After that the third elements of the triples increase by 1 each step until reaching the highest third element of a triple, namely $3a+a-1=4a-1$ (So the last triple $T_a$ is $[a,a+1,4a-1]$).\n\nI don't know if better can be done for a stick of length $6a$, but I haven't been able to prove that; it may be that some other sheme of getting different triples could give more than $a$ sums for the $6a$ long stick. What I tried to do was to have the middle numbers going down two each time, and make the block of them start right after the end of the first block going up one each time, and end just before the final block which again goes up one each time. I can't think of a denser way to pack the triples.\n\nBy the way in my opinion, given the restriction of no number used twice in any one triple or even anywhere on the list of triples obtained, the OP should specify whether his question is to find the maximal number of sums say $F(n)$ for a given stick length $n$, or on the other hand maybe the OP is interested in a formula of type $F(n,t)$ for the number of ways a stick of length $n$ can be cut into three parts in $t$ ways, no repeated numbers. The latter would be a lot harder, and even a provable formula for $F(n)$ would seem difficult, at least to me.\n\nEDIT In this construction the \"middle numbers\" are spaced 2 apart. And in most cases more triples can be found in the unused numbers of the middle range. For example in the case $a=4$ with stick length $6a=24$, the $a=4$ triples formed using the construction are\n\n$[1,11,12],\\ [2,9,13],\\ [3,7,14],\\ [4,5,15]$\n\nThe unused numbers of the middle range make up another triple $[6,8,10],$ so that for stick length 24 one can find 5 triples.\n\nFor the case $a=10$ (stick length 60) besides the ten automatically constructed triples, the unused middle numbers are the nine even numbers from 12 through 28, and these can be put into the three triples $[12,20,28],\\ [14,22,24],\\ [16,18,26].$ So for stick length 60 the max number of triples is at least 13.\n\nshare|improve this answer\nI'm interested in maximal number of sums $F(n)$ \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 1:18\nThanks for the comment. This narrows down what you're looking for. I'll try for some provably maximal cases. I guess each sum may as well be in say increasing order, as rearrangements of a single sum cannot appear on the list because of the uniqueness requirement... \u2013\u00a0 coffeemath Feb 5 '13 at 1:28\nThanks for helping. \u2013\u00a0 Mohammad Al-Turkistany Feb 5 '13 at 1:47\n\nI assume that your lengths have to be integers. Let $a, b,c$ be the lengths.\n\nYou want $a+b+c=N$ and $a,b,c$ pairwise distinct.\n\nSince the equation is homogeneous in $a,b,c$ we can find the solutions for which $a<b<c$ and then by permuting we get all solutions (thus the no of solutions will be multiplied by 6).\n\nNow this is a simple counting problem.\n\n$N=a+b+c < 3c$, thus $c > \\frac{N}{3}$. Also $c=N-a-b <N-2$.\n\nFor each fixed $\\frac{N}{3} < c < N-2$ you need to count all the solutions to the equation $a+b =N-c$ with $a < b <c$. This is very easy, since any $b$ yields an unique $a$, the only thing you have to make sure is that $a < b <c$.\n\nAfter finding this number, add this by $c$ and you get your formula...\n\nshare|improve this answer\n\nI think you're asking about partitions of an integer into distinct parts. That is, you're interested in $$ q_k(N) := \\# \\{ (a_1, \\dots, a_s) \\; : \\; a_1 > \\dots > a_s > 0, \\; \\sum a_i = N \\} $$ (and $s$ is allowed to be anything). You can show that $q_k(N + \\binom{k}{2}) = p_k(N)$ where $p_k(N)$ is equal the number of partitions of $N$ into exactly $k$ parts. Then, if $N$ isn't too big you can compute $p_k(N)$ via the recurrence $p_k(N) = p_{k-1}(N-1) + p_k(N-k)$. (Base conditions are $p_k(k) = 1$ for all $k$, $p_{n-1}(n) = 1$, $p_1(n) = 1$, and $p_2(n) = \\lfloor n/2 \\rfloor$.)\n\nshare|improve this answer\n\nThese values (where the first term is the count for $N=6$ here) form sequence A001339 in the Online Encyclopedia of Integer Sequences.\n\nThe number of ways to partition $N$ into exactly three distinct positive integer parts equals the number of ways to partition $N-6$ into at most three (non-negative) integer parts. The following observation explains a one-to-one correspondence: If $N-6=a+b+c$ for non-negative integers $a \\le b \\le c$, then $N = (a+1) + (b+2) + (c+3)$ is a partition of $N$ into three distinct positive integer parts.\n\nNo closed form is provided in OEIS, so one may presume there is none.\n\n(The \"EDIT\" remark in the original question is unclear to me, so this may not be the right answer.)\n\nshare|improve this answer\n\"No closed form is provided in OEIS\"? Au contraire, several closed forms are provided in OEIS. Also, a simple, rational generating function is given, which guarantees the existence of a closed form. But, as you note, this doesn't seem to be the question OP wants answered. \u2013\u00a0 Gerry Myerson Feb 5 '13 at 11:20\nThanks, Gerry. I struck my wrong remark about closed form. \u2013\u00a0 Steve Kass Feb 5 '13 at 16:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/252298/how-to-find-sum-of-changing-binomnr-times-binomms-series\nText:\nTake the 2-minute tour \u00d7\n\nHow can we find the sum of the following series\n\n$$\\sum_{i=0}^p \\binom{m-q+1+i}{i} \\binom{n+q-1-i}{n-i}=\\sum_{i=0}^p\\frac{(m-q+1-i)!}{ i! (m-q+1)!}\\frac{ ( n + q-1-i)!}{ (q-1)! (n-i)!}$$ where $p < n,m$?\n\nshare|improve this question\nDo you denote by $!n$ the factorial? Usually it is denoted by $n!$. \u2013\u00a0 martini Dec 6 '12 at 14:21\n$!n$ is not the notation for factorial, but rather for derangements. \u2013\u00a0 Cameron Buie Dec 6 '12 at 14:30\n\n2 Answers 2\n\nHere is an answer computed by maple\n\n$${n+q-1\\choose n}{_2F_1(-n,m-q+2;\\,-n-q+1;\\,1)}-{m-q+2+p\\choose p+1}{n+q -2-p\\choose n-p-1}$$ $$\\times\\,{_3F_2(1,-n+1+p,m-q+3+p;\\,p+2,-n-q+2+p;\\,1)} $$\n\nwhere $_2F_1$ and $_3F_2$ are the hypergeometric function.\n\nThe same answer can be computed by Mathematica $9$.\n\nshare|improve this answer\n\nIf $p\\ge n$, then $$ \\begin{align} \\sum_{i=0}^p\\binom{m-q+1+i}{i}\\binom{n+q-1-i}{n-i} &=\\sum_{i=0}^p\\binom{m-q+1+i}{m-q+1}\\binom{n+q-1-i}{q-1}\\\\ &=\\binom{m+n+1}{m+1} \\end{align} $$ However, if $p\\lt n$ I don't think there is a closed form (that, in general, doesn't involve hypergeometric functions).\n\nTo confirm Mhenni Benghorbal, Mathematica 8 gives $$ \\binom{n+q-1}{n}\\,_2F_1(-n,m-q+2;-n-q+1;1) -\\binom{m+p-q+2}{p+1}\\binom{n-p+q-2}{n-p-1}\\\\ \\times\\,_3F_2(1,-n+p+1,m+p-q+3;p+2,-n+p-q+2;1) $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-to-find-antiderivative-of-product.140410/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHow to find antiderivative of product\n\n  1. Oct 29, 2006 #1\n    problem: find the anti derivative of x^5 + tan(2x)sec(2x)dx\n\n    how do you find the anti derivative of the second half of that problem tan(2x)sec(2x)\n  2. jcsd\n  3. Oct 29, 2006 #2\n    Does the function y=sec(u)tan(u) look familiar at all? Perhaps as the derivative of some common elementary function?\n  4. Oct 29, 2006 #3\n    yeah, you are going to have to use u-substitution twice. I don't know if I am correct or not, but I changed everything to sin and cos before anything and manipulated it that way. I then let u = cosx and du = -sinx. For the second u-substitution, I let v=u\u00b2-1 and (1/2)dv = udu. I hope that helps and does not confuse you and more.\n  5. Oct 29, 2006 #4\n    What are you doing? What is the derivative of secant?\n  6. Oct 29, 2006 #5\n    oh yeah... I see that the deriveitive of secx = secx tanx... Hmm... looks like I went a long.. long long long way around it.. haha. Sorry about that donjt81, I hope I didn't lead you too far the wrong way. I think it comes out to the same answer. Does it? Well, I guess we can both learn a lesson, or at least myself. And that is to really look at what's in front of you with the equation before just jumping into it. I just jumped right in and started to manipulate it, when I could have just taken a minute to think about what was really there and solved it much quicker and easier.\n\nHave something to add?\n\nSimilar Discussions: How to find antiderivative of product"}
{"text": "Retrieved from https://www.physicsforums.com/threads/magnetic-flux-equator-and-flying-bullets.272027/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMagnetic Flux, Equator and flying bullets!\n\n  1. Nov 15, 2008 #1\n\n\n    User Avatar\n\n\n    At the equator, the earth\u2019s magnetic field is approximately horizontal, is directed towards the north and has a value of [tex] 8 \u00d7 10^{-5} [/tex] T.\n\n\n    Estimate the EMF induced between the top and bottom of a bullet shot horizontally at a target on the equator if the bullet is shot east. Assume the bullet has length of 1 cm, a diameter of 0.4 cm and travels at a speed of 300 m/s (for simplicity, one can assume that the bullet has a square cross-section).\n\n    2. Relevant equations\n\n    [tex] \\epsilon = -\\frac{d\\Phi}{dt} [/tex]\n\n    [tex] \\Phi = \\int B da = BHx [/tex]\n\n    3. The attempt at a solution\n\n    I think I have done this question, but would like to check to see it I have done it correctly...\n\n    [tex] \\Phi = BHx [/tex]\n\n\n    [tex] \\epsilon = -\\frac{dBHx}{dt} [/tex]\n\n    B and H are constants:\n\n    [tex] \\epsilon = -BH\\frac{dx}{dt} [/tex]\n\n\n    [tex] \\frac{dx}{dt} = v [/tex]\n\n    [tex] \\epsilon = -BHv [/tex]\n\n    we know:\n\n    B = [tex] 8 \u00d7 10^{-5} [/tex]\n    H = 0.004\n    v = 300\n\n    thus inserting the values I get:\n\n    [tex] \\epsilon = -9.6 \\time 10^{-5} [/tex] Volts\n\n    Does this look correct?\n\n  2. jcsd\n  3. Nov 15, 2008 #2\n\n\n    User Avatar\n\n    Does this look like the right solution?\n\n  4. Nov 16, 2008 #3\n\n\n    User Avatar\n\n    Does it look like I have attempted the question in the correct way? Does it look right?\n\n\n  5. Nov 16, 2008 #4\n    Hi TFM,\n\n    Your answer looks good to me, although I wouldn't use H as a variable when considering B-fields since it could be confused with the auxillary field H. This question is familar to a hall effect question, although the circumstances are different you get the same final equation. I geuss when it comes down to it though you still have moving charges in a B-field, so in essence it's the same. Odd.\n  6. Nov 17, 2008 #5\n\n\n    User Avatar\n\n    Ok that's good. For the second part,\n\n\n    What is the EMF if the bullet was travelling South?\n\n    I am assuming that the same equation will be used, which should give the same value, since none of the variables appear to have changed. The only real difference is that the bullet is no longer travelling perpendicular, but it does have a perpendicular surface (to the current). Does this sound right?\n\n  7. Nov 17, 2008 #6\n    If the bullet is travelling south then all the charges inside it are also travelling south. The velocity of the charges will be parallel to the magnetic field. What is the force on a charge when moving parallel to a magnetic field?\n  8. Nov 17, 2008 #7\n\n\n    User Avatar\n\n    Well the formula is:\n\n    [tex] Q(v \\times B) [/tex]\n\n    which is a cross product, so the force will be 0?\n\n  9. Nov 18, 2008 #8\n\n\n    User Avatar\n\n    Does this look right? If so, how would this force connect to the EMF force, [tex] \\epsilon [/tex]?\n\n  10. Nov 18, 2008 #9\n    note: emf isn't a force.\n\n    The two methods (Faraday and Lorentz) should lead to the same answer. However I am now confused, since when the bullet moves south there is still a surface parallel to B (so B.da is non zero) which will sweep out an area and lead to an emf. However the Lorentz force law contradicts this, because it says that since all the charges are now moving parallel to B the force on them must be zero.\n\n    Please can someone explain this odd inconsistency? I think I have something obvious mixed up somewhere.\n  11. Nov 19, 2008 #10\n    I think that as the bullet is now travelling parallel to the B-field there will be no change in magnetic flux through any of it's surfaces or open surfaces, since there will be as much B-field going in as there is coming out and it's not cutting any field lines. Does that make sense?\n  12. Nov 20, 2008 #11\n\n\n    User Avatar\n\n    That does indeed make sense.\n\n\nHave something to add?\n\nSimilar Discussions: Magnetic Flux, Equator and flying bullets!\n  1. Metal Magnetic Flux (Replies: 19)\n\n  2. Magnetic Flux (Replies: 0)\n\n  3. Magnetic flux (Replies: 13)\n\n  4. Magnetic Flux (Replies: 5)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-scalars-from-vectors.43276/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestion: scalars from vectors\n\n  1. Sep 15, 2004 #1\n    I saw this question posted yesterday, and now got a similar question to work out.\n\n    A = (6i-8j) cm\n    B = (-8i+3j) cm\n    C = (26i+19j) cm\n\n\n    Determine the two scalars a and b.\n\n    Ideas anyone??\n\n\n    Last edited: Sep 15, 2004\n  2. jcsd\n  3. Sep 15, 2004 #2\n    C=0 ?? But you jsut said C=26i+19j . Is this a typo? or did you mean aA+bB-C=0\n\n    in which case aA+bB=C\n    seems pretty straightforward to me. Split it up into the vector components, and youll have 2 equations with 2 unknowns, easily solveable.\n  4. Sep 15, 2004 #3\n    Sorry. That was a tipo. I made a mistake.\n\n    aA+bB+C=0 not aA+bB=C=0 not\n  5. Sep 15, 2004 #4\n    Well, what have you done so far? How have you approached it?\n  6. Sep 15, 2004 #5\n    I used the equation a^2 + b^2 = c^2 and the coodinates (6,-8) and (-8,3) to determine that the magnitude of A is 0.5cm and that the magnitude of B is 0.7cm. But I don't know if that is what is meant by \"determine the two scalars a and b\". I'm asuming scalars in this question is the scalar quantity or \"magnitude\".\n    Last edited: Sep 15, 2004\n  7. Sep 15, 2004 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The \"equation a^2+ b^2= c^2\" doesn't even make sense here. You are given vectors A, B, C, not numbers a, b, c (and you certainly don't have any number c).\n\n    Do you know how to add vectors and multiply vectors by a number? That should have been ther first thing you learned!\n\n    If A= 6i+8j, then aA= (6a)i+ (8a)j.\n\n    If B= -8i+ 3j, then bB= (-8b)i+ (3b)j\n\n    aA+ bB = (6a- 8b)i+ (8a+ 3b)j and that must be equal to C= 26i+ 19j.\n\n    Okay, have you learned that two vectors are equal only if the respective components are equal?\n\n    To have aA+ bB= C, you must have (6a- 8b)i+ (8a+ 3b)j= 26i+ 19j and so\n    6a- 8b= 26 and -8a+ 3b= 19.\n\n    Can you solve those two equations for a and b?\n\nHave something to add?\n\nSimilar Discussions: Question: scalars from vectors\n  1. Vector and scalars (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/entropy-of-the-universe.249227/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEntropy of the universe\n\n  1. Aug 9, 2008 #1\n\n    A model universe comprises 100 atoms in system 1 and 1500 atoms in system 2. Compute the entropy for the universe when there are 3 atoms on in system 2 and 97 atoms on in system 1 (using sterlings approximation).\n\n    3. The attempt at a solution\n    I am able to find the entropy of systems 1 and 2 by initially finding the number of microstates and then the equation:\n\n    entropy = boltzmanns * ln(microstates)\n\n    Just wondering how I would get the entropy of the universe though.\n  2. jcsd\n  3. Aug 10, 2008 #2\n\n\n    User Avatar\n\n    Well, if you know how many microstates there are for systems 1 and 2, then how many microstates are possible for the combined system (1+2)?\n  4. Aug 10, 2008 #3\n    I was unsure of the terminology. So taking universe as systems 1 and 2:\n\n    I can find number of microstates using \u03a9 = C(N,n)\n    (i.e. the number of ways of moving n atoms from N sites)\n\n    Thus for system 1:\n    \u03a9 = C(1500,3)?\n    This is a massive number!\n\n    Am I on the right track?\n  5. Aug 10, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    Yup that's the correct way of doing the calculation. The calculation may be made easier by finding a formula for C(N,n) in terms of factorials, then applying Stirling's approximation.\n  6. Aug 11, 2008 #5\n    sterlings approximation only helps once I get a value of \u03a9 though correct?\n    I cannot even compute C(1500,3)=1500!/3!1497! due to overflow!\n  7. Aug 11, 2008 #6\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    Try to calculate ln(\u03a9) instead.\n  8. Aug 12, 2008 #7\n    Ok, so I managed to compute C(1500,3) and C (100,97).\n    I got 561375500 and 646800 respectively.\n\n    (I wish to keep in terms of boltzmanns)\n    Therefore for system 1:\n    entropy = K*ln(561375500) = 20.15K\n\n    and system 2:\n    entropy = K*ln(646800) = 13.38K\n\n    total = 33.53K?\n\n    Where does Sterling's Approximation come into this?\n  9. Aug 12, 2008 #8\n\n\n    User Avatar\n    Science Advisor\n    2015 Award\n\n    ln(\u03a9) = ln(1500!/3!1497!) = ln(1500!) - ln(3!) - ln(1497!) = 1500ln(1500) - 1500 - ln(6) - 1497ln(1497) + 1497\n\n    Here's where sterling's approximation saves you from evaluating horrible factorials.\n  10. Aug 13, 2008 #9\n    yeah i completed it, thanks for help\n\nHave something to add?\n\nSimilar Discussions: Entropy of the universe\n  1. Quantum entropy and ? (Replies: 2)\n\n  2. Entropy expression (Replies: 1)\n\n  3. Finding Entropy (Replies: 3)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/finding-the-surface-flux-of-the-sun.185342/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nFinding the surface flux of the sun\n\n  1. Sep 17, 2007 #1\n\n    The flux from the Sun above the Earth's atmosphere is about 1370 watts/m^2. This quantity is called the solar constant S and equals pi*f(sun). Use the angular radius of the sun as seen from the Eart to find pi*F , the surface flux of the sun.\n\n    2. Relevant equations\n\n    possible equations that may be relevant: Flux=sigma*T^4, T being the temeperature dependence and sigma=5.669*10^-8/m^2 *K^4; Luminosity = flux*area, a\n\n    3. The attempt at a solution\n\n    I have to find the angular radius of the sun in order to find the surface flux of the sun. To find the angular radius of the sun, I would probably have to used the fact that theta=lambda/Diameter of the sun; theta=lambda/2*radius of the sun. L=4*pi*R^2 *sigma*T^4. There are still 3 unknown variables: lambda, and the Temperature. Perhaps I should approach a solution to this problem in a different fashion: I know the radius of the sun is 6.96*10^5 km and luminosity of the sun is 3.90*10^26 W and the flux from the sun over the earth's atmosphere is 1370 watts/m^2. L/A=flux => (3.90*10^26 W)/(4pi(6.96*10^8 m)^2) = 64067276.69 W/m^2. But that calculation gives me the total flux of the sun, it doesn't give me the surface flux of the sun. how do you find the surface flux of the sun?\n  2. jcsd\n  3. Sep 18, 2007 #2\n    I think you can just use the area of spheres, and the sun as a point source to calculate this.\n  4. Sep 18, 2007 #3\n\n\n    User Avatar\n    Homework Helper\n\n    I don't think you want to treat the Sun as a point source if your aim is to find its surface flux (the angular radius is not that tiny).\n  5. Sep 18, 2007 #4\n\n\n    User Avatar\n    Homework Helper\n\n    I believe you're supposed to proceed from the angular radius, *without* knowing the radius of the Sun or the distance to it from here. As BlackWyvern says, you want to use the surface areas of spheres. You want to consider that one square meter versus the entire sphere at Earth's distance, then consider how that relates to the area of the Sun's surface. Using the definition of angular radius (in the small-angle approximation), you'll notice that it can be identified in your proportional relations.\n\n    You shouldn't need to know anything about blackbody radiation or the Sun's surface temperature either.\n\n    I was puzzled by one other thing you said: what definition are they using in your course for \"surface flux\"? I've been checking around and that term generally means power or luminosity per surface area ( W/[m^2] ).\n    Last edited: Sep 18, 2007\n  6. Sep 18, 2007 #5\n    I just realized that wouldn't work because of the distance differences.\n\n    But you could do pretty much the same thing, just know that since it's a radiation, it's intensity will depreciate proportional to 1/d^2. Use this and the surface area of spheres (I think it's A = 4 (pi) r^2 ) to derive it.\n  7. Sep 18, 2007 #6\n\n\n    User Avatar\n    Homework Helper\n\n    Actually, these two statements are equivalent. This is because L = F x A, which is the key to the solution. Since intensity is power/area, it has a simple relation to flux; in fact, depending on which specialists' definition you're using, that can *be* the same thing. (That's why I asked what definition was intended in the problem.)\n  8. Sep 18, 2007 #7\n\n\n    User Avatar\n    Homework Helper\n\n    I found one source that might help with this. In Foukal's _Solar Astrophysics_ (pp.40-41), what we will find is the net flux through the Sun's surface. If we call *that* f, then f = pi*F, where F is known as the \"astrophysical flux\".\n  9. Sep 18, 2007 #8\n    I don't think the definition of angular radius is stated clearly in my textbook , but is it theta=lambda/2*radius. how do you find theta and lambda in order to find radius of the sun. Also should I assume that the luminosity of the sun is 3.90*10^26 Watts\n\n    well according to my book, theta = lambda/d , d being the size of the apeture. theta= 5e-7 rad. so the two unkwowns are lambda and d. I don't understand why d and lambda are relevant in helping me find the radius of the sun.\n\n    also, would r just be the distance from one point on earth to another point on the sun, which is just one astronomical unit ?\n\n    if so, then the surface area sun would be: SA=4*pi*r^2 = 4*pi*(1.496e11 m)^2 = 2.812e23 m^2\n\n    Since the flux of the earth is given in the problem, I can now find the luminosity of the sun, which is just L = SA *F = (2.81e21m^2)(1370 W/m^2) = 3.84e24 watts.\n\n    Now how would I find the surface flux of the Sun , now that I calculated its luminosity? Could I also used the fact that sin(theta)= R/AU. How would I find theta ?\n\n    I don't understand why my professor wants me to go through numerous calculations for finding the radius of the sun when it is given in the book. I mean whats the point of have the radius of the sun in the appendix of my textbook if I'm going to have to going to have rederived it through tedious calculations.\n    Last edited: Sep 18, 2007\n  10. Sep 18, 2007 #9\n\n\n    User Avatar\n    Homework Helper\n\n    I think they're giving you an apparent radius, based on the wavelength of observation. The theta = lambda/d is an approximate value for the angular size of the Airy disk for a point source.\n\n    In any case, that isn't what we need here. For the physical angular size of the Sun, we'd just want the angle subtended by the Sun's radius at the distance of Earth (1 AU, as you've said). Use the small-angle approximation, since this angle is much less than 0.1 radian.\n\n    I think you have the radius of Earth's orbit in there...\n\n    So you have the surface area of a sphere of 1 AU radius, but something's off because that value for the luminosity is a factor of 100 low...\n\n    You can drop the sine because the small-angle approximation will be valid (it gives entirely adequate precision).\n\n    You don't need to *find* theta, actually, as I'll explain below. Go back to the equation you gave, L = F x A. Consider that the same power leaving the Sun's surface also passes through that sphere with 1 AU radius. So you can equate F x A for each sphere and solve for F for the Sun's surface; theta will appear in your expression.\n\n    Are you in an astrophysics or experimental physics course? The point of the exercise is that you are calculating the nex flux of the Sun from two *directly measurable* quantities, the solar radiation flux at the \"top\" of Earth's atmosphere and the angular diameter of the Sun. Quantities calculated only from directly measurable ones are more reliable than those which are computed from inferred quantities, such as the solar radius or the astronomical unit (there is a whole historical literature you can look at about how these and similar quantities were found and how we got to the currently accepted values).\n\n    When you get past the introductory courses (1000-level in some systems) in the physical sciences, you start getting more into *how* various quantities and equations are derived, rather than just being told, \"Take our word for this and use it!\"\n\n    All those nicely-tabulated quantities listed in your textbook or handbooks of reference data are the result of uncounted person-years of effort and debate. It is always a good idea to know where the numbers you use came from and how reliable (precise, or even just accurate) they really are...\n\nHave something to add?"}
{"text": "Retrieved from https://www.physicsforums.com/threads/finding-best-fit-for-a-parabolic-segment.173305/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nFinding best fit for a parabolic segment\n\n  1. Jun 8, 2007 #1\n    I have a set of points\n\n    x y\n    0 0\n    1 1\n    2 3\n    3 4\n    4 6\n    5 8\n    6 9\n    7 11\n    8 14\n    9 16\n    10 18\n    11 21\n    12 24\n    13 27\n    14 30\n\n    That seem to define, fairly closely, a parabolic segment. How do I find the scale and x/y origin of the parabola that most closely fits these points?\n    Last edited: Jun 8, 2007\n  2. jcsd\n  3. Jun 9, 2007 #2\n\n\n    User Avatar\n    Homework Helper\n    Education Advisor\n    Gold Member\n\n    Must the set of points be a parabola? What does the scatter plot of the points look like?\n\n    You might try picking a few points to use for a set of equations based on the general form for conic sections; solve the set of equations for the coefficients and make your best judgement. the relationship of the coefficient values determine what kind of conic section the chosen set of points represent. You might want to try the points which you believe are the most important for your system. Some kind of matrix or linear algebra/curve fitting software would make the task efficient.\n\n    Your general form would be like:\n    [tex] \\[\n    Ax^2 + By^2 + Cxy + Dx + Ey + F = 0\n    \\] [/tex]\n  4. Jun 9, 2007 #3\n\n    Gib Z\n\n    User Avatar\n    Homework Helper\n\n    [tex]y = 1.1\\cdot10^{-8}x^7 + 2.5\\cdot10^{-7}x^6 + 3.2\\cdot10^{-6}x^5 + 3.1\\cdot10^{-5}x^4 + 0.00063x^3 + 0.036x^2 + 1.34x - 0.0981[/tex] although y=1.8x isnt bad either.\n    Last edited: Jun 9, 2007\n  5. Jun 9, 2007 #4\n    After working with a larger data set, I don't think it is a parabola. It looks very similar to one when I manually overlay a true parabola in Adobe Illustrator but it can't be made to fit exactly. It's doesn't appear to be an asymptote either.\n\n    When calculated a different way, the points seem to follow\n\n    y = x^(1/m)\n\n    Where m is in the neighborhood of pi/2\n  6. Jun 9, 2007 #5\n\n    The results show a concavity towards the y axis. A function such as [tex]x^{1/m} [/tex] with m > 1 gives a concavity towards the x axis.\n\n    PS: Could you PM me the datasheet?\n  7. Jun 9, 2007 #6\n    Thanks Gib.\n\n    Did you derive that with Mathematica? I only posted a few data points because there are an infinite number :)\n\n    When I calculate them a different way, it appears to be a simple power function with an exponent of 1/m. I tried i/phi which diverges too quickly and 1/(pi/2) which is better but still diverges a little too quickly.\n  8. Jun 9, 2007 #7\n\n    Gib Z\n\n    User Avatar\n    Homework Helper\n\n    I used Graphmatica. How do you have an infinite number of points without some sort of generating function...however you do it, send it over.\n  9. Jun 9, 2007 #8\n    The original data set was a bit contrived to get it to oriented it that way.\n\n    Will do. Thanks for taking a look.\n  10. Jun 9, 2007 #9\n    Hey ktoz, I'll take a look another time, it's time for me to go to bed... it's 6:19 AM here. :zzz:\n  11. Jun 9, 2007 #10\n\n    Gib Z\n\n    User Avatar\n    Homework Helper\n\n    Holy whack...Worst i've ever done was 5:30 :)\n\nHave something to add?\n\nSimilar Discussions: Finding best fit for a parabolic segment\n  1. Gaussian of best fit (Replies: 6)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limit-of-a-sequence.3335/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLimit of a sequence\n\n  1. Jun 26, 2003 #1\n    It isn't a homework problem but I think I better post it here instead of Mathematics forum, since it belongs to \"exam help\".\n\n    Prove that for any positive real numbers a and b,\n    lim [(an+b)1/n-1] = 0\n\n    I don't need to use things like |a-b|<epsilon. A simple way will do. I know it's an easy question but I don't know where to start. Could someone please help.\n  2. jcsd\n  3. Jun 26, 2003 #2\n\n    Tom Mattson\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    This one just screams \"L'Hopital!\"\n\n    First, rearrange it to:\n\n\n    Then take the natural log of both sides to get:\n\n    lim ln(an+b)/n=0\n\n    This goes to &infin;/&infin;, which is an indeterminate form and ripe for L'Hopital's rule.\n  4. Jun 26, 2003 #3\n    LOL, thanks Tom and L'hopital\n\n    lim ln(an+b)/n\n\n    = lim a/(an+b)\n  5. Jun 27, 2003 #4\n    Oh sorry, I forgot to mention\n    is a sequence, not a function. I think L'hopital's rule applies to differentiable functions only.\n\n    Perhaps I better rephase the question a bit.\n    A sequence {an} is defined by (an+b)1/n-1\n    Prove that\n    lim (an+b)1/n-1 = 0\n    (a and b are real numbers and n is a positive integer)\n  6. Jun 27, 2003 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    It is true that L'hopital's rule applies to functions rather than sequences.\n\n    However, IF we can convert a sequence an to a function f(x) (we can't if the sequence involves things like n! or \"floor\" or \"ceiling\" that can't be written simply as a continuous function), then f(x)-> L, an-> L. The other way doesn't necessarily work- the function might not have a limit, depending on how it is defined for non-integer values.\n  7. Jun 27, 2003 #6\n    So we can treat a sequence as a function if it is an \"elementary\" one like the one I posted, and can apply L'hopital's rule, is it correct?\n\nHave something to add?\n\nSimilar Discussions: Limit of a sequence\n  1. Limit of sequence (Replies: 13)\n\n  2. Limits of Sequences (Replies: 8)\n\n  3. Limit of a sequence (Replies: 3)\n\n  4. Limit of a sequence (Replies: 2)"}
{"text": "Retrieved from http://mathoverflow.net/questions/109106/upper-bound-on-expectation-value-of-the-product-of-two-random-variables/109110\nText:\nTake the 2-minute tour \u00d7\n\nHello, I am trying to find an upper bound on the expectation value of the product of two random variables.\n\nSo suppose x, y are two non-independent random variables, given that I know the distribution of x p(x) and the distribution of y q(y), how can I find an upper bound on E[|x * y |] that is a function of p and q?\n\nI know that Holder's inequality gives an upper bound to my problem in terms of moments of x and y, but this is a poor bound for the problem that I am considering.\n\nThank you! Best Michele\n\nshare|improve this question\n\nclosed as not a real question by Yemon Choi, Qiaochu Yuan, Andres Caicedo, Will Jagy, Bill Johnson Oct 8 '12 at 16:04\n\n\nCauchy-Schwarz? \u2013\u00a0 Yemon Choi Oct 8 '12 at 0:22\nWell if it gives you a poor bound for your problem, you need to specify more details. The Cauchy-Schwarz inequality is sharp \u2013\u00a0 Yemon Choi Oct 8 '12 at 1:42\nWhy the down-votes? I don't think that C-S is sharp for this situation. If you assume that they are non-negative valued, the sharp upper bound is obtained when the variables are monotonically coupled. I'll post a formula for this in a few minutes. \u2013\u00a0 Anthony Quas Oct 8 '12 at 3:04\nC-S is sharp if all that you know are the second moments. Here we've got far more information: the entire distribution of the random variables. \u2013\u00a0 Anthony Quas Oct 8 '12 at 3:07\nI still think, though, that the question should have included at least some examples of the kinds of distribution that the OP had in mind \u2013\u00a0 Yemon Choi Oct 8 '12 at 3:52\n\n2 Answers 2\n\nI'll assume that $X$ and $Y$ are non-negative random variables. Let $F_X$ be the cumulative distribution function of $X$ (that is $F_X(t)=\\mathbb P(X\\le t)$) and $F_Y$ be the cumulative distribution function of $Y$.\n\nIn your notation, probably $F_X(t)=\\int_0^t p(s)\\,ds$ and $F_Y(y)=\\int_0^t q(t)\\,dt$.\n\nNow define two functions on $[0,1]$: $g_X(x)=\\sup\\lbrace t\\colon \\mathbb P(X\\le t)\\le x\\rbrace $ and similarly $g_Y(x)=\\sup\\lbrace t\\colon \\mathbb P(Y\\le t)\\le x\\rbrace$. These functions are the increasing rearrangements of $X$ and $Y$. That is these are non-decreasing functions with the property that $m\\lbrace x\\colon g_X(x)\\le t\\rbrace =\\mathbb P(X\\le t)$ and $m\\lbrace x\\colon g_Y(x)\\le t\\rbrace = \\mathbb P(Y\\le t)$.\n\nNow the largest possible value of $\\mathbb E XY$ given the distributions is $\\int_0^1 g_X(t)g_Y(t)\\ dt$. Intuitively the reason for this is that the largest value for the expectation is obtained when the largest values of $X$ are multiplied by the largest values of $Y$. Slightly more precisely imagine you've arranged the $X$ values from largest to smallest. Think of these as \"weights\" for the $Y$ values. Obviously you get the biggest integral if you weight the big $Y$ values with the biggest weights.\n\nshare|improve this answer\nDear Anthony, Thank you very much for your answer! A few questions: - Is this bound better than Holder's inequality's bound \ud835\udd3c[XY] <= E[X^p]^(1/p)*E[Y^q]^(1/q) with q>1,p>1,1/p+1/q = 1? If it is, is there a way of proving or simply justifying this? - Where can I find a proof of the bound that you suggested? Thanks you Best Michele \u2013\u00a0 Michele Oct 9 '12 at 23:54\nThe justification is in my answer. For more, you could try Lindvall's book \"Lectures on the Coupling Method\". This is the best possible bound: If you let $\\omega$ be uniformly distributed in the unit interval, then $g_X(\\omega)$ has the same distribution as $X$ and $g_Y(\\omega)$ has the same distribution as $Y$ and the product of these random variables has the integral in my answer. \u2013\u00a0 Anthony Quas Oct 10 '12 at 5:19\nDear Anthony, Still, it is not clear to me how to prove the inequality that you suggested : E[X*Y] <= \\int_{0}^{1} dt g_{X}(t) * g_{Y}(t). Is the proof in the book \"Lectures on the Coupling Method\"? It it not clear either wether and why this bound is better than the Holder's inequality bound E[X^p]^(1/p)*E[Y^q]^(1/q). Can you prove this? Thanks! Michele \u2013\u00a0 Michele Oct 16 '12 at 1:05\nIf you know that $X$ is uniformly distributed on the unit interval and $Y$ are is the uniformly distributed random variable on [1,2], then the bound I'm suggesting comes from $g_X(t)=t$, $g_Y(t)=1+t$, so that $\\mathbb E XY\\le \\int (t+t^2)\\,dt=5/6$. If you use H\\\"older's inequality, you get $(1/(p+1))^{1/p}((2^{q+1}-1)/(q+1))^{1/q}$. This is greater than 5/6 for all $1/p+1/q=1$. My bound is attained if $X$ is uniform and $Y=1+X$. In general, my bound is always attained for some joint distribution on $X$ and $Y$. The Holder bound is not always attained. So mine is lower and is best poss. \u2013\u00a0 Anthony Quas Oct 16 '12 at 5:57\nApparently the inequality I'm quoting goes by the name \"Hardy-Littlewood inequality\". See math.toronto.edu/almut/rearrange.pdf \u2013\u00a0 Anthony Quas Oct 16 '12 at 6:55\n\nI would try yo apply Hoeffding's Lemma, who used his result to identify the bivariate cdfs with given marginal cdfs that minimize or maximize correlation. Let $(X,Y)$ be a random vector with bivariate cdf $H$, let $F$ and $G$ be their marginal cdfs, respectively. It is well known that a sharp upper bound for $H(x,y)$ is $\\min(F(x),G(y))$. By Hoeffding's Lemma we get that $$E(XY)\\leq E(X)E(Y)+\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\big[\\min(F(x),G(y))-F(x)G(y)\\big]dxdy$$\n\nshare|improve this answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56191.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nBalls in Boxes\n\nDate: 05/05/99 at 13:49:04\nFrom: Alp Bassa\nSubject: A combinatorial problem (putting balls in boxes)\n\n\nI tried to solve the following problem. I know the answer, but I \ndon't know how to find it. I hope you can help me:\n\nin 2 of the boxes should be more then the balls in the other box. How \nmany ways are there to do this?\n\nAnswer: t*(t+1)/2 (why?)\n\nI tried to solve it this way:\n\n\nIf there are B(n-2) ways to do this with n-2 balls, then we can to \nthis with n Balls in B(n) ways. Now we just have to find some relation \nbetween B(n) and B(n-2). So it seems like a recursion problem.\n\nThank you very much,\nAlp Bassa\n\nDate: 05/05/99 at 16:09:40\nFrom: Doctor Anthony\nSubject: Re: A combinatorial problem (putting balls in boxes)\n\nIf any box is empty one box will have more balls than the other two, \nso we know that every box has some balls. Also with 2t+1 balls no box \ncan have more than t balls or again it would not satisfy the condition \nof being outnumbered by the other two. So the generating function is\n\n(x + x^2 + x^3 + ..... + x^t)^3 and we require coefficient of x^(2t+1)\n\nWe can write the series as  \n\n                 x^3(1 - x^t)^3\n                    (1 - x)^3 \n\n       = x^3(1-x^t)^3(1-x)^(-3)\n\n  =  x^3[1 -3x^t + 3x^(2t) - x^(3t)][1 + C(3,1)x + C(4,2)x^2 + ....\n\n  = x^3 - 3x^(t+3) + 3x^(2t+3) - x^(3t+3)]SUM[C(r+2,2)x^r] \n\nWe can ignore the terms 3x^(2t+3) - x^(3t+3) as they are already \nbeyond the power of 2t+1 that we require.\n\n  We have x^3.C(2t,2t-2).x^(2t-2)  =  C(2t,2t-2).x^(2t+1)\n\n  also  -3x^(t+3).C(t,t-2).x^(t-2)  =  -3.C(t,t-2).x^(2t+1)\n\nSo required coefficient is\n\n    2t(2t-1)     3t(t-1)       4t^2 - 2t - 3t^2 + 3t\n      2!           2!                    2!\n\n                                t^2 + t        t(t+1)\n                                   2             2 \n\nand so the number of arrangements satisfying the condition is \n\n\n- Doctor Anthony, The Math Forum\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56218.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nLab Partner Pairings\n\nDate: 01/21/2001 at 22:45:08\nFrom: Don Maynard\nSubject: Finding lab partner pairs in a class of 22\n\nA friend who is a teacher would like to find all the possible pairings \nof his 22 students for science labs. Is there an algorithm for this? \n\nIt's a problem that is much more complicated than it appears at first \nsight. There should be 11 pairs and no student should be paired to the \nsame other student twice in the series. I wrote a program that could \nlist up to 14 pairings, but that was not satisfactory because we \nwanted to find all possible lists and be assured that they were all \nthere. Any ideas? \n\nThanks for your consideration.\n\nDon Maynard\nAmerican School in Japan\n\nDate: 01/29/2001 at 11:52:31\nFrom: Doctor Ian\nSubject: Re: Finding lab partner pairs in a class of 22\n\nHi Don,\n\nIf I understand your question correctly, you are using the word \n'pairing' in the following way. A class of four students has the \nfollowing pairings:\n\n   Pairing 1:  AB CD \n   Pairing 2:  AC BD\n   Pairing 3:  AD BC\n\nIf this is the correct interpretation, then you can generate all the\npossible pairings in the following way.  \n\nI'll use the following data structure to represent a single pairing.  \nIt's a list that contains two other lists. The first list is a list of \nstudent pairs. (Each pair is itself a list.) The second list is a list \nof unpaired students. \n  (((a b) (c d))            The pairing so far.\n   (e f g h))               Students yet to be paired.\n\nStart with list containing a single empty pairing:\n\n    (a b c d)))\n\nFrom this, generate the set of possible first pairs, and make a new \npairing that begins with each of those pairs:\n\n  ((((a b))\n    (c d))\n   (((a c))\n    (b d))\n   (((a d))\n    (b c))\n   (((b c))\n    (a d))\n   (((b d))\n    (a c))\n   (((c d))\n    (a b))\n\nNote what we did here - we took each possible pair from the list of\nunpaired students, and added that pair to the pairing. Then we removed\nthose students from the unpaired list. Each pair gives rise to a \ncompletely new pairing. \n\nNow do the same thing over again:\n\n  ((((a b) (c d))\n   (((a c) (b d))\n   (((a d) (b c))\n   (((b c) (a d))\n   (((b d) (a c))\n   (((c d) (a b))\n\nEach pairing is expanded until its unpaired list is empty, at which \npoint the pairing is complete. Note that in the general case (i.e., \nmore than two unpaired students), each pairing will give rise to \nseveral new pairings each time a new pair is selected, e.g.:\n\n  (((a f) (c e))\n   (b d g h))\n  (((a f) (c e) (b d))\n   (g h))\n  (((a f) (c e) (b g))\n   (d h))\n  (((a f) (c e) (b h))\n   (d g))\n  (((a f) (c e) (d g))\n   (b h))\n  (((a f) (c e) (d h))\n   (b g))\n  (((a f) (c e) (g h))\n   (b d))\nIn fact, a pairing with N unpaired students will give rise to \nN*(N-1)/2 new pairings.  \nNote that this algorithm will generate some duplicate pairings. But \nyou can sort all the pairings, which will force duplicates to appear \nnext to each other, making them easy to find and remove: \n\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a d) (b c))\n  ((b c) (a d))\n  ((b d) (a c))\n  ((c d) (a b))\n\n  == sort ==>\n\n  ((a b) (c d))\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a c) (b d))\n  ((a d) (b c))\n  ((a d) (b c))\n\n  == remove duplicates ==>\n\n  ((a b) (c d))\n  ((a c) (b d))\n  ((a d) (b c))\n\nIn fact, since the number of possible pairings for 22 students is \ngoing to be VERY large, you might want to so this sort-and-remove step \nafter each round of selections, instead of waiting until the end.  \n\nI've used notation from the Lisp programming language, which is \nideally suited for this kind of thing; but you should be able to \nimplement the same algorithm in just about any programming language. \n\nI hope this helps.  Write back if you'd like to talk about this some \nmore, or if you have any other questions. \n\n- Doctor Ian, The Math Forum\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/110892/a-question-about-standard-inner-product-linear-algebra\nText:\nTake the 2-minute tour \u00d7\n\nIt's a question from a test I didn't knew how to solve:\n\nAn inner product space in $V=R^n$, such as $$\\left\\langle \\pmatrix{ x_1\\\\ \\vdots \\\\ x_n}\\pmatrix{ y_1\\\\ \\vdots\\\\ y_n} \\right\\rangle = x_1y_1 + x_2y_2 +\\ldots +x_ny_n $$ (standard)\n\n$ v , u $ are not linear dependent in $V$. And $W = \\operatorname{sp}d \\left \\{ (u+v),(u-v) \\right \\}$; now I am asked to prove that if exists a $w$ in $W^\\perp$, $w\\neq0$ then : $3 \\leq \\dim(V)$.\n\nI tried to check for dimensions $2$, $1$ and to prove that $w=0$ but with no luck...\n\n\nshare|improve this question\n\"sp\" stands for \"span\", right? So $W$ is in fact the vector space generated by $u$ and $v$. Then show that $\\{u,v,w\\}$ is linearly independent. \u2013\u00a0 Davide Giraudo Feb 19 '12 at 11:03\nyes it is :) I will try to solve it now. thank you! \u2013\u00a0 YNWA Feb 19 '12 at 11:10\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nSince $2u=(u+v)+(u-v)$ and $2v=(u+v)-(u-v)$, we have $\\operatorname{span}\\{u+v,u-v\\}=\\operatorname{span}(u,v)$. If we have $au+bv+cw=0$ where $a,b,c\\in\\mathbb R$ then $$0=\\langle au+bv+cw,w\\rangle=a\\langle u,w\\rangle+b\\langle v,w\\rangle+c\\langle w,w\\rangle=c\\langle w,w\\rangle.$$ Since $w\\neq 0$ we have $\\langle w,w\\rangle\\neq 0$ so $c=0$ and $au+bv=0$. Since $u$ and $v$ are linearly independent, we have $a=b=0$ so finally the set $\\{u,v,w\\}$ is linearly independent.\n\nNote that the fact that $\\langle\\cdot,\\cdot\\rangle$ was the usual inner product was not necessary; it would work for example if $\\langle x,y\\rangle=\\sum_{j=1}^na_jx_jy_j$ where $a_j$ are positive real numbers.\n\nshare|improve this answer\nthank you, simple and well written... :) \u2013\u00a0 YNWA Feb 19 '12 at 11:33\nYou're welcome. \u2013\u00a0 Davide Giraudo Feb 19 '12 at 11:33\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/131300/can-one-prove-int-f-0-for-f-0-without-lebesgue-integration\nText:\nTake the 2-minute tour \u00d7\n\nIn an exercise session of an analysis course (which covers Riemann integration and differentiation in one dimension rigorously) the following question came up:\n\nSuppose $f$ is strictly positive and integrable (on some compact interval $[a,b]$ on the real line). Can we show that $\\int_a^b f > 0$?\n\nThe proof by using measure theory and Lebesgue integration is easy, but also beyond the students at this point. So can one do without machinery such as sets of zero measure?\n\nTools in use: Mean value theorems, fundamental theorem of calculus, Riemann's condition for integrability (upper and lower integral within every epsilon of each other implies integrability), Riemann-Darboux integral, usual integration and differentiation techniques, as well as elementary real analysis in the epsilon-delta style.\n\nshare|improve this question\nHint: interval sequence theorem and upper Darboux sum \u2013\u00a0 89085731 Apr 13 '12 at 14:57\nThere's also a proof via the Baire category theorem. \u2013\u00a0 Chris Eagle Apr 13 '12 at 19:08\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nThis can be shown using the concept of oscillation.\n\nFor a bounded $f$, the oscillation of $f$ over set $A$ (which is not a single point) is given by\n\n$$w(A) = \\sup_{A} f - \\inf_{A} f$$\n\nFor a single point $x$, the oscillation is defined as\n\n$$ w(x) = \\inf_{J} w(J)$$\n\nwhere $J$ ranges over bounded intervals containing $x$.\n\nNote that if $x \\in I$, then $w(x) \\le w(I)$.\n\nNow if $f$ is Riemann integrable over $[a,b]$, then we can show that given any $n \\gt 0$, there is a sub-interval $I_{n}$ of $[a,b]$ such that $w(I_n) \\le \\frac{1}{n}$.\n\nThis is because, if every subinterval $I$ of $[a,b]$ had $w(I) \\gt \\frac{1}{n}$, then for every partition of $[a,b]$ the difference between the upper and lower sums would be at least $\\frac{b-a}{n}$ and as a consequence, $f$ would not be integrable.\n\nNow pick $I_{n+1} \\subset I_{n}$ such that $w(I_{n+1}) \\le \\frac{1}{n+1}$.\n\nBy completeness there is a point $c$ such that $c \\in I_n$.\n\nThus $w(c) \\le w(I_n) \\le \\frac{1}{n}$ for all $n$. Hence $w(c) = 0$.\n\nNow it can be show that $f$ is continuous at point $x$ if and only if $w(x) = 0$.\n\nNote: This is basically a simplification of one proof of the Riemann Lebesgue theorem of continuity almost everywhere.\n\nshare|improve this answer\nI think it may not be the Riemann Lebesgue theorem.The Riemann Lebesgue Theorem might be $\\lim_{n\\to \\infty}\\int_a^b f(x)g(nx)dx=\\frac{1}{T}\\int_a^b f(x)dx\\int_0^T g(x)dx$ \u2013\u00a0 89085731 Apr 14 '12 at 0:26\n@Gingerjin: There are multiple with \"Riemann Lebesgue\" name. For instance, there is the Riemann Lebesgue Lemma... \u2013\u00a0 Aryabhata Apr 14 '12 at 0:29\n\nIf f is integrable in [a,b], there is a point x0 in the interval where f is continuous, and positive. Then there is a neighborhood of the point where f is positive , contained in the interval.There we can take a closed inreval where it is positive and there f has minimum then the integral at this interval is bigger or equal than the integral of the minimum which is positive. We can then apply aditivity in the interval [a,b] and in the other closed intervals the integral is no negative since each riemann summ si no negative.\n\nshare|improve this answer\nI think you first need to prove there is a point that is continuous in[a,b] for him.Actually, this conclusion will lead to the conclusion that the continuous point is dense. \u2013\u00a0 89085731 Apr 13 '12 at 15:05\nYes.We can use that if f is Riemann integrable then the set of discontinuities has measure zero, but I will think how to prove without measure theory that there is a point of continuity. \u2013\u00a0 alpha.Debi Apr 13 '12 at 15:56\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/proof-by-induction.253129/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProof by induction\n\n  1. Sep 1, 2008 #1\n    Show, by induction, that for all whole number of Roubles greater than 7, the amount can be given without change by using only 3 rouble and 5 rouble notes.\n\n    2. Relevant equations\n    In other words for all [tex]n \\in N, n > 7[/tex], there exist [tex] a, b \\in N [/tex] such that [tex] n = 5a + 3b [/tex]\n\n    3. The attempt at a solution\n    This is true for n = 8\n\n    I'm wondering if I can't use strong induction. I've noticed that all of these n's appear to be writable with [tex]a \\in \\{0,1,2\\}[/tex] while letting b take on any value, and that when you express the integers greater than 7 in order the a's when thus constrained go 1, 0, 2, 1, 0, 2, etc and each time around the b increments by one for each repetition of a. So, I don't know if I can weasel something out of this like to go from n to n+1 means either going from 1 to 0, 0 to 2, or 2 to 1 in a with the associated incrementation, but I just get the feeling that this isn't the way to go. It seems I'm missing something easier.\n  2. jcsd\n  3. Sep 1, 2008 #2\n    Looks like you're on the right track, and since it's true for n=8, it's true for n=18, n=28, etc. And if it's true for n=9...\n  4. Sep 2, 2008 #3\n    I think the real trick on this was to use strong induction and notice that P(n+1) is implied by assuming P(1)...P(n) are true. Specifically, if P(n-2) is true, then P(n+1) is implied because it is three more than it, so if P(n-2) were written as 5a+3b, P(n+1) is 5a + 3(b+1)\n\nHave something to add?\n\nSimilar Discussions: Proof by induction\n  1. Proof by induction (Replies: 2)\n\n  2. Proof by induction (Replies: 9)\n\n  3. Proof by induction (Replies: 32)\n\n  4. Induction Proof (Replies: 14)\n\n  5. Proof by Induction (Replies: 6)"}
{"text": "Retrieved from https://brainmass.com/physics/electric-power/electric-field-in-a-spherical-cavity-in-a-dielectric-medium-170253\nText:\nExplore BrainMass\n\nElectric field in a spherical cavity in a dielectric medium\n\nShow that the field inside a spherical cavity cut in a uniform dielectric medium is uniform and of magnitude\n\nEcav = 3erEm/(2Er+1),\n\nwhere er is the relative permittivity of the medium and Em is the uniform field in the dielectric at a point distant from the cavity.\n\nSolution Preview\n\nAs usual we introduce the \"electric displacement field\" D:\n\nD = er E (1)\n\nwhere er is the relative permittivity .\n\nThen, as explained in your textbook,\n\ndiv D = rho_free/epsilon_0 (2)\n\nwhere rho_free is the charge density due to free charges, not the induced polarization charges. So, the polarization effects of the medium do not appear in D and D behaves like the electric field would if there were no medium.\n\nTo solve problems like this one where you have different regions with constant relative permittivities, you reason as follows. In each of the regions equation (1) is valid, albeit it with a different er for each region. If we introduce the electric potential V defined by E = -nabla V, then it follows from (1) that in each region:\n\nD = -er nabla V (3)\n\nInsert this in (2) to obtain:\n\nnabla^2 V = -rho_free/(er epsilon_0) (4)\n\nOr if there are no free charges, such as in this problem, we have:\n\nnabla^2 V = 0 (5)\n\nSo, we just need to solve the Laplace equation. To do that we need to know the boundary conditions. Let's consider the boundary of two dielectrics. It follows from the Maxwell equation nabla times E = 0 (which allows you to write E = nabla V in the first place), via Stokes' Theorem that:\n\nThe ...\n\nSolution Summary\n\nA detailed explanation is given."}
{"text": "Retrieved from http://mathforum.org/kb/thread.jspa?threadID=2455175&messageID=8911841\nText:\nThe Math Forum\n\nSearch All of the Math Forum:\n\n\nMath Forum \u00bb Discussions \u00bb sci.math.* \u00bb sci.math\n\nTopic: probability problem\nReplies: 2 \u00a0 Last Post: May 4, 2013 11:34 AM\n\nAdvanced Search\n\n\nPosts: 419\nRegistered: 10/7/06\nRe: probability problem\nPosted: May 4, 2013 11:34 AM\n\nOn May 4, 1:43\u00a0pm, wrote:\n> Hello,\n> I am stuck with a probability problem. Here is the problem. Any help would be great.\n> There are N samples each have probability of Pi (i=0......n-1)\n> I want to find out probability of at least K of them occurs. Each is sampled only once. If probability of N events to be same it would have simpler. now since probability is different , not sure how to calculate this. Please also mention logic behind the calculations.\n\n1. What's the result if K = 0? With that out of the way, assume K >=\n\n2. Let q (i, j) be the probability that exactly j of the first i\nsamples occur, for 0 <= i <= n, 0 <= j < K. Let r (i) be the\nprobability that K or more of the first samples occur.\n\nGiven that K > 0, what is q (0, 0), what is q (0, j) for 1 <= j < K,\nwhat is r (0)? Look at the definitions of q and r, and the result\nshould be obvious.\n\nFor 1 <= i <= n: Since you know q (i-1, j) for 0 <= j < K, r (i-1),\nand p (i-1) which is the probability that the i-th sample occurs, how\ndo you calculate q (i, 0), q (i, j) for 1 <= j < K, and r (i) ?\nThere's a simple formula for each.\n\nThe desired result is r (n). Why?\n\n3. For extra points: How do you reduce the number of calculations if K\n>= n / 2?\n\n\n[Privacy Policy] [Terms of Use]"}
{"text": "Retrieved from http://math.stackexchange.com/questions/673824/generalization-of-sum-of-cube-of-any-3-consecutive-integers-is-divisible-by-3\nText:\nTake the 2-minute tour \u00d7\n\nI have this question posted by professor in graduate Number Theory class. First he asked for proof that the sum of cube of 3 consecutive integers is divisible by 3, which is very easy to prove, but then he continued by asking to prove its generalization, ie., n | 1^n + 2^n + 3^n + ... + n^n.\n\nHere you can easily find a counterexample that if n is even, the generalization fails. But if n is odd, looks like it works. I tried using mathematical induction but did not go anywhere. Then I tried using Binomial Expansion, Pascal Triangle, and using representation of consecutive numbers as ... (a-3), (a-2), (a-1), a, (a+1), (a+2), (a+3), ... in order to cancel out, but still did not go anywhere.\n\nI would appreciate any help. Thank you for your time.\n\nshare|improve this question\nHint: Use modular arithmetic. If you have $1,2,3,4,\\dots, n$, in modulo $n$, you have $1,2,3,\\dots, -3,-2,-1,0$. If $n$ is odd, then $(-a)^n = -a^n$, so that would cancel with $a^n$. \u2013\u00a0 Braindead Feb 12 '14 at 14:29\nWhy doesn't $a-3,a-2,a-1,a,a+1,a+2,a+3$ work? Add those $7$ numbers together and you get $7a$, which is divisible by $7$. \u2013\u00a0 John Habert Feb 12 '14 at 15:16\nThanks for your response! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:29\n@Braindead: Do give me example. Suppose you have 5, 6, 7, 8, 9, 10, 11 (mod 7), how do you turn them into -3, -2, -1, 0, 1, 2, 3 (mod 7) such that they will be cancel out? Thanks. \u2013\u00a0 A.Magnus Feb 14 '14 at 15:27\n@LoveMath I edited my answer to include the example. \u2013\u00a0 Braindead Feb 14 '14 at 17:01\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nSince this is a graduate level number theory class, I think it's safe to assume that you are familiar with modulo arithmetic?\n\nGiven any list of $n$ consecutive integers, $a, a+1, a+2, \\dots, a+n-1$, modulo $n$ this list is equivalent to $0,1,2,3,\\dots,n-1$ modulo $n$. (Note that I am not saying $a \\equiv 0 \\pmod{n}$). This list can be rewritten as:\n\n$1 \\equiv 1 \\pmod{n}$\n\n$2 \\equiv 2 \\pmod{n}$\n\n$3 \\equiv 3 \\pmod{n}$\n\n\n$\\dfrac{(n-1)}{2} \\equiv \\dfrac{(n-1)}{2} \\pmod{n}$\n\n$n-1 \\equiv -1 \\pmod{n}$\n\n$n-2 \\equiv -2 \\pmod{n}$\n\n$n-3 \\equiv -3 \\pmod{n}$\n\n\n$\\dfrac{(n+1)}{2} \\equiv -\\dfrac{(n-1)}{2} \\pmod{n}$\n\nSince $n$ is odd, exponentiation preserves the sign. And so\n\n$$0^n + 1^n + 2^n + \\dots + \\left(\\dfrac{n-1}{2}\\right)^n + \\left(\\dfrac{n+1}{2}\\right)^n + \\dots + (n-2)^n + (n-1)^n + n^n$$\n\nis equivalent to\n\n$$1^n + 2^n + \\dots + \\left(\\dfrac{n-1}{2}\\right)^n - \\left(\\dfrac{n-1}{2}\\right)^n + \\dots - 2^n - 1^n$$\n\nmodulo $n$, and so the sum becomes $0$ modulo $n$. Note that the exponent could be replaced by any odd integer and the statement will still hold.\n\nEDIT: Here is the example you requested in the comments.\n\nLet's say we have the list 5, 6, 7, 8, 9, 10, 11, with $n=7$.\n\nOkay, so the first thing I will do is to find their representatives in $\\mod 7$ between $0$ and $6$ inclusive.\n\n\n5, 6, 7, 8, 9, 10, 11 becomes 5, 6, 0, 1, 2, 3, 4.\n\nNow, let's look at $(n-1)/2$. For $n=7$, this number is 3. That is the cut off for the positive terms. The rest of them I turn them into negatives:\n\n$5, 6, 7, 8, 9, 10, 11$ becomes\n\n$5, 6, 0, 1, 2, 3, 4,$ which is\n\n$7-2, 7-1, 0, 1, 2, 3, 7-3$, which becomes\n\n$-2, -1, 0, 1, 2, 3, -3$.\n\nNow, take any odd power of these numbers, sum, you get 0 in modulo 7.\n\nTechnically, I could've gone directly from the original list to $-2, -1, 0, 1, 2, 3, -3$, without going through the intermediate step, but I wanted to illustrate how the proof applies to this particular example.\n\nshare|improve this answer\nThanks for your elaborate response! I actually came up with my own, but mine is good only for prime, yours is more comprehensive. (I used binomial coefficient, when n is prime then all coefficients will be divisible by n, etc.) Thanks again! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:29\nSolid Answer, nicely done. \u2013\u00a0 Newb Feb 14 '14 at 17:02\n\nThe remainders modulo $2k+1$ can be (re)written as $0,\\pm1,\\pm2,\\ldots,\\pm k$. By rising them each to any positive odd power of our choosing, they will maintain their sign, while their absolute values will be pair-wise equal, so ultimately their sum will be divisible through $n=2k+1$.\n\nshare|improve this answer\nThank you for your response! \u2013\u00a0 A.Magnus Feb 13 '14 at 15:26\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/431164/distributing-distinguishable-particles-in-dinstinguishable-boxes-and-computing-c\nText:\nI have n distinguishable particles and m distinguishable boxes. If all particles are in the same box the system has an energy of -$\\epsilon$ in all the other cases the energy is 0.\n\nNow I want to compute the canonical partition function. The Helmhltoz energy and the entropy of the ground state.\n\nTo start with I would count the number of possibilities to put all particles in single boxes.\n\nThere are $n!$ ways to arrange n distinguishable particles. And I have m boxes. And last I have $m!$ ways to arrange the different boxes. Therefore I have $n!*m*m!$ possibilities. The next step is to compute all possibilities to distribute n distinguishable particles in m distinguishable boxes. To distribute n particles in m boxes I have $m^{n}$ possibilities for a single configuration. Then I can arrange each configuration in $n!$ ways and last I can arrange the boxes again in $m!$ different ways. Hence the number of remaining possibilities is\n\n$$ m^{n}*n!*m!-n!*m*m!. $$\n\nThis gives the partition function:\n\n$$ Z(m,n,T)=m^{n}*n!*m!-n!*m*m!+n!*m*m!*e^{\\beta*\\epsilon}=\\\\ m!*n!*m*(m^{n-1}-1+e^{\\beta\\epsilon}) $$\n\nSince constant factors in the partition function do not matter when computing averages since they cancel I can neglect the prefactor m!*n!*m The partition function is therefore $$ Z(m,n,T)=m^{n-1}-1+e^{\\beta\\epsilon} $$\n\nThe Hemholtz free energy is then: $$ F=-k_bT*log(m^{n-1}-1+e^{\\beta\\epsilon}) $$\n\nNow I am not sure if the counting I have done above is correct and the next thing is I am not completely sure how to compute the ground state entropy.\n\nThe entropy is defined as $S=-k_{b}\\sum_{i}p_{i}log(p_i)$ and for as single state it should be $S=-k_{b}*p*log(p)$. The probability for the ground state would then be:\n\n$$ p_{G}=\\frac{e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}} $$ and hence the entropy $$ S=-\\frac{k_b*e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}}*log\\left(\\frac{e^{\\beta\\epsilon}}{m^{n-1}-1+e^{\\beta\\epsilon}}\\right) $$\n\nBut still I am not quite sure if this is correct especially with the counting I feel very insecure. Thanks for your help\n\n  \u2022 $\\begingroup$ I am not sure, but here is what I think could be the right way. I am not sure why you are bothered with arranging the boxes and particles after you have considered m^n possibilities. I think that this itself includes all possible arrangements of the particles and boxes. Rearranging the order in which you consider the boxes or particles should not create more microstates. Hence I think the partition function should be (m^(n) - m) + m * e^(beta * E) $\\endgroup$ \u2013\u00a0Hari Sep 28 '18 at 15:30\n  \u2022 $\\begingroup$ @Hari. Okay but what is the criterion for creating a new microstate I think this is the point I don't quite get. So what is the criterion to be a microstate? Because I thought since the particles are distinguishable and so are the boxes any arrangement of particles and boxes would create a new microstate. Is this wrong $\\endgroup$ \u2013\u00a0zodiac Sep 29 '18 at 10:09\n  \u2022 $\\begingroup$ Suppose there are 2 boxes (B1,B2) and 2 particles (P1, P2). The microstates will be : 1) B1 (P1,P2) B2 () ; 2) B1 () B2(P1,P2) ; 3) B1 (P1) B2(P2) ; 4) B1(P2) B2(P1). I think these are the only microstates, rearranging the order in which you write B1 and B2, in this case 5) B2(P1) B1(P2) or 6) B2(P2) B1(P1) are not microstates as they are physically the same as (4) and (3) respectively. $\\endgroup$ \u2013\u00a0Hari Sep 29 '18 at 18:33\n  \u2022 $\\begingroup$ Thank but I fear I still don't get it right I guess. I mean what you are saying sounds completely reasonable. But if 5) and 6) are the same as 4) and 3) does't this mean those states have a higher entropy since they have more realizations. $\\endgroup$ \u2013\u00a0zodiac Oct 1 '18 at 6:44\n  \u2022 $\\begingroup$ And also I can place the labeled particles in different orders to the boxes since they are distinguishable. Then for example your state 1) B1 (P1,P2) B2 () could also be written as 1')B1(P2,P1) , B2(). I mean for sure those states are physically indistinguishable but dont' they have a higher a priori probability since there are more possibilities to create those states. I am sorry for bothering you again. But this seems to be a very crucial point that I don't get. I think this is also shown on this wiki page. link: en.wikipedia.org/wiki/Microstate_(statistical_mechanics). $\\endgroup$ \u2013\u00a0zodiac Oct 1 '18 at 6:44\n\nBased on Harrys comments I would like to answer this question to close this thread. It does not matter in which order I put the labeled particles in to the boxes since there are no drawers in the boxes and hence in the end I am not able to differentiate between the order of the particles anymore. This means $B(1,2,3)$ is the same as B(2,1,3) because the balls are lose in this box and are able to roll around freely. The next thing is the boxes have labels this states that box one will always be box one no matter where it is put to on the shelf. Hence there is no need to take into account the permutations of the boxes. Therefore the canonical partition function is just\n\n$$ Z(n,m,T)=(m^{n}-m)+me^{\\beta\\epsilon} $$\n\nThe Helmholtz free energy $$ F(n,m,T)=-k_{B}T=log\\left( m^{n} - m + e^{\\beta\\epsilon} \\right) $$\n\nAnd the ground state probability and the entropy stay the same since one m factors out.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/23269/differential-equation-quite-weird-task\nText:\nI'm having some trouble while trying to understand one task.. The task is as follows:\n\n$$\\ddot{x}(t) + \\dot{x}(t) + 2x(t) = \\sin(\\omega t)$$ where $x(0) = 7, t\\geq 0$\n\nThe solution is in the following form:\n\n$$x(t) = f(t) + A\\sin(\\omega t + \\varphi)$$\n\nAnd the task is: find $\\omega$ so that $A$ is max.\n\nMy understanding of this is that $f(t)$ is the solution of the homogeneous differential equation and the rest is the special solution of the nonhomogeneous equation. Still that does not give me any clue about how to evaluate the relationship between $A$ and $\\omega$. Any clues?\n\n\nSince $f$ is the (generic) homogeneous solution, you can choose to set it equal to zero; then you just have the special solution $x(t) = A\\mathrm{sin}(\\omega t+\\phi)$. You should be able to find $\\ddot{x}(t)$ and $\\dot{x}(t)$, then plug them all into your core differential equation and see what it means for both sides to be equal - if you've done it right, this will give you the relation between $\\omega$ and $A$ that you're looking for.\n\n  \u2022 $\\begingroup$ Thank you. I'm certainly able to do that, but is it right to just \"choose the solution to be equal to 0\" ? What are the consequences? $\\endgroup$ \u2013\u00a0kubal5003 Feb 22 '11 at 20:36\n  \u2022 $\\begingroup$ kubal: if you plug in the generic form for $x(t)$ into the equation and then use the fact that $f(t)$ solves the homogeneous version of the equation, you'll find that it cancels right out and you're left with exactly the same terms that you would've had if you had chosen $f(t)$ to be $0$ to begin with. $\\endgroup$ \u2013\u00a0Steven Stadnicki Feb 22 '11 at 21:37\n  \u2022 $\\begingroup$ I guess I'll have to do that in order to prove that the solution is not just a special case. This might appear on tommorows exam (I hope not) $\\endgroup$ \u2013\u00a0kubal5003 Feb 22 '11 at 22:12\n\nThe correct value of $\\omega$ is not $\\frac{\\sqrt{7}}{2} \\approx 1.32$. It's $\\sqrt{\\frac{3}{2}} \\approx 1.22$. We are looking for a near resonance effect, but you can't actually have resonance when the harmonic oscillator is damped. This makes the analysis is a little different.\n\nA reference is the section on sinusoidal forcing in the Wikipedia page on the harmonic oscillator. From the formulas there you can see that the relationship between $A$ and $\\omega$ is given by\n\n$$A = \\frac{1}{\\sqrt{\\omega^2 + (2 - \\omega^2)^2}}.$$\n\nSolving $\\frac{dA}{d \\omega} = 0$ yields $\\omega = \\sqrt{\\frac{3}{2}}$.\n\nUpdate: Here's the derivation.\n\nThe trick is to generalize, and solve the differential equation $x'' + x' + 2x = e^{i \\omega t}$. The resulting solution will have a real part and an imaginary part. Since $e^{i \\omega t} = \\cos \\omega t + i \\sin \\omega t$, you actually want the imaginary part of the solution.\n\nAs the driving force is an exponential, we know that the particular solution must be of the form $x_p(t) = c e^{i \\omega t}$. Subbing that into the differential equation produces the auxiliary equation $-c \\omega^2 + i c\\omega + 2c = 1$. Solving that for $c$ yields $$c = \\frac{1}{a + i b} = \\frac{a - i b}{a^2 + b^2},$$ where $a = 2 - \\omega^2$ and $b = \\omega$. Thus the particular solution to the complex differential equation is $$x_p(t) = \\frac{a - i b}{a^2 + b^2} (\\cos \\omega t + i \\sin \\omega t),$$ of which the imaginary part is $$-\\frac{b}{a^2 + b^2} \\cos \\omega t + \\frac{a}{a^2+b^2} \\sin \\omega t.$$ Since $A$ is just the magnitude of this solution (you're doing a rotation to the vertical axis when converting to $A \\sin (\\omega t + \\phi)$), we get $$A = \\frac{1}{\\sqrt{a^2+b^2}} = \\frac{1}{\\sqrt{\\omega^2 + (2 - \\omega^2)^2}}.$$\n\n  \u2022 $\\begingroup$ You could also get this by assuming a solution of the form $c_1 \\cos \\omega t + c_2 \\sin \\omega t$. Once you find $c_1$ and $c_2$ in terms of $\\omega$, you'll have $A = \\sqrt{c_1^2 + c_2^2}$. I like the solution with the complex exponential, though; it seems more intuitive to me. $\\endgroup$ \u2013\u00a0Mike Spivey Feb 23 '11 at 3:37\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/42930/what-is-the-expected-value-of-the-number-of-die-rolls-necessary-to-get-a-specifi\nText:\nGiven a discrete random number generator, such as a six-sided die, what is the expected value of the number of rolls necessary to roll a specific number (e.g. a six)?\n\nI think the result should be given by E$\\langle$rolls$\\rangle$ = $\\frac{1}{6}\\sum_{n=0}^\\infty{(\\frac{5}{6})^n(n+1)}$, but I don't know how to calculate the convergence of that sum.\n\nAlso, how do I calculate the variance?\n\n\nA slightly simpler recursive derivation is this. We must roll the die at least once. On the first roll we get a 6 with probability $\\frac{1}{6}$. Otherwise we start again. Hence, $E = 1 + \\frac{5}{6}E$, which gives $E=6$.\n\nHere is a more general answer:\n\nRegard rolling the die as a Bernoulli process $X_1,X_2, \\ldots$, where $X_i = $ Success, with probability $p$, and $X_i = $ Failure, with probability $1-p$. The process stops after the first success.\n\nLet $N_s$ be the length of the sequence until the first Success. This is a random integer. Then we have $$ \\Pr (N_s=k) = \\Pr(\\underbrace{FF\\cdots F}_{k-1}\\ S) = \\underbrace{(1-p)(1-p)\\cdots(1-p)}_{k-1}\\ p=(1-p)^{k-1}p=pq^{k-1}, $$ where $q=1-p$ and $k\\ge1$. This is called a Geometric Distribution, which is the discrete equivalent of the Exponential Distribution. Random variables with these distributions are called memoryless. (See Ross, Introduction to Probability Models, 9th Edition, page 284.)\n\nThe expected value and variance of $N_s \\sim \\text{Geom}(p)$ are $$ \\text{E}{N_s(p)}=\\frac{1}{p}, \\text{ and } \\text{Var}{N_s(p)} = \\frac{1-p}{p^2}. $$Proof can be found in Ross, above. Note that $$\\text{E}{N_s(p)} = 1 +(1-p)\\text{E}{N_s(p)}, \\text{ whose solution is } \\frac{1}{p}.$$\n\nIn your case $p = \\frac{1}{6}\\,$ and so E(No. rolls) = 6, and Var(No. rolls) = 30 -- Geom$(\\frac{1}{6})$ has a long tail.\n\n\nOne \"trick\" that often lets you avoid issues of convergence when solving probability problems is to use a recursive argument.\n\nYou have a 1/6 probability of rolling a 6 right away, and a 5/6 chance of rolling something else and starting the process over (but with one additional roll under your belt).\n\nLet $E$ be the expected number of rolls before getting a 6; by the reasoning above, we have:\n\n$E = (1)(1/6) + (E + 1)(5/6)$\n\nSolving for $E$ yields $E = 6$.\n\nAn alternative approach is to use the generating function. The generating function $G(t)$ for a probability distribution that only takes on integer values is defined as:\n\n$G(t) = \\Sigma_{i = 0}^{\\infty} p_i t^i$\n\nThe reason the generating function comes in handy is that $G'(1)$ gives the expected value and $G''(1) + G'(1) - (G'(1))^2$ gives the variance; one can check this directly.\n\nIn our case, the generating function is:\n\n$G(t) = (1/6)t + (1/6)(5/6)t^2 + (1/6)(5/6)^2t^3 + \\ldots$\n\nWe can rewrite this as follows:\n\n$G(t) = (1/5)(5t/6 + (5t/6)^2 + (5t/6)^3 + \\ldots)$\n\nSumming the geometric series gives $G(t) = t/(6-5t)$; from here, we can calculate $G'(t)$ and $G''(t)$, plug in $t = 1$, and use the above expressions to extract both the expected value and the variance (6 and 30, respectively).\n\n\nElliott's answer is surely the nicest. To sum the series, we can use a method similar to the geometric series.\n\nLet $$S = 1 + 2 \\cdot \\left(\\frac{5}{6}\\right) + 3 \\cdot \\left(\\frac{5}{6}\\right)^2 + \\cdots $$\n\n\n$$\\frac{5}{6}S = \\frac{5}{6} + 2 \\cdot \\left(\\frac{5}{6}\\right)^2 + 3 \\cdot \\left(\\frac{5}{6}\\right)^3 + \\cdots $$\n\n$$S - \\frac{5}{6}S = 1+ \\left(\\frac{5}{6}\\right) +\\left(\\frac{5}{6}\\right)^2 + \\cdots $$\n\nThis is just a geometric series and hence we have that\n\n$$S = 36$$\n\nNow we have that $$\\frac{1}{6} \\sum_{n=0}^\\infty \\left(\\frac{5}{6}\\right)^n (n+1) = \\frac{1}{6} \\cdot S = 6,$$ as expected.\n\n(Convergence of the series can be seen by the ratio test)\n\n  \u2022 $\\begingroup$ Very nice. It's great to see so many different ways to find the convergence value for power series. $\\endgroup$ \u2013\u00a0jeremy radcliff Jan 25 '17 at 21:12\n\nHere's an intuitive argument. Roll the die $6000$ times. You'd expect there to be $1000$ 6's among them. Consider the gaps between successive 6's in the list (plus the initial gap to the first 6). These lengths are the values of independent draws from a geometric RV with $p=1/6$, so the average gap length is the expected value you want.\n\nThe sum of these (~1000) gap lengths is 6000, and so the average gap is $6000/1000=6$ (modulo a little fudge at the end which would go to $0$ by making the string longer).\n\n\nI'm late to the party, but here's a slightly different path to the same solution. Let $X$ be the number of die rolls until we roll a specific number. Let $p$ be the probability that we roll the specific number and $q = 1-p$ be the probability that we roll any of the other numbers. We know\n\n$$ \\mathbb{E}[X] \\triangleq 1p + 2qp + 3q^2 p + 4q^3p + \\dots $$\n\nNote that the geometric series $\\sum_{x=1}^{\\infty} q^x = \\frac{q}{1-q}$. Using this fact and a little algebra and calculus, we get,\n\n$$ \\begin{align} \\mathbb{E}[X] &= 1p + 2qp + 3q^2 p + 4q^3p + \\dots \\\\ &= \\sum_{x = 0}^{\\infty} (x + 1) q^x p \\\\ &= \\sum_{x = 1}^{\\infty} x q^{x-1} p \\\\ &= \\sum_{x = 1}^{\\infty} \\frac{\\partial}{\\partial q} q^x p \\\\ &= p \\frac{\\partial}{\\partial q} \\Big( \\sum_{x = 1}^{\\infty} q^x \\Big) \\\\ &= p \\frac{\\partial}{\\partial q} \\Big( \\frac{q}{1-q} \\Big) \\\\ &= p \\frac{1}{(1 - q)^2} \\\\ &= \\frac{\\frac{1}{6}}{\\big(1 - \\frac{5}{6}\\big)^2} \\\\ &= 6 \\end{align} $$\n\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/4887/dijkstra-to-favor-solution-with-smallest-number-of-edges-if-several-paths-have-s\nText:\nYou can modify any graph $G$ so that Dijkstra's finds the solution with the minimal number of edges thusly:\n\nMultiply every edge weight with a number $a$, then add $1$ to the weight to penalize each additional edge in the solution, i.e.\n\n\nThis does not work for all values of $a$; $a$ needs to be at least $x$ for this to work. If $a$ is not this minimum number, it might not choose the shortest path. How do I find this minimum value $x$?\n\nPs. This was done recreationally, I'm done with homework long ago.\n\n  \u2022 $\\begingroup$ If two paths have an equal weight, the one with the fewest edges should be chosen. Sorry. I see that I did not make that clear. $\\endgroup$ \u2013\u00a0The Unfun Cat Oct 5 '12 at 19:16\n  \u2022 $\\begingroup$ You could also do it by adding $\\epsilon$ to all edge weights, where $\\epsilon < m/e$, m = minimum edge weight, e = number of edges in shortest path (or even overall, if you don't know the shortest path length). $\\endgroup$ \u2013\u00a0BlueRaja - Danny Pflughoeft Oct 5 '12 at 20:04\n  \u2022 $\\begingroup$ Interesting tidbit, thanks. Will have to look at it. $\\endgroup$ \u2013\u00a0The Unfun Cat Oct 5 '12 at 20:05\n\nGiven a graph $G = (V,E,w)$, we define $G'=(V,E,w')$ with $w'(e) = aw(e) + 1$ where $a = |E| + \\varepsilon$ for some $\\varepsilon \\geq 0$ as proposed in the comments of the question.\n\nLet $P$ a path in $G$ with cost $C$, i.e. $w(P)=C$. Then, $P$ has cost $aC + |P|$ in $G'$, i.e. $w'(P) = aC + |P|$.\n\nThe lemma follows directly from the definition of $w'$.\n\nCall the result of Dijkstra on $G'$ $P$, which is a shortest path in $G'$. Assume $P$ was not a shortest path with fewest edges (among all shortest paths) in $G$. This can happen in one of two ways.\n\n  1. $P$ is not a shortest path in $G$.\n    Then, there is a path $P'$ with $w(P') < w(P)$. As $|P|,|P'| \\leq |E| \\leq a$, this implies that also $w'(P') < w'(P)$ with above lemma\u00b9. This contradicts that $P$ was chosen as shortest path in $G'$.\n  2. $P$ is a shortest path but there is a shortest path with fewer edges.\n    Then, there is another shortest path $P'$ -- i.e. $w(P) = w(P')$ -- with $|P'| < |P|$. This implies that $w'(P') < w'(P)$ by above lemma, which again contradicts that $P$ is a shortest path in $G'$.\n\nAs both cases have led to a contradiction, $P$ is indeed a shortest path with fewest edges in $G$.\n\nThat covers one half of the proposition. What about $a < |E|$, i.e. $a = |E| - \\varepsilon$ with $\\varepsilon \\in (0,|E|)$?\n\n  1. Actually, we also need that $a$ or all weights in $G$ are integers. Otherwise, $w(P') < w(P)$ does not cause the weights in $G'$ to be at least $|E|$ apart. This is not a restriction, though; we can always scale $w$ with a constant factor so that all weights are integer, assuming we start with rational weights.\n  \u2022 $\\begingroup$ I haven't yet been able to come up with a proof that $a = |E|$ is the smallest $a$ for which this works. I'll give it some more thought. $\\endgroup$ \u2013\u00a0Raphael Oct 7 '12 at 22:17\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/47636/prompt-with-pre-populated-minibuffer-input/47642\nText:\nI need to prompt user for input, but I also would like to prepend the user's minibuffer input with a string. e.g.:\n\n  \u2022 user runs my function\n  \u2022 after the prompt, the text awesome (hardcoded string) is automatically inserted in the minibuffer\n  \u2022 user can start typing and it simply appends what she types to awesome, which is already there\n  \u2022 user types bananas, presses RET, the value returned is awesome bananas\n\nUser should also be able to modify awesome part of the string. For example one may chose to send bad bananas instead.\n\nCan someone help me to achieve that? I've tried with completing-read, but can't get it right.\n\n\nI think what you need is (read-string \"input: \" \"awesome\").\n\n  \u2022 I don't have a read-input function, I think you meant read-string. \u2013\u00a0Omar Feb 6 at 2:13\n  \u2022 1\n    It looks like read-input is obsolete, and read-string is preferred. I updated the answer. Thanks for noting it! \u2013\u00a0John Kitchin Feb 6 at 2:52\n  \u2022 Exactly what I needed. Thanks John! \u2013\u00a0iLemming Feb 6 at 18:48\n\nI think you're asking how you can tell completing-read to insert some text in the minibuffer by default, so you can append some more text that you type, to have the returned value be the result of the append.\n\nThat is, I don't think you're asking about prepending awesome to the prompt, but rather appending it to the prompt. I think you're saying that you want it to be part of the returned value (by default, i.e., if the user doesn't erase it), not part of the prompt. (I've edited your question along those lines. If I guessed wrong then please reject the edit.)\n\n(completing-read \"My prompt: \" '(\"awesome blue\" \"awesome red\" \"some\" \"other\")\n                 nil nil \"awesome \" nil \"a default, if you want it\")\n\nThe initial input is the 5th arg. The 3rd arg is nil, so you can enter anything you like - it need not match any of the completion candidates. C-h f completing-read tells you:\n\ncompleting-read is a built-in function in C source code.\n\n\nRead a string in the minibuffer, with completion.\n\nPROMPT is a string to prompt with; normally it ends in a colon and a space.\n\nCOLLECTION can be a list of strings, an alist, an obarray or a hash table. COLLECTION can also be a function to do the completion itself.\n\nPREDICATE limits completion to a subset of COLLECTION.\n\nSee try-completion, all-completions, test-completion, and completion-boundaries, for more details on completion, COLLECTION, and PREDICATE. See also Info node (elisp)Basic Completion for the details about completion, and Info node (elisp)Programmed Completion for expectations from COLLECTION when it\u2019s a function.\n\nREQUIRE-MATCH can take the following values:\n\n  \u2022 t means that the user is not allowed to exit unless the input is (or completes to) an element of COLLECTION or is null.\n\n  \u2022 nil means that the user can exit with any input.\n\n  \u2022 confirm means that the user can exit with any input, but she needs to confirm her choice if the input is not an element of COLLECTION.\n\n  \u2022 confirm-after-completion means that the user can exit with any input, but she needs to confirm her choice if she called minibuffer-complete right before minibuffer-complete-and-exit and the input is not an element of COLLECTION.\n\n  \u2022 anything else behaves like t except that typing RET does not exit if it does non-null completion.\n\nIf the input is null, completing-read returns DEF, or the first element of the list of default values, or an empty string if DEF is nil, regardless of the value of REQUIRE-MATCH.\n\nIf INITIAL-INPUT is non-nil, insert it in the minibuffer initially, with point positioned at the end. If it is (STRING . POSITION), the initial input is STRING, but point is placed at zero-indexed position POSITION in STRING. (Note that this is different from read-from-minibuffer and related functions, which use one-indexing for POSITION.) This feature is deprecated--it is best to pass nil for INITIAL-INPUT and supply the default value DEF instead. The user can yank the default value into the minibuffer easily using M-n.\n\nHIST, if non-nil, specifies a history list and optionally the initial position in the list. It can be a symbol, which is the history list variable to use, or it can be a cons cell (HISTVAR . HISTPOS). In that case, HISTVAR is the history list variable to use, and HISTPOS is the initial position (the position in the list used by the minibuffer history commands). For consistency, you should also specify that element of the history as the value of INITIAL-INPUT. (This is the only case in which you should use INITIAL-INPUT instead of DEF.) Positions are counted starting from 1 at the beginning of the list. The variable history-length controls the maximum length of a history list.\n\nDEF, if non-nil, is the default value or the list of default values.\n\nIf INHERIT-INPUT-METHOD is non-nil, the minibuffer inherits the current input method and the setting of enable-multibyte-characters.\n\nCompletion ignores case if the ambient value of completion-ignore-case is non-nil.\n\nSee also completing-read-function.\n\nYou'll notice that it tells you that parameter INITIAL-INPUT is deprecated. That's nonsense, IMHO. That just reflects someone's preference for not using it, as a user-interface style. If you want input inserted initially, that's what it's for. Whoever deprecated it is really just telling you that you shouldn't want input inserted initially. If you want it then do it.\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/98596/check-if-two-items-are-equal-after-replacing\nText:\nLet's say that an item is either a natural number or a list of items. Examples of items are:\n\n  \u2022 1\n  \u2022 [2]\n  \u2022 [4, [3, 1], 3, 4]\n\nA rule states that two items are equal. For example:\n\n  \u2022 1 = 2\n  \u2022 3 = [3, 1]\n  \u2022 [4, 3] = [1, 5]\n\nWhen using these example rules, we can transform [4, [3, 2]] into [4, [3, 1]] into [4, 3] into [1, 5] and we can say that [4, [3, 2]] equals [1, 5].\n\nI want to find an algorithm that, given items $a$ and $b$ and a finite set of rules, determines if $a = b$.\n\nI already thought of an algorithm that works in some cases. But I hope to find an efficient algorithm that works in all cases. It would also be nice if the algorithm can detect $a \\not= b$ instead of infinitely searching for ways to let $a = b$. Is this a known problem? Any help is appreciated.\n\nNote: We can simplify the problem by only allowing the number 1 instead of every natural number. This is equivalent, because we can transform 1 into [1], 2 into [1, 1], 3 into [1, 1, 1], etcetera.\n\n  \u2022 1\n    $\\begingroup$ This looks like the decision problem for the theory of equality with uninterpreted functions, from smt (arrays here being function calls). However, I don't know of any nice explanation of how to solve it quickly, beyond using Union Find. $\\endgroup$ \u2013\u00a0Curtis F Oct 15 '18 at 1:25\n  \u2022 1\n    $\\begingroup$ @CurtisF The underlying problem is about function calls. I thought this would be an easier way to display the problem. $\\endgroup$ \u2013\u00a0Paul Oct 15 '18 at 2:15\n  \u2022 $\\begingroup$ @Paul, if this question comes from a book or a paper, can you add a reference? If it comes back your personal thinking, any background or motivation? It would be great for you to add those information in the question, which should motivate and help people to tackle this question more and better. $\\endgroup$ \u2013\u00a0Apass.Jack Oct 23 '18 at 3:29\n\nI found a solution to my problem. Let's look at the simpler but equivalent problem in which an item is recursively defined as an empty list or a list of items. I'll summarize the algorithm.\n\n\n  \u2022 Int counter starting at 0\n  \u2022 Hash map: list of integers $\\to$ integer. The integers represent equivalence classes.\n\nFunction find(item) $\\to$ int:\n\nFinds the equivalence class of an item. Recursively call find on all the children of item. Now you have a list of ints. If this list of ints is contained in the hash map, return the corresponding value. If not, add the list to the hash map with the counter as value. Increase the counter and return the value.\n\nFunction merge(int a, int b):\n\nMerges two equivalence classes a and b. In the hash map, replace all occurences (both in keys and in values) of a by b. Now it can happen that one key is mapped to multiple values. If that happens, again merge those values. Repeat this until every key maps to a unique value.\n\n\nFor every rule c = d, call merge(find(c), find(d)). Then to see if a = b, check if find(a) = find(b).\n\n  \u2022 2\n    $\\begingroup$ \"Finds the equivalence class of an item\". There are infinitely many elements in an equivalence class. $3 =[3, 1] = [[3,1],1] = [[[3,1],1]]=\\cdots$. Have you handled them all? $\\endgroup$ \u2013\u00a0Apass.Jack Oct 23 '18 at 23:28\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/202755/independent-permutation-symmetry-of-a-tensor-using-tensorsymmetry-command\nText:\nSuppose I have this tensor $A_{ijkl} = \\epsilon_{ik} \\epsilon_{jl}+\\epsilon_{il} \\epsilon_{jk}$. Now I want to find all the independent permutation symmetries of the indices of this tensor. The answer is $(ij)$,$(kl)$,$(ik)(jl)$, where by $(ij)$ I mean the tensor is symmetric under the permutation of $i,j$. Similarly $(ik)(jl)$ represents the multiplication of two disjoint cycles.\n\nI am very new to computation and I want to implement this in Mathematica. Here's what I tried:\n\nss = TensorProduct[LeviCivitaTensor[2], LeviCivitaTensor[2]]; A = ss + TensorTranspose[ss, {Cycles[{{2, 4}}], 1}]; TensorSymmetry[A] \n\nThis yields the result:\n\n{{Cycles[{{2, 4}}], 1}, {Cycles[{{1, 2}, {3, 4}}], 1}, {Cycles[{{1, 2, 3, 4}}], 1}}\n\nWhich when translated back into my notation reads $(kl)$, $ (ik) (jl) $ and $(ikjl)$, but we can see that the results are not simplified. For example we can use $ (ik) (jl) $ to simplify $(ikjl)$ as follows:\n\n$ (ikjl) = (ikj) (jl) = (jik) (jl) = (ji) (ik) (jl)$\n\nSo $(ijkl)$ when used with $(ik)(jl)$ reduces to $(ij) \\equiv (ji)$ as wanted. I want to do this simplification using Mathematica, in other words I want Mathematica to use all the cycles in the list to reduce it to a simplified and independent one. Could someone please help me to implement this? Thanks in advance. On a side note I find manipulating symbolic tensors in Mathematica very difficult. Suggestion for packages that helps this kind of calculation is much appreciated. I know there exists packages like Ricci which are dedicated for GR related calculations, I want something more simple and accessible for tensor analysis.\n\n\nI don't think your TensorProduct expression agrees with your notation. If you correct the definition of A you get your desired symmetries:\n\nA = TensorTranspose[TensorProduct[LeviCivitaTensor[2],LeviCivitaTensor[2]],{1,3,2,4}] + \n\n\n{{Cycles[{{3, 4}}], 1}, {Cycles[{{1, 2}}], 1}, {Cycles[{{1, 3}, {2, 4}}], 1}}\n\n  \u2022 $\\begingroup$ Thank you for your answer, but if we take a more complicated example Mathematica does not simplify as pointed out, for example take 3 epsilon tensor direct product ordered as {1,2,3,4,5,6}. Mathematica gives you as one of the Tensor symmetries this: (135)(246), which using others could be simplified to (15)(26). $\\endgroup$ \u2013\u00a0Sudhakantha Girmohanta Jul 27 at 3:54\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1189169/find-a-branch-of-log-2z-1-that-is-analytic-at-all-points-in-the-plane\nText:\nFind a branch of $\\log (2z - 1)$ that is analytic at all points in the plane except those on the following rays\n\na) {$x + iy : x \\leq \\frac{1}{2}, y = 0$}\n\nDefinition: $F(z)$ is said to be a branch of a multiple valued function $f(z)$ in a domain $D$ if $F(z)$ is single valued and continuous in D and has the property that, for each $ z$ in $D$, the value $F(z)$ is one of the values of $f(z)$\n\nCan someone please help me start this problem? I don't how to start, and there are no examples in the book. I would really appreciate it . Thanks\n\n\nThe best idea is probably to substitute variables, and investigate what happens to the given ray after the substitution:\n\nLet, for example, $w=u+i\\cdot v=2z-1=2(x+i\\cdot y)-1$. Then we get that $z\\in \\mathbb{C}\\setminus(-\\infty,1/2]\\Leftrightarrow w\\in \\mathbb{C}\\setminus(-\\infty,0]$.\n\nNow, by definition, $\\log(w)=\\ln|w|+i\\cdot \\arg(w)$. Thus you should only investigate the argument. Basically, what we want to avoid is to have an argument branch that is continuous when $\\Re(w)=u<0$.\n\nLet us therefore create a branch for $\\arg$, which we will call $\\tilde\\arg$. We define this branch by $\\tilde\\arg(w):=\\theta(w)$, where $\\theta$ is a continuosly varying argument for $w$ on one of the intervals $(-\\pi+2n\\pi,\\pi+2n\\pi)$, $n\\in \\mathbb{Z}$. This means that $\\tilde\\arg(w)$ is continuous for all $w\\notin (-\\infty,0]$.\n\nThus, we define the suitable branch of $\\log$ with $\\tilde\\log(w):=ln|w|+i\\cdot \\tilde\\arg(w)$. As the argument now varies continuously, this branch of the logarithm is now analytic on the desired set.\n\nAn example of a branch that works in this case is the principal branch of $\\log$, which has an argument varying continuosly between $(-\\pi,\\pi)$.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/598091/deriving-diff-b-w-angles-of-minute-and-hour-hands-11m-2-30h\nText:\nI encountered this formula, $x=\\frac{11m}2-30h$, where x is the angle between the minute hand and hour hand of a clock. m being minutes and h being hours. Ex- at 3:20, m=20 and h=3, so, x=20 degree from the above formula. It's a very handy formula. But I wonder how to derive it.\n\nI see that minute hand makes 6 degrees in 1 minute and hour hand makes half degree. So, the difference in their angles after m minutes will be $\\frac{11m}2$. But from where did we get 30h?\n\n\nAs the hour hand, in $1$ minutes rotates $\\displaystyle\\frac12^\\circ,$\n\nSo, in $h$ hour $m$ minute $\\displaystyle =60h+m$ minute it will rotate $\\displaystyle \\left(\\frac{60h+m}2\\right)^\\circ=\\left(30h+\\frac m2\\right)^\\circ$\n\nSimilarly, in $h$ hour $m$ minute the minute hand will rotate $\\displaystyle 6(60h+m)^\\circ\\equiv 6m^\\circ\\pmod{360^\\circ}$ assuming $h$ to be some integer\n\nNow find the difference\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3188325/in-how-many-ways-can-7-women-10-men-sit-at-table-such-that-no-woman-sits-beside\nText:\nWe have $7$ women and $10$ men; they sit at a table. I've been trying to solve how many ways can they sit excluding the case of women sitting next to each other.\n\nMy reasoning was the following: I will have to alternate woman and men to certain extent so that no woman will sit next to another woman. The possible alternations are the following cases:\n\n$a)$ One of $7$ woman takes the first sit; one of $10$ men take the second; one of $6$ remaining women take the third; one of $9$ remaining men take the fourth, etc. So I have $10*7*9*6*8*5*7*4*6*3*5*2*4*1=10!7!$ possibilties.\n\n$b)$One of $10$ men takes the first place; one of $7$ woman the second; etc. Again, $10!7!$ possibilities, but the order has changed.\n\nIn either case, I have $3$ men remaining. Let's call $A$ and $A'$ the selections of alternated men and woman that I described on points $a)$ and $b)$, and $S$ the selection of the three remaining men. The first man of $S$ is any of the three remaining; the second man of $S$ is any of the two remaining; the last one is the one that's neither of the previous two. So I have for $S$ $3*2*1=3!$ cases.\n\nSo my posibilities are that $A$ is the case or $A'$ is the case, and $P$. Which leaves me with $(10!7!+10!7!)*3!$ posibilities.\n\nIs my reasoning okay? With this type of problems it troubles me how hard it is to actually test or check if one's answer is right. (Excuse any error on my english, it's not my native language.)\n\n  \u2022 1\n    $\\begingroup$ Is the table round? $\\endgroup$ \u2013\u00a0Dbchatto67 Apr 15 '19 at 5:45\n  \u2022 $\\begingroup$ Yes, sorry I forgot to say this. $\\endgroup$ \u2013\u00a0lafinur Apr 15 '19 at 14:06\n\nYour result is correct. More generally, assume that there are $m$ men and $w$ women with $m\\geq w\\geq 1$. Number the $m+n$ chairs around the circular table from $1$ to $m+n$ and let the \"oldest\" woman sit down at the $1$-st chair. In our final arrangement, let $x_i$ be the number of men between the $i$-th woman and the next one. Then $$x_1+x_2+\\dots +x_w=m$$ where each $x_i$ is a positive integer. The number of solutions of this equation is $\\binom{m-1}{w-1}$ (see stars-and-bars). Each solution tells us which chair goes to a man or to a women. Now we have $(w-1)!$ ways to place the remaining $w-1$ women and $m!$ ways to place the $m$ men. Therefore the number of arrangements is $$\\binom{m-1}{w-1}(w-1)!m!=\\frac{(m-1)!m!}{(m-w)!}.$$ For $m=10$ and $w=7$ the above formula gives $$\\frac{9!\\cdot 10!}{3!}=219469824000$$ which coincides with your result $(10!7!+10!7!)3!$.\n\n  \u2022 1\n    $\\begingroup$ I really didn't expect my result to be correct, haha. Well, surprises come in life! Thank you very much, Robert, for your assistance! $\\endgroup$ \u2013\u00a0lafinur Apr 15 '19 at 14:10\n\nRobert Z has provided a nice solution. Here is another approach.\n\nSuppose Edward is one of the men. We will use him as a reference point. Seat Edward first. Once Edward has been seated, there are $9!$ ways to seat the remaining men as we proceed clockwise around the table. This creates ten spaces in which we can place the women, one to the left of each of the ten men. To ensure that the women are separated, we choose seven of these ten spaces in which to place a woman. The women can be arranged in those spaces in $7!$ ways. Hence, the number of admissible arrangements is $$9!\\binom{10}{7}7!$$ For $m$ men and $w$ women, a similar argument yields $$(m - 1)!\\binom{m}{w}w!$$ which is equal to zero when $w > m$, as we would expect.\n\n  \u2022 $\\begingroup$ +1. For OP, the number of ways to arrange $10$ men around the table is a circular permutation: $P_{10}=(10-1)!=9!$. $\\endgroup$ \u2013\u00a0farruhota Apr 15 '19 at 11:33\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/59948/project-to-nearest-point-in-convex-polytope\nText:\nIs there a reasonably efficient algorithm for the following task?\n\nInput: a point $x \\in \\mathbb{R}^d$; a convex polytope $\\mathcal{C} \\subseteq \\mathbb{R}^d$\nFind: a point $y \\in \\mathcal{C}$ that is as close to $x$ as possible\n\nAssume that $\\mathcal{C}$ is specified by a collection of linear inequalities, that the dimension $d$ is fairly high, and \"close\" is measured using $L_2$ distance, i.e., we want to minimize $||x-y||_2$. is there an efficient algorithm for this problem?\n\nI can see how to solve this in polynomial time using linear programming if \"close\" were measured using $L_1$ or $L_\\infty$ distance, but I'm more interested in the $L_2$ distance metric. I keep thinking there might be some algorithm based on identifying the set of inequalities that are violated by $x$ and then doing something, but I can't quite put together a working algorithm.\n\nI found the following paper which describes an algorithm (exponential-time in the worst case but often efficient, like the simplex method):\n\nPhilip Wolfe. Finding the Nearest Point in a Polytope. Mathematical Programming, vol 11, 1976, pp.128--149.\n\nHowever, that paper requires $\\mathcal{C}$ to be presented as a list of vertices rather than a list of inequalities, so it can't be used for my problem. (Converting from inequalities to a set of vertices will cause an exponential blowup; typically the number of vertices is exponential in the number of inequalities.)\n\n\nA quadratic program is an optimization problem where the goal is to minimize $y^T Q y + c^T y$ subject to $A y \\leq b$. If $Q$ is positive definite, then this is a convex quadratic program and we can solve this problem in polynomial time using several methods, one being the ellipsoid method (originally due to Kozlov, Tarasov and Khachiyan\u00a0[1]).\n\nWe can write $\\|y - x\\|_2^2$ as $y^Ty - 2x^Ty + x^Tx$. Thus an equivalent problem is $$ \\min_y\\ (y^Ty - 2x^Ty) \\text{ such that } A y\\leq b. $$ This is a convex quadratic program, since in this case $Q$ is the identity matrix, which is positive definite.\n\n[1] The polynomial solvability of quadratic programming, USSR Computational Mathematics and Mathematical Physics, 20(5):223\u2013228, 1980; Science Direct\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1926519/dead-of-winter-probability-of-avoiding-death\nText:\nIn the board game Dead of Winter, certain actions a player can take result in rolling a 12-sided die. On one face of the die, there's a tooth, representing instant death by zombie. Two faces of the die result in a frostbite wound, and three faces of the die result in a regular wound. Half the time one rolls the die, there is no e ffect. Suppose the game calls for a player to roll the die three times in a row. Assume that if a tooth is rolled, death occurs and no further rolls are made. Assume also that if three wounds of any kind are rolled, death occurs. What is the probability that a player rolling the die three times escapes death?\n\nI tried (11/12)(11/12)(6/12), but I don't think that this accounts for the order of the die. For example, if I rolled a non-wound on the second roll, wouldn't that change my third probability?\n\n  \u2022 1\n    $\\begingroup$ frost bite = regular wound in this exercise ? $\\endgroup$ \u2013\u00a0marmouset Sep 14 '16 at 13:06\n\nFirst of all, you must avoid that tooth three times running. The probability of that is $\\left(\\frac {11}{12}\\right)^3$.\n\nNow, let's suppose that you have dodged the tooth. That means that each of your three rolls is one of the other eleven options. Five of these are wounds, though, and you mustn't get three of those. What is the (conditional) probability of getting three of those? Well, it's $\\left(\\frac {5}{11}\\right)^3$. Therefore the conditional probability that you don't get three wounds is $1-\\left(\\frac {5}{11}\\right)^3$.\n\nAs you need both things to occur the final answer is $$\\left(\\frac {11}{12}\\right)^3\\times\\left(1-\\left(\\frac {5}{11}\\right)^3\\right)=0.697916667$$\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from http://mathfactor.uark.edu/2009/12/morris-follow-up-trieltruelwhatever/\nText:\nMorris: Follow Up: Triel/Truel/Whatever\n\n\n\n\nJeff suggested that they might all choose not to shoot at each other and it would go on forever. \u00a0This made me think about the logic. \u00a0I\u2019m going to say that someone shoots at someone at some point and everyone knows this. \u00a0So everyone knows that if they shoot to miss then one of the others will shoot to hit at some point.\n\nIf anyone shoots to hit then they will shoot at the best shot. \u00a0If they hit they will be in two-man duel and would prefer to be against the worst shot possible.\u00a0\n\nSo\u00a0Fran\u00e7ois\u00a0knows that no-one will shoot at him. \u00a0Xavier knows that one of the others will shoot at him. \u00a0\n\n\nFran\u00e7ois\u00a0has two options, he can shoot at Xavier or he can shoot to miss.\n\nIf he hits Xavier he will be in a two man dual with JC shooting first, he only has a one in five chance of surviving the first shot so his chance of survival is less than 1/5.\n\nIf\u00a0Fran\u00e7ois\u00a0shoots to miss he knows that the other two will shoot at each other, if they choose to shoot to hit. \u00a0So at some point JC or Xavier will kill the other. \u00a0At this point\u00a0Fran\u00e7ois\u00a0will be in a two man duel with himself shooting first. \u00a0This gives him at least a fifity/fifty chance.\n\nSo\u00a0Fran\u00e7ois\u00a0shoots to miss.\n\n\nXavier and JC know this. \u00a0They know they are effectively in a two man duel with each other. \u00a0They therefore shoot at each other.\n\n\nThat sorts out the strategy, what about the probabilities?\n\n\nLet\u2019s consider JC first. \u00a0There is a fifty/fifty chance that Xavier or JC will shoot first. \u00a0JC\u2019s only chance is to shoot first and hit. \u00a0The chance is 1/2 x 4/5 = 2/5.\n\nSo 2/5 of the time JC will face\u00a0Fran\u00e7ois\u00a0with Francois shooting first. \u00a0\n\nLet\u2019s say that the chance that\u00a0Fran\u00e7ois\u00a0wins is f. \u00a0He has a 1/2 chance of killing JC with his first shot. \u00a0There is a 1/2 x 1/5 = 1/10 chance that both miss with their first shot, we are back to the starting position so the probability of\u00a0Fran\u00e7ois\u00a0surviving is now f again.\n\nThe chance of\u00a0Fran\u00e7ois\u00a0surviving is f = 1/2 + 1/10 f. \u00a0This gives 9/10 f = 1/2 and f = 5/9. \u00a0The chance of\u00a0Fran\u00e7ois\u00a0surviving is 5/9. \u00a0The chance of JC surviving is 4/9.\n\n\nThis gives JC a total survival chance of 2/5 x 4/9 = 8/45.\n\n\nNow consider Xavier. \u00a0He has a 3/5 chance of facing\u00a0Fran\u00e7ois\u00a0with\u00a0Fran\u00e7ois\u00a0shooting first.\n\nHis chance of surviving is 1/2, the chance that\u00a0Fran\u00e7ois\u00a0misses.\n\nHis total survival chance is 3/10.\n\n\nFinally Francois\u2019 chance of surviving is 2/5 x 5/9 + 3/5 x 1/2 = 2/9 + 3/10 = 47/90.\n\n\nSo the probabilities of being the last man standing are: \u00a0Fran\u00e7ois\u00a047/90; Xavier 3/10 and JC 8/45.\n\n\nAmazingly the worst shot has the best chance of survival!\n\n\nRSS feed for comments on this post \u00b7 TrackBack URL\n\nLeave a Comment\n\nYou must be logged in to post a comment.\n\nThe Math Factor Podcast Website\n\n\nA production of the University of Arkansas, Fayetteville, Ark USA\n\nDownload a great math factor poster to print and share!"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/80860/maximisation-of-graphs-weight/80863\nText:\nI have a graph related problem. Let $G$ be an undirected weighted graph of $N$ nodes. I want to find $p$ independent (they have no edge linking them) sub-graphs of $m$ nodes in a way that the total weight is maximized.\n\nFor example, let $G$ be a graph of $16$ nodes, I want to find $4$ sub-graphs of $4$ nodes with $w_1, w_2, w_3, w_4$ as their weights (sum of the weights on the subgraph's edges) I want to determine the $4$ subgraphs that will maximize $w_1+w_2+w_3+w_4$.\n\nIs this a classic graph problem? Is there already an algorithm for this? I am not very experienced with graphs and my research on the net was only confusing. Any ideas on how to approach this?\n\nThank you for your help\n\n\nIt is definitely not a classic graph problem such as the shortest path, maximum-flow, or graph coloring problem. But your problem, in its general form, seems to solve the Independent set problem, which is $NP$-complete.\n\nAssume that you have a polynomial time algorithm $A(G,m,p)$ solving this problem. Then take $m=1$ and call $A(G,1,p)$ for $p=N,N-1,...,2,1$ (at most $N$ times) until you find a solution. When $m=1$, each subgraph has only one node and so its weight is 0, which is maximum for a single node graph. Furthermore, these nodes are not connected by an edge, and so they are not adjacent, i.e. they are independent.\n\nIf this procedure finds a solution for the maximum $p$ less than $N$, then this means we have a maximal independent set, since we have exactly $n$ nodes (subgraphs) with no edges between them, i.e. independent.\n\nOnce your problem is $NP$-complete, you could try any approximation algorithm including Linear or Integer programming.\n\n  \u2022 $\\begingroup$ Thank you for answering. What if my m is not a variable of the algorithm and it is a fixed value since the beginning. would this affect the NP-completeness of the prob? $\\endgroup$ \u2013\u00a0user76838 Sep 8 '17 at 11:25\n  \u2022 $\\begingroup$ Fixing only $m$ does not affect NP-completeness of the problem. Even when we fix $m$ to $1$, we can solve the Independent set. $\\endgroup$ \u2013\u00a0fade2black Sep 8 '17 at 21:45\n  \u2022 $\\begingroup$ Decision version of problem is trivially in $\\mathsf{NP}$. $\\endgroup$ \u2013\u00a0rus9384 Sep 8 '17 at 22:35\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/76758/count-of-distinct-substrings-in-string-inside-range\nText:\nHaving string $S$ of length $n$, finding the count of distinct substrings can be done in linear time using LCP array. Instead of asking for unique substrings count in whole string $S$, query $q$ containing indexing $(i,j)$ where $0 \\le i \\le j < n$ is asking for count of distinct substring inside given query range for string $S[i..j]$.\n\nMy approach is just applying linear time construction of LCP array to each query. It gives complexity $O(|q|n)$. Number of queries could raise to order of $n$ so answering all queries makes it $O(n^2)$.\n\nCan it be done better, than linear time for every query?\n\nIn general, if one process substring of string for which we already have suffix array, suffix tree, lcp array, are those structures not relevant anymore, and must be build from scratch again?\n\n  \u2022 $\\begingroup$ The size of input and output seem to be natural lower bounds. $\\endgroup$ \u2013\u00a0Raphael Jun 14 '17 at 5:59\n  \u2022 1\n    $\\begingroup$ I don't have time to think about this, but it's quite standard to build segment trees out of these complex structures (in competitive programming), maybe it's the case for suffix arrays/trees/etc. You just have to be clever in defining a fast \"combine\" operation (which will be used for a father node with his children, or at the end to combine the results of all the leaves covering your interval). $\\endgroup$ \u2013\u00a0md5 Jun 14 '17 at 8:44\n  \u2022 $\\begingroup$ The number of queries is the number of ordered pairs $i, j$ which is $(n*(n+1))/2$, so the complexity should be $O(n^3)$ $\\endgroup$ \u2013\u00a0user11171 Jul 3 '18 at 22:45\n  \u2022 $\\begingroup$ @md5 I don't think a segment tree (or fenwick tree) based solution will work because the number of substrings lacks additive inverse. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 16:27\n\nThe question does not motivate the number of queries being $O(n)$, which seems an arbitrary worst case since the number of unique possible queries is the number of ordered pairs and thus $O(n^2)$.\n\nHere are two different solutions with better time complexity for the $O(n^2)$ case based on (implicit) suffix trees constructed incrementally with Ukkonen's algorithm. Both solutions are based on preprocessing and have complexity $O(n^2 + |Q|)$ where $Q$ is the set of queries. The second solution runs in $O(n + |Q|)$ if all queries have the same width.\n\nSolution 1 - Preprocess all unique queries\n\nIterate over the suffixes of $S$. For each suffix $S_i=S[i..n]$, build the suffix tree of $S_i$ with Ukkonen's algorithm. After update $j$ to the current suffix tree, store the tree size in a matrix at position $(i,i+j-1)$. A query for the range $[x,y]$ is answered by the matrix element at $(x,y)$.\n\nSuffix tree size can be stored along with the suffix tree and updated in constant time at each step by modifying the update procedure in Ukkonen's algorithm. For each update the size increases by the current number of leaves.\n\nSolution 2 - Preprocess unique query widths\n\nThis solution is harder to implement but requires less preprocessing work if there are few query widths. Preprocessing takes $O(n)$ time if there is only one query width.\n\nFor each query width $w$, use a sliding window of width $w$ and incrementally build a suffix tree. Remove the suffix starting one character to the left of the window by remove the longest suffix from the tree. At each step, the current number of substrings within the sliding window is the tree size.\n\nAll queries can then be answered in linear time by using the results of the precomputation.\n\nNote: removing the longest suffix can be done by removing the oldest leaf of the suffix tree. It is not easy to implement correctly.\n\n  \u2022 $\\begingroup$ This seems to be a bit off. The task is not to answer all possible $O(n^2)$ queries, but to answer some $q$ given queries. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 11:17\n  \u2022 $\\begingroup$ I answered the question for the general case, which was the point of the question. In the special case where the number of queries is low, the solution proposed by the question author would run faster in practice. The number of outputs of a valid solution is $q$, which is of size $O(n^2)$ (disregarding duplicate queries), so any possible solution must run in $O(n^2)$ or slower. My proposed solution takes time $O(n^2)$ for preprocessing and then each query can be answered in constant time. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 15:10\n  \u2022 $\\begingroup$ Again, $q$ is a parameter. The question is explicitly interested in the number of queries $q$ being $\\Theta(n)$, not $\\Theta(1)$ nor $\\Theta(n^2)$. The answer for $q$ queries is of size $\\Theta(q)$ which need not be $\\Theta(n^2)$. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 15:39\n  \u2022 $\\begingroup$ Why would the number of queries be of order $n$? It seems like an arbitrary condition, if not an oversight by the author. $\\endgroup$ \u2013\u00a0user11171 Jul 4 '18 at 15:46\n  \u2022 $\\begingroup$ The whole problem statement is kind of the same degree of arbitrary. However, this is how a typical data structures problem in competitive programming looks like, so it is unlikely that $n^2$ queries are what the OP looks for. I'd bet $n$ and $q$ are independent parameters from $1$ to $100\\,000$ or so, and the time limit is a couple of seconds, so that an $O(nq)$ solution times out, but something better like $O(n \\sqrt q)$ doesn't. $\\endgroup$ \u2013\u00a0Gassa Jul 4 '18 at 15:51\n\nThere is $O(n \\sqrt{n} + |Q| \\sqrt{n})$ offline solution.\n\n  1. Sort elements $(i,j)$ of $Q$ in ascending order of $j$.\n  2. Distribute them into $\\sqrt{n}$ buckets so, that $(i,j)$ goes into bucket number $\\lfloor \\frac{i}{\\sqrt{n}} \\rfloor$.\n  3. For each bucket starting at $b$ and each query $(i,j)$ in it, build a suffix tree for $S[b,j]$.\n  4. For each query in a bucket, remove redundant characters from the left and report the answer.\n\nStep 3 takes $O(n)$ for each bucket, because we use Ukkonen's algorithm and $j$ goes in ascending order.\n\nStep 4 takes $O(\\sqrt{n})$ for each query, because removing $\\sqrt{n}$ longest suffixes from the tree takes $O(\\sqrt{n})$. Note that you can use an indirection layer to avoid modifications to the original suffix tree.\n\n  \u2022 $\\begingroup$ The number of distinct substrings is the number of paths in the suffix tree that start at the root and end at a node with just a single leaf below it, correct? Do you store these path counts explicitly in the notes? If so, then how do you update things when removing the first character in O(1) time? There could be up to $\\sqrt n$ of them (in the case where the first character is unique within the block). If not, how do you compute them on the fly? $\\endgroup$ \u2013\u00a0j_random_hacker Jul 8 '18 at 7:49\n  \u2022 $\\begingroup$ @j_random_hacker Ukkonen's algorithm builds so called implicit suffix tree. Number of distinct substrings is just sum of lengths of its edges (i.e. size of corresponding trie). $\\endgroup$ \u2013\u00a0Dmitri Urbanowicz Jul 8 '18 at 14:14\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/319842/how-many-ways-to-fill-in-a-square-grid-with-certain-restrictions\nText:\nSuppose I have a 5x5 grid of squares. I would like to fill in 15 checkmarks in the squares such that (1) each of the 25 square cells contains at most one checkmark, (2) each row has exactly 3 checkmarks, and (3) each column has exactly 3 checkmarks. How many ways are there to fill in these 15 checkmarks?\n\nMore generally, suppose I have an $n \\times n $ square grid, and I would like to fill in $mn$ checkmarks such that (1) each of the $n^2$ square cells contains at most one checkmark, (2) each row has exactly m checkmarks, and (3) each column has exactly m checkmarks. How many ways are there to do so? If $m=1,$ I think the answer is $n!$. But I am not sure about the general case.\n\nAlso, if I have an additional restriction that no checkmarks on the diagonal, i.e., no checkmark in the (1,1), (2,2),... (n,n) cells. How many ways are there?\n\nThanks very much! Wish all very happy new year!\n\n  \u2022 $\\begingroup$ If you remove the only one checkmark per box requirement then you are looking at the Ehrhart polynomial of the Birkhoff polytope, and get into the Anand-Dumir-Gupta conjecture and related areas. $\\endgroup$ \u2013\u00a0Sam Hopkins Dec 31 '18 at 21:25\n\nWhat you are looking for is the number of matrices in the class $\\mathcal A(n,m)$ of $(0,1)$-matrices that are $n\\times n$ and have each row and column containing exactly $m$ entries equal to $1$. This is a pretty well-studied question, but an exact answer isn't known except in some small cases.\n\nYou are right that for $m=1$, the number is $n!$, as then you are counting the $n\\times n$ permutation matrices. A sort of generalization of this was obtained in\n\nWei, Wan-Di. \"The class $\\mathfrak A(R,S)$ of $(0,1)$-matrices.\" Discrete Mathematics 39, no. 3 (1982): 301\u2013305. Journal link\n\nwhere it is given that the number of such matrices is at least\n\n\nI say it is \u201csort of\u201d a generalization because it is only a lower bound. Again, there is no closed form known for the exact number. I think the most frequently-cited asymptotic results are those of McKay and others, for example see\n\nMcKay, Brendan D., Wang, Xiaoji. \"Asymptotic enumeration of 0-1 matrices with equal row sums and equal column sums.\" Linear Algebra and its Applications. 373 (2003): 273\u2013287. Journal link\n\nand anything that cites it.\n\nThere are other results \u2013 and other asymptotic results \u2013 out there. A good starting point for more details is the book Combinatorial Matrix Classes by Brualdi.\n\nFinally, note that this is the same as counting balanced regular bipartite graphs. For example, your question is the same as this one where the $d_v$ and $d_c$ of that question are taken to be equal. So you may wish to see the answer \u2013 provided by McKay! \u2013 appearing there.\n\n  \u2022 $\\begingroup$ Thanks so much for the very helpful information!! Happy New Year! $\\endgroup$ \u2013\u00a0KPU Jan 1 at 4:25\n\nThe problem amounts to counting binary or $0/1$-matrices with restrictions on row/column sums.\n\nIn general, let the row sums be $r(n)=(r_1,\\dots,r_n)$ and column sums $c(n)=(c_1,\\dots,c_n)$. Obviously, $0\\leq r_i, c_j\\leq n$ for all $i, j$. Further, let $\\mathbf{x}=(x_1,\\dots,x_n)$ and $\\mathbf{y}=(y_1,\\dots,y_n)$ with the multi-exponent notation $\\mathbf{x}^{u}=x_1^{u_1}\\cdots x_n^{u_n}$. Then, there is this generating function $$\\prod_{i,j=1}^n(1+x_iy_j)=\\sum_{r(n),c(n)} N(r(n),c(n))\\mathbf{x}^{r(n)}\\mathbf{y}^{c(n)} \\tag1$$ for the enumeration $N(r(n),c(n))$ of the number of binary matrices with row sums $r(n)$ and $c(n)$.\n\nTo get back to your question, extract the coefficient $N((k,\\dots,k),(k,\\dots,k))$ of $$\\mathbf{x}^{(k,\\dots,k)}\\mathbf{y}^{(k,\\dots,k)}$$ from the above product in (1).\n\n\nYour Answer"}
{"text": "Retrieved from http://metamathological.blogspot.com/2013/07/today-i-learned-its-all-goodstein.html\nText:\nTuesday, 9 July 2013\n\nToday I Learned: It's All Goodstein\n\nI came back from China last Thursday and I've found it surprisingly difficult to restart this blog.\n\nMaybe it's the thought that now that I've finished my semester with my Accelerated Maths tutorial class, I'll no longer have a real human audience for this writing? Or maybe it's just sloth. =P\n\nSo, I was away in China for a little over two weeks. It's summer there and suffocatingly hot and humid.\n\nThe first week or so I spent with my grandfathers: they live in the same apartment building, one floor away from each other. It was good to see that my (paternal) gramps was much healthier looking than the last time that I went back, although his attention span has grown somewhat evanescent. He would sit in his wicker chair, nude from the waist up, brows poised delicately on the fulcrum of furrowedom and unfurrowedness. The clacking of the rotating mechanical fan and his rhythmic laboured breathing lending his countenance an ethereal air. Except when we spoke, I was never sure if he was with me, or dreaming.\n\nAnd the second week I spent in Shanghai. Yea, Shanghai's pretty chill, just not weatherwise. But let's start with the actual journey to China.\n\nMy flight was delayed by half an hour, so I sat in frustration (*) reading Harer and Penner's Combinatorics of Train Tracks. Nearing the original (undelayed) boarding time, I hear some commotion behind me and turn around to have a look: a Chinese girl had approached the metallic security door that you go through to get onto the plan. She was feeling...no...she was...groping every crevice of the door, until a few of the elderly aunties came up to her and told her that boarding had not yet commenced. She seemed content with that answer, strolled back to the waiting area, before swivelling about and running back to the gate, flailing at imaginary buttons that might magically open this door.\n\nThe buttons, they just weren't there.\n\nAnd soon, the Chinese aunties came hobbling towards her once more, and so we saw the repetition of a few more cycles of this explanation/flailing-loop. Throughout this process, the airport staff are struggling to communicate with her, but to no avail. In between their attempts to talk to her, she makes a phone call to her dad (I found this out later), frantically crying out in fumbling, tumbling Chinese: \"I'll listen to you\", \"The steel door is closed. It's closed\" and \"I want to go home; I want to go home; I JUST WANT TO GO HOME\".\n\nI just want to go home.\n\nAt this point the staff are asking for someone to help them translate, and I happily acquiesce, and we independently arrive at the (obvious) conclusion that she is probably a higher-functioning Asperger's syndrome-sufferer (**). Soon, security is called, and as they gently drag her from the security gate, I call out to her and begin explaining to her that I understand her desire to be on the plane since it's nearing 11. At this, she seemed relieved. I then ask if she received the firm instructions that she must be on the plane by 11 from a family member like her mother or her aunt (I didn't know that it was her father at this point) in the hopes that I could convince her to call them again and that I might then explain to them the actual situation (my guess is that she probably miscommunicated to the plane situation, and that perhaps they could give her new instructions). Maybe she was troubled at my line of questioning, maybe I just reminded her of her family and homesickness, but whatever the case she ran off.\n\nImmediately, the security guards asked me to help talk to her, so I race around the crowd, get to her and by the time that I reach her she is in a state of hysteria. She is surrounded by a flock of chanting aunties, and has begun dry-sobbing. I offer her my hands (***), she takes them, and I begin anew my attempt to get her to call her father (by this time I've been informed by someone that it was her father).\n\nShe does (****) calm down.\n\nBut then I'm interrupted by a forceful middle-aged uncle who tells her that she must calm down and a middle-aged lady with an infant in her arm saying \"look, my baby isn't afraid, so you shouldn't be scared either\". And....and...I back away, entrusting them with the situation. And returning to my seat.\n\nI..just walked away. =/\n\nAnd then security took her away.\n\nI mean, fair enough - security was probably always going to take her away; even if I'd managed to get her to contact her father, explain the situation, and have him relay to her new instructions regarding plane boarding, how might the airline staff trust her to behave sufficiently \"normally\" on the long flight back to China? A part of me keeps trying to find ways out - could her father have assigned me as a temporary \"guardian\" on this flight? Indeed, completely ridiculous \"solutions\" like these.\n\nAnd after boarding, the empty seat next to mine on a mostly filled out plane did not help relieve me of these haunting thoughts: I kept wondering if this was her seat, the seat of that poor, crying, sobbing girl flailing herself against the hard, cold, metallic barrier: wanting to go home, but hindered by her own frets and incomprehension.\n\nI guess, as a Christian, there's a parable here - there is, for me, a reminder that often we Christians, Jews and Muslims (worshippers of the same God) struggle and flail and cry and shout to \"go home\", but are stumbled by our own incomprehension. We do not see that Heaven/Paradise is to come to know, love and even befriend the God of the Jews, the Father of Abraham/Ibrahim, the Creator (*****) of the universe. And instead, miss the point.\n\nSo...erm...in remembrance of my inability to communicate with this girl...let's...let's try to communicate beyond the limitation of language. Let's try to do today's maths without words:\n\n  1. \\(\\leadsto 3^0-1=0.\\)\n\\(\\Rightarrow G(1)=1.\\)\n\n  1. \\(\\leadsto 3^1-1=2=2\\cdot 3^0.\\)\n  2. \\(\\leadsto 2\\cdot 4^0-1=1=4^0.\\)\n  3. \\(\\leadsto 5^0-1=0.\\)\n\\(\\Rightarrow G(2)=3.\\)\n\n  1. \\(\\leadsto 3^1+2^0-1=3^1.\\)\n  2. \\(\\leadsto 4^1-1=3=3\\cdot 4^0.\\)\n  3. \\(\\leadsto 3\\cdot 5^0-1=2=2\\cdot 5^0.\\)\n  4. \\(\\leadsto 2\\cdot 6^0-1=1=6^0.\\)\n  5. \\(\\leadsto 7^0-1=0.\\)\n\\(\\Rightarrow G(3)=5.\\)\n\n\\(\\Rightarrow G(4)=\\ldots 7?\\)\n\n  1. \\(\\leadsto 3^3-1=28=2\\cdot 3^2+2\\cdot 3^1+2\\cdot 3^0.\\)\n  2. \\(\\leadsto 2\\cdot 4^2+2\\cdot 4^1+2\\cdot 4^0-1=41=2\\cdot 4^2+2\\cdot 4^1+4^0.\\)\n  3. \\(\\leadsto 2\\cdot 5^2+2\\cdot 5^1+5^0-1=60=2\\cdot 5^2+2\\cdot 5^1.\\)\n  4. \\(\\leadsto 2\\cdot 6^2+2\\cdot 6^1-1=83=2\\cdot 6^2+6^1+5\\cdot 6^0.\\)\n  5. \\(\\leadsto 2\\cdot 7^2+7^1+5\\cdot 7^0-1=109=2\\cdot 7^2+7^1+4\\cdot 7^0.\\)\n  6. \\(\\leadsto 2\\cdot 8^2+8^1+4\\cdot 8^0-1=139=2\\cdot 8^2+8^1+3\\cdot 8^0.\\)\n  1. \\(\\leadsto 384^2+20\\cdot 384-1=155136=384^2+19\\cdot 384+383.\\)\n  1. \\(\\leadsto 0.\\)\n\\(\\Rightarrow n=G(4)=3\\cdot 2^{77}(2^{3\\cdot 2^{77}}-1)+44>10^{100000}.\\)\n\n\n\\(G(6)=???\\Rightarrow\\) $5. =)\n\nNote that this is all made possible thanks to Goodstein's theorem, as in: it's not completely obvious that \\(G(n)\\) is finite for every positive integer \\(n\\). And I'm not the one paying out $5 for computing \\(G(6)\\), it's Ronald Graham.\n\n*: My frustration did not stem from the delay of my flight, it was more because I was stuck on one of the steps in one of their proofs.\n**: May be highly non-pc, but I will call it suffering, and I won't bother justifying myself in this footnote. =/\n***: Let's not romanticise this in the most literal interpretation of \"romanticise\", she was no Rita Leeds.\n****: At least...she does in my memories - which I don't completely trust, although I've written most of this down in a diary, so it should be fairly accurate.\n*****: Whatever creation means.\n\nNo comments:\n\nPost a Comment"}
{"text": "Retrieved from https://blog.flyingcoloursmaths.co.uk/big-lead-can-football-team/\nText:\nA reader asks:\n\nWhat\u2019s the biggest lead a football team can have in the table after $n$ games?\n\nIn a typical football league, teams get three points for a win, one for a draw, and none for getting beat. After, for example, one game, if one team wins and all of the other games are draws, the winners will have three points, while everyone except the team they beat will have one point \u2014 the winners will be two points ahead.\n\nThere\u2019s not a whole lot more to it \u2014 after two games, the biggest possible lead is four points (one team wins both of its games to get six points, and all of the others are draws, leaving everyone else with at most two points). As long as the winning team hasn\u2019t played all of the teams, the biggest lead after $n$ games is $2n$ points.\n\nBut what if they\u2019ve played everyone?\n\nIn a four-team group, it\u2019s possible to have a seven-point lead after three games, rather than just six: if you beat all three of the other teams, you\u2019ll have nine points; if they all draw with each other, they each have two points. Assuming you always win and everyone else always draws, once you\u2019ve played everyone once, you\u2019ll have $3n$ points, and the best of the rest will have $n-1$ points - they\u2019ll have drawn every game except for the one they lost to you - giving you a margin of $3n - (n-1) = 2n+1$.\n\nIn general, if you\u2019ve played everyone at least $m$ times, your biggest possible margin is $2n + m$. So, when Dunfermline beat the other nine teams in Scottish League One four times, and they all draw with each other, they\u2019ll have a lead of $2 \\times 36 + 4 = 76$ points."}
{"text": "Retrieved from https://math.stackexchange.com/questions/1422637/what-is-k-in-fermats-little-theorem/1422647#1422647\nText:\nAccording to Fermat's Little Theorem, for all integer $a$, if $p$ is a prime, then $$a^p \\equiv a \\pmod p$$ In other words, there exists a non-zero integer $k$ such that $$a^p-a=pk$$ Is there a method to determine $k$? I have seen many proofs using the multinomial expansion and/or recurrent analysis but none explicitly mentioned what $k$ is? Any Hints?\n\nEXPLANATION:let me be clearer, let's say, for any 2 integers $a,b$, if $p$ is odd, then $$(a+b)^p\\equiv {a^p+b^p}\\pmod p$$ In other words, there exists $k \\in \\mathbb {Z} \\neq 0$ such that $$(a+b)^p=a^p+b^p+kp$$ In this case using the binomial expansion, it is easy to see that $$k=\\dfrac{\\sum_{k=1}^{p-1}{ n\\choose k}a^{p-k}b^k}{p}$$ I was wondering if there is a similar expression of $k$ in the Fermat's Little Theorem.\n\n  \u2022 4\n    $\\begingroup$ One way to calculate it is to raise $a$ to the power $p$, sutract $a$ from the result, then divide that by $p$. I.e., finding $k$ is not difficult. Fermat's theorem simply proves that it is always an integer. $\\endgroup$ Sep 5, 2015 at 2:49\n  \u2022 6\n    $\\begingroup$ It's $(a^p-a)/p$. What else is there to say? $\\endgroup$\n    \u2013\u00a0whacka\n    Sep 5, 2015 at 2:54\n\n1 Answer 1\n\n\nYou are stating an equivalence between those two statements, namely $$a^p\\,=\\,a\\;(mod\\,p) \\Longleftrightarrow\\,a^p\\,-\\,a\\,=p\\,k$$ This means, that second statement is the definition of $k$.\n\n1)Your example is not different as it is still giving $k$ in terms of the two sides and $p$. Thus it is not a method for calculating $k$ but it's merely re-expressing $k\\,=\\,\\frac{(a+b)^b\\,-\\,(a^p+b^p)}{p}$ differently.\n\nYou could as well write $k=\\frac{a\\,(a^{p-1}-1)}{p}$ for the first relation. Not knowing how $a$ (and $b$ as well in your example) depends on $p$ the best you can do is give a formal expression for $k$ -as you do in your example.\n\n2)If what you want is to still write it in terms of some power series you could argue as follows. Given that $\\sum^{p-1}_{n=0}a^n\\,=\\,\\frac{a^{p}-a}{a-1}$ for $a\\neq1$, then $$k\\,=\\,\\frac{(a-1)\\,\\sum^{p-1}_{n=0}a^n}{p}$$ But this doesn't provide you with a method for calculating $k$ different from directly using its definition.\n\n  \u2022 $\\begingroup$ Please see my edited post. $\\endgroup$\n    \u2013\u00a0user97615\n    Sep 5, 2015 at 14:50\n  \u2022 2\n    $\\begingroup$ Now I'm not sure what you are asking, I have to admit. Initially I thought you were missing something in the definition of congruence, but now I'm thinking you haven't clearly posed a question. If what you want is introduce a power series in the expression of k, I've shown you one way. However, then you should state it clearly in your question what you want and why, that's is, what motives your question. This helps people get your mindset better and provide you with better answers. $\\endgroup$\n    \u2013\u00a0MASL\n    Sep 5, 2015 at 16:26\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2111132/number-of-ways-to-choose-n-objects-from-groups-of-indistinguishable-objects\nText:\nSay I have 5 blue, 6 red, and 7 green balls. How many ways are there to choose 8 balls, without regard to order? My first thought was to just add up all the balls and choose 8 from the collection of 18, but I know that that'll overcount the possibilities, as I can get the same color combination of balls multiple ways by choosing different balls within the same color group. How would I correctly approach this problem?\n\n  \u2022 $\\begingroup$ So all the same color balls are the same? $\\endgroup$\n    \u2013\u00a0S.C.B.\n    Jan 24 '17 at 1:25\n  \u2022 $\\begingroup$ Yep. All balls in the same color group are the same. $\\endgroup$ Jan 24 '17 at 1:29\n\nAny selection can be described as a triple $(b,r,g)$ where $0\u2264b\u22645$, $0\u2264r\u22646$, $0\u2264g\u22647$ and $r+b+g=8$.\n\nAs the numbers involved are small, it's not difficult to work case by case. We'll go through the possible values of $b$.\n\nI. $b=0$. Then $r\u22651$ but any non-zero value of $r$ works so $\\fbox 6$ cases.\n\nII. $b=1$. Now $r$ can be any value from $0$ to $6$ so $\\fbox 7$ cases.\n\nIII. $b=2$ Again we can use any value of $r$ so $\\fbox 7$ cases.\n\nIV. $b=3$. Now $0\u2264r\u22645$ so $\\fbox 6$ cases.\n\nV. $b=4$ Now $0\u2264r\u22644$ so $\\fbox 5$ cases.\n\nVI. $b=5$ Now $0\u2264r\u22643$ so $\\fbox 4$ cases.\n\nFinally the answer is $$6+7+7+6+5+4=\\fbox {35}$$\n\nNote: while the logic is fairly simple, case by case enumeration can be a bit error prone so I suggest checking carefully. As an alternate method you could multiply out the generating functions $$(1+x+x^2+x^3+x^4+x^5)(1+x+\\cdots +x^6)(1+x+\\cdots +x^7)$$ seeking the coefficient of $x^8$.\n\n\nLet's say that we ignore the green balls for now. We have can have between 0 and 5 blue balls and 0 and 6 red balls. So the number of possible pairings of number blue and number red is: $$6 * 7 = 42$$ Now we have to eliminate combinations where we had more than 8 balls so we need to see how far above the target we can get by adding the number of blue (5) and red (6) balls and subtracting the total desired (8). Then we sum the integers from 1 to that answer. This gives us how many of our 42 scenarios are too high. $$5 + 6 - 8 = 3$$ $$\\sum_{n=1}^{3} n = 6$$ $$42 - 6 = 36$$ Then we need to subtract off the bottom where the greens can't get us to 8 which only occurs when we have zero blue and zero red so: $$36 - 1 = 35$$ And thus you have 35 combinations.\n\n\nYour Answer"}
{"text": "Retrieved from http://mathfactor.uark.edu/2009/01/follow-up-differences/\nText:\nFollow Up: Differences\n\nGiven a difference table, as we considered back in EV. What\u2019s the Difference , how do we come up with a polynomial that gives the values on the top row?\n\nFor example, suppose we have\n\n-1     -1     3     35     143     399     899 . . . . .\n      0     4     32    108     256     500  . . . . .\n         4    28    76     148      244  . . . . .\n             24    48     72       96   . . . . .\n                  24     24    24    . . . . .\n\nWhat is the polynomial P(n), of degree four, that gives\n\nP(0) = -1 P(1) = -1 P(2) = 3 P(3) = 35 P(4) = 143 , etc.\n\nCan this be expressed simply in terms of the leading values on the left of the table: -1, 0, 4, 24, 24?\n\nAnd finally, what is the general rule?\n\nWonderfully, beautifully, the answer is, just as tricycle and prunthaban said in the comments:\n\n24 C(n,4) + 24 C(n,3) + 4 C(n,2) + 0 C(n,1) + (-1) C(n,0)\n\nWhere C(n,j) = (n)(n-1)(n-2) \u2026 (total of j terms) / j!\n\nFor example, C(n,4) = n (n-1) (n-2) (n-3) / 4! In the special case when j=0, we set C(n,0)=1.\n\nSo our polynomial here is\n\n(24/4!) (n) (n-1) (n-2) (n-3) + (24/3!) (n) (n-1) (n-2) + (4/2!) (n) (n-1) + (0/1!) (n) + (-1)\n\nThat isn\u2019t very \u201csimplified\u201d, but at least we can see the pattern! If we multiply the whole thing out, we get\n\nP(n) = n4 \u2013 2 n3 + n2 \u2013 1\n\nbut it\u2019s hard to see the connection, in this \u2018simplified\u2019 form, to the original data.\n\nBefore proving that this is correct in general, let\u2019s take a moment to discuss some of the properties of C(n,j), often read \u201cn choose j\u201d. When n is actually a counting number, this really is the number of ways to choose j out of n objects; but we\u2019ve defined things more generally here: n could be a real number, or simply a variable (as in our expression for P).\n\n\n\n\nA key property is that C(n,m) + C(n,m+1) = C(n+1,m+1).\n\nThis is just a matter of algebra:\n\nC(n,m) + C(n,m+1) = (n) \u2026 (n-m+1) / m! + (n) \u2026 (n-m+1)(n-m)/ (m+1)!\n\n= you do this part\n\n= (n+1) (n) \u2026 (n-m+1) / (m+1)! = C(n+1, m+1).\n\n\nThis is precisely why, these are the numbers that fill in Pascal\u2019s triangle: C(n, m) is the mth entry on the nth row.\n\n\n\n\nNow, how hard is our assertion, that our polynomial is the correct one? Not very, really. Suppose we have a difference table with entries on the left ak (on the top row), on down to a0 on the bottom row.\n\nak . . . .\n\n\u00a0ak-1 . . . . .\n\n\u00a0\u00a0\u00a0 . . . . .\n\n\u00a0\u00a0\u00a0\u00a0\u00a0a1 . . . . .\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0a0. . . . .\n\nThen we claim that the jth entry (counting from 0) entries on the ith row (counting up from the bottom 0th row) are given by\n\nPi(j) = a0 C(j,i-0) + a1 C(j,i-1) + . . .\u00a0 + ai C(j,i-i)\n\nTo prove this, we first show it\u2019s true for the bottom row, then the next row up, etc, etc, clicking along like a typewriter from left to right. (This is just induction on i and j)\n\nFor the bottom row, things are pretty easy: all the entries are a0 C(j,0) = a0, so check! Also, on the left of each row, the entry, sure enough is Pi(0) = ai + a1 0 + . . .\u00a0 + ai 0 = ai\n\nsince (C(0,i) = 0, unless i=0 also\u2013 try it!)\n\nSuppose we\u2019ve walked all the way up the spot we care about, on the ith row, jth position. When we get there we will have proven our formula is correct for all the entries below, and for all the entries to the left.\n\nIn particular, when we reach the ith row, jth position, we know that (a) the formula is correct for the entry to the left, and (b) the formula is correct for the entry on the row below, to the left. For (a), the entry is Pi(j-1) and for (b), the entry is Pi-1(j-1)\n\nAll we have to show is that the value we hope is there, namely Pi(j), is what we get when we add (a) to (b), i.e. would be the correct entry in the difference table. So lets try it!\n\nPi(j-1) + Pi-1(j-1) =\n\na0 C(j-1,i-0) + a1 C(j-1,i-1) + . . .\u00a0 + ai-1 C(j-1,1) + ai C(j-1,0) +\n\na0 C(j-1,i-1) + a1 C(j-1,i-2) + . . .\u00a0 + ai-1 C(j-1,0)\n\nGathering our a\u2019s and using our identity, it falls into place, and we get the desired sum:\n\na0 C(j,i-0) + a1 C(j,i-1) + . . .\u00a0 + ai-1 C(j,1) + ai C(j-1,0)\n\nWhat about this last term? C(j-1,0) = 1, as does C(j,0), so we are set. Our total is Pi(j) as promised.\n\n\n\n  1. physicsfreak said,\n\n    January 21, 2009 at 4:27 pm\n\n    Hi, I realize this may be somewhat of an idiotic question, but I cannot for the life of me see /why/ we are using combinations here \u2014 I realize that the method works, but I don\u2019t know how to make it\u2026 intuitive. And what of newton coming up with this? where is it published?\u00a0\n\n    \u2014 Thanks so much for any help.\u00a0\n\n  2. strauss said,\n\n    February 3, 2009 at 7:55 am\n\n    The simplest (quite unsatisfying) answer is just as you say: that it works!\n\n    Let\u2019s see: how to make it intuitive? I am not sure I have a satisfying answer, except to note that the simplest example of this phenomenon is Pascal\u2019s triangle itself: sketch out what happens if the entries on the left of all but the bottom row are 0\u2019s and the entry on the left of the bottom row is 1. Actually draw this out! After a time, a slice of Pascal\u2019s triangle will appear, turned on its side. The entries along the top row will be C(n,k) (where there are k rows); we can think of this as a polynomial in n, or as a combination in n, either way.\n    The more general case is just a linear combination of multiples of this example, for different k\u2019s.\u00a0\n    Don\u2019t know that that is much more satisfying, though!\n    A really terrific reference on closely related topics (particularly, Stirling numbers) is in the beginning of Chapter 1, Vol 1 of Donald Knuth\u2019s The Art of Computer Programming; don\u2019t overlook the exercises!\n    The reference that tipped us off to this, but says less than we have said here, is Martin Gardner\u2019s Colossal Book of Mathematics.\n\nRSS feed for comments on this post \u00b7 TrackBack URL\n\nLeave a Comment\n\nYou must be logged in to post a comment.\n\nThe Math Factor Podcast Website\n\n\nA production of the University of Arkansas, Fayetteville, Ark USA\n\nDownload a great math factor poster to print and share!"}
{"text": "Retrieved from https://www.flyingcoloursmaths.co.uk/common-problem-decimal-division/\nText:\nI\u2019m a big advocate of error logs: notebooks in which students analyse their mistakes. I recommend a three-column approach: in the first, write the question, in the second, what went wrong, and in the last, how to do it correctly. Oddly, that\u2019s the format for this post, too.\n\nThe question\n\nDecimal division: something like 14.4 \u00f7 1.2\n\nWhat went wrong\n\nGot 1.2 instead of 12.\n\nHow to do it right\n\nApproach 1: Estimation. 14 \u00f7 1 is 14, so an answer of 1.2 is way off - 12 seems more reasonable.\n\nApproach 2: Decimal fractions. (A little bit of commentary here: at this point, students normally groan and say \u201cI can\u2019t do fractions\u201d or similar. It would be rude to point out that they clearly can\u2019t yet do decimal division, either.)\n\n  \u2022 Treat the sum as $\\frac{14.4}{1.2}$\n  \u2022 Decide that the bottom is ugly.\n  \u2022 \u201cCancel up\u201d: multiply top and bottom by 10 ((5 works just as well))\n  \u2022 You now have $\\frac{144}{12}$, which is obviously 12.\n\nApproach 3: Fractional fractions. Even a naive approach to dividing fractions is simple here:\n\n$14.4 \\div 1.2 = \\frac{144}{10} \\div \\frac{12}{10}$\n\n$\\frac{144}{10} \\div \\frac{12}{10} = \\frac{1440}{120} = \\frac{144}{12} = 12$.\n\nThere are probably a dozen other ways to approach this. What are your favourites?\n\n* Edited 2017-05-16 to add a category."}
{"text": "Retrieved from http://math.stackexchange.com/questions/214398/the-most-general-meromorphic-function-such-that\nText:\nTake the 2-minute tour \u00d7\n\nSuppose f is meromorphic in a neighborhood of the closed unit disk , that it does not have zeroes nor poles in the open unit disk, and that $|f(z)|=1$ for $|z|=1$. Find the most general such function. Let's denote D = open unit disk\n\nWell, since f has no poles in D, it's holomorphic there, thus by the maximum modulus principle $ |f(z)| < 1$ for $|z|<1$. If f does not have a zero , then we can use the minimum modulus principle, so f attains it's minimum in $\\partial D $ thus $f(z)=1 \\forall z \\in D$ , by analytic continuation $f(z)=1 \\forall$ in where f is defined $ I'm not sure if my solution it's correct :S. I never used the fact that it's analytic in a neighborhood of the closure. I'm missing something?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nActually the conclusion from the minimum modulus principle is $|f(z)| = 1$, not $f(z) = 1$. And the And then you can use the Open Mapping Theorem to say that $f$ is constant.\n\nYou did use the fact that $f$ is continuous on the closed unit disk in applying the maximum and minimum modulus principles.\n\nshare|improve this answer\nYou are completely right, I use the hypothesis that my domain is open , to assert that $f(D)$ is open but contained in $S^1$ Thanks :D! \u2013\u00a0 Daniel Oct 15 '12 at 20:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/72959/metric-for-signal-to-noise-ratio-in-communication-systems?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI'm not quite sure about how to define a good measure of the quality of a communication channel with fading and interference. Let us assume the simplest case, where a node in a network receives the following quantity:\n$$ y = s + w $$\nwhere $s$ is the amplitude (positive real) of the signal and $w$ the noise (gaussian with zero mean and variance $\\sigma^2$). A simple measure of the channel quality is simply given by ${\\rm SNR} = s^2 / \\sigma^2$, i.e., the ratio of the power of the signal vs the power of the noise.\nNow, suppose the received signal is $$ y = h_s s + w$$\nwhere $h_s$ and $w$ are complex gaussian with zero mean and unitary variance. A measure of the SNR that makes sense could be derived by looking at the power of the received signal $$ |y|^2 = y y' = |h_s|^2 s^2 + 2{\\rm Re}(h_ss~w') + |w|^2$$\nnow, since for practical applications the noise process is much faster than the fading (represented by $h_s$) what people normally do is to average over $w$, obtaining\n$$ E[|y|^2]_w = |h_s|^2 s^2 + \\sigma^2 $$\nhence, a measure of the signal strength that makes sense would be $ {\\rm SNR} = |h_s|^2 s^2 / \\sigma^2$.\nWhat I am interested about is the case with interference. Suppose there is an extra term that takes into account for interfering signals\n$$ y = h_s s + h_{\\rm I} s_{\\rm I} + w $$\nwhere $h_I$ is complex with zero mean and unitary variance. How could I possibly define the SNR in this case? By taking $|y|^2$ there are cross terms, i.e., products of $h_s$ and $h_{\\rm I}$ that do not disappear even if I average over the noise $w$. So it seems not obvious to me how to decouple $|y|^2$ into two different pieces, one for the signal and the other for the noise. The final goal would be determining a good measure of the SNR in order to be able to compute probabilities like\n\n$$ P({\\rm SNR} \\geq \\gamma_0).$$\n\nshare|improve this question\nif one can assume that $h_I$ is uncorrelated with $w$ and $h_s$, then you could just average $\u2223y\u2223^2$ over both $h_I$ and $w$; cross terms would still vanish; this is not what you want? \u2013\u00a0 Carlo Beenakker Aug 16 '11 at 13:47\nyes I know, but typically, the $h$ terms vary more slowly than the noise $w$. So averaging over $h$ is not that practical. \u2013\u00a0 Bob Aug 16 '11 at 22:37\n\n1 Answer 1\n\nThe general case is not known. If you find the correct information theoretic metric for the interference channel, you can find the capacity of interference channels (an open problem since the 1960s).\n\nIn your case, it looks like a MAC channel. Decode the stronger signal first and then decode the weaker one. Assuming you have a powerful code underneath, Euclidean distance as metric suffices.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/110321/effects-of-unitarian-multiplication-into-the-spectrum-of-a-finite-matrix?sort=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am interested in the following problem: Let $P$ be a $n\\times n$ complex finite matrix such as $PP^\\dagger =W$. Given $W$, what can I say about the spectrum of $P$?\n\nThis matrix \"square-root\" has of course no unique solution, for if $P$ is a solution, $PU$ is also a solution if $U$ is unitary. If we consider the space $M_n(\\mathbb{C})/U(n)$ we can seek an unique answer $P_* $, but I could not determine the shape of the space spanned by the eigenvalues of the equivalence class of $P_*$, apart for $n=2$ and some pretty horrible non-linear equations involving too many variables. Spectral theory is not my strong point, so I was wondering if anyone knew an answer to this: can we say what happens to the eigenvalues of $P$ if we multiply it by $U$ unitary?\n\nshare|improve this question\nIf $P$ is hermitian, then the spectral radius does not increase (and usually decreases) when you multiply on the left by a unitary transformation. More than that, I cannot say :( \u2013\u00a0 Igor Rivin Oct 22 '12 at 13:50\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nBy specifying $PP^{\\dagger}=W$ you are prescribing the singular values $s_n$ ($n=1,2,\\ldots N$) of the $N\\times N$ matrix $P$. These are just the positive square roots of the eigenvalues of the Hermitian, nonnegative matrix $W$. So your question can be rephrased as, what is the relation between the eigenvalues $\\lambda_n$ and the singular values $s_n$ of the matrix $P$. This is a classic problem studied by Horn (1954), who showed that the only relationships one can state in full generality are those obtained by Weyl (1949):\n\n$\\prod_{n=1}^{k} |\\lambda_n| \\leq \\prod_{n=1}^{k} s_n,$ for $k\\lt N$, and $\\prod_{n=1}^{N} |\\lambda_n| = \\prod_{n=1}^{N} s_n,$\n\nfor the ordering $|\\lambda_1|\\gt|\\lambda_2\\gt\\cdots\\gt|\\lambda_N|$ and $s_1\\gt s_2\\gt\\cdots\\gt s_N$. (The equality for $k=N$ follows trivially by equating the determinant of $PP^\\dagger$ with the determinant of $W$.)\n\nMore can be said for random matrices. As shown by Guionnet, Krishnapur, and Zeitouni (arXiv:0909.2214) in a probabilistic sense for \u201ctypical matrices\u201d, the singular values almost determine the eigenvalues. In particular, the \"single ring theorem\" relates the eigenvalue density to the density of singular values.\n\nThis presentation by Mark Rudelson gives an introduction.\n\n\nA. Horn, On the eigenvalues of a matrix with prescribed singular values, Proc. Amer. Math. Soc. 5, 4\u20137, (1954).\n\nH. Weyl, Inequalities between the two kinds of eigenvalues of a linear transformation, Proc. Nat. Acad. Sci. USA 35, 408\u2013411, (1949).\n\nshare|improve this answer\nThis is exactly what I was looking for, thank you! My problem arises from Random Matrix Theory, so, tip of the hat for you, fellow physicist. \u2013\u00a0 Ricardo Marino Oct 23 '12 at 9:51\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/16796/choosing-seats-for-guests\nText:\nTake the 2-minute tour \u00d7\n\nYou have a circular table with $N$ seats.$K$ bellicose guests are going visit your house of-course you don't want them to sit beside each other.As the host, you want to find out how many ways there are to choose $K$ seats such that none of them is adjacent to each other.\n\nI noticed that there is a solution other than $0$ if ($N \\ge 2K $) but I am not sure how to approach for the rest.\n\nEDIT: Only $K$ bellicose guests are visiting,no friendly guest are there the remaining $N-K$ seats will be vacant.\n\nA possible mathematical translation of this problem: Choosing $K$ candidate points from a circle of $N$ indistinguishable points such that there are more than one vacant point between adjacent candidate points.\n\nshare|improve this question\nUp to rotation or not? If not, try fixing K and seeing if you can write down a recurrence in terms of N. \u2013\u00a0 Qiaochu Yuan Jan 8 '11 at 13:46\n@ Qiaochu Yuan: Please rephrase, I don't understand what you meant by \"Up to rotation or not\". \u2013\u00a0 Quixotic Jan 8 '11 at 13:48\nQiaochu is asking (since the table is circular) whether your count of solutions should treat a rotation of a solution as another solution (or just count rotationally equivalent solutions as one). Also notice that you've misstated the inequality: should be $N \\ge 2K$ to get solutions. \u2013\u00a0 hardmath Jan 8 '11 at 14:38\n@hardmath: I am not sure whether the clock-wise or anticlockwise solution are treated different of not. \u2013\u00a0 Quixotic Jan 8 '11 at 14:45\nRight, I'd assume those (reflections) are counted differently, although of course \"who sits next to whom\" will be the same. A reflection is never a rotation except for the trivial case N=2, so there's not really a conflict in saying we want to identify rotationally equivalent solutions but distinguish reflections. \u2013\u00a0 hardmath Jan 8 '11 at 15:13\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nChoose a seat $S$, and a bellicose guest $B$. Sit $B$ in $S$, and tell them not to move, whether they like it or not. That done, there are $(K-1)!$ ways of ordering the remaining bellicose guests clockwise around the table, and $F!$ ways of ordering the friendly guests (here I am using leonbloy's notation $F = N - K$). For each such ordering, we have to choose a pattern of the form $f...b...f...b...f$. This pattern:\n1. starts and ends with $f$ (so that $B$ is isolated);\n2. contains $(K-1)$ $b$'s and $F$ $f$'s; and\n3. contains no two adjacent $b$'s.\n\nBut the number of such patterns is the same as the number of patterns that\n1. start with $f$; and\n2. contain $(K-1)$ $b$'s and $(F-K+1)$ $f$'s.\n\n(To see this, just replace each instance of $bf$ in the original pattern by $b$.) The number of such patterns is the binomial coefficient $\\binom{F-1}{K-1}$. So we end up with:\n\n$(K-1)!F!\\binom{F-1}{K-1} = \\frac{F!(F-1)!}{(F-K)!}$\n\nThis is the number of seating arrangements with guest $B$ in seat $S$. Multiply by $N$ to get the total number.\n\nEdit Reading the question more carefully, it asks for the number of (what I call here) patterns, not the number of seatings. For each pattern, there are $K!F!$ seatings, so the answer is\n\n$N\\frac{F!(F-1)!}{(F-K)!}/(K!F!) = \\frac{N(F-1)!}{(F-K)!K!}$\n\nshare|improve this answer\nSeems right to me. Just to clarify: \"This is the number of seating arrangements with guest B in seat S\" means: with \"a particular B guest (say b1) in seat S\", not \"with some belicose guest in seat S\". \u2013\u00a0 leonbloy Jan 9 '11 at 0:13\n@leonbloy: I suggest that my answer was perfectly clear on that point. I think you must have forgotten the first two sentences by the time you reached the last two. \u2013\u00a0 TonyK Jan 9 '11 at 0:22\nIn TonyK's counting the seats have name tags. If you only distinguish between white and black seats you have a different problem, see my former comment on this question. Maybe the proposer should clarify this point. \u2013\u00a0 Christian Blatter Jan 9 '11 at 11:59\nLet $N = 4$ and $K = 2$ we get $F = 2$ then your formula is giving $2 \\times N = 8$ but given answer is $2$. \u2013\u00a0 Quixotic Jan 9 '11 at 12:28\n@Christian Blatter: My first result is the number of seating arrangements with B in S, which is the same as the number of seating arrangements counting rotations (but not reflections) as identical. Now just multiply this by N to get the number of seating arrangements counting rorations as distinct. No special Polya theory is required. \u2013\u00a0 TonyK Jan 9 '11 at 12:29\n\nLet's call $F=N-K$ number of \"friendly\" guests. And let's call $S(F,K)$ the count of seating ways assuming that seats and guests are distinguible (rotations are distinct solutions).\n\nWe know that $F \\ge K$. For the limit case $F = K$ we have $S(F,K) = 2 K (K-1)! K! = 2 K!^2$.\n\nNow, the recursion: we count the number of ways when adding a friendly guest:\n\n$S(F+1,K) = (F+K+1) S(F,K)$\n\nFrom this (if it's correct!) you can get an explicit solution.\n\nUpdate: this is not correct. See TonyK's answer\n\nshare|improve this answer\nI don't think your recursion is right. Adding a friendly guest between two bellicose guests can transform an invalid seating into a valid one. Also it doesn't agree with the formula in my answer :-) \u2013\u00a0 TonyK Jan 8 '11 at 20:02\n@TonyK: you're right \u2013\u00a0 leonbloy Jan 9 '11 at 0:00\nNo friendly guests are there,please read my question. :-) \u2013\u00a0 Quixotic Jan 9 '11 at 15:04\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/7308/n-3-and-n-4-periodic-and-pseudo-anosov-auto-homeomorphisms\nText:\nTake the 2-minute tour \u00d7\n\nIt is well know that the genus three non orientable surface, N3, has only periodic and reducible auto-homeomorphisms, meanwhile the surface N4 is the first non orientable surface with pseudo Anosov maps. Also, recently profesor B.Szepietowski gave the MCG presentation of N4, from where, I calculated that there are seven periodic mapping classes. The question is: are there more?\n\nCuriously, the torus and N3 show also seven periodic mapping classes each but we would like to understand better why N3 loses pseudo Anosov maps which contrast with the fact that N3 is got from the 2-torus via an one-point blow up...\n\nshare|improve this question\nMaybe if you provided a couple of references, more people would find the question interesting. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Nov 30 '09 at 20:18\nDo you mean \"The mapping class group of N_4 has at least 7 distinct conjugacy classes of periodic elements. Are there any more?\"? \u2013\u00a0 Sam Nead Nov 30 '09 at 20:54\nR.C. Penner. A construction of pseudo-Anosov homeomorphisms, Trans. Amer. Math. Soc., 310 (1988) No 1, 179-197, for the results in the existence of pA maps. In the other hand Szepietowski is easy to find in the Front-for-the-arXiv \u2013\u00a0 janmarqz Nov 30 '09 at 20:56\nSam, yes! it seems to me that the Szepietowski presentation produce at least seven automorphisms in the aut(MCG)... \u2013\u00a0 janmarqz Nov 30 '09 at 20:59\noops I mean Ab(MCG(N_4))... \u2013\u00a0 janmarqz Nov 30 '09 at 21:01\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nJust to lend some context to the above question: the mapping class group of the two-torus is naturally isomorphic to GL(2, Z). If we restrict to orientation preserving homeomorphism the mapping class group is SL(2, Z). The periodic mapping classes (isotopy classes of homeomorphisms) are exactly those with trace less than two in absolute value. (Hmm, and +/- Id, I guess!) Now we need to count the number of conjugacy classes of periodic elements. There should be a cool algebraic way to do this. (Perhaps it would help to give a purely algebraic proof that the order of torsion is at most 6?)\n\nI think that there is a geometric way to do this: every periodic element occurs as the symmetry of some flat torus (= parallelogram with opposite sides identified). All tori have have the hyperelliptic symmetry, corresponding to rotation by 180 degrees about any point. (These maps lie in the mapping class of the negative identity.) Other symmetries:\n\nRombic tori have a reflection symmetry as do rectangular tori.\nThe square torus has a rotation by 90 degrees.\nThe hexagonal torus has a rotation by 60 degrees.\n\nSo I count:\n1. the identity, Id\n2. the hyperelliptic = -Id = rotation by 180\n3. rotation by 90\n4. rotation by 60\n5. rotation by 120\n6. the reflection [[-1,0],[0,1]] (reflection in an axis) and\n7. the reflection [[0,1],[1,0]] (exchange axes).\n\nYou can prove that the last two are distinct algebraically. Perhaps the lack of 45 degree rotation is a geometric proof.\n\nNow, we could perform similar geometric tricks to obtain symmetries of $N_4$ and get at least all of the rotations... [Edit: For example, it is possible to build a copy of $\\rm{Sym}_4$ by placing the cross-caps at the vertices of a tetrahedron.]\n\nshare|improve this answer\nYou can easily check that a finite subgroup of SL(2,Z) maps injectively to SL(2, Z_3) by the obvious map, and you can also easily check that elements of SL(2,Z_3) have orders 1, 2, 3, 4, or 6. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Dec 4 '09 at 7:19\nAlternatively, the minimum polynomial of an element of $GL(2,Z)$ of finite order $n$ must be divisible by the minimal polynomial of a primitive $n$th root of unity, which has degree $\\phi(n)$. This is at most $2$ iff $n\\in\\{1,2,3,4,6\\}$ \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Dec 4 '09 at 7:25\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/59212/deriving-torque-from-euler-lagrange-equation\nText:\nTake the 2-minute tour \u00d7\n\nHow could you derive an equation for the torque on a rotating (but not translating) rigid body from the Euler-Lagrange equation? As far as I know from my first class in Classical Mechanics, there is no potential defined for a rotating body, so the only term I see in the Lagrangian is the $\\frac{1}{2}I\\omega^2$. Since there is no $\\theta$, I'm just getting that torque always equals $0$.\n\nshare|improve this question\nIt depends how the body is fixed in space. If it is floating, there's no torque and the angular momentum is conserved. But if the body is supported by a pedestal or something like that, the potential energy $mgh$ where $h$ is the height of the center of mass effectively does depend on the angle $\\phi$ and the derivative of this potential energy with respect to the angle gives you torque. \u2013\u00a0 Lubo\u0161 Motl Mar 27 '13 at 15:26\nComment to the question (v1): It is still possible to define the potential energy $V$ of a torsion spring, so that angular system has a Lagrangian formulation. \u2013\u00a0 Qmechanic Mar 27 '13 at 15:30\nHow does height depend on theta (The angle between the applied force and the radius)? Knowing torque should equal |F||R|sin(theta), the potential should then equal |F||R|cos(theta). If |F||R|cos(theta) = mgh = |F|*h, that would imply that the height is less than the radius. -- What am I missing here? \u2013\u00a0 JLA Mar 27 '13 at 16:16\nYou know you need to refine the rotation with generalized coordinates (like Euler angles) which will yield generalized forces (torques). \u2013\u00a0 ja72 Aug 20 '13 at 14:32\nadd comment\n\n1 Answer\n\nThe question isn't clear to me, the torque is zero if there's not an applied torque, and it's nonzero if it's not zero, but that's just a tautology. Do you mean that you just want to derive something/anything torque-esque given an applied force? If so, here's one way.\n\nThis isn't a job for a potential, it's the job for a generalized force. Consider the 2d case, with a particle at some position $s=(x,y)$, with mass $m$ and a force vector $F$ applied to it.\n\nThe first form of the Euler-Lagrange equations I learned was the form:\n\n$$\\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_i}-\\frac{\\partial T}{\\partial q_i}=Q_i$$ where $T$ is the kinetic energy (NOT the lagrangian), $q_i$ are the parameters describing the system, and $Q_i$ is defined as the generalized force $Q_i=\\sum_j F_j \\frac{\\partial s_j}{\\partial q_i}$. (Goldstein classical mechanics ch 1)\n\nThen, parameterizing in terms of polar coordinates, we can define $s=(q_1 \\cos(q_2),q_1 \\sin(q_2))$.\n\nGoing through the motions of finding the kinetic energy, generalized forces, and partial derivatives:\n\n$\\dot{s}=(\\dot{q_1}\\cos(q_2)-q_1\\sin(q_2) \\dot{q_2},\\dot{q_1}\\sin(q_2)+q_1\\cos(q_2) \\dot{q_2})$\n\n\n\n$Q_1=F\\cdot(\\cos(q_2),\\sin(q_2))\\equiv F_r$ (define $F_r$ this way)\n\n$Q_2=F\\cdot(-q_1\\sin(q_2),q_1\\cos(q_2))\\equiv \\tau$ (define $\\tau$ this way)\n\nEuler-Lagrange equation for $q_1$:\n\n$\\ddot{q_1}m-m\\dot{q_2}^2 q_1=F_r$\n\nfor $q_2$:\n\n$\\frac{d}{dt}(m q_1^2 \\dot{q_2})-0=\\tau =m q_1^2 \\ddot{q_2}+2 m q_1 \\dot{q_1} \\dot{q_2}$\n\nDenoting $q_1=r$, $q_2=\\theta$ for clarity's sake, we wind up with the equations: $$m\\ddot{r}-m r \\dot{\\theta}^2=F_r$$ $$m r^2 \\ddot{\\theta}+2 m r \\dot{r} \\dot{\\theta}=\\tau$$\n\nFrom which we can identify the torque and whatever we want. If $r$ is constant, we have $F_r=-m v^2/r$, and identifying $m r^2 \\dot{\\theta}=L$ with the angular momentum, we see $\\dot{L}=\\tau$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18319/can-a-continuous-nowhere-differentiable-function-have-specified-shape-at-ever\nText:\nTake the 2-minute tour \u00d7\n\nI'm a bit embarrassed to admit that:\n\na) This is a rather unmotivated question.\n\nb) I can't remember whether or not I've asked this before, but searching doesn't seem to turn anything up so ...\n\nConsider some \"shape\" function $\\phi: \\mathbf{R} \\to \\mathbf{R}$. Then given some function $f: \\mathbf{R} \\to \\mathbf{R}$, one can ask whether the \"difference quotient\",\n\n$\\lim_{y\\to x} \\frac{f(y)-f(x)}{\\phi(y-x)}$,\n\nexists at various points $x$. Letting $\\phi(x) = x$ corresponds to taking normal derivatives, and intuitively when the limit exists this means that near $x$, the function $f$ \"looks like\" $\\phi$ does near 0.\n\nHowever, if the ratio $\\phi(x)/x$ is not bounded above or away from 0 as $x\\to 0$ (I'm mostly thinking of the case when it is neither, so that $\\phi$ is \"wildly oscillating\" in some sense), then anywhere the above limit exists and is nonzero, the function $f$ is necessarily non-differentiable.\n\nMy question: If $\\phi$ is some wildly oscillating function as described above (pick your favorite), can there be an $f$ for which this limit exists everywhere?\n\n(Edit: I suppose I really want $\\phi$ and $f$ to be continuous functions.)\n\nshare|improve this question\nDo you want the limit to be nonzero almost everywhere? \u2013\u00a0 Douglas Zare Mar 15 '10 at 22:50\nHow about taking $\\phi$ to be a discontinuous additive function and $f=\\phi$? \u2013\u00a0 Jonas Meyer Mar 15 '10 at 22:51\n@Douglas Zare Not necessarily. Is there an easy (non-constant) example if it isn't required? @Jonas Meyer Good point. I guess I really want $\\phi$ to be continuous, and $f$ to be a continuous nowhere-differentiable function. I really should have put the adjective continuous in a lot of places. \u2013\u00a0 Mike Hall Mar 16 '10 at 0:32\n@Mike, Any $C^{0,\\alpha}$-function $f$ and $\\phi(x)=|x|^\\beta$ for $0<\\beta<\\alpha<1$ will do. \u2013\u00a0 Anton Petrunin Mar 16 '10 at 1:12\nBut Anton, I don't think that meets the \"wildly oscillating\" criterion. \u2013\u00a0 Jonas Meyer Mar 16 '10 at 1:18\nshow 2 more comments\n\n1 Answer\n\nup vote 5 down vote accepted\n\nAssume WLOG that $\\phi(x)>0$ when $x>0$. Since the limit described exists for all $x$ in the source of $f$. We get for any $x$ the bound:\n\n$f(x+\\delta)-f(x) \\leq C\\phi(\\delta)$\n\nfor $0 < \\delta < \\delta_0$ for some $C,\\delta_0>0$ which may depend on $x$.\n\ndiving by $\\delta$ we get by the assumptions on $\\phi$ that\n\n$\\underline{\\lim}_{\\delta \\to 0} ( \\frac{f(x+\\delta) - f(x)}{\\delta}) \\leq 0$\n\nThis is one the four derivatives of $f$, and proposition 2 chapter 5 in Real Analysis by H.L. Royden states that if $f$ is continuous then it is (non-strictly) decreasing. Similar for increasing. So $f$ is constant.\n\nshare|improve this answer\n\u201cAssume WLOG that $\\phi(x)>0$ when $x>0$.\u201d Why? M Hall specifically wants to consider the \u2018wildly oscillatory\u2019 case. (I am supposing that $x \\mapsto x\\sin(1/x)$ is wildly oscillatory, anyway.) \u2013\u00a0 L Spice May 9 '11 at 2:13\nWildly oscilating refers to $\\phi(x)/x$ being both close to zero and unbounded for very small $x$. The assumption WLOG refers to the fact that the limit would not exist if $\\phi$ were not strictly positive or negative in a small $(0,\\epsilon)$ (assuming continuity). \u2013\u00a0 Thomas Kragh May 27 '11 at 15:12\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/132743/probability-of-having-linearly-independent-sparse-vectors-over-finite-fields\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that there are $i< N$ linearly independent $N$-dimensional vectors $\\mathbf{v}_1,\\mathbf{v}_2,\\ldots,\\mathbf{v}_i$ over a finite field $\\mathbb{F}_q$, whose elements are denoted as $\\{0,1,2,\\ldots,q-1\\}$. Each vector consists of exactly $m$ nonzero elements uniformly randomly chosen from $\\{1,2,\\ldots,q-1\\}$, $m\\ll N$. The nonzero coordinates of each vector are randomly located.\n\nNow the question is, given a new such random $N$-dimensional vector $\\mathbf{v}_{i+1}$, what is the probability that it is linearly independent with the previous $i$ vectors?\n\nBest Regards.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nThese are some preliminary thoughts that are too long for a comment.\n\nAn equivalent question is: How many vectors with exactly $m$ nonzero entries are in the subspace generated by the first $i$ vectors? Then one just divides by $(q-1)^m\\left(\\begin{array}{c}N \\\\ m \\end{array}\\right)$ to get the probability. A naive guess is $\\frac{(q-1)^m}{q^{N-i}} \\left(\\begin{array}{c}N \\\\ m \\end{array}\\right)$. A trivial lower bound is $i (q-1)$. A trivial upper bound is $q^i-1$.\n\nI would guess that, as long as $m$ is reasonably large, for small $i$ the trivial lower bound is approximately correct, and for larger $i$ the naive guess is correct. All in all, the problem behaves very differently depending on the relative sizes of $i$, $m$, $N$, and, to a lesser extent, $q$. What regimes are you most interested in?\n\nWhen $m$ is very small, we get some interesting behavior. For $m=1$, we can exactly compute the probability of linear independence - it is $(1-1/N)^{i}$. For $m=2$, we can see the $N$ elements as vertices of a graph and the $i$ vectors as edges. Then our new vector can be linearly dependent only if the two nonzero coordinates are connected to each other, or both connected to cycles. I think one can get accurate formulas without too much difficulty this way.\n\nWhen the probability of a linear dependence among the $i$ vectors is sufficiently small, a good upper bound is provided by counting the expected number of ways to write a new vector as the sum of old vectors. One can write this a a sum over different ways to write a new vector as a sum of old ones, and try to find the largest terms. In particular for small $i$ I think only a couple of ways of writing a new vector as a sum of old ones will be dominant - most vectors of length $m$ that are sums of vectors of length $m$ will be sums of only $1$ or $2$ or $3$ vectors of length $m$. Then you would get a sequence of increasingly exact formulas.\n\nThe most important question is really how $i,m,$ and $N$ relate to each other. The problem is really very different for different values of that.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/73958/intersection-of-a-smooth-projective-variety-and-a-plane/83663\nText:\nTake the 2-minute tour \u00d7\n\nLet $X \\subset P^n$ be an irreducible smooth complex projective variety embedded in the $n$-dimensional projective space. Let $k$ be the dimension of $X$ and $d$ its degree. Let $L \\subset P^n$ be a linear subspace of dimension $n-k$ and $Z=L \\cap X$. Assume that\n\n(a) $X$ is not contained in any hyperplane of $P^n$ and\n\n(b) $Z$ is finite of cardinality $d$.\n\nQuestion: Is it true that $Z$ spans $L$?\n\nComment: I was told that this is true if $X$ is ACM (arithmetically Cohen-Macaulay). A reference for this would be appreciated.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nIt is true that $Z$ spans $L$ \u2014 even if $X$ isn't ACM. You can also allow $X$ to be singular (but you do need $X$ irreducible and non-degenerate, of course). To illustrate one of the main ideas it is useful to first look at the case when $X$ is a curve.\n\nIf $X$ is a curve. Let $M$ be the span of $Z$ and suppose that $M\\neq L$. (In the curve case, $L$ will be a hyperplane). Let $p$ be any point of $X$ outside of $Z$ and let $H$ be any hyperplane containing $M$ and $p$. Then $H\\cap X$ contains at least $d+1$ points, so by Bezout's theorem the intersection cannot be zero dimensional. Since $X$ is irreducible and one dimensional, this means that the intersection must be all of $X$, so $X$ is contained in $H$, contrary to hypothesis.\n\nThe general case. The idea when $k\\geqslant 2$ is to show that if $H$ is a general hyperplane containing $L$ then $H \\cap X$ is irreducible and non-degenerate (i.e, the intersection $H\\cap X$ is not contained in a smaller linear space of $H$). But now all dimensions have been reduced by $1$, and so iterating this procedure reduces us to the curve case, which we've already solved.\n\nTo set this up, note that hyperplanes in $\\mathbb{P}^n$ containing $L$ are parameterized by a $\\mathbb{P}^{k-1}$ (If $V$ is the underlying vector space of $\\mathbb{P}^{n}$, $W$ the underlying vector space of $L$, then the hyperplanes are parameterized by the projectivization of $(V/W)^{*}$). We'll use $H$ to refer both to a point of $\\mathbb{P}^{k-1}$ and the corresponding hyperplane in $\\mathbb{P}^n$ containing $L$. Define $\\Gamma\\subset \\mathbb{P}^{k-1}\\times (X\\setminus Z)$ to be the set\n\n$$\\Gamma = \\left\\{(H,p) \\mid p\\in H\\right\\}$$\n\ni.e, the pairs $(H,p)$ so that $H$ is a hyperplane containing $L$, and $p$ a point of $H\\cap X$ not on $Z$.\n\nIf we fix $p$, then the set of possible $H$'s satisfying this condition are simply the hyperplanes $H$ containing the span of $L$ and $p$, and this is parameterized by a $\\mathbb{P}^{k-2}$. In other words, $\\Gamma$ is a $\\mathbb{P}^{k-2}$ bundle over $X\\setminus Z$. (This fibration is where we use $k\\geqslant 2$.) Since $X\\setminus Z$ is irreducible this implies that $\\Gamma$ is irreducible.\n\nLet $\\overline{\\Gamma}$ be the Zariski-closure of $\\Gamma$ in $\\mathbb{P}^{k-1}\\times X$. Then $\\overline{\\Gamma}$ is irreducible since $\\Gamma$ is. For a fixed $H\\in \\mathbb{P}^{k-1}$ the fibre of the projection $\\overline{\\Gamma}\\longrightarrow \\mathbb{P}^{k-1}$ over $H$ is simply the intersection $X\\cap H$, of dimension $k-1$.\n\nNow let $q$ be any point of $Z$. Then $q\\in X\\cap H$ for every $H\\in \\mathbb{P}^{k-1}$ so $q$ gives a section of $\\overline{\\Gamma}\\longrightarrow\\mathbb{P}^{k-1}$. Since $Z$ consists of $d$ distinct points where $d$ is the degree of $X$ we conclude that $q$ is a smooth point of $X$. Finally, since $Z$ is the intersection of all $X\\cap H$ for $H\\in \\mathbb{P}^{k-1}$ this implies that the general intersection $X\\cap H$ is smooth at $q$. Summarizing, we have a section of the map which generically lies in the smooth locus of the fibres. Since $\\overline{\\Gamma}$ is irreducible, this implies that the generic fibre is irreducible, i.e, if $H$ is a generic hyperplane containing $L$, then $H\\cap X$ is irreducible.\n\n(The intuitive reason for this implication is that, generically over $\\mathbb{P}^{k-1}$ the section lets us pick out precisely one irreducible component of the fibre. The union of these components gives us a subset of $\\overline{\\Gamma}$ which has the same dimension as $\\overline{\\Gamma}$, and hence whose closure must be all of $\\overline{\\Gamma}$ by irreducibility. But if there is more than one component in a general fibre, this is a contradiction, thus the general fibre must be irreducible. To make this intuitive construction rigorous requires passing to the normalization of $\\overline{\\Gamma}$ and then looking at the Stein factorization of the map from the normalization to $\\mathbb{P}^{k-1}$. The section gives a generic section of the finite part of the Stein factorization, and that allows one to construct the ``union of the components containing the section''.)\n\nFinally, the same trick as in the curve case also shows us that for any hyperplane $H$, $H\\cap X$ must be non-degenerate. Let $Y=H\\cap X$, so that $Y$ is a variety of degree $d$ and dimension $k-1$. Let $M$ be the span of $Y$. If $M\\neq H$ then pick any point $p\\in X\\setminus Y$ and let $H'$ be any hyperplane containing $M$ and $p$. Then $H'\\cap X$ can't be all of $X$ (since this would contradict the non-degeneracy of $X$), so $Y'=H'\\cap X$ must be a subvariety of dimension $k-1$ (more precisely, all components of $Y'$ have dimension $k-1$) and degree $d$. But $Y$ is therefore a component of $Y'$, and the equality of degrees tells us that $Y'$ can't have any other components so we must have $Y'=Y$. This contradicts the fact that $p\\in Y'$ and $p\\not\\in Y$.\n\nTogether this shows the required inductive step: If $H$ is a general hyperplane containing $L$ then $H\\cap X$ is irreducible and non-degenerate.\n\nOther remarks. I'm guessing from the setup of the question that you want to apply the result for a particular $L$ that you have chosen. If, in the application, you're allowed to pick a general $L$ then you can say something stronger. The classical uniform position principle (where ''classical'' in this case means ''established by Joe Harris in the 80's'') states that for a general subspace $L$ of dimension $n-k$ the finite set of $d$-points in $Z=L\\cap X$ have the property that any subset of $r+1$ of the points (with $r\\leqslant n-k$) span a $\\mathbb{P}^{r}$. Picking $r=n-k$, this means that any subset of $n-k+1$ points of $Z$ spans all of $L$, and so in particular $Z$ spans $L$. (Note that $d\\geqslant n-k+1$; for instance, as a consequence of the argument above: if $d < n-k+1$ then the $d$ points of $Z$ would never span $L$.)\n\nshare|improve this answer\nThanks for the edit. I originally couldn't justify your statement \"Since $\\overline{\\Gamma}$ is irreducible with connected fibers over an irreducible base, its general fiber is irreducible.\" Of course you are right that the section is what helps out here. For other people who may have been confused, a counterexample is given as follows: consider the space of conic plane curves singular at the origin. This is naturally parameterized by a $\\mathbb{P}^2$, and one can check the total space of the universal family is irreducible. \u2013\u00a0 Jack Huizenga Dec 19 '11 at 20:32\nDear Jack - Yes, my previous justification for the irreducibility of the general fibre was completely wrong. I was thinking of the case that $X$ was smooth, and so $\\overline{\\Gamma}$ could be assumed normal. Then the general fibre is normal and so connectedness implies irreducibility. The general case of (possibly) non-normal $\\overline{\\Gamma}$ requires the use of the section to get around this, as your example shows. \u2013\u00a0 Mike Roth Dec 20 '11 at 15:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/110346/if-two-probability-distributions-have-the-same-weak-limit-and-one-of-them-satisf?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nIf the probability distribution function of two sequences of random variables have the same weak limit and one of the sequences satisfies a Large deviation principle, then does it imply that the other one also satisfies a LDP with the same rate function? Here is a more precise version of my question:\n\nLet $$ X_n: (\\Omega_n, P_n) \\rightarrow \\mathbb{R} $$ and $$ X_n^{\\prime}: (\\Omega_n^{\\prime}, P^{\\prime}_n) \\rightarrow \\mathbb{R}$$be a sequence of random variables. We define the probability distribution function as $$ \\mu_n(A) := P_n(X_n^{-1}(A)), \\qquad \\mu_n^{\\prime}(A) := P_n^{\\prime}(X_n^{\\prime^{-1}}(A)) $$ for every set $A \\subset \\mathbb{R}$. We are given that for every bounded continuous function $\\phi : \\mathbb{R} \\rightarrow \\mathbb{R}$ (or equivalently for every continuous function with compact support) $$ \\lim_{n\\rightarrow \\infty} \\int \\phi d \\mu_n = \\lim_{n\\rightarrow \\infty} \\int \\phi d \\mu_n^\\prime = \\int \\phi d \\mu $$ Furthermore, we also know that the random variable $X_n$ satisfies the Large deviation principal, ie for a given number $x \\in \\mathbb{R}$ the following limit exists $$ \\lim_{n \\rightarrow \\infty} \\frac{-1}{n}\\log(\\mu_n(t\\in \\mathbb{R}: t > x )) = I(x) $$\n\nDoes it follow that the other random variable also satisfies a large deviation principle with the same rate function, ie $$ \\lim_{n \\rightarrow \\infty} \\frac{-1}{n}\\log(\\mu_n^{\\prime}(t\\in \\mathbb{R}: t > x )) = I(x) $$\n\nNote that I am asking two questions: First of all does the limit exist? Secondly, is it the same limit.\n\nshare|improve this question\ntwo sequences can converge to the same limit but at very different speed. \u2013\u00a0 Alekk Oct 22 '12 at 19:18\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nNo and no. To see why the limit need not exist, suppose $\\mu = \\delta_0$ and $X^\\prime_n = \\frac{(-1)^n}{n}$ a.s. Then $\\liminf \\frac{-1}{n}\\log \\mu^\\prime_n(0,\\infty) = 0$ while $\\limsup \\frac{-1}{n}\\log \\mu^\\prime_n(0,\\infty) = \\infty$. Even if the limit exists, it need not be the same limit. Suppose $\\mu = \\delta_0$. Suppose $X_n = 1/n$ and $X^\\prime_n = -1/n$ a.s. Then $\\lim\\frac{-1}{n}\\log \\mu^\\prime_n(0,\\infty)=\\infty$ while $\\lim\\frac{-1}{n}\\log \\mu_n(0,\\infty) = 0$.\n\nshare|improve this answer\nThank you, that is a clear counter example. In which case, is there any extra ``reasonable'' hypothesis that guarantees the answer to my question will be yes? \u2013\u00a0 Ritwik Oct 23 '12 at 4:57\nExponential tightness would help. See, for example, Theorems 3.7 and 3.8(b) of math.wisc.edu/~kurtz/feng/chap3.pdf \u2013\u00a0 Dan Oct 23 '12 at 13:17\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/nonempty-subset-proof.71048/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nNonempty subset proof\n\n  1. Apr 11, 2005 #1\n    No idea where to start with this one...to prove that it is not possible to have a set B of 5 distinct positive single-digit integers such that every possible nonempty subset of B has a different sum. How do I approach it/do it?\n  2. jcsd\n  3. Apr 11, 2005 #2\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Given 5 distinct numbers, there are 2^5 - 1 possible sums of subsets, excluding the sum of all 5 which is 31.\n\n    However, the biggest possible sum of 4 distinct single digit numbres is 9+8+7+6= 28, so apply the pigeon hole principle.\n  4. Apr 11, 2005 #3\n    I'll try that, thanks for the suggestion!\n\nHave something to add?\n\nSimilar Discussions: Nonempty subset proof\n  1. A proof. (Replies: 2)\n\n  2. Any subset (Replies: 2)\n\n  3. Subset product (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/galois-theory-morphisms.546932/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nGalois Theory: Morphisms\n\n  1. Nov 3, 2011 #1\n\n    Let K = Q(21/4)\n\n    Determine the automorphism group Aut(K/Q)\n\n    2. Relevant equations\n\n    An automorphism is an isomorphism from a Field to itself\n\n    Aut(K/Q) is the group of Automorphisms from k/Q to K/Q\n\n    Definition: A K-Homomorphism from L/K to L'/K is a homomorphism L---> L' that is the identity on K\n\n    3. The attempt at a solution\n\n    I am completely at a loss really. I have calculated there are four homomorphisms from K to C and think from there if I know how many are K-homomorphisms then that'll be the number of automorphisms, because a homomorphism from a field to itself is an automorphism (Please correct me if I'm wrong on this). Then that'll give me the set of Automorphisms.\n\n    My problem is that I don't know how to go from the number of homomorphisms to the actual homomorphisms. I think it has a relation to the roots of 2(1 /4) in C (which I have calculated to be 2(1 /4), - 2(1 /4), i*2(1 /4), -i2(1 /4) )\n\n    Please help, this lack of understanding is preventing me from moving forward with other questions and my notes from lectures completely gloss over how to do this.\n  2. jcsd\n  3. Nov 3, 2011 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    [itex](2^{1/4}^2= 2^{1/2}[/itex] and [itex](2^{1/4}^3=2^{3/4}[/itex] are irrational but [itex](2^{1/4})^4= 2[/itex] is rational so any number in [/itex]Q(2^{1/4})[/itex] is of the form [itex]a+ b2^{1/4}+ c2^{1/2}+ d2^{3/4}[/itex] for rational numbers a, b, c, d. For any automorphism, f, [itex]f(a+ b2^{1/4}+ c2^{1/2}+ d2^{3/4})= a + bf(2^{1/4})+ cf(2^{1/2})+ df(2^{3/4})[/itex] so the possible values of f depend entirely upon the possible values of [itex]f(2^{1/4})[/itex], [itex]f(2^{1/2})[/itex] and [itex]f(2^{3/4})[/itex].\n\n    Further, [itex](f(2^{1/4})^4= f(2)[/itex] is rational so [itex]f(2^{1/4}[/itex] must be a fourth root of 2. Also, [itex]f(2^{1/2})^2= f(2)[/itex] so [itex]f(2^{1/2}) must be [itex]2^{1/2} (or [itex]-2^{1/2}[/itex] which is just a rational number times [itex]2^{1/2}. Each f permutes the fourth roots of 1 while fixing [itex]2^{1/2}[/itex].\n  4. Nov 3, 2011 #3\n\n\n    User Avatar\n    Science Advisor\n\n    it is somewhat misleading to say the values of f depend on the values of f(21/4), f(21/2) and f(23/4).\n\n    f is a field automorphism, so (for example) f(23/4) = f((21/4)3)= (f(21/4)3,\n\n    so f ONLY depends on the value of f(21/4).\n\n    while it is true that f permutes the roots of x4-2, it is not true that any such permutation yields an \"f\". f takes conjugate pairs to conjugate pairs, as well (the square of a fourth root of 2 must be a square root of 2).\n\n    so if one regards the 4 roots of x4-2 as \u03b11234, where:\n\n    \u03b1j = \u03b1e(j-1)\u03c0i/4\n\n    then (\u03b12 \u03b14) yield a member of Aut(K/Q), but (\u03b12 \u03b13) does not.\n\nHave something to add?\n\nSimilar Discussions: Galois Theory: Morphisms\n  1. Galois theory (Replies: 4)\n\n  2. Galois Theory question (Replies: 0)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-final-velocity-of-the-cart-and-students.53214/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the final velocity of the cart and students\n\n  1. Nov 18, 2004 #1\n    Three Physics 111 AP students, each having a mass of 60kg, climb onto a large flatbed cart that has a mass of 120 kg. Standing at one end and taking turns they run to the opposite end and jump off, one immediately following the other, each with a velocity of 10 m/s with respect to the cart. Calculate the final velocity of the cart and students with respect to the earth.\n\n    I know I need to use [itex]m_1v_1 + m_2v_2 = m_1v_1 + m_2v_2[/itex], and I have done a bunch of simpler problems with no trouble. I'm pretty sure this has to be done in steps but I'm not sure how to incorporate the answer of each step into the next. I have something like this for the first step:\n\n    [tex]60 \\cdot 0 + 120 \\cdot 0 = 60 \\cdot 10 + 120(v + 10)[/tex]\n  2. jcsd\n  3. Nov 18, 2004 #2\n    Read integral's post.\n    Last edited: Nov 18, 2004\n  4. Nov 18, 2004 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    I believe that this problem is a bit more subtle, it is essentially a rocket problem. The mass of the \"cart\" does not remain constant. As each student jumps it becomes less massive, thus each successive student will cause a larger change in velocity.\n    after the first student jumps the carts velocity will change by:\n    [tex] v_c = \\frac {m_1 V_1} {m_2 + m_3 + m_c}[/tex]\n\n    Repeat for each student and sum the changes to get the total change.\n\nHave something to add?\n\nSimilar Discussions: Calculate the final velocity of the cart and students"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55629.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nMonty Hall Strikes Again\n\nSubject: Probability Question from OZ!\nDate: Wed, 2 Nov 1994 17:13:05 +1100 (EST)\nFrom: \"Sean Pryor\"\n\n\nBasically the problem goes like this.  There are three cups, one of which \nswap them?\n\nTo summarise:\n\nThree cups with a coin under one.\nYou pick one, I pick one that DOESN'T have the coin.\nYou then either stay with your choice, or swap it with the remaining cup.\nWhat is the probability of getting the coin, either way?\n\nBTW the answer I get is 50% either way - though it has been suggested \nthat you have a 2/3 chance if you swap cups....  I disagree with this, \nbut I don't think my maths is capable of giving a definitive answer \n(which is why you're reading this!)\n\n(This problem has placed a cool Australian $50 on the line here in a bet - \nso I need an answer proving me right! :-)  My mate would never let me \nforget it if he was right...)\n\n\nSean Pryor\n\nDate: Thu, 3 Nov 1994 08:20:34 -0500\nFrom: Phil Spector\n\n\nThis question is a famous brain teaser that is usually described in terms\nof the game show Let's Make a Deal.  Indeed, you do have a 2/3 chance \nof winning if you swap cups.  The answer is anti-intuitive, and my efforts \nat explaining it usually fall a little flatter than others' explanations, so\nI'm going to let other Dr. Math's try to provide an answer, and I'm going\nto work on a productive explanation.\n\nBasically, the solution is based as follows:\nLet's say it was under cup 1.\nOption 1: You originally choose cup 1.  Then, you get shown one of the\nempty cups (let's say cup 2 or 3) at which point if you CHANGE (to the\nremaining empty cup, either cup 2 or 3), you LOSE, but if you REMAIN \nwith cup one, you WIN.\n\nOption 2: You originally choose cup 2.  Then, you get shown the remaining\nempty cup (cup 3), at which point if you CHANGE (to cup 1), you WIN, \nbut if you REMAIN with cup 2, you LOSE\n\nOption 3: You originally choose cup 3.  Then, you get shown the remaining\nempty cup (cup 2), at which point if you CHANGE (to cup 1), you WIN, \nbut if you REMAIN with cup 3, you LOSE.\n\nEach of the three options has an equal chance of occuring, based upon your\noriginal random pick.  If you change 1/3 of the time, you lose (in the case\nof option 1, which has a 1/3 probability of occuring), while if you change\n2/3 of the time (with options 2 or 3, which have a 2/3 probability of\noccuring), you win.\n\nTherefore, the proper choice is always to change!  Sorry about that 50\ndollars. :(\n\nI think the place where things skew to the anti-intuitive is the fact that\nyou will -always- get shown an EMPTY cup by the game-show host/tricker, \nnot necessarily a random cup.\n\nHope this helped.\n\nPhil, a Dr. Math who knows only statistics revolving around game shows...\n\nSubject: Probability Question from OZ!\nFrom: \"Sean Pryor\"\n\nHey, it wasn't my $50!  It was a mate you was silly enough to bet on a\nmaths problem!! :-)\n\nI think I understand.  My query is that perhaps you have a 2/3 of getting\nthe coin when changing, taking into account the whole process.  If you\nisolate the last choice and say - now it's either in this cup or that and\nI can choose this or that, its 1/2.  Is that a reasonable method of\nexplaining the anti-intuitive bit?  Or have I missed the point here...\n\nX-Sender: pspecto1@cc.swarthmore.edu\nDate: Fri, 4 Nov 1994 18:46:18 -0500\n\nExactly.  Nope, you explained it better than I did...\n\n\n>What better place to start - my favourite was always the Wheel of Fortune\n>- spinning wheels, angular momentum, friction, force, acceleration, sectors,\n>degrees, probability - that show had it all! :-)\n\nTrue, but I always thought Pat Sajak was a dweeb. :)  Glad Dr. Math could\nhelp, and of course, write back with any other problems you have...\n\nAssociated Topics:\nHigh School Logic\nHigh School Probability\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from https://www.physicsforums.com/threads/new-electric-car-idea.216131/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nNew? electric car idea\n\n  1. Feb 18, 2008 #1\n    new? electric car idea...!!\n\n    Hey guys,\n\n    I dont have any formal education in engineering (yet :D) but i think i have had a reasonable (and original??) idea for powering electric cars and I was wondering if it could possibly work. Here goes...\n\n    My idea is to have some sort of magnets in an area of the wheels of the car which is rotating. And then to have some sort of coil surrounding it so that as the wheel spins a current would be induced in the wire.\n\n    I thought of this and wondered wether once the car gets moving (either through a combustion engine or electric etc.) would this current created bu the wheel movement be enough to keep the car running as an electric motor would.\n\n    There are probably some HUGE flaws in this, was just wondering what anyone thought. If it wouldnt work could you tell me why? (there are probably heaps of reasons so pick a biggy lol)\n\n    Thanks alot,\n  2. jcsd\n  3. Feb 18, 2008 #2\n    I thought hybrid cars already do something like this. But I'm not sure.\n  4. Feb 18, 2008 #3\n    on really? Anyone else know if this is the case?\n  5. Feb 18, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If you mean powering the car by an electric motor and driving the electric motor from a generator on the same wheel you are driving then this is a perpetual motion machine - good luck with that.\n\n    what electirc and some hybrid cars do is called regenerative braking.\n    Instead of using brakes to slow the car down (either because you are going down a hill or coming to stop) they run the motors as generators and put energy back into the battery. So the energy that would have been wasted as heat can be re-used.\n    Because this slows the vehicle it should be obvious why you can't use this as the only source of power.\n  6. Feb 18, 2008 #5\n    Yeh ok I see, I didn't know that was what happened in hybrids. Meh nevermind.\n  7. Feb 18, 2008 #6\n\n\n    User Avatar\n    Gold Member\n\n    Don't give up thinking about things just because that idea isn't Earthshaking. I doubt that any Science Advisor or Mentor on this site didn't do the same thing several times. You wouldn't believe some of the crap that I came up with in my younger years (and still do, once in a while). Keep up with the ideas; eventually, one of them will be great.\n  8. Feb 18, 2008 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I thought you were going to go on about how your idea for a perpetual motion was different to all the others and would work!\n  9. Feb 19, 2008 #8\n    Danger: I won't don't worry haha. When I was younger I hadn't heard of the magrail (is that what its called?) and was really excited that id come up with something brilliant until my dad told me it already existed.\n\n    Mgb_phys: I said i hadn't studied engineering yet, not that i was mentally retarded lol.\n\n    Also how do you quote more than one person??\n  10. Feb 19, 2008 #9\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Then you might like to join in the many, 'plane takign off from a conveyor belt' discussions :approve:\n    Don't worry most of us have brilliant ideas only to be told they are on page X of the catalogue.\n\n    You can just copy the text and put it inside \"[\"QUOTE\"]\" \"[\"/QUOTE\"]\" boxes\n  11. Feb 19, 2008 #10\n    Dont get me started on the plane conveyor belt thing... God that's annoying. I tried explaining why it would take off to a friend for about an hour. Still don't know if he gets it lol.\n\n    Thanks for the quote help :)\n  12. Feb 21, 2008 #11\n    Your talking about using the axles as the shaft essentially of the Generator? It would be like adding alternator/s along your shaft, so as your moving your generating a current. The thing is about generators, that they add load. So depending on the build of the Generator, it could be a great idea.\n\n    The reverse part, would need to have a relay that disconnects the Generator while reversing, (unless generators still produce a current if they run opposite rotation?, I'm not sure actually lol)\n\n    Also, if they brake, than you'd have to remove probably a few things (tires/brakes/hub/maybe upper/lower control arms/shocks/struts etc.\n\n    If you guys read his post more thouroughly he said\n    so Its not using the motor, and generator perpetual energy thought everybody has atleast once untill his 5th grade teacher drops a bomb on that little world and sends the poor kid back to the stone age.\n\n    Its like I said, he wants to use a different means to rotate that little shaft on the alternator, pretty much (to grosely simplify it). I would say the axle is not the worst place for it eh?!\n    Last edited: Feb 21, 2008\n  13. Feb 21, 2008 #12\n    about the perpetual motion thing... What i imagined this thing doing was keeping the car at constant speed, not accelerating. So i suppose you would use another meand of power aswell, but only to accelerate.\n\n    I think this is probably still perpetual motion though (because of friction and air resistance ??) so i think it is still impossible?\n  14. Feb 21, 2008 #13\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'm afraid so - friction is a real pain sometimes!\n\n    The big win for electric hybrids is for short periods at low speeds or stop/start driving.\n    This is especially good for large vehicles like buses and delivery trucks.\n    Petrol/Diesel engines aren't very efficent at low speeds while an electric motor generates it's highest torque at zero speed - so you can use a smaller internal combustion engine and an electric motor for starting to move.\n  15. Feb 22, 2008 #14\n    just to add a bit more, when you put a coil around the axle to produce current, that current also produce a reactive force against the stator magnet, so you need to provide more energy to keep the axle(rotor) rotating, and only if working at 100% efficiency you ll get the same energy back which you put as extra at the first place. so finally the result is an over solved problem(which i usually do).\n    but nevertheless, the fact that you thought of such things without studying about them is a great start. keep on\n  16. Feb 26, 2008 #15\n    Every car I've seen has 0% efficiency getting from point A and returning to point A. Some just use more gas doing it.\n  17. Feb 27, 2008 #16\n\n\n    User Avatar\n    Gold Member\n\n    The idea of an electric car as a viable alternative to fossil fuels should be killed, unless there is a shown gain in total energy usage, no matter what scheme is forwarded, electricity still has to be generated to charge these electric vehicles, even recycling the waste from the batteries may be more environmentally costly if not energy costly.\n  18. Feb 29, 2008 #17\n    But Wolram, the Electric Car will be a very useful device, fulfilling an important emotional niche to the eager consumer.\n\n    A recent and noteworthy commercial advertising a hybrid SUV indicates the importance among numerous consumers to be seen as dedicated to preserving the 'environment'.\n\n    In this particular commercial, our hero quietly goes about his tasks, never advertising the fact that his car is a hybrid. This frees the buyer of these cars from the humiliating task of blatently advertising their moral superiority themselves, as the commercial has done it for them.\n\n    They can safely maintain the myth that their actions are altruistic. Nothing is further from the truth, of course.\n\n    It doen't matter if these devices preform any useful task--or are even more damaging --to the rest of humanity, only that they be perceived do so by the greaterunwashed, in the never-ending quest to be seen as superior.\n\n    So how's your carbon footprint today?\n  19. Mar 10, 2008 #18\n\n\n    User Avatar\n    Gold Member\n\n    Not so fast with the dagger, there are two fundamental reasons why E cars are theoretically far superior to current vehicles. (1)The electric motor is a very good method of producing mechanical energy, 90 -95% efficient, plus you can recapture braking energy once you've introduced a means of storing energy (batteries). The best any heat based engine can ever do is ~40%. Yes the energy has to come from somewhere but thats also the case w/ existing cars. The point is you get far more miles per unit of energy w/ the E car, aka miles per gallon for existing cars. (2) The pure electric car has zero emissions to the atmosphere. Again, there will be emissions at the central power plant if its fossil, but those can be made much more efficient than cars and can have ellaborate means to capture the emissions, or the fossil plant may eventually become a renewables based or nuclear plant thus zero emissions. All of the solid parts any car, batteries whatever, have to eventually be recycled regardless of the car type so thats really a wash.\n\n    Problems: the battery technology is not quite there yet, and neither is the electric power generation and distribution required to run all E cars. Thus hybrids will be the way to go for sometime to come.\n    Last edited: Mar 10, 2008\n  20. Mar 10, 2008 #19\n    Turbo disels are competative with hybrids in gas milage. I imagine this is true with or without all the many other tweeks used to hybrid manufactures improve milage. Regenerative braking is nearly useless. In designing an electric vehicle, I've found I can recapture about 5%--maybe. In my application it isn't worth the extra luggage. And all this tweaking comes at a cost. The market forces would be a much better indicator of overall usefullness after subtracting the legislative bias.\n\n    Electric power distributed to your automobile by high tension wires from elsewhere is not as efficient as imagined. Great amounts of energy are lost in transmission and conversion. If cost is any indicator --and it should be if the environment of your friends, family, and community are included in your definition of \"the environment\", upon reciept it is less efficient than combustion. Ask anyone who has had the privilege of paying for an electric heating bill one winter and a gas bill the next in similar years.\n\n    Let's talk about the \"carbon foot print\" the \"environmental impact\", and the fuel efficiency of automobile storage batteries. Maybe you can answer some key questions. What's their lifetime? What's their enviromental impact on mining, producing, and displosal or recycling? What's their 'carbon footpring' in fossile fuel to produce them from the mine to the consumer? How much of their true value is hidden by governmental interference?\n\n    About the lifetime of these batteries. The auto dealers won't tell you what it is, or fewer would buy their cars. Sometime in the next couple of years, we will start getting these answers as they begin to fail. These things will cost a good chunk of change to replace. When the cost of replacement becomes better known the market, the resale value of the vehicle will plumet driving it's value toward scrap prices. What's the enviromental-impact-and-carbon-footprint on early retirement scrap?\n\n    That's just the batteries. For all the gadgetry to make a hybrid vehicle fuel efficient, one can ask the same questions.\n\n    Many of these question will apply to purely electric vehicles. As I've stated before, contemporarily it's really not important to the advocates that the answers to these questions wash-out in favor of electric powered vehicles or against, or the answers would be much more widely known. But what we find is the proponents don't really know the questions, let alone the answers. It seems more important to appear devout than be devout.\n\n    -deCraig, student of contempory anthropology\n  21. Mar 11, 2008 #20\n\n\n    User Avatar\n    Gold Member\n\n    Thats incorrect even now, and in the context of most electric cars to come w/ some hybrid backup its wildly incorrect.\n\n    Wildly incorrect. Regen. braking is also used in trains purely because it makes economic sense to so.\n\n    No. Power plants + E distribution is still more efficient than internal combustion.\n\n    As I said above, the batteries are not quite there yet. They're close and with a little more improvement E cars and other types of E transportation are likely to take off.\n\nHave something to add?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214315/norm-of-integral-operator-in-l1\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the norm of the operator $$ T\\colon L^1[0,1] \\to L^1[0,1]: f\\mapsto \\left(t\\mapsto \\int_0^t f(s)ds\\right) $$ ?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nLet $f\\in L^1([0,1])$. Then\n\n$$\\|Tf\\|_1=\\int_0^1 \\left|\\int^t_0 f(s) ds\\right| dt \\le \\int_0^1 \\int_0^1 |f(s)| ds dt = \\|f\\|_1$$\n\nThis shows $\\|T\\|\\le 1$. Setting $f_n(x)=n\\chi_{[0,1/n]}(x)$, we see $||f_n||_1=1$. Note that\n\n$$\\int^t_0 n\\chi_{[0,1/n]}(s) ds=\\left\\{\\begin{array}\\,1 & \\text{if}\\;t\\ge1/n\\\\ nt & \\text{if}\\;t<1/n\\end{array}\\right.$$ It follows that $$||Tf_n||_1=\\int^1_0\\int_0^t n\\chi_{[0,1/n]}(s)ds dt=\\int_0^{1/n}nt\\,dt+\\int_{1/n}^1 1\\,dt =1-\\frac{1}{2n}\\rightarrow 1\\;\\text{as}\\;n\\rightarrow\\infty. $$ Hence $||T||=1$.\n\nshare|improve this answer\nFor $f \\equiv 1$, I found $||Tf||_1=1/2$ and not $1$. Otherwise, $f(x)=e^x$ works. \u2013\u00a0 Seirios Oct 15 '12 at 16:46\nThanks for the answers! But by the definition of the norm of T as $\\Vert T \\Vert = \\sup_ {f \\in L^1[0,1],\\Vert f\\Vert_1=1} \\Vert Tf \\Vert_1$, I can't really see how $f=2$ works, nor can I see that using $f=e^x$ will work, since $\\Vert f \\Vert _1 \\neq 1$ for both of these cases. Is the definition I'm using wrong? \u2013\u00a0 Maethor Oct 15 '12 at 20:17\nWhat makes you think that your simple-minded estimate is anywhere near sharp? If you do just one step in your computation, you get $$ \\int_{0}^{1}\\left\\lvert\\int_{0}^t f(x)\\,dt\\right\\rvert\\,dx \\leq \\int_{0}^1 \\int_{0}^t \\lvert f(x)\\rvert\\,dx\\,dt $$ which is an integral over a triangular region. If you brutally replace $t$ by $1$ here, you will get an integral over a square, so your estimate will overshoot badly. I would suggest to think about $F(t) = \\int_{0}^t f(x)\\,dx$ and think about what differential equation it solves. You should get $2/\\pi$ as a final solution, unless I'm mistaken. \u2013\u00a0 commenter Oct 16 '12 at 2:27\n@Norbert: geeez, you're right... I was led astray by considering $f(x) = \\frac{\\pi}{2} \\cos{\\frac{\\pi x}{2}}$ as in the $L^2$-case. .@IHaveAStupidQuestion: Try $f_n = n \\chi_{[0,1/n]}$. This sequence will minimize the effect of charging the upper right triangle in your estimate and a computation shows that $\\lVert Tf_n\\rVert_{1} \\nearrow 1$. \u2013\u00a0 commenter Oct 16 '12 at 11:40\n@MattN. The operator $T$ is the Volterra operator. The trick to compute its norm in $L^2$ is to consider $S = T^\\ast T$. Then $\\lVert T\\rVert^2 = \\lVert T^\\ast T\\rVert$. Use that $S$ is compact and self-adjoint, so its norm is equal to its maximal eigenvalue. An eigenfunction $\\lambda f = T^\\ast T f$ is a solution to $f'' = - \\lambda f$ and this yields an ansatz that lets you compute the eigenvalues and eigenvectors of $S$ and thus its norm. \u2013\u00a0 commenter Oct 16 '12 at 13:22\nshow 18 more comments\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/12717/charging-12v-150ah-battery/12718\nText:\nTake the 2-minute tour \u00d7\n\nI want to charge a 12V battery of 150Ah with a solar panel. The solar panel specs is 12V, 25 Watt.\n\nCan anyone please provide me how to calculate that how much time it will take to charge the battery? Please provide the calculations and formulas.\n\nshare|improve this question\nCan someone migrate this to electrical.stackexchange and make sure people don't have to see this question asked here? \u2013\u00a0 Larry Harson Jul 24 '11 at 21:35\n@user2146 - at the level of understand how Ah, V, watts go together and how to model the time - it's physics. If they were askign for a specific charge circuit then it would be eeng \u2013\u00a0 Martin Beckett Jul 24 '11 at 22:49\n@user2146: in addition to agreeing with what Martin said, I'll mention that the best way to signal that you think a question should be migrated is to flag it. Commenting really doesn't help. I'm not sure why you seem to hate this question so much, anyway. \u2013\u00a0 David Z Jul 24 '11 at 22:55\nok, david and martin are right. I'll delete my comments to save clutter and david and martin can do the same \u2013\u00a0 Larry Harson Jul 25 '11 at 2:33\n@user2146 - no need it's a useful discussion to decide the level of questions here. consider it 'case law' ;-) \u2013\u00a0 Martin Beckett Jul 25 '11 at 3:24\nadd comment\n\n5 Answers\n\nup vote 3 down vote accepted\n\nWatts (electrical power) = Volts $\\cdot$ Amps, so 25W = 12V $\\cdot$ 2.1A\n\n150Amp Hour is the total capacity so 150amp $\\cdot$ 1hour, 1amp $\\cdot$ 150hours, or 2.1amp for 72hours.\n\nThat's in an ideal world of course, there are heating losses as you charge the battery, the voltage of the solar panel varies with the load and if you entirely empty a 12V lead acid battery you are likely to damage it. But basically you are looking at 10days of full sunshine\n\nshare|improve this answer\n+1 for remembering that most solar panels do not work at night \u2013\u00a0 Henry Jul 24 '11 at 23:45\nIt depends on the year, of course. One hour on a sunny day in winter is going to be pretty useless compared to one hour in summer. \u2013\u00a0 Larry Harson Jul 25 '11 at 2:36\n@Henry - well I was making the unproven assumption the OP wasn't in orbit! \u2013\u00a0 Martin Beckett Jul 25 '11 at 3:22\nadd comment\n\nThe answers you've got so far from Vladimir and Martin give you a good first-order approximation: power = current x voltage. Energy = power x time. So your 12V battery of 150Ah needs 1800Wh of energy (12 x 150). So a 25W PV panel would need 72 hours at full output (1800Wh/25W).\n\nThe equation is: Peak-hours required = $\\frac{V_{batt} \\times capacity_{batt}}{Power_{PV}} $\n\nThat's an unusual combination of quite a small panel and a very big battery - is the battery designed to be a multi-week store for a low-power system, by any chance?\n\nFor a more accurate answer, you need a lot more information.\n\nThe output of the panel at any moment will depend on:\n\n(1) the voltage, (which will be determined by the battery, and will change as the battery charges)\n\n(2) the ambient temperature, and\n\n(3) the amount light hitting the panel. The amount of light hitting the panel will depend on panel tilt, orientation, overshading, weather, altitude, location, time of year, time of day.\n\nFor (1), you need the panel IV curve, typically presented on the manufacturer's datasheet. That datasheet will also tell you how output varies with panel temperature. You can then estimate the panel's temperature from the ambient temperature - it will (to the first order) be a fairly steady amount above ambient.\n\nHere are some example power curves for a 12V PV (and it looks like it's approx 125W peak) panel, from altestore.com :\n\nPV panel I-V curve\n\nYou also need to know about the battery's characteristics as it charges: the heat losses, and how its voltage changes with temperature and % charged. In a more complex system that involves a controller too, you'd need to know how the controller behaves, how it tracks the maximum power point, and what its internal losses are. A controller is very desirable, not only because it will track the PV panel's maximum power point, but also because it will prevent the battery over-charging.\n\nThere are various online PV calculators that will combine some of this information to give you estimates of output, such as the US NREL PVWATTS calculator. And there are free online GIS insolation resources to give you the raw source information to do detailed calculations yourself, such as the EU PVGIS database.\n\nshare|improve this answer\nI think it's the combination of biggest standard pickup/SUV battery and largest (cheap) battery top-up solar panel \u2013\u00a0 Martin Beckett Aug 3 '11 at 4:23\nadd comment\n\n150 Amper*hour is the battery charge capacity. With power of 25 Watt = 25 A*V at V = 12 V you will supply 25/12 Coulomb each second (Amper*s). So the charge time is equal to 150/(25/12) = 72 hours.\n\nshare|improve this answer\nadd comment\n\nIn the simplest case, and some unmentioned assumptions, the minimum charging time would be given by the formula already mentioned: $$ T = \\frac{V \\times Ah}{W}$$ this gives 12x150/25 = 72 hours.\n\nHowever, this case makes at least two major assumptions, the battery is fully discharged and there are no losses of any kind!\n\nIn the real world, the battery will not be fully discharged and there are energy losses \"everywhere.\" Just to drive the point home, if the battery is already charged, then the time would be zero.\n\nA typical 12V battery is considered \"discharged\" when its voltage is reduced to 9V. This means it has lost only 1/4 of its energy. Everything else remaining the same, it would only need 1/4 of the time (18 hrs) to charge up. If we assume 50% efficiency, this would bring the time up to 36 hours. Assuming 8 hrs per day of sunshine, it would take about 4 days.\n\nshare|improve this answer\nadd comment\n\nYou need to know the implication of using a 25W panel, for me that is pretty small. The idea is 150Ah at 12 V (DC) we need to apply the 10hr charging method, so 10% of 150Ah gives 15A.$$\\frac{150\\,\\text{Ah}}{10\\,\\text h}=15\\,\\text A$$\n\nSo power of needed solar panel is computed as follows, $12\\,\\text V\\cdot15\\,\\text A=180\\,\\text W$. So the power of your panel is 180 W.\n\nshare|improve this answer\nThe 10% of 150ah is 15ah. \u2013\u00a0 jinawee Feb 2 at 12:48\nadd comment\n\nprotected by Qmechanic Apr 11 at 14:32\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/119655/how-many-permutations/119665\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to calculate the number of possible non-repeated permutations of these serial key styles.\n\nI have no mathematical background and cannot read formulas, which is why I'm struggling with other online literature about this.\n\nIf someone could either let me know how many for each, or how I might calculate it, I'd be very grateful.\n\nThe character set is 24 uppercase letters, and 8 numbers. (removing I, O, 0, 1)\n\n1) 7FB-E48-W60\n\n\n\n4) H6EFA-N6H7O-08WW8-0S4SC-4K4S8\n\nThanks very much.\n\n\nshare|improve this question\nYou say \"removing I, O, 0, 1$, but I see 0,1, and O in your examples. Do you mean these are examples without the restrictions? \u2013\u00a0 Thomas Andrews Mar 13 '12 at 12:39\nHi, Thomas. Sorry, these examples don't have those excluded, they're to demonstrate the grouping and length. The finished product would have those excluded. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:02\nHi, dtldarek. I struggle with simple multiplication and division when it involves odd numbers. I don't know what any of that stuff means. I was hoping for pointers on what to type into a calculator, or just the answer for each. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:07\nTo be specific, what do you mean by \"non-repeated\" and what do you mean by \"permutations of styles\"? \u2013\u00a0 dtldarek Mar 13 '12 at 13:08\nHi, Sorry that part was unclear. I'm choosing to adopt one of these, numbered 1, to 4 styles of codes to use as voucher codes to be printed on coupon cards to be sold in stores. I want to know how many of these \"keys\" or \"serials\" I could generate uniquely with the character set of 24 upper case letters and 8 numbers, by \"non-repeated\" I mean unique entire keys, but each key can contain the same character more than once. I'd prefer to use style 1, but if that only gives me 2 million possible serial keys, then I'd have to go for 2, etc... \u2013\u00a0 i-CONICA Mar 13 '12 at 13:15\nadd comment\n\n4 Answers\n\nup vote 2 down vote accepted\n  1. The dashes don't make any difference.\n  2. Your alphabet has 24 + 8 = 32 characters.\n  3. There are 32^n = 32 * 32 * 32 * ... * 32 * 32 (n times) different strings of length n using this alphabet.\n  4. Using your schemes:\n    1. 32^9 = 35184372088832,\n    2. 32^12 = 1152921504606846976,\n    3. 32^16 = 1208925819614629174706176,\n    4. 32^25 = 42535295865117307932921825928971026432.\n\nHave fun ;-)\n\nshare|improve this answer\nadd comment\n\nsince without repetition: (32 because 8+24)\n\n1- 32*31*30*29*28*27*26*25*24 = $\\frac{32!}{(32-9)}!$\n\n2- $\\frac{32!}{(32-12)}!$ \n\n3- $\\frac{32!}{(32-16)}!$ \n\n4- $\\frac{32!}{(32-25)}!$\n\nBut your example above shows repetition and I,O,0, & 1. I hope that is what you want.\n\nshare|improve this answer\nHi, Zeina. Sorry, I written the question a little confusingly. By \"non-repeating\" I mean how many of these keys could I generate uniquely. Each key can contain the same character more than once. I've left some notes on the question. Thank you for your time. \u2013\u00a0 i-CONICA Mar 13 '12 at 13:17\nadd comment\n\nIf, as you say in an earlier comment, characters can occur multiple times in a given serial number, then it's quite straightforward: the total number of serial numbers available for a key of length $k$ is $32^k$, where 32 is the size of your character set (24 letters and 8 digits).\n\nIn practice it's usually more complicated, though, since the serial key is generated in such a way that some information can be extracted from the key (most notably whether or not the key is valid, but also things like an identifier for the product and its version number).\n\nshare|improve this answer\nadd comment\n\nIn that case the probabilities become:\n\n1- $\\32^{9} = 35184372088832\n\n2- $\\32^{12}\n\n3- $\\32^{16}\n\n4- $\\32^{25}\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/516612/probability-of-getting-n-heads-after-cn-tosses\nText:\nTake the 2-minute tour \u00d7\n\nIf $X_n$ is the number of coin tosses to get $n$ heads, then how can one show that there exists a constant $c>1$ such that $P(X_n \\geq cn) \\leq 1/n$? I am looking for a direct elementary proof.\n\nAssume the coin tosses are fair and independent.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nSince $X_n$ is the sum of $n$ i.i.d. geometric random variables with parameter $\\frac12$, $E[X_n]=2n$ and $\\mathrm{var}(X_n)=2n$. Bienaym\u00e9-Chebychev inequality implies that, for every nonnegative $x$, $$ P[X_n\\geqslant E[X_n]+x]\\leqslant\\mathrm{var}(X_n)/x^2. $$ If $x^2=2n^2$, the RHS is $1/n$ and $E[X_n]+x=(2+\\sqrt2)n$ hence $c=2+\\sqrt2$ answers the question. Or, $$ P[X_n\\gt 4n]\\leqslant1/(2n). $$\n\nshare|improve this answer\nThank you. This would be a great answer but I was hoping, perhaps in vain, that there might be a proof that was elementary and entirely self contained. \u2013\u00a0 felix Oct 6 '13 at 16:43\nI suppose I could just incorporate a direct proof of en.wikipedia.org/wiki/\u2026 . \u2013\u00a0 felix Oct 6 '13 at 17:36\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/11778/insidious-exponential-integral/19300\nText:\nTake the 2-minute tour \u00d7\n\nI hope that someone's up for the challenge; I'm attempting to solve this via computer:\n\n\\begin{equation} \\int_{-\\pi}^\\pi{\\displaystyle \\frac{e^{i\\cdot a\\cdot t}(e^{i\\cdot b\\cdot t}-1)(e^{i\\cdot c \\cdot t}-1)}{(e^{i\\cdot t}-1)(e^{i\\cdot d \\cdot t}+1)(e^{i\\cdot f \\cdot t}-1)} \\dots dt} \\end{equation}\n\nI want to know if it's possible to break this up into simpler subproblems. You can use just about anything to do this, but there is one restriction. In computer science terms, I want this to be in $P$.\n\nLet me try to explain. I don't want the work I have to do grow exponentially. For instance, if I break up the integral into two integrals, I don't want to double the amount of work I have to do. I don't want to dramatically increase the amount of work I have to do by breaking things apart, I want to keep things fairly fast.\n\nEDIT I'd prefer to see integration techniques used for this.\n\nshare|improve this question\nHave you tried standard numerical integration methods? \u2013\u00a0 Yuval Filmus Nov 25 '10 at 2:59\n@Yuval:yes. They have potential; I'm not ruling them out if I can use them on subproblems. The main thing is that with these exponentials, everything seems to grow exponentially! Now I'm trying to see if breaking up the problem somehow can be competitive. \u2013\u00a0 Matt Groff Nov 25 '10 at 3:18\nYour integrand has a number of singularities; can you guarantee that the integral is even bounded? \u2013\u00a0 Rahul Nov 25 '10 at 3:32\nYes. It's gauranteed that it will integrate to a positive integer or zero. In fact, I'd be satisfied (really elated!) if I could simply determine if the result is nonzero or not. \u2013\u00a0 Matt Groff Nov 25 '10 at 3:51\nWhat does \"...\" mean? I'm not sure how the pattern would continue. \u2013\u00a0 Hans Lundmark Nov 25 '10 at 5:45\nshow 4 more comments\n\n2 Answers\n\nThis is at least as hard as the Number Partition Problem (or the related Subset Sum) and is probably equivalent. The Number Partition Problem is NP-Complete so the solution to such an integral is, in general, probably not polynomial time solvable.\n\nTo see that it's at least as hard, I will consider a special case of your integral. First notice that:\n\n$$ a_k \\in \\mathbb{N}, \\ \\ k \\in [ 0, 1, \\dots, n-1 ] $$\n\n$$ \\mathbb{I}_{\\sigma, a} = \\frac{1}{2 \\pi} \\int_{-\\pi}^{\\pi} e^{ i \\theta \\sum_{k=0}^{n-1} \\sigma_k a_k } d\\theta $$\n\nfor $ \\sigma_k \\in \\{-1, 1\\}$.\n\nNotice that $\\mathbb{I}_{\\sigma, a}$ will be 1 if the sum $\\sum_{k=0}^{n-1} \\sigma_k a_k = 0$. Otherwise $\\mathbb{I}_{\\sigma, a}$ will be 0. This gives us an indicator function to test whether the configuration is perfect or not.\n\nDefine $Z_a$ as follows:\n\n$$ Z_{ a } = \\int_{-\\pi}^{\\pi} \\prod_{k=0}^{n-1} ( e^{i \\theta a_k} + e^{- i \\theta a_k } ) d\\theta = \\int_{-\\pi}^{\\pi} e^{- i \\theta \\sum_{k=0}^{n-1} a_k } \\prod_{k=0}^{n-1} (e^{ 2 i a_k } + 1 ) d\\theta $$\n\nand notice that $Z_a$ also equals the sum of all indicator functions:\n\n$$ Z_a = \\sum_{ <\\sigma> } \\mathbb{I}_{\\sigma, a} $$\n\nwhere $<\\sigma>$ denotes all possible configurations of $ \\sigma_k \\in \\{ -1, 1\\}$.\n\n$Z_a$ counts the number of solutions and is a special case of the integral you presented above. Were you to produce an algorithm to evaluate your integral in polynomial time, it could be applied to the above integral not just showing that $ P = NP \\ $ but that the related counting problem is also in $P\\ $ ($ \\text{#} P = P $).\n\nWhile this means that you probably cannot produce a polynomial time algorithm (in general) to solve your integral, it also means that you can probably adapt algorithms used to solve the Number Partition Problem (or Subset Sum) to provide a solution to the original integral. For the integral you presented there is a (what appears to me) small hurdle of having the denominators being other than one, but perhaps you could simplify by using continued fractions.\n\nTo my knowledge, the current 'state of the art' algorithm in solving the Number Partition Problem is the Complete Karmarkar Karp algorithm (CKK). See here, here and here for discussions and descriptions.\n\nIf you want further reference on the Number Partition Problem and its integral representation, see Borgs, Chayes and Pittel's paper \"Phase transition and finite-size scaling for the integer partitioning problem\".\n\nshare|improve this answer\nMatt happens to be attempting to use analytic techniques to solve P vs. NP, so I'm not surprised that this is true. \u2013\u00a0 Qiaochu Yuan Jan 28 '11 at 0:04\nadd comment\n\nWhy don't you try complex integration ?. $\\large z \\equiv {\\rm e}^{{\\rm i}t}$. In order to accomplish this task we need to know anything about the constants $\\left(a, b, \\ldots\\right)$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/138368/function-space-inner-product/138552\nText:\nTake the 2-minute tour \u00d7\n\nLet $u,v$ be arbitrary elements of a function space $X$ defined on $\\Omega \\subset \\mathbb{R}^n$. Define\n\n$$ (u,v)_2 = \\int_\\Omega \\partial_x u \\, \\partial_x v + \\partial_y u \\, \\partial_y v \\:dx $$\n\nNow, my question is what should $X$ be so that $(\\cdot,\\cdot)_2$ defines an inner product?\n\nIt is clear that $(\\cdot,\\cdot)_2$ is symmetric and linear but the problem seems to be positive-definitiveness.\n\nshare|improve this question\nIn particular, $(u,u)_2 = 0$ for every constant function $u=c$. \u2013\u00a0 chango Apr 29 '12 at 9:25\nHint: $(u,u)_2=\\int_\\Omega |\\nabla u|^2$. Hence the only constant function in $X$ must be $0$. Anyway, the most used choice is $X=W_0^{1,2}(\\Omega)$. But you can also think of a space of functions $u$ with $\\int_\\Omega u=0$. \u2013\u00a0 Siminore Apr 29 '12 at 9:43\nOk, so $X=W_0^{1,2}(\\Omega)$ is the space of functions in $H^1(\\Omega)$ which vanish on $\\partial \\Omega$. And I have that $(u,u)_2=0$ implies that $u$ is constant a.e. But how do I conclude from that that $c=0$? \u2013\u00a0 chango Apr 29 '12 at 10:50\nSince $u$ vanishes on $\\partial \\Omega$. Actually, by Poincar\u00e9's inequality, $\\int_\\Omega |\\nabla u|^2 =0$ implies $\\int_\\Omega |u|^2=0$. This is a more refined viewpoint. \u2013\u00a0 Siminore Apr 29 '12 at 11:26\nadd comment\n\n2 Answers\n\nThe norm involving the inner product of the first derivative shall be associate with the Sobolev norm for the space $W^{1,2}(\\Omega)$, in which the elements and their weak derivative are both $L^2$-integrable. And as you mentioned in the comment, the fact that having constant plugging in would make the inner product be zero makes the induced \"norm\" only a semi-norm, we denote it as $|\\cdot|_{W^{1,2}(\\Omega)}$\n\nSo Here what we wanna do is to find $X$ such that this semi-norm behaves the same as the full $W^{1,2}(\\Omega)$-norm on $X$, ie, we want to quotient the kernel of $\\nabla$ out to get an equivalence class $W^{1,2}(\\Omega)/ \\mathbb{R}$, there are normally two ways to do this:\n\n  \u2022 For every element $u\\in W^{1,2}(\\Omega)$, consider the new space for $\\displaystyle \\bar{u} = u - \\frac{1}{|\\Omega|}\\int_{\\Omega} u $, and we have $\\displaystyle \\int_{\\Omega} \\bar{u} = 0$, naming this equivalence class as space $\\mathring{H}^1(\\Omega) = X$, then by Poincar\u00e9 inequality, for any $w\\in \\mathring{H^1}(\\Omega)$: $$ \\|w \\|_{L^2(\\Omega)}\\leq C\\|\\nabla w \\|_{L^2(\\Omega)} $$ hence $$ |w |_{W^{1,2}(\\Omega)} \\leq \\|w \\|_{W^{1,2}(\\Omega)}\\leq(1+ C)|w |_{W^{1,2}(\\Omega)} $$ we have the norm equivalence, and this construction is normally associated with the Pure Neumann problem for the second order elliptic PDEs.\n\n  \u2022 Another construction is we set the boundary value to be zero like $H^1_0 = X$ like you said, and use Friedrichs' inequality(Poincar\u00e9 inequality's counterpart for zero-trace functions), we could get the same norm equivalence relation above whereas the geometry constant $C$ might be different. This space relates to the Dirichlet problem for Poisson equation.\n\n  \u2022 We also could have a mixed version of above two which associates to the following problem $$ \\left\\{ \\begin{aligned} -\\Delta u &= f &\\text{ in } \\Omega \\\\ u &= g &\\text{ on } \\Gamma_D\\subset \\partial \\Omega \\\\ \\nabla u\\cdot \\boldsymbol{n} &= g_N &\\text{ on } \\Gamma_N\\subset \\partial \\Omega \\end{aligned} \\right. $$ Define the space $X = H^1_{g}(\\Omega) = \\{u\\in H^1(\\Omega): u = g \\text{ on } \\Gamma_D\\}$, if the Dirichlet boundary is not empty, $|\\cdot|_{W^{1,2}(\\Omega)}$ is a norm too.\n\nshare|improve this answer\nadd comment\nup vote 0 down vote accepted\n\nOk, so from what I gather on the basis of Siminore's comments:\n\n$X=H_0^1$ and using Poincare's inequality we have that\n\n$$ \\|u\\|_{L^2}\\leq C \\| \\nabla u \\|_{L^2}. $$\n\nHence $(u,u)_2=\\| \\nabla u \\|_{L^2}=0$ implies $u=0$ a.e.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/239441/properties-of-the-unit-normal-to-a-partially-rotated-hyperplane?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be an $n-1 \\times n$ matrix. The span of the rows of $A$ define a hyperplane in $\\mathbb{R}^n$; let $u$ be the unit normal to this hyperplane.\n\nNow, let $x \\in \\mathbb{R}^{n-1}$, and replace each element $A_{i1}$ in the first column of $A$ with a variable term $A_{i1}cos(\\theta) - x_i sin(\\theta)$; let $u(\\theta)$ be the resulting unit normal (thus, $u(0) = u$).\n\nSuppose we slide $\\theta$ up from $0$ continuously, and stop if/when $u_k(0) - u_k(\\theta) = \\Delta$ for some index $k \\in \\{1, \\dots, n\\}$. In terms of $A$, $x$, $k$, and $\\Delta$, how far can we slide $\\theta$?\n\nEDIT: I've managed to reduce the problem to a possibly simpler one. If we delete column $k$ from the modified matrix, then can we find an analytic form for its determinant? In other words, what is $\\det(A_{*,\\sim k}, \\theta)$?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nLet $A_{\\star,\\tilde{k}}$ be your matrix of interest (the sub-matrix from removing column $k$). Let it have determinant of $d$. Also let $\\mathbf{u}^\\top$ be the first row of the inverse for the matrix. Call the first column of the matrix $\\mathbf{y}$. Then the determinant is $d\\mathbf{u}^\\top\\mathbf{y}$. If $\\mathbf{y}$ is altered while keeping the rest of the matrix, then the determinant still has the same form but with the new column in place of $\\mathbf{y}$: $$d_{new}=d\\mathbf{u}^\\top\\left(\\mathbf{y}\\cos\\theta-\\mathbf{x}\\sin\\theta\\right) = d\\left(\\cos\\theta-\\mathbf{u}^\\top\\mathbf{x}\\sin\\theta\\right)$$ since from the definition of inverse we have that $\\mathbf{u}^\\top\\mathbf{y} = 1$. Thus your variation on $\\theta$ (from $0$ to $\\pi$) gives a determinant ranging from $d$ to the quantity of $-d\\mathbf{u}^\\top\\mathbf{x}$ where $\\mathbf{x}$ is the vector of elements $x_i$.\n\nMy notation of $\\mathbf{u}$ here is different than your $u(\\theta)$. The point is that the determinant of your altered matrix will take the form of a dot product with $\\mathbf{u}$ and the altered column of the matrix. This is simply known to me and may be more difficult to show you in proof form, I hope this helps regardless.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/202630/product-of-3-integers-is-72-find-the-3-integers-that-give-the-smallest-sum\nText:\nTake the 2-minute tour \u00d7\n\nProduct of 3 integers a, b, c equals 72, where every factor is positive integer. Find the integers a, b, c with the smallest sum.\n\nIt's easy to get the factors of 72 manually and see that the 3 smallest factors that give the product as 72 will be the smallest sum.\n\nI checked the factorization like this:\n\n1-1-72: 74\n1-2-36: 39\n1-4-18: 25\n1-8-9:  18\n2-4-9:  15\n3-4-6:  13\n\nIt seems like the smallest possible factors will give the smallest sum.\n\nBut there must be some trick to it or some kind of algorithm to find the smallest integers for any arbitrary product without laborious factoring.\n\nThanks for your help.\n\nshare|improve this question\nThe factors must be close to each other. A heuristic: The AM-GM inequality gives us $(a+b+c)/3 \\geq \\sqrt[3]{abc}$ where equality holds when $a=b=c$ and the difference between the LHS and RHS increases when $a$, $b$ and $c$ are far apart from each other. \u2013\u00a0 user17762 Sep 26 '12 at 5:00\nYes @Marvis is right: And 3-4-6 are the closest number in this case. \u2013\u00a0 Sumit Bhowmick Sep 26 '12 at 6:15\nOne algorithm might be to find the factor of $72$ closest to $\\sqrt[3]{72}$, which is $4$. Then find the factor of $72/4=18$ closest to $\\sqrt[2]{18}$, which is $3$. That leaves $18/3=6$. I don't know if it is always optimal, but it should be close to optimal. \u2013\u00a0 Henry Sep 26 '12 at 7:40\n@Graphth: Lagrange multipliers don't work when you need integer solutions. \u2013\u00a0 TonyK Nov 19 '12 at 15:34\n\n1 Answer 1\n\nYou could try decomposing $72$ into its prime factors. This is:\n\n$$72 = 2^3\\times 3^2 = 2*2*2*3*3.$$\n\nThen pick the smallest combination of factor, which is $2\\times 2$, $2\\times 3$ and $3$, so that $4\\times 6\\times 3 = 72$, and $4 + 6 + 3 = 13$.\n\nHope it helps.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/258204/finding-a-pythagorean-triple-a2-b2-c2-with-abc-40\nText:\nTake the 2-minute tour \u00d7\n\nLet's say you're asked to find a Pythagorean triple $a^2 + b^2 = c^2$ such that $a + b + c = 40$. The catch is that the question is asked at a job interview, and you weren't expecting questions about Pythagorean triples.\n\nIt is trivial to look up the answer. It is also trivial to write a computer program that would find the answer. There is also plenty of material written about the properties of Pythagorean triples and methods for generating them. However, none of this would be of any help during a job interview.\n\nHow would you solve this in an interview situation?\n\nshare|improve this question\nI personally have memorized most of the small Pythagorean triples (this one, for example, is 8, 15, 17). \u2013\u00a0 Joe Z. Dec 13 '12 at 20:36\ntbh, I bet they were testing your ability to admit that you didn't have the tools to solve it right there in the limited amount of time. I highly doubt they wanted you to know the answer. \u2013\u00a0 picakhu Dec 13 '12 at 20:41\nIt certainly helps to know the formula for general relatively prime triples, since you can solve for any triple such that $a+b+c$ divides 40 and then multiply to get a triple with $a+b+c=40$. \u2013\u00a0 Thomas Andrews Dec 13 '12 at 20:41\n\n5 Answers 5\n\nup vote 8 down vote accepted\n\nAssuming you do have a pen and paper, you could substitute $c = 40 - a - b$ into the first equation to get\n\n$$a^2 + b^2 = (40 - a - b)^2 = a^2 + b^2 + 1600 - 80(a + b) + 2ab.$$\n\nRewriting this equation, you get\n\n$$a + b - 20 = \\frac{ab}{40}.$$\n\nFrom this it follows that $ab$ has to be a multiple of $40$, i.e., one of them is a multiple of $5$. That narrows it down to only a few options...\n\nIf that's still too much brute-force, you could also note that $a + b > 20$ from the above equation, and $a + b < 27$, since $c$ has to be the largest of the three. This leaves only the three pairs\n\n\nLooking at the earlier equation, you see the third pair is the right one.\n\nshare|improve this answer\nOr you can rewrite that as $ab=40a+40b-800$ or $(a-40)(b-40)=800$. Given that you know $0<a,b<40$, this shouldn't be too hard to work out. \u2013\u00a0 Thomas Andrews Dec 13 '12 at 20:46\n@thomas, you know better, you know 0<a,b<20 \u2013\u00a0 picakhu Dec 13 '12 at 20:48\n@Thomas: Yes, that should work too. Still, at some point you will have to guess $a$ and $b$ I think. \u2013\u00a0 TMM Dec 13 '12 at 20:55\nThis is exactly the sort of thing I was looking for. Thank you! \u2013\u00a0 NPE Dec 14 '12 at 7:09\n\nThe general pythagorean triple can be written (up to swapping $a$ and $b$) as $$a=2kuv$$ $$b=k(u^2-v^2)$$ $$ c=k(u^2+v^2)$$ where $k,u,v$ are positive integers, $u,v$ are relatively prime with different parity and $u\\geq v$. For $a+b+c=40$, then, you get the condition $2k(u^2+uv)=40$, so you need $u^2+uv=u(u+v)$ to be a factor of $20$. Since $u,v$ have different parity, and they are positive, you know $u+v>1$ is odd, so $u+v=5$.\n\nGiven that $u\\geq v$, that yields $u=4,v=1$ and $u=3,v=2$. But $u=3$ isn't possible, since $3$ is not a factor of $20$. So The only solution is $(u,v)=(4,1)$ and therefore the only solution is $k(15,8,17)$ which you can see must have $k=1$, and you are done - the only solution is $(15,8,17)$. And $(8,15,17)$, if you count that as different.\n\nFor the more general problem, $a+b+c=2n$ (the sum of a Pythagorean triple is always even) this amounts to factoring $n=kuw$ with the following conditions:\n\n  \u2022 $k,u,w$ are positive in\n  \u2022 $w$ is odd\n  \u2022 $u<w<2u$\n\nGiven such a solution, you get a triple (by setting $v=w-u$:) $$a=2ku(w-u)$$ $$b=kw(2u-w)$$ $$c=k(2u^2+w^2-2uw)$$\n\nAnd this gives all such triples (modulo swapping $a$ and $b$.)\n\nListing these amounts to first listing the set of possible values of $w$, which can be any odd factors of $n$ such that $1<w<\\sqrt{2n}$. Then find values of $u$ with $w/2<u<w$ and $uw|n$. Then set $k=n/uw$ and you have your triple $(k,u,w)$ from which you can compute an $(a,b,c)$.\n\n(If you want to allow $ab=0$, the change the above to $u\\leq w < 2u$. Then $u=v=1$ and $k=n$ is always a solution.)\n\nshare|improve this answer\n\nThis is a rect triangle with a length of 40. for example triangle (3,4,5) with a length of 12, you can get the solution: (120/12,160/12,200/12). the point is that you know some patterns in advanced. (5,12,13) etc...\n\nshare|improve this answer\nThe solution you give is not integer. \u2013\u00a0 Martin Argerami Dec 13 '12 at 22:56\nThe term \"Pythagorean triple\" is used only for integer solutions to $a^2+b^2=c^2$ \u2013\u00a0 Thomas Andrews Dec 14 '12 at 14:25\n\n$$a^2=(c-b)(c+b) \\Rightarrow b+c = \\frac{a^2}{c-b}$$\n\n\nFor simplicity let $c-b=\\alpha$.\n\n\n$$a^2+\\alpha a-40\\alpha =0$$ Since this equation has integral solutions,\n\n$$\\Delta=\\alpha^2+160 \\alpha$$\n\nis a perfect square.Thus\n\n$$\\alpha^2+160 \\alpha =\\beta^2$$\n\n\n$$(\\alpha+80)^2=\\beta^2+80^2 \\,.$$\n\nThis way we reduced the problem to finding all pytagorean triples of the type $(80, ??, ??)$. This can be easily done if you know the formula, or by setting\n\n$$80^2=(\\alpha+80-\\beta)(\\alpha+80+\\beta)$$ and solving.\n\nshare|improve this answer\n\nIn practical, I will first solve this problem by assuming a=b. This gives approximately (11.72,11.72,16.56), then I try all possible ways around this solution. I can first assume the largest side is 17, then try (12,11),(13,10),(14,9),(15,8).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/71040/marble-game-theory\nText:\nTake the 2-minute tour \u00d7\n\nIn a game, there exist three piles of marbles, each pile with ,a,b, and c marbles respectively, where a,b,c are natural numbers and all different. At each turn, you can double the number of marbles in one pile by transporting marbles from one other larger pile (relative to the pile that is going to be doubled, before the doubling). The game is won when any two of the piles have an equal number of marbles.\n\nEither show that the game can be won from any starting a,b,c, or prove that this is not the case. (In particular, prove that the game cannot be won from every starting a,b,c.)\n\nAn interesting one, but the solution come does not.\n\n\nshare|improve this question\n\n2 Answers 2\n\nA duplicate of this question, Emptying buckets by moving pebbles around, was asked (and, interestingly, received a lot more upvotes than this one). Before Brian pointed out that it was a duplicate, I came up with a solution different from the shortlist solution. (I treat the problem of emptying one of the piles, which, as discussed in Phira's answer and comments, is equivalent.)\n\nThe idea is to successively produce $0$s in the binary representations of two of the numbers, starting with the least significant bit. So assume that the last $k$ bits of $b$ and $c$ are already zero; then if neither $b$ nor $c$ is zero yet, our aim is to make the last $k+1$ bits of two of the numbers zero.\n\nSo consider the $(k+1)$-th bits of $b$ and $c$. If they're both $0$, we're done. If they're both $1$, we just need one transfer between $b$ and $c$ to make them both $0$. If one is $0$ and one is $1$, we can put the $1$ in the lesser of the two by transferring from the greater to the lesser until it becomes the lesser.\n\nWithout loss of generality, assume $b\\lt c$. Now there are two cases. If $a\\ge b$, we can get rid of the $1$ by a transfer from $a$ to $b$. Otherwise, $a\\lt b\\lt c$, and we transfer first from $b$ to $a$ and then from $c$ to $b$, thus going from $a,b,c$ to $2a,b-a,c$ to $2a,2(b-a),c+a-b$. Now the sum of the first two numbers is $2b$, which has $0$s in the last $k+1$ bits, so we can make the last $k+1$ bits of those two numbers $0$ by making transfers between them, each of which gets rid of their last $1$ bits.\n\nIf we initially assign $a$, $b$ and $c$ such that $a$ has the fewest final zeros, this strategy seems to be slightly more efficient than the shortlist strategy: Compared to the total of $103505$ transfers minimally required to solve all distinct instances with totals less than $100$, this strategy makes $172865$ transfers while the shortlist strategy makes $190994$.\n\nshare|improve this answer\nThe $2b$ trick is nice. ($2b$ or $\\lnot 2b\\dots$) \u2013\u00a0 Brian M. Scott Dec 8 '11 at 21:33\n:-) ${}{}{}{}{}$ \u2013\u00a0 joriki Dec 8 '11 at 21:39\n\nIf you start with 0,1,2 it does not work.\n\nFor strictly positive numbers this is essentially problem C3 of the IMO shortlist 1994 where we want to empty an account in the same situation. (Because you have to have two equal amounts before an amount can get zero.)\n\nThere are several websites that offer shortlist solutions, for example:\n\n\nI don't know if I am supposed to copy a solution here.\n\nshare|improve this answer\nPresumably, \"natural numbers\" here is meant to exclude 0 (pretty common usage). \u2013\u00a0 Alon Amit Oct 9 '11 at 8:54\nFor natural number read positive integer. It\u2019s a regrettably common usage. \u2013\u00a0 Brian M. Scott Oct 9 '11 at 9:02\nPositive is also not always advisable as there are languages/countries where 0 is positive and negative. \u2013\u00a0 Phira Oct 9 '11 at 9:09\n@Brian M.Scott Note that the IMO problem has two parts. The first part is about emptying just one of the three accounts which is exactly equivalent to making two accounts the same size. \u2013\u00a0 Phira Oct 10 '11 at 7:22\nYou\u2019re right. $\\quad$ \u2013\u00a0 Brian M. Scott Oct 10 '11 at 7:42\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/76472/inverted-factorial-and-trailing-zeros-problem\nText:\nTake the 2-minute tour \u00d7\n\nFirst than anything a big Hello for all math fans like me.\n\nI've found a problem that is pretty interesting and I can't find the answer. As all of you must know, to counting the trailing zeros of $n$ factorial goes by this formula:\n\n$$c = (n/5)+(n/25)+(n/125)+(n/5^q)$$\n\nNow the problem is the following:\n\nWhat happen if the problem is in the other side, you have $c$ number of trailing zeros and you want to know the first $n$ that its $n!$ has $q$ trailing zeros, how can it be done?, I've searched a lot and I can't reach a solution. Is there an approach that I'm missing or something?\n\nThanks in advance and sorry about my English and my lack of Latex, but I'm already learning :D\n\nshare|improve this question\nI guess that $q$ is the floor of $\\log_5 (n)$. So it amounts to inverting the above function. There might not be a nice closed form for this, but I'd guess that you can write program to do this quickly. \u2013\u00a0 Tony Huynh Sep 27 '11 at 6:11\nI guess that $(m)$ refers to the floor function $\\lfloor m\\rfloor$, and that some dots are missing between the $125$ term and the $5^q$ term. Use $\\backslash\\text{lfloor}$, $\\backslash\\text{rfloor}$ and $\\backslash\\text{cdots}$. \u2013\u00a0 Did Sep 27 '11 at 6:29\nI looked at this too quickly to check the following but it seems that $\\frac16n-\\log_5n\\le c\\le\\frac16n+\\log_5n$, hence $x\\le n\\le y$ where $x=6c-6\\log_5x$ and $y=6c+6\\log_5y$. \u2013\u00a0 Did Sep 27 '11 at 6:39\nPlease replace every $6$ by $4$ in my previous comment. Sorry. \u2013\u00a0 Did Sep 27 '11 at 7:28\nThe number of trailing zeros in $n!$ is at oeis.org/A027868 -- perhaps some of the facts about the sequence given there can be inverted to give what you want. \u2013\u00a0 Michael Lugo Sep 27 '11 at 16:05\n\n2 Answers 2\n\nConsider the mixed radix representation of a positive integer using the bases 1, 6, 31, 156, 781, ... defined recursively by $b_n = 5b_{n-1}+1$, or in closed form as the sequence $(5^n-1)/4$. For example, the mixed radix representation of 2011 is <22421>, since $2011 = 2\\cdot 781 + 2\\cdot156 + 4\\cdot 31+2\\cdot 6+1\\cdot 1$. All the digits in this representation are 0, 1, 2, 3, or 4, except that a number can have 5 as a digit if all digits after the 5 equal 0; for example, the mixed radix representation of 2028 is <22450>, the mixed radix representation of 2029 is <22500>, and the mixed radix representation of 2030 is <23000>.\n\nThe point of defining this mixed radix representation is as follows: if $n$ is written in base 5 as $n = [d_kd_{k-1}\\cdots d_1d_0]_5$, then the number of trailing zeros in $n!$ is equal to the integer whose mixed radix representation is <$d_kd_{k-1}\\cdots d_1$> (note the omission of $d_0$).\n\nTherefore we can invert the function - that is, given the number $c$, we can find the smallest integer $n$ such that $n!$ has $c$ trailing zeros - as follows. Write $c$ in mixed radix representation; then append a zero to that string of numbers; then convert the string of numbers to a base-5 integer.\n\nFor example, with $c=2011={}$<22421>, the first integer $n$ such that $n!$ has $c$ trailing zeros is $n = [224210]_5 = 8055$. (Of course, the set of such integers $n$ is then precisely {8055,8056,8057,8058,8059}.)\n\nOne must be a little careful if the mixed radix representation of $c$ contains the digit 5: that means that there is no integer $n$ such that $n!$ has exactly $c$ trailing zeros. But we can find the smallest integer $n$ such that $n!$ has at least $c$ trailing zeros by \"carrying\" the 5s to the left.\n\nFor example, with $c=2028={}$<22450>, we rewrite $[224500]_5 = [225000]_5 = [230000]_5$, and so $n=[230000]_5= 8125$ is the smallest integer such that $n!$ contains at least 2028 trailing zeros; in fact, thanks to the 2 carries, $n!$ actually contains <23000>${}={}$2030 trailing zeros.\n\nshare|improve this answer\n\nAn article in GanitCharcha (www.ganitcharcha.com) will help you and have discussed on your question. Look at Problem 2 here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/60510/top-degree-local-cohomology-under-action-by-a-non-zerodivisor\nText:\nTake the 2-minute tour \u00d7\n\nLet $R$ be a noetherian commutative ring of dimension $n$, and let $M$ be a faithful finite $R$-module. Let $I$ be a proper ideal of $R$, and let $x\\in I$ be a non-zerodivisor on $M$.\n\nWhen does multiplication by $x$ induce an injection $H^n_I(M)\\hookrightarrow H^n_I(M)$?\n\nshare|improve this question\nThe local cohomology modules are $I$ torsion, so multiplication by $x$ will actually be the $0$ map. \u2013\u00a0 Hailong Dao Apr 4 '11 at 1:44\nUh-oh! Really? \u2013\u00a0 Harry Gindi Apr 4 '11 at 2:01\nNot necessarily the zero map, but definitely not injective. For example, when $M = R$ is a Gorenstein local ring and $I = m$ is the maximal ideal, the top local cohomology is the injective hull of $R/m$, which is $m$-torsion. \u2013\u00a0 Graham Leuschke Apr 4 '11 at 2:38\n@Harry: The $I$-torsionness follows from the fact that there is an isomorphism ${\\rm H}^i_I(M) = \\varinjlim_d {\\rm Ext}^i_R(R/I^d, M)$ \u2013\u00a0 Steven Sam Apr 4 '11 at 2:41\nGraham was right, let me give a careful answer then. \u2013\u00a0 Hailong Dao Apr 4 '11 at 4:37\n\n1 Answer 1\n\nup vote 6 down vote accepted\n\nGraham was right, the map is not necessarily $0$ as I wrote in the first comment. However, it is true that $H_I^n(M)$ is $I$-torsion, so it will be injective if and only if $H_I^n(M)=0$.\n\nAmusingly, I will observe that the map is actually surjective.\n\nApply $\\Gamma_I(-)$ to the sequence:\n\n$$ M \\stackrel{x}{\\to} M \\to M/xM$$\n\nto get $$ \\to H_I^n(M) \\stackrel{x}{\\to} H_I^n(M) \\to H_I^n(M/xM) \\to $$\n\nNow note that $\\dim M/xM < \\dim M = n$ because $x$ is $M$-regular, so $H_I^n(M/xM) = 0$. (In general, $H_I^n(N) =0 $ for $n>\\dim N$). So the multiplication by $x$ map is surjective, as claimed (may be this is what you had in mind anyway).\n\nFor completeness, the question of when $H_I^n(M) =0$ is rather subtle. It will be true, for example, if $I$ can be generated up to radical by at most $n-1$ elements, because you can calculate local cohomology using the Cech complex on those elements.\n\nAnother instance is when $R$ is a complete local domain, and $\\dim R/I>0$ (this is known as the Hartshorne-Lichtenbaum vanishing theorem). I do not know an easy equivalent condition off the top of my head.\n\nshare|improve this answer\nHeh, for what it's worth, I already knew it was surjective by that exact argument =). \u2013\u00a0 Harry Gindi Apr 4 '11 at 4:57\n@Harry: I am glad you agree! \u2013\u00a0 Hailong Dao Apr 4 '11 at 5:02\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/197567/metric-in-riemannian-manifold\nText:\nTake the 2-minute tour \u00d7\n\nLet $(M,g)$ be a riemannian Manifold, we can use the metric $g$ to obtain a metric $d_g:M\\times M\\to \\mathbb{R}$.\n\nI ask for a kind of converse, we can start with a metric $d:M\\times M\\to \\mathbb{R}$ and ask when we can recover a metric $g$ such that $d=d_g$. What obstructions need to be required on $d$ so the answer is positive, at least necessary?\n\nshare|improve this question\nYou'll want $M$ to be at least path connected, otherwise $d_g$ is not well-defined. Note that $(d_g)^2$ is always smooth when defined, so if you remember the smooth structure on $M$ that's one necessary condition on $d$. Another obvious one is that $d$ must induce the right topology on $M$ \u2013 so this rules out e.g. the discrete metric. \u2013\u00a0 Zhen Lin Sep 16 '12 at 14:57\nI think for any two points $x$, $y$ there must exist a rectifiable path from $x$ to $y$ whose length (determined using $d$) is exactly $d(x,y)$. What I'm sure is that at least the infimum of all path lengths from $x$ to $y$ must be $d(x,y)$. \u2013\u00a0 celtschk Sep 16 '12 at 15:26\n@celtschk The second part is correct: every Riemannian manifold is a length space: $d$ is the infimum of lengths of connecting curves. If $M$ is also complete, then the first property holds as well ($M$ is a geodesic space), by the Hopf-Rinow theorem. Without completeness it's not true: consider the plane minus a point. \u2013\u00a0 user31373 Sep 17 '12 at 0:05\nadd comment\n\n1 Answer\n\nIf you are given a metric $d_g$ induced by a Riemannian metric $g$, then you can reobtain $g$ in the following way: I will wlog assume that $(M,g)$ is embedded in Euclidean space with $g$ the induced metric (this could be avoided, but the calculations might be messier).\n\nFix $p\\in M$ and let $v\\in T_pM$ be arbitrary. Then there exists a smooth path $\\gamma: \\mathbb R \\to M$ such that $\\gamma(0) = p$ and $\\dot \\gamma(0) = v$. Now we use the fact that\n\n$$\\lim_{q\\to p} \\frac{d_g(p,q)}{|p-q|} = 1$$\n\nin the embedded setting (here $|\\,\\cdot\\,|$ denotes Euclidean distance). This implies that\n\n$$\\lim_{t\\to 0} \\frac{d_g(p,\\gamma(t))}{t} = \\lim_{t\\to 0} \\frac{d_g(p,\\gamma(t))}{|p-\\gamma(t)|} \\frac{|p-\\gamma(t)|}{t} = \\lim_{t\\to 0} \\frac{|tv + O(t^2)|}{t} = |v| = \\sqrt{g_p(v,v)}$$\n\nSo if $d_g$ comes from a Riemannian metric, then we can recover the length of vectors via\n\n$$\\Vert v \\Vert_{g(p)} = \\sqrt{g_p(v,v)} = \\lim_{t\\to 0} \\frac{d_g(p,\\gamma(t))}{t}$$\n\nNote that although the proof used a (hypothetical) isometric embedding of $M$ into Euclidean space, the resulting formula is purely intrinsic. Furthermore, it follows from the polarization identity that this determines $g_p$ uniquely (if it exists).\n\nThus, given an arbitrary metric $d$ on your manifold, you can in principle use the above expression (together with the polarization identity) and check whether it determines a smooth Riemannian metric $g$ on your manifold as you vary $p$. If it does determine a Riemannian metric $g$, then it would at least seem plausible if the associated metric $d_g$ where $=d$.\n\nAdd.: Indeed, suppose this is the case. I.e. let us assume that we can define $\\Vert v\\Vert_{g(p)}$ as indicated above, that this norm varies continuously on $M$ and that it is induced by an inner product. Then for an arbitrary curve $\\gamma: [a,b]\\to M$ and a partition $a=t_0<t_1 <\\dots < t_n = b$ of $[a,b]$, we get\n\n$$\\sum_{i=1}^n d(\\gamma(t_i),\\gamma(t_{i-1})) = \\sum_{i=1}^n \\frac{d(\\gamma(t_i),\\gamma(t_{i-1}))}{t_i - t_{i-1}} (t_i - t_{i-1})\\to \\int_a^b \\Vert \\dot \\gamma \\Vert_{(g\\circ \\gamma)(t)} \\, dt$$\n\nas the partition becomes finer and finer. So the RHS approaches the length of the curve in the newly obtained Riemannian manifold $(M,g)$ in this case. On the other hand the expression on the LHS approaches the length of $\\gamma$ in the metric space $(M,d)$ if we choose appropriate partitions! Hence $L^{(M,d)}(\\gamma) = L^{(M,g)}(\\gamma)$ for all smooth curves $\\gamma$.\n\nLet me summarize:\n\nLet $M$ be a manifold and suppose $d$ is a metric on $M$ such that $d(p,q) = \\inf_{\\gamma} L(\\gamma)$ for all $p,q \\in M$, where the infimum is taken over all smooth paths running from $p$ to $q$. Then there is a Riemannian metric $g$ on $M$ such that $d_g = d$ if and only if\n\n  \u2022 $d^2$ is smooth, $\\lim_{t\\to 0} \\frac{d(\\gamma(t),p)}{t}$ exists for all curves running through $p$ at $t=0$ and\n  \u2022 the following \"polarization identity\" holds at every point $p\\in M$: Given $v,w \\in T_pM$ and any four curves $\\gamma_v, \\gamma_w, \\gamma_{v+w}$ and $ \\gamma_{v-w}$ in $M$ running through $p$ at $t=0$ with velocities $v,w,v+w$ and $ v-w$, respectively. Then \\begin{align} \\left[\\frac{d}{dt}\\Big|_{t=0} d(\\gamma_{v+w}, p)\\right]^2 &+ \\left[\\frac{d}{dt}\\Big|_{t=0} d(\\gamma_{v-w}, p)\\right]^2 \\\\ & \\qquad = 2\\left[\\frac{d}{dt}\\Big|_{t=0} d(\\gamma_{v}, p)\\right]^2 +2\\left[ \\frac{d}{dt}\\Big|_{t=0} d(\\gamma_{w}, p)\\right]^2 \\end{align}\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/69490.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nManipulating a Formula Algebraically\n\nDate: 06/15/2006 at 23:45:03\nFrom: Debbie\nSubject: What is this formula used for?  \n\nI have the formula M = C(1 + r) in my algebra text, but it doesn't \ntell me what it is for.  It also asks me to solve for the r variable.  \n\nI know that the formula when solved for the r variable is:\n      M - C\n  r = -------\n\nbut I don't understand how to get all the way there.  This is as far\nas I know:  \n      M = C(1 + r)\n     -C  -C\n  M - C =  (1 + r)\n\nBeyond this I haven't got a clue.  Where did the 1 go?  Where does the\nextra C come from?  How do you get r alone?  Thanks for your help!\n\nDate: 06/16/2006 at 10:17:55\nFrom: Doctor Peterson\nSubject: Re: What is this formula used for?\n\nHi, Debbie.\n\nFirst, you don't need to even ask what a formula is for in this sort \nof problem.  One of the most important things about algebra (or math \nin general, really) is that it is abstract: that is, we can take all \nsorts of real-world problems and turn them into math problems (such \nas equations to solve), and once you've done that, it doesn't matter \nat all where they came from.  The methods you use in algebra ignore \nthe meaning of the problem, and just look at the equation itself.\n\nMany equations you'll work with in class don't come from anywhere at \nall; you are just practicing techniques that you can use on problems \nthat do have some real-world meaning.  It's sort of like a medical \nstudent practicing an operation on a dummy; he doesn't have to ask \nabout the patient's family or insurance!  But when he gets into real \nmedicine, all those things will matter.  In this case, the equation \nMIGHT relate to interest on a bank account, with r being the interest \nrate; but the same equation could come from other sorts of problems, \ntoo--or none at all.\n\nNow, to solve this equation for r, the important thing is to make \nsure that at each step you are making a new equation that is still \ntrue--that is, an equivalent equation.  We know that if we do the \nsame thing to each side, e.g. adding the same thing, the new equation \nwill be equivalent.  But often students don't pay close attention to \nwhat they are doing, and they don't really make an equivalent \n\nLook closely at what you did:\n\n      M = C(1 + r)\n     -C  -C\n  M - C =  (1 + r)\n\nWhat you say you are doing is subtracting C from both sides.  But \nthat's not really what you did.  When you do the subtraction (without \nsimplifying anything), you actually get\n\n  M - C = C(1 + r) - C\n\nNow you have to simplify, and you can't just cross off the C's!  If we \nexpand C(1 + r) using the distributive property, we get\n\n  M - C = C + Cr - C\n\nand then combining like terms gives\n\n  M - C = Cr\n\nThat's not what you got!  Why?  Because you didn't actually subtract C \nfrom the right side, but just crossed something off, thinking it was \nthe right thing to do.  This is a very common mistake!  You must \nalways think of the subtraction as making a change to the equation and \nthen simplifying, not just as canceling something.\n\nWe can continue, now--even though what you did is not the recommended\nmethod, which I will get to in a minute.  Look at the equation we have \n\n  M - C = Cr\n\nWhat is our goal?  To get r by itself.  We're almost there; all that's \n\"wrong\" with this is that r is multiplied by C, and we can get rid of\nthat by dividing by C.  So let's divide BOTH SIDES by C, again making \nsure that's really what we do:\n\n  M - C   Cr\n  ----- = --\n    C     C\n\nNow we can simplify the right side; multiplying r by C and then \ndividing by C undoes the multiplication and just leaves r:\n\n  M - C\n  ----- = r\n\nAnd that's our answer!\n\nNow, there are two other methods that make the first step easier than \nwhat we ended up doing.  One is to always simplify both sides of an \nequation before we start solving:\n\n  M = C(1 + r)\n\n  M = C + Cr\n\n(I distributed on the right side.)\n\nNow we want to get r alone; on the right side it is FIRST being \nmultiplied by C (remember the order of operations?) and THEN we're \nadding C to it.  To get it by itself, we have to undo both operations; \nand we do that in reverse order.  (For example, in the morning I put \non my socks first, then my shoes; to undo that at night, I take off \nmy shoes first, then my socks.)  So we'll first undo the addition of \nC, by subtracting C from both sides:\n\n    M   =   C + Cr\n  - C     - C\n  M - C =       Cr\n\nWhat this really means is that we are subtracting C from both sides \nlike this:\n\n  M - C = C + Cr - C = Cr\n\nwhere I simplified the right side by combining the like terms C and \n\nNow we're right where we were in the first method, and just have to \ndivide by C to finish.\n\nThere's another way we could have done this, without simplifying \nfirst; we'd look at the equation as given and see that in\n\n  M = C(1 + r)\n\nwe are FIRST adding 1 to r, and THEN multiplying by C.  We can undo \nthat by FIRST dividing both sides by C, and THEN subtracting 1 from \nboth sides.  The answer we get would look different, but would mean \nthe same thing.  If you wish, you may try doing that; but the method \nI've shown is what is usually taught.  I mention it because it is \nclose to what you tried to do: you wanted to get rid of the C first; \nbut because it is being MULTIPLIED rather than added, you have to \nDIVIDE by it rather than subtract, in order to eliminate it.  What you \nreally did was to subtract C from the left side and divide by C on \nthe right, which didn't give an equivalent equation.\n\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nMiddle School Equations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://www.redorbit.com/news/science/1112743724/river-valley-networks-math-120612/\nText:\nUsing Math To Better Understand River, Valley Networks\nDecember 6, 2012\n\nUsing Math To Better Understand River, Valley Networks\n\nLee Rannals for \u2014 Your Universe Online\n\n\n\nMIT scientists have created a mathematical theory to discover a common angle at which valleys branch off. The theory predicts that rivers branch at an angle of 72 degrees.\n\nTo put the theory to test, the team measured 5,000 branching angles in the Florida Panhandle, and found that branching was indeed 72 degrees.\n\nDan Rothman, a professor of geophysics in MIT\u00b4s Department of Earth, Atmospheric and Planetary Sciences (EAPS), said the mathematical analysis may be applicable to other systems, like neuron dendrites and fungal filaments.\n\nAnother team of scientists published a report in the journal Nature that looked at another mathematical model of river networks. This model identifies a tipping point at which rivers branch.\n\nThe river may give rise to a dense network of tributaries, depending on a river's capacity to erode a landscape.\n\n\u201cWe use mathematics to speed up time and help us understand how these systems evolve,\u201d Taylor Perron, leader of the team with the paper published in Nature, said in a statement. \u201cIf you could speed up the clock, you would see that the landscape is a lot more dynamic.\u201d\n\nRothman and his team looked to near the town of Bristol for their research. This area hosts a network of valleys cut into the landscape, and from an aerial view, you can see midsize branches running with water. Over time, the tips of the smallest valleys branch to create a denser valley network.\n\nThe team looked to the mechanics of groundwater flow to try and gain a better understanding of how these valleys branch. Groundwater flows under the surface, through material like porous sand. In the Florida Panhandle, groundwater may act to cut into a network of valleys.\n\nGroundwater stored in the hills surrounding a valley slowly seeps out, and over time, the process slowly erodes the surrounding hills, which ultimately extends a valley and splits it in two.\n\nRothman and colleagues derived a mathematical expression to find the angle at which the split occurs. These paths generally curve either away from each other, when the angle between the stream is small, or toward each other, when the angle is large.\n\n\u201cWhat we show is that because of the properties of groundwater flow, one can understand something about the organization of this pattern,\u201d Rothman said. \u201cIt opens a world into a really interesting geometry.\u201d\n\nPerron and his team examined the formation of river networks over land. They sought to find what governs the branching pattern that takes place.\n\nThe researchers of this study had to develop a simple mathematical model that represents the erosional mechanisms that act on a river network. With their model, the shape a river network takes is governed by a tug of war between two forces. The first force is the strength of river incision, or how quickly a river erodes. The second is the strength of soil creep, or how quickly soil from surrounding hills fills in a river valley.\n\nThe team found that as they turned up river incision, a river basin with a single river channel morphs into a network of branching channels at a very specific tipping point. This tipping point explains why larger rivers develop a network of tributaries.\n\nConnecting the tipping point to specific erosional mechanisms allowed Perron and his team to understand why river basins in landscapes grow tributaries at different scales. They predicted that river basins should branch at a smaller size in environments where river incision is strong, or where soil creep is weak.\n\n\u201cUnderstanding how river networks originate and evolve is key to understanding how landscapes have evolved in the past, and how they will evolve in the future,\u201d said Mikael Attal, a lecturer in landscape dynamics at the University of Edinburgh who was not a part of the research. \u201cWhat is fascinating about these two papers is that they provide a physical explanation for the geometry of river networks using some very simple concepts. Studies such as these will help better parameterize models and help make more accurate predictions of what may happen in the future.\u201d"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limits-when-determining-area-between-two-graphs.78874/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nLimits When Determining Area between two Graphs\n\n  1. Jun 13, 2005 #1\n    Hi all having a little problem with finding the limits on the area between 2 graphs.\n\n    i can find the easy one such as:\n\n    Find the area between y=x^2 and y = 2x\n    which is:\n    x^2 = 2x\n    x^2 - 2x = 0\n    x(x-2) = 0\n\n    x = 0 & 2\n\n    but when i have a question like:\n    Find the area between y=2-x^2 & y =x\n\n    i cant work it out i got to x(1+x)= 2\n\n    but im sooo lost\n    any help appreciated\n  2. jcsd\n  3. Jun 13, 2005 #2\n    Nvermind, I understand what your saying. To find the points of intersection between those two graphs, set them equal to each other.\n\n    [tex] 2-x^2 = x [/tex]\n\n    [tex] x^2 + x = 2 [/tex]\n\n    An obvious one is x=1.\n\n    Try quadratic formula.\n    Last edited: Jun 13, 2005\n  4. Jun 13, 2005 #3\n    sorry whozum i dont think i explained the question well, i need to work out the points of intersection i have no problems working out the area.\n\n    yeh ive already got 1. so using the quadratic formula i should be able to find the points out?\n  5. Jun 13, 2005 #4\n    so the intersecting points are -2 & 1?\n  6. Jun 13, 2005 #5\n    There you go. Graph it to make sure.\n  7. Jun 13, 2005 #6\n    hello there\n\n    well first of all you need to find where both functions actually intersect this is done by making 2-x^2=x then using the quadratic formulae to find where they intersect, and so you will find that they will intersect at 1 and at -2 now if you want to find the area between these functions its best that you graph it and then split up the area which should correspond to the addition to a couple of integrals\n    [tex]\\int_0^1 2-x-x^2 dx+\\int_{-\\sqrt{2}}^0 2-x^2+x dx-\\int_{-2}^{-\\sqrt 2} x -2+x^2 dx[/tex]\n    by integrating you will be able to find the area between those two functions?\n    by the way y=2-x^2 has roots at +/-sqrt{2}\n    the area is 2.5 units hopefully with out any small errors\n    Last edited: Jun 13, 2005\n  8. Jun 13, 2005 #7\n    thanks guys!\n  9. Jun 13, 2005 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Why in the world should one do such a thing? For all x between -2 and 1, 2- x2 is larger than x so 2-x2- x is positive and is the \"height\" of a thin rectangle between the two. The area is\n    [tex]\\int_{-2}^1 2- x- x^2 dx= \\frac{9}{2}= 4.5[/tex].\n  10. Jun 13, 2005 #9\n    yeh thats tha answer i got 9/2\n\nHave something to add?\n\nSimilar Discussions: Limits When Determining Area between two Graphs"}
{"text": "Retrieved from https://www.physicsforums.com/threads/2nd-order-de-solution.142577/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\n2nd Order De Solution\n\n  1. Nov 6, 2006 #1\n    I am familiar with how to solve a second order, non-homogenous DE with constants, i.e.\n\n    [tex]\\frac {\\partial^2X(t)}{\\partial t^2} + \\frac{\\partial X(t)}{\\partial t} = C[/tex]\n\n    by first solving the homogenous eqn, then setting the equation equal to a constant, yielding a sol'n of\n\n    [tex]X(t)= Ae^{0}+ Be^{-t}+ C[/tex]\n\n    But how does one solve a 2nd order equation that also has another t variable in it, such as:\n\n    [tex]\\frac {\\partial^2X(t)}{\\partial t^2} + \\frac{1}{t} \\frac{\\partial X(t)}{\\partial t} = C[/tex]?\n  2. jcsd\n  3. Nov 6, 2006 #2\n    First of all, you only seem to have one independent variable, so it may suitable to express your equation as\n\n    [tex]\\frac{d^2 X(t)}{dt^2} + \\frac{1}{t} \\frac{d X(t)}{dt} = C[/tex]\n\n    (note total derivative, not partial). Also, since no X(t) appears outside a derivative, you effectively have a first order equation, namely\n\n    [tex]\\frac{dp}{dt} + \\frac{p}{t} = C [/tex]\n\n\n    [tex]p(t) = \\frac{dX(t)}{dt} [/tex]\n\n    Now, any first order equation of the form\n\n    [tex]\\frac{dy}{dx} + s(x) y + r(x) = 0 [/tex]\n\n    has the solution\n\n    [tex]y(x) = -e^{-\\int s(x) dx} \\int r(x) e^{\\int s(x) dx} dx [/tex]\n\n    (just differentiate this and you'll see it works) Hence you can solve for p(t), and then for X(t).\n    Last edited: Nov 6, 2006\n  4. Nov 6, 2006 #3\n    Ah, that's a very nice way of framing the equation, I hadn't thought of that. Thanks!\n\nHave something to add?\n\nSimilar Discussions: 2nd Order De Solution\n  1. Solving a 2nd order DE (Replies: 11)\n\n  2. 2nd order nonlinear DE (Replies: 0)\n\n  3. 2nd order Linear DE (Replies: 1)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/203491/expected-coverage-after-sampling-with-replacement-k-times\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nprobability distribution of coverage of a set after X independently, randomly selected members of the set\n\nIf I sample with replacement $k$ times from a jar of with a finite population of $N$ unique marbles. What is the probability distribution for the fraction of the unique marbles that I sample?\n\nshare|improve this question\nadd comment\n\nmarked as duplicate by Byron Schmuland, tomasz, Chris Eagle, Norbert, Noah Snyder Oct 7 '12 at 19:09\n\n\n1 Answer\n\nup vote 1 down vote accepted\n\nWe answer only the expectation question in the title, and not the more complicated distribution question asked in the body of the post. Questions like this one have been asked several times on MSE. There is also a large technical literature on related questions.\n\nFor $i=1$ to $N$, let random variable $X_i$ be $1$ if $i$ is chosen at least once, and let $X_i=0$ otherwise.\n\nThe probability that $X_i=1$ is $1$ minus the probability that the number is chosen no times. On any one trial, the probability of not choosing $i$ is $\\frac{N-1}{N}$. Hence $$\\Pr(X_i=1)=1-\\left(\\frac{N-1}{N}\\right)^k.$$ The number $Y$ of $i$ chosen is given by $$Y=\\sum_{i=1}^N X_i,$$ so by the linearity of expectation, $$E(Y)=\\sum_{i=1}^N X_i=N\\left( 1-\\left(\\frac{N-1}{N}\\right)^k \\right).$$ For the expected proportion, divide by $N$.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://newton.dep.anl.gov/askasci/math99/math99144.htm\nText:\nNEWTON, Ask A Scientist!\nName: Norman\nStatus: student\t\nAge:  N/A\nLocation: N/A\nCountry: N/A\nDate: N/A \n\nIf the probability of being struck by lightning is 1 in 600,000, what is the probability of being struck twice?\n\n\nIn general, the probability of some occurrence with known probability happening twice to the same individual would be a product of the independent probabilities.\n\nIn your example, this would mean 1/600,000 times 1/600,000 or 1/360,000,000,000.\n\nJust a comment on this result...such a probability would represent the chance for a random occurrence assuming the original probability was calculated from random occurrences. This probability might be much higher for someone who tends to golf, mountain climb, fish, etc during lightning storms.\n\nIt also presumes that the individual could survive the first strike, which unfortunately might not be very likely.\n\nThanks for using NEWTON!\n\nRic Rupnik\n\n\nLightning does not know whether you have been struck previously. After you are struck, you have a 1 in 600,000 chance of being struck a second time. The probability of being struck twice can be worked out as follows. Consider 600,000 sets of events. In the first 599,999 you are never struck. In the last you are struck at least once. This is the 1 in 600,000 chance of being struck at least once. Make each of these sets 600,000 events. All of the first 599,999 sets of 600,000 events are \"never struck\"(359,999,400,000 events). In the last set of 600,000 events, the first 599,999 are \"only struck once\". The last is \"struck more then once\". This is a total of 360,000,000,000 events. The probabilities are:\n\nnever struck: (599,999 in 600,000),or (359,999,400,000 in 360,000,000,000)\n\nstruck exactly once: (599,999 in 360,000,000,000),or essentially (1 in 600,000)\n\nstruck more than once: 1 in 360,000,000,000 (1 in 360 billion)\n\nDr. Ken Mellendorf\nPhysics Instructor\nIllinois Central College\n\nClick here to return to the Mathematics Archives\n\n\n\nEducational Programs\nBuilding 360\n9700 S. Cass Ave.\nArgonne, Illinois\n60439-4845, USA\nUpdate: June 2012\nWeclome To Newton\n\nArgonne National Laboratory"}
{"text": "Retrieved from https://mathzsolution.com/is-there-an-injective-cubic-polynomial-z2%E2%86%92zmathbb-z2-rightarrow-mathbb-z/\nText:\nIs There An Injective Cubic Polynomial Z2\u2192Z\\mathbb Z^2 \\rightarrow \\mathbb Z?\n\nEarlier, I was curious about whether a polynomial mapping Z2Z could be injective, and if so, what the minimum degree of such a polynomial could be. I\u2019ve managed to construct such a quartic and rule out the existence of such a quadratic, but this leaves open the question of whether a cubic might exist. Equivalently my question is:\n\nCan a cubic polynomial of two variables with integer coefficients be injective?\n\nMy intuition is that there probably is such a function since there is a quadratic bijection N2N so if we allow ourselves an extra \u201cdegree\u201d to compensate for the transition from N to Z, it seems like it ought to be sufficient. However, I have yet to come up with an example that I suspect of being injective nor any general method I might use to try to prove injectivity.\n\nThe Part of This Post That Isn\u2019t A Question, But That Helps Motivate It Or Maybe Inspire Someone:\n\nSo far I have determined that there is an injective quartic and there is not an injective quadratic. To construct the quartic which is injective, note that the map f:N2N defined by f(x,y)=(x+y)2+y is injective and so is the map g:ZN defined by g(n)=2n2n. Then, one can set\nas an injective polynomial (of degree 4) in the two variables.\n\nNo quadratic polynomial may exist because any integer valued polynomial of degree two has a (non-zero) multiple expressible as:\nwhere P1 and P2 are polynomials with integer coefficients. Then, if we choose some y1 and a y2 such that y_1\\equiv y_2 \\pmod{4aP_1(y_1)}, we clearly have that P_1(y_1)\\equiv P_1(y_2)\\pmod a and that P_2(y_1)-P_2(y_2)=4aP_1(y_1)k for integer k. Then, we can choose two integers c_1 and c_2 such that c_1^2-c_2^2=P_2(y_2) \u2013 P_2(y_1)\nc_1\\equiv c_2 \\equiv P_1(y_1)\\equiv P_1(y_2) \\pmod a\nIn particular the values\nsatify the above. Then, choosing x_1=\\frac{c_1-P_1(y_1)}{a} x_2=\\frac{c_2-P_1(y_2)}{a} yields that P(x_1,y_1)=P(x_2,y_2), since their difference is (c_1^2-c_2^2) \u2013 (P_2(y_2)-P_2(y_1)) which we chose the c\u2018s to make 0.\n\nI have no idea how to approach the cubic case.\n\nA Moderately Surprising Computational Result\n\nUsing Mathematica, I determined that there is no polynomial of degree three with integer coefficients with absolute value 2 or less which is injective over the domain (\\mathbb Z \\cap [-2,2])^2. This surprises me, but it such a small set of polynomials that it might not mean anything other than that we might expect large-ish coefficients if a suitable polynomial does exist. (It could also be indicative of the fact that no such polynomial exists). I would have checked a larger range, but my computer crashed.\n\nI also thought the solving the one-dimensional case completely might help, and can see that x\\mapsto ax^3 + bx^2 + cx + d is injective if and only if it cannot be written as a(x-A)(x-B)\\left(x-\\frac{C}a\\right)+k for integer a,A,B,C,k \u2013 but this isn\u2019t super helpful, far as I can tell. However, the statement f(x,y) is injective is equivalent to asserting that t\\mapsto f(m_1t + b_1,m_2t+b_2) is injective for all m_1,b_1,m_2,b_2\\in\\mathbb Z with not both m equalling 0 \u2013 so this could be used to eliminate some cases, if nothing else.\n\n\nDisclaimer: This is merely a too lengthy comment to fit in the comment section.\n\nI still have no idea about the general degree 3 case, but here is another proof that no polynomial of degree 2 will work:\n\nWrite the polynomial P(x,y) of degree 2 as\n\nP(x,y)=\\sum_{i+j\\leq 2}c_{ij} x^i y^j,\\quad c_{ij}\\in\\mathbb Z\n\nConsider a point (a,b)\\in\\mathbb Z^2\\setminus\\{(0,0)\\} and the expression\n\n\nIf the coefficient (c_{10}a+c_{01}b) is zero, then t\\mapsto P(ta,tb) is an even function. Then\n\n\nfor all t\\in\\mathbb Z. If c_{10}=c_{01}=0 we can choose any (a,b)\\in\\mathbb Z^2\\setminus\\{(0,0)\\}. Otherwise (a,b)=(-c_{01},c_{10})\\neq(0,0) works. In any case, we have found an infinitude of pairs (ta,tb),(-ta,-tb) contradicting P being injective.\n\nSource : Link , Question Author : Milo Brandt , Answer Author : String\n\nLeave a Comment"}
{"text": "Retrieved from http://www.math.uni-magdeburg.de/institute/imo/teaching/wise19/cao/models/color.mod\nText:\nset V; # nodes param q default card(V); # number of colors to try # we definitely won't need more colors than there are vertices set C = 1..q; # set of potential colors set E within V cross V; # edges var x {V cross C} binary; # x[v,c] = 1 if vertex v is colored using color c, and x[v,c] = 0 otherwise var y {C}; # encodes whether color c is used (1 = used) # x binary => y binary, so we don't need to declare that here # objective function: minimize the number of colors used minimize NumOfUsedCols: sum {c in C} y[c]; # each vertex has exactly one color s.t. AssignColor {v in V}: sum {c in C} x[v,c] = 1; # adjacent vertices must not have the same color s.t. Conflict {(v,w) in E, c in C}: x[v,c] + x[w,c] <= 1; # if vertex v has color c, then color c is used s.t. SetIndicator {v in V, c in C}: x[v,c] <= y[c]; # we allow that y[c] = 1 although c is not used. # However, this will never occur in an optimal solution, so we # don't have to exclude it explicitly"}
{"text": "Retrieved from https://www.johndcook.com/blog/2012/06/03/calculating-pi-with-agm-and-mpmath/\nText:\nCalculating pi with AGM and mpmath\n\nThis post gives an algorithm based on the arithmetic-geometric mean that rapidly converges to pi. I\u2019ll use it to illustrate multiple precision arithmetic using Python\u2019s mpmath module.\n\nGiven two non-negative numbers a and b, their arithmetic mean is (a + b)/2 and their geometric mean is \u221a(ab). Suppose you start with two non-negative numbers and take their arithmetic mean and geometric mean. Then take the arithmetic and geometric mean of the results. Keep doing this repeatedly, and the result converges to what is called the arithmetic-geometric mean (AGM).\n\nThere is a formula for calculating pi based on the AGM that goes back to Gauss.\n\npi = frac{ 4M^2left(1, frac{1}{sqrt{2}}right)}{1 - sum_{n=1}^infty 2^{n+1} (a_n^2 - b_n^2)}\n\nHere M(a, b) is the AGM of a and b, and an and bn are the values after n steps of the iteration.\n\nThe process defining the AGM converges quickly, and so the formula is practical for computing pi. I found it in a paper from 1988, and at that time the formula had been used to compute pi to over 29 million decimal places. In the code below, we compute pi to 997 decimal places in only 10 iterations.\n\nfrom mpmath import mp, sqrt, mpf, pi, log10, fabs\n\n# carry out calculations to 1000 decimal places\ndecimal_places = 1000\nmp.dps = decimal_places\nepsilon = 1/mpf(10**decimal_places)\n\n# set a = 1 and b = 1/sqrt(2) as multi-precision numbers\na = mpf(1)\nb = 1/sqrt(mpf(2))\n\ndiff = a - b\nseries = mpf(0)\n\nn = 0\nwhile diff > epsilon:\n    n += 1\n    arith = (a + b)/2\n    geom = sqrt(a*b)\n    a, b = arith, geom\n    series += 2**(n+1) * (a*a - b*b)\n    diff = a - b\n\n# a and b have converged to the AGM\nmy_pi = 4*a*a/(1 - series)\n\nerror = fabs(pi - my_pi)\ndecimal_places = int(-log10(error))\n\nprint \"Number of steps used: %d\" % n\nprint \"Number of correct decimal places: %d\" % decimal_places\n\nThe code can be used to calculate pi out further. The number of correct decimal places roughly doubles with each iteration. For example, computing pi to 10,000 places takes only 3 more iterations.\n\nMore posts on computing pi\n\n12 thoughts on \u201cCalculating pi with AGM and mpmath\n\n  1. Reference: \u201cGauss, Landen, Ramanujan, the Arithmetic-Geometric Mean, Ellipses, pi, and the Ladies Diary\u201d by Gert Almevist and Bruce Berndt. Available here.\n\n  2. sherifffruitfly\n\n    what about the computation\u2019s stability characteristics? in particular, if the summation is close to 1, or a_i close to b_i ?\n\n  3. Steven: All calculations are carried out to the same precision, in this case 1000 decimal places. I suppose you\u2019re asking how the square root of 2 accuracy propagates throughout the rest of the calculation since it is computed first. I don\u2019t have a direct answer to that, but the final result of carrying all calculations out to 1000 places is that 3 decimal places are lost.\n\n    I don\u2019t know just where those decimal places are lost. It would be interesting to look at this computation in more detail and see which steps contribute the most to the error.\n\n    It seems that about the same number of decimal places are lost as the precision varies. For example, when I reran the calculation with 20,000 decimal precision, I still lose 3 decimal place, i.e. the result is correct to 19,997 places. I suppose the precision loss depends on the number of iterations, not the precision. Using 20,000 decimal places only required 14 iterations, only 4 more than using 1,000 decimal places.\n\n    When I go up to 100,000 decimal places, it takes 17 iterations, and I lose 5 decimal places of precision. This is more evidence that the number of decimal places lost increases very slowly as the working precision increases.\n\n  4. On a hunch that the expression (a*a - b*b) was contributing to loss of precision, I eventually discovered that the following version of the loop gives full precision:\n\n    while diff > epsilon:\n    series += 2**n * diff**2\n    n += 1\n    arith = (a + b)/2\n    geom = sqrt(a*b)\n    a, b = arith, geom\n    diff = a - b\n\n    This comes from substituting (a + b)/2 for a and sqrt(a*b) for b in the expression (a*a - b*b), so that each term in the series is based on the previous values of a and b.\n\n  5. Loop is done while diff (=a-b) > epsilon.\n    Final error is pi \u2013 4*a*a/(1 \u2013 series), not diff (=a-b).\n\n  6. UltimateQuantumGuy\n\n    Having come to this website by chance after attempting a calculation of my own using the Borwein quartic convergence AGM algorithm, I thought it might be of interest for you to know that in my implementation, I found a striking resemblance between your error in the decimals and my own \u2013 having noted almost exactly the same results with my version.\n\n  7. The book by Borwein & Borwein, Pi and the AGM (Canadian Mathematical Society Series of Monographs and Advanced Texts, Wiley-Interscience Publication, 1987) contains another algorithm to compute PI using arithmetic geometric means, given in the same chapter as the one you use. Algorithm 2.1 given on page 47, is slightly different. I implemented it and studied precisely the propagation of errors during computations. It turns out that the errors are proportional to the number of iterations, with a formula of the form:\n\n    e = 21 * n + 2 times ulp\n\n    Where ulp stands for \u201cunit in the last place\u201d, the difference between the two closest numbers you can represent. As soon as n is larger than 5, but until n reaches 22, you know that the error e is not more than 500, so this explains why three or four extra digits are required for a wide range of precisions (20 is enough for one million digit precision).\n\n    Of course, the algorithm I studied is not exactly the same as yours, but I expect them to be quite quite close in behavior. If you want to know more about my experience, you may want to look at the following article published by ACM:\n\n    A preprint is also available for free at the following address.\n\n    Accidentally, all mathematical proofs about this algorithm were verified using a proof system called Coq.\n\n  8. This is very nice algorithm, but I use to change it (slightly) \u2026.\n    Try this: instead of calculating \u201cdiff\u201d before loop as \u201cdiff=a-b\u201d calculate it as \u201cdiff=b\u201d (so it is sqrt(1/2)); inside loop: first calculate \u201cdiff=diff*diff/(4*a)\u201d and after this \u201cseries=2**(n+1)*diff*diff\u201d; \u201cmy_pi\u201d is still calculated, after loop, as \u201cmy_pi=4*a*a/(1-series)\u201d; that\u2019s all \u2026\n\nLeave a Reply"}
{"text": "Retrieved from http://archives.math.utk.edu/visual.calculus/4/int_by_parts.7/index.html\nText:\nEvaluate the following integral:\n\n  1. Let\n    and let\n\n  2. Hence,\n    and let\n\n  3. Using the formula for integration by parts\n\n    we get\n\n  4. Now we can use integration by parts again to compute the following integral\n\n  5. Let\n    and let\n\n  6. Hence,\n    and let\n\n  7. Finally we get\n\n  8. We can now use the above result to finish solving the problem:\n\n  9. It is easy to see that the integral obtained ( marked in red ) is the same as the original integral. Let us combine both integrals on the left hand side:\n\n  10. Acknowledgment: The java applet which is used on this page to display the equations in the discussion above is HotEqn from the Virtual Control Lab.\n\n    This page and the javascript used on this page was written by Marek Szapiel."}
{"text": "Retrieved from https://gaurish4math.wordpress.com/tag/infinte-descent/\nText:\nTag Archives: infinte descent\n\nA Curious Investigation\n\n\nAs I always say:\n\nMathematicians are those weird beasts who enjoy being surrounded by problems.\n\nMy current field of interest is Diophantine Equations (DE). Those who ever studied Number theory know about the classic\u00a0Pythagorean Triplets,\u00a0 equivalent to finding possible integer solutions of x^2+y^2 = z^2.\n\nAlso, it is a standard exercise (involving Method of Infinite Descent)\u00a0in DE to prove \u00a0thatx^2+y^2 = 3 z^2 has no integer solutions. But in this blog post I intend \u00a0to discuss following sibling of such degree two DE:\n\nSolve x^2+y^2 = 2z^2 for integers.\n\nClearly, z\\neq 0, I can divide whole equation by z^2 and denote, X=x/z and Y=y/z to get:\n\nSolve\u00a0X^2+Y^2 = 2 for rational numbers.\n\nObserve that (1,1) is a solution of given equation, then any other\u00a0solution (a,b) will lie with (1,1) on a line with rational slope (or\u00a0infinite slope, a vertical line, trivial case).\u00a0Furthermore, every line through (1,1) with rational slope will intersect with the quadratic curve in exactly two points. Because every quadratic equation has either no solutions or two real solutions, and\u00a0we already know that (1,1) is one solution.\n\nTo find all solutions, we first look at the vertical line case by\u00a0substituting X=1 \u00a0and seeing what two solutions you get. \u00a0One will be Y=1,\u00a0and the other gives a solution (which is the same solution in this case). Next, we take a line with rational slope m through (1,1), so that (using slope-intercept form):\n\n\nNow solve this line \u00a0and given curve X^2+Y^2 = 2\u00a0(which is circle of radius\u00a0\\sqrt{2} ). We will get:\n\nX = \\frac{m^2-2m -1}{m^2+1}\n\n\nWhere, m \\in \\mathbb{Q}, thus like x^2+y^2=z^2, x^2+y^2 = 2z^2 has infinite integer solution.\n\nEnding note:\n\nx^2+y^2 = 2 has only 4 integer solutions."}
{"text": "Retrieved from https://www.khanacademy.org/math/math-for-fun-and-glory/puzzles/brain-teasers/v/brain-teaser-blue-forehead-room\nText:\nMain content\nCurrent time:0:00Total duration:7:25\n\nBlue forehead room brain\u00a0teaser\n\nVideo transcript\n\nThere's a new reality television program, and it's called the Blue-- I should probably write it in blue-- but it's called the Blue Forehead Room. And what they do in this reality television program-- and you'll have to bear with me, because the show probably wouldn't be that interesting to watch-- but it's interesting to predict what happens. What they do is, they take a room. They'll call it the blue forehead room. And let's see, that's kind of a top view of the room. And let's say there's a door here. None of this is relevant to the actual problem. This is the door, right there. And what they do is they get 100 perfect logicians to sit in this room, in a circle. So they're all sitting in a circle in this room. Now, before the game even starts, before they even enter the room the first time, the logicians are told two things. They're told, One: that at least one of you has your forehead painted blue. At least one of you has your forehead-- And they all get their foreheads painted, so that obviously if you're the only guy who has your forehead painted. But you just don't know what color it is. So all of them have different color foreheads. Or, we don't know. But all they're told is, obviously I've painted your forehead. At least one of the people in the room that you will enter will have their forehead painted blue. And then they're also told that as soon as you deduce that your forehead is blue, you need to leave the room. And what's going to happen is-- and it's very important that I set this up properly. They're all outside of the room. No-one's inside the room. And let's say they're blindfolded. And while they're blindfolded, they essentially have the thing painted onto their forehead. So they can't see the paintbrush or anything. So they really don't know what's on their forehead. And then after that, they all enter the room. And they all sit in a circle like this, so that they can all look at each other. And let's say when they enter, the lights are off. So the lights are off, and then the protocol is that the lights will be turned on, and then they can all look around at each other. There's no reflective surfaces. They can't look into each other's eyes and try to see the reflection. No tricks like that. There are no mirrors in this room. Nothing like that. All they can do is look at each other. So, just as an example, let's say that this is me right here. As soon as the lights get turned on the first time, I'll be able to look at all the other people in the room. And I could see, it'll be pretty obvious to me if anyone has a blue forehead. Maybe that guy has one, that guy doesn't. I don't know, right? And I can see them. I can't see my own forehead. And what happens is, then they will turn off the lights, and the way they're going to do it is you have to leave the room after you have realized that you have a blue forehead. So for example, let's say I enter into the room, and because I'm a perfect logician I see things that allow me to perfectly deduce that I have a blue forehead. Then what they're going to do is they're going to turn off the lights again. And then, if I know that I have a blue forehead while the lights are turned off, I would leave the room. And then when they turn the lights back on, I'd be gone. So there would be no Sal here. So let's say there were 100 before, then there would be 99 guys sitting in the room. Right? As soon as I realize I have a blue forehead, when the lights get turned off, I leave. And just remember these are perfect logicians. So everyone in the room. And not only are they all perfect logicians, but they all know that everyone else is a perfect logician. So, everyone is also told, and this is true, everyone is a perfect logician. Which means they have infallible powers of logic. So my question to you-- Just remember, I have each of these perfect logicians. We set them up outside of the room, paint their foreheads. They're blindfolded. They have no clue. Then we have all of them walk into a dark room, sit in a circle like this. And then what we tell them is, as soon as you realize that you have a blue forehead, as soon as you have a blue forehead, you have to leave the room. Now my question to you is, let's say that we've actually painted everybody's forehead blue. What happens? So remember, this is what we've told each of the people. Right? As soon as you realize your forehead is blue, you leave the room. And now I've just asked you, the producers like to really play with these logicians. They've actually painted everybody's forehead blue. So when everyone goes in the room the first time, what's going to happen? Let's say I'm one of the logicians. This is me right here. As soon as I open my eyes, I'm going to see 99 other fellow logicians with blue foreheads. And then, maybe I can somehow deduce something about my own. I don't think you can. And the lights will go off. And then if I haven't deduced anything about my own blueness of my forehead, then they'll turn the lights back on. And then maybe some other guy will have left. I don't know. Or maybe not. And then I'll see the same 99 guys again. And that'll just keep occurring until something happens. And my question to you is what happens? When? And why? I'm thinking whether I should give you a hint right now. Well let me tell it to you this way. That's the problem. You should be able to solve it. And just so you know where this came from, if I remember correctly I think this was on a computer science exam I had at MIT. So just so you know, this isn't just for fun. I don't want to go into all of the applications that this type of problem can apply to, because that by itself would be a bit of a hint. So if you don't want a hint, turn off the video now or pause it. If you do want a hint, I'm about to give it to you. So my hint is-- and remember turn this off if you don't want to hint-- but the hint is what happens when there are less than 100 people. So I gave the situation where we have 100 logicians. But this problem is actually a lot easier if you try it with a smaller number. Anyway I'll see you in the solution video."}
{"text": "Retrieved from http://www.mathpages.com/home/kmath300.htm\nText:\nTwo In the Shop\n\nSuppose we have 10 units in service, each with an MTBF (Mean Time \nBetween Failure) of 2,000 hours.  Each operates for 2 months per \nyear.  When one fails it is returned to the maintenance shop for \nrepair, and spends 1 week there.  What is the probability that\ntwo units will be in the maintenance shop at the same time for \n\nAssuming the MTBF is quoted in operational hours, the failure\ndistribution is exponential, and the \"2 months per year\" operational\ntime is spread evenly through the year (e.g., 4 hours per day), it\nfollows that the mean calender time between failures of a specific\nunit is 12,000 hours.  Also, a unit spends 168 hours (=1 week) in \nthe shop each time it fails.  Therefore, each unit has a mean duty\ncycle of 12168 hours, of which 12000 are spent in the field and 168\nare spent in the shop.\n\nThe periods in the shop are random and uncorrelated for each of the \n10 units.  The probability of any particular unit being in the shop \nat a randomly chosen instant is just p = 168/12168.  The probability\nof two specific units being in the shop at a random instant is p^2.\nIn general, the probability of exactly k out of 10 units being in the\nshop at a given instant is \n              Pr{k}  =   ----------  p^k (1-p)^(10-k)\n                         (10-k)! k!\n\nso the probability of finding exactly 2 units in the shop is 0.007675,\nwhereas the probability of TWO OR MORE in the shop is 0.007970.\n\nOf course, the above analysis makes several tacit assumptions, and in\nreality the probability could be significantly higher or lower, for \nany of several reasons.  For example, we didn't specify that all the\noperational periods were independent and uniformly distributed over\nthe year, so it's possible that all the units are operational for the \nsame 2-month period each year, which would increase the probability of\nhaving two in the shop at some point during the \"busy season\".  On the \nother hand, the real probability could also be much smaller.  Strictly \nspeaking, within the stated conditions of the original problem, the \nprobability of two or more units in the shop simultaneously could be \nanything from 0 to about 0.3874.  For example, if each unit operates \nfor EXACTLY 2000 hours between failures, we could stagger their repair \ncycles so that one fails every 200 hours, which is greater than the \none week repair time of 168 hours.  Thus, the probability of two in \nthe shop would be 0.  (One could also manipulate the probability by \nassuming the units operate in more or less mutually exclusive 2-month \nperiods during the year.)\n\nOn the other hand, if the units are operated in synchronized pairs\n(hopefully not two engines of a twin-engine airplane), and each fails\nevery 2000 hours exactly, then each pair is in the shop for 168 hours\nout of every 2168 hours, giving a probability of 0.0774.  If the five\npairs of units are staggerred, then the fraction of [active] time with\ntwo units in the shop would be 0.3874.\n\nIt might be interesting to figue out the maximum probability that\nwould be strictly consistent with the stated conditions of the\nproblem.  In many casually-stated probability problems it turns out\nthe answer can be anything on the interval from 0 to 1 (inclusive).\n\nReturn to MathPages Main Menu"}
{"text": "Retrieved from http://mathoverflow.net/questions/34988/maximum-number-of-distinct-diagonals-generated-by-permutations\nText:\nTake the 2-minute tour \u00d7\n\nGiven an n by $n$ matrix with $0$'s and $1$'s only, consider the $n!$ different permutations generated by permuting the rows, what is the maximum number of different diagonals generated?\n\nshare|improve this question\nIs the question for a general upper bound or an upper bound if I know the matrix? \u2013\u00a0 Daniel Krenn Aug 9 '10 at 11:09\nAs in, you can choose any n by n 0-1 matrix you want to maximize this number. \u2013\u00a0 Kamil Aug 9 '10 at 12:12\n\n1 Answer 1\n\nIf I am allowed to choose the matrix, it seems that I can generate all $2^n$ different diagonals.\n\nEdit. Sorry, this approach only generates $2^n -n $ diagonals.\n\nLet $I$ be the $n \\times n$ identity matrix and let $D$ be a diagonal whose non-zero entries are indexed by $S$.\n\nFurther suppose that $D$ does not have exactly one zero entry.\n\nLet $\\pi$ be a perumation of the rows of $I$ whose fixed points are exactly $S$. Then the diagonal of $\\pi(I)$ is $D$, and there are $2^n-n$ such diagonals.\n\nUpdate. Here is a proof that $2^n-n$ is in fact the best one can do.\n\nAn $n \\times n$ bipartite graph is a bipartite graph with bipartition $([n]_r, [n]_c)$, where $[n]_r$ and $[n]_c$ are both copies of $[n]$. Let $G$ be an $n \\times n$ bipartite graph. Define $G'$ to be equivalent to $G$, if $G'$ can be obtained from $G$ by complementing the neighbourhoods of some vertices in $[n_r]$. Note that the equivalence class of $G$, denoted $[G]$, has size $2^n$.\n\nIt is easy to check that the following lemma proves the tightness of the bound.\n\nLemma. For any $n \\times n$ bipartite graph $G$, at most $2^n-n$ members of $[G]$ have a perfect matching.\n\nProof. For each $i \\in [n]_c$ there is a graph $G^i \\in [G]$ such that $i \\in [n_c]$ has degree 0 in $G^i$. Just pick the vertices in $[n]_r$ that are adjacent to $i$ in $G$ and complement their neighbourhoods. If all $G^i$ are distinct, then the lemma clearly follows. Otherwise, $G^i=G^j$ for some $i \\neq j$. Thus, both $i$ and $j$ have degree 0 in $G^i$. But now, the $n$ graphs obtained from $G^i$ by performing a single complementation each do not have a perfect matching.\n\nshare|improve this answer\nThis seems to have a slight problem with the case of the configurations with exactly one zero. \u2013\u00a0 damiano Aug 9 '10 at 12:20\nNot with $n=3$ you can't :-) \u2013\u00a0 Robin Chapman Aug 9 '10 at 12:23\nI suppose that I cannot generate diagonals that have exactly $n-1$ ones in this way, since if I fix $n-1$ rows, then I automatically fix the last one. But it seems that I can still get $2^n-n$ diagonals. \u2013\u00a0 Tony Huynh Aug 9 '10 at 12:24\nA clever argument! One minor comment: I do not think that the current proof of the lemma deals with the case where more than one vertex in [n]_c have exactly the same set of neighbors, but it can be fixed easily. \u2013\u00a0 Tsuyoshi Ito Aug 10 '10 at 1:03\njust a minor remark, the same without graphs: if two rows (say i-th and j-th) are equal to $r$, then each diagonal has at least two coincidences with $r$ (coincidence means coincidence of one of $n$ coordinate functionals). So, there are at least $n$ forbidden diagonals. If all rows are different, then all their complements are forbidden and we again have $n$ forbidden diagonals. \u2013\u00a0 Fedor Petrov Aug 10 '10 at 12:17\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/57266.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nBlending Seed\n\nDate: 09/27/98 at 00:26:11\nFrom: Anonymous\nSubject: Grass seed problem\n\nHi!  Here is a problem that my father and I have been working on for \nhalf an hour:  \n\nA lawn-and-garden dealer wants to make a new blend of grass seed by \nusing 200 pounds of $0.45 per pound seed and some $0.65 per pound \nseed. How much of the $0.65 seed does the dealer need to make a $0.55 \nper pound blend?\n\nThank you so very much for your help. Hope to hear from you soon.\n\nDate: 09/27/98 at 01:22:14\nFrom: Doctor Ken\nSubject: Re: Grass seed problem\n\n\nFirst I'll give you a sort of intuition-based solution, and then I'll \ngo back and be a little more formal, writing things out in algebraic \n\nThe first thing I noticed about this problem was that a pound of one \nkind of seed costs 45 cents, a pound of the other costs 65 cents, and \nwe want to make a mix that costs 55 cents. Well, 55 is halfway between \n45 and 65, so it seems like we should combine equal parts of the two \nkinds of seed. Since we need to use 200 pounds of the first kind, we \nshould use 200 pounds of the other kind, for a total of 400 pounds.  \n\nTo verify this solution, let's see how much the pieces would cost.  \n200 pounds of the first kind of seed would cost 200 * $0.45 = $90, and \n200 pounds of the second kind of seed would cost 200 * $0.65 = $130.  \nWe bought 400 pounds total and paid $220, so we paid on average \n$220/400 = $0.55. Seems to check out.\n\nNow, how can we use algebra to find this same solution? The first \nthing I usually try to do is to find a sentence (an English sentence, \nor whatever language you like best) that says something true and \nuseful about the problem. Then I translate that sentence into an \nalgebraic equation.  \n\nIn this problem, I think I'd make this sentence: \"The cost per pound \nof the combined seed mixture is 55 cents.\" Let's work on translating \nthat into an equation. First it becomes:\n\n   cost per pound = $0.55\n\nWhat is the cost per pound? It's the number you get when you divide \nthe total price by the number of pounds of seed:\n\n     total price\n    pounds of seed\n\nThe total price is the cost of the 45c part and the 65c part. The \nnumber of pounds of seed is the number of pounds of the first kind \nplus the number of pounds of the second kind. The only unknown thing \nhere is the number of pounds of the second kind, so let's call that x.\n\n    200*$0.45 + x*$0.65\n         200 + x\n\nNow we've done the translation. I'll leave it to you to work out the \nsolution from here, and verify that the answer really is 200.\n\n- Doctor Ken, The Math Forum\nAssociated Topics:\nElementary Word Problems\nMiddle School Algebra\nMiddle School Word Problems\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/104426/an-pure-intriguing-counting-problem-of-index-sets\nText:\nTake the 2-minute tour \u00d7\n\nHi Guys. The problem here seems like a homework, but I think that it is not that easy.It comes from a theorem I recently proved.The content of the theorem is not important, the issue is that I have no idea how to counting the number of the index sets that satisfy the constraint the theorem restricted.\n\nTheorem: Suppose a sequence of integers has distinct $n^2+1$ numbers and have exactly t one monotone subsequence of length $n+1$,(Note Erdos Szekeres Theorem guarantees the existence of the unique subsequence.),the index set $C$ of the unique monotone subsequence of length n+1 must satisfy following properties.\n\n(Constraint of index set)\n\nLet $C_i$ denotes the $i$th element of the index set $C$ where $2 \\leq i \\leq n$.Then\n\n(0) $ C_1 < C_2 < \\dots < C_i < C_{n+1}$\n\n(1) $j< C_1 <(j-1)n+1$\n\n(2) $ij < C_i<(j-1)n+i+(i-2)(n-j)$\n\n(3) $ nj+1 < C_{n+1} < (j-1)n + n + 1 + (n-1)(n-j) $\n\nwhere $j$ is any integer for $1$ to $n$ .\n\n(End of the Constraint)\n\nThe meaning of the $j$ is that if the elements of $C$ satisfies the group of constraints above for any $j$, we say that it satisfies the constraints.\n\nEND of the theorem.\n\n\nHow many index sets C satisfy the constraint above are there?\n\nOr could someone provide an approximation of the numbers of qualified index set $C$s. Even the ration of the qualified index sets to the trivial bound $ { n^2 +1 \\choose n+1 }$ would be very desirable.\n\nIF you are reading this, thank you for you patient for at least arriving here. I would also thank for anyone that might suggest some people might know a method to the problem.\n\nshare|improve this question\nYour last constraint expression might be easier to grok if written as n^2+1-(n-j). Also, there have been a few questions asked on related matters recently on specialized combnations, which is what your sets appear to be. You might check those out. (Link to be provided later.) Gerhard \"Search Engines Stole My Memory\" Paseman, 2012.08.10 \u2013\u00a0 Gerhard Paseman Aug 10 '12 at 22:04\nHere is the first in a chain of links that might be of interest. mathoverflow.net/questions/104028/string-possible-combinations/\u2026 . My answer has a comment from me which contains the next link. My guess is that parking functions and Gessel-Viennot (somewhere after the third link) will be relevant to your problem. Gerhard \"Ring Around The Web References\" Paseman, 2012.08.10 \u2013\u00a0 Gerhard Paseman Aug 11 '12 at 2:12\nHi Gerhard. Thanks very much about your links.It seems that I need time to dig it out. \u2013\u00a0 WangYao Aug 11 '12 at 6:31\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathoverflow.net/questions/20942/brownian-bridge-under-observational-error?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $Z_t$ follows a simple discrete random walk $Z_t=Z_{t-1}+e_t$ , where $e_t$ are a bunch of uncorrelated normal variables with arbitrary variance sigma^2, and that there are observations of the series at t=a and t=b, with both observations having normal uncorrelated observational error with variance $O_a$ and $O_b$.\n\nHow can I find distribution for intermediate values between a and b?\n\nshare|improve this question\n\n1 Answer 1\n\nif you consider a Gaussian vector $V=(X,Y) \\in \\mathbb{R}^{d=m+n}$, you know how to find the conditional distribution of $X$ knowing the value of $Y=y$, right ? This is exactly the same thing here.\n\nFor example, let us suppose that $a=0, b=N+1$:\n\n  \u2022 you have a noisy observation $Y=(y_1, y_2)=(O_a, O_b)$ with know covariance matrix $\\Sigma_Y$\n  \u2022 the data you are looking for, $X=(z_1, \\ldots, z_N) \\in \\mathbb{R}^N$, have a known covariance matrix $\\Sigma_X$\n  \u2022 the covariance matrix $E[X Y^t] = \\Sigma_{X,Y}$ is also known.\n\nA quick way to find the conditional distribution of $X$ knowing $Y$ is to write $$X = AU + BV$$ $$Y=CU$$ where $U,V$ are independent standard Gaussian random variable of size $2$ and $N$ respectively, while $A \\in M_{N,2}(\\mathbb{R})$ and $B \\in M_{N,N}(\\mathbb{R})$ and $C \\in M_{2,2}(\\mathbb{R})$. Because\n\n  \u2022 $CC^t = \\Sigma_Y$ gives you $C=\\Sigma_y^{\\frac{1}{2}}$,\n  \u2022 $AC^t = \\Sigma_{X,Y}$ then gives you $A=\\Sigma_{X,Y}\\Sigma_y^{-\\frac{1}{2}}$,\n  \u2022 $AA^t + BB^t = \\Sigma_{X}$ then gives you $B=(\\Sigma_{X}-\\Sigma_{X,Y}\\Sigma_y^{-1}\\Sigma_{X,Y})^{\\frac{1}{2}}$,\n\nthe $3$ matrices are easily computable, and $C$ is invertible in the case you are considering. This shows that if you know that $Y=y$, the conditional law of $X | Y=y$ is given by $$X = AC^{-1}y + BV,$$ which is a Gaussian vector with mean $AC^{-1}y = \\Sigma_{X,Y}\\Sigma_y^{-1}y$ and covariance $BB^t = \\Sigma_{X}-\\Sigma_{X,Y}\\Sigma_y^{-1}\\Sigma_{X,Y}$\n\nshare|improve this answer\nI'm having trouble working through the notation, specifically the covariance matrix of Y (The covariance matrix of the sampling error? Or of the observations?). Could you elaborate the calculation for N=2? \u2013\u00a0 David Shor Apr 11 '10 at 11:12\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/64231.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nWhere Do the Parentheses Go?\n\nDate: 09/12/2003 at 00:48:21\nFrom: Lynn\nSubject: order of operations and writing equations\n\nI'm trying to help my daughter with some problems she's been given. \nEach one has a string of numbers and operations on one side, and a\nresult on the other side.  What you're supposed to do is insert\nparentheses around the numbers and operations in order to get the\nresult.  For example:\n\n      2    2    2\n 2 + 7  - 3  / 3  - 1 * 5 = 35\n\nI know how PEMDAS works, but I don't see how to solve these problems\nwithout just doing a lot of guessing.  Argh!\n\nDate: 09/12/2003 at 08:53:18\nFrom: Doctor Peterson\nSubject: Re: order of operations and writing equations\n\nHi, Lynn.\n\nThis sort of problem is just a puzzle -- there is no standard, \nstraighforward way to solve it, you just have to try things out and \nmake intelligent guesses. It may help to read what we have to say \nabout the order of operations\n\n\nbut there is no specific technique we can give you. I'll just try to \nget you started, thinking through the problem until I see where to go.\n\nUsing our e-mail notation, your equation is\n\n\nLooking at this, I notice that 35 = 5*7, and that there is a 7 and a \n5 in the left side. So my first action is to add parentheses so that \nmultiplication by 5 will be the last operation performed; if we can \nmake the rest of the expression equal 7, we'll be in good shape. This \nis just a guess; it may turn out that we won't want to multiply by 5 \nat all. But we can try it:\n\n  (2 + 7^2 - 3^2 / 3^2 - 1) * 5 = 35\n\nNow, it's not obvious that we can get 7 out of that, or that the 7 \nthat is there will in any way show through in the final form (since \nwe can't undo the squaring, and we would have to divide by 7 to leave \nourselves with just one 7). But I do see, at least, that 7^2 is much\ntoo big, so we have to make it smaller, either by subtracting\nsomething big or by dividing. \n\nAs written, the division only affects 3^2; 3^2/3^2 is 1. So we'll want\nto have parentheses around at least part of \n\n  2 + 7^2 - 3^2\n\nand we can decide eventually how much of \n\n  3^2 - 1\n\nto divide by. If we used all of both, we'd have\n\n  (2 + 7^2 - 3^2) / (3^2 - 1) = 42/10\n\nwhich is in the right ballpark but not a whole number, much less \nexactly 7. It doesn't help if we divide 42 by 3^2 or by 3 rather than \n3^2 - 1.\n\nNow we can try either adding more parentheses inside (2 + 7^2 - 3^2) \nto change what we are dividing, or pull the 2 outside of the \n\nAt this point I've finally looked ahead enough to see the solution. \nI'll leave you with just a hint: you'll want to take the first choice \nI mentioned in the last paragraph, and you'll have to change what you \ndivide by as well. See what you can do.\n\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Puzzles\nMiddle School Puzzles\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/64159/algebraic-plane-curves-and-their-tangent-curves/64180\nText:\nTake the 2-minute tour \u00d7\n\nGiven an algebraic plane curve how can one construct a corresponding curve whose degree is one less and such that the points of intersection are also points of tangency?\n\nSpecifically, if a plane curve $F$ is given by the polynomial equation $f(x,y) \\equiv \\sum_{j=0}^{n}\\sum_{i=0}^j{a_{i,j}x^{j-i}y^i}=0$, where $x,y \\in \\mathbb{C}$, how can one construct a corresponding plane curve $\\widetilde{F}$, given by $\\widetilde{f}(x,y) \\equiv \\sum_{j=0}^{n-1}\\sum_{i=0}^j{\\widetilde{a}_{i,j}x^{j-i}y^i}=0$ such that for a pair $p,q$ satisfying\n\n\\begin{equation} f(p,q)=\\widetilde{f}(p,q)=0 \\end{equation}\n\nwe also have\n\n\\begin{equation} \\dfrac{\\partial_xf}{\\partial_x \\widetilde{f}} \\bigg|_{x=p,y=q}=\\dfrac{\\partial_yf}{\\partial_y \\widetilde{f}} \\bigg|_{x=p,y=q} \\end{equation}?\n\nshare|improve this question\nI probably do not understand what you mean: but why doesn't $\\tilde F(x,y)=1$ work? \u2013\u00a0 Mariano Su\u00e1rez-Alvarez May 6 '11 at 21:26\nBecause that polynomial has no roots, i.e. $\\widetilde{f}(x,y) \\equiv 1 \\neq 0$ and does not constitute an algebraic plane curve \u2013\u00a0 hailekofi May 6 '11 at 21:39\nadd comment\n\n2 Answers\n\nIf $n$ is odd, you can take an arbitrary $g$ of degree $(n-1)/2$ and $\\tilde f = g^2$. The solution is far from unique and there will be others. For $n=2$, $\\tilde f$ is the tangent line at some point of $F$. For $n=3$, if you have a smooth cubic with inflexion $O$, taken as origin of the group law, choose a point of order $2, P_0$. For arbitrary points $P,Q$ on the curve, let $R= -(P+Q)+P_0$. Then $2(P+Q+R)=0$ so there is a conic through $P,Q,R$ tangent to $F$ at these points. The case $P_0=O$ reduces to my first construction, but as you see there are three other families. Do you have any reason to believe there will be a nice formula?\n\nshare|improve this answer\nYou don't need n to be odd for the nonreduced trick: let g have degree one and take $\\tilde f=g^{d-1}$. I guess the interesting question is whether a nonreduced all-tangent curve exists. A quick parameter count makes me skeptical... \u2013\u00a0 quim May 7 '11 at 8:17\nadd comment\n\nThe answer is clearly yes for d=2,3,4 and 6. I am skeptical about larger degrees.\n\nThe family of plane curves of degree (at most) d-1 has dimension (d-1)(d+2)/2. Imposing d(d-1)/2 tangency points with the given curve determines a family of curves of degree d-1 tangent to C of dimension at least d-1. For large d, the family of nonreduced solutions will have dimension bigger than d-1, so this gives no information about existence of reduced solutions. However, for d=2,4 and 6 there must be reduced solutions because the nonreduced families of solutions have dimension 0, 2 and 4 respectively.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/276279/how-to-define-a-function-which-takes-a-real-number-and-gives-as-a-result-the-clo/276283\nText:\nTell me more \u00d7\n\nHow can I define a function which takes as an only parameter a real number and gives as a result the closest smaller natural number? E.g. $f(3.554)=3, f(4.95485)=4, f(2.001)=2$.\n\nshare|improve this question\nThe function is called $floor$ and written as $\\lfloor x\\rfloor$ \u2013\u00a0 Shard Jan 12 at 11:56\nIf you're looking for a function that can be expressed in terms of elementary functions, you're out of luck. Floor and ceiling functions can be represented as infinite series that converge, but only in part of the domain. You can't use those representations in practice. \u2013\u00a0 Greg Ros Jan 12 at 12:12\nYes, exactly what I wanted to know. I asked my Mathematics teacher(I'm in High school) and he told me that I got the definiton of the function with my question. So I decided to search or ask how it could be defined in pure math notation, not in a specific language. \u2013\u00a0 user1113314 Jan 12 at 12:46\nadd comment\n\n2 Answers\n\nFirst, if your real number $k < 1$, then the function $f$ is not defined at $k$ since there is no natural number lesser than the value of $k$.\n\nThe function $f$ you are trying to define is just a subset of the floor function where $f:\\{x|x\\ge 1\\} \\mapsto \\mathbb{N}$. Thus we can define your function as $f(x) = \\max (y\\in \\mathbb{N}|y\\le x), x \\in [1,\\infty)$.\n\nshare|improve this answer\nPhew, I needed too many corrections on this one. \u2013\u00a0 \u03a0\u03b1\u03c1\u03b8 \u039a\u03bf\u03c7\u03bb\u03b9 Jan 12 at 12:09\nThank you, really comprehensive answer. \u2013\u00a0 user1113314 Jan 12 at 13:04\n@user1113314: No problem! \u2013\u00a0 \u03a0\u03b1\u03c1\u03b8 \u039a\u03bf\u03c7\u03bb\u03b9 Jan 12 at 13:34\nadd comment\n\nYou can define such a function directly by it's desired properties, i.e. for $x\\geq 1$, define $$ f(x) :=\\max \\left\\{ n\\in\\mathbb{N}:n\\leq x \\right\\}. $$ As has already been pointed out, $f(x)$ is commonly denoted by $\\lfloor x\\rfloor$. Clearly $f$ is discontinuous, so it cannot be expressed as a finite composition of continuous functions (which probably is what you've actually been looking for) or a power series.\n\nOne obvious representation of $f$ would be to write it as a limit of step functions: $$ f = \\lim_{n\\rightarrow \\infty}\\sum_{k=1}^n k \\cdot\\chi_{[k,k+1)}$$ where $\\chi_I$ is the characteristic function of the interval $I$, but this is really nothing more than toying with the definition.\n\nshare|improve this answer\nThank you for the answer. the representation is too complicated for me. I'll take a look at the floor(x) implementation in Wikipedia. \u2013\u00a0 user1113314 Jan 12 at 13:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/58160.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nGreatest Common Factor (GCF)\n\nDate: 04/13/99 at 10:38:25\nFrom: Eugene\nSubject: Mathematics 6th grade\n\nHere's the question: The GCF of my numerator and denominator is 5. The \nfraction is equivalent to 4/6. \n\nI tried listing all the multiples of 5 and none is divisible by 6 \nexcept 30. But if I divide this by 6 it will be 5 and 5 x 4 is 20. But \n20/30's GCF is not 5, it's 10. HELP!\n\nDate: 04/13/99 at 12:48:27\nFrom: Doctor Peterson\nSubject: Re: Mathematics 6th grade\n\nHi, Eugene.\n\nYes, this is a little tricky; I fell into almost the same trap you \ndid. You're thinking well so far, but now you have to back up and ask \nwhy it didn't work. To let you practice avoiding the trap, I'll work a \nslightly different problem: the GCF will be 7 rather than 5, and the \nfraction will be equivalent to 3/6 rather than 4/6.\n\nWhat you are doing is looking for some number N by which you can \nmultiply the numerator and denominator, so that\n\n    3xN    3\n    --- = ---\n    6xN    6\n\nand the GCD of 3xN and 6xN is 7. It makes sense to try N = 7, as you \ndid with 5; but the GCD of 21 and 42 is 21, not 7. What happened?\n\nLet's factor the numerator and denominator of our new fraction:\n\n    3xN    3xN\n    --- = -----\n    6xN   2x3xN\n\nDo you see that the GCD will not be N, but 3xN, because 3 and 6 \nalready have a common factor, 3? In order to make the GCD be 7, then, \nN must be 7/3. Then\n\n    3xN   7\n    --- = --\n    6xN   14\n\nwhich is equivalent to 3/6, and the GCD of 7 and 14 is 7.\n\nWere you surprised that N was not a whole number? You can multiply the \nnumerator and denominator of a fraction by any fraction and it will \nstill be equivalent; but the result will be two whole numbers only if, \nas in this case, there was a common factor (3).\n\nSo the reason our problem was tricky is that 3/6 is not in lowest \nterms, so equivalent fractions do not have to have whole-number \nmultiples of the numerator and denominator. We can get to the answer \nvery easily by first writing 3/6 in lowest terms as 1/2, then \nmultiplying numerator and denominator by 7.\n\nNow see what you can do with your problem. There are several ways to \nsolve it, once you see what's wrong.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nElementary Fractions\nMiddle School Fractions\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/15907/position-function-not-always-retuning-an-answer-even-with-no-apparent-problems?answertab=oldest\nText:\nTell me more \u00d7\n\nI'm having some problems with Position.\n\nSometimes it will give an empty list instead of the actual position of the element I am looking for when that element is specified through some other code but will return the correct position when the element is specified directly as a number as in the minimum working example below.\n\ndata = {{0.1, 0.0001683}, {0.2, 0.00035754}, {0.3, 0.00056711}, {0.4, \n   0.00078986}, {0.5, 0.0010333}, {0.6, 0.0010333}, {0.7, \n   0.0015758}, {0.8, 0.0018738}, {0.9, 0.0022054}, {1., \n   0.0025706}, {1.1, 0.0029788}, {1.2, 0.0034366}, {1.3, \n   0.0039831}, {1.4, 0.0046433}, {1.5, 0.0055203}, {1.6, \n   0.0068061}, {1.7, 0.010939}, {1.8, 0.031246}, {1.9, 0.054948}, {2.,\n    0.076556}, {2.1, 0.098521}, {2.2, 0.12551}, {2.3, 0.1585}, {2.4, \n   0.1921}, {2.5, 0.22544}, {2.6, 0.25798}, {2.7, 0.28992}, {2.8, \n   0.32051}, {2.9, 0.35095}, {3., 0.38104}}\n\ninterpol = Interpolation[data];\n\nq = FindRoot[interpol[x] == 0.159, {x, 2.9}][[1, 2]]\n\nxlow = Floor[q, 0.1]\n\nPosition[data[[All, 1]], xlow]\n\nPosition[data[[All, 1]], 2.3]\n\nWhen running v8 on xP this code gives {} for the first output and {{23}} for the second.\n\nThis type of error is referenced in the Possible Issues section of the documentation for Position in v8 and v9 but no advice is given.\n\nIn[1] := Position[Range[-1, 1, 0.05], 0.1]\nOut[1] = {}\n\nI've tried putting N everywhere I can to solve it as I thought it could just be a precision or representation issue ( i.e. 2.3 vs 23/10 ) but with no success. Does anyone have nifty work around or solution to this that I am missing please?\n\nshare|improve this question\nWould Position[data[[All, 1]], Nearest[data[[All, 1]], xlow][[1]]] be acceptable ? \u2013\u00a0 b.gatessucks Dec 7 '12 at 10:25\nIt works so it most certainly would be acceptable! Thanks for the fast reply. \u2013\u00a0 fizzics Dec 7 '12 at 10:40\nSince I believe the correct answer is to use Chop (see below), it's also worth pointing to this and this. \u2013\u00a0 Jens Dec 8 '12 at 18:26\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nPosition is looking for an exact match (pseudo-SameQ), rather than a numeric one.\nYou will get the result you want with:\n\nPosition[data[[All, 1]], _?(# == xlow &)]\n\n\nPosition[data[[All, 1]], x_ /; x == xlow]\n\nGenerally you should use Equal (short form ==) any time you are trying to mach Real numbers, to allow for small rounding errors.\n\nUsing the pattern 0 | 0. is not sufficient; See this for examples.\n\nFor an excellent treatment of the problems of matching inexact numbers see:\n\nInstability in DeleteDuplicates and Tally\n\nshare|improve this answer\nThanks for the fast reply. Both of those do the job perfectly but I'm a bit confused by the structure you use in the first one. Wouldn't the _? return a True value instead of a numeric? The second structure I don't fully understand either as I don't see how Position knows to loop over x and compared each term. There is obviously more functionality built in than I appreciate \u2013\u00a0 fizzics Dec 7 '12 at 10:37\n@fizzics Both _?(# == xlow &) and x_ /; x == xlow are patterns, which is what Position needs as a second argument. _?testfunction is a pattern for any single expression for which testfunction yields True when applied. x_ /; expr is a pattern for any single expression, which we locally name x, for which expr evaluates to True; if x appears in expr the local definition is used. Read the documentation for Pattern, PatternTest, and Condition, then see this question. Return with any further questions. \u2013\u00a0 Mr.Wizard Dec 7 '12 at 11:27\nadd comment\n\nOne alternative approach that is very powerful when dealing with approximate real numbers hasn't been mentioned yet: use Chop or Threshold.\n\nThese two functions are intended for just the type of situations you describe, so I would always try them first:\n\nIn your example, this simple command works:\n\nPosition[Chop[data[[All, 1]] - xlow], 0]\n\n\nInstead of finding xlow, I reformulated the problem so that you find 0 in the list of differences with xlow.\n\nshare|improve this answer\nExcellent recommendation. Numeric methods are almost always faster. \u2013\u00a0 Mr.Wizard Dec 8 '12 at 22:22\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/kb/plaintext.jspa?messageID=9179096\nText:\nDate: Jul 24, 2013 7:38 AM\nAuthor: Waldek Hebisch\nSubject: Re: An independent integration test suite\n\nNasser M. Abbasi <> wrote:\n> I remember reading that some math people, 100 or 200 years ago,\n> decided that sqrt (of non-negative, non-complex values) was single valued\n> function and its value is the non-negative root (ie. principal\n> square root).\n\nBeware that mathematicians have Humpty Dumpty attitude:\n: When I use a word. it means just what I choose it to\n: mean -- neither more nor less.\nAnother mathematician may use the same word with different\nmeaning (of course, in good math text meaning is explained).\n\nBefore complex numbers were invented only nonnegative\nsquare root was in use.\n\nCurrently there are three sligtly different conventions:\n\n- real one: sqrt can be only applied to non-negative numbers\nand produces non-negative values. This one is used in\nschools before pupils learn about complex numbers,\nsometimes in real analysis and in theory of real fields\n\n- algebraic: y = sqrt(x) is basically abbreviation for\nequation y^2 = x. Using functional notation is\njustified by fact that in algebraic context it normally\ndoes not matter which root you use. In fact, given\na single root there is no algebraic way to distinguish\nit from the other one. Only dependent roots, like\nsqrt(2)*sqrt(3) versus sqrt(6) allows you to see\ndifference. In some context dependent roots are\njust illegal input, in other context case reasoning\nis needed.\n\n- complex analytic: sqrt is a multivalied function. When\nwe need a single branch this branch is choosen so that\nresulting function is analytic\n\nYou may ask: Is not the principial branch of squre root\nthe \"true\" one? My opinion is that using principial branch\nfor numerical computation is unavoidable imperfection\nmorally not much different from using floating point\ninstead of true reals. Simply, for numeric computations\nwe choose alternative which can be implemented with\nreasonable effort and frequently gives correct results.\nBut ultimately it is up to programmers to make sure\nthat correct branch is choosen. For example FriCAS\nnumeric code for elliptic functions makes heavy use\nof square roots. To ensure nice branch cuts for\nelliptic integrals I had to compute appropriate\nbranch of square root and this branch is different\nthan principal branch.\n\nWaldek Hebisch"}
{"text": "Retrieved from http://mathoverflow.net/questions/63978/lowest-weight-representation-of-loop-groups?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to understand lowest representations of loop groups as developed in Pressley and Segal's book. Specifically I want to be able to compute the weight spaces that appear in a lowest weight representation. I realize there is a formula for this -my question is along the lines of how to apply the formula correctly.\n\nI tried to do a small example with $LSL_3$ (actually $\\mathbb{C}^\\times_{\\theta} \\ltimes \\tilde LSL_3$) and something fishy happened so I was hoping someone could point out my mistake. The maximal torus is $\\mathbb{C}^\\times_\\theta \\times T \\times \\mathbb{C}^\\times$ where $\\mathbb{C}^\\times_\\theta$ is the loop rotations and the other $\\mathbb{C}^\\times$ is central.\n\nThe fundamental weights are $w_0 = (0,0,1)$, $w_1 = (0,-\\omega_1,1)$, $w_2 = (0, -\\omega_2,1)$. The positive roots are $(0,\\alpha_1,0), (0,\\alpha_2,0),(1,-\\alpha_3,0)$. Where $\\omega_i,\\alpha_i$ are fundamental weights and positive roots of $SL_3$. Pressley and Segal normalize the Killing form so $\\langle H_{\\alpha_i},H_{\\alpha_i}\\rangle = 2$. Choosing coordinates $H_{\\alpha_1} = [1\\ \\ 0]^T$, $H_{\\alpha_2} = [0\\ \\ 1]^T$, $\\alpha_1 = [2 \\ \\ -1]$, $\\alpha_2 = [-1 \\ \\ 2]$, $\\omega_1 = [1\\ \\ 0]$, $\\omega_2 = [0\\ \\ 1]$ and the restriction of the Killing form to the torus is just the Cartan matrix $(B_{11} = B_{22} = 2, B_{12} = B_{21} = -1)$.\n\nI'm interested in the representation $V_{\\tilde \\lambda}$ of lowest weight $\\tilde\\lambda = (0, - \\alpha_3,3) = w_0 + w_1 + w_2$. Let $\\tilde \\mu = (m,\\mu, 3)$ be a weight of $V_{\\tilde \\lambda}$. According to Loop Groups (11.1.1) it is the case that $\\tilde \\mu - \\tilde \\lambda = (m,\\mu +\\alpha_3, 0)$ is a sum of positive roots. Viewing $B$ as a map from co-characters to characters and noting that $\\alpha_i = BH_{\\alpha_i}$ it follows that we can write $\\mu = B[a\\ \\ b]^T$ for some $a,b$.\n\nAccording to (9.3.7) on pg 180 of Loop Groups the $\\tilde\\mu =(m, \\mu,3)$ which satisfy\n\n$3\\langle \\mu,\\mu\\rangle - 6m = 6 = 3\\langle -\\alpha_3,-\\alpha_3\\rangle$\n\nappear among the weight of $V_{\\tilde \\lambda}$. This says\n\n$m = {1 \\over 2}\\langle\\mu,\\mu\\rangle-1 = {1\\over 2}[a\\ \\ b]B[a\\ \\ b]^T - 1 = a^2 + b^2- ab -1$.\n\nTaking $a,b = 0$ produces the weight $\\tilde \\mu = (-1, 0, 3)$ but then $\\tilde \\mu - \\tilde \\lambda = -(1,-\\alpha_3,0)$. Which is certainly not a sum of positive roots. So what gives?\n\nshare|improve this question\nI'm tempted in a situation like this to suggest that you try contacting one or both authors by email. That doesn't invariably get a helpful response (or any response), but on the other hand the authors of books have a vested interest in clarifying things for their readers. \u2013\u00a0 Jim Humphreys May 5 '11 at 14:32\nWhy is the equation (9.3.7) as you have it? I would have thought $||\\mu||^2-2mh=||\\widetilde \\lambda||^2$ should be $\\langle \\mu, \\mu \\rangle - 6m = \\langle -\\alpha_3, -\\alpha_3 \\rangle=2$ \u2013\u00a0 charris May 6 '11 at 0:06\n@charris My original thinking was that for a level $h$ representation you have to take $h$ times the standard pairing. But perhaps its as you say; that would certainly prevent negative values of $m$. \u2013\u00a0 solbap May 6 '11 at 19:51\n@charris actually that business of taking $h$ times the standard pairing is something I confused with representation of loop groups of tori (9.5.10) so I think you are absolutely right. \u2013\u00a0 solbap May 6 '11 at 20:31\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nThe formula for the invariant bilinear form is given in $(4.9.3)$ on page 64 $$\\langle (x_1,\\xi_1, y_1),(x_2,\\xi_2,y_2) \\rangle=\\langle \\xi_1, \\xi_2 \\rangle - x_1 y_2-y_1x_2$$ As I mentioned in the comments, $(9.3.7)$ becomes then $||\\mu||^2-6m=2$. So your last equation would be $m=\\frac{1}{3}(a^2-ab+b^2)-\\frac{1}{3}$. As you said, there's no more worries about negative $m$ and as a consistency check, for $m=0$, the solutions for $[a \\ \\ b]$ are $[\\pm 1 \\ \\ 0]$, $[0 \\ \\ \\pm 1]$, $[1 \\ \\ 1 ]$, and $[-1 \\ \\ -1]$. Applying, $B$ gives you the six weights in the Weyl orbit of $-\\alpha_3$ (the roots).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?t=165712\nText:\nRegister to reply\n\nH2SO4, dissolution\n\nby moleman1985\nTags: dissolution, h2so4\nShare this thread:\nApr14-07, 03:23 PM\nP: 20\nHello, I have the following problem and am unsure how to solve it, although I believe the heat of dissolution to be -71.76kJ/mol, but I can only see how this would help me if my acid was infinetly dissoluted which is not the case so I need to know how the calculate a temperature rise when this is not the case.\n\nMy acid starts off at 98% wt. total wieght 115.985041 kg, (1158.9 moles H2SO4, and 128.8 moles H2O).\nThe acid ends up at 75% wt. total weight 151.55284 kg, (1158.9 moles H2SO4, and 2103.1 moles H20).\n\nBoth the acid and water initial temps can be taken as 30oC,\n\nSo basically 115.98kg of 98% wt. H2SO4 at 30oC, with 35.5kg water at 30oC\nPhys.Org News Partner Engineering news on\nAugmented reality helps in industrial troubleshooting\nHow wireless technology can dramatically improve ship safety\nApr14-07, 03:52 PM\nP: 20\nthe water is also in vapour phase at the beggining, so will I also have to consider the heat of condensation of the water going from the vapour phase to the liquid phase? thankyou.\nApr16-07, 03:43 AM\nP: 116\nI vote no to the second question, but I'm not sure. It's not like it's steam? If the pressure is 1 atm of course... They are little particles of water at 30 \u00b0C.\n\nAnd, the solution of H2SO4 seems 18 M so, I think you may use the formular of:\n\nWhich you posted yourself.\n\nSo if all H2SO4 dissociates it will give: 83170 kJ of energy to the solution.\n\nFor the warmth capacity I'd say approximately:\n\nH2SO4: 3,5 J/gC . 113000 g = 400 kJ/C\nH2O: 4,18 J/gC . 35,3 kg = 150 kJ/C\n\nSo dQ = (cp1m1 + cp2m2) dT\n\ndT = 152 \u00b0 C\n\nOh boy, there must be something wrong with the calculation??? Hey I'm not a professional... yet.\n\nYour reactor is going to explode... do you have some kind of cooling medium?\n\nThe boiling point of H2SO4 was something at 350\u00b0C so maybe, just maybe your solution won't evaporate at 180 \u00b0C. Otherwise, you're in a big trouble. I don't know how your installation looks like, so that info would be interesting too.\n\nI'm curious myself how you're going to handle this calculation! Please post everything you got.\n\nApr16-07, 05:23 AM\nP: 20\nH2SO4, dissolution\n\nHi can I just say first thanks loads for your reply, I will be using a cooling loop in the system, sorry but I gave you all the information I got, but it going to 150oC sounds correct. So do you recon that I would be able to half or maybe even third the heating due to it not beening infinet dilution woukld you be able to hazard a guess with a vague explanation, if not it doesn't matter too much all I need to do is put in my report that I presume that it is infinet dissolution, its just that I dont want to be using more cooling than I sholud as I have to do a detailed costing on the system.\n\nOne other thing I also found the heat of dissolution to be 800kJ/mol, but that was on, or however it's spelt, so it's probaly not reliable.\n\nThanks loads.\nApr16-07, 05:30 AM\nP: 20\nI'm just looking for a basic temperature rise, the whole system is an absorption tower, a wet gas feed at the bottom, and the acid feed at top, so somehow I'm also going to have to come up with a compromise of the two phases increasing with temperature due to the dissolution and the general heat transfere between the two counter flows as both streams will rise in temperature but flow past the inlet streams as they exit which will be at the original lower temperature, but I'm probaly just going to say and presume there is no heat transfer from counter flows but that both the acid and gas are heated together to the same temperature, ha lazy....!\nApr16-07, 01:32 PM\nP: 20\nhi, would you not also have to take into consideration the heating of the gas via the acid (heat transfer), I have a spread sheet set up which considers this and as the gas flow rate is many time the liquid flow rate, and whole system only reaches 55.65oC, and this is good as the column works at optimum absorption at 55-60oC. This is assuming that the heat is shared equally let me know what you think of this if you think its a bad idea then I scrap it, thanks\nApr16-07, 07:06 PM\nP: 116\nSo you spray HS2O4 above and you have some kind of gas at the bottom? Or is it air with water?\nAs for the 800 kJ/mol, that seems much! Meaning the reactor will even blow more up than I predicted. You should know exactly what you are doing here!!!\n\nThe thing is, I calculated that it's 18 M and the internet site also uses 18 M solution as an example. So the heat of reaction they use there should be correct. Maybe I read something wrong there.\n\nI think -800 kJ/mol is the formation of HSO4- from pure H2SO4 (solid) with H2O and -70 kJ/mol takes in account the solution of H2SO4/H2O.\n\nI'm just a student don't take me so seriously! I make mistakes. :)\n\nRegister to reply\n\nRelated Discussions\nH2SO4 preparation Chemistry 6\nCuO dissolution Materials & Chemical Engineering 0\nH2SO4 + Sugar Reaction? Chemistry 1\nQuestions on HCl and H2SO4 reactions Biology, Chemistry & Other Homework 5\nShape of H2SO4 Chemistry 3"}
{"text": "Retrieved from http://mathoverflow.net/questions/11981/building-a-multi-variable-regression-model\nText:\nTake the 2-minute tour \u00d7\n\nI have a large set of data points which have 18 dimensions to them. I know that these data points must follow a strict polynomial formula with no possible variance. Given that I have enough data (I assure you I have), how do I go about building a regression model to find the general formula of the lowest polynomials for the equation which gives these data points?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nThe input dimension being 18 is a little problematic, so I have a few suggestions. I'm putting the statistical approach first due to your choice of tags and terminology..\n\nLinear regression can be made to fit polynomials by simply explicitly creating all the monomial terms; ie for an input with two dimensions $x= (x_1,x_2)$, for a quadratic you'd instead use $x' = (1,x_1,x_2,x_1x_2,x_1^2,x_2^2)$. Notice that this means, to add all $d$th order terms, you would create $O(18^d)$ dimensions! Notice furthermore that your regression model has equivalently many parameters! Therefore, it may be beneficial to try to simplify the model a little with some regularization, maybe use lasso (l1-regularization). Note that, as specified, the degree of the polynomial is not being minimized. The regularization I mentioned only minimizes the l1 length, and even putting a sparsity constraint on the weights alone (which is simpler than minimizing degree) is nonconvex. To find the degree, you could binary search; ie try degrees $1,2,4,8,\\ldots$ until you get zero error, and then binary search within the last interval to find the exact order.\n\nAnother approach is to directly use polynomial interpolation. Simply grow $d$, building an interpolating polynomial at each iteration, and stopping when the one built on the provided points fits all other points. For univariate data, the Lagrange Polynomial[1] is the way to go. I don't know your case offhand but just noticed wikipedia has a \"polynomial interpolation\" page which should be helpful.\n\nanything you try will be slow due to the dimension, your stipulation that you necessarily find the absolute smallest degree, and the vast number of parameters in any such polynomial.\n\n[1] lagrange interpolation\n\nshare|improve this answer\nadd comment\n\nIf there is no possible variation then this isn't really a regression question. It's straight up linear algebra. You have alot of equations of the form. y= ax_1+b x_2+..+q x_18 + aa x_1^2+ab x_1x_2... (all terms taken 2 at a time),+ (stuff taken 3 at a time)+..\n\nNow either you have an idea of where to end this and need to solve a giant matrix, or you aren't sure where to end this and don't really have enough data. By not enough data I mean that you can fit infintely many polynomials if you allow the degree to be unbounded. Just as you can fit infintely many polynomials to a finite set of points in R^2.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/3576/why-does-this-sum-mod-out-to-0/3577\nText:\nTake the 2-minute tour \u00d7\n\nIn making up another problem today I came across something odd. I've been thinking it over and I can't exactly place why it's true, but after running a long Python script to check, I haven't yet found a counter example.\n\nWhy is $\\sum_{n=1}^{m}{n^m}\\equiv 0\\mod m$ true for all odd $m \\ge 3$? The script showed me that each term for odd $m$ is equivalent to $n$ when taken $\\mod m$ (until term $m$), and so the sum would be $\\frac{m(m-1)}{2}$ which is obviously $0 \\mod m$. What I am unable to understand is why $n^m\\equiv n \\mod m$ only for odd $m$.\n\nshare|improve this question\nThe claim in the second paragraph is false in general; it is only true for primes and certain \"pseudoprimes.\" For example, it should be false for m = 15. See en.wikipedia.org/wiki/Fermat's_little_theorem and en.wikipedia.org/wiki/Euler's_theorem . \u2013\u00a0 Qiaochu Yuan Aug 29 '10 at 0:51\nNope, it's still true for every odd number. See Casebash's answer below. \u2013\u00a0 Eugene Bulkin Aug 29 '10 at 1:01\nSorry, I meant the claim in the second sentence of the second paragraph. I assume you meant to say $n^m$ is equivalent to $n$ when taken $\\bmod m$. \u2013\u00a0 Qiaochu Yuan Aug 29 '10 at 1:05\nNearly, but not quite, ironic that just a teensy bit of cancellation can so radically change an outcome that is subtle term-wise. \u2013\u00a0 paul garrett Jul 11 '11 at 21:27\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nIf it is odd, each n can be paired with -n. So we get $n^m+(-n)^m=n^m-n^m=0$\n\nshare|improve this answer\nIn fact, the sum of $n^r$ should work for any odd value of $r$ regardless of what m is \u2013\u00a0 Casebash Aug 29 '10 at 0:48\nAh, there we go. That was the thing I was missing. Thanks! \u2013\u00a0 Eugene Bulkin Aug 29 '10 at 0:58\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/55169.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPixels in a Triangle\n\nDate: 08/02/99 at 09:14:15\nFrom: Berkant Barla Cambazoglu\nSubject: Triangle pixel intersection\n\nI basically want to find the number of pixels inside a 2D triangle. \nThe triangle may have nodes with floating point coordinate values, but \nthe points returned as answer must have integer-valued coordinates.\n\nThere are some exact solutions: we may scan convert the triangle, or \nperform an inside-outside test over the triangle using the line \nequations of the edges forming the triangle. However, these methods \nare too slow, and they are unnecessary for this particular problem. \nI don't want the coordinates of the pixels; what I seek is just the \ntotal number of pixels inside the triangle.\n\nAn approximation to this problem would be to calculate the area of the \ntriangle and assume that it is the same with the number of pixels \ninside the triangle. However, in this method some triangles can get \nmuch higher values than the actual value. For example, even a triangle \nhas no pixels inside, it is always assigned a positive value instead \nof 0.\n\nI will be glad if you can offer me a smart solution. Thanks for your \n\nDate: 08/02/99 at 13:03:26\nFrom: Doctor Peterson\nSubject: Re: Triangle pixel intersection\n\nHi, Berkant.\n\nThis sounds like it might be a good place to apply Pick's Theorem, \nwhich you can read about here:\n\n\nThis says that the area of a triangle (or any polygon) whose vertices \nare lattice points (in your situation, this is the same as saying they \nare on pixels - integer coordinates) is I+B/2-1, where I is the \nnumber of lattice points (pixels) inside the polygon, and B is the \nnumber of lattice points on the boundary. You want to find I, so \nyou'll need to find the area and B. Of course, your vertices don't \nnecessarily have integer coordinates, but it will probably work if you \nround to find the corner pixel.\n\nSo what's B? The number of lattice points exactly on the line from \n(x1,y1) to (x2,y2), including one of its endpoints, will be the GCD of \n(x1-x2) and (y1-y2). Add these and you'll have B.\n\nSo my formula for I, given three vertices (x1,y1), (x2,y2), and \n(x3,y3) rounded to integers, would be\n\n   I = A + 1 - [gcd(x1-x2, y1-y2) + gcd(x2-x3, y2-y3)\n       + gcd(x3-x1, y3-y1)]/2\n\nIn case you're not familiar with it, you can get the area (again after \nrounding the coordinates) this way:\n\n  A = [(x1-x2)(y1+y2) + (x2-x3)(y2+y3) + (x3-x1)(y3+y1)]/2\n    = [x1 y2 - x2 y1 + x2 y3 - x3 y2 + x3 y1 - x1 y3]/2\n\nwhich is the same as using a determinant, as explained here:\n\n\nLet's test this with a triangle that will contain no pixels:\n\n    (0,0) (15,15) (15,16)\n\nThe area is\n\n    A = [0*15 - 15*0 + 15*16 - 15*15 + 15*0 - 0*16]/2 = 7.5\n\n    gcd(-15,-15) = 15\n    gcd(0,-1)    =  1\n    gcd(15,16)   =  1\n\n    I = 7.5 + 1 - (15+1+1)/2 = 8.5 - 8.5 = 0\n\nwhich is correct.\n\nI'm a little uncertain about how this will work out in practice, \nbecause if you're working with lines drawn on a computer, the \nalgorithm that draws the lines will count many pixels that are \nactually inside as being part of the edge, in order to be able to draw \nit without gaps. On the other hand, if you're looking for exactly the \npixels within the actual triangle defined by non-integer vertices, \nyou'll gain or lose points when you round the coordinates. Whether \nthis is acceptable depends on the details of your application.\n\nPlease let me know whether or not this helps.\n\n- Doctor Peterson, The Math Forum\nAssociated Topics:\nHigh School Geometry\nHigh School Practical Geometry\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/215999/how-many-0s-are-at-the-end-of-20\nText:\nTake the 2-minute tour \u00d7\n\nI'm not exactly sure how to answer this question, any help would be appreciated. After reading this I'm still not sure.\n\n\nshare|improve this question\nDoes this site answer it and walk through enough details? purplemath.com/modules/factzero.htm, using the number of fives method or Wolfram Alpha: wolframalpha.com/input/?i=number+of+trailing+zeros+in+20%21 \u2013\u00a0 Amzoti Oct 18 '12 at 1:09\nThat's funny, I literally just stumbled across this site. \u2013\u00a0 Unknown Oct 18 '12 at 1:10\nEvidently there is only one! (sorry, couldn't resist) \u2013\u00a0 treble Oct 18 '12 at 1:34\nI got asked this in a programming job interview once, but for $100!$ - I didn't get the job :( \u2013\u00a0 Ergwun Oct 18 '12 at 6:50\nadd comment\n\n3 Answers\n\nup vote 10 down vote accepted\n\nThere is a general formula that can be used. But it is good to get one's hands dirty and compute.\n\nIf $20!$ seems dauntingly large, calculate $10!$. You will note it ends with two zeros. Multiplying $10!$ by all the numbers from $11$ to $20$ except $15$ and $20$ will not add to the zeros. Multiplying by $15$ and $20$ will add one zero each.\n\nRemark: Suppose that we want to find the number of terminal zeros in something seriously large, like $2048!$. It is not hard to see that this number is $N$, where $5^N$ is the largest power of $5$ that divides $2048!$. This is because we need a $5$ and a $2$ for every terminal $0$, and the $5$s are the scarcer resource.\n\nTo find $N$, it is helpful to think in terms of money. Every number $n$ between $1$ and $2048$ has to pay a $1$ dollar tax for every $5$ \"in it.\" So $45$ has to pay $1$ dollar, but $75$ has to pay $2$ dollars, because $75=5^2\\cdot 3$. And a $5$-rich person like $1250$ has to pay $4$ dollars.\n\nLet us gather the tax in stages. First, everybody divisible by $5$ pays a dollar. These are $5$, $10$, $15$ and so on up to $2045$, that is, $5\\cdot 1, 5\\cdot 2,\\dots, 5\\cdot 409$. So there are $409$ of them. It is useful to bring in the \"floor\" or \"greatest integer $\\le x$ \" function, and call the number of dollars gathered in the first stage $\\lfloor 2048/5\\rfloor$.\n\nBut many numbers still owe some tax, namely $25,50,75,\\dots,2025$. Get them to pay $1$ dollar each. These are the multiples of $25$, and there are $\\lfloor 2048/25\\rfloor$ of them.\n\nBut $125$, $250$, and so on still owe money. Get them to pay $1$ dollar each. We will gather $\\lfloor 2048/125\\rfloor$ dollars.\n\nBut $625$, $1250$, and $1875$ still owe money. Gather $1$ dollar from each, and we will get $\\lfloor 2048/625\\rfloor$ dollars.\n\nNow everybody has paid up, and we have gathered a total of $$\\lfloor 2048/5\\rfloor + \\lfloor 2048/25\\rfloor +\\lfloor 2048/125\\rfloor +\\lfloor 2048/625\\rfloor$$ dollars. That's the number of terminal zeros in $2048!$.\n\nshare|improve this answer\nI don't always upvote answers that are in \"competition\" with my own...but when I do, it's because it's a damn good answer! (+1) \u2013\u00a0 Cameron Buie Oct 18 '12 at 3:59\nYours is a good answer, now with an additional upvote. I thought that this might be an opportunity to describe in very concrete terms the process that yields the usual formula. \u2013\u00a0 Andr\u00e9 Nicolas Oct 18 '12 at 4:13\nAgreed. You did it much more explicitly and intuitively than I (though, to be fair, I'd never even realized that there was an explicit formula before, and was operating off the cuff). Upvote appreciated. \u2013\u00a0 Cameron Buie Oct 18 '12 at 4:33\nadd comment\n\nCount up the number of factors of $5$ and the number of factors of $2$ in $20!$. Since we get a zero for every pair of factors $5\\cdot 2$, then the minimum of these will answer your question. More simply, $5$ happens less often as a factor (since it's bigger than $2$), so we need only count up the number of $5$'s. In particular, there's one each in $5,10,15,20$, so there are $4$ zeroes at the end.\n\nIf the problem had asked about $25!$, then there'd be $6$ zeroes--not $5$--because there are two factors of $5$ in $25$. Similar idea for other numbers.\n\nshare|improve this answer\nIt gets harder when you try it with bases other than 10. \u2013\u00a0 marty cohen Oct 18 '12 at 1:44\nThat's true, Marty, though not relevant to the context. \u2013\u00a0 Cameron Buie Oct 18 '12 at 1:52\nadd comment\n\nGeneral formula (for the interested) about the number of zeroes in n! in any base (b). First consider all prime factors of b, then consider the biggest one (p). Then use this formula.\n\n$\\lfloor n/p \\rfloor$ + $\\lfloor n/p^2 \\rfloor$ + $\\lfloor n/p^3 \\rfloor$ + ....\n\nThis and using the fact that, the floor becomes zero after some exponent, you can calculate the number of zeroes in any base.\n\n\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/84671/minimum-distance-between-two-data-sets\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have two sets of data, $X$ and $Y$, each of which contains $10$ positive numbers. Now let us order the data sets $X=\\left\\{ x_{1},\\cdots,x_{10}\\right\\}$, $x_{1}\\ge\\cdots\\ge x_{10}>0$ and $Y=\\left\\{ y_{1},\\cdots,y_{10}\\right\\}$, $y_{1}\\ge\\cdots\\ge y_{10}>0$ and define $d:=\\sum_{k=1}^{10}\\left|x_{i_{k}}-y_{j_{k}}\\right|$, that is the sum of the distances of the numbers in pairs from the two data sets. Does anyone know how to prove that $d$ achieves its minimum when $i_{k}=j_{k}=k$ for $1\\le k\\le10$, or is there any counter example if it is not true? Thanks.\n\nshare|improve this question\nsame question was posted and was answered here: math.stackexchange.com/questions/95546/\u2026 \u2013\u00a0 Paul Jan 1 '12 at 11:29\nadd comment\n\n1 Answer\n\nHere is a slightly more general proof.\n\nLet $x$ be any vector in $R^n$. Let $x^\\downarrow$ denote the vector obtained from $x$ by sorting its entries in decreasing order, so that $x_1^\\downarrow \\ge x_2^\\downarrow \\ge \\cdots \\ge x_n^\\downarrow$. Now, let $x, z \\in R^n$, and consider $x+z$. Clearly, if we apply the same permutation to $x$ and $z$ separately, the entire sum $x+z$ is also permuted the same way. Hence, we may assume wlog that $x=x^\\downarrow$. Now, let $x$ be as in your question above, and let $z=-y$.\n\nRecall now the concept of majorization. A quick calculation (also see Theorem II.4.2 of Matrix Analysis by R. Bhatia) shows that $$x^\\downarrow + z^\\uparrow \\prec x + z$$ (since we assumed wlog that $x=x^\\downarrow$); also since $y=-z$ we obtain\n\n$$x^\\downarrow - y^\\downarrow \\prec x - y.$$\n\nBut this majorization implies that for any symmetric gauge function $G$, we have $$G(x^\\downarrow-y^\\downarrow) \\le G(x-y).$$ This then implies the original minimization claim if we choose $G=\\|\\cdot\\|_1$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathhelpforum.com/advanced-statistics/134307-deriving-event-probability-discrete-time-interval-probability-time-series.html\nText:\nThe probability that I am smiling at any given point during the day is given by a function f(t) [note this is not a pdf but simply the probability of the event at a given time; thus 0<=f(t)<=1 but int_0^24 f(s) ds does not necessarily equal 1].\nWhat is the probability P that I will smile during a specific time interval[t1,t2] during the day?\nI have noted that:\nint_t1^t2 f(s) ds has units time and is not bounded above by 1;\nbreaking the time interval into smaller timesteps and treating the probability in each of these as independent (and then multipliying) gives arbitary results since it is dependent on the choice of time step;\ntaking the mean or maximum etc. of f(t) in the interval would mean that watching me for one minute or twenty four hours could have the same probability of success;\nobviously if f(t)=1 for any t in[t1,t2] then P=1 while if f(t)=0 for all t in[t1,t2] then P=0."}
{"text": "Retrieved from http://math.stackexchange.com/questions/266171/irreducibility-of-polynomial-if-no-root-capelli\nText:\nTake the 2-minute tour \u00d7\n\nThis question already has an answer here:\n\nLet $F$ be a field of arbitrary characteristic, $a\\in F$, and $p$ a prime number. Show that $$f(X)=X^p-a$$ is irreducible in $F[X]$ if it has no root in $F$.\n\nThis answer to a related question mentions the result is due to Capelli.\n\nI can prove the result if $F$ has characteristic $p$ as follows. Suppose $f$ is reducible: $f(X)=g(X)h(X)$ with $g(X)$ an irreducible factor of degree $m$, $1\\le m<p$. Then if $\\alpha$ is a root of $g$ in some extension field $K$ of $F$, we have $$f(X)=X^p-\\alpha^p=(X-\\alpha)^p$$ so its divisor $g(X)$ must be of the form $(X-\\alpha)^m$. Since the coefficient of $X^{m-1}$ in $g$ is in $F$, we have $m\\alpha\\in F$. So $\\alpha\\in F$ because $m$ is invertible modulo $p$.\n\nHow would you show the result in other characteristics?\n\nshare|improve this question\nadd comment\n\nmarked as duplicate by leo, Daniel Robert-Nicoud, Sujaan Kunalan, Davide Giraudo, Old John Nov 27 '13 at 21:53\n\n\n3 Answers\n\nup vote 3 down vote accepted\n\nA proof of this result can be found on page 297 of Lang's Algebra and goes as follows.\n\nLet $F$ be a field of characteristic $q \\neq p$. If $f(x)$ has no root in $F$, then it must be the case that $a$ is not a $p$ - th power in $F$. Suppose that $f(x)$ is reducible. By passing the larger extension $K = F(\\alpha)$ , we see that $\\alpha$ must have degree $d$ where $d < p$. Then $\\alpha^p = a$ and by applying $N_{K/F}(-)$ gives that $N_{K/F}(\\alpha)^p = a^d$ by multiplicativity of the field norm. Since $(d,p) = 1$ this means that $a$ is a power of $p$ in $F$, a contradiction.\n\nshare|improve this answer\nI'm curious though because I don't see where the hypothesis that the characteristic is not equal to $p$ is used. \u2013\u00a0 fpqc Dec 28 '12 at 1:33\nWhat I think: If the field is of characteristic $p$ then for any $a\\in F$ there is $b\\in F$ s.t $b^p=a$ hence $F(b)=b^p-a=a-a=0$ hence the polynomial is reducible \u2013\u00a0 Belgi Dec 28 '12 at 1:39\n@Belgi The Frobenius automorphism is surjective IIRC iff the field is finite. \u2013\u00a0 fpqc Dec 28 '12 at 1:40\nhmm yes, but we are not given that $F$ is not finite \u2013\u00a0 Belgi Dec 28 '12 at 1:41\n@Belgi Nor are we given that $F$ is finite. The point now is that $F$ is an arbitrary field of arbitrary characteristic. \u2013\u00a0 fpqc Dec 28 '12 at 1:42\nshow 11 more comments\n\nSuppose the characteristic of $F$ is not $p$. Let $\\Omega$ be the algebraic closure of $F$. By the assumption on the characteristic of $F$, $\\Omega$ has a primitive $p$-th root of unity $\\zeta$. Let $\\alpha$ be a root of $x^p - a$ in $\\Omega$. Since $\\alpha$ is not contained in $F$, $\\alpha \\neq 0$. Hence $\\alpha, \\alpha\\zeta, \\cdots, \\alpha\\zeta^{p-1}$ are distinct roots of $x^p - a$. Suppose $x^p - a = g(x)h(x)$, where $g(x)$ and $h(x)$ are monic polynomials in $F[x]$ and $1 \\le$ deg $g(x) \\lt p$. Let $k =$ deg $g(x)$. Let $b$ be the constant term of $g(x)$. Then $b = (-1)^k \\alpha^k \\zeta^m$, where $m$ is an integer. Hence $b^p = (-1)^{kp} a^k$ If $(-1)^{kp} = 1$, then let $c = b$. Suppose $(-1)^{kp} = -1$. If $p$ is odd, then let $c = -b$. If $p = 2$, then let $c = b$. In either case, $c^p = a^k$.\n\nLet $\\Gamma$ be the multiplicative group of $F$. Let $\\Gamma^p = \\{x^p |\\ x \\in \\Gamma\\}$. $\\Gamma^p$ is a subgroup of $\\Gamma$. Let $\\pi$ be the canonical homomorophism $\\Gamma \\rightarrow \\Gamma/\\Gamma^p$. Let $\\beta = \\pi(a)$. Since $x^p - a$ does not have a root in $F$, $\\beta \\neq 1$. On the other hand, $\\beta^p = \\pi(a^p) = 1$. Hence the order of $\\beta$ is $p$. However, since $c^p = a^k$, $\\beta^k = 1$. This is a contradiction. Hence $x^p - a$ is irreducible in $F[x]$.\n\nshare|improve this answer\nadd comment\n\n1) I can give you the details of a paper by Chebotarev translated from russian to german in which appears the Capelli Lemma, yet\n\n2) There's also a paper in italian by Capelli, from 1904, which details I can give you, yet\n\n3) The book \"Algebra I\", by R\u00e9dei, has the same lemma with extensions. Alas, the book was written in hungarian, though it seems to be there's a translation to german with, perhaps, the help of Halm\u00f6s.\n\nGoogling around a little there are several references to that lemma but, as far as I could see, none of the first ones, at least, brings the version you want.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/265650/finding-a-harmonic-function\nText:\nTake the 2-minute tour \u00d7\n\nI need to find a harmonic function in the region ${ {z: |z|<1: Imz>0} }$ whose boundary values are in 1 on the interval $(-1,1)$ and $0$ on the half- circle.\n\nI have no clue, where to start!\n\nI do not think I can proceed like as I used to for finding conformal mapping.\n\nI do not mind getting details since this one of the qual question. Any help much appreciated.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nFirst, find a conformal map from the half-disk to the upper half plane, making sure that the half circle is sent to the positive real half-line, and the diameter of the half-disk is sent to the negative real half-line. (Hint: look at the map $z \\mapsto - \\frac{1}{2}(z + z^{-1})$). Let's call this map $\\Phi$.\n\nSecond, consider the Arg function (or, if you like, the imaginary part of the logarithm with a suitable branch cut making it analytic on the upper half plane). Define your Arg so as to assign the value zero to the positive half line and $\\pi$ to the negative half line.\n\nThird, having done all this, you've concocted a harmonic function $u$ on the upper half plane. Now form $u \\circ \\Phi$, which takes on the correct boundary values.\n\nshare|improve this answer\nWould you please prove more rigorously please. I kind of lost in the second and third part. \u2013\u00a0 Deepak Dec 27 '12 at 0:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/69412/is-lebesgue-borel-non-measurability-actually-caused-by-non-uniqueness\nText:\nTake the 2-minute tour \u00d7\n\nIn ZFC, every construction of a Lebesgue or Borel non-measurable set uses the axiom of choice. None of them that I've seen use choice to define a unique set, even though it's entirely possible to do so (e.g. under the AoC, if $\\kappa = |A|$ is the cardinality of set $A$, then $\\kappa$ is unique). So I've been wondering lately whether the strength of the AoC is enough by itself to construct a non-measurable set.\n\nHere's an attempt at a specific question. In the language of set theory (first-order logic with equality extended with the ZFC axioms), is there a formula without parameters that identifies a unique, Lebesgue/Borel non-measurable set?\n\nshare|improve this question\nIt seems to me that this would imply the existence of non-measurable sets in the G\u00f6del's L, where AC is true. \u2013\u00a0 Martin Brandenburg Jul 3 '11 at 20:07\nI think it would, but I don't see anything in the construction of, say, the Vitali sets, that excludes it from L. And Googling around, I see that it's known that there are \"non-measurable $\\Delta^1_2$ sets\" (I assume w.r.t. the Lebesgue $\\sigma$-algebra) in L. \u2013\u00a0 Neil Toronto Jul 3 '11 at 20:19\nHow about Lusin's set of continued fractions such that there exists an infinite increasing sequence $i_1 \\lt i_2 \\lt i_3 \\lt \\cdots$ with $a_{i_1} \\mid a_{i_2}, \\; a_{i_2} \\mid a_{i_3}, \\ldots$ which is Lebesgue (in fact analytic) but not Borel (Fund. Math 10, 1927, p. 77), see also planetmath.org/encyclopedia/\u2026 \u2013\u00a0 Theo Buehler Jul 3 '11 at 20:39\nnon-Borel and non-Lebesgue sets: two completely different questions. \u2013\u00a0 Gerald Edgar Jul 3 '11 at 20:54\n@Gerald: Yes. I am sneakily asking two questions by parameterizing one question on two values. \u2013\u00a0 Neil Toronto Jul 4 '11 at 4:59\nadd comment\n\n5 Answers\n\nup vote 9 down vote accepted\n\nThe answer below has been edited in light of other answers and comments.\n\nThere are all sorts of models of $ZFC$ in which every set is definable without parameters, including nonmeasurable sets; indeed a recent paper of Hamkins, Linetsky, and Reitz is devoted to such \"pointwise definable\" models.\n\nAlso, as pointed out in Theo Buehler's comment to the question, there certainly exist definable subsets of reals that are $ZFC$-provably not Borel.\n\nHowever, the situation is completely different for measurability. The classical work of Solovay [using an inacessible] shows that there is a model of $ZFC$ in which every subset of reals in $OD(\\Bbb{R})$ is Lebesgue measurable. Recall that $X$ is in $OD(\\Bbb{R})$ if $X$ is definable with parameters from $Ord \\cup \\Bbb{R}$.\n\nAs pointed out in Demer's answer, Krivine [without an inaccessible] provided a model of $ZFC$ in which every ordinal definable subset of reals is measurable. Moreover, as shown by Harvey Friedman, here, there is a model of $ZFC$ [which is a generic extension of Solovay's model] in which the following property holds:\n\n(*) Every equivalence class of sets of reals modulo null sets that is in $OD(\\Bbb{R})$ consists of Lebesgue measurable sets.\n\nNote that (*) implies that no non-measurable subset of reals in definable, since if $X$ is any definable subset of reals that is not measurable, then the equivalence class $\\[X\\]$ of $X$ modulo null sets satisfies the following two properties:\n\n(1) $\\[X\\]$ definable,\n\n(2) No member of $\\[X\\]$ is measurable.\n\nSo, to sum-up, the answer to the question for Lebesgue measurability is negative, i.e., there is no formula $\\phi(x)$ in the language of set theory for which $ZFC$ proves \"there is a unique nonmeasurable subset of reals satisfying $\\phi$\".\n\nHowever, if $ZFC$ is strengthened to $ZFC+V=L$ then such a formula does exist, as pointed out in Goldstern's answer.\n\nshare|improve this answer\nAli, thank you for mentioning my paper with Linetsky and Reitz. But it should also be mentioned that Ali himself has done important work on exactly the same topic (as we mention in our paper). See, for example, academic2.american.edu/~enayat/DO.pdf, and perhaps Ali can post other suitable links. \u2013\u00a0 Joel David Hamkins Jul 4 '11 at 1:28\nI am a bit confused. I think that already Solovay's theorem provides a negative answer to the original question (if you read \"identifies a unique set\" as \"defines a set\"). \u2013\u00a0 Goldstern Jul 4 '11 at 12:32\n@Martin: you are right, Solovay's result already does the job, and Friedman's extends it further. I will edit to clarify this point. \u2013\u00a0 Ali Enayat Jul 4 '11 at 16:28\nI am in awe at how deep the answer to this question is. Thanks! \u2013\u00a0 Neil Toronto Jul 5 '11 at 1:04\nAli, I think that the result of Krivine that you mention gets only that all OD sets are Lebesgue measurable. For OD$(\\mathbb R)$ sets you really need a Solovay-style argument, using an inaccessible. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:02\nshow 2 more comments\n\nThe other answers are excellent. But since you have adopted such a strong notion of definability, let me augment them with a positive observation.\n\nThe fact is that any particular set can be made definable without parameters in a forcing extension of the universe $V$. Indeed, there is a single definition $\\varphi(x)$, such that for any set $A$ at all, there is a forcing extension $V[G]$ in which $A$ is the unique set such that $\\varphi(A)$. Furthermore, one can arrange that the forcing extension $V[G]$ agrees with $V$ far beyond the reals, so that it has the same reals, the same sets of reals, the same measurable sets and so on for quite a long way.\n\nIn particular, there is a single definition such that for any non-Lebesgue measurable set $A$ that you favor, there is a forcing extension $V[G]$, an alternative set-theoretic universe, in which $A$ is defined by $\\varphi$ and still non-measurable there.\n\nLet me explain the proof. Fix any set $A$. Let $\\kappa$ be the cardinality of the transitive closure $\\text{TC}(\\{A\\})$. Thus, there is binary relation $E$ on $\\kappa$ for which $\\langle\\kappa,E\\rangle\\cong\\langle\\text{TC}(\\{A\\}),{\\in}\\rangle$. This isomorphism is unique, since it is precisely the Mostowski collapse. Let $E_0\\subset\\kappa$ be the set of ordinals coding pairs in $E$. In the style of Easton's theorem, let $\\mathbb{P}$ be the forcing notion coding the GCH pattern on the regular cardinals above $2^{\\aleph_0}$ to first have a block of length exactly $\\kappa$ on which the GCH holds, and then an violation of GCH and then a sequence of length $\\kappa$ on which the GCH pattern on the regular cardinals matches the elements of $E_0$. In the resulting forcing extension $V[G]$, the cardinal $\\kappa$ and the set $E_0$ and hence $E$ and hence $A$ are definable without parameters. Because the forcing is sufficiently closed, it does not adds new reals or sets of reals and it does not affect measurability. So in the extension, the set $A$ is definable by the formula $\\varphi$ that expresses the decoding of the GCH pattern to $E_0$ and hence $E$ and hence $A$. This coding idea is due originally to K. McAloon.\n\nThe conclusion is that there is a kind of universal definition $\\varphi$, which can serve to define any object at all, if only you apply the definition in the correct set-theoretic universe.\n\nshare|improve this answer\nThat is really cool, but it seems like cheating! \"Indeed, there is a single definition $\\phi(x)$, such that <i>for any set $A$ at all</i>...\" So you can invent a universe in which $\\phi$ uniquely identifies any set that you like. But then, in the meta-set-theory in which you build this universe, that set $A$ may be defined in some non-unique way. If you handed me this set-theoretic universe and such a $\\phi$, I couldn't tell precisely which set $\\phi$ defines. It's more like you would have handed me a <i>collection</i> of universes. Is that right? \u2013\u00a0 Neil Toronto Jul 5 '11 at 1:03\nSort of, yes. The forcing method allows us to build extensions of any given set-theoretic universe, and we can build them in such a way that the definition I mentioned succeeds in defining a given desired set $A$, no matter which $A$ we use (each $A$ gets its own forcing extension). The issue here is that the notion of definable-in-the-language-of-set-theory is extremely powerful and general, perhaps much more general than the kind of definitions that you may have intended. It would make sense to restrict to, say, projective definitions, which are addressed by the other answers. \u2013\u00a0 Joel David Hamkins Jul 5 '11 at 1:24\n@Neil: If Joel \"handed me [a] set-theoretic universe and such a $\\phi$,\" then it would be completely determined what set $\\phi$ defines in that universe. That \"I couldn't tell precisely which set $\\phi$ defines\" is just the result of my inability to fully inspect an infinite universe. (The same inability prevents me from telling exactly what the set of prime numbers is, even though that's the same in all models of set theory whose natural numbers are standard.) What's special about Joel's $\\phi$ is how dramatically its extension varies from universe to universe. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:10\n@Neil: Another comment about \"if you handed me this set-theoretic universe and such a $\\phi$\" --- Joel has, in effect, handed us $\\phi$. His argument specifies a particular formula $\\phi$. Handing you a universe is admittedly harder, because each set-theoretic universe is infinite. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:14\nadd comment\n\nThere is no simple formula that invariably describes a set of reals which is not Lebesgue measurable. The reason is that the existence of certain large cardinals imply that all simply definable subsets of $\\mathbb{R}$ are Lebesgue measurable.\n\nFor example, if there are infinitely many Woodin cardinals with a measurable above, then $L(\\mathbb{R})$ satisfies the Axiom of Determinacy and hence all sets in $L(\\mathbb{R})$ are Lebesgue measurable. Here, $L(\\mathbb{R})$ is the smallest transitive model of ZF that contains all the ordinals and all the reals; this universe contains all the projective sets and much more.\n\nIt seems that the situation is hopeless, but this is not quite true. There has been a lot of recent research which shows that the existence of definable wellorderings of $\\mathbb{R}$ is not incompatible with some of the largest cardinals we know. However, the definition of these wellorderings of $\\mathbb{R}$ is necessarily very complex.\n\nshare|improve this answer\nadd comment\n\nConcerning Borel measurability, it was already pointed out that there is an explicit formula s(x) such that ZFC proves \"The set { x in R: s(x) } is not Borel\". (This is not true for ZF, as was pointed out elsewhere.)\n\nConcerning Lebesgue measurability, ZFC neither proves nor refutes the following:\n\nThere is an OD-definition (or: OD(R)-definition) of a subset of the reals which is non-measurable.\n\nThere is a slight fuzziness here, because there are many non-equivalent notions of definability; OD(R)-definability is perhaps the most prominent and useful.\n\nBut an explicit formula can be given: There is a formula phi(x) in the language of set theory (without parameters) such that ZFC neither proves nor refutes\n\n\"The set { x in R : phi(x) } is non-measurable\".\n\nIn fact, phi(x) can be of a rather simple form ($\\Delta^1_2$, as you remarked above). Here is an abbreviated version of phi: For each real number x, let $x_1$ be the number obtained from x by deleting all even decimal places, $x_2$ by deleting all odd decimal places (do what you want for the countably many reals where this is not well-defined). This defines a measure-preserving Borel map from $\\mathbb R$ to $\\mathbb R\\times \\mathbb R$. Now consider the set M of all reals x for which there is some $\\alpha$ such that $x_1\\in L_\\alpha$, but $x_2\\notin L_\\alpha$. ZFC does neither prove nor refute that M is Lebesgue-measurable.\n\n(I think that the fact that ZFC does not prove that M is measurable is already due to G\u00f6del.)\n\nshare|improve this answer\n@Martin: as an example of a $\\Delta^1_2$ non-measurable set in $ZF+V=L$ isn't it easier to look at the well-ordering $W$ of the reals of order-type $\\aleph_1$ in $L$? Sierpinski had already observed, using Fubini's theorem, that no such $W$ can be measurable. \u2013\u00a0 Ali Enayat Jul 4 '11 at 17:29\nMartin's example is very close to the well-ordering suggested by Ali. The former is the pre-well-ordering obtained from the latter by obliterating the distinction between reals that are constructed simultaneously. Since the resulting equivalence classes are countable, Sierpinski's argument seems adequate for handling the pre-well-ordering as well as the well-ordering. \u2013\u00a0 Andreas Blass Jul 5 '11 at 4:24\nThank you, Andreas. I prefer the preorder that I gave over the (possibly more usual) well-order for two reasons: It is as canonical as the hierarchy of $L_\\alpha$'s; well-ordering the countable differences $L_{\\alpha+1} \\setminus L_\\alpha$ is less canonical, as you have to introduce some arbitrary order on the formulas (or G\u00f6del operations). The second reason is related: In an exposition of $L$, this preorder can appear right after the definition of $L$, half a page before the well-order on $L$ is introduced. \u2013\u00a0 Goldstern Jul 6 '11 at 12:53\nThanks for pointing out that it was probably Sierpinski, not G\u00f6del, who showed that a well-order of the reals in type omega1 yields a nonmeasurable set. \u2013\u00a0 Goldstern Jul 6 '11 at 12:54\nadd comment\n\n\n\"In particular Krivine (1969) showed there was a model of ZFC\nin which every ordinal-definable set of reals is measurable.\"\n\nIf all subsets of $\\mathbb{R}$ are ordinal-definable then there is such a formula.\n\nshare|improve this answer\nFor the second part, you only need that every real is ordinal definable since that already gives a definable wellordering of $\\mathbb{R}$. \u2013\u00a0 Fran\u00e7ois G. Dorais Jul 3 '11 at 22:04\n(And thanks for pointing out that Krivine paper!) \u2013\u00a0 Fran\u00e7ois G. Dorais Jul 3 '11 at 22:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209842/simple-way-for-solving-generic-work-and-time-problems\nText:\nTake the 2-minute tour \u00d7\n\nI was looking for a general way of formulating solutions for work and time problems.\n\nFor example,\n\n30 soldiers can dig 10 trenches of size 8*3*3 ft in half a day working 8 hours per day. How many hours will 20 soldiers take to dig 18 trenches of size 6*2*2 ft working 10 hours per day?\n\nNow i know that Work = Efficiency * Time, but i get confused sometimes in selecting which factor in the given problem will contribute directly to the work i.e. increase it and which factors will result in the work being done faster.\n\nI've seen the method in which one uses a table to write all the parameters given in the problem e.g. making columns titled work, number of soldiers, volume of trench, number of days required, number of hours per day, efficiency, wages etc and uses the direct and inverse proportionality to write the equation for solving a given unknown. However i face the same problem i.e. finding out which factors are directly related and which are in an inverse relation.\n\nIs there a simple way of solving these general problems?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\n$30$ soldiers can dig $10$ trenches of size $8\\cdot 3\\cdot 3$ cube fit in $4$ hours.\n\n$1$ soldier can dig $10$ trenches of size $8\\cdot 3\\cdot 3$ cube fit in $4\\cdot 30$ hours.\n\n$1$ soldier can dig $1$ trench of size $8\\cdot 3\\cdot 3$ cube fit in $\\frac{4\\cdot 30}{10}$ hours.\n\n$1$ soldier can dig $1$ trench of size $1\\cdot 1\\cdot 1$ cube fit in $\\frac{4\\cdot 30}{10\\cdot 8\\cdot 3\\cdot 3}$ hours.\n\n$20$ soldiers can dig $18$ trenches of size $6\\cdot 2\\cdot 2$ cube fit in $$\\frac{4\\cdot 30\\cdot 18\\cdot 6\\cdot 2\\cdot 2}{10\\cdot 8\\cdot 3\\cdot 3\\cdot 20}=\\frac{36}{10}=3.6$$ hours which is clearly $<10$ hours.\n\nThe number of trenches and the size of trenches are directly proportional to the time, but the number of soldiers is inversely roportional to the time, the more the number of soldiers, the lesser is the time.\n\nshare|improve this answer\n@BrianM.Scott, thanks for your observation. \u2013\u00a0 lab bhattacharjee Oct 10 '12 at 5:00\nadd comment\n\nIdentify the basic assumptions. In this problem it\u2019s clear that soldiers are considered interchangeable: they all work at the same rate. (Recall that in some problems we have different workers working at different rates and have to keep track of the work rate of each worker. And it\u2019s the work rates that are important, because they\u2019re additive: if $A$ and $B$ have work rates of $r$ and $s$ amount of work per unit of time, then $A$ and $B$ working together have a combined work rate of $r+s$.) It\u2019s also clear the amount of work is being measured in cubic feet dug, and that cubic feet are to be considered interchangeable: they\u2019re all equally hard to dig. Finally, the basic unit of time here is the hour, since we\u2019re dealing with working days of two different lengths in hours.\n\nNow convert the initial data to basic units. We have $30$ soldiers doing the work. They dig $10$ trenches of $8\\cdot3\\cdot3$ cubic feet each, for a total of $720$ cubic feet of earth dug, and they do it in half of an $8$-hour day, or $4$ hours.\n\nAt this point we can calculate their combined work rate: $720$ cubic feet in $4$ hours is $\\frac{720}4=180$ cubic feet per hour. But that\u2019s the combined work rate of $30$ interchangeable soldiers, so each soldier is digging only $\\frac1{30}$-th of that, or $\\frac{180}{30}=6$ cubic feet per hour.\n\nNow let\u2019s take a look at the question (which we should have had in the backs of our minds all along as a guide to what\u2019s relevant and what\u2019s likely to be useful). We have $20$ soldiers available. We want to dig $18$ trenches, each $6\\cdot2\\cdot2$ cubic feet in size, so we want to move $18\\cdot6\\cdot2\\cdot2=432$ cubic feet of earth. Finally, we want to know how long this will take. We know that one soldier digs $6$ cubic feet per hour, so $20$ soldiers dig $20\\cdot6=120$ cubic feet per hour. It will therefore take them $\\frac{432}{120}=3.6$ hours, considerably less than one $10$-hour working day.\n\nshare|improve this answer\nThanks for the explanation. \u2013\u00a0 Karan Oct 10 '12 at 14:59\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/442326/math-olympiad-problem\nText:\nTake the 2-minute tour \u00d7\n\nA year is peculiar if the sum of the first two digits and the last two digits is equal to the middle two digits. For example, 1978. When was the last peculiar year and is there an algorithm to find any peculiar year?\n\nHow would I go about solving this problem? I am completely lost. Any ideas would help.\n\nshare|improve this question\nfor i=0 to 2013; If ... then print ... \u2013\u00a0 Lord Soth Jul 12 '13 at 20:45\n@LordSoth are you suggesting to put leading zeros to those years with number of digits less than 4, since you've started from 0? \u2013\u00a0 Mathlovin Jul 12 '13 at 20:52\n@LordSoth: Starting in 1978 seems like a much better idea. Or just going backwards from 2013. \u2013\u00a0 Chris Eagle Jul 12 '13 at 20:52\n@MathApprentice I have written the code for you. $1978$ is the last one we saw. Unfortunately we need to wait for another $294$ years (note that we would be dead by then) to see the next one, $2307$. \u2013\u00a0 Lord Soth Jul 12 '13 at 20:56\nGuys, I think all of you are missing one important thing \u2013 this is/was a math problem, not a 5-th grade programming problem, so it needs to be solved somehow analytically and somewhat intuitively. As a starter, if $\\overline{abcd}$ your number, where $0 < a \\le 9,\\, 0 \\le a,b,c \\le 9$ and $a,b,c,d \\in \\mathbb N$, then the condition might be written as $$ 10a + b + 10c + d = 10b + c $$ So, one might try to solve it using divisibility or whatever. \u2013\u00a0 Mathlovin Jul 12 '13 at 21:04\nshow 1 more comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThere is no peculiar year in the 21st century, since the middle two digits form a 1 digit number.\n\nIn the 20th century, any year is of the form $19xy$. Then the year is peculiar if and only if\n\n$$19+xy=9x \\Leftrightarrow 19+10x+y=90+x \\Leftrightarrow 9x+y=71 \\,.$$\n\nThen since $0 \\leq y \\leq 9$ we get\n\n$$9x \\leq 71 \\leq 9x+9 \\Rightarrow 62 \\leq 9x \\leq 71 \\Rightarrow x=7 \\,.$$\n\nPlugging $x=7$ in $9x+y=71$ we get that $y=8$.\n\nThus, the only peculiar year in 20's century is 1978.\n\nIf the question asks for the peculiar year before 1978, it must be in the 19th century or before:\n\n\nIn the 19th century, any year is of the form $18xy$. Then the year is peculiar if and only if\n\n$$18+xy=8x \\Leftrightarrow 18+10x+y=80+x \\Leftrightarrow 9x+y=62 \\,.$$\n\n\n$$9x \\leq 62 \\leq 9x+9 \\Rightarrow 53 \\leq 9x \\leq 62 \\Rightarrow x=6 \\,.$$\n\nPlugging $x=6$ in $9x+y=62$ we get that $y=8$.\n\nThus in the 19th century the only peculiar year is $1868$.\n\nP.S. Any peculiar year of the form $1abc$ satisfies\n\n$$10+a+10b+c=10a+b \\Rightarrow 9a-9b-c=10$$\n\nThis implies that $c \\equiv -1 \\pmod{9}$ thus $c=8$ and then\n\n$$a-b=2 \\,.$$\n\nFrom here you get easily all the peculiar years between $1000$ and $1999$.\n\nP.P.S. If you are looking for all $4$ digits answers $abcd$ then you need to solve\n\n$$10a+b+10c+d=10b+c \\Rightarrow 10a+d= 9(b-c) \\,.$$\n\n\n$$a+d \\equiv 0 \\pmod 9 \\,,$$ and any pair $(a,d)$ which satisfies this relation uniquely determine $b-c$.\n\nSo fixing $a$ you get the value(s) of $d$ and from here $b-c$.\n\nshare|improve this answer\nThe answer is getting too long, so added this as a comment. The $a+d \\equiv 0 \\pmod 9$ is pretty obvious if you are familiar with $\\pmod 9$ arithmetic: $$a+b+c+d \\equiv ab+cd \\equiv bc \\equiv b+c \\pmod 9 $$ \u2013\u00a0 N. S. Jul 12 '13 at 21:29\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/41236/deriving-the-poynting-theorem/41240\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to derive the Poynting theorem. So far, I've only been able to narrow down which equations I think I'll need to do so. These are the equations:\n\nMaxwell's Equations: $$ \\nabla\\times{\\bf E} = - {{\\partial{\\bf B}}\\over{\\partial t}} $$ $$ \\nabla\\times{\\bf H} = {\\bf J} + {{\\partial{\\bf D}}\\over{\\partial t}} $$ Equations relating the flux densities and fields: $$ \\bf D = \\epsilon_0\\bf E + \\bf P $$ $$ \\bf B = \\mu_0\\bf H + \\mu_0\\bf M $$ The vector identity: $$ \\nabla\\cdot (\\bf E\\times\\bf H) = (\\nabla\\times\\bf E)\\cdot \\bf H - (\\nabla\\times\\bf H)\\cdot \\bf E $$ Using these equations, I need to obtain Poynting's theorem, which is given as: $$ \\nabla\\cdot\\bf S = -\\frac{\\partial}{\\partial t}(\\frac{1}{2}\\epsilon_0\\bf E^{2}+\\frac{1}{2}\\mu_0\\bf H^{2})+\\bf E\\cdot\\frac{\\partial\\bf P}{\\partial t}+\\mu_0\\bf H\\cdot\\frac{\\partial\\bf M}{\\partial t} $$ Could someone please help me out?\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 1 down vote accepted\n\nFirst of all, I think you're missing a $-\\textbf{J}.\\textbf{E}$ term in the RHS of your final expression. The rest of the expression looks fine.\n\nI present here some general guidelines on how to approach this derivation. As per the homework guidelines of stackexchange I will not provide all the steps. Others are welcome to correct me on this if I have not completely understood the guidelines. I understand that solving coupled equations using vector calculus can be overwhelming and error-prone. Therefore, I will provide \u201canchor points,\u201d which are nothing but validation steps that you are heading in the right direction. My TA used this technique. If you are getting some horrible terms, which I failed to mention, then it is \u201cprobably\u201d time to step back and recheck your calculations. The reason I say \u201cprobably\u201d is because it is possible that you come up with an alternate derivation. I think the one I worked out is the simplest one. Here it is:\n\nYou can observe that the identity is nothing but:\n\n$$\\nabla.\\textbf{S}=(\\nabla \\times \\textbf{E}).\\textbf{H}-(\\nabla \\times \\textbf{H}).\\textbf{E}$$\n\nThe two terms on the RHS of the above equation should give a hint as to which equations you should manipulate first. Where in the above list can you find $\\nabla \\times \\textbf{E}$ or $\\nabla \\times \\textbf{H}$? You\u2019ll need to bring those equations in that form first, i.e. the form $(\\nabla \\times \\textbf{E}).\\textbf{H}$ and $(\\nabla \\times \\textbf{H}).\\textbf{E}$ and then substitute their modified RHS in the identity. After all these manipulations, say you have obtained a form (*). You can observe that the RHS of (*) has time derivatives. You can now start seeing that (*) is closer to the form that you want. You will now need to use $\\textbf{D}= \\epsilon_0 \\textbf{E}+\\textbf{P}$ and $\\textbf{B}= \\mu_0 (\\textbf{H}+\\textbf{M})$ in (*) in the time derivatives. Yes, you are missing the latter in the above list. After a little bit of simplification, you will need to obtain a contracted form. I will show one (of the two):\n\n$$\\textbf{E}.\\frac{\\partial \\textbf{E}}{\\partial t} = \\frac{\\partial}{\\partial t}\\left(\\frac{1}{2}\\textbf{E}^2\\right)$$\n\nAfter performing a similar manipulation for the magnetic field term, you will obtain the desired expression (with the missing $-\\textbf{J}.\\textbf{E}$).\n\nshare|improve this answer\nadd comment\n\nPoynting's theorem is the statement of the conservation of energy and momentum for a system of charged particles and electromagnetic fields.\n\nYou're on the right track. A definition should help you get the theorem into standard from: $u = \\frac{1}{2}(\\mathbf{E}\\cdot\\mathbf{D} + \\mathbf{B}\\cdot\\mathbf{H})$. (Up to some constants like $\\mu_0$, $\\epsilon_0$ and $4\\pi$.)\n\nThe result you're looking for is: \\begin{align} \\frac{\\partial u}{\\partial t} + \\nabla\\cdot\\mathbf{S} = -\\mathbf{J}\\cdot\\mathbf{E}. \\end{align}\n\nBest of luck.\n\nshare|improve this answer\nadd comment\n\nWell, trying to get in the form of what Mark Wayne put down...you can start with the dfinition of the energy density \"u\" and find the partial wrt time. From there you can use Maxwell's Equations to make some substitutions. Finally in the end you will NEED a not so known/popular vector identity to give you the (ExB) term. Good luck...not a bad derivation at all :)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141999/series-solution-near-ordinary-points-for-second-order-differential-equations?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nGiven $(1+x^2)y''+2xy'-2y = 0$\n\nThe above equations obviously has analytic points everywhere except for $x=1$ and $-1$.\n\nFind two linearly independent solutions $y_1$ and $y_2$ to the differential equation valid near $x_0=0$. To make life a little easier, choose the linearly independent equations:\n\n$y_1$ $:$ $a_0$ = $y(x_0)$ = 1 and $a_1$ = $y'(x_0)$ = 0\n\n$y_2$ $:$ $a_0$ = $y(x_0)$ = 0 and $a_1$ = $y'(x_0)$ = 1\n\nAfter a mess of writing, I came up with the following:\n\n$a_{n+2}$ = $[{-(n-1)(n)a_n - 2a_n(n-1)}]/[{(n+1)(n+2)}]$\n\nI don't know if that monster is right, but that's where I need you help. Can somebody give this a sanity check, and then solve the rest?\n\nshare|improve this question\nSome more detail would be nice. What did you get after substituting your power series ansatz into your differential equation? \u2013\u00a0 \uff2a. \uff2d. May 7 '12 at 1:43\nI checked the series solution myself, your expression of $a_{n+2}$ looks correct to me. \u2013\u00a0 Shuhao Cao May 7 '12 at 2:14\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nIf we set up $y = \\displaystyle \\sum^{\\infty}_{n=1} a_n x^n$ like you did, plugging back to the original equation: $$ (-2a_0+2a_2) + 6a_3 x +\\sum^{\\infty}_{n=2}\\Big((n+2)(n+1)a_{n+2} - (n-1)(n+2)a_n\\Big)x^n = 0 $$ simplify the expression for $a_{n+2}$ when $n\\geq 2$: $$ a_{n+2} = -\\frac{n-1}{n+1} a_n \\qquad (*) $$ for the constant and $x$-term we have: $$ a_0 = a_2, \\text{ and } a_3 = 0 $$\n\n  \u2022 Now if the initial condition is $a_0 = 1, a_1 = 0$, then we have: $$ a_2 = 1, \\text{ and } a_{n+2} = (-1)^{n/2}\\frac{n-1}{n+1}\\cdot \\frac{n-3}{n-1}\\cdots\\frac{1}{3} = \\frac{(-1)^{n/2}}{n+1} $$ and $n$ can be even numbers, let $n = 2k$ we have the solution is: $$ y = 1+x^2 + \\sum^{\\infty}_{k=1}\\frac{(-1)^k x^{2k+2}}{2k+1} = 1 + x\\cdot \\sum^{\\infty}_{k=0}\\frac{(-1)^k x^{2k+1}}{2k+1} = 1+ x\\arctan x $$\n\n  \u2022 Now if the initial condition is $a_0 = 0, a_1 = 1$, $a_2 = a_0 = 0$ implies all even powered $x$ coefficients are zero after $n=2$ because of the relation $(*)$, also by $(*)$ and $a_3 = 0$ we know that all odd powered $x$ coefficients are zero too after $n=3$, therefore the solution is just: $$ y = x $$\n\nTo sum up, the two linearly independent solutions are: $$y = x \\;\\text{ or }\\; 1+ x\\arctan(x)$$\n\nshare|improve this answer\nThanks Jon. The only reason why I got stuck was because the simplification threw me off. It was late and I didn't even think to simplify (in fact I thought it was already simplified). Anyway, thanks again. \u2013\u00a0 Nico Bellic May 7 '12 at 14:16\n@NicoBellic Haha, no problem, btw I love GTA4 too! \u2013\u00a0 Shuhao Cao May 7 '12 at 17:01\nHaha, nice few people recognize the reference. \u2013\u00a0 Nico Bellic May 7 '12 at 18:16\nThe power series method works well provided I can solve the recursion relation. All the textbook examples usualy lead to a recursion that involves two coefficients only ( in this case $a_{n+2}$ and $a_n$). However, in most real world examples this is not the case, ie $a_{n+2}$ is usualy a function of $a_n$ and som other values of $a$ with lower indices. How do I solve the recursion relation then? Or in other words how would I go about solving an equation $(1 + x^2)y^{''} + 2 x y^{'} -2 x y =0$ using the power expansion method? \u2013\u00a0 Przemo Feb 12 at 16:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/18268/consecutive-birthdays-probability\nText:\nTake the 2-minute tour \u00d7\n\nLet $n$ be a number of people. At least two of them may be born on the same day of the year with probability: $$1-\\prod_{i=0}^{n-1} \\frac{365-i}{365}$$\n\nBut what is the probability that at least two of them are born on two consecutive days of the year (considering December 31st and January 1st also consecutive)? It seems a good approximation is: $$1-\\prod_{i=0}^{n-1} \\frac{365-2 \\times i}{365}$$\n\nHowever, simulating pseudo-random integers with Python, the 99%-confidence intervals may be slightly different. So do you have any closed formula?\n\nResults of the simulation with Python. Here are 99%-confidence intervals below:\n\nNumber of people:  1    Lower bound: 0.0        Upper bound: 0.0\nNumber of people:  2    Lower bound: 0.00528    Upper bound: 0.00567\nNumber of people:  3    Lower bound: 0.01591    Upper bound: 0.01657\nNumber of people:  4    Lower bound: 0.03185    Upper bound: 0.03277\nNumber of people:  5    Lower bound: 0.0528     Upper bound: 0.05397\nNumber of people:  6    Lower bound: 0.07819    Upper bound: 0.07959\nNumber of people:  7    Lower bound: 0.10844    Upper bound: 0.11006\nNumber of people:  8    Lower bound: 0.14183    Upper bound: 0.14364\nNumber of people:  9    Lower bound: 0.17887    Upper bound: 0.18086\nNumber of people: 10    Lower bound: 0.21816    Upper bound: 0.2203\nNumber of people: 11    Lower bound: 0.25956    Upper bound: 0.26183\nNumber of people: 12    Lower bound: 0.30306    Upper bound: 0.30544\nNumber of people: 13    Lower bound: 0.34678    Upper bound: 0.34925\nNumber of people: 14    Lower bound: 0.39144    Upper bound: 0.39397\nNumber of people: 15    Lower bound: 0.43633    Upper bound: 0.4389\nNumber of people: 16    Lower bound: 0.48072    Upper bound: 0.48331\nNumber of people: 17    Lower bound: 0.52476    Upper bound: 0.52734\n\nI give here some results with a tweaked approximation formula, using Wolfram Alpha: $$\\left( 1 - \\frac{n-1}{2 \\times 365 + n-1} \\right) \\times \\left( 1-\\prod_{i=0}^{n-1} \\frac{365-2 \\times i}{365} \\right)$$\n\nHowever, this is just a tweak, ans is clearly wrong for $n=33$ since:\n\nNumber of people: 33    My guess: 0.91407\nNumber of people: 33    Lower bound: 0.94328    Upper bound: 0.94447\n\nThanks to Jacopo Notarstefano, leonbloy, and Moron, here is the (correct) formula: $$ 1-\\sum_{k=1}^{n}\\frac{1}{365^{n-k}k}\\left(\\prod_{i=1}^{k-1}\\frac{365-\\left(k+i\\right)}{365\\times i}\\right)\\sum_{j=0}^{k-1}\\left(-1\\right)^{j}C_{k}^{j}\\left(k-j\\right)^{n} $$\n\nAnd here are the results of the computations using this formula with Python:\n\nNumber of people:  1    Probability: 0.0\nNumber of people:  2    Probability: 0.005479452\nNumber of people:  3    Probability: 0.016348283\nNumber of people:  4    Probability: 0.032428609\nNumber of people:  5    Probability: 0.053459591\nNumber of people:  6    Probability: 0.079104502\nNumber of people:  7    Probability: 0.108959718\nNumber of people:  8    Probability: 0.14256532\nNumber of people:  9    Probability: 0.179416899\nNumber of people: 10    Probability: 0.218978144\nNumber of people: 11    Probability: 0.260693782\nNumber of people: 12    Probability: 0.304002428\nNumber of people: 13    Probability: 0.34834893\nNumber of people: 14    Probability: 0.393195856\nNumber of people: 15    Probability: 0.438033789\nNumber of people: 16    Probability: 0.482390182\nNumber of people: 17    Probability: 0.525836596\nNumber of people: 18    Probability: 0.567994209\nNumber of people: 19    Probability: 0.608537602\nNumber of people: 20    Probability: 0.647196551\nNumber of people: 21    Probability: 0.683756966\nNumber of people: 22    Probability: 0.718059191\nNumber of people: 23    Probability: 0.749995532\nNumber of people: 24    Probability: 0.779509664\nNumber of people: 25    Probability: 0.806569056\nNumber of people: 26    Probability: 0.831211564\nNumber of people: 27    Probability: 0.853561895\nNumber of people: 28    Probability: 0.873571839\nNumber of people: 29    Probability: 0.892014392\nNumber of people: 30    Probability: 0.906106867\nNumber of people: 31    Probability: 0.919063161\nNumber of people: 32    Probability: 0.928791992\nNumber of people: 33    Probability: 0.944659069\nshare|improve this question\nThe reason your first formula doesn't work is this: if two people have the same birthday, then they only exclude two days between them, not four. I can't see what your second formula is trying to do. \u2013\u00a0 TonyK Jan 20 '11 at 10:09\nThanks. For information, the second formula is just the result of playing with the simulation and the results. It seems okay for small n, but just an approximation of the expected result. \u2013\u00a0 Wok Jan 20 '11 at 10:11\nI wish people didn't ask questions like this. I have work to do! \u2013\u00a0 TonyK Jan 20 '11 at 10:16\nI'll tell my friend to stop asking me intractable problems: he does not know the answer and I am not sure there is a nice formula. Sorry. \u2013\u00a0 Wok Jan 20 '11 at 11:18\nThe second formula is wrong but is a nice try: it corresponds to count all the possible ways of placing the n birthdays, taking into count that each new birthday removes two possibilities. But this is incorrect because it may happen that a new birthday just removes one possibiliy (or none!) It must be a good approximation for small n. \u2013\u00a0 leonbloy Jan 20 '11 at 11:58\n\n3 Answers 3\n\nup vote 9 down vote accepted\n\nI believe we can give a formula, but I would not call it \"closed form\".\n\nWe have $\\displaystyle n$ people, and $\\displaystyle k$ possible birthdays to choose from (i.e. $\\displaystyle k$ days in a year). Let $\\displaystyle M$ be the minimum of the two.\n\nWe will try and count the number of birthday assignments in which no two people have consecutive birthdays.\n\nTo do this, we will try and count the assignments which use exactly $d$ distinct birthdays, for $\\displaystyle d=1, 2 \\dots, k$, and then add them up.\n\nNow suppose we had a set of $\\displaystyle d$ distinct birthdays (don't worry about the consecutive part, just yet). How many ways can we assign these $\\displaystyle d$ birthdays to $\\displaystyle n$ people, so that each birthday is used at least once?\n\nThis is basically the problem of finding the number of ways to partition a set of size $\\displaystyle n$ in exactly $\\displaystyle d$ non-empty parts and assign the $\\displaystyle d$ birthdays to each part in the partition, exactly one to each.\n\nThe number of ways to partition a set of size $\\displaystyle n$ into $\\displaystyle d$ non-empty parts is given by a Stirling Number of Second Kind, $S(n,d)$. The number of ways to assign $\\displaystyle d$ birthdays is $\\displaystyle d!$.\n\nThus the number we are looking for is $\\displaystyle S(n,d) \\times d!$.\n\nNow suppose we managed to count the number of subsets containing $\\displaystyle d$ elements (from the $\\displaystyle k$ birthdays) such that no two elements of the set are consecutive, then we could multiply that number by $\\displaystyle S(n,d) \\times d!$ to give the number of birthday assignments which use exactly $\\displaystyle d$ birthdays such that no two are consecutive.\n\nFor the moment, ignore the fact that Jan 1 and Dec 31 are consecutive.\n\nWe need to select $\\displaystyle d$ numbers from $\\displaystyle 1,2, \\dots, k$ such that no two are consecutive.\n\nNow if $\\displaystyle b_1 \\lt b_2 \\lt \\dots \\lt b_d$ were such numbers, then notice that\n\n$\\displaystyle 1 \\le b_1 \\lt b_2 - 1 \\lt b_3 - 2 \\dots \\lt b_d - (d-1) \\le k-(d-1)$ gives us a way to select numbers from $\\displaystyle 1, 2, \\dots, k-(d-1)$ without having to bother about the consecutive issue.\n\nThis can be done in $\\displaystyle {k-d+1 \\choose d}$ ways.\n\nNow since Jan 1 and Dec 31 are consecutive, we need to subtract from this, the number of sets which contain both $\\displaystyle 1$ and $\\displaystyle k$.\n\nThis number is same as the number of $\\displaystyle d-2$ non-consecutive subsets of $\\displaystyle \\{3, \\dots, k-2\\}$ which is $\\displaystyle {k-d-1 \\choose d-2}$.\n\nThus the number of ways of selecting $\\displaystyle d$ non-consecutive birthdays (assuming $\\displaystyle 1$ and $\\displaystyle k$ are consecutive) is $\\displaystyle {k-d+1 \\choose d} - {k-d-1 \\choose d-2}$, with the understanding that the term being subtracted is $\\displaystyle 0$ for $\\displaystyle d = 1$ and that $\\displaystyle {a \\choose b} = 0$ if $\\displaystyle a \\lt b$\n\nThus, for $\\displaystyle M = \\text{min}\\{n,k\\}$, the total number we are looking for is,\n\n$$ \\sum_{d=1}^{M} S(n,d)\\times d! \\times \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)$$\n\nNote that $\\displaystyle S(n,d) \\ d! = \\sum_{j=0}^{d} (-1)^j {d \\choose j} (d-j)^n$\n\nSo we could also write the formula as\n\n$$ \\sum_{d=1}^{M} \\left(\\sum_{j=0}^{d} (-1)^j {d \\choose j} (d-j)^n\\right) \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)$$\n\nwhich is a bit ugly.\n\nThus the probability you are looking for is\n\n$$1 - \\frac{ \\sum_{d=1}^{M} S(n,d)\\times d! \\times \\left({k-d+1 \\choose d} - {k-d-1 \\choose d-2}\\right)}{k^n}$$\n\nshare|improve this answer\nWhat I don't get is \"We have n people, and k birthdays.\" In my \"experiment\", I have n (fixed) people, each with a random birthday. The set of distict birthdays (which also appeared in my deduction) is a random number, not an input. Perhaps I'm missing something. \u2013\u00a0 leonbloy Jan 20 '11 at 23:37\n@leon: $k = 365$ in our case. Have edited to make it clearer. \u2013\u00a0 Aryabhata Jan 20 '11 at 23:40\n@leon: I see where your confusion might be. We are using similarly named variables, but they mean different things in our answers. For instance, your $k$, is my $d$. Your $M$ is my $k$. btw, I have confirmed that your answer and my answer give the same answer. Also, in your answer, instead of $Q(n,k)$, you perhaps meant $Q(M,k)$. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:31\n+1 for thorough explanations. I believe all three answers are great! Yet yours would be the most pedagogical one. \u2013\u00a0 Wok Jan 21 '11 at 15:44\n@Moron: right, thanks for the correction, fixed. I prefered to expressed it in that way (Q individualized) to emphasize that it's a probability \u2013\u00a0 leonbloy Jan 21 '11 at 18:01\n\nNB: I worked earlier on this problem and came up with the following solution. The first answer that was posted made me think that I got something wrong, and I discarded my work. Since the new answer by Moron agrees (essentially) with my previous work here it is, a slightly different derivation of the same formula.\n\nLet $k$ be the number of days in a year. Let $m$ be the distinct number of birthdays among the $n$ friends. Let's assume that $k$ is big enough to have a non-trivial problem (say, $k > n/2$)\n\nWe're interested in binary strings with these three conditions:\n\n  1. Are of length $k$, with $m$ ones and $k-m$ zeros.\n  2. There's at least one zero between any two ones.\n  3. Condition 2 holds when \"wrapping around\" the string.\n\nLet's count them by constructing them with the following algorithm:\n\n  \u2022 Start with a string of $m$ ones: $11\\dots 1$\n  \u2022 There are now three distinct cases: there's a birthday on the first day of the year, there is a birthday on the last day of the year, there's a birthday on neither.\n  \u2022 In the first case we have to distribute $k-m$ zeros in $m$ non-empty buckets. Those are called compositions, and one can show that there are $\\binom{k-m-1}{m-1}$ such assignments.\n  \u2022 The second case is analogous, giving another $\\binom{k-m-1}{m-1}$ possible strings.\n  \u2022 The third case is similar, giving instead $\\binom{k-m-1}{m}$ strings.\n\nPutting this together we have: $$2\\cdot \\binom{k-m-1}{m-1}+\\binom{k-m-1}{m}$$\n\nSince $n$ friends share $m$ birthdays we have to account for that, giving this expression:\n\n$$p(n,k) =\\frac{\\sum_{m=1}^n{ m! \\cdot S(n,m)\\cdot \\Bigg (2\\cdot \\binom{k-m-1}{m-1}+\\binom{k-m-1}{m}}\\Bigg )}{k^n}$$\n\nwhere $S(n,m)$ is the Stirling number of the second kind.\n\n@Moron: Why do we need to multiply by $m!$ here? Oh right! Stirling numbers of the second kind count the number of coalitions, but we care about their order, too!\n\nshare|improve this answer\nDid you mean $S(n,m)$? We need to multiply by factorial as we also need to assign the birthdays. The Stirling number counts the number of unordered partitions. We could assign the birthdays to each partition in $m!$ ways. For instance for $m=2$ there are $2^{n-1} - 1$ partitions, but you can rearrange the parts of the partition to get different birthdays assigned. \u2013\u00a0 Aryabhata Jan 21 '11 at 4:12\n+1: Apart from the missing $m!$ term. We have that identity $2 \\binom{k-m-1}{m-1} + \\binom{k-m-1}{m} = \\binom{k-m+1}{m} - \\binom{k-m-1}{m-2}$, which matches my answer. So this confirms that this matches Leonbloy's answer too. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:39\nOh right! We do care about their order, too. Fixed the typo in $S(n,m)$. Thank you! \u2013\u00a0 Jacopo Notarstefano Jan 21 '11 at 8:54\n+1 for an explanation using binary strings and compositions. \u2013\u00a0 Wok Jan 21 '11 at 15:21\nUsing weak compositions makes the problem really simple to handle. Bravo! \u2013\u00a0 Wok Jan 21 '11 at 15:32\n\nUPDATE - THIS IS WRONG -- SEE BELOW CORRECT ANSWER --- Let's call N1 the number of configurations that have at least one day in between birthdays (this excludes not only consecutive birthdays, but also coincident birthdays).\n\nI get (counting weak compositions) :\n\n$ \\displaystyle N_1 = 365 \\frac{(365-n-1)!}{(365-2n)!}$\n\nIf you want to include coincident birthdays, we have\n\n$\\displaystyle N_0 = \\frac{365!}{(365-n)!}$\n\nSo the probability asked is\n\n$\\displaystyle P = \\frac{N_0 - N_1}{365^n}$\n\nUpdate: there might be is some error here, I think I'm failing to taking into account the configurations that have both coincident and consecutive birthdays, I'll revise this tonight. I suspect that N1 is correct, and that allows to compute the probability of having consecutive OR coincident birthdays. To count consecutive (exclusively) birthdays seems more difficult.\n\nUPDATE: Here's the correct (I hope) answer.\n\nThe probability of having at least a pair of consecutive birthday for M (=365) days and n persons is\n\n$\\displaystyle P(M,n) = 1 - \\sum_{k=1}^n Q(M,k) {M \\choose k} \\frac{S(n,k) k! }{M^n} = 1 - \\frac{1}{M^{n-1}} \\sum_{k=1}^n \\frac{(M-k-1)!}{(M-2k)!} S(n,k) $\n\nwhere $ \\displaystyle Q(M,k) = \\frac{{M -k - 1 \\choose k -1} }{{M -1 \\choose k -1} } $\n\nand $S(n,k)$ are the Stirling numbers of the second kind\n\nSome computed values follow\n\nM=365 n=1 p=0.00000000\nM=365 n=2 p=0.00547835\nM=365 n=3 p=0.01634745\nM=365 n=4 p=0.03242761\nM=365 n=5 p=0.05345896\nM=365 n=6 p=0.07910314\nM=365 n=7 p=0.10895871\nM=365 n=8 p=0.14256439\nM=365 n=9 p=0.17941667\nM=365 n=10 p=0.21897764\nM=365 n=11 p=0.26069278\nM=365 n=12 p=0.30400167\nM=365 n=13 p=0.34834843\nM=365 n=14 p=0.39319571\nM=365 n=15 p=0.43803357\nM=365 n=16 p=0.48239009\nM=365 n=17 p=0.52583640\n\nM=365 n=30 p=0.90729104\n\nM=365 n=42 p=0.99074145 \n\n\nLet $M$ (=365) number of days, and $n$ = number of persons and $k$ = number of distinct birthdays ($k$ is not fixed, it's a random variable in the range $1..n$). Let $P_{M,n}(S)$ be the probability of NOT having consecutive birthdays (S is the event: \"all birthdays are separated\")\n\nThen $P_{M,n}(S) = \\sum_k P_{M,n}(S \\; k) = \\sum_k P_{M,n}( S | k ) P_{M,n}(k )$\n\nThe following steps compute the two factors inside the summation:\n\n\n$P_{M,n}( S | k )$ is the probability of having the events separated, given that the number of distinct birthdays is $k$. If we think of birthdays as occupied boxes in a circular list, a little reflection shows that all configurations are equiprobable ($n$ does not matter now) and we can assume without altering the result that the first box of the list is occupied. Now, the total number of possible ocurrences are the number of selection of $k-1$ boxes among $M-1$ (combination).\n\nAnd the number of \"succesfull\" arrangements are those that result in non-consecutive occupied boxes. But this is equivalent of specifying a list of $k$ numbers greater than 1 that sum up to M; and this is the same as specifying a list of $k$ numbers greater than 0 than sum up to $M-k$; and this can be counted, by a reasoning similar to this one, as the combination of $k -1$ taken from $M -k - 1$. So,\n\n$\\displaystyle P_{M,n}( S | k ) = \\frac{{M -k - 1 \\choose k -1} }{{M -1 \\choose k -1} } = Q(M,k)$\n\n\n$P_{M,n}(k)$ : if we place $n$ balls at random in $M$ boxes, what is the probability that exactly $k$ boxes will be non-empty?\n\nThe total counting is given by $M^n$. To count the \"successful\" cases, we multiply:\n\n  \u2022 all the possible sets of occupied boxes (combinations of $k$ taken from $M$)\n\n  \u2022 the total numbers of ways of putting $n$ balls in $k$ boxes leaving no empty box: that is given by the Stirling numbers of the second kind.\n\n  \u2022 and we need to multiply by $k!$ (permutations of boxes) because the Stirling numbers consider nondistinct boxes.\n\n    $\\displaystyle P_{M,n}(k ) = {M \\choose k} \\frac{S(n,k) k! }{M^n}$\n\nAnd from there follows the formula above.\n\nshare|improve this answer\nI agree (now!) with all this. I hope you don't have anything else on tonight though :-) \u2013\u00a0 TonyK Jan 20 '11 at 15:39\nThanks for trying, but it does not fit the estimated probabilities with Python. :( \u2013\u00a0 Wok Jan 20 '11 at 19:07\nAlthough my symulations do not give the same probabilities for several n, I wonder whether there is a bias due to the *pseudo-*randomness of generated integers. \u2013\u00a0 Wok Jan 20 '11 at 22:08\nWeird. You made the edit while I was writing my answer. They seem to be a bit different though. \u2013\u00a0 Aryabhata Jan 20 '11 at 23:30\nI have confirmed that the updated formula is same as mine. +1. Basically I have confirmed that $Q(M,k) {M \\choose k} = {M-k+1 \\choose k} - {M-k-1 \\choose k-2}$. \u2013\u00a0 Aryabhata Jan 21 '11 at 6:32\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/263429/four-digit-reversal-numbers\nText:\nTake the 2-minute tour \u00d7\n\nHow to prove without an exhaustive checking that there are only 2 (nontrivial) four digit reversal numbers?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThat depends how exhaustive you are willing to be. The multiplier can only be in the range $2-9$, which is only eight cases. To check $4$ we write $abcd \\times 4=dcba$ where concatenation indicates different digits. $a$ has to be even as the last digit of the product, and has to be $2$ or there would be a carry. Then $d$ has to be $8$ so that it can produce $a$. $b$ has to be $0,1,2$ to avoid a carry and is odd because of the carry from the ones place, so it is $1$. Then $c$ has to be $7$ and we are done-$2178 \\times 4 = 8712$. $5, 6$ and $8$ are out because $a$ would have to be $1$ to avoid a product over $10,000$ but that is odd and not $5$. $7$ is out because again $a$ would have to be $1$, but then $d$ can't be $3$. So we just have to check $2, 3,$ and $9$-not too much work.\n\nshare|improve this answer\n\nLet $A = \\{2,3,4,5,6,7,8,9\\}$.\n\nLet the $4$ digit reversal number be $abcd$ i.e. $1000a + 100b + 10 c + d$, where $a \\in \\{1\\} \\cup A$, $d \\in \\{1,2,3,\\ldots,a-1\\}$ and $b,c \\in \\{0,1\\} \\cup A$. Its reversed number is $$dcba = 1000d + 100c + 10b + a$$ We want $abcd = k \\times (dcba)$ where $k \\in A$. This gives us $$(1000-k)a + (100-10k)b + (10-100k)c + (1-1000k) d = 0$$\n\n$$\\color{red}{\\text{First note that $10 \\vert (ka-d)$. This also means that if $a$ is even, then $d$ also has to be even.}}$$\n\nLet us call the above necessary condition in red as $\\star$. As explained below, this necessary condition filters out almost all the solutions that are not possible.\n\n  \u2022 If $a=2$. Then $d=1$. Violates $\\star$.\n  \u2022 If $a=3$. Then $d=1$. Hence, $k=1$ or $2$. $ka - d = 1 or 5$. Violates $\\star$.\n  \u2022 If $a=4$. Then $d=2$. If $d=2$, then $k=2$, then $ka-d = 6$. Violates $\\star$.\n  \u2022 If $a=5$. Then $d=1$ or $2$. If $d=1$, $k = 3$ or $4$ or $5$. But $10$ doesn't divide $ka - d$ if $d=1$. Violates $\\star$. If $d=2$, $k=2$. Violates $\\star$.\n  \u2022 If $a=6$, then $d=2$. If $d=2$, then $k=3$. Violates $\\star$.\n  \u2022 If $a=7$, then $d=1,2,3$. If $d=1$, $k=4,5,6,7$. Violates $\\star$. If $d=2$, then $k=3$. Violates $\\star$.\n  \u2022 If $a=8$, then $d=2,4$. If $d=4$, $k=2$. Violates $\\star$. If $d=2$, $k=3,4$. $k=3$ violates $\\star$. However, $k=4$ satisfies $\\star$. Hence, $a=8$, $d=2$ and $k=4$ is a possible candidate. Let us return to this candidate later.\n  \u2022 If $a=9$, then $d=1,2,3,4$. If $d=1$, $k=5,6,7,8,9$. Except $k=9$, the rest violate $\\star$. We will return to the case $a=9$, $d = 1$ and $k=9$ later. If $d=2$, then $k=4$. Violates $\\star$. If $d=3$, $k=3$. Violates $\\star$. If $d=4$, $k=2$. Violates $\\star$.\n\nHence, after this elimination using the necessary condition $\\star$, we get only two possibilities.\n\n  1. $a = 8$, $d=2$ and $k=4$. This means $60b - 390c + 996 \\times 8 - 3999 \\times 2 = 0$. Hence, $2b - 13c = 1$. This gives $b=7$ and $c=1$.\n  2. $a = 9$, $d=1$ and $k=9$. This means $10b - 890c + 991 \\times 9 - 8999 \\times 1$. Hence, $b-89c = 8$. This gives us $b=8$ and $c=0$.\n\nHence, the only two numbers are $8712$ and $9801$.\n\nshare|improve this answer\nI like both answers thus far, though. Thank you. \u2013\u00a0 anon Dec 21 '12 at 22:38\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/280837/cdf-of-maxx-1-x-2-maxx-3-x-4-where-all-x-is-are-iid-from-ua-b?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am looking for the cumulative density function of the sum of two variables, which are themselves the result of a rank order process.\n\nThus, if $x_1, x_2, x_3$ and $x_4$ are all independent draws from a uniform distribution with support $[a,b]$, what is the CDF for $\\max(x_1,x_2)+\\max(x_3,x_4)$?\n\n\nshare|improve this question\n\n2 Answers 2\n\nLet $X=\\max\\{x_1,x_2\\}$. We find the density function of $X$. We have that $F_X(x)=\\mathbb{P}\\{X\\leq x\\}=\\mathbb{P}\\{\\max\\{x_1,x_2\\}\\leq x\\}=\\mathbb{P}\\{x_1\\leq x \\cap x_2\\leq x\\}=\\mathbb{P}\\{x_1\\leq x\\}\\mathbb{P}\\{x_2\\leq x\\}$. Because they are uniformly distributed, it follows that the above is just the product of the cdfs of your original uniform distribution. Therefore $F_X(x)=(\\frac{x-a}{b-a})^2$ whenever $x\\in[a.b)$. From this it follows that $f_X(x)=\\frac{2(x-a)}{(b-a)^2}$. Similarly, if $Y=\\max\\{x_3,x_4\\}$, you have that $f_Y(y)=\\frac{2(y-a)}{(b-a)^2}$. Now let $Z=X+Y$. You have that $Z\\leq 2b$ with probability one and $Z\\leq 2a$ with probability 0. For $z\\in[2a,2b)$ you have $F_Z(z)=\\mathbb{P}\\{Z\\leq z\\}=\\mathbb{P}\\{X+Y\\leq z\\}=\\int_A f_{X,Y}(x,y) dA$ Because of independence of $x_1,x_2,x_3$ and $x_4$ you have that $X$ and $Y$ are independent. This means that $f_{X,Y}(x,y)=f_X(x)f_Y(y)$. Therefore, $F_Z(z)=\\int_A f_X(x)f_Y(y) dA=\\int_{-\\infty}^\\infty\\int_{-\\infty}^{z-x}f_X(x)f_Y(y)dydx=\\int_{-\\infty}^\\infty f_X(x)\\int_{-\\infty}^{z-x}f_Y(y)dydx=\\int_a^b f_X(x)\\int_a^{z-x}f_Y(y)dydx=\\int_a^b f_X(x) (\\frac{a+x-z}{b-a})^2dx=\\frac{1}{(b-a)^4}\\int_a^b 2(x-a)(a+x-z)^2 dx=\\frac{1}{12(a-b)^2}(11a^2+10ab-16az +3b^2-8bz+6z^2)$. I hope this is correct.\n\nshare|improve this answer\nThanks. Been working on this and got to the point where I have the PDFs and CDFs of x and y correct as as yours. I follow most of the rest of your derivations, but your result produces a strictly convex to the origin CDFs and therefore negative probabilities over some range. I have tried to take it from the double integrals in Mathematica. I get something close but slightly different but still with implausible results. \u2013\u00a0 user58641 Jan 17 '13 at 21:02\nI could've made a typo, but notice also that you have $z\\in[2a,2b)$. So the cdf is zero for all $z<2a$, whatever that integral turns out to be for $z\\in[2a,2b)$ and 1 for $z\\geq 2b$. \u2013\u00a0 mathemagician Jan 17 '13 at 21:15\nGot that. I am only plotting from 2a to 2b but there appears to be something not quite right in the development of the integrals since trying to go back up and replicating your steps I get similar results. \u2013\u00a0 user58641 Jan 17 '13 at 21:19\nif somebody could point at the mistake that would be highly appreciated \u2013\u00a0 mathemagician Jan 17 '13 at 22:01\n\nSuppose $u,v$ are i.i.d. $U(0,1)$. Then for any $w\\in[0,1]$, $\\operatorname{Pr}(\\max(u,v)\\le w)=w^2$. Hence the density of $W=\\max(u,v)$ is given by $f(w)=2w$. Therefore, if $X=(\\max(x_1,x_2)-a)/(b-a)$ and $Y=(\\max(x_3,x_4)-a)/(b-a)$, the densities of $X$ and $Y$ on $[0,1]$ are $2x$ and $2y$ respectively.\n\nNow let $Z=X+Y=\\left[\\max(x_1,x_2)+\\max(x_1,x_2)-2a\\right]/(b-a)$. Then for any $m\\in[0,\\,2]$, we have $$ \\phantom{=}\\operatorname{Pr}\\left(Z\\le m\\right) =\\begin{cases} \\int_0^m \\int_0^{m-y} 4xy\\, dx dy=\\frac{m^4}{6} &\\text{ if } m\\le1,\\\\ 1-\\int_{m-1}^1 \\int_{m-y}^1 4xy\\, dx dy = 1-\\frac16m(m-2)^2(m+4) &\\text{ otherwise}. \\end{cases} $$\n\nshare|improve this answer\n@D. The density may exceed $1$. Why not? The standard normal density evaluated at $x=0$, for instance, approaches infinity when the standard deviation $\\sigma$ approaches zero. By the way, I've verified the formula using computer simulation. With a million simulation trials, the above formula agrees with the simulation value to three decimal places for $m=0.1,0.2,\\ldots,1.9$. \u2013\u00a0 user1551 Jan 17 '13 at 23:54\nThanks. If you got an email of my last comment, just disregard.. That was silly! Thanks a lot for your help. I think I got it now, although a good reference for these derivations would be useful! \u2013\u00a0 user58641 Jan 18 '13 at 0:25\n@D. I don't have any reference. For $m\\le1$, I just integrated the joint density function over the triangular domain bounded by the $x$-axis, the $y$-axis and the line $x+y=m$. For $m\\ge1$, I integrated the density over the triangular domain bounded by $x=1$, $y=1$ and $x+y=m$, and then subtract the result from $1$. \u2013\u00a0 user1551 Jan 18 '13 at 1:08\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/125671/ell-1-dense-in-c-0\nText:\nTake the 2-minute tour \u00d7\n\nThis may be a silly question, but here goes. To ensure clarity, $\\ell_1$ is the space of absolutely summable sequences, and $c_0$ the space of bounded sequences with limit 0. So we know that $\\ell_1\\subset c_0$ by basic principles. My question is: is $\\ell_1$ when equipped with the sup-norm dense in $c_0$?\n\nHere is my thought, and I would appreciate a comment on correctness or if something went wrong:\n\nLet $\\xi\\in c_0$ and write $\\xi=\\{\\xi_1,\\xi_2,\\xi_3,\\dots\\}$. Now define $P_n:\\ell_1\\to c_0$ by $$P_n(\\eta)=\\{\\eta_1,\\eta_2,\\dots,\\eta_n\\}$$ So if $\\xi\\in c_0$, we can say $$\\xi=\\underset{n\\to\\infty}{\\lim}P_n\\xi$$\n\nSo does this get us all of $c_0$?\n\nA typical example would be the harmonic sequence $\\{1, 1/2, \\dots, 1/n,\\dots\\}$. This is in $c_0$ but not $\\ell_1$, but taking finite pieces of this sequence at a time guarantees us to remain in $\\ell_1$, and we can approximate the sequence in $c_0$ as the limit of elements of $\\ell_1$.\n\nshare|improve this question\nYour proof for the harmonic sequence generalizes. \u2013\u00a0 dls Mar 28 '12 at 23:41\n$c_{00}$ is dense in $c_0$, so any set containing $c_{00}$ is dense in $c_0$. \u2013\u00a0 user16299 Mar 29 '12 at 2:50\n@Yemon Will the same reasoning always hold for sums of Banach spaces? It seems like the same arguments will work to show that the $\\ell_1$ sum of Banach spaces is dense in the $c_0$ sum of Banach space, and so on. Or is there an example out there where this would break down? \u2013\u00a0 Keaton Mar 29 '12 at 16:04\n@keaton I think it should work, just as you say \u2013\u00a0 user16299 Apr 1 '12 at 0:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nYes. Let $(x_n)\\in c_0$ and take $\\epsilon>0$. Since $x_n\\to 0$, we have some $N$ such that $n\\geq N\\implies |x_n|<\\epsilon$. Define the sequence $(y_n)$ by $y_n=x_n$ for $n<N$ and $y_n=0$ for $n\\geq N$. Clearly $(y_n)\\in \\ell^1$, and for any $n$, $|x_n-y_n|\\leq \\epsilon$, hence $\\sup\\limits_{n}|x_n-y_n|\\leq \\epsilon$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/84634/help-prove-a-maximal-inequality\nText:\nTake the 2-minute tour \u00d7\n\nLet $X_1,\u2026,X_n$ are exchangeable of random variables, and $n$ is an even number. $S_k=X_1+\\dots+X_k$. $M_k=X_{n/2}+\\dots+X_{n/2+k}$.\n\nI want to prove:\n\n$$\\Pr(\\max_{1 \\le k \\le n}{|S_k|>\\epsilon}) \\le \\\\Pr(\\max_{1 \\le k \\le n/2}{|S_k|>\\epsilon/2}) + \\Pr(\\max_{1 \\le k \\le n/2}{|M_k|>\\epsilon/2})$$\n\n[added by YC] for background context to this question, see this MSE question\n\nshare|improve this question\nIf $X_1,\\dots, X_n$ are exchangeable, then doesn't $(S_1,\\dots, S_{n/2})$ have the same distribution as $(M_1,\\dots, M_{n/2})$? \u2013\u00a0 Yemon Choi Dec 31 '11 at 9:04\nWell, it isn't true in general. Take $X_i=1/n$ for all $i$ and $\\epsilon=2/3$. \u2013\u00a0 Brendan McKay Dec 31 '11 at 14:19\n@BrendanMcKay, It is still right, the LHS is $\\Pr(1>2/3)=1$, the RHS is $\\Pr(1/2>1/3)+\\Pr(1/2>1/3)=2$ \u2013\u00a0 Fan Zhang Dec 31 '11 at 15:51\nI think the summation for $M_k$ should start at $n/2 + 1$ so that it is the sum of $k$ terms. With this modification, as Yemon Choi pointed out, $M_k$ has the same distribution as $S_k$ so both probabilities on the right hand side are equal. \u2013\u00a0 Pablo Lessa Dec 31 '11 at 18:00\nThe motivation: math.stackexchange.com/questions/94948/\u2026 \u2013\u00a0 Byron Schmuland Dec 31 '11 at 19:11\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nYou can prove it by using the fact that the following holds always:\n\n$\\max_{1 \\le k \\le n}|S_k| \\le \\max_{1 \\le k \\le n/2}|S_k| + \\max_{1 \\le k \\le n/2}|M_k|$\n\nIf the left hand side is larger than $\\epsilon$ then one of the right hand terms is larger than $\\epsilon/2$.\n\nThis also shows that the inequality is valid under absolutely no assumptions on the joint distribution of the variables $X_1,\\ldots,X_n$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/41933/uniqueness-for-solution-of-a-d-dbar-system-related-to-davey-stewartson-solitons\nText:\nTake the 2-minute tour \u00d7\n\nThis question concerns a system of equations that arise in the study of one-soliton solutions to the Davey-Stewartson equation.\n\nIn what follows, $f(z)$ denotes a function which depends smoothly (but not necessarily analytically!) on $z=x+iy$. Thus $f:\\mathbb{C} \\rightarrow \\mathbb{R}$ or equivalently $f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$. We denote by $\\overline{\\partial}$ and $\\partial$ the usual operators $$ \\overline{\\partial} = \\frac{1}{2} \\left( \\partial_x + i \\partial_y \\right) $$ and $$\\partial = \\frac{1}{2} \\left( \\partial_x - i \\partial_y \\right). $$\n\nThe system is:\n\n$$\\overline{\\partial} n_1(z) = (1+|z|^2)^{-1} n_2(z)$$ $$\\partial n_2(z) = -(1+|z|^2)^{-1} n_1(z)$$\n\nand the question is as follows. Suppose that\n\n$$\\lim_{|z|\\rightarrow \\infty} |z| n_1(z) = \\lim_{\\|z| \\rightarrow \\infty} |z| n_2(z) = 0$$\n\nCan one prove that $n_1(z)=n_2(z)=0$ if one assumes a priori that $n_1$ and $n_2$ belong to $L^p(R^2)$ for all $p>2$ (including $p=\\infty$)? For this purpose one can assume that the limits above exist.\n\nThanks in advance for any help.\n\nPeter Perry, University of Kentucky\n\nshare|improve this question\nDid you try with some Pohozaev-type inequality? e.g. like this: 1) apply $\\partial$ to the first equation so it becomes $\\Delta n_1+(1+|z|^2)^{-1}n_1=g$ where $g$ decays at infinity faster than $z^{-3}$ 2) multiply by $\\overline{z}n_1$ and integrate over an annulus. Typically you obtain quite good information on the behavior of the gradient with this method \u2013\u00a0 Piero D'Ancona Oct 13 '10 at 7:09\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/108276/linear-code-in-cryptography\nText:\nTake the 2-minute tour \u00d7\n\nIs it possible to construct a [6,2] linear code that is two-error correcting?\n\nI think I need to use this Theorem:\n\nSuppose that C is a t-error correcting code in (Z_2)^8. Then order(C)*((n choose 0)+(n choose 1) +...+(n choose t)) is less than or equal to 2^n\n\nshare|improve this question\nSurely coding-theory is a more appropriate tag for this question? \u2013\u00a0 Jyrki Lahtonen Feb 11 '12 at 22:06\nYes, you have the \"correct theorem\" to use in proving the result (except that you probably meant to type $\\mathbb Z_2^6$ instead of $\\mathbb Z_2^8$ and of course $n$ is $6$. \u2013\u00a0 Dilip Sarwate Feb 11 '12 at 22:26\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nNo. At least not, if you are talking about binary linear codes (which seems to be the case judging from everything else that you say). There are several ways of seeing that this is impossible. The result that you described is one of them. There are $$ {6\\choose 0}+{6\\choose 1}+{6\\choose 2}=22 $$ binary vectors at distance $\\le 2$ from a given codeword. So if you had 4 codewords in a double-error correcting binary code of length 6, then these 4 Hamming spheres sets of vectors should not intersect. Therefore between themselves they would cover a total of $4\\cdot 22=88$ vectors. But there are only $2^6=64$ in the entire space $F_2^6$! Therefore this is impossible.\n\nThis also follows from the so called Griesmer bound stating that if a binary code of dimension $k$ has minimum distance at least $d$, then its length $n$ satisfies the bound $$ n\\ge \\sum_{i=0}^{k-1}\\lceil\\frac{d}{2^i}\\rceil. $$ So if a 2-dimensional binary linear code can correct two errors, its minimum distance is at least $d5$, then its length must be at least $$ n\\ge \\lceil\\frac51\\rceil+\\lceil\\frac52\\rceil=5+3=8. $$ The double-error correcting code in your other question is an example of a shortest possible binary linear double error correcting code that has 4 codewords.\n\nContinue to read at your own peril:\n\nNote: It is possible to find 2-dimensional double error correcting codes of length six over a larger alphabet. For example using suitably chosen Reed-Solomon codes you can shorten it to form a code with the properties:\n\n  1. The codewords have six components, all of which are bytes (as opposed to bits like here).\n  2. Two out of the six bytes carry information, and the remaining four are check bytes.\n  3. The code can recover from any error, where at most two out of the six bytes are incorrectly received/read.\nshare|improve this answer\nTo add to Jyrki's excellent answer, the Hamming bound that the OP said he thought he needed to use (and Jyrki filled in the details) actually shows that no binary code (whether linear or nonlinear) with $4$ codewords of length $6$ can correct $2$ errors. \u2013\u00a0 Dilip Sarwate Feb 11 '12 at 22:27\nThis is all very interesting stuff, I appreciate the help with all of this. I'm guessing applications such as maple and matlab would be good for playing around with these types of codes. \u2013\u00a0 Jackson Hart Feb 11 '12 at 23:07\nWhy do you assume there are 4 codewords? What if it were 2 codewords? Then it might work, right? \u2013\u00a0 Jackson Hart Feb 11 '12 at 23:11\n>Why do you assume there are 4 codewords? Because the terminology $[n,k]$ linear binary code usually means a code with $2^k$ binary vectors of length $n$ that constitute a $k$-dimensional subspace of $\\mathbb Z_2^n$. Older books also used $(n,k)$ instead of $[n,k]$ but in more modern texts, a $[n,k]$ code is linear (or at least has $2^k$ or $q^k$ codewords) while a $(n,M)$ code means $M$ vectors (of length $n$) that do not necessarily constitute a linear code. \u2013\u00a0 Dilip Sarwate Feb 12 '12 at 1:45\n@Jackson: A 2-dimensional binary linear code (or any binary code with 4 words) is so small that you can play with them without any CAS. If we look at 2-dimensional codes of length 6, then the best code (in terms of minimum distance) is {000000,111100,110011,001111}. You see that its minimum distance is four, so it can correct one error and detect two. Notice two further things: the bits here are in groups of two so that the second bit always the same as the first, the fourth the same as the third, ditto the sixth and the fifth. \u2013\u00a0 Jyrki Lahtonen Feb 12 '12 at 7:20\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/116864/subadditivity-for-renyi-entropies\nText:\nTake the 2-minute tour \u00d7\n\nDo the Renyi entropies satisfy the standard subadditivity of Shannon entropy? That is,\n\n\\begin{equation} H_\\alpha(A,B) \\leq H_\\alpha(A) + H_\\alpha(B) ? \\end{equation}\n\nfor $\\alpha \\ne 1$. If they do, for which $\\alpha$?\n\nHere $H_\\alpha(X)$ is the standard Renyi $\\alpha$-entropy of the random variable X, \\begin{equation} H_\\alpha(X)=\\frac{1}{1-\\alpha}\\log\\sum_i^n p_i^\\alpha, \\end{equation} and $H_\\alpha(A,B)$ is the Renyi entropy of the joint probability distribuition of the random variables A and B.\n\nshare|improve this question\nPlease expand the definitions that you are using, example by linking en.wikipedia.org/wiki/R%C3%A9nyi_entropy and also, by telling us what does $R_\\alpha(A,B)$ mean... \u2013\u00a0 Suvrit Dec 20 '12 at 13:46\nadd comment\n\n2 Answers\n\nNo, the Renyi entropy is not subadditive. It also lacks several other \"natural\" properties of entropies.\n\nSee this paper on \"Additive entropies of degree-$q$ and the Tsallis Entropy by B. H. Lavenda and J. Dunning-Davies for more details, references, and versions of entropy, which possess many desired Shannon-entropy-like properties, while generalizing it.\n\nshare|improve this answer\nadd comment\n\nSuvrit has answered it completely, but let me suggest how you might go about finding counterexamples.\n\nIt's often useful to work with not the R\u00e9nyi entropies but their exponentials, $$ D_\\alpha(X) = \\exp(H_\\alpha(X)) = \\Bigl( \\sum_{i=1}^n p_i^\\alpha \\Bigr)^{1/(1-\\alpha)} $$ (where, as in your question, $X$ is a random variable with distribution $p_1, \\ldots, p_n$). One advantage of working with $D$ rather than $H$ is that there's a useful limit as $\\alpha \\to \\infty$, namely $$ D_\\infty(X) = 1/\\max_i p_i. $$ Since this is such a simple formula, $\\alpha = \\infty$ is a good case to try when testing conjectures.\n\nIn terms of $D$, subadditivity becomes $D_\\alpha(A, B) \\leq D_\\alpha(A) D_\\alpha(B)$. It's easy to find counterexamples when $\\alpha = \\infty$: for instance, $$ \\begin{pmatrix} 1/2 &1/4 \\\\\\ 1/4 &0 \\end{pmatrix} $$ is a counterexample since $$ \\frac{1}{\\max\\{1/2, 1/4, 1/4, 0\\}} = 2 > \\frac{16}{9} = \\frac{1}{\\max\\{3/4,1/4\\}}\\frac{1}{\\max\\{3/4,1/4\\}}. $$ It follows that this is a counterexample for all sufficiently large finite $\\alpha$. If you graph it, you see that it is in fact a counterexample for all $\\alpha$ greater than about $1.6$. Tweaking it gives you counterexamples for all $\\alpha > 1$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/208696/number-of-roots-of-an-equation/208719\nText:\nTake the 2-minute tour \u00d7\n\nPlotting the equation $x^3-x^2 \\sin(x)+\\cos(x)$ I see that $x^3-x^2 \\sin(x)+\\cos(x)=0$ has only one real solution, is there a simpler way to see that it cannot have 3 real solutions?\n\nshare|improve this question\nOne consideration is the sin and cos are less than $1$ in magnitude, so the function may be compared to $x^3-x^2+1$ which also is close to $x^3 - x^2 = x^2(x-1)$. \u2013\u00a0 adam W Oct 7 '12 at 13:11\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nWe have $f(x) = x^3-x^2\\sin(x) +\\cos(x)$, hence $f'(x)=(3-\\cos(x))x^2-(2x-1)\\sin(x)$, $f''(x)=(x^2-2)\\sin(x) + 6x-(4x-1)\\cos(x) $.\n\nFor $0\\le x$ we have $\\sin x\\le x$, hence $f(x)\\ge x^3-x^3+\\cos(x)\\ge \\cos x$, hence any positive root of $f$ must be $\\ge\\frac\\pi2$. But already for $x\\ge\\frac 3 2$, we have $f(x)\\ge x^3-x^2-1=(x-1)x^2-1\\ge(\\frac32-1)\\frac94-1=\\frac18>0$. Therefore $f$ has no nonnegative root.\n\nIf $-\\frac\\pi2\\le x\\le 0$ then $\\sin(x)\\le \\frac2\\pi x$ and $\\cos(x)\\ge1+\\frac2\\pi x$, hence $f(x)\\ge(1-\\frac2\\pi)x^3+1+\\frac2\\pi x$. The right hand side becomes $=0$ at $x=-1$ and has positive derivative. We conclude that $f(x)>0$ for $x> -1$.\n\nObserve that $A\\sin x+B \\cos x=\\sqrt{A^2+B^2}(\\cos u\\sin x+\\sin u \\cos x)=\\sqrt{A^2+B^2}\\sin(x+u)$ for some $u$, i.e. $$\\tag1 |A\\sin x + B\\cos x|\\le \\sqrt {A^2+B^2}.$$ Therefore we see that $f(x)=x^3-x^2\\sin x+\\cos x$ can be estimated as $$ f(x)\\le x^3+\\sqrt{x^2+1}<x^3+\\sqrt{x^2+1+\\frac1{4x^2}}=x^3+\\left|x+\\frac1{2x}\\right|,$$ i.e. for negative $x$ by $$ f(x)<x^3-x-\\frac1{2x}=\\frac{2x^2(x^2-1)-1}{2x} $$ The numerator is positive for $x^2>\\frac{1+\\sqrt 3}2$, i.e. for $x<-\\sqrt{\\frac{1+\\sqrt 3}2}$, even more so for $x\\le -\\frac65$.\n\nBy the results so far, $f$ can have roots only in $(-\\frac65,-1]$.\n\nBetween any two roots of $f$, there must be a root of $f'$. If $f$ has moe than one root, it must have at least three roots (counting multiplicity) because $f(x)\\to\\pm\\infty$ as $x\\to\\pm\\infty$, hence $f'$ must have two roots in $(-\\frac65,-1]$ (again, counting multipliciites) and finally $f''$ must have at least one root in $(-\\frac65,-1]$. Even a mild estimate for $\\sin$ and $\\cos $ in this interval should suffice to show $f''(x)<0$ here.\n\nshare|improve this answer\n\nLet $f(x) = x^3$ and $g(x) = x^2 \\sin(x) - \\cos(x)$. Clearly $$ |g(x)| \\le x^2 + 1, $$ and hence a necesary condition for $f(x) - g(x) = 0$ is that $$ -\\beta = \\frac{1}{3}\\big(-1 - \\alpha_1^{-1/3} - \\alpha_1^{1/3}\\big) \\le x \\le \\frac{1}{3}\\big(1+\\alpha_1^{1/3}+\\alpha_2^{1/3}\\big) = \\beta $$ where $\\alpha_1 = \\frac{29-3\\sqrt{93}}{2}$ and $\\alpha_2 = \\frac{29+3\\sqrt{93}}{2}$.\n\nNow, $$ g'(x) = x^2\\cos(x) + (2 x + 1)\\sin(x) $$ implies $g'(x) > 0$ from $0 < x \\le \\frac{\\pi}{2}$, meaning that $g(x)$ is strictly increasing in $0 < x \\le \\beta < \\frac{\\pi}{2}$, achieving its maximum at $x = \\beta$ and minimum at $x = 0$.\n\nGiven that $g(0) < f(0)$, $\\,f$ striclty increasing, and $$ g(\\beta) < \\beta^2 \\sin(\\beta) < \\beta^3 = f(\\beta), $$ there is no positive solution to $f(x) - g(x) = 0$ for $x \\in [0,\\infty)$.\n\nThe case $ x < 0$ is a bit more interesting. First, we see that $$ g'(x) = 0 \\quad \\Longleftrightarrow \\quad \\frac{x^2}{2 x +1} = -\\tan(x) $$ meaning that $g(x)$ has a (unique) critical point $x_c$ in $\\big(-\\beta,0\\big)$; moreover, $x_c \\in [-\\frac{1}{2},0)$ and it's a maximum (it's easy to see that $g'(-\\pi/4) > 0$ and $g'(-\\pi/12) < 0$).\n\nIn $x \\in [-\\frac{1}{2},0)$, $g(0) < f(0)$ and $$ g(x) < -\\cos(x) \\le -\\cos(-1/2) < -(1/2)^3 \\le x^3 = f(x) $$ implying that there is no solution for $f(x) - g(x) = 0$ for $x \\in [-\\frac{1}{2},\\infty)$.\n\nFinally, $g'(x) > 0 $ for $x \\in [-\\beta, -\\frac{1}{2}]$, and then there is one (and only one) solution in that interval.\n\nHope I didn't made any mistakes.\n\nshare|improve this answer\n\nIt might be helpful to notice that it has an uneven number of solutions, since $x^3 \\to \\pm\\infty$ for $x \\to \\pm\\infty$. We can furthermore see that the function is not strictly even or odd (as it is composed of both an even function $\\cos(x)$, and uneven functions $x^3, x^2\\cdot\\sin(x)$), this might hint at only one solution.\n\nHowever, since the total function is made up of both polynomials of finite order and sinus/cosinus parts, it could have many more solutions - just compare it to the plot of\n\n$$\\frac{1}{100} x^3 - x^2\\sin(x) + \\cos(x).$$\n\nSo, to answer your question, there is no general way of deciding how many solutions such a function could have.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/328091/every-complete-countable-metric-space-has-a-discrete-dense-subset\nText:\nTake the 2-minute tour \u00d7\n\nGiven a complete, countable metric space, say $X$, I'd like to show it has a discrete, dense subset. This seems like an application of the Baire Category Theorem, but that doesn't seem to go anywhere. Any help would be appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 8 down vote accepted\n\nConsider the collection $I$ of all isolated points of $X$. (By the Baire Category Theorem $I$ is nonempty, but that is somewhat immaterial for the moment.) Note that $I$ is then a discrete subspace of $X$. If $I$ were not dense, then $U = X \\setminus \\overline{I}$ is a nonempty (open) set without isolated points. From here we can construct in the usual manner a Cantor set as a subset of $X$, contradicting that $X$ is countable! (The construction goes as in the linked answer, just ensuring that the $x_\\sigma$ are chosen from $U$.)\n\nshare|improve this answer\nAh, so I was heading in the right direction it seems. Thanks for your help. \u2013\u00a0 Alexander Sibelius Mar 12 '13 at 4:58\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/84382/does-an-essential-resolution-of-2-dimensional-hypersurface-singularity-preserves\nText:\nTake the 2-minute tour \u00d7\n\nPut $V= \\mathbb{C}^3$. Let $D \\subset V$ be an isolated singularity and\n$\\mu: \\tilde{V} \\rightarrow V$ be a log resolution of the pair $(V,D)$ whose exceptional locus $E$ and the strict transform $\\tilde{D}$ satisfies that $\\tilde{D} \\cup E$ has a normal crossing support. We can define $c_j \\in \\mathbb{Z}$ such that $K_{\\tilde{V}} + \\tilde{D}\u3000= \\mu^* (K_V +D)+ \\sum c_j E_j $ where $E = \\bigcup E_j$ is the irreducible decomposition.\n\nQuestion Is there $\\mu$ such that $c_j \\le 0$ for all $j$?\n\nshare|improve this question\n\n1 Answer 1\n\nThe answer is surely no.\n\nIf $D$ itself does not have a minimal log smooth resolution, then certainly $(V,D)$ couldn't have such a log resolution you need. On the other hand, there are bunch of isolated surface singularities whose minimal resolution is not log smooth, e.g., the log canonical surface singularity whose minimal log resolution has its exceptional locus an nodal rational curve.\n\nshare|improve this answer\nThank you for the comment. I think that every normal surface singularity $D$ has a log resolution such that each discrepancy is non-positive. It is called an essential resolution, e.g. in Ishii's paper. Actually, if I blow up the node of the nodal curve in your example, the coefficient of the $-1$-curve is 0. \u2013\u00a0 tarosano Jan 14 '12 at 18:04\nI see. You are right. We also need to consider the curves of discrepancy 0 which doesn't necessarily appear in the minimal resolution of the surface itself. \u2013\u00a0 CYXU Jan 16 '12 at 0:58\nJust for safety, maybe the discrepancy of the $-1$-curve is $-1$. \u2013\u00a0 tarosano Mar 4 '13 at 11:24\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/142809/sampling-value-prediction-and-error-correction?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI am a programmer and I don't have much background in mathematics. I know this question might look much more clear to you if I could articulate it in mathematical terminologies. The problem is this is my first question here and I don't know how to ask it in maths languages! So bare with me...\n\nI am making a car-racing game where multiple players on the Internet can compete with each other. Each player drives a car whose position and rotation changes continuously over time. To let players over the network share the same game I have to quickly deliver each player's position and rotation to all other player. The problem is there is always going to be a network latency between data being sent and being received. In other words, by the time a piece of data reaches another player, it is already dated.\n\nI think the solution to my problem is to make a function that can predict the position and rotation of other cars based on the previous data collected. When newer data arrives, the function should have a feedback so that error could be corrected. Parameters used for prediction should also be modified, maybe.\n\nFor example, I am thinking about sampling the position as well as velocity of my car evenly over time, and sending them to other player one by one. Now before other players receive my new data, they can use their own \"predicted velocity\" to approximate my movement. Once the new data arrives, they can use the new position and velocity to do error correction and make new predictions.\n\nSome additional requirements about the function includes:\n\n  1. Efficiency: the prediction and error correction function must be efficient because it is going to be computed by computer every tens of milliseconds.\n  2. Robust: I will sample evenly but the other players won't receive data at an even speed, due to network uncertainties.\n  3. Error Bound: it would be great if there is a way to confine error within a certain range.\n\nI have been googling papers for such functions but I haven't found much useful information. Maybe it's because I don't have the correct keywords. So any answer/comment that\n\n  1. helps to identify & clarify the problem in the math realm\n  2. points to papers of solutions\n\nis highly appreciated!\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYou might want to consider a Kalman filter with a very low measurement error (since presumably, when a player receives an update about position and rotation through the network, that update is treated as gospel).\n\nIn a little more detail, if you have last known position $x$, velocity $v$, rotation $\\theta$ and angular velocity $\\omega$, then you can compute an updated position and velocity after time $\\delta t$:\n\n$$x \\leftarrow x + v \\delta t$$ $$v \\leftarrow v$$ $$\\theta \\leftarrow \\theta + \\omega\\delta t$$ $$\\omega \\leftarrow \\omega$$\n\nSince this involves two multiplications and two additions, it should be fast. You do this every $\\delta t$ seconds until you receive an update, at which point you set the position, velocity, rotation and angular velocity to their updated values, and continue as before.\n\nIf you additionally have the last known acceleration $a$ and angular acceleration $\\nu$ then your update equations become:\n\n$$x \\leftarrow x + v \\delta t + \\tfrac{1}{2} a \\delta t^2$$ $$v \\leftarrow v + a \\delta t$$ $$\\theta \\leftarrow \\theta + \\omega \\delta t + \\tfrac{1}{2} \\nu \\delta t^2$$ $$\\omega \\leftarrow \\omega + \\nu \\delta t$$\n\nwhich will be more accurate, as they take the time-varying velocity and angular velocity into account (whereas the previous equations assume they are constant).\n\nAs for bounding the error, it will depend somewhat on how the game works and how fast quickly the players can change their accelerations. For a naive estimate, you can say that the error in position from the first set of equations is $O(n v \\delta t^2)$ where $n$ is the number of time steps since you received an update, and in the second case it is $O(na\\delta t^3)$, but if the accelerations have changed significantly since you last received an update, these bounds can be violated.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/150259/question-about-the-collatz-conjecture-nicomachuss-triangle-and-more\nText:\nTake the 2-minute tour \u00d7\n\nUsing $(3p+1)/2$ starting with $p = 44102911$, we find an ordered set of $8$ primes. By computer, we find that this is the only ordered set of $8$ primes $< 300000000$ primes.\n\nThe primes:\n\n$\\{44102911, 66154367, 99231551, 148847327, 223270991, 334906487, 502359731, 753539597\\}$\n\nWhen we take the differences and remove the common factor, $344554$, we have:\n\n$\\{64, 96, 144, 216, 324, 486, 729\\}$\n\nAs you can see, this is the $7th$ row of Nicomachus's Triangle. A036561\n\n\nQuestion: What would it take to show that a count of $8$ is the upper bounds for this ordered set?\n\nTerry Tao has a recent blog about this.\n\nCollatz on arxiv and another Collatz on arxiv.\n\nSet of $7$ primes\n\n$\\{89599, 134399, 201599, 302399, 453599, 680399, 1020599\\}$\n\nWhen we take the differences and remove the common factor, $1400$, we have:\n\n$\\{32, 48, 72, 108, 162, 243\\}$\n\nAs you can see, this is the $6th$ row of the triangle.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 5 down vote accepted\n\nThe numbers $p_i$ in your list are of the form $p_i=344554\\cdot2^{7-i}3^i-1,$ for $i=0,1,\\ldots,7$, so there is nothing mysterious about the appearance of a row from Nicomachus' triangle, as $$ \\frac{p_{i+1}-p_i}{344554}=3^{i+1}2^{6-i}-3^i2^{7-i}=3^i2^{6-i}(3-2)=3^i2^{6-i}. $$ Of course, it is rare that they would all primes, but as Gerry Myerson explained, there is no obvious reason, why we couldn't find even longer sequences of primes given that the residue class of $-1$ is a fixed point for the mapping $x\\mapsto(3x+1)/2$ modulo $q$, $q$ any odd prime.\n\nAs an example of a constraint to your search for such sequences, implicit in Gerry's answer, let us consider the following. If you search for such a sequence of length ten, then all the primes in that sequence must be congruent to $-1$ modulo $11$. This is because the mapping $x\\mapsto(3x+1)/2$ permutes the other residue classes modulo $11$ as a 10-cycle: $$ 6\\mapsto 4\\mapsto 1\\mapsto 2\\mapsto 9\\mapsto 3\\mapsto 5\\mapsto8\\mapsto 7\\mapsto 0(\\mapsto 6), $$ so any integer $x$ that is not $\\equiv-1\\pmod{11}$ will become divisible by eleven after at most nine iterations.\n\nTrying to address the question on the emergence of Nicomachus' triangle. Assume that we start a Collatz run from the number $a_0=m\\cdot 2^k-1$, where $k>0$ and $m$ is an odd integer. Observe that every odd positive integer $a_0$ can be written in this way. As $a_0$ is odd, the next Collatz step gives $3a_0+1=m\\cdot2^k\\cdot3-2$. This is an even number, so the next step yields $a_1=m\\cdot2^{k-1}\\cdot3-1.$ If $k>1$, then we can repeat the same reasoning, and two further steps of Collatz gives us $a_2=(3a_1+1)/2=m\\cdot2^{k-2}\\cdot3^2-1.$ The logic will be broken after $2k$ Collatz steps, because $a_k=m\\cdot2^03^k-1$ is an even number, so the two types of steps stop alternating at this point.\n\nAssume that the numbers $a_i$ are primes in the range $i=0,1,\\ldots,\\ell$. Obviously then $\\ell<k$. Let us consider the differences $\\Delta_i=a_{i}-a_{i-1}$, for $i=1,2,\\ldots,\\ell$. Then $$ \\Delta_i=(m\\cdot2^{k-i}3^i-1)-(m\\cdot2^{k-i+1}3^{i-1}-1)=m\\cdot2^{k-i}3^{i-1}(3-2) =m\\cdot2^{k-i}3^{i-1}. $$ We immediately see that the greatest common divisor of the numbers $\\Delta_i,i=1,2,\\ldots,\\ell$ is $d=m\\cdot2^{k-\\ell}.$ This is because, we always have $3\\Delta_i=2\\Delta_{i+1}$. Thus the numbers $$ \\frac{\\Delta_i}{d}=\\frac{m\\cdot2^{k-i}3^{i-1}}{m\\cdot2^{k-\\ell}}=2^{\\ell-i}3^{i-1} $$ form the $\\ell^{\\text{th}}$ row Nicomachus' triangle with $i$ ranging from $1$ to $\\ell$.\n\nshare|improve this answer\n...it is rare that they would all [be] primes... My observations indicate that matching to the Triangle is a necessary condition to finding only primes in the set. I'll edit the OP to include some sets of 5, 6, and 7 \u2013\u00a0 Fred Kline May 27 '12 at 7:48\n@Rudy, I think that you get a similar match with the triangle, whenever the numbers are such that Collatz rules force the pair of operations $x\\mapsto 3x+1\\mapsto (3x+1)/2$ to be followed enough many times. Quite irrespective of whether the numbers are all primes or not. Should I elaborate on that? \u2013\u00a0 Jyrki Lahtonen May 27 '12 at 7:55\nI know this can generate sequences on non-primes as well. However, I force primes at each step. mathematica.stackexchange.com/questions/4882/\u2026 for a slight variation of the algorithm \u2013\u00a0 Fred Kline May 27 '12 at 8:23\n@Rudy, does the latest addition answer your question? \u2013\u00a0 Jyrki Lahtonen May 27 '12 at 8:54\nYes, thank-you. So you're counting the multiply and divides as two Collatz steps? So my count of eight would be sixteen? \u2013\u00a0 Fred Kline May 27 '12 at 10:40\n\nI would expect you'd get arbitrarily long sequences of primes by iterating $(3p+1)/2$. You're asking whether some finite set of linear expressions can be simultaneously prime. The general belief is that it can be, if there is no simple congruential reason why it can't. For small primes $q$, just make sure $p+1$ is a multiple of $q$. For sufficiently large primes $q$, there should be no problem.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/163440/will-the-following-expression-be-irrational-rational-or-integer?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWill the following expression be irrational, rational or integer?\n\n$$\\sqrt[3]{\\sqrt a +b} - \\sqrt[3]{\\sqrt a -b}$$\n\nwhere $a$ = $52$ and $b$ = $5$ .\n\nBy intuition, I think this will be an integer.\n\nshare|improve this question\nIt certainly depends on $a,b$. For example, take $a=b=0$, then the expression is $0 \\in \\mathbb{Z}$. Take $a=b=1$ and the expression is $2^{1/3}$ which is irrational. \u2013\u00a0 nullUser Jun 26 '12 at 18:51\n@Bazinga I've added LaTeXed version of your formula. If this is what you meant, you can edit the post ant leave the LaTeX-ed version there. For more about writing math at this site see here or here. \u2013\u00a0 Martin Sleziak Jun 26 '12 at 18:51\nThanks @MartinSleziak \u2013\u00a0 Bazinga Jun 26 '12 at 18:53\nGiven any natural $a,b$, it will be an algebraic integer, therefore either integer or irrational. \u2013\u00a0 sdcvvc Jun 26 '12 at 18:57\nInstead of saying \"irrational, rational or integer\", it may be more useful to say \"irrational, non-integer rational, or integer\". \u2013\u00a0 Dave L. Renfro Jun 26 '12 at 19:02\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nLet's use the identity $(\\alpha + \\beta)^3 = \\alpha^3+\\beta^3+3\\alpha\\beta(\\alpha+\\beta)$\n\nSet $\\alpha =\\sqrt[3]{b+\\sqrt{a}} \\text{ and } \\beta= \\sqrt[3]{b - \\sqrt{a}} \\text { and } \\alpha+\\beta=x$\n\nWe know that $\\alpha\\beta = \\sqrt[3]{b+\\sqrt{a}} \\times \\sqrt[3]{b - \\sqrt{a}} = \\sqrt[3]{b^2-a} = \\sqrt[3]{25-52} = -3$\n\nSo $x^3= b+\\sqrt a + b-\\sqrt a - 9x = 2b-9x = 10-9x$\n\nYou know that you are looking for a real answer, because $a$ is positive and the two cube roots are therefore cube roots of real numbers. Arturo has factorised the cubic, but it is easy to see that 1 is a root (integer roots must be divisors of 10).\n\nshare|improve this answer\n\nThe expression quickly brings to my mind the Cardano formulas for a (depressed) cubic. Which suggested the following:\n\nWe can rewrite as $$\\sqrt[3]{b+\\sqrt{a}} + \\sqrt[3]{b - \\sqrt{a}}.$$ This is a root of the cubic $y^3 + 3py + q=0$, where $b = \\frac{-q}{2}$ and $a=\\frac{q^2+4p^3}{4}$.\n\nWith $b=5$, we have $q=-10$, so $$52 = a = \\frac{100+4p^3}{4}.$$ This gives $4p^3 = 208-100 = 108$, so $p^3 = 27$, or $p=3$.\n\nThus, the expression at hand is a root of the cubic $$y^3 + 9y -10 = 0.$$ This cubic has an obvious integer root $y=1$ (or you could use the rational root test to see if it has any rational roots if this is not obvious), which after factoring gives $$y^3 + 9y - 10 = (y-1)(y^2 + y+10).$$ The quadratic is irreducible over $\\mathbb{R}$, so its roots are complex.\n\nAssuming you mean the real cubic roots of the real numbers, since our number is real, it must equal $1$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234473/sum-of-random-variables-uniformly-distributed-0-1-and-0-2\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to get $P(0.9<Y<=1.8)$ for the sum of 2 random and uniform values x1,x2 (so that y=x1+x2) where $x1$~$u(0,1)$ and $x2$~$(0,2)$ and I'm trying to do the convolution for it. Seems like $\\int\\limits_a^b\\int_0^2 xf(x)\\,\\mathrm{d}x$ where a=0.9, b=1.8 and which seems like a logical way to start. I'm not comfortable with convolution but I'm trying to understand the step-by-step reason that this is the proper equation, and how the problem can be solved. I'd like to understand as much about this as possible so I'd like to also compare that problem to finding the $P(0.9<Y<=1.8)$ for just $x1$~$u(0,1)$ where the values summed are independent but still over the same (0,1) area, and also compare it to $P(0.9<Y<=1.8)$ for $exp(2)$ where lambda is 2, which I'm also not really understanding the summed distribution.\n\nshare|improve this question\nHow is $Y$ related to $x_1$ and $x_2$? It is not clear from your description. \u2013\u00a0 Daryl Nov 10 '12 at 22:37\nsum of two random variables is y. \u2013\u00a0 Seyhmus G\u00fcng\u00f6ren Nov 10 '12 at 22:42\nthat's correct, and also added to the above. y=x1+x2 \u2013\u00a0 stackuser Nov 10 '12 at 22:44\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe answer to your question is $\\frac{179}{400}$. First you need to make the convolution of two $p.d.f.$s. However note that this operation is valid only for the independent random variables $X_1$ and $X_2$. I assume they are independent and continue with the solution.\n\nThe result of the convolution will be on the positive $y$ axis, having non zero values between $0$ and $3$. The density of $Y$ is a linear increasing function from $0$ to $1/2$ for $y\\in [0,1]$, a constant function $p_Y(y)=1/2$ when $y\\in [1,2]$ and a linear decreasing function from $1/2$ to $0$ when $y\\in [2,3]$.\n\nWhat remains to do is to find the area under this $p.d.f.$. If you draw and calculate the area either with integrals or using some simple geometric relations, you will find that the area under the curve w.r.t. the square is $0.4$ and the area with respect to the left triange is $19/400$, which adds up to $\\frac{179}{400}$.\n\nshare|improve this answer\nthank you!! so it sounds like the graph is a triangle from 0 to 2 peaking at 1/2. not sure what the limits of integration are here, sounds like a single integral though. if this can be shown in latex, it would be great for visualizing. sorry it tells me i can't upvote until i get to 15 but i would if i could. \u2013\u00a0 stackuser Nov 11 '12 at 1:36\n@stackuser: There's a very elegant solution to that in this case. If this answer answers your question, you can accept it by checking the little checkmark next to it (see this faq and this one). That gives you $2$ reputation points, exactly what you're missing to be able to upvote :-) \u2013\u00a0 joriki Nov 11 '12 at 8:08\ndone and done. that works! there's so much for a newcomer to learn about the stack-exchange rules. \u2013\u00a0 stackuser Nov 11 '12 at 8:27\nadd comment\n\nHere is a blog post describing something similar to the problem you are attempting to solve. Convolution is the way to go.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141792/how-do-you-prove-that-1-is-the-supremum-of-the-set-a-fracmn-m-n-in-m\nText:\nTake the 2-minute tour \u00d7\n\nit might be a simple question.\n\nI need to prove that $1$ is the supremum of the following set: $$A=\\left\\{\\frac{m}{n}\\mathrel{}\\middle|\\mathrel{} m<n\\wedge m,n\\in \\mathbb{N}\\right\\}$$ So, actually I need to prove 2 things:\n\n  1. $\\forall x\\in A .x\\le 1$\n  2. $\\forall \\varepsilon>0 \\ \\exists x\\in A .x>1-\\varepsilon$\n\nSo, the the first requirement is easy to prove, from the defeinition of $A$. but the second is not so simple for me. I've tried to show that this $x$ exists, but I can't show how it looks like.. I guess I should express it with $\\varepsilon$, but I have no success so far.\n\nIf there are other ways to prove it, it'll fine too, and I'll be happy to hear about them.\n\n\nshare|improve this question\nCan you find an integer $N$ with $N>\\frac 1 {\\epsilon}$? (The Axiom of Archimedes, if you have encountered it) \u2013\u00a0 Mark Bennet May 6 '12 at 15:24\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHint: ${n\\over n+1} =1-{1\\over n+1}$.\n\nshare|improve this answer\nI'm not sure how to use it. I guess I should look at $\\frac{1}{n+1}$ as $\\varepsilon$, but still I don't understand how to build $x$ from it :( \u2013\u00a0 RB14 May 6 '12 at 15:41\n@RB14 Given $\\epsilon>0$, select $n$ such that ${1\\over n+1}<\\epsilon$ (why can you do this?). Then show that $1-{1\\over{n+1}} >1-\\epsilon$. \u2013\u00a0 David Mitra May 6 '12 at 15:45\nyeah, apprently I'm a bit idiot :) \u2013\u00a0 RB14 May 6 '12 at 15:48\n@RB14 Not at all; this stuff is hard unless you've been doing it for 15+ years... \u2013\u00a0 David Mitra May 6 '12 at 15:49\nthere supposed to be a continuation to that comment, but I accidently pressed enter, and my chrome browser did not allow me to delete that comment. any way, I get it now, I should select $x$ to be $\\frac{n}{n+1}$ where $n > \\frac{1}{\\epsilon}$. that is possible from the reason Mark mentioned in his comment - the axiom of archimedes. thanks guys! \u2013\u00a0 RB14 May 6 '12 at 15:54\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/275539/whats-the-quickest-way-to-solve-3i-equiv-1-mod-28\nText:\nTake the 2-minute tour \u00d7\n\nKind of leading on from my other question, how would I solve for $i$? Or how would I check that it is possible to have such an $i$?\n\nFirst I had to check for all $2^i$ and clearly this doesn't happen as all $2^i$ are even and so I will just get even $x's$ such that $2^i \\equiv x \\mod 28$. So the next one I go onto is $3$.\n\nNow how do I go about doing this?\n\nshare|improve this question\nThe quickest way I know of to solve that type of relation is to type it in to Wolfram Alpha. I know that's probably not what you're looking for, but it's a way to check your work... :) \u2013\u00a0 anorton Jan 11 '13 at 1:15\n@anorton I disagree. The quickest way is to compute in one's head $3^3=27=-1\\pmod{28}$, hence $3^6=1\\pmod{28}$, and to convince oneself that neither $3^1$ nor $3^2$ is $1\\pmod{28}$. Hence solutions $6\\mathbb N$. \u2013\u00a0 Did Jan 11 '13 at 8:36\n@did Actually, I like your way better than mine... :) That's a good explanation... \u2013\u00a0 anorton Jan 11 '13 at 13:11\nadd comment\n\n4 Answers\n\nup vote 7 down vote accepted\n\nTo solve $a^i \\equiv 1 \\pmod{n}$, first note that we must have $\\gcd(a,n) = 1$ in order to get a positive (non-zero) integer solution. Like you realized, since $\\gcd(2, 28)=2$, thus $2^i$ will always be a multiple of $2$, and hence cannot be of the from $28k+1$.\n\nGiven that condition, such an $i$ always exists, by Euler's theorem, which states that $ a^{\\phi(n)} \\equiv 1 \\pmod{n}$. The solution, is known as the order. I.e. the smallest positive integer such that $3^k \\equiv 1 \\pmod{28}$ is called the order of 3 modulo 28.\n\nIn this case, we calculate that $ \\phi(28) = 28 \\times \\frac {1}{2} \\times \\frac {6}{7} = 12$, and so we know that $3^{12} \\equiv 1 \\pmod{28}$. From here, we only need to check the factors of 12, which are 1, 2, 3, 4, 6, 12.\n\n$3^1 \\equiv 3, 3^2 \\equiv 9, 3^3\\equiv 27 \\equiv -1, 3^4 \\equiv -3, 3^6 \\equiv (-1)^2 \\equiv 1 \\pmod{28}$. Hence, the order of 3 modulo 28 is 6.\n\nshare|improve this answer\nadd comment\n\n\n\n\n\n\n\nshare|improve this answer\nNote btw that once you get $3^{3}\\equiv -1\\pmod{28}$, you know that $3^{3+1}=3^3\\times 3\\equiv -1\\times 3\\pmod{28}\\equiv-3\\pmod{28}\\equiv 25\\pmod{28}$, $3^{3+2}\\equiv -9\\pmod{28}$, etc. And in particular: $3^{2\\times 3}\\equiv -1\\times -1 \\equiv 1\\pmod{28}$. \u2013\u00a0 Alexander Gruber Jan 11 '13 at 1:29\nadd comment\n\nIf you know the Chinese Remainder Theorem, then you see that you can check this separately mod $4$ and mod $7$. Already $3^2 \\equiv 1 \\bmod 4,$ and so you are left to finding the smallest power of $3$ that is $1 \\bmod 7$. By Euler it is a factor of $7- 1,$ i.e. of $6$, and one easily rules out $1,2,$ and $3$. Thus $i = 6$ is your answer.\n\nIn this case there is not much difference between this approach and applying Euler's theorem directly to $28$, since all the numbers involved are small. But in general, if we have $N = mn$ with $m$ and $n$ coprime, then this method means you only have to compute congruences mod $m$ and $n$, which might be quite a bit easier than working directly mod $N$.\n\nAlso, this method shows that the value of $i$ has to be a factor of the lcm of $\\varphi(m)$ and $\\varphi(n)$, whereas applying Euler directly mod $N$, we only get that the value of $i$ is a factor of $\\varphi(N) = \\varphi(m)\\varphi(n)$. (E.g. since $\\varphi(4) = 2$ and $\\varphi(7) = 6$, we saw immediately that $i$ would be a factor of $6$, whereas since $\\varphi(28) = 12$, applying Euler directly mod $28$ just gives that $i$ is a factor of $12$.)\n\nshare|improve this answer\nadd comment\n\nCarmichael Function is more useful than Totient Function, while dealing with composite numbers like $28$.\n\nFor $\\phi(28)=\\phi(7)\\cdot\\phi(4)=6\\cdot2=12\\implies 3^{12}\\equiv1\\pmod{28}$\n\n$\\lambda(28)=lcm(\\lambda(7),\\lambda(4))=lcm(6,2)=6\\implies 3^6\\equiv1\\pmod{28}$\n\nSo, if $ord_{28}3=d,d\\mid 6\\implies d $ can be $1,2,3$ or $6$\n\n$3^1=3\\not\\equiv 1\\pmod{28},3^2=9\\not\\equiv 1\\pmod{28},3^3=27\\not\\equiv 1\\pmod{28}\\implies ord_{28}3=6$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/86250/finding-all-functions-f-satisfying-ft-ft-int-abftdt/86254\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to find all functions f satisfying $f'(t)=f(t)+\\int_a^bf(t)dt$.\n\nThis is a problem from Spivak's Calculus and it is the chapter about Logarithms and Exponential functions. I gave up and read the solution (which I quickly regretted, but at the same time realized that I had not carefully read one very important theorem* in the text) to find that it begins with:\n\nWe know $f''(t)=f'(t)$.\n\nHow do we know this? Also, in general, how would you have approached this problem? Any solution with your thoughts written out would be very appreciated. I am not interested in the solution, but the thought process behind this.\n\n*For the curious, the theorem was that:\n\nIf $f$ is differentiable and $f'(x)=f(x)$ for all $x$ then there is a number $c$ s.t. $f(x)=ce^x$ for all $x$.\n\nshare|improve this question\nUnfortunately, $t$ is used in two different roles here: an ordinary variable and a \"dummy variable\" in the integral. It would be better practice, and less confusing, to use a different letter for the dummy variable, e.g. $f'(t) = f(t) + \\int_a^b f(s)\\ ds$. That makes it more obvious that this term is constant. \u2013\u00a0 Robert Israel Nov 28 '11 at 8:10\nSri, thanks for the edit. I could barely read the question before you intervened :) \u2013\u00a0 The Chaz 2.0 Dec 7 '11 at 0:07\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n  1. How do we know that $f''(x) = f'(x)$? Differentiate both sides of $$f'(x) = f(x) + \\int_a^b f(t)\\,dt.$$ Remember: $\\int_a^bf(t)\\,dt$ is a number (the net signed area between the graph of $y=f(x)$, the $x$-axis, and the lines $x=a$ and $x=b$). So what is its derivative?\n\n    Why would you do this? Because that integral is somewhat annoying: if you just had $f'(x) = f(x)$, then you would be able to solve the differential equation simply enough (e.g., with the theorem you have). But since all that is standing in our way is a constant that is adding, differentiating should spring to mind: that will get rid of the constant, and just \"shift\" the problem \"one derivative down\" (to a relation between $f''(x)$ and $f'(x)$).\n\n  2. Once you know that $f''(x) = f'(x)$, let $g(x) = f'(x)$. Then we have $g'(x)=g(x)$, so the theorem applies to $g(x)$ (exactly what we were hoping for). And you go from there.\n\nAdded. As both Didier Piau and Robert Israel point out, it's probably definitely bad practice to use the same letter as both an actual variable and the variable of integration (sometimes called the 'dummy variable'). Though I see from looking at my copy of Spivak that this originated in the text and not with you.\n\nshare|improve this answer\nSorry but why one would reproduce OP's (mal)practice of using the same unknown in and out of the integral baffles me. Before saying everything else, I would try to explicitly discourage it. \u2013\u00a0 Did Nov 28 '11 at 8:26\n@DidierPiau: A fair point; though Spivak does exactly that, so it's not the OP's practice. Problem 26 in Chapter 17 reads: \"Find all functions $f(t)$ that satify $f'(t) = f(t) + \\int_0^1 f(t)\\,dt$.\" (At least in my Second Edition in Spanish) \u2013\u00a0 Arturo Magidin Nov 28 '11 at 14:13\nYes. But if your edition is faithful to the original in English, you can check that Problem 26 is the one and only (unfortunate) occurrence. Everywhere else, Spivak is correct. Anyway, to me all this has little to do with what we write here and how we choose to write it (and I do not understand the probably in your Addendum). \u2013\u00a0 Did Nov 28 '11 at 18:08\nadd comment\n\nSince $\\int_a^bf(t)dt$ is a constant, we denote it as $C$\uff0c so we get $f'(t)=f(t)+C$. It is $\\frac{df(t)}{dt}=f(t)+C$, i.e. $\\frac{df(t)}{f(t)+C}=dt$. Integrate it, we get $ln(f(t)+C)=t+D$, where D is a constant. Thus, $f(t)=e^{t+D}-C$. Let $e^D=K$, we get $f(t)=K{e^{t}}-C$.\n\nNow plug it into the original eqution, we get $Ke^t=Ke^t-C+\\int_a^b{(Ke^t-C)}dt$. After some manipulation, we have $K=\\frac{b-a+1}{e^b-e^a}C$. Note here we assume that $b \\neq a$.\n\nIf $b=a$,$C$ is obviously $0$, so the equations can be simplified to $f'(t)=f(t)$. In this case, $f(t)=ke^t$, where k is an arbitrary constant and $k \\neq 0$\n\nshare|improve this answer\n@DidierPiau, of course, It my mistake. \u2013\u00a0 Emmad Kareem Nov 28 '11 at 9:14\n+1, clear answer. \u2013\u00a0 Emmad Kareem Nov 28 '11 at 13:03\nadd comment\n\nYou know that $f''(t)=f'(t)$ because you can differentiate the equation you are trying to solve.\n\nSince the second term in the right hand side of the equation you are trying to solve is annoying, it is a good idea to try to get rid of it. Since it is constant, then that can be done by differentiating the equality with respect to $t$.\n\nshare|improve this answer\nadd comment\n\nYes it's a solved problem. Here's a synopsis that may be a little easier to follow. Start with the equation $$ f^\\prime(t) = f(t) + \\int_a^bf(t)dt, $$ for $a<b$ and note that the integral on the RHS is $(b-a)$ times the average value of $f$ on $[a,b]$; call this term M, which is constant for a given $f$. Any solution of $f^\\prime(t)=f(t)+M$ is differentiable, so the RHS is differentiable, implying that $f^{\\prime\\prime}=f^\\prime$ (and, by recursion, that $f$ is actually infinitely differentiable). This has solution $f^\\prime(t)=ce^t$ by a standard argument (the additive constant must be zero) so that $f(t)=ce^t+d$. But then $$ M=\\int_a^bf(t)dt=\\left[ce^t+dt\\right]_a^b=c(e^b-e^a)+d(b-a), $$ giving us a constraint on the constants $c$ and $d$: $$ ce^t=f^\\prime(t)=f(t)+M=ce^t+d+M \\quad\\implies\\quad M=-d \\quad\\implies $$ $$ 0=M+d=c(e^b-e^a)+d(b-a+1)\\quad\\implies\\quad d=-c\\frac{e^b-e^a}{1+b-a} $$ so that the general solution is $$ f(t)=c\\left[e^t-\\frac{e^b-e^a}{1+b-a}\\right]. $$ Finally, the \"standard argument\" referred to above is that if $u^\\prime=u$ for some function $u(t)$, then $$ \\frac{du}{u}=dt \\quad\\implies\\quad \\ln|u|=t+c_1 \\quad\\implies\\quad |u|=e^{t+c_1} \\quad\\implies\\quad u=ce^t $$ where $c=\\pm e^{c_1}$ can be any nonzero constant but in fact also zero (which couldn't be inferred from the derivation because we divided by $u$ along the way, so we recover the solution at the end by inspection).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/53344/sections-of-grassmannian-bundles\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a smooth projective variety of dimension $n$. Take the bundle $TX \\oplus Sym^2(TX)$ over $X$ where $Sym^2(TX)$ is the second symmetric product of the tangent space. The Grassmannian bundle $Gr(n,TX \\oplus Sym^2(TX))$ has a canonical section, namely $TX$.\n\nMy question is: what is the Poincare dual of this section in the cohomology ring of the Grassmannian bundle?\n\nThe cohomology ring is\n\n$H^*(Gr(n,TX \\oplus Sym^2(TX)))=H(X)[c_1,\\ldots, c_n,d_1,\\ldots, d_{{n+1 \\choose 2}}]/$\n\n$(1+c_1+\\ldots +c_n)(1+d_1+\\ldots +d_{{n+1 \\choose 2}})=c(TX \\oplus Sym^2(TX))$\n\nThis is probably a trivial question I am a bit confused about it now.\n\nshare|improve this question\nHi Gergely! This should be not extremely difficult but for sure not completely trivial... I'll think about it later, if no one answers you meanwhile! All the best! \u2013\u00a0 diverietti Jan 26 '11 at 11:57\nMy guess: it is the top Chern class of $Hom(TX,Sym^2(TX))$, that is $\\prod(\\beta_i-\\alpha_j)$ where $\\beta_i$s and $\\alpha_j$s are the Chern roots of the $d$`s and $c$'s respectively, i.e $\\prod(1+\\beta_i)=1+d_1+\\ldots$ \u2013\u00a0 Gergely Berczi Jan 26 '11 at 12:18\nadd comment\n\n1 Answer\n\nup vote 3 down vote accepted\n\nLet $U$ denote the tautological subbundle. I guess that $c_i = c_i(U^*)$ in your notation. Consider the composition map $$ U \\to p^*(TX + S^2TX) \\to p^*S^2TX, $$ where $p:Gr \\to X$ is the projection. Then your section is the zero locus of this map. In other words, it is the zero locus of a global section of the vector bundle $U^*\\otimes p^* S^2TX$. The section is regular, so the class of the zero locus equals the top Chern class of the bundle. Thus the answer is $$ c_{n^2(n+1)/2}(U^*\\otimes p^*S^2TX). $$ The rest is a straightforward computation.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.maths-in-industry.org/miis/274/\nText:\nThe MIIS Eprints Archive\n\nModelling Li+ Ion Battery Electrode Properties\n\n\n\n\nWe formulated two detailed models for an electrolytic cell with particulate electrodes based on a lithium atom concentration dependent Butler-Volmer condition at the interface between electrode particles and the electrolyte. The first was based on a dilute-ion assumption for the electrolyte, while the second assumed that Li ions are present in excess.\n\nFor the first, we used the method of multiple scales to homogenize this model over the microstructure, formed by the small lithium particles in the electrodes.\nFor the second, we gave rigorous bounds for the effective electrochemical conductivity for a linearized case.\nWe expect similar results and bounds for the \"full nonlinear problem\" because variational results are generally not adversely affected by a sinh term.\n\nFinally we used the asymptotic methods, based on parameters estimated from the literature, to attain a greatly simplified one-dimensional version of the original homogenized model. This simplified model accounts for the fact that diffusion of lithium atoms within individual electrode particles is relatively much faster than that of lithium ions across the whole cell so that lithium ion diffusion is what limits the performance of the battery. However, since most of the potential drop occurs across the Debye layers surrounding each electrode particle, lithium ion diffusion only significantly affects cell performance if there is more or less complete depletion of lithium ions in some region of the electrolyte which causes a break in the current flowing across the cell. This causes catastrophic failure. Providing such failure does not occur the potential drop across the cell is determined by the concentration of lithium atoms in the electrode particles. Within each electrode lithium atom concentration is, to leading order, a function of time only and not of position within the electrode. The depletion of electrode lithium atom concentration is directly proportional to the current being drawn off the cell. This leads one to expect that the potential of the cell gradually drops as current is drawn of it.\n\nWe would like to emphasize that all the homogenization methods employed in this work give a systematic approach for investigating the effect that changes in the microstructure have on the behaviour of the battery. However, due to lack of time, we have not used this method to investigate particular particle geometries.\n\nItem Type:Study Group Report\nProblem Sectors:Energy and utilities\nCompany Name:TIAX, LLC.\nID Code:274\nDeposited By:Dr Kamel Bentahar\nDeposited On:25 Jan 2010 17:06\nLast Modified:25 Jan 2010 17:06\n\nRepository Staff Only: item control page"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?t=681376\nText:\nCauchy-Goursat's theorem and singularities\n\nby Verdict\nTags: cauchygoursat, singularities, theorem\nVerdict is offline\nMar27-13, 07:36 PM\nP: 113\nCalculate the closed path integral of [tex]\\frac{z+2 i}{z^3+4 z}[/tex] over a square with vertices (-1-i), (1,i)\nand so forth.\n\n2. Relevant equations\nThe closed line integral over an analytic function is 0\n\n3. The attempt at a solution\nAlright, so first I factored some stuff, leaving me with\n[tex]\\frac{1}{z (z-2 i)}[/tex]\n\nNow, this has a simple pole at 0 and at 2i. However, 2i isn't in the square, so I'm only concerned about the one at 0. Now, I don't know how to continue from here on, formally. I know (do I?) that the answer has to be i*2pi, as that always happens to be the case when doing a closed integral of a function that has 1 singularity (and it is enclosed by the path). But how do I 'calculate' this? I tried writing z = x+iy and the same for dz, and then working it all out and parameterizing the vertices, but that gives horrible expressions to integrate and just doesn't seem right.\n\nIs there something I'm missing?\n\nAlso, there is a follow up question, which concerns the same integral but now over the square with vertices (-1-3i), (1+3i) and so forth. So this encloses both singularities, but they aren't symmetric or anything, so then I can't really go any further. (Is it even true, that when the singularities are distributed symmetrically, that they sort of cancel each others effect and your integral evaluates as 0?)\n\nKind regards\nPhys.Org News Partner Science news on\nNASA data shed new light on changing Greenland ice\nMandelbroth is offline\nMar28-13, 02:36 PM\nMandelbroth's Avatar\nP: 583\nCauchy-Goursat only gets you so far. You have two options:\n\n1. Evaluate it using the typical method of line integrals.\n2. Use the more general theorem.\n\nNot all contour integrals around singularities yield ##2\\pi i##. They do, however, follow the relation $$\\oint_{\\beta}f(z) \\ dz = 2\\pi i \\sum \\mathfrak{R}_{z_i}(f(z))$$\nif ##\\beta## is a Jordan curve, where ##\\mathfrak{R}_{z_i}## denotes the residue of the function at a point ##z=z_i## interior to ##\\beta##.\n\nIf you are unfamiliar with residues, I would suggest using the typical line integral method.\n\nEdit: Didn't see the bottom of your post.\nI see where you would get the idea that they might \"cancel each other out.\" However, it is entirely wrong. Once you get a little further into complex analysis, you'll probably have a kind of epiphany moment where you'll start thinking \"Hey! None of this makes any logical real sense in terms of what I learned from basic calculus. Better start thinking about it differently!\" At that point, everything starts making sense because you'll notice that, in terms of complex numbers, it really doesn't matter what the contour is or where the poles are. As long as the contour contains the same poles and has the same winding number, you get the same answer.\nVerdict is offline\nMar28-13, 02:46 PM\nP: 113\nThank you for your answer!\nI've discussed my issue with the teacher today, and apparently he accidentally gave out exercises that were meant for later in the course. This was only one of them, and I've spent hours thinking about this one and the others, so that is a little frustrating.\n\nEither way, it is still very good to see that what I thought might have been the case is not true at all. I wasn't sure that it was, it just seemed to be so every single time. But its good to know that it is simply not the case. I look forward to getting further into the material though, I really enjoy how elegant everything is in the complex numbers.\n\nRegister to reply\n\nRelated Discussions\nThe Cauchy-Goursat Theorem Topology and Analysis 1\nKln theorem and initial-state singularities High Energy, Nuclear, Particle Physics 0\nContour integral with multiple singularities inside domain without residue theorem?? Calculus & Beyond Homework 14\ngreens theorem and cauchy theorem help Calculus & Beyond Homework 4\nCauchy horizon singularities General Astronomy 2"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/9914/finding-the-height-of-a-d-ary-heap\nText:\nTake the 2-minute tour \u00d7\n\nI would like to find the height of a d-ary heap. Assuming you have an Array that starts indexing at $1$ we have the following:\n\nThe parent of a node $i$ is given by: $\\left\\lfloor\\frac{i+1}{d}\\right\\rfloor$\n\nThe $d$ children of a parent at node $i$ are given by: $di-d+1, di-d+2,\\ldots di+1$\n\nThe height of a heap (which is slightly different than the height of a binary search tree) is a longest path from the root to a leaf. A longest path will always be from the last node in the heap to the root, but how do I calculate this longest path?\n\nMy first Idea is to setup a recurrence relation for the height of the tree:\n\n\\begin{equation} h(1) = 0\\\\ h(i) = h\\left(\\left\\lfloor\\frac{i+1}{d}\\right\\rfloor\\right)+1 \\end{equation}\n\nThis seems overly-complicated and I feel like the answer is much more simple. Is there a better way to find the height of a $d-$ary heap?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nA path from the last node to the leaf would always be a longest path. This is because the last node is always at the lowest level in the heap. Now, assume the root is at level $0$. Then the number of nodes at a completely filled level $i$ would be $d^i$.\n\nLet level $k$ be the last completely filled level in the heap. So the number of nodes upto (and including) level $k$ is: $$\\sum\\limits_{i = 0}^{k}d^i = \\frac{d^{k+1} - 1}{d - 1}$$\n\nNow, the last node - the $n^{th}$ node - can either be the last node at level $k$, or it can be in an incomplete level $k+1$. Taking care of these two cases, it can be seen that: $$\\frac{d^{k+1} - 1}{d - 1} \\le n < \\frac{d^{k+2} - 1}{d - 1}$$ $$\\Rightarrow k\\le \\log_d(n(d-1) + 1) - 1 < k+1$$\n\nNow, equality is only if the last node is the last leaf of level $k$, which also has distance $k$ from the root. If not, that is if there is a level $k+1$, then the $\\log$ term would not be an integer, and applying the ceiling operator would give the right height of $k+1$. Thus, if the last element of the array is at position $n$, the height of the heap is: $$h = \\lceil \\log_d(nd - n + 1) \\rceil - 1$$ You can change the base of the logarithm using the change of base formula. Note that this is the same method that Yuval gives in his answer.\n\nshare|improve this answer\nadd comment\n\nA different approach is to calculate the number of points $n_d(h)$ in a saturated (maximal) $d$-ary heap of height $h$. Given $n_d(h)$, the height of a $d$-ary heap of size $n$ is the minimal $h$ such that $n_d(h) \\geq n$. Given the formula for $n_d(h)$, you should be able to find $h$ explicitly.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166684/proving-inf-limits-f-in-gamma-fytft-fyt\nText:\nTake the 2-minute tour \u00d7\n\nI would like to proof the next claim:\n\nLet $X$ a Banach space, $F\\colon X\\to X^*$ a linear continuous function, $$ \\Gamma:=\\{f\\in (\\mathcal{C}([0,1],X)\\,:\\, f(0)=f(1)=0\\mbox{ and }\\|f\\|\\leq 1\\} $$ and fix $t\\in [0,1]$, $y\\in \\Gamma$. Then $F(y(t))\\in X^*$. How I can prove that $$ \\inf\\limits_{f\\in\\Gamma} \\{ F(y(t))(f(t))\\}= -\\|F(y(t))\\| $$ ? I tried it using Hahn-Banach, but maybe there is another easier way. Thanks in advance.\n\nEdit: sorry, I forgot to put that F es linear... Thanks for the answers.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou need to assume $F(0) = 0$ for this to hold as the left hand side is $0$ for $t\\in \\{0,1\\}$, hence the right hand side should also be zero, i. e. $F(0) = 0$. As $F$ and $y$ are evaluated at exactly one point, let's write $x^* = F\\bigl(y(t)\\bigr)$, if $t \\in (0,1)$, then $\\Gamma(t) = \\{f(t)\\mid f\\in \\Gamma\\} = B_X$, so you have to prove $\\inf_{x\\in B_X} x^*(x) = -\\|x^*\\|$, which holds as \\[ \\|x^*\\| = \\sup_{x \\in B_X} x^*(x) = -\\inf_{x\\in B_X} x^*(-x) = -\\inf_{x\\in B_X} x^*(x). \\]\n\nshare|improve this answer\nSorry, I think if you put, for example, f(t)=t if t<=1/2 and f(t)=1-t if t>=1/2, then $\\Gamma(t)$ it isn't equal to $B_X$. \u2013\u00a0 Manolete Jul 4 '12 at 20:23\n@Manolete I think there should be $f\\in\\Gamma$ instead of $t\\in\\Gamma$ \u2013\u00a0 Norbert Jul 4 '12 at 20:26\n@Norbert Thx. You're right. \u2013\u00a0 martini Jul 4 '12 at 20:56\nAh, ok. I have read it bad. So it's clear that $\\Gamma(t)=B_X$. Then $\\inf\\limits_{f\\in \\Gamma} x^*\\big(f(t)\\big)=\\inf\\limits_{f(t)\\in \\Gamma(t)} x^*(f(t))=\\inf\\limits_{x\\in B_X} x^*(x)$. Thanks a lot! \u2013\u00a0 Manolete Jul 4 '12 at 21:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?p=2003624\nText:\nFinding max/min given contraint\n\nby ultra100\nTags: constraint equation, lagrange, maximum, minimum, multivariable\nultra100 is offline\nDec15-08, 09:13 PM\nP: 9\n\nFind the product of the maximum and minimum values of the function f(x, y) = xy\non the ellipse (x^2)(1/9) + y^2 = 2\n\n3. The attempt at a solution\n\nI tried soving using lagrange multiplier and got:\n\nfx = y - (2/9)(x*lambda)\nfy = x - 2y*lambda\nflambda = (x^2)(1/9) + y^2 - 2\n\nthen I set these = 0, but my answer came out wrong.. any suggestions for figuring out the min/max?\n\n2. Relevant equations\n\n3. The attempt at a solution\nPhys.Org News Partner Science news on\nAt tech fest: 3D printers, bitcoin and 'Titanfall'\nLondon launches hi-tech trial for pedestrian safety\nLignin breakthroughs serve as GPS for plant research\nNoMoreExams is offline\nDec15-08, 09:23 PM\nP: 626\nFor y I'm getting, [tex] y = \\pm 1 [/tex]\n\nThe way I set this up was as follows:\n\n\n[tex] f(x,y) = xy; g(x,y) = \\frac{x^{2}}{9} + y^{2} = 2 \\Rightarrow h(x,y,\\lambda) = f(x,y) + \\lambda g(x,y) [/tex]\n\n(Note that the sign in front of [tex] \\lambda [/tex] does not matter)\n\nSo let's take our partials, we get:\n\n[tex] \\frac{dh}{dx} = y + \\frac{2 \\lambda}{9}x, \\frac{dh}{dy} = x + 2 \\lambda y, \\frac{dh}{d\\lambda} = \\frac{x^2}{9} +y^2 - 2 [/tex]\n\nWe know that each of those partials vanish i.e. we can set each to 0.\n\nThe first one gives us\n\n[tex] 9y = -2 \\lambda x [/tex]\n\nand the second one gives us\n\n[tex] \\frac{x}{y} = -2 \\lambda[/tex]\n\nAnd by simple substitution we get:\n\n[tex] 9y^{2} = x^{2} [/tex]\n\nSo let's substitute it into our 3rd equation to get:\n\n[tex] y^{2} + y^{2} = 2 [/tex]\n\nWhich yields our desired result of [tex] y = \\pm 1 [/tex]. Now we can plug this into our g(x,y) to get [tex] x = \\pm 3 [/tex]\n\nNote that it doesn't matter which value for y we pick therefore our solution set will be:\n\n[tex] (1,3), (1,-3), (-1,3), (-1,-3) [/tex]\n\nNow if you don't want to do this using Lagrange Multipliers, we can just realize that we can rewrite our g(x,y) as\n\n[tex] y = \\pm \\sqrt{2 - \\frac{x^2}{9}} [/tex]\n\nand now we can substitute this into our f(x,y) get an equation of one variable i.e.\n\n[tex] \\bar{f}(x) = \\pm x \\cdot \\sqrt{2 - \\frac{x^2}{9}} [/tex]\n\nNow we can proceed using the techniques you learned in Calculus 1 (I'm going to use Maple because I'm lazy)\n\n> a:=x*sqrt(2-x^2/9);\n\na := [tex] \\frac{1}{3} x \\sqrt{18 - x}[/tex]\n\n> solve(diff(a,x)=0,x);\n\n-3, 3\n\nNote that choosing the negative root produces the same results.\nultra100 is offline\nDec15-08, 09:31 PM\nP: 9\nwhat equations are you using to get y = to +/- 1?\n\nNoMoreExams is offline\nDec15-08, 09:50 PM\nP: 626\n\nFinding max/min given contraint\n\nQuote Quote by ultra100 View Post\nRefresh your page :)\nultra100 is offline\nDec15-08, 09:56 PM\nP: 9\nThanks!!! This helps a lot\n\nRegister to reply\n\nRelated Discussions\nFinding the Method of moments estimator? Having trouble finding E(Y^2) Calculus & Beyond Homework 1\nFinding the pH of TSP Biology, Chemistry & Other Homework 5\nFinding pH Biology, Chemistry & Other Homework 11\nfinding the inverse and finding a matrix * A = 0 matrix Introductory Physics Homework 6\nFinding Yourself General Discussion 34"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296742/prove-partial-derivatives-of-uniformly-convergent-harmonic-functions-converge-to\nText:\nTake the 2-minute tour \u00d7\n\nI think the title says it all.\n\nIf you have a sequence of harmonic functions from a bounded complex domain to the real numbers, show that on a subset at a positive distance from the boundary of the domain, e.g. a compact subset of the domain, the derivatives of the harmonic functions converge uniformly to the derivative of the limit of the sequence of the harmonic functions.\n\nThank you!\n\nMy attempt: I tried to apply the mean value property (like Gamelin does for analytic functions) to find a bound (unsuccessfully). I know the question has been asked before, but I did not understand the solution. I also tried to come up with something similar to Cauchy estimates for harmonic functions, but I wound up more confused than when I started.\n\nEDIT: Keep in mind by derivative I meant partial derivatives. My attempt was to find an analogue of the Cauchy integral formula (for derivatives) but I seem to get the same formula for both partial derivatives, which does not make sense to me because it seems like the partial derivatives can be different.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nYour approach is correct, I would use the mean value property to try to derive an analogue of the Cauchy estimates. Let $\\Omega$ be the domain, and let $u$ be harmonic. See if you can show that if $B(z,r) \\subset \\Omega$, then $$ |\\partial_i u(z)| \\le Cr^{-1} \\|u \\|_{L^{\\infty}(\\partial B(z,r))}$$ You will be using both the mean value property (since $\\partial_i u$ is itself harmonic) and the divergence theorem. If you have further questions I can elaborate more.\n\nElaboration: The $L^{\\infty}$, in the context of continuous functions (such as the harmonic functions in this problem), is just the norm corresponding to uniform convergence. So the sequence of harmonic functions $u_n$ converging uniformly on a compact set $K$ can be rewritten as $\\|u - u_n\\|_{L^{\\infty}(K)} \\rightarrow 0$ as $n \\rightarrow \\infty$.\n\nTo obtain the estimate in question, first use the mean value property to obtain: $$ \\partial_i u(z) = \\frac{1}{\\pi r^2} \\int_{B(z,r)} \\partial_i u(x,y) \\, dx \\, dy, $$ which follows from $\\partial_i u$ itself being harmonic. By the divergence theorem, then this is equal to $$ \\frac{1}{\\pi r^2} \\int_{\\partial B(z,r)} u \\nu^i \\, dS, $$ where $\\nu^i$ is the $i$-th component of the unit vector normal to the surface $\\partial B(z,r)$. Thus $$ |\\partial_i u(z)| \\le \\frac{1}{\\pi r^2} \\int_{\\partial B(z,r)} |u| \\, dS = \\frac{2}{r} \\|u\\|_{L^{\\infty}(\\partial B(z,r))}$$ This allows you to control the pointwise convergence of the partial derivatives of $u_n$ by the uniform convergence of $u_n$. However, this in turn allows you to control the uniform convergence of the derivatives on a compact set, since then you can just use larger balls.\n\nshare|improve this answer\nHello. I'm unfamiliar with L norms. I'm learning about harmonic functions in a one variable complex analysis course. I was wondering if you could elaborate on how you derived the given inequality. I'm still unsure of where divergence theorem comes in. I think I was able to derive the Cauchy integral formula for harmonic functions but the formula for derivative I'm getting seems to be the same for all the partial derivatives... \u2013\u00a0 MR1992 Feb 7 '13 at 0:35\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/130088/two-variable-recurrence-equation-with-varying-coefficients\nText:\nTake the 2-minute tour \u00d7\n\n\nI have the following two variable recurrence equation for integers $j,k$:\n\n$f(j,k) = (k/j)f(j-1,k-1) - (3 + k/j)f(j-1,k+2)$\n\nwhere $f(j,0) = (3^j - 1)/j + 3jf(j-1,2)$, $f(0,0) = 0$, $f(0,k) = a_k$.\n\nI would like to express $f(n,0)$ in terms of the different $a_k$ values.\n\nI tried a generating function approach, by considering the generating function $\\phi(x,y) = \\sum_j\\sum_k f(j,k)x^jy^k$, but it gives rise to a nasty differential equation.\n\nAny ideas on how to attack this recurrence equation? Maybe by just calculating it for a few $n$ values, observe a pattern and use induction? The latter is also quite tedious. Is there any neat approach to this?\n\nshare|improve this question\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/237280/smallest-imperfect-graph-whos-chromatic-number-equals-clique-number\nText:\nTake the 2-minute tour \u00d7\n\nSo I need to find the smallest imperfect graph, $G$ who's chromatic number equals it's clique number. ie:\n\n$$\\chi(G) = \\omega(G)$$\n\nFinding imperfect graphs isn't hard (since finding perfect graphs is). Even finding imperfect graphs with this property isn't too hard. But how do we find the smallest graph (I assume minimal # vertices). Even if I have an idea what this graph is, how can I prove it is the smallest? I.e if I think sum graph on $n$ vertices is the smallest graph satisfying this, it seems daunting to show every graph of order $<n$ fails to satisfy this (unless $n$ is relatively small).\n\nMethods to approach and tackle this problem?\n\nshare|improve this question\nWhat is the smallest $n$ you can easily find an example for? \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 16:19\n$C_5$ with an added internal vertex connected to 3 vertices of $C_5$, 2 of which neighbours, 1 of which is not a neighbour to either. so $n=6$ \u2013\u00a0 user45814 Nov 14 '12 at 16:53\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nConsider the cyclic graph with five vertices $a,b,c,d,e$ and add a sixth vertex $f$ with edges $af$, $bf$, $df$. Then $\\omega(G)=\\chi(G)=3$ and the graph is not perfect becaus the induced subgraph obtained by removing $f$ has $\\chi=3$ and $\\omega=2$.\n\nWhy is six minimal? For graphs up to four vertices, $\\chi=\\omega$ always holds, hence every graph with at most five vertices having $\\chi=\\omega$ is perfect.\n\nshare|improve this answer\nOh, I see you found that by yourself in a comment meanwhile. \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 17:05\nYes, but couldn't find a way to show it was minimal. Thanks! \u2013\u00a0 user45814 Nov 14 '12 at 17:13\nIs there an easy way to show for graphs up to four verticies that X=w? I can tell it's true, but not sure if I can just state that (Ill post this as a new question, since it seems it may take some thought) \u2013\u00a0 user45814 Nov 14 '12 at 17:44\nIf $\\omega=n$, then trivially $\\omega=\\chi$. If $\\omega=n-1$, then colour a maximal clique with $\\omega$ colours and the remaining vertex with the colour of one of its non-neighbours. If $\\omega\\le n-2$, then $G$ is either $C_4$ or a tree with $\\chi=2$ or disconnected with $\\chi=1$. \u2013\u00a0 Hagen von Eitzen Nov 14 '12 at 17:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/16059/can-a-super-extremal-charged-black-hole-be-made-out-of-electrons-only/16061\nText:\nTake the 2-minute tour \u00d7\n\nIn a previous Question it was argued that it would be impossible to add enough charge to a black hole to make it pass the extremal black hole limit since adding charge would increase the mass of the black hole due to the electrostatic field energy (and thus mass) that would be added as the charge is added.\n\nNote that an electron cannot be a black hole but if an electron were a black hole it would be a super-extremal black hole per this wikipedia article: Basically the Schwarzchild radius for the electron's mass is $r_s = 1.35 \\times 10^{-57} m$ whereas the charge radius of the electron is $r_q = 9.15 \\times 10^{-37} m$. So since $$\\frac{r_q}{r_s} \\approx 10^{21} \\gt 1$$ an electron, if it was a black hole, would be a super-extremal black hole by a large margin. In words, the electrons mass is completely negligible compared to its charge.\n\nAn uncharged black hole can be constructed out of matter at any given mass density by simply constructing a big enough sphere of that matter. This is true because a sphere of radius $R$ with a constant (low?) density will have a mass $M$ that is $\\propto R^3$ whereas the Schwartzchild radius is $\\propto M \\propto R^3$. So as $R$ increases the radius of the sphere will eventual be less than the Schwartzchild radius.\n\nSo, can we make a super-extremal charged black hole by using a very large sphere of radius $R$ that is made out of electrons uniformly distributed with (low) charge density $\\rho$?\n\nshare|improve this question\nI was hoping the answer was yes, but as I did the calculations I convinced myself it would not work, so I am documenting my calculations by asking and answering this question. I hope this might be interesting to other people and I hope you will check my calculations. If my answer is wrong, please correct me! \u2013\u00a0 FrankH Oct 23 '11 at 8:13\nIt should be added that there is no reason to suppose that the relation Q=M for extreme black holes is correct for black holes the size of electrons. Electrons are quantum black holes in string theory--- they are strings--- and the lightest black hole excitation in a charged string theory always is on the other side of the extremality bound. Whether you call it a black hole is a matter of convention, but you can't use classical GR to describe something that small. \u2013\u00a0 Ron Maimon Oct 23 '11 at 17:44\nYes, @ron, you are right. The electron cannot be a black hole for lots of reasons. The electrons Schwartzchild radius is many orders of magnitude smaller than the Planck length so classical GR will not apply. I will edit the question to clarify that. Thanks. Any opinion on my answer would be appreciated. \u2013\u00a0 FrankH Oct 23 '11 at 18:17\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe answer is no. As stated, the electrons mass will be ignored. If we assume the mass of the sphere is just due to the electrostatic field energy of the uniformly charged sphere, can we create a black hole and can the charge to mass ratio $\\frac{Q}{M}$ be super-extremal ($\\frac{Q}{M} \\gt 1$ in appropriate units).\n\nNow the charge of the sphere is $$Q \\propto \\rho R^3$$ the electric field strength $E(r)$ as a function of the radius $r$ is $E(r) \\propto \\rho r$ and the mass $M$ due to the electrostatic field energy is $$M \\propto \\int_0^R E^2(r) d^3r \\propto \\rho^2 R^5 $$ Therefore the ratio of charge to electrostatic field energy-mass is $$\\frac{Q}{M} \\propto \\rho^{-1} R^{-2}$$\n\nConsider the case of constant $\\rho$ with $R$ increasing: Since $M \\propto R^5$ increases rapidly, eventually a black hole will form. However the ratio $\\frac{Q}{M}$ will decrease as $R$ increases, so it will not be an extremal black hole.\n\nNow consider the case of constant $R$ with $\\rho$ increasing: Since $M \\propto \\rho^2$ a black hole will eventually form. but again the ratio $\\frac{Q}{M}$ will decrease as $\\rho$ increases, so it will not be an extremal black hole.\n\nTherefore it is impossible to create a super-extremal black hole from a uniform sphere with a constant charge density since the electrostatic energy-mass alone will create a black hole with a charge to mass ratio less than 1. Any additional neutral mass added into the sphere will result in an even lower charge to mass ratio so that will also not be super-extremal.\n\nshare|improve this answer\n+1: nice answer. \u2013\u00a0 Ron Maimon Oct 23 '11 at 18:35\nDue to the fact that no one has found any mistake in my calculations for the past 2 weeks, I am accepting my own answer so this will not stay as an open question forever... \u2013\u00a0 FrankH Nov 5 '11 at 4:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/123951/find-two-contiguous-subarrays-with-the-greatest-difference\nText:\nHere's an interview question I've seen on a few sites. People claim that an O(n) solution is possible, but I've been racking my brain these last 2 days and I couldn't come up with a solution, nor find one anywhere on the web.\n\nGiven an array of integers, find two disjoint, contiguous subarrays such that the absolute difference between the sum of the items in each subarray is as big as possible.\n\nExample input: (2, -1, -2, 1, -4, 2, 8)\n\nExample output: ((1, 4), (5, 6))\n\nThe output above is the indices of these two subarrays: ((-1, -2, 1, -4,), (2, 8))\n\nI've been trying to reduce this problem to the Maximum subarray problem but with no success.\n\n  \u2022 $\\begingroup$ Hint, two contiguous subarrays means the last element of the first subarray is adjacent to the first element of the second subarray. Did you see a parameter here? $\\endgroup$ \u2013\u00a0John L. Apr 11 at 17:35\n  \u2022 $\\begingroup$ I believe OP did not mean that the two subarrays are adjacent. My guess is that they used the word 'contiguous' to just mean that the two disjoint subarrays are independently contiguous themselves, which I think is redundant given the definition of subarray. But it is still used in many places. eg. \"finding a contiguous subarray with the largest sum\" in en.wikipedia.org/wiki/Maximum_subarray_problem $\\endgroup$ \u2013\u00a0CodeChef Apr 11 at 17:45\n  \u2022 1\n    $\\begingroup$ @CodeChef Unfortunately, the example given in the question can be considered the supposed interpretation of \"contiguous subarray.\", although it does not rule out the possibility to treat is as \"redundant\" as well. Treating it as meaningful and not redundant shows, I believe, the most respect to the almost universal convention that \"subarray means contiguous elements\" and, hence, the the author of the original problem. $\\endgroup$ \u2013\u00a0John L. Apr 11 at 17:53\n  \u2022 1\n    $\\begingroup$ Yes, I agree. My guess was also based on having seen this problem (the variant I assumed it to mean) multiple times in relation to interview questions, but you are absolutely right. $\\endgroup$ \u2013\u00a0CodeChef Apr 11 at 17:57\n\nBecause the two subarrays are disjoint, there exists at least one index $m$ such that one entire subarray lies $\\leq m$ and the other subarray lies $\\gt m$.\n\nBut we do not know what this $m$ is, beforehand. So let us iterate over all the $n$ possibilities for $m$. Now if an $m$ is fixed, then the problem reduces to the Maximum subarray problem, and the Minimum subarray problem. This is because for the absolute difference to be the largest, one side of $m$ should have the maximum possible subarray, and the other side should have the minimum possible subarray. So we try both of these options and take the maximum absolute difference among the two.\n\nBut this is still $\\mathcal{O}(n^2)$, because there are $n$ different values of $m$, and for each of those values, we have to spend $\\mathcal{O}(n)$ time to compute the needed minimum and maximum subarrays.\n\nThe next observation is to note that a single $\\mathcal{O}(n)$ run of the Maximum subarray algorithm on the entire array can actually give us one of the needed values for all values of $m$:\n\nGiven: int A[n]\n\nMaxSubarrayTill[0] = A[0]\nMaxSubarrayEndingAt[0] = A[0]\n    MaxSubarrayEndingAt[i] = max{A[i], MaxSubarrayEndingAt[i - 1] + A[i]}\n    MaxSubarrayTill[i] = max{MaxSubarrayTill[i - 1], MaxSubarrayEndingAt[i]}\n\nHere, $\\text{MaxSubarrayTill}[i]$ denotes the maximum sum subarray which ends $\\le i$, and $\\text{MaxSubarrayEndingAt}[i]$ denotes the maximum sum subarray which ends at index $i$.\n\nSimilarly, we can compute the $\\text{MinSubarrayTill}[i]$ array in $\\mathcal{O}(n)$ time. And by repeating the same two algorithms in reverse (ie. from the end of the array to the beginning), we can get $\\text{MaxSubarrayFrom}[i]$ and $\\text{MinSubarrayFrom}[i]$.\n\nSo in $\\mathcal{O}(n)$ time we have precomputed all the values that we needed in the first algorithm, which we can now go back to. Interate over all the values of $m$, and find the largest absolute difference in $\\mathcal{O}(n)$ time.\n\nIf the problem also stipulates that the two subarrays should be adjacent, then we can leave out $\\text{MaxSubarrayTill}[i]$ and its analogous arrays, and instead only consider $\\text{MaxSubarrayEndingAt}[i]$ and its analogous three other arrays. The rest of the algorthm remains the same.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from http://www.inquirymaths.com/home/geometry-prompts/area-of-a-triangle-inquiry\nText:\nHome\u200e > \u200eGeometry prompts\u200e > \u200e\n\nArea of a triangle inquiry\n\nThe prompt invites\u00a0students to use the formula for the area of a non-right-angled\u00a0triangle:\nDuring classroom inquiry, students' initial questions and observations have included:\n  \u2022 How do you work out the area of the triangle?\n  \u2022 The triangle is not drawn to scale because it's not isosceles.\n  \u2022 The statement\u00a0must be true because the sides are getting longer.\n  \u2022 n can't be 180 because then the angle would not exist.\n  \u2022 You cannot work out the area of the triangle unless n = 90. Then the angle is 90 degrees and the height and base are both 90.\nIn the first phase of the inquiry, the teacher will introduce\u00a0the formula and, if appropriate, show how it is derived from the simpler formula (half the product of base and height).\u00a0\nAs students explore the area, they realise that the contention in the prompt is false. The greatest area is achieved when n = 131.1 (accurate to one decimal place), at which point the area starts to decrease. Students realise that the area must be\u00a0a minimum at the limits of n.\u00a0That is because:\n  \u2022 As\u00a0tends to 0, the angle gets closer to 180 degrees, and\n  \u2022 As n tends to 180, the angle gets closer\u00a0to zero degrees.\nAs you approach both limits, the triangle tends towards a straight line. One way to show this (and the maximum area) is to use a spreadsheet.\nIn the another phase of the inquiry, students have changed the parameters in the prompt to see how the value of n changes for the maximum\u00a0area. For example, the side lengths could be (n - 1) and the angle (180 - 10n) degrees and so on.\nPerimeter inquiry\nAfter the initial phase of the inquiry, year 10 students\u00a0at Haverstock School (London, UK) developed another line of inquiry when they posed questions about the perimeter:\n  \u2022 As\u00a0n\u00a0increases, does the perimeter\u00a0increase?\n  \u2022 What is the perimeter of the triangle when the area is at its maximum?\nMichael Joseph, their mathematics teacher, took the opportunity\u00a0to teach the students about the cosine rule. He created this spreadsheet\u00a0(using radians) to show that the perimeter\u00a0is at a maximum when n = 2.61308 (accurate to five decimal\u00a0places) at which point the angle is (p\u00a0- 2.61308) radians or 30.28 degrees.\nAlternative prompt\nThe prompt could be presented in a simpler\u00a0form by making the angle smaller, giving students fewer cases to explore. The area increases until n = 61.7, whereupon it starts to decrease. At n = 61.7, the angle is 28.3 degrees and the area equals 902.4 square units (accurate to one decimal place).\n\nProof using differentiation and iteration\nShawki Dayekh, a teacher of mathematics in north London (UK), proved the maximum area occurs when n = 131.14 (accurate to 2 decimal places). He used differentiation\u00a0and iteration, expressing the angle in radians.\nThe value of x is 131.14, which means an angle of 48.86 degrees gives the maximum area."}
{"text": "Retrieved from https://mathlair.allfunandgames.ca/missingdollar.php\nText:\n[Math Lair] The Missing Dollar\n\nMath Lair Home > Puzzles & Problems > The Missing Dollar\n\nThree men decide to spend a night in a hotel room. They pay $30 for the room (assume that this took place a long time ago, when hotel rooms might have actually cost $30). They split the cost evenly amongst themselves, with each man paying $10. As they are about to leave, the manager of the hotel, realizing that the three men are frequent patrons of the hotel, decides to give the men $5 back. He gives $5 to the bellhop and asks him to give the money to the three men. The bellhop, not wanting to split $5 among the three men, decides to pocket $2 of the money and gives each of the three guests $1. Each of the guests has now paid $9 for the room, for a total of $27, and the bellhop has $2, for a total of $29. Where is the missing dollar?\n\nMany people find this problem rather frustrating. The key to it is to look at it in a different way. The three men each paid $30. Out of that, $25 is in the hotel's cash register, $2 is in the bellhop's pocket, and each of the three men have $1, for a total of $30. Looking at it this way, there is no missing dollar. So why is there a dollar missing in the analysis above?\n\nThe problem contains a trick. Each of the guests paid $9, for a total of $27. That $27 includes the $2 in the bellhop's pocket. You can't add that $2 to the $27 and expect to get a meaningful result, but that's what the problem does. The sum in the problem is a red herring that doesn't correspond to any real-life amount."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/58000/maximum-cost-path-in-integer-matrix\nText:\nIn preparation for my design and algorithms exam, I encountered the following problem.\n\nGiven a $2 \\times N$ integer matrix $(a[i][j] \\in [-1000, 1000])$ and an unsigned integer $k$, find the maximum cost path from the top left corner $(a[1][1])$ and the bottom right corner $a[2][N]$, given the following:\n\n$\\bullet$ The path may not go through the same element more than once\n\n$\\bullet$ You can move from one cell to the other vertically or horizontally\n\n$\\bullet$ The path may not contain more than $k$ consecutive elements from the same line\n\n$\\bullet$ The cost of the path is determined by the sum of all the values stored within the cells it passes through\n\nI've been thinking of a simple greedy approach that seems to work for the test cases I've tried, but I'm not sure if it's always optimal. Namely, while traversing the matrix, I select a the maximum cost cell on the vertical or horizontal and then go from there. I've got a counter I only increment if the current cell is on the same line with the previously examined one and reset it otherwise. If at some point the selected element happens to be one that makes the counter go over the given value of $k$, I simply go with the other option that's left.\n\nHowever, I feel that I'm missing out on something terribly important here, but I just can't see what. Is there some known algorithm or approach that may be used here?\n\nAlso, the problem asks for an optimal solution (regarding temporal complexity).\n\n\nThis problem was basically made for dynamic programming (DP). Just review it and follow a couple of examples and solving this problem is straight-forward.\n\nYour simple greedy approach does not always work. Consider:\n\n[ begin ] [  2 ]\n[ 3 ]     [ 10 ]\n[ 1 ]     [ -1000 ]\n[ 1 ]     [ end ]\n\nThe optimal solution would be to go right, down, left, down, down, right.\n\n  \u2022 $\\begingroup$ I meant $2$ lines and $N$ columns, but I guess it doesn't make a difference in this case. $\\endgroup$ \u2013\u00a0user43389 May 29 '16 at 23:28\n\nWe shall approach this using dynamic programming -- the greedy algorithm is 'myopic' in that it only considers immediate neighbors and not the path that follows those neighbors.\n\nLet $C(i, \\ j, \\ m)$ be the cost of the max-cost path starting from $a[i][j]$ going towards $a[2][n]$, where $i$ is either $1$ or $2$, $\\ j \\in [1, n]$ and $m \\in [0, k]$.\n\n  \u2022 $m$ here denotes that we have $m$ remaining consecutive steps that could be taken along row $i$.\n  \u2022 The additional constraint we enforce here is that when we are calculating $a[1][i]$, we have not yet visited $a[2][i]$, and similarly when we're calculating $a[2][i]$, we have not yet visited $a[1][i]$.\n\nWith this constraint in place, what recurrence can we come up with? Well,\n\n  1. $C(1, \\ j, \\ m) = a[1][j] + \\max \\{ M(1, j+1, m-1), \\ a[2][j] + M(2, j+1, k)\\} \\ $ and similarly,\n  2. $C(2, \\ j, \\ m) = a[2][j] + \\max \\{ M(2, j+1, m-1), \\ a[1][j] + M(1, j+1, k)\\} \\ $\n\nNow, what's the rationale here? If we started at $a[1][j]$, we have two choices:\n\n  \u2022 continue along row $1$ : we then go to $a[1][j+1]$ with $m-1$ remaining consecutive steps that we can take along row $1$. (note here that $a[2][j+1]$ is not yet visited, maintaining the invariant).\n\n  \u2022 switch to row $2$ : we go to $a[2][j]$, incurring a cost of $a[2][j]$, and then have only one choice from there - to go to $a[1][j+1]$. Because we have switched rows, we can now refresh our count and take $k$ consecutive steps along row $2$. (note again that we haven't visited $a[1][j+1]$ yet).\n\nNow if we calculate our subproblems starting from $j = n$ towards $j=1$ for every value of $m$, you shall have your answer in $C(1, \\ 1, \\ k)$.\n\nI shall leave the base cases and runtime analysis to you. Note that my solution calculates the cost of the path and not the path itself; can you extend my solution to calculate the path too?\n\n\nYour Answer"}
{"text": "Retrieved from https://skeptics.stackexchange.com/questions/28634/was-the-mileage-of-the-apollo-spaceships-7-inches-to-the-gallon-for-their-moon-f/28635\nText:\nBuzz Aldrin facebook post\n\nAccording to this Facebook post apparently by Buzz Aldrin, \"[Apollo]'s mileage to the moon was 7 inches to the gallon.\"\n\nIf the moon is 250,000 miles away, that seems to come out to 2.2 * 10^9 gallons of fuel (And that's just in one direction!)\n\nIs there some sense in which this statement is accurate?\n\n  \u2022 4\n    Our cars seem to get much better mileage than the Saturn V! However, they are not moving straight up in the sky. In terms of travelling to the Moon, they all get 0 miles per gallon. \u2013\u00a0Ralph Dratman Aug 3 '15 at 4:57\n  \u2022 2\n    This whole topic seems oddly worded because of how the fuel is actually burned versus what it seems to do from the question. Rocket 'mileage' per gallon doesn't really make sense if you want to say the moon is 250,000 miles away since the engines are not running for most of the flight. It is a fall to the moon. Not a burn all the way to the moon. \u2013\u00a0user27407 Aug 3 '15 at 5:27\n\nYes, that's pretty close in at least one sense, though not for the entire trip.\n\nAs noted here\n\nThe Saturn V rocket\u2019s first stage carries 203,400 gallons (770,000 liters) of kerosene fuel and 318,000 gallons (1.2 million liters) of liquid oxygen needed for combustion. At liftoff, the stage\u2019s five F-1 rocket engines ignite and produce 7.5 million pounds of thrust.\n\nAt an altitude of 42 miles (67 kilometers), the F-1 engines shut down.\n\nThe \"mileage\" of the first stage can be calculated from that information as 42 miles/203,400 gallons of kerosene, which works out to 0.000206 miles/gallon, or 13 inches per gallon of kerosene. If both the kerosene and oxygen are included, the answer is 42/(203,400 + 318,000) = 0.00008 miles/gallon, or 5.1 inches per gallon.\n\nBuzz's value of 7 inches per gallon is accurate during the first stage portion of the flight.\n\nConversely, if you factor in the entire trip, their fuel economy (counting oxidizer) is pretty close to 1 mile per gallon. 947,529 gallons and about 953,700 miles (828,743 nautical miles)\n\n  \u2022 12\n    Conversely, if you factor in the entire trip, their fuel economy (counting oxidizer) is pretty close to 1 gallon per mile. 947,529 gallons and about 953,700 miles (828,743 nautical miles). \u2013\u00a0Compro01 Aug 1 '15 at 11:10\n  \u2022 12\n    The above comment should be part of the answer, otherwise it can be misleading. Spacecraft travel by burning a lot of fuel in the first few minutes of the flight and using very little fuel on the remaining portion of the trip. \u2013\u00a0vsz Aug 1 '15 at 12:01\n  \u2022 4\n    Making such calculations for the whole trip is somewhat arbitrary. Viewed from a \"fixed\" point on the rotating Earth surface, resting on or orbiting around the Moon looks like travelling 2 times pi times 380000 km per day. \u2013\u00a0Hagen von Eitzen Aug 1 '15 at 13:05\n  \u2022 11\n    Keep in minde that once you reach escape velocity and are in space, then the expectation is to do infinite miles per gallon (because there's no friction and you are effectively orbiting the sun). \u2013\u00a0Sklivvz Aug 1 '15 at 14:45\n  \u2022 5\n    An altitude of 42 miles does not mean the rocket has traveled only that far. Typically the spacecraft would be 60 to 110 miles downrange at that point, for a total traveled distance in the neighborhood of 120 miles. \u2013\u00a0Brock Adams Aug 3 '15 at 3:20\n\nYou must log in to answer this question.\n\nNot the answer you're looking for? Browse other questions tagged ."}
{"text": "Retrieved from https://www.physicsforums.com/threads/entropy-change-of-a-hot-falling-object.521552/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEntropy change of a hot, falling object\n\n  1. Aug 14, 2011 #1\n\n    A shipyard worker drops a hot steel rivet (mass 125g, temperature 350 degrees C)\n    into a river at temperature 5 degrees C, a distance 30m below. Stating any assumptions\n    you make, calculate the entropy change of the universe as a result of this event.\n    (specific heat capacity of steel ~0.4 J g-1 K-1).\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n\n\n\n\n    If anybody could tell me if I'm on the right lines at all or what the heck to do with the fact that the rivet's being dropped from 30m I'd greatly appreciate it. Thanks!\n    Last edited: Aug 14, 2011\n  2. jcsd\n  3. Aug 14, 2011 #2\n\n\n    User Avatar\n    Homework Helper\n\n    You have traced the change in entropy of the rivet, but I believe there are two more things you need to look at in the \"universe\" (essentially the rivet-Earth system). How much heat has been added to the river by the change in gravitational potential energy in the rivet-Earth system? Also, the river absorbs the heat of the rivet with virtually no temperature change (it's large enough to serve as a \"heat reservoir\"), so what is the change in the entropy of the river from that?\n\n    So there is the entropy change of the cooling rivet plus the entropy change from the change in mechanical energy plus the entropy change from the heat transfer from rivet to river.\n  4. Aug 14, 2011 #3\n    Thanks for the reply.\n\n    So, as I see it, so far I've worked out the decrease in the entropy of the rivet.\n\n    The heat flowing into the reservoir from the rivet cooling will be the same as the heat loss from the rivet:\n\n\n    That gives me 17250 J.\n\n    Then, if we assume the temperature of the reservoir doesn't change, then, using the temperature of the river in Kelvins for T:\n\n\n    That gives me an increase of entropy in the river as 62.1 JK-1\n\n    Finally, the change in gravitational potential energy is:\n\n\n    If we assume that this is all converted to heat in the river we can work out a second component for the increase in entropy. I get S = 0.13 JK-1.\n\n    Overall this gives me a net increase in the entropy of the universe as S = 21.93 JK-1.\n\n    Is this the right track or have I completely messed up?\n  5. Aug 14, 2011 #4\n\n\n    User Avatar\n    Homework Helper\n\n    I agree with those results to the first decimal place (since I rounded off only at the end), so we get a net increase in entropy for the \"universe\" of 21.9 J/K .\n\n    It is a reasonable safe assumption that just about all of the potential energy change is transferred into heating the river. The \"splash\" at impact displaces water and ejects some of it upward (briefly), as well as producing (a minute amount of) acoustical energy. But since practically all the water falls back into the river, that mechanical energy winds up heating the river after all. (We can extend \"the universe\" to include the air over the river, but the tiny amounts of water scattered as microdroplets and vapor and of sound energy probably contribute additions to entropy scarcely worth pursuing...)\n\nSimilar Discussions: Entropy change of a hot, falling object\n  1. Entropy change (Replies: 1)\n\n  2. Change of entropy (Replies: 0)\n\n  3. Change in entropy (Replies: 2)\n\n  4. Entropy changes (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-to-begin-oscillation-in-steady-state.42282/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHow to begin oscillation in steady state?\n\n  1. Sep 8, 2004 #1\n    I need to find the initial conditions such than an underdamped harmonic oscillator will immediately begin steady-state motion under the time dependent force F = m f cos\u03c9t.\n\n    For the underdamped case:\n    [tex]x(t) = ae^{-\\gamma t}cos(\\Omega t+\\alpha)+\\frac{f}{r}cos(\\omega t-\\theta)[/tex]\n\n    and if it matter, [tex]r^2 = (\\omega^2_0-\\omega^2)^2+4\\gamma^2\\omega^2[/tex]\n    and [tex]\\theta = Tan^{-1}\\frac{2\\gamma\\omega}{\\omega^2_0-\\omega^2}\n\n    I thought I would just have to find x0 and v0 such that the transient was 0, but that doesn't seem to be leading down the right track. What direction should my solution be heading?\n    Last edited: Sep 8, 2004\n  2. jcsd\n  3. Sep 8, 2004 #2\n    Why not just let x0=0 and v0=0? This should zero out the transient portion of the solution and leave the driving force intact.\n  4. Sep 8, 2004 #3\n    Makes sense to me, but the back of the book doesn't seem to agree. It has [tex]x_0=\\frac{f (\\omega^2_0-\\omega^2)}{r^2}[/tex] and [tex]v_0=\\frac{2\\gamma\\omega^2f}{r^2}[/tex].\n  5. Sep 8, 2004 #4\n    oh. take x(0) and x'(0) and let a = 0. If a = 0 then the transient solution is immediate null, but you'll see x0 and v0 are not. You'll have to subtitute for theta as well.\n  6. Sep 9, 2004 #5\n\n\n    User Avatar\n    Homework Helper\n\n    It was a good start. Let [tex]a=0[/tex]. Find x(0) and v(0). You have\n    [tex]x(0)=\\frac{f}{r}cos(\\theta ) \\mbox{ and }v(0)=\\frac{f\\omega}{r}\\sin(\\theta ) [/tex], use that\n    [tex] cos(\\theta ) = \\frac{1}{\\sqrt{1+tan^2(\\theta )}}\\mbox{, }sin(\\theta )=\\frac{tan(\\theta )}{\\sqrt{1+tan^2(\\theta )}} \\mbox{ and } tan(tan^{-1}(\\theta))=\\theta [/tex].\n\n\nSimilar Discussions: How to begin oscillation in steady state?\n  1. Steady-state current (Replies: 11)"}
{"text": "Retrieved from https://math.stackexchange.com/questions/812503/periodicity-of-a-triginometric-function\nText:\nI have a trigonometric function and I'm interested to know whether or not it has a period. At this stage I'm fairly certain that it is not periodic. However, I don't know how to prove it. Can anyone help?\n\nThis is the function:\n\n$$g(x) = \\sin(2 \\pi (x-a) \\times b \\times \\cos(2 \\pi (x - a) \\times c)) + d$$\n\n\n\nSubstitute $\\xi=2\\pi(x-a)$ and set $d=0$ w.l.o.g, then your period $T$ should satisfy\n\n$$\\sin[(\\xi+T)b\\cos((\\xi+t)c)]=\\sin[\\xi b \\cos(\\xi c)]$$ i.e. for $bc\\neq 0$ the arguments must differ by an integer multiple of $2\\pi$ for all $x$:\n\n$$(\\xi+T)b\\cos(\\xi x+Tc)=\\xi b \\cos(\\xi c) + 2\\pi k(x)$$\n\nwith some function $k(x)\\in\\mathbb{Z}$. As this function has to be smooth and is restricted to $\\mathbb{Z}$, it must be constant and you get\n\n$$\\xi \\cos(\\xi c + Tc)+T\\cos(\\xi c +Tc)=\\xi\\cos(\\xi c)+2\\pi k,\\qquad \\forall \\xi.$$\n\nThis is obviously not possible for $T\\neq 0$.\n\nEdit: Of course as mentioned, the specific case $bc=0$ has to be excluded.\n\n  \u2022 $\\begingroup$ :) ${}{}{}{}{}{}{}{}$ $\\endgroup$ \u2013\u00a0MPW May 28 '14 at 13:40\n  \u2022 $\\begingroup$ Thanks! My maths skills are questionable to say the least, but I have two questions: 1) is it not true that if the period is $T$, then $g(x) = g(x + T) \\forall x$? And, if so, I'm wondering if the substitution is correct? 2) should $\\forall \\xi$ be $\\forall k$? $\\endgroup$ \u2013\u00a0SnagaDuath May 28 '14 at 20:08\n  \u2022 $\\begingroup$ @SnagaDuath (improved comment) (1) This point I did a bit fast. If the function is invariant under replacing $x\\mapsto x+T_x$ with some period $T_x\\neq 0$ it is also invariant under replacing $\\xi\\mapsto \\xi+T_\\xi$ with some period $T_x\\neq 0$. You have $T_\\xi=2\\pi T_x$ In my answer i discussed $T_\\xi$. (2) No it is $\\forall \\xi$ meaning for all function arguments like the $\\forall x$ in your comment. $\\endgroup$ \u2013\u00a0flonk May 29 '14 at 18:02\n\nIn some cases the function is periodic. Specifically, if $c=0$ and $b\\neq 0$, the function has period $\\frac1b$.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1261179/number-of-solutions-of-equations-mod-pn\nText:\nUsing Hensel's lemma, it is easy to prove that if $p$ is a prime with $p\\equiv 1\\mod 3$ then the equation $x^2-x+1=0$ has at least two solutions $\\mod p^n$ for all $n\\geq 1$. Are there more than two solutions?. Of course, the anwer is not when $n=1$ but what happens if $n\\gt 1$?. I have many more equations to analyze so it would be interesting to find an answer for more general equations.\n\nThanks in advance.\n\n\nIt is convenient to note that $x$ is a solution of $x^2-x+1\\equiv 0\\pmod{p^n}$ if and only if $x\\equiv -t\\pmod{p^n}$, where $t$ is a solution of $t^2+t+1\\equiv 0\\pmod{p^n}$.\n\nSince $p$ is an odd prime, there is a primitive root $g$ modulo $p^n$. To show that there are exactly $2$ solutions of $t^2+t+1\\equiv 0\\pmod{p^n}$, it is enough to show that the congruence $t^3-1\\equiv 0\\pmod{p^n}$ has exactly $3$ solutions. We look for solutions of the shape $g^k$.\n\nWe have that $g^k$ is a solution of the congruence $t^3-1\\equiv 0\\pmod{p^n}$ if and only if $g^{3k}\\equiv 1\\pmod{p^n}$.\n\nNote that $\\varphi(p^n)=(p-1)p^{n-1}$. Let $p=1+3m$. If we put $k=mp^{n-1}$, then $g^{3k}\\equiv 1\\pmod{p^n}$. And in general, $g^{3k}\\equiv 1\\pmod{p^n}$ if and only if $\\varphi(p^n)$ divides $3k$. For $0\\le k\\lt \\varphi(p^n)$, this happens if and only if $k=0$, $m$, or $2m$.\n\n  \u2022 $\\begingroup$ @Diego: Thanks for the edit! $\\endgroup$ \u2013\u00a0Andr\u00e9 Nicolas May 1 '15 at 23:29\n  \u2022 $\\begingroup$ question: why did you prefer $t^3-1$ over $t^2+t+1=(t+\\frac{1}{2})^2+\\frac{3}{4}$ and the three solutions must be counted with multiplicity for $p=3$ the solution $t=1$ is a double root $\\endgroup$ \u2013\u00a0Elaqqad May 2 '15 at 1:19\n  \u2022 $\\begingroup$ The problem is about primes of the form $3k+1$. As to $t^3-1$, it looks nicer than $(t+1/2)^2+3/4$, and a basic chapter in elementary number theory has to do with order. Also, the same idea would work with longer sums. But it is true that $(2t+1)^2+3$ would work nicely, and then it comes down to $x^2\\equiv a\\pmod{p^n}$. $\\endgroup$ \u2013\u00a0Andr\u00e9 Nicolas May 2 '15 at 1:42\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1931497/copula-pde-hv-frac-partial-pu-v-partial-v-c-hu-frac-partial-pu\nText:\nI wish to solve the following PDE:\n\n\\begin{equation} H(v) \\frac{\\partial P(u,v)}{\\partial v} = c H(u) \\frac{\\partial P(u,v)}{\\partial u} \\end{equation}\n\nwhere $c$ is some constant in $(- \\infty, 0)$ and $P(u, v)$ is defined on $[0, 1]^2$, satisfying the boundary conditions:\n\n\\begin{align} P(0, v) &= 0 \\\\ P(u, 0) &= 0 \\\\ P(u, 1) &= u \\\\ P(1, v) &= v \\end{align}\n\nI have already ruled out the following solutions:\n\n  1. $P(u, v) = A(u) B(v)$. This admits a solution to the PDE but fails to satisfy the boundary constraints.\n\n  2. $P(u, v) = A(B(u, v))$ where $B$ is symmetric, i.e., $B(u, v) = B(v, u)$.\n\n\nIf $F$ is the cumulative distribution function of some random variable $X$ and $H$ is defined by\n\n\\begin{equation} H(x) = F^{-1}(x) f(F^{-1}(x)) \\end{equation}\n\nwhere $f$ is the density of $X$ (i.e. $\\frac{dF(x)}{dx}$ if it exists) and $F^{-1}$ is the inverse function of the cumulative distribution function $F$, then the provided PDE is satisfied by the copulas of bivariate random variables where both marginals are distributed according to $F$ and the correlation between the two is zero.\n\n  \u2022 $\\begingroup$ Use \\partial for the partial derivative notation $\\partial$. Also, is this not just a linear, first order PDE which can be solved using the method of characteristics? You may not be able to find the characteristics explicitly unless you know the form of $H$, but I think you can solve this. $\\endgroup$ \u2013\u00a0mattos Sep 18 '16 at 13:55\n  \u2022 $\\begingroup$ Thanks for the edit and pointing out characteristics. Can't believe I forgot about those; I'll give it a try and report back. $\\endgroup$ \u2013\u00a0R.G. Sep 18 '16 at 14:09\n  \u2022 $\\begingroup$ @Mattos It seems that for given functions $H$ characteristics seem to admit solutions (at least in very easy cases). Thanks again for the heads-up! $\\endgroup$ \u2013\u00a0R.G. Sep 19 '16 at 12:36\n  \u2022 $\\begingroup$ All good mate, hope it helps. $\\endgroup$ \u2013\u00a0mattos Sep 19 '16 at 14:04\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://robotics.stackexchange.com/questions/19509/ik-3dof-iterative\nText:\nI want to solve for a 3dof planar arm using gradient descent to approximate end position. Now I am a little confused about the formula and was wondering if someone can help me out.\n\nThis is my thought process:\n\n  1. First start about using the forward kinematic solution mapping angles to euclidean space:\n\n    $x = l_1 * cos\\theta_1 + l_2 * \\cos(\\theta_1 + \\theta_2) + l_3 * \\cos(\\theta_1 + \\theta_2 + \\theta_3)$\n\n    $y = l_1 * sin\\theta_1 + l_2 * \\sin(\\theta_1 + \\theta_2) + l_3 * \\sin(\\theta_1 + \\theta_2 + \\theta_3)$\n\n    $\\phi = (\\theta_1 + \\theta_2 + \\theta_3)$\n\n  2. Now to I need to define a cost function ( that is where I get a little stuck), I know from a 2dof example, that I need to minimize the distance from the endpoint of my arm $x_{ep} $ to the target in euclidean space $x_{tg}$. defined as: $|| x_{ep} - x_{tg}||^2$ using gradient descent. Now, for a 3dof arm, obviously I would have an unlimited amount of solutions with this solution, so that I need to add one additional constraint, namely the angle $\\phi$ for my endeffector too. Here I am not quite sure on how to add the angle to the cost function as a parameter.\n\n  3. Then I would find the gradient function $\\nabla f_{cost} $ for each $\\theta$, in respect to my cost function, specified above using partial derivatives. $\\frac{\\partial f_{cost}}{\\partial \\theta_{1}}(|| \\begin{bmatrix} x_{ep} \\\\ y_{ep} \\\\ \\phi_{ep} \\end{bmatrix} - \\begin{bmatrix} x_{tg} \\\\ y_{tg} \\\\ \\phi_{tg} \\end{bmatrix}||^2)$, $\\frac{\\partial f_{cost}}{\\partial \\theta_{2}} ...$ , $\\frac{\\partial f_{cost}}{\\partial \\theta_{3}} ...$\n\nThen we simply try to iteratively minimize the cost function until we are below a tolerance $tol$.\n\nI know there is a missing piece, but I am not quite sure where, I believe it lies the cost function. Maybe I am wrong, thank you for your suggestions!\n\n\nIt can be demonstrated that the Gradient Descent (GD) policy corresponds to the use of the classical Jacobian transposed method for solving IK problems in robotics.\n\nThis strategy does not suffer from singularities but turns out to be slow and can get stuck in particular circumstances. More importantly, GD does not offer a principled way to deal with multiple prioritized objectives as you are looking for, instead.\n\nTo this end, you ought to make use of the Jacobian pseudoinverse $\\mathbf{J}^+$ that allows you to exploit kinematic redundancies to implement a hierarchy of tasks to be attained.\n\nIn particular, this policy can be represented by the following relation:\n\n$$ \\mathbf{\\dot{q}} = \\mathbf{J}^+ \\cdot \\left( \\mathbf{x}_\\text{tg} - \\mathbf{x}_\\text{ep} \\right) + \\left( \\mathbf{I} - \\mathbf{J}^+\\mathbf{J} \\right) \\cdot \\mathbf{\\dot{q}_0}, $$\n\n\n  \u2022 $\\mathbf{\\dot{q}}$ is the direction where to convergence iteratively (or, equivalently, the velocity that you would send to the joints).\n  \u2022 $\\left( \\mathbf{x}_{tg} - \\mathbf{x}_{ep} \\right)$ is the primary task that encodes the reaching in position.\n  \u2022 $\\mathbf{J}^+=\\mathbf{J}^T\\left(\\mathbf{J}\\mathbf{J}^T\\right)^{-1}$ is the pseudoinverse of the Jacobian of the primary task $\\mathbf{J}=\\frac{\\partial \\left( \\mathbf{x}_\\text{tg} - \\mathbf{x}_\\text{ep} \\right)}{\\partial \\mathbf{\\theta}}$ (as $\\mathbf{J}$ is not square).\n  \u2022 $\\mathbf{\\dot{q}_0}$ is the Jacobian of the secondary task \u2212 not yet specified \u2212 that encodes the reaching in orientation.\n  \u2022 $\\left( \\mathbf{I} - \\mathbf{J}^+\\mathbf{J} \\right)$ is the Null Space projection ensuring that the secondary task won't interfere with the primary task. In essence, the algorithm will provide directions that will drive the system toward both the objectives, if possible; otherwise, the primary task will take over the secondary task. Therefore, the primary task acts as a constraint in a typical optimization setting.\n\nIn our context, the simplest secondary objective $q_0$ could be:\n\n$$ q_0 = \\left( \\phi_\\text{tg} - \\phi \\right)^2. $$\n\nHence, it stems that:\n\n$$ \\mathbf{\\dot{q}_0} = \\frac{\\partial q_0}{\\partial \\mathbf{\\theta}}. $$\n\nRemarkably, $\\mathbf{J}^+$ is prone to singularities, thus it can be replaced by the Damped Least-Squares version $\\mathbf{J}_\\text{DLS}^+$ that makes the policy work very similarly to a Jacobian transposed in the neighborhood of singularities:\n\n$$ \\mathbf{J}_\\text{DLS}^+ = \\mathbf{J}^T\\left(\\mathbf{J}\\mathbf{J}^T + \\mu^2\\mathbf{I}\\right)^{-1}, $$\n\nwhere $\\mu$ is a damping factor that can be chosen as a function of the smallest singular value of $\\mathbf{J}$.\n\nInterestingly enough, we challenge students with the same exact problem during our school on robot programming \ud83d\ude09\n\n\n\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/32785/finding-a-maximum-diameter-tree-in-an-undirected-unweighted-graph\nText:\nThe diameter of a graph is the largest of all shortest-path distances in it. How can we find a tree of maximum diameter within an undirected unweighted graph?\n\nNote that the tree does not have to be a spanning tree.\n\n  \u2022 $\\begingroup$ It makes no difference whether the tree is spanning or not. If there is a tree of diameter $d$, there is a spanning tree of diameter $d$ or greater so the question \"Is there a tree of diameter $d$?\" has the same complexity as \"Is there a spanning tree of diameter $d$?\" $\\endgroup$ \u2013\u00a0David Richerby Nov 6 '14 at 12:46\n\nThis (probably) can't be done efficiently since a maximum-diameter spanning tree could be a Hamiltonian path.\n\nMore specifically, an $n$-vertex graph has a tree of diameter $n-1$ as a subgraph if, and only if, it has a Hamiltonian path (the tree is the Hamiltonian path). Therefore, the problem of finding a maximum-diameter subtree is NP-hard, since you can reduce Hamiltonian path to it by finding the maximum-diameter subtree and checking whether or not it's a path of length $n-1$.\n\n  \u2022 $\\begingroup$ The problem includes the Hamiltonian path problem, and therefore is NP complete. $\\endgroup$ \u2013\u00a0Bangye Nov 6 '14 at 12:40\n  \u2022 2\n    $\\begingroup$ @Bangye Careful. $\\Sigma^*$ includes Hamiltonian path, too. $\\endgroup$ \u2013\u00a0Raphael Nov 6 '14 at 12:58\n\nYour Answer"}
{"text": "Retrieved from https://www2.stockton.edu/sciences-math/faculty-staff/faculty-lind.html\nText:\nCraig Lind\n\nAssistant Professor of Biology\n\n\n\n\nUSC2 - 308\n\n\n\n\n\n\nPh.D. Biology, University of Arkansas\nPostdoctoral Training, Stetson University\nM.S. Biology, California Polytechnic State University\nB.S. Animal Science, University of Illinois\n\n\n\n\nPhysiological Ecology, Endocrinology, Reproduction, Herpetology\n\n\n\n\nMy research is broadly targeted at understanding the role of the endocrine system in coordinating the vertebrate response to environmental change. The endocrine system plays a key role in translating environmental cues into physiological and behavioral responses that impact fitness. My research examines both sides of this equation by quantifying how the environment impacts the endocrine system and how the endocrine system affects physiology and behavior. By elucidating the endocrine mechanisms that link environment and trait expression, my research endeavors to provide a better understanding of the capacity of individuals to respond to threats such as climate change and emerging disease and, in doing so, contributes basic foundational knowledge critical to informed and effective conservation strategies. My laboratory at Stockton is continuing to pursue this goal by examining the physiological response to an emerging fungal pathogen in snakes and describing the hormonal coordination of reproductive physiology and social behavior in reptiles. I also believe that detailed documentation of the natural and life history of populations is vital to conservation, and I continue to pursue work describing the general ecology and natural history of reptiles and amphibians.\n\n\n\n*indicates undergraduate author\n\nGibbs, M., *Watson, P., *Johnson-Sapp, K., Lind, C.M. Reproduction revisited \u2013 A decade of changes in the reproductive strategies of an invasive catfish, Pterygoplichthys disjunctivus (Weber, 1991), in Volusia Blue Spring, Florida. Aquatic Invasions. In Press.\n\nLind, C.M., *Birky, N.K., *Porth, A.M., Farrell, T.M. 2017. Vasotocin receptor blockade disrupts maternal care of offspring in a viviparous snake, Sistrurus miliarius. Biology Open. Doi 10.1242/bio.022616\n\n*McCoy, C.M., Lind, C.M. and Farrell, T.M. 2017. Environmental and physiological correlates of clinical signs of snake fungal disease in a population of pigmy rattlesnakes, Sistrurus miliarius. Conservation Physiology. 5. Doi 10.1093/conphys/cow077.\n\nLind, C.M., Flack, B., Beaupre, S.J., and D.D. Rhoads. 2016. The reproductive ecology of Female Timber Rattlesnakes, Crotalus horridus, in Northwest Arkansas. Copeia. 2016, 518-528.\n\n*Sparks, A.M., Lind, C.M., Taylor E.N. 2016. Diet of the northern Pacific Rattlesnake (Crotalus o. oreganus) in California. Herpetological Review. 46(2), 1-7.\n\nLind, C. M., and Beaupre, S. J. 2015. Male snakes allocate time and energy according to individual energetic status: Body condition, steroid hormones, and reproductive behavior in timber rattlesnakes, Crotalus horridus. Physiological and Biochemical Zoology, 88, 624-633.\n\nLind, C.M., and S.J. Beaupre. 2014. Natural variation in steroid hormone profiles of timber rattlesnakes in Northwest Arkansas. General and Comparative Endocrinology, 206, 72-79.\n\n*Putman, B. J., Lind, C. M., E. N. Taylor. 2013. Does Size Matter? Factors influencing the spatial ecology of Northern Pacific Rattlesnakes (Crotalus oreganus oreganus) in Central California. Copeia, 2013, 485-492.\n\nLind, C. M., J.F. Husak, C. Eikenaar, I. T. Moore, E. N. Taylor. 2010. The relationship between plasma steroid hormone concentrations and the reproductive cycle of the Northern Pacific Rattlesnake, Crotalus oreganus. General and Comparative Endocrinology 166, 590-599."}
{"text": "Retrieved from https://mathoverflow.net/questions/265386/can-there-be-underdetermined-linear-systems-whose-set-of-minimal-support-solutio\nText:\nLet $A \\in \\mathbb{F}^{m \\times n},$ $m<n,$ and let $b \\in \\mathbb{F}^{m \\times n}$ be such that the system $Ax=b$ is consistent. Does it follow that the set $X$ of minimal support solutions of this system $$ X:= \\arg \\min\\limits_{x:Ax=b, x \\in \\mathbb{F}^n}\\{\\|x\\|_0\\}$$ is such that $|X| < \\infty?$\n\nI thought of this question randomly today while thinking about improvements I can make to my dissertation. Oddly, even though I have been studying compressive sensing for almost a year now, I have never thought about this question, nor do I recall seeing any results in the literature or in Foucart and Rauhut's text.\n\nIt seems almost immediate intuitively that the answer to this question is ``yes'' given that the problem involves vector spaces that are not infinite.\n\nThe linear algebraic interpretation, and my attempt at an actual proof, is that all minimal support solutions to, say, the consistent system $Ax=b$ where $A \\in \\mathbb{R}^{3 \\times n}, b \\in \\mathbb{R}^3,$ $3 < n,$ are represented by taking any triplet of $n\\choose{3}$ columns and row reducing the system to turn these columns into identity columns -the order of appearance of the identity columns in the modified system won't matter, and if the columns are dependent, at least one variable is free; the minimal support solution will set any coefficients of $x$ matching the indices of any free variables, and all the other $n-3$ elements of $x,$ to zero. Therefore $|X| \\leq $ $n \\choose 3$ $<\\infty$.\n\nThis spells out the geometric intuition that drove me to my quick answer; a line, plane, or the whole space $\\mathbb{R}^3$ (which can be representative of $x$ if $\\|x\\|_0 \\leq 3$) must cross a unique point with lowest weight somewhere (corresponding to setting free variables to zero after reduction of my system to exchange my three column choices with identity columns).\n\nI did not use any properties unique to real fields, nor did I use the particular row rank of $3,$ having merely assumed that $3<n,$ so it seems like I can rewrite the above argument for a comprehensive proof.\n\nI am still uneasy with this line of thinking for some reason. I feel like there is either a much more elegant, simple, and direct formal proof, or else a glaringly obvious counterexample (perhaps over $\\mathbb{C}$) that disproves this conjecture.\n\nI apologize ahead of time if this question is too trivial for this forum, but I felt this belonged here rather than on Mathematics SE, as compressive sensing seems to be at the research level in general.\n\n\nIf the minimal $\\|x\\|_0$ for a solution is $k$, any solution with $\\|x\\|_0 = k$ has support one of the ${n \\choose k}$ subsets of $n$ with cardinality $k$. The $m \\times k$ submatrix $A_S$ of $A$ consisting of these columns has the property that $A_S x = b$ has a solution with all entries nonzero, but no solution with any entries $0$. That implies that the solution of $A_S x = b$ is unique (if there were two different solutions $y$ and $z$, they would differ on some coordinate, and then we could take a solution $y + t (z-y)$ for some $t \\in \\mathbb F$ to make that coordinate $0$). So we conclude that there are at most ${n \\choose k}$ minimal support solutions.\n\n  \u2022 $\\begingroup$ Nice insight, Robert. Your last line really hit it home for me. Thank you! $\\endgroup$ \u2013\u00a0Thomas Rasberry Mar 23 '17 at 20:41\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/14239/functional-derivative-of-convolution\nText:\nTake the 2-minute tour \u00d7\n\nHow to carry out the following functional derivative?\n\n$$\\frac{\\delta F}{\\delta n(r)}$$ where $$F=\\int dr n(r) \\int C(|r-r'|) n(r') dr'$$\n\nis it simply: $$2 \\int dr' C(|r-r'|) n(r')$$?\n\nshare|improve this question\nThe answer to the question (v1) is Yes. \u2013\u00a0 Qmechanic Sep 1 '11 at 18:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nNotice that $F$ is essentially a quadratic form; i.e. if it were matrices then you would have (in summation notation): $$F = x_i C_{ij} x_j.$$ Then you would use the fact that $\\frac{\\partial x_i}{\\partial x_j} = \\delta_{ij}$ to get \\begin{align} \\frac{\\partial F}{\\partial x_k} &= \\delta_{ik} A_{ij} x_{j} + x_i A_{ij} \\delta_{jk} \\ &= 2 A_ik x_k \\end{align} if $A_{ij} = A_{ij}$ i.e. it is symmetric.\n\nHere, we use a similar fact: $$\\frac{\\delta n(x)}{\\delta n(y)} = \\delta(x-y)$$ where $\\delta$ this time is the Dirac distribution. Your \"matrix\" in the middle is obviously symmetric, so your proposed answer is correct.\n\nshare|improve this answer\nThanks, that makes sense. Cheers Biosftw \u2013\u00a0 Biosftw Sep 1 '11 at 18:37\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/171807/positive-primes-represented-by-indefinite-binary-quadratic-form?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nNeil Sloane asked me about commands in computer languages to find the (positive) primes represented by indefinite binary quadratic forms. So I wrote something in C++ that works. This is for the OEIS, these primes go into sequences... Note that, within a few hours, another guy had run the tables much higher with a one-line Maple command. Some days it does not pay to get up.\n\nI thought of one I really do not understand. Discriminant $205$ has four classes of forms, $$ \\langle 1, 13, -9 \\rangle, \\; \\langle -1, 13, 9 \\rangle, \\; \\langle 3, 13, -3 \\rangle, \\; \\langle -3, 13, 3 \\rangle. $$\n\nThe third and fourth are opposites so in the same genus, although distinct. The first two are in the principal genus, but they are not opposites, one is $-1$ times the other; in particular, they get diffeent positive primes, although both do residues $\\pmod 5$ and $\\pmod {41}.$ For $\\langle 1, 13, -9 \\rangle$ we get $$ 1,5,59,131,139,241,269,271,359,409, \\ldots, $$ while for $\\langle -1, 13, 9 \\rangle$ we get $$ 31,41,61,251,349,379,389,401,419,431, \\ldots. $$\n\nFor positive forms, low class number, there are polynomials, such as in Cox's book, such that primes represented by the principal form are those for which the polynomial factors a certain way. For a prime $p \\equiv 1 \\pmod 3,$ Gauss showed that $2$ is a cubic residue if an only if $p = u^2 + 27 v^2.$ Jacobi showed that $3$ is a cubic residue if an only if $p = u^2 + uv + 61 v^2.$ All I found in Henri Cohen's tables was the fact that $\\mathbb Q(\\sqrt {205})$ has class number $2$ and $L_K = \\mathbb Q(\\sqrt 5),$ appendix 12C on pages 533 and 534. See related information at IT'S A LINK.\n\nLet's see, $34$ is the smallest number where it is a surprise that there is no solution to $x^2 - 34 y^2 = -1.$ The smallest such odd number is $205,$ as there is no solution to $x^2 - 205 y^2 = -1.$ For prime $p \\equiv 1 \\pmod 4,$ there is always a solution to $x^2 - p y^2 = -1.$ Proof in Mordell's book. Anyway, this is why $\\langle 1, 13, -9 \\rangle, \\; \\langle -1, 13, 9 \\rangle$ are distinct classes.\n\nSo, that is the question, can I distinguish the represented (positive) primes by factoring some polynomial mod these primes?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 13 down vote accepted\n\nClass field theory promises such a polynomial (more properly, such a number field $H$, since a polynomial generating $H$ might have to err on the first few primes, though in our case it turns out there's a polynomial with no exceptional primes). The proof is effective, though the recipe is often hard to carry out. So I attempted an end run by asking this database for number fields of degree $8$ and discriminant $205^4$, and was rewarded with $$ x^8 + 15 x^6 + 48 x^4 + 15 x^2 + 1, $$ which generates an unramified normal extension $H \\, / \\, {\\bf Q}(\\sqrt{205})$ with the right Galois group. This polynomial matches your list exactly: the gp code\n\n   f = factormod(x^8+15*x^6+48*x^4+15*x^2+1, p)[,1];\n\nreturns your 5, 59, 131, 139, 241, 269, 271, 359, 409, and then continues 541, 569, 599, 661, 701, 761, 859, 881, 911, 941, still in exact agreement with the list of primes represented by $u^2 + 13uv - 9v^2$.\n\n[added later] That gp code checks whether all factors of $P_8(x) := x^8 + 15 x^6 + 48 x^4 + 15 x^2 + 1 \\bmod p$ have degree $1$. Since the polynomial is Galois, it would have been sufficient to check that one factor is linear:\n\n   if(poldegree(factormod(x^8+15*x^6+48*x^4+15*x^2+1, p)[1,1])==1, print(p))\n\n(I \"cheated\" a tad by excluding $p=2$, which is a factor of the discriminant of $P_8$ but not of the number field.) The Galois group of $P_8$ is dihedral, so one can find a quartic polynomial $P_4$ with the same Galois closure that factors completely mod $p$ iff $P_8$ does; such a polynomial was exhibited by NAME_IN_CAPS answering the follow-up Question 171846. Alternatively, we know already that $p$ is (either $5$ or) a quadratic residue of both $5$ and $41$, so by Quadratic Reciprocity $5$ and $41$ have square roots mod $p$, which means that $p$ factors completely in ${\\bf Q}(\\sqrt{5},\\sqrt{41})$. And indeed $x^2$ generates that field and equals (some conjugate of) $$ -\\frac14 (15 + 3 \\sqrt{5} + \\sqrt{41} + \\sqrt{205}); $$ so you can also test whether $p$ is represented by $u^2 + 13uv - 9v^2$ by computing $\\sqrt{5} \\bmod p$ and $\\sqrt{41} \\bmod p$ (if they don't exist then there's no representation), and then testing whether $-(15 + 3 \\sqrt{5} + \\sqrt{41} + \\sqrt{205})$ is a square mod $p$.\n\nshare|improve this answer\nFor the very similar discriminant 221 and $x^2 + 13 x y - 13 y^2, $ I was surprised to find that $$ f(x) = x^8 + x^6 - 4 x^5 - 38 x^4 - 2 x^3 + 123 x^2 -34 x + 17, $$ has a repeated root $\\pmod {101},$ although still linear factors, seven of them with one of them squared. Is that allowed? After that it is always 8 roots. This time the primes are $ 17,101,103,127,179,251,263,373,433,$ \u2013\u00a0 Will Jagy Jun 15 at 20:47\nFor 221, the quartic $$ x^4 + x^3 + x^2 + 2 x + 4 $$ behaves well \u2013\u00a0 Will Jagy Jun 15 at 20:57\nThe repeated root mod $101$ is an example of my warning that \"a polynomial generating [the Hilbert class field] $H$ might have to err on the first few primes\" if $H$ has no generator $x$ such that ${\\bf Z}[x]$ is the full ring of integers of $H$. A better choice for this purpose is $x^8 + 34 x^6 + 83 x^4 + 34 x^2 + 1$, which has spurious repeated roots only mod $2$ and $3$ (and as it happens no linear factors modulo either of these primes). Then $x+1/x$ generates a quartic isomorphic with the one you found with coefficients $1,1,1,2,4$. \u2013\u00a0 Noam D. Elkies Jun 15 at 22:14\nCool. Thanks, Noam. That does look much better. I found my degree eight on that website you mentioned, by putting in $221^4.$ Actually, the first time it thought i meant 2214 and complained. i decided it was better to multiply out the number. \u2013\u00a0 Will Jagy Jun 15 at 22:17\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/20622/how-to-compute-drag-coefficient-given-initial-position-initial-velocity-and-fin\nText:\nTake the 2-minute tour \u00d7\n\nThe equations I'm using are:\n\nx = x + (DT * vx)\nvx = vx * C\n\nMy DT is always 0.01 and the coefficient C (related to a linear drag coefficient, as mentioned in the comments) is greater than 0 and less than 1. The above will keep happening until x naturally reaches its limit.\n\nWhat I want is an equation to find C given the other three inputs: initial x, initial velocity x and final resting x(this is where the object has come to a stop and vx = 0). Right now it's tedious because I have to plug in ix, ivx and C and run my simulation to see where the object stops. Then I have to do further tweaking to get exactly what I'm looking for.\n\nHere are some samples:\n\ninitial x = 3.5\nvelocity x = -12.0\nacceleration = 0.92\nfinal resting x = 2.0\n\ninitial x = 3.5\nvelocity x = -14.0\nacceleration = 0.92\nfinal resting x = 1.75\n\nFor example(from the first dataset), we start at 3.5 we want to end at 2.0 and our velocity is -12.0 .. what do we need to use for C?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nBasically what you're doing is calculating a discrete time series: you're finding an discrete series of positions $x_n$ (where $n\\in\\mathbb{Z}_+$) which are paired with times $t_n = t_0 + n\\Delta t$. But there are a couple of ways you could interpret this time series, and the formula you're looking for depends on which one you use.\n\nExact positions\n\nOne option is to say that $x_n$ represents the exact position of the particle at time $t_n$. In order to find the asymptotic position as $n\\to\\infty$ (that is, the position where the particle stops), you need to convert your iterative formulas,\n\n$$\\begin{align}x_n &= x_{n-1} + v_{n-1}\\Delta t \\\\ v_n &= Cv_{n-1}\\end{align}$$\n\ninto direct formulas. Hopefully you can see that, because the speed gets multiplied by $C$ at every step, the speed at the $n$'th step will be given by\n\n$$v_n = C^n v_0$$\n\nThen figuring out the formula for $x_n$ is probably most easily done by finding a pattern:\n\n$$\\begin{align}x_1 &= x_0 + v_0\\Delta t \\\\ x_2 &= x_1 + v_1\\Delta t \\\\ &= x_0 + v_0\\Delta t + Cv_0\\Delta t \\\\ x_3 &= x_2 + v_2\\Delta t \\\\ &= x_0 + v_0\\Delta t + Cv_0\\Delta t + C^2v_0\\Delta t\\end{align}$$\n\nYou wind up with\n\n$$x_n = x_0 + v_0\\Delta t \\sum_{k=0}^{n}C^k$$\n\nIn the limit as $n\\to\\infty$, this simplifies to\n\n$$x_\\infty = x_0 + \\frac{v_0\\Delta t}{1-C}$$\n\nwhich you can solve for $C$. This equation reproduces the sample results you listed.\n\nIt's important to note that the value of $C$ you get from this interpretation depends on your choice of $\\Delta t$. To simulate the same motion using a different time step, you'll need to change the value of $C$. Only the ratio $\\frac{\\Delta t}{1-C}$ is fixed.\n\nDiscrete approximation\n\nThe other way in which one could interpret your time series is as a discrete approximation to some continuous function $x(t)$ that describes the actual motion. If you find it strange that the result depends on the time step $\\Delta t$, this might be worth looking into.\n\nTo motivate this interpretation, you need to know something about finite difference approximations. In a nutshell, when you want to use a computer to numerically solve a differential equation, you can replace the derivative operator with a finite difference operator:\n\n$$\\frac{\\mathrm{d}f}{\\mathrm{d}t} \\to \\frac{f(t + \\Delta t) - f(t)}{\\Delta t}$$\n\nThe thing on the right here is merely the simplest example of a finite difference operator. (It also happens to be quite inaccurate.) This particular one looks a lot like the definition of the derivative, except that $\\Delta t$ is finite, not infinitesimal (hence the name).\n\nYour iteration equations can be written in the form\n\n$$\\begin{align}\\frac{x_n - x_{n-1}}{\\Delta t} &= v_{n-1} \\\\ \\frac{v_n - v_{n-1}}{\\Delta t} &= \\frac{C - 1}{\\Delta t}v_n\\end{align}$$\n\nYou can assume that this is the finite difference approximation to some exact differential equation, and work backwards to find the equation. For example, by replacing the finite difference operator in the position equation with a derivative, you get\n\n$$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = v(t)$$\n\nIf you try to do the same thing with the velocity, well, you can't, because the right side doesn't have a defined limit as $\\Delta t\\to 0$. But there are a couple of little hacks you can use, for example: choose some characteristic time scale $\\tau$ and set $\\Delta t = \\tau$ on the right, while still taking the limit on the left. You wind up with\n\n$$\\frac{\\mathrm{d}v}{\\mathrm{d}t} = \\frac{C - 1}{\\tau}v(t)$$\n\nSolving this differential equation gives you\n\n$$\\begin{align}v(t) &= v(0)e^{-t(1-C)/\\tau} \\\\ x(t) &= x(0) + \\frac{v(0)\\tau}{1-C} \\bigl(1 - e^{-t(1-C)/\\tau}\\bigr)\\end{align}$$\n\nand in the limit as $t\\to\\infty$,\n\n$$x(\\infty) = x(0) + \\frac{v(0)\\tau}{1-C}$$\n\nwhich, again, you can solve for $C$. It turns out to be the same thing as before, only with $\\tau$ instead of $\\Delta t$. This is only the case because this is an exceptionally simple equation, and because of the particular way in which I chose to define the time scale $\\tau$. In general, these two methods won't give identical results, in part because of the inaccuracies of the particular finite difference approximation I used.\n\nshare|improve this answer\nThank you. Is it possible to implement this type of motion without it being dependent on the DT? \u2013\u00a0 Ryan Feb 7 '12 at 6:49\nNo, there's no way to avoid introducing a time scale of some sort if the particle is going to come to rest. \u2013\u00a0 David Z Feb 7 '12 at 7:21\nadd comment\n\nIntegrate with respect to the time. One problem is that if you change DT, you will get a different result, since acceleration does not change with DT, although it should.\n\nYour formulas written as functions:\n\n$$ x(t) = x_0 + \\int_0^t v(t) \\cdot \\mathrm dt $$\n\n$$ v(t) = v_0 \\cdot a^t $$\n\nCombining those yields:\n\n$$ x(t) = x_0 + \\int_0^t v_0 \\cdot a^t \\cdot \\mathrm dt $$ $$ x(t) = x_0 + v_0 \\int_0^t e^{\\log(a)t} \\cdot \\mathrm dt $$ $$ x(t) = x_0 + v_0 \\left[ \\frac{1}{\\log(a)} e^{\\log(a)t} \\right]_0^t $$ $$ x(t) = x_0 + v_0 \\frac{1}{\\log(a)} (a^t - 1)$$\n\n$\\log(a)$ is negative, so for $t \\to \\infty$ you should get:\n\n$$ \\lim_{t \\to \\infty} x(t) = x_{\\mathrm{final}} = x_0 + v_0 \\frac{1}{\\log(a)} (0 - 1)$$ $$ x_{\\mathrm{final}} = x_0 - v_0 \\frac{1}{\\log(a)}$$\n\nThe greater your $a$ is, the less far the particle will have made it. Sounds reasonable.\n\nIf you have a $\\mathrm dt = 0.01$ seconds, you will have a factor of $a^{100}$ per second. So for your $a = 0.92$ I would instead use $a^{100} = 0.000239212$ as $a$.\n\nWhen I put this into my formula, I get:\n\n$$ x_{\\mathrm{final}} = 3.5 - (-12.0) \\frac{1}{\\log(0.000239212)} = 2.0608 $$\n\n$$ x_{\\mathrm{final}} = 3.5 - (-14.0) \\frac{1}{\\log(0.000239212)} = 1.82097 $$\n\nI am not sure whether the formula is wrong or whether your program just makes rounding errors (as usual with numeric calculations).\n\nshare|improve this answer\nThank you for the detailed derivation, but I realize I only need a coefficient of friction. See my comment to my original question up top. \u2013\u00a0 Ryan Feb 6 '12 at 23:54\nThere were some edits made to the question, in case you'd like to update your answer to reflect them. \u2013\u00a0 David Z Feb 7 '12 at 3:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/214353/trouble-with-this-integral\nText:\nTake the 2-minute tour \u00d7\n\nCould anyone help me to do this integral ?\n\n$$\\int_{\\,0}^\\infty \\; \\frac{\\exp \\left( -\\frac{1}{x} -x\\right)}{\\sqrt{x}} \\, dx = \\sqrt{\\pi}e^{-2} $$\n\nI think you start with completing the square in the exponent, but what substitution do you make then ? $u=\\sqrt{x}$ didn't seem to get me far.\n\nshare|improve this question\nAre you familiar with Error Functions? \u2013\u00a0 Inquest Oct 15 '12 at 18:17\nDoes $\\displaystyle \\frac{1}{\\sqrt x}= \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{\\infty} e^{-xt^2} dt$ help? Anyway, (+1) for the question. \u2013\u00a0 Chris's sis Oct 15 '12 at 18:18\n@JoeKing: This is a special case of the integral dealt with here. This is the case $n = t = 1/\\sqrt{\\pi}$. \u2013\u00a0 user26872 Oct 15 '12 at 20:17\nadd comment\n\n1 Answer\n\nup vote 10 down vote accepted\n\nSubstitute first $x=u^2$ in order to have:\n\n$$ I = \\int_{0}^{+\\infty}\\frac{dx}{\\sqrt{x}\\exp\\left(x+\\frac{1}{x}\\right)}=2\\int_{0}^{+\\infty}e^{-\\left(x^2+\\frac{1}{x^2}\\right)}\\,dx$$\n\nUse now the substitution $x=\\frac{1}{y}$ to have:\n\n$$ I = 2\\int_{0}^{+\\infty}\\frac{1}{x^2}e^{-\\left(x^2+\\frac{1}{x^2}\\right)}\\,dx,$$\n\nfrom which follows:\n\n$$ I = \\int_{0}^{+\\infty}\\left(1+\\frac{1}{x^2}\\right)e^{-\\left(x^2+\\frac{1}{x^2}\\right)}\\,dx,$$\n\nand the key substitution is now $u = x-\\frac{1}{x}$, from which we have:\n\n$$ I = \\int_{-\\infty}^{+\\infty}e^{-u^2-2}\\,du = e^{-2}\\sqrt{\\pi}, $$\n\n\nshare|improve this answer\nNice and simple (+1). \u2013\u00a0 Chris's sis Oct 15 '12 at 18:30\nWow. I would never have worked that out. Was it obvious to you ? \u2013\u00a0 Joe King Oct 15 '12 at 18:45\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/244850/are-there-infinitely-many-pairs-of-rational-numbers-such-that?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nAre there infinitely many pairs of rational numbers $(a,b)$ such that $a^3+1$ is not a square in $\\mathbf{Q}$, $b^3+2$ is not a square in $\\mathbf{Q}$ and $b^3+2 = x^2(a^3+1)$ for some $x$ in $\\mathbf{Q}$?\n\nThis question can be phrased also as follows:\n\nAre there infinitely many rational numbers $(a,b)$ such that the extensions $\\mathbf{Q}(\\sqrt{a^3+1})$ and $\\mathbf{Q}(\\sqrt{b^3+2})$ are quadratic and equal?\n\nshare|improve this question\nWhat motivated this question? It seems like this should have some relation to elliptic curves. \u2013\u00a0 Thom Tyrrell Nov 26 '12 at 22:35\nadd comment\n\n1 Answer\n\nup vote 8 down vote accepted\n\nYes. Consider the two elliptic curves: $$7r^2 = a^3+1$$ and $$7s^2 = b^3+2.$$\n\nOne can check (using SAGE or MAGMA) that these two curves have infinitely many rational points (in fact they both have rank 1).\n\nFor rational points $(a,r)$ and $(b,s)$ on these curves we have that $a$ and $b$ satisfy the requirements of your question.\n\nshare|improve this answer\nI chose 7 because this was the smallest square-free positive integer for which both curves have positive rank. If you don't care that $a$ and $b$ vary, you could take $b=0$ and look at the curve $2r^2=a^3+1$, which has infinitely many rational points. \u2013\u00a0 Zach Nov 27 '12 at 18:38\nQuestion: Do I understand correctly that we always have $\\mathbf{Q}(\\sqrt{a^3+1}) =\\mathbf{Q}(\\sqrt{7}) = \\mathbf{Q}(\\sqrt{b^3+2})$ if $(a,r)$ and $(b,s)$ lie on the curve? \u2013\u00a0 Harry Nov 27 '12 at 20:49\nI like this answer a lot. It prompts the following question: Are there infinitely many square-free integers $n$ such that $nr^2=a^3+1$ has positive rank and $ns^2=b^3+2$ has positive rank? \u2013\u00a0 Harry Nov 27 '12 at 21:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/1283/permutationsrange12-produces-an-error-instead-of-a-list/1362\nText:\nTake the 2-minute tour \u00d7\n\nThis input:\n\n\nResults in this (error) output:\n\n  The result of evaluating Permutations[{1,2,3,4,5,6,7,8,9,10,11,12}] \n  would be a packed array with 5748019200 elements, but the number of elements \n  in a packed array must be a machine integer. >>\n\nThat number (5748019200) is interesting, because it's exactly 12 times 12! (that's factorial, not exclamation point)\n\nPresumably, Mathematica is trying to store all 12! length 12 lists in a single monolithic array. I can imagine this failing.\n\nUsually, Mathematica shields me from these types of problems. For example, I had no trouble calculating 12*12!.\n\nMy intention is to Select some elements from this list, so I don't need to have every permutation in memory at once.\n\nQuestion: Is there a different way to generate the permutations that avoids this problem?\n\nshare|improve this question\nRun the same code on a 64-bit machine ;-) Seriously though, it is possible to iterate over permutations but I'm not sure if the algorithm is implemented directly in Mathematica. \u2013\u00a0 David Z Feb 4 '12 at 3:28\n@David It doesn't work on a 64-bit machine either. Harold: Apparently the maximum size of a packed array is 2^31-1. This is a huge array: a 2^31 - 1-element packed array of machine integers (i.e. assuming the most efficient storage possible) would take up 8 GB of contiguous memory. You need to have a lot of memory in your computer to be able to store such an array (definitely much more than 8 GB because of the contiguous memory block requirement) \u2013\u00a0 Szabolcs Feb 4 '12 at 20:13\nadd comment\n\n3 Answers\n\nup vote 7 down vote accepted\n\nCombinatorica` has the function NextPermutation which allows you to iterate over the permutations. There may be ways of generating a smaller subset if you have more information about what you are looking for.\n\nshare|improve this answer\nOn that note: the algorithms in Combinatorica are based on old FORTRAN routines discussed in this book; OP might want to take a look at the book and see what other strategies might be appropriate for his circumstances. \u2013\u00a0 \uff2a. \uff2d. Feb 4 '12 at 3:48\n@J.M., that book looks to be a tremendous resource. I'm glad I asked this question now. \u2013\u00a0 Harold Feb 4 '12 at 4:52\n@Harold note, the functionality in Combinatorica` is being slowly folded into the kernel functions. So, loading it will give a warning message to that effect, but NextPermutation doesn't (yet?) seem to have been moved over. \u2013\u00a0 rcollyer Feb 4 '12 at 4:55\n@J.M. Thanks a lot for the link to that book. Looks excellent \u2013\u00a0 TomD Feb 4 '12 at 9:34\nadd comment\n\nConsider than the permutations of {1, 2, 3, 4, 5} are each of the permutations of {1, 2, 3, 4} with 5 inserted at each possible place. One can therefore examine the permutations of {1, 2, 3, 4, 5} in blocks like this:\n\np4 = Permutations@Range@4;\n\n  ReplaceList[x, {h___, t___} :> {h, 5, t}],\n  {x, p4}\n\nFor example, making a certain selection:\n\n    # + #2 - #3*#4/#5 > 7 & @@ # &\n  {x, p4}\n\nThe same can be applied to the permutations of Range@12.\n\nshare|improve this answer\nadd comment\n\nWell from computational point of view, if you wanted the whole list or some part of it then the size of output would be the main problem.\n\nAssuming plaintext output is used ... by my rough estimation it would take over 225 GB (gigabytes) to store the whole list on a disk. Furthermore it would take about 4 days to compute them all on this laptop.\n\nYou need data like:\n\nfilename = \"f://out.txt\";\nseed = Range[12];\nsize = 10;\n\nRecursive method call like:\n\nseed = MPermutations[seed, size, filename]\n\nOther useful lines:\n\n\nThis is an example of what MPermutations could look like if flat file output is used. It computes next count number of permutations of list, prints them in filename and returns the last element.\n\nMPermutations[list_, count_Integer, filename_String] := Module[\n  {n = 1, current = list},\n   n < count, current = NextPermutation[current];\n   Write[filename, current]];\n\nReturn result is needed to make recursive method call possible. Recomputing that line will add next size amount of results to file (assuming that data is in a different cell).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/248966/2-connected-planar-graph-and-vertex-degree\nText:\nTake the 2-minute tour \u00d7\n\nIf $G$ is a 2-connected loopless planar graph, and for each vertex $v$ we define: $f(v) = (1/2) - (1/deg(v))$, where $deg(v)$ is the degree of vertex $v$,\n\nShow that for some region $R: \\sum f(v) < 1 $, where the sum is over all vertices $v$ incident with $R$.\n\nI'm confused about how to go about this. Some properties that could be relevant are:\n\n  \u2022 for 2-connected planar graphs, every region is bounded by a cycle\n  \u2022 $12 \\leq \\sum [6 - deg(v)]$ so $\\sum deg(v) \\leq 6|V(G)| - 12$\n  \u2022 $\\sum deg(v) = 2 |E(G)| $\n  \u2022 every region is clearly bounded by at least 3 edges and thus has at least 3 vertices incident to it\n  \u2022 for 2-connected graphs, every vertex has $deg(v) \\geq 2$\n\n    Anyone have ideas?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nLet us denote the sum for a region as $$F(R) = \\sum_{v\\in R}f(v)$$ Consider the sum of $F$ over all regions of the graph. There are $\\deg v$ faces incident with each vertex so each $f(v)$ is counted precisely $\\deg v$ times. $$\\sum_{R\\in G}F(R) = \\sum_{v\\in G} f(v)\\deg v=\\sum_{v\\in G}\\left(\\frac{\\deg v}{2}-1\\right)$$ From the handshaking lemma, this is equal to $$\\sum_{R\\in G}F(R)=|E| - |V|$$ From Euler's formula $$|E|-|V| = |R|-2$$ where $|R|$ is the number of regions. Therefore the average of $F$ over the regions $$\\overline{F(R)} = \\frac{|R|-2}{|R|}<1$$ is less than $1$. Therefore there must exist at least one region for which $F(R)$ itself is less than $1$.\n\nshare|improve this answer\nthank you! the trick here was to see that there are deg(v) faces incident with each vertex. I'm assuming thats because the graph is 2-connected? \u2013\u00a0 DustinH Dec 2 '12 at 15:53\nYes, it's necessary for the graph to be 2-connected. You may want to prove that fact just to be complete. \u2013\u00a0 EuYu Dec 2 '12 at 18:48\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/4800/choosing-solutions-for-the-intersections-of-n-number-of-circles\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I have an number of distances from an unknown location to a known location. I can use these distances and the known locations to draw a number of circles. The point where all the circles intersect is my unknown location. This is easy to solve. However, if my distance measurements have some error, I will get a cluster of points around my unknown location. The question is, for each pair of intersection points, how can I tell which solution is closer to my unknown point?\n\nEvery solution I have come up with involves many special cases, such as when all the known locations are inside one circle, or all the known locations are co-linear, and so on, buy I am hoping to come up with a more elegant solution.\n\n\nLets make this more simple. I have 2 circles that have at most 2 intersection points. If they don't intersect, I can easily choose the point between them. If they do intersect at 2 points, how can I use a third circle to choose which one of these 2 intersections is the correct one?\n\nMy current plan is to do a comparison between the distance between the radius of the third circle and the intersection points and choose the smaller one. The problem with this is that I don't know how much error this approach can tolerate before you choose the wrong side. If I knew that, I could put a goal on my measurement method to try to reduce the error by X%\n\nshare|improve this question\nThe Wikipedia page for GPS suggests that such a system can be solved using a generalization of Newton's method. \u2013\u00a0 Isaac Sep 16 '10 at 18:27\nadd comment\n\n1 Answer\n\nOne handles error with a probability model. In this case, the typical error in a distance measurement is likely proportional to the distance itself. The errors themselves are often thought of as accumulated small nearly independent errors, allowing one to invoke the Central Limit Theorem and suppose, at least as a reasonable hypothesis, that the errors are normally distributed. We usually assume there's no systematic bias in the errors: they should average out to zero in principle. A simple model is obtained by supposing the errors are independent. (Other suppositions can be treated, depending on how the measurements were made, but it quickly gets complicated.)\n\nThis leaves us with just three unknowns to estimate: the true coordinates $(x,y)$ of your location and the precision of the relative errors, usually expressed as their (common) standard deviation $\\sigma$. Your data consist of $n$ measured distances to the known locations $(x_i, y_i)$, say $d_i, i = 1 \\ldots n$. Mathematically, these assumptions translate to the following. The probability of observing $d_i$ equals\n\n$$\\frac{1}{\\sqrt{2 \\pi} \\sigma \\delta_i} \\exp \\left( -\\frac{(d_i - \\delta_i)^2}{2 \\sigma^2 \\delta_i^2)} \\right)$$\n\nwhere $\\delta_i = \\delta_i(x,y) = \\sqrt{(x - x_i)^2 + (y - y_i)^2}$.\n\nThe probability of your data $(d_1, d_2, \\ldots, d_n)$ is the product of these probabilities. This is the likelihood.\n\nOne reasonably tractable estimator maximizes the likelihood (as a function of the unknown parameters $x$, $y$, and $\\sigma$). This is usually done by maximizing the negative logarithm of the likelihood, which will be a sum of terms, one for each data value. It's nonlinear and a little nasty, but we know geometrically that there will be at least one global optimum and, quite likely, exactly one. Many methods exist to solve this, available in statistical packages, numerical optimization routines, and general-purpose math software like Mathematica.\n\nOf course the optimal arguments $(x,y)$ tell you where your location likely is. The optimal value of $\\sigma$ estimates the typical relative error in the distance measurement: you can check that it's a reasonable value. There are ways to extract confidence intervals for all three parameters (from the Hessian of the log likelihood). A joint confidence interval for $(x,y)$ gives you an ellipse in which the true point is likely to be. Statistical packages will give you this information. If you are doing this by hand, you can analyze any other candidate solution $(x',y')$, such as the intersection of a few circles, by evaluating the likelihood there and comparing it to the optimum likelihood. If the logarithms differ by less than $2$, the candidate solution is consistent with the data.\n\nBTW, as you've seen, you're practically forced to take a statistical approach. With real data you find that some circles don't even intersect and that overall the set of data has little or no internal consistency. You have to model the error somehow.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/97965/solve-drag-equation-for-previous-timestep?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI am working on a series of equations to calculate the trajectory of a projectile in reverse. For example, given the ground impact angle and velocity, calculate the flight of the projectile. Here is the equation to calculate the drag on a projectile in normal flight (not reversed yet):\n\n$$ x_2=x(1-k\\sqrt{x^2+y^2}) $$ $$ y_2=y(1-k\\sqrt{x^2+y^2}) $$\n\n$x$ and $y$ are the before-drag velocities, and $k$ is a constant that includes the fluid density, reference area, drag coefficient, and timestep. The result, $x_2$ and $y_2$, are the after-drag velocities. On my graphing calculator, including these functions in a program creates a nice-looking trajectory. However, to reverse the formula, I need to solve the above equations for $x$ and $y$. Given the resulting velocity, find the velocity at the previous timestep. I am at a loss on how to do this.\n\nPut simply, solve the above 2 equations for $x$ and $y$.\n\nAny help will be appreciated.\n\nshare|improve this question\nCould you please explain exactly what you're trying to do? Are the $x,y$'s infinitesmal quantities that are evaluated at each time step and then summed up (integrated) to calculate the trajectory? If so, what integration scheme are you using? \u2013\u00a0 yohBS Jan 10 '12 at 20:47\n@yohBS I don't understand exactly what you are saying (I'm in 10th grade). Every timestep, $x_2$ times the timestep is added to the x position of the projectile, and $y_2$ times the timestep is added to the y position. Then, $x$ and $y$ are set equal to $x_2$ and $y_2$ for the next timestep. Hope this helps. \u2013\u00a0 Joel Jan 10 '12 at 21:11\nYou just do what you would do as if time was running forwards, but change the sign of the drag $k$ (is the opposite of drag shove?) and the two \"after-drag velocities\", so the projectile goes up and backwards with extra shove. \u2013\u00a0 Henry Jan 10 '12 at 22:50\n@Henry Changing the sign of $k$ doesn't work. That is applying negative drag to $x_2$ and $y_2$. For the equations to work, the drag must be applied to $x$ and $y$. \u2013\u00a0 Joel Jan 11 '12 at 16:11\nadd comment\n\n1 Answer\n\nIt helps to write down the equation in vector form: $$\\mathbf v_2=(1-k|\\mathbf v|)\\mathbf v\\tag1$$ This shows that $\\mathbf v_2$ is a scalar multiple of $\\mathbf v$ (no surprise there). Take the magnitude on both sides of(1): $$|\\mathbf v_2|=(1-k|\\mathbf v|)|\\mathbf v|\\tag2$$ Here I assume that $1-k|\\mathbf v|\\ge 0$, that is the velocity does not change direction due to drag. This is physically reasonable. Equation (2) is quadratic for $|\\mathbf v|$, with the solution $$|\\mathbf v|=\\frac{1-\\sqrt{1-4k|\\mathbf v_2|}}{2k} \\tag3$$ Thus, to obtain $\\mathbf v$ from $\\mathbf v_2$, we should divide $\\mathbf v_2$ by its magnitude, and the multiply the result by the right side of (3): $$ \\mathbf v =\\frac{1-\\sqrt{1-4k|\\mathbf v_2|}}{2k |\\mathbf v_2|}\\mathbf v_2 $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/120848/differential-equation-with-absolute-value\nText:\nTake the 2-minute tour \u00d7\n\nAfter some algebraic simplification, I got the ODE: $$\\ddot x(t)+\\sqrt {(\\dot x(t)+x(t))^2}+k x(t)=0$$ I interpreted this equation as: $$\\ddot x(t)+|{(\\dot x(t)+x(t))}|+k x(t)=0$$ I have some problem to solve it. Could you give me some hint please? Thanks.\n\nshare|improve this question\nNormally when I have absolute values I split the problem into two cases. \u2013\u00a0 Godisemo Mar 16 '12 at 8:40\nYou may use Godisemo's hint and then it becomes a 2nd ordered linear ODE with constant coefficients. \u2013\u00a0 Tapu Mar 16 '12 at 9:01\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYour equation is equivalent to\n\n$$\\ddot x(t)\\pm\\dot x(t)\\pm x(t)+kx(t)=0$$\n\nso you have to solve the equations\n\n$$\\ddot x(t)+\\dot x(t)+(1+k)x(t)=0 \\qquad \\ddot x(t)-\\dot x(t)-(1-k)x(t)=0.$$\n\nThe solutions of these equations can be obtained by solving the characteristics equations\n\n$$\\lambda^2\\pm\\lambda+(\\pm 1+k)=0$$\n\n\n$$\\lambda_{1,2}=\\frac{\\mp 1\\pm\\sqrt{1-4(\\pm 1+k))}}{2}$$\n\nand depending on the value of $k$ you will get different sets of solutions.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/166294/condition-to-have-unique-solution\nText:\nTake the 2-minute tour \u00d7\n\nConsider $\\Delta u =f(x) , x \\in \\Omega $ and $\\nabla u\\cdot n +\\alpha u = g(x) , x\\in \\partial\\Omega $, where $n$ is outward normal. Can anyone give me a hind how to find sufficient condition on $\\alpha$ so that the solution is unique. Thanks\n\nshare|improve this question\nwhat do you mean by $\\nabla\\cdot n$? Do you mean $\\nabla u\\cdot n$ instead? \u2013\u00a0 Paul Jul 3 '12 at 21:22\n@Paul : thanks for pointing out. \u2013\u00a0 Theorem Jul 3 '12 at 21:24\nFor future reference, you should write the operators as \\Delta and \\nabla instead of \\triangle and \\triangledown. \u2013\u00a0 Rahul Jul 3 '12 at 21:50\n@RahulNarain : thank you , i didn't know that . \u2013\u00a0 Theorem Jul 3 '12 at 21:51\nadd comment\n\n2 Answers\n\nI think the condition is $\\alpha \\geq 1,$ which you need for coercivity of the bilinear form, which in turn can be got by using the fact that$$\\lVert \\nabla u \\rVert_{L^2(\\Omega)}^2 + \\lVert u \\rVert^2_{L^2(\\partial\\Omega)} \\geq C\\lVert u \\rVert_{H^1(\\Omega)}^2$$ for every $u \\in H^1(\\Omega).$\n\nAdded: If you multiply by a test function $v \\in H^1(\\Omega)$ and IBP, you get $$\\int_\\Omega{\\nabla u \\nabla v} - \\int_{\\partial\\Omega}{v\\nabla u \\cdot \\nu} = \\int_\\Omega{-fv}$$ where $\\nu$ is the normal. Plugging in your boundary condition and moving the term involving $g$ on the other side: $$\\int_\\Omega{\\nabla u \\nabla v} + \\alpha\\int_{\\partial\\Omega}{uv} = \\int_{\\partial\\Omega}{gv} - \\int_\\Omega{fv}$$ So your bilinear form $b(u,v)$ (for Lax-Milgram) is the LHS. For coercivity, we need $$b(v,v) \\geq C_1\\lVert v \\rVert^2_{H^1(\\Omega)}$$ for some $C_1$. We have $$b(v,v) = \\lVert \\nabla v \\rVert^2_{L^2(\\Omega)} + \\alpha \\lVert v \\rVert^2_{L^2(\\partial\\Omega)},$$ which implies coercivity if $\\alpha \\geq 1$ because you can use the statement I gave at the top of this post.\n\nshare|improve this answer\nSir , can you tell me how can i get the condition on $\\alpha$ using the fact that u have given ? \u2013\u00a0 Theorem Jul 4 '12 at 3:19\n@Theorem I updated the answer. \u2013\u00a0 Court Jul 4 '12 at 7:16\n@Court I would like to add to Court's solution. A sharper condition is $\\alpha > 0$. Just note that $$ b(v,v) \\ge \\min \\{1, \\alpha \\} (\\| \\nabla v \\|_{L^2 (\\Omega)} + \\| v \\|_{L^2(\\partial \\Omega)} \\ge \\min \\{1, \\alpha \\} C \\| u \\|_{H^1(\\Omega)}$$ \u2013\u00a0 D... Jan 5 at 16:42\nadd comment\n\nI think that this paper can be very useful and essentially contains the answer.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/273000/is-it-possible-to-reverse-this-sequence-of-permutations\nText:\nTake the 2-minute tour \u00d7\n\nLet $ S = (a_1, a_2, ..., a_N) $ be a finite (arbitrarily long) sequence of elements, and let $p_1, p_2, ..., p_n $ be the first $n$ prime numbers, with $n \\ge 3$.\n\nWe apply a sequence of permutations to $S$ as follows.\n\nFirst, we take every element in $S$ whose index is congruent with 1 modulo 2, and we rotate them within themselves $A^2_1$ positions (where $A^2_1$ is an integer in $[0, N/2)$). For instance, if $S = (a,b,c,d,e,f)$, and $A^2_1=2$, the result would be $(\\mathbf c,b,\\mathbf e,d,\\mathbf a,f)$.\n\nIn the second place, we take every element in the sequence obtained whose index is congruent with $0$ (that is, the rest), and rotate them within themselves $A_0^2$ positions (where $A^2_0$ is an integer in $[0,N/2)$); that will be $S_1$. Following the previous example, rotating with $A^2_0 = 1$ would bear $S_1 = (c,\\mathbf f,e,\\mathbf b,a,\\mathbf d)$.\n\nNow, we take every element in $S_1$ with index congruent with 1 modulo 3, and we rotate them within themselves $A^3_1$ positions; afterwards, every element with index congruent with 2 modulo 3, $A^3_2$ positions, and finally, every element with index congruent with 0 modulo 3, $A^3_0$ positions. $A_i^3$ is an integer in $[0,N/3)$. Continuing the example, assuming $A^3_1 = 1, A^3_2 = 0, A^3_0 = 1$, we would obtain $(b,f,d,c,a,e)$.\n\nThis process is repeated for every prime up to $p_n$, and let $S_n$ be the result.\n\n(Edited: see below) My question is: assuming $n$ and $S_n$ are known, how much additional information would be necessary to calculate the coefficients? (Edited: see below) By additional information I mean, for example, knowing the initial positions (in $S$) of some elements in $S_n$. I have been working for days on this, but my current option, which is straightforward using systems of equations, does not seem t otake me anywhere since I don't know which coefficients are being used in each case. Is there any other approach that I should consider?\n\nApologies for my English, and sorry if this is not the correct stackexchange site for this question.\n\nEDIT: As Alexander pointed, coefficients would not be unique (see his example below), so to state it more accurately: would it be possible to obtain the original $S$ given $n, S_n$, and some additional information?\n\nThis problem is related to a cryptography project, where I intend to cypher a message by rearranging it, using coefficients as a key. This means that, even if the original permutation (or any complete set of coefficients) were impossible to find, any way to determine information on them, or bounding them, would greatly hurt the scheme. I know this is not the place for crypto problems, but maybe explaining the objective would be useful to anyone trying to answer.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nIf I understand correctly, we can take $$(a_1,\\ldots,a_{12})$$ and pick primes $2,3$. Then we can set $A_0^2=A_1^2=3$ and $A_0^3=A_1^3=A_2^3=2$ and the permutation produced by the algorithm is the identity permutation, the same as if we had chosen $A_0^2=A_1^2=A_0^3=A_1^3=A_2^3=0$.\n\nSo even if you have $S_n$, $n$, and the initial position of each $a_i$, you can still in general have multiple solutions. I would say there is no way to determine the coefficients $A_i^j$ uniquely.\n\nI realize that you said $n\\geq 3$, but the above example is illustrative. Note that even for $n\\geq 3$ and even if you insist that $N=\\prod_{i=1}^np_i$ (which is the minimum value of $N$, since $N$ must be divisible by each $p_i$) this does not change. When $n=3$ and $N=30$, we can set $A_0^2=A_1^2=3$ and $A_0^3=A_1^3=A_2^3=8$ and $A_0^5=A_1^5=A_2^5=A_3^5=A_4^5=0$ and obtain the identity permutation, as well as $A_0^2=A_1^2=A_0^3=A_1^3=A_2^3=6$ and $A_0^5=A_1^5=A_2^5=A_3^5=A_4^5=0$.\n\nThe permutations are unique for the case where $n=2$ and $N=6$, in which case the possible permutations correspond to the unique subgroup of $S_6$ of order $72$. But this is the only such case.\n\nshare|improve this answer\nThank you, Alexander! Great point on lack of unicity, I hadn't noticed that. Probably, even if the coefficients are forced to be all different, unicity still won't be possible; I'll look into that! On the other hand, my (admittedly unstated... sorry!) intention with this question was to \"undo\" the permutation. I hurried to assume unicity of the coefficients, which I thought would be equivalent with \"undoing\" the transformations, but I am going to edit the question to further clarify. Thank you for your time! :) \u2013\u00a0 Carlos Jan 9 '13 at 12:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/93367/measurable-functions-with-the-same-integral-over-a-set\nText:\nTake the 2-minute tour \u00d7\n\nSuppose $f:\\mathbb R \\to \\mathbb R,g:\\mathbb R \\to \\mathbb R $ are Lebesgue measurable with $\\int_{\\mathbb R}f(x)=\\int_{\\mathbb R}g(x)=1$.\n\nHow to show that for every $r\\in(0,1)$, there is a measurable $E \\subset \\mathbb R$ such that $\\int_{ E}f(x)=\\int_{ E}g(x)=r$?\n\nshare|improve this question\nWhat have you got so far? Also, I gave the question a more descriptive title; feel free to edit if you don't like it. \u2013\u00a0 Nate Eldredge Dec 22 '11 at 4:56\nthanks. I'm trying to construct a $F_\\sigma$ set, but failed. \u2013\u00a0 Leitingok Dec 22 '11 at 5:04\nI don't understand why this should be true. If $f$ and $g$ correspond to two probability densities, say Gaussian and Cauchy respectively, why should the corresponding probability measures put same mass on a set. \u2013\u00a0 Ashok Dec 22 '11 at 5:44\n@Leitingok, why you post the question in that form? If $\\int_\\mathbb{R} f=\\int_\\mathbb{R} g$, then $f=g$ almost everywhere in $\\mathbb{R}$, and then almost everywhere in any subset of $\\mathbb{R}$. If that is true, why this question considers two functions? Can someone explain please? \u2013\u00a0 leo Dec 22 '11 at 15:07\n@leo: This holds if $f \\ge 0$ a.e. It is obviously false otherwise: take for example $f(x) = \\sin x$ with $E = [-\\pi,\\pi]$. There are also various results saying that if $\\int_E f = 0$ for every $E$ in a certain collection of sets, then $f = 0$ a.e. \u2013\u00a0 Nate Eldredge Dec 23 '11 at 3:26\nshow 3 more comments\n\n2 Answers\n\nup vote 8 down vote accepted\n\nFor $r = 1/2$, there is an interval $E$ for which this holds. Several proofs of this fact are given in:\n\nTotik, Vilmos. A tale of two integrals. American Mathematical Monthly 106: 227-240, 1999. MathSciNet | Full text (JSTOR)\n\n(These proofs are given replacing the domain $\\mathbb{R}$ with $[0,1]$, so apply the obvious transformation. Totik also gives a proof that the desired equality holds with $E$ an interval if and only if $r = 1/k$ for some integer $k$.)\n\nSo let $E_1$ be an (open) interval such that $\\int_{E_1} f = \\int_{E_1} g = 1/2$. Then by applying the same result to $f_1 = 2f1_{E_1^c}$, $g_1 = 2 g 1_{E_1^c}$, we can produce $E_2$, disjoint from $E_1$, with $\\int_{E_2} f = \\int_{E_2} g = 1/4$. ($E_2$ may not be an interval, because we have to remove $E_1$ from it, but we can take it to be a finite union of open intervals.) Proceeding, we can produce disjoint sets $E_n$ with $\\int_{E_n} f = \\int_{E_n} g = 2^{-n}$. Now consider the binary expansion of $r$ and take the union of the corresponding $E_n$. The resulting set $E$ is not only measurable but in fact open.\n\nHopefully I didn't overlook any subtle details...\n\nshare|improve this answer\nI don't have the paper. what happens when r=1/2? \u2013\u00a0 Leitingok Dec 22 '11 at 7:20\n@Leitingok, Nate provides links to the Full text paper. Perhaps is better to access at your university. \u2013\u00a0 leo Dec 22 '11 at 14:57\nadd comment\n\nIn the special case $f\\ge 0$, $g\\ge 0$, this follows from a theorem of Lyapunov stating that the range of a vector measure is convex. In the present context this means that the set $R:=\\{(\\int_E f(x)\\,dx,\\int_E g(x)\\,dx): E\\in{\\mathcal L}\\}$ is a convex subset of $[0,1]^2$. (Here ${\\mathcal L}$ denotes the $\\sigma$-algebra of Lebesgue measurable subsets of the real line.) Since $R$ clearly contains $(0,0)$ and $(1,1)$, it contains the segment connecting them. Therefore for each $r\\in(0,1)$ the point $(r,r)$ is an element of $R$, and so there exists $E\\in{\\mathcal L}$ with $\\int_E f=\\int_E g = r$.\n\nshare|improve this answer\nInteresting. Do you have a reference for this theorem? \u2013\u00a0 Nate Eldredge Dec 22 '11 at 19:05\nLyapunov's paper \"Sur les fonctions-vecteurs compl\u00e9tement additives\" is here: [Izvestia Akad. Nauk SSSR, vol. 4 (1940) pp. 465-478]. There is a nice exposition in an article by D. Ross in the American Mathematical Monthly [vol. 112 (2005) pp. 651-653]. \u2013\u00a0 John Dawkins Dec 23 '11 at 0:21\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/84746/bounds-on-sum-k-0m-binomnkxk-and-sum-k-0m-binomnkxk1?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI've read this interesting article by Woersch (1994) dealing with approximation of binomial coefficients (rows of Pascal's triangle). I'm just wondering if similar bounds exist for partial binomial sums such as (for $ m < n $)\n\n$$\\sum_{k=0}^{m} \\binom{n}{k}x^k$$ and $$\\sum_{k=0}^{m} \\binom{n}{k}x^k(1-x)^{n-k}.$$\n\nIf $0<x<1$ the second case can be approximated with the normal distribution using the central limit theorem. If anyone could suggest some general approach to solving problems like these I'd be very grateful.\n\nshare|improve this question\nJust as a note, they're kinda the same problem;$$\\sum_{k=0}^m{n\\choose k}x^k(1-x)^{n-k}=(1-x)^n\\sum_{k=0}^n{n\\choose k}\\left(\\frac{x}{1-x}\\right)^k;$$ $$y=\\frac{x}{1-x}\\iff x=\\frac{y}{1+y}.$$ \u2013\u00a0 anon Nov 22 '11 at 22:48\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nAs pointed out in the comments, if you can solve one problem you can solve the other, so I'm just going to give a bound for the first sum. Also, $x > 0$. (It seems like the case $x<0$ might be trickier.) We have\n\n$\\begin{align} &\\frac{\\binom{n}{m}x^m + \\binom{n}{m-1}x^{m-1} + \\cdots + \\binom{n}{0}x^0}{\\binom{n}{m}x^m} \\\\ &= 1 + \\frac{m}{(n-m+1)x} + \\frac{m(m-1)}{(n-m+1)(n-m+2)x^2} + \\cdots + \\frac{m!}{n^{\\underline{m}}!x^m} \\\\ &\\leq 1 + \\frac{m}{(n-m+1)x} + \\left(\\frac{m}{(n-m+1)x}\\right)^2 + \\cdots + \\left(\\frac{m}{(n-m+1)x}\\right)^m, \\end{align}$\n\nwhich is the partial sum of a geometric series. Therefore,\n\n$$\\sum_{k=0}^m \\binom{n}{k} x^k \\leq \\binom{n}{m} x^m \\frac{1 - r^{m+1}}{1-r},$$ where $$r = \\frac{m}{(n-m+1)x}.$$\n\nOf course, if $r < 1$, then we obtain the simpler expression $$\\sum_{k=0}^m \\binom{n}{k} x^k \\leq \\binom{n}{m} x^{m+1} \\frac{n-m+1}{(n-m+1)x-m}.$$\n\n(To give credit where credit is due, this is an adaption of Michael Lugo's answer to a related question on Math Overflow.)\n\nshare|improve this answer\nI like this answer. \u2013\u00a0 Michael Lugo Dec 2 '11 at 6:05\nthanks, Mike. Is there any way to estimate the size of error? $O(\\frac{1}{m})$ maybe? \u2013\u00a0 user19821 Dec 7 '11 at 1:11\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.mathworks.co.uk/help/optim/ug/minimization-with-gradient-and-hessian.html?nocookie=true\nText:\nDocumentation Center\n\n  \u2022 Trial Software\n  \u2022 Product Updates\n\nMinimization with Gradient and Hessian\n\nThis example involves solving a nonlinear minimization problem with a tridiagonal Hessian matrix H(x) first computed explicitly, and then by providing the Hessian's sparsity structure for the finite-differencing routine.\n\nThe problem is to find x to minimize\n\n\nwhere n = 1000.\n\n\n\ntype brownfgh\n\n\n\nn = 1000;\nxstart = -ones(n,1);\nxstart(2:2:n,1) = 1;\noptions = optimoptions(@fminunc,'GradObj','on','Hessian','on');\n[x,fval,exitflag,output] = fminunc(@brownfgh,xstart,options);\n\nThis 1000 variable problem is solved in about 7 iterations and 7 conjugate gradient iterations with a positive exitflag indicating convergence. The final function value and measure of optimality at the solution x are both close to zero. For fminunc, the first order optimality is the infinity norm of the gradient of the function, which is zero at a local minimum:\n\n\nfval =\n\nexitflag =\n\noutput = \n         iterations: 7\n          funcCount: 8\n       cgiterations: 7\n      firstorderopt: 4.7948e-10\n          algorithm: 'large-scale: trust-region Newton'\n            message: 'Local minimum found.\n\nOptimization completed because the size of the grad...'\n    constrviolation: []\nWas this topic helpful?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/187255/determining-the-value-of-h-that-makes-a-linear-system-consistent/187294\nText:\nTake the 2-minute tour \u00d7\n\nI'm just beginning linear algebra at university and have a teacher who moves very fast and has pre-done slides so i can't actually see the problem worked out, he just talks it out. On top of this, he's also from China and heavily accented, making him hard to understand.\n\nAnyway, i have an augmented matrix, and i want the values of $h$ that make it consistent:\n\n$$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 2 & -8 & 6 \\\\ \\end{array}\\right]$$\n\nand quite frankly, i'm not sure just how to start. I tried eliminating the 1 in the second row, but that made the second line $[0\\;\\;\\; h+4\\;\\; -8]$ and i'm not even sure if that's the right direction or even allowed.\n\nThanks in advance.\n\nshare|improve this question\nIs it clear to you what \"consistent\" means, or even what we mean by an \"augmented matrix\"? \u2013\u00a0 akkkk Aug 26 '12 at 22:13\nI don't see the relevance of the ethnicity of your professor. I would wager he spends time to create those slides so that you read them. \u2013\u00a0 James S. Cook Aug 26 '12 at 23:02\nI don't see the relevance of looking so much into it, I was just stating that I felt behind because he was from another country and heavily accented and I was having a hard time keeping up. The only difference was that I off-handedly mentioned where he was from. \u2013\u00a0 BMEdwards37 Sep 11 '12 at 16:17\nadd comment\n\n3 Answers\n\nA linear system is inconsistent is if it represents a contradiction, for instance the system\n\n$$\\left[\\begin{array}{cc|c} 0 & 0 & -10 \\\\ 3 & -2 & 1 \\\\ \\end{array}\\right]$$\n\nis inconsistent because the first line represents a linear equation $0x+0y=-10$, i.e. $0=-10$, which is a contradiction. Geometrically, when you solve a 2x2 linear system, you are finding the intersection between a pair of lines. If you reach a contradiction, like the system above, then your lines do not intersect, i.e. they must be parallel.\n\nIf you are being asked this question, you have probably already covered Gauss-Jordan ellimination. Inconsistencies in linear systems can be readily identified if the system is brought to reduced row echelon form (can you see why?), so I would start with that. The steps are simple:\n\n$$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 2 & -8 & 6 \\\\ \\end{array}\\right]$$ Multiply the second row by $1/2$: $$\\left[\\begin{array}{cc|c} 1 & h & -5 \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ Subtract the second row from the first: $$\\left[\\begin{array}{cc|c} 0 & h+4 & -8 \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ Without even proceeding further, it is obvious that one way for the system to be inconsistent is if the first line is $0\\, 0\\, |\\, -8$, since this would be equivalent to saying $0x+0y=-8$, that is $0=-8$, a contradiction. The first row would have this form only if $h=-4$, so $h=-4$ makes the system inconsistent.\n\nNow it is pretty clear at this point that no other value of $h$ would make the system inconsistent, and after you are comfortable with Gauss-Jordan elimination this fact would be apparent to you as well, though you should really try to understand why first. So let's say $h\\ne-4$. Then we can multiply the first row by $\\frac 1 {h+4}$: $$\\left[\\begin{array}{cc|c} 0 & 1 & -\\frac 8 {h+4} \\\\ 1 & -4 & 3 \\\\ \\end{array}\\right]$$ And now subtract 4 times the first row from the second: $$\\left[\\begin{array}{cc|c} 0 & 1 & -\\frac 8 {h+4} \\\\ 1 & 0 & 3+\\frac {32} {h+4} \\\\ \\end{array}\\right]$$ To really be precise, you can swap the two rows: $$\\left[\\begin{array}{cc|c} 1 & 0 & 3+\\frac {32} {h+4} \\\\ 0 & 1 & -\\frac 8 {h+4} \\\\ \\end{array}\\right]$$\n\nThus for any value of $h$ other than $-4$, we can solve the system - there is no way to make the system displayed above have a row which looks like $0\\,0\\,|\\,c$, for any non-zero number $c$.\n\nshare|improve this answer\nadd comment\n\nA simpler solution is based on a theorem that any system $Ax = b$ is consistent iff rank of $[A \\mid b]$ equal to rank of $A$.\n\nTo compute rank of $A$ perform elimination on $A$ to get: $ \\pmatrix{1 & 0 \\\\ 0 & -8-2h} $ Hence $\\text{rank}(A)=1$ if $h = -4$ and $\\text{rank}(A) = 2$ otherwise.\n\nTo compute rank of $[A \\mid b]$ perform elimination on $[A \\mid b]$ to get: $$ \\pmatrix{1 & 0 & \\frac{3h-20}{h+4} \\\\ 0 & 1 & \\frac{-8}{h+4}} $$ So for values other that $h=-4$ we have $\\text{rank}([A \\mid b]) = 2$.\n\nComparing two ranks, we have a consistent system other than $h=-4$.\n\nshare|improve this answer\nadd comment\n\nSo it is consistent whenever there is at least one solution. That means that the two lines you have cannot be parallel to each other. Multiply the first row by $2$, and you get $[2, 2h, -10]$. The lines will be parallel for the equations $m_1x+n_1y=a$ and $m_2x+n_2y=b$ if $m_1=m_2$ and $n_1=n_2$. In this case, $m_1=2, m_2=2, n_1=2h, n_2=-8$. Since $m_1 = m_2, n_1 \\neq n_2$, so $2h \\neq -8, h\\neq-4$.\n\nNote that there are an infinite number of solutions (aka consistent) if $m_1=m_2, n_1=n_2,$ and $a=b$. Otherwise, you do not have to worry about the $a$ and $b$ values.\n\nshare|improve this answer\nWow, I was going in the complete wrong direction. I'm probably going to have another question here soon, but let me look at it first now after seeing this and i'll see if it helps, these variables are really throwing me off. Thank you though, and keep an eye out for another question here in about 20 minutes :p \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:28\n@BMEdwards37 Sorry I messed up with the negatives, but i fixed my answer. You can think of an augmented matrix as a system of equations, where the each column represents a different dimension, and the last column represents a constant. I was wrong in using \"x\" and \"y\" as dimensions. Usually, people would use $X_1, X_2, X_3...X_n$ \u2013\u00a0 mathguy Aug 26 '12 at 22:30\n@BMEdwards37 Wait, I want to let you know that you are not going in the wrong direction. You ended up with [0 h+4 -8], which is good! The only way to make sure a system is consistent is that ALL of the values cannot equal 0 (nevermind the last column). In your example, since the first column is 0, then the second column CANNOT be 0, so $h+4\\neq0$. If all of the columns except the last equal 0, then there are no solutions. If all columns including the last equal 0, then there are infinite solutions =) \u2013\u00a0 mathguy Aug 26 '12 at 22:35\nI understood your meaning, didn't catch the negatives either. I'm going to post another question because i'm not even sure what it's asking, i appreciate the help. \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:37\nAhh i see, i wasn't so far off. Thanks. \u2013\u00a0 BMEdwards37 Aug 26 '12 at 22:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/110812/show-a-sigma-algebra-contains-the-borel-sets-with-a-infty-or-infty/110816\nText:\nTake the 2-minute tour \u00d7\n\nFor a certain $\\sigma$-algebra $A$ on the real line, I would like to show that it contains the Borel sets. I can show that $A$ contains the left and right half-line $(a,\\infty)$ and $(-\\infty,b)$ for any real numbers $a$ and $b$. My question is : can I infer that $A$ contains the Borel sets by only prooving that it contains the left half-line or is it mandatory to show that $A$ contains both half-line? I'm not clear on how the Borel sets are generated from half-line and open intervals.\n\nshare|improve this question\nMaybe I'm missing something, but for any $a\\leq b$, $(a,b)=(a,\\infty)\\cap(-\\infty,b)$. So the $\\sigma$-algebra contains the base of open intervals, and contains the $\\sigma$-algebra generated by them, hence the Borel sets. \u2013\u00a0 Vika Feb 19 '12 at 3:54\n@Vika yes, but I think Nicolas was asking if it is enough to start with only one of these -- either right OR left -- half-open intervals; i.e. suppose you have $(a, \\infty)$ in your $\\sigma$-algebra for all $a\\in \\mathbb R$. \u2013\u00a0 William DeMeo Feb 19 '12 at 4:03\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nWhat is the complement of one of these half-lines? Then consider intersections, unions, etc. In other words, yes, if you can show your $\\sigma$-algebra contains $(a, \\infty)$ for any $a$, that is enough... but it sounds like it would be a good exercise for you to prove this. Here are some hints:\n\n  1. What is the complement of $(a, \\infty)$?\n\n  2. For $a< b$, what is the intersection of $(a, \\infty)$ and $(-\\infty, b]$?\n\n  3. Show that a $\\sigma$-algebra containing all half-open intervals $(a, b]$ contains all Borel sets. In fact, this is sometimes taken as the definition -- i.e. the Borel $\\sigma$-algebra is the $\\sigma$-algebra generated by the half-open intervals. So, you are either done, or you need to show that this is equivalent to whatever definition you are using. (Hint: at this point you have all the intervals $(a, b-1/n]$, for $n\\in \\mathbb N$ in your $\\sigma$-algebra.)\n\nshare|improve this answer\nYour trivia is motivating. Here is my attempt. 1. The complement of $(a,\\infty)$ is $(-\\infty,a]$. 2. The intersection of $(a,\\infty)$ and $(-\\infty,b]$ is $(a,b]$. 3. Since $(a,b)=\\cup_{n=0}^{\\infty}(a,b-1/n]$ then the $\\sigma$-algebra $A$ contains all open intervals. Since any open set is the union of a countable collection of open intervals, then $A$ contains all the open sets. Since the Borel $\\sigma$-algebra is the intersection of all such $\\sigma$-algebra, then $A$ contains the Borel $\\sigma$-algebra and hence all Borel sets. Thank you. \u2013\u00a0 Nicolas Essis-Breton Feb 19 '12 at 21:06\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/373251/how-to-show-polynomial-is-irreducible-in-extension-field-of-rationals\nText:\nTake the 2-minute tour \u00d7\n\nHow would one show this? is there any test?\n\nsay $x^3 - 2x - 5$ over $\\mathbb{Q}[\\sqrt{2}]$\n\nThis is just a made-up example, but I'm interested in the general process and how it differs from showing irreducible over $\\mathbb{Q}$.\n\nshare|improve this question\nsince the polynomial degree is 3, it is sufficient to show it has no roots in the field \u2013\u00a0 Federica Maggioni Apr 26 '13 at 7:18\nright... so does that involve simple computation of plugging in a + b*sqrt(2) into the polynomial and showing that that can never equal 0? \u2013\u00a0 tyur43 Apr 26 '13 at 7:19\ni do agree, except for the word \"simple\" \u2013\u00a0 Federica Maggioni Apr 26 '13 at 7:24\nyeah i realized it becomes quite complicated which is why i would like to hear if there are more general/simpler methods. thanks though. \u2013\u00a0 tyur43 Apr 26 '13 at 7:31\nadd comment\n\n1 Answer\n\nIn this case it's easy. Suppose $\\theta$ is a root of $x^3-2x-5$. Observe that $x^3-2x-5$ has no rational roots (say by the rational root test) so is irreducible over $\\mathbb Q$. Thus $\\mathbb Q[\\theta]$ has degree $3$. If $\\theta\\in \\mathbb Q[\\sqrt{2}]$ then we would have $\\mathbb Q[\\theta]\\subseteq \\mathbb Q[\\sqrt2]$, thus $[\\mathbb Q[\\theta]:\\mathbb Q]|[\\mathbb Q[\\sqrt2]:\\mathbb Q]$, i.e. $3|2$, a contradiction.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathhelpforum.com/advanced-statistics/191930-semi-infinite-integers-1-d-random-walk-persistent-transient.html\nText:\nI know that for the infinite 1-D random walk, it is persistent (my professor showed us by showing that \\sum_{n=1}^{\\infty}{P_{jj}(n)} = \\infty, so f_{jj}=1), which makes me think that that the semi-infinite walk is also persistent, but I'm having a hard time showing it. The problem I was given is below, any help would be greatly appreciated. f_{ij} below is the probability of the first return (or visit) to state j starting in state i\n\nA random walk is defined on the integers {0,1,2,3,...} with the following\ntransition probabilities:\np_{00}=1/2 , p_{01}=1/2\np_{n,n+1}=1/2 , p_{n,n-1}=1/2\n\nDetermine whether the walk is transient or persistent. [Hint: relate the walk\nto the standard symmetric walk on the integers. The standard symmetric walk is persistent, thus f_{0,1}=1. By conditioning on the fi rst step of the walk starting at 0, use this to compute f_{0,0}=1 for the walk on the half-line given above]."}
{"text": "Retrieved from http://mathoverflow.net/questions/92311/distributional-derivative-is-locally-integrable-then-the-distribution-as-well\nText:\nTake the 2-minute tour \u00d7\n\nGiven a distribution $T \\in D'(\\mathbb{R})$ such that the distributional derivative $\\partial T \\in L^1_{loc}(\\mathbb{R})$. Can one deduce that $T \\in L^1_{loc}(\\mathbb{R})$ as well? Or can anyone give me an example where $T \\notin L^1_{loc}(\\mathbb{R})$?\n\nshare|improve this question\nIt's not just in $L^1_{loc}$; it's actually continuous. You should be able to prove this yourself. \u2013\u00a0 Deane Yang Mar 26 '12 at 21:48\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nLet $T$ be your distribution. By hypothesis $$ T'(\\phi)=-T(\\phi')=\\int_\\mathbb R f\\phi'dx, $$ where $\\phi$ is a test function and $f\\in L^1_{\\text{loc}}$.\n\nFix $x_0\\in\\mathbb R$ and define $$ F(x):=\\int_{x_0}^x f(x)dx. $$ Then $F$ is a continuous function, which is almost everywhere differentiable; moreover, if $F'(x)$ is defined at some point $x$, then it equals $f(x)$, so that $F'$ and $f$ define the same element in $L^1_{\\text{loc}}$.\n\nThen, the distribution $T$ is given by integration against $F$ up to some additive constant. Indeed, by integration by parts one obtains $$ \\int_\\mathbb R F\\phi' dx=-\\int_\\mathbb R F'\\phi dx=-\\int_\\mathbb R f\\phi'dx=T(\\phi') $$ This shows that the distribution $T_F$ defined by $F$ equals $T$ on every test function which is the derivative of a test function (the point is that a priori a primitive of a test function is no longer a test function in general). To conclude you just need the following elementary lemma:\n\nLemma. Let $S$ be a distribution such that $S'=0$. Then, $S(\\bullet)=\\alpha\\int_\\mathbb R\\bullet dx$, for some $\\alpha\\in\\mathbb R$.\n\nProof. Let $\\alpha:=S(\\phi_0)$, where $\\phi_0$ is a test function such that $\\int_\\mathbb R\\phi_0 dx=1$. Let $\\phi$ be any test function and write it as $\\phi=(\\phi-c\\phi_0)+c\\phi_0$, where $c=\\int_\\mathbb R\\phi dx$. Then, $\\int_\\mathbb R(\\phi-c\\phi_0)dx=0$ so that $\\phi-c\\phi_0$ admits a primitive which is actually a test function, for instance $$ \\Phi_c:=\\int_{-\\infty}^x(\\phi(t)-c\\phi_0(t))dt. $$ Therefore, $S(\\phi-c\\phi_0)=S(\\Phi_c')=-S'(\\Phi_c)=0$. But then, $$ S(\\phi)=c S(\\phi_0)=\\alpha\\int_\\mathbb R\\phi dx.\\qquad\\qquad\\square $$ Thus, since $(T_F-T)'(\\phi)=T(\\phi')-T_F(\\phi')=0$ for every test function $\\phi$, you have that $T=T_F+\\alpha\\int_\\mathbb R\\bullet dx$, for some $\\alpha\\in\\mathbb R$.\n\nTherefore, $T=T_{F+\\alpha}$ and $T$ is the distribution associated to the continuous almost everywhere differentiable function $F+\\alpha$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/93247/irreducible-elements-in-a-ideal-of-rx-1-x-2\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbf R$ denote the real numbers, let's take a finite number of points in $\\mathbf R^2$ and let's take the ideal $I$ of all the polynomials that vanish on this points. Using the Hilbert basis theorem we know that $I$ is finitely generated. I want to know if there exists an element in this ideal that is an irreducible polynomial.\n\nClearly I can suppose that all the finite generators are not irreducible, otherwise it's done. Using this, how can I find such a polynomial?\n\nshare|improve this question\nTake $F=\\sum_{i+j\\le N} a_{ij}x_1^jx_2^j$. To pass through the points imposes a finite set of conditions on the coefficients $a_{ij}$. Taking $N$ sufficiently large you can find such an $F$ which is also irreducible. \u2013\u00a0 J.C. Ottem Apr 5 '12 at 20:05\nBut how can I prove that it\u00b4s irreducible? \u2013\u00a0 Daniel Apr 5 '12 at 20:09\nLet ${\\cal P}_N$ be the space of degree-$N$ polynomials. The reducible polynomials in ${\\cal P}_N$ form the union of subvarieties each of codimension at least $N-O(1)$ [see e.g. my answer to mathoverflow.net/questions/88895]. The polynomials vanishing on a finite set $S$ of points constitute a subspace of ${\\cal P}_N$ of codimension at most $\\#(S)$. Therefore, once $N > \\#(S) = O(1)$ most polynomials in that subspace are irreducible, QED. \u2013\u00a0 Noam D. Elkies Apr 5 '12 at 21:06\nI don\u00b4t understand your answer, and your link is deleted. \u2013\u00a0 Daniel Apr 5 '12 at 23:59\n@Daniel: Try mathoverflow.net/questions/88895 (I see that if you click on what I wrote the final \"]\" gets appended to the URL). What I wrote has a slight typo: should be $N > \\#(S) + O(1)$, not $\\#(S) = O(1)$. Basically, once $N$ is large enough (bigger than the size of the finite subset plus a bit), there aren't enough reducible polynomials of degree $N$ to fill the space of degree-$N$ polynomials vanishing on $S$. (If $N < \\#(S)$ the claim can fail, because all the points in $S$ might lie on one line $l$, and then a degree-$N$ polynomial vanishing on $N$ would vanish identically on $l$.) \u2013\u00a0 Noam D. Elkies Apr 6 '12 at 0:08\n\n1 Answer 1\n\nTo give an explicit answer, choose a system of coordinates $x,y$ such that no two points have the same $x$ coordinate. This is possible since the slopes of lines that pass through pairs of points in the set are only finitely many of all the slopes. Then use basic algebra or the Chinese remainder theorem to find a polynomial equation $y=f(x)$ that passes through all your points. $y-f(x)$ is irreducible so you're done.\n\n(Proof: its degree in $\\mathbb R[x][y]$ is one so it must be the product of a linear and a constant term, but no nontrivial constant terms divide it.)\n\nEdit: A secondary question might be: what is the worst-case scenario lowest-degree polynomial that accomplishes this goal? This method shows that, with $n$ points, there is always a degree $n-1$ irreducible polynomial. Sometimes, there is no degree $n-2$ polynomial: Take $n-1$ points on a line, and one off it. Then an irreducible polynomial vanishing at all $n$ points cannot vanish identically on the line, but vanishes at $n-1$ points on it, so has degree at least $n-1$.\n\nshare|improve this answer\nAh and I forgot something, not only must cancel on this points, and be irreducible, also has only that roots , and no more! \u2013\u00a0 Daniel Apr 6 '12 at 5:46\nI would never have thought there was such a beautifully elementary solution: congratulations, Will ! \u2013\u00a0 Georges Elencwajg Apr 6 '12 at 7:15\n@Will Sawin Your polynomials has other roots right? ( Not just the finite points, What can I do to find a polynomial that only has that finite points and it\u00b4s also irreducible)? \u2013\u00a0 Daniel Apr 6 '12 at 15:31\n@J.C. Ottem I have a question, how can I put in the coefficients the conditions of being irreducible? \u2013\u00a0 Daniel Apr 6 '12 at 15:32\n@Daniel: Let $y,f(x)$ be as before and $g(x)$ vanish at the $x$ coordinates of the set of points, then $(y-f(x))^2+g(x)^2$ is irreducible in $\\mathbb R[x,y]$, because it splits in $\\mathbb C[x,y]$ into $(y-f(x)+ig(x))(y-f(x)-ig(x))$, neither of which is in $\\mathbb R[x,y]$ \u2013\u00a0 Will Sawin Apr 7 '12 at 0:03\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/178664/consider-x-2-sqrt36-x-xt-where-x-is-the-integer-part-of?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nconsider $x = (2+\\sqrt[]{3})^6$, $x=[x]+t$, where $[x]$ is the integer part of $x$, and $t$ is the 'non integer' part of $x$. find the value of $x(1-t)$\n\nshare|improve this question\nNOTE: $(2+\\sqrt3)=(2+\\sqrt[]{2^2-1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 4:36\nNOTE: $(2+\\sqrt[]{3})^6=((2+\\sqrt[]{3})^3)^2=(26+\\sqrt[]{26^2-1})^2=(1351+\\sqrt[]{1351\u200c\u200b^2-1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 5:43\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nNote that $(2+\\sqrt{3})^6+(2-\\sqrt{3})^6$ is an integer, indeed an even integer. For imagine expanding each term, using the Binomial Theorem. The terms involving odd powers of $\\sqrt{3}$ cancel.\n\nWe have $2-\\sqrt{3}=\\frac{1}{2+\\sqrt{3}}$. So $(2-\\sqrt{3})^6=\\frac{1}{x}$, and $$(2+\\sqrt{3})^6+(2-\\sqrt{3})^6=x+\\frac{1}{x}.$$\n\nSince $2-\\sqrt{3}$ is between $0$ and $0.3$, the number $(2-\\sqrt{3})^6$ is positive but close to $0$. So $x$ is close to but below the integer $x+\\frac{1}{x}$, and therefore $$\\lfloor x\\rfloor=x+\\frac{1}{x}-1.$$\n\nAlso, $t=x-(x+\\frac{1}{x}-1)=1-\\frac{1}{x}$, so $1-t=\\frac{1}{x}$. It follows that $x(1-t)=(x)(1/x)=1$.\n\nRemark: The result is obviously structural. In particular, the exponent $6$ is irrelevant. The same argument works with, for example, $(3+2\\sqrt{2})^{99}$, and in many analogous situations.\n\nA crucial role was played by the conjugate $2-\\sqrt{3}$ of the number $2+\\sqrt{3}$. This sort of thing happens very frequently.\n\nThe fact that medium sized powers of $2+\\sqrt{3}$ are almost integers (but just a little bit smaller than an integer) is at first a little startling. It may be enlightening to use the calculator to compute a few powers. For similar but not identical behaviour, compute some powers of $2+\\sqrt{5}$.\n\nshare|improve this answer\nAnd I was working all the numbers out by hand. I got as far as recognizing that the integer part of (2+sqrt(3))^6=1351+[75660/56] if I didn't make any mistakes anywhere... Checking in Python, I see I was off by one. I thought Newton's method gave under-approximations for square roots but I was wrong, it gives over-approximations \u2013\u00a0 dspyz Aug 4 '12 at 5:03\n$(2+\\sqrt[]{5})^2$=$(9+\\sqrt[]{9^2-1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 6:46\n$(2+\\sqrt[]{5})^3=(38+\\sqrt[]{38^2+1})$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 6:53\nNote that in this case we are alternately a bit below an integer and a bit above an integer. That's basically because $2-\\sqrt{5}$ is negative. \u2013\u00a0 Andr\u00e9 Nicolas Aug 4 '12 at 6:57\n$(2+\\sqrt[]{5})=\\frac{-1}{2-\\sqrt[]{5}}$ \u2013\u00a0 Rajesh K Singh Aug 4 '12 at 6:59\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/429590/prove-that-there-not-real-roots-with-px-ax3bx2cxd\nText:\nTake the 2-minute tour \u00d7\n\nlet $P(x)=ax^3+bx^2+cx+d,a,b,c,d\\in R$, such that $$\\min{\\{d,b+d\\}}>\\max{\\{|c|,|a+c|\\}}$$\n\nshow that $P(x)=0$ have no real roots in $[-1,1]$\n\nshare|improve this question\nYou have left out two key pieces of information in the question: the context in which you encountered the question (what class, what book), and what you have tried already. Separately, questions that are phrased in the imperative (\"Show that\") are often considered impolite, because they can come across as orders rather than as questions. \u2013\u00a0 Carl Mummert Jun 26 '13 at 2:15\nWhat's the close votes for?? OP has numerous questions, and contributed answers to non-trivial questions. I think the phrasing has more to do with English not being OP's first language. \u2013\u00a0 Calvin Lin Jun 26 '13 at 4:01\n@Calvin Lin: the number of close votes matches the number of upvotes on my previous comment, if you count the author (me) as an upvote. This particular question could be substantially improved. \u2013\u00a0 Carl Mummert Jun 26 '13 at 11:05\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\n$P(-1)=-a+b-c+d$ and $P(1) = a+b+c+d$ so $P(-1)\\times P(1)= -a^2+b^2-c^2+d^2-2ac+2bd=-(a+c)^2+(b+d)^2$ Since $Min\\{d,b+d\\}>Max${|c|,|a+c|}, we have $P(-1)\\times P(1)>0$ and we have, granted by Bolzano's Theorem, that the number of roots of $P(x)=0$ in $[-1,1]$ is even, that means that $P(x)$ has $0$ or $2$ roots in $[-1,1]$.\n\nNow uses the Cardano's formula to show that it cant have 3 distinct real roots, wich means that 2 roots are complex number and only one is real and this one cant be in $[-1,1]$\n\nshare|improve this answer\nDoes this account for the possibility that it has a double root in $[-1,1]$? \u2013\u00a0 Antonio Vargas Jun 26 '13 at 16:46\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/96239/determinant-of-an-updated-covariance-matrix/96240\nText:\nTake the 2-minute tour \u00d7\n\nI am faced with the following problem :\n\nOriginally (at time 0) I have a number of data samples $x^0_{1...n}$ (normalised : $E[x] = 0, Var[x] = 1$) from which I have calculated the covariance matrix $C^0 = X^T X$ (where $X$ is the matrix of data samples), and the corresponding determinant $|C^0|$ (I could also store all and any minors are necessary).\n\nGiven this information I would like to perform the following iterative process incurring the smallest computational cost possible :\n\nAt time $t+1$ I am presented with a new data sample $x^{t+1}_{new}$ (similarly normalised) which can replace any of my existing data samples. Thus if I discard example $x^t_k$ in favour of this new sample, I have a new covariance matrix $C^{t+1}_{k,new}$. I would like to calculate (given $C^0$, its minors and determinant) $\\forall t$ $argmax_k |C^{t+1}_{k,new}|$.\n\nNote that at each time step $t+1$, if I decide to discard $x^t_k$ in favour of $x^{t+1}_{new}$ then $x^{t+1}_k = x^{t+1}_{new}$ .\n\nMy question is, is there a method to calculate the determinants without incurring a cost of $n^3$ per determinant per time step?\n\nThanks for the help.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nFirst compute a Cholesky factorization of the covariance matrix. Now your tentative new covariance matrix is a rank-2 update of the old, $$ M_{new}=M_{old}+\\frac{1}{n}x_{new}x_{new}^T-\\frac{1}{n}x_{old}x_{old}^T. $$ You can use Sylvester's formula here to compute the determinant of the update; for this you'll only need to solve a linear system, which is $O(n^2)$ using your Cholesky factorization.\n\nThen when your \"replacement\" take place for real you just have to update the Cholesky factorization, and there are algorithms to do that (low-rank updates of Cholesky factorization) in $O(n^2)$ as well. Check Matlab's cholupdate for instance.\n\nSo you pay $O(n^3)$ at the first step and then $O(n^2)$ per step.\n\nEDIT: better and clearer algorithm\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/70803/shortest-painting-of-the-sphere/70807\nText:\nTake the 2-minute tour \u00d7\n\nLet $S$ be the sphere in $\\mathbb{R}^3$ and $C:[0,1]\\to S$ a continuously differentiable curve on $S$. Let $T:[0,1]\\to\\mathbb{R}^3$ denote the tangent vector of $C$. Let $P(t)$ be the plane containing $C(t)$ and having normal vector $T(t)$.\n\nGiven a size $d$ of the \"paint brush\" we define the \"brush\" $b:[0,1]\\to \\mathcal{P}(S)$ by letting $b(t)$ be the points of $S$ that are at most a distance $d$ (metric on the sphere) from $C(t)$ that are contained in $P(t)$.\n\nWe can think of this as saying the \"brush\" $b(t)$ is an arc on the sphere that is \"orthogonal\" to the motion $C(t)$ of the \"paint brush\".\n\nGiven $d$ what is the arclength of the shortest curves such that $\\cup_{t\\in[0,1]} b(t) = S$. This says that the \"paint brush\" covered the sphere.\n\nshare|improve this question\nDuplicate? mathoverflow.net/questions/26212/\u2026 \u2013\u00a0 Gjergji Zaimi Jul 20 '11 at 9:19\n\n2 Answers 2\n\nThe model is that used by Henryk Gerlach and Heiko von der Mosel in their 2010 paper \"On sphere-filling ropes\" arXiv:1005.4609v1 (math.GT) may be relevant. Their question is different: What is the longest rope of a given thickness on a sphere? But their explicit solutions are packings, and it seems they could be converted to painting paths. Here is a piece of their Fig. 6:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Rope on sphere\n\nshare|improve this answer\nYes indeed -- by as brush width half the width of the rope. This seems to give an optimal painting for countably many widths. Very nice! \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:38\n\nThis question is somewhat related to this recent one. More precisely, the comment by Gjergji Zaimi in the earlier question gives a painting of length $2\\sqrt{2}\\pi$ for $d=\\pi/4$, which, as explained in another comment there, is optimal for a path at constant distance from the sphere. So for $d=\\pi/4$ the optimal length should be $2\\sqrt{2}\\pi$.\n\nshare|improve this answer\nOf course $d=\\pi/4$ is very special, since for this painting each point of the sphere is painted exactly once (except for a curve). It's not clear whether there is another value of $d$ for which this is possible. \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:02\nindeed your comment there was very good too. \u2013\u00a0 Pietro Majer Jul 20 '11 at 10:04\nThanks! But the answer by Joseph O'Rourke above is much more complete. \u2013\u00a0 Jean-Marc Schlenker Jul 20 '11 at 10:46\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/91528/probability-to-be-the-winner-in-a-tournament\nText:\nTake the 2-minute tour \u00d7\n\nIn a project in Game Theory we (Ayala Arad and Ariel Rubinstein) are stuck with the following \"simple\" question. We are sure of the conjecture but we failed to find a (hopefully simple) proof:\n\nLet A and B be two non-empty finite disjoint sets of players. Any two players in A are \"matched\" and $\\$2$ are transferred from one to the other. Any player in A is also matched with any player in B and $\\$1$ is transferred from one to the other. The two possible directions of each transfer are equally likely and independent. No transfers are carried out between players in B. The winner is the player with the highest net transfers. In the case of a tie, the winner is selected randomly from among the highest scoring players. (For example if |A|=1 and |B|=2 the probability of winning for the player in A is 1/4 and the probability for the player in B is 3/8. If |A|=|B|=2 the corresponding numbers are 21/64 and 11/64). Claim: If |AUB|>3 then the probability of winning for any player in A is strictly larger than that of any player in B.\n\nshare|improve this question\nDear Ariel, Welcome to MathOverflow! May the force be with you :) \u2013\u00a0 Gil Kalai Mar 18 '12 at 14:16\nWouldn't any two players in A have the same number of transfers, and the same for B? I guess I don't understand the game. \u2013\u00a0 Patrick Reardon Mar 18 '12 at 18:15\nTo Patrick: Note, that the direction of transfer between any two players is indepedent from the directions in other \"matches\". \u2013\u00a0 Ariel Rubinstein Mar 18 '12 at 22:00\nThanks, it's clearer now. So we could say that every pair of players in $A$ flip a fair coin and the winner gets $\\$2$. Every pair of players with one from $A$ and one from $B$ flip a fair coin and the winner gets $\\$1$. Interesting problem! \u2013\u00a0 Patrick Reardon Mar 19 '12 at 8:33\n\n3 Answers 3\n\nHere's a partial answer, I believe that the technique can be generalized to include more cases.\n\nSuppose that $|A|=|B|=n$ and $n$ is large enough. As $n\\to \\infty$, the distribution of what an $A$-player gets is roughly $N(0,3n-2)$ and what $B$=player gets is roughly $N(0,n)$. Hence, we can choose some threshold $t_n$ (about $\\sqrt{\\log n}$ or so) such that the expected number of $A$-players getting more than $t_n$ is large (tends to infinity) and the expected number of $B$-players getting more then $t_n$ is small (tends to zero). The probability that a $B$-player will get more then $t_n$ therefore also goes to 0.\n\nFurthermore, the amounts different players get are almost pairwise independent (they are independent up to the amount one of them pays the other). Thus, a second moment argument easily show that the probability of some $A$-player gets more then $t_n$ goes to 1. So the probability that an $A$-player will win goes to 1. Since the players are symmetric and there are equal number of $A$ and $B$ players, we get that the probability of an $A$-player to win is strictly larger then that of a $B$-player.\n\nThis can be extended to other regimes by analyzing what $t_n$ and the probabilities actually are and perhaps using the binomial distribution instead of Normal (actually, I now notice that the argument is not precise as it is since I use Normal approximation in a regime where it is not formally valid, but it's easy to correct). Perhaps all cases where either $|A|$ or $|B|$ are large enough can be covered that way and perhaps \"large enough\" turns out to be pretty small after all. Perhaps I'll try to give a more complete answer later.\n\nOne final remark: it seems that (at least asymptotically) it is not important that $2>1$, but only that $2>0$.\n\nshare|improve this answer\nThanks. We do need the result for small values as well (and not just for large numbers). Note that for general |A| and |B| (not for the case that |A|=|B|) we need the condition that $2>$1: Consider the case that the transfer between a member of A and a member of B (which is now $1) is very very high then if |A|>|B|, the probability of a member of B to win will be larger (the transfers inside B will be negligible). \u2013\u00a0 Ariel Rubinstein Mar 18 '12 at 21:58\n\nThis was intended to be a comment to Ori's post but it is too long, so I'm posting it as an answer. First of all, let us modify the game a bit by initially giving each player a random score between $0$ and $\\varepsilon$. That will break the ties just as needed but will allow us to talk about the winner.\n\nNow the case $|A|=|B|$ is trivial. Let's do all transactions between $A$ and $B$ first and look at the resulting configurations. They split into natural pairs (swapping $A$ and $B$). Now let $a$ be the top score in $A$ and $b$ be the top score in $B$. Arrange the pair so that $a>b$. Then we need to show that for every configuration the probability that the top score in $A$ will become less than $b$ after transactions in $A$ is less than that the probability that the top score in $B$ will become larger than $a$ if we do the transactions in $B$. Identify $A$ with $B$ in some way so that the top scorers are identified. Any way to do the transactions in $A$ that moves the winner to $B$ should bring the score $a$ of the top scorer in $A$ below $b$ at the very least and that may be insufficient in some configurations. On the other hand, if have one such way and do the inverse transactions in $B$ instead, they'll bring the top scorer in $B$ above $a$ and it is not necessary to move the winner to $B$. That's all one needs to say about the equal cardinalities case.\n\nNow, like Ori, I have to say that I'll try to give a more complete answer later.\n\nshare|improve this answer\n\nFor the little it might be worth, here are the results of some simulations:\n\nThe columns correspond to values of $|A|$ and the rows to values of $|B|$. The four-tuple in each cell is (Probability winner is in $A$, Probability winner is in $B$, Probability a given member of $A$ is the winner, Probability a given member of $B$ is the winner).\n\nI simulated each of these 10,000 times, rounded results to the nearest percent, and retyped them (which has a small chance of having introduced additional errors).\n\nI was struck by the non-monotonicity in the third entry as you go down the third column, so I repeated these trials and got the same result.\n\nshare|improve this answer\nThanks. We conducted here similar simulation for all |A|,|B|<11 In case you are interested: arielrubinstein.tau.ac.il/simulation.pdf \u2013\u00a0 Ariel Rubinstein Mar 19 '12 at 5:43\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/116236/mean-value-property-with-fixed-radius\nText:\nTake the 2-minute tour \u00d7\n\nI will focus on the real line. Let $f$ be a smooth function on $\\mathbb{R}$, if $\\forall x\\in\\mathbb{R}, r>0$, $$\\frac{f(x-r)+f(x+r)}{2}=f(x),$$ we say that f has the spherical mean value property (MVP); if instead $$\\frac{1}{2r}\\int_{x-r}^{x+r}f(t)dt=f(x),$$ we say f has the ball MVP. It is easy to see that spherical MVP implies ball MVP.\n\nIt is well known, and not hard to prove (though it is much harder in higher dimensions), that ball MVP implies that $f$ is harmonic, i.e. $f$ is of the form $ax+b$, where $a$ and $b$ are constants.\n\nNotice that in the definitions above, we require the radius $r$ to run over all the positive numbers. Out of curiosity, I tried to find non harmonic functions which satisfy the MVPs only for $r=1$. It turns out any $1$-periodic function will satisfy the spherical MVP with $r=1$, which is obvious. But it seems much harder to find one for ball MVP. So here is my question:\n\nQuestion: Does there exist a function $f$ which is not of the form $ax+b$, such that $\\forall x\\in\\mathbb{R},$ $$\\frac{1}{2}\\int_{x-1}^{x+1}f(t)dt=f(x)?$$\n\nThank you!\n\nshare|improve this question\nJust a side comment: for the mean value property to imply harmonicity, you don't need $r$ to run over all the positive numbers. It suffices (for example) that the property holds for all $r\\in [0,\\epsilon)$ for some $\\epsilon > 0$. \u2013\u00a0 Willie Wong Mar 5 '12 at 9:34\n@WillieWong: does $\\epsilon$ depend on $x$? \u2013\u00a0 Syang Chen Apr 13 '12 at 5:16\nit may. For $C^2$ functions it follows directly from the proof for MVP to imply harmonicity. \u2013\u00a0 Willie Wong Apr 17 '12 at 4:30\n@WillieWong: Can we weaken the $C^2$ assumption into, say $C^0$? In practice $C^2$ seems hard to verify. \u2013\u00a0 Syang Chen Apr 28 '12 at 3:54\nSee page 17 of Harmonic Function Theory by Axler, Bourdon, and Ramey \u2013\u00a0 Willie Wong Apr 30 '12 at 8:29\nshow 1 more comment\n\n2 Answers\n\nup vote 8 down vote accepted\n\nNote that\n\n$$ \\frac{1}{2}\\int_{x-1}^{x+1}e^{as}ds = \\frac{\\sinh(a)}{a}e^{ax}. $$\n\nLet $a+ib \\in \\mathbb{C}$ be a non-zero root of $\\sinh(z)=z$. Then also $a-ib$ is a root and because the MVP is linear the function $f(x) = e^{ax}\\cos(bx)$ has the mean value property.\n\nRemains to prove that $\\sinh(z)-z$ has non-zero roots. I present two proofs below. The second one (that I gave first) is a bit clunky but has the advantage that it gives some information about the distribution of the roots.\n\nProof 1: Let $f(z) = \\sinh(z)-z$. Then $f$ has an essential singularity at $\\infty$. By Picard's great theorem the function $f$ attains all values infinitely often with at most one exception. In particular at least one of $0$ and $2\\pi i$ must be attained infinitely often. However, $f(z + 2\\pi i) = f(z) - 2\\pi i$ and so both cases imply that $f$ has infinitely many roots.\n\nProof 2: I'll show that $|\\sinh(z)|=|z|$ holds along some curve in $\\mathbb{C}$ extending to $\\infty$ and that $\\sinh(z)/z$ must wind around the unit circle infinitely often along this curve.\n\nIf $z=x+iy$ then $2|\\sinh(z)|^2 = \\cosh(2x)-\\cos(2y)$ and so $|\\sinh(z)| = |z|$ exactly if $\\cosh(2x)-2x^2=\\cos(2y)+2y^2$. To show that for each $x$ there is a $y$ that satisfies this equation define the following functions:\n\n$$ f(x) = \\cosh(2x)-2x^2, \\ g(x) = \\cos(2x)+2x^2. $$\n\nOn $\\mathbb{R}_{>0}$ both functions are strictly increasing and $f(x) > g(x)$. (The latter inequality can be checked from their power series.) In particular, for each $x>0$ there exists a unique $y>x$ such that $f(x) = g(y)$. Let $\\tau: \\mathbb{R}_{>0} \\rightarrow \\mathbb{C}$ be the curve $\\tau: x \\mapsto x+iy$, then $|\\tau'(x)| \\geq 1$ and $|\\sinh(\\tau)| = |\\tau|$. So the curve\n\n$$ x \\mapsto \\frac{\\sinh(\\tau)}{\\tau} $$ maps into the unit circle. If we can bound its derivative from below, then it must wind around the unit circle (and therefore pass through $1$) infinitely many times. That this is indeed the case follows from the following inequalities:\n\n$$ \\left|\\frac{\\partial}{\\partial x}\\frac{\\sinh(\\tau)}{\\tau}\\right| \\geq \\left| \\frac{\\cosh(\\tau)}{\\tau} - \\frac{\\sinh(\\tau)}{\\tau^2} \\right| \\geq \\left| \\frac{\\sqrt{\\left| |\\tau|^2-1 \\right|}}{|\\tau|} - \\frac{1}{|\\tau|} \\right| \\xrightarrow{x \\rightarrow \\infty} 1 $$\n\nThis shows that $\\sinh(\\tau) = \\tau$ occurs infinitely many times. Moreover, all solutions of $\\sinh(z) = z$ with $\\Re(z)>0$ and $\\Im(z) >0$ lie on $\\tau$.\n\nshare|improve this answer\nAre you sure that $\\sinh(z) = z$ has a nonzero solution? \u2013\u00a0 Nick Strehlke Mar 4 '12 at 10:49\n@NickStrehlke Using Mathematica's function FindRootyou find many solutions like $z=13.9+3.35221\\,I$ and $z=7.49768 + 2.76868$. I have not tried to prove that they are in fact solutions. \u2013\u00a0 Juli\u00e1n Aguirre Mar 4 '12 at 11:54\n@WimC: Nice! Could you show why $\\sinh(z)=z$ has a nonzero solution? \u2013\u00a0 Syang Chen Mar 4 '12 at 16:27\n@NickStrehlke Yes, I posted solutions to $\\sin a=a$. For such $a$, $\\sin(a x)$ and $\\cos(a x)$ are a solutions to the problem. I was going to write the answer, but I WinC had already done so. \u2013\u00a0 Juli\u00e1n Aguirre Mar 4 '12 at 20:05\n@WimC Even nicer proof for the existence of roots!! \u2013\u00a0 Syang Chen Mar 4 '12 at 22:52\nshow 10 more comments\n\nWe can construct many solutions by setting $f(x)=F'(x)$ where $F$ is smooth and satisfies $$ 2F'(x)=F(x+1)-F(x-1)$$ for all $x$. For example, $F$ can be generated from this formula by starting with an arbitrary smooth ($C^\\infty$) function on $[-1,1]$ that vanishes near the points $-1$, $0$, and $1$: For $x>1$, $$F(x)= F(x-2)+2F'(x-1)$$ defines $F$ successively on $(k,k+1]$ for $k=1,2,\\dots$, and for $x<-1$, $$F(x)=F(x+2)-2F'(x+1)$$ does the same trick successively on $[-k-1,-k)$. This yields a function $F$ that vanishes near each integer, and is clearly smooth.\n\nshare|improve this answer\nKeen observation! Are there similar arguments in higher dimensions? Please see this MO post. mathoverflow.net/questions/90233/\u2026 \u2013\u00a0 Syang Chen Mar 5 '12 at 1:09\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/146187/probability-of-picking-a-specific-card-from-a-deck\nText:\nTake the 2-minute tour \u00d7\n\nQuestion: Assume you have a deck with with $52$ cards ($4$ suites of $13$ cards: numbers $1\\ldots 9$, and faces J,Q,K). What is the probability you draw jack of hearts in a hand of $5$?\n\nMy way of thinking is the following:\n\n$$\\frac{\\left(\\dfrac{1\\cdot51\\cdot50\\cdot49\\cdot48}{4!}\\right)}{ \\left(\\dfrac{52\\cdot51\\cdot50\\cdot49\\cdot48}{5!}\\right)}$$\n\n$1$ is for the jack of hearts being drawn, and then $51\\ldots48$ for the rest of the $4$ cards\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 4 down vote accepted\n\nYour thinking is correct, though let me provide another way of looking at the problem that might make its structure clearer:\n\n  \u2022 There are ${51\\choose 4}$ ways to pick a hand that include the Jack of Hearts (because once we've picked the Jack, we can choose 4 other cards from the remaining 51)\n  \u2022 There are ${52\\choose 5}$ ways to pick a hand, with no restrictions.\n\nTherefore the probability of getting a hand with the Jack of Hearts is\n\n$$\\frac{51\\choose 4}{52\\choose 5} = \\frac{51!5!47!}{4!47!52!} = \\frac{5}{52}$$\n\nYou can check that the obvious generalization is, in fact, true: the probability of drawing a particular card in a hand of $m$ cards with a deck of size $n$ is $m/n$.\n\nshare|improve this answer\nadd comment\n\nThe probability you draw the jack of hearts is the same as the probability of drawing any other particular card. Since you draw 5 cards, the 52 individual probabilities have to add up to 5, so each probability is 5/52. In particular, the probability of drawing the jack of hearts is 5/52.\n\nshare|improve this answer\nadd comment\n\nAlternatively, there are $\\binom{51}{5}$ ways of picking a hand that does not have the Jack of Hearts. There are a total of $\\binom{52}{5}$ ways of picking $5$ cards, so the probability of choosing a hand with the Jack of Hearts is: $$1 - \\frac{\\binom{51}{5}}{\\binom{52}{5}} = 1-\\frac{47}{52} = \\frac{5}{52}$$\n\nshare|improve this answer\nAlthough a bit more complicated, this is valid (+1) \u2013\u00a0 robjohn Mar 5 at 23:42\nadd comment\n5/52 seems wrong to me.  \n\nI suggest the slightly higher probability of:\n                          n = (1/52 + 1/51 + 1/50 + 1/49 + 1/48)\n\nWhich approximates to:\n                          n = 5/50\n\nEach time a cards is picked the deck gets smaller, and the probability of \npicking the \"good\" card the next round increases.\n\n5/52 would be the probability ONLY if after each time you drew one card, \nyou replaced it into the deck before the next draw.\nshare|improve this answer\nWith replacement, the probability would be $1-\\left(\\frac{51}{52}\\right)^5$ \u2013\u00a0 robjohn Mar 5 at 23:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/138944/questions-on-symmetric-matrices\nText:\nTake the 2-minute tour \u00d7\n\nDescribe a basis for the vector space of symmetric n x n matrices. What is the dimension of this space?\n\nshare|improve this question\nIs this homework? If it is, it is customary to label it so, and to mention any attempts you have made. \u2013\u00a0 Martin Argerami Apr 30 '12 at 16:08\n@Jim_CS : My guess is that whoever down-voted this question did so because it's written as if you copied a question written by someone other than yourself. \u2013\u00a0 Michael Hardy Apr 30 '12 at 16:16\nIt was in an exam i had today and i never came across it during the course or pre exam study so i had no answer for it. well i said the dimension was n as that seemed obvious. \u2013\u00a0 Jim_CS Apr 30 '12 at 16:20\nReading the comments, I feel you could first try to answer the following questions: (i) Describe a basis for the vector space of all the $n\\times n$ matrices? (ii) What is its dimension? \u2013\u00a0 Did Apr 30 '12 at 18:13\nI dont know what all the downvotes are for...what else am I supposed to put in the post when I wasnt even able to make an attempt at this question in the exam? (apart from putting dim = n, which seems wrong in any case) \u2013\u00a0 Jim_CS Apr 30 '12 at 22:19\nadd comment\n\n2 Answers\n\nup vote 9 down vote accepted\n\nHINT: If you know all of the elements on and above the diagonal of a symmetric matrix, you know the whole matrix. How many elements are there on or above the diagonal of an $n\\times n$ matrix?\n\nAdded: I can see that you're having trouble getting a handle on the vector space in question; perhaps this will help. Let $S_n$ be the space of $n\\times n$ symmetric matrices. In the simplest case that isn't completely trivial, $n=2$, the elements of $S_2$ are matrices of the form $$\\pmatrix{a&b\\\\b&c}\\;.$$ Vector addition in $S_2$ is just ordinary matrix addition: $$\\pmatrix{a_1&b_1\\\\b_1&c_1}+\\pmatrix{a_2&b_2\\\\b_2&c_2}=\\pmatrix{a_1+a_2&b_1+b_2\\\\b_1+b_2&c_1+c_2}\\;.$$ Note that the result of this addition is still symmetric, so it really is in $S_2$. If it weren't, $S_2$ wouldn't be closed under addition and therefore wouldn't be a vector space after all.\n\nScalar multiplication in $S_2$ is ordinary multiplication of a matrix by a scalar: $$\\alpha\\pmatrix{a&b\\\\b&c}=\\pmatrix{\\alpha a&\\alpha b\\\\\\alpha b&\\alpha c}\\;,$$ and again all's well, since the result is still in $S_2$.\n\nHere's a simple exercise to help you get more accustomed to working with this vector space.\n\nLet $V=\\{\\langle a,b,c,d\\rangle\\in\\Bbb R^4:b=c\\}$.\n\n  1. Prove that $V$ is a subspace of $\\Bbb R^4$.\n  2. Prove that $V$ is isomorphic to $S_2$. That is, find a linear transformation $T:V\\to S_2$ that is one-to-one and maps $V$ onto $S_2$.\nshare|improve this answer\nWell there are n elements on the diagonal so the dimension is n, yes? \u2013\u00a0 Jim_CS Apr 30 '12 at 17:01\n@Jim_CS: There are $n$ elements on the diagonal, but specifying them isn't enough to specify the whole matrix, so the dimension of the space is more than $n$. You also have to specify the elements above the diagonal. How many of those are there? As for your other question, it means exactly what it says: the space of $n\\times n$ symmetric matrices, i.e., the space whose elements are these matrices. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 17:03\n@Jim_CS : it seems to me that you're making a confusion between the dimension of the space spanned by the column of a single matrix (i.e. its rank) and the dimension of the space of all (symmetric) matrices, which is a vector space itself (the \"vectors\" are the matrices) \u2013\u00a0 Andrea Mori Apr 30 '12 at 17:13\n@Jim_CS: The $3\\times 3$ identity matrix isn't a vector space, so it doesn't even have a dimension. Its rank is $3$. That aside, you're not thinking about what the question actually asks. You have a vector space $V$ whose elements $-$ the actual vectors in $V$ $-$ are $n\\times n$ symmetric matrices. Each matrix is one vector in $V$. You could write it out as a single row of $n^2$ numbers instead of as a square array, except that it would be much harder to tell that it was symmetric. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 17:15\n@Jim_CS: I'll expand my answer a bit to try to give you a better idea of what the space itself is like. \u2013\u00a0 Brian M. Scott Apr 30 '12 at 22:24\nshow 4 more comments\n\nIf $A$ is a symmetric $n\\times n$ matrix, then $A$ has the form $$ \\begin{bmatrix} * \\ & a_1 & a_2 & \\cdots & a_k \\\\ a_1 & * \\ & a_3 \\\\ a_2 & a_3 & * \\ \\\\ \\vdots & & & \\ddots & \\\\ \\\\ a_k & & & & * \\ \\end{bmatrix} $$ where the $*$ entries are whatever you like them to be. You can see that we have $a_{ij}=a_{ji}$.\n\nFrom this form you can see that we need $n$ elements in the basis to span the diagonal entries. For the remaining $n(n-1)$ entries, we need exactly $\\frac{1}{2}n(n-1)$ elements in the basis to in order to span those entries (due to the fact that $a_{ij}=a_{ji}$). This gives a basis with $\\frac{1}{2}n(n+1)$ elements.\n\nDefine $T_{ij}$ to be the matrix with $(T_{ij})_{ij}=1$ and all other entries equal to $0$. Then define $$ M_{ij} = T_{ij}+T_{ij}^\\text t $$ where $i$ and $j$ range over $1,2,\\dots, n$. Then for a given $n\\times n$ symmetric matrix $A$, we can write it as $$ A = \\sum_{i=1}^n\\sum_{j=1}^n \\frac{1+\\delta_{ij}}{2}(A)_{ij}M_{ij} $$ where $(A)_{ij}$ denotes the $(i,j)^\\text{th}$ entry of the given matrix $A$. The $\\frac{1+\\delta_{ij}}{2}$ in the sum is to correct for the fact that $M_{ij}=M_{ji}$.\n\nThe collection of the distinct $M_{ij}$ will form a basis for the space of $n\\times n$ symmetric matrices. Of course, this is not proof, but provides a way that you might express the basis.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/20529/fast-method-for-nth-squarefree-number-using-mathematica/20541\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to compute Nth Squarefree numbers using Mathematica. What I am trying to utilize is the SquareFreeQ[i] function.\n\nHere is my solution :\n\nNSqFree[N_] := For[n = 1; i = 1, n <= N + 1, If[SquareFreeQ[i], If[n == N, Print[i] ] n++] i++]\n\nBut I am supposed to compute NSqFree[1000000000] but seems like my approach is taking for ever. Any faster method ?\n\n\n\nHere an exactly identical topcoder question and the corresponding editorial for the same.\n\nshare|improve this question\nadd comment\n\n4 Answers\n\nup vote 6 down vote accepted\n\nYou have to us the Inclusion-Exclusion principle: suppose you want to find the number of square free numbers up to $N$, then from $N$ you have to substract the number of integers divisible by the square of a prime, but then you have to add any multiple of the square of the product of two discinct primes and so on, in formulas the number looked for is $$ N - \\sum_{p^2 \\le N} \\left\\lfloor\\frac{N}{p^2}\\right\\rfloor + \\sum_{p^2q^2 \\le N} \\left\\lfloor\\frac{N}{p^2q^2}\\right\\rfloor - \\sum_{p^2q^2r^2 \\le N} \\left\\lfloor\\frac{N}{p^2q^2r^2}\\right\\rfloor + \\cdots -\\cdots $$ using the moebius $\\mu$ function you can write this last formula as $$ \\sum_{n \\le \\sqrt{N}} \\mu(n) \\left\\lfloor\\frac{N}{n^2}\\right\\rfloor $$ I don't know how to write this in mathematica but it should take a negligible fraction of the time it takes your current method.\n\nshare|improve this answer\nBut my problem is to find the exact Nth Square free number not the number of square free numbers up to N,I have used your idea in here and here but I am not getting how to use the same formula to get the exactly Nth square free number. \u2013\u00a0 Quixotic Feb 5 '11 at 18:42\nOkay I guess I got my answer and here is the explanation. \u2013\u00a0 Quixotic Feb 5 '11 at 18:50\nI'm sorry, I had misunderstood the question. But you can use the same formula combined with a binary search. It will take only a few applications of the formula. \u2013\u00a0 Esteban Crespi Feb 5 '11 at 18:52\nadd comment\n\nYou won't do a billion (if I counted the zeros right) loops any time soon, so you need a better approach. Wikipedia has an approximation under the section Distribution of square-free numbers. So you could start with $10^9 \\pi^2/6$ and calculate how many below that are square-free, then correct from there. You will need to use inclusion/exclusion, but there are only about 40,000 to consider.\n\nshare|improve this answer\nadd comment\n\nI'm not an expert of number-theoretic algorithms, but it seems to me that you can employing the Chinese Remainder Theorem to obtain a decent first stab at a \"sieving\" algorithm.\n\n  \u2022 Use several registers r[p], each storing a residue modulo p2 for some prime p. Define such a register for various small primes p\u00a0\u2208\u00a0{2,\u20093,\u20095,\u2009...\u2009,\u2009P} for some suitably large prime P. You will use these to represent an integer R, such that R\u00a0\u2261\u00a0r[p] (mod p2). You shouldn't need too many such registers to faithfully represent even reasonably large non-negative numbers (the registers can uniquely determine any integer from 1 to 22\u00a0\u00d7\u00a032\u00a0\u00d7\u00a052\u00a0\u00d7\u00a0...\u00a0\u00d7\u00a0P2).\n\n  \u2022 Whenever you wish to increment R, increment each of the registers r[p] as well. If R is square-free, none of these registers will be zero modulo the square of the appropriate prime. For sufficiently small integers N, you can even characterize N as being square-free if none of these residues are zero. Put another way, the more registers r[p] you maintain, the larger the range of square-free numbers you can automatically detect using these registers.\n\nSuppose that you want to test for square-freeness up to some upper limit N. What do you need to test square-freeness using nothing but registers such as I've described? What you need is for any composite number less than N to have a prime factor from the list of registers that you maintain; that is, you need registers for each of the primes up to \u221aN.\n\nIf you're going to iterate through all integers anyway, you can discover the list of primes that you need to characterize square-freeness at the same time by the Sieve of Erasthotenes, and construct the list of residues modulo squares-of-primes as you go. Any time you find a new prime P, so long as P2\u00a0<\u00a0N, add P to the list of primes for which you maintain registers and initialize a register for residues modulo P2.\n\nAs Ross suggests in his answer, you can use results on the distribution of square-free numbers to obtain an upper bound for the Nth square-free number (it should grow more slowly than N\u00a0ln(N) or so, in any case). This gives you an upper bound on the number of registers that you have to maintain as you search for square-free integers.\n\nFrom this, you should actually be able to show a polynomial-time asymptotic upper bound on the runtime of your procedure.\n\nshare|improve this answer\nadd comment\n\nI think that your method can be improved by sieving: if $n$ is not squarefree you don't need to check any of its multiples. Start with a reasonable estimate (like the one Ross Millikan gave) and sieve like you would do in a prime sieve.\n\nIs this viable? I don't know! I can't program in Mathematica, but later today I'll try to implement this in Python.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/322498/build-smooth-function-on-smooth-manifold\nText:\nTake the 2-minute tour \u00d7\n\nI would like to know how can I build smooth function f on smooth n- dimensional manifold X which provides: f=0 on some open set U. f=1 on a slightly larger V contains U. I know to do it if the manifold contained in R^n (I can write explicitly this kind of function using convolution on characteristic function) but for general manifold I can't since I don't have euclidean metric on the manifold. thanks for the helpers .\n\nshare|improve this question\nAs stated: it is impossible. You have $U\\subset V$ and you are requiring $f(U) = \\{0\\}$ and $f(V) = \\{1\\}$, which contradicts the fact that $f$ is a function. \u2013\u00a0 Willie Wong Mar 6 '13 at 12:29\nIn general, the idea you are looking for is probably that of a smooth partition of unity, which are guaranteed to exist for most definitions of \"smooth manifold\", and can be used to build Riemannian metrics by gluing together local definitions. See for example Theorem 2.23 in Lee's Introduction to Smooth Manifolds. \u2013\u00a0 Willie Wong Mar 6 '13 at 12:34\nadd comment\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/68966/mean-value-of-arithmetic-function?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we define a mean value of arithmetic function $G(f)$ as $$ G(f)=\\lim_{x \\rightarrow \\infty} \\frac{1}{x \\log{x}} \\sum_{n \\leq x} f(n) \\log{n},$$ and suppose now for an arithmetic function $f$, $G(f)$ exist and is equal to $A$, how to use this result to show that the ordinary mean value of arithmetic function $M(f)=\\lim_{x \\rightarrow \\infty} \\frac{1}{x} \\sum_{n \\leq x} f(n)$ also exists?\n\nshare|improve this question\nPunctution should go inside double dollar signs (ideally separated by \"\\;\"), otherwise it appears on the next line. \u2013\u00a0 joriki Oct 1 '11 at 8:46\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nVia Abel's summation formula: $$\\sum_{n\\le x} (f(n)\\log n)\\frac{1}{\\log n}=\\left(\\sum_{n\\le x}f(n)\\log n\\right)\\frac{1}{\\log x}+\\int_2^x \\left(\\sum_{m\\le u} f(m)\\log m\\right)\\frac{du}{u\\log^2 u}.$$ Divide by $x$ and subtract, obtain: $$M_x(f)-G_x(f)=\\frac{1}{x}\\int_2^xG_u(f)\\frac{du}{\\log u}=\\frac{\\mathrm{Li}(x)}{x}\\left(A+O(1)\\right)\\to0.$$\n\nshare|improve this answer\nadd comment\n\nYou'll want to use \"partial summation\", also called \"summation by parts\". Define $G(f;x) = \\sum_{n\\le x} f(n)\\log n$ and $M(f;x) = \\sum_{n\\le x} f(n)$. Then you can write $M(f;x)$ as a Riemann-Stieltjes integral $$ M(f;x) = \\int_1^x \\frac1{\\log t} \\, dG(f;t). $$ (Technically the lower endpoint should be $1-\\epsilon$.) Then integrating by parts gives $$ M(f;x) = \\frac{G(f;x)}{\\log x} + \\int_1^x \\frac{G(f;t)}{t(\\log t)^2} \\,dt. \\tag1 $$ (Even if you don't know Riemann-Stieltjes integrals, you can still verify this last identity by hand - just split the integral up into intervals of length 1, on which $G$ is constant.)\n\nWhen you divide both sides of equation (1) by $x$ and take the limit as $x\\to\\infty$, all that remains to show is that the term with the integral tends to $0$. (Note that $G(f;t)=0$ for $t<2$, so there's no problem with the integral at the lower endpoint.)\n\nshare|improve this answer\n(+1) I just realized my answer is essentially the same thing, I didn't see it at first because I'm not used to RS integration. The integrand in $\\mathrm{(1)}$ is $(A+o(1))/t$ so its integral divided by $x$ is $\\frac{\\log x}{x}(A+O(1))$ which is $o(1)$. Thus the arithmetic mean exists and equals $A$. \u2013\u00a0 anon Oct 1 '11 at 9:40\nTrue ... the integrand is in fact $(A+o(1))/\\log t$, but the integral still turns out to be $o(1)$. \u2013\u00a0 Greg Martin Oct 2 '11 at 3:29\nOh yes, you're correct. \u2013\u00a0 anon Oct 2 '11 at 3:43\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55065/maximizing-the-smallest-eigenvalue-of-a-diagonally-dominant-matrix/55072\nText:\nTake the 2-minute tour \u00d7\n\nAssume that we have a full-rank diagonally dominant matrix $A$, all the diagonal elements of which are positive, all the non-diagonal elements are negative, and the sum of the absolute values of the non-diagonal elements is equal to the diagonal element. More precisely: \\begin{equation} A=[a_{i,j}] \\qquad a_{i,i}>0 \\qquad a_{i,j} \\leq 0 \\textrm{ for $i \\neq j$} \\quad \\textrm{and } \\quad a_{i,i}=\\sum _{j\\neq i}|a_i,_j | \\end{equation}\n\nWe also have a positive diagonal matrix $D$ whose trace is constant and equal to $K$: \\begin{equation} d_{ij}=0 \\textrm{ for } i \\neq j \\qquad d_{ii} \\geq 0 \\quad \\textrm{and } \\quad K=\\sum_{i}d_{i,i} \\end{equation}\n\nWhat is the matrix $D$ such that the smallest eigenvalue of the matrix sum $T=A+D$ is as large as possible? In other words, how can we find the $d_{ii}$ 's such that we maximize the smallest eigenvalue of $T=A+D$? Thank you all in advance! :-)\n\nshare|improve this question\nThe existence of such matrix is easy to prove, do you want to find it's coefficients? \u2013\u00a0 Kate Juschenko Feb 10 '11 at 22:05\nWe need to find the elements of the diagonal matrix $D$, such that the real part of the eigenvalue with the smallest real part is as large as possible. If finding this matrix is easy, could you please give me some pointers on where to look? Thanks! :-) \u2013\u00a0 Maria Kinget Feb 10 '11 at 23:18\nBecause everything acts on a finite-dimensional Hilbert space such matrix always exists. I don't know how to find it's coefficients. \u2013\u00a0 Kate Juschenko Feb 10 '11 at 23:58\nThe smallest eigenvalue (or the real part of the eigenvalue with smallest real value) of a matrix is a nonconvex function of the matrix. Thus I would expect this to be a hard nonconvex optimization problem unless something special about the additional structure of your problem simplifies things. \u2013\u00a0 Brian Borchers Feb 11 '11 at 0:53\nYou say the matrix $A$ has full rank, but all the row sums are zero, so that the all-ones vector is an eigenvector with eigenvalue $0$. So $A$ can't be full rank. \u2013\u00a0 alex Feb 24 '11 at 21:55\n\n2 Answers 2\n\nIf the A matrix were symmetric (so the eigenvalues are real), then you could just solve a semidefinite programming problem (SDP) to find the matrix D (and 'lambda'). In particular, maximizing the smallest eigenvalue ('lambda') of the matrix A + D in your case would be equivalent to the SDP (over variables D and lambda):\n\nmax lambda such that: A + D >= lambda I Trace(D) = K D_{ii} >= 0\n\nwhere the first '>=' denotes 'greater-or-equal in the cone of positive semidefinite matrices', and I is the identity matrix.\n\nThere are several MATLAB-based packages in which you can formulate and solve problems like this (for instance, Yalmip and CVX). You'll probably also need a solver for SDPs (e.g., sedumi or sdpt3). Good luck, -Dan\n\nshare|improve this answer\n\nMaximize what? The smallest eigenvalue is complex... Do you want to maximize the absolute value of the smallest eigenvalue?\n\nshare|improve this answer\nThe question states that the entries of A and D are real (and even states what their signs should be). So, if A is symmetric, then the eigenvalues will be real. (The nonsymmetric case seems less natural, although you could study it as well.) \u2013\u00a0 David Speyer Feb 10 '11 at 20:35\nWrong on three counts: The smallest eigenvalue is real, by Perron-Frobenius. The convention chosen in the question has row sum zero, so actually the all-ones vector is a right eigenvector. Choosing equal diagonal entries is not always the best you can do, as you can see by the example $A = \\left[\\begin{array}{rr}1 & -1\\\\\\\\ 0 & 0 \\end{array}\\right]$ and $K=1$. \u2013\u00a0 Tracy Hall Feb 10 '11 at 20:36\n@Tracy: How does P-F tell you that the smallest eigenvalue is real? \u2013\u00a0 Igor Rivin Feb 10 '11 at 20:39\n@Igor: Apply it to $tI -A-D$ for large enough positive $t$, such as $t=\\mathrm{tr}(A)+K$. \u2013\u00a0 Tracy Hall Feb 10 '11 at 20:55\nWe need to maximize the real part of the eigenvalue with the smallest real part. Thanks for pointing this out! :-) \u2013\u00a0 Maria Kinget Feb 10 '11 at 21:28\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2770005/number-of-ways-putting-m-nonadjacent-balls-in-a-nnn-chess-board\nText:\nI'm trying to solve a problem by using combinatorics. The problem goes like this:\n\nI want to place $m$ balls in a $n\\times n\\times n$ chessboard. No two balls should be adjacent. Thus, no two of them should be the nearest neighbor (each location in the chessboard has six nearest neighbors).\n\nFor example: if a ball is placed at (1,1,1), there must be no ball at (0,1,1), (1,0,1), (1,2,1), (2,1,1), (1,1,0), (1,1,2).\n\nFor the ball at the corner location, like (0,0,0), there must be no ball at (0,0,1), (0,1,0) and (1,0,0).\n\nHow many different ways to put these $m$ balls? Is this problem solvable in general? Is it possible to write down a generating series for such problem?\n\n  \u2022 $\\begingroup$ If two rooks are at (0,0,0) and (0,1,1) are they attacking? Or do they need to differ by 1 in only one coordinate to attack? [Also suggest not calling them rooks] $\\endgroup$ \u2013\u00a0coffeemath May 7 '18 at 2:22\n  \u2022 $\\begingroup$ No, they are not, if a rook is placed at (0,0,0), only rooks on (0,1,0), (1,0,0),(0,0,1) can attack it. $\\endgroup$ \u2013\u00a0Lonitch May 7 '18 at 2:25\n  \u2022 $\\begingroup$ Sorry for the confusion, I have changed them to \"balls\" and added an example @coffeemath $\\endgroup$ \u2013\u00a0Lonitch May 7 '18 at 2:49\n  \u2022 $\\begingroup$ The problem is rephrased, sorry for the confusion @darij grinberg $\\endgroup$ \u2013\u00a0Lonitch May 7 '18 at 2:51\n  \u2022 $\\begingroup$ Now that it's been clarified, I think it's a good question (will upvote) Note that positions on a side or at a corner have less than 6 nearest neighbors. $\\endgroup$ \u2013\u00a0coffeemath May 7 '18 at 9:53\n\nQuick answer is there isn't a formula and there is unlikely to be one in the future.\n\nIn terms of graph theory, the request is for the number of independent vertex sets of size m in the n X n X n grid graph. A search of Oeis for 'independent sets' gives hundreds of results and a search for 'nonattacking' gives even more - so efforts have been made on many graphs. In general, counting independent sets on a random given graph is NP complete, but the grid graph isn't random so that doesn't apply here.\n\nIt is easiest to start by looking at the n X n grid or even k X n grid for some fixed k. In Oeis a lot of these will be found under 'nonattacking wazir'. The main sequence counting all independent sets on the n X n grid is A006506 (37 terms are known) and that for the n X n X n grid is A292702 (just 4 terms known). [that last one could probably be raised to 5 or 6 - since 36(6^2) is no more than 37]. For an n X k grid there is A089934 and that is probably the easiest place to begin. Each column (fixed k) is a linear recurrence. The best known method for enumeration is to construct a state machine that processes the grid row by row - after each row is added what is behind the final row is no longer relevant (except the count of the number of balls that have been added). The number of states required is the number of ways of placing balls in that final row which is given by the Fibonacci numbers. Using symmetry it is possible to reduce the number of states by approximately two and it turns out that this number of states almost always exactly matches the order of the linear recurrences, suggesting that there is a level of complexity that cannot be easily removed. For the n X n X n grid the frontier consists of a n X n slice through the grid.\n\nYour question is actually asking for more detail - not just the total number of independent sets, but only those of a specific size. For small m these will be polynomials. (most obviously for m=1). For the n X n grid there are sequences in Oeis that cover small m (A172225, A172226, A172227, A172228, A178409, A201507, A201508, A201510) but I am not sure anybody has bothered to create them for the n X n X n grid.\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Thanks for your reply, I'm actually thinking about building a state machine like the one you suggested above. $\\endgroup$ \u2013\u00a0Lonitch May 8 '18 at 4:06\n\nYour Answer"}
{"text": "Retrieved from https://mathhelpboards.com/threads/manipulating-quadratic-and-exponential-expressions.26380/\nText:\nWelcome to our community\n\nBe a part of something great, join today!\n\nmanipulating quadratic and exponential expressions\n\n\nNew member\nJul 19, 2019\nI am having so much trouble figuring this out, I would really appreciate some help.\n\nThe question is:\nThe following function, L, gives the approximate percent literacy rate in India t years after 1900.\n\nL(t)=5.3 x 1.025^t\n\nWhich of the following equivalent functions shows, as a constant or coefficient, the approximate number of years it took for the literacy rate to triple?\n\n(a) L(t)=5.3 x 3^t/44.5\n(b) L(t)=5.3 x 1.077^t/3\n(c) L(t)=5.3 x 1.008^3t\n(d) L(t)=3 x 1.025^t+23\n\nThanks so much. I know what the answer is, but I just have no idea why it is the answer. I just want to understand :(\n\n\nWell-known member\nMHB Math Helper\nMar 1, 2012\nNorth Texas\ninitial literacy percentage is $L(0) = 5.3 \\cdot (1.025)^0 = 5.3$\n\ntriple literacy percentage is $3 \\cdot 5.3$ ...\n\n$3 \\cdot 5.3 = 5.3 \\cdot (1.025)^t$\n\n$3 = 1.025^t$\n\n$\\log(3) = t\\log(1.025) \\implies t = \\dfrac{\\log(3)}{\\log(1.025)} \\approx 44.5 \\text{ years}$\n\n... now look at equation (a)"}
{"text": "Retrieved from https://math.stackexchange.com/questions/948098/determine-the-nth-string-among-those-of-a-given-length-in-alphabetical-order-s\nText:\nWhen building strings using a particular character set (the set can change), such as in a brute-force password cracking, how would I determine which string occurs in the $n$th position when the strings are ordered alphabetically for each length, starting at a given string? (Conversely, what is the position of a given string among those of the same length, starting at a given string of that length?)\n\nFor example, if the character set is $ABCDEFG$, then among the strings of length 2, starting at $AA$, string $AC$ is in position 3 and string $AE$ is in position 5:\n\n$$\\begin{matrix} \\text{position:}&1&2&3&4&5&6&7\\\\ \\text{string:}&AA&AB&AC&AD&AE&AF&AG \\end{matrix} $$\n\nI am programming in Delphi and want to use a function that returns the string: function CharArrayPosToStr(ca: TCharArray; len, pos: Integer): String;\n\nThe purpose is to break the job into working sets of given lengths, so I need to be able to quickly determine something like: Set 1 starts at $AAAA$ and ends at $AAQA$ and set 2 begins at $AAQB$, etc.\n\n\nThe shortlex ordered list of all words on the seven-letter alphabet $ABCDEFG$ is $$A,B, C, D, E, F, G, AA, AB, ..., GF, GG, AAA, ..., GGG, ...$$\n\nIf we replace the letters $A,B,C,D,E,F,G$ with the nonzero digits $1,2,3,4,5,6,7$, then\nthis becomes the list of positive integers written in bijective base-7 notation (in numerical order): $$1, 2, 3, 4, 5, 6, 7, 11, 12, ..., 76, 77, 111, ..., 777, ...$$\n\nMore generally, in the shortlex ordering of all the words on the digit-set $\\{1, 2, ..., k\\} (k \\ge 1)$, the $m$th word is $a_n a_{n\u22121} ... a_1 a_0$, where\n\n$$\\begin{align} a_0 & = m - q_0 k , & & q_0 = f\\left(\\frac m k \\right) \\\\ a_1 & = q_0 - q_1 k , & & q_1 = f\\left(\\frac {q_0} k \\right) \\\\ a_2 & = q_1 - q_2 k , & & q_2 = f\\left(\\frac {q_1} k \\right) \\\\ & \\vdots & & \\vdots \\\\ a_n & = q_{n-1} - 0 k , & & q_n = f\\left(\\frac {q_{n-1}} k \\right) = 0 \\end{align} $$\n\nand $$f(x) = \\lceil x \\rceil - 1.$$\n\nSo, to find the $m$th word in the shortlex ordering of words on an alphabet of $k$ letters, just use the preceding algorithm to find the bijective base-$k$ numeral for $m$ (and convert back to letters using the reverse substitution).\n\nAlso, note that the list-position $m$ of a given word is obtained simply by making the digit-substitution and then reading the result (say $a_n a_{n\u22121} ... a_1 a_0$) as a bijective base-$k$ numeral: $$ m = (a_n a_{n\u22121} ... a_1 a_0)_{\\text{bijective base-}k} = a_n\\ k^n + a_{n-1}\\ k^{n-1} + ... + a_1\\ k^1 + a_0\\ k^0.$$\n\nIf you're interested in the positions of certain words relative to that of others (i.e. in a particular list segment), just find the relative position by the appropriate subtractions.\n\n\nI realize this is an old thread, but the problem seemed familiar, and I recognized I've had a solution for years. In VBA, you can do it like this:\n\nFunction ShortlexPos(sInp As String, sSym As String) As Long\n  If Len(sInp) Then ShortlexPos = InStr(sSym, Right(sInp, 1)) _\n     + Len(sSym) * ShortlexPos(Left(sInp, Len(sInp) - 1), sSym)\nEnd Function\n\nFor example, columns in Excel are named\n\nA, B, ..., Y, Z, AA, AB, ..., AX, AY, AZ, BA, ... XFD\n\nThe position of the last column is given by\n\n\n... which (correctly) returns 16384.\n\nThe complementary function returns the sequence at a given position:\n\nFunction ShortLexStr(iNum As Long, sSym As String) As String\n  If iNum > 0 Then ShortlexStr = ShortlexStr((iNum - 1) \\ Len(sSym), sSym) & _\n   Mid(sSym, ((iNum - 1) Mod Len(sSym)) + 1, 1)\nEnd Function\n\nFor example,\n\n\nreturns XFD\n\n\nYour Answer"}
{"text": "Retrieved from https://mechanics.stackexchange.com/questions/4495/shifting-stops-when-critically-low-on-gas/22644\nText:\n\u2022 3\n  \u2022 5\n\nThis sounds like it could possibly be an Evaporative Emissions problem involving your fuel tank. The engineering side of fuel systems refer to the amount of air in a fuel tank as \"Head Pressure\". Since fluids are almost impossible to compress, as you gain more air (and use fuel) in the tank it's contents are more easily compressed. The vehicle's computer can see the fuel pressure or EVAP solenoids to see if they are falling within specification. Many times when you have a condition where the tank is empty and problems begin, it is due to either a EVAP problem or vacuum related issue. If you keep your tank filled up, you can actually run the engine on a faulty fuel pump for quite some time. The \"Head Pressure\" of the tank combined with the gasoline's weight will actually assist the pump in pushing it up to your fuel rail when its full. THAT being said, you could additionally have a faulty fuel delivery system and your ECU could be shoving it into limp mode to avoid damage to transmission or engine. Once you fill your tank back up you're essentially making the ECU think the problem is fixed. If it is a vacuum driven transmission, an EVAP leak or vacuum leak from the tank could also cause this.\n\nOne other possibility is foreign deposit in the fuel tank. This can temporarily or permanently clog your fuel pump. Once the fluid reaches a low part of the tank, it can cause a concentration of sediment to pool around where the fuel gets pulled into the pump. You would need to do a full diagnostic analysis of the system to ensure it's one of the above problems.\n\nLets not forget that Chrysler's computer systems aren't the best to begin with lol.\n\n  \u2022 It is a Dodge, not a Chrysler. \u2013\u00a0Linger Nov 20 '15 at 15:51\n  \u2022 3\n    Chrysler Motor Company owns dodge. They purchased it back in 1928 when the brothers that owned the company died. Fiat now owns Chrysler and Fiat owns Alfa Romeo, Chrysler, Dodge, Ferrari, Jeep, Lancia, Maserati, Ram and SRT. Chrysler owned Dodge and Jeep far before Fiat bought Chrysler. \u2013\u00a0cloudnyn3 Nov 21 '15 at 0:11\n\n\nAnyone have thoughts on this idea?\n\n\nI have this same problem on a 1999 Dodge Ram 4x4. Didn't start doing it Until it had 50,000 miles on it.\n\nThe 1999 has only one oxygen censor and throttle body. That said, itss not not a vary smart electronic system so I wouldn't think the system has a limp mode.\n\nI also remember years ago that a deep snow broke a plastic vacuum line under the trany that causes the 4 wheel drive too stop working. I spliced a piece of rubber vacuum hose on the line to fix it.\n\nI don't recall if the low fuel and shift problem started at this time."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/78145/exponentially-different-running-times-random-access-machine-ram-vs-turing-mach?noredirect=1\nText:\nI propose a simple polynomial algorithm for the following problem. Given $m$ integers each one stored on $n$ bits, output the integer that appears the most often.\n\n  1. Reserve a memory area with $2^n$ slots/registers/locations/cells, each cell being long enough to store the number $m$. This requires constant time because we do not initialize/touch the cells. If you agree with this, skip to step 2. Otherwise, check the following four points.\n    \u2022 One could easily be tempted to read \"reserve a memory area\" as \"allocate a memory area\". Actually, the memory allocation operation is an invention/complication of real multi-tasking machines where programs can \"fight\" for memory. If I consider some (Random Access Machine) RAM machine that only knows running my algorithm, I can state that the algorithm can simply use the whole memory. Thus, it is enough to reserve (read \"put aside\" not \"allocate\") the first $2^n$ cells for a an array with $2^n$ elements. The next memory cells are simply used for other variables.\n    \u2022 To be more precise, I consider running my algorithm on a RAM-TM (Random Access Memory-Turing Machine) that is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to move the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics. The RAM-TM has no notion of memory allocation. This seems to be a simplification of the various (Transdichotomous or word) RAM machines out there.\n    \u2022 Even if I must confess I do not really know the exact technical details of all theoretical machines RAM (or RASP), it is possible to work with an exponentially-large memory area and yet use only a polynomially large number of cells and my algorithm is not the first doing this. This also happens in the binary search algorithm over a sorted array: $n$ cells but only $O(log(n))$ time complexity. This scientific paper introduced a data structure that uses a large memory area but has constant time access, see also the answer of zotachidil to this question. My algorithm could work with this data structure instead of explicitly reserving space.\n    \u2022 see Ps 1.\n  2. Go through the $m$ numbers in the input and for each one of them $x$ assign $[x]=0$, where $[x]$ is the memory slot/location number $x$ in the above reserved memory area.\n  3. Go through the $m$ numbers in the input and for each one of them $x$ assign $[x]=[x]+1$.\n  4. Take the first number $x$ in the input and assign $outVal=x$ and $maxFreq=[x]$.\n  5. Scan again the $m$ numbers and for each number $x$ perform: if $[x]>maxFreq$, set $outVal=x$ and $maxFreq=[x]$.\n  6. Output $outVal$.\n\nThe algorithm has time complexity $O(mn)$ assuming $n\\hskip 0.7mm \\not \\hskip -0.7mm \\ll m$ at least on the RAM-TM (see ps 2.), i.e., linear. It is certainly not the only algorithm to solve the problem, but I do not know any other linear algorithm using polynomial memory.\n\nHowever, the big problem is that the algorithm would require exponential time in a Turing machine, no? Does this contradict one of the Extended/Complexity-Theoretic Church\u2013Turing Theses? The section \"Variations\" of the Wikipedia article on the Church\u2013Turing thesis states that \"polynomial-time overhead and constant-space overhead could be simultaneously achieved for a simulation of a Random Access Machine on a Turing machine [55]\", where [55] is \"C. Slot, P. van Emde Boas, On tape versus core: an application of space efficient perfect hash functions to the invariance of space, STOC, December 1984\". Something seems inconsistent. Any help would be greatly appreciated.\n\nps 1. A real-machine argument for the fact one can allocate $O(2^n)$ bits in constant time. Notice I did not say the $2^n$ cells are initialized to some zero values. In a programming language like C this should be achieved by an instruction malloc instead of calloc. In my comment to D.W.'s answer, I provide a reference for a real-life memory allocator that \"performs the allocation/deallocation in constant time\". However, D.W. seem to reject this argument, claiming the above \"constant time\" is calculated by ignoring the fact that we can have $n\\to \\infty$ since in practice $n$ does no go to $\\infty$, if I understood the response. As for me, it is hard to believe this \"constant time\" is actually $O(2^n)$, constant time is really far from $O(2^n)$. I would be surprised to see such large approximations in a paper published by Real-Time Systems.\n\nps 2. Not really essential, but a technical edit: because of Step 5, the complexity of the algorithm should be $O(nm+m\\cdot log(m))$ on a RAM-TM and not $O(nm)$, which is relevant only if $n$ is very very small compared to $m$.\n\n  \u2022 $\\begingroup$ You claim that there is no polynomial time algorithm for a TM machine solving that problem, or you say there is no LINEAR time algorithm for that problem? Time complexity may change depending on what model you choose. But I think your problem is solvable in polynomial time on a deterministic TM. $\\endgroup$ \u2013\u00a0fade2black Jul 20 '17 at 21:28\n  \u2022 $\\begingroup$ Thanks for this reply. I do not really claim there is no Linear algorithm, not essential (by the way, I think the TM needs $O(n^2)$ to compare two numbers on n digits). I agree the deterministic TM can solve it in polynomial time. But the algorithm itself, is it really polynomial on a RAM machine? If yes, how could a TM simulate it with only a polynomial time overhead as stated by the citation from [55]? There are some extended Church-Turing theses claiming the TM can simulate any realistic computation model up to polynomial-time reductions (sec \"Variations\" in the Church-Turing wiki article). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 20 '17 at 21:42\n  \u2022 1\n    $\\begingroup$ You say that \"[...] Turing machine should be able to simulate my algorithm in polynomial time\" but at the same time you demand that you should be able to create a $2^k$ size \"array\" in the RAM model, whereas this must take $2^k$ time in a Turing Machine model. Well, then, of course the TM will be exponentially slower than the RAM machine, but only because you demand it. $\\endgroup$ \u2013\u00a0P\u00e5l GD Jul 21 '17 at 18:11\n  \u2022 $\\begingroup$ Two more things. You need to reserve $2^{n \\log m}$ cells to hold your information, second, in your question regarding binary search, you are given the \"array\" an an input to the algorithm, i.e., the array is already allocated and populated. Nobody claims you're able to construct and populate an array of $n$ elements in $\\log n$ time. $\\endgroup$ \u2013\u00a0P\u00e5l GD Jul 22 '17 at 8:06\n  \u2022 $\\begingroup$ @P\u00e5l GD, thanks for your replies, I agree. If you think I need to edit my question to take these remarks into account, please specify the information I need to update. I said we need $2^n$ cells, each one large enough to store $m$, which is perfectly equivalent to using $2^{n~\\text{log}(m)}$ bits as you said (incidentally, you actually said \"$2^{n~\\text{log}(m)}$ cells\", but I assume you thought about bits). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 11:24\n\nYour algorithm involves an array of length $2^n$. Allocating an array of length $2^n$ takes $\\Theta(2^n)$ time. Consequently, the running time will be $O(m+2^n)$.\n\nAlternatively, you can represent the array in a sparse way using a self-balancing binary tree data structure. Then each access to the array takes $O(\\log m)$ time, so the total running time of your algorithm is $O(m \\log m)$ (assuming we can treat $n$ as a constant).\n\nAlternatively, you could use a hash table to replace the array. Then the expected time per access is $O(1)$ if you use a suitable hash function, so your algorithm will have expected running time $O(m)$ (again, treating $n$ as a small constant). However, this is the expected running time, not the worst-case running time; the worst case could be as bad as $O(m^2)$.\n\nYou seem to have the idea that you can allocate and work with an array of exponential in constant time. I don't think that's correct. What is true is that you can simulate such an array, at the cost of a logarithmic increase in the running time (using the methods I described above). If you care only about whether the algorithm is polynomial-time or not, you can ignore the logarithmic increase, but if you care about the concrete running time, you can't ignore it.\n\nAnd if you really care about the precise running time, you should probably specify the model of computation (e.g., transdichotomous model, etc.). For instance, in the transdichotomous model, if $n$ is guaranteed to be at most the word size (i.e., all of your integers fit within a word), then yes, your algorithm works and runs in linear time -- you can allocate/reserve memory for $2^n$ cells without difficulties. However if $n$ is larger than the word size, you can't. So, giving a precise answer to your question requires specifying a particular model of computation.\n\nRelated: Saving on array initialization.\n\n  \u2022 $\\begingroup$ Could you please expand on why allocating $O(2^n)$ bits requires $O(2^n)$ time? I do not fully agree on this. You think this holds on which RAM machine(s)? Regarding the real-life machines, there is at least a memory allocator that \"performs the allocation/deallocation in constant time maintaining a very low memory fragmentation.\", citing page 150 of [M. Masmano, I. Ripoll, P. Balbastre, and A. Crespo. A constant-time dynamic storage allocator for real-time systems. Real-Time Systems, 40(2):149-179, 2008]. My algorithm should be polynomial when using with this allocator, no? $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:24\n  \u2022 $\\begingroup$ @DanielPorumbel, I haven't read that paper, but my guess would be that it is constant-time in a particular model. Ultimately, memory allocators tend to rely on virtual memory, which tend to rely on a page table datastructure, which are based on a tree data structure, and in the end, as $n \\to \\infty$, the cost of accessing a page you've never accessed before is $O(\\log n)$. (We treat it as $O(1)$ in real machines because in real life $n$ doesn't get very large, but if you want to do asymptotic analysis, arguably it really should be considered $O(\\log n)$ time.) $\\endgroup$ \u2013\u00a0D.W. Jul 21 '17 at 16:44\n  \u2022 $\\begingroup$ So if you're using virtual memory to support memory allocation of extremely large memory regions, of which you write to only a small amount of... you're basically using the \"simulate the array using a tree data structure\" without realizing it. The hardware is doing the tree for you, so it's not visible to you, but it's there. Anyway, if we want to make really precise statements about running time, we have to fix a specific model of computation, and that requires deeper analysis than what's in my answer. $\\endgroup$ \u2013\u00a0D.W. Jul 21 '17 at 16:45\n  \u2022 $\\begingroup$ @ D.W. If you don't trust the memory allocator is really constant-time as claimed (by the way, you seem to accept a complexity of $O(log n)$ which is not $O(2^n)$ and would keep my algo polynomial), please check my first argument below point 1 on the edited question. I can simply consider a RAM machine only for my algorithm. My algorithm would not need memory allocation on this machine, because it can have the whole available memory at its disposal. It can simply put aside the first $O(2^n)$ bits and access them in constant time using the formalization of the RAM machine. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 16:57\n  \u2022 $\\begingroup$ @DanielPorumbel, it's simple since changing $f(n)$ bits requires $\\Omega(f(n))$ time. Because changing a bit in $0$ time is impossible. We consider that machine memory is not essentially bounded by constant unlike computer. $\\endgroup$ \u2013\u00a0rus9384 Jul 21 '17 at 20:50\n\nI would argue that this is not an exponential algorithm on either Random Access Memory or a Turing Machine. On a Turing Machine you could compute as follows (assuming you have a symbol set and state set large enough to cover all of the integers. If not, you are going to have to do a more complex comparison, but that will only be a linear slowdown): Along the tape, alternate cells are the integers, and then counters next to them.\n\nFor each integer in the list:\n    Iterate along the tape, and compare each cell with the current integer\n    If it is the same, increment the relevant counter, otherwise move along the tape.\nOnce you have completed this for all of the integers, iterate along the tape again, and look for the highest counter. Output the integer next to the highest counter\n\nThis algorithm will take $4m$ steps per integer (two out and two back for each integer currently on the tape), multiplied by $m$ integers. It will then take $2m$ time to compare all of the counters, and $2m$ to return to the start to output the answer. This is a total of $4m^2+4m$, which is $O(n^2)$ By using RAM, either a hashtable or an exponential amount of memory can be used. For a hashtable, it is a worst case $O(n^2)$ algorithm, and best case $O(n)$, and with exponential memory it is $O(n)$.\n\nTherefore, in answer to your question, no, it does not have to take exponential time on a Deterministic Turing Machine. Your implementation does, but only because you opted to use an exponential amount of memory. By using RAM, the algorithm can be reduced to $O(n)$ given sufficient memory, or $O(n^2)$ with reasonable limits.\n\nEdited to answer both the comments and the edited question:\n\nWhile the algorithm you use allocates an exponential amount of memory, as you correctly point out it does not write to it. Because of this, the TM can simulate the algorithm without needing the same number of memory locations. Where I have above written the integer to the tape, that is effectively a pointer to your exponential amount of memory. In the interests of simplicity I did not have my array in order, however had I inserted into the middle of the array, rather than appending new values. (at a cost of $O(n)$), then my algorithm would exactly simulate yours.\n\nTo demonstrate this difference, consider the following algorithm:\n\nFor an input of length n:\n    write a 1 to the 2^nth cell\n\nBy your definition, this algorithm is exponential, because the TM would have to move out $2^n$ cells to write. When running this in RAM, it would take constant time. Crucially however, ONLY the $2^n$th cell has been written to, and the rest are undefined. For this reason, the TM could simulate it by writing a 1 to the first cell and ending. I would argue therefore, that this algorithm is constant time.\n\nBased on the above logic, although your algorithm reserves an exponential amount of memory, it only ever uses a linear amount of it (the total amount required to transcribe the input). For this reason, it is not required for the TM to allocate an exponential amount of memory, it can also use a linear amount. This will take either $O(n^2)$ or $O(n^3)$ depending on whether or not you want the array in order.\n\nIn answer to your second point, yes, I sidestepped the issue of the amount of time taken to compare integers. I did this by assuming that the symbol and state set was large enough to accomodate the integers. If you ignore this assumption, there is a further $n^2$ slowdown. (I would note however that it's $n^2$ on the length of a single integer, not on the length of the input as a whole.)\n\nIn conclusion, depending on precisely how you simulate the algorithm, and what you define to be part of the machine vs variable with the input, the TM algorithm can range from $O(n^2)$ to $O(n^5)$, but is definitely polynomial.\n\n  \u2022 $\\begingroup$ Thanks, I agree to what you said. But you actually only prove that the Turing machine solves the problem in polynomial time, using a different algorithm. But the extended Church-Turing theses mentioned at the end of my question seem to say that the Turing machine can simulate RAM machines with polynomial overhead. This would mean that the Turing machine should be able to simulate my algorithm in polynomial time. I don't know how this could happen? $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:30\n  \u2022 $\\begingroup$ A second comment, less important. In the complexity of you Turing Machine (TM) algorithm, do you think the TM can compare two integers on $n$ bits in less than $O(n^2)$? Did you take this into account in the TM complexity calculation? I think this is one of the reasons why multi-tape TMs are useful: they can recognize language $xx$ in linear time, while the TM needs $n^2$ moves, where $n$ is the binary size of $x$. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 21 '17 at 9:40\n  \u2022 $\\begingroup$ @DanielPorumbel, \"simulate the algorithm\" doesn't mean it works exactly identically. The simulation might do all sorts of clever things... including replacing a giant array with a small sorted list, as this answer suggests. $\\endgroup$ \u2013\u00a0D.W. Jul 22 '17 at 1:40\n  \u2022 $\\begingroup$ @C Baish, thanks for the response. As far as I can see, you still use an additional assumption that the input comes alternating the integers and the counters. It is simple to avoid this by using a second tape for the counters. A TM with two tapes can be simulated in quadratic time by a TM with one tape. The second tape could well represent the contents of my utilized memory cells. Less importantly, your $m$ and $n$ notations are a bit confusing, because your $n$ is not my $n$ but it is the input size which is also $m$, assuming \"my $n$\" (size of each integer) is a bounded constant (?). $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 10:42\n  \u2022 $\\begingroup$ @C Baish,@D.W. maybe you both found the key: simulate the huge memory with a polynomial size list. This list can work somehow as a virtual memory with polynomial access time. It is enough to use a lame list, no need for a faster red black tree. I will try to answer the question myself by adapting this ideas to bring the resulting Turing machine closer to what I understand by \"simulation\". As it stands the algorithm of C. Baish is not (yet) a simulation for my taste, because it requires a particular input structure. This can however be easily avoided with a second tape as in my above comment. $\\endgroup$ \u2013\u00a0Daniel Porumbel Jul 22 '17 at 10:52\n\nSo this is what I consider as the pitfalls of abstracting physical computation into a purely mathematical theory. First, to answer your question, by extended Church-Turing, when you implement your algorithm on a physical RAM machine, it will run in exponential time.\n\nThere are some subtle points here.\n\n  1. To access a uniformly random memory cell among all $2^n$ cells (of constant size, say, of bits), assuming general relativity and quantum mechanics, there is no way you can do this in $o(2^{n/3})$ time (proof left as exercise, hint: use concentration of volume).\n  2. There are no contradictions because when you reduce a RAM program with time $T$ and space $S$ into a Turing machine, the running time of the Turing machine will be ${\\sf poly}(S, T)$. So extended Church-Turing thesis is robust as long as you don't use superpolynomial space. See also: Strongly polynomial time v.s. weakly polynomial time, although this particular example is not a typical example of weakly polynomial time.\n\nTo conclude, extended Church-Turing thesis really considers reasonable computational models, and the seeming contradiction really stems from the fact that you are making an unreasonable assumption that RAM access only costs constant time.\n\nP.S. You can also consider similar \"speed-ups\" in the circuit model, in fact, you can prove that circuits can decide everything (including undecidable problems) in as much time as one needs to read the input.\n\n  \u2022 $\\begingroup$ Welcome to CS.SE! $\\endgroup$ \u2013\u00a0D.W. Apr 3 at 22:48\n\nThanking everybody for the responses, I come myself with a solution that satisfies me at 99.99%, using arguments from your replies. The main idea is that the Turing Machine (TM) can simulate my RAM machine in polynomial time, provided an initialization axiom.\n\nTo be very clear, I can run my algorithm in $O(nm+m\\log(m))$ time on a RAM-TM (Random Access Memory-Turing Machine). The RAM-TM is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to jump the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics, and an input tape. We consider an additional program tape that represent instructions. For instance, scan, $+1$ could mean ''scan the input tape and for each number increment the memory content pointed by the number''. Incidentally, my algorithm also runs in polynomial time on a Transdichotomous RAM machine with word size $w=n+1$. I think D.W. agrees on this (last paragraph of the response).\n\nA Turing Machine (TM) can simulate my RAM-TM in polynomial time, circumventing the fact that my RAM-TM has infinite memory, since the memory tape is infinite. Consider a whole execution of the RAM-TM consisting of running algorithms/programs $A_1$, $A_2$, $\\dots$, $A_p$, where $A_p$ is my algorithm. If the total time complexity of all these runs is polynomial in $p$ and in the total input size of $A_1$, $A_2$, $\\dots$, $A_p$, then the TM can simulate the whole execution in polynomial time.\n\nWe simulate the whole RAM-TM execution using a 2-tape TM, knowing that a 2-tape TM can be simulated in quadratic (hence polynomial) time by a TM. We use the second tape to store the accessed memory cells of the infinite RAM-TM memory. Since the RAM-TM execution is polynomial, the number of accessed cells is polynomial. We can simply use the second tape of the TM to store all accessed memory locations, each location together with its content. Whenever any of the algorithms accesses memory content $[x]$ on the RAM-TM, the 2-tape TM can scan the second tape in polynomial time and search for index $x$ and retrieve the associated content $[x]$.\n\nI said I am satisfied at 99.9%, because I think we still need an initialization axiom. It is not clear what the 2-tape TM should do when it finds no content associated to some index $x$, i.e., if the RAM-TM asks to retrieve an uninitialized memory cell. We use the following axiom: when the RAM-TM is first turned on, the memory tape contains only zeros. This does not mean that my algorithm $A_p$ can rely on the fact that all uninitialized cells are 0. From the viewpoint of $A_p$, uninitialized cells have an undetermined value, due to the previous programs $A_1$, $A_2$, $\\dots$, $A_{p-1}$.\n\nWithout this axiom, the RAM-TM can not be simulated as far as I can see. Imagine a RAM-TM that has the following memory state when first turned on: the infinitely many bits of the memory tape contain the binary digits of $\\pi$. It can solve the following problem: given an integer $n$ as input, return the $n^\\text{th}$ digit of $\\pi$. It can do this by simply returning $[n]$ in $O(\\log(n))$ time, where it needs $O(\\log(n))$ to write $n$ on the index tape. If we try to simulate this using some multi-tape TM with $\\pi$ on one of the tapes, it would need $O(n)$ time to go to the $n^\\text{th}$ location on that tape. $O(n)$ is exponential compared to the input size $log(n)$.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/water-pressure-in-conical-tank-question.9850/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nWater Pressure in Conical Tank Question\n\n  1. Nov 28, 2003 #1\n\n    Another God\n\n    User Avatar\n    Staff Emeritus\n    Gold Member\n\n    I was wondering if anyon could help me out.\n\n    You have a conical tank with a top diameter of 1m, going down to an outlet of 150mm diameter, height of the tank = 3m, and it's full of water. Assuming an air pressure of 15psi, what is the pressure at the 150mm opening? (the bottom)?\n\n    Does the air pressure make a difference due to the nozzle shape of the tank?\n\n  2. jcsd\n  3. Nov 28, 2003 #2\n\n    Are you trying to say something about a pipeline with a wider beginning and a narow end. The water is flowing from the wider end to the narrower end.\n\n    If this is the problem, then u can use bernoulli's theorem,\n    The total energies at both the ends are the same.\n\n    i.e the sum of pressure energy, kinetic energy and potential energy is constant throughout the flow.\n\n    in other words:\n\n    [tex](p^2)/w + gh + (v^2)/2g [/tex] is always a constant. Assuming that flow is downwards in the problem, the height of the 1m openong is 3 m and that of the 150mm end is 0. So using this find the total energy on each side and equate them. Since the same fluid is flowing w-the sp.density is the same. p is the pressure. At the opening the pressure = air pressure.\n    v is the velocity. To find the value of v at both the ends (or atleast cancel out the v term in the equation) u need to use the continuity equation A1*v1 = A2*v2. Using this find, v1/v2, substitute the other values and then find the value of the pressure at the other end.\n\n    Got it???\n\n  4. Nov 29, 2003 #3\n\n    Another God\n\n    User Avatar\n    Staff Emeritus\n    Gold Member\n\n    Yep, that exactly what we meant.\n\n    Thanks for the reply, we'll run some numbers, and get back to you with what conclusions we reach.\n\n    Thanks again.\n  5. Nov 29, 2003 #4\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Nope. Thats one of the trick questions in fluids. Remember - pressure is pressure. The pressure (static and velocity are the same for the various cases you could do here, conveniently) at the bottom is simply the weight density of water times the height. Technically, thats the static pressure, but if the water is flowing, the static pressure at the bottom of the tank is equal to the velocity pressure. So from that you can caluclate the velocity of the water and the flowrate."}
{"text": "Retrieved from https://www.physicsforums.com/threads/conservation-of-energy-inclined-plane-w-spring.539899/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nConservation of energy/inclined plane w/ spring\n\n  1. Oct 13, 2011 #1\n    Problem: A 2 kg mass is held at the top of a ramp 6m above a spring which has a spring constant of 40 N/m (the 6 m distance is measured along the ramp surface). The ramp is at 30 degrees relative to the horizon. Find the speed of the mass as it just strikes the spring 6 meters below the point it was released from. Find how much the spring is compressed. Ignore friction.\n\n    Formulae: PEspring=1/2kx2, KE=1/2mv2, GPE=mgh (we use 10 m/s2 for acceleration due to gravity), and conservation of energy\n\n    The professor said this problem was tricky, but the solution I found seems like it may be too easy. I calculated the gravitational potential energy to be 60J at the top of the incline. At the end of the ramp, where theoretically all of the GPE would be kinetic energy now because \u03bc=0, I calculated the velocity to be 7.75 m/s. Would this be the correct way to go, given that the incline is at an angle?\n  2. jcsd\n  3. Oct 13, 2011 #2\n    The dimensions of the incline are 6m on the hypotenuse, 3m on vertical leg, 5.2m on horizontal leg by trigonometry.\n  4. Oct 13, 2011 #3\n    And also, k=40N/m.\n  5. Oct 13, 2011 #4\n    The solution will become fairly easy if you apply the work energy theorem.\n\n    Initial configuration - ke is 0\n\n    Final configuration (when spring is completely compressed) - ke is again 0\n\n    So between these to configurations, the work done by all the forces should cancel out to be zero.\n\n    W(gravity) {for 6m + compression} + W(spring){For Cmpression ONLY} = 0\n  6. Oct 13, 2011 #5\n    Thanks for the help! I looked in the textbook (there was an example problem that was exactly the same but done backwards and with different values) and they all lined up with your explanation of using the work-energy theorem, and it basically seemed to be the way I worked it at first. I guess the tricky part that he was talking about was figuring out that you need to find the vertical leg of the inclined plane in order to use that value to plug in to find the potential energy.\n\n    Thanks again!"}
{"text": "Retrieved from https://www.physicsforums.com/threads/vector-differentiation-of-velocity-polar-coord.363484/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Vector differentiation of velocity (polar coord.)\n\n  1. Dec 15, 2009 #1\n    The velocity of a particle moving in a plane in polar coordinates is\n\n    [tex]{\\bf{v}} = v_r {\\bf{\\hat r}} + r\\omega \\hat \\theta[/tex]\n\n    where [tex]v_r = \\frac{{dr}}{{dt}}[/tex] and [tex]\\omega = \\frac{{d\\theta }}{{dt}}[/tex].\n\n    By differentiating w.r.t. time, show that the acceleration of the particle is\n\n    [tex]{\\bf{a}} = \\left( {\\frac{{dv_r }}{{dt}} - \\omega ^2 r} \\right){\\bf{\\hat r}} + \\left( {2\\omega v_r + r\\frac{{d\\omega }}{{dt}}} \\right)\\hat \\theta[/tex]\n\n    (The no-subscript v should be bold, as should the a and the r's with hats.)\n\n    Okay, I'm confident I can work this one out, except for one thing: how does that [tex]\\omega ^2 r[/tex] get into the derivative? I assume the [tex]\\bf{\\hat r}[/tex] is a unit vector, so the derivative of [tex]v_r[/tex] should just be [tex]{\\frac{{dv_r }}{{dt}}[/tex] right? Anyway, if anyone could just explain that detail to me, I'll be on my way.\n\n  2. jcsd\n  3. Dec 15, 2009 #2\n    I like writing in the dot notation because it helps me to remember the dependencies of each variable.\n\n\n    So r depends on time and theta depends on time, what are all the variables that now have r in them and theta in them? (Hint: unit vectors might count!)\n    Last edited: Dec 15, 2009"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-about-simple-harmonic-motion.93241/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Question about simple harmonic motion\n\n  1. Oct 9, 2005 #1\n    A square block, with a mass of 3.40 kg and edge lengths d = 6.00 cm, is mounted on an axle through its center. A spring of spring constant k = 1190 N/m connects the block's upper corner with a rigid wall. Initially the spring is at its rest length. If the block is rotated by 3\u00b0 and then released, what is the period of the resulting SHM?\n\n    What type of problem should this be treated as?\n  2. jcsd\n  3. Oct 9, 2005 #2\n\n\n    User Avatar\n    Homework Helper\n\n    It oscillates by rotation ... it's called a torsional oscillator.\n    You look at \"restoring torque\" which returns the object\n    (which responds slowly due to its rotational Inertia) to\n    the equilibrium orientation angle.\n\n    set torque = I alpha , get torque as function of theta.\n    Now it should operationally look like an oscillator eq'n.\n\n    Be careful to keep the omega_(orientation_change_rate)\n    distinct from the omega_(forward trig function argument)\n    omega_ocr has amplitude 3 degrees, while\n    omega_tfa is multiplied by time.\n\n    Enjoy it, this one is fun!\n  4. Oct 9, 2005 #3\n    there are two different omegas? I'm slightly confused. I know for a torsion oscillator, period is usually found using T = (2*pi)*(I/kappa)^(1/2)\n    Inertia can be calculated...but how should I go about getting kappa, setting the net torque = -k*theta?\n  5. Oct 10, 2005 #4\n\n\n    User Avatar\n    Homework Helper\n\n    Torque is force multiplied by perpendicular distance from axis of rotation.\n\n    Tau = -K(d/2)^2 @ sin@ =@ approx"}
{"text": "Retrieved from https://economics.stackexchange.com/questions/34206/unit-elasticity-calculation-question\nText:\nI'm struggling with a math concept dealing with unit elasticity at an undergraduate textbook level. In most problems, we are given a starting price and an ending price as well as corresponding quantities demanded. For example:\n\nWhen bread was ${$2.00}$ a loaf Bobby wanted ${4}$ loaves, when bread prices raised to ${$2.50}$ Bobby wanted just ${2}$ loaves. What is bobby's price elasticity of demand?\n\nTo calculate these we say the percent change in price is ${\\% \\Delta P = \\frac{$2.50-$2.00}{$2.00}=25\\%}$. The percent change is measured relative to the starting price. Meanwhile ${\\% \\Delta Q = \\frac{2-4}{4}=-50\\%}$. Making elasticity ${-2.0}$.\n\nHowever, I came across a problem where essentially it asked what is the elasticity for someone who wants to spend exactly ${$10}$ on gasoline. I first tried to think about this intuitively, \"If price doubles, she'll be able to get half as much quantity no matter the starting price,\" which seems like elasticity of ${1}$. However, I set it up algebraically I get the following: $${Q*P=10 \\implies Q = 10/P}$$\n\nSo I put in some random values of ${P}$, for example ${P_1=$2.00}$ and ${P_2=$2.50}$ for ${\\% \\Delta P = \\frac{$2.50-$2.00}{$2.00}=25\\%}$. Meanwhile, For quantity we have ${Q_1 = \\frac{10}{2}=5}$ and ${Q_2 = \\frac{10}{2.5}=4}$. So that ${\\% \\Delta Q = \\frac{4-5}{5}=-20\\%}$.... Which isn't unit elastic.\n\nSo I turned to calculus and did the following:\n\n$${Q(P)=\\frac{10}{P} \\implies \\frac{dQ}{Q}*\\frac{P}{dP}=\\frac{dQ}{dP}*\\frac{P}{\\frac{10}{P}}=-\\frac{10}{P^2}*\\frac{P^2}{10}=-1.}$$\n\nWhich is unit elasticity. Clearly the discrepancy here is caused by the fact that the derivative has the \"starting quantity\" = \"ending quantity\" since it's the same point. But should we be measuring percent change relative to starting price and quantity? Or relative to starting price, but ending quantity? Or does it depend? And why?\n\n\nYou have to use the midpoint method to resolve this (if I recall correctly).\n\n\nThe reason I may not recall correctly is because the second you introduce calculus into the study of economics, you discard these formulae entirely and (try to) forget they ever existed. You seem to already know calculus, which is probably causing you to be even more confused rather than less, and understandably so.\n\nThe primary purpose of these non-calculus formulations of elasticity is to teach you the intuition around what elasticity is as a concept - I definitely have strong opinions about how well it accomplishes that. :)\n\nEDIT: Just wanted to add that, if indeed the problem is as you're saying it (come hell or high water, Billy is going to spend \\$10 and only \\$10 on gas) then your intuition is right - Billy has unit price elasticity of demand for gas, although in a kludgy sort of way. This is supported by your calculus-based analysis.\n\n  \u2022 $\\begingroup$ Thank you! The material doesn't mention the midpoint method, at all. I think the complication I was having was the disconnect between my intuition about what unit elasticity means and trying to plug in numbers to prove what I was thinking. In some ways it makes sense that it shouldn't be based on the \"starting\" or \"ending\" value since those are relative to our perception of time while it seems elasticity should not depend on such a notion. $\\endgroup$ \u2013\u00a0James Bender Feb 27 '20 at 21:48\n  \u2022 $\\begingroup$ Yeah, the formulas you first encounter are various approximations of the \"correct\" calculus method. In addition to the linear method and midpoint method, there's also an arc-length method, all of which are clearly flawed to the observant student in a way that can't be addressed in class because at the first and second year level, calculus is verboten. Heck, you'll be lucky if you see an integral in undergraduate at all, unless you're studying at a top-tier school. $\\endgroup$ \u2013\u00a0heh Feb 27 '20 at 22:57\n  \u2022 $\\begingroup$ By the way the reason the calculus method is \"correct\" is because it produces expressions that you'll see pop out of solutions to more advanced optimization problems. This allows you to talk about things like the optimal Ramsey price in terms of the price elasticities of the products in question, which helps make intuitive sense of some highly abstract concepts. $\\endgroup$ \u2013\u00a0heh Feb 27 '20 at 22:59\n\nYour Answer"}
{"text": "Retrieved from https://flyingcoloursmaths.co.uk/ask-uncle-colin-elastic-speed-limit/\nText:\nDear Uncle Colin,\n\nI clumsily dropped a particle of mass $m$! Luckily, it\u2019s attached to a light elastic string with a modulus of elasticity of $3mg$ and natural length $a$. The other end of the string is attached to the point where I dropped the weight from.\n\nWhen I say \u2018dropped\u2019, I mean \u2018propelled downwards with a speed of $\\sqrt{3ga}$\u2019, of course. I\u2019m worried it\u2019s going to go too fast! What\u2019s the fastest it goes?\n\n-- Hands Off Our Kinetic Energy!\n\nHello HOOKE! There are a few ways to approach this. You hint at one of them in your name: you can work with the conservation of energy to find out when the velocity stops changing.\n\nThe total energy throughout the travel is made up of (potential) + (kinetic) + (elastic). I\u2019ll take the zero level for height as the point where the particle is dropped.\n\nInitially, then, the energy is $E_0 = (0) + \\left( \\frac 12 m v_0^2 \\right) + 0$, which comes to $E_0 = \\frac 32 mga$.\n\nOnce the elastic becomes taut, let\u2019s write \u2018height\u2019 as $(a+x)$, where $x$ is the extension of the string; the velocity is unknown.\n\n$E_t = -\\left( mg(x+a) \\right) + \\left( \\frac 12 mv^2 \\right) + \\left( \\frac 12 \\lambda \\frac{x^2 }{a} \\right)$. That needs some tidying up: $E_t = mgx + mga + \\frac 12 mv^2 + \\frac 32 mg \\frac{x^2}{a}$\n\nBy conservation of energy, we have $E_0 = E_t$, so $\\frac 32 mga = -mgx - mga + \\frac 12 mv^2 + \\frac 32 mg \\frac{x^2}{a}$.\n\nIt\u2019s still a mess. Everything has a factor of $m$ we can get rid of, and it\u2019s probably good to multiply by 2 as well: $3ga = - 2gx - 2ga + v^2 + 3g \\frac{x^2}{a}$\n\nNow rearrange to get $v^2$ on its own: $v^2 = g\\left( 5a + 2x - 3\\frac{x^2}{a} \\right)$\n\nDifferentiate with respect to $x$ and you get $v \\diff vx = g\\left( 2 - 6\\frac{x}{a} \\right)$, which has its extremum when $2 - 6\\frac xa = 0$, or when $x = \\frac 13 a$.\n\nPutting this back into the $v^2$ equation, we get: $v^2 = g\\left( 5a + \\frac 23 a - \\frac{a}{3} \\right)$, or $v^2 = \\frac {16}{3} ga$. The maximum speed is $\\frac 43 \\sqrt {3ga}$.\n\nAs I say, there are alternative approaches: you can find the maximum speed by looking for the point where the net force is zero; you can model the freefall part of the travel with SUVAT and then use either energy or a differential equation; I\u2019m sure there are other approaches that didn\u2019t spring to my mind.\n\nI hope your particle is all right after its trauma!\n\n-- Uncle Colin"}
{"text": "Retrieved from https://mathoverflow.net/questions/360632/bounds-on-operatornamesgnau-operatornamesgnav-when-u-v-1-leq/360722\nText:\n$\\DeclareMathOperator\\sgn{sgn}$Suppose A is a $N \\times N$ Hermitian and unitary matrix, i.e., $A^{\\dagger}=A$ and $A^{\\dagger}A=I =AA^{\\dagger}$. (Assume all entries are real.)\n\nAnd let $u \\in \\{-1,1\\}^N$, $v \\in \\{-1,1\\}^N$.\n\nSuppose $\\|u- v\\|_1 \\leq \\epsilon N$ (i.e., $u$ and $v$ differ on $\\frac{\\epsilon}{2} N$ coordinates) .\n\nand $\\sgn: \\mathbb{R} \\rightarrow \\{-1,0,1\\}$ be the sign function, i.e., maps all negative numbers to $-1$, and positive numbers to $1$, and $0$ to $0$.\n\nI want a non-trivial upper bound on $$\\|\\sgn(Au)-\\sgn(Av)\\|_1$$ in terms of $\\epsilon$. For example, is it upper bounded by $4\\epsilon N$?\n\n  \u2022 1\n    $\\begingroup$ Since each place where $u$ and $v$ differ contributes 2 to their $\\operatorname L^1$-distance, I guess you want $\\|u - v\\| \\le 2\\epsilon N$, or that $u$ and $v$ differ in at most $\\frac1 2\\epsilon N$ places? $\\endgroup$ \u2013\u00a0LSpice May 18 '20 at 23:12\n  \u2022 $\\begingroup$ @Omnomnomnom, thanks for fixing my bone-headed error of including \\sgn in the subject. $\\endgroup$ \u2013\u00a0LSpice May 19 '20 at 1:24\n  \u2022 1\n    $\\begingroup$ @LSpice No problem. Anyway, Mathjax doesn't behave in an intuitive way. For instance, despite the fact that your command is only defined in the question body, it used to be the case that the command \\sgn would work in any answer-posts below your definition. $\\endgroup$ \u2013\u00a0Ben Grossmann May 19 '20 at 1:26\n\nThere is a straightforward bound.\n\nConsider A to be the $\\log(N)$-fold tensor product of $H= \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$.\n\nA is Unitary and Hermitian. In fact A is just the Fourier transform.\n\nSet $u$ to be all one vector, i.e. $u=(1, 1, 1, \\ldots , 1)^T$.\n\nAnd $v$ is all one vector with the first coordinate set to $-1$, i.e. $v=(-1, 1, 1, \\ldots , 1)^T$\n\nSee $Au =(1, 0 , 0 , \\ldots 0)^T$\n\nand $Av$ has non zero entries in all coordinates.\n\nThus, $\\|\\operatorname{sgn}(Au)-\\operatorname{sgn}(Av)\\|_1 \\geq N-1$.\n\nConclusion. No non-trivial bound.\n\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/103468/a-problem-on-lagrange-interpolation-polynomials/103520\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nBased on a previous question, I had the following conjecture and was wondering if anyone knew how to prove it or find a counterexample.\n\nConsider the polynomial $$ p(t)=c\\frac{(t-x_0)(t-x_1)\\cdots(t-x_n)}{(x-x_0)(x-x_1)\\cdots(x-x_n)}$$\n\nwhere $x_0,x_1,\\ldots,x_n$, and $x$ are distinct and all lie in the interval $[a,b]$, and $c\\neq 0$. The polynomial $p(t)$ is the lagrange interpolation polynomial of degree $n+1$ satisfying $p(x_i) = 0$ for $i=0,\\ldots,n$ and $p(x)=c$. Its $(n+1)$-th derivative is the constant $$p^{(n+1)}(t)=\\frac{c(n+1)!}{(x-x_0)(x-x_1)\\cdots(x-x_n)}$$\n\nConjecture: suppose $f(t)\\in C^{(n+1)}[a,b]$ and satisfies $f(x_i) = 0$ for $i=0,\\ldots,n$ and $f^{(n+1)}(t)>p^{(n+1)}(t)$ for all $t\\in [a,b]$ or $f^{(n+1)}(t)<p^{(n+1)}(t)$ for all $t\\in [a,b]$. Prove that $f(x) \\neq p(x)=c$.\n\nOr find a counter example to the conjecture\n\nshare|cite|improve this question\nup vote 0 down vote accepted\n\nThis is true. If $f(x)=p(x)$, then $f-p$ has $n+2$ distinct zeros, between which lie $n+1$ distinct zeros of $(f-p)'$, between which lie $n$ distinct zeros of $(f-p)''$, and so on, leading to a zero of $(f-p)^{(n+1)}$, contradicting the fact that $f^{(n+1)}\\lessgtr p^{(n+1)}$.\n\nNote that the proof uses neither the fact that $p$ is a polynomial, nor the fact that the function values are zero; it proves the more general fact that if two $C^n$ functions coincide at $n+1$ distinct points, their $n$-th derivatives must coincide at some point in between.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/247183/rational-function-with-special-properties-on-unit-disk\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm now solving the following complex analysis problem.\n\n\"determine the form of rational function in a plane hat has a positive value on unit circle.\"\n\nhint suggested me that such a rational function must have same number of zeros and poles inside unit disk. But I cannot understand that. Using symmetry(Schwarz reflection principle) I can see that number of poles(zeros) inside unit disk is equal to number of poles(zeros) outside unit disk. BUT I CANNOT SEE WHY NUMBER OF POLES AND ZEROS MUST BE EQUAL..\n\ncan anybody give me some suggestion?\n\nshare|cite|improve this question\nup vote 0 down vote accepted\n\nLet $g(t) = \\log(f(e^{i t}))$ for $t \\in [0, 2 \\pi]$. Then $g$ is well-defined, real valued, $g(0) = g(2 \\pi)$ and\n\n$$ g'(t) = \\frac{i \\, f'(e^{i t}) \\, e^{i t}}{f(e^{i t})}. $$\n\nLet $\\gamma$ denote the unit circle then\n\n$$ 0 = \\frac{1}{2 \\pi i}\\int_0^{2 \\pi} g'(t) dt = \\frac{1}{2 \\pi i} \\int_{\\gamma}\\frac{f'(z)}{f(z)}dz $$\n\nand the latter is equal to the number of zeroes minus the number of poles of $f$ on the unit disc.\n\nshare|cite|improve this answer\nI should have theught the argument principle.. Thanks! \u2013\u00a0Detectives Dec 1 '12 at 4:21\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/285270/show-blockmatrix-is-invertible\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $B \\in \\mathbb{R}^{n \\times n}, C \\in \\mathbb{R}^{m \\times n}, m \\leq n$ and $\\operatorname{rank} C = m$\n\nSuppose for every $v \\neq 0$ with $Cv=0$ it is $v^TBv > 0$.\n\nShow: then $A = \\begin{pmatrix}B & C^T \\\\ C & 0 \\end{pmatrix}$ is invertible.\n\nClearly the columns of $\\begin{pmatrix}C^T \\\\ 0 \\end{pmatrix}$ are linearly independent, since $\\operatorname{rank} C = \\operatorname{rank} C^T$. (or somethin like $dim Im(C) = dim Ker(C^T)$ ?)\n\nThen the columns of $\\begin{pmatrix}B \\\\ C \\end{pmatrix}$ are linearly independent, since for every $v \\neq 0$ with $Cv=0$ it is $v^TBv > 0$ which already requires $Bv \\neq 0$ and therefore the kernel is trivial.\n\nBut how to conclude now that these first n columns are idependent from the other m columns and therefore that $A$ is invertible?\n\nshare|cite|improve this question\nA nice way to solve the exercise is to think as if $B$ and $C$ were numbers. How would you find the inverse in this case? Apply \"the same formula\" here. \u2013\u00a0Quimey Jan 23 '13 at 19:49\nWell, but wouldn't i need $B$ to be invertible for the first block? \u2013\u00a0fritz Jan 23 '13 at 19:53\nDon't really get somewhere trying to think about it this way.. \u2013\u00a0fritz Jan 23 '13 at 20:27\n\n$A$ is a square matrix, so invertibility is equivalent to the kernel being trivial. So what you can do is suppose that $v \\in \\mathbb{R}^{n + m}$ is nonzero, and show that $Av$ is nonzero. You can do this by breaking down $v = (v_1, v_2) \\in \\mathbb{R}^n \\oplus \\mathbb{R}^m$, in other words you analyze the problem by matrix multiplying $$ \\begin{bmatrix} B & C^T \\\\ C & 0 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}$$ It is also useful to know that since $\\mathrm{rank}(C) = m$, then the linear map $x \\mapsto Cx$ is onto, so then the linear map $y \\mapsto C^T y$ is one-to-one.\n\nEdit: Here is a more fleshed out solution. Consider the matrix product given above. If $v$ is nonzero, we will show that $Av$ is nonzero. Multiplying out the matrix product, we obtain $$ Av = \\begin{bmatrix} Bv_1 + C^T v_2 \\\\ Cv_1 \\end{bmatrix} $$ If $Cv_1 \\neq 0$, then we are done, so assume that $Cv_1 = 0$. Now, suppose that $v_1 = 0$. Then $v_2 \\neq 0$, in which case $Av = \\begin{bmatrix} C^T v_2 \\\\ 0 \\end{bmatrix}$. Since $y \\mapsto C^T y$ is a 1-1 linear map, then $C^T v_2 \\neq 0$, so then $Av \\neq 0$. Now, alternatively suppose that $v_1 \\neq 0$, but still $Cv_1 = 0$. Then, by the hypothesis, it must be that $v_1^T B v_1 > 0$. Therefore\n\n$$ v_1^T (Bv_1 + C^T v_2) = v_1^T Bv_1 + v_1^T C^T v_2 > v_1^T C^T v_2 = (v_2^T Cv_1)^T = 0,$$ where the last expression is $0$ since $Cv_1 = 0$. Thus the first entry in the vector is nonzero, and hence $Av \\neq 0$ in this case as well. Thus we have shown that $A$ has a trivial kernel, and hence is an invertible matrix.\n\nshare|cite|improve this answer\nThanks for this approach. I considered the following cases: a) $v=(v_1,0)$: so it's either $Cv_1=0$ but then it follows that $Bv_1 \\neq 0$ (since $v_1^TBv_1 > 0$) or it is already $Cv_1 \\neq 0$, done. b) $v=(0,v_2)$: since $y \\mapsto C^Ty$ is one-to-one it is clear that $C^Tv_2 \\neq 0$, done. c) $v=(v_1,v_2)$: ??? \u2013\u00a0fritz Jan 23 '13 at 21:15\nThere doesn't need to be a third case. The two cases are (1) $v_1$ is nonzero, and (2) $v_2$ is nonzero. These cases are not mutually exclusive; all we require is that $v = (v_1, v_2)$ is not zero, so at least one case holds. \u2013\u00a0Christopher A. Wong Jan 23 '13 at 21:17\nOkay, I screwed it up at this point. I focused on $Bv_1 + C^T v_2 = 0$ which I thought might be possible for $v_1$ with $Cv_1 = 0$ and therefore $Bv_1 \\neq 0$ and then thought about why $v_2$ can't be choosen in a way so that $Bv_1 = - C^T v_2$. It would be nice to resolve this mistake, when starting thinking like this? \u2013\u00a0fritz Jan 23 '13 at 21:23\nYes, you need to deal with this case. Perhaps in a short while I will post a more detailed solution. \u2013\u00a0Christopher A. Wong Jan 23 '13 at 21:27\nThanks a lot. Minor note: Am I right, that you actually can't conclude that the first entry in the vector is greater than zero but just that it is different from zero? $v_1^T(Bv_1 + C^Tv_2) > 0 \\not{\\implies} (Bv_1 + C^Tv_2) > 0$? \u2013\u00a0fritz Jan 24 '13 at 6:27\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/2857/non-trivial-colouring-of-the-edges-of-an-infinite-complete-graph?sort=votes\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nCan you build a probabilistic scheme for colouring each edge (independently of all other edges) of the complete graph G on the positive integers such that the probability that G contains an infinite monochromatic complete subgraph is neither 0 nor 1?\n\nshare|cite|improve this question\nThe question has been answered, but I'm still confused. Isn't Ramsey's theorem exactly the statement that there is always a infinite monochromatic complete subgraph, so that the probability would be identically 1? \u2013\u00a0Tom Church Oct 28 '09 at 5:28\nWell the infinite Ramsey theorem holds if you use only finitely many colours, but there is no such assumption here. Does that help? \u2013\u00a0Randomblue Oct 28 '09 at 10:29\nup vote 8 down vote accepted\n\nIt seems like this would go against the Kolmogorov 0-1 law.. If we let Xi denote the coloring of all of the edges from i to integers larger than i, wouldn't the existence of an infinite monochromatic subgraph be a tail event?\n\nshare|cite|improve this answer\nI didn't know the definition of a tail event, nor did I know Kolmogorow's 0-1 law. But yeah, it's seems you are right... Disappointing. \u2013\u00a0Randomblue Oct 27 '09 at 18:28\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162794/maximum-likelihood-estimation-of-an-ornstein-uhlenbeck-process/163220\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI am wondering whether an analytical expression of the maximum likelihood estimates of an Ornstein-Uhlenbeck process is available. The setup is the following: Consider a one-dimensional Ornstein-Uhlenbeck process $(X_t)_{t\\geq 0}$ with $X_0=x$ for some $x\\in\\mathbb{R}$, i.e. $(X_t)_{t\\geq 0}$ solves the SDE $$ \\mathrm{d} X_t=\\theta(\\mu-X_t)\\,\\mathrm{d} t + \\eta\\,\\mathrm{d} W_t,\\quad X_0=x $$ where $(W_t)_{t\\geq 0}$ is a standard Wiener process and $\\eta,\\theta>0$, $\\mu\\in\\mathbb{R}$. If $\\lambda=(\\eta,\\theta,\\mu)$ is the vector of parameters, then the transition densities are known and if $p_{\\lambda}(t,x,\\cdot)$ denotes the density of $X_t$ (remember $X_0=x$) with respect to the Lebesgue-measure, then $$ p_{\\lambda}(t,x,y)=(2\\pi\\beta)^{-1/2}\\exp\\left(-\\frac{(y-\\alpha)^2}{2\\beta}\\right),\\quad y\\in\\mathbb{R}, $$ where $\\alpha=\\mu+(x-\\mu)e^{-\\theta t}$ and $\\beta=\\frac{\\eta^2}{2\\theta}(1-e^{-2\\theta t})$.\n\nSuppose we have observed an Ornstein-Uhlenbeck process in equidistant time-instances (where the parameter $\\lambda$ is unknown), i.e. the vector of observations is given by $$ \\mathbf{x}=\\{x_0,x_{\\Delta},\\ldots,x_{N\\Delta}\\}, $$ where $x_0=x$ and $\\Delta>0$ and $N+1$ is the number of observations. Then by the Markov property of $(X_t)_{t\\geq 0}$ we have that the log-likelihood function is given by $$ l(\\lambda)=l(\\theta,\\eta,\\mu;\\mathbf{x})=\\sum_{i=1}^N \\log\\left(p_{\\lambda} (\\Delta,x_{(i-1)\\Delta},x_{i\\Delta})\\right). $$ Now i am asking if it is possible to maximize this expression with respect to $\\lambda=(\\eta,\\theta,\\mu)$ simultaneously and if so, how would one go about doing this. If anyone can point me in the direction of a paper/book where this is shown, it would be much appreciated. Thanks in advance!\n\nshare|cite|improve this question\ni think that when you discretize the ou process you get a genuine AR(1) process. There is 1 issue with 'exact' mle, but it is perfectly reasonable use OLS type estimates. See Brockwell & Davis or any other time series book. \u2013\u00a0mike Jun 25 '12 at 12:00\nAha, that's a good point! I will surely look into that. Thanks. \u2013\u00a0Stefan Hansen Jun 25 '12 at 12:04\nup vote 3 down vote accepted\n\nIn the paper \"Parameter estimation and bias correction for diffusion processes\" by Tang and Chen explicit formulas for the MLE are given. Their formulas ignore $X_0$, but this makes little difference if the number of observations is reasonably large. I am puzzled how they managed to come up with this formulas, though. Solving $l'(\\lambda)=0$ seem to be a difficult task.\n\nshare|cite|improve this answer\nThat was exactly what I was looking for. Thanks. \u2013\u00a0Stefan Hansen Jun 27 '12 at 7:06\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/69813/residency-time-of-a-spherical-brownian-particle-in-a-cylindrical-container-with\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI place two spherical particles, $P_1$ and $P_2$ (with radii $r_1$ & $r_2$), into a cylindrical container of radius $r_c$ ($r_1$ & $r_2$ $\\leq \\frac{1}{2}r_c$) and height $h$. While $P_1$ is immobilized at the centerpoint of the cylindrical container, $P_2$ has a coefficient of diffusion $D$, and can freely diffuse throughout the container and across its walls (i.e. the boundaries of the cylindrical container are non-reflecting).\n\nWe randomly position $P_1$ and $P_2$ somewhere inside the cylindrical container. Can we derive an expression for the mean residency time of $P_2$ as a function of the relative sizes of the particles and the cylindrical container? Is it a fair approximation to simply estimate the residency time of $P_2$ in a cylindrical container resized to subtract the volume of $P_1$?\n\nUpdate - $P_1$ is now fixed at the centerpoint of the cylindrical container, and $r_1$ & $r_2$ are defined to be $\\leq \\frac{1}{2}r_c$, s.t. $P_1$ cannot block access, say, to half the cylindrical container.\n\nUpdate 2 - In practice, $r_1$, $r_2$, and $r_c$ will be within one or two orders of magnitude of one another, i.e. it is not the case that $r_1$ & $r_2$ $<< \\frac{1}{2}r_c$). Also, all collisions between particles, like the walls of the container, are fully reflecting.\n\nUpdate 3 - I'd be perfectly happy calling the cylindrical container a \"spherical container\" with the same radius, $r_c$. Similarly, I'd be happy to not pin $P_1$ at any particular point, and instead to simply make the walls of the sphere reflecting specifically for this particle.\n\nshare|cite|improve this question\nYou haven't said anything about the relative sizes of the particles and the cylindrical container. Clearly, in one extreme case (P1's radius is as large as the radius of the cylinder so it completely blocks access to part of the cylinder) P1 matters. Just as clearly, P1 doesn't matter in the other extreme case (e.g. the cylinder has a diameter measured in light years and P1 and P2 are the size of small molecules.) You need to tell us something more about what you're actually trying to model... \u2013\u00a0Brian Borchers Jul 8 '11 at 18:21\n@Brian, you're absolutely right. Hopefully the added clarifications will better address your concerns. \u2013\u00a0Rob Grey Jul 8 '11 at 19:56\nNot really. If r_1 and r_2 are far smaller than r_c, then the additional particle shouldn't have any significant effect on the escape time. The problem only becomes interesting if r_1 is big enough. You also haven't told us what happens if particle 1 and particle 2 interact with each other. Does particle 2 just bounce off particle 1? \u2013\u00a0Brian Borchers Jul 8 '11 at 23:28\nRob, there's an hour to go on this bounty, and one answer which is very reasonable. Is there a problem with the answer? \u2013\u00a0Nilima Nigam Jul 20 '11 at 1:23\nup vote 3 down vote accepted\n\nYou can use the Feynman-Kac formula to get the Moment Generating Function of the time it takes the particle to leave.\n\nI will consider the case where you fix $P_1$ and let $P_2$ move. Whatever the geometry of your problem, you can get an equivalent problem with a point particle diffusing in some region in space, where there is one wall that it reflects off (let's call it $\\Gamma_0$) and another where it is absorbed (let's call it $\\Gamma_1$.) Let $X(t)$ be the position of the particle at time $t$. Let $T$ be the time at which the process first hits $\\Gamma_1$. Let $f(x,\\lambda) =E [ e^{\\lambda T} | X(0)=x]$. Then Feynman-Kac gives you that $f$ satisfies $\\nabla^2 f/2 + \\lambda f =0$ with $\\frac{\\partial f}{\\partial n} = 0$ on $\\Gamma_0$ and $f=1$ on $\\Gamma_1$. This is the Helmholtz equation on your domain with mixed boundary conditions. $f(x,\\lambda)$ is the moment generating function of $T$ with $X(t)=x$, evaluated at $\\lambda$. So now you can compute the mean of $T$, etc.\n\nOne geometry for your problem for which you can get an exact solution for each $\\lambda$ is if you have one sphere fixed at the middle of the big sphere and you are tracking a point particle that diffuses, bounces off the small sphere and is absorbed by the big sphere. In that case the solutions to the PDE are spherical Bessel functions.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inertial-problem-is-the-helicopter-still-moving-with-the-speed-of-the-rotating-earth.50285/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nInertial problem:is the helicopter still moving with the speed of the rotating earth?\n\n  1. Oct 29, 2004 #1\n    a helicopter flies up straightly perpendicular to an \"X\" marked on a floor. then, the helicopter keep static in the air when it has reached 10m from the floor. after 5 hours, will the \"X\" still remain right on the floor below the helicopter?\n  2. jcsd\n  3. Oct 29, 2004 #2\n\n\n    User Avatar\n    Science Advisor\n\n    What could make it otherwise?\n    Reilly Atkinson\n  4. Oct 29, 2004 #3\n    actually, my point is that will the X \"moves\" away as the earth is rotating after 5 hours?\n    for example, the earth is rotating with the speed 1km/s(just an example coz i dunno what's the actual speed). will the helicopter remain the speed of 1km/s in the direction of the rotation of the earth while it's floating staticly on the sky. it's because newton's nertial law tells us that the objects inside the same reference frame will have the same speed with the reference frame if no other force is applied to the objects inside. in my question before, the earth is the reference frame and it's moving in the speed of 1km/s and the helicopter is the object inside the reference frame. so, is the helicopter still have the same speed with the earth, which is 1km/s, after 5 hours? if yes, the X will remain 90 degree below of the helicopter.\n  5. Oct 29, 2004 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    that's funny...\n\n    If Newton's law would not apply,it would be a great problem (actaully a fatal one) for those athletes in the high jump discipline.They would definitely be crushed by the stadium approaching them at 465 m/s (at the equator)... :rofl: That's the first example that crossed my mind.Other even more sadistic could be imagined.\n  6. Oct 29, 2004 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I think it was Isaac Asimov that wrote a short story about a scientist, who was very smart but very poor, that found a way to bring any object to a complete stop instantaneously. A rival scientist, less smart, but more famous and rich, publicly ridiculed the poor scientist's theory. The two scientists often challenged each other to billiards, so the poor scientist invited the famous scientist to a demonstration of the first operational 'anti-momentum machine'. The poor scientist demonstrated how his anti-momentum machine worked by shooting a pool ball into the anti-momentum field.\n\n    If you add the rotation of the Earth, the Earth's motion around the Sun, the Solar System's motion about the center of the Milky Way, the Milky Way's motion, etc., etc., it's amazing how fast all those velocities add up.\n\n    I liked that story almost as much his story about the poor soccer referee who made a bad game deciding call against the home team. 100,000 mirror weilding fans focusing their ire into one united effort can really make a referee's blood boil. I referee soccer and always use that story to comfort comrades who've just endured the fury of a critical blown call.\n  7. Oct 29, 2004 #6\n    Let's examine two cases :\n\n    1. As the helicopter gains in altitude, it keeps its inertia in the horizontal direction, as does the air which supports it, so if he is above the equator, would stay right a top the x. (Of course, the pilot has to have the x as a reference over which to fly, but what I mean is that he will not have to make corrections if he is near the equator. I believe \"near the equator\" includes most of the industrial world : up to 60 or 70 degrees in latitude.)\n\n    2. If he is flying above the north pole, he will have to yaw, because the earth and atmosphere will tend to spin under and around him.\n\n    So if he is \"near\" the north pole, then yes, the pilot will have to make corrections to stay over the x. The perceived force is exactly what is called the Coriolis effect and is entirely compatible with all that Newton has to say. The amount of corrections depends on the helicopter's horizontal speed and latitude (+ distance and time of travel), and it does have to be accounted for in self-guided systems or by visual pilots (perhaps unkowingly when flying visual). Even some advanced training simulators (for helicopters and planes) take it into account.\n    Last edited by a moderator: Oct 29, 2004\n  8. Oct 29, 2004 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The helicopter did not maintain a constant speed. It accelerated in order to raise it's height. Even if it is only pushing in a radial direction (directly away from the center of the Earth), the atmosphere is pushing in the direction of the Earth's rotation and giving the helicopter some tangential acceleration.\n\n    However, if the Earth were a vacuum, a push strictly in the radial direction with no tangential component would cause the object to fall behind the Earth's rotation. You add energy, you increase the size of an object's orbit, regardless of how you add the energy - in other words, if a geosysnchronous satellite is accelerated in the same direction of the Earth's rotation instead of radially, it will still increase the size of the orbit and its angular velocity will still fall behind the Earth's angular velocity.\n  9. Oct 29, 2004 #8\n    There is however an initial tangential component of speed, whether atmosphere or vacuum. It is the reason for 2D-directionnal symmetry in our daily lives (high jump, golf etc.).\n  10. Oct 30, 2004 #9\n    if the helicopter is not flying in the vacuum, the air or the wind will become the friction forces to the helicopter. then, the inertial tangential component of the helicopter would be effected by these frictions. with this reason, i suppose that the pilot would see the X \"moving\" away slowly from the below of his helicopter.\n\nHave something to add?\n\nSimilar Discussions: Inertial problem:is the helicopter still moving with the speed of the rotating earth?\n  1. Helicopter's rotation (Replies: 6)\n\n  2. Rotation of earth (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/inverse-of-upper-triangular-matrix.206915/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nInverse of Upper Triangular Matrix\n\n  1. Jan 2, 2008 #1\n    Does anyone know a formula to find the inverse of an upper triangular matrix of dimension n (with a reference preferred)?\n  2. jcsd\n  3. Jan 2, 2008 #2\n    isn't row reduction how you find inverses? as in augment the matrix with the correspondent identity matrix and row reduce\n  4. Jan 2, 2008 #3\n    Yes, I understand. However, I am trying to find a general formula for upper triangular matrices. Something along the lines of the inverse formula for 2x2 matrices. I remember my linear algebra teacher telling us that formulas like that exist for higher dimension matrices.\n  5. Jan 2, 2008 #4\n    Do you remember the analytic formula for the inverse of a matrix from that linear algebra class? Note that the determinant of an upper triangular matrix is just the product of the diagonal components (which are the eigenvalues of the matrix). The cofactors are either 0 or signed determinants of smaller upper triangular matrices.\n  6. Jun 18, 2009 #5\n    For those of you, like me, that just want the answer... here it is (Slider142, please read the item at the bottom re: cofactors and why that doesn't work in this case, sorry):\n\n    My full problem was as follows:\n\n    Given a set of observations and a fixed start-point - in this case acoustic ranges, magnetic and true bearings and some angles, from a ship at sea to towed cables behind it - solve the position in x and y of all other nodes in a network down the length of those cables. For those familiar with surveying, it's a classic triangulation network, using the variation of co-ordinates method of least squares.\n\n    Underlying this is the fact that this network is VERY large, needs to be solved millions of times during a survey and at a minimum, once every few seconds as a boat moves forward acquiring data in real time. There are more than 10,000 observations and more than 1500 nodes to solve.\n\n    I firstly designed a Normal Matrix, A (for those interested 'A' is actually C'WC where C is a design matrix of observations).\n\n    Then, having obtained 'A' I formed 'b' - a simple vector (again, for those interested, 'b' is actually A'Wb where this 2nd 'b' is just the observed minus computed observations for the current estimate of node positions)\n\n    What I need is x, in Ax=b, where x is a vector of the corrections I need to make to positions of the nodes from their currently estimated position.\n\n    Having found x, I will then correct the node positions by this amount, go back to the beginning and re-iterate until such time as the node positions are not changing.\n\n    Now, and here's the rub - no observation is ever perfect, and eliminating 'bad' or unacceptaby bad observations requires a solution to the inverse of A to be found and used.\n\n\n    (again, for those interested, I need a solution of C.A^-1.C', to work out the normalised residuals, or w statistic, and eliminate the worst offender from the network and re-solve)\n\n    In summary:\n\n    I needed the least squares solution of a system Ax=b AND the inverse of the Sparse, positive Definite, symmetric Matrix, A, to enable data snooping using the w-test, which can only be done by multiplying items by the inverse of A. I then need to eliminate bad data and re-compute the network from the beginning. That's the problem. Within the solution I'll need to compute the inverse of a triangular matrix.\n\n    My solution\n    Start with an initial approximation of the node positions, and set x to zero.\n\n    1. Firstly, compute A - which is sparse, positive definite and symmetric - and store it. Computing and storing it is most efficiently achieved by using CSR (Compressed Sparse Row) format - essentially only storing non-zero values and indexes instead of the whole matrix.\n\n    2. Compute b - store this as a vector.\n\n    3. Apply a matrix row re-ordering algorithm to minimise the work required in the next step, Cholesky decomposition. I used Banker's algorithm for this - generally recognised as being better than Reverse Cuthill-McKee (RCM)\n\n    4. Decompose A, using Cholesky decomposition - but store the result as a simple vector of values of a triangular matrix, including zeros. This is because in computing the Cholesky decomposition the same structure as the original matrix is not preserved and so a large amount of manipulation and data 'insertion' (which is time consuming) can be avoided simply by storing it as a simple vector.\n\n    5. Take the matrix stored as a vector in 4 and put it into CSR format for the next step.\n\n    6. Use Forward and Backward Substitution to solve for x, using CSR format thoughout and storing the result, x, as a simple vector. It is important to use CSR format for this, otherwise it becomes very time consuming.\n\n    7. Having solved for x, apply the corrections to node positions and go back to the beginning, using these updated positions for all nodes as the new estimate of position and put x back to zero.\n\n    8. When no further useful changes in position are occurring - or the solution has converged - then the work starts... we now need to assess an estimate of the error from each observation. the w-statistic needs to be computed.\n\n    this is where The inverse is needed - we compute it using the latest value of the Cholesky factor, determined above - let's call it L - which is Triangular.\n\n    The inverse of A is the inverse of L (call it Li) multiplied by it's own transpose, Li.Li'\n\n    Here's where the inverse of a triangular matrix comes in, as L is triangular - but I simply don't have the time to do a naive solution - I need the fastest available because my L is over 1500 rows and may be up to 3000 rows long.\n\n    So, store L as CSR format and use the fact that ONE VECTOR (one column) of the inverse can be computed from FORWARD SUBSTITUTION as follows:\n\n    Let L.Li = I where I is one vector of the identity matrix...\n\n    (Any Matrix, times it's own inverse, is the identity matrix...)\n\n    For One vector of Li, use forward substitution to solve L x Li = [1,0,0,0,0...0] - Store the resulting vector as the 1st column of Li...\n\n    Then use the next vector, [0,1,0,0,0,0....0], and the next [0,0,1,0,0,0,0....0] and so on, building up a solution to Li column by column.\n\n    The use of CSR format in this is vital to keep the computation time to a minimum.\n\n    This works because forward substitution, when using CSR format on a sparse matrix, is very fast.\n\n    et voila, we have the Inverse of a triangular matrix using the minimum possible flops (or at least I believe it to be the minimum possible... ANYONE who knows a faster way, PLEASE, PLEASE, PLEASE let me know!!\n\n    The next problem, for me, is to compute Li.Li' - ie. a Triangular x it's own transpose in the minimum possible time, ie. the minimum number of flops.\n\n    This seemingly trivial, final operation, actually takes more time than the entire of the solution above when the matrix is large (which it always is.)\n\n    One final thing, for those interested - if you are wondering why I didn't use Conjugate Gradients for the least squares solution... it's because although that IS faster than cholesky decomposition, it is numerically unstable when computing the inverse as a sum of it's components - rounding error really kills it. Otherwise it would be beautiful, and quick. if anyone knows a way of stabilising CG, please let me know!\n\n    Well, that's it - I genuinely hope to have been of use to someone out there... it's taken me quite a while to hammer out the method above. Unlike many of you, I'm not a student or professor - just a guy trying to do a job in the real world. So please, if it is useful or if you see something I missed, or a way of improving it, please DO let me know.\n\n\n    Mike Li, from New Zealand.\n\n  7. Jun 18, 2009 #6\n    Sorry Slider142 - got carried away and forgot to say why cofactors don't work quite as simply as you suggest here...\n\n    When you form the cofactor by eliminating a row/column, some of the resulting matricies are not triangular any more - which means the determinant needs to be found of a full matrix, not a simple triangular one. For the others you're right, they're either 0 or the product of the diagonals.\n\n    That makes the solution a whole lot more complex... consequently it's quicker and easier to use forward substitution to find the inverse of a matrix, one vector at a time from L.Li = I where L is a triangular matrix and Li is 1 vector of it's inverse and I is one vector from the identity matrix.\n\n\n    Mike Li.\n\nHave something to add?\n\nSimilar Discussions: Inverse of Upper Triangular Matrix"}
{"text": "Retrieved from https://www.physicsforums.com/threads/multiple-percentages-probability.134225/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nMultiple Percentages Probability\n\n  1. Sep 30, 2006 #1\n    Hi, I seem to be having problems calculating this out. My friends were asking me how to caculate multiple precentages and I thought it would be easy but I got a little stuck. Here is the problem.\n\n    Lets say there is a program that spits out the words yes and no. 60% chance it says yes and 40% chance it says no. If I hit it once, there is a 60% chance it says yes and a 40% chance it says no. If I click it 7 times and it says yes 6 times, what are the odds? I put .6^6 to calculate it, but it seems that I don't include the fact that it says no once. Also, what would the odds be if it said yes all 7 times or no all 7 times? How would you calculate these percentages?\n\n    Thanks alot, seems like a great forum so far.\n  2. jcsd\n  3. Sep 30, 2006 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You're looking for what's called the binomial distribution.\n\n    The odds of exactly 6 out 7 \"yes\" is (7 choose 6) * 0.6^6 * 0.4 ^ 1. Let me explain. You are getting 6 \"yes\" and 1 \"no\"; the chances of getting those answers []in that order[/i] is 0.6^6 * 0.4 ^ 1. Since you don't care about the order, you need to multiply this by the number of ways to choose 6 elements out of 7. In general, (x choose y) is\n\n\n    For (7 choose 6), that's 7!/(6! * 1!) = 7, giving a total probability of [itex]7\\cdot0.6^6\\cdot0.4^1[/itex].\n  4. Sep 30, 2006 #3\n    Thanks so much\n    I cant believe someone actually solved this for me in such a clear manner.\n    This forum is great!\n  5. Sep 30, 2006 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'm glad to have helped. o:)\n\nHave something to add?\n\nSimilar Discussions: Multiple Percentages Probability\n  1. Percentage help (Replies: 7)\n\n  2. Multiple Percentages (Replies: 2)\n\n  3. Percentage reduction (Replies: 10)"}
{"text": "Retrieved from http://mathinsight.org/penicillin_clearance_model\nText:\nMath Insight\n\nConstructing a mathematical model for penicillin clearance\n\nIn developing a model of bacteria growth, we detailed every step of building the model from the data. Since we assumed the change in the population size in one time step was a linear function of the population size, the model was so simple that we could even solve it. We ended up with a fairly simple expression showing the exponential growth of the population size.\n\nHere we'll examine a situation that seems completely different. We'll look at what happens when we give a patient a bolus injection (a one-time injection) of penicillin. In this case, of course, the penicillin won't start multiplying like bacteria in the patient. Instead, the body (i.e., the kidneys) will start removing the penicillin from the body. However, if we make a model where the amount of penicillin removed is a linear function of the amount penicillin in the blood, the model is starting to look a lot like the bacteria growth model. In fact, we'll get exponential decay of the amount of penicillin in the blood.\n\nThere's one more big difference between the bacteria growth example and this page. Here, we'll just get you started on the process, giving you background information about the drug clearance. We then let you go make the model on your own.\n\n\nWhen penicillin was first discovered, its usefulness was limited by the efficiency with which the kidney eliminates penicillin from the blood plasma (blood minus blood cells) passing through it. The modifications that have been made to penicillin (leading to amphicillin, moxicillin, mezlocillin, etc.) have enhanced its ability to cross membranes and reach targeted infections and reduced the rate at which the kidney clears the plasma of penicillin.\n\nEven with these improvements in penicillin, the kidneys can still remove penicillin fairly rapidly. In this project, you will build a mathematical model of penicillin clearance based on an assumption of how the kidneys operate. The secret to your success will be to build into the model a key parameter that captures the speed of the penicillin clearance. Then, you can estimate the model parameter by fitting predictions of the model to data. Lastly, you will compare your model predictions to the data to see how well the model matches the data.\n\nThe assumption behind the model is that the amount of penicillin removed by the kidneys in a five minute interval is proportional to the total amount of penicillin. We can formulate this assumption as a word model for the renal (i.e., kidney) clearance of penicillin.\n\nRenal clearance of penicillin\n\nIn each five minute interval following penicillin injection, the kidneys remove a fixed fraction of the penicillin that was in the plasma at the beginning of the five minute interval.\n\nYour goal is to translate this word model into a mathematical model that has a parameter that determines how much penicillin the kidneys remove in each interval. You can then use the below data to determine this parameter.\n\nThe following table and graph contain data for serum penicillin concentrations at 5 minute intervals for the 20 minutes following a bolus injection (a one-time injection) of 2 g into the serum of \u201cfive healthy young volunteers\u201d (read \u201cmedical students\u201d) taken from T. Bergans, Penicillins, in Antibiotics and Chemotherapy, Vol 25, H. Sch\u00f8onfeld, Ed., S. Karger, Basel, New York, 1978. We are interpreting serum in this case to be plasma.\n\nTime (min)Penicillin Concentration (\u03bcg/ml)\nPenicillin concentration versus time\n\nYour turn\n\nNow its your turn to develop a mathematical model of penicillin clearance. You can use a procedure similar to the one we used to developed the model of bacteria growth. Your model should be based on\n\n  \u2022 the above data, and\n  \u2022 the assumption that the drop in penicillin concentration each 5 minutes will depend linearly on the concentration.\n\nIf all goes well, you should be able to create a model that has an unknown parameter, fit the model to determine that parameter from the data, and then compare your model prediction to the data to see how well you did.\n\nWhen you are all finished, you can compare your results to some findings from the research literature. Analysis of some numbers from the research literature seems to indicate that the all of the blood plasma of a human passes through the kidneys every 5 minutes and that the kidneys remove about 20% of the penicillin in the blood that passes through them.1 You can determine if your analysis of the above data yields a result close to that rate of clearance.\n\nInstructions from writing up the penicillin project are here.\n\nFor more practice on building dynamical system models, try out the exercises."}
{"text": "Retrieved from http://math.stackexchange.com/questions/93808/what-is-the-smallest-convex-set-includes-all-smooth-unit-curves\nText:\nTake the 2-minute tour \u00d7\n\nI try to understand: is there a smallest in area convex set that every smooth curve with length 1 can be placed inside it by translation and rotation?\n\nI only have a upper bound $S \\leq \\frac14+\\frac{\\pi}{16}$ because of convex hull of two circles radius $\\frac14$ and simple lower bound $S\\geq\\frac1{4\\pi}$.\n\nDoes this set exist and what is its length?\n\nshare|improve this question\nIs your question the same as this one on MathOverflow? Smallest area shape that covers all unit length curve \u2013\u00a0 Rahul Dec 24 '11 at 3:19\nOh, I've searched here, not on the MathOverflow because this problem looks so pretty simple. Thx. \u2013\u00a0 sas Dec 24 '11 at 4:33\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nThis is entry D18, \"The worm problem,\" in the book Unsolved Problems in Geometry (Croft, Falconer, and Guy, 1991):\n\nLeo Moser asked what are the minimal comfortable living quarters for a \"unit worm\"?\n\nThey credit the smallest cover yet discovered to Gerriets & Poole (in 1973 or 1974), and describe it as a \"certain truncated rhombus of area less than $0.286$...\". Maybe someone will have a link or reference to the particular shape? For your bounds, I would only point out that the convex hull of a semicircle of arclength $1$, with radius $1/\\pi$ and area $1/(2\\pi)$, gives a better lower bound (of $0.159...$).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/190053/field-extension-question-basis-cannot-be-expressed-as-linear-combination\nText:\nTake the 2-minute tour \u00d7\n\nSuppose I have a field extension K of F with basis $\\{1,\\beta\\}$, $\\beta\\in K^*/F^*$.\n\nHow do I show that $\\beta^2$ cannot be written as $c_1+c_2\\beta$, where $c_1,c_2\\in F, c_2\\ne 0$ unless $\\beta^2 \\in F^*$?\n\nFor example, if $K=\\mathbb{Q}(\\sqrt 2)$, $F=\\mathbb{Q}$, I would want to show that $2$ cannot be written as $c_1 +c_2 \\sqrt{2}$, where $c_i \\in \\mathbb{Q}, c_2\\ne 0$, unless 2 is in $\\mathbb{Q^*}$, which it is. This follows by arguing that $\\sqrt{2}$ is irrational, but how do I do it in the more general setting as in above?\n\nSincere thanks for help.\n\nshare|improve this question\nBut 2 is $2+0\\sqrt{2}$. Take $c_1=2,c_2=0$. \u2013\u00a0 Sigur Sep 2 '12 at 15:27\nIf $\\{1,\\beta\\}$ is a basis for $K$ over $F$ then every element of $K$ can be written as $c_1+c_2\\beta$ where $c_1,c_2 \\in F$ in particular $\\beta^n$. \u2013\u00a0 JSchlather Sep 2 '12 at 15:29\n@Sigur That was fast! I edited my question above. \u2013\u00a0 yoyostein Sep 2 '12 at 15:29\n@JacobSchlather Thanks (+1), but I just added a new condition that $c_2\\ne 0$. \u2013\u00a0 yoyostein Sep 2 '12 at 15:32\nThe intended question seems to be muddled. If $\\{1, \\beta\\}$ are an $F$-basis of $K$, then necessarily $\\beta^2$ can be written (uniquely) as $c_1+c_2\\beta$ with $c_1, c_2\\in F$. Then $X^2-c_2 X - c_1$ is the minimal poylnomial of $\\beta$. As it is irreducible, we conclude that is $c_1=0$ is impossible. However, $c_2=0$ is equivalent to $\\beta^2=c_1\\in F$. \u2013\u00a0 Hagen von Eitzen Sep 2 '12 at 17:14\n\n1 Answer 1\n\nThis is still false. Let $F=\\mathbb{Q}$, $K=F(\\sqrt{2})$ and $\\beta=1+\\sqrt2$. Then $$ \\beta^2=1+2\\sqrt2+2=3+2\\sqrt2=1+2\\beta. $$ Here $c_2=2\\neq0$ as requested, but $\\beta^2\\notin F$.\n\nIs this really what you wanted to ask?\n\nshare|improve this answer\nOk. This is what the OP really wanted to ask. \u2013\u00a0 Jyrki Lahtonen Sep 3 '12 at 5:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/9277/minimum-for-this-function?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI thought of writing this question Minimum for this function in a different way, if it helps.\n\nI want to minimize $$\\sum_{i=1}^n a_ix_i + \\nu \\sum_{i=1}^n b_i 2^{x_i} ,$$\nwhere $a_i \\in [0,1]$, $b_i \\in (0,\\infty)$, and $x_i \\in [x_{\\min},0)$, and\n$$ \\sum_{i=1}^n 2^{x_i} = 1 .$$\n\n$x_{\\min}$, $\\nu$, $a_i$ and $b_i$ are constants.\n\nI guess the tricky part is to minimize the function while ensuring all $2^{x_i}$ sum up to $1$ for these $n$ variables.\n\nThank you for your patience and help.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nFirst let $x = (x_1, \\dots, x_n)$ and write $f(x) = \\sum_i^n a_i x_i + \\nu\\sum_i^n b_i 2^{x_i}$ and $g(x) = \\sum_i^n 2^{x_i} - 1$. Now the method of Lagrange's multipliers tells you that you have a solution $x'$ iff it is an extremal point of the function $f(x) + \\lambda g(x)$ with $\\lambda$ a parameter to be determined. So you get equations $a_i + (\\nu b_i + \\lambda) 2^{x'_i} \\log{2} = 0$ for all $1 \\leq i \\leq n$. It's now easy to express $x'_i$ as a function of lambda and plugging this into the remaining constraint $g(x') = 0$ to find the lambda and complete the solution. Hope this helps.\n\nshare|improve this answer\nI agree but is this (math.stackexchange.com/questions/9105/\u2026) not going to happen here. I will get a polynomial equation for $\\lambda$, which will be not solvable if degree is greater than 5. \u2013\u00a0 SkypeMeSM Nov 7 '10 at 16:54\nIt will be solvable numerically. \u2013\u00a0 Yuval Filmus Nov 7 '10 at 16:54\nIt will not be solvable in radicals (in general). Is this a problem? Another thing is that x' need not be a minimum but only a stationary point, so you will need to further inspect the stationary points. The minimum can also be attained on the boundary of the domain D(f), g=0 which means that some x_k might be equal to x_{min} but that only reduces the problem to having less variables. \u2013\u00a0 Marek Nov 7 '10 at 17:26\nOk. I understand what you are saying. I guess I got my answer here. :) Thank you all. \u2013\u00a0 SkypeMeSM Nov 7 '10 at 17:29\n\nI don't think rewriting this way helps. In the first place, how would you show that if $y$ is the optimal solution of $\\min_y f(y)$, then $x = 2^y$ is the optimal solution to $\\min_x f(\\log x)$?\n\nshare|improve this answer\nThis is not a good answer. \u2013\u00a0 The Chaz 2.0 Dec 13 '11 at 5:23\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/magnetic-reconnection-vs-double-layers.286458/\nText:\nMagnetic Reconnection vs Double Layers\n\n\n\n    Magnetic reconnection is something that has supposedly been \"tested\" and proven in the lab yet for some reason the lab results keep coming out \"wrong.\"\n\n    Currently when scientists create a \"reconnection\" event in the lab between two electrically charged plasma sheets the \"reconnection\" event takes place at twice the speed MHD theory predicts.\n\n    So far no one has been able to rectify this problem, nor have they been able to produce a \"reconnecting\" magnetic field without first applying current to the plasma sheets they are observing. The reason being obvious of course, in order to create a magnetic field, one must first induce an electrical current. So far, this is the only known way of producing a magnetic field in a plasma that can be tested.\n\n    As soon as the current shuts off, so too does the magnetic field.\n\n    Magnetic reconnection is proposed to account for the sudden bursts of observed kinetic energies that power the aurora's substorms and light up the polar skies. It\u2019s also proposed to account for about a billion other phenomena that I will not get into here.\n\n    Focusing on the aurora, some very interesting facts come to light.\n\n    THEMIS, Viking, FAST, UARS and several other satellites have confirmed the existence of parallel electric fields powering the auroras. Electric fields of course must complete a circuit in order to flow. Without charge deficiency in one area of space, there would be no current flow which is a product of charge equalization.\n\n    Some papers on the findings of parallel electric field aligned currents, otherwise known as \"Birkeland currents\" after Kristian Birkeland, the man who postulated their existence back in 1901.\n    Quasi-static, magnetic-field-aligned (parallel) potentials have been considered the primary source of charged particle acceleration in the aurora where precipitating electrons create a visible display. This finding has been controversial since, at one time, it was widely believed that parallel potentials could not be supported by a collisionless plasma. We present observations from the fast auroral snapshot (FAST) satellite which strongly support this acceleration mechanism and, moreover, show evidence of a second plasma regime region which supports quasi-static parallel potentials.\n    Electron distribution functions measured on the Dynamics Explorer 1 spacecraft are shown to have the characteristics expected in a region of parallel electric fields.\n    Using plasma wave data sampled by the Freja spacecraft from the topside ionosphere during auroral conditions, the possible existence of electric fields with an intense parallel component (a few tens of millivolts per meter) with respect to the Earth's magnetic field is discussed.\n    We present a survey of 64 direct observations of large-amplitude parallel electric fields E\u2225 in the upward current region of the southern auroral acceleration zone, obtained by the three-axis electric field experiment on Polar.\n    Satellite observations have established that parallel electric fields of both upward and downward current regions of the aurora are supported, at least in part, by strong double layers.\n    It is demonstrated that the simultaneous observations on Viking of upward field-aligned fluxes of energetic ions and electrons of energies in the same range may be due to acceleration in field-aligned electric fields, the ions in an upward directed parallel dc field and the electrons in a downward directed parallel field which is fluctuating but appears as quasi-static for the electrons as long as they are in the acceleration region.\n    Magnetic field and particle observations from the Upper Atmosphere Research Satellite particle environment monitor (UARS/PEM) are used to estimate field-aligned currents, electron precipitation energy flux, ionospheric conductivities, and Joule heating rates during the main phase of the November 4, 1993, geomagnetic storm.\n\n    Given that we know field aligned electrical currents exist in the space plasma surrounding earth, some fundamental properties of conducting plasma can be employed to describe the events many astrophysicists currently ascribe to \u201cmagnetic reconnection.\u201d\n\n    So let\u2019s look at some papers, the models, and how they are related to the observed phenomena.\n\n    R. E. Ergun et al.: Double layers in the downward current region of the aurora\n    Nonlinear Processes in Geophysics (2003) 10: 45\u201352\n    These results suggest that large double layers can\n    account for the parallel electric field in the downward current\n    region and that intense electrostatic turbulence rapidly stabilizes\n    the accelerated electron distributions. These results also\n    demonstrate that parallel electric fields are directly associated\n    with the generation of large-amplitude electron phasespace\n    holes and plasma waves\u2026.\n\n    We presented direct observations of the parallel electric field\n    in the downward current region of the auroral zone. The observations\n    are consistent with a strong double layer moving\n    along B at the ion acoustic speed in the same direction of the\n    accelerated electrons. The potential drop extends _10 _D\n    along B. Intense electrostatic emissions are spatially separated\n    from the structure on the high-potential side. Electron\n    phase-space holes emerge from the wave turbulence associated\n    with the double layer.\n\n    The potential structure accelerates electrons to several\n    times their initial thermal velocity which results in a factor\n    of 10 gain from the initial thermal energy. Intense quasielectrostatic\n    wave emissions and electron phase-space holes\n    rapidly modify the accelerated electron distribution. Part of\n    the electron distribution (stagnating electrons) is reflected\n    back into the double layer through interaction with the intense\n    wave turbulence. Thus, the intense wave turbulence\n    may interact with the double layer through this stagnating\n    electron population.\n\n    Singh, N., and G. Khazanov (2003), Double layers in expanding plasmas and their relevance to the auroral plasma processes, J. Geophys. Res., 108(A4), 8007, doi:10.1029/2002JA009436.\n    When a dense plasma consisting of a cold and a sufficiently warm electron population expands, a rarefaction shock forms [ Bezzerides et al., 1978 ]. In the expansion of the polar wind in the magnetosphere, it has been previously shown that when a sufficiently warm electron population also exists, in addition to the usual cold ionospheric one, a discontinuity forms in the electrostatic potential distribution along the magnetic field lines [ Barakat and Schunk, 1984 ]. Despite the lack of spatial resolution and the assumption of quasi-neutrality in the polar wind models, such discontinuities have been called double layers (DLs). Recently similar discontinuities have been invoked to partly explain the auroral acceleration of electrons and ions in the upward current region [ Ergun et al., 2000 ]. By means of one-dimensional Vlasov simulations of expanding plasmas, for the first time we make here the connection between (1) the rarefaction shocks, (2) the discontinuities in the potential distributions, and (3) DLs. We show that when plasmas expand from opposite directions into a deep density cavity with a potential drop across it and when the plasma on the high-potential side contains hot and cold electron populations, the temporal evolution of the potential and the plasma distribution generates evolving multiple double layers with an extended density cavity between them. One of the DLs is the rarefaction-shock (RFS) and it forms by the reflections of the cold electrons coming from the high-potential side; it supports a part of the potential drop approximately determined by the hot electron temperature. The other DLs evolve from charge separations arising either from reflection of ions coming from the low-potential side or stemming from plasma instabilities; they support the rest of the potential drop. The instabilities forming these additional double layers involve electron-ion (e-i) Buneman or ion-ion (i-i) two-stream interactions. The electron-electron two-stream interactions on the high-potential side of the RFS generate electron-acoustic waves, which evolve into electron phase-space holes. The ion population originating from the low-potential side and trapped by the RFS is energized by the e-i and i-i instabilities and it eventually precipitates into the high-potential plasma along with an electron beam. Applications of these findings to the auroral plasma physics are discussed.\n\n    Quoting dic.academic\u2019s definition of a double layer\n\n\n    Another known property of charged plasma that can explain the sudden and dramatic bursts of kinetic energy we see in the aurora substorms is something called an \u201cexploding double layer.\u201d\n\n    Given that we have parallel currents and double layers in the surrounding regions of earths magnetosphere; a simple explanation arises for the sudden substorms:\n\n    Stability: Double layers in laboratory plasmas may be stable or unstable depending on the parameter regime. [Torven, S. High-voltage double layers in a magnetised plasma column] \" (1982) \"Journal of Physics D: Applied Physics\", Volume 15, Issue 10, pp. 1943-1949] Various types of instabilities may occur, often arising due to the formation of beams of ions and electrons. Unstable double layers are \"noisy\" in the sense that they produce oscillations across a wide frequency band. A lack of plasma stability may also lead to a dramatic change in configuration often referred to as an explosion (and hence \"exploding double layer\"). In one example, the region enclosed in the double layer rapidly expands and evolves. [B Song, N D Angelo and R L Merlino Stability of a spherical double layer produced through ionization] \" (1992) Journal of \"Physics D: Applied Physics\", Volume 25, Issue 6, pp. 938-941] An explosion of this type was first discovered in mercury arc rectifiers used in high-power direct-current transmission lines, where the voltage drop across the device was seen to increase by several orders of magnitude. Double layers may also drift, usually in the direction of the emitted electron beam, and in this respect are natural analogues to the smooth--bore magnetron. [ Koenraad Mouthaan and Charles S\u00fcsskind, Statistical Theory of Electron Transport in the Smooth-Bore Magnetron] (1966) \"Journal of Applied Physics\" June 1966, Volume 37, Issue 7, pp. 2598-2606 ] ) (not to be confused with a unit of magnetic moment, the Bohr magneton, which is created by the \"classical circular motion\" of an electron around a proton).\n\n    This idea was put forth by Hannes Alfven after the rectifier incident noted above.\n\n    Double layers and circuits in astrophysics\n\n    Continuing on with \u201cmagnetic reconnection\u201d as a theory, we find it violates known laws of physics. F\u00e4lthammar, does an excellent job describing the problems with \u201cmagnetic reconnection\u201d theory as it pertains to real current carrying plasmas here:\n\n    On the Concept of Moving Magnetic Field Lines\n    Eos, Vol. 88, No. 15, 10 April 2007\n    Alfv\u00e9n, who had introduced the concept,\n    became a strong critic of \u2018moving\u2019 magnetic\n    field lines [Alfv\u00e9n, 1976], especially in his\n    later years. He warned against use of the\n    concepts of \u2018frozen-in\u2019 and \u2018moving\u2019 magnetic\n    field lines for the reasons that are\n    emphasized above.\n    The basic reason for these difficulties with\n    \u2018moving\u2019 magnetic field lines is, of course,\n    that motion of magnetic field lines is inherently\n    meaningless. The magnetic field B is a\n    vector field defined as a function of space\n    coordinates and time. At a fixed time, one\n    may trace a field line from any given point in\n    space. But that field line has no identity, and\n    in a time-dependent magnetic field it cannot\n    be identified with any field line at a different\n    time, except by one convention or another.\n    As we have seen, such conventions are\n    fraught with pitfalls and should only be used\n    with utmost care lest they lead to erroneous\n    conclusions. To paraphrase Ralph Nader,\n    moving magnetic field lines are \u201cunsafe at\n    any speed.\u201d\n\n    As does Donald Scott:\n\n    Real Properties of Electromagnetic Fields and Plasma in the Cosmos\n\n    Alfv\u00e9n [1] was explicit in his condemnation of the reconnecting\n    concept: \u201cOf course there can be no magnetic merging\n    energy transfer. The most important criticism of the merging\n    mechanism is that by Heikkila [21], who, with increasing\n    strength, has demonstrated that it is wrong. In spite of all\n    this, we have witnessed, at the same time, an enormously\n    voluminous formalism building up based on this obviously\n    erroneous concept.\n\n    Hannes Alfv\u00e9n, a Nobel Laureate, being the founding father of MHD theory that magnetic reconnection is predicated on.\n\n    This leaves us with two competing models to describe the function of the Aurora and other astrophysical plasmas, one being based on a theory that violates known laws of physics, the other being based on known properties of conducting plasmas.\n    Last edited: Jan 21, 2009\n  2. jcsd\n  3. Nereid\n\n    Nereid 4,014\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    Interesting post, Suede.\n\n    I wonder ... to what extent is the disagreement merely one of appearance?\n\n    I mean, plasmas behave the way they do (as we learn from experiment and observation), and theories are developed to account for the observed behaviours.\n\n    It is possible, and to some extent even easy, to develop two theories that are equivalent ... in the sense that there is no experiment or observation which could distinguish between the two, even in principle*.\n\n    In this case, perhaps there are two different ways to look at the bulk properties and behaviours of plasmas that are indistinguishable in terms of any experiment or observation?\n\n    If so, the choice of which one to use is a matter of practicality, convenience, history, or whatever ... but not of physics.\n\n    After all, plasmas are composed of particles - charged and uncharged - and so the only 'true' description of their behaviour must be one built on QED, mustn't it? And any physics of plasmas which does not show, explicitly, how it is compatible with QED in the appropriate limit must necessarily be incomplete (at best), mustn't it?\n\n    * for a discussion of this kind of equivalence, in terms of 'expanding universe' vs 'shrinking universe', see here.\n\n  4. my opinion:\n\n    What I think will happen, is over time 'magnetic reconnection' will evolve from a theory that is incompatible with standard plasma physics to one that is compatible.\n\n    What they call a \"reconnection event\" will replace \"exploding double layer\" but will mean the same thing as an exploding double layer.\n\n    I don\u2019t think classical plasma physics is too far removed from QED theory. Classical plasma physics starts at the level of the electron and works its way up to macro scale structures. So what you have is a direct unification between classical electrodynamics and the macro scale universe.\n\n    QED, from what I understand of it, deals mostly in theory below the scale of the electron. If we have, starting at the level of the electron, a working model that can accurately depict and describe macro scale events based on electrical interactions, I think that would put us at a better standing than we are at now.\n  5. It would be nice if you could show in detail that the regions in which reconnection happens can be correctly described by an \"exploding double layer\".\n\n    At the moment the observations by e.g. Cluster are so good and in agreement with the theoretical description of reconnection, with the inward motion of \"field lines\" the energization of particles, the Hall current signature because of the decoupling of the ions from the field. I would look up the observations described by Sergeev et al (and refs therein).\n\n    Also there is the interesting paper by Treumann et al. about the role of the Hall field.\n\n    Although I did my PhD on double layers in astrophysics (mentioned in the Wiki page which is greatly rewritten by me with help from my predecessors, in its current and excellent form), I cannot see how a DL can make all the things that are observed near a reconnection region.\n\n    But please show me with data and a model how it works.\n  6. Just some random comments on your first post:\n\n    Naturally there is a current in the system because reconnection happens in oppositely directed magnetic fields and through Maxwell's equations it is clear that these are two fields are separated by a current sheet, just like in nature in e.g. the Earth's magnetotail.\n\n    electric fields must complete a circuit to flow?\n    I do hope this is a language problem, because electric fields don't flow.\n\n    Field aligne electric fields and field aligned currents have absolutely nothing to do with reconnection, so you cannot use that to claim that reconnecting is correct or not. Take a look at my paper here where the motion of the magnetic field is the cause of currents flowing. Something (which you will see I leave to the reader to decide what, reconnection, current disruption,...) sets plasma flows in motion, which is pulled along with the magnetic field (in the tail the frozen in condition is very well satisfied, determined from measurements not assumptions) As there is a barrier this motion needs to be stopped and one of the main ways of stopping is cross tail currents, and these close as field aligned currents.\n\n    Now these field aligned currents, when they go through a region of low density, they need to be accelerated to maintain the current, which is usually done by a double layer.\n\n    But from your description above, it sounds like you have no idea what a DL is.\n\n    And I am insulted! You forget my paper on solitary kinetic Alfv\u00e9n waves which carry parallel electric field in the auroral zone, and there is the paper by Chust et al which shows strong parallel E-fields measured by Freja and shows that they are real and no artifact.\n\n    However, all these double layers and parallel electric fields are mainly close to the Earth, most of them in the auroral zone, whereas reconnection happens rather far down the tail (20 Earth radii) or near the nose of the magnetosphere.\n\n  7. Just search for 'double layer' 'aurora' 'birkeland current' 'parallel electric field' in any geophysical journal.\n\n    I turned up a bucket load with just a few simple searches.\n\n    I'm not sure what kind of data and model you're looking for.\n\n    Double layers in the downward current region of the aurora\n\n    Parallel electric fields in the upward current region of the aurora: Numerical solutions\n\n    Particle Simulation of Auroral Double Layers\n    A double layer is that solution which preserves gross quasineutrality within its volume while permitting momentum balance between incident accelerated particles. The potential of the double layer is limited by the ion kinetic energy but need not match the global potential required for overall charge neutrality. One and two dimensional electrostatic particle simulations verify both double layer solutions and dependence of potentials on the injected energy. The difference between global and local potentials is absorbed in a sheath opposite the injection boundary. Potential formations are strictly dependent on the self-consistent charge distributions they support. Microinstabilities cause changes in particle distributions. Double layer motion is associated with exchange of momentum between particles and these fields.\n\n    Double layers\n    The basic properties of electrostatic double layers observed in laboratory gaseous discharges are reviewed. Theoretical results from both macroscopic 4-fluid theory and microscopic, Vlasov, theory are described and found to be in fairly good agreement. Recent work on Penrose-stable double layers, as well as double layers with oblique electric and magnetic fields are described. Applications to Birkeland currents in the ionosphere are made. It was found that kilovolt potential which drops along the geomagnetic field can be produced in the topside ionosphere by double layers. Anomalous turbulent resistivity effects are unlikely to produce large parallel potential drops since that would lead to excessive heating of the ambient plasma. Since double layers are laminar structures they will not produce heat until the accelerated particles are stopped in the lower much denser E-layer.\n\n    Large parallel electric fields in the upward current region of the aurora: Evidence for ambipolar effects\n\n    Double layers on auroral field lines\n    Time-stationary solutions to the Vlasov-Poisson equation for ion holes and double layers were examined along with particle simulations which pertain to recent observations of small amplitude (e phi)/t sub e approx. 1 electric field structures on auroral field lines. Both the time-stationary analysis and the simulations suggest that double layers evolve from holes in ion phase space when their amplitude reaches (e phi)/t sub e approx. 1. Multiple small amplitude double layers which are seen in long simulation systems and are seen to propagate past spacecraft may account for the acceleration of plasma sheet electrons to produce the discrete aurora.\n\n  8. A double layer can \"explode\" at any point and we have evidence for their existence throughout the magnetosphere of earth. I do indeed know what a double layer is, in fact I quoted the dictionary definition of one.\n\n    If you want to believe magnetic field lines are real physical objects that merge and reconnect I suppose that's your business.\n\n    I personally prefer Alfven's opinion.\n    Last edited: Jan 23, 2009\n    24 July 2008\n\n    Surprise sequence\n\n\n    I'll tell you why it's a \"suprise\".\n\n    Magentic reconnection isn't real and the models are wrong.\n\n    That's a pretty huge suprise btw. That's like predicting: egg first splaters, then hammer falls.\n    Last edited: Jan 23, 2009\n\nHave something to add?"}
{"text": "Retrieved from http://math.stackexchange.com/questions/591784/if-two-sequences-converge-in-a-metric-space-the-sequence-of-the-distances-conve\nText:\nTake the 2-minute tour \u00d7\n\nLet $(p_n)$ and $(q_n)$ be sequences in the metric space $(X, d)$ and assume that $p_n \\rightarrow p \\in X$ and $q_n \\rightarrow q \\in X$. Prove that $d(p_n, q_n)$ converges to $d(p, q)$.\n\nOk, so using the triangle inequality (and assuming the sequences are Cauchy - but can I do that?), I can prove that the distance does converge, but how do I say it converges to $d(p,q)$ exactly?\n\nshare|improve this question\nWhy don't you look at the sequence d(p, $q_n$) -- what does that converge to? \u2013\u00a0 Betty Mock Dec 4 '13 at 0:48\nAssume it converges to $d'\\neq d(p,q)$, where $|d'-d(p,q)|=\\varepsilon > 0$. Go far enough in the sequences that $d(p_n,p)$, $d(q_n,q)$, and $|d'-d(p_n,q_n)|$ are all less than $\\varepsilon/3$. Show a contradiction. \u2013\u00a0 mjqxxxx Dec 4 '13 at 0:49\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe key is to use the reverse triangle inequality. Since $d$ is a distance, you have $d(x,y)\\leq d(x,z)+d(z,y)$ for any $x,y,z\\in X$. This you can write as $$ d(x,y)-d(z,y)\\leq d(x,z). $$ As the roles of $x$ and $z$ can be reversed, you get the reverse triangle inequality $$ |d(x,y)-d(z,y)|\\leq d(x,z). $$\n\nNow we get directly that $$ |d(p_n,q)-d(p,q)|\\leq d(p_n,p),\\ \\ \\ |d(p_n,q_n)-d(p_n,q)|\\leq d(q_n,q). $$ Now (using the triangle inequality) $$ |d(p_n,q_n)-d(p,q)|\\leq |d(p_n,q_n)-d(p_n,q)|+|d(p_n,q)-d(p,q)|\\leq d(q_n,q)+d(p_n,p). $$ So $\\lim_{n\\to\\infty}d(p_n,q_n)=d(p,q)$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/71917/proof-involving-a-convex-set?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nSo, the problem is actually from a microeconomics class. The problem is this:\n\nIf preferences are represented by a utility function $u(x,y)=xy$, show that these preferences are convex.\n\nNow in case you don't know, in economics, \"convex preferences\" means preferences such that the set of preferences that are at least as preferred to some bundle is convex. So basically what this means is I need to show this:\n\nLet $0\\le t\\le 1$\n\nif $u(x_1,y_1)=u(x_2,y_2)$, then $u(tx_1+(1-t)x_2,ty_1+(1-t)y_2)\\ge u(x_1,y_1)$.\n\nso $x_1y_1\\le (tx_1+(1-t)x_2)(ty_1+(1-t)y_2)$.\n\nNow, I have tried expanding this out and factoring all kinds of different ways, and I feel like I'm not getting anywhere. Am I going about this incorrectly by trying to expand this? Is there some simpler way? If anyone could give me some kind of hint that would be amazing.\n\n\nshare|improve this question\nAre you sure that the inequality is in that direction? A convex function is usually defined as $$f(tx+(1-t)y)\\le tf(x)+(1-t)f(y)$$ for $0\\le t\\le1$. \u2013\u00a0 robjohn Oct 12 '11 at 6:20\n@robjohn, Colin asks that the sets $\\{u\\geqslant h\\}$ are convex for every $h$ (that is, yes, that the function $u$ is concave). \u2013\u00a0 Did Oct 12 '11 at 6:27\n@Didier: Thanks, that makes sense. \u2013\u00a0 robjohn Oct 12 '11 at 6:50\nThe implication \"it has sets $\\Rightarrow$ [elementary-set-theory] or [set-theory] fits as tags\" is incorrect. I removed the unneeded tag. :-) \u2013\u00a0 Asaf Karagila Oct 12 '11 at 7:13\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nSince $x_1y_1=x_2y_2$, what you want to prove is equivalent to $$tx_1y_1+(1-t)x_2y_2\\leqslant(tx_1+(1-t)x_2)(ty_1+(1-t)y_2). $$ Expanding the RHS, one sees that the RHS minus the LHS is $$t(1-t)(x_1y_2+x_2y_1-x_1y_1-x_2y_2)=t(1-t)(x_1-x_2)(y_2-y_1). $$ Using $x_1y_1=x_2y_2$ once again, you know that $x_1>x_2$ implies $y_1<y_2$ and that $x_1<x_2$ implies $y_1>y_2$ hence the last product is always nonnegative. Done.\n\nshare|improve this answer\nHoly moly. I thought about trying to use the fact that $$x_1 y_1 = x_1 y_1$$ but it never occurred to me to do it the way that you did. How did you even think of that? Anyway, thank you very much for your help, I've got it. \u2013\u00a0 crf Oct 12 '11 at 7:32\nNot enough time to elaborate just now but the answer is: symmetry. \u2013\u00a0 Did Oct 12 '11 at 7:36\n\nYour Answer"}
{"text": "Retrieved from http://cs.stackexchange.com/questions/7383/ltl-show-negaub-leftrightarrow-neg-b-u-neg-a-land-neg-b-lor-g-neg\nText:\nTake the 2-minute tour \u00d7\n\nI got as far as \\begin{align} w \\vDash \\neg (a U b) &\\Leftrightarrow \\neg (w \\vDash a U b) \\Leftrightarrow \\neg (\\exists_{i\\geq0} : w^i \\vDash b \\land \\forall_{0\\leq k < i} : w^k \\vDash a) \\\\ &\\Leftrightarrow \\forall_{i\\geq0} : \\neg(w^i \\vDash b) \\lor \\exists_{0\\leq k < i} : \\neg(w^k \\vDash a) \\end{align}\n\nbut got stuck.\n\nIf you could offer some advice as on where to start I would very much appreciate it. Thanks in advance\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\n$aUb$ means that $a$ holds up to (and not necessarily including) the first point where $b$ holds, which must exist. There are two ways in which this can fail: $b$ never holds, or the first time that $a$ fails precedes the first time in which $b$ is true. The first case is handled by $G \\lnot b$. The second case is handled by $\\lnot b U (\\lnot a \\land \\lnot b)$ (why?).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/183259/collatz-ish-olympiad-problem\nText:\nTake the 2-minute tour \u00d7\n\nThe following is an Olympiad Competition question, so I expect it to have a pretty solution:\n\nFor a positive integer $d$, define the sequence: \\begin{align} a_0 &= 1\\\\ a_n &= \\begin{cases} \\frac{a_{n-1}}{2}&\\quad\\text{if }a_{n-1}\\text{ is even}, \\\\ a_{n-1}+d &\\quad\\text{if }a_{n-1}\\text{ is odd.} \\end{cases} \\end{align} Find all values of $d$ such that $a_n=1$ for some $n>0$.\n\nIt is obvious that $d$ must be odd, or else the sequence is monotone increasing. Also, I have numerically observed that all odd values of $d$ seem to work. Can anyone provide a hint as to how to even begin to prove this? Thank you!\n\nshare|improve this question\nDid you intend \"... if $a_n$ is even, .... if $n$ is odd.\" Should $n$, or $a_n$ be used in both predicates? \u2013\u00a0 Sasha Aug 16 '12 at 16:05\nThanks for pointing that out. I edited the question \u2013\u00a0 Raj Raina Aug 16 '12 at 16:25\nYes I have tried induction, but I see no way of relating previous values of $d$ with bigger values of $d$ (i.e. the induction step) \u2013\u00a0 Raj Raina Aug 16 '12 at 16:40\n@RajRaina There still seems be to a typo. Did you mean to say $a_{n+1} = \\frac{a_n}{2}$ if $a_n$ is even, and $a_{n+1} = a_n + d$ if $a_n$ is odd? \u2013\u00a0 Sasha Aug 16 '12 at 16:41\nAHH sorry for not proofreading more carefully! I edited :) \u2013\u00a0 Raj Raina Aug 16 '12 at 16:43\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere is an outline of an argument. Our guess was that the sequence goes back to $1$ for any $d = 2m-1$.\n\nFirst, it seems preferable to work with the sequence\n\n$$b_0 = 1, \\quad b_n = \\begin{cases} \\dfrac{b_{n-1}}2 & (b_{n-1}\\text{ even}) \\\\ \\frac{b_{n-1}+d}2 & (b_{n-1} \\text{ odd})\\end{cases}$$\n\ninstead of $a_n$ (the statement to be proven remains the same).\n\nHint: Show that it is enough to show $b_n\\equiv 1 \\pmod d$ for some $n$. What does the sequence $b_n$ look like mod $d$?\n\nI have included a more detailed outline below (but I fear it is giving away way too much!)\n\nClaim 1: We have $0<b_n<d$ for all $n$.\n\n\nThis allows us to work mod $d$ from now on, i.e. we have $b_n = 1$ if and only if $b_n\\equiv 1 \\pmod d$.\n\n\nClaim 2: $\\frac12 \\equiv m \\pmod d$, where $d=2m-1$ as above.\n\n\nNow notice that the sequence is really simple when considered $\\pmod d$! Use this to show\n\n\nClaim 3: $b_n \\equiv m^n \\pmod d$\n\n\nClaim 3 implies that $b_k \\equiv 1 \\pmod d$ for some $k$ (why?), so by Claim 1 it follows that $b_k=1$ for this $k$. $\\square$\n\nshare|improve this answer\nSince you tagged the question (homework) I assume you wanted a hint rather than a full solution. Please let me know whether you think the above format is helpful in this/how it could be improved... \u2013\u00a0 Sam Aug 16 '12 at 17:59\nA nice argument. You actually show what the return time is, not just that it does return as I do. \u2013\u00a0 Ross Millikan Aug 16 '12 at 18:09\n@RossMillikan: Thank you. Yes, at least for the $b_n$, the return time is given by $\\mathrm{ord}(m)$, where $m\\in \\mathbb Z_{2m-1}^\\times$ and $d = 2m-1$. But it doesn't seem easy to get a return time for the $a_n$ from this (although it does give an upper bound of $2\\varphi(d)$). \u2013\u00a0 Sam Aug 16 '12 at 18:20\n@SamL. I posed a related question before seeing your response. Your response answers the question completely though. You might want to respond to it, to claim the credit. Thanks! \u2013\u00a0 Sasha Aug 16 '12 at 18:59\nThank you Sam L. If I am understanding correctly, we can now say that $b_{n}\\equiv 2^{\u2212n}\\pmod d$ (Claim 3), and so we need $2^n \\equiv 1 \\pmod d$, which has the trivial solution $n = \\phi (d)-1$ since $2$ and $d$ are relatively prime, and so we will always have $b_{\\phi(d)-1} =1$. What a simple solution! But what was Claim 2 necessary for? \u2013\u00a0 Raj Raina Aug 16 '12 at 23:12\n\nIt is true that you return to $1$ for all odd $d$, and the power of $2$ that you get to for the return is the next power of $2$ above $d$.\n\nAll odd numbers in the series are less than $d$, which means it must cycle. If $a_n$ is odd and less than $d$, $a_{n+1}$ is less than $2d$ and even, so the next odd is again less than $d$.\n\nTo have a cycle that does not include $1$ you must have a number that can be reached from two different numbers-one to enter the cycle and one to continue it. But this is impossible-odd numbers have to be reached by division by $2$, even numbers greater than $d$ have to be reached by addition, and even numbers less than $d$ have to be reached by division.\n\nshare|improve this answer\nThank you for your help! \u2013\u00a0 Raj Raina Aug 16 '12 at 23:04\n\nThe question has already an \"accepted\" answer - but the following scheme may be useful for some later reader anyway.\nThe iterative dividing and adding can be expressed as a whole operation.\nWe formulate one transformation as $$ a_{k+1}={a_k+d \\over 2^A }$$ and work on odd $a_k$ only. The value for A is determined by the requirement, that it is the highest A such that the result of the transformation is an odd integer.\nThe second transformation is then $$ a_{k+2}={{a_k+d \\over 2^A }+d \\over 2^B} = {a_k \\over 2^{A+B} } + d \\cdot ({1 \\over 2^{A+B} } + {1 \\over 2^B} )$$ and so on.\n\nLet the h subsequent exponents of such transformations $a_0 \\to a_h = 1$ be denoted as $A,B,C,\\ldots,G,H$ and their sum as $S$. Then the full transformation can be written as\n$$ 1 (=a_h) = {a_0 \\over 2^S} + d \\cdot {(1+2^A + 2^{A+B} + \\ldots + 2^{A+B+\\ldots + G})\\over 2^S} $$ and we must have an integer solution for\n$$ 2^S = a_0 + d \\cdot (1+2^A + 2^{A+B} + \\ldots + 2^{A+B+\\ldots +G})= a_0 + d \\cdot x $$\nwhere S is to be found (if there is a solution in $A,B,C,\\ldots,H$ at all!).\n\nThus we solve for S such that $ 2^S = a_0 \\pmod d$ which must in general be done by searching (see \"discrete-logarithm-problem\").\nNow here seems to be the critical problem of the original question: we need to know such combinations of $d$ and $a_0$ that this equation has a solution at all. Possibly this is also meant to be the core problem in your homework-assignment, so I won't proceed here ( #1 see below)\n\nIf in fact there is a solution for some S then we compute\n$$ x = { 2^S - a_0 \\over d} $$. Then the bits in the binary representation of x correspond to the \"division by 2's\" of the original formulation of the problem.\n\nFor instance, with $a_0 = 605, d=13$ I found $2^S = a_0 + d \\cdot x $ with $ S=11, x=111$ and $2048 = 605 + 13 \\cdot 111 $\n\n(#1): Referring to another answer we might reformulate this as $ 2 = a_0^{1 \\over S} \\pmod d$ which hints to the concept of \"primitive roots (mod p)\".\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/305026/enumerating-rooted-labeled-trees-without-langrange-inversion-formula\nText:\nTake the 2-minute tour \u00d7\n\nI am wondering how to enumerate rooted labeled trees without the Langrange inversion formula. Because each tree is a collection of other trees, the recursive generating function becomes $$C(x) = x + xC(x) + xC(x)^2 ... = \\sum_n x[C(x)]^n/{n!} = xe^{C(x)}$$\n\nFrom my notes, I am told that we may be able to utilize the function $G(x)$ which counts the number of forests on n vertices => $xG(x) = C(x)$ I can been trying to fiddle around with these functions as well as taking derivatives/log of both, but I can't seem to isolate $C(x)$ to get a functional equation to extract coefficients. Any help would be appreciated!\n\nshare|improve this question\nThe solution to $C(x) = x \\exp(C(x))$ is a new transcendental function, you won't find a \"nice\" formula for it, it is related to Lambert's W function <en.wikipedia.org/wiki/Lambert_W_function>; \u2013\u00a0 vonbrand Feb 15 '13 at 20:21\nBTW, why restrict yourself from using one of the most useful tools to handle this type of equations? \u2013\u00a0 vonbrand Feb 15 '13 at 20:22\nWell based on the notes, we're not suppose to have covered the LIF so the problems should be doable without. I actually asked this problem to give me some intuition for other problems and the counting proofs are great! \u2013\u00a0 Azhuang Feb 17 '13 at 7:07\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nHere's another proof, I believe due to Jim Pitman.\n\nA rooted forest is a disjoint union of rooted trees, which we will think of as a digraph with edges always directed toward the roots. Given a rooted forest $F$ on $n$ vertices with $k$ components, we would like to add an edge while still having a forest. To do this, choose any vertex $x$ and any of the $k-1$ roots $y$ not in the same component as $x$ and add the edge $y \\rightarrow x$. There are thus $n(k-1)$ ways of doing this, and the resulting forest now has $k-1$ components. If we start from forest with $n$ isolated vertices, we see that we can add $n-1$ edges in\n\n$$n(n-1)\\cdot n(n-2) \\cdot \\ldots \\cdot n(1) = (n-1)! \\cdot n^{n-1}$$ ways. In this expression each tree has been counted $(n-1)!$ ways since the order in which we added edges does not matter, so dividing this out gives the desired formula.\n\nshare|improve this answer\n\nUsually, you would use the Lagrange inversion formula together with the functional equation $C(x)=x e^{C(x)}$ to extract the coefficients from $C(x)$. But if you don't want to do that, here is a combinatorial argument to count labeled rooted trees, from Joyal (1981), p. 16:\n\nCall a vertebrate an unrooted labeled tree with two (possibly coincident) distinguished points, a red one and a black one. By following a path from the red point to the black point, rooting each subtree you come to at that point, and removing all edges along the path, you can change the vertebrate into a nonempty sequence of rooted labeled trees. This is a bijective correspondence, so the number $V_n$ of vertebrates on $n$ vertices which are labeled $\\{1,\\ldots,n\\}$ is the same as the number of nonempty sequences of rooted trees on vertices labeled $\\{1,\\ldots,n\\}$.\n\nLet $n\\ge 1$. The number of ways of arranging the roots of $k$ rooted trees into a sequence is $k!$, which is the same as the number of ways of arranging the roots of $k$ rooted trees into a permutation. So, $V_n$ is also the number of sets of rooted trees on vertices labeled $\\{1,\\ldots,n\\}$ together with a permutation acting on their roots. But every self-map on $\\{1,\\ldots,n\\}$ gives such a structure (composed of trees of elements which coalesce under the action of the self-map and eventually fall into cycles), and conversely. This is a bijective correspondence, so $V_n$ equals the number of self-maps on $\\{1,\\ldots,n\\}$, which is $n^n$.\n\nEach rooted tree on labeled vertices $\\{1,\\ldots,n\\}$ gives $n$ different vertebrates, by coloring the root black and any of $\\{1,\\ldots,n\\}$ red. This is an $n$-to-$1$ correspondence, so, if $n\\ge 1$, the number of rooted trees on $n$ vertices is $n^n/n=n^{n-1}$.\n\nJoyal also uses similar reasoning to give a combinatorial proof of the Lagrange inversion formula (pp. 21-24.)\n\nshare|improve this answer\nThere is a detailed presentation of this argument in Mikl\u00f3s B\u00f3na, Introduction to Enumerative Combinatorics, McGraw-Hill, 2007, pp. 266-8. \u2013\u00a0 Brian M. Scott Feb 16 '13 at 0:27\n\nPitman gave a wonderful solution.\n\nTalking about \"Joyal point of view\" one could give up those vertebrates and talking only about functions and labeled trees. And in case we haven't rooted trees there'll be $n^2$ functions for each tree. Otherwise, if the problem concerns labeled rooted trees, then we'll have $n$ functions associated to every such tree.\n\n(So there are $n^{n-2}$ labeled trees and $n^{n-1}$ labeled rooted trees)\n\nTalking on the base set $[n]={1,2,...,n}$\n\nIt's not that obvious how you build the function(s) starting from a labeled tree (rooted or not). But it's similar. For example, in the case of \"unrooted\" labeled trees we'll have \"n X n\" = $n^2$ unique paths, from each vertex to each vertex (including from a vertex to itself). Such a path, with the vertices M = {$v_1, ..., v_k$} like this $v_1$ -> $v_2$ ->...-> $v_k$ will build partially a function $f(v_i)=v_{i+1}$, where $v_{k+1}$ is $v_1$. For the \"subtrees\" (having the ROOT in the paths' vertices it's simple).\n\nConversely, having a function, you must build a tree ... There is a unique (nonempty) set $M$ with maximum elements such as $f$ is bijective on $M$ ... If we write the elements of $M$ increasingly $M = \\{i_1, i_2,...,i_2\\}$ then $f(i_1)$ -> $f(i_2)$ -> ... -> $f(i_k)$ will be the path .. for the rest is much more simple... (and we'll have finally $n^2$ functions giving the same tree). The operations are inverse to one another...\n\nIn the case of rooted labeled trees we'll have $n$ unique paths joining the root with every other vertex (including the root itself). The rest is just the same.\n\nAnyway, here are only the main STEPS. A rigorous demonstration it's much more longer than this, because you must justify all, major or minor \"tricks\" or statements.\n\nWhat is interesting in my case (what I'm looking for) is the possibility to follow similar steps (in the \"Joyal style\", using functions) to prove the Moon theorem, I mean enumerating labeled trees having given (fixed) degrees, so $d(x_i)= d_i$ for $i \\in [n]$, of course with $\\sum d_i = 2(n-1)$...\n\n... and find the well known multinomial coefficient $\\binom{n-2}{d_1 -1 \\; d_2 -1 \\; ... \\; d_n -1}$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/192981/proving-1-0-using-only-the-field-axioms-and-order-axioms?answertab=oldest\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nHow do I prove $1 > 0$ using only field axioms and order axioms? I have tried using the cancellation law, with the identities in a field and I cannot get anywhere. Does anybody have any suggestions?\n\nshare|cite|improve this question\nI think $1 = 1^2$ is helpful. \u2013\u00a0Dylan Moreland Sep 9 '12 at 2:02\n@GerryMyerson I assume the OP means \"ordered field axioms\". \u2013\u00a0Alex Becker Sep 9 '12 at 2:28\nYou need not only the axioms of fields and the axioms of linearly ordered sets, but also the axioms that say the linear order is compatible with the algebraic operations, i.e. if $a,b>0$ then $ab>0$, etc..... \u2013\u00a0Michael Hardy Sep 9 '12 at 2:53\nIn general assume the most minimal set of axioms. I think a lot of textbooks and people might have different terminology. \u2013\u00a0CodeKingPlusPlus Sep 10 '12 at 1:52\nup vote 6 down vote accepted\n\nSuppose $1 < 0$. Adding $(-1)$ to both sides we'd also have $0 < -1$ (addition axiom). But if $0 < a$ then it must also hold that $0 < a^2$ (multiplication axiom). For $a = -1$ this means $0 < (-1)^2 = 1$, a contradiction.\n\nshare|cite|improve this answer\nCan't you do the same with $0$ < $1$? Subtract 1 from each side then we have $-1$ < $0$. Now square both sides. We have $1$ < $0$ another contradiction. Thus, this method does not work. \u2013\u00a0CodeKingPlusPlus Sep 10 '12 at 1:51\n@CodeKingPlusPlus There is some missing detail that I believe Marek meant for you to fill in. Of course it is incorrect to say that if $a, b$ are elements of an ordered field then $a < b$ implies $a^2 < b^2$ \u2014 one remembers the graph of $ y = x^2$ over $\\mathbb R$. But what is true is that if $0 < a < b$ then $0 < a^2 < b^2$. \u2013\u00a0Dylan Moreland Sep 10 '12 at 3:34\n@CodeKingPlusPlus: I was not squaring. I was multiplying by (a > 0) -- a positive number by assumption (since 0 < -1). In your argument (-1 < 0) is a negative number, so the multiplication axiom cannot be applied. \u2013\u00a0Marek Sep 10 '12 at 6:29\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/40816/fibonacci-series-mod-a-number/40818\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'm trying to write a program with an input of numbers $n$ and $k$ (where $n<10^{1000}$ and $k<10^9$), where I compute fib[n] % k. What is a good FAST way of computing this?\n\nI realize that the resulting series is periodic, just not sure how to find it efficiently.\n\nshare|cite|improve this question\nIf k has no large prime or large prime power factors, then brute force combined with the Chinese Remainder Theorem will get you somewhere quickly. Otherwise use recursions to do the Fibonacci series mod k, to compute e.g. F(2j) and F(2j+1) mod k from F(j) and f(j+1) mod k. If n and k satisfy the bounds you say, a reasonably coded laptop can give you the answer in seconds or less. Gerhard \"Ask Me About System Design\" Paseman, 2010.10.01 \u2013\u00a0Gerhard Paseman Oct 2 '10 at 6:11\nThe Fibonacci entry in wikipedia has this identity : $F_{lk+c} = \\sum_{i=0}^l {l\\choose i} F_{c-i} F_k^i F_{k+1}^{l-i}$. It definitely seems to be relevant in your case, where write $n=lk+c$ and then you have to know $F_j$ mod $k$ for $j=1,\\ldots,k+1$ as well as ${l\\choose i}$ mod $k$. I don't know if this is efficient enough. \u2013\u00a0Somnath Basu Oct 2 '10 at 6:19\nModulo a prime $>5$ the Fibonacci sequence has a period that is either a factor of $p-1$ or $2(p+1)$. This follows from Binet's formula. If $5$ is a quadratic residue modulo $p$, then $$x^2=x+1$$ has two roots in the field $F_p$, and thus both roots have multiplicative orders that are factors of $p-1$. OTOH if $5$ is a quadratic non-residue, then the roots $\\tau_1,\\tau_2$ of that polynomial are in the finite field $K=F_{p^2}$. But by known Galois theory of $K$ we then have $$\\tau_1^p=\\tau_2=-1\\frac1{\\tau_1},$$ so $\\tau_^{p+1}=\\tau_2^{p+1}=-1.$$ See \u2013\u00a0Jyrki Lahtonen May 26 '12 at 15:56\nup vote 12 down vote accepted\n\nThis is really just an expansion of Gerhard's comment. One has the matrix formula $$\\begin{pmatrix} 1&1\\\\\\ 1&0 \\end{pmatrix}^n= \\begin{pmatrix} F_{n+1}&F_n\\\\\\ F_n&F_{n-1} \\end{pmatrix} $$ so the problem reduces to computing $A^n$ modulo $k$ where $$A=\\begin{pmatrix} 1&1\\\\\\ 1&0 \\end{pmatrix}.$$ This can be done by the repeated squaring method often used in modular exponentiation. The idea is to compute $A^n$ recursively either as $(A^m)^2$ or $A(A^m)^2$ according to whether $n=2m$ or $n=2m+1$.\n\nshare|cite|improve this answer\nSorry for the late accept, I have been busy lately. Thank you all for the help! \u2013\u00a0user9734 Oct 4 '10 at 12:28\nAlso note that the order of $GL_2(\\Z_k)$ is much smaller than $n$, and the order of the matrix divides this order. If $l$ is the reminder of $n$ divided by this order, then $A^n=A^l \\mod p$. Last but not least it is enough to consider the subgroup of matrices of $det =\\pm1$. \u2013\u00a0Nick S Nov 7 '10 at 19:52\n\nPerhaps Elsenhans, Jahnel, \"The Fibonacci sequence modulo $p^2$ \u2013 An investigation by computer for $p < 10^{14}$\" will be interesting for you. There are sections about the algorithm.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/50770/open-parent-cell-groups-of-selected-cell\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI wrote a small script for a palette, which allows me to highlight a specific cell in a notebook by using SelectionMove[mycell, All, Cell]. The cell is selected as expected, but sometimes this cell is part of a cell group (section, subsection etc.) which is currently closed, so the cell itself is hidden, and SelectionMove does not reveal it. So far, I didn't find a way to open all parent groups of this cell programatically so that this cell will be shown... Is this possible?\n\nshare|improve this question\nYou can use pattern matching like there: 33416 \u2013\u00a0Kuba Jun 14 '14 at 9:11\nup vote 1 down vote accepted\n\nYou can select parent cell group of currently selected object in notebook nb with SelectionMove[nb, All, CellGroup] and then open it using FrontEndTokenExecute[nb, \"SelectionOpenAllGroups\"]. To open all groups containing currently selected cell you can use something like this:\n\n       SelectionMove[nb, All, CellGroup];\n       If[MatchQ[NotebookRead[nb], Cell[CellGroupData[_, Closed], ___]],\n           FrontEndTokenExecute[nb, \"OpenCloseGroup\"]\n\nIt will select parent group, open it (if it's closed), return selected cell expression and repeat until returned expression is unchanged (i.e. when there's no parent CellGroup).\n\n\nIt seems that NotebookLocate automatically opens all groups containing located cell.\n\nSo you could just add CellTags to selected cell and then locate it:\n\nSetOptions[NotebookSelection[nb], CellTags -> \"MyFavoriteCell\"]\nSetSelectedNotebook[nb]; NotebookLocate[\"MyFavoriteCell\"]\n\nIt should be much faster (and cleaner) than my previous, overcomplicated method.\n\nshare|improve this answer\nThanks - does what I want, but the use of NotebookRead makes this slightly slow when using this function in a large notebook. I didn't find a workaround, because this seems to be the only way to find out whether or not the cell group is open... \u2013\u00a0mjayvizzle Jun 15 '14 at 10:51\n@mjayvizzle Please look at edited version. \u2013\u00a0jkuczm Jun 15 '14 at 11:33\nThanks - that's much faster! Didn't think about the option to assign a cell tag... \u2013\u00a0mjayvizzle Jun 15 '14 at 14:58\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/100688/convexity-of-spectral-radius-of-markov-operators-random-walks-on-non-amenable-g\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $P_1,P_2$ denote stochastic transition matrices on a countable set $I$. Consider $P_1,P_2$ as operators on $\\ell^2(I)$ given by multiplication.\n\nQuestion Under which conditions can we show that for $t\\in (0,1)$, $$\\rho(tP_1+(1-t)P_2)\\le t\\rho(P_1)+(1-t)\\rho(P_2),$$ where $\\rho(\\cdot )$ denotes the spectral radius? (Of course, it would be nice to consider this problem also for more general classes of Markov operators acting on some function space.)\n\nMy hope is that the strong assumption that both matrices are stochastic, is enough to prove the inequality.\n\nExample My favorite example is the case where $I$ is the free group $G$ of rank $d\\ge2$ and $P_1,P_2$ are given by $P_i(g,g'):=\\mu_i( g^{-1}g' )$, where $\\mu_i$ is some measure on a set of generators of $G$. In this case, the spectral radius of $P_i$ is strictly less than one, since the group is non-amenable (H. Kesten 1959). I don't know if the above inequality holds in this setting. (Note that non-zero constant functions are not in $\\ell^2(G)$.)\n\nAn additional assumption I'm fine with the additional assumption that $P_1$ and $P_2$ have zeros at the same places. So, regarding the previous example, the measures $\\mu_i$ have the same support. A further simplification would be to assume that one of measures is equidistributed on its support.\n\nRelated results If $P_1,P_2$ commute, then the inequality holds. This is too restrictive.\n\nIf $P_1,P_2$ are selfadjoint, then the spectral radius can be replaced by the norm, and the inequality holds. I'm not interested in this case. I don't want to assume that $P_i$ is reversible with respect to some measure.\n\nFinite matrices with real eigenvalues In the following paper, Lax proved that the spectral radius on the set of $n\\times n$ matrices with real eigenvalues is convex.\n\nKingman proved that spectral radius is log-convex on the space of finite dimensional non-negative matrices.\n\nCohen proved that the spectral radius is a convex function of the diagonal elements on the space of finite dimensional non-negative matrices. There are generalisations for multiplication operators by Kato.\n\nOn amenability If the group is $G$ is amenable in the previous example, then for a large class of transition operators, the spectral radius is equal to one (e.g. uniform irreducibility and invariant measure bounded away from zero and infinity). Hence, under these conditions, all the spectral radii in the above inequality are equal to one. So, equality holds.\n\nExample As an example, let $G$=$\\mathbb{Z}$ and consider $P_1,P_2$ corresponding to the random walks, which go one step to the left resp. right with probabilities $p_i$ resp. $q_i$, $p_i+q_i=1$, $i=1,2$.\n\nReferences LAX, P. D. Differential equations, difference equations and matrix theory. Comm. Pure Appl. Math. 11 (1958), 175-194.\n\nKingman, J.F.C.: A convexity property of positive matrices. Quart. J. Math. Oxford (2) 12, 283-284 (1961)\n\nCohen, J.E.: Convexity of the dominant eigenvalue of an essentially nonnegative matrix. Proc. Amer. Math. Soc. 81, 657-658 (1981)\n\nKato: Superconvexity of the Spectral Radius, and Convexity of the Spectral Bound and the Type, Mathematische Zeitschrift, (1982)\n\nUsing commutativity There are several papers of M.Zima about related properties for positive operators on partially ordered Banach spaces (see below). In there, some commutativity is required to prove the inequality in question. I don't want to assume commutativity.\n\nM.Zima, A theorem on the spectral radius of the sum of two operators and its applications, Bull. Austral. Math. Soc. 48 (1993), 427{434. MR 94j:47006\n\nM.Zima, On the local spectral radius in partially ordered Banach spaces, Czechoslovak Math. J. 49 (1999), 835{841. MR 2001m:47011\n\nshare|cite|improve this question\n\nFor a lot of results of this sort (though probably not exactly what you are asking for), check out:\n\nConvexity and log convexity for the spectral radius Roger D. Nussbaum Linear Algebra and its Applications Volume 73, January 1986, Pages 59\u2013122\n\nshare|cite|improve this answer\nThanks for the reference. But, so far, I didn't find an answer to my question in it. It seems that the paper is more about eigenvalues. I don't see how to apply it to the l^2 setting. \u2013\u00a0Mika Jun 27 '12 at 3:42\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/146424/what-is-the-number-of-functions-f-a-rightarrow-a-forall-x-ina-ffx-x/146432\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWhat is the number of functions $f : A\\rightarrow A, \\forall_{x\\in{A}} f(f(x))=x$, set $A$ have $n$ distinct elements.\n\nFor $A=\\{a,b,c,d\\}$ we could look on the right-upper triangle of matrix of all possible pairs (? better word needed here) - below. For $a$ we have four possibilities but if we choose $a->b$ for example, then we have to delete second column. Without deletation we would have $4!$ functions $f$ for $A=\\{a,b,c,d\\}$, but there is only 1+6+3 of them.\n\n$a->a,a->b,a->c,a->d \\\\ ........b->b,b->c,b->d \\\\ ................c->c,c->d \\\\ ........................d->d $\n\nI think that if $n=2k$ then we could choose first $k$ elements so we have $k$ sets with single element then for each elements with number $k+1 : 2k$ we assign $0$ or $1$. $0$ if $a_{i}->a_{i}$ and $1$ if $a_{i}->a_{1 : n}$, for $i\\in k+1:2k$, so we have $2^k$ possibilities. If $j$, $1's$ have been assigned then we have $\\binom{k}{j}$ possibilities for two element sets and ... I'm out of ideas.\n\nYou could edit my post this is welcome.\n\nshare|cite|improve this question\nIn other words, the number of permutations $\\sigma\\in S_n$ such that $\\sigma^2=e$. If you're familiar with the terms, consider the cycle decomposition of these $\\sigma$'s. (Apparently, the answer isn't terribly simple, though.) \u2013\u00a0anon May 17 '12 at 18:30\nyes, it's the essence of my question \u2013\u00a0Qbik May 17 '12 at 18:33\nI don't get the tagging. This is neither set theory nor category theory related. \u2013\u00a0Asaf Karagila May 17 '12 at 18:33\nup vote 4 down vote accepted\n\nLet $B$ denote a set of size $n+1$ with $B=A\\cup\\{o\\}$, $A$ of size $n$, and $o$ not in $A$. Let $f$ denote an involution of $B$. Then:\n\n  \u2022 Either $f(o)=o$, then $f$ is characterized by an involution of $A$.\n  \u2022 Or $f(o)\\ne o$, then there are $n$ possible choices of $f(o)=a$ with $a$ in $A$. Once $a$ is fixed, one knows that $f(a)=o$ hence $f$ is characterized by an involution of $A\\setminus\\{a\\}$.\n\nLet $i_n$ denote the number of involutions of a set of size $n$. One sees that $i_1=1$, $i_2=2$, and that the recursion $i_{n+1}=i_n+ni_{n-1}$ holds, for every $n\\geqslant2$. This characterizes the sequence $(i_n)_{n\\geqslant1}$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/16851/set-x-increases-by-1-set-y-increases-by-3-need-help-with-a-function-that-will\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nTwo sets\n\nx = 1,2,3,4,5...\ny = 1,4,7,10,13...\n\nI need to write a function\n\n$f(x_n) = y_n$\n\nI found that if I\n\n  1. take a number from x\n  2. double it\n  3. subtract 2\n  4. add the result to the original number\n  5. I get the corresponding number from y\n\nHere's what I have so far (it's in ruby code), it works but is there a better way of doing it.\n\ndef f(x)\n  if x > 1\n    return x + ((2 * x) - 2)\n    return 1\n\ny = f(x)\nshare|cite|improve this question\nNot sure what better way you are looking for. What you have seems fine, expect we can multiply by 3 instead of doubling and then adding itself. I guess Ruby does not have overflow issues. \u2013\u00a0Aryabhata Jan 9 '11 at 1:12\nup vote 3 down vote accepted\n\nYour values y form what is called an arithmetic progression, namely a sequence where each element is obtained from the previous one just by adding always the same constant. In your case the constant is 3, namely: 1, 4=1+3, 7=4+3, 10=7+3 and so on.\n\nSince the FIRST time you add 3 corresponds to x=2, the formula is just\n\n\nor (equivalently)\n\n\nshare|cite|improve this answer\nWow thanks, I can't believe I didn't think about 3x instead of 2x + x lol. \u2013\u00a0Seth Archer Brown Jan 9 '11 at 3:32\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-do-you-calculate-all-the-possible-combinations-on-a-rubiks-cube.759259/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHow do you calculate all the possible combinations on a Rubik's cube?\n\n  1. Jun 23, 2014 #1\n    I thought it would just be the number of faces multiplied by the nine cubes on each face? What am i doing wrong?\n  2. jcsd\n  3. Jun 23, 2014 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Not all combinations are possible mechanically. I would probably try to solve this with a program. Are you comfortable writing a C program (or using some other programming language) to solve this?\n  4. Jun 23, 2014 #3\n    I know very little programming, a tiny but if Python but that's about it\n  5. Jun 23, 2014 #4\n\n    D H\n\n    User Avatar\n\n    Staff: Mentor\n\n    You're not going to be able to count the permutations on a computer. The number is too big.\n\n    If you consider the problem of the number of permutations that can be made by pulling a Rubik's cube apart piece by piece and then reassembling it, this is a huge number. There are eight corner cubes which can be placed. That means 8! permutations just based on corner cube location. Each corner cube can be placed in one of three orientations. That's a factor of 38 permutations on top of the 8! location permutations. The twelve corner cubes lead to two more factors, 12! and 212. Altogether, there are ##8! \\, 3^8 \\, 12! \\, 2^{12}## permutations of the ripped apart and resembled cube. That is a *big* number.\n\n    Most of these permutations do not lead to the nice all colors on one face arrangement. There are constraints, but the final number is still huge.\n  6. Jun 24, 2014 #5\n\n\n    User Avatar\n    Homework Helper\n\n    See here\n    There are\n    $${8! \\times 3^7 \\times (12!/2) \\times 2^{11}} = 43,252,003,274,489,856,000 \\\\\n\n    the larger number is 12 times the smaller as there are 12 orbits\n    that is any position can reach 1/12 positions though legal moves separating possible moves into 12 orbits\n\nHave something to add?\nDraft saved Draft deleted\nSimilar Discussions: How do you calculate all the possible combinations on a Rubik's cube?\n  1. Rubik cube (Replies: 8)\n\n  2. Rubik's cube (Replies: 2)"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/15055/finding-distribution-parameters-of-a-gaussian-mixture-distribution\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nShort version: how to estimate the parameters of a mixture of multivariate normal distributions (i.e.: Gaussian mixture model)?\n\nLong version.\n\nI am trying to estimate the parameters of a mixture of multivariate Gaussian distribution.\n\nI know how to do it for a single multivariate normal distribution:\n\ndataSet = RandomVariate[dist, 300];\nestDist = EstimatedDistribution[dataSet, MultinormalDistribution[{m1, m2}, {s11, s12}, {s12, s22]}}]]\n\nPlot[{PDF[dist, {x, 0}], PDF[estDist, {x, 0}]}, {x, -4, 4}, Filling -> Axis]\nPlot3D[PDF[estDist, {x, y}], {x, -2, 2}, {y, -2, 2}]\n\nSimilarity of PDF at y=0, density of dataset and estimated density.\n\nAll fine and dandy. However, the same approach does not work for me with mixture distributions. In particular, I am interested in mixtures of Gaussian distribution (Gaussian Mixture Model).\n\nI generate a sample dataset:\n\ntargetDist = MixtureDistribution[{1/3, 2/3}, {MultinormalDistribution[{0, 0}, {{1, 0}, {0, 1}}], MultinormalDistribution[{3, 3}, {{1, 0}, {0, 1}}]}];\ndataSet = RandomVariate[targetDist, 500];\n\nMixture of Gaussians\n\nI try to find the estimated distribution with:\n\nestimatedDist = EstimatedDistribution[dataSet,\n    MixtureDistribution[{w1, w2}, {\n        MultinormalDistribution[{m11, m12}, {{s111, s112}, {s112, s122}}],\n        MultinormalDistribution[{m21, m22}, {{s211, s212}, {s212, s222}}]\n\nBut the evaluation always fails with:\n\nNMaximize::cvdiv: Failed to converge to a solution. The function may be unbounded. >>\n\nFor some reason, it works if, instead of using MultinormalDistribution I use BinormalDistribution with $\\rho$=0.\n\nI know how to estimate these parameters using the Expectation Maximization algorithm, but I was wondering if there is a Mathematica-friendly way to do it.\n\n\nGiving initial estimates of the parameters does not really improve much. Even when giving the exact parameters like this:\n\nestimatedDist = EstimatedDistribution[dataSet, \n        {w1, w2},\n        {MultinormalDistribution[{m11, m12}, {{s111, s112}, {s121, s122}}],\n         MultinormalDistribution[{m21, m22}, {{s211, s212}, {s221, s222}}]}],\n        {{w1, 1/3}, {w2, 2/3}, {m11, 0}, {m12, 0}, {s111, 1}, {s112, 0}, {s121, 0}, {s122, 1}, {m21, 3}, {m22, 3}, {s211, 1}, {s212, 0}, {s221, 0}, {s222, 1}}]\n\nEstimatedDistribution seems to take much more time than what it would be reasonable (and, since the estimates are exact, \"reasonable\" means 0.1 sec).\n\nAfter about 15 minutes of processing on a 3.3GHz Xeon, I got this error:\n\nFindMaximum::eit: The algorithm does not converge to the tolerance of\n4.806217383937354`*^-6 in 500 iterations. The best estimated solution,\nwith feasibility residual, KKT residual, or complementary residual of\n{2.1536*10^-12,0.00200273,5.6281*10^-13}, is returned. >>\n\nThen a popup message:\n\nClick here to find out if this problem is known, and to help improve\nMathematica by reporting it to Wolfram Research.\nshare|improve this question\nYou are aware that you can supply EstimatedDistribution[] with initial estimates of parameters? \u2013\u00a0J. M. Nov 22 '12 at 14:19\n@J.M. Please see my edit. Using the exact parameters as estimation seems just to avoid divergence, but EstimatedDistribution still fails to return a meaningful result. \u2013\u00a0Giuseppe Cardone Nov 22 '12 at 15:15\nup vote 9 down vote accepted\n\nYou need to make sure that the constraints on the parameters are satisfied. In this case, these are\n\n1) The mixture weights sum to one. 2) The covariance matrices of the two bivariate normals need to be positive definite.\n\nThe first constraint can be guaranteed by specifying the weights as follows:\n\nw1 = Exp[w]/(1 + Exp[w]);\n\nwhere w is unconstrained.\n\nThe second constraint can be enforced by using the Cholesky Decomposition of the covariance matrices as below.\n\nc1 = {{c111, 0}, {c112, c122}};\n\nwhere c1 is a lower triangular matrix of unrestricted elements. The resulting covariance matrix is given by s1 below.\n\ns1 = c1.Transpose[c1]\n\nOut[9]= {{c111^2, c111 c112}, {c111 c112, c112^2 + c122^2}}\n\nSimilarly, we have for the other covariance,\n\ns2 = c2.Transpose[c2];\n\nLet the two mean vectors be\n\nm1 = {m11, m12};\n\nm2 = {m21, m22};\n\nThe mixture pdf can be written as\n\nIn[15]:= mixPDF = MixtureDistribution[{w1, 1 - w1}, \n  {MultinormalDistribution[m1, s1], \n   MultinormalDistribution[m2, s2]\n\nOut[15]= MixtureDistribution[{E^w/(1 + E^w), \n  1 - E^w/(1 + E^w)}, {MultinormalDistribution[{m11, \n    m12}, {{c111^2, c111 c112}, {c111 c112, c112^2 + c122^2}}], \n    m22}, {{c211^2, c211 c212}, {c211 c212, c212^2 + c222^2}}]}]\n\nThen one may get what you are looking for, depending upon starting values.. The first try here does not give the correct answer.\n\nIn[16]:= est1 = EstimatedDistribution[dataSet, mixPDF]\n\nOut[16]= MixtureDistribution[{0.0172133, \n  0.982787}, {MultinormalDistribution[{1.37871, \n    0.821044}, {{4.88591, 1.35155}, {1.35155, 0.373881}}], \n    1.88312}, {{3.0206, 2.01692}, {2.01692, 3.08025}}]}]\n\nSpecifying starting values helps.\n\nIn[17]:= est2 = \n  mixPDF, {{m11, - 0.5}, {m12, 0.8}, {m21, 1.5}, {m22, 2.0}, {c111, \n    1.5}, {c112, 0.0}, {c122, 1.0}, {c211, 1.5}, {c212, 0.0}, {c222, \n    1.0}, {w, 0.2}}]\n\nOut[17]= MixtureDistribution[{0.39772, \n  0.60228}, {MultinormalDistribution[{0.110727, \n    0.110757}, {{1.05393, 0.060291}, {0.060291, 1.07923}}], \n    3.02315}, {{0.84418, -0.148054}, {-0.148054, 0.982491}}]}]\n\nAn alternative approach can use FindDistributionParameters as follows\n\nest3 = FindDistributionParameters[dataSet, \n  mixPDF, {{m11, 0.0}, {m12, 0.0}, {m21, 2.5}, {m22, 3.0}, {c111, \n    1.0}, {w, 0.5}}]\n\nOut[18]= {m11 -> 0.110727, m12 -> 0.110757, m21 -> 3.0927, \n m22 -> 3.02315, c111 -> 1.02661, c112 -> 0.0587281, c122 -> 1.0372, \n c211 -> 0.918792, c212 -> -0.16114, c222 -> 0.978021, w -> -0.414975}\n\nThe original parameters can be obtained as\n\nIn[19]:= {w1, 1 - w1, m1, s1, m2, s2} /. est3\n\nOut[19]= {0.39772, 0.60228, {0.110727, \n  0.110757}, {{1.05393, 0.060291}, {0.060291, 1.07923}}, {3.0927, \nshare|improve this answer\nThis is a great answer. I hadn't realized that EstimatedDistribution doesn't take sensible constraints on the parameters into account. So, I assume that we have to use similar tactics for other distributions, right? Like n>=0 for the binomial distribution and sigma >=0 for normal distribution. \u2013\u00a0Sjoerd C. de Vries Jul 3 '13 at 21:03\n\nYou may have more success creating your own custom mixture distribution.\n\nOleksandr Pavlyk created a presentation about creating distributions in Mathematica for the Wolfram Technology Conference 2011 workshop:\n\n'Create Your Own Distribution'.\n\nYou can download it here.\n\nThe downloads include the notebook,\n\n\nthat seems to lay out all the pieces required to create a distribution that one can use like the distributions that come with Mathematica.\n\nIt takes some time and thought to set up all of the pieces, but once done your custom distribution can work like a charm.\n\nshare|improve this answer\nI think that defining a new distribution would be much more difficult that implementing the EM algorithm, which is relatively simple. \u2013\u00a0Giuseppe Cardone Nov 23 '12 at 20:13\nI cant seem to find the .nb file? \u2013\u00a0Chen Stats Yu Dec 19 '14 at 1:04\n@ChenStatsYu -- Send me an email and I can send you the notebook. You can find my address in my profile. \u2013\u00a0Jagra Dec 19 '14 at 14:04\n@Jagra Sorry about the confusion. I finally got the notebook. I will give it a go. I am having some trouble optimizing a likelihood from a mixture distribution. I wonder define an implicit PDF will have a better way to find mle. \u2013\u00a0Chen Stats Yu Dec 19 '14 at 14:17\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-total-current.82840/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the total current\n\n  1. Jul 21, 2005 #1\n    A coil of self-inductance 0.7H is joined in parallel with a non-inductive resistance of 50 ohm. Calculate the total current, the current throught the wattless and power components when connected to a supply of 200V at a frequency of 50Hz.\n\n    Here is my steps:\n    Impedance Z= root [ 50^2 + (2pi*50*0.7)^2 ] = 225.5 ohm\n    Total current = 200/ Z = 0.9756A\n\n    Am I right? as for the other two questions, i really don't know how to solve them. :confused: Please help me with it. Thank you!\n\n  2. jcsd\n  3. Jul 21, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have treated the resistor and coil as a series combination. The problem says they are in parallel.\n\n\n    When you do the first part correctly, you will be able to find the total current. You can find the current in each branch, and therefore in each device using the individual impedences and the applied voltage.\n    Last edited: Jul 21, 2005\n  4. Jul 21, 2005 #3\n    the equation for total impedance Z you used above would apply to a series circuit with coil inductance 0.7H and resistor resistance 50 ohms.\n    however, in this case, these 2 components are in parallel, and you would first need to compute Ztotal using (complex impedances):\n\n    [tex] \\frac{1}{Z_{total}} \\ = \\ \\frac{1}{Z_{coil}} \\, + \\, \\frac{1}{Z_{resistor}} [/tex]\n\n    and then use:\n\n    [tex] Total \\ Current \\ Magnitude \\ = \\ \\frac{200 \\ Volts}{|Z_{total}|} [/tex]\n\n    an easier method for this parallel circuit is to sum the currents thru each branch of the parallel circuit:\n\n    [tex] \\mbox{Current Thru Coil} \\ = \\ \\frac{200}{2 \\pi (50)(0.7)\\mathbf{j}} [/tex]\n\n    [tex] \\left ( \\ \\ \\mbox{Current Magnitude Thru Coil} \\ = \\ \\left | \\, \\frac{200}{2 \\pi (50)(0.7)\\mathbf{j}} \\, \\right | \\ = \\ \\frac{200}{2 \\pi (50)(0.7)} \\ \\ \\right ) [/tex]\n\n    [tex] \\mbox{Current Thru Resistor} \\ = \\ \\frac{200}{(50)} [/tex]\n\n    [tex] \\mbox{Total Current Magnitude} \\ = \\ \\, \\left \\Large | \\, \\mbox{Current Thru Coil} \\ + \\ \\mbox{Current Thru Resistor} \\, \\right | [/tex]\n\n    this also answers the last 2 questions of your problem.\n    (*** Clarifications/corrections added from suggestions by OlderDan ***)\n    Last edited: Jul 21, 2005\n  5. Jul 21, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The currents are not in phase. You cannot simply add them. Your first equation is valid only if complex impedences are used. I fixed the link in my earlier post. Check it out.\n  6. Jul 21, 2005 #5\n    Hello olderdan and geosonel, thank you for your help. I realise I have treated the problem wrongly. However, when I follow your method, i get the total current to be 4.9095 ohm; and the answer given is 0.8865A. Yet, the other two answers are 0.8642A and 0.1964A respectively, which do not add up to 0.8865A...What do you think? :)\n  7. Jul 21, 2005 #6\n    OlderDan -- your comments are, of course, correct.\n    the entire Msg #3 was originally intended to incorporate COMPLEX impedances and use complex representations. clarifications/corrections have been added based on your suggestions.\n\n    Clari --\n    changes were made to Msg #3 to better indicate the COMPLEX representations of the various quatities. do you know how to use these complex representations? specifically, the total current would be equal to:\n    total current = (complex current thru coil) + (complex current thru resistor)\n    = (-0.9095j) + (4)\n\n    total current MAGNITUDE = | (-0.9095j) + (4) |\n\n    [tex] \\ = \\ \\sqrt{(0.9095)^{2} + (4)^{2}} \\ = \\ 4.102 \\ amps [/tex]\n\n    the individual current magnitudes must be combined like shown above because the current thru the coil and current thru the resistor are out of phase (which is why they are represented by complex quantities).\n\n    apparently the book is wrong about the answer. either that or you may have made a careless error in copying the problem. you might double check the problem.\n  8. Jul 21, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I think you have not treated the impedence as complex when calculating the equivalent impedence, and the unit of \"ohm\" in your result should be \"amp\". I see no way of getting the answers you have been given. A 50 ohm resistor by itself connected to a 200 volt supply would give a 4 amp current. A parallel path through the 0.7H inductor would give a current of 0.9095 amp at 50 hz that is 90 degrees out of phase with the resistor current. You cannot simply add these two (which is effectively what you did by not calculating the equivalent impedence correctly) because they are out of phase, but even when added correctly they still add up to about 4.10 amps, which is a lot more than the answers you are given.\n\n    EDIT: Late to the party again :smile: See geosonel's reply for more detail on the calculations\n\n    Please check the problem and make sure you are stating it correctly. The ratio of the currents given for the separate currents is about right. Is there something else in series with the parallel combination? Do you have the voltage right?\n    Last edited: Jul 21, 2005\n  9. Jul 23, 2005 #8\n    I think your answers are right, while those given by my teacher are wrong, so i believe i know how to sort it out now. ^^ Thank you very much!! :smile:\n\n    To geosonel, i haven't learned anything about the RLC circuit in parallel in fact, so i know nothing about complex representations. What is j in:\n    To olderdan, i have stated out the problems clearly, and there's certainly nothing in series with the parallel combination.\n  10. Jul 23, 2005 #9\n    Clari -\n    we didn't know your mathematical background when suggesting the \"complex representation\" method for AC circuits. unfortunately, it's difficult to provide a complete tutorial on AC circuit methods in this forum.\n\n    if you're interested in learning what the \"j\" signifies in the previous msgs and how the \"complex representation\" method works, try the tutorial given in the URL link below. (this tutorial takes 8 pages, including the introduction). this link also provides good info on many other electronic circuit topics.\n    Last edited: Jul 23, 2005\n  11. Jul 23, 2005 #10\n\n\n    User Avatar\n    Homework Helper\n\n    I have done the problem with very basic method by taking voltage V = v(max)sin(wt)\n    taking the total instantaneous current then finding the rms value of it using integration method and got the same answer 4.102 A as by geosonel\n    Last edited: Jul 23, 2005\n\nHave something to add?\n\nSimilar Discussions: Calculate the total current\n  1. Calculating current (Replies: 2)\n\n  2. Calculating current (Replies: 3)\n\n  3. Calculating Current (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/volume-of-a-solid.3590/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nVolume of a solid\n\n  1. Jul 4, 2003 #1\n    I need help on this problem which is giving me a few headaches...!!!!\n\n    here goes..\n\n    Show that the volume of the solid bounded by the coordinate planes and the plane tangent to the portion of the surface xyz = k, k>0, in the first octant does not depend on the point of tangency.\n\n    Your help will be much appreciated.\n  2. jcsd\n  3. Jul 4, 2003 #2\n    OK, i think i have the answer. i make it 9k/2. how much help do you want?\n\n    my first hint: the normal to that surface can be found by taking the gradient.\n  4. Jul 4, 2003 #3\n    Hi lethe,\n\n    I am totally lost on this question to be honest and I can't seem to work out what to do here to solve it. I would really appreciate it if you could explain step by step what you are doing so I can understand how you came to your conclusion and your answer.\n\n    eg. how you came to your answer of 9k/2.\n\n    and also your hint: the normal to that surface can be found by taking the gradient.\n\n    How would you go about solving this?\n\n    Your help will be greatly appreciated.\n  5. Jul 4, 2003 #4\n\n    step 1: the gradient of xyz - k gives you the normal vector to the surface.\n\n    the gradient is (yz,xz,xy)\n\n    step 2: the equation for a plane with normal vector n is n*(x-x0)=0\n\n    so the equation for the tangent plane at x0 is y0z0(x-x0)+x0z0(y-y0)+x0y0(z-z0)=0\n\n\n    x/x0 + y/y0 + z/z0 = 3\n\n    step 3: find the three coordinate intercepts of this plane by plugging in x=y=0 and get z=30, then x=z=0 and get y=3y0, and x=3x0\n\n    step 4: calculate the volume. it is a right pyramid, the base has legs 3x0 and 3y0, so the area of the base is 9x0y0/2. the area for a pyramid is 1/3*Base*height, so this is 9x0y0z0/2, but since x0 is on the surface, x0y0z0 = k, and we get 9k/2 for the volume\n  6. Jul 5, 2003 #5\n    Hey thanks for your help lethe!\n\n\nHave something to add?\n\nSimilar Discussions: Volume of a solid\n  1. Volume of a solid (Replies: 1)\n\n  2. Solid angle (Replies: 7)\n\n  3. Imaginary volume (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/intersection-of-two-functions.265279/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntersection of two functions\n\n  1. Oct 17, 2008 #1\n    (Problem from practice math subject GRE exam:) At how many points in the xy-plane do the graphs of [tex]y=x^{12}[/tex] and [tex]y=2^x[/tex] intersect?\n\n    The answer I got was 2, but the answer key says 3.\n\n    Intuitively, by the shape of their graphs, I would say two. I tried to calculate actual values for x:\n\n\n    [tex]x\\ln2=12\\ln x[/tex]\n\n    [tex]\\frac{\\ln2}{12}=\\frac{\\ln x}{x}[/tex]\n\n\n    I don't know what to do with that last equation.\n\n    I'm really confused though, because I can't even imagine how they would get a third intersection. Any help would be appreciated. :)\n  2. jcsd\n  3. Oct 18, 2008 #2\n    It's pointless to try to solve a transcendental equation analytically. Remember that x^12 is an even function, and note that 2^x approaches 0 as x approaches -infinity, but also remember that when x=0 that x^12 = 0, so you know that the two plots cross once for x < 0. You might guess they cross once for x>=0, but think about when x is > say 1000 and when x is say 2. Which function is larger in each case? Which is larger at x=0? Which is larger for x = -1000?\n  4. Oct 18, 2008 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Clearly the graph of y= 2x crosses the graph of y= x12 for x somewhere between -1 and 0: 2-1= 1/2 and (-1)12= 1 so the graph of x12 is higher for x= -1 while, at x= 0, 20= 1 and 012= 0 so the graph of 2x is higher for x= 0.\n\n    Also 212= 4096 while 22= 4: the graph of x12 is higher again so the graph must intersect again between x= 0 and x= 2.\n\n    The question, then, is whether the graphs intersect a third time for x> 2; whether 2x is larger than x12 for \"sufficiently large x\".\n\n    One way to answer that is to look at the limit of 2x/x12 as x goes to infinity. Since that fraction itself becomes \"infinity over infinity\" we can apply L'Hopital's rule. Repeatedly differentiating, the numerator just stays 2x (times a power of ln(2)) while the denominator has lower and lower powers eventually becoming a constant (after 12 differentiations, we get 12!) and then 0. What does that tell you about the limit? And what does that tell you about whether 2x or x12 is larger for very large x?\n  5. Oct 18, 2008 #4\n    Thanks! This makes sense. So...\n\n\n    Which means that for very large x, 2^x does eventually exceed x^12, which gives us the third intersection point.\n\n    So, one last question -\n\n    Is this a good general strategy for this type of problem (if I were to get a similar one on the actual exam): First sketch the graph and see what obvious/immediate intersection points I can find. Then use the limit idea for [tex]x\\rightarrow\\infty[/tex] and [tex]x\\rightarrow-\\infty[/tex].\n\n    Will this ensure that I find all of my intersection points?\n\n    Thanks so much! :)\n  6. Oct 18, 2008 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Not necessarily. For example, it there were 3 more intersections between x= 2 and infinity, the same changes in which is smaller and which is larger would be true. You might try looking at the derivative of f- g. If that is always positive, then that can't happen.\n\nHave something to add?"}
{"text": "Retrieved from http://www.pedagonet.com/mathgenius/answer257.html\nText:\nAnswer :\n\nThe correct answer is 1,992 different ways.\u00a0\nEvery F is either a corner F or a side F\u2014standing next to a corner in its own square of F's.\u00a0\nNow, FIED may be read from a corner F in 16 ways; therefore DEIF may be read into a corner F also in 16 ways; hence DEIFIED may be read through a corner F in 16\u00a0\u00d7\u00a016\u00a0=\u00a0256 ways.\u00a0\nConsequently, the four corner F's give 4\u00a0\u00d7\u00a0256\u00a0=\u00a01,024 ways.\u00a0\nThen FIED may be read from a side F in 11 ways, and DEIFIED therefore in 121 ways.\u00a0\nBut there are eight side F's; consequently these give together 8\u00a0\u00d7\u00a0121\u00a0=\u00a0968 ways.\u00a0\nAdd 968 to 1,024 and we get the answer, 1,992.\n\nIn this form the solution will depend on whether the number of letters in the palindrome be odd or even.\u00a0\nFor example, if you apply the word NUN in precisely the same manner, you will get 64 different readings; but if you use the word NOON, you will only get 56, because you cannot use the same letter twice in immediate succession (since you must \"always pass from one letter to another\") or diagonal readings, and every reading must involve the use of the central N.\n\nThe reader may like to find for himself the general formula in this case, which is complex and difficult. I will merely add that for such a case as MADAM, dealt with in the same way as DEIFIED, the number of readings is 400.\n\nMath Genius"}
{"text": "Retrieved from http://math.stackexchange.com/questions/2356/is-it-possible-to-split-coin-flipping-3-ways/620526\nText:\nSign up \u00d7\n\nWhen flipping a coin to make important decisions in life you can flip once to choose between 2 possible outcomes. (Heads I eat cake, Tails I eat chocolate!)\n\nYou can also flip twice to choose between 4 outcomes. (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads)\n\nCan you use a coin to choose evenly between three possible choices? If so how?\n\n(Ignoring slight abnormalities in weight)\n\nshare|cite|improve this question\nSee also:\u2026 \u2013\u00a0Isaac Aug 13 '10 at 15:55\n@Isaac: Your link is an exact duplicate. Why wasn't this question closed? \u2013\u00a0Casebash Aug 13 '10 at 23:39\nMeta discussion here:\u2026 \u2013\u00a0Tom Boardman Aug 14 '10 at 0:08\nfind a coin with a large edge, so that the probability it falls on the edge is 1/3. now you only need one toss :) \u2013\u00a0user20963 Dec 10 '11 at 6:05\n@Nico: Or just flip a coin in a world where 2 = 3... not very useful answer. \u2013\u00a0The Chaz 2.0 Dec 10 '11 at 10:11\n\n8 Answers 8\n\nup vote 17 down vote accepted\n\nIf you throw your coin $n$ times you have $2^n$ outcomes, the probability of each of which is $\\frac{1}{2^n}$. The larger $n$ is, the better you can divide $2^n$ into three approximately equal parts:\n\nJust define $a_n=[2^n/3]$ and $b_n=[2\\cdot 2^n/3]$, where $[\\cdot]$ denotes rounding off (or on). Since $\\frac{a_n}{2^n}\\to\\frac{1}{3}$ and $\\frac{b_n}{2^n}\\to\\frac{2}{3}$ as $n\\to\\infty$, each of the three outcomes\n\n\"the number of Heads is between $0$ and $a_n$\",\n\n\"the number of Heads is between $a_n$ and $b_n$\", and\n\n\"the number of Heads is between $b_n$ and $2^n$\"\n\nhas approximately the probability $\\frac{1}{3}$.\n\nAlternatively, you could apply your procedure to get four outcomes with the same probability (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads) to your problem in the following way:\n\nAssociate the three outcomes Heads-Heads, Tails-Tails, Heads-Tails with your three possible choices. In the case that Tails-Heads occurs, just repeat the experiment.\n\nSooner or later you will find an outcome different from Tails-Heads.\n\nIndeed, by symmetry, the probability for first Heads-Heads, first Tails-Tails, or first Heads-Tails is $\\frac{1}{3}$, respectively.\n\n(Alternatively, you could of course throw a die and select your first choice if the outcome is 1 or 2, select your second choice if the outcome is 3 or 4, and select your third choice if the outcome is 5 or 6.)\n\nshare|cite|improve this answer\nCan't you count tails-heads as the same as heads-tails? \u2013\u00a0Tyler Hilton Aug 13 '10 at 15:26\n@Affan, it would not be fair as that possibility would occur with the same probability as the other two combined. \u2013\u00a0Joshua Shane Liberman Aug 13 '10 at 15:35\nOh I get ya, thanks! \u2013\u00a0Tyler Hilton Aug 13 '10 at 17:15\nI think what Rasmus meant (in the second part) is that you would always toss in pairs and take into account the order of the two tosses: only if the first toss (of a pair) is tails and the second toss is heads toss the coin another two times. \u2013\u00a0Andre Holzner Aug 19 '10 at 18:58\n\nA simple (practical, low-computation) approach to choosing among three options with equal probability exploits the fact that in a run of independent flips of an unbiased coin, the chance of encountering THT before TTH occurs is 1/3. So:\n\nFlip a coin repeatedly, keeping track of the last three outcomes. (Save time, if you like, by assuming the first flip was T and proceeding from there.)\n\nStop whenever the last three are THT or TTH.\n\nIf the last three were THT, select option 1. Otherwise flip the coin one more time, choosing option 2 upon seeing T and option 3 otherwise.\n\nshare|cite|improve this answer\n\nEDIT Oh dear, Rasmus has extended his answer and rendered this one obsolete! In fact, stop reading this right now and go see what he has done.\n\nI interpret what you are asking as trying to find a way to decide without introducing bias (as would be introduced by counting tails-heads as the same as heads-tails). Rasmus's suggestion of repeating the experiment for a certain configuration seems the best choice.\n\nI drew a little tree and tried to group outcomes into three \"equally-likely\" sets and then realized this is impossible because $3$ does not divide $2^n$ for any $n$. (The quantity $2^n$ being the number of unique outcomes after $n$ \"flips\".)\n\nshare|cite|improve this answer\n\nHere's another method: consider H to be 0 and T to be 1. Consider the results that you get from your coins as successive bits (after the binary point) in a binary number. Assign numbers in the interval [0, 1/3) to the first choice; [1/3, 2/3) to the second choice; [2/3, 1) to the third choice. Flip coins until you know, no matter what happens on the remaining flips, in which of these intervals the resulting real number in [0, 1) will lie.\n\nMore concretely, this means that if you flip two coins and observe HH, make the first choice; no matter what happens the result will be between .0000... = 0 and .001111... = 1/4. Similarly if you observe TT, make the third choice; the result will be between 3/4 and 1. If you observe HT, you can't commit to a choice yet; the result will be between 1/4 and 1/2, which overlaps two of the intervals. Something similar is true for TH.\n\nIn either case flip a third time. HTT corresponds to the interval [3/8, 1/2) which lies entirely in [1/3, 2/3), so HTT corresponds to the second choice; similarly for THH. If you see HTH you're still undecided between the first and second choices; THT is still undecided between the second and third.\n\nContinuing in this way, HTHH corresponds to the first choice, HTHT and THTH are still undecided, THTT corresponds to the third choice.\n\nIn general, for the cut-points 1/3 and 2/3, you flip coins until you get either two heads or two tails in a row. If you first get two heads in a row, this corresponds to the first choice if the initial flip was a head, the second if the initial flip was a tail. If you first get two tails in a row, this corresponds to the second choice if the initial flip was a head, the third choice if the initial flip was a tail.\n\nYou might wonder how many flips this takes, on average, to give a result. With probability 1/2 you get a result on the second flip; with probability 1/4, on the third flip; with probability 1/8, on the fourth flip, and in general with probability $1/2^{n-1}$ for $n \\ge 2$. The sum $\\sum_{n \\ge 2} n/2^{n-1}$ has value 3, so on average this method takes three flips.\n\nThis is a bit slower on average than the method Rasmus suggested, which takes on average 8/3 flips. However, the same method works even if the three choices are not equally likely! (It won't have such a clean way of being expressed as \"flip until you get two in a row\", though.)\n\nshare|cite|improve this answer\n\nIf you are at a crossroads in life requiring you to choose one of three options, then coin tossing is not the correct thing to do.\n\nRather, pick up a dice and roll it. Go for first option if the diece turns up 1 or 2. Go for second option if the dice turns up 3 or 4. Go for the third option if the dice turns up 5 or 6.\n\nEdit: Oops, I saw that Rasmus already gave this option. Anyway I strongly suggest that you prefer this one to the other two methods given by him.\n\nshare|cite|improve this answer\nWell, from the philosophically view-point, I think it's inadvisable to use random experiments for decision making anyway. \u2013\u00a0Rasmus Aug 13 '10 at 15:57\nTrue, true. But if at all someone does a random experiment for decision making, better do one that will get done in the shortest time! So your third method is more time-saving compared to the other two. \u2013\u00a0user1119 Aug 13 '10 at 16:02\n@Rasmus: From a game-theory viewpoint, it often is advisable to use a random method to make decisions. :) \u2013\u00a0Larry Wang Aug 13 '10 at 16:40\n@Kaestur Hakarl: Well... Touch\u00e9! :) \u2013\u00a0Rasmus Aug 13 '10 at 16:53\nOne of Piet Hein's grooks comes to mind: A PSYCHOLOGICAL TIP Whenever you're called on to make up your mind, and you're hampered by not having any, the best way to solve the dilemma, you'll find, is simply by spinning a penny. No -- not so that chance shall decide the affair while you're passively standing there moping; but the moment the penny is up in the air, you suddenly know what you're hoping. \u2013\u00a0Bob Durrant Sep 15 '10 at 20:49\n\nI think I have a pretty good idea where you don't have to redo at all.\n\nflip the coin to decide a side for the first two possibilities. if heads come up, its heads for option 1 and tails for option 2 or vice versa flip again to decide a side for option 3. hence, we have 3 outcomes of a coin for 3 possibilities, and all three are not the same. example: H for 1, T for 2 and T for 3, but not H or T for all 3 options.\n\nnow flip again. if the coin lands on heads, and heads is only on say, option 1, then option 1 wins. if H is on 2 options, select those 2, keep heads for 1 and tails for the other, flip again and decide. the same is applicable if it lands on tails.\n\nI hope you understand how it works and how each option has an equal chance of getting selected.\n\nyou don't have to redo your flips anywhere here. (there is a definite answer).\n\nshare|cite|improve this answer\nAn interesting idea, but I don't think it works. Option 3 is guaranteed to match one of the first two options. It will never be the lone-H or lone-T, and thus will never be selected by the first flip. Option 1 or Option 2 are thus more likely to be selected. \u2013\u00a0Nathan Kurz Mar 22 '14 at 17:46\n\nI prefer a method based on a simple unbalanced game: the first person to throw heads wins. In this game, the person who throws first has a $\\frac 23$ chance of winning, the other has a $\\frac 13$ chance of winning.\n\nTo decide fairly between three outcomes, simply put two outcomes on one team in this game, so they have a $\\frac 23$ chance of getting picked. If this team of outcomes wins, simply toss another coin to decide between them. If the other team wins, there is only one outcome on that team and so no further tosses are needed.\n\nThis method is equivalent to Rasmus's \"alternatively\" answer, and will take $2{\\frac 23}$ coin tosses on average. I don't think there exists a method with fewer average coin tosses, but I have no proof of this.\n\nshare|cite|improve this answer\n\nConsider a similar problem and answer first that happens for our gaming group: If you have a die and need a choice from 1-5, how do you do it? One way is to roll the die and re-roll if you get a six. The advantage of this method is that in a noisy group of drunken people you won't get an objection that one outcome is favored over another.\n\nIn the same vein, people are apt to readily acknowledge there are 4 possibilities for a coin flipped twice (or flip two different coins such as a sickle and a knut at once). In the case that both sickle and knut come up tails, flip both again until you have one of the other three outcomes.\n\nshare|cite|improve this answer\n\nprotected by Zev Chonoles Jul 14 at 0:46\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/22002/travelling-salesman-with-start-and-end-points-for-30-points/22015\nText:\nSign up \u00d7\n\nI am doing a route optimisation for delivery vehicles and failing dismally. Please see problem statement below. My current solution uses FindShortestTour, but this does not have defined start and end points.\n\nData is received from the calling application in the following format: {\"Unique Identifier used by server\", Original order, Task locked, Latitude, Longitude}\n\nThe first point will always have the unique identifier \"00000000-0000-0000-0000-000000000000\" and represents the depot. This point will always have an order of 1 and always be locked.\n\nA number of tasks may be locked in their given order at the beginning of the list. The Task locked is a boolean represented by 1 - locked, 0 - unlocked. These locked tasks are not included in the optimisation as they are fixed in their given order at the beginning of the scheduled.\n\nThe route is to be optimised finding the shortest path starting at the last locked point and ending back at the depot, traversing all other unlocked points. Depot is always locked and will be used if there are no other locked tasks.\n\nThe output is to be in the following format: {\"Unique Identifier used by server\", Original order, Distance to Next Task in km} and is to be arranged in the optimal order. The order will always start with the depot the traverse locked Tasks in their given order. This will be followed by unlocked tasks optimised from the last locked to the depot. This list will not contain the final depot point as the distance returned is the distance to next task. i.e. The last ordered task distance will be the distance from itself to the depot.\n\nThe calculation needs to be able to handle the optimisation of 30 points in under a minute as accurately as possible.\n\ninput = {{\"00000000-0000-0000-0000-000000000000\", 1., \n    1., -26.17132739, \n    28.21375807}, {\"817463b3-e330-4405-9008-e21821e6c121\", 2., \n    1., -26.2055333333333, \n    28.420565}, {\"36418378-a9ef-49d7-be5a-3a54264a8479\", 3., \n    0., -25.99202013, \n    27.53309061}, {\"49595197-11e5-463a-8f7b-6cd294c33f43\", 4., \n    0., -26.14895194, \n    27.92271447}, {\"83fd029b-0313-4519-a785-ff7b9843c85c\", 5., \n    0., -26.169355, \n    28.2079083333333}, {\"612bf08a-1679-4feb-8fee-d12deb49803a\", 6., \n    0., -25.6755766666667, \n    28.0820533333333}, {\"382f1997-5efe-42c1-99f5-bcb8da30e1c8\", 7., \n    0., -26.8742866666667, \n    28.25047}, {\"883d68f2-b50f-48ca-b065-febfc6ea9546\", 8., \n    0., -26.0938733333333, \n    28.1937966666667}, {\"1bf089bf-acae-4a41-8c4b-e120cef8a148\", 9., \n    0., -25.9877716666667, \n    28.0691433333333}, {\"6958e90b-d42a-4c13-b6ec-78bbdd301aba\", 10., \n    0., -25.7661166666667, \n    28.2811033333333}, {\"2f2c5d25-c1de-449e-b779-dd95699d83ed\", 11., \n    0., -26.0474216666667, \n    28.0060766666667}, {\"a11feb01-f067-49aa-b99d-50879229c423\", 12., \n    0., -25.7949916666667, \n    28.29928}, {\"729b8bfb-029a-483a-814a-1575a6fe47bc\", 13., \n    0., -26.0258616666667, \n    28.0692033333333}, {\"732771dd-55fd-4074-a097-2665686f67d8\", 14., \n    0., -26.772045, \n    28.49977}, {\"0690914d-ba34-4086-b5ae-feda7ed6d22b\", 15., \n    0., -26.044905, \n    28.0346666666667}, {\"5de23f0e-9a05-40af-8e1e-f887d5a06452\", 16., \n    0., -26.4070083333333, \n    28.138515}, {\"3e95a2ac-9985-4753-a4cc-5372ca44ed12\", 17., \n    0., -25.64392423, \n    28.13148167}, {\"d2e0bce2-8061-4b57-b983-aa409c1532fe\", 18., \n    0., -26.42138814, \n    28.1074221}, {\"0259d54a-0782-4ac8-a5f6-42af6e3edbc3\", 19., \n    0., -25.78637, 28.28066}, {\"f686b23a-de85-4004-ae70-8d2703336b5d\",\n     20., 0., -26.043795, \n    28.1197816666667}, {\"e8bca7d4-69ad-4477-8791-9daedbc563c9\", 21., \n    0., -26.2624883333333, 28.17859}};\n\n   27.24}, ..., {\"83fd029b-0313-4519-a785-ff7b9843c85c\", 5., 0.62}}\n\nCurrent poor solution here:\n\nEdit The requirement boils down to a traveling salesman path problem.\n\nI have a fixed start and end point with a list of intermediate points which need to be visited exactly once in an optimal order.\n\nI have a working solution here\n\nshare|improve this question\nHello, and welcome to Mathematica.SE! Please edit your question to contain a minimal example, say, with a small collection of cities for your problem. So we can most directly address the Mathematica question at hand, and not the logistics one. \u2013\u00a0VF1 Mar 24 '13 at 19:59\n@TheGwa: is this a typo in the headline? I'm only counting 20 or 21 points (depending on how you see this, it can be considered a 20 or 21 point problem). But where does the 30 in the title come from? \u2013\u00a0Andreas Lauschke Mar 25 '13 at 18:24\n@VF1 I am new to Mathematica and was hoping that giving the most possible information about my problem at hand would get me the most directed help. I have clarified the question and added my working solution to it too. Many thanks. \u2013\u00a0TheGwa Mar 25 '13 at 22:21\n@Andreas: Sorry I have edited the question. 30 points is what I need. \u2013\u00a0TheGwa Mar 25 '13 at 22:22\nTry with an intelligent goo:\u2026 \u2013\u00a0faysou Mar 26 '13 at 9:42\n\n3 Answers 3\n\nup vote 7 down vote accepted\n\nCould make the end point have distance zero from the depot. Say pt 2is your start point and pty 1 is the finish (depot). Then your example could have a route computed thusly.\n\npt2 = input[[All, 4 ;; -1]];\nlen = Length[pt2];\n\ndists = Table[Norm[pt2[[j]] - pt2[[k]]], {j, 1, len}, {k, 1, len}];\ndists[[1, 2]] = dists[[2, 1]] = 0.;\n\n DistanceFunction -> (dists[[#1, #2]] &)]\n\n(* Out[123]= {3.808066795204197, {1, 5, 8, 20, 13, 15, 11, 9, 12, 19, 10,\n   17, 6, 3, 4, 21, 16, 18, 7, 14, 2}} *)\n\nNow just reverse it to start at point 2 and end at the depot.\n\nshare|improve this answer\nBut that's exactly my point. It's cheating if you can pick and choose your start and end nodes. The optimal tour is {{-25.6756,28.0821},{-25.6439,28.1315},{-25.7661,28.2811},{-25.7864,28.2807},{-2\u200c\u200b5.795,28.2993},{-26.2055,28.4206},{-26.772,28.4998},{-26.8743,28.2505},{-26.4214,\u200c\u200b28.1074},{-26.407,28.1385},{-26.2625,28.1786},{-26.1713,28.2138},{-26.1694,28.207\u200c\u200b9},{-26.0939,28.1938},{-26.0438,28.1198},{-25.9878,28.0691},{-26.0259,28.0692},{-\u200c\u200b26.0449,28.0347},{-26.0474,28.0061},{-26.149,27.9227},{-25.992,27.5331}}, verified optimal, and the longest edge is between start and end, the length is 3.22458 \u2013\u00a0Andreas Lauschke Mar 25 '13 at 5:27\n@Andreas The query stated that it was necessary to fix a start and end (and gave a straightforward justification for that). I made no claim to the effect that the tour I found was optimal in the TSP sense, only that it seemed fine for the stated purpose of the original post. As for \"cheating\", I have no idea how meeting (or trying to meet) a stated requirement falls into that category. \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 17:10\nthe o/p does not mention a specific start point -- unless I'm missing something (in that case please correct me). You pick the start point purely arbitrary, which gives you room to make your solution almost arbitrarily \"good\". As for you having no idea how meeting a stated requirement falls into the cheating category, I can only concur, but you merely CLAIM you are meeting a stated requirement. As I said, you pick your start node arbitrarily, giving you the option to pick and choose, thus making your tour (almost) arbitrarily \"good\" (or bad). \u2013\u00a0Andreas Lauschke Mar 25 '13 at 17:17\n@Andreas The statement has the route beginning at the last locked point, and ending at the depot (which I assumed to be the initial point, also categorized as locked). I simply reversed this, found a tour starting at the depot and ending at the last locked point which, in this example, was the second point. Then said to simply reverse that. I now notice that another point, #14, is also locked, so the basic idea seems about right but not the actual result. On a separate note, I'm not sure how preselecting a starting point leads to a better (let alone arbitrarily good) solution for a TSP. \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 17:24\n@Andreas You are certainly correct. I confess I was oblivious to the possibility that our discussion had a point... \u2013\u00a0Daniel Lichtblau Mar 25 '13 at 18:04\n\nNote that FindShortestTour will not allow for start and end points because it is a tour, and thus you can cycle your staring and ending point by simply removing an edge in your Hamiltonian circuit. To find the shortest path for a given start and end point, I would recommend searching for \"find shortest path\" in the Documentation Center, which would lead one to the function of interest, FindShortestPath.\n\nAs speed seems to be an issue, consider changing the Method used by the function or implementing your own approximate algorithm. However, I don't think it would be necessary to go this far as you stated your problem is for 30 points.\n\nEDIT: As requested, here is an approximate algorithm for the traveling salesman problem. If a significant speed/optimization is required, feel free to implement your own. In the method, start refers to the starting vertex, and adj refers to the adjacency matrix of the graph (you will have to create your own).\n\nHere is a nearest-neighbor algorithm:\n\nNearestNeighbor[start_Integer?Positive, adj_?MatrixQ]:=\n    With[{len = Length[adj]},\n        Module[{visited=ConstantArray[1, len], nearest, neighbors, mult, total = 0},\n                visited[[#]] = Infinity;\n                neighbors = adj[[#]];\n                mult=neighbors visited;\n                First@First[Position[mult, nearest]]\n\nYou can easily create an adjacency matrix by telling Mathematica to do so after you have created a Graph object from your coordinates. Look up WeightedAdjacencyMatrix and Graph in the documentation. If you have a set of points pts, then it is fairly easy to do:\n\npts = RandomReal[1, {20, 2}];\nwam[pts_, dist_: EuclideanDistance] := \n  Array[If[Equal[##], Infinity, \n     dist[pts[[#1]], pts[[#2]]]] &, {Length@pts, Length@pts}];\nshare|improve this answer\nThanks VF1. I have tried to implement the shortest path algorithm from here:\u2026 it is too slow for anything over 17 points however. I have tried the FindShortestPath function, but I can't work out how to create a graph from my list of coordinates. Could you please point me to an approximate algorithm for the shortest path problem. \u2013\u00a0TheGwa Mar 24 '13 at 21:50\nI have supplied the Nearest-Neighbor approximate algorithm. This takes in a weighted adjacency matrix. In order to convert a set of coordinates into a Mathematica Graph object, I recommend you take a look at the documentation for Graph, please read the rest of my answer. \u2013\u00a0VF1 Mar 24 '13 at 23:31\nThank you for your input. It has helped me significantly in understanding a number of key concepts in Mathematica. It was not the solution I used in the end, but it helped greatly. \u2013\u00a0TheGwa Mar 25 '13 at 22:25\n\nJVMTools has very powerful TSP functions, using initial and post-opt methods and exploiting concurrency by submitting competing algorithms in parallel, and chaining post-opt methods (also in parallel):\n\nTSP Intro and TSP Power Examples\n\nIf you want specific start and end points, you could use the option \"All\", which will return all tours for the subdivision of the list of nodes, and then pick the first one. That is guaranteed to use the start and end points the user has provided. However, note that with fixed start and end points you may not necessarily get the shortest tour through all nodes. The author of JVMTools has specifically implemented it in a manner so that node list subdivision is used in parallel with the start-end edge as a viable candidate, so that it's not possible to \"cheat\" to create particularly good or bad solutions by specifying fixed start and end points. But, you can discard n-1 solutions and take only the first, that will use your start and end nodes.\n\nFindShortestTour[] uses very simple algorithms. 20 points is small enough, but even with 20 points you are most likely not getting an optimal tour with any of the FST methods. They have a free trial version for JVMTools that is not feature-capped (only time-limited). Some of the algorithms available through JVMTools solve TSP problems with a few thousand nodes to optimality with amazing speed (like less than a minute).\n\nAddition Mar 25:\n\nDue to Lou's request, here is my code. I'm a bit hesitant to say/show too much about JVMTools, because it's my own commercial product, and I don't want to do \"cheap plugs\" in this venerable community, but due to Lou's request, here it comes. Geez, this is gonna get long, but I like the \"Leonid method\" :).\n\nThere's a few ways to do it. If all distances are Euclidean lengths and you want one of the best TSP algorithms in the world (MAOS, \"multi-agent optimization system\", similar to an ant-colony optimization system), you could simply submit\n\nJTravellingSalesmanMAOS[Round[1000 input[[All,{4,5}]]],200,200,100,1,\"EUC_2D\"]//AbsoluteTiming\n\n\nThis uses 200 agents, 200 as the size of the maximum learning cycle as termination condition, 100 as the number of cycles for the best cycle that no longer changes, 1 as the number of trials, and EUC_2D to specify the 2-dimensional Euclidean norm as distance function. Don't worry, if you understand a bit about multi-agent / ant colony optimization, these terms will not be intimidating. With JVMTools you can use that powerful algorithm without understanding too much about multi-agent optimization / ant colony optimization. MAOS is used by JVMTools with permission of the owners.\n\nThe tour is verified optimal, and the only reason it takes 1.4 seconds total time is because the data is encrypted with asymmetric 2048 cipher strength encryption on the client side and sent to the JVMTools server, where the MAOS algorithm runs (like a webservice) on a high-performance Fedora 18 system, and then the result is sent back. 1.4 seconds for 20 nodes is a prohibitively long run time, but the encryption takes constant time for long as well as short data lists, and JVMTools wasn't written for such toy problems. When choosing the MAOS algorithm in JVMTools there is some 1.4 second overhead for everything you send, due to the encryption. This is to ensure that the client data remains confidential when travelling over the public internet with proven unbreakable encryption (active attacks, passive attacks, eavesdropping attacks, chosen-plaintext attacks, chosen ciphertext attacks, man-in-the-middle attacks, padding attacks, ...), and for large problems this constant 1.4 second encryption overhead amortizes away.\n\nBut you can also model things in a more flexible way, by specifying the node pairs you want to consider (or drop) and explicitly setting the edge lengths. This may be more appropriate here, as the o/p has \"non-standard\" edge lengths.\n\n\n\nIt looks a bit more complicated than how you specify it when using the MAOS algorithm in JVMTools or FST in M, but in the end it gives you more flexibility, because a) you can specify the distances for each and every one of the n(n-1)/2=Binomial[n,2] theoretically feasible edges individually (assuming complete graph to start with), setting it to any (positive) number, including MaxDouble or 0, b) you can leave out index pairs, which means there is no edge (taken as infinity) -- which means it is no longer a complete graph. With FST you can only specify a distance function, not what I would call edge data. In addition, pairs then provides a \"data overview\" in a concise form of what you are about to submit as edge-by-edge data. You could literally edit that manually in a spreadsheet program and read in as a M symbol, if you want to model a complicated non-Eudlidean, highly non-convex structure. And although these lists can get long (generated or edited manually), there is no time delay when sending it over to the JVM, because both indices as well as costs are rectangular arrays of compatible type, thus internally they are packed arrays (auto-packed), and JLink/MathLink uses native array methods for primitives, giving you native speed.\n\nUnless I miss something, the o/p did not specify the start node, only the end node (the first), so I can't address that specific case. All TSP functions in JVMTools assume that you want an optimal solution for the FULL cycle, this is by design and not an omission. But you can leave out edges and set arbitrary positive edge lengths, giving you full control over how to model it very individually.\n\nThe option ConcurrentPostOpt shown above did the following in 41 milliseconds:\n\n  \u2022 in thread 1, FarthestInsert is used as initial method, then 6NodeSwap is applied as post-opt, this is candidate 1. Next CheapestInsert is used as initial method, then 6NodeSwap is applied as post-opt, this is candidate 2.\n  \u2022 in thread 2 NearestNeighbor is used as initial method, then 6NodeSwapSingle is applied as post-opt, this is candidate 3.\n  \u2022 in thread 3 NearestNeighbor is used as initial method, then 6NodeSwapDouble is applied as post-opt, this is candidate 4.\n\nThe output is the best solution of candidates 1 through 4. As 6NodeSwap is extremely fast (yet effective), I have put two initial/post-opt pairs in one thread, as even both strategies one after the other is faster than the other two, meaning I can get 4 candidates by using only 3 threads.\n\nThe tour is verified optimal.\n\nBut with 20 nodes you can't really show any meaningful comparison. 20 nodes is a toy problem, a \"micro-benchmark\", which is not a meaningful comparison. The TSP functions in JVMTools were written for a few thousand nodes (a practical runtime/memory limitation is probably around 20 thousand nodes), where M can do nothing but throw in the towel.\n\nshare|improve this answer\nWhy don't you post the anser by using your environment. It seems that we now have two different answers to one question :). Your website looks great. \u2013\u00a0Lou Mar 25 '13 at 10:31\n@Lou: done, see my addition above. \u2013\u00a0Andreas Lauschke Mar 25 '13 at 17:06\nLauske Thanks for the edit. I learned alot and it seems more and more that Java and Mathematica form a very great couple indeed. Impressive. \u2013\u00a0Lou Mar 25 '13 at 20:24\n@Lou: indeed, M and the JVM are a match made in heaven. The M/.Net combination (qua NETLink) is also quite powerful, it's very, very similar. I mull writing a blog post here about using JLink. I think JLink is totally under-appreciated. \u2013\u00a0Andreas Lauschke Mar 25 '13 at 20:33\n@Andreas: This looks like a really amazing technology. Unfortunately I cannot install Java on the server due to security concerns, but I appreciate the input. I am sure it will help others greatly. \u2013\u00a0TheGwa Mar 25 '13 at 22:27\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164928/find-the-number-of-common-normals-to-both-these-curves\nText:\nSign up \u00d7\n\nFind the number of common normals to the curves $ x^2 + (y-1)^2 =1 $ and $y^2=4x$.\n\nMy take :\n\nI formed a cubic in $m$ i.e. slope, so there'll be 3 normals. Please help.\n\nshare|cite|improve this question\nPlease explain how you formed a cubic in slope $m$. \u2013\u00a0hardmath Jun 30 '12 at 15:13\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYour first curve is a circle of radius 1, centered at $(0,1)$. Its normals are the lines through its center, that is, the lines $$y=mx+1$$ for arbitrary $m$ (this leaves out the vertical normal, but that's obviously not normal to the other curve). So now you just have to work out the values of $m$ for which the graph of $y=mx+1$ is normal to the graph of $y^2=4x$. Can you do that?\n\nI guess not, so here goes.\n\nFrom $y^2=4x$ we get $2yy'=4$, so $y'=2/y$. If $(a,b)$ is a point on the graph of $y^2=4x$, then\n1. the slope of the normal to the curve at that point is $-b/2$, and\n2. $b^2=4a$.\nSo the equation of the normal is $$y-b=-(b/2)(x-a)$$ which we can write as $$y=-(b/2)x+(1/2)ab+b$$ But we want the normal to be $y=mx+1$, so $$(1/2)ab+b=1$$ Now combining that with $b^2=4a$, we get, after a little algebra, $$b^3+8b-8=0$$ and it's easy to show that equation has exactly one real zero, so there is exactly one common normal.\n\nshare|cite|improve this answer\nso, no real values of m. Thus no common normals. \u2013\u00a0Bazinga Jul 1 '12 at 7:46\nIf you sketch the two curves, I think it's clear that there is at least one common normal. \u2013\u00a0Gerry Myerson Jul 1 '12 at 9:00\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/58161/simulate-a-double-chance-bet-with-two-single-bets/58184\nText:\nSign up \u00d7\n\nIf you bet on the result of a soccer match, you usually have three possibilities. You bet\n\n  \u2022 1 - if you think the home team will win\n  \u2022 X - if you think the match ends in a draw\n  \u2022 2 - if you think the away team will win\n\nLets say we have the following soccer match with the following betting quotes:\n\nKansas City vs. Portland - 1 = 1.92, X = 3.57, 2 = 5.00\n\nThis means: If you think Portland (In the opinion of the bookie, the underdog) will win the match, you bet on 2\n\nExample (I bet \\$100): In case Portland wins I win \\$400 $$100*5.00-100 = 400$$ $$stake*quote-stake = net win$$ (When Portland loses the match, or it ends in a draw, I'll lose my stake)\n\nNow, some bookies offer a so-called double chance bet. This kind of bet takes one possibility out. That leaves you to following bets. You bet\n\n  \u2022 1/X - if you think the home team will win or the match ends in a draw\n  \u2022 X/2 - if you think the away team will win or the match ends in a draw\n\nThis variant is perfect if you think Portland will win the match, or at least it will end up in a draw. To calculate this quotes I use the following formula: (Q1 = 1st quote 1, Q2 = 2nd quote)\n\n$$ 1/(1/Q1+1/Q2) $$\n\nFor the 1/X bet $$ 1/(1/1.92+1/3.57) = 1.25 $$\n\nFor the X/2 bet $$ 1/(1/3.57+1/5) = 2.08 $$\n\nNow comes my math problem: When the bookie does not offer a double chance bet, I want to create it my self: With two single bets. For the Kansas City vs. Portland bet I'd like to place a X/2 bet. The quote for the bet is as I showed before 2.08. I want to place \\$100 on it. When I win the bet, I'll get \\$108 net win:\n\n$$100*2.08-100 = 108$$\n\nHow do I have to split the money on two (X and 2) single bets, to win \\$108, when Portland wins or the match ends in a draw?\n\nI got to the solution for this case by trying out. But with the result in my hand, I still don't get the formula to calculate it.\n\nI bet \\$58.35 on X and \\$41.65 on 2\n\n$$ 58.35*3.57-58.53-41.65 \u2248 108$$ and $$ 41.65*5.00-41.65-58.53 \u2248 108$$\n\nNotice the last subtraction. You have to subtract the stake of the other bet. Because when Portland wins, I win only the 2 bet and lose the stake for the X bet.\n\nshare|cite|improve this question\n\n4 Answers 4\n\nup vote 3 down vote accepted\n\nLet's examine the X/2 case. Denote by $Q_X=3.57$ the bookie's quote for X and $Q_2=5.00$ for 2. Denote by $Q=1/(1/Q_X+1/Q_2)=(Q_X Q_2)/(Q_X+Q_2)\\approx 2.0828$ the quote you have calculated for the X/2 bet. You want to split the total bet $B=\\$100$ into two bets $B_X$ (for X) and $B_2$ (for 2) so that $B_X Q_X=BQ=B_2 Q_2$. From the first equation you get $B_X=B(Q/Q_X)$. Similarly from the second equation you get $B_2=B(Q/Q_2)$, or alternatively $B_2=B-B_X$ (as the value of $B_1$ is already known). Let's substitute the values: $$B_X=100(2.0828/3.57)\\approx 58.34\\quad\\text{and}\\quad B_2=100-58.34=41.66.$$ In fact, you can do this more easily without calculating $Q$ at all, since $$B_X=B\\frac{Q}{Q_X}=B\\frac{Q_2}{Q_X+Q_2}.$$\n\nshare|cite|improve this answer\n\nThe defining feature of a double chance bet is that, if either of the events you bet on happens, you win the same amount regardless of which event it was.\n\nTo simulate a double chance bet with single bets, you need to divide the stake so that the same will happen.\n\nSo, let $Q_1$ and $Q_2$ be the quotes offered for the two events. We seek a value $0 \\le \\alpha \\le 1$ such that, if we bet a fraction $\\alpha$ of our total stake on event 1 and the rest on event 2, the payout in either case will be the same, i.e.\n\n$$\\alpha Q_1 = (1 - \\alpha) Q_2.$$\n\nTo solve this, expand the right hand side, collect the $\\alpha$ terms together on one side and divide to get\n\n$$\\alpha = \\frac{Q_2}{Q_1 + Q_2}.$$\n\nThen, to ensure equal payout in either case, you should bet $\\alpha$ times you total stake on event 1, and the rest on event 2.\n\nshare|cite|improve this answer\n\nPlanning on betting that either team wins?\n\n\n$S_1=S_2*\\frac{Q_2}{Q_1}, S_2=S_1*\\frac{Q_1}{Q_2}$\n\n$S_1+S_2=1$ (to find $S_1$ and $S_2$ as percentages)\n\n$S_1+S_1\\frac{Q_1}{Q_2}=1, S_2+S_2\\frac{Q_2}{Q_1}$\n\n$S_1=\\frac1{Q_2/Q_1+1}, S_2=\\frac1{Q_1/Q_2+1}$\n\nFor X/2, S_1 = 58.3% just as above.\n\nshare|cite|improve this answer\nIf you think it isn't a tie with these odds, put 72.2% on 1 and 27.7% on 2 for +38.7% on a win. Remember that you never win a double-chance if $\\frac1{1/Q_1+1/Q_2}<=1$. \u2013\u00a0user474632 Aug 17 '11 at 23:50\n\nYou bet $\\$100$ $Q2 / (Q1 + Q2)$ on X and $\\$100$ $Q1 / (Q1 + Q2)$ on 2. To the nearest cent, these work out at $\\$58.34$ and $\\$41.66$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://nrich.maths.org/7016/note?nomenu=1\nText:\nCopyright \u00a9 University of Cambridge. All rights reserved.\n\n'A Little Light Thinking' printed from\n\nShow menu\n\nA Little Light Thinking\n\nThe rules for turning on the lights of Charlie's Delightful Machine are all given by linear sequences (like those found in Shifting Times Tables).\n\nIn the first problem, you found efficient strategies for working out the rules controlling each light.\n\nNow try to make two lights light up at once.\n\n\nWhy do this problem?\n\nThis problem encourages students to think about the properties of numbers. It could be used to consolidate work on linear sequences. The interactivity encourages learners to begin the problem experimentally before working more theoretically as they engage with the main ideas.\n\nPossible approach\n\nThis problem follows on from Charlie's Delightful Machine, so we assume students have a strategy for determining the rule to switch individual lights on.\n\n\"Did anyone find examples where two or more lights switched on simultaneously?\"\n\"Our challenge now is to determine how to turn on two lights (or more) simultaneously, if we know the rules for each individual light.\"\n\nIf computers are available, students could work in pairs determining the rules for individual lights, then finding the rule for switching on pairs of lights simultaneously. Remind them of the importance of recording their findings to share with the class.\n\nIf computers are not available, this worksheet contains the rules for a collection of sequences that students could explore, searching for examples where two sequences have numbers in common.\nOne way they could record their work is by creating a table with sequence rules along the top and down the side, and indicating with a tick or a cross in each cell whether both lights could light up simultaneously. When appropriate, they could also indicate numbers which successfully switch on both lights.\n\nRemind the class that the task is not simply to find examples, but to find a way of determining, by just looking at the sequence rules, whether or not a pair of lights will ever light up simultaneously.\n\nWhen trying to produce convincing arguments, ideas from the problem Stars might be useful.\n\nLeave some time for the class to come together to share examples of rules where more than one light could be switched on simultaneously, and examples where it was impossible, together with their reasoning.\n\nKey questions\n\nWhat is true about any pair of rules where it is not possible to light up both lights?\n\nIf two sequences are described by the rules $an+b$ and $cn+d$, can you explain the conditions for determining whether the lights will ever switch on together?\n\nPossible extension\n\nSome students may wish to use ideas of modular arithmetic to prove their findings; reading this article first may help.\n\nPossible support\n\nThe problem Shifting Times Tables offers an introductory challenge for exploring linear sequences.\n\nIn the Hint there is a version of the interactivity with just two lights which students might find more accessible.\n\nStudents could use a 100 square (Word, pdf) as a visual way to record sequences and see where (if) they coincide."}
{"text": "Retrieved from http://math.stackexchange.com/questions/518186/eulerian-paths-in-non-traversable-graphs\nText:\nSign up \u00d7\n\nSuppose I have a weighted connected graph which is traversable (each vertex has even degree) and I wish to walk over all edges. Clearly any Eulerian path minimizes the total weight. What can be said about the case of non-traversable (weighted connected) graphs? Can a minimum-weight path still be found in polynomial time?\n\nshare|cite|improve this question\nYou want a path that traverses every edge at least once, I suppose? \u2013\u00a0Henning Makholm Oct 7 '13 at 22:57\n@HenningMakholm: Yes. Sorry, I had typed that but it must have been deleted as I edited the post before submitting. \u2013\u00a0Charles Oct 8 '13 at 3:46\nI would be surprised if it had an efficient solution. It is a variant of the travelling purchaser problem (on the line graph) but with some simplifications (like travel cost zero) and only one product. \u2013\u00a0Leen Droogendijk Oct 8 '13 at 5:58\nThis is the Route inspection problem a.k.a. Chinese Postman Problem. This has a polynomial time algorithm for undirected graphs and polynomial for directed graphs, but it is NP-complete for mixed graphs. \u2013\u00a0N. S. Oct 8 '13 at 17:10\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nYes, this can be done in polynomial time.\n\nWhat we need to is find a minimum-weight set of edges to traverse twice, such that the graph with some edges doubled is traversable. Once we have that, finding an actual Eulerian path is of course easy.\n\nThe edges we need to double will form a set of paths each connecting two odd-degree nodes, such that each odd-degree node is the endpoint of exactly one of the path.\n\nTo find out which odd-degree nodes to connect, temporarily disregard the even-degree nodes and instead consider a graph with one edge between each pair of odd-degree nodes, its weight being the length of the shortest path between those nodes in the original graph.\n\nWhat we need to find is then a minimal perfect matching in the reduced graph, which is known to have a polynomial-time algorithm.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/131081/with-2-lists-of-numbers-is-it-possible-to-get-the-actual-ratio-of-the-sum-of-bot\nText:\nTake the 2-minute tour \u00d7\n\nTo get the ratio of two lists of numbers, I take the sum of each column and divide the first by the second.\n\nSuppose I only have 'access' to the ratio of each individual number combo. Is it possible to get the 'total' ratio from just the individual ratios?\n\nI'm linking a google spreadsheet that should help illustrate what I'm trying to do.\n\n\nTaking the average of the individual ratios gets me pretty close but it's no good.\n\nEDIT: Thanks for the re-tagging :)\n\nshare|improve this question\nSince the ratio of totals can change while the individual ratios stay the same, the answer is no. \u2013\u00a0 Henry Apr 12 '12 at 22:32\noh :( Alright. Thanks for your help. If you submit a answer, I'll accept it for you. \u2013\u00a0 Robo Apr 12 '12 at 22:35\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\n\nHere is an example where two single ratios (of 3 and 5) can correspond to different ratios of the totals\n\n     num denom ratio\na     3   1      3\nb     7   1      7\nsum  10   2      5\n\n     num denom ratio\na     9   3      3\nb     7   1      7\nsum  16   4      4\nshare|improve this answer\nI went the other way around with my answer (one total ratio can be found by two different ratio vectors), but this is more convenient for an answer. +1 \u2013\u00a0 Patrick Da Silva Apr 12 '12 at 22:42\n\nSo clearly, you are given $a_1, a_2, a_3, b_1, b_2, b_3$. You're computing the individual ratios $r_i = a_i / b_i$, you sum them to form $R_1 = r_1 + r_2 + r_3$. Then you compute another ratio which is $(a_1 + a_2 + a_3)/(b_1 + b_2 + b_3)$, and you expect that given $r_1, r_2, r_3$, you can compute $(a_1 + a_2 + a_3) / (b_1 + b_2 + b_3)$. If I am wrong on this description correct me.\n\nLet's see what we can do. I'll try to express the total ratio in terms of the $r_i$'s and assume they are real numbers. You can compute $$ \\frac{a_1 + a_2 + a_3}{b_1 + b_2 + b_3} = \\frac{r_1 b_1 + r_2 b_2 + r_3 b_3}{r_1 a_1 + r_2 a_2 + r_3 a_3} = \\frac{r \\cdot b}{r \\cdot a} $$ by letting $r = (r_1, r_2, r_3)$, $a = (a_1, a_2, a_3)$, and $b = (b_1, b_2, b_3)$, with the $\\cdot$ meaning scalar product (hence my algebra-precalculus tag). You have access to the vector $r$ and wish to know the ratio $(r \\cdot b)/(r \\cdot a)$. As you can see from linear algebra, you can find two different ratios that will give you the same total ratio. For instance, if $\\lambda \\in \\mathbb R \\backslash \\{0 \\}$, $$ \\frac{r \\cdot b}{r \\cdot a} = \\frac{(\\lambda r) \\cdot ((1/\\lambda)b)}{(\\lambda r) \\cdot ((1/\\lambda) a)} $$ Therefore, given the ratios $r_1, r_2, r_3$ or the ratios $\\lambda r_1, \\lambda r_2, \\lambda r_3$, you find the same total ratio. This makes no hope of computing the total ratio with only the \"component-wise ratios\", since you can take component wise ratios as big as you want and still obtain the same total ratio. But then again it doesn't mean that there exist no such formula ; I just have little faith that such a formula exists. It doesn't seem very useful either, to be honest ; why do you want to compute things this way? With more information perhaps I could help on the problem behind the question.\n\nHope that helps,\n\nshare|improve this answer\nUnfortunately, the ratio of the components is the only thing that we have access to due to the way the data was processed and stored in a database. I was hoping there was a mathematical solution to this problem so I wouldn't have to re-write the application I'm working on. \u2013\u00a0 Robo Apr 12 '12 at 22:51\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/209441/prove-factoring-is-in-np\nText:\nTake the 2-minute tour \u00d7\n\nINPUT: an integer $n$ and a integer $d$\nQUESTION: does $n$ have a prime factor less than $d$?\n\nDoes a polynomial time algorithm exist that can tell whether or not $n$ has a prime factor $< d$?\n\nWould iterating through all possible primes $< d$ take too long?\n\nshare|improve this question\nYour title doesn't match your question. \u2013\u00a0 Chris Eagle Oct 8 '12 at 20:19\nAm I mistaken that in order to prove a problem is in NP the following must be true? \"Given some information C, you can create an algorithm V that will verify for every input whether X is in your domain or not. V must run in polynomial time.\" \u2013\u00a0 Takkun Oct 8 '12 at 20:22\nTakkun: you are mistaken. The most straightforward characterization of NP is as polynomially checkable problems, roughly: 'if we are given a purported solution for this problem, can we in fact verify that it is a solution in polynomial time?' Note that this then allows you to guess a potential solution (the 'N', Nondeterministic) and then check it in polynomial time (the 'P', Polynomial). \u2013\u00a0 Steven Stadnicki Oct 8 '12 at 20:24\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nIterating through all possible primes $\\lt d$ would in fact take too long; assuming that $n$ and $d$ are both given in binary and that $d$ is comparable to $n$, then it would take time exponential in the size of your input. But you don't have to iterate through all possible primes; instead, you can guess a number $k$ less than $d$ and then check whether or not $k$ is a factor of $n$. (Can you see why you don't need to check whether $k$ is prime or not?)\n\nshare|improve this answer\nIs it true that every non-prime number has a prime factor? (Addressing your question of why you don't have to check for primality of k) \u2013\u00a0 Takkun Oct 8 '12 at 20:54\n@Takkun Exactly; and moreso, that factor must be less than the number itself - so even if $k$ isn't prime, you've established that $n$ has some prime factor $p\\leq k\\lt d$. (Note that this means you don't necessarily know what the prime factor is - you're answering a yes-no question, not finding a value!) \u2013\u00a0 Steven Stadnicki Oct 8 '12 at 21:01\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/255885/constructing-idempotent-generator-of-idempotent-ideal/258657\nText:\nTake the 2-minute tour \u00d7\n\nExercise 2.1 in Matsumura's Commutative Ring Theory reads as follows: \"Let $A$ be a commutative ring and $I$ an ideal that is finitely generated and $I=I^2$. Then $I$ is generated by an idempotent.\"\n\nIn trying to solve it, i first followed a constructive approach, where e.g. for the case of two generators i tried to construct an idempotent generator. However, it seemed difficult. Then i realized that i could apply Nakayama's lemma to the $A$-module $I$ and the existence of the idempotent generator follows.\n\nMy question is: How could one go about finding this idempotent generator? Is there a systematic way?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nOne can reconstruct a method by considering the usual proof of Nakayama's lemma.\n\nSuppose you know that the ideal is generated by $n$ elements, $(x_1, ..., x_n)$. By assumption, we may write $x_i = \\sum a_{ij} x_j$, where the $a_{ij} \\in I$. The element we're looking for is $p(1) -1$, where $p$ is the characteristic polynomial of the matrix $(a_{ij})$.\n\nTo see this, consult the proof of NAK in, say, Matsumura or Atiyah-Macdonald.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/355720/probability-distribution-of-a-sum-of-random-variables\nText:\nTake the 2-minute tour \u00d7\n\nSuppose we have two independent random variables $X$ and $Y$. Their sum is $Z = X + Y$. How can I calculate the conditional distribution of $P(Z|X)$?\n\nshare|improve this question\nDo you mean the conditional distribution? or the conditional expectation? \u2013\u00a0 Sim\u00e9on Apr 9 '13 at 8:04\n@Ju'x: I mean the conditional distribution. Sorry for the confusion. \u2013\u00a0 prasopes Apr 9 '13 at 8:05\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nRecall that the conditional distribution of $Z$ conditioned by $X$ is defined as any family of probability measures $(\\mu_x)_x$ such that, for every bounded function $u$, one has $E[u(Z)\\mid X]=v(X)$, where the function $v$ is defined as $$ v(x)=\\int u(z)\\mathrm d\\mu_x(z). $$ Here, one can take for each $\\mu_x$ the distribution of $x+Y$. Thus, introducing the distribution $\\nu$ of $Y$, for every Borel subset $B$ and every $x$, one sets $$ \\mu_x(B)=P[x+Y\\in B]=\\nu(B-x). $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://plus.maths.org/content/os/latestnews/jan-apr10/roboroach/index\nText:\nControlling cockroach chaos\n\nby Rachel Thomas\n\n\nA cockroach\n\n\nAn interdisciplinary team of scientists from Germany have created a robotic cockroach that autonomously behaves in a way reminiscent of a real cockroach. The robot independently changes gait depending on the surface it is walking on, avoids obstacles and can even extricate its leg from a hole or run away from predators. Recreating lifelike behaviour is not new, but this robot reproduces a huge range of behaviours and quickly reacts to new situations and switches between them. And the secret to its success is controlled chaos in its robotic brain.\n\nAn autonomous robot works by taking inputs from sensors (such as light, floor contact for each leg, and object recognition cameras) and generating outputs to the motors that control the robot's movement. But deciding exactly which combination of inputs should lead to which combination of outputs rapidly becomes very difficult as more inputs and outputs are considered. In contrast, a living cockroach processes information from a large number of sensors (such as touch, vision, smell, temperature and vibration) to control the 100 or so muscles responsible for its movement. Therefore, the researchers noted in their paper, nature has apparently solved the difficult problem of coordinating a large number of inputs and outputs.\n\nIn humans and animals, periodically recurring movements like walking or breathing are controlled by small neural circuits called central pattern generators (CPGs). Scientists have been using this principle in the development of walking machines. To date, typically one separate CPG was needed for every gait. Previously robots received information about the environment via several sensors and selected the CPG that would produce the gait appropriate for the current situation.\n\nThere is growing evidence that the CPGs in real biological systems exploit chaos. Mathematically something is chaotic if a tiny change in starting conditions produces vastly different results. For example, one starting point for a mathematical function could produce a steady repeated pattern of outputs, but a slight nudge (called a perturbation) might result in wildly different output.\n\nIt seems that individual neurons may behave in a chaotic way, but when connected to other neurons they interact, pushing and pulling each other, to create the patterned neural output of a CPG. And operating at the very edge of chaos seems to be an advantage: the organism can flip between behaviours in an instant, and even into chaos itself. For example it is thought that the CPG that produces steady flight in some moths also controls the erratic fluttering and tumbling that help the insect dodge predators. (You can read more in Lewis Dartnell's Plus article Chaos in the brain.)\n\nSilke Steingrube, Marc Timme, Florentin W\u00f6rg\u00f6tter and Poramate Manoonpong have tried to install this controlled chaos into their robotic cockroach. Inspired by the biology of the insect itself, they used a very simple neural network of two neurons to act as a CPG. The outputs of this CPG controlled the movement of the 18 mechanical muscles of the robot.\n\nThis simple neural network was defined mathematically, where the state of each of the two neurons at any time (each a real value between 0 and 1) was dependent on the state of both neurons an instant before. This mathematical system was tuned so that the network behaved chaotically: a tiny change in the value of the starting states would result in vastly different output.\n\nTo control this chaos, the researchers introduced an extra term in their equations that would essentially provide nudges to move the system from one type of behaviour to another. For example if the input sensors indicated the robot was on level floor, the control parameter would push the system into a periodic pattern of length 5, resulting in a walking style called a tetrapod gait (see movie). Different inputs from the sensors, such as that it was on a hill, on rough terrain, and predator attack stimulated a different periodic output. If the input did not fit a known situation the control parameter was turned off, turning the output of the CPG back to chaotic and allowing the robot to flail about until it found itself in one of its known situations again. This chaotic behaviour turned out to be ideal for many situations, for example when the robot is turned on its back, or its leg is trapped in a hole, as the chaotic behaviour eventually righted the robot and enabled it to quickly switch back to a stable gait.\n\nThe connection between sensory properties and CPG can either be preprogrammed or learned by the robot from experience. The scientists use a key example to show how this works: the robot can autonomously learn to walk up a slope with as little energy input as possible. As soon as the robot reaches a slope, a sensor shows that the energy consumption is too high. Thereupon, the connection between the sensor and the control input of the CPG is varied until a gait is found that allows the robot to consume less energy. Once the right connections have been established, the robot has learned the relation between slope and gait. When it tries to climb the hill a second time, it will immediately adopt the appropriate gait.\n\nIn the future, the robot will also be equipped with a memory device which will enable it to complete movements even after the sensory input ceases to exist. In order to walk over an obstacle, for instance, the robot would have to take a large step with each of its six legs. \"Currently, the robot would not be able to handle this task \u2014 as soon as the obstacle is out of sight, it no longer knows which gait to use,\" says Marc Timme. \"Once the robot is equipped with a motor memory, it will be capable to use foresight and plan its movements\".\n\nBy mathematically controlling chaos these researchers have developed an elegant neural network that autonomously mimics real insect behaviour. The robot provides further proof that a chaotic ground state CPG is key in producing a wide range of behaviours and instinctively switching between them, whether in a robot, a roach, or even ourselves.\n\n\nQuantum_Flux said...\n\n\nHarry van der Velde said..."}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56476.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nEllipse Geometry\n\nDate: 08/09/98 at 03:03:00\nFrom: Simon Crosbie\nSubject: Ellipse geometry\n\nan ellipse and bisecting the perimeter of the ellipse at right angles \nto the tangent at that point. How do I determine the distance along \nthe long axis of an ellipse that this line must start from? \n\nI am a joiner who specializes in constructing special-shaped plantation \nshutters. A formula showing this relation would help me work out the \nprecise timbers required to construct an ellipse. I have already worked \nout a formula which I use to draw an ellipse of a given width and \nheight using two centers and a piece of string. The distance between \nthe two centers is found with the expression:\n\n   Center spacing = 2*Sqrt((Height/2)*(Height/2)*(Width/2))\n   Length of string = Height + Center spacing\n\nwhere Height is the length of the long axis of the ellipse and Width \nis the length of the short axis.\n\nDate: 08/09/98 at 09:16:33\nFrom: Doctor Jerry\nSubject: Re: Ellipse geometry\n\nHi Simon,\n\nLet's see if I understand your problem. You have an ellipse:\n\n\nThe numbers 2a and 2b are the lengths of the major and minor axes. The \nfoci of the ellipse are at (-c,0) and (c,0), where c = sqrt(a^2-b^2). \nThe length of the string is 2a.\n\nI think 2a is what you have called width and 2b is what you have called \nheight. I don't understand your formula for center spacing. I'd say \nthat the center spacing (the distance between centers) is: \n\n   2c = 2*sqrt(a^2-b^2)\n\nI'll use what I understand, as outlined in my first paragraph. You are \nseeking a point (X,0), where -a < X < a, on the major axis, from which \na line at a specified angle d (I'll assume 0 < d < 90) will intercept \nthe ellipse at right angles to the tangent.\n\nThere is a well-known formula for the equation of the tangent line to \nthe ellipse at any point (x0,y0) of the ellipse. It is:\n\n   a^2*y0*y + b^2*x*x0 = a^2*b^2\n\nAssuming (x0,y0) is in the first quadrant, the slope of this line is\n-b^2*x0/(a^2*y0). The slope of the line K perpendicular to this line is \nthe negative reciprocal of this, namely, a^2*y0/(b^2*x0). This is the \ntangent of the angle d.\n\nThe equation of K is y-y0 = a^2*y0/(b^2*x0)(x-x0). Its x-intercept, \nwhich you want, is (set y=0):\n\n   X = x0(1-b^2/a^2) = x0(a^2-b^2)/a^2 = x0*c^2/a^2\n\nSince tan(d) = a^2*y0/(b^2*x0) and x0^2/a^2+y0^2/b^2 = 1, we can \neliminate y0:\n\n   1/x0^2 = (b^2/a^4)tan^2(d) + 1/a^2  \n\nWe now know x0 in terms of d. Put this into the equation for X and \nyou're done.\n\nPlease check this out. Write back if I've made mistakes or been \n\n- Doctor Jerry, The Math Forum\nAssociated Topics:\nHigh School Conic Sections/Circles\nHigh School Coordinate Plane Geometry\nHigh School Geometry\nHigh School Practical Geometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56132.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPossible Combinations on a Push Lock\n\nDate: 4/17/96 at 15:53:5\nFrom: Anonymous\nSubject: lock problem\n\nThe digits available are 1 thru 5.  Furthermore, in each \ncombination a digit can occur only once.  You need at least two \npushes to open the lock. How many different combinations are \n\nThis is as far as I got......\n\n\t5! = 120 combinations\n\nThis seem to be the right answer but I feel that there is more to \nit. I am not sure I understand the problem fully.  Any help to the \nsolution of this problem would be most appreciated.\n\nDate: 4/18/96 at 20:2:40\nFrom: Doctor Ken\nSubject: Re: lock problem\n\nHey there -\n\nIf I understand this problem correctly, you can't use any number \ntwice in a combination, even if they are in different pushes.  So \nthe following would be okay:\n\n4, then \n5 and 2, \nthen 3 and 1.  \n\nBut this wouldn't:\n\n4, then\n5 and 4, then\n3 and 4, because you re-use 4.\n\nNotice that this limits us to at most 5 pushes, because after that \nyou're going to have to start repeating.  Anyway, let's get some \nnotation: if a push consists of 5 and 4, for example, let's write \nthat as (5,4).  And let's use the + sign to seperate consecutive \npushes, so that the first combination we had would be written as \n(4) + (5,2) + (3,1).\n\nAnyway, I think this is a harder problem than one that will be \nable to be solved with just one case: we're going to have to break \nit down.\n\nSo let's break it down according to how many digits we use in each \ncombination.  We know we need to use at least 2, because we need \nto have at least 2 pushes.  So how many different combinations can \nwe have that use exactly 2 digits?  Well, we'll have 5 choices for \nthe first one and 4 choices for the second (order does matter in \nthis case).  So that's 20 ways of choosing our digits.  Then how \nmany different combinations can we get with these 2 digits?  It \nseems pretty obvious, in this case, that all we can do is push one \nbutton, then the other (i.e. we can't push 2 at the same time).  \nSo we'll just get 20 different combinations that use 2 digits.\n\nNow let's look at 3 digits, which is a little more interesting.  \nHow many ways can we choose which 3 digits to use?  Well, again, \nit's 5*4*3 = 60.  \n\nBut now we have several choices for whether these buttons are \npushed one at a time, or together with others.  For instance, if \nwe chose the digits 1, 2, and 3, in that order, we could have \n(1) + (2) + (3), or we could have (1,2) + (3), or (1) + (2,3).  \nIt looks like these are the only possible combinations that use \nonly 1, 2, and 3 in that order.  So since every selection of 3 \ndigits will have these 3 different combination orders, there will \nbe a total of 60 * 3 = 180 combinations that use 3 digits.\n\nCan you do the cases where we use 4, and then 5 digits yourself?  \nThey get tougher the more digits you have, but try to get it \nyourself before you write back for more help.  This is a neat \nproblem, and it will be worth it if you solve it yourself.\n\n-Doctor Ken,  The Math Forum\n\nAssociated Topics:\nHigh School Permutations and Combinations\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://www.physicsforums.com/showthread.php?t=457931\nText:\nRegister to reply\n\nCauchy Riemann Equations (basic doubt)\n\nby ask_LXXXVI\nTags: cauchy riemann\nShare this thread:\nDec20-10, 04:58 AM\nP: 53\nLets say we have a function of a complex variable z , f(z).\n\nI read that for the function to be differentiable at a point z0 , the CR equations are a necessary condition but not a sufficient condition.\n\nCan someone give me an example where the CR equations hold but the function is not differentiable at that point , thus justifying that the CR equations holding true aren't sufficient test.\n\nI am unable to visualise.\nPhys.Org News Partner Science news on\nSapphire talk enlivens guesswork over iPhone 6\nGeneticists offer clues to better rice, tomato crops\nUConn makes 3-D copies of antique instrument parts\nDec20-10, 07:11 AM\nSci Advisor\nPF Gold\nP: 39,340\nLet g(x, y)= 1 if xy is not 0, 0 if xy= 0 and let f(z)= g(x,y)(1+ i)= g(x, y)+ ig(x,y) where z= x+ iy. Then\n[tex]\\frac{g(x,y)}{\\partial x}= \\frac{\\partial g(x,y)}{\\partial y}= 0[/tex]\nfor (x,y)= (0, 0) so the Riemann-Cauchy equations are satisfied there but the function is not even continuous at (0, 0).\nDec20-10, 11:46 AM\nP: 53\nThanks.Doubt resolved.\n\nRegister to reply\n\nRelated Discussions\nCauchy-Riemann equations Calculus & Beyond Homework 1\nCauchy-Riemann Equations Calculus & Beyond Homework 5\nCauchy-Riemann equations Calculus & Beyond Homework 14\nCauchy-Riemann Equations problem (f(z) = ze^-z) Calculus 3\nCauchy-Riemann Equations Calculus 0"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207208/cutting-a-n-dimensional-cubic-cake\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nGiven a cubic cake, defined as $\\{(x,y,z)|0\\leq x,y,z\\leq 1\\}$.\n\nWe cut it by the planes\n\n$p_1\\leftrightarrow x=y$\n\n$p_2\\leftrightarrow y=z$\n\n$p_3\\leftrightarrow x=z$.\n\nHow many pieces will we have after cutting?\n\nAnd the 4-dimensional case: $\\{(x,y,z,u)|0\\leq x,y,z,u\\leq 1\\}$\n\nHow many pieces will we have after having cut by the spaces\n\n$x=y$, $x=z$, $x=u$, $y=z$, $y=u$, $z=u$?\n\nAnd the $n$-dimensional case...\n\nshare|cite|improve this question\nHint: What are the conditions on the two subsets after cutting along $x=y$? That is, how do you determine if $(x,y,z)$ is in one subset or the other? \u2013\u00a0Thomas Andrews Oct 4 '12 at 15:30\nI have a solution, but i wanted to share this with others. Because i find it a beautiful problem. \u2013\u00a0barto Oct 4 '12 at 15:37\nThis is not a puzzle site, it is a site for answering questions so that later people with the same question can find the answer. So if you have an answer, then post it. @barto \u2013\u00a0Thomas Andrews Oct 4 '12 at 15:41\nup vote 1 down vote accepted\n\nWhen cutting by the space $x=y$, we divide the cake in two parts:\n\nOne part with $x>y$ and one part with $x<y$.\n\nThe same holds for spaces like $y=z$, $z=u$, ...\n\nThat means, that every ordering of the variables $x$, $y$, $z$, ... defines a part. And since there are $n!$ orderings, there are $n!$ pieces after cutting.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/320506/degree-bounds-and-coefficient-size-in-elimination-theory\nText:\nSuppose we have polynomials is of form $$h_1(x_1,\\dots,x_{dn})-c_1\\in\\mathbb Z[x_1,\\dots,x_{dn}]$$ $$\\vdots$$ $$h_{nd}(x_1,\\dots,x_{dn})-c_{nd}\\in\\mathbb Z[x_1,\\dots,x_{dn}]$$ where $h_1(x_1,\\dots,x_{dn}),\\dots,h_n(x_1,\\dots,x_{dn})\\in\\mathbb Z[x_1,\\dots,x_{nd}]$ are homogeneous polynoials of degree $d$ with each $x_i$ degree $1$ (that is only monomials of form $x_{i_1},\\dots,x_{i_d}$) on the conditions that\n\n  1. each coefficient except $c_1,\\dots,c_{nd}$ is random in $[-B,B]\\setminus\\{0\\}$\n\n  2. with $c_1,\\dots,c_{nd}$ being of absolute value at most $B^{1+\\frac1{2^d-1}}$\n\n  3. in each monomial $x_{i_1},\\dots,x_{i_d}$ we have $i_j\\in\\{(j-1)n+1,\\dots,jn\\}$.\n\nThen if you use elimination theory we can successively eliminate variables and reduce to an univariate polynomial.\n\nLet the absolute value of the maximum coefficient size $B'$ of final univariate polynomial in reduced form (no common gcd of coefficients) and the let the degree be $d'$.\n\nThen can $B'^{\\frac1{d'}+\\epsilon}>B^{\\frac1{d(2^d-1)}}$ hold with probability $1-o(1)$ at arbitrarily small $\\epsilon>0$ as $B$ increases and $d$ is fixed?\n\n  \u2022 $\\begingroup$ Editing a question with high frequency indicates that the questioner hasn't thought enough about his/her question before asking. (And my experience is to better stay away from questions that are not well-thought.) $\\endgroup$ \u2013\u00a0tj_ Jan 11 at 23:42\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/45123/dired-file-open-using-external-viewers-based-on-filetype-and-without-promptin\nText:\nWhen I hit RETURN on a filename in Dired, I'd like Emacs to automatically do one of several things, depending on the file's type:\n\n1 - If it's a text file, I'd like to open the file in a new buffer in Emacs.\n\n2 - If the filetype is listed in a user-configurable list of filetypes and external viewers, open the file in an external viewer associated with that filetype.\n\n3 - If the filetype is not text and not in the above list, return an error saying the file is of an unknown type.\n\nI've found some answers (1, 2) that advise using dired-read-shell-command and either ! or & to open files with external viewers.\n\nThe above answers are insufficient for my needs, because:\n\n1 - They require multiple keystrokes (at least ! or & and then RETURN at the prompt), while I want this done with just a single keystroke, without any prompting.\n\n2 - They won't open text files in Emacs, but will instead try to use external viewers for everything. I want text files opened in Emacs.\n\n3 - They dispatch based on filename extensions, while I want to dispatch based on filetype (ie. as a result of using either the \"file\" or \"mimetype\" command on linux)\n\n4 - They don't error-out if the filetype is not found in the list of known filetypes.\n\n\nThe following is a macOS specific solution as it needs file(1) and open(1). Feel free to adjust the code.\n\n(defun chunyang-file-mime-type (file)\n  \"Return mime-type of FILE.\"\n  ;; file(1) doesn't fail in such case\n  (unless (file-readable-p file)\n    (error \"%s: No such file or no read permission\" file))\n    (let ((exit (call-process \"file\" nil t nil \"--brief\" \"--mime-type\" file)))\n      ;; Remove the final newline if any\n      (when (eq (char-before) ?\\n)\n        (delete-char -1))\n      (if (zerop exit)\n        (error \"file: %s: %s\" file (buffer-string))))))\n\n(defun chunyang-open-file-with-app (file app)\n  \"Open FILE with APP.\"\n  ;; open(1) exists immediately and does not block Emacs\n  (call-process \"open\" nil nil nil \"-a\" app file))\n\n(defvar chunyang-mime-type-app-alist\n  '((\"video/mp4\" . \"VLC\")\n    (\"application/pdf\" . \"Firefox\")))\n\n(defun chunyang-open-file (file)\n  \"Open FILE base on its mime-type.\"\n  (interactive \"f\")\n  (setq file (expand-file-name file))\n  (let ((mime-type (chunyang-file-mime-type file)))\n    (if (string-prefix-p \"text/\" mime-type)\n        (find-file file)\n      (let ((app (cdr (assoc mime-type chunyang-mime-type-app-alist))))\n        (if app\n            (chunyang-open-file-with-app file app)\n          (user-error \"No app is associated with %s\" mime-type))))))\n\n(defun chunyang-dired-open-file ()\n  (chunyang-open-file (dired-get-file-for-visit)))\n\nYour Answer"}
{"text": "Retrieved from https://galwaymathsgrinds.wordpress.com/maths-topics/binomial-theorem/\nText:\nBinomial Theorem\n\nFormulae and Tables page 20\n\nI think that on first seeing the Binomial theorem many students think it very complicated and straight away tell themselves that this is too difficult to deal with. But like many other things in maths if we just identify a few patterns in how things are ordered it suddenly appears much simpler.\n\nIt is binomial because we are working with the sum or difference of two algebraic terms, (x+y). It tells us the result of raising this to any whole number power. Lets take a few examples that we know already or can easily work out by multiplying out the (x+y) the required number of times. Remember from the rules of indices that anything to the power of zero is 1.\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)0 = 1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1 term\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)1 = x+y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2 terms\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)2 = x2 +2xy + y2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0 3 terms\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (x+y)3 = x3 + 3x2y + 3xy2 + y3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\u00a0 4 terms\n\nIf we raise it to the power of n, then the number of terms in the expansion will be n + 1, and these are all added together.\n\nLook at the powers of x. They start at the same power as the binomial is being raised to and then decrease by 1 in each succeeding term until we reach x0. Remember x0 is 1. And since multiplying by 1 makes no difference we do not need to write it in.\n\nThe powers of y follow the reverse pattern starting at y0 in the first term. Again since this is 1 and it is multiplied by xn it is just ignored. They increase by 1 in each succeeding term until we reach yn.\n\nWe then have to find the coefficients of the different terms. These are given by calculating nCr where n is the power we are raising the binomial to, and r starts at 0 for the first term and increments by 1 in each succeeding term until it reaches n.\n\nThe booklet gives the definition of nCr in terms of factorials but it is much simpler to just use the nCr button on your calculator.\n\nIn general then a binomial expansion raised to the power of n will consist of the sum of n+1 terms of the form nCr . xn-r .yr where r starts at zero and increases by 1 in succeeding terms.\n\nThis results in\n\nGeneral term of binomial expansion\n\n= Tr+1 = nCr . xn-r .yr\n\nFind the term independent of x in (x2 \u2013 1/x)15\n\nThe term independent of x is the term with no x, in other words the index (power) on x is zero.\n\nTr+1 = 15Cr . (x2)15-r .(-1/x)r\n\n= 15Cr . (x)30-2r .(-1/x)r\n\n= 15Cr . x30-2r .(-x)-r\n\n= 15Cr . -x30-3r\n\n30-3r = 0 for independent term. r = 10\n\nTr+1 = 15Cr . (x2)15-r .(-1/x)r = 3003 . x10 . 1/(-x10) = 3003"}
{"text": "Retrieved from https://se.mathworks.com/matlabcentral/answers/362571-improve-the-accuracy-convergence-of-dlyap?s_tid=prof_contriblnk\nText:\nImprove the accuracy/convergence of dlyap\n\n7 views (last 30 days)\nKwin on 22 Oct 2017\nEdited: Kwin on 22 Oct 2017\nI was playing a little with solving the discrete Lyapunov equation (A * X * A' - X + Q = 0) myself when I came across this question, which also posted an answer to. In this answer I did notice that my algorithm scales much worse in computation time that dlyap (which should be O(n^3) I believe), but the accuracy of dlyap gets much worse when the dimension of the matrices gets above 15 by 15.\nFor example if I use:\nn = 15;\nA = diag(ones(1,n-1),1);\nQ = eye(n);\np = poly(0.1 * ones(1,n));\nA(end,:) = -p(end:-1:2);\nP = dlyap(A, Q);\naccuracy = norm(A * P * A' - P + Q);\nThis gives the result accuracy = 8.3891e+08, but if I use my method I get accuracy = 5.3357e-15, which is much much much better. And it also seems to imply that dlyap did not converge to the solution. So my question is if it is possible to improve the accuracy/convergence of dlyap, or if this would just be the limitation the algorithm that is used?\nSimilar results can also be obtained when doing this with lyap instead.\nPS: I am not running the latest MATLAB version, namely R2017a, but I assume that dlyap hasn't changed since then.\n\nAnswers (0)\n\nCommunity Treasure Hunt\n\n\nStart Hunting!"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/116566/is-there-a-olog-n-time-algorithm-to-find-the-maximum-element-of-a-circular-shi\nText:\nConsider this problem: You are given an array $A$ (of distinct integers) of one out of the following four types:\n\n  \u2022 Ascending (e.g., 1,2,4,6);\n  \u2022 Descending (e.g., 6,4,2,1);\n  \u2022 Ascending rotated (a non-trivial circular shift of an ascending array, e.g., 4,6,1,2);\n  \u2022 Descending rotated (a non-trivial circular shift of an descending array, e.g., 4,2,1,6).\n\nThe task is to determine the type and the maximum element of $A$.\n\nSince $A$ is \"sorted\", is there a $O(\\log n)$-time approach or is the best possible time complexity $O(n)$, as suggested in the link?\n\n  \u2022 3\n    $\\begingroup$ Please include the question as part of your post. The link could rot in the future. $\\endgroup$ Nov 1 '19 at 16:45\n  \u2022 $\\begingroup$ The question has been put on hold seconds before I could post my answer. Am I allowed to edit the question even if I'm not the original poster? $\\endgroup$\n    \u2013\u00a0Steven\n    Nov 1 '19 at 18:31\n  \u2022 $\\begingroup$ @Steven yes, and edit was very good. $\\endgroup$\n    \u2013\u00a0Evil\n    Nov 2 '19 at 4:20\n  \u2022 1\n    $\\begingroup$ Let N>= 3 be the array size, n = N/3, m=2N/3, x=position of last element. Read a, b, c from index 0, n and m. a, b, c can be sorted in six different ways, and each corresponds to one of the six cases array sorted in ascending/descending order, and x<n, n<=x<m, and x>= m. The rest is binary search in a sub array of size N/3, so O(log N). $\\endgroup$\n    \u2013\u00a0gnasher729\n    Nov 2 '19 at 10:36\n  \u2022 $\\begingroup$ What did you try? Where did you get stuck? Can you recognize any of the four cases? We're happy to help you understand the concepts but just solving exercises for you is unlikely to achieve that. You might find this page helpful in improving your question. $\\endgroup$\n    \u2013\u00a0D.W.\n    Nov 3 '19 at 7:31\n\nLet $A = \\langle a_1, \\dots, a_n \\rangle$ be the input array. I will only consider the case $n \\ge 3$, otherwise the problem is trivial.\n\nThe key property is that the order relation between all but one pair of consecutive elements modulo $n$ in $A$ will be \"greater than\" if $A$ is some circular shift of an increasing array (possibly the trivial shift by $0$), and \"less than\" if $A$ is some circular shift of a decreasing array. Examining the first and last elements suffices to determine if the shift is trivial or not.\n\nIn practice you can determine the type of $A$ in constant time, as follows:\n\n  \u2022 Look the majority value $x$ among $\\textrm{sign}(a_1-a_n)$, $\\textrm{sign}(a_2-a_1)$, and $\\textrm{sign}(a_3-a_2)$.\n\n  \u2022 If $x = +1$ then $A$ is some circular shift of an increasing array. If $\\textrm{sign}(a_1-a_n)=-1$, $A$ is of type \"ascending\", otherwise it is of type \"ascending rotated\".\n\n  \u2022 If $x = -1$ then $A$ is some circular shift of a decreasing array. If $\\textrm{sign}(a_1-a_n)=1$, $A$ is of type \"descending\", otherwise it is of type \"descending rotated\".\n\nAs for returning the maximum, I will only discuss the case in which $A$ is a circular shift of an increasing array (the complementary case is handled similarly). Notice that, if the maximum element is in some position $a_j$, then all $a_1, \\dots, a_j$ are larger than or equal to $a_1$, while all ements $a_{j+1}, \\dots, a_n$ are smaller than $a_1$. This allows you to binary search for the last element that is larger than or equal to $a_1$, i.e., $a_j$.\n\n  \u2022 1\n    $\\begingroup$ No doubt this is a great answer as per me. But, I think we should consider $x$ as majority of $sign(a_1-a_n), sign(a_2-a_1)$ and $sign(a_3 - a_2)$. Because I'm getting wrong answer if I follow above approach with sequence $6,3,4,5$. $\\endgroup$ Nov 2 '19 at 11:07\n  \u2022 $\\begingroup$ Ughh. You are right! Thanks for spotting that. $\\endgroup$\n    \u2013\u00a0Steven\n    Nov 2 '19 at 11:13\n\nif we are given with first two cases i.e Ascending sorted array and descending sorted arrays we can simply find the difference b/w last element of array and first element of array i.e (last element of array - first element of arrays)if difference is positive then it is ascending order and maximum element is the element at last index of array (in ascending sorted arrays ) and vice versa. it takes just 0(1) in that case.\n\n  \u2022 1\n    $\\begingroup$ We don\u2019t know which of the four cases it is, finding which case is part of the problem. $\\endgroup$\n    \u2013\u00a0gnasher729\n    Nov 3 '19 at 13:35\n\nYour Answer"}
{"text": "Retrieved from https://politics.stackexchange.com/questions/50145/can-people-who-arent-exactly-suffering-more-pain-than-the-average-citizen-choos\nText:\nPreliminary information:\n\nI have asked the question What age was the youngest person without any illness to die by euthanasia by own sane willingness? [closed] in the History Stack Exchange site and was told in a comment that it should perhaps be asked here because it is a political topic. As such I have adapted the question to try to make it suitable and edited as requested in comments below.\n\nI understand the nature of euthanasia being controversial/debatable as it is quite a complex subject. There are different types. Voluntary, non-voluntary and involuntary, each with the variants of passice and active, and assisted suicide being similar but different as it is done by the person themselves.\n\nFew places have it legalized. And while there are cases of it being practiced, my question is specific.\n\nActual question:\n\nIs there any place in the world where someone who does not suffer from any physical nor psychiatric problem can actually decide to painlessly end their life through a legal process where they aren't the ones doing it but someone else administerating it to them (for example, first being put into an unconscious state and then having their life taken), from their own proven sane choice regardless if they have a socially highly accepted moral reason such as friends/family dying, having a lonely life, etc?\n\nHave there ever been any cases like that which I have described?\n\nFurther details:\n\nAs the process of it being accepted legally is quite extensive and requires valid reasons to be considered, my question focus on what other reasons have ever been accepted or if they're actually considered at all. Without exhausting it nor going too in depth into long detailing, some examples of reasons that I can think of are the person:\n\n  \u2022 having some sort of religious belief that conducted them to make such decision.\n\n  \u2022 desiring to not go through a painful death whenever it does happen and so wishing to make it as painlessly as possible while they can decide beforehand.\n\n  \u2022 having thoroughly decided rationally that life is not worth enduring even after considering all aspects (that they know of) of the spectrum of the positive and negative sides of existence.\n\nI believe I should stress the fact that I'm asking about it specifically in a legal way (permitted by law), active (death administered by someone other than the one dying) and intentional (the person dying having requested it by their own sane wishes without having being forced by anyone nor being drunk or drugged).\n\nI have attempted to close as many loopholes as I could but any request for clarification, suggestions, improvements, doubt of meaning and others things about the question are appreciated in the comments bellow.\n\nCaveat notice:\n\nThis is not a question that should be treated as any sort of suicide attention seeking. It is merely a question out of curiosity, knowledge and philosophical interest (though the question itself in this form not being suitable for Philosophy Stack Exchange) which I can not find information about, and don't know where else or how else to search/ask about (specially without worrying anyone). If still in doubt please explain how else I could learn about it.\n\n  \u2022 3\n    it depends on what you mean by trauma. In Holland, there was a case 2-3 years back where a woman was deeply depressive, having lost her husband and child and did not want to continue living. she successfully petitioned for the procedure, and, yes, it was controversial. she was certainly in no physical risk at the time, and did feel life was not worth living, but one could certainly argue that she had been traumatized. would she be in the scope of your question, or fall within your justified-by-PTSD slot? which is excessive to what most people support euthanasia for, IMHO. Feb 7 '20 at 14:56\n  \u2022 @ItalianPhilosophers4Monica That does sound like it falls IMO into what I tried to describe as a serious case of someone deciding to and using as reason a traumatic event that happened in their life. I'm not sure how to define \"traumatic\" without mistakenly restricting some cases that might be desired as an answer. That case is not exactly what I'm seeking but is nevertheless interesting to know of. Feb 7 '20 at 15:18\n  \u2022 1\n    but I would argue that she goes in the 3rd bucket \"life not worth\" living. I am very uneasy about the procedure being extended to non-physical issues, because that does blur the line with suicide. I want euthanasia to be available, yes, including non-terminal patients that are either in massive pain or paralyzed or the like. I don't want the slippery slope of \"doesn't feel like living\" because that harms the passage of euthanasia laws. If you are surprised by this case, which made the news, which other cases do you have in mind where trauma, not physical, was successfully invoked? Feb 7 '20 at 15:25\n  \u2022 @ItalianPhilosophers4Monica I don't know of any euthanasia cases. I think that what I'm trying to seek is if someone that wasn't physically nor clearly/visibly mentally considered to be suffering has ever managed to go through such process. For example, if someone who seemed just as alright as most other civilians but intended to not exist anymore had any possibility to do so legally, or if they would be \"forced\" to exist unless they showed a strong reason to be permitted (such as physical pain, or a big unfortunate event that society empathize as resulting in a strong psychological pain). Feb 7 '20 at 15:34\n  \u2022 This is honestly clear as mud (still) so unless you edit the question VTC is the only real option I see. Read this for some background on psychiatric euthanasia cases, which it seems your question might be about... Or are you excluding those too, seemingly per your last comment (which is not even remotely reflected in the body of your question)? Use the edit function to clarify the question, not comments...\n    \u2013\u00a0Fizz\n    Feb 7 '20 at 17:33\n\nIn the Netherlands, no.\n\nEven though the Netherlands is (in)famous for having comparatively permissive euthanasia laws, it is in fact a highly regulated process with very strict requirements. The most important of those is one I've translated to the best of my ability as \"inescapable and unbearable suffering\". This excludes all the cases you are asking about.\n\nIt is worth mentioning though that this topic is actively debated, with one political party (D66) in particular pushing for legislation that would put the decision to ends one's life in the hands of individuals of over 75 years old, and would legalize the means to do so (the \"Pil van Drion\"). This has led to a lot of misunderstandings (caused by foreign media representing policy proposals as actual policy) but at the time of writing no such policies exist.\n\n  \u2022 @Fizz Seems to me OP is asking a simple question in a somewhat roundabout way, they wan't to know if people have been legally euthanized without a severe medical (be it mental or physical) indication. Well, not in the Netherlands, as this wouldn't be legal.\n    \u2013\u00a0Douwe\n    Feb 7 '20 at 17:39\n  \u2022 @Douwe I may be overthinking it which is why the question might not be as good as it could be but I am trying to improve it, and that's what feedback is for as well. My question is pretty much what you said on your last comment, both if it has happened and if it currently can happen. Feb 7 '20 at 20:05\n  \u2022 1\n    @JJforTransparencyandMonica there you go. It's in Dutch though, I couldn't find suitable sources in English\n    \u2013\u00a0Douwe\n    Feb 7 '20 at 20:09\n  \u2022 @user7393973 I updated my answer though, I inadvertently misrepresented the D66 proposal pretty bad.\n    \u2013\u00a0Douwe\n    Feb 7 '20 at 20:16\n  \u2022 There is a very suspicious death of Noa Pothoven (en.wikipedia.org/wiki/Noa_Pothoven). Allegedly not killed by lethal injection, but kept in a comma and allowed to starve (or die from dehydration) . Which is in fact even worse then lethal injection.\n    \u2013\u00a0rs.29\n    Feb 7 '20 at 20:56\n\nBasically, no. The BeNeLux countries which allow euthanasia for \"psychological suffering\" (with fairly similar laws) actually have more specific requirements, as exemplified by Belgium below:\n\nThe euthanasia declarations the Federal Control and Evaluation Commission on Euthanasia (FCECE) receives often mention both physical and psychological suffering, with a preponderance of psychological suffering: while medicine can ease physical pain in many cases, it is often powerless when it comes to psychological suffering, such as despair, dependence, loss of dignity. The precondition for this physical or psychological requirement under the Euthanasia Act of 28 May 2002 is that there must be a causal link between the (serious and incurable) medical condition and the suffering. They emphasise that the three essential conditions (i.e. a well-considered request, a serious and incurable medical condition, and constant and unbearable suffering) are intrinsically linked, with the result that, in respect of each euthanasia request, the connection between those three essential conditions must be examined.\n\n(Emphasis in original.) So basically, psychological suffering without (causal) link to an incurable medical condition is not legally valid grounds for granting euthanasia request, in Belgium at least.\n\nIn slight contrast the similar\n\n[Dutch] Act talks about suffering and not about a medical condition, but legal doctrine and case law, and more specifically the doctrine developed by the five Regional Review Committees, stipulates that a patient\u2019s suffering must have a medical dimension, irrespective of whether it is somatic or psychiatric in nature. The Dutch Act does not differentiate between patients who are expected to die in the near future or those who are not: at least one physician consulted is required, regardless of whether the patient is in the terminal stage or not.\n\nYou can actually find the RTE Code in English and indeed it says:\n\nIt is evident from the parliamentary history of the Act that there must be a medical dimension to the suffering. [...]\n\nIn its 2002 Brongersma judgment, the Supreme Court, citing the parliamentary history of the Act, held that the patient\u2019s suffering must on the whole be the result of one or more medically recognised diseases or conditions. The Supreme Court also reiterated the opinion it held in the 1994 Chabot judgment, i.e. that the condition may be either somatic or psychiatric. Since then, the KNMG has adopted the position that in assessing suffering in the context of termination of life by a physician, the suffering must (at least) have a medical dimension. In view of the Brongersma judgment and the KNMG\u2019s position, the guiding principle for the RTEs is that the suffering must have a medical dimension: it must fall within the physician\u2019s domain, that is to say within the scope of his responsibility and expertise. There must be a state that can be described as a disease or a medical condition. However, there need not be a single, dominant or life-threatening medical problem. For instance, the patient could be suffering from two (or more) diseases. The medical dimension to the suffering then lies in the combination of these medical conditions.\n\nDo note however that such (accepted) medical conditions include most of the \"standard\" psychiatric diagnoses though. From a Dutch review on such cases, a vignette (of a somewhat controversial case):\n\nThe patient was a man between 30 and 40 years old with a schizoaffective disorder and unspecified personality problems, suffering mostly from depressive complaints and frequently requesting euthanasia. Three psychiatrists were involved in the euthanasia procedure. First, the patient asked his attending psychiatrist, who consulted a second psychiatrist. A third independent psychiatrist was consulted, who advised additional medicinal and psychotherapeutic treatment. The second psychiatrist, in concurrence with the attending psychiatrist, chose to disregard this advice, arguing that these were not reasonable options due to patient\u2019s lack of motivation for further treatment, and performed euthanasia. According to the RTE [regional euthanasia review committee], the performing psychiatrist had sufficient reasons for why he or she saw no benefit in the proposed treatment options and the process was judged as diligent.\n\nSuch cases of \"psychiatric euthanasia\" (as they've been called) are quite a small fraction of the total cases of euthanasia in these countries (e.g. 1% in 2017 in the Netherlands). Similar numbers for Belgium have been reported: 0.5% in 2008, 3% in 2013. Furthermore, most such requests for euthanasia (from psychiatric patients) are denied, e.g. in the Netherlands:\n\nthe percentage of EAS requests from psychiatric patients that is granted remains low: 2% in 1995, 6% in 2008 and 5% in 2016\n\nThere don't seem to have been (even) any cases of \"psychiatric euthanasia\" in Luxembourg, although the law supposedly allows them there too. There has been some commentary that a recent court decision in Quebec would allow \"psychiatric euthanasia\" there too, but insofar, I've seen no cases reported.\n\nBut to repeat this point, even the \"psychiatric euthanasia\" cases (which are also rather sparse) do not meet your criteria, as they involve a psychiatric diagnosis.\n\n  \u2022 That is very interesting and pretty much the information that I was looking to know about. Those countries north/central of Europe sometimes really show to me that they're the most ahead/developed mentality-wise (IMO). I don't think that I should say that it's a shame that the numbers are that low, but, hopefully some day those who trully don't desire any other option will be less restricted to it if they so wish so, because even though some might change ideas after undefined amount of help and/or time, others don't, and it's unfortunate that they have to continue to exist against their will. Feb 7 '20 at 23:04\n  \u2022 1\n    I'm sorry if I didn't expressed my question well enough at first and maybe still not as good as it could be. I did tried to put a substantial amount of effort into it... and a few work hours too. Feb 7 '20 at 23:06\n\nYou must log in to answer this question.\n\nNot the answer you're looking for? Browse other questions tagged ."}
{"text": "Retrieved from https://math.stackexchange.com/questions/499031/minimum-number-of-weighings-necessary\nText:\n8 boxes each having different weights are numbered from 1 to 8 (the lightest 1, the heaviest 8). The total weight of 4 boxes are equal to the other 4\u2019s total, and your task is to identify these two groups. You have a balance scale with two pans on which you can compare the weight of two groups each having exactly 4 boxes. What is the minimum number of weighings necessary to guarantee to accomplish this task?\n\n  \u2022 $\\begingroup$ As there are $\\frac 12 {8 \\choose 4}=35 \\gt 2^5$ (barely) ways to split the eight boxes into fours, one would guess $6$. $\\endgroup$ Sep 19 '13 at 22:05\n  \u2022 $\\begingroup$ Thank you very much. I was trying to solve it by choosing the most useful 4's every time. But it's hard to be sure that way=) thanks again. $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 19 '13 at 22:15\n  \u2022 $\\begingroup$ I didn't post that as an answer, as I am not convinced. But it gives an idea where to look. In puzzles like this, there may be a trick that gets you down to $5$. $\\endgroup$ Sep 19 '13 at 22:20\n  \u2022 $\\begingroup$ But you're saying it shouldn't be more than 6 right? Because I could guarantee it with 7 weighings, which should be wrong if that's what you mean. $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 19 '13 at 22:32\n  \u2022 1\n    $\\begingroup$ Some of the valid combinations are 1238, 1248,1258,1268, 1278. If you weigh 1258 first you can eliminate two of the others by noting which way the balance tilts. I believe this is the kind of thinking needed. $\\endgroup$ Sep 20 '13 at 18:46\n\nKnowing that the weights increase monotonically from box $1$ to box $8$ allows several options to be discarded out of hand. In particular, if the groups are $A=\\{a_1,a_2,a_3,a_4\\}$ and $B=\\{b_1,b_2,b_3,b_4\\}$, with $a_1<a_2<a_3<a_4$ and $b_1<b_2<b_3<b_4$ and $a_1<b_1$, then we already know the $A$'s are lighter if $a_i<b_i$ for each $i$. These ignorable configurations correspond to walks by $\\pm 1$ from $0$ to $0$ that are always non-negative: $$ 010101010 \\\\ 010101210 \\\\ 010121010 \\\\ 012101010 \\\\ 012121010 \\\\ 012101210 \\\\ 010121210 \\\\ 012321010 \\\\ 012121210 \\\\ 010123210 \\\\ 012123210 \\\\ 012321210 \\\\ 012323210 \\\\ 012343210 $$ (fourteen, or the Catalan number $C_4$) where the $A$'s are definitely lighter. (The last in this list corresponds to $A=\\{1,2,3,4\\}$ and $B=\\{5,6,7,8\\}$, for instance.) This leaves only $\\frac{1}{2}{{8}\\choose{4}}-14=21$ partitions to choose from. So it's quite possible that $5$ weightings are enough.\n\nIndeed, even $4$ may be enough, since a weighing may be balanced (that is, there are three possible outcomes, one of which consists of only one possibility). So ideally the first weighing would either balance or reduce us to $10$ possibilities; the second would either balance or reduce us to $5$ possibilities; the third would either balance or reduce us to $2$ possibilities; and the fourth would determine the answer.\n\n\nI would start with $1278$. If heavy, it allows you to knot that $7$ and $8$ are in different groups, if light, you know $1$ and $2$ are in different groups. Let us assume it is heavy, otherwise subtract all numbers below from $9$.\n\nThe remaining combinations that are possible are $$\\begin {array} \\\\1268&1368&1468&1568\\\\ 1258&1358&1458\\\\1248&1348\\\\1238\\\\ \\\\2368\\\\2358&2458\\\\2348\\\\ \\\\3458\\end{array}$$ where combinations above, north or east are known to be heavier. The line breaks represent layers in a 3D matrix. If we try $1358$ next, then either $1468$ or $2358$, we might need as many as four more. This gives $7$ weighings. I haven't proven that you can't do it in $6$.\n\n  \u2022 $\\begingroup$ There is something I dont understand. There are 6 combinations(considering 21 valid) which has 7 and 8 on the same side. There should be 15 left. How did you narrow it down to ten? What happened to 2368, 3458, 2458, 2358 and 2348 ? $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 21 '13 at 22:23\n  \u2022 $\\begingroup$ @Taner: oversight. Updated and it cost me one. Now I think one can do better. $\\endgroup$ Sep 21 '13 at 23:01\n  \u2022 $\\begingroup$ Maybe I'm asking too many questions, but I also couldnt entirely understand why did we assume 1278 would be heavier and not lighter? How does 1278 being lighter be an easier way to find the equality? $\\endgroup$\n    \u2013\u00a0Taner\n    Sep 22 '13 at 2:46\n  \u2022 $\\begingroup$ @Taner: there is a symmetry in the problem that is broken when we get that result. Any strategy that applies if 1278 is heavy is mirrored by one where 1278 is light, with all the numbers subtracted from 9. So instead of trying 1358 next, we would try 1468, then 1358 or 1467. $\\endgroup$ Sep 22 '13 at 5:16\n\nYour Answer"}
{"text": "Retrieved from https://ww2.mathworks.cn/help/stats/improve-an-engine-cooling-fan-using-design-for-six-sigma-techniques.html\nText:\nMain Content\n\nImprove an Engine Cooling Fan Using Design for Six Sigma Techniques\n\nThis example shows how to improve the performance of an engine cooling fan through a Design for Six Sigma approach using Define, Measure, Analyze, Improve, and Control (DMAIC). The initial fan does not circulate enough air through the radiator to keep the engine cool during difficult conditions. First the example shows how to design an experiment to investigate the effect of three performance factors: fan distance from the radiator, blade-tip clearance, and blade pitch angle. It then shows how to estimate optimum values for each factor, resulting in a design that produces airflows beyond the goal of 875 ft3 per minute using test data. Finally it shows how to use simulations to verify that the new design produces airflow according to the specifications in more than 99.999% of the fans manufactured. This example uses MATLAB\u00ae, Statistics and Machine Learning Toolbox\u2122, and Optimization Toolbox\u2122.\n\nDefine the Problem\n\nThis example addresses an engine cooling fan design that is unable to pull enough air through the radiator to keep the engine cool during difficult conditions, such as stop-and-go traffic or hot weather). Suppose you estimate that you need airflow of at least 875 ft3/min to keep the engine cool during difficult conditions. You need to evaluate the current design and develop an alternative design that can achieve the target airflow.\n\nAssess Cooling Fan Performance\n\nLoad the sample data.\n\n\nThe data consists of 10,000 measurements (historical production data) of the existing cooling fan performance.\n\nPlot the data to analyze the current fan's performance.\n\nylabel('Max Airflow (ft^3/min)')\ntitle('Historical Production Data')\n\nThe data is centered around 842 ft3/min and most values fall within the range of about 8 ft3/min. The plot does not tell much about the underlying distribution of data, however. Plot the histogram and fit a normal distribution to the data.\n\nhistfit(originalfan) % Plot histogram with normal distribution fit\nformat shortg\nxlabel('Airflow (ft^3/min)')\nylabel('Frequency (counts)')\ntitle('Airflow Histogram')\n\npd = fitdist(originalfan,'normal') % Fit normal distribution to data\npd = \n\n\n  Normal distribution\n       mu = 841.652   [841.616, 841.689]\n    sigma =  1.8768   [1.85114, 1.90318]\n\nfitdist\u00a0fits a normal distribution to data and estimates the parameters from data. The estimate for the mean airflow speed is 841.652 ft3/min, and the 95% confidence interval for the mean airflow speed is (841.616, 841.689). This estimate makes it clear that the current fan is not close to the required 875 ft3/min. There is need to improve the fan design to achieve the target airflow.\n\nDetermine Factors That Affect Fan Performance\n\nEvaluate the factors that affect cooling fan performance using design of experiments (DOE). The response is the cooling fan airflow rate (ft3/min). Suppose that the factors that you can modify and control are:\n\n  \u2022 Distance from radiator\n\n  \u2022 Pitch angle\n\n  \u2022 Blade tip clearance\n\nIn general, fluid systems have nonlinear behavior. Therefore, use a response surface design to estimate any nonlinear interactions among the factors. Generate the experimental runs for a Box-Behnken design in coded (normalized) variables [-1, 0, +1].\n\nCodedValue = bbdesign(3)\nCodedValue =\n\n    -1    -1     0\n    -1     1     0\n     1    -1     0\n     1     1     0\n    -1     0    -1\n    -1     0     1\n     1     0    -1\n     1     0     1\n     0    -1    -1\n     0    -1     1\n     0     1    -1\n     0     1     1\n     0     0     0\n     0     0     0\n     0     0     0\n\nThe first column is for the distance from radiator, the second column is for the pitch angle, and the third column is for the blade tip clearance. Suppose you want to test the effects of the variables at the following minimum and maximum values.\n\nDistance from radiator: 1 to 1.5 inches\nPitch angle: 15 to 35 degrees\nBlade tip clearance: 1 to 2 inches\n\nRandomize the order of the runs, convert the coded design values to real-world units, and perform the experiment in the order specified.\n\nrunorder = randperm(15);     % Random permutation of the runs\nbounds = [1 1.5;15 35;1 2];  % Min and max values for each factor\n\nRealValue = zeros(size(CodedValue));\nfor i = 1:size(CodedValue,2) % Convert coded values to real-world units\n    zmax = max(CodedValue(:,i));\n    zmin = min(CodedValue(:,i));\n    RealValue(:,i) = interp1([zmin zmax],bounds(i,:),CodedValue(:,i));\n\nSuppose that at the end of the experiments, you collect the following response values in the variable TestResult.\n\nTestResult = [837 864 829 856 880 879 872 874 834 833 860 859 874 876 875]';\n\nDisplay the design values and the response.\n\ndisp({'Run Number','Distance','Pitch','Clearance','Airflow'})\ndisp(sortrows([runorder' RealValue TestResult]))\n'Run Number'    'Distance'    'Pitch'    'Clearance'    'Airflow'\n\n            1          1.5           35          1.5          856\n            2         1.25           25          1.5          876\n            3          1.5           25            1          872\n            4         1.25           25          1.5          875\n            5            1           35          1.5          864\n            6         1.25           25          1.5          874\n            7         1.25           15            2          833\n            8          1.5           15          1.5          829\n            9         1.25           15            1          834\n           10            1           15          1.5          837\n           11          1.5           25            2          874\n           12            1           25            1          880\n           13         1.25           35            1          860\n           14            1           25            2          879\n           15         1.25           35            2          859\n\nSave the design values and the response in a table.\n\nExpmt = table(runorder', CodedValue(:,1), CodedValue(:,2), CodedValue(:,3), ...\n\nD stands for Distance, P stands for Pitch, and C stands for Clearance. Based on the experimental test results, the airflow rate is sensitive to the changing factors values. Also, four experimental runs meet or exceed the target airflow rate of 875 ft3/min (runs 2, 4,12, and 14). However, it is not clear which, if any, of these runs is the optimal one. In addition, it is not obvious how robust the design is to variation in the factors. Create a model based on the current experimental data and use the model to estimate the optimal factor settings.\n\nImprove the Cooling Fan Performance\n\nThe Box-Behnken design enables you to test for nonlinear (quadratic) effects. The form of the quadratic model is:\n\nAF\u00a0=\u00a0\u03b20+\u03b21*Distance+\u03b22*Pitch+\u03b23*Clearance+\u03b24*Distance*Pitch+\u03b25*Distance*Clearance+\u03b26*Pitch*Clearance+\u03b27*Distance2+\u03b28*Pitch2+\u03b29*Clearance2,\n\nwhere AF is the airflow rate and Bi is the coefficient for the term i. Estimate the coefficients of this model using the fitlm function from Statistics and Machine Learning Toolbox.\n\nmdl = fitlm(Expmt,'Airflow~D*P*C-D:P:C+D^2+P^2+C^2');\n\nDisplay the magnitudes of the coefficients (for normalized values) in a bar chart.\n\nh = bar(mdl.Coefficients.Estimate(2:10));\nset(h,'facecolor',[0.8 0.8 0.9])\nset(gcf,'units','normalized','position',[0.05 0.4 0.35 0.4])\nylabel('Airflow (ft^3/min)')\nxlabel('Normalized Coefficient')\ntitle('Quadratic Model Coefficients')\n\nThe bar chart shows that Pitch and Pitch2 are dominant factors. You can look at the relationship between multiple input variables and one output variable by generating a response surface plot. Use plotSlice to generate response surface plots for the model mdl interactively.\n\n\nThe plot shows the nonlinear relationship of airflow with pitch. Move the blue dashed lines around and see the effect the different factors have on airflow. Although you can use\u00a0plotSlice\u00a0to determine the optimum factor settings, you can also use Optimization Toolbox to automate the task.\n\nFind the optimal factor settings using the constrained optimization function fmincon.\n\nWrite the objective function.\n\nf = @(x) -x2fx(x,'quadratic')*mdl.Coefficients.Estimate;\n\nThe objective function is a quadratic response surface fit to the data. Minimizing the negative airflow using\u00a0fmincon\u00a0is the same as maximizing the original objective function. The constraints are the upper and lower limits tested (in coded values). Set the initial starting point to be the center of the design of the experimental test matrix.\n\nlb = [-1 -1 -1]; % Lower bound\t\t\t\t\t\nub = [1 1 1];    % Upper bound                       \nx0 = [0 0 0];    % Starting point\n[optfactors,fval] = fmincon(f,x0,[],[],[],[],lb,ub,[]); % Invoke the solver\nLocal minimum found that satisfies the constraints.\n\nOptimization completed because the objective function is non-decreasing in \nfeasible directions, to within the default value of the function tolerance,\nand constraints are satisfied to within the default value of the constraint tolerance.\n\nConvert the results to a maximization problem and real-world units.\n\nmaxval = -fval;\nmaxloc = (optfactors + 1)';\nbounds = [1 1.5;15 35;1 2];\nmaxloc=bounds(:,1)+maxloc .* ((bounds(:,2) - bounds(:,1))/2);\ndisp('Optimal Values:')\ndisp([maxloc' maxval])\nOptimal Values:\n    'Distance'    'Pitch'    'Clearance'    'Airflow'\n\n            1       27.275            1       882.26\n\nThe optimization result suggests placing the new fan one inch from the radiator, with a one-inch clearance between the tips of the fan blades and the shroud.\n\nBecause pitch angle has such a significant effect on airflow, perform additional analysis to verify that a 27.3 degree pitch angle is optimal.\n\ntbl = table(pitch,airflow);\nmdl2 = fitlm(tbl,'airflow~pitch^2');\nans =\n\n\nThe results show that a quadratic model explains the effect of pitch on the airflow well.\n\nPlot the pitch angle against airflow and impose the fitted model.\n\nhold on\nylim([840 885])\ntitle('Fitted Model and Data')\nxlabel('Pitch angle (degrees)') \nlegend('Test data','Quadratic model','Location','se')\nhold off\n\nFind the pitch value that corresponds to the maximum airflow.\n\nans =\n\n\nThe additional analysis confirms that a 27.3 degree pitch angle is optimal.\n\nThe improved cooling fan design meets the airflow requirements. You also have a model that approximates the fan performance well based on the factors you can modify in the design. Ensure that the fan performance is robust to variability in manufacturing and installation by performing a sensitivity analysis.\n\nSensitivity Analysis\n\nSuppose that, based on historical experience, the manufacturing uncertainty is as follows.\n\nFactorReal ValuesCoded Values\nDistance from radiator1.00 +/- 0.05 inch1.00 +/- 0.20 inch\nBlade pitch angle27.3 +/- 0.25 degrees0.227 +/- 0.028 degrees\nBlade tip clearance1.00 +/- 0.125 inch-1.00 +/- 0.25 inch\n\nVerify that these variations in factors will enable to maintain a robust design around the target airflow. The philosophy of Six Sigma targets a defect rate of no more than 3.4 per 1,000,000 fans. That is, the fans must hit the 875 ft3/min target 99.999% of the time.\n\nYou can verify the design using Monte Carlo simulation. Generate 10,000 random numbers for three factors with the specified tolerance. First, set the state of the random number generators so results are consistent across different runs.\n\n\nPerform the Monte Carlo simulation. Include a noise variable that is proportional to the noise in the fitted model, mdl (that is, the RMS error of the model). Because the model coefficients are in coded variables, you must generate dist, pitch, and clearance using the coded definition.\n\ndist = random('normal',optfactors(1),0.20,[10000 1]);\npitch = random('normal',optfactors(2),0.028,[10000 1]);\nclearance = random('normal',optfactors(3),0.25,[10000 1]);\nnoise = random('normal',0,mdl2.RMSE,[10000 1]);\n\nCalculate airflow for 10,000 random factor combinations using the model.\n\nsimfactor = [dist pitch clearance];\nX = x2fx(simfactor,'quadratic');\n\nAdd noise to the model (the variation in the data that the model did not account for).\n\nsimflow = X*mdl.Coefficients.Estimate+noise;\n\nEvaluate the variation in the model's predicted airflow using a histogram. To estimate the mean and standard deviation, fit a normal distribution to data.\n\npd = fitdist(simflow,'normal');\nhold on\ntext(,300,['Mean: ' num2str(round(])\ntext(,280,['Standard deviation: ' num2str(round(pd.sigma))])\nhold off\ntitle('Monte Carlo Simulation Results')\n\nThe results look promising. The average airflow is 882 ft3/min and appears to be better than 875 ft3/min for most of the data.\n\nDetermine the probability that the airflow is at 875 ft3/min or below.\n\nformat long\npfail = cdf(pd,875)\npass = (1-pfail)*100\npfail =\n\n\npass =\n\n\nThe design appears to achieve at least 875 ft3/min of airflow 99.999% of the time.\n\nUse the simulation results to estimate the process capability.\n\nS = capability(simflow,[875.0 890])\npass = (1-S.Pl)*100\nS = \n\n       mu: 8.822982645666709e+02\n    sigma: 1.424806876923940\n        P: 0.999999816749816\n       Pl: 1.509289008603141e-07\n       Pu: 3.232128339675335e-08\n       Cp: 1.754623760237126\n      Cpl: 1.707427788957002\n      Cpu: 1.801819731517250\n      Cpk: 1.707427788957002\n\npass =\n\n\nThe Cp value is 1.75. A process is considered high quality when Cp is greater than or equal to 1.6. The Cpk is similar to the Cp value, which indicates that the process is centered. Now implement this design. Monitor it to verify the design process and to ensure that the cooling fan delivers high-quality performance.\n\nControl Manufacturing of the Improved Cooling Fan\n\nYou can monitor and evaluate the manufacturing and installation process of the new fan using control charts. Evaluate the first 30 days of production of the new cooling fan. Initially, five cooling fans per day were produced. First, load the sample data from the new process.\n\n\nPlot the X-bar and S charts.\n\ncontrolchart(spcflow,'chart',{'xbar','s'}) % Reshape the data into daily sets\n\nAccording to the results, the manufacturing process is in statistical control, as indicated by the absence of violations of control limits or nonrandom patterns in the data over time. You can also run a capability analysis on the data to evaluate the process.\n\n[row,col] = size(spcflow);\nS2 = capability(reshape(spcflow,row*col,1),[875.0 890])\npass = (1-S.Pl)*100\nS2 = \n\n       mu: 8.821061141685465e+02\n    sigma: 1.423887508874697\n        P: 0.999999684316149\n       Pl: 3.008932155898586e-07\n       Pu: 1.479063578225176e-08\n       Cp: 1.755756676295137\n      Cpl: 1.663547652525458\n      Cpu: 1.847965700064817\n      Cpk: 1.663547652525458\n\npass =\n\n\nThe Cp value of 1.755 is very similar to the estimated value of 1.73. The Cpk value of 1.66 is smaller than the Cp value. However, only a Cpk value less than 1.33, which indicates that the process shifted significantly toward one of the process limits, is a concern. The process is well within the limits and it achieves the target airflow (875 ft3/min) more than 99.999% of the time."}
{"text": "Retrieved from https://web2.0calc.com/questions/math-question_88\nText:\nwhat is 6^2/2(3)+4\n\nGuest\u00a0Aug 3, 2017\n\n4+0 Answers\n\n\nwhat is 6^2/2(3)+4\n\n\nPower calculation before point calculation before line calculation,\nthen from left to right.\n\n\n\\(\\frac{6^2}{2\\times 3}+4=\\frac{36}{6}+4=6+4\\color{blue}=10\\)\n\n\nWhoever wants can also shorten de Bruch by 6. \u00a0\u00a0 (\\(\\frac{36}{6}=\\frac{6}{1}\\) )\n\n\nlaugh\u00a0 !\n\nasinus \u00a0Aug 3, 2017\n\nThis is a rare example in mathematics where, I believe,\u00a0parentheses is necessary in order to evaluate the expression without ambiguity. I will demonstrate why.\n\n\nStrictly speaking, asinus's interpretation is incorrect. If you were to evaluate this with a calculator inputted like as is, the calculator would evaluate it as\u00a0\\(\\frac{6^2}{2}*3+4\\). This is because the 2(3) is really multiplication, so division takes precedence since it is\u00a0comes first in the expression. First it does 6^2, then it divides 6^2 by 2 because division is first from left to right, and then it multiplies that quantity by 3. Here is another example with a variable\u00a0\n\n\n\n\nUsing the same logic as above, this equation, in fraction form is strictly\u00a0\\(\\frac{8}{2}y\\)--not\u00a0\\(\\frac{8}{2y}\\). Some would argue, however, that 2y is a term, so it shouldn't be separated.\u00a0\u00a0\n\n\nHow do we eliminate this ambiguity if there is no fraction button to speak of? Use parentheses!\u00a0\n\n\nAsinus's interpretation of \\(\\frac{6^2}{2*3}+4\\)\u00a0will be unambiguous once you add 1 set of parentheses with\u00a0\\(6^2/(2(3))+4\\). Now, the only correct interpretation is\u00a0\\(\\frac{6^2}{2*3}+4\\)\u00a0because the parentheses indicate that we are dividing by the quantity of the product of 2 and 3.\n\n\nThe strict interpretation is\u00a0\\(\\frac{6^2}{2}*3+4\\)\u00a0should be written like\u00a0\\((6^2/2)(3)+4\\). In this case, the quantity of six squared divided by two is all multiplied by three. No more ambiguity.\n\n\nOkay, after all of this ranting, now I will evaluate what I believe to be, under the current rules of the order of operations, the way to evaluate the expression 6^2/2(3)+4 as\u00a0\\(\\frac{6^2}{2}*3+4\\):\n\n\n\\(\\frac{6^2}{2}*3+4\\) Evaluate the numerator.\u00a0\\(6^2=36\\)\n\\(\\frac{36}{2}*3+4\\) Simplify the fraction\u00a0by recognizing that the 36 is divisible by 2 because 36 is even.\n\\(18*3+4\\) Do multiplication before addition.\n\n\n\n\n\nTheXSquaredFactor \u00a0Aug 3, 2017\n\nHello\u00a0 \\(X^2\\)\n\nNeither of us is wrong.\nRight, who puts brackets to represent the meaning of his term.\ngreetings :)\n\nasinus \u00a0Aug 4, 2017\n\nGreetings to you, too :)\n\nTheXSquaredFactor \u00a0Aug 5, 2017\n\n23 Online Users"}
{"text": "Retrieved from https://www.physicsforums.com/threads/minimize-a-certain-function-involving-sine-and-cosine.662968/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMinimize a certain function involving sine and cosine\n\n  1. Jan 7, 2013 #1\n    It isn't a homework problem per se, but a curiosity a stumbled upon when trying to solve a physics problem (I was trying to calculate the angle I would need to do less work possible, while moving the box). The equation I found is:\n    [itex]f(\\theta)=\\cos(\\theta)+ 0.4sen(\\theta)[/itex]\n\n    2. Relevant equations\n\n    Just the one stated above, and trig identities, probably.\n\n    3. The attempt at a solution\n\n    I tried a few things (including deriving and finding the roots of the function without success, since I couldn't found the roots), I also tried to rewrite (Using cos\u00b2 + sin\u00b2 = 1) and got:\n    [itex]f(\\theta)=\\sqrt{1-\\sin^2(\\theta)}+ 0.4sin(\\theta)[/itex]\n    But I also don't know how to find the minimum in this equation.\n\n    How could I go about solving that?\n\n    Thanks in advance!\n    Last edited: Jan 7, 2013\n  2. jcsd\n  3. Jan 7, 2013 #2\n    What problems did you run into? Did you do anything with tangent?\n  4. Jan 7, 2013 #3\n\n\n    User Avatar\n    Science Advisor\n\n    Interesting that you use both \"sen\" and \"sin\"! Can't decide between French and English?\n\n    You have [itex]f(\\theta)= cos(\\theta)+ 0.4sin(\\theta)[/itex] (only English for me, I'm afraid.). I don't see any reason to introduce a square root just to have only sine. Taking the derivative, [itex]f'(\\theta)= -sin(\\theta)+ 0.4cos(\\theta)= 0[/itex] at a max or min. That is the same as [itex]sin(\\theta)= 0.4 cos(\\theta)[/itex] or, since sine and cosine are not 0 for the same [itex]\\theta[/itex], we must have [itex]sin(\\theta)/cos(\\theta)= tan(\\theta)= 0.4[/itex]. You can use a calculator to solve that.\n    Last edited by a moderator: Jan 7, 2013\n  5. Jan 7, 2013 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Reposting HallsofIvy's post to fix up the LaTex:\n  6. Jan 7, 2013 #5\n    Oh god, I can't believe I ignored sin(x)/cos(x) = tan(x). I'm terribly sorry, thanks a lot! That solves my problem.\n\n    About the whole sen and sin thing, it's because I'm actually Brazilian, and here we write \"Sen\", so I sometimes get both of them confused :P\n  7. Jan 7, 2013 #6\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You also need to worry about whether the point you find is a maximizer or a minimizer of f.\n  8. Jan 7, 2013 #7\n    Yes indeed, but that was easily done by deriving again and finding if the result in this particular point would be positive or negative, since I found a negative value I concluded that it was a maximum, the value I wanted(In OP I miswrote, I actually wanted a maximum initially).\n\n    [itex]tan(\\theta)= 0.4;\\theta = 21.8^o\\\\f''(21.8^o)= -1.077[/itex]\n\n    However, since you mentioned that, I just realized that I have no idea on how to find the minimum. Shouldn't [itex]tan(\\theta) = 0.4[\\itex] yield two values, one of which is a maximum and another which is a minimum?\n  9. Jan 7, 2013 #8\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n  10. Jan 7, 2013 #9\n    Hmm. I found by trial and error that the angles should be: 21.8\u00b0 and 201.8\u00b0, but how am I supposed to get the 201.8\u00b0? My calculator only gave me 21.8\u00b0.\n  11. Jan 7, 2013 #10\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    tan(x)=tan(x+180). The values of tan repeat every 180 degrees (pi in radians). It's periodic with period pi.\n  12. Jan 7, 2013 #11\n    Ohhh, I see, thanks!\n    I really need to get better in trigonometry. I have several wrong concepts :S\n  13. Jan 7, 2013 #12\n\n\n    User Avatar\n    Homework Helper\n\n    This is usually done with the identity\n\n    [tex]\\cos (x)+\\frac{2}{5} \\sin (x)=\\sqrt {1+\\left( \\frac{2}{5} \\right) ^2 } \\sin \\left( x+\\arctan \\left( \\frac{5}{2} \\right) \\right)[/tex]\n\n    Which is quite easy to optimize.\n\nSimilar Discussions: Minimize a certain function involving sine and cosine"}
{"text": "Retrieved from https://www.physicsforums.com/threads/questions-on-weinberg-cosmology-book.697215/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestions on Weinberg Cosmology Book\n\n  1. Jun 15, 2013 #1\n    I am following up Weinberg Cosmology book, but I have one question.\n\n    In chapter 3.1, we have Eq (3.1.3) and (3.1.4)\n\n    [itex] s(T) = \\frac{\\rho(T) + p(T)}{T} [/itex]\n    [itex] T\\frac{dp(T)}{dT} = \\rho(T) + p(T) [/itex]\n\n    In Eq (3.1.5), we have the Fermi-Dirac or Bose-Einstein distributions.\n\n    [itex] n(p, T) = \\frac{4 \\pi g p^2}{(2 \\pi \\hbar)^3} \\frac{1}{exp(\\sqrt{p^2 + m^2} / k_B T) \\pm 1} [/itex].\n\n    From using this number distribution, the author said we have the energy density and pressure of a particle mass m are given by Eq (3.1.6) and (3.1.7).\n\n    [itex] \\rho(T) = \\int n(p, T) dp \\sqrt{p^2 + m^2} [/itex]\n    [itex] p(T) = \\int n(p, T) dp \\frac{p^2}{3\\sqrt{p^2 + m^2}} [/itex]\n\n    Here, energy density is straightforward by the definition of number density.\n    But, for pressure, the author said it can be derived from Eq(3.1.4), the second equation on this post.\n\n    However, I cannot derive this pressure equation using Eq(3.1.4). Can somebody help me do this?\n\n    Thank you.\n  2. jcsd\n  3. Jun 22, 2013 #2\n\n\n    User Avatar\n    Science Advisor\n\n    My Weinberg seems a lot different from your Weinberg! But tracing through it, here's where the p(T) equation comes from. For a particle (using c = 1), the energy is E = \u03b3m and the momentum is p = \u03b3mv. Thus p/E = v (Eq.1)\n\n    For a system of particles, the energy-momentum tensor is T\u03bc\u03bd = \u2211n pn\u03bc dxn\u03bd/dt \u03b43(x-xn), or using Eq.1, T\u03bc\u03bd = \u2211n pn\u03bc pn\u03bd/En \u03b43(x-xn\n\n    For a perfect fluid, the spatial components of T\u03bc\u03bd are related to the pressure p by Tij = p \u03b4ij.\n\n    Thus p = (1/3) \u01a9j Tjj = (1/3) \u01a9n pn2/En \u03b43(x-xn).\n\n    This gets you the p2 in the numerator, the E in the denominator, and the 1/3 out front."}
{"text": "Retrieved from https://www.physicsforums.com/threads/factoring-3rd-degree-polynomial-for-eigenvalues.719119/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nFactoring 3rd degree polynomial for eigenvalues\n\n  1. Oct 27, 2013 #1\n    Was given a matrix\n    To find the eigenvalues I set up the characteristic equation\n    [-1-x | 7 | -5 ]\n    [-4 | 11-x | -6 ]\n    [-4 | 8 | -3-x]\n\n    With some dirty work I got this bad boy out, which I'm having trouble factoring\n\n    2. Relevant equations\n    Looking for method to factor it, without aid of calculator\n    Or if there's a better way to determine the equation which will give me the factors without setting up a polynomial\n\n    3. The attempt at a solution\n    I tried the grouping method but that doesn't work since all I end up with is\n  2. jcsd\n  3. Oct 27, 2013 #2\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Use the rational root theorem on the polynomial ##x^3 - 7x^2 + 15 x - 9##; that is, look for roots among the + or - integer factors of -9.\n  4. Oct 27, 2013 #3\n    Thanks I forgot about that theorem.\n    But how do I rule out the negative or positive integers?\n  5. Oct 27, 2013 #4\n\n\n    Staff: Mentor\n\n    You can rule out a potential root r by discovering that x - r is not a factor of your cubic polynomial. The rational root theorem says that the possible rational roots for your cubic are 1, -1, 3, -3, 9, and -9.\n\n    Use either long division or synthetic division to determine whether x - 1, x - (-1), x - 3, x - (-3), x - 9, or x - (-9) are factors. If one of these is a factor, the remainder will be zero. If it's not a factor, the remainder will be nonzero.\n  6. Oct 27, 2013 #5\n  7. Oct 27, 2013 #6\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    In this case you can put x = -y to find that the polynomial has the form p(x) = -q(y), where ##q(y) = y^3 + 7 y^2 + 15 y +9##. Obviously, q(y) does not have any positive roots (all its coefficients are > 0), so p(x) does not have any negative roots. This type of trick does not always work, but it happens to be OK in this example. Even if it did not work, you could just try out all the factors of -9 to see if one of them sets p(x) = 0. As soon as you find one that works you can stop checking and start again with the resulting quadratic remaining factor.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/what-is-this-constant-in-the-gravitational-acceleration-formula.542612/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nWhat is this constant in the gravitational acceleration formula?\n\n  1. Oct 21, 2011 #1\n\n    Hey all, I'm doing an assignment and I was given the formula below, but I'm unsure what one of the constants is.\n\n    2. Relevant equations\n\n    Acceleration = - \u03bcEr/r3\n\n    3. The attempt at a solution\n\n    Below the formula it says \"where \u03bcE is the gravitational constant for the Earth and r is the position vector of the vehicle\". But this is talking about a satellite orbiting Earth, so it can't be 9.8m/s/s, can it?\n\n    Am I meant to use \u03bcE = u*m1*m2/r2 to find it?\n\n    I've used the 'geocentric gravitational constant' elsewhere in the assignment, but it used a different symbol, this isn't it either is it?\n\n  2. jcsd\n  3. Oct 21, 2011 #2\n\n\n    User Avatar\n    Homework Helper\n\n  4. Oct 21, 2011 #3\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Last edited by a moderator: Apr 26, 2017\n  5. Oct 21, 2011 #4\n\n\n    User Avatar\n    Homework Helper\n\n    The correct formula you asked about is\n\n    [tex]\\vec a = -\\mu_e \\frac{\\vec r}{r^3}[/tex]\n\n    [itex]\\vec r [/itex] is the position vector of a satellite or any point-like mass with respect to the centre of Earth, and [itex]\\vec a [/itex] is its gravitational acceleration. The formula is a special case of the Universal Law of Gravity,\n\n    [tex]\\vec F = -G \\frac{m_1 m_2 \\vec r}{r^3}[/tex]\n\n    the force a point mass 1 exerts on an other point mass 2 at distance r. The force is parallel and opposite to the vector [itex]\\vec r[/itex] pointing to mass 2 from mass 1.\n    G is the gravitational constant G= 6.67259 \u02d910-11 Nm2kg-2.\n\n    If the first mass is the Earth, Gm1=GMearthe.\n\n  6. Oct 21, 2011 #5\n    Is that 'Gravitational Constant' the 'Universal Gravitational Constant (6.67*10-11' Nascent?\n  7. Oct 21, 2011 #6\n    Ignore my above post.\n\n    That makes sense ehild! Because F = ma, a = F/m. You remove the mass of the satellite from your second formula and exchange F for a. Leaving you with a = G*mE*r/r3.\n\n  8. Oct 21, 2011 #7\n\n\n    User Avatar\n    Homework Helper\n\n    All right, I see you got it."}
{"text": "Retrieved from http://www.maths.cam.ac.uk/damtp-and-dpmms-join-forces-new-lectureship\nText:\nskip to content\n\nFaculty of Mathematics\n\n\nThe faculty is proud to welcome Claude Warnick, a lecturer with a joint appointment in the Department of Applied Mathematics and Theoretical Physics and the Department of Pure Mathematics and Mathematical Statistics. What kind of research does such an inter-departmental position entail?\n\nFor teaching there is a lot of value on being\u00a0able to draw on aspects from many different places. When trying to explain a concept, the more ways you can explain it, the better chance students have of understanding. Claude Warnick\n\nTo modern eyes the boundary between pure mathematics on the one hand and applied mathematics and physics on the other can seem like a rigid line. The Faculty has been divided along this line and many mathematicians place themselves firmly into one of the two camps. The famous Cambridge number theorist GH Hardy even prided himself on the (supposed) lack of applicability of pure maths. \"The 'real' math of the 'real' mathematicians, the mathematics of Fermat and Euler and Gauss and Abel and Riemann, is almost wholly 'useless',\" he wrote in A Mathematician's Apology.\n\nIn reality ideas have always crossed the boundary between pure maths and physics. The geometric notions developed by Bernhard Riemann and mentioned by Hardy, though not inspired by physical problems, turned out to be exactly what Albert Einstein needed for his general theory of relativity, to describe the curvature of spacetime induced by matter. Considerations of mathematical symmetry have predicted the existence of fundamental particles of nature, including the famous Higgs boson, and continue to lead the way in theoretical physics.\n\nPerhaps less famously, ideas have also flowed in the other direction, especially in recent decades. A beautiful example comes from physicists' approach to explore an object by bombarding it with particles and seeing how they scatter, as happens in particle colliders. The idea inspired mathematicians to explore geometric objects by letting hypothetical particles (or strings from string theory), described by mathematical formulae, move around on them. The approach eventually helped them answer questions in pure geometry that had been open for a hundred years.\n\nA foot in each camp\n\nWarnick's appointment by both departments acknowledges the non-trivial intersection of pure maths and physics. \"It's a very natural thing to blur the lines and I think there have always been people who have worked on both sides of the boundary.\" Warnick's research concerns the malleable nature of spacetime, as predicted by Einstein's famous theory and mentioned above. \"I work on partial differential equations and general relativity,\" he explains. \"Partial differential equations describe how a physical quantity varies depending on two or more continuous quantities. [General relativity] is our theory to describe [the force of gravity].\"\n\nIn Warnick's case the link between the two rests on a phenomenon we're all familiar with: waves. \"The fact that you can hear me is down to the fact that sound waves are propagating through the air in this room,\" says Warnick. Waves, including sound waves, can be described by partial differential equations, and it's these wave equations that Warnick is interested in. \"One of the most interesting things about [general relativity] is that [its central equation] is very similar in character to the wave equation that describes sound,\" he explains. The equivalent of sound waves moving through air are gravitational waves. First predicted by Einstein around a 100 years ago, these waves are ripples in the fabric of spacetime that originate from gravitational events, such as the collisions of massive black holes. The detection of gravitational waves in 2015 was one of the major breakthroughs in modern physics.\n\n\"My research [explores] the kind of equations that link these phenomena: wave equations and also problems to do with gravity and general relativity,\" says Warnick. \"The kind of work I am interested in naturally has aspects that are pure mathematical. [In] the study of partial differential equations one has to do a fair amount of analysis and one wants to prove rigorous theorems where possible. On the other hand [what we] are interested in are questions like how black holes behave or how gravitational radiation propagates through the Universe. These are very physical questions, so it's very natural to have a foot in both camps.\"\n\nTeaching from many angles\n\nIn terms of his research a joint lectureship is a natural choice for Warnick, but he thinks that his teaching also stands to benefit. \"The boundary between pure and applied maths is not a rigid line,\" he says. \"For teaching there is a lot of value in being able to draw on aspects from many different places. When trying to explain a concept, the more ways you can explain it, the more ways you can link it to other parts of mathematics, the better chance students have of understanding. From the point of teaching it's a valuable thing to be able to link the two departments.\"\n\nWarnick, who completed is undergraduate degree and PhD in Cambridge, will be working with other researchers based in both DPMMS and DAMTP. He returns to the Faculty at a time of spectacular advances in his field. \"The most exciting recent development in my field is the direct measurement of gravitational waves. [Their\u00a0existence] has been conjectured for many decades and only now do we have direct experimental evidence to show that [they do] exist. It's a really exciting time because [gravitational waves] open a window on gravitational physics and a window on the Universe. I think a tremendous amount of interesting data will come out of [gravitational wave] experiments in the near future. I'm really looking forward to where this discovery will go in the next few years.\"\n\nYou can find out more about gravitational waves, and the role of Faculty researchers in their discovery, in this feature.\u00a0To find out more about the impact of physics on pure mathematics, watch this lecture by David Tong, Professor of Theoretical Physics at DAMTP."}
{"text": "Retrieved from https://www.physicsforums.com/threads/air-resistance-and-drag-coefficien.260206/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Air Resistance and drag coefficien\n\n  1. Sep 29, 2008 #1\n\n    An object of mass 10kg is projected upwards (from ground level) with initial velocity 60m/s. It hits the ground 8.4 seconds later.\n\n    Find the drag coefficient, k.\n\n    2. Relevant equations\n\n    dv/dt + rv = -g, where r = k/m\n\n    3. The attempt at a solution\n\n    I have used the integrating factor of e^rt to give me the final equation:\n\n    v = -g/r + C/e^rt\n\n    I then plug in the initial values to get:\n\n    60 = -98/k + C\n\n    I am not sure what to do next. We are given an impact time of 8.4 seconds. Do I assume that at this instant the velocity is -60 m/s (i.e. the exact opposite of the initial)? Or can I assume that at time 4.2 seconds the velocity is equal to 0? In either case, I am not sure how to solve the equation so that I only have one variable (e.g. just k or just C).\n\n  2. jcsd\n  3. Sep 29, 2008 #2\n    I don't follow your logic, why would you do this? I would start by making a FBD of the object. Your drag force will obviously be a function of velocity but you should come up with a fairly simple integral based off of the golden kinematics equations.\n  4. Sep 29, 2008 #3\n    Solved it.\n\n    I had to use e^-rt, use the initial velocity to give me a value for C, substitute that back in and then integrate with respect to t to give me height. From there you know that at t=0 and t=8.4, the height is 0. You can then calculate r and because you know the mass, k.\n\n    Use that r value for the velocity and you can then solve the velocity at t=8.4. The maximum height will be when the velocity equation is equal to 0.\n\n\n    Took me 2 hours, but I worked it out."}
{"text": "Retrieved from https://www.physicsforums.com/threads/eccentricity-of-orbit.244403/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Eccentricity of Orbit\n\n  1. Jul 10, 2008 #1\n    A particle moves in an elliptical orbit in an inverse-square law central force \ufb01eld. If the\n    ratio of the maximum angular velocity to the minimum angular velocity of the particle\n    in its orbit is n, then show that the eccentricity of the orbit is\n\n    \\epsilon = \\frac{\\sqrt{n}-1}{\\sqrt{n}+1}[/tex]\n\n    Not sure where to go with this. I tried finding total energy and angular momentum in terms of max/min angular velocity and radius but can't get anywhere\n  2. jcsd\n  3. Jul 10, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n\n    At what points in the orbit are the maximal and minimum angular (or, for that matter, linear) velocities attained? At what distances from the \"massive body\" (what the particle is orbiting around -- assumed to be \"infinitely massive\" here) is the particle at those moments? (You don't need values here -- just identify those places on the orbit and label them appropriately.)\n\n    Now for the critical part. Angular momentum is conserved. What angle does the velocity makes to the radial vector from the massive body at those moments (and no others)? Express the angular momentum in terms of radial distance and velocities for those two moments and set them equal. What is the relationship between these two angular (or linear) velocities and the two distances from the massive body?\n\n    Having found how the ratio of angular velocities, called n here, relates to those distances, how do those distances fit into the expression for the eccentricity of an ellipse?\n\n    That would be the full derivation of the answer. If you already know how n relates to the ratio of distances, it's a short step to getting to the eccentricity expression...\n  4. Jul 10, 2008 #3\n    Thanks, got it. Silly of me for starting with eccentricity in terms of energy and angular momentum instead of geometry.\n  5. Jul 10, 2008 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    \u2026 geometry \u2026\n\n    Hi cscott! :smile:\n\n    Consider it geometrically \u2026\n\n    Hint: if F is a focus of the ellipse, and P and Q are the ends of the major axis, what is PF/QF as a function of e?\n\n    And then what is n as a function of PF/QF? :smile:"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54873.html\nText:\nThe Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nDistance Between 2 Lines: Vectors\n\nDate: 8/19/96 at 23:29:28\nFrom: Anonymous\nSubject: Shortest Distance...\n\nWhat is the shortest distance between 2 lines?\n\nDate: 8/20/96 at 8:16:26\nFrom: Doctor Anthony\nSubject: Re: Shortest Distance...\n\nI am not sure how much vector work you have done, but I will assume a \nknowledge of scalar products of vectors, and the vector equation of \nstraight lines.  \n\nIn 3D space the shortest distance between two skew lines is in the \ndirection of the common perpendicular. (There is one and only one such \ndirection, as can be seen if you move one line parallel to itself \nuntil it intersects the other line. These two lines would now define a \nplane, and the perpendicular to this plane is the direction of the \ncommon perpendicular).  \n\nYou now take any point on one line, and any point on the other line, \nand write down the vector joining these two points.  Finally you find \nthe component of this vector in the direction of the common \nperpendicular.  This is done by finding the scalar product of the \nvector with the UNIT vector in the direction of the common \nperpendicular.  The result of the scalar product is the shortest \ndistance you require.  \n\nI will illustrate the method by means of an example. \n\nFind the shortest distance between the lines:\n\nx/1 = (y-3)/1 = z/(-1)\n\n(x-5)/3 = (y-8)/7 = (z-2)/(-1)\n\nFirst we require the vector perpendicular to both (1,1,-1) and \n\nLet the common perpendicular be (p,q,r). The scalar product of this \nwith both (1,1.-1) and (3,7,-1) will be zero, so:\n\n   p+q-r = 0 and 3p+7q-r = 0\n\nNote that although there are apparently 3 unknowns and only two \nequations, these are homogeneous equations (having 0 on the right hand \nside), so we could find values of p/r and q/r and hence the ratios \np:q:r which is all that we require.  Using the determinant method for \nsolving, we have:\n\n    p       -q          r\n|1  -1|   |1  -1|     |1   1|\n|7  -1|   |3  -1|     |3   7|\n\n   p/6  =  -q/2    =   r/4\n\n   p/3  =  q/-1    =   r/2   and so  p:q:r = 3:-1:2\n\nSo the common perpendicular is the vector (3,-1,2)\n\nAs a UNIT vector this is (1/sqrt(14)){3,-1,2}\n\nNext we have point (0,3,0) on line (1) and (5,8,2) on line (2).  \nThe vector joining these points is (5,5,2)  and now scalar product \nthis with the unit vector of the common perpendicular.\n\nScalar product = (1/(sqrt(14)){5*3 + 5*(-1) + 2*2}\n               = (1/sqrt(14)){15 - 5 + 4}\n               = 14/sqrt(14)\n               = sqrt(14)    \n\n   and this is the shortest distance required.\n\n-Doctor Anthony,  The Math Forum\n Check out our web site!   \nAssociated Topics:\nHigh School Geometry\nHigh School Higher-Dimensional Geometry\nHigh School Linear Algebra\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM"}
{"text": "Retrieved from https://www.physicsforums.com/threads/probability-expected-value-of-z-where-z-x-1-y-2.530580/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Probability- expected value of Z, where z= X/(1+y)^2\n\n  1. Sep 15, 2011 #1\n\n    X & Y are independent r.v.s with uniform distribution between 0 and 1.\n\n    Z= X/(1+Y)^2\n\n    find E[Z].\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    Here is what I did.\n\n    E[Z]= E[X]*E[1/(1+Y)^2]\n    I think that once I know the distribution of (1+Y)^(-2), I'll be able to find the answer. Is it 1/(1+Y)^2~ U(1,2) ?\n  2. jcsd\n  3. Sep 15, 2011 #2\n    You can also use this theorem:\n\n\n    So, in your case, this comes down to\n\n  4. Sep 15, 2011 #3\n\n\n    thanks for the answer.\n\n    Is 1+y^2 a typo in your answer?\n    so adding a constant to a uniform r.v. doesn't change it's distribution?\n  5. Sep 15, 2011 #4\n\n    Obviously it does change the distribution. But I don't see how that is important here.\n  6. Sep 15, 2011 #5\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If W = 1/(1+Y)^2, then for any w > 0 we have P{W <= w} = P{1/(1+Y)^2 <= w} = P{-sqrt(w) <= 1/(1+Y) <= sqrt(w)}. The left-hand inequality -sqrt(w) <= 1/(1+Y) holds automatically because Y >= 0, so P{W <= w} = P{1/(1+Y) <= sqrt(w)} = P{Y >= -1 + 1/sqrt(w)}. Since Y ~ U(0,1), we can easily get P{W <= w} and hence can get the density function of W. Alternatively: just apply the standard formula for the density of a transformed random variable.\n\n  7. Sep 15, 2011 #6\n\n    Well I was thinking that now its uniformly distributed from 1 to 2... isn't it?\n\n    Oh right its still uniform from 0 to 1...\n    omg... I'm so rusty :\\\n\n    Last edited: Sep 15, 2011\n  8. Sep 15, 2011 #7\n\n    Ray Vickson\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have all the information you need to work out the answer for yourself."}
{"text": "Retrieved from https://www.physicsforums.com/threads/extended-power-derivative.763884/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Extended power derivative\n\n  1. Jul 29, 2014 #1\n    I am having difficulty calculating the following derivative [tex]{ \\frac{2x^2-1}{(3x^4+2)^2}}[/tex]\n\n    Could someone demonstrate the first step algebraically? Assuming c is the exponent on the variable expression, n is the numerator and d is the denominator, I tried:\n\n\n    Which gives me\n\n    Which simplifies to\n    [tex]\\frac{-48 x^7+72 x^5+8 x^3-16 x}{(3x^4+2)^3}[/tex]\n\n    However, the book lists the answer as being [tex]\\frac{-36x^5+24x^3+8x}{(3x^4+2)^2}[/tex]\n  2. jcsd\n  3. Jul 29, 2014 #2\n\n    Char. Limit\n\n    User Avatar\n    Gold Member\n\n    I'm not quite sure what rule you're trying to use, but if it's the quotient rule, then you've got it written down wrong. The correct way is:\n\n    [tex]\\frac{d}{dx} \\frac{n(x)}{d(x)} = \\frac{n'(x) d(x) - d'(x) n(x)}{d(x)^2}[/tex]\n\n    Since you've already worked the latter expression out, it should be easy to finish for you.\n  4. Jul 29, 2014 #3\n    Are you sure that : [tex]\\frac{d}{dx} (3x^4+2)^2=12x^3[/tex] ?\n  5. Jul 29, 2014 #4\n    My book lists a rule called the \"extended power rule,\" which goes as follows:\n\n    \"Suppose g(x) is a differentiable function of x. Then, for any real number k,\n\n    [tex]\\frac {d}{dx}[g(x)]^k=k[g(x)]^{k-1}*\\frac{d}{dx}[g(x)][/tex]\n\n    Here's a link to the text:\n\n\n    I could easily solve the problem by expanding the binomial expression (3x^4+2)^2 and then using the standard product rule, but I need to know how to use the extended product rule as one of the sample question is raised to the power of 7, and there is no way that I am going to expand that. If you can offer me an alternative method to dealing with the derivatives of high order expressions, I would accept that as well.\n  6. Jul 29, 2014 #5\n\n    Char. Limit\n\n    User Avatar\n    Gold Member\n\n    The extended power rule isn't exactly relevant here. And you got that particular part correct. The problem was that the quotient rule, for whatever reason, was done incorrectly. I'm not sure where you got a c or the first part of that product.\n  7. Jul 29, 2014 #6\n    The book says to use the extended power rule in addition to the quotient rule to solve this particular problem, so it has to be relevant >_>\n\n    According to the extended power rule, I take the exponent off the expression, k (i accidentally put c), and multiply it by g(x). The text has a step-by-step example of how to use the extended power rule in conjunction with another quotient problem, [tex]\\sqrt[4]{\\frac{x+3}{x-2}}[/tex] in which they use the setup [tex]k\\frac{n(x)}{d(x)}\\frac{n'(x)*d(x)-d'(x)*n(x)}{d(x)^2}[/tex], but that form doesn't appear to work here.\n  8. Jul 29, 2014 #7\n    You don't need to expend these high order derivatives, just use the chain rule. As a reminder [tex](3x^4+2)^2[/tex] can be seen as a function of this type : [tex]f(g(x))\\ \\mbox{where}\\ g(x)=3x^4+2\\ \\mbox{and}\\ f(x) = x^2\\\\ \\mbox {Now consider that the x in}\\ x^2\\ \\mbox{actually is your function g(x), that is, f(x) is applied to g(x), the x in brackets become g(x).}\\\\ \\mbox{You then have your function h(x) = f(g(x)), which is} (3x^4+2)^2\\\\ \\mbox{You can now differentiate h(x), and as you can see, it's simply the derivative of f(g(x)).}\\\\ \\mbox{Use the chain rule:} \\frac{d}{dx}f(g(x)) = f'(g(x)) * g'(x)\\ \\mbox{and you've got the derivative.}\\\\ \\mbox{You can now differentiate polynomials, for instance :} \\frac{d}{dx}(4x^5+3)^9 = 9*(4x^5+3)^8 * 20x^4\\\\ \\mbox{In general :}\\ \\frac{d}{dx}(P(x))^n = n(P(x))^{n-1} * P'(x)[/tex]\n\n    Hope this helps!\n  9. Jul 29, 2014 #8\n    thank you!\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/mis-using-bernoullis-equation.836002/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHomework Help: Mis-using Bernoulli's equation\n\n  1. Oct 4, 2015 #1\n\n    An incompressible heated gas of constant temperature and pressure flows along an infinitely long tube at an unspecified velocity v1; a pressure of P1; and a density of p1 into an unheated open area of infinite volume containing the same gas at a lower pressure of P2; a density of p2,; and an effective velocity v2 of 0 m/s. The pipe is horizontal. Find the velocity of the gas inside the tube, ignoring friction and head losses.\n\n    2. Relevant equations\n    Bernoulli's equation, maybe\n\n    3. The attempt at a solution\n    Since the pipe is horizontal, h1 and h2 are treated as 0, cancelling out the pgh terms on each side of the equation. Since v2 is also 0, the .5p2v22 is eliminated. That leaves us with:\n\n    P1 + .5p1v12 = P2\n\n    Since P1 > P2 in this situation, the answer is always going to be the square root of a negative number.\n\n    Common sense tells me that the gas will flow from a region of high pressure to a region of low pressure, so it should flow out of the tube; sadly, it seems that I am applying Bernoulli's equation incorrectly in attempting to form a basic model of that effect. That, or something else is terribly wrong with the way the scenario is laid out (this is my own thought experiment; it is not homework, and no teacher is to blame for this problem).\n\n    Just looking at the reduced equation, it's all wrong. There's no way the high pressure value plus PLUS the squared velocity is going to equal the low pressure value. But the flow velocity in the tube is going to be non-zero since gas will be constantly leaving the tube ad infinitum, while the velocity outside of the tube is going to be zero since it is effectively a section of tube with a cross-sectional area approaching infinity.\n  2. jcsd\n  3. Oct 5, 2015 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    2017 Award\n\n    Bernoulli equation is conservation of energy. At tube inlet you have pressure energy and kinetic energy. At tube outlet you have lower pressure energy, so if all else can be ignored, you should have higher kinetic energy. I.e. v2 > v1, in contradiction with your assumption that v2 = 0.\n    The change from v2 > v1, to v'2 = 0 must occur somewhere in or around the tube outlet area, apparently.\n\n    Look at Bernoulli examples for flow through a small orifice (most have \u0394p > 0 from tank to jet) and compare with your case (\u0394p > 0 from pipe to 'tank')\n  4. Oct 5, 2015 #3\n    Your answer makes sense. I have erred in assuming that the equation covers the quiescent gas in the open area rather than the gas ejected from the tube in the immediate vicinity of the tube's outlet.\n  5. Oct 6, 2015 #4\n    Followup question: Given that the above-mentioned gas in the tube assumes a velocity of v2 immediately after exiting the tube where v2 > v1, is it safe to assume that the pressure P2 and density p2 of said gas will be the same as that of the quiescent gas in the open area? Or will that only pertain once the velocity of the exiting gas settles out after some arbitrary amount of time and effectively equals 0?\n  6. Oct 6, 2015 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    2017 Award\n\n    Bernoulli to the rescue again: when the gas is slowing down, the pressure must necessarily increase ! So I would say no. There will be some contraction effects and a volume where p is even lower than P2. I think I saw them described in one of the orifice flow examples.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from http://mathoverflow.net/questions/122104/area-of-triangles-vs-comparison-triangles\nText:\nTake the 2-minute tour \u00d7\n\nLet $X$ be a complete, simply connected Riemannian manifold satisfying a quadratic (coarse) isoperimetric inequality. (I.e., there is a constant $C_{0}$ such that every loop of length $\\ell$ has a filling disk of area $\\leq C_{0}\\ell^{2}+C_{0}$.)\n\nFor points $a,b,c\\in X$, define $Area_{X}(a,b,c)$ to be the minimal area of any geodesic triangle in $X$ with vertices $a,b,c$. Define $Area_{comp}(a,b,c)$ to be the area of a Euclidean triangle with side lengths $d(a,b)$, $d(b,c)$ and $d(c,a)$.\n\nDoes there exist a constant $C$ such that for all $a,b,c\\in X$ we have:\n\n$Area_{X}(a,b,c)\\leq C Area_{comp}(a,b,c)+C$?\n\nIf the answer is no, then are there counterexamples when $X$ is homogeneous?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\n\nBlow a bubble of the same size at each integer point of $\\mathbb R^2$. Clearly coarse isoperimetric inequality will hold.\n\nOn the other hand, the global metric on the plane can be made arbitrary close to the Manhattan metric, in particular there will be triangles which bound arbitrary large area while its comparison area is near zero.\n\nshare|improve this answer\nP.S. If you look in \"Periodic metric\" by Burago you will see more than you want to. \u2013\u00a0 Anton Petrunin Feb 18 '13 at 0:17\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/rate-of-change-of-x-wrt-sin-x.747893/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nRate of change of x wrt sin(x)\n\n  1. Apr 9, 2014 #1\n    Is possible to compute the rate of change of x wrt sin(x)? ##\\frac{dx}{d \\sin(x)}##\n  2. jcsd\n  3. Apr 9, 2014 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Have you tried just plotting it in Excel? You will get some 1/0 inflection points that you will need to deal with...\n  4. Apr 9, 2014 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Compare with ##\\frac{dsin^{-1}(x)}{dx}##\n\n    Or, turn the graph of sin(x) on its side.\n  5. Apr 9, 2014 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Compare to reciprocal dsin(x)/dx. Sin-1(x) is not relevant.\n  6. Apr 9, 2014 #5\n    Why isn't it relevant?\n\n    If we have dx/d(sinx), why is it not reasonable for me to let sinx = y and therefore have that x = arcsin(y)?\n\n    Then I have d(arcsin(y))/y = 1 / sqrt(1-y\u00b2)\n\n    And thus dx/d(sinx) = 1/sqrt(1-sin\u00b2(x)) = 1/sqrt(cos\u00b2(x)) = 1/|cos(x)|\n\n    Just curious, so where does this break down? This is a very unique question so I'm sure there is an error in my logic. One may note that this comes out to be only slightly different than the reciprocal method (no absolute value). I suspect this is because in assigning these variables in the way I did, I restricted/changed domain?\n    Last edited: Apr 9, 2014\n  7. Apr 9, 2014 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n\n    Due to the inverse function theorem, it is very relevant.\n  8. Apr 10, 2014 #7\n    After a quick Google, it looks like I followed this theorem with f(a) = sin(x). So why does f'(b) evaluate to 1/|cos(x)| according to my work rather than 1/cos(x) as the inverse function theorem claims it should?\n\n    I mean, hopefully we can agree that the answer to the OP's question is actually 1/cos(x) and not 1/|cos(x)|.\n  9. Apr 10, 2014 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    There are two ways to \"differentiate x with respect to sin(x)\". The first is to use the fact that\n    [tex]\\frac{dx}{dy}= \\frac{1}{\\frac{dy}{dx}}[/tex].\n    Here y= sin(x) so dy/dx= cos(x). Then dx/dy= 1/cos(x) is a perfectly good answer.\n\n    The other way is to say that if y= sin(x) then [itex]x= sin^{-1}(y)[/itex] so that the derivative of \"x with respect to sin(x)\" is [itex]dx/dy= d(sin^{-1}(y))/dy= 1/\\sqrt{1- y^2}[/itex].\n\n    It's not at all difficult to prove that those are the same. If y= sin(x) then [itex]1- y^2= 1- sin^2(x)= cos^2(x)[/itex] so [itex]1/\\sqrt{1- y^2}= 1/cos(x)[/itex].\n  10. Apr 10, 2014 #9\n    So, I can differentiate any function f(x) wrt another any function g(x).\n\n    If df = f'(x) dx and dg = g'(x) dx, thus df/dg = f'/g' ...\n  11. Apr 10, 2014 #10\n    Our work is the same, but I don't understand how you conclude that sqrt(cos\u00b2(x)) = cos(x). This is |cos(x)|, don't you agree?\n  12. Apr 10, 2014 #11\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n\n    Well, the sine function is not invertible, since it's not injective and not surjective. This is of course no problem for the inverse function theorem, since it will take a \"local inverse\".\n    You worked with the arcsine, which is indeed a local inverse. But not all local inverses are like the arcsine. That is, if we restrict the sine to ##(-\\pi/2,\\pi/2)## then the arcsine is an inverse. But guess what? The cosine function is actually positive on that said, so the absolute values drop.\n\n    If you apply the inverse function theorem on some other domain, then you can't use the arcsine anymore in that form.\n\n    Does that make sense?\n  13. Apr 10, 2014 #12\n    Yes, thank you.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Rate of change of x wrt sin(x)\n  1. Integration of sin(x) (Replies: 14)\n\n  2. Sin x =cosh x (Replies: 12)\n\n  3. Inverse of sin(x)+x (Replies: 10)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/y-x-2-y-2-xy-ode.86514/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\n\n  1. Aug 27, 2005 #1\n    for this O.D.E. :\n    y`= (x^2 + y^2)/xy\n    it's unseparable, so what other methods can there be taken?\n  2. jcsd\n  3. Aug 27, 2005 #2\n    It's a change of variables case (actually excercise #1 in my book on this topic), the way you do this is check to see whether f(x,y) = f(tx,ty), where f(x,y) = dy/dx.\n    So if you substitute tx and ty for x and y respectively, you'll see that equality holds. Then do following substitution: y = x V(x) into the DE and see what you get with applying dy/dx and some simplifications. It should reduce to separable equation.\n  4. Aug 27, 2005 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    This is just like the post about the other ODE. You can write it as:\n\n\n    Again, with the substitution z=y/x it becomes:\n\n    which is separable.\n  5. Aug 28, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    it's homogenous, separable, use v=y/x\n  6. Aug 30, 2005 #5\n    ok, thanks!\n  7. Sep 3, 2005 #6\n    here's my work:\n    y`=x/y +x/y\n    suppose y=vx\n    => y`=v+xv`\n    so v+xv`=1/v+v\n    => vdv=dx/x\n    => v^2=ln[absolute value(x)]+c`\n    => (y^2)/(x^2)=ln[absolute value(x)]+c\n    => y^2=2(x^2)ln[absolute value(x)]+cx^2\n    now if i take the square root on both sides, there should be a positive and negative sign on the right~\n    the correct answer should only have the positive sign, but how can you be sure that it should be positive?\n  8. Sep 3, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Whoopsie, you've forgot a factor 1/2 on the left side.\n\n    You can use either sign, both will be valid solutions to the ODE. This becomes clear when you plug y back into the ODE to check if it works out. Then, with the benefit of hindsight, you could foresee this, since if y is one solution, then the other is -y and it's derivative is -y'. If you write the ODE as xyy'=x^2+y^2 you can see that if y is a solution, then -y is too.\n\n    Ofcourse, if you're given a boundary value or initial value/condition then there will be only one solution. (otherwise the problem is ill-stated).\n  9. Sep 4, 2005 #8\n    thank you very much! :)\n\nHave something to add?"}
{"text": "Retrieved from http://mathoverflow.net/questions/131066/in-cell-decomposed-manifolds-how-easy-is-it-to-arrange-for-the-tubular-neighbor\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that you have decomposed a manifold $M$ into cells (I care most, if it matters, about compact oriented smooth manifolds; but if my question can be solved in the PL category, all the better). By this, I have in mind some sort of combinatorial description, so there probably should be various words like \"regular\" or whatnot. For various reasons, I cannot restrict my attention to simplicial decompositions \u2014 I must allow cubes, for example. In any case, if you have done so, then on the set of cells in $M$ there is a metric, generated by declaring that $\\operatorname{distance}(a,b) = 1$ if $a$ is a facet of $b$ (i.e. if the cell $a$ lies in the closure of the cell $b$). Then given any collection $Y$ of cells and any $\\ell \\in \\mathbb N = \\lbrace 0,1,2,\\dots\\rbrace$, I can define the set $\\mathrm{B}_\\ell(Y)$ to consist of the closure of the union of all cells at distance at most $\\ell$ from some element of $Y$. It is a sub-cell-complex of $M$. Suppose that the cell decomposition is very fine compared to the topologies of $Y$ and $M$: then one should expect that $\\mathrm{B}_\\ell(Y)$ contracts onto the closure of $Y$. Note that the closure of $Y$ is precisely $\\mathrm{B}_0(Y)$.\n\nMy specific situation is as follows. I have a manifold (compact, oriented, etc., if it matters) $X$. If I choose a cell decomposition of $X$, then I can induce a cell decomposition of $M = X^n$ by declaring that a cell of $M$ is an $n$-tuple of cells in $X$. (Certainly, if my cells were simplices with ordered vertices, then I could make other choices, but for my application this is most natural.) The diagonal map $X \\hookrightarrow X^n$ is not a map of cell complexes, but still for each cell in $X$, there is a corresponding diagonal cell of $M$, and I will define $Y$ to be this \"diagonal\" copy of $X$.\n\nMy question is the following:\n\nFor fixed $\\ell$, but letting $n$ vary, how can one find a cell decomposition of $X$ such that, with the notation above, $\\mathrm B_\\ell(Y)$ has the homotopy type of $X$? Or at least the same rational homology?\n\nAlmost surely, the $\\ell$-fold barycentric subdivision of any cell decomposition of $X$ will do the trick \u2014 probably the $\\lceil \\log_2\\ell \\rceil$-fold barycentric subdivision would work \u2014 but I find myself unable to prove this, even after talking to various friends who know more topology than I do. Or perhaps I'm supposed to find a Riemannian metric for which I would have the appropriate result, and then choose a cell decomposition in which all vertices are at distance roughly $1$ from each other. Or something. In any case, I know that my intuition for high-dimensional manifolds is poor.\n\nI do know how to prove that after one barycentric subdivision, $\\mathrm{B}_0(Y)$ has the rational homology of $X$.\n\nshare|improve this question\nYour question is very close in spirit to Abrams and Ghrist's work on discretized configuration spaces. It's not quite the same but it's close. \u2013\u00a0 Ryan Budney May 18 '13 at 20:28\n@Ryan: Thanks for the comment! I was unaware of their work, but I'll look it up. \u2013\u00a0 Theo Johnson-Freyd May 18 '13 at 21:57\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/597134/deformations-of-a-cuspidal-plane-cubic\nText:\nTake the 2-minute tour \u00d7\n\nTo practice with deformations, I am trying to compute the space of first order deformations of the cuspidal curve $X=\\textrm{Spec }B$, where $B=P/I$, $P=k[x,y]$ and $I=(f)=(y^2-x^3)$.\n\nThe conormal sequence $$I/I^2\\overset{d}{\\longrightarrow}\\Omega_{P/k}\\otimes_PB\\cong B\\,dx\\oplus B\\,dy\\longrightarrow \\Omega_{B/k}\\longrightarrow 0$$ induces a $B$-linear map (the \"dual\" of $d$) $$\\alpha:\\hom_B(\\Omega_{P/k}\\otimes_PB,B)\\to\\hom_B(I/I^2,B).$$ Just to be as clear as possible with those who read this question, I give a list of \"synonyms\" of the space of first order deformations of $X$ (hoping not to confuse anyone, nor to state something wrong!):\n\n  \u2022 $\\textrm{coker } \\alpha$,\n  \u2022 $T^1(B/k,B)$,\n  \u2022 $\\textrm{Ex}_k(B,B)$,\n  \u2022 $\\textrm{Ext}^1_B(\\Omega_{B/k},B)$.\n\nI attempted to determine $\\textrm{coker }\\alpha$, but now I'm stuck.\n\nWhat I did was just to translate the maps explicitly. So for instance $I/I^2$ is a principal module generated by $\\overline f=f+I^2$, so $$d:\\overline f\\mapsto 2y\\,dy-3x^2\\,dx.$$ This is useful to determine $\\alpha$. The source is generated by two vector fields $\\partial/\\partial x$ and $\\partial/\\partial y$, so: \\begin{align} \\alpha: &\\partial/\\partial x\\mapsto (\\overline f\\mapsto \\partial f/\\partial x=-3x^2),\\\\ \\alpha: &\\partial/\\partial y\\mapsto (\\overline f\\mapsto \\partial f/\\partial y=2y). \\end{align}\n\nNow, as $I/I^2$ is a principal module, we get an identification $(\\star)$ $$\\textrm{coker }\\alpha=\\hom_B(I/I^2,B)/\\textrm{Im }\\alpha\\overset{(\\star)}{\\cong} B/(-3x^2,2y)\\cong k[t^2,t^3]/(t^4,t^6).$$\n\nI cannot go further, and I remember having read on Moduli of Curves that this space should be $2$-dimensional. Can anyone help me to conclude?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nThe quotient $B/(-3x^2,2y) \\cong B/(x^2,y) = k\\langle 1, x \\rangle$.\n\nA mini-versal deformation is given by $x^3 + y^2 + ax + b$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/131648/even-more-generalized-catalan-numbers/131656\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the number of ways to parenthesize $n$ elements using applications of operators of arbitrary arities larger than or equal to $2$? For example, for $n=3$, there are $3$ ways: $$ abc, a(bc),(ab)c $$ and for $n=4$ there are 11 ways: $$ abcd,\\ ab(cd),\\ a(bc)d,\\ (ab)cd ,\\ a(bcd), (abc)d,$$ $$ a(b(cd)),\\ a((bc)d),\\ (ab)(cd),\\ (a(bc))d,\\ ((ab)c)d $$ Note that, if we restrict the operators to have arity $2$ (i.e. binary operators), then the answer would be given by the Catalan number $C_{n-1}$. (More generally, if we restrict the operators to have arity $p$, the answer would be given by generalized Catalan numbers. So the point here is that the arity is arbitrary, corresponding to a situation where I can select between operators of arities 2,3,4,...\n\nAn aymptotic formula for $n\\to\\infty$ would also be highly appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nA little bit of programming and a look up in the OEIS tells me that this is the sequence A001003, the solution to Schroeder's second problem, see also Wikipedia.\n\nAccording to the page in OEIS, the asymptotic form is $$ \\frac{n^{-3/2}}{4}\\sqrt{\\frac{\\sqrt{18}-4}{\\pi}}(3+\\sqrt{8})^n. $$\n\nshare|improve this answer\nThe wikipedia is clickable in this notation: en.wikipedia.org/wiki/Schr%C3%B6der%E2%80%93Hipparchus_number \u2013\u00a0 Gottfried Helms May 24 '13 at 1:10\nJust was I was looking for. Thank you! \u2013\u00a0 Esben May 24 '13 at 7:03\nBy the way, if you take just the first four terms in the sequence (1,1,3,11) and put them into OEIS, the first suggestion (out of 191) that comes up is in fact the right answer. OEIS is incredibly useful for these types of questions. \u2013\u00a0 Kirill May 24 '13 at 17:50\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/46350/between-mu-and-primitive-recursion/46359\nText:\nTake the 2-minute tour \u00d7\n\nIt is well known that primitive recursion is not powerful enough to express all functions, Ackermann function being probably the best known example.\n\nNow, in the logic courses (that I have had look at) one always proceeded from primitive recursion to mu-recursion. In computer science terms this basicly means we are jumping from a formalism where programs are quaranteed to halt to a Turing-complete formalism where halting is a non-computable property i.e. we can't say for every program if it will eventually halt.\n\nI got curious if there is any hierarchy between primitive recursion and mu-recursion. After a while I found a programming language called Charity. In Charity (according to Wikipedia) all programs are quaranteed to stop, thus its not Turing-complete, but, on the other hand, it is expressive enough to implement Ackermann function.\n\nThis suggests there is at least one level between mu-recursion and primitive recursion.\n\nMy question is: does there exists any other halt-for-sure formalisms that are more expressive than primitive recursion? Or, even better, does there exist some known hierarchies between mu-recursive and primitive recursive functions? I'm curious about how \"much\" we can compute with a formalism that guarantees halting.\n\nshare|improve this question\nThis question appears to be very closely related: mathoverflow.net/questions/35461/\u2026 \u2013\u00a0 Chris Pressey Nov 29 '12 at 21:30\n\n7 Answers 7\n\nup vote 11 down vote accepted\n\nI think it would also be reasonable to (explicitly) mention the functions definable by primitive recursion in higher types - instead of only defining functions $\\mathbb{N}\\to\\mathbb{N}$ by primitive recursion, we may also define families of functions (i.e. functions $\\mathbb{N}\\to\\mathbb{N^N}$) by primitive recursion (and, of course, even more complicated things).\n\nAs an example, let us first define an iteration function $g\\colon\\mathbb{N}\\times\\mathbb{N^N}\\to\\mathbb{N^N}$ by primitive recursion, by: \\begin{array}{l} g(0,f) = i \\qquad\\qquad\\text{(the identity function)}\\\\\\\\ g(n+1, f) = f\\circ g(n, f) \\end{array} We can then easily define a `curried' version of the Ackermann function as a function $A\\colon\\mathbb{N}\\to\\mathbb{N^N}$, by: \\begin{array}{l} A(0) = S \\quad\\quad\\text{(successor)}\\\\\\\\ A(n+1) = g(n, A(n)) \\end{array}\n\nThis is quite popular with (some groups of) computer scientists, particularly those interested in functional programming, and some form of primitive recursion in higher types is behind the strength of the language Charity you mentioned (which also allows primitive recursion over other data structures than the natural numbers).\n\nshare|improve this answer\nThank you for adding this! I was sorry to see an answer accepted without this approach being mentioned, when it seems to me to be more useful for real programming. I wanted to mention it myself, but it was not something I was in a position to look up or work out myself when I made my original answer: I was invigilating an exam. \u2013\u00a0 Max Nov 29 '10 at 21:08\nThis is very helpful answer and I might have rushed when flagging answer (I wasn't expecting more answers). Thank you for writing this up anyway! Kow, do you happen to have any references in hand for any applications of this method? \u2013\u00a0 user10891 Dec 10 '10 at 18:07\nReferences is perhaps overstating it. I've learnt about it in the context of proof assistants for higher-order logic (e.g. Isabelle/HOL) and type theory (e.g. Coq). All these have extensive online documentation and examples (and have been used for major proofs, e.g. Gonthier's proof of the four color theorem). You might also look at the chapter on finite type arithmetic in Troelstra&van Dalen's Constructivism in Mathematics, Vol 2, for more background. It might also interest you to think about what can be done with an NNO in a Cartesian Closed Category -- exponentials are very useful. \u2013\u00a0 kow Dec 14 '10 at 15:49\n\nRobin Chapman's answer is very apropos. Here is a theoretical answer that points out a subtlety in the question.\n\nFirst, recall that the primitive recursive functions are the smallest class of functions on $\\mathbb{N}$ that:\n\n  \u2022 Includes the constant zero function, the successor function, and all projection functions;\n  \u2022 is closed under composition;\n  \u2022 and is closed under primitive recursion.\n\nLet's call this class of functions $\\operatorname{PR}(\\emptyset)$. For any set $A$ of number theoretic functions, we can define a more general class $\\operatorname{PR}(A)$ as the smallest class of functions that satisfies the above properties and also includes every function in $A$.\n\nIf every function in $A$ is computable, then every function in $\\operatorname{PR}(A)$ is computable. Moreover, if every function in $A$ is total then every function in $\\operatorname{PR}(A)$ is total.\n\nIt would be trivial, assuming $A$ is finite (or, more generally just explicitly enumerated), to create a programming language such that every program in the language computes a function in $\\operatorname{PA}(A)$ and every such function has a program in the language. The language simply has primitives for all the functions in $A$ and for the basic primitive recursive functions, along with operators for composition and primitive recursion.\n\nTherefore, one answer to \"I'm curious about how \"much\" we can compute with a formalism that guarantees halting.\" is \"For any total computable function there is such a formalism\" and more generally this is true for any effective sequence of total computable functions.\n\nThe main thing that such a system cannot have is a universal function, provided the system has some basic closure properties.\n\n\nSince several people pointed out the same thing, I may as well add some value to the answer by including the standard proof of my remark about universal functions. A universal two-place function, for some system, is a function $g(i,k)$ such that for every one-place function $f(k)$ in the system there is some natural number $e$ with $\\lambda k .f(k) = \\lambda k. g(e,k)$. Suppose that $g$ is such a function; define a function $h$ as $h(k) = g(k,k) + 1$. Then $h$ has some index $e$. Thus $g(e,e) = h(e)$ by the definition of $g$ and $e$, and $h(e) = g(e,e) + 1$ by construction of $h$. This is impossible, so any system of total functions that allows me to form the functions like $h$ cannot have a universal function $g$.\n\nIn particular, for any class of functions $A$ and any function $g(j,i)$ in $\\operatorname{PA}(A)$, the function $h(n) = g(n,n)+1$ is in $\\operatorname{PR}(A)$. So this class will not have a universal function provided that every function in $A$ is total. Of course if you let $A$ be the set of all partial computable functions then $\\operatorname{PR}(A)$ is also the set of all partial computable functions and so it does contain a universal function (which is not total).\n\nFrom this point of view, the limitation is not on whether particular computable functions can be included; the limitation is on the internal structure of any particular effective class of functions.\n\nshare|improve this answer\nCarl, it seems we came to the same conclusion. \u2013\u00a0 Joel David Hamkins Nov 17 '10 at 14:48\nYes, and Max also had the same insight, just in a more preliminary form. \u2013\u00a0 Carl Mummert Nov 17 '10 at 14:51\nOk, it surely seems I got the mathematical background well explained in these answers. Thanks to everybody for that. I'm not sure about the usual policy about the points and stuff, but as the fast growing hierarchy pointer happens to be pretty much what I was looking for I'll mark it as an answer. \u2013\u00a0 user10891 Nov 18 '10 at 10:37\n\nYou might look up fast-growing hierarchies.\n\nshare|improve this answer\nAt a high level, this is very much the answer, in that it allows us to capture the strength of theories described by certain amount of recursion, while being independent of the actual presentation of the version of recursion being allowed (instead, as a typical example, we have access to a limited amount of induction). \u2013\u00a0 Andres Caicedo Nov 17 '10 at 17:49\nBut PR can extend to the side also, and not just upward; not every extension of PR involves fast-growing functions. For example, adding the characteristic function of a suitably generic real will not lead to any dominating functions at all. \u2013\u00a0 Joel David Hamkins Nov 23 '10 at 14:53\n\nOne can consider programming formalisms where a program is a pair (M, P), with M a Turing machine and P a proof that M halts on all inputs. Then, if the proof is correct, (M, P)(x) = M(x); if it is incorrect, (M, P)(x) = 0.\n\nAlternatively, one can consider primitive recursion with an \"oracle\" function: so, for example, we can allow the Ackermann function in our recursion bounds. If we use a primitive recursive oracle, we gain no power; but as long as we use a computable function, our functions remain computable. This should give a hierarchy with respect to the oracles, but I'm not sure of the details.\n\nshare|improve this answer\n\nThe class PR of primitive recursive functions is the smallest class of functions containing a few simple functions (successor, zero, projection) and closed under composition and definition of functions by recursion.\n\nIf $f:\\mathbb{N}^k\\to \\mathbb{N}$ is any function at all, one can form the class $PR(f)$ of functions that are primitive recursive relative to $f$, simply by adding $f$ as one of the simple functions and then closing under composition and recursion. If $f$ is total, then every function in $PR(f)$ is total, and if $f$ is computable, then every function in $PR(f)$ will be computable. This amounts to using $f$ as an oracle, as mentioned by Max. There is a clear hierarchy here, because if $f\\in PR(g)$, then $PR(f)\\subset PR(g)$, and this hierarchy amounts to something like the hierarchy of Turing degrees, but with primitive recursion.\n\nMore generally, for any set $F$ of functions, we may form $PR(F)$ by adding all the functions in $F$ and closing under composition and recursion, and we still have the hierarchy that if $F\\subset PR(G)$, then $PR(F)\\subset PR(G)$. This more general situation seems fully general, since if you have a class $F$ of functions containing all primitive recursive functions and closed under composition and recursion, then $F=PR(F)$, and so this hierarchy seems to capture all the classes that you might wish to consider.\n\nshare|improve this answer\n\nLook for John Reynolds paper \"Total functional programming\" which is about a programming language in which only primitive recursive functions in a setting where higher-order types (like in G\u00f6del's system T) are allowed. Maybe that resembles Charity which Kow mentioned. Reynolds cites a theorem (of Spector?) saying the functions his language can express are exactly the ones provably total in second-order arithmetic. That is enormous compared with Ackermann's function but still stops short of various total functions that can be implemented on general Turing machines.\n\nshare|improve this answer\nYou mean DA Turner's paper Total functional programming? \u2013\u00a0 Martin Berger May 5 '14 at 10:51\n\nRegarding hierarchy, it's basic result of recursion theory that every recursive function f, is expressible as:\n\n$f(x_{0},\u2026,x_{n}) = u(\\mu y.(T(e_{f},\\langle x_{0},\u2026,x_{n}\\rangle))$\n\nwhere $T$, $u$ are fixed primitive recursive functions, and $e_{f}\\in\\mathbb{N}$ depends on $f$ (it is a code name describing how $f$ is built). (See any elementary text like Sch\u00f6nfield.)\n\nThus the hierarchy is pretty short.\n\nshare|improve this answer\nThe question and answers are about the hierarchy that arises without the $\\mu$-operator, closing under primitive recursion but not unbounded search. \u2013\u00a0 Joel David Hamkins Feb 7 '11 at 8:40\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/72180/what-dirichlet-doesnt-tell/72181\nText:\nTake the 2-minute tour \u00d7\n\nLet $n>1$ be an integer, and let us consider the set $P(n)$ of all prime numbers $p$ such that $p$ is not congruent to $1$ modulo $n$. Dirichlet's Density Theorem tells us that $P(n)$ has a natural density, equal to $$1-\\varphi(n)^{-1}$$ where $\\varphi(n) = |(\\mathbb Z /n)^\\ast|$ is Euler's totient.\n\nFrom the Frobenian point of view, saying that $p$ is congruent to $1$ modulo $n$ is to say that the ideal $(p)$ splits completely in the cyclotomic field $\\mathbb Q(\\zeta_n)$.\n\nFrom Chebotarev's point of view, saying that $p$ is congruent to $1$ modulo $n$ is to say that the Frobenius element over $p$ in $\\operatorname{Gal}(\\mathbb Q(\\zeta_n)|\\mathbb Q) \\simeq (\\mathbb Z /n)^\\ast$ is the identity.\n\nSo far so good, now let us consider the set $P$ of all prime numbers $p$ which are not congruent to $1$ modulo $n^2$ for any $n>1$, that is $$P := \\bigcap_{n>1}P(n^2) = \\bigcap_{\\ell\\mathrm{ prime}}P(\\ell^2)$$ Supposing that \"the events $P(\\ell^2)$ are uncorrelated\" for different $\\ell$'s, we can phantasise about the density of $P$, hoping it might be (at least up to a rational factor, I don't vouch for it) $$\\operatorname{dens}(P) = \\prod_\\ell 1-\\frac{1}{\\ell(\\ell-1)} \\quad = 0.37395581361920228805...$$ a number called Artin's constant (it appears in Artins primitive root conjecture, which is similar in nature). The question whether $P$, or similarly constructed sets of primes, have a density and whether it is the expected one goes far beyond the density theorems of Dirichlet, Frobenius and Chebotarev. The corresponding Galois extension would be the maximal cyclotomic extension of $\\mathbb Q$, which is ramified everywhere.\n\nCan you name this problem? Have you seen it before? Where?\n\nHooley (1967) has shown that Artins primitive root conjecture follows from GRH. In principle, the problem of determining the density of $P$ should be simpler.\n\nUnder GRH, is it true that the density of $P$ exists and is equal to Artin's constant?\n\nshare|improve this question\nInteresting question, but perhaps a more precise title is appropriate. \u2013\u00a0 Martin Brandenburg Aug 5 '11 at 16:03\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nThe specific density result you quote is a result of Mirsky, see\n\nL. Mirsky, \"The number of representations of an integer as the sume of a prime and a k-free integer\", Amer. Math. Monthly 56 (1949)\n\nThere have been several generalizations, for the direction on replacing squares with higher powers see \"Values of the Euler function free of k-th powers\" by W.D. Banks and F. Pappalardi. For the result on primes not congruent to $\\frac{a}{b}\\pmod{n^2}$ see \"Arithmetic progressions, prime numbers, and squarefree integers\" by S. Clary and J. Fabrykowski.\n\nshare|improve this answer\n\nLet me sketch a proof. If you fix a bound $z$, then the events $P(\\ell^2)$ for different $\\ell \\leq z$ are uncorrelated; this is just a consequence of the prime number theorem for progressions and the multiplicativity of Euler's function. This reduces the problem to \"understanding the tails\"; in other words, we have to show that as $z\\to\\infty$, the relative upper density of the primes divisible by $\\ell^2$ for some $\\ell > z$ tends to zero.\n\nConsider the primes $p \\leq x$. By the Brun--Titchmarsh inequality, the number of such $p$ for which $p-1$ is divisible by $\\ell^2$ for some prime $\\ell$ with $z < \\ell \\leq x^{1/4}$ (say) is $$ \\ll \\sum_{z< \\ell \\leq x^{1/4}} \\frac{x}{\\phi(\\ell^2)\\log{(x/\\ell^2)}} \\ll \\pi(x) \\sum_{z > \\ell} \\frac{1}{\\ell^2} \\ll \\frac{\\pi(z)}{x}. $$ Also, the number of $p$'s with $p-1$ divisible by $\\ell^2$ for some $\\ell > x^{1/4}$ can be estimated trivially: We just count how many $n \\leq x$ are divisible by some $\\ell^2$ with $\\ell > x^{1/4}$, which is clearly at most $\\sum_{\\ell > x^{1/4}} \\lfloor x/\\ell^2\\rfloor \\ll x^{3/4}$. This is negligible for us. Hence, the relative upper density in the previous paragraph is $\\ll 1/z$. So it does indeed tend to zero as $z\\to\\infty$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/58972/probability-of-preserving-connectivity-between-pair-of-vertices-in-weighted-grap\nText:\nTake the 2-minute tour \u00d7\n\nLet $G=(V,E)$ be an undirected graph and $p \\colon E \\mapsto (0,1]$ defines weights of its edges.\n\nLet's fix two connected vertices $v_1, v_2 \\in V$.\n\nRandom graph $G'=(V,E')$ is obtained from $G$ by removing each edge $e \\in E$ with probability $1-p(e)$.\n\nWhat is the probability that connectivity between $v_1$ and $v_2$ is preserved in $G'$?\n\nshare|improve this question\nThis looks hopeless to have a nice formula isn't it ? \u2013\u00a0 camomille Mar 20 '11 at 14:39\nYou definitely must tell more about the graph (and about the weight function) to get any answer at all. Compare the case of the line graph with $v_1$ and $v_2$ far apart to the case of the complete graph on $n$ vertices with $n$ large. \u2013\u00a0 Did Mar 20 '11 at 14:52\n@Didier well, you right, that's implied part of the question -- if there are no nice results for arbitrary graph, maybe there are any non-trivial classes of graphs, where this problem is trackable? In my context it would be randomly generated scale-free network with number of edges that makes the brute force method unfeasible. \u2013\u00a0 alyst Mar 20 '11 at 17:33\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet L be the set of all simple paths in G from $v_1$ to $v_2$. By inclusion-exclusion, the probability that $v_1$ and $v_2$ are connected is\n\n$\\sum_{A \\subseteq L} (-1)^{|A|-1} P(\\cup A \\subseteq E')$\n\nwhere for any set S of edges, $P(S \\subseteq E') = \\prod_{e \\in S} p(e)$.\n\nAlthough explicit computation won't be feasible for large graphs, under appropriate conditions this might be used to get asymptotics.\n\nshare|improve this answer\nThanks, Robert. That gives an idea for an alternative formula: if $M$ is a collection of all minimal sets of edges, which removal disrupts connectivity between $v_1$ and $v_2$, then $1 - \\sum_{B \\subseteq M} (-1)^{|B|-1} P(\\cup B \\not\\subseteq E')$ should also be the sought probability, where $P(S \\not\\subseteq E') = \\prod_{e \\in S} (1-p(e))$. \u2013\u00a0 alyst Mar 20 '11 at 21:28\n\nYour Answer"}
{"text": "Retrieved from http://swmath.org/software/8812\nText:\nScalaBLAST: A Scalable Implementation of BLAST for High-Performance Data-Intensive Bioinformatics Analysis. Genes in an organism\u2019s DNA (genome) have embedded in them information about proteins, which are the molecules that do most of a cell\u2019s work. A typical bacterial genome contains on the order of 5,000 genes. Mammalian genomes can contain tens of thousands of genes. For each genome sequenced, the challenge is to identify protein components (proteome) being actively used for a given set of conditions. Fundamentally, sequence alignment is a sequence matching problem focused on unlocking protein information embedded in the genetic code, making it possible to assemble a \u201dtree of life\u201d by comparing new sequences against all sequences from known organisms. But, the memory footprint of sequence data is growing more rapidly than per-node core memory. Despite years of research and development, high-performance sequence alignment applications either do not scale well, cannot accommodate very large databases in core, or require special hardware. We have developed a high-performance sequence alignment application, ScalaBLAST, which accommodates very large databases and which scales linearly to as many as thousands of processors on both distributed memory and shared memory architectures, representing a substantial improvement over the current state-of-the-art in high-performance sequence alignment with scaling and portability. ScalaBLAST relies on a collection of techniques - distributing the target database over available memory, multilevel parallelism to exploit concurrency, parallel I/O, and latency hiding through data prefetching - to achieve high-performance and scalability. This demonstrated approach of database sharing combined with effective task scheduling should have broad ranging applications to other informatics-driven sciences"}
{"text": "Retrieved from https://www.physicsforums.com/threads/trigonometric-substitution.264934/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nTrigonometric substitution\n\n  1. Oct 16, 2008 #1\n    Hello, I have been wokring on this problem for some hours now, and I get the wrong answer, but I can't understand why, could you guys please look at it?\n  2. jcsd\n  3. Oct 16, 2008 #2\n    I should probably mention that the answer is supposed to be:\n\n    2*arctan(2x)+4x/(4x^2+1) +C\n  4. Oct 16, 2008 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    I didn't go through that in detail but it looks like a very strange way to attack the problem! You have a square of a square and you write it as a fourth power of a square root of a square so you can apply a trig substitution!\n    You don't need the square root to apply a trig substitution. Let 2x= tan t and 4x2+ 1= tan2 t+ 1= sec2. (4x2+ 1)2= sec4 t and 2dx= sec2 t dt. Your integral becomes\n    [tex]\\int\\frac{8dx}{(4x^2+ 1)^2}= \\int \\frac{4dt}{sec^2 t}= 4\\int cos^2 t dt[/itex]\n    That should be easy.\n\nHave something to add?\n\nSimilar Discussions: Trigonometric substitution"}
{"text": "Retrieved from http://math.stackexchange.com/questions/370862/find-a-best-fit-line-through-a-point-cloud-that-goes-through-a-specific-point\nText:\nTake the 2-minute tour \u00d7\n\nI'm not a mathematician so I hope I ask this question properly; I apologize for anyone who is annoyed with how I ask it (I will try my best to be precise).\n\nSay I have a point cloud in $\\Re^3$. I wish to fit a line through to this point cloud. However - and this is the kicker - I wish to force the line through a specified point in the point cloud; that is, I wish to find a vector through a point I specify which minimizes the distance squared from all the points in the cloud to the line spanned by the vector. Does this make sense?\n\nIf I were explaining this to a non-mathematician (like me), I would say I want to \"anchor\" a line on one of the points and then best fit the line from there.\n\nI understand the notion of ordinary least squares, but this particular spin on the problem doesn't make sense to me.\n\nThanks in advance, Ben\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\nThis notion makes sense. You still have two degrees of freedom for the line, which can be two angles we will call elevation $(E)$ and azimuth $(A)$. It is easiest if you move the origin to the anchor point by subtracting the coordinates of the anchor points from each of the points in the cloud. Then your line has parameterization $t(\\sin E \\cos A, \\sin E \\sin A, \\cos E)$ if you measure $E$ up from the $xy$ plane and $A$ counterclockwise from the $X$ axis. Now you can find the distances from each other point in the cloud to the line using this formula where the vector I gave is $\\bf n$, square them, and add them up. Now use a 2D function minimizer on $A,E$. Depending on the points, there may be local minima to fool you.\n\nshare|improve this answer\nThanks! I will try this out and post the results here for the sake of posterity. \u2013\u00a0 user74039 Apr 23 '13 at 22:52\nLike ordinary least squares, there are no \"local\" minima distinct from the global minimum (though in degenerate cases the location of the global minimum may not be unique). Differentiating the sum of squares \"errors\" with respective to the unknown parameters gives a (homogeneous) linear system to solve. \u2013\u00a0 hardmath Apr 26 '13 at 0:27\nadd comment\n\nRoss Millikan's solution will work. To get the exact answer, probably faster, you can modify a solution for finding the 3D line of best fit (without an anchor point). The way that works is you compute the covariance matrix of the point cloud and the line of best fit is the line through the centroid in the direction of the eigenvector associated with the largest eigenvalue.\n\nTo modify this solution for the current problem, you can do the same thing, only when you're computing the covariance matrix, you subtract the anchor point from each point in the point cloud, rather than subtracting the centroid.\n\nshare|improve this answer\nadd comment\n\nThe least squares fit of a line/plane/etc. with an additional constraint of passing through a specified point is usually reduced to the case where that point is the origin (subtract the specified point from all data and fit a linear homogenous function). In this connection such model fitting is called \"regression through the origin\" (RTO) to quickly distinguish it from ordinary least squares (OLS).\n\nSome references and discussions are given in Answers to this previous Question.\n\nNote that the number of parameters for a line and a plane surface in 3D are equal, but there is a difference in what the nearest distance to the line or the plane is. Passing through the origin makes the fitted model a subspace, so the nearest distance is given by (subtracting) the orthogonal projection of each data point onto the subspace.\n\nLike ordinary least squares one gets a system of linear equations to solve for the unknown parameters, but the system is homogeneous. One is therefore solving for a nontrivial solution to a problem like $Au = 0$, and since there are only three unknowns speed of solution is not an issue.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/309879/showing-representation-numbers-are-at-most-on-the-order-of-polynomial-growth/311972\nText:\nTake the 2-minute tour \u00d7\n\nIf $Q$ is the sum of squares quadratic form $\\sum_1^n x_i^2$ over some lattice, then $r_Q(m)$, the number of representations of an integer $m$ by $Q$ (order/sign matter) is sometimes given in a nice formula, as in the case with Jacobi's formula in the case of $n=4$. Can we say something moderate about how $r_Q$ grows? It seems like it shouldn't grow faster than polynomially, but I am struggling to see why in a rigorous way. Since $\\sum_1^n x_i^2=m$ is the equation of a sphere (or I suppose an ellipsoid if we transform our lattice to $Z^n$ under a change of variable?), we should be able to bound such solutions by some function of the surface area since there should be some small upper bound for the proportion of lattice points over the surface area and the surface area is a polynomial function of the radius.\n\nI would like to make the argument a bit more rigorous, any advice?\n\nEdit: To be clear, I'm interested in how $r_Q(m)$ grows with $m$.\n\nshare|improve this question\nAre you interested in how $r_Q$ grows with $r$ or with $Q$? \u2013\u00a0 Ross Millikan Feb 21 '13 at 5:22\n$r_Q$ is a function. I'm interested in how it grows with $n$. \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:25\nOK, I was thinking of it as a function of $r$ or $Q$, but a function of $n$ is a fine question. It will top out at $n=Q$ unless you count different orders as different. Do you? \u2013\u00a0 Ross Millikan Feb 21 '13 at 5:31\nI should have written \"grows with $m$\", rather than $n$ (assume $n$ is fixed, fixed by $Q$ in fact).Different orders are the same, though signs matter. \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:34\nSorry, scratch that. Order DOES matter. The point is that we are looking at the distinct number of points on a lattice that map to $m$ under $r_Q$. \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:46\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nFor each solution to $\\sum_{i=1}^n x_i^2 = m$, you can place an open cube of side-length $1$ centered on that solution. Doing so, you obtain a family of disjoint open cubes covering the solutions, with each open cube having volume $1$. So your next move should be to bound the volume that you can possibly cover with those cubes, polynomially in $m$.\n\nSince every cube centered on $x$ is included in the open ball of radius $\\sqrt n/2$ centered on $x$ (using the euclidean metric), and $d(0,x) = \\sqrt m$ whenever $x$ is a representation of $m$, you obtain with the triangular inequality that all those cubes are included in $\\{y \\in \\Bbb R^n, \\sqrt m - \\sqrt n/2 < d(0,y) < \\sqrt m + \\sqrt n/2 \\} = B(0,\\sqrt m + \\sqrt n/2) - B(0,\\sqrt m - \\sqrt n/2)$\n\nSince the volume of a ball of radius $R$ is $k_nR^n$ for some constant $k_n$, you get that the volume of this domain is $k_n((\\sqrt m + \\sqrt n/2)^n - (\\sqrt m - \\sqrt n/2)^n) \\sim k_n(n^{3/2}m^{(n-1)/2}) $ (you can also argue intuitively that this should behave like $\\sqrt n$ times the area of the sphere of radius $\\sqrt m$, and again find a volume bounded by a $K_n m^{(n-1)/2}$).\n\nSince the number of representations of $m$ is bounded by the volume of this domain, and since this volume is a $O(m^{(n-1)/2})$, that number $r_n(m)$ grows polynomially at worst.\n\nYou can also use this reasoning with volumes to show that the degree $(m-1)/2$ is the smallest possible for this kind of result : if it wasn't, then putting cubes around every solution of $\\sum x_i < R^2$ would tell you that the volume of the sphere of radius $R$ would grow smaller than $R^n$, which is absurd.\n\nshare|improve this answer\nadd comment\n\nIf order and signs matter, I strongly suspect that for large $n$ it will be dominated by sums of $\\pm 1$ and $0$. We have to select $Q$ spots for a non-zero and $2^Q$ signs, so we have ${n \\choose Q}2^Q$ expressions. There will be a few more with summands greater than $1$, but for large $n$ they will be insignificant. This is exponential in $n$ and $Q$.\n\nshare|improve this answer\nSo you don't like my ellipsoid argument? \u2013\u00a0 Eric Gregor Feb 21 '13 at 5:58\n@EricGregor: not if some of the $x_i$ can be zero. If not, when $n \\gt Q$there are no representations. That is a small growth rate. \u2013\u00a0 Ross Millikan Feb 21 '13 at 6:00\nRoss, I think the interest is in fixing $n$ and asking about large $m$. \u2013\u00a0 Gerry Myerson Feb 21 '13 at 6:03\n@GerryMyerson: for fixed $n$ and large $m$ the surface area argument is a good one. There can't be more than $O(m^2)$ lattice points on the ellipsoid. Most of them won't have a representation with exactly $n$ terms. A few will have more than one, like $25^2=7^2+24^2=15^2+20^2$ but it seems likely not enough to matter. \u2013\u00a0 Ross Millikan Feb 21 '13 at 6:11\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/269478/non-constant-bounded-holomorphic-function-on-some-open-set\nText:\nTake the 2-minute tour \u00d7\n\nthis is an exercise I came across in Rudin's \"Real and complex analysis\" Chapter 16.\n\nSuppose $\\Omega$ is the complement set of $E$ in $\\mathbb{C}$, where $E$ is a compact set with positive Lebesgue measure in the real line.\n\nDoes there exist a non-constant bounded holomorphic function on $\\Omega$?\n\nEspecially, do this for $\\Omega=[-1,1]$.\n\nSome observations:\n\nSuppose there exists such function $f$, then WLOG, we may assume $f$ has no zeros points in $\\Omega$ by adding a large enough positive constant, then, $\\Omega$ is simply-connected implies $\\int_{\\gamma}fdz=0$, for any closed curve $\\gamma\\subset \\Omega$, how to deduce any contradiction?\n\nshare|improve this question\nWhy do you say that $\\Omega$ is simply connected? // You are going in the wrong direction: such a function exists on any domain with complement of positive measure on the line. Think of the Cauchy integral formula. // In the case of $E=[-1,1]$ (you have a typo there in the question) it's possible to find it explicitly using conformal maps. \u2013\u00a0 user53153 Jan 3 '13 at 0:16\n@Pavel M, the function constructed using Cauchy integral formula is not bounded on $\\Omega$, this is the first several questions before this one on the book, you can check it. That is why Rudin post this question on the book. \u2013\u00a0 ougao Jan 3 '13 at 0:23\nMaybe it depends on how you use the Cauchy integral. Anyway, here's an example for $E=[-1,1]$: the conformal map $g(z)=\\frac12(z+z^{-1})$ sends the unit disk onto the complement of $E$. Therefore, its inverse $f=g^{-1}$ is bounded by $1$ on the complement of $E$. // At least this shows that your attempt to find a contradiction could not work. \u2013\u00a0 user53153 Jan 3 '13 at 0:37\nYou are correct, I double checked the problem, and found I have made a silly typo, in fact, I want to know whether there exists a non-constant bounded holomorphic(not just analytic) function, sorry for the confusion. \u2013\u00a0 ougao Jan 3 '13 at 1:06\nDoes not change anything in my replies. I assumed you wanted a holomorphic function from the beginning. \u2013\u00a0 user53153 Jan 3 '13 at 1:34\nshow 2 more comments\n\n1 Answer\n\nup vote 6 down vote accepted\n\nReading Exercise 8 of Chapter 16, I imagine Rudin interrogating the reader.\n\nLet $E\\subset\\mathbb R$ be a compact set of positive measure, let $\\Omega=\\mathbb C\\setminus E$, and define $f(z)=\\int_E \\frac{dt}{t-z}$. Now answer me!\na) Is $f$ constant?\nb) Can $f$ be extended to an entire function?\nc) Does $zf(z)$ have a limit at $\\infty$, and if so, what is it?\nd) Is $\\sqrt{f}$ holomorphic in $\\Omega$?\ne) Is $\\operatorname{Re}f$ bounded in $\\Omega$? (If yes, give a bound)\nf) Is $\\operatorname{Im}f$ bounded in $\\Omega$? (If yes, give a bound)\ng) What is $\\int_\\gamma f(z)\\,dz$ if $\\gamma$ is a positively oriented loop around $E$?\nh) Does there exist a nonconstant bounded holomorphic function on $\\Omega$?\n\nPart h) appears to come out of the blue, especially since $f$ is not bounded: we found that in part (e). But it is part (f) that's relevant here: $\\operatorname{Im}f$ is indeed bounded in $\\Omega$ (Hint: write it as a real integral, notice that the integrand has constant sign, extend the region of integration to $\\mathbb R$, and evaluate directly). Therefore, $f$ maps $\\Omega$ to a horizontal strip. It's a standard exercise to map this strip onto a disk by some conformal map $g$, thus obtaining a bounded function $g\\circ f$.\n\nshare|improve this answer\nthanks, I should be more careful to deal with part (f). \u2013\u00a0 ougao Jan 3 '13 at 14:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/26771/what-is-the-expected-number-of-steps-in-the-following-process\nText:\nTake the 2-minute tour \u00d7\n\nWe have $n$ boxes. And initially there are $x_1, x_2, x_3, \\ldots, x_n$ marbles in each box. We randomly (with equal probabilities) select one of the boxes. We take one marble from it and we put it into another (different from the origin) box chosen randomly (with equal probabilities). We continue this process until one of the boxes become empty. How many operations we do on average?\n\nIt is not a homework. I don't know whether a closed form solution exists. My current results are:\n\n\\begin{align}{} x_1 x_2 & \\text{ for } n=2\\\\ \\frac{3x_1 x_2 x_3}{x_1 + x_2 + x_3} & \\text{ for } n=3 \\end{align}\n\nI have crossposted in artofproblemsolving. This problem is related and maybe (or not) useful.\n\nUpdate2: As i learned: this problem has been studied before. As usual :) It seems very hard even for $n=4$. No explicit solution is known, only asymptotics for the case $f(x,x,x,x)$. Nevertheless the solution is much much more easier if we change slightly the problem. For example.\n\nBig thanks to Viktor for pointing the reference!\n\nshare|improve this question\nLooking at what you have for $n=2$ and $n=3$, my guess would be $\\frac{\\binom{n}{2}}{\\displaystyle \\sum_{i,j,i \\neq j}\\frac{1}{x_i x_j}}$ \u2013\u00a0 user17762 Mar 13 '11 at 20:33\nIt's beautiful but it seems that it does not pass the following test for $n=4$: $f(x,x,x,x)=f(x-1,x+1,x,x)+1$. \u2013\u00a0 Roah Mar 13 '11 at 21:21\n@Tomek The case $n=2$ is the usual one dimensional gambler's ruin problem. It is true, but not intuitively obvious, that for a symmetric random walk the expected number of steps needed to hit 0 is infinite, even starting at 1. Unless we hit 0 very soon, the random walk wanders far into the positives and then takes a long (but finite!) number of steps to reach 0. \u2013\u00a0 Byron Schmuland Mar 15 '11 at 0:22\nThat is N-player ruin problem. See: Y.Swan - A Matrix-Analytic Approach to the N-Player Ruin Problem \u2013\u00a0 Viktor Mar 15 '11 at 23:23\nThere is a paper arguing for why this is unlikely to have any closed form solution for N>3. projecteuclid.org/\u2026 \u2013\u00a0 user1708 Mar 18 '11 at 7:42\n\n1 Answer 1\n\nHere are some results for very small numbers, when there are $n$ variables: $$ \\begin{align*} f(1,1,1,\\ldots,1) &= 1, \\\\ f(2,1,1,\\ldots,1) &= \\frac{n}{n-1}, \\\\ f(3,1,1,\\ldots,1) &= \\frac{n^3-2n^2+3n}{n^3-3n^2+4n-2} = \\frac{n}{n-1} \\cdot \\frac{n^2-2n+3}{n^2-2n+2}, \\\\ f(2,2,1,\\ldots,1) &= \\frac{n^3-n^2+2n}{n^3-3n^2+4n-2} = \\frac{n}{n-1} \\cdot \\frac{n^2-n+2}{n^2-2n+2}. \\end{align*} $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/25505/what-is-int-0-12-dx-dy-mathcalp-frac-logxx-y?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nWhat is the value of $$\\int_{[0,1]^2} \\!\\!\\!dx\\,dy\\,\\mathcal{P} \\frac{\\log(x)}{x-y},$$ where $\\mathcal{P}$ denotes Cauchy's principal value. I solved this once for a homework, but I can neither remember the answer nor reproduce it right now... (bad memory)\n\nAny help or comment is highly welcome.\n\nshare|improve this question\nwhat do you mean by principal value? you have infinite values along $y=x$ and $\\{0\\}\\times[0,1]$. how are you approaching those? \u2013\u00a0 yoyo Mar 7 '11 at 17:16\nThe logarithmic singularity at ${0}\\times [0,1]$ seems to be integrable. So only the pole at $x=y$ poses problems. Cauchy's princial value (en.wikipedia.org/wiki/Cauchy_principal_value) denotes the limit when this singularity is approached symetrically... \u2013\u00a0 Fabian Mar 7 '11 at 17:32\nMathematica tells me that the result is $\\pi^2/6$ [looks like $\\zeta(2)$]. Any thoughts why (or if) this is correct? \u2013\u00a0 Fabian Mar 7 '11 at 17:34\nCan you not take the Hilbert transform of $1_{[0,1]}$ and then compute the (principal value) integral of $\\log(x)$ times the result of that? \u2013\u00a0 Jonas Teuwen Mar 7 '11 at 21:30\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $f(x,y)=\\frac{\\log x}{x-y}$. Since the principal value does not seem well-defined here, let's integrate $f(x,y)+f(y,x)= \\frac{\\log (x/y)}{x-y}$ (which is positive) on the triangle defined by $0<y<x<1$. Now $\\int_0^x \\frac{\\log (x/y)}{x-y} dy = -\\int_0^1 \\frac{\\log u}{1-u} du$ (change of variable $y=xu$), which does not depend on $x$, and so this is equal to the first integral (integrating for $x$ between $0$ and $1$).\n\nNow $-\\int_0^{1-\\epsilon} \\frac{\\log u}{1-u} du = \\int_0^{1-\\epsilon} \\sum_{ n \\geq 1} \\frac{u^{n-1}}{n} du = \\sum_{n \\geq 1} \\frac{(1-\\epsilon)^n}{n^2}$ and letting $\\epsilon$ go to $0$ gives $\\zeta(2)=\\frac{\\pi^2}{6}$.\n\nshare|improve this answer\nWhy you think the principal value is not well defined? \u2013\u00a0 Fabian Mar 9 '11 at 18:22\nThe examples at the end of the Wikipedia page illustrate this fact, for a given integral you can get different values if you choose your epsilons differently. But most of the time if you make \"reasonable\" choices the result is the same: for example in your case if we integrate on a closed symetric (with respect to the diagonal) domain not containing the diagonal and if this domain \"converges\" to the whole of $[0,1]^2$. If we integrate wrt $y$ first, excluding $[x-\\epsilon,x+\\epsilon]$ (then $\\epsilon \\rightarrow 0$) we still find $\\zeta(2)$. But other choices would give different values. \u2013\u00a0 Plop Mar 9 '11 at 19:12\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/16583/a-trigonometry-problem?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet x = pi/(2k+1), for k>0. Prove that\ncosxcos2xcos3x...coskx = (1/2)^k\n\nI've confirmed this numerically for n from 1 to 30. I'm finding it surprisingly difficult using standard trig formula manipulation. Even for the case k = 2, I needed to actually work out cosx by other methods to get the result.\n\nPlease let me know if you have a neat proof.\n\nshare|improve this question\nMaybe such puzzles are better posted in www.artofproblemsolving.com \u2013\u00a0 Gerald Edgar Feb 27 '10 at 11:53\n\n3 Answers 3\n\nup vote 13 down vote accepted\n\nLet $S(x)=\\prod_{j=1}^k \\text{sin}(jx)$ and $C(x)=\\prod_{j=1}^k \\text{cos}(jx)$. Let x = $\\frac{\\pi}{2k+1}$. Then $S(2x) = S(x)$ (from $\\text{sin}(\\pi-x)=\\text{sin}(x)$), and $S(2x)=2^kS(x)C(x)$ (from $\\text{sin}(2x)=2\\text{sin}(x)\\text{cos}(x)$), from which the result follows.\n\n\nshare|improve this answer\nThanks Steve. Very neat ! \u2013\u00a0 Cosmonut Feb 27 '10 at 12:03\n\nHint: multiply by sin(x)\n\nshare|improve this answer\n\nThe standard way of doing problems like these is to look at the coefficients of the Chebyshev polynomials. The polynomial $T_n$ of degree $n$ such that $T_n(2 \\cos \\theta) = 2 \\cos n \\theta$ has leading term $1$, and we want to compute something like the fourth root of the product of the roots of $T_{2k+1}(x)^2 = 4$. Vieta's formulas and some reflection identities should handle it from here.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/question-about-ellipse.62405/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nQuestion about Ellipse\n\n  1. Feb 3, 2005 #1\n\n    Here is a problem in coordinate geometry, in particular about the ellipse.\n\n    A point moves such that the sum of the squares of its distances from two intersecting straight lines is constant. Prove that its locus is an ellipse and find the eccentricity in terms of the angle between the straight lines.\n\n    My solution:\n\n    Without loss of generality we may assume the two straight lines to be [itex]y = 0[/itex] and [itex]y = mx[/itex] where [itex]m = \\tan\\phi[/itex] ([itex]\\phi[/itex] is the angle between the lines). Their point of intersection is thus the origin O(0,0).\n\n    Let the point whose locus is to be found be [itex]P(\\alpha,\\beta)[/itex]. The constraint on P is then,\n\n    [tex]\\beta^2 + \\frac{(m\\alpha - \\beta)^2}{m^2+1} = k^2 [/tex]\n\n    where k is some constant ([itex]k\\epsilonR[/itex])\n\n    This after some rearranging and replacing [itex](\\alpha,\\beta)[/itex] with with general coordinates [itex](x,y)[/itex] yields\n    [itex]m^2x^2 - 2mxy + y^2(m^2+2) - k^2(1+m^2) = 0[/itex]\n    which when compared with the general second degree equation,\n    [itex]Ax^2 + 2Hxy + By^2 + 2gx + 2fy + c = 0 [/itex]\n    does turn out to be an ellipse.\n\n    However it is not in the standard form, so finding its eccentricity is not as easy. Now I understand that by rotating the coordinate axes we can bring the equation into such a form by a suitable choice of the rotation angle which causes the cross term (H) to disappear. However, I want to know if there is some other way out to find the eccentricity (or more generally to do this problem).\n\n    I would be grateful if someone could offer some ideas.\n\n    Thanks and cheers\n  2. jcsd\n  3. Feb 3, 2005 #2\n    After posting this, I realized this probably isn't the right place for this post. For the moderator(s): if you think, could you please shift it to the right place. Sorry for the inconvenience...\n  4. Feb 5, 2005 #3\n    Someone please help!!\n  5. Feb 5, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    Dearly Missed\n\n    What's wrong with writing it in standard form?? :confused:\n  6. Feb 5, 2005 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I don't see any other way to extract the excentricity,other than knowing the semiaxes...You can do that simply applying the theory of conics and the set of linear transformations which bring the conic to a known form,in this case an ellipse.\n\n  7. Feb 6, 2005 #6\n    Okay thanks for your replies. Suppose that I live in a very weird world and I'm supposed to show that I can do this \"smartly\" but not in a lengthy way. How would I do it? :biggrin:\n\n    I know I can rotate the axes and do what I've said I can in the first post to get it in the standard form. But I was wondering if there's some other way out. Anyway thanks...\n\n  8. Feb 7, 2005 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    How about if i told you that the equation:\n    [tex] m^{2}x^{2}-2mxy+y^{2}(m^{2}+2)-k^{2}(m^{2}+1) [/tex](1)\n\n    is the EQUATION OF A CIRCLE...\n\n    The equation (1) can be written:\n    [tex](mx-y)^{2}+[y\\sqrt{m^{2}+1}]^{2} =[k\\sqrt{m^{2}+1}]^{2} [/tex] (2)\n\n    and making the rotation & the notation:\n    [tex] x'=:mx-y [/tex] (3)\n    [tex] y'=y\\sqrt{m^{2}+1} [/tex] (4)\n    [tex] R=:k\\sqrt{m^{2}+1} [/tex] (5)\n\n    is exactly the equation of a circle:\n    [tex] x'^{2}+y'^{2}=R^{2} [/tex] (6)\n\n    If this outcome is not correct,then it's your fault for providing an incorrect quadratic form... :wink:\n\n  9. Feb 8, 2005 #8\n    I do not know what you are trying to imply. The question and my working are before you. Do you believe the question is wrong?\n    Last edited: Feb 8, 2005\n  10. Feb 8, 2005 #9\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I don't know that.I've just shown you that the equation u came up with when substituting alpha & beta wiht x & y is the equation of a circle,and not of an ellipse.\n\n  11. Feb 8, 2005 #10\n    You could try assuming [itex]y = mx[/itex] and [itex]y = -mx[/itex] where [itex]m = \\tan\\phi/2[/itex]\n\n    This is squashing the coordinates, and so will transform a circle into an ellipse\n  12. Feb 8, 2005 #11\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Ups,you made me realize that what i had was not a genuine rotation and indeed i squashed \"y\" and so the initial ellipse became a circle... :frown:\n\n    I would have to stick to the initial advice,namely applying the theory of conics...\n\n  13. Feb 10, 2005 #12\n    Yes but the problem is to extract the eccentricity from the equation without reducing it to a standard form via rotation. However, as the problem stands now, I do not think there is any other method than to do it the brute force way. Thanks for your help though.\n\n\nHave something to add?\n\nSimilar Discussions: Question about Ellipse"}
{"text": "Retrieved from https://www.physicsforums.com/threads/exponential-function.272143/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nExponential function\n\n  1. Nov 15, 2008 #1\n    Its true that if you integrate an exponential function from some time t0 to infinity it will converge to a finite value.\n\n    However, is the same true if it is multiplied by say t, t^2, t^3,t^n.\n\n    i.e. t*exp(-t) for example.\n\n    the exp is decaying to zero faaster than t is, so it goes to zero in the limit. But there are functions that decay to zero but their integral is not finite because the rate of decay is not *fast enough*.\n\n    Would the integral of exp multiplied by any power of t ALWAYs converge to a finite number?\n  2. jcsd\n  3. Nov 15, 2008 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n\n    [tex]\\int_{t_0}^\\infty t^n e^{-t} dt[/tex]\n\n    is always finite. You can prove this by induction (hint: use integration by parts).\n\n    Here's an interesting factoid for you:\n\n    [tex]\\int_0^\\infty t^n e^{-t} dt = n!.[/tex]\n  4. Nov 15, 2008 #3\n    Yes, using an integration by parts to get an inductive argument. Integrating t*exp(-t) for example will get you\n\n    -te^{-t} + \\int_{t_0}^\\infty e^{-t} dt\n\n    The left summand will go to 0 and the right integral converges. That establishes that the indefinite integral of t*exp(-t) converges, then since the derivative t^2 is 2t you can establish it again with t^2 and so on (the left summand, t^n*exp(-t) will always go to 0 since t^n = o(e^t) for all n).\n\n    Edit: oops, morphism already answered.\n  5. Nov 15, 2008 #4\n    Also consider what happens when you integrate the power series.\n\n    t^n*exp(-t) is sufficiently nice that you should be able to interchange the sum and integral.\n\nHave something to add?\n\nSimilar Discussions: Exponential function\n  1. Exponential Functions (Replies: 6)\n\n  2. Exponential function (Replies: 4)\n\n  3. Exponential function (Replies: 7)\n\n  4. Exponential functions (Replies: 2)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/106353/why-does-sum-n-in-mathbbz-widehatfn-infty-gives-that-the-matchin\nText:\nTake the 2-minute tour \u00d7\n\nI'd really love to understand why does the fact that the series of the absolute Fourier coefficient converges ($\\sum_{n \\in \\mathbb{Z}}|\\widehat{f(n)}|<\\infty$) for a function $f$, leads to the fact that the whole Fourier series, $\\sum_{n \\in \\mathbb{Z}}\\widehat{f(n)}e^{inx}$, uniformly converges.\n\nThanks a lot.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nWe have $\\sup_{x\\in\\mathbb R}|\\widehat f(n)e^{inx}|=|\\widehat f(n)|$ so by Weierstrass M-test, the series $\\sum_{n\\in\\mathbb Z}\\widehat f(n)e^{inx}$ is normally convergent on the real line, hence uniformly convergent.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/321738/does-sum-n-3-infty-frac-1-log-n-log-logn-converge\nText:\nTake the 2-minute tour \u00d7\n\nDoes the following series converge:\n\n$$\\sum_{n=3}^\\infty \\frac {1}{(\\log n)^{\\log(\\log(n)}}$$\n\nI've tried all test I know... Any ideas ?\n\nshare|improve this question\nHave you tried $\\lim_{n\\to\\infty}n\\cdot u_n$? \u2013\u00a0 Babak S. Mar 5 '13 at 19:32\ncan this be done using cauchy's condensation test? \u2013\u00a0 MSEoris Mar 5 '13 at 19:52\nAndr\u00e9 Nicolas has already answered this question, but if you're interested in seeing some motivation for a slighly different approach, see this post. \u2013\u00a0 Dave L. Renfro Mar 6 '13 at 16:24\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nNote that $(\\log n)^{-\\operatorname{loglog} n}=e^{-(\\operatorname{loglog} n)^2}$, since $\\log n=e^{\\operatorname{loglog} n}$.\n\nFor large $n$, we have $(\\operatorname{loglog} n)^2\\lt \\log n$, so for large $n$ the $n$-th term is greater than $\\frac{1}{n}$.\n\nThe fact that $(\\operatorname{loglog} n)^2$ is eventually dominated by $\\log n$ is just the familiar fact that $e^x\\gt x^2$ for large enough $x$.\n\nRemark: In dealing with convergence of series, it is often better to ask oneself first: How fast are the terms approaching $0$? Looking instead for a test to use tends to distance us from the concrete reality of the series.\n\nshare|improve this answer\nInteresting philosophy in the remark, are there any specific schools of thought using similar views? \u2013\u00a0 Arjang Mar 5 '13 at 20:17\nThe remark was not really of a philosophical nature, though it could be interpreted as a tilt towards Platonism as opposed to Formalism. However, what was meant is that in problem-solving, concrete confrontation of the problem can be more effective than searching through the toolchest for a suitable tool. \u2013\u00a0 Andr\u00e9 Nicolas Mar 5 '13 at 20:23\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/129879/filling-in-a-rational-orthogonal-matrix-given-one-row?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nQuick version: given natural $n$ and a row of $n$ integers such that the sum of the squares is another square, call it $m^2.$ For $n=5,6,7$ is it always possible to fill in the rest of an $n$ by $n$ matrix of integers, call it $M,$ so that $M M^T = m^2 I? $ If so, $M/m$ is rational orthogonal.\n\nNotes: this is true for $n=1,2,3,4,8.$ 1 is trivial 2 uses complex numbers, 4 uses quaternions, 8 uses octonions. 3 uses quaternion stuff applied to ternary quadratic forms, papers of Jones and Pall mostly, the main one 1939. The naive adaptation of the Jones-Pall formalism to our $n=7$ does not work very well, see Octonions and the dance of the seven veils\n\nThis is false for $n = 9,17,25,33,\\ldots.$ Indeed, take any odd $n = k^2,$ let the first row have all entries $1,$ no second row is possible that is orthogonal to the given first row, consists of integers, and has the same length. Problem mod 2, insofar as the dot product of the two rows is odd, therefore nonzero. Actually, for any $n >1, \\; \\; \\; n \\equiv 1 \\pmod 8,$ one may specify any $n-3$ odd numbers, then find the final three (also odd) by Gauss three square theorem to get an odd square sum, no luck.\n\nAnyway, I did some computer checks, entirely successful for small entries for $n=5,6,7,$ and instinct tells me that it only gets easier with larger entries.\n\nSo, that is the short version, does this work for any first row of integral length (sum of squares is another square) in dimension $n=5,6,7?$\n\nshare|improve this question\nThat's nice, if you do a large number of edits, but they are all in a few minutes, it clumps them together and counts only one edit. \u2013\u00a0 Will Jagy May 6 '13 at 19:42\nIndeed. However, note that after a certain number of edits (maybe 8) the question automatically becomes CW, so be careful despite the clumping. \u2013\u00a0 Tony Huynh May 6 '13 at 19:51\n@Tony, yes, I pay attention to that. If I click in the middle, where it currently says \"edited 13 mins ago\" it shows me the revision list and the official edit count. So that is how I know when to start an answer of my own, for example. \u2013\u00a0 Will Jagy May 6 '13 at 19:54\nYou might be interested in weighing matrices. (I think that's the term.) I know Robert Craigen and others in combinatorial matrix theory have studied matrices with MM^T = wI. Also Will Orrick might know some people who can help. Gerhard \"Ask Me About Indirect References\" Paseman, 2013.05.06 \u2013\u00a0 Gerhard Paseman May 6 '13 at 20:03\n@Gerhard, I used to have a very nice bathroom scale, based on strain gauge. Later I dripped a bunch of water on it and it died. en.wikipedia.org/wiki/Weighing_matrix Will Orrick is an MO regular, not sure about the other name. It appears the important case for most people has entries $0,1,-1.$ \u2013\u00a0 Will Jagy May 6 '13 at 20:37\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nYes, it is possible to fill in. Your problem is a particular case of a completion problem and is treated in the following paper:\n\nHsia, J.S. Two theorems on integral matrices. Linear Multilinear Algebra 5, 257-264 (1978).\n\nshare|improve this answer\nThank you. I had that article at one point. \u2013\u00a0 Will Jagy May 8 '13 at 20:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/15162/hitting-times-for-an-n-dimensional-random-walk-on-a-lattice-with-strictly-posit?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nPlease consider a random walk on a finite N-dimensional lattice with vectors $(x_1, ..., x_N)$. We define the origin to be $(0, ..., 0)$ and the target to be at the point in the lattice furthest away from the origin - i.e. $(||x_1||, ..., ||x_N||)$ where $||x_k||$ is the integer length of the lattice in the $x_{k}$ dimension. Here, each step of the random walk is a uniformly distributed, strictly positive random integer in each of the N-dimensions with an upper-bound value defined by the requirement that one cannot exceed the dimensions of the lattice.\n\nIs there a nice method, aside from explicit path-counting, to derive the probability density for hitting times provided an arbitrary lattice as defined above?\n\nSome computational results: For the $N=1$ case I expected the target hitting time (defined as the number of steps to reach the target) to fit well with a logarithmic growth function of the form $A*ln(S)$ where A is a positive real number and $\"S\"$ is the number of integer steps one takes to reach the target from the origin. Running simulations (averaging 10,000 times) this yielded a decent fit with the value of $A$ ~ 1.146 for $||x|| = 100$, but $A$ decreases to ~1.095 for $||x|| = 1,000$ and decreased further ~1.069 for $||x||=10,000$.\n\nshare|improve this question\nThis sounds a lot like directed percolation. ;) \u2013\u00a0 Gjergji Zaimi Feb 13 '10 at 3:08\nHow are you choosing your random step sizes? \u2013\u00a0 Qiaochu Yuan Feb 13 '10 at 3:08\nLeonid, yes, that's exactly what I mean. One would generate a uniformly distributed random integer between '1' and the largest integer value that won't take you out of the lattice for each of the 'N' dimensions. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:24\nLeonid, I apologize, I misspoke. The overall step size must be non-zero, but movement in any subset of the dimensions may be zero for a step. I.e. one of the randomly generated integers must be at least one, but the remainder may be zero-valued. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:35\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAssuming you mean Leonid Kovalev's interpretation, the distribution of the hitting time in the $N = 1$ case is the same as the distribution of the number of cycles of a random permutation of $[n]$.\n\nTo be more specific, I'll change coordinates. Let $X_0 = (x_0^1, \\ldots, x_0^N) = (S, S, \\ldots, S)$. Let $X_1 = (x_1^1, \\ldots, x_1^N)$, where $x_1^j$ is chosen uniformly at random from $0, 1, \\ldots, x_0^j-1$. Define $X_2$ similarly in terms of $X_1$, and so on.\n\nThen the sequence $(x_0^1, x_1^1, x_2^1, x_3^1, \\ldots)$ are as follows:\n\n  \u2022 $x_0^1 = L$, of course.\n  \u2022 $x_1^1$ is uniformly distributed on $\\{ 0, \\ldots, S-1 \\}$.\n  \u2022 $x_2^1$ is uniformly distributed on $\\{ 0, \\ldots, x_1^1-1 \\}$.\n\nand so on... In particular the distribution of $x_1^1$ is the distribution of number of elements in a random permutation on $S$ elements which are {\\it not} in the cycle containing 1; In particular the distribution of $x_1^1$ is the distribution of number of elements in a random permutation on $S$ elements which are {\\it not} in any of the $k$ cycles with the smallest minima.\n\nSo the distribution of the smallest $k$ for which $x_k^1 = 0$ is exactly the distribution of the number of cycles of a random permutation of $\\{ 1, \\ldots, S \\}$; this is $1 + 1/2 + \\cdots + 1/S \\sim \\log S + \\gamma$, where $\\gamma = 0.577\\ldots$ is the Euler-Mascheroni constant.\n\nIn the higher-dimensional cases, the time to reach $(0, \\ldots, 0)$ is just the {\\it maximum} of the number of cycles of $N$ permutations chosen uniformly at random; this should still have expectation $\\log S$ plus a constant depending on $N$.\n\nshare|improve this answer\nThanks for your answer Michael. \u2013\u00a0 Rob Grey Feb 13 '10 at 3:39\nYou're welcome! It just happens that I spend way too much time thinking about random permutations. That being said, the original problem was a little underspecified, and I happened to make the interpretations that led to me being able to solve it. In your second comment I see you actually had a different interpretation in mind. I suspect the overall behavior is the same -- still logarithmic -- but it would be harder to prove because the $N$ dimensions are no longer independent. \u2013\u00a0 Michael Lugo Feb 13 '10 at 3:50\n\nWhile I like Michael Lugo's answer better, I thought I might as well put up the solution I sketched out for myself for the one-dimensional case:\n\nThe probability that the walker visits a particular point on the one-dimensional lattice can be expressed as $\\frac{1}{||x_k||-p}$ where $p$ is the distance between the lattice point and the origin. Therefore, we can express the probability that, during a given step, the walker visits the target lattice point (i.e. the lattice point furthest from the origin) as - $P(target)$ = $\\frac{(\\frac{1}{||x_k||-(||x_k||-1)})}{\\sum_{i=0}^{\\||x_k||-1}\\frac{1}{||x_k||-i}}$. $\\frac{1}{P(target)}$ should therefore provide the average hitting time for the one-dimensional walkers under the imposed conditions. Computationally this value approximates Michael Lugo's answer of $ln(||x_k||)+\\gamma$ within ~0.1 by $||x_k||$ = 5.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/203347/cutting-the-corners-of-a-cube\nText:\nTake the 2-minute tour \u00d7\n\nDo you know of any way to cut the corners of a cube by means of rotation assuming that the cube is centered in the origin of XoYZ?\n\nFor example if we have a square centered in the origin of XoY and we rotate this square 45 degrees the rotated square will cut all the corners of the original one with equal cuts. I do not know how to generelize this for higher dimensions.\n\nThanks, Bogdan.\n\nshare|improve this question\nWell, I guess rotating the cube 45 degrees along the x axis, 45 degress along the z axis, and 45 degrees along the x=y, z=0 axis should do the job. \u2013\u00a0 roman Sep 27 '12 at 9:02\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nA square has $2\\cdot2$ sides and $2^2$ vertices, but a three-dimensional cube $C$ has $2\\cdot3$ faces and $2^3$ vertices; so you can never cut off all vertices at the same time, using a rotated copy of $C$.\n\nYou can, however, do the following: When $C=[{-1},1]^3$ then consider for a suitable $\\epsilon>0$ the octahedron $$O:=\\bigl\\{(x,y,z)\\ \\bigm|\\ |x|+|y|+|z|\\leq 3-\\epsilon\\bigr\\}\\ .\\qquad(*)$$ This will cut off the eight vertices of $C$ allright. In addition, this idea can be generalized to $n$ dimensions, $n\\geq2$.\n\nThat $(*)$ describes an octahedron is seen as follows: The vertex $(1,1,1)$ in the first octant is cut off in a symmetric way with respect to the three axes by means of the condition $x+y+z\\leq 3-\\epsilon$. Writing $|x|+|y|+|z|\\leq3-\\epsilon$ instead of $x+y+z\\leq 3-\\epsilon$ makes the resulting solid symmetric with respect to all three reflections $x\\mapsto -x$, $y\\mapsto -y$, $z\\mapsto -z$. In $n$ dimensions the corresponding condition would read as $|x_1|+|x_2|+\\ldots+|x_n|\\leq n-\\epsilon$.\n\nshare|improve this answer\nThe generalization can be:|x1|+|x2|+ ... |xn|\u2264n\u2212\u03f5 ? \u2013\u00a0 Bogdan Sep 27 '12 at 10:35\n@Bogdan: See my edit. \u2013\u00a0 Christian Blatter Sep 27 '12 at 11:11\nThank you for your answer. I am looking at the dual polyhedron from the linear programming theory point of view. The cube is a set of inequalities 0<=x<=1, 0<=y<=1, 0<=z<=1. This is something like A * [x, y, z]' <= b. I would like to know if the dual polyhedron can also be expressed in a similar form. \u2013\u00a0 Bogdan Sep 27 '12 at 11:19\n\nYou can cut the corners of a cube by another concentric and congruent cube: taking it in random orientation, it will in most cases not contain any of the corners, thereby \"cutting them all off\". But the corners will never be cut off regularly in this case for a simple reason: the cutting is done by the faces of a cube of which there are $6$, but there are $8$ corners to cut, so necessarily some distinct corners will be cut off by the same face (which will cut off the whole edge between them as well).\n\nYou can cut off the corners of a cube regularly using an octahedron though. In general you need a dual polytope; the dual of a square happens to be a square. The same happens for any regular $n$-gon in the plane, and for the tetrahedron in space, but not for any other (regular) solids.\n\nshare|improve this answer\nA cube can be described by linear inequalities of the form: 0<=x<=1, 0<=y<=1, 0<=z<=1. Do you know of any transformation which takes this inequalities and gives the equations of the dual polyhedron? \u2013\u00a0 Bogdan Sep 27 '12 at 10:43\n@Bogdan: You cannot obtain equations for the dual polyhedron directly from those of the polyhedron, as again their numbers do not match ($6$ for the cube, $8$ for the octahedron). The equations for the dual polyhedron come from the vertices of the original polyhedron, and vice versa. \u2013\u00a0 Marc van Leeuwen Sep 27 '12 at 11:19\nThanks! ... you are right! \u2013\u00a0 Bogdan Sep 27 '12 at 13:44\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/152021/solutions-of-an-integral-equation\nText:\nTake the 2-minute tour \u00d7\n\nGiven the integral equation: $$\\sqrt{f(x)}\\int_{0}^{x}f(\\tau)d\\tau=g(x)$$ with g(x) known function, in what cases and how is it possible to solve it?\n\n\nshare|improve this question\nIf $g(x)=k_1x^\\beta$ then the solution has a simple form $f(x)=\\sqrt{(\\alpha+1)k_1} x^\\alpha$ being $\\alpha=\\frac{2}{3}(\\beta-1)$ with $\\beta\\ne 1$. \u2013\u00a0 Jon May 31 '12 at 14:08\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nSquare both sides of the equation : $$F^'(x) \\ (F(x))^2=(g(x))^2$$ with $F(x) = \\int_{0}^{x}f(\\tau)d\\tau $.\nNow by integration between 0 and t : $$\\frac{(F(t))^3}{3} = \\int_{0}^{t} (g(x))^2 dx$$ F(t) can now be expressed : $$F(t) =\\sqrt[3]{3} \\ \\left( \\int_{0}^{t} (g(x))^2 dx \\right)^{1/3}$$ since $F'(t)=f(t)$, by derivation we obtain : $$f(t) = \\sqrt[3]{3} \\ (g(t))^2 \\left(\\int_{0}^{t} (g(x))^2 dx \\right)^{-2/3}$$\n\nshare|improve this answer\n\nLet us assume that $g(x)$ is differentiable (in fact $g(x)$ should be also positive and monotonously increasing $f(x)$ has to be positive such that the square root is properly defined).\n\nTake a derivative of your equation and you obtain $$ f(x)^{3/2} + \\frac{g(x)\\, f'(x)}{2 f(x)} =g'(x). $$ Thus, you have reduced your equation to a differential equation with the initial condition $f(0) = g(0)$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/30071/efficient-approximation-of-a-matrix-and-its-inverse\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $ A $ is a real $ n\\times n $ matrix whose rows constitute an orthonormal basis of $ \\mathbb R^n $.\n\nInformal statement of question: Assume we want to approximate $ A $ by a rational matrix, such that each entry can be written efficiently (that is, has a small binary encoding), but we require also the inverse of the approximate matrix to have small representation. Is this possible?\n\nFormal statement of question: Let $ p(n) $ be some polynomial in $ n $. For a real number $ r $, we say that $ a/b $ is a polynomial approximation of $ r $, if $ a/b$ is a rational number (that is, $ a,b $ are integers) and both $ a $ and $ b $ are of size at most $p(n) $ (e.g., their binary representation is of logarithmic size in $ n $), such that $ |r-a/b|\\le 1/p(n) $.\n\nQuestion: Does there exist a rational matrix $ B$, such that $ B $ polynomially approximates $ A $ (that is, the entry $ B_{ij} $ in $ B $, is a polynomial approximation of the entry $ A_{ij} $ in $ A $, for all $ 1\\le i,j\\le n $), and such that $ B^{-1} $ is a rational matrix whose entries are all polynomially-bounded (that is, for any $ 1\\le i,j\\le n $, $ B^{-1}_{ij}=a/b$, where $ a,b $ are integers of size at most $ p(n) $) ?\n\nshare|improve this question\n\n2 Answers 2\n\nIn $\\mathbb{R}^3$, Milenkovic and Milenkovic give an alogrithm for efficiently approximating an orthogonal matrix by a rational orthogonal matrix. As lhf points out, the inverse of an orthogonal matrix is its transpose, so the inverse will also have short entries in this setting.\n\nRegarding $n>3$, here is a tentative thought, and a reference. I haven't put much effort into either :).\n\nLet $v=(v_1, v_2, \\ldots, v_n)$ be a nonzero vector. Define a linear operator $$s_v(u) := u - 2 \\frac{\\langle v,u \\rangle}{\\langle v,v \\rangle} v.$$ This is the orthogonal reflection that negates $v$. Note that, if $v \\in \\mathbb{Q}^n$, then the entries of the matrix $s_v$ are rational. This is true even if $v$ does not have norm $1$.\n\nNow, any rotation matrix can be written as a product of $\\leq n$ reflections: $R=\\prod_{i=1}^h s_{v_i}$ for some sequence of vectors $v_i$ in $\\mathbb{R}^n$. A potential algorithm, then, is to find such a factorization and then approximate each $v_i$ by a rational vector $w_i$ which is roughly parallel to it. (There are plenty of standard algorithms for rational approximation of a vector.) Then take $\\prod s_{w_i}$ as the approximation to $R$.\n\nI got this strategy from a paper of Eric Schmutz. Schmutz follows this strategy, but he forces his approximating vectors $w_i$ to lie on the unit sphere. As far as I can see, this is a waste of effort, since $s_v$ is orthogonal with rational entries even if $v$ is not on the unit sphere. However, Schmutz has exact bounds, which you may find useful.\n\nshare|improve this answer\nThanks, I'll have a look. Maybe they (or future citations of this paper) have some references for the general case of $ n $. \u2013\u00a0 Iddo Tzameret Jun 30 '10 at 18:09\nI haven't followed through on the links, so I don't know which method do they use, but my first reaction to \"rational orthogonal matrix\" is \"Cayley transform\". \u2013\u00a0 Victor Protsak Jul 1 '10 at 5:45\n\nIf A is orthogonal then its inverse is the transpose and so you only need to approximate A.\n\nshare|improve this answer\nBut your approximation may not be orthogonal, so its inverse may require a lot of bits to store. \u2013\u00a0 David Speyer Jun 30 '10 at 17:45\nYes, David is right. (lhf would be right too, if the orthogonalization algorithm (of e.g., Gram-Schmidt) would end up with a matrix in which the entries are polynomially-bounded by the entries in the original matrix. I can't see why this should be true though.) \u2013\u00a0 Iddo Tzameret Jun 30 '10 at 18:01\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/97811/pencil-of-lines-and-degree-d-curve-in-mathbbcp2/97816\nText:\nTake the 2-minute tour \u00d7\n\nQuestion. Let $C$ be a generic smooth curve of degree $d$ in $\\mathbb{CP}^2$, and let $P$ be an arbitrary point away from this curve. How many lines are there through point $P$ that are tangent, or have tangency of order $k$ (for any $k$ between 3 and $d$) with $C$? Probably this can be done for small $d$ using the equation for $C$, but I would like to find out if there is a formula for general $d$.\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nYou have some polynomial $f(x,y,z)$. A line through the point $(1:0:0)$ can be paramaterized by a map from $\\mathbb P^1: (u:v) \\to (u:av:bv)$ for some constant $a$ and $b$. $f$ restricts to a degree $d$ polynomial in $u$ and $v$. Since it has no roots where $v=0$, set $v=1$. You now have a univariate polynomial such that the $k$th coefficient is a degree $k$ polynomial in $a$ and $b$. The discriminant of this polynomial determines whether it has a double root, which is the same as if the line is tangent. The discriminant is a degree $d(d-1)$ polynomial in $a$ and $b$.\n\nThus, the generic number of roots is $d(d-1)$. This is similarly the generic number of tangent lines. The generic number of inflection points or higher is zero, as this would require a multiple root of the discriminant.\n\nTo check that there is not some extra constraint on the discriminant polynomial that forces a multiple root, we can just find an example that does not have a multiple root. If $f(x,y,z)=x^d+xy^{d-1}+z^d$, then $f(u)=u^d+ua^{d-1}+b^d$, whose discriminant, which is $a^{d^2-d}+b^{d^2-d}$ up to some constant factors, has no multiple roots.\n\nshare|improve this answer\n@Will thanks for your answer \u2013\u00a0 user23802 May 24 '12 at 6:13\nYou can also find the tangency points as intersections with the polar curve $\\partial f/\\partial x=0$. This is an alternative way to see that there are $d(d-1)$ such points. If the base point of the pencil is $[a:b:c]$, you need the polar to be $a \\partial f/\\partial x + b \\partial f/\\partial y +c \\partial f/\\partial z=0$. For non generic curves the amount by which $d(d-1)$ is bigger than the actual number can be controlled (depending on higher order tangencies and singularities). Look for \"Pl\u00fccker formulas\". \u2013\u00a0 quim May 24 '12 at 9:34\n\nLet $\\tilde\\pi:\\mathbb{PC}^2\\setminus\\{P\\}\\to\\mathbb{PC}$ be the projection from $P$, which restricts to a surjective morphism $\\pi:C\\to\\mathbb{PC}$ of degree $d$. You are asking for the number of points of ramification of this morphism with multiplicity, or more precisely the degree of the ramification divisor $R$. By Hurwitz' theorem, it can be computed as $$\\deg(R) = 2g(C)-2 - d(2g(\\mathbb{PC}) - 2)=2\\binom{d-1}{2} + 2(d-1) = d(d-1).$$\n\nshare|improve this answer\n@Jesko thanks for your answer. \u2013\u00a0 user23802 May 24 '12 at 6:15\nA technical note: There is of course no morphism from $\\mathbb {CP}^2$ to $\\mathbb {CP}$. You mean to say that $\\bar{\\pi}$ is a morphism from $\\mathbb {CP}^2-\\{P\\}$. \u2013\u00a0 Will Sawin May 24 '12 at 6:16\n@Will: Thanks, I corrected it. \u2013\u00a0 Jesko H\u00fcttenhain May 24 '12 at 6:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/283740/finding-the-first-odd-abundant-number-less-than-1000/291555\nText:\nTake the 2-minute tour \u00d7\n\nWe say about number $n $ abundant if the sum of the divisors except $n$ is bigger than the number $n$.For example : $12$ is abundant because the sum of divisors except $12$ is bigger than $12$ : $1+2+3+4+6=16>12$ .How to find the first odd abundant number less than $1000$\n\nshare|improve this question\n\"the first odd abundant number less than 1000\": that's a strange way of putting it! If the smallest abundant number is less than 1000, then that's your answer right there; and if it's not, then your question is like \"who is the present king of France?\" \u2013\u00a0 TonyK Jan 21 '13 at 20:54\n@TonyK The smallest abundant number. \u2013\u00a0 sen Jan 21 '13 at 20:57\n\n3 Answers 3\n\nWe will take the problem to be finding the smallest abundant number, then will confirm that it is less than $1000.$ For a prime power $p^e$, the sum of divisors is $\\sum_{i=1}^e p^i=\\frac{p^{e+1}-1}{p-1}$. The sum of divisors function is multiplicative, so if $n=\\prod_i p_i^{e_i}$, the sum of divisors of $n, \\sigma(n) = \\prod_i \\frac{p_i^{e_i+1}-1}{p_i-1}$. We need $\\frac {\\sigma(n)}n =\\prod_i \\frac{p_i^{e_i+1}-1}{p_i^{e_i}(p_i-1)}=\\prod_i 1+\\frac {p_i^{e_i}-1}{p_i^{e_i}(p_i-1)}\\gt 2$\n\nIf we make a table of $\\frac{p_i^{e_i+1}-1}{p_i^{e_i}(p_i-1)}$ we get\n\n$$\\begin {array}&&3&5&7&11\\\\0&1&1&1&1\\\\ 1&1.333333&1.2&1.142857&1.090909\\\\ 2&1.444444&1.24&1.163265&1.099174\\\\ 3&1.481481&1.248&1.166181&1.099925\\\\ 4&1.493827&1.2496&1.166597&1.099993\\\\ 5&1.497942&1.24992&1.166657&1.099999\\\\ 6&1.499314&1.249984&1.166665&1.1\\\\ \\end{array}$$\n\nwhere the column is the prime and the row is the exponent. We want to find the set of entries that multiply to more than $2$ with the smallest product of prime powers. This makes us think that what as we increase the power of each prime, what we get is the difference of the log of the next entry and the current entry and what we pay is the log of the prime. So we make a new table that way\n\n$$\\begin{array} &&3&5&7&11\\\\ 1&0.26186&0.113283&0.068622&0.036287\\\\ 2&0.072858&0.020373&0.009096&0.003147\\\\ 3&0.023045&0.003996&0.001286&0.000285\\\\ 4&0.007554&0.000796&0.000184&2.59E-05\\\\ 5&0.002504&0.000159&2.62E-05&2.35E-06\\\\ 6&0.000833&3.18E-05&3.74E-06&2.14E-07\\\\ \\end{array}$$\n\nUsing the greedy algorithm, the priority order of factors is $3,5,3,7,11,3,5\\ldots$ leading to a series of candidates $3,15,45,315,3465$, but we see we can sneak another factor of $3$ onto $315$ giving $945$. The way the candidates stack up:\n\n$$\\begin{array} n&\\sigma(n)&\\frac {\\sigma(n)}n\\\\ 3&4&1.333333\\\\ 15&24&1.6\\\\ 45&78&1.733333\\\\ 315&624&1.980952\\\\ 945&1920&2.031746\\\\ 3465&7488&2.161039 \\end {array}$$\n\nand $945$ is the first to exceed $2$. We get more \"bang for the buck\" with $3465$, but $945$ is good enough.\n\nshare|improve this answer\n\nThe oeis is a good source for sequences like these.\n\nFor example, your answer can be found here as linked from here.\n\nIn particular, the answer is $945$.\n\nIf you want to check this particular example, you could do it as so in Wolfram|Alpha.\n\nshare|improve this answer\n\nIf you're familiar with a bit of R-programming, then you could try this script:\n\nn <- 1000\no <- sapply(seq(3, n, by=2), function(x) {\n    t <- sapply(1:x-1, function(y) {\n        ifelse(x %% y == 0, y, 0)\n    t <- sum(t, na.rm = TRUE)\ndf <- data.frame(num = seq(3, n, by = 2), sum_div = o)\n> df[with(df, sum_div > num), ]\n\n#     num sum_div\n# 472 945     975\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/11818/probability-of-random-number-repeating\nText:\nTake the 2-minute tour \u00d7\n\nIn the situation of having a high entropy random number generator, that generates numbers in the range of 0 and 2,147,000,000.\n\nIf i have a list of 1,000,000 integer values, what are the chances that a random number will already be on my list?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nOne minus the probability that they are all different: $$1 - \\left( 1- \\frac{1}{n} \\right) \\left( 1- \\frac{2}{n} \\right) \\cdots \\left( 1- \\frac{k-1}{n} \\right),$$ where $n=2,147,000,001$ (since you include $0$) and $k=1,000,000.$\n\nSee the birthday problem for more information.\n\nshare|improve this answer\n\nIf the list is drawn with replacement, the chance that a given number (the new draw) is not in it is $$(1-\\frac{1}{2147000001})^{1000000}$$ The birthday problem only comes up if you ask for the chance of a collision anywhere in the 1000001 numbers.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/321150/find-a-nonzero-3-times-3-matrix-with-all-0-eigenvalues-is-there-a-systematic/321154\nText:\nTake the 2-minute tour \u00d7\n\nAfter playing around for a bit I found one:\n\n\nbut I couldn't find a good systematic way.\n\nshare|improve this question\nIt is not hard to come up with non-zero nilpotent matrices. \u2013\u00a0 Andr\u00e9 Nicolas Mar 5 '13 at 6:12\nI get lots of junk mail about solving nilpotency problems... \u2013\u00a0 copper.hat Mar 5 '13 at 6:13\n@Andr\u00e9Nicolas thank you for telling me what I was looking for! That+Wikipedia was a great help. \u2013\u00a0 crf Mar 6 '13 at 4:31\n\n3 Answers 3\n\nup vote 1 down vote accepted\n\nAll strictly triangular matrices are nilpotent (see here) & hence can have $0$ as the only eigenvalue.\n\nshare|improve this answer\n\n\n$$A = \\begin{bmatrix} 0&a&c\\\\ 0&0&b\\\\ 0&0&0 \\end{bmatrix} $$\n\nwith $ab \\ne 0$ and $c$ arbitrary.\n\nSo the only eigenvalue is $\\lambda_{1,2,3} = 0$, with multiplicity three.\n\nUpdate: from CH's comment, the restriction on $a, b$ is not needed.\n\nshare|improve this answer\nWhy do you care about the values of $a,b$? \u2013\u00a0 copper.hat Mar 5 '13 at 6:15\n@copper.hat: You are correct, I don't need that restriction. Since $ab \\ne 0$, the \ufb01rst two rows are not proportional and their cross-product is $(ab, 0, 0)$, so the eigenspace, $E(0) = ker A$ is the line through $e_1 = (1, 0, 0)$. However, we don't need anything quite so rigid for this problem. I tried to do something to help match the example from the OP. \u2013\u00a0 Amzoti Mar 5 '13 at 6:21\nNice post, and update, too...I've done my fare share of edits/updates based on feedback! \u2013\u00a0 amWhy Apr 25 '13 at 0:25\n\nUsing the Schur decomposition, it is exactly the set of matrices $U T U^*$, where $U$ is unitary, and $T$ is strictly upper triangular.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/27234/elogz-t2-proof-of-convergence-with-law-of-large-numbers\nText:\nTake the 2-minute tour \u00d7\n\nHi all, question: Let $Z_t$ be an iid sequence with $$\\mathbb{E}\\log(Z_t^2)<0 $$ Show that $$\\sum_{j=0}^\\infty Z_t^2 Z_{t-1}^2 ... Z_{t-j}^2 < \\infty$$ almost surely\n\nI am supposed to use LLN to solve this... but i can't make ends meet (this is exam preparation sheet question)\n\nshare|improve this question\nThis is just a straightforward exercise. Don't think it is really the kind of question this site is intended for. To answer, take the log of the product, divide by n and use LLN to deduce that the product is less than one (almost surely) for all large n. \u2013\u00a0 George Lowther Jun 6 '10 at 17:13\nActually I misread it. The formula doesn't seem to make sense. Shouldn't the product be $Z_1\\cdots Z_j$, in which case the LLN shows that the terms are almost surely bounded by a geometric series with ratio less than 1, so absoluty convergent. \u2013\u00a0 George Lowther Jun 6 '10 at 17:22\n\n2 Answers 2\n\nIf the term $Z_i^2$ of the independent and identically distributed random sequence is less than 1, then you can find a $q$ with $Z_i^2 \\leq q < 1$ for almost all $i$ (acording to the law of large numbers). Then the $k$-fold product is less than $q^k$ such that the geometric series limits your sum by $\\frac{1}{1-q}$.\n\nI presume that you meant $Z_{t+j}^2$ instead of $Z_{t-j}^2$. Otherwise you'd get negative indices.\n\nshare|improve this answer\n\nFor every $t$, let $Y_t=\\log(Z_t^2)$. Fix some $t$. The sequence $(Y_{t-k})_{k\\geqslant0}$ is i.i.d. with $E[Y_t]\\lt0$ hence the usual law of large numbers yields $\\frac1j\\sum\\limits_{k=0}^{j-1}Y_{t-k}\\to E[Y_1]$. Fix some negative $m\\gt E[Y_1]$.\n\nThen $\\frac1j\\sum\\limits_{k=0}^{j-1}Y_{t-k}\\leqslant m$ for every $j$ large enough, that is, for every $j\\geqslant J$ where $J$ is random and almost surely finite. In particular, for every $j\\geqslant0$, $\\sum\\limits_{k=0}^{j}Y_{t-k}\\leqslant mj+X$, for some almost surely finite random $X$. This implies the pointwise convergence of the series since $$ \\sum_{j\\geqslant0}\\exp\\left(\\sum\\limits_{k=0}^{j}Y_{t-k}\\right)\\leqslant\\sum_{j\\geqslant0}\\mathrm e^X\\mathrm e^{mj}=\\mathrm e^X(1-\\mathrm e^m)^{-1}. $$ Note that the RHS above is almost surely finite since $m\\lt0$ but is not (a priori) uniformly bounded since $X$ may be unbounded.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207303/throwing-coins-probability\nText:\nTake the 2-minute tour \u00d7\n\nX and Y are throwing coins. X throws $n$ times and Y throws $n+1$ times. What's the probability that Y got more heads than Y?\n\nI was trying to consider all the situations that X got $i$ heads and Y got $j>i$ heads but it didn't lead me to any sensible conclusion.\n\nshare|improve this question\n\n2 Answers 2\n\nLet $H_X, H_Y,T_X,T_Y$ denote the heads and tails counts of $X$ and $Y$. Assume that the heads of $X$'s coin is red, tails green, whereas the heads of $Y$'s coin is green, tails red. We ask for the probability of $$H_Y>H_X$$ $$\\iff T_X+H_Y=n-H_X+H_Y>n+H_X-H_Y=H_X+T_Y-1\\\\\\iff T_X+H_Y\\ge T_Y+H_X$$ But the latter expression is just that the number of grean outcomes is at least as large as the number of red ones. For this, the answer (by symmetry and since ties cannot occur) $\\frac12$.\n\nAlternatively, let $Y$ delay her last throw. With both players making $n$ throws, there is a certein probability $p$ that $X$ has more heads, the same probaility that $Y$ has more heads, and the probability $1-2p$ for a tie. With the last coin, $Y$ can only make a change in case of a tie and does so half the time for a win. That is: The probability of more heads for $Y$ is $p+\\frac{1-2p}2=\\frac12$.\n\nshare|improve this answer\n\nLet $X_n$ and $Y_n$ be the number of head in the first $n$ tosses. What is asked for is the probability of $$P(X_n < Y_{n+1}) = P(X_n < Y_n) + P(X_n = Y_n)P(\\text{last toss of }Y \\text{is a head})$$ Apparently, $P(X_n<Y_n)+P(X_n>Y_n)+P(X_n=Y_n)=1$ and because of symmetry, $P(X_n<Y_n)=P(X_n>Y_n)$ so that $P(X_n<Y_n)=\\frac{1-P(X_n=Y_n)}{2}$. Moreover, $P(\\text{last toss of }Y \\text{is a head})=1/2$. Plug them into the above equation, you will find out that $$P(X_n<Y_{n+1})=\\frac{1}{2}$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/72555/generating-coordinates-for-n-points-on-the-circumference-of-an-ellipse-with-fi/442308\nText:\nTake the 2-minute tour \u00d7\n\nI have an ellipse with semimajor axis $A$ and semiminor axis $B$. I would like to pick $N$ points along the circumference of the ellipse such that the Euclidean distance between any two nearest-neighbor points, $d$, is fixed. How would I generate the coordinates for these points? For what range of $A$ and $B$ is this possible?\n\nAs a clarification, all nearest-neighbor pairs should be of fixed distance $d$. If one populates the ellipse by sequentially adding nearest neighbors in, say, a clockwise fashion, the first and last point added should have a final distance $d$.\n\nshare|improve this question\nadd comment\n\n5 Answers 5\n\nup vote 3 down vote accepted\n\nAs long as $d$ is sufficiently small (where \"sufficiently small\" depends on the eccentricity of the ellipse), you can proceed as follows:\n\nStart at point $P_0$, and set off around the ellipse in steps of (Euclidean) length $d$, leaving point $P_i$ at the $i$th step. When you reach or pass the original point $P_0$, leave a point $P_n$ there, and stop.\n\nIf $P_n$ and $P_0$ coincide, we are done, Otherwise, decrease $d$ continuously until they do. Now we have $n$ equally spaced points on the ellipse. And we can repreat this procedure to find $n+1$ equally spaced points, and so on.\n\nThere are two things that can go wrong:\n\n  1. This procedure works, but the ellipse is so eccentric that $P_{i-1}$ and $P_{i+1}$ are not the nearest neighbours of $P_i$ (because there is a closer point across the semi-minor axis).\n  2. For some $i$, the position of $P_i$ is not a continuous function of $d$. This can happen if $P_{i-1}$ is near the 'sharp end' of the ellipse, and the line $P_{i-1} P_i$ is normal to the ellipse at $P_i$. This can happen if, roughly, the curvature of the ellipse exceeds $\\frac{1}{2d}$ at some point.\nshare|improve this answer\nadd comment\n\nPerhaps I am misinterpreting your question, as I think there is a very simple way to do this. Given the ellipse, and given $N$, take $d$ very small compared to $A/N$, pick a point on the ellipse, then going around the ellipse clockwise (say) pick points such that each is at distance $d$ from the preceding one. Locating each point is a simple matter of finding the intersection with the ellipse of a circle of radius $d$ centered at the previous point.\n\nIf this is not what you want, please clarify your question.\n\nshare|improve this answer\nIf I take $d$ very small to $\\frac{A}{N}$ then won't the two terminal points won't have a nearest-neighbor distance of $<<d$? \u2013\u00a0 Ness Oct 14 '11 at 8:54\n@Ness: it may, it may not. It's hard to tell unless you actually do it... \u2013\u00a0 \uff2a. \uff2d. Oct 14 '11 at 8:59\nI think the OP wants the distance between the first and last points to be $d$ too. So the question is not trivial. \u2013\u00a0 TonyK Oct 14 '11 at 9:03\n@TonyK, right, that's what I was trying to say. If I don't care about this nearest-neighbor pair, the problem is trivial. \u2013\u00a0 Ness Oct 14 '11 at 9:13\nI just adding a (hopefully) appropriate clarification to the problem description. \u2013\u00a0 Ness Oct 14 '11 at 9:18\nshow 2 more comments\n\nTo find such points exactly amounts to solving a system of $2N$ or so quadratic equations. A practical way could be the following: Choose the points $$z_k:=\\bigl(A\\cos{2\\pi k\\over N}, B\\sin{2\\pi k\\over N}\\bigr)\\quad(0\\leq k\\leq N)$$ $(z_0=z_N)$ as starting set and update the $z_k$, $0<k<N$, recursively in the following way: Each $z_k$ is replaced by the point $z_k'$ on the arc $(z_{k-1},z_{k+1})$ which is at equal distance from $z_{k-1}$ and $z_{k+1}$. This point can be found by solving a single quadratic equation. I conjecture that this procedure converges \"linearly\" to the unique solution of the problem with $z_0=(A,0)$.\n\nshare|improve this answer\nadd comment\n\nI will assume that $A$, $B$ and $N$ are given, and that $d$ is unknown.\n\nThere is always a solution. Let $L$ be the perimeter of the ellipse. An obvious constraint is $N\\,d<L$. Take $d\\in(0,L/N)$. As explained in Gerry Myerson's answer, pick a point $P_1$ on the ellipse, and then pick points $P_2,\\dots,P_N$ such that $P_{i+1}$ is clockwise from $P_i$ and the euclidean distance between $P_i$ and $P_{i+1}$ is $d$. If $d$ is small, $P_N$ will be short of $P_1$, while if $d$ is large, it will \"overpass\" $P_1$. In any case, the position of $P_N$ is a continuous function of $d$. By continuity, there will be a value of $d$ such that $P_1=P_N$. It is also clear that this value is unique.\n\nTo find $P_N$ for a given $d$ you need to solve $N-1$ quadratic equations. To compute the value of $d$, you can use the bisection method.\n\nEdit: TonyK's objections can be taken care of if $N=2\\,M$ is even. Take $P_1=(A,0)$ and follow the procedure to find points $P_2,\\dots,P_{M+1}$ in the upper semiellipse such that $P_{i+1}$ is clockwise of $P_i$ and at distance $d$, and $P_{M+1}=(-A,0)$. The the sought solution is $P_1,\\dots,P_{M+1},\\sigma(P_M),\\dots,\\sigma(P_2)$, where $\\sigma(P)$ is the point symmetric of $P$ with respect to the axis $y=0$.\n\nIf $N=2\\,M+1$ is odd, I believe that there is also a symmetric solution, but I have to think about it.\n\nshare|improve this answer\nSee my answer for objections to this argument! \u2013\u00a0 TonyK Oct 14 '11 at 10:03\n@TonyK I have edited my answer. \u2013\u00a0 Juli\u00e1n Aguirre Oct 14 '11 at 11:37\nYour solution for even $M$ doesn't answer my first point. If the ellipse is flat enough, it may be that $P_{M+1}$ is closer to $P_{M-1}$ than it is to $P_M$. \u2013\u00a0 TonyK Oct 14 '11 at 11:42\nSo by symmetry we could also have $P_3$ closer to $P_1$ than $P_2$? \u2013\u00a0 Juli\u00e1n Aguirre Oct 14 '11 at 13:14\nSorry, I meant $P_{M+2}$ is closer to $P_M$ than to $P_{M+1}$. So by symmetry $P_2$ is closer to $P_{N-1}$ than to $P_1$. Draw yourself an ellipse with $A=5, B=1$, and take $N=8$. Then you'll see what I mean. \u2013\u00a0 TonyK Oct 14 '11 at 14:44\nshow 3 more comments\n\nAssuming you have a starting point along the ellipse, position P, generate the next candidate points by intersecting the ellipse with a circle of radius d, where d is the desired distance between adjacent points\n\nThen choose the candidate which is of the desired winding. Winding can be calculated by considering the vector from the origin of the ellipse to position P and the vector from position P to the candidate position.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/141377/ranking-probability-problem\nText:\nTake the 2-minute tour \u00d7\n\n$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$.\n\nWe know $P(A > B) = 0.7, P(B > C) = 0.6$, what is $P(A > C)$?\n\nIs this a well defined problem? Does it have a sensible answer?\n\nEDIT: Suppose we have two careless observers. An observer observes $A > B$ and there are 70% probability that she is right. Another observer observes $B > C$ and there are 60% probability that she is right. So what is the probability of $A > C$ in the underlying event?\n\nshare|improve this question\nWait, if they are all sampled from the same uniform distribution on $[0,1]$, how can we have $P(A > B) \\neq 0.5$? \u2013\u00a0 TMM May 5 '12 at 13:37\n@TMM I edited the question. Is it well defined now? \u2013\u00a0 lqhl May 5 '12 at 14:05\nThere is a potentially interesting Bayesian problem here, struggling to get out. \u2013\u00a0 Andr\u00e9 Nicolas May 5 '12 at 14:29\nadd comment\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nI wrote following MATLAB code. Simulation results show the probability is around 0.602. I hope someone could confirm this with an analytic answer.\n\nN = 1000000;\n\nA = rand(N, 1);\nB = rand(N, 1);\nC = rand(N, 1);\n\np1 = 0.7;\np2 = 0.6;\n\nc1 = rand(N, 1);\nc2 = rand(N, 1);\n\nob1 = ((A > B) & (c1 < p1)) | ((A < B) & (c1 > p1));\nob2 = ((B > C) & (c2 < p2)) | ((B < C) & (c2 > p2));\n\nob = ob1 & ob2;\n\npos = ob & (A > C);\n\nsum(pos) / sum(ob)\n\n\nI enumerate all the 6 possibilities of relative order of $A, B, C$. They all appear with probability 1/6.\n\nThe following lists shows with how much probability each case passes the two observers\n\n  \u2022 $A>B>C$, $0.7\\times 0.6$\n\n  \u2022 $A>C>B$, $0.7\\times 0.4$\n\n  \u2022 $B>A>C$, $0.3\\times 0.6$\n\n  \u2022 $B>C>A$, $0.3\\times 0.6$\n\n  \u2022 $C>A>B$, $0.7\\times 0.4$\n\n  \u2022 $C>B>A$, $0.3\\times 0.4$\n\nAmong them, $A>B>C$, $A>C>B$, $B>A>C$ are the valid cases. So\n\n$\\frac {0.7\\times 0.6+0.7\\times 0.4+0.3\\times 0.6} {0.7\\times 0.6+0.7\\times 0.4+0.3\\times 0.6+0.3\\times 0.6+0.7\\times 0.4+0.3\\times 0.4} = 0.6027$\n\nshare|improve this answer\nWhat does \"$A > C > B, 0.7 \\times 0.4$\" mean? Certainly it cannot mean $P(A > C > B) = 0.7 \\cdot 0.4$. \u2013\u00a0 TMM May 5 '12 at 15:35\n@TMM It means the probability that $A>C>B$ passes the two observers. Since $A>C$, it passes the first observer probability with $70\\%$ (she makes a correct observation) probability. Since $C>B$, it passes the second observer with $40\\%$ probability (she makes a mistake). And the two events are independent. Hope this solves your problem :) \u2013\u00a0 chtlp May 5 '12 at 15:41\nNope, it doesn't. The two observations are fixed, while the values of $A,B,C$ are not. So what does \"the probability that [it] passes the two observers\" mean? \u2013\u00a0 TMM May 5 '12 at 15:45\n@TMM Imagine we repeat sampling $\\langle A, B, C\\rangle$ many times, some of them fit the description $P(A>B)=0.7$, $P(B>C)>0.6$ (``pass the observers''). And we want to know in these events, how many of them have $A>C$. \u2013\u00a0 chtlp May 5 '12 at 16:16\n+1: Despite the downvoting, the simulated answer and the maths is absolutely correct, under the assumption that the values of A,B and C are independent of the observed probabilities. Nice job. \u2013\u00a0 Ronald May 5 '12 at 23:27\nadd comment\n\nAh. It depends strongly on the method for making those probabilistic observations.\n\nFor example: If we observe that A=0.7, then we should note P(A>B)=0.7.\n\nIf we observe that C=0.4, then we should note P(B>C)=0.6.\n\n(This is perhaps the most obvious, natural way of accessing those probabilities. An observation of B would affect both probabilities)\n\nAnd, if those were our observations, then it's absolutely guaranteed that A>C. P(A>C) = 1.\n\nshare|improve this answer\nYou are assuming $A$ is fixed in $P(A > B) = 0.7$, but it could also be that $B$ is fixed, e.g. $B = 0$ and $A = B + U(-0.3, 0.7)$ and $C = B + U(-0.4, 0.6)$ with $U(a,b)$ a uniformly distributed random variable on $[a,b]$. In that case $P(A > C) > 0.5$ but $P(A > C) \\neq 1$. \u2013\u00a0 TMM May 5 '12 at 17:24\nAs I said, it depends on the method of making the probabilistic observations. What I said is consistent with the observations, and I would argue is the most natural way for those observations to occur, but there are other possible cases. \u2013\u00a0 Ronald May 5 '12 at 23:02\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/246812/finding-maximal-chain-of-cardinality-aleph\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nA countale partially ordered set that has an uncountable number of maximal chains\n\nLet $(P,\\leq) $ partial ordered set. We say $I\\subseteq P $ is a chain if for all $a,b \\in I $, held $a\\leq b$ or $b\\leq a$.\n\n$I\\subseteq P $ is maximal chain if there is no $J\\subseteq P$ that contains $I$ totally.\n\n\nFind partial ordered set $(P,\\leq) $, such that $\\text{card P}=\\aleph_0$, but the set of maximal chain cardinality is $\\aleph$.\n\nCan somebody explain me what I need to do?\n\nThank you!\n\nshare|improve this question\n\nmarked as duplicate by Asaf Karagila, martini, Cameron Buie, tomasz, Henry T. Horton Nov 29 '12 at 2:21\n\n\nIs $\\aleph$ the same as $\\aleph_0$? If not, what is it? \u2013\u00a0 Brian M. Scott Nov 28 '12 at 21:06\n$\\text{card}\\mathbb{R}=\\aleph$ \u2013\u00a0 17SI.34SA Nov 28 '12 at 21:16\nThat\u2019s a most unusual notation; normally one writes $2^{\\aleph_0}$, $2^\\omega$, or $\\mathfrak c$ for $|\\Bbb R|$. \u2013\u00a0 Brian M. Scott Nov 28 '12 at 21:23\n@Brian: That was Cantor's original notation, actually. It is also not uncommon in Israel (for some reason) to use $\\aleph$. At least in introductory courses. \u2013\u00a0 Asaf Karagila Nov 28 '12 at 21:42\nadd comment\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nI expect that you know what a chain in the partial order $\\langle P,\\le\\rangle$ is: a subset of $P$ that is linearly ordered by $\\le$. A maximal chain is simply a chain that is not a proper subset of any other chain. For example, if you partially order the positive integers by divisibility (i.e., $m\\le n$ iff $m\\mid n$), then $C=\\{2^k:k\\in\\Bbb N\\}$ is a maximal chain: if you add to $C$ any positive integer that is not a power of $2$, you\u2019ll no longer have a chain. Thus, you\u2019re being asked to find a countable partial order that has $|\\Bbb R|$ distinct maximal chains.\n\nIt is perhaps a little surprising that it\u2019s possible to find such a small partial order with so many different chains, so it\u2019s not surprising that an example probably isn\u2019t immediately obvious. I\u2019ve given a couple of (very similar) examples below, leaving the verification that they work to you; if you want to try finding one on your own, you should stop reading here.\n\nLet $P$ be the set of finite sequences of $0$\u2019s and $1$\u2019s, setting $\\sigma\\le\\tau$ if and only if $\\sigma$ is an initial segment of $\\tau$. Show that there is a maximal chain for each infinite sequence of $0$\u2019s and $1$\u2019s.\n\nAlternatively, let $\\mathscr{F}$ be the family of finite subsets of $\\Bbb N$, and define the partial order $\\le$ as follows: for $F,G\\in\\mathscr{F}$, $F\\le G$ if and only if $F\\subseteq G$ and either $F=G$ or $\\max F<\\min(G\\setminus F)$. In other words, if $F$ and $G$ are distinct members of $\\mathscr{F}$, then $F<G$ if and only if $F\\subseteq G$ and every element of $G\\setminus F$ is larger than every element of $F$. Show that there is a maximal chain in $\\langle\\mathscr{F},\\le\\rangle$ for each infinite subset of $\\Bbb N$. (This partial order is isomorphic to the subset of the first one consisting of those finite sequences whose last terms are $1$.)\n\nshare|improve this answer\nBrian, read closely. The OP asked for an explanation what is the question asking, instead you wrote a solution to the question. :-) \u2013\u00a0 Asaf Karagila Nov 28 '12 at 21:46\n@Asaf: Damn. I knew that, and then I got distracted before writing my answer. \u2013\u00a0 Brian M. Scott Nov 28 '12 at 21:50\nadd comment\n\nYou need to find a countable partial order $(P,\\leq)$ such that the collection of $\\{C\\subseteq P\\mid C\\text{ is a maximal chain}\\}$ has cardinality $2^{\\aleph_0}$.\n\nOne example would be all finite binary strings ordered by end-extension. Show that any maximal chain would correspond to an infinite subset of $\\mathbb N$, and that different subsets correspond to different maximal chains.\n\n$C\\subseteq P$ is a maximal chain, I'll remind you, if $(C,\\leq\\upharpoonright C)$ is a linear order, and whenever $C\\subsetneqq D$ we have that there are $x,y\\in D$ such that $x\\nleq y$ and $y\\nleq x$. Namely $C$ is a chain and it cannot be extended to a strictly larger chain.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/113477/what-is-expected-number-of-turns-to-play-this-childrens-game/113483\nText:\nTake the 2-minute tour \u00d7\n\nI'm playing this game with children am I'm ready to stab my eyes with an ice pick. It seems like it never ends, but I know I expect it to end. What is my expected number of spins to remove all the fruit from the tree?\n\nGoal: To remove 14 cherries from tree by executing one of following seven directions at random per turn.\n\n 1. Remove 1 cherry.\n 2. Remove 2 cherries.\n 3. Remove 3 cherries.\n 4. Remove 4 cherries.\n 5. Return 1 cherry to tree.\n 6. Return 2 cherries to tree.\n 7. Return all your cherries to tree.\n\nOnce I realized I have a 1/7 chance each turn of playing this game in perpetuity, I started reaching for the kitchen drawer.\n\nshare|improve this question\nSuppose there are 2 cherries on the tree. Does the game end if you roll a 3 or a 4? (ie, if you're asked to remove more cherries than there are left.) \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:32\nYes, if there are two cherries, picking 2,3, or 4 cherries will end the game. \u2013\u00a0 zundarz Feb 26 '12 at 3:35\nAlso, if all 14 cherries are on the tree and you roll a 5, does the tree now have 15 cherries or does nothing happen? \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:36\nIn my solution below, I assume that nothing happens in this case. \u2013\u00a0 Brett Frankel Feb 26 '12 at 3:46\nUm, if there are children threatening you with ice picks, then the statistical properties of some game probably shouldn't be on top of your priority list. \u2013\u00a0 Henning Makholm Feb 26 '12 at 3:48\n\n3 Answers 3\n\nup vote 6 down vote accepted\n\nI actually spent some time about a year ago doing some computations for a variant of this game, sold as Hi-Ho Cherry-O. It's identical to your game, except with 10 cherries instead of 14. (I learned about it from a colleague with a 4-year-old daughter.)\n\nThe computation is a nice example of some simple Markov chain techniques, which produce linear equations of the sort in Brett Frankel's answer. I considered the cases of 1 to 4 players, which are amenable to computer solution.\n\nAnother interesting feature is that since the players take turns, the first player has a slight advantage.\n\nHere are the results I got for 10 cherries. If you are really interested, I can try and reconstruct my code and run the 14 cherry case.\n\n1 player game:\n\nExpected length: 15.8019792994073 rounds\n\n2 player game:\n\nExpected number of rounds: 9.58554137805221\nP(player 1 wins) = 0.518720469382215\nP(player 2 wins) = 0.481279530617784\nExpected number of turns = 18.6523622867222\n\n3 player game:\n\nExpected number of rounds: 7.49668096168849\nP(player 1 wins) =  0.357756582790784\nP(player 2 wins) =  0.332728455615310\nP(player 3 wins) =  0.309514961593905\nExpected number of turns: 21.4418012638686\n\n4 player game:\n\nExpected number of rounds: 6.44149249272987\nP(player 1 wins) =  0.276928283784381\nP(player 2 wins) =  0.258099951775544\nP(player 3 wins) =  0.240610168544412\nP(player 4 wins) =  0.224361595895655\nExpected number of turns: 24.1783750474708\n\nEdit: I should also mention some previous work by Jeffrey Humpherys.\n\nshare|improve this answer\nI get $1179248/80915\\approx14.573910894148181$ for $10$ cherries, yet the same as DSM for $14$ cherries. Are you sure you used exactly the same rules (especially when there aren't enough cherries to remove or to return)? \u2013\u00a0 joriki Feb 26 '12 at 5:22\n@joriki: DSM's answer is now deleted, but I believe the rule I used is that when there aren't enough cherries, you add or remove as many as possible. E.g. if you have only one cherry in your bucket and spin a 6, you return that one cherry to your tree. Again, I unfortunately only saved pieces of my code, so I can't check it, but perhaps if I have some time in the near future I'll reconstruct it. \u2013\u00a0 Nate Eldredge Feb 26 '12 at 14:16\nNate E.: The game is Hi-Ho-Cherry-Oh. It seems like 14 cherries!! After I removed the ice-picks from my eyes, I recounted and there are just 10 cherries. \u2013\u00a0 zundarz Feb 26 '12 at 14:26\nI've resolved the discrepancy between our results; see my answer. \u2013\u00a0 joriki Feb 27 '12 at 12:35\n\nYou can solve via a series of 14 linear equations: Let $E_n$ be the expected number of turns remaining until the game is over when there are currently $n$ cherries on the tree. For example, $$E_1=\\frac{4}{7}1+\\frac{1}{7}(1+E_2)+\\frac{1}{7}(1+E_3)+\\frac{1}{7}(1+E_{14})$$\n\n\nBy the time you finish writing down all 14 equations and solving, the game may well be over. (Then again, I expect the answer will be quite large).\n\nshare|improve this answer\n\nI've found the reason for the discrepancy between Nate's answer and my results (which agree with DSM's). In the version of the game that Nate linked to, the dog and the bird both require you to return $2$ cherries to the tree, whereas in the present version 5. says one cherry and only 6. says two cherries. If I change my code to the linked version my result for the expected number of turns is in agreement with Nate's. For the present version, I get\n\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/12139/number-of-relations-that-are-both-symmetric-and-reflexive\nText:\nTake the 2-minute tour \u00d7\n\nConsider a non-empty set A containing n objects. How many relations on A are both symmetric and reflexive?\n\nThe answer to this is $2^p$ where $p=$ $n \\choose 2$. However, I dont understand why this is so. Can anyone explain this?\n\nshare|improve this question\nthis is not (number-theory); just because it numbers does not make it number theory. It's about counting, so it's combinatorics. \u2013\u00a0 Arturo Magidin Nov 27 '10 at 23:40\n\n5 Answers 5\n\nup vote 12 down vote accepted\n\nTo be reflexive, it must include all pairs $(a,a)$ with $a\\in A$. To be symmetric, whenever it includes a pair $(a,b)$, it must include the pair $(b,a)$. So it amounts to choosing which $2$-element subsets from $A$ will correspond to associated pairs. If you pick a subset $\\{a,b\\}$ with two elements, it corresponds to adding both $(a,b)$ and $(b,a)$ to your relation.\n\nHow many $2$-element subsets does $A$ have? Since $A$ has $n$ elements, it has exactly $\\binom{n}{2}$ subsets of size $2$.\n\nSo now you want to pick a collection of subsets of $2$-elements. There are $\\binom{n}{2}$ of them, and you can either pick or not pick each of them. So you have $2^{\\binom{n}{2}}$ ways of picking the pairs of distinct elements that will be related.\n\nshare|improve this answer\n\nBeing reflexive means that $(x,x)\\in R$ for all $x\\in A$. Being symmetric means that $(x,y)\\in R$ implies that $(y,x)\\in R$ as well.\n\nBegin by listing $A$ as $A=\\{a_1,\\dots,a_n\\}$. Then let $B$ be the set $$\\{(a_i,a_j)\\mid 1\\le i<j\\le n\\}.$$ Note that if $x\\ne y$ are elements of $A$, then either $(x,y)\\in B$ or $(y,x)\\in B$ but not both.\n\nLet $S$ be any subset of $B$. Let $$R_S=S\\cup\\{(y,x)\\mid (x,y)\\in S\\}\\cup\\{(x,x)\\mid x\\in A\\}.$$ Then $R_S$ is a symmetric and reflexive relation on $A$.\n\nNote that there are $2^{|B|}$ subsets of $B$, and that if $S\\ne S'$ are subsets of $B$, then $R_S\\ne R_{S'}$. Also, note that $|B|=\\binom{n}2$. (If the last equality is not clear, note that $$B=\\{(a_1,a_j)\\mid j>1\\}\\cup\\{(a_2,a_j)\\mid j>2\\}\\cup\\dots$$ so $|B|=(n-1)+(n-2)+\\dots+1$, and it is well-known that the last sum equals $n(n-1)/2=\\binom n2$.\n\nThis shows that the number of symmetric, reflexive relations on $A$ is at least $2^p$ with $p=\\binom n2$.\n\nTo see the equality, it is enough to check that any such relation $R$ is $R_S$ for some $S\\subseteq B$. But, given $R$, let $S=\\{(a_i,a_j)\\in R\\mid i<j\\}$. This is a subset of $B$, and it is easy to check that $R=R_S$.\n\nshare|improve this answer\n\nMaybe you can see it like this: a relation $R$ on $A$ is a subset of $A\\times A$, and it is symmetric if and only if $(x,y)\\in R \\implies (y,x)\\in R$, moreover, if the relation is reflexive, then $(x,x)\\in R$ for all $x\\in A$. Then you can determine uniquely such a relation by saying which subsets of two distinct elements of $A$ \"belong\" to $R$, in the sense that $\\{x,y\\}\\in R \\iff (x,y),(y,x)\\in R$. Now, you know that the number of subsets with two distinct elements of $A$ is $\\binom{n}{2}$, and the number of subset of a set with $p$ elements is $2^p$. I'm sorry if i was too obscure.\n\nshare|improve this answer\nI had not seen that Arturo Magidin had already answered, so that i gave almost an equal explanation. Sorry again (for my bad english too!). \u2013\u00a0 Daniele A Nov 27 '10 at 23:55\n\nYou can also think of it as a matrix of $nxn$, with the elements of the matrix being $(a_i,a_j)$ with $ a_i,a_j \\in A$. The elements of the main diagonal have to be included in R because R is reflexive. For the remaining $n^2-n$, picking a pair from the upper triangle say $(a_2,a_1)$ implies that you are also picking $(a_1,a_2)$. So in reality you only have $\\frac{n^2-n}{2}$ elements to pick from. This can be done in $2^{\\frac{n^2-n}{2}}$ ways.\n\nshare|improve this answer\n\nThere is only one way to make the relation reflexive -- all ordered pairs $(x,x), x\\in A$ must be in the relation. So the number of reflexive symmetric relations on $A$ is the same as the number of ways of adding symmetric pairs $(a,b),(b,a)$, where $a\\neq b$ into the relation.\n\nLet $S$ be a subset of $2^A$ consisting of subsets of 2 elements. Then $S$ gives rise to exactly one reflexive symmetric relation on $A$. For example, if $A=\\lbrace 1,2,3,4\\rbrace$, then an example of $S$ is $\\lbrace \\lbrace 1,2\\rbrace, \\lbrace 1,4\\rbrace, \\lbrace 3,2\\rbrace\\rbrace$. The relation induced by $S$ is $$\\lbrace (1,2), (2,1), (1,4), (4,1), (2,3), (3,2)\\rbrace$$ plus all $(x,x), x\\in A$. Conversely, every reflexive symmetric relation on $A$ arises in this way.\n\nSince there are $p={n\\choose 2}$ subsets of 2 elements, there are $2^p$ such $S$'s. The answer to your question is therefore $2^p$.\n\nshare|improve this answer\nI think this is not quite right. If the number of reflexive symmetric relations on $A$ were the same as the number of symmetric relations on $A$, then every symmetric relation would have to be reflexive. \u2013\u00a0 Rahul Nov 28 '10 at 2:00\n@Rahul. I have edited my post. \u2013\u00a0 TCL Nov 28 '10 at 3:42\nI just noticed that I had a $-1$ on my reputation. In checking it out, I found out that apparently I downvoted this two days ago. I don't remember this question/answer at all, and I certainly wouldn't have marked this (correct, well written) answer down intentionally. So, I apologize. If this is important to you, edit the answer (so I can revote), and then ping me. Sorry! \u2013\u00a0 Jason DeVito Apr 19 '14 at 19:51\n@DeVito.I have just edited it. \u2013\u00a0 TCL Apr 21 '14 at 14:54\n\nYour Answer"}
{"text": "Retrieved from https://meta.mathoverflow.net/questions/3497/an-error-in-calculations-of-percents-in-reputations/3498\nText:\nLooking at the MO reputation league I found that it shows up 1767 screens, all screns but the last one show up 9x4=36 users and the last screen shows 27 users. So totally MO has 1766x36+27=63 603 users.\n\nOn the other hand, in the profile of the MO leader Hamkins we can find that he is 0,02% overall. But if MO indeed has 63603 users, he should be $\\frac1{63 603}\\cdot 100\\%\\approx 0.0017\\%$ overall.\n\nThe same problem with other users:\n\nfor David Speyer is written 0,04% but should be $\\frac2{63 603}\\cdot 100\\%\\approx 0,003\\%$\n\nfor Joseph O'Rourke is written 0,07% but should be 0,005%\n\nfor Qiaochu Yuan is written 0,09% but should be 0,006%,\n\nand so on...\n\nWhat is the reason in such more than 10 times difference?\n\n| |\n\n\nAs far as I know, only users from reputation leagues count for the purpose of these statistics. (That means that cut-off is at 200 reputation points. Notice the explanation in the sidebar: \"users with less than 200 reputation are not tracked in the leagues\". It is, at least to some extent, reasonable. Probably we don't want to count the users who never interacted with the site, just created an account. Which means that any reasonable cut-off should be above 101 points.)\n\nCurrently there are 4456 users in the reputation league. Considering that the the percentile is taken from these users, the numbers seem about right: \\begin{align*} \\frac1{4456} &\\doteq 0.022\\%\\\\ \\frac2{4456} &\\doteq 0.045\\%\\\\ \\frac3{4456} &\\doteq 0.067\\%\\\\ \\frac4{4456} &\\doteq 0.090\\% \\end{align*}\n\nSee also:\n\nI will also add that unregistered users are counted in reputation leagues (if they have at least 200 reputation points) but they are not shown in the list of users. Existence of unregistered users also explains why you counted approximately 64k users while official stats show 74k users. (The latter includes the unregistered users.)\n\n| |\n\nYou must log in to answer this question.\n\nNot the answer you're looking for? Browse other questions tagged ."}
{"text": "Retrieved from http://www.riddlesandanswers.com/v/229407/once-upon-a-time-there-lived-a-king-who-wished-to-find-the-wisest-man-in-the-realm-to-be-his-assista/\nText:\nTrending Tags\n\nPopular Searches\n\nTerms \u00b7 Privacy \u00b7 Contact\nRiddles and Answers \u00a9 2020\n\nThe Red Hat\n\nOnce upon a time there lived a king who wished to find the wisest man in the realm to be his assistant. He summons the 3 known wisest men to his court and he administers the following test.\n\nHe sits them in a circle, facing each other and he says Im going to put either a red hat or a white hat on each of your heads. He proceeds to place a red hat on each of their heads. Obviously they can see each other but there are no mirrors in the room so they cant see whats on their heads. He says If you can see a red hat, raise your hand. They all raise their hands. Then he says If you can tell what color hat you have on, stand up.\n\nTime goes on, one guy looks at another guy, he looks at the other guy. The other guy looks at him. Finally one guy stands up. The question is how did he know he was wearing a red hat?\nHint: For a moment or two, nobody moved. Nobody knew for certain what color his hat was, and thats what told the wisest guy that all of the hats were red.\nStep 1:\nWiseguy #1 knows he can see two red hats.\n\nStep 2:\nWiseguy #1 thinks, \"Hey, if I were wearing a white hat, Wiseguy #2 would see one red hat and one white.\"\n\nStep 3:\nWiseguy #1 then thinks, \"If I were wearing a white hat, and Wiseguy #2 saw one red hat and one white (and if he were wearing a white hat himself), then Wiseguy #3 would have seen two white hats. So, Wiseguy #3 wouldnt have raised his hand to the first question.\n\nWiseguy #1 thinks, \"If that were true, Wiseguy #2 would be sure that he had a red hat. But since Wiseguy #2 was actually unsure about his hat color, it can only mean one thing, my hat is red.\"\nDid you answer this riddle correctly?\n\nAdd Your Riddle Here"}
{"text": "Retrieved from https://mathoverflow.net/questions/137077/spreading-out-integers-via-multiplication\nText:\nLet $a_1,...,a_n\\in [0,m]$ be a set of $n$ positive integers, where $n<<m$, $m=poly(n)$. One can assume $m$ is prime. Is there an efficient, possibly randomized, way to find an integer $N=poly(n)$, such that $(a_i \\cdot N) (mod \\ m)$ is approximately uniform on $[0,m]$. The value of $N$ may also depend on the approximation parameter.\n\n  \u2022 $\\begingroup$ Should there be some additional hypothesis to prevent, for example, the situation where all the $a_i$ are equal? $\\endgroup$ \u2013\u00a0Andreas Blass Jul 18 '13 at 14:52\n  \u2022 $\\begingroup$ Yes, let's assume they are all different. $\\endgroup$ \u2013\u00a0Lior Eldar Jul 18 '13 at 15:04\n  \u2022 $\\begingroup$ \"All different\" won't work because there are $n$ of the integers $a_i$'s, all in $[0,m]$ with $m < n$ $\\endgroup$ \u2013\u00a0Andreas Blass Jul 18 '13 at 15:08\n  \u2022 $\\begingroup$ Of corse! - fixed the mistake above. $\\endgroup$ \u2013\u00a0Lior Eldar Jul 18 '13 at 15:49\n\nChoosing $N$ at random and checking should work. Put $e(t)=e^{2\\pi i t/m}$. Then we have \\begin{eqnarray*} \\sum_{N=1}^m\\sum_{k=1}^K\\left|\\sum_{i=1}^ne(k N a_i)\\right|^2 & = & \\sum_{N=1}^m\\sum_{k=1}^K\\sum_1\\leq i,j\\leq n e(kN(a_i-a_j))\\\\ & = & m\\sum_{k\\leq K} \\#\\{(i,j)|a_i\\equiv a_j\\pmod{\\frac{m}{(m, k)}}\\}. \\end{eqnarray*} Since the $a_i$ are all different and in $[0, m]$, for fixed $a_i$ the number of $a_j$ satisfying the last congruence is $(m,k)$ at most, and the last sum is bounded above by $mn\\sum_{k\\leq K}(k,m)\\leq mnK^2$.\n\nDenote by $D_N$ the discrepancy of $a_iN\\bmod m$. Then we have $$ D_N\\ll \\frac{n}{K}+\\sum_{k\\leq K}\\frac{1}{k}\\left|\\sum_{i=1}^n e(kNa_i)\\right|, $$ thus $$ \\frac{1}{m}\\sum_{N=1}^m D_N \\ll \\frac{n}{K} + \\sqrt{nK}\\log K. $$ Hence for most $N$ we have $D_N\\ll n^{2/3}\\log n$, which is reasonable good equidistribution.\n\nChecking whether for a random $N$ we have that $D_N<n$ is small requires between $n^{1+\\epsilon}$ and $n^{3/2}$ steps, depending on how small $D_N$ has to be.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/86019/how-can-i-partially-evaluate-a-function/86031\nText:\nI have a multivariable function, from which I'd like to define a marginalization:\n\nf(a,b,c,d,...,z) ---> g(a,1,c,d,...,z)\n\nGenerally, g will have fewer argument than f, possibly none (full evaluation). Is it possible to take the output of a function and transform it into a second function?\n\nThis is part of a looped Block[] segment in a larger code, where the number of variables, slot positions, and their values are specified anew on each iteration.\n\nHere is my best failed attempt:\n\nPartialEvaluate[func_, totargs_, args_, targets_] :=\n\nBlock[{tmp, g, r},\n\ntmp = Table[Slot[i], {i, 1, totargs}];\n\nDo[tmp[[targets[[slot]]]] = args[[slot]];, {slot, 1, Length[targets]}];\n\ng = Function[func @@ tmp]\n\n\n\n  \u2022 2\n    $\\begingroup$ g[a_,c_]:= f[a, 1, c]? $\\endgroup$ \u2013\u00a0Dr. belisarius Jun 16 '15 at 0:58\n  \u2022 $\\begingroup$ How are the variables specified? $\\endgroup$ \u2013\u00a0C. E. Jun 16 '15 at 1:02\n  \u2022 $\\begingroup$ I've updated the post with an example. $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 1:09\n  \u2022 1\n    $\\begingroup$ You mean partial application? $\\endgroup$ \u2013\u00a0ciao Jun 16 '15 at 1:24\n  \u2022 $\\begingroup$ Somewhat related: mathematica.stackexchange.com/q/48137/7936 $\\endgroup$ \u2013\u00a0evanb Jan 14 '17 at 9:11\n\nUpdated version\n\nTo be more in line with what the OP wanted, we have the following updated code. Given inputs (in order) g, totargs = 5, args = {x[1],x[4]}, and targets = {1,4}, if we call the function\n\npartialEvaluate[func_, totargs_, args_, targets_] := Block[{argsEvaluated = 1, newArgs = 1}\n , Evaluate[func @@ Table[\n    If[MemberQ[targets, i], args[[argsEvaluated++]], Slot[newArgs++]]\n    , {i, 1, totargs}]\n   ] &\n\nthe result is\n\ng[x[1], #1, #2, x[4], #3] &\n\nThe main reason the OP's original code didn't work is that Function has the Attribute HoldAll:\n\n(* {HoldAll, Protected} *)\n\nIf you want the insides of Function to be evaluated, you have to explicitly Evaluate it, as I've done.\n\nOriginal post\n\nI'm not sure of exactly what the inputs and outputs should be, but here's my best guess as to what you want, with minimal changes to your code. For the purpose of concreteness, let's suppose that totargs = 5, args = {x[1],x[2],x[3],x[4],x[5]}, and the target variables to which the function is going to be applied to are targets = {1,4}. Then if we call the function\n\npartialEvaluate[func_, totargs_, args_, targets_] := Block[{tmp}\n  ; tmp[[targets]] = args[[targets]]\n  ; Evaluate[func @@ tmp] &\n\nwith the input\n\npartialEvaluate[g, 5, {x[1], x[2], x[3], x[4], x[5]}, {1, 4}]\n\nwe get the pure function\n\ng[x[1], #2, #3, x[4], #5] &\n| improve this answer | |\n  \u2022 $\\begingroup$ This is what I was looking for, thank you! $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 4:25\n  \u2022 $\\begingroup$ Thank you for the accept! However, are you sure? Is it possible that what you actually want is g[x[1], #1, #2, x[4], #3] &? Because I imagine you will want to apply this new function to a three-element list, rather than still a five element list. If so, I can update with a new version that returns this alternative version $\\endgroup$ \u2013\u00a0march Jun 16 '15 at 5:09\n  \u2022 $\\begingroup$ Ah, I forgot to share. I added a simple j=1;Do[If[tmp[[i]]==Slot[i],tmp[[i]]=Slot[j++],{i,Range[totargs]}] fix. before the evaluation step. Share your solution anyway, it's probably more clever! $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 5:43\n  \u2022 $\\begingroup$ That's essentially what I did, actually, but I'll post anyway, since it's slightly cleaner. $\\endgroup$ \u2013\u00a0march Jun 16 '15 at 5:47\n  \u2022 $\\begingroup$ A pedantic difference, but my ugly do loop was to account for a Length[args]=Length[targets] constraint which I didn't mention earlier. Thanks a lot for your help. $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 5:51\n\nSince mathematica does not use currying evaluation like language like haskell, you should do the currying for partial evaluation by yourself.\n\nHere is some simple example:\n\nIn[1]:= addx[x_] := Function[y, x + y]\nIn[2]:= addx[3][4]\nOut[2]:= 7\nIn[3]:= add3 = addx[3]\nOut[3]:= Function[y$, 3 + y$]\nIn[4]:= add3[4]\nOut[4]:= 7\n\nIn general, you should make the function you want to partial evaluate take arguments and return another function which take the remaining arguments. And then you can pass few arguments to the function and you will get another function which can be applied to the remaining arguments.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Thanks for your suggestion, didn't know about 'currying'. Unfortunately the structure of func is fixed by other elements of the larger code. I was hoping to find a solution to the problem as I posted it above. it is sufficiently general and presumably will be simple to solve. but I'm not sure why the application of the Function fails to recruit the slots in the output of Apply [func]. $\\endgroup$ \u2013\u00a0sampson Jun 16 '15 at 3:16\n\nMarch's version is problematic: in case the original function uses itself pure functions in its definition then this can lead to unintended results and errors. Consider the following example:\n\nfoo[x_,y_] := (x #)& /@ {x,y}\n\nPartial evaluation of foo with the second argument set to three should result in a function that is equivalent to:\n\nfooPartial[x_] := (x #)& /@ {x,3}\n\nIf we now use march's method for partial evaluation we get the following pure function\n\n{#1^2, 9}&\n\nwhich is equivalent to\n\nfooPartialWrong[x_] := (# #)& /@ {x,3}\n\nwhich is not equivalent to fooPartial! The problem is that the #'s in the argument of foo and in the definition get mixed up.\n\nA further problem (probably even more problematic in this case) is that Evaluate \"breaks\" scoping\n\nIn[1]:= x = 3                                                                   \n\nOut[1]= 3\n\nIn[2]:= foo2[x_,y_]:= Evaluate[x y]                                              \n\nIn[3]:= ?foo2                                                                    \n\nfoo2[x_, y_] := 3*y\n\nA better method is to exploit the fact that List does not have the attribute HoldAll (see Enforcing correct variable bindings and avoiding renamings for conflicting variables in nested scoping constructs):\n\nModule[{x},SetDelayed @@ {fooPartial[x_],foo[x,3]}]\n\nIn rewriting partialEvaluate one cannot use Module as above since the number of variables scoped by Module is fixed, so I use Unique instead to avoid side-effects.\n\npartialEvaluate2[func_, funcPartial_, totargs_, args_, targets_] :=\n Module[{num1 = 1,num2 = 1,variablesNames,variablesNamesUnderscore},\n  variablesNames = Unique /@ ConstantArray[\"x\",totargs - Length[args]];\n  variablesNamesUnderscore = Pattern[#,Blank[]]& /@ variablesNames;\n  SetDelayed @@ {funcPartial@@variablesNamesUnderscore, func @@ Table[\n    If[MemberQ[targets, i], args[[num1++]], variablesNames[[num2++]]],\n    {i, 1, totargs}]}\n\nAnd we now get as desired:\n\nIn[1]:= partialEvaluate2[foo,fooPartial,2,{3},{2}] \nIn[2]:= ?fooPartial                                                                                                                           \n\nfooPartial[x31_] := {x31^2, 3*x31}\n| improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/261812/vectors-that-are-almost-orthogonal-on-average-lower-bounds-on-dimension/261821\nText:\nLet $v_1,\\dotsc,v_k \\in \\mathbb{R}^d$ be unit-length vectors such that $$\\sum_{1\\leq i,j\\leq k} |\\langle v_i,v_j\\rangle|^2 \\leq \\epsilon k^2.$$ What sort of lower bound can we give on $d$ in terms of $k$ and $\\epsilon$?\n\nMust it be the case that $d\\gg \\min(\\log k,\\epsilon^{-1})$, say, or anything of the sort? Is that tight?\n\n  \u2022 $\\begingroup$ I guess a more flexible reformulation is to let $v_1,\\ldots,v_k$ be unit-length vectors in some vector space of large (infinite?) dimension, and ask for a lower bound on the dimension of their span given the almost-orthogonal condition. $\\endgroup$ \u2013\u00a0Peter Humphries Feb 9 '17 at 22:05\n  \u2022 1\n    $\\begingroup$ Isn't this equivalent? $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 22:12\n  \u2022 $\\begingroup$ Yes of course.. $\\endgroup$ \u2013\u00a0Peter Humphries Feb 9 '17 at 22:13\n\nThe Johnson Lindenstrauss Lemma states that there are $k$ vectors achieving $\\epsilon$ provided $d\\geq C \\epsilon^{-2} \\log k.$\n\nIf you actually want to bound the maximum absolute value of the inner product for distinct vectors, instead of the average as you stated which is of course stronger, then tighter bounds apply.\n\nRelevant results for this case are due to Welch, Kabatianski, Levenshtein, Sidelnikov. Welch's applies to arbitrary vectors, real or complex. The others apply to vectors constructed from complex roots of unity of some finite order. Welch's bound states\n\nLet $e\\geq 1$ be an integer and let $a_1,\\ldots,a_k$ be distinct vectors in $\\mathbb{C}^d.$ Then the following inequalities hold $$ \\sum_{i=1}^k \\sum_{j=1}^k \\left| \\langle a_i, a_j \\rangle \\right|^{2e} \\geq \\frac{\\left(\\sum_{i=1}^k \\lVert a_i \\rVert^{2e}\\right)^2}{\\binom{d+e-1}{e}}, $$ If the set of vectors you are interested in is of size roughly $d^u,$ the tightest lower bound is obtained by choosing $e=\\lfloor u\\rfloor.$\n\n\nSince you required $\\langle a_i,a_i\\rangle=1,1\\leq i\\leq k,$ if I subtract the diagonal inner products, I obtain $$ \\sum_{1\\leq i\\neq j\\leq k} \\left| \\langle a_i, a_j \\rangle \\right|^{2} \\geq \\frac{k^2-kd}{d}, $$ recovering the dependence on $k.$\n\nEdit 2:\n\nThe Johnson Lindenstrauss Lemma is tight up to a constant factor. The Welch bound is tight for some cases, when so-called Welch Bound with Equality sets of vectors exist, which correspond to all unequal innner products being the same in absolute value.\n\n\nV.M. Sidelnikov, On mutual correlation of sequences, Soviet Math Dokl. 12:197-201, 1971.\n\nV.M. Sidelnikov, Cross correlation of sequences, Problemy Kybernitiki, 24:15-42, 1971 (in Russian)\n\nWelch, L.R. Lower Bounds on the Maximum Cross Correlation of Signals. IEEE Transactions on Information Theory. 20 (3): 397\u2013399, 1974.\n\nKabatianskii, G. A.; Levenshtein, V. I. Bounds for packings on the sphere and in space. (Russian) Problemy Pereda\u010di Informacii 14 (1978), no. 1, 3\u201325. (A version of this might be available in English translation, in Problems of Information Transmission)\n\n| cite | improve this answer | |\n  \u2022 $\\begingroup$ Wait. Doesn't the inequality you cite as Welch's imply that $d\\geq \\epsilon^{-1}$, with no dependence on $k$? This seems a little too strong. $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 23:13\n  \u2022 $\\begingroup$ @HAHelfgott, please see edit. $\\endgroup$ \u2013\u00a0kodlu Feb 9 '17 at 23:31\n  \u2022 $\\begingroup$ Thanks. That answers the question, then. But how far is it from being tight? Is the Johnson Lindenstrauss Lemma tight? $\\endgroup$ \u2013\u00a0H A Helfgott Feb 9 '17 at 23:52\n  \u2022 1\n    $\\begingroup$ As I pointed out earlier in a now deleted comment, we can (trivially) achieve the bound for a given $\\epsilon$ without any real size restrictions on $k$ if $d\\ge\\epsilon^{-1}$ by just repeating an ONB of $\\mathbb R^d$. (I guess it would be more honest to say that if $d$ is very close to $\\epsilon^{-1}$, then $k$ should be a multiple of $d$ to be safe.) $\\endgroup$ \u2013\u00a0Christian Remling Feb 10 '17 at 1:51\n  \u2022 $\\begingroup$ May you give references to \"Welch, Kabatianski, Levenshtein, Sidelnikov\", please. $\\endgroup$ \u2013\u00a0Sergei Feb 11 '17 at 5:37\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/149324/why-is-only-the-third-component-of-weak-isospin-used-as-a-conserved-quantity/296618\nText:\nUsing Noether's theorem\n\n\\begin{equation} \\partial_0 \\int d^3x \\left(\\frac{\\partial L}{\\partial(\\partial_0\\Psi)} \\delta \\Psi \\right) = 0 \\end{equation}\n\nwe get three conserved quantites $Q_i$ from global $SU(2)$ symmetry, because the Lagrangian is invariant under infinitesimal transformations of the form $\\delta \\Psi = i a_i \\sigma_i \\Psi $. The conserved quantities that follow from the free doublet Lagrangian $L= i\\bar{\\Psi} \\gamma_\\mu \\partial^\\mu \\Psi$ are therefore\n\n\\begin{align} Q_i&= i\\bar{\\Psi} \\gamma_0 \\sigma_i \\Psi \\notag \\\\ &= \\begin{pmatrix} v_e \\\\ e \\end{pmatrix}^\\dagger \\underbrace{\\gamma_0 \\gamma_0}_{{=1}} \\sigma_i \\begin{pmatrix} v_e \\\\ e \\end{pmatrix} \\end{align}\n\nWhy are the conserved quantities that follow from $i=1$ or $i=2$, never mentioned or used? For $i=1$ we have\n\n\\begin{align} Q_1&= \\begin{pmatrix} v_e \\\\ e \\end{pmatrix}^\\dagger \\sigma_1 \\begin{pmatrix} v_e \\\\ e \\end{pmatrix} \\notag \\\\ &= \\begin{pmatrix} v_e \\\\ e \\end{pmatrix}^\\dagger \\begin{pmatrix} 0 & 1 \\\\1 & 0 \\end{pmatrix} \\begin{pmatrix} v_e \\\\ e \\end{pmatrix} \\notag \\\\ &= v_e^\\dagger e + e^\\dagger v_e \\end{align}\n\nor for $i=3$ we have\n\n\\begin{align} Q_3&= \\begin{pmatrix} v_e \\\\ e \\end{pmatrix}^\\dagger \\sigma_3 \\begin{pmatrix} v_e \\\\ e \\end{pmatrix} \\notag \\\\ &= \\begin{pmatrix} v_e \\\\ e \\end{pmatrix}^\\dagger \\begin{pmatrix} 1 & 0 \\\\0& -1 \\end{pmatrix} \\begin{pmatrix} v_e \\\\ e \\end{pmatrix} \\notag \\\\ &= v_e^\\dagger v_e - e^\\dagger e \\end{align}\n\nwhich is the usually used third component of weak isospin.\n\n  \u2022 4\n    $\\begingroup$ hint: how many generators of SU(2) can be simultaneously diagonalized? why might a diagonal generator lead to a more useful quantum number than a non-diagonal one? $\\endgroup$ \u2013\u00a0innisfree Nov 28 '14 at 15:09\n  \u2022 $\\begingroup$ $SU(2)$ has one Cartan generator. I'm not sure about your second question. Do you mean that diagonal operators can be measured at the same time and therefore only one of these three conserved quantities can be \"measured\" at the same time? Or: The objects in the doublet, here $v_e$ and $e$ are only eigenstates for the diagonal generator. For the other generators we can't assign a definitive number to $v_e$ and $e$, because they aren't eigenstates? $\\endgroup$ \u2013\u00a0jak Nov 28 '14 at 15:17\n  \u2022 1\n    $\\begingroup$ That is a convention. All 3 components can be equally chosen as a conserved quantity. Unfortunately, they cannot be measured simultaneously, so if you measure one of them and get the eigenvalue of that, the others won't be fixed. So it is conventional to only consider one component. $\\endgroup$ \u2013\u00a0Drake Marquis Nov 28 '14 at 15:50\n\nThe question is malformed. Noether's theorem is fine as a symmetry statement, but your gambit fails. In order for the charge you are discussing to exist, it must annihilate the vacuum of the theory, per the Fabri\u2013Picasso theorem. Failing that, it blows up ~ does not exist: the hallmark of SSB. I gather you may have misunderstood $Q_3$ presented as a conserved quantity, which it is not: Note the toxic minus sign instead of the plus of the valid lepton number! (In practice, a propagating left-handed electron couples/transmutes to a right-handed weak-isosinglet one through the mass term involving a Higgs v.e.v. As it were, it would \"absorb some $Q_3$ out of the EW vacuum\"\u2014an admittedly baroque caricature for a quantity that is ill-defined!)\n\nIn the standard model, all currents are conserved \u2014otherwise they would not couple consistently to gauge fields; but the final step you start from, i.e. the space integral of the current zero component, may or may not exist, as per the above caveat.\n\nIn the SM, of course, the EM charge, a linear combination $Q_3+Y$, where Y is the weak hypercharge does annihilate the vacuum (so it is unbroken) and thus exists!\n\nThe independent would-be charge whose current couples to the Z , $Q_3\\cos^2 \\theta_W-Y \\sin^2\\theta_W$, by contrast, does not, just like $Q_1,Q_2$. You do not see them written down, since few cherish shadow-boxing with phantoms.\n\nEdit: But... could you cheat? When? A qualmful fiddler might well object that, at the very least, Fermi's effective \u03b2-decay vertex, $G_F~ \\bar{n} \\gamma_\\mu P_L p ~ \\bar{\\nu} \\gamma ^\\mu P_L e$, or the current-current one for \u03bc decay, etc, preserve some $Q_3$ as a fine quantum number, after all: $$Q_3(n_L)=Q_3(p_L)+Q_3(\\bar{\\nu}_e)+Q_3(e_L)= 1/2 -1/2 -1/2=-1/2,$$ $Q_3(\\mu)=Q_3(e)+Q_3(\\nu_\\mu )+Q_3(\\bar{\\nu}_e)$, and so on. And this is not a coincidence. Could some $Q_3$ be somehow still useful as an approximate conservation law?\n\nIndeed, the EW Lagrangian, itself, and its effective avatars, do possess the SU(2)L symmetry as indicated, and unless a Higgs coupling were involved vertices are expected to respect this symmetry, at some level. Still, any Higgs interaction is liable to SSB contamination, such as in the fermion propagation, illustrated above, which spoils the symmetry. The answer then is \"with care\"\u2013caveat fiddler. Forensic excision of Higgs contamination effects would be a risky art.\n\n| cite | improve this answer | |\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/295300/recurrence-finding-asymptotic-bounds-for-tn-tn-2-n2\nText:\nTake the 2-minute tour \u00d7\n\nI've been working on a problem set for a bit now and I seem to have gotten the master method down for recurrence examples. However, I find myself having difficulties with other methods (recurrence trees, substitution). here is the question I am stuck on: $$T(n) = T(n-2) + n^2$$ Is there a pattern as follows? $$n^2 + T(n-2) + T(n-4) +...$$ where it goes until there is no more n left. so around n/2 times and would that mean that $$n^2 + (n-2)^2 + (n-i) ^2$$ so the asymptotic bound would be $\\theta(n^2)$?\n\nI am honestly taking a shot in the dark here, so I was hoping someone could help guide me in how to approach these questions.\n\nThank you,\n\n\nshare|improve this question\nperhaps an indirect answer would even do, something to show how to solve questions of form t(n-i) + f(n) \u2013\u00a0 Tyler Feb 5 '13 at 9:31\n\n2 Answers 2\n\n$$T(n) = T(n-2) + n^2 = T(n-4) + (n-2)^2 + n^2 = T(n-2k) + \\sum\\limits_{i = 0}^{k - 1}(n - 2i)^2$$\n\nThis goes down till $n - 2k \\ge 0$. Assuming even $n$ (for asymptotic complexity, it does not really matter, and you can do similar calculations for odd $n$ also, with the same asymptotic results), we have $k = \\frac{n}{2}$ at the end.\n\n$$T(n) = T(0) + \\sum\\limits_{i = 0}^{\\frac{n}{2} - 1}(n - 2i)^2 = \\sum\\limits_{i = 0}^{\\frac{n}{2} - 1}(n^2 - 4ni + 4i^2) + C$$ $$T(n) = n^2\\cdot\\left(\\frac{n}{2}-1\\right) - 4n\\cdot\\frac{1}{2}\\cdot\\frac{n}{2}\\cdot\\left(\\frac{n}{2} - 1\\right) + 4\\cdot\\frac{1}{6}\\cdot\\left(\\frac{n}{2} - 1\\right)\\cdot\\frac{n}{2}\\cdot n + C$$ $$\\therefore \\ T(n) = \\Theta(n^3)$$\n\nshare|improve this answer\n\nNote that if $n=2k$ is even, then $$ T(n)+T(n-1) = n^2+(n-1)^2+ \\cdots+4^2+3^2 + T(2)+T(1) =\\frac{n(n+1)(2n+1)}{6} + C. $$ Here $C=T(2)+T(1) -2^2-1^2$ and we used the formula $\\sum_{i=0}^n i^2 = \\frac{n(n+1)(2n+1)}{6}$. We also note that $T(n) \\sim T(n-1)$, so we may conclude that $$ T(n) \\sim n^3/12. $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://magic.aladdin.cs.cmu.edu/category/mathematics/combinatorics/\nText:\nCategory Archives: Combinatorics\n\nAn Annoying Combinatorial Problem\n\nHere is an \u201cinnocent\u201d combinatorial problem, with the best known bounds being very simple (but nobody managed to improve them since 1978). Disclaimer: the problem is very catchy (I struggled with it for quite a while), so do not read any further if, for example, you are writing a PhD thesis :-)\n\nMaker and Breaker alternatively select 1 and q edges of K_n (the complete graph on n vertices) until all edges have been claimed. Maker wins if his graph has a triangle. What is the smallest q=q(n) such that Breaker has a winning strategy?\n\nThe best known strategy for Maker is to claim edges incident to some vertex x (and never miss a one-step win). If Breaker managed to block x completely, say after m rounds, then Breaker made n-1-m + {m\\choose 2}\\le m q(n) moves. This implies that q(n) is approximately at least \\sqrt{2n}.\n\nOn the other hand, Breaker can win if q> 2\\sqrt{n}: for each edge xy claimed by Maker, Breaker selects \\sqrt{n} edges at x and \\sqrt{n} edges at y. Thus Maker\u2019s graph has maximum degree at most (n-1)/\\sqrt{n}+1 and Breaker can always block all immediate threats.\n\nReference: V.Chvatal and P.Erdos, Biased positional games, Ann. Discrete Math. 2 (1978), 221-229.\n\nI would bet on the \\sqrt{2n} bound :-)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/162301/normal-subgroups-of-p-groups?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a group of order $p^\\alpha$, where $p$ is prime. If $H\\lhd G$, then can we find a normal subgroup of $G/H$ that has order $p$?\n\nshare|improve this question\nNot if $H=G$. Otherwise, of course: order of $G/H$ divides order of $G$, so it's a power of $p$, so it has an element of order $p$, done. \u2013\u00a0 Gerry Myerson Jun 24 '12 at 7:59\nOk, I mistyped my question. I was wondering if we can find a normal subgroup of $G/H$ that has order $p$. \u2013\u00a0 youngtableaux Jun 24 '12 at 8:10\nI saw somewhere, if $|G|=m$ and $p$ is the smallest prime number dividing the order of $G$ then every subgroup of $G$ with index $p$ is normal in $G$. As Gerry noted; $|\\frac{G}{H}|=p^s$ for any $s$. I think by taking $m=p^s$ we can solve the problem. I hope it help. \u2013\u00a0 Babak S. Jun 24 '12 at 8:24\nI repeat: not if $H=G$. Other than that, I don't think $G/H$ differs form any other $p$-group. Does every finite $p$ group have a normal subgroup of order $p$? If so, then the answer t your question is yes. If no, let $A$ be a $p$-group with no normal subgroup of order $p$, let $G=A\\times B$ for some $p$-group $B$, then $1\\times B$ is normal in $G$, etc. \u2013\u00a0 Gerry Myerson Jun 24 '12 at 8:56\nIt may help you to note that finite non-trivial $p$-groups have non-trivial centers. \u2013\u00a0 Geoff Robinson Jun 24 '12 at 9:47\n\n1 Answer 1\n\nTheorem: a group $\\,G\\,$ of order $\\,p^n\\,,\\,p\\,$ a prime, $\\,n\\in\\mathbb N\\,$ , always has normal subgroup of order $\\,p^m\\,\\,,\\,\\,\\forall\\, m\\leq n\\,\\,,\\,m\\in \\mathbb N$\n\nProof: Exercise, using that always $|Z(G)|>1\\,$ and induction on $\\,n\\,$\n\nSo the comments by Gerry and Geoff close the matter.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296817/n-arcs-on-a-ring-which-are-either-blue-or-red-find-expectation-and-variance-of\nText:\nTake the 2-minute tour \u00d7\n\nThere are n distinct points marked on the ring, each of which is either blue or red with equal probabilities independently of each other. These n points divide the ring into n arcs. If an arc has both endpoints red, the arc is also considered red. If N is the number of red arcs, compute E[N] and var(N).\n\nI do not understand where to start this problem, I understand one will need to use indicators but how would one go about this? Also, The condition that if both end points are red then the arc is, is a bit confusing, how will this be utilized in solving the problem?\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nExplanation of problem: There are $n$ arcs. They are all \"short,\" just joining two consecutive points on the circle. We colour an arc red iff both of its endpoints are red. We are only interested in arcs, the colours of the points are irrelevant except insofar as they determine whether an arc will be coloured red or not. Or to put it another way, we want to count the situations in which we have two consecutive red points.\n\nSo for example the pattern BRRRB gives us $2$ red arcs. For further information about how indicator functions can be used, please read the first four lines only of the solution outline.\n\nOutline of solution: Call the points $P_1,P_2,\\dots,P_n$, with the understanding that $P_{n+1}=P_1$.\nSuppose they are arranged counterclockwise in that order around the circle.\n\nLet random variable $X_i$ be $1$ if $P_i$ is red and $P_{i+1}$ are red. Otherwise, let $X_i=0$.\n\nThen the number of $N$ of red arcs is $X_1+X_2+\\cdots+X_n$.\n\nThe expectation of this sum is the sum of the expectations. It should be easy for you to find $\\Pr(X_i=1)$, and hence $E(X_i)$.\n\nThe variance is more complicated. We use the fact that $\\text{Var}(N)=E(N^2)-(E(N))^2$.\n\nSo we need $E(N^2)$. Expand $(X_1+X_2+\\cdots +X_n)^2$. By the linearity of expectation, we need $E(X_i^2)$ and $E(X_iX_j)$. The first is no problem, since $X_i^2=X_i$. For the second, there is a need to distinguish between the cases where $P_i$ and $P_j$ are neighbours, and the cases where they are not.\n\nshare|improve this answer\n@Olivia, For Variance, you may expand it using covariance, and note that $Cov (V_i V_j) = 0 $ if $j\\neq i \\pm 1$, and calculate it otherwise. \u2013\u00a0 Calvin Lin Feb 7 '13 at 2:43\nthe direct expansion isn't hard. $Cov (V_i V_{i+1} ) = E[V_i V_{i+1}] - E[V_i]E[V_{i+1}] = \\frac {1}{8} - \\frac {1}{16} = \\frac {1}{16}$. So the variance is $\\sum Var (V_i) - 2\\sum Cov(V_i V_j) = \\frac {3n}{16} - \\frac {2n}{16} = \\frac {n}{16}$. \u2013\u00a0 Calvin Lin Feb 7 '13 at 2:45\n@CalvinLin: The procedure I suggested for variance uses only very basic machinery. Yours is smoother if the OP has some background. \u2013\u00a0 Andr\u00e9 Nicolas Feb 7 '13 at 2:50\nThe expectation of this sum is the sum of the expectations. It should be easy for you to find Pr(Xi=1), and hence E(Xi). This phrase,while helpful, does not help me, I am confused as to how to find out the probability, they give me I have n arcs each equally likely to be blue or red, so 1/2 chance blue or red right? The confusion is what the whole 2 ends being red condition comes in. otherwise I understand what you had up til there. Also can you be a little more explicit. I know this is quite trivial but I need to understand the reasoning behind the approach. \u2013\u00a0 Olivia Irving Feb 7 '13 at 2:56\n@Andr\u00e9Nicolas I thought that using of Indicator Variables would indicate knowledge of Expectation / Variance formulas, but apparently no necessarily. \u2013\u00a0 Calvin Lin Feb 7 '13 at 3:03\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/352570/martingale-not-uniformly-integrable?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nI've come across a statement that implies that non-negative martingales for which $\\{M_{\\tau}\\mid \\tau \\ \\rm{stopping} \\ \\rm{time}\\}$ is not uniformly integrable exist. I personally can't think of an example tho.\n\nI've considered gambling strategies and Brownian Motions but none seem to work.\n\nIs there anyone who can think of an example and help me understand the concept a bit more?\n\nBeen looking into this for a while now so help is much appreciated.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nLet $\\xi_j$ be i.i.d. with $\\mathbb{P}(\\xi=0)=\\mathbb{P}(\\xi=2)=1/2$, and define $M_n=\\prod_{j=1}^n \\xi_j$ for $n\\geq 0$. Then $(M_n)$ is a non-negative martingale with $\\mathbb{E}(M_n)=1$ for all $n$. But $M_n\\to 0$ almost surely, so $(M_n)$ cannot be uniformly integrable.\n\nshare|improve this answer\nI've considered this before but I came to the conclusion that the stopped proces $\\{M_{\\tau}\\mid \\tau \\ \\rm{stopping} \\ \\rm{time}\\}$ was UI. \u2013\u00a0 user70267 Apr 6 '13 at 7:16\n@user70267 Already the sequence $(M_n)_n$ is not UI, and the family $(M_\\tau)_\\tau$ contains it, hence... \u2013\u00a0 Did Apr 6 '13 at 10:46\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262115/why-are-hyperbolic-toral-automorphisms-e-g-arnolds-cat-map-ergodic\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\varphi : \\mathbb{T}^2 \\to \\mathbb{T}^2$ be a hyperbolic automorphism of the torus, induced by a linear map $A : \\mathbb{R}^2 \\to \\mathbb{R}^2$ of determinant $\\pm 1$ with no eigenvalues of modulus 1. What is an easy way to prove that $\\varphi$ is ergodic?\n\nIt's true that the stable and unstable manifolds at $(0,0) \\in \\mathbb{T}^2$ (projections of the eigenspaces of $A$ to the torus) are dense in the torus, which can be used to prove that such maps are topologically mixing. An example is Arnold's cat map.\n\nArnold and Avez show in Ergodic Problems in Classical Mechanics that Arnold's cat map is ergodic by proving that it has \"Lebesgue spectrum\", which implies that it is strong mixing, which implies that it is ergodic. Is there a more direct way to prove this?\n\nshare|improve this question\nA few weeks ago, someone here asked for a proof that these maps are chaotic. I found one in a textbook by Elaydi on discrete dynamical systems. The hardest part was proving the map transitive. \u2013\u00a0 Gerry Myerson Dec 20 '12 at 4:57\n@GerryMyerson I saw that thread. I found a simpler proof of a stronger statement (topologically mixing) in the book by Broer and Takens (proposition 2.15, page 111). But I don't see how topological transitivity or mixing can help me prove that these maps are ergodic. \u2013\u00a0 Ricardo Buring Dec 20 '12 at 11:25\nadd comment\n\n1 Answer\n\nI suggest using the following characterization of ergodicity:\n\n$\\varphi$ is ergodic if and only if every $f\\in L^2(\\mathbb{T}^2)$ such that $f\\circ \\varphi = \\varphi$ is constant function.\n\nNow let's use this criterion to prove $\\varphi$ is ergodic. Suppose $f\\in L^2$ with $f\\circ \\varphi = \\varphi$. Decompose $f$ into its Fourier series $$f = \\sum_{m,n\\in \\mathbb{Z}} = \\alpha_{(m\\,n)}e^{2\\pi imx}e^{2\\pi iny},$$ with coefficients $\\alpha_{(m\\,n)}\\in \\mathbb{C}$. Then, if $\\varphi$ is given by the matrix $$A = \\left(\\begin{matrix} a & b\\\\c & d\\end{matrix}\\right),$$ it is easy to compute that $$f\\circ \\varphi = \\sum_{m,n}\\alpha_{(m\\,n)}e^{2\\pi i(ma+nc)x}e^{2\\pi i(mb+nd)y}.$$ Since $f$ is invariant, the Fourier series for $f$ and $f\\circ \\varphi$ must agree, so $\\alpha_{(m\\,n)} = \\alpha_{(ma+nc\\,mb+nd)}$ for all $m,n\\in \\mathbb{Z}$. We can express this more simply as follows. If $v = (m\\,\\,n)\\in \\mathbb{Z}^2$, then $\\alpha_v = \\alpha_{vA}$. By iterating, $\\alpha_v = \\alpha_{vA^k}$ for each $k\\in \\mathbb{Z}$.\n\nSuppose that $v\\in \\mathbb{Z}^2$. Either the sequence $vA^k$ of vectors with integer coordinates is periodic, or else $\\|vA^k\\|\\to \\infty$ as $k\\to \\infty$. Note that the first case cannot happen unless $v = 0$, since if $v = vA^k$ for some $k$, then $A^k$ would have $1$ as an eigenvalue, which contradicts the assumption of hyperbolicity. Thus either $v = 0$, or $\\|vA^k\\|\\to \\infty$. Suppose $v\\neq 0$. Since $f\\in L^2$, the coefficients $\\alpha_{(m\\,n)}\\to 0$ as $\\|(m\\,\\,n)\\|\\to \\infty$, and thus $\\alpha_v = \\alpha_{vA^k}\\to 0$, i.e., $\\alpha_v = 0$. We have therefore shown that the only way $\\alpha_v$ can be nonzero is if $v = 0$. The Fourier series for $f$ is then $f = \\alpha_0$, so $f$ is a constant function.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/294969/show-that-the-given-series-for-z1-is-fracz1-z\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\nProve the following equation of complex power series.\n\nI must show for $|z|<1$ that $$\\sum_{k=0}^\\infty \\frac{z^{2^k}}{1-z^{2^{k+1}}} = \\frac{z}{1-z}.$$ I'm not really sure where to start or how to simplify the problem at all. Any help would be great.\n\nshare|improve this question\nWhat do you get for the partial sum $S_n$? Note that $(1-z^{2^{k+1}})=(1-z^{2^k})(1+z^{2^k})$. \u2013\u00a0 Calvin Lin Feb 5 '13 at 0:37\nadd comment\n\nmarked as duplicate by Micah, Cameron Buie, Calvin Lin, David Moews, Thomas Feb 5 '13 at 1:09\n\n\n1 Answer\n\nThis looks nasty, but with the following approach it should boil down to a straight forward calculation:\n\nYou can write the RHS as a power-series: $$\\frac{z}{1-z} = z \\sum_{k=0}^{\\infty} z^k = \\sum_{k=0}^{\\infty} z^{k+1}$$\n\nNow try to rewrite you LHS as power-series as well and compare the coeffecients: $$\\sum_{k=0}^{\\infty} \\frac{z^{2^k}}{1-z^{2^{k+1}}} = \\sum_{k=0}^{\\infty} \\left(z^{2^k} \\frac{1}{1 - z^{2^{k+1}}}\\right) = \\sum_{k=0}^{\\infty} \\left(z^{2^k} \\sum_{j=0}^{\\infty} \\left(z^{2^{k+1}}\\right)^j\\right) \\\\= \\sum_{k=0}^{\\infty} \\left(z^{2^k} \\sum_{j=0}^{\\infty} z^{2^{k+1}j}\\right) = \\sum_{k=0}^{\\infty}\\sum_{j=0}^{\\infty} z^{2^k + j2^{k+1}}$$\n\nTo see that both power-series are the same note that every $n \\in \\mathbb{Z}$, $n\\geq 1$ there exists unique integers $k$ and $j$ such that $n=2^k + j2^{k+1}$ (namely $2^k$ is the gratest power of $2$ which divides $n$).\n\nI guess there are more elegant ways to prove this, but since you didn't know how to start it might be usefull to see this approach.\n\nshare|improve this answer\nHow exactly does the LHS break down like that? That is the only part I can't follow. The step with the double summation throws me off \u2013\u00a0 Moses G Feb 5 '13 at 4:26\nI added two more steps to the calculation. I use the geometric series to rewrite the fraction as a power-series: $1/(1-w) = 1 + w^2 + w^3 + \\cdots$ with $w = z^{2^{k+1}}$. \u2013\u00a0 Sam Feb 5 '13 at 9:43\nadd comment"}
{"text": "Retrieved from http://www.mathworks.com/matlabcentral/answers/68186\nText:\nDiscover MakerZone\n\nMATLAB and Simulink resources for Arduino, LEGO, and Raspberry Pi\n\nLearn more\n\nDiscover what MATLAB\u00ae can do for your career.\n\nOpportunities for recent engineering grads.\n\nApply Today\n\nCan I solve this with Matlab Optimization Toolbox?\n\nAsked by GFX on 22 Mar 2013\n\nDear all,\n\nHi, I'm new to Matlab and also to optimization problems. I need help on an optimization problem. The problem is as follows:\n\nfind x=(est_pos_1, ... est_pos_n)\nminimizing the sum of squared difference between elements in matrix A and B\na_ij = 1 if Euclidean distance between est_pos_i and est_pos_j is less than constant R and 0 otherwise, 0 < i, j < m + n, m is number of points with known position, n of points with unknown positions to be estimated, b_ij = 1 if Euclidean distance between actual_pos_i and actual_pos_j is less than R and 0 otherwise. Matrix B is given.\n\nI tried solving it using Particle Swarm Optimization with poor success, i.e. the error between the estimated and actual positions is high.\n\n\nWalter Roberson on 22 Mar 2013\n\nThe two matrices A and B appear to be different sizes, as B only goes as far as the known positions but A extends to estimated positions. I am not sure what the sum of the squared difference would mean for different sized matrices?\n\nIf the values are all 0's and 1's, then squared difference would be the same as absolute difference, right? And in turn would be the same as \"not equal\" ?\n\nWhat does it mean to estimate position (i,j) for points whose actual position is known?\n\nGFX on 29 Mar 2013\n\nHi, the size of A an B are of the same size. However, instead of determine all m+n points, we are to decide only on the position of n unknown points, since the m points we already known their position from prior knowledge. We are to determine positions of est_pos_i (estimated positions of unknown points i, n of these) given some connectivity constrains, given by B. So, we are trying to recreate the position of all points based on connectivity readings. In actual, B can be obtained for e.g. say the points know who their neighboring points are. However, for simulation, B can simply be calculated by determining if the distances between the actual positions between any pair of points. In simulation, we also have the exact positions of all points. I hope I am clear. Thank you.\n\nGFX on 29 Mar 2013\n\nAnd the objective here is to recreate the configuration (positioning) of points that resembles the exact configuration. Hence the sum of square difference objective.\n\nThank you.\n\n\n\nNo products are associated with this question.\n\n1 Answer\n\nAnswer by Matt J on 29 Mar 2013\nEdited by Matt J on 29 Mar 2013\nAccepted answer\n\nNo, you can't use the Optimization Toolbox. The solvers in the Toolbox are smooth algorithms (except for bintprog) and therefore apply to differentiable functions.\n\nHowever, your matrix A, and therefore the objective function overall, is a piecewise constant, non-differentiable, function of x. The piecewise constant behavior will also mean that the objective function is flat almost everywhere, making almost every point a local minimum where the optimization can get stuck.\n\n\nGFX on 29 Mar 2013\n\nFor example, how do I easily and quickly determine if such a problem is say linear, convex, or non linear? I know about the standard forms of LP, convex programs and such, but for eg. in my original question, how do you determine them?\n\nMatt J on 29 Mar 2013\n\nWell, I don't think there's always an easy way. Certainly optimization textbooks will always give examples of functions that are convex etc... and you build your analysis skills from that.\n\nHowever, in your case, the A matrix can only take on values 0 or 1. Discrete-valued functions like that have to be piecewise constant.\n\nGFX on 31 Mar 2013\n\nThanks Matt J, thanks all. :-)\n\nMatt J\n\nContact us"}
{"text": "Retrieved from http://math.stackexchange.com/questions/197267/reducing-the-index-and-improper-fractions/198407\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to do the problem\n\n\nWhen you try to reduce the index for 40^4, its going to be 4/3. How does the index get reduced into 2x\u221a5x? I understand 3 cubed of 40, but what happens to the 4/3\n\nshare|improve this question\nIt's hard to understand what you have written. Do you mean $\\root3\\of{40x^4/y^9}$? \u2013\u00a0 Gerry Myerson Sep 17 '12 at 11:14\nadd comment\n\n1 Answer\n\nThe problem is not clear. I'm going to assume it's, simplify $$\\root3\\of{{40x^4\\over y^9}}$$ [$\\TeX$ aside --- that tiny 3 looks very strange --- if someone knows how to edit it to look nicer, be my guest]\n\nSo, let's work on it one piece at a time. $$\\root3\\of{40}=\\root3\\of{8\\times5}=\\root3\\of8\\times\\root3\\of5=2\\root3\\of5$$ Then, $$\\root3\\of{x^4}=\\root3\\of{x^3\\times x}=\\root3\\of{x^3}\\times\\root3\\of x=x\\root3\\of x$$ Finally, $\\root3\\of{y^9}=y^3$. Putting it all together, we get $$\\root3\\of{{40x^4\\over y^9}}={2x\\root3\\of{5x}\\over y^3}$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/239697/huffman-code-with-probabilities-p-1-p-2-ldots-p-n?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have solved the first two subsections of an assignment, but I can't solve the last subsection.\n\nWe have a Huffman code with probabilities $p_1,p_2,\\ldots, p_n$ and we know that $p_1>p_2>\\cdots>p_n>0$.\n\n$y_1$ - the code for the character whose probability is $p_1$? And $|y1|$ is the length of $y_1$.\n\nI proved that:\n\n  \u2022 if $|y_1| = 1$ then $p_1 \\geq 1/3$.\n  \u2022 if $p_1 < 1/3$ then $|y_1| \\geq 2$ (it is not the same as above).\n\nI can't prove:\n\n  \u2022 if $p_1 > 2/5$ then $|y_1| = 1$.\n\nThanks for all kind of help.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nSince you say it's an assignment I won't give you the full answer, but here's an orientation. You can build a proof by contradiction from two components: Dirichlet's principle and the construction of the Huffman tree.\n\nFirst prove that given that $p_1 = 2/5 + \\epsilon$ and $|y_1| > 1$ there must be a merge step where the words are partitioned into three disjoint sets: $\\{y_1\\}$, $A$, and $B$ such that the total probability of the words in $A$ is more than $p_1$ (and hence the total probability of the words in B is less than $1/5 - 2\\epsilon$).\n\nThen prove that the step which generated $A$ by merging the two smallest sets was performed incorrectly because $B$ was actually smaller than one of them.\n\nshare|improve this answer\nthank you, I solved this assignment an another way. \u2013\u00a0 Tatar Elem\u00e9r Nov 18 '12 at 22:30\nadd comment\n\nI use this:\n\nif p1 > 2/5 then at least one symbol is encoded by a codeword of length 1. (Hint: Suppose not and consider the vertices of the Hu\ufb00man tree which are distance 2 from the root.) Solution: Suppose not. This immediately implies that at distance 2 from the root of the encoding tree there are exactly 4 vertices, say a1, a2, a3, a4 with probabilities p1, p2, p3, p4 . One of these, say a1 corresponds to a1 or was obtained by merging it. It follows that p1 > p1 > 2/5. Suppose a3 and a4 are merged at the next step to form a new symbol a with probability p. Since a1 must be merged before the \ufb01nal step, we must have that p > p1 (otherwise we would merge a2 with a). Since also 2p2 > p3 + p4 = p > p1 and p1 + p2 + p = 1, we obtain that 1 > p1 + p1/2 + p1 = 5p1/2 > 5p1/2, a contradiction.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/171878/formula-obtained-by-using-trignometric-approximation-for-a-triangle-with-a-very/171893\nText:\nTake the 2-minute tour \u00d7\n\nI am reading a paper on the force between hooft polyakov monopoles, but I am completely baffled by one of the 'elementary trignometric' equation they have got using an approximation. Consider a triangle say triangle ABC. The author says that when A is very close to B, i.e. when $\\cos{C}\\approx 1$, we get $\\cos{C}-1=-\\frac{1}{2a^2}c^{2}\\sin^2{B}$. Please can anyone tell me, how has this been done. I am extremely sorry if this is a silly question.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nEDIT Hmm, the question changed while I was answering. See the 2. revision.\n\nWhen $A$ is close to $B$, we get a small $\\theta_2$. So a truncated Taylor series would look like $$\\cos{\\theta_2}-1=-\\frac{1}{2}\\theta_2^2\\; .$$ Now $\\theta_2\\approx \\tan \\theta_2=\\frac{r_1\\cos \\theta_1}{s}$, where $r_1\\cos \\theta_1$ is the projection of $r_1$ on the opposite side in a right triangle $AB'C$, with $B'$ being in $\\overline{BC}$, such that $AB' \\perp BC$.\n\nshare|improve this answer\nHey, thanks. This solves my question. Actually, the project of $r_1$ on the right angled triangle formed by dropping the perpendicular is $r_1 \\sin{\\theta_1}$. SO I get the required answer. Didnt think of using taylor expansion. How could I oversee it? \u2013\u00a0 ramanujan_dirac Jul 17 '12 at 11:06\n@ram: anytime somebody's talking about an \"approximation for small (something)\", it will likely involve the use of a Taylor/Maclaurin expansion. \u2013\u00a0 \uff2a. \uff2d. Jul 17 '12 at 11:16\nadd comment\n\nFrom the Law of Sines we get $c\\sin B=b\\sin C$, so the mystery conclusion can also be written $$ \\cos C -1 = -\\frac12 \\left(\\frac ba\\right)^2 \\sin^2 C $$ Note it is true in general that $\\cos \\theta -1 \\approx -\\frac12 \\sin^2\\theta$ for small angles $\\theta$ (this is a matter of comparing the Taylor approximations of the two sides).\n\nSo the important premise is not just that angle $C$ is small, but that points $A$ and $B$ are close to each other and therefore $\\frac ba\\approx 1$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/118626/real-symmetric-matrix-has-real-eigenvalues-elementary-proof/118640\nText:\nTake the 2-minute tour \u00d7\n\nEvery real symmetric matrix has at least one real eigenvalue. Does anyone know how to prove this elementary, that is without the notion of complex numbers?\n\nshare|improve this question\nThis is a very weird notion of \"elementary\", isn't it? Defining the complex numbers using the reals takes hardly more than 1 page. There is a real-analysis proof of the spectral theorem which never uses complex numbers; instead, it uses induction and Lagrange multipliers to find the maximum of $\\left|\\left|Ax\\right|\\right|$ over $x\\in S\\left(0,1\\right)$ (the sphere with center $0$ and radius $1$). This maximum is then shown to be an eigenvalue of $A$, and the vector $x$ for which the maximum is achieved is an eigenvector. ... \u2013\u00a0 darij grinberg Jan 11 '13 at 13:28\nWhat does \"has real eigenvalues\" mean? Apparently it is not to be understood as \"has no nonreal eigenvalues\", since mention of complex numbers is forbidden. Does it mean \"has at least one real eigenvalue\"? Does it mean: (where the size is $n \\times n$) \"has $n$ linearly independent eigenvectors with real eigenvalues\"? \u2013\u00a0 Gerald Edgar Jan 11 '13 at 14:16\nI'm with Gerald in not being sure exactly what the question's asking. By definition, the eigenvalues of a matrix over a field $k$ are elements of $k$. So strictly speaking, the question is trivial; looking for a nontrivial interpretation, I guess it must be one of the two possibilities that Gerald mentions. @Z254R: yes, I think Gerald is helping to formulate the problem. \u2013\u00a0 Tom Leinster Jan 11 '13 at 17:08\n@Z254R: As Gerald points out, it is still unclear whether by \"has real eigenvalues\" the OP means \"has at least one real eigenvalue\" or \"has $n$ real eigenvalues\". \u2013\u00a0 Mark Meckes Jan 11 '13 at 20:54\n@marjeta: the point is that we shouldn't have to spend time guessing exactly what your question means, which is what many of these comments are trying to do. You should make it clear what your question means. \u2013\u00a0 Tom Leinster Jan 12 '13 at 22:23\nshow 9 more comments\n\n9 Answers\n\nup vote 27 down vote accepted\n\nIf \"elementary\" means not using complex numbers, consider this.\n\n  1. First minimize the Rayleigh ratio $R(x)=(x^TAx)/(x^Tx).$ The minimum exists and is real. This is your first eigenvalue.\n\n  2. Then you repeat the usual proof by induction in dimension of the space.\n\n  3. Alternatively you can consider the minimax or maximin problem with the same Rayleigh ratio, (find the minimum of a restriction on a subspace, then maximum over all subspaces) and it will give you all eigenvalues.\n\nBut of course any proof requires some topology. The standard proof requires Fundamental theorem of Algebra, this proof requires existence of a minimum.\n\nshare|improve this answer\nAlexander, when you said that the minimum is an eigenvalue, did you mean to prove it by applying the Lagrange multiplier equation to the function $f(x)=x^tAx$ restricted to a level set of $g(x)=x^tx$, or did you have a different idea in mind? \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 23:56\nMarcos. In that case, you can prove the Lagrange multiplier relation hand: if $\\lambda$ is the minimum, then for every $y$, $(x+y)^TA(x+y)\\geq \\lambda (x+y)^T(x+y)$, that is, $2((y^T (Ax-\\lambda x)\\geq \\lambda y^Ty - y^TAy$. The LHS is homoegeneous of degree $1$, the RHS of degree $2$. So the LHS has to be zero for every $y$. This implies $Ax=\\lambda x$. \u2013\u00a0 ACL Jan 14 '13 at 0:15\nMarcos: yes. ACL's explanation is one way to do it. \u2013\u00a0 Alexandre Eremenko Jan 14 '13 at 21:31\nadd comment\n\nHow about Jacobi's proof?\n\nSee, e.g., Folkmar Bornemann, ``Teacher's Corner - kurze Beweise mit langer Wirkung,'' DMV-Mitteilungen 3-2002, Seite 55 (in German, sory). I don't have the original reference, sorry.\n\nThe idea is simple, define $\\Sigma(A)=\\sum_{i=1}^n\\sum_{j=i+1}^n a_{ij}^2$ for $A=(a_{ij})$ a symmetric real matrix. Then minimize the function $O(n)\\ni J \\mapsto \\Sigma(J^TAJ)$ over the orthogonal group $O(n)$. The function is continuous and bounded below by zero, and $O(n)$ is compact, so the minimum is attained. But it can not be strictly positive, because if there is an $a_{ij}\\not=0$, $i\\not=j$, then you can make it zero by a rotation that acts only on the $i$th and $j$th row and column, so that it decreases $\\Sigma$ (this is a simple little calculation with $2\\times 2$ matrices). Therefore the minimum is zero and it is attained in a matrix $J$ for which $J^TAJ$ is diagonal.\n\nThe eigenvalues of $A$ are now the (diagonal) entries of $J^TAJ$. No complex numbers are used, but you have to know that the minimum exists. We get the existence of an orthonormal basis consisting of eigenvectors with real eigenvalues.\n\nshare|improve this answer\nTo add a little more detail: The total energy $\\frac 12\\sum a_{ij}$, which is the sum of the energy on the diagonal and $\\Sigma$, is invariant by orthogonal conjugation, so we want to move it to the diagonal. When you apply a rotation $J$ in the plane spanned by the canonic vectors $e_i$ and $e_j$, which only affects the $i$th and $j$th rows and columns, the resulting coefficients $ii$, $ij$, $ji$, $jj$ of $J^tAJ$ depend only on the same coefficients of $A$, so the problem is reduced to increasing the energy on the diagonal of a $2\\times 2$ matrix. \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 2:00\nI meant $\\frac 12\\sum a_{ij}^2$. \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 14:21\nThis feels so wrong! :-) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 14 '13 at 4:29\nadd comment\n\nLet me give it a try. This one only uses the existence of a maximum in a compact set, and the Cauchy-Schwarz inequality.\n\nLet $T$ be a selfadjoint operator in a finite dimensional inner product space.\n\nClaim: $T$ has an eigenvalue $\\pm\\|T\\|$.\n\nProof: Let $v$ in the unit sphere be such that $\\|Tv\\|$ attains its maximum value $M=\\|T\\|$. Let $w$ also in the unit sphere be such that $Mw=Tv$ (which is like saying that $w=\\frac{Tv}M$, except in the trivial case $T=0$).\n\nThis implies that $\\langle w,Tv\\rangle=M$. In fact, the only way that to unit vectors $v$ and $w$ can satisfy this equation is to have $Mw=Tv$. (Since we know that $\\|w\\|=1$ and $\\|Tv\\|\\leq M$, the Cauchy-Schwarz inequality tells us that $|\\langle w,Tv\\rangle\\|\\leq M$, and the equality case is only attainable when $Tv$ is a scalar multiple of $w$, being $M$ the only possible value of the scalar.)\n\nBut by selfadjointness of $T$, we also know that $\\langle v,Tw\\rangle=M$, so that $Mv=Tw$.\n\nNow, one of the two vectors $v\\pm w$ is nonzero, and we can compute\n\n$T(v\\pm w)=Tv\\pm Tw=Mw\\pm Mv=M(w\\pm v)=\\pm M(v\\pm w)$.\n\nThis concludes the proof that $\\pm\\|T\\|$ is eigenvalue with eigenvector $v\\pm w$. The reality of the other eigenvalues can be proved by induction, restricting to $(v\\pm w)^\\bot$ as in the usual proof of the spectral theorem.\n\nRemark: The proof above works with real or complex spaces, and also for compact operators in Hilbert spaces.\n\nComment: I would like to know if this proof can be found in the literature. I obtained it while trying to simplify a proof of the fact that if $T$ is a bounded selfadjoint operator, then $\\|T\\|=\\sup_{\\|v\\|\\leq 1} \\langle Tv,v\\rangle$ (as found, for example, on p.32 of Conway J.B., \"An Introduction to Functional Analysis\"). In the case of non-compact operators, one can only prove that $T$ has as an approximate eigenvalue one of the numbers $\\pm\\|T\\|$. The argument is similar to the one above, but knowledge of the equality case of Cauchy-Schwarz is not enough. One has to know that near-equality implies near-dependence. More precisely, let $v$ be a fixed unit vector, $M\\geq 0$ and $\\varepsilon\\in[0,M]$. If $z$ is a vector with $\\|z\\|\\leq M$ such that $|\\langle v,z\\rangle|\\geq \\sqrt{M^2-\\epsilon^2}$, then it can be proved that $z$ is within distance $\\varepsilon$ of $\\langle v,z\\rangle v$.\n\nshare|improve this answer\nI don't see why this is different from Alexander Eremenko's answer. \u2013\u00a0 Deane Yang Jan 13 '13 at 22:10\nI don't understand Alexander's answer. How do you prove that if $R(x)=\\frac{x^tAx}{x^tx}$ is maximum, then $x$ is an eigenvector? I got nowhere by derivating $R$, and the only easy way that I see to complete his proof is to normalize $x$ to get a maximum of $x^tAx$ in the unit sphere, and then write the Lagrange multipliers equation that tells you that $x$ is an eigenvector. \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 23:35\nBut Lagrange multipliers is, in my opinion, different from the argument above, which in fact was originally designed to deal with bounded operators, as explained in the comment. Can Lagrange multiplier be used to prove that $\\pm\\|T\\|$ is an approximate eigenvalue of a bounded operator T? If not, is this enough to conclude that the proofs are different? \u2013\u00a0 Marcos Cossarini Jan 13 '13 at 23:45\nI think that the main difference is that Alexander extremises $x^tAx$ and I extremise $y^tAx$. That the two situations are not trivially equal is the subject of p.32 of Conway. \u2013\u00a0 Marcos Cossarini Jan 14 '13 at 0:33\nadd comment\n\nWe can do it in two steps.\n\nStep 1: show that if $A$ is a real symmetric matrix, there is an orthogonal matrix $L$ such that $A=LHL^T$, where $H$ is tridiagonal and its off-diagonal entries are non-negative. (Apply Gram-Schmidt to sets of vectors of the form $\\{x,Ax,\\ldots,A^mx\\}$, or use Householder transformations, which is the same thing.)\n\nStep 2. We need to show that the eigenvalues of tridiagonal matrices with non-negative off-diagonal entries are real. We can reduce to the case where $H$ is indecomposable. Assume it is $n\\times n$ and let $\\phi_{n-r}$ the the characteristic polynomial of the matrix we get by deleting the first $r$ rows and columns of $H$. Then $$ \\phi_{n-r+1} = (t-a_r)\\phi_{n-r} -b_r \\phi_{n-r-1}, $$ where $b>0$. Now prove by induction on $n$ that the zeros of $\\phi_{n-r}$ are real and are interlaced by the zeros of $\\phi_{n-r-1}$. The key here is to observe that this induction hypothesis is equivalent to the claim that all poles and zeroes of $\\phi_{n-r-1}/\\phi_{n-r}$ are real, and in its partial fraction expansion all numerators are positive. From this it follows that the derivative of this rational function is negative everywhere it is defined and hence, between each consecutive pair of zeros of $\\phi_{n-r-1}$ there must be a real zero of $\\phi_{n-r}$.\n\nshare|improve this answer\nMight it be done using eigenvalue interlacing on the original matrix rather than reducing to tridiagonal form first? \u2013\u00a0 Brendan McKay Jan 13 '13 at 5:54\nI can do it if I am allowed to use spectral decomposition. Write $A$ as $A_1 + bb^T$, where the first row and column of $A_1$ are both zero. (If needed replace $A$ by $-A$.) Then $$ \\det(tI-A) = \\det(tI-A_1-bb^T) = \\det(tI-A_1)\\det(I-(tI-A)^{-1}bb^T) $$ and since $\\det(I-uv^T)=1-v^Tu$, we get that $\\det(tI-A)/\\det(tI-A_1)$ is equal to $1-b^T(tI-A_1)^{-1}b$. Now use spectral decomposition to deduce that the numerators in $b^T(tI-A_1)^{-1}b$ are real. (This argument is logical, but it might not be a lot of fun in a classroom.) \u2013\u00a0 Chris Godsil Jan 13 '13 at 15:38\nadd comment\n\nThis is just the details of the first step of Alexander Eremenko's answer (so upvote his answer if you like mine), which I think is by far the most elementary. You only need two facts: A continuous function on a compact set in $R^n$ achieves its maximum (or minimum), and the derivative of a smooth function vanishes at a local maximum. And there's no need for Lagrange multipliers at all.\n\nLet $C$ be any closed annulus centered at $0$. The function $$ R(x) = \\frac{x\\cdot Ax}{x\\cdot x}, $$ is continuous on $R^n\\backslash\\{0\\}$ and therefore achieves a maximum on $C$. Since $R$ is homogeneous of degree $0$, any maximum point $x \\in C$ is a maximum point on all of $R^n\\backslash\\{0\\}$. Therefore, for any $v \\in R^n$, $t = 0$ is a local maximum for the function $$ f(t) = R(x + tv). $$ Differentiating this, we get $$ 0 = f'(0) = \\frac{2}{x\\cdot x}[Ax - R(x) x]\\cdot v $$ This holds for any $v$ and therefore $x$ is an eigenvector of $A$ with eigenvalue $R(x)$.\n\nshare|improve this answer\n(You could add this to his answer, probably) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 14 '13 at 4:26\nadd comment\n\nAnother elementary proof, based on the order structure of symmetric matrices. Let me first recall the basic definitions and facts to avoid misunderstandings: we define $A\\ge B$ iff $(A-B)x\\cdot x\\ge0$ for all $x\\in\\mathbb{R}^n$). Also, a lemma:\n\nA symmetric matrix $A$, which is positive and invertible, is also definite positive (that is, $A\\ge\\epsilon I$ for some $\\epsilon > 0\\, > $).\n\nWe may say, equivalently: if $A$ is positive but, for any $\\epsilon >0$, the matrix $A-\\epsilon I$ is not, then $A$ is not invertible. (A quick proof passes through the square root of $A$: $(Ax\\cdot x)=\\|A^{1/2} x\\|^2 \\ge \\|A^{-1/2}\\|^{-2} \\| x\\|^2$; one has to construct $A^{1/2}$ before, without diagonalization, of course).\n\nAs a consequence, $\\alpha^*:=\\sup_{|x|=1}(Ax \\cdot x)$ is an eigenvalue of $A$, because $ \\alpha^*I-A$ is positive and $\\alpha^*I-A-\\epsilon I$ is not (and $\\alpha _ *:=\\inf _ {|x|=1}(Ax \\cdot x)$ too, for analogous reasons).\n\nThe complete diagonalization is then performed inductively, as in other proofs.\n\nshare|improve this answer\nadd comment\n\nThis is quite an interesting question, perhaps a research problem. I think an elementary answer should be a high school algebra answer in the sense of Abhyankar and it would have to be in the spirit of what follows. But first a little story.\n\nI was teaching linear algebra and had just covered eigenvalues and characteristic polynomials but was not yet at the chapter on the spectral theorem for real symmetric matrices. I was looking for problems to assign for my students as homework in the textbook we were using. One of the exercises was to show that a real matrix $$ A=\\left[ \\begin{array}{cc} \\alpha & \\beta \\\\\\ \\beta & \\gamma \\end{array} \\right] $$ only had real eigenvalues. Not too hard. Write the characteristic polynomial $$ \\chi(\\lambda)=det(\\lambda I-A)=\\lambda^2-(\\alpha+\\gamma)\\lambda+\\alpha\\gamma-\\beta^2 $$ then its discriminant is $$ \\Delta=(\\alpha+\\gamma)^2-4(\\alpha\\gamma-\\beta^2)=(\\alpha+\\gamma)^2+4\\beta^2\\ge 0\\ . $$ Hence two real roots.\n\nThe next problem in the book was to do the same for $$ A=\\left[ \\begin{array}{ccc} \\alpha & \\beta & \\gamma\\\\\\ \\beta & \\delta & \\varepsilon \\\\\\ \\gamma & \\varepsilon & \\zeta \\end{array} \\right] $$ and (silly me) I also assigned it...\n\nHere is the solution in the 3X3 case. All roots are real if the discriminant (for a binary cubic) is nonnegative. The discriminant of the characteristic polynomial is $$ \\Delta = (\\delta \\varepsilon ^{2} + \\delta \\zeta ^{2} - \\zeta \\delta ^{2} - \\zeta \\varepsilon ^{2} + \\zeta \\alpha ^{2} + \\zeta \\gamma ^{2} - \\alpha \\gamma ^{2} - \\alpha \\zeta ^{2} + \\alpha \\beta ^{2} + \\alpha \\delta ^{2} - \\delta \\alpha ^{2} - \\delta \\beta ^{2})^{2} \\\\\\ \\mbox{} + 14(\\delta \\gamma \\varepsilon - \\beta \\varepsilon ^{2} + \\beta \\gamma ^{2} - \\alpha \\gamma \\varepsilon )^{2} \\\\\\ \\mbox{} + 2(\\delta \\alpha \\gamma + \\delta \\beta \\varepsilon + \\delta \\gamma \\zeta - \\gamma \\delta ^{2} - \\gamma \\varepsilon ^{2} + \\gamma ^{3} - \\alpha \\beta \\varepsilon - \\alpha \\gamma \\zeta )^{2} \\\\\\ \\mbox{} + 2(\\delta \\beta \\gamma + \\delta \\varepsilon \\zeta - \\varepsilon ^{3} + \\varepsilon \\alpha ^{2} + \\varepsilon \\gamma ^{2} - \\alpha \\beta \\gamma - \\alpha \\delta \\varepsilon - \\alpha \\varepsilon \\zeta )^{2} \\\\\\ \\mbox{} + 2(\\zeta \\alpha \\beta + \\zeta \\beta \\delta + \\zeta \\gamma \\varepsilon - \\beta \\varepsilon ^{2} - \\beta \\zeta ^{2} + \\beta ^{3} - \\delta \\alpha \\beta - \\alpha \\gamma \\varepsilon )^{2} \\\\\\ \\mbox{} + 14(\\zeta \\beta \\varepsilon - \\gamma \\varepsilon ^{2} + \\gamma \\beta ^{2} - \\alpha \\beta \\varepsilon )^{2} \\\\\\ \\mbox{} + 2(\\zeta \\beta \\gamma + \\delta \\varepsilon \\zeta - \\varepsilon ^{3} + \\varepsilon \\alpha ^{2} + \\varepsilon \\beta ^{2} - \\alpha \\beta \\gamma - \\alpha \\delta \\varepsilon - \\alpha \\varepsilon \\zeta )^{2} \\\\\\ \\mbox{} + 14(\\varepsilon \\beta ^{2} + \\zeta \\beta \\gamma - \\delta \\beta \\gamma - \\varepsilon \\gamma ^{2})^{2} \\\\\\ \\mbox{} + 2(\\zeta \\alpha \\beta + \\zeta \\beta \\delta + \\zeta \\gamma \\varepsilon - \\beta \\gamma ^{2} - \\beta \\zeta ^{2} + \\beta ^{3} - \\delta \\alpha \\beta - \\delta \\gamma \\varepsilon )^{2} \\\\\\ \\mbox{} + 2(\\alpha \\gamma \\zeta + \\zeta \\beta \\varepsilon - \\gamma ^{3} + \\gamma \\beta ^{2} + \\gamma \\delta ^{2} - \\delta \\alpha \\gamma - \\delta \\beta \\varepsilon - \\delta \\gamma \\zeta )^{2}\\ . $$\n\nThis formula comes from a paper by Ilyushechkin in Mat. Zametki, 51, 16-23, 1992.\n\nI suspect the elementary answer should be as follows. First find a list of invariants or covariants of binary forms $C_1,C_2,\\ldots$ such that a form with real coefficients has only real roots iff these covariants are nonnegative. Apply this to the characteristic polynomial of a general real symmetric matrix and show that you get sums of squares. I suppose these covariants, via Sturm's sequence type arguments, should correspond to subresultants or rather subdiscriminants. This seems also related to Part 2) of Godsil's answer.\n\nEdit: Another recent research reference which relates to the above sum-of-squares formula is the article The entropic discriminant by Sanyal, Sturmfels and Vinzant.\n\nEdit 2: I just found out that the problem I mentioned above has been completely solved! See Proposition 4.50 page 127 in the book by Basu, Pollack and Roy on real algebraic geometry. The connection with classical invariants/covariants of binary forms is not apparent but it is there: their proof is based on subresultants and subdiscriminants which are leading terms of $SL_2$ covariants.\n\nshare|improve this answer\nadd comment\n\nThe fact that real symmetric matrix is ortogonally diagonalizable can be proved by induction. The crucial part is the start. Namely, the observation that such a matrix has at least one (real) eigenvalue. But this can be done in three steps.\n\n(1) An easy observation (using direct matrix multiplication) shows that all columns of a matrix $\\mathbf{A}\\in\\mathbb{R}_{m\\times n}$ are orthogonal to any vector $z\\in\\mathbb{R}_{m\\times 1}$ iff $z$ belongs to the null space of the transpose $\\mathbf{A}^{\\sf T}$, i.e. $\\mathcal{N}(\\mathbf{A}^{\\sf T})=\\mathcal{R}(\\mathbf{A})^{\\perp}$.\n\n(2) If $\\mathbf{S}^{\\sf T}=\\mathbf{S}$ and $\\mathbf{S}x \\neq 0$ for every $x\\neq 0$, then the dot product $\\langle\\mathbf{S}x,x\\rangle\\neq 0$ for any $x\\neq 0$ as well. Otherwise, if $\\langle \\mathbf{S}z,z\\rangle=0$ for some $z\\neq 0$, then we have, using (1), $z\\in\\mathcal{R}(\\mathbf{S})^{\\perp}=\\mathcal{N}(\\mathbf{S}^{\\sf T})= \\mathcal{N}(\\mathbf{S})$, i.e. a contradiction $z\\ne0$ and $\\mathbf{S}z=0$.\n\n(3) If matrix $\\mathbf{A}=\\mathbf{A}^{\\sf T}\\in\\mathbb{R}_{n\\times n}$ has no (real) eigenvalue, then $(t\\mathbf{I}-\\mathbf{A})x\\neq 0$ for any $x\\neq 0$ and every $t\\in\\mathbb{R}$. Consequently, according to (2), we have $\\langle(t\\mathbf{I}-\\mathbf{A})y,y\\rangle\\neq 0$ for fixed $y\\neq 0$ and $t\\in\\mathbb{R}$. Therefore $t\\|y\\|^2 -\\langle\\mathbf{A}y,y\\rangle \\neq 0$ for every $t\\in\\mathbb{R}$, which is impossible.\n\nshare|improve this answer\nI'm confused by your (2)...doesn't putting $S=\\left(\\begin{array}{cc} 0 & 1 \\\\ 1 & 0\\end{array}\\right)$ and $z=\\left(\\begin{array}{c} 1 \\\\ 0\\end{array}\\right)$ give a counterexample? The statement that $\\langle Sz,z\\rangle=0$ isn't enough to imply that $z$ is orthogonal to the range. \u2013\u00a0 Mike Usher Jan 12 '13 at 18:40\nThank you for the comment. Unfortunately, the relation $z\\perp\\mathbf{S}z$ does not imply $z\\perp y$ for \\underline{every} $y\\in\\mathcal{R}(\\mathbf{S})$. I apologize for the false proof. Vito Lampret \u2013\u00a0 Vito Jan 13 '13 at 13:48\nadd comment\n\nJust found in Godsil-Royle's Algebraic graph theory: One first proves that two eigenvectors associated with two different eigenvalues are necessarily orthogonal to each other (pretty standard), then observes that if $u$ is eigenvector associated with eigenvalue $\\lambda$, then $\\bar u$ is eigenvector associated with eigenvalue $\\bar\\lambda$. Now the eigenvalues $\\lambda,\\bar\\lambda$ cannot be different, for otherwise by the above observation $0=u^T u=\\|u\\|^2$ although $u\\not=0$.\n\n(It does contain complex numbers, but is still amazingly straightforward).\n\nshare|improve this answer\nThis is what I would call the standard approach (going through operators on ${\\mathbb C}^n$) and as such I don't think it really fulfils the requirements of the original question. \u2013\u00a0 Yemon Choi Feb 26 '13 at 23:45\nYes, this is how an operator theorist would do it. But the question was also the existence of an eigenvalue (possibly without the fundamental theorem of algebra). Is there an argument for it too? \u2013\u00a0 Andr\u00e1s B\u00e1tkai Feb 27 '13 at 7:26\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/47421/qed-commutation-relations-implications\nText:\nTake the 2-minute tour \u00d7\n\nIn Brian Hatfield's book on QFT and Strings there is the following quote:\n\nIn particular $$ [A_i (x,t), E_j(y,t)] = -i \\delta_{ij}\\delta(x-y) $$ implies that $$ [A_i(x,t),\\nabla \\cdot E(y,t)] = -i\\partial _i \\delta(x-y).$$\n\nI'm not sure how to get between those lines. If I take the partial of the fist line I get $$ [\\partial_j A_i(x,t),E_j(y,t)] +[A_i(x,t),\\partial_jE_j(y,t)] = -i\\partial_i \\delta(x-y) $$ So perhaps my question turns into: \"Why is $[\\partial_j A_i(x,t),E_j(y,t)] = 0$ ?\" Thanks.\n\nshare|improve this question\nMaybe the partial is with respect to the y coordinate? \u2013\u00a0 twistor59 Dec 22 '12 at 23:07\nLol, of course. Thanks. \u2013\u00a0 k\u03b7ives Dec 23 '12 at 2:20\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's nothing strange going on. $\\partial_i$ is shorthand for $$\\frac{\\partial}{\\partial X^i},$$ where some coordinate set $X^i$ is implied. Since $E_j = E_j(y,t)$ you 'obviously' need to derive with respect to $y$ (as twistor59 notes), i.e. $$\\nabla \\cdot E = \\frac{\\partial}{\\partial y^i} E^i(y,t).$$ The derivative doesn't act on $A_i(x,t)$, so you're done.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/127546/is-the-solution-to-a-driftless-sde-with-lipschitz-variation-a-martingale\nText:\nTake the 2-minute tour \u00d7\n\nIf $\\sigma$ is Lipschitz, with Lipschitz constant $K$, and $(X_t)_{t\\geq 0}$ solves\n\n$$dX_t=\\sigma(X_t)dB_t,$$ where $B$ is a Brownian motion, then is $X$ a martingale? I'm having difficulty getting past the self-reference here. I tried showing that, for $t\\geq 0$, $\\mathbb{E}[X]_t$ is finite. Perhaps Gronwall's lemma is needed?\n\nThank you.\n\nshare|improve this question\nYou could try and have a look at Theorem 4.40 (b) (and the above definition 4.39) in Jacod and Shiryaev's Limit Theorems for Stochastic Processes. If we are in the scope of that Theorem then $(X_t)$ is in fact a square integrable martingale. \u2013\u00a0 Stefan Hansen Apr 3 '12 at 10:57\n@StefanHansen I'm away from a library at the moment. If this works, put it as an answer, and I'll find the book later. :) \u2013\u00a0 Ben Derrett Apr 3 '12 at 12:32\nadd comment\n\n2 Answers\n\nUnfortunately, it didn't work in general (not saying that your claim is false though). Here is what I was trying to do. Maybe it can help you come up with ideas, otherwise just nevermind it.\n\nLet $L^2(X)$ be the set of all predictable processes $H$ such that the process $(\\int_0^t H^2_s d\\langle X\\rangle_s)_{t\\geq 0}$ is integrable, where $(\\langle X \\rangle_t)_{t\\geq 0}$ denotes the predictable quadratic variation process.\n\nIn the following $\\mathcal{H}^2$ (resp. $\\mathcal{H}_{\\text{loc}}^2$) denotes the set of all square integrable martingales (resp. locally square integrable martingales). Then we have the following theorem from Jacod & Shiryaev:\n\nTheorem 4.40(b). Let $(X_t)_{t\\geq 0}\\in \\mathcal{H}_{\\text{loc}}^2$. Then $(\\int_0^t H_s d X_s)_{t\\geq 0} \\in \\mathcal{H}^2$ if and only if $H\\in L^2(X)$.\n\nObviously we are in the scope of this theorem as $(B_t)_{t\\geq 0}\\in\\mathcal{H}^2$ with predictable quadratic variation $\\langle B_t\\rangle = t$, $t\\geq 0$. Furthermore if $(X_t)_{t\\geq 0}$ is the solution to the SDE of the original post, i.e. $$ X_t=\\int_0^t \\sigma(X_s) dB_s,\\quad t\\geq 0, $$ then $(X_t)$ is adapted and continuous and hence it is a predictable process. The theorem now yields that $(X_t)_{t\\geq 0}\\in \\mathcal{H}^2$ if and only if $$ E\\left[\\int_0^t \\sigma(X_s)^2 d \\langle B\\rangle_s\\right]=E\\left[\\int_0^t \\sigma(X_s)^2 ds\\right]=\\int_0^t E\\left[\\sigma(X_s)^2\\right] ds<\\infty $$ holds for all $t\\geq 0$. Using the Lipschitz assumption we get a sufficient condition for $(X_t)$ being a square integrable martingale: $$ \\int_0^t E[|X_s|]ds<\\infty, \\quad t\\geq 0. $$\n\nshare|improve this answer\nadd comment\nup vote 0 down vote accepted\n\n\n$$[X]_t = \\int_0^t\\sigma(X_u)^2du,$$\n\n\n$$\\begin{align} \\mathbb{E}([X]_t) \\le \\int_0^t \\mathbb{E}\\left[(x_0 + K|X_u-x_0|)^2\\right]du.\\\\ \\end{align} $$\n\n$X$ is locally bounded in $L^2$. See, for example, Karatzas and Shreve equation 5.2.15 (p. 289). So it follows easily that $\\mathbb{E}([X]_t)<\\infty$, for each $t$. Hence $X$ is a martingale.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/72545/prove-textranka-geq-frac-texttra2-texttra2-when-a-is/72546\nText:\nTake the 2-minute tour \u00d7\n\nIf $A \\in \\mathbb{C}^{n \\times n}$ is a non-zero Hermitian matrix, I need to show that $$\\text{rank}(A) \\geq \\frac{(\\text{tr}(A))^2}{\\text{tr}(A^2)}$$ and reason out when the equality is attained?\n\nCan anyone help me in showing this result?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nYour matrix is diagonalizable to a diagonal matriz with real entries, when you diagonalize it, $\\mathrm{rank}A$, $\\mathrm{tr} A$ and $\\mathrm{tr} A^2$ do not change. This means that you can suppose that $A$ is real and diagonal to begin with.\n\nSo suppose $A=\\operatorname{diag}(\\lambda_1,\\dots,\\lambda_n)$ with the $\\lambda_i\\in\\mathbb R$. Then $\\operatorname{rank}A$ is the number of non-zero $\\lambda_i$s, $\\operatorname{tr}A=\\sum_i\\lambda_i$ and $\\operatorname{tr}A^2=\\sum_i\\lambda_i^2$. It follows that we are reduced to showing that\n\nif $\\lambda_1$, $\\dots$, $\\lambda_n$ are real numbers, then $\\big(\\sum_{i=1}^n\\lambda_i\\big)^2\\leq n\\sum_{i=1}^n\\lambda_i^2$.\n\nOne way to do prove this is to fix $r\\geq0$, compute the maximum $M$ of the function $f(\\lambda_1,\\dots,\\lambda_n)=(\\lambda_1+\\cdots+\\lambda_n)^2$ in the sphere $\\lambda_1^2+\\cdots+\\lambda_n^2=r$, and finally check that $M$ is equal to $nr$. This can be done easily using the method of Lagrange multipliers---it will, moreover, tell you where the maximum is achieved, and show when your inequality becomes an equality.\n\nshare|improve this answer\nRank of a matrix is linked to number of independent rows/ columns in the matrix, whereas trace is linked with sum of eigen values of the matrix. How do we link them? Also number of non-zero eigen value not necessary equals rank of a matrix! \u2013\u00a0 Learner Oct 14 '11 at 5:11\n@Learner But number of zero eigs equal to the rank drop no? \u2013\u00a0 user13838 Oct 14 '11 at 5:13\nMariano: (1) The blockquoted inequality is a case of Cauchy-Schwarz inequality. (2) Both the inequality itself and the equality case are direct once you note that RHS$-$LHS is $\\sum_{i,j}(x_i-x_j)^2$. \u2013\u00a0 Did Oct 14 '11 at 5:32\n@Didier: my favourite proof of C-S uses Lagrange multipliers, so there is no loss :) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Oct 14 '11 at 5:37\nSeems to me like a typical case of cracking nuts with a sledgehammer since, for example, no differential structure is involved, but as they say, gustibus non est disputandum... \u2013\u00a0 Did Oct 14 '11 at 5:42\nshow 2 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/140147/brownian-motion-convergence\nText:\nTake the 2-minute tour \u00d7\n\nIf $X$ is a standard 1d brownian motion and $M_t$ $= \\mbox{max}\\{X_S: 0 \\le s \\le t\\} $, what can we say about $M_t/t$ as $t \\rightarrow \\infty$?\n\nMainly, what can we say about the behavior of this martingale?\n\nMy attempt: P(Msubt > a) = 2P(B(t) >a), but what integral does this fit in with?\n\nshare|improve this question\nHint: The reflection principle gives that $M_t$ has the same distribution as $|B_t|$. \u2013\u00a0 Chris Janjigian May 2 '12 at 23:46\nSorry I used $B_t$ as my notation for a Brownian motion there. \u2013\u00a0 Chris Janjigian May 2 '12 at 23:52\nIt also might help you at some point when estimating the tail of the normal distribution that there is a really stupid bound: $e^{-x^2}\\leq xe^{-x^2}$ for $x$ large. \u2013\u00a0 Alex R. May 3 '12 at 0:27\nSo you are saying to use Hoeffdings inequality? will it help? \u2013\u00a0 mary May 3 '12 at 1:59\nPerhaps I was being too cryptic. Chris suggested that the distribution of $M_t$ is the same as $|B_t|$. You can easily calculate the probability that $|B_t|\\geq at$ for $a$ a positive constant, as a Gaussian integral but you'll need to do some estimates for how this \"tail\" probability behaves for large $t$. I believe my prior hint will help. \u2013\u00a0 Alex R. May 3 '12 at 2:53\nshow 2 more comments\n\n1 Answer\n\nSince $B_t$ is symmetric, the result recalled in the post reads $\\mathrm P(M_t\\gt at)=\\mathrm P(|B_t|\\gt at)$ $(\\ast)$.\n\nSince $B_t$ equals $\\sqrt{t}B_1$ in distribution, $(\\ast)$ is $\\mathrm P(|B_1|\\gt a\\sqrt{t})$. Since $|B_1|$ is almost surely finite and $a\\sqrt{t}\\to+\\infty$ for every $a\\gt0$, the last probability goes to zero, hence $\\mathrm P(M_t/t\\gt a)\\to0$ for every $a\\gt0$. That is, $M_t/t\\to0$ in probability.\n\nOne can strengthen this convergence, noting that the series $\\sum\\limits_n\\mathrm P(|B_1|\\gt a\\sqrt{n})$ converges since $\\mathrm P(|B_1|\\gt a\\sqrt{n})$ is $\\mathrm e^{-\\frac12a^2n+o(n)}$. By the first Borel-Cantelli lemma, $M_n/n\\to0$ almost surely when the integer $n$ goes to infinity. For every $t\\geqslant1$ there exists an integer $n\\geqslant1$ such that $n\\leqslant t\\lt n+1$, and $(M_t)_t$ is nondecreasing hence $M_t/t\\leqslant M_{n+1}/n\\leqslant 2M_{n+1}/(n+1)$. This proves that $M_t/t\\to0$ almost surely when the real number $t$ goes to infinity.\n\nThe same identity $(\\ast)$ shows the convergence in $L^p$ for every finite $p\\geqslant1$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/39426/computing-the-proportion-of-vectors-with-the-same-sign?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nLet $s \\propto (1, \\ldots, 1)$ be a d-dimensional unit vector, so that $s_i = 1 / \\sqrt{d}$. Let ${\\cal V} = \\{ u \\in {\\mathbb S}^{d-1}:u \\cdot s = \\cos \\theta \\}$ be a collection of unit vectors that form an acute angle with $s$. Suppose that $\\cos \\theta \\rightarrow 1$ as $d \\rightarrow \\infty$ at a rate to be specified below.\n\nI am interested in the following: what fraction of elements of ${\\cal V}$ have the same sign as $s$? Put another way, suppose that $U$ is uniformly distributed over ${\\cal V}$, then what is ${\\mathbb P}[\\cap_{i=1}^d\\{{\\rm sign}(s_i) = {\\rm sign}(U_i)\\}]$?\n\nIt is clear that when $d(1-\\cos^2\\theta) \\rightarrow 0$ that all elements of ${\\cal V}$ have the positive sign. However, I am not sure how to obtain a closed form solution when $d(1-\\cos^2\\theta) \\rightarrow \\infty$?\n\nshare|improve this question\nWhat do you mean by the 'sign' of a vector? \u2013\u00a0 Chris Taylor May 16 '11 at 15:38\n@Chris Taylor: I would guess that ${\\rm sign}((s_1,\\ldots,s_n))=({\\rm sign}(s_1),\\dots,{\\rm sign}(s_n))$. But that is just a guess. \u2013\u00a0 mac May 16 '11 at 17:07\n@Chris Taylor: I mean that sign is applied to each element of the vector and the equality holds element-wise. \u2013\u00a0 mkolar May 16 '11 at 21:50\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://www.math.hawaii.edu/~lee/algebra/history.html\nText:\nThe Origins of Abstract Algebra\n\nLee Lady\n\n\nI don't know of any other subject which is taught in such an anti-historical way as mathematics. Although mathematicians are often fairly scrupulous in giving credit to the original discoverers of theorems, they also are energetic in restating these theorems in terms of concepts which the original discoverers would have been completely unfamiliar with.\n\nWhen Emil Artin taught Galois Theory, he did apparently discuss Galois's own approach. He tells an anecdote to the effect that he asked one of his classes how much of his book on the subject Galois himself would have recognized, and one of his students suggested that probably the title would have been the only recognizable thing in the whole book. And then another student said, \"No, he probably would say, 'Okay, Galois, that's me, but who's this guy Theory?'\u00a0\"\n\nArtin's teaching in this respect was exceptional. In general, the teaching of mathematics gives students little way of understanding where mathematical ideas have come from and what the original motivation for the development of various mathematical topics was.\n\nGraduate students learn all sorts of high-powered concepts and theorems about Banach spaces, for instance, before they ever have any idea of why mathematicians ever got interested in such spaces or what the theory they are learning is good for. (Many students never do learn this.)\n\nIn my opinion this has a lot to do with the fact that today we see a splintering of mathematics into zillions of tiny little subspecialties, many of whose practitioners know almost nothing about any mathematics except their own little splinter.\n\nI am not a historian of mathematics by any means. Here, I simply present a brief sketch of the development of modern Algebra (sometimes called Abstract Algebra) taken from the book by Bourbaki, Elements of the History of Mathematics (French title, El\u00e9lements d'Histoire des Math\u00e9matiques).\n\n\nThe Axiomatic Approach\n\nThe birth of Algebra as mathematicians know it today is also the birth of the axiomatic approach to mathematics.\n\nWe generally don't teach students how revolutionary the axiomatic approach is. Typically, in an undergraduate course in Modern Algebra (what is often referred to as a Herstein level course), we simply take the axiomatic approach for granted from Day One. This approach is so familiar and so comfortable to a contemporary mathematician that we seldom give much thought about how bewildering it is to students whose previous experience of mathematics has been limited to courses like calculus. (However sometimes students have seen a little of the axiomatic approach in Linear Algebra, but with very little explanation about why it was ever decided to deal with a seemingly concrete topic like vector spaces in such an abstract way.)\n\nThe axiomatic approach is not simply a matter of using axioms in mathematics. The use of axioms, after all, goes back as far as Euclid.\n\nBut Euclid, before giving his axioms, starts out by defining the primitive notions of geometry. A point is defined as, roughly speaking, \"That which has position but no size.\" And a line is defined as, \"That which has length but no breadth.\" (I don't remember how Euclid goes about defining the concept of straightness. I don't think he defined a straight line as being the shortest distance between two points.)\n\nThe contemporary axiomatic approach, on the other hand, is basically the attitude that when we do mathematics, we don't need to know what the things we are working with are. We only need to know what the rules are. (So that in geometry, we don't need to know what a point or a line is. We only need to know the axioms.)\n\nThis is very different from the teaching of mathematics in grammar school and high school and college calculus courses. There, it is considered very important that students understand what numbers are (albeit in a way that to mathematicians is shockingly informal) and what addition, subtraction, and multiplication are, before learning the rules that enable one to actually do arithmetic. And it is very important to thoroughly master arithmetic before going on to represent it in symbolic form in high school algebra. And it is very important to be familiar with a number of specific examples of functions and to understand the concepts of differentiation and integration before going on to learn the rules which enable one to actually differentiate and integrate functions. (In fact, calculus teachers are often annoyed when students, inventing the axiomatic approach on their own, as it were, discover that it is not really necessary to understand the concepts in order to do the calculations.)\n\nBut a typical undergraduate course in Modern Algebra starts out saying something like, \"A group consists of a set of elements which can be multiplied in such as a way that the following three axioms are satisfied.\" (Four axioms if one includes closure, which was in fact the key axiom and to some extent was the only one in the original development of group theory, associativity and the existence of an identity element and inverses being taken as pretty much self-evident.)\n\nIt is understandable that a student might ask in bewilderment, \"But what are these elements? And how does this multiplication work?\" And the answer given by the Axiomatic Approach is, \"It doesn't matter. Only the rules matter.\"\n\nThis attitude, that it is possible to study things without knowing what one is talking about, is an incredible cognitive leap, and it is the real foundation (not the mathematical foundation, but the psychological foundation) of abstract mathematics.\n\nOf course in order to provide students with the sense that there is some tangible reality to what we are talking about, we immediately provide them with some familiar examples of groups (or rings, or whatever). And one strategy students might use when they can't cope with the level of abstraction they are given is to say, \"Okay, when the professor says 'group,' I'm going to think he's talking about the integers. And when he says, 'multiplication,' I'm going to think about addition.\"\u00a0 (I've used this strategy myself sometimes, when learning a new kind of mathematics.)\u00a0 But this strategy doesn't work very well. It's misleading, because any particular example will have a number of special properties that will not be true of groups in general. \u00a0(Addition of integers is commutative, for example, and the integers form a cyclic group.)\u00a0 And so if one needs to have concrete things to think about (and I think that almost all of us do), one needs to think not just in terms of one example, but in terms of a number of very dissimilar examples.\n\nAnd my own experience was that even after I got to be good at this sort of abstract thinking, I would still come to certain concepts (such as the concept of the free product of non-abelian groups, or that of the tensor product) that were so abstract and where it was so difficult to find any natural examples, that for quite a while I still found them very difficult to think about.\n\nBut here the axiomatic approach can rescue you on a higher level. You don't really need to think about what a free product or a tensor product actually is (\"what it looks like,\" in my words). You simply need to find a set of axioms that describe the way it behaves. \u00a0(This has become pretty much the standard way of thinking about tensor products, and I always felt a sort of contempt for mathematicians who proved theorems about tensor products by starting with the construction.)\n\nThis is certainly one advantage of the axiomatic approach: that one can work with quite complicated objects (and most mathematical constructions, even the natural numbers, are actually quite complicated) without needing to think about what they \"look like.\"\u00a0 But the primary advantage of the approach is that usually a single set of axioms will describe a very large number of vastly dissimilar mathematical systems, and so by starting from axioms, one can prove theorems that apply to a huge number of different things. \u00a0(Most of us don't make a big point of using the axiomatic characterization of the real numbers, for instance, because the field of real numbers is the only mathematical thing to which that complete set of axioms applies.)\n\n\nBut how did this revolutionary new way of mathematical thinking come about?\n\nIt came about, actually, in a very gradual and somewhat natural way. It came about because over the course of the 19th century, mathematicians started becoming more and more interested in a new kind of subject matter having to do with algebra, but not algebra in the sense of solving equations (although the interest in solving algebraic equations was certainly one of the roots of this new interest). But rather this was algebra in more or less the sense we use the word today (but without thinking of it in abstract terms), namely the study of structures in which one could work in very much the same way that traditional algebra operates in the realm of rational numbers, real numbers, or complex numbers. Some of these structures were: the complex numbers, the quaternions, various algebraic number rings (certain subrings of the complex numbers), in addition to the algebra of matrices developed by Sylvester and Cayley and the algebra of logic developed by Boole. In addition, there was the study of permutation groups, which was originally not thought of as being algebra at all, I believe, but where the basic concepts were developed by Legendre, Abel, and Galois as an approach to understanding the solution of algebraic equations.\n\nAll of these subjects were originally studied for very natural and practical reasons having to do with questions in geometry, analysis, number theory, and the theory of equations.\n\nWhat was new about all these subjects was the interest primarily in the structure as a whole, rather than in doing calculations within that structure. This was perhaps especially clear in the work of Legendre, Abel, and Galois on permutation groups, where what was important was the set of subgroups rather than the individual permutations.\n\nBourbaki identifies three main streams leading to the development of modern Algebra: \u00a0(1)\u00a0The theory of algebraic numbers, developed by Gauss, Dedekind, Kronecker, and Hilbert. \u00a0(2)\u00a0The theory of groups of permutations (and, later, groups of geometric transformations), where the work of Galois and Abel was fundamental. \u00a0(3)\u00a0The development of linear algebra and hypercomplex systems.\n\nGroup Theory\n\nThe study of permutation groups was used by Lagrange in the first attempt to develop what would later become Galois Theory. It was Galois who in 1832 later defined the concept of a normal subgroup, a solvable group, and asserted the existence of Sylow subgroups, although apparently without proof. (On the other hand, Galois did not use the concept of a field.)\n\nBut as group theory was further developed by other mathematicians (Galois himself, of course, was killed in a duel, apparently because of his political activism, immediately after finishing his treatise), gradually it started becoming clear that the study of permutation groups actually had very little to do with permutations themselves.\n\nAnd Jordan in 1868 began the study of infinite groups, specifically groups consisting of transformations of geometric space. This study was continued by Felix Klein and Poicar\u00e9, and was especially encouraged by Felix Klein's Erlanger Program for geometry. (At this point, there were a number of different kinds of geometry, such as Euclidean geometry, non-Euclidean geometry, projective geometry, affine geometry, and differential geometry. Klein suggested that each particular form of geometry should be characterized as the study of those properties which are invariant under a particular group of transformations. For instance, Euclidean geometry consists of the study of those geometric properties which are not changed by rigid motions.)\u00a0 The concepts and theorems which had been developed for permutation groups applied just as well to these groups of transformations.\n\nBy the late 19th century, Cayley and Dedekind and many other mathematicians were becoming very aware that what was really relevant in group theory was the law of composition (multiplication) in a group and not the nature of the objects making up the group.\n\nBut the importance of groups at this point still had to do with their concrete applications. Groups were still seen as consisting of operators of some sort and Dedekind and Cayley stopped short of defining groups in an axiomatic way and seeing them as structures which were of interest for their own sake.\n\nAlgebraic Number Theory and the Rise of Commutative Ring Theory\n\nThe theory of algebraic numbers (which was initiated by Gauss) was primarily developed in connection with attempts to prove Fermat's Last Theorem. Lagrange, Euler, and Gauss had seen that an approach to proving this is to notice that the left-hand side of the equation \u00a0x^p + y^p = z^p\u00a0 factors completely if one allows the use of the pth root of \u00a0-1, which is of course a complex number. (It's adequate to deal with the case where p is prime and of course different from 2.)\u00a0 It is commonly believed that this is the proof that Fermat himself had in mind. But the proof is flawed, because it depends on the assumption that factorization into prime factors is unique, even when algebraic numbers are involved. But this is not always true, as one can see from the example,\n(1 + \\sqrt{-5})(1-\\sqrt{-5})\u00a0=\u00a0(2)(3),\n\nwhere it is easy to prove that none of four factors in these two decompositions can be further decomposed into products within the ring consisting of all numbers of the form a + b\\sqrt{-5}, with \u00a0a\u00a0 and \u00a0b\u00a0 ordinary integers. (Here \u00a0\\sqrt{-5}\u00a0 is used to denote the square root of \u00a0-5\u00a0, which is, of course, a complex number.)\n\nThe theory of algebraic numbers was further developed by Dirichlet, Hermite, Kummer, Kronecker, and Dedekind. Kronecker and Dedekind used two different methods (which although very dissimilar are ultimately equivalent) to introduce of certain \"ideal numbers\" into algebraic number rings to remedy the lack of unique factorization. Dedekind's method was the invention of what we today call, in an arbitrary ring, ideals. In his work, Dedekind basically established the foundations of modern commutative ring theory. However the methods of Dedekind and Kronecker fell short of providing a proof of Fermat's Last Theorem, although they did enable proofs in many special cases.\n\nThe other main thread leading to modern commutative ring theory came from algebraic geometry, and I won't really discuss that here except to mention that mathematicians were becoming very aware that the algebra of functions defined on an algebraic curve or surface had a great deal in common with algebraic number rings. Here we see that importance of the fact that mathematicians working in what originally seemed very different specialties were familiar with each others work and influenced by it. (There existed still a third major example of commutative rings, namely those consisting of functions defined by power series.)\n\nBourbaki identifies the 142 page article by Steinitz in 1910 titled The Algebraic Theory of Fields as having given birth to the modern concept of Algebra. (One can also note that much earlier, Peano, in 1888, gave the axiomatic definition of a real vector space and defined the concept of a linear transformation between vector spaces.) The word field had first been used by Dedekind, whose concern was with certain fields contained within the complex numbers (algebraic number fields). And it was Dedekind and Hilbert who had first seen Galois Theory as a correspondance between subfields and subgroups of the Galois group. (Dedekind was the first to think of the Galois group as consisting of the automorphisms of the field extension rather than permutations of the roots of the polynomial in question.)\n\nSteinitz in his 1910 article developed the notions of prime field (by this time there had been a lot of work on the theory of finite fields), separable extension, and transcendence degree, and proved that every field has an algebraically closed extension. But what makes his article thoroughly modern is that instead of defining a field as a set of complex numbers or congruence classes or the like, Steinitz simply defined a field to be a structure consisting of a set of elements in which two operations are defined (to be referred to as addition and multiplication) satisfying a certain set of rules.\n\nThe concept of a ring was first used by Dedekind, who used the word \"order\" (or rather, of course, its German equivalent, \"ordnung.\")\u00a0 The word \"ring\" (which is actually the same in German and in English) was introduced by Hilbert. The point is that in an algebraic number ring (or any finite integral extension of a base ring), if one looks at the powers of an element then one finds a point where subsequent powers can be expressed as linear combinations of the preceding ones. Thus the multiplication in a certain sense turns back on itself in a way that is somewhat like a geometric ring.\n\nBut it was not until 1914 when the first paper where the general notion of a ring is defined axiomatically: \"On Zero Divisors and Decomposition of Rings,\" by Fraenkel. Although this gave the general definition, the paper itself was concerned with commutative artinian local rings where the unique prime ideal is principal.\n\nIn the same year, 1914, Hausdorff in his Grundz\u00fcge der Mengenlehre, gave an axiomatic definition of general topology. Of course this was a time when algebraists, analysts, and topologists talked to each other, were interested in each other's work, were influenced by each other, and in many cases were actually the same individuals.\n\nThe Theory of Algebras (Hypercomplex Systems)\n\nThe starting point for third stream in the development of algebra was Hamilton's invention of the quaternions. (Complex numbers had been used in algebra by the Italian algebraists since roughly 1550 and by 1800 the theory of calculus using complex variables was fairly well developed, by Cauchy and others. It was Gauss who introduced the geometric representation of complex numbers.)\n\nIn 1878, Frobenius proved that the quaternions were the only possible (finite-dimensional) associative extension of the complex numbers in which division was possible and the only (finite-dimensional) non-commutative extension of the real numbers in which division was possible. This was independently proved two years later by C. S. Pierce. (Gauss had been convinced that the field of complex numbers was the only finite dimensional commutative field extension of the real number system. This was subsequently proved by Weierstrass.)\n\nLater Cayley noted that there exists a set of two by two matrices satisfyiing the multiplication table of the quaternions. (The concept of a matrix is due to Sylvester, who introduced matrices as a shorthand for substitutions of variables, i.e.\u00a0what we now call linear transformations.) But not until about 1870 was it noted, by the Americans B. Pierce and C.S. Pierce, that the set of square matrices of a given size form an algebraic system which permits addition, subtraction, and multiplication (i.e., in modern terminology, a ring).\n\nThe term \"an algebra\" seems to have been used by the Americans and British in pretty much its modern sense, i.e. a ring which is a finite-dimensional vector space over the complex numbers (or real numbers). On the other hand, the Germans generally preferred the term \"hypercomplex system.\" Aside from Hamilton's quaternions, the main example before 1850 was Grassman's \"exterior algebras,\" but the analogy to the quaternions and other algebras was only much later seen.\n\nOther examples of algebras over the complex numbers were seen during the period 1850 to 1860, but the general study of algebras (and thus the roots of non-commutative ring theory) begins only in 1870 in the work of B. Pierce and C.S. Pierce, who introduce the concepts of idempotent and nilpotent elements and the decomposition of an idempotent element into a sum of orthogonal primitive idempotents.\n\nCayley and Sylvester and other British and American mathematicians then started working on the problem of classifying algebras of small dimension over the complex numbers.\n\nDuring this time, the development of Lie groups and algebras (which are non-associative) was proceeding and some of the fundamental concepts in the theory of associative algebras (the concept of the radical, for instance) were developed first for Lie algebras.\n\nAnother key source of ideas and examples was the concept of a group algebra, which had been essentially defined by Dedekind in 1896, in a letter to Frobenius. Dedekind was very clear on the relation of this to the general theory of algebras, although the theory of group representations as developed by Burnside and Schur (around 1905) did not at that time explicitly use ring-theoretic methods.\n\nThe concept of a simple algebra over the complex numbers had been defined in 1893 by the German mathematician T. Molien, who then proved the first version of the Wedderburn Theorem, i.e.\u00a0that a simple algebra over the complex numbers is isomorphic to the ring of n by n matrices over the complex numbers. It was at this point that the concept of a two-sided ideal became current and a lot of theorems were proved about them. But it is not clear from the Bourbaki survey whether the word \"ideal\" was originally used, and it is possible that the analogy to Dedekind's work on commutative rings was not immediately seen.\n\nThe concept of a semi-simple algebra was introduced by Elie Cartan. (Unfortunately, I don't have a date.)\n\nThe development around 1900 of the theory of finite fields by the American mathematicians E. H. Moore and L. E. Dickson was what motivated the generalization of the theory of algebras to the case where the base field was unrestricted. Wedderburn, another American, in 1905 proved that every finite skew field (a.k.a. division algebra) is in fact commutative.\n\nIn 1903, in a memoir on the algebraic solution of differential equations, Poincar\u00e9 had defined the concepts of left ideal and right ideal for an algebra. (As mentioned, two-sided ideals had been essentially known since Molien's paper in 1893.) In this memoir, Poincar\u00e9 proves that the minimal left ideals in the ring of n by n matrices have dimension n. However this result was not noticed by the algebraists.\n\nThe notions of left and right ideals were rediscovered in 1907 by Wedderburn, who proved that the radical was the largest nilpotent left ideal and proved his well known \"Wedderburn Theorem\" (later generalized by Emil Artin) which states that every semi-simple algebra over an arbitrary base field is a direct product of matrix rings over skew fields.\n\nIn 1920, Emmy N\u00f6ther and W. Schmeidler used the concepts of left and right ideal in a paper devoted to rings of differential operators. But otherwise, these concepts were ignored after Wedderburn's paper until 1927, when Emmy N\u00f6ther, and Brauer (and later A.A. Albert and Hasse) resumed the study of them.\n\nBy 1934, the basic theory of semi-simple rings was essentially complete.\n\n\nBourbaki's summary statement is, \"The axiomatization of algebra was begun by Dedekind and and Hilbert, and then vigorously pursued by Steinitz (1910). It was then completed in the years following 1920 by Artin, N\u00f6ther and their colleagues at G\u00f6ttingen (Hasse, Krull, Schreier, van der Waerden).\u00a0 It was presented to the world in complete form by van der Waerden's book (1930).\"\n\nWhat we see from all this (at least in my view) is that the development of modern Algebra was never motivated by mathematicians seeking abstraction for its own sake. Instead, algebraists working on quite concrete problems were trying to invent tools that might help with their investigation of these problems, and slowly (very slowly, as we look at their work in retrospect) began to notice that the same logical patterns recurred over and over again in different examples."}
{"text": "Retrieved from http://math.stackexchange.com/questions/112411/solving-the-system-sum-sin-sum-cos-0/113612\nText:\nTake the 2-minute tour \u00d7\n\nCan we solve the system of equations:\n\n$$\\sin \\alpha + \\sin \\beta + \\sin \\gamma = 0$$\n\n$$\\cos \\alpha + \\cos \\beta + \\cos \\gamma = 0$$\n\n\n(i.e. find the possible values of $\\alpha, \\beta, \\gamma$)\n\nshare|improve this question\nadd comment\n\n5 Answers\n\nup vote 11 down vote accepted\n\nTry something similar to what has been posted yet. Take one variable to the other side, then square and add the equations. What you get is $\\alpha-\\beta=120\u00b0$ and same for cyclic permutations (or negating all angles). The solutions is the three angles $\\delta$, $\\delta+120\u00b0$, $\\delta-120\u00b0$ (arbitrary $\\delta$) in any order.\n\nEDIT: Or simply realize that the equations are equivalent to $\\exp(i\\alpha)+\\exp(i\\beta)+\\exp(i\\gamma)=0$ which make the answer immediately obvious.\n\nshare|improve this answer\nadd comment\n\nDeveloping on Gerenuk's answer, you could consider the complex numbers\n\n$$ z_1=\\cos \\alpha+i\\sin \\alpha,\\ z_2=\\cos \\beta+i\\sin\\beta,\\ z_3=\\cos \\gamma+i\\sin \\gamma$$\n\nThen you know that $z_1,z_2,z_3$ are on the unit circle, and the centroid of the triangle formed by the points of afixes $z_i$ is of afix $\\frac{z_1+z_2+z_3}{3}=0$. From classical geometry, we can see that if the centroid of a triangle is the same as the center of the circumscribed circle, then the triangle is equilateral. This proves that $\\alpha,\\beta,\\gamma$ are of the form $\\theta,\\theta+\\frac{2\\pi}{3},\\theta+\\frac{4\\pi}{3}$.\n\nshare|improve this answer\nadd comment\n\nTry writing $$ \\sin^2(\\alpha)=(\\sin(\\beta)+\\sin(\\gamma))^2=\\sin^2(\\beta)+\\sin^2(\\gamma)+2\\sin(\\beta)\\sin(\\gamma)\\tag{1} $$ and $$ \\cos^2(\\alpha)=(\\cos(\\beta)+\\cos(\\gamma))^2=\\cos^2(\\beta)+\\cos^2(\\gamma)+2\\cos(\\beta)\\cos(\\gamma)\\tag{2} $$ then add $(1)$ and $(2)$ to get $$ 1=1+1+2\\cos(\\beta-\\gamma)\\tag{3} $$ which means $\\cos(\\beta-\\gamma)=-\\frac12$. The same is true for the other pairs, so we get that each of $\\alpha$, $\\beta$, and $\\gamma$ differ from each other by $\\frac{2\\pi}{3}$, which is the same answer that was achieved using complex means already.\n\nshare|improve this answer\nNice Answer without complex numbers. \u2013\u00a0 user21436 Feb 26 '12 at 15:25\nadd comment\n\nHere's an algebraic proof : Write $z_k = e^{i \\alpha_k}$. Then your equations are equivalent to $z_1 + z_2 + z_3 = 0$. Write $\\theta = \\frac{\\alpha_1 + \\alpha_2 + \\alpha_3}{3}$ and $z = e^{i \\theta}$\n\nExpand the polynomial $P = (X-z_1)(X-z_2)(X-z_3)$. The $X^2$ term is $0$ by hypothetis, and the $X$ term can be written as $z_1 z_2 z_3 (z_1^* + z_2^* + z_3^*) = 0$. So $P = X^3 - z_1 z_2 z_3 = X^3 - z^3$. So the roots are $z . e^{2i k \\pi /3}$.\n\nshare|improve this answer\nadd comment\n\nMore of a comment and less of an answer!\n\nWell, your information seems to tell us that,\n\n\n(To see this, square both equalities and add.)\n\nI don't see any other obvious thing, you can do with these equations. If any thought plops up, I will type it in here.\n\nshare|improve this answer\nYour relation should be with $\\alpha-\\beta,\\beta-\\gamma$ and $\\gamma-\\alpha$ \u2013\u00a0 Beni Bogosel Feb 23 '12 at 17:58\n@BeniBogosel I am sorry for having made that blunder. Thanks for the pointer. That the answer has posted, I'll flag it for the moderator to make it CW. \u2013\u00a0 user21436 Feb 24 '12 at 8:01\nYour result follows from my answer which shows that $$\\cos(\\alpha-\\beta)=\\cos(\\beta-\\gamma)=\\cos(\\gamma-\\alpha)=-\\frac12$$ \u2013\u00a0 robjohn Feb 26 '12 at 23:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/208851/need-a-tip-hint-evaluating-a-limit?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI have the following limit:\n\n\nwhere $0<b<a$.\n\nI care for the case where $\\epsilon>-1/2$. I suspect that for $\\epsilon>0$ this limit evaluates to 1, and for $-1/2<\\epsilon\\leq0$ it evaluates to 0. However, I am having hard time evaluating this. I have tried taking the log of the expression (moving the $x$ in the exponent down), substituting $y=1/x$ and then Taylor-expanding the log, but didn't get anywhere.\n\nDoes anyone have any tips/hints that might help me evaluate this?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nSince $c=1/2+\\varepsilon\\gt0$, one knows that $1-\\exp(-bx^{-c})\\sim bx^{-c}$ and $\\log(ax^{-c})\\sim-c\\log(x)$ when $x\\to+\\infty$. Thus, the function to be evaluated is $$ f(x)=(1-kg(x))^x,\\quad k=abc\\gt0,\\quad g(x)\\sim x^{-2c}\\log x. $$ Since $g(x)\\to0$ and $\\log(1+u)\\sim u$ when $u\\to0$, $$ f(x)=\\exp\\left[x\\log(1-kg(x))\\right]=\\exp\\left[-kxg(x)\\cdot(1+o(1))\\right]. $$ Note that $xg(x)\\sim x^{-2\\varepsilon}\\log x$ and recall that $k\\gt0$. This yields:\n\n  \u2022 If $-1/2\\lt\\varepsilon\\leqslant0$, then $xg(x)\\to+\\infty$ hence $f(x)\\to0$ when $x\\to+\\infty$.\n  \u2022 If $\\varepsilon\\gt0$, then $xg(x)\\to0$ hence $f(x)\\to1$ when $x\\to+\\infty$.\nshare|improve this answer\nSo it turns out I made a mistake in the original definition of the problem: I flipped the plus sign after the first 1 to a minus sign when I was typing this up (I've edited the question since I saw your answer and my mistake). However, you solved the problem that I originally had in mind (otherwise the minus in $-c\\log(x)$ would've flipped the minus in your re-definition of $f(x)=(1-kg(x))^x$ to a plus). Thank you, this confirms my intuition (which was backed up by numerical evaluations)! \u2013\u00a0 M.B.M. Oct 8 '12 at 5:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/122257/finding-the-formula-for-bezier-curve-ratios-hull-point-point-baseline\nText:\nTake the 2-minute tour \u00d7\n\nGiven a cubic Bezier curve defined by points p\u2081, p\u2082, p\u2083, and p\u2084, a point B on that curve at some t value (where 0 \u2264 t \u2264 1), a point A on the line (p\u2082p\u2083) at distance ratio t from p\u2082, and a point C that is the intersection of the line (p\u2081p\u2084) and the line that goes through A and B, the ratio between distance d1 = (AB) and d2 = (BC) is a fixed value, regardless of the values for coordinates p\u2081, p\u2082, p\u2083, and p\u2084\n\nI'd like to find the formula that expresses this ratio as a function of t (all interactive graphing experiments suggest that this function is an identity function for cubic Bezier curves, not actually being dependent on the coordinates used for the curve) but I'm having little success coming up with something satisfactory. My math skills are not sufficient...\n\nI initially wrote up a quick data-generator using the \"Processing\" programming language to see if I could use that data for polynomial regression (based on the fact that the function is symmetrical around t = 0.5, finding the expression for the interval t=0.5 to t=1), but the fact that the ratio is actually asymptotic at t = 0 and t = 1 (towards positive infinity) means that it's not a straight-forward power function.\n\ncurve parameter -> ratio plot.\n\n(note: the jsfiddle link doesn't actually log all 5000 step values; normal Processing does)\n\nWould anyone know how to express this ratio function as a proper formula? I don't quite know how to approach this symbolically, as I'm using de Casteljau's algorithm to determine my red and green lines; since I don't know how to symbolically express the values d1 and d2, expressing the ratio d1/d2 as a function is quite hard.\n\nN.B.: Apologies if the tags don't fit the question. I'll take suggestions on using the right ones instead; first question on MathOverflow.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nA cubic bezier defined by $p_1, p_2, p_3, p_4$ has parametric equation $$B(t) = (1-t)^3p_1 + 3(1-t)^2tp_2 + 3(1-t)t^2p_3 + t^3p_4.$$\n\nThe setup here also defines $A(t) = (1-t) p_2 + tp_3$.\n\nThe way $C$ is defined, there are some real $s(t)$ and $u(t)$, both possibly depending on $p_1,\\ldots,p_4$ such that $C = sA + (1-s)B = up_1 + (1-u)p_4$.\n\nSo $B - C = B - sA - (1-s)B = s(B-A)$. Hence $\\frac{|B - C|}{|A - B|} = |s|$.\n\nOn the other hand, we want $sA + (1-s)B - up_1 - (1-u)p_4 = 0$. That comes out to\n\n$$((1-s)(1-t)^3 - u)p_1 + (s(1-t) + 3(1-s)t(1-t)^2)p_2 + (st + 3(1-s)t^2(1-t))p_3 + ((1-s)t^3 - (1-u))p_4 = 0.$$\n\nSet $$s = \\frac{t^3+(1-t)^3-1}{t^3 + (1-t)^3}$$ and $$u = \\frac{(1-t)^3}{t^3 + (1-t)^3}.$$\n\nThen the coefficents of $p_1,\\ldots,p_4$ in the above expression become identically 0. Note that the denominators of these expressions are never 0 for $t \\in [0,1]$, so the divisions are ok.\n\nSo your ratio is given by the $|s|$ above (or its reciprocal, depending on how you're taking the ratio).\n\nshare|improve this answer\nyou are a hero, thanks! \u2013\u00a0 Mike 'Pomax' Kamermans Feb 19 '13 at 18:34\nadd comment\n\nJust in case someone finds this question using google at some point, and is also curious about the solution for the quadratic case, its solution is similar:\n\n$A(t) = p_2$\n\n$B(t) = (1-t)^2p_1 + 2t(1-t)p_2 + t^2p_3$\n\n$C(t) = sA(t) + (1-s)B(t) = up_1 + (1-u)p_2$\n\nThis requires solving:\n\n$$sp_2 + (1-s)((1-t)^2p_1 + 2t(1-t)p_2 + t^2p_3) - up_1 + (1-u)p_2 = 0$$\n\nwhich, expressed in terms of the control points, is:\n\n$$((1-s)(1-t)^2 - u)p_1 + (s+2t(1-s)(1-t))p_2 + ((1-s)t^2 + u - 1)p_3 = 0$$\n\nIf we want these coefficients to become identically zero, we can determine s(t):\n\n$$(1-s)(1-t)^2 = u = -((1-s)t^2 - 1)$$\n\nwhich means solving:\n\n$$(1-s)(1-t)^2 + ((1-s)t^2 - 1) = 0$$\n\nwhich gives us the following expressions for s and u (after substituting s into either of the identities for u and solving):\n\n$$s(t) = \\frac{2t^2 - 2t}{2t^2 - 2t + 1}$$\n\n$$u(t) = \\frac{(t-1)^2}{2t^2 - 2t + 1}$$\n\n(Also note that there are no solutions for curves of order 4 and higher; unlike for quadratic and cubic curves, the ratio between the two distances is not a fixed value for higher order curves, unfortunately)\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/241795/show-that-there-cannot-be-an-entire-function-f-that-satisfy-the-following-cond\nText:\nTake the 2-minute tour \u00d7\n\nShow that there cannot be an entire function $F$ such that $F(x) = 1-\\exp(2\\pi i/x)$ for $1 \\leq x \\leq 2$. I think this has got something to do with Rouche's Theorem or the Argument Principle, but I'm not sure how to apply either of these to this specific problem. Can anyone shed some light?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nIf $F(x)=1-\\exp(2\\pi i/x)$ for $1\\leq x\\leq 2$ and $f$ is entire, then in fact that equality holds over the whole of $\\Omega=\\mathbb C\\setminus\\{0\\}$. Indeed, the two sides of the equality are holomorphic functions on the connected set $\\Omega$ which coincide in a set which accumulates inside $\\Omega$.\n\nNow you should be able to check that there is no entire function which coincides with $1-\\exp(2\\pi i/x)$ on all of $\\Omega$.\n\nshare|improve this answer\nCan you elaborate a bit more? I don't understand why the equality has to hold over the punctured complex plane. \u2013\u00a0 Aden Dong Nov 21 '12 at 18:54\nSee the \u00abimprovement\u00bb section in this Wikipedia page. This should be done in all complex analysis textbooks. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Nov 21 '12 at 19:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/131336/help-with-this-diophantine-equation\nText:\nTell me more \u00d7\n\nNote: This question was posted in error, and should be closed as no longer relevant. The correct question is posted at Help with this system of Diophantine equations (End of note)\n\nFor a research problem that I'm working on, I need to solve this Diophantine equation:-\n\n$a^3+b^3+c^3-3d=-83449$, where $a,b,c,d>0$ are all DISTINCT positive integers and$ a,b,c\u2209 ${$2,9,15,16,33,34$}.\n\nHow does one go about solving this? Is brute-force the only possible way? Or could there be a case that no integer solutions exist for this equation?\n\nAlso, are there any online computing engines, that allow me to set constraints, and solve Diophantine equations of this sort?\n\nAny and all help is appreciated! Thanks!\n\nshare|improve this question\nYour conditions imply a is less than 70, and from this you can get small bounds on b and c. This is well within a brute force search with a laptop, and you can use digital considerations and perhaps a table of cubes to do much of the search by hand. Gerhard \"Ask Me About System Design\" Paseman, 2013.05.21 \u2013\u00a0 Gerhard Paseman May 21 at 13:49\n@Gerhard: Why do the conditions imply that $a < 70$? \u2013\u00a0 Stefan Kohl May 21 at 13:55\nStefan, I made the mistake of assuming b and c were both larger than a. I see now that there is no bound on $a^3$ when it is larger than one of the cubes. There are some restrictions mod 3 on b-a and c-a, but they don't seem as useful now. Gerhard \"Missed It By A Lot\" Paseman, 2013.05.21 \u2013\u00a0 Gerhard Paseman May 21 at 14:50\nThank you guys, for the replies! But sorry to say, my original equation was at fault. I've edited the question now. \u2013\u00a0 Jobin Idiculla May 21 at 15:15\nThis question (in its original form) was posted at\u2026 -- @Jobin, please do not cross-post the same question at both sites -- it can result in unnecessary duplication of effort. (It is sometimes OK to do so, if time has passed and you haven't gotten an answer at math.stackexchange, but even then you should say so and include the link.) \u2013\u00a0 Barry Cipra May 21 at 15:59\nshow 5 more comments\n\n3 Answers\n\nFor $0 < a \\le3966887 $ solutions are $(9419, 10418, 8146),(69167, 10776, 87090)$ and (added) $(3966887, 2434179, 4797573)$.\n\nHere is an idea for searching. Loop $a$ from $1$ to certain bound.\n\nYou have to solve $x^3 + y^3 = C + 2 a^3 = N$. This is easy to solve if $N$ can be factored since $x^3+y^3$ factors nicely.\n\nAdded to the edited question\n\nYou have to solve $ a^3+b^3+c^3 + 83449 = 3 d $\n\nJust pick \"random\" $a,b,c$ such the the lhs is divisible by $3$ like $(300,301,304)$ and $d=27482938$\n\nHere is a pari/gp script which found the solutions.\n\n if(v == [],next);\nshare|improve this answer\nI just realized I'd made a huge mistake in my assumptions for the problem. Subsequent calculations reveal my required Diophantine equation to be a^3 + b^3 + c^3 - 3d = -83449. Here, 'd' is also a positive integer, but NOT subjected to the constraint that d be in {2,9,15,16,33,34}. Could you help solve this, please? \u2013\u00a0 Jobin Idiculla May 21 at 15:07\nDo you mean \"that $d$ not be in\"? \u2013\u00a0 Joel Reyes Noche May 21 at 15:30\nI'm terribly sorry for troubling you again, joro. I'd committed a blatant \"freshman\" error again. I've newly posted the question I'd actually meant to ask here:-\u2026 \u2013\u00a0 Jobin Idiculla May 21 at 16:03\nadd comment\n\nSorry for a long comment. Joro has given a nice answer already. Writing $36650=b^3+c^3-a^3-a^3$, the question is related to the problem which numbers can be represented by the sum of $4$ signed cubes. A result of Demjanenko says that all numbers not of the form $9n \\pm 4$ are representable as a sum of four signed cubes. Indeed, all integers $n\\le 10^7$ have such a representation, and for $n$ sufficently large the representation also exists (see the artcle Kenji Koyama, On searching for solutions of the Diophantine equation $x^3 + y^3 + 2z^3 = n$ , Math. Comput. 69 (2000).\n\nEDIT: the new equation seems to be $a^3+b^3+c^3=n=3d-83449$. The conjecture is that this has solutions if and only if $n$ is not of the form $9k\\pm 4$.\n\nshare|improve this answer\nNot sure if this is correct, check the counterexamples in my answer. \u2013\u00a0 joro May 21 at 15:03\nSorry guys for the trouble, but my question was in error. I've edited it accordingly now. \u2013\u00a0 Jobin Idiculla May 21 at 15:18\nFrom (\"On partitions into four cubes\" by Moreno and Palma): Demjanenko [7] proved that every number $n \\nequiv \\pm4 \\mod 9$ can be expressed as the sum of four positive or negative cubes: $x^3 + y^3 + z^3 + w^3$. \u2013\u00a0 Barry Cipra May 21 at 15:36\nsorry, that \"\\nequiv\" was meant to be a $\\not\\equiv$. \u2013\u00a0 Barry Cipra May 21 at 15:38\nadd comment\n\nLet a,b,c satisfy the restrictions given, as well as $1 + a + b + c $ is a multiple of $3$. Then $83449 + a^3 + b^3 + c^3$ is also a multiple of 3, and then $d$ can be chosen to be $1/3$ of the last quantity.\n\nGerhard \"3D Makes It So Easy\" Paseman, 2013.05.21\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/351623/does-an-mid-bn-imply-a-mid-b\nText:\nTell me more \u00d7\n\nDoes $a^n \\mid b^n$ imply $a\\mid b$? I think it does but haven't been able to prove it. I don't know much number theory so an elementary answer would be great.\n\nshare|improve this question\nHint: Look at prime factors. \u2013\u00a0 Brett Frankel Apr 5 at 0:29\nYou can start with the fundamental theorem of arithmetic. \u2013\u00a0 julien Apr 5 at 0:30\nConsider this. Might I call yhis a duplicate? Since they end up in asking the same question. \u2013\u00a0 awllower Apr 5 at 13:32\n@awllower: you're right that it's a duplicate, but I think this one has better answers. \u2013\u00a0 Javier Badia Apr 5 at 14:16\n@JavierBadia Probably because the previous one prohibited the use of GCD and UFD. \u2013\u00a0 awllower Apr 5 at 15:01\nadd comment\n\n3 Answers\n\nup vote 6 down vote accepted\n\nIf you can assume the fundamental theorem of arithmetic (that each integer has a unique factorization in prime numbers), you can write: $$ \\begin{align*} a &= p_1^{e_1} p_2^{e_2} \\ldots p_r^{e_r} \\\\ b &= q_1^{d_1} q_2^{d_2} \\ldots q_s^{d_s} \\end{align*} $$ Here the $p_i$, $q_i$ are primes, and $e_i$ and $d_i$ are all greater than 0. If $a^n \\mid b^n$, then $p_i^{n e_i}$ must have a counterpart in a $q_j^{n d_j}$, in that $p_i = q_j$ and $n e_i \\le n d_j$, so it must then also be that $e_i \\le d_j$; and this means $a \\mid b$.\n\nshare|improve this answer\nadd comment\n\nHint $\\ $ Either examine exponents in unique prime factorizations, or, by the Rational Root Test, the reduced rational root $\\rm\\:x = b/a\\:$ of $\\rm\\:x^n = c\\in\\Bbb Z\\:$ must be integral, so $\\rm\\:b/a\\in\\Bbb Z\\:\\Rightarrow\\:a\\mid b.$\n\nshare|improve this answer\n@Peter For that, after cancelling any common factor, one needs only $\\rm\\:(a,b)=1\\:\\Rightarrow\\:(a,b^n)=1,\\:$ true by iterating Euclid's Lemma. Thus $\\rm\\:1 < a\\nmid b^n,\\:$ so $\\rm\\:a^n\\nmid b^n.\\ \\ $ \u2013\u00a0 Math Gems Apr 5 at 0:41\nYes, that was my idea. I was awfully unclear, sorry. \u2013\u00a0 Pedro Tamaroff Apr 5 at 0:44\nadd comment\n\nHint: $p$ is a prime factor of $k$ if and only if $p^n$ is a factor of $k^n$. This holds for any prime $p$, integer $k$, and positive integer $n$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/63491.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nMean Latitude/Longitude\n\nDate: 07/10/2003 at 14:21:30\nFrom: Peter Richard\nSubject: Spherical Trigonometry\n\nIf we have three points on the earth measured in latitude/longitude, \nsuch as 'A'= 33S54;151E12 / 'B'= 37S49;144E58 / 'C'= 51N30;0W10 \nwhat is the formula to calculate a mean latitude/longitude for this \ngroup of 3?\n\nWhen I say 'mean latitude/longitude' I am referring to a 'midpoint in \nspace' between the three. So perhaps if I used the term 'equidistant' \nrather than 'mean' it might make it clearer.\n\nDate: 07/15/2003 at 14:47:57\nFrom: Doctor Rick\nSubject: Re: Spherical Trigonometry\n\nHi, Peter.\n\nI might approach this as follows: \n\nConvert the lat-long positions into x,y,z coordinates, find the mean \nposition in 3-dimensional space, and project this point back onto the \nsphere, and convert back to latitude and longitude. (I am assuming - \nand hoping - that a spherical approximation to the earth's surface \nis sufficient.)\n\nThis method will give the correct result in the \"flat-earth \napproximation\" in which the points are close enough together that the \ncurvature of the earth can be ignored. It seems like a reasonable \noperational definition of an average position on the earth, but I'm \nbeing rather intuitive at this point.\n\nTo convert each location to (x,y,z) coordinates, use the formulas\n\n  x_n = cos(lat_n)*cos(lon_n)\n  y_n = cos(lat_n)*sin(lon_n)\n  z_n = sin(lat_n)\n\nwhere location n has latitude lat_n and longitude lon_n. I have set \nthe radius of the earth equal to 1 since we aren't interested in \nactual distances; the radius would cancel out eventually anyway.\n\nAverage the coordinates independently:\n\n  x = (x_1 + x_2 + x_3)/3\n  y = (y_1 + y_2 + y_3)/3\n  z = (z_1 + z_2 + z_3)/3\n\nNow convert to latitude and longitude using the inverse transformation\n\n  lat = arcsin(z/r)\n  lon = arctan(y/x)\n\nI haven't tested this, so let me know if you have any trouble with \nit. If you're programming, you should use the atan2() function found \nin many programming languages, spreadsheets etc. Otherwise you'll \nhave to do some extra stuff if x = 0 or if the longitude is more than \n90 degrees from the Prime Meridian.\n\nThe \"mean\" in any ordinary sense can be quite different from the \npoint that is equidistant from three points. To demonstrate, draw a \ncircle and pick three points on the circle, all on the right side. \nThe point that is equidistant from the three points is the center of \nthe circle. I doubt that this is what you mean by \"mean\"! (However, \nit could be what you want: If you expect a structure to be circular \nand you have found three points on the edge of the structure, you \ncould use such a method to find the center of the structure.)\n\n- Doctor Rick, The Math Forum\nAssociated Topics:\nHigh School Higher-Dimensional Geometry\nHigh School Trigonometry\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/9551/concentration-of-measure-for-gaussian-inner-products?sort=votes\nText:\nTake the tour \u00d7\n\nThere exists extensive theory for the concentration of Gaussian measure. Through that, it can be easily proved that the square of the $\\ell_2$ norm of a length $n$ zero mean Gaussian vector ${\\bf x}$ with covariance matrix ${\\bf I}_n$ is concentrated around $n$ with overwhelming probability. Such a result also follows immediately from the Restricted Isometry Property that holds for Gaussian matrices. I was wondering if any concentration results could be inferred for inner products of Gaussian i.i.d random variables. Namely, if $\\Pr(|{\\bf x}{\\bf y}|<\\alpha)$ is overwhelming (or exponentially vanishing in $n$) for some meaningful $\\alpha$.\n\nshare|improve this question\nYour notation isn't clear. Do you want a concentration result for ${\\rm Pr}(| |\\langle x,y\\rangle| - \\mu | < \\epsilon$? Where $\\mu$ is say a mean or median and $x$ and $y$ are independent Gaussian vectors? If so, this is a standard result. \u2013\u00a0 Steve Flammia Dec 22 '09 at 17:39\nI was looking for $\\Pr(||\\langle x,y\\rangle|-\\sqrt{n}|<\\epsilon)$ and x,y are i.i.d Gaussian zero mean vector with covariance matrix the identity of size $n\\times n$ \u2013\u00a0 anadim Dec 22 '09 at 17:54\nyes, this is true for any alpha> pi/2 \u2013\u00a0 Gil Kalai Dec 22 '09 at 18:26\nOne way to say it is that most ponts in the sphere are near the equator. (You can assume x is the north pole.) This follows from the formulas for volumes of spherical caps. \u2013\u00a0 Gil Kalai Dec 22 '09 at 18:28\nGil, you should post this as an answer! \u2013\u00a0 Greg Kuperberg Dec 23 '09 at 6:58\nadd comment\n\n2 Answers\n\nIf you have 2 standard Gaussians in $\\mathbb{R}^n$, their inner product is the sum of $n$ i.i.d. variables, with their common distribution fixed (and having finite moments), so you will get convergence to the appropriate Gaussian distribution in line with the central limit theorem, with exponential bounds coming from Hoeffding's inequality, say. Do you need tight bounds or asymptotics is enough?\n\nshare|improve this answer\nAlso, what Gil Kalai said: testing for $|\\langle x,y \\rangle|<\\alpha$ is with high probability in $x$ testing for $y$ to fall within a layer of width $2\\alpha/\\sqrt{n}$ centered around the origin, so up to an exponentially decaying error you get $2\\Phi\\left(\\frac{\\alpha}{\\sqrt{n}}\\right)$, so you will get exponential bounds for $\\alpha >> \\sqrt{n \\log n}$. \u2013\u00a0 Thorny Dec 23 '09 at 8:55\nadd comment\n\nI am not sure if I am understanding you quite clearly: you have i.i.d Gaussian random variables $x_i, y_i$ so that for any $\\alpha > 0$ the quantity $P[|\\sum_i x_i y_i| < \\alpha]$ goes to zero. What you are looking for is the rate of convergence to zero ? Or you are looking for a function $\\phi$ that gives non-trivial bounds like $P[|\\sum_{i=1}^n x_i y_i| < \\alpha] \\leq \\phi(\\alpha, n)$ ?\n\nshare|improve this answer\nI am trying to find such a function $\\phi$ that is exponentially vanishing in $n$. \u2013\u00a0 anadim Dec 22 '09 at 18:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/36851/how-many-permutations-of-a-word-do-not-contain-consecutive-vowels/36854\nText:\nTake the 2-minute tour \u00d7\n\nThe word is \"ENGINEERING\".\n\nThe number of ways that the consonants can be ordered is 6! / 3!2!\n\nThe number of ways that the vowels can be ordered is 5! / 3!2!\n\nBut how would I determine how many ways vowels can be ordered so that they are not next to each other?\n\nshare|improve this question\nThink of using the vowels as separators, and thus you'll have 6 bins to place 6 consonants. Then you need to place a consonant between each spacer, and you'll be left with 2 consonants to place in any of the 6 bins. And of course take into account the double letters. \u2013\u00a0 Nicolas Villanueva May 4 '11 at 3:19\nI slightly edited as the capital letters were really offensive on the front page. \u2013\u00a0 Asaf Karagila May 4 '11 at 7:02\nIf your question has been answered satisfactorily, you should upvote and accept the answer so that it doesn't keep popping up in the frontpage unnecessarily. \u2013\u00a0 svenkatr May 5 '11 at 16:29\nadd comment\n\n2 Answers\n\nup vote 7 down vote accepted\n\nImagine that you arrange the consonants first. There are six consonants which you can arrange in $6!/(3!2!)$ ways.\n\nNow there are 7 spaces for the 5 vowels to go into but only one vowel can go into each space. So you choose 5 of the 7 available spaces and put a permutation of the vowels into these spaces.\n\nTotal number of arrangements with no consectutive vowels $= 6!/(3!2!) \\times 5!/(3!2!) \\times \\binom{7}{5}$.\n\nshare|improve this answer\nHow do you know that there are 7 spaces for the 5 vowels to go in? \u2013\u00a0 Krysten May 4 '11 at 3:38\n@krysten - You know that the consonants have to separate the vowels. Counting one space in front of the consonants, one at the end and the five in the middle gives us 7 seven spaces. For example, look at .N.G.N.R.N.G. which is an arrangement of consonants with the dots representing places where vowels can go. There are seven dots, which are the seven places where a vowel can go into. \u2013\u00a0 svenkatr May 4 '11 at 3:42\nalright thanks. \u2013\u00a0 Krysten May 4 '11 at 3:53\nadd comment\n\n(edit: Answer has been updated to include four missed combinations and the fact that permutations are not considered unique if their spelling matches that of another permutation.)\n\n12345678901  (11 letters in ENGINEERING)\nC.C.C.C.C.C (alternating sequence, bounded on both sides by C)\n.C.C.C.C.CC  (start single consecutive C pair, one end bounded by C)\nC.C.C.C.CC. (count: 10)\n.CC.CC.C.C. (start double consecutive C pair)\n.C.C.CC.CC. (count: 6)\n.CCC.C.C.C. (start triple C string)\n.C.C.C.CCC. (count: 4)\n\nIn all of these formats, there are 6!/(3!2!) ways to order the C's (i.e. consonants) and 5!/(3!2!) ways to order the .'s (i.e. vowels,) so there should be (21)(6!/3!2!)(5!/3!2!), or 12,600, permutations in which there are no adjacent vowels.\n\nshare|improve this answer\nI forgot one possible combination: C1 C2 V1 C3 V2 C4 V3 C5 V4 C6 V5. I went back and edited the post, bringing the total up to (17)6!5!. \u2013\u00a0 Michael May 4 '11 at 3:48\n@Michael - your starting count of $6!5!$ is wrong because there are repeating vowels and consonants. Also, I don't see how you can get a factor of 17. I suspect you have made a mistake when you manually count the possible arrangements. \u2013\u00a0 svenkatr May 4 '11 at 3:53\n@Michael - That's a very interesting way to look at it. I guess if all else fails you can just look at all the different possibilities. However, I believe the answer is 12,600. \u2013\u00a0 Krysten May 4 '11 at 3:55\n@svenkar I made a prettier version of it, showing all 17 formats that the vowels and consonants can follow. If you can find anything wrong with the formats, please explain! \u2013\u00a0 Michael May 4 '11 at 4:07\n@Krysten I've noticed a problem! The subject/title of this question is \"How many permutations of ENGINEERING do not contain consecutive vowels,\" which is the question that I answered. This, however, does not match up with the question that you ask in the body of your post, which asks, \"how would I determine how many ways vowels can be ordered so that they are not next to each other?,\" which I find to be both ambiguous and quite different than the subject/title. \u2013\u00a0 Michael May 4 '11 at 4:08\nshow 3 more comments\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/41318/probability-of-achieving-a-given-density-of-iid-random-variables\nText:\nTake the 2-minute tour \u00d7\n\nI have a sequence of IID random variables $X_1, X_2, \\dots, X_n$. In this particular case, each of the variables is L\u00e9vy distributed with PDF\n\n$f(x) = (\\lambda / 2 \\pi x^3)^{-1/2} \\exp(-\\lambda/2x)$\n\nfor $x > 0$, and $f(x) = 0$ otherwise.\n\nI'm trying to find the probability, given constants $\\tau > 0$ and $b < n$, that there exists an interval of length $\\tau$ which contains at least $b$ of the $n$ random variables.\n\nMy first approach was to use order statistics; for example, if $X_{(1)}, X_{(2)}, \\dots, X_{(n)}$ are the order statistics, the probability that the $b$ smallest fall in an interval of length $\\tau$ could be found using the joint distribution of $X_{(1)}$ and $X_{(b)}$. From the Wikipedia article,\n\n\nThis could then be integrated over the simplex $0 \\leq x \\leq y \\leq x + \\tau$, and the result could be repeated for each group of $b$ random variables and summed. However, I feel that this approach leads to double counting (for example, both $X_{(1)} \\dots X_{(b)}$ and $X_{(n-b+1)} \\dots X_{(n)}$ could fall in disjoint intervals of length $\\tau$) and also seems to be difficult to obtain in closed form.\n\nThe other approach I considered was to use the joint density of all order statistics:\n\n$f_{X_{(1)},\\ldots,X_{(n)}}(x_1,\\ldots,x_n)\\,dx_1\\cdots dx_n=n!f_X(x_1)\\cdots f_X(x_n)\\,dx_1\\cdots dx_n$\n\nHowever, I can't determine how to express the region of integration in any meaningful way. Any thoughts or pointers would be appreciated!\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nThe nonexistence of such interval is equivalent to $X_{(i+b-1)} > X_{(i)}+r$ for $i=1\\ldots n-b+1$. So for the probability of the complement of your event, integrate $n! f(x_1) \\ldots f(x_n)$ over the region defined by $$ x_{b-1} > x_{b-2}> \\ldots >x_2 > x_1>0 $$ and $$ x_b > \\max(x_{b-1}, x_1 + r), \\ldots, x_n > \\max(x_{n-1}, x_{n-b+1} + r). $$\n\nshare|improve this answer\nThanks, that makes a lot of sense. This helps when using numerical approximations, but the bounds don't seem to lead to a closed form solution - I suppose this is unlikely anyways. \u2013\u00a0 sciyoshi May 25 '11 at 18:19\nadd comment\n\nAs said before, there is no simple closed form solution. But one can prove some upper and lower bounds, which yield a precise value in a semi-explicit range of values of $b$, $n$ and $\\tau$.\n\nWe start with some notations. For $x\\le y$, call $g(x,y)=P(x\\le X_1\\le y)$ the integral of the density function $f$ of $X_1$ from $x$ to $y$. For any subset $I$ of $\\{1,2,\\ldots,n\\}$ of size $b$, call $A_I=[R_I\\le\\tau]$ where $R_I$ is the range of the sample $(X_k)$ over $I$, that is, $$ A_I=[R_I\\le\\tau],\\qquad R_I=\\max\\{X_k;k\\in I\\}-\\min\\{X_k;k\\in I\\}. $$ Using the fact that the event $[x\\le\\min\\{X_k;k\\in I\\},\\max\\{X_k;k\\in I\\}\\le y]$ has probability $g(x,y)^b$, one sees that $P(A_I)=\\alpha_b$ for every $I$ of size $b$, with\n\n$$ \\alpha_b=\\int bf(x)g(x,x+\\tau)^{b-1}\\mathrm{d}x. $$\n\nThe event $A$ that there exists an interval of length (at most) $\\tau$ which contains (at least) $b$ values from the sample of size $n$ is $$ A=\\bigcup_IA_I,\\quad A_I=[R_I\\le\\tau], $$ where the union is over the subsets $I$ of $\\{1,2,\\ldots,n\\}$ of size $b$. By the inclusion-exclusion principle, $$ S-S'\\le P(A)\\le S,\\quad S=\\sum_{I}P(A_I),\\ S'=\\sum_{I\\ne J}P(A_I\\cap A_J). $$ For every $I$ of size $b$, $P(A_I)=\\alpha_b$. For every $I\\ne J$ of size $b$, $A_I$ and $A_J$ are independent if $I\\cap J=\\emptyset$ and positively correlated otherwise, hence $P(A_I\\cap A_J)\\ge \\alpha_b^2$. Finally,\n\n$$ {n\\choose b}\\alpha_b-\\frac12\\left({n\\choose b}^2-{n\\choose b}\\right)\\alpha_b^2\\le P(A)\\le{n\\choose b}\\alpha_b. $$\n\nThis reads approximately as $p-\\frac12p^2\\le P(A)\\le p$ with $p=\\displaystyle{n\\choose b}\\alpha_b$ hence this estimation of $P(A)$ is as precise as the upper bound $p$ is small.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/25874/what-is-the-minimal-size-of-a-partial-order-that-is-universal-for-all-partial-or\nText:\nTake the tour \u00d7\n\nA partial order $\\mathbb{B}$ is universal for a class $\\cal{P}$ of partial orders if every order in $\\cal{P}$ embeds order-preservingly into $\\mathbb{B}$.\n\nFor example, every partial order $\\langle\\mathbb{P},\\lt\\rangle$ maps order-preservingly into its power set by the map $$p\\mapsto\\{q\\in\\mathbb{P}\\mid q\\leq p\\}$$ that sends each element $p$ to its lower cone.\n\nThus, the power set order $\\langle P(\\{1,2,\\ldots,n\\}),{\\subseteq}\\rangle$ is universal for the class of partial orders of size $n$. This provides an order of size $2^n$ that is universal for orders of size $n$.\n\nQuestion. What is the minimal size of a partial order that is universal for orders of size $n$?\n\nIn particular, is there a polynomial upper bound?\n\nOne can make at least slight improvements to the $2^n$ upper bound, by observing that the emptyset was not needed, as it never arises as a lower cone, and we don't need all the atoms, since if they are needed, then one can use the co-atoms instead. I suspect that there is a lot of waste in the power set order, but the best upper bound I know is still exponential.\n\nFor a lower bound, my current knowledge is weak and far from exponential. Any order that is universal for orders of size $n$ will contain a chain and an antichain, making it have size at least $2n-1$. (That bound is exact for $n\\leq 3$.) A student in my intro logic course extended this to $n\\log(n)$ by considering $k$ chains (and antichains) of size $n/k$.\n\nCan one find better lower bounds?\n\nInterestingly, the same student observed that we cannot in general expect to find unique smallest universal orders, since he found several orders of size 5 that are universal for orders of size 3 and which are minimal with that property. So in general, we cannot expect a unique optimal universal order. Does this phenomenon occur for every $n$? (He also found minimal universal orders of size larger than the minimal size universal order.)\n\nshare|improve this question\nNeat question. I guess the logic tag is because it came up in your logic class? \u2013\u00a0 Pete L. Clark May 25 '10 at 13:58\nThe concept of universal structures is important in model theory and used in set theory (although usually for infinite structures). Also, the easiest way to show that every countable partial order embeds into the Turing degrees is to consider orders that are universal for countable orders (and there are countable such orders). For the warm-up to that theorem, we first embedded the finite powersets into the Turing degrees, and then concluded that all finite orders embed by universality. \u2013\u00a0 Joel David Hamkins May 25 '10 at 14:09\nCorrection: my student's lower bound is $n\\log(n)-n$. \u2013\u00a0 Joel David Hamkins May 25 '10 at 14:41\nadd comment\n\n2 Answers\n\nDenote by $F(n)$ the number of different partial orders on the set of cardinality $n$. Then the minimal size $N$ of a partial order that is universal for orders of size $n$ satisfies $\\binom{N}{n}\\geq F(n)$ (that's captain obvious advice, yes). Since $\\log F(n)$ behaves like $cn^2$ (the lower estimate, which we need, is proved as follows: take $n/2$ blue elements and $n/2$ red elements, then decide for each pair of red and blue elements $r_i$, $b_j$, whether $r_i > b_j$ or not. We get $2^{n^2/4}$ patial orders, each isomorphism class is counted at most $n!$ times). So, $N^n> \\binom{N}{n}\\geq F(n)$, taking logarithms we get $n\\log N > cn^2$, so $N$ should grow at least exponentially.\n\nshare|improve this answer\nThanks very much for this excellent answer! I appreciate it very much. Could I ask kindly whether you might carry your argument through to the conclusion of an explicit lower bound? \u2013\u00a0 Joel David Hamkins May 25 '10 at 17:46\nOf course, but if you carry on the sharp constant in the exponent, I have to think bit more:) Now the lower estimate is $2^{n/4+o(n)}$ . But I suppose that calculating the best constant is very hard, similar to Ramsey numbers precise asymptotics. \u2013\u00a0 Fedor Petrov May 25 '10 at 20:13\nadd comment\n\nThere does not exist a polynomial upper bound.\n\nLet $P_n$ be the number of partial orders on $n$ elements. It is know that $P_n \\geq 2^{n^2/4}$. Thus, any method of uniquely representing the partial orders on $n$ elements, say in binary, will require at least $log_2(2^{n^2/4}) = O(n^2)$ bits.\n\nNow assume that for every $n$ there is a partial order on $n^k$, or fewer, elements, where $k$ is a constant, that is universal for the class of partial orders on $n$ elements. Fix some canonical ordering of the partial orders and let $U(n)$ be the first universal partial orders on $n^k$, or fewer elements.\n\nLabel each of the elements in $U(n)$ with a unique number from $1$ up to $log_2(f(n)) = O(log(n))$ in some fixed canonical way. Now each partial order on $n$ elements can be uniquely described by writing down for each element that elements corresponding label in $U(n)$. This takes $O(nlog(n))$ bits. However; this representation is not quite complete, as it seems to require the description of $U(n)$ to actually reconstruct a partial order given its representation in this form.\n\nHowever, since $U(n)$ is the first universal partial order on $n^k$ or fewer elements, rather than appending an encoding of $U(n)$ to each partial order directly we can instead append an encoding of the following Turing machine $M$. $M$ takes in three arguments $n$, $i$ and $j$ and accepts if element $i$ is less than element $j$ in $U(n)$ and rejects otherwise. Given such a Turing machine we can clearly reconstruct the partial order. $M$ simply enumerates all partial orders of size between $n$ and $n^k$ and stops at the first partial order that is universal for all partial orders on $n$ elements. It then labels the elements of $U(n)$ in the canonical manner and accepts if the element labeled $i$ in $U(n)$ is less than the element labeled $j$ in $U(n)$. This TM has constant size.\n\nWe can thus uniquely and completely represent all partial orders on $n$ elements by $O(nlog(n)) + O(1) = O(nlog(n))$ bits, which is a contradiction as there are too many partial orders on $n$ elements to be represented in only $O(nlog(n))$ bits.\n\nshare|improve this answer\nIt is not true that $P_n \\geq 2^{n^2/4}$. Also, LaTeX knows \\log. \u2013\u00a0 JBL May 25 '10 at 17:19\nIf you consider distinguishable elements then it is true that $P_n \\geq 2^{n^2/4}$. If you consider indistinguishable elements then the there are still at least $\\frac{2^{n^2/4}}{n!} \\geq 2^{n^2/4 - n\\log{n}} = 2^{\\Theta(n^2)}$ partial orders on $n$ elements and the proof still holds. \u2013\u00a0 Travis Service May 25 '10 at 18:19\n+1. Travis, thanks very much for the argument--your information-theoretic way of analyzing it appeals to me very much. \u2013\u00a0 Joel David Hamkins May 25 '10 at 18:49\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/180520/sqrtx-y-4-x-sqrty-6-find-the-solution-x-y\nText:\nTake the 2-minute tour \u00d7\n\n$\\sqrt{x} +y = 4$, $\\sqrt{y} +x= 6$, find the solution (x,y). $NOTE$ : $\\sqrt{4}+1= 4-1$, $\\sqrt{1} +4 =1+4$\n\nshare|improve this question\n$(\\sqrt{2}+1) \\lt (2+\\sqrt{1})$, $(\\sqrt{4}+1) \\lt (4+\\sqrt{1})$ \u2013\u00a0 Rajesh K Singh Aug 9 '12 at 5:09\n$\\sqrt x=4-y$, $x=y^2-8y+16=6-\\sqrt y$, $y=(y^2-8y+10)^2$ gives you an equation of degree 4 in $y$. If you can solve it, you win. \u2013\u00a0 Gerry Myerson Aug 9 '12 at 6:00\nAnother approach is $y=4-\\sqrt x$, $\\sqrt y = 6-x$ implies $y=(6-x)^2$. Since $y=y$, we can set the right side of both equations equal to each other. Then we get an 4th degree equation in $\\sqrt x$. \u2013\u00a0 Matt Groff Aug 9 '12 at 6:07\nlet $u=\\sqrt{x}, v=\\sqrt{y}$. Then $u^2+v=4, u+v^2=6$ Hence $v=4-u^2$. Hence $u+16-8u^2+u^4=6 \\iff u^4-8u^2+u+10=0$. Wolframalpha gives some disgusting solutions to this quartic equation: wolframalpha.com/input/?i=u%5E4-8u%5E2%2Bu%2B10%3D0 \u2013\u00a0 progressiveforest Aug 9 '12 at 6:07\nBeautiful question with ugly answer... \u2013\u00a0 \u1d0a \u1d00 s \u1d0f \u0274 Aug 9 '12 at 6:13\nshow 1 more comment\n\n2 Answers\n\nThis is basically the method which was suggested in the comments above - turning this into a quartic equation. We will see whether someone suggest a substantially more elegant solution.\n\n$$\\sqrt{x}+y=4\\\\ x+\\sqrt{y}=6$$\n\nUsing the substitution $\\sqrt{x}=s$ and $\\sqrt{y}=t$ we get: $$s+t^2=4\\\\ t+s^2=6$$\n\nWhich gives $$s=4-t^2=4-(6-s^2)^2\\\\ (s^2-6)^2+s-4=0\\\\ s^4-12s^2+s+32=0$$\n\nIt should be possible to solve this as a quartic equation, although it would be quite laborious. You can check what WolframAlpha is able to find out here and here\n\nshare|improve this answer\ngreat attempt indeed \u2013\u00a0 Rajesh K Singh Aug 9 '12 at 6:20\nadd comment\n\nLet, $\\sqrt{x}=s$, $\\sqrt{y}=t$\n\nwe have, $s^4 -12s^2+s+32=0$, which is a 'biquadratic' equation of the form,\n\n\ni.e. $$s^4 -12s^2+s+32=(s^2+ks+l)(s^2-ks+m)$$\n\nnow by equating coefficients, we have\n\n$$l+m-k^2 = -12, k(m-l) = 1, lm = 32$$\n\nfrom the first two of these equations, we obtain\n\n$$2m=k^2-12+(1/k), 2l=k^2-12-(1/k)$$\n\nhence substituting in the third equation, the values of l,m,\n\n\n\n\n\nthis is a cubic in $k^2$ which always has one real positive solution and we can find $k^{2}$,$l$,$m$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/60743/tameness-for-the-galois-closure-of-a-map-of-curves/60807\nText:\nTake the 2-minute tour \u00d7\n\nSay we are working over some $K=\\overline{K}$, of characteristic $p>0$. Let $\\phi: Y\\rightarrow X$ be a nonconstant map of smooth projective curves. To this map we can associate a map $\\psi: Z\\rightarrow X$, where on the level of fields this is the Galois closure of $k(X)\\subseteq k(Y)$. I would like to know about the tameness of this map.\n\nLet $e_P$ denote the ramification indices (with the maps understood to be either $\\psi$ or $\\phi$ depending on where $P$ lives). Now obviously if $p|e_P$ and if $Q$ lies above $P$, $p|e_Q$ as well, so $\\psi$ has wild ramification at $Q$. I am wondering when we can ensure this map is (everywhere) tamely ramified. For instance if $d=deg(\\phi) < p$, then the degree of the Galois closure of $k(Y)$ over $k(X)$ has degree dividing $d!$, and hence $\\psi$ remains tame.\n\nMy question is this: Suppose we can show for each $P\\in Y$ such that $e_P \\geq p$ that each point above $P$ is tamely ramified. Can we conclude that $\\psi$ is (everywhere) tamely ramified? It seems to me that this isn't true but I cannot produce a counterexample. It would be fortuitous if it were true, however. Any help is greatly appreciated.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nLook at Lemma 2.1.3 i.v) from Grothendieck and Murre: \"The Tame Fundamental Group of a Formal Neighbourhood of a divsors with Normal Crossings on a Scheme\".\n\nIt says when given a tame field extension $L \\supset K$, then its Galois closure will again be tame.\n\nHere, tameness is just defined with respect to one valution of $K$. But the proof should apply in your situation as well.\n\nshare|improve this answer\nThat's certainly true, but the question was unclearly enough phrased that I thought that he was asking the converse: if the Galois closure of $L\\supset K$ is tame over $L$, is then $L$ tame over $K$? I'll wait for OP's comment. \u2013\u00a0 Lubin Apr 6 '11 at 20:12\nI was asking what Holger has posted. The converse seems clear to me. Just a silly error though--you meant iv) rather than v), but yes this is exactly the sort of result I was hoping for. \u2013\u00a0 Randy Reddick Apr 6 '11 at 20:26\nNo, the converse, as I stated it, is not true. \u2013\u00a0 Lubin Apr 6 '11 at 22:04\nthe converse is true, since if Q lies over S and S over P, where Q is place of a Galois closure of L/K S is place of L and P of K then e(Q|P)=e(Q|S)e(S|P) and hence if p does not divide e(Q|P) then p does not divide e(S|P) (p=char(K). \u2013\u00a0 Alexey Zaytsev Apr 6 '11 at 22:16\nSorry, it seems that we understand the converse in different sense. if the property being tame only over L, then you are right. \u2013\u00a0 Alexey Zaytsev Apr 6 '11 at 22:21\nshow 1 more comment\n\nFor the first glance it should follow form the Abhaynkar's lemma (see \"Algebraic Function Fields\" by Stichtenoth, Theorem 3.9.1) and the fact the Galois closure is the composite of all the different embeddings of L over K into fixed algebraic closure of K (so each of them has the same properties of tame ramifications). Then we just apply the lemma and get the result that $p=char(K)$ does not divide $e_P$ for any place P in K.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/55736/a-problem-in-finite-group-theory?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThis is a problem I encountered in Martin Isaacs' 'Finite Group Theory'. It's located at the end of Chapter II which deals with subnormality, and the particular paragraph is concerned with a couple of not so well-known results which I quote for reference:\n\n(In what follows $F$ is the Fitting subgroup)\n\nTheorem (Zenkov)\nLet $A$ and $B$ be abelian subgroups of the finite group G, and let $M$ be a minimal (in the sense of containment) member of the set {$A \\cap B^g : g \\in G$}. Then $M\\subseteq F(G)$.\n\nAn easy corollary follows which establishes the existence of a subnormal subgroup:\n\nIf $A$ is an abelian subgroup of the finite group $G$ and $|A|\\geq|G:A|$, then $A \\cap F(G)>1$.\n\nIn fact, if $A$ is cyclic, then a normal subgroup is guaranteed:\n\nTheorem (Lucchini)\nLet A be a cyclic proper subgroup of a finite group G, and let $K=core_G(A)$. Then $|A:K|<|G:A|$, and in particular, if $|A|\\geq|G:A|$, then $K>1$.\n\nLet G be a finite group such that $G=AN$, where $A$ is abelian, $N \\unlhd G$, $C_A(N)=1$ and $F(N)=1$. Show that $|A|<|N|$.\n\nNote that, since $N \\unlhd G$, it follows that $F(N)= N \\cap F(G)$. So, if $|A|\\geq|N|$ in the problem, then $|A|\\geq|N:N \\cap A|=|NA:A|=|G:A|$ and the corollary applies to give $A \\cap F(G)>1$.\n\nHow does one proceed from here to obtain a contradiction? In particular, how can the condition on the centralizer be utilized effectively?\n\nshare|improve this question\nI'm not sure this is the right site to visit for this kind of question, which is somewhat advanced but based on a textbook problem. I hope it's not a homework problem. (The issue would be different if you thought you found a serious gap or error in a published proof. Anyway, Isaacs himself is still active in mathematics and could be consulted in that case.) \u2013\u00a0 Jim Humphreys Feb 17 '11 at 18:17\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou were almost there: Since $N$ and $F(G)$ are two normal subgroups intersecting trivially, they commute. But now take a non-trivial element $a \\in A \\cap F(G)$; then by the previous observation, $a$ commutes with every element of $N$. But this contradicts the fact that $C_A(N) = 1$.\n\nshare|improve this answer\nIndeed. What if we replace the condition on the Fitting subgroup with the requirement that A and N have relatively prime orders. Is it still true that |A|<|N|? \u2013\u00a0 user13040 Feb 20 '11 at 23:15\nYes: if $A$ is a $\\pi$-group (where $\\pi$ is a set of primes), then the fact that $A \\cap F(G) > 1$ gives $A \\cap O_\\pi(G) > 1$. Now proceed as in the previous problem with $F(G)$ replaced by $O_\\pi(G)$. \u2013\u00a0 Tom De Medts Feb 21 '11 at 13:19\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/33834/calculating-impact-force-for-a-falling-object?answertab=oldest\nText:\nTake the tour \u00d7\n\nGood evening, I'm trying to calculate what kind of impact force a falling object would have once it hit something. This is my attempt so far:\n\nBecause $x= \\frac{1}{2} at^2$, $t=\\sqrt{2x/a}$\n$v=at$, therefore $v=a \\sqrt{2x/a}$\n$E_k=\\frac{1}{2} mv^2$, so $E_k=\\frac{1}{2} m(2ax)=m \\cdot a \\cdot x$\nSince $W=E_k=F_i s$, $F_i=E_k/s=(m \\cdot a \\cdot x)/s$\n\nFor an object weighing about as much as an apple, $0.182$ kg, falling $2.00$ m straight down and creating a dent of $0.00500$ m, this would result in:\n\n$$F_i=(m \\cdot a \\cdot x)/s$$\n\n$$F_i=(0.182 \\cdot 9.81 \\cdot 2.00)/0.00500=706 \\, \\text{N}$$\n\nDoes this make any sense? I wouldn't be surprised at all to find out I'm missing something here.\n\nAny input would be appreciated,\n\nthanks in advance!\n\nshare|improve this question\nYou forget air resistance. \u2013\u00a0 sidht Aug 9 '12 at 19:38\nRegarding Qmechanic's edit: While I know this is high-school level physics, please note that this is not, in fact, homework, as the tag would suggest. I do not have any assignment to go from nor any way to look up the answer. \u2013\u00a0 Chris Aug 9 '12 at 20:06\nYour calculations are ok and the model you used (constant hitting force) is reasonable. Though remember that's just a model, real apples hit the ground in a more complicated way, but I think for what you might use your calculations, your model is accurate enough. Unless, of course, you are not allow for the apple to bounce. \u2013\u00a0 Yrogirg Aug 10 '12 at 8:20\nRead all replies and marked an answer, thanks all for your help! \u2013\u00a0 Chris Aug 10 '12 at 9:29\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nIf your apple falls $2m$ it's velocity is calculated using the equation you give:\n\n$$ v^2 = 2as $$\n\nand you get $v^2 = 39.24 \\space m^2s^{-2}$ (I've haven't taken the square root for reasons that will become obvious). You know the apple is slowed to rest in $0.005m$, so you just need to work out what acceleration is needed when $v^2 = 39.24$ and $s = 0.005$. A quick rearrangement of your equation gives:\n\n$$ a = \\frac{v^2}{2s} $$\n\nand plugging in $v^2 = 39.24$ and $s = 0.005$ gives $a = 3925 \\space ms^{-2}$. To get the force just use Newton's equation:\n\n$$ F = ma $$\n\nwhere $m$ is the mass of the apple, $0.18 kg$, and you get $F = 706.32N$. So you got the correct answer (my answer differs from yours only because I used $g = 9.81 \\space ms^{-2}$).\n\nTo get a more general result substitute for $v^2$ in the second equation to get:\n\n$$ F = ma = m\\frac{2gs_1}{2s_2} = mg\\frac{s_1}{s_2}$$\n\nwhere $s_1$ is the distance the apple falls and $s_2$ is the distance it takes to stop.\n\nshare|improve this answer\nExactly what I was looking for, explanation and confirmation. Thank you very much! \u2013\u00a0 Chris Aug 10 '12 at 9:26\nadd comment\n\nI would have done this calculus if there was a uniform constant breaking force applied all all along the trajectory and if at impact, the ball had a zero velocity. The work done by such a force must exactly balance the initial mechanical energy of the ball. For a shock, I would rather use something like: d(mV)/dt=mg-F and use for instance a contact time dt=0.001s\n\nBefore impact: v=sqrt(2*g*x) After impact: v=0 Duration of the impact: dt=0.001s\n\n\nF=1140 N\n\nshare|improve this answer\nadd comment\n\nI'm not sure where you're going with the .0050 being treated as time, unless you meant to say it's in contact with the ground for .005 seconds. In that case, what you have would work algebraically.\n\nshare|improve this answer\nadd comment\n\nCalculate Potential energy using the following formula $PE = mgh = 0.182 \\cdot 9.81 \\cdot 2\\: \\mathrm{Joules}$\n\nAverage Impact Force = $0.182 \\cdot 9.81 \\cdot 2 \\cdot 0.005\\: \\mathrm{Newtons}$ (that is the answer)\n\nshare|improve this answer\nadd comment\n\nprotected by Qmechanic May 12 at 0:00"}
{"text": "Retrieved from http://math.stackexchange.com/questions/234782/cyclotomic-polynomials\nText:\nTake the tour \u00d7\n\nLet $E(n)$ denote an nth root of unity. (For convenience, we may take $E(n) = \\exp(\\frac{2\u03c0i}{n})$.)\n\nProve that for any prime $p$ and any natural number $r$, we have $$ \\prod_{\\substack{j\\\\ \\gcd(p^r, j) = 1}} \\left(1 \u2013 E(p^r)^j\\right) = p,$$ without using the formula to get the cyclotomic polynomial of $p^r$.\n\nshare|improve this question\nWithout using what formula? And why without using it? \u2013\u00a0 Phira Nov 11 '12 at 10:49\n@Phira, because with using the formula it would be really direct. I wanted to see a proof without using the formula. The formula is Phi(x) = sum i= 1 to p-1 ( x^(i*p^(k-1))) \u2013\u00a0 John Chang Nov 11 '12 at 13:20\nIt should be $\\displaystyle{\\prod_{\\left(p^r,j\\right)=1} \\left(1 \u2013 E\\left(p^r\\right)^j\\right) = p^r}$. \u2013\u00a0 P.. Nov 12 '12 at 11:57\n@Pambos, the cyclotomic polynomial of p^r, Phi(x) = sum i= 1 to p-1 ( x^(i*p^(k-1))) gives us that it is indeed p. I think. But I wanted to see a more detailed proof without using this formula. \u2013\u00a0 John Chang Nov 12 '12 at 12:00\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nLet $n$ be a natural number and let $E_n=e^{2\\pi i/n}$. Then the polynomial $x^n - 1$ splits in $\\mathbb{Q}(E_n)$ as\n\n$x^n - 1 = (x - 1)(x - E_n)\\cdots(x-E_n^{n-1})$, which yields:\n\n$1+x+\\cdots+x^{n-1} = \\frac{x^n-1}{x-1} = (x - E_n)(x - E_n^2)\\cdots(x-E_n^{n-1})$\n\nand so we get the following result.\n\n$\\prod_{j=1}^{n-1}(1-E_n^j) = n$\n\nNow let $n = p^m$, for some natural number $m$. Thus,\n\n$p^m = \\prod_{j=1}^{p^m-1}(1-E_{p^m}^j) = \\prod_{(j, p^m)=1}(1-E_{p^m}^j)\\prod_{(j, p^{m-1})=1}(1-E_{p^{m-1}}^j)\\cdots\\prod_{(j, p)=1}(1-E_p^j)$\n\nNow look at the right side of the last equation. Each product $\\prod_{(j, p^r)=1}(1-E_{p}^j)$ is greater than 1, and there are a total of $m$ factors of this form. Since the product of these $m$ factors is $p^m$, then each factor must be equal to $p$.\n\nTherefore, $\\prod_{(j, p^r)=1}(1-E_{p^r}^j) = p$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/240175/computing-lim-n-rightarrow-infty-sqrtn1-sqrtn2-cdots-sqrtn2\nText:\nTake the tour \u00d7\n\nI'm trying to find:\n\n$$ \\lim_{n\\rightarrow\\infty} (\\sqrt[n]{1}+\\sqrt[n]{2}+\\cdots+\\sqrt[n]{2007}-2006)^n $$\n\n(Problem from CMJ)\n\nWe have:\n\n$$ k^{1/n}=1+\\frac{\\ln k}{n}+O(1/n^2) $$\n\n$$ \\left( \\sum_{k=1}^{2007}k^{1/n}-2006 \\right)^n= \\left(1+\\frac{1}{n}\\sum_{k=1}^{2007}\\ln k+O(1/n^2) \\right)^n \\sim_{n\\rightarrow\\infty} \\exp \\left( \\sum_{k=1}^{2007} \\ln k \\right)(=2007!)$$\n\nI'm quite sure of my result but I could not check it numerically.\n\nDo you agree with this limit?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nYes. Your limit looks fine. You can simplify it further into $$\\exp \\left( \\sum_{k=1}^{2007} \\log (k) \\right) = \\exp \\left( \\log \\left(\\prod_{k=1}^{2007} k \\right) \\right) = \\exp \\left( \\log (2007!) \\right) = 2007!$$\n\nshare|improve this answer\nOK, thank you Marvis! \u2013\u00a0 Chon Nov 18 '12 at 22:24\nadd comment\n\nTake the log of your expression and replace $x=\\frac{1}{n}$, you get the expression:\n\n$$\\frac{\\log\\left((\\sum_{k=1}^{2007} k^x) - 2006\\right)}{x}$$\n\nFirst, show the numerator approaches zero as $x\\to 0$. Then apply L'Hopital's rule, yielding a limit:\n\n$$ \\sum_{k=1}^{2007} \\log k = \\log 2007!$$\n\nThat is the log of your limit, so your limit is $e^{\\log 2007!}=2007!$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/41030/why-is-int-dp-2-pi-p-rangle-langle-p-1\nText:\nTake the tour \u00d7\n\nIn quantum mechanics, why is $\\int (dp/2\\pi) |p \\rangle\\langle p| = 1 $ where $|p \\rangle$ represents momentum eigenstate?\n\nshare|improve this question\nAre you sure about the two pi? A family of orthonormal vectors spans the whole space (is 'complete') is the sum of all the projectors onto each single basis vector gives the identity operator. A projector onto the normalized state |p> is |p><p|, the sum over all projectors $\\int dp |p><p|$, and the identity operator is just 1 \u2013\u00a0 A.O.Tell Oct 17 '12 at 16:33\nIt's from A.Zee's Quantum Field Theory page 11.. So it is wrong? \u2013\u00a0 RRRR Oct 17 '12 at 17:51\nIt's not wrong, it's just a way to normalize states that is a bit unconventional. Maybe it has advantages elsewhere. I'll check Zee later \u2013\u00a0 A.O.Tell Oct 17 '12 at 18:10\nadd comment\n\n3 Answers\n\nup vote 4 down vote accepted\n\nThe factor of $2\\pi$ is a convention Zee uses which normalizes the $|p\\rangle$ states so that they are not quite orthonormal:\n\n$$ \\langle p | p' \\rangle = 2\\pi \\delta(p-p') $$\n\nwhich means that Zee's $p$ states are different from Ahmed's $p$ states by a factor of $\\sqrt{2\\pi}$. Let me call these unit normalized $p$ states $||p\\rangle$, then\n\n$$ \\sqrt{2\\pi} || p \\rangle = |p\\rangle $$\n\nThis is something Dirac does also, and it becomes essential for relativistic states, when you want\n\n$$ \\int {d^3 p \\over (2\\pi)^3 2\\omega_p} |p\\rangle\\langle p| = 1 , $$\n\nbecause then all the parts are manifestly invariant andso the integral over $p$ is an integral over the mass-shell hyperboloid:\n\n$$ \\int {d^4 p \\over (2\\pi)^4} (2\\pi) \\delta(p_\\mu p^\\mu - m ^2) = \\int {d^3 p\\over (2\\pi)^3 (2\\omega_p)} , $$\n\nwhere the delta function projects you onto the mass shell in a relativistically invariant way. But for this to be true, you need\n\n$$ |p\\rangle = (\\sqrt{2\\pi})^3 \\sqrt{2\\omega_p} || p \\rangle $$\n\nwhere $\\omega_p = \\sqrt{p^2 + m^2} $. This is called a relativistically normalized state. The relativistically normalized states are natural, and define relativistically normalized creation operators,\n\n$$ \\alpha(k) |0\\rangle = |k\\rangle , $$\n\nwhich are related to the usual nonrelativistically normalized creation operators as follows:\n\n$$ \\alpha(k) = (\\sqrt{2\\pi})^3 \\sqrt{2\\omega_k} a_k . $$\n\nIn terms of the $\\alpha(k)$'s and their conjugates, the field Fourier expansion is manifestly invariant:\n\n$$ \\phi(x) = \\int e^{ikx} \\alpha(k) + e^{-ikx} \\alpha^\\dagger(x) {d^3p \\over (2\\pi)^3 2\\omega_k} . $$\n\nThis looks trivial, but it makes everything in scattering theory and mode expansions relativistically consistent. So you can make trivial all the first chapters of any old quantum field theory books with mode expansions which look opaque, because they are noncovariant.\n\nshare|improve this answer\nadd comment\n\nI don't think this question has been answered. The original poster asked: why is \\begin{align} \\int dp |p\\rangle \\langle p| = 1, \\end{align} up to unimportant normalization issues that have been discussed extensively (but are off the point).\n\nThe above statement is equivalent to the question of completeness of a set of states on an Hilbert space (which ahmed addressed but did not answer the question why the LHS of the original poster's equation is equal to the RHS).\n\nCompleteness is, heuristically, the statement that a set of vectors (functions on a Hilbert space) spans the space of possible (piecewise continuous and some degree of smoothness (differentiable)) functions on that space. In other words, just about any \"well-behaved\" function can be expanded in a basis of states that is complete.\n\nA proof of completeness of eigenfunctions of differential equations is given in Chapter VI, Section 3, p. 424 of Courant & Hilbert's Methods of Mathematical Physics, Vol. 1, first English edition. It's too lengthy to reproduce here.\n\nBut motivation (not a \"proof\") for the completeness relation can be given as follows. We consider the expansion of the Dirac $\\delta$ function in a particular basis, say the position basis. We assume that it can be written as an expansion over momentum eigenstates in the position basis, $e^{-ipx'}$: \\begin{align} \\delta(x-x') &= \\int_{-\\infty}^\\infty\\!dp\\,c_p(x)\\frac{e^{-ipx'}}{\\sqrt{2\\pi}}. \\end{align} Clearly the coefficient, $c_p$ in the expansion must depend on $x$ since the $\\delta$ function on the LHS does.\n\nThe completeness relation is determined as follows. Mulitply the above equation by $e^{ip'x'}/\\sqrt{2\\pi}$, interchange the order of the two integrals, and integrate over $x'$ on the interval $(-\\infty,\\infty)$. Use orthonormality of the plane waves, $\\int_{-\\infty}^\\infty \\frac{dx'}{2\\pi} e^{i(p'-p)x'}=\\delta(p'-p)$ to get \\begin{align} c_{p'}(x) &= \\frac{1}{\\sqrt{2\\pi}} e^{ip'x}. \\end{align} Substitution back into the expression for $\\delta(x-x')$ gives \\begin{align} \\delta(x-x') = \\int_{-\\infty}^\\infty \\frac{dp}{2\\pi}e^{ip(x-x')}. \\end{align} Rewriting this \\begin{align} \\delta(x-x') &= \\langle x|x' \\rangle = \\langle x|1|x' \\rangle \\\\ &= \\int_{-\\infty}^\\infty\\! dp\\, \\langle x|p\\rangle\\langle p|x'\\rangle \\\\ \\langle x|1|x' \\rangle &= \\langle x| \\cdot\\Big[\\int_{-\\infty}^\\infty\\! dp\\, |p\\rangle\\langle p|\\Big] \\cdot |x'\\rangle. \\end{align} And completeness follows from the arbitrariness of the values of $x,x'$.\n\nNota Bene: This is not a proof as we have made several questionable steps (like reversing the orders of integration $dx' \\leftrightarrow dp$) and essentially assumed the result we wanted (by using orthonormality).\n\nWhat this does, though, is to make plausible the idea that if you need to expand a function in a complete set of states, you need a relation like $\\int\\! dp\\, |p\\rangle\\langle p| =1$ to hold.\n\nshare|improve this answer\n-1: OP was asking about why the $2\\pi$ factors appear in some books and not others, not about why basis states are supposed to be orthonormal. \u2013\u00a0 Ron Maimon Mar 28 at 3:15\nYou need to read the question again, Maimon: \"In quantum mechanics, why is \u222b(dp/2\u03c0)|p\u27e9\u27e8p|=1 where |p\u27e9 represents momentum eigenstate?\" This is asking about completeness not normalization. -1 for being off-topic. \u2013\u00a0 MarkWayne Mar 28 at 4:49\nI was here when OP asked the question, the issue was the 2pi factor, which confused OP, because it is not orthonormal, but a different convention from other books. I understand what was being asked, really, I am not offtopic. I shouldn't have downvoted you, I suppose, you didn't say wrong things, just things OP already knows. \u2013\u00a0 Ron Maimon Mar 28 at 19:20\nadd comment\n\nThe composition of any state in terms of the momentum eigenstates is $\\lvert\\psi\\rangle = k\\int \\mathrm{d}^{3}p\\lvert p\\rangle\\langle\\psi \\vert p\\rangle$. The set of momentum eigenstates form a complete set of orthogonal state vectors in Hilbert space (this set is uncountably infinite). The components of this decomposition are the $\\langle\\psi \\vert p\\rangle$ for each $p$ (a complex number).\n\nTo simplify things, $\\int \\mathrm{d}^{3}p\\lvert p\\rangle \\langle p\\rvert$ is an operator. Let $\\int \\mathrm{d}^{3}p\\lvert p\\rangle\\langle p\\rvert = A$, then $A\\lvert\\psi\\rangle = \\lvert\\psi\\rangle$ for an arbitrary $\\lvert\\psi\\rangle$ then $A$ must be the identity operator.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/114945/mutually-tangent-ellipsoids-in-3-space/115059\nText:\nTake the tour \u00d7\n\nI recently heard a claim that for any n, it is possible to arrange n ellipsoids in 3 space such that each pair of ellipsoids is kissing. Is this true, and if so, how?\n\nEdit: By kissing, I mean that I would like the interiors of the ellipsoids to be disjoint, but each pair of ellipsoids should intersect at a point.\n\nshare|improve this question\n\"kissing\" might mean different things... \u2013\u00a0 Anton Petrunin Nov 30 '12 at 0:11\nThere was a MathOverflow post some months back mentioning work of Jeff Erickson on n convex bodies that were cotangent. (Some kind of voronoi cells of points on a helix.) Perhaps someone can guide you and extend it to ellipsoids. Gerhard \"Ask em About System Design\" Paseman, 2012.11.29 \u2013\u00a0 Gerhard Paseman Nov 30 '12 at 1:03\nI think she means that the solid ellipsoids have disjoint interiors, but nevertheless all their pairwise intersections are non-empty. Kissing, yes, but nothing more! \u2013\u00a0 alvarezpaiva Nov 30 '12 at 14:26\nThanks for the comments and ideas. I added in what I mean by kissing, which, as many guessed, includes disjoint interiors. If I should have used another word, please let me know! \u2013\u00a0 Linda Brown Westrick Dec 1 '12 at 1:33\nadd comment\n\n3 Answers\n\nHere is the paper that Gerhard remembered, which doesn't answer the question as posed, but does answer a related question:\n\nJeff Erickson and Scott Kim, \"Arbitrarily large neighborly families of congruent symmetric convex 3-polytopes,\" 2003. (link)\n\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Erickson Fig\nThat their paper does not mention ellipsoids might be taken as indirect evidence that the posed question may not yet have been answered a decade ago.\n\nshare|improve this answer\nadd comment\n\nI've never heard of this before, and it sounds quite counterintuitive. If one is granted that this is true, then one can try to work backwards and apply a bit of dimensional analysis to understand how this can be.\n\nFirst, note that ellipsoids are quadrics, and there are a $9$ dimensional space of quadrics. Also, note that ellipsoids are invariant under affine (or more generally projective) transformations, so if we have one such configuration, we will expect to get at least a $15$-dimensional family of kissing ellipsoids.\n\nOn the other hand, there are degenerate quadrics for which this is true. Consider $n$ mutually non-parallel lines in the plane. We can consider these as degenerate ellipsoids, with two axes $0$ radius and one axis $\\infty$ radius. They the are each mutually tangent, since they each meet in a point. There is an $2n+3$-parameter family of these. One could hope to \"regenerate\" families of $n$ tangent ellipsoids from these, but there might be restrictions on when this is possible.\n\nFor $n=1$, there is a $9$ dimensional family.\n\nFor $n=2$, there is a $17=9+8$ dimensional family. We have $9$ dimensions for the first ellipsoid. Choosing any other ellipsoid with center disjoint from the first, we may rescale it uniquely to be tangent to the first ellipsoid. So this gives us $8$ dimensions for the second ellipsoid.\n\nFor $n=3$, let's assume that one of the ellipsoids is a sphere. Then its center is equidistant from the other two ellipsoids. The space of points equidistant from two kissing ellipsoids is $2$-dimensional. So we get a $17+2=19$-dimensional space of 3 tangent ellipsoids, with one round. We may change the round sphere by an affine transformation based at its center to get any ellipsoid with the same center, and we have a $6$-parameter family of such affine maps (we have $3$ dimensions for the major axis, $2$ for the minor axis, and $1$ for the third axis). However, this over-counts, since a similarity (all $3$ axes equal) will take the sphere to a sphere, so this gives us $19+6-1=24$ dimensions (or we may take a $5$-parameter family of volume-preserving affine transformations to eliminate repetitions).\n\nFor $n=4$, let's again assume that one of the ellipsoids is a sphere. The space of points equidistant from $3$ ellipsoids is $1$-dimensional. As above, we may modify the sphere by a $5$-parameter family of volume-preserving affine transformations to get $24+1+5=30$ dimensions of 4 mutually tangent ellipsoids.\n\nFor $n=5$, we expect finitely many points which are equidistant from $4$ mutually tangent ellipsoids, so the computation gives $35$ dimensions.\n\nAt this point, one expects adding the next sphere will cut down on the dimension of the space of 5 tangent ellipsoids which have an equidistant point. If we continue the sequence $9,17,24,30,35$, then the next term ought to be $39$ dimensions ($42, 44, 45, ?$). Of course, this trend couldn't possibly continue if one expects to have $n$ tangent ellipsoids for all $n$, so there must be some non-generic phenomenon creating the incidence.\n\nshare|improve this answer\nadd comment\n\nI'm assuming \"kissing\" means osculating, i.e. the ellipsoids intersect at a point where they have second-order contact, i.e. in a coordinate system where the point of contact is the origin and the tangent plane is the $xy$ plane, near the origin we have $z = a x^2 + b x y + c y^2 + O((|x|+|y|)^3)$ for the same $a,b,c$. Well, e.g. this is true for the ellipsoids $$ x^2 + y^2 + b (z - 1/b)^2 = 1/b,\\ b > 0$$ which are all mutually osculating at the origin.\n\nOr did you want each pair to be osculating at a different point?\n\nshare|improve this answer\nI suspect the asker wanted the interiors of the ellipsoids to be disjoint. \u2013\u00a0 Graham Leuschke Nov 30 '12 at 3:02\nMe too. Otherwise why not just use ellipses in two dimensions rather than ellipsoids in three? \u2013\u00a0 Noam D. Elkies Nov 30 '12 at 3:24\nThey couldn't be osculating if the interiors are disjoint. \u2013\u00a0 Robert Israel Nov 30 '12 at 3:42\nKissing usually means disjoint interior plus tangent; one does not ask for osculation. \u2013\u00a0 Beno\u00eet Kloeckner Nov 30 '12 at 17:07\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/322851/on-the-precise-asymptotic-scaling-of-n-n-k-as-n-k-to-infty\nText:\nTake the 2-minute tour \u00d7\n\nOn page 23 of [Erd\u0151s+R\u00e9nyi 1960, \"On the evolution of random graphs\"], the following asymptotic formula is stated without proof: $$ \\binom{n}{k} \\sim \\frac{n^k \\mathrm e^{-\\frac{k^2}{2n} - \\frac{k^3}{6n^2}}}{k!} $$ valid for $k \\in o(n^{\\text{[some illegible fraction]}})$. That is, we have $$ \\frac{n!}{(n-k)!} \\;=\\; n^k \\exp\\left(-\\tfrac{k^2}{2n} - \\tfrac{k^3}{6n^2}\\right) \\cdot \\Bigl[1 \\pm o(1)\\Bigr].$$ I was curious about what the limitations of the illegible upper bound on $k$ were for this approximation, and hoped that I could use at least some useful scaling for $k \\in \\Theta(n^{2/3})$, so I tried to rederive it. However, using Stirling's approximation for the factorial, $$ n! = n^{n+\\frac{1}{2}} \\mathrm e^{-n}\\cdot \\Bigl[\\sqrt{2\\pi} + o(1)\\Bigr], $$ the best that I could rederive was the following: $$\\begin{align} \\frac{n!}{(n-k)!} \\;&=\\; \\frac{n^{n-k+\\frac{1}{2}} n^k \\mathrm e^{n-k}}{(n-k)^{n - k + \\frac{1}{2}} \\mathrm e^n} \\cdot \\Bigl[1 \\pm o(1)\\Bigr] \\\\&=\\; n^k \\left(1 - \\frac{k}{n}\\right)^{-n+k-\\frac{1}{2}} \\mathrm{e}^{-k} \\cdot \\Bigl[1 \\pm o(1)\\Bigr]\\end{align}$$ which looks as though it should scale like $$ \\frac{n!}{(n-k)!} \\;\\;\\stackrel{\\;?\\,}\\sim\\;\\; n^k \\exp\\Bigl( - \\tfrac{k^2}{n} + \\tfrac{k}{2n} \\Bigr),$$ for all $k \\in o(n)$. This is close, but no cigar. Is there anything that I'm missing?\n\nshare|improve this question\nA comment on the \"illegible fraction\": the denominator seems to be a $4$. The numerator looks like a $2$, which doesn't make sense. It might also be a $3$. \u2013\u00a0 Andrew Uzzell Mar 6 '13 at 19:18\n@AndrewUzzell: that's more or less what I thought, too. Mind you, if it's as trivial a formula as they imply (and it doesn't seem as though it should be too hard to prove in principle if correct, right?) then it shouldn't be too hard to show it, and possibly discover that the value of the exponent plays a particular role. \u2013\u00a0 Niel de Beaudrap Mar 6 '13 at 19:19\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nAs you say, if $n$ approaches infinity so that $k/n\\to 0$, by Stirling's approximation $$ k! n^{-k} \\binom{n}{k} = (1 + o(1)) (1-\\frac{k}{n})^{-(n-k)} e^{-k}. \\qquad\\ \\ \\ (*) $$ Then, taking logarithms and expanding in a Taylor series with remainder gives \\begin{eqnarray*} \\log\\left((1-\\frac kn)^{-(n-k)} e^{-k}\\right)&=&-k-(n-k)\\log(1-\\frac kn)\\\\ &=& -k + (n-k) \\left(\\sum_{1\\le i\\le j} \\frac 1i (\\frac kn)^i + O((\\frac kn)^{j+1})\\right)\\\\ &=& -\\sum_{1\\le i\\le j-1} \\frac 1 {i(i+1)} \\frac{k^{i+1}}{n^i}+ O(\\frac{k^{j+1}}{n^j}) \\end{eqnarray*} for any fixed $j\\ge 1$. Exponentiating and substituting this back into $(*)$ gives, as $n\\to\\infty$, $$ \\binom{n}{k} = (1 + o(1)) \\frac{n^k}{k!} \\exp\\left(-\\sum_{1\\le i\\le j-1}\\frac{1}{i(i+1)} \\frac{k^{i+1}}{n^i} \\right),\\ \\ \\ \\text{where } k=o(n^{j/(j+1)}). $$ The formula in the Erd\u0151s-R\u00e9nyi paper is obtained by setting $j:=3$. The illegible exponent should then be $3/4$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/206854/whats-the-probability-that-abe-will-win\nText:\nTake the 2-minute tour \u00d7\n\nAbe and Bill are playing a fun game. Each of them roll a dice every turn. Abe succeeds if he rolls either a 1 or 2. Bill succeeds is he rolls either a 3, 4, or 5.\n\nIf they both succeed on a turn, then they tie the game. If exactly 1 player succeeds on a turn, then the succeeding player wins. If neither player succeeds on a turn, another turn occurs.\n\nWhat's the probability that Abe will win? I originally thought that the answer was $\\frac{2}{5}$, but I realized that the players could tie as well.\n\nshare|improve this question\nDoes Bill succeed if Abe rolls a $3$, $4$, or $5$? Or do they need to roll \"their\" number? \u2013\u00a0 Andr\u00e9 Nicolas Oct 4 '12 at 0:12\nThey both need to roll one of their numbers on their own dice. Good point. \u2013\u00a0 David Faux Oct 4 '12 at 0:13\nA non-mathematical comment: dice is plural, the singular being die. \u2013\u00a0 Brian M. Scott Oct 4 '12 at 0:28\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nOut of 36 (6x6) combinations of die rolls:\n\nAbe will win in 6 of them: (Abe rolls 1 or 2) AND (Bill rolls 1 or 2 or 6)\n\nBill will win in 12 of them: (Abe rolls 3 or 4 or 5 or 6) AND (Bill rolls 3 or 4 or 5)\n\nThe remaining lead to another roll, so they became irrelevant as only one of the 18 situation above finishes up the game.\n\nOut of 18 possible, and equally likely, game ends, Abe wins 6 times, thus:\n\nP{Abe wins} = 6/18 = 1/3\n\nshare|improve this answer\n\nLet $p$ be the probability that Abe eventually wins the game. This can happen in three ways:\n\n(i) (Immediately) Abe succeeds and Bill fails.\n\n(ii) Abe succeeds, and Bill does. Then they are tied. Given this, Abe's probability of ultimately winning is $p$.\n\n(iii) Abe and Bill both fail. Then we are in a situation similar to (ii).\n\nSo $$p=\\frac{2}{6}\\cdot\\frac{3}{6}+\\left(\\frac{2}{6}\\cdot\\frac{3}{6}\\right)p+\\left(\\frac{4}{6}\\cdot\\frac{3}{6}\\right)p.$$\n\nSolve. We get $p=\\dfrac{1}{3}$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/1956/is-there-an-integral-that-proves-pi-333-106\nText:\nTake the 2-minute tour \u00d7\n\nThe following integral,\n\n$$ \\int_0^1 \\frac{x^4(1-x)^4}{x^2 + 1} \\mathrm{d}x = \\frac{22}{7} - \\pi $$\n\nis clearly positive, which proves that $\\pi < 22/7$.\n\nIs there a similar integral which proves $\\pi > 333/106$?\n\nshare|improve this question\nHey, how do you know that it is clearly positive? is there something about the integral that makes it positive? \u2013\u00a0 Tyler Hilton Aug 10 '10 at 20:01\nIf $f(x)>0$ then $$\\int\\limits_{a}^{0} f(x)>0$$ \u2013\u00a0 anonymous Aug 10 '10 at 20:06\n@Affan, you're integrating a fraction of even powers: it can't be negative. \u2013\u00a0 Andrea Ambu Aug 11 '10 at 7:13\nYou can use $\\pi = \\int_0^1 \\frac{4}{1+x^2}$. Now the power series of $\\frac{4}{1+x^2}$ is alternating, thus stopping after odd/even numbers of terms gives under and overevaluations. Thus, for all $a< \\pi <b$ you can find $m, n$ so that $a< \\int_0^1 P_m(x) dx < \\pi < \\int_0^1 P_n(x) < b$, where $P_n$ denotes a Taylor Polynomial. \u2013\u00a0 N. S. Aug 3 '12 at 13:25\nadd comment\n\n3 Answers\n\nup vote 57 down vote accepted\n\nThis integral would do the job:\n\n$$\\int_0^1 \\frac{x^5(1-x)^6(197+462x^2)}{530(1+x^2)}= \\pi -\\frac{333}{106}$$\n\n  \u2022 Also you can refer to S.K. Lucas Integral proofs that $355/113 > \\pi$, Gazette, Aust. Math. Soc. 32 (2005), 263-266.\n\n  \u2022 This is the link. (Thanks to lhf for pointing out.)\n\nshare|improve this answer\nGreat! I had not expected anyone to answer this so quickly! \u2013\u00a0 anon Aug 9 '10 at 21:10\nHow does one come up with that integral, may I ask? \u2013\u00a0 ShreevatsaR Aug 9 '10 at 21:33\nmath.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf Please read this article \u2013\u00a0 anonymous Aug 9 '10 at 21:38\nThe link above is broken. The current one is educ.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf \u2013\u00a0 lhf Jun 10 '11 at 19:05\n@lhf: Thanks for the link. \u2013\u00a0 user9413 Jun 10 '11 at 19:09\nadd comment\n\nAlthough this is not exactly an answer to the question, it seems sufficiently related to mention: there are some direct generalizations, given on the Wikipedia page about this integral. For instance, $$0 < \\frac14\\int_0^1\\frac{x^8(1-x)^8}{1+x^2}\\ dx=\\pi -\\frac{47171}{15015}$$\n\nIn general, $$\\frac1{2^{2n-1}}\\int_0^1 x^{4n}(1-x)^{4n}\\ dx <\\frac1{2^{2n-2}}\\int_0^1\\frac{x^{4n}(1-x)^{4n}}{1+x^2}\\ dx <\\frac1{2^{2n-2}}\\int_0^1 x^{4n}(1-x)^{4n}\\ dx$$\n\nwhich for $n=1$ (the integral in the question) gives slightly better bounds than just $\\pi < 22/7$: $$ \\frac{1}{1260} < \\frac{22}{7} - \\pi < \\frac{1}{630}$$\n\nshare|improve this answer\nThank you! Doesn't that imply that pi is irrational? \u2013\u00a0 anon Aug 9 '10 at 21:17\n@muad: Without checking the asymptotics of the respective numerators and denominators, I'm not sure. It doesn't follow simply from the fact that the left and right expressions go to 0: for instance 1 is rational, but you could still find sequences of rational numbers $x_n, y_n, z_n$ such that $x_n$ and $y_n$ go to 0, but $x_n < 1 - z_n < y_n$ for all $n$. \u2013\u00a0 ShreevatsaR Aug 9 '10 at 21:31\n@anon For this to work, you'd have to show that the rational approximants converged suitably fast. See Dirichlet's irrationality test. \u2013\u00a0 A Walker Oct 19 '11 at 6:23\nadd comment\n\nIn the beginning of 2009 I was posting re similar issue at several sites, namely, at sci.math.symbolic, www.math.utexas.edu, etc.\n\nTo repeat: In Paper 1 Lucas found, by brute-force search using Maple programming, several different variants of integral identities which relate each of several first Pi convergents (described in terms of OEIS sequences as A002485(n)/A002486(n)) to Pi.\n\nFurther, in my above-mentioned postings, I conjectured the following identity below, which represents a generalization of Stephen Lucas' experimentally obtained identities between Pi and its convergents:\n\n$$(-1)^n\\cdot(\\pi - \\text{A002485}(n)/\\text{A002486}(n))$$\n\n$$=(|i|\\cdot2^j)^{-1} \\int_0^1 \\big(x^l(1-x)^m(k+(i+k)x^2)\\big)/(1+x^2)\\; dx$$\n\nwhere integer n = 0,1,2,3,... serves as index for terms in OEIS A002485(n) and A002486(n), and {i, j, k, l, m} are some integers (to be found experimentally or otherwise), which are probably some functions of n.\n\nThe \"interesting\" (I think) part of my generalization conjecture is that \"i\" is present in both:\n\ndenominator of the coefficient in front of the integral and in the body of the integral itself\n\nFor example, in cited by Lucas old known formula for 22/7\n\n22/7 - Pi = Int(x^4*(1-x)^4*/(1+x^2),x = 0 .. 1)\n\nn=3, i=-1, j=0, k=1, l=4, m=4\n\nIn Lucas's formula for 333/106 (mentioned above in the comment by Chandrasekhar)\n\nPi - 333/106 = 1/530*Int(x^5*(1-x)^6*(197+462*x^2)/(1+x^2),x = 0 .. 1)\n\nn=4, i=265, j=1, k=197, l=5, m=6\n\nIn Lucas's formula for 355/113\n\n355/113 - Pi = 1/3164*Int(x^8*(1-x)^8*(25+816*x^2)/(1+x^2),x = 0 .. 1)\n\nn=5, i=791, j=2, k=25, l=8, m=8\n\nIn Lucas's formula for 103993/33102\n\nPi - 103993/33102 = 1/75521*Int(x^14*(1-x)^12*(124360-77159*x^2)/(1+x^2),x = 0 .. 1)\n\nn=6, i= 47201, j=4, k=77159, l=14, m=12\n\nIn Lucas's formula for 104348/33215\n\n104348/33215 - Pi = 1/38544*Int(x^12*(1-x)^12*(1349-1060*x^2)/(1+x^2),x = 0 .. 1)\n\nn=7, i= -2409, j=4, k=1349, l=12, m=12\n\nI do not have computer math resources (Mathematica, Maple, etc.) to experimentally prove or disprove it for all larger n (but see my comment below).\n\nBest Regards, Alexander R. Povolotsky\n\nshare|improve this answer\nOne also could check and see that my above generalization formula also applies to identities obtained by Jaume Oliver Lafont, described in the \"Following Lucas (2009)\" section in oeis.org/wiki/User:Jaume_Oliver_Lafont/\u2026 \u2013\u00a0 Alex Apr 8 '12 at 21:20\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/240803/how-do-i-subtract-times/240808\nText:\nTake the 2-minute tour \u00d7\n\nI have an embarrassingly basic modular arithmetic question. I understand that I can subtract, for example, 1 hour from 10 o'clock to get 9 o'clock, or even 2 hours from 1 o'clock to get 11 o'clock; but how do I subtract 2 o'clock from 11 o'clock to get 3 hours.\n\nThat is, I want a function that takes two times on the face of a clock, and gives me the interval between them.\n\nFor example: I have two angular values measured in \"hours\". One value is the right ascension of the apparent sun, $\\alpha(t)$, while the other is the right ascension of the \"mean sun\", $\\langle\\alpha\\rangle(t)$; both are mod 24. I'm interested in the angular difference between these two values $$E(t) = \\langle\\alpha\\rangle(t) - \\alpha(t)$$ Is this just inherently ambiguous, so that I need to impose some additional constraint based on information about the system (e.g., here that the values can be positive or negative, and are always small, so that, say $\\pm 22$ should be interpreted as $\\mp 2$), or is there some simple systematic way to esnure that I get the correct values?\n\nshare|improve this question\nmath.stackexchange.com/questions/388361/\u2026 check this answer \u2013\u00a0 iostream007 May 11 '13 at 16:50\nadd comment\n\n4 Answers\n\nup vote 3 down vote accepted\n\nJust subtract. Your answer will only be well-defined mod 12 (because maybe 15 hours passed between 11 and 2 o clock). If you want a \"canonical\" answer, you can always take the least residue mod 12. In this case, we get $(2 - 11) = -9 = 3.$\n\nIn fancy language, the times on a clock are a torsor for $\\frac{\\mathbb{Z}}{12}$. John Baez has a great blog entry on this.\n\nshare|improve this answer\n@Jean-S\u00e9bastien: I've added an example of my application to make things a bit more concrete. \u2013\u00a0 raxacoricofallapatorius Nov 19 '12 at 20:01\nadd comment\n\n2 o'clock - 11 o'clock = -9 = 3 mod 12 ?\n\nshare|improve this answer\nadd comment\n\n$$ 2-11=-9\\equiv 3 \\mod 12 $$ you can take the absolute value of that, or work with the $24$ hours format and use the fact that $2$ is also $14$ and then have $$ 14-11=3 $$\n\nshare|improve this answer\nI think I need a nap... :-S \u2013\u00a0 amWhy Nov 19 '12 at 19:17\n@amWhy you only needed to add the fact that we work mod $12$ \u2013\u00a0 Jean-S\u00e9bastien Nov 19 '12 at 19:17\nI saw that others already covered that...I knew what I was thinking, but that's hardly the same as being clear and explicit in the first place! (+1) by the way! \u2013\u00a0 amWhy Nov 19 '12 at 19:36\n@amWhy I'd be down for a nap as well, great idea ;). I like the 24 hours format for that kind of thing. Obviously you could argue that the problem comes back if you want ot know the time difference between say $23$ hours and $2$ but that is equivalent to $11$ and $14$ anywya so \u2013\u00a0 Jean-S\u00e9bastien Nov 19 '12 at 19:46\nadd comment\n\nIf you just have times with no dates attached, you can't tell +2 from -22. You can choose to have the result be in the range $[-12,+12)$ or any other range of length $24$ like $(-5,19]$ that you like. Based on what you day, I would opt for one centered at zero.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/372638/100-sided-die-probability/372644\nText:\nTake the 2-minute tour \u00d7\n\nThe question is as follows: You are given a 100-sided die. After you roll once, you can choose to either get paid the dollar amount of that roll OR pay one dollar for one more roll. What is the expected value of the game? There is no limit on number of rolls.\n\nThe EV for a 100-sided die roll is 50.5, but the fact that you can pay a dollar for an extra roll complicates things. Not quite sure how to proceed.\n\nshare|improve this question\nUnless I'm misreading the question, the EV should be infinite. The WORST you can do is an infinite string of {1}s, with probability 0, in which case you end up with $0. However, EVERY other roll you get nets you money. \u2013\u00a0 Foo Barrigno Apr 25 '13 at 17:07\n@FooBarrigno No, the payout is the last value you rolled, not the sum. \u2013\u00a0 gt6989b Apr 25 '13 at 17:10\nwouldn't it just be 50? Your EV of the first roll is 50.5 and your EV of the second roll is 49.5 since you've paid a dollar. This problem also has the constraint that you can choose to roll again or keep your money, so doesn't that play in to calculating this stuff? \u2013\u00a0 Eleven-Eleven Apr 25 '13 at 17:23\n@gr6968b Ah, that clears it up then. I'm not sure how I missed the words \"that roll\" in the problem statement. \u2013\u00a0 Foo Barrigno Apr 26 '13 at 18:00\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nIf the expected value of this game is $a$, then at a die roll of $X$ you have the choice of either collecting $X$ or paying a dollar and restart, which gives you an expected value of $a-1$. To maximize the expected value, you should take $X$ if $X> a-1$ and start over if $X\\le a-1$ (it does not really matter what we do when $X=a-1$). We obtain therefore $$ a = \\frac1{100}\\left(\\lfloor a-1\\rfloor\\cdot a+\\sum_{k=\\lfloor a-1\\rfloor+1}^{100}k\\right) =\\frac1{100}\\left(\\lfloor a-1\\rfloor\\cdot a+\\frac{100\\cdot101}{2}-\\frac{\\lfloor a-1\\rfloor \\cdot\\lfloor a\\rfloor}{2}\\right). $$ I find numerically (didn't do much code checking, but the results are somewhat plausible) $$a\\approx87.3571 $$ which seems to be exactly (and of course the true result must be rational) $$a=87\\frac{5}{14}.$$ But I'm sure you can do the justification after the fact, i.e. show that the strategy that consists in continuing until you roll at least $87$ gives you $87\\frac{5}{14}$ as expected value.\n\nFor your convenience, here is the PARI one-liner:\n\n\nIf an extra roll costs two dollars instead of one, the result would be $$a=82\\frac12$$ instead, and with a cost of only $0.1$ dollars it would be $$a=96\\frac1{10}.$$\n\nshare|improve this answer\nI get an expected value of 1135/13 = 87.30... for the strategy \"Roll until you get higher than 87\" and an expected value of 1223/14 = 87.35... for the strategy \"Roll until you get higher than 86\". This seems to be the best strategy. \u2013\u00a0 Charles Apr 25 '13 at 17:55\nadd comment\n\n\nIf your value now is $X_t$, what is the marginal value of the roll? If you roll $R \\sim \\mathcal{U}[1,100]$, then if $R > X_t+1$ you gained and if $R \\leq X_t+1$, you either lost or became indifferent. So what is the marginal value?\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/65472/official-name-and-complexity-of-k-way-balanced-set-partitioning-what-is-the-be?sort=newest\nText:\nTell me more \u00d7\n\nAs a lot of people know, graph partitioning is NP-Complete. In graph partitioning, you try to create k balanced (within some pre-specified epsilon) disjoint subsets of (possibly weighted) vertices such that the edgecut is minimized. (See\n\nBut what about the simpler problem of partitioning a set of arbitrarily weighted objects into k balanced disjoint subsets, seeking to minimize not some edgecut (only applicable to graph) but the imbalance itself?\n\nIt seems this simpler problem is itself still either NP-Complete or at least NP-Hard, based on similarity to problems such as Graph Partitioning, Bin Packing, Subset Sum, Multiprocessor Scheduling, Set Cover, etc.\n\nIs there a real name for this problem (other than the one I made up in the title)?\n\nAnd does anyone know of a formal paper or some other official, citable source proving its complexity?\n\nLast but not least, and this is the primary reason why I am looking for the name/complexity, what is the best known heuristic for this problem?\n\n(I am currently doing a greedy approach-- iteratively placing the next heaviest object in the total set on the currently lightest partition. But is it possible to do better?)\n\n\nshare|improve this question\nExcuse my density: what about putting vertex I in part J, where J = I mod k? I assume conseuctively numbered v ertices and parts. Gerhard \"Ask Me About System Design\" Paseman, 2011.05.19 \u2013\u00a0 Gerhard Paseman May 19 '11 at 20:27\nBut what about the case in which vertices are weighted? (Or general objects, not necessarily vertices, for the simplified version.) I am working with case where objects can have arbitrary weights. \u2013\u00a0 user15230 May 19 '11 at 21:53\nI have edited my question to clarify that the objects/vertices can have arbitrary weights, thanks Gerhard. \u2013\u00a0 user15230 May 19 '11 at 22:00\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nThe problem is NP-complete, because it contains the problems Partition and 3-Partition (problems 41 and 46 in If your instances are not extremely huge, I would give an integer programming formulation a try. The heuristics build into modern solvers will probably be competitive (and come without any implementation work on your side).\n\nFor a heuristic, local search seems to be a natural approach. After greedily generating a start solution you can repeat the following steps.\n\n  \u2022 pick blocks $A$ and $B$ with maximal weight difference $w(A)-w(B)$\n  \u2022 find subsets $A'\\subseteq A$ and $B'\\subseteq B$ such that $|w((A\\setminus A')\\cup B')-w((B\\setminus B')\\cup A')|<w(A)-w(B)$\n  \u2022 replace $A$ by $(A\\setminus A')\\cup B'$ and $B$ by $(B\\setminus B')\\cup A'$\n\nTo spice it up a bit one could GRASP it (see ). That just means that the greedy generation of the start solution is randomized: instead of adding the heaviest object to the lightest block, an object, randomly chosen from the $k_1$ heaviest is added to a block randomly chosen from the $k_2$ lightest. Then you start the local search, and when that becomes boring, you just generate a new randomized greedy start solution. This procedure is iterated very often with varying $(k_1,k_2)$, and one can keep track of which parameters $(k_1,k_2)$ tend to lead to good solutions.\n\nshare|improve this answer\nUnfortunately I typically have several million arbitrarily weighted objects, sometimes much more, and am guessing this may qualify as huge. My guess is that heuristics that are tailored to the characteristics of this problem instead of the IP formulation may perform better. \u2013\u00a0 user15230 May 20 '11 at 0:06\nI noticed the connection to Partition/3-Partition but they're not exactly instances of the problem I mention. Aren't partition/3-partition decision problems (vs the optimization problem in my question)? It's a relatively small difference I'll admit but... If possible, I'd really like to know if there is a name/proof for this k-partition optimization generalization of Partition/3-Partition. If no one can find a name/proof for the generalization after a few days, I'll assume neither exist and I'll mark your answer correct. :) (I've already googled for a few hours with no success.) \u2013\u00a0 user15230 May 20 '11 at 0:10\nBy definition, NP-completeness always refers to decision problems. A decision problem corresponding to your optimization problem would be: Given $n$ objects, an integer $k$ and a bound $L$, can they be partitioned in $k$ blocks such that the weights of two blocks differ by at most $L$. Partition: $k=2$, $L=0$ 3-partition: $k=m$, $L=0$ (the $m$ from the fromulation of 3-partition in my link) \u2013\u00a0 Thomas Kalinowski May 20 '11 at 0:43\nAccording to the abstract, the paper has a heuristic for minimizing the maximum weight difference, but subject to the additional constraint that the blocks contain roughly the same number of objects. \u2013\u00a0 Thomas Kalinowski May 20 '11 at 1:32\nI didn't find the Zhang et al paper you link to-- that's a good catch. Even though the paper requires an additional cardinality balance (not what I'm looking for), the paper itself cites other papers that are indeed about my problem (no cardinality constraint) and seem to hint there is no commonly agreed upon name, eg \"set partitioning\", \"multiway number partitioning\", etc. I knew such papers had to exist, but couldn't find them. Thanks! :) \u2013\u00a0 user15230 May 21 '11 at 7:12\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/27524/fair-value-of-a-hat-drawing-game\nText:\nTell me more \u00d7\n\nI've been going through a problem solving book, and I'm a little stumped on the following question:\n\nAt each round, draw a number 1-100 out of a hat (and replace the number after you draw). You can play as many rounds as you want, and the last number you draw is the number of dollars you win, but each round costs an extra $1. What is a fair value to charge for entering this game?\n\nOne thought I had was to suppose I only have N rounds, instead of an unlimited number. (I'd then let N approach infinity.) Then my expected payoff at the Nth round is (Expected number I draw - N) = 50.5 - N. So if I draw a number d at the (N-1)th round, my current payoff would be d - (N-1), so I should redraw if d - (N-1) < 50.5 - N, i.e., if d < 49.5. So my expected payoff at the (N-1)th round is 49(50.5-N) + 1/100*[(50 - (N-1)) + (51 - (N-1)) + ... + (100 - (N-1))] = 62.995 - N (if I did my calculations correctly), and so on.\n\nThe problem is that this gets messy, so I think I'm doing something wrong. Any hints/suggestions to the right approach?\n\nshare|improve this question\ncan you share which book you found this problem? thanks. \u2013\u00a0 Qiang Li Mar 17 '11 at 21:18\nadd comment\n\n3 Answers\n\nConsider what happens in the first stage. You get a number out of the hat, and either stop or go on. And you do it in some \"optimal\" way (maximizes expectation). If you do go on, the rule that will ensure you the maximal expectation is the same rule you used before - your original optimal rule.\n\nThis shows that your stopping rule can be characterized by some threshold $X$, which is the minimal number for which you'd stop (alternatively we could have chosen $X-1$, which is the maximal number for which you'd go on). Denote the expected gain by $E$. We have $$ E = -1 + \\frac{X-1}{100}E + \\frac{\\sum_{t=X}^{100} t}{100} = -1 + \\frac{X-1}{100} + \\frac{(100-X+1)(100+X)}{200}. $$ Multiplying by $200$ and rearranging, we get $$ 2(101-X)E = (101-X)(100+X) - 200. $$ Therefore $$ E = \\frac{(101-X)(100+X) - 200}{2(101-X)}. $$ This is maximized by $101 - 10\\sqrt{2} \\approx 86.86$. Thus the best value for $X$ is either $86$ or $87$. These values give $E \\approx 86.33$ and $E \\approx 86.37$, so $X = 87$ is better, and the value of the game is $1209/14$.\n\nMy calculations don't agree with Ross's, so there's probably a mistake somewhere; this doesn't invalidate the method.\n\nshare|improve this answer\nOur philosophies are the same. I think the difference is the factor $\\frac{100\u2212\u230aR\u230b}{100}$ in my first term, which is the chance that the next draw will be accepted. I think that should multiply your third term, which is the $\\frac{100+\u230aR\u230b}{2}$ part. I just edited my subtraction of the cost of another play, which decreased the expected value by 1. It appears it \"wants\" the expected value to be just below a natural. \u2013\u00a0 Ross Millikan Mar 17 '11 at 6:12\nadd comment\n\nYour expected return if you draw a number on the last round is 49.5 (because it costs a dollar to make the draw). On round N-1, you should keep what you have if it is greater than 49.5, or take your chances if it is less. The expected value if N=2 is then $\\frac {51}{100}\\frac {100+50}{2} -1 + \\frac {49}{100}49.5=61.505$ where the first term is the chance that you keep the first draw times the expectation of that draw (assuming you will keep it), the second is the cost of the first draw, and the third is the chance that you will decline the first draw and take your chances on the second times the expectation of the second draw.\n\nAdded: As Yuval makes more explicit, your strategy will be to quit when you get a number at least $X$. The gain then is $\\frac{100+X}{2}-\\frac{100}{101-X}$ where the first is the payoff and the second is the cost of the expected number of plays. As he says, this is maximized at X=87 with value $\\frac{1209}{14}=86.3571$. I'll have to think where I was a bit off.\n\nshare|improve this answer\nadd comment\n\nEdit: I've added some information about the game with a restricted number $N$ of rounds, since the OP mentioned this.\n\nJust a comment to complement the nice answers we have already.\n\nThere is an algorithm that calculates the optimal strategy and the value of each state for such an optimal stopping problem.\n\nLet $f(x)$ be the payout at each state $x\\in {\\cal S}$ for the underlying Markov chain $(X_n)$, and let $g(x)$ be the cost of leaving state $x$.\n\nSet $u_0=f$ and for $N\\geq 1$ put $u_N=\\max(Pu_{N-1}-g,f)$. Here $P$ is the transition matrix of the Markov chain. Then $u_N$ is the value function for the restricted game with at most $N$ rounds; that is, $$u_N(x)=\\sup_{T\\leq N}\\ \\mathbb{E}\\left[ f(X_T)\\, | \\, X_0=x\\right],$$ where the supremum is over all stopping times $T$ that satisfy $T\\leq N$.\n\nAs $N\\to\\infty$, we get $u_N\\uparrow v$ where $v$ is the value function for the unrestricted game. The optimal strategy is to stop when the chain hits the set $\\lbrace x: f(x)=v(x)\\rbrace$. Here $v(x)$ means the value of state $x$, i.e., $v(x)$ is the maximum expected payout starting in state $x$ and using any finite stopping time $T$ as a strategy:\n\n$$v(x)=\\sup_T\\ \\mathbb{E}\\left[ f(X_T)\\, | \\, X_0=x\\right].$$\n\nThis is all nicely explained in the section on Optimal Stopping in Gregory Lawler's book \"Introduction to Stochastic Processes\".\n\nIn your problem we have $f(x)=x$ for $1\\leq x\\leq 100$, and $g(x)\\equiv 1$. Your Markov chain $(X_n)$ is a sequence of independent, uniform $\\lbrace 1,2,\\dots, 100\\rbrace $ random variables. Thus the $P$ operator applied to $h$ gives the constant function whose value is the average value of $h$, that is, $Ph(x)\\equiv \\sum_{i=1}^{100} h(i)/100$. So we calculate $$u_0(x)=x,\\quad u_1(x)=\\max\\left(x,{99\\over 2}\\right), \\quad u_2(x)=\\max\\left(x,{12301\\over 200}\\right). $$\n\nTaking very large $N$ gives $$v(x)\\approx \\max\\left(x,{86.35714}\\right),$$ which shows that the optimal strategy (over all finite stopping times!) is to quit as soon as we get $87$ or higher, and the value of the game is $86.35714$ dollars.\n\nIn your problem it is pretty straightforward to calculate the exact answer, but this algorithm also gives the answer for more complicated games where exact calculations are not so easy.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/62426/generating-bernoulli-correlated-random-variables-with-space-decaying-correlation\nText:\nTell me more \u00d7\n\n\nI have a set of N objects randomly distributed in a 2D physical space. Each object (i) generates a bernoulli random number (0 or 1) based on a marginal probability Pr(xi = 1) = p. These objects a correlated by physical distance. The closer the objects are, the larger their correlation is.\n\nE.g. If objects i and j are co-located, they are expected to generate correlated results. For Example, if P(Xi=1)= 0.6 and P(Xj=1)=0.3 they would produce something like:\n\nXi= 0 1 0 1 1 1 0 1 0 1\n\nXj= 0 1 0 0 0 1 0 1 0 0\n\nSuch that Pr(Xi|Xj)=1\n\nOn the other hand if i and j are distant they would produce uncorrelated results such that Pr(Xi|Xj)=Pr(Xi)\n\nI have tried to use some of the packages in Matlab (Sampling from multivariate correlated binary and poisson random variables) and R (bindata) but I could not produce an acceptable correlation matrix.\n\nAny ideas how I can produce an acceptable correlation matrix?\n\nBTW, I have checked the following earlier posts discrete stochastic process: exponentially correlated Bernoulli?\n\n\nConstructing Bernoulli random variables with prescribed correlation\n\nBut I am not sure how I can relate to them.\n\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nHere's a suggestion:\n\nDefine a non-negative decreasing function $w(r)$ measuring interaction strength. Given each object its own independent $N(0,1)$ random variable $N_i$. Now set $$ Y_i=\\frac{\\sum_{j}w(\\|x_i-x_j\\|)N_j}{\\sqrt{\\sum_j w(\\|x_i-x_j\\|)^2}}, $$ where $x_i$ denotes the location of the $i$th object.\n\nThen the $Y_i$ are correlated $N(0,1)$ random variables. If two objects are co-located the normal random variables agree.\n\nFinally set $t_i=\\Phi^{-1}(p_i)$ (i.e. $\\mathbb P(N < t_i)=p_i$) and set $X_i=1$ if $Y_i < p_i$ and 0 otherwise.\n\nWith this setup you can write down the covariance of $Y_i$ and $Y_k$ explicitly: it's just $$ \\text{Cov}(Y_i,Y_k)=\\frac{\\sum_j w(\\|x_i-x_j\\|)w(\\|x_k-x_j\\|)} {\\sqrt{\\sum_j w(\\|x_i-x_j\\|)^2\\sum_j w(\\|x_k-x_j\\|)^2}}. $$\n\nIf you write this as $\\cos\\theta_{ik}$ then you can write the covariance of $X_i$ and $X_k$ as an integral: $$ 1/(2\\pi)\\int_{ x < t_1\\;,\\; cos\\theta_{ik}x+\\sin\\theta_{ik}y < t_2} e^{-(x^2+y^2)/2}\\,dxdy-p_ip_k. $$\n\nshare|improve this answer\nIf i understood you correctly, what you are saying is to simply use the Cov(Yi,Yk) above as the covariance matrix and plug it in the bernoulli generator. If so, then Unfortunately, I tried that but I keep getting an Unacceptable correlation matrix, which seams to be not positive definite. \u2013\u00a0 alandalusi Apr 26 '11 at 21:44\nNo you didn't understand me correctly. Here is my concrete suggestion. (1) Compute $t_i=\\Phi^{-1}(p_i)$; (2) Compute the matrix $Cov(Y_i,Y_k)$ as above (3) Use a multivariate normal generator to build some $Y_i$'s. (4) Set $X_i=1$ if $Y_i<t_i$ and 0 otherwise. You could compute the covariance of the Bernoulli's (using the nasty integral formula I wrote down), but if your purpose is to just generate the random #s, then the procedure I described will work just as well. \u2013\u00a0 Anthony Quas Apr 26 '11 at 22:59\nAcually, It is positive definite, but does not have a dichotomized Gaussian distribution for the correlation matrix. \u2013\u00a0 alandalusi Apr 26 '11 at 23:03\nOK, I think I understand your suggestion now. I will test it right away. \u2013\u00a0 alandalusi Apr 26 '11 at 23:32\nIt works!, but I noticed that the Correlation (or Conditional Probabilities) $Pr(X{_i}=1|X{_k}=1)$ between any fixed pair (i and k) slightly change as we add more objects into the physical space. So, I changed $Cov(Y{_i},Y{_k})$ to be $w(||x{_i}-x{_k}||)$ and it worked with fixed conditional probabilities, even if I add more objects. I am still testing it, but does this make sense to you? For your information, my distance functions is $e^{(-\\frac{eucaliandistance}{dcorr})}$ \u2013\u00a0 alandalusi Apr 27 '11 at 16:33\nshow 1 more comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/346134/packing-radios-into-cartons-why-is-my-solution-wrong/346141\nText:\nTake the 2-minute tour \u00d7\n\nA manufacturer of car radios ships them to retailers in cartons of $n$ radios. The profit per radio is $\\$59.50$, minus shipping cost of $\\$25$ per carton, so the profit is $59.5n-25$ dollars per carton. To promote sales by assuring high quality, the manufacturer promises to pay the retailer $\\$200X^2$ if $X$ radios in the carton are defective. Suppose radios are produced independently and that $5\\%$ of radios are defective. How many radios should be packed per carton to maximize expected net profit per carton?\n\nMy solution:\n\nSuppose that $n$ radios are packed into a carton. Then, the expected profit is clearly $$\\mu = 59.5n-25-200(0.05n)^2$$ Simplifying we get $$\\mu = 59.5n-25-0.5n^2$$\n\nWe want to find a maximum, so we find a derivative:\n\n\nClearly there is just one maximum, so set $\\mu'=0$ we find that $$n^2=59.5$$ and thus $$n\\approx 7.7136\\dots$$This however seems to be wrong. The textbook gives an answer of exactly $50$ in the solution without any explanation of the steps.\n\nshare|improve this question\nadd comment\n\n3 Answers\n\nup vote 2 down vote accepted\n\n$X$ is binomially distributed with $n$ trials and success probability $0.05$. For any random variable $X$ whose mean and variance exist, \\begin{eqnarray*} {\\Bbb E}X^2&=&({\\Bbb E}X)^2+\\text{Var } X, \\end{eqnarray*} and since the mean and variance of a binomial distribution with $n$ trials and success probability $p$ are $np$ and $np(1-p)$, in this case this equals \\begin{eqnarray*} &&(0.05 n)^2+n\\cdot 0.05 \\cdot (1-0.05)\\\\ &=& 0.0025 n^2+0.0475 n \\end{eqnarray*} and the expected profit is \\begin{eqnarray*} &\\ &59.5n-25-200{\\Bbb E}X^2\\\\ &=&59.5n-25-0.5n^2-9.5n\\\\ &=&1225-\\frac 12 (n-50)^2, \\end{eqnarray*} which is maximized at $n=50$.\n\nshare|improve this answer\nadd comment\n\nThe expected loss isn't just $(0.05n)^2$, you must compute its average the hard way ($\\mathbb{E}(x^2) \\ne (\\mathbb{E}(x))^2$ in general!). If the probability of $n$ ones broken is $p_n$, your expected loss due to breakage is $$ \\sum_{n \\ge 0} p_n \\cdot 200 n^2 = 200 \\sum_{n \\ge 0} p_n n^2 $$ Presumably you can start assuming that the number of radios in each box isn't limited, that should give a starting point. Once you have an approximate number of radios per box, refine.\n\nshare|improve this answer\nadd comment\n\nThe profit $Y$ is given by $$Y=59.5n -25-200 X^2,$$ where $X$ is the number of defectives.\n\nThe number of defectives has binomial distribution, with $p=0.05$.\n\nWe want to find $E(X^2)$. There are various ways to do this. One way is to recall that the relevant binomial has mean $np$ and variance $np(1-p)$. But the variance of $X$ is $E(X^2)-(E(X))^2. So E(X^2)=np(1-p) +n^2p^2$.\n\nThere are various other ways to find $E(X^2)$.\n\nSo we are maximizing $59.5n-25-200np(1-p)-200n^2p^2$, which in this case is $-(0.5n^2 -50n +25)$.\n\nFor the maximization, complete the square, or use calculus.\n\nThe answer does turn out to be exactly $50$.\n\nRemark: You asked why your answer was wrong. One way was uninteresting. You differentiated $59.5n-0.5n^2$ and got $59.5-n^2$ instead of the correct $59.5-n$.\n\nThat would have given an answer of $59.5$, say $60$-ish.\n\nThe actual answer is less, and for an interesting reason. The penalty for bad radios is $200X^2$. This is quite sensitive to large values of $X$. Roughly speaking that explains why the optimal number of radios is smaller than the $59.5$ given by your method.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/114879/an-optimization-problem-non-complete-bipartite-graph-and-hungarian-algorithm/114954\nText:\nTake the 2-minute tour \u00d7\n\nI have two tables at my disposal, one work dataset and one reference dataset. Each dataset has got two columns, lets say these are fields A and B. I would like the rows in reference dataset with the rows in work dataset that are 'closest' w.r.t. some distance. I have more rows in work dataset than in reference dataset, and i will match all rows in reference dataset to some rows in work dataset.\n\nI can define distance between two rows in reference and wrk dataset like this:\n\n$ d_{i,j} = (A_{w}(i) - A_{r}(j))^{2} + (B_{w}(i) - B_{r}(j))^{2} $\n\nwith $A_{w}, A_{r}, B_{w}, B_{r} $ the A and B columns work and reference datasets with obvious notation.\n\nIn other word, i want to minimize over all permutations of rows from the work dataset (with the same number of rows as in reference dataset) the sum of distances between one row in reference dataset and one row in wrk dataset.\n\nI do not know how to proceed if not examining all permutations.\n\nThis is combinatorial problem. What about stochastic methods: genetic algorithm, swarm...\n\nCould you hint at some idea for a start ?\n\nI had a look at linear assignment problem. However, my problem is not a complete bipartatite graph representation, it is not complete since there can be more peaks in work signal than there are in reference signal.\n\nThanks !\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's a standard trick to convert the min cost matching problem on a balanced bipartite graph to one on an unbalanced bipartite graph. Let $G = (X \\cup Y, E, w)$ be the bipartite graph where $E \\subset X \\times Y$ and $|X| \\le |Y|$.\n\nNow create a copy of $G$ and add it \"reversed\", so that in the new graph both sides have exactly $|X| + |Y|$ vertices. All old edges have their same weight: edges between vertices in $X$ and their copies have weight $\\infty$, and edges between vertices in $Y$ and their copies have weight zero.\n\nNow run the usual algorithm, and the solution will have cost exactly twice the unbalanced cost.\n\np.s the fact that the graph is not complete is irrelevant - you can always pretend that there are dummy edges with infinite weight.\n\nWhile the above method works, it's inefficient. there's a recent (2012) paper by Ramshaw and Tarjan on exactly this problem.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/149325/finding-extremas-of-a-three-variable-function\nText:\nTake the 2-minute tour \u00d7\n\nFind all points on he portion of the plane $x+y+z=5$ in the first octant at which $f(x,y,z)=xy^2z^2$ has a maximum value.\n\nAttempt; Since $x+y+z=5$; $x=5-y-z$. I plug this into the $f(x,y,z)$: $$f(5-y-z,y,z)=u(y,z)=y^2 z^2 (5-y-z)=\\text{5 }y^2 z^2-y^3 z^2-y^2 z^3$$\n\nNow I find critical points: $$u_y=10 yz^2-3y^2z^2-2yz^3=0$$ $$u_z=10 y^2 z-2 y^3 z-3 y^2 z^2=0$$\n\nThe solution for this system of equations is $y=z=0$.Therefore, $x=5$. So thats the only critical point $(0,0,5)$ I get and $f(0,0,5)=0$. The answer should be a max at $(1,1,2)$ according to the answer key. How do I get it? Any hints please.\n\nshare|improve this question\nit's $(1,2,2)$. Typing sol \u2013\u00a0 Simon Markett May 24 '12 at 19:03\nYou missed a solution of the system of two equations. Not surprising, they are messy equations. \u2013\u00a0 Andr\u00e9 Nicolas May 24 '12 at 19:05\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nThe maximum is at $(1,2,2)$ (I assume there is a typo, either in your question or in the answer key.)\n\nYou did everything correctly up to the point where you determine the critical points. We have\n\n$$10yz^2-3y^2z^2-2yz^3=0$$ and $$10y^2z-2y^3z-3y^2z^2=0$$\n\nThe solution is not only $z=y=0$, but it is a sufficient condition if either $y$ or $z$ is $0$. You also get a solution where $z,y\\neq 0$.\n\nFirst look at the original function. In the first octant the values are non-negative. If $y=0$ or $z=0$ the value is also $0$. So let us assume both are positive. Then the equations simplify to\n\n$$10-3y-2z=0$$ and $$10-2y-3z=0$$\n\nWe see easily that the only solution is $y=z=2$ which yields $x=1$.\n\nshare|improve this answer\nI see. But, how do you come to a conclusion that if $y$ and $z$ are positive then the equations simplify in that way? \u2013\u00a0 Koba May 24 '12 at 19:32\n@Dostre :The kicker is that we can write them in factored form as $(10-3y-2z)yz^2=0$ and $(10-2y-3z)y^2z=0$, so if we take $y,z$ to be non-$0$ (we don't actually need to assume positive), then we may divide the two equations by $yz^2,y^2z$ (respectively) to get the simplified equations given by Simon. Now, of course, we are looking for a solution in the first octant, so if the solution to that system of equations didn't have $y,z$ positive, then it wouldn't actually be the solution we wanted, at all. \u2013\u00a0 Cameron Buie May 24 '12 at 20:40\nYeah. Now I understand it completely. Thanks. \u2013\u00a0 Koba May 25 '12 at 4:58\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/270578/laplace-boundary-problem\nText:\nTake the 2-minute tour \u00d7\n\nConsider a boundary given by vertices $(0,a)$, $(0,0)$ and $(1,0)$ (an 'L' shaped boundary).\n\nThe problem is to find the equation that passes between the endpoints $(0,a)$ $(1,0)$ of minimum length that encloses a specified area $A$.\n\nA trivial case would be $A=a/2$ in which case the solution would be a line.\n\nThis is one dimensional Laplace problem with two boundaries (area and lenth) but how do I try to get a series solution for $A < a/2$?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nThe formulation is as follows: Maximize $$L[y]=\\int_{x_1}^{x_2}\\sqrt{1+y'\\ ^2}\\ dx$$ subject to $$A=\\int_{x_1}^{x_2}y\\ dx$$ We can use Lagrange multipliers for a new formulation such as $$G=\\sqrt{1+y'\\ ^2}+\\lambda \\ y$$ and the Euler equation is $$\\frac{\\partial G}{\\partial y}-\\frac{d}{dx}\\frac{\\partial G}{\\partial y'}=\\lambda-\\frac{d}{dx}\\bigg(\\frac{y'}{\\sqrt{1+y'\\ ^2}}\\bigg)=0$$ where the open formulation is $$\\lambda-\\frac{1}{\\big(1+y'\\ ^2\\big)^{3/2}}=0$$ and can be solved for y such as $$y[x]=\\alpha \\ x^2+\\beta \\ x +\\gamma\\qquad \\alpha=\\frac{1}{2}\\sqrt{\\frac{1}{\\lambda^{2/3}}-1}$$ To satisfy the conditions to pass through points $(0,a)$ and $(1,0)$; and $A=\\int_{x_1}^{x_2}y\\ dx$ $$y[x]=(3a-6A)\\ x^2+(6A-4a)\\ x +a$$\n\nshare|improve this answer\nadd comment\n\nWelcome to Math.SE! This is an interesting question which would be approached in different ways depending on the context in which it arrives (e.g., level of a course). For example, the curves could be assumed to be smooth or merely rectifiable. They could be assumed to be graphs, or not. The attainment of minimal length could be taken for granted, or require a proof. All this makes it hard to pitch the answer at the right level, and I'm most likely going to fail at that. Indeed, I do not see how one would get a solution in the form of a series, because in general the minimizer is not analytic. If this problem comes from a textbook, it would be helpful to have a reference so that an answer can be given within the context of that book.\n\nIf the existence and differentiability of a minimizing curve can be granted, then there is a variational argument to show it must have the same curvature at all points where it does not meet the constraint (i.e, does not lie on the vertical or horizontal axis). Indeed, write the curve in vector form $\\gamma(t)$, parametrized by arclength, and consider the perturbation $$\\Gamma(t)=\\gamma(t)+\\epsilon \\eta(t) R\\gamma'(t)$$ where $\\epsilon$ is a parameter, $\\eta$ is a smooth function with compact support, and $R$ denotes rotation by $\\pi/2$ clockwise. Note that $(Ru)\\times v =u\\cdot v$ and $u\\times Rv=-u\\cdot v$. The area bounded by $\\Gamma$ is expressed as an integral of $\\Gamma\\times \\Gamma'$, in which the linear term in $\\epsilon $ simplifies to $$2\\epsilon \\eta \\gamma'\\cdot \\gamma' - \\epsilon (\\eta \\gamma\\cdot \\gamma')' $$ Here the first term yields $2\\epsilon \\int \\eta$ and the second integrates to zero. Thus, we should have $\\int \\eta=0$ to preserve the area up to $O(\\epsilon^2)$.\n\nThe length of $\\Gamma$ is given by the integral of $|\\Gamma'(t)| = (\\Gamma'(t)\\cdot \\Gamma'(t))^{1/2}$ in which the linear term simplifies to\n$$ \\epsilon \\eta (\\gamma' \\cdot R\\gamma'') = \\epsilon \\eta \\kappa $$ where $\\kappa$ is the curvature of $\\gamma$. The conclusion is that $\\int \\eta \\kappa =0$ for any $\\eta$ such that $\\int \\eta =0$. Equivalently, $\\kappa$ is constant.\n\nThus, the minimizing curve will be a circular arc as long as it is free to move; i.e., as long as it does not hit the obstacle (vertical or horizontal axes). And the obstacle does get involved when $A$ is so small that no circular arc through $(0,a)$ and $(1,0)$ can bound area $A$ and stay within the first quadrant. When the obstacle takes effect, the minimizing curve consists of parts of the vertical and/or horizontal axes joined by a circular arc that is tangent to them. An obstacle must always be met tangentially: otherwise the point of contact could slide along the obstacle, decreasing length. This takes a separate perturbation argument, into which I will not go.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.math.niu.edu/~rusin/known-math/95/volume.polyh\nText:\nFrom: (Boyan I. Boyanov) Newsgroups: sci.math Subject: Volume of a tetrahedron Date: 27 Mar 1995 00:30:42 GMT Hi, I have a stupid question that I cannot solve myself and cannot find the answer to in any of the math handbooks I've looked at. Is there a general formula for the volume of an ARBITRARY polyhedron? I know everything there is to know about the polyhedron - the coordinates of the vertices, the equations of the planes that form the walls, the number of walls, the number of sides, the number of vertices, etc. About the only restriction that is put on the polyherdon is that it is \"convex\", i.e. all vertices lie in a single \"half-space\" relative to any wall. I was trying to do it by breaking up the polyhedron into a collection of tetrahedra and summing up the volumes of the tetrahedra, but I can't seem to come up with an algorithm that allows me to determine which vertices form the tetrahedra that make up the polyhedron. Any ideas? Is there a better nad easier way to do this? Please Cc: me if you post a followup, if at all possible. Thanks! Boyan -- Boyan I. Boyanov ============================================================================== From: (Dave Rusin) Newsgroups: sci.math Subject: Re: Volume of a tetrahedron Date: 27 Mar 1995 22:52:56 GMT In article <3l50vi$>, Boyan I. Boyanov wrote: >Is there a general formula for the volume of an ARBITRARY polyhedron? Well, I suppose I ought to answer this since I just advertised Green's theorem for a similar purpose. In this question, the author wants a space integral integral_P 1 dxdydz where P is the polyhedron. The corresponding technique is to use Stokes' Theorem, whose general form _ _ _/ w = _/ dw boundary(S) S (for w any differential form on S) specializes for 2-forms to _ _ _/ P dxdy + Q dydz + R dzdx = _/ (dP/dz + dQ/dx + dR/dy) dxdydz so we can get the space integral of 1, for example, by integrating the 2-form z dxdy over the surface of the polyhedron. We can compute the surface integrals face-by-face. The quick answer here is that the individual surface integrals, when divided by the area of the face, would compute the average value of the z coordinate on the face. Therefore, we can compute the surface integrals easily by averaging the z coordinates of the vertices of the face, and multiplying by an area: the surface integral int( zdxdy ) over a face spanned by (x0 y0 z0), (x1 y1 z1), and (x2 y2 z2) is (z0+z1+z2)/3 . | (1/2)( y1.(x0-x2) + y2.(x1-x0) + y0.(x2-x1) ) | This surface integral is added to the total if the three points are in counterclockwise order as seen from the outside of the polyhedron, subtracted otherwise. A proof is appended as a postscript to this post; it may perhaps reinforce an understanding of surface integrals. It perhaps bears mentioning that this procedure does not assume the polyhedron is convex, nor indeed homeomorphic to a sphere. It does assume that the polyhedron is closed (no boundary) and a triangularization of a manifold (which will then be compact and orientable, conditions which I would otherwise have to add). It is not necessary that all the faces be triangles, really, although any other polygons may be so divided. The method may also be extended to other surface integrals besides volume, and so for example may be used to compute the center of mass. One can remove the absolute values and simply add in the polynomial expression if an orientation is chosen consistent with the \"right-hand-rule\" for outward pointing normals. As in the previous post I will concede that there is some redundant calculation here, so that if it is important that the computation be done quickly it pays to watch for repeated line integrals and so on. dave __Derivation of formula for surface integral over one face__ Assuming that the face is not vertical, we can write z = Ax+By+C for some constants A, B and C (easily computed from any three non-collinear vertices on the face). Then that face contributes to the surface integral the sum A integral(x) + B integral(y) + C integral(1) where the integral may be taken over the projection of the face to the xy-plane (translation: ignore the z coordinates on the face). There is an orientation problem: the integral over the projection to the xy-plane will be off by a sign if the polyhedron faces \"in\" rather than \"out\", so you will need to know whether the interior of the polyhedron contains those points whose z coordinates are just larger than Ax+By+C or just smaller. In a previous post, I discussed integrating these very three surface integrals around a polygon. (These were done with Green's theorem.) The upshot is that these integrals may be computed as simple sums around the perimeter of the polygon. The segment from (x0, y0) to (x1, y1) contributes (x0 + x1)/2 . (y1-y0) to the integral of 1 over the polygon, (x0^2 + x0 x1 + x1^2)/6 . (y1-y0) to the integral of x, and ( (y0 x1 + x0 y1) + 2(x1 y1 + x0 y0) )/6 . (y1 - y0) to the integral of y. So, for example, if one face of your polyhedron is a triangle with vertices (x0,y0,z0), (x1,y1,z1), and (x2,y2,z2), then the equation for the plane is z = Ax + By + C where A, B, and C are determined by ( A ) ( x0 y0 1 )^{-1} ( z0 ) ( B ) = ( x1 y1 1 ) ( z1 ) ( C ) ( x2 y2 1 ) ( z2 ) We compute the line integrals around the triangle in the xy-plane: the integral of 1 is I1 = (1/2)( y1.(x0-x2) + y2.(x1-x0) + y0.(x2-x1) ) as in a followup I made to the previous post; the integral of x is this times (x0+x1+x2)/3, and the integral of y is the same factor I1 times (y0+y1+y2)/3. (All these should have their sign adjusted in case the points (x0,y0), (x1,y1), (x2,y2) do not wrap counterclockwise around the triangle. The correction is easy: since integral(1)=Area > 0, the sign correction to multiply by is just the sign S1 of I1. Thus, the surface integral over this face is the linear combination [ A(x0+x1+x2)/3 + B(y0+y1+y2)/3 + C ] . (S1 I1) As it happens, I1 is precisely the determinant of the matrix to be inverted above, so multiplyng thru we see that A B and C may be replaced by the cofactors, making division unnecessary. Apart from the sign correction, the previous surface integral may thus be written (z0.(y1-y2)+z1.(y2-y0)+z2.(y0-y1)) . (x0+x1+x2)/3 + (z0.(x2-x1)+z1.(x0-x2)+z2.(x1-x0)) . (y0+y1+y2)/3 + (z0.(x1y2-x2y1)+z1.(x2y0-x0y2)+z2.(x0y1-x1y0)) This, in turn, simplifies to just (z0+z1+z2)/3 . (I1) (again, times the sign correction so that S1 I1 > 0 ) This is the formula given above."}
{"text": "Retrieved from http://math.stackexchange.com/questions/334375/conditional-probability-uniform-distributions\nText:\nTake the 2-minute tour \u00d7\n\nProblem: Suppose that the random variable X is uniformly distributed symmetrically around zero, but in such a way that the parameter is uniform on (0, 1); that is, suppose that $X\\mid (A=a) \\sim U(-a,a)$ with $A \\sim U(0,1)$. Find the distribution of X.\n\nMy attemt: $f_{A,X}(a,x)=f_{X\\mid A=a}(x) \\cdot f_{A} (a)$.\n\n$f_{A}(a)=1$ for $0<a<1$ and $f_{X,A=a}(x)=\\frac{1}{2a}$ for $-a<x<a$ which means that $f_{A,X}(a,x)=\\frac{1}{2a}$ for $0<a<1$ and $-a<x<a$. Next I integrate the joint distribution over a to find $f_{X}(x)$.\n\n$f_{X}(x)=\\int_0^1 f_{A,X}(a,x) da=\\int_0^1 \\frac{1}{2a}da$, but this integral is not convergent. Where do I go wrong?\n\n\nshare|improve this question\nI think the standard symbol where you use $\\in$ would be $\\sim$. \u2013\u00a0 joriki Mar 19 '13 at 2:04\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou were correct up until setting up the integral for the marginal density: $$ f_X(x) = \\int_0^1 f_{A,X}(a,x) \\mathrm{d}a = \\int_0^1 \\frac{1}{2a} [-a<x<a] \\mathrm{d}x $$ For a given $-1<x<1$, the indicator function $[-a<x<a]$ is non-zero for $|x|<a<1$, therefore $$ f_X(x) = \\int_{|x|}^a \\frac{\\mathrm{d}a}{2a} = \\frac{1}{2} \\ln \\frac{1}{|x|} $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.jiskha.com/questions/360191/n2h4-g-h2-g-2-nh3-g-h1-1876kj-3-h2-g-n2-g-2-nh3-g-h2-922-kj-the\nText:\nEnthalpy of Formation\n\nN2H4(g) + H2(g)--> 2 NH3(g) H1 = \u20131876kJ\n\n3 H2(g) + N2(g)--> 2 NH3(g) H2 = \u2013922 kJ\n\nThe H.f for the formation of hydrazine: 2 H2(g) + N2(g)--> N2H4(g) will be______kj/mol\n\nI am very confused here. I thought I would just add H1 and H2 and divide by the molar mass of N2H4, but that is not correct. Please Help. Thank You!\n\n  1. \ud83d\udc4d\n  2. \ud83d\udc4e\n  3. \ud83d\udc41\n  1. I got the answer to be 95.4 kj/mol\n    I reversed the 1st equation to get an overall 187.6 kj = h1\n    then I just added that to H2 and I got the answer.\n    But I still don't really understand the processes. If someone could explain that to me I would truly appreciate it.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n  2. You have to reverse the direction of one reaction and change the sign of H.\n\n    3 H2+ N2--> 2 NH3 H2 = -922 kJ/mole\n    2NH3 -> N2H4 + H2 H = +1876 kJ/mole\n\n    NOW add, and cancel out terms that appear on both sides.\n\n    N2 + 2H2 -> N2H4 H = -954 kJ\n\n    There is another problem. Your heat of formation of NH3 does not agree with accepted data. It should be -10.97 kJ/per mole of NH3, or twice that much for the reaction as written (which forms two moles). Also, the standard form of N2H4 at room temperature is a liquid, and your reaction involves the gas.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n  3. For what it is worth, the correct heat of formation of N2H4 (liq.) is +12.10 kcal/mole and for N2H4(g) it is +22.79 kcal/mole. Those values are at 298 K. They are a few kcal/mole different at 0 K. Multiply by 4.18 for kJ/mole. That gives +95.3 kJ/mole for the N2H4(g) heat of formation, which agrees well with your second answer. You seem to have misplaced decimal points in your first version of the question.\n\n    Those values come from the JANAF Thermochemcial Tables of the U.S National Bureau of Standards, 2nd edition.\n\n    1. \ud83d\udc4d\n    2. \ud83d\udc4e\n\nRespond to this Question\n\nFirst Name\n\nYour Response\n\nSimilar Questions\n\n  1. Honors Chemistry\n\n\n  2. Chemistry\n\n    Calculate the molarity and the molality of an NH3 solution made up of 30 g of NH3 in 70 g of water. The density of the solution is 0.982 g/ml. Molar Mass of NH3 = 17.04 g\n\n  3. chemistry\n\n    Nitrogen (N2) and hydrogen (H2) react to form ammonia (NH3). Consider a mixture of six nitrogen molecules and six hydrogen molecules in a closed container. Assuming the reaction goes to completion, what will the final product\n\n  4. Chemistry\n\n    If 2.50 g of CuSO4 are dissolved in 9.4 102 mL of 0.34 M NH3, what are the concentrations of Cu(NH3)42+, NH3 and Cu2+ at equilibrium? i tried doing Cu2+ first and i did Kf=5e13= salt/cu2+ nh3+^4 and i did molesCuSO4/.94 L = .01666\n\n  1. chemistry\n\n    How many moles are in 1.50 x 1023 molecules NH3? A. 2.49 x 10 -1 mol NH3 B. 2.49 x 101 mol NH3 C. 2.65 x 10 -1 mol NH3 D. 2.78 x 10 1 mol NH3 maybe B\n\n  2. Chem help\n\n    Which reaction of ammonia does not involve the non-bonding pair of electrons on the nitrogen atom? A NH3(g) + CH3I(g) \u2192 CH3NH 3+ I \u2013(s) B NH3(g) + HCl (g) \u2192 NH4Cl (s) C 2NH3(l) + 2Na(s) \u2192 2NaNH2(s) + H2(g) D 2NH3(aq) +\n\n  3. Chemistry\n\n    Consider this equilibrium N2(g) + H2(g) NH3(g) +94 kJ The equilibrium law exoression for the balanced chemical equationwould be A. [N2][H2]/[NH3] B. [NH3]/[H2][N2] C. [NH3]2/[H2][N2] D. [NH3]2/[H2]3[N2] E. 2[NH3]2/3[H2]3[N2]\n\n  4. science\n\n    Calculate the solubility of silver chloride in 10.0 M ammonia given the following information: Ksp (AgCl) = 1.6 x 10^\u201310 Ag+ + NH3--->AgNH3+ K=2.1x10^3 AgNH3+ + NH3-----> Ag(NH3)2+ K=8.2x10^3 Answer : 0.48 M Calculate the\n\n  1. Chemistry\n\n\n  2. AP Chem\n\n    At a certain temperature, 4.0 mol NH3 is introduced into a 2.0 L container, and the NH3 partially dissociates by the reaction. 2 NH3(g) N2(g) + 3 H2(g) At equilibrium, 2.0 mol NH3 remains. What is the value of K for this reaction?\n\n  3. chemistry\n\n    from the balanced equation 4NH3 +7O2 - 4NO2 + 6H2O How many molecules of water are produced when 2.25 moles of ammonia are completely reacted? The equation tells us that 4 mol NH3 will produce 6 mols water. That means 2 mols NH3\n\n  4. Chemistry\n\n    Calculate the molar concentration of uncomplexed Zn2+ (aq) in a solution that contains 0.22 mol of Zn(NH3)4 2+ per liter and 0.3109 M NH3 at equilibrium. Kf for Zn(NH3)4 2+ is 2.9 X 10^9 I started this way... (0.3109 +\n\nYou can view more similar questions or ask a new question."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/51738/algorithm-to-find-the-shortest-walk-with-k-leaf-nodes-on-a-tree\nText:\nLet's say I have a general tree. What algorithm can I use to find a shortest walk that starts at the root, passes through exactly $k$ different leaves, and ends at the root? Passing through a node/edge more than once is allowed.\n\nFor example, consider this graph:\n\n\nFor $k = 1$, the shortest walk would have the node 4. For $k = 2$, the leaf nodes would be 4 and 12. For $k = 3$, the leaves would be 4, 16 and 17.\n\nWhat I actually need is the length of the shortest walk (if this simplifies anything).\n\nI could not find an algorithm for this, but maybe I searched with the wrong terms.\n\n  \u2022 $\\begingroup$ What have you tried? Where did you get stuck? We do not want to just do your exercise for you; we want you to gain understanding. However, as it is we do not know what your underlying problem is, so we can not begin to help. See here for a relevant discussion. $\\endgroup$ \u2013\u00a0D.W. Jan 12 '16 at 0:21\n\nThis can be solved by a fairly standard dynamic programming algorithm. For a given node $v$, let $C(v,k)$ be the minimum length of a (closed) walk through the subtree rooted at $v$ passing through exactly $k$ leaf nodes ($C(v,k)=\\infty$ if there is no such walk).\n\nIf a node $v$ has children $c_1,\\ldots c_m$, then $C(v,k) = min_{k=a_1 + \\ldots + a_m} \\Sigma_{\\{i:a_i\\not = 0\\}} 2 + C(c_i, a_i)$ (i.e. taking the minimum over all ways to split up $k$ over the children of the node).\n\nWith some modification, this can be made to run in $O(n^3)$.\n\n  \u2022 $\\begingroup$ $O(n^2)$? Interesting. $\\endgroup$ \u2013\u00a0Hendrik Jan Jan 12 '16 at 17:40\n  \u2022 $\\begingroup$ Whoops, now that I think about it I can only do $O(n^3)$, but you definitely don't need to iterate over the exponentially many ways to split up $k$. $\\endgroup$ \u2013\u00a0Tom van der Zanden Jan 12 '16 at 17:47\n  \u2022 $\\begingroup$ How to achieve $O(n^3)$? $\\endgroup$ \u2013\u00a0hengxin May 26 '16 at 12:39\n\nYour Answer"}
{"text": "Retrieved from https://in.mathworks.com/matlabcentral/answers/636780-how-can-i-obtain-the-mean-and-standard-deviation-of-a-gaussian-pdf\nText:\nMATLAB Answers\n\nHow can I obtain the mean and standard deviation of a gaussian PDF\n\n3 views (last 30 days)\nThis might be a trivial question but i calculated 3 gaussian pdf's on the domain\nx = [0 : 0.1 : 200],\nand computed the pdf's as:\ny1 = normpdf(x,mu1,sigma1)\ny2 = normpdf(x,mu2,sigma2)\ny3 = normpdf(x,mu3,sigma3)\nI averaged them together such that:\ny_final = (y1+y2+y3)./3\nMy question is how can I obtain the the mean and standard deviation of the y_final?\n\n\nSign in to comment.\n\nAccepted Answer\n\nDavid Goodmanson\nDavid Goodmanson on 5 Nov 2020\nHi Matthew,\nhere is an example, where mu and sigma are calculated by numerical integration. Also shown are analytical results for those, which agree with the numerical results. For the mean of y = (y1 +y2 +y3)/3,\nmu = (mu1 + mu2 + mu3)/3\nwhich is not a big surprise. The variance of y is\nvar = Integral (x-mu)^2*(y1 +y2 +y3)/3 dx\nIf y1 has mean mu1 and standard deviation sigma1 then the integral involving y1 above is\nsigma1^2 + (mu-mu1)^2\nand similarly for y2 and y3. The analytic expression for the variance and standard deviation is shown below.\nNote that none of these results has anything to do with whether or not the pdfs are normal distributions. The pdfs could be anything, not even of the same type (as long as each is normalized to 1), and the result is the same.\nxplot = -20:.001:38; % use plenty of points\ngrid on\nN = integral(@(x) y(x), -inf,inf) % should be 1\nmu = integral(@(x) x.*y(x), -inf,inf) % mean\nvar = integral(@(x) (x-mu).^2.*y(x),-inf,inf) % variance\nsig = sqrt(var) % standard deviation\n% analytical calculations of mu, variance, std deviation\nmus = [16 3 9];\nsigs = [ 2 1 3];\nmuA = (1/3)*sum(mus)\nvarA = (1/3)*(sigs(1)^2 + (mu-mus(1))^2 ...\n+ sigs(2)^2 + (mu-mus(2))^2 ...\n+ sigs(3)^2 + (mu-mus(3))^2)\nsigA = sqrt(varA)\nfunction a = y(x)\n% sum of three pdfs\nmus = [16 3 9];\nsigs = [ 2 1 3];\ny1 = normpdf(x,mus(1),sigs(1));\ny2 = normpdf(x,mus(2),sigs(2));\ny3 = normpdf(x,mus(3),sigs(3));\na = (1/3)*(y1+y2+y3);\n\n\nSign in to comment.\n\nMore Answers (0)\n\n\n\n\n\nCommunity Treasure Hunt\n\n\nStart Hunting!"}
{"text": "Retrieved from https://mathematica.stackexchange.com/questions/176554/evaluate-arguments-in-a-curried-function-left-to-right\nText:\nI have an inner pattern\n\nf[g, n_] := inner\n\nand I want to define an outer curried pattern\n\nf[h, m_][f[g, n_]] := ...\n\nwhich has unrelated behaviour to f[g,n] and so should receive expression f[g,n] rather than inner. Alas, f[h,m][f[g,n]] is undesiredly first evaluated as f[h,m][inner]. How can I prevent Mathematica from evaluating the inner f[g,n] whilst still recognising a pattern for f[h,m_][..] without having to explicitly insert Hold into the outermost expression?\n\nOf course SetAttribute[f, HoldAll] doesn't work, and I can't exactly set an attribute for the experssion f[h].\n\nMy motivation: I'm creating inner \"functions\" with subscript \"arguments\", and I want to define an outer \"functional\" which also has subscript \"arguments\" which should start evaluating before the passed inner functions are evaluated.\n\n\nSubscript[g1, n_] := bad[n]\nSubscript[g2, n_] := bad[n] \n\nSubscript[h, m_][ Subscript[g_,n_] ] := good[g,m,n]\n\nI want the behaviourwhere $g1_n$ gives bad[n], but $h_m[g1_n]$ gives good[g1,m,n]. The above code instead gives $h_m[bad[n]]$.\n\nI notice that the last line of the above code doesn't affect the DownValues of Subscript:\n\n\n    {HoldPattern[Subscript[g1, n_]] :> bad[n], \n    HoldPattern[Subscript[g2, n_]] :> bad[n]}\n\nIs this at all possible?\n\n  \u2022 $\\begingroup$ @kglr Actually the \"inner\" arguments aren't declared verbatim (see my motivation) $\\endgroup$ \u2013\u00a0Anti Earth Jul 3 '18 at 14:24\n  \u2022 $\\begingroup$ @kglr Pardon the over-simplicity in the original statement of my problem - please see 'my motivation' $\\endgroup$ \u2013\u00a0Anti Earth Jul 3 '18 at 14:35\n  \u2022 $\\begingroup$ Some of us here think that using Subscript while defining symbols (variables) should be avoided. Subscript[x, 1] is not a symbol, but a composite expression where Subscript is an operator without built-in meaning. You expect to do $x_1=2$ but you are actually doing Set[Subscript[x, 1], 2] which is to assign a DownValues to the operator Subscript and not an OwnValues to an indexed x as you may intend. Read how to properly define indexed variables here $\\endgroup$ \u2013\u00a0rhermans Jul 4 '18 at 8:18\n  \u2022 $\\begingroup$ I agree, but I'm still looking to do it :) I can use /: to attach an OwnValues to x if that was really a problem $\\endgroup$ \u2013\u00a0Anti Earth Jul 4 '18 at 13:19\n\nWhen I run into problems like this, I workaround it by using ReplaceAll like so:\n\nrules = {\n  f[g, n_] :> inner,\n  f[h, m_][f[g, n_]] :> outer\n\nf[h, m][f[g, n]] //. rules\n\n(* outer *)\n\nThat's because while the standard evaluation procedure looks at elements before moving up, ReplaceAll works by first trying to match the whole expression before going deeper.\n\n| improve this answer | |\n  \u2022 $\\begingroup$ Works fantastic. I'll hopelessly wait a little longer for I accept this answer :) $\\endgroup$ \u2013\u00a0Anti Earth Jul 4 '18 at 16:30\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1486538/proving-an-asymptotic-relation/1486566\nText:\nI want to show that $$ \\sum_{k=1}^{n} k^{\\alpha} \\sim \\frac{n^{\\alpha+1}}{\\alpha+1} \\ \\ \\ \\ \\ \\ n\\to \\infty$$\n\nfor $\\alpha > -1$ . So I need to show that the following limit exists and is equal to $1$ : $$ \\displaystyle \\lim_{n \\to \\infty} \\frac{\\sum_{k=1}^{n} k^{\\alpha}}{\\frac{n^{\\alpha+1}}{\\alpha+1}} $$\n\nBecause $\\alpha > -1$, it is clear that the above limit is of the type $\\frac{\\infty}{\\infty}$. Here I have doubts about using the L'Hospital's rule, because that means differentiating with respect to the upper bound of the sum which is a discrete variable, then how shoud I proceed with the computation of this limit?\n\n\n  \u2022 $\\begingroup$ use euler mac-laurin summation formula $\\endgroup$ \u2013\u00a0tired Oct 18 '15 at 21:50\n  \u2022 1\n    $\\begingroup$ Or simply look at $$\\frac{1}{n^{\\alpha+1}}\\sum_{k = 1}^n k^\\alpha$$ and think Riemann sum. $\\endgroup$ \u2013\u00a0Daniel Fischer Oct 18 '15 at 21:54\n\nUse the inequality\n\n\nwhich holds because the middle term is an upper sum for the left integral and a lower sum for the right integral. Equality holds if and only if $\\alpha=0$. Now compute both integrals, divide throughout by ${n^{\\alpha+1}}$ and let $n\\to\\infty$.\n\nAs pointed out by the8thone, the above holds for $\\alpha\\geq 0$, and for $-1<\\alpha<0$ both inequalities are reversed, but the limits are still the same.\n\n  \u2022 $\\begingroup$ Thank you, however , the inequality you wrote is true for $\\alpha \\geq 0$, for $\\alpha < 0$ we have the reverse inequalty, which finally gives the desired answer. $\\endgroup$ \u2013\u00a0the8thone Oct 18 '15 at 22:16\n  \u2022 $\\begingroup$ You are absolutely correct. I'll fix it. $\\endgroup$ \u2013\u00a0uniquesolution Oct 18 '15 at 22:16\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1664140/4-married-couples-and-2-single-men-will-sit-at-a-circular-table\nText:\n$4$ married couples and $2$ single men sit at a circular table. In how many ways can they sit so that a man can't sit next to a woman who is not his wife?\n\nI have tried but I am not sure to the following answer :\n\nFirst, the husbands sit in the circular table of which the possible ways is $3!$.\n\nThe wives should sit next to her husband which is only $1$ way.\n\nThe two men can only be put between two husbands in only $2$ ways and they then can be permuted in $2$ ways. So the number of ways is $4$.\n\nBy applying the multiplication principle, the total number of ways for this possibility is $3! \\times 4$ = $24$.\n\nThe second possibility is similar which is making the wives sit first and put each husband next to his own wife and then put the single men. The total number of ways is also $24$.\n\nSo the answer is $24 + 24 = 48$.\n\n\nAs each woman has two neighbors, one way to have a woman not sit next to a man who is not her husband is to line up husband$_1$ wife$_1$ wife$_2$ husband$_2$ twice. Then we have three ways to pair up the couples and two ways to flip each pair left/right. We might as well put the leftmost of the pair including husband A at seat $1$ to break the rotational symmetry. Then there are three groups of seats for the other married couple and a factor two for placing the single men. Total is $$3 \\cdot 2^2 \\cdot 3 \\cdot 2=72$$\nThe other way to deal with the women is to place all four together in some order, $4!$ ways and seat the husbands of the end ones next to them. Again break the symmetry by seating the leftmost woman in seat $1$. Now you can arrange the other four men any way you want, another $4!$ ways, giving $$4!^2=576$$ The total is then $$72+576=648$$\n\n  \u2022 $\\begingroup$ Do you think OP wants to consider rotational overcounts? $\\endgroup$ \u2013\u00a0K. Jiang Feb 20 '16 at 13:42\n  \u2022 $\\begingroup$ +1 for rechecking an earlier answer that had been wrong. $\\endgroup$ \u2013\u00a0Oscar Lanzi Feb 21 '16 at 3:38\n\nI get 648.\n\nThe women must sit in two pairs of adjacent seats, and if the pairs are separated there must be at least two intervening positions (for different husbands) in each direction.\n\nThis leads to three distinct arrangements for the women: 1-2-3-4, 1-2-5-6, 1-2-6-7. In the first case two men must sit next to their respecive wives in positions 5 and 10, while the other four men sit in any fashion that choose in positions 6-7-8-9. Thus 24\u00d724 = 576 permutations. For the second arrangement of the women, all four husbands must sit next to their wives leaving only the two single men with any free choice. Thus 24\u00d72 = 48 permutations.\n\nThe third female arrangement is tricky, in fact I had to edit my answer because I got it wrong the first time. If we count 24 permjtations for the women and two for the single men we seem to get 48. But because the women (and their husbands) are in a twofold rotationally symmetric arrangemet only half of these 48 are actually distinct. So we can really count only 24 additional permutations to go with the 576+48 from the other cases. Total: 648.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/307752/2d-elastic-collision-in-the-center-of-mass-frame-of-reference/307799\nText:\nIn a collision between two spheres $A$ and $B$, their velocities are symmetric ($v$ and $-v$, respectively) in the center-of-mass frame of reference. The final speed of $A$ does a $45\u00b0$ angle with its initial velocity.\n\nDetermine the final speed of the spheres if the collision is elastic, in the frame of reference where the sphere B is initially at rest.\n\nHow do I solve this? I am not used to solve these problems with the center-of-mass frame of reference.\n\n\nThe centre of mass frame information is there to give you some information about the relative masses of the two spheres and the initial speed of sphere $A$ in terms of speed $v$.\nThe rest of the problem can then be done in the reference frame of sphere $B$ which you would have done many times before.\n\nIf you decide correctly about the relative masses the problem can be solved fairly easily by writing the conservation of kinetic energy equation from which the shape of the momentum vector addition triangle can be inferred.\n\n\nFinish the calculation in the CoM frame of reference. That is the frame in which the problem is set.\n\nThen transform from the CoM frame to the frame of reference in which B is initially at rest by adding the reverse of the initial velocity vector of B (ie $-\\vec{u_B}=+\\vec{v}$) to each of the final velocities in the CoM frame.\n\nThe wording of the question does not make clear whether the collision is elastic in the CoM frame or in the frame in which B is initially at rest. Does this matter? No. The amount of KE each sphere has depends on which frame you are measuring it in, but the fact that total (kinetic) energy is conserved in the collision does not depend on which frame of reference you are using. If the collision is elastic in the CoM frame, it is elastic in the rest frame of B also.\n\n  \u2022 $\\begingroup$ Why do we transform in the COM frame tho.....is it because of it being momentum conserved frame and elastic collision is known to have its momentum conserved so why do we have to change back then $\\endgroup$ \u2013\u00a0user195235 Aug 15 '18 at 11:25\n  \u2022 $\\begingroup$ @user195235 The COM frame is specified in the question, so we have to use it to solve the problem. And we have to change to another frame because that is what the question asks for. However, generally there is no requirement to use one frame or another if the question does not require it. You can use whatever frame you find convenient. The COM frame sometimes makes the problem easier. In other cases the solution might be obvious or more intuitive in a non-inertial frame of reference. $\\endgroup$ \u2013\u00a0sammy gerbil Aug 19 '18 at 17:35"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/69910/how-to-solve-this-partial-order-reduction-in-on2/69934\nText:\nThere are two orderings of numbers from the same set. Number $a$ is \"immediately before\" $b$ iff $a$ appears before $b$ in both sequences and there is no other number that appears between them in both sequences.\n\nSo in this example:\n\nSeq 1: 1 2 3 4 5 6\nSeq 2: 6 2 1 3 5 4\n  \u2022 1 is not immediately before 2 because they appear in opposite orders.\n  \u2022 1 is not immediately before 4 because 3 appears between them in both sequences.\n  \u2022 2 is immediately before 3 and 3 is immediately before 4.\n\nThe problem is to find all pairs $a$, $b$ such that $a$ is immediately before $b$ in $O(n^2)$ time. How can this be done?\n\nI understand that the naive solution can work in $O(n^3)$: For each pair in the first sequence ($n^2$ pairs) verify it using the second sequence ($O(n)$ time).\n\n\nYour solution looks good to me, except that your lookup arrays are a bit handwavy: What happens if the set contains negative numbers? Or what if it contains an extremely large number ($\\gg n^2$), so that the arrays would need to be massive?\n\nTo address this, I'd suggest creating just a single lookup table, that instead of mapping from values to indices, maps from indices in one sequence to indices in the other. Thus seq2[i] = seq1[translator[i]]. You can build that table in $\\mathcal{O}\\left(n^2\\right)$ time using nested loops. You can then ignore seq1 and seq2 in all of your logic: the problem becomes, \"find all pairs of indices (i, j) such that i < j, that translator[i] < translator[j], and that i < k < j precludes translator[i] < translator[k] < translator[j]\" (which you can solve using basically the same approach as what you've written). The only time you'd refer to seq1 or seq2 again is when you're adding an entry to the result (since for that you want the actual values rather than the indices).\n\n\nI think I am able to solve it.\n\nFirst, have a lookup array for each sequence where array[element] = element's position in sequence [O(1)].\n\nPhrased another way, this algorithm will find all \"successors\" for each of the elements in the first sequence. Finding successors for each element will take O(n) time.\n\nFor i in range(0,n):\n    initialize most_recent_successor to None\n    For j in range(i+1, n):\n        if pos. of seq_1[j] > pos. of most_recent_successor in both sequences:\n            advance j\n            most_recent_successor = seq_1[j]\n            add (seq_1[i], seq_1[j]) to result\n\nEssentially, if a valid pair (seq_1[i], seq_1[j]) exists, then any pair (seq_1[i], seq_1[k]) will not be valid if the position of seq_1[k] in comes after the position of seq_1[j] in both sequences.\n\nSo, for the example in the question, (1, 3) is a valid pair. Therefore, (1,4) and (1, 5) are not valid pairs since 4 and 5 come after 3 in both sequences.\n\nEdit: Please look at ruakh's insightful answer on lookup arrays I used here.\n\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/double-integral.349791/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nDouble Integral\n\n  1. Oct 28, 2009 #1\n    I need to find the area of the hyperbolic paraboloid z=xy contained within the cylinder x^2+y^2=1. I know I need to take a double integral but am having real difficulty finding the correct limits, so far I've got that;\n\n    [tex]\\int dx[/tex][tex]\\int dy[/tex]\n\n    With the x limits being 1 and -1 and the upper y limit to be sqrt(1-x^2) I'm having trouble finding the lower y limit. Although to be honest I'm not completely sure about the other three limits! Sorry about my awful attempt at Latex-ing I don't know how to do it so couldn't write the limits of the integrals on the integral. Any help would be great! Thanks.\n  2. jcsd\n  3. Oct 29, 2009 #2\n    the problem is symmetric by pi/2 so I'd just stick to the (+,+) quadrant and your lower limit is y=0. Then your x limits would be 1 and 0.\n\n    The area in the entire domain is then four times the area in a single quadrant.\n  4. Oct 29, 2009 #3\n\n\n    User Avatar\n    Science Advisor\n\n    I have no idea what you mean by\n    Shouldn't there be some function to be integrated in that? And it probably is NOT\n    [tex]\\int dx\\int dy[/tex]\n    but rather\n    [tex]\\int f(x,y) dxdy[/tex]\n    Even ignoring the \"f(x,y)\" the two separate integrals implies that the two coordinates can be separated- which is not the case here- at least not in Cartesian coordinates.\n\n    The surface area of z= f(x,y) is given by\n    [tex]\\int\\int \\sqrt{1+ \\left(\\frac{\\partial f}{\\partial x}\\right)^2+ \\left(\\frac{\\partial f}{\\partial y}\\right)^2} dA[/tex]\n    where dA is the differential of area in whatever coordinate system you are using, in the xy-plane. Because of the circular symmetry I would recommend changing to polar coordinates- where the two coordinate variables can be separated."}
{"text": "Retrieved from https://www.physicsforums.com/threads/orbital-mechanics.839274/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nOrbital mechanics\n\n  1. Oct 23, 2015 #1\n    I'm having trouble with orbItal mechanics, I'm trying to determine the total potential energy of an orbiting satellite, what I've done so far is this:\n    I know m*g*h is potential energy, but I also know that gravity deceases with distance avoiding to the inverse square law. I know I Just can't use the satellites current Ag because that will increase as it falls towards the earth, and I'm having trouble determining exactly what that is.\n    This is giving me serious trouble because I want to calculate periapsis or apoapsis given just one of those two, and the velocity at that point.\n  2. jcsd\n  3. Oct 23, 2015 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    The gravitational potential energy of an orbiting body is different from mgh, which applies only to something located close to the surface of a planet, like earth.\n\n\n    U = -GMm / r\n\n\n    M - Mass of the planet, kg\n    m - mass of the orbiting body, kg\n    G - Universal Gravitational Constant = 6.67408 \u00d7 10-11 m3/kg-s2\n    r - distance between the centers of mass of M and m, in meters\n    U - gravitational potential energy (= 0 when r \u2192 \u221e)\n  4. Oct 23, 2015 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    I'd make one adjustment to SteamKing's equation. Use specific energy per unit of mass.\n\n    F= -GMm/r^2\n    therefore, a=GM/r^2\n\n    All objects accelerate at the same rate (due to gravity).\n\n    Since it's the motion you're interested in, you can do the same with the energy (divide out the mass). And, if you do need to know the energy (to determine how much fuel to do a delta V, for example), you just multiply the specific energy (or the change in specific energy) by the mass when you need that info.\n\n    Likewise, your specific kinetic energy would be (v^2)/2. And your total specific energy would be (GM)/(-2a), where a is the semi-major axis of your orbit.\n\n    Given that you mentioned Earth, I assume you're talking about a satellite orbiting Earth? The universal gravitational constant and the mass of the Earth are constant. Once you've multiplied them together once, you can just remember the answer. You can even look up the answer in a book. It's your geocentric gravitational constant (3.986 x 10^5 km^3/sec^2).\n  5. Oct 28, 2015 #4\n    Is it really that simple? It makes sense but It seems too simple. I came up with that about two weeks ago but I didn't believe myself when I did it. I guess I'll just have to launch a scientific mission in KSP to verify it.\n  6. Oct 28, 2015 #5\n    Wait, that doesn't make sense, by getting higher your potential energy decreases? And in a higher orbit you move slower so your kinetic energy decreases too, that can't be right.\n    I'm looking for \u03a3 specific potential energy, our the whole of all the specific kinetic energy that would be gained from a fall of such altitude.\n  7. Oct 28, 2015 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    First, you were looking for orbital elements; now, you're looking for the K.E. a satellite gains by falling out of orbit.\n\n    This article discusses orbital mechanics in some detail:\n\n\n    This article talks about the relationship between gravitational P.E. into K.E. for an orbiting body:\n\n  8. Oct 28, 2015 #7\n    No. Notice the minus sign in front of the expression fro PE.\n    The PE increase as you go higher, the maximum value being zero. This is so because the reference is chosen to be at infinite distance.\n  9. Oct 28, 2015 #8\n    I don't see how my request has changed. if an object has 25,000,000 Joules of kinetic energy when it impacts, then it must have had 25,000,000 Joules of potential energy when it began to fall. I am just looking for the potential energy of an object in freefall beginning at a distance where the gravitational inverse-square law becomes relevant, as I always have been. maybe I was sloppy with my wording before, but I truly do not see a difference between what I was originally asking for and the description you gave here.\n  10. Oct 28, 2015 #9\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n\n    The gravitational inverse square law is always relevant, regardless of distance. After all, this law still works between Pluto and the Sun, even though these two bodies are separated by a distance of some 4.5 billion kilometers.\n\n    If you want to calculate the periapsis or apoapsis of an orbiting body, then application of Newton's laws of motion can tell you this.\n\n    If you want to calculate the impact energy of a body falling out of orbit, a different application of the same laws is required.\n\n    Depending on the problem you want to solve, you have to tailor the analysis to obtain the solution. It is not immediately obvious how knowing the periapsis of an orbiting body will necessarily convert into the K.E. of that body hitting the ground.\n  11. Oct 28, 2015 #10\n\n\n    User Avatar\n    Science Advisor\n\n    No, it must have had 25,000,000 more Joules of potential energy when it began to fall than when it impacts. Zero is 25,000,000 more than -25,000,000.\n  12. Oct 28, 2015 #11\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    The total orbital energy of your satellite is the sum of it's kinetic and potential energies.\n    KE = mv2/2\n    GPE = - GMm/r\n    (note since r is measured from the center of M, working out the potential energy difference between the satellite in orbit vs on the ground means solving the following\n    [tex]\\Delta GPE = \\frac{GMm}{r_E}- \\frac{GMm}{r_o}[/tex]\n\n    Where rE and ro are the Earth's radius and orbit radial distance\n\n    Now, to get to your orbital question:\n\n    We start with:\n\n    (1)[tex]E= \\frac{mv^2}{2}- \\frac{GMm}{r}[/tex]\n\n    If we assume a circular orbit, we know that [itex]v= sqrt{\\frac{GM}{r}}[/itex]\n\n    subbing for v, and reducing the equation gives\n\n    (2)[tex]E=- \\frac{GMm}{2r}[/tex]\n\n    It also turns out that this equation holds for elliptical orbits if we use a, the semi-major axis for r:\n\n    (3)[tex]E=- \\frac{GMm}{2a}[/tex]\n\n    If we equate equation 1 and 3 and solve for a, we get\n\n    [tex]a =\\frac{1}{\\frac{2}{r}-\\frac{v^2}{GM}}[/tex]\n\n    which gives us the semi-major axis if we know the velocity at r\n    (This last equation is a re-arrangement of the vis viva equation)\n\n    Now its just a simple case of knowing that\n\n    [tex]a= \\frac{r_{per}+r_{app}}{2}[/tex]\n\n    to find either apogee or perigee if you know the other and the velocity at it."}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-harmonic-motion-inside-earth.164142/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Harmonic Motion Inside earth\n\n  1. Apr 4, 2007 #1\n    A particle is dropped into a hole drilled straight through the center of the Earth. Neglecting rotational effects, show that the particle's motion is simple harmonic if you assume Earth has uniform density. Show that the period of the oscillation is about 84 min.\n\n    2. Relevant equations\n    [tex]F = -G m \\int_V \\frac{\\rho(r') e_r}{r^2}dv'[/tex]\n\n    3. The attempt at a solution\n\n    I was going to use Newton's second law to show that\n    [tex] m \\frac{d^2 r}{dt^2} = -G m \\int_V \\frac{\\rho(r') e_r}{r^2}dv'[/tex]\n\n    Where the volume integral should produce some function of r. So, I started off the integration by choosing an arbitrary point in the sphere a distance r' away, and using R as the distance from the origin to the point mass, r as the distance between the arbitrary distance and the distance of the point mass, theta as the asimuthal angle, and phi as the rotational angle I got.\n\n    [tex]m \\frac{d^2 r}{dt^2} = -G m \\int_0^{R} \\int_0^\\pi \\int_0^{2\\pi} \\frac{\\rho r'^2 sin\\theta}{r^2}dr' d\\theta d\\phi[/tex]\n\n    integrating with respect to phi brings in a factor of 2\u03c0, and now I used law of cosines\n\n    [tex]r^2 = r'^2 + R^2 - 2r'Rcos\\theta[/tex]\n\n    [tex] 2r dr = 2r'Rsin\\theta d\\theta[/tex]\n\n    [tex]\\frac{sin\\theta}{r}d\\theta = \\frac{dr}{r'R}[/tex]\n\n    so the substitute the law of cosines stuff into the force equation\n\n    [tex]F = \\frac{-2 \\pi G m \\rho}{R} \\int_0^R r'^2 dr \\int_{r'-R}^{r'+R} \\frac{1}{r}dr[/tex]\n\n    doing the r' integral I can see that this ultimately won't give a linear function of R\n\n    [tex]\\frac{2 \\pi}{3} \\frac{G m \\rho}{R} R^3 \\int_{r'-R}^{r'+R} \\frac{1}{r}dr [/tex]\n\n    Can someone help me out, point out what I did wrong, put me on the right track?\n\n    I think that once I find the right equation for force, which I actually know from experience should be [tex]F(r) = -\\frac{4 \\pi}{3}G m r \\rho[/tex], that I can do the differential equation stuff.\n  2. jcsd\n  3. Apr 5, 2007 #2\n    You're making it too complicated. Assume that the density of the earth is a constant function, and realize that because of the character of the 1/r^2 force law, you can turn this into a surface integral. Once you do that, you're golden.\n  4. Apr 5, 2007 #3\n\n\n    User Avatar\n    Gold Member\n\n    At any point in the fall, the only mass exerting a nett force on the test body is that contained inside the current radius because the shell of matter outside the radius has no effect. So the force at point x is\n\n    [tex]F(x) = -\\frac{4}{3}\\pi Gm\\rho x^3/x^2[/tex]\n\n    which gives\n\n    [tex]F(x) = -Kx[/tex]\n\n    QED I think. Assuming uniform density.\n    Last edited: Apr 5, 2007"}
{"text": "Retrieved from https://www.physicsforums.com/threads/coupled-oscillator.330209/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCoupled Oscillator\n\n  1. Aug 11, 2009 #1\n\n\n    User Avatar\n\n\n    One mass [itex]m[/itex] constrained to the x-axis, another mass [itex]m[/itex] constrained to the y-axis. Each mass has a spring connecting it to the origin with elastic constant [itex]k[/itex] and they are connected together by elastic constant [itex]c[/itex]. I.e. we have a right-angle triangle made from the springs with lengths [itex]b[/itex], [itex]b[/itex], and [itex]\\sqrt{2} b[/itex].\n\n    Write the Lagrangian, find the normal mode frequencies.\n\n    3. The attempt at a solution\n\n    Again having trouble with the coupling. For the two springs connected to the origin the potentials are straightforward:\n\n    [tex]V = \\frac{1}{2} k x^2 + \\frac{1}{2} k y^2[/tex]\n\n    Given the geometry wouldn't the coupling spring add the potential,\n\n    [tex]V = \\frac{1}{2} c \\left [ \\sqrt{x^2 + y^2} - \\sqrt{2} b \\right ]^2 = \\frac{1}{2} c \\left [ x^2 + y^2 - 2 \\sqrt{2 x^2 + 2 y^2} + 2 b^2 \\right ][/tex]\n\n    But I don't know how to put this in matrix form...\n    Last edited: Aug 11, 2009\n  2. jcsd\n  3. Aug 11, 2009 #2\n    I reworked the problem and got the same potential as you, so it looks like you do indeed have the spring interaction potential correct. It looks a bit pesky because of the presence of the square root. This would make a closed form solution a bit difficult.\n\n    I did think of a potential trick you could use (I don't remember if I read this in a textbook or came up with it myself...hopefully the former). You could try converting to polar coordinates with,\n\n    [tex]x = r cos(\\theta)[/tex]\n    [tex]y = r sin(\\theta)[/tex]\n\n    Be careful here, because in this context [tex]r[/tex] and [tex]\\theta[/tex] don't have any physical meaning; it's merely a math trick. You can then rewrite the Lagrangian with these new generalized coordinates. If my algebra/calculus are right, you should get the following set of differential equations:\n\n    [tex]m\\ddot{r} = -(k + c)r + cb[/tex]\n    [tex]\\ddot{\\theta} = 0[/tex]\n\n    This seems comparatively a lot easier than what you would likely get by writing the Lagrangian using the generalized coordinates that you were working with. And the first differential equation looks like it will give you the oscillatory motion (without damping) that you would expect. After you solve for the two coordinates, you can transform back into the coordinates given in the problem.\n\n    Disclaimer: I don't know if this method will work, and indeed I see one potential pitfall. When you transform into polar coordinates, you get the weird effect of [tex]\\theta = \\theta + 2\\pi[/tex]. I normally leave it to the mathematicians to prove that physics math tricks actually work, but in this case I could see this as possibly being the cause of an incorrect solution. But hey, try it out and see what happens\n  4. Aug 11, 2009 #3\n\n\n    User Avatar\n\n    Thanks for your insight. I may have misled you into thinking I needed to the differential equations because I asked for the Lagrangian. I'm trying to get the normal mode frequencies by solving the eigenvalue problem.\n\n    I was thinking your trick might help still but it seems [itex]\\theta[/itex] drops out of the expression for V.\n\n    [tex]T = \\frac{1}{2} m \\dot{r}^2[/tex]\n\n    [tex]V = \\frac{1}{2} c (r^2 - 2 \\sqrt{2} r)[/tex]\n\n    (constant term dropped in V)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/spring-with-mass.127950/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSpring with Mass\n\n  1. Aug 3, 2006 #1\n    Suppose a spring with mass m and length L is connected to a rigid wall and a mass of M. Assuming no damping how do we find the frequency?\n\n    for the spring Density = m/L = D; dm = D dx\n    I don't know where to go from there.\n  2. jcsd\n  3. Aug 3, 2006 #2\n    The effective mass of a spring undergoing oscillatory motion is considered\n    to be 1/3 the mass of the spring. For any portion of the spring the\n    KE of dm is 1/2 dm * v^2. For a spring fixed at one end the velocity of an\n    element dm will be proportional to the distance from the fixed end - so\n    v = V*(y/Y) where Y is the length of the spring and V is the velocity of the moving end. Also, you can write dm = M * (dy/Y). Using these values\n    integrate 1/2 v^2 dm over the length of the spring to get the KE of the\n    oscillating spring and determine the effective mass of the spring.\n  4. Aug 5, 2006 #3\n    Thanks, I understand now."}
{"text": "Retrieved from https://fds.duke.edu/db/aas/math/pierce/publications/320386\nText:\nDepartment of Mathematics\n\u00a0Search | Help | Login | pdf version | printable version\n\nMath @ Duke\n\n\n\nPublications [#320386] of Lillian B. Pierce\n\nPapers Published\n\n  1. Pierce, LB; Schindler, D; Wood, MM, Representations of integers by systems of three quadratic forms, Proceedings of the London Mathematical Society, vol. 3 no. 113 (2016), pp. 289-344, London Mathematical Society [doi]\n    (last updated on 2018/03/21)\n\n    It is classically known that the circle method produces an asymptotic for the number of representations of a tuple of integers $(n_1,\\ldots,n_R)$ by a system of quadratic forms $Q_1,\\ldots, Q_R$ in $k$ variables, as long as $k$ is sufficiently large; reducing the required number of variables remains a significant open problem. In this work, we consider the case of 3 forms and improve on the classical result by reducing the number of required variables to $k \\geq 10$ for \"almost all\" tuples, under appropriate nonsingularity assumptions on the forms $Q_1,Q_2,Q_3$. To accomplish this, we develop a three-dimensional analogue of Kloosterman's circle method, in particular capitalizing on geometric properties of appropriate systems of three quadratic forms.\nph: 919.660.2800\nfax: 919.660.2821\n\nMathematics Department\nDuke University, Box 90320\nDurham, NC 27708-0320"}
{"text": "Retrieved from https://www.physicsforums.com/threads/probability-choice-of-boxes.303637/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nProbability: choice of boxes\n\n  1. Mar 30, 2009 #1\n    hi, I am writing a computer algorithm which descibes the change of choice.\n\n    1.your friend puts $10 in a box among three (there are three boxes) but you don't know which.\n    2.you choose one of them but do not open it.\n    3.your friend opens (eliminates) one of empty boxes\n    i.e. if you choose the lucky box, he eliminate either one of two empty boxes at equal probability\n    and if you choose an unlucky one, he eliminates the empty remainder.\n    4.then you decide, whether or not you change your choice between two remainings.\n    5.repeat 1~4 many times and expect the maximum result(in $).\n\n    Question: you'd better change your choice? or should not change? for the maximum outcome.\n\n    I expected that the change of choice should not matter: the equal probabilities.\n\n    but my computer algorithm tells that \"if you change the choice, better\"\n\n    Can someone tell me whether I am wrong or my algorithm is wrong?\n  2. jcsd\n  3. Mar 30, 2009 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The algorithm is right. Search for Monty Hall problem (here or on the search engine of your choice). It's a popular topic. In short: picking the remaining box is really as good as picking both remaining boxes, and there's a better chance it's in one of the two remaining boxes than in your original 1.\n  4. Mar 30, 2009 #3\n    Thank you for such a quick reply!\n    I will check it out. but your explanation helped a lot, CRGreathouse!"}
{"text": "Retrieved from http://mathforum.org/blogs/pows/mentoring-the-cherokee-creek-checkers-club-algpow-with-the-noyce-scholars/\nText:\nLast Friday, I was invited to speak about the Problems of the Week to the Northeast region Noyce Scholars (early career and future STEM educators, and a really fun group to do math with!).\n\nSince I\u2019d been thinking a lot about the AlgPoW that just wrapped up, Cherokee Creek Checkers Club, we looked at that problem and some students\u2019 work on the problem.\n\nWe began with this scenario:\n\nCherokee Creek Middle School has a checkers club with an enthusiastic group of players. Unfortunately, they started this semester in a bit of a slump, winning only 40 of their first 90 games in various inter-school competitions. That gave them a winning percentage of only about 44%.\n\nThen they found a new coach, who inspired them and significantly improved their overall level of play. This month they went on a hot streak, winning 3 out of every 5 games they played.\n\nWe used a scenario to loosen our thinking up and try to focus on three big preparation themes: prerequisite knowledge, big math ideas, and multiple approaches.\n\nLooking at the scenario, the Noyce Scholars noticed and wondered about cool math like:\n\n  \u2022 Quantities are represented as percentages, fractions, and ratios in this problem.\n  \u2022 How could you determine which coach was better? How do you know for sure?\n  \u2022 What\u2019s the overall winning percentage, based on the number of games played, before and after the new coach.\n  \u2022 If they won 40 out of 90 games at first, how many games might they play over a year? A week?\n  \u2022 How come winning 3 out of 5 is an improvement over winning 40 out of 90?\n  \u2022 They increased their winning percentage by 16 percent\n\nAll of these noticings and wonderings gave us insight into two of our three foci.\n\n  1. What do students need to know/understand to work on a problem about this story?\n    \u2022 Fractions, ratios, and percents and how they are related\n    \u2022 How winning percentages are calculated\n    \u2022 That two coaches are being compared and one might be better than the other; the team improved over time\n  2. What big math ideas are at work here?\n    \u2022 Comparing two quantities using fractions, ratios, and percentages\n    \u2022 Change in one quantity as a function of another e.g. overall winning percentage as a function of games played with the new coach\n\nOur third focus is multiple approaches, and for that we needed a problem to solve. I revealed that after playing some more games, the team\u2019s overall winning percentage climbed to exactly 52% and we wondered, \u201chow many games did they play? How many did they win?\u201d Recalling that they won 3 out of every 5 games, we set to work.\n\nThe multiple methods that we used were Make a Table, Guess and Check, and Make a Mathematical Model (an algebraic model, in this case).\n\nThen we took a look at the work of an Algebra I student, M.:\n\n\nThey played 85 games that month\n\n\nFor this problem I did guess and check. First I tried 40/90 and 30/50 because it says they won 3/5 games so 70/140 was 50% which was too little so I tried 33+40/55+90 and got 50.3% so I realized I needed to go up a lot more. Then I tried 60/100 + 40/90 and 100/190 and got 52.6% so I went down a bit and did 94/180 and got 52.22222% so I went down more and did 91/175 and 52% evenly. so they had played 90 games and now they played a total of 175, so they played 85 games that month\n\nCheck- 40/90 + 51/90 is 91/175 which is 52%\n\nHere are some of the initial things we noticed and wondered about M\u2019s work:\n\n  \u2022 She checks her work at the bottom\n  \u2022 In the check, she adds 40/90 + 51/90 = 91/175 and we wondered how she was using that calculation to check her work\n  \u2022 We also wondered in the check if she meant 51/85 instead of 51/90 because 51/85 was used earlier in the problem and would represent winning 3 out of every 5 games (17 sets of 5 games)\n  \u2022 We wondered how she thought of her first guess, 30/50\n  \u2022 We noticed that sometimes she used \u201cand\u201d and sometimes she used the \u201c+\u201d sign\n  \u2022 We noticed she used fraction notation and wondered if she was using it informally, using \u201c+\u201d to mean \u201cand\u201d and using \u201c/\u201d to mean \u201cout of\u201d\n  \u2022 We noticed that she got the correct answer, and it didn\u2019t take her very many guesses at all!\n\nAnd finally, we thought of some questions we could ask M. to help her revise her work and keep reflecting on the problem such as:\n\n  \u2022 This time, it took you 5 guesses to get the answer. What are some ways you could find an answer with fewer guesses next time you solve a similar problem?\n  \u2022 How did you decide what guess to start at? What did you notice in the problem that led to your first guess?\n  \u2022 How would you explain your steps and calculations to another student who is stuck and doesn\u2019t understand how to make a guess and check it?\n  \u2022 Each time you did a calculation you wrote it a different way. If you pick one of the ways (e.g. 33+40/55+90) and translate all the other calculations into that format, what patterns do you notice in the calculations?\n\nThe final step, which we ran out of time for, is to get feedback on the questions we generated. Which of them are engaging? Which inspire reflection and meta-cognition? What do you think of the tone of each question?\n\nBy the way, if you\u2019re interested in the process of looking at student work and finding the right question to ask, we are focusing a new set of Professional Development courses on it this year. We\u2019d love to have you join us!\n\nIf you teach with the PoWs, or work with pre-service teachers, you might also be interested in our free mentoring, which pairs volunteer pre-service teachers with students working on the PoWs. The mentors learn to ask good questions and the students get feedback on their mathematical thinking.\n\nSome \u201cCherokee Creek Checkers Club\u201d links in case you are interested:"}
{"text": "Retrieved from http://math.stackexchange.com/questions/97602/finding-the-minimum-grade/97606\nText:\nTake the 2-minute tour \u00d7\n\nProfessor sent the following data to his students: Full Grade: 25, Max. grade: 22.5, Mean: 19.9, Median: 20\n\nAssuming the number of students is n. Is it possible to calculate the minimum grade from the given data only?\n\nshare|improve this question\nPS: you may know some of other students' grades. For example you heard that student x1 got 21, another student x2 got 18 and so on .. but you don't know all the students' grades of course \u2013\u00a0 Osama Gamal Jan 9 '12 at 11:27\nWhat does \"full grade\" mean? \u2013\u00a0 Dan Brumleve Jan 9 '12 at 11:29\n@Dan Probably \"Full Grade\" is the maximum grade you can get in the exam. For instance there are 5 questions 5 points each. \u2013\u00a0 marvinthemartian Jan 9 '12 at 11:36\n@marvinthemartian, is that information relevant? \u2013\u00a0 Dan Brumleve Jan 9 '12 at 11:38\n@Dan Frankly, I do not think it is. But I do not know the answer yet, so maybe. \u2013\u00a0 marvinthemartian Jan 9 '12 at 11:41\nshow 2 more comments\n\n2 Answers\n\nThe answer is no. Let us look for an easier example:\n\nAssume $n=5$, our students are called \"A\",\"B\",\"C\",\"D\",\"E\" and the grades are given by:\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 2&1&1&1&0 \\end{array}\n\nClearly Maximum, Median and Mean are given by {2,1,1}. But the dataset\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 2&1&1&1/2&1/2 \\end{array}\n\nAlso has the same Mean, Median and Maximum. You can always do this by using a convex combination of the last two values as long as they stay below the median. They will not affect the median, nor the mean or the maximal element but they will change the minimal grade given.\n\nEdit: Now with this knowledge we can come back to your question and easily construct a counterexample flor $n=5$:\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 22.5&20&20&20&17 \\end{array}\n\n\\begin{array}{c|c|c|c|c} A&B&C&D&E\\ \\newline 22.5&20&20&19&18 \\end{array}\n\nThose do both fit to your data. For higher $n$ you can pad with the mean $19.9$ on the left and right side of the median (odd $n$). For even $n$ there is a similar counterexample. For $n \\in \\{3,4\\}$ refer to the answer given by tom.\n\nshare|improve this answer\nadd comment\n\nI don't believe so, not for general n at least. We can for some isolated cases:\n\nFor $n = 2$, the problem simply doesn't work\n\nFor $n = 3$, we need one student to get 22.5, another student to get 20, and the other to get $s_3$ so that:\n\n$$\\frac{22.5+20+s_3}{3}=19.9$$ Which works out for $s_3=17.2$, the minimum grade\n\nFor $n=4$, lets say we have 4 students with 4 grades $s_1 \\geq s_2\\geq s_3\\geq s_4$. We know then that $s_1=22.5$, that: $$\\frac{s_2+s_3}{2}=20$$\n\nand $$\\frac{22.5+s_2+s_3+s_4}{4}=19.9$$ We can then solve this for $s_4$ using the fact that $s_2+s_3=40$ to get $s_4=17.1$.\n\nHowever, for $n=5$, we run into difficulties. We know (using the same system of notation) that $s_1=22.5$, and that $s_3=20$, but beyond that, the fact that\n\n\nWill never allow us to say any more about $s_5$. Indeed, this is true for any $n\\geq5$ (is this clear?).\n\nshare|improve this answer\nNote that you are searching for integer numbers (for simplification since grades can only be x.0 or x.5) and note that s_2 > s_4 > s_5 \u2013\u00a0 Osama Gamal Jan 9 '12 at 12:17\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/18482/find-the-subset-of-a-line-on-a-sphere-far-from-a-set-of-points-on-the-sphere/18521\nText:\nTake the 2-minute tour \u00d7\n\nI have some code where the \"hot part\" relies on an inefficient solution to this problem.\n\nProblem: I have 3 inputs: a. A collection of N points on the surface of a sphere.\nb. A line segment on the sphere.\nc. A distance X (distance can be on the surface or in 3D as it's trivial to map between them)\n\nOutput: Find the subset of the line segment which is more than distance X from the collection of points.\n\n(My problem actually involves a curve on the sphere, but I can reduce it to a line segment by chopping it up into smaller pieces.)\n\nAt present, I parametrize the line and created a distance function, subtract X then slam it into a method that finds the times when a function is positive. VERY slow.\n\nAlso, precomputations count in this algorithm. That is, the set does change over time, but it changes less frequently than I need this result for different line segments. Maybe 5 queries to every set change? That's worst case.\n\nX is fixed over time.\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 5 down vote accepted\n\nBy a line on the sphere, I assume you mean a part of a great circle spanning less than 180\u00b0.\n\nFor each of the N points, find what part of the line is closer than X to that point. This is at most a single segment. Find their union C as a disjoint union of segments. This is probably easier if you sort them by their starting point, and the obvious algorithm gives you the union as a sorted list as well \u2013 which makes the last part trivial: Find the complement of C.\n\nOh, and the first part can be done with some simple linear algebra.\n\nshare|improve this answer\nadd comment\n\nIf the querying aspect is important for you (i.e the lines keep appearing), then you should really build a data structure on the disks. Here's what you need to do. You need to build the arrangement on disks of radius X centered at each point (the arrangement being the way in which the sphere is decomposed into patches by the boundaries of the disks). Then, a point location query for each endpoint locates the start and end cells, and walking through the arrangement along the line gives you the subset of the line not covered by the disks.\n\nWhile this is overkill for a single line (and Harald's solution is fine), it'll be more efficient if the lines are short and there are many of them (since the point location queries will run in time logarithmic in the number of points, and you hopefully won't have to walk through too many cells). To implement this is a little tricky though: luckily, CGAL has packages that you can use for this purpose. A source paper on this topic is here.\n\nshare|improve this answer\nVery nice paper. That is kind of what I had in mind, but Harald's answer looks to be a lot easier to code, and probably is going to be good enough for me as long as X is large enough. (The exact final values of X are TBD.) THANKS! \u2013\u00a0 John Mar 17 '10 at 22:16\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://zbmath.org/?q=an:1182.11014\nText:\nzbMATH \u2014 the first resource for mathematics\n\n\na & b logic and\na | b logic or\n!ab logic not\nabc* right wildcard\n\"ab c\" phrase\n(ab c) parentheses\nany anywhere an internal document identifier\nau author, editor ai internal author identifier\nti title la language\nso source ab review, abstract\npy publication year rv reviewer\ncc MSC code ut uncontrolled term\nA 2-adic formula for Bernoulli numbers of the second kind and for the N\u00f6rlund numbers. (English) Zbl\u00a01182.11014\n\nThe Bernoulli numbers of the second kind are defined by means of the following generating function\n\nt log(1+t)= n=0 b n t n \u00b7\n\nThe numbers n!b n have been called the Cauchy numbers of the first kind. These numbers satisfy the following relation\n\nn!b n = 0 1 x(x-1)(x-2)(x-n+1)dx\u00b7\n\nThe first few of these numbers are given by b 0 =1,b 1 =1 2,b 2 =-1 12,b 3 =1 24,b 4 =-19 720,b 5 =3 160. These numbers are related to Euler\u2019s constant, \u03b3 and nth harmonic numbers, H n , that is\n\nn=1 (-1) n+1 b n n=\u03b3\n\n\n1+ n=1 (-1) n+1 H n n=\u03c0 2 6,\n\n\nH n = k=1 n 1 k\u00b7\n\nThe Bernoulli numbers of higher-order are defined by means of the following generating function\n\n(t e t -1) s = n=0 B n (s) t n n!\u00b7\n\nFor n=s the numbers B n (n) are called the N\u00f6rlund numbers or the Cauchy numbers of the second type, may be determined by the generating function\n\nt (1+t)log(1+t)= n=0 B n (n) t n n!\u00b7\n\nRelations between the numbers b n and B n (n) are given by\n\nB n (n) =n! k=1 n (-1) n-k b k ,\n\n\nb n =B n (n) n!+B n-1 (n-1) (n-1)!\u00b7\n\nThe author gives a formula expressing the Bernoulli numbers of the second kind as 2-adically convergent sums of traces of algebraic integers. By using this formula, the author proves the formulae and conjectures of Adelberg concerning the initial 2-adic digits of these numbers. He also gives many relations on these numbers and N\u00f6rlund numbers or the Cauchy numbers of the second type.\n\n11B68Bernoulli and Euler numbers and polynomials\n11B65Binomial coefficients, etc."}
{"text": "Retrieved from http://math.stackexchange.com/questions/135478/using-linear-algebra-how-is-the-binet-formula-for-finding-the-nth-fibonacci-nu?answertab=active\nText:\nTake the 2-minute tour \u00d7\n\nIf possible, please refrain from any type of proof besides linear algebra. So, using the recursion formula $F_{n+1} = F_{n-1} + F_n$, for $n\\gt 1$, and where $F_0 = 0$ and $F_1 = 1$, and the Fibonacci matrix, derive the golden ratio and ultimately the Binet formula.\n\nshare|improve this question\nI haven't done eigenvectors yet (I do that in about a week in my L.A. course). Is there a way to derive all that without using those concepts? \u2013\u00a0 Nico Bellic Apr 22 '12 at 20:08\nYou could use the shift operator $S$ in the space of sequences. Then $F$ satisfies $S^2 F=SF+F$ and so $(S^2-S-I)F=0$. You now factor $S^2-S-I$ to find its kernel. @BillDubuque has proposed this approach several times here but I can't find a good link right now. \u2013\u00a0 lhf Apr 22 '12 at 20:10\nI'm truly, really sorry, but I'm not sure if I'm able to follow you. \u2013\u00a0 Nico Bellic Apr 22 '12 at 20:15\nSee for instance cs-netlab-01.lynchburg.edu/courses/algorithms/recurenc.htm (Example - solving the Fibonacci numbers) This is a random link found by Google. I could not find anything in Wikipedia. \u2013\u00a0 lhf Apr 22 '12 at 20:20\nadd comment\n\n2 Answers\n\nup vote 3 down vote accepted\n\nI am not sure to which extent this will be helpful for OP, but I'll post this anyway. This is basically the same solution as the one posted by Zhen Lin, but without any explicit reference to eigenvalues or eigenvectors.\n\nSo the sequence given by $F_{n+2}=F_{n+1}+F_n$ seems to be complicated. But there is a wide class of sequences we understand very good - geometric progressions.\n\nLet us ask the question whether we can modify the sequence $F_n$ to get a geometric progression. E.g. we can ask whether there is an $x$ such that the sequcence $G_n=xF_n+F_{n-1}$ is a geometric progression.\n\nFrom $$\\begin{align} F_{n+1}&=F_n+F_{n-1}\\\\ F_{n}&=F_{n-1}+F_{n-2} \\end{align} $$ we get $$G_{n+1}=xF_{n+1}+F_n=xF_n+(x+1)F_{n-1}+F_{n-2}= xF_n+(x+1)F_{n-1}+F_n-F_{n-1}=(x+1)F_n+xF_{n-1}.$$ If we want the RHS to be a multiple of $G_n$, then we must have $$\\frac{x+1}x=x,$$ i.e. $x+1=x^2$ or $x^2-x-1=0$, which has the two solutions $\\lambda_{1,2}=\\frac{1\\pm\\sqrt5}2$.\n\nNotice that $\\lambda_1+\\lambda_2=1$, $\\lambda_1\\lambda_2=-1$.\n\nFor any of the above values we have $$G_{n+1}=(\\lambda+1)F_n+\\lambda F_{n-1}=\\lambda\\left(\\frac{\\lambda+1}\\lambda F_n+F_{n-1}\\right)=\\lambda G_n.$$ We also have $G_1=\\lambda$, $G_0=1$.\n\nSo we get $$ \\begin{align} \\lambda_1F_{n}+F_{n-1}&=\\lambda_1^n\\\\ \\lambda_2F_{n}+F_{n-1}&=\\lambda_2^n \\end{align} $$ If we subtract the above two equations, we get $$(\\lambda_1-\\lambda_2)F_{n}=\\lambda_1^n-\\lambda_2^n$$ which gives $$F_n=\\frac{\\lambda_1^n-\\lambda_2^n}{\\lambda_1-\\lambda_2}.$$\n\nIn the solution, which used the diagonal form and eigenvalues, we did not have to guess, that it is possible to obtain geometric progressions combining Fibonacci sequence and shifted Fibonacci sequence - we get this fact from that diagonal matrix.\n\nOr we can look at this the other way round - many applications of diagonal matrices similar to given matrix (e.g. in linear recurrences, ordinary differential equations) can be viewed as an effort to transform the original problem to a simpler form; in this case the simpler form was a geometric progression.\n\nshare|improve this answer\nadd comment\n\nThe Fibonacci numbers are defined by a second-order linear recurrence equation: $$F_{n+2} = F_{n+1} + F_n$$ This means we can treat the solution of $F_n$ in terms of $n$ as a problem in linear algebra involving only $2$-dimensional vectors. In some sense, what we are doing is modelling this as a dynamical process on a $2$-dimensional state space.\n\nLet $V = \\mathbb{R}^2$. We define a linear operator $T : V \\to V$ by $$T(x, y) = (y, x + y)$$ Notice that $T(F_{n}, F_{n+1}) = (F_{n+1}, F_{n+2})$, so you can think of $V$ as being a sliding $2$-entry window on the Fibonacci sequence and $T$ as the operator which advances the window along the Fibonacci sequence. The initial conditions $F_0 = 0, F_1 = 1$ then imply that $$T^n(0, 1) = (F_n, F_{n+1})$$ so all we need to do to find $F_n$ in terms of $n$ is to find an effective way to compute iterates of the operator $T$!\n\nNow, we get our hands dirty and represent $T$ as a matrix: $$T = \\begin{pmatrix} 0 & 1 \\\\ 1 & 1 \\end{pmatrix}$$ Imagine if we could somehow find an invertible matrix $P$ and a diagonal matrix $D$ such that $T = P D P^{-1}$; then, by matrix algebra, we would have $T^n = P D^n P^{-1}$, and it is easy to compute powers of diagonal matrices. The theory of eigenvectors and eigenvalues gives us one way to find such a factorisation of $T$. Notice that $$\\det (T - x I) = \\det (P(D - x I)P^{-1}) = (\\det P)(\\det (D - x I))(\\det P^{-1}) = \\det (D - x I)$$ but a simple calculation shows $$\\det (D - x I) = \\det \\begin{pmatrix} \\lambda_1 - x & 0 \\\\ 0 & \\lambda_2 - x \\end{pmatrix} = (\\lambda_1 - x)(\\lambda_2 - x)$$ so whatever $\\lambda_1$ and $\\lambda_2$ are, they must be the zeros of the polynomial $$\\det (T - x I) = \\det \\begin{pmatrix} -x & 1 \\\\ 1 & 1 - x \\end{pmatrix} = x^2 - x - 1$$ which, surprise surprise, is the minimal polynomial of the golden ratio. So let $\\lambda_1 = \\frac{1}{2} (1 + \\sqrt{5})$ and $\\lambda_2 = \\frac{1}{2} (1 - \\sqrt{5})$. These are the eigenvalues of $T$. By construction, $\\det (T - \\lambda_1 I) = \\det (T - \\lambda_2 I) = 0$, so there must be non-zero vectors $\\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix}$ and $\\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix}$ such that $$ T \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} = \\lambda_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} $$ $$ T \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = \\lambda_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} $$ These vectors are called the eigenvectors of $T$. I leave you to verify that $x_1 = \\lambda_1 - 1$, $y_1 = 1$, $x_2 = \\lambda_2 - 1$, $y_2 = 1$ works, but there are other solutions.\n\nDefine the matrix $P$ by $$P = \\begin{pmatrix} x_1 & x_2 \\\\ y_1 & y_2 \\end{pmatrix}$$ Notice that $$\\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\alpha_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} + \\alpha_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = P \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$$ so by linearity we have $$T \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\lambda_1 \\alpha_1 \\begin{pmatrix} x_1 \\\\ y_1 \\end{pmatrix} + \\lambda_2 \\alpha_2 \\begin{pmatrix} x_2 \\\\ y_2 \\end{pmatrix} = P \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix} \\begin{pmatrix} \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix}$$ but we can invert $P$ to find $\\alpha_1$ and $\\alpha_2$ in terms of $x$ and $y$, so we have obtained the desired factorisation of $T$ as $P D P^{-1}$ with $D$ diagonal. Putting everything together, we get the formula $$T^n = P \\begin{pmatrix} {\\lambda_1}^n & 0 \\\\ 0 & {\\lambda_2}^n \\end{pmatrix} P^{-1}$$ and applying this to the vector $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ gives Binet's formula.\n\nshare|improve this answer\nThe OP seems to want to avoid eigenvalue decompositions. \u2013\u00a0 lhf Apr 23 '12 at 1:09\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/207076/convex-combination?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nAssume that $I$ is a countable set, and we have $u_i\\in \\mathbb{R}^n$ for $i\\in I$. Suppose that $v=\\sum_{i\\in I} a_i u_i$ and $\\sum_{i\\in I}a_i=1$ and $a_i\\geq 0$.\n\nCan one show that there exists a finite $J\\subseteq I$ and $b_j$ for $j\\in J$ such that $\\sum_{j\\in J}b_j=1$, $b_j\\geq 0$, and $v=\\sum_{j\\in J} b_j u_j$?\n\nIs this some well-known result?\n\nshare|improve this question\nCarath\u00e9odory's theorem almost says that you can get away with just $n+1$ elements in $J$. Except here you start with an infinite convex combination, and then the theorem does not apply, at least not without further work. \u2013\u00a0 Harald Hanche-Olsen Oct 4 '12 at 10:41\nI like this question. Too bad your 0% accept rate won't help in attracting answers to it... \u2013\u00a0 joriki Oct 4 '12 at 11:55\nI second joriki's comment. Do you not know about accepting answers to questions you post on this site? \u2013\u00a0 Gerry Myerson Oct 4 '12 at 12:34\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nYes, one can.\n\nWithout loss of generality, assume $a_i\\gt0$ and let $I=\\mathbb N$. For any subset $A\\subseteq\\mathbb N$, call\n\n$$ W_A=\\frac{\\sum_{i\\in A}a_iu_i}{\\sum_{i\\in A}a_i} $$\n\nthe weighted average for $A$. If the $u_i$ all lie in some proper affine subspace of $\\mathbb R^n$, we can restrict to that subspace, so without loss of generality we can assume that their affine span is $\\mathbb R^n$. Then at some finite index $k$ there are positive contributions from $n+1$ affinely independent vectors $A=\\{u_{i_1},\\dotsc,u_{i_{n+1}}\\}$, and $W_A$ is therefore in the interior of their convex hull $H$. Thus, since both $\\sum_ia_i$ and $\\sum_ia_iu_i$ converge (so their tails converge to zero) there is some $l\\ge k$ such that the weighted average remains inside $H$ if the tail $\\{i\\in\\mathbb N\\mid i\\ge l\\}$ is added to $A$. Then the desired finite sum can be obtained by replacing the contributions from the tail by corresponding linear combinations of $u_{i_1},\\dotsc,u_{i_{n+1}}$.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathnotations.blogspot.com/2010/05/challenging-geometry-assumptions-review.html\nText:\nTuesday, May 18, 2010\n\nChallenging Geometry Assumptions: Review for SAT I/II\n\nThe video below presents a more challenging 3-dimensional geometry problem which would be at the upper end of SAT I or SAT II - Subject Tests (Math I/II). The key here is to challenge students' assumptions about a quadrilateral being a square because it has 4 congruent sides, a common error. This question will also review a considerable amount of geometry: Pythagorean Theorem, Volume of cube, spatial reasoning, 45-45-90 triangles, area of a rhombus, etc.\n\nAs always, the focus is on the art of questioning, suggested instructional strategies and pedagogy, although this problem may be interesting enough to capture the attention of some students who are preparing for upcoming standardized tests. For students who need help with spatial visualization, a model could be provided or have enough empty boxes available (they don't have to be cubes!). \u00a0\n\nI strongly urge using learning partners or pairs for the discussion.\u00a0\n\nBenefits include:\n(1) Students feel less tentative when offering ideas to one other person or in a small group.\n(2) Instead of posing conceptual questions to individuals, receiving little or no response except from the most confident or capable, you can pose a question to a learning pair: \"Julie and Jason, what is needed to insure that ABCD is a square?\" They should be given a few moments to think and confer before responding. The stronger student will usually explain it to the other. If neither can respond, they can say, \"Pass!\"\n(3) The biggest advantage of student dialog is that often our explanations simply don't click with several students, but they do make sense to others. Those who \"get it\" can usually explain it in terms that their peers understand better, a benefit to both the \"explainer\" and the \"explainee\"!\n\nBy the way, the question posed near the end of the video is worth pursuing if time permits:\n\n\"Without calculating the areas,\u00a0ithe area of the non-square rhombus less than or greater than the area of the square?\"\n\nThe answer is less for many reasons, but we would hope they would recall the base x height formula for a rhombus. The height is maximized when the angle between the sides is 90\u00b0. Why? Interestingly, the areas are quite close: 19.6 vs. 20. I believe strongly that this is the type of higher-order question that not only reviews important concepts but promotes deeper thinking, or should I say, thinking more than one inch deep!\n\nWhat are your thoughts? Would you give students the e\u221a3 formula before a standardized test or ever?Are these videos helpful to you? If you respond both on this blog and on my YouTube Channel, MathNotationsVids, and also rate these videos, that gives me the guidance I need to improve them.\n\n\n\nSol said...\n\nDave - this is a great video. I really like how many concepts it ties together.\n\nSol said...\n\n\nI liked this problem so much that I stole it and blogged about it:\n\n\nMr. Chase said...\n\nThere's a relatively easy solution using vectors and the cross product. I describe the solution in the comments here:\n\n\nDave Marain said...\n\nSorry for the delay in replying Sol and Mr. Chase--\nSol, Sharing is what the blogosphere is all about. I get most of my ideas from others! It's a compliment for you to discuss my question.\n\nMr. Chase--\nI completely agree that vector cross products are designed for areas of parallelograms but I made the decision to demonstrate a method accessible to less advanced students. I should have mentioned a vector approach however ( or did I, I can't remember...)."}
{"text": "Retrieved from http://math.stackexchange.com/questions/205260/solutions-of-diophantine-equations-xy-yx/205264\nText:\nTake the 2-minute tour \u00d7\n\nPossible Duplicate:\n$x^y = y^x$ for integers $x$ and $y$\n\nHow to prove that $(2,4)$ and $(4,2)$ are the only solutions of Diophantine equations ${x^y} = {y^x}$ for $x \\ne y$?\n\nshare|improve this question\n@DavidWallace For $x \\ne y$. \u2013\u00a0 glebovg Oct 1 '12 at 5:02\nHah! Sorry, I can't read. \u2013\u00a0 user22805 Oct 1 '12 at 5:04\nadd comment\n\nmarked as duplicate by Cameron Buie, Thomas, Noah Snyder, Chris Eagle, \uff2a. \uff2d. Oct 5 '12 at 13:00\n\n\n1 Answer\n\nup vote 3 down vote accepted\n\nTaking logarithms:\n\n$$x\\ln y=y\\ln x$$ $$\\frac{\\ln y}y=\\frac{\\ln x}x$$\n\nFor this to be true, the function has to take the same value at two different locations. Take the function\n\n$$f(x)=\\frac{\\ln x}x$$ $$f'(x)=\\frac{1-\\ln x}{x^2}$$\n\nIt has a maximum at $x=e$, is decreasing for $x>e$ and increasing for $x<e$. So if two values are equal, one has to be greater than $e$ and the other must be less. So for the lower value we only have $x=1,2$ as options. Our problem amounts to proving that there is no other number that gives the same value as $x=1$. Since $f(1)=0$, and $\\ln(x)$ only has a single root at $1$, we know this can't happen, so we're done.\n\nshare|improve this answer\nKeep in mind that logarithms assume the numbers are positive. $x=-4, y=-2$ works as well. Cases of negative integers either reduce to the positive case in disguise (when both are negative) or are trivial (when only one is). \u2013\u00a0 Robert Mastragostino Oct 1 '12 at 5:29\nI used a very similar argument, but I was not convinced. Thanks. \u2013\u00a0 glebovg Oct 1 '12 at 5:30\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/103588/expression-that-hits-integer-multiples-of-two-variables/103777\nText:\nTake the 2-minute tour \u00d7\n\nIs there a way to generate am expression that will get all integer multiples of an arbitrary pair of integers?\n\nI.e. Some function that will spit out ${0,2,3,4,6,8,9,10, ... }$ and all of the other multiples of 2 and 3 given integer arguments. It should not generate results for integer arguments that are not multiples of 2 and 3.\n\nBy function I mean using elementary mathematical operations.\n\nI would prefer a single variable expression.\n\nshare|improve this question\nI'm confused. Your $f(x,y)$ outputs many more integers than the multiples of a and b. But if that's allowed, then just take your single-variable function to be $f(x)=x$, and then you get all your multiples out. \u2013\u00a0 Cam McLeman Jan 29 '12 at 15:25\nDoes $$f(n)=\\text{the }n\\text{th natural number that is a multiple of either }a\\text{ or }b\\text{ (or both)}$$ count for you? If not, then you'll have to specify more precisely what you mean by \"function\". \u2013\u00a0 Henning Makholm Jan 29 '12 at 15:25\n@CamMcLeman, Henning, edited, you are correct. \u2013\u00a0 soandos Jan 29 '12 at 15:30\nSo what you want is not just a function (which in mathematics can be just about anything you are able to define unambiguously), but an expression with one or more free variables. But then you need to specify what is an \"elementary mathematical operation\" to you. \u2013\u00a0 Henning Makholm Jan 29 '12 at 15:32\nStandard definition, composition of constants, logarithms, exponentiation, extractions of nth roots by using $(+,-,*,/)$. \u2013\u00a0 soandos Jan 29 '12 at 15:34\nshow 6 more comments\n\n1 Answer\n\nup vote 3 down vote accepted\n\nThe function $$f(n)={3\\over2}n+{i^n-i^{-n}\\over4i}$$ (where $i$ is a square root of minus one) gives the outputs $0,2,3,4,6,8,9,10,\\dots$ on being given the inputs $0,1,2,3,4,5,6,7,\\dots$.\n\nEDIT: In general, suppose you're given positive intgers $a,b$, and want the output to be all $n$ divisible by one or the other. First find the least common multiple $L$ of $a$ and $b$ (in the example, $L=6$). Then find the number $N$ of multiples of $a$ and/or $b$ in $0,1,2,\\dots,L-1$ (in our example, $N=4$; in general, this is a simple exercise). The main term of $f(n)$ will be $(L/N)n$. The difference, $f(n)-(L/N)n$, will be periodic with period $N$, so it will be a linear combination of the functions $g_j(n)=e^{2\\pi ijn/N}$, $j=0,1,\\dots,N-1$. You find the coefficients in this linear combination by the standard techniques of intro linear algebra - it's just solving $N$ linear equations in $N$ unknowns.\n\nshare|improve this answer\nHow could I generalize this for arbitrary multiples? \u2013\u00a0 soandos Jan 29 '12 at 23:50\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/291956/if-p-is-prime-and-p-5-show-that-when-p-is-divided-by-10-the-remainder\nText:\nTake the 2-minute tour \u00d7\n\nIf $p$ is prime and $p > 5$, show that when $p$ is divided by 10, the remainder is 1, 3, 7, or 9.\n\nThis is a problem from Hungerford's Abstract Algebra: An Introduction. I would like some help on it, it was an example in class. Thanks.\n\nshare|improve this question\nConsider the case when the remainder is 2. Then $p = 10 q + 2$ for some integer $q$, so that $p = 2 (5 q + 1)$ is even, but cannot be 2 by the assumption $p > 5$. The other cases are entirely similar, it is useful for you to work them out yourself. \u2013\u00a0 Andreas Caranti Feb 1 '13 at 7:27\nSince you are new, I want to give some advice about the site: To get the best possible answers, you should explain what your thoughts on the problem are so far. That way, people won't tell you things you already know, and they can write answers at an appropriate level; also, people are much more willing to help you if you show that you've tried the problem yourself. If this is homework, please add the [homework] tag; people will still help, so don't worry. Also, many would consider your post rude because it simply states the problem, and is not a request for help, so consider rewriting it. \u2013\u00a0 Zev Chonoles Feb 1 '13 at 7:34\n$p > 5$ prime means $p$ not divisible by $2$ or $5$. \u2013\u00a0 Benjamin Dickman Feb 1 '13 at 8:26\nadd comment\n\n6 Answers\n\nup vote 5 down vote accepted\n\nBy the division algorithm, we can write each $p$ as $$p = 10q + r$$ for some quotient $q$ and remainder $0\\le r < 10$. As $p$ is prime, clearly $r\\neq 0$. $r$ also cannot be even, otherwise $p$ is even. Finally, note that $r \\neq 5$ or $5 \\mid p$.\n\nFor a more brief and algebraic solution, note that $(p,\\ 10) = 1$ implies that $p$ is a unit in $\\mathbb{Z}/10\\mathbb{Z}$. The units of the ring are precisely $1,\\ 3,\\ 7$ and $9$.\n\nFor completeness, you should probably show that there exists primes for each of the remaining congruence classes.\n\nshare|improve this answer\nadd comment\n\nYou already have a couple of nice \u2018mathematical-looking\u2019 answers. In attacking a question like this, though, you might want to start with simple, familiar facts.\n\nThe remainder when $p$ is divided by $10$ is simply the last digit of $p$. If the last digit of a number $n$ is $0,2,4,6$, or $8$, what kind of number is $n$? Can it be prime if it\u2019s greater than $2$? If the last digit is $0$ or $5$, what can you say about $n$? Can it be prime and greater than $5$?\n\nThese are enough to tell you, at least informally, why the prime $p>5$ must end in $1,3,7$, or $9$, and now you can worry about explaining the reasoning in the previous paragraph a bit more formally.\n\nshare|improve this answer\nThank you for the tip, I was not sure how to best ask questions here but I'm learning and will remember that. \u2013\u00a0 grayQuant Feb 1 '13 at 14:36\nadd comment\n\nTo say that a prime $p > 5$ gives a remainder of $1, 3, 7$ or $9$ when divided by $10$ is merely remarking that the prime is odd (and not $5$, since all integers ending in five are multiples thereof).\n\nAfter all, the remainder when divided by $10$ is simply the unit of the number itself, and if that unit was any of $0, 2, 4, 6, 8$ we'd plainly see that it was an even number, and therefore not prime. Likewise with the five.\n\nThat said, we could come to the conclusion of your statement by, say, basing an argument on how all primes above $3$ are of the form $6n \\pm 1$ (mind you, this follows from an argument akin to the above): the multiples of $6$ begin as follows: $$6, 12, 18, 24, 30\\ldots$$ From which we father that the units of such multiples are either $0, 2, 4, 6$ or $8$. Now take the '$\\pm 1$' bit into consideration and we find that we have the following units possible: $$1, 3, 5, 7, 9$$ (Remember, a remainder of $-1$ when divided by $10$ is equivalent to a remainder of $9$.)\n\nSo, much like the above, we disregard the $5$ since that certainly isn't prime, and we have $1, 3, 7, 9$ leftover, as desired.\n\nshare|improve this answer\nadd comment\n\nAny natural number $n$ can be expressed as $$n=a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$$\n\nfor some natural numbers (including $0$) $k,a_k,\\dots , a_1, a_0$. This representation is unique (up to commutation of the products and sums).\n\nSuppose $p\\in \\mathbb{P}$. Then $p=a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$.\n\nClearly the remainder of $a_k\\cdot 10^k + a_{k-1}\\cdot 10^{k-1} + \\cdots + a_1\\cdot 10 + a_0$ when divided by $10$ is $a_0$.\n\nCan you conclude?\n\nshare|improve this answer\nThis helped me think about the problem. I think using the division algorithm is what the author of the book had in mind, just because it was in the previous section. \u2013\u00a0 grayQuant Feb 1 '13 at 22:03\nadd comment\n\nyou are looking for the unit digit of the prime.For prime $p\\neq 2$, unit digit is odd which means $p\\pmod {10}\\in\\{1,3,5,7,9\\}$\n\nNow, for any prime $p\\gt 5$, unit git can't be $5$ otherwise it would be divisible by $5$ and hence won't be a prime.\n\nThus only possible candidates for unit digit of a prime $p\\gt 5$ are $\\{1,3,7,9\\}$\n\nshare|improve this answer\nadd comment\n\nThis is clear from the Euclidean algorithm. Write the remainder $\\rm\\: r = (p\\ mod\\ 10).\\:$ By Euclid\n\n$$\\rm p\\equiv r\\,\\ (mod\\ 10)\\ \\Rightarrow\\ gcd(p,10) = gcd(r,10)$$\n\nIn particular, $ $ when the $ $ gcd $= 1,\\, $ then: $\\rm\\,\\ p\\,$ is coprime to $10$ $\\iff$ $\\rm\\,r\\,$ is coprime to $10$\n\nNow, by hypothesis, $\\rm\\, p\\,$ is prime $ > 5,\\,$ so $\\rm\\, p\\,$ is coprime to $10,\\ $ thus $\\rm\\ r\\,$ is coprime to $10,\\:$ so we infer that $\\rm\\,r\\,$ is odd and coprime to $\\,5,\\:$ hence $\\rm\\:r\\in \\{1,3,7,9\\},\\,$ since the remainder $\\rm\\,r\\in [0,9].$\n\nRemark $\\ $ Ditto if we generalize $\\rm\\,10\\,$ to any modulus $\\rm\\,m\\!:\\ $ if prime $\\rm\\,p\\nmid m\\:$ then its remainder $\\rm\\, p\\ mod\\ m\\,$ is one of the $\\,\\varphi(m)\\,$ remainders coprime to $\\rm\\,m.\\:$ Or, expressed in radix language:\n\n$\\quad$ in radix $\\rm\\,m\\!:\\ $ if $\\rm\\,n\\,$ has units digits $\\rm\\,r,\\ $ then $\\rm\\ n\\,$ is coprime to $\\rm\\, m\\iff r\\,$ is coprime to $\\rm\\,m$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64940/zeros-of-a-sequence-related-to-roots-of-unity\nText:\nTake the 2-minute tour \u00d7\n\nConsider the sequence\n\n$$ a(n) = \\prod_{u^n=1,u \\neq 1}( (1+u)^n+1) $$\n\nSome terms are: $$ 1,1,0,9,121,2704,118336, 4092529,0,97734390625, \\ldots $$\n\nAlonso del Arte asks:\n\nQuestion: What are the multiples of $3$ such that\n\n$$ a(3k) =0 $$\n\nI tried some factorization of cyclotomic polynomials without success. May be true for all odd $k$ ???\n\nEDIT: Another simple property of the sequence is\n\n(hope this may please the negative voter (???))\n\n$$ a(p) \\equiv 1 \\pmod{p} $$\n\nfor any prime $p>3$\n\n\n$$ a(n) (2^n+1) $$ is the determinant of a circulant matrix with first line $$ 3,\\binom{n}{1}, \\ldots,\\binom{n-1}{n} $$\n\nshare|improve this question\nWhy does this question deserve negative feedback? \u2013\u00a0 Daniel Parry May 14 '11 at 22:38\n@Daniel: faq, first line, first paragraph \u2013\u00a0 Franz Lemmermeyer May 15 '11 at 18:37\n\n2 Answers 2\n\nup vote 9 down vote accepted\n\nSuppose that $n=3m$, where $m$ is odd, and $u=e^{2\\pi i/3}$. Then $$ (1+u)^n+1 = ((1+u)^3)^m+1 = (-1)^m+1=0, $$ so $a(n)=0$.\n\nshare|improve this answer\nnice ! I do not see that... \u2013\u00a0 Luis H Gallardo May 13 '11 at 23:03\nReminds me of the old joke about how to simplify the expression $(x-a) (x-b) \\ldots (x-z)$. \u2013\u00a0 Terry Tao May 15 '11 at 18:37\n\nThe complex number $a(n)$ is the resultant of the polynomials $P=(X^n-1)/(X-1)$ and $Q=(X+1)^n+1$; similarly, $(2^n+1)a(n)$ is the resultant of $X^n-1$ and $(X+1)^n+1$. Since these polynomials have integer coefficients, their resultant is a rational integer.\n\nThe resultant of two polynomials vanishes whenever they have a common root. So $a(n)=0$ if and only if there exists a $n$th root of unity $u$ such that $(u+1)^n+1=0$. This implies that $u$ and $u+1$ are both roots of unity, in particular they belong to the unit circle, so that necessarily $u=e^{2\\pi i/3}$ or $u=e^{-2\\pi i/3}$, and $u+1=e^{\\pm i\\pi/3}$. If $u$ is a $n$th root of unity, one gets $3|n$; if $(u+1)^n=-1$, one obtains that $n/3$ is odd. Conversely, if $n=3m$ with $m$ odd, $u=e^{2\\pi i/3}$ satisfies $u^n=1$, $u\\neq 1$, and $(u+1)^n=-1$, hence $a(n)=0$.\n\nSince the two polynomials $P$ and $Q$ above are monic, their resultant vanishes mod $p$ if and only if they have a common root when considered as polynomials modulo $p$. If $n=p$ is prime, then $X^n-1=(X-1)^p$, so $1$ is the only root of $P$, with multiplicity $p-1$; it follows that $$\u00a0a(n)\\equiv ((1+1)^p+1)^{p-1}\\equiv (2^p+1)^{p-1}\\equiv 3^{p-1} \\pmod p.$$ If, moreover, $p\\neq 3$, then $a(n)\\equiv 1\\pmod p$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/29005/characterisation-of-parabolic-subalgebras-reference-sought/29012\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathfrak{g}$ be a complex semisimple Lie algebra and $\\mathfrak{p}$ a subalgebra. As we all know, $\\mathfrak{p}$ is parabolic if it contains a Borel (thus maximal solvable) subalgebra. In this case, with $\\mathfrak{p}^\\perp$ the orthocomplement of $\\mathfrak{p}$ with respect to the Killing form of $\\mathfrak{g}$, $\\mathfrak{p}^\\perp$ is the nilradical of $\\mathfrak{p}$.\n\nThere is a handy converse to this statement which goes as follows: a subalgebra $\\mathfrak{p}$ of $\\mathfrak{g}$ is parabolic if $\\mathfrak{p}^\\perp$ is a nilpotent (thus central descending series terminates) subalgebra of $\\mathfrak{g}$. Note that there is no a priori demand that $\\mathfrak{p}^\\perp$ is even contained in $\\mathfrak{p}$ (though that is, of course. part of the conclusion).\n\nMy question: does anyone know a reference for this (not difficult to prove) fact? (I have, in the past, incorrectly attributed it to Grothendieck.)\n\nshare|improve this question\nI think you need to be more careful about what you mean by nilpotent subalgebra here, since you are implicitly requiring that it consist of \"nilpotent\" elements in the sense of the abstract Jordan decomposition in $\\mathfrak{g}$. A Cartan subalgebra is also nilpotent, for example, but consists of \"semisimple\" elements. An arbitrary nilpotent subalgebra could involve both types. Unless you assume $\\mathfrak{n}$` consists of nilpotent elements, the discussion gets more subtle (and the orthocomplement need not even be a subalgebra of $\\mathfrak{g}$) \u2013\u00a0 Jim Humphreys Jun 22 '10 at 12:35\nI think I am being careful, Jim: I only require that $\\mathfrak{p}^\\perp$ is nilpotent in the usual sense that the central descending series terminates. However, I am definitely requiring that the orthocomplement be a subalgebra, else, as you say, a CSA would provide a counterexample. I will edit my question to make my meaning clearer. \u2013\u00a0 Fran Burstall Jun 22 '10 at 17:58\nMaybe I understand better: the essential statement not already implied by the Bourbaki theorem is that the orthocomplement of a nilpotent subalgebra containing nonzero semisimple elements is never a Lie subalgebra (since if it were, it would have to be parabolic and thus its orthocomplement in turn would be a nil algebra)? This is somewhat roundabout to state though probably true. I haven't seen it in print, however. \u2013\u00a0 Jim Humphreys Jun 22 '10 at 22:16\nA more \"forward\" way is to say that if $\\mathfrak{n}$ is a nilpotent Lie subalgebra of $\\mathfrak{g}$ such that its orthocomplement $\\mathfrak{p}:=\\mathfrak{n}^\\perp$ is a Lie subalgebra then $\\mathfrak{p}$ is a parabolic subalgebra (and hence $\\mathfrak{n}$ is its nilradical). I can't help thinking that Ozeki and Wakimoto paper, which proves that any polarizable subalgebra is parabolic, is somehow relevant; at least, it gives the right conclusion. \u2013\u00a0 Victor Protsak Jun 23 '10 at 0:09\nVictor: thank you for drawing the Ozeki-Wakimoto paper to my attention. It is indeed interesting but does not, as far as I can see, prove my statement. In fact, their result seems much deeper and uses 'non-algebraic' considerations: they look at the analytic subgroup corresponding to a w-polarisable subalgebra and see that the resulting coset space is compact whence the subgroup and so, eventually, the subalgebra is parabolic. \u2013\u00a0 Fran Burstall Jun 23 '10 at 18:29\n\n2 Answers 2\n\nI think that this follows from Bourbaki's \u00c9l\u00e9ments de Math\u00e9matique. Groupes et alg\u00e8bres de Lie, Chapitre VIII, \u00a710, Theorem 1 (see below) applied to the adjoint representation. Alas, I cannot provide the google books link because the book that Google Books claims to be this one, is actually Alg\u00e8bre commutative, Chapitres 5 \u00e0 7! (And the \"Feedback\" link does not allow me to point this out, since in their arrogance, Google does not even allow for the possibility of such an error!)\n\nTh\u00e9or\u00e8me 1. --- Soient $V$ un espace vectoriel de dimension finie, $\\mathfrak{g}$ une sous-alg\u00e8bre de Lie r\u00e9ductive dans $\\mathfrak{gl}(V)$, $\\mathfrak{q}$ une sous-alg\u00e8bre de Lie de $\\mathfrak{g}$ et $\\Phi$ la forme bilin\u00e9aire $(x,y) \\mapsto \\mathrm{Tr}(xy)$ sur $\\mathfrak{g} \\times \\mathfrak{g}$. On suppose que l'orthogonal $\\mathfrak{n}$ de $\\mathfrak{q}$ par rapport \u00e0 $\\Phi$ est une sous-alg\u00e8bre de Lie de $\\mathfrak{g}$ compos\u00e9e d'endomorphismes nilpotents de $V$. Alors, $\\mathfrak{q}$ est une sous-alg\u00e8bre parabolique de $\\mathfrak{g}$.\n\nAnd here's a possible translation:\n\nTheorem 1. --- Let $V$ be a finite-dimensional vector space, $\\mathfrak{g}$ a reductive Lie subalgebra of $\\mathfrak{gl}(V)$, $\\mathfrak{q}$ a Lie subalgebra of $\\mathfrak{g}$ and $\\Phi$ the bilinear form $(x,y) \\mapsto \\mathrm{Tr}(xy)$ on $\\mathfrak{g} \\times \\mathfrak{g}$. If the orthogonal complement $\\mathfrak{n}$ of $\\mathfrak{q}$ relative to $\\Phi$ is a Lie subalgebra of $\\mathfrak{g}$ consisting of nilpotent endomorphisms of $V$, then $\\mathfrak{q}$ is a parabolic subalgebra of $\\mathfrak{g}$.\n\n\nAs Fran points out in the comments below, my original translation was incorrect and had $\\mathfrak{n}$ nilpotent instead of consisting of nilpotent endomorphisms. Happily, for the case of the adjoint representation, one has Engel's theorem, which says that the the two notions agree.\n\nshare|improve this answer\nAlmost, but not quite. What Bourbaki has is Grothendieck's result which, for the adjoint representation, requires that each element of $\\xi\\in\\mathfrak{n}$ have $\\mathrm{ad}\\xi$ nilpotent on $\\mathfrak{g}$. This is a stronger condition than simply requiring $\\mathfrak{n}$ to be nilpotent---a distinction which got Lost in Translation! \u2013\u00a0 Fran Burstall Jun 22 '10 at 7:09\nBut isn't that just Engel's theorem? i.e., a Lie algebra $\\mathfrak{g}$ is nilpotent if and only if the endomorphisms $\\mathrm{ad}_x$ are nilpotent for every $x \\in \\mathfrak{g}$. \u2013\u00a0 Jos\u00e9 Figueroa-O'Farrill Jun 22 '10 at 11:19\nI'll edit the translation, though -- since as you point out it is not literal! \u2013\u00a0 Jos\u00e9 Figueroa-O'Farrill Jun 22 '10 at 11:20\nEngel's theorem isn't directly applicable here, since you have to look at the adjoint representation of the semisimple Lie algebra and not that of its nilpotent subalgebra. The Bourbaki theorem has to be applied carefully to an abstract Lie algebra and its Killing form. \u2013\u00a0 Jim Humphreys Jun 22 '10 at 11:56\nDisclaimer: I wrote that book when much younger to learn the subject better, but still haven't gotten to \"expert\" level. Writing a book is definitely the best way for the author to learn a subject in mathematics, though not invariably so for the reader. \u2013\u00a0 Jim Humphreys Jun 22 '10 at 22:22\n\nAs alluded to in the comments above, there is a rather old paper by Jacques Dixmier that contains a result in this direction. The reference is\n\nDixmier, Jacques. Polarisations dans les alg\u00e8bres de Lie. II. Bull. Soc. Math. France 104 (1976), no. 2, 145--164.\n\nThe result is Lemme 1.1, but the proof is attributed to P. Tauvel. The proof proceeds with a judicious application of the invariance of the Killing form and, for the nilpotency of $\\mathfrak{p}^{\\perp}$, Bourbaki's Groupes et alg\u00e8bres de Lie, Chapitre I, \u00a75, Lemme 3.\n\nHowever, there is a caveat: a slightly different notion of co-isotropy is assumed. Dixmier's notion of co-isotropy is to define the orthogonal complement $\\mathfrak{p}^f$ with respect to an anti-symmetric bilinear form $B_f$ derived from the Killing form.\n\nEdit: I claimed earlier that Dixmier's notion of co-isotropy implies that $\\mathfrak{p}^{\\perp}$ is contained in $\\mathfrak{p}$. This is not quite correct: you can prove, as is done there, that $\\mathfrak{p}^{\\perp} = [x,\\mathfrak{p}^f]$ is an ideal of $\\mathfrak{p}$ without using the assumption of co-isotropy that Dixmier made. The assumption kicks in only for the proof of nilpotency.\n\nshare|improve this answer\nThanks for the reference! I shall have a look at this. \u2013\u00a0 Fran Burstall Mar 22 '12 at 8:35\nYou're welcome! Your proof of the statement is also very interesting. \u2013\u00a0 Rongmin Lu Mar 23 '12 at 4:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/349839/markovs-inequality-question-about-random-variable\nText:\nTake the 2-minute tour \u00d7\n\na busy cat\n\nHow to do this problem, I am really confused. Also, what is the definition of Markov's inequality?\n\nshare|improve this question\n\n2 Answers 2\n\nMarkov inequality is the integrated version of the almost sure inequality $a\\mathbf 1_{X\\geqslant a}\\leqslant X$ hence the equality case happens if and only if $a\\mathbf 1_{X\\geqslant a}=X$ almost surely, that is, $X\\in\\{0,a\\}$ almost surely.\n\nshare|improve this answer\n\nLet $X$ be a non-negative random variable with a finite expectation $E(X)$. Markov's Inequality states that in that case, for any positive real number $a$, we have $$\\Pr(X\\ge a)\\le \\frac{E(X)}{a}.$$\n\nIn order to understand what that means, take an exponentially distributed random variable with density function $\\frac{1}{10}e^{-x/10}$ for $x\\ge 0$, and density $0$ elsewhere. Then the mean of $X$ is $10$.\n\nTake $a=100$. Markov's Inequality says that $$\\Pr(X\\ge 100)\\le \\frac{E(X)}{100}=\\frac{10}{100}.$$\n\nIt is straightforward to show that for this exponential, we have $\\Pr(X\\ge 100)=e^{-100/10}$. This is a number that is very close to $0$.\n\nNote that the Markov Inequality did not lie. The probability that $X\\ge 100$ really is $\\le \\frac{1}{10}$. But $e^{-10}$ is very much less than $\\frac{1}{10}$. So in this case the Markov Inequality produced a correct but lousy bound for the \"tail probability\" of the exponential.\n\nCould we produce a general but better bound. Yhe purpose of the exercise is to show that in a sense we cannot.\n\nThat is the price we pay for having a theorem that applies to all random variables that have a finite expectation. The bound produced by the Markov Inequality is often not at all sharp.\n\nThe question asks us, given a positive integer $a$, to produce a random variable $X=X_a$ such that $\\Pr(X\\ge a)=\\frac{E(X)}{a}$.\n\nWe can produce a very boring random variable that will do the job. Let $X=a$ with probability $1$. Then $\\Pr(X\\ge a)=1$. You should show that in this case, $\\frac{E(X)}{a}=1$. That will show that it is perfectly possible to have $\\Pr(X\\ge a)$ exactly equal to $\\frac{E(X)}{a}$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/68604/can-we-write-the-electromagnetic-potential-covariantly-in-terms-of-the-four-curr\nText:\nTake the 2-minute tour \u00d7\n\nIn the Lorenz gauge, we have a beautiful relation between the four-current and the four-potential:\n\n$$\\Box A^{\\alpha} = \\mu_0 J^{\\alpha}$$\n\nTo get $A$ in terms of $J$, however, we have to use a considerably uglier formula; or, at least, this is the formula presented in textbooks:\n\n$$A^{\\alpha}(t, \\mathbf{r}) = \\frac{\\mu_0}{4\\pi} \\int \\frac{J^{\\alpha}\\left(t - \\frac{1}{c}\\|\\mathbf{r} - \\mathbf{r}'\\|, \\mathbf{r}' \\right)}{\\|\\mathbf{r} - \\mathbf{r}'\\|} d^3\\mathbf{r}'$$\n\nThe first equation is evidently Lorentz covariant. The second one, on the other hand, doesn't look covariant at all. The integrand has some messy dependence on $(t, \\mathbf{r})$ and the integration goes over only the spatial dimensions.\n\nCan we rewrite the second equation in a covariant form? If not, then why not?\n\nshare|improve this question\nMore on retarded $4$-potential: physics.stackexchange.com/q/67533/2451 \u2013\u00a0 Qmechanic Jun 20 '13 at 6:47\nLorentz covariance of the solution is provided with the Lorentz covariance of the four-current and the Lorentz invariance of the retarded Green's function given in Lubosh's answer. \u2013\u00a0 Vladimir Kalitvianski Jun 20 '13 at 11:19\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nThe integral expression is Lorentz-covariant, too, and it may be made manifestly Lorentz-covariant, too.\n\nThe integral measure $\\int d^3 r' / ||\\vec r - \\vec r'||$ is equal to and may be rewritten as the four-dimensional integral with a delta-function (and step function) added: $$2\\int {d^4 x'} \\cdot \\delta[(x-x')^2]\\cdot \\theta(t-t') $$ It's understood that $J$ is substituted at the point $J(x')$.\n\nNote that the step function $\\theta$ (equal to one for positive arguments and zero otherwise) is Lorentz-covariant assuming that the points $x,x'$ aren't spacelike-separated (because the ordering of a cause and its effect is frame-independent), and they're not spacelike-separated as guaranteed by the delta-function that is only non-vanishing near/at the null separation of $x,x'$\n\nThe step function guarantees that the cause precedes its effect.\n\nThe argument of the delta-function is a Lorentz invariant, $(x-x')^2$ which means $(x-x')^\\mu(x-x')_\\mu$. The sign convention for the metric doesn't matter becase this invariant is the argument of an even function (delta-function).\n\nFinally, the equivalence of the two integrals may be shown by performing the integral over $t'$. The theta-function implies that we only integrate over the semi-infinite line $t'\\lt t$. The delta-function implies that the integral is only sensitive on the value of $J(t')$ where $c|t-t'| = |r-r'|$ where the delta-function vanishes.\n\nFinally, the delta-function also automatically generates the $1/|\\vec r - \\vec r'|$ factor because $$\\delta(y^2) = \\delta (y_0^2-|\\vec y|^2) = \\delta[(y_0+|\\vec y|)(y_0-|\\vec y|)]=\\dots $$ which is equal, because $\\delta(kX) = \\delta (X)/ |k|$, to $$\\dots = \\frac{\\delta(y_0-|\\vec y|)}{y_0+|\\vec y|}=\\frac{\\delta(y_0-|\\vec y|)}{2|\\vec y'|}$$ You see that the factor of two was needed, too.\n\nshare|improve this answer\nI think we also need an extra factor of $c$ in order to make the units work out. \u2013\u00a0 Brian Bi Jun 20 '13 at 7:20\nRight. I just wasn't sure which powers of $c$ I wanted to add to the definition of the 4-vector because this depends on some conventions, too. Adult physicists work in the $c=1$ units, anyway. \u2013\u00a0 Lubo\u0161 Motl Jun 20 '13 at 8:33\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/111066/is-there-any-techniques-for-solving-a-differential-equation-including-iterated-f/111073\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to solve this differential equation but I have no idea how.\n\n$f ' (x) = f( f( x ) ) $\n\nAlthough I don't think this differential equation is solvable, I'd like to know if there is any interesting approach on solving a differential equation of this kind, or at least a non-trivial solution of the equation.\n\nP.S. I don't think chain rule is useful for this\n\nshare|improve this question\nI think this is more suitable for math.stackexchange.com \u2013\u00a0 Beni Bogosel Oct 30 '12 at 10:49\nBeni, why do you say that? \u2013\u00a0 Vidit Nanda Oct 30 '12 at 11:57\n@Vel Nias I think math analysis questions are not welcome here. \u2013\u00a0 Anixx Nov 1 '12 at 11:03\n@Anixx. For the best of my knowledge, this claim is plain wrong. However, I agree that the remarks like \"this is homework\" or \"ask that on MSE\" that are not supported by any evidence that the person making them can solve the problem himself can be somewhat irritating... As to Beni's recommendation itself, MSE is not a bad site per se but it is just DROWNED in \"homeworks\" nowadays. MO and AoPS are much better choices for something nontrivial IMHO. \u2013\u00a0 fedja Nov 1 '12 at 12:33\nIs that a delay differential equation? \u2013\u00a0 Zsb\u00e1n Ambrus Nov 1 '12 at 14:03\nshow 2 more comments\n\n5 Answers\n\nup vote 14 down vote accepted\n\nNothing is new under the Moon...\n\n\nshare|improve this answer\nwow! Thank you very much! Did you solve it by yourself? You're amazing! \u2013\u00a0 frigen Nov 1 '12 at 3:17\nI see no solution following the link. \u2013\u00a0 Anixx Nov 1 '12 at 3:27\nMeaning you haven't scrolled down or you failed to understand what is written there? In the latter case you are welcome to ask questions. \u2013\u00a0 fedja Nov 1 '12 at 3:32\n@fedja I only see the supposed proofs of existence. Regarding the solution, you yourself wrote \"I have no hope for an explicit elementary formula for it.\" \u2013\u00a0 Anixx Nov 1 '12 at 3:34\nExistence and uniqueness of a one-parameter family of solutions, to be exact ;). Do you believe one can come with a formula? We can, probably, give it a shot and try to prove that the functions in question are not elementary but that is quite another story (and, most likely, quite a non-trivial one given that there exist formal elementary pseudo-solutions like the ones you mentioned). If you are interested in such a project, I can think of what might be the right approach here (but a bit later :)). \u2013\u00a0 fedja Nov 1 '12 at 3:46\nshow 3 more comments\n\nThere are two closed form solutions:\n\n$$\\displaystyle f_1(x) = e^{\\frac{\\pi}{3} (-1)^{1/6}} x^{\\frac{1}{2}+\\frac{i \\sqrt{3}}{2}}$$ $$\\displaystyle f_2(x) = e^{\\frac{\\pi}{3} (-1)^{11/6}} x^{\\frac{1}{2}+\\frac{i \\sqrt{3}}{2}}$$\n\nThe solution technique can be found in this paper.\n\nFor a general case, solution of the equation\n\n\nhas the form\n\n$$f(z)=\\beta z^\\gamma$$\n\nwhere $\\beta$ and $\\gamma$ should be obtained from the system\n\n$$\\gamma^m=\\gamma-1$$ $$\\beta^{\\gamma^{m-1}+...+\\gamma}=\\gamma$$\n\nIn your case $m=2$.\n\nshare|improve this answer\nSee also my answer regarding real solutions below. \u2013\u00a0 Anixx Nov 2 '12 at 10:36\nadd comment\n\nI don't know, but one answer is $f(x)=ax^c$ where $a=\\frac12(\\sqrt {3}+i){ e^{\\frac16\\pi\\sqrt {3}}}$ and $c=\\frac12+\\frac12i\\sqrt{3}$. Another is obtained by taking the complex conjugate of both $a$ and $b$.\n\nshare|improve this answer\nThe only unclear thing is where this function is defined. Note that complex powers of real numbers are complex and complex powers of complex numbers are branching like crazy... \u2013\u00a0 fedja Nov 1 '12 at 2:41\nadd comment\n\nFor what I know, the standard method is the Taylor series expansion at a fixed point, i.e. at a point $x=a$ such that $f(a)=a$.\n\nshare|improve this answer\nYes. +1 And I will give the expansion in another answer. \u2013\u00a0 Anixx Nov 1 '12 at 11:04\nadd comment\n\nAnd regarding real solutions to the question, Alex Gavrilov is completely correct. A Taylor expansion at fixed point $p$ gives us the real solution. Existence of this solution is proven in the paper which I already referenced from my another answer.\n\n$$f(z)=\\sum_{n=0}^\\infty \\frac{d_n (z-p)^n}{n!}$$\n\nwhere $d_n$ is defined as follows:\n\n$$d_0=p$$ $$d_{n+1}=\\sum _{k=0}^n d_k \\operatorname{B}_{n,k}(d_1,...,d_{n-k+1})$$\n\nwhere $B_{n,k}$ are the Bell polynomials\n\nThis gives the following starting coefficients:\n\n$$d_1=p^2$$ $$d_2=p^3+p^4$$ $$d_3=p^4 + 4 p^5 + p^6 + p^7$$ $$d_4=p^5 + 11 p^6 + 11 p^7 + 8 p^8 + 4 p^9 + p^{10} + p^{11}$$\n\n\nThe fixed point $p$ here serves as a parameter, which determines the family of solutions. According the linked theorem, the expansion should converge in the neighborhood of $p$ for $0 < |p| < 1 $ or $p$ being a Siegel number.\n\nshare|improve this answer\nAnixx, this becomes boring. Yeah, if $p$ is small enough, this has a chance to work (though I wonder how you prove that there are no other solutions). However, for large $p$, you have a polynomial with the leading term $p^N$ with $N\\approx k^2$ for the $k$'th coefficient. The miraculous cancellations can shave only something like $8^{N}$ off it for a typical $p$ (Remez). So, you are left with $(p/8)^{ck^2}$ which eats up the factorial and the geometrical progression for breakfast and happily flies to infinity by the lunchtime if $p$ is like $-20$. \u2013\u00a0 fedja Nov 2 '12 at 2:50\n@fedja yes, the proof in the linked paper requires p<1 or a Siegel number. I wiil add this to the answer. \u2013\u00a0 Anixx Nov 2 '12 at 10:25\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/24517/dedekind-esque-sums\nText:\nTake the 2-minute tour \u00d7\n\nGiven real numbers $a, b$, let $f(x)$ be the integer nearest to $ax+b$, let $S_n$ be $\\sum_{k=0}^{n} (n-2k) f(n-k) = n f(n) + (n-2) f(n-1) + (n-4) f(n-2) + ... - (n-2) f(1) - n f(0)$, and let $s_n = an(n+1)(n+2)/6$ (the value you would get if you replaced each term $f(x)$ in the sum by the associated $x$). I believe (with no especially good evidence) that for a set of real numbers $a$ of full measure, and for all real numbers $b$, $|S_n - s_n|$ is $O(n)$. Is this true?\n\nThis is an updated version of the question \"sums involving the nearest-integer function\" that I posted a couple of weeks ago. One person who replied to that post appeared to be claiming that if $a$ is any irrational number and $b = 0$ then $|(S_n - s_n)/n|$ is unbounded. Can anyone provide a proof, or steer me towards a proof in the on-line literature? (I tried $a = (1+\\sqrt{5})/2$ and $b = 0$, and I found that $\\max_{n \\leq N} |(S_n - s_n)/n|$ takes on the successive values 0.59, 0.81, 0.81, and 1.10 for $N = 10,10^2,10^3,$ and $10^4$.)\n\nWhen $a$ is rational, it is easy to show that $|S_n - s_n|$ is $O(n)$. In this case, are there good bounds of the form $Cn$ for explicit constants $C$ (presumably obtained from the continued fraction expansion of $a$)?\n\nshare|improve this question\nWhat happens if you rewrite $f(x)$ as $[ax+b+(1/2)]$, which is $ax+b+(1/2)-\\{ax+b+(1/2)\\}$? You get a main term and then a term involving a sum with fractional parts, which may be in the literature. \u2013\u00a0 Gerry Myerson May 13 '10 at 23:54\nFurther to my comment, you get $S_n-s_n=-\\sum_{r=0}^n(2r-n)\\{ar+b'\\}$ where $b'=b+(1/2)$. I suspect this is in the discrepancy literature. \u2013\u00a0 Gerry Myerson May 14 '10 at 1:36\nYou may find what you need among the answers at mathoverflow.net/questions/17132/\u2026 \u2013\u00a0 Gerry Myerson May 14 '10 at 23:30\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/236687/finding-the-volume-of-a-cylinder-without-using-pi?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nGiven a cylinder's radius and height, $a$ and $z$, and given that $z\\ll a$, what is it's volume without using $\\pi$?\n\nI was thinking that I could integrate to get the cylinder's circumference, and then divide this by the diameter to get $\\pi$, but I haven't tried it yet. Is this correct?\n\nshare|improve this question\nJust out of curiosity, why do you want to avoid $\\pi$? \u2013\u00a0 EuYu Nov 13 '12 at 20:50\nYou need $\\pi$ to get the cylinder's circumference. \u2013\u00a0 timvermeulen Nov 13 '12 at 20:52\nIt is simply a mind-bender, a challenging question designed to make me think. However, every solution I've tried so far has not worked. \u2013\u00a0 Stan Harvey Nov 13 '12 at 20:53\nIf the area of the base is $A$, the volume is $zA$. Or if the circumference is $C$ the volume is $aCz/2$ \u2013\u00a0 Ross Millikan Nov 13 '12 at 21:29\nYou could always take the Archimedes route: place it in a bowl full of water (or a measuring jug) and measure the volume of liquid displaced. \u2013\u00a0 Mark Bennet Nov 13 '12 at 21:51\nshow 1 more comment\n\n4 Answers\n\nIn order to exactly find the volume, you must use $\\pi$, as volume of a cylinder is given by\n\n$$V = \\pi a^2 z$$\n\nshare|improve this answer\nOver 6k now ${}$ :D \u2013\u00a0 amWhy Nov 27 '12 at 2:07\n@amWhy Haha, thank you! \u2013\u00a0 Argon Nov 27 '12 at 2:50\nadd comment\n\nThe area of the base is $\\dfrac{\\tau a^2}{2}$, so the volume is $\\dfrac{\\tau a^2 z}{2}$.\n\nshare|improve this answer\nHaha, I know about $\\tau$! It does seem like the easy way out, though... \u2013\u00a0 Stan Harvey Nov 13 '12 at 20:55\nI think $\\tau$ is cheating a bit, because $\\tau = 2\\pi$! \u2013\u00a0 Argon Nov 13 '12 at 20:56\nIt reminds me of a cure for hiccups that I was told about as a child: Run three times around the house without thinking of wolves. It is very important not to think of wolves. If you do, the hiccups will continue. Anyway, to get more mathematical, just use the first positive zero of the sine function. No \u03c0 needed. \u2013\u00a0 Harald Hanche-Olsen Nov 13 '12 at 21:16\nadd comment\n\nWhy don't you inscribe the cylinder into a prism whose base is a regular polygon and has $h=z$, and then compute its volume as a function of $n$? The resulting expression does not involve $\\pi$ and if you take the limit when $n$ goes to $\\infty$ you get the volume of the cylinder. The tricky part is to express the apothema in terms of $n$, so you can check that the limit is actually finite, but it can be done.\n\nTo me, this sounds like a typical application of the density of $\\mathbb{Q}$ in $\\mathbb{R}$.\n\nshare|improve this answer\nadd comment\n\nSure you can without pi. Remove the top of the cylinder. Fill it with fine-grained sand. Then pour the sand into a rectangular box, and measure how far it comes up. Of course, it will be an estimate, but not a bad one. (Get an even finer grade sand.) You can do the same by unscrewing the top of a sphere.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/35054/help-on-unit-conversion-problem/35061\nText:\nTake the 2-minute tour \u00d7\n\nThis is a problem from school. I will show my attempt.\n\nThe question:\n\n\"The gas constant for dry air R is 287 $\\frac{m^2}{s^2*K}$. Assuming the temperature is 330 K and the pressure is 1050 hPa, what is the atmospheric density.\"\n\nThe professor said DO NOT produce an answer by finding a formula, but to use the magic of unit conversion to try to solve things.\n\nI know density is measured in kg/m^3 or thereabouts so I tried the following:\n\n1050 hPA = 105, 000 Pa\n\n1 Pa = 1 kg/m*s^2\n\n105,000 $\\frac{kg}{m*s^2}$ * 330 K * 287 $\\frac{m^2}{s^2*K}$.\n\nThis cancels some units... but not enough...in fact it cancels just K, so far as I understand, far from what I need for my density unit.\n\nAny ideas on what Im doing foolishly here?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nthe line you wrote\n\n\nhas to read in fact\n\n$\\frac{105,000 \\frac{kg}{m*s^2} }{ 330 K * 287 \\frac{m^2}{s^2*K}} = 1.11 \\frac{kg}{m^3}$.\n\nThis comes from the gas law\n\n$p=\\rho \\ R \\ T $\n\nwhere $p$ is the air pressure and $\\rho$ is the air density. Solving for $\\rho$ you get\n\n$\\rho =\\frac{p}{R T} $\n\nfrom which the numerical solution follows.\n\nshare|improve this answer\nThank you - this is excellent and uses what I already did to show me how to arrive to a solution for problems like these! \u2013\u00a0 Anne Aug 28 '12 at 0:28\nWelcome! You started well but you have to write more carefully the units. Now and then write also the formulas you are going to use, even if they look very simple. This helps to cross-check the numerical calculation in each step. Longer multiplications with unit conversions come very quickly out of control (you are not the only one!) \u2013\u00a0 Lupercus Aug 28 '12 at 0:39\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/87914/linear-mmse-estimate-of-mmse-estimator\nText:\nTake the 2-minute tour \u00d7\n\nThis question is prompted by a recent discussion about the relationship between conditional expectation and covariance.\n\nSuppose that $X$ and $Y$ are zero-mean unit-variance random variables with covariance (and correlation coefficient) $\\rho$. The minimum-mean-square error (MMSE) estimator of $Y$ given $X$ is the random variable $g(X)$ that minimizes $E[(Y-g(X))^2]$, and as is well known, $$g(X) = E[Y \\mid X] ~\\text{minimizes}~E[(Y-g(X))^2]$$ It is also well known that $E[g(X)] = E[E[Y\\mid X]] = E[Y] = 0$. In general, $g(X)$ is a nonlinear function. On the other hand, if the estimator is restricted to being of the form $\\hat{Y} = aX + b$ where $a$ and $b$ are real numbers, then the linear MMSE estimator of $Y$ given $X$ is $\\hat{Y} = \\rho X$, that is, $$a = \\rho, ~ b = 0, ~\\text{minimizes}~E[(Y-aX-b)^2].$$ The linear MMSE estimator $\\rho X$ has a mean-square-error $E[(Y-\\rho X)^2] = 1 - \\rho^2$ and so the mean-square-error of the MMSE estimator $g(X)$ can be no larger:\n$$E[(Y-g(X))^2] \\leq 1 - \\rho^2.$$\n\nA simplified version of the question in the previous discussion is: if $g(\\cdot)$ is a decreasing function of its argument, show that $\\rho$ is nonpositive.\n\nMy question is: what is the linear MMSE estimate of $g(X) = E[Y \\mid X]$ given $X$? That is, what choice of real numbers $c$ and $d$ minimizes $E[(g(X) - cX - d)^2]$? Since $g(X)$ and $X$ both have zero mean and $X$ has unit variance, standard linear MMSE estimator theory gives that $d = 0$ and $$c = \\frac{\\text{cov}(g(X),X)}{\\text{var}(X)} = \\text{cov}(g(X),X) = E[Xg(X)]$$ which I think might work out to be $\\rho$, but I am not sure about this. Any suggestions on how to proceed further would be appreciated.\n\nshare|improve this question\nYour final result is correct: for simple least-squares regression of $Y$ on $X$, the line passes through the point $(\\mu_X,\\mu_Y)$ with gradient $\\rho \\dfrac{\\sigma_Y}{\\sigma_X} = \\dfrac{\\text{cov}(X,Y)}{\\sigma_X^2}$. So here it is just $\\rho$. \u2013\u00a0 Henry Dec 3 '11 at 3:36\nI am somewhat uncomfortable with your language, since I fear that this way of using the word \"linear\" might feed into the popular misunderstanding that the reason why linear regression in called linear regression is that one is fitting a line. People who think that then find it confusing when a statistician insists that one is doing linear regression when one fits a parabola or a sine wave, etc. \u2013\u00a0 Michael Hardy Dec 3 '11 at 5:38\n@MichaelHardy I thought about editing the question to say something like \"straight-line MMSE estimation\" instead of \"linear MMSE estimation\" but decided against it because linear MMSE estimation is reasonably well-established, at least in the engineering literature: Google provides over $900,000$ hits. But, thanks for your answer which I am accepting. I was able to show $E[Xg(X)] = \\rho$ for discrete and for jointly continuous random variables but wanted a proof that did not rely on special cases, and your answer gave me exactly what I wanted. \u2013\u00a0 Dilip Sarwate Dec 4 '11 at 3:56\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nYour conjecture is correct. By the law of total expectation we have $$ \\begin{align} E(X(Y-g(X)) & = E(\\;E(X(Y-g(X))\\mid X)\\;) \\\\ \\\\ & = E(\\; E(XY\\mid X) - E(Xg(X)\\mid X)\\;) \\\\ \\\\ & = E(\\; XE(Y\\mid X) - Xg(X) \\;) \\\\ \\\\ & = E( Xg(X) - Xg(X)) = 0. \\end{align} $$ Therefore $$ E(XY) = E(Xg(X)). $$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54889.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nLines Intersecting within a Polygon\n\nDate: 10/24/96 at 18:12:24\nFrom: Keith Loveland\nSubject: geometry\n\nA fellow math teacher asked me this the other day:\n\nGiven an n-sided regular polygon with each vertex connected to each \nother vertex by a straight line segment, how do you determine the \nnumber of intersection points within the polygon? I tried n = 3 \nthrough n = 8, looked for a pattern, and noticed some things but \nnothing definitive. I plotted these points with the intersection \npoints as a function of n and tried curve fitting, but couldn't get an \nexact fit. Do you know a rule for this? Is there an odd and even set \nof rules?\n\nThanks for any help you're able to give me,\nKeith Loveland \n\nDate: 10/24/96 at 20:48:14\nFrom: Doctor Tom\nSubject: Re: geometry\n\nHi Keith,\n\nWell, this isn't a complete answer, but it may help some. I can solve \nthe problem if the points are \"unevenly\" spaced around the polygon, \nbut not if they're evenly spaced.\n\nWhat I mean is this - I can count the number of times pairs of lines \ncross each other, but the simplest case where this goes bad is the \nperfect hexagon. Three lines go through the center, and if those are \ncalled lines A, B, and C, then my method counts AB, BC, and CA as \nthree points when it probably should be counted as one. Notice that \nif the vertices are moved just a little, instead of hitting at a \nsingle point, there would be a tiny triangle with 3 intersections.\n\nAs the number of lines goes up, the number of these multiple\nintersections increases, and in a funny way that has to do with the \nprime factorization of the numbers.  My formula should work exactly \nfor all prime-sided polygons, for example.\n\nHere's how I did it:\n\nFor a triangle, there are no intersections.\n\nFor a square connecting points 1,2,3,4, break it into two parts: those \ninvolving a line from 1, and those not involving a line from 1.\n\nThose not involving a line from 1 include all the crossings made by \nthe triangle 234: zero to be exact.\n\nThose involving a line from 1 include 13 crossing 24, or one \nintersection.  So for a square, there is 1 total.\n\nI'll jump up a bit so you can see more easily, I think, what's going\non.  Consider a 7-sided polygon 1,2,3,4,5,6,7.\n\nSuppose you've got the crossing number for the 6 sided 2,3,4,5,6,7,\nand you just need to count the number of lines involving point 1.\n\nIf 1 connects to 4, those crossing it must connect 2 or 3 with 5, 6, \nor 7.  If 1 connects to 3, those crossing it must connect 2 with 4, 5, \n6, or 7, and so on.  If 1 connects to 2, nothing crosses it.  So \nconsider all the lines starting from 1:\n\n   1-2:  nothing               0   ways\n   1-3:  {2} to {4,5,6,7}      1x4 ways\n   1-4:  {2,3} to {5,6,7}      2x3 ways\n   1-5:  {2,3,4} to {6,7}      3x2 ways\n   1-6:  {2,3,4,5} to {7}      4x1 ways\n   1-7:  nothing               0   ways\n\nSo the answer is whatever your answer for 6 was plus 1x4+2x3+3x2+4x1.\n\nSo here's the full method, where f(n) is the number of ways to do this \nwith n points:\n\n   f(3) = 0\n   f(4) = f(3) + 1x1 = 0 + 1 = 1\n   f(5) = f(4) + 1x2 + 2x1 = 1 + 2 + 2 = 5\n   f(6) = f(5) + 1x3 + 2x2 + 3x1 = 5 + 3 + 4 + 3 = 15\n   f(7) = f(6) + 1x4 + 2x3 + 3x2 + 4x1 = 15 + 4 + 6 + 6 + 4 = 35\n\net cetera.\n\nMy intuition tells me that these numbers will satisfy a fourth-power \nequation (I am 99% sure of this for reasons that I can't explain).\n\nSo if you work out a few more terms for f(8), f(9), and so on, and \nthen imagine that the solution must look like this:\n\n   f(n) = A*n^4 + B*n^3 + C*n^2 + D*n + E\n\nPlug in n = 3, 4, 5, 6, 7, and consider A, B, C, D, and E to be \nunknowns, you'll get 5 equations in 5 unknowns, and you can work out \nA, B, C, D, and E.\n\nBut as I said, I have no idea how to take into account the multiple \n\nGood luck.\n\n-Doctor Tom,  The Math Forum\nAssociated Topics:\nHigh School Geometry\nHigh School Triangles and Other Polygons\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://mathoverflow.net/questions/101140/a-question-about-collections-of-sets\nText:\nTake the tour \u00d7\n\nIs there anything known about the following problem? Which (sub)field to look into for questions of this flavor?\n\nConsider a collection $F$ of subsets of $[n]$, excluding the empty set, with the property that every element of $[n]$ is contained in exactly $n$ sets. The same set might appear more than once in $F$ (The number of sets in $F$ is thus between $n$ and $n^2$ and the sum of cardinalities is $n^2$).\n\nIs there a sequence (possibly with repetitions) of the numbers $1 \\dots n$, of length at most $n^\\alpha$, such that each set appears somewhere in the sequence in at most $n^\\beta$ contiguous blocks.\n\nHere's a small example: F = { {1,2}, {1,3}, {2,3}, {1,2,3} }. In the sequence (1,2,3) the set {1,3} can be mapped to two blocks only. In the sequence (1,2,3,1) all sets can be mapped to a single block.\n\n$\\alpha = 1, \\beta=1$ works if we use any permutation of the numbers.\n\n$\\alpha = 2, \\beta =0$ works if we concatenate all sets of F.\n\nCan we get something \"in between\" ?\n\nEDIT: as an important special case, F could consist of n \"partitions\" of [n].\n\nshare|improve this question\nUnfortunately, I do not understand the important special case when $F$ consists of $n$ partitions of $[n] := \\{ 1,2,\\dots,n \\}$. If $F$ is to have size $n$, then necessarily $F$ must consist of $n$-many copies of $\\{ 1,2,\\dots,n \\}$. Right? \u2013\u00a0 Asher M. Kach Jul 2 '12 at 23:08\nYes, if $F$ has size $n$, then $F$ just contains $n$ copies of $[n]$, in other words, $F$ contains $n$ copies of the partition, which is just the whole set itself. In this sense, it contains $n$ partitions of $[n]$ in this case too. For example, for n=3, $F$ could be {{1,2,3},{1,2,3},{1,2,3}} or {{1},{2,3},{1,2},{3},{1,2,3}} or {{1},{2},{3},{1},{2},{3},{1},{2},{3}}, etc. \u2013\u00a0 Laszlo Kozma Jul 3 '12 at 8:59\nBut $F$ is not necessarily of size $n$, it is just $\\geq n$ and $\\leq n^2$. \u2013\u00a0 Laszlo Kozma Jul 3 '12 at 9:01\nadd comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/34814/how-to-release-mathematica-from-the-pre-holdallcomplete-lock/34815\nText:\nTake the tour \u00d7\n\nNot sure if posted before, but I'm asking this question from a Mathematica fellow user who tried to load expressions, whose problem soon turned into a prison break game featuring the following code.\n\nSetAttributes[hold, HoldAllComplete];\nGetOut /: hold[GetOut] := Unset[$Pre];\n\n$Pre = hold;\n\nAfter executing this code, all subsequent evaluations are hold, including the GetOut \"key\" and the reset expression.\n\n$Pre = .\n\nAre there any ways to unhold subsequent evaluations, in addition to rebooting Mathematica?\n\nshare|improve this question\nAre you looking for a good solution, or the user's physical integrity should be preserved? \u2013\u00a0 belisarius Oct 26 at 2:36\n@belisarius Definitely both, if possible. I don't feel like hurting executed evaluations preceeding the lock. \u2013\u00a0 FrenzY DT. Oct 26 at 2:39\nGood question. I've always just restarted my kernel when I bungle up $Pre or $PreRead, since I didn't think there was any other way around. Would be interesting if there was... \u2013\u00a0 rm -rf Oct 26 at 2:46\n@rm-rf It's interesting that once we change HoldAllComplete to Hold, both the original attempts work. \u2013\u00a0 FrenzY DT. Oct 26 at 2:49\nOoh... I have a way out. Writing an answer. \u2013\u00a0 rm -rf Oct 26 at 2:52\nadd comment\n\n1 Answer\n\nup vote 5 down vote accepted\n\nThere's nothing that can break out of a HoldAllComplete as long as it has to pass through the kernel. But what if we had a way to bypass the kernel? Hmmm... buttons!\n\nI suggest using the following button as an escape mechanism instead of your GetOut:\n\nButton[\"Clear $Pre\", Unset[$Pre]]\n\nWith this, you can clear $Pre by simply clicking it \u2014 even with the HoldAllComplete. It works because the evaluation is done via the Front End and not the kernel, thus bypassing $Pre.\n\nshare|improve this answer\nHow does the Button function get evaluated? Is it through the Front End? \u2013\u00a0 FrenzY DT. Oct 26 at 4:34\n@FrenzYDT. Read the last paragraph? \u2013\u00a0 Sjoerd C. de Vries Oct 26 at 6:45\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/40808/velocity-of-electron-in-electrostatic-field-does-radiation-matter\nText:\nTake the 2-minute tour \u00d7\n\nThere's a voltage difference of 1000 Volts between two points 2 meters apart. An electron starts at the point of lower potential and is left to travel alone in a straight line until it reaches the other point. Question: What speed does the electron have when it reaches the second point?\n\nMy concern is whether the retardation effects of the radiation of the electron are important here. I tried doing it using the relativistic formulae for the kinetic energy and got\n\n\nwhere $m_e$ is the electron mass, $c$ the speed of light, $V$ the voltage difference between the two points, and $v$ the final speed of the electron.\n\nThis is not a homework exercise. I am just curious as to the effects of radiation.\n\nEdit: What if the potential difference was 10 000 Volts in 2 meters? What if it was 1 000 000 Volts in 2 meters?\n\nshare|improve this question\nIn principle yes, there is some loss to Bremsstrahlung, but...half a kilovolt per meter over two meters is chump change. The electron is still mostly non-relativistic (around 2% of c) and the acceleration is quite modest (by accelerator physics standards). For comparison, high gradients are measured in MV/m. \u2013\u00a0 dmckee Oct 15 '12 at 2:44\nBy the way, you'll find the math easier if you work in $c = 1$ units. Then $m_e \\approx 511\\text{ keV}$, and the above claim about the velocity becomes reasonably clear. \u2013\u00a0 dmckee Oct 15 '12 at 2:47\n@dmckee I added two additional cases. So at about a million Volts per meter is that the retardation effects of radiation start to be felt? \u2013\u00a0 becko Oct 15 '12 at 3:36\nadd comment\n\n1 Answer\n\nup vote 1 down vote accepted\n\nYou need to distinguish between retardation and radiation.\n\nRetardation usual refers to the effect of limited propogation seeds on interactions. That is we replace $$a_g = G\\frac{M}{r^2}$$ with $$a_{g,\\mathrm{ret}} = G\\frac{M}{r(t - \\frac{r}{c})^2} .$$\n\nThis only matters if\n\n  1. The ration of velocities in the system to propogation speeds are significant, or\n  2. The effect is constantly in one direction\n\nin other cases (as in retarded Newtonian gravity in the solar system) it simply results in a constant correction to some effective parameter of the system (reduced mass in our example).\n\nIn your case, you have a static field which means that $\\mathcal{E}(t) = \\mathcal{E}$ and the problem reduced to original case. There is no effect due to retardation.\n\nI'm taking \"radiation\" to mean the loss of energy by accelerating charges known as Bremsstrahlung.\n\nEverything you really want to know is in the Wikipedia link. You propose a linear acceleration case, so we can use $$ P_{a\\parallel v} = \\frac{q^2 a^2 E^6}{6 \\pi^2 \\epsilon_0 m^6 c^{15}}$$ for the power lost to radiation. Here I have used $E = \\gamma m c^2$ for the total energy of the electron (including it's mass).\n\nAs I noted above, the energies involved are such that the electron remains largely non-relativistic, so we'll stick to the Physics 101 for of the kinematic equations. The average velocity is about 1% of the speed of light, so the time to cover the distance is about 600 ns, and the acceleration is $a = \\frac{0.02 * 3\\times10^8\\text{ m/s}}{6\\times10^{-7}\\text{ s}} = 10^{13}\\text{ m/s}^2$.\n\nBecause the electron's energy only changes by about 2% over the whole range I'm not going to bother with a proper integration of the power, and instead just multiply (I make an error on order of 6% by doing so). The energy lost to radiation is about $$E_l = P_{a \\parallel v} t = \\frac{q^2 a^2 \\left(1.01*mc^2\\right)^6}{6 \\pi^2 \\epsilon_0 m^6 c^{15}} t = \\left(1.01\\right)^6 \\frac{q^2 a^2}{6 \\pi^2 \\epsilon_0 c^3} t$$ and (after furiously checking the units) I just start plugging in\n\n  \u2022 $q = 1.6 \\times 10^{-16}\\text{ C}$\n  \u2022 $\\epsilon_0 = 8.8 \\times 10^{-12} \\text{ m}^{-3} \\text{ kg}^{-1} \\text{ s}^2 \\text{ C}^2$\n  \u2022 $c = 3\\times10^8\\text{ m/s}$\n  \u2022 $t = 6\\times10^{-6}\\text{ s}$\n\n$$E_l \\approx 1.2\\times 10^{-28}\\text{ J} = 7 \\times 10^{-10}\\text{ eV}$$.\n\nSo the losses are trivial.\n\nThis isn't surprising since a typical CRT runs at 10+ keV over a few centimeters and doesn't spew lots of x-rays around the room.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/180974/explanation-of-why-the-height-of-a-binary-tree-thetalgn\nText:\nTake the 2-minute tour \u00d7\n\nFrom Heap Sort chapter of Introduction to algorithms :\n\nSince a heap of n elements is based on a complete binary tree , its height is $\\theta({lg}(n))$.\n\nI know this is correct but how can this be proved ?\n\nshare|improve this question\nHint: prove that a complete binary tree of hight $h$ has $2^h$ elements \u2013\u00a0 pritam Aug 10 '12 at 9:03\n@pritam thats a pretty good way of coming to this conclusion . Can you throw an answer so that I can accept it as the accepted answer . \u2013\u00a0 Geek Aug 10 '12 at 9:11\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nIf we write down the series counting the number of elements at each level of the tree, then we get $$ \\mbox{Number of elements} = n = 1 + 2 + 4 + 8 + ... + k \\tag{1}$$ That is, at the first level, there is only one node, the root of the tree. At the second level are the root's two children. At the third, each of those two children's two children (making the total four at the third level). And so on until the last level, in which there are $k$ leaves of the tree.\n\n$n$ is a finite geometric series whose first element is $a = 1$, ratio is $r = 2$. Using the formula for a geometric series, we get: $$ n = \\frac{a(1 - r^i)}{1 - r} = 2^i - 1 $$ We seek $i$, which is the number of elements in the sequence given by $(1)$: $$ n = 2^i - 1 \\Rightarrow i = \\lceil\\lg(n + 1)\\rceil $$\n\nThis means there are $\\lceil\\lg(n + 1)\\rceil$ levels in the tree, or $\\lceil\\lg(n + 1)\\rceil$ terms in the series in $(1)$. The ceiling is required because nodes taking up part of a level warrant an extra count to the number of levels. We're interested in the height of the tree, not the number of levels. A keen observation will reveal that the height $h$ of a complete binary tree is one less than the number of levels. In other words, the height is the number of plus signs in $(1)$. So the height $h$ of a complete binary tree in terms of its $n$ elements is $$ h(n) = \\lceil\\lg(n + 1)\\rceil - 1 \\tag{2}$$\n\nTo show that $h(n) \\in \\Theta(\\lg(n))$, first note the ceiling function will not affect the asymptotic behavior of $h(n)$, so the rounding up will be ignored for the rest of the discussion.\n\n$h(n)$ is in $\\Theta(\\lg(n))$ if $$ \\exists n_0 \\in \\mathbb{N},\\; c_1, c_2 \\in \\mathbb{R},\\; c_1, c_2 > 0 : c_1 \\lg(n) \\le \\lg(n + 1) - 1 \\le c_2 \\lg(n), \\quad \\forall n \\ge n_0 \\tag{3}$$\n\nFor the lower bound, let $c_1 = \\frac{1}{2}$. Then we have: $$\\frac{1}{2}\\lg(n) = \\lg(\\sqrt{n}) \\le \\lg(n + 1) - 1, \\quad \\forall n \\ge 1 \\tag{4}$$ In $(4)$, $n_0 = 1$.\n\nFor the upper bound, let $c_2 = 2$. We have: $$2\\lg(n) = \\lg(n^2) \\ge \\lg(n + 1) - 1, \\quad \\forall n \\ge 1 \\tag{5}$$ where $n_0 = 1$ here too.\n\nSo, for $c_1 = \\frac{1}{2}$, $c_2 = 2$, and $n_0 = 1$, $(3)$ holds. Therefore $h(n) \\in \\Theta(\\lg(n))$.\n\nshare|improve this answer\n@ladadhini I changes my accepted answer as it has proved it rigorously . Can you explain a little bit more why the ceiling is required ?I guess the ceiling is required when it is near complete binary tree and not a complete binary tree ? Thanks . \u2013\u00a0 Geek Aug 10 '12 at 11:31\n@Geek: Yes, you're on the right track, though a complete binary tree, despite its name, permits the last level to not be \"full.\" The reason we must round up is the same reason we round up for the following situation: if a school bus has a capacity of 30 children, how many buses are need to transport 100 children? \u2013\u00a0 ladaghini Aug 10 '12 at 12:54\nI have posted another question related to this here . can you try to clear my doubts on that too ? \u2013\u00a0 Geek Aug 10 '12 at 13:03\nadd comment\n\nUsing induction one can prove that a complete binary tree of hight $h$ has $2^h-1$ elements. So you have $n=2^h-1$, i.e. $h=\\lg (n+1)=\\theta(\\lg n)$.\n\nshare|improve this answer\nShouldn't that be $2^h-1$? \u2013\u00a0 Mike Aug 10 '12 at 9:17\n@Mike the number of internal nodes in a complete binary tree is 2^h-1 . \u2013\u00a0 Geek Aug 10 '12 at 9:21\n@Mike Yeah you are correct, actually i was thiking $\\theta(2^h)$; anyway corrected it \u2013\u00a0 pritam Aug 10 '12 at 9:27\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/105217/how-to-easy-calculate-card-of-union-of-sets/105218\nText:\nTake the 2-minute tour \u00d7\n\nFor example I have sets\n\n\nfor some reason I can't do |AUBUC|, only what i can do is calculate |A|, |B|, |C|.\n\nHow do I do to calculate |AUBUC| in this situation? is there any algorithm?\n\nshare|improve this question\nI am not sure whether this question better fits MO, or MSE. \u2013\u00a0 Ilya Aug 22 '12 at 9:44\nWithout further information, you can't do it. \u2013\u00a0 Yemon Choi Aug 22 '12 at 10:24\nMark, your question isn't a good fit for this site. You'd be better off trying one of the other math sites listed in the FAQ. Good luck. \u2013\u00a0 Tom Leinster Aug 22 '12 at 10:42\nthanks all, Actually it is computer-science relative question \u2013\u00a0 mark Aug 23 '12 at 3:00\nThis is an enumerative combinatorics question, even if it originates in computer science. (Many enumerative combinatorics do arise in computer science.) To learn more about this sort of thing, I'd suggest reading an enumerative combinatorics textbook. \u2013\u00a0 Patricia Hersh Aug 23 '12 at 12:47\nshow 1 more comment\n\nclosed as too localized by Yemon Choi, Tom Leinster, Felipe Voloch, Asaf Karagila, quid Aug 22 '12 at 11:34\n\n\n2 Answers\n\nTo extend the last sentence of Ilya's reply have a look in Wikipedia for the inclusion-exclusion principle which accounts for the size of the intersections by the formula\n\n$$ \\left| A \\cup B \\cup C \\right | = \\left| A \\right| + \\left| B \\right| + \\left| C \\right| - \\left| A \\cap B\\right| - \\left| B \\cap C \\right| - \\left| A \\cap C \\right| + \\left| A \\cap B \\cap C\\right|. $$\n\nThere is an obvious generalisation to an alternating sum over the cardinalities of all the $k$-fold intersections in the case of $n$ sets. Of course if you don't know the cardinalities of the intersections this is not so useful!\n\nshare|improve this answer\nyes, I agree with you, the info is not enough so that it's nearly impossible to calculate the result. \u2013\u00a0 mark Aug 23 '12 at 3:02\n@Michael: Sorry I couldn't resist correcting \"principal\" to \"principle\". \u2013\u00a0 Mark Grant Aug 23 '12 at 17:48\n@Mark. Ah thanks for fixing that. Too many principal bundles in my past perhaps ? \u2013\u00a0 Michael Murray Aug 24 '12 at 10:09\n@Michael: Better that than a lack of principles! \u2013\u00a0 Mark Grant Aug 24 '12 at 20:43\nadd comment\n\nI do not know, how much is it related to set-theory, but from the measure-theoretical point of view, $|A| = \\mu(A)$ where $\\mu$ is a counting measure, i.e. the one which assigns the unit weight to each element of the set. In general, if you have a finite number of sets $A_1,\\dots,A_n$ then $$ \\mu(A_1\\cup\\dots\\cup A_n)\\leq\\sum\\limits_{i=1}^n\\mu( A_i) $$ which is quite a trivial fact in your case. The strict inequality only holds when the sets are not disjoint, i.e. $A_i\\cap A_j$ is not empty for some $i\\neq j$. In that case, you have also to account for how many element are in the intersection - and to be able to compute $\\mu(A_1\\cap A_2)$, $\\mu(A_1\\cap A_2\\cap A_3)$ etc.\n\nshare|improve this answer\nadd comment"}
{"text": "Retrieved from http://math.stackexchange.com/questions/406139/how-many-sets-can-we-get-by-taking-interiors-and-closures\nText:\nTake the 2-minute tour \u00d7\n\nI'm having following problem. I'm looking for the maximum number of different sets that we can generate by one set $B \\subseteq \\mathbb{R}$ by taking a finite amount of closures and interiors. For example $\\{0\\}$ generates the sets $\\{0\\}$ and $\\emptyset$. At first I thought the answer was 3 (we can only generate B, the closure of B and the interior of B) because I thought $\\overline{B^\\circ}=\\overline{B}$ and $\\overline{B}^\\circ=B^\\circ$. But then I looked at the example $B=\\mathbb{Q}$ and found that $\\overline{\\mathbb{Q}}^\\circ=\\mathbb{R}^\\circ=\\mathbb{R}\\neq\\emptyset=\\mathbb{Q}^\\circ$.\nThis is not what I would expect and I clearly need another method te search that maximum.\n\nshare|improve this question\nNote that both these operations are idempotent, so the only way to achieve actual results is to intertwine them. \u2013\u00a0 Asaf Karagila May 29 '13 at 21:52\nThis isn't exactly what you're looking for, but it is related (and interesting): Kuratowski's Problem \u2013\u00a0 Jared May 29 '13 at 21:55\nAs suggested by @Jared's link, have a look at closure and interior repeatedly applied to $B=(0,1)\\cup(1,2)\\cup \\{3\\}\\cup([4,5]\\cap \\mathbb Q)$. \u2013\u00a0 Hagen von Eitzen May 29 '13 at 21:59\n@Jared: indeed related to my question and very interessenting. I'm suprised that the answer is 14 (I would absolutely not guess that answer). \u2013\u00a0 mvcouwen May 29 '13 at 22:03\nNote that as the Wikipedia article on the 14 set problem says, that $S^\\circ = \\overline{S^c}^c$ (or $iS = ckcS$), so it seems that the problem reduces to the closure-complement question. \u2013\u00a0 kahen May 29 '13 at 22:32\nshow 4 more comments\n\n1 Answer\n\nTrying with the set $B=(0,1)\\cup(1,2)\\cup\\{3\\}\\cup([4,5]\\cap\\mathbb{Q}$ (as suggested by Hagen von Eitzen) gives me that the answer has to be at least 8.\nTaking first the closure followed by the interior followed by the closure and so on, gives me 4 extra possibilities.\nStarting with the interior instead gives me 3 more possibilities.\nIncluding the set I have started with, I have 8 possibilities. The only question that is left: is it the maximum? I guess so, but to prove it I think a need to find certain relations between the closures and interior so that I can relate them to the two sequences I found with this example. More precisely (if we denote taking an interior by I and taking a closure by C) we have to proof that:\nAny suggestions for proofing this?\n\nshare|improve this answer\nat.yorku.ca/p/a/c/a/24.pdf has proofs for these statements. \u2013\u00a0 Henno Brandsma May 30 '13 at 17:55\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/64233/could-this-be-a-np-complete?sort=oldest\nText:\nTake the 2-minute tour \u00d7\n\n Given a undirected and unweighted graph G(V,E). M is a subset of vertices of V. \n s is a vertex in V - M.\n Find an optimal tree T of G defined as:\n (1) M and s are in V(T)\n (2) Distance (which is length of the shortest path) from s to any vertex in M in tree T is equal to distance from s to these vertices in G\n (3) No other tree T' satisfying condition (1) and (2) can have fewer nodes than T  \nMy idea was to use Dijkstra's algorithm to find shortest path from s to all vertices in M. However, there could be many shortest paths from vertex s to a vertex v. So, I will pick the shortest path that has the most number of vertices in M.\n Merge all these paths together to get tree T.  \nThis seems to solve the problem in polynomial time. However, my concern is the number of shortest path from vertex s to a vertex v could be very large that can make this algorithm be exponential. I don't know if there is any upper bound for the number of shortest path between 2 vertex in a graph.  \nAlso, does any one know if this problem is NP problem or it could be solved in polynomial time?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 4 down vote accepted\n\nThe problem is NP-complete.\n\nI think that the following algorithm describes a polynomial reduction of SAT to your problem.\n\nLet S be an instance of SAT. So you have a finite set of clauses $C_1$, $C_2$, ...,$C_n$.\nand a finite set of variables $p_1$, $p_2$, ..., $p_k$. Each clause contains some literals, i.e., variables $p_i$ and/or negated variable $\\lnot p_i$. (in 3sat we assume that each clause contains at most 3 literals.) We may assume that for each variable $p$ there is a clause $C_p$ containing only $p$ and $\\lnot p$, so $n\\ge k$.\n\nMake S into a graph as follows: There is a special vertex $ s$. For each variable $p$ there are two vertices $p$ and $\\lnot p$, both connected to $s$ (EDITED to simplify) by an edge. There is a vertex for every clause. Each literal $L$ is connected by an edge to each clause $C$ in which $L$ appears.\n\nThe set $M$ will be the set of all clauses.\n\nIf the original problem S was satisfiable, say with an assignment $A$, then then there is an optimal tree with $n+k$ edges: Connect $s$ with all literals which are true under $A$, and connect each clause $C$ with a literal $L$ in $C$ that is true under $A$.\n\n(EDITED to clarify and to close a gap:) Conversely, if there is an optimal graph with at most $n +k$ edges, then:\n\n  1. Each clause has to be on the tree, so it has to be connected to some literal. This costs $n$ edges.\n\n  2. For each variable $p$, either $p$ or $\\lnot p$ has to be on the tree (because of $C_p$), so either $p$ or $\\lnot p$ has to be connected (by an edge) to $s$ (because the distance has to be $1$). These connections cost $k$ edges.\n\n  3. So from each such pair EXACTLY one is connected with $s$. Those literals which are connected to $s$ now define a satisfying truth assignment.\n\nHence the instance $G,M$ of your problem that I constructed from the SAT problem $S$ has a solution of size at most $n+k$ iff $S$ is satisfiable. So any algorithm to solve your problem also solves SAT. Hence your problem is NP-complete.\n\nshare|improve this answer\nThanks a lot goldstern. I thinks this transformation is correct. I just wonder why we don't connect s directly to each variable instead of going through path o length n. That way we can have a tree of n + k edges, can't we? \u2013\u00a0 chepukha May 8 '11 at 1:18\nanother problem with this transformation is that you're trying to limit the number of edges while the optimal tree must have minimum number of vertices. With the way you select the tree, the number of vertices is not minimum. \u2013\u00a0 chepukha May 8 '11 at 5:02\nYou are right, the paths are not necessary. I edited my answer to simplify it (and also to clarify some points). \u2013\u00a0 Goldstern May 8 '11 at 8:19\nI do not understand your question about edges vs vertices. A tree with v vertices has v-1 edges. So you minimize the number of edges iff you minimize the number of vertices. \u2013\u00a0 Goldstern May 8 '11 at 8:20\nMaybe I didn't quite understand your proof. So let me give an example. Let say I have a 3SAT (x+y+z)(x+\u00acy+z). We can assign x=y=z=T. So, if we follow the proof, then we will get a tree with 6 vertices and n+k=2+3=5 edges. However, I can have another smaller tree that can have the same shortest paths to vertices in M={C1, C2}. That tree has 3 edges connecting the vertex representing x with s, C1, and C2. It also has only 4 vertices. Am I missing something here? \u2013\u00a0 chepukha May 8 '11 at 8:48\n\nJust a rough idea: (I am not really an expert on graph theory, so there may be a much better upper bound.)\n\nYou can group the vertices according to their distance to $s$, say\n\n$L_i=\\{v\\in V|dist(s,v)=i\\}$\n\nThen of course the $L_i$ are pairwise disjoint. Any shortest path from $s$ to a given vertex $v$ has to pass the $L_i$ ascending (you can easily proof this fact), so first a vertex from $L_1$, then one from $L_2$, and so on. That means there are at most $\\prod_{i=1}^{dist(s,v)-1}|L_i|$ shortest paths. As $|L_i|\\leq |V|$, you have a polynomial upper bound.\n\nWhile thinking about it: There might be a way to press this bound much lower, as $|L_i|=|V|$ only happens when all vertices have distance 1, which means the shortest path is the direct connection between $s$ and $v$. For decreasing amount of vertices in the $L_i$, the possible length of the path grows. You probably could use this to get a better bound.\n\nI do not see why the rest of your algorithm should not work.\n\nshare|improve this answer\nThank you. I didn't have time to verify your proof here but I think the above transformation is correct. \u2013\u00a0 chepukha May 8 '11 at 1:19\n\nYour Answer"}
{"text": "Retrieved from http://www.chegg.com/homework-help/questions-and-answers/satellite-moves-circular-orbit-around-earth-speed-64-km-s-determine-satellite-s-altitude-s-q1065421\nText:\nA satellite moves in a circular orbit around the Earth at a speed of 6.4 km/s.\nDetermine the satellite\u2019s altitude above the surface of the Earth. Assume the\nEarth is a homogeneous sphere of radius 6370 km and mass 5.98 \u00d7 1024 kg. The\nvalue of the universal gravitational constant is 6.67259 \u00d7 10-11 N \u00b7 m2/k2\nAnswer in units of km.\n\n\nDetailed answers to tough\nhomework problems"}
{"text": "Retrieved from http://mathoverflow.net/questions/35351/minimum-differences-in-vectors-of-naturals?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nI have run into this problem (or something similar to it) a few times now and I am wondering if the answer is known.\n\nGiven an vector $s$ of integers let $d(s)$ be the minimum difference between any two integers in $s$, that is $$d(s) = \\min_{i,j \\in s} |i - j|.$$ For $s$ a vector of length $m$ from $\\lbrace 1,2,\\dots,n\\rbrace^m$ we must have $0 \\leq d(s) < n$.\n\nGiven $0 \\leq k < n$, how may such vectors have $d(s) = k$ ?\n\nI'm more interested in the case where $n$ is much larger than $m$.\n\nNote: If $N_k$ is the answer for $k$. Then you should have $n^m = \\sum_{k=0}^{n-1}N_k$\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 7 down vote accepted\n\nThe number of $m$-subsets of {$1,2,\\ldots,n$} with distance at least $k$ between any pair is $n - (k-1)(m-1) \\choose m$.\n\nProof: for any subset of size $m$ of the first $n-(k-1)(m-1)$ integers, you can get a subset $S$ of the first $n$ with $d(S)\\geq k$ by just adding $k-1$ consecutive integers after each of the first $m-1$ elements of $S$.\n\nSo your answer is ${ n - (k-1)(m-1) \\choose m } -{ n - k(m-1) \\choose m }$ .\n\nUPDATE The intended question was about vectors and not sets. Essentially the same proof works; see the comments.\n\nshare|improve this answer\nHi Peter, I don't think this is correct. With ''m-subsets of $\\{1,2,\\cdots,n\\}$'' you are not allowing repetition, but I mean for the question to allow repetition. This is wholly my fault, I should never have called $S$ a set! \u2013\u00a0 Robby McKilliam Aug 12 '10 at 21:57\nMy comment makes no sense! Repetition implies that $d(S) = 0$. I'm going to have to stop and think about what I am asking. \u2013\u00a0 Robby McKilliam Aug 12 '10 at 22:14\nThat is the answer for sets since one gets just those sets, and once each. Then $\\binom {n}{m} = \\sum_{k=1}^{n-1}N_k$. If you want to have an $N_0$ and $n^m = \\sum_{k=0}^{n-1}N_k$ then you really are talking about vectors. Then, for $k \\gt 0$, multiply the answer above by $m!$. And then $N_0$ is what it would have to be, $n^m-\\frac{n!}{(n-m)!}$ \u2013\u00a0 Aaron Meyerowitz Aug 12 '10 at 23:18\nIt seems that you really do mean vectors and not multisets as in your amended title. But the answer for multisets is cute. Then $N_k$ is as Peter said for $k \\gt 0$ and $N_0=\\binom{n+m-1}{m}-\\binom{n}{m}$ which is the $k=0$ case of the formula. \u2013\u00a0 Aaron Meyerowitz Aug 12 '10 at 23:44\nIndeed, I mean vectors. I have fixed the title. I have made a bit of a mess of this question! And multiplying Peters answer by $m!$ as you have said give the desired result. \u2013\u00a0 Robby McKilliam Aug 13 '10 at 0:28\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/210352/boolean-simplification?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm having some trouble getting a handle with this course. We are starting Boolean algebra and my professor wants us simplify the following:\n\n\n\nI am assuming the \"()\" with \"'\" means the over-score above the variables.\n\nForgive my ignorance but my professor does not explain anything. He just says \"Do!\" in a Russian accent. I just want to understand.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nBy de Morgan\u2019s law $(AB)'=A'+B\\,'$, and it\u2019s always true that $X+X'=1$, so $$(AB)'+(A'+B\\,')'=(A'+B\\,')+(A'+B\\,')'=1\\;.$$\n\nSimilarly, we can start simplifying $(AB)'+BC+A'B\\,'C\\,'$ by using de Morgan\u2019s law to expand the first term, getting $A'+B\\,'+BC+A'B\\,'C'$. Now use one of the distributive laws to get $$A'+A'B\\,'C\\,'=A'1+A'B\\,'C\\,'=A'(1+B\\,'C\\,')$$ and then an absorption law to get $$A'+A'B\\,'C\\,'=A'(1+B\\,'C\\,')=A'1=A'\\;.$$ Thus, $$A'+B\\,'+BC+A'B\\,'C'=A'+B\\,'+BC\\;.$$\n\nNote that I could have reached the same final result by simplifying $B\\,'+A'B\\,'C\\,'$ to $B\\,'$, using exactly the same approach.\n\nAdded: As StainlessSteelRat notes in the comments, the simplification can be taken a step further. Specifically,\n\n\nso $A'+B\\,'+BC=A'+B\\,'+C$.\n\nshare|improve this answer\nAlright that makes sense. My question is now do we always follow those same steps? i.e. de Morgans, distribute laws, absorption laws. Or does each equation go through a different approach, depending how it is presented? \u2013\u00a0 Leo Oct 10 '12 at 9:29\n@Leo: In general it\u2019ll be a different approach each time, just as it was back in eighth- or ninth-grade algebra when you were asked to simplify an expression. In fact it is just algebra, though the rules are a little different from the ones for the familiar algebra of real numbers. \u2013\u00a0 Brian M. Scott Oct 10 '12 at 9:35\nThanks Brain for help. \u2013\u00a0 Leo Oct 10 '12 at 9:48\n@Leo: You\u2019re welcome. \u2013\u00a0 Brian M. Scott Oct 10 '12 at 10:03\n@Brian Since B' is there the B in BC is not required, so it reduces to A' + B' + C. \u2013\u00a0 StainlessSteelRat Apr 8 at 15:56\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/232989/finding-radius-of-convergence-for-power-series\nText:\nTake the 2-minute tour \u00d7\n\nFind the radius of convergence of the given power series:\n\n$$\\sum _{n=0}^{ \\infty} \\frac{8n!x^n}{2^n}$$\n\nAfter taking the limits as n-> $\\infty$, I get $\\frac{8x}{2}$, and Radius of convergence is R = 2. Is this correct?\n\nshare|improve this question\nThis is a very standard, very straightforward problem; what have you tried? \u2013\u00a0 Brian M. Scott Nov 8 '12 at 16:59\nUse the Ratio Test. Informally, the problem is that $n!$ grows hugely fast. \u2013\u00a0 Andr\u00e9 Nicolas Nov 8 '12 at 17:01\nTry by using the ratio test \u2013\u00a0 M. Strochyk Nov 8 '12 at 17:02\n@everyone except the OP: meta.math.stackexchange.com/a/2179/7850 \u2013\u00a0 The Chaz 2.0 Nov 8 '12 at 17:40\nshow 1 more comment\n\n2 Answers\n\nup vote 0 down vote accepted\n\nUsing the Ratio Test, it looks like we get $R=0$.\n\n$$\\left|a_{n+1}\\over a_{n}\\right| = \\left| \\frac{8(n+1)! \\cdot x^{n+1} \\cdot 2^n}{2^{n+1} \\cdot 8n! \\cdot x^n} \\right| = \\left| \\frac{8(n+1)n! \\cdot x \\cdot x^n \\cdot 2^n}{2\\cdot 2^n \\cdot 8n! \\cdot x^n} \\right|$$\n\n$$=\\frac{\\left|x\\right|} {2} \\lim_{n\\to\\infty} (n+1) \\to \\infty \\ \\ \\forall x \\ne 0\\implies R=0$$\n\nThus, the power series only converges when $x=c$, which is at $x=0$ here.\n\nshare|improve this answer\nadd comment\n\nThis can help you solve this problem.\n\nThe answer is:\n\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/147332/can-a-herglotz-nevanlinna-function-attain-real-values\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\mathbb{H}^+=\\{z \\in \\mathbb{C}\\mid \\Im(z)>0\\}$. We say that an analytic $F\\colon \\mathbb{H}^+\\to\\overline{\\mathbb{H}^+}$ is a Herglotz-Nevanlinna's function.\n\nQuestion Can it be that $F(z)\\in \\mathbb{R}$ for some $z \\in \\mathbb{H}^+$?\n\nI guess that the answer is no, because if this happened then we could find a small loop $\\gamma$ around $z$ such that $F\\circ \\gamma$ slips outside $\\overline{\\mathbb{H}^+}$, but I'm not sure this is true and how to formalize this little argument.\n\nThank you.\n\nshare|improve this question\nOf course in both this question and the answer by Davide Giraudo it is assumed that $F$ is not constant. \u2013\u00a0 Giuseppe Negro May 22 '12 at 9:57\nadd comment\n\n1 Answer\n\nup vote 2 down vote accepted\n\nIf $F$ is constant it's clear, otherwise, since $\\mathbb H^+$ is connected, by the open mapping theorem, $F(\\mathbb H^+)$ is open in $\\mathbb C$. If $F(z)\\in\\Bbb R$ for some $z\\in\\mathbb H^+$, then we can find $r$ such that if $|y-F(z)|<2r$ then $y=F(y')$ for some $y'\\in\\mathbb H^+$. If we consider $F(z)-ri$, we get a contradiction.\n\nshare|improve this answer\nAw, thank you! This was a good occasion to review the open mapping theorem (which evidently I had forgotten! :-) ). \u2013\u00a0 Giuseppe Negro May 20 '12 at 17:14\nYou are welcome. In which context do we use such maps? \u2013\u00a0 Davide Giraudo May 20 '12 at 17:15\nMeasure theory and spectral analysis. Specifically I am reading this lecture by Terence Tao: terrytao.wordpress.com/2011/12/20/\u2026 . Have a look at Theorem 4. \u2013\u00a0 Giuseppe Negro May 20 '12 at 17:18\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/46792/how-long-does-it-take-for-every-node-of-a-graph-to-become-infected/46793\nText:\nTake the 2-minute tour \u00d7\n\nConsider the following stochastic process.\n\nWe begin with an undirected graph on $n$ vertices, exactly one of which is ''infected.'' Now at every time step, each infected node infects one of its non-infected neighbors uniformly at random. For example, if a given node has $3$ neighbors that are infected and $5$ that are not, then it infects exactly one of those latter $5$, each of which has probability $1/5$ of being the one chosen.\n\nNow its clear that after $n-1$ steps every node becomes infected, since at every step at least one non-infected node becomes infected. However, I suspect that the infection actually spreads faster, because as the number of infected nodes grows, more and more non-infected nodes become infected at every stage.\n\nMy question: Is it actually true that every node is infected after $O(D)$ steps, where $D$ is the diameter of the graph?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 6 down vote accepted\n\nConsider a tree of $n$ layers where each node at layer $n$ (up to $n-1$)has $n$ branches leading upward. The last node will be infected after $1+2+3 \\ldots +(n-1)=\\frac{n(n-1)}{2}$, but the diameter is $2n-2$\n\nshare|improve this answer\nadd comment\n\nConsider a starlike graph of n+1 nodes in which every node except node A is adjacent to A and only to A.\n\nIf A is infected, exactly one of its neighbors becomes infected at each step until all are. So the number of steps until every node is infected is n, not O(D) since D = 2.\n\nshare|improve this answer\nSimpler than mine. This one deserves the check mark. \u2013\u00a0 Ross Millikan Jun 22 '11 at 14:38\n@Ross: No, you had the answer first. I only posted because I thought I could add something. \u2013\u00a0 hardmath Jun 22 '11 at 16:15\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/54364.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nSum of Unit Fractions\n\nDate: 07/17/2001 at 20:28:27\nFrom: Candyce\nSubject: Java programing class\n\nSuppose that p/q is a fraction in lowest terms such that \n1/(n+1) < p/q < 1/n for some positive integer n. Show that \n(p/q) - (1/(n+1)) is a fraction which in its lowest terms has \nnumerator less than p. Hence by induction, prove that every proper \nfraction p/q with p < q can be written as a finite sum of distinct \nreciprocals of positive integers. \n\nFor example, 19/15 = 1/2 + 1/3 + 1/4 + 1/6 + 1/60. \n\nUse this technique to express 5/7 as a sum of reciprocals.\n\nThe example given here is correct, though it's not true that all \nfractions greater than 1 can be expressed finitely in this way \n(e.g. 2) - you've been asked to prove the statement only when the \nfraction is less than 1 (which is always true). If you want an \nexample for this case, then 14/17 = 1/2 + 1/4 + 1/14 + 1/476. \n\nThe problem is the PROFF part. I can understand that it works.\n\nDate: 07/18/2001 at 10:53:15\nFrom: Doctor Paul\nSubject: Re: Java programing class\n\nHere's how to do it for fractions less than one (assumed to be in \nlowest terms):\n\nI'll show you how it works for 14/17 and you should be able to \nit for any p/q.\n\nGiven 14/17, find the largest unit fraction less than 14/17. I think \nthe easiest way to do this is to systematically increment the \ndenominator by one until the fraction reduces to a unit fraction. The \nreduced unit fraction will be the largest unit fraction less than the \ngiven number. In the case of 14/17, we first consider: 14/18 = 7/9, \nwhich is not a unit fraction, so we next consider 14/19, 14/20 = 7/10, \n14/21 = 2/3, which is not a unit fraction, so we next consider 14/22, \n.... , 14/28 = 1/2.\n\nSo we know that 1/2 is a unit fraction and we know that it is less \nthan 14/17.\n\nThus we can write:\n\n  14/17 = 1/2 + a/b where a/b is to be determined.\n\nsubtract 1/2 from both sides to obtain:\n\n  a/b = 14/17 - 1/2 = 11/34\n\nThus we have:\n\n  14/17 = 1/2 + 11/34\n\nIf a/b had turned out to be a unit fraction, we would be done. But \nsince it isn't a unit fraction, we do the process again. We now want \nto convert 11/34 into a sum of unit fractions:\n\nIncrease the denominator until you get a unit fraction:\n\n  11/35, 11/36, ... , 11/44 = 1/4\n\n  so 11/34 = 1/4 + c/d\n\n\n  c/d = 11/34 - 1/4 = 5/68\n\nSo we have:\n\n  14/17 = 1/2 + 1/4 + 5/68\n\nIf c/d had been a unit fraction, we would be done. But since c/d was \nequal to 5/68, we now need to repeat the process and convert 5/68 into \na unit fraction.\n\nincrease denominators:\n\n  5/68, ..., 5/70 = 1/14\n\nso we have:\n\n  5/68 = 1/14 + e/f\n\n  e/f = 1/476\n\nSince e/f is a unit fraction, we're done.\n\nWe can now write the final result:\n\n\nwhich is exactly the answer you gave above.\n\nThis method is attributed to the British mathematician J.J. Sylvester \n\nIn general, the decomposition of a fraction into a sum of unit \nfractions is not unique. For example, 3/8 = 1/4 + 1/8 = 1/3 + 1/24.\n\nSince your subject is \"Java programming class\" I'm guessing that you \nhave to implement this algorithm in Java. Obviously, you're going to \nneed to run some sort of 'for' or 'until' loop to get this thing to \nrun properly. I've never programmed in Java, but I think it's a great \nassignment in any programming language! Good luck.\n\n- Doctor Paul, The Math Forum\nAssociated Topics:\nHigh School Calculators, Computers\nHigh School Number Theory\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/49141/galois-theory-splitting-field-of-cubic-as-a-vector-space?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nI'm trying to express the splitting field of a cubic equation as a vector space over the rationals. Specifically I am looking for a set of six independent vectors that span the space. If the roots are a,b, and c then I know I need to be able to express all expressions in a,b and c up to second degree: namely,\n\na, a^2\n\nb, b^2\n\nc, c^2\n\nab, bc, ca\n\na^2b, b^2c, c^2a, ab^2, bc^2, ca^2\n\nObviously there are 15 of these and they are not all independent. Given a and b, I easily get c as a linear term in a, b, and (a+b+c). Likewise c^2 is not independent of a^2 and b^2. And I find that I can generate ab etc as linear combinations of c, c^2, and abc.\n\nSo what are my six vectors? I have allowed myself 1, a, b, a^2, and b^2 ....this gives me five and I think they are all linearly independent. I'm only allowed one more and I can't get it to work. I'm inclined to try (a^2b + b^2c + c^2a) because I'm pretty sure I need it, but having done so I can't see how I generate terms like a^2b on their own.\n\nAny ideas? I'd be especially interesteds if there is a basis which is more symmetric in some sense than the arbitrary collection of terms which I'm cobbling together.\n\nshare|improve this question\nA cubic extension has degree $3$, not degree $6$. Or do you mean the splitting field of a cubic? In that case, it depends on the Galois group of the cubic. \u2013\u00a0 Qiaochu Yuan Jul 3 '11 at 5:01\nHave you tried a Gr\u00f6bner basis algorithm (Buchberger?) on the obvious set of generators? Also, is it immediately clear that you don't need to worry about monomials like $a^2b^2$? \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 5:25\n@qiaochu Although English is my first language, I am very weak on the terminology in this subject. Yes, I think I meant the splitting field of the cubic; and I know that some cubics have a different Galois group, but I meant the most general case of S3. \u2013\u00a0 Marty Green Jul 3 '11 at 5:45\n@Jyrki I don't know anything about the methods you refered to; but yes, I forgot about terms like a^2b^2 when I posted my question. In fact, I get them the same way I got terms like ab; since a^2b^2c^2 is an integer, I divide by c^2 which is the same as multiplying by a linear term in c. I think. \u2013\u00a0 Marty Green Jul 3 '11 at 5:48\n@Marty: Sorry about bringing up Gr\u00f6bner here. Too heavy a tool for this job. \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 8:17\nadd comment\n\n1 Answer\n\nup vote 4 down vote accepted\n\nThe simplest basis I can think of consists of monomials $\\mathcal{B}=\\{1,a,a^2,b,ab,a^2b\\}$. One way to see this goes as follows. Let's first write $$ P(x)=(x-a)(x-b)(x-c)=x^3-s_1x^2+s_2x-s_3, $$ with the elementary symmetric polynomials $s_1=a+b+c$, $s_2=ab+bc+ac$ and $s_3=abc$. If $K$ is your base field, I claim that all the monomials $a^ib^jc^k$ can be written as linear combinations of monomials from the set $\\mathcal{B}$ with coefficients from the field $L=K(s_1,s_2,s_3)$ (in your case surely $s_1,s_2,s_3\\in K$, so the combinations are really $K$-linear).\n\nThe first and most obvious thing is to replace everywhere $c$ with $s_1-a-b$. After that we only need to take care of monomials $a^ib^j$. The quantities $a$ and $b$ are zeros of $P(x)$, so we know how to replace $a^i, i\\ge 3$ and $b^j, j\\ge3$ with lower powers. So we are left with the 9 monomials $\\mathcal{B}\\cup\\{b^2,ab^2,a^2b^2\\}$. Substituting $c=s_1-a-b$ to the equation $ab+ac+bc-s_2=0$ gives us a relation $$ b^2=ab+a(s_1-a-b)+b(s_1-a)-s_2 $$ that allows us to write $b^2$ as an $L$-linear combination of $a^2,ab,a,b$ and $1$. When we do this substitution to a monomial like $ab^2$ or $a^2b^2$ we introduce higher powers of $a$. But we can reduce these to lower powers of $a$ as before. It may feel like $s_3$ wasn't really used, but it did make an appearance, when we reduced the higher powers of $a$ and $b$.\n\nshare|improve this answer\nNicely done, and very well explained. Thanks. \u2013\u00a0 Marty Green Jul 3 '11 at 12:23\nIn retrospect the basis is obvious given that this is the usual way of getting a basis for a tower of field extensions. $L(a)/L$ has a basis $\\{1,a,a^2\\}$ and $L(a,b)/L(a)$ a basis $\\{1,b\\}$. A basis for $L(a,b)/L$ is gotten by including all the products of elements of the two bases. \u2013\u00a0 Jyrki Lahtonen Jul 3 '11 at 18:41\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/81944/whats-the-expected-matched-pair-of-shoes-when-10-pairs-mixed-up\nText:\nTake the 2-minute tour \u00d7\n\nWe've got $10$ different pairs of shoes. Now we mix them up and randomly regroup them into $10$ \"pairs\". Of course some \"pairs\" are not matched and maybe some of them are. So what's the expect number of pairs that are matched?\n\nBy \"randomly group\", I mean you can randomly pick one from the $20$, then choose one from the remaining $19$ to pair it up, and so on.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nLet $X$ be the number of pairs of shoes that are matched. It is somewhat complicated to work with $X$ directly, so we think of $X$ as a sum of simpler variables:\n\nFor $i=1,2,\\ldots10$, let $X_i=\\cases{1 & \\text{if the }i\\text{th pair is matched},\\\\ 0 & \\text{otherwise}.}$\n\nThen each $X_i$ is a Bernoulli variable and $X=\\sum_{i=1}^{10}X_i$.\n\nExpectation is linear, so $$ \\Bbb E(X)=\\sum_{i=1}^{10}\\,\\Bbb E(X_i). $$\n\nNow we fix $i$ and find $\\Bbb E(X_i) $:\n\nSince $X_i$ is a Bernoulli variable, $\\Bbb E(X_i)=P[X_i=1]$. But the probability that $X_i=1$ is the probability that the $i$th pair was matched. Since it is equally likely that any one of the other 19 shoes is paired with the left shoe of the $i$th pair, $P[X_i=1]={1\\over19}$.\n\nSo $\\Bbb E(X_i)={1\\over19}$.\n\nFinally, we have:\n\n$$\\Bbb E(X)=\\sum_{i=1}^{10}\\Bbb E(X_i)=\\sum_{i=1}^{10}{1\\over19}=10/19.$$\n\nshare|improve this answer\nI should mention why $P[X_i=1]={1\\over19}$ without \"hand waving\": there are ${20!\\over2^{10}}\\cdot{1\\over10!}$ ways to divide the 20 shoes into pairs and there are ${18!\\over2^9}\\cdot{1\\over9!}$ ways to divide them into pairs with the $i$th pair matched. $P[X_i=1]$ is the ratio of these quantities, which is $1/19$. \u2013\u00a0 David Mitra Nov 14 '11 at 10:15\nInteresting that you're allowed to pair a right shoe with another right shoe. I might have stated the problem differently---maybe using socks, since with those you can't tell left from right. \u2013\u00a0 Michael Hardy Nov 14 '11 at 11:45\nI'm thinking of the problem as the same as \"10 married couples are split into 10 groups, each of size 2\". Find the expected number of groups consisting of a married couple. (That is, a pair of shoes consists of two distinct objects.) \u2013\u00a0 David Mitra Nov 14 '11 at 11:52\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/83958/combinatorial-geometry-covering-a-square?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm stuck with this problem. can anyone help me?\n\nA finite collection of squares has total area 4. show that they can be arranged to cover a square of side 1.\n\nshare|improve this question\nSquare overlapping is allowed, right ? If, for exemple, you have 21 small squares with areas $a_1,a_2, \\ldots ,a_{21}$ given by $a_k=\\frac{19}{105}+\\frac{k-1}{1050}$, then all the $a_k$'s are different and smaller than $a_{21}=\\frac{1}{5}$, so if we cover a unit square with those small squares, some small squares will necessarily overlap. \u2013\u00a0 Ewan Delanoy Nov 20 '11 at 17:16\nyes, overlapping is allowed. \u2013\u00a0 Goodarz Mehr Nov 20 '11 at 17:37\nadd comment\n\n1 Answer\n\nup vote 7 down vote accepted\n\nHere's a proof using the following simple combinatorial\n\nLemma. Let a positive integer $k$ and a nonempty finite multiset $P$ of powers $k^i$ with $i\\in\\mathbf{Z}$ be given. Put $s=\\sum P$, the sum of all the powers, and $k^m$ the greatest power occurring in $P$; let the integer $q>0$ be such that $s\\geq qk^m$. Then there exists a partition of a sub-multiset of $P$ into $q$ parts each of sum exactly $k^m$.\n\n(Finding a decent formulation is more difficult here than finding a proof.) One can obviously take $q$ the quotient of the Euclidean division of $s$ by $k^m$, but for the proof it will be convenient to have a bit more freedom. The condition for a collection of multisets of being a partition of a sub-multiset of $P$ is what the terminology suggests: it just means that for any element, the sum of its multiplicities of occurrence in members of the collection is no more than its multiplicity of occurrence in $P$.\n\nProof. By induction on the number $n\\geq1$ of elements in $P$. Split off from $P$ the singleton $\\{k^m\\}$ of its greatest element, which will be one part of the partition sought, leaving a remainder $P'$. If $q=1$, then the one-part partition $\\{k^m\\}$ is a solution. In the remaining case one certainly has $n>1$, so $P'$ is non-empty; let $k^{m'}$ be the greatest element of $P'$, with obviously $m'\\leq m$. Applying the induction hypothesis to $P'$ and $q'=(q-1)\\,k^{m-m'}$, one obtains a partition of a sub-multiset of $P'$ into $q'$ parts each of sum $k^{m'}$. Grouping them together $k^{m-m'}$ at a time (in an arbitrary way) provides a partition of the same sub-multiset of $P'$ into $q-1$ parts, which together with $\\{k^m\\}$ give a solution. QED\n\nNow for the problem of the squares, round the lengths of their sides down, each to a (probably negative) integer power of $2$. Each square will certainly cover a square of the rounded-down size, and replacing the collection by the so rounded-down squares gives a multiset of squares whose total area is greater than a quarter of the original area, that is greater than 1. Excluding the trivial case of a single square of area $4$, the largest square has size $2^{-l}$ with $l\\in\\mathbf{N}$. Apply the lemma with $k=4$, the multiset of the areas of the rounded-down squares, and $q=4^l\\in\\mathbf{N}$. This provides a partition of a sub-multiset of the squares into $q$ parts, each of which parts will cover one of the $q$ squares of the $2^l\\times2^l$ subdivision of the unit square. (One needs to check that the regrouping of $4^{m-m'}$ multisets done in the proof of the lemma can be realised geometrically, but this is obvious by a similar $2^{m-m'}\\times2^{m-m'}$ subdivision.)\n\nshare|improve this answer\n\"...the greatest power occurring in S\" - what is S? Did you mean P? \u2013\u00a0 Erel Segal Halevi May 19 '13 at 10:30\n@ErelSegalHalevi Yes, thank you. Corrected now. \u2013\u00a0 Marc van Leeuwen May 19 '13 at 10:38\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/24637/p-adic-numbers-and-binomial-coefficients\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\alpha\\in \\mathbb{Z}_p$ be an $p$-adic integer and define for $n\\in \\mathbb{Z}_{\\geq 0}$ $${\\alpha\\choose n} := \\frac{\\alpha(\\alpha-1)\\cdot\\ldots\\cdot(\\alpha-n+1)}{n!}.$$\n\nThis is again a $p$-adic integer, and we can define $$\\alpha_1:=\\sum_{n=0}^\\infty \\overline{{\\alpha \\choose n}} p^n$$ and $$\\alpha_2:=\\sum_{n=0}^\\infty \\overline{{\\alpha \\choose p^n}} p^n,$$\n\nwhere $\\overline{(\\cdot)}$ means reduction modulo $p$. How are $\\alpha,\\alpha_1,\\alpha_2$ related? Are there formulas expressing this relation?\n\nThanks a lot!\n\nEdit: Some thinking led me to the following conclusion: Using continuity of $x\\mapsto {x\\choose p^n}$ as a function $\\mathbb{Z}_p\\rightarrow \\mathbb{Q}_p$ and Lucas' Theorem it follows that $\\alpha=\\alpha_2$. Does this seem correct?\n\nshare|improve this question\nIt is not very clear to me what you mean by \"reduction modulo $p$\". Classes mod $p$ live in the finite field ${\\Bbb F}_p$ and the sums $\\alpha_1$ and $\\alpha_2$ wouldn't make much sense there. Are you saying that you are taking some fixed representants of the classes mod $p$ such as $\\{0,1,\\ldots,p-1\\}$ ? \u2013\u00a0 Andrea Mori Mar 2 '11 at 16:39\nOh, yes, the unique nonnegative representative $<p$. \u2013\u00a0 user7698 Mar 2 '11 at 17:55\nYou can determine whether $p$ divides $\\binom{m+n}{n}$ by seeing whether there are any carries when adding $m$ and $n$ in base $p$. $\\binom{\\alpha}{p^n}$ is particularly simple, since $p^n$ in base $p$ is very easy. \u2013\u00a0 Arturo Magidin Mar 2 '11 at 20:30\nadd comment\n\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/152911/showing-sin1-x-is-not-a-rectifiable-curve\nText:\nTake the 2-minute tour \u00d7\n\nIntuitively it looks like near $0$, $\\sin(1/x)$ oscillates wildly so that two points will be very far apart, but how can I properly formulate this?\n\nshare|improve this question\nProbably it is intuitively obvious, and we can leave it at that! But if you want to be more formal, look at the arclength from $0$ to $1$. Set up the integral and show it does not converge. Or even more properly, look at arclength from $\\epsilon>0$ to $1$, and show it blows up as $\\epsilon$ approaches $0$. So we calculate $\\sqrt{1+(f'(x))^2}$. You will see this is real big near $0$. \u2013\u00a0 Andr\u00e9 Nicolas Jun 2 '12 at 15:50\nHint: Remember that the supremum is taken over all partitions of an interval, and notice that as $x$ approaches 0, the function will go from +1 to -1 and back an unbounded number of times, so the supremum must also be unbounded. \u2013\u00a0 Old John Jun 2 '12 at 15:51\n\n1 Answer 1\n\nup vote 2 down vote accepted\n\nLet $x_n = \\frac{1}{\\pi(\\frac{1}{2}+n)}$, $n=0,1,...$. Note that $\\sin x_n = (-1)^n$. Note that $x_n$ monotonically decreases to $0$.\n\nConsider the function on the interval $[x_n,x_0]$, using the partition $t_k = x_{n-k}$. Then the variation is exactly $2n$. Hence the variation is unbounded on the interval $(0,1)$ (or any open interval with $0$ as the left most point).\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/262199/relating-the-genus-of-a-curve-to-its-degree-via-n-canonical-embedding\nText:\nTake the 2-minute tour \u00d7\n\nLet $n\\geq 3$ be an integer. If we embed a connected curve $C$ (e.g. a stable curve) of genus $g$ in $\\mathbb P^N$ by an $n$-canonical embedding, i.e. using the very ample linear system $|nK_C|$, we have that $N=(2n-1)(g-1)-1$. This is clear. But I do not see how to deduce that the degree of $C$ is $2n(g-1)$. This is equivalent to the assertion \\begin{equation} g+\\deg C=N, \\end{equation} which I am not able to justify. Does anyone have any hint? Is it possible to use some adjunction formula argument even if we are not in the plane case?\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nThe degree of $C$ in $\\mathbb P^N$ is the intersection number of a hyperplane with $C$, or equivalently, the degree (as divisor on $C$) of the restriction of a hyperplane to $C$. In terms of invertible sheaf, a hyperplane corresponds to $O_{\\mathbb P^N}(1)$ and its restriction to $C$ is, by construction, $nK_C$. So the degree of $C$ in $\\mathbb P^N$ is just the degree on $C$ of $nK_C$, which is $n(2g-2)=2n(g-1)$ by Riemann-Roch.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56582.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nProbability Distribution\n\nDate: 12/22/97 at 19:15:33\nFrom: Smith, Cassandra\nSubject: Probability distribution\n\nI have written to you before with much success. I am once again\nstumped. I have tried several times to answer this question and even\nthough the answers are available to me, I am unable to solve it.\n\nA county containing a large number of rural homes is thought to have \n60% of those homes insured against fire. Four homeowners are chosen \nat random and x are found to be insured against fire. Find the\nprobability distribution for x. What is the probability that at least \n3 of the 4 are insured?\n\nI am able to find p(0) = 0.0256  and the p(4) = 0.1296\nThe answers to p(1) = 0.1536   p(2) = 0.3456  p(3) = 0.3456\nProbability of 3 out of 4 = 0.4572\n\nI have tried to work towards these answers without any success.  \nPlease show me how to solve this problem.  \n\nThank you.\n\nDate: 01/28/98 at 13:54:14\nFrom: Doctor Sonya\nSubject: Re: Probability distribution\n\nWhat you have described is known as a Bernoulli trial.  \n\nYou use a Bernoulli trial when you want to know the number of \nsuccesses in n trials. For example, if I have a probablity of 0.34 of \nwinning a game, I could use Bernoulli trials to tell me my probability \nof winning three out of five.\n\n\"What does this have to do with insurance?\" you may ask. Well, if my \ngame is picking a house, and I win that game if the house is insured, \nwe can use Bernoulli trials to find the probability of \"winning\" 0, 1, \n2, 3, or 4 times. This is also the probability that 0, 1, 2, 3, or 4 \nof the houses are insured.\nOne thing that has to be true about our game before we can use \nBernoulli trials is that each play must be independent. This means \nthat one house having insurance has nothing to do with its neighbor \nalso having insurance.\n\nI'm sure there's a chapter about Bernoulli trials in your textbook if \nyou want more information. \n\nLet's say I have n trials (or n plays of a game), with a probability p \nfor success. Then the probability that I will win EXACTLY k of these \nn trials is given by\n\n  P(X = k) = (n choose k) * (p^k) * (1 - p)^(n-k)\n\nSo for our problem, if n = 4, and k = 3, and p = .6 we have\n\n  P(X = 3) = (4 choose 3) * (.6^3) * (.4)^1\n           = (4) * (.6^3) * .4\n           = (4) * (.216) * .4\n           = .3456\n\nHowever, this isn't all.  Your problem asked for the probability of \n\"at least 3\" being insured. So if 4 of the 4 get insurance, then the \nproblem is also solved. \n\nI'll let you use the Bernoulli trials for P(X=4). (Remember that k=4.)\n\nThus the probability that at least 3 of the four houses are insured \n\n  P(X=4) + P(X=3) \n\nand you'll see that these are the answers you're looking for.\n\nGood luck, and don't hesitate to write back with more questions.\n\n-Doctor Sonya,  The Math Forum\nAssociated Topics:\nHigh School Probability\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/309536/quaternions-torque-and-impulse\nText:\nTake the 2-minute tour \u00d7\n\nIn a physics simulation I have a solid ball of mass $m$ and moment of interia $M$ (which is a diagonal matrix with all entries equal to ${2\\over5}mr^2=i$). Its instantaneous rotation is given by a quaternion $q$.\n\nThis body is touching another rotating body which applys a force $f$ at a point $p$ measured from the centre of the ball. $f$ resolves into a push into the radius (which we can disregard here) and a tangential torque $f^T$.\n\nThe simulation advances in a time step of $t$ seconds. How should I update $q$?\n\nI have a basic understanding of quaternions but not enough familiarity to approach this. Computational efficiency matters so I'd like to avoid converting $q$ into a matrix and back again. I imagine that $f^T$ and $p$ combine to some kind of \"impulse\" rotation $r_t$ so I can just do $q \\to qr_t$. Is this at all the right way to do it?\n\nshare|improve this question\n\n1 Answer 1\n\nI don't know the term \"instantaneous rotation\", so I don't know whether you mean the instantaneous orientation or the instantaneous angular momentum or angular velocity; whichever one you mean, the other one seems to be missing from your state description. I also don't know what to make of a force resolving into a push and a torque, since a torque doesn't have the same dimensions as a force. Further it's unclear to me what you mean by \"$f^T$ and $p$ combine\", since $f^T$ is a force or a torque and $p$ is a point. I'll restate the problem in a form and notation that I understand, and I hope you'll be able to map that onto what you're doing.\n\nThe orientation of the body at time $t$ can be described by a quaternion $s(t)$ corresponding to the rotation required to get to that orientation from some reference orientation. Its rotational state can be described by either its angular momentum $L$ or its angular velocity $\\omega$; since the body is symmetric and its moment of inertia $I=\\frac25mr^2$ is a scalar, these two are proportional to each other, $L=I\\omega$. The angular velocity can be regarded as an element of the Lie algebra of the quaternions, specified by a three-dimensional vector whose direction is the instantaneous axis of rotation and whose magnitude is the instantaneous angular speed. The body's orientation evolves according to $\\dot s(t)=\\Omega(t)s(t)$, where the dot denotes differentiation with respect to the time $t$ and $\\Omega(t)=(0,\\omega(t))$ is the purely imaginary quaternion corresponding to the angular velocity $\\omega(t)$. In the absence of torques, the angular velocity is constant and the motion can be integrated to $s(t)=\\exp(\\omega t)s(0)$, where $\\exp$ is the exponential map from the Lie algebra to the quaternions,\n\n$$\\exp(x)=\\left(\\cos|x|,\\sin|x|\\frac x{|x|}\\right)\\;.$$\n\nA torque is by definition a rate of change of the angular momentum. A force $F$ acting at a point $p$ exerts a torque $\\tau=r\\times F$ on the ball, where $r$ is the vector from the ball's centre to $p$. This causes the angular momentum to change according to $\\dot L=\\tau$, so the angular velocity changes according to $\\dot\\omega=\\tau/I$. Section $3$ of this paper gives what might be called a closed form for the resulting motion, but it's rather complicated and I gather you want to approximate the motion in finite time steps $\\Delta t$. Since $\\omega$ changes linearly, its update is exactly given by $\\omega(t+\\Delta t)=\\omega(t)+\\Delta t\\tau/I$. To update the orientation $s$, you could take the average angular velocity $\\bar\\omega=\\omega(t+\\Delta t/2)=\\omega(t)+\\Delta t\\tau/(2I)$ during the time step and update $s$ according to $s(t+\\Delta t)\\approx\\exp(\\bar\\omega\\Delta t)s(t)$. If you want, you can also approximate the exponential map by\n\n$$ \\exp(x)\\approx\\left(\\sqrt{1-|x|^2},x\\right) $$\n\nfor small time steps.\n\nI hope you can translate that into how you're thinking about the problem; if not, feel free to ask.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/168965/calculating-taylor-polynomials-for-a-function-in-mathbbr3?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nHello how does one apply the Taylor polynomials in a function of three variables?\n\nIf we consider the function $f: \\mathbb{R}^3$ to $\\mathbb{R}$ with $(x_1, x_2, x_3)$ mapped to $\\sin(x^2_1) + \\exp(x_2) + \\cos(x_1x_3)$.\n\nHow can one calculate the Taylor polynomials of order one, two and three evaluated at the point $x = 0$?\n\nCan someone please give me an idea as to how one tackles it.\n\nshare|improve this question\n\n1 Answer 1\n\nComputationally simplest is using the known Taylor expansions of the functions $\\sin$, $\\exp$, and $\\cos$. This would give $$\\eqalign{\\sin(x_1^2)&=x_1^2-{1\\over6}x_1^6 +{1\\over120}x_1^{10}-\\ldots\\ ,\\cr \\exp(x_2)&=1+x_2+{1\\over 2}x_2^2+{1\\over 6}x_2^3 +\\ldots\\ ,\\cr \\cos(x_1x_3)&=1-{1\\over2}x_1^2x_3^2 +{1\\over24}x_1^4x_3^4 -\\ldots\\ .\\cr}$$ Now collect all terms up to the desired order. E.g., the third order taylor expansion of $f$ at ${\\bf 0}=(0,0,0)$ is given by $$f(x_1,x_2,x_3)=2+x_2+x_1^2+{1\\over2}x_2^2+{1\\over6}x_2^3+ R_3({\\bf x})\\ ,$$ where the remainder term is $o(|{\\bf x}|^3)$ when ${\\bf x}\\to{\\bf 0}$.\n\nOf course there is also a general procedure for the Taylor expansion in several variables. When $f:{\\mathbb R}^n\\to{\\mathbb R}$ is sufficiently smooth then at any point ${\\bf p}$ it has differentials of order $0$, $1$, $2$, $3$, etc.. The differential of order $r$ at ${\\bf p}$, denoted by $d^r f({\\bf p})$, is a homogeneous polynomial in the auxiliary variable ${\\bf X}=(X_1, \\ldots, X_n)$ and is given by $$d^r f({\\bf p}).{\\bf X}=\\sum_{k_1,\\ldots, k_r} f_{.k_1\\ldots k_r}({\\bf p}) X_{k_1}\\cdot\\ldots\\cdot X_{k_r}\\ .$$ Here the summation variables $k_j$ run independently from $1$ to $n$, so formally there are $n^r$ terms in this sum. The zeroth differential is just the constant function with value $f({\\bf p)}$, and $d^1f({\\bf p}).{\\bf X}=f_{.1}X_1+\\ldots+f_{.n}X_n$ (the $f_{.k}$ evaluated at ${\\bf p}$) is the usual \"differential\" of $f$ at ${\\bf p}$.\n\nThe Taylor expansion of $f$ at ${\\bf p}$ can then be written as $$f({\\bf p}+{\\bf X})=\\sum_{r=0}^N{1\\over r!}d^r f({\\bf p}).{\\bf X} + R_N$$ where $R_N$ denotes the remainder term. The Taylor theorem says, e.g., that $R_N=o(|{\\bf X}|^N)$ when ${\\bf X}\\to{\\bf 0}$.\n\nWhen ${\\bf p}={\\bf 0}$ we can replace ${\\bf X}=(X_1,\\ldots ,X_n)$ by ${\\bf x}=(x_1,\\ldots,x_n)$ and simply write $f({\\bf x})=\\sum_{r=0}^N\\ldots + R_N$.\n\nshare|improve this answer\nConsidering the first method, for 1, 2 and 3, we get x2, (x1)^2, (1/6)(x2)^3 respectively. So in this question, why have we been given the third term (i.e., cos(x1.x3)? \u2013\u00a0 carla Jul 10 '12 at 10:31\nI mean, we get the polynomials of order 1, 2 and 3 as 2 + x2,, 2 + x2 + (x1)^2, 2 + x2 + (x1)^2 +(1/6)(x2)^3. So how does the third term help? \u2013\u00a0 carla Jul 10 '12 at 10:47\n@carla: The third term in $f$ is given for whatever reason. In the third order Taylor polynomial of $f$ at ${\\bf 0}$ it only contributes $1$ to the constant term but nothing further. \u2013\u00a0 Christian Blatter Jul 10 '12 at 11:30\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49259/when-is-the-product-of-two-ideals-equal-to-their-intersection/49299\nText:\nTake the 2-minute tour \u00d7\n\nConsider a ring $A$ and an affine scheme $X=SpecA$ . Given two ideals $I$ and $J$ and their associated subschemes $V(I)$ and $V(J)$, we know that the intersection $I\\cap J$ corresponds to the union $V(I\\cap J)=V(I)\\cup V(J)$. But a product $I.J$ gives a new subscheme $V(I.J)$ which has same support as the union but can be bigger in an infinitesimal sense. For example if $I=J$ you get a scheme $V(I^2)$ which is equal to \"double\" $V(I)$.\n\nVague Question : What is geometric interpretation of $V(I.J)$ in general?\n\nPrecise question : When is $I\\cap J=I.J$? Everybody knows the case $I+J=A$ but this is absolutely not necessary. For example if $A$ is UFD and $f,g$ are relatively prime then $(f).(g)=(f)\\cap(g) $ but in general $(f)+(g)\\neq A$ (e.g. $f=X, g=Y \\in k[X, Y]$)\n\nThank you very much.\n\nshare|improve this question\n\n3 Answers 3\n\nup vote 21 down vote accepted\n\nTo add to David Speyer's answer, since this story continues with a rather interesting and illustrious history:\n\nWhen $A$ is regular, the Tor functor satisfies the following property:\n\n(1) $\\text{Tor}_1^A(M,N) = 0$ implies $\\text{Tor}_i^A(M,N) = 0$ for $i>0$ for any two finitely generated modules.\n\n(this is a theorem by Auslander in the geometric and unramified case and Lichtenbaum in the ramified case. (1) is called the rigidity of Tor).\n\nIt turns out that when $A$ is regular and local (so one can talk about depth), (1) implies\n\n(2) $\\text{depth} (M) + \\text{depth}(N) = \\dim A + \\text{depth} {M\\otimes_AN}$\n\nThis stunning formula looks exactly the same as the property of \"proper intersection\" in intersection theory, except that one uses depth instead of dimension. Note that if $M=A/I, N=A/J$ then $M\\otimes N = A/(I+J)$, which represents the intersection of $V(I)$ and $V(J)$, so this is very geometric.\n\n(3) Talking about intersection theory, by Serre formula for intersection multiplicity, as all the Tors vanish, one can compute the intersection multiplicity of $V(I), V(J)$ by counting the length at the minimal components (i.e. the naive way). So you will have a generalization of Bezout theorem.\n\nFinally, if $V(I)$ and $V(J)$ only intersect at isolated closed points, (2) implies (1) locally on the support of the intersection, so\n\n(4) If $V(I) \\cap V(J)= \\{m_1, \\cdots, m_n \\}$ then $I\\cap J = IJ$ if and only if $A/I, A/J$ are locally Cohen-Macaulay at the points $m_i$s.\n\nYou can find the last statement in Serre's Local Algebra book, V.6, Theorem 4, p 110 of the English version.\n\nPS: Also, David did not mention his own interesting contribution, here.\n\nshare|improve this answer\nNice exhaustive answer, so let me ask a stupid reference. I do not want to prove that if $f,g$ have no common factor in a UFD then $(f)\\cap(g)=(f\\cdot g)$ in a paper I am writing, but I found no explicit reference: do you know any? Adapting Serre's criterion seems a bit overkilling, for a UFD...Thanks. \u2013\u00a0 Filippo Alberto Edoardo Aug 27 '13 at 10:54\nFilippo: Any thing in $(f)\\cap (g)$ would be of the form $fx=gy$. By writing both sides a product of irreducibles one concludes that $g$ divides $x$... \u2013\u00a0 Hailong Dao Aug 28 '13 at 0:47\n...hmm, I guess I agree and that NO reference is by far the best option. I was probably a bit puzzled when I asked, sorry. \u2013\u00a0 Filippo Alberto Edoardo Aug 28 '13 at 4:38\n\nAnswer to the precise question: When $\\mathrm{Tor}^1(A/I, A/J)=0$.\n\nProof: We have the exact sequence $$0 \\to I \\to A \\to A/I \\to 0$$ Tensoring with $A/J$, we get $$0 \\to \\mathrm{Tor}^1(A/I, A/J) \\to I/(I \\cdot J) \\to A/J \\to A/(I+J) \\to 0.$$ The left hand term is $0$ because $A$ is flat as an $A$-module.\n\nNow, what is the kernel of $I \\mapsto A/J$? Clearly, it is $I \\cap J$. So the kernel of $I/(I \\cdot J) \\to A/J$ is $(I \\cap J)/(I \\cdot J)$. We see that $I \\cap J = I \\cdot J$ if and only if $\\mathrm{Tor}^1(A/I, A/J)=0$.\n\nshare|improve this answer\nThe condition with Tor is looking more complicated than the question. \u2013\u00a0 Mark Sapir Dec 13 '10 at 14:22\nBut it is more \"geometric\" since only $V(I)$ and $V(J)$ are involved. \u2013\u00a0 Martin Brandenburg Dec 13 '10 at 14:35\n@Martin: So you think it is better than the question? If we have Groebner bases of $I$, and $J$, can we decide whether $IJ=I\\cap J$? I think that can be an interesting question. In fact I am not sure that David's answer gives any algorithm to decide $IJ=I\\cap J$. It must be decidable, though. \u2013\u00a0 Mark Sapir Dec 13 '10 at 14:47\nI agree that the condition with Tor is more geometric --- it can be viewed as a kind of `purity' of intersection (for instance, two smooth subvarieties of a smooth variety have this property if and only if their intersection has the expected dimension). Is there an accepted name for this condition? \u2013\u00a0 t3suji Dec 13 '10 at 15:38\n@t3suji. Let V and W be closed integral subschemes of a nonsingular quasi-projective irreducible variety. Then, for any irreducible component Z of VcapW, it holds that codim Z <= codim V + codim W. (See Serre's Local Algebra.) We say that V and W intersect properly in Z if equality holds. A stronger condition is being in general position. If V and W are in general position all the higher Tor's vanish. The cycle [VcapW] associated to VcapW is then equal to the product cycle [V][W]. As far as I know, this is standard language in intersection theory for algebraic varieties. \u2013\u00a0 Ari Dec 13 '10 at 17:49\n\nA vague answer to the vague question:\n\nWhen you want the union of $V(I)$ and $V(J)$ to behave well under deformations and to `count with multiplicity', then you may prefeer to use the ideal $IJ$ rather than $I\\cap J$. Let me give an example:\n\nTake $V=V(x)$, $W=V(x-t)$ and $T=V(t)$ denote $V_0:=V\\cap T=V(x,t)=W\\cap T=:W_0$. If you use intersection of ideals for the union of varieties you will get:\n\n$(V\\cup W)\\cap T=V(x^2)$, and\n\n$(V_0\\cup W_0)\\cap T=V(x)$.\n\nWhile using product you will get:\n\n$(V\\cup W)\\cap T=V(x^2)=(V_0\\cup W_0)\\cap T$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/14094/if-a-kerr-newman-black-hole-is-like-a-charged-spinning-heavy-magnet-what-kind/14098\nText:\nTell me more \u00d7\n\nI was reading up on De Sitter spaces, which states that the gravitational effects from a black hole is indistinguishable from any other spherically symmetric mass distribution. This makes a lot of sense to me.\n\nI'm now super curious, can we just formulate all the properties of a black hole beyond the limit at which GR is needed in a completely Maxwellian / Newtonian sense? The Wikipedia article on the Kerr-Newman metric seems to indicate so, but the equations are in terms of the GR metrics. This is not what I want, I want a simplification, a limit-case of that math.\n\nTed Bunn answered a part of my question in Detection of the Electric Charge of a Black Hole. Let me repeat the stupidly simple form of the gravitational and electric field for a black hole beyond the point at which GR is needed.\n\n$$\\vec{g} = \\frac{GM}{r^2} \\hat{r}$$\n\n$$\\vec{E} = \\frac{Q}{4\\pi\\epsilon_0 r^2} \\hat{r}$$\n\nCorrect me if I'm wrong, but these would be a meaningful and accurate approximation in many, in fact, most situations where we would plausibly interact with a black hole (if we were close enough that these are no longer representative, we'd be risking a date with eternity).\n\nQuestion: Fill in the blank; what would the magnetic field $\\vec{B}$ around a black hole be?\n\nHere is why I find it non-trivial: Every magnet in \"our\" world has some significant waist to it. So here is a normal magnet.\n\nnormal magnet\n\nWhat happens when this is a black hole? Would the approximation for $\\vec{B}$ that I'm asking for have all the magnetic field lines pass through the singularity? Or would they all pass through the event horizon radius but not necessarily a single point?\n\nI think most people who have understood this already, but ideally the answer would use the 3 fundamental metrics of a black hole. Mass $M$, charge $Q$, and angular momentum $L$. The prior equations for gravity and electric field already fit this criteria. So the answer I'm looking for should be doable in the following form.\n\n$$\\vec{B} = f \\left( M, Q, L, \\vec{r} \\right) $$\n\nshare|improve this question\nKeep in mind that rotating black holes won't have a single point singularity, but in fact will have a ring singularity, but that is a minor fact. \u2013\u00a0 Benjamin Horowitz Aug 29 '11 at 3:46\n@Benjamin ooooh, you're right! That had not occurred to me. Well that's already on the way to answering the question! \u2013\u00a0 AlanSE Aug 29 '11 at 3:53\nYou should first ask yourself what you mean by a magnetic field. Maxwell theory is inherently Lorentz invariant, and it is well known that (even just in special relativity) changing the reference frame can change the measured electric/magnetic fields.\u2026 If you fixed your coordinates in Kerr-Schild form, doesn't the Kerr-Newman article you linked to already give you an expression of the magnetic field? \u2013\u00a0 Willie Wong Aug 29 '11 at 14:46\n@Willie I believe that I can very explicitly define the reference frame in question here, which is the frame in which $\\vec{p}=0$ for the BH and at a distance from the black hole at which $GM/r \\ll c^2$. In that case, we can ditch the GR coordinates. So maybe we would be left with just the classical perfect magnetic dipole equation (which would be fine). But even IF this is the case, I don't know what the magnetic moment is since a self-gravitating loop singularity is impossible with Newtonian gravity. \u2013\u00a0 AlanSE Aug 29 '11 at 15:22\nThe answer is the same as for any other current loop with a magnetic dipole. There is nothing special about black holes. You just need the dipole moment to get the far field. The field lines end on the horizon for an external observer. \u2013\u00a0 Ron Maimon Sep 4 '11 at 2:10\nadd comment\n\n2 Answers\n\nup vote 4 down vote accepted\n\nIt's a little tricky giving a formal answer to this, but here is a sketch:. The electromagnetic potential of the Kerr-Newman hole is given by:\n\n$$A_{a}dx^{a}=-\\frac{Qr}{r^{2}+a^{2}\\cos^{2}\\theta}\\left(dt-a \\sin^{2}\\theta d\\phi\\right)$$\n\nThis field will acquire a magnetic field from the fact that $\\frac{\\partial A_{\\phi}}{\\partial r}$ and $\\frac{\\partial A_{\\phi}}{\\partial \\theta}$ are both nonzero. The problem is that the magnetic field, when re-phrased in terms of vectors and not one-forms, will fall off as $\\frac{1}{r^{3}}$. At that point, if we're keeping terms that fall off that quickly, then we need to have a discussion about that asymptotic form of the metric you imply above, because there are terms in the metric that we need to keep, arising from frame-dragging effects of the black hole. If you want, I can go into more detail.\n\n\nOK, so once we have the vector potential, we can calculate the magnetic field according to the rule: $B^{i}=\\frac{1}{\\sqrt{\\left|g\\right|}}\\epsilon^{ijk}\\left(\\frac{\\partial A_{j}}{dx^{k}}-\\frac{\\partial A_{k}}{dx^{j}}\\right)$, where $\\epsilon^{r\\theta\\phi}=1$, $\\epsilon^{ijk}=-\\epsilon^{jik}=-\\epsilon^{ikj}$ and $\\epsilon^{ijk}=0$ if $i=j$, $i=k$ or $j=k$. So, now, we just plug in the above expression for the spatial components of $A_{a}$, the metric tensor, and turn the crank.\n\nAfter doing this, and taking the limit that $r$ is larger than everything else, we find that\n\n$${\\vec B}=\\frac{2Qa\\cos\\theta}{r^{3}}{\\hat e}_{r} + \\frac{Qa \\sin \\theta}{r^{3}}{\\hat e}_{\\theta}$$\n\nSensibly, this is zero if either $Q=0$ or $a=0$. And I will once again assert that there are $\\frac{1}{r^{3}}$ corrections to the gravitational force that must be taken into account in your high $r$ limit if you are going to keep this magnetic field.\n\nshare|improve this answer\nI'm a little confused by the occurrence of $d\\phi$, since I'd imagine that the solution will have rotational symmetry about the axis of rotation, GR or not. I think that solving for the one-form of magnetic scalar potential would be sufficient, since I think $\\vec{B}$ follows directly from that unless I completely don't know what I'm talking about. But for a classical magnetic dipole, these things would fall off as $1/r^3$, although there are other terms. Right now I'm most interested to ask if there should be anything fundamentally different for a BH. \u2013\u00a0 AlanSE Aug 29 '11 at 14:57\nfall off as $\\frac{1}{r^{3}}$ though, so you would need to keep those if you are going to keep the magnetic field. \u2013\u00a0 Jerry Schirmer Aug 29 '11 at 15:27\n@Zasso: the field is axially symmetric. But unlike the case of spherical symmetry, axially symmetric vector fields can have components tangent to the circle action. Just imagine the magnetic field generated by an infinitely long wire carrying current along the $z$ axis. For the multipole moments, there is a paper by Sotiriou et al in Class. Quan. Gravitiy in 2004 that does some of these computations. (For example in regards to the Gravitomagnetic effect that Jerry mentioned.) \u2013\u00a0 Willie Wong Aug 29 '11 at 15:28\ncan you please fix the answer to put the correct falloff from the comments in? It's like any other magnet. \u2013\u00a0 Ron Maimon Sep 3 '11 at 22:40\n@Ron I know, and I thought someone would see this a an easy 50 reputation... I like how you said it \"The answer is the same as for any other current loop with a magnetic dipole. There is nothing special about black holes.\" However, that statement is novel to me, and I want to select an answer that answers the question and is written by someone with a background in this (not me). \u2013\u00a0 AlanSE Sep 4 '11 at 20:08\nshow 4 more comments\n\nI'm going to answer this question with the a priori assumption that if some amount of matter collapses with a given field, then those fields are maintained as it collapses into a black hole. I see nothing to refute this assumption, but the validity of it is beyond my knowledge. As I was pointing out before, this sufficiently far from the singularity such that GR specific concepts aren't needed. The cutoff for this is formalized by the following condition.\n\n$$GM/r \\ll c^2/2$$\n\nAgain, we have $Q$, $M$, and $L$ to describe the black hole. Obviously the black hole, and the singularity itself is some amount of mass rotating. I find this problematic due to difficulties with loop singularities in a completely Newtonian sense. Anyway, I need to make statements about the angular momentum.\n\n$$L = M a V$$\n\nThis is to say, the angular momentum is due to the fact that the mass of the singularity is located at some position away from the axis of rotation, $a$ and spinning at speed $V$. With the above statement we can make some meaningful statement about the magnetic moment, $\\vec{m}$. I'll assume the axis of rotation is the z-axis and denote that unit vector with $\\hat{k}$. The following equation comes from Wikipedia. I will then combine this with the prior equation. Doing this algebra makes the assumption that the mass has the same distribution as the charge.\n\n$$\\vec{m} = \\frac{1}{2} Q a V \\hat{k}$$\n\n$$\\vec{m} = \\frac{Q L}{2 M} \\hat{k} $$\n\nThis does make intuitive sense to me. The more angular momentum, the stronger I expect the magnetic field from it to be. Also, since angular momentum has mass as a component, we basically have to divide that back out. Next, I would just use the equation for a perfect magnetic dipole. This is to say the waist is zero, basically assuming it's a singularity. I think this would be fine unless the rotational energy was a significant part of the energy contained in it. I'll just ignore the delta function for the infinite magnetic field at the origin, because this isn't valid there anyway.\n\n$$\\vec{B}(\\vec{m}, \\vec{r}) = \\frac {\\mu_0} {4\\pi r^3} \\left(3(\\vec{m}\\cdot\\hat{r})\\hat{r}-\\vec{m}\\right)$$\n\n$$\\vec{B}(M,Q,L,\\vec{r}) = \\frac {\\mu_0 Q L} {8 \\pi r^3 M} \\left(3 \\frac{r_z}{r} \\hat{r}-\\hat{k}\\right)$$\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.hackmath.net/en/math-problem/1271?tag_id=124_9\nText:\nDiagonals in the diamond\n\nThe length of one diagonal in diamond is 24 cm greater than the length of the second diagonal and diamond area is 50 m2. Determine the sizes of the diagonals.\n\nCorrect result:\n\nu1 = \u00a01012.07 cm\nu2 = \u00a0988.07 cm\n\n\nu2=u124\u00a0S=u1u22=u1(u124)2=50\u00a0m2=500000\u00a0cm2\u00a02S=u1224u1\u00a0u224u1000000=0\u00a0\u00a0a=1;b=24;c=1000000\u00a0D=b24ac=24241(1000000)=4000576\u00a0D>0\u00a0\u00a0u1,2=b\u00b1D2a=24\u00b140005762=24\u00b18625092\u00a0u1,2=12\u00b11000.0719974082\u00a0u1=1012.0719974082\u00a0u2=988.07199740819\u00a0\u00a0\u00a0Factored\u00a0form\u00a0of\u00a0the\u00a0equation:\u00a0\u00a0(u1012.0719974082)(u+988.07199740819)=0\u00a0\u00a0u>0\u00a0u1=1012.07\u00a0cmu_2 = u_1 - 24 \\ \\\\ S = \\dfrac{u_1 \\cdot u_2}{2 } = \\dfrac{u_1 \\cdot (u_1-24)}{2 } = 50 \\ m^2 = 500000 \\ cm^2 \\ \\\\ 2S = u_1^2-24 u_1 \\ \\\\ u^2 -24u -1000000 =0 \\ \\\\ \\ \\\\ a=1; b=-24; c=-1000000 \\ \\\\ D = b^2 - 4ac = 24^2 - 4\\cdot 1 \\cdot (-1000000) = 4000576 \\ \\\\ D>0 \\ \\\\ \\ \\\\ u_{1,2} = \\dfrac{ -b \\pm \\sqrt{ D } }{ 2a } = \\dfrac{ 24 \\pm \\sqrt{ 4000576 } }{ 2 } = \\dfrac{ 24 \\pm 8 \\sqrt{ 62509 } }{ 2 } \\ \\\\ u_{1,2} = 12 \\pm 1000.0719974082 \\ \\\\ u_{1} = 1012.0719974082 \\ \\\\ u_{2} = -988.07199740819 \\ \\\\ \\ \\\\ \\text{ Factored form of the equation: } \\ \\\\ (u -1012.0719974082) (u +988.07199740819) = 0 \\ \\\\ \\ \\\\ u>0 \\ \\\\ u_1 = 1012.07 \\ \\text{cm}\nu2=u124=988.07\u00a0cmu_2 = u_1 - 24 = 988.07 \\ \\text{cm}\n\n\nShowing 2 comments:\nMath student\nHow comes about U1 and U2\n\nDr Math\nu1, u2 = unknown diagonals.\n\n\nTips to related online calculators\nLooking for help with calculating roots of a quadratic equation?\nDo you want to convert area units?\nDo you want to convert length units?\n\n\nNext similar math problems:\n\n  \u2022 Alopecia\n    alopecia Medical literature indicates that 45% of men suffer from alopecia. For random sample of 8 men, calculate the probability that: (a) exactly four men suffer from alopecia. (b) at most two men suffer from alopecia.\n  \u2022 Assembly time\n    mean_normal The assembly time for the toy follows a normal distribution with a mean of 75 minutes and a standard deviation of 9 minutes. The company closes at 5 pm every day. If one starts assembling at 4 pm what is the probability that he will finish before the comp\n  \u2022 Pascal's law\n    lis Please calculate according to Pascal's law. Krupp's machines were known for their large size. In 1861, a blacksmith's steam hydraulic press was put into operation in Essen. What was the cross-sectional area of the larger piston if a compressive force of 1\n  \u2022 RC time constant\n    capacitor You introduced 1 Coulomb worth of electrons into the inner volume of a dielectric material with \u03f5r=6. 30 minutes later, you found that only 36.79% of the electrons were in the inner volume. Determine the conductivity \u03c3 of the dielectric material.\n  \u2022 Decibel\n    tv_1 By what percentage does the sound intensity increase if the sound intensity level increases by 1 dB?\n  \u2022 Natural fertilizer\n    garden_1 The rectangular garden measuring 120m and 60m was fertilized with 16kg of natural fertilizer. Natural fertilizer contains 45% organic matter. How much organic matter falls on 1 m2 of garden?\n  \u2022 Sphere in cone\n  \u2022 Hiking trip\n    walker Rosie went on a hiking trip. The first day she walked 18kilometers. Each day since she walked 90 percent of what she walked the day before. What is the total distance Rosie has traveled by the end of the 10th day? Round your final answer to the nearest ki\n  \u2022 2 cyclists and car\n    cyclist_1 One cyclist rides at a constant speed over a bridge. It is 100 meters long. When he is 40 meters behind him, he meets an oncoming cyclist who is riding at the same speed. The car travels along the bridge in the same direction as the first cyclist at a spe\n  \u2022 Water mixing\n    watermixing We have 520 ml of hot water and 640 ml of water at 48\u00b0C. What is the temperature of approximately hot water when the resulting mixture has a temperature of 65\u00b0C?\n  \u2022 Closed circuit\n  \u2022 Energy consumption\n    elektromer The device is connected to 230V and draws 3.5A current. Power consumption is 1932kJ. How many minutes has this device been in operation?\n  \u2022 Permille of alcohol\n    heart I have 2 per mille of alcohol in my blood. How many milliliters is it when I have 5 liters of blood?\n  \u2022 Wall thickness\n    sphere_Nickel The hollow metal ball has an outside diameter of 40 cm. Determine the wall thickness if the weight is 25 kg and the metal density is 8.45 g/cm3.\n  \u2022 What percentage\n    astronaut What percentage of the Earth\u2019s surface is seen by an astronaut from a height of h = 350 km. Take the Earth as a sphere with the radius R = 6370 km\n  \u2022 Self-oscillation period\n    lambda The water in the vessel carried by the boy has a self-oscillation period of 0.8 s. What is the size of the boy's movement speed when the length of the boy's step is 60 cm? Give the result in m/s.\n  \u2022 Power line pole\n    pole From point A, the power line pole is seen at an angle of 18 degrees. From point B to which we get when going from point A 30m away from the column at an angle of 10 degrees. Find the height of the power pole."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/88180/how-to-determine-the-maximum-valued-play-in-rummikub/128553\nText:\nThis question is meant as a follow-up this question and my answer here.\n\nThe question asked multiple questions about algorithms for playing Rummikub and my answer provided an algorithm that, given a set of Rummikub pieces $S$, determines whether they can be arranged as a set of valid plays (called an arrangement).\n\nHowever, when we actually play Rummikub, the situation is slightly different: there is a given board state $B$ and a hand $H$. We want to empty our hand by adding pieces to the board. We assume the board $B$ has a valid arrangement.\n\nSo, the problem now becomes:\n\n  1. Does there exists a subcollection $S\\subseteq H$ such that there exists a valid arrangement for $S \\cup B$; and\n  2. What is the largest such subcollection $S$ ?\n\nObviously, we can iterate over every subcollection $S$ of $H$ and test validity for each of them, but that is inefficient. To make precise what I mean by 'efficient' here, consider the game to be played with $3,4$ or $5$ colours and the numbers $1\\ldots n$ for each color.\n\nDoes there exist an polynomial (in $n$) time algorithm that solves problem 1 or 2? Or this 1 or 2 intractable (e.g. NP-hard)? Feel free ignore complications such as jokers or assume all tiles are distinct.\n\n\nI will describe a polynomial time algorithm that solves both problem 1 and problem 2. I learned of the algorithm from this paper.\n\nI am going to make the following assumptions:\n\n  1. No jokers (adding them is a small change).\n  2. There are only four colors.\n  3. There are at most two copies of each tile.\n  4. The face values range from 1 to 13.\n\nTo find the maximum value play, complete these steps:\n\n  1. Recursively enumerate every valid configuration that can be built from tiles in $hand \\cup board$\n  2. Ignore any configuration where not all tiles from board are used (the board constraint).\n  3. Of the visited configurations, choose one with maximal score. Where score is the sum of values of tiles played or number of tiles played (whichever you prefer to maximize).\n\nStep 1\n\nHow do we build a configuration from a given set of tiles? We proceed by playing tiles in order of their face value. First play all tiles of value 1. Then play all tiles of value 2, and so on. We can visit every configuration by recursing for each way to play tiles of the current value.\n\nLet's look at the different ways to form runs. Assume we are playing tiles of value 5, that we have a red 5, and that we will use it in a run. Our tile can be used to start a new run or it can be used to extend any existing run (or partial run) that contains a red 4. If we extend an existing run then there is at most two choices for where to put it since there is at most two runs that contain a red 4 (there are at most two red 4's). If we have two copies of our tile then we can extend or start two runs.\n\nIn forming runs there is an optimization that can be made. We should not start a new run if we know in advance that there is no way we could finish the run. This can be implemented by counting the number of tiles of greater value.\n\nNow on to forming groups. For a given way to play runs we should recurse for every way to play groups using the remaining tiles since we want to enumerate all possible valid configurations. However this would be very slow and in the end we really only care about finding the best configuration. So instead we recurse for only the best way to play groups. Notice, for a given choice of how to form runs, how we form groups does not effect what choices we have in forming groups and runs using tiles of greater value. So given a choice of how to form runs, we should use as many of the remaining tiles in groups as possible. To do this enumerate all ways to pick groups and choose the one containing the most tiles.\n\nFinally after choosing how to play all tiles, discard any tile not used in a valid set.\n\nStep 2\n\nHow do we ensure every valid configuration we visit uses all tiles from board? After choosing how to play all tiles and discarding invalid sets, do not accept the configuration as valid if not all tiles from board are contained in it. This is correct but it would be inefficient. Instead we check at each step, after choosing how to form runs and groups, whether we have used enough tiles of the current value. For example, if the current value is 5 and we have chosen a way to play the red 5's, then we need to check if we have played at least as many red 5's as are contained in board. If we have not, then we choose another way to play red 5's before moving to the next value. Note if we have played $n+m$ red 5's where $n$ is the number of red 5's in board, then we have played $m$ red 5's from our hand. If there is no way to play red 5's (including not playing red 5's) then this branch of the recursion tree does not lead to a valid configuration and we should return.\n\nHowever, these checks are not sufficient to guarantee we never violate the board constraint. Why? Because when forming runs using tiles of value 6 we can choose to not extend a run that has length one or two. The tiles in that run would have to be discarded which could violate the board constraint due to not having enough 4's or 5's. In this case we would not be able to catch this error because so far we only know how to check the board constraint for the current value. The way to fix this is to keep count of how many tiles we have played of the previous two values (for each color separately). Then when forming runs with red 6's we can check if not extending a red run (of length one or two) puts us in a state where not enough red 4's or 5's have been played. Note that if a run has length at least three then not extending it does not force us to discard any tiles and so can not violate the board constraint (so we do not have to check in this case).\n\nWe do not have to do anything special for choosing groups. In the following proof of this fact I will use 'configuration' to mean a set of groups. Also, I will use 'maximal configuration' to mean a configuration containing the most tiles possible among all configurations where tiles come from some set $S$. Note that if we have $n$ tiles of color $c$ in a configuration then there are at least $n$ groups in the configuration. Also if a subset of the available tiles can be arranged into a configuration of $n$ groups then a maximal configuration contains at least $n$ groups (there are at most three groups, if using two jokers, and at most two groups of four in any configuration). Now assume a subset $S$ of the available tiles can be arranged into a configuration with $n$ tiles of color $c$ and that we have arranged some maximal configuration $M$. If $M$ contains $k < n$ tiles of color $c$ then $M$ contains at least $n - k$ groups which do not contain a tile of color $c$ (groups of size three). In this case we can add $n-k$ tiles of color $c$ from $S$ to $n-k$ groups of three in $M$ which contradicts that $M$ is a maximal configuration. Thus $k\\geq n$. This shows that if there are $n$ tiles of color $c$ in the set of tiles of current value that remain after playing runs and if those $n$ tiles can be played in some configuration then every maximal configuration contains those $n$ tiles. So choosing a maximal group guarantees that we satisfy the board constraint if it is possible to satisfy the board constraint by playing groups.\n\nStep 3\n\nA simple way to do step 3 would be to compute the score of a configuration when you accept it as valid then update some global variable with the configuration of max score ('configuration' meaning set of runs & groups). But this solves the same subproblem many times (compute score for sets common to more than one valid configuration). Instead make use of the fact that we know at each step how many tiles of the current value we will play. Multiply this number of tiles by the current value to find how much these choices contribute to the score. Sum the contribution with the return value of the recursive call and then update the max if necessary. Instead of updating a global max variable, we will update a local (available only in scope of recursive call) max variable which will hold the score of the best way to play tiles of the current value. The recursive function should return the value of this max variable. After attempting to play tiles of current value in all ways, if no play leads to a valid configuration (every play violates the board constraint), then return $-\\infty$. Returning $-\\infty$ is useful because even if we have a high contribution (from runs & groups), adding that contribution to $-\\infty$ is still $-\\infty$.\n\nNote that we cannot know the contribution of extending a length zero or length one run. This is because, when playing tiles of the next greater value, we may choose to not extend a run of length one or two and so the tiles in those runs would be discarded. Instead we say the contribution of extending a length zero run (starting a run) or length one run is 0. When a run is extended from length two to length three then we say it's contribution is the sum of the values of the three tiles in the run. When extending a run that has length at least three then the contribution is just the value of the tile played into the run.\n\nThere are other things you can do here too. For example, It may be desireable to find a configuration that is maximally similar to the previous configuration of the board. This can be done by maximizing score and then maximizing some similarity function. This would inflate the dp table size by two.\n\nState, Memoization, & Time Complexity\n\nThe only state we need to know is the current value and the length of the runs that we could possibly extend. The length of runs can be recorded in a list of pairs, for example [(0,0), (0,0), (0,1), (0,3)], where the $i^{th}$ pair is the length of the two possible runs of color $i$. The order of the numbers in the pairs does not matter so the above state is the same as [(0,0), (0,0), (1,0), (0,3)]. A particular extension (i.e. child state) of those runs could be [(1,1), (0,1), (0,0), (1,3)]. Also, we never need to know if a run is longer than three tiles (so an extension of (3,3) is (3,3)). We will only need to distinguish between when a run is of length 0, 1, 2, or 3. A benefit of this is the size of the state space is reduced which makes memoization much more effective.\n\nThis algorithm is exponential in the number of distinct values in $hand \\cup board$. However it can be made linear by memoization.\n\nTo memoize, store in a dictionary the key-value pair key=(currentTileValue, runLengthsList) and value=localMaxValue. Other inputs like the board, $hand\\cup board$, number of jokers available, number of tiles played per color on the last two turns, etc, are just used to bound the search and so we do not need to memoize them.\n\nHopefully I have been able to effectively communicate most of the ideas of this algorithm. For more details see the paper and my implementation. Note, the paper claims that the dynamic programming state space (number of unique inputs, max size of dp table needed, i think) is of size $n * k * f(m)$. Where $n$ is the number of possible tiles, $k$ is the number of colors, $m$ is the max number of copies of a tile, and $f(x)$ computes 4 choose $x$ with replacement. This might be a typo, I do not know. In any case the state space of the algorithm I've described is $n * f(m)^k$.\n\nNote both the paper and my implementation refer to what you call the board as the table.\n\nBy the way, before learning of this algorithm, I tried to understand the algorithm you gave here. I could not understand how to deal with duplicates. I can see how breaking into sublists, ordering those sublists, and then combining them into a single list again would allow your recursive formula to handle duplicates for some inputs. But you did not describe how exactly to break the original list into sublists nor how to combine them into a single list again. For some inputs, your recursive formula will give different answers depending on how sublists are split/recombined. Unfortunately, I do not have enough stackoverflow reputation to comment on your answer to ask for clarification. Thanks for giving the answer though, your recursive formula is nice.\n\n\nI did not read your long answer at the linked thread. However, you did mention proceeding in order of number and using a recursive relation. You can do the same here. Define $Q(x,k,m)$ to be true iff there is a valid grouping $G$ of $B\u222aS$ for some $S\u2286H$ such that exactly $k$ pieces in $S$ have numbers at most $m$ and $x$ is the multiset of colours of runs in $G$ that include the number $m$. Since there are a fixed number $c$ of colours, $x$ is encoded as a $c$-tuple of naturals with sum $O(n)$. Each state transition either stops or extends each of these runs (by adding an $m{+}1$), and may also form groups of $m{+}1$, such that all $m{+}1$-tiles from $B$ with number are used (either in extending runs or in forming groups), and the number of $m{+}1$-tiles used from $H$ are reflected in the change in $k$. I will leave the details as an exercise for you.\n\nAlso, there seems to be an incorrect assumption in your question, because the actual games rules do not allow arbitrary rearrangement of the played tiles. For instance, if the played tiles are the three sets 1a 1b 1c + 2a 2b 2c + 3a 3b 3c, then you cannot play 4a by rearranging the tiles to form 1a 2a 3a 4a + 1b 2b 3b + 1c 2c 3c. In other words, a solution to your question does not provide a solution to finding the maximal number of tiles that can be played given an actual game position. I did not check but I do think there is an algorithm along the same lines as above to solve that actual game-based problem.\n\n  \u2022 $\\begingroup$ This does not assume all tiles are distinct, and furthermore a slight modification can also handle any number of jokers. $\\endgroup$ \u2013\u00a0user21820 Jul 20 '20 at 16:33\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/263262/dodgy-turing-degrees\nText:\nThis question was originally asked and bountied at MSE, but received no answer there, so I'm asking it again here.\n\nBelow, I'm specifically interested in weak truth table (wtt) reducibility, but other reducibilities between truth table and Turing are interesting to me, too, if the question happens to be easier to answer for them.\n\nLet $d$ be a Turing degree, and fix a representative $X\\in d$. Say $d$ is (wtt-)dodgy if there is some $d$-computable functional $F=\\Phi_e^{X\\oplus -}$ such that for all $Y$ with $deg(Y)=d$, we have\n\n  \u2022 $\\Phi_e^{X\\oplus Y}=F(Y)$ is total,\n\n  \u2022 $F(Y)\\equiv_TY$, but\n\n  \u2022 $F(Y)\\not\\le_{wtt}Y$.\n\n(Note that I demand nothing about $F(Z)$ for $Z\\not\\in d$; in particular, $F$ only needs to output reals when fed elements of $d$, it may fail to be total elsewhere.)\n\nDodginess is most interesting for \"sufficiently large\" degrees - for example, above $0'$ every Turing degree splits into infinitely many $wtt$-degrees, so the question is nontrivial. Dodginess is a reasonably definable property, so by Martin's Cone Theorem, either every sufficiently large degree is dodgy or every sufficiently large degree is not dodgy. My question is, Which of these two holds?\n\nMy feeling is that a fairly simple trick should show that every sufficiently large (indeed, $\\ge_T0'$) degree will not be dodgy; however, I don't see how to do this. In particular, the Recursion Theorem doesn't seem to immediately kill it: suppose $d$ is a sufficiently large degree, and fix $X\\in d$. Then $F$ can be identified with a total computable function $g$: $F(\\Phi_e^X)\\sim\\Phi_{g(e)}^X$. Now $g$ is total computable, so it has a fixed point $c$: $\\Phi_c^X\\sim \\Phi_{g(c)}^X$. However, there's no reason to believe that $\\Phi_c^X$ is total, let alone an element of $d$, so I don't see how to get any leverage here.\n\n\nEvery sufficiently large degree is dodgy. Assuming $X \\geq_T \\emptyset'$, we can define $F(Y)$ as follows. First compute a set $Z$ from $X$ and $Y$: Given $n = \\langle i,j \\rangle$, ask $X$ whether $\\Phi_i(n)$ converges. If not then $Z(n)=0$. If yes then ask $X$ whether $\\Phi_j^{Y \\upharpoonright \\Phi_i(n)}(n)$ converges. If not then $Z(n)=0$. If yes then $Z(n)=1-\\Phi_j^{Y \\upharpoonright \\Phi_i(n)}(n)$. This ensures that $Z \\nleq_{wtt} Y$. Now let $F(Y)=X \\oplus Z$. Then $F$ is total and $F(Y) \\nleq_{wtt} Y$ for all $Y$, and if $Y \\equiv_T X$ then also $F(Y) \\equiv_T Y$.\n\n  \u2022 $\\begingroup$ Thanks! Do you know of any reducibilities stronger than Turing (but, necessarily, weaker than wtt) for which the corresponding notion of dodginess might fail on a cone? $\\endgroup$ \u2013\u00a0Noah Schweber Mar 1 '17 at 21:54\n  \u2022 $\\begingroup$ No, I can't think of any. $\\endgroup$ \u2013\u00a0Denis Hirschfeldt Mar 1 '17 at 23:21\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/342299/index-and-congruence-subgroup-from-scaling-variables-of-jacobi-form\nText:\nLet $J_{k,m}(N)$ be the space of Jacobi forms of weight $k$, index $m$, and congruence subgroup $\\Gamma_{0}(N) \\rtimes \\mathbb{Z}^{2}$. I do not believe it is relevant here to specify what type of Jacobi form (weak, holomorphic, etc). I can't find hardly any references on how the index, and the congruence subgroup change when scaling the variables. So my question is simply:\n\nGiven $\\varphi(\\tau, z) \\in J_{k,m}(1)$, what is the index and congruence subgroup of the Jacobi form $$\\psi_{d_{1}, d_{2}}(\\tau, z) = \\varphi(d_{1} \\tau, d_{2} z)$$ for general $d_{1}, d_{2} \\in \\mathbb{Z}_{>0}$?\n\nThere are a few relevant things I know. For an ordinary modular form $f(\\tau)$ of weight $k$ on $SL_{2}(\\mathbb{Z})$, it's straightforward to use the \"slash operator\" to show that $f(d \\tau)$ is a weight $k$ form on $\\Gamma_{0}(d)$. (See Exercise 1.2.11 of Diamond and Shurman)\n\nI also know that in the case of $d_{1}=1$, $\\varphi(\\tau, dz) \\in J_{k, d^{2}m}(1)$. This is easy to show from the transformations, and moreover it coincides with a well-known Hecke-like operator\n\n$$U_{d} : J_{k,m}(1) \\to J_{k, d^{2}m}(1).$$\n\nI'm unsure what the right statement is for general $d_{1}, d_{2}$ specifically perhaps $\\varphi(d \\tau, z)$ and $\\varphi(d \\tau, d z)$.\n\nPart of what's confusing me is that if $F(\\tau, z, \\sigma)$ is a weight $k$, degree 2 Siegel modular form, then it has a Fourier-Jacobi expansion in $Q = e^{2 \\pi i \\sigma}$:\n\n$$F(\\tau, z, \\sigma) = \\sum_{m=0}^{\\infty} Q^{m} \\varphi_{k,m}(\\tau, z), \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\varphi_{k,m} \\in J_{k,m}(1)$$\n\nI believe it's true that $F(d\\tau, dz, d\\sigma)$ is a weight $k$ form for the degree 2 congruence subgroup $\\Gamma^{(2)}_{0}(d) \\subset Sp_{4}(\\mathbb{Z})$. So we have a Fourier-Jacobi expansion:\n\n$$F(d\\tau, dz, d\\sigma) = \\sum_{m=0}^{\\infty} Q^{dm} \\varphi_{k,m}(d\\tau, dz).$$\n\nBut I think we need the index of the Jacobi forms to match the exponent of $Q$. So somehow, $\\varphi_{k,m}(d\\tau, dz) \\in J_{k, dm}(d)$? So the index is multiplied by $d$, not $d^{2}$ in this case.\n\n\n$\\varphi(d_1\\tau,d_2 z)$ will generally be a Jacobi form for a congruence subgroup of this kind only when $d_1 | d_2$. Otherwise it will not transform correctly under $(\\tau,z) \\mapsto (\\tau,z+\\tau)$.\n\nIn this case its congruence group is $\\Gamma_0(d_1) \\rtimes \\mathbb{Z}^2$ and its index is $m\\frac{d_2^2}{d_1}$, as you can see using the Fourier-Jacobi expansions (the index indeed matches the exponent) or by checking the transformations directly.\n\n  \u2022 $\\begingroup$ This is great, thanks a lot! Maybe I'm just not looking in the right places, but it would be nice if this was remarked in the literature somewhere. By the way, you say a \"congruence subgroup of this kind.\" Is something like, say, $\\varphi(d\\tau, z)$ possibly a Jacobi form for some more exotic subgroup? $\\endgroup$ \u2013\u00a0Benighted Sep 25 '19 at 16:18\n  \u2022 1\n    $\\begingroup$ @Benighted Sure, you'll have to replace the $\\mathbb{Z}^2$ by something else, like $d \\mathbb{Z}^2$, and the index will no longer be an integer. $\\endgroup$ \u2013\u00a0user146384 Sep 30 '19 at 7:54\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/567929/heat-absorbed-from-a-reservoir-by-a-moving-object\nText:\nImagine two bodies, say a body A with an infinite heat capacity(reservoir) and the another body B with some finite heat capacity($C = \\alpha \\ T_{B}(t) $).\n\nThey come into direct contact with each other for a limited time, as B moves along the surface of A with a constant velocity v.\n\nGiven the thermal conductivity $\\kappa$ of the moving object B, the temperatures of the reservoir $T_{A}$ and the moving object $T_{B}(t)$.\n\nHow to calculate the amount of heat transferred in the process as a function of time?\n\n  \u2022 $\\begingroup$ What does $C \\propto \\alpha \\ T_{B}(t)$ mean precisely? What is $\\alpha$? $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 17:27\n  \u2022 $\\begingroup$ actually $\\alpha $ is just a constant that depends on the type of the material of B $\\endgroup$ \u2013\u00a0EverydayFoolish Jul 24 '20 at 20:01\n  \u2022 $\\begingroup$ In thermodynamics we normally write: $\\Delta Q=mc_p\\Delta T$: the heat absorbed (or shed) by a change of temperature of an object of mass $m$ and specific heat capacity $c_p$. $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 20:06\n  \u2022 $\\begingroup$ I made another edit. $\\endgroup$ \u2013\u00a0Gert Jul 24 '20 at 22:14\n\n\nThe calculation will first of all depend on the Biot Number:\n\n\nwhere $h$ is the convective heat transfer coefficient, $\\kappa$ the thermal conductivity and $L$ a characteristic length of the object (a length or diameter, typically)\n\n  1. Low Biot Number:\n\nThe interior of the object may be considered of uniform temperature distribution (no or low temperature gradient inside the object $B$)\n\nHere lumped thermal analysis can be used by means of Newton's Law of Cooling. It states:\n\n$$\\dot{Q}=hA[T(t)-T_A]=hA\\Delta T(t)\\tag{1}$$ where:\n\n  \u2022 $\\dot{Q}$ is the rate of heat transfer out of the body ($B$)\n  \u2022 $A$ is the surface area shared by $A$ and $B$\n  \u2022 $T(t)$ the temperature of body $B$ and $T_A$ the (constant) temperature of $A$\n\nNote that due to cooling (or heating) of $B$, $\\Delta T(t)\\neq \\text{constant}$. To calculate the heat transfer in a given amount of time, the evolution of $T(t)$ has to be (and can be) calculated.\n\n$\\text{NLC}$ is mathematically simple to use.\n\nEq. $(1)$ is a separable differential equation that solves to:\n\n$$\\Delta T(t)=(T_0-T_A)e^{-kt}\\text{ where }k=\\frac{hA}{mc_p}$$\n\n($T_0$ is the initial temperature of $B$)\n\nSo with $(1)$ we get:\n\n\nThe heat transferred in a time-interval $\\Delta t$ is:\n\n$$Q=\\int_0^{\\Delta t}hA(T_0-T_A)e^{-kt}\\text{d}t$$\n\n\n$$Q=-mc_p(T_0-T_A) e^{-k\\Delta t}$$\n\n  1. High Biot Number:\n\nHere significant temperature gradients in the body $B$ must be assumed and heat conduction will play a significant part in the heat transfer process.\n\nThe 'go to' equation here is Fourier's Heat Equation:\n\n$$\\frac{\\partial T}{\\partial t}=\\alpha \\nabla^2T\\text{ with }\\alpha=\\frac{\\kappa}{c_p\\rho}$$\n\nwhich is a partial differential equation (PDE) and will require boundary conditions and an initial condition. From the obtained spatial distribution of temperature can then be calculated the heat transferred in a given time-interval.\n\nIn many cases solving Fourier's equation is mathematically very demanding, requiring higher calculus. Analytical solutions are really only possible for simple geometries (rod, plate, sphere for instance)\n\nAn example for an internally heated sphere can be found here."}
{"text": "Retrieved from https://cs.stackexchange.com/questions/47101/maximum-independent-nodes-subset-algorithm-with-strong-constraint\nText:\nI've a tree with weighed nodes, the problem is to flag a subset of nodes with the following constraints:\n\n  \u2022 The selected nodes must be the optimal solution (maximal sum of weight).\n  \u2022 If one node is flagged no adjacent nodes can be flagged.\n  \u2022 If a node is flagged it will be called: \"directly controlled\", the adjacent nodes instead will be called: \"indirectly controlled\", all nodes must be directly or indirectly controlled.\n\nI think is a dynamic programming problem (a greedy approach didn't find always a optimal solution), the first two constraints are a typical maximum independent subset problems, but i cannot find a solution with the third constraint included. Any idea? Thanks\n\n\nA set satisfying condition (3) is known as a dominating set. The exercise asks for a maximum weight dominating independent set.\n\nIf all node weights are positive, then every optimal solution is automatically a dominating set (why?), regardless of whether the graph is a tree or not. In the more general case in which negative weights are allowed, you can use a standard dynamic programming approach. Root the tree at an arbitrary node, and for every subtree rooted at some internal node $v$, compute the maximum weight independent set in the following three cases:\n\n  \u2022 The independent set is dominating and includes $v$.\n  \u2022 The independent set is dominating and doesn't include $v$.\n  \u2022 The independent set is dominating if $v$ is removed (it is allowed to dominate $v$ as well), and doesn't include $v$.\n\nI'll let you complete the details.\n\n  \u2022 $\\begingroup$ Thanks for your help. My tree have all positive weights, i've tried the independent set algorithm with some particular tree and, as you said, is always a dominating set, so intuitively i've understood that it's true, now i'm trying to find a better formal demonstration. $\\endgroup$ \u2013\u00a0FabioL Sep 12 '15 at 14:39\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/119227/undecidability-of-two-turing-machines-acting-the-same-way-on-an-input\nText:\nSo I need to find a reduction to the (undecidable) problem of deciding if two Turing machines $M_1$ and $M_2$ behave the same way on an input $x$. \"Behaving the same way\" is defined like this:\n\n$M_1$ and $M_2$ behave the same way on an input $x$, when they both don't halt, or when they both accept $x$ or when they both halt and reject $x$.\n\nI found a reduction from the halting problem which uses the fact that if the Turing machines behave in the same way, than they must have the same language. But this all breaks down in the case that $M_1$ rejects $x$ and $M_2$ doesn't halt, obviously they could have the same language, but they don't act in the same way.\n\nI do think the best way to approach this is by reducing from the halting problem, but I just can't find a valid reduction. Any help would be appreciated.\n\n\nYou were very close to the answer. The special case you mentioned can be handled by hand. Modify the machines resulting from the reduction such that, for each transition, where the machine halts and rejects, let the resulting machine go into an endless loop instead.\n\nNow each machine either accepts or goes into an endless loop. That means, checking if both machines are equivalent on an input $x$ is checking whether both accept the input $x$.\n\n  \u2022 1\n    $\\begingroup$ \"each time the machine halts and rejects\" We don't have this information. The halting problem: $H = \\left\\{ \\left \\langle M \\rangle, x \\: \\right| x \\in L(M) \\right\\} $. Either $M$ accepts $x$ or it doesn't. If $x \\notin L(M)$, $M$ either doesn't halt or it halts and rejects, but we can't tell which. $\\endgroup$ \u2013\u00a0Karla Jan 5 '20 at 20:44\n  \u2022 $\\begingroup$ I probably did not formulate the idea correctly, I meant to look into the transitions function, and instead of transition to the state \"no\", go into an endless loop. I updated the answer correspondingly $\\endgroup$ \u2013\u00a0narek Bojikian Jan 5 '20 at 21:00\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/help-on-fredholm-eqn-of-the-first-kind.622208/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nHelp on Fredholm Eqn of the First Kind\n\n  1. Jul 20, 2012 #1\n    Hello humans,\n    Can you offer advice on the following situation?\n    [itex] g(s)=\\int_{a}^{b}K(t,s)f(t)dt [/itex]\n    However I understand that if K can be expressed as\n    [itex] K(t,s)=K(t-s) [/itex]\n    then we can say\n    [itex]f(t)=\\mathcal{F}^{-1}\\left [ \\frac{\\mathcal{F}[g(t)]}{\\mathcal{F}[K(t)]} \\right ] [/itex]\n    Where the fancy F is Fourier, natch. Although I am fuzzy on what happened to a and b. Anyway, in my case, my function looks like this:\n    [itex] g(s)=\\int_{0}^{\\infty}t f(t)dt [/itex]\n    Can you offer any tips, advice, et cetera?\n  2. jcsd\n  3. Jul 20, 2012 #2\n    By the way the idea here is to solve for f, knowing g.\n  4. Jul 20, 2012 #3\n\n\n    User Avatar\n    Homework Helper\n\n    K(t,s) = K(t-s) is not a good enough condition to be able to use the fourier transform method to solve the equation. Your integration limits also have to be [itex]\\pm \\infty[/itex].\n\n    You could solve the equation numerically using quadrature methods, since then it's basically a linear algebra problem [itex]\\mathbf{g} = K\\mathbf{f}[/itex].\n  5. Jul 20, 2012 #4\n    Thanks man. I appreciate it.\n  6. Jul 20, 2012 #5\n    What if we say\n    [itex] t=e^{\\omega u/2} [/itex], so [itex] dt=\\frac{\\omega}{2}e^{\\omega u/2}du [/itex]\n    and then\n    [itex] g=\\int_{0}^{\\infty}\\frac{\\omega}{2}e^{\\omega u}f(u)du [/itex]\n    which means just taking the inverse Laplace transform of g in order to get f?\n    Just an idea?\n  7. Jul 20, 2012 #6\n\n\n    User Avatar\n    Homework Helper\n\n    I overlooked the part of your original post where you said your equation was\n\n    [tex]g(s) = \\int_0^\\infty dt~t f(t).[/tex]\n\n    Unless g(s) happens to be a constant, that is an ill-formed equation. The integration kernel does not depend on s, so the integral is a constant. If g is constant, you can have infinitely many solutions for f.\n  8. Jul 20, 2012 #7\n    Good point, you're right, in the interest of expedience I haven't written it right. The real problem looks like this:\n    [itex] g(s)=\\int_{0}^{\\infty}tf(t,s)dt [/itex]\n    I know g, I am trying to find f.\n    Last edited: Jul 20, 2012\n  9. Jul 20, 2012 #8\n\n\n    User Avatar\n    Homework Helper\n\n    Hm, well, general solutions to integral equations are hard to come by. You can't apply the Laplace transform as is, for instance, since it will only decouple the integrand if the upper limit is s. You could try, for example, assuming that [itex]f(t,s) = \\tilde{f}(s-t)\\Theta(s-t)[/itex], where Theta is a Heaviside side function. Then your equation would be of the form\n\n    [tex]g(s) = \\int_0^s dt~t \\tilde{f}(s-t),[/tex]\n\n    and the Laplace transform would factor the integral for you:\n\n    [tex]\\mathcal L g(u) = \\frac{\\mathcal L f(u)}{u},[/tex]\n    which you could then inverse Laplace transform. However, since you have to assume a particular form of the solution here, it might not be general, or perhaps the inverse transform won't exist, etc.\n\n    Another possibility is to consider the Mellin transform. The Mellin transform of a function f(x) is\n\n    [tex]\\varphi(y) = \\int_0^\\infty dx x^{y-1} f(x).[/tex]\n    (it's actually related to the Laplace transform by a change of variables). This is almost the form of your equation, if your g were g(s,y=2). If you can choose a suitable generalization of g(s) to some g(s,y), then the solution to\n\n    [tex]g(s,y) = \\int_0^\\infty dt~t^{y-1} f(t,s)[/tex]\n    would simply be the inverse Mellin transform of g:\n\n    [tex]f(t,s) = \\frac{1}{2\\pi i}\\mathcal M^{-1}[g(s,y)](t) = \\int_{c-i\\infty}^{c+i\\infty} dy t^{-y} g(s,y).[/tex]\n\n    (see the wikipedia page for the Mellin transform definition and what the inverse equation means)\n\n    But I'm not sure if you can really get the f(t,s) that you actually want out of that solution.\n\n    Another cause for concern that I have with this approach is that there are effectively infinitely many ways you might generalize g(s) to g(s,y) such that g(s,2) is the g(s) you're starting with. I don't know if that means there are infinitely many solutions, or if some solutions just won't work (e.g., the inverse Mellin transform doesn't exist because your g doesn't satisfy the Mellin inversion theorem requirements), or something else.\n    Last edited: Jul 20, 2012\n  10. Jul 20, 2012 #9\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n    2016 Award\n\n    My immediate reaction is to get rid of the t factor by change of variable, u = t2, f(t) = 2h(u).\n    If g(s) can be written as \u01a9ans-n, n > 0, then there's a solution h(u, s) = e-us\u01a9anun-1/(n-1)! (the details may be wrong).\n    Given any solution h = h(u, s), h + k(u,s) is also a solution iff \u222b0k(u,s)du is identically 0.\n\nSimilar Discussions: Help on Fredholm Eqn of the First Kind\n  1. Logrithmic eqn (Replies: 9)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/is-this-the-right-working-out-for-integral-x-3sin-x-dx-x-2-1-x-2-9.171431/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIs this the right working out for integral x^3sin(x)dx/[(x^2+1)(x^2+9)]\n\n  1. May 23, 2007 #1\n    [tex] int^{infty}_{0} \\frac{x^3sinx}{(x^2+1)(x^2+9)} dx [/tex]\n\n    2. Relevant equations\n\n    I understand the value of the integral will be 2 * pi * [sum of residues]\n    and I am also aware of the formula\n\n    Res_{z=z_0} f(z) = [tex] \\frac{g^{m-1} (z_0)}{(m-1)!} [/tex]\n\n    3. The attempt at a solution\n\n    I know the poles exsit and are x= + / - i and x = +/- 3i\n\n    only 2 in the countour and that is x=i and x=3i\n\n    so I get stuck here because all the examples have a bit of working out with a less than or equal to sign and an absolule value, which shows as it goes to zero R goes to inifity... I just don't understand how to set that bit up and why it is necessary, if you know what i'm talking about, can you please explain it to me?\n\n\n  2. jcsd\n  3. May 23, 2007 #2\n\n\n    User Avatar\n    Homework Helper\n\n    ok, to cut a long story short...\n    you wish to apply Cauchy integral theorem to help you doing this integral...because it seems \"hard\" to do if we stay on the real line. Therefore the idea is to analytically continue the function onto the complex plane and treat it as a contour integration. Here you have nice theorems like Cauchy integral theorems, Jordan lemma...etc. to help you do things.\n\n    ok, so you are looking for a \"closed\" contour such that you can apply your theorems. now, however, your initial integral is only from 0 to infty, so you need to make sure that the \"extra piece\" used to close the contour actually vanishes in the desire limit. (that's where the R->infty bit comes from) let me list the procedure:\n\n    1. goto complex plane x->z\n    2. close contour (from a straight line 0->infty, you add an arc of radius R, then return to zero vertically from iR ->0)\n    3. wish to make sure the arc bit disappear in the limit of R->infty, the vertical bit may require more work such as change of variables and other tricks (can't remember off top of my head for this specific case)\n    4. now to see whether the arc really disappear, you do a \"test\" on what happen to the integral\n    [tex]\\int_{\\text{arc}}\\ldots = \\int_{0}^{\\pi/2}\\ldots d\\theta [/tex]\n    where [tex]\\ldots[/tex] means the integral in polar form (with R and theta instead of z)\n    5. you would really want to just look at absolute value because, phases don't matter, only R matters since R->infty eventually\n    6. now, if the function/integrand is bounded from above by some function that goes to zero when R becomes large, then you can say this integral involving the \"arc\" really vanishes (that's where those less than or equal to sign comes from .... i presume)\n    7. once, all auxiliary stuffs are proved to be \"OK\" you can then proceed to solve the problem using those theorems\n  4. May 23, 2007 #3\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Split sin(x) up as (exp(ix)-exp(-ix))/(2i) and split the integral into two parts. For the part with exp(ix) in it you can argue the contribution from the extra part of the contour can be ignored if you close it in the upper half plane. For the exp(-ix) part you will want to close in the lower half plane (use the other set of poles and reverse the overall sign since the contour is going in the opposite direction)."}
{"text": "Retrieved from http://devblog.thinkthroughmath.com/blog/2013/02/27/optimizing-long-running-queries-with-new-relic/\nText:\nTech Blog\n\nThe technology team behind Think Through Math\n\nOptimizing Long-running Queries With New Relic\n\nSummary: For single-threaded Rails web apps, a good strategy to improve concurrency is to ensure a low and consistent transaction time across all of your controller actions. New Relic provides excellent tools for identifying and prioritizing the worst offenders.\n\nAt Think Through Math, we\u2019re always happy when we can use math to solve a real-world problem. When it comes to modeling operational efficiency in Rails, math once again provides a great framework. Many Rails apps are single-threaded; as of the time of this writing ours is no different. Let\u2019s assume that the average controller method in our app takes 250ms. That means in a perfectly ordered environment we can process four requests per second, per web server queue. We\u2019re hosted on Heroku, using the Unicorn Web server with four worker processes per dyno. Since each worker is its own queue, we can process on average 16 requests per-second-per-dyno, or 960 requests per minute. To generalize this we can write an equation: (1000 / avg_response_time) * queues_per_dyno * 60 = dyno_throughput.\n\nThis is where New Relic comes in. New Relic will always show you your average app server response time, both real-time and as a graph over the time range you have selected.\n\nTo start using New Relic to optimize queries, click the Web transactions tab under Monitoring. Click App server if it isn\u2019t already selected, then sort by Slowest average response time. This will give you a list of controller methods, sorted by highest average tranaction time. Heroku\u2019s recommendation is that all transactions have an average response time below 500ms, so that\u2019s a good place to start. What we do is make the time window reflect at least three hours of peak usage, then export the list as CSV (there\u2019s an option in New Relic). We then look at the combination of average response time, max response time, std deviation, and call count to prioritize our efforts.\n\nImplementing the refactor to reduce the average is going to be specific to your application, but we generally end up with one of four different strategies:\n\n  \u2022 Use the transaction tracing features in New Relic to identify the slowest parts of the transaction and optimize that code\n  \u2022 Database optimization; add indexes, denormalize, add counter caches\n  \u2022 Switch elements of the page to use an ajax callback strategy\n  \u2022 If it\u2019s not time-sensitive, move the transaction to a background job (we use and love the awesome sidekiq for this)\n\nWe typically dedicate a portion of development effort each iteration to this activity. Rather than assign it to a specific developer we like to do optimization parties - divvy the list up and have people pair on solutions. It gives people a chance to work on parts of the code they don\u2019tnormally interact with, and it\u2019s an excellent way to add technical breadth to the team."}
{"text": "Retrieved from https://www.physicsforums.com/threads/molar-volume-of-gas-in-function-of-temperature-and-pressure.672926/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMolar volume of gas in function of temperature and pressure\n\n  1. Feb 19, 2013 #1\n\n    Given are two relations for the molar volume. Are they possible? If so, give the formula for v in function of P and T.\n    a) dv =R/P dT - RT/P\u00b2 dP\n    b) dv = 2R/P dT - RT/2P\u00b2 dP\n\n    2. Relevant equations\n\n    3. The attempt at a solution\n\n    If I integrate dv I get \u222bR/P dT - \u222bRT/P\u00b2 dP= RT/P + RT/P (in case a) and 5/4 * RT/P (in case b).\n    does this mean they are both 'possible'?\n\n    intuitively I would say only a is possible\n\n    another thing that struck me - probably resulting from some kind of error I made- was the following discrepancy:\n    say v=RT/P then dv=dv/dT dT + dv/dP dP = R/P dT - RT/P\u00b2 dP.\n    So according to this v=RT/P might well be the solution to the integral \u222bdv (in the case of a).\n  2. jcsd\n  3. Feb 20, 2013 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    The molar volume v is function of P and T: v(T,P). If its first and second partial derivatives exist and continuous its differential is\n\n    dv=\u2202v/\u2202T dT + \u2202v/\u2202P dp.\n\n    an the mixed second partial derivatives are equal:\n\n\n    The integral of dv is independent of he path taken, v is a \"potential\", only if that condition holds.\n\n    In case of the first example, \u2202v/\u2202T=R/P and \u2202v/\u2202P=-RT/P2. The mixed derivatives are equal.\n\n    Now you have \u2202v/\u2202T=R/P, and integrate with respect to T: V=RT/P + integration constant. But that constant can depend on P, so v(T,P)=R/P+f(P). You can find f(P) from the condition that the derivative of v with respect to P has to be -RT/P2:\n    \u2202v/\u2202P= -RT/P2+df/dP=-R/P2, so f=constant.\n\n    Check if the other dv can be the perfect differential of a potential function."}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculating-battery-usage.581732/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculating battery usage?\n\n  1. Feb 26, 2012 #1\n    I have a phone. Since it was last charged, I used it for 8 hours and it was on standby for 16. Now my battery's down to 50%. How much battery did I use when I used the phone?\n\n    I'm thinking it's as simple as x + 2x = 50%.\n  2. jcsd\n  3. Feb 27, 2012 #2\n\n\n    Staff: Mentor\n\n    Maybe or maybe not. You're assuming that the battery draw is the same when the phone is in use versus when it's in standby mode. It's possible and maybe likely that the phone uses less power when it's in standby mode, since it might not need to use power to drive the screen. If so, your equation doesn't take this reduced current draw into account.\n  4. Feb 27, 2012 #3\n    Yes, the screen shuts off in standby mode.\n  5. Feb 27, 2012 #4\n\n\n    User Avatar\n    Science Advisor\n\n    So the phone uses less energy in standby mode. Unfortunately, you do not know how much less. If you knew, for example, that in standby mode you phone uses fraction m of the amount of energy it uses when in use, you could argue that, since it was in standby twice as long as in use, the total energy uses is E+ 2mE= 0.5. That gives (1+ 2m)E=0.5 so the amount of energy used while in use would be E= (0.5)/(1+ 2m).\n\nSimilar Discussions: Calculating battery usage?\n  1. Calculate the variance (Replies: 3)\n\n  2. Log calculation (Replies: 16)"}
{"text": "Retrieved from https://faculty.math.illinois.edu/~tyson/595f15.html\nText:\nUniversity of Illinois at Urbana-Champaign\n\nMath 595 Section GMT (Geometric Measure Theory) Fall 2015\n\nCourse Description\n\nGeometric measure theory considers the structure of Borel sets and Borel measures in metric spaces. In addition to its intrinsic interest, it has been a valuable tool for problems arising from real and complex analysis, harmonic analysis, PDE, and other fields. For instance, rectifiability criteria and metric curvature conditions played a key role in Tolsa's resolution of the longstanding Painlev\u00e9 problem on removable sets for bounded analytic functions.\n\nThe classical setting for geometric measure theory is finite-dimensional Euclidean spaces. Contemporary trends in analysis and geometry in metric measure spaces, including analysis on fractals, motivate extensions of the subject to non-Riemannian and nonsmooth spaces. Sub-Riemannian spaces, particularly, the sub-Riemannian Heisenberg group, are an important testing ground and model for the general theory.\n\nIn the first part of the course we will give an extended review of Euclidean geometric measure theory. Major topics to be covered include Hausdorff measure and dimension, density theorems, energy and capacity methods, almost sure dimension distortion theorems, and tangent measures. Rectifiable sets and measures provide a rich measure-theoretic generalization of smooth differential submanifolds and their volume measures. We will give a short introduction to this important topic.\n\nIn the second part of the course we will discuss ongoing efforts to extend this theory into non-Riemannian and general metric spaces. Motivation for such efforts will be indicated. We will emphasize notions of rectifiability and almost sure dimension distortion theorems in sub-Riemannian spaces."}
{"text": "Retrieved from https://www.physicsforums.com/threads/inequalities-with-two-different-fractions-which-include-x-in-the-denominator.664277/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nInequalities with two different fractions which include x in the denominator.\n\n  1. Jan 14, 2013 #1\n\n    (x-2)/(x+3) less than (x+1)/(x)\n\n    3. The attempt at a solution\n\n    I broke it up into cases.\n\n    When x+3 less than 0 and x less than 0\n\n    and then when both are positive, when one is positive and the other is negative and then the other way around.\n\n    I'm not sure if that's the right way though. I was thinking that maybe you can say:\n\n    (x+3)(x) less than 0\n\n    and a second case\n\n    (x+3)(x) greater than 0\n  2. jcsd\n  3. Jan 14, 2013 #2\n    (x+3) and x are not independent. You have to consider the value ranges of x.\n\n    Perhaps a good place to start is to consider the value of each expression as they pass the \"difficult\" value of x in each case, and how those behave as x is large-negative and large-positive in each case again.\n\n    There are three relevant ranges of x, one of which is a little trickier than the other two.\n  4. Jan 14, 2013 #3\n    So you mean to say x\u2260-3 and x\u22600 and x\u2260 some other number?\n  5. Jan 14, 2013 #4\n    One of the ranges is x < -3\n  6. Jan 14, 2013 #5\n    You mean x < -3 is not in the 'solution set' right? x is -4 makes it not a true statement.\n\n    After trying the first method again (the textbook's method except they didn't show any examples with two fractions both with x in the denominator) I found that x > -3 , x cannot equal -1/2 , 0\n  7. Jan 14, 2013 #6\n    x can equal anything. Of the two expressions being considered in the question, each one is undefined at one value of x (which you already have indicated you know).\n\n    {x<-3} is a range of values where both expressions are well-defined. You might like to explore this range with some values of x (like -4, -5, -10) to see how the functions are behaving.\n  8. Jan 14, 2013 #7\n    When you input -4 for x, you get 6 < 0.75 which means that x < -3 is not a part of the solution right?\n\n    When you input -1/2 for x, you get -1 < -1 which again is not true.\n\n    Although plugging values is good to check answers, I wanted to know if my method was correct. I don't have the answer to this question though.\n\n    What I did was solve for x under all circumstances. When x+3 > 0 and x > 0 and then when x+3 < 0 and x < 0 and then when x+3 > 0 but x < 0 then when x+3 < 0 and x > 0\n\n    The idea behind this is that when solving for x, multiplying by -(x+3) or -(x) would switch the inequality sign. So the possibility that one or the other or both are positive or negative becomes an issue. Is this a correct way to solve this inequality?\n  9. Jan 14, 2013 #8\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    It seems a lot easier to write [itex]\\displaystyle \\ \\ \\frac{x-2}{x+3}<\\frac{x+1}{x}[/itex]\n\n    as the equivalent inequality: [itex]\\displaystyle \\ \\ \\frac{x-2}{x+3}-\\frac{x+1}{x}<0\\ .[/itex]\n\n    Then use a common denominator to combine the two fractions into one fraction.\n  10. Jan 14, 2013 #9\n    Don't you still have to consider that x + 3 and x could be negative?\n  11. Jan 14, 2013 #10\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, it is really the same thing.\n\n    Well, x+3< 0 is the same as x< -3 and, then, of course, x< 0.\n    The three cases you want to consider are\n    x< -3 when x+3< 0 and x< 0 are BOTH true.\n\n    [itex]-3\\le x< 0[/itex] when [itex]x+ 3\\le 0[/itex] and x< 0.\n\n    [itex]0\\le x[/itex] when both x+3> 0 and [itex]x\\ge 0[/itex].\n  12. Jan 14, 2013 #11\n    Yes, I quickly found out that when both are negative and when x+3<0 and x>0 there are no solutions. Maybe in the future I will have the instinct to realize that from the start. But for now I am just trying to get the medthod down.\n\n    I got the same answer by putting both terms together and finding the commoj denomintor. Surely the answer must be correct.\n\n    I thank you all for your help in rehabilitating my mathematics.\n  13. Jan 15, 2013 #12\n    You're not done yet.\n\n    It's possible to establish the answer for the ranges {x<-3} and {x>0} just by considering function values relative to 1 (= x/x).\n\n    However, the intermediate range {-3<x<0} is more complicated. Look at both function values at -2.9 and at -0.1 which should tell you there is more to discover.\n    Last edited: Jan 15, 2013\n  14. Jan 15, 2013 #13\n    Are you supposed to state that there are asymptotes at -3 and 0 ?\n\n    x cannot be -1/2 is that what you're referring to?\n  15. Jan 15, 2013 #14\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    The resulting inequality is: [itex]\\displaystyle \\ \\ \\frac{-6x-3}{x(x+3)}<0\\ .[/itex]\n\n    This simplifies to: [itex]\\displaystyle \\ \\ \\frac{2x+1}{x(x+3)}>0\\ .[/itex]\n\n    You have three factors, one in the numerator and two in the denominator. Either all three must be positive, or one must be positive and two of them negative.\n  16. Jan 15, 2013 #15\n    There is another range for x which satisfies the condition.\n\n    Both original expressions - and the combined expression too - are valid for ##x = -\\frac 12##\n\n    SammyS's simplified expression can also be expressed as $$ \\frac{x+\\frac 12}{x(x+3)}>0 $$\n  17. Jan 15, 2013 #16\n    It seems like I kept making careless errors. Thank you all for being patient with me.\n\n    -3 < x < -1/2 , x > 0\n\n    That should be the right answer.\n  18. Jan 16, 2013 #17\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    You want to determine when [itex](x-2)/(x+3)< (x+1)/(x)[/itex].\n\n    As I said before, since we clearly want to multiply both sides by x+ 3 and x, to clear the fractions, we need to consider when they are positive of negative. So consider 3 cases:\n    1) x< -3. Then both x+ 3 and x are negative. Multiplying the above inequality by x(x+ 3) is multiplying by a positive number (the product of two negatives) so the direction of inequality does not change. [itex](x- 2)(x)< (x+ 3)(x+ 1)[/itex]. [itex]x^2- 2x< x^2+ 4x+ 3[/itex]. Subtract [itex]x^2[/itex] from both sides to get [itex]-2x< 4x+ 3[/itex] so that [itex]0< 6x+ 3= 3(x+ 1)[/itex]. Dividing both sides by the positive number 3, we have [itex]0< x+ 1[/itex] or [itex]x< -1[/itex] which can't happen when x< -3.\n\n    2) -3< x< 0. Now x+ 3 is positive but x is still negative. Multiplying both sides by x(x+ 3) is now multiplying by a negative number and changes the direction of the inequality: [itex](x- 2)(x)> (x+ 3)(x+ 1)[/itex]. The same calculations as before go through with the changed inequality sign: [itex]x< -2[/itex]. That tells us that the orignal inequality is true for [itex]-3< x< -2[/itex].\n\n    3) x> 0. Now both x+ 3 and x are positive so j=multiplying both sides of the inequality by x(x+ 3) does not change the sign: [itex](x- 2)(x)< (x+ 3)(x+ 1)[/itex] and again we get [itex]x> -1[/itex]. Of course that is true for all x> 0 so we have the inequality true for all x> 0.\n\n    We have, so far, that the inequality is true for -3< x< -2 and x> 0. You should also check to see if it is true at x= -3, x= -2, and x= 0.\n    Last edited: Jan 17, 2013\n  19. Jan 16, 2013 #18\n    I think you made a mistake in the firsf case where you ended up with 3(x+2)\n\n    Also the question didn't include any inequality symbols with equal signs. (No line under the inequality is what I mean.\n  20. Jan 17, 2013 #19\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Oh, bother! Thanks. I have gone back and edited my post.\n  21. Jan 17, 2013 #20\n    ## (x\u22122)(x) > (x+3)(x+1) ##\n\n    ## x^2-2x > x^2 +4x +3 ##\n\n    ## -2x > 4x +3 ##\n\n    ## 0 > 6x +3 ##\n\n    ## x < -\\frac 36 = -\\frac 12 ##"}
{"text": "Retrieved from https://www.physicsforums.com/threads/conte-riccati-and-jakob-hermann.865072/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nConte Riccati and Jakob Hermann\n\n  1. Apr 2, 2016 #1\n\n    Riccati sets y/x=q and then arrives at x^2*dq. This is his analysis of Jacob Hermann's differential equations criticised by Johannes Bernoulli (published in 1710).\n\n    x*dy-y*dx is a constant and is equivalent to dt.\n\n    I have understood everything except for the q-substitution.\n\n    3. The attempt at a solution\n\n    Well, I have tried several times but all my solutions are not correct. E.g. x*dx*(dq-q). I have no idea how he got this square. I am missing some clues.\n\n    Attached Files:\n\n  2. jcsd\n  3. Apr 2, 2016 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Perhaps you would find a more recent textbook easier to work from. :oldsmile: Ideal is roughly 1900-1970, after that they get more difficult again.\n\n    If I have understood right your missing thing is the standard formula for derivative of a quotient, one of the half-dozen practically learnt off by heart by most calculus students, see any calculus textbook:\n\n    y/x = q\n\n    dq = d(y/x) = (x dy - y dx)/x2\n\n    His formula Is just given by multiplying dq = (x dy - y dx)/x2 by q2\n  4. Apr 2, 2016 #3\n    Oh dear. What an idiot I am!!!!!!!!!!!!!!!!!!!!!!!! Many thanks. :)\n  5. Apr 2, 2016 #4\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Oh, I think when you have not done it for a year or two it fades. In fact, I am often not that sure whether to write x dy minus... or y dx minus... and have to stop and think about it.\n\n    I was intrigued by your avatar, guessed who she was though I did not remember the name amongst all the Madame de's offhand, and traced her via Voltaire.\n    I knew of Emilie du Chatelet's important translation of Newton, but I don't think I had known of her as the first to formulate of the law of conservation of energy.\n    You are doing some interesting studies. :oldsmile:\n    Last edited: Apr 2, 2016\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Conte Riccati and Jakob Hermann\n  1. Riccati equation (Replies: 1)\n\n  2. Riccati equations (Replies: 0)\n\n  3. Riccati Equation (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/unitarily-equivalent.591586/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nUnitarily equivalent\n\n  1. Mar 29, 2012 #1\n    I've had the flu all week.\n\n    Of course, the book defines unitary equivalent, but it doesn't talk about an efficient method of determining if two matrices are unitarily equivalent.\n\n    Is there an efficient way to determine if these matrices are unitarily equivalent?\n\n    0 & 1 & 0\\\\\n    -1 & 0 &0 \\\\\n    0 &0 &1\n\n    1 & 0 & 0\\\\\n    0 & i &0 \\\\\n    0 &0 &-i\n  2. jcsd\n  3. Mar 29, 2012 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Education Advisor\n    2016 Award\n\n    You can easily find the eigenvalues, no?\n  4. Mar 29, 2012 #3\n    How does that relate to unitary equivalence?\n  5. Mar 29, 2012 #4\n    I found that A and B are unitarily equivalent if they have the same sets of eigenvalues, counting multiplicity.\n\n    A = P*BP (unitarily equivalent)\n\n    det(A) = det(P*BP) = det(P*)det(B)det(P) = det(P*)det(P)det(B) = det(B)\n    det(A) = det(B)\n\n    Their characteristic polynomials must be equal.\n  6. Mar 29, 2012 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    No, that is not true. The matrices\n    [tex]A= \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}[/tex]\n    [tex]B= \\begin{bmatrix}1 & 1 \\\\ 0 & 1\\end{bmatrix}[/tex]\n    have the same eigenvalues (1 with multiplicity two) but are not unitarily equivalent because they do not have the same eigenvectors. A has every vector as eigenvector while B has only multiples of <1, 0> as eigenvectors.\n\n    Two matrices are \"unitarily equivalent\" if and only if they have the same eigenvalues and the same corresponding eigenvectors.\n\n  7. Mar 29, 2012 #6\n    Okay, so I found the eigenvalues of each of the matrices: 1, -i, +i. Now I have the tedious job of finding the eigenvectors. -_-\n  8. Mar 29, 2012 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Halls is definitely wrong to say that they have to have the same eigenvectors. You just have to have the same number of linearly independent eigenvectors for every eigenvalue. You have three distinct eigenvalues. That means you don't have to compute the eigenvectors. Why?\n    Last edited: Mar 29, 2012\n  9. Mar 29, 2012 #8\n    Ah, you're right. The dimensions of the eigenspaces are equal - 3."}
{"text": "Retrieved from https://www.physicsforums.com/threads/differential-form-of-gauss-theorem-with-dielectrics.754928/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nDifferential form of Gauss' theorem with dielectrics\n\n  1. May 23, 2014 #1\n    Hi all,\n    I'm stuck on this incompatibility within the differential form of Gauss' thearem (or Maxwell's first equation) with dielectrics.\n\n\n\n    But with a linear, homogeneous, isotropic dielectric we have\n\n\n    And therefore we get\n\n    [itex]\\vec{\\nabla}\\cdot\\vec{E}=\\frac{\\rho_{free}}{\\epsilon_{0}}[/itex] (1)\n\n    But using the general formula we have\n\n    [itex]\\vec{\\nabla}\\cdot\\epsilon_{0}\\vec{E} + \\vec{\\nabla}\\cdot\\vec{P}=\\rho_{free}[/itex]\n\n\n    So ([itex]1+\\chi_e=\\epsilon_r[/itex], [itex]\\epsilon_0\\cdot\\epsilon_r=\\epsilon[/itex])\n\n\n    which means\n\n\n    and is incompatible with (1).\n\n    Where is the mistake?\n\n    Thank you in advance,\n  2. jcsd\n  3. May 23, 2014 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Hi, Ocirne94. Welcome to PF!\n\n    I don't think there is any mistake. But you did assume that ##\\rho_{bound} = 0##. You have essentially proven an interesting fact about linear, homogeneous, and isotropic dielectrics whenever ##\\rho_{bound} = 0##. There is only one way for your two equations for ##\\vec{\\nabla} \\cdot \\vec{E}## to be compatible. What is it?\n  4. May 23, 2014 #3\n    where did [itex]-\\vec{\\nabla}\\cdot\\vec{P}=0=\\rho_{bound}[/itex] come from?\n  5. May 23, 2014 #4\n    thank you for your answers.\n\n    There are two ways for those two equations to be compatible inside the dielectric: the first is that\n    [itex]\\epsilon = \\epsilon_0[/itex]\n    which I would interpret as saying that the dielectric isn't there.\n\n    The other one is that the divergence is zero in both cases, which implies\n    inside any linear, homogenous and isotropic dielectric.\n    In other words, no LIH dielectric can have free electrons inside its volume.\n    Now this is somewhat disturbing (so much that in three hours of messing around the problem I have never considered this possibility), but eventually consistent with the fact that\n    and I have started from\n\n    Thank you very much for your illuminating answer! :smile:\n  6. May 23, 2014 #5\n    You still haven't explained why you think the divergent of P is zero.\n  7. May 23, 2014 #6\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Keep in mind that you assumed ##\\rho_{bound} = 0## in your analysis. So, what you showed is that if ##\\rho_{bound} = 0## then ##\\rho_{free} = 0## also.\n\n    You should be able to show the converse.\n\n    So, in a \"Class A\" dielectric (i.e., linear, homogeneous, and isotropic), ##\\rho_{free} = 0## \u21d4 ##\\rho_{bound} = 0##.\n\n    But, as dauto is suggesting, it is not necessarily true that these charge densities are both zero. But if one is zero, the other is zero. If one is nonzero, then the other is nonzero. You could certainly imagine that some free charge density is embedded inside a dielectric, so that ## \\rho_{free} \\neq 0##. Then you would also have ##\\rho_{bound} \\neq 0##.\n\n    You might try to show ##\\rho_{bound} = - \\frac{\\epsilon_r-1}{\\epsilon_r} \\rho_{free}##.\n  8. May 24, 2014 #7\n    I was taught that (as a rough model with some approximations) within a LIH dielectric the dipoles get a uniform orientation: this implies that no net bound charge can be found inside the dielectric's volume, and only surface charge is present.\n\n    I definitely agree that the maths allows nonzero charge densities, but in this case I face a problem with definitions: (quoting from my and many other textbooks), \"in dielectrics all the charges are bound to specific atoms and molecules\".\n    So considering a free charge density within a dielectric, hence a bound charge density, looks like violating the definition: this likely enters the domain of the microscopic structure of matter and of the particles' interaction, but I would say that the volume taken by a free charge density within a dielectric cannot be considered dielectric.\n  9. May 24, 2014 #8\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Free charge in a dielectric is just additional charge added into the material. For example, you could imagine an electron beam that sends electrons into a dielectric material and that these electrons become entrapped in the material with some volume charge density \u03c1f that might vary with position inside the material. These electrons would be considered \"free charge\" that is not due to polarization of the molecules of the dielectric. Admittedly, this is not a typical situation for dielectric materials. But in such a situation I think you would consider the free charge and dielectric as occupying the same region.\n\n    If you embed small, but macroscopic-sized charged particles into a dielectric, then I think your are right that you could consider these particles as not occupying the same region as the dielectric but, rather, as particles that are surrounded by the dielectric material.\n\n    Anyway, you will see problems in standard textbooks where you have dielectrics that contain some specified free volume charge density.\n  10. May 24, 2014 #9\n    That's only true if the electric field is uniform. If the electric field varies from spot to spot in the dielectric - that is it is a function of the coordinates - than there will be non-zero net bound charges in the dielectric. if there are embedded \"free\" charges in the dielectric those free charges produce no uniform electric field that induce a net bound charge in the dielectric that partially shields the free charge.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Differential form of Gauss' theorem with dielectrics"}
{"text": "Retrieved from https://www.physicsforums.com/threads/integration-by-parts.68260/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nIntegration by parts\n\n  1. Mar 22, 2005 #1\n    ok i`m really struggling with the concept.\n    I've been asked to find the indefinite integral of;\n\n    [tex] \\int \\frac{x^2}{(2+ x^3)} dx [/tex]\n\n    so before i beg for the answer could someone confirm that i`ve got the right rule to solve this;\n\n    [tex] \\int u(x) v'(x) = [ u(x) v(x)] - \\int v(x) u'(x) [/tex]\n\n    if this is right would you mind giving a suggestion to what u(x) to use?\n\n    p.s. i may have to edit this if latex doesn`t come out right I've been having trouble with it and only jointed the forum a few day's ago!\n    Last edited: Mar 22, 2005\n  2. jcsd\n  3. Mar 22, 2005 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Yes, that is the correct formula (it's surely in your text book), but I don't see any good reason for using integration by parts. That's a fairly standard anti-derivative: look up \"arctangent\".\n  4. Mar 22, 2005 #3\n    I`ve just edited it. Now it`s integration by parts! see I`m getting all flustered\n  5. Mar 22, 2005 #4\n    Actually, you still don't need integration by parts. Substituting [itex]u = x^3[/itex] will simplify it to a standard form.\n\n    Anyways, since differentiation is in some sense the inverse operation to integration, every differentiation rule yields an integration rule. I'm sure you remember the product rule:\n\n    [tex] \\frac{d}{dx}(f(x) g(x)) = f^\\prime (x) g(x) + g^\\prime (x) f(x)[/tex]\n\n    Rearraging the equation above gives\n\n    [tex] f(x) g^\\prime (x) = \\left[f(x) g(x)\\right]^\\prime - f^\\prime(x)g(x)[/tex]\n\n    And integrating both sides with respect to x gives\n\n    [tex] \\int f(x) g^\\prime (x) \\ dx = \\int \\left(\\frac{d}{dx} (f(x) g(x)) - f^\\prime(x)g(x)\\right) \\ dx[/tex]\n\n    but certainly, [tex] \\int \\frac{d}{dx}(f(x)g(x)) \\ dx = f(x)g(x)[/tex], so this just reduces to\n\n    [tex] \\int f(x)g^\\prime (x) \\ dx = f(x)g(x) - \\int g(x) f^\\prime (x) \\ dx[/tex]\n\n    which is what your teacher probably called the formula for integration by parts.\n    Last edited: Mar 22, 2005\n  6. Mar 22, 2005 #5\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    [tex] x^{2}dx=\\frac{1}{3}d(2+x^{3}) [/tex] so the integration is simple...\n\n  7. Mar 22, 2005 #6\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    As others have said, you don't have to use integration by parts to solve this, but .....\n\n    Pick the term whose derivative will eventually go to zero (the soonest). In this case, it's x^2. First derivative is 2x. Second derivative is 2. Third derivative is 0.\n\nSimilar Discussions: Integration by parts"}
{"text": "Retrieved from https://www.physicsforums.com/threads/composition-of-infinite-deformation-retracts.620651/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nComposition of infinite deformation retracts\n\n  1. Jul 13, 2012 #1\n    I'm trying to give an answer to the following problem, I hope someone could come in help! Consider a smooth [itex]n[/itex]-dimensional manifold [itex]M[/itex] with smooth (nonempty) boundary [itex]\\partial M[/itex], and suppose given a function [itex]f: M\\setminus \\partial M \\to \\mathbb{R}[/itex] (which one can assume to be differentiable) satisfying the property that there exists [itex]A > 0[/itex] such that for any [itex]A \\le \\alpha \\le \\beta[/itex], one has that the sublevel [itex]\\left\\{F\\le -\\beta\\right\\}[/itex] is a deformation retract of [itex]\\left\\{F\\le -\\alpha \\right\\}[/itex]. The question is: is it true that [itex]\\partial M[/itex] is a deformation retract of [itex]\\left\\{F\\le -A\\right\\}\\cup \\partial M[/itex] (i.e., is it true that a composition of infinitely many of such deformation retracts is a deformation retract)?\n  2. jcsd\n  3. Jul 14, 2012 #2\n    I don't have a full answer for you, but as a rule of thumb, infinite compositions of maps don't necessarily retain the properties of the individual maps. I think in this case a compactness argument might work, although I think either I'm missing something from your statement, or it's incomplete. Do we know what [itex]f\\big|_{\\partial M}[/itex] is? I was assuming it's identically zero, but I realize the problem doesn't say, nor does it say anything about what happens on the levels between zero and A.\n  4. Jul 15, 2012 #3\n    First of all, thank you for your reply. Next, you're right, I forgot an hypothesis that could be crucial: [itex]f(p)\\to -\\infty[/itex] as [itex]p[/itex] approaches the boundary [itex]\\partial M[/itex]. Could this do any difference?\n    Maybe, (but I don't know if this makes any sense...) an idea could be to work with the extended function [itex]\\hat{f}: M \\to \\mathbb{R}^*[/itex], where [itex]\\mathbb{R}^*:=\\mathbb{R}\\cup \\left\\{\\infty\\right\\}[/itex] (the Alexandroff compactification of [itex]\\mathbb{R}[/itex]), [itex]\\hat{f}(p):=f(p)[/itex] if [itex]p \\in M\\setminus \\partial M[/itex] and [itex]\\hat{f}:=\\infty[/itex] if [itex]f \\in \\partial M[/itex] (hoping that this [itex]\\hat{f}[/itex] inherits some regularity from [itex]f[/itex]...). In this way, [itex]\\partial M[/itex] would become the level [itex]\\left\\{f=\\infty\\right\\}[/itex]...\n  5. Jul 15, 2012 #4\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    Slice the north polar ice cap off of a sphere to get a manifold with boundary. Then remove the South pole. Let f be the reciprocal of the minimum of the distances along a great circles to the South pole and to the edge of the removed polar cap. This function is continuous and f(p) -> -\u221e as p approaches the edge of the removed ice cap.\n\n    But but the set,\n\n    f < - the distance of the meridian where both distances are the same\n\n    does not deform onto the edge circle of the ice cap.\n\n    it seems that you need to assume that f(p) -> -\u221e if and only if p approaches the boundary.\n    Last edited: Jul 15, 2012\n  6. Jul 15, 2012 #5\n    I really apologize with all of you for the incompleteness of the provided hypothesis. Actually, the manifold [itex]M[/itex] is simply connected as well as its boundary [itex]\\partial M[/itex], and these restrictions seems to exclude the latter counterexample (if I'm not wrong).\n    And (finally) these are all the hypothesis I have...\n\nSimilar Discussions: Composition of infinite deformation retracts\n  1. Deformation retract (Replies: 9)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/equations-of-speed-and-position-under-a-constant-force.86698/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nEquations of speed and position under a constant force\n\n  1. Aug 28, 2005 #1\n    there's a question in my book that says \"If you jump upward with a speed of 2 m/s, how long will it take before you stop rising?\" anyone have a hint as to how i would go about answering this?\n  2. jcsd\n  3. Aug 28, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    Use the equations of speed and position under a constant force (in this case the gravitational force).\n\n    v(t) = v_0 + a*t\n    x(t) = x_0 + v_0*t + 0.5at\u00b2\n  4. Aug 29, 2005 #3\n    Assuming no air resistance, right?\n    Since you're jumping [itex] vertically [/itex],\n    *Set your initial position at y=0, then apply that equation\n    [tex] y\\left( t \\right) = t\\left( {2\\frac{m}{s}} \\right) - \\frac{{t^2 }}{2}\\left( {9.8\\frac{m}{{s^2 }}} \\right) [/tex].\n    Simply then, set [itex] y\\left( t \\right) = 0s [/tex] to find your jump duration (*Note: [itex] t \\ne 0s [/itex] :smile: )\n\n    The answer is 0.41 seconds :biggrin:\n  5. Aug 29, 2005 #4\n\n\n    User Avatar\n    Homework Helper\n\n    1) Bomba's \"jump duration\" is 2x as long as the\n    duration of upward travel. No big deal ...\n\n\n    2) It is important to find out how to READ the WORDS of a question!\n    Otherwise it's going to be a long, hard, confusing, frustrating year.\n    The key is knowing what event-condition tells you to stop timing...\n    here, \"stop rising\" is translated into \"upward speed = 0\".\n\n    So Quasar's first equation is all you need to answer this question.\n    Bomba's approach will get you the right answer\n    (if you divide by 2, and if there's no air resistance)\n    but can't be generalized to, say, when does a police car catch up.\n    Quasar's APPROACH even works (slight mod of eq'n) if there IS drag."}
{"text": "Retrieved from https://www.physicsforums.com/threads/y-x-2-1-and-y-x-2-tangent.67554/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nY=(x^2) +1 and y = - (x^2)? tangent\n\n  1. Mar 16, 2005 #1\n    Find the equations of the lines that are tangent to both curves simultaneously:y=(x^2) +1 and y = - (x^2)? :eek:\n  2. jcsd\n  3. Mar 16, 2005 #2\n    Find the equations for the tangent lines to both curves and set them equal to each other. You will find when the slope of the tangents are equal and then can make an equation(s) of of it.\n  4. Mar 17, 2005 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Jameson is correct but it's a bit more complicated than he implies.\n\n    Suppose a line is tangent to y= x2+ 1 at (x0,x02+ 1) and tangent to y= -x2 at (x1,-x12).\n    Any (non-vertical) line can be written as y= mx+ b. m is equal to the derivative of the functions at the given points: m= 2x0= -2x1 so x1= -x0. We must have x02+1= (2x0)x0+ 1 or b= 1- x02. We must also have -x12= (-2x1)x1+ b or b= x12. That is, b= x12= 1- x02. But since x1= -x0, x12= x02 so 1- x02= x02.\n\n    Solve that for x0 and then you can find m and b.\n\n    Because of the squares, there are, of course, two symmetric solutions,.\n    Last edited: Mar 17, 2005\n\nSimilar Discussions: Y=(x^2) +1 and y = - (x^2)? tangent\n  1. Integral of 2/(y+1)? (Replies: 4)\n\n  2. Integrate ln(4+y^2)dy? (Replies: 8)\n\n  3. D/dx y^2 help (Replies: 2)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/investigating-max-and-min-value-of-a-function.222944/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nInvestigating max and min value of a function\n\n  1. Mar 19, 2008 #1\n\n    [tex] f(x) = (1/2)sin2x + cosx [/tex]\n\n\n    [tex] f^2 min +f^2 max = ? [/tex]\n\n    2. Relevant equations\n\n    Differentiation not allowed... only by transformations and analysis.\n\n    3. The attempt at a solution\n\n    I am confused by what it means by f^2 min +f^2 max... does it imply we have to find max and min values seperately, square them and add them? Or does this formulation imply we can directly get the required value?\n\n    Do we have to square the function before investigating it?\n  2. jcsd\n  3. Mar 20, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n\n    I think what they're asking you to do is find the sum of the squares of the maximum and minimum values of this function.\n\n    I'd suggest first writing out what sin(2x) is: you'll find that f(x) can be expressed as a product of two factors. It should be reasonably straightforward to see what the greatest and least values of that product are. Can f(x) be zero?\n  4. Mar 20, 2008 #3\n    you need to take the derivative of that..\n\n\n    after that you solve f'(x)=0\n    find the extreme points and put the y values in the asked equation\n\n  5. Mar 20, 2008 #4\n\n\n    User Avatar\n    Homework Helper\n\n    The problem statement says no differentiation allowed...\n\n    (If it were, the derivative would be f'(x)=1*cos2x - sinx .)\n    Last edited: Mar 20, 2008\n  6. Mar 21, 2008 #5\n    i'm getting\n\n    [tex]f(x) = cosx(1+sinx)[/tex]\n\n    ok i got min value = 0 (the problem says 0 <= x <= pi/2)\n    how do we get the max value of the product?\n  7. Mar 21, 2008 #6\n    you have a point in x=pi/2 +pi*k\n    and for x=3/4*pi +2pi*k\n\n    substitute them in the fuction and find their y values\n    Last edited: Mar 21, 2008\n  8. Mar 21, 2008 #7\n    how does that work?\n  9. Mar 21, 2008 #8\n\n\n    User Avatar\n    Homework Helper\n\n    If the interval is [0, pi/2], then you don't have to worry about the other periodic values of sine and cosine. (You didn't mention the interval earlier...)\n\n    The minimum is zero at pi/2 because of the cosine term. For the maximum, you could either look at the terms in f(x) or square your result for f(x) first. In any case, using x = 0 would give you\n    f(0) = 1, but there's a place where we can do better. The problem with the endpoints is that sine is high when cosine is low and vice versa. What value of x gives both fairly high values for sine and cosine? (Consider graphs of those functions.)\n  10. Mar 22, 2008 #9\n    pi/4 gives equal values for sine and cosine... however, how do we know there isn't a value thats higher? i think there may be a more rigorous proof...\n\n    e.g. on another similar problem i could obtain a quadratic equation containing f(x) in a constant term (by squaring function) and getting something like:\n\n    [tex] ax^2 +bx + c = f^2(x) [/tex]\n\n    [tex] ax^2 +bx + (c - f^2(x)) = 0 [/tex]\n\n    [tex] b^2 - 4a(c - f^2(x)) >or= 0 [/tex] (for real f(x))\n\n    thus obtaining min and max values simultaneously...\n\n    on this example, on squaring i get a quartic equation on sin(x)... i'm unable to bring it to a simpler (quadratic) form or otherwise...\n    Last edited: Mar 22, 2008\n  11. Mar 22, 2008 #10\n\n\n    User Avatar\n    Homework Helper\n\n    Maybe we shouldn't look at the quartic polynomial, but rather the factored form. The function squared is\n\n    [tex] (cos x)^{2} (1+sin x)^{2} = (1 - [sin x]^{2})(1+sin x)^{2} = (1 - sin x)(1+sin x)^{3}\n\n    So we make the substitution t = sin x and ask for the maximum on the interval [0,1] of\n\n    [tex] (1 - t)(1+ t)^{3}\n\n    [I'm still thinking about how to solve this without calculus. (The maximum turns out to occur at sin x = 1/2 , BTW, not {sqrt(2)}/2 , as I'd earlier thought.) The instruction \"use transformations and analysis\" isn't very descriptive, so I'm still trying out ideas...]\n    Last edited: Mar 22, 2008\n\nHave something to add?\n\nSimilar Discussions: Investigating max and min value of a function"}
{"text": "Retrieved from http://math.stackexchange.com/questions/23228/which-is-bigger-9999999999-or-9/23235\nText:\nTake the 2-minute tour \u00d7\n\nIn my classes I sometimes have a contest concerning who can write the largest number in ten symbols. It almost never comes up, but I'm torn between two \"best\" answers: a stack of ten 9's (exponents) or a 9 followed by nine factorial symbols. Both are undoubtedly huge, but I haven't been able to produce an argument that one is larger (surely they aren't equal). Any insight into which of these two numbers is bigger would be greatly appreciated.\n\nshare|improve this question\nYou can always define new symbols which give you higher number than before. You want perhaps to limit your alphabet to digits, addition, multiplication, exponentiation, factorial. \u2013\u00a0 Asaf Karagila Feb 22 '11 at 15:20\nTry taking the logarithm several times, estimating the results using Stirling's formula: en.wikipedia.org/wiki/Stirling's_approximation \u2013\u00a0 Qiaochu Yuan Feb 22 '11 at 15:30\n@Fdart17: $9^{999999999}$ is enormously smaller than the exponential tower of ten 9s, which is the number being considered here. \u2013\u00a0 Chris Eagle Feb 22 '11 at 15:35\nDepending on what you're willing to allow without bracketing, neither of these is the best you can do with these symbols. $9!!!!!!!!!$ is smaller than $9^9!!!!!!!!$, while (tower of ten 9s) is smaller than (tower of nine 9s)!. \u2013\u00a0 Chris Eagle Feb 22 '11 at 15:38\n\"(surely they aren't equal)\": One way to see that the exponential tower is not equal to 9!!!!!!!!! is to note that the first is odd and the second is even. \u2013\u00a0 Jonas Meyer Feb 22 '11 at 18:58\n\n3 Answers 3\n\nup vote 33 down vote accepted\n\n$n!$ grows more rapidly than $9^n$ (it grows approximately with $n^n$), so eventually it wins out; in fact, a few moments with Wolfram Alpha suggests that for all $n\\gt 21$, $n! \\gt 9^n$. This means that the best solution is mixed: after the first exponentiation (since $9^9$ is greater than $9!$), you're better off using factorials, giving the answer $9^9!!!!!!!!$. (Also, note that we're all assuming that the correct parentheses here are implicit, since there's a big difference between $\\left(9^9\\right)^9$ and $9^{\\left(9^9\\right)}$.)\n\nOn the other hand, if you're allowed to use more-or-less stock mathematical notation, you may want to have a look at Knuth's arrow notation; $9\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow9$ is bigger by far than the rest of these. (And numbers even larger than this have come up in mathematics - have a look, for instance, at Graham's Number, which most conveniently uses the arrow notation in its definition.)\n\nEDIT: In fact it's pretty straightforward to prove that the answer in the first paragraph, $9^9!!!!!!!!$, is the best that can be done (with these operations). First, as long as $a$ is at least two symbols (for this group of symbols), then $a^9 \\lt 9^a\\lt a!$, so adding a factorial symbol is always going to be better than adding a $9$ onto your tower. But what about structures like $9!^{9!}$? Well, if both $a$ and $b$ are at least two symbols long, then $a^b\\lt \\mathrm{max}(a,b)!!$; assuming for the moment that $b$ is larger (because if $a$ were larger, then $b^a\\gt a^b$), then $b! \\approx b^b$, and while this isn't enough to ensure that it's greater than $a^b$ (consider the case where $a$ = $b$ = $9!$), it's close enough that we can be certain taking a second factorial will be larger - so those extra symbols you spent on exponentiation should retroactively have just gone into more exclamation points, and this is enough to guarantee that $9^9!!!!!!!!$ is the largest possible combination of these particular operations.\n\nshare|improve this answer\nWhat do you mean by \"so eventually it wins out\" ? Of course I agree that $9^9!!!!...$ is best possible, but what about the original structures the OP is asking about? I think you can you prove that for any number of characters $n$, the power tower of nines will be larger than the iterated factorials. \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:38\n+1 for mentioning Grahams Number. I always have little chuckle when I see it's definition. \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:50\nSorry - by 'eventually it wins out' I just meant that for some n, n! will be greater than 9^n - but as Jonas points out, that doesn't imply that the iterated-factorial will be larger than the iterated-exponential with one additional iteration. \u2013\u00a0 Steven Stadnicki Feb 22 '11 at 18:14\n\nWolfram Alpha shows $$9^{9^9}\\approx 10^{10^{8.56}}$$ while $$(9!)! \\approx 10^{10^{6.26}}$$ Adding another character adds another 10 to the bottom of the stack without changing the upper exponent much at all. It will even do the full stack of 10. The exponents have 8.5678 atop the tower of 10's, while the factorials have 6.26949. So the exponents win.\n\nAdded: In Douglas Hofstadter's May, 1982 column \"On Number Numbness\" he declares these essentially equal. For numbers of this size, the first thing you should look at is how many times you have to take a log to make it reasonable, which is 9 for both of them. Then look at the number on top of the stack, which is the only one that matters. So it is like 9.85678 compared with 9.626949, which are very close.\n\nshare|improve this answer\n+1 for being the only one to answer the OP's original question, namely that the tower of nines is larger than the factorials. In fact, I think you can you prove it is true no matter how many times we iterate. That is for any number of characters, say $n$, the power tower of nines will be larger than the iterated factorials. (I find that shocking since factorials is basically $n^n$) \u2013\u00a0 Eric Naslund Feb 22 '11 at 17:32\nI have to admit, I find this really surprising too, but no less impressive for it! \u2013\u00a0 Steven Stadnicki Feb 22 '11 at 18:26\nFor comparison $(9^9)! \\approx 10^{10^9.5}$ \u2013\u00a0 Henry Feb 22 '11 at 18:27\n@Eric: thanks for noticing. Sometimes these questions take on a life of their own, but there was an original question that prompted it. \u2013\u00a0 Ross Millikan Feb 23 '11 at 3:25\n$9!!!$ is roughly $(10^{10^{6.26}})^{10^{10^{6.26}}}$, much greater than $9^{10^{10^{8.56}}}$ (most likely), so adding a character (a factorial in one case and an exponent to the tower in the other), seems to favor factorials here by quite a bit. \u2013\u00a0 Mitch May 14 '11 at 17:51\n\nA thorough study of this question is given in the article \"Exponential vs. Factorial\" by Velleman (American Mathematical Monthly Vol. 113, No. 8, Oct. 2006, pp. 689-704). In the motivating example there are 5 characters instead of 10. Of course, the conclusion is the same as in Steven Stadnicki's answer, that $9^9!!!!!!!!$ (or $9^9!!!$ in the case of 5 characters) is the largest possible.\n\nThe article also addresses your original question, proving that the exponential tower of $n$ $9$s is always larger than a $9$ with $n-1$ factorials applied (and many more general statements).\n\nshare|improve this answer\nExcellent answer! +1! No need to say more. \u2013\u00a0 Eric Naslund Feb 22 '11 at 18:00\n@Eric: Thanks. I just knew where to look because I remembered skimming the article when that Monthly was new. \u2013\u00a0 Jonas Meyer Feb 22 '11 at 18:04\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/95995/there-is-no-simple-group-of-order-448-26-cdot-7?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nHow can I prove that there is no simple group of order $448=2^6\\cdot 7$? I tried with Sylow's theorems, I proved that (if $G$ is simple) the number of 2-Sylows is 7 and that the number of 7-Sylows is 8 or 64, but I don't know how to continue, could you help me please?\n\nshare|improve this question\n(There is a monthly maximum for questions... :D ) \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Jan 3 '12 at 5:36\nHint: If there are 64 Sylow 7-subgroups, consider how may elements of order 7 there are. \u2013\u00a0 Geoff Robinson Jan 3 '12 at 5:45\n@Alex: Well, if there are 384 elements of order $7,$ how many Sylow $2$-subgroups can there be? (Actually, I see a more direct approach to the question than this anyway). \u2013\u00a0 Geoff Robinson Jan 3 '12 at 5:53\nonly 1, right thank you \u2013\u00a0 Alex M Jan 3 '12 at 5:59\n@Jack, Jyrki: I do not believe the statement about groups of order $q^{n}p.$ For example, the symmetric group $S_4$ has order $2{3}.3,$ and a Sylow $3$-subgroup normalizes the normal Klein $4$-group, but not a whole Sylow $2$-subgroup (there is noting special about these primes for this question). \u2013\u00a0 Geoff Robinson Jan 3 '12 at 9:12\n\n1 Answer 1\n\nup vote 5 down vote accepted\n\nLet $n_2$ be the number of $2$-Sylow subgroups of $G.$ Then, $n_2$ is odd and divides $7.$ If $n_2=1$ we're done, but if $n_2=7$, by Sylow theorem, conjugation of these seven $2$-Sylow subgroups defines a homomorphism $G \\to S_7.$ The kernel of this homomorphism cannot be trivial so we're done.\n\nshare|improve this answer\nwhy the kernel cannot be trivial? \u2013\u00a0 Alex M Jan 3 '12 at 7:42\n+1: This works for groups of size $2^6\\cdot 7$, because that number does not divide $7!$. But curiously it wouldn't work for $2^4\\cdot 7$ :-) \u2013\u00a0 Jyrki Lahtonen Jan 3 '12 at 7:45\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/164264/do-elliptic-operators-on-riemannian-manifolds-have-a-regularizing-effect?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm working on my master thesis and need to handle some spectral theory of the Laplace operator on compact Riemannian manifolds and especially on the sphere. While investigating essential self-adjointness I stumbled on the following problem.\n\n*Problem*$\\quad$ In a compact Riemannian manifold $M$ let $$\\Delta=\\operatorname{div}\\operatorname{grad}$$ and let $f\\in L^2(M)$ be such that $(f, u-\\Delta u)=0$ for every $u \\in C^{\\infty}(M)$. Prove that $f=0$.\n\nI believe that the claim is true, because the condition $(f, u-\\Delta u)=0$ means exactly that $f$ is a distributional solution of the elliptic equation $-\\Delta f + f=0$, and so I expect it to be a $H^2_{\\text{loc}}$ function (see Theorem 2.1 of Berezin - Shubin's book). Since $M$ is compact this must imply that $f\\in H^1(M)$ so that integrating by parts we get $\\lVert f \\rVert_{H^1}^2=(f, f)+(\\operatorname{grad}f, \\operatorname{grad}f)=0$.\n\nUnfortunately Theorem 2.1 above is set in an open subset of the Euclidean space and I don't know if it is applicable verbatim in a Riemannian manifold. Can you point me to some reference on this?\n\nThank you.\n\nshare|improve this question\nI don't know the answer to this but would first try to look in Chavel's book 'Eigenvalues in Riemannian Geometry'. \u2013\u00a0 user20266 Jun 28 '12 at 18:07\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nYes. Write your equation in local coordinates and then use the usual elliptic theory there.\n\nHere is an example. The equation $$\\Delta_g u = h$$ in local coordinates is $$g^{ij}\\frac{\\partial^2u}{\\partial x^i\\partial x^j} - \\frac{1}{\\sqrt g} \\frac{\\partial}{\\partial x^i}(\\sqrt g g^{ij})\\frac{\\partial u}{\\partial x^j} = h$$\n\nNotice that the operator on the LHS is still an elliptic operator on $\\mathbb R^n$ in the given local coordinates, due to the fact that the Riemannian metric is positive definite. Therefore all of the standard elliptic regularity theorems you know for operators on $\\mathbb R^n$ still apply.\n\nThere isn't really a standard reference for this, although it probably appears as a remark buried in most PDE books.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/296931/find-x-such-that-1213x-be-a-perfect-square/297410\nText:\nTake the 2-minute tour \u00d7\n\nFind $x \\in N$ such that $12+13^x$ be a perfect square\n\nI am going to limit $k < 12 + 13^x < k+i$ so that I can have $t<x<t+u$, I don't know how to do it, if $x=2k$, it pretty easy but x can also equal $2k +1$ too. So... Stuck here\n\nUpdate 2: I can prove that $x$ can't be $2k$, if so, x = 2k $(k \\in \\mathbb{N})$ then $13^{2k}<12+13^x = 12 + 13^{2k}<(13^k+1)^2$ => $12+13^x$ can't be a perfect square.\n\n~# if $x=2k+1$\n\n=> $12+13^x = 12+13^{2k+1}$. Now we need prove that $k$ can not greater than $1$ (how to do that ?, stuck again)\n\nshare|improve this question\n$x=1$ works, but you probably knew that. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 5:03\nWhere is this question from? \u2013\u00a0 Will Jagy Feb 7 '13 at 5:40\nRamanujan and Nagell are associated with the similar equation $-7+2^x=y^2$, which has several solutions. The methods used for finding all the solutions would probably be a good starting point for the current problem. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 6:00\nHow were you led to this question? \u2013\u00a0 Will Jagy Feb 7 '13 at 6:01\nA couple of papers that might be relevant: MR0856715 (87m:11027a) Peth\u00f6, A.; de Weger, B. M. M., Products of prime powers in binary recurrence sequences, I, The hyperbolic case, with an application to the generalized Ramanujan-Nagell equation, Math. Comp. 47 (1986), no. 176, 713\u2013727 and MR0856716 (87m:11027b) de Weger, B. M. M., Products of prime powers in binary recurrence sequences, II, The elliptic case, with an application to a mixed quadratic-exponential equation, Math. Comp. 47 (1986), no. 176, 729\u2013739. \u2013\u00a0 Gerry Myerson Feb 7 '13 at 6:09\n\n5 Answers 5\n\nThere are many ways to solve such problems -- I'm not sure that any of them are particularly easy. One way, since you've observed that your exponent $x$ is necessarily odd, would be to find all the integral points on the elliptic curves given by the equations $$ y^2 = 13^\\delta u^4+12 \\; \\mbox{ for } \\; \\delta \\in \\{ 1, 3 \\}. $$ One can do this in, for example, magma by typing : IntegralQuarticPoints([13,0,0,0,12]); and IntegralQuarticPoints([13^3,0,0,0,12]); which lead to the two known solutions (with $|u|=1$ and $|y| =5$ and $47$). These routines are using lower bounds for linear forms in logarithms (elliptic, I believe).\n\nAnother approach (which has some similarities) would be to use an argument of de Weger (from his thesis, again based on linear forms in logarithms). This would enable you, for example, to tackle the more general equation $$ 13^x + 2^y 3^z = w^2. $$ I haven't worked out the details, but one should be able to show that the only solutions are with $$ \\begin{array}{r} (x,y,z) = (0,0,1), (0,3,0), (0,3,1), (0,4,1), (0,5,2), (1,0,1), (1,0,5), \\\\ (1,2,1), (1,2,2), (1,2,3), (2,0,3), (2,6,1), (2,10,5), (3,2,1). \\\\ \\end{array} $$\n\nYet another way to solve such problems is to use the hypergeometric method of Thue and Siegel. In this context, it enables one to prove an inequality of the shape $$ \\left| y^2 - 13^x \\right| > |y|^{0.4}, $$ valid for all integers $y$ and odd $x$. Such an approach is also useful for bounding the number of solutions to equations like the one under consideration here. One can, for example, show that given any odd prime $p$ and integer $D$, there are at most $3$ positive integers $x$ such that $$ p^x+D = y^2 $$ for integer $y$. This is, of course, not quite sharp when $p=13$ and $D=12$, but it's close.\n\nshare|improve this answer\nI may be two weeks late, but welcome to Math Stack Exchange professor Bennett! \u2013\u00a0 Eric Naslund Feb 7 '13 at 18:59\nThank you, Eric. \u2013\u00a0 Mike Bennett Feb 8 '13 at 1:57\n\n$x=3 \\implies 13^x+12=2209=47^2$.\n\nshare|improve this answer\n\nI don't think there's a nice way to do this. You can, however, use a calculator or a computer to find solutions. I used the following line in Mathematica:\n\n      Intersection[12+13^(2#-1) & /@Range[100000],#^2&/@Range[300000]]\n\nAnd it returned\n\n{25, 2209}\n\nImplying the only answers less than $100000$ are $1$ and $3$.\n\nEDIT: changed code and results\n\nshare|improve this answer\n\nWe want: $$13^x + 12 = a^2$$ Not an answer just compiling results:\n$$ x=1,3 $$ Are the first two solutions.\nThere are no solutions for $$ 3<x<100000 $$ Note that $$ 12+13^x \\equiv 1 \\mod 8, \\;\\; \\forall x>1, \\mbox{ such that $x$ is odd}\\\\ 12+13^x \\equiv 5 \\mod 8, \\;\\; \\forall x>1, \\mbox{ such that $x$ is even}\\\\ $$ Hence $$ a^2 \\equiv 1 \\ $$ So we have that: $$ a \\equiv 1,3,5 \\text{ or } 7 \\mod 8 $$\nand $x$ is odd since $5$ is a non-residue $\\mod 8$\n\nA similar result yields that: $$ a \\equiv 2 \\text{ or } 5 \\mod 7 $$\n\nshare|improve this answer\n\nI think algebraic approach is appropriate to this problem. With some calculation, we get $$(y+2\\sqrt{3})(y-2\\sqrt{3})=(4+\\sqrt{3})^x (4-\\sqrt{3})^x.$$ and $4\\pm\\sqrt{3}$ is prime on $\\mathbb{Z}[\\sqrt{3}]$. And $$\\frac{5-2\\sqrt{3}}{4+\\sqrt{3}}=2-\\sqrt{3}$$ $$\\frac{47+2\\sqrt{3}}{(4+\\sqrt{3})^3}=2-\\sqrt{3}$$\n\nSo I conjectured following propositions:\n\n  1. If $(x,y)$ is solution of this equation, then $y+2\\sqrt{3}$ associates $(4+\\sqrt{3})^x$ or $(4-\\sqrt{3})^x$.\n\n  2. And each case ($(4+\\sqrt{3})^x$ associates $y+2\\sqrt{3}$ or $(4-\\sqrt{3})^x$ associates $y+2\\sqrt{3}$) gives only one solution.\n\nBut I can't get more.\n\nshare|improve this answer\nBy working out the unit group, you have $$y \\pm 2 \\sqrt{3} = (4 + \\sqrt{3})^x (2 - \\sqrt{3})^a$$ for some integer $a$ and positive integer $y$. A quick exhaust shows $a > 0$ too. Subtracting the conjugates on both sides, you get what is essentially a quadratic equation in $(2 - \\sqrt{3})^a$, so there is effectively one solution for each choice of $(4 \\pm \\sqrt{3})^x$. But there isn't always a solution where $a$ is an integer. \u2013\u00a0 Hurkyl Feb 7 '13 at 8:54\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/334585/use-fund-thm-to-evaluate-the-integral-of-zex2-dydz-3ys-dydz-2-yz7dx\nText:\nTake the 2-minute tour \u00d7\n\nUse the Fundamental Theorem to evaluate the integral of $ ze^{x^2} dydz + 3ys dydz + (2-yz^7)dxdy $ over the surface of the unit cube, except the bottom face.\n\nshare|improve this question\nWhat is $s$, a constant? \u2013\u00a0 Ron Gordon Mar 19 '13 at 9:05\nI assumed so. It is not a typo on my part. \u2013\u00a0 GaMbiT Mar 19 '13 at 9:14\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nBy \"unit cube,\" I assume you mean $[0,1]^3$. In any case, use the divergence theorem to get the net surface integral, i.e., the net outward flow across all faces of the cube. Then subtract the specific surface contribution from the bottom face to get the quantity you seek.\n\nThe vector field described above is\n\n$$\\vec{F} = (z\\, e^{x^2}, 3 s y, 2-y z^7)$$\n\nThen its divergence is\n\n$$\\vec{\\nabla}\\cdot \\vec{F} = 2 x z e^{x^2} + 3 s - 7 y z^6 $$\n\nThe net surface integral is then the integral of the divergence over the unit cube. I assume you can do this relatively simple integral; I get\n\n$$\\iiint_{[0,1]^3} dx\\,dy\\,dz\\: \\vec{\\nabla}\\cdot \\vec{F} = \\frac{1}{2} (e-3) + 3 s$$\n\nThen you must subtract out the contribution from the bottom face, i.e. $z=0$. Since the flow is outward, i.e., down in the negative $z$ direction, you add back in the integral\n\n$$2 \\iint_{[0,1]^2} dx \\,dy 2 = 2$$\n\nso the quantity you seek is\n\n$$\\frac{1}{2} (e+1) + 3 s$$\n\nshare|improve this answer\n*(e - 1), instead of (e + 1)? Thank you very much for the help, by the way. \u2013\u00a0 GaMbiT Apr 19 '13 at 14:18\n@XxGaMbiT: No, because of the factor of $1/2$. \u2013\u00a0 Ron Gordon Apr 19 '13 at 14:19\nOh, right. Careless mistake. Sorry. \u2013\u00a0 GaMbiT Apr 19 '13 at 14:30\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/445123/how-to-solve-the-advection-equation-with-spiral-motion\nText:\nTake the 2-minute tour \u00d7\n\nThe advection equation is :\n\n$$\\frac{\\partial f(x,y,t)}{\\partial t} + \\nabla_{(x,y)} \\cdot (A f)= 0$$\n\nWith initial condition $f(x,y,0) = f_0(x,y)$.\n\nIf the vector $A$ is constant, ie. $A = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix}$ we have a linear advection. Using the characteristic method we found\n\n$$\\frac{dX}{dt} = a_1\\implies X(t) = x_0 + a_1t \\\\ \\frac{dY}{dt} = a_2\\implies Y(t) = y_0 + a_2t$$\n\nIf $A = \\begin{pmatrix} -x \\\\ y \\end{pmatrix}$ the motion of the advection is a circle :\n\n$$\\frac{dX}{dt} = y \\implies X(t) = c_0\\sin(t+c_1) \\\\ \\frac{dY}{dt} = -x\\implies Y(t) = c_0 \\cos(t+c_1)$$\n\nSo I was wondering what can I do to have a spiral advection ? Let's say I want to found :\n\n$$X(t) = t\\cos(t+\\theta_0) \\\\ Y(t) = t\\sin(t+\\theta_0)$$\n\nif we derivate this system :\n\n$$\\frac {dX(t)}{dt} = -t\\sin(t+\\theta_0) + \\cos(t+\\theta_0) = x/t - y = a_1(t,x,y)$$\n\n$$\\frac {dY(t)}{dt} = t\\cos(t+\\theta_0) + \\sin(t+\\theta_0) = y/t + x = a_2(t,x,y)$$\n\nWe can notice then that $\\nabla \\cdot A = \\dfrac{2}{t}$\n\nThen the equation is :\n\n$$\\frac{\\partial f(x,y,t)}{\\partial t} + A \\cdot \\nabla_{(x,y)} f = - \\dfrac{2}{t} f$$\n\nBut I don't manage to solve it. Using the characteristic method we found the spiral equation for X and Y but for the last element I have :\n\n$$\\dfrac{dF(x,y,t)}{dt} = - \\dfrac{2}{t}f \\implies f = C_0 / t^2$$\n\nwhich is not defined when $t=0$ so I don't know how to apply the initial condition.\n\nHow can I solve this equation ?\n\nshare|improve this question\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://math.stackexchange.com/questions/193944/closed-form-for-a-sum-of-values-of-a-quadratic\nText:\nTake the 2-minute tour \u00d7\n\nToday in class we were analyzing the number of half-spaces created by $n$ number of planes. For two planes there are 4 spaces, 3 there are 8, 4 there are 15, etc. our teacher challenged us to find the formula for $n$ planes. Me and my friend came up with $$ 1+\\sum^n_{x=1} \\left(\\frac{x(x+1)}{2}+1\\right) $$ Because based on that when a line cuts a plane in half, the formula for the number of half-planes it creates is $$ \\frac{n(n+1)}{2} + 1 $$ and the difference in the number of half-spaces between each $n$ plane is equal to adding on the same number of half-planes.\n\n+--#of planes--+--1--+--2--+--3--+--4--+--5--+--50--+\n|separates into|  2  |  4  |  8  |  15 | 26  |20,876|\n| _ half-spaces|     |     |     |     |     |      |\n\nMy teacher said that this was correct, but it would be better if it was a formula/function, where you plug in the variables rather than have to evaluate the summation. I know that the final answer is $$ \\frac{n^3+5n+6}{6} $$ but I need to show my work, and am unsure of how to get from a sum to that formula. Am I approaching this incorrectly? How was the original formula derived?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 2 down vote accepted\n\nThe reasoning is basically right, with slight glitches in the details. The desired number is $$2+\\sum_{x=1}^{n-1} \\left(\\frac{x(x+1)}{2}+1\\right).\\tag{$1$}$$ Or else, if you want to sum from $1$ to $n$, the desired number is $$1+\\sum_{x=1}^{n} \\left(\\frac{x(x-1)}{2}+1\\right).\\tag{$2$}$$\n\nNote that $(x+1)^3-x^3=3x^2+3x+1$. So $$\\frac{x^2+x}{2}=\\frac{1}{6}\\left((x+1)^3-x^3-1\\right).$$ Adding $1$, we get $$\\frac{x^2+x}{2}+1=\\frac{1}{6}\\left((x+1)^3-x^3+5\\right).$$\nWe will add up $(x+1)^3-x^3+4$ from $x=1$ to $x=n-1$, and divide by $6$ at the end. We have $n-1$ $5$'s, which add up to $5n-5$. Now add up the $(x+1)^3-x^3$ from $x=1$ to $x=n-1$. The sum is $$(2^3-1^3)+(3^3-2^3)+(4^3-3^3)+\\cdots +(n^3-(n-1)^3).$$ Note the beautiful cancellations! Almost everything disappears, and we end up with $n^3-1^3$. Add the $5n-5$. We get $n^3+5n-6$.\n\nSo our answer is $2+\\dfrac{n^3+5n-6}{6}$, which simplifies to $\\dfrac{n^3+5n+6}{6}$.\n\nRemarks: $1$. If you want to work with expression $(2)$ instead of $(1)$, you may want to use the identity $x^3-(x-1)^3=3x^2-3x+1$, though the one we used works fine.\n\n$2$. The kind of collapsing that we saw comes up surprisingly often. You may want to look into telescoping sums.\n\n$3$. There are many many other ways to find a closed form for the sm. Here is another idea. It is known that for any quadratic $q(k)$, $\\sum_{k=1}^{n-1}$ is a cubic. (And for any cubic $c(k)$, $\\sum_{1}^{n-1}c(k)$ is a quartic, and so on.). So our answer must have shape $p(n)=an^3+bn^2+cn+d$. If we know the values of our function at $4$ different $n$, we get $4$ linear equations in the coefficients $a$, $b$, $c$, $d$. Solve.\n\nshare|improve this answer\nWhere does the $(x+1)^6-x^6+4$ come from? Shouldn't it be $(x+1)^3-x^3+4$? \u2013\u00a0 SomekidwithHTML Sep 12 '12 at 1:55\n@SomekidwithHTML: It comes from a typo. Thanks! \u2013\u00a0 Andr\u00e9 Nicolas Sep 12 '12 at 2:47\n\nYour question amounts to evaluating\n\n$$\\sum_{x=1}^n x^2\\,\\,\\,\\text{and}\\;\\;\\sum_{x=1}^n x$$\n\n(upon expanding your original sum). Specifically,\n\n\n$$\\sum_{x=1}^n x^2=\\frac{x(x+1)(2x+1)}{6}$$\n\nwhich can be shown by induction.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/properly-divergent-sequences.268043/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nProperly Divergent Sequences\n\n  1. Oct 29, 2008 #1\n    Suppose that (x_n) is a properly divergent sequence, and suppose that (x_n) is unbounded above. Suppose that there exists a sequence (y_n) such that limit (x_n * y_n) exists. Prove that (y_n) ===> 0.\n\n    2. Relevant equations\n    (x_n) ===> 0 <====> (1/x_n) ===> 0\n\n    3. The attempt at a solution\n    One can say with certanty that (y_n) must be bounded, as if it weren't, for all K in Naturals, there exists a b_1 in (x_n) > |K| and b_2 > |K|, and there product is unbounded.\n\n    If (y_n) is bounded, and does not converge to 0, then... what?\n\n    That's where I'm stuck. How do I finish this?\n\n  2. jcsd\n  3. Oct 29, 2008 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    If y_n does not converge to zero then there is an e>0 such that for all N there is an n>N such that |y_n|>e. If x_n is unbounded, what does this tell about y_n*x_n?\n  4. Oct 30, 2008 #3\n    When I was trying to prove it directly (for fun), I met some problems.\n    What is a *properly* divergent sequence?( I cannot find its definition in books)\n    If x_n is defined as follows:\n    x_n = 0 when n is even, x_n = n when n is odd\n    is it of such kind?\n    If so, define y_n as:\n    y_n = 1 when n is even, y_n = 0 when n is odd\n\n    does this gives x_n*y_n = 0, as a counter??\n    Last edited: Oct 30, 2008\n  5. Oct 30, 2008 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The crucial part of the problem is \"suppose that (x_n) is unbounded above\". Your example does not satisfy that.\n  6. Oct 30, 2008 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    A properly divergent series is one such that\n\n    (mathematics) A series whose partial sums become either arbitrarily large or arbitrarily small (algebraically).\n\n    So turning each partial sum into an element of the sequence, I believe a properly divergent sequence is one in which for all M there exists k s.t. j>k => |xj|>M\n  7. Oct 30, 2008 #6\n    Thanks..I forgot to search the web.... That would make sense. So a direct proof is also not hard.\n\n    BTW, to HallsofIvy, my x_n do satisfy the unboundedness, IMO.\n\nHave something to add?\n\nSimilar Discussions: Properly Divergent Sequences\n  1. Diverging sequence (Replies: 11)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/elastic-collision-is-outer-space.116432/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nElastic Collision is outer space\n\n  1. Apr 3, 2006 #1\n    I think I'm getting lost in the numbers somewhere here.\n\n    Two astronauts, one of mass 60 kg and the other 84 kg, are initially at rest in outer space. They then push each other apart. How far apart are they when the lighter astronaut has moved 10 m?\n\n    m1= 60 kg\n    m2=84 kg\n    X initial = 0\n    X1 final= 10 m\n    V1 inital = 0\n    V2 initial= 0\n    V 1 final= 10m/s\n    T=1 S\n\n    .5*60*0^2 + .5*84*0^2 = .5*60*10^2 +.5*84*V2Final^2\n    0=3000 + 42* V2Final^2\n    V2Final = -8.5 m/s\n\n    8.5+10=18.5 m\n  2. jcsd\n  3. Apr 3, 2006 #2\n\n    Physics Monkey\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Why did you say the final velocity for astronaut one is 10 m/s? This isn't right. You need to determine the velocity of each astronaut after they push off each other. Since the collision is elastic, you can use conservation of energy and momentum to find the two velocities. Notice that as it stands now, your astronauts have not conserved momentum!\n\n    Edit: Yikes, I knew there was some reason this question was bothering me. Redburns, I'm sorry, but I didn't read the question or your response very carefully. The square root of a negative number is imaginary, not another negative number. Clearly the \"collision\" or push can't be elastic since they start out with no kinetic energy. My apologies for posting too quickly without reading things carefully. You do need to use conservation of momentum.\n    Last edited: Apr 4, 2006\n  4. Apr 4, 2006 #3\n\n\n    User Avatar\n    Homework Helper\n\n    Their combined centre of mass will stay at the initial point and will not move after the interaction since they are experiencing only internal forces.\n  5. Apr 4, 2006 #4\n    In the question you posted no information is given about the strength of the push given and so finding the *numerical* velocity of either person A or B is gonna be a bit tricky (did one push very gently with his little finger or give him a mighty big shove!)...knowing these facts are not necessary!\n\n    What is important is that the impulse that A exerts on B is the same impulse that B imparts on A\n\n    Whether the lighter dudes velocity was 5m/s or 0.0001m/s he is always going to have travelled a distance of 10 meters at precisely the same point when the heavy dude has travelled 'a' meters (where 'a' is constant) (assuming no other forces are acting)\n    Last edited: Apr 4, 2006\n  6. Apr 4, 2006 #5\n    Thanks! I though I might be making this one harder than it should be.\n\nHave something to add?\n\nSimilar Discussions: Elastic Collision is outer space"}
{"text": "Retrieved from https://www.physicsforums.com/threads/keplers-third-law.75968/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nKepler's third law\n\n  1. May 17, 2005 #1\n    not sure what to do here..\n\n    Im being asked to compare the periods of 2 different satellites in orbit around a planet.\n\n    the first one is a circular orbit of radius = r\n\n    the second one orbits 1r to the left and 3r to the right around the planet.\n\n    I'll attempt to draw it here :tongue:\n\n    0 is the planet\n\n\n    I understand how the period works in the first circular orbit.. but not the second one. any ideas?\n  2. jcsd\n  3. May 17, 2005 #2\n\n    Doc Al\n\n    User Avatar\n\n    Staff: Mentor\n\n    Start by reviewing what Kepler's 3rd law says.\n  4. May 17, 2005 #3\n    it states that r^3/T^2 = K\n\n    is it just the average radius of the second satellite? (in this case 2r ?)\n  5. May 17, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Yes, the mean distance, average radius, or, more commonly, the semi-major axis.\n\n    The shape of the orbit doesn't matter (your second orbit has an eccentricity of .5)\n  6. May 17, 2005 #5\n\n\n    User Avatar\n    Gold Member\n\n    So, a satellite in an eccentric orbit will have a period that is equivalent to a circular orbit whose radius is equal to (aphelion minus perihelion) of the eccentric orbit?\n\n    So, if an asteroid happened to be on an orbit that went out as far as Jupiter, and in as far as Mercury, its orbital period would be equivalent to a circular orbit whose radius is (Jupiter's - Mercury's) orbit?\n\n    I'd always wondered that.\n  7. May 17, 2005 #6\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n    Gold Member\n\n    A circular orbit whose radius is equal to the semimajor axis of the ellipse. Perihelion is\n\n\n    where a is the semimajor axis and e is the eccentricity. Aphelion is\n\n\n    So, the semimajor axis is given not by r_ap - r_peri, but rather:\n\n\n    This is what scales with period in Kepler's 3rd law:\n\n    [tex]P^2 \\propto a^3[/tex]\n  8. May 17, 2005 #7\n\n    James R\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n\nHave something to add?\n\nSimilar Discussions: Kepler's third law\n  1. Kepler's Third Law (Replies: 7)\n\n  2. Kepler's Third Law (Replies: 11)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/279860/probability-of-rolling-the-same-number-twice/279862\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nMath novice here. With a 10-sided die, the probably of rolling '1' is 10%. I'm tempted to think the probability of rolling '1' with two consecutive rolls is 20%. Would I be correct?\n\nNot sure if I need to factor in the first roll i.e. 10% + (10% - probability of NOT rolling 1 in the first roll). Or am I overthinking this?\n\nCLARIFICATION: I mean the probability of rolling a 1, then another 1.\n\nshare|cite|improve this question\nYou need to clarify your question. Do you mean the probability of rolling a $1$ at least once, exactly once, or both times? \u2013\u00a0Isaac Solomon Jan 16 '13 at 5:38\nGetting two $1$'s in a row must be less probable than getting the first one. You have to start with the first one, then can fail on the second roll. B.D has the correct answer, but this might help with intuition. \u2013\u00a0Ross Millikan Jan 16 '13 at 5:45\n@RossMillikan makes an excellent point. If you are trying to sync this intuition up with the array visualization I posted below, the single $1$ probability corresponds to the top-left square among just the squares in the top row; the two consecutive $1$s probability corresponds to that same square among all $100$ squares. \u2013\u00a0Benjamin Dickman Jan 16 '13 at 6:03\nup vote 3 down vote accepted\n\nThink of a $10 \\times 10$ array of squares, where each square represents a possible roll. For example, we could say the square in row $a$ column $b$ corresponds to rolling an $a$ first, and then rolling a $b$.\n\nWith these $100$ different possibilities, only one of them - the one in the top left hand corner - corresponds to rolling two consecutive $1$s.\n\nTherefore, the probability is $1/100 = 1\\%$.\n\n(More generally, you want to be multiplying the probabilities of independent events rather than adding them. This sometimes goes by the name of the \"multiplication rule.\")\n\nshare|cite|improve this answer\nWhat a wonderful way of visualizing it. Thank you very much. \u2013\u00a0hoipolloi Jan 16 '13 at 5:46\nYou could also visualize it by drawing a tree: 10 different points for each of the possible rolls, then each of those points gets 10 possible points for the subsequent roll. Again, you will end up with 100 possible two roll scenarios, of which only one is 1 followed by 1. This \"tree approach\" might make it clearer why you are multiplying probabilities instead of adding them. \u2013\u00a0Benjamin Dickman Jan 16 '13 at 5:48\n\nThe probability of rolling the same number twice on a $10$-sided die is $1\\over 10^2$, which is $1\\over 100$. This means that the probability is $1$%, so it's extremely unlikely that you'll make it.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/554546/induction-proof-with-fibonacci-numbers\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nProve by induction that for Fibonacci numbers from some index $i > 10$\n\n$1.5^i \u2264 f_i \u2264 2^i$\n\nNotice! Because Fibonacci number is a sum of 2 previous Fibonacci numbers, in the induction hypothesis we must assume that the expression holds for k+1 (and in that case also for k) and on the basis of this prove that it also holds for k+2.\n\nThis where I've got so far:\n\nBase case: $i = 11$\n$f_{11} = 89 $\n$1.5^{11} \u2264 89 \u2264 2^{11} $ OK!\n\nInduction hypothesis:\n$1.5^{k+1} \u2264 f_{k+1} \u2264 2^{k+1}$\n\nInduction step:\n$1.5^{k+2} \u2264 f_{k+2} \u2264 2^{k+2}$\n\nNow I have no idea how to continue from here. Could someone help?\n\nshare|cite|improve this question\nup vote 2 down vote accepted\n\nWhen dealing with induction results about Fibonacci numbers, we will typically need two base cases and two induction hypotheses, as your problem hinted.\n\nYou forgot to check your second base case: $1.5^{12}\\le 144\\le 2^{12}$\n\nNow, for your induction step, you must assume that $1.5^k\\le f_k\\le 2^k$ and that $1.5^{k+1}\\le f_{k+1}\\le 2^{k+1}.$ We can immediately see, then, that $$f_{k+2}=f_k+f_{k+1}\\le 2^k+f_{k+1}\\le 2^k+2^{k+1}= 2^k(1+2)\\le 2^k\\cdot 4=2^{k+2}$$ As for the other inequality, we similarly see that $$f_{k+2}=f_k+f_{k+1}\\ge 1.5^k+1.5^{k+1}=1.5^k(1+1.5)=1.5^k\\cdot 2.5\\ge1.5^k\\cdot 2.25=1.5^{k+2}$$\n\nshare|cite|improve this answer\nThanks for the great answer! :) \u2013\u00a0JZ555 Nov 6 '13 at 17:24\n\nIf $\\alpha^k\\le f_k\\le \\beta^k$ and $\\alpha^{k+1}\\le f_{k+1}\\le \\beta^k$, then $$f_{k+2}=f_k+f_{k+1}\\ge \\alpha^k+\\alpha^{k+1}=\\alpha^{k+2}\\cdot(\\frac1{\\alpha^2}+\\frac1\\alpha)$$ and $$f_{k+2}=f_k+f_{k+1}\\le \\beta^k+\\beta^{k+1}=\\beta^{k+2}\\cdot(\\frac1{\\beta^2}+\\frac1\\beta),$$ so in order to conclude $$\\alpha^{k+2}\\le f_{k+2}\\le \\beta^{k+2} $$ is is sufficent to have $\\frac1{\\alpha^2}+\\frac1\\alpha\\ge 1$ and $\\frac1{\\beta^2}+\\frac1\\beta\\le 1$. You can verify that this is indeed true for $\\alpha=\\frac32$ and $\\beta=2$.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/193739/intersection-of-a-cone-and-sphere\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nShow that a the cone $xy + yz + xz = 0$ cuts the sphere $x^2 + y^2 + z^2 = r^2$ into two equal circles and find their area.\n\nI have been trying to substitute one of the variables, say $z$, from the equation of the cone and putting that into the sphere; this looks like the wrong approach though. Could someone please help me with this?\n\nshare|cite|improve this question\n\nI would start with a change of variables (orthogonal transformation) to diagonalize the quadratic form $xy + yz + xz$. Try $u = (x+y+z)/\\sqrt{3}$, $v = (x - y)/\\sqrt{2}$, $w = (x + y - 2 z)/\\sqrt{6}$.\n\nshare|cite|improve this answer\nAmazing! That's exactly the new choice of coordinates that I was about to recommend. \u2013\u00a0Lubin Sep 10 '12 at 20:07\nHi, Thanks a lot for your comment, I will try this approach too. \u2013\u00a0coolbootgeek Sep 10 '12 at 20:26\n\nThe cone's apex is at the origin, so it definitely intersects the origin-centered sphere in equal circles.\n\nNote that the cone contains the coordinate axes. (Simply set any two variables to zero, and see that the last can be arbitrary.) Consequently, it meets the sphere at the points $(\\pm r, 0, 0)$, $(0, \\pm r, 0)$, $(0,0,\\pm r)$, so that the circles of intersection must be circumcircles of equilateral triangles with side-length $r\\sqrt{2}$. So ...\n\nshare|cite|improve this answer\nGreat, thanks for the answer \u2013\u00a0coolbootgeek Sep 10 '12 at 20:25\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/56764.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nPerilous Ping-Pong\n\nDate: 11/14/97 at 10:16:11\nFrom: Amanda Stone\nSubject: Perilous ping-pong\n\nThe President is going to a ping-pong match in Tokyo. He is taking\n8 balls with him. A terrorist has implanted one of the balls with \nexplosives, but they add such a small amount that no one can tell the \ndifference. The CIA has only enough time for TWO weighings before the \n\nI know that you must weigh more than one ball on each scale and that \nyou can get information from the good batch of balls. Can you help?\n\n\nDate: 11/14/97 at 13:34:37\nFrom: Doctor Tom\nSubject: Re: Perilous ping-pong\n\nHi Amanda,\n\nI assume the explosive (bad) ball is heavier and the others all weigh \nthe same, or the problem is totally hopeless.\n\nThis isn't possible to solve if all you can do is weigh them. It can \nbe done in 3 weighings, assuming you already know what a normal ball \nweighs. In 3 weighings, here's how to do it:\n\n  Weigh 4 balls. If it is exactly 4 times as heavy as\n  one ball, the explosive ball is in the other batch, and\n  in any case, you've now got it down to 4.\n\n  Take the set of four with the bad ball and weigh 2 of them.\n  You now know which set of 2 is bad.\n\n  Weigh one of the 2 bad balls. If it's normal, the other is bad.\n\nI can prove that the problem, as stated, can't be solved in two\nweighings. Each weighing will give only one bit of information, and \nthere are 8 balls, so 8 possible solutions, which is 3 bits of \ninformation. With only 2 bits in two weighings, you can't possibly \nwork the problem.\n\nThe other possibility is that maybe the question means to use a\nbalance (where you can compare 2 weights). In this case, the problem \ncan be solved, even without knowing what a good ball weighs. In fact, \nyou could do it with up to 9 balls.\n\n  First, balance 3 against 3. If they balance, the heavy ball must\n  be among the other two, and a single comparison of those two on\n  the balance shows which one is heavy.\n\n  If not, the set of 3 that's heavier contains the bad one. Put\n  one of those on each side of the balance, and if one is heavier,\n  it's the bad one.  If they match, the other ball is bad.\n\n-Doctor Tom,  The Math Forum\n\nAssociated Topics:\nHigh School Puzzles\nMiddle School Puzzles\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2015 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/148897/determining-position-at-some-point-in-time\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI try to solve the following problem.\n\nOn $n$ parallel railway tracks $n$ trains are going with constant speeds $v_1$, $v_2$, . . . , $v_n$. At time $t$ = 0 the trains are at positions $k_1$, $k_2$, . . . , $k_n$. Give an $O(n\\log n)$ time algorithm that detects all trains that at some moment in time are leading.\n\nThe problem is I don't know how to approach the above problem. I assume it's should very popular problem in computational geometry. I saw it few times before, but never considered to solve it.\n\nIt looks like that the problem assumes preprocessing the data before giving input the moment of time.\n\nComplexity $O(n\\log n)$ points out to process similar to sorting.\n\nshare|cite|improve this question\nForgive my ignorance, but if you have the current time can't you just do $d=v*t+k$, loop through the trains one by one, and keep track of the farthest? That would be $O(n)$ if I understand the problem correctly. Or do they specifically want $O(n\\log n)$? It seems that fundamentally you're sorting an array of tuples $(train_n, v_nt+k_n)$ by their second element. \u2013\u00a0Robert Mastragostino May 24 '12 at 4:39\n@Robert: For the question to be interesting it probably means that the desired output is a list of indices $i$ such that train $\\#i$ was leading at some instant of time $t_i\\in[0,\\infty)$. \u2013\u00a0Jyrki Lahtonen May 24 '12 at 5:44\nHint: This should have the computational-geometry tag. \u2013\u00a0JeffE May 24 '12 at 8:08\nIf you view the train positions as lines in $t-v$ space, the region to the right of all lines is convex. You are looking for all trains that contribute a segment to the boundary. Maybe you can adapt one of the convex hull algorithms. \u2013\u00a0Ross Millikan May 24 '12 at 8:17\n@RossMillikan, Thank you for the comment. Let's say I almost get the idea. But could you please elaborate a little more please, I don't understand how to represent a position. \u2013\u00a0fog May 24 '12 at 18:20\nup vote 2 down vote accepted\n\nFollow-up on my comment, long for another: For any given train, the position at time $t$ is $v_it+x_{i0}$ where $v_i$ is the velocity of train $i$ and $x_i0$ is its position at $t=0$. This defines a line in the plane. The set of all lines defines a region to the left where at a given time there is at least one train to the right and a region to the right were there is no train to the right. The rightward region is convex. A train is rightmost precisely when its line is the boundary. For example, if train 1 starts at 0 with speed 1 and train 2 starts at -1 with speed 2, they meet at (1,1). Train $1$ is rightmost before $t=1$, and train $2$ is after $t=1$. If train 3 starts at -2 with speed $3/2$, it is never rightmost. If you plot the three lines you can see that. This forms the basis of my statement that you want a convex hull of the right region.\n\nshare|cite|improve this answer\nAnother term occasionally used for this concept is the upper envelope of the set of lines (for instance, in the generalization of this question to arbitrary convex curves instead of just lines, which leads to the study of Davenport-Schinzel sequences). \u2013\u00a0Steven Stadnicki May 24 '12 at 22:53\nThank you Ross Millikan, so $x$ it's a positions of the train, on $y$ it's a time. Therefore the task is to find the rightmost train on the given time, which can be done by sorting in $O(nlogn)$. \u2013\u00a0fog May 25 '12 at 4:40\n@fog: In you original post, it seemed you were to find a list of trains that were rightmost at any time, a different problem. You are right that at a given time you can calculate each train position in $O(n)$, then sort in $O(n\\log n)$ \u2013\u00a0Ross Millikan May 25 '12 at 11:00\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/can-this-be-simlified.117578/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCan this be simlified?\n\n  1. Apr 15, 2006 #1\n    Can this be simPlified?:rofl:\n\n    A = B - sin(degtorad(C)) * sqrt(abs(sqr(D/2) - sqr(sqrt(sqr(E - F) + sqr(B - G))/2)))\n\n    A, B, C, D, E, F, G are variables. I don't need to simlify down to a numerical value of a variable just now; I'm just wondering if the equation can be simplified.\n\n    Other terms\n    degtorad() means the amount inside the paranthese is converted from degrees to radians.\n    radtodeg() converts radians to degrees.\n    abs() means absolute value\n    sqr() and sqrt() are square and square root\n\n    Last edited: Apr 15, 2006\n  2. jcsd\n  3. Apr 15, 2006 #2\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Well, there's the obvious point that\n    sqr(sqrt(sqrt(sqr(E - F) + sqr(B - G))/2)= (sqrt(sqr(E - F) + sqr(B - G))/4\n    That is, that\n    [tex]\\frac{\\left(\\sqrt{(E-F)^2+ \\sqrt{B-G}}\\right)^2}{2}= \\frac{\\sqrt{(E-F)^2+ \\sqrt{B-G}}}{4}[/tex]\n\nHave something to add?\n\nSimilar Discussions: Can this be simlified?\n  1. Can this be solved? (Replies: 1)\n\n  2. Can this be proven? (Replies: 17)"}
{"text": "Retrieved from http://mathoverflow.net/questions/91685/5-8-bound-in-group-theory/91686\nText:\nTake the 2-minute tour \u00d7\n\nThe odds of two random elements of a group commuting is the number of conjugacy classes of the group\n\n$$ \\frac{ \\{ (g,h): ghg^{-1}h^{-1} = 1 \\} }{ |G|^2} = \\frac{c(G)}{|G|}$$\n\nIf this number exceeds 5/8, the group is Abelian (I forget which groups realize this bound).\n\nIs there a character-theoretic proof of this fact? What is a generalization of this result... maybe it's a result about semisimple-algebras rather than groups?\n\nshare|improve this question\nThat formula can't be quite right, since the term on the left is $<1$ and the term on the right is $>1$. Presumably you're off by a factor of $|G|$? The quaternions and $D4$ realize that bound. \u2013\u00a0 Will Sawin Mar 20 '12 at 4:40\nA nice version would be to ask this for finite loops or quasigroups. Gerhard \"Ask Me About System Design\" Paseman, 2012.03.19 \u2013\u00a0 Gerhard Paseman Mar 20 '12 at 5:00\nYeah, I dug up the article by Gustafson. This question appears as an exercise. Both groups you mention have order 8. \u2013\u00a0 john mangual Mar 20 '12 at 5:03\nAny group with center of index 4 realizes this bound. (This is an iff). \u2013\u00a0 Steve D Mar 20 '12 at 5:21\nRobert Guralnick and I have a Journal of Algebra Article called \"On the Commuting Probability in Finite Groups\" (~2006) where we discuss at some length links between the commuting probability and character theory among other things. Much of the paper is reasonably elementary, including a proof that that the commuting probabilty tends to $0$ as $[G:F(G) \\to \\infty,$ where $F(G)$ is the largest nilpotent nomal subgroup of the finite group $G.$ I am not sure whether this paper would help for other algebraic systems though. \u2013\u00a0 Geoff Robinson Mar 20 '12 at 7:27\n\n3 Answers 3\n\nup vote 78 down vote accepted\n\nIf $c(G)> 5|G|/8$, then the average character has a dimension-squared of less than $8/5$, so at least $4/5$ of the characters are dimension $1$ (since the next-smallest dimension-squared is $4$), so the abelianization, which has one element for each 1-dimensional character, is more than half the size of the group, so the commutator subgroup has size smaller than $2$ and so is trivial.\n\nshare|improve this answer\nNeat! Small correction: the average dimension-squared is less than $8/5$. \u2013\u00a0 Noam D. Elkies Mar 20 '12 at 5:28\nThe fact that more than 4/5 of the characters have degree 1 does NOT imply that the group is abelian. Look, for example, at an extraspecial group of order 2^{2n+1}. This nonabelian group has 2^n degree 1 characters, but only one of larger degree. The argument in this answer is thus, at best, incomplete. \u2013\u00a0 Marty Isaacs Feb 14 '14 at 21:33\n@MartyIsaacs Recall that $(4/5) \\times (5/8)=(1/2)$, and so the number of $1$-dimensional characters is more than half the number of elements of the group, as desired. The implication you suggest is not stated in the argument. \u2013\u00a0 Will Sawin Feb 14 '14 at 23:36\n@WillSawin Right. Sorry, I misunderstood your argument. \u2013\u00a0 Marty Isaacs Feb 16 '14 at 17:42\n\nThere is a beautiful generalization due to Guralnick and Wilson, The Probability of Generating a Finite Soluble Group. Their results:\n\n1) if the probability that two randomly chosen elements of $G$ generate a solvable group is greater than $\\frac{11}{30}$ then $G$ itself is solvable,\n\n2) If the probability that two randomly chosen elements of $G$ generate a nilpotent group is greater than $\\frac{1}{2}$, then $G$ is nilpotent,\n\n3) if the probability that two randomly chosen elements of $G$ generate a group of odd order is greater than $\\frac{11}{30}$ then $G$ itself has odd order.\n\nInterestingly, these probabilities are best possible. Note also the elementary McHale article on probability of commutativity again.\n\nshare|improve this answer\n\nOne elementary result using character theory, but going in the other direction, which is proved in the paper of R. Guralnick and myself mentioned in my comment above is that if $\\{\\chi_1, \\chi_2, \\ldots, \\chi_c \\}$ are the complex irreducible characters of $G$, where $c = c(G)$ is the numberof conjugacy classes of $G,$ then by Cauchy-Schwarz, we have $\\sum_{i=1}^{c} \\chi_i(1) \\leq \\sqrt{c}\\sqrt{|G|}$, so that $\\frac{c(G)}{|G|} \\geq \\left( \\frac{\\sum_{i=1}^{c} \\chi_i(1)}{|G|} \\right)^{2}.$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/78621/k%c3%a4hler-structure-on-a-complex-reductive-group\nText:\nTake the 2-minute tour \u00d7\n\nLet $G$ be a complex reductive group, and $K$ a maximal compact subgroup (such that $K_{\\mathbb{C}}=G$). By the polar decomposition theorem one has that, as manifolds, $G\\cong T^*K$. The inherited symplectic structure is compatible with the complex structure, making $G$ into a K\u00e4hler manifold.\n\nOn the other hand $G$ is a smooth affine variety, and therefore inherits a K\u00e4hler structure from any embedding in an affine space. The ring of regular functions of $G$ is described by the algebraic Peter-Weyl theorem, and affine embeddings are of course just given by choices of generators.\n\nCan one obtain the K\u00e4hler structure coming from $T^*K$ by any of these affine embeddings?\n\nshare|improve this question\nHow about any embedding? \u2013\u00a0 Reimundo Heluani Oct 19 '11 at 23:29\nMy formulation was slightly ambiguous, but that was the question I had intended. I've rephrased the question - thanks for the comment. \u2013\u00a0 Johan Oct 20 '11 at 8:32\nI meant something different and I might be wrong, but given such an embedding, G also inherits a K\u00e4hler structure coming from affine space as well. \u2013\u00a0 Reimundo Heluani Oct 20 '11 at 10:08\n\n3 Answers 3\n\nup vote 8 down vote accepted\n\nIsn't the answer no in the very simplest case? If $K$ is the circle group, then the K\u00e4hler structure on the cotangent bundle makes it metrically a cylinder $R \\times S^{1}$. I believe this cylinder cannot be isometrically embedded in $C^n$ (apply the maximum modulus principal to the derivative of the map).\n\nshare|improve this answer\nOoops, my bad, didn't see the exponential when I tried this example. Should remove my answer. \u2013\u00a0 Reimundo Heluani Oct 20 '11 at 17:56\nThanks Peter and Reimundo, the problem is much clearer to me know. Indeed it seems like the K\u00e4hler structure coming from the polar decomposition (which needs the choice of an invariant metric) is never compatible with an affine embedding. In the paper \"Phase Space Bounds for Quantum Mechanics on a Compact Lie Group\" by Brian Hall this K\u00e4hler structure is discussed a bit more, he shows it provides the unique \"adapted complex structure\" on $T^*K$ determined by the choice of the metric on $K$. Reimundo: no need to apologize, your answer made me think of something else, I will write it below. \u2013\u00a0 Johan Oct 20 '11 at 23:15\n\nLet me give a simple argument until we think a better answer. Using Peter-Weyl you can choose an embedding of $G \\subset \\mathbb{A}^n$ such that $K$ is Lagrangian (using real representations for example), since $G = K_\\mathbb{C} \\simeq T^* K$ you obtain that $K$ is also Lagrangian in this manifold. Now you can use Weinstein's Lagrangian Neighborhood theorem (which gives a Lagrangian in a neighborhood of $K$, but perhaps this can be deformed by using that $K$ is maximal compact?).\n\nshare|improve this answer\n\nThis is meant to be a comment to Reimundo's answer, but as it runs longer than comments allow I am posting it as an answer.\n\nIn the general situation when you think of $G$ as a symplectic manifold, and $K$ a Lagrangian submanifold, it is often possible to make the local symplectomorphism guaranteed by Weinstein's Lagrangian Neighbourhood theorem quite explicit.\n\nSuppose $G$ is complex reductive and $K$ an maximal compact subgroup. Consider the following two (left) actions of $K$ on $G$: $\\mathcal{L}_k(g)=kg$ and $\\mathcal{R}_k(g)=gk^{-1}$, for $k\\in K$ and $g\\in G$. Suppose $G$ has a symplectic form $\\omega$, for which both actions, $\\mathcal{L}$ and $\\mathcal{R}$ are Hamiltonian, with moment maps $\\mu_{\\mathcal{L}}$ and $\\mu_{\\mathcal{R}}$. Since the actions commute the moment map for one is invariant for the other. Since the actions are free $K$ is Lagrangian and both moment-maps map onto open subsets in $\\mathbb{k}^*$.\n\nConsider now $G$ as a $K$-principal bundle by means of the action $\\mathcal{L}$. This bundle is of course locally trivial, and it is not hard to see that one can in fact use $\\mu_{\\mathcal{R}}$ as the quotient map. Moreover this gives a symplectomorphism from $G$ to $K\\times \\mu_{\\mathcal{R}}(G)\\subset T^*K$. If $\\mu_{\\mathcal{R}}(G)$ contains $0$ this provides you with the local symplectomorphism guaranteed by the Lagrangian neighbourhood theorem; if $\\mu_{\\mathcal{R}}$ is surjective it gives a global symplectomorphism $G\\cong T^*K$. This is the case for the K\u00e4hler structure provided by the polar decomposition and a choice of a metric, but also for at least a fair amount of the K\u00e4hler structures coming from affine embeddings.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/92747/how-can-a-proton-be-converted-to-a-neutron-via-positron-emission-and-yet-gain-ma?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nThe mass of a neutron is greater than mass of a proton so how is it possible in positron emission for a proton to form a neutron and a positron?\n\nshare|improve this question\n\n3 Answers 3\n\nBecause the mass of a nucleus isn't just the sum of its parts. Positron emission obeys the nuclear mass-energy balance like all other nuclear reactions. The mass deficit is the energy of the reaction.\n\nIn other words, the reaction still decreases the total mass (reactants versus products). Your observation (that a neutron is heavier than a proton) tells us that positron emission can't occur for a proton in isolation - and this is true.\n\nBinding energy is one way to represent the fact that a nucleus's weight isn't just the sum of its parts. So another way to answer your question is to say that the change in binding energy is more than enough to make up for the increase in mass due to changing from a proton to a neutron. So that transition (p to n) causes an increase in nucleon mass, but the binding energy causes a decrease in mass (for the decay). The fact that positron emission happens evidences the fact that the change in binding energy is greater.\n\nshare|improve this answer\n\nIn addition to Alan's notes about keeping track of total energy in a nuclear context, it is also important to keep track of the neutrino.\n\nEven free protons can be converted to neutrons (a process called \"inverse beta decay\") if there is an incident anti-neutrino of sufficient energy: $$p + \\bar{\\nu}_e \\to n + e^+ \\,.$$ This is the detection mechanism that is used for reactor anti-neutrinos oscillation measurements (the delayed coincidence between the positron annihilation and the subsequent capture of the free neutron is very clean), and requires a anti-neutrino of 1.8 MeV or more to proceed.\n\nThe pure decay is $$ p \\to n + e^+ + \\nu_e \\,,$$ and requires a little more energy that you would naively expect from the masses of the proton, neutron and positron (and, of course, can only proceed in a context where there is energy to be had doing it, such as in some heavy nuclei).\n\nshare|improve this answer\n\nwhen anti neutrino collide with protons (process known as\"Reverse BETA DECAY\") they produce neutrons and electrons\n\nshare|improve this answer\nThis is true, and can be put into context to make it relevant but as a bare fact it simply doesn't answer the question. Also, adding this information months after another answer noted it isn't a lot of help unless you add something. \u2013\u00a0 dmckee Sep 23 '14 at 18:38\n\nprotected by Qmechanic May 21 '14 at 17:42\n\n\nWould you like to answer one of these unanswered questions instead?"}
{"text": "Retrieved from http://mathcentral.uregina.ca/QQ/database/QQ.09.06/jay1.html\nText:\nSubject: Calculus\nName: Jay\nWho are you: Student\n\nA snowball melts at a rate proportional to its surface area. Show that its radius shrinks at a constant rate. If it melts to 8/27 of its original volume in 20 minutes, how long will it take to melt completely? Please I need your help.\n\n\nHi Jay.\n\nLet's take this question step by step: first, the \"snowball melts at a rate...\" is clearly referring to the change in volume of the snowball with respect to time. If V = volume,\nA = surface area and R = radius, then dV/dt is what this phrase means.\n\nNow \"...proportional to its surface area.\" means that the dV/dt (the first part of the sentence) varies directly with the surface area A. Varies directly just means that the two terms are equal, but there is a constant of proportionality (usually called k) as a factor (usually attached to the second term). That means:\n\ndV/dt = kA.\n\nSo that's all the first sentence says.\n\nThe question is \"show that the radius shrinks at a constant rate\". That means the change in radius with respect to time is constant (let's call this constant q). So that means you are asked to show dr/dt is some constant.\n\nThe way to do this is to know the formulas for the volume and surface area of a sphere:\n\nV = (4/3) \u03c0 r3 and A = 4 \u03c0 r2\n\nand take derivatives.\n\ndV/dt is the derivative of volume with respect to time, but remember that r is also changing, so you have to use the chain rule:\n\ndV/dt = d/dt((4/3) \u03c0 r3) = (4/3) \u03c0 3 r2 (dr/dt)\n\nNow let's plug that into the first equation:\n\n(4/3) \u03c0 3 r2 (dr/dt) = k A = k(4 \u03c0 r2) = 4 \u03c0 k r2\n\nSo when we simplify by dividing left and right sides by 4 \u03c0 r2, we get:\n\ndr/dt = k\n\nwhich is saying exactly what we wanted to prove: that dr/dt is constant.\n\nFor the second (numerical) part of the question, you don't know the\noriginal volume (call it V again), but hopefully it will cancel out\nlater, so just start with what you know. Call the original radius R,\nthe radius after 20 minutes r, and the volume after 20 minutes v,.\n\nV = 4/3 \u03c0 R3\nv = 4/3 \u03c0 r3\nv = (8/27)V\n\nNow use this last equation to tie together the two volume equations:\n\n4/3 \u03c0 r3 = (8/27) (4/3 \u03c0 R3)\n\nso when you simplify and take the cube root,\n\nr = 2/3 R\n\nThat's very useful, because it is saying that the new radius is 2/3 the initial radius. But since the change in radius with respect to time is constant, the radius is shrinking at a constant rate. So if the radius lost 1/3 its length in 20 minutes, it will take another 40 minutes to melt away completely.\n\nStephen La Rocque.>"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/96642/block-on-cart-equation-of-motion\nText:\nTake the 2-minute tour \u00d7\n\nConsider a rigid block of $b \\times h$ having mass $m$ on cart (as depicted below). The cart is given an acceleration $a$, this leads to overturning of the block. The angle of rotation is indicated by $\\theta$.\n\nThis is how far I got (not considering the movement of the cart): The Lagrangian $L=T-V$ is calculated using $$T = \\frac12 J \\dot{\\theta}^2$$ $$V = m g \\Delta_y = m g \\bigg(r \\cos(\\alpha - \\theta) - \\frac{h}{2}\\bigg) $$ so that $$\\frac{\\mathrm{d}}{\\mathrm{d} t} \\bigg( \\frac{\\mathrm{d} L}{\\mathrm{d} \\dot{\\theta}} \\bigg) - \\frac{\\mathrm{d} L}{\\mathrm{d} \\theta} = 0$$ yields the EOM $$J\\ddot{\\theta} + m g r \\sin(\\alpha-\\theta) = 0$$ Now, my question is: how do I add the acceleration of the cart to the RHS? My initial guess would be $$J\\ddot{\\theta} + m g r \\sin(\\alpha-\\theta) = m a r \\cos(\\alpha - \\theta) $$ where $ma$ is the force and $r \\cos(\\alpha - \\theta)$ the lever arm. But I don't believe this is true since the block does not experience the acceleration $a$ over its full body. Can anyone help or provide some literature? Thanks.\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 0 down vote accepted\n\nVerified it with FEA, it is correct.\n\nAlso, taking into account the \"rocking\" effect requires the piece-wise description: $$ J\\ddot{\\theta} + \\bigg\\lbrace\\begin{matrix} -m g r \\sin(\\alpha + \\theta) & \\theta < 0 \\\\ m g r \\sin(\\alpha - \\theta) & \\theta \\geq 0 \\end{matrix} = m a r \\cos(\\alpha - \\theta) $$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/102358/is-the-following-curve-a-circle?answertab=oldest\nText:\nTake the 2-minute tour \u00d7\n\nLet $\\gamma(\\theta)=(\\sin(\\theta+\\alpha)\\cos\\theta,\\sin(\\theta+\\alpha)\\sin\\theta),\\theta\\in[0,2\\pi]$. Is $\\gamma(\\theta)$ a circle? What is the radius of it?\n\nshare|improve this question\nHint en.wikipedia.org/wiki/\u2026 \u2013\u00a0 David Speyer Jan 25 '12 at 17:13\nPlot it (for some suitably chosen values of $\\alpha$, such as $0$ and $\\pi/2$). Does is look like a circle? If so, what does its center and radius appear to be? If you write down the naive parameterization of a circle with that center and radius, can you prove that it equals your $\\gamma$? \u2013\u00a0 Henning Makholm Jan 25 '12 at 17:15\nPedantic note: $\\gamma$ might or might not be (the equation of) a circle (here, it is) but $\\gamma(\\theta)$ is a point in the plane. \u2013\u00a0 Did Jan 25 '12 at 17:20\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nLet's recall two trigonometric identities: $$ \\begin{align} \\sin\\gamma\\cos\\delta & = \\frac{\\sin(\\gamma+\\delta)+\\sin(\\gamma-\\delta)}{2} \\\\ \\\\ \\sin\\gamma\\sin\\delta & = \\frac{\\cos(\\gamma-\\delta)-\\cos(\\gamma+\\delta)}{2} \\end{align} $$ So put $\\theta+\\alpha$ in the role of $\\gamma$ and $\\theta$ in the role of $\\delta$. Then we have $$ \\begin{align} \\sin(\\theta+\\alpha)\\cos\\theta & = \\frac{\\sin\\alpha+\\sin(2\\theta+\\alpha)}{2} \\\\ \\\\ \\sin(\\theta+\\alpha)\\sin\\theta & = \\frac{\\cos\\alpha-\\cos(2\\theta+\\alpha)}{2} \\end{align} $$ As $\\theta$ goes from $0$ to $2\\pi$, this point goes twice around a circle centered at $(\\sin\\alpha,\\cos\\alpha)/2$, with radius $1/2$ (and diameter $1$).\n\nshare|improve this answer\n\nUsing polar coordinates $(r,\\theta)$, the equation of this curve is $$ r=\\sin(\\theta+\\alpha)=\\sin(\\theta)\\cos(\\alpha)+\\cos(\\theta)\\sin(\\alpha). $$ One sees that $r^2=r\\sin(\\theta)\\cos(\\alpha)+r\\cos(\\theta)\\sin(\\alpha)=y\\cos(\\alpha)+x\\sin(\\alpha)$, hence $$ x^2+y^2-x\\sin(\\alpha)-y\\cos(\\alpha)=0. $$ This is indeed the equation of a circle. Let me indicate its radius is $ \\frac12$ and leave you the joy to find its center.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/25119/understanding-some-basics\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $x_1,\\ldots,x_n$ be any numbers and $\\bar{x} = (x_1+ \\ldots + x_n)/n$. Then I need to prove that $$min_a \\sum_{i=1}^n (x_i - a)^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\nI do not need the answer but I need an visual/intuitive understanding of the question. I do not understand what min$_a$ mean. Actually I'm kind of struggling to understand \"minimization concepts\" i.e. the value $a$ is not defined or anything so what does minimization of $a$ mean ? It would be great if someone can explain the concept in general too. Thanks.\n\nI got the answer perfectly for what I asked. I tried to solve the problem as well. I got stuck but here is my try.\n\n$$\\sum_{i=1}^n (x_i - a)^2 = \\sum_{i=1}^n (x_i - \\bar{x} + \\bar{x} - a)^2$$ $$= \\sum_{i=1}^n (x_i - \\bar{x})^2 + 2 \\sum_{i=1}^n (x_i - \\bar{x})(x_i - a) + \\sum_{i=1}^n(x_i - a)^2 $$ ...\n\nCan anyone help me after this ? Thanks again.\n\nshare|cite|improve this question\nKind of trying to get the answer with Yuval's explanation. If I'm not wrong $a$ should be minimized at $\\bar{x}$ but how to prove it ? \u2013\u00a0Sunil Mar 5 '11 at 6:46\nup vote 5 down vote accepted\n\nGiven $x_1,\\ldots,x_n$, you can define a function $$f(a) = \\sum_{i=1}^n (x_i-a)^2.$$ This function is defined for all real $a$, and in some sense it measures the centrality of $a$.\n\nYou can try some simple example on Wolfram alpha, say \"plot((a-1)^2+(a-2)^2+(a-4)^2,a=0..5)\". In this case the data points are $1,2,4$, and you get a nice, parabolic-like shape (this is no coincidence). The lowest point of the function is the minimum.\n\nThe function $f(a)$ is bounded from below (since $f(a) \\geq 0$), and so it cannot happen that $f(a)$ can be arbitrarily small. Therefore there must be a value below which $f(a)$ cannot reach, and moreover an optimal one - this is known as the infimum. The infimum is a value $L$ such that $f(a) \\geq L$ always, and moreover for each $l > L$, there is some value of $a$ such that $f(a) < l$; that expresses the fact that $L$ is optimal.\n\nIn general, it might be that $f(a)$ can get arbitrarily close to the infimum, but never reach it. In the case at hand, this doesn't happen, and the function $f(a)$ is actually minimized at some point, namely the average (or mean).\n\nThe equation you state can be used to justify the definition of average - the average is the value that minimizes the average squared distance from the datapoints. You could choose other criteria - for example, if you replace squared distance by absolute distance, then the optimal value of $a$ is the median.\n\nThe reason that people care about squared distance is that it's much easier to work with, and the resulting theory is very nice. For example, the central limit theorem states that in many cases, processes converge to a normal distribution whose parameters depend on the mean and variance of the original distribution - the variance is just $\\min f(a)$ (normalized).\n\nshare|cite|improve this answer\nVery clear and a perfect answer. Thank you very much. \u2013\u00a0Sunil Mar 5 '11 at 6:36\n\nThe question is about minimization with respect to a variable a. For this we use the derivative: the minimum of the function $f(a)$ is where the first derivative is zero and the second is positive.\nNow write $$f(a) = \\sum_{i=1}^n(x_i-a)^2 = \\sum_{i=1}^n a^2-2ax_i+x_i^2 $$ Then the derivative is $$f'(a) = \\sum_{i=1}^n (2a - 2x_i) = 2(an - \\sum_{i=1}^n x_i) $$ We see: if $a*n$ equals the sum we have $f'(a)$ a zero. So we can compute $a_0$ by $$ a_0 = \\frac{\\sum_{i=1}^n x_i }n $$ Next, if the second derivative is positive, then indeed $f(a_0)$ is also a minimum: $$ f''(a) = 2n $$ and this is positive - independent of a and/or the $x_i$ . But the formula for $a_0 $ is just the definition of the mean: $ x_{mean} =\\frac{\\sum_{i=1}^n x_i }n $\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/536810/number-of-fibonacci-numbers-in-a-range?answertab=active\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nThe definition of the Fibonacci numbers is given by:\n\n$$\\begin{align}f_1 &= 1;\\\\ f_2 &= 2;\\\\ f_n &= f_{n-1} + f_{n-2},\\qquad (n >= 3); \\end{align}$$\n\nnow we are given two numbers $a$ and $b$, and we have to calculate how many Fibonacci numbers are in the range $[a,b]$. How can we calculate it?\n\nshare|cite|improve this question\nNaively just compute all Fibonacci numbers smaller or equal to $b$ and count. Maybe you should clarify what you mean by 'calculate'. A closed form dependent on $a$ and $b$ will probably not exist. \u2013\u00a0Simon Markett Oct 23 '13 at 10:22\nYour definition of Fibonacci numbers is off by one from the standard indexing. Normally $f_2=1, f_3=2$. My answer uses the standard indexing. The final answer doesn't change as we are subtracting two indices. \u2013\u00a0Ross Millikan Oct 23 '13 at 10:43\n'calculate'means total fibonacci numbers between the range... \u2013\u00a0rock321987 Oct 23 '13 at 11:05 it \u2013\u00a0rock321987 Oct 23 '13 at 11:06\nup vote 1 down vote accepted\n\nThis question is asked in Skiena's programming challenges. Now, to find the $ n^{\\text{th}} $ fibonacci number, we have the following closed form expression.\n\n$$ \\Large F(n) = \\dfrac{1}{\\sqrt{5}} \\left( \\left( \\dfrac{1 + \\sqrt{5}}{2}\\right)^n - \\left( \\dfrac{1 - \\sqrt{5}}{2} \\right)^n\\right) $$\n\nNow, given $ F(n) $, we can find approximately the index of the closest fibonacci number to it. Therefore, we find one $ n_1 $ such that $ F(n_1) = a $ and another $n_2 $ such that $ F(n_2) = b $. Then our answer is $\\mathsf{round(n_2)} - \\mathsf{round(n_1)}$ where $ \\mathsf{round(x)} $ find the nearest integer to $ x $.\n\nshare|cite|improve this answer\nIs the PDF in the link really freely available or is it a copyright violation? \u2013\u00a0lhf Apr 29 '14 at 12:13\nI'll change the link, since I am not sure. \u2013\u00a0adijo Apr 29 '14 at 12:20\n\nWe know that $F_n\\approx \\frac {\\phi^n}{\\sqrt 5}$, so given $a$, the next larger Fibonacci number is $F_k$, where $k= \\left \\lceil\\frac {\\log (a\\sqrt 5)}{\\log \\phi }\\right \\rceil$. Similarly the $F_m$ below $b$ is $m= \\left \\lfloor\\frac {\\log (b\\sqrt 5)}{\\log \\phi }\\right \\rfloor$, then there are $m-k+1$ between $a$ and $b$. You have to think about what you want if $a$ or $b$ are themselves Fibonacci numbers.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/270904/exponential-equation-with-three-summands/270907\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI had a simple looking math problem the other day:\n\nSolve for $y(x) = 0$: $$ 10^{2x} - 101 \\cdot 10^x + 100 = 0$$\n\nSince I have three summands, I cannot just put them to either side of the equation and apply $\\log_{10}$ to it. And I cannot see how I could factor this to get it into a product to use $\\log_{10}$.\n\nMathematica gave me $x = 2$ as a result which seems correct. How can I find the solution to this one? It is supposed to be an elementary problem for an applied math class.\n\nshare|cite|improve this question\nHave you considered substituting something? \u2013\u00a0barto Jan 5 '13 at 12:29\nHint: notice that $10^{2x} = (10^x)^2$ ... and think of quadratic equations. \u2013\u00a0Old John Jan 5 '13 at 12:32\nHow could I not see this? Thanks! \u2013\u00a0Martin Ueding Jan 5 '13 at 12:35\nSomething else to look out for in this sort of question: sometimes they might give an equation that starts $10^{2x+1}\\dots$ and then you have to notice that this can be written as $10\\times (10^x)^2 \\dots$ \u2013\u00a0Old John Jan 5 '13 at 13:04\nup vote 2 down vote accepted\n\nThe key here is to note that $10^{2x} = (10^x)^2$. So we have $$10^{2x} - 101\\cdot 10^x + 100 = (10^x)^2 - 101\\cdot 10^x + 100.$$ Now letting $y = 10^x$, we are trying to solve $$y^2 - 101y + 100 = 0.$$ This has solutions $y = 1$ and $y = 100$ which correspond to $x = 0$ and $x = 2$.\n\nshare|cite|improve this answer\n\nIt is a quadratic equation in $10^x$. So that would make it: $$ 10^x = \\frac{101}{2} \\pm \\sqrt{\\frac{101^2}{4} - 100} $$ $$ \\implies 10^x = 1 \\lor 10^x = 100 \\iff x = 0 \\lor x = 2 $$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/118889/mean-distance-from-origin-after-n-equal-steps-of-random-walk-in-a-d-dimensio/118918\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI am looking for a formula that evaluates the mean distance from origin after $N$ equal steps of Random-Walk in a $d$-dimensional space. Such a formula was given by \"Henry\" to a question by \"Diego\" (q/103170)\n\n$$\\sqrt{\\dfrac{2N}{d}} \\dfrac{\\Gamma(\\frac{d+1}{2})}{\\Gamma(\\frac{d}{2})}$$\n\nI will be very gratefull if you can give me reference to an article that show how this formula was derived. Thanks!\n\nshare|cite|improve this question\n\nThe formula is not exact, but asympotically. Informally: let $z_i = x_i - y_i$ be the $i$-th coordinate after $N$ steps, with $x_i$ ($y_i$) be the number of steps in positive (negative) direction. When $N$ is large, $\\{x_i,y_i\\}$ tend to iid Poisson variables, with $\\lambda=E(x_i) = \\frac{N}{2 d} = Var(x_i)$. Applying the CLT, $z_i$ approaches a normal distribution with zero mean and variance $Var(x_i)+Var(y_i)=\\frac{N}{d}$.\n\nWe are interested in $E(\\sqrt{z_1^2 + \\cdots z_d^2})$. But the square root of a sum of $d$ normals $N(0,\\sigma^2)$ follows a Chi distribution, with mean $\\sqrt{2 \\sigma^2} \\dfrac{\\Gamma(\\frac{d+1}{2})}{\\Gamma(\\frac{d}{2})}$ From this, you get the desired formula.\n\nshare|cite|improve this answer\nPerhaps I am missing something, but where did the Poisson variables come in? It seems to me that it is immediate from the CLT that $z_i$ is approximately normal, since it is the sum of $N$ iid random variables (with values $\\pm 1$). Also, I think $x_i, y_i$ would be approximately normal, not Poisson (the distributions of the summands are not changing with $N$) and not independent of each other (since they must sum to $N$). Otherwise, I agree with the conclusion. \u2013\u00a0Nate Eldredge Apr 11 '12 at 2:27\n@NateEldredge: the CLT is immediate only in 1D, in more dimensions $z_i$ is not the sum of $N$ variables but of $n_i$, which is itself a random variable (with $\\sum n_i = N$), hence the CLT is not so clear here. Instead, it's clear that $x_1,y_1,x_2,y_2...$ is identical to a urns-and-balls ($2d$ urns, $N$ balls) model, which is equivalent (\"Poissonization\") to $2d$ iid Poisson variables conditioned to the value of their sum being $N$ (asymptotically, this conditioning turns irrelevant). \u2013\u00a0leonbloy Apr 11 '12 at 13:54\nOh right. I was confused and thinking of something else. Thanks for the clarification. \u2013\u00a0Nate Eldredge Apr 11 '12 at 14:00\n@leonbloy:Can you give any reference to a publication where this formula was mentioned? Thanks \u2013\u00a0Picard Porath Sep 7 '13 at 13:59\nJust to add, I'd be very grateful for a textbook or paper reference for this. Finding it very useful, but hard to credit! \u2013\u00a0DRG Jul 8 '15 at 13:52\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/182375/relationship-of-a-point-to-a-rotating-plane\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI have three points in space, which cannot move relative to one another, and create a reference plane.\n\nThere is a forth point, that lays off/on the plane (off will be more general solution, on will be a private case I guess).\n\nHow can I use the information I just described to predict where the point off/on the plane will lie when the plane moves? The point is constrained by the original relationship.\n\nFor example: $P_1$, $P_2$, $P_3$ define a plane and they are respectively $(1,1,5) , (0,1,5) , (-1,0,5)$.\nThe fourth point $P$ is $(-5,2,5)$ on the plane defined by $P_{1,2,3}$. What would be the coordinates of $P$ when the plane moves (arbitrary rotation in space) and $P_{1,2,3}$ have new values. In the example all points are on the same $z$ plane $(5)$ in the initial reference state.\n\n\nshare|cite|improve this question\nAre only rotations allowed? When you say 'rotation' you mean rotations around any axis, right? Are the old values of $P_i$ mapped onto the new ones (meaning that the angles of the triangle $P_1P_2P_3$ are preserved)? \u2013\u00a0Karolis Juodel\u0117 Aug 14 '12 at 9:11\nrotation could be any rotation, not just around specific axis. the old values are mapped. imagine a tool with 4 significant points that travels freely in the 3d space. \u2013\u00a0ButterFly Aug 14 '12 at 14:32\n\nConstruct the transformation matrix used on the plane and multiply $P$ by it. The matrix is $BA^{-1}$ where matrices $A$ and $B$ move the $xOy$ plane to the one defined by old and new values of $P_i$ respectively.\n\nHere's a way to construct $A$ and $B$. It makes sense to use $4 \\times 4$ matrices. Otherwise you couldn't map $(0, 0, 0)$ to anything else. The columns of the matrices could be as follows. $(P_2-P_1, 0)$, $(P_3-P_1, 0)$, $((P_2-P_1) \\times (P_3-P_1), 0)$ and $(P_1, 1)$. The first $3$ rows are filled with the values of the vectors I wrote and the last row is $(0, 0, 0, 1)$. Note that the third column could be anything. A perpendicular vector is probably what you are looking for, though. Notice that, for example, $A*(1, 0, 0, 1) = (P_2, 1)$. Finally, $BA^{-1}*(P, 1)$ is the new value of $P$.\n\nshare|cite|improve this answer\nA is perpendicular to the old or new plane ? is it a norm vector ? \u2013\u00a0ButterFly Aug 14 '12 at 14:36\nA and B are matrices. The upper left $3 \\times 3$ part of either is supposed to have orthonormal vectors for columns. Since we are combining two matrices, these vectors can be 'wrong', as long as they are 'wrong' the same way in A and B. The third vector is the normal of the plane - the old plane in A and the new plane in B. \u2013\u00a0Karolis Juodel\u0117 Aug 14 '12 at 15:04\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/65952/n-partite-n-clique\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nWe are given an $n$-partite graph $G$. Each partition has $n$ vertices, some of which may be isolated. Let us number the vertices in some $i^{th}$ partition as $V_{i1},V_{i2},...,V_{in}$.\n\nNow each non-isolated vertex $V_{ij}$ has at least one neighbor in each of the remaining $n-1$ partitions s.t. for a given numbering of the vertices, the $n$ vertices (vertex $V_{ij}$ and its $n-1$ neighbors) form a permutation on the second index. For e.g., consider a 4-partite graph. Each partition has 4 vertices.\n\nUsing the numbering as given above, vertex $V_{12}$ has as neighbors vertices $V_{21},V_{34},V_{43}$. Vertex $V_{12}$ can have other neighbors as well. We need to show that the graph $G$ will always contain $n$-clique.\n\nA stronger claim would be to say that every vertex is part of some $n$-clique.\n\nshare|cite|improve this question\nFWIW here is a reformulation (I think). Let G be a graph with vertex set the edges of the complete bipartite graph K(n,n). Suppose that each vertex of G is contained in a perfect matching in K(n,n) and is joined to all the other edges in that perfect matching. Prove that G contains an n-clique. \u2013\u00a0gowers May 25 '11 at 12:44\nI haven't checked, but it seems likely to me that a random graph will be a counterexample: you need a very high edge probability to get an n-clique and I think probably a lot lower to satisfy your conditions with high probability. \u2013\u00a0gowers May 25 '11 at 12:52\nYou would need at least some constraint on the number of isolated vertices, wouldn't you? Currently, the graph with no edges at all is a counterexample. \u2013\u00a0Klaus Draeger May 25 '11 at 13:45\nYes, of course. I posted the details to finish it off. \u2013\u00a0fedja May 25 '11 at 13:46\nup vote 3 down vote accepted\n\nFalse as stated: take large $n$ and for each vertex $V_{ij}$ choose some random permutation and draw the corresponding edges. Now, we have $n^n$ possible cliques to form. Let's look at the probability that $V_{11},\\dots, V_{nn}$ is a clique. The chance that $V_{11}$ acquires $k$ fixed neighbors in this subgraph when its edges are drawn is $\\frac{(n-1-k)!}{(n-1)!}$. Multiplying by ${n-1\\choose k}$, we see that the chance to get $k$ vertices is less than $\\frac 1{k!}$. Thus, if $X_1$ is the number of acquired neighbors for $V_{11}$, then $Ee^{X_1}\\le e^e$. Thus $Ee^{\\sum X_j}\\le e^{en}$ by independence. But the clique means that $\\sum X_j\\ge n(n-1)/2$, so the probability that we have a given clique is at most $e^{en}e^{-\\frac{n(n-1)}2}$, which is smaller than $n^{-n}$ by an order of magnitude.\n\nI strongly suspect that you meant something else. Actually, my first impulse when seeing your post was to say \"Consider the graph consisting of isolated vertices only\" but then I decided that it would be too cheap.\n\nshare|cite|improve this answer\nIn your analysis, do you account for the edges that get added due to the permutations chosen by other vertices? I guess what I am trying to say is that once you have chosen the permutations for the vertices in a partition and added edges, when you are choosing permutations for vertices in the next partition, you only choose from the remaining $(n-2)!$ and so on. \u2013\u00a0Pawan Aurora May 26 '11 at 5:24\nAnd yes, each partition must contain at least one non-isolated vertex. The structure of the graph should remain consistent with the condition that each non-isolated vertex $V_{ij}$ has a set of $n-1$ neighbors (one in each of the remaining $n-1$ partitions) that form a permutation with $j$. What it means is that if there is some vertex in a partition that does not get any neighbor from a particular partition when adding edges, then that vertex must be isolated. \u2013\u00a0Pawan Aurora May 26 '11 at 5:24\nNot really. You said that you do not mind extra edges and you didn't say that the good edge sets must not overlap, so I run full drawing for each vertex. If I get some edges twice, I just consider myself lucky. \u2013\u00a0fedja May 26 '11 at 22:03\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/157784/can-we-always-find-a-primitive-element-that-is-a-square\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nLet $L/\\mathbb Q$ be a galois extension. The Primitive element theorem says, that there is an element $\\alpha \\in L$, so that $L=\\mathbb Q(\\alpha)$.\n\nCan I always find an element $\\beta \\in L$, so that $L=\\mathbb Q(\\beta^2)$ ?\n\nshare|cite|improve this question\nGreat question! Just a small point: the primitive element theorem only applies to finite extensions. \u2013\u00a0Zev Chonoles Jun 13 '12 at 14:04\nAlso, the extension doesn't need to be Galois, just separable. [And over $\\mathbf Q$ everything is separable.] \u2013\u00a0Dylan Moreland Jun 13 '12 at 14:05\nThis is certainly true if $L$ has odd degree over $\\mathbf Q$. Do you see why? \u2013\u00a0Dylan Moreland Jun 13 '12 at 14:08\nup vote 7 down vote accepted\n\n$\\newcommand{\\Q}{\\mathbb Q}$\n\nI think this works. Let $K/\\Q$ be a finite field extension. Note that $K$ has finitely many subfields, call them $F_1,\\dots,F_t$ and let $W$ be their union. Then any element in $K \\setminus W$ is necessarily a primitive element. So it suffices to show their exists some $\\alpha \\in K \\setminus W$ that has a squareroot. Pick $\\alpha \\in K \\setminus W$, note that for $k \\in \\Q$ we still have $\\alpha_k=\\alpha + k \\in K \\setminus W$ otherwise $\\alpha \\in W$. Consider $\\alpha_k^2=(\\alpha+k)^2=\\alpha^2+2k\\alpha+k^2$ suppose that for every $k \\in \\Q \\setminus {0}$ we have $\\alpha_k^2 \\in W$. Then by the pigeonhole principle we must have some $j$ and $k_1 \\neq k_2$ such that $\\alpha_{k_1}^2,\\alpha_{k_2}^2 \\in F_j$. So we have\n\n$$\\frac{\\alpha_{k_1}^2-\\alpha_{k_2}^2-(k_1^2+k_2^2)}{2(k_1-k_2)} \\in F_j$$\n\n\n$$ \\frac{\\alpha_{k_1}^2-\\alpha_{k_2}^2-(k_1^2+k_2^2)}{2(k_1-k_2)} =\\frac{2\\alpha(k_1-k_2)}{2(k_1-k_2)}=\\alpha. $$\n\nWhich would imply that $\\alpha \\in F_j \\subset W$ so we have some $k \\in \\Q\\setminus \\{0\\}$ such that $(\\alpha+k)^2 \\in K \\setminus W$ and thereby $\\Q((\\alpha+k)^2)=K$.\n\nI think this could be turned into a constructive argument fairly easy. Take one of the primitive elements given to you by the primitive element theorem then add $t+1$ non-zero rational numbers to it and the square of one of those will be the desired element.\n\nAmmendum: This could also extend to a proof that there always exists an element $\\alpha \\in K$ such that $\\Q(\\alpha^n)=K$. Essentially use the same argument except find $t$ such distinct $c_i$ so that $\\alpha_{c_i}^n \\in F_t$ then notice that the matrix given by $A_{ij}=\\binom{m}{j}c_i^j$ has determinant a constant multiple of the vandermode matrix $A_{ij}=c_i^j$. Thereby the determinant is nonzero and so we can find a linear combination of the $\\alpha_{c_i}^n$ that gives us $\\alpha$.\n\nshare|cite|improve this answer\nThank you very much. It is a nice proof. \u2013\u00a0Lisa Mainhard Jun 14 '12 at 13:18\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/844231/polynomial-multiplication-modulo-polynomial\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nSuppose we are working on finite field $F_{16}$ and have pritimive polynomial $z^4+z+1$. I stuck at how to compute polynomial modulo. For example, we have $z^5+z+1$ mod $z^4+z+1$. I use the usual division, I obtain the remainder is $-z^2+1=z^2+1$ because each coefficient is over $F_2$. But I don't know whether this is the correct way to compute remainder. Can anyone help me?\n\nshare|cite|improve this question\nis the polynomial $x^4+x+1$ used to construct the field as in $\\mathbb{Z}_2[x]/\\langle x^4+x+1\\rangle$? \u2013\u00a0Anurag A Jun 23 '14 at 4:21 i refer to this website. For $x^3+2x^2$ mod $x^2-1$, I don't understand how the author obtains $x+2$. I use normal long division to solve, I obtain the remainder is $x-1$ \u2013\u00a0Idonknow Jun 23 '14 at 4:26\nup vote 4 down vote accepted\n\nI am assuming that $z^4+z+1$ is the irreducible polynomial used to construct the field $\\mathbb{F}_{16}$ (this is different from the concept of primitive element). In that case $z^4+z+1 \\equiv 0$.\n\n\\begin{align*} z^4+z+1 & \\equiv 0 \\pmod{z^4+z+1}\\\\ z^4 & \\equiv z+1 \\pmod{z^4+z+1}\\\\ z^5 & \\equiv z^2+z \\pmod{z^4+z+1}\\\\ z^5+z+1 & \\equiv z^2+1 \\pmod{z^4+z+1} \\end{align*} So you have the right answer but using the above congruences can help you reduce your work.\n\nshare|cite|improve this answer\n+1 But $z^4+z+1$ is a primitive polynomial. It is the most popular choice for a primitive quartic over $\\Bbb{F}_2$. Mind you, there isn't much competition as the reciprocal $z^4+z^3+1$ is the only other quartic primitive polynomial. Consequently any zero of $z^4+z+1$ in this field is a primitive element. \u2013\u00a0Jyrki Lahtonen Jun 23 '14 at 5:24\n\nIn general, long division will always give you the right answer, but is often tedious. An approach like in Anurag A's answer will often make that calculation easier, but sometimes requires a bit of cleverness.\n\nAs for the example in your comment, a similar idea works. If you're computing modulo $x^{2}-1$, you're saying that $x^{2} -1 \\equiv 0$, or $x^{2} \\equiv 1$. So, we get:\n\n$$ x^{3} + 2x^{2} = x \\cdot x^{2} + 2 \\cdot x^{2} \\equiv x \\cdot 1 + 2 \\cdot 1 = x+2 . $$\n\nI'm thinking you should double check your long division on that one.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/67041/how-many-elements-with-a-hamming-distance-of-3-or-less/67104\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\n[This is a complete rewrite which makes some of the comments redundant or irrelevant.]\n\nTake a set of $50$ elements. How many subsets of size $5$ are needed so that every subset of size $5$ will intersect at least one of these in at least $2$ points?\n\nThis collection of subsets is known as a lottery wheel or a lotto design. $L(v,k,p,t)$ is the minimum number of subsets of a $v$ element set so that each subset has size $k$ with the property that every $p$ element subset intersects at least one $k$-subset in at least $t$ points. If you select $5$ out of $50$ numbers in a lottery which pays a prize for getting at least $2$ numbers right, then you can ensure getting a prize if you buy a particular collection of $L(50,5,5,2)$ tickets. The question is to find $L(50,5,5,2)$.\n\nshare|cite|improve this question\nCould you explain your definition of $d_h$ a bit more? (By the way, that formula defining $S$ is horrendous! Words really are better for these things.) \u2013\u00a0James Cranch Jun 6 '11 at 13:58\nThis sounds like lottery wheels or lottery designs. I suggest a web search. Gerhard \"Ask Me About System Design\" Paseman, 2011.06.06 \u2013\u00a0Gerhard Paseman Jun 6 '11 at 18:53\n@chous: you have not really defined $S_3$ uniquely. I think what you're really saying is that you want some set $T$ such that for every $s \\in S$ there is some $t \\in T$ with $d_h(s,t) \\le 3$. There are lots of such sets, for example $S$ itself. But perhaps what you want is one with minimum cardinality: you're talking about a \"minimal cover problem\" in a graph $G$ consisting of the elements of $S$, with edges corresponding to pairs with Hamming distance $\\le 3$. \u2013\u00a0Robert Israel Jun 7 '11 at 0:54\nHamming distance works better on sequences than on sets. Although we could phrase your distance in terms of the symmetric distance of two sets, I think it easier to say \"For any 5-set t, I want there to be at least one of my 5-sets s in S such that s intersect t has at least two elements. Further, I want S chosen so that S has as few 5-sets in it as can be managed.\" The La Jolla Covering Repository answers this sort of question (if I read it right). Do a web search and check it out if you agree. Gerhard \"Donates Regularly To Mega Millions\" Paseman, 2011.06.06 \u2013\u00a0Gerhard Paseman Jun 7 '11 at 1:44\nYou are asking for a wheel with parameters $(50,5,2)$. A covering design is different, which is unfortunate because there is a nice searchable database of covering designs, the La Jolla Covering Repository which Gerhard Paseman mentions. Most of the web hits when you search for lottery wheels are trying to sell junk to lottery players. \u2013\u00a0Douglas Zare Jun 7 '11 at 8:29\nup vote 7 down vote accepted\n\nYou are not using the positions at all. You have 50 points. $S$ is the set of all $\\binom{50}{5}=2118760$ selections of 5 points. You want a subset $B \\subset S$ such that any $s \\in S$ intersects at least one $b \\in B$ in at least 2 points. That is an interesting problem and does not immediately strike me as familiar. Call a member of $B$ a block. A given block intersects $152026$ members of $S$ in 2 or more points. This gives a lower bound of $14$ for the possible size of $B$. Of course this a weak bound since two disjoint blocks determine $200$ members of $S$ intersecting one in 2 points and the other in 3 and another $4000$ intersecting each in 2 points. If my calculations are correct, that raises the lower bound to at least $19$ blocks. I doubt that $20$ would suffice.\n\nSo far my record is 44 blocks.\n\nLet me digress for some terminology (which I'll try to keep fairly standard). a design is a pair $D=(V,B)$ where $V$ is a set of $v$ vertices and a $B$ is a collection of subsets called blocks There are various names for designs which satisfy additional conditions. Two are\n\nEvery pair of points is in exactly one common block. (Then $D$ is called a linear space)\n\nEvery pair of points is in at least one common block and every block has the same number $k$ of points. (Then $D$ is called a $(v,k,2)$-covering design and the La Jolla Repository has information about these.)\n\nWhen both conditions hold, $D$ is called a Steiner System $S(2,k,v).$ Many that one encounters arise from algebraic constructions. This is perhaps due to the Streetlight effect.\n\nI'll coin the term super-linear space for a design such that every pair of points from $V$ occur in at least one common block but the blocks may have various sizes (since I don't know a standard name. It turns out that this might be called a lottery wheel although that term is not very specific)\n\nYou have $50$ points and do not require that every pair of points is in a block but do wish that from every 5 points (element of $S$), at least one pair is in at least one block. You also want all blocks to have $5$ points. I'll find it convenient to only require that each block have at most 5 points, then one can arbitrarily enlarge blocks to size 5.\n\nAll my constructions have this form: Split the points into 4 groups (or 2 or 3) and for each group take a super-linear space with no block having more than 6 points. Then any element of $S$ has two points in the same group and those two points are in a common block. Perhaps one can do better without this restriction. I include a few other possibilities in case it inspires anyone to get a better result.\n\n44* blocks. Split into 4 groups of size 21,21,4 and 4. For each of the large groups take the 21 lines of a projective plane of order 4 and let the two small groups be 4 point blocks. Now any set in $S$ has at least two points in a common group and those two pints determine a unique block.\n\n60 blocks: split the points into two sets of 25 and use the 30 lines of an affine plane of order 5 on each. This is overkill because any 3 element set has two points in some block. Perhaps there is a way to cull out some of the lines.\n\nUnder 52 blocks If the points are partitioned into 3 groups of 13 and one of 11 (with two fake points added in) then (for each group) the lines of a projective plane of order 3 were taken as blocks this would give a solution with 52 blocks of size 4. Delete $X,Y$ to improve this to 45 of size 4 and 6 of size 3 and one of size two. Now tack the block of size 2 onto a block of size 3 to get $51$ blocks (one of size 5). (If $X,Y$ are in different groups it might be better, I haven't checked.) One can also get rid of at least 3 more blocks as follows: take a block abcd, delete it and add b as a fifth point to a block containing c and another containing c, add c as a fifth point to two blocks containing d and a and add d as a fifth point to two blocks containing a and b.\n\nshare|cite|improve this answer\nThanks a lot! How would you recommend to build the projective 3 space of order 4? I think I'm currently not ready for this task :(. \u2013\u00a0chous Jun 7 '11 at 12:18\nAaron Meyerowitz's construction for $42$ blocks used $F_3$ rather than $F_4$, which should make it easier. The construction is just like that of $\\mathbb{RP}^3$ so that the points are lines passing through the origin in $\\mathbb{R}^4$ and the lines of $\\mathbb{P}^3$ correspond to (two-dimensional) planes passing through the origin. $\\mathbb{P}^3(F_4)$ has $(4^4-1)/(4-1)=85$ points, though. \u2013\u00a0Douglas Zare Jun 7 '11 at 17:53\n$\\mathbb{P}^3(F_3)$ has ${40 \\choose 2}/{4 \\choose 2} = 130$ lines, not $40$, so the construction for $42$ blocks actually uses $132$ blocks. It was a little too good to be true since it would mean any quadruple would intersect a block in $2$ points, and it would be easy to use the $5$th points to make a line redundant. \u2013\u00a0Douglas Zare Jun 7 '11 at 18:40\n\nHere is a construction of size $38$. Call the points cards and divide the deck into $4$ suits, so that $2$ suits have ranks $1,...,13$ and $2$ suits have ranks $1,...,12$. Every hand of $5$ cards must have at least $2$ cards in some suit. So, if we cover all possible pairs in each suit, the result will be a wheel.\n\nThe La Jolla Covering Repository says that $C(12,5,2)=9$ so we can cover all pairs within the short suits with $9$ hands each:\n\n1  2  4  7  9 \n1  3  4  6 12 \n1  3  7 10 11 \n1  5  6  8 12 \n2  3  5  7  8 \n2  6 10 11 12 \n3  6  7  9 12 \n4  5  8 10 11 \n5  8  9 10 11 \n\nSimilarly, it says $C(13,5,2) \\le 10$ so we can cover all pairs within the long suits with $10$ hands each:\n\n1  2  3  4  5\n1  6  7  8  9\n1 10 11 12 13\n2  3  6  7 10\n2  3  8  9 11\n4  5  6  7 11\n4  5  8  9 10\n2  3  4 12 13\n5  6  7 12 13\n1  8  9 12 13\n\nThe total is $38$ hands which intersect each hand of $5$ cards in at least $2$ cards. So, $L(50,5,5,2) \\le 38$.\n\nEdit: The best this method can do with the coverings known in the La Jolla Repository is $37$. That can be done by splitting a $50$ card deck into suits of sizes $(17, 11, 11, 11),$ $(13,13,13,11)$, or $(15, 13, 11, 11)$.\n\n$C(17,5,2) \\le 16$.\n\n$C(15,5,2) \\le 13$.\n\n$C(13,5,2) \\le 10$ as shown above.\n\n$C(11,5,2) \\le 7$.\n\nshare|cite|improve this answer\nThanks (truly!) for clarifying the question and making my LJCR comment less useful (since a covering design was not wanted) and also more useful (by showing how two covering designs could help). Gerhard \"Likes To Feel Really Useful\" Paseman, 2011.06.07 \u2013\u00a0Gerhard Paseman Jun 7 '11 at 23:47\nThanks! I wish I could mark more than one answers. Searching in the Internet I found a solution with 36 tuples, and I'll try to find more using your suggestions, but I'm not discarding using a \"branch and bound\" algorithm. \u2013\u00a0chous Jun 8 '11 at 19:45\n@Douglas Zare: Thanks for rewriting the question. It's much clearer now. \u2013\u00a0chous Jun 8 '11 at 19:50\nPlease post at least a link to the wheel of size $36$, since it must have been constructed using a different method. It's ok to answer your own question. \u2013\u00a0Douglas Zare Jun 8 '11 at 20:01\nThis 36 block solution is nice. It is actually close to one of the 37 block solutions by @Douglas. In the solution with suits of size 11,11,11,17 and covering designs of sizes 7,7,7,16, each covering design has a block which can be reduced to 3 cards. Take the 3 card blocks abc def ghi jkl and replace them by abcjk defjl ghikl. In fact one of the pairs from jkl ( in the 17 card suit) has a pair already covered so one could leave one of the hands with three cards. \u2013\u00a0Aaron Meyerowitz Jun 10 '11 at 5:38\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/690866/triangle-geometric-problem\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn triangle ABC, AB=BC=12. Side AC extended through C a length equal to itself to a point D. Point E is on AB; DE intersects BC at F and BF equal to 8. Find AE ?\n\nshare|cite|improve this question\n\nThe answer is $AE=BE=6$ because in the triangle ABD, BC is a median and F is the intersection point of medians, therefore DE is also median. Since, $BF=8$ then $CF=4$, but we know that the intersection point of medians splits them into two segments which lenghts have quatient 2:1 from the vertex.\n\nshare|cite|improve this answer\n+1 Nice way of seeing it, in this special setup. You could fill in a bit more details about why F is the centroid (of what triangle). \u2013\u00a0Calvin Lin Feb 26 '14 at 6:56\n\nBC divides AD in half. So in triangle ABD, BC is the median. BF:FC = 2:1, so F is the centroid. Since ED passes through centroid, it is also a median. Hence AE = BE = 6.\n\nshare|cite|improve this answer\n\nHint: Apply Menelaus' theorem to triangle $ABC$ and transversal $DEF$.\n\nshare|cite|improve this answer\nYes, more \"classical\" theorems that don't get much \"air play\" nowadays... \u2013\u00a0RecklessReckoner Feb 26 '14 at 7:16\n@RecklessReckoner If you are a student training for olympiads, they are important. But once you are out of that phrase of your life, very few people care about Euclidean Geometry anymore. \u2013\u00a0Calvin Lin Feb 26 '14 at 8:05\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calculate-the-expected-frequencies-of-3-4-5-and-6-eggs.105383/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalculate the expected frequencies of 3,4,5 and 6 eggs\n\n  1. Dec 30, 2005 #1\n    Hello, i found one question really difficult and I cant solve it. Please help.\n\n    Six hens are observed over a period of 20 days and the number of eggs laid each day is summarised in the following table:\n\n    No. of eggs: 3 4 5 6\n    No. of days: 2 2 10 6\n\n    This can be considered as a binomial model, with n=6, for the total number of eggs laid in a day. State the probability that a randomly chosen hen lays an egg on a given day. Calculate the expected frequencies of 3,4,5 and 6 eggs.\n\n    I know the probability required is 5/6. but i dont know how to find the expected frequencies.\n  2. jcsd\n  3. Dec 30, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You said it is a binomial distribution so the frequencies (probabilities) are\n\n    [tex]p_j = \\binom {6}{j} \\left( \\frac {5}{6} \\right)^j \\left( \\frac {1}{6} \\right)^{6-j}[/tex]\n  4. Dec 30, 2005 #3\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    Tide, that's assuming the base probability is 5/6 which is one of the things Clari needs to determine.\n\n    Clari, you should know that the expected value for a binomial distribution with base probability p is np. The 6 chickens laid a total of 100 eggs in 20 days or an average of 5 eggs per day. Assuming that the sample does reflect the actual expected value, np= 6p= 5 so p= 5/6.\n\n    Now use Tides's suggestion to answer the rest of the problem.\n  5. Dec 30, 2005 #4\n    Thanks for your help,Tide and HallsofIvy ^-^\n\nHave something to add?\n\nSimilar Discussions: Calculate the expected frequencies of 3,4,5 and 6 eggs"}
{"text": "Retrieved from http://mathoverflow.net/questions/128993/on-solution-of-a-discrete-time-equation\nText:\nTake the 2-minute tour \u00d7\n\nHello, members. I have a problem for the following problem when I derive an optimization algorithm for stochastic singular systems $$S(k+1)=A(k)S(k)A^{T}(k)+R(k)+F(k)S(k+1)F^{T}(k)$$ where $R(k)>=0$ So, how to calculate $S$, is there analytic solution or numerical solution to $S$?\n\nThis problem is different from the following one On solution of a recursion with rectangular matrices\n\nThanks for your help\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nyou'll want to solve this equation iteratively, considering $S(k)$ as known and $S(k+1)$ as unknown; for $F(k)$ invertible you then have a Sylvester equation, of the form $F^{-1}(k)S(k+1)-S(k+1)F^{T}(k)=C(k)$, which has a unique solution iff $F^{-1}(k)$ and $F(k)$ have no common eigenvalue. The Wikipedia page gives algorithms to solve this equation, implemented in several software packages.\n\nshare|improve this answer\nThere are numerical methods dealing directly with the equation $X-FXF^T=C$, known as discrete-time Lyapunov equation, or Stein equation. There is no need to invert $F$ and convert it to a Sylvester; sometimes algorithms even go the other way round and convert a continuous-time Lyapunov equation to a discrete-time one to solve it. \u2013\u00a0 Federico Poloni Apr 28 '13 at 18:37\nThanks for your kind help, Dr. Carlo and Dr. Federico. When $F$ is singular, The Sylvester method may fail to work. So, would you please give me some links or references on the equation $X-FXF^{T}=C$. It seems we can solve it using LMI techniques for obtaining numerical solutions. \u2013\u00a0 eolithr Apr 29 '13 at 1:07\nNo, I made the problem too complex. By using 'dlyap' in Matlab can solve this equation. \u2013\u00a0 eolithr Apr 29 '13 at 3:04\nYep. dlyap will be fine for a small-scale problem; it should use a variant of the same Bartels-Stewart method that is used for continous-time lyapunov eqs; essentially, take a Schur form of $F$ and solve directly via back-substitution for each entry of $X$ \"in the right order\". For large-scale problems, you can truncate the series $X=\\sum_{i=0}^{\\infty} F^{i}CF^{Ti}$, or obtain the partial sum truncated at the term $2^{k}$ directly from the one truncated at $2^{k-1}$ with some manipulations (Smith methods). You can apply some M\u00f6bius transforms to $F$ without changing the solution to make... \u2013\u00a0 Federico Poloni Apr 29 '13 at 7:09\nit more stable, and ultimately obtain a discrete-time version of the ADI method for Lyapunov equations. In short, with some algebraic manipulations everything that works in the continuous-time case rates to work in the discrete-time case as well. \u2013\u00a0 Federico Poloni Apr 29 '13 at 7:10\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/45759/find-the-limit-lim-limits-n-to-infty-cos-left-pi-sqrtn2-n-right/45760\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI'd love your help with finding the following limit: $$\\lim_{n\\to \\infty }\\cos (\\pi\\sqrt{n^{2}-n}).$$\n\nI was asked to find this limit, but honestly I believe that it doesn't exist.\n\nAccording to Heine Theorem of limit of functions, I can choose two sequences:\n\n$x_{k}=2\\pi k$ and $y_{k}=2\\pi k+\\pi$ and notice that when I apply the function on both of them, I'll get -1 and 1, respectively.\n\nAm I right?\n\nThank you again.\n\nshare|cite|improve this question\nDo you mean to have that $\\pi$ in your sequences? There's already multiplication by $\\pi$ inside the cosine. Or did you plan to start with, say, $x_k$, and work backwards to a sequence of $n_k$ such that $\\cos\\pi\\sqrt{n_k^2-n_k} = \\cos{x_k}$? \u2013\u00a0MartianInvader Jun 16 '11 at 17:12\nYes, my mistake. without the $\\pi$'s. thanks. \u2013\u00a0user6163 Jun 17 '11 at 7:05\nYou kinda started the wrong way, by asking what tool to use. Your first question should have been \"what's happening here?\" It is then natural to calculate, for largish but not too large $n$. (Not too large because if you take $n=10^9$, roundoff error kills you.) So look at $n=100, 101, 102$. Calculate. You will get answers near $0$. And while you are taking $\\sqrt{n^2-n}$, you may notice it is almost exactly halfway between consecutive integers. Now an idea for a proof may come. \u2013\u00a0Andr\u00e9 Nicolas Jun 18 '11 at 3:39\nup vote 56 down vote accepted\n\nWe have \\begin{align*} \\cos (\\pi\\sqrt{n^2-n})&= (-1)^n\\cos(\\pi(\\sqrt{n^2-n}-n))\\\\ &= (-1)^n \\cos\\pi\\frac{-n}{\\sqrt{n^2-n}+n}\\\\ &=(-1)^n\\cos \\pi\\frac 1{\\sqrt{1-\\frac 1n }+1}, \\end{align*} hence $|\\cos(\\pi\\sqrt{n^2-n})| = \\left|\\cos \\left(\\pi\\frac 1{\\sqrt{1-\\frac 1n }+1}\\right)\\right|$. Since $\\lim \\limits_{n\\to +\\infty}\\pi\\frac 1{\\sqrt{1-\\frac 1n }+1} =\\frac{\\pi}2$, the $\\cos$ is continuous and $\\cos \\frac{\\pi}2 =0$ we conclude that the limit is $0$.\n\nshare|cite|improve this answer\nIt is intresting that when you go by intuition and write the limit as $\\cos \\pi n\\sqrt{1-\\frac{1}{n}}$ you sincerely might think that the limit does not exist. \u2013\u00a0user6163 Jun 18 '11 at 10:14\n@Nir Yes, I agree. The idea comes from an exercise that I've done some years ago. I had to look at the convergence of the series $\\sum_{n\\geq 0}\\sin(\\pi\\sqrt{n^2+1})$. \u2013\u00a0Davide Giraudo Jun 18 '11 at 10:25\nAre you sure of this answer?*sqrt+%28n^2-n%29%29 \u2013\u00a0user6163 Jun 18 '11 at 10:37\n@Nir: it is very important that $n$ here is integer. \u2013\u00a0Marek Jun 18 '11 at 12:18\n\nSince a nice formal argument has been supplied by Davide Giraudo, I will allow myself the luxury of informality.\n\nLet $n$ be a large positive integer. Complete the square. We have $$n^2-n=\\left(n-\\frac{1}{2}\\right)^2 -\\frac{1}{4}$$\n\nTake the square root. When $n$ is very large, the term $-1/4$ makes a vanishingly small contribution to the square root.\n\nSo our square root is nearly equal to $n-1/2$. And the cosine of $\\pi n -\\pi/2$ is $0$.\n\nshare|cite|improve this answer\n\nConsidering the form $\\cos(\\pi n \\sqrt{1-\\frac{1}{n}})$ and using Taylor's expansion for $\\sqrt{1-\\frac{1}{x}}$ $\\to$ see here, we get that when n is large $\\cos (\\pi\\sqrt{n^{2}-n}) \\approx \\cos( \\pi n -\\frac{\\pi}{2})$. Therefore, $L=0$.\n\n\nshare|cite|improve this answer\nNice answer Chris's sis........ \u2013\u00a0juantheron Nov 3 '13 at 13:36\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/609700/in-how-many-ways-can-we-select-n-objects-from-a-collection-of-size-2n-that-consi\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn how many ways can we select $n$ objects from a collection of size $2n$ that consists of $n$ distinct and $n$ identical objects?\n\nThe answer is $2^n$ and I really don't see how they get this. Selecting $n$ distinct from $2n$ is $\\binom{2n}{n}$.\n\nshare|cite|improve this question\nTry working a small example: one white sock, one red sock, two black socks. Hint: sort the 12 possibilities in order by number of black socks. \u2013\u00a0Eric Lippert Dec 17 '13 at 0:31\n\nLet $A=\\{a_1,\\ldots,a_n\\}$, where the $a_k$ are mutually distinguishable, and let $S$ be $A$ together with $n$ indistinguishable objects. An $n$-element subset $X$ of $S$ is completely determined when you know $X\\cap A$: if $|X\\cap A|=k$, the remainder of $X$ is just $n-k$ of the indistinguishable objects. $A$ has $2^n$ subsets, so there are exactly $2^n$ different possibilities for $X\\cap A$ and therefore for distinguishable sets $X\\subseteq S$ of cardinality $n$.\n\nshare|cite|improve this answer\n\nHint. If you choose $k$ elements from the $n$ distinct, and $n-k$ from the $n$ identical, there are:\n\n$$\\binom{n}{k}\\cdot 1$$\n\nways to do this. Now sum from $k=0$ to $k=n$.\n\nshare|cite|improve this answer\n\nNote that the set of objects chosen is determined by which of the distinct objects are chosen and how many of the identical objects are chosen. For each of the $2^n$ subsets of the $n$ distinct objects, the number of identical objects we need to take in order to fill our quota of $n$ total objects is uniquely determined. Hence there are $2^n$ total ways to take $n$ total objects from $n$ distinct and $n$ identical objects.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/63283/proof-that-lnn2-lnn-1-n-for-all-n-in-mathbbn\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nI would like to know which proof strategy to use when proving the next inequality: $\\ln(n^2)(\\ln(n) - 1) < n,\\quad\\forall n \\in \\mathbb{N}$. I have been trying to use this two proved inequalities $\\dfrac{n}{n+1} < \\ln(n+1) < n$ ,but it did not give me solution.\n\nshare|cite|improve this question\nHint: $log(n^2)(log(n)-1) \\le 2 log(n)^2$. \u2013\u00a0Dan Brumleve Sep 10 '11 at 9:08\n@Dan,I think that it is wrong approach \u2013\u00a0pedja Sep 10 '11 at 9:32\npedja, try $n \\ge 14$. Can you show inductively that the inequality continues to be satified? Then check the finite cases. \u2013\u00a0Dan Brumleve Sep 10 '11 at 9:41\n@pedja, please DO NOT CHANGE (substantially) THE QUESTION, it invalidates correct answers to the question as was asked. If you want to ask a different question, you can leave this one as is and go ask a different question. \u2013\u00a0Did Sep 11 '11 at 8:50\n@pedja Also, I do not think that the [algebra] tag means what you take it to mean. The [algebra-precalculus] tag seems more appropriate (even though most solutions till now seem to employ calculus in some form). \u2013\u00a0Srivatsan Sep 11 '11 at 8:57\nup vote 7 down vote accepted\n\nDefine a function $u$ on $x>0$ by $u(x)=x-\\log(x^2)(\\log(x)-1)=x-2\\log(x)^2+2\\log(x)$. The goal is to prove that $u(n)>0$ for every positive integer $n$, let us prove the stronger statement that $u(x)\\ge1$ for every real number $x\\ge1$.\n\nTo do so, first note that $u'(x)=v(x)/x$ with $v(x)=x-4\\log(x)+2$ and that $v'(x)=1-4/x$, hence $v$ is decreasing on $(1,4)$ and increasing on $(4,+\\infty)$.\n\nSince $v(4)=6-8\\log(2)=.4548>0$, $v>0$ everywhere and $u$ is increasing. In particular, $u(x)\\ge u(1)=1$ for every $x\\ge1$.\n\nFinally, for every positive integer $n$, $$ \\log(n^2)(\\log(n)-1)\\le n-1<n. $$\n\nshare|cite|improve this answer\n,I was looking for more \"algebraic\" proof but this looks nice also....I will wait bit more before accepting answer \u2013\u00a0pedja Sep 10 '11 at 13:10\n\nMake the substituting $x = \\log n$, so $x \\geq 0$. The inequality now reads $$ 2x(x-1) < \\exp(x). $$ All we have to do know is to take the Taylor expansion of $\\exp(x)$ and stop at the right place. For example, $$ 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\frac{x^4}{24} < \\exp(x), $$ and it so happens that when $x \\geq 0$, $$ 2x(x-1) < 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\frac{x^4}{24}. $$ This can be verified formally using e.g. Sturm sequences (or by finding explicitly all the roots using the quartic formula).\n\nshare|cite|improve this answer\n,using quartic formula is not so elegant solution but may give positive result... \u2013\u00a0pedja Sep 11 '11 at 5:07\nquartic formula \u2013\u00a0pedja Sep 11 '11 at 5:36\n\nHere's a simple approach. Verify the inequality for the base cases $n=1$ and $n=2$; we will assume $n \\geq 3$ from now on. Let us now make the substitution $x = \\ln n$ (where $x \\geq \\ln 3 > 1$), and rewrite the inequality as $e^x \\geq 2x(x-1)$.\n\nUsing the famous inequality $e^{t} \\geq t+1$, we get $$ e^{x- \\frac{3}{2}} \\geq x- \\frac{1}{2}. $$ for all real $x$. Integrating between the limits $0$ and $x > 0$, we get: $$ e^{x- \\frac{3}{2}} - e^{-\\frac{3}{2}} \\geq \\frac{1}{2}(x^2-x). $$ Rearranging this slightly (and dropping one term), we get $$ e^x \\geq \\frac{e^{3/2}}{4} \\cdot 2x(x-1), $$ which implies the claim since $\\frac{e^{3/2}}{4} \\geq 1.1 > 1$. (Note that the final step is valid only if $2x(x-1)$ is positive, but this is the true since $x \\geq 1$.)\n\nshare|cite|improve this answer\nIt is funny that the numerical evaluation your solution relies on, namely that $\\log(2)<\\frac34$, is exactly the one needed in my solution, although the rest of our proofs seem to use different arguments. \u2013\u00a0Did Sep 11 '11 at 7:18\n@Didier That's true, I didn't see that till now. :-) There should be some explanation I guess... \u2013\u00a0Srivatsan Sep 11 '11 at 7:25\n@SrivatsanNarayanan,Brilliant but not strictly algebraic since integration is involved \u2013\u00a0pedja Sep 11 '11 at 8:01\n@pedja I do not know what Didier thinks, but my answer is: it depends. Since you did not (!) object to my first inequality $e^t \\geq t+1$, if you are ok with using it, I can actually believe that there is an algebraic proof that uses only that inequality. Otherwise I cannot imagine any way... \u2013\u00a0Srivatsan Sep 11 '11 at 8:13\n@pedja, I usually try to avoid thinking, it gives me headaches... More seriously, I wanted to draw your attention to the fact that the logarithm is not a priori an algebraic object (whatever that means), hence that your motto of a purely algebraic proof was odd, mathematically speaking. (As regards MO etiquette, you did not mention this requirement in the question itself and you gave no motivation for it). \u2013\u00a0Did Sep 11 '11 at 8:21\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/how-can-one-find-the-area-between-the-curves.90727/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nHow can one find the area between the curves\n\n  1. Sep 25, 2005 #1\n    when three curves intersect,i mean like the intersection of three straight lines to give a triangle,how can one find the area between the curves\n  2. jcsd\n  3. Sep 25, 2005 #2\n    area of a triangle is given by 1/2 * b * h\n  4. Sep 25, 2005 #3\n    I think mathelord means any three curves. You can use a double integral. Do you know calculus?\n  5. Sep 25, 2005 #4\n    If you don't know calculus you calculate the height. The factor of two perpendicular slopes is -1.\n  6. Sep 26, 2005 #5\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    The man said curves! Assuming he is asking about the area of the region formed by three general curves, he will need to use caluculus.\n\n    Exactly how that is done depends on the curves themselves. In the very common situation, a sort of \"curvy\" triangle, where you have one curve under the other two (between the points where the other two intersect it), then you don't need a double integral. You will need to break the integral into two parts. I'm going to call the curve on the bottom C1, the graph of y= f1(x), and the other two C1 and C2, graphs of y=f2(x), y= f3(x) respectively. Let's say that C2 intersect C1 at x=a, C3 intersects C1 at x= c, and that C2 is below C3 until they intersect at x= b after which C3 is below C2.\n\n    Then the area is given by two separate integrals:\n    [tex]\\int_a^b(f2(x)-f1(x))dx+ \\int_b^c(f3(x)-f1(x)dx[/tex]\n\nHave something to add?\n\nSimilar Discussions: How can one find the area between the curves\n  1. How do i find the area (Replies: 1)\n\n  2. How can one prove (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/limit-of-a-long-trig-function.268716/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLimit of a long trig function.\n\n  1. Nov 2, 2008 #1\n    x->0 ((sin5x)/(sin2x) - (sin3x)/(4x))\n\n    2. Relevant equations\n    i guess sinx/x as x approaches zero is 1.\n\n    3. The attempt at a solution\n    lets be honest, this is a simple question. i am getting a final answer of 4, but it is wrong apperently according to the book's solution. i want to see if anyone else got this answer\n\n    I separated the limit into two limits, divided by 5x's and 2x's on the left limit and divided by 3x's on the right limit. this shouldnt be a problem (and yes i divided top and bottom by the same amounts so they would cancel out; thats not my mistake). please someone help\n  2. jcsd\n  3. Nov 2, 2008 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    You've obviously made an algebra error somewhere, If you show your work, we can tell you where your error is.\n  4. Nov 2, 2008 #3\n\n\n    Staff: Mentor\n\n    Are you sure you have given us the problem as it appears in your book or assignment? Could it be lim sin(5x)/(2x) - sin(3x)/(4x)? If so, that's a much simpler problem, whose limit is 1.75, as x approaches 0.\n  5. Nov 2, 2008 #4\n\n\n    User Avatar\n    Staff Emeritus\n    Science Advisor\n\n    [tex]\\frac{sin(3x)}{4x}= \\frac{3}{4}\\frac{sin(3x)}{3x}[/tex]\n\n    [tex]\\frac{sin(5x)}{sin(2x)}= \\frac{5}{2}\\frac{sin(5x)}{5x}\\frac{sin(2x)}{2x}[/tex]\n  6. Nov 2, 2008 #5\n    HOW IS IT 1.75!!!!!!!!!!!!!!!!!!!! wheres the flaw in my logic.\n\n    (sin5x)/sin2x = [((sin5x)/(5x*2x)]/[(sin2x)/(5x*2x)]\n    = (5/2x)/(2/5x))\n    = 25/4\n\n    (sin3x)/4x = [(sin3x/3x)]/[(4x/3x)]\n    = 3/(4x/3x)\n    = 3/(4/3)\n    = 9/4\n\n    25/4 - 9/4 = 16/4 = 4 where is my flaw!!!???\n  7. Nov 2, 2008 #6\n\n\n    Staff: Mentor\n\n    Halls, are you missing a division symbol in your second equation?\n  8. Nov 2, 2008 #7\n\n\n    Staff: Mentor\n\n    How did you get (5/2x)/(2/5x)) from the expression above it? lim (as x [tex]\\rightarrow[/tex] 0) of sin(5x) / (5x) is 1, not 5, if that's what you did.\n\n    The expression on the right side of your first line is equal to\n    [tex]\\frac{sin(5x)}{5x} * \\frac{5x}{2x} * \\frac{2x}{sin(2x)}[/tex]\n    As x [tex]\\rightarrow[/tex] 0, this expression approaches 1 * 5/2 * 1 = 5/2. Similarly sin(3x)/(4x) approaches 3/4, so the difference approaches 7/4 = 1.75.\n\n    Regarding my earlier question about whether the denominator of the first fraction should have been 2x rather than sin(2x), it doesn't matter. For x close to 0, sin(x) [tex]\\approx[/tex] x, and sin(2x) [tex]\\approx[/tex] 2x.\n\n\nHave something to add?\n\nSimilar Discussions: Limit of a long trig function.\n  1. Limit of trig function (Replies: 23)"}
{"text": "Retrieved from http://math.stackexchange.com/questions/148444/how-to-solve-the-limit-of-a-succession-on-this-particular-circumstances\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nGiven this limit $\\displaystyle\\lim_{n \\to{+}\\infty}{\\frac{\\sqrt{16n^2+3}}{(1+a_n)n+5cos n}=\\frac{7}{6}}$ I need to calculate this one : $\\displaystyle\\lim_{n \\to{+}\\infty}{a_n}$\n\nAny ideas of how to solve it. Thanks!!!\n\nshare|cite|improve this question\nHint: Divide top and bottom by $n$, let $n$ get big. Top approaches $4$. Term $(5\\cos n)/n$ at the bottom dies. So for large $n$, $4/[(1+a_n)]$ is very close to $7/6$, and therefore $\\dots$ \u2013\u00a0Andr\u00e9 Nicolas May 22 '12 at 22:40\nup vote 1 down vote accepted\n\nHint: write $$ {\\sqrt{16n^2+3}\\over (1+a_n) n +5\\cos n} = {n\\cdot\\sqrt{16+{3\\over n^2} }\\over n\\cdot\\bigl( (1+a_n)+{5\\cos n\\over n}\\bigr)} = {\\sqrt{16+{3\\over n^2} }\\over (1+a_n)+{5\\cos n\\over n}}. $$ Then note $$ \\lim_{n\\rightarrow\\infty} {\\sqrt{16+{3\\over n^2} }\\over (1+a_n)+{5\\cos n\\over n}} ={4\\over 1+\\lim\\limits_{n\\rightarrow\\infty}a_n}. $$\n\nshare|cite|improve this answer\nPerfect. Thank you so much. I have a test tomorrow, and this exercise was killing me! \u2013\u00a0limoragni May 22 '12 at 23:12\n\nYour Answer"}
{"text": "Retrieved from http://physics.stackexchange.com/questions/27479/calculating-correlation-functions-of-exponentials-of-fields\nText:\nSign up\nHere's how it works:\n  1. Anybody can ask a question\n  2. Anybody can answer\n\nIn their book Condensed Matter Field Theory, Altland and Simons often use the following formula for calculating thermal expectation values of exponentials of a real field $\\theta$:\n\n$$ \\langle e^{i(\\theta(x,\\tau)-\\theta(0,0))} \\rangle = e^{-\\frac12 \\langle (\\theta(x,\\tau)-\\theta(0,0))^2 \\rangle} $$\n\nAn example can be found in chapter 4.5, problem \"Boson-fermion duality\", part c). (This refers to the second edition of the book, page 185.)\n\nIn other words, expectation values of exponentials can be cast as exponentials of expectation values under certain conditions. Unfortunately, I seem to be unable to find an explanation of why this can be done and what the conditions on the Lagrangian of $\\theta$ are.\n\nHence, my question is:\n\nHow to derive the above formula? What do we need to know about $\\theta$ for it to be valid in the first place?\n\nIdeally, I am looking for a derivation using the path integral formalism. (I managed to rederive a very special case in terms of operators and the Baker-Campbell-Hausdorff formula, but I'd like to gain a more thorough understanding.)\n\nshare|cite|improve this question\nup vote 17 down vote accepted\n\nThis is just a property of Gaussian averaging analogous to the finite dimensional case:\n\n$\\langle e^{ix} \\rangle=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty} e^{ix}e^{-\\frac{x^2}{2\\sigma^2}}=e^{-\\frac{\\sigma^2}{2}}= e^{-\\frac{\\langle x^2 \\rangle}{2}}$\n\nThe field can be decomposed into its independent Gaussian modes and integrated for each mode separately.\n\nshare|cite|improve this answer\nThe simplest answers are simply the best. \u2013\u00a0Greg Graviton Oct 7 '11 at 7:50\nSo this formula only holds in the noninteracting case. \u2013\u00a0Arnold Neumaier May 2 '12 at 18:48\n\nDavid Bar Moshe's derivation is of course right. Let me offer you a Taylor-expansion-based alternative proof: $$ \\left\\langle e^{ix} \\right \\rangle = \\left\\langle \\sum_{n=1}^\\infty \\frac{(ix)^n}{n!} \\right \\rangle = \\left\\langle \\sum_{k=1}^\\infty \\frac{(ix)^{2k}}{(2k)!} \\right \\rangle $$ Here, I just used that by some odd-ness, the odd powers have a vanishing expectation value. In the formula above, $x$ is whatever linear function of the elementary fields you want, including your coefficient. But the expectation value of $x^{2k}$ is $$ \\left\\langle x^{2k} \\right \\rangle = \\frac{ \\int_{-\\infty}^\\infty {\\rm d}x \\,x^{2k}\\exp(-x^2/2x_0^2)}{ \\int_{-\\infty}^\\infty {\\rm d}x \\,\\exp(-x^2/2x_0^2)} = 1\\times 3\\times \\cdots \\times (2k-1) \\times x_0^{2k} $$ which may be computed by integrating by parts or by converting it to the Euler integral (which is also evaluated by parts) so when you combine it with the $1/(2k)!$ factor, the odd integers cancel, only the product of the even integers which is equal to $2^k k!$ is left, and the original sum from the first line is $$\\sum_{k=1}^\\infty \\frac{(-x_0^2)^k}{2^k k!} = \\exp(-x_0^2/2) $$ where $x_0^2$ is the expectation value of $\\langle x^2\\rangle$ because I used it in the probabilistic distribution. Again, you may set $x=\\theta(x_1,t_1)-\\theta(x_2,t_2)$ or whatever linear function of variables and my derivation still holds.\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/121961/is-there-a-n-2-version-of-the-erdos-hanani-conjecture?answertab=votes\nText:\nTell me more \u00d7\n\nThis question comes out of REU research from this past summer. Unfortunately weeks of thought led to only trivial observations and the conclusion that the problem is quite hard.\n\nFix $k,t$. Let $F$ be a set of $k$-subsets of $[n] := \\{1,\\ldots,n\\}$ of minimal cardinality such that $F$ covers all $t$-subsets of $[n]$ (covers in the sense that any $t$-subset of $[n]$ is a subset of an element of $F$.) Let $\\kappa_n := |F|$. The Erd\u0151s-Hanani conjecture states that\n\n$\\kappa_n = \\binom{n}{t} / \\binom{k}{t}(1 + o(1))$.\n\nOf course $\\binom{n}{t} / \\binom{k}{t}$ is a lower bound on $\\kappa_n$, so the EH conjecture is saying that the obvious necessary condition is asymptotically sufficient. R\u00f6dl proved the EH conjecture in 1985.\n\nThis question is about what happens when $k$ and $t$ are not fixed. Specifically, take $k = \\lfloor n/2 \\rfloor$ and $t = \\lfloor n/2\\rfloor - 1$. Define $F$ and $\\kappa_n$ as above. Is it true that\n\n$\\kappa_n = \\frac{1}{\\lfloor n / 2 \\rfloor} \\binom{n}{\\lfloor n/2 \\rfloor}(1 + o(1))$?\n\n\nThe EH conjecture lead to the study of what is called \"packing in a hypergraph.\" See R\u00f6dl's proof introduced what is now called the \"R\u00f6dl nibble\" and is pseudo-random in nature. Spencer gave a lovely proof using branching processes. There are a lot of results from the late 80s to 90s that say, as Kahn puts it in \"Asymptotics of Hypergraph Matching, Covering and Coloring Problems\", that hypergraphs are asymptotically well-behaved as long as their edge sizes are bounded! Unfortunately the $n/2$ version of EH involves hypergraphs of unbounded edge size and the existing methods appear useless.\n\nSome ideas\n\nA straightforward application of the method of alterations (or equivalently, some easy analysis of the greedy algorithm) gives that $\\kappa_n \\leq \\log n \\frac{1}{\\lfloor n / 2 \\rfloor} \\binom{n}{\\lfloor n/2 \\rfloor} (1 + o(1))$, so the whole question is whether we can eliminate this log factor.\n\nA set of $\\lfloor n/2 \\rfloor$-subsets has maximum coverage of $(\\lfloor n/2 \\rfloor - 1)$-subsets when all its elements have pairwise symmetric difference of at least 4. So really this is a coding theory problem. The paper \"Lower bounds for constant weight codes\" by Graham and Sloane shows that we can find a set $H$ of $\\lfloor n /2\\rfloor$-subsets of $[n]$ such that $|H| \\geq \\frac{1}{2}\\binom{n}{\\lfloor n/2 \\rfloor}$ and the hamming distance between elements is at least 4. Let $G$ be the set of $(\\lfloor n/2 \\rfloor - 1)$-subsets covered by $H$. $G$ is half the size we want it to be, but we only used half as many elements are we are allowed. So we might be optimistic that by allowing some small overlap we can cover everything we want. If we take a permutation $\\sigma \\in S_n$ and look at $\\sigma(H)$ (i.e. apply the permutation to the elements of the elements of $H$) it covers $\\sigma(G)$. Of course $|\\sigma(G)| = |G|$. We could hope that a good choice of $\\sigma$ gives $|G \\cup \\sigma(G)| \\approx 2|G|$ and we have found an appropriate set $F := H \\cup \\sigma(H)$. I asked the question of whether such a $\\sigma$ must exist before: Size of union of a set of subsets and its permutations. That question is interesting in its own right, but this EH conjecture is really why I wanted an answer.\n\nshare|improve this question\nHave you checked out the La Jolla Covering Repository online? That might give a nice suggestion of what to expect. Gerhard \"Ask Me About System Design\" Paseman, 2013.02.15 \u2013\u00a0 Gerhard Paseman Feb 16 at 1:32\nDoes your description have $t$ and $l$ mixed up? If so, please edit. \u2013\u00a0 Brendan McKay Feb 16 at 1:36\n@Brendan McKay: Yes, thank you. It is corrected. \u2013\u00a0 Sam Hopkins Feb 16 at 2:04\nI should mention also that the Graham-Sloane construction means that the EH-conjecture for $k = \\phi(n)$ and $t = k - 1$ has a positive answer when $\\phi(n) = o(n)$, so $n/2$ is in fact the \"hard case.\" \u2013\u00a0 Sam Hopkins Feb 16 at 2:15\nSome structural results on this part of the boolean lattice can be found with the search phrases \"middle levels\" and \"boolean\" together. For example, see the references in . \u2013\u00a0 Brendan McKay Feb 16 at 3:09\nshow 1 more comment\n\n\nYour Answer\n\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://physics.stackexchange.com/questions/8453/are-there-examples-in-classical-mechanics-where-dalemberts-principle-fails\nText:\nTell me more \u00d7\n\nD'Alembert's principle suggests that the work done by the internal forces for a virtual displacement of a mechanical system in harmony with the constraints is zero.\n\nThis is obviously true for the constraint of a rigid body where all the particles maintain a constant distance from one another. It's also true for constraining force where the virtual displacement is normal to it.\n\nCan anyone think of a case where the virtual displacements are in harmony with the constraints of a mechanical system, yet the total work done by the internal forces is non-zero, making D'Alembert's principle false?\n\nshare|improve this question\nrelated: \u2013\u00a0 Ben Crowell Aug 13 at 19:25\nadd comment\n\n2 Answers\n\nGiven a system of $N$ point-particles with positions ${\\bf r}_1, \\ldots , {\\bf r}_N$; with corresponding virtual displacements $\\delta{\\bf r}_1$, $\\ldots $, $\\delta{\\bf r}_N$; with momenta ${\\bf p}_1, \\ldots , {\\bf p}_N$; and with applied forces ${\\bf F}_1^{(a)}, \\ldots , {\\bf F}_N^{(a)}$. Then D'Alembert's principle states that\n\n$$\\tag{1} \\sum_{j=1}^N ( {\\bf F}_j^{(a)} - \\dot{\\bf p}_j ) \\cdot \\delta {\\bf r}_j~=~0. $$\n\nThe total force\n\n$${\\bf F}_j ~=~ {\\bf F}_j^{(a)} +{\\bf F}^{(ec)}_j+{\\bf F}^{(ic)}_j + {\\bf F}^{(i)}_j + {\\bf F}_j^{(o)}$$\n\non the $j$'th particle can be divided into five types:\n\n  1. applied forces ${\\bf F}_j^{(a)}$ (that we keep track of and that are not constraint forces).\n\n  2. an external constraint force ${\\bf F}^{(ec)}_j$ from the environment.\n\n  3. an internal constraint force ${\\bf F}^{(ic)}_j$ from the $N-1$ other particles.\n\n  4. an internal force ${\\bf F}^{(i)}_j$ (that is not an applied or a constraint force of type 1 or 3, respectively) from the $N-1$ other particles.\n\n  5. Other forces ${\\bf F}_j^{(o)}$ not already included in type 1, 2, 3 and 4.\n\nBecause of Newton's 2nd law ${\\bf F}_j= \\dot{\\bf p}_j$, D'Alembert's principle (1) is equivalent to$^1$\n\n$$\\tag{2} \\sum_{j=1}^N ( {\\bf F}^{(ec)}_j+{\\bf F}^{(ic)}_j+{\\bf F}^{(i)}_j+{\\bf F}_j^{(o)}) \\cdot \\delta {\\bf r}_j~=~0. $$\n\nSo OP's question can essentially be rephrased as\n\nAre there examples in classical mechanics where eq. (2) fails?\n\nEq. (2) could trivially fail, if we have forces ${\\bf F}_j^{(o)}$ of type 5, e.g. sliding friction, that we (for some reason) don't count as applied forces of type 1.\n\nHowever, OP asks specifically about internal forces.\n\nFor a rigid body, to exclude pairwise contributions of type 3, one needs the strong Newton's 3rd law, cf. this Phys.SE answer. So if these forces fail to be collinear, this could lead to violation of eq. (2).\n\nFor internal forces of type 4, there is in general no reason that they should respect eq. (2).\n\nExample: Consider a system of two point-masses connected by an ideal spring. This system has no constraints, so there are no restrictions to the class of virtual displacements. It is easy to violate eq. (2) if we count the spring force as a type 4 force.\n\n\nH. Goldstein, Classical Mechanics, Chapter 1.\n\n\n$^1$It is tempting to call eq. (2) the Principle of virtual work, but strictly speaking, the principle of virtual work is just D'Alembert's principle (1) for a static system.\n\nshare|improve this answer\nadd comment\n\nYou can have instances where there is no local extremum of the action--for instance, take the lagrangian $L=m\\left(\\dot x ^{2}+\\dot y^{2}\\right)$ over the space defined by a crescent embedded in $\\mathbb{R}^2$--then, even though the tips of the crescent are both perfectly good starting and ending points in your domain, there is no extremal path connecting them--it would have to be the straight line that leaves the domain of your configuration space.\n\nBut this is admittedly a contrived example.\n\nshare|improve this answer\nI was asking about cases where D'Alembert's principle fails, not where the principle of least action fails - which is the application of D'Alembert's principle for holonomic constraints. \u2013\u00a0 Larry Harson May 13 '11 at 16:26\n@user2146: and thus, a subclass of D'Albert's principle. \u2013\u00a0 Jerry Schirmer May 13 '11 at 16:31\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/301722/meaning-of-p-phi-where-phi-x-y-xy-x-2y-and-px-x2-2x-1\nText:\nSign up \u00d7\n\nConsider the linear transformation $\\phi : \\mathbb{R}^2 \\to \\mathbb{R}^2$ defined by $\\phi (x,y) = (x+y, x- 2y)$. Let $p(x) = x^2 -2x + 1$. Does $p(\\phi)$ make sense and if yes what is it?\n\nshare|cite|improve this question\n$\\phi^2=\\phi\\circ \\phi$ etc. \u2013\u00a0 Jp McCarthy Feb 13 '13 at 1:09\nIf $p$ is a polynomial then you cannot evaluate a polynomial at a vector in $\\mathbb R^2$. But a linear transformation \"is\" a matrix, and $p(\\phi)$ may denote $p(\\textrm{this matrix})$, which is a matrix. \u2013\u00a0 Brenin Feb 13 '13 at 1:12\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nYes, one can make sense of this according to the following: if $\\phi: X \\rightarrow X$ is a function on a vector space (not even necessarily linear), and if $p(x) = ax^2 + bx + c$ is a polynomial, then $$ p(\\phi) = a (\\phi \\circ \\phi) + b \\phi + c \\, \\mathrm{Id}_X $$ where $\\phi \\circ \\phi$ indicates composition of $\\phi$ with itself, and $\\mathrm{Id}_X$ is the identity map. We can generalize this appropriately to any polynomial $p$.\n\nIn your specific case, you can compute this in a variety of ways, either by hand, or by first finding a matrix representation of $\\phi$, call it $A$, and then $p(\\phi)$ has a matrix representation in the same basis given by $A^2 - 2A + I$, where $I$ is the identity matrix of the appropriate size.\n\nshare|cite|improve this answer\nFair enough! Thank you very much! \u2013\u00a0 user44069 Feb 13 '13 at 1:12\n\nIf I have understood your problem, yes, it makes sense. Consider that linear transformations over a vector field form an algebra over a field. You can see easily changing point of view and considering the matrix representation of your transformation. If $A$ is the matrix that represents $\\phi$ in the canonical basis of $\\mathbb{R}^{2}$ then $p(\\phi)$ is represented by $AA+ 2A+ \\mathbb{1}$\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://pari.math.u-bordeaux.fr/archives/pari-users-0903/msg00004.html\nText:\nKurt Foster on Sat, 14 Mar 2009 17:10:41 +0100\n\n\nAvoiding a znlog() computation\n\nSuppose that a and b are given, and for some prime p you know that\n\nn1 = znorder(Mod(a,p),p-1)\n\n\nMod(b,p)^n1 == Mod(1,p).\n\nThen the multiplicative order n2 of b (mod p) is automatically a divisor of n1, so we can compute it using n2 = znorder(Mod(b.p),n1).\n\nThen alpha = Mod(a,p)^(n1/n2) has multiplicative order n2, so\n\nMod(b,p) = alpha^k\n\nfor a unique k in (0, n2) with gcd(k, n2) ==1.\n\nThe problem is, how to determine k.  One way is to let\n\ng = znprimroot(p); l1 = znlog(alpha,g);l2 =znlog(b,p);k=lift(Mod(l2/ l1,n2))\n\nbut this entails finding a primitive root and TWO znlog()s. Given that Mod(k,n2) is already known to be well defined, is there a more direct/faster way to compute it?"}
{"text": "Retrieved from http://mathoverflow.net/questions/24609/are-there-primes-p-q-such-that-p41-2q2?answertab=active\nText:\nSign up \u00d7\n\n$\\exists p, q \\in \\mathbb{P}: p^4+1 = 2q^2$? I suspect there is some simple proof that no such p, q can exist, but I haven't been able to find one.\n\nSolving the Pell equation gives candidates for p^2=x and q=y, with x=y=1 as the first candidate solution and subsequent ones given by x'=3x+4y, y'=2x+3y; chances of a prime square seem vanishingly unlikely as x increases, but I don't have a proof.\n\nMeta: how do you search for a question like this? I looked for a searching HOWTO here and on meta, and couldn't find one. That the search appears to strip '^' and '=' makes it all the harder.\n\nshare|cite|improve this question\nIf you're looking for a simple proof, you probably have to a) factor the left hand side over Z[i]; b) subtract 1 and factor the right hand side over Z[sqrt{2}], or c) multiply by 2 and use the classification of Pythagorean triples (or subtract a square and factor the right hand side, which is a difference of squares). \u2013\u00a0 Franz Lemmermeyer May 14 '10 at 12:31\nYes, $\\mathbb{P}$ is the primes. That is standard isn't it? \u2013\u00a0 Hugo van der Sanden May 14 '10 at 12:32\n@Franz: This is a variation of Pell's equation, so $p^2+q\\sqrt2=(1+\\sqrt2)^{2k+1}$ (it can be shown by modular argument that $k$ is multiple of 4). Thus (a) can't work, (b) is used in derivation of the above formula (there are useless recursions mentioned by the author), and for (c) I have no idea of what do you mean (how to relate the equation with Pythagorean triples?) \u2013\u00a0 Wadim Zudilin May 14 '10 at 13:45\nInterestingly enough, the similar equation p^2 + 1 = 2q^4 DOES have an interesting solution, namely (p,q) = (239,13). This is related to Machin's identity pi/4 = 4 arctan(1/5) - arctan(1/239). (See Ribenboim's book on Catalan Conjecture for this.) See p.7-8 of for an \"explanation\" of this solution via a congruence mod 5 between a weight-2 cuspform in conductor 1024 and an Eisenstein series. \u2013\u00a0 JSE May 14 '10 at 20:45\n@Wadim: I can't see why a) cannot work. As for c), 2p^4 + 2 = (p^2+1)^2 + (p^2-1)^2 = (2q)^2. \u2013\u00a0 Franz Lemmermeyer May 16 '10 at 16:10\n\n3 Answers 3\n\nup vote 20 down vote accepted\n\nThis is not my solution, but I don't remember where I learned it.\n\nSquare both sides, subtract $4p^4$, and divide by 4 to obtain $({p^4-1\\over 2})^2=q^4-p^4$.\n\nHowever, $z^2=x^4-y^4$ has no solutions in non-zero integers. This is Exercise 1.6 in Edwards's book on Fermat's Last Theorem. The proof uses the representation of Pythagorean triples and infinite descent.\n\nSo you must have $p=\\pm 1$.\n\nshare|cite|improve this answer\nThanks, this does solve it. I also found the infinite descent proof of the lemma at\u2026 \u2013\u00a0 Hugo van der Sanden May 14 '10 at 15:42\n\nI think -- correct me if I am wrong -- that it is known that the equation $x^4+1=Dy^2$ with given squarefree $D$ has at most one solution in integers, primes or no primes. See for example J. H. E. Cohn., Math. Comp. 66 (1997), 1347-1351. ( The article cites an original proof by Ljunggren in 1942, which I can't find online.\n\nshare|cite|improve this answer\nAh, excellent. That suggests x=y=1 is the only solution; I'll take a look at the paper to see if it constitues a proof. \u2013\u00a0 Hugo van der Sanden May 14 '10 at 14:07\nOh, it is the Ljunggren paper I'd need. \u2013\u00a0 Hugo van der Sanden May 14 '10 at 15:40\n\nI don't know if there is a simple proof, but I know one which is easy to do because it lets a computer do all the work (but the work is perhaps complicated): you simply ask a computer to solve Y^2=2X^4+2 in integers for you, like this (in MAGMA, but other packages will do it too):\n\n> IntegralQuarticPoints([2,0,0,0,2]);\n    [ 1, 2 ],\n    [ -1, 2 ]\n\nso the only solution with p,q integers is p,q=+-1 and that's it.\n\nshare|cite|improve this answer\nHow can Magma be used with confidence, their code is not open. \u2013\u00a0 teil May 14 '10 at 13:39\nNegative's point is a valid one, but I think Kevin's answer points to the fact that there is a standard algorithm to solve these kinds of problems. Maybe it is also implemented in other packages. \u2013\u00a0 Felipe Voloch May 14 '10 at 14:59\nThis is only semi-true. The outer code of SIntegralPoints in Magma can be viewed easily. As Felipe Voloch says in part, this lists the algorithm. Low-level functions (eg. Height) cannot be seen, though \"open\" is technically true as you can decompile. From the philosophy of science, no system is used with confidence, and only independent verification can be partially satisfactory. We still have at least two chip manufacturers, so hardware independence is possible. For using software, too many packages throw eggs into a large basket (like GMP), and so I see a scarcity of true independence often. \u2013\u00a0 Junkie May 15 '10 at 6:19\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/46590/whats-the-minimum-of-int-01-fx2-dx-subject-to-int-01-fx-dx/46603\nText:\nSign up \u00d7\n\nThe question is as in the title: what's the minimum of $\\int_0^1 f(x)^2 \\: dx$, subject to $\\int_0^1 f(x) \\: dx = 0, \\int_0^1 x f(x) \\: dx = 1$? (Assume suitable smoothness conditions.)\n\nA problem in the textbook for the course I am TEACHING (not taking) reduces to minimizing $w_1^2 + w_2^2 + w_3^2$ subject to $w_1 + w_2 + w_3 = 0, w_1 + 2w_2 + 3w_3 = 1$. Of course there's nothing special about the number $3$ here, and so one can ask for the minimum of $\\sum_{i=1}^n w_i^2$ subject to $\\sum_{i=1}^n w_i = 0, \\sum_{i=1}^n iw_i = 1$. At least when $n = 3, 4, 5$, we get $w_i = c_n(i-(n+1)/2)$, for some constant $c_n$ which depends on $n$. So for fixed $n$, $w_i$ is a linear function of $i$. (This is a bit of an annoying computation, so I won't reproduce it here.)\n\nSo it seems like there should be a continuous analogue of this. If we have $$ \\int_0^1 f(x) \\: dx = 0, \\int_0^1 x f(x) \\: dx = 1 $$ and $f(x)$ is linear, then we get $f(x) = 12(x-1/2)$, and $\\int_0^1 f(x)^2 \\: dx = 12$. Is this the function satisfying these integral conditions with smallest $\\int_0^1 f(x)^2 \\: dx$? That is, is it the case that $$ \\int_0^1 f(x)^2 \\: dx \\ge 12 $$ for every $f(x)$ satisfying the two conditions above and whatever smoothness conditions are necessary?\n\nI've tagged this calculus-of-variations because that's what it looks like to me. But I don't know the calculus of variations, which is why I can't just solve the problem myself.\n\nshare|cite|improve this question\nIn my answer here I proved that if $f \\in C^1$, $\\int_{0}^{1} f = 0$ and $m \\leq f' \\leq M$ then $$\\frac{m}{12} \\leq \\int_{0}^{1} x f(x) \\leq \\frac{M}{12}.$$ I'm not sure if that helps immediately but it seems related and I'd try a few integrations by parts. It's getting late here, so I'm not sure that I could succeed now. \u2013\u00a0 t.b. Jun 20 '11 at 23:33\nWell, there is the same mysterious constant of 12. I may give it a shot. \u2013\u00a0 Michael Lugo Jun 20 '11 at 23:36\n\n3 Answers 3\n\nup vote 24 down vote accepted\n\nThe integrals above can be interpreted using the $L^2$ inner product $$ \\langle f,g\\rangle \\;=\\; \\int_0^1 f(x)\\,g(x)\\,dx. $$ Specifically, we are given that $\\langle 1,f\\rangle = 0$ and $\\langle x,f\\rangle =1 $, and we are asked to find the minimum possible value of $\\langle f,f\\rangle$.\n\nSince components of $f$ orthogonal to both $1$ and $x$ will only increase the norm of $f$, the minimizing function must lie in the subspace spanned by $1$ and $x$. A simple calculation shows that the minimum is obtained when $f(x) = 12x - 6$, in which case $\\langle f,f\\rangle = 12$.\n\nshare|cite|improve this answer\nIndeed, there are nice exercises at the end of chapter 4 of Walter Rudin's Real and Complex Analysis that provide practice with this technique. \u2013\u00a0 Amitesh Datta Jun 21 '11 at 0:24\n\nYes, it is true.\n\nConsider the Hilbert space $L^2([0,1])$ of square integrable functions $f\\colon[0,1]\\to\\mathbb{R}$ with inner product $\\langle f,g\\rangle = \\int_0^1 f(x)g(x)\\,dx$. Letting $V$ be two dimensional subspace generated by $u(x)=1$ and $v(x)=x$, then the function $g(x)=12(x-1/2)$ is in $V$ and satisfies $\\langle g,u\\rangle=0$ and $\\langle g,v\\rangle=1$. So, your question is equivalent to choosing $f$ to minimize $\\langle f,f\\rangle$ subject to $\\langle f,h\\rangle=\\langle g,h\\rangle$ for all $h\\in V$. This condition is just saying that $g$ is the orthogonal projection of $f$ onto $V$.\n\nSo, any $f\\in L^2$ satisfying the condition can be written as $$ f = g + h $$ where $h$ is in the orthogonal complement of $V$ and, therefore, $$ \\langle f,f\\rangle = \\langle g,g\\rangle+\\langle h,h\\rangle\\ge \\langle g,g\\rangle=12 $$ with equality if and only if $f=g$ almost everywhere.\n\nshare|cite|improve this answer\nThis solution is so beautiful and simple that it's almost disappointing. \u2013\u00a0 t.b. Jun 21 '11 at 0:23\nNote that you could alternatively try varying $f$ by an (infinitesimal) amount $\\delta f$, giving $0=\\delta\\int_0^1f^2\\,dx=\\int_0^1f\\delta f\\,dx$ for the optimal $f$. In order that the conditions remain satisfied, you must choose $\\int u\\delta f\\,dx=0$ for $u=1$ and $u=x$. This means that $f$ is orthogonal to any $\\delta f$ orthogonal to both $1$ and $x$. As the orthogonal complement of the orthogonal complement of a closed subspace gets you back to the original space, this means that $f$ is in the linear span of $1,x$. Making this a bit cleaner and more rigorous gives the argument above. \u2013\u00a0 George Lowther Jun 21 '11 at 0:28\n\nSeeing the very nice solutions using linear algebra that have been posted, I am again reminded that the calculus of variations is a bigger and less elegant hammer than is necessary for most nails. For what it's worth, here is how you could solve this problem with the calculus of variations. Jos\u00e9 Figueroa-O'Farrill has some nice notes which cover this:\n\nAs we have two constraints, we introduce two Lagrange multipliers $\\lambda$ and $\\mu$, and attempt to extremize the functional $$S[f] = \\int_0^1 \\big( f(x)^2 + \\lambda f(x) + \\mu x f(x) \\big) dx.$$ Let us denote the integrand by $$L\\big(x,f(x),f'(x)\\big) = f(x)^2 + \\lambda f(x) + \\mu x f(x).$$\n\nThe function $f$ which is a stationary point of the functional $S[f]$ satisfies the corresponding Euler-Lagrange equation, $$\\frac{\\partial L}{\\partial f} = \\frac{d}{dx} \\frac{\\partial L}{\\partial f'}$$ which in this case reduces to $$2f(x) + \\lambda + \\mu x = 0.$$ So we see that the extremal $f(x)$ is indeed linear, and the values of $\\lambda$ and $\\mu$ can be obtained from the constraints $\\int_0^1 f(x) dx = 0$ and $\\int_0^1 xf(x) dx = 1$.\n\nshare|cite|improve this answer\nOut of curiosity what was your air in jee? i might be your junior... \u2013\u00a0 kuch nahi Jun 21 '11 at 5:05\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/157866/derivative-for-matrix-function?answertab=active\nText:\nSign up \u00d7\n\nI have a matrix kernel function which I am trying to find the derivative to. Function is K = c * exp[-1/2 * (P(X1 - X2))' * P(X1 -X2)] where uppercase are matrices and lower case are scalars (and ' denotes transpose). I'm trying to find dK/dP. I'm pretty rusty on matrix calculus, can anyone give me a hand here?\n\n\nshare|cite|improve this question\nYour notation is not very clear. Is $P$ a matrix? then did you mean something like $K(P) = c \\exp[-\\frac12 \\| P(X_1 - X_2) \\|^2]$? In that case you should probably write (P(X1-X2))', the transpose should be around everything and maybe a trace before it? Is P symmetric or not? \u2013\u00a0 passerby51 Jun 13 '12 at 17:43\nI was assuming this is a matrix valued function. If that's true I'd undelete my (by now corrected) answer. If @passerby51 assumption is correct, the derivative is just $$ D_V K = -1/2K \\langle V(X_1-X_2), P(X_1-X_2)\\rangle$$ with $\\langle.,.\\rangle$ the scalar product on the vector space of matrices. \u2013\u00a0 user20266 Jun 13 '12 at 17:50\nSorry yeah the transpose is around the whole thing. P is not symmetric. \u2013\u00a0 tomas Jun 13 '12 at 17:50\nYeah it is a matrix valued function. I didn't quite get a chance to see your deleted answer Thomas. What was it? Thanks for the response guys. \u2013\u00a0 tomas Jun 13 '12 at 17:53\nundeleted my reply. \u2013\u00a0 user20266 Jun 13 '12 at 17:53\n\n1 Answer 1\n\nLet $$Z(P)=(P(X_1-X_2))^TP(X_1-X_2)$$ If $K$ is viewed as depending only on $P$ and if you differentiate in direction $V$ you get $$ D_V K = K*\\frac{-1}{2} \\left\\{\\frac{I-e^{-ad_{Z(P)}}}{ad_{Z(p)}} \\left[ (V(X_1-X_2))^TP(X_1-X_2) + P(X_1-X_2)^TV(X_1-X_2) \\right] \\right\\}$$\n\nThe term on the right hand side in curly parenthesis needs explanation. It is the matrix valued function $\\frac{I-e^{-ad_{Z(P)}}}{ad_{Z(P))}}$ applied to the term in square brackets. This in turn means\n\n$$\\frac{I-e^{-ad_{Z}}}{ad_{Z}}[Y] = Y-\\frac{[Z,Y]}{2!} + \\frac{[Z,[Z,Y]]}{3!} - \\ldots$$\n\nSee, e.g., Chapter 3.3 in Brian C. Halls Book 'Lie Groups, Lie Algebras and Representations for a derivation of the derivative of the exponential.\n\n(Sorry for posting a too simple and wrong answer first, which is true only if $Z$ and $D_VZ $ commute). (I don't like the $\\frac{d}{dP}$ notation).\n\nshare|cite|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/45061/linear-ordering-of-color-balls\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $n+m$ balls of which $n$ are red and $m$ are blue, are arranged in a linear order, we know there are $(n+m)!$ possible orderings. If all red balls are alike and all blue ball are alike, we know there are $\\frac{(n+m)!}{n!m!}$ possible orderings.\n\nFor example, 2 red and 3 blue balls:\n\nR1 R2 B1 B2 B3\n\nR2 R1 B2 B3 B1\n\nThe above two orderings are equivalent and can be denoted as:\n\n\nNow here is the problem: what if we further concentrate on the color, and record consecutive balls of the same color with the just ONE color code?\n\nFor example the color code for the afore-mentioned example would be:\n\n\nHow many possible color code orderings are there?\n\nshare|improve this question\nShould be tagged co.combinatorics instead of pr.probability? \u2013\u00a0 Emil Nov 6 '10 at 12:27\nadd comment\n\n2 Answers\n\nup vote 2 down vote accepted\n\nSuch a color-code ordering starts with either R or B and continues with strictly alternating R and B. The string can be of any length up to the smaller of $n$ or $m$, meaning it can be twice that smaller value, but that can be followed by one more character if there are enough of the other color. Moreover, every such string is a color-code ordering for some linear ordering of balls. There are a couple of special cases, namely that if either $n$ or $m$ is zero then there is exactly one color-code ordering and there aren't any if both are zero. Also, if neither is zero, we must have at least one instance of each letter.\n\n\nIf $n = m = 0$, the answer is 0.\n\nIf exactly one of $n$ and $m$ is zero, the answer is 1.\n\nIf $n = m > 0$, the answer is $4n - 2$.\n\nOtherwise, let $p$ be the minimum of $n$ and $m$. The answer is $4p-1$.\n\nshare|improve this answer\nadd comment\n\nWithout loss of generality, assume $n \\leq m$. Such a colour code ordering is just a sequence of alternating $R$ and $B$ letters. There are four types of such sequences, depending which letter they start and end with. Say a sequence is of type $(X,Y)$ if it begins with $X$ and ends with $Y$.\n\nSo, there are\n\n  1. $n$ sequences of type $(R,B)$\n  2. $n$ sequences of type $(B,R)$\n  3. $n-1$ sequences of type $(R,R)$\n  4. $n$ sequences of type $(B,B)$ (and only $n-1$ of them if $n=m$).\n\nThus, the answer is $4n-1$ if $n < m$, and $4n-2$ if $n=m$.\n\nEdit. As Larry Denenberg mentions, in the degenerate case of $n=0$, the answer is always 1 (I count the empty string if $n=m=0$).\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/106008/how-does-expxy-expx-expy-imply-expx-exp1x/106038\nText:\nTake the 2-minute tour \u00d7\n\nIn Calculus by Spivak (1994), the author states in Chapter 18 p. 341 that $$\\exp(x+y) = \\exp(x)\\exp(y)$$ implies $$\\exp(x) = [\\exp(1)]^x$$ He refers to the discussion in the beginning of the chapter where we define a function $f(x + y) = f(x)f(y)$; with $f(1) = 10$, it follows that $f(x) = [f(1)]^x$. But I don't get this either. Can anyone please explain this? Many thanks!\n\nshare|improve this question\nAs a first step: try writing out the argument Spivak gave in your question, and try writing it in your own words. \u2013\u00a0 \uff2a. \uff2d. Feb 5 '12 at 16:08\nEither $f(x+y)=f(x)+f(y)$ or $f(x)=[f(1)]^x$ is incorrect. One of the two should be changed to $f(x+y)=f(x)f(y)$ or $f(x)=[f(1)]x$ respectively. \u2013\u00a0 Adam Feb 5 '12 at 16:40\nadd comment\n\n4 Answers\n\nup vote 7 down vote accepted\n\nI think you should assume $x$ is an integer (since $a^x$ is defined using $\\exp$ if $x$ is a positive real). You can write $\\exp(x) = \\exp(1+1+1+1+\\cdots+1)$ (there is $x$ times \u00ab 1 \u00bb\u00a0in the last term).\n\nUsing the property of $\\exp$, you find now $\\exp(x) = \\exp(1)\\exp(1)\\cdots\\exp(1) = (\\exp(1))^n$\n\nshare|improve this answer\nNote that $a^x = \\exp( x \\log(a))$ and is defined for all complex $x$ and $a$, s.t. $a \\not= 0$, where the principal branch of $\\log$ is taken. \u2013\u00a0 Sasha Feb 5 '12 at 16:50\nadd comment\n\nAs Paul Pichaureau has mentioned, it is easy to see that the formula holds for $n$\u00a0natural. You can also easily go further: what should $\\exp(-n)$\u00a0be? Well, $\\exp(0) = 1 = \\exp(-n+n) = \\exp(-n) \\exp(n)$, so $\\exp(-n) = 1/\\exp(n)$. Furthermore, it is easily seen that $\\exp(nx) = \\exp(x)^{n}$, so that $$\\exp(1) = \\exp(n\\cdot 1/n) = \\exp(1/n)^n,$$ and hence $$\\exp(1/n) = \\exp(1)^{1/n}$$ by the usual rules for powers. Combining these, we see that $$\\exp(p/q) = \\exp(1)^{p/q},$$ so the formula holds for any rational number $x$. I think this is about as far as you can get using only that formula (in addition to the requirement that $\\exp(0) = 1$). If we, in addition, assume that $\\exp$ is continuous on $\\mathbb{R}$, then we can choose a sequence $(r_{i})_{i =1}^{\\infty}$\u00a0of rational numbers such that $\\lim_{n \\to \\infty} r_{i} = x$, and compute $$\u00a0\\lim_{n\\to \\infty} \\exp(1)^{r_n} = \\lim_{n \\to \\infty} \\exp(r_{n}) = \\exp(\\lim_{n \\to \\infty} r_{n}) = \\exp(x).$$ The problem now is what $\\exp(1)^x$\u00a0is supposed to be. If we already know that the power function $x \\mapsto \\exp(1)^x$\u00a0is continuous, then certainly the right hand side is equal to $\\exp(1)^x$, but as Paul mentions, the power functions are often defined in terms of the exponential function. However, I don't think you have to do it that way (you could define rational powers as usual, and prove that a continuous extension to the reals exists), so it all depends on what Spivak has done prior to that chapter (you also didn't specify what $x$\u00a0is, so it conceivable that he assumes it is rational, in which case it doesn't matter much).\n\nshare|improve this answer\nInstead of continuity, you could get by with monotonicity. \u2013\u00a0 Michael Hardy Feb 6 '12 at 2:41\n@michaelhardy: interesting! \u2013\u00a0 Martin Wanvik Feb 6 '12 at 2:54\nexcellent answer Martin, thorough and comprehensive without abstruosity \u2013\u00a0 David Holden Dec 23 '13 at 16:22\nadd comment\n\nThe $n$-th $\\ (n\\in{\\mathbb N}_{\\geq1}$) power of a real number $a>0$ is defined in elementary terms as product of $n$ factors equal to $a$. It is only reasonable to define $a^0:=1$ and $a^n:=1/a^{-n}$ when $n<0$. One then has $$a^{m+n}=a^m\\cdot a^n\\ ,\\qquad a^{m\\ n}=\\bigl(a^m\\bigr)^n \\qquad(*)$$ for all $m$, $n\\in{\\mathbb Z}$. The aim now is to extend the definition of an $x$-th power of $a$ from $x\\in{\\mathbb Z}$ to $x\\in{\\mathbb Q}$ and $x\\in{\\mathbb R}$ such that the law $(*)$ is preserved.\n\nThe first step is easy: For $p\\in{\\mathbb Z}$ and $q\\in{\\mathbb N}_{\\geq1}$ put $$a^{p/q}\\ :=\\ \\root q \\of {a^p}\\ .$$ Using the \"rules of algebra\" one then can verify that $(*)$ is true for arbitrary $x$, $y\\in{\\mathbb Q}$ instead of $m$, $n\\in{\\mathbb Z}$. That is as far as one can get using the algebraic notions of $n$-th power and $q$-th root.\n\nNow analysis provides a wonderful (in particular, continuous) function $x\\mapsto\\exp (x)$ with the property that $\\exp(x+y)=\\exp(x)\\cdot\\exp(y)$ for all $x$, $y\\in{\\mathbb C}$. Put $\\exp(1)=:e\\doteq 2.718$. Then it follows by an easy induction that in fact $$\\exp\\Bigl({p\\over q}\\Bigr)\\ =\\ e^{p/q}$$ for all ${p\\over q} \\in{\\mathbb Q}$. As $\\exp$ is continuous it is only natural to define arbitrary real powers of the number $e$ by $$e^x\\ :=\\ \\exp(x)\\qquad(x\\in{\\mathbb R})\\ .$$ Via the logarithm function (which I won't explain here) we can define arbitrary real powers not only of $e$, but of an arbitrary number $a>0$: $$a^x\\ :=\\ \\exp\\bigl(x\\log(a)\\bigr)\\qquad (x\\in{\\mathbb R})\\ .$$ Using the functional equations of $\\exp$ and $\\log$ one then easily proves that the rule $(*)$ remains true for arbitrary $x$, $y\\in{\\mathbb R}$ instead of $m$, $n\\in{\\mathbb Z}$.\n\nshare|improve this answer\nadd comment\n\nI like (as I have done here before) to start with a functional equation and derive properties of the function.\n\nIf $f(x+y) = f(x) f(y)$ and $f$ is differentiable (and non-zero somewhere), $f(0) = 1$ and $f(x+h)-f(x) = f(x)f(h)-f(x) =f(x)(f(h)-1) =f(x)(f(h)-f(0)) $ so $$(f(x+h)-f(x))/h = f(x)(f(h)-f(0))/h.$$ Letting $h \\to 0$, $f'(x) = f'(0) f(x)$. From this, $f(x) = \\exp(f'(0)x)$.\n\nThis also works for $\\ln$, $\\arctan$, and $\\sin$ and $\\cos$.\n\nFunctional equations are fun!\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/225602/for-nu-a-probability-measure-on-mathbbr-mathcalb-mathbbr-the-s\nText:\nTake the 2-minute tour \u00d7\n\nGiven a probability measure $\\nu$ on $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$, how do I show that the set (call it $S$) of all $x\\in \\mathbb{R}$ where $\\nu(x)>0$ holds is at most countable?\n\nI thought about utilizing countable additivity of measures and the fact that we have $\\nu(A) < 1$ for all countable subsets $A\\subset S$. How do I conclude rigorously?\n\nshare|improve this question\nadd comment\n\n2 Answers\n\nup vote 1 down vote accepted\n\nGiven $n\\in\\mathbb N$, consider the set $$A_n=\\{x\\in\\mathbb R:\\nu(\\{x\\})\\geq\\tfrac{1}{n}\\}$$ It must be finite; otherwise, the probability of $A_n$ would be infinite since $\\nu$ is additive. Thus, $A=\\cup_{n\\in\\mathbb N}A_n$ is countable as a countable union of finite sets, but it is clear that $$A=\\{x\\in\\mathbb R:\\nu(\\{x\\})>0\\}$$ so you are done.\n\nshare|improve this answer\nadd comment\n\nLet $S_n:=\\{x,\\nu(\\{x\\})\\geq n^{-1}\\}$. Using $\\sigma$-additivity, we have that $S_n$ is finite (it contains actually at most $n$ elements, as $\\nu$ is a probability measure). Then $S=\\bigcup_{n\\geq 1}S_n$ is countable as an union of such sets.\n\nshare|improve this answer\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://mathforum.org/kb/thread.jspa?threadID=2616226\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nSearch All of the Math Forum:\n\n\nMath Forum \u00bb Discussions \u00bb sci.math.* \u00bb sci.math.independent\n\nTopic: Final Detailed Constructive proof of No Odd Perfect Number beyond 1\n#1449 Correcting Math\n\nReplies: 4 \u00a0 Last Post: Jan 21, 2014 8:59 PM\n\nAdvanced Search\n\n\nPosts: 8,731\nRegistered: 3/31/08\nFinal Detailed Constructive proof of No Odd Perfect Number beyond 1\n#1449 Correcting Math\n\nPosted: Jan 20, 2014 1:36 AM\n\nFinal Detailed Constructive proof of No Odd Perfect Number beyond 1 #1449 Correcting Math\n\nAlright, I am sorry for the hundreds or more posts of \"proof of No Odd Perfect Number\" that I posted on the sci.math newsgroup. Sorry because all of them were tentative and not actually a proof. Because I now have the proof, as the below shows. So that all those hundreds of tentative proofs finally lead to the true one. So I guess, then, No Odd Perfect was the hardest of these 6 proofs: Goldbach, Bertrand's postulate, AP-postulate, Fermat's Last Theorem FLT, Beal's conjecture, No Odd Perfect, for it took the longest to resolve. Maybe there is a lesson in it, which I am not going to try to seek. Maybe it is the oldest unsolved math problem for a good reason, in that it hides in the shadows and you need to solve it with a minimum facts such as k-1. No Odd Perfect turns out to be more difficult of finding that unwanted \"2\", whereas square root of 2 the unwanted \"2\" pops up soon. But one of the reasons No Odd Perfect took so long is the contorted and arbitrary definition of what is a factor and what is not. There are still some illogical folk who think the factors of 9 are just 1,3, or think that 1,3,9, when in truth, with a proper logic the factors of 9 are cofactors of 1x9 and then 3x3 for four numbers in full. So that No Odd Perfect could ever be proven if one batch of mathematicians counts 9 as only 2 factors, another batch counts 3 factors and then I count 4 factors.\n\nDetailed Constructive proof No Odd Perfect Number\n\n\nExample is 6 and 15:\n\nThe number 6 has cofactors of 1 with 6, and 2 with 3 and represented as this:\n\n\n\n\nNow we omit or delete the number itself and 1 factor and for 6 we omit the 1 and 6 and have remaining the 2,3 cofactors so we have k-1 when k is the number. For 6, k-1 is 5 where 2+3 = 5. For 15, k-1 is 14 and where we have 3+5 = 8.\n\nFor 18 we have\n\nand for k-1 we have 17, but we have 2+9+3+6 = 20\n\nFor 20 we have\n\n(1 + 20) + (2 + 10) + (4 + 5) = 42 and for k-1 we have 19, but we have\n2+10+4+5 = 21\n\nFor 9 we have\n\n(1 + 9) + (3 + 3) = 16 and for k-1 we have 8, but we have 3+3=6\n\nFor 28 we have\n(1 + 28) + (2 + 14) + (4 + 7) = 56, and for k-1 we have 27, and we have\n2 + 14 + 4 + 7 = 27\n\nConstructive Definition of a Perfect Number\nNow let me define the Perfect Number in general with a formula. Summation of cofactors with the 1 and k omitted must equal k-1.\n\nConstruction proof\n\n\nMeans that the cofactor summation is k-1 once the 1 and k cofactors are omitted.\n\nSince k is Odd Perfect, all its cofactors below k-1 are odd numbers. That means their sum is an even number.\n\nHere we have two possibilities: either the smallest divisor of k is 2 or is 3.\n\nCan 3 be the smallest cofactor divisor of this arbitrary odd perfect number k, would mean that we can separate the divisors into two groups, one of which is 1/3(k-1) and the the remaining terms are 2/3(k-1).\n\nOr, is 2 the smallest cofactor divisor, would mean that the two groups are both 1/2(k-1).\n\n\n(1 + 945) omitted\n\nFor 945 the k-1 is 944, but in actuality, once we omit the 1 and 945. We have remaining the sum\n\nI displayed the abundant odd number to compare with the deficient odd number of 15. Few people know that some odd numbers can be abundant.\n\nNow for the impossibilty of the construction of the Odd Perfect.\nThe Odd Perfect has a k-1 that is even, for odd +odd is even. The smallest cofactor divisor of the Odd Perfect number must be either 3 or 2, or if you want the smallest to be say 5, the argument works the same. If 3 is the smallest divisor of k, then 1/3(k-1) is the sum of factors and 2/3(k-1) the remaining sum of factors for k-1. That makes for an impossible construction situation, since the sum of k-1 is even, and a portion of the factors is to add together to be 1/3* even number k-1 and the other portion to be 2/3*even number k-1. You cannot divide an even number k-1 into two portions of 1/3 and 2/3.\n\nSo here we grasp the impossible construction of a even number k-1 with 1/3 portion and 2/3 portion of an even number. Now if 5 were the smallest divisor we run into the problem of 1/5 and 4/5 and the same goes for larger odd numbers as the smallest divisor.\n\nThe only other alternative is that 2 is the smallest divisor of k-1 and that implies that 2 is a divisor of k. But that is impossible for then an odd number k has 2 as a divisor.\n\nSo basically, the proof hinges on the fact that we take the arbitrary odd perfect number and force it to have a sum that is even. That means we separate k into k-1 where we are guaranteed of a even number sum since pairs of odd numbers is always even. Now, the final operation of construction is ask what the lowest or smallest divisor could possibly be for the k-1. Is it 3 or 2 or some larger odd number? We then show it cannot be 3, nor 2 nor any larger odd number.\n\n\n\n\nArchimedes Plutonium\n\n\n[Privacy Policy] [Terms of Use]\n\n\u00a9 Drexel University 1994-2014. All Rights Reserved."}
{"text": "Retrieved from http://zbmath.org/?q=an:0689.28003&format=complete\nText:\nzbMATH \u2014 the first resource for mathematics\n\n\na & b logic and\na | b logic or\n!ab logic not\nabc* right wildcard\n\"ab c\" phrase\n(ab c) parentheses\nany anywhere an internal document identifier\nau author, editor ai internal author identifier\nti title la language\nso source ab review, abstract\npy publication year rv reviewer\ncc MSC code ut uncontrolled term\nFractal geometry: mathematical foundations and applications. (English) Zbl\u00a00689.28003\nChichester etc.: John Wiley &| Sons (ISBN 0-471-92287-0). xxii, 288 p. \u00a319.95; $ 36.75 (1990).\n\nFirst some quotes from preface: \u201dThe main aim of the book is to provide a treatment of the mathematics associated with fractals and dimensions at a level which is reasonably accessible to those whoe encounter fractals in mathematics or science. Although basically a mathematics book, it attempts to provide an intuitive as well as mathematical insight into the subject. The book falls naturally into two parts. Part I is concerned with the general theory of fractals and their geometry.\u201d \u201dPart II of the book contains examples of fractals, to which the theory of the first part may be applied, drawn from a wide variety of areas of mathematics and physics.\u201d\n\nThe first part, called \u201dFoundations\u201d, deals with that area of geometric measure theory where measures, in particular Hausdorff measures, are used to find and describe geometric properties of very general subsets of Euclidean spaces. It is closely connected with the earlier book of the author, \u201dThe geometry of fractal sets\u201d (1985; Zbl 0587.28004). But while that book developed the theories of Besicovitch, Marstrand and others in detail, the present book avoids most complicated proofs trying, and in my opinion also succeeding, to reveal the basic ideas. This part consists of 8 chapters. It presents Hausdorff measures and dimension, and also other dimensions, like box-counting and packing dimensions. It shows methods for calculating these dimensions in terms of general measures, their potentials and Fourier transforms. Then local tangential and density properties are discussed. The last three chapters of Part I present the basic equalities and inequalities for the dimensions of orthogonal, Cartesian products, and intersections.\n\nPart II, \u201dApplications and examples\u201d, consists of 10 chapters each treating a rather different topic. They include self-similar and self- affine fractal constructions, number-theoretic fractals, graphs of nowhere differentiable functions, real and complex dynamical systems and their attractors, various random fractals, multifractal measures and a glance at physical applications.\n\nI think Falconer has gained his aims very well. The book is delightful, accessible to a wide audience, and pleasant to read. It gives good introduction to many branches of mathematics connected with fractals.\n\nReviewer:\u00a0P.Mattila\n\n28A75Length, area, volume, other geometric measure theory\n28-02Research monographs (measure and integration)\n37C70Attractors and repellers, topological structure\n54H20Topological dynamics"}
{"text": "Retrieved from http://math.stackexchange.com/questions/432652/confusion-regarding-change-of-variables-in-odes\nText:\nTake the 2-minute tour \u00d7\n\nConsider the following exercise:\n\nUsing the Laplace transform, find a solution $y(x)$ of the following initial value problem:\n\n$$\\begin{cases} y'' +y = x + 1, \\quad x > \\pi \\\\ y(\\pi) = \\pi^2 \\\\ y'(\\pi) = 2\\pi \\end{cases}$$\n\nSuggestion: Make the change of variables $t = x - \\pi$.\n\nOf course, this equation is pretty easy to solve without the Laplace transform, but the whole point of the exercise is to use it. That's not the problem, though. I'm having some trouble with the change of variables.\n\nI know that for the derivatives you have to use the chain rule; in this case, since $dt = dx$ there's no difference. My main issue is with the initial conditions. I'm not very sure how to restate them in terms of $t$, and I think that's because I don't really know a precise definition of change of variables. How is it done? Do we define a new function, something like $g(t) = y(x-\\pi)$, if that even makes sense? What would be a general method to make sure one does things like this carefully?\n\nI apologize if the question is rather vague. Just to be clear, I'm not asking how to solve this particular differential equation; I've realized I get confused in general when using change of variables in an ODE.\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nTry to use Laplace transform to solve: $$\\begin{cases} g'' +g = t+ \\pi + 1, \\quad t > 0 ,\\\\ g(0) = \\pi^2, \\\\ g'(0) = 2\\pi. \\end{cases}$$\n\nLike you said, but it is not letting $g(t) = y(x-\\pi)$, rather it is letting $g(t) := y(t+\\pi) = y(x)$. Basically the equation is translated by $\\pi$ in the independent variable, so when originally the initial condition is at $x = \\pi$, now it is at $t = x-\\pi = 0$.\n\nshare|improve this answer\nThat works. But what's the point then ofusing two different \u2013\u00a0 Javier Badia Jun 30 '13 at 13:09\n@JavierBadia Because Laplace transform's formula for derivatives involve the initial value at 0: $\\mathcal{L}\\{f'\\} = s\\mathcal{L}\\{f \\}-f(0)$. You can use the initial value at $\\pi$ as well, but whenever you perform the integration by parts using the definition of Laplace transform, you will find it essentially you are translating the coordinates as well, so it is easier to do it before going into the Laplace transform stage. \u2013\u00a0 Shuhao Cao Jun 30 '13 at 16:03\n@Shuhaho: I'm sorry, I accidentally submitted that comment early and was going to fix it but I forgot. I understand that. What I was going to say is, what's the point of using a different variable name? Like you said; isn't it clearer to say \"use $g(x) = g(x+\\pi)$\" instead of \"use $t = x - \\pi$\"? \u2013\u00a0 Javier Badia Jun 30 '13 at 16:43\n@JavierBadia Using the same letter would cause confusion, for $g(x) = g(x+\\pi)$ means periodicity for the same function $g$, using a different letter just avoid this: say $y(x) = x^2$, then letting $g(t) := y(t+\\pi) = t^2 + 2\\pi t + \\pi^2$, this can be also written as $g(x) := y(x+\\pi) = x^2 + 2\\pi x + \\pi^2$, $g$ and $y$ are simply different functions, one of which is a translation in $x$ of the other. \u2013\u00a0 Shuhao Cao Jun 30 '13 at 16:58\nIt seems I just can't write comments today. I meant $g(x) = y(x+\\pi)$. \u2013\u00a0 Javier Badia Jun 30 '13 at 17:04\nadd comment\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/permutation-groups.52613/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nPermutation groups\n\n  1. Nov 14, 2004 #1\n    what is the number of elements of order 5 in the permutaion group S7??\n    so what we're concerned with here is, after decompositon into disjoint cycles the l.c.m of the lengths must be 5. since 5 is a prime, the only possible way we could get 5 as l.c.m would be to fix ANY 2 elements amongst the 7 to themselves....so we end up getting 2 cycles of length 1 each. the remaining five elements can be arranged in 4! ways...\n    so, the answer is 7C2 * 4! = 21*24 = 504.\n    :smile: but unfortunately, this answer is WRONG!!\n  2. jcsd\n  3. Nov 14, 2004 #2\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Since 5 is prime, you MUST have cycle of length 5.\n    Then there could be a 2-cycle in addition.\n  4. Nov 15, 2004 #3\n\n    well....yes, it's possible to have a cycle of length 2 in addition to the 5 cycle...but then the l.c.m becomes 10. so that rules out such a consideration!\n  5. Nov 15, 2004 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Yes, so the only permutations in S7 of order 5 are the 5-cycles.\n  6. Nov 15, 2004 #5\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    Your answer is wrong because you've counted, for example:\n\n    12345, 23451, 34512, 45123, and 51234 as different elements.\n  7. Nov 15, 2004 #6\n    ya....so what further? that's a valid point you've raised...\n    so do you divide by 4?\n  8. Nov 15, 2004 #7\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    You have [itex]{7 \\choose 5}[/itex] ways to pick 5 elements from a set of 7.\n    There are 5! ways you can order 5 elements in a cycle.\n    For a given cycle of length 5, 5 orderings are give the same permutation.\n  9. Nov 16, 2004 #8\n    hey galileo\n\n    please read stuff carefully...\n    we left this a long while ago, right astronut?! :smile:\n  10. Nov 21, 2004 #9\n    i think the solution 504 is correct....\n    i don't see any fallacy in it.\n  11. Nov 21, 2004 #10\n\n    matt grime\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n\n    The general solution is:\n\n    suppose t is a permutation of type\n\n\n    then the order of the centralizer is\n\n    [tex]\\prod_i i^{m_i}m_i![/tex]\n\n    in this case it is 1^2.5\n\n    so the centralizer's order is\n\n\n    hence the conjugacy class has order\n\n\n    which is indeed 504\n\nHave something to add?\n\nSimilar Discussions: Permutation groups\n  1. Permutation Group (Replies: 2)\n\n  2. Permutation Group (Replies: 29)"}
{"text": "Retrieved from http://mathforum.org/library/drmath/view/53536.html\nText:\nDrexel dragonThe Math ForumDonate to the Math Forum\n\nAsk Dr. Math - Questions and Answers from our Archives\n\nRate of Change of Angle\n\nDate: 8/12/96 at 0:31:2\nFrom: da bellm\nSubject: Rate of Change of Angle\n\nDear Dr. Math,\n\nI'm an engineering student at the University of Adelaide in South \nAustralia.  This is a problem that I was given about 4 years ago,  \nback in high school.  No one I've asked has been able to give me a \nsatisfactory answer to it.\n\nTwo roads, BA and CA, meet at an angle of 60 degrees. A landmark \nsituated at B, 500 metres from A, is visible to drivers approaching \nA along CA. A vehicle at X is moving along CA towards A at \n72 kilometres per hour.\n           /  o\n         /  60\n      A                   X           C\n\na)  Find the rate at which BX is changing when the vehicle is 500m \nfrom A. (This bit is easy,  but leads on to part b.)\n\nb)  Find the rate at which angle BXA is changing in radians per second \nwhen the distance BX is least,  and give a physical explanation of why \nit is whatever it is. (This is the hard bit!)\n\nHave a nice day, \n\nDate: 8/24/96 at 19:30:46\nFrom: Doctor Mike\nSubject: Re: Rate of Change of Angle\n\nHi  Dave, \nSince you already understand part (a) I'll skip that one. \nPart (b) is a fantastic calculus problem! The straightforward way\nis incredibly long and messy, but there's a quick way if you look\nat it right.  The key is the Chain Rule for derivatives.\nDrop a perpendicular from B to the road CA and let that be the\norigin of a coordinate system with +x toward C and +y toward B.\nThis origin is 250 metres from A and 250*sqrt(3) metres from B.\nThe only *physical explanation* I see is the observation that\nBX is least exactly when the vehicle location X is at the origin.\nTo keep consistent units, use 20 metres per second rather than \n72kph.  With respect to some arbitrary reference time t=0 let p(t)\nbe the x-coordinate of the vehicle location on road CA at time \nt seconds.  If the reference time is when the vehicle is M metres\nfrom the origin, then p(t) = M-20t and p'(t) = -20 is constant.\nLet d(t) be the distance BX at time t seconds, and a(t) be the\nangle BXA at time t seconds.  Then cos(a(t)) = p(t)/d(t).  \nTake derivatives of both sides to get : \n                             d(t)*p'(t) - p(t)*d'(t)  \n       -sin(a(t)) * a'(t) = ------------------------- \nYou want to solve for a'(t) when BX is least, which is when X is\nat the origin, a(t) = pi/2, and d'(t) = 0 for a d(t) minimum.\nAnswer: (2/75)*sqrt(3) or about 0.046188 radians per second.\nI hope this is what you were looking for. \n\n-Doctor Mike,  The Math Forum\nAssociated Topics:\nHigh School Calculus\n\nSearch the Dr. Math Library:\n\nFind items containing (put spaces between keywords):\nClick only once for faster results:\n\n\nparts of words whole words\n\nSubmit your own question to Dr. Math\n\n[Privacy Policy] [Terms of Use]\n\n\nAsk Dr. MathTM\n\u00a9 1994-2013 The Math Forum"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204036/simplify-sum-i-0n-1-2n-choosei-cdot-xi/204049\nText:\nTake the 2-minute tour \u00d7\n\nI am trying to simplify an expression involving summation as follows:\n\n$$\\sum_{i=0}^{n-1} { {2n}\\choose{i}}\\cdot x^i$$\n\nwhere $n$ is an integer, and $x$ is a positive real number.\n\nAt a first glance, I can see that\n\n$$\\sum_{i=0}^{2n} { {2n}\\choose{i}}\\cdot x^i = {(1+x)}^{2n}.$$\n\nBut what if in the case when $i$ goes from 0 to $n-1$?\n\nshare|improve this question\n\n2 Answers 2\n\nup vote 1 down vote accepted\n\nIf you sum from $0$ to $n-1$, then no longer you get an easy espression. Instead, you can get the sum in terms of the hypergeometric function\n\n$$ \\left( x+1 \\right) ^{2\\,n}-{2\\,n\\choose n}{x}^{n} {F (1,-n;\\,n+1;\\,-x)}\\,.$$\n\nshare|improve this answer\n\nIt's just a partial answer.\n\nLet $S_1(x):=\\sum_{i=0}^{n-1}\\binom{2n}ix^i$, and $S_2(x):=\\sum_{i=n+1}^{2n}\\binom{2n}ix^i$. Then writing $j=2n-i$, we get $$S_2(x)=\\sum_{j=0}^{n-1}\\binom{2n}jx^{2n-j}=S_1(x^{-1})x^{2n}.$$ So $$(1+x)^{2n}=S_1(x)+\\binom{2n}nx^n+S_2(x)=S_1(x)+\\binom{2n}nx^n+S_1(x^{-1})x^{2n}.$$ Writing $f(x):=\\frac{S_1(x)}{x^n}$, we get that $f$ satisfies the functional equation $$f(x)+f(x^{-1})=\\left(1+\\frac 1x\\right)^n(1+x)^n-\\binom{2n}n.$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/257875/a-difficult-symmetric-inequality\nText:\nTake the 2-minute tour \u00d7\n\nIn my studies of various geometric inequalities I reached an inequality which seems true (numerically) but I cannot prove it. Let $p$, $q$, and $r$ be real numbers from the interval $(0,1)$. Let's also define the following function $$f({p})=\\frac{\\sqrt{1-p}}{(2-p)^2}$$ Prove (or disprove) that: $$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq \\frac{f(p)}{p\\sqrt{p}}+\\frac{f(q)}{q\\sqrt{q}}+\\frac{f(r)}{r\\sqrt{r}} $$\n\nI've tried Lagrange multipliers but the resulting equations do not seem tractable.\n\nEDIT: The original question had the condition $p+q+r=2$ which apparently is not necessary, so I dropped it. I can prove that the inequality holds for $p=q$. A possible strategy is to try to establish monotonicity in one of the parameters under certain conditions. Unfortunately I can't manage the calculations.\n\nshare|improve this question\nI've noticed that this inequality seems to be true for other functions $f(x)$. Which suggests an additional question - what conditions are needed for $f(x)$ so that the inequality holds given the initial conditions. \u2013\u00a0 ivan Dec 14 '12 at 7:28\nHi ivan, the inequality would not be contrary? \u2013\u00a0 Elias Dec 15 '12 at 15:04\nNo, it is like this. \u2013\u00a0 ivan Dec 15 '12 at 16:57\n@ivan : of course, it is no coincidence that you treated the $p=q$ case. For a fixed $r$, and when we let $p$ and $q$ vary, numerically it seems that the minimum of the difference is attained when $p=q$. This is a familiar pattern in symmetrical inequalities : optimality is reached when the variables are equal. \u2013\u00a0 Ewan Delanoy Dec 17 '12 at 8:51\nI would be tempted to study $$g(p,q,r)= \\frac{f(p)}{p\\sqrt{p}}+\\frac{f(q)}{q\\sqrt{q}}+\\frac{f(r)}{r\\sqrt{r}}-\\frac{f(p)+\u200c\u200bf(q)+f(r)}{\\sqrt{p q r}}\\,.$$ It is clear that $g(1,1,1)=0$ (and even $g(p,1,1)\\geq0$). If one could prove that $\\frac{\\partial}{\\partial p} g(p,q,r)\\leq 0$ on $(0,1]^3$, it would be sufficient (using the symmetry in $p$, $q$, $r$) to conclude on $(0,1]^3$, and then I guess the case with one or several of the other variables equal to $0$ could be handled separately. But the partial derivative does not seem to be very nice, as a maple computation indicates. \u2013\u00a0 Sebastien B Dec 17 '12 at 13:39\n\n2 Answers 2\n\nThis is a comment too long to fit in the usual format. Put $g(x)=\\frac{f(x)}{x\\sqrt{x}}$. Then the inequality to be shown is\n\n$$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq g( p ) +g( q ) +g( r ) \\tag{1} $$\n\nI can show this inequality in a special case, when $r=\\frac{1}{10}$. Indeed, a stronger inequality holds in this case :\n\n$$ \\frac{f(p)+f(q)+f(r)}{\\sqrt{p q r}}\\leq g( r ) \\tag{2} $$\n\nTo show (2), it will suffice to show the following four inequalities :\n\n$$ \\begin{array}{lc} \\frac{f(p)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (3) \\\\ \\frac{f(q)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (4) \\\\ \\frac{f(r)}{\\sqrt{p q r}}\\leq \\frac{9}{10} & (5) \\\\ 6 \\leq g(r) & (6) \\\\ \\end{array} $$\n\nConsider the term $$T_1=\\bigg(\\frac{9}{10} (2-p)^2\\bigg)^2pqr - (1-p) $$ Using the fact that $r=\\frac{1}{10}$ and $q=(19/10)-p$, $T_1$ can be rewritten $$ T_1=\\frac{673289}{10^8}+\\frac{62373961}{10^8}(1-q)+\\frac{29403}{80000}(1-q)^2+ (1-q)^3\\Bigg(\\frac{81}{1000}(1-p)^3 + \\frac{1701}{5000}(1-p)^2 + \\frac{48033}{100000}(1-p) + \\frac{58887}{500000}\\Bigg) $$ So $T_1$ is nonnegative, which yields (3). Interchanging $p$ and $q$, we obtain (4). We have $$ f ( r )=\\frac{1}{(2-\\frac{1}{10})^2} \\sqrt{1-\\frac{1}{10}}=\\frac{300}{361\\sqrt{10}} \\tag{7} $$ and hence $$ \\frac{f ( r )}{\\sqrt{pqr}} = \\frac{300}{361\\sqrt{pq}} $$ The identity $$ pq-(\\frac{10}{9} \\times \\frac{300}{361})^2=\\frac{556001}{11728890}+(1-p)(1-q) $$ shows that $pq \\geq (\\frac{10}{9} \\times \\frac{300}{361})^2$, which yields (5). Finally, we deduce from (7) that $$ g ( r )=\\frac{f ( r ) }{r\\sqrt{r}}=\\frac{300}{361\\sqrt{10}} \\times 10\\sqrt{10}=\\frac{3000}{361} $$ and this is indeed larger than $6$, which proves (6) and settles the $r=\\frac{1}{10}$case.\n\nshare|improve this answer\nNice. I tried to generalize this without using $p+q+r=2$ (which seems not to be necessary) but couldn't do it. \u2013\u00a0 ivan Dec 17 '12 at 7:42\nup vote 2 down vote accepted\n\nI was able to prove this, finally. Here is a brief sketch of the proof. I will use the following simple fact:\n\nLemma. For positive numbers, if $a\\geq b\\geq c$ and $(x_1,x_2,x_3)\\succ(y_1,y_2,y_3)$ then $ax_1+bx_2+cx_3\\geq ay_1+by_2+cy_3\\geq ay_i+by_j+cy_k$ where $(i,j,k)$ is an arbitrary permutation of $(1,2,3)$\n\nNow notice that the function : $g(p)=f(p)/\\sqrt{p}$ is decreasing in $(0,1)$. Assume $p\\leq q\\leq r$. Our inequality is equivalent to:$$\\frac{g(p)}{p}+\\frac{g(q)}{q}+\\frac{g(r)}{r}\\geq\\frac{g(p)}{\\sqrt{q r}}+\\frac{g(q)}{\\sqrt{p r}}+\\frac{g(r)}{\\sqrt{p q}}$$ Let's put $x_1=1/p, x_2=1/q$, $x_3=1/r$ and $y_1=(x_1+x_2)/2, y_2=(x_1+x_3)/2, y_3=(x_2+x_3)/2$. Notice that $x_1\\geq x_2\\geq x_3$, $y_1\\geq y_2\\geq y_3$ and $(x_1,x_2,x_3)\\succ(y_1,y_2,y_3)$. Applying the lemma for $a=g(p), b=g(q)$ and $c=g(r)$ ($a\\geq b\\geq c$ because $g(x)$ is decreasing) we get: $$ ax_1+bx_2+cx_3\\geq ay_3+by_2+cy_1=a\\frac{x_2+x_3}{2}+b\\frac{x_1+x_3}{2}+c\\frac{x_1+x_2}{2}\\geq a\\sqrt{x_2 x_3}+b\\sqrt{x_1 x_3} + c\\sqrt{x_1 x_2} $$\n\nand this is exactly what we are trying to prove.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/114378/when-does-every-group-with-order-divisible-by-n-have-a-subgroup-of-order-n/114779\nText:\nTake the 2-minute tour \u00d7\n\nAccording to Sylow's theorem, every finite group with order divisible by $p^k$ for some prime $p$ has a subgroup of order $p^k$. Is this the best possible result in this direction? That is, if $n$ is not a power of a prime, does there always exist a group with order divisible by $n$ that does not have a subgroup of order $n$?\n\nEDIT: Just to clarify, I am aware that groups like this exist. The standard example seems to be $A_4$, which has order divisible by $6$ but no subgroup of order $6$. What I am looking for is a proof that a counterexample exists for any $n$ that is not a power of a prime.\n\nshare|improve this question\nI think this question showed up before. The standard counterexample is $A_4$ that has no subgroup of order $6$. \u2013\u00a0 ego Feb 28 '12 at 9:28\n@m. k.: Also, maybe you should read about Hall subgroups: en.wikipedia.org/wiki/Hall_subgroup \u2013\u00a0 Dennis Gulko Feb 28 '12 at 9:52\nego and Alex: you haven't read the question! I would guess that the answer is yes, but proving it might not be easy. \u2013\u00a0 Derek Holt Feb 28 '12 at 9:58\nI think this is not a duplicate. OP is asking about existence of a group for each $n$, such that $n$ divides the order of the group but, there is no subgroup of order $n$. Well, I am sure a general infinite family is not possible but, there might be a reasonable answer. Further, what Dennis suggests will answer the converse of the question. Hall subgroups in Solvable groups. \u2013\u00a0 user21436 Feb 28 '12 at 10:01\nBTW, I am interested in an answer too. +1 and a star! :-) \u2013\u00a0 user21436 Feb 28 '12 at 10:02\n\n3 Answers 3\n\nup vote 21 down vote accepted\n\nHere is a proof that the answer is yes. Suppose first that $n = p^aq^b$ with $p,q$ prime, $a,b>0$, and suppose that $p^a > q^b$. Let $c$ be minimal such that $p^a$ divides $q^c-1$ - so clearly $c > b$. Then a faithful irreducible module for the cyclic group of order $p^a$ over the field of order $q$ has dimension $c$. (You can define the action explicitly as multiplication by an element $x$ in the field of order $q^c$, where $x$ has multiplicative order $p^a$.)\n\nNow let $G = Q \\rtimes P$ be the semidirect product of an elementary abelian group $Q$ of order $q^c$ by a cyclic group $P$ of order $p^a$, using this module action. So $Q$ is the unique minimal normal subgroup of $G$. A subgroup of $G$ of order $p^aq^b$ would have a normal subgroup of order $q^b$ which would also be normal in $Q$ and hence normal in $G$, contradiction, so there is no such subgroup.\n\nFor the general case, let $n = p^aq^br$ where $r$ is coprime to $p$ and $q$. Then a direct product of $G$, as constructed above, with a cyclic group of order $r$ has no subgroup of order $n$.\n\nshare|improve this answer\nNice! Thank you for this elegant proof. Also, thanks to m.k. for a nice question. \u2013\u00a0 William DeMeo Feb 28 '12 at 11:53\n\nGood question! And, you might also look at research on the following: a CLT (Converse Lagrange Theorem) group is a finite group with the property that for every divisor of the order of the group, there is a subgroup of that order. It is known that a CLT group must be solvable and that every supersolvable group is a CLT group: however solvable groups exist, which are not CLT and CLT groups which are not supersolvable.\n\nshare|improve this answer\n\nI don't know if you are familiar with Hall's theorem which gives a further partial answer to your question.\n\nA Hall-subgroup $H$ in $G$ with regard to a set of primes $\\Pi$ has the property that the index of $|G:H|$ is coprime to every element in $\\Pi$.\n\nHall's theorem states that for solvable groups Hall-subgroups exist for every set of primes. Furthermore for a given set of primes two Hall-subgroups are conjugate.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/644861/if-both-integers-x-and-y-can-be-represented-as-a2-b2-4ab-prove-that\nText:\nTake the 2-minute tour \u00d7\n\nThere is a set $Q$ which contains all integral values that can be represented by $$a^2 + b^2 + 4ab$$, where $a$ and $b$ are also integers. If some integers $x$ and $y$ exist in this set, prove that $xy$ does too.\n\nI really have no idea how I can go about solving this. I tried simple multiplication of the two assuming one to be $(a^2 + 4ab + b^2)$ and other as $(c^2 + 4cd + d^2)$ but ultimately it leads to a long equation I can make no tail of :/\n\nAny help whatsoever would be greatly appreciated\n\nshare|improve this question\nI have updated your post to LaTeX. Please see that the updates are correct. \u2013\u00a0 gekkostate Jan 20 at 12:48\n@hardmath Fixed! Thanks for the catch! \u2013\u00a0 gekkostate Jan 20 at 13:01\n\n2 Answers 2\n\nup vote 6 down vote accepted\n\nSince $a^2+b^2+4ab=(a+2b)^2-3b^2$, your numbers are exactly the numbers of the form $x^2-3y^2$. Now $x^2-3y^2$ is the norm of the algrebraic number $x+y\\sqrt{3}$, so you have the identity\n\n$$ (x^2-3y^2)(u^2-3v^2)=(xu+3yv)^2-3(xv+yu)^2 $$\n\n(multiplicativity of norms).\n\nshare|improve this answer\nThank you so much, now I can finally sleep with this homework done. \u2013\u00a0 skatter Jan 20 at 12:54\nTo make the resulting identity explicit in terms of $a, b, c, d$, if $f(x,y) = x^2 + 4xy + y^2$, then $$f(ac-bd,ad+4bd+bc) = f(a,b) f(c,d).$$ \u2013\u00a0 heropup Jan 20 at 13:13\n\n\nUsing Brahmagupta-Fibonacci Identity,\n\n\n$$n=-m\\implies (a^2-mb^2)(c^2-md^2)=(ac\\mp mbd)^2-m(ad\\mp bc)^2$$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/49532/partitioning-a-matrix-with-bounded-row-sums?sort=newest\nText:\nTake the 2-minute tour \u00d7\n\nLet $A$ be a $n \\times n$ matrix with non-negative entries $a_{ij}$, where $a_{ij}$ is the entry in the $i^{th}$ row and $j^{th}$ column. Assume $\\sum_{1 \\leq j \\leq n} a_{ij} \\leq 1$ for all $1 \\leq i \\leq n$. Also assume $a_{ii} = 0$ for all $1 \\leq i \\leq n$.\n\nI want to partition the index set $I = \\{1, 2 \\ldots n\\}$ into minimum number of sets $I_1, I_2, \\ldots I_t$ so that the column sum is bounded by $1$ in each sub-matrix defined by the sets, or more formally:\n\n  1. $\\cup_{1 \\leq k \\leq t} I_k = I$\n  2. For all $1 \\leq k \\leq t$, $\\sum_{i \\in I_k}a_{ij} \\leq 1$ for all $j \\in I_k$\n  3. The number $t$ is minimized\n\nI can construct examples where $t$ has to be at least $2$, on the other hand, $t = \\Theta(\\log n)$ would suffice for all such matrices. I am wondering if a tighter bound exists.\n\nMotivation: this is a sort of generalization of the coloring problem in bounded out-degree digraphs. If a di-graph has out-degree upper bounded by $k$ it can be colored with $k + 1$ colors.\n\nshare|improve this question\nSo to rephrase the question, you take an edge-weighted digraph with maximum in-degree $k$, and you want to $t$-colour the vertices such that the maximum out-degree to any colour is $k$, right? (I guess you know about the Alon-Tarsi list colouring theorem.) \u2013\u00a0 Andrew D. King Dec 15 '10 at 15:08\nLook at A remark on finite-dimensional $P\\sb{\\lambda }$-spaces by J. Bourgain Studia Mathematica [0039-3223] Bourgain yr: 1982 vol: 72 iss: 3 pg: 285 -289. \u2013\u00a0 Bill Johnson Dec 15 '10 at 16:08\nWell, when you say \"the maximum out-degree to any colour\" if you mean, the maximum weighted out-degree from any node to nodes of the same color, they yes. I actually didn\u2019t know about the theorem you mention :) \u2013\u00a0 Pradipta Dec 15 '10 at 16:09\nYes, that's what I mean. Here is the link for the original Alon-Tarsi paper springerlink.com/content/u627qn50r7013363 , but you might get more out of it by looking at the papers which cite it, for example onlinelibrary.wiley.com/doi/10.1002/jgt.20500/abstract . The proof of their result, which relates to list colourings, uses combinatorial nullstellensatz, which is useful but intimidating. Better to look at what you can do using their theorem as a black box, first. \u2013\u00a0 Andrew D. King Dec 15 '10 at 16:21\nThanks to both Andrew and Bill. I\u2019ll take a look at both papers. \u2013\u00a0 Pradipta Dec 15 '10 at 16:24\n\n2 Answers 2\n\nWhy the qualification \"bounded row-sums\" for a matrix of finite dimension?\n\nshare|improve this answer\nJust emphasizing the upper bound of 1. I guess one could rephrase in the terms the maximum row sum as well. \u2013\u00a0 Pradipta Dec 15 '10 at 19:42\nup vote 0 down vote accepted\n\nOk, I think there are examples where $\\Omega(\\log n)$ colors are needed.\n\nHere\u2019s an example, let $a_{ij} = \\frac{1}{i}$ for $j < i$ and $a_{ij} = \\frac{1}{j^2}$ for $j > i$. Then $\\sum_{j} a_{ij} = \\frac{i-1}{i} + \\sum_{j > i} \\frac{1}{j^2} = O(1)$. Of course, the bound is $O(1)$ instead of $1$, but that can be normalized and all that.\n\nHowever, note that $\\sum_j a_{j1} = \\Omega(\\log n)$ and if we only have $o(\\log n)$ partitions, this sum cannot be \"distributed\" into small enough parts.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/5874/existence-of-a-perfect-measurable-set\nText:\nTake the 2-minute tour \u00d7\n\nGiven a set $E$ which is bounded, measurable and $m^{\\ast}(E)=x >0$, then for each $y \\in (0,x)$ we can find a measurable set $A \\subset E$, such that $m^{\\ast}(A)=y$. To see this one considers measure as a continuous function and applies the Intermediate Value property.\n\nNow we extend the question in the following manner: Suppose $E$ is a set which has finite measure, then for each positive $x < m^{\\ast}(E)$ prove that there exists a perfect set $A \\subset E$, such that $m^{\\ast}(A)=x$.\n\nshare|improve this question\nen.wikipedia.org/wiki/Smith%E2%80%93Volterra%E2%80%93Cantor_set - something like that? \u2013\u00a0 Asaf Karagila Oct 2 '10 at 13:40\nIs $m^*$ a particular type of measure? The term is impossible to google, and I don't see it used in Kolmogorov & Fomin. \u2013\u00a0 aschepler Oct 2 '10 at 14:20\nthe general lebesgue measure \u2013\u00a0 anonymous Oct 2 '10 at 15:09\n@Asaf: I have edited the question \u2013\u00a0 anonymous Oct 2 '10 at 15:11\nBy the continuity argument, I think he meant to look at $m(E\\cap [0,y])$ as $y$ increases, which is continuous. \u2013\u00a0 JDH Oct 2 '10 at 17:36\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nSuppose first that $E$ is contained in the closed interval $[a,b]$ and let $E' = [a,b] \\setminus E$. By definition of Lebesgue measure, we can find an open set $G$ containing $E'$ such that $m(G) = m(E') + \\varepsilon = (b - a) - m(E) + \\varepsilon$, where $\\varepsilon$ is small enough. Then $F = [a,b] \\setminus G$ is a compact set contained in $E$ with measure $m(F) = m(E) - \\varepsilon$.\n\nSuppose we have chosen $\\varepsilon$ small enough that $x \\leq m(E)-\\varepsilon = m(F)$. Your intermediate value argument proves the existence of some point $c \\in [a,b]$ such that $m(F \\cap [a,c]) = x$. By the Cantor-Bendixson Theorem, we have a decomposition $F \\cap [a,c] = K \\cup H$ where $K$ is perfect and $H$ is countable. Since $m(H) = 0$, it follows that $m(K) = m(F \\cap [a,c]) = x$.\n\nIf $E$ is unbounded, then pick $[a,b]$ such that $m(E \\cap [a,b]) = m(E) - \\delta$, where $\\delta$ is small enough, and apply the above argument to $E \\cap [a,b]$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/682420/find-the-mle-of-bivariate-normal\nText:\nTake the 2-minute tour \u00d7\n\nSuppose that $X = (x_{ij})n*2$ follows a bivariate normal distribution $\\mathcal{N}(\\mu, \\sigma^2I)$, where I is the $2\\times 2$ identity matrix. How to find the maximum likelihood estimates of $\\mu$ and $\\sigma^2$? Specifically, how to deal with the determinant part in the density formula of bivariate normal distribution? Thanks!\n\nshare|improve this question\nCan you please explain what you want to mean by $(x_{ij})n*2$? Does it mean a $n\\times 2$ matrix $X$? \u2013\u00a0 Samrat Mukhopadhyay Feb 19 at 18:28\nit's a n*2 matrix, has n rows and 2 columns \u2013\u00a0 user2350622 Feb 19 at 18:37\n\n1 Answer 1\n\nIf $X$ is a $m\\times n$ matrix with $n$ random vectors distributed identically as $\\mathcal{N}(\\mu,\\sigma^2 I_{m\\times m})$, and if the random vectors are independent then you can write the joint distribution of the vectors as $$p(x_1,x_2,\\cdots,\\ x_n)=\\prod_{i=1}^np(x_i)\\\\=\\frac{1}{(2\\pi)^{mn/2} \\sigma^{mn}}\\exp\\left(-\\frac{\\sum_{i=1}^n\\sum_{j=1}^m(x_{ji}-\\mu_{j})^2}{2\\sigma^2}\\right)$$ So, to find the MLE of $\\mu$ and $\\sigma^2$ find the simultaneous solutions of $$\\nabla_{\\mu}p(x_1,x_2,\\cdots,x_n)=0\\\\ \\frac{\\partial p(x_1,x_2,\\cdots,x_n)}{\\partial \\sigma^2}=0$$\n\nshare|improve this answer\nI solved the equations but I ended up getting a strange MLE for sigma^2. I got 1/2*variance of X. \u2013\u00a0 user2350622 Feb 19 at 19:07\nIf by variance you mean the sample variance of $X$, then it is fine. \u2013\u00a0 Samrat Mukhopadhyay Feb 19 at 19:16\nokay! It just seemed to be wired to me because usually MLE variance does not have a 1/2 in front of it \u2013\u00a0 user2350622 Feb 20 at 0:04\nIf you do the math, then you'll see that for the case where you have $m$ samples, a factor of $1/m$ is coming in front of the sample variance. \u2013\u00a0 Samrat Mukhopadhyay Feb 20 at 6:47\nyes but I tried in R and the variance of the samples should be really close to the true sigma. \u2013\u00a0 user2350622 Feb 24 at 1:57\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/95889/cardinality-of-a-certain-set-of-distinct-subsets-of-mathbbn/95913\nText:\nTake the 2-minute tour \u00d7\n\nA recent question here has convinced me that folks here have a warm heart for the foundations of quantum mechanics, so I decided to ask a question that has been bothering me for a while.\n\nQuantum motivation\n\nHardy has proved a theorem saying the the cardinality of the ontic space $\\Lambda$ must always be infinite. As Spekkens put it more clearly, his proof works by making a injection of the set of pure quantum states into the set of distinct subsets of $\\Lambda$. Since the set of pure states is continuous, it follows that $\\Lambda$ must be infinite.\n\nBut the injection isn't exactly onto $\\mathcal{P}(\\Lambda)$, but rather onto a set $D$ of distinct subsets of $\\Lambda$ such that that for no $A,A'\\in D$ is it true that $A \\subset A'$. My question is then: is this additional restriction enough to show that $\\Lambda$ must be continuous? Or is there a countable $\\Lambda$ such that $D$ is uncountable?\n\nQuantum-free question\n\nLet $D$ be a set of distinct subsets of $\\mathbb{N}$ such that for no $A,A'\\in D$ is it true that $A \\subset A'$. What is the maximal cardinality of such a $D$?\n\nThis question seems simple enough, but I haven't been able to answer it.\n\nshare|improve this question\nThe cardinality is the largest possible, $|2^{\\mathbb N}|$. For eample: Identify ${\\mathbb N}$ with ${\\mathbb Q}$, and assign to each real (the range of) a strictly increasing sequence of rationals converging to it. \u2013\u00a0 Andres Caicedo May 3 '12 at 16:21\nYou can have continuum many infinite subsets of $\\mathbb{N}$ such that any two of them are almost disjoint (have finite intersection). \u2013\u00a0 Ramiro de la Vega May 3 '12 at 16:23\nSo the question was in fact simple. Andres, could you please post your comment as an answer so I can accept it? Ramiro, could you please provide an example of your family of subsets of $\\mathbb{N}$? \u2013\u00a0 Mateus Ara\u00fajo May 3 '12 at 16:53\nMateus, the example Andres gave satisfies what I said. \u2013\u00a0 Ramiro de la Vega May 3 '12 at 17:16\n\n3 Answers 3\n\nup vote 8 down vote accepted\n\nA simpler construction, which yields pairwise incomparable sets (but not almost disjoint sets):\n\nFor any subset $A\\subseteq \\mathbb N$, let $X_A:= \\{ 2n: n\\in A\\}$, and let $Y_A:= \\{ 2n+1: n\\notin A\\}$, and let $Z_A:= X_A \\cup Y_A$.\n\nThen the family of all $Z_A$ has size continuum, and $Z_A \\subseteq Z_B$ implies both\n\n  \u2022 $A\\subseteq B$ (because of $X_A\\subseteq X_B$)\n  \u2022 and also $B \\subseteq A$ (because $Y_A\\subseteq Y_B$),\n\nhence $A=B$. So the $Z_A$ are pairwise incomparable.\n\n(A similar construction works also for larger cardinalities; a set of size $\\kappa$ has $2^\\kappa$ many pairwise incomparable subsets; here I use a bijection between $\\kappa$ and $\\kappa\\times 2$.)\n\nshare|improve this answer\nSince I only need pairwise incomparable sets and your construction is simpler, I'm going to accept your answer. \u2013\u00a0 Mateus Ara\u00fajo May 4 '12 at 15:02\n\nMateus, say that a family ${\\mathcal F}$ of infinite subsets of ${\\mathbb N}$ is almost disjoint iff $A\\cap B$ is finite for any distinct sets $A,B$ in ${\\mathcal F}$.\n\nThe answer to your question is that there is a family as you require of size $|{\\mathcal P}({\\mathbb N})|=|{\\mathbb R}|$, which is of course largest possible. In fact, one can find an almost disjoint such family.\n\nThere are several ways of exhibiting an example. I am fond of this construction: Identify ${\\mathbb N}$ with ${\\mathbb Q}$, and assign to each real $r$ (the range of) a strictly increasing sequence of rationals converging to $r$.\n\nAnother way is to identify ${\\mathbb N}$ with the nodes of the binary tree $\\{0,1\\}^{<\\mathbb N}$ whose elements are finite sequences of $0$s and $1$s. Now, each infinite sequence of $0$s and $1$s (and there are $|\\{0,1\\}^{\\mathbb N}|=|{\\mathcal P}({\\mathbb N})|$ many such sequences) can be thought of as an infinite branch through this tree. Associate to it the collection of its initial segments (its \"path\"). This uniquely identifies the branch, and any two different paths eventually diverge, so they have finite intersection.\n\nIf $|X|=\\kappa$ is infinite, the question of the size of a maximal almost disjoint family of subsets of $X$, where we now require $|A\\cap B|<\\kappa$ for distinct $A,B$ in the family, is more delicate if $2^{<\\kappa}>\\kappa$ (otherwise the second argument above adapts to give a family of size $2^\\kappa$). For example, (Baumgartner showed that) it is independent of the usual axioms of set theory with choice whether there is a family of almost disjoint subsets of $\\omega_1$ of size $2^{\\omega_1}$.\n\nshare|improve this answer\nBeautiful answer, thank you! Fortunately the physical question does not depend on the general case =) \u2013\u00a0 Mateus Ara\u00fajo May 3 '12 at 21:26\n\nHere's a way of showing the existence of a family $\\mathcal{D}$ of sets with $\\vert \\mathcal{D}\\vert=2^{\\aleph_0}$ and $\\forall A\\not=A'\\in\\mathcal{D}(A\\not\\subseteq A')$, using computability theory:\n\nSay that a set $A\\subseteq \\mathbb{N}$ is introreducible if it is infinite and is computed by all of its infinite subsets (i.e., $\\forall B\\subseteq A, B\\ge_T A)$.\n\nClaim: for all $X\\subseteq\\mathbb{N}$, there is an introreducible set $Y\\subseteq \\mathbb{N}$ with $Y\\equiv_T X$.\n\nProof: Assume WLOG that $X$ is infinite (otherwise $X$ is computable, and $Y=\\mathbb{N}$ fulfills the claim), and write $X=\\lbrace x_0 < x_1 < . . .\\rbrace $. Let $Y=\\lbrace \\langle x_0, x_1, . . . , x_n\\rangle: n\\in\\mathbb{N}\\rbrace$. Clearly $Y$ is introreducible and $Y\\equiv_T X$.\n\nNow it is known that there exist antichains of size $2^{\\aleph_0}$ in the Turing degrees (i.e., families $\\mathcal{C}=(X_r)_{r\\in\\mathbb{R}}$ with $X_r\\not\\le_T X_s$ whenever $r\\not=s$). Let $Y_r$ be an introreducible set of the same degree as $X_r$ for each $r\\in\\mathbb{R}$. Then clearly $\\mathcal{D}=\\lbrace Y_r: r\\in\\mathbb{R}\\rbrace$ is a family of sets of size $2^{\\aleph_0}$ no one of which is a proper subset of another.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/99007/rate-of-convergence-of-series-of-squared-prime-reciprocals\nText:\nTake the 2-minute tour \u00d7\n\nIt is well known that $\\sum_{p \\text{ prime}} \\frac{1}{p}$ diverges, and in fact - it behaves like log of the harmonic series: $$ \\sum_{p \\le x} \\frac{1}{p} = \\log \\log x + O(1). $$ It is also well known that $\\sum\\limits_{p \\text{ prime}} \\frac{1}{p^2}$ converges. What is known about the rate? Letting $C = \\sum\\limits_{p \\text{ prime}} \\frac{1}{p^2}$, what can be said about $C - \\sum\\limits_{p \\le x} \\frac{1}{p^2}$?\n\nI am reading an article (a survey of Artin's Primitive Root Conjecture - which follows from the GRH). I am trying to understand what are the condition on functions $f_1\\le f_2$ tending to infinity in order that $$ \\sum_{f_1(x) \\le p \\le f_2(x)} \\frac{1}{p^2} = O\\left(\\frac{1}{\\log x}\\right). $$ Of course I can take $f_1(x) = \\log\\log\\log x$, $f_2(x) = \\log\\log x$, but I want the general conditions.\n\nshare|improve this question\nThe sum from $x$ to infinity of $1/p^2$ is bounded by the sum from $x$ to infinity of $1/n^2$ which, by comparison with the integral, is on the order of $1/x$. 29% accept rate - do you understand the value of accepting answers to your questions here? \u2013\u00a0 Gerry Myerson Jan 14 '12 at 23:20\n\n1 Answer 1\n\nup vote 6 down vote accepted\n\nLets rearrange the sum $C-\\sum_{p\\leq x}\\frac{1}{p^{2}}=\\sum_{p>x}\\frac{1}{p^{2}}$. Using integration by parts this is $$\\sum_{p>x}\\frac{1}{p^{2}}=\\int_{x}^{\\infty}\\frac{1}{t^{2}}d\\left(\\pi(t)\\right)=\\frac{\\pi(t)}{t^{2}}\\biggr|_x^\\infty+2\\int_{x}^{\\infty}\\frac{\\pi(t)}{t^{3}}dt.$$ Using the prime number theorem, that is the asymptotic for $\\pi(x),$ you can deduce that the quantity on the right hand side is $\\sim\\frac{1}{x\\log x},$ which is your rate of convergence.\n\nJust worth noting, this is exactly what we would expect. The tail of the sum over all integers has size $\\frac{1}{x}$, that is $\\sum_{n>x} \\frac{1}{n^2}\\sim \\frac{1}{x}$ and the primes occur with density $\\frac{1}{\\log n}$ around $n$, so we would expect the tail of the sum to be of size $\\frac{1}{x\\log x}$. Partial summation/integration allows to prove this.\n\nEdit: Replaced $\\asymp$ with $\\sim$, since as pointed out by Greg Martin in the comments, the Prime Number Theorem is strong enough to yield this/\n\nshare|improve this answer\nUsing the prime number theorem actually gives an asymptotic formula for the tail of the series, not just the order of magnitude, right? \u2013\u00a0 Greg Martin Jan 22 '12 at 10:29\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/136831/factorial-number-of-digits\nText:\nTake the 2-minute tour \u00d7\n\nIs there any neat way to solve how many digits the number $20!$ have? I'm looking a solution which does not use computers, calculators nor log tables, just pen and paper.\n\nshare|improve this question\nI suspect Stirling's approximation will help. \u2013\u00a0 David Mitra Apr 25 '12 at 15:43\nThe simplest way is just to compute $20!$. $20$ is small enough that this shouldn't take too much time (or paper). \u2013\u00a0 Chris Eagle Apr 25 '12 at 15:45\nSee \"D. FACTORIALS OF LARGE NUMBERS\" in groups.google.com/group/sci.math/msg/d12962e3af2c74b7 \u2013\u00a0 Dave L. Renfro Apr 25 '12 at 15:45\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nAs a rough approximation, multiplying an $n$-digit number by an $m$-digit number yields a result with about $n+m$ digits. So the numbers from 2 to 9 are all 1-digit numbers. From 10 to 20 are all 2-digit numbers. That suggests we should have about 18 digits or so.\n\nWolfram|Alpha claims that $20! = 2.4 \\times 10^{18}$. Not far off! :-D\n\nshare|improve this answer\n(Exponents of more than one character require {} to render properly) \u2013\u00a0 The Chaz 2.0 Apr 25 '12 at 16:00\nApparently I fail basic math. If you actually count 2 for all of the 2-digit numbers, you come up with 28, which is quite a way out. sigh \u2013\u00a0 MathematicalOrchid Apr 25 '12 at 20:34\n@TheChaz Thanks for that... \u2013\u00a0 MathematicalOrchid Apr 25 '12 at 20:35\n\nI come from a background in computers, so here's my two cents. Taking the logarithm to the base 10 of n!. If the log comes out to be x, it is not hard to see that the number of digits must be the lowest integer greater than or equal to x, i.e, $floor(x)+1$. Now the question comes down to approximating the $log(n!)$ It is possible to prove by induction that n! lies between $(\\frac{n}{2})^n$ and $(\\frac{n}{3})^n$. Thus the log(n!) lies between $nlog(\\frac{n}{2})$ and $nlog(\\frac{n}{3})$. We can get a pretty tight bound if we used log tables for log(20/3), but as you have disallowed that, using the upper limit(which becomes log(10) = 1) will do quite nicely too. The answer comes to 20*log(10) = 20, which should tell you that the expected number of digit is about 19 or 20.(Since 20 is only the upper bound). And 19 happens to be the answer.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/105586/equality-of-integrals-of-differential-forms\nText:\nTake the 2-minute tour \u00d7\n\nI have two $(n-1)$-forms $\\omega_{1}$ and $\\omega_{2}$ on $\\mathbb{R}^n$ and a smooth function $g(x) \\colon \\mathbb{R}^n \\to \\mathbb{R}$ ($dg$ doesn't vanish anywhere) such that $dg \\wedge \\omega_1 = dg \\wedge \\omega_2$ holds. Let $M = \\{x \\in \\mathbb{R}^n \\mid g(x) = 0 \\}$. Is it true that $$ \\int\\limits_{M} \\omega_1 = \\int\\limits_{M} \\omega_2 $$\n\nshare|improve this question\nDid you try to show the result when $g(x)=x_n$? \u2013\u00a0 Davide Giraudo Feb 4 '12 at 11:02\nNo, but I considered difference $dg \\wedge (\\omega_1 - \\omega_2)$ so it is sufficient to show for $\\omega_2 = 0$. I have $dg(X) = 0$ for any $X$ that is tangent to $g(x) = 0$. Then I take $X_1,...,X_n$ such that $X_1,...,X_{n-1}$ are tangent to $g(x) = 0$ and so $dg \\wedge \\omega_1 (X_1,...,X_n) = \\pm dg(X_n) \\omega_1(X_1,...,X_n)$, but $dg(X_n) \\neq 0$ so $\\omega_1$ is zero on tangent bundle of $M$. \u2013\u00a0 Nimza Feb 4 '12 at 11:12\n$\\omega_1$ and $\\omega_2$ are closed? \u2013\u00a0 Paul Feb 4 '12 at 12:26\n$\\omega_1$ and $\\omega_2$ are arbitrary $(n-1)$-forms such that $dg \\wedge (\\omega_1 - \\omega_2) = 0$ \u2013\u00a0 Nimza Feb 4 '12 at 13:49\nTo the question is reduced to the next: why if the form $\\omega$ vanishes on tangent spaces of $M$ then $\\int_{M} \\omega = 0$? \u2013\u00a0 Nimza Feb 4 '12 at 17:24\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nConsidering $\\omega = \\omega_1 - \\omega_2$ we have to show that if $dg \\wedge \\omega = 0$ then $\\int_{M} \\omega = 0$.\n\n  1. $dg(X_p) = 0$ iff $X \\in T_{p}M$ because $dg(X_p) = \\langle \\nabla g(p), X \\rangle$.\n  2. Let $X^1,...,X^n$ be such that $X^1,...,X^{n-1}$ are from $T_pM$ and $X^n$ is transversal to $T_pM$. Then $$ 0 = dg \\wedge \\omega (X^1_p,...,X^n_p) = \\pm dg(X^n_p) \\omega(X^1_p,...,X^{n-1}_p) $$ but $dg(X^n_p) \\neq 0$ then $\\omega$ vanishes on tangent spaces to $M$, hence $\\int_{M} \\omega = 0$.\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/8426/elliptic-integrals-with-parameter-outside-0m1?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nI'm attempting to implement an equation (for calculating magnetic forces between coils, eqs\u00a0(22\u201324) in the linked paper) that requires the use of elliptic integrals.\n\nUnfortunately these equations require the evaluation of the elliptic integrals far outside their standard parameter range of $0\\le m\\le 1$ and the numerical implementations I have available to evaluate them give inconsistent results.\n\nI believe that Mathematica is correct in its answer:\n\nEllipticF[ArcSin[Sqrt[1/c5]], c5] //. c5 -> 817.327\n=> 0.054961 - 1.17196*10^-17 i\n\nWhereas Matlab's MuPad engine gives:\n\n=> 0.054961 - 0.000707i\n\n(Mma's function takes parameter $m=k^2$ whereas MuPad takes modulus $k$, explaining the sqrt) While I can use Mathematica for my own work, my colleagues only have Matlab available and I'd like them to be able to use this code.\n\nI'm a pretty unfamiliar with the theory behind elliptic integrals, but Baker's \u2018Elliptic Functions\u2019 says\n\nWe shall see later on that the quantity $k^2$ [...] can always be considered real and less than unity.\n\nWhich leads me to ask: can the arguments to these elliptic integrals be re-stated in terms of an input of $k>1$, such as I seem to require above?\n\nshare|improve this question\n...and if I may make a slightly gauche suggestion, it might be profitable to re-express the whole mess in terms of the Carlson integrals, which are less finicky about argument restrictions. \u2013\u00a0 \uff2a. \uff2d. Oct 31 '10 at 3:56\nLest people become confused with terminology: $k$ is a modulus, while $m$ is a parameter. \u2013\u00a0 \uff2a. \uff2d. Oct 31 '10 at 8:10\nI had a look at that paper you linked to; a lot of their elliptic integral expressions are a baroque mess, and I suspect they only wrote what Mathematica spat out without even pausing to look at what can be simplified. \u2013\u00a0 \uff2a. \uff2d. Oct 31 '10 at 10:40\nThanks for the nudge on getting my naming straight. I edited the question slightly to improve my terminology there. Regarding the elliptic integrals, I'm sure you're right unfortunately; I'm actually having some further issues (my question only addresses one term of the equations, as you will have seen in the paper) but I need to get my head straight before I keep asking for help. Thanks again in the mean time! \u2013\u00a0 Will Robertson Oct 31 '10 at 14:18\n\n1 Answer 1\n\nup vote 4 down vote accepted\n\nWhat you seem to require here are the so-called \"reciprocal-modulus transformations\".\n\nIn your specific case, upon applying the reciprocal-modulus transformation, your elliptic integral can actually be simplified to\n\n$$\\frac1{\\sqrt{c_5}}F\\left(\\frac{\\pi}{2}\\vert \\frac1{c_5}\\right)=\\frac1{\\sqrt{c_5}}K\\left(\\frac1{c_5}\\right)$$.\n\nwhere $K(m)$ is the complete elliptic integral of the first kind with parameter $m$ (though I understand MuPAD uses $k=\\sqrt{m}$ as argument, in which case you seem to know the conversion formulae already).\n\nThere are similar formulae for the elliptic integrals of the second and third kinds, and I direct you to the DLMF link I gave above for them.\n\nshare|improve this answer\nFor a Mathematica demonstration: With[{c5 = 817.327}, {EllipticK[1/c5]/Sqrt[c5], EllipticF[ArcSin[1/Sqrt[c5]], c5]}] // Chop \u2013\u00a0 \uff2a. \uff2d. Oct 31 '10 at 3:54\nFantastic, thanks! This both fixes my Matlab code and makes the equation nicer. One of the downsides of equation derivation by a CAS, I suppose. I suspect there are some more simplifications that can then be made in the overall equation. \u2013\u00a0 Will Robertson Oct 31 '10 at 4:34\n\nYour Answer"}
{"text": "Retrieved from http://mathoverflow.net/questions/22243/what-is-the-smallest-cardinal-number-of-a-set-that-requires-the-axiom-of-choice/22250\nText:\nTake the 2-minute tour \u00d7\n\nLet C(x) be a formula belonging to the language of ZFC in which the variable \"x\" and no other variable occurs free. Suppose that (a sentence of this language equivalent to) the following statement, is provable in ZFC but not in ZF.\n\n\"There exists a non-empty set Q such that every element x of Q satisfies the formula C(x)\"\n\nQUESTION: What is the smallest cardinal number that such a set Q can (be proved in ZFC) to have?\n\nI know of no examples of such a set Q having a cardinal number less than 2^(2^k) where k is the cardinal number of the contnuum. Examples of such sets Q are the set of all uncountable sets of real numbers that are non-measurable in the sense of Lebesgue or that contain no perfect subset.\n\nshare|improve this question\nWhat about a set Q containing just one element which is a non-measurable subset of the reals? Do you mean the set of all x satisfying C(x)? \u2013\u00a0 Sergei Ivanov Apr 22 '10 at 20:14\nSergei, even if he does mean all x, then my answer still gives a one-element set. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:29\nBut your answer isn't sporting! \u2013\u00a0 Simon Thomas Apr 22 '10 at 20:42\nBut it is optimal...But seriously, I am interested in the projective version. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:54\n\n2 Answers 2\n\nYou probably won't like this, but the answer is cardinality 1.\n\nLet C(x) be the statement, \"x=0 and the Axiom of Choice holds\".\n\nZF doesn't prove that any x satisifes C(x), since it doesn't prove AC. If AC fails, then no x can have C(x). Thus, ZF+\u00acAC proves that no x has C(x).\n\nBut ZFC proves that C(0) holds, and so it proves that Q={0} is the desired set.\n\n\nThe set { x | C(x) } is an indicator set for AC, in the sense that it is either 0 or 1, depending exactly on whether AC holds. A similar trick works to construct indicator sets for any assertion.\n\nI have suggested that the question be focused on the possibility of projective statements C(x). A projective statement is one expressible in the language of second order number theory, with quantifiers over real numbers and natural numbers. Thus, the question would be whether there is a specific projective statement C(x) such that ZFC proves that Q = { x | C(x) } is nonempty, but ZF does not.\n\nThis version of the question is exactly equivalent to the question of whether ZFC is not conservative over ZF for projective sentences, since if there is a counterexample C(X), then the assertion $\\exists x C(x)$ is provable in ZFC but not ZF, and if $\\sigma$ is provable in ZFC but not in ZF, then the set {x | $\\sigma$} is ZFC provably all of the reals, but ZF is consistent with this set being empty.\n\nTherefore, the question amounts to: Is ZFC not conservative over ZF for projective statements?\n\nI think it is not, but I don't have a counterexample.\n\nMeanwhile, I can say that if one replaces ZF here with ZF+DC, looking at the difference between the full Axiom of Choice and the Axiom of Dependent Choices, rather than at the difference between full AC and no AC at all, then the answer is that it IS conservative. In this MO answer, I explained that ZFC is conservative over ZF+DC for projective sentences, and so if one replaces ZF with ZF+DC in the question, the answer would be no. But without DC, weird things can happen in the reals, and I'm not yet quite sure about it.\n\nshare|improve this answer\nIn this case, the formula asserting that there is such a nonempty Q is exactly equivalent to AC. You could replace AC in this argument with any statement whatsoever; what you get is a kind of indicator set for the truth of that statement. It is empty when the statement fails, and it is 1 when the statement holds. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:05\nI take this answer to show that you will want to revise your question. Probably it is natural to restrict the complexity of the statement C(x). For example, can there be a projective such C(x)? \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:22\nThis is a really cool answer. \u2013\u00a0 Harry Gindi Apr 22 '10 at 20:27\nThanks, Harry. \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:33\n@Joel: I'm thinking about C(x) = \"x is a minimal uncountable ordinal\". Is it projective? \u2013\u00a0 Sergei Ivanov Apr 22 '10 at 20:55\n\nWilfrid Hodges has shown that it is consistent with ZF that there is an algebraic closure $L$ of the rational field $\\mathbb{Q}$ with no nontrivial automorphisms. Obviously $|Aut(L)\\smallsetminus \\{1\\}| = 2^{\\aleph_{0}}$.\n\nSee: W. Hodges, L\u00e4uchli's algebraic closure of $\\mathbb{Q}$. Math. Proc. Cambridge Philos. Soc. 79 (1976), no. 2, 289--297\n\nshare|improve this answer\nIs that rigidity due to the fact that there are less functions in his model than in the usual one? I imagine there is a bijection between his $L$ and the usual algebraic closure, if there is any sense one can talk about such a bijection... \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Apr 22 '10 at 20:10\nSimon, does this example lead to a projective C(x)? I guess not, since I think your L cannot be countable, as weird as that sounds, since if it were then the assertion that L is rigid would be Pi^1_1, and hence absolute to forcing extensions with AC for reals. Could you clarify this? \u2013\u00a0 Joel David Hamkins Apr 22 '10 at 20:26\nI find this shocking and disturbing...so much so that I dug up the paper. It is available at math.uga.edu/~pete/Hodges76.pdf \u2013\u00a0 Pete L. Clark Apr 22 '10 at 21:50\n\u00abThe reader may well feel he could have bought Corollary 10 cheaper in another bazaar\u00bb Best comment in a paper EVAR. \u2013\u00a0 Mariano Su\u00e1rez-Alvarez Apr 22 '10 at 22:04\nYes, this is shocking! Joel is right: L is not countable in that model of ZF. The basic idea goes back to Plotkin who showed that given any countably categorical theory T you can find a model of ZF with an model M of T such that the only subsets of M that exist are the T-definable subsets of M. This doesn't directly apply to the algebraic closure of Q since ACF_0 is not countably categorical, but Hodges showed that ACF_0 is still nice enough for the basic idea to work... \u2013\u00a0 Fran\u00e7ois G. Dorais Apr 22 '10 at 22:14\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/282743/what-are-the-probabilities-in-this-particular-spin-off-of-blackjack\nText:\nTake the 2-minute tour \u00d7\n\nA few of my friends are playing on a gaming server where this game exists. I was curious about the probabilities in it but i was unable to derive them. Any help would be MUCH appreciated. Note: For this problem, please assume that /dice is absolutely random. It is generated by a computer using a pseudo random code but i would appreciate it if that didnt work its way in here.\n\nAs for the game itself, here is how it works, there are two people who play the game, The Player and The Dealer.\n\nAs the game begins, the player uses /dice as many times as he wants(Each /dice has 6 outcomes which have absolutely equal chances). The player then dices as many times as he wants but his total must not go over 21.\n\nFor example when the total reaches 19, it would be a good choice to stop. If he gets 22, 23 or so on then he automatically loses.\n\nOnce he has \"stayed\" at a particular amount the dealer then rolls. His aim is to ensure that he gets a number higher than the player. If he succeeds, he wins. If he trips and gets 22, 23 or so on then he loses.\n\nNow what is the probability that the dealer will win? What is the probability that the player will win? On a average game what is the probability of a 21 being rolled.\n\nshare|improve this question\nJust to be clear, that unless the the player went bust, the dealers strategy is always to roll until he has higher number then the player so that ties are impossible? (so that if the players rolls 21 the dealer always loses) \u2013\u00a0 Shard Jan 20 '13 at 13:54\nWhat's the significance of the slash in front of \"dice\"? \u2013\u00a0 joriki Jan 20 '13 at 14:18\nWhat do you mean by \"On a average game what is the probablity of a $21$ being rolled.\"? How does this differ from \"what is the probablity of a $21$ being rolled?\"? \u2013\u00a0 joriki Jan 20 '13 at 14:40\n1 - In case of a tie, the player re-rolls. I am sorry i forgot to mention that. 2- / signifies a command, i should of probably mentioned that. 3 - Both are one and the same, my bad again :/ \u2013\u00a0 Aayush Agrawal Jan 20 '13 at 18:25\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nWith Shard's notation, the probability that the player wins if she rolls until she has at least $b$ is\n\n$$ p_b=\\sum_{a=b}^{21}\\sum_{c=22}^{a+6}p(a,b)p(c,a+1)\\;, $$\n\nand she will choose $b$ to maximize this. Here's code that calculates these probabilities using Shard's recurrence:\n\n$$ \\begin{array}{c|c} b&p_b\\\\\\hline 16&0.28518\\\\ 17&0.39679\\\\ 18&0.47400\\\\ 19&0.49650\\\\ 20&0.44231\\\\ 21&0.28597\\\\ \\end{array} $$\n\nThus the player should roll until she has at least $19$, and then her winning probability is very nearly even. The probability that she rolls $21$ is $p(21,19)\\approx0.19091$, and the probability that the dealer rolls $21$ is $p(19,19)p(21,20)+p(20,19)p(21,21)\\approx0.13597$, for a total of about $0.32689$.\n\nshare|improve this answer\nI am not very accurate with high level math(13 years old, just learnt 2 variable algebra).What i dont get is why are the probablities that the dealer rolls a 21 different than the players rolling a 21? The dice is fair to both ends right? Also the table describes the probablity of landing on any of those numbers but it doesnt mention the chances of a bust. I am sorry but i am a bit confused :/ \u2013\u00a0 Aayush Agrawal Jan 20 '13 at 18:30\nAlso the probablity of rolling a 21 is given thx but what are the probablities of any random game being won by the player or the dealer? \u2013\u00a0 Aayush Agrawal Jan 20 '13 at 18:34\n@Aayush: I think you misunderstood the table. The probabilities $p(a,b)$ that Shard introduced are the probabilities for landing on $a$ if you keep rolling until you have at least $b$. The probabilities $p_b$ that I introduced are not probabilities for landing on any particular number; they're winning probabilities, which I believe is what you asked for. The table shows that the highest winning probability is achieved if the player rolls until she has at least $19$. I'll explain it in more detail later if I find the time. \u2013\u00a0 joriki Jan 20 '13 at 21:00\n@Aayush: If the player rolls until she has at least $b$, she might win if she ends up with anything from $b$ to $21$. That's reflected in the first sum in the equation, where $a$ is the number she ends up with and the probabilities for these cases are $p(a,b)$. Then the dealer will roll until he has at least one more than $a$ (that's the second argument in $p(c,a+1)$), and the player will win if he ends up with anything from $22$ to $a+6$ -- that's reflected in the second sum and in the first argument of $p(c,a+1)$. Summing over all these cases yields the probability for the player to win. \u2013\u00a0 joriki Jan 20 '13 at 22:39\n@Aayush: Note that this answers the question as originally posed, not the one as modified in your comment under the question. Regarding the probabilities of rolling a $21$: It's not the dice that cause the difference in these probabilities, but the different roles of the player and the dealer. They play with different targets, $b$ and $a+1$, respectively, and the dealer's target $a+1$ depends on the player's result $a$. If they'd play with the same target, they'd have the same probability of hitting $21$. \u2013\u00a0 joriki Jan 20 '13 at 22:42\n\nEach players turn can be described by a set of probabilities based on the \"sticking number\" $b$ they choose which is the lowest total number at which they will stop rolling the dice. The dealer always picks $b=n+1$ where $n$ is the score the player got to try and beat them. The player has a more tricky decision which will be based off what the probabilities are of him winning after sticking vs the probability of immediately going bust.\n\nLet $p(a,b)$ be the probability that the the total = $a$ given we keep rolling until the total is $\\ge b$. Clearly $p(a,b)=0$ if $a<b$ as we are supposed to keep rolling until $a\\ge b$. Also $p(a,b)=0$ for $a>=b+6$ since a single roll of the die cannot take us from a number less then $b$ to one greater then or equal to $b+6$.\n\nAlso if we choose $b=1$ then clearly we stop after our very first roll and so $$p(1,1)=p(2,1)=p(3,1)=p(4,1)=p(5,1)=p(6,1)=\\frac16$$ Now let us consider $b=2$. After our first roll we would only choose to roll again if we rolled a one, and so we end up with\n\n$p(2,2)=p(3,2)=p(4,2)=p(5,2)=p(6,2)=\\frac16+\\frac1{6^2}$ and $p(7,2)=\\frac1{6^2}$\n\nIn general we end up with the recurrence relation $$p(a,b)=p(a,b-1)+\\frac{p(b-1,b-1)}6$$ where $b\\le a\\le b+5$ and zero for other values of $a$.\n\nIt should be easy to calculate the table of probabilities up to $b=21$, and thus work out the chance the dealer wins given that the player \"stuck\" on a certain number. Knowing these probabilities the player can now decide their own sticking number by working out if the chance of going \"bust\" on the next roll is less then the chance they would lose anyway by \"sticking\" and letting the dealer play.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/213374/group-homomorphisms-between-two-abelian-groups-with-different-kernel\nText:\nTake the 2-minute tour \u00d7\n\nDoes there exist two abelian groups $A,B$ with an epimorphism $f: A\\to B$, and two other abelian groups $A', B'$ along with an epimorphism $g: A'\\to B'$ such that $A\\cong A'$, $B\\cong B'$ and $ker\\,f \\not\\cong ker\\,g$? It seems to me that the groups must be infinite, since we have $B\\cong A/ker\\,f$ and $B'\\cong A'/ker\\,g$.\n\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 1 down vote accepted\n\nLet me reformulate the question: you want an abelian group $G$ with two subgroups $H, H'$ which are not isomorphic but such that the quotients $G/H, G/H'$ are isomorphic.\n\nThe smallest example is $G = C_2 \\times C_4, H = C_2 \\times C_2, H' = 1 \\times C_4$.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/303939/planar-graph-number-of-faces\nText:\nTake the 2-minute tour \u00d7\n\nI need to determine the number of faces of a planar graph with $n$ vertices, $m$ edges and $k$ connected components. I was thinking of using Euler's formula $f=m-n+2$ but that is for a connected graph. Because I have $k$ components I was thinking $k$ times Euler formula, for each connected component.\n\nAny advice or help is welcome.\n\nshare|improve this question\nMy advice would be to draw a bunch of examples with, say, three connected components, and calculate $f-m+n$ for each of them, and make a conjecture, and prove it. If you get stuck along the way, come back, tell us what you've done, and someone will help. \u2013\u00a0 Gerry Myerson Feb 14 '13 at 12:34\nIn the Euler's formula for a connected planar graph $f-m+n=2$, one of the face is the exterior face. If you only count the inner face, it is $f_{inner}-m+n=1$. If you have $k$ connected component, you get $f_{inner}-m+n=k$. Add back the exterior face, you get $f-m+n=k+1$. \u2013\u00a0 achille hui Feb 14 '13 at 13:01\n\n2 Answers 2\n\nup vote 3 down vote accepted\n\nEuler's formula can be extended $$ V+F = E +C+\\chi, $$ where $C$ is the number of components and $\\chi$ is Euler's characteristic of the surface where the graph lives on. If you deal with $k$-regular planar graphs the mean face degree obeys: $$ \\frac{\\sum f_k}{F}=\\frac {2k}{k -2} \\left( 1-\\frac{1+\\chi}{F}\\right) $$ (see here)\n\nshare|improve this answer\n\nWe will count the outer face as its own face. So a cycle has two faces, for example.\n\nThe idea is to take each connected component $C_1$, $C_2$, etc., and connect them by drawing a bridge between $C_1$ and $C_2$, $C_2$ and $C_3$, etc. We will thus add $n-1$ edges (the restriction is if you contract the connected components we had previously, you must form a tree).\n\n  \u2022 $F = f$ remains the same.\n  \u2022 $V = n$ since no vertices were added.\n  \u2022 $E = m + k - 1$ since $k-1$ edges were added.\n\nNow apply Euler's formula.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/645289/properties-of-modular-arithemtic-mod-primes-and-quadratic-residues\nText:\nTake the 2-minute tour \u00d7\n\nI have the following two equations:\n\n$$z_1 = x_1^2 \\pmod p$$ $$z_2 = x_2^2 \\pmod q$$\n\nand p and q are prime.\n\nand I want to show $x^2$ and $z^2$ are equal mod pq\n\n$$x^2 = x_1^2 c_1^2 + x_2^2 c^2_2$$ $$z^2 = z_1 c_1^2 + z_2 c^2_2$$\n\nIntuitively, it seems \"obvious that they are equal since $z_1 = x_1^2$ and $z_2 = x_2^2$\" but these statements are only true mod p and q respectively. Then how can one claim that they are indeed equal? I guess I was wondering if I was missing some \"obvious\" property of modular arithmetic or/and quadratic residues?\n\nAlso for reference $c_1$ and $c_1$ are Chinese remainder theorem coefficients. i.e.\n\n$c_1 = 1 \\pmod p$\n\n$c_1 = 0 \\pmod q$\n\n$c_2 = 0 \\pmod p$\n\n$c_2 = 1 \\pmod q$\n\n\nI ran into that doubt when trying to prove:\n\n$ z \\in \\mathbb{QR}_{pq} \\iff z \\in \\mathbb{QR}_p$ and $z \\in \\mathbb{QR}_q$\n\nshare|improve this question\n\n1 Answer 1\n\nup vote 3 down vote accepted\n\nYour equations imply $x^2$ and $z^2$ are $\\,\\equiv z_1\\pmod p,$ and $\\,\\equiv z_2\\pmod{q},\\,$ so $\\,x^2\\equiv z^2 \\pmod{pq}\\,$ by CRT. Or, directly $\\,p,q\\mid x^2-z^2\\Rightarrow\\, pq\\mid x^2-z^2,\\,$ since $\\,p,q\\,$ coprime $\\Rightarrow {\\rm lcm}(p,q) = pq.$\n\nTo be explicit: $\\ {\\rm mod}\\ p\\!:\\ x^2 = x_1^2\\color{#c00}{c_1}^{\\!2}+x_2^2\\color{#0a0}{c_2}^{\\!2} \\equiv x_1^2\\equiv z_1\\ $ by $\\color{#c00}{c_1\\equiv 1},\\,\\ \\color{#0a0}{c_2\\equiv 0}.\\,$\n\nAnd, similarly $\\ {\\rm mod}\\ p\\!:\\ z^2 \\equiv z_1 \\color{#c00}{c_1}^{\\!2} + z_2 \\color{#0a0}{c_2}^{\\!2} \\equiv z_1.\\ $ And similarly $\\,{\\rm mod}\\ q.$\n\nRemark $\\ $ Essentially it concerns the uniqueness mod $pq\\,$ of the solution $X$ of\n\n$$\\begin{eqnarray} X &\\equiv& x_1^2\\pmod p\\\\ X &\\equiv& x_2^2 \\pmod{q}\\end{eqnarray}$$\n\nThis follows by CRT (the easy direction). One doesn't need to write the explicit solution given by CRT, viz. $\\, X = c_1 x_1^2 + c_2 x_2^2.\\,$ (Why do use $\\,c_i^2$ vs. $c_i\\,?)\\,$ What is the context of your problem?\n\nshare|improve this answer\nHi Bill, ur always so helpful to my questions :). The context was that I was trying to prove the following $ z \\in \\mathbb{QR}_{pq} \\iff z \\in \\mathbb{QR}_p$ and $z \\in \\mathbb{QR}_q$ and then ran into the doubt I pointed out. \u2013\u00a0 Pinocchio Jan 20 '14 at 20:11\nWhat does \"viz\" mean? \u2013\u00a0 Pinocchio Jan 20 '14 at 20:43\n@Pinocchio \"namely\", see here \u2013\u00a0 Bill Dubuque Jan 20 '14 at 20:56\nLet me tell you why I used that $c^2$.I wanted to show $x=x_1c_1+x_2c_2$ and $z=z_1c_1+z_2c_2$ satisfied $z=x^2 \\pmod {pq}$.So I computed $x^2 = (x_1c_1)^2+(x_2c_2)^2 +2x_1x_2c_1c_2$.Then I applied modpq leading to: $x^2 = (x_1c_1)^2+(x_2c_2)^2 \\pmod {pq}$ since the way that $c_1$ and $c_2$ is defined,means $c_1c_2$ is divisible by pq.Then I realized that if I just changed the way z was originally defined I would be very close of showing that z was indeed a quadratic residue.So I just changed the definition of it to make it look more similar to what I was looking for i.e. $z=z_1c_1^2+z_2c_2^2$ \u2013\u00a0 Pinocchio Jan 20 '14 at 21:20\nWhich lead me to the exact problem I posted about, because I had the problem that $z_1 = x_1^2 \\pmod p$ and $z_2 = x_2^2 \\pmod q$ only applied in mod p and mod q but I had my final stuff in mod pq. Which I felt there was just something not right going on. Which lead to my post and which your answer resolved because the way that you did stuff with my \"wrong\" stuff made me realize that the technique you used worked on the original problem. :) \u2013\u00a0 Pinocchio Jan 20 '14 at 21:25\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/204659/finding-the-winning-probability-of-the-game\nText:\nTake the 2-minute tour \u00d7\n\nSuppose in an independent game which has 2 players, player 1 and player 2, the probability of player 1 to win each game is $r$. To be the overall winner of the game, one of the players needs to win 2 more games than the other. What is the probability that player 1 will be the overall winner?\n\nMy sketch to solve the question: Note that to be the overall winner, one player should have won 2 games consecutively. So if player 1 is the winner, the outcome should either a draw, i.e. each player wins a game consecutively or player one won 2 games consecutively. But I am not sure how to start calculating.\n\nshare|improve this question\nJust to clarify, they play a game, say head or tail, until one of them has a $2$ games lead onto the other? \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 0:54\nI am not sure as in a head tail game, it is possible to have 2 winner at the same time, i think may be consider a simplier case first, i.e.each game always have one winner \u2013\u00a0 abc Sep 30 '12 at 1:01\nWhat is the tie probability? \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:07\n\n2 Answers 2\n\nLet $a$ be the probability that the first player (ultimately) wins if the two players are tied in wins. Let $b$ be the probability that she wins if she is $1$ ahead. And let $c$ be the probability she wins if she is $1$ behind. We have the equations $$\\begin{align}a&=rb+(1-r)c,\\\\ b&=r+(1-r)a, \\\\ c&=ra.\\end{align}$$\n\nSolve the system of linear equations.\n\nshare|improve this answer\nWould you mind briefly explain how you get the equations \u2013\u00a0 Mathematics Oct 9 '12 at 14:45\nWe justify the first equation. Suppose the two are tied. Player $1$ can ultimately win if (i) she wins next game and ultimately wins or (ii) she loses next game but ultimately wins. For (i), the probability she wins next game is $r$, and given that, she will be $1$ ahead, and the probability she ultimately wins is by definition $b$. So the probability of (i) is $rb$. For (ii), the probability she loses the next game is $1-r$, and given that, she will be $1$ behind, so by definition the probability she ultimately wins is $c$. So the probability of (ii) is $(1-r)c$. (Continued $\\dots$) \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 14:56\nNow we add the probabilities of (i) and (ii). We get $a=rb+(1-r)c$. The other two equations are obtained the same way, except that for the third, if Player $1$ is $1$ behind and wins (probability $r$, they are tied, but if she loses the game, then it's all over, Player $1$ has lost. So probability Player $1$ ultimately wins if she is $1$ behind is $ra$. \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 15:01\nI did the problem this way because it is a general approach to similar problems. A system can be in any one of several states. In our case there are $3$ states (tied, $1$ ahead, $1$ behind). There are various transition probabilities between states. We form a matrix with these transition probabilities, and multiplying by that matrix lets us trace out the evolution of the system. If you are familiar with Linear Algebra, you will note we found an eigenvector of the matrix with eigenvalue $1$. \u2013\u00a0 Andr\u00e9 Nicolas Oct 9 '12 at 15:12\nWhat a gorgeous solution, Thank you very much. \u2013\u00a0 Mathematics Oct 9 '12 at 15:23\n\nThe probability player 1 wins the first two games is $r^2$ while the probability player 2 wins the first two is $(1-r)^2$; otherwise they start again.\n\nSo the probability player 1 wins the first two games given that either of the players does is $\\dfrac{r^2}{r^2 + (1-r)^2}$ and this is therefore the probability overall that player 1 wins overall.\n\nshare|improve this answer\nSituation is not that clear, as mentionned in a comment, the games can tie... \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:04\n@Jean-S\u00e9bastien: if that was a possibility then the question could not be answered without knowing the probability of player 2 winning an individual game. abc's comment says \"each game always has one winner\" \u2013\u00a0 Henry Sep 30 '12 at 1:08\nyes right, he said that he could consider a simpler case. I asked him to specify what is the Tie probability, or player 2's \u2013\u00a0 Jean-S\u00e9bastien Sep 30 '12 at 1:11\n@Jean-S\u00e9bastien: The probability of an overall tie is $0$. \u2013\u00a0 Brian M. Scott Sep 30 '12 at 1:11\nhow do you get that form? \u2013\u00a0 abc Sep 30 '12 at 1:23\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/294007/system-of-linear-equations-for-congruency?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nSo this is my question:\nFind all x such that $4x=3 \\pmod{21}$, $3x=2 \\pmod{20},$ and $7x=3 \\pmod{19}$\n\nSo I know I have to use chinese remainder theorem and I know how to do it if $x$ didn't have a coefficient in front of it. In other words, if it was like:\n$x=3 \\pmod{21}$, $x=2 \\pmod{20},$ and $x=3 \\pmod{19}$\n\nThen I would be able to do it. All you would have to do is pick a pair, list out the congruency and find the commonality. But how do I do it with the coefficients?\n\nshare|improve this question\n\n2 Answers 2\n\nYou can use the fact that the coefficient of $x$ is coprime to the modulus in each case, hence a unit. In the first case, $4\\cdot 16=1\\pmod{21}$, so $$ 4x=3\\pmod{21}\\iff x=3\\cdot 16=6\\pmod{21}. $$\n\nAlso, $3\\cdot 7=1\\pmod{20}$, so $$ 3x=2\\pmod{20}\\iff x=14\\pmod{20}. $$\n\nI'll leave the last one for you. Try using the Euclidean Algorithm on $7$ and $19$ to find an inverse if you get stuck. So you can get an equivalence system of congruences, and solve with CRT, as you mention you are familiar with.\n\nshare|improve this answer\n\nUsing the Convergent proeprty of continued fraction, $$\\frac{21}4=5+\\frac14$$\n\nThe last but one convergent is $5$ $\\implies 21-4\\cdot5=1\\implies 4\\cdot5\\equiv-1\\pmod{21}\\implies 4^{-1}\\equiv-5\\equiv16$\n\nSo, $4x\\equiv 3\\pmod{21}$ becomes $x\\equiv16\\pmod{21}--->(1)$\n\n$$\\frac{20}3=6+\\frac23=6+\\frac1{\\frac32}=6+\\frac1{1+\\frac12}$$ The last but one convergent is $6+\\frac11=7$ $\\implies 20\\cdot1-3\\cdot7=-1\\implies 3\\cdot7\\equiv1\\pmod{20}\\implies 3^{-1}\\equiv7$\n\n$3x\\equiv2\\pmod{20}$ becomes $x\\equiv2\\cdot7\\pmod{20}\\equiv14--->(2)$\n\n\nThe last but one convergent is $2+\\frac1{1+\\frac1{2}}=\\frac83$ $\\implies 19\\cdot3-7\\cdot8=1\\implies 7\\cdot8\\equiv-1\\pmod{19}\\implies 7\\equiv-8\\equiv11$\n\n$7x\\equiv3\\pmod{19}$ becomes $x\\equiv3\\cdot11\\pmod{19}\\equiv14--->(3)$\n\nApplying Chinese Remainder Theorem on $(1),(2),(3)$, $$x\\equiv 16\\cdot19\\cdot20\\cdot b_1+14\\cdot19\\cdot21\\cdot b_2+14\\cdot20\\cdot21\\cdot b_3\\pmod{ 19\\cdot20\\cdot21} $$ where\n\n$19\\cdot20\\cdot b_1\\equiv1\\pmod {21}\\implies (-2)(-1)b_1\\equiv1\\pmod {21}\\implies b_1\\equiv11\\pmod{21}$ as $\\frac{21}2=10+\\frac12\\implies 21\\cdot1-2\\cdot10=1\\implies 2^{-1}\\equiv-10\\pmod{21}\\equiv11$\n\n$19\\cdot21\\cdot b_2\\equiv1\\pmod {20}\\implies (-1)(1)\\cdot b_2\\equiv1\\pmod {20}\\implies -b\\equiv1$ or $b\\equiv-1\\equiv19\\pmod{20}$\n\n$20\\cdot21\\cdot b_3\\equiv1\\pmod {19}\\implies (1)(2)b_3\\equiv1\\pmod {19}\\implies b_3\\equiv10\\pmod{19} $ as $\\frac{19}2=9+\\frac12\\implies 19\\cdot1-10\\cdot2=-1\\implies 2^{-1}\\equiv10\\pmod{19}$\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from http://mathematica.stackexchange.com/questions/39331/how-to-replace-multiple-variables-at-once/39337\nText:\nTake the 2-minute tour \u00d7\n\nI would like to make a replacement \"c1 C1 -> F1, c2 C2-> F2....\" such that the expression like this \"c1 C1 c2 C2 c3 C3 c4 C4\" becomes \"F1 F2 F3 F4\".\n\nI used the standard replacement method: c1 C1 c2 C2 c3 C3 c4 C4 /. {c1 C1 ->F1, c2 C2 -> F2, c3 C3-> F3, c4 C4-> F4}. But mathematica only gives \"F1 c2 C2 c3 C3 c4 C4\", it only replace the first product.\n\nWhat is the reason this replacement does not work? How could I make such a replacement at once?\n\nThanks a lot.\n\nshare|improve this question\nuse //. instead of /. \u2013\u00a0 belisarius Dec 24 '13 at 3:08\nIt works! Thanks a lot! In fact, I used /. for the multiple variables replacement before but never have problems. May I ask why this does not work this time? \u2013\u00a0 skippyho Dec 24 '13 at 3:12\nCheck out the help files for ReplaceAll and ReplaceRepeated \u2013\u00a0 bill s Dec 24 '13 at 4:49\nSome of the discussion here is related. There are probably other questions where issues related to matching subexpressions of Plus and Times are discussed. \u2013\u00a0 Michael E2 Dec 24 '13 at 5:16\nadd comment\n\n1 Answer\n\nWhen it's not more complicated than your example, I do the replacement in the form\n\nc1 C1 c2 C2 c3 C3 c4 C4 /. {C1 -> F1 / c1, C2 -> F2 / c2, C3 -> F3 / c3, C4 -> F4 / c4}\n\nwith simplified patterns that avoid tricky issues of pattern-matching.\n\nThe trouble is that the FullForm of c1 C1 is Times[c1, C1] which on the face of it doesn't exactly match the FullForm of c1 C1 c2 C2 c3 C3 c4 C4, which is\n\nTimes[c1, C1, c2, C2, c3, C3, c4, C4]\n\nBut the pattern-matcher does match them and replaces only a subsequence of the arguments of Times. But since the Times expression has matched already, further rules are not applied. We're lucky (as users) that it matches once, but unlucky that it doesn't match repeatedly. That's why ReplaceRepeated (//.) works: it keeps applying the rules until there are no more matches. First rule will be applied the first time but not on subsequent tries since it will no longer match; and second on the second try, etc.\n\nshare|improve this answer\nNice explanation and recommendations! \u2013\u00a0 belisarius Dec 24 '13 at 13:31\nThanks a lot for such a nice explanation!! \u2013\u00a0 skippyho Dec 25 '13 at 6:01\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/336429/in-this-cumulative-distribution-function-am-i-finding-the-wrong-term\nText:\nTake the 2-minute tour \u00d7\n\nQuestion I was given: Let V be a uniform random variable distributed over the interval (0,1). Let $\\ X = \\frac{1}{\\sqrt(U)}$. What is the cumulative distribution function and probability density function of X?\n\nI understand the basic concept here behind cumulative distribution functions and probability density functions. What's throwing me off here is the additional parameter saying that V is a uniform random variable.\n\nIs the cumulative distance function just: $\\ \\int\\limits_0^1 \\frac{1}{\\sqrt(V)}dV $ which would then just equal 2?\n\nThen the prob dens function would be: $$ \\frac{1}{\\sqrt(V)}-----0<V<1 $$ $$ 0------otherwise $$ This seems too simple to me to be the correct answer though. Am I missing something? Am I finding the cumulative distance function of V rather than of X?\n\nshare|improve this question\nadd comment\n\n1 Answer\n\nup vote 0 down vote accepted\n\nWe find the cumulative distribution function $F_X(x)$ of $X$. So we want to find $\\Pr(X\\le x)$.\n\nIf $x\\le 1$, then $F_X(x)=0$. For since $0\\lt U\\lt 1$, it is impossible for $\\dfrac{1}{\\sqrt{U}}$ to be $\\le 1$.\n\nNow we find $F_X(x)$ for $x\\gt 1$.\n\nWe have $X\\le x$ if and only if $\\dfrac{1}{\\sqrt{U}}\\le x$. Flip it over. So $X\\le x$ if and omly if $\\sqrt{U}\\ge \\dfrac{1}{x}$, that is, if and only if $U\\ge \\dfrac{1}{x^2}$.\n\nBut $\\Pr\\left(U\\ge \\dfrac{1}{x^2}\\right)=1-\\Pr\\left(U\\le \\dfrac{1}{x^2}\\right)$. Since $U$ is uniform, this is simply $1-\\dfrac{1}{x^2}$. Thus for $X\\gt 1$, $$F_X(x)= 1-\\frac{1}{x^2}.$$\n\nFor the density function $f_X(x)$, differentiate the cdf.\n\nshare|improve this answer\nWhich would just yield 2/X^3 for X>1 and 0 otherwise? \u2013\u00a0 chrisbster Mar 21 '13 at 2:24\nAnd thank you - that clarification was fantastic! \u2013\u00a0 chrisbster Mar 21 '13 at 2:24\nYou are welcome. Yes, the density function (for $x\\gt 1$) is $\\frac{2}{x^3}$. \u2013\u00a0 Andr\u00e9 Nicolas Mar 21 '13 at 2:32\nadd comment\n\nYour Answer"}
{"text": "Retrieved from http://www.newton.dep.anl.gov/newton/askasci/1993/math/MATH029.HTM\nText:\nNEWTON, Ask A Scientist!\nNEWTON Home Page NEWTON Teachers Visit Our Archives Ask A Question How To Ask A Question Question of the Week Our Expert Scientists Volunteer at NEWTON! Frequently Asked Questions Referencing NEWTON About NEWTON About Ask A Scientist Education At Argonne Spirals... Circles... Radius\nName: Name\nStatus: N/A\nAge: N/A\nLocation: N/A\nCountry: N/A\nDate: Around 1993\n\nQuestion: Is there any mathematical formula for determining the un-rolled length of a spiral? For instance, if I had a roll of ribbon that had a radius of two inches, and the ribbon was one sixteenth of an inch thick, how long would the ribbon be? If there is not a formula for it, what would be the best way to determine this?\n\nA very close approximation for this kind of spiral is to pretend that the roll of ribbon is a series of concentric circular loops of ribbon. Then, the length of each loop is 2 * pi * r, where r = the loop's radius and pi = 3.1415926...so the answer for your example would be: 2 * pi * (1/16 + 2/16 + 3/16 + ... + 32/16) = 2 * pi * 528/16. If the ribbon was on a spindle of radius, say, 1 inch, the sum would be (16/16 + 17/16 + ... + 32/16). An interesting related problem is find (and prove) a formula for ( 1 + 2 + 3 + ... + N ) John Hawley\n\nHere is another approach. If we assume that the ribbon is tightly wound up (i.e., no gaps between the layers of ribbon), then the volume occupied by the 'disk' of wound-up ribbon equals the volume of the unwound strip (a very flat and long 'box'). Let R denote the radius of the 'disk', T the thickness of the ribbon, L its unwound length (the quantity we want to compute), and W its width. The wound-up volume is pi*R^2*W (\"R^2 means \"R squared\"), and the unwound volume is L*W*T. Setting these equal and solving for L, we get L = pi*R^2/T. For the values given (R=2 in., T=1/16 in.), we get L = 64*pi (about 201) inches. By the way, your idea of using a spiral would work. One could write an equation (polar coordinates would be the easiest choice) for a curve that would lie within the ribbon-say, at mid- interior. There is a formula for length of a curve, using integral calculus. As it happens, the answer you get is the same as that obtained above. If you would like more details on this calculus approach, please ask (here or via e- mail).\n\nRon Winther\n\nClick here to return to the Mathematics Archives\n\n\n\nEducational Programs\nBuilding 360\n9700 S. Cass Ave.\nArgonne, Illinois\n60439-4845, USA\nUpdate: June 2012\nWeclome To Newton\n\nArgonne National Laboratory"}
{"text": "Retrieved from http://math.stackexchange.com/questions/26167/expectation-of-the-maximum-of-iid-geometric-random-variables/26214\nText:\nTake the 2-minute tour \u00d7\n\nGiven $n$ independent geometric random variables $X_n$, each with probability parameter $p$ (and thus expectation $E\\left(X_n\\right) = \\frac{1}{p}$), what is $$E_n = E\\left(\\max_{i \\in 1 .. n}X_n\\right)$$\n\nIf we instead look at a continuous-time analogue, e.g. exponential random variables $Y_n$ with rate parameter $\\lambda$, this is simple: $$E\\left(\\max_{i \\in 1 .. n}Y_n\\right) = \\sum_{i=1}^n\\frac{1}{i\\lambda}$$\n\n(I think this is right... that's the time for the first plus the time for the second plus ... plus the time for the last.)\n\nHowever, I can't find something similarly nice for the discrete-time case.\n\nWhat I have done is to construct a Markov chain modelling the number of the $X_n$ that haven't yet \"hit\". (i.e. at each time interval, perform a binomial trial on the number of $X_n$ remaining to see which \"hit\", and then move to the number that didn't \"hit\".) This gives $$E_n = 1 + \\sum_{i=0}^n \\left(\\begin{matrix}n\\\\i\\end{matrix}\\right)p^{n-i}(1-p)^iE_i$$ which gives the correct answer, but is a nightmare of recursion to calculate. I'm hoping for something in a shorter form.\n\nshare|improve this question\nIs there are typo there? How did $32$ get into it? \u2013\u00a0 joriki Mar 10 '11 at 8:58\nOh yes, whoops. This question arises from a concrete example, where n was 32. \u2013\u00a0 Rawling Mar 10 '11 at 9:04\nIs there a reason for the \"RV\" abbreviation? The main page has plenty of space for two lines... \u2013\u00a0 Uticensis Mar 10 '11 at 9:15\nForce of habit. I can now see all the other questions in \"Related\" with \"random variable\" in their titles :) \u2013\u00a0 Rawling Mar 10 '11 at 9:17\n\n3 Answers 3\n\nup vote 14 down vote accepted\n\nFirst principle:\n\nTo deal with maxima $M$ of independent random variables, use as much as possible events of the form $[M\\leqslant x]$.\n\nSecond principle:\n\nTo compute the expectation of a nonnegative random variable $Z$, use as much as possible the complementary cumulative distribution function $\\mathrm P(Z\\geqslant z)$.\n\nIn the discrete case, $\\mathrm E(M)=\\displaystyle\\sum_{k\\ge0}\\mathrm P(M>k)$, the event $[M>k]$ is the complement of $[M\\leqslant k]$, and the event $[M\\leqslant k]$ is the intersection of the independent events $[X_i\\leqslant k]$, each of probability $F_X(k)$. Hence, $$ \\mathrm E(M)=\\sum_{k\\geqslant0}(1-\\mathrm P(M\\leqslant k))=\\sum_{k\\geqslant0}(1-\\mathrm P(X\\leqslant k)^n)=\\sum_{k\\geqslant0}(1-F_X(k)^n). $$ The continuous case is even simpler. For i.i.d. nonnegative $X_1$, $X_2$, ..., $X_n$, $$ \\mathrm E(M)=\\int_0^{+\\infty}(1-F_X(t)^n)\\mathrm{d}t. $$\n\nshare|improve this answer\nThese are very nice principles. I'd just add that what Didier has called \"repartition function\" is called \"cumulative distribution function\" in English. \u2013\u00a0 Michael Lugo Mar 10 '11 at 19:27\n@Michael Thanks, post modified. \u2013\u00a0 Did Mar 10 '11 at 21:01\n@Did sorry to bother you over such an old answer but I am unclear on what F_X(k) is. For a geometric distribution of parameter p, I think it is the c.d.f. or (1-(1-p)^{k+1}). Is this correct? \u2013\u00a0 Dale M Apr 2 '13 at 1:52\n@DaleM If $P(X=k)=p(1-p)^k$ for every $k\\geqslant0$, yes. \u2013\u00a0 Did Apr 2 '13 at 5:08\n\nThere is no nice, closed-form expression for the expected maximum of IID geometric random variables. However, the expected maximum of the corresponding IID exponential random variables turns out to be a very good approximation. More specifically, we have the hard bounds\n\n$$\\frac{1}{\\lambda} H_n \\leq E_n \\leq 1 + \\frac{1}{\\lambda} H_n,$$ and the close approximation $$E_n \\approx \\frac{1}{2} + \\frac{1}{\\lambda} H_n,$$ where $H_n$ is the $n$th harmonic number $H_n = \\sum_{k=1}^n \\frac{1}{k}$, and $\\lambda = -\\log (1-p)$, the parameter for the corresponding exponential distribution.\n\nHere's the derivation. Let $q = 1-p$. Use Did's expression with the fact that if $X$ is geometric with parameter $p$ then $P(X \\leq k) = 1-q^k$ to get\n\n$$E_n = \\sum_{k=0}^{\\infty} (1 - (1-q^k)^n).$$\n\nBy viewing this infinite sum as right- and left-hand Riemann sum approximations of the corresponding integral we obtain\n\n$$\\int_0^{\\infty} (1 - (1 - q^x)^n) dx \\leq E_n \\leq 1 + \\int_0^{\\infty} (1 - (1 - q^x)^n) dx.$$\n\nThe analysis now comes down to understanding the behavior of the integral. With the variable switch $u = 1 - q^x$ we have\n\n$$\\int_0^{\\infty} (1 - (1 - q^x)^n) dx = -\\frac{1}{\\log q} \\int_0^1 \\frac{1 - u^n}{1-u} du = -\\frac{1}{\\log q} \\int_0^1 \\left(1 + u + \\cdots + u^{n-1}\\right) du $$ $$= -\\frac{1}{\\log q} \\left(1 + \\frac{1}{2} + \\cdots + \\frac{1}{n}\\right) = -\\frac{1}{\\log q} H_n,$$ which is exactly the expression the OP has above for the expected maximum of $n$ corresponding IID exponential random variables, with $\\lambda = - \\log q$.\n\nThis proves the hard bounds, but what about the more precise approximation? The easiest way to see that is probably to use the Euler-Maclaurin summation formula for approximating a sum by an integral. Up to a first-order error term, it says exactly that\n\n$$E_n = \\sum_{k=0}^{\\infty} (1 - (1-q^k)^n) \\approx \\int_0^{\\infty} (1 - (1 - q^x)^n) dx + \\frac{1}{2},$$ yielding the approximation $$E_n \\approx -\\frac{1}{\\log q} H_n + \\frac{1}{2},$$ with error term given by $$\\int_0^{\\infty} n (\\log q) q^x (1 - q^x)^{n-1} \\left(x - \\lfloor x \\rfloor - \\frac{1}{2}\\right) dx.$$ One can verify that this is quite small unless $n$ is also small or $q$ is extreme.\n\nAll of these results, including a more rigorous justification of the approximation, the OP's recursive formula, and the additional expression $$E_n = \\sum_{i=1}^n \\binom{n}{i} (-1)^{i+1} \\frac{1}{1-q^i},$$ are in Bennett Eisenberg's paper \"On the expectation of the maximum of IID geometric random variables\" (Statistics and Probability Letters 78 (2008) 135-143).\n\nshare|improve this answer\nIs the log here based 2 or mathematical constant? \u2013\u00a0 Fan Zhang Apr 2 '12 at 4:35\n@FanZhang: It's log base $e$. \u2013\u00a0 Mike Spivey Apr 2 '12 at 13:59\n\n$$\\begin{align} P(\\max Y_i=k)&=P(\\max Y_i\\leq k)-P(\\max Y_i<k)\\\\\\\\&=F(k)^n-(F(k)-f(k))^n. \\end{align}$$ Thus $$\\begin{align} E(\\max Y_i) &= \\sum_{k=0}^{\\infty} k\\left[F(k)^n-(F(k)-f(k))^n\\right] \\\\\\\\ &=\\sum_{k=1}^{\\infty}k\\left[\\left(1-(1-p)^k\\right)^n-\\left(1-(1-p)^{k-1}\\right)^n\\right]. \\end{align}$$\n\nNot a closed form though.\n\nSee also Order statistic for both continuous and discrete case. The formula for the continuous case appears in Shai Covo's post here.\n\nshare|improve this answer\nVery nice. No recursion required to calculate, works with any distribution, and gives me a whole new concept to look into. I'll have to try with the continuous case to see if it gives me the same answer as I have above. \u2013\u00a0 Rawling Mar 10 '11 at 9:48\n\nYour Answer"}
{"text": "Retrieved from http://math.stackexchange.com/questions/104946/poisson-process-courts?answertab=votes\nText:\nTake the 2-minute tour \u00d7\n\nIITK sports facility has $4$ tennis courts. Players arrive at the courts at a Poisson rate of one pair per $10$ min and use a court for an exponentially distributed time with mean $40$ min. Suppose that a pair of players arrives and finds all courts busy and $k$ other pairs waiting in queue. How long will they have to wait to get a court on the average?\n\nshare|improve this question\n\n1 Answer 1\n\nThey need to wait for $k+1$ pairs to finish before they can start.\n\nSince the exponential distribution is memoryless, the expected time for a given pair to finish once started is $40$ minutes, and there are four courts, the expected time for any of the four courts to finish is $\\frac{40}{4}=10$ minutes, and so their expected waiting time is $10(k+1)$ minutes.\n\nSlightly more worryingly, since the service rate of the courts is equal to the arrival rate, the expected waiting time (in effect summing over $k$ weighted by the probability that there are $k$ queuing at any one time) is infinite.\n\nshare|improve this answer\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1815268/how-might-i-solve-the-following-equation\nText:\n$$x * 0.98^{\\sqrt x / 321868} = 9.46 * 10^8$$\n\nI mean is there any way to do this algebraically? There's a single variable, but I don't know of any way to manipulate it such that I can get x on one side -- or even get it out of the exponent, since I can't take the log base 0.98 of the right hand side over a variable...\n\n  \u2022 $\\begingroup$ You can't do it algebraically. $\\endgroup$ Jun 6 '16 at 1:25\n  \u2022 $\\begingroup$ You're right. Is there even a solution? Wolfram $\\endgroup$\n    \u2013\u00a0rb612\n    Jun 6 '16 at 1:27\n  \u2022 $\\begingroup$ Lol it timed out...even with extended computing time $\\endgroup$\n    \u2013\u00a0James\n    Jun 6 '16 at 1:38\n  \u2022 1\n    $\\begingroup$ I think there is a solution. I wrote a program to plug in one x and get the other. I find that 9.4783 * 10^8 works. Of course this is limited precision, and it's not what OP asked for. $\\endgroup$ Jun 6 '16 at 1:52\n\nAny equation which can write as $$A+Bx+C\\log(D+Ex)=0$$ shows solutions which can be expressed in terms of Lambert function.\n\nFor the case of $$x\\, a^{b \\sqrt{x}}=c$$ the solution is given by $$x=\\frac{4 W\\left(\\pm\\frac{1}{2} b \\sqrt{c} \\log (a)\\right)^2}{b^2 \\log ^2(a)}$$ where $W(z)$ denotes Lambert function.\n\nFor your values of $a,b,c$, this will give, as roots, $x_1\\approx 9.4783\\times 10^8$ and $x_2 \\approx 8.5147\\times 10^{16}$.\n\nIn your specific case, the value of the argument is quite small $(z\\approx -0.000965267)$ and you can use the approximation around $z=0$ given in the Wikipedia page $$W(z)=z-z^2+\\frac{3 z^3}{2}-\\frac{8 z^4}{3}+\\frac{125 z^5}{24}+O\\left(z^6\\right)$$\n\nFrom a practical point of view, since you handle very large numbers, I would suggest, for a better scaling, some preliminary change of variable such as $$\\frac{\\sqrt{x}}{321868}=y\\implies x=103599009424 y^2$$ which would reduce the equation to $$y^2 \\times \\left(\\frac{49}{50}\\right)^y=\\frac{59125000}{6474938089}$$ and, taking logarithms, consider the plot of function $$f(y)=2\\log(y)+y \\log\\left(\\frac{49}{50}\\right)-\\log\\left(\\frac{59125000}{6474938089}\\right)$$\n\n$f'(y)$ cancels at $y_*=\\frac{2}{\\log \\left(\\frac{50}{49}\\right)}\\approx 98.9966$ and $f(y_*)\\approx 11.8862$. $f''(y)$ being negative for all $y$, $y_*$ corresponds to a maximum and two roots are expected. Graphing the function to locate more or less the roots, then Newton method will lead to solutions $y_1\\approx 0.0956505$ and $y_2\\approx 906.582$. From here, go back to the solutions for $x$.\n\n  \u2022 $\\begingroup$ Woah - cool solution $\\endgroup$\n    \u2013\u00a0James\n    Jun 6 '16 at 4:43\n  \u2022 $\\begingroup$ @James. This is a fantastic function with a lot of applications. Search on this site. You will find plenty of problems using Lambert function. $\\endgroup$ Jun 6 '16 at 4:45\n\nYour Answer"}
{"text": "Retrieved from https://mathoverflow.net/questions/257313/when-do-27-lines-lie-on-a-cubic-surface/257593\nText:\nConsider $27$ (pairwise distinct!) lines in $\\mathbb{P}^3$ whose intersection graph is that expected\u00b9 of the $27$ lines on a smooth cubic surface. Question: Is there a simple necessary and sufficient condition for these $27$ lines to indeed lie on a smooth cubic surface?\n\nFor a long time I thought this was always the case, but there is at least one obvious necessary condition\u00b2:\n\n(T) Whenever three lines pairwise intersect (i.e., are pairwise coplanar), all three lie on a common plane.\n\n(Because the plane through two mutually intersecting lines on a cubic surface cuts the surface as the union of three distinct lines. There are $45$ such tritangent planes on the cubic surface.)\n\nIs this condition (T) sufficient?\n\nFurther comment and bonus question: The locally closed subvariety of $\\mathrm{Gr}(2,4)^{27}$ (or $\\mathrm{Sym}^{27}(\\mathrm{Gr}(2,4))$) consisting of configurations of $27$ lines satisfying the incidence conditions (made explicit in note\u00a0(1) below) is not irreducible (because of the first sentence of note\u00a0(2) below). What are its irreducible components?\n\n\n  1. I.e., we can label the lines as $a_1,\\ldots,a_6$, $b_1,\\ldots,b_6$ and $c_{12},\\ldots,c_{56}$ (the latter indexed by the $15$ unordered pairs in $\\{1,\\ldots,6\\}$) such that the $a_i$ mutually don't intersect, the $b_i$ mutually don't intersect, each $a_i$ intersects each $b_j$ except exactly when $i=j$, the $c_{ij}$ intersect exactly when their index pairs are disjoint, and $c_{ij}$ intersects exactly $a_i,a_j,b_i,b_j$ among the $a_k$ and $b_k$. Equivalently, the intersection graph is the complement of the vertex graph of the Gosset $2_{21}$ polytope. Equivalently, the faithful transitive action of $W(E_6)$ on $27$ elements where the incidence relation is given by the orbit on the unordered pairs such that every line is incident to exactly $10$ others.\n\n  2. Three distinct mutually intersecting lines in $\\mathbb{P}^3$ either lie on a common plane or, dually, meet at a common point. (Apologies for pointing out something so obvious, but I'm sure I'm not the only one who might have missed this trivial fact.) If we take the $27$ lines on a smooth cubic surface $X$ and dualize (i.e., replace them by their polars w.r.t. some fixed nondegenerate quadric), we get another configuration of $27$ lines (lying on the projective dual $X^\\vee$ to the cubic surface) which have $45$ points of intersection of triples of lines, but in general (unless $X$ had some Eckardt points) no planes in which three lines lie; so this configuration does not lie on a cubic surface (and indeed, $X^\\vee$ is not a cubic surface).\n\n  \u2022 2\n    $\\begingroup$ there is something I don't understand in the last paragraph: in the configuration of the 27 lines on the cubic there are just 45 points of (triple) intersection, not 135. $\\endgroup$ Dec 16 '16 at 0:19\n  \u2022 $\\begingroup$ I agree with Dima Pasechnik: there are 45 2-planes that intersect the cubic surface in a \"triangle\", not 135. $\\endgroup$ Dec 16 '16 at 12:38\n  \u2022 $\\begingroup$ Indeed, I miscounted (135 is the number of pairs of intersecting lines, so it counts every tritangent plane three times). Fixed. $\\endgroup$\n    \u2013\u00a0Gro-Tsen\n    Dec 19 '16 at 16:08\n\nIt turns out that condition (T) is, indeed, sufficient for the $27$ lines (distinct and intersecting as expected) to lie on a cubic surface.\n\nTo see this, consider the lines $a_1,a_2,a_3,a_4,a_5$ and $b_6$, where the labeling is as in note\u00a0(2) of the question: $a_1$ through $a_5$ are pairwise skew, and $b_6$ intersects all of them. Choose $4$ distinct points on $b_6$, and $3$ distinct points on each of $a_1$ through $a_5$ also distinct from the intersection point with $b_6$: this makes $4+5\\times3=19$ points in total; since there are $20$ coefficients in a cubic form on $4$ variables, there exists a cubic surface $S$ passing through these $19$ points. Since $S$ contains four distinct points on $b_6$, it contains $b_6$ entirely, and since it contains four points (viz., the intersection with $b_6$ and the three additional chosen points) on each of $a_1$ through $a_5$, it contains these also.\n\nNow $b_1$ intersects the four lines $a_2$ through $a_5$ in four distinct points since $a_2$ through $a_5$ are pairwise skew; and since these four points lie on $S$, it follows that $b_1$ lies entirely on\u00a0$S$; similarly, $b_2$ through $b_5$, and finally $a_6$ (which intersects $b_1$ through\u00a0$b_5$ in distinct points), all lie on\u00a0$S$. So $S$ contains the \"double-six\" $\\{a_1,\\ldots,a_6,b_1,\\ldots,b_6\\}$.\n\nSo far, property (T) has not been used, only the incidence relation. Now it remains to see that the $c_{ij}$ lie on $S$. Consider the intersection line $\\ell$ of the planes $a_i\\vee b_j$ (spanned by $a_i$ and $b_j$) and $a_j\\vee b_i$ (spanned by $a_j$ and $b_i$; these planes are well-defined since $a_i$ meets $b_j$ and $a_j$ meets $b_i$, and they are distinct since $a_i$ and $a_j$ are skew): this line $\\ell$ must be equal to the $c_{ij}$ of the given configuration, because $c_{ij}$ intersects both $a_i$ and $b_j$ so property (T) implies that it lies in the plane $a_i\\vee b_j$, and similarly it lies in the plane $a_j\\vee b_i$. But $\\ell$ also lies on\u00a0$S$ for similar reasons\u00b9, in other words, $c_{ij}$ lies on\u00a0$S$, and all the given lines lie on\u00a0$S$.\n\nFinally, $S$ must be smooth because it contains the configuration of $27$ lines expected of a smooth cubic surface (it is easy to rule out the case where $S$ is a cubic cone, a reducible surface or a scroll by considering the intersecting and skew lines in the double-six; and every configuration where $S$ has double point singularities has fewer than $27$ lines).\n\n  1. Let me be very precise here, because at this stage we don't know whether $S$ is smooth (so we can't invoke (T) directly on\u00a0$S$). We have four distinct lines $a_i,a_j,b_i,b_j$ on $S$ such that $a_i$ meets $b_j$ and $a_j$ meets $b_i$ and all other pairs are skew. Call $\\pi := a_i\\vee b_j$ and $\\pi' := a_j \\vee b_i$ the planes generated by the two pairs of concurrent lines, and $\\ell := \\pi\\wedge\\pi'$ their intersection. We want to show that $\\ell$ lies on the surface\u00a0$S$. If $\\pi$ or $\\pi'$ is contained in\u00a0$S$ (reducible) then the conclusion is trivial, so we can assume this is not the case. So the (schematic) intersection of $S$ with the plane $\\pi$ is a cubic curve containing two distinct lines ($a_i$ and $b_j$), so it is the union of three lines: $a_i$, $b_j$ and a third line\u00a0$m$ (a priori possibly equal to one of the former). Consider the intersection point of $a_j$ and $\\pi$ (which is well-defined since $a_j$ is skew with $a_i$ so does not lie in\u00a0$\\pi$): it lies on $\\ell$ because it is on both $\\pi$ and $\\pi'$; and it must also lie on $m$ since it is on $\\pi$ but neither on $a_i$ nor on $b_j$ (as the two are skew with\u00a0$a_j$); similarly, the intersection point $b_i\\wedge\\pi$ is well-defined and lies on both $\\ell$ and $m$; so $\\ell=m$ lies on $S$ (and we are finished) unless perhaps the two intersections considered are equal, i.e., $a_j,b_i,\\pi$ concur at a point $P$, necessarily on $m$. Assume the latter case: $S$ must be singular at $P$ because the line $m$ through $P$ does not lie on the plane $\\pi'$ generated by two lines ($a_j,b_i$) through\u00a0$P$ (i.e., we have three non-coplanar tangent directions at\u00a0$P$). Now symmetrically, if we call $m'$ the third line of the intersection of $S$ with $\\pi'$ (besides $a_j$ and $b_i$), we are done unless $a_i,b_j,\\pi'$ concur at a point $P'$, necessarily on $m'$ and necessarily singular on $S$. The points $P$ and $P'$ are distinct because $a_i$ and $a_j$ are skew; and they are on $\\ell$ because they are on $\\pi$ and\u00a0$\\pi'$; and the line joining two singular points on a cubic surface lies on the surface, so $\\ell = P\\vee P'$ lies on\u00a0$S$ in any case. (Phew!)\n\nWhat I still don't know is whether there are configurations of $27$ distinct lines with the expected incidence relations and which satisfy neither condition (T) nor its dual (viz., whenever three lines pairwise meet, all three meet at a common point), and in particular, what are the irreducible components of the space of configurations. (I also don't know if there is a way to substantially simplify the tedious argument given in note\u00a0(1) above.)\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/45405/highlight-current-line-in-gud-disassembler-window/45410\nText:\nI am using GUD for debugging C code. Because many of the lines and variables have been optimized away, it is necessary to follow the C source and the corresponding disassembly simultaneously. I want the current line in the disassembler window to be highlighted each time I \"step instruction.\" Right now the cursor moves automatically, in the disassembler window, but hl-line-mode does not highlight the line that the cursor moved to. If I switch to that window, the new line gets highlighted, and remains highlighted when I move away from that window again. But each time I step, the highlighting from hl-line-mode disappears in the inactive window.\n\nHow can I get a good visual indication of the \"current line\" in the disassembler window? The tiny triangle in the fringe is not enough, because the lines are quite long, and it is difficult to tell at a glance which instruction will be executed next.\n\n  \u2022 Wherever you see gud-overlay-arrow-position (make-marker) ... set-marker, you can put something after that location using (marker-position gud-overlay-arrow-position) as the point at which to update hl-line-mode or other gizmo that suits your needs. I see two (2) locations in the version I am using: gud-display-line and gdb-frame-handler. However, I have limited experience using gdb and am unfamiliar with terms such as disassembler and step instruction ... Therefore, I am unable to write up an answer because I cannot test it myself.\n    \u2013\u00a0lawlist\n    Oct 16 '18 at 18:33\n  \u2022 Thanks, @lawlist. I tried this and found out that the gud-overlay-arrow-position is different from the gdb-disassembly-position overlay. Interestingly the gud-display-line function already has special handling for hl-line-mode, so regular source buffers already work as expected with hl-line-mode, even when the source buffer is not the active window. (re-reading this comment right after typing it, I realize that it might be more confusing than anything.)\n    \u2013\u00a0nispio\n    Oct 16 '18 at 21:57\n\nThanks to @lawlist nudging me into the source code, I found out that gdb mode will highlight the line for me, but only on the condition that the window containing the disassembly does not have fringes. The following was enough to make that happen:\n\n;; Enable automatic highlighting of the active line in disassembly window\n(defun nispio/disable-window-fringes () (set-window-fringes nil 0 0))\n(add-hook 'gdb-disassembly-mode-hook #'nispio/disable-window-fringes)\n\nBecause I usually pop the disassembly window out into a separate frame, this is okay. Otherwise, it would disable the fringes on some semi-arbitrary window.\n\n\nThis is the solution I came up with using hl-line. I needed to advise the function that updates the disassembly buffer and invoke hl-line-highlight directly to make it work.\n\n(defadvice gdb-disassembly-handler-custom\n    (after nispio/ad-after-disas-handler-hl-line activate)\n  \"Make sure that `hl-line' gets updated after updating disassembly buffer\"\n  (let* ((buffer (gdb-get-buffer 'gdb-disassembly-buffer))\n         (window (get-buffer-window buffer 0)))\n    (when (and window (featurep 'hl-line))\n      (with-current-buffer buffer\n          (goto-char gdb-disassembly-position)\n         ((and hl-line-mode hl-line-sticky-flag)\n          (goto-char gdb-disassembly-position)\n\n(add-hook 'gdb-disassembly-mode-hook #'hl-line-mode)\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/choosing-whats-integrated.150659/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nChoosing what's integrated\n\n  1. Jan 9, 2007 #1\n    Sorry for the undescriptive title, but I couldn't think of a better one.\n\n    My question is essentially this: is the following procedure correct?\n\n    a=-kx and we want v.\n\n    Multiply both sides by v to get:\n\n    [tex] \\frac {d^2x} {dt^2} * \\frac {dx} {dt} = -kx *\\frac {dx} {dt} [/tex]\n\n    Now, by dt, and some rearranging :\n\n    [tex] (\\frac {d^2x} {dt^2} dt) * \\frac {dx} {dt} = -kx *dx [/tex]\n\n    And the step which I'm not convinced can be done:\n\n    [tex]( \\int \\frac {d^2x} {dt^2} dt) * \\frac {dx} {dt} = -k \\int x *dx [/tex]\n\n    and so we end up with v^2 = -(kx^2)/2 +c which is but an errant 1/2 away from what I need.\n\n    I just don't trust integrating a wrt t, while having a v just sitting there as if it were a constant. The only reason that I haven't already disregarded it is that it checks out if you analyse the dimensions...\n  2. jcsd\n  3. Jan 9, 2007 #2\n\n\n    User Avatar\n    Homework Helper\n\n    No, that's not right. As you mention, you're treating v as a constant, and it isn't.\n\n    You started out right, you just need to rewrite:\n\n\n\n    [tex]\\frac{1}{2} \\frac{d}{dt} \\left( \\left(\\frac{dx}{dt} \\right)^2 \\right)[/tex],\n\n    then integrate.\n  4. Jan 9, 2007 #3\n    Wow, quite the nifty identity. Thanks a lot for that help."}
{"text": "Retrieved from https://mathoverflow.net/questions/156846/closed-form-solution-to-a-system-of-linear-equations\nText:\nConsider the following $n \\times n$ matrix with a particularly nice structure: \\begin{equation}\\mathbf{P}=\\begin{pmatrix} 0 & 0& \\dots&0 & 0 &1\\\\ 0 & 0& \\dots&0 & \\frac{1}{2}&\\frac{1}{2}\\\\ \\vdots& & & & & \\vdots \\\\ 0 &\\frac{1}{n-1}& \\dots&\\frac{1}{n-1}&\\frac{1}{n-1}&\\frac{1}{n-1}\\\\ \\frac{1}{n} &\\frac{1}{n} &\\dots&\\frac{1}{n} &\\frac{1}{n} &\\frac{1}{n} \\end{pmatrix} , \\end{equation} and let \\begin{equation} \\mathbf{\\pi}=(1,2, \\text{ ..., }n). \\end{equation} Is there any hope in fiding closed-form expressions for the elements of the $n$-dimensional vector $\\mathbb{w}$ (not in terms of matrix inverses) that solve the following set of linear equations: \\begin{equation} \\begin{pmatrix} \\mathbf{I}-\\mathbf{P}\\\\ \\mathbf{\\pi} \\end{pmatrix}\\mathbb{w}=\\begin{pmatrix} \\mathbf{a}\\\\ 0 \\end{pmatrix}, \\end{equation} where $a_i=\\frac{1}{i+1}-C$ and $C=\\frac{2(n+1-\\sum_{j=1}^n\\frac{1}{j})}{n(n+1)}$, or is that a hopeless endeavor?\n\n(See also: Eigenvectors of a particular transition matrix)\n\n  \u2022 $\\begingroup$ Is $\\pi$ a diagonal matrix with the said entries? Also $I-P$ is singular, so anyways we cannot write $(I-P)^{-1}$... $\\endgroup$ \u2013\u00a0Suvrit Feb 6 '14 at 15:04\n  \u2022 $\\begingroup$ I guess $\\pi$ is a vector, so it's a pseudo-inverse + a normalization condition on $w$. If I am correct, that system is called Poisson equation for a Markov chain. $\\endgroup$ \u2013\u00a0Federico Poloni Feb 6 '14 at 16:06\n  \u2022 $\\begingroup$ But Federico then it's a syntax error, because how does $\\pi$ operator on the $w$? or maybe it is $\\langle pi, w\\rangle$, so $\\pi$ is a \"row\"-vector. Ok, got it. $\\endgroup$ \u2013\u00a0Suvrit Feb 6 '14 at 17:25\n  \u2022 $\\begingroup$ But this system need not always have a solution...or am I missing something? $\\endgroup$ \u2013\u00a0Suvrit Feb 6 '14 at 17:30\n  \u2022 $\\begingroup$ Well, apparently it should, still unclear why for me, but I'm not very strong in linear algebra. And I already deduced that $C=\\frac{2}{n(n+1)}\\sum_{i=1}^n\\frac{i}{i+1}=\\frac{2(n+1-\\sum_{j=1}^n\\frac{1}{j})}{n(n+1)}$. $\\endgroup$ \u2013\u00a0MthQ Feb 6 '14 at 19:36\n\nYour Answer\n\n\nBrowse other questions tagged or ask your own question."}
{"text": "Retrieved from http://polymathprogrammer.com/2012/11/30/modulo-26-and-column-names/\nText:\nModulo 26 and column names\n\nI was sitting in the lecture theatre valiantly trying to keep awake. The professor was speaking on the rigorous application and proving of the modulus function. It\u2019s basically the remainder, but I\u2019ve never been introduced to it in such, uh, rigor.\n\nHe brought up an example using modulo 26. And demonstrated the wrapping around of values. And the use of it in cryptology (a class I took later on, and I got tasked by the cryptography professor to write a program to do simple encryption. But another story perhaps\u2026).\n\nModulo 26 is similar to finding the remainder. The difference is that the remainder is unique. This is important to our discussion.\n\n\u201cAbout what?\u201d you may ask.\n\nExcel column names.\n\nThere are 2 types of cell references used in spreadsheets, the R1C1 format and the A1 format. The R1C1 is simple. If the row index is 5 and the column index is 7, the result is R5C7.\n\nThe A1 format takes on a column name and the row index. Using our example again, the result is G5, because \u201cG\u201d is the 7th alphabet. Yes, that list of 26 alphabets.\n\nThe version of Excel currently (Excel 2007 and 2010) has up to 3 letters, with XFD as the last column name (that\u2019s the 16384th column). What happens is you have column names A, B, and then up to Z. Then the next column name is AA, then AB and then up AZ. Then BA, BB and so on.\n\nBasically, it\u2019s base 26 arithmetic.\n\nAs far as I know, the typical method of getting the column name given the column index, is to run a loop. You add 1 until it hits 26, then you move to the next \u201cposition\u201d, and then start from 1 again.\n\nThere\u2019s nothing wrong with this method. It\u2019s just that you have to iterate as many times as the given column index. If you\u2019re given 16384, the loop runs 16384 times. This is regardless of the fact that the result is always the same. Given the range of values, the result can only be one of 16384 values.\n\nSo it was with this in mind, and my dabbling in game development (which said \u201cPrecalculate everything!\u201d), that I precalculated an array of strings that are the column names. The array has 16384 items. The context is a spreadsheet software library.\n\nNow to recoup that precalculation cost, I\u2019d have to access my array at least 16384 times. This is where the context of the spreadsheet library comes in. Everybody (and their dog) wants to know if my library can handle millions of cells. This means if the column name calculation is in a method, that method is called millions of times. Given the iteration loop in it, that means the method with the iteration loop thing isn\u2019t efficient (it\u2019s O(n^2)).\n\nHowever, due to technical issues, I can\u2019t keep the array of strings. The column name array needs to be static to be available throughout the library. This causes issues if multi-threads or multi-processors or multi-whatevers comes in.\n\nSo I can\u2019t use my static array anymore. Bummer. The O(n) of simple array access was working so well.\n\nBut I still want to have an efficient way of getting column names. So instead of iterating, I used simple division and modulus operations.\n\nConsider 587. How do you know there\u2019s 5 hundred? 587 / 100 equals 5 (truncating remainders). How do you know there\u2019s 8 tens? 87 / 10 equals 8 (truncating remainders).\n\nYes, it\u2019s elementary arithmetic, but it works great. So we can do the same for column names. There\u2019s a problem though.\n\nIn the case above, we divided by 100. Why 100? Because it\u2019s 10^2, and we\u2019re concerned with the 2nd position after the ones position. The ones position is 10^0 by the way, which is 1.\n\nSo for our case, for the \u201chundreds\u201d position, we divide by 676, which is 26^2. And for the \u201ctens\u201d position, we divide by 26.\n\nNow 587 is 100*5 + 10*8 + 7. I\u2019m going to use the notation (5,8,7) to denote this.\n\nNow consider a column index of 3380. 3380 is equal to 676*5 + 26*0 + 0. This is (5,0,0).\n\nHowever, in our case, our acceptable range of values is 1 through 26. It doesn\u2019t contain zero. So (5,0,0) is not valid.\n\nIn the case of 587, we\u2019re working in base 10, with the acceptable range of values being 0 to 9. This is \u201cproper\u201d remainder. Given any number in base 10, there\u2019s a unique number within [0, 9] that\u2019s the remainder.\n\nHowever, for our purposes, there\u2019s no unique number. Because we\u2019re working in modulo 26, not just \u201cremainder 26\u201d.\n\nThe correct column name corresponding to column index 3380 is \u201cDYZ\u201d. This corresponds to (4,25,26). Or\n3380 = 676*4 +26*25 + 26.\n\nNote that 3380 is also 676*5 + 26*0 + 0.\n\nMy solution is to start from the \u201cones\u201d position. If it\u2019s greater than zero, fine. If it\u2019s less than or equal to zero, borrow from the next larger position. Then we move to the next larger position, and check again. Continue to borrow until there are no zero values (or negatives) on the \u201cright\u201d side of the resulting notation (we can have \u201cleading\u201d zeroes).\n\nSo (5,0,0) becomes (5, -1, 0 + 26), or just (5,-1,26), borrowing 1 from the \u201ctens\u201d position. We cannot have -1, so that becomes (4, -1 + 26, 26), which becomes (4, 25, 26).\n\nAn interesting effect is that we typically assign 0 to A, 1 to B, and 25 to Z. In this case, 1 is assigned to A, 2 is to B, and most interestingly, both 0 and 26 map to Z. In fact, any multiple of 26 will map to Z.\n\nDon\u2019t think Z is special. Any multiple of 26 plus 1 also maps to A. So 1, 27, 53 and so on map to A. This is a property of the modulo thing.\n\nDo you have a better way of converting (5,0,0) to (4,25,26)? Let me know in the comments."}
{"text": "Retrieved from https://mathoverflow.net/questions/311084/additive-discrepancy-under-a-multiplicative-constraint\nText:\nConsider four sequences of numbers, $0 \\le a_i, b_i, c_i, d_i \\le 1$, suppose they satisfy the following constraints:\n\n(1). $\\sum_{i=1}^K a_i, \\sum_{i=1}^K b_i, \\sum_{i=1}^K c_i \\ge 1/2 + \\epsilon$;\n\n(2). $\\sum_{i=1}^K d_i \\le 1/2 - \\epsilon$;\n\n(3). $a_i d_i = b_i c_i$ for all $i=1, \\ldots, K$.\n\nIs it true that \\begin{equation} \\sum_{i=1}^K (|a_i - b_i| + |a_i - c_i|) = \\Omega(\\epsilon) ? \\end{equation}\n\nThe following example shows that the absolute value and the sum is necessary: \\begin{align*} a_1 = 1/2 + \\epsilon, \\quad &a_2 = \\epsilon^2, \\\\ b_1 = 1/2 + \\epsilon + \\epsilon^2, \\quad &b_2 = 0, \\\\ c_1 = 0, \\quad &c_2 = 1/2 + \\epsilon + \\epsilon^2, \\\\ d_1 = 0, \\quad &d_2 = 0. \\end{align*}\n\nNote that the following case is easy: if we have an explicit lower bound $b_i \\ge c > 0$ for all $i$, then let $j$ be the index that maximizes $c_i/d_i$, then \\begin{equation} a_j / b_j = c_j/d_j \\ge (\\sum_i c_i)/(\\sum_i d_i) \\ge 1 + \\epsilon. \\end{equation} Hence \\begin{equation} a_i - b_i \\ge c\\epsilon. \\end{equation} Similarly if we have a lower bound for $c_i$. Note that in these cases we don't even need the assumption that $\\sum_i a_i \\ge 1/2 + \\epsilon$.\n\n  \u2022 $\\begingroup$ There is no $d_i$ in that sum: did you mean that, or is it a mistake? Also, are the various conditions understood to hold for all $K \\in \\mathbb N$ (and the sequences to be infinite), or is $K$ fixed? $\\endgroup$ \u2013\u00a0Alex M. Sep 21 '18 at 15:47\n  \u2022 $\\begingroup$ Even though this problem has a pretty simple solution, I think it is nontrivial and somewhat intriguing. So, I don't understand the down vote. $\\endgroup$ \u2013\u00a0Iosif Pinelis Sep 21 '18 at 17:38\n\n\nIt is not hard to show (see the proof at the end of this answer) that for any real $a,b,c,d\\ge0$ such that $ad=bc$ we have \\begin{equation}\\tag{1} |a-b|+|a-c|\\ge a-d. \\end{equation} Replacing here $a,b,c,d$ by $a_i,b_i,c_i,d_i$ and summing in $i$, we have \\begin{equation} \\sum_i (|a_i - b_i| + |a_i - c_i|)\\ge\\sum_i a_i-\\sum_i d_i\\ge2\\ep, \\end{equation} as desired. (The conditions that $\\sum_i b_i, \\sum_i c_i \\ge 1/2 + \\ep$ were not needed or used here.)\n\nProof of (1). If $a=0$, then $a-d\\le0$, so that (1) holds. So, without loss of generality (wlog), $a>0$, whence $d=bc/a$ and $a-d=(a^2-bc)/a$. So, wlog $a^2>bc$ and hence $a\\ge b\\wedge c$. Also, wlog $c\\le b$. So, one of the following two cases takes place.\n\nCase 1: $0\\le c\\le b\\le a$. Here (1) can be rewritten as $$f(a,b,c):=a-b-c+bc/a\\ge0,$$ which follows because $f(a,b,c)$ is nonincreasing in $b$ (given that $c/a\\le1$) and hence $f(a,b,c)\\ge f(a,a,c)=0$. So, (1) holds in Case 1.\n\nCase 2: $0\\le c\\le a\\le b$. Here (1) can be rewritten as $$g(a,b,c):=b-c+bc/a-a\\ge0,$$ which follows because $g(a,b,c)$ is nondecreasing in $b$ and hence $g(a,b,c)\\ge g(a,a,c)=0$. So, (1) holds in Case 2 as well.\n\nInequality (1) is completely proved.\n\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/314063/conservation-of-angular-momentum-exercise?noredirect=1\nText:\nA disk of radius $R$ and moment of inertia $I_1$ rotates with angular velocity $\\omega_0$. The axis of a second disk, of radius $r$ and moment of inertia $I_2$ is at rest. The axes of the two disks are parallel. The disks are moved together so that they touch. After some initial slipping the two disks rotate together. Find the final rate of rotation of the smaller disk.\n\n\n\n$L_{1_0} = L_1 + L_2 \\rightarrow I_1\\omega_0 = I_1\\omega_1 + I_2\\omega_2$\n\n$\\omega = \\frac{v}{r} \\rightarrow v = \\omega r$\n\n$\\omega_1 R = \\omega_2 r \\rightarrow \\omega_1 = \\frac{r}{R}\\omega_2$\n\n$I_1\\omega_0 = I_1\\frac{r}{R}\\omega_2 + I_2\\omega_2 \\rightarrow \\omega_2 = \\frac{I_1\\omega_0}{\\frac{r}{R}I_1 + I_2}$\n\n$$\\omega_2 = \\frac{I_1\\omega_0}{\\frac{r}{R}I_1 + I_2}$$\n\n\nIs my solution correct? If not, where and why?\n\n  \u2022 $\\begingroup$ Angular momentum cannot be conserved as is assumed in your solution. The system starts with the clockwise angular momentum of disc 1. After contact with disc 1, disc 2 has to have an anti-clockwise angular momentum. To conserve angular momentum disc 1 would need to rotate faster in the clockwise direction which is impossible as then the kinetic energy of the system of two discs would increase with no input of energy. $\\endgroup$ \u2013\u00a0Farcher Feb 23 '17 at 8:14\n\nFront view of two disks\n\nLooking at the system above, you can write for the left disk $$I_2 \\dot{\\omega_2}=Fr$$ and for the second one $$I_1 \\dot{\\omega_1}=FR$$ where $F$ is the (unknown) friction force. Getting $F$ from the second equation $$F=\\frac{I_1}{R} \\dot{\\omega}_1$$and putting in the first we get $$\\frac{I_2}{r} \\dot{\\omega}_2-\\frac{I_1}{R}\\dot{\\omega}_1=0$$ This means that tha quantity $$\\frac{I_2}{r} \\omega_2-\\frac{I_1}{R}\\omega_1$$ is conserved. Setting it equal to the initial value we obtain $$\\frac{I_2}{r} \\omega_2-\\frac{I_1}{R}\\omega_1=-\\frac{I_1}{R}\\omega_0$$\n\nIn the final situation there is no slipping, so $\\omega_2 r=-\\omega_1 R$ and substituting $\\omega_1$ in the previous equation we get $$\\frac{R I_2}{r} \\omega_2+\\frac{r I_1}{R}\\omega_2=-I_1\\omega_0$$ which gives the final solution $$\\omega_2=-\\frac{I_1 r R }{R^2 I_2+r^2 I_1}\\omega_0$$ The angular momentum of the system is not conserved because there are external forces applied on the axes of the disks, and they apply a torque on the system.\n\n  \u2022 $\\begingroup$ In think this derivation using the friction force between the wheels and assuming that the axes of the disks are fixed and don't start to rotate around each other is correct. When the whole experiment is done in free space with a device for the pivots of the axes of known (or negligible) moment of inertia the conservation of angular momentum can probably still be used leading to an additional rotation of the axes of the disks around each other. $\\endgroup$ \u2013\u00a0freecharly Feb 23 '17 at 5:00\n  \u2022 1\n    $\\begingroup$ How is the angular momentum not conserved .....The disks was rotating and it sets the other in rotation. A angular momentum should be conserved about the center of mass. $\\endgroup$ \u2013\u00a0Shashaank Feb 23 '17 at 12:08\n  \u2022 $\\begingroup$ This is not an isolated system, there are external torques acting on it. $\\endgroup$ \u2013\u00a0GCLL Feb 23 '17 at 16:48\n  \u2022 $\\begingroup$ @Shashaank There are forces acting on the axles equal in magnitude to the frictional forces. $\\endgroup$ \u2013\u00a0Farcher Feb 23 '17 at 22:45\n  \u2022 $\\begingroup$ @GCLL Sorry , I couldn't understand . Could you tell which force in particular is giving the torque $\\endgroup$ \u2013\u00a0Shashaank Feb 24 '17 at 5:31\n\nThe solution is not correct because the angular velocities must have opposite signs after contact. Thus $$\\omega_1 = -\\frac{r}{R}\\omega_2$$ which yields the correct angular velocity of the smaller disk $$\\omega_2 = \\frac{I_1\\omega_0}{I_2-\\frac{r}{R}I_1}$$\n\n  \u2022 $\\begingroup$ Good point. I totally missed that. However, could there be more errors? The answer in the book is $\\omega_2 = \\frac{rRI_1}{r^2I_1+R^2I_2}$ (the book's answer could be wrong; it's had mistakes before). $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:30\n  \u2022 $\\begingroup$ @Sir Jony - There seems to be a problem with the use of conservation of angular momentum. When you assume equal disks, there can be no solution because then both disks rotate in opposite sense which always should result in total angular momentum zero. The formula in you comment is dimensionally incorrect, probably a factor $\\omega_0$ is missing. $\\endgroup$ \u2013\u00a0freecharly Feb 22 '17 at 20:46\n  \u2022 $\\begingroup$ Right, I forgot to multiply the RHS by $\\omega_0$. Thanks for catching that. $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:55\n  \u2022 $\\begingroup$ @Sir Jony - In order to get the correct answer you have probably to consider that the contact of the disks in the described manner will also produce a rotation of the disk axes around each other. Otherwise the paradox mentioned above likely cannot be resolved. $\\endgroup$ \u2013\u00a0freecharly Feb 22 '17 at 20:58\n  \u2022 $\\begingroup$ I assume that the axes simply represent pivot points. Other than that, I think they're meant to be ignored. $\\endgroup$ \u2013\u00a0Fine Man Feb 22 '17 at 20:59"}
{"text": "Retrieved from https://electronics.stackexchange.com/questions/258765/how-to-determine-if-a-signal-path-needs-to-be-treated-as-a-transmission-line\nText:\nI remember reading this somewhere but cannot find the ratio of the rise time vs. the propagation time (i.e. the trace length?) of a signal when transmission line effects come into effect?\n\nFor example - if I have a SPI bus running at 12.5MHz. If it runs a few inches through the PCB trace, it is not a transmission line - but at what length goes it become a transmission line (at least in theory). How to calculate that?\n\n  \u2022 \\$\\begingroup\\$ It is somewhat arbitrary and may depend on what you are trying to accomplish. \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 2:50\n  \u2022 \\$\\begingroup\\$ I am trying to determine what reflections I might get. I have a SPI master and I want to run it at 12.5MHz over about 5\" of FR4 PCB trace and about 6 feet of 26awg wire. I dont know if that is even possible and how to do it. \\$\\endgroup\\$ \u2013\u00a0user1406716 Sep 20 '16 at 2:52\n  \u2022 \\$\\begingroup\\$ It will probably work. Use a dedicated GND wire for each signal wire and twist the signal with the GND. Add a series resistor on the source board (start with 0 Ohms, and change it if needed) and an AC termination on the receive board. AC termination is a cap and resistor in series. For MOSI, add the series resistor on the master, and AC termination on the slave. For MISO add series resistor on the slave board, and AC termination on the master. Don't install any AC termination to start. You might not need it. Clock is same as MOSI. \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 2:59\n  \u2022 \\$\\begingroup\\$ pericom.com/assets/App-Note-Files/AB023.pdf \\$\\endgroup\\$ \u2013\u00a0mkeith Sep 20 '16 at 3:00\n  \u2022 \\$\\begingroup\\$ In theory, it is a transmission line at any length. Termination always works, but sometimes you can leave it out and ignore the resulting overshoot/ringing. \\$\\endgroup\\$ \u2013\u00a0Whit3rd Sep 20 '16 at 4:37\n\nThe boundary between lumped and distributed systems is not clear-cut but there are some commonly used values. For distributed systems transmission line theory is required.\n\nThe distinction is usually made based on the effective length of a signal or the feature of a signal like an edge. So it's important to consider the rise- and fall time of a signal and not the frequency. Nevertheless the frequency imposes an upper limit on the risetime.\n\nIn air a signal travels with about 85ps/in (~ 33ps/cm). The propagation delay depends on the dielectric constant, it is proportional to the square root of it. For a PCB with a dielectric constant of 4 (like FR4 which is in the range of 3 to 5) the propagation delay doubles.\n\nA rising edge with a risetime of 1ns would occupy a trace length of 1ns/(2*85ps) ~ 6in (~ 15cm). At the driving side the signal is already high when at a 6in distance it just starts to rise.\n\nSo a 6in (15cm) track clearly is too long, since the potential varies from low to high along the track.\n\nIf the length of the track is between 1/6 or 1/4 of the effective length of a feature like an edge a system can be regarded as lumped.\n\nSo the upper limit for the example given above is between 6in / 6 (= 1 in, ~2.5cm) and 6in /4 (= 1.5in, ~4cm) for a trace on a PCB with a dielectric constant of 4.\n\n\nFor analog signals (sine waves, let's say), the rule of thumb I was taught is when the line length is 1/8 of the wavelength, you should treat it as a transmission line. Practically speaking, the propagation speed of an electromagnetic wave is determined by the dielectric the wave is traveling in. For PCB's it is typically around C/2, where C is the speed of light in space. Your wavelength will be shorter by the same scale factor (wavelength in free space / 2). So a 100 MHz signal would be 3 meters in free space. 1.5 meters in a PCB. And 1/8 of that is 18.75 cm.\n\nFor digital signals, there are several alternative ways to look at it. One way is rise time and bandwidth. The basic idea is, you use the rise time to estimate the bandwidth, then use the analog signal rule above, but with the bandwidth as the frequency. The justification for this is that the wave can be somewhat accurately reproduced provided that you have the majority of the BW. So the highest significant frequency in the signal is given by the BW.\n\nThe rule of thumb I have seen is that BW = 0.35/TR. BW is bandwidth in GHz, and TR is rise-time in nanoseconds. This formula uses the 10/90 rise time. So if your rise time is 10 ns, then your BW is 0.35/10 = 0.035 GHz = 35 MHz.\n\nAnother way to look at it is that you want the round trip flight time of your signal to be substantially less than your rise time. This means that the reflections will return to the source while the signal is still rising or falling. Reflections like this will not cause the rising and falling edges to be jagged or have \"shelves\" on them. They will still be smooth.\n\nHope this helps.\n\n  \u2022 \\$\\begingroup\\$ Thank you. This is the kind of 'rule of thumb' i was looking for. \\$\\endgroup\\$ \u2013\u00a0user1406716 Sep 22 '16 at 4:29\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/35571/3-2-approximation-probabilistic-algorithm-for-max-3-color\nText:\nI have a textbook question here regarding Max-3-Coloring and need some assistance with it. I have searched for any type of information regarding it but haven't found anything substantial. Here is the question:\n\nIn MAX-3-COLOR you are given a graph $G=(V,E)$ and your goal is to find a coloring of the vertices with only 3 colors $c: V \\rightarrow [3]$ that maximizes the quality function $q(c)$ - The number of edges whose endpoint vertices are colored with different colors:\n\n$\\sum_{(i,j)\\in E} (1_{c(i) \\neq c(j)})$\n\nGive a probabilistic $3/2$-approximation algorithm. (i.e $q(c)\\geq 2/3 \\cdot OPT$ with probability at least $1-\\frac{1}{e^{k}}$ for any $k \\in \\mathbb{N}$\n\nOK so up until now the textbook only talks about one probabilistic algorithm which fits the requirements - MAX-3-SAT. The textbook gives a probabilistic $8/7$ - approximation algorithm for it (for every literal, toss a fair coin and decide whether to set it to $True$ or $False$).\n\nI also found several other sources which prove that the 3-COLOR is NP-Complete by reducing it to the 3-SAT problem. Thus I am pretty confident that MAX-3-SAT is the way to go.\n\nAccording to this thread: 3 Colorability reduction to SAT I thought about doing the same thing:\n\nFor every $x \\in V$ create three literals: $x_1, x_2, x_3 \\in \\{{True, False}\\}$ where each literal denotes if said vertex $x$ is colored with color $i$.\n\nThen for every edge $e =(x,y)\\in E$ create the following 3-CNF formula $\\varphi$:\n\n$ \\varphi_e = (\\urcorner x_1 \\vee \\urcorner y_1 \\vee \\urcorner y_1) \\wedge (\\urcorner x_2 \\vee \\urcorner y_2 \\vee \\urcorner y_2) \\wedge (\\urcorner x_3 \\vee \\urcorner y_3 \\vee \\urcorner y_3) \\wedge (x_1 \\vee x_2 \\vee x_3)$\n\nAnd the final formula $\\phi$ is:\n\n$\\phi = \\bigwedge_{e \\in E} \\varphi_e$\n\nEvery 3-CNF formula for an edge makes sure that the two endpoints are not of the same color and that one of them is either color 1, 2 or 3.\n\nThe thing is I don't see how this would help me. This gives me a MAX-3-SAT problem since I have a 3-CNF formula for every edge and one big 3-CNF formula for the whole graph. So technically I could use the same algorithm that was given in the textbook before\n\nBut wouldn't using the same probabilistic probabilistic $8/7$ - approximation algorithm for the MAX-3-SAT give the exact same approximation? whereas I wish to achieve a $3/2$- approximation\n\nThanks to anyone who helps!\n\n\nIf you simply uniformly at random (i.i.d) color each of the vertices of $V$ by each of the three possible colors, then for every edge $e\\in E$, it's endpoint will be colored by different colors w.p. $\\frac{2}{3}$, hence the expected quality of the random coloring is exactly $\\frac{2|E|}{3}$. We know that the optimal quality is at most $q^*\\leq |E|$, hence this is a $\\frac{3}{2}$ approximation.\n\n  \u2022 $\\begingroup$ This is a $3/2$-approximation in expectation. To get the high probability result required by the original question, you need to run this algorithm several times and return the best of the resulting colorings. $\\endgroup$ \u2013\u00a0JeffE May 28 '17 at 20:36\n\nConsider the greedy algorithm that loops through the vertices in arbitrary order and assigns each vertex $v$ the least popular color among its previously-colored neighbors. Each vertex $v$ gets a different color than at least $2/3$ of its neighbors, so the quality of the greedy coloring is at least $2|E|/3$. The optimal quality is trivially at most $|E|$, so the greedy coloring is always a $3/2$-approximation. (In particular, the greedy coloring is a $3/2$-approximation with probability at least $1-e^{-k}$ for any integer $k\\in \\mathbb{N}$.)\n\n(You might object that this is not a probabilistic algorithm. Okay, whatever. In a preprocessing phase, generate a random permutation of the colors, and use this permutation to break ties in the greedy algorithm. Alternatively, flip 42 independent fair coins, and if they all come up heads, do ten jumping jacks and a lap around the football field before running the greedy algorithm.)\n\n  \u2022 $\\begingroup$ This is just the derandomization of the algorithm in the other answer, using the method of conditional expectations. $\\endgroup$ \u2013\u00a0Yuval Filmus May 28 '17 at 21:32\n  \u2022 $\\begingroup$ @YuvalFilmus In retrospect, sure. But that's not the easiest way to think about it. $\\endgroup$ \u2013\u00a0JeffE May 28 '17 at 21:35\n\nYour Answer"}
{"text": "Retrieved from https://gamestoday.info/pc/heroes-of-the-storm/can-someone-help-me-with-a-bit-of-ability-damage-math/\nText:\nHeroes of the Storm\n\nCan someone help me with a bit of ability damage math?\n\nHeroesoftheStorm 7 - Can someone help me with a bit of ability damage math?\n\nRight now, I'm working on a big spreadsheet involving damage values and scaling and I want to make sure I'm correctly applying modifiers and scaling (and not screwing up the rounding). The issue I'm running into is with Hanzo's Target Practice and Flawless Technique talents. Storm Bow's level 0 damage is 291, its scaling is the standard 1.04, Target Practice's quest completion provides 100 bonus damage (non-scaling), and Flawless Technique grants a modifier of .3 to Storm Bow. Here's some of the XML pertaining to this:\n\n <CEffectDamage id=\"HanzoStormBowDamage\" parent=\"StormSpell\"> <Amount value=\"291\" /> <MultiplicativeModifierArray index=\"FlawlessTechniqueTalentDamageBonus\" Validator=\"HanzoFlawlessTechniqueIsEmpoweredStormBowMissile\" Modifier=\"0.3\" Crit=\"1\" /> <FlatModifierArray index=\"TargetPracticeTalentFlatDamage\" Validator=\"HanzoTargetPracticeCasterHasDamageIncreaseBehavior\" Modifier=\"100\" /> <SourceButtonFace value=\"HanzoStormBow\" /> </CEffectDamage> \n\nFuther down is the scaling\u2026\n\n <LevelScalingArray Ability=\"HanzoStormBowFireTargetPoint\"> <Modifications> <Catalog value=\"Effect\" /> <Entry value=\"HanzoStormBowDamage\" /> <Field value=\"Amount\" /> <Value value=\"0.040000\" /> <AffectedByAbilityPower value=\"1\" /> <AffectedByOverdrive value=\"1\" /> </Modifications> \n\nI'm trying to calculate the value of a level 20 Storm Bow with both of these bonuses (and no spell power or armor shred from other talents). If we scale the base 291 up to level 20, we get the following:\n\n\n291 * 1.04^20 = 637.616834623\n\nNow we add the Target Practice Bonus:\n\n637.616834623 + 100 = 737.616834623\n\nAnd finally our .3 multiplier from Flawless Technique:\n\n737.616834623 * 1.3 = 958.90188501\n\nSo I end up at a value of ~958.9, which I assume the UI would normally round up to 959. However! When I take these talents, go into Try Mode, set the level to 20, and do this in practice, I get a crit hit of 960 on a Target Dummy. While this seems to confirm that my math was pretty close, it wasn't exact. I'm not sure where this extra bit of damage is coming from and I want to make sure this isn't because I'm missing something in my calculations. At the very least, I think I'm misunderstanding something about the way HotS does rounding.\n\nIt's not a big deal for me to be off by one on this spell, but I have a formula going down an entire column in Google Sheets and I don't want to mess up 500 calculations by a tiny bit.\n\nRead:\u00a0 (Inven) [Interview] Farewell from the best HotS Esports player: Jaewon 'Rich' Lee\n\nAny help is appreciated!\n\nEdit: One clue is that the UI seems to be giving me 638.1 for a level 20 Storm Bow cast on a Target Dummy with no talents. Starting from 638.1, you get:\n\n(638.1 + 100) * 1.3 = 959.53\n\nThis value rounds up to 960 quite nicely and makes perfect sense to me. But it begs the question: why is an untalented level 20 Storm Bow dealing ~638.1 damage?\n\nSource: Original link\n\n\u00a9 Post \"Can someone help me with a bit of ability damage math?\" for game Heroes of the Storm.\n\nTop 10 Most Anticipated Video Games of 2020\n\n\nTop 15 NEW Games of 2020 [FIRST HALF]\n\n\nYou Might Also Like\n\nLeave a Reply"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/436201/optical-theorem-in-qft\nText:\nI've been working with the Optical theorem in the case in which final and initial states are equals and I have the following doubt. Let's write the scattering matrix $S$ as:\n\n$$S = 1 + i\u00b7T \\tag1$$\n\nwhere $T$ is the transition matrix. Therefore, the Optical theorem is:\n\n$$2\u00b7Im(T) = T^\\dagger T \\implies 2\u00b7Im(T_{ii}) = \\sum_a|T_{ai}|^2 \\tag2$$\n\nIn Eq. (2), we have imposed the particular case commented above with $a$ any state in between. So my doubt arises from here: if, for Eq. (1), $$<i|S|i> = 1 + i<i|T|i> \\implies S_{ii} = 1 + iT_{ii},\\tag3$$ then for that particular case, when I computed the $T_{ii}$ and took $$|S_{ii}|^2 = probability\\ of\\ the\\ process\\ i \\rightarrow i,\\tag4$$ I will get a probability greater than 1. But that isn't possible.\n\nWhat am I misunderstanding?\n\nThanks in advance!\n\n  \u2022 1\n    $\\begingroup$ What happened to the crossterm $-2{\\rm Im} T_{ii}$ in eq. (4)? $\\endgroup$ \u2013\u00a0Qmechanic Oct 22 '18 at 20:00\n\nYou might be assuming the matrix element $T_{ii}$ to be real. If so, then\n\n$$ \\lvert S_{ii} \\rvert^2 = 1 + \\lvert T_{ii} \\rvert^2 > 1 $$\n\nWithout such an assumption, $$ \\begin{align*} \\lvert S_{ii} \\rvert^2 &= 1 + \\lvert T_{ii} \\rvert^2 - 2\\mathrm{Im}(T_{ii})\\\\ &= 1 + \\lvert T_{ii} \\rvert^2 - \\sum_a \\lvert T_{ai} \\rvert^2 \\\\ &= 1 - \\sum_{a \\neq i} \\lvert T_{ai} \\rvert^2 \\end{align*} $$\n\nwhich is smaller than $1$.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/661801/infinite-matrix-leading-eigenvalue-problem\nText:\nI'm trying to find the leading eigenvalue and corresponding left and right eigenvectors of the following infinite matrix, for $\\lambda>0$:\n\n$$ \\mathrm{A}=\\left( \\begin{array}{cccccc} 1 &e^{-\\lambda} & 0 &0 &0 & \\dots\\\\ 1 &e^{-\\lambda} & e^{-2\\lambda} &0 &0 & \\dots\\\\ 1 &e^{-\\lambda} & e^{-2\\lambda} &e^{-3\\lambda} &0 & \\dots\\\\ \\vdots & \\vdots & \\vdots & & \\ddots \\end{array} \\right) $$\n\nNote that there are terms above the main diagonal.\n\nI know that in general infinite matrices aren't really a self-consistent idea, but from doing it numerically with $n\\times n$ matrices using power iteration it looks like the problem converges in the limit of infinite $n$. The convergence is slower for smaller values of $\\lambda$, but it looks like it probably converges for all $\\lambda>0$.\n\nNote that I only care about the leading eigenvalue, i.e. the one with the largest magnitude, which should be real and positive. Its corresponding eigenvectors should have only positive entries, due to the Perron-Frobenius theorem.\n\nAlternatively, if it's easier, a solution for the following matrix will be just as useful to me: $$ \\mathrm{B}=\\left( \\begin{array}{cccccc} 1 & 1& 0 &0 &0 & \\dots\\\\ e^{-\\lambda} &e^{-\\lambda} & e^{-\\lambda} &0 &0 & \\dots\\\\ e^{-2\\lambda} & e^{-2\\lambda} &e^{-2\\lambda} &e^{-2\\lambda} &0 & \\dots\\\\ \\vdots & \\vdots & \\vdots & & \\ddots \\end{array} \\right) $$\n\nAgain note the terms above the diagonal. (The two problems are not equivalent, it's just that either one of them will help me solve a larger problem.)\n\nThe problem is, I just don't have much of an idea how to do this. I've tried a variety of naive methods, along the lines of writing the eigenvalue equation $\\mathrm{A}\\mathbf{x} = \\eta \\mathbf{x}$ as a system of equations involving infinite sums and then trying to find $\\{x_i >0\\}$ and $\\eta>0$ to satisfy them, but this doesn't seem to lead anywhere nice.\n\nIt could be that there is no analytical solution. Or even worse it could be that these matrices have unbounded spectra after all (in which case I'd really like to know!), but if anyone has any insight into how to solve one of these two problems I'd really appreciate it.\n\n  \u2022 $\\begingroup$ Does this come about from discretizing some continuous operator? I ask because that might give some insight or inspiration for how to approach this problem, or solve it by analogy to the continuous problem. $\\endgroup$ \u2013\u00a0rajb245 Feb 10 '14 at 19:00\n  \u2022 $\\begingroup$ @rajb245 no it doesn't unfortunately. (It comes from maximising the entropy of a discrete probability distribution subject to a complex series of constraints - the full explanation is a paper's worth.) $\\endgroup$ \u2013\u00a0Nathaniel Feb 11 '14 at 0:38\n  \u2022 $\\begingroup$ I have a gut feeling that this does have a good closed form answer anyway. I have done some numerical investigations myself and agree that the dominant eigenvalue converges. I made some progress on a solution...I might post what I've got tomorrow if I can get it better shape. $\\endgroup$ \u2013\u00a0rajb245 Feb 11 '14 at 2:40\n  \u2022 $\\begingroup$ @rajb245 that's great! I look forward to it. $\\endgroup$ \u2013\u00a0Nathaniel Feb 11 '14 at 2:44\n  \u2022 $\\begingroup$ In which sequence space are you considering this operator, by the way? It may be a difference if the eigenvectors are bounded, convergent, or square-summable, for example. $\\endgroup$ \u2013\u00a0Roland Feb 11 '14 at 2:55\n\n(No promises here, because I haven't worked the algebra all the way through, but...)\n\nTry writing the matrix equation $A\\mathbf{x}= \\mu \\mathbf{x}$, and then looking at the individual equations it gives;\n\n$$ x_1 + e^{-\\lambda}x_2 = \\mu x_1 \\\\ x_1 + e^{-\\lambda}x_2 + e^{-2 \\lambda}x_3 = \\mu x_2 \\\\x_1 + e^{-\\lambda}x_2 + e^{-2 \\lambda}x_3 + e^{-3 \\lambda}x_4 = \\mu x_3 $$ etcetera.\n\nNotice that you can substitute previous equations in to each one to get that for each $i \\geq 1$, $$\\mu x_i + e^{-(i+1)\\lambda}x_{i+2} = \\mu x_{i+1} \\\\ \\Rightarrow \\mu (x_{i+1} - x_i) = e^{-(i+1)\\lambda}x_{i+2} $$\n\nYou can then solve the recurrence relation similarly to a differential equation, by finding two distinct (neither a constant multiple of the other) solutions, which gives the general solution of any linear combination of these.\n\nThen substitute the general solution into the first equation and see if you can make it consistent with that.\n\nFinding the general solution to the recurrence could still be difficult though - the $e^{-(i+1)\\lambda}$ means that the $x_i = k^i$ trick will fail to work. I'm not actually sure if there is a solution of a different form, or if actually you can show that there is no solution - in which case, it would follow that $A$ did not have eigenvalues.\n\nSorry if this is what you've tried, but you mentioned infinite sums, and this at least doesn't involve them.\n\n  \u2022 $\\begingroup$ This is pretty much what I'd tried. The problem is that solving the recurrence relation gets pretty gnarly pretty quickly. The infinite sums appear when trying to do the same thing for the left eigenvector - I tried that when I couldn't get this to work. $\\endgroup$ \u2013\u00a0Nathaniel Feb 12 '14 at 7:40\n  \u2022 $\\begingroup$ Aaah, I meant to award you the bounty for your effort, but I was really busy today and it timed out. I'm very sorry about that, maybe another time. $\\endgroup$ \u2013\u00a0Nathaniel Feb 13 '14 at 11:58\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3001136/0-sqrt-a-sqrt3b-epsilon-for-a-b-in-bbb-z\nText:\nI'm trying to solve the following problem:\n\nGiven $\\epsilon>0$, are there positive integers $a,b$ such that $0<|\\sqrt a-\\sqrt[3]b|<\\epsilon$ ?\n\nMy solution: given $n\\in\\Bbb N$, $$|\\sqrt{n^2}-\\sqrt[3]{n^3+1}|=\\sqrt[3]{n^3+1}-n=\\frac1{\\sqrt[3]{(n^3+1)^2}+n\\sqrt[3]{n^3+1}+n^2}<\\frac1{3n}\\to 0$$ Thus, the answer is yes.\n\nBut I was trying to find an \"optimal\" solution. That is, now the problem becomes\n\nGiven $\\epsilon>0$, find the least $b\\in \\Bbb Z_+$ such that there exists $a\\in\\Bbb Z_+$ such that $0<|\\sqrt a-\\sqrt[3]b|<\\epsilon$\n\nand now I'm totally lost. Is there some theory about this? Perhaps has it to do with the diophantine equation $a^3-b^2=\\pm1$, and hence, to Catalan's conjecture?\n\nRemark: Please note the '$0<$' in the inequality. I'm aware that $\\sqrt 1=\\sqrt[3]1$.\n\n\nListing some easy observations to get the ball rolling.\n\nMy guess is that the variable $b$ and the error $\\epsilon$ are, asymptotically, related by estimates of the form $$\\epsilon\\approx \\frac C{b^\\alpha},$$ where $C$ and $\\alpha>0$ are positive constants.\n\nThe true relation may be very complicated, but at least we can derive upper and lower bounds of the prescribed form. Your example with $b=n^3+1$, $\\root3\\of b-\\sqrt a\\le 1/(3n^2)$, shows that $$ \\epsilon\\le \\frac{1/3}{b^{2/3}} $$ is possible for infinitely many values of $b$.\n\nOn the other hand, let $\\zeta=(1+i\\sqrt3)/2$ be a primitive sixth root of unity. We have the polynomial factorization $$ x^6-y^6=(x-y)\\prod_{j=1}^5(x-\\zeta^j y).\\qquad(*) $$ Assume that integers $b, a$ are chosen in such a way that $\\root3\\of b-\\sqrt a$ is very small (but non-zero). Plug $x=\\root3\\of b, y=\\sqrt a$ into $(*)$. The left hand side $b^2-a^3$ has absolute value $\\ge1$ because it is an integer. Predalescu/Catalan says that actually it is $\\ge2$ when $b>3$ but that's insignificant, at least for now. Because $x\\approx y$, the other factors on the right hand side of $(*)$ have absolute values $\\approx x, \\sqrt{3}x,2x,\\sqrt3 x,x$ for $j=1,2,3,4,5$ respectively. Their product is thus $\\approx 6x^5$. The factorization $(*)$ thus gives the estimate $$ |\\root3\\of b-\\sqrt a|\\ge\\frac{K}{b^{5/3}} $$ with a constant $K\\approx 1/6$.\n\nI would summarize this by stating that\n\n$$2/3\\le \\alpha\\le 5/3.$$\n\nWaiting for the experts to show up with something more precise.\n\n\nYour Answer"}
{"text": "Retrieved from https://emacs.stackexchange.com/questions/29872/how-many-bytes-are-in-the-region/29877\nText:\nAfter far too many years of counting the number of characters in the region by doing M-: (- (point) (mark)), I just discovered M-= (count-words-region). Much better! But now I'm looking for a way to obtain the number of bytes that the characters in the region occupy in the buffer's coding system--typically, or always really, UTF-8. Is there an easy way to do this?\n\nFor context, I've been doing some code golfing on codegolf.stackexchange.com in a language that supports various Unicode operators, and I need to know how many bytes my submission occupies. So far I've been saving the region to a file, doing ls -l on it, then deleting it. I could easily whip up a function to do this automatically, but it seems rather inelegant.\n\n  \u2022 You could also probably open the file in hexl mode, you could then use the regular Emacs commands to count bytes. \u2013\u00a0wvxvw Jan 8 '17 at 5:56\n  \u2022 I'm typically in a shell buffer when I want to know the byte count, so hexl-mode isn't really practical. A nice thought though. \u2013\u00a0Sean Jan 8 '17 at 20:19\n\nSounds like you are asking for something like this:\n\n(defun region-bytes ()\n  (let ((strg  (if (use-region-p)\n    (message \"Region has %d bytes\" (string-bytes strg))))\n\nYou might also be interested in showing the region size in the mode line. You can do that with library modeline-posn.el -- see Mode Line Position. One of the style choice is to show the number of bytes in the active region -- just what you are asking for here. The difference is that it would always be shown (when the region is active), instead of being reported as a message only on demand (as per the command above).\n\n\nWhile Drew's answer will work correctly in many cases (where utf-8 is pervasive and if you don't use DOS-style EOLs), if you want to make it work reliably for \"all\" buffers, you could do something like the following:\n\n(defun region-bytes (start end)\n  \"Return the number of bytes used by the region.\"\n  (interactive \"r\")\n  (message \"Region has %d bytes\"\n           (- (bufferpos-to-filepos end 'exact)\n              (bufferpos-to-filepos start 'exact))))\n\nand for cases where efficiency is more important than precision, you could pass approximate instead of exact, in which case bufferpos-to-filepos will always be very fast tho it will not handle correctly cases like GBK or utf-2022 encodings.\n\n  \u2022 +1. Good to know about bufferpos-to-file-pos. It is apparently available only in Emacs 25 and later. And it apparently presumes that the buffer is associated with a file (?). You speak of \"all\" buffers, but I imagine the quotes mean (at least) that it is limited to file buffers. \u2013\u00a0Drew Jan 27 '17 at 3:17\n  \u2022 The notion of \"bytes\" here only makes sense with respect to some encoding. bufferpos-to-file-pos uses the encoding specified by buffer-file-coding-system, but other than that it should also work in a non-file buffer (e.g. if you let-bind buffer-file-coding-system around the call). \u2013\u00a0Stefan Jan 27 '17 at 3:29\n  \u2022 I see; thanks. I did not bother to look at the code - looked at only the doc. The doc mentions only \"the file\". It might be more useful if what you say in your comment, or similar, were added. \u2013\u00a0Drew Jan 27 '17 at 3:31\n  \u2022 I see also that the doc says that bufferpos-to-file-pos with type exact \"may end up re-(en/de)coding a large part of the file/buffer\", which might not be desirable in some contexts, for performance reasons. That text seems misleading, BTW, since it suggests that the buffer can be modified, with some of its text changing coding system. If I read the code right, when b-t-f-p re-(en/de)codes the text it puts the result in a different, temporary buffer, and returns the size - the original text does not have its encoding changed. \u2013\u00a0Drew Feb 5 '17 at 17:07\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1736959/filled-suit-vs-triple-quads-which-is-more-likely-to-happen-first-on-average/1738504\nText:\nSuppose we have a standard well shuffled $52$ card deck and deal cards from it without replacement (for each hand). Which is likely to happen first on average, we deal out an entire suit (all $13$ cards of any one suit) or get $3$ quads?\n\nNone of the cards have to be in any special order, just that they show up. For example, the quads could show up with other \"irrelevant\" cards in between.\n\nNote that both of these are stopping conditions for a trial, whether you first get the full suit or the triple quads.\n\nAlso note that each case could be poised, waiting for $1$ card to \"win\" but a single card drawn could satisfy both conditions simultaneously and thus will be considered a tie or no decision and we would then reshuffle and retry a new hand. For example, if you needed the K of hearts to complete all $13$ hearts but you also have seen $5,5,5,5,3,3,3,3,K,K,K$ so far with no other quads seen yet that hand. The K of hearts would satisfy both conditions simultaneously and thus create a \"tie\" (no decision) situation, prompting a reshuffle and retrial.\n\n  \u2022 $\\begingroup$ What is a \"quad\"? $\\endgroup$ \u2013\u00a0K. Jiang Apr 11 '16 at 3:48\n  \u2022 $\\begingroup$ I gave examples. A quad in this context is $4$ cards all of the same rank such as K,K,K,K. There are $13$ different ranks in a standard $52$ card deck. $\\endgroup$ \u2013\u00a0David Apr 11 '16 at 4:00\n\nAs I said in my other answer, it is feasible to explicitly calculate all the probabilities. We generate all the distributions of cards into ranks, ${13+4\\choose4}=2380$ except the distributions that lack $3$ cards of any rank, ${13+3\\choose3}=560$. Then for each distribution we can compute the probability of having that distribution given a hand of that many cards, $$P_{dist}=\\frac{\\frac{13!}{n_0!n_1!n_2!n_3!n_4!}{4\\choose0}^{n_0}{4\\choose1}^{n_1}{4\\choose2}^{n_2}{4\\choose3}^{n_3}{4\\choose4}^{n_4}}{{52\\choose0\\cdot n_0+1\\cdot n_1+2\\cdot n_2+3\\cdot n_3+4\\cdot n_4}}$$ Where $n_i$ is the number of ranks that have $i$ cards in the distribution. Then we multiply that by the probability of ending a game requiring $n_4+1$ quads on the next card, $$P_{over}=\\frac{n_3}{52-(0\\cdot n_0+1\\cdot n_1+2\\cdot n_2+3\\cdot n_3+4\\cdot n_4)}$$ Now we have to find the probabilities of winning on that next card, drawing, or already having lost. $$\\begin{align}P_{win}&=P(0)\\\\ P_{tie}&=\\frac14P(1)\\\\ P_{lose}&=\\frac34P(1)+P(2)+P(3)+P(4)\\end{align}$$ Where $P(i)$ is the probability of having completed $i$ suits after the next card has been drawn. Then by inclusion-exclusion, we can find that $$\\begin{align}P(0)&=1-4P(\\spadesuit)+6P(\\heartsuit\\spadesuit)-4P(\\diamondsuit\\heartsuit\\spadesuit)+P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(1)&=4P(\\spadesuit)-12P(\\heartsuit\\spadesuit)+12P(\\diamondsuit\\heartsuit\\spadesuit)-4P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(2)&=6P(\\heartsuit\\spadesuit)-12P(\\diamondsuit\\heartsuit\\spadesuit)+6P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(3)&=4P(\\diamondsuit\\heartsuit\\spadesuit)-4P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\\\ P(4)&=P(\\clubsuit\\diamondsuit\\heartsuit\\spadesuit)\\end{align}$$ Where, for example $P(\\heartsuit\\spadesuit)=P_2$ is the probability of having completed both the hearts and spades suits by the time the next card is drawn. Having picked $K$ specific suits, the probability of all of those suits being present in a rank where $N$ cards has been drawn is $$P_{NK}=\\frac{{4-K\\choose N-K}}{{4\\choose N}}$$ Where ${N\\choose k}=0$ if $k<0$. So the probability of success over all ranks is $$P_K=P_{0K}^{n_0}P_{1K}^{n_1}P_{2K}^{n_2}P_{3K}^{n_3-1}P_{4K}^{n_4+1}$$ Where conventionally $0^0=1$. Putting all that stuff together we can write a program (not posted) to calculate the probabilities of winning, losing, or drawing for games requiring all numbers of quads to win.\n\n$$\\begin{array}{r|rrr} \\text{Quads}&\\text{Win}&\\text{Lose}&\\text{Tie}\\\\ \\hline 1&0.998563&0.001078&0.000359\\\\ 2&0.992344&0.005746&0.001910\\\\ 3&0.975825&0.018161&0.006013\\\\ 4&0.941256&0.044220&0.014525\\\\ 5&0.879013&0.091425&0.029562\\\\ 6&0.778897&0.168285&0.052818\\\\ 7&0.633332&0.282725&0.083944\\\\ 8&0.444088&0.438620&0.117292\\\\ 9&0.234020&0.629219&0.136761\\\\ 10&0.060783&0.826763&0.112455\\\\ 11&0.004689&0.972954&0.022357\\\\ 12&0.000048&0.999376&0.000576\\\\ 13&0.000000&1.000000&0.000000\\\\ \\end{array}$$\n\n\nWhile I can't tell you the exact likelihood of either option coming first, I can prove that getting three quads first is far more likely.\n\nConsider that after 42 cards, you are guaranteed to have at least three quads since there are only 10 cards remaining. After 42 cards, the likelihood of having a full suit would be the likelihood that the remaining 10 cards contain 3 suits or fewer. This probability is $${4*{39 \\choose 10}-6*{26 \\choose 10}+{13 \\choose 10}\\over {52 \\choose 10}}=.1587 $$\n\nThis means that at a point when you are certain you have three quads, there is still a more than 84% chance that you do not have a full suit. Hence, the three quads are more likely to come first.\n\n  \u2022 $\\begingroup$ Can anyone run a Monte Carlo simulation to help confirm this? I'd be interested to know things like the percentages of each, % of ties, average number of cards for a winner.... $\\endgroup$ \u2013\u00a0David Apr 11 '16 at 14:28\n  \u2022 $\\begingroup$ @David Thanks for the suggested edit. I changed it to 84%. $\\endgroup$ \u2013\u00a0browngreen Apr 11 '16 at 15:45\n  \u2022 $\\begingroup$ @Browngren, can you redo your calculation to see what happens when checking for $8$ quads instead of only $3$? According to the simulation by user5713492, those outcomes (one full suit vs. $8$ quads) are almost \"even steven\" (equiprobable). Thanks. $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 4:12\n  \u2022 $\\begingroup$ You are guaranteed at least 8 quads after 47 cards. At that point, the likelihood of having a full suit is $${4*{39 \\choose 5}-6*{26 \\choose 5}+{13 \\choose 5}\\over {52 \\choose 5}}=.7348$$ Based on this alone, we see that the probability of 8 quads coming first is at least .2652, but you couldn't conclude which is more likely to come first. $\\endgroup$ \u2013\u00a0browngreen Apr 12 '16 at 16:00\n\nI tried a simulation. Ran a total of $1.0\\times10^{10}$ times. Program was:\n\nprogram shuffle\n   implicit none\n   integer(INT64) deck(52)\n   integer i, j\n! The deal has 4 4-bit counters for suits and 13 2-bit counters\n! for ranks. Like this:\n! xxxx0SSSS0HHHH0DDDD0CCCC0AA0KK0QQ0JJ0TT099088077066055044033022\n! Each card has a bit set for its suit and for its rank.\n! When added to the deal it updates the appropriate suit and rank\n! counters. When a counter overflows, we know that all 4 of a\n! rank or all 13 of a suit have been dealt (the suit counters\n! were initialized to 3 so that 13 more overflowed them.)\n   integer(INT64), parameter :: initial(52) = &\n   integer(INT64), parameter :: suits = &\n   integer(INT64), parameter :: ranks = &\n   integer(INT64), parameter :: first = &\n   integer(INT64) Nsim, k, deal\n   integer(INT64) :: win = 0, tie = 0, lose = 0\n   real harvest(51)\n   integer quads\n   logical won, lost\n\n   Nsim = 1000000000\n   call random_seed()\n   do k = 1, Nsim\n      deck = initial\n      deal = first\n      call random_number(harvest)\n      do i = 1, 51\n         j = harvest(i)*(53-i)\n         if(j /= 0) deck([i,j+i]) = deck([j+i,i])\n      end do\n      do i = 1, 52\n         deal = deal+deck(i)\n         won = popcnt(iand(deal,ranks)) >= 3\n         lost = iand(deal,suits) /= 0\n         if(won .OR. lost) exit\n      end do\n      if(won) then\n         if(lost) then\n            tie = tie+1\n            win = win+1\n         end if\n         lose = lose+1\n      end if\n   end do\n   write(*,'(a,i12,1x,f12.8)') ' win = ', win, win*1.0d2/Nsim\n   write(*,'(a,i12,1x,f12.8)') 'lose = ', lose, lose*1.0d2/Nsim\n   write(*,'(a,i12,1x,f12.8)') ' tie = ', tie, tie*1.0d2/Nsim\nend program shuffle\n\nResults were as follows: $$\\begin{array}{rrr} \\text{win} & 9758240072 & 97.5824\\% \\\\ \\text{lose} & 181632175 & 1.8163\\% \\\\ \\text{tie} & 60127753 & 0.6013\\% \\end{array}$$ So it can be seen that a loss (all of a suit before 4 quads) was rare, and ties even less frequent.\n\n  \u2022 $\\begingroup$ Just curious. How many quads are needed to make it \"neck and neck\" with filling a full suit? 6? 7?...? Can you mod your program to check when the percentages approach 50% each please? $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 2:19\n  \u2022 1\n    $\\begingroup$ When I cranked it up to 8 quads, it was 44.39% win, 43.87% lose, 11.74% tie. $\\endgroup$ \u2013\u00a0user5713492 Apr 12 '16 at 2:51\n  \u2022 $\\begingroup$ Wow that tie seems very high maybe someone else should also do a Monte Carlo simulation to check. How can it be that just as you get the $8$th quad you are also finishing the first complete suit on that same exact card about $1$ out of $9$ trials? What is the average number of cards of the win, loss, and tie \"buckets\"? $8$ quads is at least $32$ cards and likely more. $\\endgroup$ \u2013\u00a0David Apr 12 '16 at 3:52\n  \u2022 $\\begingroup$ If you think about it, the 8th quad is very likely to come in the 45th-47th card range, which is also a very reasonable range to complete the first full suit. $\\endgroup$ \u2013\u00a0browngreen Apr 12 '16 at 8:06\n  \u2022 1\n    $\\begingroup$ Another $6.0\\times10^9$ simulations, tracking mean game length: $$\\begin{array}{rr}\\text{Quads}&\\text{Length}\\\\3&35.11\\\\4&37.96\\\\5&40.19\\\\6&41.96\\\\7&43.33\\\\8&44.33\\end{array}$$ Come to think of it, it may be feasible to calculate exact probabilities -- in terms of distributions there aren't really that many possibilities. $\\endgroup$ \u2013\u00a0user5713492 Apr 12 '16 at 17:18\n\nYour Answer"}
{"text": "Retrieved from https://mechanics.stackexchange.com/questions/828/driving-in-second-gear-at-65-mph\nText:\nI accidentally drove my 2000 Grand Marquis on second gear on the highway. I was going 65 for like 5 minutes and tried to get it to 70mph but the car was shaking, when I realized I put it into regular drive while going 65 and it stopped shaking.\n\nIs there any damage that this can do to my car?\n\n  \u2022 11\n    I am curious as to how you managed to do this by accident. Unless you are deaf, in which case I mean no offence. \u2013\u00a0Tom W Sep 19 '11 at 18:22\n  \u2022 There was a little old lady who drove her Austin 1100 from Dunedin to Milton in second gear .This was about 30 miles .She complained to the mechanic that the car was very noisey and not very economical . \u2013\u00a0Autistic Jan 7 '17 at 13:58\n\nIt's definitely not great. The redline is there for a reason. That shaking was likely the engine speed limiter looking at the RPMs and saying, \"yes, that's high enough.\" The speed limiter can be either an ignition cutoff or a fuel cutoff - both will make the car feel very shaky.\n\nThe most common bad consequence of an overspeed condition when the engine speed limiter fails to thwart the operator is a bent valve. There's a lot going on in the engine when it's turning at several thousand RPMs: if the valve does not have time to return to its seat before the piston comes back up, the piston is going to hit the valve harder than you would like.\n\nOf course, that's not the only possibility, just the most common that I've heard of.\n\nIn short, listen to your car and be glad that the limiter worked that time.\n\n  \u2022 Hmmmm. Pretty sure that's what happened to my Corolla a few years ago. Never really knew what happened to it, but I was messing around on ice and the revs got pretty high. Makes sense. \u2013\u00a0Vian Esterhuizen May 9 '11 at 20:46\n  \u2022 @Vian, the worst part about the redline is that it isn't a sure thing. It's not a contract from the vendor that says \"below this line good, above this line BOOM!\" Instead it's really just a statistical measure. At the redline, the probability that something bad will happen is much greater. Higher than that, it's higher. However, you could have a bad day, touch the redline and bend something. \u2013\u00a0Bob Cross May 9 '11 at 21:49\n  \u2022 Yeah. It was just personal commentary. I'm about 99% sure that I bent a valve. That makes a lot of sense for what happened to me. \u2013\u00a0Vian Esterhuizen May 9 '11 at 21:51\n\nMore details of the vehicle in question would be helpful to be sure. However, from personal experience, my guess would be that the shakes are not solely due to the engine being run at high RPM.\n\nThe Mercury Grand Marquis is equipped with a 4.6L Modular V8 engine and 4R70W automatic transmission, similar to many other products of the Ford Motor Company. Notable among these, at one point or another, have been the Ford Mustang, Ford Crown Victoria, Lincoln Town Car, and the Lincoln Mark VIII.\n\nIn the Lincoln Mark VIII, 65-70 MPH in 2nd gear was very doable. In fact, redline (6,000 RPM) for 2nd gear got you going at around 90 MPH. Maintaining such a high engine speed for long durations would definitely get things heated up a bit, but it's nothing the car can't handle as long as you don't do it for too long or too often.\n\nI once had to do this myself to take the Mark VIII for repairs after the one-way clutch had failed - rendering the transmission unable to engage any gear higher than 2nd. To get to the shop where the work was going to be done required about a half-hour or so of highway travel. Parts of the highway were 65-70 MPH zones, where of course most drivers were running 75-80+. The way I managed the trip was to take the car up to speed until the engine started to get too warm, and then coast in neutral long enough to let it cool down to a more regular temperature before engaging the transmission for another run. I definitely don't recommend doing this if it can be avoided, but it should serve as a case example for two points:\n\n  1. It's doubtful that your car was redlining at 65-70 MPH in 2nd gear.\n  2. A one-time incident of approximately 5 minutes' duration at that speed, while not exactly good for the car, should not cause significant damage to an otherwise healthy drivetrain.\n\nGiven the shaking that you've experienced though, I'd definitely want to have a professional take a look at the car.\n\n  \u2022 Good summary points. \u2013\u00a0Bob Cross Aug 19 '11 at 17:54\n\nYou probably did no immediate damage. Most cars have an electronic limiter that keep the engine RPM from going into the redline, which could cause a blown engine. However, if you kept doing that, your engine would wear out a lot faster.\n\n\nmost newer cars automatics shift gears for you so as not to let you blow the engine. They put this in so people who bought a new car would stop blowing the engine and saying i dont no what happen (tring not to have to pay for the car lemon)put your car or truck in low gear gun it going down the road it will shift for you.\n\n  \u2022 1\n    Greg, you aren't seeing the original point: the car stayed in second. It didn't automatically upshift because of the driver's gear selection. \u2013\u00a0Bob Cross Aug 15 '12 at 22:23\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/479892/problem-in-the-continuum-limit-of-a-kronecker-delta\nText:\nI am having troubles in understanding how to correctly perform the continuum limit of a double sum containing a Kronecker delta.\n\nImagine to integrate a function depending on $t$ and $t'$, both ranging from $0$ (initial time) to $T$ (final time):\n\n$$I:=\\int_0^Tdt_1\\int_0^Tdt_2 f(t_1,t_2).\\tag{1}$$\n\nThe corresponding Riemann sums, dividing the time intervals in slices of width $\\epsilon=T/N$ is:\n\n$$I_{disc}:=\\sum_{j,j'=1}^N \\epsilon^2 f(j\\epsilon,j'\\epsilon).\\tag{2}$$\n\nObviosly lim$_{N\\rightarrow\\infty}I_{disc}=I$. Now consider the case when only the diagonal elements of the double integral are different from zero i.e.\n\n$$J_{disc}:=\\sum_{j,j'=1}^N \\delta_{j,j'}\\epsilon^2 f(j\\epsilon,j'\\epsilon).\\tag{3}$$\n\nI would expect that, in the continuum limit $N\\rightarrow \\infty$ ($\\epsilon\\rightarrow 0$) it becomes\n\n$$J:=\\int_0^Tdt\\int_0^Tdt'\\delta(t-t') f(t,t'),\\tag{4}$$\n\nwhere $\\delta(t-t')$ is a Dirac delta.\n\nHere is the problem: the Kronecker delta is adimensional, while the Dirac Delta has the dimensions of seconds$^{-1}$. This implies that $J_{disc}$ and $J$ have different dimensions, which does not make any sense. Therefore, there must be some mistake I am doing in going from the discrete to the continuum version of $J$. Could you help me spotting it and, more important, suggest the way to do this limit correctly?\n\n  \u2022 $\\begingroup$ Maybe $\\delta\\left(\\frac{t-t'}{T}\\right)$? $\\endgroup$ \u2013\u00a0Cryo May 14 at 0:06\n\nThe translation between the Kronecker delta function and the Dirac delta distribution is\n\n$$ \\frac{1}{\\epsilon}\\delta_{j,j^{\\prime}}\\qquad\\longrightarrow\\qquad\\delta(t-t^{\\prime}),\\tag{A}$$\n\nwhere $\\epsilon$ is the \"volume\" of a unit-cell in the discretization. See e.g. this related Phys.SE post.\n\nIn particular, the rhs. of OP's eq. (3) should be divided with $\\epsilon$ to have a finite continuum limit.\n\n  \u2022 $\\begingroup$ Thank you very much, I think this clarifies! To summarize, if I just take (3) as it is and perform the limit I get zero, which is also consistent of doing an integral of a finite quantity (the function f) on a set with null measure (the line s=s'). $\\endgroup$ \u2013\u00a0Sandro May 15 at 14:01\n  \u2022 $\\begingroup$ $\\uparrow$ Yes. $\\endgroup$ \u2013\u00a0Qmechanic May 15 at 16:49\n\nYour Answer"}
{"text": "Retrieved from https://cs.stackexchange.com/questions/104520/find-a-language-l-such-that-l-notin-mathbfp-but-l-in-mathbfp\nText:\nI'm being asked the following\n\nFind a language $L$, such that $L \\notin \\mathbf{P}$, but $L^* \\in \\mathbf{P}$\n\nFor the $L \\notin \\mathbf{P}$-part I have to show that there is no polynomial Turing Machine that could accept $L$.\n\nI've been struggling with this problem for quite a while, so I would appreciate any help with it.\n\nMy attempt:\n\n\n$$L = \\{0, 1\\} \\cup \\{0^i| M_i\\text{ does not accept }\\langle M_i \\rangle\\}$$\n\nThen $L^* = \\{0, 1\\}^*$. Since this language is regular, we can defined a TM that works on the word $w$ in just a single pass $\\implies$ TM runs in $O(|w|) = O(n) \\implies L^* \\in \\mathbf{P}$.\n\nI take this $L$ as example because it seems to me easier to show that $L \\notin \\mathbf{P}$ by proving that indeed there is no MT that accepts $L$ than showing that it is not accepted by any polynomial MT. To prove the former I was thinking about applying a diagolization argument on $L$.\n\nAm I on the right track? It seems to me that I'm trying to prove something stronger than what I'm asked, so maybe there is a more straightforward way.\n\n\n  \u2022 $\\begingroup$ You can prove that $L$ (or a similar language) is not computable by reduction from the halting problem. $\\endgroup$ \u2013\u00a0Yuval Filmus Feb 18 at 17:18\n  \u2022 $\\begingroup$ @YuvalFilmus when we reduce a language $A$ to a language $B$, we take an instance $x$ of A and transform it into an instance $f(x)$ of $B$ so that $x \\in A$ iff $f(x) \\in B$. I cannot see how $M$ halting on $w$ would mean (can be transformed such that) that $M$ doesn't accept its own description. I'd appreciate any hint. $\\endgroup$ \u2013\u00a0Jazz Feb 18 at 23:07\n  \u2022 $\\begingroup$ You can make $M$ independent of its input, for example. $\\endgroup$ \u2013\u00a0Yuval Filmus Feb 19 at 2:08\n\n\nThat looks like an excellent approach. Proving something stronger is sometimes easier1 and usually useful.\n\nWhat's particularly nice about your template for $L$ is that it opens up new questions about what happens if you generalise to $L = A \\cup B$ where $A$ and $B$ are in different complexity classes and $B \\subset A^*$. The extreme of $A$ regular and $B$ undecidable is good enough, but you could also consider $B \\in NP^c$, $B \\in EXP^c$, maybe specific context-free $A$, ... Perhaps it would be an interesting question to ask how close they can be to each other while still getting some kind of separation. If you enjoy this kind of thing, there may be a mini research project in it.\n\n1 This is particularly true of proofs by induction, where proving a tight bound often makes the inductive step work where a loose bound wouldn't.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/706243/alternating-series-error-bound\nText:\nThe taylor series for $ln(x)$, centered at $x=1$, is $$\\sum_{n=1}^{\\infty}(-1)^{n+1}\\frac{(x-1)^n}{n} $$ Let $f$ be the function given by the sum of the first three nonzero terms of this series. The maximum value of $|\\ln(x)-f(x)|$ for $0.3\\le\\ x \\le\\ 1.7$ is?\n\nWhen I look at this question, I instinctively think of alternating series error bound. Therefore the maximum error should be equal to the first omitted term $$= (-1)^{4+1}\\frac{(x-1)^4}{4}$$ when we substitute in the endpoints of x, the results are the same $ =0.060025$\n\nThis solution is incorrect, but I do not understand why. The correct solution is the tedious way of actually calculating $$|\\ln(0.3)-(\\frac{x-1}{1}-\\frac{(x-1)^2}{2}+\\frac{(x-1)^3}{3})|$$ $=0.145$ (assuming $\\ln(0.3)$ gives the largest answer). Why is this so? Why does using error bound give an incorrect answer?\n\n\nDoes your series really alternate?\n\nEach term you add is negative for $x = 0.3$.\n\nAddendum: When $n$ is an even number you multiply an even term by $(-1)^{(n+1)}$ to reach a negative number.\n\n  \u2022 $\\begingroup$ not when $n$ is an even number $\\endgroup$ \u2013\u00a0Harrison Mar 10 '14 at 3:53\n  \u2022 $\\begingroup$ @Harrison: user1789954 is pointing out that for $x \\lt 1$, your series is not alternating. All terms are negative. Your alternating series error bound will work for $x \\gt 1$, but not for $x$ below that \"center of the expansion\". $\\endgroup$ \u2013\u00a0hardmath Mar 10 '14 at 3:57\n  \u2022 $\\begingroup$ Ahhh..I see. Thank you! $\\endgroup$ \u2013\u00a0Harrison Mar 10 '14 at 4:01\n  \u2022 $\\begingroup$ Here are the first few terms of the series: $-.7, -.245, -.114333, -.060025...$ $\\endgroup$ \u2013\u00a0Brad Mar 10 '14 at 4:01\n\nYour Answer"}
{"text": "Retrieved from https://physics.stackexchange.com/questions/76556/gravitational-force-exerted-by-a-rod-on-a-point-mass\nText:\nI have doubts with the solution of a certain problem. I will give the entire solution below and will lay out my doubts as well.\n\nA point mass $m_1$ is separated by a distance $r$ from a long rod of mass $m_2$ and length $L$.The objective is to find the total gravitational force exerted by the rod on the point mass.\n\nThis is how a particular author solved this question in a book.\n\nThe total mass of the rod was differentiated with respect to the total length of the rod, and each mass piece was called $dm$ and each length piece was called $dx$. Hence this equation was formulated:\n\n$\\large \\frac{m_2}{L}\\ =\\ \\frac{dm}{dx}$\n\nAlso, the distance between the point mass and each individual $dm$ piece was taken as $x$. Then the gravitational force between the point mass and each mass piece is given by:\n\n$F\\ =\\ \\large \\frac{Gm_1dm}{x^2}$\n\n$dm$ was substituted using the first equation, now the new equation becomes:\n\n$F\\ =\\ \\large \\frac{Gm_1m_2}{Lx^2}\\small dx$\n\nThis is then integrated from $x\\ =\\ r$ to $x\\ =\\ r + L$.\n\nMy question is this: how can we integrate $x$ with respect to $dx$?\n$dx$ represents the tiny length pieces of the rod, and $x$ represents the distance from the centre of the point mass to any point along the rod. How can we integrate $x$ with respect to $dx$, it does not make any physical sense to me? I am new to differentiation and integration, but I understand the basics well enough. If there is something wrong with this solution please tell me the right way to solve this problem, otherwise tell me how this solution makes sense.\n\n  \u2022 $\\begingroup$ You are right. One cannot integrate $x$ wit respect to $dx$. Maybe you are misinterpreting the author. A link to that solution would help. $\\endgroup$ \u2013\u00a0udiboy1209 Sep 7 '13 at 14:54\n  \u2022 $\\begingroup$ @udiboy. It is not on a site, it is from one of the coaching center study materials. The final answer comes out to be $F\\ =\\ \\frac{Gm_1m_2}{r(L + r)}$. Is this what you would get if you solved the problem the right way? $\\endgroup$ \u2013\u00a0Ram Sidharth Sep 7 '13 at 17:21\n\nI don't think that you really understand integration. Let me clear this up for you. In that question there is a rod of length l. You know how to calculate gravitational force between two point masses but not in continuous mass bodies.\n\nIf you apply the formula to find the gravitational force you don't know what to take the distance as because it is continuous body. Let us apply the formula $F\\ =\\ \\large \\frac{Gm_1m_2}{r^2}$ by taking r as the distance between the two bodies. Obviously we get a wrong answer. Now let us consider the rod to be made up of two bodies each of mass $m_2/2$ an length $l/2$ . Now we can define the force as $F\\ =\\ \\large \\frac{Gm_1m_2/2}{r^2} + \\frac{Gm_1m_2/2}{(r+l/2)^2}$ . Again we get a wrong answer. Now let us divide it into $N$ parts. Now the force can be represented as $F\\ =\\ \\large \\frac{Gm_1m_2/N}{r^2} + \\frac{Gm_1m_2/N}{(r+l/N)^2} +\\frac{Gm_1m_2/N}{(r+2l/N)^2}+...... \\frac{Gm_1m_2/N}{(r+(N-1)l/N)^2}+\\frac{Gm_1m_2/N}{(r+l)^2}$ Or $F\\ =\\ \\large \\frac{Gm_1m_2}{N}[\\frac{1}{(r)^2} +\\frac{1}{(r+l/N)^2} + \\frac{1}{(r+2l/N)^2} + .....\\frac{1}{(r+(N-1)l/N)^2}+\\frac{1}{(r+l)^2}]$ Now if we increase the value of $N$ we get a more accurate answer as the divisions become more smaller and more like point masses. Now if we make the value of $N$ very very high then we would get an accurate answer. This is where differentiation ad integration comes in. $\\large \\frac{m_2}{N}$ represents $dm$ and $\\large \\frac{l}{N}$ represents $dx$. Now you know why $dm\\ =\\large \\frac{m_2dx}{l}$\n\nLet us now apply this in the above expression. So now we have .. $F\\ =\\ \\large \\frac{Gm_1m_2dx}{l}[\\frac{1}{(r)^2} +\\frac{1}{(r+dx)^2} + \\frac{1}{(r+2dx)^2} + \\frac{1}{(r+3dx)^2} + .....+\\frac{1}{(r+l)^2}]$ This is same as integrating $\\ \\large \\frac{Gm_1m_2dx}{lx}$ from $x=r$ to $x=r+l$\n$Note:$ Every dm mass is not at the same distance from the point mass. We can integrate $x$ with respect to $dx$ as $dx$ is a small change in $x$ . You add all the values and you add $dx$ to $x$ in every next value. Hope this helps\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/69875/maximization-over-vectors-seen-as-column-matrices\nText:\nI am trying to solve the following question: $$\\text{Maximize } f(x_1,x_2,\\ldots, x_n)=2\\sum\\limits_{i=1}^n x_i^t A x_i+\\sum\\limits_{i=1}^{n-1}\\sum\\limits_{j>i}^n (x_i^tAx_j+x_j^tAx_i)$$ subject to\n$$x_i^t x_j=\\left\\{\\begin{array}{cc} 1&~i=j \\\\ -\\frac{1}{n}&~i\\ne j \\end{array}\\right.$$ where $x_i$'s are column vectors ($m\\times1$ matrices) with real entries and A is an $m\\times m$ $(n<m)$ real symmetric matrix.\n\nFrom some source, I know the answer as $$f_\\max=\\frac{n+1}n \\sum\\limits_{i=1}^n\\lambda_i^\\downarrow,$$ $\\lambda_i^\\downarrow$ being the eigenvalues of $A$ sorted in non-increasing order (counting multiplicity). But I am unable to prove it. I will appreciate any help (preferably with established matrix inequality, or Lagrange's multiplier method).\n\n  \u2022 $\\begingroup$ Just checking; does $$f(x_1,x_2,\\dots,x_n)=\\sum_{i=1}^nx_i^tAx_i+u^tAu$$ where $u=x_1+x_2+\\dots+x_n$? $\\endgroup$ \u2013\u00a0robjohn Oct 4 '11 at 21:15\n  \u2022 $\\begingroup$ yes, it is. Actually, I have expanded the sum... $\\endgroup$ \u2013\u00a0Tapu Oct 4 '11 at 21:26\n  \u2022 $\\begingroup$ This looks a lot like an equation I got when I was doing a least squares regression for a rigid rotation. If that is what you are doing, you might want to take a look at something I wrote up for sci.math. $\\endgroup$ \u2013\u00a0robjohn Oct 4 '11 at 22:55\n\nWhy Lagrange multipliers? Your maximization problem can be solved in a rather straightforward manner using some standard tricks in matrix theory. Let $e=\\frac1{\\sqrt{n}}(1,\\ldots,1)^T\\in\\mathbb{R}^n$ and $X=(x_1,\\ldots,x_n)\\in M_{m,n}(\\mathbb{R})$ (hence $X$ is \"tall\" and $X^T$ is \"wide\"). The problem can be formulated as maximizing $$ f(X)=\\textrm{tr}(X^TAX)+ne^TX^TAXe=\\textrm{tr}\\left((I+nee^T)X^TAX\\right) $$ subject to the constraint $X^TX=\\frac{n+1}{n}I-ee^T$.\n\nThe eigenvalues of $X^TX$ are $\\frac{n+1}{n}$ (with multiplicities $n-1$) and $\\frac{1}{n}$ (with $e$ being an eigenvector). Pick any orthogonal matrix $V$ whose last column is $e$. Then every $X$ that satisfies $X^TX=\\frac{n+1}{n}I-ee^T$ can be written as $X=U\\Sigma V^T$, where $U$ is some $m\\times m$ orthogonal matrix, $\\Sigma$ is the $m\\times n$ (tall) diagonal matrix with diagonal $\\left(\\sqrt{\\frac{n+1}{n}},\\ldots,\\sqrt{\\frac{n+1}{n}},\\sqrt{\\frac{1}{n}}\\right)$, and $V$ is an $n\\times n$ orthogonal matrix. Now let $e_n=(0,\\ldots,0,1)^T\\in\\mathbb{R}^n$. Then $$ \\begin{align} \\Sigma V^T(I+nee^T)V\\Sigma^T &= \\Sigma\\left[I+n(V^Te)(e^TV)\\right]\\Sigma^T \\\\ &= \\Sigma(I+ne_ne_n^T)\\Sigma^T \\\\ &=\\textrm{diag}\\left(\\underbrace{\\frac{n+1}{n},\\ldots,\\frac{n+1}{n}}_{n \\textrm{ entries}},\\ \\underbrace{0,\\ldots,0}_{m-n \\textrm{ entries}}\\right) = D\\quad\\textrm{(say)}. \\end{align} $$ Hence $$ \\begin{align} f(X)&=\\textrm{tr}\\left((I+nee^T)X^TAX\\right)\\\\ &=\\textrm{tr}\\left((I+nee^T)V\\Sigma^T U^TAU\\Sigma V^T\\right)\\\\ &=\\textrm{tr}\\left(\\Sigma V^T(I+nee^T)V\\Sigma^T U^TAU\\right)\\\\ &=\\textrm{tr}\\left(DU^TAU\\right) \\end{align} $$ and the maximum of $f$ occurs when $U^TAU$ is a diagonal matrix whose diagonal entries are in descending order. Thus the answer follows.\n\n  \u2022 $\\begingroup$ Please let me verify (and how it matches with my original problem)...and I'll then accept your answer. Thanks in advance! $\\endgroup$ \u2013\u00a0Tapu Oct 10 '11 at 17:38\n\nThis is not an answer but a reformulation of the question. As robjohn stated, the question becomes: Maximize $f:\\mathbb{M}^{m\\times n}\\mapsto \\mathbb{R}$ such that\n\n$$ f(X) = \\operatorname{tr}(X^TAX) + \\underbrace{u^TAu}_{\\in\\mathbb{R}} $$ This can be combined into $$ \\operatorname{tr}(X^TAX) + \\operatorname{tr}(u^TAu) = \\operatorname{tr}\\left(\\begin{bmatrix}X&u\\end{bmatrix}^T A \\begin{bmatrix} X &u\\end{bmatrix} \\right) = \\operatorname{tr}\\left(\\pmatrix{I &\\mathbf{1}}^TX^TAX\\pmatrix{I &\\mathbf{1}}\\right) $$ where $I$ is the identity matrix and $\\mathbf{1}$ is the all-ones vector. You might want to check these lecture notes page 123. I would try something similar by myself but I am burned out and I need to rest. I will edit later if I can come with anything.\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/2982598/how-to-show-convergence-a-s-when-sum-of-pa-n-is-infty-and-the-sequence-i\nText:\nThere is a sequence of random variables defined by $$Y_n = \\Big(\\Big|{1-\\frac\\Theta \\pi}\\Big|\\Big)^n$$ where $\\Theta\\sim\\mathrm{unif}[0,2\\pi].$ I have shown that the sequence converges to $0$ in probability. Applying Borel Cantelli Lemma by taking $A_n = \\{|Y_n|>0\\}$ and then evaluating $\\sum_{n=1}^\\infty P(A_n)$, I get it to be $\\infty$. Since the random variables are not independent, I can't conclude anything from this result. How do I prove/disprove convergence almost surely?\n\n\n$Z=(1-\\Theta/\\pi)$ is almost surely in $(-1,1),$ in which case $Z^n\\to 0.$ Thus $Y_n = Z^n \\to 0$ almost surely.\n\n  \u2022 $\\begingroup$ Thank you for you answer. $P(\\lim_{n\\to\\infty}Y_n = 0) = 1$ implies a.s. convergence right? In this case $Y_n \\to 0$ a.s. as $n \\to \\infty$. Does that guarantee a.s. convergence? $\\endgroup$ \u2013\u00a0learner Nov 3 '18 at 6:34\n  \u2022 1\n    $\\begingroup$ @learner If it almost surely converges to zero, then it almost surely converges. More formally, $P(Y_n \\mbox{ converges}) \\ge P(Y_n\\to 0) = P(Z^n\\to 0) \\ge P(|Z|<1) = 1.$ $\\endgroup$ \u2013\u00a0spaceisdarkgreen Nov 3 '18 at 6:41\n  \u2022 $\\begingroup$ thank you so much for clarifying. $\\endgroup$ \u2013\u00a0learner Nov 3 '18 at 6:50\n\nYour Answer"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-practical-gas-law.735502/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple practical gas law\n\n  1. Jan 29, 2014 #1\n    Hi all...!\n\n    Gas laws.\n\n    Sorry about the simplicity of the question, but that should make it easy :)\n\n    I have two rigid containers open to air. One is 10 times the volume of the other.\n\n    I cap each.\n\n    I increase the temperature of each, 50 degrees.\n\n    What can I say about the pressure inside the containers, compared to each other?\n\n    A brief explanation?\n\n    Thanks ever so much.\n    Last edited: Jan 29, 2014\n  2. jcsd\n  3. Jan 29, 2014 #2\n    The pressure will be the same.\n\n    Just look at the ideal gas law:\n\n    PV = nRT, here P is pressure, V is volume, n is the number of molecules and T is the temperature. R is just a constant.\n\n    Solving for P you get:\n\n    P = nRT / V\n\n    Now, right after you close the lid on each container, notice that the number of molecules in each container is directly proportional to the volume of the container. Therefore the pressure will be the same. When you increase the temperature, it is proportional to the pressure in both cases, so when you increase the temperature equally much in both containers, you increase the pressure equally much. So the end pressure is the same.\n  4. Jan 29, 2014 #3\n    Thanks... this is how I see it as well... but I'm in disagreement with a PhD about it... (I'm not one, so I have less cred), so I appreciate the sanity check.\n\n    I just think of a (very tough) soap bubble in a pressure cooker.\n\n    If you add or subtract heat... he would have to believe that the bubble would change size one way or the other as you changed temperature.\n\n    Intuitively, I just couldn't see that happening. The gas would become equally more active on both sides of the bubble, so the bubble would retain its size. The only way to change the bubble size would be to add or remove gas.... so even if the bubble was slowly permeable... there would be no net exchange (discounting surface tension of the bubble, of course :)\n    Last edited: Jan 29, 2014\n  5. Jan 29, 2014 #4\n    It's not quite the same problem.\n    The gas inside the bubble has a higher pressure than the environment, to start with.\n    In your OP both containers have the same initial pressure.\n  6. Jan 29, 2014 #5\n\n\n    User Avatar\n\n    I would tend to think a bubble would be pretty close to zero gauge pressure - in other words, the same pressure as the environment.\n  7. Jan 29, 2014 #6\n    That's why I said:\n\n    \"discounting surface tension of the bubble, of course :)\"\n\n    So there you go.\n\n    Thanks to all!"}
{"text": "Retrieved from http://www.learn-math.top/calculating-the-reciprocal-distance-matrix-without-inflicting-complexinfinity/\nText:\nCalculating the reciprocal distance matrix without inflicting `ComplexInfinity`\n\nGiven a list of coordinates r (r[[i]]!=r[[j]]), I\u2019d like to know the reciprocals of distances of all pairs in the list, and for the convenience subsequent operations, the trace of the resulting matrix should be all zero. I feel that this should be a frequent need, but I can\u2019t do it optimally.\n\nMy code:\n\nR = Outer[Norm, r, r, 1];\nrR = Quiet[1/R] /. {ComplexInfinity -> 0.}\n\nBut this is not such a good idea as ReplaceAll is significantly slower than the other calculations in this code. Is it a good idea to use For or Table and loop over all indices, or is there a better way to do this?\n\n\n\n\nIf you know all of the r values are different, why not just set the diagonal to 0 afterward? Do UpperTriangularize[#, 1] + LowerTriangularize[#, -1] &@Quiet[1/R]. See here.\n\u2013\u00a0march\nSep 6 at 5:41\n\n\n\nOr what\u2019s your definition of distances of all pairs?\n\u2013\u00a0goodbye_M.SE\nSep 6 at 14:07\n\n\n\nI think Outer[Norm, r, r, 1] should be Outer[EuclideanDistance, r, r, 1]?\n\u2013\u00a0xzczd\nSep 6 at 14:41\n\n\n3 Answers\n\n\nIf the coordinates are machine reals and speed is an issue, I would Compile a function:\n\nreciprocalDist = Compile[{{r, _Real, 2}},\nR = Outer[Subtract, r, r, 1]; (* Outer[Norm,..] is not supported in Compile *)\nMap[If[# == 0, 0, 1/#] &@Norm[#] &, R, {2}]\n\nSeedRandom[0]; (* for reproducibility *)\nreciprocalDist[RandomReal[{-1, 1}, {4, 3}]] // MatrixForm\n\nTheoretically one could cut the speed in half by calculating the upper triangular part. One could preallocate a zero matrix and fill the distances two at a time with a Do loop, for instance.\n\n\n\nWhy DV? I can\u2019t see what\u2019s wrong, other than the stated limitations. Since no comment, obviously a cowardly troll not sincerely interested in improving the site.\n\u2013\u00a0Michael E2\nSep 15 at 23:46\n\nSince DistanceMatrix[] is built-in, it seems natural to use it for this problem. Using Michael\u2019s example, let me present two approaches:\n\nBlockRandom[SeedRandom[0]; (*for reproducibility*)\npts = RandomReal[{-1, 1}, {4, 3}]];\n\n(* method 1 *)\nWith[{id = IdentityMatrix[Length[pts]]}, 1/(DistanceMatrix[pts] + id) \u2013 id]\n\n(* method 2 *)\nDistanceMatrix[pts, DistanceFunction -> (With[{d = EuclideanDistance[##]},\nIf[d == 0, 0, 1/d]] &)]\n\nBoth should return\n\nreci[R_] :=\nWith[{l = Length@R}, {m = SparseArray[Band[{1, 1}] -> 1, {l, l}]}, (1 \u2013 m)/(R + m)]\n\nIf you\u2019re before v10.4:\n\nreci[R_] :=\nWith[{l = Length@R},\n\n\n\nTo the downvoter, I am interested in what was missing from my answer. Did I give too little detail? Or, was it considered incorrect in some way? Either way, would you please elaborate? I\u2019m not trying to complain here, I\u2019m just curious about what I could have done instead.\n\u2013\u00a0xzczd\nOct 6 at 11:09"}
{"text": "Retrieved from https://www.physicsforums.com/threads/de-of-the-form-y-by-a.243575/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nDE of the form y'' + by' = a\n\n  1. Jul 5, 2008 #1\n    Hi, I'm trying to solve the following equation\n\n    y'' + by' = a\n\n    But my answer doesn't make sense:\n\n    The question:\n    an object is flying through space, with velocity could be approximated as:\n    v_next = v_current + a*dt - damp*v*dt\n\n    dt - time increment taken repetitively\n    a - acceleration\n    damp - a constant\n\n    For large dt the approximation is inappropriate, find an equation that will do for large dt.\n\n    My go:\n\n    it looks like the above equation is \"similar\" to\n    x'' = a - damp*x'\n    x'' + damp*x' = a\n\n    part 1: x_c\n    [tex]x'' + damp*x = 0 => r*r + damp*r = 0; r = 0, r = \\frac{-1}{damp}[/tex]\n    [tex]x_c = c_1 + c_2e^{\\frac{-t}{damp}}[/tex]\n\n    part 2: x_p\n    x(t) = k*t\n    x'' + damp*k = a\n    (k*t)'' = 0\n    [tex]k = \\frac{a}{damp}[/tex]\n    [tex]x_p = \\frac{a*t}{damp}[/tex]\n\n    part 3:\n    [tex]x = x_c + x_p = c_1 + c_2e^{\\frac{-t}{damp}} + \\frac{a*t}{damp}[/tex]\n    we want x' approximation so\n    [tex]x' = \\frac{-c_2}{damp}e^{\\frac{-t}{damp}} + \\frac{a}{damp}[/tex]\n\n    what doesn't make sense is lets say damp -> 0 then x' should be a streight line but it doesn't look like it?\n\n    Where may I have gone wrong?\n\n    Thank you\n    Last edited: Jul 5, 2008\n  2. jcsd\n  3. Jul 5, 2008 #2\n    Your solution for nonzero damp looks fine to me: the system starts with some initial speed and then approaches asymptotically the so called \"terminal speed\", v(terminal) = a/damp, at which the pulling force balances the friction exactly: m*a = m*damp*v(terminal).\n\n    Your solution doesn't apply to damp=0 case because you assumed you got two distinct roots of the characteristic equation and hence the full general solution of the homogeneous equation in part 1. That assumption breaks down when damp =0.\n\n    When damp=0, the homogeneous diff. equation in part 1 is x\" = 0.\n    You get a double zero root of the characteristic equation hence only one exponent which can't capture the full general solution required to depend on two arbitrary constants not one. In such cases the general prescription tells you to look for solution of other types not exp(kt). In this case the solution is a linear function xc = c1 + c2*t. The double zero root in the exponent produces only the c1 term.\n    Last edited: Jul 5, 2008"}
{"text": "Retrieved from https://www.physicsforums.com/threads/linear-stuff-i-never-get-the-awnser.89423/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nLinear stuff: I never get the awnser\n\n  1. Sep 17, 2005 #1\n    Linear stuff: I never get the awnser...!!!\n\n    [3 1 1 1 0]\n    [5 -1 1 -1 0]\n\n    Where the variables are X1 X2 X3 X4.\n\n    I always get somethignt that is far away from the answer.\n    The answer should be x1= -s x2=-t-s x3=4s x4 = t\n\n    Help please!\n  2. jcsd\n  3. Sep 17, 2005 #2\n    What did you do to begin?\n  4. Sep 17, 2005 #3\n    At first, i putted the first number in the frist row as 1.\n\n    so i get [1 1/3 1/3 1/3 0]\n    than i eliminate the 5 to make it a 0.\n    But its after that i got ****ed!\n\n  5. Sep 17, 2005 #4\n\n\n    User Avatar\n    Science Advisor\n\n    What was the question?? I think you have two equations in 4 unknowns and both equations are equal to 0. (It is mildly confusing that you tell us the variables are X1, X2, X3, X4 but then write x1, x2, x3, and x4!)\n\n    Do you understand that there are many different ways to write the answer depending on exactly how you do this? It might be that your answers that are \"far away from the answer\" are, in fact, exactly on the answer!\n\n    You could do this by \"row reducing\" but with a simple problem like this I think just \"substitution\" is best.\n\n    The equations are 3x1+ x2+ x3+ x4= 0 and 5x1- x2+ x3- x4= 0. I might do something like add the two equations and get 8x1+ 2x3= 0 so that x3= -4x1.\n    Now, I choose (arbitrarily) to make x1= s. Then x3= -4s. Putting those into the two equations I get 3s+ x2- 4x+ x4= 0 or x2+ x4= s and\n    5s- x2- 4s- x4= 0 or x2+ x4= s. Since those two equations are exactly the same, I choose (again arbitrarily) to let x2= t and solve for x4= s-t.\n    My solution is x1= s, x2= t, x3= -4s, x4= s-t.\n\n    Is that \"far away from the answer\", which was x1= -s x2=-t-s x3=4s x4 = t? No, not at all. It might make a little more sense if I don't use the same letters as in your given answer: In my answer use \"u\" instead of \"s\" and \"v\" instead of \"t\". Then my answer is x1= u, x2=v, x3=-4u, x4= u- v. Looking at the \"given\" answer, I see that x1=u= -s. If I just replace u by -s, I will have both x1= -s and x3= -4u= 4s as in the \"given\" answer. MY x2 was v while the \"given\" x2 is -t-s. That would be the same if v= -t-s. In that case, my x4= u- t would become x4= (-s)-(-t-s)= -s+ t+ s= t, exactly as given.\n\n    That means that the set of points from my answer and the \"given\" answer are exactly the same! For example, If you take s= 1, t= 1 in the \"given\" answer you get x1= -1, x2= -2, x3= 4, x4= 1.\n    If you take s= -1, v= -2 (in my original form. In terms of u, v, I am taking u= -s= -1, v= -t-s= -2.) so that x= s= -1, x2= t= -2, x3=-4s= 4, x4= s-t= 1, just as before.\n\n    Because there are 2 (independent) equations in 4 unknowns, we have 4-2= 2 \"degrees of freedom\". We are free to choose any two parameters, arbitrarily, and write x1, x2, x3, x4 in terms of those two parameters. Of course, the equations you get will depend upon those arbitrary choices.\n    Last edited by a moderator: Sep 17, 2005\n  6. Sep 17, 2005 #5\n    Thanks bud, i'll look at it later on. If i have any problem, i'll post.\n\nSimilar Discussions: Linear stuff: I never get the awnser"}
{"text": "Retrieved from https://www.physicsforums.com/threads/frequency-addition.226941/\nText:\nDismiss Notice\nJoin Physics Forums Today!\n\nFrequency Addition\n\n  1. Apr 6, 2008 #1\n    Hi everyone, first post so go easy :)\n\n    What I want to do is design a circuit to add two square wave frequencies into one output.\n\n    The use is for a vehicle fitted with a Karman Vortex mass airflow sensor.\n    The MAF sensor has a 5V square wave output of 0~150Hz.\n    The vehicle has been modified with twin throttle bodies currently plumbed back to a single MAF.\n    The idea is to run two MAF sensors, one for each throttle body.\n\n    So how do I combine the two signals into one output to the ECU?\n    The problem that I see is that even if the two signals are 180 degrees out of phase, they must still add. Ie. 50Hz + 50Hz input, regardless of phase, must = 100Hz output.\n\n    All feedback appreciated,\n\n  2. jcsd\n  3. Apr 7, 2008 #2\n    I think I get the idea. You don't care about phase and amplitudes. If one signal has a frequency of F1 and the other F2, you want the output to have a frequency of F1+F2, correct?\n\n    This would be new to me. The first thing I would do is look at a PPL VCO (phase lock loop, voltage controled oscillator).\n  4. Apr 7, 2008 #3\n    You got it, that's exactly what I'm looking for.\n\n    Ok then. Time to hit Google and look that up. Forgive me but I'm an electronics noob.\n  5. Apr 7, 2008 #4\n    the CD4046 is a CMOS PLL-VCO---of course there's always an easier way to do something.\n  6. Apr 7, 2008 #5\n    would a mixer work?\n    it will return F1-F2 and F1+F2\n    put a high pass filter to get rid of the lower frequency\n  7. Apr 7, 2008 #6\n    I really don't know edmondng. Care to elaborate?\n    EDIT: Actually given the low frequency's I'm dealing with (30~150Hz) would it even be possible to filter out the original input frequencies?\n\n    What about a half adder? Would that work?\n    Last edited: Apr 7, 2008\n  8. Apr 7, 2008 #7\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    The biggest problems are the 0 Hz thing and the \"square wave\" thing. You will need to understand what the ECU expects out of the MAF signal, before you can pick the best way (if one exists) of combining the two MAF signals into one for the ECU.\n\n    For example, if the ECU divides the MAF square wave down by two right away (like, it is only rising edge sensitive), then it is easier to combine the two signals with an adder or some such thing, since you wouldn't care about the duty cycle, only getting the right number of rising edges. You should also find out about the response time and stability criteria for the ECU, since you could confuse it if the two MAF sensors rolled through phase and gave the ECU some jittery edges.\n\n    If the ECU expects a 50% duty cycle input signal from the MAF, then you have to do more work. And the 0 Hz part is still a problem for this. What is the minimum frequency really, that is, what is it at idle. Probably not 0 Hz, right? If it is something reasonable, then you can take the two MAF signals, add them, and phase lock a 50% duty cycle signal to them as suggested already. Your comparison in the PLL will be between the added signal divided by 2, versus the PLL output signal divided by 2. That gets rid of jitter in the comparison, and as long as your PLL output is reasonably square, the ECU should be okay with it.\n\n    But even with a PLL, you are going to have to trade off PLL lock delay and jitter numbers, versus how fast and accurate you want your ECU to be able to respond.\n\n    You might be best off just to stay with the single MAF sensor to the ECU, and maybe make a simple comparison circuit for now that measures the difference in MAF from the two sensors, and just displays that for you to see. If the two MAFs are giving about the same readings anyway, then there is no reason to go to the pretty big trouble of combining the signals, IMO.\n  9. Apr 7, 2008 #8\n    Ok, the MAF sensor outputs a 5V square wave signal of ~30Hz at idle rising to ~150Hz at WOT.\n    The MAF sensors output is 50% duty cycle.\n\n    Your example above makes the most sense to me and eliminates problems introduced by phase shift.\n\n    But your right, I need to find out if the ECU is rising edge sensitive or requires a 50% duty cycle square wave.\n    So how much delay are we talking about here?\n\n    Obviously I've got a lot to learn, I'm going to reserch about PLL's and how they work.\n\n    Thanks for the great reply even if I didn't understand half of it :)\n  10. Apr 7, 2008 #9\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    So when you go to two MAF sensors, the output frequency range of each will now be about 15Hz-75Hz, right?\n\n    I'd suggest drawing a few representative waveforms (with different phases, etc.), to start to get an idea for how you might want to combine them. You can also do a full-digital PLL without an analog VCO for this low-frequency project. You would run a higher-freq digital clock (say, 32kHz like with a watch crystal, or 10MHz with a regular crystal oscillator), and oversample the MAF digital signals, and compute what the sum waveform would be, and output that to the ECU. That would be a fun all-digital project for you.\n  11. Apr 7, 2008 #10\n    You got it.\n    Hahah, sounds way over my head but if you point me in the right direction I'll give it a go.\n  12. Apr 7, 2008 #11\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    I'm not sure I can point you to a good design reference... maybe others reading this thread will know of a good reference for you to read up on this.\n\n    If a brief description would help, I'll try that. Basically you would have two high-frequency counters running, counting the half periods of each of the MAF sensor outputs. Each time a counter finished counting a half period, that information would go toward adjusting the half period of your final output counter.\n\n    So if you used a 32kHz watch crystal as your time base, you would get to a half period count of about 425/2 for a 75Hz input square wave from a MAF, and a half period count of about 2100/2 for a 15Hz input. Each time you got an update from either MAF's counter (each rising or falling edge of the MAF output waveform), you would use that number plus the most recent number from the other MAF channel to pre-set the next terminal count for the output counter. There's a little bit of arbitration and synchronization stuff that has to happen also, but that's a bit complicated to get into in this simple explanation.\n\n    So I think you see the concept of how it would work. I still think as a practical matter, it's best to just stick with a single MAF sensor output. Well, except it just occurred to me that the MAF output will now be too low in frequency, since you have divided the airflow in half. Yikes. Any chance the ECU can be re-mapped to handle the 1/2 MAF output frequency?\n  13. Apr 8, 2008 #12\n    You could be making more work for yourself than necessary.\n\n    If you expect the two MAF to output about the same frequency, you many only need to take the signal from one, and double it.\n\n    By the way, I really like the half-adder idea. Ultimately simple, if not a bit chaotic. Of course you may never know what the ECU expects to see. But if the ECU samples the MAV infrequently, instead of every wave, or doesn't do any sort of averaging, then it wouldn't work at all.\n    Last edited: Apr 8, 2008\n  14. Apr 8, 2008 #13\n    Well this is the problem, there is no guarantee that both MAF sensors would have the same airflow. Also if one filter was to become more restricted then the other, then that would throw it out of balance. Unfortunatly this won't work reliably.\n\n    I'll do some asking around and find out what the ECU needs\n  15. Apr 8, 2008 #14\n    How about using a frequency to Voltage Converter and Voltage to frequency converter to achieve this??\n    Use F to V converter for two inputs F1 and F2 to get V1 and V2 respectively, then add those two analog voltage and again use V to F converter to get a frequency output. Dont have idea on pros and cons.... just an idea to achieve frequency addition.\n\nSimilar Discussions: Frequency Addition\n  1. Addition of decibels (Replies: 21)\n\n  2. Addition of vectors (Replies: 12)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/significant-digits-ruler-to-what-decimal-point.687574/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSignificant Digits Ruler -To what decimal point\n\n  1. Apr 23, 2013 #1\n    Significant Digits Ruler -To what decimal point\n    To what decimal point do I write the number 30 if the uncertainty is 0.0625?\n    The ruler has 1/8 marks.\n\n    Thank you :)\n  2. jcsd\n  3. Apr 23, 2013 #2\n\n\n    User Avatar\n\n    Staff: Mentor\n\n    Welcome to the PF.\n\n    You are required to show your Attempt at a Solution before we can offer any tutorial help. How would *you* approach this problem?\n  4. Apr 23, 2013 #3\n    I thought it would be 30.000 +- 0.0625 bc there are 3 sig figs in the uncertainty, but I'm not sure. :/\n    Also, should the uncertainty be rounded since it looks very precise? I'm so sonfused\n  5. Apr 23, 2013 #4\n\n\n    User Avatar\n    Science Advisor\n    Homework Helper\n    Gold Member\n\n    There are three sources of error here. One is that you are rounding to the nearest mark. That introduces an uncertainty of exactly \u00b10.0625. Next is any error in the placing of the marks on the ruler. You could handle that by rounding the first uncertainty up a little, \u00b10.064, say. Third is any error in your decision of which is the nearest mark. That's the same in nature as the second error, but statistically independent.\n    Now, suppose you decide the error is \u00b10.07 and you measured the value as 30.375. It would be quite appropriate to write the answer as, say, 30.375\u00b10.070, strange though that may seem. But it would also be reasonable to compromise there, e.g. with 30.37\u00b10.08.\n\nHave something to add?\nDraft saved Draft deleted\n\nSimilar Discussions: Significant Digits Ruler -To what decimal point\n  1. Significant digits (Replies: 2)\n\n  2. Significant Digits (Replies: 3)\n\n  3. Significant Digits (Replies: 2)\n\n  4. Significant digits (Replies: 1)\n\n  5. Significant digits (Replies: 1)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/magnitude-of-current-induced.805827/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nMagnitude of current induced\n\n  1. Mar 30, 2015 #1\n    . A circular coil of radius 5.0 cm and resistance 0.20 \u03a9 is placed in a uniform magnetic field perpendicular to the plane of the coil. The magnitude of the field changes with time according to B = 0.50e-20t T. What is the magnitude of the current induced in the coil at the time t = 2.0 s?\n\n    2. Relevant equations\n\n    \u03a6 = BAcos(0) = BA\n    emf = -d\u03a6B /dt = -d(BA)/dt = -A * d(B)/dt\n\n    3. The attempt at a solution\n\n    I differentiated that magnetic field and got -10e-20t, then multiplied that times pi*(.052), and ultimately divided by .2 \u03a9. My answer is 1.66*1018, which is nowhere near any of the answers. I feel like I'm following a logical path but obviously this isn't working, so I don't know what else to do.\n  2. jcsd\n  3. Mar 30, 2015 #2\n\n\n    User Avatar\n    Homework Helper\n    Gold Member\n\n    Your mistake is that you dont take into account the self inductance L of the coil. It will be [itex] E+L\\frac{dI}{dt}+IR=0[/itex] where E(t) exactly as you calculated and R=0.2Ohm. You still have to calculate L from the geometrical data of the coil and then solve the differential equation. In doing that becareful that E is not constant but varies with time as of course the current I(t) do so also.\n\nHave something to add?\nDraft saved Draft deleted"}
{"text": "Retrieved from https://www.physicsforums.com/threads/solving-an-inquality.576662/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSolving an inquality\n\n  1. Feb 11, 2012 #1\n\n    So this is the question\n\n\n    2. Relevant equations\n\n\n    3. The attempt at a solution\n\n    I tried it, the solution seems right, but i don't know if my approach is correct.\n\n  2. jcsd\n  3. Feb 11, 2012 #2\n\n\n    User Avatar\n    Homework Helper\n\n    Think about these absolute values like this:\n\n    At x=1 or x=2, one of the absolute values is 0, so you can call these the \"roots\" (thought not technically roots, I can't think of a more appropriate name for them right now), so what you want to do is check all possibilities around those roots, and the roots themselves.\n\n\n    For this range, both [itex]x-1[/itex] and [itex]x-2[/itex] will be negative, so the inequality you need to solve would be [tex]-(x-1)-(x-2)>1[/tex]\n\n    Here you will have [itex]x-1>0[/itex] and [itex]x-2<0[/itex] so what you need to solve is [tex](x-1)-(x-2)>1[/tex]\n\n    For this value, both are positive so it should be clear what you need to solve here.\n\n    And then always check the \"roots\" themselves. Plug in the values of x=1 and x=2. By this point, you've checked all possible cases and should have your solution set.\n  4. Feb 11, 2012 #3\n    The way I learned it:\n\n    To solve |ax+b|>k, solve ax+b>k and ax+b<-k. (This is basically what you did.)\n\n    Then I would plug test values into the original equation to see if it makes a true or false statement. You would use the intervals (-[itex]\\infty[/itex],1);(1,2);(2,[itex]\\infty[/itex]).\n\n    The values from those intervals that make true statements give you your solution set.\n  5. Feb 11, 2012 #4\n\n\n    User Avatar\n    Homework Helper\n\n    edit: I just realized that your question is a special case. What if it was instead [tex]|x-1|+|x-2|>2[/tex] or [tex]|x-1|+|x-2|>0[/tex] ? For the first what you need to do is check when [tex]|x-1|+|x-2|=2[/tex] and then check each interval around that.\n    Last edited: Feb 11, 2012\n  6. Feb 11, 2012 #5\n    Thanks Mentallic and Adaptation!\n\nSimilar Discussions: Solving an inquality\n  1. Solve for a (Replies: 6)\n\n  2. Solve for A (Replies: 17)\n\n  3. Solving an equation (Replies: 4)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/simple-integration.209566/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nSimple Integration\n\n  1. Jan 18, 2008 #1\n    [SOLVED] Simple Integration\n\n    1. Integrate the following\n\n    f(x) = sin x/(cos x )^2\n\n    3. Well i dont really want to use subsititution or anything since im pretty sure this can be done very simply but i dont know why i cannot get it...\n\n    sin x /cos ^2 x = sinx / 1- sin^2x\n\n    i know ln (cos x)^2 will give me (-2(cosx)*sinx)(1/cos^2x)\n\n    so thats not good...\n  2. jcsd\n  3. Jan 18, 2008 #2\n    How about u-substitution?\n  4. Jan 18, 2008 #3\n    You must use substitution. Using trig identities will only make it messier.\n\n    Hint: get f(x) into the form du / u ^2 .\n  5. Jan 18, 2008 #4\n    yea i just did it with u as well but that weird, cause this question was in my first section for integral calc (where we basically onyl went through basic rules like power rule, and integrals of other trig functions)\n\n    but anyways\n\n    let u = cosx\n\n    du/dx = -sinx\n\n    now i integrate - 1/(u)^2 * du\n    = integral of -u^-2 *du\n\n    = u^-1\n\n    = cos^-1 x\n\n    = 1/cos x\n\n    = sec x\n\n  6. Jan 18, 2008 #5\n\n\n    User Avatar\n    Homework Helper\n\n    Yup, that seems perfectly correct. Except for a small error, you forgot the Constant of Integration \"+ C\" at the end of the final result. :)\n  7. Jan 18, 2008 #6\n\n\n    User Avatar\n    Homework Helper\n\n    It happens in this case that there is another way to go about this, although it's not something you'd generally spot at first (you notice it after doing the u-substitution). You can also write\n    (sin x)/[(cos x)^2] as (1/cos x)\u00b7(sin x / cos x) = sec x tan x , which is the derivative of sec x . (This at least serves as a check on your result...)\n  8. Jan 20, 2008 #7\n    [tex]\\int\\frac{\\sin x}{\\cos^2 x}dx=-\\int\\frac{1}{\\cos^2 x}d(\\cos x)=-\\int (\\cos x)^{-2}d(\\cos x)=-\\frac{(\\cos x)^{-2+1}}{-2+1}+C=\\frac{1}{\\cos x} +C[/tex]\n    [tex]d(\\cos x)=-\\sin x dx[/tex]\n    [tex]dx=\\frac{d(\\cos x)}{-\\sin x}[/tex]\n    Last edited: Jan 20, 2008\n\nSimilar Discussions: Simple Integration\n  1. Simple integration (Replies: 2)\n\n  2. Simple Integral (Replies: 3)\n\n  3. Simple Integral (Replies: 10)\n\n  4. Simple integral (Replies: 7)\n\n  5. Simple Integral (Replies: 8)"}
{"text": "Retrieved from https://www.physicsforums.com/threads/calc-problem.59117/\nText:\nDismiss Notice\nDismiss Notice\nJoin Physics Forums Today!\n\nCalc problem\n\n  1. Jan 9, 2005 #1\n    We have a set of problems for hw. I am stuck on 1 where I know the answer but cant seem to get it.\n\n    If dy/dt=ky and k is a nonzero constant then y could be\n    a. 2e^kty b. 2e^kt c. e^kt d. kty+5 e. 1/2ky^2 +1/2\n\n    I know the answer is b but i cant get that answer\n    Here is my work\n    S=integral sign\n\n\n    How do u get a 2 in there for choice b\n    Last edited: Jan 9, 2005\n  2. jcsd\n  3. Jan 9, 2005 #2\n\n\n    User Avatar\n    Science Advisor\n    Gold Member\n\n    You forgot about the constant of integration:\n    [tex]\\frac{dy}{dt}=ky [/tex]\n    [tex] \\frac{dy}y=kdt [/tex]\n    [tex] \\int{\\frac{dy}y} = \\int{kdt} [/tex]\n    [tex] \\ln y = kt +C [/tex]\n    [tex] e^{\\ln y} = e^{kt + C} [/tex]\n    [tex] y = e^{kt}\\cdot e^C [/tex]\n    eC is also a constant, so it can be written as C1 if you like.The value of C1 will depend on the initial conditions. Unless there's a typo in your answer list, I can see two answers that are of this form:\n    b. [tex]y=2e^{kt}[/tex]\n    and c. [tex] y = e^{kt} [/tex]\n\n    I hope that helps.\n  4. Jan 9, 2005 #3\n    thanks forgot the C and yea choice c was a typo it should be e^kt +3\n\nSimilar Discussions: Calc problem\n  1. Ap calc AB problems (Replies: 1)"}
{"text": "Retrieved from https://math.stackexchange.com/questions/3146359/pdf-of-the-product-of-two-independent-uniformly-distributed-random-variables/3146380\nText:\nSuppose that X and Y are independent U[0,1]-random variables. Find the probability density function of the product V = XY.\n\nI have seen that \ud835\udc53(\ud835\udc67)=(\u22121)^(\ud835\udc5b\u22121)log(\ud835\udc5b\u22121)(\ud835\udc67)/(\ud835\udc5b\u22121)! for the product of n independent random variables from 0 < z < 1 but I am not sure how to derive this.\n\n\n$P(XY\\leq t)=EP(XY \\leq t |Y)=E(\\frac t Y I_{Y >t}+I_{Y \\leq t})$ so $P(XY\\leq t)=t\\log (\\frac 1 t)+t$ for $0<t<1$. The density is $\\log (\\frac 1 t)$ for $0<t<1$.\n\n  \u2022 $\\begingroup$ Where did you get the -tlogt +t after the indicator functions? $\\endgroup$ \u2013\u00a0gigglegirl6 Mar 13 at 10:36\n  \u2022 $\\begingroup$ @gigglegirl6 $\\int_t^{1} \\frac t y \\, dy=t\\log\\, y|_t^{1}=-t\\log\\, t$ $\\endgroup$ \u2013\u00a0Kavi Rama Murthy Mar 13 at 11:37\n\nYour Answer"}
{"text": "Retrieved from http://alphapowertrading.com/index.php/12-research-papers/95-portfolio-math-i\nText:\nJanuary 30, 2015\n\nWhen designing stock trading systems it is a good idea to view the problem, not only with a vision of what a trading program could or should do but also with an understanding of the environment in which this program will have to operate.\n\nIn a software trading program, which we can make it do whatever we want it to do, we only have logical decisions, calculations and statements in code to execute.\n\nNo feelings, no moods, no hunches and no trader psychology even if these in some way could also be programmed in. But this won't stop anyone from just gambling, be it in a discretionary manner or by using a partially or totally automated solution.\n\nA trading program will just do what it is programmed to do. It does not know the difference between good or bad code. It is up to the strategy designer to put in his program whatever he thinks is appropriate or required to make that program profitable over the long term. This may include technical and fundamental data that it be used or not; sentiment indicators, or outside input such as long-term prognosis on individual companies, minor or major world economic trends. Every strategy designer carries his own information set, to be used or not, in the making of trading decisions.\n\nThe not executed trade makes absolutely no profit and evidently no loss either.\n\nThe \"I told you so\", \"I knew\", or \"you could or should have\" also do not generate profits. It's the set of executed trading decisions, on whatever basis they were made, or will be made, that matters. It's the sum of all these trading/investment decisions that will determine if in the end you win or lose. This does not imply that you can avoid drawdowns; they are an inherent part of the investment/trading process.\n\nThe primary objective is not just to make money, the primary objective is first to survive the game, and then also prosper. Capital preservation should be the cornerstone of any stock trading/investment strategy. Be it investing or speculating; be it discretionarily, partially or totally automated: no capital means no trade, no game, no return.\n\nWhy Automate?\n\nYou design an automated trading strategy because you view the problem as amenable to logical trading rules, and the task too considerable to do it all by hand. You also want to know if the trading strategy you have in mind could have at least survived its past; because if it didn't, this would not be a good omen that it could outperform going forward.\n\nWhat should transpire in your trading script is your expertise, your knowledge, and understanding of what a stock trading strategy should do. But whatever the code's simplicity or complexity for that matter, the final outcome will entirely depend on the applied decision process that determined when and how much to buy, sell or hold.\n\nYou are, technically, designing an expert system. No wonder some use quite sophisticated tools to get there. It's not an easy task as evidenced by all the academic literature available and the huge number of people pushing their particular brand of trading methodology, philosophy or other.\n\nYou do automation because you can not type fast enough or handle more than just a few trades and stocks at a time. As a portfolio grows, it becomes more and more difficult to follow everything. Automation is an answer to a more systematic trading methodology. What you can do by hand can be done by machines at a much faster pace and grander scale.\n\nAs an individual or organization, your interest should be for the long term. And here long term means 20+ years. The idea is simple as to why: if your trading strategy blows up at any time before the 20+ years are up, you lose. Period. It's not just that you lost the game, you also lost the capital. All that time wasted, all those resources wasted. Maybe most important of all, it was your time wasted with absolutely nothing to show for it except your vaporized account.\n\nPerforming a task that might have been doomed from the start because your strategy design was inadequate to properly handle its future long-term trading environment is not a desirable outcome. It's something that should have been corrected before you started to \"play\" this stock market \"game\".\n\nAny trading strategy, be it discretionarily driven up to totally automated, needs to be based on something that is there. This from a single phenomenon to any combination of notions that can serve to describe what is happening in the market. A trade needs to be executable, if not, even if it is hardcoded in your trading strategy, it might have absolutely no economic value.\n\nThat is why you do long-term back tests. To see how your trading strategy would have behaved in general terms over long-term historical data. It is not enough to simulate on a single stock or instrument, the strategy must work at the portfolio level. This means multiple stocks over a long trading interval. These tests will also give you added knowledge as to general trading behavior, order placements and maybe help uncover new avenues to explore as you see more potential in some of your trading procedures.\n\nIf you do not do these back tests, on what grounds could you claim that your particular brand of trading strategy has some value going forward. If you want to sell me that your short-term trading strategy operating on breakouts is worthwhile, bring me a 20+ year test, at the portfolio level (say 30 stocks or more), showing that it was at least feasible in the past. If not, I pass. And there are many reasons why.\n\nThe Math\n\nThe most concise form of expressing the evolution of a portfolio of stocks of any size over any duration can be given using a payoff matrix equation of the form: A(t) = A(0) + \u03a3(H.*\u0394P). The symbol .* represents element-wise matrix multiplication. Easily done in Excel. The expression:\u00a0H.*\u0394P\u00a0resumes all the trading activity of any trading strategy over the life of a portfolio.\n\nI remember seeing this equation for the first time. It took me about 15 minutes to convert all my stuff to adhere to it, most of it was already in that general form, only a few minor modifications were required. It is what is implied by this equation that can be revealing. The output of the payoff matrix \u03a3(H.*\u0394P) is a vector of the cumulated profits and losses generated by each of the stocks in the portfolio over its entire history. What an easy way to express such a complex problem.\n\nAn equation representing a price series can be given by P(t) = P(0) + \u03a3 \u0394P, an initial price to which is added the cumulative sum of all price variations up to time t. It's not the only representation available, one could consider a stock price as if composed of a series of n consecutive numbers: P(t) = P(0), P(1), ..., P(n) spanning the trading or investment interval.\n\nThe holding inventory of about anything could also be written as: H(t) = H(0) + \u03a3 \u0394H, also saying an initial inventory to which is added the sum of all inventory changes. All the terms used in the payoff matrix could be view as starting with an initial value to which is added the sum of all variations over any duration. These series could be fragmented into as many segments as desired or required for whatever reason.\n\nIf there is no variation, there is no change. And if the sum of all variations over any duration is zero (\u03a3\u0394P = 0), you are left with the same thing: the initial value. It should be evident that the object of the \"game\" is to achieve: \u03a3(H.*\u0394P) > 0, meaning making an overall profit, no matter the size of the portfolio payoff matrix over whatever the duration.\n\nBoth the price series and the inventory series can be chopped in any which way one thinks appropriate. It's only when one decides to play the stock market game live that the manner in which one will chop, slice and dice these two particular data series that it will become critical. This requires a decision process: how much of this or that, when and at what price?\n\nThat is the problem to be solved, with a profitable outcome: \u03a3(H.*\u0394P) > 0. A portfolio payoff matrix ending in the red (no profit): \u03a3(H.*\u0394P) < 0, should not be part of acceptable solutions, neither should one design the output of a trading strategy to tend to zero: \u03a3(H.*\u0394P) \u2192 0 and this from either side of zero.\n\nOne needs to introduce a decision process in order to play the game. But there, there is no perfect equation for that. Yet, it's what will bring a change in inventory! I can write: D(t) = D(0) + \u03a3 \u0394D. The equation is right, but it has absolutely no monetary value, it is totally disembodied. However, if you play the game live, it is of the utmost importance. It will be this decision process that will determine what you will trade at what time and in what quantity. Therefore, this decision process needs to be divided into its components; you have time, prices, and quantity of shares bought or sold.\n\nAll this to come back full circle to A(t) = A(0) + \u03a3(H.*\u0394P) which resumes it all! The equation could have been written as: A(t) = A(0) + \u03a3(D.*(B.-S).*\u0394P) where the decision process is involved in the buying and selling,\u00a0of part\u00a0or all, of the outstanding inventory in each of the selected stocks in the portfolio. The holding inventory matrix\u00a0H\u00a0varies according to the result of the trading decision process in action:\u00a0H\u00a0=\u00a0D.*(B.-S).\n\nAny trading strategy that needs to survive over long periods of time (read 20+ years) need the following properties: feasibility, executability, marketability, and maintainability for the entire duration of the investment period. It's imperative that it be feasible, just as it needs to be logical and respond to just basic common sense.\n\nThings you can't do in real life, even if they are programmed and backtested using your trading software are not executable and therefore worthless. Things like trading a million shares a day when the average daily volume is less than 100k shares are not feasible in real life, but your backtest program could still process price data as if it was. This would result in a doomed and worthless trading strategy, and this from the start and by design.\n\nThe Payoff Matrix\n\nThe construction of a price matrix\u00a0P\u00a0can be the closing price of every stock in the DOW 30 over the last 25 years (making this a representative sample of the market as a whole). Every price element in the matrix p(i,j) would be the close of that day (i) for a particular stock (j). Since we are looking at the past, all p(i,j) would be recorded historical data and easily accessible. The Dow 30 price matrix\u00a0P\u00a0would grow in size, day by day, by j = 30 new closing prices, and for i = 0 to about 6,500 trading days (195,000 prices in all). The 195,000 entries in the\u00a0P\u00a0matrix would be the same closing prices for everyone.\n\nLooking at the\u00a0P\u00a0matrix, each column (j) is the actual closing price of a single stock. But the payoff matrix needs the difference in price from entry to exit with all price changes in between \u0394P. This difference matrix is easily constructed: \u0394p(i,j) = p(i,j) \u2013 p(i-1,j), subtract the previous price from current price for all the stocks in the\u00a0P\u00a0matrix and you get \u0394P. Since all the data in\u00a0P\u00a0was historical data, their daily change or price variations are also part of recorded history. Again, whatever the composition of the historical price matrix\u00a0P, its price variation matrix \u0394P\u00a0is also the same for everyone. One could view\u00a0P\u00a0and \u0394P\u00a0as a portfolio's stock selection to which can be applied any trading strategy\u00a0H.\n\nSo if I want to design an EOD (end-of-day) trading strategy from the above matrix, the price universe would be composed in the above case of 195,000 data points. Both\u00a0P\u00a0and \u0394P, are totally determined with no option to modify the price data since being taken as it is from historical records. If I design two different EOD trading strategies, they both will have to contend with the same closing price data.\n\nIf I want to extract some other information from the price series, it will be of my doing. Say I want a moving average, well the data is there, so I can do it. Will it be useful, this depends on what I want to do with it. It opens the door to a multitude of data interpretations. From the original data series, which was the same for everyone, I can now transform it into any suitable form in order to feed my trading decision surrogate.\n\nThe main course of a trading strategy is\u00a0H\u00a0the holding inventory matrix. Evidently, it will have the same size as\u00a0P\u00a0and \u0394P: 195,000 data elements. Each h(i,j) gives the state of the inventory level, the quantity held in each of the stocks on that particular day. It is with the decision matrix that we can slice and dice the price series at will and for whatever reasons we see fit:\u00a0H\u00a0=\u00a0D.*(B.-S).\n\nThe Buy & Hold is the easiest payoff matrix to build:\u00a0H.*\u0394P\u00a0where\u00a0H\u00a0is a matrix having its first row h(0,j) equal to the number of initial shares bought in each of the stocks, and all other rows, all 6,499 of them are identical to the first, since the initial inventory is held constant for the entire duration.\n\nI prefer writing the Buy & Hold strategy using scalar multiplication as: A(t) = A(0) + \u03a3(hoI.*\u0394P) where ho is the initial scalar vector the same size as j, while\u00a0I\u00a0is a matrix the same size as \u0394P\u00a0but entirely composed of ones. This produces a matrix where each column has for data element: h(i,j) = h(hoj,j). Using the 30 Dow stocks case, it can be considered as a Buy & Hold benchmark where the quantities held are constant, and \u0394P\u00a0the difference in the closing prices of the stocks in DJIA index. The same principles could be applied to the S&P100 or S&P500, and respectively generate matrices of 650,000 or 3,125,000 data elements over a 25 year period.\n\nBecoming a benchmark, all the characteristics of the index would equally apply to a Buy & Hold strategy. The historical Sharpe ratio, as well as any other ratios you might want to choose, long-term CAGR, drawdowns, including other statistics and metrics.\n\nAnother useful tidbit is that you can now compare other trading strategies to this basic benchmark, just as you can compare one trading strategy to another over the same stock selection and duration: is \u03a3(H(S#n).*\u0394P) >? \u03a3(H(S1).*\u0394P) >? \u03a3(H(B&H).*\u0394P) > 0 ? Is your latest trading strategy better than your previous ones and better than a Buy & Hold?\n\nWhere is the Money or Where is the Strategy\n\nDesigning a trading strategy should have for primary purpose to do better than a Buy & Hold benchmark. Otherwise, why bother? Do a Buy & Hold instead. Simply buy some index funds and be done with it. At least an index fund is designed to generate a long-term average performance that will tend to about the same performance level as a Buy & Hold strategy. Why strive and put the effort to in the end underperform an index?\n\nDoing less than the Buy & Hold over the same period of time is surely less than optimum, if not downright useless considering the small effort required in executing a Buy & Hold. Consider all the time saved not constantly monitoring the market, all that effort just to underperform.\n\nA strategy S1 playing EOD Dow stocks can be written as: A(t) = A(0) + \u03a3(H(S1).*\u0394P(Dow)). From its equation, one can surmise what is required: \u03a3(H(S1).*\u0394P(Dow)) > \u03a3(hoI.*\u0394P(Dow)). Whatever you design as a trading strategy, it must at least beat the Buy & Hold as its\u00a0final outcome. The closer your trading strategy is to the Buy & Hold, the closer your performance level will tend to the Buy & Hold. If\u00a0H(S1) \u2192 hoI, then the output of the payoff matrix will be about the same or close to it: \u03a3(H(S1).*\u0394P(Dow)) \u2192 \u03a3(hoI.*\u0394P(Dow)). Should S1 be the strategy of an index fund, then one should not be surprised if its payoff is about the same as the index.\n\nOne could compare multiple trading strategies by ordering them from most to least productive. The differences would be the result of how the trading strategy changed the inventory over time. How they would have sliced and diced the price series for all their trades. Not just one in and there, but all of them, since all trades will be accounted for over the trading interval. The question becomes: is\u00a0H(S#n) >?\u00a0H(S3) >?\u00a0H(S2) >?\u00a0H(B&H)? Is a particular trading strategy better than the others including better than the Buy & Hold or an index fund?\n\nFrom the holding matrix equation:\u00a0H\u00a0=\u00a0D.*(B.-S), the decision surrogate\u00a0D\u00a0determines if you buy or sell. It will slice the time series and thereby determine how long you will hold onto bought shares. But there is one ingredient still undefined: q(i,j), the quantity to be bought or sold for each stock over the entire trading interval.\n\nThe price of a transaction in an EOD system has already been determined, it is p(i+1,j), which is the next day at the open using a market order as demonstrated in the\u00a0DEVX V6\u00a0strategy. Market orders at the open for the next day is not the most efficient way to set entry prices. But all you want in the initial stage of designing a trading strategy is to find out if it is worthwhile even if it trades under adverse conditions.\n\nWhat is left to determine is:\u00a0B.*P\u00a0and\u00a0S.*P. I opted to use a buying trade unit (u) as a fix amount: u = q(i+1,j)p(i+1,j), with u having position sizes like $5k, $10k, $50k or more. This way I can scale the trading functions using this trade unit, and as a result, the payoff matrix would be scalable to any value I might want, need or consider feasible.\n\nThis would result in: u/p(i+1,j) = b(i+1,j), the quantity that will be bought on the next day at the opening price and that will be added to the then current inventory: h(i+1,j) = h(i,j) + b(i+1,j). The same would hold when selling shares: h(i+1,j) = h(i,j) - s(i+1,j). A strategy\u00a0H(S?) can be applied to a portfolio of selected stocks over the entire trading interval. For the Dow 30 stocks this would give: A(t) = A(0) + \u03a3(H(S?).*\u0394P(Dow)), and for the S&P100 100 stocks, one would get: A(t) = A(0) + \u03a3(H(S?).*\u0394P(SP100)).\n\nHaving set a buying trade unit (u), I can already answer some investment questions. If I double the trade unit by doubling the initial capital, what will happen? Easy: 2A(t) = 2A(0) + \u03a3(2H.*\u0394P). The position size, the trade unit, would be twice as big producing twice as much profits or losses as before. It's the same as if I traded 200 shares at a time compared to only 100 each trade; I would get twice as much profit or loss. I could scale the portfolio to any size I want as long as the trading strategy remains feasible, executable, marketable and sustainable.\n\nBy analyzing the whole trading strategy as a block, not in the Markowitz sense from period to period, but from start to finish, I can extract a different view of the portfolio management process. It is not anymore the determination of what can come next from period to period, from trade to trade, but more what is the combined and final output of all those trading decisions (all 195,000 or 650,000 decisions depending on the Dow 30 or S&P100 case). A global view of the problem is now required and it is all resumed in its payoff matrix: \u03a3(H.*\u0394P).\n\nStrategy Design\n\nThis provides a framework to develop trading strategies. Using a single price series as an example of a time-ordered sequence of prices, one could take from it a number n of time slices. At the limit, on an EOD strategy, one could buy at the open of the next day and sell the next. Thereby having n = 6,499 one day trades. The result would not be difficult to guess. It's equivalent to a Buy & Hold minus the trading expenses. Only slightly under-performing due to frictional costs. I could express such a strategy: \u03a3(H(S1).*\u0394P(Dow)) \u2192 \u03a3(hoI.*\u0394P(Dow)), as tending to the Buy & Hold.\n\nIf I took a trade every other week and sold the next, I would be in the market about \u00bd the time, or about 3,250 trading days. I could opt to be in the market only one day a week (1,300 days) set a fixed day or select at random one day a week. However, I should not expect to perform at the same level as if at a full market participation.\n\nThis raises basic and simple considerations to take care of. One of which is market exposure. A strategy might try splicing price series in such a way as to extract the best parts, those generating a profit. In reality, one might find that averaging out participating in the market half the time might also result in having one's equity working half the time as well. The equation: A(t) = A(0) + 1/2*\u03a3(H.*\u0394P) can express that the equity is only participating over half the trading interval, thereby generating half of the profit or loss even if this splicing is randomly generated.\n\nAnother consideration is the position size. Trading smaller positions of say half the usual trade size unit (u/2) will also have for equation: A(t) = A(0) + 1/2*\u03a3(H.*\u0394P) showing that reducing the bet size also reduces average generated profits. Understandably, Q is a profit/loss scaling factor as in q\u0394p.\n\nThe Buy & Hold is a full exposure and full participation trading strategy. And as such, historically it has managed to generate, on average, and including reinvested dividends, a little less than a 10% CAGR over long holding periods. As a matter of fact, holding for 20+ years will have a probability of generating a portfolio profit asymptotically approaching 1: E[\u03a3(hoI.*\u0394P(Dow)) > 0] \u2192 1. As Mr. Buffett has said many times before: \"... an almost guarantee to win in the long run\" simply due to market participation.\n\nIf you reduce exposure and participation, then you are operating with some drawbacks. It means that a trading strategy will have to compensate for these shortcomings. Say you use only half your capital and reduce your trade unit by half as well, this would result, on average, in A(t) = A(0) + 1/2*1/2*\u03a3(H.*\u0394P), the equivalent of putting only \u00bc of your capital at work. Should you want to beat the Buy & Hold with that, you better have an outstanding trading strategy since it might require something around a 16.27% compounded rate of return just to compensate and reach the same level as the Buy & Hold over a 25 year investment period: (1+r)t\u00a0= 1/4*(1+g)t, or in numbers: (1+0.10)25\u00a0= 1/4*(1+0.1627)25. Much more if you shorten the investment interval. Over a ten year period, it would require a CAGR of about 26.35% to be equivalent to its Buy & Hold counterpart: (1+0.10)10\u00a0= 1/4*(1+0.2635)10. This is a major drawback entirely related to the actual trading strategy\u00a0H\u00a0being used.\n\nNot only that but depending on your strategy design you might find yourself with an added problem: gradual performance degradation. This one is hidden and kind of insidious. It is aimed at the sequential and linear trader that is trying to average out his/her performance level over the year.\n\nSay you have a trading strategy designed to generate, on average, $300k/year from a starting capital of $1M, thereby an expected 30% return on your first year. Even though each year you make $300k, each year it would represent less and less as a percentage of the accumulating account. After just 9 years, your $300k gain would represent less than a 10% increase for the year. After 25 years, your original 30% return on the account is now less than a 4% increase.\n\nPortfolio Return Degradation\n\nPortfolio Return Degradation\n\n(click to enlarge)\u00a0\n\nIt is not the only source of long-term portfolio degradation. For instance, take a look at\u00a0Fixed Fraction\u00a0as a trading technique where one sets the same percentage gain or loss by setting a percent profit target and equal percent stop loss. The\u00a0paper\u00a0covers the subject and provides easy solutions to this problem as this one relates to the number of trades taken over the life of a portfolio. And since my trading strategies go for a large number of trades, it becomes wise to compensate for the fixed fraction shortcomings by simply over-compensating.\n\nI would say that it is imperative to address all these potential problems (and others) when designing a trading strategy in order to deliberately compensate for these deteriorating performance agents before or as they arise. And it is the responsibility of the strategy designer to do these things.\n\nNot compensating for these problems will not make them go away.\n\nIt is not after, that you need to compensate for these problems, it is before; right from the start. And that is by designing trading strategies that will take care of these problems or at least account for them and compensate where you can. Otherwise, you will have designed a trading strategy with inherent flaws that will inevitably show up as you spend more and more time in the pursuit of your alpha generation.\n\nAnother consideration is the need, not only to keep up with the Buy & Hold, but to outperform, not just once in awhile but over the long term where it really counts. If your end game is less than what could have been achieved by a simple Buy & Hold, then your efforts were kind of useless. And here again, the objective remains: \u03a3(H(S#n).*\u0394P(Dow)) > \u03a3(hoI.*\u0394P(Dow)) > 0. You definitely must outperform the Buy & Hold, otherwise... the Buy & Hold was the solution.\n\nAll that is being said is: if you deal with the same price series as everybody else, then the differences in payoff matrices, the outcome of the game, will have to come from the trading methodology itself.\n\n... to be continued ...\n\nCreated...\u00a0January 30, 2015,\u00a0 \u00a0 \u00a9 Guy R. Fleury. All rights reserved."}
{"text": "Retrieved from https://math.stackexchange.com/questions/1100198/expected-value-and-variance-of-a-stochastic-process\nText:\nHaving trouble finding expected value and variance of a stochastic process defined by SDE:\n\n$dX_{t} = a X_{t} dt + b dB_{t}$\n\n$X_0 = x$, $a$ and $b$ are constant values, $B_t$~$N(0,t)$\n\nThank you for any help or pointers. I will now post my progresses:\n\n1) Considering an auxiliary process $Z_t=X_te^{-at}$\n\n2) Using Ito's formula to derive $dZ_t$ omitting quadratic covariance term due to it being between a stochastic and a determinist process (=0):\n\n$dZ_t = e^{-at} dX_t+X_t(-ae^{-at}) dt$\n\n3) Plugging in $dX_t$:\n\n\n\n\n4) Applying the integral on both sides ( change of variable from t to s inside the integral)\n\n$\\int_{0}^{t}dZ_s = b \\int_{0}^{t}e^{-as}dB_s $\n\n$Z_t-Z_0 = b \\int_{0}^{t}e^{-as}dB_s $\n\n5) Plugging back in $Z_t=X_te^{-at}$ and isolating $X_t$\n\n\n$X_t=X_0e^{at} + be^{at}\\int_{0}^{t}e^{-as}dB_s$\n\n6) Applying expectations\n\n$\\mathbb{E}(X_t)=xe^{at} + be^{at}\\,\\mathbb{E}(\\int_{0}^{t}e^{-as}dB_s)$\n\nI end up with this expression, now I know that I should use the Dol\u00e9ans exponential to prove that the stochastic integral is 0. But how can I proceed further to recover both expected value and variance?\n\n  \u2022 $\\begingroup$ So what happens if you plug in $dX_t$? (And I suppose $(B_t)_{t \\geq 0}$ is a Brownian motion. If so, the statement \"$B_t \\sim N(0,1)$\" is not correct.) $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:01\n  \u2022 $\\begingroup$ You plugged in $dX_t$, so there should be no \"$dX_t$\" in the last 3 lines. (Note that the expression $dB_t dX_t$ doesn't even make sense...) Consequently, you end up with $$dZ_t = b dB_t.$$ Solve it! $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:07\n  \u2022 $\\begingroup$ yes, thank you I'll fix the mistakes you pointed out and try to solve it, kinda new to Latex and stoch calculus, please bear with me $\\endgroup$ \u2013\u00a0Clemente Cortile Jan 11 '15 at 17:09\n  \u2022 $\\begingroup$ You are welcome. (There is a typo in my previous comment, it should read $dZ_t = b e^{-a t} \\, dB_t$.) $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:24\n  \u2022 $\\begingroup$ So far your calculations are correct. What does this tell you about $X_t$? $\\endgroup$ \u2013\u00a0saz Jan 11 '15 at 17:43\n\nHint: The stochastic integral\n\n$$M_t := \\int_0^t e^{-as} \\, dB_s$$\n\nis a martingale. Hence, $\\mathbb{E}M_t = \\mathbb{E}M_0=0$. In order to calculate the variance of $X_t$ use It\u00f4's isometry.\n\nAlternative approach: Since stochastic integrals are martingales, we have\n\n$$\\mathbb{E}X_t- \\mathbb{E}X_0 = \\int_0^t a \\cdot \\mathbb{E}X_s \\, ds,$$\n\ni.e. $m(t) := \\mathbb{E}X_t$ solves the ordinary differential equation (ODE)\n\n$$m'(t) = a \\cdot m(t) \\qquad m(0) = \\mathbb{E}X_0.$$\n\nThe (unique) solution is $m(t) =e^{at} \\mathbb{E}X_0$. Similarly, using It\u00f4's formla, one can show that\n\n$$\\mathbb{E}(X_t^2)-\\mathbb{E}(X_0^2) = \\int_0^t \\left( 2a \\mathbb{E}(X_s^2) + b^2 \\right) \\, ds.$$\n\nConsequently, $\\sigma(t) := \\mathbb{E}(X_t^2)$ solves\n\n$$\\sigma'(t) = 2a \\sigma(t)+b, \\qquad \\sigma(0) = \\mathbb{E}(X_0^2).$$\n\nSolving this (linear) ODE yields $\\mathbb{E}(X_t^2)$.\n\nRemark: The process $(X_t)_{t \\geq 0}$ is called Ornstein-Uhlenbeck process.\n\n  \u2022 $\\begingroup$ How is the expected value of a process defined? Does it depend on $t$? $\\endgroup$ \u2013\u00a0user415535 Sep 13 '17 at 10:03\n  \u2022 1\n    $\\begingroup$ @user21312 Yes, it does depend on $t$; the expected value is the mapping $m(t) := \\mathbb{E}(X_t)$. $\\endgroup$ \u2013\u00a0saz Sep 13 '17 at 12:51\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/346384/how-to-turn-this-into-an-equation-and-then-sum-the-series\nText:\nI'm reading \"How would you move Mount Fuji?\", and one of the puzzzles/questions is:\n\nA train leaves Los Angeles for New York at a constant speed of 15 miles an hour. At the same moment, a train leaves New York for Los Angeles on the same track. It travels at a constant 20 miles an hour. At still the same moment, a bird leaves the Los Angeles train station and flies toward New York, following the track, at a speed of 25 miles an hour. When it reaches the train from New York, it instantly reverses direction. It travels at the same speed until it reaches the train from Los Angeles, when it reverses again, and so forth. The bird flies back and forth between the two trains until the very moment they collide. How far will the bird have travelled?\n\nIn the answer, they mention that it could be solved by using an infinite series (and that most people will probably have forgotten how to do it when asked in an interview, and that John von Neumann did so almost instantly when asked this type of question), but they do it another way. First, they note that the time until the trains crash is given by h, and d = 15h + 20h, where d is the distance (they use 3500). Thus, h = 100 hours. The distance that the bird travels is 25d. Thus, the answer is 2500 miles.\n\nI'm curious though, how does one solve this using an (infinite) series? How does one write this problem as a series in the first place? The only thing that I can get is that the series (of the hours that the bird spends flying) starts like this: (77.77, 9.73, ...)\n\n\nI will take a general tack; yes, you use an infinite series, as follows. We begin with the trains being a distance $d_0$ apart. After the bird goes up and back, the trains will be a distance $d_1$ apart. Once we find this distance, we will be able to sort out a geometric series because the bird repeats the same behavior ad infinitum.\n\nThe bird initially flies a distance $d_u$ (distance up) that is equal to $v_b t_u$, where $v_b$ is the bird's speed. This is equal to $d_0 - v_2 t_u$, where $v_2$ is the speed of the NY-to-LA train. Then $t_u = d_0/(v_b+v_2)$, and\n\n$$d_u = \\frac{v_b}{v_b+v_2} d_0$$\n\nNow the bird flies back to the other train and intercepts it at time $t_d$ later. The LA-to-NY train has traveled a distance $v_1 (t_u+t_d)$ by this time. The bird's position is at $d_u-v_b t_d$, and we solve for $t_d$. By then, the bird will have traveled at distance $v_b (t_u+t_d)$. The result is that, on the first pass, the bird travels a distance of\n\n$$v_b (t_u+t_d) = \\frac{2 v_b^2}{(v_b+v_1)(v_b+v_2)} d_0$$\n\nMeanwhile, the trains at this time are a distance apart of\n\n$$d_1 = [d_0-v_2(t_u+t_d)] - v_1 (t_u+t_d) = \\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}d_0$$\n\nBy now, we can see how to construct the series that will lead to the result. When the trains are a distance $d_k$, the bird travels a distance\n\n$$\\frac{2 v_b^2}{(v_b+v_1)(v_b+v_2)} d_k$$\n\n\n$$d_k = \\left [\\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}\\right ]^k d_0$$\n\nTherefore, the total distance the bird travels is\n\n$$\\begin{align}d &= \\frac{2 v_b^2 d_0}{(v_b+v_1)(v_b+v_2)} \\sum_{k=0}^{\\infty} \\left [\\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}\\right ]^k \\\\ &= \\frac{\\frac{2 v_b^2}{(v_b+v_1)(v_b+v_2)} d_0}{1-\\frac{(v_b-v_1)(v_b-v_2)}{(v_b+v_1)(v_b+v_2)}}\\end{align}$$\n\nI will leave the rest of the algebra to the reader. The final result is\n\n$$d = \\frac{v_b}{v_1+v_2} d_0$$\n\nFor the stated problem, the answer is $[25/(15+20)] 3500 \\text{miles} = 2500 \\text{miles}$.\n\n\nSuch a simple result from a relatively complicated analysis screams for a simple explanation. I guess you can look at it this way. Imagine the NY train is held fixed while the LA train moves at $v_1+v_2$ toward NY. The bird flies out at the same time at its speed $v_b$ and simply flies on. The LA train gets to NY in time $t=d_0/(v_1+v_2)$; in that time, the bird flies a distance $v_b d_0/(v_1+v_2)$.\n\n\nLet $v_a$, $v_b$ and $v$ be the speeds of the two trains and of the bird respectively (the first being the one from which the bird leaves), $d$ the distance between the cities. Let $t$ denote the time variable, and $t_k$ ($k\\in\\mathbb N$) the time starting from $t_0=$ in which the bird reverses direction for the $k$-th time. We may refer to Los Angeles and New York as $A$ and $B$ respectively.\n\nBy the time the bird has flown $t_1$, the trains have moved by $v_at_1$ and $v_bt_1$ respectively. Since the bird has to reach the second train we have $vt_1=d-v_bt_1$, so that $$ t_1=\\frac{d}{v+v_b} $$ Now the bird, which is $t_1v_a$ far from $B$, reverses direction and flies a distance $t_2v$ meeting the first train which now is $(t_1+t_2)v_a$ far from $A$. So $t_2v=d-(t_1+t_2)v_a-t_1v_b$ which gives $$ t_2 = \\frac{d - t_1(v_a+v_b)}{v+v_a} = d\\frac{v - v_a}{(v+v_a)(v+v_b)} $$ Now suppose you are at time $t_{2n}$, i.e. the bird touches the first train which is now $\\sum_{i=1}^{2n}t_iv_a$; by that time, the second train is far $\\sum_{i=1}^{2n}t_iv_b$ from $B$. The bird will meet the second train after $t_{2n+1}$, so $t_{2n+1}v=d-\\sum_{i=1}^{2n}t_iv_a-\\sum_{i=1}^{2n}t_iv_b-t_{2n+1}v_b$ which gives $$ t_{2n+1} = \\frac{d-\\sum_{i=1}^{2n}t_i(v_a+v_b)}{v+v_b} $$ The same reasoning shows that $$ t_{2n} = \\frac{d-\\sum_{i=1}^{2n-1}t_i(v_a+v_b)}{v+v_a} $$\n\nUsing induction you can show that $$ \\begin{cases} t_{2n} = & d\\frac{(v-v_a)^n(v-v_b)^{n-1}}{(v+v_a)^n(v+v_b)^n} \\\\[6pt] t_{2n+1} = & d\\frac{(v-v_a)^n(v-v_b)^n~~}{~(v+v_a)^n(v+v_b)^{n+1}} \\end{cases} $$ So altogether the bird will fly a distance of \\begin{align} v\\sum_{n=1}^\\infty t_n = & v\\left( \\sum_{n=1}^\\infty t_{2n} + \\sum_{n=0}^\\infty t_{2n+1} \\right) \\\\ = & dv\\left(\\frac{1}{v-v_b}+\\frac{1}{v+v_b}\\right) \\sum_{n=0}^\\infty \\left[ \\frac{(v-v_a)(v-v_b)}{(v+v_a)(v+v_b)} \\right]^n - \\frac{dv}{v-v_b} \\end{align} The term $\\frac{dv}{v-v_b}$ has been taken out since the first sum starts from $n=1$ and not $n=0$.\n\nSince $\\sum_{n=0}^\\infty x^n=\\frac{1}{1-x}$ for $x\\in(0,1)$, you have a total distance of $$ dv\\left(\\frac{1}{v-v_b}+\\frac{1}{v+v_b}\\right) \\frac{1}{1- \\frac{(v-v_a)(v-v_b)}{(v+v_a)(v+v_b)} } - \\frac{dv}{v-v_b} = \\frac{vd}{(v_a+v_b)} $$\n\n\nYour Answer"}
{"text": "Retrieved from https://math.stackexchange.com/questions/1966062/how-do-you-find-the-area-of-a-parallelogram-with-the-vertices/1966509\nText:\nHow do you find the area of a parallelogram with the following vertices; $A(4,2)$, $B(8,4)$, $C(9,6)$ and $D(13,8)$.\n\n\nclosed as off-topic by user21820, Xander Henderson, Jos\u00e9 Carlos Santos, YuiTo Cheng, RRL May 18 at 2:36\n\n\n\n  \u2022 $\\begingroup$ Use the determinant. $\\endgroup$ \u2013\u00a0Steven Gubkin Oct 13 '16 at 13:05\n\nFor this, we plan to use the Shoelace formula.\n\nShoelace Formula: Given the coordinates of vertices of a polygon, its area is found by $$A=\\frac 12\\left|\\sum_{i=1}^{n-1}x_iy_{i+1}+x_ny_1-\\sum_{i=1}^{n-1}x_{i+1}y_i-x_1y_n\\right|$$ Or, in other words, we have $$A=\\frac 12|x_1y_2+x_2y_3+\\ldots x_{n-1}y_n+x_ny_1-x_2y_1-x_3y_2-\\ldots -x_ny_{n-1}-x_1y_n|$$ Where $A$ is the area of the polygon, and $(x_i,y_i)$ with $i=1,2,3\\dots$ are the vertices of the polyon\n\nSo with your case, the vertices are $A(4,2), B(8,4), C(9,6)$ and $D(13,8)$. We let $x_1=13,y_1=8,x_2=9,y_2=6,x_3=4,y_3=2,x_4=8,y_4=4$ and the area is given by $$A=\\frac 12|13\\cdot 6+9\\cdot 2+4\\cdot 4+8\\cdot 8-9\\cdot 8-4\\cdot 6-8\\cdot 2-13\\cdot 4|\\\\=\\frac 12\\cdot 12=6$$\n\n  \u2022 $\\begingroup$ You answered with another person's answer? xD $\\endgroup$ \u2013\u00a0Billy Rubina Oct 13 '16 at 8:15\n  \u2022 4\n    $\\begingroup$ This is hitting a nail with a sledge hammer. There aren't many polygons that are as simple to handle as parallelograms. Or to be more specific, it is very probably the computation for parallelograms (and derived from that, triangles) that serves as basis for deriving the shoelace formula. $\\endgroup$ \u2013\u00a0Marc van Leeuwen Oct 13 '16 at 9:14\n\nThe absolute value of the cross product of two vectors $\\vec{a}, \\vec{b} \\in \\mathbb{R}^3$ spanning the parallelogram is its area:\n\n$$A_\\text{parallelogram}= \\left|\\vec{a}\\times\\vec{b}\\right|$$\n\nSo in your case we have to write the points in $\\mathbb{R}^2$ as vectors in $\\mathbb{R}^3$ and apply the formula:\n\n$\\vec{AB}\u00a0= \\begin{pmatrix}8\\\\4\\\\0\\end{pmatrix} -\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} =\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix}$\n\n$\\vec{AD}\u00a0= \\begin{pmatrix}13\\\\8\\\\0\\end{pmatrix} -\\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} =\\begin{pmatrix}9\\\\6\\\\0\\end{pmatrix}$\n\n$A_\\text{parallelogram}= \\left|\\vec{AB}\\times\\vec{AD}\\right| = \\left| \\begin{pmatrix}4\\\\2\\\\0\\end{pmatrix} \\times \\begin{pmatrix}9\\\\6\\\\0\\end{pmatrix} \\right| = \\left|\\begin{pmatrix}0\\\\0\\\\6\\end{pmatrix} \\right| = 6$\n\nYou might have noticed that this simplifies to\n\n$$A_\\text{parallelogram}= (b_1 - a_1)(d_2-a_2)-(b_2-a_2)(d_1-a_1)$$ $$= (8 - 4)(8-2)-(4-2)(13-4)=-24-(-18)=6$$\n\n\nThere are plenty of ways, such as the Shoelace Theorem and Pick's Theorem.\n\nIf you have a graph, you can also simply draw a rectangle around the shape and subtract the parts you don't want.\n\n\nI think this is a special case of shoelace theorem. A quad is made up of two triangle and area of a triangle is\n\n$${1\\over 2}{|x_1(y_2 - y_3) + x_2(y_3 - y_1) + x_3(y_1 - y_2)|}$$\n\nOr you can use distance formula\n\n$$distance = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$\n\nand then heron's formula\n\n$$A = {1\\over 2}\\sqrt{s(s-a)(s-b)(s-c))}$$ Where s is the semi-perimeter of the triangle and, a,b,c are the length of its sides.\n\n\nFor any quadrilateral the area is one-half the magnitude of the cross product of the two diagonal vectors.\n\n\nI am just providing you with the simplest shortcut to doing this\n\nPick the first three points A(4,2), B(8, 4) and C(9, 6)\n\nNegate point A to get (-4, -2) and add to the other two points B and C. Add x's and y's so you have a new point\n\n(4, 2) (5, 4) Now use determinant to find the area.\n\n16-10 = 6sq unit\n\nNeglect any negative sign that arises\n\n  \u2022 $\\begingroup$ I don't understand so much. What is 6sq unit? $\\endgroup$ \u2013\u00a0El borito Jan 25 at 4:47\n  \u2022 $\\begingroup$ square unit as in square meter or any unit of length measurement...mm, cm, m..etc $\\endgroup$ \u2013\u00a0Daniel Wasty Jan 25 at 4:49"}
{"text": "Retrieved from https://math.stackexchange.com/questions/631576/probability-of-x-heads-before-y-consecutive-tails-in-n-biased-coin-tosses\nText:\nI have another coin toss question:\n\nAssume I am tossing a biased coin n times with probability p of coming up heads. What is the probability that x heads come up, before y consecutive tails?\n\nA code example would be preferable.\n\n  \u2022 $\\begingroup$ Just to be clear about what you mean, is HTHTT a case where $x=2$ heads come up before $y=2$ consecutive tails? Or did you mean to say \"$x$ consecutive heads\"? $\\endgroup$ \u2013\u00a0Barry Cipra Jan 8 '14 at 17:42\n  \u2022 $\\begingroup$ @BarryCipra, Yes, the heads do not need to be consecutive. $\\endgroup$ \u2013\u00a0user27 Jan 8 '14 at 17:46\n\nConsider the following events:\n\n$A_{x,y}$: You observe $x$ heads before $y$ consecutive tails.\n\n$B_{x,y}$: You observe $y$ consecutive tails before $x$ heads.\n\nLet $X_{i}$ follow a Geometric(p). This means that $X_{i}$ denotes the number of tail counts until you observe the first head with a biased coin. Observe that, in particular, $P(A_{1,y}) = P(X_{1} < y)$.\n\nIn order to solve for the general case, consider $X_{1},\\ldots,X_{x}$ i.i.d. Geometric(p). I claim that:\n\n\\begin{align*} P(A_{x,y}) = P(X_{1} < y, \\ldots,X_{x} < y) = P(X_{1} < y)^{x} \\end{align*}\n\nIn order to understand the claim, you can think of $X_{i}$ as the number of observed tails it takes until you observe a head after having already observed $i-1$ heads in the past. Hence, we only need to find $P(X_{1} < y)$. This is well known and equals $1-(1-p)^{y}$.\n\nHence, in general $P(A_{x,y}) = (1-(1-p)^{y})^{x}$\n\n  \u2022 $\\begingroup$ Thank you! Though this does not answer my question exactly, since I was asking for a specific maximum number of tosses. On second thought, I don't actually need to know this, so I marked your answer as accepted. $\\endgroup$ \u2013\u00a0user27 Jan 9 '14 at 16:09\n\nYour Answer"}
